- en: Chapter 3\. Computing Technology Basics for Life Scientists
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章。生命科学家的计算技术基础
- en: In an ideal world, you wouldn’t need to worry too much about computing infrastructure
    when you’re pursuing your research. In fact, in later chapters we introduce you
    to systems that are specifically designed to abstract away the nitty-gritty of
    computing infrastructure in order to help you focus on your science. However,
    you will find that a certain amount of terminology and concepts are unavoidable
    in the real world. Investing some effort into learning them will help you to plan
    and execute your work more efficiently, address performance challenges, and achieve
    larger scale with less effort. In this chapter, we review the essential components
    that form the most common types of computing infrastructure, and we discuss how
    their strengths and limitations inform our strategies for getting work done efficiently
    at scale. We also go over key concepts such as parallel computing and pipelining,
    which are essential in genomics because of the need for automation and reproducibility.
    Finally, we introduce virtualization and lay out the case for cloud infrastructure.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想的情况下，当您进行研究时，您不需要过多关注计算基础设施。事实上，在后面的章节中，我们会向您介绍专门设计的系统，以便摆脱计算基础设施的繁琐细节，帮助您专注于科学研究。然而，在现实世界中，您会发现某些术语和概念是不可避免的。投入一些精力学习它们将有助于您更有效地规划和执行工作，解决性能挑战，并以更少的努力实现更大规模。在本章中，我们回顾形成最常见类型计算基础设施的基本组件，并讨论它们的优势和局限性如何影响我们在大规模高效完成工作的策略。我们还讨论了诸如并行计算和管道化等关键概念，由于基因组学中自动化和可重现性的需求，这些概念至关重要。最后，我们介绍了虚拟化，并阐述了云基础设施的案例。
- en: The first few sections in this chapter are aimed at readers who have not had
    much training, if any, in informatics, programming, or systems administration.
    If you are a computational scientist or an IT professional, feel free to skip
    ahead until you encounter something that you don’t already know. The last two
    sections, which together cover pipelining, virtualization, and the cloud, are
    more specifically focused on the problems that we tackle in this book and should
    be informative for all readers regardless of background.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的前几节旨在针对那些在信息学、编程或系统管理方面没有太多培训经验（如果有的话）的读者。如果您是计算科学家或IT专业人士，请随意跳过，直到遇到您尚未了解的内容。最后两节涵盖管道化、虚拟化和云等内容，更专注于本书探讨的问题，无论背景如何，对所有读者都应该具有信息价值。
- en: Basic Infrastructure Components and Performance Bottlenecks
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本基础设施组件和性能瓶颈
- en: Don’t worry; we’re not going to make you sit through an exhaustive inventory
    of computer parts. Rather, we’ve put together a short list of the components,
    terminology, and concepts that you’re most likely to encounter in the course of
    your work. In relation to each of these, we’ve summarized the main performance
    challenges and the strategies that you might need to consider to use them effectively.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心；我们不会让您详尽列举计算机零件清单。相反，我们为您整理了一个关于您在工作过程中最有可能遇到的组件、术语和概念的简短清单。关于每一个，我们总结了主要的性能挑战和您可能需要考虑的有效使用策略。
- en: Let’s begin with a brief overview of the types of processors that you might
    come across in scientific computing today.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先简要概述一下您今天在科学计算中可能会遇到的处理器类型。
- en: 'Types of Processor Hardware: CPU, GPU, TPU, FPGA, OMG'
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理器硬件类型：CPU、GPU、TPU、FPGA、OMG
- en: At its simplest, a *processor* is a component in your computer that performs
    computations. There are various types of processors, with the most common being
    the *central processing unit* (CPU) that serves as the main processor in general-use
    computers, including personal computers such as laptops. The CPU in your laptop
    may have multiple cores, subunits that can process operations more or less independently.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在最简单的情况下，*处理器*是您计算机中执行计算的一个组件。有各种类型的处理器，其中最常见的是作为一般用途计算机的主处理器的*中央处理单元*（CPU），包括笔记本电脑等个人计算机。您笔记本电脑中的CPU可能有多个核心，这些子单元可以相对独立地处理操作。
- en: In addition to a CPU, your personal computer also has a *graphical processing
    unit* (GPU) that processes the graphical information for display on your screen.
    GPUs came into the limelight with the development of modern video games, which
    require extremely fast processing to ensure smooth visual rendering of game action.
    In essence, the GPU solution outsources the rather specific type of processing
    involved in mathematical calculations like matrix and vector operations from the
    CPU to a secondary processing unit that specializes in handling certain types
    of calculations that are applied to graphical data very efficiently. As a result,
    GPUs are also becoming a popular option for certain types of scientific computing
    applications that involve a lot of matrix or vector operations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 除了CPU，你的个人计算机还配备了*图形处理单元*（GPU），用于处理显示屏上的图形信息。GPU随着现代视频游戏的发展而引起关注，这些游戏要求非常快的处理速度，以确保平滑地渲染游戏动作的视觉效果。实质上，GPU解决方案将数学计算（如矩阵和向量操作）中的特定类型处理从CPU外包到专门处理某些类型计算的辅助处理单元中，这些计算非常有效地应用于图形数据。因此，GPU也成为某些涉及大量矩阵或向量运算的科学计算应用的热门选择。
- en: The third type of processor you should know about is called a *field-programmable
    gate array* (FPGA), which, despite breaking with the *PU naming convention, is
    also a type of processing unit; however, it’s unlikely that you’ll find one in
    your laptop. What’s interesting about FPGAs is that unlike GPUs, FPGAs were not
    developed for a specific type of application; quite the contrary, they were developed
    to be adaptable for custom types of computations. Hence “field-programmable” as
    part of their name.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该了解的第三种处理器称为*现场可编程门阵列*（FPGA），尽管与*PU命名约定不同，但它也是一种处理单元；然而，你的笔记本电脑中不太可能找到它。关于FPGA的有趣之处在于，与GPU不同，FPGA并非为特定类型的应用程序开发；相反，它们被开发为适应定制类型的计算。因此，“现场可编程”作为其名称的一部分。
- en: On GCP, you might also come across something called a *tensor processing unit*
    (TPU), which is a kind of processor developed and branded by Google for machine
    learning applications that involve tensor data. A *tensor* is a mathematical concept
    used to represent and manipulate multiple layers of data related to vectors and
    matrices. Consider that a vector is a tensor with one dimension, and a matrix
    is a tensor with two dimensions; more generally, tensors can have arbitrary numbers
    of dimensions beyond that, so they are very popular in machine learning applications.
    TPUs belong to a category of processors called [application-specific integrated
    circuit](https://oreil.ly/bz4mv) (ASIC), which are custom designed for specialized
    uses rather than general use.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在GCP上，你可能也会遇到一种称为*张量处理单元*（TPU）的处理器，这是谷歌专门为涉及张量数据的机器学习应用开发和品牌化的处理器。*张量*是一个数学概念，用于表示和操作与向量和矩阵相关的多层数据。考虑到向量是一个具有一维的张量，而矩阵是一个具有两维的张量；更一般地说，张量可以具有超出这些维度的任意数量的维度，因此它们在机器学习应用中非常流行。TPU属于称为[专用集成电路](https://oreil.ly/bz4mv)（ASIC）的处理器类别，这些处理器专门设计用于特定用途而非通用用途。
- en: Now that you have the basic types of processors down, let’s talk about how they
    are organized in typical high-performance computing setups.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经掌握了基本的处理器类型，让我们讨论它们如何在典型的高性能计算设置中组织起来。
- en: 'Levels of Compute Organization: Core, Node, Cluster, and Cloud'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算组织的层次：核心，节点，集群和云
- en: When you move beyond personal computers and into the world of high-performance
    computing, you’ll hear people talk about cores, nodes, and either clusters or
    clouds, as illustrated in [Figure 3-1](#levels_of_compute_organization). Let’s
    review what these mean and how they relate to one another.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当你超越个人计算机进入高性能计算领域时，你会听到人们谈论核心，节点以及集群或云，如[图3-1](#levels_of_compute_organization)所示。让我们回顾一下它们的含义及其彼此之间的关系。
- en: '![Levels of compute organization ](Images/gitc_0301.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![计算组织的层次](Images/gitc_0301.png)'
- en: Figure 3-1\. Levels of compute organization.
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1\. 计算组织的层次。
- en: 'Low level: core'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 低层次：核心
- en: 'A *core* is the smallest indivisible processing unit within a machine’s, or
    node’s, processor unit, which can comprise one or more cores. If your laptop or
    desktop is relatively recent, its CPU probably has at least two cores, and is
    therefore called *dual-core*. If it has four, it’s a *quad-core*, and so on. High-end
    consumer machines can have more than that; for example, the latest Mac Pro has
    a twelve-core CPU (which should be called dodeca-core if we follow the Latin terminology)
    but the CPUs on professional-grade machines can have tens or hundreds of cores,
    and GPUs typically have an order of magnitude more, into the thousands. Meanwhile,
    TPUs have core counts in the single digits like consumer CPUs, and FPGAs break
    the mold entirely: their cores are defined by how they are programmed, not by
    how they are built.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*核心*是机器或节点处理器单元内的最小不可分割处理单元，可以由一个或多个核心组成。如果您的笔记本电脑或台式机比较新，其CPU可能至少有两个核心，因此被称为*双核*。如果有四个核心，则为*四核*，依此类推。高端消费级机器可以拥有更多核心；例如，最新的Mac
    Pro拥有十二核CPU（如果按照拉丁术语来说应该称为十二核）。但是，专业级机器的CPU可以拥有数十个或数百个核心，而GPU通常有数量级更高的核心，达到数千个。与此同时，TPU的核心数量与消费级CPU类似，而FPGA则完全打破了这一模式：它们的核心是由编程方式定义的，而不是由建造方式定义的。'
- en: 'Mid level: node/machine'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中层：节点/机器
- en: A *node* is really just a computer that is part of a cluster or cloud. It is
    analogous to the laptop or desktop computer that most of us interact with primarily
    in our day-to-day work, except without the dedicated monitor and peripherals we
    are used to seeing associated with personal computers. A node is also sometimes
    simply called a *machine*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*节点*实际上只是集群或云中的计算机。它类似于我们在日常工作中主要与之交互的笔记本电脑或台式电脑，但没有我们通常与个人计算机相关联的专用显示器和外围设备。节点有时也简称为*机器*。
- en: 'Top level: cluster and cloud'
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 顶层：集群和云
- en: A cluster and a cloud are both a collection of machines/nodes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一个集群和一个云都是一组机器/节点。
- en: A *cluster* is an HPC structure composed of nodes networked together to some
    extent. If you have access to a cluster, the chances are that either it belongs
    to your institution, or your company is renting time on it. A cluster can also
    be called a *server farm* or a *load-sharing facility*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*集群*是由节点部分网络连接在一起的HPC结构。如果您可以访问集群，那么很可能它要么属于您的机构，要么是您的公司租用的时间。集群也可以称为*服务器农场*或*负载共享设施*。
- en: A *cloud* is different from a cluster in that in its resting state, its nodes
    are not explicitly networked together. Rather, it is a collection of independent
    machines that are available to be networked (or not) depending on your needs.
    We cover that in more detail in the final section of this chapter, along with
    the concept of virtualization, which gives us virtual machines (VMs), and containerization,
    which gives us Docker containers.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*云*与集群不同，因为在其休眠状态下，其节点不是显式地网络连接在一起的。相反，它是一组独立的机器，可以根据您的需求进行网络连接（或不连接）。我们在本章的最后一节详细介绍了这一点，还包括虚拟化的概念，它提供了虚拟机（VM）以及容器化，它提供了Docker容器。
- en: For now, however, we move on to the very common concern of how to use a given
    set of computing infrastructure effectively, which typically revolves around identifying
    and solving key computational bottlenecks. As with the rest of this chapter, an
    in-depth exploration of this topic would be beyond the scope of this book, so
    we’re aiming simply to familiarize you with the key concepts and terminology.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们转向如何有效使用给定的计算基础设施的非常常见问题，这通常涉及识别和解决关键的计算瓶颈。与本章的其余部分一样，深入探讨这个主题将超出本书的范围，因此我们的目标仅仅是让您熟悉关键概念和术语。
- en: Addressing Performance Bottlenecks
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理性能瓶颈
- en: You’ll occasionally find that some computing operations seem slow and you’ll
    need to figure out how to make them go faster (if possible). The solutions available
    to you will depend on the nature of the bottleneck you’re facing.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 您偶尔会发现某些计算操作似乎很慢，您需要找出如何使它们更快（如果可能的话）。可供您选择的解决方案将取决于您面临的瓶颈的性质。
- en: 'At a very high level, following are the main operations that the computer typically
    has to perform (not necessarily in a linear order):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在非常高的层次上，计算机通常必须执行以下主要操作（不一定是线性顺序）：
- en: Read some data into memory from the permanent storage where it resides at rest
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从永久存储中将一些数据读入内存
- en: Have the processor execute instructions, transforming data and producing results
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使处理器执行指令，转换数据并产生结果
- en: Write results back to the permanent storage
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果写回永久存储
- en: 'Data storage and I/O operations: hard drive versus solid state'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据存储和I/O操作：硬盘对比固态
- en: Steps 1 and 3 are called *I/O operations* (I/O stands for input/output). You
    might hear people describe some software programs as being “I/O-bound,” which
    means the part of the program that takes the longest is reading and writing data
    to and from relatively slow storage. This is typically the case for simple programs
    that do things like file format conversions, in which you’re just reading in some
    data and writing it out in a different shape, and you’re not doing any real computing
    (i.e., there’s little to no math involved). In those cases, you can speed up operation
    by using faster storage drives; for example, solid-state drives (SSDs) rather
    than hard-disk drives (HDDs). The key difference between them is that HDDs have
    physical disks called platters that spin and an armature that reads data from
    and writes it to the platter via magnetics—like a tiny high-tech turntable—whereas
    SSDs have no moving parts. That makes SSDs less prone to physical malfunctions
    and also quite a bit faster at accessing data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 1 和 3 被称为*I/O操作*（I/O代表输入/输出）。你可能会听到一些人将某些软件程序描述为“I/O受限”，这意味着程序中最耗时的部分是从相对缓慢的存储中读取和写入数据。这通常适用于简单的程序，比如文件格式转换，其中你只是读取一些数据并以不同的形式写出，没有进行实际的计算（即几乎没有涉及数学运算）。在这些情况下，你可以通过使用更快的存储驱动器来加快操作速度；例如固态硬盘（SSD）而不是硬盘驱动器（HDD）。它们之间的关键区别在于，HDD有物理盘片旋转和通过磁性从盘片读取和写入数据的臂；就像一个微型高科技转盘一样，而SSD没有移动部件。这使得SSD不太容易发生物理故障，并且在访问数据时也快得多。
- en: If you’re working with a networked infrastructure in which the storage drives
    are not directly connected to the computing nodes, you will also be limited by
    the speed at which data can be transferred over the network connections. That
    can be determined by hardware factors as pedestrian as the kind of cables used
    to connect the network parts. Although you might not notice the difference when
    computing on small files, you definitely will notice it when running on whole
    genomes; and even on a network with very fast transfer speeds, transferring whole
    genomes will consume some noticeable time.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个网络基础设施中工作，其中存储驱动器不直接连接到计算节点，你的速度也会受到网络连接传输数据速度的限制。这可能由硬件因素决定，例如连接网络部件所用的电缆的种类。尽管在处理小文件时你可能察觉不到差异，但在处理整个基因组时，你肯定会注意到；即使在传输速度非常快的网络上，传输整个基因组也会耗费一些显著的时间。
- en: 'Memory: cache or crash'
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内存：缓存或崩溃
- en: Step 2 is where your program is taking data and applying some kind of transformation
    or calculation, aka the interesting part. For a lot of applications, the calculation
    requires holding a lot of information in memory. In those cases, if your machine
    doesn’t have enough memory, it might resort to *caching*, which is a way of using
    local storage space as a substitute for real memory. That allows you to keep working,
    but now your processes become I/O bound because they need to copy data back and
    forth to slow storage, which takes you back to the first bottleneck. In extreme
    cases, the program can stall indefinitely, fail to complete, or crash. Sometimes,
    it’s possible for a developer to rewrite the program to be smarter about the information
    it needs to see concurrently, but when it’s not, the solution is to simply add
    more memory. Fortunately, unlike memory in humans, computer memory is just hardware,
    and it comes relatively cheap.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 2 是你的程序获取数据并应用某种转换或计算的地方，也就是有趣的部分。对于许多应用程序来说，这种计算需要在内存中保存大量信息。在这些情况下，如果你的机器内存不足，它可能会采用*缓存*的方式，这是一种利用本地存储空间作为真实内存替代品的方法。这使得你可以继续工作，但现在你的进程变成了I/O受限，因为它们需要将数据来回复制到慢速存储器中，这又使你回到了第一个瓶颈。在极端情况下，程序可能会无限期地停顿、无法完成或崩溃。有时，开发人员可以重新编写程序，使其在并发查看所需信息时更加智能，但当无法做到这一点时，解决方案就是简单地增加更多内存。幸运的是，与人类的记忆不同，计算机内存只是硬件，而且相对便宜。
- en: 'Specialized hardware and code optimizations: navigating the trade-offs'
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 专门的硬件和代码优化：权衡取舍
- en: At times, the nature of the program requires the processor itself to do a lot
    of heavy lifting. For example, in the widely used GATK tool `HaplotypeCaller`,
    an operation can calculate genotype likelihoods; we need to compute the likelihood
    of every single sequence read given each candidate allele using a hidden Markov
    model (HMM) called *PairHMM* (don’t worry if this sounds like gibberish at the
    moment—it’s just a bunch of genomics-specific math). In some areas of the genome,
    that leads us to do millions of computations per site across a very large number
    of sites. We know from performance profiling tests, which record how much time
    is spent in processing for each operation in the program, that PairHMM is by far
    the biggest bottleneck for this tool. We can reduce this bottleneck in some surface-level
    ways; for example, by making the program skip some of the computations for cases
    in which we can predict they will be unnecessary on uninformative. After all,
    the fastest way to calculate something is to not calculate it at all.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，程序的性质要求处理器本身进行大量的重型工作。例如，在广泛使用的GATK工具`HaplotypeCaller`中，一个操作可以计算基因型似然度；我们需要使用名为*PairHMM*的隐马尔可夫模型（HMM）来计算每个候选等位基因给定每个序列读取的似然度（如果这听起来像胡言乱语，目前不用担心——这只是一堆基因组特定的数学）。在基因组的某些区域，这导致我们在非常多的位点上每个位点做数百万次计算。通过性能分析测试，我们知道PairHMM对该工具来说是迄今为止最大的瓶颈。我们可以在一些表面层次上减少这一瓶颈；例如，通过使程序跳过一些我们可以预测在无效信息的情况下将不需要的计算。毕竟，计算某事物最快的方法是根本不计算它。
- en: Being lazy gets us only so far, however, so to get to the next level, we need
    to think about the kind of processor we can (or should) use for the work we need
    to do. Not just because some processors run faster than others, but also because
    it’s possible to write program instructions in a way that is very specific to
    a particular type and architecture of processor. If done well, the program will
    be extra efficient in that context and therefore run faster. That is what we call
    *code optimization*, and more specifically *native* code optimization because
    it must be written in a low-level language that the processor understands “natively”
    without going through additional translation layers.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅因为懒惰使我们只能走到这一步，所以为了达到更高的水平，我们需要考虑我们需要做的工作的处理器类型（或应该使用的处理器类型）。不仅因为某些处理器运行比其他处理器更快，而且因为可以以一种非常特定于特定类型和架构处理器的方式编写程序指令。如果做得好，程序在这种情况下将特别高效，因此运行得更快。这就是我们所谓的*代码优化*，更具体地说是*本地*代码优化，因为它必须用处理器能够“本地”理解的低级语言编写，而不是通过额外的翻译层。
- en: Within a type of processor like CPUs, different manufacturers (e.g., Intel and
    AMD) develop different *architectures* for different generations of their products
    (e.g., Intel Skylake and Haswell), and these different architectures provide opportunities
    for optimizing the software. For example, the GATK package includes several code
    modules corresponding to alternative implementations of the PairHMM algorithm
    that are optimized for specific Intel processor architectures. The program automatically
    activates the most appropriate version when it finds itself running on Intel processors,
    which provides some useful speed gains.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在像CPU这样的处理器类型中，不同的制造商（例如Intel和AMD）为其产品的不同世代（例如Intel Skylake和Haswell）开发了不同的*架构*，这些不同的架构为优化软件提供了机会。例如，GATK软件包包括几个代码模块，对应于PairHMM算法的替代实现，这些实现针对特定的Intel处理器架构进行了优化。程序在运行在Intel处理器上时会自动激活最合适的版本，从而提供一些有用的速度增益。
- en: However, the benefits of hardware optimizations are most obvious across processor
    types; for example, if you compare how certain algorithms perform when implemented
    to run on FPGAs instead of CPUs. The Illumina DRAGEN toolkit (originally developed
    by Edico Genome) includes implementations of tools like `HaplotypeCaller` that
    are optimized to run on FPGAs and as a result are much faster than the original
    Java software version.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，硬件优化的好处在于跨处理器类型最为明显；例如，当你比较某些算法在实施为在FPGA上运行而不是在CPU上运行时的表现如何时。Illumina DRAGEN工具包（最初由Edico
    Genome开发）包括了优化为在FPGA上运行的工具实现，例如`HaplotypeCaller`，结果比原始的Java软件版本快得多。
- en: The downside of hardware-optimized implementations is that by definition, they
    require specialized hardware. This can be a big problem for the many research
    labs that rely on shared institutional computing systems and don’t have access
    to other hardware. In contrast, applications written in Java, like GATK, can run
    on a wide range of hardware architectures because the Java Virtual Machine (JVM)
    translates the application code (called *bytecode* in the Java world) into instructions
    appropriate for the machine. This *separation of concerns* (SoC) between the bytecode
    of Java and what actually is executed on the machine is called an *abstraction
    layer* and it’s incredibly convenient for everyone involved. Developers don’t
    need to worry about exactly what kind of processor we have in our laptops, and
    we don’t need to worry about what kind of processor they had in mind when they
    wrote the code. It also guarantees that the software can be readily deployed on
    standard off-the-shelf hardware, which makes it usable by anyone in the world.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件优化实现的缺点在于，根据定义，它们需要专门的硬件。这对于依赖共享机构计算系统并且无法访问其他硬件的许多研究实验室可能是一个大问题。相比之下，用Java编写的应用程序，如GATK，可以在各种硬件架构上运行，因为Java虚拟机（JVM）将应用程序代码（在Java世界中称为*字节码*）转换为适合该机器的指令。Java字节码和实际在机器上执行的内容之间的*关注分离*（SoC）称为*抽象层*，对于所有相关方来说都非常方便。开发人员不需要担心我们的笔记本电脑上有什么样的处理器，我们也不需要担心他们编写代码时考虑了什么样的处理器。它还保证软件可以轻松部署在标准的现成硬件上，这使得任何人都可以使用。
- en: Sometimes, you’ll need to choose between different implementations of the same
    algorithms depending on what is most important to you, including how much you
    prize speed over portability and interoperability. Other times, you’ll be able
    to enjoy the best of both worlds. For example, the GATK team at the Broad Institute
    has entered into a collaboration with the DRAGEN team at Illumina, and the two
    teams are now working together to produce unified DRAGEN-GATK pipelines that will
    be available both as a free open source version (via Broad) and as a licensed
    hardware-accelerated version (via Illumina). A key goal of the collaboration is
    to make the two implementations functionally equivalent—meaning that you could
    run either version and get the same results within a margin of error considered
    to be insignificant. This will benefit the research community immensely in that
    it will be possible to combine samples analyzed by either pipeline into downstream
    analyses without having to worry about batch effects, which we discussed briefly
    in the previous chapter.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，你需要根据对你最重要的因素选择相同算法的不同实现之间。包括你更看重速度还是可移植性和互操作性。有时，你将能够同时享受两全其美。例如，Broad研究所的GATK团队与Illumina的DRAGEN团队展开合作，两个团队现在正在共同努力制作统一的DRAGEN-GATK流水线，这将作为免费开源版本（通过Broad）和作为经许可的硬件加速版本（通过Illumina）提供。合作的一个关键目标是使这两种实现在功能上等效——这意味着你可以运行任一版本并在被认为是微不足道的误差范围内获得相同的结果。这将极大地使研究社区受益，因为可以将任一流水线分析的样本结合到下游分析中，而无需担心我们在上一章中简要讨论的批次效应。
- en: Parallel Computing
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行计算
- en: When you can’t go faster, go parallel. In the context of computing, *parallel
    computing*, or *parallelism*, is a way to make a program finish sooner by performing
    several operations in parallel rather than sequentially (i.e., waiting for each
    operation to finish before starting the next one). Imagine that you need to cook
    rice for 64 people, but your rice cooker can make enough rice for only 4 people
    at a time. If you need to cook all of the batches of rice sequentially, it’s going
    to take all night. But if you have eight rice cookers that you can use in parallel,
    you can finish up to eight times sooner.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当你无法更快地前进时，就并行处理。在计算领域中，*并行计算*，或者*并行性*，是一种通过同时执行多个操作而不是按顺序（即等待每个操作完成后再开始下一个）来使程序更快完成的方法。想象一下，你需要为64个人煮饭，但你的电饭锅一次只能做够4个人的份量。如果你需要按顺序煮所有批次的米饭，那将需要整夜的时间。但如果你有八个可以并行使用的电饭锅，你可以提前八倍完成。
- en: 'This is a simple idea but it has a key requirement: you must be able to break
    the job into smaller tasks that can be performed independently. It’s easy enough
    to divide portions of rice because rice itself is a collection of discrete units.
    But you can’t always make that kind of division: for example, it takes one pregnant
    woman nine months to grow a baby, but you can’t do it in one month by having nine
    women share the work.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的想法，但它有一个关键要求：你必须能够将工作分解为可以独立执行的较小任务。将米饭分成部分很容易，因为米饭本身是一组离散单位。但你并不总是能够做到这种分割：例如，一个孕妇需要九个月才能生出一个婴儿，但你不能让九个女人共同完成这项工作。
- en: The good news is that most genomic analyses are more like rice than like babies—they
    essentially consist of a series of many small independent operations that can
    be parallelized. So how do we get from cooking rice to executing programs?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，大多数基因组分析更像是米饭而不是婴儿——它们基本上由许多可以并行化的小独立操作组成。那么我们如何从煮米饭转变为执行程序呢？
- en: Parallelizing a Simple Analysis
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行化一个简单的分析
- en: 'Consider that when you run an analysis program, you’re just telling the computer
    to execute a set of instructions.  Suppose that we have a text file and we want
    to count the number of lines in it. The set of instructions to do this can be
    as simple as this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑当你运行一个分析程序时，你只是告诉计算机执行一组指令。假设我们有一个文本文件，我们想要计算其中的行数。要做到这一点的指令集可能就像这样简单：
- en: Open the file; count the number of lines in it; tell us the number; close the
    file.
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 打开文件；计算其中的行数；告诉我们数字；关闭文件。
- en: Note that “tell us the number” can mean writing it to the console or storing
    it somewhere for use later on—let’s not worry about that right now.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，“告诉我们数字”可以意味着将其写入控制台或将其存储在某个地方以供以后使用——现在我们不用担心这个。
- en: 'Now suppose that we want to know the number of words on each line. The set
    of instructions would be as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设我们想知道每行的单词数。指令集将如下所示：
- en: Open the file; read the first line; count the number of words; tell us the number;
    read the second line; count the number of words; tell us the number; read the
    third line; count the number of words; tell us the number.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 打开文件；读取第一行；计算单词数；告诉我们数字；读取第二行；计算单词数；告诉我们数字；读取第三行；计算单词数；告诉我们数字。
- en: 'And so on until we’ve read all the lines, and then finally we can close the
    file. It’s pretty straightforward, but if our file has a lot of lines, it will
    take a long time, and it will probably not use all the computing power we have
    available. So, to parallelize this program and save time, we just cut up this
    set of instructions into separate subsets, like this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 依此类推，直到我们读完所有行，最后我们可以关闭文件。这很简单，但如果我们的文件有很多行，将会花费很长时间，并且可能不会充分利用我们可用的所有计算能力。因此，为了并行化这个程序并节省时间，我们只需将这组指令分割成单独的子集，如下所示：
- en: Open the file; index the lines.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打开文件；索引行。
- en: Read the first line; count the number of words; tell us the number.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读第一行；计算单词数；告诉我们数字。
- en: Read the second line; count the number of words; tell us the number.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读第二行；计算单词数；告诉我们数字。
- en: Read the third line; count the number of words; tell us the number.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读第三行；计算单词数；告诉我们数字。
- en: '[Repeat for all lines.]'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对所有行重复。]'
- en: Collect final results and close the file.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集最终结果并关闭文件。
- en: Here, the “read the *N*th line” steps can be performed in parallel because they
    are all independent operations.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，“阅读第*N*行”步骤可以并行执行，因为它们都是独立操作。
- en: You’ll notice that we added a step, “index the lines.” That’s a little bit of
    preliminary work that allows us to perform the “read the *N*th line” steps in
    parallel (or in any order we want) because it tells us how many lines there are
    and, importantly, where to find each one within the file. It makes the entire
    process much more efficient. As you will see in the following chapters, tools
    like GATK require index files for the main data files (reference genome, read
    data and variant calls). The reason is to have that indexing step already done
    so that we can have the program look up specific chunks of data by their position
    in the genome.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到我们添加了一个步骤，“索引行”。这是一点点预备工作，让我们能够并行执行“阅读第*N*行”步骤（或以任何我们想要的顺序），因为它告诉我们有多少行，以及重要的是，在文件中如何找到每一行。这使整个过程更加高效。正如你将在接下来的章节中看到的，像GATK这样的工具需要主数据文件（参考基因组、读取数据和变异调用）的索引文件。原因是已经完成了索引步骤，这样我们就可以让程序通过它们在基因组中的位置查找特定数据块。
- en: 'Anyway, that’s the general principle: you transform your linear set of instructions
    into several subsets of instructions. There’s usually one subset that has to be
    run first and one that has to be run last, but all the subsets in the middle can
    be run at the same time (in parallel) or in whatever order you want.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，这是一个通用原则：你将线性的一系列指令转化为几个指令子集。通常有一个必须首先运行的子集和一个必须最后运行的子集，但中间的所有子集可以同时运行（并行）或按照你想要的任何顺序运行。
- en: 'From Cores to Clusters and Clouds: Many Levels of Parallelism'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从核心到集群和云：多层次的并行ism
- en: So how do we go from rice cookers to parallelizing the execution of a genomic
    analysis program? Overall, the action of parallelizing computing operations consists
    of sending subsets of the work we want done to multiple cores for processing.
    We can do that by splitting up the work across the cores of a single multicore
    machine, or we can dispatch work to other machines if we have access to a cluster
    or cloud. In fact, we can combine the two ideas and dispatch work to multicore
    machines, in which the work is further split up among each machine’s cores. Going
    back to the rice-cooking example, it’s as if instead of cooking the rice yourself,
    you hired a catering company to do it for you. The company assigns the work to
    several people, who each have their own cooking station with multiple rice cookers.
    Now, you can feed a lot more people in the same amount of time! And you don’t
    even need to clean the dishes.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何从煮饭器转变为并行化执行基因组分析程序呢？总的来说，并行化计算操作的行为包括将我们想要完成的工作的子集发送到多个核心进行处理。我们可以通过将工作分配到单个多核机器的核心上来实现这一点，或者如果我们可以访问集群或云，则可以将工作分派到其他机器上。事实上，我们可以结合这两种思想，并将工作分派到多核机器，其中工作进一步分配到每台机器的核心中。回到煮饭的例子，这就好像你不是自己煮饭，而是雇了一个餐饮公司来为你做。公司将工作分配给几个人，每个人都有自己的烹饪站，配备多个煮饭器。现在，你可以在同样的时间内喂更多的人！而且你甚至不需要洗碗。
- en: 'Whether we want to distribute the work across multiple cores on a single machine
    or across multiple machines, we’re going to need a system that splits up the work,
    dispatches jobs for execution, monitors them for completion, and then compiles
    the results. Several kinds of systems can do that, falling broadly into two categories:
    internal or external to the analysis program itself. In the first case, the parallelization
    happens “inside” the program that we’re running: we run that program’s command
    line, and the parallelization happens without any additional “wrapping” on our
    part. We call that *multithreading*. In the second case, we need to use a separate
    program to run multiple instances of the program’s command line. An example of
    an external parallelization is writing a script that runs a given tool separately
    on the data from each chromosome in a genome and then combines the result with
    an additional merge step. We call that approach *scatter-gather*. We cover that
    in more detail in the next section when we introduce workflow management systems.
    In [Figure 3-2](#scatter_gather_allows_parallel_executio), you can see how we
    can use multithreading and scatter-gather parallelism in the course of an analysis.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们想要将工作分配到单台机器的多个核心上还是分配到多台机器上，我们都需要一个系统来分割工作，分派任务进行执行，监视任务完成情况，然后编译结果。有几种系统可以做到这一点，大致分为两类：内部或外部于分析程序本身。在第一种情况下，并行化发生在我们正在运行的程序“内部”：我们运行该程序的命令行，而并行化发生在我们的任何额外“包装”之外。我们称之为*多线程*。在第二种情况下，我们需要使用一个单独的程序来运行程序的多个实例的命令行。外部并行化的一个例子是编写一个脚本，分别在基因组中每个染色体的数据上运行给定工具，然后通过额外的合并步骤将结果组合起来。我们称之为*散射-聚集*。当我们介绍工作流管理系统时，我们将在下一节中更详细地介绍这一点。在[图3-2](#scatter_gather_allows_parallel_executio)中，您可以看到我们如何在分析过程中使用多线程和散射-聚集并行性。
- en: '![Scatter-gather allows parallel execution of tasks on different CPU cores
    (on a single machine or multiple machines depending on how it’s implemented).](Images/gitc_0302.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![散射-聚集允许在不同CPU核心上并行执行任务（在单台机器或多台机器上，取决于实现方式）。](Images/gitc_0302.png)'
- en: Figure 3-2\. Scatter-gather allows parallel execution of tasks on different
    CPU cores (on a single machine or multiple machines, depending on how it’s implemented).
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2。散射-聚集允许在不同CPU核心上并行执行任务（在单台机器或多台机器上，取决于实现方式）。
- en: 'Trade-Offs of Parallelism: Speed, Efficiency, and Cost'
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行性的权衡：速度、效率和成本
- en: Parallelism is a great way to speed up processing on large amounts of data,
    but it has overhead costs. Without getting too technical at this point, let’s
    just say that parallelized jobs need to be managed, you need to set aside memory
    for them, regulate file access, collect results, and so on. So it’s important
    to balance the costs against the benefits, and avoid dividing the overall work
    into too many small jobs. Going back to our earlier example, you wouldn’t want
    to use a thousand tiny rice cookers that each boil a single grain of rice. They
    would take far too much space on your countertop, and the time required to distribute
    each grain and then collect it when it’s cooked would more than negate any benefits
    from parallelizing in the first place.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化是加快处理大量数据处理的好方法，但它具有开销成本。在这一点上不要深入技术细节，我们只需说并行化作业需要管理，需要为其分配内存，调节文件访问，收集结果等等。因此，平衡成本与收益是非常重要的，避免将整体工作分解成过多的小作业。回到我们之前的例子，你不会希望使用一千个每次只煮一粒米的小型电饭煲。它们会占用太多台面空间，并且在分发每粒米和在煮熟后收集它们时所需的时间将大大抵消最初并行化带来的任何好处。
- en: More generally, although it’s tempting to think of parallelism as a way to make
    things go faster, it’s important to remember that the impression of speed is entirely
    subjective to the observer. In reality, the computation being run on each piece
    of data is not going any faster. We’re just running more computations at the same
    time, and we’re limited by the parallel capacity of our computing setup (typically
    measured in number of nodes or cores) as well as hardware limitations like I/O
    and network speeds. It’s more realistic to think of parallelism as a way to optimize
    available resources in order to finish tasks *sooner*, rather than making individual
    tasks run *faster*.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 更普遍地说，虽然将并行性视为加快速度的一种方式很诱人，但重要的是要记住速度印象完全是观察者的主观看法。实际上，每个数据片段上运行的计算速度并没有加快。我们只是同时运行更多的计算，并且我们受到计算设置（通常以节点或核心数量衡量）以及I/O和网络速度等硬件限制的限制。更现实的是，将并行性视为优化可用资源以便更早完成任务的一种方式，而不是使单个任务运行更*快*。
- en: This distinction might seem pedantic given that, from the point of view of the
    human at the keyboard, the elapsed time (often called *wall-clock time*; that
    is, “the time shown by the clock on the wall”) is shorter. And isn’t that what
    we all understand as going faster? However, from the point of view of the resources
    we utilize, if we add up the time spent doing computation by the processor across
    all the cores we use, we might find that the overall job takes *more* time to
    complete compared to purely sequential execution because of the overhead costs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管从键盘前的人的角度来看，经过的时间（通常称为*挂钟时间*；即“墙上时钟显示的时间”）似乎更短，这种区分可能显得有些迂腐。而这不正是我们理解为什么速度更快的吗？然而，从我们所利用的资源的角度来看，如果我们把处理器在所有使用的核心上执行计算所花费的时间加起来，我们可能会发现整个任务比纯顺序执行花费的时间*更多*，这是因为开销成本的缘故。
- en: 'That brings us to another important question: what is the monetary cost of
    utilizing those resources? If we’re working with a dedicated machine that is just
    sitting there with multiple cores and nothing else to do, the parallelization
    is still absolutely worth it, even with the overhead. We’ll want to parallelize
    the heck out of everything we do on that machine in order to maximize efficiency.
    However, when we start working in the cloud environment, as we do in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud),
    and we need to start paying for itemized resources as we go, we’ll want to look
    more carefully at the trade-offs between minimizing wall-clock time and the size
    of the bill.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了另一个重要问题：利用这些资源的货币成本是多少？如果我们使用的是一个专用机器，它只是坐在那里有多个核心而没有其他任务可做，那么并行化仍然绝对值得，即使有开销。我们将希望在这台机器上对我们做的每件事情进行并行处理，以最大化效率。然而，当我们开始在云环境中工作，就像我们在[第4章](ch04.xhtml#first_steps_in_the_cloud)中所做的那样，并且我们需要根据使用的资源逐项支付费用时，我们将需要更仔细地权衡最小化挂钟时间和账单大小之间的权衡。
- en: Pipelining for Parallelization and Automation
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于并行化和自动化的流水线技术
- en: Many genomic analyses involve running a lot of routine data-processing operations
    that need to be parallelized for efficiency and automated to reduce human error.
    We do this by describing the workflow in a machine-readable language, which we
    then can feed into a workflow management system for execution. We go over how
    this works in practice in [Chapter 8](ch08.xhtml#automating_analysis_execution_with_work),
    but first let’s set the stage by introducing basic concepts, definitions, and
    key software components. As we go, please keep in mind that this field currently
    has no such thing as a one-size-fits-all solution, and it’s ultimately up to you
    to review your needs and available options before picking a particular option.
    However, we can identify general principles to guide your selection, and we demonstrate
    these principles in action using the open source pipelining solution that is recommended
    by the GATK development team and used in production at the Broad Institute. As
    with most of this book, the goal here is not to prescribe the use of specific
    software, but to show through working examples how all of this fits together in
    practice.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 许多基因组分析涉及大量例行数据处理操作，需要并行化以提高效率并自动化以减少人为错误。我们通过用机器可读语言描述工作流程来实现这一点，然后可以将其馈送到工作流管理系统中进行执行。我们在[第8章](ch08.xhtml#automating_analysis_execution_with_work)详细介绍了这在实践中的运作方式，但首先让我们通过介绍基本概念、定义和关键软件组件来铺垫舞台。在进行时，请记住，这个领域目前没有通用的解决方案，最终取决于您在选择特定选项之前审查您的需求和可用选项。然而，我们可以确定一般原则来指导您的选择，并且我们使用GATK开发团队推荐并在Broad
    Institute的生产中使用的开源管道化解决方案来演示这些原则。就像本书的大部分内容一样，这里的目标不是规定特定软件的使用，而是通过实际工作示例展示所有这些如何结合在一起。
- en: One tricky aspect is that we have dozens of scripting languages and workflow
    management systems to choose from in the bioinformatics world—likely hundreds
    if you look at a wider range of fields. It can be difficult to compare them directly
    because they tend to be developed with a particular type of audience in mind,
    leading to very different modalities of user experience. They are often tuned
    for particular use cases and are sometimes optimized to operate on certain classes
    of infrastructure. We often see one solution that is preferred by one group prove
    to be particularly difficult or frustrating to use for another. These various
    solutions are also generally not interoperable, meaning that you can’t take a
    workflow script written for one workflow management system and run it unmodified
    on the next one over. This lack of standardization is a topic of both humor and
    desperation in just about every field of research known to humankind, as is illustrated
    in [Figure 3-3](#xkcd_comic_on_the_proliferation_of_stan).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 生物信息学世界中一个棘手的方面是我们有数十种脚本语言和工作流管理系统可供选择——如果您考虑更广泛的领域可能会有数百种。直接比较它们可能会很困难，因为它们往往是为特定类型的受众开发的，导致用户体验的模态非常不同。它们通常针对特定的用例进行调整，有时优化以在特定类别的基础设施上运行。我们经常看到一个解决方案被一个群体偏爱，但对另一个群体来说使用起来特别困难或令人沮丧。这些各种解决方案通常也不可互操作，这意味着您不能将为一个工作流管理系统编写的工作流脚本未经修改地在另一个系统上运行。这种缺乏标准化是人类已知的几乎每个研究领域都具有幽默和绝望的主题，正如在[图3-3](#xkcd_comic_on_the_proliferation_of_stan)中所示。
- en: '![XKCD comic on the proliferation of standards.](Images/gitc_0303.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![标准的泛滥](Images/gitc_0303.png)'
- en: 'Figure 3-3\. XKCD comic on the proliferation of standards (source: https://xkcd.com/927).'
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-3\. 标准的泛滥的XKCD漫画（来源：https://xkcd.com/927）。
- en: In recent years, we have seen some high-profile initiatives such as the Global
    Alliance GA4GH emerge with the explicit mission of developing common standards
    and consolidating efforts around a subset of solutions that have interoperability
    as a core value. For example, the GA4GH Cloud Work Stream has converged on a small
    set of workflow languages for its driver projects, including CWL, Nextflow, and
    WDL, which we use in this book. At the same time, given the recognition that no
    single language is likely to satisfy all needs and preferences, several groups
    are working to increase interoperability by building support for multiple workflow
    languages into their workflow management systems. The workflow management system
    we use in this book, Cromwell, supports both WDL and CWL, and it could be extended
    to support additional languages in the future.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，我们看到一些备受关注的倡议，比如全球联盟GA4GH，其明确任务是制定通用标准并团结力量，集中精力在以互操作性为核心价值的一小部分解决方案上。例如，GA4GH云工作组已经统一了其驱动项目的少量工作流语言，包括CWL、Nextflow和WDL，这些语言也被本书采用。同时，鉴于无法单一语言可能满足所有需求和偏好的认识，几个团体正在努力通过将多种工作流语言的支持集成到其工作流管理系统中来增强互操作性。我们在本书中使用的工作流管理系统Cromwell支持WDL和CWL，并且未来还可以扩展支持其他语言。
- en: Workflow Languages
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作流语言
- en: In principle, we could write our workflows in almost any programming language
    we like; but in practice, some are more amenable than others for describing workflows.
    Just like natural languages, programming languages also exhibit a fascinating
    diversity and can be classified in various ways including grammar, mode of execution,
    and the programming paradigms that they support.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，我们可以用几乎任何编程语言编写我们的工作流程；但实际上，某些语言比其他语言更适合描述工作流程。就像自然语言一样，编程语言也展示出多样化，可以通过语法、执行方式以及支持的编程范式等多种方式进行分类。
- en: From a practical standpoint, we begin by making a distinction between all-purpose
    programming languages, which are intended to be usable for a wide range of applications,
    and domain-specific languages (DSLs) that are, as the name indicates, specifically
    designed for a particular domain or activity. The latter are typically preloaded
    with things like specially formulated data structures (i.e., ways to represent
    and manipulate data that “understand” the nature of the underlying information)
    and convenience functions that act as shortcuts; for example, handling domain-specific
    file formats, applying common processing actions, and so on. As a result, a DSL
    can be an attractive option if your needs fit well within the intended scope of
    the language, especially if your computational background is limited, given that
    the DSL typically enables you to get your work done without having to learn a
    lot of programming concepts and syntax.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际角度来看，我们首先要区分通用编程语言和领域特定语言（DSLs）。通用编程语言旨在适用于广泛的应用程序，而DSLs则专门为特定领域或活动而设计。后者通常预装了专门制定的数据结构（即表示和操作数据的方式，能够“理解”底层信息的性质）和方便函数，作为快捷方式；例如，处理特定领域的文件格式，应用常见处理操作等。因此，如果您的需求完全符合语言的预期范围，DSL可能是一个有吸引力的选择，特别是如果您的计算背景有限，因为DSL通常使您能够完成工作而无需学习大量编程概念和语法。
- en: On the other hand, if your needs are more varied or you are used to having the
    more expansive toolbox of a general-purpose language at your disposal, you might
    find yourself uncomfortably constrained by the DSL. In that case, you might prefer
    to use a general-purpose language, especially one enriched with domain-specific
    libraries that provide relevant data structures and convenience functions (e.g.,
    Python with Biopython and related libraries). In fact, using a general-purpose
    language is more likely to enable you to use the same language for writing the
    data-processing tasks themselves and for managing the flow of operations, which
    is how many have traditionally done this kind of work. What we’re seeing now in
    the field, however, is a move toward separation of description and content, which
    manifests as increased adoption of DSLs specifically designed to describe workflows
    as well as of specialized workflow management systems. This evolution is strongly
    associated with the push for interoperability and portability.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果您的需求更加多样化，或者您习惯于拥有通用语言更丰富的工具箱，您可能会觉得领域特定语言限制了您的舒适度。在这种情况下，您可能更喜欢使用通用语言，特别是那些附带领域特定库（例如，Python与Biopython及相关库）。事实上，使用通用语言更有可能使您能够同时用同一种语言编写数据处理任务和管理操作流程，这正是许多人传统上完成此类工作的方式。然而，我们现在在这个领域看到的是描述和内容分离的趋势，这体现为专门设计用于描述工作流的DSL及专门的工作流管理系统的增加采纳。这种演变与推动互操作性和可移植性紧密相关。
- en: Popular Pipelining Languages for Genomics
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基因组学中流行的管道语言
- en: 'When we look at the cross-section of people who find themselves at the intersection
    of bioinformatics and genomics, we see a wide range of backgrounds, computational
    experience, and needs. Some come from a software engineering background and prefer
    languages that are full featured and highly structured, offering great power at
    the cost of accessibility. Some come from systems administration and believe every
    problem can be solved with judicious application of Bash, sed, and awk, the duct
    tape of the Unix-verse. On the “bio” side of the fence, the more computationally
    trained tend to feel most at home with analyst favorites like Python and R, which
    have been gaining ground over old-time classics Perl and MATLAB; some also tend
    to gravitate toward DSLs. Meanwhile wetlab-trained researchers might find themselves
    baffled by all of this, on initial contact at least. (Author’s note and disclaimer:
    Geraldine identifies as one of the initially baffled, having trained as a traditional
    microbiologist and eventually learned the rudiments of Perl and Python in a desperate
    bid to escape the wetlab workbench. Spoiler: it worked!)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们看向生物信息学和基因组学交汇处的人群时，我们看到了各种背景、计算经验和需求。一些人来自软件工程背景，喜欢功能丰富、高度结构化的语言，虽然强大但不易接触。另一些人来自系统管理，相信一切问题都可以通过巧妙运用Bash、sed和awk来解决，这些是Unix世界的胶带。在“生物”这一边，那些接受过计算训练的人更倾向于喜欢Python和R这样的分析师喜爱的语言，这些语言正在取代古老的Perl和MATLAB；有些人也倾向于使用领域特定语言。与此同时，湿实验室训练过的研究人员可能对所有这些都感到困惑，至少在初次接触时是这样。（作者注和免责声明：杰拉尔丁认为自己是最初感到困惑的人之一，曾接受传统微生物学培训，并最终在拼命逃离湿实验室工作台时学会了Perl和Python的基础。剧透：她成功了！）
- en: Based on recent polling, some of the languages that are most popular with workflow
    authors in the genomics space are SnakeMake and Nextflow. Both are noted for their
    high degree of flexibility and ease of use. Likewise, CWL and WDL are picking
    up steam because of their focus on portability and computational reproducibility.
    Of the two, CWL is more frequently preferred by people who have a technical background
    and enjoy its high level of abstraction and expressiveness. In contrast, WDL is
    generally considered to be more accessible to a wide audience.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 根据最近的民意调查，在基因组学领域最受工作流程作者欢迎的一些语言包括SnakeMake和Nextflow。它们都因其高度灵活性和易用性而著名。同样，CWL和WDL因其侧重于可移植性和计算再现性而受到青睐。在这两者中，CWL更常被技术背景的人士青睐，他们喜欢其高抽象度和表现力。相比之下，WDL一般被认为更易于广泛受众接受。
- en: 'At the end of the day, when it comes to picking a workflow language, we look
    at four main criteria: what kind of data structures the language supports (i.e.,
    how we can represent and pass around information), how it enables us to control
    the flow of operations, how accessible it is to read and write for the intended
    audience, and how it affects our ability to collaborate with others. Whatever
    we choose, it’s unlikely that we can satisfy everyone’s requirements. However,
    if we were to boil all this down to just one recommendation, it would be this:
    if you want your workflow scripts to be widely used and understood in your area
    of research, pick a language that is open and accessible enough to newcomers yet
    scales well enough to the ambitions of the more advanced. And, of course, try
    to pick a language that you can run across different workflow management systems
    and computing platforms, because you never know what environment you or your collaborators
    might find yourselves in next.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当选择工作流语言时，我们最终会考虑四个主要标准：语言支持的数据结构类型（即我们如何表示和传递信息），它如何使我们能够控制操作流程，对预期读写者而言它的可访问性，以及它如何影响我们与他人合作的能力。无论我们选择什么，都不太可能满足每个人的要求。然而，如果我们要将所有这些归结为一个建议，那就是：如果您希望您的工作流脚本在您的研究领域广泛使用和理解，请选择一种对新手来说既开放又易于访问，但又能够扩展到更高级别需求的语言。当然，尽量选择一种可以在不同工作流管理系统和计算平台上运行的语言，因为您或您的合作者下一个工作环境可能是什么，这是无法预测的。
- en: Workflow Management Systems
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作流管理系统
- en: Many workflow management systems exist, but in general they follow the same
    basic pattern. First, the workflow engine reads and interprets the instructions
    laid out in the workflow script, translating the instruction calls into executable
    jobs that are associated with a list of inputs (including data and parameters).
    It then sends out each job with its list of inputs to another program, generally
    called a *job scheduler*, that is responsible for orchestrating the actual execution
    of the work on the designated computing environment. Finally, it retrieves any
    outputs produced when the job is done. Most workflow management systems have some
    built-in logic for controlling the flow of execution; that is, the order in which
    they dispatch jobs for execution and for determining how they deal with errors
    and communicate with the compute infrastructure.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 许多工作流管理系统存在，但通常它们都遵循相同的基本模式。首先，工作流引擎读取并解释工作流脚本中的指令，将这些指令调用转换为可执行的作业，并与一系列输入（包括数据和参数）关联起来。然后，它将每个带有其输入列表的作业发送到另一个程序，通常称为*作业调度器*，负责在指定的计算环境上实际执行工作。最后，在作业完成时检索任何生成的输出。大多数工作流管理系统都具有一些内置逻辑，用于控制执行流程，即它们调度执行作业的顺序，并确定如何处理错误以及与计算基础设施进行通信的方式。
- en: Another important advance for increasing portability and interoperability of
    analyses is the adoption of container technology, which we cover in detail in
    the last section of this chapter. For now, assume that a container is a mechanism
    that allows you to encapsulate all software requirements for a particular task,
    from the deepest levels of the operating system (OS) all the way to library imports,
    environment variables, and accessory configuration files.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 增加分析的可移植性和互操作性的另一个重要进展是采用容器技术，在本章的最后一节中详细介绍。暂时假设容器是一种机制，允许您封装特定任务的所有软件需求，从操作系统（OS）的最深层到库导入、环境变量和附属配置文件。
- en: Virtualization and the Cloud
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚拟化和云计算
- en: Up to this point, we have been assuming that whether you’re working with a single
    computer or a cluster, you’re dealing with “real” physical machines that are each
    set up with a given OS and software stack, as represented in [Figure 3-4](#representation_of_aright_parenthesis_th)
    A. Unfortunately, interacting with that kind of system has several disadvantages,
    especially in a shared environment like an institutional cluster. As an end user,
    you typically don’t have a choice regarding the OS, environment, and installed
    software packages. If you need to use something that isn’t available, you can
    ask an administrator to install it, but they might decline your request or the
    package you want might not be compatible with existing software. For the system
    administrators on the other side of the helpdesk, it can be a headache to keep
    track of what users want, manage versions, and deal with compatibility issues.
    Such systems take effort to update and scale.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们假设不论你是在使用单台计算机还是集群，你都在处理“真实”的物理机器，每台都设置有特定的操作系统和软件堆栈，如图[3-4](#representation_of_aright_parenthesis_th)
    A 所示。不幸的是，在像机构集群这样的共享环境中，与这种类型的系统交互有几个缺点。作为最终用户，你通常无法选择操作系统、环境和安装的软件包。如果你需要使用一些不可用的内容，你可以要求管理员安装，但他们可能会拒绝你的请求，或者你想要的包可能与现有软件不兼容。对于帮助台背后的系统管理员来说，跟踪用户需求、管理版本和处理兼容性问题可能是一件令人头疼的事情。这些系统需要花费精力来更新和扩展。
- en: That is why most modern systems use various degrees of *virtualization*, which
    is basically a clever bit of abstraction that makes it possible to run multiple
    different software configurations on top of the same hardware through virtual
    machines (VMs) and containers as represented in [Figure 3-4](#representation_of_aright_parenthesis_th)
    B and C respectively. These constructs can be utilized in many contexts, including
    optionally on local systems (you can even use containers on your laptop!), but
    they are absolutely essential for cloud infrastructure.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，大多数现代系统使用不同程度的*虚拟化*，这基本上是一种巧妙的抽象技术，通过虚拟机（VMs）和容器，在同一硬件上运行多种不同的软件配置，如图[3-4](#representation_of_aright_parenthesis_th)
    B 和 C 所示。这些构造可以在许多情境下使用，包括（可选地）在本地系统上（你甚至可以在笔记本电脑上使用容器！），但它们对于云基础设施是绝对必要的。
- en: '![Representation of A) The software stack installed on a physical machine;
    B) a server providing clients with access to individual VMs; C) VMs and containers
    side by side comparison.](Images/gitc_0304.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![A) 安装在物理机器上的软件堆栈；B) 提供客户端访问单独VM的服务器；C) VM和容器并排比较。](Images/gitc_0304.png)'
- en: Figure 3-4\. A) The software stack installed on a physical machine; B) a system
    hosting multiple VMs; C) a system hosting multiple containers.
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-4\. A) 安装在物理机器上的软件堆栈；B) 托管多个VM的系统；C) 托管多个容器的系统。
- en: VMs and Containers
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VM 和容器
- en: A VM is an infrastructure-level construct that includes its own OS. The VM sits
    on top of a virtualization layer that runs on the actual OS of the underlying
    physical machine(s). In the simplest case, VMs can be run on a single physical
    machine, with the effect of turning that physical machine into multiple servers
    that share the underlying resources. However, the most robust systems utilize
    multiple physical machines to support the layer of VMs, with a complex layer between
    them that manages the allocation of physical resources. The good news is that
    for end users, this should not make any difference—all you need to know is that
    you can interact with a particular VM in isolation without worrying about what
    it’s sitting on.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: VM 是一个基础架构级别的构造，包括自己的操作系统。VM 位于运行在底层物理机实际操作系统上的虚拟化层之上。在最简单的情况下，VM 可以在单台物理机上运行，其效果是将该物理机转换为共享底层资源的多台服务器。然而，最强大的系统利用多台物理机支持VM层，这些物理机之间有一个复杂的层，负责管理物理资源的分配。好消息是，对于最终用户来说，这并不会有任何区别——你只需知道你可以独立地与特定的VM进行交互，而不必担心它所依赖的环境。
- en: A container is similar in principle to a VM, but it is an application-level
    construct that is much lighter and more mobile, meaning that it can be deployed
    easily to different sites, whereas VMs are typically tied to a particular location’s
    infrastructure. Containers are intended to bundle all the software required to
    run a particular program or set of programs. This makes it a lot easier to reproduce
    the same analysis on any infrastructure that supports running the container, from
    your laptop to a cloud platform, without having to go through the pain of identifying
    and installing all the software dependencies involved. You can even have multiple
    containers running on the same machine, so you can easily switch between different
    environments if you need to run programs that have incompatible system requirements.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 容器在原理上类似于虚拟机，但它是一个应用程序级别的构造，要轻得多且更具移动性，这意味着可以轻松地部署到不同的站点，而虚拟机通常与特定位置的基础设施绑定。容器旨在捆绑运行特定程序或一组程序所需的所有软件。这使得可以在支持运行容器的任何基础设施上轻松重现相同的分析，从你的笔记本电脑到云平台，而无需去辛苦地识别和安装所有涉及的软件依赖关系。甚至可以在同一台机器上运行多个容器，因此如果需要运行具有不兼容系统要求的程序，可以轻松地在不同环境之间切换。
- en: 'If you’re thinking, “These both sound great; which one should I use?” here’s
    some good news: you can use both in combination, as illustrated in [Figure 3-5](#representation_of_a_system_with_three_v).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在想，“这两者听起来都不错；我应该选择哪一个？” 这里有个好消息：你可以将两者结合使用，如 [图 3-5](#representation_of_a_system_with_three_v)
    所示。
- en: '![Representation of a system with three VMs, of which two are running containers.](Images/gitc_0305.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![一个系统的表示，其中有三个虚拟机，其中两个正在运行容器。](Images/gitc_0305.png)'
- en: 'Figure 3-5\. A system with three VMs: the one on the left is running two containers,
    serving App #1 and App #2; the middle is running a single container, serving App
    #3; the right is serving App #4 directly (no container).'
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 3-5\. 一个有三个虚拟机的系统：左侧的虚拟机运行两个容器，为应用程序 #1 和应用程序 #2 服务；中间的虚拟机运行一个容器，为应用程序 #3
    服务；右侧直接为应用程序 #4 提供服务（没有容器）。'
- en: There are several registries for sharing and obtaining containers, including
    [Docker Hub](https://hub.docker.com), [Quay.io](https://quay.io), and [GCR](https://cloud.google.com/container-registry),
    Google’s general-purpose container registry in GCP. In the registry, the container
    is packaged as an *image*. Note that this has nothing to do with pictures; here
    the word *image* is used in the same software-specific way that refers to a special
    type of file. You know how sometimes when you need to install new software on
    your computer, the download file is called a *disk image*? That’s because the
    file you download is in a format that your OS is going to treat as if it were
    a physical disk on your machine. This is basically the same thing. To use a container,
    you first tell the Docker program to download, or *pull*, a container image file
    from a registry—for example, Docker Hub (more on Docker shortly)—and then you
    tell it to initialize the container, which is conceptually equivalent to booting
    up a VM. And after the container is running, you can run any software within it
    that is installed on its system. You can also install additional packages or perform
    additional configurations as needed. [Figure 3-6](#the_relationship_between_containercomma)
    illustrates the relationship between container, image, and registry.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个注册表用于分享和获取容器，包括 [Docker Hub](https://hub.docker.com)、[Quay.io](https://quay.io)
    和 [GCR](https://cloud.google.com/container-registry)，Google 在 GCP 中的通用容器注册表。在注册表中，容器被打包为一个
    *镜像*。请注意，这与图片无关；这里的 *镜像* 是以软件特定方式使用的术语，指的是一种特殊类型的文件。你知道有时候在需要在计算机上安装新软件时，下载的文件称为
    *磁盘镜像* 吗？那是因为你下载的文件是以你的操作系统会把它当作物理磁盘的格式来对待。这基本上就是同样的概念。要使用一个容器，首先要告诉 Docker 程序从注册表（比如
    Docker Hub，稍后会详细介绍 Docker）下载或 *拉取* 一个容器镜像文件，然后告诉它初始化容器，这在概念上等同于启动一个虚拟机。在容器运行之后，你可以在其系统上运行任何安装的软件。你还可以根据需要安装额外的软件包或执行额外的配置。[图 3-6](#the_relationship_between_containercomma)
    说明了容器、镜像和注册表之间的关系。
- en: '![The relationship between container, image, and registry.](Images/gitc_0306.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![容器、镜像和注册表之间的关系。](Images/gitc_0306.png)'
- en: Figure 3-6\. The relationship between registry, image, and container.
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-6\. 注册表、镜像和容器之间的关系。
- en: The most widely used brand of container systems is Docker, produced by the company
    of the same name. As a result of Docker’s ubiquitousness, people will often say
    “a docker” instead of “a container,” much like when “xerox” became a replacement
    for “copy machines” (in the US at least) because of the dominance of the Xerox
    company. However, `docker` with a lowercase *d* is also the command-line program
    that you install on your machine to run Docker containers. Similarly, although
    the action of bundling a software tool, package, or analysis into a Docker container
    should rightly be called “containerizing,” people often call it “dockerizing,”
    as in, “I dockerized my Python script.” Dockerizing a tool involves writing a
    script called a Dockerfile that describes all installations and environment configurations
    necessary to *build* the Docker image, as demonstrated in [Figure 3-7](#the_process_for_creating_a_docker_conta).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 容器系统中使用最广泛的品牌是由同名公司制造的**Docker**。由于Docker的普及性，人们通常会说“一个docker”而不是“一个container”，就像在美国，人们因为Xerox公司的主导地位而用“xerox”替代“复印机”一样。然而，小写的`docker`也是你在机器上安装以运行Docker容器的命令行程序。同样地，尽管将软件工具、包或分析打包成Docker容器的操作应该被称为“containerizing”，但人们通常称之为“dockerizing”，比如，“我将我的Python脚本dockerized了”。Dockerizing一个工具涉及编写一个名为Dockerfile的脚本，描述构建Docker镜像所需的所有安装和环境配置，如[图 3-7](#the_process_for_creating_a_docker_conta)所示。
- en: '![The process for creating a Docker container.](Images/gitc_0307.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![创建Docker容器的过程。](Images/gitc_0307.png)'
- en: Figure 3-7\. The process for creating a Docker image.
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-7\. 创建Docker镜像的过程。
- en: As noted earlier, it is possible to use containers in various contexts, including
    local machines, HPC, and the cloud. One important restriction is that Docker specifically
    is usually not allowed in shared environments like most institutions’ HPCs, because
    it requires a very high level of access permissions called *root*. In that kind
    of setting, system administrators will prefer *Singularity*, an alternative system
    that achieves the same results. Fortunately, it is possible to run Docker containers
    within a Singularity system.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，可以在各种环境中使用容器，包括本地机器、高性能计算（HPC）和云中。一个重要的限制是，像大多数机构的HPC这样的共享环境通常不允许使用特定的Docker，因为它需要称为*root*的非常高级的访问权限。在这种情况下，系统管理员会更喜欢*Singularity*，这是一个可以达到相同效果的替代系统。幸运的是，在Singularity系统中可以运行Docker容器。
- en: Introducing the Cloud
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入云计算
- en: 'Finally, we get to the topic many of you have been waiting for: what is this
    cloud thing anyway? The surprisingly easy answer is that the cloud is a bunch
    of computers that you can rent. In practice, that means that as a user, you can
    easily launch a VM and select how much RAM, storage, and what CPUs you want. You
    want a VM with 1 TB of RAM and 32 CPUs for genome assembly? No problem! Most of
    the VMs in the cloud are running some form of Linux as the OS, which you get to
    choose when you launch it, and are typically accessed using a remote shell via
    Secure Shell (SSH).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们来到了许多人一直在等待的话题：云计算究竟是什么？出人意料的简单答案是，云是一堆你可以租用的计算机。在实践中，这意味着作为用户，你可以轻松启动一个虚拟机，并选择需要多少RAM、存储空间以及什么样的CPU。你需要一台有1
    TB RAM和32个CPU用于基因组装的虚拟机？没问题！大多数云中的虚拟机都在运行某种形式的Linux作为操作系统，你可以在启动时选择，并通常使用安全外壳（SSH）通过远程Shell访问。
- en: Although some VMs include free storage, this is typically ephemeral and will
    go away when you stop and start your VM. Instead, use block storage (a persistent
    device) to store data, scripts, and so on on your VM. You can think of these very
    much like a USB thumb drive that you can have “plugged” into your VM whenever
    you like. Even when you terminate your VM, files on block storage will be OK and
    safely saved. Files can also be stored in object store—think of this more like
    Google Drive or Dropbox, where files can be read and written by multiple VMs at
    the same time, but you don’t typically use these as a normal filesystem. Instead,
    they are more akin to an SSH File Transfer Protocol (SFTP) server for sharing
    files between VMs, where you transfer files through a utility to and from the
    object storage system. The final basic component of a cloud is networking. With
    a virtual networking service, you can control who has access to your VMs, locking
    it down tightly to ensure that only you (or others you trust) have access.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管一些虚拟机包含免费存储空间，但这通常是暂时的，当你停止和启动虚拟机时会消失。相反，请使用块存储（一种持久设备）来存储数据、脚本等内容在你的虚拟机上。你可以把它们想象成可以随时“插入”虚拟机的USB闪存驱动器。即使终止虚拟机，块存储上的文件也会安全保存。文件也可以存储在对象存储中——把它想象成类似Google
    Drive或Dropbox，文件可以被多个虚拟机同时读取和写入，但通常你不会将其用作普通文件系统。相反，它们更像是用于在虚拟机之间共享文件的SSH文件传输协议（SFTP）服务器，你可以通过实用程序与对象存储系统之间传输文件。云的最后一个基本组成部分是网络。通过虚拟网络服务，你可以控制谁能访问你的虚拟机，严密锁定以确保只有你（或你信任的其他人）能访问。
- en: Clouds are not fluffy
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 云并非松软
- en: When you think about clouds, they are fluffy, distant, and elusive, not at all
    concrete, real things that you can touch, feel, and capture. Unlike their namesake,
    the cloud infrastructure that most of us use directly (or indirectly) today ultimately
    is composed of real, physical computers racked up and blinking away in huge datacenters.
    What makes it different, though, from previous models for compute (and rings true
    to their name) is its ephemeral nature. Just like clouds coming and going—popping
    up, dumping their rain, and then blowing away—cloud computing is transient for
    the end user. The cloud allows you as a researcher, developer, or analyst to request
    computational infrastructure when you need it, to use it for computing as long
    as you need it, and then you can release all the resources when you’re done.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想到云时，它们是松软、遥远和难以捉摸的，根本不是可以触摸、感受和捕捉的真实事物。与其名字相反，如今大多数人直接（或间接）使用的云基础设施最终由真实的物理计算机组成，这些计算机装在巨大的数据中心中并不停地闪烁。然而，它与以往的计算模型不同之处在于它的短暂性。就像云朵时而出现、倾盆大雨后消散一样，云计算对于最终用户而言也是短暂的。云允许你作为研究人员、开发人员或分析人员在需要时请求计算基础设施，使用它进行计算，然后在完成后释放所有资源。
- en: This approach is great because it saves time and money insomuch as you can spin
    up a lot of resources at once, get your work done, and spin these back down, saving
    on the costs or running hardware continuously. You don’t need to think too much
    about where the servers are racked, how they are configured, the health of the
    hardware, power consumption, or myriad other infrastructure concerns. These are
    all *abstracted away* from you and are taken care of without you having to think
    about it too much. What you focus on, instead, is the computational work that
    you need to perform, the resources you need to do it, and how to most effectively
    use these resources both from a time and money perspective.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法很棒，因为它节省了时间和金钱，你可以一次性启动大量资源，完成工作后再将其关闭，节省运行硬件的成本。你无需过多考虑服务器的机架位置、配置方式、硬件健康状况、功耗或其他基础设施问题。所有这些都已经为你*抽象化*并在你不需要过多考虑的情况下处理好了。你所专注的是需要执行的计算工作、需要使用的资源以及如何从时间和金钱的角度最有效地使用这些资源。
- en: Evolution of cloud infrastructure and services
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 云基础设施和服务的演进
- en: Amazon launched the first widely successful commercial public cloud service
    in 2006, but the basic idea has been around for a long time. Mainframes in the
    1960s were often rented for use, which made a ton of sense, given the massive
    costs of buying and operating them. Regardless of the invention of the personal
    computer, the idea of renting computing infrastructure has cropped up again over
    and over in the intervening decades. In academic groups and industry, the concept
    of shared grid computing in the 1990s and 2000s was the more modern equivalent
    of rented mainframe time. Groups banded together to build cheap but powerful Linux-based
    HPC clusters that were often centrally managed and allocated out to multiple groups
    based on some sort of financial split.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊在2006年推出了第一个广泛成功的商业公共云服务，但这个基本理念已经存在很长时间了。上世纪60年代的大型计算机通常是租用使用的，考虑到购买和运行这些设备的巨大成本，这是非常合理的。尽管个人计算机的发明，租用计算基础设施的概念在随后的几十年里一次又一次地出现。在学术界和工业界，上世纪90年代和2000年代共享网格计算的概念是租用主机时间的现代等价物。团体联合建立了廉价但功能强大的基于Linux的HPC集群，通常由中心管理并根据某种财务分配方法分配给多个团体使用。
- en: 'Today’s public clouds are different, though, in the level of abstraction. Hence,
    the adoption of the fluffy, amorphous name to reflect the fact that an understanding
    of the underlying details is not required in order to run large-scale analysis
    on clouds. When working with a given cloud, you might know the general region
    of the world that hosts your infrastructure (e.g., North Virginia for AWS `us-east-1`),
    but many of the details are hidden from you: how many people are using the underlying
    hardware of your VM, where the datacenter is really located, how the network is
    set up, and so on. What you do know are key details that affect service cost and
    job execution time, like how many CPUs are available, how much RAM the VM has,
    the uptime guarantees of the file storage system, and the regulations the system
    conforms to.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当今的公共云在抽象级别上有所不同。因此，采用了“蓬松、无定形”的名称来反映这样一个事实：在云上运行大规模分析时，并不需要理解底层细节。在使用特定云时，您可能知道托管基础设施的大致地理位置（例如，AWS的北弗吉尼亚区域`us-east-1`），但很多细节对您来说是隐藏的：您的虚拟机底层硬件有多少人在使用，数据中心真正的位置在哪里，网络如何设置等等。您了解的是影响服务成本和作业执行时间的关键细节，例如可用的CPU数量，虚拟机的RAM容量，文件存储系统的正常运行时间保证以及系统遵守的法规等。
- en: 'There are now many public cloud providers—clouds available to anyone who can
    pay for the service. The most dominant currently in the Western hemisphere are
    AWS, Microsoft Azure, and GCP. Each provides a similar mix of services that range
    from simple VMs rentable by the hour (or minute), file storage services, and networking
    to more specialized services such as Google’s Cloud TPU service, which allows
    you to perform accelerated machine learning operations. The important feature,
    though, is that these resources are provided as services: you use what you need
    per hour, minute, second, or API call, and are charged accordingly.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有许多公共云提供商——任何能支付服务费的人都可以使用的云服务。目前在西半球最主导的是AWS、微软Azure和GCP。每家公司提供的服务组合类似，从可按小时（或分钟）租用的简单VM，文件存储服务和网络服务到更专业的服务，例如谷歌的Cloud
    TPU服务，允许您执行加速的机器学习操作。然而，重要的特征是这些资源是作为服务提供的：您按需使用，按小时、分钟、秒或API调用计费。
- en: Pros and cons of the cloud
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 云的利弊
- en: One of the major advantages that many people point to when discussing the cloud
    is cost. When building a datacenter, the fixed costs are enormous. You must hire
    people to rack and maintain physical servers, monitor the network for intrusion,
    deal with power fluctuations, backups, air conditioning, and so on. Honestly,
    it is a lot of work! For a datacenter that supports hundreds of users, the costs
    associated with maintaining the infrastructure can be worth it. But many researchers,
    developers, analysts, and others are realizing that they don’t need to have hundreds
    of computers always available and running, just waiting for a task. Instead, it
    makes a lot more sense to use a cloud environment in which you can do local work
    on your laptop, without extensive resources, and then, when your analysis is ready,
    you can scale up to hundreds or thousands of machines. Commercial public clouds
    allow you to easily *burst* your capacity and do a huge analysis when you need
    to, as opposed to waiting weeks, months, or even years for a dedicated local cluster
    to finish your tasks. Likewise, you don’t need to pay for the maintenance of local
    infrastructure for all the time you spend developing your algorithms and perfecting
    your analysis locally.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当讨论云时，许多人指出的主要优势之一是成本。建设数据中心的固定成本是巨大的。您必须雇用人员来机架和维护物理服务器，监视入侵网络，处理电力波动，备份，空调等等。老实说，这是一项繁重的工作！对于支持数百用户的数据中心，维护基础设施所需的成本可能是值得的。但是许多研究人员、开发人员、分析师和其他人意识到，他们不必总是拥有数百台计算机随时待命，只等待任务。相反，使用云环境更有意义，您可以在笔记本电脑上进行本地工作，无需大量资源，然后，在您的分析准备好时，您可以扩展到数百甚至数千台机器。商业公共云允许您在需要时轻松扩展您的容量，并进行大规模分析，而不是等待几周、几个月甚至几年，以等待专用本地集群完成任务。同样，您不必为开发算法和在本地完善分析所花费的所有时间支付本地基础设施的维护费用。
- en: Finally, as a public cloud user, you have full control of your environment.
    Need a specific version of Python? Do you have a funky library that compiles only
    if very specific tool chains are installed? No problem! The cloud lets you have
    full control over your VMs, something that a shared, local infrastructure would
    never allow. Even with this control, when they are set up following cloud vendor
    best practices, public cloud solutions are invariably more secure than on-premises
    infrastructure because of the vast amount of resources dedicated to security services
    in these environments and the isolation between users afforded by virtualization.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，作为公共云用户，您可以完全控制您的环境。需要特定版本的Python吗？您有一个只有在安装了非常特定的工具链时才能编译的奇特库吗？没问题！云让您完全控制您的虚拟机（VMs），这是共享的本地基础设施所不能允许的。即使有这种控制权，如果按照云供应商的最佳实践进行设置，公共云解决方案由于在这些环境中专门用于安全服务的大量资源以及虚拟化带来的用户隔离，通常比本地基础设施更安全。
- en: Although the public cloud platforms are amazing, powerful, flexible and, in
    many cases, can be used effectively to save a ton of money in the long run, there
    are some disadvantages to look out for. If you are looking to always process a
    fixed number of genomes produced by your sequencing group per month, the public
    cloud might be less attractive and it would make more sense to build a small local
    compute environment for this very predictable workload of data produced locally.
    This is assuming, of course, that you have IT professionals who can act as administrators.
    Another consideration is expertise. Using the cloud demands a certain level of
    expertise, and an unsuspecting novice user might accidentally use VMs with weak
    passwords, set up data storage buckets with weak security, share credentials in
    an insecure way, or just be totally lost in the process of managing a fleet of
    Linux VMs. Even these potential downfalls, though, are generally outweighed by
    the benefits of working flexibly on commercial cloud environments for many people.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管公共云平台令人惊叹、强大、灵活，并且在许多情况下可以有效地节省大量费用，但也有一些需要注意的缺点。如果您希望每月始终处理由您测序组生成的固定数量的基因组，那么公共云可能就不那么吸引人了，而构建一个小型的本地计算环境对于这种非常可预测的本地数据工作负载更为合理。当然，这是在假设您有能够担任管理员角色的IT专业人员的情况下。另一个考虑因素是专业知识。使用云需求一定水平的专业知识，一个不经意的新手用户可能会意外地使用带有弱密码的虚拟机，设置具有弱安全性的数据存储桶，以不安全的方式共享凭据，或者在管理Linux虚拟机群时完全迷失。尽管如此，对于许多人来说，这些潜在的缺点通常被在商业云环境中灵活工作的好处所抵消。
- en: Categories of Research Use Cases for Cloud Services
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云服务研究用例类别
- en: The basic components of the cloud described in the previous section are really
    just the tip of the iceberg. Many more services are available on the main commercial
    cloud platforms. In fact, there are far too many services, some universal and
    some unique to a particular cloud, than we can describe here. But let’s take a
    look at how researchers might use the services or the cloud most commonly. [Table 3-1](#an_overview_of_the_types_of_usage_of_cl)
    provides an overall summary.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节中描述的云的基本组件实际上只是冰山一角。主要商业云平台上提供了更多服务。事实上，服务种类繁多，有些是通用的，有些是特定于特定云的，我们无法在此详细描述。但是，让我们看看研究人员如何最常见地使用云服务。[表3-1](#an_overview_of_the_types_of_usage_of_cl)提供了总体概述。
- en: Table 3-1\. An overview of the types of usage of cloud infrastructure
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-1\. 云基础设施使用类型概览
- en: '| Usage type | Cloud environment | Description | Positives | Negatives |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 使用类型 | 云环境 | 描述 | 优点 | 缺点 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Lightweight development | Google Cloud Shell | Using a simple-to-launch free
    VM for editing code and scripts |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 轻量级开发 | Google Cloud Shell | 使用简单启动的免费虚拟机编辑代码和脚本 |'
- en: Free
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 免费
- en: Extremely easy to launch and log in to
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动和登录非常容易
- en: '|'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Extremely limited VM
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常有限的虚拟机
- en: '|'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Intermediate analysis and development | Single VM | Launching a single VM,
    logging in, performing development and analysis work |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 中级分析和开发 | 单个虚拟机 | 启动单个虚拟机，登录，执行开发和分析工作 |'
- en: Can control the resources on the VM launched
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以控制启动的虚拟机上的资源
- en: VMs can be powerful enough to perform realistic analysis
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虚拟机可能足够强大，能够进行逼真的分析
- en: '|'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Launching a VM requires more configuration
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动虚拟机需要更多的配置
- en: Larger VMs have increased costs
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更大的虚拟机会增加成本
- en: '|'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Batch analysis | Multiple VMs via batch system | Using a system like AWS
    Batch or Google Cloud Pipelines API to launch many VMs and analyze data in parallel
    |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 批量分析 | 通过批处理系统使用多个虚拟机 | 使用像AWS Batch或Google Cloud Pipelines API这样的系统来并行启动多个虚拟机并分析数据
    |'
- en: Allows for parallel, scaled-up analysis
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许并行扩展分析
- en: Workflow management systems like Cromwell support these with little effort
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似Cromwell的工作流管理系统支持这些操作，几乎不费吹灰之力
- en: '|'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Increased costs and complexity
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本和复杂性增加
- en: '|'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Framework analysis | Multiple VMs via a framework | Using Spark, Hadoop,
    or other framework for data analysis |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 框架分析 | 通过框架使用多个虚拟机 | 使用Spark、Hadoop或其他框架进行数据分析 |'
- en: These frameworks allow for specialty analysis
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些框架允许进行专业分析
- en: '|'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Increased costs and complexity
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本和复杂性增加
- en: '|'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Lightweight development: Google Cloud Shell'
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 轻量级开发：Google Cloud Shell
- en: The cloud is a fantastic place for software development. Even though many researchers
    will want to use their own laptops or workstation for development, there can be
    some really compelling reasons for using the cloud as a primary development environment,
    especially for testing. On GCP, for example, you can use the Google Cloud Shell
    from the Google Cloud Console for light development and testing. This is a free
    (yes, *free*!) VM with one virtual CPU core and 5 GB of storage that you can use
    just by clicking the terminal icon in the web console. This is a fantastic environment
    for some light coding and testing; just remember to copy code off of your free
    instance (using Git, for example) because there are quotas for total runtime per
    week, and, if you don’t use the service for a while, your 5 GB volume might get
    cleaned out. Still, this is a great option for quickly getting started with the
    cloud and performing lightweight tasks. You just need a web browser, and the GCP
    tools are all preinstalled and configured for you. Many other tools that you might
    want to work with are already installed as well, including Git and Docker, along
    with languages like Java and Python. You’ll have a chance to try it out early
    on in the next chapter.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 云是软件开发的绝佳场所。即使许多研究人员希望使用自己的笔记本电脑或工作站进行开发，使用云作为主要开发环境，尤其是用于测试，有时也有非常引人注目的理由。例如，在GCP上，您可以从Google
    Cloud控制台使用Google Cloud Shell进行轻量级开发和测试，这是一个免费（是的，*免费*！）的虚拟机，具有一个虚拟CPU核心和5 GB存储空间，只需点击Web控制台中的终端图标即可使用。这是一个非常适合进行轻量级编码和测试的环境；只需记住从您的免费实例复制代码（例如使用Git），因为每周的总运行时间有限制，如果一段时间不使用该服务，您的5
    GB存储空间可能会被清空。但是，这是一个快速入门云计算并执行轻量级任务的绝佳选择。您只需要一个Web浏览器，GCP工具已经预安装和配置好了。许多其他您可能希望使用的工具也已经安装，包括Git和Docker，以及Java和Python等语言。在下一章中您将有机会早期尝试它。
- en: 'Intermediate development and analysis: single VM'
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中级开发和分析：单个 VM
- en: 'Although the Google Cloud Shell is great for many purposes, easy to use, and
    free, sometimes you might need a bit more power, especially if you want to test
    your code or analysis at the next scale up, so you spin up your own dedicated
    VM. This is perhaps the most commonly used option because of the mix of flexibility
    and simplicity it offers: you can customize your VM, ensuring you have enough
    CPU cores, RAM, and local storage to accomplish your goal. Unlike the Google Cloud
    Shell, you must pay for each hour or minute you run this VM; however, you have
    full control over the nature of the VM. You might use this for software or algorithm
    development, testing your analysis approach, or spinning up a small fleet of these
    VMs to perform analysis on multiple VMs simultaneously. Keep in mind, however,
    that if you are manually launching these VMs, fewer tools will be preinstalled
    on them and ready to go for you. That makes using utilities such as Git and Docker
    very helpful for moving your analysis tasks from VM to VM. You’ll have a chance
    to use this extensively in [Chapter 4](ch04.xhtml#first_steps_in_the_cloud) through
    [Chapter 7](ch07.xhtml#gatk_best_practices_for_somatic_variant).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Google Cloud Shell 在许多用途上表现出色，易于使用且免费，但有时您可能需要更强大的功能，特别是如果您想要在下一个规模上测试您的代码或分析，因此您会启动自己专用的
    VM。这可能是最常用的选项之一，因为它提供了灵活性和简易性的结合：您可以定制您的 VM，确保有足够的 CPU 核心、RAM 和本地存储来完成您的目标。与 Google
    Cloud Shell 不同，您必须支付您运行此 VM 的每小时或每分钟费用；但是，您可以完全控制 VM 的性质。您可以将其用于软件或算法开发，测试分析方法，或者同时启动一小组这些
    VM 来在多个 VM 上执行分析。但请记住，如果您手动启动这些 VM，它们上面预安装的工具较少，这些工具对您来说是准备好的。这使得像 Git 和 Docker
    这样的实用程序对于将分析任务从一个 VM 移动到另一个 VM 非常有帮助。在[第四章](ch04.xhtml#first_steps_in_the_cloud)到[第七章](ch07.xhtml#gatk_best_practices_for_somatic_variant)中，您将有机会广泛使用这些功能。
- en: 'Batch analysis: multiple VMs via batch services'
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 批量分析：通过批处理服务多个 VM
- en: This approach is really the sweet spot for most users who are aware of it. Although
    you might use your laptop or Google Cloud Shell for software and script development,
    and one or more VMs for testing them on appropriately sized hardware, you ultimately
    don’t want to manually manage VMs if your goal is to scale up your analysis. Imaging
    running 10,000 genome alignments at the same time; you need systems that can batch
    up the work, provision VMs automatically for you, and turn the VMs off when your
    work is done. Batch systems are designed just for this task; Google Cloud, for
    example, offers the Google Cloud Pipelines API, which you can use to submit a
    large batch of multiple jobs simultaneously. The service will take care of spinning
    up numerous VMs to perform your analysis and then automatically clean them up
    after collecting the output files. This is extremely convenient if you need to
    perform noninteractive analysis on a ton of samples. You’ll see in [Chapter 8](ch08.xhtml#automating_analysis_execution_with_work)
    through [Chapter 11](ch11.xhtml#running_many_workflows_conveniently_in) that workflow
    engines like Cromwell are designed to take advantage of these batch services,
    which take care of all the details of launching batch jobs. That makes it much
    easier for you to focus on the details of the analysis you’re performing rather
    than on the infrastructure involved.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数了解它的用户来说，这种方法确实是最佳选择。虽然您可能会使用您的笔记本电脑或 Google Cloud Shell 进行软件和脚本开发，并在一个或多个
    VM 上进行适当规模的硬件测试，但如果您的目标是扩展您的分析，则最终不希望手动管理 VM。想象一下同时运行 10,000 个基因组对齐任务；您需要能够批处理工作、自动为您提供
    VM，并在工作完成后关闭 VM。批处理系统专为此任务设计；例如，Google Cloud 提供了 Google Cloud Pipelines API，您可以使用它同时提交大量作业。该服务将负责启动多个
    VM 来执行您的分析，然后在收集输出文件后自动清理它们。如果您需要对大量样本进行非交互式分析，这将非常方便。在[第八章](ch08.xhtml#automating_analysis_execution_with_work)到[第十一章](ch11.xhtml#running_many_workflows_conveniently_in)中，您将看到像
    Cromwell 这样的工作流引擎是如何利用这些批处理服务的，它们负责处理启动批处理作业的所有细节。这使得您更容易专注于正在执行的分析细节，而不是所涉及的基础设施。
- en: 'Framework analysis: multiple VMs via framework services'
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 框架分析：通过框架服务多个 VM
- en: The final approach that many researchers will use involves interactive, iterative
    analysis. In genomics, you can use a batch system to perform large-scale alignment
    and variant calling but, after you have VCF files for your variants, you might
    choose to move to a Spark cluster, RStudio, Jupyter Notebook, or any of a large
    number of analytical environments for subsequent analysis. In [Chapter 12](ch12.xhtml#interactive_analysis_in_jupyter_noteboo),
    we explore how this works in Terra, which you can use to easily create a custom
    environment for data processing with a Jupyter interface for interactive analysis,
    generating plots for your publications, and sharing results with others.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究人员将采用的最终方法涉及交互式迭代分析。在基因组学中，您可以使用批处理系统进行大规模比对和变异调用，但是在您获得变异的VCF文件后，您可能选择转移到Spark集群、RStudio、Jupyter
    Notebook或任何大量分析环境中进行后续分析。在[第12章](ch12.xhtml#interactive_analysis_in_jupyter_noteboo)中，我们探讨了在Terra中的实现方式，您可以使用该平台轻松创建自定义环境进行数据处理，具有Jupyter界面进行交互式分析，生成用于出版的图表，并与他人分享结果。
- en: Wrap-Up and Next Steps
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结与下一步
- en: In this chapter, we completed the primer topics, which gave you a background
    on genomics ([Chapter 2](ch02.xhtml#genomics_in_a_nutshell_a_primer_for_new))
    and computing technologies (this chapter). We delved into the nitty-gritty details
    of computer hardware, parallel computing, and virtualization and gave you a glimpse
    of the power of using workflow execution systems to scale out your analysis on
    the cloud. In [Chapter 4](ch04.xhtml#first_steps_in_the_cloud), we take our first
    baby steps to the cloud environment and show you how to get started with your
    own VMs running in GCP.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们完成了初级主题，为您介绍了基因组学（[第2章](ch02.xhtml#genomics_in_a_nutshell_a_primer_for_new)）和计算技术（本章）。我们深入研究了计算机硬件、并行计算和虚拟化的细节，并为您展示了使用工作流执行系统在云上扩展分析能力的潜力。在[第4章](ch04.xhtml#first_steps_in_the_cloud)中，我们迈出了在云环境中的第一步，并向您展示如何在GCP上运行您自己的虚拟机。
