- en: Chapter 14\. From Prediction to Decisions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第14章 从预测到决策
- en: According to a [survey](https://oreil.ly/Kl_7y) done by McKinsey, 50% of their
    respondent organizations had adopted artificial intelligence (AI) or machine learning
    (ML) in 2022, a sharp 2.5x increase relative to 2017, but still lower than the
    peak reached in 2019 (58%). If AI is the [new electricity](https://oreil.ly/O_tsb)
    and data the [new oil](https://oreil.ly/bU0xd), why did adoption stall before
    the advent of large language models (LLMs) such as ChatGPT and Bard?^([1](ch14.html#id744))
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 根据麦肯锡进行的[调查](https://oreil.ly/Kl_7y)，他们的受访组织中有50%在2022年采用了人工智能（AI）或机器学习（ML），相较于2017年增长了2.5倍，但仍低于2019年的峰值（58%）。如果AI是[新的电力](https://oreil.ly/O_tsb)，而数据是[新的石油](https://oreil.ly/bU0xd)，那么在大语言模型（LLM）如ChatGPT和Bard出现之前为什么采用率会停滞呢？^([1](ch14.html#id744))
- en: While the root causes are varied, the most proximate cause is that the majority
    of organizations have yet to find a positive [return on investment](https://oreil.ly/Stpro)
    (ROI). In [“Expanding AI’s Impact With Organizational Learning”](https://oreil.ly/izJb7),
    Sam Ransbotham and his collaborators argue that only “10% of companies obtain
    significant financial benefit from artificial intelligence technologies.”
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管根本原因各不相同，但最直接的原因是大多数组织尚未找到积极的[投资回报率](https://oreil.ly/Stpro)（ROI）。在[“扩展组织学习中的AI影响”](https://oreil.ly/izJb7)中，Sam
    Ransbotham及其合作者认为“只有10%的公司从人工智能技术中获得显著的财务利益”。
- en: Where does this ROI come from? At its core, ML algorithms are predictive procedures,
    so it’s natural to expect that most value is created by improved decision-making
    capabilities. This chapter goes into some of the ways that predictions improve
    decisions. Along the way, I will present some practical methods that will help
    you move from prediction to improved decision making.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这种投资回报率从何而来？在其核心，机器学习算法是预测性过程，因此我们自然期望大多数价值是通过改善决策能力来创造的。本章探讨了一些预测如何改善决策的方法。在此过程中，我将介绍一些实用方法，帮助您从预测转向改进决策。
- en: Dissecting Decision Making
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分解决策制定
- en: Prediction algorithms attempt to circumvent uncertainty, and doing so is extremely
    important in improving our decision-making capabilities. For instance, I can try
    to predict tomorrow’s weather in my hometown for the pure pleasure of doing so.
    But the prediction itself facilitates and improves our ability to make better
    decisions in the face of this uncertainty. It’s not hard to find many use cases
    where different people and organizations would be willing to pay for this information
    (think farmers, party planners, the telecommunications industry, government agencies
    like NASA, etc.).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 预测算法试图规避不确定性，在提高我们的决策能力方面非常重要。例如，我可以试图预测我家乡明天的天气，仅仅出于乐趣。但预测本身促进并改善了我们在面对这种不确定性时做出更好决策的能力。我们可以轻易找到许多使用案例，不同的人和组织愿意为这些信息付费（例如农民、派对策划者、电信行业、NASA等政府机构）。
- en: '[Figure 14-1](#ch14_uncertainty) shows diagramatically the role that uncertainty
    plays in decision making. Starting from the right, once uncertainty is resolved,
    there is an outcome that affects some metric you care about. This outcome depends
    on the set of levers (actions) at your disposal and their interplay with the underlying
    uncertainty. For example, you don’t know if it will rain today (uncertainty) and
    you care about being comfortable and dry (outcomes). You can decide to take your
    umbrella or not (levers). Naturally, if it rains, you’re better off taking your
    umbrella (you’re dry), but if it doesn’t, the best decision is leaving it (you’re
    more comfortable since you don’t have to take it with you).'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[图14-1](#ch14_uncertainty) 图示了不确定性在决策制定中的角色。从右侧开始，一旦不确定性被解决，就会有影响您关心的某些度量指标的结果。这一结果取决于您可以操作的杠杆（行动）集合及其与基础不确定性的相互作用。例如，您不知道今天是否会下雨（不确定性），而您关心的是保持舒适和干燥（结果）。您可以决定是否带伞（操作）。自然地，如果下雨了，带伞是最好的选择（保持干燥），但如果没有下雨，最佳决策是不带伞（因为您无需带着它更舒适）。'
- en: '![decisions under uncertainty](assets/dshp_1401.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![不确定性下的决策](assets/dshp_1401.png)'
- en: Figure 14-1\. Decisions under uncertainty
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14-1 不确定情况下的决策
- en: In [Table 14-1](#tab_examples) I’ve assembled some common use cases in ML, where
    I highlight the roles that decision and uncertainty play, and some possible outcomes.
    Let’s go through the first row, the case of health insurance [claims processing](https://oreil.ly/4V5Du).
    Given a new claim, you must decide to review it manually or approve a payment,
    since a claim might be illegitimate. Illegitimate claims unnecessarily increase
    the insurer’s costs, but review processes are often quite involved and take a
    substantial amount of time and effort. If you were able to predict correctly,
    you could lower prediction error and your costs, as well as increase customer
    satisfaction.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在[Table 14-1](#tab_examples)中，我整理了一些常见的ML用例，其中强调了决策和不确定性的角色以及一些可能的结果。 让我们来看看第一行，即健康保险的案例[理赔处理](https://oreil.ly/4V5Du)。
    针对新的理赔，你必须决定是手动审查还是批准付款，因为理赔可能是不合法的。 不合法的理赔会不必要地增加保险公司的成本，但审查过程通常相当复杂，需要大量时间和精力。
    如果你能正确预测，你可以降低预测误差和成本，同时提高客户满意度。
- en: Table 14-1\. Examples of ML use cases
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 表14-1\. ML用例示例
- en: '| Category | Use case | Decision | Uncertainty | Outcome |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 使用案例 | 决策 | 不确定性 | 结果 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Service operations | Claims processing | Automatic payment versus review
    | Legitimate or not | Reduction of manual process (cost), higher customer satisfaction,
    lower fraud |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 服务运营 | 理赔处理 | 自动支付与审查 | 合法或不合法 | 减少手动流程（成本），提高客户满意度，减少欺诈 |'
- en: '| Service operations | Staffing | Hire or relocate | Staff size depends on
    demand | Higher customer satisfaction, lower unused resources (cost) |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 服务运营 | 人员配置 | 招聘或重新安置 | 员工规模依赖于需求 | 提高客户满意度，减少未使用资源（成本） |'
- en: '| Service operations | Proactive customer support | Call or not call a customer
    | Will a customer have a problem I can solve | Improve satisfaction and lower
    churn |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 服务运营 | 主动客户支持 | 是否联系客户 | 是否会有问题需要我解决 | 提高满意度和减少流失率 |'
- en: '| Supply chain optimization | Demand forecasting | Manage inventory | Inventory
    depends on demand | Higher sales and lower depreciation costs |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 供应链优化 | 需求预测 | 管理库存 | 库存依赖于需求 | 提高销售并降低折旧成本 |'
- en: '| Fraud detection | Chargeback prevention | Approve or decline a transaction
    | Legitimate or not | Lower fraud-related costs, higher customer satisfaction
    |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 欺诈检测 | 反向支付预防 | 批准或拒绝交易 | 合法或不合法 | 减少与欺诈相关的成本，提高客户满意度 |'
- en: '| Marketing | Lead generation | Call or not call a potential customer | Will
    they buy or not | Higher sales efficiency |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 营销 | 潜在客户生成 | 是否联系潜在客户 | 是否购买 | 销售效率更高 |'
- en: '| ML-based products | Recommender system | Recommend A or B | Will they buy
    or not | Higher engagement, lower churn |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 基于ML的产品 | 推荐系统 | 推荐A还是B | 是否购买 | 提高参与度，减少流失率 |'
- en: Thinking first about decisions and outcomes, and only then about ML applications,
    can take you a very long way in developing a strong data science practice at your
    organization.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先思考决策和结果，然后再考虑ML应用，可以帮助您在组织中发展强大的数据科学实践。
- en: Tip
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'Thinking about decisions and levers is a great way to find new ML use cases
    at the workplace. The process is:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 思考决策和杠杆是发现工作场所新ML用例的一个好方法。 过程如下：
- en: Identify the *key* decisions made by your stakeholder (along with the relevant
    metrics and levers).
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定利益相关者所做的*关键*决策（以及相关的指标和杠杆）。
- en: Understand the role of uncertainty.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理解不确定性的角色。
- en: Make a business case for building an ML solution.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为建立ML解决方案做商业案例。
- en: Simple Decision Rules by Smart Thresholding
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 智能阈值设定的简单决策规则
- en: 'As opposed to regression, simple decision rules arise naturally in classification
    models in the form of *thresholding*. I will describe the case of a binomial model
    (two outcomes), but this same principle can be adjusted to the more general multinomial
    case. The typical scenario is something like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 与回归相对，简单的决策规则在分类模型中以*阈值设定*的形式自然产生。 我将描述一个二项模型（两种结果）的情况，但这个原则同样适用于更一般的多项情况。 典型场景如下：
- en: <math alttext="StartLayout 1st Row  Do left-parenthesis tau right-parenthesis
    equals StartLayout Enlarged left-brace 1st Row 1st Column upper A 2nd Column if
    3rd Column ModifyingAbove p With caret Subscript i Baseline greater-than-or-equal-to
    tau 2nd Row 1st Column upper B 2nd Column if 3rd Column ModifyingAbove p With
    caret Subscript i Baseline less-than tau EndLayout EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><mtext>Do</mtext> <mrow><mo>(</mo>
    <mi>τ</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="" open="{" separators=""><mtable><mtr><mtd
    columnalign="left"><mi>A</mi></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><msub><mover accent="true"><mi>p</mi> <mo>^</mo></mover> <mi>i</mi></msub>
    <mo>≥</mo> <mi>τ</mi></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mi>B</mi></mtd>
    <mtd columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><msub><mover accent="true"><mi>p</mi>
    <mo>^</mo></mover> <mi>i</mi></msub> <mo><</mo> <mi>τ</mi></mrow></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row  Do left-parenthesis tau right-parenthesis
    equals StartLayout Enlarged left-brace 1st Row 1st Column upper A 2nd Column if
    3rd Column ModifyingAbove p With caret Subscript i Baseline greater-than-or-equal-to
    tau 2nd Row 1st Column upper B 2nd Column if 3rd Column ModifyingAbove p With
    caret Subscript i Baseline less-than tau EndLayout EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><mtext>Do</mtext> <mrow><mo>(</mo>
    <mi>τ</mi> <mo>)</mo></mrow> <mo>=</mo> <mfenced close="" open="{" separators=""><mtable><mtr><mtd
    columnalign="left"><mi>A</mi></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><msub><mover accent="true"><mi>p</mi> <mo>^</mo></mover> <mi>i</mi></msub>
    <mo>≥</mo> <mi>τ</mi></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mi>B</mi></mtd>
    <mtd columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><msub><mover accent="true"><mi>p</mi>
    <mo>^</mo></mover> <mi>i</mi></msub> <mo><</mo> <mi>τ</mi></mrow></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
- en: Here <math alttext="ModifyingAbove p With caret Subscript i"><msub><mover accent="true"><mi>p</mi>
    <mo>^</mo></mover> <mi>i</mi></msub></math> is the predicted probability score
    for unit *i*, and <math alttext="tau"><mi>τ</mi></math> is a threshold chosen
    by you. The rule activates action *A* if the score is large enough, and action
    *B* otherwise. Note that a similar rationale applies if you replace the predicted
    probability with a predicted continuous outcome. However, the simplified structure
    inherent to classification settings allows you to include the cost of different
    prediction errors in your deliberation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 <math alttext="ModifyingAbove p With caret Subscript i"><msub><mover accent="true"><mi>p</mi>
    <mo>^</mo></mover> <mi>i</mi></msub></math> 是单位 *i* 的预测概率分数，<math alttext="tau"><mi>τ</mi></math>
    是您选择的阈值。如果分数足够高，则规则激活动作 *A*，否则激活动作 *B*。请注意，如果用预测的连续结果替换预测概率，则类似的理由也适用。然而，在分类设置中固有的简化结构允许您在决策过程中考虑不同预测错误的成本。
- en: In a nutshell, everything boils down to a thorough understanding of false positives
    and negatives. In a binomial model, outcomes are usually labeled as positive (1)
    or negative (0). Once you have a predicted probability score and a threshold,
    units with a higher (lower) probability are predicted as positives (negatives).
    See the confusion matrix in [Table 14-2](#confusion_matrix).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 简言之，一切归结为对假阳性和假阴性的深入理解。在二项模型中，结果通常标记为正（1）或负（0）。一旦您有了预测的概率分数和阈值，概率较高（较低）的单位被预测为正例（负例）。参见表
    [Table 14-2](#confusion_matrix) 中的混淆矩阵。
- en: Table 14-2\. A typical confusion matrix
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 表 14-2\. 典型的混淆矩阵
- en: '| Actual/predicted | <math alttext="ModifyingAbove upper N With caret left-parenthesis
    tau right-parenthesis"><mrow><mover accent="true"><mi>N</mi> <mo>^</mo></mover>
    <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mrow></math> | <math alttext="ModifyingAbove
    upper P With caret left-parenthesis tau right-parenthesis"><mrow><mover accent="true"><mi>P</mi>
    <mo>^</mo></mover> <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mrow></math>
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 实际/预测 | <math alttext="ModifyingAbove upper N With caret left-parenthesis
    tau right-parenthesis"><mrow><mover accent="true"><mi>N</mi> <mo>^</mo></mover>
    <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mrow></math> | <math alttext="ModifyingAbove
    upper P With caret left-parenthesis tau right-parenthesis"><mrow><mover accent="true"><mi>P</mi>
    <mo>^</mo></mover> <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mrow></math>
    |'
- en: '| --- | --- | --- |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| N | TN | FP |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| N | TN | FP |'
- en: '| P | FN | TP |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| P | FN | TP |'
- en: Rows and columns in the confusion matrix denote actual and predicted labels,
    respectively. As mentioned, predicted outcomes depend on the chosen threshold
    ( <math alttext="tau"><mi>τ</mi></math> ). Thus, you can classify every instance
    in your sample as true negative (*TN*), true positive (*TP*), false negative (*FN*),
    or false positive (*FP*), depending on whether the predicted label matches the
    true label or not. Cells in the matrix denote the number of cases for each category.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵中的行和列分别表示实际标签和预测标签。如前所述，预测的结果取决于选择的阈值（ <math alttext="tau"><mi>τ</mi></math>
    ）。因此，您可以将样本中的每个实例分类为真负例（*TN*）、真正例（*TP*）、假负例（*FN*）或假正例（*FP*），具体取决于预测标签是否与真实标签匹配。矩阵中的单元格表示每个类别的案例数。
- en: Precision and Recall
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确度和召回率
- en: 'Two common performance metrics in classification problems are the precision
    and recall:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 分类问题中的两个常见性能指标是精确度和召回率：
- en: <math alttext="StartLayout 1st Row 1st Column Precision 2nd Column equals 3rd
    Column StartFraction upper T upper P Over upper T upper P plus upper F upper P
    EndFraction 2nd Row 1st Column Recall 2nd Column equals 3rd Column StartFraction
    upper T upper P Over upper T upper P plus upper F upper N EndFraction EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mtext>Precision</mtext></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mtd></mtr>
    <mtr><mtd columnalign="right"><mtext>Recall</mtext></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>T</mi><mi>P</mi></mrow> <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mtd></mtr></mtable></math>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column Precision 2nd Column equals 3rd
    Column StartFraction upper T upper P Over upper T upper P plus upper F upper P
    EndFraction 2nd Row 1st Column Recall 2nd Column equals 3rd Column StartFraction
    upper T upper P Over upper T upper P plus upper F upper N EndFraction EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mtext>Precision</mtext></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mtd></mtr>
    <mtr><mtd columnalign="right"><mtext>Recall</mtext></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>T</mi><mi>P</mi></mrow> <mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mtd></mtr></mtable></math>
- en: 'Both metrics can be thought of as true positive rates, but each considers different
    universes.^([2](ch14.html#id751)) Precision answers the question: *out of everything
    I said is positive, what percentage was actually positive?* On the other hand,
    recall answers the question: *out of everything that’s actually positive, what
    percentage did I predict correctly*? When you use precision as your considerations,
    you are really thinking about the cost of a false positive; with recall, what
    matters is the cost of a false negative.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个指标都可以看作是真正例率，但每个指标考虑不同的情况。^([2](ch14.html#id751)) 精确度回答的问题是：*在我说的所有正例中，实际上有多少是正的？*
    另一方面，召回率回答的问题是：*在所有实际上是正例的情况下，我预测正确的百分比是多少？* 当您使用精确度作为您的考虑因素时，您实际上在考虑假阳性的成本；而对于召回率来说，重要的是假阴性的成本。
- en: '[Figure 14-2](#ch14_precision_recall) shows precision and recall curves for
    three alternative models trained on a simulated latent variable linear model for
    a balanced outcome. The first column shows a classifier that assigns a probability
    score by drawing random uniform numbers in the unit interval; this *random* classifier
    will serve as a baseline. The middle column plots precision and recall obtained
    from a logistic regression. The final column switches the predicted classes, on
    purpose, to create an inverse probability score where a higher score is associated
    with lower incidence rates.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[图14-2](#ch14_precision_recall)展示了针对模拟的潜在变量线性模型训练的三种替代模型的精确度和召回率曲线，用于平衡结果。第一列显示了一个分类器，通过在单位间隔内绘制随机均匀数来分配概率分数；这个*随机*分类器将作为基线。中间列绘制了从逻辑回归中获得的精确度和召回率。最后一列切换了预测的类别，故意创建了一个反向概率分数，其中更高的分数与更低的发病率相关联。'
- en: 'You can readily see several patterns: precision always starts at the fraction
    of positive cases in your sample, and can be relatively straight (random classifier),
    increasing, or decreasing. Most of the time you get an increasing precision, since
    most models tend to outperform random classifiers and are at least somewhat informative
    of the outcome you want to predict. Though theoretically possible, a negatively
    sloped precision is highly unlikely.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以轻松地看到几种模式：精确度始终从样本中的阳性案例的分数开始，可以是相对直的（随机分类器），增加或减少。大多数情况下，你会得到一个增加的精确度，因为大多数模型倾向于优于随机分类器，并且至少在某种程度上是对你想要预测的结果信息化的。尽管在理论上可能，但负斜率的精确度非常不可能。
- en: Precision is better behaved, in the sense that it always starts at one and then
    decreases to zero, and only the curvature changes. A nice concave function (middle
    plot) is to be generally expected, and is also related to the fact that in healthy
    classification models, scores are informative of the probability of occurrence.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度表现更好，在一个意义上，它始终从一个开始，然后降低到零，只有曲率会改变。一个漂亮的凹函数（中间图）通常可以预期，并且与模型健康分类的事实相关，得分通常是对所要预测事件的概率信息化的。
- en: '![An image of a cartoonish tiger head](assets/dshp_1402.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![一张卡通虎头的图片](assets/dshp_1402.png)'
- en: Figure 14-2\. Precision and recall for different models
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14-2\. 不同模型的精确度和召回率
- en: 'Example: Lead Generation'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 例子：潜在客户生成
- en: Take the example of a lead generation campaign, where you score leads to predict
    which will end in a sale. Your data consists of successful (sale) and failed (no
    sale) contacts for a historical sample of leads previously used by the telemarketing
    team.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以潜在客户生成活动为例，你对潜在客户进行评分，以预测哪些会以销售结束。你的数据包括历史上电话营销团队使用过的潜在客户样本的成功（销售）和失败（未销售）联系。
- en: Consider the simple decision rule to contact a customer if the predicted probability
    is higher than a threshold. An FN is a lead that would’ve become a sale had it
    been sent to the marketing team, and an FP is a lead that was incorrectly sent
    for contact, so it didn’t end up in a sale. The cost of a false negative is the
    forgone revenue from the sale, and the costs of a false positive are any resources
    spent on the processing of a lead (for instance, if the hourly salary of a telemarketing
    executive is $*X*, and each lead takes *k* minutes to be processed, the cost of
    each false positive is $*kX/60*).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个简单的决策规则，即当预测的概率高于一个阈值时联系客户。FN是一个如果被发送给营销团队会成为销售的潜在客户，而FP则是错误地发送给联系人，因此没有最终成交。误报负成本是由于销售损失而产生的未实现收入，误报正的成本是用于处理潜在客户的任何资源（例如，如果一个电话营销执行的小时薪水为$*X*，每个潜在客户的处理时间为*k*分钟，那么每个误报正的成本为$*kX/60*）。
- en: 'A simple *volume* threshold rule works like this: the sales team tells you
    how much volume (*V*) they can handle each period (day or week), and you send
    them the top *V* leads according to the estimated probability score. Clearly,
    by fixing the volume you also implicitly set the threshold of your decision rule.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的*量*阈值规则工作原理如下：销售团队告诉你每个周期（天或周）他们可以处理多少销量（*V*），然后你根据估计的概率分数发送给他们排名前*V*的潜在客户。显然，通过固定销量，你也隐含地设置了你的决策规则的阈值。
- en: Let’s look at a simplified lead generation funnel (see also [Chapter 2](ch02.html#ch02_decom_metrix))
    to understand the effects of such a rule:^([3](ch14.html#id757))
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个简化的潜在客户生成漏斗（参见 [第2章](ch02.html#ch02_decom_metrix)），以理解这种规则的影响：^([3](ch14.html#id757))
- en: <math alttext="StartLayout 1st Row 1st Column Sales 2nd Column equals 3rd Column
    ModifyingBelow StartFraction Sales Over Called EndFraction With bottom-brace Underscript
    left-parenthesis 1 right-parenthesis Endscripts times ModifyingBelow StartFraction
    Called Over Leads EndFraction With bottom-brace Underscript left-parenthesis 2
    right-parenthesis Endscripts times ModifyingBelow Leads With bottom-brace Underscript
    left-parenthesis 3 right-parenthesis Endscripts 2nd Row 1st Column Blank 2nd Column
    equals 3rd Column ModifyingBelow Conv period Eff left-parenthesis tau right-parenthesis
    With bottom-brace Underscript Precision Endscripts times Call Rate left-parenthesis
    FTE right-parenthesis times Leads left-parenthesis tau right-parenthesis EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mtext>Sales</mtext></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><munder><munder accentunder="true"><mfrac><mtext>Sales</mtext>
    <mtext>Called</mtext></mfrac> <mo>︸</mo></munder> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></munder>
    <mo>×</mo> <munder><munder accentunder="true"><mfrac><mtext>Called</mtext> <mtext>Leads</mtext></mfrac>
    <mo>︸</mo></munder> <mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow></munder> <mo>×</mo>
    <munder><munder accentunder="true"><mtext>Leads</mtext> <mo>︸</mo></munder> <mrow><mo>(</mo><mn>3</mn><mo>)</mo></mrow></munder></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><munder><munder accentunder="true"><mrow><mtext>Conv.</mtext><mtext>Eff</mtext><mo>(</mo><mi>τ</mi><mo>)</mo></mrow>
    <mo>︸</mo></munder> <mtext>Precision</mtext></munder> <mo>×</mo> <mtext>Call</mtext>
    <mtext>Rate</mtext> <mrow><mo>(</mo> <mtext>FTE</mtext> <mo>)</mo></mrow> <mo>×</mo>
    <mtext>Leads</mtext> <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column Sales 2nd Column equals 3rd Column
    ModifyingBelow StartFraction Sales Over Called EndFraction With bottom-brace Underscript
    left-parenthesis 1 right-parenthesis Endscripts times ModifyingBelow StartFraction
    Called Over Leads EndFraction With bottom-brace Underscript left-parenthesis 2
    right-parenthesis Endscripts times ModifyingBelow Leads With bottom-brace Underscript
    left-parenthesis 3 right-parenthesis Endscripts 2nd Row 1st Column Blank 2nd Column
    equals 3rd Column ModifyingBelow Conv period Eff left-parenthesis tau right-parenthesis
    With bottom-brace Underscript Precision Endscripts times Call Rate left-parenthesis
    FTE right-parenthesis times Leads left-parenthesis tau right-parenthesis EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mtext>Sales</mtext></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><munder><munder accentunder="true"><mfrac><mtext>Sales</mtext>
    <mtext>Called</mtext></mfrac> <mo>︸</mo></munder> <mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></munder>
    <mo>×</mo> <munder><munder accentunder="true"><mfrac><mtext>Called</mtext> <mtext>Leads</mtext></mfrac>
    <mo>︸</mo></munder> <mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow></munder> <mo>×</mo>
    <munder><munder accentunder="true"><mtext>Leads</mtext> <mo>︸</mo></munder> <mrow><mo>(</mo><mn>3</mn><mo>)</mo></mrow></munder></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><munder><munder accentunder="true"><mrow><mtext>Conv.</mtext><mtext>Eff</mtext><mo>(</mo><mi>τ</mi><mo>)</mo></mrow>
    <mo>︸</mo></munder> <mtext>Precision</mtext></munder> <mo>×</mo> <mtext>Call</mtext>
    <mtext>Rate</mtext> <mrow><mo>(</mo> <mtext>FTE</mtext> <mo>)</mo></mrow> <mo>×</mo>
    <mtext>Leads</mtext> <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
- en: 'Total sales depend on the conversion efficiency (1), call rate (2), and the
    volume of leads (3). Note that conversion efficiency and the volume of leads depend
    on the threshold you choose: in an idealized setting, conversion efficiency is
    equal to the *precision* of your model, and the number of leads depends on the
    scores distribution. On the other hand, the call rate depends on the number of
    full-time equivalent (FTE) or total employees of the sales team: large enough
    sales forces will be able to call every lead in the sample.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 总销售额取决于转化效率（1）、通话率（2）和潜在客户量（3）。请注意，转化效率和潜在客户量取决于您选择的阈值：在理想情况下，转化效率等于您模型的*精度*，而潜在客户数量则取决于分数分布。另一方面，通话率取决于销售团队的全职等效人数（FTE）或总人数：足够大的销售团队将能够拨打样本中的每一个潜在客户。
- en: 'With this you can see why and when the volume rule may work. By sorting the
    leads on the probability score in a descending fashion, and contacting only the
    top *V*, you optimize conversion efficiency (since precision is an increasing
    function in predictive classification models). You also take care of idle resources
    in the telemarketing team: if you send more than they’re able to handle, leads
    with lower scores won’t be contacted in the current time window; if you send less,
    there will be idle sales agents.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个您可以看到量规则何时何地可能起作用。通过按照预测分数按降序对潜在客户进行排序，并仅联系排名前*V*的客户，您可以优化转化效率（因为精度是预测分类模型中的一个增函数）。您还可以照顾电话营销团队中的空闲资源：如果您发送超过他们能够处理的数量，当前时间窗口内评分较低的潜在客户将不会被联系；如果您发送得少，将会有闲置的销售代理人。
- en: '[Figure 14-3](#ch14_lead_opt) plots the product of (1) and (3) as a function
    of the threshold set for the same simulated sample and the same three models used
    before.^([4](ch14.html#id758)) Moving from right to left, you can see that lowering
    the threshold is always better from a total sales perspective, explaining why
    a volume rule usually works well for telemarketing teams.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[图表 14-3](#ch14_lead_opt) 绘制了作为相同模拟样本和之前使用的三个模型之一设置的阈值的函数的（1）和（3）的乘积。从右向左移动，您可以看到降低阈值总是从总销售额的角度来看更好，解释了为什么量规则通常对电话营销团队效果良好。'
- en: '![Optimizing volume](assets/dshp_1403.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![优化潜在客户量](assets/dshp_1403.png)'
- en: Figure 14-3\. Optimizing total sales
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14-3\. 优化总销售额
- en: 'One potential source of confusion arising from this figure is that it may suggest
    that you should set the threshold to zero (call every scored lead) instead of
    just following the volume rule. Put differently, should the sales team hire the
    exact number of FTEs that guarantee that the call rate is maximized and that all
    leads are contacted? The answer is negative: if the score is informative, leads
    with lower predicted scores are also less likely to convert, so the cost of an
    additional FTE (certain) will be larger than the (uncertain) benefit from the
    additional sale. The volume rule assumes that the size of the team is fixed, and
    then optimizes for the largest precision and sales, given this team size.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 由于该图可能暗示您应将阈值设置为零（拨打每个评分潜在客户）而不仅仅是遵循量规则，这可能导致一些混淆。换句话说，销售团队是否应雇佣确保通话率最大化并联系所有潜在客户的确切FTE数量？答案是否定的：如果分数具有信息性，那么预测得分较低的潜在客户也更不可能转化，因此额外FTE的成本（确定的）将大于（不确定的）额外销售收益。量规则假设团队规模固定，并且然后根据此团队规模最大化精度和销售。
- en: Confusion Matrix Optimization
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆矩阵优化
- en: The case of lead generation is somewhat atypical, because you effectively put
    zero weight to false negatives and focus only on optimizing precision. But this
    is not true for most problems (and even with lead generation, there’s a case to
    be made to include false positives in the choice of a threshold). To see this,
    consider the case of fraud, where for any incoming transaction, you need to predict
    whether it’s going to be fraudulent or not.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在客户生成的情况有些特殊，因为您实际上对假阴性置零，并且只专注于优化精度。但对于大多数问题来说这并不适用（即使是在潜在客户生成方面，也有理由在阈值选择中考虑假阳性）。要看到这一点，请考虑欺诈案例，对于任何进入的交易，您需要预测其是否会存在欺诈行为。
- en: A typical decision rule blocks a transaction for large enough probability scores.
    False positives typically translate to infuriated customers (lower customer satisfaction
    and higher churn). On the other hand, a false negative creates a direct cost of
    fraud. This tension gives rise to interesting optimization problems for threshold
    selection.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的决策规则会针对足够大的概率分数阻止交易。假阳性通常会导致愤怒的客户（降低客户满意度和增加流失率）。另一方面，假阴性会直接产生欺诈成本。这种紧张关系引发了阈值选择的有趣优化问题。
- en: 'The general idea is to find the threshold that *minimizes* the expected cost
    from incorrect predictions; alternatively, if you think you should also include
    the value from correct predictions, you can choose the threshold to *maximize*
    the expected profits. These can be expressed as:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 总体思路是找到*最小化*由于错误预测而产生的预期成本的阈值；或者，如果您认为还应包括正确预测的价值，您可以选择*最大化*预期利润的阈值。这可以表示为：
- en: <math alttext="StartLayout 1st Row 1st Column upper E left-parenthesis Cost
    right-parenthesis left-parenthesis tau right-parenthesis 2nd Column equals 3rd
    Column upper P Subscript upper F upper P Baseline left-parenthesis tau right-parenthesis
    c Subscript upper F upper P plus upper P Subscript upper F upper N Baseline left-parenthesis
    tau right-parenthesis c Subscript upper F upper N 2nd Row 1st Column upper E left-parenthesis
    Profit right-parenthesis left-parenthesis tau right-parenthesis 2nd Column equals
    3rd Column upper P Subscript upper T upper P Baseline left-parenthesis tau right-parenthesis
    b Subscript upper T upper P plus upper P Subscript upper T upper N Baseline left-parenthesis
    tau right-parenthesis b Subscript upper T upper N minus left-parenthesis upper
    P Subscript upper F upper P Baseline left-parenthesis tau right-parenthesis c
    Subscript upper F upper P Baseline plus upper P Subscript upper F upper N Baseline
    left-parenthesis tau right-parenthesis c Subscript upper F upper N Baseline right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi>
    <mo>(</mo> <mtext>Cost</mtext> <mo>)</mo> <mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>P</mi> <mrow><mi>F</mi><mi>P</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>c</mi> <mrow><mi>F</mi><mi>P</mi></mrow></msub>
    <mo>+</mo> <msub><mi>P</mi> <mrow><mi>F</mi><mi>N</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>c</mi> <mrow><mi>F</mi><mi>N</mi></mrow></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mi>E</mi> <mo>(</mo> <mtext>Profit</mtext>
    <mo>)</mo> <mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><msub><mi>P</mi> <mrow><mi>T</mi><mi>P</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>b</mi> <mrow><mi>T</mi><mi>P</mi></mrow></msub>
    <mo>+</mo> <msub><mi>P</mi> <mrow><mi>T</mi><mi>N</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>b</mi> <mrow><mi>T</mi><mi>N</mi></mrow></msub>
    <mo>-</mo> <mrow><mo>(</mo> <msub><mi>P</mi> <mrow><mi>F</mi><mi>P</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>c</mi> <mrow><mi>F</mi><mi>P</mi></mrow></msub>
    <mo>+</mo> <msub><mi>P</mi> <mrow><mi>F</mi><mi>N</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>c</mi> <mrow><mi>F</mi><mi>N</mi></mrow></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column upper E left-parenthesis Cost
    right-parenthesis left-parenthesis tau right-parenthesis 2nd Column equals 3rd
    Column upper P Subscript upper F upper P Baseline left-parenthesis tau right-parenthesis
    c Subscript upper F upper P plus upper P Subscript upper F upper N Baseline left-parenthesis
    tau right-parenthesis c Subscript upper F upper N 2nd Row 1st Column upper E left-parenthesis
    Profit right-parenthesis left-parenthesis tau right-parenthesis 2nd Column equals
    3rd Column upper P Subscript upper T upper P Baseline left-parenthesis tau right-parenthesis
    b Subscript upper T upper P plus upper P Subscript upper T upper N Baseline left-parenthesis
    tau right-parenthesis b Subscript upper T upper N minus left-parenthesis upper
    P Subscript upper F upper P Baseline left-parenthesis tau right-parenthesis c
    Subscript upper F upper P Baseline plus upper P Subscript upper F upper N Baseline
    left-parenthesis tau right-parenthesis c Subscript upper F upper N Baseline right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi>
    <mo>(</mo> <mtext>Cost</mtext> <mo>)</mo> <mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>P</mi> <mrow><mi>F</mi><mi>P</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>c</mi> <mrow><mi>F</mi><mi>P</mi></mrow></msub>
    <mo>+</mo> <msub><mi>P</mi> <mrow><mi>F</mi><mi>N</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>c</mi> <mrow><mi>F</mi><mi>N</mi></mrow></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mi>E</mi> <mo>(</mo> <mtext>Profit</mtext>
    <mo>)</mo> <mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><msub><mi>P</mi> <mrow><mi>T</mi><mi>P</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>b</mi> <mrow><mi>T</mi><mi>P</mi></mrow></msub>
    <mo>+</mo> <msub><mi>P</mi> <mrow><mi>T</mi><mi>N</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>b</mi> <mrow><mi>T</mi><mi>N</mi></mrow></msub>
    <mo>-</mo> <mrow><mo>(</mo> <msub><mi>P</mi> <mrow><mi>F</mi><mi>P</mi></mrow></msub>
    <mrow><mo>(</mo> <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>c</mi> <mrow><mi>F</mi><mi>P</mi></mrow></msub>
    <mo>+</mo> <msub><mi>P</mi> <mrow><mi>F</mi><mi>N</mi></mrow></msub> <mrow><mo>(</mo>
    <mi>τ</mi> <mo>)</mo></mrow> <msub><mi>c</mi> <mrow><mi>F</mi><mi>N</mi></mrow></msub>
    <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
- en: where <math alttext="upper P Subscript x Baseline comma c Subscript x Baseline
    comma b Subscript x Baseline"><mrow><msub><mi>P</mi> <mi>x</mi></msub> <mo>,</mo>
    <msub><mi>c</mi> <mi>x</mi></msub> <mo>,</mo> <msub><mi>b</mi> <mi>x</mi></msub></mrow></math>
    denote the probability of a true or false positive or negative (*x*), and their
    associated cost or benefit, respectively. Probabilities are estimated using the
    frequencies in the confusion matrix as <math alttext="upper P Subscript x Baseline
    equals n Subscript x Baseline slash sigma-summation Underscript y Endscripts n
    Subscript y"><mrow><msub><mi>P</mi> <mi>x</mi></msub> <mo>=</mo> <msub><mi>n</mi>
    <mi>x</mi></msub> <mo>/</mo> <msub><mo>∑</mo> <mi>y</mi></msub> <msub><mi>n</mi>
    <mi>y</mi></msub></mrow></math> , and depend on the chosen threshold.^([5](ch14.html#id762))
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 <math alttext="upper P Subscript x Baseline comma c Subscript x Baseline
    comma b Subscript x Baseline"><mrow><msub><mi>P</mi> <mi>x</mi></msub> <mo>,</mo>
    <msub><mi>c</mi> <mi>x</mi></msub> <mo>,</mo> <msub><mi>b</mi> <mi>x</mi></msub></mrow></math>
    表示真阳性或假阳性或假阴性（*x*）的概率及其相关成本或利益。概率是使用混淆矩阵中的频率来估算的，如 <math alttext="upper P Subscript
    x Baseline equals n Subscript x Baseline slash sigma-summation Underscript y Endscripts
    n Subscript y"><mrow><msub><mi>P</mi> <mi>x</mi></msub> <mo>=</mo> <msub><mi>n</mi>
    <mi>x</mi></msub> <mo>/</mo> <msub><mo>∑</mo> <mi>y</mi></msub> <msub><mi>n</mi>
    <mi>y</mi></msub></mrow></math> ，并依赖于选择的阈值。^([5](ch14.html#id762))
- en: '[Figure 14-4](#ch14_sym_cost) shows sample estimates using the same simulated
    dataset as before; importantly, I assume a symmetric case where all costs and
    benefits have the same value (normalized to one). You can see that for cost (left)
    and profit optimization (right), the optimal threshold is ~0.5, as expected in
    a model with balanced outcomes and symmetrical cost/benefit structure.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[图14-4](#ch14_sym_cost) 显示了使用与之前相同的模拟数据集的样本估计；重要的是，我假设所有成本和收益都具有相同的值（归一化为一）。您可以看到，对于成本（左侧）和利润优化（右侧），最优阈值约为0.5，这在具有平衡结果和对称成本/收益结构的模型中是预期的。'
- en: '![symmetric cost and profit](assets/dshp_1404.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![对称成本和利润](assets/dshp_1404.png)'
- en: Figure 14-4\. Symmetric expected cost and profits
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14-4\. 对称预期成本和利润
- en: '[Figure 14-5](#ch14_asym_cost) shows the effect of doubling the cost of a false
    positive and negative on the optimal threshold. Directionally speaking, you would
    expect that increasing the cost of a false positive increases the threshold, as
    you put more weight on the precision of the model. Alternatively, a higher cost
    of a false negative lowers the optimal threshold since you put more weight on
    the recall.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[图14-5](#ch14_asym_cost) 显示了将假阳性和假阴性成本加倍对最优阈值的影响。从方向上讲，您可以预期增加假阳性的成本会增加阈值，因为您更加关注模型的精确性。相反，增加假阴性的成本会降低最优阈值，因为您更加关注召回率。'
- en: '![asymmetric cost](assets/dshp_1405.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![非对称成本](assets/dshp_1405.png)'
- en: Figure 14-5\. Asymmetric expected costs
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图14-5\. 非对称预期成本
- en: 'You can use this method to find suitable thresholds that will transform your
    classification model into a decision rule. The process involves the following
    steps:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用此方法找到适当的阈值，将您的分类模型转换为决策规则。该过程涉及以下步骤：
- en: Train a classifier with good predictive performance.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用具有良好预测性能的分类器进行训练。
- en: For cost minimization, set suitable costs for prediction errors. Because of
    the structure of the problem, you need only have relative costs (such as, *the
    cost of a false negative is 3x that of a false positive*; that is, you can normalize
    everything with respect to one outcome).
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了成本最小化，设置适当的预测错误成本。由于问题的结构，您只需有相对成本（例如，*假阴性的成本是假阳性的3倍*；也就是说，您可以相对于一个结果来归一化一切）。
- en: A similar consideration applies for profit maximization.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 利润最大化也适用类似的考虑。
- en: These can be computed for different threshold values and optimized.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些可以针对不同的阈值进行计算和优化。
- en: Key Takeaways
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要要点
- en: 'These are the key takeaways from this chapter:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是本章的要点：
- en: Moving from prediction to decisions is critical if you want to find positive
    ROI for your data science practice.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望为您的数据科学实践找到正面的投资回报率，从预测转向决策至关重要。
- en: ML is a set of predictive algorithms that can, first and foremost, greatly improve
    your organization’s decision-making capabilities.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一组预测算法，首先可以极大地提升您组织的决策能力。
- en: Threshold decision rules abound in ML.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中充斥着阈值决策规则。
- en: Many regression and classification models give rise to simple decision rules
    that trigger actions if the predicted outcome is greater than, equal to, or lower
    than a predetermined threshold.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 许多回归和分类模型产生简单的决策规则，如果预测结果大于、等于或低于预定阈值，则触发动作。
- en: Decision rules in classification models.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型中的决策规则。
- en: Because of the simplified outcome structure, classification models give rise
    to decision rules that can be easily optimized. One such optimization path takes
    into account the costs and benefits from different prediction outcomes (true and
    false positives or negatives). I showed how a simple volume-threshold rule arises
    when you only care about the precision of your model, and the more complete case
    where false positives and negatives matter.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 由于简化的结果结构，分类模型产生易于优化的决策规则。这种优化路径考虑了不同预测结果（真阳性或假阳性或真阴性或假阴性）的成本和效益。我展示了当您只关心模型精度时如何产生简单的体积阈值规则，以及更全面的情况，其中假阳性和假阴性问题。
- en: Further Reading
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: My book *Analytical Skills for AI and Data Science* goes in depth into many
    of the themes of this chapter. Importantly, I did not cover the practical problem
    of threshold optimization described here.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我的书 *Analytical Skills for AI and Data Science* 深入探讨了本章许多主题。重要的是，我没有涵盖这里描述的阈值优化实际问题。
- en: 'Ajay Agrawal et al., *Power and Prediction: The Disruptive Economics of Artificial
    Intelligence* (Harvard Business Review Press) strongly reinforce the point that
    the potential for AI and ML to disrupt the economy depends on their ability to
    improve our decision-making capabilities.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 'Ajay Agrawal等人的 *Power and Prediction: The Disruptive Economics of Artificial
    Intelligence*（哈佛商业评论出版社）强调AI和ML改善我们决策能力的潜力将如何影响经济。'
- en: ^([1](ch14.html#id744-marker)) One may even ask if LLMs are really going to
    change the trend of adoption in a significant way. I believe that the fundamentals
    haven’t really changed *yet*, at least until machines reach artificial general
    intelligence (AGI). But I’ll discuss this topic in [Chapter 17](ch17.html#ch17_llms).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch14.html#id744-marker)) 甚至可以质疑LLMs是否真的会显著改变采纳趋势。我认为基础原理至少在机器达到人工智能通用性之前*尚未*真正改变。但我将在[第17章](ch17.html#ch17_llms)讨论这个话题。
- en: ^([2](ch14.html#id751-marker)) Note that in the ML literature, recall is commonly
    taken as the *true positive rate*.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch14.html#id751-marker)) 请注意，在机器学习文献中，召回率通常被视为*真阳性率*。
- en: ^([3](ch14.html#id757-marker)) I assume that the contact ratio is one, so every
    call ends in a contact. In applications this is usually not true, so not only
    does the funnel need to be expanded, but you may also need to adjust your model.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch14.html#id757-marker)) 我假设联系比率为1，因此每通电话都以联系结束。在实际应用中通常并非如此，因此不仅需要扩展销售漏斗，还可能需要调整您的模型。
- en: ^([4](ch14.html#id758-marker)) Sample size was normalized to 100 and the outcome
    is balanced, so there are only ~50 true positive cases.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch14.html#id758-marker)) 样本大小已标准化为100，结果平衡，因此只有约50个真阳性案例。
- en: ^([5](ch14.html#id762-marker)) While this is correct for the profit calculation,
    you may want to use the conditional probabilities, given a prediction error for
    the cost calculation. The chosen threshold doesn’t change since this amounts to
    a rescaling of the objective function.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch14.html#id762-marker)) 尽管这对于利润计算是正确的，但在成本计算中，您可能希望使用条件概率，考虑到预测误差。所选阈值不变，因为这相当于目标函数的重新缩放。
