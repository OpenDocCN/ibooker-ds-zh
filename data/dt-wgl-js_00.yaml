- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: 'Getting started: establishing your data pipeline'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧：建立你的数据处理管道
- en: '**This chapter covers**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**本章涵盖**'
- en: Understanding the what and why of data wrangling
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据处理的“是什么”和“为什么”
- en: Defining the difference between data wrangling and data analysis
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义数据处理与数据分析之间的区别
- en: Learning when it’s appropriate to use JavaScript for data analysis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习何时适合使用JavaScript进行数据分析
- en: Gathering the tools you need in your toolkit for JavaScript data wrangling
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集你在JavaScript数据处理工具箱中需要的工具
- en: Walking through the data-wrangling process
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 漫步数据处理过程
- en: Getting an overview of a real data pipeline
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取真实数据处理管道的概览
- en: 1.1 Why data wrangling?
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 为什么需要数据处理？
- en: Our modern world seems to revolve around data. You see it almost everywhere
    you look. If data can be collected, then it’s being collected, and sometimes you
    must try to make sense of it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的现代世界似乎围绕着数据旋转。你几乎在任何地方都能看到它。如果数据可以被收集，那么它正在被收集，有时你必须努力理解它。
- en: Analytics is an essential component of decision-making in business. How are
    users responding to your app or service? If you make a change to the way you do
    business, does it help or make things worse? These are the kinds of questions
    that businesses are asking of their data. Making better use of your data and getting
    useful answers can help put us ahead of the competition.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分析学是商业决策过程中的一个重要组成部分。用户对你的应用或服务有何反应？如果你改变你的业务方式，这有助于改善情况还是使情况变得更糟？这些问题是企业在他们的数据中询问的问题。更好地利用你的数据并获得有用的答案可以帮助我们在竞争中脱颖而出。
- en: Data is also used by governments to make policies based on evidence, and with
    more and more *open data* becoming available, citizens also have a part to play
    in analyzing and understanding this data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据也被政府用来基于证据制定政策，随着越来越多的*开放数据*变得可用，公民也在分析和理解这些数据中扮演着一定的角色。
- en: Data wrangling, the act of preparing your data for interrogation, is a skill
    that’s in demand and on the rise. Proficiency in data-related skills is becoming
    more and more prevalent and is needed by a wider variety of people. In this book
    you’ll work on your data-wrangling skills to help you support data-related activities.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理，即准备你的数据以便进行查询的行为，是一项需求日益增长且不断上升的技能。数据相关技能的熟练度越来越普遍，并且需要更多样化的人群。在这本书中，你将练习数据处理技能，以帮助你支持数据相关活动。
- en: These skills are also useful in your day-to-day development tasks. How is the
    performance of your app going? Where is the performance bottleneck? Which way
    is your bug count heading? These kinds of questions are interesting to us as developers,
    and they can also be answered through data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技能在日常的开发任务中也同样有用。你的应用性能如何？性能瓶颈在哪里？错误数量的发展趋势是什么？这些问题对我们这些开发者来说很有趣，而且它们也可以通过数据得到解答。
- en: 1.2 What’s data wrangling?
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 什么是数据处理？
- en: Wikipedia describes data wrangling as the process of converting data, with the
    help of tools, from one form to another to allow convenient consumption of the
    data. This includes transformation, aggregation, visualization, and statistics.
    I’d say that data wrangling is the whole process of working with data to get it
    into and through your pipeline, whatever that may be, from data acquisition to
    your target audience, whoever they might be.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科将数据处理描述为在工具的帮助下将数据从一种形式转换为另一种形式的过程，以便方便地消费数据。这包括转换、聚合、可视化和统计分析。我认为数据处理是将数据带入并通过你的管道的整个过程，无论这管道是什么，从数据采集到目标受众，无论他们是谁。
- en: Many books only deal with data analysis, which Wikipedia describes as the process
    of working with and inspecting data to support decision-making. I view data analysis
    as a subset of the data-wrangling process. A data analyst might not care about
    databases, REST APIs, streaming data, real-time analysis, preparing code and data
    for use in production, and the like. For a data wrangler, these are often essential
    to the job.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 许多书籍只涉及数据分析，维基百科将其描述为处理和检查数据以支持决策的过程。我认为数据分析是数据处理过程的一个子集。数据分析师可能不会关心数据库、REST
    API、流数据、实时分析、为生产使用准备代码和数据等。对于数据处理员来说，这些通常是工作的关键。
- en: 'A data analyst might spend most of the time analyzing data offline to produce
    reports and visualizations to aid decision-makers. A data wrangler also does these
    things, but they also likely have production concerns: for example, they might
    need their code to execute in a real-time system with automatic analysis and visualization
    of live data.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析师可能会花大部分时间离线分析数据，以生成报告和可视化，帮助决策者。数据处理员也做这些事情，但他们也可能有生产方面的考虑：例如，他们可能需要他们的代码在一个实时系统中执行，自动分析和可视化实时数据。
- en: The data-wrangling puzzle can have many pieces. They fit together in many different
    and complex ways. First, you must acquire data. The data may contain any number
    of problems that you need to fix. You have many ways you can format and deliver
    the data to your target audience. In the middle somewhere, you must store the
    data in an efficient format. You might also have to accept streaming updates and
    process incoming data in real time.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理难题可能有多个部分。它们以许多不同和复杂的方式组合在一起。首先，你必须获取数据。数据可能包含任何你需要解决的问题。你有许多方式可以格式化和向目标受众交付数据。在某个中间位置，你必须以高效的方式存储数据。你也可能需要接受流式更新并实时处理传入的数据。
- en: Ultimately the process of data wrangling is about communication. You need to
    get your data into a shape that promotes clarity and understanding and enables
    fast decision-making. How you format and represent the data and the questions
    you need to ask of it will vary dramatically according to your situation and needs,
    yet these questions are critical to achieving an outcome.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，数据处理的过程是关于沟通的。你需要将你的数据整理成一种促进清晰度和理解，并能够快速做出决策的形状。你如何格式化和表示数据，以及你需要对其提出的问题，将根据你的情况和需求而有很大差异，但这些问题是实现结果的关键。
- en: Through data wrangling, you corral and cajole your data from one shape to another.
    At times, it will be an extremely messy process, especially when you don’t control
    the source. In certain situations, you’ll build ad hoc data processing code that
    will be run only once. This won’t be your best code. It doesn’t have to be because
    you may never use it again, and you shouldn’t put undue effort into code that
    you won’t reuse. For this code, you’ll expend only as much effort as necessary
    to prove that the output is reliable.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通过数据处理，你将你的数据从一种形状调整到另一种形状。有时，这会是一个非常混乱的过程，尤其是当你无法控制源头时。在某些情况下，你会构建一次性的数据处理代码，它只会运行一次。这不会是你的最佳代码。它不必是，因为你可能永远不会再次使用它，你不应该对不会重用的代码投入过多的努力。对于这段代码，你将只投入必要的努力来证明输出是可靠的。
- en: At other times, data wrangling, like any coding, can be an extremely disciplined
    process. You’ll have occasions when you understand the requirements well, and
    you’ll have patiently built a production-ready data processing pipeline. You’ll
    put great care and skill into this code because it will be invoked many thousands
    of times in a production environment. You may have used *test-driven development,*
    and it’s probably some of the most robust code you’ve ever written.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他时候，数据处理，就像任何编码一样，可以是一个非常严谨的过程。你会有理解需求很好的时候，并且你已经耐心地构建了一个生产就绪的数据处理管道。你将对这段代码投入极大的关注和技巧，因为它将在生产环境中被调用成千上万次。你可能已经使用了*测试驱动开发*，这可能是你写过的最健壮的代码之一。
- en: More than likely your data wrangling will be somewhere within the spectrum between
    ad hoc and disciplined. It’s likely that you’ll write a bit of throw-away code
    to transform your source data into something more usable. Then for other code
    that must run in production, you’ll use much more care.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能你的数据处理将介于临时和严谨之间。你可能会写一些临时代码来将源数据转换成更可用的形式。然后对于必须在生产中运行的代码，你会更加小心。
- en: The process of data wrangling consists of multiple phases, as you can see in
    [figure 1.1](#figure1.1). This book divides the process into these phases as though
    they were distinct, but they’re rarely cleanly separated and don’t necessarily
    flow neatly one after the other. I separate them here to keep things simple and
    make things easier to explain. In the real world, it’s never this clean and well
    defined. The phases of data wrangling intersect and interact with each other and
    are often tangled up together. Through these phases you understand, analyze, reshape,
    and transform your data for delivery to your audience.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理的过程包括多个阶段，正如你在[图1.1](#figure1.1)中可以看到的那样。这本书将这个过程划分为这些阶段，好像它们是独立的，但实际上它们很少被干净地分开，也不一定按顺序依次进行。我在这里将它们分开，以保持事情简单，并使解释更容易。在现实世界中，事情永远不会这么干净和明确。数据整理的阶段相互交叉和相互作用，通常纠缠在一起。通过这些阶段，你理解、分析、重塑和转换你的数据，以便交付给受众。
- en: '![c01_01.eps](Images/c01_01.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![c01_01.eps](Images/c01_01.png)'
- en: '[Figure 1.1](#figureanchor1.1) Separating data wrangling into phases'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.1](#figureanchor1.1) 将数据整理分为阶段'
- en: The main phases of data wrangling are data acquisition, exploration, cleanup,
    transformation, analysis, and finally reporting and visualization.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理的主要阶段包括数据获取、探索、清理、转换、分析，最后是报告和可视化。
- en: Data wrangling involves wrestling with many different issues. How can you filter
    or optimize data, so you can work with it more effectively? How can you improve
    your code to process the data more quickly? How do you work with your language
    to be more effective? How can you scale up and deal with larger data sets?
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据整理涉及处理许多不同的问题。你如何过滤或优化数据，以便更有效地工作？你如何改进你的代码以更快地处理数据？你如何使用你的语言来提高效率？你如何扩展并处理更大的数据集？
- en: Throughout this book you’ll look at the process of data wrangling and each of
    its constituent phases. Along the way we’ll discuss many issues and how you should
    tackle them.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，你将了解数据整理的过程及其各个组成部分。在这个过程中，我们将讨论许多问题以及如何应对它们。
- en: 1.3 Why a book on JavaScript data wrangling?
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 为什么会有关于JavaScript数据整理的书？
- en: JavaScript isn’t known for its data-wrangling chops. Normally you’re told to
    go to other languages to work with data. In the past I’ve used Python and Pandas
    when working with data. That’s what everyone says to use, right? Then why write
    this book?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript并不以数据处理能力著称。通常你会被告知去使用其他语言来处理数据。在过去，我使用Python和Pandas来处理数据。这就是大家都会说的使用方法，对吧？那么为什么写这本书？
- en: Python and Pandas *are* good for data analysis. I won’t attempt to dispute that.
    They have the maturity and the established ecosystem.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Python和Pandas *确实*适合数据分析。我不会试图否认这一点。它们具有成熟度和建立的生态系统。
- en: Jupyter Notebook (formerly IPython Notebook) is a great environment for exploratory
    coding, but you have this type of tool in JavaScript now. Jupyter itself has a
    plugin that allows it to run JavaScript. Various JavaScript-specific tools are
    also now available, such as RunKit, Observable, and my own offering is Data-Forge
    Notebook.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebook（以前称为IPython Notebook）是一个用于探索性编码的绝佳环境，但现在你也有这种类型的工具在JavaScript中。Jupyter本身有一个插件，允许它运行JavaScript。现在也提供了各种JavaScript特定的工具，例如RunKit、Observable以及我自己的Data-Forge
    Notebook。
- en: I’ve used Python for working with data, but I always felt that it didn’t fit
    well into my development pipeline. I’m not saying there’s anything wrong with
    Python; in many ways, I like the language. My problem with Python is that I already
    do much of my work in JavaScript. I need my data analysis code to run in JavaScript
    so that it will work in the JavaScript production environment where I need it
    to run. How do you do that with Python?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用Python来处理数据，但我总觉得它不适合我的开发流程。我并不是说Python有什么问题；在许多方面，我喜欢这门语言。我对Python的问题是我已经在JavaScript中做了很多工作。我需要我的数据分析代码在JavaScript中运行，以便在需要运行的JavaScript生产环境中工作。你如何用Python做到这一点？
- en: 'You could do your exploratory and analysis coding in Python and then move the
    data to JavaScript visualization, as many people do. That’s a common approach
    due to JavaScript’s strong visualization ecosystem. But then what if you want
    to run your analysis code on live data? When I found that I needed to run my data
    analysis code in production, I then had to rewrite it in JavaScript. I was never
    able to accept that this was the way things must be. For me, it boils down to
    this: I don’t have time to rewrite code.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用 Python 进行探索和分析编码，然后将数据移动到 JavaScript 可视化，正如许多人所做的那样。由于 JavaScript 强大的可视化生态系统，这是一种常见的做法。但如果你想在实时数据上运行你的分析代码呢？当我发现我需要在生产环境中运行我的数据分析代码时，我就不得不将其重写为
    JavaScript。我从未能够接受这是事情必须如此的方式。对我来说，这归结为一点：我没有时间重写代码。
- en: But does anyone have time to rewrite code? The world moves too quickly for that.
    We all have deadlines to meet. You need to add value to your business, and time
    is a luxury you can’t often afford in a hectic and fast-paced business environment.
    You want to write your data analysis code in an exploratory fashion, à la Jupyter
    Notebook, but using JavaScript and later deploying it to a JavaScript web application
    or microservice.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 但谁有时间为代码重写呢？世界变化太快，以至于没有时间。我们都有要遵守的最后期限。你需要为你的业务增加价值，而在繁忙和快节奏的商业环境中，时间通常是一种你难以承受的奢侈。你希望以探索的方式编写你的数据分析代码，就像
    Jupyter Notebook 一样，但使用 JavaScript，然后将其部署到 JavaScript 网络应用程序或微服务中。
- en: This led me on a journey of working with data in JavaScript and building out
    an open source library, Data-Forge, to help make this possible. Along the way
    I discovered that the data analysis needs of JavaScript programmers were not well
    met. This state of affairs was somewhat perplexing given the proliferation of
    JavaScript programmers, the easy access of the JavaScript language, and the seemingly
    endless array of JavaScript visualization libraries. Why weren’t we already talking
    about this? Did people really think that data analysis couldn’t be done in JavaScript?
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这引导我走上了在 JavaScript 中处理数据并构建开源库 Data-Forge 的旅程，以帮助实现这一目标。在这个过程中，我发现 JavaScript
    程序员的数据分析需求没有得到很好的满足。鉴于 JavaScript 程序员的激增、JavaScript 语言的易于访问以及看似无尽的 JavaScript
    可视化库系列，这一状况有些令人困惑。我们为什么还没有谈论这个问题呢？人们真的认为数据分析不能在 JavaScript 中完成吗？
- en: These are the questions that led me to write this book. If you know JavaScript,
    and that’s the assumption I’m making, then you probably won’t be surprised that
    I found JavaScript to be a surprisingly capable language that gives substantial
    productivity. For sure, it has problems to be aware of, but all good JavaScript
    coders are already working with the good parts of the language and avoiding the
    bad parts.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题引导我写下了这本书。如果你知道 JavaScript，这是我所做的假设，那么你可能不会对我发现 JavaScript 是一种出人意料的有能力且能显著提高生产力的语言感到惊讶。当然，它有一些需要注意的问题，但所有优秀的
    JavaScript 开发者都已经在使用语言的优点，并避免使用缺点。
- en: These days all sorts of complex applications are being written in JavaScript.
    You already know the language, it’s capable, and you use it in production. Staying
    in JavaScript is going to save you time and effort. Why not also use JavaScript
    for data wrangling?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这些天，各种复杂的应用程序都在用 JavaScript 编写。你已经熟悉这门语言，它功能强大，并且你在生产环境中也在使用它。继续使用 JavaScript
    将会为你节省时间和精力。为什么不也用 JavaScript 来处理数据呢？
- en: 1.4 What will you get out of this book?
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 你将从这本书中获得什么？
- en: You’ll learn how to do data wrangling in JavaScript. Through numerous examples,
    building up from simple to more complex, you’ll develop your skills for working
    with data. Along the way you’ll gain an understanding of the many tools you can
    use that are already readily available to you. You’ll learn how to apply data
    analysis techniques in JavaScript that are commonly used in other languages.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你将学习如何在 JavaScript 中进行数据处理。通过众多示例，从简单到复杂，你将发展你的数据处理技能。在这个过程中，你将了解许多你可以使用的工具，这些工具已经
    readily 可用。你将学习如何在 JavaScript 中应用其他语言中常用的数据分析技术。
- en: Together we’ll look at the entire data-wrangling process purely in JavaScript.
    You’ll learn to build a data processing pipeline that takes the data from a source,
    processes and transforms it, then finally delivers the data to your audience in
    an appropriate form.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将一起纯粹在 JavaScript 中查看整个数据处理过程。你将学会构建一个数据处理管道，它从数据源获取数据，对其进行处理和转换，然后最终以适当的形式将数据交付给受众。
- en: You’ll learn how to tackle the issues involved in rolling out your data pipeline
    to your production environment and scaling it up to large data sets. We’ll look
    at the problems that you might encounter and learn the thought processes you must
    adopt to find solutions.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你将学习如何解决将你的数据处理管道部署到生产环境并扩展到大数据集所涉及的问题。我们将探讨你可能会遇到的问题，并学习你必须采用的思维过程来找到解决方案。
- en: I’ll show that there’s no need for you to step out to other languages, such
    as Python, that are traditionally considered better suited to data analysis. You’ll
    learn how to do it in JavaScript.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我将证明你不需要转向其他语言，如Python，这些语言传统上被认为更适合数据分析。你将学习如何在JavaScript中做到这一点。
- en: The ultimate takeaway is an appreciation of the world of data wrangling and
    how it intersects with JavaScript. This is a huge world, but *Data Wrangling with
    JavaScript* will help you navigate it and make sense of it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的收获是对数据处理世界的欣赏以及它与JavaScript的交汇点。这是一个巨大的世界，但《使用JavaScript进行数据处理》将帮助你导航并理解它。
- en: 1.5 Why use JavaScript for data wrangling?
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 为什么使用JavaScript进行数据处理？
- en: I advocate using JavaScript for data wrangling for several reasons; these are
    summarized in table 1.1.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我主张使用JavaScript进行数据处理，原因有几个；这些原因总结在表1.1中。
- en: Table 1.1 Reasons for using JavaScript for data wrangling
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.1 使用JavaScript进行数据处理的理由
- en: '| **Reason** | **Details** |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| **理由** | **详情** |'
- en: '| --- | --- |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| You already know JavaScript. | Why learn another language for working with
    data? (Assuming you already know JavaScript.) |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 你已经了解JavaScript。| 为什么还要学习另一种语言来处理数据？（假设你已经了解JavaScript。）|'
- en: '| JavaScript is a capable language. | It’s used to build all manner of complex
    applications. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| JavaScript是一种强大的语言。| 它被用来构建各种复杂的应用程序。|'
- en: '| Exploratory coding. | Using a prototyping process with live reload (discussed
    in chapter 5) is a powerful way to write applications using JavaScript. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 探索性编码。| 使用带有实时重载的原型制作流程（在第5章中讨论）是使用JavaScript编写应用程序的强大方式。|'
- en: '| Strong visualization ecosystem. | Python programmers often end up in JavaScript
    to use its many visualization libraries, including D3, possibly the most sophisticated
    visualization library. We’ll explore visualization in chapters 10 and 13. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 强大的可视化生态系统。| Python程序员通常会转向JavaScript来使用其许多可视化库，包括D3，可能是最复杂的数据可视化库。我们将在第10章和第13章中探讨可视化。|'
- en: '| Generally strong ecosystem. | JavaScript has one of the strongest user-driven
    ecosystems. Throughout the book we’ll use many third-party tools, and I encourage
    you to explore further to build out your own toolkit. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 通常拥有强大的生态系统。| JavaScript拥有最强大的用户驱动生态系统之一。在整个书中，我们将使用许多第三方工具，并鼓励你进一步探索以构建自己的工具包。|'
- en: '| JavaScript is everywhere. | JavaScript is in the browser, on the server,
    on the desktop, on mobile devices, and even on embedded devices. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| JavaScript无处不在。| JavaScript在浏览器、服务器、桌面、移动设备，甚至嵌入式设备上都有。|'
- en: '| JavaScript is easy to learn. | JavaScript is renowned for being easy to get
    started with. Perhaps it’s hard to master, but that’s also true of any programming
    language. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| JavaScript易于学习。| JavaScript因其易于入门而闻名。也许它难以精通，但这同样适用于任何编程语言。|'
- en: '| JavaScript programmers are easy to find. | In case you need to hire someone,
    JavaScript programmers are everywhere. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| JavaScript程序员容易找到。| 如果你需要雇佣某人，JavaScript程序员无处不在。|'
- en: '| JavaScript is evolving. | The language continues to get safer, more reliable,
    and more convenient. It’s refined with each successive version of the ECMAScript
    standard. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| JavaScript正在发展。| 语言继续变得更加安全、更可靠、更方便。它随着ECMAScript标准的每一版更新而得到改进。|'
- en: '| JavaScript and JSON go hand in hand. | The JSON data format, the data format
    of the web, evolved from JavaScript. JavaScript has built-in tools for working
    with JSON as do many third-party tools and libraries. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| JavaScript和JSON密不可分。| JSON数据格式，即网络数据格式，是从JavaScript演变而来的。JavaScript内置了处理JSON的工具，许多第三方工具和库也是如此。|'
- en: 1.6 Is JavaScript appropriate for data analysis?
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.6 JavaScript适合数据分析吗？
- en: We have no reason to single out JavaScript as a language that’s *not* suited
    to data analysis. The best argument against JavaScript is that languages such
    as Python or R, let’s say, have more *experience* behind them. By this, I mean
    they’ve built up a reputation and an ecosystem for this kind of work. JavaScript
    can get there as well, if that’s how you want to use JavaScript. It certainly
    is how I want to use JavaScript, and I think once data analysis in JavaScript
    takes off it will move quickly.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有理由单独将JavaScript视为不适合数据分析的语言。反对JavaScript的最好论点是，像Python或R这样的语言背后有更多的*经验*。我的意思是，它们已经为这种工作建立起了声誉和生态系统。如果这是你想要使用JavaScript的方式，JavaScript也可以达到那里。这确实是我想要使用JavaScript的方式，我认为一旦JavaScript数据分析起飞，它将迅速发展。
- en: I expect criticism against JavaScript for data analysis. One argument will be
    that JavaScript doesn’t have the performance. Similar to Python, JavaScript is
    an interpreted language, and both have restricted performance because of this.
    Python works around this with its well-known native C libraries that compensate
    for its performance issues. Let it be known that JavaScript has native libraries
    like this as well! And while JavaScript was never the most high-performance language
    in town, its performance has improved significantly thanks to the innovation and
    effort that went into the V8 engine and the Chrome browser.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我预计会对JavaScript在数据分析方面的批评。一个论点将是JavaScript没有性能。与Python类似，JavaScript是一种解释型语言，由于这个原因，两者都有受限的性能。Python通过其众所周知的原生C库来解决这个问题，这些库补偿了其性能问题。请知道，JavaScript也有类似的本地库！而且，尽管JavaScript从未是镇上最高性能的语言，但得益于V8引擎和Chrome浏览器的创新和努力，其性能已经显著提升。
- en: Another argument against JavaScript may be that it isn’t a high-quality language.
    The JavaScript language has design flaws (what language doesn’t?) and a checkered
    history. As JavaScript coders, you’ve learned to work around the problems it throws
    at us, and yet you’re still productive. Over time and through various revisions,
    the language continues to evolve, improve, and become a better language. These
    days I spend more time with *TypeScript* than JavaScript. This provides the benefits
    of *type safety* and *intellisense* when needed, on top of everything else to
    love about JavaScript.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 反对JavaScript的另一个论点可能是它不是一个高质量的语言。JavaScript语言有设计缺陷（哪种语言没有呢？）和复杂的历史。作为JavaScript程序员，你已经学会了如何绕过它向我们抛出的问题，而且你仍然很有效率。随着时间的推移和多次修订，该语言继续发展、改进，并成为一个更好的语言。如今，我花在*TypeScript*上的时间比JavaScript多。这提供了在需要时*类型安全*和*智能感知*的好处，以及其他所有关于JavaScript的喜爱之处。
- en: One major strength that Python has in its corner is the fantastic exploratory
    coding environment that’s now called Jupyter Notebook. Please be aware, though,
    that Jupyter now works with JavaScript! That’s right, you can do exploratory coding
    in Jupyter with JavaScript in much the same way professional data analysts use
    Jupyter and Python. It’s still early days for this . . . it does work, and you
    can use it, but the experience is not yet as complete and polished as you’d like
    it.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Python在它的角落里有一个主要优势，那就是现在被称为Jupyter Notebook的出色的探索性编码环境。请记住，Jupyter现在与JavaScript一起工作！没错，你可以在Jupyter中使用JavaScript进行探索性编码，与专业数据分析师使用Jupyter和Python的方式几乎一样。这还处于早期阶段……它确实可以工作，你可以使用它，但体验还没有达到你期望的完整和精致。
- en: Python and R have strong and established communities and ecosystems relating
    to data analysis. JavaScript also has a strong community and ecosystem, although
    it doesn’t yet have that strength in the area of data analysis. JavaScript *does*
    have a strong data visualization community and ecosystem. That’s a great start!
    It means that the output of data analysis often ends up being visualized in JavaScript
    anyway. Books on bridging Python to JavaScript attest to this, but working across
    languages in that way sounds inconvenient to me.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Python和R在数据分析方面拥有强大且成熟的社区和生态系统。JavaScript也有一个强大的社区和生态系统，尽管它还没有在数据分析领域达到那种强度。JavaScript确实有一个强大的数据可视化社区和生态系统。这是一个很好的开始！这意味着数据分析的输出通常最终会在JavaScript中可视化。关于连接Python和JavaScript的书籍证实了这一点，但以那种方式跨语言工作对我来说听起来不方便。
- en: JavaScript will never take away the role for Python and R for data analysis.
    They’re already well established for data analysis, and I don’t expect that JavaScript
    could ever overtake them. Indeed, it’s not my intention to turn people away from
    those languages. I would, however, like to show JavaScript programmers that it’s
    possible for them to do everything they need to do without leaving JavaScript.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript永远不会取代Python和R在数据分析中的角色。它们在数据分析方面已经非常成熟，我不认为JavaScript能够超越它们。实际上，我的意图也不是让人们远离这些语言。然而，我确实想向JavaScript程序员展示，他们可以在不离开JavaScript的情况下完成所有需要做的事情。
- en: 1.7 Navigating the JavaScript ecosystem
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.7 探索JavaScript生态系统
- en: The JavaScript ecosystem is huge and can be overwhelming for newcomers. Experienced
    JavaScript developers treat the ecosystem as part of their toolkit. Need to accomplish
    something? A package that does what you want on npm (node package manager) or
    Bower (client-side package manager) probably already exists.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript生态系统非常庞大，对于新手来说可能会令人不知所措。经验丰富的JavaScript开发者将生态系统视为他们工具箱的一部分。需要完成某事？在npm（node包管理器）或Bower（客户端包管理器）上可能已经存在一个能够完成你想要的工作的包。
- en: Did you find a package that almost does what you need, but not quite? Most packages
    are open source. Consider forking the package and making the changes you need.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否找到一个几乎能满足你需求但又不完全符合的包？大多数包都是开源的。考虑复制这个包并做出你需要的修改。
- en: Many JavaScript libraries will help you in your data wrangling. At the start
    of writing, npm listed 71 results for *data analysis*. This number has now grown
    to 115 as I near completion of this book. There might already be a library there
    that meets your needs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 许多JavaScript库将帮助你进行数据处理。在写作开始时，npm列出了71个关于*数据分析*的结果。随着这本书的接近完成，这个数字已经增长到115。可能已经有了一个满足你需求的库。
- en: You’ll find many tools and frameworks for visualization, building user interfaces,
    creating dashboards, and constructing applications. Popular libraries such as
    Backbone, React, and AngularJS come to mind. These are useful for building web
    apps. If you’re creating a build or automation script, you’ll probably want to
    look at Grunt, Gulp, or Task-Mule. Or search for *task runner* in npm and choose
    something that makes sense for you.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现许多用于可视化、构建用户界面、创建仪表板和构建应用的工具和框架。如Backbone、React和AngularJS这样的流行库，对于构建Web应用非常有用。如果你正在创建构建或自动化脚本，你可能想看看Grunt、Gulp或Task-Mule。或者，在npm中搜索*任务运行器*，选择对你有意义的工具。
- en: 1.8 Assembling your toolkit
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.8 组装你的工具箱
- en: As you learn to be data wranglers, you’ll assemble your toolkit. Every developer
    needs tools to do the job, and continuously upgrading your toolkit is a core theme
    of this book. My most important advice to any developer is to make sure that you
    have good tools and that you know how to use them. Your tools must be reliable,
    they must help you be productive, and you must understand how to use them well.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当你学习成为数据处理者时，你会组装你的工具箱。每个开发者都需要工具来完成工作，而不断升级你的工具箱是这本书的核心主题之一。我对任何开发者的最重要的建议是确保你有好的工具，并且你知道如何使用它们。你的工具必须是可靠的，它们必须帮助你提高生产力，你必须了解如何很好地使用它们。
- en: Although this book will introduce you to many new tools and techniques, we aren’t
    going to spend any time on fundamental development tools. I’ll take it for granted
    that you already have a text editor and a version control system and that you
    know how to use them.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这本书会介绍许多新的工具和技术，但我们不会在基本开发工具上花费任何时间。我会假设你已经有一个文本编辑器和版本控制系统，并且知道如何使用它们。
- en: For most of this book, you’ll use Node.js to develop code, although most of
    the code you write will also work in the browser, on a mobile (using Ionic), or
    on a desktop (using Electron). To follow along with the book, you should have
    Node.js installed. Packages and dependencies used in this book can be installed
    using npm, which comes with Node.js or with Bower that can be installed using
    npm. Please read chapter 2*for help coming up to speed with Node.js.*
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书的大部分内容中，你将使用Node.js来开发代码，尽管你写的绝大多数代码也可以在浏览器、移动设备（使用Ionic）或桌面（使用Electron）上运行。为了跟随这本书的内容，你应该已经安装了Node.js。这本书中使用的包和依赖项可以使用npm安装，npm是Node.js的一部分，或者使用npm安装的Bower。请阅读第2章*以了解如何快速掌握Node.js*。
- en: '*You likely already have a favorite testing framework. This book doesn’t cover
    automated unit or integration testing, but please be aware that I do this for
    my most important code, and I consider it an important part of my general coding
    practice. I currently use Mocha with Chai for JavaScript unit and integration
    testing, although there are other good testing frameworks available. The final
    chapter covers a testing technique that I call *output testing;* this is a simple
    and effective means of testing your code when you work with data.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*你可能已经有一个偏好的测试框架。本书不涵盖自动化的单元或集成测试，但请记住，我对我最重要的代码进行自动化测试，并将其视为我一般编码实践的重要组成部分。我目前使用Mocha与Chai进行JavaScript单元和集成测试，尽管还有其他好的测试框架可用。最后一章介绍了一种我称之为*输出测试*的测试技术；这是一种简单而有效的测试方法，当你与数据一起工作时，可以测试你的代码。'
- en: For any serious coding, you’ll already have a method of building and deploying
    your code. Technically JavaScript doesn’t need a build process, but it can be
    useful or necessary depending on your target environment; for example, I often
    work with TypeScript and use a build process to compile the code to JavaScript.
    If you’re deploying your code to a server in the cloud, you’ll most certainly
    want a provisioning and deployment script. Build and deployment aren’t a focus
    of this book, but we discuss them briefly in chapter 14\. Otherwise I’ll assume
    you already have a way to get your code into your target environment or that’s
    a problem you’ll solve later.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何严肃的编码工作，你已经有了一种构建和部署代码的方法。技术上JavaScript不需要构建过程，但根据你的目标环境，它可能是有用的或必要的；例如，我经常使用TypeScript，并使用构建过程将代码编译成JavaScript。如果你将代码部署到云服务器，你肯定需要一个配置和部署脚本。构建和部署不是本书的重点，但我们将在第14章中简要讨论它们。否则，我将假设你已经有一种方法将代码放入目标环境，或者这是一个你以后会解决的问题。
- en: Many useful libraries will help in your day-to-day coding. Underscore and Lodash
    come to mind. The ubiquitous *JQuery* seems to be going out of fashion at the
    moment, although it still contains many useful functions. For working with collections
    of data linq, a port of *Microsoft LINQ* from the C# language, is useful. My own
    Data-Forge library is a powerful tool for working with data. Moment.js is essential
    for working with date and time in JavaScript. Cheerio is a library for scraping
    data from HTML. There are numerous libraries for data visualization, including
    but not limited to D3, *Google Charts*, Highcharts, and Flot. Libraries that are
    useful for data analysis and statistics include jStat, Mathjs, and Formulajs.
    I’ll expand more on the various libraries through this book.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 许多有用的库将帮助你日常的编码工作。Underscore和Lodash会首先想到。无处不在的*JQuery*似乎正在过时，尽管它仍然包含许多有用的功能。对于处理数据集合，linq，从C#语言移植的*Microsoft
    LINQ*，非常有用。我自己的Data-Forge库是处理数据的有力工具。Moment.js是处理JavaScript中日期和时间的必备工具。Cheerio是一个从HTML中抓取数据的库。数据可视化方面有众多库，包括但不限于D3、*Google
    Charts*、Highcharts和Flot。对于数据分析和统计，有用的库包括jStat、Mathjs和Formulajs。我将在本书中详细介绍各种库。
- en: Asynchronous coding deserves a special mention. *Promises* are an expressive
    and cohesive way of managing your asynchronous coding, and I definitely think
    you should understand how to use them. Please see chapter 2 for an overview of
    asynchronous coding and promises.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 异步编码值得特别提及。*Promise*是管理异步编码的一种表达性和一致性的方式，我确实认为你应该了解如何使用它们。请参阅第2章以了解异步编码和Promise的概述。
- en: Most important for your work is having a good setup for exploratory coding.
    This process is important for inspecting, analyzing, and understanding your data.
    It’s often called *prototyping*. It’s the process of rapidly building up code
    step by step in an iterative fashion, starting from simple beginnings and building
    up to more complex code—a process we’ll use often throughout this book. While
    prototyping the code, we also delve deep into your data to understand its structure
    and shape. We’ll talk more about this in chapter 5.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你的工作来说，拥有一个良好的探索性编码环境是最重要的。这个过程对于检查、分析和理解你的数据非常重要。它通常被称为*原型设计*。这是一个快速构建代码的过程，逐步迭代，从简单的开始，逐步构建到更复杂的代码——我们将在整本书中经常使用这个过程。在原型设计代码的同时，我们也会深入挖掘你的数据，以理解其结构和形状。我们将在第5章中更多地讨论这一点。
- en: In the next section, we’ll talk about the data-wrangling process and flesh out
    a data pipeline that will help you understand how to fit together all the pieces
    of the puzzle.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论数据处理过程，并详细阐述一个数据管道，这将帮助你理解如何将拼图的各个部分组合在一起。
- en: 1.9 Establishing your data pipeline
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.9 建立你的数据处理流程
- en: The remainder of chapter 1 is an overview of the data-wrangling process. By
    the end you’ll cover an example of a data processing pipeline for a project. This
    is a whirlwind tour of data wrangling from start to end. Please note that this
    isn’t intended to be an example of a typical data-wrangling project—that would
    be difficult because they all have their own unique aspects. I want to give you
    a taste of what’s involved and what you’ll learn from this book.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章的其余部分是对数据整理过程的概述。到那时，你将涵盖一个项目的数据处理流程的示例。这是一次从开始到结束的数据整理快速浏览。请注意，这并不是一个典型数据整理项目的示例——那将是困难的，因为它们都有自己独特的方面。我想要给你一个关于涉及的内容以及你将从这个书中学到的内容的味觉。
- en: You have no code examples yet; there’s plenty of time for that through the rest
    of the book, which is full of working code examples that you can try for yourself.
    Here we seek to understand an example of the data-wrangling process and set the
    stage for the rest of the book. Later I’ll explain each aspect of data wrangling
    in more depth.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你目前还没有代码示例；在本书的其余部分还有很多时间来学习这些，书中充满了你可以亲自尝试的工作代码示例。在这里，我们旨在理解数据整理过程的示例，并为本书的其余部分奠定基础。稍后我会更深入地解释数据整理的各个方面。
- en: 1.9.1 Setting the stage
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.1 奠定基础
- en: I’ve been kindly granted permission to use an interesting data set. For various
    examples in the book, we’ll use data from “XL Catlin Global Reef Record.” We must
    thank the University of Queensland for allowing access to this data. I have no
    connection with the Global Reef Record project besides an interest in using the
    data for examples in this book.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我得到了使用一个有趣数据集的许可。在本书的各个示例中，我们将使用“XL Catlin全球珊瑚礁记录”的数据。我们必须感谢昆士兰大学允许访问这些数据。我与全球珊瑚礁记录项目没有其他联系，除了对在本书的示例中使用这些数据感兴趣之外。
- en: The reef data was collected by divers in survey teams on reefs around the world.
    As the divers move along their *survey* route (called a *transect* in the data),
    their cameras automatically take photos and their sensors take readings (see [figure
    1.2](#figure1.2)). The reef and its health are being mapped out through this data.
    In the future, the data collection process will begin again and allow scientists
    to compare the health of reefs between then and now.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 珊瑚礁数据是由世界各地的珊瑚礁调查团队的潜水员收集的。随着潜水员沿着他们的*调查*路线（在数据中称为*横断面*）移动，他们的相机会自动拍照，他们的传感器会读取数据（见[图1.2](#figure1.2)）。通过这些数据，珊瑚礁及其健康状况正在被绘制出来。在未来，数据收集过程将再次开始，并允许科学家比较那时和现在的珊瑚礁健康状况。
- en: '![c01_02.tif](Images/c01_02.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![c01_02.tif](Images/c01_02.png)'
- en: '[Figure 1.2](#figureanchor1.2) Divers taking measurements on the reef.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.2](#figureanchor1.2) 潜水员在珊瑚礁上测量数据。'
- en: © The Ocean Agency / XL Catlin Seaview Survey / Christophe Bailhache and Jayne
    Jenkins.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: © 海洋机构 / XL Catlin Seaview Survey / 克里斯托夫·巴伊哈切和杰恩·詹金斯。
- en: The reef data set makes for a compelling sample project. It contains time-related
    data, geo-located data, data acquired by underwater sensors, photographs, and
    then data generated from images by machine learning. This is a large data set,
    and for this project I extract and process the parts of it that I need to create
    a dashboard with visualizations of the data. For more information on the reef
    survey project, please watch the video at [https://www.youtube.com/watch?v=LBmrBOVMm5Q](https://www.youtube.com/watch?v=LBmrBOVMm5Q)[.](http://.)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 珊瑚礁数据集是一个引人入胜的样本项目。它包含与时间相关的数据、地理定位数据、水下传感器获取的数据、照片，以及由机器学习从图像生成数据。这是一个大型数据集，对于这个项目，我提取并处理了其中我需要用来创建数据可视化仪表板的部分。有关珊瑚礁调查项目的更多信息，请观看[https://www.youtube.com/watch?v=LBmrBOVMm5Q](https://www.youtube.com/watch?v=LBmrBOVMm5Q)视频[.](http://.)
- en: I needed to build a dashboard with tables, maps, and graphs to visualize and
    explore the reef data. Together we’ll work through an overview of this process,
    and I’ll explain it from beginning to end, starting with capturing the data from
    the original MySQL database, processing that data, and culminating in a web dashboard
    to display the data. In this chapter, we take a bird’s-eye view and don’t dive
    into detail; however, in later chapters we’ll expand on various aspects of the
    process presented here.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要构建一个包含表格、地图和图表的仪表板来可视化和探索珊瑚礁数据。我们将一起完成这个过程的大致概述，我会从开始到结束解释整个过程，从从原始MySQL数据库中捕获数据，处理这些数据，最终到创建一个显示数据的网络仪表板。在本章中，我们采取的是鸟瞰视角，并没有深入细节；然而，在后面的章节中，我们将扩展这里展示的过程的各个方面。
- en: Initially I was given a sample of the reef data in CSV (comma-separated value)
    files. I explored the CSV for an initial understanding of the data set. Later
    I was given access to the full MySQL database. The aim was to bring this data
    into a production system. I needed to organize and process the data for use in
    a real web application with an operational REST API that feeds data to the dashboard.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 初始时，我得到了一些珊瑚数据的 CSV（逗号分隔值）文件样本。我探索了 CSV 文件，以对数据集有一个初步的了解。后来，我获得了访问完整 MySQL 数据库的权限。目标是把数据带入生产系统。我需要组织和处理数据，以便在具有操作性的
    REST API 的实际网络应用程序中使用，该 API 为仪表板提供数据。
- en: 1.9.2 The data-wrangling process
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.2 数据处理过程
- en: 'Let’s examine the data-wrangling process: it’s composed of a series of phases
    as shown in [figure 1.3](#figure1.3). Through this process you acquire your data,
    explore it, understand it, and visualize it. We finish with the data in a production-ready
    format, such as a web visualization or a report.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看数据处理过程：它由一系列阶段组成，如图 [图 1.3](#figure1.3) 所示。通过这个过程，你获取数据，探索它，理解它，并可视化它。我们最终以一个生产就绪的格式完成数据，例如网络可视化或报告。
- en: '[Figure 1.3](#figure1.3) gives us the notion that this is a straightforward
    and linear process, but if you have previous experience in software development,
    you’ll probably smell a rat here. Software development is rarely this straightforward,
    and the phases aren’t usually cleanly separated, so don’t be too concerned about
    the order of the phases presented here. I have to present them in an order that
    makes sense, and a linear order is a useful structure for the book. In chapter
    5 you’ll move beyond the linear model of software development and look at an iterative
    *exploratory* model.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1.3](#figure1.3) 给我们一个直观且线性的过程的印象，但如果你有软件开发的经验，你可能会在这里嗅到一些问题。软件开发很少这么直接，阶段通常不会完全分开，所以不要过于担心这里展示的阶段顺序。我必须以一个有意义的顺序来展示它们，线性顺序对于本书来说是一个有用的结构。在第
    5 章中，你将超越软件开发的线性模型，并查看一个迭代的**探索性**模型。'
- en: '![c01_03.eps](Images/c01_03.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![c01_03.eps](Images/c01_03.png)'
- en: '[Figure 1.3](#figureanchor1.3) The data-wrangling process'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1.3](#figureanchor1.3) 数据处理过程'
- en: As you work through the process in this chapter, please consider that this isn’t
    *the process*; rather this is an example of what the data-wrangling process looks
    like for a particular project. How the process manifests itself will be different
    depending on your data and requirements. When you embark on other projects, your
    own process will undoubtably look different than what I describe in this chapter.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在你阅读本章内容并逐步完成这个过程时，请记住这**不是**一个标准的过程；相反，这是一个特定项目数据处理过程的一个示例。这个过程的具体表现将根据你的数据和需求而有所不同。当你开始其他项目时，你自己的过程无疑会与我在本章中描述的不同。
- en: 1.9.3 Planning
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.3 规划
- en: Before getting into data wrangling, or any project for that matter, you should
    understand what you’re doing. What are your requirements? What and how are you
    going to build your software? What problems are likely to come up, and how will
    you deal with them? What does your data look like? What questions should you ask
    of the data? These are the kinds of questions you should ask yourself when planning
    a new project.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始数据处理或任何项目之前，你应该了解你在做什么。你的需求是什么？你将如何构建你的软件？可能遇到哪些问题，你将如何处理它们？你的数据是什么样的？你应该对数据提出哪些问题？当你规划一个新项目时，你应该问自己这些问题。
- en: When you’re doing any sort of software development, it’s important to start
    with planning. The biggest problem I see in many programmers is their failure
    to think and plan out their work before coding. In my experience, one of the best
    ways to improve as a coder is to become better at planning.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当你进行任何形式的软件开发时，从规划开始是很重要的。我看到的许多程序员的最大问题是他们在编码之前没有思考和规划他们的工作。根据我的经验，提高编码能力的一个最好方法是提高规划能力。
- en: Why? Because planning leads to better outcomes through better implementation
    and fewer mistakes. But you must be careful not to *over* plan! Planning for a
    future that’s unlikely to happen leads to overengineering.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么？因为规划通过更好的实施和更少的错误导致更好的结果。但你必须小心不要**过度**规划！为不太可能发生的情况规划会导致过度设计。
- en: You might need to do *exploratory coding* before you can plan! This is an example
    of the phases not being cleanly separated. If you don’t have enough information
    to plan, then move forward with exploratory coding and return to planning when
    you have a better understanding of the problem you’re trying to solve.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在你能够规划之前，可能需要先进行*探索性编码*！这是一个阶段划分不够清晰的例子。如果你没有足够的信息来规划，那么就先进行探索性编码，并在对你要解决的问题有更好的理解后返回规划阶段。
- en: '![c01_04.png](Images/c01_04.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![c01_04.png](Images/c01_04.png)'
- en: '[Figure 1.4](#figureanchor1.4) The feedback loop'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.4](#figureanchor1.4) 反馈循环'
- en: Planning is an important part of an effective feedback loop (see [figure 1.4](#figure1.4)).
    Planning involves working through the mistakes that will likely happen and figuring
    out how to avoid those mistakes. Avoiding mistakes saves you much time and anguish.
    Each trip around the feedback loop is a valuable experience, improving your understanding
    of the project and your ability to plan and execute.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 规划是有效反馈循环的重要组成部分（请参阅[图1.4](#figureanchor1.4)）。规划涉及处理可能发生的错误，并找出如何避免这些错误。避免错误可以节省你大量的时间和痛苦。每次绕过反馈循环都是一次宝贵的学习经历，它提高了你对项目的理解，以及你规划和执行的能力。
- en: 'To plan this project, let’s note several requirements for the end product:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了规划这个项目，让我们记录几个最终产品的需求：
- en: Create a web dashboard to provide easy browsing of the reef data.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个网络仪表板，以方便浏览珊瑚礁数据。
- en: Summarize reefs and surveys completed through tables, charts, and maps.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过表格、图表和地图总结珊瑚礁和完成的调查。
- en: 'Requirements usually change over time as you develop your understanding of
    the project. Don’t be concerned if this happens. Changing requirements is natural,
    but be careful: it can also be symptomatic of poor planning or scope creep.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你对项目理解的加深，需求通常会发生变化。如果发生这种情况，请不要担心。需求的变化是自然的，但请注意：它也可能是规划不当或范围蔓延的迹象。
- en: At this stage, I plan the structure of the website, as shown in the [figure
    1.5](#figure1.5).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我规划网站的架构，如图[图1.5](#figure1.5)所示。
- en: '![c01_05.png](Images/c01_05.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![c01_05.png](Images/c01_05.png)'
- en: '[Figure 1.5](#figureanchor1.5) Dashboard website structure'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.5](#figureanchor1.5) 仪表板网站结构'
- en: 'Simple wireframe mockups can help us solidify the plan. [Figure 1.6](#figure1.6)
    is an example. During planning, you need to think of the problems that might arise.
    This will help you to preemptively plan solutions to those problems, but please
    make sure your approach is balanced. If you believe a problem has little chance
    of arising, you should spend little effort mitigating against it. For example,
    here are several of the problems that I might encounter while working with the
    reef data set and building the dashboard:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的线框草图可以帮助我们巩固计划。[图1.6](#figure1.6)是一个例子。在规划过程中，你需要考虑可能出现的各种问题。这将帮助你预先规划解决方案，但请确保你的方法平衡。如果你认为某个问题出现的可能性很小，你应该投入很少的努力来减轻它的影响。例如，以下是我可能在处理珊瑚礁数据集和构建仪表板时遇到的一些问题：
- en: '![c01_06.eps](Images/c01_06.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![c01_06.eps](Images/c01_06.png)'
- en: '[Figure 1.6](#figureanchor1.6) Dashboard page mockup'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.6](#figureanchor1.6) 仪表板页面草图'
- en: Due to its size, several of the tables contain more than a million records.
    It might take a long time to copy the MySQL database, although it can run for
    as many hours as we need it to. I have little need to optimize this process because
    it happens only once, so it isn’t time critical.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于其规模，其中一些表格包含超过一百万条记录。复制MySQL数据库可能需要很长时间，尽管它可以运行我们需要的任何小时数。我优化这个过程的必要性很小，因为它只发生一次，所以不是时间敏感的。
- en: There will likely be problems with the data that need to be cleaned up, but
    I won’t know about those until I explore the data set (see chapter 6 for data
    cleanup and preparation).
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中可能存在需要清理的问题，但我在探索数据集之前不会知道（请参阅第6章关于数据清理和准备的内容）。
- en: If the visualizations in the dashboard are slow to load or sluggish in performance,
    you can prebake the data into an optimized format (see chapters 6 and 7 for more
    on this).
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果仪表板中的可视化加载缓慢或性能不佳，你可以预先将数据烘焙成优化的格式（有关更多信息，请参阅第6章和第7章）。
- en: 'Of primary importance in the planning phase is to have an idea of what you
    want from the data. Ask yourself the following questions: What do you need to
    know from the data? What questions are you asking of the data?'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划阶段，最重要的是对数据想要得到的结果有一个概念。问自己以下问题：你需要从数据中了解什么？你在向数据提出什么问题？
- en: 'For your example, here are several of the questions to ask of the reef data:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你的示例，以下是一些对珊瑚礁数据提出的问题：
- en: What’s the average temperature per reef in Australia reefs that were surveyed?
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 澳大利亚被调查的珊瑚礁的平均温度是多少？
- en: What’s the total coverage (distance traversed) for each reef?
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个珊瑚礁的总覆盖面积（穿越的距离）是多少？
- en: What’s the average dive depth per reef?
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个珊瑚礁的平均潜水深度是多少？
- en: Often, despite planning, you may find that things don’t go according to plan.
    When this happens, take a break and take time to reassess the situation. When
    necessary, come back to planning and work through it again. Return to planning
    at any time when things go wrong or if you need confirmation that you’re on the
    right track.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，尽管有计划，你可能会发现事情并不按计划进行。当这种情况发生时，请休息一下，花时间重新评估情况。必要时，回到计划并再次工作。当事情出错或你需要确认自己是否走在正确的道路上时，随时回到计划。
- en: 1.9.4 Acquisition, storage, and retrieval
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.4 数据获取、存储和检索
- en: In this phase, you capture the data and store it in an appropriate format. You
    need the data stored in a format where you can conveniently and effectively query
    and retrieve it.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你捕获数据并将其存储在适当的格式中。你需要将数据存储在一个你可以方便和有效地查询和检索的格式中。
- en: Data acquisition started with a sample CSV file that was emailed from the University
    of Queensland. I did a *mini exploration* of the sample data to get a feel for
    it. The sample data was small enough that I could load it in Excel.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 数据获取始于从昆士兰大学发送的一个样本CSV文件。我对样本数据进行了*小规模探索*，以了解其感觉。样本数据足够小，以至于我可以将其加载到Excel中。
- en: I needed to get an idea of what I was dealing with before writing any code.
    When looking at the full data set, I used a SQL database viewer called HeidiSQL
    ([figure 1.7](#figure1.7)) to connect to the remote database, explore the data,
    and develop understanding of it.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写任何代码之前，我需要先了解我要处理的内容。当查看完整的数据集时，我使用了一个名为HeidiSQL的SQL数据库查看器（[图1.7](#figure1.7)）来连接远程数据库，探索数据，并对其形成理解。
- en: '![c01_07.tif](Images/c01_07.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![c01_07.tif](Images/c01_07.png)'
- en: '[Figure 1.7](#figureanchor1.7) Inspecting an SQL table in HeidiSQL'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.7](#figureanchor1.7) 在HeidiSQL中检查SQL表'
- en: Due to slow internet speeds, remote data access wasn’t going to work well for
    exploratory coding. I needed to download the data to a local database for efficient
    access. I also wanted the data locally so that I could make changes to it as needed,
    and I couldn’t make changes to a database that I didn’t own. I planned to copy
    the data down to a local MongoDB database ([figure 1.8](#figure1.8)).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 由于网络速度慢，远程数据访问对于探索性编码来说不会很有效。我需要将数据下载到本地数据库以实现高效访问。我还希望数据在本地，这样我就可以根据需要对其进行更改，并且我无法更改我不拥有的数据库。我计划将数据复制到本地的MongoDB数据库中（[图1.8](#figure1.8)）。
- en: '![c01_08.png](Images/c01_08.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![c01_08.png](Images/c01_08.png)'
- en: '[Figure 1.8](#figureanchor1.8) Pulling the data from SQL to MongoDB'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.8](#figureanchor1.8) 从SQL到MongoDB的数据提取'
- en: 'You might wonder why I chose MongoDB? Well, the choice is somewhat arbitrary.
    You need to choose a database that works well for you and your project. I like
    MongoDB for several reasons:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道我为什么选择MongoDB？好吧，选择是有些随机的。你需要选择一个适合你和你项目的数据库。我喜欢MongoDB的几个原因：
- en: It’s simple to install.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装很简单。
- en: It works well with JavaScript and JSON.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它与JavaScript和JSON配合得很好。
- en: It’s easy to store and retrieve data.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储和检索数据都很简单。
- en: The query language is built into the programming language.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询语言内置在编程语言中。
- en: Ad hoc or irregular data can be stored.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以存储临时或非规则数据。
- en: It has good performance.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的性能很好。
- en: 'If you’re concerned that moving the data from SQL to MongoDB will cause the
    data to lose structure, please don’t be: MongoDB can store structured and relational
    data just as well as SQL. They’re different, and MongoDB doesn’t have the convenience
    of SQL *joins* and it doesn’t *enforce* structure or relationships—but these are
    features that you can easily emulate in your own code.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你担心将数据从SQL迁移到MongoDB会导致数据结构丢失，请不要担心：MongoDB可以像SQL一样存储结构化和关系型数据。它们是不同的，MongoDB没有SQL
    *连接*的便利性，它也不*强制*结构或关系——但这些是你可以轻松在自己的代码中模拟的功能。
- en: Something else that’s important with MongoDB is that there’s no need to predefine
    a schema. You don’t have to commit to the final shape of your data! That’s great
    because I don’t yet know the final shape of my data. Not using a schema reduces
    the burden of designing your data, and it allows you to more easily evolve your
    data as you come to understand your project better.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 与MongoDB相关的重要事情之一是，你不需要预先定义模式。你不必承诺数据的最终形状！这很好，因为我还不知道数据的最终形状。不使用模式可以减轻设计数据的工作负担，并允许你随着对项目理解的加深更容易地演进数据。
- en: You’ll learn more about SQL, MongoDB, and other data sources in chapter 3.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在第 3 章中了解更多关于 SQL、MongoDB 和其他数据源的信息。
- en: At this point it’s time to start coding. I must write a script to copy from
    the SQL database to MongoDB. I start by using nodejs-mysql to load a MySQL table
    into memory from the remote database. With large databases, this isn’t realistic,
    but it did work on this occasion. In chapters 8 and 9, we’ll talk about working
    with data sets that are too large to fit into memory.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，是时候开始编码了。我必须编写一个脚本，从 SQL 数据库复制到 MongoDB。我开始使用 nodejs-mysql 从远程数据库将 MySQL
    表加载到内存中。对于大型数据库来说，这并不现实，但这次它确实有效。在第 8 章和第 9 章中，我们将讨论处理无法装入内存的数据集。
- en: With the SQL table loaded into memory, you now use the MongoDB API to insert
    the data into our local MongoDB database instance ([figure 1.9](#figure1.9)).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在将 SQL 表加载到内存后，你现在使用 MongoDB API 将数据插入到我们本地的 MongoDB 数据库实例中（[图 1.9](#figureanchor1.9)）。
- en: Now I can assemble the code I have so far, and I have a Node.js script that
    can replicate a MySQL table to MongoDB. I can now easily scale this up and have
    a script that can replicate the entire MySQL database to our local MongoDB instance.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我可以组装到目前为止的代码，我有一个 Node.js 脚本可以复制 MySQL 表到 MongoDB。我现在可以轻松地将其扩展，并有一个可以复制整个
    MySQL 数据库到我们本地 MongoDB 实例的脚本。
- en: How much data am I pulling down and how long will it take? Note here that I’m
    not yet processing the data or transforming it in any way. That comes later when
    I have a local database and a better understanding of the data.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我要下载多少数据？需要多长时间？注意，我目前还没有处理数据或以任何方式转换数据。那是在我有了本地数据库并对数据有了更好的理解之后的事情。
- en: It took many hours to replicate this database, and that’s with a lousy internet
    connection. Long-running processes like this that depend on fragile external resources
    should be designed to be fault-tolerant and restartable. We’ll touch on these
    points again in chapter 14\. The important thing, though, is that most of the
    time the script was doing its work without intervention, and it didn’t *cost*
    much of my own time. I’m happy to wait for this process to complete because having
    a local copy of the data makes all future interactions with it more efficient.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 复制这个数据库花费了很多小时，而且是在糟糕的网络连接下。像这样依赖于脆弱的外部资源的长时间运行的过程应该设计成容错和可重启的。我们将在第 14 章再次讨论这些点。不过，重要的是，大多数时候脚本都在没有干预的情况下完成其工作，而且并没有占用我太多的时间。我很乐意等待这个过程完成，因为拥有数据的本地副本使得所有未来的交互都更加高效。
- en: '![c01_09.eps](Images/c01_09.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![c01_09.eps](Images/c01_09.png)'
- en: '[Figure 1.9](#figureanchor1.9) Downloading an SQL database table with a Node.js
    script'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1.9](#figureanchor1.9) 使用 Node.js 脚本下载 SQL 数据库表'
- en: Now that I have a local copy of the database, we are almost ready to begin a
    more complete exploration of the data. First, though, I must retrieve the data.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经有了数据库的本地副本，我们几乎准备好开始更全面地探索数据了。不过，首先我必须检索数据。
- en: I use the MongoDB API to query the local database. Unlike SQL, the MongoDB query
    language is integrated into JavaScript (or other languages, depending on your
    language of choice).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用 MongoDB API 来查询本地数据库。与 SQL 不同，MongoDB 查询语言集成到 JavaScript（或根据你选择的语言的其他语言）中。
- en: In this case, you can get away with a basic query, but you can do so much more
    with a MongoDB query, including
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你可以用一个基本的查询来应付，但你可以用 MongoDB 查询做更多的事情，包括
- en: Filtering records
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤记录
- en: Filtering data returned for each record
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤每个记录返回的数据
- en: Sorting records
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 排序记录
- en: Skipping and limiting records to view a reduced *window* of the data
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 跳过和限制记录以查看数据的简化 *窗口*
- en: This is one way to acquire data, but many other ways exist. Many different data
    formats and data storage solutions can be used. You’ll dive into details on MongoDB
    in chapter 8.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种获取数据的方式，但还有许多其他方式。可以使用许多不同的数据格式和数据存储解决方案。你将在第 8 章深入了解 MongoDB。
- en: 1.9.5 Exploratory coding
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.5 探索性编码
- en: In this phase, you use code to deeply explore your data and build your understanding
    of it. With a better understanding, you can start to make assumptions about the
    structure and consistency of the data. Assumptions must be checked, but you can
    do that easily with code!
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你使用代码来深入探索你的数据，并建立对它的理解。有了更好的理解，你可以开始对数据的结构和一致性做出假设。假设必须得到验证，但你可以用代码轻松地做到这一点！
- en: We write code to poke, prod, and tease the data. We call this *exploratory coding*
    (also often called *prototyping*), and it helps us get to know our data while
    producing potentially useful code.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编写代码来探索、检查和挑逗数据。我们称之为*探索性编码*（也常被称为*原型设计*），这有助于我们在编写可能有用的代码的同时了解我们的数据。
- en: It’s important to work with a smaller subset of data at this point. Attempting
    to work with the entire data set can be inefficient and counterproductive, although
    of course it depends on the size of your particular data set.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，与数据的一个较小子集一起工作是很重要的。尝试处理整个数据集可能既低效又适得其反，尽管当然这取决于你特定数据集的大小。
- en: Exploratory coding is the process of incrementally building your code through
    an iterative and interactive process ([figure 1.10](#figure1.10)). Code a few
    lines, then run the code and inspect the output, repeat. Repeating this process
    builds up your code and understanding at the same time.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 探索性编码是通过迭代和交互过程逐步构建你的代码的过程（[图 1.10](#figure1.10)）。编写几行代码，然后运行代码并检查输出，重复此过程。重复此过程同时构建你的代码和理解。
- en: '![c01_10.eps](Images/c01_10.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![c01_10.eps](Images/c01_10.png)'
- en: '[Figure 1.10](#figureanchor1.10) Exploratory coding process'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1.10](#figureanchor1.10) 探索性编码过程'
- en: The simplest way to start looking at the data is to use a database viewer. I
    already used HeidiSQL to look at the SQL database. Now I use Robomongo (recently
    renamed to Robo 3T) to look at the contents of my local MongoDB database ([figure
    1.11](#figure1.11)).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 开始查看数据的最简单方式是使用数据库查看器。我已经使用 HeidiSQL 来查看 SQL 数据库。现在我用 Robomongo（最近更名为 Robo 3T）来查看我的本地
    MongoDB 数据库的内容（[图 1.11](#figure1.11)）。
- en: '![c01_11.eps](Images/c01_11.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![c01_11.eps](Images/c01_11.png)'
- en: '[Figure 1.11](#figureanchor1.11) Looking at the transects collection in Robomongo'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1.11](#figureanchor1.11) 在 Robomongo 中查看横断面集合'
- en: 'Using code, I explore the data, looking at the first and last records and the
    data types they contain. I print the first few records to the console and see
    the following:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 使用代码，我探索数据，查看第一条和最后一条记录以及它们包含的数据类型。我将前几条记录打印到控制台，看到以下内容：
- en: '[PRE0]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'From looking at the data, I’m getting a feel for the shape of it and can ask
    the following questions: What columns do I have? How many records am I dealing
    with? Again, using code, I analyze the data and print the answers to the console:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看数据，我正在了解其形状，并可以提出以下问题：我有哪些列？我正在处理多少条记录？再次使用代码，我分析数据并将答案打印到控制台：
- en: '[PRE1]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'With the help of my open source data-wrangling toolkit Data-Forge, I can understand
    the types of data and the frequency of the values. I print the results to the
    console and learn even more about my data:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的开源数据处理工具包 Data-Forge 的帮助下，我可以了解数据的类型和值的频率。我将结果打印到控制台，并进一步了解我的数据：
- en: '[PRE2]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You’ll learn more about using Data-Forge and what it can do throughout the book,
    especially in chapter 9.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在整本书中了解更多关于使用 Data-Forge 以及它能做什么的信息，尤其是在第 9 章中。
- en: Now that I have a basic understanding of the data, I can start to lay out our
    assumptions about it. Is each column expected to have only a certain type of data?
    Is the data consistent?
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我对数据有了基本的了解，我可以开始列出我们对它的假设。每一列是否预期只包含某种类型的数据？数据是否一致？
- en: Well, I can’t know this yet. I’m working with a large data set, and I haven’t
    yet looked at every single record. In fact, I can’t manually inspect each record
    because I have too many! However, I can easily use code to test my assumptions.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，我目前还不知道这个。我正在处理一个大数据集，我还没有查看每一条记录。实际上，我无法手动检查每一条记录，因为我有太多记录了！然而，我可以轻松地使用代码来测试我的假设。
- en: I write an *assumption checking* script that will verify my assumptions about
    the data. This is a Node.js script that inspects each record in the database and
    checks that each field contains values with the same types that we expect. You’ll
    look at code examples for assumption checking in chapter 5.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我编写了一个*假设检查*脚本，该脚本将验证我对数据的假设。这是一个检查数据库中每条记录并检查每个字段是否包含我们预期的相同类型值的 Node.js 脚本。你将在第
    5 章中看到假设检查的代码示例。
- en: Data can sometimes be frustratingly inconsistent. Problems can easily hide for
    a long time in large data sets. My assumption checking script gives me peace of
    mind and reduces the likelihood that I’ll later be taken by surprise by nasty
    issues in the data.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 数据有时可能令人沮丧地不一致。问题可能在大数据集中长时间隐藏。我的假设检查脚本让我安心，并减少了我在数据中遇到意外问题的可能性。
- en: Running the assumption checking script shows that my assumptions about the data
    don’t bear out. I find that I have unexpected values in the dive_temperature field
    that I can now find on closer inspection in Robomongo ([figure 1.12](#figure1.12)).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 运行假设检查脚本显示，我对数据的假设并不成立。我发现我在dive_temperature字段中有意外值，现在可以在Robomongo中更仔细地检查（[图1.12](#figureanchor1.12)）。
- en: Why is the data broken? That’s hard to say. Maybe several of the sensors were
    faulty or working intermittently. It can be difficult to understand why faulty
    data comes into your system the way it does.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 数据为什么损坏？这很难说。也许有几个传感器故障或间歇性工作。理解为什么错误数据以这种方式进入您的系统可能很困难。
- en: '![c01_12.png](Images/c01_12.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![c01_12.png](Images/c01_12.png)'
- en: '[Figure 1.12](#figureanchor1.12) Inspecting bad temperature values in Robomongo'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.12](#figureanchor1.12) 在Robomongo中检查不良温度值'
- en: What if the data doesn’t meet expectations? Then we have to rectify the data
    or adapt our workflow to fit, so next we move on to data cleanup and preparation.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据不符合预期怎么办？那么我们必须纠正数据或调整我们的工作流程以适应，因此接下来我们转向数据清理和准备。
- en: You’ve finished this section, but you haven’t yet finished your exploratory
    coding. You can continue exploratory coding throughout all phases of data wrangling.
    Whenever you need to try something new with the data, test an idea, or test code,
    you can return to exploratory coding to iterate and experiment. You’ll spend a
    whole chapter on exploratory coding in chapter 5.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经完成了这一部分，但您还没有完成您的探索性编码。您可以在数据整理的所有阶段继续探索性编码。无论何时您需要尝试对数据进行新的操作，测试一个想法或测试代码，您都可以回到探索性编码以迭代和实验。您将在第5章中花费整整一章来探讨探索性编码。
- en: 1.9.6 Clean and prepare
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.6 清洁和准备
- en: Did your data come in the format you expected? Is your data fit for production
    usage? In the *clean and prepare* phase, you rectify issues with the data and
    make it easier to deal with downstream. You can also normalize it and restructure
    it for more efficient use in production.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据是否以您预期的格式到来？您的数据是否适合生产使用？在*清洁和准备*阶段，您将解决数据中的问题，使其更容易处理。您还可以对其进行标准化和重构，以便在生产中更有效地使用。
- en: The data you receive might come in any format! It might contain any number of
    problems. It doesn’t matter; you still have to deal with it. The assumption checking
    script has already found that the data isn’t willing to conform to my expectations!
    I have work to do now to clean up the data to make it match my desired format.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 您收到的数据可能以任何格式到来！它可能包含任何数量的问题。这无关紧要；您仍然必须处理它。假设检查脚本已经发现数据不愿意符合我的预期！我现在必须清理数据，使其符合我期望的格式。
- en: I know that my data contains invalid temperature values. I could remove records
    with invalid temperatures from my database, but then I’d lose other useful data.
    Instead, I’ll work around this problem later, filtering out records with invalid
    temperatures as needed.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道我的数据包含无效的温度值。我可以从数据库中删除包含无效温度的记录，但这样我会丢失其他有用的数据。相反，我将在稍后解决这个问题，根据需要过滤掉包含无效温度的记录。
- en: 'For the sake of an example, let’s look at a different problem: the date/time
    fields in the `surveys` collection. You can see that this field is stored as a
    string rather than a JavaScript date/time object ([figure 1.13](#figure1.13)).'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明，让我们看看另一个问题：`surveys`集合中的日期/时间字段。您可以看到该字段存储为字符串，而不是JavaScript日期/时间对象（[图1.13](#figureanchor1.13)）。
- en: '![c01_13.png](Images/c01_13.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![c01_13.png](Images/c01_13.png)'
- en: '[Figure 1.13](#figureanchor1.13) Date/time fields in the surveys collection
    are string values.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.13](#figureanchor1.13) 调查集合中的日期/时间字段是字符串值。'
- en: With date/time fields stored as strings, this opens the possibility that they
    might be stored with inconsistent formats. In reality, my sample data is well
    structured in this regard, but let’s imagine for this example that several of
    the dates are stored with time zone information that assume an Australian time
    zone. This sort of thing can be an insidious and well-hidden problem; working
    with dates/times often has difficulties like this.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 日期/时间字段存储为字符串时，这可能导致它们以不一致的格式存储。实际上，我的样本数据在这方面结构良好，但让我们假设在这个例子中，有几个日期是以假设的澳大利亚时区的时间信息存储的。这类问题可能是一个隐蔽且难以发现的问题；处理日期/时间时经常遇到这样的困难。
- en: To fix this data, I write another Node.js script. For each record, it examines
    the fields and if necessary fixes the data. It must then save the repaired data
    back to the database. This kind of issue isn’t difficult to fix; it’s spotting
    the problem in the first place that’s the difficult part. But you might also stumble
    on other issues that aren’t so easy to fix, and fixing them could be time consuming.
    In many cases, it will be more efficient to deal with the bad data at runtime
    rather than trying to fix it offline.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了修复这些数据，我编写了另一个Node.js脚本。对于每条记录，它检查字段并在必要时修复数据。然后必须将修复后的数据保存回数据库。这类问题并不难修复；最难的是首先发现问题。但你也可能遇到其他不那么容易修复的问题，修复它们可能很耗时。在许多情况下，在运行时处理坏数据比尝试离线修复它更有效率。
- en: At this stage, you might also consider normalizing or standardizing your data
    to ensure that it’s in a suitable format for analysis, to simplify your downstream
    code, or for better performance. We’ll see more examples of data problems and
    fixes in chapter 6.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你也可能考虑对数据进行归一化或标准化，以确保它适合分析，简化下游代码，或提高性能。我们将在第6章中看到更多数据问题和解决方案的例子。
- en: 1.9.7 Analysis
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.7 分析
- en: In this phase, you analyze the data. You ask and answer specific questions about
    the data. It’s a further step in understanding the data and extrapolating meaningful
    insights from it.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你分析数据。你针对数据提出并回答具体的问题。这是理解数据并从中提取有意义的洞察的进一步步骤。
- en: Now that I have data that’s cleaned and prepared for use, it’s time to do analysis.
    I want to do much with the data. I want to understand the total distance traversed
    in each survey. I want to compute the average water temperature for each reef.
    I want to understand the average depth for each reef.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我有了清洗和准备好的数据，是时候进行分析了。我想从数据中获得很多信息。我想了解每次调查的总距离。我想计算每个珊瑚礁的平均水温。我想了解每个珊瑚礁的平均深度。
- en: 'I start by looking at the total distance traveled by divers for each reef.
    I need to aggregate and summarize the data. The aggregation takes the form of
    grouping by reef. The summarization comes in the form of summing the distance
    traveled for each reef. Here’s the result of this analysis:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我首先查看每个珊瑚礁潜水员的总行程距离。我需要聚合和总结数据。聚合的形式是按珊瑚礁分组。总结的形式是计算每个珊瑚礁的行程距离总和。这是这次分析的结果：
- en: '[PRE3]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The code for this can easily be extended. For example, I already have the data
    grouped by reef, so I’ll add average temperature per reef, and now I have both
    total distance and average temperature:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码可以很容易地扩展。例如，我已经根据珊瑚礁对数据进行分组，所以我将添加每个珊瑚礁的平均温度，现在我有总距离和平均温度：
- en: '[PRE4]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'With slight changes to the code I can ask similar questions, such as what’s
    the average temperature by country. This time, instead of grouping by reef, I
    group by country, which is a different way of looking at the data:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对代码的轻微修改，我可以提出类似的问题，比如平均温度按国家划分是多少。这次，我不再按珊瑚礁分组，而是按国家分组，这是看待数据的不同方式：
- en: '[PRE5]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This gives you a taste for data analysis, but stay tuned; you’ll spend more
    time on this and look at code examples in chapter 9.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这让你对数据分析有了初步的了解，但请保持关注；你将在第9章中花费更多时间，并查看代码示例。
- en: 1.9.8 Visualization
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.8 可视化
- en: Now you come to what’s arguably the most exciting phase. Here you visualize
    the data and bring it to life. This is the final phase in understanding your data.
    Rendering the data in a visual way can bring forth insights that were otherwise
    difficult to see.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你来到了可能最令人兴奋的阶段。在这里，你将数据可视化并使其生动起来。这是理解数据的最终阶段。以可视化的方式呈现数据可以揭示那些原本难以察觉的洞察。
- en: After you explore and analyze the data, it’s time to visualize it and understand
    it in a different light. Visualization completes your understanding of the data
    and allows you to easily see what might have otherwise remained hidden. You seek
    to expose any remaining problems in the data through visualization.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在你探索和分析数据之后，是时候以不同的视角可视化和理解它了。可视化完成了你对数据的理解，并允许你轻松地看到可能否则隐藏的东西。你希望通过可视化暴露数据中任何剩余的问题。
- en: For this section, I need a more complex infrastructure (see [figure 1.14](#figure1.14)).
    I need
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本节，我需要一个更复杂的基础设施（见[图1.14](#figure1.14)）。我需要
- en: A server
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务器
- en: A REST API to expose your data
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个REST API来暴露你的数据
- en: A simple web application to render the visualization
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个简单的Web应用程序来呈现可视化
- en: '![c01_14.eps](Images/c01_14.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![c01_14.eps](Images/c01_14.png)'
- en: '[Figure 1.14](#figureanchor1.14) Infrastructure for a web app with a chart'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.14](#figureanchor1.14) 带有图表的Web应用程序基础设施'
- en: I build a simple web server using Express.js. The web server hosts a REST API
    that exposes the reef data using HTTP GET. The REST API is the interface between
    the server and your web application ([figure 1.14](#figure1.14)).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用Express.js构建了一个简单的Web服务器。该Web服务器托管一个REST API，该API通过HTTP GET公开珊瑚礁数据。REST API是服务器和您的Web应用程序之间的接口（[图1.14](#figure1.14)）。
- en: Next, I create a simple web application that uses the REST API to retrieve the
    data in JSON format. My simple web app retrieves data from the database using
    the REST API, and I can put that data to work. I’m using C3 here to render a chart.
    I add the chart to the web page and use JavaScript to inject the data. We’ll learn
    more about C3 later in the book.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我创建了一个简单的Web应用程序，该程序使用REST API以JSON格式检索数据。我的简单Web应用程序使用REST API从数据库中检索数据，我可以将数据投入使用。我在这里使用C3来渲染图表。我将图表添加到网页上，并使用JavaScript注入数据。本书稍后我们将了解更多关于C3的信息。
- en: But I have a big problem with the first iteration of the chart. It displays
    the temperature for each survey, but there’s too much data to be represented in
    a bar chart. And this isn’t what I wanted anyway. Instead, I want to show average
    temperature for each reef, so I need to take the code that was developed in the
    analysis phase and move that code to the browser. In addition, I filter down the
    data to reefs in Australia, which helps cut down the data somewhat.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我对图表的第一版有很大的问题。它显示了每个调查的温度，但数据太多，无法用条形图表示。而且这也不是我想要的。相反，我想展示每个珊瑚礁的平均温度，所以我需要将分析阶段开发出的代码移动到浏览器中。此外，我还筛选出澳大利亚的珊瑚礁数据，这有助于减少数据量。
- en: Building on the code from the analysis phase, I filter out non-Australian reefs,
    group by reef name, and then compute the average temperature for each reef. We
    then plug this data into the chart. You can see the result in figure. (To see
    the color, refer to the electronic versions of the book.)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析阶段代码的基础上，我筛选出非澳大利亚珊瑚礁，按珊瑚礁名称分组，然后计算每个珊瑚礁的平均温度。我们将这些数据输入到图表中。您可以在图中看到结果。（要查看颜色，请参考书籍的电子版。）
- en: '![c01_15.eps](Images/c01_15.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![c01_15.eps](Images/c01_15.png)'
- en: Figure 1.15 Chart showing temperature of reefs in Australia
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.15 显示澳大利亚珊瑚礁温度的图表
- en: 1.9.9 Getting to production
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.9.9 进入生产阶段
- en: 'In this final phase of data wrangling, you deliver your data pipeline to your
    audience. We’ll deploy the web app to the *production environment*. This is arguably
    the most difficult part of this process: bringing a production system online.
    By production, I mean a system that’s in operation and being used by someone,
    typically a client or the general public. That’s where it must exist to reach
    your audience.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据整理的最后阶段，您将您的数据管道交付给您的受众。我们将部署Web应用程序到**生产环境**。这可能是这个过程中最具挑战性的部分：将生产系统上线。通过生产，我指的是一个正在运行并被某人使用（通常是客户或公众）的系统。这就是它必须存在以触及您的受众的地方。
- en: There will be times when you do a one-time data analysis and then throw away
    the code. When that’s adequate for the job, you don’t need to move that code to
    production, so you won’t have the concerns and difficulties of such (lucky you),
    although most of the time you need to get your code to the place where it needs
    to run.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 有时会进行一次性的数据分析然后丢弃代码。当这足以完成工作时，您不需要将代码移动到生产，因此您不会有这样的担忧和困难（幸运的是），尽管大多数时候您需要将代码移动到需要运行的地方。
- en: You might move your code to a web service, a front end, a mobile app, or a desktop
    app. After moving your code to production, it will run automatically or on demand.
    Often it will process data in real-time, and it might generate reports and visualizations
    or whatever it needs to do.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会将代码移动到Web服务、前端、移动应用或桌面应用。在将代码移动到生产后，它将自动运行或在需要时运行。通常，它将实时处理数据，并可能生成报告和可视化或执行它需要完成的任何操作。
- en: In this case I built a dashboard to display and explore the reef data. The final
    dashboard looks like [figure 1.16](#figure1.16).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我构建了一个仪表板来显示和探索珊瑚礁数据。最终的仪表板看起来像[图1.16](#figureanchor1.16)。
- en: '![c01_16.eps](Images/c01_16.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![c01_16.eps](Images/c01_16.png)'
- en: '[Figure 1.16](#figureanchor1.16) The reef data dashboard'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.16](#figureanchor1.16) 珊瑚礁数据仪表板'
- en: The code covered so far in this chapter is already in JavaScript, so it isn’t
    difficult to slot it into place in my JavaScript production environment. This
    is one of the major benefits of doing all our data-related work in JavaScript.
    As you move through the exploratory phase and toward production, you’ll naturally
    take more care with your coding. With a plan and direction, you might engage in
    test-driven development or another form of automated testing (more on that in
    chapter 14).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中已经涵盖的代码已经是JavaScript，所以将它放入我的JavaScript生产环境中并不困难。这是我们在JavaScript中完成所有数据相关工作的主要好处之一。随着你进入探索阶段并向生产阶段过渡，你自然会更加注意你的编码。有了计划和方向，你可能会参与测试驱动开发或其他形式的自动化测试（关于这一点，请参阅第14章）。
- en: The dashboard also has a table of reefs where you can drill down for a closer
    look ([figure 1.17](#figure1.17)). To make the data display efficiently in the
    dashboard, I’ve prebaked various data analysis into the database.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板还有一个珊瑚礁表，你可以深入查看（[图1.17](#figure1.17)）。为了在仪表板中有效地显示数据，我已经在数据库中预先处理了各种数据分析。
- en: '![c01_17.png](Images/c01_17.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![c01_17.png](Images/c01_17.png)'
- en: '[Figure 1.17](#figureanchor1.17) Table of reefs in the dashboard'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.17](#figureanchor1.17) 仪表板中的珊瑚礁表'
- en: To get your code into production, you’ll most likely need a form of build or
    deployment script, maybe both. The build script will do such things as static
    error checking, concatenation, minification, and packaging your code for deployment.
    Your deployment script takes your code and copies it to the environment where
    it will run. You typically need a deployment script when you’re deploying a server
    or microservice. To host your server in the cloud, you may also need a provisioning
    script. This is a script that creates the environment in which the code will run.
    It might create a VM from an image and then install dependencies—for example,
    Node.js and MongoDB.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将你的代码投入生产，你很可能会需要一个构建或部署脚本，可能两者都需要。构建脚本将执行诸如静态错误检查、连接、压缩和打包代码以供部署等任务。你的部署脚本将你的代码复制到它将运行的环境。当你部署服务器或微服务时，通常需要部署脚本。为了在云中托管你的服务器，你可能还需要一个配置脚本。这是一个创建代码将运行的环境的脚本。它可能从镜像创建一个虚拟机，然后安装依赖项——例如，Node.js和MongoDB。
- en: 'With your code moved to the production environment, you have a whole new set
    of issues to deal with:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的代码转移到生产环境时，你将面临一系列全新的问题：
- en: What happens when you get data updates that don’t fit your initial assumptions?
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你得到不符合你最初假设的数据更新时会发生什么？
- en: What happens when your code crashes?
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你的代码崩溃时会发生什么？
- en: How do you know if your code is having problems?
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你如何知道你的代码有问题？
- en: What happens when your system is overloaded?
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你的系统过载时会发生什么？
- en: You’ll explore these issues and how to approach them in chapter 14.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在第14章中探讨这些问题以及如何处理它们。
- en: Welcome to the world of data wrangling. You now have an understanding of what
    a data-wrangling project might look like, and you’ll spend the rest of the book
    exploring the various phases of the process, but before that, you might need help
    getting started with Node.js, so that’s what we’ll cover in chapter 2.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到数据整理的世界。你现在对数据整理项目可能的样子有了了解，你将在本书的剩余部分探索该过程的各个阶段，但在那之前，你可能需要帮助开始使用Node.js，这就是我们在第2章要涵盖的内容。
- en: Summary
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Data wrangling is the entire process of working with data from acquisition through
    processing and analysis, then finally to reporting and visualization.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据整理是从获取到处理和分析，最后到报告和可视化的整个数据处理过程。
- en: Data analysis is a part of data wrangling, and it *can* be done in JavaScript.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分析是数据整理的一部分，并且可以用JavaScript完成。
- en: JavaScript is already a capable language and is improving with each new iteration
    of the standard.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JavaScript已经是一种功能强大的语言，并且随着标准的每一次更新而不断改进。
- en: As with any coding, data wrangling can be approached in a range of ways. It
    has a spectrum from ad hoc throw-away coding to disciplined high-quality coding.
    Where you fit on this spectrum depends on the time you have and the intended longevity
    of the code.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就像任何编码一样，数据整理可以以多种方式处理。它从临时的丢弃编码到有纪律的高质量编码有一个范围。你在这一范围内的位置取决于你拥有的时间和代码预期的持久性。
- en: Exploratory coding is important for prototyping code and understanding data.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索性编码对于原型设计和理解数据非常重要。
- en: 'Data wrangling has a number of phases: acquisition, cleanup, transformation,
    then analysis, reporting, and visualization.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据整理有几个阶段：获取、清理、转换，然后是分析、报告和可视化。
- en: The phases are rarely cleanly separated; they’re often interspersed and tangled
    up with each other.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阶段通常不会完全分开；它们往往交织在一起，相互纠缠。
- en: You should always start with planning.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该始终从规划开始。
- en: It’s important to check assumptions about the data.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查关于数据的基本假设非常重要。
- en: Moving code to production involves many new issues.*
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将代码部署到生产环境涉及许多新问题*。
