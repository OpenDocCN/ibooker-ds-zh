- en: 3 Graphs in machine learning applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习应用中的3个图表
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The role of graphs in the machine learning workflow
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图表在机器学习工作流程中的作用
- en: How to store the training data and the resulting model properly
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何正确存储训练数据和生成的模型
- en: Graph-based algorithms for machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的图算法
- en: Data analysis with graph visualization
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图可视化进行数据分析
- en: In this chapter, we’ll explore in more detail how graphs and machine learning
    can fit together, helping to deliver better services to end users, data analysts,
    and businesspeople. Chapters 1 and 2 introduced general concepts in machine learning,
    such as
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更详细地探讨图表和机器学习如何结合在一起，帮助为最终用户、数据分析师和商业人士提供更好的服务。第1章和第2章介绍了机器学习的一般概念，例如
- en: 'The different phases that compose a generic machine learning project (specifically,
    the six phases of the CRISP-DM model: business understanding, data understanding,
    data preparation, modeling, evaluation, and deployment)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构成通用机器学习项目的不同阶段（特别是CRISP-DM模型的六个阶段：业务理解、数据理解、数据准备、建模、评估和部署）
- en: The importance of data quality and quantity to create a valuable and meaningful
    model that can provide accurate predictions
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据质量和数量对于创建一个有价值且有意义、能够提供准确预测的模型的重要性
- en: How to handle a large amount of data (big data) by using a graph data model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何通过使用图数据模型来处理大量数据（大数据）
- en: 'Here, we will see how to harness the power of the graph model as a way of representing
    data that makes it easy to access and analyze, as well as how to use the “intelligence”
    of the machine learning algorithms based on graph theory. I would like to start
    this chapter with an image (figure 3.1) that represents the path of converting
    raw data, available from multiple sources, to something that is more than simple
    knowledge or insight: *wisdom*.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将看到如何利用图模型作为表示数据的手段，使其易于访问和分析，以及如何使用基于图理论的机器学习算法的“智能”。我想以一张图像（图3.1）作为本章的开端，这张图像代表了将来自多个来源的原始数据转换为不仅仅是简单知识或洞察力的过程：智慧。
- en: '![CH03_F01_Negro](../Images/CH03_F01_Negro.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F01_Negro](../Images/CH03_F01_Negro.png)'
- en: Figure 3.1 Illustration by David Somerville, based on the original by Hugh McLeod[¹](#pgfId-1016273)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 由David Somerville绘制，基于Hugh McLeod的原始作品[¹](#pgfId-1016273)
- en: 'We are flooded by data. Data is *everywhere*. News, blog posts, emails, chats,
    and social media are only a few examples of the multiple data-generating sources
    that surround us. Furthermore, at the time of this writing, we are in the middle
    of the IoT explosion: today even my washing machine sends me data, reminding me
    that my pants are clean, and my car knows when I should stop driving and take
    a coffee break.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们被数据淹没。数据无处不在。新闻、博客文章、电子邮件、聊天和社交媒体只是围绕我们的多个数据生成源的几个例子。此外，在撰写本文时，我们正处于物联网爆炸的中间：今天甚至我的洗衣机都会给我发送数据，提醒我我的裤子已经洗好了，我的汽车也知道我应该停车休息喝杯咖啡。
- en: 'Data by itself is useless, though; on its own, it doesn’t provide any value.
    To make sense of the data, we have to interact with it and organize it. This process
    produces information. Turning this information into knowledge, which reveals relationships
    between information items—a quality change—requires further effort. This transformation
    process connects the dots, causing previously unrelated information to acquire
    sense, significance, and logical semantics. From knowledge come insight and wisdom,
    which are not only relevant, but also provide guidance and can be converted to
    actions: producing better products, making users happier, reducing production
    costs, delivering better services, and more. This action is where the true value
    of data resides, at the end of a long transformation path—and machine learning
    provides the necessary intelligence for distilling value from it.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据本身是无用的；单独来看，它不提供任何价值。为了理解数据，我们必须与之互动并组织它。这个过程产生了信息。将信息转化为知识，揭示信息项之间的关系——这是一种质量变化——需要进一步的努力。这个转换过程连接了点，使之前无关的信息获得意义、重要性和逻辑语义。从知识中产生洞察力和智慧，这不仅相关，而且提供指导，可以转化为行动：生产更好的产品，让用户更快乐，降低生产成本，提供更好的服务等等。这个行动就是数据的真正价值所在，在漫长的转换路径的终点——而机器学习提供了从数据中提炼价值的必要智能。
- en: 'Figure 3.1 to some extent represents the learning path for the first part of
    this chapter:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1在一定程度上代表了本章第一部分的学习路径：
- en: Data and information are gathered from one source or several sources. This data
    is the training data, on top of which any learning will happen, and it is managed
    in the form of a graph (section 3.2).
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一个或多个来源收集数据和信息。这些数据是训练数据，任何学习都将在此基础上发生，并以图的形式管理（第3.2节）。
- en: When the data is organized in the form of knowledge and represented by a proper
    graph, machine learning algorithms can extract and build insights and wisdom on
    top of it (section 3.3).
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当数据以知识和适当的图的形式组织时，机器学习算法可以在其上提取和构建洞察和智慧（第3.3节）。
- en: The prediction models that are created as the result of the training of a machine
    learning algorithm on the knowledge are stored back in the graph (section 3.4),
    making the wisdom inferred permanent and usable.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为在知识上训练机器学习算法的结果而创建的预测模型被存储回图中（第3.4节），使得推断出的智慧永久可用。
- en: Finally, the visualization (section 3.5) shows the data in a way that the human
    brain can easily understand, making the derived knowledge, insights, and wisdom
    accessible.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，可视化（第3.5节）以人类大脑容易理解的方式展示数据，使得推导出的知识、洞察和智慧易于获取。
- en: This path follows the same mental model used in chapters 1 and 2 to highlight
    and organize the multiple ways in which graphs can be a valuable help in your
    machine learning project (figure 3.2).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 此路径遵循第1章和第2章中使用的相同心智模型，以突出和整理图在机器学习项目中作为有价值的帮助的多种方式（图3.2）。
- en: '![CH03_F02_Negro](../Images/CH03_F02_Negro.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F02_Negro](../Images/CH03_F02_Negro.png)'
- en: Figure 3.2 Mental model for graph-powered machine learning
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 图驱动机器学习的心智模型
- en: We’ll start from the beginning of this mental model and go in deep, showing
    some of the many techniques and approaches that use graph features to deliver
    a better machine learning project.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从这个心智模型的开始部分开始，深入探讨，展示许多使用图特征来提高机器学习项目的技术和方法。
- en: 3.1 Graphs in the machine learning workflow
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 机器学习工作流程中的图
- en: 'The CRISP-DM model described in chapter 1 [Wirth and Hipp, 2000] allows us
    to define a generic machine learning workflow that can be decomposed, for the
    purposes of our discussion, into the following macro steps:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 第1章中描述的CRISP-DM模型（Wirth和Hipp，2000）允许我们定义一个通用的机器学习工作流程，为了我们的讨论，可以将它分解为以下宏观步骤：
- en: Select the data sources, gather data, and prepare the data.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择数据源，收集数据，并准备数据。
- en: Train the model (the learning phase).
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型（学习阶段）。
- en: Provide predictions.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供预测。
- en: Some learning algorithms don’t have a model.[²](#pgfId-1010000) The instance-based
    algorithms don’t have a separate learning phase; they use the entries in the training
    dataset during the prediction phase. Although the graph approach can be a valid
    support even in these cases, we will not consider these algorithms in our analysis.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一些学习算法没有模型。[²](#pgfId-1010000) 基于实例的算法没有单独的学习阶段；它们在预测阶段使用训练数据集中的条目。尽管在这种情况下图方法可以是一个有效的支持，但我们不会在我们的分析中考虑这些算法。
- en: Furthermore, quite often, data needs to be visualized in multiple shapes to
    achieve the purpose of the analysis. Hence, visualization plays an important role
    as a final step that completes the machine learning workflow, allowing further
    investigation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，很多时候，数据需要以多种形状可视化，以达到分析的目的。因此，可视化在作为完成机器学习工作流程的最终步骤中扮演着重要的角色，允许进一步的调查。
- en: This workflow description matches the mental model in figure 3.2, which you
    will see throughout this chapter (and the book) to help you figure out where we
    are in each step. In such a workflow, it is important to look at the role of the
    graph from operational, task-based, and data-flow perspectives. Figure 3.3 illustrates
    how data flows from the data sources through the learning process to end users
    in the form of visualizations or predictions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工作流程描述与图3.2中的心智模型相匹配，你将在本章（以及本书）的整个过程中看到它，以帮助你弄清楚每个步骤的位置。在这样的工作流程中，从操作、任务和数据流的角度来看图的作用是很重要的。图3.3说明了数据如何从数据源通过学习过程流向最终用户，以可视化的形式或预测的形式。
- en: '![CH03_F03_Negro](../Images/CH03_F03_Negro.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F03_Negro](../Images/CH03_F03_Negro.png)'
- en: Figure 3.3 The role of graphs in the machine learning workflow
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 机器学习工作流程中图的作用
- en: 'The process starts, as usual, from the data available. Different data sources
    will have different schemas, structure, and content. Generally, the data used
    in machine learning applications can be classified as big data. (We discussed
    working with big data in chapter 2.) This data must be organized and managed before
    the learning process can begin. The graph model helps with data management by
    creating a connected and well-organized source of truth. The transformation from
    the original data shape to a graph could be done through multiple techniques that
    can be classified in two groups:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 过程通常从可用的数据开始。不同的数据源将具有不同的模式、结构和内容。通常，用于机器学习应用的数据可以归类为大数据。（我们在第2章讨论了与大数据一起工作。）在学习过程开始之前，必须对这些数据进行组织和管理。图模型通过创建一个连接良好且组织有序的真相来源来帮助数据管理。从原始数据形状到图的转换可以通过多种技术完成，这些技术可以分为两组：
- en: '*Graph modeling*—Data is converted to some graph representation by means of
    a modeling pattern. The information is the same, only in a different format, or
    the data is aggregated to make it more suitable to feed into the learning process.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图建模*——通过建模模式将数据转换为某种图表示。信息是相同的，只是格式不同，或者数据被聚合以使其更适合输入学习过程。'
- en: '*Graph construction*—A new graph is created, starting from the data available.
    The resulting graph contains more information than before.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图构建*——从可用的数据开始创建一个新的图。生成的图包含比之前更多的信息。'
- en: 'After this preparation, the data is stored in a well-structured format, ready
    for the next phase: the learning process. The graph representation of the data
    doesn’t support only graph-based algorithms; it can feed multiple types of algorithms.
    Specifically, the graph representation is helpful for the following tasks:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在此准备之后，数据以良好的结构格式存储，为下一阶段：学习过程。数据的图表示不仅支持基于图的算法；它可以喂养多种类型的算法。具体来说，图表示对于以下任务很有帮助：
- en: '*Feature selection*—Querying a relational database or extracting a key from
    a value in a NoSQL database is a complex undertaking. A graph is easy to query
    and can merge data from multiple sources, so finding and extracting the list of
    variables to use for training is made simpler by the graph approach.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征选择*——查询关系数据库或从NoSQL数据库中的值中提取一个键是一项复杂的任务。图易于查询，可以合并来自多个来源的数据，因此通过图方法找到和提取用于训练的变量列表变得简单。'
- en: '*Data filtering*—The easy-to-navigate relationships among objects make it easy
    to filter out useless data before the training phase, which speeds the model-building
    process. We’ll see an example in section 3.2.4, where we’ll consider the recommendation
    scenario.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据过滤*——对象之间易于导航的关系使得在训练阶段之前过滤掉无用数据变得容易，这加快了模型构建过程。我们将在3.2.4节中看到一个例子，我们将考虑推荐场景。'
- en: '*Data preparation*—Graphs make it easy to clean the data, removing spurious
    entries, and to merge data from multiple sources.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据准备*——图使得清理数据变得容易，去除虚假条目，并合并来自多个来源的数据。'
- en: '*Data enrichment*—Extending the data with external sources of knowledge (such
    as semantic networks, ontologies, and taxonomies) or looping back the result of
    the modeling phase to build a bigger knowledge base is straightforward with a
    graph.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据丰富*——通过图，可以轻松地用外部知识来源（如语义网络、本体和分类法）扩展数据，或者将建模阶段的结果循环回来构建更大的知识库。'
- en: '*Data formatting*—It’s easy to export the data in whichever format is necessary:
    vectors, documents, and so on.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据格式化*——很容易以所需的任何格式导出数据：向量、文档等。'
- en: In both scenarios (graph-based or non-graph-based algorithms), the result could
    be a model that is well suited to a graph representation; in that case, it can
    be stored back in the graph or stored in a binary or proprietary format.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在两种场景（基于图或非基于图的算法）中，结果可能是一个非常适合图表示的模型；在这种情况下，它可以存储回图中，或者以二进制或专有格式存储。
- en: Whenever the predictive model allows it, storing the model back in the graph
    gives you the opportunity to perform predictions as queries (more or less complex)
    on the graph. Moreover, the graph provides access to the same model from different
    perspectives and for different scopes. Recommendations, described in section 3.2.4,
    are an example of the potential of this approach.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当预测模型允许时，将模型存储回图中，您就有机会在图上执行预测（更或更复杂）查询。此外，图提供了从不同角度和不同范围访问相同模型的方式。在第3.2.4节中描述的推荐是这种方法的潜在能力的例子。
- en: Finally, the graph model can be used to visualize the data in a graph format,
    which often represents a big advantage in terms of communication capabilities.
    Graphs are whiteboard friendly, so the visualizations can also improve communication
    between business owners and data scientists in the early stages of a machine learning
    project.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，图模型可以用来以图格式可视化数据，这在沟通能力方面通常是一个很大的优势。图易于在白板上展示，因此这些可视化也可以在机器学习项目的早期阶段改善业务所有者和数据科学家之间的沟通。
- en: Not all the phases and steps described here are mandatory; depending on the
    needs of the machine learning workflow, only some might be helpful or necessary.
    Later sections present a range of concrete example scenarios. For each scenario
    presented, the role of the graph is clearly illustrated.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这里描述的所有阶段和步骤并非都是强制性的；根据机器学习工作流程的需求，可能只有一些是有帮助或必要的。后面的章节将展示一系列具体的示例场景。对于每个场景，图的作用都得到了清晰的说明。
- en: 3.2 Managing data sources
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 管理数据源
- en: As we’ve seen, graphs are extremely useful for encoding information, and data
    in graph format is increasingly plentiful. In many areas of machine learning—including
    natural language processing, computer vision, and recommendations—graphs are used
    to model local relationships between isolated data items (users, items, events,
    and so on) and to construct global structures from local information [Zhao and
    Silva, 2016]. Representing data as graphs is often a necessary step (and at other
    times only a desirable one) in dealing with problems arising from applications
    in machine learning or data mining. In particular, it becomes crucial when we
    want to apply graph-based learning methods to the datasets. Figure 3.4 highlights
    the role of graphs related to the management of data sources in machine learning
    projects.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，图在编码信息方面极为有用，以图格式呈现的数据也越来越多。在机器学习的许多领域——包括自然语言处理、计算机视觉和推荐系统——图被用来模拟孤立数据项（用户、物品、事件等）之间的局部关系，并从局部信息构建全局结构
    [赵和席尔瓦，2016]。将数据表示为图通常是处理机器学习或数据挖掘应用中产生的问题的必要步骤（有时也只是一种期望）。特别是，当我们想要将基于图的机器学习方法应用于数据集时，这一点变得至关重要。图3.4突出了在机器学习项目中管理数据源相关的图的作用。
- en: '![CH03_F04_Negro](../Images/CH03_F04_Negro.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F04_Negro](../Images/CH03_F04_Negro.png)'
- en: Figure 3.4 Managing data sources in the mental model
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 心智模型中的数据源管理
- en: 'The transformation from structured or unstructured data to a graph representation
    can be performed in a lossless manner, but this lossless representation is not
    always necessary (or desirable) for the purpose of the learning algorithm. Sometimes,
    a better model is an aggregated view of the data. If you are modeling a phone
    call between two people, for example, you can decide to have a relationship between
    the two entities (the caller and the receiver) for each call, or you can have
    a single relationship that aggregates all the calls. You can construct a graph
    from the input dataset in two ways:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 将结构化或非结构化数据转换为图表示可以以无损的方式进行，但这种无损表示并不总是对学习算法的目的来说是必要的（或理想的）。有时，更好的模型是数据的聚合视图。例如，如果你正在模拟两个人之间的电话通话，你可以决定为每次通话在这两个实体（打电话者和接收者）之间建立关系，或者你可以有一个聚合所有通话的单个关系。你可以通过以下两种方式从输入数据集中构建图：
- en: By designing a graph model that represents the data
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过设计一个表示数据的图模型
- en: By using some convenient graph formation criteria
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用一些方便的图形成标准
- en: In the first case, the graph model is an alternative representation of the same
    information available in the dataset itself or in multiple datasets. The nodes
    and the relationships in the graph are a mere representation (aggregated or not)
    of the data available in the original sources. Furthermore, in this case the graph
    acts as a connected data source that merges data coming from multiple heterogeneous
    sources, operating as the single trusted source of truth at the end of the process.
    There are multiple methodologies, techniques, and best practices for applying
    this model shift and representing data in a graph format, and we will discuss
    some of them here, considering multiple scenarios. Other data model patterns are
    presented in the rest of the book.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下，图模型是数据集中本身或多个数据集中可用的相同信息的替代表示。图中的节点和关系仅仅是原始来源中可用数据的表示（可能是聚合的或非聚合的）。此外，在这种情况下，图充当一个连接的数据源，合并来自多个异构源的数据，在过程结束时作为单一可信的真实数据源。有多个方法、技术和最佳实践用于应用这种模型转换并在图格式中表示数据，我们将在多个场景中讨论其中一些。其他数据模型模式在本书的其余部分中介绍。
- en: In the second scenario—using some convenient graph formation criteria—the data
    items are stored in the graph (generally as nodes), and a graph is created by
    means of some edge construction mechanism. Suppose that in your graph, each node
    represents some text, such as a sentence or an entire document. These entries
    are isolated entries. There are no relationships among the nodes unless they are
    explicitly connected (such as via a citation in a paper). In machine learning,
    text is generally represented as a vector, with each entry containing the weight
    of a word or a feature in the text. Edges can be created (constructed) by using
    the similarity or dissimilarity value between the vectors. A new graph is created
    starting from unrelated information. In such a case, the resulting graph embeds
    more information than the original datasets. This additional information is made
    up of several ingredients, the most important of which is the structural or topological
    information of the data relationships.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二种场景中——使用一些方便的图形成标准——数据项存储在图中（通常作为节点），通过某种边构建机制创建图。假设在你的图中，每个节点代表一些文本，例如一个句子或整个文档。这些条目是孤立条目。除非它们被明确连接（例如通过论文中的引用），否则节点之间没有关系。在机器学习中，文本通常表示为向量，每个条目包含文本中单词或特征的权重。可以通过使用向量之间的相似度或差异值来创建（构建）边。从无关信息开始创建一个新的图。在这种情况下，生成的图包含比原始数据集更多的信息。这些附加信息由几个成分组成，其中最重要的是数据关系的结构或拓扑信息。
- en: The result of both processes is a graph that represents the input data and that
    becomes the training dataset for the relevant machine learning algorithms. In
    some cases, these algorithms are themselves graph algorithms, so they require
    a graph representation of the data; in other cases, the graph is a better way
    of accessing the same data. The examples and scenarios described here represent
    both cases.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个过程的结果是一个图，它表示输入数据，并成为相关机器学习算法的训练数据集。在某些情况下，这些算法本身就是图算法，因此它们需要数据的图表示；在其他情况下，图是访问相同数据的更好方式。这里描述的示例和场景代表了这两种情况。
- en: Figure 3.5 shows the required steps in the process of converting data to its
    graph representation (or creating it as a graph).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5显示了将数据转换为图表示（或作为图创建）过程中的必要步骤。
- en: '![CH03_F05_Negro](../Images/CH03_F05_Negro.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F05_Negro](../Images/CH03_F05_Negro.png)'
- en: Figure 3.5 Process of converting data to a graph representation
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 将数据转换为图表示的过程
- en: 'Let’s take a closer look at each step:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看每个步骤：
- en: '*Identify the data sources.* Identify the data available for algorithm training
    purposes, as well as the sources from which such data can be extracted. This step
    corresponds to the second phase in a machine learning project, after the goals
    are defined (the data preparation phase of the CRISP-DM data model).'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*确定数据来源*。确定用于算法训练目的的数据，以及可以从哪些来源提取此类数据。这一步骤对应于机器学习项目的第二阶段，在定义目标之后（CRISP-DM数据模型的数据准备阶段）。'
- en: '*Analyze the data available.* Analyze each data source available, and evaluate
    the content, in terms of quality and quantity. To achieve good results from the
    training phase, it’s imperative to have a large amount of good-quality data.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*分析可用数据*。分析每个可用的数据源，并从质量和数量方面评估其内容。为了从训练阶段获得良好的结果，拥有大量高质量的数据至关重要。'
- en: '*Design the graph data model.* This step is twofold. According to the specific
    analytics requirements, you must'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*设计图数据模型*。这一步是双重的。根据具体的分析需求，你必须'
- en: Identify the meaningful information to be extracted from the data sources.
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别从数据源中提取的有意义的信息。
- en: Design a specific graph model, considering the data available, access patterns,
    and extensibility.
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设计一个特定的图模型，考虑到可用的数据、访问模式和可扩展性。
- en: '*Define the data flow.* Design the architecture of the ingestion process (known
    as the ETL process) that extracts, transforms, and loads the data from the multiple
    sources into the graph database, using the schema designed.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*定义数据流*。设计摄入过程的架构（称为ETL过程），该过程使用设计的模式从多个源提取、转换和加载数据到图数据库。'
- en: '*Import data into the graph.* Start the ETL process defined in step 4\. Generally,
    steps 3, 4, and 5 are iterative until you arrive at the right model and the right
    ETL process.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*将数据导入图*。启动第4步中定义的ETL过程。通常，第3步、第4步和第5步是迭代的，直到你得到正确的模型和正确的ETL过程。'
- en: '*Perform postimport tasks.* Before you start the analysis, the data in the
    graph might require some preprocessing. These tasks include'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*执行导入后任务*。在开始分析之前，图中的数据可能需要进行一些预处理。这些任务包括'
- en: '*Data cleaning*—Remove or correct incomplete or incorrect data.'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*数据清理*—删除或纠正不完整或不正确的数据。'
- en: '*Data enrichment*—Extend the existing data sources with external sources of
    knowledge or with knowledge extracted from the data itself. The latter case falls
    under graph creation.'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*数据丰富*—通过外部知识源或从数据本身提取的知识扩展现有数据源。后一种情况属于图创建。'
- en: '*Data merging*—Because the data comes from multiple sources, related elements
    in the dataset can be merged in a single element or can be connected through new
    relationships.'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*数据合并*—因为数据来自多个源，数据集中的相关元素可以合并为一个单一元素，或者可以通过新的关系连接起来。'
- en: Steps 5 and 6 can be inverted or mixed. In some cases, the data may pass through
    a process of cleaning before the ingestion happens. In any case, at the end of
    those six steps, the data is ready for the next phase, which involves the learning
    process.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第5步和第6步可以颠倒或混合。在某些情况下，数据在摄入之前可能需要经过一个清理过程。
- en: The new representation of the data provides several advantages that we’ll investigate
    here through the lens of multiple scenarios and multiple models. You’ll be seeing
    some of these scenarios for the first time, but others were introduced in chapters
    1 and 2, and will be extended further throughout the book. For each scenario presented,
    I describe the context and purpose—key aspects of defining the right model and
    understanding the value of the graph approach to storing and managing data and
    of graphs as input for the next steps in the analysis.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的新表示提供了几个优势，我们将通过多个场景和多个模型来探讨这些优势。你将首次看到其中一些场景，但其他场景已在第1章和第2章中介绍，并在整本书中进一步扩展。对于每个提出的场景，我将描述背景和目的——定义正确模型和理解使用图方法存储和管理数据以及将图作为分析下一步输入的价值的关键方面。
- en: Starting with part 2, the book describes in detail the techniques for representing
    different datasets by using a graph model. This chapter highlights, through the
    example scenarios, the primary advantages of using a graph to manage the data
    available for training the prediction model.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从第2部分开始，本书详细介绍了使用图模型表示不同数据集的技术。本章通过示例场景突出了使用图管理用于训练预测模型的数据的主要优势。
- en: 3.2.1 Monitor a subject
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.1 监控一个主体
- en: Suppose again that you are a police officer. You would like to attempt to track
    a suspect and predict their future movements by using cellular tower data collected
    from the continuous monitoring signals every phone sends to (or receives from)
    all towers it can reach. Using graph models and graph clustering algorithms, it
    is possible to structure cellular tower data to represent a subject’s positions
    and movements in a simple, clear manner. Then you can create a predictive model.[³](#pgfId-1010017)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你再次是一名警察。你希望通过使用从每部手机发送到（或接收自）它能到达的所有塔的持续监控信号收集到的蜂窝塔数据来尝试追踪嫌疑人并预测他们的未来行动。使用图模型和图聚类算法，可以将蜂窝塔数据结构化，以简单、清晰的方式表示一个主体的位置和移动。然后你可以创建一个预测模型。[³](#pgfId-1010017)
- en: The goal in this scenario is to monitor a subject and create a predictive model
    that identifies location clusters relevant to the subject’s life and that is able
    to predict and anticipate subsequent movements according to the subject’s current
    position and last movements [Eagle, Quinn, and Clauset, 2009]. The data in this
    scenario is cellular tower data generated by the interactions between the subject’s
    phone and the cellular towers, as represented in figure 3.6.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在此场景中，目标是监控一个对象并创建一个预测模型，该模型能够识别与对象生活相关的位置聚类，并且能够根据对象的当前位置和最后移动情况预测和预测后续移动 [Eagle,
    Quinn, and Clauset, 2009]。在此场景中，数据是手机与移动基站之间交互产生的移动基站数据，如图 3.6 所示。
- en: '![CH03_F06_Negro](../Images/CH03_F06_Negro.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F06_Negro](../Images/CH03_F06_Negro.png)'
- en: Figure 3.6 Phones communicating with cellular towers
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6 手机与移动基站通信
- en: For the purpose of such an analysis, data can be collected from the towers or
    from the phones belonging to the monitored subjects. The data from the cellular
    towers is easy to obtain with the necessary permissions, but it requires a lot
    of cleaning (removing the irrelevant numbers) and merging (data from multiple
    cellular towers). Gathering data from the phones requires hacking, which is not
    always possible, but this data is clean and already merged. In their paper, Eagle,
    Quinn, and Clauset consider this second data source, and we do the same here,
    but the results and the considerations are the same regardless of the source of
    the data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行此类分析，可以从基站或受监控对象的手机中收集数据。通过必要的权限，从移动基站收集数据很容易，但需要进行大量的清理（去除无关的号码）和合并（来自多个移动基站的数据）。从手机收集数据需要黑客技术，这并不总是可能的，但此数据是干净的并且已经合并。在他们的论文中，Eagle,
    Quinn 和 Clauset 考虑了第二种数据源，我们在这里也这样做，但结果和考虑与数据来源无关。
- en: Let’s suppose that the phones will provide data in the format shown in table
    3.1.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 假设手机将以表 3.1 所示的格式提供数据。
- en: Table 3.1 Examples of the data provided by a single phone with the four towers
    (identified by ID) reached at each timestamp
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.1 单个手机与四个基站（按 ID 标识）在各个时间戳下提供的数据示例
- en: '| Phone identifier | Timestamp | Cellular tower 1 | Cellular tower 2 | Cellular
    tower 3 | Cellular tower 4 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 手机标识符 | 时间戳 | 移动基站 1 | 移动基站 2 | 移动基站 3 | 移动基站 4 |'
- en: '| 562d6873b0fe | 1530713007 | eca5b35d | f7106f86 | 1d00f5fb | 665332d8 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 562d6873b0fe | 1530713007 | eca5b35d | f7106f86 | 1d00f5fb | 665332d8 |'
- en: '| 562d6873b0fe | 1530716500 | f7106f86 | 1d00f5fb | 2a434006 | eca5b35d |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 562d6873b0fe | 1530716500 | f7106f86 | 1d00f5fb | 2a434006 | eca5b35d |'
- en: '| 562d6873b0fe | 1530799402 | f7106f86 | eca5b35d | 2a434006 | 1d00f5fb |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 562d6873b0fe | 1530799402 | f7106f86 | eca5b35d | 2a434006 | 1d00f5fb |'
- en: '| 562d6873b0fe | 1531317805 | 1d00f5fb | 665332d8 | f7106f86 | eca5b35d |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 562d6873b0fe | 1531317805 | 1d00f5fb | 665332d8 | f7106f86 | eca5b35d |'
- en: '| 562d6873b0fe | 1533391403 | 2a434006 | 665332d8 | eca5b35d | 1d00f5fb |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 562d6873b0fe | 1533391403 | 2a434006 | 665332d8 | eca5b35d | 1d00f5fb |'
- en: For the sake of simplicity, this table represents the data provided by a single
    phone. (The phone identifier is always the same.) The phone records the four towers
    with the strongest signals at 30-second intervals.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化起见，此表表示单个手机提供的数据。（手机标识符始终相同。）手机以 30 秒的间隔记录四个信号最强的基站。
- en: The analysis requires us to identify locations in which the monitored subject
    spends time. The cellular tower data available on the phone cannot provide this
    information by itself, because it contains only the identifiers of the four towers
    with the highest signal strengths. But starting from such data, it is possible
    to identify key locations by passing through a graph representation of the data
    and a graph algorithm. Therefore, this data can be modeled as a graph that represents
    a cellular tower network (CTN). As you’ll recall from chapter 2, each node in
    this graph is a unique cellular tower; edges exist between any two nodes that
    co-occur in the same record, and each edge is assigned a weight according to the
    total amount of time that pair of nodes co-occurred in a record, across all records.
    A CTN is generated for the subject that shows every tower logged by their phone
    during the monitoring period. The result looks like figure 3.7.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 分析需要我们识别出被监控主题花费时间的位置。手机上可用的蜂窝基站数据本身无法提供这些信息，因为它只包含四个信号强度最高的基站的标识符。但是，从这些数据开始，通过数据的一个图表示和一个图算法，可以识别出关键位置。因此，这些数据可以建模为一个表示蜂窝基站网络（CTN）的图。正如你从第二章回忆的那样，这个图中的每个节点都是一个独特的蜂窝基站；任何两个节点之间都存在边，如果它们在同一个记录中同时出现，则每条边都会根据这对节点在所有记录中同时出现的总时间分配一个权重。为该主题生成一个CTN，显示了在监控期间由他们的手机记录下的每个基站。结果看起来像图3.7。
- en: '![CH03_F07_Negro](../Images/CH03_F07_Negro.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F07_Negro](../Images/CH03_F07_Negro.png)'
- en: Figure 3.7 A graph representation of the CTN for a single subject
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 单个主题的CTN图表示
- en: A graph clustering algorithm is applied to this graph to identify the main locations
    where the subject spent a significant amount of time (at the office, at home,
    at the supermarket, at church, and so on). The result of the analysis looks like
    figure 3.8, in which multiple clusters are identified and isolated.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 将图聚类算法应用于此图，以识别主题花费大量时间的主要位置（在办公室、在家、在超市、在教堂等）。分析的结果看起来像图3.8，其中识别并隔离了多个聚类。
- en: '![CH03_F08_Negro](../Images/CH03_F08_Negro.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F08_Negro](../Images/CH03_F08_Negro.png)'
- en: Figure 3.8 A clustered view of the CTN
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 CTN的聚类视图
- en: This scenario shows how well adapted a graph model is to representing the data
    for the specific purposes of this analysis. By performing a graph-based analysis
    using the community detection algorithm, we can easily identify areas where the
    subject spends a lot of time—a task that would be difficult, if not impossible,
    with other representations or analysis methods.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个场景展示了图模型在表示分析特定目的的数据方面是多么地适应良好。通过使用社区检测算法进行基于图的分析，我们可以轻松地识别出主题花费大量时间的地方——如果使用其他表示或分析方法，这项任务将变得困难，甚至不可能。
- en: The graph modeling described here illustrates a graph construction technique.
    The resulting graph can be generalized as a *co-occurrence graph*. The nodes represent
    entities (in this case, cellular towers), and the relationships represent the
    fact that two entities belong to a common set or group. (In the CTN, the set is
    the row in the table indicating that at a specific point in time, the phone can
    reach two towers.) This technique is a powerful one that’s used in many algorithms
    and machine learning applications as a data-preprocessing step before analysis.
    Quite often, this type of graph construction technique is used in applications
    related to text analysis; we’ll see an example in section 3.3.2.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这里描述的图建模技术说明了图构建技术。生成的图可以概括为*共现图*。节点代表实体（在这种情况下，是蜂窝基站），关系表示两个实体属于一个共同的集合或组。（在CTN中，集合是表格中的一行，表示在特定时间点，手机可以到达两个基站。）这项技术是一种强大的技术，在许多算法和机器学习应用中作为分析前的数据预处理步骤使用。这种类型的图构建技术通常用于与文本分析相关的应用；我们将在3.3.2节中看到一个例子。
- en: 3.2.2 Detect a fraud
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.2 检测欺诈
- en: Suppose again that you would like to create a fraud detection platform for banks
    that reveals the point of origin of a credit card theft. A graph representation
    of the transactions can help you identify, even visually, the location of the
    theft.[⁴](#pgfId-1010044)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要为银行创建一个欺诈检测平台，该平台可以揭示信用卡盗窃的源头。交易的一个图表示可以帮助你识别，甚至通过视觉识别，盗窃的位置。[⁴](#pgfId-1010044)
- en: In this scenario, the data available is the credit card transactions, with details
    about the date (timestamp), the amount, the merchant, and whether the transaction
    is disputed or undisputed. When a person’s credit card details have been stolen,
    real operations are mixed with illegal or fraudulent operations in their transaction
    history. The goal of the analysis is to identify the point where the fraud started—the
    shop where the theft occurred. The transactions at that shop will be real, but
    any transactions that have taken place afterward may be fraudulent. The data available
    looks like table 3.2.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，可用的数据是信用卡交易，包括关于日期（时间戳）、金额、商家以及交易是否争议的详细信息。当某人的信用卡详情被盗时，真实操作与非法或欺诈操作会混入他们的交易历史中。分析的目标是识别欺诈开始的地方——盗窃发生的商店。该商店的交易将是真实的，但在此之后发生的任何交易可能是欺诈性的。可用的数据看起来像表3.2。
- en: Table 3.2 A subset of user transactions
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.2 用户交易子集
- en: '| User identifier | Timestamp | Amount | Merchant | Validity |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 用户标识 | 时间戳 | 金额 | 商家 | 有效性 |'
- en: '| User A | 01/02/2018 | $250 | Hilton Barcelona | Undisputed |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 用户A | 2018年2月1日 | $250 | Hilton Barcelona | 未争议 |'
- en: '| User A | 02/02/2018 | $220 | AT&T | Undisputed |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 用户A | 2018年2月2日 | $220 | AT&T | 未争议 |'
- en: '| User A | 12/03/2018 | $15 | Burger King New York | Undisputed |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 用户A | 2018年3月12日 | $15 | Burger King New York | 未争议 |'
- en: '| User A | 14/03/2018 | $100 | Whole Foods | Disputed |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 用户A | 2018年3月14日 | $100 | Whole Foods | 争议 |'
- en: '| User B | 12/04/2018 | $20 | AT&T | Undisputed |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 用户B | 2018年4月12日 | $20 | AT&T | 未争议 |'
- en: '| User B | 13/04/2018 | $20 | Hard Rock Cafe | Undisputed |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 用户B | 2018年4月13日 | $20 | Hard Rock Cafe | 未争议 |'
- en: '| User B | 14/04/2018 | $8 | Burger King New York | Undisputed |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 用户B | 2018年4月14日 | $8 | Burger King New York | 未争议 |'
- en: '| User B | 20/04/2018 | $8 | Starbucks | Disputed |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 用户B | 2018年4月20日 | $8 | Starbucks | 争议 |'
- en: '| User C | 03/05/2018 | $15 | Whole Foods | Disputed |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 用户C | 2018年5月3日 | $15 | Whole Foods | 争议 |'
- en: '| User C | 05/05/2018 | $15 | Burger King New York | Undisputed |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 用户C | 2018年5月5日 | $15 | Burger King New York | 未争议 |'
- en: '| User C | 12/05/2018 | $15 | Starbucks | Disputed |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 用户C | 2018年5月12日 | $15 | Starbucks | 争议 |'
- en: Our aim is to identify some common pattern that reveals the point at which users
    start disputing their transactions, which will help us to locate the establishment
    where the card details were stolen. This analysis can be performed by using a
    graph representation of the transactions. The data in table 3.2 can be modeled
    in a transaction graph, as shown in figure 3.9.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目的是识别一些常见的模式，揭示用户开始对交易提出争议的点，这将帮助我们定位到卡片详情被盗的场所。这种分析可以通过使用交易的图表示来进行。表3.2中的数据可以建模成交易图，如图3.9所示。
- en: '![CH03_F09_Negro](../Images/CH03_F09_Negro.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F09_Negro](../Images/CH03_F09_Negro.png)'
- en: Figure 3.9 A transaction graph for credit card fraud detection
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 用于信用卡欺诈检测的交易图
- en: As described in chapter 2, by starting from this representation of the transactions
    and using graph queries, we can determine that the theft occurred at Burger King.
    (The steps taken to arrive at this conclusion are described in section 2.2.2 and
    will not be repeated here.)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如第2章所述，从这种交易表示开始，使用图查询，我们可以确定盗窃发生在Burger King。 (得出这一结论的步骤在第2.2.2节中描述，此处不再重复。)
- en: The graph of the transactions allows us to easily identify where the card thief
    operates. In this case, the analysis is performed on the graph as it appears after
    the ETL phase; no other intermediate transformation is required. This data representation
    expresses the information in such a way that it is possible to quickly recognize
    behavioral patterns in a long list of transactions and spot where the issue is.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 交易图使我们能够轻松地识别卡片窃贼的活动区域。在这种情况下，分析是在ETL阶段之后的图上进行的；不需要其他中间转换。这种数据表示方式使得在长长的交易列表中快速识别行为模式并发现问题所在成为可能。
- en: 'Transaction graphs like the one shown in figure 3.9 can represent any kind
    of event that involves two entities. Generally, these graphs are used for modeling
    monetary transactions in an unaggregated way, which means that every single operation
    can be related to a specific portion of the graph. For the majority of cases,
    in the resulting graph each transaction is represented in one of the following
    two ways:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9所示的交易图可以表示任何涉及两个实体的活动。通常，这些图用于以非聚合方式建模货币交易，这意味着每个单独的操作都可以与图的一个特定部分相关联。在大多数情况下，在生成的图中，每个交易以以下两种方式之一表示：
- en: As a *directed edge* between the two entities involved in the transaction. If
    User A makes a purchase at Shop B, this event is translated into a directed edge
    that starts with User A and terminates at Shop B. In this case, all the relevant
    details about the purchase, such as the date and amount, are stored as properties
    of the edge (figure 3.10 (a)).
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为涉及交易的两个实体之间的**有向边**。如果用户A在商店B进行购买，这一事件被转换为一个有向边，起点是用户A，终点是商店B。在这种情况下，所有与购买相关的详细信息，如日期和金额，都存储为边的属性（图3.10
    (a)）。
- en: As a *node* that contains all the relevant information about the event and is
    connected via edges to the related nodes. In the case of the purchase, the transaction
    itself is modeled as a node; then it is connected to the source and destination
    of the purchase (figure 3.10 (b)).
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为包含关于事件所有相关信息的一个**节点**，并通过边与相关节点相连。在购买的情况下，交易本身被建模为一个节点；然后它连接到购买的源和目的地（图3.10
    (b)）。
- en: '![CH03_F10_Negro](../Images/CH03_F10_Negro.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F10_Negro](../Images/CH03_F10_Negro.png)'
- en: Figure 3.10 Transaction modeling examples
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 交易建模示例
- en: The first approach is generally used when the amount of information related
    to the event is small or when a simpler model is preferable for the purpose of
    the analysis. The second approach is generally preferred when the event itself
    contains valuable information that could be connected to other information items
    or when the event involves more than two items.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法通常在事件相关的信息量较小或分析目的更倾向于简单模型时使用。第二种方法通常在事件本身包含有价值的信息，这些信息可以与其他信息项相关联，或者事件涉及超过两个项目时更受欢迎。
- en: Transaction graphs are quite common in fraud detection analysis and all machine
    learning projects in which each event contains relevant information that would
    be lost if the events were aggregated.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 交易图在欺诈检测分析和所有机器学习项目中都很常见，在这些项目中，每个事件都包含相关信息，如果事件被汇总，这些信息将会丢失。
- en: 3.2.3 Identify risks in a supply chain
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.3 在供应链中识别风险
- en: Suppose that you have to implement a risk management system that identifies
    or predicts possible risks in a *supply chain*. A supply chain network (SCN) is
    a common way to represent supply chain elements and their interactions in a graph.
    Such a representation, together with proper graph analysis algorithms, makes it
    easy and fast to spot issues throughout the chain.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你必须实施一个风险管理系统，该系统可以识别或预测供应链中的可能风险。供应链网络（SCN）是表示供应链元素及其交互的一种常见方式，以图形的形式。这种表示方式，加上适当的图分析算法，使得在整个供应链中快速发现问题变得容易且快速。
- en: 'This scenario has become more and more relevant in recent years, for multiple
    reasons, including the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这种场景近年来变得越来越相关，原因有很多，包括以下方面：
- en: With the development of the global economy, any supply chain can have a global
    dimension, so the problems that supply chain management faces are becoming more
    complex.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着全球经济的发展，任何供应链都可以具有全球性，因此供应链管理面临的问题正变得越来越复杂。
- en: Customers located at the end of the chain are becoming more interested in the
    origins of the products they buy.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 位于供应链末端的客户越来越关注他们所购买产品的来源。
- en: Managing the disruption risk and making the chain more transparent are mandatory
    tasks in any supply chain. Supply chains are inherently fragile and face a variety
    of threats, from natural disasters and attacks to contamination of raw products,
    delivery delays, and labor shortages [Kleindorfer and Saad, 2005]. Furthermore,
    because the parts of the chain are complex and interrelated, the normal operation
    of one member—and the efficient operation of the chain as a whole—often relies
    on the normal operation of other components. The members of a supply chain include
    suppliers, manufacturers, distributors, customers, and so on. All members are
    dependent on one another and cooperate through material, information, and financial
    flows, but they are also independent entities operating on their own, perhaps
    providing the same services to multiple companies. Therefore, the data available
    in such a scenario will be distributed across multiple companies that have different
    structures. Any kind of analysis based on data in this shape is a complex task;
    gathering the required information from the multiple members and organizing it
    requires a lot of effort.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 管理中断风险和使供应链更加透明是任何供应链中的强制性任务。供应链本质上脆弱，面临着各种威胁，包括自然灾害和攻击，以及原材料污染、交货延误和劳动力短缺[Kleindorfer和Saad，2005]。此外，由于链的各个部分复杂且相互关联，单个成员的正常运营——以及整个链的效率运营——通常依赖于其他组件的正常运营。供应链的成员包括供应商、制造商、分销商、客户等等。所有成员相互依赖，通过物质、信息和金融流进行合作，但它们也是独立实体，可能在多个公司提供相同的服务。因此，在这种场景下可用的数据将分布在具有不同结构的多个公司中。基于此类形状数据的任何分析都是一个复杂任务；从多个成员那里收集所需信息并对其进行组织需要大量努力。
- en: The purpose of the analysis here is to spot elements in the chain that, if compromised,
    can disrupt the entire network (or a large part of it) or significantly affect
    normal behavior. A graph model can support such an analysis task through different
    network analysis algorithms. We will discuss details of the algorithms in section
    3.3; here, we’ll focus on the graph construction techniques that can be used to
    build the graph representation from the multiple sources available.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 这里分析的目的在于发现链中的元素，如果这些元素受到损害，可能会破坏整个网络（或其大部分）或严重影响正常行为。图模型可以通过不同的网络分析算法支持此类分析任务。我们将在第3.3节中讨论算法的细节；在这里，我们将重点介绍可以用于从多个可用来源构建图表示的图构建技术。
- en: 'A supply chain can be represented in a graph by using the following approach:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下方法在图中表示供应链：
- en: Each member of the supply chain is represented by a node. The members could
    be raw-product suppliers (primary suppliers), secondary suppliers, intermediate
    distributors, transformation processes, organizational units in a big company,
    final retailers, and so on. The granularity of the graph is related to the risk
    evaluation required.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 供应链的每个成员都由一个节点表示。成员可以是原材料供应商（一级供应商）、二级供应商、中间分销商、转换过程、大公司中的组织单位、最终零售商等等。图的粒度与所需的风险评估相关。
- en: Each relation in the graph represents a dependency between two members of the
    chain. The relationships could include transport from a supplier to an intermediate
    distributor, a dependency between two processing steps, the delivery to the final
    retailer, and so on.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图中的每个关系都代表链中两个成员之间的依赖关系。这些关系可能包括从供应商到中间分销商的运输、两个加工步骤之间的依赖关系、最终零售商的交货等等。
- en: To each node, it is possible to relate some temporal data that could store historic
    as well as forecasting information.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个节点，可以关联一些时间数据，这些数据可以存储历史信息以及预测信息。
- en: The network structure might evolve over time as well. The graph model can be
    designed to keep track of the changes, but that design would make it too complicated
    for the purpose of this example. Our example graph model is shown in figure 3.11.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 网络结构也可能随时间而演变。图模型可以设计为跟踪这些变化，但这样的设计会使本例目的过于复杂。我们的示例图模型如图3.11所示。
- en: '![CH03_F11_Negro](../Images/CH03_F11_Negro.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F11_Negro](../Images/CH03_F11_Negro.png)'
- en: Figure 3.11 A supply chain network
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11 供应链网络
- en: This model represents an important method for gathering data and organizing
    it in an organic and homogeneous way, and it provides a suitable representation
    for the type of analysis that risk management requires. The algorithms that allow
    us to perform the analysis to reveal high-risk elements in the chain are discussed
    in sec-tion 3.3.1.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型代表了一种收集数据并以有机和均匀方式组织数据的重要方法，并为风险管理所需的分析类型提供了合适的表示。允许我们执行分析以揭示链中高风险元素的算法在3.3.1节中讨论。
- en: 3.2.4 Recommend items
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.4 推荐项目
- en: Suppose that you would like to recommend items to users in an e-commerce shop,
    using the data you have about previous interactions (clicks, purchases, ratings,
    and so on). Graphs can help you store the User-Item dataset in a way that speeds
    access to it, and storing the predictive models in the graph not only facilitates
    the predictions, but also allows you to merge multiple models smoothly.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要在电子商务商店中向用户推荐项目，使用你关于先前交互（点击、购买、评分等）的数据。图可以帮助你以加快访问速度的方式存储用户-项目数据集，并且在图中存储预测模型不仅便于预测，还允许你平滑地合并多个模型。
- en: One of the most common use cases for graphs in machine learning is recommendations.
    I wrote the first recommendation engine ever built on top of Neo4j in 2012\. That’s
    how my career with graphs started, and it’s why this specific topic is close to
    my heart. Throughout this book, using multiple examples, we will discover the
    great advantages of using graphs for building multimodel recommendation engines,
    but here, we’ll start with a simple example by considering the most basic implementation.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，图的最常见用例之一是推荐。我在2012年编写了第一个基于Neo4j构建的推荐引擎。这就是我的图学职业生涯的开始，也是为什么这个特定主题对我来说如此亲近。在这本书中，我们将通过多个示例发现使用图构建多模型推荐引擎的巨大优势，但在这里，我们将从一个简单的例子开始，考虑最基本实现。
- en: 'It is possible to use multiple approaches to provide recommendations. In this
    specific example, the approach selected is based on a technique called *collaborative
    filtering*. The main idea of collaborative approaches to recommendations is to
    exploit information about the past behavior or opinions of an existing user community
    to predict which items the current user of the system will most probably like
    or be interested in [Jannach et al., 2010]. Pure collaborative approaches take
    a matrix of given user-item interactions of any type (views, past purchases, ratings,
    and so on) as input and produce the following types of output:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用多种方法来提供推荐。在这个特定例子中，选择的方法是基于一种称为*协同过滤*的技术。协同推荐方法的主要思想是利用现有用户社区过去的行为或意见信息来预测系统当前用户最可能喜欢或感兴趣的项目
    [Jannach et al., 2010]。纯协同方法将任何类型的给定用户-项目交互矩阵（查看、过去购买、评分等）作为输入，并产生以下类型的输出：
- en: A (numerical) prediction indicating the likelihood that the current user will
    like or dislike a certain item (the relevance score)
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个（数值）预测，表示当前用户可能会喜欢或不喜欢某个特定项目的可能性（相关度得分）
- en: An ordered list of top n recommended items for a user based on the value predicted
    (from most likely to least likely)
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据预测值（从最有可能到最不可能）为用户提供的推荐项目的前n个项目的有序列表
- en: The relevance is measured by a utility function f that is estimated based on
    user feedback [Frolov and Oseledets, 2016]. More formally, the relevance function
    can be defined as
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 相关度是通过一个基于用户反馈估计的效用函数f来衡量的 [Frolov and Oseledets, 2016]。更正式地说，相关度函数可以定义为
- en: '*f*: *User* × *Item* → *Relevance Score*'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*: 用户 × 项目 → 相关度得分'
- en: where *User* is the set of all users and *Item* is the set of all items. This
    function can be used to compute the relevance scores for all the elements for
    which no information is available. The data on which the predictions are based
    can be directly provided by the users (through ratings, likes/dislikes, and so
    on) or implicitly collected by observing the users’ actions (page clicks, purchases,
    and so on). The type of information available determines the types of techniques
    that can be used to build the recommendations. A content-based approach is possible
    if information about the users (profile attributes, preferences) and items (intrinsic
    properties) can be drawn upon. If only implicit feedback is available, a collaborative
    filtering approach is required.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *用户* 是所有用户的集合，*项目* 是所有项目的集合。此函数可以用于计算所有无信息元素的关联得分。基于预测的数据可以直接由用户（通过评分、点赞/不喜欢等）或通过观察用户的行为（页面点击、购买等）隐式收集。可用的信息类型决定了可以用于构建推荐的技术类型。如果可以获取关于用户（配置文件属性、偏好）和项目（内在属性）的信息，则可以实现基于内容的推荐方法。如果只有隐式反馈可用，则需要采用协同过滤方法。
- en: After predicting relevance scores for all the unseen (or unbought) items, we
    can rank them and show the top n items to the user, performing the recommendation.
    As usual, we start our discussion from the data available. The data source in
    this case looks like table 3.3 (in which 1 is a low rating and 5 means that the
    user has a high opinion of the item).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测所有未见过（或未购买）项目的相关性得分后，我们可以对它们进行排序，并向用户展示前n个项目，从而进行推荐。像往常一样，我们从可用的数据开始讨论。在这种情况下，数据源看起来像表3.3（其中1表示低评分，5表示用户对项目的评价很高）。
- en: Table 3.3 An example User-Item dataset represented in a matrix
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.3 一个示例用户-项目数据集，以矩阵形式表示
- en: '| User | Item 1 | Item 2 | Item 3 | Item 4 | Item 5 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 用户 | 项目1 | 项目2 | 项目3 | 项目4 | 项目5 |'
- en: '| Bob | - | 3 | - | 4 | ? |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Bob | - | 3 | - | 4 | ? |'
- en: '| User 2 | 3 | 5 | - | - | 5 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 用户2 | 3 | 5 | - | - | 5 |'
- en: '| User 3 | - | - | 4 | 4 | - |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 用户3 | - | - | 4 | 4 | - |'
- en: '| User 4 | 2 | - | 4 | - | 3 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 用户4 | 2 | - | 4 | - | 3 |'
- en: '| User 5 | - | 3 | - | 5 | 4 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 用户5 | - | 3 | - | 5 | 4 |'
- en: '| User 6 | - | - | 5 | 4 | - |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 用户6 | - | - | 5 | 4 | - |'
- en: '| User 7 | 5 | 4 | - | - | 5 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 用户7 | 5 | 4 | - | - | 5 |'
- en: '| User 8 | - | - | 3 | 4 | 5 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 用户8 | - | - | 3 | 4 | 5 |'
- en: This table is a classic User-Item matrix containing the interactions (in this
    case, the ratings) between the users and the items. The cells with the symbol
    - mean that the user has not bought or rated that item. In an e-commerce scenario
    like the one we are considering, there could be a large number of users and items,
    so the resulting table could be quite sparse; each user will buy only a small
    subset of the available items, so the resulting matrix will have a lot of empty
    cells. In our example table, the unseen or unbought element that we would like
    to predict interest in is item 5 for user Bob.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表格是一个经典的用户-项目矩阵，包含了用户和项目之间的交互（在这个例子中，是评分）。带有符号-的单元格表示用户没有购买或评分该项目。在我们考虑的电子商务场景中，可能会有大量的用户和项目，因此生成的表格可能相当稀疏；每个用户只会购买一小部分可用的项目，因此生成的矩阵将有很多空单元格。在我们的示例表中，我们想要预测的用户Bob对未见过或未购买的项目5的兴趣。
- en: Starting from the data available (in the shape described) and from the basic
    idea of collaborative filtering, multiple ways of implementing this prediction
    exist. For the purpose of this scenario, in this part of the book we will consider
    the item-based algorithms. The main idea of item-based algorithms is to compute
    predictions by using the similarity between items. Therefore, we will consider
    the table column by column, with each column describing a vector of elements (called
    the rating vector) where the - symbol is replaced by a 0 value. Let’s examine
    our User-Item dataset and make a prediction for Bob for item 5\. First, we compare
    all the rating vectors of the other items and look for items that are similar
    to item 5\. Now the idea of item-based recommendation is to look at Bob’s ratings
    for these similar items. The item-based algorithm computes a weighted average
    of these other ratings and uses this average to predict a rating for item 5 for
    user Bob.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 从可用的数据（以描述的形状）和协同过滤的基本思想出发，存在多种实现这种预测的方法。为了本场景的目的，在本书的这一部分，我们将考虑基于项目的算法。基于项目的算法的主要思想是通过使用项目之间的相似度来计算预测。因此，我们将逐列考虑表格，每一列描述一个元素向量（称为评分向量），其中-符号被0值替换。让我们检查我们的用户-项目数据集，并为Bob预测第5个项目的评分。首先，我们比较其他所有项目的评分向量，寻找与项目5相似的项目。现在基于项目的推荐想法是查看Bob对这些相似项目的评分。基于项目的算法计算这些其他评分的加权平均值，并使用这个平均值来预测用户Bob对项目5的评分。
- en: 'To compute the similarity between items, we must define a similarity measure.
    Cosine similarity is the standard metric in item-based recommendation approaches:
    it determines the similarity between two vectors by calculating the cosine of
    the angle between them [Jannach et al., 2010]. In machine learning applications,
    this measure is often used to compare two text documents, which are represented
    as vectors of terms; we will use it frequently in this book.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算项目之间的相似度，我们必须定义一个相似度度量。余弦相似度是项目推荐方法中的标准度量：它通过计算两个向量之间角度的余弦值来确定两个向量之间的相似度[Jannach
    et al., 2010]。在机器学习应用中，这个度量通常用于比较两个表示为术语向量的文本文档；我们将在本书中经常使用它。
- en: 'The formula to compute the cosine of the angle between the two vectors and,
    therefore, the similarity between two items a and b, is as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 计算两个向量之间角度的余弦值以及因此两个项目a和b之间的相似度的公式如下：
- en: '![CH03_F12_EQ01_Negro](../Images/CH03_F12_EQ01_Negro.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F12_EQ01_Negro](../Images/CH03_F12_EQ01_Negro.png)'
- en: The · symbol indicates the dot product of the two vectors. |![1a_vector](../Images/1a_vector.png)| is
    the Euclidian length of the vector, which is defined as the square root of the
    dot product of the vector with itself.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ·符号表示两个向量的点积。|![1a_vector](../Images/1a_vector.png)|是向量的欧几里得长度，定义为向量与其自身点积的平方根。
- en: Figure 3.12 shows a representation of cosine distance in 2D space.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12展示了2D空间中余弦距离的表示。
- en: '![CH03_F12_Negro](../Images/CH03_F12_Negro.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F12_Negro](../Images/CH03_F12_Negro.png)'
- en: Figure 3.12 Cosine distance representation in 2D space
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 2D空间中的余弦距离表示
- en: 'To further explain the formula, let’s consider the cosine similarity of item
    5, described by the rating vector [0, 5, 0, 3, 4, 0, 5, 5], and item 1, described
    by the vector [0, 3, 0, 2, 0, 0, 5, 0]. It is calculated as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步解释公式，让我们考虑第5个项目的余弦相似度，该项目的评分向量为[0, 5, 0, 3, 4, 0, 5, 5]，以及第1个项目的向量[0, 3,
    0, 2, 0, 0, 5, 0]。计算如下：
- en: '![CH03_F13_EQ02_Negro](../Images/CH03_F13_EQ02_Negro.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F13_EQ02_Negro](../Images/CH03_F13_EQ02_Negro.png)'
- en: The numerator is the dot product between the two vectors, computed from the
    sum of the products of the corresponding entries of the two sequences of numbers.
    The denominator is the product of the Euclidian lengths of the two vectors. The
    *Euclidian distance* is the distance between two points in the multidimensional
    space of the vectors. Figure 3.13 illustrates the concept in 2D space.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 分子是两个向量之间的点积，由两个数字序列对应项的乘积之和计算得出。分母是两个向量的欧几里得长度的乘积。*欧几里得距离*是多维空间中两点之间的距离。图3.13在2D空间中说明了这一概念。
- en: '![CH03_F13_Negro](../Images/CH03_F13_Negro.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F13_Negro](../Images/CH03_F13_Negro.png)'
- en: Figure 3.13 Euclidian distance in 2D space
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13 2D空间中的欧几里得距离
- en: 'The formula is as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 公式如下：
- en: '![CH03_F13_EQ03_Negro](../Images/CH03_F13_EQ03_Negro.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F13_EQ03_Negro](../Images/CH03_F13_EQ03_Negro.png)'
- en: 'The *Euclidian length* is the Euclidian distance of the vector from the origin
    of the space (the vector [0,0,0,0,0,0,0,0], in our case):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '*欧几里得长度*是向量从空间原点（在我们的情况下是向量[0,0,0,0,0,0,0,0]）的欧几里得距离：'
- en: '![CH03_F14_EQ04_Negro](../Images/CH03_F14_EQ04_Negro.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F14_EQ04_Negro](../Images/CH03_F14_EQ04_Negro.png)'
- en: The similarity values range between 0 and 1, with 1 indicating the strongest
    similarity. Consider now that we have to compute this similarity for each pair
    of items in the database, so if we have 1 million products, we need to compute
    1M × 1M similarity values. We can reduce this number by half because similarity
    is commutative—cos(a,b) = cos(b,a)—but we still have a lot of computations to
    make. In this case, a graph can be a valuable helper to speed the machine learning
    algorithm for the recommendations. The User-Item dataset can be converted easily
    to a graph like the one in figure 3.14.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 相似度值介于0和1之间，其中1表示最强的相似度。现在考虑我们必须为数据库中的每一对物品计算这种相似度，因此如果我们有100万种产品，我们需要计算1M ×
    1M个相似度值。我们可以将这个数字减半，因为相似度是可交换的——cos(a,b) = cos(b,a)，但我们仍然有很多计算要做。在这种情况下，图可以成为加速推荐机器学习算法的有价值助手。用户-物品数据集可以很容易地转换为如图3.14所示的图。
- en: '![CH03_F14_Negro](../Images/CH03_F14_Negro.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F14_Negro](../Images/CH03_F14_Negro.png)'
- en: Figure 3.14 Bipartite graph representing the User-Item dataset
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14表示用户-物品数据集的二分图
- en: In this graph representation, all the users are on the left, and all the items
    are on the right. The relationships go only from nodes in one subset to nodes
    in the other subset; no relationships occur between nodes of the same set. This
    figure is an example of a *bipartite graph*, or *bigraph*. More formally, a *bigraph*
    is a special type of graph whose vertices (nodes) can be divided into two disjoint
    and independent sets U and V such that every edge connects a vertex in U to one
    in V, or vice versa. Vertex sets U and V are usually called the parts of the graph
    [Diestel, 2017].
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种图表示中，所有用户都在左侧，所有物品都在右侧。关系仅从一个子集的节点到另一个子集的节点；同一集合的节点之间没有关系。这个图是一个*二分图*或*双图*的例子。更正式地说，一个*双图*是一种特殊的图，其顶点（节点）可以被分为两个不相交且独立的集合U和V，使得每条边都连接U中的一个顶点到V中的一个顶点，反之亦然。顶点集U和V通常被称为图的“部分”
    [Diestel, 2017]。
- en: 'How can a bipartite graph representation reduce the number of similarity computations
    we have to perform? To understand this concept, it is necessary to understand
    cosine similarity a little better (although the principle can be extended to a
    wider set of similarity functions). The cosine similarity metric measures the
    angle between two n-dimensional vectors, so the two vectors have a cosine similarity
    equal to 0 when they are *orthogonal* (perpendicular). In the context of our example,
    this happens when there are no overlapping users between two items (users that
    rate both the items). In such cases, the numerator of the fraction will be 0\.
    We can compute the distance between item 2, described by the vector [3, 5, 0,
    0, 3, 0, 4, 0], and item 3, described by the vector [0, 0, 4, 4, 0, 5, 0, 3],
    as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如何通过二分图表示减少我们必须执行的相似度计算数量？为了理解这个概念，有必要更好地理解余弦相似度（尽管原理可以扩展到更广泛的相似度函数集）。余弦相似度度量两个n维向量之间的角度，因此当两个向量是*正交的*（垂直）时，它们的余弦相似度为0。在我们的例子中，这种情况发生在两个物品之间没有重叠用户（对两个物品都进行评分的用户）时。在这种情况下，分数的分子将为0。我们可以计算由向量[3,
    5, 0, 0, 3, 0, 4, 0]描述的物品2和由向量[0, 0, 4, 4, 0, 5, 0, 3]描述的物品3之间的距离，如下所示：
- en: '![CH03_F15_EQ05_Negro](../Images/CH03_F15_EQ05_Negro.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F15_EQ05_Negro](../Images/CH03_F15_EQ05_Negro.png)'
- en: In this case, the similarity value will be 0 (figure 3.15). In a sparse User-Item
    dataset, the probability of orthogonality is quite high, so the number of useless
    computations is correspondingly high. Using the graph representation, it is easy
    to use a simple query to find all the items that have at least one rating user
    in common. Then the similarity can be computed only between the current item and
    the overlapping items, greatly reducing the number of computations required. In
    a native graph engine, the query for searching overlapping items is fast.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，相似度值将为0（图3.15）。在稀疏的用户-物品数据集中，正交性的概率相当高，因此无用的计算数量相应地很高。使用图表示法，使用简单的查询很容易找到至少有一个评分用户的所有物品。然后，只需在当前物品和重叠物品之间计算相似度，从而大大减少所需的计算数量。在原生图引擎中，搜索重叠物品的查询速度很快。
- en: '![CH03_F15_Negro](../Images/CH03_F15_Negro.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F15_Negro](../Images/CH03_F15_Negro.png)'
- en: Figure 3.15 Two nonoverlapping items. These items have no rating users in common,
    so the cosine similarity between them is 0.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 两个不重叠的项目。这些项目没有共同的评分用户，因此它们之间的余弦相似度为0。
- en: Another approach is to separate the bipartite graph into clusters and compute
    the distance only between the items belonging to the same cluster.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是将二分图分成簇，并仅计算属于同一簇的项目之间的距离。
- en: In the scenario presented in this section, the graph model helps to improve
    performance by reducing the amount of time required to compute the similarities
    between the items and, therefore, the recommendations. In section 3.4, we will
    see how, starting from this graph model, it is possible to store the results of
    similarity computations to perform fast recommendations. Furthermore, cosine similarity
    will be used as a technique for graph construction.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节所描述的场景中，图模型通过减少计算项目相似性所需的时间来帮助提高性能，从而提高推荐的效果。在3.4节中，我们将看到如何从这一图模型出发，存储相似性计算的结果以实现快速推荐。此外，余弦相似度将被用作图构建的技术。
- en: 3.3 Algorithms
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 算法
- en: Section 3.2 described the role of the graph model in representing the training
    data that is used for the learning phase. Such a representation of the source
    of truth has multiple advantages, as described previously, whether the learning
    algorithm is graph-based or not.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 3.2节描述了图模型在表示用于学习阶段的学习数据中的作用。这种对真相来源的表示具有多种优势，如前所述，无论学习算法是否基于图。
- en: 'This section describes, again using multiple scenarios, some machine learning
    techniques that use graph algorithms to achieve the project’s goals. We’ll consider
    two approaches:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 本节再次使用多个场景，描述了一些使用图算法实现项目目标的机器学习技术。我们将考虑两种方法：
- en: The graph algorithm as the main learning algorithm
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为主要学习算法的图算法
- en: The graph algorithm as a facilitator in a more complex algorithm pipeline
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图算法作为更复杂算法管道中的促进者
- en: '![CH03_F16_Negro](../Images/CH03_F16_Negro.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F16_Negro](../Images/CH03_F16_Negro.png)'
- en: Figure 3.16 Algorithms in the mental model
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16 心理模型中的算法
- en: Figure 3.16 highlights the role of graph-based algorithms in machine learning
    projects.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16突出了图算法在机器学习项目中的作用。
- en: In the rest of the book, an entire catalog of algorithms is described in detail
    with implementation examples. In this chapter, the purpose is to highlight the
    role of graph algorithms for delivering predictions to the end user. These techniques,
    by contrast with the traditional methods, provide alternative and novel ways to
    solve the challenging problems posed by machine learning use cases. The focus
    here (and in the rest of the book) is on showing how to use these techniques in
    real-world applications, but we will also take into account the design of the
    methods introduced that are complementary or helpful in terms of performance and
    computational complexity.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的其余部分，详细描述了一个完整的算法目录，并提供了实现示例。在本章中，目的是突出图算法在向最终用户提供预测中的作用。与传统的相比，这些技术提供了解决机器学习用例提出的挑战性问题的替代和新颖的方法。在这里（以及本书的其余部分），重点是展示如何在现实世界应用中使用这些技术，但我们也会考虑引入的方法的设计，这些方法在性能和计算复杂度方面是互补或有益的。
- en: 3.3.1 Identify risks in a supply chain
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.1 识别供应链中的风险
- en: Supply chain risk management aims primarily at determining the susceptibility
    of the chain to disruptions, also known as *supply chain vulnerability* [Kleindorfer
    and Saad, 2005]. Evaluating the vulnerability of supply chain ecosystems is challenging
    because it cannot be observed or measured directly. The failure or overloading
    of a single node can lead to cascading failures spreading across the whole network.
    As a result, serious damage will occur within the supply chain system. The analysis
    of vulnerability, therefore, must take into account the entire network, evaluating
    the effect of a disruption of each node. This approach requires identifying the
    nodes that, more than others, represent critical elements in the network. If the
    supply chain is represented as a network, as in figure 3.17, several graph algorithms
    can be applied to identify nodes that expose it to greater vulnerability.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 供应链风险管理主要旨在确定供应链对中断的敏感性，也称为*供应链脆弱性* [Kleindorfer and Saad, 2005]。评估供应链生态系统的脆弱性具有挑战性，因为它不能直接观察或测量。单个节点的故障或过载可能导致整个网络发生级联故障。因此，供应链系统内部将发生严重损害。因此，脆弱性分析必须考虑整个网络，评估每个节点中断的影响。这种方法需要识别出比其他节点更能代表网络关键元素的节点。如果将供应链表示为网络，如图3.17所示，可以应用多种图算法来识别使其面临更大脆弱性的节点。
- en: The purpose of the analysis is to determine the most important or central nodes
    in the network. This type of analysis will reveal the supply chain’s nodes of
    interest—the most likely targets of attack and the nodes that require the most
    protection, because any disruption of them would gravely affect the entire supply
    chain and its ability to operate normally. In figure 3.17, for example, an issue
    with the supply of Raw Product B (the disruption could be on the provider’s end
    or in the connection) will affect the entire chain because it is on the paths
    to all the shops.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 分析的目的是确定网络中最重要或中心节点。这种类型的分析将揭示供应链感兴趣的节点——最可能成为攻击目标以及需要最多保护的节点，因为任何对这些节点的中断都将严重影响整个供应链及其正常运行能力。例如，在图3.17中，原材料B（B）的供应问题（中断可能发生在供应商端或连接处）将影响整个链条，因为它位于所有商店的路径上。
- en: '![CH03_F17_Negro](../Images/CH03_F17_Negro.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F17_Negro](../Images/CH03_F17_Negro.png)'
- en: Figure 3.17 A supply chain network
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17 供应链网络
- en: '*Importance* has many possible definitions; consequently, many centrality measures
    could be used for the network. We will consider two of them, not only because
    they are useful for the specific scenario of the supply chain, but also because
    they are powerful techniques used in multiple examples later in the book:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '*重要性*有许多可能的定义；因此，可以用于网络的许多中心性度量。我们将考虑其中两种，不仅因为它们对供应链的具体场景有用，而且因为它们是本书后面多个示例中使用的强大技术：'
- en: '*PageRank*—This algorithm works by counting the number and quality of edges
    to a node to arrive at a rough estimate of the node’s importance. The basic idea
    implemented by the PageRank model, invented by the founders of Google for their
    search engine, is that of voting or recommendation. When a node is connected to
    another node by an edge, it is basically casting a vote for that node. The more
    votes a node receives, the more important it is—but the importance of the “voters”
    matters too. Hence, the *score* associated with a node is computed based on the
    votes that are cast for it and the scores of the nodes casting those votes.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PageRank*——该算法通过计算一个节点到其他节点的边数和质量，对节点的重要性进行粗略估计。由谷歌创始人发明用于其搜索引擎的PageRank模型所实现的基本思想是投票或推荐。当一个节点通过边连接到另一个节点时，它基本上是在为该节点投票。一个节点收到的投票越多，它就越重要——但“投票者”的重要性也很重要。因此，与节点关联的*分数*是根据为其投下的投票以及投下这些投票的节点的分数来计算的。'
- en: '*Betweenness centrality*—This algorithm measures the importance of a node by
    considering how often it lies on the shortest paths between other nodes. It applies
    to a wide range of problems in network theory. In a supply chain network, for
    example, a node with higher betweenness centrality will have more control of the
    network because more goods will pass through that node.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*中间中心性*——该算法通过考虑节点在连接其他节点之间的最短路径上出现的频率来衡量节点的重要性。它适用于网络理论中的广泛问题。例如，在供应链网络中，具有更高中间中心性的节点将拥有对网络的更多控制权，因为更多的商品将通过该节点。'
- en: Figure 3.18 illustrates these two algorithms.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18说明了这两种算法。
- en: '![CH03_F18_Negro](../Images/CH03_F18_Negro.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F18_Negro](../Images/CH03_F18_Negro.png)'
- en: Figure 3.18 PageRank (a) and betweenness centrality (b) examples
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.18 PageRank（a）和中间中心性（b）示例
- en: 'In the supply chain vulnerability use case, both algorithms can be used to
    determine the most interesting nodes in the supply chain network, but from two
    different perspectives:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在供应链脆弱性用例中，两种算法都可以用来确定供应链网络中最有趣的节点，但出发点不同：
- en: '*Betweenness centrality* allows us to determine which nodes may have considerable
    influence within the supply chain by virtue of their control of the products passing
    through them. The nodes with highest centrality are also the ones whose removal
    from the supply chain network will most disrupt the products’ flow, because they
    lie on the largest number of paths taken by the products. Suppose that in the
    chain, a single company is the only provider of a basic component of all the products
    in the supply chain, or that one company operates as the sole distributor of a
    particular product. In both cases, the greatest number of paths for that component
    or product pass through them, and any serious disruption of these nodes would
    affect the entire supply chain.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*中间中心性*使我们能够通过它们控制通过的产品来识别在供应链中可能具有相当影响力的节点。具有最高中心性的节点也是那些从供应链网络中移除将最严重干扰产品流动的节点，因为它们位于产品采取的最大路径数量上。假设在供应链中，一家公司是所有产品基本组件的唯一供应商，或者一家公司作为特定产品的唯一分销商运营。在这两种情况下，该组件或产品的最大路径数量都通过它们，任何对这些节点的严重干扰都会影响整个供应链。'
- en: '*PageRank* allows us to identify nodes that, according to the relative importance
    of the nodes they are connected to, have a high value in the network. In this
    case, disrupting an important node might affect only a small portion of the network,
    but the disruption could still be significant. Suppose that in the chain, a transformation
    process converts a product to a form suitable only for one of the biggest end
    customers of the supply chain. In this case, not many paths pass through the process,
    so the node’s betweenness centrality is quite low, but the value of the node is
    high because disrupting it would affect an important element in the chain.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*PageRank*使我们能够识别节点，根据它们连接的节点的相对重要性，这些节点在网络中具有高价值。在这种情况下，破坏一个重要节点可能只会影响网络的一小部分，但破坏仍然可能是重大的。假设在供应链中，一个转换过程将产品转换为仅适合供应链中最大的最终客户之一的形式。在这种情况下，通过该过程的路径不多，因此节点的中间中心性相当低，但节点的价值很高，因为破坏它会影响链中的重要元素。'
- en: As these examples illustrate, graph algorithms provide a powerful analysis mechanism
    for supply chain networks. This approach can be generalized for many similar scenarios,
    such as communication networks, social networks, biological networks, and terrorist
    networks.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如这些示例所示，图算法为供应链网络提供了一种强大的分析机制。这种方法可以推广到许多类似场景，例如通信网络、社交网络、生物网络和恐怖主义网络。
- en: 3.3.2 Find keywords in a document
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.2 在文档中查找关键词
- en: Suppose that you would like to identify automatically a set of terms that best
    describe a document or an entire corpus. Using a graph-based ranking model, you
    can find the most relevant words or phrases in the text via an unsupervised learning
    method.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想自动识别一组最能描述文档或整个语料库的术语。使用基于图排序的模型，你可以通过无监督学习方法找到文本中最相关的话语或短语。
- en: Companies often need to manage and work with large amounts of data, whether
    to provide services to end users or for internal processes. Most of this data
    takes the form of text. Because of the unstructured nature of textual data, accessing
    and analyzing this vast source of knowledge can be a challenging and complex task.
    Keywords can provide effective access to a large corpus of documents by helping
    to identify the main concepts. Keyword extraction can also be used to build an
    automatic index for a document collection, to construct domain-specific dictionaries,
    or to perform text classification or summarization tasks [Negro et al., 2017].
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 公司通常需要管理和处理大量数据，无论是为了向最终用户提供服务还是为了内部流程。其中大部分数据以文本形式存在。由于文本数据的非结构化特性，访问和分析这一庞大的知识来源可能是一项具有挑战性和复杂性的任务。关键词可以帮助识别主要概念，从而有效地访问大量文档。关键词提取还可以用于为文档集合构建自动索引、构建特定领域的词典或执行文本分类或摘要任务
    [Negro 等人，2017]。
- en: Multiple techniques, some of them simple and others more complex, can be used
    to extract a list of keywords from a corpus. The simplest possible approach is
    to use a relative-frequency criterion (identifying the terms that occur most frequently)
    to select the important keywords in a document—but this method lacks sophistication
    and typically leads to poor results. Another approach involves using supervised
    learning methods, wherein a system is trained to recognize keywords in a text
    based on lexical and syntactic features—but a lot of labeled data (text with the
    related keywords extracted manually) is required to train a model accurate enough
    to produce good results.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用多种技术从语料库中提取关键词列表。最简单的方法是使用相对频率标准（识别出现频率最高的术语）来选择文档中的重要关键词——但这种方法缺乏复杂性，通常会导致较差的结果。另一种方法涉及使用监督学习方法，其中系统被训练根据词汇和句法特征来识别文本中的关键词——但需要大量的标记数据（手动提取相关关键词的文本）来训练一个足够准确以产生良好结果的模型。
- en: Graphs can be your secret weapon for solving a complex problem like this one,
    providing a mechanism to extract keywords or sentences from the text in an unsupervised
    manner by using a graph representation of the data and a graph algorithm like
    PageRank. *TextRank* [Mihalcea and Tarau, 2004] is a graph-based ranking model
    that can be used for this kind of text processing.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图可以成为解决这类复杂问题的秘密武器，通过使用数据图的表示和图算法（如PageRank）以无监督的方式从文本中提取关键词或句子。*TextRank* [Mihalcea
    and Tarau, 2004] 是一种基于图的排名模型，可用于此类文本处理。
- en: 'In this case, we need to build a graph that represents the text and interconnects
    words or other text entities with meaningful relations. Depending on the purpose,
    the text units extracted—keywords, phrases, or entire sentences for summarization—can
    be added as nodes in the graph. Similarly, the final scope defines the types of
    relations that are used to connect the nodes (lexical or semantic relations, contextual
    overlap, and so on). Regardless of the type and characteristics of the elements
    added to the graph, the application of TextRank to natural language texts consists
    of the following steps [Mihalcea and Tarau, 2004]:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们需要构建一个表示文本并使用有意义的关联将单词或其他文本实体相互连接的图。根据目的，提取的文本单元——可以是用于摘要的关键词、短语或整个句子——可以作为图中的节点添加。同样，最终范围定义了用于连接节点的关系的类型（词汇或语义关系、上下文重叠等）。无论添加到图中的元素类型和特征如何，将TextRank应用于自然语言文本的过程包括以下步骤
    [Mihalcea and Tarau, 2004]：
- en: Identify text units relevant to the task at hand, and add them to the graph
    as nodes.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定与当前任务相关的文本单元，并将它们作为节点添加到图中。
- en: Identify relations that connect the text units. The edges between nodes can
    be directed or undirected and weighted or unweighted.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定连接文本单元的关系。节点之间的边可以是有向的或无向的，可以是加权的或无权的。
- en: Iterate the graph-based ranking algorithm until convergence or until the maximum
    number of iterations is reached.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迭代基于图的排名算法，直到收敛或达到最大迭代次数。
- en: Sort the nodes based on their final scores, use these scores for ranking/selection
    decisions, and eventually merge two or more text units in a single (phrase) keyword.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据最终得分对节点进行排序，使用这些得分进行排名/选择决策，并最终将两个或多个文本单元合并为一个（短语）关键词。
- en: The nodes, therefore, are sequences of one or more lexical units extracted from
    text, and they are the elements that will be ranked. Any relation that can be
    defined between two lexical units is a potentially useful connection (edge) that
    can be added between the nodes. For keyword extraction, one of the most effective
    methods of identifying relationships is co-occurrence. In this case, two nodes
    are connected if both occur within a window of a maximum of N words (an N-gram),
    with N typically being between 2 and 10\. This case is another example (maybe
    one of the most common) of using a co-occurrence graph; figure 3.19 shows an example
    of the result. Additionally, it is possible to use syntactic filters to select
    only lexical units of certain parts of speech (only nouns, verbs, and/or adjectives,
    for example).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，节点是从文本中提取的一个或多个词汇单元的序列，它们是将被排名的元素。任何可以在两个词汇单元之间定义的关系都是可以在节点之间添加的潜在有用连接（边）。对于关键词提取，识别关系最有效的方法之一是共现。在这种情况下，如果两个节点都出现在最多N个单词（N-gram）的窗口内，则两个节点是连接的，N通常在2到10之间。这种情况是使用共现图的一个例子（可能是最常见的例子之一）；图3.19显示了结果的一个示例。此外，还可以使用句法过滤器来选择特定词性的词汇单元（例如，仅名词、动词和/或形容词）。
- en: '![CH03_F19_Negro](../Images/CH03_F19_Negro.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F19_Negro](../Images/CH03_F19_Negro.png)'
- en: Figure 3.19 A co-occurrence graph created by TextRank
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.19 TextRank 创建的共现图
- en: When the graph has been constructed, the TextRank algorithm can be run on it
    to identify the most important nodes. Each node in the graph is initially assigned
    a value of 1, and the algorithm runs until it converges below a given threshold
    (usually for 20 to 30 iterations, at a threshold of 0.0001). After a final score
    has been determined for each node, the nodes are sorted in reverse order by score,
    and postprocessing is performed on the top T nodes (typically between 5 and 20).
    During this postprocessing, words that appear one after the other in the text
    and are both relevant are merged into a single keyword.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 当图构建完成后，可以在其上运行 TextRank 算法以识别最重要的节点。图中的每个节点最初被分配一个值为 1 的值，算法运行直到收敛到给定的阈值以下（通常为
    20 到 30 次迭代，阈值为 0.0001）。为每个节点确定最终分数后，节点按分数降序排序，并对前 T 个节点（通常为 5 到 20 个）进行后处理。在此后处理过程中，文本中连续出现且都相关的单词合并成一个关键词。
- en: The accuracy achieved by this unsupervised graph-based algorithm matches that
    of any supervised algorithm [Mihalcea and Tarau, 2004]. This result indicates
    that with a graph approach, it’s possible to avoid the considerable effort supervised
    algorithms require to provide prelabeled data for a task such as the one described
    here.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这种无监督的基于图的算法所达到的准确性与任何监督算法相当 [Mihalcea and Tarau, 2004]。这一结果表明，使用图方法，可以避免监督算法在提供预标记数据时所需的相当大的努力，例如本节所描述的任务。
- en: 3.3.3 Monitor a subject
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.3 监控一个主题
- en: Let’s continue our discussion of how to monitor a subject’s movements by using
    cellular tower data. Earlier in this chapter, we discussed how to convert the
    data distributed across multiple towers or multiple phones and stored in a tabular
    format to a homogeneous graph called a CTN (shown again here in figure 3.20).
    As explained in chapter 2, the nodes in the graph that have the highest total
    edge weight correspond to the towers that are most often visible to the subject’s
    phone [Eagle, Quinn, and Clauset, 2009].
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论如何通过使用蜂窝基站数据来监控主题的运动。在本章前面，我们讨论了如何将分布在不同塔或多个手机上并以表格格式存储的数据转换为同质图，称为 CTN（如图
    3.20 所示）。正如第 2 章所述，图中具有最高总边权重的节点对应于最常被主题的手机看到的塔 [Eagle, Quinn, and Clauset, 2009]。
- en: '![CH03_F20_Negro](../Images/CH03_F20_Negro.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F20_Negro](../Images/CH03_F20_Negro.png)'
- en: Figure 3.20 A graph representation of the CTN for a single subject
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.20 单个主题的 CTN 图表示
- en: The graph construction described earlier in this chapter was a preliminary task
    for using graph clustering algorithms that allow us to identify groups of towers.
    The logic here is that a group of nodes connected to one another by heavily weighted
    edges and to other nodes by less heavily weighted edges should correspond to a
    location where the monitored subject spends a significant amount of time. *Graph
    clustering* is an unsupervised learning method that aims to group the nodes of
    the graph in clusters, taking into consideration the edge structure of the graph
    in such a way that there should be many edges within each cluster and relatively
    few between the clusters [Schaeffer, 2007]. Multiple techniques and algorithms
    exist for this purpose and are discussed extensively in the rest of the book.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 本章前面描述的图构建是一个初步任务，用于使用允许我们识别塔群组的图聚类算法。这里的逻辑是，通过大量加权边相互连接，并通过较少加权边与其他节点连接的一组节点应该对应于监控主题花费大量时间的位置。*图聚类*是一种无监督学习方法，旨在根据图中的边结构将图中的节点分组，使得每个簇内部应该有许多边，而簇之间的边相对较少
    [Schaeffer, 2007]。为此目的存在多种技术和算法，并在本书的其余部分进行了广泛讨论。
- en: When the graph is organized into multiple subgraphs that identify locations,
    the next step is using this information to build a predictive model that is able
    to indicate where the subject is likely to go next, based on their current position.
    The clusters of towers identified previously can be incorporated as states of
    a *dynamic model*.[⁵](#pgfId-1010064) Given a sequence of locations visited by
    a subject, the algorithm learns patterns in the subject’s behavior and is able
    to calculate the probability that the subject will move to different locations
    in the future. The algorithm used for the modeling here [Eagle, Quinn, and Clauset,
    2009] is a dynamic Bayesian network that is introduced together with a simpler
    approach, the Markov chain, in section 3.4.2.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 当图被组织成多个子图以识别位置时，下一步是使用这些信息构建一个预测模型，该模型能够根据当前位置指示主题可能去往的下一个位置。之前识别出的塔群可以作为*动态模型*的状态。[⁵](#pgfId-1010064)
    给定一个主题访问的位置序列，算法学习主题行为中的模式，并能够计算主题在未来移动到不同位置的概率。这里用于建模的算法 [Eagle, Quinn, and Clauset,
    2009] 是一个动态贝叶斯网络，它在与更简单的方法（马尔可夫链）一起在3.4.2节中介绍。
- en: Whereas in the previous scenario, applying the graph algorithm (TextRank) was
    the main and only necessary action, here, because the problem is more complex,
    the graph algorithm is used as part of a more articulated learning pipeline to
    create an advanced prediction model.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一种场景中，应用图算法（TextRank）是主要且唯一必要的操作，而在这里，由于问题更加复杂，图算法被用作更细致的学习流程的一部分，以创建一个高级预测模型。
- en: 3.4 Storing and accessing machine learning models
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.4 存储和访问机器学习模型
- en: The third step in the workflow involves delivering predictions to end users.
    The output of the learning phase is a model that contains the result of the inference
    process and allows us to make predictions about unseen instances. The model has
    to be stored in permanent storage or in memory so that it can be accessed whenever
    a new prediction is required. The speed at which we can access the model affects
    the prediction performance. This time aspect is fundamental to the machine learning
    project’s definition of success. If the accuracy of the resulting model is high,
    but it requires a long time for prediction, the system will not be able to accomplish
    the task properly.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程的第三步涉及将预测结果交付给最终用户。学习阶段的输出是一个包含推理过程结果的模型，并允许我们对未见实例进行预测。该模型必须存储在永久存储或内存中，以便在需要新的预测时可以访问。我们可以访问模型的速度会影响预测性能。这一时间因素对于机器学习项目成功定义至关重要。如果最终模型的准确性很高，但预测需要很长时间，系统将无法正确完成任务。
- en: Figure 3.21 summarizes how graphs contributes to this phase.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.21总结了图如何贡献这一阶段。
- en: '![CH03_F21_Negro](../Images/CH03_F21_Negro.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F21_Negro](../Images/CH03_F21_Negro.png)'
- en: Figure 3.21 Storing and accessing models in the mental model
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.21 在心智模型中存储和访问模型
- en: 'Consider the recommendation scenario for an e-commerce site. The user is looking
    for something but does not have a specific idea about what product to buy, so
    they start their navigation with a text search and then click here and there in
    the results list, navigating through the several options. At this point, the system
    starts recommending items to the user according to the navigation path and the
    clicks. All this is done in a matter of moments: with a decent network, the user
    navigates quickly, moving from one page to the next every 5 to 10 seconds or less.
    Therefore, if the recommendation process requires 10 or more seconds, it is useless.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑电子商务网站的推荐场景。用户正在寻找某物，但没有具体的产品购买想法，因此他们从文本搜索开始导航，然后在结果列表中这里点击那里，浏览几个选项。在这个时候，系统开始根据导航路径和点击推荐项目给用户。所有这些都在瞬间完成：在有相当的网络条件下，用户可以快速导航，每5到10秒或更短的时间内从一个页面跳转到下一个页面。因此，如果推荐过程需要10秒或更长时间，那就毫无意义。
- en: This example shows the importance of having a system that is able to provide
    predictions quickly. In this sense, providing fast access to the model is a key
    aspect of success, and again, graphs can play an important role. This section
    explores, through some explanatory scenarios, the use of graphs for storing prediction
    models and providing fast access to them.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子展示了拥有一个能够快速提供预测的系统的重要性。在这种情况下，提供快速访问模型是成功的关键，而且，图可以再次发挥重要作用。本节通过一些解释性场景，探讨了使用图存储预测模型并提供快速访问的方法。
- en: 3.4.1 Recommend items
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.1 推荐项目
- en: The item-based (or user-based) approach to collaborative filtering produces
    as a result of the learning phase an Item-Item matrix that contains the similarity
    between each pair of items in the User-Item dataset. The resulting matrix looks
    like table 3.4.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 基于物品（或基于用户）的协同过滤方法在学习阶段的结果是一个包含用户-物品数据集中每对物品之间相似度的物品-物品矩阵。生成的矩阵看起来像表3.4。
- en: Table 3.4 Similarity matrix
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.4 相似度矩阵
- en: '|  | Item 1 | Item 2 | Item 3 | Item 4 | Item 5 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '|  | 物品1 | 物品2 | 物品3 | 物品4 | 物品5 |'
- en: '| Item 1 | 1 | 0.26 | 0.84 | 0 | 0.25 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 物品1 | 1 | 0.26 | 0.84 | 0 | 0.25 |'
- en: '| Item 2 | 0.26 | 1 | 0 | 0.62 | 0.25 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 物品2 | 0.26 | 1 | 0 | 0.62 | 0.25 |'
- en: '| Item 3 | 0.84 | 0 | 1 | 0.37 | 0.66 |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 物品3 | 0.84 | 0 | 1 | 0.37 | 0.66 |'
- en: '| Item 4 | 0 | 0.62 | 0.37 | 1 | 0.57 |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 物品4 | 0 | 0.62 | 0.37 | 1 | 0.57 |'
- en: '| Item 5 | 0.25 | 0.25 | 0.66 | 0.57 | 1 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 物品5 | 0.25 | 0.25 | 0.66 | 0.57 | 1 |'
- en: 'Having determined the similarities between the items, we can predict a rating
    for Bob for item 5 by calculating a weighted sum of Bob’s ratings for the items
    that are similar to item 5\. Formally, we can predict the rating of user u for
    a product p as follows [Jannach et al., 2010]:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 确定了物品之间的相似性后，我们可以通过计算与物品5相似的物品的Bob的评分的加权总和来预测Bob对物品5的评分。形式上，我们可以预测用户u对产品p的评分如下[Jannach等人，2010]：
- en: '![CH03_F22_EQ06_Negro](../Images/CH03_F22_EQ06_Negro.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F22_EQ06_Negro](../Images/CH03_F22_EQ06_Negro.png)'
- en: In this formula, the numerator contains the sum of the multiplication of the
    similarity value of each product that Bob rated to the target product and his
    rating of that product. The denominator contains the sum of all the similarity
    values of the items rated by Bob to the target product.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，分子包含Bob对目标产品评分的每个产品的相似值与他对该产品的评分的乘积之和。分母包含Bob对目标产品评分的所有物品的相似值之和。
- en: Let’s consider only the line of the User-Item dataset shown in table 3.5 (technically,
    a slice of the User-Item matrix).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们只考虑表3.5中显示的用户-物品数据集的行（技术上，是用户-物品矩阵的一个切片）。
- en: Table 3.5 User-Item slice for user Bob
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.5 用户Bob的用户-物品切片
- en: '| User | Item 1 | Item 2 | Item 3 | Item 4 | Item 5 |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 用户 | 物品1 | 物品2 | 物品3 | 物品4 | 物品5 |'
- en: '| Bob | - | 3 | - | 4 | ? |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| Bob | - | 3 | - | 4 | ? |'
- en: 'The preceding formula will appear as follows:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 上述公式将如下所示：
- en: '![CH03_F22_EQ07_Negro](../Images/CH03_F22_EQ07_Negro.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F22_EQ07_Negro](../Images/CH03_F22_EQ07_Negro.png)'
- en: The Item-Item similarity matrix from table 3.4 can be stored in the graph easily.
    Starting from the bipartite graph created for storing the User-Item matrix, storing
    this matrix is a matter of adding new relationships that connect items to other
    items (so the graph will not be bipartite anymore). The weight of the relationship
    is the value of the similarity, between 0 (in this case, no relationship is stored)
    and 1\. The resulting graph looks like figure 3.22.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.4中的物品-物品相似度矩阵可以轻松存储在图中。从为存储用户-物品矩阵而创建的二部图开始，存储这个矩阵就是添加新的关系，这些关系将物品连接到其他物品（因此图将不再是二部图）。关系的权重是相似度的值，介于0（在这种情况下，不存储任何关系）和1之间。生成的图看起来像图3.22。
- en: '![CH03_F22_Negro](../Images/CH03_F22_Negro.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F22_Negro](../Images/CH03_F22_Negro.png)'
- en: Figure 3.22 Similarity distance model stored in the original bipartite graph
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.22 存储在原始二部图中的相似度距离模型
- en: In this figure, to reduce the number of arcs connecting the nodes, bidirectional
    relationships between items are represented; in reality, they are two different
    relationships. Additionally, because the number of relationships is N x N, it
    could be quite difficult, in terms of both reading and writing, to store all the
    relationships. The typical approach is to store only the top K relationships for
    each node. When all the similarities are computed for each other item, they are
    sorted in descending order, from the most similar to the least similar, and only
    the first K are stored, because during the computation of the prediction, only
    the top K will be used. When the data is stored in this way, computing the topmost
    interesting item for a user is a matter of a few hops in the graph. According
    to the formula, all the items the target user rated are considered (in our case,
    items 2 and 4 are connected to the user Bob), and then for each of them, the similarity
    to the target item (item 5) is taken. The information for computing the prediction
    is local to the user, so making the prediction using the graph model presented
    is fast. There is no need for long data lookups.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在此图中，为了减少连接节点的弧的数量，表示了项目之间的双向关系；在现实中，它们是两种不同的关系。此外，由于关系的数量是 N x N，从阅读和写作的角度来看，存储所有关系可能相当困难。典型的方法是只为每个节点存储前
    K 个关系。当为每个项目计算所有相似性后，它们按降序排列，从最相似到最不相似，只存储前 K 个，因为在预测计算过程中，只使用前 K 个。以这种方式存储数据时，计算用户最感兴趣的项目只需在图中跳跃几次。根据公式，考虑了目标用户评价的所有项目（在我们的案例中，项目
    2 和 4 与用户 Bob 相连），然后对每个项目，计算与目标项目（项目 5）的相似度。用于计算预测的信息是本地化的，因此使用所提出的图模型进行预测速度快。无需进行长时间的数据查找。
- en: Furthermore, it is possible to store more types of relationships and navigate
    them at the same time during the prediction to provide combined predictions based
    on multiple similarity measures. These predictions could be based on approaches
    other than pure collaborative filtering. We will discuss other techniques for
    computing similarity or distance (the same concept from a different point of view)
    in part 3 of the book.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在预测过程中，可以存储更多类型的关系，并同时导航它们，以基于多个相似性度量提供组合预测。这些预测可以基于除了纯协同过滤之外的方法。我们将在本书的第
    3 部分讨论计算相似度或距离（从不同角度的相同概念）的其他技术。
- en: 3.4.2 Monitoring a subject
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.2 监控一个主题
- en: In the subject-monitoring scenario, after the identification of clusters of
    towers that represent locations where the subject spends significant amounts of
    time, the algorithm continues by learning patterns in the subject’s behavior.
    Then we can use dynamic models, such as a dynamic Bayesian network, to build a
    predictive model for subject location.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在主题监控场景中，在识别代表主题花费大量时间的地点的塔群之后，算法继续通过学习主题的行为模式。然后我们可以使用动态模型，如动态贝叶斯网络，来构建主题位置的预测模型。
- en: 'A *Bayesian network* is a directed graph in which each node is annotated with
    quantitative probability information (such as 50% or 0.5, 70% or 0.7). The Bayesian
    network (aka *probabilistic graphical model* or *belief network*) represents a
    mix of probability theory and graph theory in which dependencies between variables
    are expressed graphically. The graph not only helps the user understand which
    variables affect which other ones, but also enables efficient computing of marginal
    and conditional probabilities that may be required for inference and learning.
    The full specification is as follows [Russell and Norvig, 2009]:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '*贝叶斯网络* 是一个有向图，其中每个节点都标注了定量概率信息（例如 50% 或 0.5，70% 或 0.7）。贝叶斯网络（又称 *概率图模型* 或
    *信念网络*）代表了概率理论和图理论相结合的混合体，其中变量之间的依赖关系以图形方式表示。该图不仅有助于用户理解哪些变量影响哪些其他变量，而且还能有效地计算可能用于推理和学习的边缘概率和条件概率。完整的规范如下
    [Russell and Norvig, 2009]:'
- en: '*Each node corresponds to a random variable. These variables may be observable
    quantities, latent variables, unknown parameters, or hypotheses.*'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '*每个节点对应一个随机变量。这些变量可能是可观察的数量、潜在变量、未知参数或假设。*'
- en: '*Edges represent conditional dependencies. If there is an edge from node X
    to node Y, X is said to be a parent of Y. The graph has no directed cycles (and
    hence is a directed acyclic graph, or DAG). Nodes that are not connected (where
    there is no path between the variables in the Bayesian network) represent variables
    that are conditionally independent.*'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '*边代表条件依赖。如果从节点 X 到节点 Y 有边，则称 X 为 Y 的父节点。该图没有有向循环（因此是一个有向无环图，或 DAG）。没有连接的节点（在贝叶斯网络中变量之间没有路径）代表条件独立的变量。*'
- en: '*Each node Xi has a conditional probability distribution P(Xi, Parents(Xi))
    that quantifies the effect of the parents on the node. In other words, each node
    is associated with a probability function that takes (as input) a particular set
    of values for the node’s parent variables and gives (as output) the probability,
    or probability distribution, if applicable, of the variable represented by the
    node.*'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '*每个节点 Xi 都有一个条件概率分布 P(Xi, Parents(Xi))，它量化了父节点对节点的影响。换句话说，每个节点都与一个概率函数相关联，该函数接受节点父变量的一组特定值作为输入，并给出节点所代表变量的概率，或适用的概率分布。*'
- en: 'To make this discussion clearer, consider a simple example [Russell and Norvig,
    2009]:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '为了使这个讨论更清晰，考虑一个简单的例子 [Russell and Norvig, 2009]:'
- en: '*You have a new burglar alarm installed at home. It is fairly reliable at detecting
    a burglary, but also responds on occasion to minor earthquakes. . . . You also
    have two neighbors, John and Mary, who have promised to call you at work when
    they hear the alarm. John nearly always calls when he hears the alarm, but sometimes
    confuses the telephone ringing with the alarm and calls then, too. Mary, on the
    other hand, likes rather loud music and often misses the alarm altogether. Given
    the evidence of who has or has not called, we would like to estimate the probability
    of a burglary.*'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '*你在家里安装了一个新的防盗报警器。它相当可靠地检测到盗窃，但有时也会对轻微的地震做出反应……你还有两个邻居，约翰和玛丽，他们承诺在听到警报时给你打电话。约翰几乎每次听到警报都会打电话，但有时会把电话铃声误认为是警报，然后也会打电话。另一方面，玛丽喜欢很响的音乐，经常完全错过警报。根据谁打电话或没打电话的证据，我们想要估计盗窃的概率。*'
- en: The related Bayesian network for this example appears in figure 3.23\. Burglaries
    and earthquakes have a direct effect on the probability that the alarm will go
    off, as illustrated by the directed edges that connect the Burglary and Earthquake
    nodes at the top to the Alarm node. At the bottom, you can see that whether John
    or Mary calls depends only on the alarm (denoted by the edges connecting Alarm
    to the JohnCalls and MaryCalls nodes). They do not perceive the burglaries directly
    or notice minor earthquakes, and they do not confer before calling.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 与此例相关的贝叶斯网络如图 3.23 所示。盗窃和地震直接影响报警器发出警报的概率，这由连接顶部 Burglary 和 Earthquake 节点到 Alarm
    节点的有向边表示。在底部，你可以看到约翰或玛丽是否打电话只取决于警报（由连接 Alarm 到 JohnCalls 和 MaryCalls 节点的边表示）。他们没有直接感知盗窃或注意到轻微的地震，并且在打电话之前没有进行协商。
- en: In figure 3.23, the tables near each node are the conditional distributions,
    represented as conditional probability tables (CPTs). A *conditional distribution*
    is a probability distribution for a subpopulation. Each row in a CPT contains
    the conditional probability of each node value, given the possible combinations
    of values for the parent nodes. P(B) represents the probability of a burglary
    happening, for example, and P(E) represents the probability of an earthquake happening.
    These distributions are simple because they don’t depend on any other event. P(J),
    the probability that John will call, and P(M), the probability that Mary will
    call, depend on the alarm. The CPT for JohnCalls says that if the alarm is going
    off, the probability that John will call is 90%, whereas the probability of him
    calling when the alarm is not going off (recall that John can confuse the phone
    ringing with an alarm) is 5%. A little more complex is the CPT for the Alarm node,
    which depends on the Burglary and Earthquake nodes. Here, P(A) (the probability
    that the alarm will go off) is 95% when a burglary and an earthquake happen at
    the same time, but it is 94% in the case of a burglary that does not coincide
    with an earthquake and 29% in the case of an earthquake with no burglary. A false
    alarm is rare, with a probability of 0.1%.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3.23中，每个节点附近的表格是条件分布，表示为条件概率表（CPT）。*条件分布*是子群体的概率分布。CPT中的每一行包含每个节点值的条件概率，给定父节点值的可能组合。P(B)代表发生盗窃的概率，例如，P(E)代表发生地震的概率。这些分布很简单，因为它们不依赖于任何其他事件。P(J)，约翰打电话的概率，和P(M)，玛丽打电话的概率，依赖于警报。JohnCalls的条件概率表表明，如果警报响起，约翰打电话的概率是90%，而当他没有响起警报时（记住，约翰可能会把电话铃声误认为是警报）打电话的概率是5%。Alarm节点的CPT稍微复杂一些，它依赖于Burglary和Earthquake节点。在这里，当盗窃和地震同时发生时，P(A)（警报响起的概率）是95%，但在盗窃与地震不同时发生的情况下是94%，在没有盗窃的情况下发生地震时是29%。误报很少见，概率为0.1%。
- en: '![CH03_F23_Negro](../Images/CH03_F23_Negro.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F23_Negro](../Images/CH03_F23_Negro.png)'
- en: Figure 3.23 A typical Bayesian network, showing both the topology and the conditional
    probability tables
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.23 一个典型的贝叶斯网络，显示了拓扑结构和条件概率表
- en: A *dynamic Bayesian network* (DBN) is a special type of Bayesian network that
    relates variables over adjacent time steps. Returning to our subject-monitoring
    scenario, the simplest version of a DBN that can be used for performing a location
    prediction is a *Markov chain*. The example shown in figure 3.24 is a pure graph,
    a special case of the more general graph representation of a Bayesian network.
    Nodes in this case represent the status (in our case, the subject’s location)
    at point t, and the weights of the relationships represent the probability of
    a status transition at time t + 1.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '*动态贝叶斯网络*（DBN）是一种特殊的贝叶斯网络，它关联相邻时间步的变量。回到我们的主题监控场景，用于执行位置预测的最简单的DBN版本是*马尔可夫链*。图3.24中显示的例子是一个纯图，是贝叶斯网络更一般图表示的特殊情况。在这种情况下，节点代表t点的状态（在我们的例子中，是主题的位置），关系的权重代表t+1时间步状态转换的概率。'
- en: In the graph in figure 3.24, if the subject is at Home at time t, it is most
    likely that they will stay at home (45%). The probability that they will move
    to the Office is 25%; there is a 20% likelihood that they will instead go to the
    Market and a 10% probability that they will go to the School (perhaps to drop
    off the kids). This example is the representation of a model built from the observations.
    Starting from this model, computing the probability of a location t-step-ahead
    is a path navigation among nodes in which each node can appear more times.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3.24中，如果某人在时间t处于家中，他们最有可能留在家里（45%）。他们移动到办公室的概率是25%；他们去市场的可能性是20%，他们去学校的可能性是10%（可能是送孩子）。这个例子是观察到的模型表示。从这个模型开始，计算t步后的位置概率是在节点之间进行路径导航，其中每个节点可以出现多次。
- en: '![CH03_F24_Negro](../Images/CH03_F24_Negro.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F24_Negro](../Images/CH03_F24_Negro.png)'
- en: Figure 3.24 A simple Markov chain. (The most probable movement is shown in red.)
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.24 一个简单的马尔可夫链。（最可能的移动用红色表示。）
- en: This approach can be extended further. Eagle, Quinn, and Clauset [2009] noticed
    that patterns of movement for people in practice depend on the time of day and
    day of the week (Saturday night versus Monday morning, for example). Therefore,
    they created an extended model based on a *contextual Markov chain* (CMC), in
    which the probability of the subject being in a location is also dependent on
    the hour of the day and the day of the week (which represent the context). The
    CMC is not described in detail here, but figure 3.25 shows the basic ideas behind
    it.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可以进一步扩展。Eagle、Quinn和Clauset [2009] 注意到，实践中人们的移动模式取决于一天中的时间和一周中的某一天（例如周六晚上与周一早晨）。因此，他们基于*上下文马尔可夫链*（CMC）创建了一个扩展模型，其中主题位于某个位置的概率也取决于一天中的小时和一周中的某一天（这些代表上下文）。CMC在此处不做详细描述，但图3.25展示了其背后的基本思想。
- en: '![CH03_F25_Negro](../Images/CH03_F25_Negro.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F25_Negro](../Images/CH03_F25_Negro.png)'
- en: 'Figure 3.25 A simple contextual Markov chain for two values of the context:
    C = {midday, weekend} (a), and C = {morning, weekday} (b)'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.25 两个上下文值的一个简单上下文马尔可夫链：C = {中午，周末}（a），和C = {早晨，工作日}（b）
- en: The context is created considering the time of day, defined as “morning,” “afternoon,”
    “evening,” or “night,” and the day of the week, split into “weekday” or “weekend.”
    The graphs in figure 3.25 represent the resulting Markov chains after learning
    the maximum likelihood parameters for each context. Figure 3.25(a) shows the Markov
    chain for a midday during the weekend, so there is no school for the kids, and
    there is no work at the office. Figure 3.25(b) shows the Markov chain related
    to a morning on a weekday. Such graphs allow us to compute, through a simple query
    on the graph, a prediction of where the subject is most likely to go next.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到一天中的时间，定义为“上午”、“下午”、“傍晚”或“夜间”，以及一周中的某一天，分为“工作日”或“周末”，来创建上下文。图3.25中的图表表示学习每个上下文的最大似然参数后的结果马尔可夫链。图3.25(a)显示了周末中午的马尔可夫链，因此孩子们没有学校，办公室也没有工作。图3.25(b)显示了工作日早晨相关的马尔可夫链。这样的图表使我们能够通过在图上简单查询，预测主题最有可能去的地方。
- en: Markov chains, CMCs, and more generally (dynamic) Bayesian networks are prediction
    models that work for a lot of use cases. The subject-monitoring scenario is used
    to illustrate here, but such models are actively used in many kinds of user modeling
    and especially in web analysis to predict user intentions.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链、CMC以及更一般地（动态）贝叶斯网络是适用于许多用例的预测模型。此处使用主题监控场景进行说明，但此类模型在许多类型的用户建模和尤其是在网络分析中积极用于预测用户意图。
- en: 3.5 Visualization
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.5 可视化
- en: One of the main goals of machine learning is to make sense of data and deliver
    some sort of predictive capability to the end user (although as described at the
    beginning of this chapter, data analysis in general aims at extracting knowledge,
    insights, and finally wisdom from raw data sources, and prediction represents
    a small portion of possible uses). In this learning path, data visualization plays
    a key role because it allows us to access and analyze data from a different perspective.
    In our mental map of the machine learning workflow (figure 3.26), visualization
    is presented at the end of the process, because visualizing data after initial
    processing has been performed is much better than visualizing raw data, but data
    visualization can happen at any point in the workflow.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的主要目标之一是理解数据并为最终用户提供某种预测能力（尽管如本章开头所述，数据分析通常旨在从原始数据源中提取知识、洞察力，最终是智慧，而预测只是可能用途的一小部分）。在本学习路径中，数据可视化起着关键作用，因为它使我们能够从不同的角度访问和分析数据。在我们对机器学习工作流程的心理地图（图3.26）中，可视化位于流程的末尾，因为在对数据进行初步处理之后可视化数据要比直接可视化原始数据好得多，但数据可视化可以在工作流程的任何一点发生。
- en: '![CH03_F26_Negro](../Images/CH03_F26_Negro.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F26_Negro](../Images/CH03_F26_Negro.png)'
- en: Figure 3.26 Visualization in the mental model
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.26 心理模型中的可视化
- en: In this context, again, the graph approach plays a fundamental role. A growing
    trend in data analysis is to make sense of linked data as networks. Rather than
    looking solely at attributes of the data, network analysts also focus on the connections
    and resulting structures in the data. If graphs are a helpful way of organizing
    data to better understand and analyze the relationships contained within that
    data, visualizations help expose that organization, further simplifying understanding.
    Combining the two methods helps data scientists to make sense of the data they
    have. Furthermore, successful visualizations are deceptive in their simplicity,
    offering the viewer new insights and understanding at a glance.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，图表方法再次扮演了基础角色。数据分析中的一个日益增长的趋势是将链接数据视为网络。网络分析师不仅关注数据的属性，还关注数据中的连接和结果结构。如果图表是组织数据以更好地理解和分析其中关系的有用方式，那么可视化有助于揭示这种组织，进一步简化理解。结合这两种方法有助于数据科学家理解他们拥有的数据。此外，成功的可视化在简单性上具有欺骗性，一眼就能为观众提供新的洞察和理解。
- en: 'Why does visualizing data, specifically in the form of a graph, make it easier
    to analyze? There are several reasons:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么将数据可视化，特别是以图表的形式，使其更容易分析？有几个原因：
- en: Humans are naturally visual creatures. Our eyes are our most powerful sensory
    receptors, and presenting data through information visualizations makes the most
    of our perceptual abilities [Perer, 2010].
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类天生是视觉生物。我们的眼睛是我们最强大的感官接收器，通过信息可视化展示数据可以最大限度地发挥我们的感知能力[Perer, 2010]。
- en: Many datasets today are too large to be inspected without computational tools
    that facilitate processing and interaction. Data visualizations combine the power
    of computers and the power of the human mind, capitalizing on our pattern-recognition
    abilities to enable efficient and sophisticated interpretation of the data. If
    we can see the data in the form of a graph, it’s easier to spot patterns, outliers,
    and gaps [Krebs, 2016; Perer, 2010].
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 今天，许多数据集太大，无法在没有便于处理和交互的计算工具的情况下进行检查。数据可视化结合了计算机的力量和人类大脑的力量，利用我们的模式识别能力，使我们能够高效且复杂地解释数据。如果我们能以图表的形式看到数据，就更容易发现模式、异常值和缺口[Krebs,
    2016; Perer, 2010]。
- en: The graph model exposes relationships that may be hidden in other views of the
    same data (such as tables and documents) and helps us pick out the important details
    [Lanum, 2016].
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图表模型揭示了可能隐藏在其他数据视图（如表格和文档）中的关系，并帮助我们挑选出重要细节[Lanum, 2016]。
- en: 'On the other hand, choosing an effective visualization can be a challenge,
    because different forms have different strengths and weaknesses [Perer, 2010]:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，选择有效的可视化可能是一个挑战，因为不同的形式有不同的优点和缺点[Perer, 2010]：
- en: '*Not all information visualizations highlight the patterns, gaps, and outliers
    important to analysts’ tasks, and furthermore, not all information visualizations
    “force us to notice what we never expected to see” [Tukey, 1977].*'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '*并非所有信息可视化都能突出分析师任务中重要的模式、缺口和异常值，而且并非所有信息可视化“强迫我们注意到我们从未预料到看到的东西”[Tukey, 1977]。*'
- en: Moreover, visualizing big data requires significant effort in terms of filtering,
    organizing, and displaying it on a screen. But despite all these challenges, the
    graph view remains appealing to researchers in a broad range of areas.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，将大数据可视化需要投入大量的精力来进行筛选、组织和在屏幕上展示。尽管面临所有这些挑战，图表视图仍然对众多领域的科研人员具有吸引力。
- en: Some good examples of using graph representations to reveal insights into human
    behavior appear in the work of social network analyst Valdis Krebs. An interesting
    aspect of Krebs’s work is that he is able to take data from any kind of source
    (old documents, newspapers, databases, or web pages); convert it to a graph representation;
    perform some network analysis; and then visualize the results with his own software,
    called InFlow. Then he analyzes the graph and comes up with some conclusions.
    One example, which we saw in chapter 1, is his analysis of political-book purchases
    on Amazon.com from the two US presidential elections before 2003 (figure 3.27).
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 社会网络分析师Valdis Krebs在其工作中展示了使用图表示法揭示人类行为洞察力的良好例子。Krebs工作的一个有趣方面是，他能够从任何类型的来源（旧文档、报纸、数据库或网页）获取数据；将其转换为图表示法；进行一些网络分析；然后使用他自己的软件InFlow可视化结果。然后他分析图表并得出一些结论。一个例子，我们在第一章中看到的是他对2003年之前两次美国总统选举在Amazon.com上购买政治书籍的分析（图3.27）。
- en: '![CH03_F27_Negro](../Images/CH03_F27_Negro.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F27_Negro](../Images/CH03_F27_Negro.png)'
- en: Figure 3.27 The political-book networks from the two US presidential elections
    before 2003 [Krebs, 2016]
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.27 2003年之前两次美国总统选举的政治书籍网络 [Krebs, 2016]
- en: Amazon provides summary purchase data that can be used to create a co-occurrence
    network (a type of graph we saw earlier in some of our example scenarios). Two
    books are connected when a customer buys both books. The more customers who purchase
    both items, the stronger the association between them is and the higher on the
    “customers who bought this item also bought” list the associated item appears.
    Consequently, by using Amazon data, it is possible to generate a network that
    provides significant insights into customers’ preferences and purchasing behavior.
    As Krebs puts it, “With a little data mining and some data visualization, we can
    get great insights into the habits and choices of Amazon’s customers—that is,
    we can come to understand groups of people without knowing about their individual
    choices.”
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊提供了可以用来创建共现网络（我们在一些示例场景中之前看到过的一种图）的购买摘要数据。当一位顾客购买了这两本书时，两本书就连接在一起。购买这两件商品的顾客越多，它们之间的关联就越强，在“购买此商品的顾客还购买了”列表中出现的关联商品就越高。因此，通过使用亚马逊数据，可以生成一个网络，该网络可以提供对客户偏好和购买行为的深刻见解。正如Krebs所说：“通过一点数据挖掘和一些数据可视化，我们可以深入了解亚马逊顾客的习惯和选择——也就是说，我们可以了解一群人，而无需了解他们的个人选择。”
- en: 'In figure 3.27, it is possible to recognize two distinct political clusters:
    a red one (gray, in the print book) designating those who read right-leaning books
    and a blue one (black, in the print book) designating those who read left-leaning
    books. Only one book holds the red and blue clusters together; ironically, that
    book is named *What Went Wrong*. This graph visualization provides strong evidence
    of how polarized US citizens were during the political election in 2008\. But
    this “evidence” is not so evident to a machine learning algorithm, because it
    requires a lot of contextual information that it’s much easier for a human brain
    to supply: the political orientation of the book or the book’s author, the circumstances
    of the ongoing political election, and so on.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3.27中，可以识别出两个不同的政治集群：一个红色集群（在印刷版中为灰色），代表那些阅读右倾书籍的人；一个蓝色集群（在印刷版中为黑色），代表那些阅读左倾书籍的人。只有一本书将这两个集群连接在一起；具有讽刺意味的是，这本书的名字叫*出了什么问题*。这个图可视化提供了强有力的证据，证明了2008年政治选举期间美国公民是多么的极化。但是，对于机器学习算法来说，这个“证据”并不那么明显，因为它需要大量的上下文信息，而这些信息对于人类大脑来说更容易提供：书籍的政治倾向或作者的倾向，正在进行的政治选举的情况等等。
- en: '3.6 Leftover: Deep learning and graph neural networks'
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.6 剩余：深度学习和图神经网络
- en: 'Machine learning is a broad and constantly growing field. It is so huge that
    none of the books available covers the full spectrum of tasks and possibilities
    that such practices could accomplish. This book is not an exception. A lot of
    topics have been intentionally left out of our discussion. Among the others, one
    deserves at least to be mentioned because at the time of writing, it is shining
    in research and even in applications: *deep learning*. Let me introduce it a little
    bit to give you a high-level understanding of what it is, how it fits into the
    machine learning panorama, and how it can be applied to graphs.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个广泛且不断发展的领域。它如此庞大，以至于没有任何一本书能涵盖这些实践可能完成的全部任务和可能性。这本书也不例外。我们有意省略了很多话题。其中，有一个话题至少值得提及，因为在写作的时候，它在研究和应用中都显得非常突出：*深度学习*。让我简要介绍一下，以便您对它有一个高层次的理解，了解它在机器学习领域的位置，以及它如何应用于图。
- en: As we have seen so far, and as we will discuss across the entire book, the performance
    (in terms of accuracy) of machine learning algorithms depends heavily on the quality
    of the data and the way in which it is represented. Each piece of information
    included in the representation and used during the training and the prediction
    is defined as a *feature*. Examples of features are a list of the items bought
    by a user, the places where a subject has spent some time, and the tokens in a
    text. The machine learning process takes these features and will infer a model
    capable of mapping this input with potential output. In the case of the recommendations,
    the process takes the items bought or rated by users and tries to predict what
    they could be interested in. In the case of subject monitoring, considering the
    previous locations, the algorithm predicts where a subject will be in the next
    hours or days. This book explains how to use graph data models to represent these
    features and how to simplify or improve the mapping.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，并且我们将在整本书中讨论，机器学习算法的性能（从准确性的角度来说）在很大程度上取决于数据的质量以及它的表示方式。在表示中包含的每一项信息，以及在训练和预测过程中使用的信息，都被定义为*特征*。特征的例子包括用户购买的商品列表，用户花费时间的地方，以及文本中的标记。机器学习过程将这些特征作为输入，并推断出一个能够将这种输入映射到潜在输出的模型。在推荐的情况下，这个过程会考虑用户购买或评价的商品，并试图预测他们可能感兴趣的内容。在主题监控的情况下，考虑到之前的地点，算法预测用户在接下来的几小时或几天内可能在哪里。本书解释了如何使用图数据模型来表示这些特征，以及如何简化或改进映射。
- en: Unfortunately, for many tasks, it is not so simple to identify features to be
    extracted for training a model. Suppose that you need to write an algorithm to
    recognize a face in a picture. A person has a pair of eyes, hair (not all of them)
    of some color, a nose, a mouth, and so on. A face is simple to describe in words,
    but how can we describe what an eye looks like in terms of pixels?
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，对于许多任务来说，确定用于训练模型的特征提取并不是那么简单。假设你需要编写一个算法来识别图片中的面孔。一个人有一对眼睛，一些颜色的头发（不是所有头发），一个鼻子，一个嘴巴等等。用语言描述面孔很简单，但我们如何用像素来描述眼睛的形状呢？
- en: One possible solution to this representation problem is to use machine learning
    to discover not only the mapping from representation to output, but also the representation
    itself. This approach is known as *representation learning* [Goodfellow et al.,
    2016]. The resulting representations often result in much better performance compared
    with hand-picked features. Moreover, because the machine is capable of learning
    representations from simpler data (only the images or a bunch of text, for example),
    it can adapt to new tasks rapidly with reduced human effort. What requires minutes
    or days for a machine could require decades of research for humans.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这种表示问题的可能方法之一是使用机器学习来发现不仅是从表示到输出的映射，还包括表示本身。这种方法被称为*表示学习* [Goodfellow等人，2016]。这种表示通常比手工挑选的特征有更好的性能。此外，因为机器能够从更简单的数据（例如，只有图像或一些文本）中学习表示，所以它能够以减少人力投入的方式快速适应新的任务。对于机器可能只需要几分钟或几天就能完成的事情，对于人类可能需要数十年的研究。
- en: Deep learning approaches the problem of representation learning by introducing
    representations that are expressed in terms of other, simpler representations
    [Goodfellow et al., 2016]. In deep learning, the machine builds multiple levels
    of increasing complexity over the underlying simpler concepts. The concept of
    an image of a person can be represented by combining corners and contours, which
    are in turn defined in terms of edges. Figure 3.28 describes the differences between
    classic machine learning and the subarea of deep learning.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习通过引入用其他更简单的表示表达表示来解决表示学习问题 [Goodfellow等人，2016]。在深度学习中，机器在基础更简单概念之上构建多个越来越复杂的层次。人的图像概念可以通过结合角点和轮廓来表示，而这些角点和轮廓又可以用边缘来定义。图3.28描述了经典机器学习和深度学习子领域之间的差异。
- en: '![CH03_F28_Negro](../Images/CH03_F28_Negro.png)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F28_Negro](../Images/CH03_F28_Negro.png)'
- en: Figure 3.28 Differences between the rule-based approach, classical machine learning,
    and deep learning (inspired by Goodfellow et al., 2016)
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.28 基于规则的算法、经典机器学习和深度学习之间的差异（受Goodfellow等人，2016年启发）
- en: In the preceding examples, we mentioned images, text, and so on. These data
    types are defined as Euclidean because they can be represented in a multidimensional
    space. What if we want to use such an approach on a graph, perhaps to recognize
    whether a node in a social network is a bot or to predict the formation of a link
    (and, hence, a correlation) between two nodes representing diseases? Figure 3.29
    shows the representation of images and text in a Euclidean space versus the graph
    that cannot be represented easily in such a multidimensional space. (At bottom
    left in the figure, TF-IDF stands for *term frequency-inverse document frequency*.)
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们提到了图像、文本等。这些数据类型被定义为欧几里得类型，因为它们可以在多维空间中表示。如果我们想在图上使用这种方法，比如识别社交网络中的节点是否为机器人，或者预测表示疾病的两个节点之间链接（以及因此产生的相关性）的形成？图3.29显示了图像和文本在欧几里得空间中的表示与难以在这样多维空间中表示的图。
    (图下方左侧，TF-IDF代表*词频-逆文档频率*。)
- en: '![CH03_F29_Negro](../Images/CH03_F29_Negro.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F29_Negro](../Images/CH03_F29_Negro.png)'
- en: Figure 3.29 Euclidean representation of images and text versus graphs
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.29 图像和文本的欧几里得表示与难以在多维空间中表示的图
- en: Graphs, with multiple node types and different types of relationships, are far
    from being a Euclidean space. This task is where graph neural networks (GNNs)
    comes in. *GNNs* are deep learning-based methods that operate on a graph domain
    to perform complex tasks such as node classification (the bot example), link prediction
    (the disease example), and so on. Due to its convincing performance, GNN has become
    a widely applied graph analysis method.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 具有多个节点类型和不同类型关系的图远非欧几里得空间。这项任务正是图神经网络（GNNs）的用武之地。*GNNs*是基于深度学习的方法，在图域上执行复杂任务，如节点分类（例如机器人示例）、链接预测（例如疾病示例）等。由于其令人信服的性能，GNN已成为广泛应用的图分析方法。
- en: Figure 3.30 shows a generic encoding function that is capable of converting
    nodes (or relationships) in d-dimensional vectors. This function is generally
    used as an embedding technique. When the graph elements have been migrated in
    a Euclidean space, we can use classical machine learning techniques for images
    and text. The quality of this representation learning affects the quality and
    accuracy of the subsequent tasks.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.30展示了一个通用的编码函数，该函数能够将d维向量中的节点（或关系）进行转换。这个函数通常用作嵌入技术。当图元素已经迁移到欧几里得空间时，我们可以使用图像和文本的经典机器学习技术。这种表示学习质量影响后续任务的质量和准确性。
- en: '![CH03_F30_Negro](../Images/CH03_F30_Negro.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![CH03_F30_Negro](../Images/CH03_F30_Negro.png)'
- en: Figure 3.30 A generic encoder example
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.30 通用编码器示例
- en: GNNs are capable of generating representations of nodes that depend on the structure
    of the graph as well as on any feature information we have. These features could
    be nodes’ properties, relationship types, and relationship properties. That’s
    why GNNs could drive the final tasks to better results. These embeddings represent
    the input for tasks such as node classification, link prediction, and graph classification.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: GNNs能够生成依赖于图结构以及我们拥有的任何特征信息的节点表示。这些特征可能是节点的属性、关系类型和关系属性。这就是为什么GNNs能够推动最终任务达到更好的结果。这些嵌入代表了节点分类、链接预测和图分类等任务的输入。
- en: These concepts are more complex and require broader understanding of both machine
    learning (in particular, deep learning) and graphs, which is why I preferred to
    keep these topics out of this book. New techniques, such as deep learning and
    GNNs, don’t invalidate what is presented in this book; they are built on the principles
    presented in these pages that represent the ground truth. I definitely think that
    the concepts presented here give the reader a mental model for understanding more
    recent approaches, allowing them to evaluate when to use each type.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概念更加复杂，需要更广泛地理解机器学习（特别是深度学习）和图，这就是为什么我更喜欢将这些主题留在这本书之外。新的技术，如深度学习和GNNs，并没有使本书中介绍的内容失效；它们是建立在这些页面上的原则之上的，这些原则代表了事实真相。我确实认为这里介绍的概念为读者提供了一个理解更近期方法的思维模型，使他们能够评估何时使用每种类型。
- en: Summary
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter presented a comprehensive array of use cases for graphs in machine
    learning projects. In this chapter, you learned
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了机器学习项目中图的综合应用案例。在本章中，你学习了
- en: How to use graphs and a graph model to manage data. Designing a proper graph
    model allows multiple data sources to be merged in a single connected and well-organized
    source of truth. This approach is useful not only because it creates a single
    knowledge base—the *knowledge graph*—that can be shared among multiple projects,
    but also because it can organize the data in a way that suits the kind of analysis
    to be performed.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用图和图模型来管理数据。设计合适的图模型允许将多个数据源合并为一个单一、连接良好且组织有序的真相来源。这种方法不仅因为它创建了一个单一的知识库——*知识图谱*，可以供多个项目共享，而且还因为它可以以适合要执行的分析方式组织数据。
- en: How to process data by using graph algorithms. Graph algorithms support a wide
    spectrum of analysis and can be used in isolation or as part of a more complex
    and articulated analytics pipeline.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用图算法处理数据。图算法支持广泛的分析，可以单独使用或作为更复杂和细致的分析管道的一部分。
- en: How to design a graph that stores the prediction model resulting from training
    to simplify and speed access during the prediction phase.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何设计一个图，该图存储训练得到的预测模型，以简化预测阶段的数据访问并提高速度。
- en: How to visualize data in the form of graphs. Data visualization is a crucial
    aspect of predictive analysis. A graph can be a pattern for modeling the data
    so that it can be visualized by an analyst in an efficient and effective way;
    the human brain can do the rest.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将数据以图形的形式可视化。数据可视化是预测分析的关键方面。图可以作为建模数据的模式，以便分析师以高效和有效的方式可视化；人脑可以完成剩余的部分。
- en: What deep learning and graph neural networks are.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习和图神经网络是什么。
- en: References
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Diestel, 2017] Diestel, Reinhard. *Graph Theory*. 5th ed. New York: Springer,
    2017.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '[Diestel, 2017] Diestel, Reinhard. 《图论》。第5版。纽约：Springer，2017年。'
- en: '[Eagle, Quinn, and Clauset, 2009] Eagle, Nathan, John A. Quinn, and Aaron Clauset.
    “Methodologies for Continuous Cellular Tower Data Analysis.” Proceedings of the
    7th International Conference on Pervasive Computing (2009): 342-353.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '[Eagle, Quinn, and Clauset, 2009] Eagle, Nathan，John A. Quinn 和 Aaron Clauset.
    “连续蜂窝基站数据分析的方法。” 第7届国际普适计算会议论文集（2009年）：342-353.'
- en: '[Frolov and Oseledets, 2016] Frolov, Evgeny, and Ivan Oseledets. “Tensor Methods
    and Recommendation Engines.” GroundAI, March 18, 2016.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[Frolov and Oseledets, 2016] Frolov, Evgeny 和 Ivan Oseledets. “张量方法和推荐引擎。”
    GroundAI，2016年3月18日。'
- en: '[Goodfellow et al., 2016] Goodfellow, Ian, Yoshua Bengio, and Aaron Courville.
    *Deep Learning*. The MIT Press. 2016.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '[Goodfellow et al., 2016] Goodfellow, Ian，Yoshua Bengio 和 Aaron Courville.
    《深度学习》。麻省理工学院出版社。2016年。'
- en: '[Jannach et al., 2010] Jannach, Dietmar, Markus Zanker, Alexander Felfernig,
    and Gerhard Friedrich. *Recommender Systems: An Introduction*. Cambridge, UK:
    Cambridge University Press, 2010.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '[Jannach et al., 2010] Jannach, Dietmar，Markus Zanker，Alexander Felfernig 和
    Gerhard Friedrich. 《推荐系统：入门》。英国剑桥：剑桥大学出版社，2010年。'
- en: '[Kleindorfer and Saad, 2005] Kleindorfer, Paul R., and Germaine H. Saad. “Managing
    Disruption Risks in Supply Chains.” Production and Operation Management 14:1 (2005):
    53-68.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kleindorfer and Saad, 2005] Kleindorfer, Paul R. 和 Germaine H. Saad. “供应链中断风险的应对策略.”
    生产与运营管理 14:1 (2005): 53-68.'
- en: '[Krebs, 2016] Krebs, Valdis. Political Choices. T N T: The Network Thinkers,
    January 2016\. [http://www.thenetworkthinkers.com](http://www.thenetworkthinkers.com).'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '[Krebs, 2016] Krebs, Valdis. 政治选择. T N T: 网络思想家，2016年1月。[http://www.thenetworkthinkers.com](http://www.thenetworkthinkers.com).'
- en: '[Lanum, 2016] Lanum, Corey L. *Visualizing Graph Data*. Shelter Island, NY:
    Manning, 2016.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '[Lanum, 2016] Lanum, Corey L. 《可视化图数据》。纽约：Manning，2016年。'
- en: '[Mihalcea and Tarau, 2004] Mihalcea, Rada, and Paul Tarau. “TextRank: Bringing
    Order into Text.” Proceedings of the 2004 Conference on Empirical Methods in Natural
    Language Processing (2004): 404-411.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mihalcea and Tarau, 2004] Mihalcea, Rada 和 Paul Tarau. “TextRank：将秩序带入文本。”
    第2004年实证自然语言处理会议论文集（2004年）：404-411.'
- en: '[Negro et al., 2017] Negro, Alessandro, Vlasta Kus, Miro Marchi, and Christophe
    Willemsen. “Efficient Unsupervised Keywords Extraction Using Graphs.” GraphAware,
    October 3, 2017\. [http://mng.bz/w0Z7](http://mng.bz/w0Z7).'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '[Negro et al., 2017] Negro, Alessandro，Vlasta Kus，Miro Marchi 和 Christophe
    Willemsen. “使用图进行高效的未监督关键词提取。” GraphAware，2017年10月3日。[http://mng.bz/w0Z7](http://mng.bz/w0Z7).'
- en: '[Perer, 2010] Perer, Adam. “Finding Beautiful Insights in the Chaos of Social
    Network Visualizations.” In *Beautiful Visualization*, edited by Julie Steele
    and Noah Iliinsky. Sebastopol, CA: O’Reilly, 2010\. 157-173.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '[Perer, 2010] Perer, Adam. “在社交网络可视化混乱中寻找美丽的洞察力。” 见《美丽可视化》，由Julie Steele 和
    Noah Iliinsky 编著。加利福尼亚州塞巴斯蒂波利斯：O’Reilly，2010年。157-173.'
- en: '[Russel and Norvig, 2009] Russell, Stuart J., and Peter Norvig. *Artificial
    Intelligence: A Modern Approach*. 3rd ed. Upper Saddle River, NJ: Pearson, 2009.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '[Russel and Norvig, 2009] Russell, Stuart J. 和 Peter Norvig. *人工智能：现代方法*. 第3版.
    新泽西州上萨德尔河：Pearson，2009.'
- en: '[Schaeffer, 2007] Schaeffer, Satu Elisa. “Survey: Graph Clustering.” Computer
    Science Review 1:1 (2007): 27-64.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '[Schaeffer, 2007] Schaeffer, Satu Elisa. “调查：图聚类。”计算机科学评论 1:1 (2007): 27-64.'
- en: '[Tukey, 1977] Tukey, John W. *Exploratory Data Analysis*. Reading, MA: Addison-Wesley,
    1977.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '[Tukey, 1977] Tukey, John W. *探索性数据分析*. 麻省雷丁：Addison-Wesley，1977.'
- en: '[Wirth and Hipp, 2000] Wirth, R., and J. Hipp. “CRISP-DM: Towards a Standard
    Process Model for Data Mining.” Proceedings of the Fourth International Conference
    on the Practical Application of Knowledge Discovery and Data Mining (2000): 29-39.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '[Wirth and Hipp, 2000] Wirth, R. 和 J. Hipp. “CRISP-DM：数据挖掘的标准流程模型。”第四国际知识发现和数据挖掘实际应用会议论文集（2000）：29-39.'
- en: '[Zhao and Silva, 2016] Zhao, Liang, and Thiago Christiano Silva. *Machine Learning
    in Complex Networks*. New York: Springer, 2016.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '[Zhao and Silva, 2016] Zhao, Liang 和 Thiago Christiano Silva. *复杂网络中的机器学习*.
    纽约：Springer，2016.'
- en: '* * *'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.)[www.smrvl.com](http://www.smrvl.com/).
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: ^(1.)[www.smrvl.com](http://www.smrvl.com/).
- en: ^(2.)See appendix A for details.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: ^(2.)详细信息请见附录A。
- en: ^(3.)This scenario was introduced in chapter 2 for different purposes. Here,
    it is extended and split in the multiple tasks composing our mental model. Let
    me apologize for the small (but necessary) repetition.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: ^(3.)这个场景在第二章中出于不同的目的被引入。在这里，它被扩展并分割成构成我们心智模型的多项任务。请允许我为这种（但必要的）小重复表示歉意。
- en: ^(4.)For the same reasons as in the previous example, there is a bit of repetition
    from chapter 2\. In this chapter, the scenario is described in more detail.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: ^(4.)与前例相同的原因，本章中从第二章有一些重复。在本章中，场景描述得更加详细。
- en: ^(5.)A *dynamic model* is used to represent or describe systems whose state
    changes over time.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: ^(5.)使用*动态模型*来表示或描述随时间变化状态的系统。
