- en: '4 Model-agnostic methods: Local interpretability'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 模型无关方法：局部可解释性
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Characteristics of deep neural networks
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度神经网络的特性
- en: How to implement deep neural networks that are inherently black-box models
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何实现本质上是黑盒模型的深度神经网络
- en: Perturbation-based model-agnostic methods that are local in scope, such as LIME,
    SHAP and anchors
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于扰动的局部范围模型无关方法，如LIME、SHAP和锚点
- en: How to interpret deep neural networks using LIME, SHAP, and anchors
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用LIME、SHAP和锚点来解释深度神经网络
- en: Strengths and weaknesses of LIME, SHAP, and anchors
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME、SHAP和锚点的优缺点
- en: In the previous chapter, we looked at tree ensembles, especially random forest
    models, and learned how to interpret them using model-agnostic methods that are
    global in scope, such as partial dependence plots (PDPs) and feature interaction
    plots. We saw that PDPs are a great way of understanding how individual feature
    values impact the final model prediction at a global scale. We were also able
    to see how features interact with each other using the feature interaction plots
    and how they can be used to expose potential issues such as bias. PDPs are easy
    and intuitive to understand, but their major drawback is that they assume features
    are independent of each other. In addition, higher-order feature interactions
    cannot be visualized using feature interaction plots.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们探讨了树集成，特别是随机森林模型，并学习了如何使用全局范围内的模型无关方法来解释它们，例如部分依赖图（PDPs）和特征交互图。我们看到PDPs是理解单个特征值如何在全球范围内影响最终模型预测的绝佳方式。我们还能够通过特征交互图看到特征如何相互作用，以及它们如何被用来揭示潜在的偏差等问题。PDPs易于理解且直观，但它们的最大缺点是假设特征之间是相互独立的。此外，使用特征交互图无法可视化高阶特征交互。
- en: In this chapter, we will look at black-box neural networks, specifically focusing
    on deep neural networks (DNNs). These models are inherently complex and require
    more sophisticated interpretability techniques to understand them. We will specifically
    focus on techniques such as local interpretable model-agnostic explanations (LIME),
    SHapley Additive exPlanations (SHAP), and anchors. Unlike PDPs and feature interaction
    plots, these techniques are local in scope. This means that we can use them to
    interpret only a single instance or prediction.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨黑盒神经网络，特别是深度神经网络（DNNs）。这些模型本质上是复杂的，需要更高级的解释技术来理解它们。我们将特别关注局部可解释模型无关解释（LIME）、SHapley
    Additive exPlanations（SHAP）和锚点等技术。与PDPs和特征交互图不同，这些技术是局部的。这意味着我们可以使用它们来解释单个实例或预测。
- en: We will follow a similar structure as the previous chapters. We start off with
    a concrete example where the objective is to build a model for breast cancer diagnosis.
    We will explore this new dataset and learn how to train and evaluate DNNs in PyTorch.
    We then learn how to interpret them. It is worth reiterating that although the
    main focus of this chapter is on interpreting DNNs, we will also cover basic concepts
    of DNNs and how to train and test them. Because the learning, testing, and understanding
    stages are iterative, it is important to cover all three together. We also cover
    some key insights and concepts in the earlier sections that will be useful during
    model interpretation. Readers who are already familiar with DNNs and how to train
    and test them are free to skip the earlier sections and jump straight to section
    4.4, in which we cover model interpretability.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遵循与前面章节相似的结构。我们从一个具体的例子开始，目标是构建一个用于乳腺癌诊断的模型。我们将探索这个新的数据集，并学习如何在PyTorch中训练和评估深度神经网络（DNNs）。然后我们将学习如何解释它们。值得重申的是，尽管本章的主要重点是解释DNNs，我们还将涵盖DNNs的基本概念以及如何训练和测试它们。由于学习、测试和理解阶段是迭代的，因此同时涵盖这三个方面非常重要。我们还将在前面的部分中介绍一些关键见解和概念，这些在模型解释过程中将非常有用。对于已经熟悉DNNs以及如何训练和测试它们的读者，可以自由跳过前面的部分，直接跳到第4.4节，其中我们将涵盖模型可解释性。
- en: '4.1 Diagnostics+ AI: Breast cancer diagnosis'
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 诊断+ AI：乳腺癌诊断
- en: 'Let’s look at a concrete example. We’ll go back to Diagnostics+, introduced
    in chapters 1 and 2\. The center would like to extend its AI capabilities to diagnose
    breast cancer and has digitized the images of a fine needle aspiration of breast
    masses from around 570 patients. Features were computed from these digitized images
    that described the characteristics of cell nuclei present in the images. For each
    cell nucleus, the following 10 features are used to describe its characteristics:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个具体的例子。我们将回到第1章和第2章中介绍的Diagnostics+。中心希望扩展其AI能力以诊断乳腺癌，并已将约570名患者的乳腺肿块细针穿刺图像进行了数字化。从这些数字化图像中计算了描述图像中存在的细胞核特征的特性。对于每个细胞核，以下10个特征被用来描述其特征：
- en: Radius
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半径
- en: Texture
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纹理
- en: Perimeter
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 周长
- en: Area
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面积
- en: Smoothness
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平滑度
- en: Compactness
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 紧凑度
- en: Concavity
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 凹凸性
- en: Concave points
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 凹点
- en: Symmetry
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对称性
- en: Fractal dimension
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分形维度
- en: For all the nuclei present in an image for a patient, the mean, standard error,
    and the largest or worst values are computed for each of these 10 features. Each
    patient, therefore, has 30 features in total. Given these input features, the
    goal of the AI system is to predict whether the cell is benign or malignant and
    to provide a confidence score for the doctor to help with their diagnosis. This
    is summarized in figure 4.1.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于患者图像中存在的所有核，计算每个这些10个特征的均值、标准误差以及最大或最差值。因此，每位患者总共拥有30个特征。给定这些输入特征，AI系统的目标是预测细胞是良性还是恶性，并为医生提供信心分数以帮助他们诊断。这总结在图4.1中。
- en: '![](../Images/CH04_F01_Thampi.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F01_Thampi.png)'
- en: Figure 4.1 Diagnostics+ AI for breast cancer diagnosis
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 乳腺癌诊断的Diagnostics+ AI
- en: Given this information, how would you formulate this as a machine learning problem?
    Because the target of the model is to predict whether a given breast mass is benign
    or malignant, we can formulate this problem as a *binary classification* problem.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这些信息，你将如何将这个问题表述为一个机器学习问题？因为模型的目的是预测给定的乳腺肿块是良性还是恶性，我们可以将这个问题表述为一个*二元分类*问题。
- en: 4.2 Exploratory data analysis
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 探索性数据分析
- en: Let’s now try to understand this dataset a bit better. Exploratory data analysis
    is an important step in the process of model development. We will specifically
    be looking at the volume of the data, the target class distribution, and whether
    features like the cell’s Area, Radius, and Perimeter can be used to differentiate
    between benign and malignant cases. We will use a lot of the insights gleaned
    in this section to determine what features should be used for model training,
    what metrics should be used for model evaluation, and how to validate the model
    interpretations obtained using the techniques that we will cover later in this
    chapter.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在尝试更好地理解这个数据集。探索性数据分析是模型开发过程中的一个重要步骤。我们将特别关注数据的体积、目标类别的分布，以及像细胞的面积、半径和周长这样的特征是否可以用来区分良性和恶性病例。我们将使用本节中获得的许多见解来确定应该使用哪些特征进行模型训练，应该使用哪些指标进行模型评估，以及如何验证我们将在本章后面介绍的技术的模型解释。
- en: 'The dataset contains 569 patient cases and 30 features in total. The features
    are all continuous. Figure 4.2 shows the proportion of cases that are benign and
    malignant. Out of the 569 cases, 357 of them (roughly 62.7%) are benign and 212
    (roughly 37.3%) are malignant. This shows that the dataset is skewed, or imbalanced.
    As we saw in chapter 3, we say that the data is imbalanced when a disproportionate
    number of examples or data points exist for a given class. Most machine learning
    algorithms work best when the proportion of samples for each class is roughly
    the same. This is because most algorithms are designed to minimize error or maximize
    accuracy, and these algorithms tend to be naturally biased toward the majority
    class. To recapitulate, you should note the following two things when dealing
    with imbalanced datasets:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含569个患者案例和总共30个特征。所有特征都是连续的。图4.2显示了良性病例和恶性病例的案例比例。在569个案例中，357个（大约62.7%）是良性的，212个（大约37.3%）是恶性的。这表明数据集是倾斜的，或者说是不平衡的。正如我们在第3章中看到的，当我们对于一个给定类别的例子或数据点存在不成比例的数量时，我们说数据是不平衡的。大多数机器学习算法在每个类别的样本比例大致相同的情况下表现最佳。这是因为大多数算法旨在最小化错误或最大化准确性，这些算法倾向于自然地偏向多数类。为了总结，当处理不平衡数据集时，你应该注意以下两点：
- en: Use the right performance metrics (like precision, recall, and F1) when testing
    and evaluating the models.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在测试和评估模型时，使用正确的性能指标（如精确度、召回率和F1）。
- en: Resample the training data such that the majority class is either undersampled
    or the minority class is oversampled.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新采样训练数据，使得多数类要么被欠采样，要么少数类被过采样。
- en: '![](../Images/CH04_F02_Thampi.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F02_Thampi.png)'
- en: Figure 4.2 Distribution of benign and malignant cases
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2 良性和恶性病例的分布
- en: We will discuss this further in section 4.3.2\. Let’s now look at the distributions
    of the cell’s Area, Radius, and Perimeter and see if there are any major differences
    between the benign and malignant cases. Figure 4.3 shows the distributions of
    the mean cell area and worst or largest cell area.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在4.3.2节中进一步讨论这个问题。现在，让我们看看细胞的面积、半径和周长的分布，看看良性和恶性病例之间是否有任何显著差异。图4.3显示了平均细胞面积和最差或最大细胞面积的分布。
- en: '![](../Images/CH04_F03_Thampi.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F03_Thampi.png)'
- en: Figure 4.3 Cell area distribution comparison of benign and malignant cases
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 比较良性和恶性病例的细胞面积分布
- en: In figure 4.3, we can see that if the mean cell area is greater than 750, then
    the case is much more likely to be malignant than benign. Also, if the worst or
    largest cell area is greater than 1,000, then the case is much more likely to
    be malignant. There seems to be a good but weak separation between the malignant
    and benign cases by looking at just two features related to the cell area.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在图4.3中，我们可以看到，如果平均细胞面积大于750，那么病例更有可能是恶性的而不是良性的。同样，如果最差或最大细胞面积大于1,000，那么病例更有可能是恶性的。仅通过观察与细胞面积相关的两个特征，似乎恶性与良性病例之间有良好的但较弱地分离。
- en: How about the cell’s Radius and Perimeter? Figures 4.4 and 4.5 show the distributions
    of the Radius and Perimeter, respectively. We see a similar separation between
    the benign and malignant cases. For instance, a case with a mean radius that is
    greater than 15 is much more likely to be malignant than benign. Also, a case
    with worst or largest cell perimeter of 100 is much more likely to be malignant.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 那么细胞的半径和周长呢？图4.4和图4.5分别显示了半径和周长的分布。我们可以看到良性和恶性病例之间有类似的分离。例如，平均半径大于15的病例比良性病例更有可能是恶性的。同样，周长最差或最大的细胞周长为100的病例更有可能是恶性的。
- en: '![](../Images/CH04_F04_Thampi.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F04_Thampi.png)'
- en: Figure 4.4 Cell radius distribution comparison of benign and malignant cases
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 比较良性和恶性病例的细胞半径分布
- en: The purpose of this analysis is to get a sense of how good the features are
    in predicting the target variable, that is, whether a given case is benign or
    malignant. By looking at the distributions in figures 4.3, 4.4, and 4.5, we can
    see pretty good signal in the six features that we’ve considered where there’s
    good separation between the benign and malignant cases. We will also use these
    insights to validate the interpretations obtained through LIME, SHAP, and anchors
    later in this chapter.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 本分析的目的在于了解特征在预测目标变量（即给定病例是良性还是恶性）方面的好坏。通过观察图4.3、4.4和4.5中的分布，我们可以看到我们考虑的六个特征中，良性和恶性病例之间有很好的分离信号。我们还将利用这些见解来验证本章后面通过LIME、SHAP和锚点获得的解释。
- en: '![](../Images/CH04_F05_Thampi.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F05_Thampi.png)'
- en: Figure 4.5 Cell perimeter distribution comparison of benign and malignant cases
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 比较良性和恶性病例的细胞周长分布
- en: Let’s finally look at how correlated each of the input features are with each
    other and the target variable. We know that the input features are continuous,
    but the target variable is discrete and binary. In the dataset, a malignant case
    is encoded as 0 and a benign case is encoded as 1\. Because the input features
    and the target are all numerical values, we can use the Pearson, or standard,
    correlation coefficient to measure correlation. As we saw in chapter 2, the Pearson
    correlation coefficient measures the linear correlation between two variables
    and has a value between +1 and –1\. If the magnitude of the coefficient is above
    0.7, that means really high correlation. If the magnitude of the coefficient is
    between 0.5 and 0.7, that means moderately high correlation. If the magnitude
    of the coefficient is between 0.3 and 0.5, that means low correlation, and a magnitude
    less than 0.3 means little to no correlation. You can easily compute the pairwise
    correlations using the `corr()` function provided by Pandas. As an exercise, please
    reuse the code learned in section 2.2 to compute and plot the correlation matrix.
    The code to load the dataset can be found in section 4.3.1\. The resulting plot
    for the breast cancer dataset is shown in figure 4.6.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们来探讨每个输入特征与彼此以及目标变量之间的相关性。我们知道输入特征是连续的，但目标变量是离散的二进制变量。在数据集中，恶性病例被编码为0，良性病例被编码为1。由于输入特征和目标都是数值型，我们可以使用皮尔逊相关系数，或称标准相关系数，来衡量相关性。正如我们在第2章中看到的，皮尔逊相关系数衡量两个变量之间的线性相关性，其值介于+1和-1之间。如果系数的绝对值大于0.7，这意味着高度相关。如果系数的绝对值介于0.5和0.7之间，这意味着中等高度相关。如果系数的绝对值介于0.3和0.5之间，这意味着低度相关，而系数的绝对值小于0.3则意味着几乎没有相关性。你可以使用Pandas提供的`corr()`函数轻松计算成对的相关性。作为练习，请重新使用第2.2节中学到的代码来计算并绘制相关矩阵。加载数据集的代码可以在第4.3.1节中找到。乳腺癌数据集的结果图示如图4.6所示。
- en: '![](../Images/CH04_F06_Thampi.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F06_Thampi.png)'
- en: Figure 4.6 Correlation plot of input features and the target variable
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 输入特征与目标变量的相关性图
- en: In figure 4.6, let’s first focus on the last column, which shows the correlation
    of all the input features with the target variable. We can see that features like
    mean cell Area, Radius, and Perimeter are highly correlated with the target class.
    The correlation coefficient is negative, however, which means that the larger
    the value for the features, the smaller the value for the target variable. This
    makes sense because the target class has a smaller value (i.e., 0) for the malignant
    class and a higher value (i.e., 1) for the benign class. As we saw in figures
    4.3, 4.4, and 4.5, the larger the value for these features, the more likely that
    the case is malignant. We can also see that quite a few features are highly correlated
    with each other. For instance, features like mean cell Radius, Area, and Perimeter
    are highly correlated with worst cell Radius, Area, and Perimeter. As we discussed
    in chapter 2, features that are correlated with each other are said to be multicollinear,
    or redundant. One way of dealing with multicollinearity is to remove redundant
    features for the model. We will discuss this further in the following section.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在图4.6中，我们首先关注最后一列，它显示了所有输入特征与目标变量的相关性。我们可以看到，像平均细胞面积、半径和周长这样的特征与目标类别高度相关。然而，相关系数是负的，这意味着特征值越大，目标变量的值就越小。这是有道理的，因为目标类别对于恶性类别有较小的值（即，0），而对于良性类别有较高的值（即，1）。正如我们在图4.3、4.4和4.5中看到的，这些特征的值越大，病例为恶性的可能性就越大。我们还可以看到，相当多的特征彼此之间高度相关。例如，平均细胞半径、面积和周长等特征与最差细胞半径、面积和周长高度相关。正如我们在第2章中讨论的，彼此相关的特征被称为多重共线性，或冗余。处理多重共线性的一种方法是从模型中移除冗余特征。我们将在下一节中进一步讨论这个问题。
- en: 4.3 Deep neural networks
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 深度神经网络
- en: An artificial neural network (ANN) is a system designed to loosely model a biological
    brain. It belongs to a broad class of machine learning methods called deep learning.
    The central idea of deep learning based on ANNs is to build complex concepts or
    representations from simpler concepts or features. An ANN learns a complex function
    by mapping the input to the output and is composed of many simpler functions.
    In this chapter, we will focus on ANNs consisting of multiple layers of units,
    or neurons, that are fully interconnected with each other. These are also called
    *deep neural networks (DNNs)*, *fully connected neural networks (FCNNs)*, or *multilayer
    perceptrons (MLPs)*. In subsequent chapters, we will cover *convolutional neural
    networks (CNNs)* and *recurrent neural networks (RNNs)*, which are more advanced
    structures of neural networks used for complex computer vision and language understanding
    tasks.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络（ANN）是一个旨在松散地模拟生物大脑的系统。它属于被称为深度学习的一类广泛的机器学习方法。基于ANN的深度学习的核心思想是从更简单的概念或特征构建复杂的概念或表示。ANN通过将输入映射到输出学习一个复杂函数，它由许多简单的函数组成。在本章中，我们将重点关注由多层单元（或神经元）组成的ANN，这些单元彼此完全互联。这些也被称为*深度神经网络（DNN）*、*全连接神经网络（FCNN）*或*多层感知器（MLP）*。在随后的章节中，我们将介绍*卷积神经网络（CNN）*和*循环神经网络（RNN）*，这些是用于复杂计算机视觉和语言理解任务的更高级神经网络结构。
- en: 'Figure 4.7 illustrates a simple ANN consisting of three types of layers: the
    input layer, the hidden layer, and the output layer. The input layer acts as the
    input for your data. The number of units in the input layer is equal to the number
    of features in your dataset. In figure 4.7, we consider only two features from
    the breast cancer dataset, namely, mean cell Radius and mean cell Area. This is
    why two units exist in the input layer.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7展示了由三种类型的层组成的一个简单ANN：输入层、隐藏层和输出层。输入层充当数据的输入。输入层中的单元数量等于数据集中特征的数量。在图4.7中，我们仅考虑来自乳腺癌数据集的两个特征，即平均细胞半径和平均细胞面积。这就是为什么输入层中存在两个单元的原因。
- en: '![](../Images/CH04_F07_Thampi.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图4.7](../Images/CH04_F07_Thampi.png)'
- en: Figure 4.7 An illustration of an ANN
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7 人工神经网络的示意图
- en: The input layer is then connected to all the units in the first hidden layer.
    The hidden layer transforms the inputs based on the activation function used for
    its units. In figure 4.7, the function `f` is used to represent the activation
    function for all the units in the hidden layer. The units in one layer are connected
    with units in another layer using edges. Each edge is associated with a weight,
    which defines the strength of the connection between the units that it connects.
    Note that a bias term also connects to each of the units in the hidden layer,
    with an edge weight of 1\. A weighted sum of the inputs and the bias term is taken
    before it is transformed by the activation function. If more than one hidden layer
    is present, then the ANN is said to be “deep.” Hence, an ANN with two or more
    hidden layers is called a *DNN*.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 输入层随后连接到第一隐藏层中的所有单元。隐藏层根据其单元使用的激活函数对输入进行转换。在图4.7中，函数`f`用于表示隐藏层中所有单元的激活函数。同一层的单元通过边与另一层的单元连接。每条边都关联着一个权重，它定义了连接的单元之间的连接强度。请注意，偏置项也通过权重为1的边连接到隐藏层中的每个单元。在通过激活函数转换之前，对输入和偏置项进行加权求和。如果存在多个隐藏层，则称人工神经网络（ANN）为“深度”。因此，具有两个或更多隐藏层的ANN被称为*深度神经网络（DNN）*。
- en: The units in the final hidden layer are then connected to units in the output
    layer. In figure 4.7, one unit exists in the output layer because for the breast
    cancer detection task, we have binary output where the given cell is either malignant
    or benign. The unit in the output layer also has an activation function *g*, which
    transforms the inputs to that unit to an output prediction. One of the challenges
    in creating neural networks is determining the structure of the neural network—how
    deep (number of hidden layers) and how wide (number of units in each layer) the
    network should be. We will briefly talk about how to determine and interpret the
    structure of the neural network in section 4.4 and cover it in more detail in
    subsequent chapters when we look at CNNs and RNNs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最终隐藏层的单元随后连接到输出层的单元。在图4.7中，输出层中存在一个单元，因为对于乳腺癌检测任务，我们有二元输出，即给定的细胞要么是恶性的，要么是良性的。输出层中的单元也有一个激活函数*g*，它将输入转换为输出预测。创建神经网络的一个挑战是确定神经网络的架构——网络应该有多深（隐藏层的数量）和多宽（每层的单元数量）。我们将在4.4节中简要讨论如何确定和解释神经网络的架构，并在后续章节中更详细地介绍，当我们查看卷积神经网络（CNNs）和循环神经网络（RNNs）时。
- en: Let’s now see how the input data is transformed into the output as it passes
    through the ANN. This is called forward propagation and is illustrated in figure
    4.8\. The input data is fed through the units in the input layer. The values of
    the input units for the two features are represented as *x1* and *x2*. These values
    are then propagated through the network in the forward direction through the hidden
    layers. At each unit in the hidden layer, a weighted sum of the inputs is computed
    and passed through an activation function. In figure 4.8, the first unit in the
    hidden layer computes the weighted sum of the inputs *x1* and *x2* and the bias
    term *b1* to obtain the preactivation value *a1*. This is then passed through
    the activation function *f* to obtain *f(a1)*. A similar set of operations happens
    at the second unit in the hidden layer. Note that the same activation function
    is used for both units in the hidden layer. We will discuss activation functions
    in more depth later in this section.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看输入数据是如何在通过人工神经网络（ANN）时转换为输出的。这被称为前向传播，如图4.8所示。输入数据被输入到输入层的单元中。两个特征输入单元的值表示为*x1*和*x2*。然后这些值通过隐藏层在网络中向前传播。在隐藏层的每个单元中，计算输入的加权和并通过激活函数传递。在图4.8中，隐藏层中的第一个单元计算输入*x1*和*x2*以及偏置项*b1*的加权和，以获得预激活值*a1*。然后这个值通过激活函数*f*得到*f(a1)*。在隐藏层的第二个单元中也发生类似的操作。请注意，隐藏层中的两个单元使用相同的激活函数。我们将在本节稍后更深入地讨论激活函数。
- en: '![](../Images/CH04_F08_Thampi.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F08_Thampi.png)'
- en: Figure 4.8 An illustration of forward propagation in an ANN
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 人工神经网络中的前向传播示意图
- en: Once we have computed the outputs for the units on the hidden layer, these outputs
    are then fed as inputs to the units in the subsequent layer. In the next illustration,
    the outputs from the two units at the hidden layer are fed as inputs to the one
    unit in the output layer. Just as before, first a weighted sum of the inputs together
    with the bias term is determined to obtain the preactivation value *a3*. This
    is then passed through the activation function *g* to obtain the output of the
    unit as *g(a3)*. The output of this final unit is meant to be an estimate of the
    target variable *y*, represented as *ŷ*. The weights for all the edges in the
    network will be randomly initialized at the start.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们计算了隐藏层单元的输出，这些输出随后被作为输入传递到下一层的单元。在下一幅图中，隐藏层中两个单元的输出被作为输入传递到输出层的一个单元。就像之前一样，首先确定输入的加权和以及偏置项，以获得预激活值*a3*。然后这个值通过激活函数*g*得到单元的输出作为*g(a3)*。这个最终单元的输出旨在作为目标变量*y*的估计，表示为*ŷ*。网络中所有边的权重在开始时都会随机初始化。
- en: Now the objective of the learning algorithm is to determine the weights of the
    edges, or the strength of the connections between the units, such that the output
    prediction is as close to the actual value for the target variable. How do you
    learn these weights? We will apply the same technique that we learned in chapter
    2 to determine the weights for a linear regression model—gradient descent. An
    optimum set of weights are those that minimize a cost or loss function. For regression
    problems, a common cost function is the squared error or squared difference between
    the predicted output and the actual output. For binary classification problems,
    a common cost function is the log loss or the binary cross-entropy (BCE) loss
    function.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在学习算法的目标是确定边的权重，或者单元之间连接的强度，使得输出预测尽可能接近目标变量的实际值。你是如何学习这些权重的呢？我们将应用在第2章中学到的相同技术来确定线性回归模型的权重——梯度下降。最优的权重集是那些最小化损失或损失函数的权重集。对于回归问题，一个常见的损失函数是预测输出和实际输出之间的平方误差或平方差。对于二元分类问题，一个常见的损失函数是对数损失或二元交叉熵（BCE）损失函数。
- en: 'The squared error cost function and its corresponding derivative with respect
    to the predicted output are shown in the following equations:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 平方误差损失函数及其相对于预测输出的导数在以下方程中展示：
- en: '![](../Images/CH04_F08_Thampi_equation01.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9](../Images/CH04_F08_Thampi_equation01.png)'
- en: '![](../Images/CH04_F08_Thampi_equation02.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9](../Images/CH04_F08_Thampi_equation02.png)'
- en: 'The log loss or BCE loss function and its corresponding derivative with respect
    to the predicted output are shown next:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来展示了对数损失或BCE损失函数及其相对于预测输出的导数：
- en: '![](../Images/CH04_F08_Thampi_equation03.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9](../Images/CH04_F08_Thampi_equation03.png)'
- en: '![](../Images/CH04_F08_Thampi_equation04.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9](../Images/CH04_F08_Thampi_equation04.png)'
- en: The cost function is said to be at a minimum (global or local) when the gradient
    of the cost function is 0 or close to 0\. We can easily determine the weights
    for a linear regression or logistic regression type of problem because the number
    of weights is equal to the number of input features (plus an additional bias term).
    For a DNN, on the other hand, the number of weights depends on the structure of
    the network. The number of weights can easily explode as we add more units and
    layers to the network. Applying the gradient descent algorithm directly is not
    computationally feasible. An efficient algorithm to determine these weights in
    a DNN is backpropagation.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当损失函数的梯度为0或接近0时，称损失函数处于最小值（全局或局部）。对于线性回归或逻辑回归类型的问题，我们可以很容易地确定权重，因为权重的数量等于输入特征的数目（加上一个额外的偏置项）。另一方面，对于深度神经网络（DNN），权重的数量取决于网络的结构。随着我们向网络添加更多的单元和层，权重的数量可能会迅速增加。直接应用梯度下降算法在计算上是不切实际的。在DNN中确定这些权重的有效算法是反向传播。
- en: The backpropagation algorithm for the simple ANN structure seen earlier is illustrated
    in figure 4.9\. Once we have evaluated the output of the network after forward
    propagation, the next step is to compute the cost or loss function and the gradient
    of the cost function with respect to the predicted output. Then visit the nodes
    in reverse order and propagate an error signal that we can use to compute the
    gradient with respect to the weights for all the edges in the network. Let’s go
    through it step by step by parsing figure 4.9 from right to left.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 之前看到的简单ANN结构的反向传播算法在图4.9中进行了说明。一旦我们评估了网络的前向传播后的输出，下一步就是计算损失函数或损失函数相对于预测输出的梯度。然后以相反的顺序访问节点，并传播一个错误信号，我们可以使用这个信号来计算网络中所有边的权重相对于梯度的值。让我们一步一步地通过从右到左解析图4.9来了解这个过程。
- en: '![](../Images/CH04_F09_Thampi.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9](../Images/CH04_F09_Thampi.png)'
- en: Figure 4.9 An illustration of backward propagation of error signals in an ANN
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9 ANN中错误信号反向传播的示意图
- en: We first compute the gradient of the cost function with respect to the predicted
    output variable. This is represented as *J’* in figure 4.9\. This gradient is
    then passed in the reverse direction through the unit in the output layer. Within
    the output layer, the local gradient of the activation function *g* is stored.
    This is represented as *g’*. The preactivation value *a3* evaluated during forward
    propagation is also stored. These values are used to compute the output error
    signal of the unit, represented as *e1*. The computed value, shown in figure 4.9,
    is the gradient of the loss function multiplied by the local gradient of the activation
    function. Using terminology from calculus, we are applying the chain rule here
    to compute the gradient of the loss function with respect to the input to the
    unit in the output layer. This error signal *e1* is then propagated to the two
    units in the hidden layer. The process is then repeated to compute the output
    error signals of the hidden units. Once the error signals have been propagated
    through the network and we have reached the input layer, we can compute the gradient,
    with respect to each edge weight, by multiplying the error signal flowing through
    it during backward propagation by the value that flowed through it during forward
    propagation. Multiple online resources and books explain backpropagation and the
    mathematical concepts in great depth. We will, therefore, not cover these concepts
    in more depth in this chapter.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先计算成本函数相对于预测输出变量的梯度。这如图4.9中的*J’*所示。然后，这个梯度通过输出层的单元以相反的方向传递。在输出层中，激活函数*g*的局部梯度被存储，这表示为*g’*。在正向传播过程中评估的预激活值*a3*也被存储。这些值用于计算单元的输出误差信号，表示为*e1*。如图4.9所示，计算值是损失函数的梯度乘以激活函数的局部梯度。使用微积分的术语，我们在这里应用链式法则来计算损失函数相对于输出层单元输入的梯度。这个误差信号*e1*随后传播到隐藏层的两个单元。然后重复这个过程来计算隐藏单元的输出误差信号。一旦误差信号通过网络传播并且我们到达输入层，我们可以通过将反向传播过程中通过它的误差信号乘以正向传播过程中通过它的值来计算梯度，这个梯度相对于每个边权重。多个在线资源和书籍对反向传播和数学概念进行了深入的解释。因此，我们将在本章中不深入探讨这些概念。
- en: The activation function is an important feature within a neural network. It
    decides whether a neuron should be activated and by how much. The properties of
    an activation function are that it is differentiable (i.e., the first derivative
    exists) and monotonic (i.e., it is either entirely nondecreasing or nonincreasing).
    Common activation functions used in neural networks include the sigmoid function,
    hyperbolic tangent (tanh), and the rectified linear unit (ReLU), which are defined
    in table 4.1.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数是神经网络中的一个重要特性。它决定了神经元是否应该被激活以及激活的程度。激活函数的特性是它可导（即存在一阶导数）且单调（即要么完全非递减，要么非递增）。在神经网络中常用的激活函数包括Sigmoid函数、双曲正切（tanh）函数和修正线性单元（ReLU），这些函数在表4.1中定义。
- en: The sigmoid activation function is typically used for classifiers because the
    output of the function ranges from 0 to 1\. For the breast cancer detection problem
    in this chapter, we will use the sigmoid function as the activation function `g`
    in the output layer. The hyperbolic tangent function has similar properties as
    the sigmoid, but the output ranges from –1 to 1\. Both the sigmoid and hyperbolic
    tangent activation functions suffer from the problem of vanishing gradients. This
    is because the gradients for both functions are 0 (also said to be saturated)
    for very large or small values of the input, as seen in table 4.1.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid激活函数通常用于分类器，因为函数的输出范围在0到1之间。在本章关于乳腺癌检测问题的讨论中，我们将使用Sigmoid函数作为输出层的激活函数`g`。双曲正切函数与Sigmoid函数具有相似的性质，但输出范围在-1到1之间。Sigmoid和双曲正切激活函数都存在梯度消失的问题。这是因为对于这两个函数，当输入值非常大或非常小时，梯度为0（也称为饱和），如表4.1所示。
- en: Table 4.1 Common activation functions used in neural networks
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.1 神经网络中常用的激活函数
- en: '| Activation Function | Description |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 激活函数 | 描述 |'
- en: '| Sigmoid | The sigmoid function is defined as follows:![](../Images/CH04_F09_T0401_a.png)The
    output of the function ranges from 0 to 1\. It is differentiable and is monotonic
    as shown in the figure above. |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Sigmoid | Sigmoid函数的定义如下：![Sigmoid函数图](../Images/CH04_F09_T0401_a.png)函数的输出范围在0到1之间。它是可导的，并且如图所示是单调的。|'
- en: '| Hyperbolic Tangent (tanh) | The hyperbolic tangent function is defined as
    follows:![](../Images/CH04_F09_T0401_b.png)The output of the function ranges from
    -1 to 1\. It is also differentiable and monotonic as shown in the figure above.
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 双曲正切（tanh）| 双曲正切函数定义为如下：![](../Images/CH04_F09_T0401_b.png)函数的输出范围从 -1 到
    1。它也是可微和单调的，如图所示。|'
- en: '| Rectified Linear Unit (ReLU) | The ReLU function is defined as follows:![](../Images/CH04_F09_T0401_c.png)The
    output of the function ranges from 0 to the infinity (depending on the value of
    the input *x*). It is differentiable and is monotonic as shown in the following
    figure.![](../Images/CH04_F09_T0401_d.png) |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 线性整流单元（ReLU）| ReLU函数定义为如下：![](../Images/CH04_F09_T0401_c.png)函数的输出范围从 0 到无穷大（取决于输入
    *x* 的值）。它是可微和单调的，如图所示。![](../Images/CH04_F09_T0401_d.png)|'
- en: ReLUs are the most widely used activation functions in neural networks because
    they handle the vanishing gradient problem well. We can see that the value of
    the ReLU is 0 if the input is negative. This means that if the input to a neuron
    with a ReLU activation function is negative, then the output of that neuron is
    0 and is, therefore, not activated. Only neurons with non-negative inputs are
    activated. Because not all neurons are activated at the same time, the ReLU activation
    function is more computationally efficient. In practice, for simplicity, the same
    activation function is used for all the units in the hidden layers of the neural
    network.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ReLUs是神经网络中最广泛使用的激活函数，因为它们很好地处理了梯度消失问题。我们可以看到，当输入为负时，ReLU的值为0。这意味着如果具有ReLU激活函数的神经元的输入为负，那么该神经元的输出为0，因此没有激活。只有具有非负输入的神经元才会被激活。因为不是所有神经元同时被激活，ReLU激活函数在计算上更有效率。在实践中，为了简单起见，神经网络隐藏层的所有单元都使用相同的激活函数。
- en: 4.3.1 Data preparation
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1 数据准备
- en: Let’s now train a DNN for the breast cancer detection problem. We will use PyTorch
    to build and train the network. PyTorch is a library that facilitates building
    neural networks in Python. PyTorch is gaining popularity among researchers and
    machine learning practitioners in the industry due to its ease of use. We can
    use other libraries, such as TensorFlow and Keras, to build neural networks as
    well, but we will focus on PyTorch in this book. Because the library is pythonic,
    it will be easier for data scientists and engineers who are already familiar with
    Python to use it. To learn more about PyTorch, please see appendix B.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们训练一个用于乳腺癌检测问题的深度神经网络（DNN）。我们将使用PyTorch来构建和训练网络。PyTorch是一个库，它简化了在Python中构建神经网络的过程。PyTorch因其易用性而受到研究人员和行业机器学习实践者的青睐。我们也可以使用其他库，如TensorFlow和Keras来构建神经网络，但在这本书中我们将专注于PyTorch。因为这个库是Pythonic的，所以对于已经熟悉Python的数据科学家和工程师来说，使用它将更容易。要了解更多关于PyTorch的信息，请参阅附录B。
- en: 'The first step before training the DNN is to prepare the data. The following
    code shows how to load the data—split it into training, validation, and test sets,
    and then transform them into inputs for the PyTorch implementation of the network:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练深度神经网络（DNN）之前的第一步是准备数据。以下代码展示了如何加载数据——将其分为训练集、验证集和测试集，然后将它们转换为网络PyTorch实现的输入：
- en: '[PRE0]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ① Imports NumPy, which is used for loading the dataset as vectors and matrices
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ① 导入NumPy，用于将数据集加载为向量和矩阵
- en: ② Imports the breast cancer dataset available in Scikit-Learn
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ② 导入Scikit-Learn中可用的乳腺癌数据集
- en: ③ Imports the train_test_split function available in Scikit-Learn
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 导入Scikit-Learn中可用的train_test_split函数
- en: ④ Imports PyTorch and the Variable data structure to store the input dataset
    as tensors
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 导入PyTorch和Variable数据结构，用于将输入数据集存储为张量
- en: ⑤ Loads the breast cancer dataset and extracts the features and target
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 加载乳腺癌数据集并提取特征和目标
- en: ⑥ Splits the data into train and validation/test sets
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 将数据分为训练集和验证/测试集
- en: '⑦ Splits the validation/test set into two equal sets: validation and test'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 将验证/测试集分为两个相等的集合：验证集和测试集
- en: ⑧ Initializes the train, validation, and test sets into PyTorch tensors
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 将训练集、验证集和测试集初始化为PyTorch张量
- en: Note that 70% of the data is used for training, 15% for validation, and the
    remaining 15% as the held-out test set. Let’s now check to see if the distribution
    of the target variable, shown in figure 4.10, is similar across the three sets.
    We can see that roughly 60–62% of the cases are benign (where the target variable
    = 1) and 38–40% of the cases are malignant (where the target variable = 0) in
    all three sets.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，70% 的数据用于训练，15% 用于验证，剩余的 15% 作为保留的测试集。现在让我们检查目标变量的分布，如图 4.10 所示，在三个集中是否相似。我们可以看到，在所有三个集中，大约
    60-62% 的情况是良性的（目标变量 = 1），38-40% 的情况是恶性的（目标变量 = 0）。
- en: '![](../Images/CH04_F10_Thampi.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F10_Thampi.png)'
- en: Figure 4.10 Target variable distribution across the training, validation, and
    test sets
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 训练集、验证集和测试集中目标变量的分布
- en: 4.3.2 Training and evaluating DNNs
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.2 训练和评估 DNN
- en: 'Now that we’ve prepared the data, the next step is to define the DNN. We will
    create a class where the number of layers and units can be passed in as attributes,
    as shown here:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了数据，下一步是定义 DNN。我们将创建一个类，其中可以传递层数和单元数作为属性，如下所示：
- en: '[PRE1]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ① Creates a Model class that inherits from the PyTorch Sequential class
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ① 创建一个从 PyTorch Sequential 类继承的 Model 类
- en: ② Passes the number of layers and units for each layer as an array to the constructor
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将每层的层数和单元数作为数组传递给构造函数
- en: ③ Initializes the PyTorch Sequential super class
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 初始化 PyTorch Sequential 超类
- en: ④ For each element in the array, extracts the index and the number of units
    for that layer
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 对于数组中的每个元素，提取该层的索引和单元数量
- en: ⑤ Creates a layer module containing all linear units until the final output
    layer
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 创建一个包含所有线性单元直到最终输出层的层模块
- en: ⑥ Uses the sigmoid activation function for the unit in the output layer
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 对输出层的单元使用 sigmoid 激活函数
- en: ⑦ Uses the ReLU activation function for all the units in the hidden layers
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 对隐藏层中的所有单元使用 ReLU 激活函数
- en: 'Note that the DNN `Model` class inherits from the PyTorch `Sequential` class,
    which layers modules in the sequential order that they are initialized. For the
    input layer and hidden layers, `Linear` units are used to compute a weighted sum
    of all the inputs to that unit. For the hidden layers, we use the ReLU activation
    function. The final output layer consists of a single unit where we use the sigmoid
    activation function. The output of a sigmoid activation function is a score between
    0 and 1\. This output acts as a proxy for a probability measure for the positive
    class in the classification task. In this case, the positive class is benign.
    Now that we have the `Model` class, let’s initialize it as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，DNN `Model` 类继承自 PyTorch `Sequential` 类，该类以初始化的顺序排列层模块。对于输入层和隐藏层，使用 `Linear`
    单元来计算该单元所有输入的加权和。对于隐藏层，我们使用 ReLU 激活函数。最终的输出层由一个单元组成，我们使用 sigmoid 激活函数。sigmoid
    激活函数的输出是一个介于 0 和 1 之间的分数。这个输出作为分类任务中正类概率度量的代理。在这种情况下，正类是良性。现在我们有了 `Model` 类，让我们按照以下方式初始化它：
- en: '[PRE2]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ① The number of units for the input layer is equal to the number of features
    in the training set.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ① 输入层的单元数量等于训练集中特征的数量。
- en: ② The number of units in the output layer is 1 because we are dealing with a
    binary classification problem.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ② 输出层的单元数量为 1，因为我们处理的是一个二元分类问题。
- en: ③ Initializes the layer dimensions array to define the structure for the DNN
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 初始化层维度数组以定义 DNN 的结构
- en: ④ Initializes the DNN model with the predefined structure
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 使用预定义的结构初始化 DNN 模型
- en: 'If you print the model, using the command `print(model)`, you will get the
    following output, which summarizes the structure of the DNN:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用命令 `print(model)` 打印模型，你会得到以下输出，它总结了 DNN 的结构：
- en: '[PRE3]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this output, you can see that the DNN consists of one input layer, three
    hidden layers, and one output layer. The input layer consists of 30 units because
    the dataset contains 30 input features. The first hidden layer consists of 20
    units, the second hidden layer consists of 10 units, and the third hidden layer
    consists of 5 units. The ReLU activation function is used for all the units in
    the hidden layers. Finally, the output layer consists of a single unit with a
    sigmoid activation function. The number of units in the input and output layers
    must be 30 and 1, respectively, for this dataset, because the number of features
    is 30 and only a single output is required for the binary classification task.
    You are, however, free to tune the number of hidden layers and the number of units
    in each hidden layer, depending on which structure gives the best performance.
    You can use the validation set to determine these hyperparameters.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个输出中，您可以看到DNN由一个输入层、三个隐藏层和一个输出层组成。输入层包含30个单元，因为数据集包含30个输入特征。第一个隐藏层包含20个单元，第二个隐藏层包含10个单元，第三个隐藏层包含5个单元。隐藏层中的所有单元都使用ReLU激活函数。最后，输出层由一个具有sigmoid激活函数的单个单元组成。对于这个数据集，输入层和输出层的单元数必须分别为30和1，因为特征数为30，并且二分类任务只需要一个输出。然而，您可以根据哪种结构给出最佳性能来调整隐藏层的数量和每个隐藏层的单元数。您可以使用验证集来确定这些超参数。
- en: 'With the model in place, let’s now define the loss function and the optimizer
    that will be used to determine the weights during backpropagation as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 模型就绪后，现在让我们定义损失函数和优化器，它们将用于在反向传播期间确定权重，如下所示：
- en: '[PRE4]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ① Initializes the binary cross-entropy (BCE) loss as the criterion for optimization
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ① 将二元交叉熵（BCE）损失初始化为优化的标准
- en: ② Uses the Adam optimizer with a learning rate of 0.001 to determine the weights
    during backpropagation
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ② 使用学习率为0.001的Adam优化器在反向传播期间确定权重
- en: 'As mentioned in the previous section, the BCE loss is used as the criterion
    of optimization for binary classification problems. We are also using the Adam
    optimizer here with a predefined initial learning rate to determine the edge weights
    during backpropagation. The Adam optimizer is a technique that adaptively determines
    the learning rate for the gradient descent algorithm. You can find more details
    on the Adam optimization technique in this blog post: [http://mng.bz/zQzX](http://mng.bz/zQzX).
    Finally, train the model as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，BCE损失被用作二分类问题的优化标准。我们在这里也使用Adam优化器，并使用预定义的初始学习率来确定反向传播期间的边权重。Adam优化器是一种自适应确定梯度下降算法学习率的技巧。您可以在以下博客文章中找到有关Adam优化技术的更多详细信息：[http://mng.bz/zQzX](http://mng.bz/zQzX)。最后，按照以下方式训练模型：
- en: '[PRE5]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ① Initializes the number of epochs to 300
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ① 将时代数初始化为300
- en: ② In each epoch, obtains the output of the DNN for the training set
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时代，获取训练集的DNN输出
- en: ③ Computes the BCE loss for the training set
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 计算训练集的BCE损失
- en: ④ Zeroes out the gradients before backpropagating
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 在反向传播之前将梯度置零
- en: ⑤ Computes the gradient with respect to every parameter/edge weight
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 计算每个参数/边权重的梯度
- en: ⑥ Updates the weights based on the current gradients
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 根据当前梯度更新权重
- en: Note that we are training the model over 300 epochs. An epoch is a hyperparameter
    that defines the number of times we propagate the entire training set in the forward
    and backward directions through the neural network. During each epoch, we first
    obtain the output of the DNN by propagating the training set through the network
    in the forward direction. We then compute the gradient with respect to every parameter
    or edge weight and update the weights during backpropagation. Note that the gradients
    are set to 0 in each epoch before starting backpropagation because PyTorch accumulates
    gradients during backward passes by default. If we do not set the gradients to
    0, the weights will not be updated correctly.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们正在对模型进行300个时代的训练。一个时代是一个超参数，它定义了我们在神经网络的前向和反向方向中传播整个训练集的次数。在每个时代，我们首先通过将训练集通过网络的前向方向传播来获取DNN的输出。然后，我们计算每个参数或边权重的梯度，并在反向传播期间更新权重。请注意，在每个时代开始反向传播之前，梯度被设置为0，因为PyTorch默认在反向传递期间累积梯度。如果我们不将梯度设置为0，权重将不会正确更新。
- en: The next step is to evaluate the model performance using the test set. Because
    this is a classification problem, we will use the same metrics that we used in
    chapter 3 for the student grade-prediction problem. The metrics we will use are
    precision, recall, and the F1 score. We will compare the performance of the trained
    DNN model with a reasonable baseline model. As seen in section 4.2, the majority
    of the cases in the dataset are benign. We will, therefore, consider a baseline
    model that always predicts benign. This is not ideal because we will get all the
    malignant cases wrong. In a real-life situation, the baseline model will typically
    be predictions made by a human or expert or an existing model that the business
    is using. For this example, unfortunately, we do not have access to that information,
    and so we will compare the model with a baseline that always predicts benign.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用测试集来评估模型性能。因为这是一个分类问题，我们将使用与第3章中用于学生成绩预测问题的相同指标。我们将使用的指标是精确率、召回率和F1分数。我们将比较训练好的深度神经网络（DNN）模型与一个合理的基线模型的性能。如第4.2节所示，数据集中大多数案例都是良性的。因此，我们将考虑一个总是预测良性的基线模型。这并不理想，因为我们将会错误地预测所有恶性案例。在现实情况下，基线模型通常是由人类或专家或企业正在使用的现有模型做出的预测。对于这个例子，不幸的是，我们没有获取到这些信息，因此我们将比较模型与总是预测良性的基线。
- en: Table 4.2 shows the three key performance metrics used to benchmark the models—precision,
    recall, and F1\. If we look at the recall metric, the baseline model does better
    than the DNN. This is expected because the baseline model is predicting the positive
    class all the time and will, therefore, get all the positive cases right. The
    recall with respect to the negative class, however, will be 0 for the baseline
    model. Overall, though, the DNN model does much better than the baseline, achieving
    a precision of 98.1% (+35.4% better than the baseline) and an F1 score of 96.2%
    (+19.1% better than the baseline).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.2显示了用于基准测试模型的三项关键性能指标——精确率、召回率和F1分数。如果我们看召回率指标，基线模型比深度神经网络（DNN）做得更好。这是预期的，因为基线模型总是预测正类，因此会正确地预测所有正类案例。然而，对于负类，基线模型的召回率将是0。尽管如此，深度神经网络（DNN）模型的整体表现仍然优于基线，实现了98.1%的精确率（比基线高35.4%）和96.2%的F1分数（比基线高19.1%）。
- en: As an exercise, I highly encourage you to tune the hyperparameters of the model
    and see if you can improve the performance of this model. You can tune the structure
    of the network by changing the number of hidden layers and units in each layer,
    and also the number of epochs used for training. In section 4.2 (figure 4.6),
    we also saw that some of the input features are highly correlated with each other.
    The performance of the model could be further improved by removing some of the
    redundant features. As another exercise, perform feature selection, and determine
    the best subset of features that maximizes the performance of the model.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一项练习，我强烈建议你调整模型的超参数，看看你是否能提高这个模型的性能。你可以通过改变网络结构中的隐藏层数量和每层的单元数，以及用于训练的epoch数来调整网络结构。在第4.2节（图4.6）中，我们也看到一些输入特征彼此之间高度相关。通过移除一些冗余特征，模型的性能可以进一步提高。作为另一项练习，进行特征选择，确定最大化模型性能的最佳特征子集。
- en: Table 4.2 Performance comparison of the baseline model with the DNN model
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.2 基线模型与深度神经网络（DNN）模型性能比较
- en: '|  | Precision (%) | Recall (%) | F1 score (%) |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|  | 精确率（%） | 召回率（%） | F1分数（%） |'
- en: '| Baseline model 1 | 62.7 | 100 | 77.1 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 基线模型1 | 62.7 | 100 | 77.1 |'
- en: '| DNN model | 98.1 (+35.4) | 94.4 (–5.6) | 96.2 (+19.1) |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 深度神经网络（DNN）模型 | 98.1 (+35.4) | 94.4 (–5.6) | 96.2 (+19.1) |'
- en: With the DNN model performing better than the baseline, let’s now interpret
    it and understand how the black-box model arrived at the final prediction.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度神经网络（DNN）模型的性能优于基线，现在让我们来解释它，并了解这个黑盒模型是如何得出最终预测的。
- en: 4.4 Interpreting DNNs
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 解释深度神经网络（DNN）
- en: 'As we saw in the previous section, to make a prediction with a DNN, we pass
    data through multiple layers, with each layer consisting of multiple units. The
    inputs to each layer go through a nonlinear transformation based on the weights
    and the activation function used for the units. A single prediction can involve
    a lot of mathematical operations, depending on the structure of the neural network.
    For the relatively simple architecture used in the previous section for breast
    cancer detection, a single prediction involved roughly 890 mathematical operations
    based on the number of training parameters or weights, as shown next:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如前节所述，要使用深度神经网络（DNN）进行预测，我们需要将数据通过多个层传递，每一层由多个单元组成。每一层的输入数据会根据单元使用的权重和激活函数进行非线性转换。一个单一的预测可能涉及大量的数学运算，这取决于神经网络的架构。对于前节中用于乳腺癌检测的相对简单的架构，一个单一的预测大约涉及890次数学运算，这是基于训练参数或权重的数量，如下所示：
- en: '[PRE6]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This example can very easily explode into millions of operations as we add more
    hidden layers and units per hidden layer. This is what makes DNNs black boxes—it
    becomes really difficult to understand what transformations each layer is doing
    and how the model arrives at the final prediction. We will see in later chapters
    that it becomes even more difficult with more complex structures like CNNs and
    RNNs.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们添加更多的隐藏层和每隐藏层的单元，这个例子可以非常容易地扩展到数百万次运算。这就是为什么DNN被称为黑盒——它变得非常难以理解每一层执行了什么转换以及模型是如何得出最终预测的。我们将在后面的章节中看到，对于像CNN和RNN这样更复杂的结构，这变得更加困难。
- en: One way we can interpret DNNs is by looking at the weights or the strengths
    of the edges connected to the units in the input layer. This could be seen as
    a proxy to determine the overall influence of the input features on the output
    prediction. It will not, however, give us an accurate measure of the feature importance
    as we saw for white-box models and tree ensembles in the previous chapters. The
    main reason is the neural network learns a representation of the input at the
    hidden layers. The initial input features are transformed into intermediate features
    and concepts. Therefore, the importance of those input features is not just dictated
    by the edges connected to the units in the input layer. So how do we interpret
    DNNs?
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以解释DNN的一种方式是查看连接到输入层单元的权重或边的强度。这可以被视为确定输入特征对输出预测的整体影响的代理。然而，它不会给我们一个像我们在前几章中看到的白盒模型和树集成那样准确的特征重要性度量。主要原因是因为神经网络在隐藏层学习输入的表示。初始输入特征被转换成中间特征和概念。因此，这些输入特征的重要性不仅仅由连接到输入层单元的边来决定。那么我们如何解释DNN呢？
- en: We have multiple ways of interpreting DNNs. We can use the model-agnostic methods
    we learned in the previous chapter that are global in scope. We learned about
    PDPs and feature interaction plots—model-agnostic techniques, meaning they are
    interpretability techniques that could work with any machine learning model. They
    are also global in scope, in that they look at the overall influence of the model
    on the final prediction. PDPs and feature interaction plots are easy and intuitive
    to use, and they are great tools for shedding light into how specific feature
    values influence the model output. We also learned how they can be used to uncover
    potential issues like data and model bias. We could very easily apply these techniques
    to the DNN model trained for breast cancer detection. For PDPs and feature interaction
    plots to work, however, the input features for the model have to be independent,
    and we saw in section 4.2 that they are not.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有多种方式来解释DNN。我们可以使用在前一章中学到的模型无关方法，这些方法具有全局范围。我们学习了PDPs（Partial Dependence Plots）和特征交互图——模型无关的技术，意味着它们是可以与任何机器学习模型一起工作的可解释性技术。它们在范围上也是全局的，因为它们查看模型对最终预测的整体影响。PDPs和特征交互图易于使用且直观，它们是揭示特定特征值如何影响模型输出的优秀工具。我们还学习了如何使用它们来揭示潜在问题，如数据和模型偏差。我们可以非常容易地将这些技术应用到为乳腺癌检测训练的DNN模型上。然而，为了使PDPs和特征交互图起作用，模型的输入特征必须是独立的，我们在第4.2节中看到它们并不是。
- en: In the subsequent sections, we will learn about more advanced model-agnostic
    techniques, specifically focusing on LIME, SHAP, and anchors. These interpretability
    techniques are local in scope, that is, they focus on a specific instance or example
    to interpret. In later chapters, we will learn about feature attribution methods
    that aim to quantify the contribution of each input feature on the final prediction
    and also learn how to dissect the neural network and visualize the features learned
    by the intermediate hidden layers and units.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将学习更多高级的模型无关技术，特别是关注LIME、SHAP和锚点。这些可解释技术是局部的，也就是说，它们专注于解释特定的实例或示例。在后面的章节中，我们将学习特征归因方法，旨在量化每个输入特征对最终预测的贡献，并学习如何剖析神经网络以及可视化中间隐藏层和单元学习到的特征。
- en: 4.5 LIME
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.5 LIME
- en: LIME, an acronym for local interpretable model-agnostic explanations, was proposed
    in 2016 by Marco Tulio Ribeiro and team. Let’s break down this technique. In the
    previous section, we trained a DNN that learned how to separate the benign cases
    from the malignant cases using 30 features. Let’s simplify this by collapsing
    the feature space into 2-D space, as shown in figure 4.11\. The figure illustrates
    the complex decision function learned by the DNN where the model separates the
    benign cases from the malignant cases. The decision boundary is intentionally
    exaggerated in figure 4.11 to illustrate a complex function that is harder to
    explain globally and possibly easier to explain locally using a technique such
    as LIME.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: LIME，即局部可解释模型无关解释的缩写，由Marco Tulio Ribeiro及其团队于2016年提出。让我们分解这项技术。在上一个章节中，我们训练了一个DNN，它使用30个特征学习如何区分良性病例和恶性病例。让我们通过将特征空间折叠成2-D空间来简化这一点，如图4.11所示。该图展示了DNN学习到的复杂决策函数，其中模型将良性病例与恶性病例分开。决策边界在图4.11中被故意夸张，以说明一个全局上难以解释但可能通过LIME等技术局部解释的复杂函数。
- en: '![](../Images/CH04_F11_Thampi.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F11_Thampi.png)'
- en: Figure 4.11 A 2-D illustration of a complex decision boundary learned by the
    DNN (or any black-box model) to separate the benign cases from the malignant cases
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11 DNN（或任何黑盒模型）学习到的复杂决策边界的2-D示意图，用于区分良性病例和恶性病例
- en: LIME first picks an example to interpret. This is shown in figure 4.12 where
    we have picked one malignant case to interpret. The aim is to probe the model
    as often as needed to interpret how the model comes up with the prediction for
    that picked example. You can probe the model by *perturbing* the dataset to get
    the model predictions for that new dataset.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: LIME首先选择一个示例进行解释。这如图4.12所示，我们选择了一个恶性病例进行解释。目标是尽可能频繁地探测模型，以解释模型是如何对所选示例做出预测的。你可以通过*扰动*数据集来获取该新数据集的模型预测。
- en: '![](../Images/CH04_F12_Thampi.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F12_Thampi.png)'
- en: Figure 4.12 An illustration of an instance picked to interpret using LIME
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 使用LIME选择的实例进行解释的示意图
- en: How do we create this new *perturbed dataset* ? Given the training data, we
    calculate the key summary statistics for each feature. For numerical or continuous
    features, we calculate the mean and standard deviation. For categorical features,
    we compute the frequency of each value. Then we create a new dataset by sampling
    based on these summary statistics. For numerical features, we sample data from
    a Gaussian distribution, given the mean and standard deviation for that feature.
    For categorical features, we sample based on the frequency distribution or probability
    mass function. Once we’ve created this dataset, we probe the model by getting
    predictions for them, as shown in figure 4.13\. The picked instance is shown as
    the big plus sign. The malignant and benign predictions on the perturbed dataset
    are shown as small plus signs and circles, respectively.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何创建这个新的*扰动数据集*？给定训练数据，我们计算每个特征的关键摘要统计量。对于数值或连续特征，我们计算均值和标准差。对于分类特征，我们计算每个值的频率。然后我们根据这些摘要统计量创建一个新的数据集。对于数值特征，我们根据该特征的均值和标准差从高斯分布中采样数据。对于分类特征，我们根据频率分布或概率质量函数进行采样。一旦我们创建了数据集，我们就通过获取它们的预测来探测模型，如图4.13所示。所选实例以大加号表示。在扰动数据集上的恶性和良性预测分别以小加号和圆圈表示。
- en: '![](../Images/CH04_F13_Thampi.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F13_Thampi.png)'
- en: Figure 4.13 An illustration of a generated or perturbed dataset and the corresponding
    model predictions
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13 生成的或扰动的数据集及其相应的模型预测示意图
- en: Once we have created the perturbed dataset and obtained the model predictions
    for them, we weight these new samples by their proximity to the picked instance
    to interpret the picked instance by looking at cases similar to it in terms of
    features. The locality of the interpretation is captured by this weighting—hence,
    the “local” in the acronym LIME. Figure 4.14 shows the perturbed samples that
    are close to the picked instance given a higher weight.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们创建了扰动数据集并获得了它们的模型预测，我们将根据这些新样本与所选实例的接近程度对它们进行加权，通过查看在特征方面类似的案例来解释所选实例。这种解释的局部性通过这种加权来捕捉——因此，LIME缩写中的“局部”。图4.14显示了给定的扰动样本，它们接近所选实例并赋予更高的权重。
- en: '![](../Images/CH04_F14_Thampi.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F14_Thampi.png)'
- en: Figure 4.14 An illustration of weighted instances in close proximity to the
    picked instance to interpret
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14 解释了与所选实例紧密相邻的加权实例的示意图
- en: 'Now, how do we weight the samples based on their proximity to the picked instance?
    In the original paper, the authors use the exponential kernel function. The *exponential
    kernel function* takes two parameters as inputs:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何根据样本与所选实例的接近程度来加权样本？在原始论文中，作者使用了指数核函数。*指数核函数*接受两个参数作为输入：
- en: '*Distance of perturbed sample from picked instance*—For the breast cancer dataset
    (or tabular data in general), we use Euclidean distance to measure the distance
    of the perturbed sample from the picked instance in the feature space. Euclidean
    distance is also used for images. For text, the cosine distance measure is used.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*扰动样本与所选实例的距离*——对于乳腺癌数据集（或一般表格数据），我们使用欧几里得距离来测量扰动样本在特征空间中与所选实例的距离。欧几里得距离也用于图像。对于文本，使用余弦距离度量。'
- en: '*Kernel width*—his is a hyperparameter that can be tuned. If the width is small,
    only samples that are close to the picked instance will influence the interpretation.
    If the width is large, however, samples that are further away can influence the
    interpretation. This is an important hyperparameter, and we will study its impact
    on the interpretation in greater depth later. By default, the kernel width is
    set to 0.75 × √*Number of features*. So, for the model with 30 input features,
    the default kernel width is 4.1\. The value of the kernel width can range from
    zero to infinity.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*核宽度*——这是一个可以调整的超参数。如果宽度较小，只有接近所选实例的样本会影响解释。然而，如果宽度较大，则距离较远的样本也可以影响解释。这是一个重要的超参数，我们将在稍后更深入地研究其对解释的影响。默认情况下，核宽度设置为0.75
    × √*特征数量*。因此，对于具有30个输入特征的模型，默认核宽度为4.1。核宽度的值可以从零到无穷大。'
- en: Using the exponential kernel function, samples closer to the picked instance
    in terms of distance will have a larger weight than samples further away.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指数核函数，距离所选实例较近的样本在距离方面将具有更大的权重，而距离较远的样本权重较小。
- en: The final step is to fit a white-box model that is easily interpretable on the
    weighted samples. In LIME, linear regression is used, and as we’ve seen in chapter
    2, we can use the weights of the linear regression model to interpret the importance
    of features for that picked instance—hence the “interpretable” in the acronym
    LIME. We get an interpretation that is locally faithful, and because we’re fitting
    a linear surrogate model, LIME is totally agnostic of the DNN or black-box model—hence,
    the “model-agnostic” in the acronym LIME. Figure 4.15 illustrates the linear surrogate
    model (shown by the dashed gray line) that is faithful to the region near and
    around the instance picked to interpret.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是拟合一个易于在加权样本上解释的白色盒模型。在LIME中，使用线性回归，正如我们在第2章中看到的，我们可以使用线性回归模型的权重来解释所选实例的特征重要性——因此，LIME缩写中的“可解释”。我们得到一个局部忠诚的解释，因为我们拟合了一个线性代理模型，LIME对DNN或黑盒模型是完全无知的——因此，LIME缩写中的“模型无关”。图4.15展示了用于解释所选实例的线性代理模型（由虚线灰色线表示），该模型忠实于所选实例附近和周围的区域。
- en: '![](../Images/CH04_F15_Thampi.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH04_F15_Thampi.png)'
- en: Figure 4.15 An illustration of a linear model that is used to interpret the
    picked instance using the weighted samples around it
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.15 展示了用于使用周围加权样本解释所选实例的线性模型
- en: 'Let’s now get our hands dirty and see LIME in action for the breast cancer
    diagnostics DNN model that we trained earlier. First, install the LIME library
    using pip as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们动手看看LIME在之前训练的乳腺癌诊断DNN模型上的实际应用。首先，使用pip安装LIME库，如下所示：
- en: '[PRE7]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After installing, the first step is to initialize a LIME explainer object.
    Because the dataset is tabular, we use the `LimeTabularExplainer` class. Other
    explainer classes are `LimeImageExplainer` to explain models that use images as
    inputs and `LimeTextExplainer` for text. We will make use of the `LimeImageExplainer`
    class in the next chapter when we deal with images:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 安装后，第一步是初始化一个 LIME 解释器对象。因为数据集是表格式的，所以我们使用 `LimeTabularExplainer` 类。其他解释器类有
    `LimeImageExplainer` 用于解释使用图像作为输入的模型，以及 `LimeTextExplainer` 用于文本。我们将在下一章中使用 `LimeImageExplainer`
    类来处理图像：
- en: '[PRE8]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ① Imports the library and the relevant modules
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ① 导入库和相关模块
- en: ② Initializes the explainer using the training dataset
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ② 使用训练数据集初始化解释器
- en: ③ Provides the feature names
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 提供特征名称
- en: ④ Provides the target class names (benign/malignant)
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 提供目标类名（良性/恶性）
- en: ⑤ Discretizes the continuous variables to reduce computational complexity
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 将连续变量离散化以降低计算复杂度
- en: 'Let’s now pick two cases to interpret—one benign and one malignant. We will
    use the test set here where we pick the first benign and malignant cases, as shown
    in the following code:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们选择两个案例进行解释——一个是良性，一个是恶性。在这里我们将使用测试集，选择第一个良性案例和恶性案例，如下面的代码所示：
- en: '[PRE9]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We need to create a helper function to provide the predictions of the DNN model
    for the perturbed dataset, as shown here:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要创建一个辅助函数来提供对扰动数据集的 DNN 模型预测，如下所示：
- en: '[PRE10]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We also need to create another function to plot the LIME interpretation in
    Matplotlib. We can create this plot using the library, but it doesn’t allow customizations.
    This is why we’ve created this helper function so that we can add titles and labels,
    change the colors, and even create our own plots using the LIME interpretation:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要创建另一个函数来在 Matplotlib 中绘制 LIME 解释。我们可以使用库来创建这个图，但它不允许自定义。这就是我们创建这个辅助函数的原因，这样我们就可以添加标题和标签，更改颜色，甚至使用
    LIME 解释创建我们自己的图表：
- en: '[PRE11]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s now interpret the first benign case. This is shown next, where we pass
    the picked benign case to the LIME explainer:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们解释第一个良性案例。如下所示，我们将选定的良性案例传递给 LIME 解释器：
- en: '[PRE12]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ① Passes the features of the picked benign case to the function
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ① 将选定的良性案例的特征传递给函数
- en: ② Passes the helper function that provides the predictions for the perturbed
    dataset
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ② 传递提供扰动数据集预测的辅助函数
- en: ③ Limits the number of features for the linear surrogate model to 5
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 限制线性代理模型的特征数量为 5
- en: ④ The top label or positive class is 1.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 最高标签或正类是 1。
- en: ⑤ Uses the helper function to plot the LIME interpretation
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 使用辅助函数绘制 LIME 解释
- en: Note that we are limiting the number of features for the linear surrogate model
    to 5\. LIME uses a ridge regression model as the surrogate model by default. Ridge
    regression is a variant of the linear regression model that allows for variable
    selection or parameter elimination through regularization. By using a high regularization
    parameter, we can create sparse models that pick only a few top features for prediction.
    We can use a low regularization parameter for less sparsity. Figure 4.16 shows
    the resulting LIME interpretation for the benign case.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们正在将线性代理模型的特征数量限制为 5。LIME 默认使用岭回归模型作为代理模型。岭回归是线性回归模型的一个变体，它通过正则化允许变量选择或参数消除。通过使用高正则化参数，我们可以创建稀疏模型，仅选择几个顶级特征进行预测。我们可以使用低正则化参数以获得更少的稀疏性。图
    4.16 显示了良性案例的 LIME 解释结果。
- en: For the benign case used to interpret with LIME, the DNN model predicted that
    it was benign with a probability of 0.99, or a confidence of 99%. To understand
    how it arrived at that prediction, figure 4.16 shows the top five most important
    features for the linear surrogate model and their corresponding weights or importance.
    It looks like the most important feature was the worst area with a large positive
    weight. According to LIME, the reason the model predicted benign was because the
    worst area value was between 511 and 683.95\. How did LIME get this range of values?
    It is based on the standard deviation of the weighted perturbed dataset used by
    the linear surrogate model. Now, does this interpretation make sense? To validate
    this, we must go back to the exploratory data analysis that we did in section
    4.2\. We saw in figure 4.3 that when the worst or largest cell area is less than
    700, a lot more cases are benign than malignant.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用LIME进行解释的良性案例，DNN模型预测它为良性，概率为0.99，或信心度为99%。为了理解它是如何得出这个预测的，图4.16显示了线性代理模型的前五个最重要的特征及其相应的权重或重要性。看起来最重要的特征是最差区域，具有较大的正值权重。根据LIME，模型预测良性是因为最差区域值在511和683.95之间。LIME是如何得到这个值域的？这是基于线性代理模型使用的加权扰动数据集的标准差。现在，这个解释合理吗？为了验证这一点，我们必须回到我们在4.2节中进行的探索性数据分析。我们在图4.3中看到，当最差或最大的细胞面积小于700时，良性案例比恶性案例多得多。
- en: '![](../Images/CH04_F16_Thampi.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F16_Thampi.png)'
- en: Figure 4.16 LIME interpretation of benign case 1 where the DNN model predicted
    benign with a confidence of 99%
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.16 深度神经网络模型预测为良性的第一个良性案例的LIME解释，置信度为99%
- en: If we now look at the second most important feature identified by LIME, we can
    see that if the mean area is between 415.63 and 544.05, it is much more likely
    for the case to be benign. This is further validated by our observation made in
    figure 4.3\. We can also make a similar observation for the third most important
    feature—mean perimeter. You might have observed the kernel width and a score in
    the title in figure 4.16\. We will come to this in a bit.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在查看LIME确定的第二个最重要的特征，我们可以看到，如果平均面积在415.63和544.05之间，案例为良性的可能性就大得多。这一点进一步得到了我们在图4.3中的观察的验证。我们也可以对第三个最重要的特征——平均周长——做出类似的观察。你可能已经在图4.16的标题中观察到了核宽度和一个分数。我们稍后会讨论这一点。
- en: Let’s now look at the first malignant case in the test set to interpret using
    LIME. We can use the same code as before, but we need to remember to pick the
    right feature values from the test set using `malignant_idx`. As an exercise,
    I encourage you to do that yourself. The resulting LIME interpretation is shown
    in figure 4.17\. The two most important features are the same as the benign case,
    but the range of values is different. Moreover, the weight for the most important
    features (worst cell area) is also negative. This makes sense because we expect
    the feature to have a negative effect on the model’s output. The DNN is trained
    to predict the probability of the positive class, which is, in this case, benign.
    Therefore, if the case is malignant, we expect the output of the model to be as
    low as possible; that is, the probability that the case is benign must be as low
    as possible.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来查看测试集中第一个恶性案例，并使用LIME进行解释。我们可以使用之前相同的代码，但需要记住使用`malignant_idx`从测试集中选择正确的特征值。作为一个练习，我鼓励你自己去尝试。得到的LIME解释如图4.17所示。最重要的两个特征与良性案例相同，但值域不同。此外，最重要的特征（最差细胞面积）的权重也是负值。这很有道理，因为我们预期该特征会对模型的输出产生负面影响。深度神经网络（DNN）被训练来预测正类的概率，在这种情况下，是良性。因此，如果案例是恶性的，我们期望模型的输出尽可能低；也就是说，案例为良性的概率必须尽可能低。
- en: '![](../Images/CH04_F17_Thampi.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F17_Thampi.png)'
- en: Figure 4.17 LIME interpretation of malignant case 1 where the DNN model predicted
    malignant with confidence of 100%
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.17 深度神经网络模型预测为恶性的第一个恶性案例的LIME解释，置信度为100%
- en: For this malignant case, the DNN predicts that the case is benign with a probability
    of 0\. This means that the model is 100% confident that the case is malignant.
    Now let’s inspect the feature value ranges. We can see that the model predicted
    malignant because the worst, or largest, cell area is greater than 683.95 but
    less than 1030.75\. This makes sense because from the exploratory analysis, we
    observed more malignant cases than benign cases in that range (see figure 4.3).
    We can make similar observations for the other features.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个恶性案例，DNN预测该案例为良性的概率为0。这意味着模型100%确信该案例为恶性。现在让我们检查特征值范围。我们可以看到，模型预测为恶性，因为最坏或最大的细胞面积大于683.95但小于1030.75。这在探索性分析中是有意义的，因为我们观察到在该范围内恶性案例比良性案例多（见图4.3）。对于其他特征，我们可以做出类似的观察。
- en: Impact of the Kernel Width It is important to point out that the kernel width
    is an important hyperparameter for LIME. Picking the right kernel width is important
    and has an impact on the quality of the interpretation. We can’t pick the same
    kernel width for all instances that we wish to interpret. The choice of width
    has an impact on the weighted perturbed samples that LIME considers for the linear
    surrogate model. If we choose a large kernel width, samples further away from
    the picked instance will influence the linear surrogate model. This may not be
    desirable because we want the surrogate model to be as locally faithful to the
    original black-box model as possible. By default, the LIME library uses a kernel
    width that is the square root of the number of features multiplied by a factor
    of 0.75\. So, if `kernel_width` `=` `None`, the default value is used. It may
    be the case that the same kernel width may not be applicable for all instances
    that need to be interpreted using LIME. To evaluate the quality of the interpretation,
    LIME provides an explanation, or fidelity score. The parameter is called `score`
    for the resulting LIME explanation. A higher score means that the linear model
    used by LIME is a good approximation of the black-box model. The kernel width
    and the LIME fidelity score are shown in the title for figures 4.16 and 4.17.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 内核宽度的影响需要指出的是，内核宽度是LIME的一个重要超参数。选择合适的内核宽度非常重要，并且会影响解释的质量。我们不能为所有希望解释的实例选择相同的内核宽度。宽度的选择会影响LIME考虑的加权扰动样本，用于线性代理模型。如果我们选择较大的内核宽度，距离选定的实例较远的样本将影响线性代理模型。这可能不是我们想要的，因为我们希望代理模型尽可能忠实地反映原始的黑盒模型。默认情况下，LIME库使用一个内核宽度，它是特征数量的平方根乘以0.75的因子。因此，如果`kernel_width`
    `=` `None`，则使用默认值。可能的情况是，相同的内核宽度可能不适用于所有需要使用LIME解释的实例。为了评估解释的质量，LIME提供了一个解释，或称为保真度分数。该参数称为`score`，用于结果LIME解释。分数越高，意味着LIME使用的线性模型是黑盒模型的良好近似。内核宽度和LIME保真度分数在图4.16和图4.17的标题中显示。
- en: 'Let’s now look at the impact of the kernel width by looking at another benign
    case. We have picked the second case here from the test set, as shown next:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们通过观察另一个良性案例来分析内核宽度的影响。我们在此选择了测试集的第二种情况，如下所示：
- en: '[PRE13]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The LIME explainer we created earlier used the default value, which is 0.75
    × *sqrt(number of features)*. This evaluates to a kernel width of 4 because the
    number of features in the dataset is 30\. We will also create another LIME explainer
    that is initialized with a smaller kernel width of 1 to see the impact on the
    interpretation. The following code shows how to create a LIME explainer with kernel
    width = 1:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前创建的LIME解释器使用了默认值，即0.75乘以*特征数量的平方根*。这计算出的内核宽度为4，因为数据集中的特征数量为30。我们还将创建另一个LIME解释器，其初始化内核宽度为1，以观察对解释的影响。以下代码显示了如何创建内核宽度为1的LIME解释器：
- en: '[PRE14]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ① The kernel_width parameter is set to 1.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ① 将`kernel_width`参数设置为1。
- en: The resulting LIME interpretations using the default kernel width and kernel
    width of 1 for the second benign case are shown in figure 4.18 (a) and figure
    4.18 (b), respectively.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 使用默认内核宽度和内核宽度为1的第二个良性案例的LIME解释结果分别显示在图4.18（a）和图4.18（b）中。
- en: '![](../Images/CH04_F18a_Thampi.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F18a_Thampi.png)'
- en: Figure 4.18a LIME interpretation of benign case 2 with a default kernel width
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.18a 默认内核宽度的良性案例2的LIME解释
- en: '![](../Images/CH04_F18b_Thampi.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F18b_Thampi.png)'
- en: Figure 4.18b LIME interpretation of benign case 2 with a kernel width of 1
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.18b 内核宽度为1的良性案例2的LIME解释
- en: Let’s first compare the default LIME interpretation of the second benign case
    with the first case shown earlier. The first most important feature is the same.
    We can see, however, that the range of values for the features is different. For
    the second benign case, we see that the model predicted benign because the worst
    cell area was less than 511, as opposed to being between 511 and 683.95, as seen
    for the first case. This is still a valid prediction because a lot more cases
    are benign when the worst area is less than 511\. The fidelity score is also higher
    for default LIME interpretation of the second benign case. This means that the
    linear model in LIME reflects the DNN model more closely for this case than the
    first one.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将默认LIME解释的第二良性案例与之前展示的第一个案例进行比较。最重要的特征是相同的。然而，我们可以看到特征的值域是不同的。对于第二个良性案例，我们看到模型预测良性是因为最坏细胞的面积小于511，而第一个案例的面积介于511和683.95之间。这仍然是一个有效的预测，因为当最坏面积小于511时，有更多的案例是良性的。第二个良性案例的默认LIME解释的保真度分数也更高。这意味着LIME中的线性模型在这个案例中比第一个案例更接近DNN模型。
- en: If we now switch to figure 4.18 (b), we can see how different the interpretation
    is if we use a smaller kernel width. The top-most feature is still the same, but
    we see different features and a much smaller range of values for them because
    a small kernel width focuses the linear surrogate model on perturbed cases that
    are very close to the picked instance. Which kernel width is better for the second
    benign case? We can see that a kernel width of 1 achieves a fidelity score of
    only 0.27, as opposed to 0.22 for the default. Therefore, a kernel width of 1
    is better in this case. As an exercise, I highly encourage you to increase the
    kernel width for the second case to see if you can achieve a higher fidelity score
    and to analyze the resulting LIME plot. I also suggest you tune the kernel width
    hyperparameter for the first case to see if you can get a better interpretation
    that is much more faithful to the DNN.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在切换到图4.18（b），我们可以看到如果我们使用较小的核宽度，解释会有多么不同。最上面的特征仍然是相同的，但我们看到不同的特征以及它们的一个小得多的值域，因为小的核宽度将线性代理模型集中在与所选实例非常接近的扰动案例上。对于第二个良性案例，哪个核宽度更好？我们可以看到，核宽度为1的保真度分数仅为0.27，而默认值为0.22。因此，在这个案例中，核宽度为1更好。作为一个练习，我强烈建议你增加第二个案例的核宽度，看看你是否可以达到更高的保真度分数，并分析结果LIME图。我还建议你调整第一个案例的核宽度超参数，看看你是否可以得到一个更好的解释，这个解释与DNN的忠实度更高。
- en: Figure 4.19 (a) and figure 4.19 (b) show the LIME interpretations for the second
    malignant case for two kernel widths—one default and the other with width 1\.
    As an exercise, compare these interpretations with the first malignant case and
    see which kernel width gives you a higher quality interpretation.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.19（a）和图4.19（b）展示了第二个恶性案例的两个核宽度的LIME解释——一个是默认宽度，另一个是宽度为1。作为一个练习，比较这些解释与第一个恶性案例，看看哪个核宽度给出了更高质量的解释。
- en: '![](../Images/CH04_F19a_Thampi.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F19a_Thampi.png)'
- en: Figure 4.19a LIME interpretation of malignant case 2 with a default kernel width
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.19a 默认核宽度的LIME解释的恶性案例2
- en: '![](../Images/CH04_F19b_Thampi.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F19b_Thampi.png)'
- en: Figure 4.19b LIME interpretation of malignant case 2 with a kernel width of
    1
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.19b 核宽度为1的LIME解释的恶性案例2
- en: LIME is a great tool for interpreting black-box models. It is model-agnostic
    and can work with different types of models. LIME can also work with different
    types of data—tabular data, images, and text. We have seen it in action using
    tabular data in this section. We will explore images and text data in later chapters,
    and you can find examples in the library documentation ([https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)).
    It is a widely used library with lots of active contributors.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: LIME是一个解释黑盒模型的优秀工具。它是模型无关的，可以与不同类型的模型一起工作。LIME还可以与不同类型的数据一起工作——表格数据、图像和文本。我们已经在本节中看到了它使用表格数据的实际应用。我们将在后面的章节中探索图像和文本数据，你可以在库文档中找到示例（[https://github.com/marcotcr/lime](https://github.com/marcotcr/lime)）。这是一个广泛使用的库，拥有许多活跃的贡献者。
- en: The quality of the LIME interpretation, however, depends greatly on the choice
    of the kernel width, which is an input to the kernel function that is used to
    weight the perturbed samples. It is an important hyperparameter, and we have seen
    that the width could be different for different examples that we pick to interpret.
    We can use the fidelity score provided by the library to determine the right width,
    but the selection of the right kernel width is still ambiguous. Another limitation
    of LIME is that the perturbed dataset is created by sampling from a Gaussian distribution,
    and it ignores correlations between features. The perturbed dataset may, therefore,
    not have the same characteristics as the original training data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，LIME解释的质量在很大程度上取决于核宽度的选择，这是用于加权扰动样本的核函数的输入。它是一个重要的超参数，我们已看到对于不同例子，我们选择的宽度可能不同。我们可以使用库提供的保真度分数来确定正确的宽度，但选择正确的核宽度仍然是不明确的。LIME的另一个限制是，扰动数据集是通过从高斯分布中进行采样创建的，并且它忽略了特征之间的相关性。因此，扰动数据集可能不具有与原始训练数据相同的特征。
- en: 4.6 SHAP
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.6 SHAP
- en: SHAP, an acronym for SHapley Additive exPlanations, was proposed in 2017 by
    Scott M. Lundberg and Su-In Lee. It unifies the idea behind LIME (and linear surrogate
    models) and game theory and provides more mathematical guarantees on the accuracy
    of the explanations than LIME. A *Shapley value* is a concept from game theory
    that quantifies the impact of a coalition of players in a cooperative game. Let’s
    now see what we mean by a cooperative game, the players of the game, and coalitions
    of players. In the context of model interpretability, the cooperative game is
    the model and the predictions it comes up with. The input features to the model
    are equivalent to players, and coalitions of players are sets of features that
    interact with each other to come up with the final prediction. Shapley values
    could, therefore, be used to quantify the impact of features (i.e., players) and
    their interactions (i.e., player coalitions) on a model prediction (i.e., cooperative
    game). Let’s break down the SHAP interpretability technique by looking at the
    concrete example shown in figure 4.20.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP，即SHapley Additive exPlanations的缩写，由Scott M. Lundberg和Su-In Lee于2017年提出。它统一了LIME（以及线性代理模型）和博弈论的思想，并在解释的准确性方面提供了比LIME更多的数学保证。*Shapley值*是博弈论中的一个概念，它量化了合作游戏中玩家联盟的影响。现在让我们看看我们所说的合作游戏、游戏的玩家以及玩家联盟的含义。在模型可解释性的背景下，合作游戏是模型及其做出的预测。输入到模型中的特征相当于玩家，而玩家联盟是相互作用的特征集，以得出最终预测。因此，Shapley值可以用来量化特征（即玩家）及其相互作用（即玩家联盟）对模型预测（即合作游戏）的影响。让我们通过查看图4.20中所示的具体示例来分解SHAP可解释性技术。
- en: The idea behind SHAP is quite similar to that behind LIME. The first step is
    to pick an instance to explain. In figure 4.20, the picked instance is shown as
    the first row in index 0\. Because SHAP uses game-theoretic concepts, the picked
    instance consists of a coalition of all the features. When all the features are
    selected, or “switched on,” it is represented by a vector containing all 1s for
    all the features in the dataset. The first column in figure 4.20 shows the *coalition
    vector* as a table. For the picked instance, the coalition vector consists of
    all 1s, so we pick all the actual feature values for that instance when we convert
    that vector into the feature space. This *feature vector* is shown as a table
    in the second column in figure 4.20.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP背后的思想与LIME背后的思想相当相似。第一步是选择一个实例进行解释。在图4.20中，选择的实例显示为索引0的第一行。由于SHAP使用博弈论概念，选择的实例由所有特征的联盟组成。当所有特征都被选中，或“打开”时，它由包含所有特征的所有1s的向量表示。图4.20的第一列显示了*联盟向量*作为表格。对于选择的实例，联盟向量由所有1s组成，因此当我们把该向量转换到特征空间时，我们选择该实例的所有实际特征值。这个*特征向量*在图4.20的第二列中作为表格显示。
- en: '![](../Images/CH04_F20_Thampi.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F20_Thampi.png)'
- en: Figure 4.20 An illustration of creating the perturbed dataset for SHAP
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.20 创建SHAP扰动数据集的说明
- en: Once we’ve picked the instance to interpret, the next step is to create the
    perturbed dataset. This process is the same as in LIME, but unlike with LIME,
    the idea in SHAP is to generate a bunch of coalition vectors where features are
    randomly “switched on” or “switched off.” If a feature is switched on, its value
    in the coalition vector is 1\. If the feature is switched off, its value in the
    coalition vector is 0\. We know how to represent the feature in the feature space
    when it is switched on—we just pick the actual value from the instance that we’ve
    picked to interpret. If, however, the feature is switched off, we pick a value
    randomly from the training set for that feature.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们选择了要解释的实例，下一步就是创建扰动数据集。这个过程与LIME相同，但与LIME不同，SHAP的思路是生成一系列联盟向量，其中特征是随机“开启”或“关闭”。如果一个特征被开启，其在联盟向量中的值为1。如果一个特征被关闭，其在联盟向量中的值为0。我们知道如何在特征空间中表示开启时的特征——我们只需从已选择的实例中选取实际值。然而，如果特征被关闭，我们从训练集中随机选取该特征的一个值。
- en: After creating the perturbed dataset, the next step is to weight the dataset
    based on its proximity to the picked instance. This is again similar to LIME,
    but unlike with LIME, SHAP uses the *SHAP kernel* to determine the weights for
    the samples in the perturbed dataset as opposed to the exponential kernel function.
    The SHAP kernel function gives higher weight to coalitions that consist of very
    low or very high numbers of features. The next steps are then the same as with
    LIME, which is to fit a linear model on the weighted dataset and return the coefficients
    or weights of the linear model as the interpretation for that picked instance.
    These coefficients or weights are called *Shapley values*.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 创建扰动数据集后，下一步是根据其与所选实例的接近程度对数据集进行加权。这又与LIME相似，但与LIME不同，SHAP使用*SHAP核*来确定扰动数据集中样本的权重，而不是指数核函数。SHAP核函数会给包含非常低或非常高数量特征的联盟更高的权重。接下来的步骤与LIME相同，即在加权数据集上拟合线性模型，并返回线性模型的系数或权重作为所选实例的解释。这些系数或权重被称为*Shapley值*。
- en: 'Let’s now see SHAP in action on the breast cancer diagnostics model trained
    earlier. The authors of SHAP have created a Python library in GitHub. We can install
    this library using pip as follows:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看SHAP在之前训练的乳腺癌诊断模型上的实际应用。SHAP的作者在GitHub上创建了一个Python库。我们可以使用pip安装此库，如下所示：
- en: '[PRE15]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We will use the same helper function called `prob` (introduced in the previous
    section on LIME) to provide the DNN model predictions for the perturbed dataset.
    You can now create the perturbed dataset and initialize the SHAP explainer as
    follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用之前在LIME部分介绍的名为`prob`的相同辅助函数来提供对扰动数据集的DNN模型预测。你现在可以创建扰动数据集并初始化SHAP解释器，如下所示：
- en: '[PRE16]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ① Initializes JavaScript for interactive visualizations
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ① 初始化JavaScript以进行交互式可视化
- en: ② Uses the prob helper function to obtain the DNN predictions
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ② 使用prob辅助函数获取DNN预测
- en: ③ Uses the logit link function because the DNN is a classifier
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 使用对数连接函数，因为DNN是一个分类器
- en: 'Note that the logit link function is used for the linear surrogate model because
    we are dealing with a binary classifier that outputs a probability estimate for
    the positive class. For regression problems, you can switch the `link` parameter
    to `identity`. Next, obtain the SHAP values for all the data in the test set as
    follows:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对数连接函数用于线性代理模型，因为我们处理的是一个二元分类器，它为正类输出概率估计。对于回归问题，你可以将`link`参数切换到`identity`。接下来，按照以下方式获取测试集中所有数据的SHAP值：
- en: '[PRE17]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You can now obtain the SHAP interpretation for the first benign case as a Matplotlib
    plot as shown here:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以像这里所示的那样，以Matplotlib图的形式获取第一个良性案例的SHAP解释：
- en: '[PRE18]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The resulting plot is shown in figure 4.21\. Recall that for the first benign
    case, the DNN model predicted it was benign with a probability of 0.99 or confidence
    of 99%.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 结果图如图4.21所示。回想一下，对于第一个良性案例，DNN模型预测其良性概率为0.99或置信度为99%。
- en: '![](../Images/CH04_F21_Thampi.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F21_Thampi.png)'
- en: Figure 4.21 SHAP interpretation of benign case 1 where the DNN model predicts
    benign with a probability of 0.99 (or a confidence of 99%)
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.21 对良性案例1的SHAP解释，其中DNN模型预测良性概率为0.99（或99%的置信度）
- en: The SHAP library provides much nicer visualizations where you can see how each
    feature value pushes the base prediction up or down. In figure 4.21, you can see
    the base value at around 0.63\. This is the positive class rate representing the
    proportion of benign cases. When we explored the data in section 4.2, we observed
    that in the dataset, roughly 63% of the cases were benign. The idea behind the
    SHAP visualization is to see how the feature value pushes the baseline prediction
    probability from 0.63 up to 0.99\. The impact of the feature is shown by the length
    of the bar. We can see from the figure that the worst cell area and mean cell
    area features have the largest Shapley values, which pushes the base prediction
    the most. The next most important feature is worst cell perimeter.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP库提供了更美观的可视化效果，您可以看到每个特征值是如何推动基础预测值上升或下降的。在图4.21中，您可以看到基础值大约在0.63。这代表的是正类率，即良性病例的比例。当我们探索4.2节中的数据时，我们观察到在数据集中，大约63%的病例是良性的。SHAP可视化的理念是观察特征值是如何将基础预测概率从0.63推高到0.99的。特征的影响通过条形长度来表示。从图中我们可以看出，最差细胞面积和平均细胞面积特征具有最大的Shapley值，这推动了基础预测值的最大变化。下一个最重要的特征是最差细胞周长。
- en: Figure 4.22 shows the SHAP interpretation for the second benign case where the
    DNN model predicted benign with a probability of 0.99.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.22展示了DNN模型预测为0.99（或置信度为99%）的第二个良性病例的SHAP解释
- en: '![](../Images/CH04_F22_Thampi.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F22_Thampi.png)'
- en: Figure 4.22 SHAP interpretation of benign case 2 where the DNN model predicts
    benign with a probability of 0.99 (or a confidence of 99%)
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.22展示了DNN模型预测为0.99（或置信度为99%）的第二个良性病例的SHAP解释
- en: We can see that the two most important features here are the worst cell area
    and the mean cell area. Because the worst area and mean area are quite low, with
    values of 424.8 and 346.4, respectively, it was enough to push the baseline prediction
    all the way to 0.99\. As an exercise, modify the code shown earlier to interpret
    the two malignant cases. The resulting plots are shown in figures 4.23 and 4.24.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这里最重要的两个特征是最差细胞面积和平均细胞面积。因为最差面积和平均面积相当低，分别为424.8和346.4，足以将基础预测推高到0.99。作为一个练习，修改前面展示的代码来解释两个恶性病例。结果图示在图4.23和4.24中。
- en: '![](../Images/CH04_F23_Thampi.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F23_Thampi.png)'
- en: Figure 4.23 SHAP interpretation of malignant case 1 where the DNN model predicts
    benign with a probability of 0 (or malignant with a confidence of 100%)
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.23展示了DNN模型预测为0（或恶性，置信度为100%）的恶性病例1的SHAP解释
- en: For the first malignant case, the model predicted that it was benign with a
    probability of 0\. In figure 4.23, we can see how the feature values push the
    baseline prediction probability down to 0\. It looks like the features that have
    the most influence on the final prediction are the worst cell area, mean cell
    area, and perimeter.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个恶性病例，模型预测其概率为0。在图4.23中，我们可以看到特征值是如何将基础预测概率推低到0的。看起来对最终预测影响最大的特征是最差细胞面积、平均细胞面积和周长。
- en: For the second malignant case, the model also predicted that it was benign with
    a probability of 0\. We can see that the most influential feature is again the
    worst cell area. Because the value was quite large—greater than 1417—it was enough
    to push the baseline prediction probability down to 0, as shown in figure 4.24.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个恶性病例，模型同样预测其概率为0。我们可以看到，最有影响力的特征再次是最差细胞面积。因为该值相当大——大于1417——足以将基础预测概率推低到0，如图4.24所示。
- en: '![](../Images/CH04_F24_Thampi.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F24_Thampi.png)'
- en: Figure 4.24 SHAP interpretation of malignant case 2 where the DNN model predicts
    benign with a probability of 0 (or malignant with a confidence of 100%)
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.24展示了DNN模型预测为0（或恶性，置信度为100%）的恶性病例2的SHAP解释
- en: SHAP is another great tool for interpreting black-box models. Like LIME, it
    is model-agnostic, and it uses concepts from game theory to quantify the impact
    of features on the model prediction of a single instance. It provides more mathematical
    guarantees on the accuracy of the explanations than LIME. The library also provides
    great visualizations of the impact of features, showing how the feature values
    push the baseline prediction up or down to the final prediction. Computing the
    Shapley values based on the SHAP kernel, however, is computationally intensive.
    The computational complexity increases exponentially with the number of input
    features.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 是另一个用于解释黑盒模型的优秀工具。像 LIME 一样，它是模型无关的，并且它使用博弈论的概念来量化特征对单个实例模型预测的影响。它比 LIME
    提供了更多关于解释准确性的数学保证。该库还提供了关于特征影响的出色可视化，展示了特征值如何将基线预测推高或推低到最终预测。然而，基于 SHAP 内核计算 Shapley
    值的计算量是密集的。计算复杂度随着输入特征数量的指数增长。
- en: 4.7 Anchors
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.7 锚点
- en: Anchors is another model-agnostic interpretability technique that is local in
    scope. It was proposed in 2018 by the same creators of LIME. It improves on LIME
    by providing high-precision rules, or predicates, for how the model arrives at
    the prediction and also by quantifying the coverage of these rules in terms of
    global scope. Let’s break this down.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 锚点是一种局部范围内的模型无关解释技术。它由 LIME 的相同创造者在 2018 年提出。它通过提供高精度规则或谓词来改进 LIME，这些规则说明了模型如何得出预测，并通过全球范围量化这些规则的范围。让我们来分解一下。
- en: In this technique, model interpretations are generated in the form of anchors.
    An *anchor* is essentially a set of *if conditions*, or *predicates*, that contains
    the picked instance that we would like to interpret. This is shown by the box
    in figure 4.25\. The anchor illustrated in the figure can be interpreted as two
    if conditions where the two features in the 2-D feature space are bounded by a
    lower bound and upper bound, thereby forming a bounding box around the picked
    instance. The first objective of the algorithm is to form high-precision anchors
    that contain the picked instance in terms of the target prediction. The *precision*
    is a measure of the quality of the anchor and is defined as the ratio of the number
    of perturbed samples with the same target prediction as that of the picked instance
    to the total number of samples within the anchor. An important hyperparameter
    for the algorithm is the *precision threshold*.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项技术中，模型解释以锚点的形式生成。一个 *锚点* 实质上是一组 *if 条件*，或 *谓词*，它包含我们想要解释的选定的实例。这如图 4.25 中的框所示。图中的锚点可以解释为两个
    if 条件，其中二维特征空间中的两个特征被下限和上限所限制，从而在选定的实例周围形成一个边界框。算法的第一个目标是形成包含选定实例且针对目标预测的高精度锚点。*精度*
    是锚点质量的度量，定义为具有与选定实例相同目标预测的扰动样本数与锚点内总样本数之比。算法的一个重要超参数是 *精度阈值*。
- en: '![](../Images/CH04_F25_Thampi.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F25_Thampi.png)'
- en: Figure 4.25 An illustration of an anchor
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.25 锚点的示意图
- en: Once the algorithm has come up with a set of high-precision anchors, the next
    step is to quantify the scope of each anchor. The scope of an anchor is quantified
    by a metric called *coverage*. The coverage metric measures the probability that
    the anchor (or the set of predicates) will be present in other samples or other
    parts of the feature space. With this metric, we can tell how applicable the anchor’s
    interpretation is at a global scale. The objective of the algorithm is to pick
    the anchor with the highest coverage.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦算法生成了一组高精度锚点，下一步就是量化每个锚点的范围。锚点的范围通过一个称为 *覆盖率* 的指标来量化。覆盖率指标衡量锚点（或谓词集）出现在其他样本或特征空间其他部分中的概率。有了这个指标，我们可以了解锚点的解释在全球范围内是如何适用的。算法的目标是选择覆盖率最高的锚点。
- en: Determining all possible predicates that meet the precision threshold and the
    coverage requirement is a computationally intensive task. The authors of the algorithm
    used a bottom-up approach in constructing the predicates or rules. The algorithm
    starts off with an empty set of rules, and in each iteration, the algorithm incrementally
    constructs an anchor that meets the precision threshold and the coverage requirement
    and adds it to the set. To estimate the precision of an anchor, the authors have
    formulated this problem as a multiarmed bandit problem and specifically used the
    KL-LUCB algorithm to identify the rules with the highest precision.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 确定所有满足精度阈值和覆盖率要求的谓词是一项计算密集型任务。算法的作者在构建谓词或规则时采用了自底向上的方法。算法从一个空的规则集开始，并在每次迭代中，算法增量地构建一个满足精度阈值和覆盖率要求的锚点，并将其添加到集合中。为了估计锚点的精度，作者将此问题表述为一个多臂老虎机问题，并特别使用了KL-LUCB算法来识别精度最高的规则。
- en: 'Let’s now interpret the breast cancer DNN model using anchors. The authors
    of the paper have created a library in Python that can be found in GitHub. You
    can install the library using pip as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用锚点来解释乳腺癌DNN模型。论文的作者在GitHub上创建了一个Python库。您可以使用pip安装此库，如下所示：
- en: '[PRE19]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'As we did with LIME and SHAP, let’s now create the anchors tabular explainer
    for the breast cancer dataset as follows:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 如同我们使用LIME和SHAP所做的那样，现在让我们创建乳腺癌数据集的锚点表格解释器，如下所示：
- en: '[PRE20]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ① Imports the anchor_tabular module from the library
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ① 从库中导入anchor_tabular模块
- en: ② Sets the target label names
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: ② 设置目标标签名称
- en: ③ Sets the feature names for the dataset
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 设置数据集的特征名称
- en: ④ Provides categorical feature names, if any
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 如果有，提供分类特征名称
- en: ⑤ Fits the anchors explainer on the train and validation sets
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 将锚点解释器拟合到训练集和验证集
- en: 'We need to create a different helper function for anchors that provides the
    DNN predictions as discrete labels rather than probabilities. This helper function
    is shown next:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为锚点创建一个不同的辅助函数，该函数提供DNN预测作为离散标签而不是概率。此辅助函数如下所示：
- en: '[PRE21]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ① Predicts 1 if the output probability is greater than 0.5, else 0
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ① 如果输出概率大于0.5，则预测为1，否则为0
- en: 'Let’s now interpret the first benign case using anchors. The following code
    shows how to interpret the instance, extract the predicates or rules, and obtain
    the precision and coverage of the interpretation:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用锚点来解释第一个良性案例。以下代码展示了如何解释实例，提取谓词或规则，以及获得解释的精度和覆盖率：
- en: '[PRE22]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ① Passes the picked instance as the first parameter
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ① 将选定的实例作为第一个参数传递
- en: ② Provides the helper function that provides the model label predictions
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ② 提供提供模型标签预测的辅助函数
- en: ③ Sets the precision threshold
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 设置精度阈值
- en: ④ Prints the label prediction made by the model
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 打印模型做出的标签预测
- en: ⑤ Prints the rules or predicates
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 打印规则或谓词
- en: ⑥ Prints the precision of the anchor
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 打印锚点的精度
- en: ⑦ Prints the coverage of the anchor
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 打印锚点的覆盖率
- en: 'Note that the precision threshold is set to 0.95\. The rules or predicates
    are obtained as a list of strings and are strung together using the AND clause.
    The resulting output from the code is shown here:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，精度阈值设置为0.95。规则或谓词以字符串列表的形式获得，并使用AND子句连接。代码的输出结果如下所示：
- en: '[PRE23]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can see that the model predicted benign correctly, and the interpretation,
    or anchor, with the highest precision consists of two rules, or predicates. If
    the worst area is less than or equal to 683.95 and the mean radius is less than
    or equal to 13.27, the model predicts benign 100% of the time in the region around
    the picked instance. In terms of coverage, this anchor does pretty well with a
    coverage of 44.3%. This means that the rule is applicable to quite a lot of benign
    cases globally. You can also obtain an HTML visualization of this interpretation,
    shown in figure 4.26, using the following line of code:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到模型正确预测了良性，具有最高精度的解释或锚点由两个规则或谓词组成。如果最坏区域小于或等于683.95，并且平均半径小于或等于13.27，则模型在所选实例周围的区域预测良性100%。在覆盖率方面，此锚点表现相当不错，覆盖率为44.3%。这意味着该规则适用于全球相当多的良性案例。您还可以使用以下代码行获得此解释的HTML可视化，如图4.26所示：
- en: '[PRE24]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The anchors library as it stands now does not provide Matplotlib visualizations.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，锚点库不提供Matplotlib可视化。
- en: '![](../Images/CH04_F26_Thampi.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F26_Thampi.png)'
- en: Figure 4.26 Anchor interpretation of benign case 1 where precision is 100% and
    coverage is 44.3%
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.26良性案例1的锚点解释，精度为100%，覆盖率为44.3%
- en: 'As an exercise, extend this code to the other benign and malignant cases. The
    resulting visualization for the second benign case is shown in figure 4.27\. You
    can see that the model predicted benign correctly and the anchors algorithm came
    up with two rules with precision 1: if the worst cell area is less than or equal
    to 683.95 and the worst cell radius is less than or equal to 12.98, the model
    predicts benign 100% of the time. The coverage of this anchor is, however, 20.9%
    lower than the first benign case. This means that the interpretation for the second
    benign case is a lot more local than the first one.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 作为练习，将此代码扩展到其他良性及恶性案例。第二良性案例的结果可视化如图4.27所示。你可以看到模型正确预测了良性，并且锚定算法提出了两个规则，精确度为1：如果最坏细胞面积小于或等于683.95，且最坏细胞半径小于或等于12.98，模型100%预测为良性。然而，此锚定的覆盖率比第一个良性案例低20.9%。这意味着第二个良性案例的解释比第一个案例更加局部。
- en: '![](../Images/CH04_F27_Thampi.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F27_Thampi.png)'
- en: Figure 4.27 Anchor interpretation of benign case 2 where precision is 100% and
    coverage is 20.9%
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.27展示了精确度为100%、覆盖率为20.9%的良性案例2的锚定解释
- en: 'The anchor’s interpretation for the first malignant case is shown in figure
    4.28\. The model correctly predicted it was malignant, and the interpretation
    consists of two rules, or predicates, with a precision of 1\. The rules follow:
    if the worst cell area is greater than 683.95 and the mean cell radius is less
    than or equal to 544.05, the model predicts malignant 100% of the time. The anchor
    has a very low coverage of just 1.2%, however. The interpretation is, therefore,
    extremely local and is not really applicable to a lot of the other malignant cases.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个恶性案例的锚定解释如图4.28所示。模型正确预测其为恶性，解释由两个规则或谓词组成，精确度为1。规则如下：如果最坏细胞面积大于683.95且平均细胞半径小于或等于544.05，模型100%预测为恶性。然而，锚定的覆盖率非常低，仅为1.2%。因此，解释非常局部，实际上并不适用于许多其他恶性案例。
- en: '![](../Images/CH04_F28_Thampi.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F28_Thampi.png)'
- en: Figure 4.28 Anchor interpretation of malignant case 1 where precision is 100%
    and coverage is 1.1%
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.28展示了锚定对恶性案例1的解释，其中精确度为100%，覆盖率为1.1%
- en: 'Finally, the anchor’s interpretation of the second malignant case is shown
    in figure 4.29\. The model again predicted malignant correctly, and the interpretation
    consists of one rule with a precision of 1\. The rule follows: if the worst cell
    area is greater than 1030.75, the model predicts malignant 100% of the time. The
    coverage of this anchor is a lot better than the first case at 27.1%. This makes
    sense because if we go back to the exploratory analysis we did in section 4.2
    and look closely at figure 4.3, we see many more malignant cases with worst cell
    areas greater than 1030.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，第二个恶性案例的锚定解释如图4.29所示。模型再次正确预测其为恶性，解释由一个精确度为1的规则组成。规则如下：如果最坏细胞面积大于1030.75，模型100%预测为恶性。此锚定的覆盖率比第一个案例好得多，为27.1%。这是有道理的，因为如果我们回到第4.2节中进行的探索性分析，并仔细观察图4.3，我们会看到许多恶性案例的最坏细胞面积大于1030。
- en: '![](../Images/CH04_F29_Thampi.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F29_Thampi.png)'
- en: Figure 4.29 Anchor interpretation of malignant case 2 where precision is 100%
    and coverage is 27.1%
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.29展示了精确度为100%、覆盖率为27.1%的恶性案例2的锚定解释
- en: Anchors are a powerful model-agnostic interpretability technique because they
    provide interpretations as a set of high-precision rules, predicates, or human-readable
    if conditions. The technique also gives us a sense of the coverage or scope of
    the rules, that is, how applicable the rules are at a global scale. The Python
    library, however, is still a work in progress and is not as actively developed
    as LIME or SHAP.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 锚定是一种强大的模型无关解释技术，因为它们提供了一组高精度规则、谓词或人类可读的if条件作为解释。这项技术还让我们对规则的覆盖范围或范围有了一定的感觉，即规则在全局范围内适用性如何。然而，Python库仍在开发中，并且不如LIME或SHAP那样活跃。
- en: In the next and subsequent chapters, we will go deeper into the world of neural
    networks and learn about more complex structures like CNNs and RNNs. We will also
    learn how to perform feature attributions on neural networks and how to dissect
    them to get a much better understanding of what the network has learned.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将更深入地探讨神经网络的世界，并了解更复杂的结构，如CNN和RNN。我们还将学习如何在神经网络上执行特征归因，以及如何剖析它们以更好地理解网络学到了什么。
- en: Summary
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: An artificial neural network (ANN) is a system that is designed to loosely model
    a biological brain. It belongs to a broad class of machine learning methods called
    deep learning. The central idea of deep learning based on ANNs is to build complex
    concepts or representations from simpler concepts or features.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工神经网络（ANN）是一个旨在松散地模拟生物大脑的系统。它属于被称为深度学习的一类广泛的机器学习方法。基于ANN的深度学习的核心思想是从更简单的概念或特征构建复杂的概念或表示。
- en: An ANN with two or more hidden layers is called a deep neural network (DNN).
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有两个或更多隐藏层的ANN被称为深度神经网络（DNN）。
- en: An efficient algorithm to determine the weights in a DNN is backpropagation.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定深度神经网络（DNN）中权重的有效算法是反向传播。
- en: The activation function is an important feature within a neural network. It
    decides whether a neuron should be activated and by how much. The properties of
    an activation function are that it is differentiable and monotonic.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活函数是神经网络中的一个重要特征。它决定了神经元是否应该被激活以及激活的程度。激活函数的性质是它是可微的且单调的。
- en: ReLUs are the most widely used activation functions in neural networks because
    they handle the vanishing gradient problem well. They are also more computationally
    efficient.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReLUs是神经网络中最广泛使用的激活函数，因为它们很好地处理了梯度消失问题。它们在计算上也更高效。
- en: We can interpret neural networks in multiple ways. We can use model-agnostic
    methods that are global in scope, such as PDPs. In this chapter, we learned about
    more advanced perturbation-based model-agnostic techniques such as LIME, SHAP,
    and anchors. These interpretability techniques are local in scope, meaning they
    focus on a specific instance or example to interpret.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以用多种方式解释神经网络。我们可以使用全局范围内的模型无关方法，例如PDPs。在本章中，我们学习了更多基于扰动的模型无关技术，如LIME、SHAP和锚点。这些可解释性技术是局部的，意味着它们专注于解释特定实例或示例。
- en: LIME stands for local interpretable model-agnostic explanations. It is based
    on picking an example, randomly perturbing it, weighting the perturbed samples
    based on its proximity to the picked instance, and fitting a simpler white-box
    model on the weighted samples.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME代表局部可解释的模型无关解释。它基于选择一个示例，随机扰动它，根据其与所选实例的接近程度对扰动样本进行加权，并在加权样本上拟合一个更简单的白盒模型。
- en: The quality of the LIME interpretation depends greatly on the choice of the
    kernel width, which is an input to the kernel function used to weight the perturbed
    samples. It is an important hyperparameter, and we have seen that the width could
    be different for different examples that we pick to interpret. We can use the
    fidelity score provided by the library to determine the right width, but the selection
    of the right kernel width is still ambiguous.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME解释的质量在很大程度上取决于核宽度的选择，这是用于加权的扰动样本的核函数的输入。它是一个重要的超参数，我们已看到宽度可能因我们选择的解释示例而异。我们可以使用库提供的保真度分数来确定正确的宽度，但选择正确的核宽度仍然是不确定的。
- en: Another drawback of LIME is that the perturbed dataset is created by sampling
    from a Gaussian distribution, and it ignores correlations between features. The
    perturbed dataset may, therefore, not have the same characteristics as the original
    training data.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME的另一个缺点是，通过从高斯分布中进行采样来创建扰动数据集，并且它忽略了特征之间的相关性。因此，扰动数据集可能不具有原始训练数据的相同特征。
- en: SHAP stands for SHapley Additive exPlanations. Like LIME, it is model-agnostic,
    and it uses concepts from game theory to quantify the impact of features on the
    model prediction of a single instance. In theory, SHAP provides more mathematical
    guarantees on the accuracy of the explanations than LIME.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP代表SHapley Additive exPlanations。与LIME一样，它是模型无关的，并且它使用博弈论的概念来量化特征对单个实例模型预测的影响。理论上，SHAP在解释的准确性方面比LIME提供了更多的数学保证。
- en: The SHAP library provides great visualizations of the impact of features, showing
    how the feature values push the baseline prediction up or down to the final prediction.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP库提供了关于特征影响的出色可视化，显示了特征值如何将基线预测推高或推低到最终预测。
- en: Computing the Shapley values based on the SHAP kernel is, however, computationally
    intensive. The computational complexity increases exponentially with the number
    of input features.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，基于SHAP核计算Shapley值是计算密集型的。计算复杂度随着输入特征数量的指数增长。
- en: Anchors is another technique that improves on LIME by providing interpretations
    as a set of high-precision rules, predicates, or human-readable if conditions.
    The technique also gives us a sense of the coverage or scope of the rules, that
    is, how applicable the rules are at a global scale. The Python library, however,
    is still a work in progress and is not as actively developed as LIME or SHAP.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anchors 是一种改进 LIME 的技术，它通过提供一组高精度规则、谓词或人类可读的 if 条件作为解释。该技术还让我们对规则的覆盖范围或范围有了一种感觉，即规则在全球范围内适用性的如何。然而，Python
    库仍然处于开发中，并且不如 LIME 或 SHAP 活跃。
