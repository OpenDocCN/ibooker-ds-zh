- en: 1 Introduction to machine learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 机器学习简介
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Understanding machine learning and the problems it can solve
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解机器学习及其解决的问题
- en: Organizing a successful machine learning project
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织成功的机器学习项目
- en: Training and selecting machine learning models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和选择机器学习模型
- en: Performing model validation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行模型验证
- en: In this chapter, we introduce machine learning and describe the cases in which
    it’s most helpful. We show how machine learning projects are different from traditional
    software engineering (rule-based solutions) and illustrate the differences by
    using a spam-detection system as an example.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍机器学习，并描述它在哪些情况下最有帮助。我们展示了机器学习项目与传统软件工程（基于规则的解决方案）的不同之处，并通过使用垃圾邮件检测系统作为例子来说明这些差异。
- en: 'To use machine learning to solve real-life problems, we need a way to organize
    machine learning projects. In this chapter, we talk about CRISP-DM: a step-by-step
    methodology for implementing successful machine learning projects.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用机器学习解决现实生活中的问题，我们需要一种组织机器学习项目的方法。在本章中，我们讨论CRISP-DM：一个实施成功机器学习项目的逐步方法论。
- en: Finally, we take a closer look at one of the steps of CRISP-DM—the modeling
    step. In this step, we train different models and select the one that solves our
    problem best.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们更详细地研究CRISP-DM的一个步骤——建模步骤。在这个步骤中，我们训练不同的模型，并选择解决我们问题的最佳模型。
- en: 1.1 Machine learning
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 机器学习
- en: Machine learning is part of applied mathematics and computer science. It uses
    tools from mathematical disciplines such as probability, statistics, and optimization
    theory to extract patterns from data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是应用数学和计算机科学的一部分。它使用来自概率、统计和优化理论等数学学科的工具体现数据中的模式。
- en: 'The main idea behind machine learning is learning from examples: we prepare
    a dataset with examples, and a machine learning system “learns” from this dataset.
    In other words, we give the system the input and the desired output, and the system
    tries to figure out how to do the conversion automatically, without asking a human.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习背后的主要思想是从例子中学习：我们准备一个包含例子的数据集，机器学习系统“学习”这个数据集。换句话说，我们给系统输入和期望的输出，系统试图自动找出如何进行转换，而不需要询问人类。
- en: We can collect a dataset with descriptions of cars and their prices, for example.
    Then we provide a machine learning model with this dataset and “teach” it by showing
    it cars and their prices. This process is called *training* or sometimes *fitting*
    (figure 1.1).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以收集一个包含汽车描述和价格的数据集。然后，我们提供一个机器学习模型并使用这个数据集“教授”它，通过展示汽车及其价格。这个过程被称为*训练*或有时称为*拟合*（图1.1）。
- en: '![](../Images/01_01.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图片1.1](../Images/01_01.png)'
- en: Figure 1.1 A machine learning algorithm takes in input data (descriptions of
    cars) and desired output (the cars’ prices). Based on that data, it produces a
    model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 机器学习算法接收输入数据（汽车的描述）和期望输出（汽车的价格）。基于这些数据，它产生一个模型。
- en: When training is done, we can use the model by asking it to predict car prices
    that we don’t know yet (figure 1.2).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练完成后，我们可以通过要求它预测我们尚未知的汽车价格来使用模型（图1.2）。
- en: '![](../Images/01_02.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片1.2](../Images/01_02.png)'
- en: Figure 1.2 When training is done, we have a model that can be applied to new
    input data (cars without prices) to produce the output (predictions of prices).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 当训练完成后，我们得到一个可以应用于新的输入数据（无价格的车）以产生输出（价格预测）的模型。
- en: All we need for machine learning is a dataset in which for each input item (a
    car) we have the desired output (the price).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要的只是机器学习的一个数据集，其中对于每个输入项（一辆车），我们都有期望的输出（价格）。
- en: 'This process is quite different from traditional software engineering. Without
    machine learning, analysts and developers look at the data they have and try to
    find patterns manually. After that, they come up with some logic: a set of rules
    for converting the input data to the desired output. Then they explicitly encode
    these rules using a programming language such as Java or Python, and the result
    is called software. So, in contrast with machine learning, a human does all the
    difficult work (figure 1.3).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程与传统软件工程截然不同。没有机器学习，分析师和开发者会查看他们拥有的数据，并尝试手动寻找模式。之后，他们会提出一些逻辑：将输入数据转换为所需输出的规则集。然后，他们使用Java或Python等编程语言明确地编码这些规则，结果就是软件。因此，与机器学习相比，人类做了所有困难的工作（图1.3）。
- en: '![](../Images/01_03.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片1.3](../Images/01_03.png)'
- en: Figure 1.3 In traditional software, patterns are discovered manually and then
    encoded with a programming language. A human does all the work.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 在传统软件中，模式是手动发现的，然后使用编程语言进行编码。人类完成所有工作。
- en: In summary, the difference between a traditional software system and a system
    based on machine learning is shown in figure 1.4\. In machine learning, we give
    the system the input and output data, and the result is a model (code) that can
    transform the input into the output. The difficult work is done by the machine;
    we need only supervise the training process to make sure that the model is good
    (figure 1.4B). In contrast, in traditional systems, we first find the patterns
    in the data ourselves and then write code that converts the data to the desired
    outcome, using the manually discovered patterns (figure 1.4A).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，传统软件系统与基于机器学习系统的区别如图1.4所示。在机器学习中，我们向系统提供输入和输出数据，结果是模型（代码），它可以将输入转换为输出。困难的工作由机器完成；我们只需要监督训练过程，确保模型是好的（图1.4B）。相比之下，在传统系统中，我们首先自己发现数据中的模式，然后编写代码将数据转换为期望的结果，使用手动发现的模式（图1.4A）。
- en: '| ![](../Images/01_04a.png) | (A) In traditional software we discover patterns
    manually and encode them using a programming language. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| ![图1.4a](../Images/01_04a.png) | (A) 在传统软件中，我们手动发现模式并使用编程语言进行编码。 |'
- en: '| ![](../Images/01_04b.png) | (B) A machine learning system discovers patterns
    automatically by learning from examples. After training, it produces a model that
    “knows” these patterns, but we still need to supervise it to make sure the model
    is correct. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| ![图1.4b](../Images/01_04b.png) | (B) 机器学习系统通过学习示例自动发现模式。训练后，它产生一个“知道”这些模式的模型，但我们仍然需要监督它以确保模型是正确的。
    |'
- en: Figure 1.4 The difference between a traditional software system and a machine
    learning system. In traditional software engineering, we do all the work, whereas
    in machine learning, we delegate pattern discovery to a machine.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 传统软件系统与机器学习系统的区别。在传统软件工程中，我们完成所有工作，而在机器学习中，我们将模式发现委托给机器。
- en: 1.1.1 Machine learning vs. rule-based systems
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 机器学习与基于规则的系统
- en: To illustrate the difference between these two approaches and to show why machine
    learning is helpful, let’s consider a concrete case. In this section, we talk
    about a spam-detection system to show this difference.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这两种方法之间的区别，并展示为什么机器学习是有帮助的，让我们考虑一个具体的案例。在本节中，我们讨论一个垃圾邮件检测系统来展示这种区别。
- en: Suppose we are running an email service, and the users start complaining about
    unsolicited emails with advertisements. To solve this problem, we want to create
    a system that marks the unwanted messages as spam and forwards them to the spam
    folder.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在运行一个电子邮件服务，用户开始抱怨收到带有广告的不请自来的电子邮件。为了解决这个问题，我们希望创建一个系统，将不受欢迎的邮件标记为垃圾邮件，并将它们转发到垃圾邮件文件夹。
- en: The obvious way to solve the problem is to look at these emails ourselves to
    see whether they have any pattern. For example, we can check the sender and the
    content.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 解决问题的明显方法是亲自查看这些电子邮件，看看它们是否有任何模式。例如，我们可以检查发件人和内容。
- en: 'If we find that there’s indeed a pattern in the spam messages, we write down
    the discovered patterns and come up with following two simple rules to catch these
    messages:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们发现垃圾邮件中确实存在模式，我们就写下发现的模式，并制定以下两个简单的规则来捕捉这些邮件：
- en: If sender = promotions@online.com, then “spam”
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果发件人是promotions@online.com，则标记为“垃圾邮件”
- en: If title contains “buy now 50% off” and sender domain is “online.com,” then
    “spam”
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果标题包含“现在购买50%折扣”且发件人域名为“online.com”，则标记为“垃圾邮件”
- en: Otherwise, “good email”
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，标记为“好邮件”
- en: We write these rules in Python and create a spam-detection service, which we
    successfully deploy. At the beginning, the system works well and catches all the
    spam, but after a while, new spam messages start to slip through. The rules we
    have are no longer successful at marking these messages as spam.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用Python编写这些规则并创建了一个垃圾邮件检测服务，我们成功地将它部署。一开始，系统运行良好，能够捕捉到所有垃圾邮件，但过了一段时间，新的垃圾邮件开始悄悄溜过。我们现有的规则已经无法成功地将这些邮件标记为垃圾邮件。
- en: 'To solve the problem, we analyze the content of the new messages and find that
    most of them contain the word *deposit*. So we add a new rule:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们分析了新消息的内容，并发现其中大部分包含单词*deposit*。因此，我们添加了一条新规则：
- en: If sender = “promotions@online.com” then “spam”
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果发件人是“promotions@online.com”，则标记为“垃圾邮件”
- en: If title contains “buy now 50% off” and sender domain is “online.com,” then
    “spam”
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果标题包含“现在购买50%折扣”且发件人域名为“online.com”，则标记为“垃圾邮件”
- en: If body contains a word “deposit,” then “spam”
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果邮件正文包含单词“deposit”，则标记为“垃圾邮件”
- en: Otherwise, “good email”
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，"good email"
- en: After discovering this rule, we deploy the fix to our Python service and start
    catching more spam, making the users of our mail system happy.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在发现这个规则后，我们将修复部署到我们的Python服务中，并开始捕获更多的垃圾邮件，使我们的邮件系统的用户感到高兴。
- en: 'Some time later, however, users start complaining again: some people use the
    word *deposit* with good intentions, but our system fails to recognize that fact
    and marks the messages as spam. To solve the problem, we look at the good messages
    and try to understand how they are different from spam messages. After a while,
    we discover a few patterns and modify the rules again:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，过了一段时间后，用户又开始抱怨：有些人出于好意使用“deposit”这个词，但我们的系统未能识别这一点，将消息标记为垃圾邮件。为了解决这个问题，我们查看好消息并试图了解它们与垃圾邮件消息的不同之处。过了一会儿，我们发现了一些模式并再次修改了规则：
- en: If sender = “promotions@online.com,” then “spam”
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果发件人是“promotions@online.com”，则是垃圾邮件
- en: If title contains “buy now 50% off” and sender domain is “online.com,” then
    “spam”
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果标题包含“buy now 50% off”且发件人域名为“online.com”，则是垃圾邮件
- en: If body contains “deposit,” then
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果正文包含“deposit”，则
- en: If the sender's domain is “test.com,” then spam
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果发件人域名为“test.com”，则是垃圾邮件
- en: If description length is >= 100 words, then spam
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果描述长度大于等于100个单词，则是垃圾邮件
- en: Otherwise, “good email”
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，"good email"
- en: 'In this example, we looked at the input data manually and analyzed it in an
    attempt to extract patterns from it. As a result of the analysis, we got a set
    of rules that transforms the input data (emails) to one of the two possible outcomes:
    spam or not spam.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们手动查看输入数据并尝试从中提取模式。分析的结果，我们得到了一组规则，将输入数据（电子邮件）转换为两种可能的结果之一：垃圾邮件或非垃圾邮件。
- en: Now imagine that we repeat this process a few hundred times. As a result, we
    end up with code that is quite difficult to maintain and understand. At some point,
    it becomes impossible to include new patterns in the code without breaking the
    existing logic. So, in the long run, it’s quite difficult to maintain and adjust
    existing rules such that the spam-detection system still performs well and minimizes
    spam complaints.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下，我们重复这个过程几百次。结果，我们最终得到的是难以维护和理解的代码。在某个时候，它变得不可能在不破坏现有逻辑的情况下将新模式包含到代码中。因此，从长远来看，维护和调整现有规则以使垃圾邮件检测系统仍然表现良好并最小化垃圾邮件投诉变得相当困难。
- en: This is exactly the kind of situation in which machine learning can help. In
    machine learning, we typically don’t attempt to extract these patterns manually.
    Instead, we delegate this task to statistical methods, by giving the system a
    dataset with emails marked as spam or not spam and describing each object (email)
    with a set of its characteristics (features). Based on this information, the system
    tries to find patterns in the data with no human help. In the end, it learns how
    to combine the features in such a way that spam messages are marked as spam and
    good messages aren’t.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是机器学习可以提供帮助的情况。在机器学习中，我们通常不尝试手动提取这些模式。相反，我们通过向系统提供一个标记为垃圾邮件或非垃圾邮件的电子邮件数据集，并描述每个对象（电子邮件）的一组特征（特征），将这项任务委托给统计方法。基于这些信息，系统试图在没有任何人工帮助的情况下在数据中找到模式。最终，它学会了如何结合特征，使得垃圾邮件被标记为垃圾邮件，而好邮件则不被标记。
- en: With machine learning, the problem of maintaining a hand-crafted set of rules
    goes away. When a new pattern emerges—for example, there’s a new type of spam—we,
    instead of manually adjusting the existing set of rules, simply provide a machine
    learning algorithm with the new data. As a result, the algorithm picks up the
    new important patterns from the new data without damaging the old existing patterns—provided
    that these old patterns are still important and present in the new data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用机器学习，维护手工规则集的问题就消失了。当出现新的模式时——例如，有新的垃圾邮件类型——我们不是手动调整现有的规则集，而是简单地向机器学习算法提供新的数据。结果，算法从新的数据中提取了新的重要模式，而不会损害旧的模式——前提是这些旧模式在新的数据中仍然重要且存在。
- en: 'Let’s see how we can use machine learning to solve the spam-classification
    problem. For that, we first need to represent each email with a set of features.
    At the beginning we may choose to start with the following features:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用机器学习来解决垃圾邮件分类问题。为此，我们首先需要用一组特征来表示每封电子邮件。一开始，我们可能选择从以下特征开始：
- en: Length of title > 10? true/false
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标题长度大于10？是/否
- en: Length of body > 10? true/false
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正文长度大于10？是/否
- en: Sender “promotions@online.com”? true/false
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发件人“promotions@online.com”？是/否
- en: Sender “hpYOSKmL@test.com”? true/false
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发件人“hpYOSKmL@test.com”？是/否
- en: Sender domain “test.com”? true/false
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发件人域名“test.com”？是/否
- en: Description contains “deposit”? true/false
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述中包含“存款”？是/否
- en: In this particular case, we describe all emails with a set of six features.
    Coincidentally, these features are derived from the preceding rules.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定的情况下，我们使用一组六个特征来描述所有电子邮件。巧合的是，这些特征是从先前的规则中推导出来的。
- en: 'With this set of features, we can encode any email as a feature vector: a sequence
    of numbers that contains all the feature values for a particular email.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个特征集，我们可以将任何电子邮件编码为特征向量：一个包含特定电子邮件所有特征值的数字序列。
- en: '![](../Images/01_05.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/01_05.png)'
- en: Figure 1.5 An email that a user marked as spam
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 用户标记为垃圾邮件的电子邮件
- en: Now imagine that we have an email that users marked as spam (figure 1.5). We
    can express this email as a vector [1, 1, 0, 0, 1, 1], and for each of the six
    features, we encode the value as 1 for true or 0 for false (figure 1.6). Because
    our users marked the message as spam, the target variable is 1 (true).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下，我们有一个用户标记为垃圾邮件的电子邮件（图1.5）。我们可以将这个电子邮件表示为向量[1, 1, 0, 0, 1, 1]，并且对于六个特征中的每一个，我们将其编码为1（真）或0（假）（图1.6）。因为我们的用户将这条消息标记为垃圾邮件，所以目标变量是1（真）。
- en: '![](../Images/01_06.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/01_06.png)'
- en: Figure 1.6 The six-dimensional feature vector for a spam email. Each of the
    six features is represented by a number. In this case, we use 1 if the feature
    is true and 0 if the feature is false.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 垃圾邮件的六维特征向量。六个特征中的每一个都由一个数字表示。在这种情况下，如果特征为真，我们使用1，如果特征为假，我们使用0（图1.6）。
- en: This way, we can create feature vectors for all the emails in our database and
    attach a label to each one. These vectors will be the input to a model. Then the
    model takes all these numbers and combines the features in such a way that the
    prediction for spam messages is close to 1 (spam) and is 0 (not spam) for normal
    messages (figure 1.7).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们可以为我们数据库中的所有电子邮件创建特征向量，并为每个电子邮件贴上标签。这些向量将成为模型的输入。然后模型将这些数字组合起来，使得垃圾邮件的预测接近1（垃圾邮件），而对于普通消息则是0（非垃圾邮件）（图1.7）。
- en: '![](../Images/01_07.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/01_07.png)'
- en: Figure 1.7 The input to a machine learning algorithm consists of multiple feature
    vectors and the target variable for each vector.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 机器学习算法的输入由多个特征向量和每个向量的目标变量组成。
- en: As a result, we have a tool that is more flexible than a set of hardcoded rules.
    If something changes in the future, we don’t have to revisit all the rules manually
    and try to reorganize them. Instead, we use only the most recent data and replace
    the old model with the fresh one.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有一个比一组硬编码的规则更灵活的工具。如果将来有什么变化，我们不需要手动重新访问所有规则并尝试重新组织它们。相反，我们只使用最新的数据，并用新的模型替换旧的模型。
- en: This example is just one way that machine learning can make our lives easier.
    Other applications of machine learning include
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子只是机器学习使我们的生活变得更简单的一种方式。机器学习的其他应用包括
- en: Suggesting the price of a car.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建议汽车的价格。
- en: Predicting whether a customer will stop using the services of a company.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测客户是否会停止使用公司的服务。
- en: Ordering documents by relevance with respect to a query.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据查询的相关性对文档进行排序。
- en: Showing users the ads they are more likely to click instead of irrelevant content.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向用户展示他们更有可能点击的广告，而不是无关的内容。
- en: Classifying harmful and incorrect edits on Wikipedia. A system like this one
    can help Wikipedia’s moderators prioritize their efforts when validating the suggested
    edits.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对维基百科上的有害和不正确的编辑进行分类。这样的系统可以帮助维基百科的版主在验证建议的编辑时优先考虑他们的工作。
- en: Recommending items that customers may buy.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐客户可能购买的商品。
- en: Classifying images in different categories.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对不同类别的图像进行分类。
- en: Applications of machine learning aren’t limited to these examples, of course.
    We can use literally anything that we can express as (input data, desired output)
    to train a machine learning model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的应用不仅限于这些例子。我们可以使用任何可以表示为（输入数据，期望输出）的东西来训练机器学习模型。
- en: 1.1.2 When machine learning isn’t helpful
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 当机器学习不起作用时
- en: Although machine learning is helpful and can solve many problems, it’s not really
    needed in some cases.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然机器学习很有帮助并能解决许多问题，但在某些情况下实际上并不需要。
- en: For some simple tasks, rules and heuristics often work well, so it’s better
    to start with them and then consider using machine learning. In our spam example,
    we started by creating a set of rules, but after maintaining this set became difficult,
    we switched to machine learning. We used some of the rules as features, however,
    and simply fed them to a model.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一些简单的任务，规则和启发式方法通常效果很好，因此最好从它们开始，然后考虑使用机器学习。在我们的垃圾邮件示例中，我们首先创建了一组规则，但随着维护这个集合变得困难，我们转向了机器学习。然而，我们使用了一些规则作为特征，并将它们简单地输入到模型中。
- en: In some cases, it’s simply not possible to use machine learning. To use machine
    learning, we need to have data. If no data is available, machine learning is not
    possible.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，使用机器学习根本不可能。要使用机器学习，我们需要有数据。如果没有数据，机器学习是不可能的。
- en: 1.1.3 Supervised machine learning
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.3 监督机器学习
- en: 'The email-classification problem we just looked at is an example of supervised
    learning: we provide the model with features and the target variable, and it figures
    out how to use these features to arrive at the target. This type of learning is
    called *supervised* because we supervise or teach the model by showing it examples,
    exactly as we would teach children by showing them pictures of different objects
    and then telling them the names of those objects.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才看到的电子邮件分类问题是一个监督学习的例子：我们向模型提供特征和目标变量，然后它找出如何使用这些特征来达到目标。这种学习被称为 *监督*，因为我们通过展示示例来监督或教导模型，就像我们通过展示不同物体的图片并告诉他们这些物体的名称来教导孩子一样。
- en: A bit more formally, we can express a supervised machine learning model mathematically
    as
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式一点，我们可以用数学方式表达一个监督机器学习模型：
- en: '![](../Images/01_07-Equation_1.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/01_07-Equation_1.png)'
- en: where
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '*g* is the function that we want to learn with machine learning.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*g* 是我们想要通过机器学习学习的函数。'
- en: '*X* is the feature matrix in which rows are feature vectors.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*X* 是特征矩阵，其中行是特征向量。'
- en: '*y* is the target variable: a vector.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y* 是目标变量：一个向量。'
- en: The goal of machine learning is to learn this function *g* in such a way that
    when it gets the matrix *X*, the output is close to the vector *y*. In other words,
    the function *g* must be able to take in *X* and produce *y*. The process of learning
    *g* is usually called *training* or *fitting*. We “fit” *g* to dataset *X* in
    such a way that it produces *y* (figure 1.8).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的目标是学习这个函数 *g*，使得当它得到矩阵 *X* 时，输出接近向量 *y*。换句话说，函数 *g* 必须能够接收 *X* 并产生 *y*。学习
    *g* 的过程通常被称为 *训练* 或 *拟合*。我们将 *g* “拟合”到数据集 *X*，使其产生 *y*（图1.8）。
- en: '![](../Images/01_08.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/01_08.png)'
- en: Figure 1.8 When we train a model, an algorithm takes in a matrix *X* in which
    feature vectors are rows and the desired output is the vector *y*, with all the
    values we want to predict. The result of training is *g*, the model. After training,
    *g* should produce *y* when applied to *X*—or, in short, *g*(*X*) **≈** *y*.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8 当我们训练一个模型时，算法接收一个矩阵 *X*，其中特征向量是行，期望的输出是向量 *y*，包含我们想要预测的所有值。训练的结果是 *g*，即模型。训练后，*g*
    应该在应用于 *X* 时产生 *y*——简而言之，*g*(*X*) **≈** *y*。
- en: There are different types of supervised learning problems, and the type depends
    on the target variable *y*. The main types are
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习问题有多种类型，类型取决于目标变量 *y*。主要类型包括
- en: 'Regression: the target variable *y* is numeric, such as a car price or the
    temperature tomorrow. We cover regression models in chapter 2.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归：目标变量 *y* 是数值型，例如汽车价格或明天的温度。我们在第2章中介绍了回归模型。
- en: 'Classification: the target variable *y* is categorical, such as spam, not spam,
    or car make. We can further split classification into two subcategories: (1) *binary
    classification*, which has only two possible outcomes, such as spam or not spam,
    and (2) *multiclass classification*, which has more than two possible outcomes,
    such as a car make (Toyota, Ford, Volkswagen, and so on). Classification, especially
    binary classification, is the most common application of machine learning. We
    cover it in multiple chapters throughout the book, starting with chapter 3\. In
    that chapter, we’ll build a model for predicting whether a customer is going to
    churn—stop using the services of our company.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类：目标变量 *y* 是分类的，例如垃圾邮件、非垃圾邮件或汽车品牌。我们可以进一步将分类分为两个子类别：（1）*二元分类*，只有两种可能的结果，例如垃圾邮件或非垃圾邮件，和（2）*多类分类*，有超过两种可能的结果，例如汽车品牌（丰田、福特、大众等）。分类，尤其是二元分类，是机器学习最常见应用。我们在本书的多个章节中介绍了它，从第3章开始。在第3章中，我们将构建一个预测客户是否会流失——停止使用我们公司服务的模型。
- en: 'Ranking: the target variable *y* is an ordering of elements within a group,
    such as the order of pages in a search-result page. The problem of ranking often
    happens in areas like search and recommendations, but it’s out of the scope of
    this book and we won’t cover it in detail.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 排序：目标变量 *y* 是组内元素的排序，例如搜索结果页面中页面的顺序。排序问题通常出现在搜索和推荐等领域，但这本书的范围之外，我们不会详细讨论。
- en: Each supervised learning problem can be solved with different algorithms. Many
    types of models are available. These models define how exactly function *g* learns
    to predict *y* from *X*. These models include
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 每个监督学习问题都可以用不同的算法来解决。有许多类型的模型可供选择。这些模型定义了函数 *g* 如何从 *X* 中学习预测 *y*。这些模型包括
- en: Linear regression for solving the regression problem, covered in chapter 2
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第2章中介绍了用于解决回归问题的线性回归
- en: Logistic regression for solving the classification problem, covered in chapter
    3
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第3章中介绍了用于解决分类问题的逻辑回归
- en: Tree-based models for solving both regression and classification, covered in
    chapter 6
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第6章中介绍了用于解决回归和分类问题的基于树的模型
- en: Neural networks for solving both regression and classification, covered in chapter
    7
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7章中介绍了用于解决回归和分类问题的神经网络
- en: Deep learning and neural networks have received a lot of attention recently,
    mostly because of breakthroughs in computer vision methods. These networks solve
    tasks such as image classification a lot better than earlier methods did. *Deep
    learning* is a subfield of machine learning in which the function *g* is a neural
    network with many layers. We will learn more about neural networks and deep learning
    starting in chapter 7, where we train a deep learning model for image classification.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习和神经网络最近受到了很多关注，这主要归功于计算机视觉方法的突破。这些网络在解决图像分类等任务方面比早期方法做得更好。*深度学习*是机器学习的一个子领域，其中函数
    *g* 是具有许多层的神经网络。我们将在第7章中了解更多关于神经网络和深度学习的内容，在那里我们将训练一个用于图像分类的深度学习模型。
- en: 1.2 Machine learning process
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 机器学习过程
- en: Creating a machine learning system involves more than just selecting a model,
    training it, and applying it to new data. The model-training part of the process
    is only a small step in the process.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个机器学习系统不仅仅是选择一个模型、训练它并将其应用于新数据。这个过程中的模型训练部分只是其中的一个小步骤。
- en: Many other steps are involved, such as identifying the problem that machine
    learning can solve and using the predictions of the model to affect the end users.
    What is more, this process is iterative. When we train a model and apply it to
    a new dataset, we often identify cases in which the model doesn’t perform well.
    We use these cases to retrain the model in such a way that the new version handles
    such situations better.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 还涉及许多其他步骤，例如确定机器学习可以解决的问题，以及使用模型的预测来影响最终用户。更重要的是，这个过程是迭代的。当我们训练一个模型并将其应用于新的数据集时，我们通常会识别出模型表现不佳的情况。我们使用这些情况重新训练模型，以便新版本能更好地处理这些情况。
- en: Certain techniques and frameworks help us organize a machine learning project
    in such a way that it doesn’t get out of control. One such framework is CRISP-DM,
    which stands for *Cross-Industry Standard Process for Data Mining*. It was invented
    quite long ago, in 1996, but in spite of its age, it’s still applicable to today’s
    problems.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 某些技术和框架帮助我们以某种方式组织机器学习项目，使其不会失控。其中一个这样的框架是CRISP-DM，代表*跨行业数据挖掘标准流程*。它是在很久以前发明的，1996年，尽管如此，它仍然适用于今天的问题。
- en: 'According to CRISP-DM (figure 1.9), the machine learning process has six steps:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 CRISP-DM（图1.9），机器学习过程有六个步骤：
- en: Business understanding
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 业务理解
- en: Data understanding
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据理解
- en: Data preparation
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据准备
- en: Modeling
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 建模
- en: Evaluation
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估
- en: Deployment
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署
- en: '![](../Images/01_09.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01_09.png)'
- en: Figure 1.9 The CRISP-DM process. A machine learning project starts with understanding
    the problem and then moves into data preparation, training the model, and evaluating
    the results. Finally, the model goes to deployment. This process is iterative,
    and at each step, it’s possible to go back to the previous one.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9 CRISP-DM过程。一个机器学习项目从理解问题开始，然后进入数据准备、模型训练和评估结果。最后，模型进入部署阶段。这个过程是迭代的，在每一步中，都有可能回到前一步。
- en: 'Each phase covers typical tasks:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 每个阶段都涵盖典型的任务：
- en: In the business understanding step, we try to identify the problem, to understand
    how we can solve it, and to decide whether machine learning will be a useful tool
    for solving it.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在业务理解步骤中，我们试图确定问题，了解我们如何解决问题，并决定机器学习是否是解决该问题的有用工具。
- en: In the data understanding step, we analyze available datasets and decide whether
    we need to collect more data.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据理解步骤中，我们分析可用的数据集，并决定我们是否需要收集更多数据。
- en: In the data preparation step, we transform the data into a tabular form that
    we can use as input for a machine learning model.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据准备步骤中，我们将数据转换成表格形式，以便将其用作机器学习模型的输入。
- en: When the data is prepared, we move to the modeling step, in which we train a
    model.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当数据准备就绪后，我们进入建模步骤，在这个步骤中我们训练一个模型。
- en: After the best model is identified, there’s the evaluation step, where we evaluate
    the model to see if it solves the original business problem and measure its success
    at doing that.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在确定最佳模型之后，接下来是评估步骤，我们评估模型是否解决了原始的业务问题，并衡量其在解决问题上的成功程度。
- en: Finally, in the deployment step, we deploy the model to the production environment.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，在部署步骤中，我们将模型部署到生产环境中。
- en: 1.2.1 Business understanding
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 业务理解
- en: 'Let’s consider the spam-detection example for an email service provider. We
    see more spam messages than ever before, and our current system cannot deal with
    it easily. This problem is addressed in the business understanding step: we analyze
    the problem and the existing solution and try to determine if adding machine learning
    to that system will help us stop spam messages. We also define the goal and how
    to measure it. The goal could be “Reduce the amount of reported spam messages”
    or “Reduce the amount of complaints about spam that customer support receives
    per day,” for example. In this step, we may also decide that machine learning
    is not going to help and propose a simpler way to solve the problem.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以电子邮件服务提供商的垃圾邮件检测为例。我们看到的垃圾邮件消息比以往任何时候都多，而我们当前的系统无法轻松处理。这个问题在业务理解步骤中得到解决：我们分析问题以及现有的解决方案，并试图确定是否将机器学习添加到该系统中将帮助我们停止垃圾邮件。我们还定义了目标和如何衡量它。目标可能是“减少报告的垃圾邮件数量”或“减少客户支持每天收到的关于垃圾邮件的投诉数量”，例如。在这一步骤中，我们可能还会决定机器学习不会有所帮助，并提出一个更简单的方法来解决问题。
- en: 1.2.2 Data understanding
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 数据理解
- en: The next step is data understanding. Here, we try to identify the data sources
    we can use to solve the problem. If our site has a Report Spam button, for example,
    we can get data generated by users who marked their incoming emails as spam. Then
    we look at the data and analyze it to decide whether it’s good enough to solve
    our problem.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是数据理解。在这里，我们试图确定我们可以用来解决问题的数据来源。例如，如果我们的网站有一个“举报垃圾邮件”按钮，我们可以获取用户标记为垃圾邮件的收件邮件生成数据。然后我们查看数据并分析它，以决定它是否足够好，可以解决我们的问题。
- en: This data may not be good enough, however, for a wide range of reasons. One
    reason could be that the dataset is too small for us to learn any useful patterns.
    Another reason could be that the data is too noisy. The users may not use the
    button correctly, so it will be useless for training a machine learning model,
    or the data-collection process could be broken, gathering only a small fraction
    of the data we want.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于各种原因，这些数据可能不足以解决广泛的问题。一个原因可能是数据集太小，我们无法学习任何有用的模式。另一个原因可能是数据太嘈杂。用户可能没有正确使用按钮，因此它对训练机器学习模型将毫无用处，或者数据收集过程可能出了问题，只收集了我们想要的数据的一小部分。
- en: If we conclude that the data we currently have is not sufficient, we need to
    find a way to get better data, whether we acquire it from external sources or
    improve the way we collect it internally. It’s also possible that discoveries
    we make in this step will influence the goal we set in the business understanding
    step, so we may need to go back to that step and adjust the goal according to
    our findings.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们得出结论，我们目前拥有的数据不足，我们需要找到一种方法来获取更好的数据，无论是从外部来源获取还是改进我们内部收集数据的方式。此外，我们在这个步骤中做出的发现可能会影响我们在业务理解步骤中设定的目标，因此我们可能需要回到那个步骤并根据我们的发现调整目标。
- en: When we have reliable data sources, we go to the data preparation step.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有可靠的数据来源时，我们进入数据准备步骤。
- en: 1.2.3 Data preparation
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 数据准备
- en: In this step, we clean the data, transforming it in such a way that it can be
    used as input for a machine learning model. For the spam example, we transform
    the dataset into a set of features that we feed into a model later.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们清理数据，将其转换成可以用于机器学习模型输入的形式。对于垃圾邮件示例，我们将数据集转换成一系列特征，我们稍后将其输入到模型中。
- en: After the data is prepared, we go to the modeling step.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备完成后，我们进入建模步骤。
- en: 1.2.4 Modeling
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.4 建模
- en: In this step, we decide which machine learning model to use and how to make
    sure that we get the best out of it. For example, we may decide to try logistic
    regression and a deep neural network to solve the spam problem.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们决定使用哪种机器学习模型以及如何确保我们从中获得最佳效果。例如，我们可能会决定尝试逻辑回归和深度神经网络来解决垃圾邮件问题。
- en: We need to know how we will measure the performance of the models to select
    the best one. For the spam model, we can look at how well the model predicts spam
    messages and choose the one that does it best. For this purpose, setting a proper
    validation framework is important, which is why we cover it in more detail in
    the next section.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要知道如何衡量模型的表现，以便选择最佳模型。对于垃圾邮件模型，我们可以查看模型预测垃圾邮件消息的效果，并选择表现最好的那个。为此，设置一个合适的验证框架非常重要，这就是为什么我们在下一节中会详细讨论它。
- en: It’s very likely that in this step, we need to go back and adjust the way we
    prepare the data. Perhaps we came up with a great feature, so we go back to the
    data preparation step to write some code to compute that feature. When the code
    is done, we train the model again to check whether this feature is good. We might
    add a feature “length of the subject,” retrain the model, and check whether this
    change improves the model's performance, for example.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们很可能需要回到并调整我们准备数据的方式。也许我们提出了一个很好的特征，因此我们回到数据准备步骤编写一些代码来计算这个特征。当代码完成后，我们再次训练模型以检查这个特征是否良好。我们可能会添加一个“主题长度”的特征，重新训练模型，并检查这种变化是否提高了模型的表现，例如。
- en: After we select the best possible model, we go to the evaluation step.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们选择了最佳模型之后，我们进入评估步骤。
- en: 1.2.5 Evaluation
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.5 评估
- en: In this step, we check whether the model lives up to expectations. When we set
    the goal in the business understanding step, we also define the way of establishing
    whether the goal is achieved. Typically, we do this by looking at an important
    business metric and making sure that the model moves the metric in the right direction.
    In the case of spam detection, the metric could be the number of people who click
    the Report Spam button or the number of complaints about the issue we’re solving
    that customer support receives. In both cases, we hope that using the model reduces
    the number.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们检查模型是否达到了预期。在业务理解步骤中设定目标时，我们也定义了确定目标是否实现的方式。通常，我们通过查看一个重要的业务指标并确保模型将指标推向正确的方向来做到这一点。在垃圾邮件检测的情况下，这个指标可能是点击“报告垃圾邮件”按钮的人数，或者客户支持收到的关于我们正在解决的问题的投诉数量。在两种情况下，我们都希望使用模型来减少这些数量。
- en: 'Nowadays, this step is tightly connected to the next step: deployment.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这一步与下一步紧密相连：部署。
- en: 1.2.6 Deployment
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.6 部署
- en: 'The best way to evaluate a model is to battle-test it: roll it out to a fraction
    of users and then check whether our business metric changes for these users. If
    we want our model to reduce the number of reported spam messages, for example,
    we expect to see fewer reports from this group compared with the rest of the users.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 评估模型的最佳方式是通过实战测试：将模型推出给一部分用户，然后检查我们的业务指标是否对这些用户有所变化。如果我们希望我们的模型减少报告的垃圾邮件数量，例如，我们预计与所有其他用户相比，这个群体会有更少的报告。
- en: After the model is deployed, we use everything we learned in all the steps and
    go back to the first step to reflect on what we achieved (or didn’t achieve).
    We may realize that our initial goal was wrong and that what we actually want
    to do is *not* reduce the number of reports but increase customer engagement by
    decreasing the amount of spam. So we go all the way back to the business understanding
    step to redefine our goal. Then, when we evaluate the model again, we use a different
    business metric to measure its success.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 模型部署后，我们利用所有在各个步骤中学到的知识，回到第一步来反思我们取得了什么成果（或没有取得什么成果）。我们可能会意识到我们的初始目标是不正确的，而我们真正想要做的是*不是*减少报告的数量，而是通过减少垃圾邮件的数量来增加客户参与度。因此，我们一直回到业务理解步骤来重新定义我们的目标。然后，当我们再次评估模型时，我们使用不同的业务指标来衡量其成功。
- en: 1.2.7 Iterate
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.7 迭代
- en: 'As we can see, CRISP-DM emphasizes the iterative nature of machine learning
    processes: after the last step, we are always expected to go back to the first
    step, refine the original problem, and change it based on the learned information.
    We never stop at the last step; instead, we rethink the problem and see what we
    can do better in the next iteration.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，CRISP-DM强调了机器学习过程的迭代性质：在最后一步之后，我们总是期望回到第一步，细化原始问题，并根据学习到的信息进行修改。我们永远不会停留在最后一步；相反，我们会重新思考问题，看看在下一轮迭代中我们能做得更好。
- en: It’s a common misconception that machine learning engineers and data scientists
    spend their entire day training machine learning models. In reality, this idea
    is incorrect, as we can see in the CRISP-DM diagram (figure 1.9). A lot of steps
    come before and after the modeling step, and all these steps are important for
    a successful machine learning project.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 人们普遍认为机器学习工程师和数据科学家整天都在训练机器学习模型。实际上，这种想法是不正确的，正如我们在CRISP-DM图中（图1.9）所看到的那样。在建模步骤之前和之后有很多步骤，所有这些步骤对于一个成功的机器学习项目来说都是重要的。
- en: 1.3 Modeling and model validation
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 建模与模型验证
- en: As we saw previously, training models (the modeling step) is only one step in
    the whole process. But it’s an important step because it’s where we actually use
    machine learning to train models.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所看到的，训练模型（建模步骤）是整个过程中的一个步骤。但这是一个重要的步骤，因为这是我们实际使用机器学习来训练模型的地方。
- en: After we collect all the required data and determine that it’s good, we find
    a way to process the data and then proceed to training a machine learning model.
    In our spam example, this happens after we get all the spam reports, process the
    emails, and have a matrix ready to be put to a model.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们收集所有必要的数据并确定数据质量良好之后，我们找到一种处理数据的方法，然后继续训练机器学习模型。在我们的垃圾邮件示例中，这发生在我们收到所有垃圾邮件报告、处理电子邮件并准备好矩阵以供模型使用之后。
- en: 'At this point, we may ask ourselves what to use: logistic regression or a neural
    network. If we decide to go with a neural network because we’ve heard it’s the
    best model, how can we make sure that it’s indeed better than any other model?'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们可能会问自己该使用什么：逻辑回归还是神经网络。如果我们决定选择神经网络，因为我们听说它是最好的模型，我们如何确保它确实比其他任何模型都要好？
- en: The goal at this step is to produce a model in such a way that it achieves the
    best predictive performance. To do this, we need to have a way to reliably measure
    the performance of each possible model candidate and then choose the best one.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步的目标是产生一个模型，使其达到最佳的预测性能。为了做到这一点，我们需要有一种可靠的方法来衡量每个可能的模型候选者的性能，然后选择最好的一个。
- en: One possible approach is to train a model, let it run on a live system, and
    observe what happens. In the spam example, we decide to use a neural network for
    detecting spam, so we train it and deploy it to our production system. Then we
    observe how the model behaves on new messages and record the cases in which the
    system is incorrect.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能的方法是训练一个模型，让它在一个实时系统上运行，并观察会发生什么。在我们的垃圾邮件示例中，我们决定使用神经网络来检测垃圾邮件，所以我们训练它并将其部署到我们的生产系统中。然后我们观察模型在新消息上的表现，并记录系统错误的案例。
- en: 'This approach, however, is not ideal for our case: we cannot possibly do it
    for every model candidate we have. What’s worse, we can accidentally deploy a
    really bad model and see that it’s bad only after it has been run on live users
    of our system.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法并不适合我们的情况：我们不可能为每个模型候选者都这样做。更糟糕的是，我们可能会意外地部署一个真的很差的模型，并且只有在它在我们系统的实际用户上运行之后才会发现它的糟糕。
- en: Note Testing a model on a live system is called online testing, and it’s important
    for evaluating the quality of a model on real data. This approach, however, belongs
    to the evaluation and deployment steps of the process, not to the modeling step.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在实时系统上测试模型被称为在线测试，这对于评估模型在真实数据上的质量非常重要。然而，这种方法属于过程的评估和部署步骤，而不是建模步骤。
- en: A better approach for selecting the best model before deploying it is emulating
    the scenario of going live. We get our complete dataset, take a part out of it,
    and train the model on the remaining part of the data. When the training is done,
    we pretend that the held-out dataset is the new, unseen data, and we use it to
    measure the performance of our models. This part of data is often called the *validation
    set*, and the process of keeping part of a dataset away and using it to evaluate
    performance is called *validation* (see figure 1.10).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署模型之前选择最佳模型的一个更好的方法是模拟上线场景。我们获取完整的数据集，从中取出部分数据，并在剩余的数据上训练模型。当训练完成后，我们假装保留的数据集是新的、未见过的数据，并使用它来衡量我们模型的性能。这部分数据通常被称为*验证集*，将数据集的一部分保留下来并用于评估性能的过程称为*验证*（见图1.10）。
- en: '![](../Images/01_10.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图1.10](../Images/01_10.png)'
- en: Figure 1.10 To evaluate the performance of a model, we set some data aside and
    use it only for validation purposes.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.10 为了评估模型的性能，我们留出一部分数据，仅用于验证目的。
- en: In the spam dataset, we can take out every tenth message. This way, we hold
    out 10% of the data, which we use only for validating the models, and use the
    remaining 90% for training. Next, we train both logistic regression and a neural
    network on the training data. When the models are trained, we apply them to the
    validation dataset and check which one is more accurate at predicting spam.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在垃圾邮件数据集中，我们可以取出每第十条消息。这样，我们保留了10%的数据，仅用于验证模型，而将剩余的90%用于训练。接下来，我们在训练数据上训练逻辑回归和神经网络。当模型训练完成后，我们将它们应用于验证数据集，并检查哪个模型在预测垃圾邮件方面更准确。
- en: If, after applying the models to validation, we see that logistic regression
    is correct in predicting the spam in only 90% of cases, whereas a neural network
    is correct in 93% of cases, we conclude that the neural network model is a better
    choice than logistic regression (figure 1.11).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在将模型应用于验证后，我们发现逻辑回归在90%的情况下正确预测垃圾邮件，而神经网络在93%的情况下正确预测，我们得出结论，神经网络模型比逻辑回归是一个更好的选择（图1.11）。
- en: '![](../Images/01_11.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图1.11](../Images/01_11.png)'
- en: Figure 1.11 The validation process. We split the dataset into two parts, train
    the models on the training part, and evaluate the performance on the validation
    part. Using the evaluation results, we can choose the best model.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11 验证过程。我们将数据集分为两部分，在训练部分上训练模型，并在验证部分上评估性能。使用评估结果，我们可以选择最佳模型。
- en: Often, we don’t have just two models to try but a lot more. Logistic regression,
    for example, has a parameter, C, and depending on the value we set, the results
    can vary dramatically. Likewise, a neural network has many parameters, and each
    may have a great effect on the predictive performance of the final model. On top
    of that, we have other models, each with its own set of parameters. How do we
    select the best model with the best parameters?
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们不仅仅尝试两种模型，而是有更多。例如，逻辑回归有一个参数C，根据我们设置的值，结果可能会有很大的不同。同样，神经网络也有许多参数，每个参数都可能对最终模型的预测性能产生重大影响。除此之外，我们还有其他模型，每个模型都有自己的参数集。我们如何选择具有最佳参数的最佳模型？
- en: To do so, we use the same evaluation scheme. We train the models with different
    parameters on the training data, apply them to the validation data, and then select
    the model and its parameters based on the best validation results (figure 1.12).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们使用相同的评估方案。我们在训练数据上使用不同的参数训练模型，然后将它们应用于验证数据，并根据最佳的验证结果选择模型及其参数（图1.12）。
- en: '![](../Images/01_12.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图1.12](../Images/01_12.png)'
- en: Figure 1.12 Using the validation dataset to select the best model with the best
    parameters
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.12 使用验证数据集选择具有最佳参数的最佳模型
- en: This approach has a subtle problem, however. If we repeat the process of model
    evaluation over and over again and use the same validation dataset for that purpose,
    the good numbers we observe in the validation dataset may appear just by chance.
    In other words, the “best” model may simply get lucky in predicting the outcomes
    for this particular dataset.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法有一个微妙的问题。如果我们反复进行模型评估过程，并使用相同的验证数据集进行评估，我们观察到的验证数据集中的良好数字可能只是偶然出现的。换句话说，“最佳”模型可能只是在这个特定数据集上预测结果时运气好。
- en: Note In statistics and other fields, this problem is known as the multiple-comparisons
    problem or multiple-tests problem. The more times we make predictions on the same
    dataset, the more likely we are to see good performance by chance.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 在统计学和其他领域，这个问题被称为多重比较问题或多重测试问题。我们在同一数据集上做出预测的次数越多，我们偶然看到良好性能的可能性就越大。
- en: 'To guard against this problem, we use the same idea: we hold out part of the
    data again. We call this part of data the *test* dataset. We use it rarely, only
    for testing the model that we selected as the best (figure 1.13).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止这个问题，我们使用同样的想法：我们再次保留一部分数据。我们称这部分数据为*测试*数据集。我们很少使用它，仅用于测试我们选定的最佳模型（图1.13）。
- en: '![](../Images/01_13.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01_13.png)'
- en: Figure 1.13 Splitting the data into training, testing, and validation parts
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.13 将数据分为训练、测试和验证部分
- en: To apply this to the spam example, we first hold out 10% of the data as the
    test dataset and then hold out 10% of the data as the validation. We try multiple
    models on the validation dataset, select the best one, and apply it to the test
    dataset. If we see that the difference in performance between validation and test
    is not big, we confirm that this model is indeed the best one (figure 1.14).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将此应用于垃圾邮件示例，我们首先保留10%的数据作为测试数据集，然后保留10%的数据作为验证。我们在验证数据集上尝试多个模型，选择最佳模型，并将其应用于测试数据集。如果我们看到验证和测试之间的性能差异不大，我们确认这个模型确实是最佳模型（图1.14）。
- en: '![](../Images/01_14.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01_14.png)'
- en: Figure 1.14 We use the test dataset to confirm that the performance of the best
    model on the validation set is good.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.14 我们使用测试数据集来确认最佳模型在验证集上的性能良好。
- en: Important Setting the validation process is the most important step in machine
    learning. Without it, there’s no reliable way to know whether the model we’ve
    just trained is good, useless, or even harmful.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 重要 设置验证过程是机器学习中最重要的一步。没有它，我们就无法可靠地知道我们刚刚训练的模型是好是坏，甚至是有害的。
- en: 'The process of selecting the best model and the best parameters for the model
    is called *model selection*. We can summarize model selection as follows (figure
    1.15):'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最佳模型及其最佳参数的过程称为*模型选择*。我们可以如下总结模型选择（图1.15）：
- en: We split the data into training, validation, and testing parts.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将数据分为训练、验证和测试部分。
- en: We train each model first on the training part and then evaluate it on validation.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先在训练部分对每个模型进行训练，然后对其进行验证。
- en: Each time we train a different model, we record the evaluation results using
    the validation part.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每次我们训练一个不同的模型时，我们使用验证部分记录评估结果。
- en: At the end, we determine which model is the best and test it on the test dataset.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们确定哪个模型是最好的，并在测试数据集上对其进行测试。
- en: '![](../Images/01_15.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01_15.png)'
- en: Figure 1.15 The model selection process. First, we split the dataset, select
    a model, and train it only on the training part of the data. Then we evaluate
    the model on the validation part. We repeat the process many times until we find
    the best model.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.15 模型选择过程。首先，我们将数据集分割，选择一个模型，并仅在数据的训练部分对其进行训练。然后我们在验证部分评估模型。我们重复这个过程多次，直到找到最佳模型。
- en: It’s important to use the model selection process and to validate and test the
    models in offline settings first to make sure that the models we train are good.
    If the model behaves well offline, we can decide to move to the next step and
    deploy the model to evaluate its performance with real users.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模型选择过程，并在离线环境中首先验证和测试模型，以确保我们训练的模型是好的。如果模型在离线环境中表现良好，我们可以决定进入下一步，并将模型部署以评估其在真实用户中的性能。
- en: Summary
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Unlike traditional rule-based software engineering systems, in which rules are
    extracted and coded manually, machine learning systems can be taught to extract
    meaningful patterns from data automatically. This gives us a lot more flexibility
    and makes it easier to adapt to changes.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与传统基于规则的软件工程系统不同，在这些系统中规则是手动提取和编码的，机器学习系统可以被训练来自动从数据中提取有意义的模式。这给我们带来了更多的灵活性，并使得适应变化变得更加容易。
- en: Successfully implementing a machine learning project requires a structure and
    a set of guidelines. CRISP-DM is a framework for organizing a machine learning
    project that breaks down the process into six steps, from business understanding
    to deployment. The framework highlights the iterative nature of machine learning
    and helps us stay organized.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成功实施一个机器学习项目需要有一个结构和一套指导方针。CRISP-DM是一个组织机器学习项目的框架，它将整个过程分解为六个步骤，从业务理解到部署。该框架突出了机器学习的迭代特性，并帮助我们保持组织有序。
- en: 'Modeling is an important step in a machine learning project: the part where
    we actually use machine learning to train a model. During this step, we create
    models that achieve the best predictive performance.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建模是机器学习项目中一个重要的步骤：这是我们实际使用机器学习来训练模型的部分。在这一步中，我们创建出能够实现最佳预测性能的模型。
- en: 'Model selection is the process of choosing the best model to solve a problem.
    We split all the available data into three parts: training, validation, and testing.
    We train models on the training set and select the best model by using the validation
    set. When the best model is selected, we use the test step as a final check to
    ensure that the best model behaves well. This process helps us create useful models
    that work well with no surprises.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型选择是选择最佳模型以解决问题的一个过程。我们将所有可用数据分为三部分：训练集、验证集和测试集。我们在训练集上训练模型，并使用验证集来选择最佳模型。当最佳模型被选中后，我们使用测试步骤作为最终检查，以确保最佳模型表现良好。这个过程帮助我们创建出既实用又不出意外的有效模型。
