- en: Chapter 8\. Introduction to pandas
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 8 章。pandas 简介
- en: pandas is a key element in our dataviz toolchain, as we will use it for both
    cleaning and exploring our recently scraped dataset (see [Chapter 6](ch06.xhtml#chapter_heavy_scraping)).
    The last chapter introduced NumPy, the Python array processing library that is
    the foundation of pandas. Before we move on to applying pandas, this chapter will
    introduce its key concepts and show how it interacts with existing data files
    and database tables. The rest of your pandas learning will be on the job over
    the next couple of chapters.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 是我们数据可视化工具链中的关键组成部分，因为我们将使用它来清理和探索我们最近抓取的数据集（参见 [第 6 章](ch06.xhtml#chapter_heavy_scraping)）。上一章介绍了
    NumPy，这是 Python 的数组处理库，也是 pandas 的基础。在我们应用 pandas 之前，本章将介绍其关键概念，并展示它如何与现有数据文件和数据库表进行交互。接下来的几章将继续在实际工作中学习
    pandas。
- en: Why pandas Is Tailor-Made for Dataviz
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: pandas 为何专为数据可视化定制
- en: Take any dataviz, whether web-based or in print, and chances are that the data
    visualized was at one point stored in row-columnar form in a spreadsheet like
    Excel, a CSV file, or HDF5\. There are certainly visualizations, like network
    graphs, for which row-columnar data is not the best form, but they are in the
    minority. pandas is tailor-made to manipulate row-columnar data tables with its
    core datatype, the DataFrame, which is best thought of as a very fast, programmatic
    spreadsheet.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是基于网络还是印刷的任何数据可视化，很有可能被可视化的数据最初都存储在类似 Excel、CSV 文件或 HDF5 的行列式电子表格中。当然，也有一些可视化方式，如网络图，对于行列式数据不是最佳形式，但它们属于少数。pandas
    专为操作行列式数据表而设计，其核心数据类型是 DataFrame，最好将其视为非常快速的编程电子表格。
- en: Why pandas Was Developed
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: pandas 的开发动机
- en: First revealed by Wes Kinney in 2008, pandas was built to solve a particular
    problem—​namely, that while Python was great for manipulating data, it was weak
    in the area of data analysis and modeling, certainly compared with big hitters
    like R.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Wes Kinney 在 2008 年首次公开，pandas 是为解决一个特定问题而构建的——即虽然 Python 在数据操作方面表现出色，但在数据分析和建模方面相对较弱，尤其是与
    R 等强大工具相比。
- en: pandas is designed to work with the kind of heterogenous^([1](ch08.xhtml#idm45607780439264))
    data found in row-columnar spreadsheets, but cleverly manages to leverage some
    of the speed of NumPy’s homogeneous numeric arrays used by mathematicians, physicists,
    computer graphics, and the like. Combined with the Jupyter notebook and the Matplotlib
    plotting library (with auxiliary libraries like seaborn), pandas represents a
    first-class interactive data analysis tool. Because it’s part of the NumPy ecosystem,
    its data modeling is easily enhanced by such libraries as SciPy, statsmodels,
    and scikit-learn, to name but a few.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 设计用于处理类似行列式电子表格中发现的异构^([1](ch08.xhtml#idm45607780439264))数据，但巧妙地利用了 NumPy
    的同质数值数组的一些速度优势，这些数组被数学家、物理学家、计算机图形学等广泛使用。结合 Jupyter 笔记本和 Matplotlib 绘图库（以及像 seaborn
    这样的辅助库），pandas 是一款一流的交互式数据分析工具。作为 NumPy 生态系统的一部分，它的数据建模可以轻松地通过诸如 SciPy、statsmodels
    和 scikit-learn 等库进行增强。
- en: Categorizing Data and Measurements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据与测量的分类
- en: I’ll cover the core concepts of pandas in the next section, focusing on the
    DataFrame and how to get your data into and out of it via the common datastores,
    CSV files, and SQL databases. But first let’s take a little diversion to consider
    what we really mean by the heterogeneous datasets that pandas was designed to
    work with and that are the mainstay of data visualizers.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我将介绍 pandas 的核心概念，重点讨论 DataFrame 以及如何通过常见的数据存储方式（如 CSV 文件和 SQL 数据库）将数据导入和导出。但首先，让我们稍作偏离，思考一下
    pandas 设计用来处理的异构数据集的真正含义，这也是数据可视化的重要基础。
- en: Chances are that a visualization, maybe a bar chart or line graph used to illustrate
    an article or a modern web dashboard, presents the results of measurements in
    the real world, the price of commodities as they change over time, changes in
    rainfall over a year, voting intentions by ethnic group, and so forth. These measurements
    can be broadly broken into two groups, numerical and categorical. Numerical values
    can be divided into interval and ratio scales, and categorical values can in turn
    be divided into nominal and ordinal measurements. This gives four broad categories
    of observation available to the data visualizer.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有可能会有一些可视化，比如柱状图或线图用来说明文章或现代网络仪表板中测量结果的变化，商品价格随时间的变化，一年中降雨量的变化，不同族裔的投票意向等。这些测量结果大致可以分为两组，数值型和分类型。数值型可以分为区间和比率尺度，分类值则可以进一步分为名义和有序测量。这样数据可视化者可以得到四种广泛的观察类别。
- en: 'Let’s take a set of tweets as an example in order to draw out these measurement
    categories. Each tweet has various data fields:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一组推文为例，以便提取这些测量类别。每条推文都有各种数据字段：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO1-1)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO1-1)'
- en: 'The `text` and `id` fields are unique indicators. The former might contain
    categorical information (e.g., the category of tweets containing the #Python hashtag),
    and the latter might be used to create a category (e.g., the set of all users
    retweeting this tweet), but they are not per se visualizable fields.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`text`和`id`字段是唯一的标识符。前者可能包含分类信息（比如包含#Python标签的推文类别），而后者可能用于创建一个类别（比如所有转发该推文的用户集合），但它们本身不是可视化字段。'
- en: '[![2](assets/2.png)](#co_introduction_to_pandas_CO1-3)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introduction_to_pandas_CO1-3)'
- en: '`favorited` is Boolean, categorical information, dividing the tweets into two
    sets. This would count as a *nominal* category, as it can be counted but not ordered.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`favorited`是布尔值，分类信息，将推文分为两组。这算作是*名义*类别，因为可以计数但不能排序。'
- en: '[![3](assets/3.png)](#co_introduction_to_pandas_CO1-4)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_introduction_to_pandas_CO1-4)'
- en: '`filter_level` is also categorical information, but it is ordinal. There is
    an order, low→medium→high, to the filter levels.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`filter_level`也是分类信息，但它是有序的。过滤级别有低→中→高的顺序。'
- en: '[![4](assets/4.png)](#co_introduction_to_pandas_CO1-5)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_introduction_to_pandas_CO1-5)'
- en: The `created_at` field is a timestamp, a numerical value on an interval scale.
    We would probably want to order the tweets on this scale, something pandas does
    automatically, and then maybe box into broader intervals, say by the day or week.
    Again, pandas makes this trivial.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`created_at`字段是时间戳，数值尺度上的区间值。我们可能希望按照这个尺度对推文进行排序，这是pandas会自动完成的，并且可能会划分为更广泛的间隔，比如按天或者按周。再次强调，pandas使这变得非常简单。'
- en: '[![5](assets/5.png)](#co_introduction_to_pandas_CO1-6)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_introduction_to_pandas_CO1-6)'
- en: '`retweet_count` is likewise on a numerical scale, but it is a ratio one. A
    ratio scale, as opposed to an interval scale, has a meaningful concept of zero—​in
    this case, no retweets. Our `created_at` timestamp, on the other hand, can have
    an arbitrary baseline (e.g., unixtime or Gregorian year 0), much in the same way
    as temperature scales, with 0 degrees Celsius being the same as 273.15 degrees
    Kelvin.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`retweet_count`同样是数值尺度，但是是比率尺度。比率尺度与区间尺度相反，有一个有意义的零点——在这种情况下是没有转发。而我们的`created_at`时间戳则可以有一个任意的基线（比如unix时间或公历的年份0），就像温度尺度一样，摄氏度的0度等同于开尔文的273.15度。'
- en: '[![6](assets/6.png)](#co_introduction_to_pandas_CO1-7)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_introduction_to_pandas_CO1-7)'
- en: '`coordinates`, if available, has two numerical scales for longitude and latitude.
    Both are interval scales, though, as it doesn’t make much sense to speak of ratios
    of degrees.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`coordinates`如果有的话，有两个经纬度数值尺度。两者都是区间尺度，虽然讨论角度的比率没有太多意义。'
- en: So a small subset of our humble tweet’s fields contains heterogeneous information
    covering all the generally accepted divisions of measurement. Whereas the NumPy
    array is generally used for homogeneous, numerical number crunching, pandas is
    designed to deal with categorical data, time series, and items that reflect the
    heterogeneous nature of real-world data. This makes it a great fit for the data
    visualization.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的简单推文字段的小子集包含了覆盖所有通常接受的测量分区的异质信息。而NumPy数组通常用于同质化的数值计算，pandas则设计用于处理分类数据、时间序列和反映现实世界数据异质性的项目。这使其非常适合数据可视化。
- en: Now that we know the type of data pandas is designed to deal with, let’s look
    at the data structures it uses.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道 pandas 设计用于处理的数据类型，让我们看看它使用的数据结构。
- en: The DataFrame
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DataFrame
- en: 'The first step in a pandas session is usually to load some data into a DataFrame.
    We’ll cover the various ways we can do this in a later section. For now, let’s
    read our *nobel_winners.json* JSON data from a file. `read_json` returns a DataFrame,
    parsed from the JSON file specified. By convention, DataFrame variables start
    with `df`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 会话中的第一步通常是将一些数据加载到 DataFrame 中。我们将在后面的部分中介绍我们可以做到这一点的各种方法。现在，让我们从文件中读取我们的
    *nobel_winners.json* JSON 数据。`read_json` 返回一个从指定的 JSON 文件解析的 DataFrame。按照惯例，DataFrame
    变量以 `df` 开头：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: With our DataFrame in hand, let’s inspect its content. A quick way to get the
    row-columnar structure of the DataFrame is to use its `head` method to show (by
    default) the top five items. [Figure 8-1](#pandas_dataframe) shows the output
    from a [Jupyter notebook](https://jupyter.org), with key elements of the DataFrame
    highlighted.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 有了我们的 DataFrame，让我们检查其内容。获取 DataFrame 的行列结构的快速方法是使用其 `head` 方法显示（默认情况下）前五个项目。[图 8-1](#pandas_dataframe)
    显示了来自 [Jupyter 笔记本](https://jupyter.org) 的输出，突出显示了 DataFrame 的关键元素。
- en: '![dpj2 0801](assets/dpj2_0801.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![dpj2 0801](assets/dpj2_0801.png)'
- en: Figure 8-1\. The key elements of a pandas DataFrame
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-1\. pandas DataFrame 的关键元素
- en: Indices
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 索引
- en: 'The DataFrame’s columns are indexed by a `columns` property, which is a pandas
    `index` instance. Let’s select the columns in [Figure 8-1](#pandas_dataframe):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 的列通过 `columns` 属性进行索引，这是一个 pandas `index` 实例。让我们选择 [图 8-1](#pandas_dataframe)
    中的列：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Initially, pandas rows have a single numeric index (pandas can handle multiple
    indices if necessary) that can be accessed by the `index` property. This is a
    memory-saving [`RangeIndex`](https://oreil.ly/7Qzia) by default:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，pandas 行具有一个单一的数值索引（如果需要，pandas 可以处理多个索引），可以通过 `index` 属性访问。默认情况下，这是一个节省内存的
    [`RangeIndex`](https://oreil.ly/7Qzia)：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As well as integers, row indices can be strings, `DatetimeIndice`s, or `PeriodIndice`s
    for time-based data, and so on. Often, to aid selections, a column of the DataFrame
    will be set to the index via the `set_index` method. In the following code, we
    first use the `set_index` method to set our Nobel DataFrame’s index to the name
    column and then use the `loc` method to select a row by the index label (`name`
    in this case):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 除了整数外，行索引还可以是字符串、`DatetimeIndex` 或 `PeriodIndex` 用于基于时间的数据，等等。通常，为了帮助选择，DataFrame
    的一列将通过 `set_index` 方法设置为索引。在以下代码中，我们首先使用 `set_index` 方法将我们的 Nobel DataFrame 的索引设置为名称列，然后使用
    `loc` 方法按索引标签选择一行（在本例中为 `name`）：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO2-1)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO2-1)'
- en: Set the index to the name column.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 将索引设置为名称列。
- en: '[![2](assets/2.png)](#co_introduction_to_pandas_CO2-2)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introduction_to_pandas_CO2-2)'
- en: You can now select a row by the `name` label.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以按 `name` 标签选择一行。
- en: '[![3](assets/3.png)](#co_introduction_to_pandas_CO2-3)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_introduction_to_pandas_CO2-3)'
- en: Return the index to original integer-based state.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将索引返回到原始基于整数的状态。
- en: Rows and Columns
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行和列
- en: The rows and columns of a DataFrame are stored as [pandas Series](https://oreil.ly/z7PF4),
    a heterogeneous counterpart to NumPy’s array. These are essentially a labeled
    one-dimensional array that can contain any datatype from integers, strings, and
    floats to Python objects and lists.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 的行和列存储为 [pandas Series](https://oreil.ly/z7PF4)，这是 NumPy 数组的异构对应物。这些本质上是带有标签的一维数组，可以包含从整数、字符串和浮点数到
    Python 对象和列表的任何数据类型。
- en: 'There are two ways to select a row from the DataFrame. We’ve seen the `loc`
    method, which selects by label. There’s also an `iloc` method, which selects by
    position. So to select the row in [Figure 8-1](#pandas_dataframe), we grab row
    number two:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以从 DataFrame 中选择一行。我们已经看到了 `loc` 方法，它通过标签进行选择。还有一个 `iloc` 方法，它通过位置进行选择。因此，要选择
    [图 8-1](#pandas_dataframe) 中的行，我们获取第二行：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can grab a column of your DataFrame using dot notation^([2](ch08.xhtml#idm45607779978240))
    or conventional array access by keyword string. This returns a pandas Series with
    all the column fields with their DataFrame indices preserved:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用点符号^([2](ch08.xhtml#idm45607779978240))或传统的关键字字符串数组访问方法获取 DataFrame 的列。这将返回一个
    pandas Series，其中包含所有列字段，并保留其 DataFrame 索引：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Selecting Groups
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择分组
- en: 'There are various ways we can select groups (or subsets of rows) of our DataFrame.
    Often we want to select all rows with a specific column value (e.g., all rows
    with category Physics). One way to do this is to use the DataFrame’s `groupby`
    method to group a column (or list of columns) and then use the `get_group` method
    to select the required group. Let’s use these two methods to select all Nobel
    Physics Prize winners:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种方法可以选择我们DataFrame的组（或行子集）。通常我们想要选择具有特定列值的所有行（例如，所有物理学类别的行）。一种方法是使用DataFrame的`groupby`方法对列（或列列表）进行分组，然后使用`get_group`方法选择所需的组。让我们使用这两种方法选择所有诺贝尔物理学奖获得者：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Another way to select row subsets is to use a Boolean mask to create a new
    DataFrame. You can apply Boolean operators to all rows in a DataFrame in much
    the same way as you can to all members of a NumPy array:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择行子集的方法是使用布尔掩码来创建新的DataFrame。你可以像在NumPy数组中对所有成员应用布尔运算符一样，对DataFrame中的所有行应用布尔运算符：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The resulting Boolean mask can then be applied to the original DataFrame to
    select a subset of its rows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以将生成的布尔掩码应用于原始DataFrame，以选择其行的子集：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We’ll cover a lot more examples of data selections in the coming chapters. For
    now, let’s see how we create DataFrames from existing data and how to save the
    results of our data frame manipulations.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将介绍更多关于数据选择的例子。现在，让我们看看如何从现有数据创建DataFrame以及如何保存我们数据框架操作的结果。
- en: Creating and Saving DataFrames
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和保存DataFrame
- en: The easiest way to create a DataFrame is to use a Python dictionary. It’s also
    a way you won’t be using very often, as you will likely be accessing your data
    from files or databases. Nevertheless, it has its use cases.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 创建DataFrame最简单的方法是使用Python字典。这也是您可能不经常使用的一种方法，因为您可能会从文件或数据库访问数据。尽管如此，它有其用途。
- en: 'By default, we specify the columns separately, in the following example creating
    three rows with name and category columns:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，我们分别指定列，在以下示例中创建三行名称和类别列：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can use the `from_dict` method to allow us to use our preferred record-based
    object arrays. `from_dict` has an `orient` argument to allow us to specify record-like
    data, but pandas is smart enough to work out the data form:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`from_dict`方法允许我们使用我们首选的基于记录的对象数组。`from_dict`有一个`orient`参数，允许我们指定类似记录的数据，但pandas足够智能，可以解析出数据形式：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO3-1)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO3-1)'
- en: Here we pass in an array of objects, each corresponding to a row in our DataFrame.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们传入一个对象数组，每个对象对应我们DataFrame中的一行。
- en: 'The methods just shown produce an identical DataFrame:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 刚才展示的方法产生了一个相同的DataFrame：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As mentioned, you probably won’t be creating DataFrames from Python containers
    directly. Instead, you will probably use one of the pandas data-reading methods.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 正如提到的，您可能不会直接从Python容器创建DataFrame。相反，您可能会使用pandas数据读取方法之一。
- en: pandas has an impressive array of `read_[format]`/`to_[format]` methods, covering
    most conceivable data-loading use cases, from CSV through binary HDF5 to SQL databases.
    We’ll cover the subset most relevant to dataviz work. For a full list, see [the
    pandas documentation](https://oreil.ly/b3VFR).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: pandas拥有令人印象深刻的`read_[format]`/`to_[format]`方法，涵盖了大多数可想象的数据加载用例，从CSV到二进制HDF5再到SQL数据库。我们将介绍与数据可视化工作最相关的子集。有关完整列表，请参阅[pandas文档](https://oreil.ly/b3VFR)。
- en: Note that by default pandas will try to convert the loaded data sensibly. The
    `convert_axes` (try to convert the axes to the proper `dtype`s), `dtype` (guess
    datatype), and `convert_dates` arguments to the read methods are all `True` by
    default. See the [pandas documentation](https://oreil.ly/MkmIx) for an example
    of the available options, in this case for reading JSON files into a DataFrame.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，pandas会尝试合理地转换加载的数据。`convert_axes`（尝试将轴转换为适当的`dtype`）、`dtype`（猜测数据类型）和`convert_dates`参数在读取方法中默认都是`True`。请参阅[pandas文档](https://oreil.ly/MkmIx)以获取可用选项的示例，本例是为了将JSON文件读入DataFrame。
- en: Let’s cover file-based DataFrames first, then see how to interact with (No)SQL
    databases.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先涵盖基于文件的DataFrame，然后看看如何与（非）SQL数据库交互。
- en: JSON
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JSON
- en: 'Loading data from our preferred JSON format is trivial in pandas:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在pandas中轻松加载我们首选的JSON格式数据：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'There are various forms the JSON file can take, specified by an optional `orient`
    argument, one of [`split`, `records`, `index`, `columns`, `values`]. An array
    of records, our standard form, will be detected:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: JSON文件可以采用各种形式，由可选的`orient`参数指定，其中之一为[`split`, `records`, `index`, `columns`,
    `values`]。我们的标准形式是一个记录数组，会被检测到：
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The default for a JSON object is `columns`, in the form:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 对象的默认格式是 `columns`，形式如下：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As discussed, for web-based visualization work, particularly D3, record-based
    JSON arrays are the most common way of passing row-columnar data to the browser.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如讨论的那样，对于基于 Web 的可视化工作，特别是 D3，基于记录的 JSON 数组是将行列数据传递给浏览器的最常见方式。
- en: Note
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Note that you will need valid JSON files to work with pandas because the `read_json`
    method and Python JSON parsers in general tend to be fairly unforgiving, and exceptions
    not as informative as they might be.^([3](ch08.xhtml#idm45607779218800)) A common
    JSON error is failing to enclose keys in double-quote marks or using single quotes
    where double quotes are expected. The latter is particularly common for those
    coming from languages where single- and double-string quotes are essentially interchangeable
    and one reason why you should never build JSON documents yourself—​always use
    an official or well-respected library.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您需要有效的 JSON 文件才能使用 pandas 工作，因为 `read_json` 方法和 Python 的 JSON 解析器通常不够宽容，并且异常信息也不够详细。一个常见的
    JSON 错误是未将键用双引号括起来，或者在期望双引号的地方使用单引号。后者对于那些来自单双引号可以互换的语言的人来说尤为常见，这也是为什么您永远不应该自己构建
    JSON 文档的原因——总是使用官方或备受尊重的库。
- en: 'There are various ways to store DataFrames in JSON, but the format that will
    play most nicely with any dataviz work is the array of records. This is the most
    common form of D3 data and the one I recommend outputting from pandas.^([4](ch08.xhtml#idm45607779160128))
    Writing a DataFrame as records to JSON is then simply a case of specifying the
    `orient` field in the `to_json` method:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种方法可以将 DataFrame 存储为 JSON，但最适合与任何数据可视化工作协作的格式是记录数组。这是 D3 数据的最常见形式，也是我建议从 pandas
    输出的形式。将 DataFrame 作为记录写入 JSON 只需在 `to_json` 方法中指定 `orient` 字段即可：
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO4-1)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO4-1)'
- en: Override the default save to store the JSON as dataviz-friendly records.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖默认保存以将 JSON 存储为适合数据可视化的记录。
- en: We also have the parameters `date_format` (*epoch* timestamp, *iso* for ISO8601,
    etc.), `double_precision`, and `default_handler` to call if the object cannot
    be converted into JSON using pandas’s parser. Check [the pandas documentation](https://oreil.ly/wqnI0)
    for more details.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还有参数 `date_format`（*epoch* 时间戳，*iso* 表示 ISO8601 等）、`double_precision` 和
    `default_handler`，用于在对象无法使用 pandas 解析器转换为 JSON 时调用。详见[pandas 文档](https://oreil.ly/wqnI0)。
- en: CSV
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CSV
- en: 'As befits pandas’s data-table ethos, its handling of CSV files is sophisticated
    enough to cope with pretty much all conceivable data. Conventional CSV files,
    which is the large majority, will load without parameters:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 符合 pandas 数据表精神的是，它对 CSV 文件的处理足够复杂，可以处理几乎所有可想象的数据。常规的 CSV 文件，也就是大多数情况下，会在没有参数的情况下加载：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Although you might expect all CSV files to be comma-separated, you will often
    find files with a CSV suffix with different delimiters such as semicolons or pipes
    (`|`). They may also use idiosyncratic quoting for strings containing spaces or
    special characters. In this case, we can specify any nonstandard elements in our
    read request. We’ll use Python’s handy `StringIO` module to emulate reading from
    a file:^([5](ch08.xhtml#idm45607779004224))
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管您可能希望所有 CSV 文件都是逗号分隔的，但您经常会发现文件名以 CSV 结尾，但使用分号或竖线 (`|`) 等不同的分隔符。它们可能还会对包含空格或特殊字符的字符串使用特定的引用方式。在这种情况下，我们可以在读取请求中指定任何非标准元素。我们将使用
    Python 方便的 `StringIO` 模块来模拟从文件中读取：^([5](ch08.xhtml#idm45607779004224))
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO5-1)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO5-1)'
- en: The fields are pipe-separated, not the default comma-separated.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这些字段是以管道符分隔的，而不是默认的逗号分隔。
- en: '[![2](assets/2.png)](#co_introduction_to_pandas_CO5-2)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introduction_to_pandas_CO5-2)'
- en: Here we provide the missing column headers.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们提供了缺失的列标题。
- en: 'We have the same degree of flexibility when saving CSV files, here setting
    the encoding to Unicode `utf-8`:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当保存 CSV 文件时，我们同样具有相同的灵活性，这里将编码设置为 Unicode `utf-8`：
- en: '[PRE19]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: For full coverage of the CSV options, see the [pandas documentation](https://oreil.ly/QPCs1).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 想要了解 CSV 选项的详细内容，请查阅[pandas 文档](https://oreil.ly/QPCs1)。
- en: Excel Files
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Excel 文件
- en: 'pandas uses Python’s `xlrd` module to read Excel 2003 (*.xls*) and the `openpyxl`
    module to read Excel 2007+ (*.xlsx*) files. The latter is an optional dependency
    that will need installing:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 使用 Python 的 `xlrd` 模块来读取 Excel 2003 (*.xls*) 文件，使用 `openpyxl` 模块来读取 Excel
    2007+ (*.xlsx*) 文件。后者是一个可选依赖项，需要安装：
- en: '[PRE20]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Excel documents have multiple named sheets, each of which can be passed to
    a DataFrame. There are two ways to read a datasheet into a DataFrame. The first
    is by creating and then parsing an `ExcelFile` object:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Excel文档有多个命名工作表，每个工作表都可以传递给DataFrame。有两种方法将数据表读入DataFrame中。第一种方法是创建然后解析`ExcelFile`对象：
- en: '[PRE21]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO6-1)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO6-1)'
- en: Grab a sheet by name and save to a dictionary.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 按名称获取一个工作表并保存到一个字典中。
- en: '[![2](assets/2.png)](#co_introduction_to_pandas_CO6-2)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introduction_to_pandas_CO6-2)'
- en: Specify the column, by position, to use as DataFrame’s row labels.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 指定要用作DataFrame行标签的列位置。
- en: '[![3](assets/3.png)](#co_introduction_to_pandas_CO6-3)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_introduction_to_pandas_CO6-3)'
- en: A list of additional strings to recognize as NaN.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 识别为NaN的其他字符串列表。
- en: '[![4](assets/4.png)](#co_introduction_to_pandas_CO6-4)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_introduction_to_pandas_CO6-4)'
- en: The number of rows (e.g., metadata) to skip before processing.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理之前要跳过的行数（例如，元数据）。
- en: 'Alternatively you can use the `read_excel` method, which is a convenience method
    for loading multiple spreadsheets:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用`read_excel`方法，它是加载多个电子表格的便捷方法：
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let’s check the content of the second Excel sheet using the resulting DataFrame:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生成的DataFrame检查第二个Excel表的内容：
- en: '[PRE23]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The only reason not to use `read_excel` is if you need different arguments for
    reading each Excel sheet.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 不使用`read_excel`的唯一原因是如果您需要不同的参数来读取每个Excel工作表。
- en: You can specify sheets by index or name using the second (`sheetname`) parameter.
    `sheetname` can be a single name string or index (beginning at 0) or a mixed list.
    By default `sheetname` is `0`, returning the first sheet. [Example 8-1](#excel_loads)
    shows some variations. Setting `sheetname` to `None` returns a sheetname-keyed
    dictionary of DataFrames.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用第二个（`sheetname`）参数按索引或名称指定工作表。`sheetname`可以是单个名称字符串或索引（从0开始）或混合列表。默认情况下，`sheetname`为`0`，返回第一个工作表。示例 8-1显示了一些变化。将`sheetname`设置为`None`将返回一个以工作表名称为键的DataFrame字典。
- en: Example 8-1\. Loading Excel sheets
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 8-1\. 加载Excel工作表
- en: '[PRE24]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `parse_cols` parameter lets you select the sheet columns to be parsed.
    Setting `parse_cols` to an integer value selects all columns up to that ordinal.
    Setting `parse_cols` to a list of integers allows you to select specific columns:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`parse_cols`参数允许您选择要解析的工作表列。将`parse_cols`设置为整数值将选择到该序数的所有列。将`parse_cols`设置为整数列表允许您选择特定的列：'
- en: '[PRE25]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: For more information on `read_excel`, see the [pandas documentation](https://oreil.ly/Js7Le).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`read_excel`的更多信息，请参阅[pandas文档](https://oreil.ly/Js7Le)。
- en: 'You can save a DataFrame to the sheet of an Excel file with the `to_excel`
    method, giving the Excel filename and a sheetname, `''nobel_winners''` and `''WinnersSheet1''`,
    respectively, in this example:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`to_excel`方法将DataFrame保存到Excel文件的工作表中，给出Excel文件名和工作表名称，本例中分别为 `'nobel_winners'`
    和 `'WinnersSheet1'`：
- en: '[PRE26]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: There are various options similar to `to_csv` covered in the [pandas docs](https://oreil.ly/g15Al).
    Because pandas `Panel`s and Excel files can store multiple DataFrames, there is
    a `Panel` `to_excel` method to write all its DataFrames to an Excel file.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多与`to_csv`类似的选项，都在[pandas文档](https://oreil.ly/g15Al)中有详细介绍。因为pandas `Panel`s
    和 Excel文件可以存储多个DataFrame，所以有一个`Panel` `to_excel`方法可以将其所有的DataFrame写入Excel文件中。
- en: 'If you need to select multiple DataFrames to write to a shared Excel file,
    you can use an `ExcelWriter` object:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要选择要写入共享Excel文件的多个DataFrame，可以使用`ExcelWriter`对象：
- en: '[PRE27]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: SQL
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SQL
- en: By preference pandas uses Python’s `SQLAlchemy` module to do the database abstraction.
    If using `SQLAlchemy`, you’ll also need the driver library for your database.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 根据偏好，pandas使用Python的`SQLAlchemy`模块来进行数据库抽象化。如果使用`SQLAlchemy`，还需要数据库的驱动程序库。
- en: 'The easiest way to load a database table or the results of an SQL query is
    with the `read_sql` method. Let’s use our preferred SQLite database and read its
    winners table into a DataFrame:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`read_sql`方法加载数据库表或SQL查询结果是最简单的方法。让我们使用我们首选的SQLite数据库，并将其获奖者表读入DataFrame中：
- en: '[PRE28]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO7-1)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO7-1)'
- en: Here, we use an existing SQLite (file-based) database. SQLAlchemy can create
    engines for all the commonly used databases, for example *mysql://USER:PASSWORD@localhost/db*.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用一个现有的SQLite（基于文件的）数据库。SQLAlchemy可以为所有常用的数据库创建引擎，例如 *mysql://USER:PASSWORD@localhost/db*。
- en: '[![2](assets/2.png)](#co_introduction_to_pandas_CO7-2)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introduction_to_pandas_CO7-2)'
- en: Read the contents of the `'nobel_winners'` SQL table into a DataFrame. `read_sql`
    is a convenience wrapper around the `read_sql_table` and `read_sql_query` methods
    and will do the right thing depending on its first argument.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 将`'nobel_winners'`SQL 表的内容读入 DataFrame。`read_sql`是`read_sql_table`和`read_sql_query`方法的便捷包装器，根据其第一个参数将执行正确的操作。
- en: 'Writing DataFrames to an SQL database is simple enough. Using the engine we
    just created, we can add a copy of the winners table to our SQLite database:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 写入 SQL 数据库非常简单。使用刚刚创建的引擎，我们可以将获奖者表的副本添加到我们的 SQLite 数据库中：
- en: '[PRE29]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'If you encounter errors due to packet-size limitations, the `chunksize` parameter
    can set the number of rows to be written at a time:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果遇到由于数据包大小限制而导致的错误，可以使用`chunksize`参数设置每次写入的行数：
- en: '[PRE30]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'pandas will do the sensible thing and try to map your data to a suitable SQL
    type, inferring the datatype of objects. If necessary, the default type can be
    overridden in the load call:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 将会尝试将数据映射到适当的 SQL 类型，推断对象的数据类型。如果需要，可以在加载调用中覆盖默认类型：
- en: '[PRE31]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO8-1)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO8-1)'
- en: Override pandas’s inference, and specify year as a `String` column.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖 pandas 的推断，并指定年份作为`String`列。
- en: Further details of pandas-SQL interaction can be found [in the pandas documentation](https://oreil.ly/kiLyQ).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步的 pandas-SQL 交互细节可以在[pandas 文档](https://oreil.ly/kiLyQ)中找到。
- en: MongoDB
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MongoDB
- en: For dataviz work, there’s a lot to be said for the convenience of document-based
    NoSQL databases like MongoDB. In MongoDB’s case, things are even better, as it
    uses a binary form of JSON for its datastore—​namely BSON, short for binary JSON.
    Since JSON is our data glue of choice, as it connects our web dataviz with its
    backend server, there’s a good reason to consider storing your datasets in Mongo.
    It also plays nicely with pandas.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据可视化工作，像 MongoDB 这样的文档型 NoSQL 数据库非常方便。在 MongoDB 的情况下，情况更好，因为它使用一种名为 BSON
    的 JSON 二进制形式作为其数据存储格式，即二进制 JSON。由于 JSON 是我们选择的数据粘合剂，连接我们的 Web 数据可视化和其后端服务器，所以有足够的理由考虑将数据集存储在
    Mongo 中。它还与 pandas 很好地协作。
- en: 'As we’ve seen, pandas DataFrames convert nicely to and from JSON format, so
    getting a Mongo document collection into a pandas DataFrame is a pretty easy affair:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，pandas 的 DataFrame 可以很好地转换到 JSON 格式，并且可以将 Mongo 文档集合轻松转换为 pandas DataFrame：
- en: '[PRE32]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO9-1)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO9-1)'
- en: Create a Mongo client, using the default host and ports.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 Mongo 客户端，使用默认的主机和端口。
- en: '[![2](assets/2.png)](#co_introduction_to_pandas_CO9-2)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introduction_to_pandas_CO9-2)'
- en: Get the `nobel_prize` database.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 获取`nobel_prize`数据库。
- en: '[![3](assets/3.png)](#co_introduction_to_pandas_CO9-3)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_introduction_to_pandas_CO9-3)'
- en: Find all documents in the `winner` collection.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在`winner`集合中找到所有文档。
- en: '[![4](assets/4.png)](#co_introduction_to_pandas_CO9-4)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_introduction_to_pandas_CO9-4)'
- en: Load all documents from the cursor into a list and use to create a DataFrame.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 将游标中的所有文档加载到列表中，并用于创建 DataFrame。
- en: '[![5](assets/5.png)](#co_introduction_to_pandas_CO9-5)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_introduction_to_pandas_CO9-5)'
- en: The winners collection is empty at this point—let’s fill it with some DataFrame
    data.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 此时 winners 集合为空—让我们用一些 DataFrame 数据填充它。
- en: 'It’s just as easy to insert a DataFrame’s records into a MongoDB database.
    Here, we use the `get_mongo_database` method we defined in [Example 3-5](ch03.xhtml#data_get_mongo)
    to get our `nobel_prize` database and save the DataFrame to its winners collection:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 记录插入 MongoDB 数据库同样简单。在这里，我们使用我们在[示例 3-5](ch03.xhtml#data_get_mongo)中定义的`get_mongo_database`方法获取我们的`nobel_prize`数据库，并将
    DataFrame 保存到其 winners 集合中：
- en: '[PRE33]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO10-1)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO10-1)'
- en: Converts the DataFrame to a `dict`, using the `records` argument to convert
    the rows into individual objects.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 转换为`dict`，使用`records`参数将行转换为单独的对象。
- en: '[![2](assets/2.png)](#co_introduction_to_pandas_CO10-2)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introduction_to_pandas_CO10-2)'
- en: For PyMongo version 2, use the `insert` method.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 PyMongo 版本 2，请使用`insert`方法。
- en: 'pandas doesn’t have MongoDB convenience methods comparable to `to_csv` or `read_csv`,
    but it’s easy enough to roll a couple of utility functions to convert from MongoDB
    to DataFrames and back again:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 没有像`to_csv`或`read_csv`那样的 MongoDB 便利方法，但是很容易编写几个实用函数来在 MongoDB 和 DataFrame
    之间进行转换：
- en: '[PRE34]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO11-1)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO11-1)'
- en: Mongo’s `_id` field will be included in the DataFrame. By default, remove the
    column.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Mongo 的 `_id` 字段将包含在 DataFrame 中。默认情况下，删除该列。
- en: 'Having inserted the DataFrame’s records into Mongo, let’s make sure they have
    been successfully stored:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 将 DataFrame 的记录插入 Mongo 后，让我们确保它们已经成功存储：
- en: '[PRE35]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO12-1)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO12-1)'
- en: The collection’s `find` method returns a cursor, which we convert to a Python
    list to see the contents.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 集合的 `find` 方法返回一个游标，我们将其转换为 Python 列表以查看内容。
- en: Another way to create DataFrames is to build them from a collection of Series.
    Let’s have a look at that, taking the opportunity to explore Series in more detail.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种创建 DataFrame 的方法是从一系列 Series 构建它们。让我们来看看这个过程，并借此机会更详细地探讨 Series。
- en: Series into DataFrames
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Series 转为 DataFrame
- en: Series are the building block of pandas’s DataFrames. They can be manipulated
    independently with methods that mirror those of the DataFrame and they can be
    combined to form DataFrames, as we’ll see in the subsection.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Series 是 pandas 的 DataFrame 的构建模块。它们可以独立地使用与 DataFrame 镜像的方法进行操作，并且它们可以组合成 DataFrame，正如我们将在子节中看到的那样。
- en: The key idea with pandas Series is the index. These indices function as labels
    for the heterogeneous data contained in, say, a row of data. When pandas operates
    on more than one data object, these indices are used to align the fields.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: pandas Series 的关键思想是索引。这些索引作为标签，用于包含在一行数据中的异构数据。当 pandas 操作多个数据对象时，这些索引用于对齐字段。
- en: 'Series can be created in one of three ways. The first is from a Python list
    or NumPy array:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Series 可以通过三种方式之一创建。第一种是从 Python 列表或 NumPy 数组创建：
- en: '[PRE36]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Note that integer indices are automatically created for our Series. If we were
    adding a row of data to a DataFrame (table), we would want to specify the column
    indices by passing them as a list of integers or labels:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们的 Series 自动创建了整数索引。如果我们要向 DataFrame（表）添加一行数据，我们将希望通过将它们作为整数或标签的列表传递来指定列索引：
- en: '[PRE37]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Note that the length of the index array should match the length of the data
    array.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，索引数组的长度应与数据数组的长度匹配。
- en: 'We can specify both data and index using a Python `dict`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Python `dict` 指定数据和索引：
- en: '[PRE38]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'If we pass an index array along with the `dict`, pandas will do the sensible
    thing, matching the indices to the data array. Any unmatched indices will be set
    to `NaN` (not a number), and any unmatched data discarded. Note one consequence
    of having fewer elements than indices is that the series is cast to a `float64`
    type:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们连同 `dict` 传递一个索引数组，pandas 将做出明智的事情，将索引与数据数组进行匹配。任何不匹配的索引将设置为 `NaN`（不是数字），并且任何不匹配的数据将被丢弃。注意，元素少于索引的一个后果是
    series 被转换为 `float64` 类型：
- en: '[PRE39]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Finally, we can pass a single, scalar value as data to the Series, provided
    we also specify an index. The scalar value is then applied to all indices:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将单个标量值作为数据传递给 Series，只要我们还指定了一个索引。然后，该标量值将应用于所有索引：
- en: '[PRE40]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Series are like NumPy arrays (`ndarray`), which means they can be passed to
    most NumPy functions:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Series 就像 NumPy 数组（`ndarray`）一样，这意味着它们可以传递给大多数 NumPy 函数：
- en: '[PRE41]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Slicing operations work as they would with Python lists or `ndarray`s, but
    note that the index labels are preserved:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 切片操作的工作方式与 Python 列表或 `ndarray` 相同，但请注意索引标签会被保留：
- en: '[PRE42]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Unlike NumPy’s arrays, pandas’s series can take data of multiple types. Adding
    two series demonstrates this utility with numbers being added while strings are
    concatenated:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 与 NumPy 的数组不同，pandas 的 series 可以接受多种类型的数据。通过添加两个 series 来演示此实用性，其中数字被加在一起，而字符串被串联：
- en: '[PRE43]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The ability to create and manipulate individual Series is particularly important
    when you are interacting with the NumPy ecosystem, manipulating data from a DataFrame,
    or creating visualizations outside of pandas’s Matplotlib wrapper.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在与 NumPy 生态系统交互、操作来自 DataFrame 的数据或在 pandas 的 Matplotlib 封装器之外创建可视化时，创建和操作单独的
    Series 尤为重要。
- en: 'As Series are the building block of DataFrames, it’s easy to join them together
    to create a DataFrame, using pandas’s `concat` method:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Series 是 DataFrame 的构建模块，因此可以使用 pandas 的 `concat` 方法将它们连接起来创建 DataFrame：
- en: '[PRE44]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[![1](assets/1.png)](#co_introduction_to_pandas_CO13-1)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introduction_to_pandas_CO13-1)'
- en: We use the `names` and `categories` series to provide the data and column names
    (the series `name` property) for a DataFrame.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `names` 和 `categories` series 为 DataFrame 提供数据和列名（series 的 `name` 属性）。
- en: '[![2](assets/2.png)](#co_introduction_to_pandas_CO13-2)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introduction_to_pandas_CO13-2)'
- en: Concatenate the two Series using the `axis` argument of `1` to indicate that
    the Series are columns.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `axis` 参数为 `1` 将两个 Series 连接起来，以指示它们是列。
- en: Along with the many ways to create DataFrames from files and databases just
    discussed, you should now have a solid grounding in getting data into and out
    of DataFrames.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 除了刚刚讨论的从文件和数据库创建DataFrame的多种方法之外，现在你应该已经掌握了从DataFrame中获取数据的坚实基础。
- en: Summary
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter laid a foundation for the two pandas-based chapters to come. The
    core concepts of pandas—​the DataFrame, Index, and Series—were discussed and we
    saw why pandas is such a good fit with the type of real-world data that data visualizers
    deal with, extending the NumPy `ndarray` by allowing the storage of heterogeneous
    data and adding a powerful indexing system.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 本章奠定了接下来两章基于pandas的基础。讨论了pandas的核心概念——DataFrame、Index和Series，我们看到了为什么pandas非常适合处理数据可视化者处理的现实世界数据类型，通过允许存储异构数据并添加强大的索引系统来扩展NumPy
    `ndarray`。
- en: With pandas’s core data structures under our belts, the next few chapters will
    show you how to use them to clean and process your dataset of Nobel Prize winners,
    extending your knowledge of the pandas toolkit and showing you how to go about
    applying it in a data visualization context.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 有了pandas的核心数据结构的基础，接下来的几章将向你展示如何使用它们来清理和处理你的诺贝尔奖获得者数据集，扩展你对pandas工具包的了解，并演示如何在数据可视化环境中应用它。
- en: Now that we know how to get data into and out of a DataFrame, it’s time to see
    what pandas can do with it. We’ll first see how to give your data a clean bill
    of health, discovering and fixing anomalies such as duplicate rows, missing fields,
    and corrupted data.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何将数据输入和输出DataFrame，是时候看看pandas可以做什么了。我们将首先了解如何确保你的数据无懈可击，发现并修复诸如重复行、丢失字段和损坏数据等异常。
- en: ^([1](ch08.xhtml#idm45607780439264-marker)) The columns in a typical spreadsheet
    will typically have different datatypes (dtypes), like floats, date-times, integers
    etc.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch08.xhtml#idm45607780439264-marker)) 典型电子表格中的列通常具有不同的数据类型（dtypes），如浮点数、日期时间、整数等。
- en: ^([2](ch08.xhtml#idm45607779978240-marker)) Only if the column name is a string
    without spaces.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch08.xhtml#idm45607779978240-marker)) 只有列名是不带空格的字符串时。
- en: ^([3](ch08.xhtml#idm45607779218800-marker)) If you have problems, you might
    try a subset of your data in [JSONLint’s validator](https://jsonlint.com) for
    better feedback.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch08.xhtml#idm45607779218800-marker)) 如果你遇到问题，可以尝试在[JSONLint的验证器](https://jsonlint.com)中验证你的数据，以获得更好的反馈。
- en: ^([4](ch08.xhtml#idm45607779160128-marker)) D3 takes a number of other data
    formats, such as hierarchical (tree type) data or node and link graph formats.
    Here’s an example of [a tree hierarchy specified in JSON](https://oreil.ly/WsBCI).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch08.xhtml#idm45607779160128-marker)) D3支持多种其他数据格式，如分层（树状）数据或节点和链接图格式。这里有一个[a
    tree hierarchy specified in JSON](https://oreil.ly/WsBCI)的示例。
- en: ^([5](ch08.xhtml#idm45607779004224-marker)) I recommend using this approach
    if you want to get a feel for the CSV or JSON parsers. It’s much more convenient
    than managing local files.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch08.xhtml#idm45607779004224-marker)) 如果你想感受一下CSV或JSON解析器的使用，我建议你采用这种方法。这比管理本地文件要方便得多。
