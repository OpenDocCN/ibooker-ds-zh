- en: epilogue
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序言
- en: You made it! Whether you’re a data scientist interested in using ensembles for
    building enterprise models, an engineer involved in building machine-learning-based
    applications, a Kaggler looking to gain an extra edge over the competition, a
    student, or a casual enthusiast, I hope you’ve learned something new about ensemble
    methods!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 您做到了！无论您是希望使用集成来构建企业模型的数据科学家，还是参与构建基于机器学习应用的工程师，或者是希望在与竞争者竞争中取得优势的Kaggler，学生，或者是普通爱好者，我都希望您在集成方法上有所新收获！
- en: This book was always intended to be more than just a another among hundreds
    of tutorials that are a simple Google search away. Instead, the goal was to foster
    intuition and a deeper understanding of what ensembles are, what motivates the
    design and development of different ensemble methods, and how we can get the best
    out of them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的初衷不仅仅是成为成百上千个教程中的一个，简单地进行Google搜索就能找到。相反，目标是培养直觉和更深入地理解集成是什么，是什么激发了不同集成方法的设计和开发，以及我们如何从中获得最佳效果。
- en: We took different ensemble methods apart and put them back together ourselves
    (in many cases, from scratch!) to really see what makes them tick. We learned
    about sophisticated off-the-shelf tools and packages for several popular ensemble
    methods. And, finally, through case studies, we learned how to use ensemble methods
    in practice to tackle challenging real-world applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不同的集成方法拆解并重新组合（在许多情况下，从头开始！）以真正了解是什么使它们运转。我们学习了几个流行集成方法的复杂现成工具和包。最后，通过案例研究，我们学习了如何在实践中使用集成方法来解决具有挑战性的现实世界应用。
- en: I hope this immersive approach was helpful in demystifying the technical and
    algorithmic details conceptually and visually. Armed with this foundation and
    ensemble mindset, you can now go on to build better applications and create your
    own ensemble methods. Table E.1 is a flashback to the various ensemble methods
    we’ve learned about.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这种沉浸式的方法在概念上和视觉上帮助您揭开了技术和算法细节的神秘面纱。凭借这个基础和集成思维，您现在可以继续构建更好的应用程序并创建您自己的集成方法。表E.1是对我们所学到的各种集成方法的回顾。
- en: Table E.1 Ensemble methods covered in this book
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 表E.1 本书涵盖的集成方法
- en: '| Chapter | Ensemble methods |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| 第 | 集成方法 |'
- en: '| Chapter 2 | Homogeneous parallel ensembles: bagging, random forests, pasting,
    random subspaces, random patches, Extra Trees |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| 第2章 | 同构并行集成：bagging、随机森林、pasting、随机子空间、随机补丁、Extra Trees|'
- en: '| Chapter 3 | Heterogeneous parallel ensembles: majority voting, weighting,
    Dempster-Shafer ensembling, stacking, and meta-learning |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 第3章 | 异构并行集成：多数投票、加权、Dempster-Shafer集成、堆叠和元学习|'
- en: '| Chapter 4 | Sequential adaptive boosting ensembles: AdaBoost, LogitBoost
    |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 第4章 | 顺序自适应提升集成：AdaBoost、LogitBoost|'
- en: '| Chapter 5 | Sequential gradient boosting ensembles: gradient boosting (and
    LightGBM) |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 第5章 | 顺序梯度提升集成：梯度提升（以及LightGBM）|'
- en: '| Chapter 6 | Sequential gradient boosting ensembles: Newton boosting (and
    XGBoost) |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 第6章 | 顺序梯度提升集成：牛顿提升（以及XGBoost)|'
- en: '| Chapter 8 | Sequential gradient boosting ensembles: ordered boosting (and
    CatBoost) |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 第8章 | 顺序梯度提升集成：有序提升（以及CatBoost）|'
- en: '| Chapter 9 | Explainable ensembles: explainable boosting machines (EBMs) |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 第9章 | 可解释的集成：可解释提升机（EBMs）|'
- en: E.1 Further reading
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: E. 进一步阅读
- en: Ensemble methods are a key part of any data scientist’s toolbox, with which
    we can train ensembles of strong learners, weak learners, and even other ensembles
    of other ensembles! As you continue to explore this rich and fascinating area,
    the following resources will help you delve more deeply into specialized subtopics
    and future directions in the area of ensemble methods.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法是任何数据科学家工具箱中的关键部分，通过它可以训练强学习器、弱学习器，甚至是其他集成方法的集成！随着您继续探索这个丰富而迷人的领域，以下资源将帮助您更深入地研究该领域的专业子主题和未来方向。
- en: E.1.1 Practical ensemble methods
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.1.1 实践中的集成方法
- en: 'Corey Wade, *Hands-On* *Gradient Boosting with XGBoost and scikit-learn: Perform
    accessible machine learning and extreme gradient boosting with Python* (Packt
    Publishing, 2020)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Corey Wade，*动手实践梯度提升：使用XGBoost和scikit-learn进行易于理解的机器学习和极端梯度提升*（Packt Publishing，2020）
- en: Dipayan Sarkar and Vijayalakshmi Natarajan, *Ensemble Machine Learning Cookbook*
    (Packt Publishing, 2019)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dipayan Sarkar和Vijayalakshmi Natarajan，*集成机器学习食谱*（Packt Publishing，2019）
- en: E.1.2 Theory and foundations of ensemble methods
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.1.2 集成方法的理论和基础
- en: 'Robert E. Schapire and Yoav Freund, *Boosting: Foundations and Algorithms*
    (The MIT Press, 2012)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Robert E. Schapire 和 Yoav Freund，*提升：基础与算法*（麻省理工学院出版社，2012年）
- en: 'Zhi-Hua Zhou, *Ensemble Methods: Foundations and Algorithms, 1st ed**.* (Chapman
    & Hall/CRC, 2012)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhi-Hua Zhou，*集成方法：基础与算法，第1版**。（查普曼与霍尔/CRC，2012年）
- en: Lior Rokach, *Pattern Classification Using Ensemble* *Methods* (World Scientific
    Publishing Co., 2010)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lior Rokach，*使用集成方法的模式分类*（世界科学出版社，2010年）
- en: E.2 A few more advanced topics
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: E.2 一些更高级的主题
- en: Before wrapping up, I’ll point you toward two other frameworks of machine learning
    and AI that have seen increased research focus on ensemble methods. The ensemble
    approaches covered in this book address the “classical machine-learning problems,”
    where data is typically represented as a table. Data, however, is far richer and
    can have many more modalities and structures than being merely tabular, including
    object-level representations, images, video, text, audio, graphs, networks, and
    even multi-modal data with combinations of these!
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束之前，我将向您介绍两个其他机器学习和人工智能框架，它们在集成方法上增加了研究重点。本书中涵盖的集成方法针对的是“经典机器学习问题”，其中数据通常以表格形式表示。然而，数据远比表格丰富得多，可以具有许多更多模态和结构，包括对象级表示、图像、视频、文本、音频、图、网络，甚至这些组合的多模态数据！
- en: The framework of relational learning (also known as symbolic machine learning)
    uses high-level symbolic representations of objects, concepts, and relationships
    between them. Machine-learning problems can then be framed in this representation
    and trained using different methods, including ensemble methods. Relational learning
    is typically well suited for reasoning problems (e.g., link prediction in social
    networks).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 关系学习（也称为符号机器学习）框架使用对象、概念及其之间关系的高级符号表示。然后可以使用不同的方法，包括集成方法，在这个表示中构建机器学习问题并进行训练。关系学习通常非常适合推理问题（例如，社交网络中的链接预测）。
- en: The framework of deep learning (also known as neural machine learning) uses
    low-level neural connectionist representations of objects and concepts between
    them. Artificial neural networks and deep learning models are framed in this representation.
    Deep learning is typically well suited for perception problems (e.g., object detection
    in video).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（也称为神经机器学习）框架使用对象及其之间概念的低级神经连接主义表示。人工神经网络和深度学习模型都基于这种表示。深度学习通常非常适合感知问题（例如，视频中的目标检测）。
- en: Ensemble methods have been employed successfully to various degrees in both
    of these learning frameworks and are topics of active research in the machine-learning
    community.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 集成方法在这两种学习框架中得到了不同程度的成功应用，并且在机器学习社区中是活跃的研究主题。
- en: E.2.1 Ensemble methods for statistical relational learning
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.2.1 统计关系学习中的集成方法
- en: As mentioned earlier, the methods covered in this book are designed for tabular
    data, where each example is an individual object with several attributes, or features.
    For example, in diabetes diagnoses, each example is a patient with several attributes
    such as blood glucose, age, and so on.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，本书涵盖的方法是为表格数据设计的，其中每个示例都是一个具有多个属性或特征的独立对象。例如，在糖尿病诊断中，每个示例都是一个具有多个属性的患者，如血糖、年龄等。
- en: 'However, data is often far more complex and can’t be easily squeezed into a
    table. In diabetes diagnosis, for example, there are many different *types* of
    objects, such as patients, medical tests, prescriptions, and drugs. Each object
    has its own set of *attributes*. Different objects have complex *relationships*
    between them: different patients have varied medical tests, with unique outcomes,
    specific prescriptions, and so on.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，数据通常更为复杂，难以轻易地挤进表格中。例如，在糖尿病诊断中，存在许多不同类型的对象，如患者、医疗测试、处方和药物。每个对象都有其自身的属性集。不同的对象之间存在着复杂的**关系**：不同的患者有不同的医疗测试，有独特的结果，特定的处方等。
- en: In short, data is often relational. In relational database terms, such data
    can’t always be captured by a single table, but realistically requires multiple
    tables with complex interactions and cross references between them.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，数据通常是关系型的。在关系数据库术语中，此类数据不能总是由单个表来捕捉，但现实中需要多个表，它们之间有复杂的交互和交叉引用。
- en: '*Statistical relational learning* (SRL) is a subarea of machine learning that
    is concerned with training models in such domains. SRL models are effectively
    probabilistic databases and can answer complex queries beyond simple SQL-like
    database queries.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*统计关系学习*（SRL）是机器学习的一个子领域，它关注于在这些领域中训练模型。SRL 模型实际上是概率数据库，并且可以回答比简单的 SQL 类数据库查询更复杂的查询。'
- en: SRL models are well suited for modeling tasks such as link prediction, entity
    resolution, group detection and clustering, collective classification, and other
    similar graph-based prediction tasks. SRL models have been applied in text mining
    and natural language processing, social network analytics, bioinformatics, web
    and document search, and in more complex applications that require reasoning.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: SRL 模型非常适合建模诸如链接预测、实体解析、群体检测和聚类、集体分类以及其他类似基于图的预测任务。SRL 模型已应用于文本挖掘、自然语言处理、社交网络分析、生物信息学、网络和文档搜索，以及需要推理的更复杂应用中。
- en: 'SRL is an advanced topic and requires background in first-order logic, graphical
    models, and probability. The following are good resources to get started on these
    topics and SRL:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: SRL 是一个高级主题，需要一阶逻辑、图模型和概率的背景知识。以下是一些关于这些主题和 SRL 的良好资源：
- en: Lise Getoor and Ben Taskar, eds., *Introduction to Statistical Relational Learning*
    (The MIT Press, 2009)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lise Getoor 和 Ben Taskar 编著，*统计关系学习导论*（麻省理工学院出版社，2009年）
- en: Luc De Raedt, Kristian Kersting, Sriraam Natarajan, and David Poole, *Statistical
    Relational Artificial Intelligence Logic, Probability, and Computation* (Morgan
    & Claypool Publishers, 2016)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luc De Raedt、Kristian Kersting、Sriraam Natarajan 和 David Poole 编著，*统计关系人工智能：逻辑、概率和计算*（摩根和克莱泼出版社，2016年）
- en: 'One prominent ensemble method for SRL is BoostSRL ([https://starling.utdallas.edu/software/boostsrl/](https://starling.utdallas.edu/software/boostsrl/)),
    which is a gradient-boosting framework for different SRL models. The following
    reference is a good starting point for delving into ensemble methods for SRL models:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: SRL（统计关系学习）的一个突出集成方法是 BoostSRL ([https://starling.utdallas.edu/software/boostsrl/](https://starling.utdallas.edu/software/boostsrl/))），它是一个用于不同
    SRL 模型的梯度提升框架。以下参考文献是深入了解 SRL 模型集成方法的良好起点：
- en: 'Sriraam Natarajan, Kristian Kersting, Tushar Khot, and Jude Shavlik, *Boosted
    Statistical Relational Learners: From Benchmarks to Data-Driven Medicine* (Springer,
    2015)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sriraam Natarajan、Kristian Kersting、Tushar Khot 和 Jude Shavlik 编著，*增强统计关系学习：从基准到数据驱动医学*（斯普林格，2015年）
- en: E.2.2 Ensemble methods for deep learning
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: E.2.2 深度学习的集成方法
- en: Neural networks have experienced a resurgence and considerable popularity over
    the past decade, with great success on large-scale learning tasks with text, image,
    video, and audio. Many ensembling techniques discussed in this book can be applied
    to create deep learning ensembles by using deep neural networks as base estimators.
    These include techniques such as bagging, adaptive boosting, and stacking.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，神经网络经历了复兴并获得了相当大的流行度，在处理大规模学习任务（如文本、图像、视频和音频）方面取得了巨大成功。本书中讨论的许多集成技术可以通过使用深度神经网络作为基础估计器来创建深度学习集成。这些技术包括袋装、自适应提升和堆叠等技术。
- en: The main downside is the computational expense associated with training deep
    learning ensembles. Individual deep learning models are computationally expensive
    to train and are data hungry. Because ensemble methods rely on ensemble diversity
    of multiple base models, an effective deep learning ensemble will require training
    of many such networks!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的缺点是与训练深度学习集成相关的计算成本。单个深度学习模型在训练时计算成本很高，并且需要大量数据。由于集成方法依赖于多个基础模型的集成多样性，一个有效的深度学习集成将需要训练许多这样的网络！
- en: 'Deep learning ensembling techniques typically try to get away with training
    a single deep neural network and rely on techniques such as *DropOut* (which randomly
    drops neurons in the network) or *DropConnect* (which randomly drops connections)
    to create diverse variants from a single pretrained network more efficiently.
    Here are some helpful references:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习集成技术通常试图通过训练单个深度神经网络来避免训练成本，并依赖于诸如 *DropOut*（在网络中随机丢弃神经元）或 *DropConnect*（随机丢弃连接）等技术，以更有效地从单个预训练网络中创建多样化的变体。以下是一些有用的参考文献：
- en: (The original DropOut paper) Geoffrey Hinton, Nitish Srivastava, Alex Krizhevsky,
    Ilya Sutskever, and Ruslan Salakhutdinov, “Improving neural networks by preventing
    co-adaptation of feature detectors” (2012)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （原始 DropOut 论文）Geoffrey Hinton、Nitish Srivastava、Alex Krizhevsky、Ilya Sutskever
    和 Ruslan Salakhutdinov，“通过防止特征检测器的共适应来改进神经网络”（2012年）
- en: (DropOut as a neural ensemble) Pierre Baldi and Peter Sadowski, *Understanding
    Dropout* (NeurIPS, 2013)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （DropOut作为神经集成）Pierre Baldi 和 Peter Sadowski，*理解Dropout*（NeurIPS，2013）
- en: 'Another approach, called *snapshot ensembling*, saves snapshots of the model’s
    weights during training to create an ensemble without any additional training
    cost:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种称为*快照集成*的方法，在训练过程中保存模型权重的快照，以创建一个无需额外训练成本的集成：
- en: 'Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E. Hopcroft, and Kilian
    Q. Weinberger, *Snapshot Ensembles: Train 1, get M for free* (ICLR, 2017)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E. Hopcroft 和 Kilian Q.
    Weinberger，*快照集成：训练1次，免费获得M个*（ICLR，2017）
- en: 'Yet another approach that specializes deep learning models for tabular data
    is neural oblivious decision ensembles (NODE), which uses differentiable oblivious
    decision trees (similar to CatBoost) but is trained with backpropagation like
    a neural network:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种专门针对表格数据深度学习模型的途径是神经无关决策集成（NODE），它使用可微分的无关决策树（类似于CatBoost），但像神经网络一样使用反向传播进行训练：
- en: Sergei Popov, Stanislav Morozov, and Artem Babenko, *Neural Oblivious Decision
    Ensembles for Deep Learning on Tabular Data* (ICLR, 2020)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sergei Popov, Stanislav Morozov, 和 Artem Babenko，*用于表格数据的深度学习神经无关决策集成*（ICLR，2020）
- en: Deep learning ensembles is an area of active research.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习集成是一个活跃的研究领域。
- en: E.3 Thank You!
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: E.3 感谢！
- en: Finally, dear reader, thank you for reading this book and for making it to the
    very end! I hope that you had fun learning about ensemble methods and that you’ll
    find this book helpful for your projects or perhaps simply as a useful reference.
    Good luck!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，亲爱的读者，感谢您阅读这本书，并坚持读到了最后！我希望您在学习集成方法的过程中感到愉快，并且您会发现这本书对您的项目有所帮助，或者也许仅仅作为一个有用的参考。祝您好运！
