- en: front matter
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前置内容
- en: preface
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前言
- en: I’ve been fortunate to have worked with data and machine learning for about
    a decade now. My background is in machine learning, and my PhD was focused on
    applying machine learning in wireless networks. I have published papers ([http://mng.bz/zQR6](https://shortener.manning.com/zQR6))
    at leading conferences and journals on the topic of reinforcement learning, convex
    optimization, and classical machine learning techniques applied to 5G cellular
    networks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我有幸在过去十年左右的时间里从事数据和机器学习工作。我的背景是机器学习，我的博士研究集中在将机器学习应用于无线网络。我在顶级会议和期刊上发表了关于强化学习、凸优化以及将经典机器学习技术应用于5G蜂窝网络的论文([http://mng.bz/zQR6](https://shortener.manning.com/zQR6))。
- en: After completing my PhD, I began working in the industry as a data scientist
    and machine learning engineer and gained experience deploying complex AI solutions
    for customers across multiple industries, such as manufacturing, retail, and finance.
    It was during this time that I realized the importance of interpretable AI and
    started researching it heavily. I also started to implement and deploy interpretability
    techniques in real-world scenarios for data scientists, business stakeholders,
    and experts to get a deeper understanding of machine-learned models.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成我的博士学业后，我开始在工业界作为数据科学家和机器学习工程师工作，并在多个行业（如制造、零售和金融）为客户部署复杂的AI解决方案方面积累了经验。正是在这段时间里，我意识到了可解释人工智能的重要性，并开始深入研究。我还开始在实际场景中实施和部署可解释性技术，以便数据科学家、商业利益相关者和专家能够更深入地理解机器学习模型。
- en: 'I wrote a blog post ([http://mng.bz/0wnE](https://shortener.manning.com/0wnE))
    on interpretable AI and coming up with a principled approach to building robust,
    explainable AI systems. The post got a surprisingly large response from data scientists,
    researchers, and practitioners from a wide range of industries. I also presented
    on this subject at various AI and machine learning conferences. By putting my
    content in the public domain and speaking at leading conferences, I learned the
    following:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我撰写了一篇关于可解释人工智能和提出构建稳健、可解释人工智能系统的原则性方法的博客文章([http://mng.bz/0wnE](https://shortener.manning.com/0wnE))。这篇文章意外地收到了来自数据科学家、研究人员和来自各行各业实践者的巨大反响。我还在多个AI和机器学习会议上就这个主题进行了演讲。通过将我的内容公之于众并在领先会议上发言，我学到了以下内容：
- en: I wasn’t the only one interested in this subject.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对这个主题感兴趣的不止我一个人。
- en: I was able to get a better understanding of what specific topics are of interest
    to the community.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我能够更好地理解社区对哪些具体主题感兴趣。
- en: These learnings led to the book that you are reading now. You can find a few
    resources available to help you stay abreast of interpretable AI, like survey
    papers, blog posts, and one book, but no single resource or book covers all the
    important interpretability techniques that would be valuable for AI practitioners.
    There is also no practical guide on how to implement these cutting-edge techniques.
    This book aims to fill that gap by first providing a structure to this active
    area of research and covering a broad range of interpretability techniques. Throughout
    this book, we will look at concrete real-world examples and see how to build sophisticated
    models and interpret them using state-of-the-art techniques.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这些经验教训导致了你现在正在阅读的这本书的诞生。你可以找到一些资源来帮助你了解可解释人工智能的最新动态，比如综述论文、博客文章和一本书，但没有单一的资源或书籍涵盖了所有对人工智能从业者有价值的重要可解释性技术。也没有关于如何实施这些尖端技术的实用指南。本书旨在填补这一空白，首先为这个活跃的研究领域提供一个结构，并涵盖广泛的可解释性技术。在这本书中，我们将探讨具体的现实世界案例，并了解如何使用最先进的技术构建复杂模型并进行解释。
- en: I strongly believe that as complex machine learning models are being deployed
    in the real world, understanding them is extremely important. The lack of a deep
    understanding can result in models propagating bias, and we’ve seen examples of
    this in criminal justice, politics, retail, facial recognition, and language understanding.
    All of this has a detrimental effect on trust, and, from my experience, this is
    one of the main reasons why companies are resisting the deployment of AI. I’m
    excited that you also realize the importance of this deep understanding, and I
    hope you learn a lot from this book.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我坚信，随着复杂机器学习模型在现实世界的部署，理解它们至关重要。缺乏深入理解可能导致模型传播偏见，我们在刑事司法、政治、零售、面部识别和语言理解中都看到了这方面的例子。所有这些都对信任产生了有害影响，根据我的经验，这也是公司抵制人工智能部署的主要原因之一。我很高兴你也意识到这种深入理解的重要性，并希望你能从这本书中学到很多。
- en: acknowledgments
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: Writing a book is harder than I thought, and it requires a lot of work—really!
    None of this would have been possible without the support and understanding of
    my parents, Krishnan and Lakshmi Thampi; my wife, Shruti Menon; and my brother,
    Arun Thampi. My parents put me on the path of lifelong learning and have always
    given me the strength to chase my dreams. I’m also eternally grateful to my wife
    for supporting me throughout the difficult journey of writing this book, patiently
    listening to my ideas, reviewing my rough drafts, and believing that I could finish
    this. My brother deserves my wholehearted thanks as well for always having my
    back!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 写一本书比我想象的要难得多，这需要大量的工作——真的！如果没有我父母 Krishnan 和 Lakshmi Thampi、我的妻子 Shruti Menon
    和我的兄弟 Arun Thampi 的支持和理解，这一切都不可能实现。我的父母让我走上了终身学习的道路，并始终给予我追逐梦想的力量。我也永远感激我的妻子，她在我写这本书的艰难旅程中一直支持我，耐心地倾听我的想法，审阅我的草稿，并相信我能够完成它。我的兄弟也值得我衷心的感谢，因为他总是支持我！
- en: 'Next, I’d like to acknowledge the team at Manning: Brian Sawyer, who read my
    blog post and suggested that there might a book there; my editors, Matthew Spaur,
    Lesley Trites, and Kostas Passadis, for working with me, providing high-quality
    feedback, and for being patient when things got rough; and Marjan Bace, for green-lighting
    this whole project. Thanks as well to all the other folks at Manning who worked
    with me on the production and promotion of the book: Deirdre Hiam, my production
    editor; Pamela Hunt, my copyeditor; and Melody Dolab, my page proofer.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我想感谢 Manning 团队：Brian Sawyer，他阅读了我的博客文章，并建议这可能是一本好书；我的编辑 Matthew Spaur、Lesley
    Trites 和 Kostas Passadis，因为他们与我合作，提供高质量的反馈，并在事情变得艰难时保持耐心；以及 Marjan Bace，因为他批准了这个整个项目。还要感谢所有其他与我在这本书的生产和推广工作中合作的
    Manning 团队成员：Deirdre Hiam，我的生产编辑；Pamela Hunt，我的校对编辑；以及 Melody Dolab，我的页面校对员。
- en: 'I’d also like to thank the reviewers who took the time to read my manuscript
    at various stages during its development and who provided invaluable feedback:
    Al Rahimi, Alain Couniot, Alejandro Bellogin Kouki, Ariel Gamiño, Craig E. Pfeifer,
    Djordje Vukelic, Domingo Salazar, Dr. Kanishka Tyagi, Izhar Haq, James J. Byleckie,
    Jonathan Wood, Kai Gellien, Kim Falk Jorgensen, Marc Paradis, Oliver Korten, Pablo
    Roccatagliata, Patrick Goetz, Patrick Regan, Raymond Cheung, Richard Vaughan,
    Sergio Govoni, Shashank Polasa Venkata, Sriram Macharla, Stefano Ongarello, Teresa
    Fontanella De Santis, Tiklu Ganguly, Vidhya Vinay, Vijayant Singh, Vishwesh Ravi
    Shrimali, and Vittal Damaraju.Special thanks to James Byleckie and Vishwesh Ravi
    Shrimali, technical proofreaders, for carefully reviewing the code one last time
    shortly before the book went into production.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我还想感谢那些在书的发展过程中花时间阅读我的手稿并在各个阶段提供宝贵反馈的审稿人：Al Rahimi、Alain Couniot、Alejandro Bellogin
    Kouki、Ariel Gamiño、Craig E. Pfeifer、Djordje Vukelic、Domingo Salazar、Dr. Kanishka
    Tyagi、Izhar Haq、James J. Byleckie、Jonathan Wood、Kai Gellien、Kim Falk Jorgensen、Marc
    Paradis、Oliver Korten、Pablo Roccatagliata、Patrick Goetz、Patrick Regan、Raymond
    Cheung、Richard Vaughan、Sergio Govoni、Shashank Polasa Venkata、Sriram Macharla、Stefano
    Ongarello、Teresa Fontanella De Santis、Tiklu Ganguly、Vidhya Vinay、Vijayant Singh、Vishwesh
    Ravi Shrimali 和 Vittal Damaraju。特别感谢 James Byleckie 和 Vishwesh Ravi Shrimali，技术校对员，在书进入生产前仔细审查了代码。
- en: about this book
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于这本书
- en: '*Interpretable AI* is written to help you implement state-of-the-art interpretability
    techniques for complex machine learning models and to build fair and explainable
    AI systems. Interpretability is a hot topic in research, and only a few resources
    and practical guides cover all the important techniques that would be valuable
    for practitioners in the real world. This book aims to address that gap.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*可解释人工智能*旨在帮助您实现复杂机器学习模型的最先进可解释技术，并构建公平可解释的人工智能系统。可解释性是研究的热点话题，但只有少数资源和实用指南涵盖了所有对现实世界从业者有价值的重要技术。本书旨在填补这一空白。'
- en: Who should read this book
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应该阅读这本书的人
- en: '*Interpretable AI* is for data scientists and engineers who are interested
    in gaining a deeper understanding of how their models work and how to build fair
    and unbiased models. The book should also be useful for architects and business
    stakeholders who want to understand models powering AI systems to ensure fairness
    and protect the business’s users and brand.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*可解释人工智能*是为那些对深入了解模型工作原理以及如何构建公平无偏模型感兴趣的数据科学家和工程师而设计的。本书对希望了解驱动人工智能系统的模型以确保公平性并保护企业用户和品牌的企业架构师和业务利益相关者也应有帮助。'
- en: 'How this book is organized: a roadmap'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本书是如何组织的：一个路线图
- en: The book has four parts that cover nine chapters.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本书分为四个部分，共涵盖九章内容。
- en: 'Part 1 introduces you to the world of interpretable AI:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 第一部分带您进入可解释人工智能的世界：
- en: Chapter 1 covers different types of AI systems, defines interpretability and
    its importance, discusses white-box and black-box models, and explains how to
    build interpretable AI systems.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一章介绍了不同类型的AI系统，定义了可解释性及其重要性，讨论了白盒和黑盒模型，并解释了如何构建可解释人工智能系统。
- en: Chapter 2 covers white-box models and how to interpret them, specifically focusing
    on linear regression, decision trees, and generalized additive models (GAMs).
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二章介绍了白盒模型及其解释方法，具体关注线性回归、决策树和广义加性模型（GAMs）。
- en: 'Part 2 focuses on black-box models and understanding how the model processes
    the inputs and arrives at the final prediction:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分专注于黑盒模型，并理解模型如何处理输入并得出最终预测：
- en: Chapter 3 covers a class of black-box models called tree ensembles and how to
    interpret them using post hoc model-agnostic methods that are global in scope,
    such as partial dependence plots (PDPs) and feature interaction plots.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三章介绍了一类称为树集成（tree ensembles）的黑盒模型，以及如何使用全局范围内的后验模型无关方法来解释它们，例如部分依赖图（PDPs）和特征交互图。
- en: Chapter 4 covers deep neural networks and how to interpret them using post hoc
    model-agnostic methods that are local in scope, such as local interpretable model-agnostic
    explanations (LIME), SHapley Additive exPlanations (SHAP), and anchors.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四章介绍了深度神经网络及其解释方法，使用局部范围内的后验模型无关方法来解释它们，例如局部可解释模型无关解释（LIME）、SHapley加性解释（SHAP）和锚点。
- en: Chapter 5 covers convolutional neural networks and how to visualize what the
    model is focusing on using saliency maps, specifically focusing on techniques
    such as gradients, guided backpropagation, gradient-weighted class activation
    mapping (Grad-CAM), guided Grad-CAM, and smooth gradients (SmoothGrad).
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第五章介绍了卷积神经网络，以及如何使用显著性图来可视化模型关注的重点，具体关注的技术包括梯度、引导反向传播、梯度加权类激活映射（Grad-CAM）、引导Grad-CAM和光滑梯度（SmoothGrad）。
- en: 'Part 3 continues to focus on black-box models but moves to understanding what
    features or representations have been learned by them:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第三部分继续关注黑盒模型，但转向理解它们学习到的特征或表示：
- en: Chapter 6 covers convolutional neural networks and how to dissect them to understand
    representations of the data that are learned by the intermediate or hidden layers
    in the neural network.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第六章介绍了卷积神经网络，以及如何剖析它们以理解神经网络中间或隐藏层学习到的数据表示。
- en: Chapter 7 covers language models and how to visualize high-dimensional representations
    learned by them using techniques like principal component analysis (PCA) and t-distributed
    stochastic neighbor embedding (t-SNE).
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第七章介绍了语言模型，以及如何使用主成分分析（PCA）和t分布随机邻域嵌入（t-SNE）等技术可视化它们学习到的高维表示。
- en: 'Part 4 focuses on fairness and bias and paves the way for explainable AI:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 第四部分专注于公平性和偏差，为可解释人工智能铺平道路：
- en: Chapter 8 covers various definitions of fairness and ways to check whether models
    are biased. It also discusses techniques for mitigating bias and a standardizing
    approach of documenting datasets using datasheets that will help improve transparency
    and accountability with the stakeholders and users of the AI system.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8章涵盖了公平的多种定义以及检查模型是否存在偏差的方法。它还讨论了减轻偏差的技术以及使用数据表来标准化记录数据集的方法，这将有助于提高与AI系统的利益相关者和用户的透明度和问责制。
- en: Chapter 9 paves the way for explainable AI by understanding how to build such
    systems and also covers contrastive explanations using counterfactual examples.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9章通过理解如何构建这样的系统为可解释人工智能铺平道路，同时也涵盖了使用反事实示例的对比解释。
- en: About the code
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于代码
- en: This book contains many examples of source code. In most cases, source code
    is formatted in a `fixed-width` `font` `like` `this` to separate it from ordinary
    text.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书包含了许多源代码示例。在大多数情况下，源代码以`fixed-width` `font` `like` `this`这样的`固定宽度`字体格式化，以将其与普通文本区分开来。
- en: In many cases, the original source code has been reformatted; we’ve added line
    breaks and reworked indentation to accommodate the available page space in the
    book. In rare cases, even this was not enough, and listings include line-continuation
    markers (➥). Additionally, comments in the source code have often been removed
    from the listings when the code is described in the text. Code annotations accompany
    many of the listings, highlighting important concepts.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，原始源代码已被重新格式化；我们已添加换行符并重新处理缩进来适应书中的可用页面空间。在极少数情况下，即使这样也不够，列表中还包括了行续续标记（➥）。此外，当代码在文本中描述时，源代码中的注释通常已从列表中删除。代码注释伴随着许多列表，突出显示重要概念。
- en: You can get executable snippets of code from the liveBook (online) version of
    this book at [https://livebook.manning.com/book/interpretable-ai](https://livebook.manning.com/book/interpretable-ai).
    The complete code for the examples in the book is available for download from
    the Manning website at [https://www.manning.com/books/interpretable-ai](https://www.manning.com/books/interpretable-ai)
    and from GitHub at [http://mng.bz/KBdZ](https://shortener.manning.com/KBdZ).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从这本书的在线版本liveBook中获取可执行的代码片段，网址为[https://livebook.manning.com/book/interpretable-ai](https://livebook.manning.com/book/interpretable-ai)。书中示例的完整代码可在Manning网站[https://www.manning.com/books/interpretable-ai](https://www.manning.com/books/interpretable-ai)和GitHub[http://mng.bz/KBdZ](https://shortener.manning.com/KBdZ)上下载。
- en: liveBook discussion forum
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: liveBook讨论论坛
- en: Purchase of *Interpretable AI* includes free access to liveBook, Manning’s online
    reading platform. Using liveBook’s exclusive discussion features, you can attach
    comments to the book globally or to specific sections or paragraphs. It’s a snap
    to make notes for yourself, ask and answer technical questions, and receive help
    from the author and other users. To access the forum, go to [https://livebook.manning.com/book/interpretable-ai/discussion](https://livebook.manning.com/book/interpretable-ai/discussion).
    You can also learn more about Manning’s forums and the rules of conduct at [https://livebook.manning.com/discussion](https://livebook.manning.com/discussion).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 购买《可解释人工智能》包括免费访问Manning的在线阅读平台liveBook。使用liveBook的独特讨论功能，您可以在全球范围内或针对特定章节或段落附加评论。为自己做笔记、提问和回答技术问题以及从作者和其他用户那里获得帮助都非常简单。要访问论坛，请访问[https://livebook.manning.com/book/interpretable-ai/discussion](https://livebook.manning.com/book/interpretable-ai/discussion)。您还可以在[https://livebook.manning.com/discussion](https://livebook.manning.com/discussion)了解更多关于Manning论坛和行为准则的信息。
- en: Manning’s commitment to our readers is to provide a venue where a meaningful
    dialogue between individual readers and between readers and the author can take
    place. It is not a commitment to any specific amount of participation on the part
    of the author, whose contribution to the forum remains voluntary (and unpaid).
    We suggest you try asking the author some challenging questions lest his interest
    stray! The forum and the archives of previous discussions will be accessible from
    the publisher’s website as long as the book is in print.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 曼宁对读者的承诺是提供一个场所，让读者之间以及读者与作者之间可以进行有意义的对话。这并不是对作者参与特定数量活动的承诺，作者对论坛的贡献仍然是自愿的（且未付费）。我们建议您尝试向作者提出一些挑战性的问题，以免他的兴趣转移！只要这本书有售，论坛和以前讨论的存档将可通过出版社的网站访问。
- en: about the author
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于作者
- en: '![](../Images/fm_ajaythampi.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/fm_ajaythampi.png)'
- en: Ajay Thampi has a strong background in machine learning. His PhD focused on
    signal processing and machine learning. He has published papers at leading conferences
    and journals on the topics of reinforcement learning, convex optimization, and
    classical machine learning techniques applied to 5G cellular networks. Ajay is
    currently a machine learning engineer at a large tech company, primarily focused
    on responsible AI and fairness. In the past, Ajay was a lead data scientist at
    Microsoft, where he was responsible for deploying complex AI solutions for customers
    across multiple industries such as manufacturing, retail, and finance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 阿贾伊·桑皮在机器学习方面有着坚实的背景。他的博士研究专注于信号处理和机器学习。他在强化学习、凸优化以及将经典机器学习技术应用于5G蜂窝网络等主题的领先会议和期刊上发表了论文。阿贾伊目前是一家大型科技公司的高级机器学习工程师，主要专注于负责任的AI和公平性。在过去，阿贾伊曾在微软担任首席数据科学家，负责为多个行业如制造业、零售业和金融业等客户部署复杂的AI解决方案。
- en: about the cover illustration
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于封面插图
- en: The figure on the cover of *Interpretable AI* is “Marchante d’Orange de Mourcy,”
    or “An orange merchant,” taken from a collection by Jacques Grasset de Saint-Sauveur,
    published in 1797\. Each illustration is finely drawn and colored by hand.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 《可解释人工智能》封面上的图像是“Mourcy的橙商”，或“橙商”，取自雅克·格拉塞·德·圣索沃尔的收藏，该收藏于1797年出版。每一幅插图都是手工精细绘制和着色的。
- en: In those days, it was easy to identify where people lived and what their trade
    or station in life was just by their dress. Manning celebrates the inventiveness
    and initiative of the computer business with book covers based on the rich diversity
    of regional culture centuries ago, brought back to life by pictures from collections
    such as this one.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在那些日子里，仅凭人们的服饰就能轻易地识别出他们居住的地方以及他们的职业或社会地位。曼宁通过基于几个世纪前丰富多样的地域文化的书封面，庆祝计算机行业的创新精神和主动性，这些文化通过如这一系列图片的图片被重新带回生活。
