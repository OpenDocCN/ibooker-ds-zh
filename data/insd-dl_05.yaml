- en: 4 Recurrent neural networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 循环神经网络
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Weight sharing and processing sequence data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重共享和处理序列数据
- en: Representing sequence problems in deep learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在深度学习中表示序列问题
- en: Combining RNNs and fully connected layers for predictions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合 RNN 和全连接层进行预测
- en: Padding and packing to use sequences of different lengths
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同长度的序列进行填充和打包
- en: 'The previous chapter showed us how to develop neural networks for a particular
    type of spatial structure: spatial locality. Specifically, we learned how the
    convolution operator endowed our neural network with a prior that items near each
    other are related but items far from each other have *no* relationship. This allowed
    us to build neural networks that learned faster and provide more accurate solutions
    for classifying images.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章向我们展示了如何为特定类型的空间结构开发神经网络：空间局部性。具体来说，我们学习了卷积算子如何赋予我们的神经网络一个先验，即相邻的项是相关的，而远离的项则没有关系。这使得我们能够构建学习更快且为图像分类提供更准确解决方案的神经网络。
- en: 'Now we want to develop models that can handle a new type of structure: *sequen
    ces* with T items that occur in a specific order. For example, the alphabet—a,
    b, c,d, . . .—is a sequence of 26 characters. Each sentence in this book can be
    thought of as a sequence of words *or* a sequence of characters. You could use
    the temperature every hour as a sequence to try to predict the temperature in
    the future. As long as each item in the sequence can be represented as a vector
    x, we can use a sequence-based model to learn over it. For example, videos can
    be treated as a sequence of images; you could use a convolutional neural network
    (CNN) to convert each image into a vector.[¹](#fn8)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想要开发能够处理一种新型结构的模型：包含 T 个项目且按特定顺序出现的 *序列*。例如，字母表——a, b, c, d, ...——是由 26
    个字符组成的序列。这本书中的每一句话都可以被视为一个单词序列 *或* 字符序列。你可以使用每小时温度作为序列来尝试预测未来的温度。只要序列中的每个项目都可以表示为一个向量
    x，我们就可以使用基于序列的模型来学习它。例如，视频可以被看作是一系列图像；你可以使用卷积神经网络（CNN）将每个图像转换为向量。[¹](#fn8)
- en: 'In all these cases, the structure is uniquely different compared to the images
    and convolution from chapter 3\. Sequences can have a *variable* number of items.
    Forexample, the two previous sentences have variable length: 18 and 8 words, respectively.
    By comparison, images are *always* the exact same width and height. This is not
    too restricting for images since it is easy to resize them without changing their
    meaning. But we can’t just “resize” a sequence, so we need an approach that can
    handle this new problem of variable-length data.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些情况下，结构与第 3 章中的图像和卷积相比具有独特的不同。序列可以有 *可变* 的项目数量。例如，前两个句子具有可变长度：18 个单词和 8
    个单词。相比之下，图像 *总是* 具有相同的宽度和高度。这对图像来说并不太受限制，因为很容易调整大小而不改变其含义。但我们不能简单地“调整大小”序列，因此我们需要一种可以处理这种新问题（可变长度数据）的方法。
- en: 'That is where recurrent neural networks (RNNs) come into play. They give us
    a different prior for our model: *inputs follow a sequence, and order matters*.
    RNNs are particularly useful because they can handle inputs with differing sequence
    lengths. When talking about sequences and RNNs, we will often refer to the sequence
    as a *time series* and the ith item in the sequence as the ith *step in time*
    (using t and i to denote a specific item or point in time is common, and we will
    use both). This comes from a view of RNNs as processing a sequence of events at
    a regular interval. This terminology is prevalent, so we’ll use T for *time* to
    refer to the number of items in the input sequence. Using the first two sentences
    from the last paragraph again, that would be *T* = 18 for 18 words in the first
    sentence and *T* = 8 for 8 words in the second sentence.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是循环神经网络（RNN）发挥作用的地方。它们为我们模型提供了不同的先验：*输入遵循序列，顺序很重要*。RNN 特别有用，因为它们可以处理具有不同序列长度的输入。在谈论序列和
    RNN 时，我们经常将序列称为 *时间序列*，并将序列中的第 i 个项目称为第 i 个 *时间步*（使用 t 和 i 表示特定项目或时间点是很常见的，我们都会使用）。这来自于将
    RNN 视为在固定间隔处理一系列事件的观点。这个术语很普遍，所以我们将使用 T 来表示 *时间*，以指代输入序列中的项目数量。再次使用上一段的前两句话，那么对于第一句话中的
    18 个单词，T = 18；对于第二句话中的 8 个单词，T = 8。
- en: 'Using an RNN, we learn in this chapter how to create networks for sequence
    classification problems. Examples include the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用 RNN 学习如何创建用于序列分类问题的网络。以下是一些例子：
- en: '*Sentiment detection*—Is this sequence of words (e.g., a sentence, tweet, or
    paragraph) indicating a positive, negative, or neutral impression? For example,
    I might run sentence detection on Twitter to find out if people like this book.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*情感检测*—这个单词序列（例如，一个句子、推文或段落）是否表明了一种积极、消极还是中性的印象？例如，我可能会在Twitter上运行句子检测来找出人们是否喜欢这本书。'
- en: '*Vehicle maintenance*—Your car may store daily or weekly information about
    how many miles have been driven, miles per gallon while driving, engine temperature,
    and more. This could be used to predict whether a car will need repairs in the
    next 3, 6, or 12 months, often called *predictive maintenance*.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*车辆维护*—你的汽车可能存储有关行驶了多少英里、行驶时的每加仑英里数、发动机温度等信息。这可以用来预测汽车在接下来的3、6或12个月内是否需要维修，通常称为*预测性维护*。'
- en: '*Weather prediction*—Every day, you can record the high, mean, and low temperature,
    humidity, wind speed, and so on. Then you can predict tons of things like the
    temperature the next day, how many people will go to the mall (companies would
    love to know that), and if traffic will be normal, bad, or good.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*天气预报*—每天，你可以记录最高温度、平均温度、最低温度、湿度、风速等等。然后你可以预测很多事物，比如第二天的温度、多少人会去商场（公司会很乐意知道这一点），以及交通是否会正常、糟糕还是良好。'
- en: RNNs are often challenging for people to grasp when diving into deep learning,
    and many materials treat them as magic black boxes that take in sequences and
    output new sequences. For this reason, we will carefully build our way up to understanding
    what an RNN actually is. This is one of the two most challenging chapters in the
    book, and it’s OK if it doesn’t all make sense on the first read. RNNs are an
    intrinsically mind-bending concept—it took me several years to wrap my head around
    them. To help you understand the concepts in this chapter, I recommend using pen
    and paper to draw the processes and figures yourself, starting with a sequence
    of T=1, then adding a second and a third, and so on.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当人们深入研究深度学习时，RNNs（递归神经网络）通常很难理解，许多资料将它们视为接收序列并输出新序列的魔法黑盒子。因此，我们将仔细构建我们的方法，逐步理解RNN实际上是什么。这是本书中最具挑战性的两个章节之一，如果第一次阅读时不是所有内容都理解，那也是正常的。RNNs是一个本质上令人费解的概念——我花了几年时间才弄清楚它们。为了帮助你理解本章的概念，我建议使用笔和纸自己绘制过程和图表，从T=1的序列开始，然后添加第二个和第三个，依此类推。
- en: 'Before diving into problems, in section 4.1 we slowly work our way up to defining
    what a RNN is via the concept of *weight sharing*. This is the foundation of how
    RNNs work, so we start by talking about weight sharing for a simple fully connected
    network to understand the concept and then show how that concept is applied to
    produce a RNN. Once we have the mental picture in place, section 4.2 moves into
    the mechanics of loading sequence classification problems and defining a RNN in
    PyTorch. A common problem with RNNs in PyTorch is that the sequences you want
    to train on have variable lengths, but the `Tensor` object does not have any flexibility:
    all dimensions must have the same length. Section 4.3 resolves this `Tensor`/sequence
    problem with a technique called *padding* that allows PyTorch to run correctly
    when sequences in a batch have variable length. Section 4.4 closes out the new
    material with two modifications to RNNs that improve their accuracy.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究问题之前，在第4.1节中，我们通过*权重共享*的概念缓慢地逐步定义RNN是什么。这是RNN工作原理的基础，所以我们首先讨论简单全连接网络的权重共享，以理解这个概念，然后展示这个概念是如何应用于产生RNN的。一旦我们有了心理图景，第4.2节就转向了加载序列分类问题以及在PyTorch中定义RNN的机制。PyTorch中RNN的一个常见问题是，你想要训练的序列长度是可变的，但`Tensor`对象没有任何灵活性：所有维度都必须具有相同的长度。第4.3节通过一种称为*填充*的技术解决了这个`Tensor`/序列问题，这使得PyTorch在批次中的序列长度可变时可以正确运行。第4.4节通过两种改进RNN以提高其准确性的方法来结束新材料。
- en: 4.1 Recurrent neural networks as weight sharing
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 递归神经网络作为权重共享
- en: 'Before we get into the new topic of recurrent neural networks (RNNs), let’s
    talk a bit more about a concept from the last chapter: *weight sharing*. To make
    sure you are familiar with this fundamental idea, we walk through solving a contrived
    problem. That way, we can show the mechanics of the process before diving into
    the more complex RNN. Figure 4.1 is a quick reminder of the weight sharing concept,
    where we reuse a layer in multiple locations. PyTorch handles the tricky math
    of learning correctly when reusing a layer.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入新的主题——循环神经网络（RNN）之前，让我们再谈谈上一章的一个概念：*权重共享*。为了确保你对这个基本概念熟悉，我们通过解决一个虚构问题来讲解。这样，我们可以在深入研究更复杂的
    RNN 之前展示这个过程的工作原理。图 4.1 是对权重共享概念的快速回顾，其中我们在多个位置重复使用一个层。PyTorch 在重复使用层时正确处理了学习中的复杂数学。
- en: '![](../Images/CH04_F01_Raff.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F01_Raff.png)'
- en: Figure 4.1 Outline of how weight sharing works. Boxes represent any kind of
    neural network or PyTorch module. Boxes have an input/output relationship, and
    normally each layer of our network is a different box. If we reuse the same box
    multiple times, we are effectively sharing the same weights between multiple layers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 权重共享工作原理的概述。方框代表任何类型的神经网络或 PyTorch 模块。方框具有输入/输出关系，通常我们的网络中的每一层都是一个不同的方框。如果我们多次重复使用相同的方框，我们实际上在多个层之间共享相同的权重。
- en: 'When using a CNN, the convolution operation is like having a single small linear
    network that we slide across the image, applying the *same function to every spatial
    position*. This is an implicit property of a CNN that we made explicit with this
    small bit of code:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 CNN 时，卷积操作就像有一个单独的小型线性网络，我们在图像上滑动，对每个空间位置应用相同的函数。这是 CNN 的一个隐含属性，我们通过这段小代码将其明确化：
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Input vector
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 输入向量
- en: This code reuses the same weights Θ for multiple inputs. Our CNN does this implicitly.
    To help understand RNNs and how they work, we explicitly apply weight sharing
    to show how we can use it in different ways. Then we can adjust how we use weight
    sharing to arrive at the original RNN algorithm.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码重复使用相同的权重 Θ 对多个输入进行操作。我们的 CNN 隐式地这样做。为了帮助理解 RNN 以及它们是如何工作的，我们显式地应用权重共享来展示我们可以以不同的方式使用它。然后我们可以调整我们使用权重共享的方式，以达到原始
    RNN 算法。
- en: 4.1.1  Weight sharing for a fully connected network
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.1  全连接网络的权重共享
- en: Let’s imagine that we want to create a fully connected network with three hidden
    layers for a classification problem. Figure 4.2 shows what this network looks
    like as a sequence of PyTorch modules.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象一下，我们想要为分类问题创建一个具有三个隐藏层的全连接网络。图 4.2 展示了这个网络作为 PyTorch 模块序列的形状。
- en: '![](../Images/CH04_F02_Raff.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F02_Raff.png)'
- en: Figure 4.2 A simple network with three hidden layers and one output layer. The
    `nn.Sequential` layer is shown wrapping the sequence of layers in the order they
    are used (first on the bottom, last at the top).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 一个具有三个隐藏层和一个输出层的简单网络。`nn.Sequential` 层显示了按使用顺序包裹层序列（最底层在最下面，最顶层在最上面）。
- en: 'To make sure we are learning how to read and write network definitions as both
    code and math, the same network, written as equations, is shown next. The linear
    layers W are also referenced in figure 4.2 so that we can map the parts to each
    other:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们学习如何以代码和数学的方式读取和编写网络定义，下面展示了以方程式形式书写的相同网络。线性层 W 也在图 4.2 中被引用，以便我们可以将各部分相互映射：
- en: '![](../Images/CH04_F02_Raff_EQ01.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F02_Raff_EQ01.png)'
- en: 'I’ve decided to be explicit with this equation and show the shape of each linear
    layer. We have d input features according to this equation, n neurons in each
    hidden layer, and classes outputs. This explicit detail will become important
    in a moment. Let’s quickly implement this network for MNIST:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定在这个方程中明确表示，并展示每个线性层的形状。根据这个方程，我们有 d 个输入特征，每个隐藏层有 n 个神经元，以及类输出。这个明确的细节在接下来会变得很重要。让我们快速实现这个网络用于
    MNIST：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ How many values are in the input? We use this to help determine the size of
    subsequent layers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 输入中有多少个值？我们使用这个值来帮助确定后续层的大小。
- en: ❷ Hidden layer size
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 隐藏层大小
- en: ❸ How many channels are in the input?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 输入中有多少个通道？
- en: ❹ How many classes are there?
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 有多少个类别？
- en: ❺ Creates our regular model
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 创建我们的常规模型
- en: 'This is a simple fully connected model since we use `nn.Linear` layers. To
    train this as a classification problem, we again use the `train_simple_network`
    function. (This should all be familiar from chapters 2 and 3.) We can train this
    model and get the following result, which is nothing new:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的全连接模型，因为我们使用了`nn.Linear`层。要将它作为分类问题进行训练，我们再次使用`train_simple_network`函数。（所有这些都应该在2章和3章中很熟悉。）我们可以训练这个模型并得到以下结果，这并不新鲜：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now, let’s *pretend* that this is a very large network—so large that we can’t
    fit the weights for all three hidden layers **W**[*d* × *n*]^((*h*[1])), **W**[*n*
    × *n*]^((*h*[2])), and **W**[*n* × *n*]^((*h*[3])). But we *really* want a network
    with three hidden layers. One option is to *share* the weights between some of
    the layers. We can do this mathematically by simply replacing *h*[3] with *h*[2],
    which is the same as defining one object and reusing that object twice in our
    definition. Figure 4.3 shows how to do this with the second and third hidden layers
    because they have the same shape.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们*假设*这是一个非常大的网络——如此之大，以至于我们无法为所有三个隐藏层**W**[*d* × *n*]^((*h*[1])), **W**[*n*
    × *n*]^((*h*[2])), 和 **W**[*n* × *n*]^((*h*[3]))分配权重。但我们*确实*想要一个具有三个隐藏层的网络。一个选项是在某些层之间*共享*权重。我们可以通过简单地用*h*[2]替换*h*[3]来实现这一点，这相当于在定义中定义一个对象并重复使用该对象两次。图4.3展示了如何使用第二和第三隐藏层来实现这一点，因为它们具有相同的形状。
- en: '![](../Images/CH04_F03_Raff.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F03_Raff.png)'
- en: Figure 4.3 A simple feed-forward network with weight sharing. Before creating
    the `nn.Sequential` object, we define a single `nn.Linear(n,n)` layer that is
    used as both the second and third hidden layers. PyTorch figures out how to learn
    with that setup, and the second and third layers share the same weights.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 一个简单的具有权重共享的前馈网络。在创建`nn.Sequential`对象之前，我们定义了一个`nn.Linear(n,n)`层，该层被用作第二和第三隐藏层。PyTorch会找出如何使用这种设置进行学习，并且第二和第三层共享相同的权重。
- en: 'The mathematical way to express this is to change our previous equation to
    the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 表达这个的数学方法是改变我们之前的方程，变为以下形式：
- en: '![](../Images/CH04_F03_Raff_EQ01.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F03_Raff_EQ01.png)'
- en: The only thing that has changed (in red) is that we are reusing the weights
    **W**^((*h*[2])) in two different locations. *This is weight sharing*, reusing
    the weights of a layer. It’s called this because we can pretend the two different
    usages of **W**^((*h*[2])) are different layers in the network that share the
    same weights. How do we implement this in PyTorch? It’s simple. If we think of
    that linear layer as an object, we *reuse the layer object*. Everything else works
    exactly the same.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一改变的是（用红色标出），我们正在两个不同的位置重复使用权重**W**^((*h*[2]))。*这是权重共享*，重复使用层的权重。之所以这样称呼，是因为我们可以假设**W**^((*h*[2]))的两种不同使用是网络中具有相同权重的不同层。我们如何在PyTorch中实现这一点？很简单。如果我们将那个线性层视为一个对象，我们*重复使用层对象*。其他一切工作方式完全相同。
- en: 'Note You may also hear weight sharing called *tied* weights. This is the same
    concept, just a different analogy for the name: the weights are tied together.
    Some people prefer this terminology if the weights are used slightly differently.
    For example, one layer may use W while the other uses the transposed weights *W*^⊤.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您也可能听到权重共享被称为*绑定*权重。这是相同的概念，只是名称的不同类比：权重被绑定在一起。有些人更喜欢这种术语，如果权重被稍微不同的方式使用。例如，一个层可能使用W，而另一个层则使用转置权重*W*^⊤。
- en: 'The following code shows the same fully connected network but with weight sharing
    for the second and third hidden layers. We declare the `nn.Linear` layer we want
    to share as an object named `h_2` and insert it twice in the `nn.Sequential` list.
    So, the `h_2` is used as both the second and third hidden layers, and PyTorch
    will correctly train the network using the very same function—no changes needed:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了相同的全连接网络，但第二和第三隐藏层使用了权重共享。我们将想要共享的`nn.Linear`层声明为一个名为`h_2`的对象，并在`nn.Sequential`列表中插入两次。因此，`h_2`被用作第二和第三隐藏层，PyTorch将正确地使用完全相同的函数来训练网络——无需任何更改：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Creates the layer of weights for our network that we plan to share
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建我们计划共享的网络权重层
- en: ❷ First use
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 第一次使用
- en: '❸ Second use: now sharing the weights'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 第二次使用：现在共享权重
- en: 'That this code works may seem trivial from a coding perspective. It’s a very
    object-oriented design: we create an object, and the object is used in two places.
    But making the math work out is not a simple matter. Luckily, PyTorch handles
    this for you, and the same training function handles this weight sharing just
    fine:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从编程的角度来看，这段代码似乎很简单。这是一个非常面向对象的设计：我们创建了一个对象，这个对象在两个地方被使用。但是让数学成立并不是一件简单的事情。幸运的是，PyTorch为你处理了这个问题，相同的训练函数可以很好地处理这种权重共享：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'With the new weight-shared network, we can plot the validation accuracy of
    both to see what PyTorch *really* learn with shared weights and what the results
    look like:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新的权重共享网络，我们可以绘制两个网络的验证精度，以查看PyTorch*真正*使用共享权重学习到了什么，以及结果看起来像什么：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Plots the results and compares them
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 绘制结果并进行比较
- en: '![](../Images/CH04_UN01_Raff.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_UN01_Raff.png)'
- en: Using weight sharing doesn’t take any longer to train, and we don’t lose any
    accuracy (that is *not* a guarantee). We do get a nice benefit of slightly reduced
    memory, but what we have done here is rarely used. Better approaches exist to
    reduce memory usage, and the purpose of this problem was just to demonstrate the
    weight sharing. We care about weight sharing because it is the foundation for
    creating and training RNNs.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用权重共享不会增加训练时间，我们也不会失去任何精度（这不是一个保证）。我们确实得到了一个好处，即略微减少了内存使用，但我们在这里所做的是很少使用的。存在更好的方法来减少内存使用，而这个问题的目的只是演示权重共享。我们关注权重共享，因为它是在创建和训练RNNs的基础。
- en: 4.1.2  Weight sharing over time
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.2  随时间变化的权重共享
- en: 'Now that we understand weight sharing, we can talk about how it is used to
    create RNNs. The goal of an RNN is to summarize every item in a sequence of items,
    using just a single item. The process is shown in figure 4.4\. The RNN takes in
    two items: a tensor **h**[*t* − 1] that represents everything seen so far in the
    order it has seen, and a tensor **x**[t] that represents the newest/next item
    in the sequence. The RNN combines the historical summary (**h**[*t* − 1]) and
    the new information (**x**[t]) to create a *new* summary of everything seen thus
    far (**h**[t]). To make a prediction about the entire sequence of T items, we
    can use the output after T inputs (**h**[T]) because it represents the Tth item
    and every preceding item.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了权重共享，我们可以讨论它是如何用于创建循环神经网络（RNNs）的。RNN的目标是使用单个项目来总结项目序列中的每个项目。这个过程在图4.4中展示。RNN接收两个项目：一个表示到目前为止看到的所有内容的张量**h**[*t*
    − 1]，其顺序与它看到的顺序相同，以及一个表示序列中最新/下一个项目的张量**x**[t]。RNN将历史摘要（**h**[*t* − 1]）和新的信息（**x**[t]）结合起来，创建到目前为止看到的所有内容的*新*摘要（**h**[t]）。为了对整个T个项目的序列进行预测，我们可以使用T个输入之后的输出（**h**[T]），因为它代表了第T个项目以及所有前面的项目。
- en: '![](../Images/CH04_F04_Raff.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F04_Raff.png)'
- en: Figure 4.4 Diagram of the RNN process. We use t to represent the current point
    in time (the tth item in a sequence). The RNN takes in a single representation
    of all previous content **h**[*t* − 1] and information about the newest item in
    the sequence **x**[t]. The RNN merges these into a new representation of everything
    seen so far **h**[t], and the process repeats until we reach the end of the sequence.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 RNN过程的示意图。我们用t来表示当前的时间点（序列中的第t个项目）。RNN接收所有先前内容的单个表示**h**[*t* − 1]和序列中最新项目的信息**x**[t]。RNN将这些合并成到目前为止看到的所有内容的新表示**h**[t]，这个过程会一直重复，直到我们到达序列的末尾。
- en: The idea is that an RNN loops over all the items in the input. Let’s make sure
    we give some mathematical notation to all the parts of this discussion. We have
    T total units of time. Instead of a single input **x** ∈ ℝ^d, we have T inputs
    **x**[1], **x**[2], …, **x**[*T* − 1], **x**[T]. Each input is a vector of the
    same size (i.e., **x**[j] ∈ ℝ^d). Remember that each **x**[1], **x**[2], …, **x**[*T*
    − 1], **x**[T] is a vector representation of something sequential. For example,
    the weather could have a vector with the high, low, and average temperature each
    day (**x**[t] = [high,low,mean]), and the days must occur in their natural order
    (no time-traveling allowed).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是RNN遍历输入中的所有项目。让我们确保我们给这个讨论的所有部分都给出一些数学符号。我们有T个总的时间单位。我们不是只有一个输入**x** ∈
    ℝ^d，而是有T个输入**x**[1]，**x**[2]，…，**x**[*T* − 1]，**x**[T]。每个输入都是一个大小相同的向量（即，**x**[j]
    ∈ ℝ^d）。记住，每个**x**[1]，**x**[2]，…，**x**[*T* − 1]，**x**[T]都是某个序列的向量表示。例如，天气可以有一个包含每天的最高、最低和平均温度的向量（**x**[t]
    = [high,low,mean]），并且这些天必须按照它们的自然顺序出现（不允许时间旅行）。
- en: How do we process something over time? If we have a network module A, where
    *A*(**x**) = **h**, we can use weight sharing to apply the network module A to
    every item independently. So, we get T outputs, **h**[i] = *A*(**x**[i]). We will
    eventually use one of these outputs h as the input to a linear layer, but first
    we need to work our way to an RNN. The naive approach of applying *A*(⋅) independently
    is shown in figure 4.5.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何处理跨时间的东西？如果我们有一个网络模块A，其中 *A*(**x**) = **h**，我们可以使用权重共享将网络模块A独立应用于每个项目。因此，我们得到T个输出，**h**[i]
    = *A*(**x**[i])。我们最终会使用这些输出中的一个h作为线性层的输入，但首先我们需要逐步构建一个RNN。在图4.5中展示了独立应用 *A*(⋅)
    的朴素方法。
- en: '![](../Images/CH04_F05_Raff.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F05_Raff.png)'
- en: Figure 4.5 A naive solution using a network module A to process T different
    inputs in a sequence independently. Each item in the sequence *x*[i] is processed
    independently of every other sequence. This approach does not recognize the sequential
    nature of the data, because there is no path connecting **x**[t] and **x**[t][+1].
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 使用网络模块A独立处理T个不同输入的朴素解决方案。序列中的每个项目 *x*[i] 都独立于其他序列进行处理。这种方法没有识别数据的序列性质，因为没有路径连接
    **x**[t] 和 **x**[t][+1]。
- en: 'We use weight sharing to apply the same function/layer *A*(⋅) to each item
    over time. But we don’t do anything to connect information *over* time. We need
    our RNN function A to take in both a history and the input so we can have code
    that looks somethinglike this:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用权重共享来将相同的函数/层 *A*(⋅)应用于每个项目。但我们没有做任何事情来连接跨时间的信息。我们需要我们的RNN函数A同时接收历史和输入，这样我们就可以有类似这样的代码：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ *h*[0]
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ *h*[0]
- en: ❷ **x**[1], **x**[2], …, **x**[T]
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ **x**[1], **x**[2], …, **x**[T]
- en: ❸ **h**[t] = *A*(**h**[*t* − 1],**x**[t])
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ **h**[t] = *A*(**h**[*t* − 1],**x**[t])
- en: 'That way, the RNN takes in both the history and the new item. This is done
    by giving A a *recurrent* weight. We’ve used *h*[t] to indicate the result from
    time step t, so let’s incorporate that into our model. First, let’s look at the
    equation with some light annotation—the kind you might see in a paper or online.
    Take a few minutes to try to parse the parts on your own; this will help you grow
    your skills in reading this kinds of deep learning math:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，RNN会同时接收历史和新的项目。这是通过给A一个*递归*权重来实现的。我们用 *h*[t] 来表示时间步t的结果，所以让我们将这个概念纳入我们的模型。首先，让我们看一下带有一些简单注释的方程——你可能在论文或网上看到的那种。花几分钟时间尝试自己解析这些部分，这将有助于你在阅读这类深度学习数学方面的技能提升：
- en: '![](../Images/ch4-eqs-to-illustrator0x.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/ch4-eqs-to-illustrator0x.png)'
- en: 'Now let’s look at a heavily annotated version of this same equation:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一下这个方程的详细注释版本：
- en: '![](../Images/CH04_UN02_Raff.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_UN02_Raff.png)'
- en: We have one set of weights (**W**[*d* × *n*]^(cur)) that takes in the *current*
    time step (**x**[i]) added to a second set of weights (**W**[*n* × *n*]^(prev))
    for the *previous* time step’s result (**h**[*i* − 1]). By reusing this new function
    at each time step, we get information across time. This is all shown in figure
    4.6.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个权重集（**W**[*d* × *n*]^(cur))，它接收当前的时步（**x**[i])，并加上第二个权重集（**W**[*n* × *n*]^(prev))，用于前一个时步的结果（**h**[*i*
    − 1])。通过在每个时步重复使用这个新函数，我们得到了跨时间的信息。所有这些都在图4.6中展示。
- en: '![](../Images/CH04_F06_Raff.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F06_Raff.png)'
- en: 'Figure 4.6 The network A is defined to take in two inputs: the previous hidden
    state *h*[*t* − 1] and the current input *x*[t]. This allows us to unroll the
    network and share information across time, dealing effectively with the sequential
    nature of the data.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 网络A被定义为接收两个输入：前一个隐藏状态 *h*[*t* − 1] 和当前输入 *x*[t]。这允许我们展开网络并在时间上共享信息，有效地处理数据的序列性质。
- en: This approach to sharing information across time defines a basic RNN. The idea
    is that we are reusing the *same function and weights* A at every time step. At
    time step t, the model gets information about the past from the hidden state **h**[**t**
    **−** **1**]. Because **h**[**t** **−** **1**] is computed from **h**[**t** **−**
    **2**], it has information from the past *two* time steps. And since **h**[**t**
    **−** **2**] depends on **h**[**t** **−** **3**], it’s *three* previous steps.
    Keep following this back to the default value of **h**[0], and you can see how
    **h**[**t** **−** **1**] has information from every previous time step based on
    the order of those time steps. That’s how RNNs capture information over time.
    But what do we do at the start of time (*i* = 1) when we need **h**[0], which
    does not exist? Implicitly, we assume that **h**[0] = ![](../Images/vec_0.png)
    (i.e., a vector of all zeros) to make things complete. It can be helpful to draw
    this out more explicitly, as shown in figure 4.7; this is often called *unrolling*
    the RNN over time.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这种在时间上共享信息的方法定义了一个基本的RNN。其思想是，我们在每个时间步都重复使用相同的函数和权重A。在时间步t，模型从隐藏状态**h**[**t**
    **−** **1**]获取关于过去的信息。因为**h**[**t** **−** **1**]是由**h**[**t** **−** **2**]计算得出的，它包含了过去**两个**时间步的信息。而且由于**h**[**t**
    **−** **2**]依赖于**h**[**t** **−** **3**]，它是**三个**之前步骤。继续这样回溯到默认值**h**[0]，你可以看到**h**[**t**
    **−** **1**]是如何根据这些时间步的顺序从每个之前的时间步获取信息的。这就是RNN如何捕捉时间上的信息。但是，当我们需要**h**[0]，而它不存在时，我们在时间开始时（*i*
    = 1）怎么办？隐含地，我们假设**h**[0] = ![图片](../Images/vec_0.png)（即所有零值的向量）以使事情完整。这有助于更明确地绘制出来，如图4.7所示；这通常被称为在时间上“展开”RNN。
- en: '![](../Images/CH04_F07_Raff.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F07_Raff.png)'
- en: Figure 4.7 An example of unrolling the RNN for *T* = 3 time steps. Here we explicitly
    draw out each input (**x**[t]) and hidden activation (**h**[t]) in the process.
    The initial hidden state **h**[0] is always set to a vector of all zero values.
    Notice that it now looks like a feed-forward model.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7 展开RNN的例子，对于 *T* = 3 个时间步。在这里，我们明确地绘制了每个输入（**x**[t]）和隐藏激活（**h**[t]）的过程。初始隐藏状态**h**[0]始终设置为所有零值的向量。注意，现在它看起来像是一个前馈模型。
- en: Notice how it is starting to look eerily similar to a fully connected network.
    The only difference is that we have multiple inputs, **x**[1], …, **x**[T], one
    for each time step. For simple classification problems, we will use the last activation
    **h**[T] as the result from which to make a prediction because **h**[T] has information
    from every previous time step, and it is the last time step. This makes **h**[T]
    the only step with information about the *entire* sequence. The fact that we can
    unroll an RNN like this is why we can use the same algorithms to train it. Unrolling
    an RNN so that we are applying the same function (weight sharing) over and over,
    just changing the inputs, is the essence of what anRNN is.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 注意它开始看起来与全连接网络非常相似。唯一的区别是我们有多个输入，**x**[1]，…，**x**[T]，每个时间步一个。对于简单的分类问题，我们将使用最后一个激活**h**[T]作为预测结果，因为**h**[T]包含了每个之前时间步的信息，并且它是最后一个时间步。这使得**h**[T]成为唯一一个具有关于整个序列信息的步骤。我们可以这样展开RNN的事实是我们可以使用相同的算法来训练它。将RNN展开，以便我们反复应用相同的函数（权重共享），只是改变输入，这是RNN的本质。
- en: 4.2 RNNs in PyTorch
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 PyTorch中的RNN
- en: Now that we know what an RNN is, we need to figure out how to use one in PyTorch.
    While a lot of code is provided for us to accomplish this goal, we still need
    to build a lot of code ourselves. Like everything in this book, the first step
    is to create a `Dataset` that represents our data and loads it, followed by a
    `model` that uses the PyTorch `nn.Module` class that takes the input data and
    produces a prediction.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了RNN是什么，我们需要弄清楚如何在PyTorch中使用它。虽然有很多代码为我们提供了实现这一目标的方法，但我们仍然需要自己编写大量的代码。就像这本书中的所有内容一样，第一步是创建一个`Dataset`来表示我们的数据并加载它，然后是一个`model`，它使用PyTorch的`nn.Module`类，该类接受输入数据并生成预测。
- en: But for RNNs, we need vectors, and most of the data we use is *not* naturally
    represented as a vector. We need to do some extra work to fix that. Figure 4.8
    shows the steps to get this working.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 但是对于RNN，我们需要向量，而我们使用的大多数数据并不是自然地表示为向量。我们需要做一些额外的工作来解决这个问题。图4.8展示了实现这一功能的步骤。
- en: '![](../Images/CH04_F08_Raff.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F08_Raff.png)'
- en: Figure 4.8 Four high-level steps for making a prediction based on an input sequence
    of length T.We need to create a representation of the sequence as vectors, pass
    that representation to an RNN toproduce T hidden states, reduce to one hidden
    state, and then use a fully connected layer to makea prediction.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 基于长度为T的输入序列进行预测的四个高级步骤。我们需要创建序列的向量表示，将这个表示传递给RNN以产生T个隐藏状态，将其缩减为一个隐藏状态，然后使用全连接层进行预测。
- en: 'To represent sequence data for an RNN in PyTorch, we use a three-dimensional
    input representation:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要在PyTorch中表示RNN的序列数据，我们使用三维输入表示：
- en: (*B*,*T*,*D*)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: (*B*,*T*,*D*)
- en: As before, B tells us how many items in a batch (i.e., how many data points)
    we will use. T gives us the total number of time steps, and D is how many features
    are present per time step. Because time is represented in the tensor object itself,
    it’s easy to specify the model.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，B告诉我们一个批次中有多少项（即有多少数据点）。T给出了总的时间步数，D是每个时间步的特征数量。因为时间在张量对象本身中表示，所以指定模型很容易。
- en: 'Let’s start by creating a many-to-one classification problem. What do I mean
    by this? We will have many inputs (every time step), but we will have only *one*
    output: the class label we are trying to predict.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先从一个多对一分类问题开始。我这是什么意思？我们将有多个输入（每个时间步），但我们将只有一个输出：我们试图预测的类别标签。
- en: 4.2.1  A simple sequence classification problem
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1  一个简单的序列分类问题
- en: 'To create a model, we first need data. This gets us to step 1 of figure 4.8\.
    To keep things simple, we will borrow the task from the PyTorch RNN tutorial ([http://mng.bz/nrKK](http://mng.bz/nrKK)):
    identifying the language a name comes from. For example, “Steven” is an English
    name. Note that this problem can’t be solved perfectly—for example, “Frank” could
    be English or German—so we should expect some errors due to these issues and oversimplification.
    Our goal is to make code that embodies the process shown in figure 4.9.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个模型，我们首先需要数据。这使我们到达图4.8的第1步。为了简化问题，我们将从PyTorch RNN教程（[http://mng.bz/nrKK](http://mng.bz/nrKK)）中借用任务：识别一个名称来自哪种语言。例如，“Steven”是一个英文名字。请注意，这个问题不能完美解决——例如，“Frank”可能是英语或德语——因此我们应该预期由于这些问题和过度简化而出现一些错误。我们的目标是编写体现图4.9中所示过程的代码。
- en: '![](../Images/CH04_F09_Raff.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F09_Raff.png)'
- en: Figure 4.9 RNN process for classifying a name's source language. The individual
    characters of a name make the sequence that is fed into the RNN. We learn how
    to convert each character into a vector and how to get an RNN to process that
    sequence and return a final activation **h**[T], and we end with a linear layer
    that produces a prediction.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9 RNN处理分类名称来源语言的过程。名称的各个字符构成了输入到RNN的序列。我们学习如何将每个字符转换为向量，以及如何让RNN处理该序列并返回最终的激活**h**[T]，最后通过一个线性层产生预测。
- en: 'The following code downloads the dataset and extracts all the files. Once complete,
    the folder structure is names/[LANG].txt, where [LANG] indicates the language
    (which is also the label for this problem), and the content of the text file is
    a list of names that occur in that language:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码下载数据集并提取所有文件。完成后，文件夹结构为names/[LANG].txt，其中[LANG]表示语言（也是此问题的标签），文本文件的内容是该语言中出现的所有名称列表：
- en: '[PRE7]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Since this dataset is pretty small, we load all of it into memory. The data
    is stored in a dictionary `namge_language_data`, which maps the language name
    (e.g., English) to a list of all the names. To simplify our lives, `unicodeToAscii`
    removes non-ASCII characters from each name. The dictionary `alphabet` contains
    all the characters we expect to see and *maps every item to a unique integer*,
    starting from 0 and increasing sequentially. This is important. Our computers
    have no idea what any character or item in your sequence means. Unless your data
    naturally exists as numeric values (e.g., the temperature outside), a conversion
    step is needed. We get to *how* that conversion is done in a moment, but we standardize
    this process by mapping every unique item that may occur in a sequence to a unique
    integer value.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个数据集相当小，我们将所有数据加载到内存中。数据存储在字典`namge_language_data`中，它将语言名称（例如，英语）映射到所有名称的列表。为了简化我们的生活，`unicodeToAscii`从每个名称中删除非ASCII字符。字典`alphabet`包含我们期望看到的所有字符，并将每个项目映射到一个唯一的整数，从0开始，依次递增。这很重要。我们的计算机不知道你的序列中的任何字符或项目代表什么。除非你的数据自然存在为数值（例如，外面的温度），否则需要一个转换步骤。我们稍后会了解到这个转换是如何进行的，但我们通过将序列中可能出现的每个唯一项目映射到一个唯一的整数值来标准化这个过程。
- en: 'Here’s the code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是代码：
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '❶ Removes UNICODE tokens to make life easy for us processing-wise: e.g., converts
    “Ślusàrski” to “Slusarski"'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 移除UNICODE标记以简化我们的处理工作：例如，将“Ślusàrski”转换为“Slusarski"
- en: ❷ Turns a Unicode string into plain ASCII
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将Unicode字符串转换为纯ASCII
- en: ❸ Loops through every language, opens the zip file entry, and reads all the
    lines from the text file
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 遍历每种语言，打开zip文件条目，并读取文本文件中的所有行
- en: ❹ Prints out the name of each language
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 打印出每种语言的名称
- en: 'Now we have created a dataset, which you may notice is not well balanced: there
    are *far* more Russian names than any other language. This is something we should
    be on the lookout for when evaluating our model.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了一个数据集，你可能注意到它并不平衡：俄罗斯语名称比其他任何语言都要多得多。这是我们评估模型时应该注意的事情。
- en: 'With our data loaded in memory, we can now implement a `Dataset` to represent
    it. The `data` list contains each name, and an associated index in the `labels`
    list indicates which language the name came from. A `vocabulary` dictionary maps
    every unique item to an integer value:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据加载到内存中后，我们现在可以实施一个`Dataset`来表示它。`data`列表包含每个名称，以及与`labels`列表中关联的索引，指示名称来自哪种语言。一个`vocabulary`字典将每个唯一项目映射到一个整数值：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ How many characters long is the string?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 字符串有多长？
- en: ❷ Creates a new tensor to store the result
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建一个新的张量来存储结果
- en: ❸ Iterates through the string and places the appropriate values in the tensor
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 遍历字符串并在张量中放置适当的值
- en: ❹ Converts the correct class label into a tensor for PyTorch
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将正确的类别标签转换为PyTorch的张量
- en: Note The concept of a vocabulary is common in machine learning and deep learning.
    You will often see the math symbol Σ used to denote the vocabulary. For example,
    we could ask, “Is the word *cheese* in the vocabulary?” more succinctly by writing
    “cheese" ∈ *Σ*. If we write “blanket" ∉ *Σ*, we are indicating that the item “blanket”
    is not in the vocabulary. We can also denote the size of the vocabulary using
    |*Σ*|.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：词汇表的概念在机器学习和深度学习中很常见。你经常会看到用数学符号Σ来表示词汇表。例如，我们可以更简洁地询问“单词*cheese*是否在词汇表中？”通过写作“cheese"
    ∈ *Σ*。如果我们写“blanket" ∉ *Σ*，我们表示“blanket”这个项目不在词汇表中。我们还可以使用|*Σ*|来表示词汇表的大小。
- en: 'The `__len__` function is straightforward: it returns the total number of data
    points in the `Dataset`. The first interesting function is the helper function
    `string2InputVec`, which takes an `input_string` and returns a new `torch.Tensor`
    as the output. The tensor’s length is the number of characters as the `input_string`,
    and it has the `torch.long` type (also known as `torch.int64`). The values in
    the tensor indicate which unique token was present in the `input_string` and their
    order. This gives us a new tensor-based representation that PyTorch can use.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`__len__`函数很简单：它返回`Dataset`中的数据点总数。第一个有趣的功能是辅助函数`string2InputVec`，它接受一个`input_string`并返回一个新的`torch.Tensor`作为输出。张量的长度是`input_string`中的字符数，并且它具有`torch.long`类型（也称为`torch.int64`）。张量中的值指示`input_string`中存在哪些唯一的标记及其顺序。这为我们提供了一个基于张量的新表示，PyTorch可以使用它。'
- en: This `string2InputVec` is then reused in our `__getitem__` method. We grab the
    original string from the `self.data[idx]` member and convert it into the tensor
    representation PyTorch needs using `string2InputVec`. The returned value is a
    tuple following the pattern (input,output). For example,
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在`__getitem__`方法中重用`string2InputVec`。我们从`self.data[idx]`成员中获取原始字符串，并使用`string2InputVec`将其转换为PyTorch需要的张量表示。返回的值是一个遵循（输入，输出）模式的元组。例如，
- en: '[PRE10]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: indicates that a name with six characters should be classified as the first
    class (Arabic). The original string was converted to a tensor of integers by our
    `string2InputVec` function so that PyTorch can understand it.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表示一个六字符的名称应被分类为第一类（阿拉伯语）。原始字符串通过我们的`string2InputVec`函数转换为整数张量，以便PyTorch可以理解它。
- en: 'With that, we can create a new dataset to determine the language of a given
    name. The following code snippet creates a train/test split, with 300 items in
    the test split. We use a batch size of 1 in the loaders (we come back to this
    nuance later in the chapter):'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们可以创建一个新的数据集来确定给定名称的语言。以下代码片段创建了一个训练/测试分割，测试分割中有300个项目。我们在加载器中使用批量大小为1（我们将在本章后面回到这个细节）：
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Stratified sampling for class imbalance
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对类别不平衡进行分层抽样
- en: Our dataset has an issue of *class imbalance* that we are not tackling at the
    moment. This occurs when the ratio of classes is uneven. In this setting, the
    model may sometimes learn to simply reiterate the most common class label. For
    example, imagine you are trying to predict whether someone has cancer. You can
    make a model that is 99.9% accurate by *always* predicting “no cancer,” because,
    thankfully, most people do not have cancer at a given moment in time. But this
    approach is not useful for a model.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据库存在一个*类别不平衡*的问题，我们目前没有解决。当类别的比例不均匀时，这种情况会发生。在这种情况下，模型可能会学会简单地重复最常见的类别标签。例如，想象你正在尝试预测某人是否患有癌症。你可以创建一个模型，该模型总是预测“没有癌症”，因为幸运的是，大多数人在某个时刻没有癌症。但这种方法对模型来说没有用。
- en: Solving class imbalance is its own niche topic area, and we will not go into
    much detail about it. But one simple improvement is to use *stratified* sampling
    to create the train/test split. It’s a common tool and available in scikit-learn
    ([http://mng.bz/v4VM](http://mng.bz/v4VM)). The idea is that you want to *force*
    the sampling to maintain the class ratios in the splits. So if the original data
    is 99% A and 1% B, you want your stratified splits to have the same percentages.
    With random sampling, you could easily end up with 99.5% A and 0.5% B. Normally,
    this is not a huge issue, but class imbalance can significantly skew your perception
    of how well a model is doing.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 解决类别不平衡是一个独立的主题领域，我们不会深入探讨。但一个简单的改进是使用*分层*抽样来创建训练/测试分割。这是一个常见的工具，在scikit-learn中可用([http://mng.bz/v4VM](http://mng.bz/v4VM))。想法是*强制*抽样以保持分割中的类别比例。所以如果原始数据是99%
    A和1% B，你希望你的分层分割有相同的百分比。使用随机抽样，你可能会轻易地得到99.5% A和0.5% B。通常，这不是一个大问题，但类别不平衡可能会显著扭曲你对模型表现好坏的看法。
- en: With the dataset loaded, we can talk about the remaining parts of our RNN model
    in PyTorch.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集加载完成后，我们可以讨论PyTorch中RNN模型的其余部分。
- en: 4.2.2  Embedding layers
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.2 嵌入层
- en: Step 1 of figure 4.8 requires us to represent the input sequence as a sequence
    of vectors. We have the `LanguageNameDataset` object to load our data, which converts
    each character/token (e.g., “Frank”) to a unique integer using a vocabulary (Σ).
    The last thing we need is a way to map each integer to a corresponding vector,
    which is accomplished using an *embedding* layer. This is shown at a high level
    in figure 4.10\. Note that this is standard terminology used in the deep learning
    community, and you should become familiar with it.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8的第1步要求我们将输入序列表示为向量序列。我们有`LanguageNameDataset`对象来加载数据，它使用词汇表(Σ)将每个字符/标记（例如，“Frank”）转换为唯一的整数。我们还需要一种将每个整数映射到相应向量的方法，这可以通过嵌入层来实现。这在图4.10中从高层次上展示了这一点。请注意，这是深度学习社区中使用的标准术语，你应该熟悉它。
- en: '![](../Images/CH04_F10_Raff.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F10_Raff.png)'
- en: Figure 4.10 Subsets (a) and (b) are both accomplished by the `LanguageNameDataset`
    we have implemented. The final subset (c) is done by an `nn.Embedding` layer.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.10的子集(a)和(b)都是通过我们实现的`LanguageNameDataset`完成的。最后的子集(c)是通过一个`nn.Embedding`层完成的。
- en: Embedding layers are lookup tables designed to map each integer value to a specific
    vector representation. You tell the embedding layer how large the vocabulary is
    (i.e., how many unique items exist) and how large you want the output dimension
    to be. Figure 4.11 shows how this process works at a conceptual level.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入层是查找表，用于将每个整数值映射到特定的向量表示。你告诉嵌入层词汇量的大小（即有多少个唯一项）以及你希望输出维度的大小。图4.11展示了这一过程在概念层次上的工作方式。
- en: '![](../Images/CH04_F11_Raff.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F11_Raff.png)'
- en: Figure 4.11 Embedding layer designed to take in a vocabulary of five unique
    items. You have to write the code that maps objects (like strings) into integers.
    The embedding maps each integer to its own d-dimensional vector **x** ∈ ℝ^d.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11 设计的嵌入层，用于接受五个独特项的词汇表。你必须编写将对象（如字符串）映射到整数的代码。嵌入将每个整数映射到其自己的d维向量 **x** ∈
    ℝ^d。
- en: In this toy example, the vocabulary contains both characters and words. The
    vocabulary does not need to be strings, as long as you can consistently map the
    items to an integer value. `nn.Embedding`’s first argument is `5` to indicate
    that the vocabulary has five unique items. The second argument `3` is the output
    dimension. You should think of this like the `nn.Linear` layer, where the second
    argument tells you how many outputs will exist. We can increase or decrease the
    output size based on how much information we think the model needs to be able
    to pack into each vector. In most applications, you want to try values in the
    range of [64,256] for the number of output dimensions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个玩具示例中，词汇表包含字符和单词。只要你能一致地将项目映射到整数值，词汇表就不需要是字符串。`nn.Embedding` 的第一个参数是 `5`，表示词汇表有五个唯一项。第二个参数
    `3` 是输出维度。你应该把它想象成 `nn.Linear` 层，其中第二个参数告诉你会有多少个输出。我们可以根据我们认为模型需要将多少信息打包到每个向量中来增加或减少输出大小。在大多数应用中，你希望尝试输出维度的值在
    [64,256] 范围内。
- en: Egad, embeddings everywhere!
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀，到处都是嵌入！
- en: Embeddings as a concept are highly leveraged in practical work. Mapping each
    word to a vector and trying to predict nearby words is the essence behind ubiquitous
    tools like word2vec ([https://en.wikipedia.org/wiki/Word2vec](https://en.wikipedia.org/wiki/Word2vec))
    and Glove ([https://nlp.stanford.edu/projects/glove](https://nlp.stanford.edu/projects/glove)),
    but that goes down a deeper rabbit hole about natural language processing than
    we have time for. In short, learning to represent items as vectors so that you
    can use other tools is an effective approach to tackle real-world problems.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种概念，嵌入在实用工作中被高度利用。将每个单词映射到向量并尝试预测附近的单词是像 word2vec ([https://en.wikipedia.org/wiki/Word2vec](https://en.wikipedia.org/wiki/Word2vec))
    和 Glove ([https://nlp.stanford.edu/projects/glove](https://nlp.stanford.edu/projects/glove))
    这样的通用工具背后的本质，但这涉及到比我们时间允许的更深入的自然语言处理领域。简而言之，学习将项目表示为向量以便使用其他工具是解决现实世界问题的有效方法。
- en: Once you have embeddings, you can use a nearest-neighbor search to implement
    a search engine or “did you mean” functionality, throw them into Uniform Manifold
    Approximation and Projection (UMAP) ([https://umap-learn.readthedocs.io/en/latest](https://umap-learn.readthedocs.io/en/latest))
    for visualization, or run your favorite non-deep algorithm to do some prediction
    or clustering. At other points in the book, I’ll note approaches that can be used
    to create embeddings.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了嵌入，你可以使用最近邻搜索来实现搜索引擎或“你是指”功能，将它们投入 Uniform Manifold Approximation and Projection
    (UMAP) ([https://umap-learn.readthedocs.io/en/latest](https://umap-learn.readthedocs.io/en/latest))
    进行可视化，或者运行你喜欢的非深度算法来进行预测或聚类。在本书的其他地方，我会指出可以用来创建嵌入的方法。
- en: 'The `nn.Embedding` layer is designed to work with sequences of things. That
    means the sequence can contain repetitions. For example, the following code snippet
    creates a new input sequence with *T* = 5 items but a vocabulary of only 3 items.
    This is OK because the input sequence [0,1,1,0,2] has repetitions (0 and 1 occur
    twice). The `embd` object is created with a dimension of *d* = 2 and processes
    the input to create a new representation `x_seq`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`nn.Embedding` 层被设计用来处理一系列的事物。这意味着序列可以包含重复项。例如，以下代码片段创建了一个新的输入序列，包含 *T* = 5
    个项目，但词汇量只有 3 个项目。这是可以的，因为输入序列 [0,1,1,0,2] 包含重复项（0 和 1 出现了两次）。`embd` 对象的维度为 *d*
    = 2，并处理输入以创建新的表示 `x_seq`：'
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This `x_seq` is the tensor representation that is now compatible with all the
    standard tools of deep learning. Notice that its shape is (5,2), with random values
    filled in—that’s because the `Embedding` layer initializes everything to random,
    and these values are altered by gradient descent as the network is trained. But
    the first and fourth rows of the matrix have the same values, as do the second
    and third. This is because the order in the output matches the order in the input.
    The unique item denoted by “0” was at the first and fourth positions, so the same
    vector is used in both places. The same is true for the unique item denoted by
    “1,” which is repeated as the second and third items.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 `x_seq` 是与所有深度学习标准工具兼容的张量表示。请注意，其形状为 (5,2)，填充了随机值——这是因为 `Embedding` 层将所有内容初始化为随机值，这些值在网络训练过程中通过梯度下降被改变。但是矩阵的第一行和第四行具有相同的值，第二行和第三行也是如此。这是因为输出的顺序与输入的顺序相匹配。标记为“0”的唯一项位于第一行和第四行，所以这两个地方使用了相同的向量。对于标记为“1”的唯一项，它作为第二项和第三项重复。
- en: When working with strings or any other content that does not naturally exist
    as vectors, you almost always want to use an embedding layer as your first step.
    This is the standard tool for converting these abstract concepts to representations
    we can work with and completes step 1 of figure 4.8.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理字符串或任何其他不自然存在为向量的内容时，你几乎总是想要使用嵌入层作为第一步。这是将这些抽象概念转换为我们可以处理表示的标准工具，并完成了图4.8的第1步。
- en: 4.2.3  Making predictions using the last time step
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.3 使用最后一个时间步进行预测
- en: The task of using an RNN in PyTorch is quite easy, as PyTorch provides implementations
    of the standard RNN algorithm. The trickier part is extracting the last time step
    **h**[T] after it’s processed by the RNN. We want to do this because the last
    time step is the *only* one that carries information from all T inputs based on
    the input’s order. This way, we can use **h**[T] as a fixed-length summary of
    the input data for a fully connected sub-network. This works because **h**[T]
    has the same shape and size no matter how long the input sequence is. So if our
    RNN layer has 64 neurons, **h**[T] will be a 64-dimension vector represented as
    a tensor of shape (*B*,64). It does not matter if our sequence has one item *T*
    = 1 or *T* = 100 items; it will always be the case that **h**[T] will have shape
    (*B*,64). This process is shown in figure 4.12.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch中使用RNN的任务相当简单，因为PyTorch提供了标准RNN算法的实现。更困难的部分是在RNN处理之后提取最后一个时间步 **h**[T]。我们想要这样做是因为最后一个时间步是*唯一*一个基于输入顺序从所有T个输入中携带信息的时间步。这样，我们可以使用
    **h**[T] 作为全连接子网络的固定长度摘要。这是因为 **h**[T] 无论输入序列有多长，都具有相同的形状和大小。所以如果我们的RNN层有64个神经元，**h**[T]
    将是一个64维向量，表示为形状为(*B*,64)的张量。无论我们的序列有一个项目 *T* = 1 或 *T* = 100个项目，**h**[T] 总是具有形状(*B*,64)。这个过程在图4.12中展示。
- en: '![](../Images/CH04_F12_Raff.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F12_Raff.png)'
- en: Figure 4.12 Parts of applying a RNN to predict a label for a sequence. The output
    of the RNN is a sequence of hidden states *h*[1], *h*[2], …, *h*[T]. The last
    time step *h*[T] contains information about the entire sequence, so we want to
    use it as a representation for the whole sequence. That way, it can go into a
    normal fully connected network *f*(⋅).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 展示了将RNN应用于预测序列标签的部分。RNN的输出是一个隐藏状态序列 *h*[1], *h*[2], …, *h*[T]。最后一个时间步
    *h*[T] 包含了整个序列的信息，因此我们希望将其用作整个序列的表示。这样，它就可以进入一个普通的完全连接网络 *f*(⋅)。
- en: 'We need to implement a new `Module` that extracts the last time step before
    we can specify a RNN architecture in PyTorch. There are a few idiosyncrasies to
    deal with in how PyTorch stores this information. We need to know two things:
    the number of layers and whether the model is bidirectional. This is because the
    RNN will return enough information to extract the result from any layer, giving
    us the flexibility to implement other models that we will discuss later. We also
    talk about what *bidirectional* means later in this chapter.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以指定PyTorch中的RNN架构之前，我们需要实现一个新的`Module`来提取最后一个时间步。在PyTorch中存储此类信息时，我们需要处理一些特殊之处。我们需要知道两件事：层数和模型是否为双向。这是因为RNN将返回足够的信息从任何层提取结果，这为我们提供了实现其他模型的灵活性，我们将在后面的章节中讨论。我们也会在本章后面讨论*双向*的含义。
- en: 'The following code is based on content from PyTorch’s documentation and does
    the work to extract the `LastTimeStep` **h**[T] from a RNN. Depending on the specific
    RNN we use (more on that in chapter 6), the output of an RNN `Module` is a tuple
    of two tensors or a nested tuple of three tensors, with the last time step’s activation
    stored in the second item of the tuple:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码基于PyTorch文档的内容，并执行从RNN中提取`LastTimeStep` **h**[T]的工作。根据我们使用的具体RNN（更多内容将在第6章中讨论），RNN
    `Module`的输出是一个包含两个张量的元组或一个包含三个张量的嵌套元组，最后一个时间步的激活存储在元组的第二个位置：
- en: '[PRE13]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Result is either a tuple (out,*h*[t]) or a tuple (out, (*h*[t], *c*[t]))
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 结果是一个元组（out, *h*[t]) 或者一个元组（out, (*h*[t], *c*[t]))
- en: ❶ This is *h*[t] unless it’s a tuple, in which case it’s the first item in the
    tuple.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这通常是 *h*[t]，除非它是一个元组，在这种情况下，它是元组的第一个项目。
- en: ❷ Per the docs, shape is ‘(num_layers * num_directions, batch, hidden_size)’
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 根据文档，形状是‘(num_layers * num_directions, batch, hidden_size)’
- en: ❸ Reshapes so everything is separate
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 重新塑形，使所有内容都分开
- en: ❹ We want the last layer’s results.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 我们想要最后一个层的输出。
- en: ❺ Reorders so the batch comes first
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 重新排序，使批次排在前面
- en: ❻ Flattens the last two dimensions into one
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 将最后两个维度展平为一个维度
- en: The output of a RNN in PyTorch is a tuple of shape (*out*,**h**[T]) or (*out*,(**h**[T],**c**[T])).
    The out object has information about *every* time step, and **h**[T] contains
    information about only the *last* time step but for *every* layer. So we check
    if the second item is a `tuple` and extract the right **h**[T] object. The value
    **c**[T] is an extract context tensor, which is part of a more advanced RNN that
    we discuss in chapter 6.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch中RNN的输出是一个形状为(*out*,**h**[T])或(*out*,(**h**[T],**c**[T]))的元组。out对象包含关于*每个*时间步的信息，而**h**[T]只包含关于*最后一个*时间步但针对*每个*层的信息。因此，我们检查第二个元素是否为`tuple`，并提取正确的**h**[T]对象。**c**[T]是一个提取的上下文张量，它是我们在第6章中讨论的更高级RNN的一部分。
- en: Once we have **h**[T], PyTorch provides it as an input that has been `flatten()`ed.
    We can use the `view` function to reshape the tensor with information about the
    layers, bidirectional content (again, we will talk about that soon), batch size,
    and number of neurons d in the hidden layer. We know we want the last layer’s
    results so we can index in and then use the `permute` function to move the batch
    dimension to the front.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了**h**[T]，PyTorch会将其作为`flatten()`过的输入提供。我们可以使用`view`函数来重塑包含层信息、双向内容（我们很快会讨论这一点）、批大小以及隐藏层中神经元的数量d的张量。我们知道我们想要最后一层的输出，所以我们可以索引并使用`permute`函数将批维度移到前面。
- en: 'That gives us what we need to extract the last layer of a RNN so we have the
    tools to implement steps 2 and 3 from figure 4.8\. The fourth step is to use a
    fully connected layer, which we already know how to do using a `nn.Linear` layer.
    The following code does the work of all four steps. The variable `D` is the size
    of the `nn.Embedding` result, `hidden_nodes` is the number of neurons in the RNN,
    and `classes` is the number of classes we are trying to predict (in this application,
    the number of different languages a name may have come from):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了提取RNN最后一层所需的内容，因此我们有了实现图4.8中的步骤2和3的工具。第四步是使用全连接层，我们已知如何使用`nn.Linear`层来完成这项工作。以下代码完成了所有四个步骤的工作。变量`D`是`nn.Embedding`结果的大小，`hidden_nodes`是RNN中的神经元数量，`classes`是我们试图预测的类的数量（在这个应用中，一个名字可能来自的不同语言的数量）：
- en: '[PRE14]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ (B, T) -> (B, T, D)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ (B, T) -> (B, T, D)
- en: ❷ (B, T, D) -> ( (B,T,D) , (S, B, D) )
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ (B, T, D) -> ( (B,T,D) , (S, B, D) )
- en: ❸ The tanh activation is built into the RNN object, so we don’t need to do it
    here. We take the RNN output and reduce it to one item, (B, D).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 双曲正切激活函数内置在RNN对象中，所以我们在这里不需要做。我们取RNN输出并将其减少到一个项目，(B, D)。
- en: ❹ (B, D) -> (B, classes)
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ (B, D) -> (B, classes)
- en: When working with RNNs, we often have a lot of complex tensor shapes occurring
    at once. For this reason, I always include a comment on each line indicating how
    the tensor shapes are changing due to each operation. The input batch is processing
    B items with a length of up to T, so the input has a shape of (*B*,*T*). The `nn.Embedding`
    layer converts this to a shape of (*B*,*T*,*D*), adding the `D` dimensions from
    the embedding.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当与RNN一起工作时，我们经常同时遇到许多复杂的张量形状。因此，我总是在每一行上包含一个注释，说明由于每个操作，张量形状是如何变化的。输入批处理B个长度最多为T的项目，因此输入的形状为(*B*,*T*)。`nn.Embedding`层将其转换为(*B*,*T*,*D*)的形状，添加了来自嵌入的`D`维度。
- en: The RNN takes inputs of shape (*B*,*T*,*D*) only if we specify that `batch_first=True`.
    While the rest of PyTorch assumes batch first, RNNs and sequence problems often
    assume that the batch dimension comes third. In early implementations, having
    the tensors shaped this way made them significantly faster due to low-level technical
    details that we are not going to get into. While that representation order can
    still be faster, the gap is not as big today. So, I prefer to use the `batch_first`
    option to make it more consistent with the rest of PyTorch.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当我们指定`batch_first=True`时，RNN才接受形状为(*B*,*T*,*D*)的输入。虽然PyTorch的其余部分假设批首先，但RNN和序列问题通常假设批维度是第三个。在早期实现中，以这种方式排列张量由于底层技术细节而使它们显著更快，这些细节我们不会深入讨论。虽然这种表示顺序仍然可能更快，但差距今天已经不那么大了。因此，我更喜欢使用`batch_first`选项，使其与PyTorch的其余部分更一致。
- en: Note The RNN classes in PyTorch apply nonlinear activation functions on their
    own. They are implicit in this case. This is another situation where the behavior
    of PyTorch for RNNs is different from the rest of the framework. For this reason,
    you should *not* apply a nonlinear activation function afterward, because it has
    already been done for you.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：PyTorch中的RNN类会自行应用非线性激活函数。在这种情况下是隐式的。这是PyTorch对RNN的行为与框架其余部分不同的另一个情况。因此，你*不应该*之后应用非线性激活函数，因为它已经为你完成了。
- en: 'The RNN returns a `tuple` of at least two tensors, but our `LastTimeStep` module
    is designed to take this and return a fixed-length vector by extracting *h*[T]
    from the last time step. Since *h*[T] ∈ ℝ^D and we are processing B items in a
    batch, that gives us a tensor of shape (*B*,*D*). This is the same shape that
    our fully connected networks expect. That means we can now use standard fully
    connected layers. In this case, we can use one to create a linear layer that makes
    the final prediction. With that, we can again use the `train_simple_network` function
    to train our first RNN:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: RNN返回至少包含两个张量的`tuple`，但我们的`LastTimeStep`模块被设计为从这个`tuple`中提取最后一个时间步的*h*[T]，并返回一个固定长度的向量。由于*h*[T]
    ∈ ℝ^D，并且我们在处理B个批次的物品，这给我们一个形状为(*B*,*D*)的张量。这与我们的全连接网络期望的形状相同。这意味着我们现在可以使用标准的全连接层。在这种情况下，我们可以使用一个来创建一个线性层，进行最终的预测。有了这个，我们再次可以使用`train_simple_network`函数来训练我们的第一个RNN：
- en: '[PRE15]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](../Images/CH04_UN03_Raff.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_UN03_Raff.png)'
- en: 'Now that we have trained our model, we can play around with it. Let’s try typing
    in a few names and see what the model thinks of them. Remember, we converted all
    names to lowercase, so don’t use any capital letters:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练了我们的模型，我们可以对其进行一些实验。让我们尝试输入几个名字，看看模型对它们的看法。记住，我们将所有名字都转换为小写，所以不要使用任何大写字母：
- en: '[PRE16]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: For a name like “Frank,” we get the largest response for English and German
    as the source languages, both of which are reasonable answers. Frank is a common
    name in English and has German origins. You should try other names yourself and
    see how the behavior changes. This also shows how we can apply our RNN to variable-length
    inputs. Regardless of the length of the input string, you still get a prediction
    at the end, whereas in our previous examples with fully connected or convolutional
    layers, the input had to *always* be the same size. This is one of the reasons
    we use RNNs is to resolve these kinds of issues.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像“Frank”这样的名字，我们得到的最大响应是英语和德语作为源语言，这两个答案都是合理的。Frank在英语中是一个常见的名字，并且有德国血统。你可以尝试其他名字，看看行为如何变化。这也展示了我们可以如何将我们的RNN应用于变长输入。无论输入字符串的长度如何，你最终都会得到一个预测，而在我们之前的例子中，使用全连接或卷积层时，输入必须*始终*是相同的大小。这就是我们使用RNN的原因之一，以解决这类问题。
- en: A note about classification and ethics
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 关于分类和伦理的注意事项
- en: The example we have been working with is an oversimplification of reality. Names
    do not necessarily come from *one* specific language, which our model implies
    because each name is labeled with one correct answer. This is an example of our
    model simplifying the world to make our lives as modelers easier.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在使用的例子是对现实的过度简化。名字不一定来自*一个*特定的语言，这是我们的模型暗示的，因为每个名字都被标记为一个正确的答案。这是我们模型简化世界以使我们的建模生活更容易的一个例子。
- en: This is a good, if simplified, example to learn on, but it also presents a good
    opportunity to talk about some of the ethics involved in machine learning. Simplifying
    assumptions can be useful and help solve real problems, but they can also alter
    how you think about the problem and how the eventual users of your model think
    about the world. For this reason, you should note why you make these assumptions
    when modeling, what the model is for, and how it is validated. These are often
    called *model cards*.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的、如果简化了的话，可以学习的例子，但它也提供了一个很好的机会来讨论机器学习中涉及的一些伦理问题。简化的假设可能是有用的，并有助于解决实际问题，但它们也可能改变你对问题的看法以及模型最终用户对世界的看法。因此，你应该注意在建模时为什么做出这些假设，模型是用来做什么的，以及它是如何得到验证的。这些通常被称为*模型卡片*。
- en: For example, imagine someone using our language model to try to determine a
    user’s background and alter content displayed based on their name. Would this
    be OK? Probably not. One name may come from several sources, and people form their
    identity in many ways other than their name and place of birth, so there is a
    good chance that using this model in such a scenario isn’t the best idea.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象一下有人使用我们的语言模型来尝试确定用户的背景，并根据他们的名字改变显示的内容。这可以吗？可能不行。一个名字可能来自多个来源，人们除了名字和出生地之外，还有许多其他方式来形成自己的身份，因此在这种情况下使用此模型可能不是最好的主意。
- en: Another common introductory problem is *sentiment classification*, where you
    attempt to determine whether a sentence or document is conveying a positive, negative,
    or neutral sentiment. This technique can be useful and valid. For instance, a
    food or beverage brand may want to monitor Twitter to see if people are mentioning
    products with a negative sentiment so that the company can investigate potential
    product failures or bad customer experiences. At the same time, positive, negative,
    and neutral are not the only sentiments, and a message can convey more complex
    thoughts. Consider making sure your users are aware of such limitations, and think
    about these kinds of choices. If you want to learn more about the ethics and impact
    of such decisions, Kate Crawford ([https://www.katecrawford.net](https://www.katecrawford.net))
    is an expert in this space who has some accessible readings on her website.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的入门级问题是*情感分类*，你试图确定一个句子或文档是否传达了积极、消极或中性的情感。这种技术可能是有用且有效的。例如，一个食品或饮料品牌可能希望监控Twitter，看看人们是否在提及带有负面情感的产品的提及，以便公司可以调查潜在的产品故障或不良客户体验。同时，积极、消极和中性并不是唯一的情感，一条信息可以传达更复杂的思想。请确保你的用户了解这些限制，并考虑这些选择。如果你想了解更多关于此类决策的伦理和影响，Kate
    Crawford ([https://www.katecrawford.net](https://www.katecrawford.net)) 是这个领域的专家，她在网站上提供了一些易于阅读的阅读材料。
- en: 4.3 Improving training time with packing
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 通过打包提高训练时间
- en: When building this model, we used a batch size of 1\. This is not a very efficient
    way to train a model. What happens if you change the batch size to 2? Go on, try
    it.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建这个模型时，我们使用了批次大小为1。这不是训练模型的一种非常有效的方式。如果你将批次大小改为2会发生什么？试试看。
- en: 'You should get an error message. The problem is that each name is a different
    length, so by default, it is very hard to represent as a tensor. Tensors need
    all dimensions to be consistent and the same, but our *time* dimension (in this
    case, how many characters long each name is) is not consistent. This is what causes
    the error: we have two different sequences with different lengths.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会收到一个错误信息。问题在于每个名称的长度不同，因此默认情况下，很难将其表示为张量。张量需要所有维度都一致且相同，但我们的*时间*维度（在这种情况下，每个名称的字符长度）是不一致的。这就是导致错误的原因：我们有两个不同长度的不同序列。
- en: We saw in chapter 2 that training on batches of data can reduce the training
    time significantly by making better use of our GPU’s compute, so we have a real
    reason to increase the batch size. Yet we appear to be stuck using an inefficient
    batch size of 1 due to inputs with differing sizes.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第二章中看到，通过更有效地利用我们的GPU计算能力，对数据批次进行训练可以显著减少训练时间，因此我们有充分的理由增加批次大小。然而，由于输入数据大小不同，我们似乎陷入了使用效率低下的批次大小为1的困境。
- en: This is an *abstraction* problem because fundamentally, nothing prevents an
    RNN from working with inputs of varying lengths of time. To fix this, PyTorch
    provides the *packed sequence* abstraction ([http://mng.bz/4KYV](http://mng.bz/4KYV)).
    All types of RNNs available in PyTorch support working on this class.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个*抽象*问题，因为从根本上讲，没有任何东西阻止RNN处理不同时间长度的输入。为了解决这个问题，PyTorch提供了*打包序列*抽象（[http://mng.bz/4KYV](http://mng.bz/4KYV)）。PyTorch中所有可用的RNN类型都支持在这个类上工作。
- en: Figure 4.13 shows conceptually what is happening when we pack six differentsequences
    of varying lengths. PyTorch organizes them by length and begins by including the
    *first* time step of all sequences in one *batch over time*. As time progresses,
    the shorter sequences reach their end, and the batch size is reduced to the number
    of sequences that have not reached their end.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13从概念上展示了当我们打包六个不同长度的不同序列时发生的情况。PyTorch根据长度组织它们，并首先将所有序列的第一个时间步包含在一个*时间批次*中。随着时间的推移，较短的序列达到其末尾，批次大小减少到尚未到达末尾的序列数量。
- en: '![](../Images/CH04_F13_Raff.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F13_Raff.png)'
- en: Figure 4.13 Example of packing a batch of five items with sequence lengths of
    3, 3, 4, 5, and 6\. For the first three steps, we process all five sequences.
    On the fourth step *t* = 4, two of the sequences have run out, so we drop them
    and continue the batch on only the sequences that have a length ≥ 4. Packing organizes
    the data by length to make this fast and efficient.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13打包长度为3、3、4、5和6的五个项目的示例。在前三个步骤中，我们处理所有五个序列。在第四步*t* = 4时，有两个序列已经结束，所以我们丢弃它们，并仅在长度≥4的序列上继续批次。打包根据长度组织数据，使其快速高效。
- en: 'Let’s talk through what is happening in this example. We are trying to train
    on a batch of five names: “ben,” “sam,” “lucy,” “frank,” and “edward.” The packing
    process has sorted them from shortest to longest. There will be a total of *T*
    = 6 steps in this sequence because “edward” is the longest name at six characters.
    This means our RNN will perform six iterations in total. Now let’s see what happens
    at each step:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过这个例子来谈谈正在发生的事情。我们正在尝试对一个包含五个名字的批次进行训练：“ben”、“sam”、“lucy”、“frank”和“edward”。打包过程已按长度从短到长对它们进行排序。在这个序列中总共有
    *T* = 6 个步骤，因为“edward”是最长的名字，有六个字符。这意味着我们的RNN总共将执行六次迭代。现在让我们看看每个步骤会发生什么：
- en: In the first iteration, all five items are processed together in one large batch.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次迭代中，所有五个项目作为一个大批次一起处理。
- en: All five items are again processed together in one large batch.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有五个项目再次作为一个大批次一起处理。
- en: All five items are again processed, but we have reached the end of the first
    two items, “ben” and “sam.” We record their final hidden states from *this* step
    **h**[3], since that’s when they were finished being processed.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有五个项目再次处理，但我们已经到达了前两个项目“ben”和“sam”的末尾。我们从*这个*步骤记录它们的最终隐藏状态**h**[3]，因为那时它们已经完成处理。
- en: A batch of only *three items* is processed, containing “lucy,” “frank,” and
    “edward,” because the first two items are done. PyTorch adaptively *shrinks* the
    effective batch size to what remains. “lucy” is finished, and its final state
    saved as **h**[4].
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅处理包含“lucy”、“frank”和“edward”的三个项目批次，因为前两个项目已经完成。PyTorch自适应地*缩小*有效批次大小到剩余的数量。“lucy”已完成，其最终状态保存为**h**[4]。
- en: A batch of only *two items* is processed. “frank” is finished after this step,
    so **h**[5] is saved for “frank.”
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅处理包含两个项目的批次。“frank”在此步骤后完成，因此**h**[5]为“frank”保存。
- en: 'The last step processes only one item, “edward,” bringing us to the end of
    the batch and the final hidden state: **h**[6].'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步只处理一个项目，“edward”，这使我们到达批次的末尾和最终的隐藏状态：**h**[6]。
- en: Processing this way ensures that we get the correct hidden state *h*[T] for
    each item even though they have different lengths. It also makes PyTorch run faster.
    We do more efficient batched computation as much as possible and shrink that batch
    as needed so we only work on the still-valid data.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式处理确保我们为每个项目获得正确的隐藏状态 *h*[T]，即使它们的长度不同。这也使PyTorch运行得更快。我们尽可能进行高效的批量计算，并在需要时缩小批次，这样我们只处理仍然有效的数据。
- en: 4.3.1  Pad and pack
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1  填充和打包
- en: 'Packing actually involves two steps: *padding* (make everything the same length)
    and *packing* (store information about how much padding was used). To implement
    both padding and packing, we need to override the *collate function* used by the
    `DataLoader`. This function’s job is to collate lots of independent data points
    into one larger batch of items. The default collate function can handle tensors
    as long as all tensors have the same shape. Our data comes in as a tuple (**x**[i],*y*[i])
    with shapes (*T*[i]) and (1), respectively. *T*[i] can be different for each item,
    which is normally a problem, so we need to define a new function called `pad_and_pack`.
    It’s a two-step process that is outlined in figure 4.14.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 打包实际上涉及两个步骤：*填充*（使所有内容长度相同）和*打包*（存储有关使用了多少填充的信息）。为了实现填充和打包，我们需要覆盖`DataLoader`使用的*collate函数*。这个函数的工作是将许多独立的数据点组合成一个更大的项目批次。默认的collate函数可以处理形状相同的张量。我们的数据以元组（**x**[i]，*y*[i]）的形式出现，形状分别为(*T*[i])和(1)。*T*[i]对于每个项目可能不同，这通常是一个问题，因此我们需要定义一个新的函数，称为`pad_and_pack`。它是一个两步过程，如图4.14所示。
- en: '![](../Images/CH04_F14_Raff.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F14_Raff.png)'
- en: Figure 4.14 Steps of packing and padding input so that an RNN can be trained
    on batches of data that have different lengths
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14打包和填充输入的步骤，以便在具有不同长度的数据批次上训练RNN
- en: 'The input is passed to our function as list objects. Every item in the tuple
    comes *directly* from the `Dataset` class. So if you alter the `Dataset` to do
    something unique, this is how you update the `DataLoader` to work with it. In
    our case, the `Dataset` returns a tuple of (input,output), so our `pad_and_pack`
    function takes in a list of tuples. The steps are as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 输入作为列表对象传递给我们的函数。元组中的每个项目都直接来自`Dataset`类。因此，如果您更改`Dataset`以执行独特操作，这就是如何更新`DataLoader`以与之一起工作。在我们的情况下，`Dataset`返回一个包含（输入，输出）的元组，因此我们的`pad_and_pack`函数接受一个元组列表。步骤如下：
- en: Store the length of every item.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存储每个项目的长度。
- en: Create new lists of *just* the inputs and *just* the output labels.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建只包含输入和只包含输出标签的新列表。
- en: Create a *padded* version of the input list. This makes all the tensors the
    same size, with a special token appended to the shorter items. PyTorch can do
    this using the `pad_sequence` function.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建输入列表的 *填充* 版本。这使得所有张量具有相同的大小，并在较短的项后面附加一个特殊标记。PyTorch可以使用 `pad_sequence` 函数来完成此操作。
- en: Create the *packed* version of the input using PyTorch’s `pack_padded_sequence`
    function. This takes the padded version as input, along with the list of lengths,
    so that the function knows how long each item was originally.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用PyTorch的 `pack_padded_sequence` 函数创建输入的 *打包* 版本。这个函数接受填充版本作为输入，以及长度列表，这样函数就知道每个项目最初有多长。
- en: 'That’s the high-level idea. The following code implements this process:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是高级概念。以下代码实现了这个过程：
- en: '[PRE17]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Organizes the batch input lengths, inputs, and outputs as separate lists
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将批输入长度、输入和输出组织为单独的列表
- en: ❷ Assumes shape is (T, *)
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 假设形状是 (T, *)
- en: ❸ Creates the padded version of the input
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建输入的填充版本
- en: ❹ Creates the packed version from the padded and lengths
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 从填充和长度创建打包版本
- en: ❺ Converts the lengths into a tensor
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将长度转换为张量
- en: ❻ Returns a tuple of the packed inputs and heir labels
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 返回一个包含打包输入及其标签的元组
- en: Notice two things about this code. First, we set an optional argument `batch_first=`
    `False` because our input data does not yet have a batch dimension; it just has
    the length. If we had a batch dimension, and it was stored as the first dimension
    (the norm for most code), we would set this value to `True`.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 注意关于此代码的两个要点。首先，我们设置了可选参数 `batch_first=` `False`，因为我们的输入数据还没有批维度；它只有长度。如果我们有一个批维度，并且它存储为第一个维度（大多数代码的规范），我们将此值设置为
    `True`。
- en: Second, for the packing step, we have the flag `enforce_sorted=False` because
    we have chosen not to presort the input batches by length. If we set `enforce_sorted=True`,
    we would get an error because our inputs are not sorted. Older versions of PyTorch
    required you to do this sorting yourself, but the current version works fine on
    unsorted inputs. It still avoids unnecessary computations and is generally just
    as fast, so we chose this easier option.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，对于打包步骤，我们设置了标志 `enforce_sorted=False`，因为我们选择不对输入批次按长度进行预排序。如果我们设置 `enforce_sorted=True`，我们会得到一个错误，因为我们的输入没有排序。PyTorch的旧版本要求你自己进行此排序，但当前版本可以在未排序的输入上正常工作。它仍然避免了不必要的计算，并且通常速度相同，所以我们选择了这个更简单的选项。
- en: 4.3.2  Packable embedding layer
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.2  可打包嵌入层
- en: 'We need one more item before we can build a RNN that can be trained in batches.
    It turns out the `nn.Embedding` layer from PyTorch does not handle packed inputs.
    I find it’s easiest to create a new wrapper `Module` that takes an `nn.Embedding`
    object in the constructor and fixes it to handle packed inputs. This is shown
    in the following code:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够构建一个可以批量训练的RNN之前，我们还需要一个额外的项目。结果是PyTorch的 `nn.Embedding` 层不能处理打包输入。我发现创建一个新的包装器
    `Module` 最为简单，该包装器在构造函数中接受一个 `nn.Embedding` 对象，并修复它以处理打包输入。这在上面的代码中显示：
- en: '[PRE18]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Unpacks the input
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 解包输入
- en: ❷ Embeds it
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 嵌入它
- en: ❸ Packs it into a new sequence
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将其打包到一个新的序列中
- en: ❹ Applies to normal data
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 适用于正常数据
- en: The first step is to check whether the input is a `PackedSequence`. If it is
    packed, we need to first *unpack* the input sequence. Now we have an unpacked
    tensor because either it was provided as unpacked or we unpacked it ourselves,
    so we can call the original `embd_layer` that we saved. Notice that because our
    data is a packed *batch* and the batch dimension is the *first* dimension, we
    have to set the `batch_first=True` flag. Unpacking gives us the original *padded*
    `sequences` as well as their respective `lengths`. The next line performs the
    standard embedding on the unpacked `sequences`, making sure to move the `sequences`
    to the same compute device that the original `input.data` was on. We call `pack_padded_sequence`
    to again create a packed version of the now-embedded inputs.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是检查输入是否为 `PackedSequence`。如果是打包的，我们需要首先 *解包* 输入序列。现在我们有一个解包的张量，因为它要么是作为解包提供的，要么是我们自己解包的，所以我们可以调用我们保存的原始
    `embd_layer`。请注意，因为我们的数据是一个打包的 *批次*，并且批次维度是 *第一个* 维度，我们必须设置 `batch_first=True`
    标志。解包会给我们原始的 *填充* `序列` 以及它们各自的 `长度`。下一行对解包的 `序列` 执行标准嵌入操作，确保将 `sequences` 移动到原始
    `input.data` 所在的相同计算设备。我们调用 `pack_padded_sequence` 再次创建现在已嵌入的输入的打包版本。
- en: 4.3.3  Training a batched RNN
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.3  训练批处理RNN
- en: 'With our `EmbeddingPackable` module in hand and our new collation function
    `pad_and_pack`, we are ready to train an RNN on batches of data at a time. First
    we need to create new `DataLoader` objects. This looks the same as previously,
    except that we specify the optional argument `collate_fn=pad_and_pack` so it uses
    the `pad_and_pack` function to create batches of training data:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有了`EmbeddingPackable`模块和新的`pad_and_pack`归一化函数，我们就可以准备批量训练RNN了。首先我们需要创建新的`DataLoader`对象。这看起来和之前一样，只是我们指定了可选参数`collate_fn=pad_and_pack`，以便它使用`pad_and_pack`函数创建训练数据批量：
- en: '[PRE19]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In this case, we have chosen to use a batch of 16 data points at a time. The
    next step is to define our new RNN module. We use the `nn.Sequential` to build
    our model out of the `EmbeddingPackable` to perform the embedding, `nn.RNN` to
    create a RNN layer, `LastTimeStep` to extract the final hidden states, and a `nn.Linear`
    to perform a classification based on the input:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们选择了一次使用16个数据点的批量。下一步是定义我们新的RNN模块。我们使用`nn.Sequential`从`EmbeddingPackable`构建模型，以执行嵌入，使用`nn.RNN`创建RNN层，使用`LastTimeStep`提取最终隐藏状态，并使用`nn.Linear`根据输入进行分类：
- en: '[PRE20]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ (B, T) -> (B, T, D)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ (B, T) -> (B, T, D)
- en: ❷ (B, T, D) -> ( (B,T,D) , (S, B, D) )
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ (B, T, D) -> ( (B,T,D) , (S, B, D) )
- en: ❸ Takes the RNN output and reduces it to one item, (B, D)
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将RNN输出减少到一个项目，(B, D)
- en: ❹ (B, D) -> (B, classes)
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ (B, D) -> (B, classes)
- en: 'Finally we can train this model. It works by calling our `train_simple_network`
    because we have abstracted all the issues of packing and padding into `collate_fn`
    and the `EmbeddingPackable` objects. Batch training is also much more efficient,
    so we train for 20 epochs—four times as many as before:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 最后我们可以训练这个模型。它通过调用我们的`train_simple_network`来工作，因为我们已经将打包和填充的所有问题抽象到`collate_fn`和`EmbeddingPackable`对象中。批量训练也更为高效，所以我们训练了20个epoch——是之前的四倍：
- en: '[PRE21]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: If we look at the accuracy of this model, it is overall very similar to the
    model trained with a batch size of 1, but perhaps a little worse. This is not
    unusual behavior for training a RNN—the weight sharing over time and multiple
    inputs can make it difficult to learn RNNs in general. For this reason, people
    often keep batch sizes for RNNs relatively smaller to improve performance, but
    in the next two chapters we’ll learn about techniques that help solve this problem.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看这个模型的准确率，它总体上与批量大小为1的训练模型非常相似，但可能略差。对于训练RNN来说，这种行为并不罕见——随着时间的推移和多个输入的权重共享可能会使学习RNN变得困难。因此，人们通常将RNN的批量大小保持相对较小以提高性能，但在接下来的两个章节中，我们将学习帮助解决这个问题的一些技术。
- en: 'Here’s the plot:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这是图表：
- en: '[PRE22]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](../Images/CH04_UN04_Raff.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_UN04_Raff.png)'
- en: 'However, this plot looks at performance as a function of *epoch*. By packing
    the data into a larger batch, it is *much* faster to train. If we look at accuracy
    as a function of the total time we had to wait, packing becomes much more competitive:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个图是查看性能作为*epoch*函数的。通过将数据打包到更大的批量中，训练速度要快得多。如果我们看准确率作为总等待时间的函数，打包变得更加具有竞争力：
- en: '[PRE23]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](../Images/CH04_UN05_Raff.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_UN05_Raff.png)'
- en: 4.3.4  Simultaneous packed and unpacked inputs
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.4  同时打包和未打包的输入
- en: 'The way we wrote our code has given us a sneaky but small benefit that makes
    the code more flexible for different scenarios. The RNN layers take in packed
    sequence objects *or* normal tensors. Our new `EmbeddingPackable` also supports
    both types of inputs. The `LastTimeStep` function we have been using always returns
    a normal tensor because there is no reason or value to the last time step being
    packed. For this reason, the same code we just wrote will work with *both* packed
    and non-packed inputs. We can confirm this by trying to see if we can predict
    the linguistic origin of some new names:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编写代码的方式给我们带来了一点点小的好处，这使得代码在不同场景下更加灵活。RNN层可以接受打包的序列对象*或*正常张量。我们新的`EmbeddingPackable`也支持这两种类型的输入。我们一直在使用的`LastTimeStep`函数总是返回一个正常张量，因为没有理由或价值将最后一步打包。因此，我们刚才编写的相同代码将适用于*打包和非打包*输入。我们可以通过尝试预测一些新名字的语言起源来确认这一点：
- en: '[PRE24]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This makes it easier to reuse the same code for both training (on a batch of
    data) and making predictions (where we may not want to wait for a batch of data).
    The code is also easier to reuse in other code that may or may not support packed
    inputs.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这样使得代码在训练（在数据批量上）和预测（我们可能不想等待数据批量）时更容易重用。代码在可能或可能不支持打包输入的其他代码中重用也更容易。
- en: 'This inconsistent support stems from RNNs and sequences being more complex
    to work with. We put in a lot of extra effort to get the code to work with batches
    of data, and much of the code online has not bothered to do so. When you learn
    about a new technique for training or using RNNs, it may not support packed inputs
    as this code does. By writing the code the way we did, you get the best of both
    worlds: faster batch training with standard tools, and compatibility with other
    tools that may not have put in the same effort.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这种不一致的支持源于 RNN 和序列处理起来更为复杂。我们投入了大量额外的工作来使代码能够处理数据批次，而网上许多代码并没有这样做。当你学习关于训练或使用
    RNN 的新技术时，它可能不支持像这个代码那样打包的输入。通过以我们这种方式编写代码，你可以获得两全其美的效果：使用标准工具进行更快的批量训练，并且与其他可能没有投入同样努力的工具兼容。
- en: 4.4 More complex RNNs
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 更复杂的 RNN
- en: 'More complex RNNs are available: in particular, we can make RNNs with multiple
    layers and RNNs that process information from right to left in addition to left
    to right. Both of these changes improve the accuracy of the RNN model. It may
    seem overwhelming that we have two new concepts to learn about with RNNs, but
    PyTorch makes both of them easy to add with minimal effort.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的 RNN 可用：特别是，我们可以创建具有多层和从右到左处理信息（除了从左到右）的 RNN。这两个变化都提高了 RNN 模型的准确率。虽然我们似乎有两个新的概念要学习关于
    RNN，但 PyTorch 使得这两个概念都很容易添加，只需付出最小的努力。
- en: 4.4.1  Multiple layers
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.1 多层
- en: Like other approaches we have learned about, you can stack multiple layers of
    RNNs. However, due to the computational complexity of training RNNs, PyTorch provides
    highly optimized versions. Rather than manually insert multiple `nn.RNN()` calls
    in a sequence, you can pass in an option telling PyTorch how many layers to use.
    Figure 4.15 shows a diagram of an RNN with two layers.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们学过的其他方法一样，你可以堆叠多个 RNN 层。然而，由于训练 RNN 的计算复杂性，PyTorch 提供了高度优化的版本。你不需要手动在序列中插入多个
    `nn.RNN()` 调用，而是可以传递一个选项来告诉 PyTorch 使用多少层。图 4.15 展示了一个具有两层 RNN 的示意图。
- en: '![](../Images/CH04_F15_Raff.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_F15_Raff.png)'
- en: Figure 4.15 Example of an RNN with two layers. The arrows show connections from
    one RNN cell to another. Blocks with the same color in a layer share weights.
    The input vectors come in from the bottom, and the last RNN’s output can go to
    a fully connected layer to produce a prediction.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15 展示了一个具有两层 RNN 的示例。箭头显示了从一层 RNN 单元到另一层的连接。同一层中颜色相同的块共享权重。输入向量从底部进入，最后一个
    RNN 的输出可以进入一个全连接层以产生预测。
- en: 'Adding multiple layers to a RNN repeats the pattern of hidden units taking
    input from the previous RNN at the *same* level and the result from the current
    time step from the *preceding* level. This is as simple as adding `num_layers=3`
    to our `RNN` and `LastTimeStep` objects if we want a model with three recurrent
    layers:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RNN 中添加多个层会重复隐藏单元从上一层的相同级别和当前时间步的上一级结果中获取输入的模式。如果我们想要一个具有三个循环层的模型，只需将 `num_layers=3`
    添加到我们的 `RNN` 和 `LastTimeStep` 对象中就足够简单了：
- en: '[PRE25]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: ❶ (B, T) -> (B, T, D)
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ (B, T) -> (B, T, D)
- en: ❷ (B, T, D) -> ( (B,T,D) , (S, B, D) )
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ (B, T, D) -> ( (B,T,D) , (S, B, D) )
- en: ❸ Takes the RNN output and reduces it to one item, (B, D)
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将 RNN 输出减少到一个项目，(B, D)
- en: ❹ (B, D) -> (B, classes)
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ (B, D) -> (B, classes)
- en: Plotting the accuracy of a three-layer approach shows that it *usually* performs
    better but generally not worse. Some of this again relates to the trickiness of
    RNNs. My recommendation is to look at using two or three layers of the recurrent
    components in your architecture. While more can do better, it becomes very expensive,
    and the difficulties of training RNNs can get in the way of gains from depth.
    We learn about other techniques that can give more of an advantage later in this
    book.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 绘制三层方法的准确率图表明，它通常表现更好，但通常不会更差。其中一些又与 RNN 的复杂性有关。我的建议是查看在架构中使用两到三层循环组件。虽然更多层可以做得更好，但它变得非常昂贵，并且训练
    RNN 的困难可能会阻碍深度带来的收益。我们将在本书的后面部分了解其他可以带来更多优势的技术。
- en: 'Here’s the plot:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是图表：
- en: '[PRE26]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](../Images/CH04_UN06_Raff.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH04_UN06_Raff.png)'
- en: 4.4.2  Bidirectional RNNs
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.2 双向 RNN
- en: A more sophisticated improvement is to create a *bidirectional* RNN. You may
    have noticed that our RNNs always go from left to right, but this can make learning
    challenging. What if the information we need occurs near the front of the input
    sequence? The RNN has to make sure information survives multiple time steps, where
    each time step is an opportunity for noise to be introduced or for other information
    to otherwise obscure the past.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 更高级的改进是创建一个 *双向* RNN。你可能已经注意到，我们的 RNN 总是从左到右进行，但这可能会使学习变得具有挑战性。如果我们需要的信息出现在输入序列的前面呢？RNN
    必须确保信息在多个时间步中存活，每个时间步都是引入噪声或使其他信息模糊过去的机会。
- en: A good way to think about why retaining information over time is difficult is
    to imagine an extreme scenario. Say you have only 32 neurons in your RNN layer,
    but the time series is *1 billion steps long*. The information in an RNN exists
    entirely within the universe of only 32 values, which is simply not enough to
    keep that information intact after a billion operations.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 要思考为什么保留信息随时间推移变得困难的一个好方法是通过想象一个极端场景。比如说，你的 RNN 层中只有 32 个神经元，但时间序列有 *10 亿步长*。RNN
    中的信息完全存在于只有 32 个值的宇宙中，这根本不足以在经过十亿次操作后保持该信息完整。
- en: To make it easier for the RNN to get the information it needs from long sequences,
    we can have the RNN traverse the input in *both* directions at once and *share*
    this information with the next layer of the RNN. This means at the second layer
    of the RNN, time step 1 has *some* information about time step T. Information
    about time accumulates more evenly through the RNN, which can make learning easier.
    The connections for this kind of RNN are shown in figure 4.16.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让 RNN 更容易地从长序列中获取所需信息，我们可以让 RNN 同时向两个方向遍历输入，并将这些信息与 RNN 的下一层共享。这意味着在 RNN 的第二层，时间步
    1 有关于时间步 T 的 *一些* 信息。信息在 RNN 中更均匀地积累，这可以使学习更容易。这种 RNN 的连接在图 4.16 中显示。
- en: '![](../Images/CH04_F16_Raff.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_F16_Raff.png)'
- en: 'Figure 4.16 Bidirectional RNN. The output of each step in time goes to two
    RNNs: one processing input from left to right (green) and the other from right
    to left (red). The output of the two RNNs is combined (via concatenation) to create
    one new item at each step. This item then goes to two outputs.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.16 双向 RNN。每个时间步的输出都进入两个 RNN：一个从左到右处理输入（绿色），另一个从右到左处理输入（红色）。两个 RNN 的输出通过连接组合，在每个步骤创建一个新项目。然后这个项目进入两个输出。
- en: Notice that the *last* time step now comes partially from the leftmost and rightmost
    items in the sequence. Our `LastTimeStep` function already handles that, which
    is why we did the work of implementing it. It allows us to seamlessly handle this
    new feature.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，现在的最后一个时间步现在部分来自序列中最左侧和最右侧的项目。我们的 `LastTimeStep` 函数已经处理了这一点，这就是我们为什么要实现它的原因。它允许我们无缝地处理这个新特性。
- en: 'Implementing bidirectional RNNs efficiently and accurately is no easy task.
    Luckily, PyTorch again makes it easy: simply set the `bidirectional=True` flag.
    Note, though, that the final hidden state is *twice as large* now because we have
    the final activations from *each* direction, so our `LastTimeStep` has twice as
    many values as expected. As long as we remember to multiply the `hidden_nodes*2`
    in the final `nn.Linear` layer, this will still work with little changes. The
    new code is as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 高效且准确地实现双向 RNN 并非易事。幸运的是，PyTorch 再次让这变得简单：只需设置 `bidirectional=True` 标志。但请注意，现在的最终隐藏状态现在大了两倍，因为我们有了来自每个方向的最终激活，所以我们的
    `LastTimeStep` 的值是预期的两倍。只要我们记得在最终的 `nn.Linear` 层中乘以 `hidden_nodes*2`，这仍然可以工作，只需做少许改动。新的代码如下：
- en: '[PRE27]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ (B, T) -> (B, T, D)
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ (B, T) -> (B, T, D)
- en: ❷ (B, T, D) -> ( (B,T,D) , (S, B, D) )
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ (B, T, D) -> ( (B,T,D) , (S, B, D) )
- en: ❸ Takes the RNN output and reduces it to one item, (B, D)
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将 RNN 输出减少到一项，(B, D)
- en: ❹ (B, D) -> (B, classes)
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ (B, D) -> (B, classes)
- en: '![](../Images/CH04_UN07_Raff.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH04_UN07_Raff.png)'
- en: The results show that the bidirectional RNN has a clear advantage. Whenever
    possible, use a bidirectional RNN, as it makes learning the access information
    across time much easier for the network. This has led to an increase in accuracy
    for our simple problem. But there will be cases where you do not want to or can’t
    use a bidirectional version; such examples come later in the book.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，双向 RNN 有明显的优势。只要可能，就使用双向 RNN，因为它使网络学习跨时间访问信息变得容易得多。这导致我们简单问题的准确性有所提高。但也会有你不想或不能使用双向版本的情况；这些例子将在本书的后面部分介绍。
- en: Exercises
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: Share and discuss your solutions on the Manning online platform at Inside Deep
    Learning Exercises ([https://liveproject.manning.com/project/945](https://liveproject.manning.com/project/945)).
    Once you submit your own answers, you will be able to see the solutions submitted
    by other readers, and see which ones the author judges to be the best.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在Manning在线平台Inside Deep Learning Exercises（[https://liveproject.manning.com/project/945](https://liveproject.manning.com/project/945)）上分享和讨论你的解决方案。一旦你提交了自己的答案，你将能够看到其他读者提交的解决方案，并看到作者认为哪些是最好的。
- en: Modify `LanguageNameDataset` so the `vocabulary` object in the constructor does
    not need to be passed in as an argument but instead can be *inferred* from the
    input dataset. This means you need to iterate through the dataset and create a
    dictionary with all the characters *actually seen*. One way to implement this
    is to create a default value `vocabulary=None` and use `is vocabulary None:` to
    change behavior.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改`LanguageNameDataset`，使得构造函数中的`vocabulary`对象不需要作为参数传入，而是可以从输入数据集中*推断*出来。这意味着你需要遍历数据集并创建一个包含所有实际出现的字符的字典。一种实现方式是创建一个默认值`vocabulary=None`，并使用`is
    vocabulary None:`来改变行为。
- en: Update `LanguageNameDataset` with a flag in the constructor for `unicode=False`.
    Change any of the code you need to so that when `unicode=True`, `Language-``NameDataset`
    instead keeps all the Unicode characters seen when`vocabulary=None` (this depends
    on exercise 1). Train a new RNN classifier with `unicode=True`. How does it impact
    the results?
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`LanguageNameDataset`的构造函数中添加一个标志`unicode=False`。修改任何需要的代码，以便当`unicode=True`时，`Language-``NameDataset`将保留在`vocabulary=None`时看到的所有Unicode字符（这取决于练习1）。使用`unicode=True`训练一个新的RNN分类器。这如何影响结果？
- en: Update `LanguageNameDataset` with a new `min_count=1` argument in the constructor.
    If `vocabulary=None`, it should replace any character that occurs too few times
    with a special `"UNK"` token, indicating an unknown value. How is the size of
    the vocabulary impacted by setting `min_count=300`, and what happens to the results?
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`LanguageNameDataset`的构造函数中添加一个新的`min_count=1`参数。如果`vocabulary=None`，它应该用特殊的`"UNK"`标记替换出现次数太少的任何字符，表示未知值。设置`min_count=300`如何影响词汇表的大小，以及结果会发生什么变化？
- en: 'The original training/test split for this task was created by randomly sampling
    the dataset. Create your own function that performs *stratified* splitting: selecting
    a test set that has the same proportions of each class. How does this impact your
    apparent results?'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个任务的原始训练/测试集分割是通过随机采样数据集创建的。创建你自己的函数来执行*分层*分割：选择一个测试集，其中每个类的比例相同。这如何影响你的表面结果？
- en: Replace the last output layer `nn.Linear(hidden_nodes, classes)` from the RNN
    implementation with a fully connected network with two hidden layers and one output
    layer. How does this impact the accuracy of the model?
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将RNN实现中的最后一个输出层`nn.Linear(hidden_nodes, classes)`替换为一个具有两个隐藏层和一个输出层的全连接网络。这如何影响模型的准确性？
- en: You can use the collation function to implement interesting features. To get
    a better handle on how it works, implement your own `collate_fn` that removes
    half the items from a batch of training data. Does training with two epochs of
    this model obtain the same results as training with one epoch of a normal `collate_fn`?
    Why or why not?
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用归一化函数来实现有趣的功能。为了更好地理解其工作原理，实现你自己的`collate_fn`，该函数从一批训练数据中删除一半的项目。使用这个模型的两个epoch进行训练与使用一个epoch的正常`collate_fn`进行训练获得相同的结果吗？为什么或为什么不？
- en: Compare training a three-layer bidirectional RNN with batch sizes of *B* = {1,
    2, 4, 8} for five epochs. Which batch size seems to give the best balance between
    speed and accuracy?
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较训练一个三层双向RNN，批大小为*B* = {1, 2, 4, 8}，进行五个epoch。哪个批大小似乎在速度和准确性之间提供了最佳平衡？
- en: Summary
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Recurrent neural networks (RNNs) are used for processing data that comes in
    as a sequence (e.g., text).
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 递归神经网络（RNNs）用于处理以序列形式到来的数据（例如，文本）。
- en: RNNs work by using weight sharing, so the same weights are reused for every
    item in the sequence. This lets them process sequences of variable length.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RNN通过使用权重共享来工作，因此相同的权重被用于序列中的每个项目。这使得它们能够处理可变长度的序列。
- en: Text problems require a vocabulary of tokens. An embedding layer converts those
    tokens to vectors for the RNN’s input.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本问题需要一个标记的词汇表。嵌入层将这些标记转换为RNN的输入向量。
- en: The hidden state is passed to the next step of the sequence and passed up to
    the next layer. The hidden state at the top-right (last layer, last item being
    processed) is a representation of the entire sequence.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏状态被传递到序列的下一步，并向上传递到下一层。右上角的隐藏状态（最后一层，正在处理的最后一个项目）是整个序列的表示。
- en: To train on batches of sequences, we pad them to have the same length and use
    the packing functions so that only the valid parts of the input are processed.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了在序列批次上训练，我们将它们填充到相同的长度，并使用打包函数，以确保只处理输入的有效部分。
- en: 'RNN accuracy can be improved by processing data bidirectionally: left to right
    and right to left.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过双向处理数据（从左到右和从右到左）可以提高RNN的准确率。
- en: '* * *'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ¹ This is a real type of model, but it tends to take a long time to train. We
    won’t do any examples that are quite that complex.[↩](#fnref8)
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 这是一个真实的模型类型，但它往往需要很长时间来训练。我们不会做任何如此复杂的例子。[↩](#fnref8)
