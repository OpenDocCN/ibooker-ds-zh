- en: Chapter 9\. Governing Data Access
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章. 管理数据访问
- en: 'This chapter describes the challenges of providing analysts access to the data
    in a data lake and presents several best practices for doing so. Data lakes differ
    from more traditional data storage in several ways:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了向分析师提供数据湖中数据访问的挑战，并提出了几种最佳实践。数据湖在几个方面与传统数据存储不同：
- en: Load
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 载入
- en: The numbers of data sets, users, and changes are extremely high.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集、用户和变更的数量非常庞大。
- en: Frictionless ingestion
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 无摩擦地摄取
- en: Because a data lake stores data for future, yet-to-be-determined analytics,
    it usually ingests the data with minimal, if any, processing.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 因为数据湖将数据存储以备将来尚未确定的分析使用，通常在摄取数据时不进行或仅进行最少的处理。
- en: Encryption
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 加密
- en: There are often government or internal regulations that require sensitive or
    personal information to be protected, yet that data is needed for analysis.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 通常存在政府或内部法规要求保护敏感或个人信息，但这些数据又需要用于分析。
- en: Exploratory nature of work
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 工作的探索性质
- en: 'A lot of data science work cannot be anticipated by IT staff. Data scientists
    often do not know what’s available in the huge and diverse data store. This creates
    a catch-22 situation for traditional approaches: if analysts cannot find data
    that they don’t have access to, they can’t ask for access to it.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 很多数据科学工作无法被IT员工预料到。数据科学家通常不知道在庞大而多样化的数据存储中有什么可用的内容。这为传统方法创建了一个进退两难的局面：如果分析师找不到他们无权访问的数据，他们就无法请求访问权限。
- en: The easiest access model is to provide all analysts access to all data. Unfortunately,
    this cannot be done if the data is subject to government regulations (as is the
    case, for example, with personally identifiable information or credit card information),
    is copyrighted with restricted access (e.g., if it has been purchased or obtained
    from external sources for very specific or limited use), or is considered critical
    and sensitive by the company for competitive or other reasons. Most companies
    have data they consider sensitive—anything from trade secrets to customer lists
    to engineering designs and financial information. Therefore, except for a limited
    set of projects mostly dealing with public data, research data, and non-sensitive
    internal data, it’s typically impossible to give full access to all data in data
    lakes to everyone.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的访问模式是为所有分析师提供对所有数据的访问权限。不幸的是，如果数据受到政府法规的约束（例如包含个人可识别信息或信用卡信息的情况），或者被版权保护并限制访问（例如因特定或有限用途而从外部来源购买或获取的数据），或者被公司认为是竞争或其他原因敏感和关键的信息，这是无法做到的。大多数公司都有他们认为敏感的数据——从商业机密到客户列表再到工程设计和财务信息。因此，除了一组主要处理公共数据、研究数据和非敏感内部数据的有限项目外，通常不可能向所有人提供对数据湖中所有数据的完全访问权限。
- en: Authorization or Access Control
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 授权或访问控制
- en: Authorization is the common way of managing data access. It involves explicitly
    assigning permissions to perform specific *actions*, such as reading or updating,
    on specific *data assets*, such as files and tables, to specific *analysts*. To
    streamline this process, security admins usually create *roles* (collections of
    permissions) and assign those roles to groups of analysts.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 授权是管理数据访问的常见方式。它涉及明确地分配权限，以执行特定的*操作*（如读取或更新）和特定的*数据资产*（如文件和表），给特定的*分析师*。为了简化这一过程，安全管理员通常创建*角色*（权限集合）并将这些角色分配给分析师群体。
- en: Most legacy systems provide their own internal authorization mechanisms. Since
    more and more companies are opting to use more and more applications, often in
    the cloud, instead of using a single integrated application from a single vendor,
    single sign-on (SSO) systems have become very popular. With single sign-on, users
    log in once and their credentials are supported by all the applications and systems.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数遗留系统提供其自身的内部授权机制。由于越来越多的公司选择在云中使用更多的应用程序而不是使用单一供应商提供的单一集成应用程序，单点登录（SSO）系统变得非常流行。通过单点登录，用户只需登录一次，他们的凭据就能被所有应用程序和系统支持。
- en: 'Unfortunately, there are several challenges with this approach. Notably:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这种方法存在几个挑战。特别是：
- en: It is very difficult to predict in advance what data analysts will need for
    their projects.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测数据分析师在项目中所需的数据是非常困难的。
- en: Unless the analysts have access to data, they cannot tell whether they need
    that data.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除非分析师能访问数据，否则他们无法确定他们是否需要这些数据。
- en: 'There is a high cost to maintaining authorizations, which may be spread out
    over many time periods and activities:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维护授权可能需要高昂的成本，这些成本可能分摊在多个时间段和活动中：
- en: Whenever a new employee is hired, the security admins need to provide appropriate
    authorizations.
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每当新员工入职时，安全管理员需要提供适当的授权。
- en: As an employee changes roles or projects, the security admins need to provide
    new privileges and revoke old privileges.
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当员工更改角色或项目时，安全管理员需要提供新的权限并撤销旧的权限。
- en: When a new data set shows up, the security admins need to figure out all the
    users who may need access to this data set.
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当出现新的数据集时，安全管理员需要确定所有可能需要访问该数据集的用户。
- en: When an analyst needs a data set that contains sensitive data, a version of
    that data set needs to be created that either removes or deidentifies the sensitive
    data.
  id: totrans-21
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当分析师需要一个包含敏感数据的数据集时，需要创建一个相应的数据集的版本，以删除或去标识化敏感数据。
- en: 'The challenges are so formidable that some enterprises are resorting to monitoring
    the access logs to make sure that the analysts are accessing appropriate data.
    Unfortunately, this approach only catches people after the fact and does not prevent
    them from intentionally using the wrong data, or help them avoid using it unintentionally.
    Enterprises that want to be more proactive take various approaches to address
    these challenges, including:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战如此巨大，以至于一些企业不得不监控访问日志，以确保分析师只能访问适当的数据。不幸的是，这种方法只能在事后发现问题，无法防止人员有意使用错误的数据，也无法帮助他们意外地避免使用错误的数据。想要更加积极主动的企业采取各种方法来应对这些挑战，包括：
- en: Using tag-based data  access policies
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于标签的数据访问策略
- en: Deidentifying sensitive data by removing, encrypting, or replacing it with generated
    random data, and granting access to these deidentified data sets to everyone
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过删除、加密或用生成的随机数据替换来去标识化敏感数据，并向所有人授予对这些去标识化数据集的访问权限。
- en: Implementing self-service access management by creating a metadata-only catalog
    that allows the analysts to find all available data sets and then request access
    to the relevant ones from data set owners or security admins
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过创建一个仅包含元数据的目录来实现自助访问管理，分析师可以从数据集所有者或安全管理员那里找到所有可用的数据集，然后请求访问相关的数据集。
- en: We’ll explore these different approaches to controlling access in the following
    sections.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中探讨这些不同的访问控制方法。
- en: Tag-Based Data Access Policies
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于标签的数据访问策略
- en: 'Traditional access control is based on physical files and folders. For example,
    the Hadoop File System (HDFS) supports typical Linux access control lists (ACLs).
    A “set file access control list” (`-setfacl`) command allows an administrator
    or file owner to specify which users and groups of users can have what access
    to a specific file or folder. For example, if a file contains salaries, the administrator
    may make it readable by users in the human resources (HR) department using the
    following command:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的访问控制是基于物理文件和文件夹的。例如，Hadoop文件系统（HDFS）支持典型的Linux访问控制列表（ACLs）。"设置文件访问控制列表"（`-setfacl`）命令允许管理员或文件所有者指定哪些用户和用户组可以对特定文件或文件夹进行什么样的访问。例如，如果一个文件包含工资信息，管理员可以使用以下命令使人力资源（HR）部门的用户能够阅读它：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This command basically says that any user in the group *human_resources* can
    read the *salaries.csv* file.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这条命令基本上表示任何*human_resources*组中的用户都可以读取*salaries.csv*文件。
- en: 'Obviously, if a data lake contains millions of files, setting permissions for
    each one manually would not be very practical. Instead, administrators usually
    set up folders and grant access permissions to groups for all the files in those
    folders or folder trees. For example, they might create an *hr_sensitive* folder
    and allow any user in the *hr* group to read any file in that folder. Often this
    approach is sufficient, but it presents some big challenges, including:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果一个数据湖包含数百万个文件，手动为每个文件设置权限显然是不太实际的。因此，管理员通常会设置文件夹，并为所有文件夹或文件夹树中的所有文件授予访问权限。例如，他们可以创建一个*hr_sensitive*文件夹，并允许*hr*组中的任何用户读取该文件夹中的任何文件。通常这种方法是足够的，但它也带来一些重大挑战，包括：
- en: Having to support complex permission schemes that reflect organizational reality
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要支持反映组织实际情况的复杂权限方案
- en: Having to determine and set permissions for every file
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要确定和设置每个文件的权限
- en: Having to detect and address schema changes
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要检测和处理模式变更
- en: Organizational realities in large enterprises are usually very complex. For
    example, if we decide that instead of giving all HR users permission to see all
    the data in the *hr_sensitive* folder we want only HR users from a particular
    division to see the data for that division, we would need to create multiple subfolders—one
    for each department (e.g., *human_resources/engineering*, *human_resources/sales*,
    etc.)—and create a separate group for each department (e.g., *hr _engineering*,
    *hr _sales*, etc.).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 大型企业中的组织实际情况通常非常复杂。例如，如果我们决定，与其给予所有 HR 用户查看 *hr_sensitive* 文件夹中所有数据的权限，我们希望只有来自特定部门的
    HR 用户可以查看该部门的数据，那么我们需要创建多个子文件夹——每个部门一个（例如 *human_resources/engineering*、*human_resources/sales*
    等），并为每个部门创建一个单独的组（例如 *hr_engineering*、*hr_sales* 等）。
- en: Every new file ingested into the data lake has to be examined to determine who
    should have access to it. One approach is to quarantine all new data until a data
    steward or security analyst can review it by, for example, keeping it in a separate
    folder—a quarantine zone, as illustrated in [Figure 9-1](#manual_review_in_quarantine_zone).
    Sometimes, companies can take shortcuts and assume that, say, any data coming
    from an HR application should be accessed only by HR. But in general, with millions
    of files, this is an impossible task to accomplish manually. And yet, companies
    cannot risk opening up the data to everyone until someone determines what it contains
    and who should have access to it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 所有进入数据湖的新文件都必须进行检查，以确定谁应该访问它。一种方法是将所有新数据隔离，直到数据管理者或安全分析师能够审核它，例如将其保存在单独的文件夹中——一个检疫区，如
    [图 9-1](#manual_review_in_quarantine_zone) 所示。有时，公司可能会采取捷径，假设例如来自 HR 应用的任何数据只能由
    HR 访问。但总的来说，对于数以百万计的文件，手动完成这项任务是不可能的。然而，公司不能冒险将数据对所有人开放，直到有人确定其内容及其应访问者。
- en: '![Manual review in quarantine zone](Images/ebdl_0901.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![检疫区的手动审核](Images/ebdl_0901.png)'
- en: Figure 9-1\. Manual review in quarantine zone
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-1\. 检疫区的手动审核
- en: While this has some chance of working for ingested data, especially if new types
    of data are rarely added to the set, it is not practical for the data created
    in a data lake. If any new file created in the data lake had to be quarantined
    until someone manually examined it and decided on access control policies, the
    work in the lake would grind to a screeching halt.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这在摄入数据方面有一些可行性，尤其是如果很少添加新类型的数据到集合中，但这对于在数据湖中创建的数据并不实际。如果必须将数据湖中创建的任何新文件隔离，直到有人手动检查并确定访问控制策略，那么数据湖中的工作将会完全停滞。
- en: A much more elegant solution implemented in some Hadoop distributions is tag-based
    security. For example, Cloudera Navigator and Apache Ranger (shipped as part of
    the Hortonworks Hadoop distribution) support tag-based policies. Instead of specifying
    ACLs for each file and folder, with these tools security administrators can set
    up policies using tags. While you still need a quarantine zone, the analysts can
    simply tag files and folders instead of manually creating ACLs for each one, as
    illustrated in [Figure 9-2](#quarantine_process_with_tag-based_polici).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些 Hadoop 发行版中实施的一个更加优雅的解决方案是基于标签的安全性。例如，Cloudera Navigator 和 Apache Ranger（作为
    Hortonworks Hadoop 发行版的一部分提供）支持基于标签的策略。使用这些工具，安全管理员可以设置使用标签的策略，而不是为每个文件和文件夹单独指定
    ACL。虽然你仍然需要一个检疫区，分析员可以简单地给文件和文件夹打上标签，而不是为每一个手动创建 ACL，如 [图 9-2](#quarantine_process_with_tag-based_polici)
    所示。
- en: '![Quarantine process with tag-based policies](Images/ebdl_0902.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![基于标签策略的检疫过程](Images/ebdl_0902.png)'
- en: Figure 9-2\. Quarantine process with tag-based policies
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-2\. 基于标签策略的检疫过程
- en: These tags can be set in local catalog tools like Cloudera Navigator and Apache
    Atlas and get automatically picked up by policy-based access control tools like
    Apache Ranger. For instance, the [Hortonworks Ranger tutorial](http://bit.ly/2MTK809)
    shows how to set a policy for any file tagged with the `PII` (personally identifiable
    information) tag, regardless of where it may be located.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些标签可以在本地目录工具（如 Cloudera Navigator 和 Apache Atlas）中设置，并且会被策略访问控制工具（如 Apache
    Ranger）自动捕捉。例如，[Hortonworks Ranger 教程](http://bit.ly/2MTK809) 展示了如何为任何标记为 `PII`（个人身份信息）的文件设置策略，无论其位于何处。
- en: This tag-based access control policy approach also addresses the challenges
    of reflecting complex organizational reality, since you are no longer trying to
    reflect it in the folder structure. Instead, files and folders can live where
    they like and policies can be arbitrarily complex and rely on multiple tags. For
    example, to refine an access control policy to take department into consideration,
    you just need to add tags with the department names (`Engineering`, `Sales`, etc.)
    to the files and create separate policies for each combination of tags (e.g.,
    `HR` and `Engineering`, `HR` and `Sales`). You do not have to create new folders,
    move data, or rewrite applications that relied on the old folder structure.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 基于标签的访问控制策略方法还解决了反映复杂组织现实的挑战，因为你不再试图在文件夹结构中反映它。相反，文件和文件夹可以随意存放，策略可以任意复杂，并依赖于多个标签。例如，要根据部门来细化访问控制策略，你只需为文件添加包含部门名称（`工程`、`销售`等）的标签，并为每个标签组合（例如，`人力资源`和`工程`、`人力资源`和`销售`）创建单独的策略。你无需创建新文件夹、移动数据，或重写依赖于旧文件夹结构的应用程序。
- en: Tags provide a powerful way of managing and organizing data. In fact, with tags,
    you do not even need a separate quarantine area. Instead, newly ingested files
    can be tagged as “quarantined” as part of the ingestion process, and a policy
    can be created to restrict access to such files by anyone but the data stewards.
    Data stewards can then review the files, tag them with appropriate sensitive data
    tags, and finally remove the quarantine tag, as illustrated in [Figure 9-3](#using_tags_to_quarantine_files).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 标签提供了一种强大的管理和组织数据的方式。事实上，使用标签，你甚至不需要一个单独的隔离区域。相反，新接收的文件可以在摄取过程中标记为“隔离”，并且可以创建策略来限制除数据监护人外的任何人访问这些文件。数据监护人随后可以审核这些文件，使用适当的敏感数据标签进行标记，最后移除隔离标签，正如在[图 9-3](#using_tags_to_quarantine_files)中所示。
- en: '![Using tags to quarantine files](Images/ebdl_0903.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![使用标签隔离文件](Images/ebdl_0903.png)'
- en: Figure 9-3\. Using tags to quarantine files
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-3\. 使用标签隔离文件
- en: Although tag-based security solves the organizational challenges around data
    and expedites manual review processes, tags stand in direct conflict with the
    premise of data lakes, where data is stored for an undetermined future and loaded
    using frictionless ingestion without any processing. Frictionless ingestion makes
    loading data fast and puts minimal stress on source systems, but it also makes
    it very difficult to figure out what sort of data you have just received and whether
    it is sensitive, in either a traditional or company-specific sense.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基于标签的安全性解决了围绕数据的组织挑战并加快了手动审核流程，但标签与数据湖的前提存在直接冲突。在数据湖中，数据存储在未来未确定的情况下，并通过无摩擦摄入加载，而无需任何处理。无摩擦摄入使数据加载快速，并对源系统施加最小的压力，但也使得很难弄清楚你刚刚接收到了什么样的数据，以及它是否敏感，无论是传统意义上还是公司特定意义上。
- en: Furthermore, analysts can easily get overwhelmed by the amount of new data and
    lose the ability to work through the quarantined items in a timely manner. Detecting
    sensitive data is a challenging exercise. How does the analyst really know that
    a million-row file does not happen to have some Social Security numbers or other
    sensitive identifiers in some (maybe tens of thousands!) of its rows that just
    happen to be stored in a field called `Notes`? Looking at the first few hundred
    rows may not reveal anything—in fact, some columns might be entirely empty—and
    doing large queries against the entire data set will take time and may require
    scripting or development of specialized tools.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，分析人员可能会因为大量的新数据而感到不知所措，并且失去及时处理隔离项目的能力。检测敏感数据是一项具有挑战性的任务。分析人员如何确切地知道一个百万行文件中的某些行（也许成千上万！）没有包含社会安全号码或其他敏感标识符，而这些行刚好存储在一个名为`Notes`的字段中？查看前几百行可能不会显示任何内容——事实上，有些列可能完全为空——而对整个数据集进行大规模查询将需要时间，并且可能需要脚本编写或开发专门的工具。
- en: Even if the analyst is able to write and run the scripts required to detect
    sensitive data, schema and data changes present an additional challenge. If a
    new file comes in and the analyst does not find any sensitive information in it,
    it’s possible that subsequent changes to that file (new partitions) will contain
    additional fields that do hold sensitive data, or that such data might be added
    to fields that were not originally sensitive.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 即使分析员能够编写和运行检测敏感数据所需的脚本，模式和数据变化仍然是一个额外的挑战。如果新文件进来，分析员没有在其中找到任何敏感信息，那么后续对该文件的更改（新的分区）可能会包含额外的字段，这些字段确实包含敏感数据，或者这些数据可能被添加到最初不敏感的字段中。
- en: The only practical solution to handling sensitive data and access control management
    is automation. Tools like Informatica, Waterline Data, and Dataguise scan all
    new files—newly ingested files, new partitions to previously ingested files, and
    new files created in the data lake—and automatically detect sensitive data and
    tag the files, as illustrated in [Figure 9-4](#automatic_tagging_of_sensitive_data).
    They then export those tags to the local catalog tools, like Apache Atlas, to
    be used for enforcing tag-based policies.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 处理敏感数据和访问控制管理的唯一实际解决方案是自动化。像Informatica、Waterline Data和Dataguise这样的工具会扫描所有新文件——新摄取的文件、之前摄取文件的新分区以及在数据湖中创建的新文件——并自动检测敏感数据并标记文件，如[图 9-4](#automatic_tagging_of_sensitive_data)所示。然后将这些标记导出到本地目录工具，如Apache
    Atlas，以用于执行基于标记的策略。
- en: '![Automatic tagging of sensitive data](Images/ebdl_0904.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![自动标记敏感数据](Images/ebdl_0904.png)'
- en: Figure 9-4\. Automatic tagging of sensitive data
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-4\. 自动标记敏感数据
- en: Deidentifying Sensitive Data
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 去识别敏感数据
- en: 'Once you identify sensitive data, you can restrict access to it. Unfortunately,
    that means that this data cannot be used for analytics. Instead, enterprises often
    encrypt sensitive data and give everyone access to the encrypted data sets. There
    are different forms of encryption that can be applied, including:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦识别出敏感数据，就可以限制对其的访问。不幸的是，这意味着这些数据无法用于分析。相反，企业通常会加密敏感数据，并允许所有人访问加密的数据集。可以应用不同形式的加密，包括：
- en: Transparent encryption
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 透明加密
- en: Explicit encryption
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显式加密
- en: Deidentification
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 去识别
- en: To describe these, let’s say we have a data set—for simplicity, let’s make it
    tabular—that contains some patient information at a healthcare provider (see [Figure 9-5](#a_sample_of_the_patient_information_data)).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了描述这些内容，我们假设有一个数据集——简单起见，我们假设它是表格的——其中包含医疗保健提供者的一些患者信息（参见[图 9-5](#a_sample_of_the_patient_information_data)）。
- en: '![A sample of the patient information data set](Images/ebdl_0905.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![患者信息数据集的示例](Images/ebdl_0905.png)'
- en: Figure 9-5\. A sample of the patient information data set
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-5\. 患者信息数据集的示例
- en: '*Transparent encryption* (like that provided by Cloudera Navigator) automatically
    encrypts data on disk when it is written and automatically decrypts it when it
    is read, as illustrated in [Figure 9-6](#transparent_encryption). This is done
    to prevent someone from accessing or copying raw disk volumes and reading them
    one byte at a time to recreate the data file, thereby avoiding all access controls.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*透明加密*（例如Cloudera Navigator提供的）会在写入时自动对数据进行磁盘加密，并在读取时自动解密，如[图 9-6](#transparent_encryption)所示。这是为了防止有人访问或复制原始磁盘卷，并一字节一字节地读取以重建数据文件，从而避开所有访问控制。'
- en: '![Transparent encryption](Images/ebdl_0906.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![透明加密](Images/ebdl_0906.png)'
- en: Figure 9-6\. Transparent encryption
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-6\. 透明加密
- en: However, transparent encryption does not prevent analysts with read privileges
    on the file from seeing sensitive data. For that, enterprises usually deploy *explicit
    encryption* and encrypt each value separately, as illustrated in [Figure 9-7](#explicit_encryption_makes_the_data_unusa).
    While this may seem straightforward—there are many open source encryption functions
    available and a range of tools providing encryption, from vendors such as Dataguise,
    Informatica, IBM, Privitar, Vormetric, and many others—it makes the sensitive
    data completely unusable, as the figure illustrates.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，透明加密无法阻止具有文件读取权限的分析员查看敏感数据。出于这个原因，企业通常部署*显式加密*，并单独加密每个值，如[图 9-7](#explicit_encryption_makes_the_data_unusa)所示。尽管这看起来很简单——有许多开源加密功能可用，并且提供加密的各种工具，如Dataguise、Informatica、IBM、Privitar、Vormetric等——但它使敏感数据完全无法使用，正如图中所示。
- en: That creates real problems for data scientists trying to use the data sets.
    As mentioned in [Chapter 1](ch01.xhtml#introduction_to_data_lakes), one data scientist
    I interviewed told me how at his company all data in the data lake is encrypted
    unless someone can prove that the attributes are not sensitive. The data scientist
    did not care for that approach. As he rhetorically put it, “How am I expected
    to prove that an attribute is not sensitive if I can’t find or view it?”
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这给试图使用数据集的数据科学家带来了真正的问题。正如在[第1章](ch01.xhtml#introduction_to_data_lakes)中提到的，我采访的一位数据科学家告诉我，在他的公司，除非能证明属性不敏感，否则数据湖中的所有数据都会被加密。这位数据科学家对这种做法并不赞同。他反问道：“如果我找不到或查看属性，我如何能证明它不是敏感的？”
- en: '![Explicit encryption makes the data unusable](Images/ebdl_0907.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![明确的加密使数据无法使用](Images/ebdl_0907.png)'
- en: Figure 9-7\. Explicit encryption makes the data unusable
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-7\. 明确的加密使数据无法使用。
- en: Even if only truly sensitive attributes are encrypted, often these attributes
    encode important information that data scientists use to derive variables for
    their models. For example, in a data set where people’s names are included but
    gender information is missing, it is often possible to infer the gender from the
    first name. It is sometimes also possible to figure out ethnicity from the first
    and last names. If the first name is encrypted, none of this information can be
    derived. Similarly, while encrypting address information is necessary, it prevents
    geographical analysis. To enable these kinds of analysis while protecting individuals’
    privacy, a class of “deidentification” or “anonymization” techniques have been
    developed. These techniques replace sensitive information with randomly generated
    values that preserve the important characteristics of the original data values.
    For example, an ethnic name might be replaced with a random name reflecting the
    same ethnicity and an address might be replaced with some other valid address
    within a 10-mile radius, as illustrated in [Figure 9-8](#data_deidentification).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 即使只加密真正敏感的属性，这些属性通常编码着数据科学家用来推导模型变量的重要信息。例如，在一个数据集中包含人名但性别信息缺失的情况下，通常可以通过名字推断出性别。有时还可以通过名字的首尾字母推断出种族。如果名字被加密，就无法推导出这些信息。同样，虽然加密地址信息是必要的，但它阻止了地理分析。为了在保护个人隐私的同时实现这些分析，开发了一类称为“去识别”或“匿名化”的技术。这些技术用随机生成的值替换敏感信息，保留原始数据值的重要特征。例如，一个民族名字可以用反映相同种族的随机名字替换，地址可以用10英里范围内的其他有效地址替换，如图[9-8](#data_deidentification)所示。
- en: '![Data deidentification](Images/ebdl_0908.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![数据去识别](Images/ebdl_0908.png)'
- en: Figure 9-8\. Data deidentification
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-8\. 数据去识别
- en: Again, several tools, including Dataguise, Privitar, IBM InfoSphere Optim, and
    Informatica, provide these capabilities.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，包括Dataguise、Privitar、IBM InfoSphere Optim和Informatica在内的多个工具提供这些功能。
- en: While deidentification or encryption of sensitive data is an effective solution
    in many cases, sometimes analysts will need access to the real data. Furthermore,
    even when there is no sensitive data, most enterprises compartmentalize data access
    and provide it on an as-needed basis only. Since data science is by its nature
    exploratory, it is difficult to predict what data the analyst is going to need.
    Even for simple analytics, a lot of power comes from understanding what data is
    available and getting access to it. As a compromise between very high-maintenance
    tightly managed privileges and a free-for-all approach that requires no management,
    companies are turning to self-service access management.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在许多情况下，去识别或加密敏感数据是有效的解决方案，但有时分析师需要访问真实数据。此外，即使没有敏感数据，大多数企业也将数据访问分隔化，并仅按需提供。由于数据科学本质上是探索性的，很难预测分析师需要哪些数据。即使是简单的分析也需要理解可用数据和获取访问权限。作为非常高维护、严密管理权限与无需管理的自由访问之间的折中，公司正在转向自服务访问管理。
- en: Data Sovereignty and Regulatory Compliance
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据主权与法规合规性
- en: In order to comply with regional, country, and industry data protection regulations,
    more and more information needs to be collected about a data set and stored in
    its metadata. For example, to comply with data sovereignty laws, it is important
    to know what country the data set came from and, more importantly, which country’s
    citizens’ data it contains. Instead of hardcoding policies for each physical data
    set, policies can be developed that, for example, specify that German data cannot
    be copied outside of the European Union.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了遵守区域、国家和行业的数据保护法规，需要收集更多关于数据集的信息，并存储在其元数据中。例如，为了遵守数据主权法，重要的是要知道数据集来自哪个国家，更重要的是，它包含哪个国家公民的数据。而不是为每个物理数据集硬编码政策，可以制定策略，例如，指定德国数据不能在欧盟之外复制。
- en: Data lineage, discussed in detail in [Chapter 6](ch06.xhtml#optimizing_for_self-service),
    can also be used to track down the country of origin of a data source. [Figure 9-9](#tagging_for_provenance)
    illustrates how this might work. For each data set, we create a `Provenance` property
    that captures where the data set came from. For example, for a data set that originated
    in the US, this property would be set to `USA`. If a data set is created by combining
    data from multiple other data sets, the provenance of each source that data came
    from is added to the `Provenance` property. So, if data from a CRM system in the
    US and an ERP system in Germany was loaded into a data warehouse in the UK and
    then into a data lake in France, the `Provenance` property of the final data set
    would contain the values `USA`, `Germany`, `UK`, and `France`. The policy can
    then specify that if the `Provenance` property contains `Germany`, certain rules
    will apply.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数据谱系，在 [第 6 章](ch06.xhtml#optimizing_for_self-service) 中详细讨论，还可以用于追踪数据源的原始国家。[Figure
    9-9](#tagging_for_provenance) 说明了这种工作原理。对于每个数据集，我们创建一个`Provenance`属性，用于记录数据集的来源。例如，对于源自美国的数据集，此属性将设置为`USA`。如果通过合并多个其他数据集创建数据集，则将每个数据来源的来源添加到`Provenance`属性中。因此，如果从美国的CRM系统和德国的ERP系统加载数据到英国的数据仓库，然后再加载到法国的数据湖中，最终数据集的`Provenance`属性将包含`USA`、`Germany`、`UK`和`France`的值。然后，策略可以指定，如果`Provenance`属性包含`Germany`，则将适用某些规则。
- en: '![Tracking provenance](Images/ebdl_0909.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![追溯来源](Images/ebdl_0909.png)'
- en: Figure 9-9\. Tracking provenance
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 9-9\. 追溯来源
- en: Similarly, the profiling described in “Technical Metadata” in [Chapter 8](ch08.xhtml#cataloging_the_data_lake)
    can be used to identify where any addresses in the data set are from. Consider
    the tables in Figures [9-10](#assigning_a_property_with_country_proven) and [9-11](#count_of_rows_for_each_country).
    The first is a `Customers` table that contains customers’ names and addresses,
    whereas the second table contains the number of rows in the `Customers` table
    that contain a specific value in the `Country` field, as determined by profiling.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，[第 8 章](ch08.xhtml#cataloging_the_data_lake)中描述的“技术元数据”中的分析可以用来确定数据集中任何地址的来源。考虑到图表
    [9-10](#assigning_a_property_with_country_proven) 和 [9-11](#count_of_rows_for_each_country)
    中的表格。第一个是一个`Customers`表，包含客户的姓名和地址，而第二个表格包含了在`Country`字段中具有特定值的`Customers`表中的行数，这是通过分析确定的。
- en: '![Assigning a property with country provenance](Images/ebdl_0910.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![分配具有国家来源的属性](Images/ebdl_0910.png)'
- en: Figure 9-10\. Assigning a property with country provenance
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 9-10\. 分配具有国家来源的属性
- en: '![Count of rows for each country](Images/ebdl_0911.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![每个国家的行数统计](Images/ebdl_0911.png)'
- en: Figure 9-11\. Count of rows for each country
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 9-11\. 每个国家的行数统计
- en: A `Referenced Countries` property can then be created and populated (ideally,
    programmatically) by the values in the `Country` column’s profile, and a policy
    can be developed that states, for example, that if a data set has a `Referenced
    Countries` property and it contains `Germany` as an entry, certain rules should
    apply. This approach would enable compliance with the data sovereignty laws of
    countries like Germany and China that prohibit moving data about their citizens
    out of the country.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以创建并填充一个`Referenced Countries`属性（最好是通过程序自动填充），填充的值来自`Country`列的分析结果。并且可以制定一个策略，例如，如果数据集具有`Referenced
    Countries`属性并且其中包含`Germany`作为条目，则应适用特定规则。这种方法可以遵守像德国和中国等国家的数据主权法，禁止将其公民的数据移出该国。
- en: In addition to concerns about data provenance, many regulations mandate usage
    restrictions for specific data sets. For example, the GDPR mandates that customer
    data can be used only for the business purpose for which it was collected, and
    any additional use requires explicit customer consent. All this information needs
    to be captured and stored somewhere so it can be considered when granting access
    to data, and a data catalog is the perfect place to store and manage it.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对数据来源的关注之外，许多法规还规定特定数据集的使用限制。例如，GDPR规定客户数据只能用于收集它的业务目的，任何额外的使用需要明确的客户同意。所有这些信息都需要被捕捉和存储在某个地方，以便在授予数据访问权限时进行考虑，而数据目录则是存储和管理这些信息的理想地点。
- en: Self-Service Access Management
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自助访问管理
- en: While proactively and automatically protecting sensitive data makes sense and
    is often required by government regulations, access control often extends beyond
    sensitive data and requires consideration of who in the organization should have
    access to what data. For example, many companies do not share the prices that
    customers pay for their products beyond the sales teams and management, do not
    share engineering designs of upcoming products outside the project teams, and
    so on. As we’ve seen, managing this access can be done proactively as new files
    are created and as users are added to the data lake, change projects, or change
    responsibilities. Alternatively, it can be done in an on-demand manner using self-service
    access management.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管积极和自动保护敏感数据是合理的，并且通常是政府法规要求的，但访问控制通常超出敏感数据，需要考虑在组织中谁应该访问什么数据。例如，许多公司不会将客户为其产品支付的价格与销售团队和管理层以外的人员分享，也不会与项目团队外的人员分享即将推出的产品的工程设计等。正如我们所见，管理这种访问可以在创建新文件时积极进行，也可以在用户添加到数据湖、更改项目或更改职责时按需进行，使用自助访问管理。
- en: 'The premise of the data lake is to keep data for future, yet-to-be-determined
    uses. An obvious issue is that it will of course be difficult to determine who
    will need access to which data in the future, and why. On the other hand, if the
    analysts don’t have access to the data and do not know that it exists, they will
    never be able to find and use it. Self-service access management coupled with
    a data catalog addresses this problem by making all the data findable. This system
    moves access control and data masking decisions to the time when someone actually
    needs the data for their project. The system offers several distinct characteristics
    and benefits:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 数据湖的前提是保留未来尚未确定用途的数据。显而易见的问题是，在未来谁需要访问哪些数据以及为什么会变得非常困难。另一方面，如果分析师们无法访问数据并且不知道其存在，他们将永远无法找到并使用它。自助访问管理与数据目录结合解决了这个问题，使所有数据都能被找到。这个系统通过在某人实际需要数据进行项目时移交访问控制和数据屏蔽决策来解决这个问题。该系统提供了几个独特的特点和好处：
- en: Analysts can explore (search and browse) metadata for all the data sets that
    may be made available to them.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析师可以探索（搜索和浏览）可能提供给他们的所有数据集的元数据。
- en: Analysts can request access to a data set from the data set owner.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析师可以向数据集所有者申请访问权限。
- en: The owner of the data set decides who can access it, in what way, and for how
    long.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的所有者决定谁可以访问它，以何种方式以及多长时间。
- en: All the requests, justifications, and permissions are tracked for security audit
    purposes.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有请求、理由和权限都会被跟踪以供安全审计目的。
- en: 'Figures [9-12](#publishing_data) through [9-15](#access_request_approved) illustrate
    a self-service access management and data provisioning system. The steps are as
    follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [9-12](#publishing_data) 到图 [9-15](#access_request_approved) 展示了一个自助访问管理和数据提供系统。具体步骤如下：
- en: The data owner publishes data assets to the catalog ([Figure 9-12](#publishing_data)).
    At this point, analysts are able to find the data, but don’t have permission to
    read or change it.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据所有者将数据资产发布到目录（[图 9-12](#publishing_data)）。此时，分析师们能够找到数据，但无权读取或更改。
- en: '![Publishing data](Images/ebdl_0912.png)'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![发布数据](Images/ebdl_0912.png)'
- en: Figure 9-12\. Publishing data
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-12\. 发布数据
- en: A data analyst finds data sets in the catalog ([Figure 9-13](#analyst_finds_data)).
    Since the analyst does not have access to the data, the search has to be done
    on metadata. That’s why it is so important to have good metadata and business-level
    descriptions, as described in the preceding chapter.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据分析师在目录中找到数据集（[图 9-13](#analyst_finds_data)）。由于分析师无权访问数据，因此必须在元数据上进行搜索。这也是为什么拥有良好的元数据和业务级描述非常重要，正如前一章所述。
- en: '![Analyst finds data](Images/ebdl_0913.png)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![分析师找到数据](Images/ebdl_0913.png)'
- en: Figure 9-13\. Analyst finds data
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 9-13\. 分析师找到数据
- en: The analyst requests access from the data owner ([Figure 9-14](#analyst_requests_access)).
    Analysts can use the catalog to find data but not to access it; they have to ask
    the data owner for permission to use it. This way, the data owner is in full control
    of who is using the data and why.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析师从数据所有者那里请求访问（[Figure 9-14](#analyst_requests_access)）。分析师可以使用目录查找数据，但无法访问它；他们必须向数据所有者请求许可才能使用。这样，数据所有者完全控制谁使用数据以及原因。
- en: '![Analyst requests access](Images/ebdl_0914.png)'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![分析师请求访问](Images/ebdl_0914.png)'
- en: Figure 9-14\. Analyst requests access
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 9-14\. 分析师请求访问
- en: The data owner approves the request ([Figure 9-15](#access_request_approved)).
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据所有者批准了请求（[Figure 9-15](#access_request_approved)）。
- en: '![Access request approved](Images/ebdl_0915.png)'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![访问请求已批准](Images/ebdl_0915.png)'
- en: Figure 9-15\. Access request approved
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 9-15\. 访问请求已批准
- en: The data sets are provided (provisioned) to the analyst ([Figure 9-16](#requestedDataSets_analyst)).
    This can be accomplished in a variety of ways, ranging from giving the analyst
    access to the source system to copying the data over to the analyst’s personal
    work area. The process may also include a deidentification step to mask sensitive
    data. The key here is that the work is done only if and when the data set is requested
    and there is a real business reason to do it.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集被提供（供应）给分析师（[Figure 9-16](#requestedDataSets_analyst)）。这可以通过多种方式完成，从给分析师访问源系统到将数据复制到分析师的个人工作区域。该过程还可能包括脱敏步骤以掩盖敏感数据。关键在于，仅在请求数据集并且确实有业务理由时才执行这项工作。
- en: '![Requested data sets are provisioned to the data lake and provided to the
    data analyst](Images/ebdl_0916.png)'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![请求的数据集被提供到数据湖并提供给数据分析师](Images/ebdl_0916.png)'
- en: Figure 9-16\. Requested data sets are provisioned to the data lake and provided
    to the data analyst
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 9-16\. 请求的数据集被提供给数据湖，并提供给数据分析师
- en: 'There are many advantages to this approach. As an IT executive at a large enterprise
    that I interviewed for this book explained:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法有很多优势。正如我为这本书采访的一位大型企业的IT高管所解释的那样：
- en: People are afraid to share data unless they can make sure it is used appropriately.
    By giving them the power to decide who can use it and how, we created an environment
    where they feel safe sharing data. Before we implemented this self-service approach,
    obtaining data required months of negotiations up and down the management chain.
    Everyone always asked for everything they could think of to make sure they did
    not have to go through the pain and delays of negotiations again. This made data
    owners distrustful of the true needs of the requesters and forced them to institute
    strict review processes where the requesters had to provide very detailed requirements
    and justifications, causing ever more work and more delays. It was virtually impossible
    to explore data in such an environment.
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 人们害怕分享数据，除非他们能确保它被适当地使用。通过让他们决定谁可以使用数据以及如何使用，我们创造了一个他们感到安全分享数据的环境。在我们实施这种自助服务方法之前，获取数据需要数月的上下管理层的谈判。每个人总是尽可能地要求一切，以确保他们不必再经历谈判的痛苦和延迟。这让数据所有者对请求者真正的需求感到不信任，并迫使他们实施严格的审查流程，请求者必须提供非常详细的需求和理由，导致更多的工作和更多的延迟。在这样的环境中几乎不可能探索数据。
- en: ''
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With the self-service access management, requesters can study the data sets
    in the catalog and figure out what they need before they even place access requests,
    so there are many fewer requests, and a lot less data is being requested even
    when the requests are made, since the analysts have done pretty extensive exploration
    with the catalog and found what data is fit for purpose. Finally, because access
    requests are pretty automated, making additional requests is quick and straightforward.
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通过自助访问管理，请求者可以在甚至发出访问请求之前就研究目录中的数据集，并找出他们需要的内容，因此请求减少了很多，即使在进行请求时，由于分析师已经在目录中进行了相当广泛的探索并找到了适合目的的数据，请求的数据量也大大减少。最后，由于访问请求相当自动化，额外的请求也是快速和简单的。
- en: In short, this self-service process gives data owners control over who uses
    their data and gives analysts the ability to explore the data sets and obtain
    access quickly. In addition, by granting access to data for a specific period
    of time, this approach eliminates both the maintenance associated with managing
    permissions to all possible data sets and the inevitable legacy access that the
    analysts retain after the project is over, just in case they may need it. With
    the self-service approach, they can just place another request for the access
    to be quickly reinstated.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，这种自助服务流程让数据所有者控制谁使用他们的数据，并使分析师能够探索数据集并快速获取访问权限。此外，通过为特定时间段授予数据访问权限，这种方法消除了管理所有可能数据集权限所需的维护工作，以及项目结束后分析师可能保留的遗留访问权限，以防万一他们可能需要。采用自助服务方法，他们可以简单地提交另一个请求，以快速恢复访问权限。
- en: Once the authorization has been obtained, physical access to the data can be
    provided to analysts in a variety of ways, depending on the nature of the data
    sets and the needs of the projects. A popular way of granting access is to create
    an external Hive table for the data set. External Hive tables do not copy or change
    the data sets and can be created or deleted with negligible compute costs (since
    they are just metadata definitions). The analysts are then granted access to the
    Hive tables.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获得授权，可以以多种方式向分析师提供对数据的物理访问，具体取决于数据集的性质和项目的需求。授予访问权限的一种流行方式是为数据集创建外部Hive表。外部Hive表不复制或更改数据集，并且可以通过可忽略的计算成本（因为它们只是元数据定义）进行创建或删除。然后向分析师授予访问外部Hive表的权限。
- en: For some projects, analysts may want to make copies of the files or create their
    own Hive tables (for example, with different input formats that tell Hive to parse
    and interpret data). In such cases, they can be given a copy of the data set or
    granted read access to the data set itself.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些项目，分析师可能希望复制文件或创建自己的Hive表（例如，使用告知Hive解析和解释数据的不同输入格式）。在这种情况下，他们可以获得数据集的副本或被授予对数据集本身的读取访问权限。
- en: Provisioning Data
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置数据
- en: The previous section covered the benefits and gave an overview of self-service
    data access. Data provisioning is an important part of building a data lake and
    deserves a deeper discussion. It consists of four steps, as illustrated in [Figure 9-17](#data_provisioning_steps).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节介绍了自助数据访问的好处，并概述了数据配置的概述。数据配置是构建数据湖的重要部分，并值得进行更深入的讨论。如[图9-17](#数据配置步骤)所示，它包括四个步骤。
- en: '![Data provisioning steps](Images/ebdl_0917.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![数据配置步骤](Images/ebdl_0917.png)'
- en: Figure 9-17\. Data provisioning steps
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-17. 数据配置步骤
- en: 'The first step is done by an analyst who wants access to a data set. The request
    usually describes:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是由想要访问数据集的分析师完成。请求通常描述：
- en: What data is needed (which data set and whether the entire data set or part
    of the data set is needed)
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要哪些数据（哪个数据集以及是整个数据集还是部分数据集）
- en: Who needs the access (a list of users or groups that need to access the data)
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谁需要访问权限（需要访问数据的用户或组列表）
- en: The project (what project the data is needed for)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目（所需数据的项目）
- en: The business justification for access (why the data is needed)
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问数据的业务理由（为何需要数据）
- en: How long the data is needed (the duration of time after which access can be
    rescinded)
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据需要多长时间（访问权限撤销后的时间段）
- en: How to provision it (if users should get access to the data in place, or if
    it should be copied to the specified database or data lake)
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何配置它（用户是否应该在原地获取数据，或者是否应将其复制到指定的数据库或数据湖）
- en: 'If the data is to be copied, the request should additionally specify:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据将被复制，请求还应明确说明：
- en: Where the data should be placed
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据应放在何处
- en: Whether it should be a private copy or can be shared
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否应该是私有副本还是可以共享的
- en: Whether it should be a one-time snapshot or should be kept up to date
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否应该是一次性快照还是应该保持更新
- en: Whether after access expires it should be kept up to date or removed
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问权限到期后是否应保持更新或删除
- en: The request is usually filed via a standard case tracking system like ServiceNow
    or Jira, or using a BPM/workflow/case management system like Pegasystems or Eccentex.
    The tracking system routes the request to the data owners or stewards. In some
    cases, automated approval rules may be implemented—for example, if the requester
    is in a certain group, the approval can be given automatically. If the data needs
    to be copied somewhere, the administrator of the target system may need to sign
    off on the request.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 通常通过像ServiceNow或Jira这样的标准案例跟踪系统或使用像Pegasystems或Eccentex这样的BPM/工作流/案例管理系统进行申请。跟踪系统将请求路由到数据所有者或管理者。在某些情况下，可能会实施自动批准规则——例如，如果请求者属于某个特定组，可以自动批准审批。如果需要将数据复制到其他地方，则目标系统的管理员可能需要签署该请求。
- en: The logic may also get more sophisticated. For example, if the requester has
    access to the data at the source but wants it copied somewhere, only the target
    admin may need to approve the request. Conversely, if the requester is asking
    for a shared copy and the data already exists in the target system, only the source
    data steward may need to approve it since no additional storage is being used
    at the target.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑可能会变得更复杂。例如，如果请求者在源数据处有访问权限，但希望将其复制到其他地方，则只有目标管理员可能需要批准该请求。相反，如果请求者请求共享副本，并且数据已经存在于目标系统中，则只有源数据管理者可能需要批准，因为目标系统不会使用额外的存储空间。
- en: The tracking system also provides a single point of access and audit, so the
    company has a record of who was using what, and for what purpose. This is not
    just good data security hygiene, but often a regulatory requirement for external
    regulations like the GDPR.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪系统还提供了单一访问点和审计功能，因此公司可以记录谁使用了什么，以及出于什么目的。这不仅是良好的数据安全卫生习惯，而且通常是像GDPR这样的外部法规要求。
- en: Since the data is copied from elsewhere, most of the time the requested data
    will not be modified, but rather will be used to create a new data set. Therefore,
    it is very attractive to share this data between multiple requesters. The data
    is copied to a predefined place (usually in the landing or raw zone) and kept
    up to date as long as there are any outstanding requesters.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据是从其他地方复制过来的，所以大部分时间请求的数据不会被修改，而是用来创建一个新的数据集。因此，共享这些数据给多个请求者非常有吸引力。数据被复制到一个预定义的位置（通常是在着陆区或原始区），只要有任何未处理的请求者，就会保持更新。
- en: Let’s work through a provisioning scenario. Imagine that we have a data warehouse
    with a table called `Customers`, shown as a small rectangle in [Figure 9-18](#user_requests_access_to_a_data_set_in_th).
    A user named Fred requests access to that table through a shared copy in the data
    lake from June 1 to August 5.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个分配场景来进行工作。想象一下，我们有一个数据仓库，其中有一个名为`Customers`的表，如[图 9-18](#user_requests_access_to_a_data_set_in_th)所示，是一个小矩形。名为Fred的用户请求从6月1日到8月5日通过数据湖中的共享副本访问该表。
- en: '![User requests access to a data set in the data warehouse](Images/ebdl_0918.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![用户请求访问数据仓库中的数据集](Images/ebdl_0918.png)'
- en: Figure 9-18\. User requests access to a data set in the data warehouse
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-18\. 用户请求访问数据仓库中的数据集
- en: Assuming the request is approved, the table will be copied to a standard path
    in the staging area, as illustrated in [Figure 9-19](#data_set_is_provisioned_to_the_data_lake),
    on June 1\. All the data in the table will be copied to a directory whose name
    matches the date when it was copied.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 假设请求被批准，表将在6月1日如[图 9-19](#data_set_is_provisioned_to_the_data_lake)所示的暂存区标准路径中被复制。表中的所有数据将被复制到一个目录，其名称与复制时的日期相匹配。
- en: '![Data set is provisioned to the data lake](Images/ebdl_0919.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![数据集已分配到数据湖](Images/ebdl_0919.png)'
- en: Figure 9-19\. Data set is provisioned to the data lake
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-19\. 数据集已分配到数据湖
- en: The next day, only the changes that occurred since the initial copy was made
    will be copied to a new directory. Its name will reflect that date (in this case
    June 2), as illustrated in [Figure 9-20](#data_lake_is_updated_with_the_latest_cha).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 第二天，仅复制自初始副本以来发生的更改到新目录。其名称将反映那一天（在本例中是6月2日），如[图 9-20](#data_lake_is_updated_with_the_latest_cha)所示。
- en: '![Data lake is updated with the latest changes from the data warehouse](Images/ebdl_0920.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![数据湖已从数据仓库中更新为最新更改](Images/ebdl_0920.png)'
- en: Figure 9-20\. Data lake is updated with the latest changes from the data warehouse
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-20\. 数据湖已从数据仓库中更新为最新更改
- en: This will continue until the request expires on August 5, 2018.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这将持续到请求在2018年8月5日到期。
- en: Now imagine that another user, Mandy, requests the same table from June 15 to
    July 15, as illustrated in [Figure 9-21](#another_user_requests_the_same_data_set).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下，另一个用户曼迪从6月15日到7月15日请求相同的表格，如[图 9-21](#another_user_requests_the_same_data_set)所示。
- en: '![Another user requests the same data set](Images/ebdl_0921.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![另一个用户请求相同的数据集](Images/ebdl_0921.png)'
- en: Figure 9-21\. Another user requests the same data set
  id: totrans-148
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-21。另一个用户请求相同的数据集。
- en: Provided her request is approved, on June 15 Mandy will get access to */Landing/DW/Customers*—a
    shared copy of the `Customers` table—as illustrated in [Figure 9-22](#both_users_will_use_the_same_copy_of_the).
    Mandy will continue to have access through July 14.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果她的请求得到批准，在6月15日，曼迪将获得对*/Landing/DW/Customers*的访问——一个`Customers`表的共享副本，如[图 9-22](#both_users_will_use_the_same_copy_of_the)所示。曼迪将继续在7月14日之前保持访问权限。
- en: '![Both users will use the same copy of the provisioned table](Images/ebdl_0922.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![两个用户将使用同一个预设表的副本](Images/ebdl_0922.png)'
- en: Figure 9-22\. Both users will use the same copy of the provisioned table
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-22。两个用户将使用同一个预设表的副本。
- en: On July 15, Mandy’s access will expire and Fred will once again be the only
    user of this data set, as illustrated in [Figure 9-23](#once_the_second_userapostrophes_access_h).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在7月15日，曼迪的访问将到期，弗雷德将再次成为这个数据集的唯一用户，如[图 9-23](#once_the_second_userapostrophes_access_h)所示。
- en: '![Once the second user’s access has expired, there will again be only one user
    with access to the data set](Images/ebdl_0923.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![第二个用户的访问权过期后，再次只有一个用户可以访问数据集](Images/ebdl_0923.png)'
- en: Figure 9-23\. Once the second user’s access has expired, there will again be
    only one user with access to the data set
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-23。第二个用户的访问权过期后，再次只有一个用户可以访问数据集。
- en: Fred will continue using this data set until August 4 and the data set will
    continue getting updated, as illustrated in [Figure 9-24](#the_data_set_will_continue_getting_updat).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 弗雷德将继续使用这个数据集直到8月4日，数据集将继续更新，如[图 9-24](#the_data_set_will_continue_getting_updat)所示。
- en: '![The data set will continue getting updated as long as there are any users
    using it](Images/ebdl_0924.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![只要有用户使用它，数据集将继续更新](Images/ebdl_0924.png)'
- en: Figure 9-24\. The data set will continue getting updated as long as there are
    any users using it
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-24。只要还有任何用户使用它，数据集将继续更新。
- en: Then, on August 5, Fred’s access will expire and there will be no users for
    this data set. The updates will stop until a new user requests it, as illustrated
    in [Figure 9-25](#once_there_are_no_more_users_using_the_d), or the system may
    continue updating it on a less frequent (say, monthly) basis.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在8月5日，弗雷德的访问权将到期，这个数据集将没有用户。更新将停止，直到有新用户请求它，如[图 9-25](#once_there_are_no_more_users_using_the_d)所示，或者系统可能以较少频率（比如每月）继续更新它。
- en: '![Once there are no more users using the data set, the updates will stop](Images/ebdl_0925.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![当没有更多用户使用数据集时，更新将停止](Images/ebdl_0925.png)'
- en: Figure 9-25\. Once there are no more users using the data set, the updates will
    stop
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-25。当没有更多用户使用数据集时，更新将停止。
- en: If a new user puts in a request for this table, it will be updated with any
    data that was added between August 5 (when the updates stopped) and the access
    request date—in the following example, August 15\. This way, the folder for August
    15 will have all the updates made between August 5 and 15, as illustrated in [Figure 9-26](#the_data_set_is_brought_up_to_date_once).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个新用户请求这个表格，它将更新到8月5日（更新停止时）和访问请求日期之间添加的任何数据——例如，8月15日的情况。这样，8月15日的文件夹将包含8月5日到15日之间所有的更新，如[图 9-26](#the_data_set_is_brought_up_to_date_once)所示。
- en: '![The data set is brought up to date once there is a new user for it](Images/ebdl_0926.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![一旦有新用户使用它，数据集将被更新](Images/ebdl_0926.png)'
- en: Figure 9-26\. The data set is brought up to date once there is a new user for
    it
  id: totrans-163
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-26。一旦有新用户使用它，数据集将被更新。
- en: Sometimes, it is desirable to keep each day’s batch in a separate folder named
    for that date. This helps tools such as Hive (SQL on Hadoop) decide which queries
    to execute against which partitions. In such cases, the data can still all be
    loaded on August 15, but for each day’s changes a separate partition can be created,
    as illustrated in [Figure 9-27](#each_dayapostrophes_updates_can_be_kept). Even
    though all the changes are extracted on August 15, each day’s changes (based,
    for example, on the change timestamp) are stored in a separate folder—August 6
    changes go into the *20180806* folder, August 7 changes go in *20180807*, and
    so on.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，将每天的批处理数据保存在以该日期命名的单独文件夹中是有益的。这有助于工具如Hive（Hadoop上的SQL）决定针对哪些分区执行查询。在这种情况下，数据仍然可以在8月15日全部加载，但每天的变更会在单独的分区中创建，例如图[9-27](#each_dayapostrophes_updates_can_be_kept)所示。尽管所有变更都是在8月15日提取的，每天的变更（例如基于更改时间戳）都存储在单独的文件夹中—8月6日的变更存放在*20180806*文件夹中，8月7日的变更存放在*20180807*文件夹中，依此类推。
- en: '![Each day’s updates can be kept in a separate partition](Images/ebdl_0927.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![每天的更新可以保存在单独的分区中](Images/ebdl_0927.png)'
- en: Figure 9-27\. Each day’s updates can be kept in a separate partition
  id: totrans-166
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-27\. 每天的更新可以保存在单独的分区中
- en: Conclusion
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Access control is one of the most critical aspects of the data lake to get right.
    By combining automation, on-demand self-service authorization techniques, and
    proactive sensitive data management, your organization can govern access to enormous
    and fast-changing collections of data efficiently and effectively.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 访问控制是数据湖中最关键的方面之一，必须做好。通过结合自动化、按需自助授权技术和积极的敏感数据管理，您的组织可以有效和高效地管理对庞大且快速变化的数据集的访问。
