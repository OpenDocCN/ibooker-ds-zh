- en: 14 Advanced building blocks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14 高级构建块
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Improving translation invariance with anti-aliased pooling
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用抗锯齿池化提高平移不变性
- en: Converging faster with improved residual connections
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过改进残差连接更快地收敛
- en: Fighting overfitting by mixing data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过混合数据来对抗过拟合
- en: The exercises in this book have thus far been designed so that you can learn
    about *real* techniques in a minimal amount of compute time. But when you work
    on real-world problems, they often require hundreds of epochs and models that
    are deeper than what you have trained so far, and they must process larger inputs
    than the examples in this book.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的练习迄今为止都是设计得让你可以在最少的计算时间内了解*真实*的技术。但是当你处理现实世界的问题时，它们通常需要数百个epoch和比你所训练的更深层次的模型，并且它们必须处理比本书中的示例更大的输入。
- en: 'When tackling these larger data sets, it sometimes takes extra tools to get
    the best results. This chapter covers some of the latest and greatest techniques
    that researchers have developed to improve deep learning models: techniques that
    often work best when training on larger data sets for many epochs. We focus on
    approaches that are simple, broadly useful, effective, and easy to implement.
    For these more advanced techniques, you often will not see the full benefit on
    smaller models or by training for only 10 to 20 epochs as we have for most of
    the book. In practice, these techniques bear the greatest fruit when training
    for 100 to 300 epochs. I have designed experiments to show some of the benefits
    in a relatively short amount of time, but you should expect more significant benefits
    on bigger problems.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理这些更大的数据集时，有时需要额外的工具来获得最佳结果。本章涵盖了研究人员为改进深度学习模型而开发的最新和最优秀的技巧：这些技巧在训练大型数据集的多个epoch时通常效果最佳。我们专注于简单、广泛适用、有效且易于实施的方法。对于这些更高级的技术，你通常不会在较小的模型或仅训练10到20个epoch（如本书大多数内容所示）时看到全部的好处。在实践中，这些技术在训练100到300个epoch时最能体现出其价值。我已经设计了实验，在相对较短的时间内展示了一些好处，但你应该期待在更大的问题上获得更显著的好处。
- en: 'We cover three approaches that you can safely add to almost any model and get
    a tangible improvement. Anti-aliasing pooling improves on the pooling operation
    we have been using, making it better for almost any CNN application. This pooling
    increases accuracy by better handling small shifts in the content of an image.
    Next, we look at a newer approach to residual connections called ReZero, allowing
    our networks a little more flexibility to decide when and how to use a skip connection.
    As a result, they are more accurate and converge in fewer epochs, simultaneously
    making learning faster. Finally, we talk about a new way to construct our loss
    functions: MixUp, the foundation for a growing approach to improving almost any
    neural network’s results by reducing overfitting.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了三种你可以安全地添加到几乎任何模型中并获得实质性改进的方法。抗锯齿池化改进了我们一直在使用的池化操作，使其更适合几乎任何CNN应用。这种池化通过更好地处理图像内容中的小位移来提高准确性。接下来，我们看看一种新的残差连接方法，称为ReZero，它让我们的网络在何时以及如何使用跳跃连接方面有更多的灵活性。因此，它们更准确，在更少的epoch中收敛，同时使学习更快。最后，我们讨论了一种构建损失函数的新方法：MixUp，这是通过减少过拟合来改进几乎任何神经网络结果的一种日益增长的方法的基础。
- en: 14.1 Problems with pooling
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.1 池化的问题
- en: 'Pooling was an early component of CNNs and has seen the least change over the
    years. As we discussed in chapter 3, pooling layers help us endow our models with
    translation invariance: they produce the same or a similar answer when we shift
    the content of an image up/down or left/right. They also increase the receptive
    field of postceding layers, allowing each convolutional layer to view more of
    the input at once and gain additional context. Despite their ubiquity, a subtle
    flaw has plagued CNNs for decades, and only recently have we noticed it and devised
    a simple solution. The crux of the problem is that naive pooling loses more information
    than necessary and introduces noise as a result. We walk through an example that
    demonstrates how this loss of information happens, and then we discuss the solution
    and develop a new pooling layer to fix it.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 池化是CNN的早期组成部分，并且在这些年里变化最少。正如我们在第3章中讨论的，池化层帮助我们赋予模型平移不变性：当我们上下或左右移动图像内容时，它们会产生相同或相似的答案。它们还增加了后续层的感受野，允许每个卷积层一次性查看更多的输入并获取额外的上下文。尽管它们无处不在，但一个微妙的缺陷已经困扰CNN数十年，而最近我们才注意到它并提出了一个简单的解决方案。问题的核心是，原始池化丢失了比必要更多的信息，并因此引入了噪声。我们通过一个示例来展示这种信息丢失是如何发生的，然后讨论解决方案并开发一个新的池化层来修复它。
- en: 'For the problem demonstration, we will download an image of a zebra from Wikipedia.[¹](#fn54)
    The fact that this is a zebra is important, as you’ll see in moment. The following
    code downloads the image from the given URL and converts it to a Python Imaging
    Library (PIL) image:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示问题，我们将从维基百科下载一张斑马的图片。[¹](#fn54) 这是一张斑马的事实很重要，您将在接下来的时刻看到。以下代码从给定的URL下载图片，并将其转换为Python
    Imaging Library (PIL)图像：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now we resize the image to 1,000 pixels on the shortest dimension and crop
    out the center content. The primary purpose of this step is to alter the code
    so you can try different images yourself afterward. The `ToTensor` transform then
    converts the PIL image to an appropriate PyTorch `Tensor` with its values scaled
    to the range [0,1]:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将图像的最短边调整到1,000像素，并裁剪出中心内容。这一步的主要目的是修改代码，以便您可以之后尝试不同的图像。然后`ToTensor`转换将PIL图像转换为适当的PyTorch
    `Tensor`，其值缩放到范围[0,1]：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Converts PIL images to PyTorch tensors
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将PIL图像转换为PyTorch张量
- en: ❷ Resizes the smallest dimension to 1,000 pixels
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将最短边调整到1,000像素
- en: ❸ Crops out the center 1, 000 × 1, 000 pixels
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 裁剪出中心1,000 × 1,000像素
- en: ❹ Combines all three transformation steps to convert the image
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将所有三个转换步骤组合起来以转换图像
- en: 'Next, a simple application of `ToPILImage` converts the image back into the
    original PIL image object. Jupyter notebooks are smart enough to display these
    images automatically, and you should see two zebras in the image. Notice that
    while the background content is fuzzy and out of focus, the zebras are crisp and
    well captured. Their fur and black-and-white stripes are clear and easy to see,
    including the more dense collection of stripes on their faces:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，简单应用`ToPILImage`将图像转换回原始的PIL图像对象。Jupyter笔记本足够智能，可以自动显示这些图像，您应该会看到图像中的两只斑马。注意，虽然背景内容模糊且不聚焦，但斑马清晰且捕捉得很好。它们的毛发和黑白条纹清晰易见，包括它们面部上更密集的条纹集合：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](../Images/CH14_UN01_Raff.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_UN01_Raff.png)'
- en: 'Now we use max pooling to shrink the image by a factor of four. We are shrinking
    it by four times instead of two to exacerbate the issue with pooling. The following
    code does the pooling and then prints the image, allowing us to see that something
    is definitely off:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用最大池化将图像缩小四倍。我们将其缩小四倍而不是两倍，以加剧池化的问题。以下代码执行池化并打印图像，使我们能够看到确实有问题：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ How much pooling to perform
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 执行多少池化
- en: ❷ Applies pooling
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 应用池化
- en: ❸ Resulting image
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 结果图像
- en: '![](../Images/CH14_UN02_Raff.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_UN02_Raff.png)'
- en: While the background still looks fine, the zebras have many pixelated patterns
    in their stripes, often called *jaggies*. The jaggies get worse where the black-and-white
    stripes are denser. They are noticeable, but not horrific, near the zebra’s rump;
    they’re distractingly bad toward the chest; and the faces look seriously garbled
    and lack any of the detail from the original photo.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然背景看起来仍然不错，但斑马的条纹中有很多像素化的图案，通常被称为*锯齿*。锯齿在黑白条纹较密集的地方会更严重。在斑马的臀部附近，它们是显而易见的，但并不可怕；靠近胸部时，它们会令人分心；而且面部看起来严重混乱，缺乏原始照片中的任何细节。
- en: This issue is called *aliasing*. A simplified explanation is that aliasing occurs
    when you try to *sample* fine, detailed information into a smaller space. We are
    emphasizing the word *sample* here because aliasing occurs when we are *selecting
    exact values* from a larger representation to fill out a smaller representation.
    This means many different inputs can result in the same block-like jaggies, and
    the more you try to shrink the input, the worse the problem gets.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题被称为**混叠**。一个简化的解释是，当你试图将精细、详细的信息采样到更小的空间时，就会发生混叠。我们在这里强调“采样”这个词，因为混叠发生在我们从更大的表示中选择精确值来填充较小的表示时。这意味着许多不同的输入可以导致相同的块状锯齿，而且你尝试缩小输入的程度越大，问题就越严重。
- en: Let’s look at a toy example of how aliasing occurs. Figure 14.1 shows three
    different one-dimensional patterns. The first has black and white blocks in a
    fixed pattern, alternating one after the other. The second shows the blocks in
    pairs of two, and the third has a pair of adjacent white blocks but no adjacent
    black blocks. Even though the patterns are different, simple max-pooling gives
    the same output for all of them.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个玩具示例，说明混叠是如何发生的。图 14.1 展示了三种不同的单维模式。第一种具有黑白块，以固定模式交替排列。第二种显示了成对的块，第三种有一对相邻的白色块但没有相邻的黑色块。尽管模式不同，简单的最大池化对所有这些模式都给出了相同的输出。
- en: '![](../Images/CH14_F01_Raff.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.2 混叠问题可能导致信息丢失的示例](../Images/CH14_F01_Raff.png)'
- en: Figure 14.2 Example of how the aliasing problem can lose information. Three
    different inputs go into the max-pooling layer, but we obtain three identical
    outputs. This is an extreme case, but it demonstrates the fundamental problem.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2 混叠问题可能导致信息丢失的示例。三个不同的输入进入最大池化层，但我们获得了三个相同的输出。这是一个极端情况，但它展示了基本问题。
- en: This is not great. But is it a problem? We have built several CNNs that seem
    to work fine, and people have been using max pooling for decades. Maybe this is
    not a big deal unless we want to build zebra detectors. While our CNNs work, the
    aliasing problem is real and gets worse every time we add another pooling layer
    to our architectures. By understanding why aliasing is a problem, we can build
    up the knowledge we need to understand how to fix the problem.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不好。但这是一个问题吗？我们已经构建了几个似乎工作得很好的 CNN，而且人们已经使用了最大池化几十年。也许这并不是一个大问题，除非我们想要构建斑马检测器。虽然我们的
    CNN 可以工作，但混叠问题确实是存在的，并且每次我们在架构中添加另一个池化层时，问题都会变得更糟。通过理解为什么混叠是一个问题，我们可以积累起我们需要了解如何解决问题的知识。
- en: 14.1.1  Aliasing compromises translation invariance
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.1  混叠问题损害了平移不变性
- en: To show why aliasing is an issue, we’ll use the CIFAR-10 data set due to its
    greater complexity compared to MNIST. CIFAR images have 32 × 32 height and width,
    but we select a smaller block of 24 × 24 pixels by taking a random crop of the
    image. (When taking smaller sub-images, it’s common practice to use a random crop
    for training for more diversity and a center crop for the test set to get consistent
    results.) This way, we can test our CNN on shifts of up to eight pixels top/down
    or left/right to see the impact that translating the image’s content has on the
    CNN’s predictions. Pooling is supposed to improve translation invariance (i.e.,
    you get the same result even if you shift things around), but we’ll show how aliasing
    prevents us from getting the full benefit.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明为什么混叠是一个问题，我们将使用 CIFAR-10 数据集，因为与 MNIST 相比，它具有更高的复杂性。CIFAR 图像的高度和宽度为 32
    × 32，但我们通过随机裁剪图像选择了一个较小的 24 × 24 像素块。（在获取较小的子图像时，通常的做法是使用随机裁剪进行训练以获得更多样性，并使用中心裁剪进行测试集以获得一致的结果。）这样，我们可以测试我们的卷积神经网络（CNN）在上下或左右方向上最多八像素的平移，以观察图像内容平移对
    CNN 预测的影响。池化应该提高平移不变性（即，即使你移动了东西，你也会得到相同的结果），但我们将会展示混叠如何阻止我们获得全部的好处。
- en: Note Training on crops that are slightly smaller than the original image size
    is a fairly common practice with images 128 × 128 or larger. Doing so provides
    extra diversity to your model’s inputs, avoids showing the exact same image multiple
    times as you progress through multiple epochs of training, and gives the model
    a little more realism (data is rarely nicely centered). We wouldn’t normally do
    this for an image as small as 32 × 32 because of how little content there is,
    but we need to so that we have pixels to shift.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在训练略小于原始图像大小的裁剪时，对于 128 × 128 或更大的图像，这是一种相当常见的做法。这样做可以为你的模型输入提供额外的多样性，避免在多个训练周期中多次显示完全相同的图像，并给模型带来更多的现实感（数据很少完美居中）。我们通常不会对如此小的
    32 × 32 像素图像这样做，因为内容很少，但我们需要这样做，以便我们有像素可以平移。
- en: 'The next block of code sets up CIFAR-10 with the sub-images we described. We
    use a random 24 × 24 crop during training, and we create two different versions
    of the same test set. In general, your test should be deterministic—you want to
    get the same results if you do the same thing. It would be very hard to determine
    whether a model change yielded any improvement if running the same model with
    the same weights gave a different test result each time. To make our test deterministic,
    our test loader takes a center crop so the test images are the same every time.
    But we also want to look at some of the results as different shifts occur, so
    we make a second version that returns the original 32 × 32 images: we can manually
    crop them to look at how shifts change the model’s predictions:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 下一段代码设置了 CIFAR-10，使用我们描述的子图像。我们在训练期间使用随机的 24 × 24 裁剪，并创建了相同测试集的两个不同版本。一般来说，你的测试应该是确定的——如果你做同样的事情，你希望得到相同的结果。如果用相同的权重运行相同的模型每次都给出不同的测试结果，那么确定模型变化是否带来了任何改进是非常困难的。为了使我们的测试确定，我们的测试加载器采用中心裁剪，这样测试图像每次都是相同的。但我们也想看看一些结果，因为不同的偏移发生时，我们制作了一个第二个版本，它返回原始的
    32 × 32 图像：我们可以手动裁剪它们来查看偏移如何改变模型的预测：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '❶ Transform for training: random crop to PyTorch tensor'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 训练时的转换：随机裁剪到 PyTorch 张量
- en: '❷ Transform for testing: crops the center to a PyTorch tensor'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 测试时的转换：将中心裁剪到 PyTorch 张量
- en: ❸ A version of the test set with full 32 × 32 images, so we can test specific
    crops
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 一个包含完整 32 × 32 图像的测试集版本，这样我们就可以测试特定的裁剪
- en: ❹ The test loader used during evaluation is the deterministic center crop.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 评估期间使用的测试加载器是确定性的中心裁剪。
- en: ❺ Maps the class index back to their original names for CIFAR-10
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将 CIFAR-10 的类别索引映射回其原始名称
- en: 'Let’s see what the data looks like with our random cropping. The following
    code selects the same image from the training set four times and then plots it
    with the class label. Each time, the image is shifted a bit, adding extra complexity:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看使用我们的随机裁剪后数据看起来像什么。以下代码从训练集中选择相同的图像四次，然后与类别标签一起绘制。每次，图像都会稍微移动一下，增加额外的复杂性：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Makes a 1 × 4 grid
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 制作一个 1 × 4 的网格
- en: ❷ Grabs a specific item from the training set (I like planes)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从训练集中抓取一个特定的项目（我喜欢飞机）
- en: ❸ Reorders to the (W, H, C) shape that NumPy and Matplotlib like for images
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 重新排序到 NumPy 和 Matplotlib 喜欢的 (W, H, C) 形状，用于图像
- en: ❹ Plots with the class name in the corner
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在角落绘制带有类别名称的图表
- en: '![](../Images/CH14_UN03_Raff.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_UN03_Raff.png)'
- en: 'Now let’s train a simple network using convolutions and the allegedly flawed
    max pooling. We use just two rounds of max pooling here, equivalent to the same
    amount of pooling we used for the example with the zebra. This is enough to demonstrate
    the problems with pooling even on non-zebra inputs. In general, the issues become
    worse with even more pooling. In this code, and throughout this chapter, we add
    our trusty `CosineAnnealingLR` scheduler from chapter 6\. It helps maximize the
    results and allows us to show in only 30 epochs some behaviors that are usually
    seen only after 100 epochs of training (that doesn’t mean you shouldn’t do 100
    epochs on a real production problem, just that we can show the kind of behavior
    more quickly this way). Here’s the code:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用卷积和据说有缺陷的最大池化来训练一个简单的网络。我们在这里只使用两轮最大池化，相当于我们用于斑马示例中相同数量的池化。这足以展示池化在非斑马输入上的问题。一般来说，问题随着更多的池化而变得更加严重。在这段代码和本章的其余部分中，我们添加了第
    6 章中我们信任的 `CosineAnnealingLR` 调度器。它有助于最大化结果，并允许我们在仅 30 个周期内展示一些通常在训练 100 个周期后才能看到的行为（这并不意味着你不应该在实际生产问题上进行
    100 个周期的训练，只是我们可以更快地展示这种行为）。以下是代码：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Number of input channels
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 输入通道的数量
- en: ❷ Number of channels in the hidden layer
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 隐藏层的通道数
- en: ❸ Helper function as we have done many times
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 作为我们多次做过的辅助函数
- en: ❹ A normal CNN with blocks of two CNN layers separated by max pooling
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 一个正常的 CNN，由两个 CNN 层块组成，层块之间有最大池化
- en: ❺ ![](../Images/CH14_F01_EQ01.png)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ ![](../Images/CH14_F01_EQ01.png)
- en: ❻ Sets up our optimizer with a learning rate scheduler to maximize performance
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 设置我们的优化器，带有学习率调度器以最大化性能
- en: ❼ Trains our model as usual
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 按常规训练我们的模型
- en: 'We have trained our model, and currently nothing *seems* out of place. The
    accuracy increased regularly with each epoch of training, which is normal and
    good. This data set is more challenging than MNIST, so getting 74.35% accuracy
    is reasonable. The issue occurs when we look at different versions of the same
    image:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经训练了我们的模型，目前看起来没有*问题*。随着每个训练周期的增加，准确率稳步提高，这是正常且好的。这个数据集比MNIST更具挑战性，因此获得74.35%的准确率是合理的。问题出现在我们查看同一图像的不同版本时：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/CH14_UN04_Raff.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_UN04_Raff.png)'
- en: 'The following code takes one of the full 32 × 32 images from the test set and
    makes a prediction on all 64 possible 24 × 24 sub-images. That’s done with the
    `x_crop` variable that is passed into the network, and the probability of the
    correct class is computed with `prob_y`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码从测试集中取一个完整的32 × 32图像，并对所有64个可能的24 × 24子图像进行预测。这是通过将`x_crop`变量传递到网络中完成的，并且使用`prob_y`计算正确类别的概率：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Test image to grab
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 要抓取的测试图像
- en: ❷ Gets the original 32 × 32 image
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取原始32 × 32图像
- en: ❸ Saves the prediction for each 24 × 24 sub-image
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 保存每个24 × 24子图像的预测
- en: ❹ For up/down shifts
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 对于上下位移
- en: ❺ For left/right shifts
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 对于左右位移
- en: ❻ Grabs the cropped image
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 抓取裁剪的图像
- en: ❼ Classifies the image and gets the probability of the correct class
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 对图像进行分类并获取正确类别的概率
- en: ❽ Saves the resulting score
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 保存结果分数
- en: 'Now we plot all 64 images, and above each image, we show the model’s probability
    of predicting the correct class. Visually, these images are almost identical because
    they are all sub-images of the same original input. We should get similar predictions
    for *all* of them because they are essentially the same:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们绘制所有64张图像，并在每张图像上方显示模型预测正确类别的概率。从视觉上看，这些图像几乎完全相同，因为它们都是相同原始输入的子图像。我们应该对*所有*它们得到相似的预测，因为它们本质上都是相同的：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ 8 × 8 grid of images
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 8 × 8的图像网格
- en: ❷ For each row
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 对于每一行
- en: ❸ Keeps track of which specific shift we are accessing
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 跟踪我们访问的具体位移
- en: ❹ Grabs the next eight images to fill out the columns
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 抓取下一个八个图像以填充列
- en: ❺ Plots the 24 × 24 sub-image
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 绘制24 × 24的子图像
- en: ❻ Prints the probability of the correct class in the top left
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 在左上角打印正确类别的概率
- en: ❼ Moves to the next image position
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 移动到下一个图像位置
- en: '![](../Images/CH14_UN05_Raff.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_UN05_Raff.png)'
- en: 'Can you see the problem? While the model is always *correct* (this time), its
    confidence can change dramatically, fluctuating from 34.84% to 99.48% confidence
    about the image being a truck. This is the problem with max pooling: it’s not
    *actually* translation-invariant. If it was, we’d get the same confidence score
    for each of these images. You can try changing the `test_img_id` variable to see
    this occurs with other test images as well. Now we know that max pooling does
    not provide good translation invariance; the degree of failure is much larger
    than we would like.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你能看到问题吗？虽然模型总是*正确*的（这次），但其置信度可以发生剧烈变化，从34.84%的置信度波动到99.48%的置信度，认为图像是一辆卡车。这是最大池化的问题：它实际上并不是平移不变的。如果它是，我们会对这些图像中的每一个得到相同的置信度分数。你可以尝试更改`test_img_id`变量，看看其他测试图像是否也会出现这种情况。现在我们知道最大池化不能提供良好的平移不变性；失败的程度比我们希望的更大。
- en: 14.1.2  Anti-aliasing by blurring
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.2  通过模糊进行反走样
- en: We can build a better version of pooling if we don’t *just* select the maximum
    value. Remember back in chapter 4 when we used a handcrafted convolution to blur
    the input? Blurring has the effect of mixing information between adjacent locations.
    If we first do some blurring to mix information, we can get our pooling to differentiate
    between patterns that would typically cause aliasing. Let’s walk through how blurring
    can help us build a better pooling operation that is robust against the aliasing
    problem and can be used as a drop-in replacement for max pooling.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不仅仅选择最大值，我们可以构建一个更好的池化版本。记得在第四章我们使用手工卷积来模糊输入吗？模糊的效果是混合相邻位置之间的信息。如果我们首先进行一些模糊以混合信息，我们可以在池化中区分那些通常会导致混叠的模式。让我们看看模糊如何帮助我们构建一个更好的池化操作，它可以抵抗混叠问题，并且可以作为最大池化的直接替代：
- en: Figure 14.2 shows how we can use blurring for the same 1D sequences we showed
    in figure 14.1\. Remember that these patterns originally all resulted in the same
    output when we used standard max pooling. In this case, we will still use max
    pooling, but we will use `stride=1` (with padding) so the output is the same size
    as the input. This gives us a new representation that returns the maximum for
    every possible local area.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2 展示了我们可以如何使用模糊来处理我们在图 14.1 中展示的相同 1D 序列。记住，这些模式最初在使用标准最大池化时都产生了相同的输出。在这种情况下，我们仍然会使用最大池化，但我们将使用
    `stride=1`（带有填充）以确保输出与输入大小相同。这给我们提供了一个新的表示，它返回每个可能局部区域的最大值。
- en: '![](../Images/CH14_F02_Raff.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F02_Raff.png)'
- en: 'Figure 14.2 An approach to max pooling that helps mitigate aliasing: also called
    *anti-aliasing*. First we do max pooling with a stride of 1 to get an output the
    same size as the input. Then we apply a blurring kernel/convolution with a stride
    of 2, which shrinks the output to the desired size and maintains the behavior
    of max pooling but allows us to delineate that the three outputs came from three
    different inputs. This approach captures more information than naive max pooling.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2 一种帮助减轻混叠的最大池化方法：也称为 *反混叠*。首先，我们使用步长为 1 的最大池化来获得与输入相同大小的输出。然后，我们应用步长为
    2 的模糊内核/卷积，这缩小了输出到所需的大小，并保持了最大池化的行为，但允许我们区分三个输出来自三个不同的输入。这种方法比简单的最大池化捕获更多的信息。
- en: 'Normal max pooling takes every other max value because we use 2 as the input
    to say we want to reduce each dimension by a factor of 2\. Instead, we *average*
    the max values in groups to select the final representation. For the left-most
    example, this has no impact on the output. But it does change the other two examples:
    the middle example’s output now has a black-and-gray pattern corresponding to
    the locations with more white cells. This allows us to better differentiate these
    similar patterns and reduce the aliasing issues that occur.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正常的最大池化会取每隔一个的最大值，因为我们使用 2 作为输入来说明我们想要将每个维度减少 2 倍。相反，我们会在组内 *平均* 最大值以选择最终表示。对于最左边的示例，这不会影响输出。但它确实改变了其他两个示例：中间示例的输出现在有一个黑白图案，对应于白色细胞较多的位置。这使我们能够更好地区分这些相似的模式，并减少出现的混叠问题。
- en: We need a function that performs blurring. As we saw in chapter 3 on CNNs, it
    is possible to perform blurring using a convolution with the right kernel. Which
    one should we choose? Richard Zhang, who showed how to fix this problem,[²](#fn55)
    used a binomial filter slightly larger than the pooling size. A binomial filter
    puts the majority of weight in the center and decreases the weight for items that
    are further away so the blurring focuses on items at the current location instead
    of far-away cases. For a 1D filter with a size of k, the ith binomial filter value
    is equal to
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个执行模糊的函数。正如我们在第 3 章关于卷积神经网络中看到的，使用正确的内核进行卷积可以执行模糊。我们应该选择哪一个？Richard Zhang，他展示了如何解决这个问题[²](#fn55)，使用了一个略大于池化大小的二项式滤波器。二项式滤波器将大部分权重放在中心，并减少远离项的权重，因此模糊集中在当前位置的项上，而不是远处的案例。对于大小为
    k 的 1D 滤波器，第 i 个二项式滤波器值等于
- en: '![](../Images/CH14_F02_EQ01.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F02_EQ01.png)'
- en: 'For *k* = 2 to *k* = 7, the following table shows the filter values. The largest
    values are always in the middle, and the values decrease toward the edges. The
    result is a weighted average that puts the most emphasis on the values where the
    filter is currently located, slowly decreasing to further-away items. That’s what
    yields the blurring effect that will help us resolve the aliasing issue:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 *k* = 2 到 *k* = 7，下表显示了滤波器的值。最大的值总是在中间，而值向边缘递减。结果是加权平均值，它将最大的重点放在滤波器当前所在的位置的值上，然后逐渐减少到更远的项。这就是产生模糊效果的原因，这将帮助我们解决混叠问题：
- en: '![](../Images/CH14_F02_EQ02.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F02_EQ02.png)'
- en: Lucky for us, this pattern matches what is known as the *binomial distribution*
    (after we divide by the sum of all k values so they add up to 1.0), which is conveniently
    implemented in the SciPy library. We can thus use this to implement a new `BlurLayer`.
    We give it an input option for `D`, the number of dimensions in our input data
    (one, two, or three), a `kernel_size` that tells how wide to make the binomial
    filter kernel, and a `stride` that controls how much to shrink the input. Both
    `kernel_size` and `stride` act the same way convolutional layers do.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这个模式与所谓的*二项分布*（在我们除以所有k值的总和，使它们加起来为1.0之后）相匹配，SciPy库方便地实现了这个分布。因此，我们可以使用它来实现一个新的`BlurLayer`。我们为它提供了一个输入选项`D`，即我们输入数据的维度数（一维、二维或三维），一个`kernel_size`，它告诉二项滤波器核有多宽，以及一个`stride`，它控制输入的缩小程度。`kernel_size`和`stride`的作用方式与卷积层相同。
- en: 'Here’s the code:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Makes a 1D binomial distribution. This computes the normalized filter_i value
    for all k values.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个1D二项分布。这计算了所有k值的归一化filter_i值。
- en: ❷ z is a 1D filter.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ z是一个1D滤波器。
- en: ❸ Invalid option for D!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ D的无效选项
- en: ❹ We are good.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 我们做得很好。
- en: ❺ The 2D filter can be made by multiplying two 1D filters.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 2D滤波器可以通过乘以两个1D滤波器来创建。
- en: ❻ The 3D filter can be made by multiplying the 2D version with a 1D version.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 3D滤波器可以通过将2D版本与1D版本相乘来创建。
- en: ❼ Applying the filter is a convolution, so we save the filter as a parameter
    in this layer. Requires_grad=False because we don’t want it to change.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 应用滤波器是一个卷积，因此我们将滤波器作为此层的参数保存。`requires_grad=False`，因为我们不希望它改变。
- en: ❽ How many channels?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 有多少个通道？
- en: ❾ How wide was our internal filter?
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 我们内部滤波器的宽度是多少？
- en: ❿ The groups argument is used to apply the single filter to every channel, since
    we don’t have multiple filters like a normal convolutional layer.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❿ 使用`groups`参数将单个滤波器应用于每个通道，因为我们没有像正常卷积层那样的多个滤波器。
- en: '⓫ We should never reach this code: if we do, we know we have a bug!'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ⓫ 我们永远不应该到达这段代码：如果我们做到了，我们知道我们有一个错误！
- en: '⓬ All three calls are the same: we just need to know which conv function to
    call.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ⓬ 所有三次调用都是相同的：我们只需要知道要调用哪个卷积函数。
- en: 'With this `BlurLayer`, we can implement the strategy we discussed for fixing
    max pooling’s aliasing problem. First, let’s try it on the original zebra image
    to show that it works. We again call `max_pool2d`, but we set `stride=1` so the
    image is not made any smaller. After that, we create a `BlurLayer` and make the
    kernel size as large as or larger than the factor we want to shrink by. That means
    if we want to pool by a factor of z, our blurring filter should have a `kernel_size`
    ≥ *z*. The `stride` of the `BlurLayer` is then set to how much we want to shrink
    by:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个`BlurLayer`，我们可以实现我们之前讨论的用于修复最大池化插值问题的策略。首先，让我们尝试在原始斑马图像上应用它，以证明其有效性。我们再次调用`max_pool2d`，但我们将`stride=1`设置为不缩小图像。之后，我们创建一个`BlurLayer`，并将核大小设置为我们要缩小的因子大小或更大。这意味着如果我们想以z的因子进行池化，我们的模糊滤波器的`kernel_size`应该≥
    *z*。然后，将`BlurLayer`的`stride`设置为我们要缩小的量：
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Applies max pooling with a stride of 1
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 以1的步长应用最大池化
- en: ❷ Blurs the max pooling result
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 模糊最大池化结果
- en: ❸ Shows the result
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 展示结果
- en: '![](../Images/CH14_UN06_Raff.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_UN06_Raff.png)'
- en: The image of the zebra is much cleaner. Ugly jaggies no longer cover the zebras
    (there are still some blocks, but not nearly as many as in the original). If we
    look at the zebra’s mane or face, it is difficult to tell how dense the stripe
    pattern is, but it at least looks smooth. Also, before, it was hard to see any
    difference between the pattern on the zebra’s face and that on its chest and front
    legs—the blocky output made it difficult to tell what was going on. With anti-aliasing,
    we can distinguish that the face must have a very fine level of detail and a dense
    pattern, and the torso’s pattern has more changes in angle.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 斑马的图像变得更加清晰。丑陋的锯齿状不再覆盖斑马（仍然有一些块，但远没有原始图像中的那么多）。如果我们观察斑马的鬃毛或面部，很难判断条纹图案的密度，但至少看起来很平滑。此外，在此之前，很难区分斑马面部和胸部的图案，以及前腿的图案——块状输出使得很难判断发生了什么。有了抗锯齿，我们可以区分出面部必须具有非常精细的细节级别和密集的图案，而躯体的图案在角度上有更多变化。
- en: 'It is also worth noticing the grass and the trees in the background. The trees
    look similar in both images because they were out of focus in the original image:
    they were effectively pre-blurred. The grass in the foreground looks subtly different
    than the original pooled image, again because our new approach is anti-aliasing
    the image.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是背景中的草地和树木。由于原始图像中的树木模糊，两种图像中的树木看起来很相似：它们实际上被预先模糊处理了。前景中的草地看起来与原始池化图像略有不同，这再次是因为我们新的方法是对图像进行抗锯齿处理。
- en: 14.1.3  Applying anti-aliased pooling
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.1.3 应用抗锯齿池化
- en: 'Now that we have shown that max pooling has a problem, we can create a new`MaxPool2dAA`
    (the AA stands for anti-aliasing) to use as a drop-in replacement for the original
    `nn.MaxPool2d`. The first argument is how much we want to pool by, just like in
    the original. We also include a `ratio` that controls how much larger the blur
    filter should be than the shrinking ratio. We set it to a reasonable default of
    1.7× larger. This way, if we want to pool by a larger amount, the code will automatically
    select a larger filter size for the blurring:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经证明了最大池化存在问题，我们可以创建一个新的`MaxPool2dAA`（AA代表抗锯齿），用作原始`nn.MaxPool2d`的替代品。第一个参数是我们想要池化的程度，就像原始版本一样。我们还包含一个`ratio`，它控制模糊滤波器应该比缩小比例大多少。我们将其设置为合理的默认值1.7倍更大。这样，如果我们想要池化更大的量，代码将自动选择更大的滤波器尺寸进行模糊：
- en: '[PRE12]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Makes a slightly larger filter for blurring
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用稍大的滤波器进行模糊
- en: ❷ Creates the blur kernel
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建模糊核
- en: ❸ Stores the pooling size
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 存储池化大小
- en: ❹ Applies pooling with stride=1
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用步长=1进行池化
- en: ❺ Blurs the result
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 模糊结果
- en: 'Next we can define the `aaPool_CNN` model from our first network, except that
    we replace every pooling operation with our new anti-aliasing version. The rest
    of the training code is also identical:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以定义来自我们第一个网络的`aaPool_CNN`模型，除了我们将每个池化操作替换为我们的新抗锯齿版本。其余的训练代码也是相同的：
- en: '[PRE13]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Same architecture as usual, but replaces pooling with our anti-aliased version
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 与常规架构相同，但用我们的抗锯齿版本替换池化
- en: 'When we look at the training results, the anti-aliased model is almost always
    ahead of the regular version of the network. Both models have the same number
    of layers and the same number of parameters to learn, so this impact is due entirely
    to changing the pooling operation:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看训练结果时，抗锯齿模型几乎总是优于网络的常规版本。这两个模型具有相同数量的层和相同数量的参数需要学习，因此这种影响完全是由于改变了池化操作：
- en: '[PRE14]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](../Images/CH14_UN07_Raff.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH14_UN07_Raff.png)'
- en: 'The new `aaPool_CNN` converges to a better solution more quickly: it reaches%
    accuracy after 30 epochs. That alone is a reason to use this approach as a replacement
    for regular pooling. But we do not know if it solved the translation problem.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 新的`aaPool_CNN`更快地收敛到更好的解决方案：在30个epoch后达到%准确率。这本身就是一个使用这种方法作为常规池化的替代品的原因。但我们不知道它是否解决了翻译问题。
- en: 'Now let’s look at how shifting the image changes the predictions of our new
    model. The following code runs the same test on `test_img_id` from the test set,
    calculating the model’s confidence of the correct class for all 64 possible shifts.
    Then we plot the probability of the correct class on the y-axis; the x-axis shows
    how many pixels we have shifted. Ideally, we should see a solid line vertically
    across the plot, indicating that the model consistently returns the same result:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看图像移动如何改变我们新模型的预测。以下代码对测试集中的`test_img_id`执行相同的测试，计算模型对所有64种可能的移动的正确类别的置信度。然后我们在y轴上绘制正确类别的概率；x轴显示我们移动了多少像素。理想情况下，我们应该在图表上看到一条垂直的实线，表明模型始终返回相同的结果：
- en: '[PRE15]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Gets the original 32 × 32 image
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取原始32 × 32图像
- en: ❷ Saves the prediction for each 24 × 24 sub-image
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 保存每个24 × 24子图像的预测
- en: ❸ For up/down shifts
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 用于上下移动
- en: ❹ For left/right shifts
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 用于左右移动
- en: ❺ Grabs the cropped image
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 获取裁剪的图像
- en: ❻ Classifies the image and gets the probability of the correct class
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 对图像进行分类并获取正确类别的概率
- en: ❼ Saves the resulting score
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 保存结果分数
- en: '![](../Images/CH14_UN08_Raff.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH14_UN08_Raff.png)'
- en: In this plot, `aaPool_CNN` does much better. While it does not solve the aliasing
    problem perfectly, the predictions returned are more consistent than the original
    model. If you try changing the `test_img_id`, you should see that this is usually
    the case, but not always. If we trained for more epochs, say 100, the consistency
    of the `aaPool_CNN`’s predictions would continue to increase, while the original
    CNN would always suffer from aliasing problems.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图中，`aaPool_CNN`表现得更好。虽然它并没有完美地解决混叠问题，但返回的预测比原始模型更一致。如果你尝试更改`test_img_id`，你应该会看到这种情况通常如此，但并非总是如此。如果我们训练更多的周期，比如说100个，`aaPool_CNN`的预测一致性将继续增加，而原始CNN将始终受到混叠问题的困扰。
- en: Note When you tackle specific problems like translation invariance, results
    can improve in sometimes unintuitive ways. Maybe the original model fluctuated
    between 60 and 95% probability, but the new model steadily returns a 40% probability
    of the correct class. That means the original model was *more accurate* on that
    sample, but the new model is *more consistent*. This can happen, but we make the
    change in the belief that greater consistency and robustness to translations *should*
    be correlated with better results *most* of the time.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：当你解决像平移不变性这样的具体问题时，结果有时可能会以不太直观的方式改善。也许原始模型在60%到95%的概率之间波动，但新模型稳定地返回正确类别的40%概率。这意味着原始模型在该样本上更**准确**，但新模型更**一致**。这种情况可能会发生，但我们相信，更高的一致性和对平移的鲁棒性应该与更好的结果**大多数时候**相关。
- en: 'These aliasing problems can also occur when we use a convolution with a stride
    ≥ 2 or with average pooling. The `nn.AvgPool2d` layers can be replaced with a
    `BlurLayer` to reduce the impact. Strided convolutions (i.e., `stride`=s) are
    fixed the same way we fixed max pooling: replace the convolution’s original stride
    with `stride=1`, apply any normalization and activation function, and then end
    with a `BlurLayer` with `kernel_size`=s.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用步长≥2的卷积或平均池化时，这些混叠问题也可能发生。可以使用`BlurLayer`替换`nn.AvgPool2d`层来减少影响。步长卷积（即`stride`=s）的修复方式与修复最大池化相同：将卷积的原始步长替换为`stride=1`，应用任何归一化和激活函数，然后以`kernel_size`=s的`BlurLayer`结束。
- en: This approach to fixing max pooling is very recent, invented in 2019 and published
    in a top-tier conference’s proceedings. If you made it this far and felt like
    you understood, congratulations—you can now comprehend and appreciate cutting-edge
    deep learning research!
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这种修复最大池化的方法非常新颖，是在2019年发明并在顶级会议的论文集中发表的。如果你已经读到这儿并且感觉你理解了，恭喜你——你现在可以理解和欣赏前沿的深度学习研究了！
- en: 14.2 Improved residual blocks
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.2 改进的残差块
- en: The next two techniques require larger networks and problems to see their full
    benefit. We still use CIFAR-10 and can show some of their improvements, but they
    are even more successful on larger and more challenging problems. We will start
    with improved residual blocks, which we first learned about in chapter 6\. The
    residual strategy generally looks like the equation
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两种技术需要更大的网络和问题才能看到它们的全部好处。我们仍然使用CIFAR-10，并可以展示它们的一些改进，但它们在更大和更具挑战性的问题上表现得更加成功。我们将从改进的残差块开始，这是我们在第6章首次了解到的。残差策略通常看起来像以下方程
- en: '**h** = ReLU(**x**+*F*(**x**))'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**h** = ReLU(**x**+*F*(**x**))'
- en: where *F*(⋅) represents a small sequence of convolutions, normalization, and
    activation functions repeated twice. This creates skip connections in the network,
    which makes it easier to learn deeper networks with more layers. These deeper
    networks also tend to converge faster and to a better-quality solution.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *F*(⋅) 代表一系列重复两次的卷积、归一化和激活函数的小序列。这会在网络中创建跳跃连接，使得学习具有更多层的深层网络更容易。这些深层网络也倾向于更快地收敛到更好的解决方案。
- en: There is nothing particularly wrong with residual connections. As we mentioned
    before, they are very effective and have been adapted to many other architectures
    (e.g., U-Net and transformers). But a few small adjustments can provide a consistent
    improvement in results with a nice intuitive logic.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余连接并没有什么特别的问题。正如我们之前提到的，它们非常有效，并且已经被应用于许多其他架构（例如U-Net和transformers）。但是，一些小的调整可以在结果上提供一致的改进，并且具有很好的直观逻辑。
- en: A technique called *ReZero*[³](#fn56) can further improve the residual approach
    to converge even faster and to even better solutions. The approach is shockingly
    simple and easy to integrate into your residual block’s definition. The idea is
    that the path *F*(**x**) is noisy and may add unnecessary complexity to our computations,
    at least early on. We would rather the network start simple and gradually introduce
    complexity as needed to solve the problem at hand. Think of it like building a
    solution one piece at a time rather than trying to build everything at once.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一种称为 *ReZero*[³](#fn56) 的技术可以进一步改进残差方法，使其收敛得更快，并得到更好的解决方案。这种方法简单得惊人，并且很容易集成到你的残差块定义中。其想法是路径
    *F*(**x**) 是有噪声的，可能会给我们的计算增加不必要的复杂性，至少在早期是这样。我们更希望网络从简单开始，根据需要逐步引入复杂性来解决手头的问题。把它想象成一次构建一个解决方案，而不是试图一次性构建一切。
- en: 'This is accomplished using the following equation, where α is a parameter learned
    by the network, but we initialize *α* = 0 at the start of training:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过以下方程实现的，其中 α 是网络学习的参数，但我们初始化 *α* = 0 作为训练的开始：
- en: '**h** = **x** + *α* ⋅ ReLU(*F*(**x**))'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**h** = **x** + *α* ⋅ ReLU(*F*(**x**))'
- en: Because *α* = 0, at the start we get the simplified network **h** = **x**. *This
    has done nothing to the input*. If all of our layers looked like this, then they
    might as well not exist—we would get the same answer if they were removed, since
    nothing was altered. But during gradient descent, the value of α is altered, and
    suddenly the inner term of ReLU(*F*(**x**)) activates and begins to contribute
    to the solution. The network can choose how much emphasis to put on the nonlinear
    operations in this term or focus on the original value x by changing the magnitude
    of α (positive or negative). The larger it gets, the more the network uses the
    computations in *F*(⋅).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 *α* = 0，所以在开始时我们得到简化的网络 **h** = **x**。*这并没有对输入造成任何影响*。如果我们的所有层都像这样，那么它们可能根本不存在——如果我们移除它们，我们仍然会得到相同的答案，因为没有任何东西被改变。但在梯度下降过程中，α
    的值会改变，突然 ReLU(*F*(**x**)) 的内部项开始激活并开始对解决方案做出贡献。网络可以选择在这个项中对非线性操作给予多少重视，或者通过改变
    α（正或负）的大小来关注原始值 x。它越大，网络就越使用 *F*(⋅) 中的计算。
- en: 14.2.1  Effective depth
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.1 有效深度
- en: The benefits of ReZero are subtle, so let’s annotate the equation and walk through
    it in more detail before we implement it. We have the ReZero residual equation
    as
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ReZero 的好处是微妙的，所以在我们实现它之前，让我们先注释方程并更详细地解释它。我们有 ReZero 残差方程如下
- en: '![](../Images/CH14_UN09_Raff.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH14_UN09_Raff.png)'
- en: The fact that we set *α* = 0 at the start of training, instead of a random value,
    is the critical thing here. If *α* = 0, we get **h** = *x*, which is the simplest
    possible function because it *does not do anything*. How can this be helpful?
    Let’s study the architecture created by ReZero in figure 14.3 to understand how
    this is a benefit. At first glance, it seems very similar to regular residual
    connections.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在训练开始时将 *α* = 0 设置为初始值，而不是随机值，这是这里的关键。如果 *α* = 0，我们得到 **h** = *x*，这是最简单的可能函数，因为它
    *什么也不做*。这有什么帮助呢？让我们研究 ReZero 在图 14.3 中创建的架构，以了解这是如何成为一项好处的。乍一看，它似乎与常规残差连接非常相似。
- en: '![](../Images/CH14_F03_Raff.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH14_F03_Raff.png)'
- en: Figure 14.3 Architecture of ReZero for two layers of a network. The shortcut
    path at the top allows easy gradient flow to the layers, and the long path at
    the bottom does all heavy work. Instead of simply adding back in the results of
    the subnetworks from the long path, we multiply them by α before adding them back
    in.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.3 ReZero 网络两层架构。顶部的快捷路径允许轻松的梯度流向层，底部的长路径做所有重工作。我们不是简单地添加长路径中子网络的输出结果，而是在添加之前将它们乘以
    α。
- en: The elegance is that this does not do anything *at first*. Because the α value
    is set to *α* = 0 at the start, the subnetworks are all effectively gone, leaving
    us with a *linear* architecture, as demonstrated in figure 14.4\. This is one
    of the simplest possible architectures we could create, which means initial learning
    happens very quickly because the total number of effective parameters is minimized.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 其优雅之处在于它一开始并没有做什么。因为 α 值一开始被设置为 *α* = 0，子网络都实际上消失了，留下我们一个 *线性* 架构，如图 14.4 所示。这是我们能够创建的最简单的架构之一，这意味着初始学习发生得非常快，因为有效参数的总数被最小化了。
- en: '![](../Images/CH14_F04_Raff.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH14_F04_Raff.png)'
- en: Figure 14.4 ReZero’s behavior at the start of training for two layers of a network.
    The shortcut path at the top make a single linear layer (**x**^((1)) = **x**^((2)))
    because nothing is added into them. The subnetworks in the long path are effectively
    gone because their contributions were multiplied by *α* = 0.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4 ReZero在训练开始时两个网络层的表现。顶部的快捷路径形成一个单一的线性层（**x**^((1)) = **x**^((2)))，因为没有任何东西被添加到它们中。长路径中的子网络实际上已经不存在了，因为它们的贡献被乘以*α*
    = 0。
- en: But as training happens, the gradient descent process may alter the α values.
    Once α is altered, the subnetwork *F*(*x*) begins to contribute. So the approach
    begins as a linear model (all *α* = 0 and does nothing) and slowly becomes more
    complex over time. The impact is shown in figure 14.5.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 但随着训练的进行，梯度下降过程可能会改变α的值。一旦α被改变，子网络*F*(*x*)就开始做出贡献。因此，这种方法开始时是一个线性模型（所有*α* =
    0且不起作用），随着时间的推移逐渐变得更加复杂。影响如图14.5所示。
- en: '![](../Images/CH14_F05_Raff.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F05_Raff.png)'
- en: Figure 14.5 ReZero architecture with several epochs of training. As the model
    trains, it can learn to change each α independently, slowly adding hidden layers
    back into the network. This way, it gradually learns to use the depth and select
    the total effective depth it desires based on the data. In this case, ReZero learned
    that it only needed one of its layers; for the second, it learned to keep *α*
    ≈ 0.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.5 ReZero架构，展示了几个训练周期的训练情况。随着模型的训练，它可以学会独立地改变每个α，慢慢地将隐藏层重新添加到网络中。这样，它逐渐学会使用深度并基于数据选择它希望使用的总有效深度。在这种情况下，ReZero学习到它只需要它的一个层；对于第二个，它学会了保持*α*
    ≈ 0。
- en: After several epochs of training, we have the resulting effective structure.
    Each residual block’s α value may have learned a different value, deciding when
    to begin contributing to the solution. This also means a value of alpha may still
    be near zero, so it effectively does not exist. ReZero lets our network decide
    on its own how many layers of residual blocks to use and when to use them. It
    may choose not to set *any* of the α values to be near zero, which is also fine.
    Sometimes it is easier to learn how to use all the layers by starting small and
    growing more complex over time, which ReZero allows.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 经过几个训练周期后，我们得到了最终的有效结构。每个残差块的α值可能已经学会了不同的值，决定何时开始对解决方案做出贡献。这也意味着α的值可能仍然接近零，因此它实际上不存在。ReZero让我们的网络自己决定使用多少层残差块以及何时使用它们。它可以选择不将任何α值设置为接近零，这也是可以的。有时，通过从小开始并随着时间的推移变得更加复杂，更容易学会如何使用所有层，这正是ReZero所允许的。
- en: 14.2.2  Implementing ReZero
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.2 实现ReZero
- en: 'That’s the secret to the ReZero trick! The original discoverers had more math
    to show theoretically *why* it helps, but we can focus on implementing it. Our
    improved residual block incorporates this change as an option to choose from.
    We compartmentalize the function *F*(⋅) into its own `nn.Sequential` module, and
    if the `ReZero` flag is set to `True`, we make `self.alpha` a `Parameter` of the
    network that can be learned. Like the original residual connection we learned
    about, we also use a `shortcut` object when the number of channels or stride changes
    so that we can use 1 × 1 convolutions to make the shapes match:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 那就是ReZero技巧的秘密！原始的发现者有更多的数学理论来展示它为什么有帮助，但我们可以专注于实现它。我们改进的残差块将这个变化作为一个可选选项来选择。我们将函数*F*(⋅)分成它自己的`nn.Sequential`模块，如果`ReZero`标志设置为`True`，我们将`self.alpha`设置为网络的一个可学习的`Parameter`。就像我们学到的原始残差连接一样，当通道数或步长发生变化时，我们也使用一个`shortcut`对象，这样我们就可以使用1
    × 1卷积来使形状匹配：
- en: '[PRE16]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ How much to pad by so W/H stays the same
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如何填充以保持W/H不变
- en: ❷ Complex branch of the network that applies two rounds of layers
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 网络的复杂分支，应用了两轮层
- en: ❸ Alpha is a float if we are not using ReZero, or a parameter if we are
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 如果我们不使用ReZero，α是一个浮点数，如果我们使用ReZero，它是一个参数
- en: '❹ Shortcut is the identify function. It returns the input as the output unless
    the output of F will have a different shape due to a change in the number of channels
    or stride: in that case, we make the shortcut a 1 × 1 convolution as a projection
    to change its shape.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ Shortcut是恒等函数。它将输入作为输出返回，除非由于通道数或步长的变化，F的输出将具有不同的形状：在这种情况下，我们将快捷方式变成一个1 ×
    1卷积，作为一个投影来改变其形状。
- en: ❺ Computes the results of F(x) and x, as needed
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 根据需要计算F(x)和x的结果
- en: ❻ ReZero
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ ReZero
- en: ❼ Normal residual block
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 正常残差块
- en: That was a simple change to include; now let’s try it. First we train a relatively
    deep network for CIFAR-10\. The following module contains 28 `ResidualBlock`s,
    each of which contains 2 layers of convolutions, giving a total of 56 convolutional
    layers. This is much deeper than most of our networks in this book due to the
    need to make examples run quickly so you can change them. But ReZero’s benefit
    comes from being able to learn extremely deep networks. You could push this to
    thousands of hidden layers, if you wanted to, and it would still learn.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个简单的更改，现在让我们试试。首先，我们为CIFAR-10训练一个相对较深的网络。以下模块包含28个`ResidualBlock`，每个`ResidualBlock`包含2层卷积，总共56层卷积。由于需要使示例运行得更快以便你可以更改它们，所以这比本书中大多数网络都要深。但ReZero的优势在于能够学习极其深的网络。如果你想的话，可以将这个网络扩展到数千个隐藏层，它仍然可以学习。
- en: 'Here’s the code:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是代码：
- en: '[PRE17]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Trains a new residual network using the ReZero approach
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用ReZero方法训练新的残差网络
- en: ❷ Instead of pooling, let’s use a strided convolution layer. This keeps the
    skip connections intact without extra code.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们不使用池化，而是使用步长卷积层。这样可以保持跳跃连接完整，而不需要额外的代码。
- en: ❸ We used adaptive pooling down to 1 × 1, so it’s easier to compute the number
    of inputs to the final layer.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 我们使用了自适应池化到1 × 1，这使得计算最终层的输入数量更容易。
- en: That trained our ReZero model. Next, we repeat the same network but set `ReZero=False`
    to make a more standard residual network to compare against. The only difference
    between these two networks is the simple multiplication by α as a parameter that
    starts at 0\. We’ll skip the code since it is identical other than the `ReZero`
    flag.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这训练了我们的ReZero模型。接下来，我们重复相同的网络，但将`ReZero=False`设置为创建一个更标准的残差网络以进行比较。这两个网络之间的唯一区别是α作为参数的简单乘法，起始值为0。由于代码除了`ReZero`标志外都是相同的，我们将跳过代码。
- en: 'Now we can plot the results. Both residual networks perform significantly better
    than the simple approach, which we expect. You may find that ReZero does worse
    than other options for the first epoch: its initial behavior is that of a linear
    model, as all the subnetworks are blocked by *α* = 0. But as training progresses,
    ReZero starts converging toward a solution more quickly, often in half as many
    epochs on big data sets or with 100+ layers. Since our networks are still small
    to normal size, we don’t see as large a difference as is possible. But the deeper
    we make this network, with more parameters, the more significant a difference
    we see between the two methods.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以绘制结果。两种残差网络的表现都显著优于简单方法，这是我们所预期的。你可能会发现ReZero在第一个epoch的表现不如其他选项：它的初始行为类似于线性模型，因为所有子网络都被*α*
    = 0所阻塞。但随着训练的进行，ReZero开始更快地收敛到解决方案，在大数据集或100+层的情况下，通常只需要一半的epoch。由于我们的网络仍然相对较小，所以我们没有看到可能出现的那么大的差异。但当我们使这个网络更深，参数更多时，两种方法之间的差异就更加显著。
- en: 'Here’s the code:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是代码：
- en: '[PRE18]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](../Images/CH14_UN10_Raff.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_UN10_Raff.png)'
- en: The ReZero approach can be used beyond residual network-style architectures.
    The original paper’s authors have shared code at [https://github.com/majumderb/rezero](https://github.com/majumderb/rezero)
    so you can use their ReZero-enhanced transformer to improve the training of transformer-based
    models. This is particularly valuable since transformers take a long time to train
    and often require more sophisticated tricks with learning rate schedules to maximize
    their performance. The ReZero technique helps minimize this complexity. I’ve personally
    had a lot of success with ReZero’s approach as a simple, easy-to-add method that
    makes things a little faster and better with almost no effort.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ReZero方法可以用于超越残差网络风格的架构。原始论文的作者在[https://github.com/majumderb/rezero](https://github.com/majumderb/rezero)上分享了代码，你可以使用他们的ReZero增强变压器来提高基于变压器的模型的训练。这对于变压器来说尤其有价值，因为训练变压器需要很长时间，并且通常需要更复杂的技巧来调整学习率以最大化其性能。ReZero技术有助于最小化这种复杂性。我个人在ReZero方法上取得了很大的成功，这是一个简单、易于添加的方法，几乎不需要努力就能使事情变得更快、更好。
- en: 14.3 MixUp training reduces overfitting
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.3 MixUp训练减少过拟合
- en: The last method we learn about helps mitigate overfitting. Say we have two inputs,
    **x**[i] and **x**[j], with corresponding labels *y*[i] and *y*[j]. If *f*(⋅)
    is our neural network and ℓ is our loss function, we normally compute our loss
    as
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习的最后一种方法有助于减轻过拟合。假设我们有两个输入，**x**[i]和**x**[j]，以及相应的标签*y*[i]和*y*[j]。如果*f*(⋅)是我们的神经网络，ℓ是我们的损失函数，我们通常计算我们的损失如下：
- en: '![](../Images/CH14_F05_EQ01.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F05_EQ01.png)'
- en: This has served us well thus far, but sometimes models learn to overfit the
    data. Most approaches to regularization involve applying a penalty to the network
    itself. Dropout, for example, alters the network’s weights by randomly forcing
    some to be zero so the network can’t rely on a specific neuron being present to
    make its decision.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，这已经为我们服务得很好了，但有时模型会学习过度拟合数据。大多数正则化的方法都涉及对网络本身应用惩罚。例如，Dropout通过随机强制某些权重变为零来改变网络的权重，这样网络就不能依赖于特定的神经元来做出决策。
- en: '*MixUp*[⁴](#fn57) takes a different approach. Instead of altering or penalizing
    the network, we alter the loss function and the inputs. This way, we can change
    the incentives (the model is always trying to minimize the loss) instead of handicapping
    the model. Given two inputs **x**[i] and **x**[j], we *mix* them together into
    one new input ![](../Images/tilde_x.png) with a new label ỹ. We do this by taking
    a random value *λ* ∈ [0,1] and taking a weighted average between the two:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '*MixUp*[⁴](#fn57)采取不同的方法。我们不是改变或惩罚网络，而是改变损失函数和输入。这样，我们可以改变激励（模型总是试图最小化损失）而不是削弱模型。给定两个输入**x**[i]和**x**[j]，我们将它们混合成一个新的输入![图像](../Images/tilde_x.png)和一个新的标签ỹ。我们通过取一个随机值*λ*
    ∈ [0,1]，并在这两个之间取加权平均值来实现这一点：'
- en: '![](../Images/CH14_F05_EQ02.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH14_F05_EQ02.png)'
- en: Writing the equation this way feels odd at first. We average two images together
    and feed the averaged image into the network? It makes sense that if an image
    was 75% cat and 25% zebra, the answer should be 75% cat and 25% zebra, but how
    do we deal with an averaged label? In practice, we do something that is mathematically
    equivalent and use both labels *y*[i] and *y*[j] with the new input ![](../Images/tilde_x.png).
    We compute our loss as
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式写方程一开始可能感觉有些奇怪。我们平均两个图像并将平均图像输入到网络中？如果一张图像是75%的猫和25%的斑马，答案应该是75%的猫和25%的斑马，但如何处理平均标签呢？在实践中，我们做的是数学上等效的事情，并使用新的输入![图像](../Images/tilde_x.png)和两个标签*y*[i]和*y*[j]。我们计算我们的损失如下：
- en: '![](../Images/CH14_F05_EQ03.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH14_F05_EQ03.png)'
- en: So we have an input ![](../Images/tilde_x.png) that is the weighted average
    between *y*[i] and *y*[j], and we take the weighted loss between both possible
    predictions. This gives us an intuition as to how to implement the MixUp loss
    in practice.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有一个输入![图像](../Images/tilde_x.png)，它是*y*[i]和*y*[j]之间的加权平均值，我们取两个可能预测之间的加权损失。这让我们对如何在实践中实现MixUp损失有了直观的理解。
- en: 'Let’s dive into this with the example shown in figure 14.6\. We have the logits:
    the output of the neural network *before* the softmax function turns them into
    probabilities. Then we have the softmax results computed from those logits. If
    the correct class is class 0, its logit value does not need to be much larger
    than the others to get high confidence. But softmax *never* assigns a 100% probability,
    so the loss for a data point *never goes to zero*. As a result, the model constantly
    gets a small but consistent incentive to push the logit for class 0 *higher* to
    push the score for the correct class ever higher. This can push the model into
    unrealistically high scores to eke out small increases in the softmax result.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过图14.6所示的示例来深入了解这个问题。我们有logits：神经网络在softmax函数将其转换为概率之前的输出。然后我们有从这些logits计算出的softmax结果。如果正确的类别是类别0，其logit值不需要比其他的大很多就能获得高置信度。但softmax**永远不会**分配100%的概率，所以数据点的损失**永远不会**降到零。因此，模型始终会得到一个小但一致的激励，推动类别0的logit**更高**，以推动正确类别的分数不断提高。这可能会将模型推到不切实际的高分，以获得softmax结果的小幅增加。
- en: '![](../Images/CH14_F06_Raff.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH14_F06_Raff.png)'
- en: Figure 14.6 Example of how regular losses can cause overfitting, encouraging
    a model to make ever-more-overconfident predictions because that is what will
    lower the loss. The score never hits zero because the correct class never hits
    1.0, so there is always an incentive to push the logit higher.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.6 正则化损失如何导致过拟合的示例，鼓励模型做出越来越自信的预测，因为这将降低损失。分数永远不会达到零，因为正确的类别永远不会达到1.0，所以始终有激励推动logit更高。
- en: MixUp instead helps the model learn to modulate its predictions, making them
    only as large as there is reason to believe—rather than going all in on what it
    believes, as demonstrated in figure 14.7\. It’s like a betting site that allows
    users to gamble on an event. You don’t want to offer 1 million to 1 odds just
    because the event is *more* likely—you want the odds to reflect a realistic assumption
    about how likely you are to be correct.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: MixUp反而帮助模型学习调整其预测，使其大小仅与有理由相信的程度相匹配——而不是像图14.7中所示的那样，全押在它相信的事情上。这就像一个允许用户对事件下注的赌博网站。你不希望因为事件更有可能发生就提供1百万比1的赔率——你希望赔率反映你对正确性的现实假设。
- en: '![](../Images/CH14_F07_Raff.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH14_F07_Raff.png)'
- en: Figure 14.7 With MixUp, there is not the same incentive to overpredict. Instead,
    the model tries to reach a target percentage based on how much of two different
    classes was selected. MixUp mixes the labels and the inputs so there is a signal
    for each class proportional to the MixUp percentage λ.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.7 在MixUp中，没有过度预测的相同激励。相反，模型试图根据选择两个不同类别的多少来达到一个目标百分比。MixUp混合标签和输入，因此每个类别的信号与MixUp百分比λ成比例。
- en: If we have a mix of λ%, the model will need to learn to predict specifically
    λ% and (1−*λ*)% to maximize its score (minimize loss). Thus there is no incentive
    for the model to ever go all in on any prediction.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有λ%的混合，模型将需要学习具体预测λ%和(1−*λ*)%，以最大化其得分（最小化损失）。因此，模型没有理由在任何预测上全押。
- en: 14.3.1  Picking the mix rate
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.1 选择混合率
- en: The only thing left to decide is how to pick λ. It needs to be in the range
    of [0,1] to make sense as an average, but we do not necessarily want to pick λ
    uniformly in this range. When we actually use our network *f*(⋅), images will
    come in with no mixing. They will be normal images, so we want to train with a
    lot of *λ* ≈ 0 and *λ* ≈ 1, as these two cases correspond to no mixing. If we
    sample λ uniformly from [0,1], this is unlikely to happen. It’s OK that λ is near
    the extreme values because it will still limit all-in behavior and penalize overly
    confident predictions.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的唯一要决定的事情是如何选择λ。它需要位于[0,1]的范围内，以便作为一个平均值有意义，但我们并不一定想要在这个范围内均匀地选择λ。当我们实际使用我们的网络*f*(⋅)时，图像将不带混合地进来。它们将是正常图像，因此我们希望用很多*λ*
    ≈ 0和*λ* ≈ 1来训练，因为这两种情况对应于没有混合。如果我们从[0,1]中均匀地采样λ，这种情况不太可能发生。λ接近极端值是可以接受的，因为它仍然会限制整体行为并惩罚过度自信的预测。
- en: We use what is known as the *beta distribution*. The beta distribution usually
    takes two arguments, a and b, and we denote a sample drawn from the distribution
    as *λ* ∼ Beta(*a*,*b*). If *a* = *b*, then the beta distribution is symmetric.
    If the value is *a* = *b* < 1, the distribution is a U shape, making values of
    *λ* ≈ 0 and *λ* ≈ 1 more likely and *λ* ≈ 1/2 less likely. This is what we want,
    so the model is good at making predictions on clean inputs at test time but is
    trained to be more robust with slightly noisy values and occasionally very noisy
    values.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用所谓的*beta分布*。beta分布通常有两个参数，a和b，我们用*λ* ∼ Beta(*a*,*b*)表示从这个分布中抽取的样本。如果*a*
    = *b*，则beta分布是对称的。如果值是*a* = *b* < 1，则分布呈U形，使得*λ* ≈ 0和*λ* ≈ 1的值更可能，而*λ* ≈ 1/2的值更不可能。这正是我们想要的，因此该模型在测试时对干净输入的预测做得很好，但训练时被训练得对稍微有噪声的值和偶尔非常噪声的值更加鲁棒。
- en: 'The original paper by Hongyi Zhang et al. suggests using a value of *α* ∈ [0.1,0.4]
    and setting both beta parameters to this value (*a* = *b* = *α*). The following
    bit of code from SciPy shows what this distribution looks like. The x-axis is
    the value of λ, and the y-axis is the probability density function (PDF), giving
    the relative probability of each value of λ:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Hongyi Zhang等人撰写的原始论文建议使用*α* ∈ [0.1,0.4]的值，并将两个beta参数都设置为这个值（*a* = *b* = *α*）。以下来自SciPy的代码片段显示了这种分布的外观。x轴是λ的值，y轴是概率密度函数（PDF），给出了每个λ值的相对概率：
- en: '[PRE19]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Takes 100 steps along the x-axis for plotting
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 沿x轴绘制100步以进行绘图
- en: ❷ Four hyperparameter values to demonstrate
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 四个超参数值以进行演示
- en: ❸ Plots the beta distribution for each option
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 绘制每个选项的beta分布
- en: '![](../Images/CH14_UN11_Raff.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH14_UN11_Raff.png)'
- en: 14.3.2  Implementing MixUp
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.2 实现MixUp
- en: 'Now we understand the mathematical form of MixUp and how we sample λ. Let’s
    talk about the implementation strategy. First we need the loss function, which
    we’ll call ℓ[M]. We need four things to implement this function: our predictions
    ŷ from our network processing the mixed data ![](../Images/tilde_x.png) (i.e.,
    *ŷ* = *f*(![](../Images/tilde_x.png))) will be the first input. Our true label
    y is composed of the three other components: the original labels *y*[i], *y*[j]
    and the mixing value λ. Using the original loss function ℓ(⋅,⋅), we can write
    this out as'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了MixUp的数学形式以及我们如何采样λ。让我们谈谈实现策略。首先，我们需要损失函数，我们将称之为 ℓ[M]。实现此函数需要四件事：我们网络处理混合数据
    ![](../Images/tilde_x.png)（即 *ŷ* = *f*(![](../Images/tilde_x.png))) 的预测 ŷ 将是第一个输入。我们的真实标签
    y 由其他三个组成部分组成：原始标签 *y*[i]，*y*[j] 和混合值 λ。使用原始损失函数 ℓ(⋅,⋅)，我们可以将其写成
- en: '![](../Images/CH14_UN12_Raff.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_UN12_Raff.png)'
- en: 'Using this, we can think of ŷ as our normal outputs/predictions and *y*[i],
    *y*[j], *λ* as a label `tuple`. So we define a `MixupLoss` function that takes
    ŷ and y. If y is a Python `tuple`, we know that we need to compute the MixUp
    loss ℓ[M]. And if it’s a normal tensor, we are computing the original loss function
    ℓ:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，我们可以将 ŷ 视为我们正常的输出/预测，*y*[i]，*y*[j]，*λ* 作为标签 `元组`。因此，我们定义一个 `MixupLoss`
    函数，它接受 ŷ 和 y。如果 y 是 Python `元组`，我们知道我们需要计算 MixUp 损失 ℓ[M]。如果是正常张量，我们正在计算原始损失函数
    ℓ：
- en: '[PRE20]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ We should be doing MixUp!
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们应该进行MixUp操作！
- en: ❷ There should be a tuple of y_i, y_j, and lambda!
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 应该有一个包含 y_i，y_j 和 lambda 的元组！
- en: ❸ Breaks the tuple into its components
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将元组分解为其组成部分
- en: ❹ Else, y is a normal tensor and a normal set of labels! Compute the normal
    way.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 否则，y 是一个正常张量和一组正常标签！按照正常方式计算。
- en: Now we have a loss function that can take in a normal batch of data and give
    us the normal loss. But at training time, we need to provide a tuple of *y*[i],
    *y*[j], *λ* to trigger the MixUp loss, and we need to somehow create a batch of
    mixed inputs ![](../Images/tilde_x.png). In particular, we need to get a batch
    of B data points **x**[1], **x**[2], …, **x**[B] with labels *y*[1], *y*[2], …,
    *y*[B] and mix them with a new batch of data to create ![](../Images/tilde_x.png)[1],
    ![](../Images/tilde_x.png)[2], ..., ![](../Images/tilde_x.png)[B], which seems
    to require a complicated change to our loader.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个可以接受正常批次数据并给出正常损失的损失函数。但在训练时，我们需要提供一个包含 *y*[i]，*y*[j]，*λ* 的元组来触发 MixUp
    损失，并且我们需要以某种方式创建一个混合输入 ![](../Images/tilde_x.png) 的批次。特别是，我们需要获取一个包含 B 个数据点 **x**[1]，**x**[2]，…，**x**[B]
    以及标签 *y*[1]，*y*[2]，…，*y*[B] 的批次，并将它们与一个新的数据批次混合以创建 ![](../Images/tilde_x.png)[1]，![](../Images/tilde_x.png)[2]，…，![](../Images/tilde_x.png)[B]，这似乎需要对我们加载器进行复杂的修改。
- en: Rather than deal with getting a new batch of data, we’ll shuffle just one batch
    of data and treat the shuffled version as a new batch. The high-level summary
    of how this is organized is shown in figure 14.8\. If we only need one batch of
    data, we can alter the `collate_fn` to modify the batch. The common mathematical
    notation for this shuffled ordering is *π*(*i*) = *i*′, where *π*(⋅) is a function
    that indicates a *permutation* (i.e., a random shuffling) of the data.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是处理新的一批数据，我们将仅对一批数据进行洗牌，并将洗牌后的版本视为新的一批。如何组织这一过程的高级总结如图14.8所示。如果我们只需要一批数据，我们可以修改`collate_fn`来修改批次。这种洗牌排序的常见数学表示是
    *π*(*i*) = *i*′，其中 *π*(⋅) 是一个表示数据 *排列*（即随机洗牌）的函数。
- en: '![](../Images/CH14_F08_Raff.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F08_Raff.png)'
- en: Figure 14.8 Process to implement MixUp training. The shaded areas are modifications
    we make. Everything else remains the same as training and implementing any other
    neural network.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.8 实现MixUp训练的过程。阴影区域是我们所做的修改。其他所有内容都与训练和实现任何其他神经网络相同。
- en: For example, say we have a batch of *B* = 4 items. The values
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设我们有一个包含 *B* = 4 个项目的批次。值
- en: '![](../Images/CH14_F08_EQ01.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F08_EQ01.png)'
- en: 'may give any one of these possible 3! = 6 orderings:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 可能给出以下可能的 3! = 6 种排序：
- en: '![](../Images/CH14_F08_EQ02.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F08_EQ02.png)'
- en: 'The function `torch.randperm(B)` will give us an array of length B that is
    a random permutation *π*(⋅). Using a random reordering of each batch, we can use
    the `collate_fn` of the `DataLoader` to alter the batch of training data with
    a random grouping of the same data. It is exceedingly unlikely that a data point
    will be paired with itself, and if it is, this process will just temporarily degrade
    to normal training. So, we get a new batch of training data:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `torch.randperm(B)` 将给我们一个长度为 B 的数组，它是一个随机排列 *π*(⋅)。使用每个批次的随机重新排序，我们可以使用
    `DataLoader` 的 `collate_fn` 来改变训练数据的批次，使用相同数据的随机分组。数据点被配对给自己几乎是不可能的，如果是这样，这个过程将暂时降级为正常训练。因此，我们得到一个新的训练数据批次：
- en: '![](../Images/CH14_F08_EQ03.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F08_EQ03.png)'
- en: 'Once the batch is altered and contains a collection of mixed training instances
    ![](../Images/tilde_xC.png), we can return a tuple y for the label:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦批次被改变并包含一组混合的训练实例 ![](../Images/tilde_xC.png)，我们可以为标签返回一个元组 y：
- en: '![](../Images/CH14_F08_EQ04.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_F08_EQ04.png)'
- en: 'Now we can define `MixupCollator` as our special `collate_fn`. It takes a `collate_fn`,
    which is the method a user can specify to change how batches are created. `MixupCollator`
    is also responsible for sampling a new value of λ for each batch, so it needs
    to take the variable α as a second argument to control how aggressive the mixing
    is. We provide reasonable default values that sample batches the regular way and
    are in the middle range of mixing aggressiveness:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以定义 `MixupCollator` 作为我们的特殊 `collate_fn`。它接受一个 `collate_fn`，这是用户可以指定的方法，用于改变批次的创建方式。`MixupCollator`
    还负责为每个批次采样一个新的 λ 值，因此它需要将变量 α 作为第二个参数，以控制混合的激进程度。我们提供了合理的默认值，以常规方式采样批次，并且混合的激进程度处于中等范围：
- en: '[PRE21]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ The batch comes in as a list. We convert it into an actual batch of data.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 批次以列表的形式进入。我们将它转换成实际的数据批次。
- en: ❷ Samples the value of lambda to use. Note the “_" at the end, because lambda
    is a keyword in Python.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 样本 lambda 的值。注意末尾的“_”，因为 lambda 是 Python 中的一个关键字。
- en: ❸ Creates a random shuffled order pi
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建一个随机打乱的顺序 pi
- en: ❹ Computes the mixed version of the input data
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 计算输入数据的混合版本
- en: ❺ Gets the labels
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 获取标签
- en: '❻ Returns a tuple of two items: the input data and another tuple of three items
    that MixupLoss needs'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 返回一个包含两个项目的元组：输入数据和 MixupLoss 需要的另一个包含三个项目的元组
- en: 'With these two classes, we can easily incorporate the MixUp approach into almost
    any model. A new training loader needs to be built with `collate_fn=MixupCollator()`,
    and we need to pass `MixupLoss()` to our `train_network` function as the loss
    function to use. All the rest of our code works just as before, but with the addition
    of MixUp training:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两个类，我们可以轻松地将 MixUp 方法集成到几乎任何模型中。需要构建一个新的训练加载器，使用 `collate_fn=MixupCollator()`，并且我们需要将
    `MixupLoss()` 传递给我们的 `train_network` 函数作为使用的损失函数。其余的代码与之前一样，但增加了 MixUp 训练：
- en: '[PRE22]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Replaces the data loader with a new one that uses our MixupCollator
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将数据加载器替换为使用我们的 MixupCollator 的新加载器
- en: ❷ Resets the weights too, out of laziness
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 由于懒惰，也重置了权重
- en: ❸ The optimizer and scheduler remain unchanged.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 优化器和调度器保持不变。
- en: ❹ Wraps our normal loss with our new MixupLoss since we are training with MixUp
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用 MixUp 训练时，将我们的正常损失函数包装在新的 MixupLoss 中
- en: 'If we plot the accuracy, we see that our ResNet ReZero model combined with
    MixUp has further improved the rate of convergence, and the final accuracy is
    88.12%:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们绘制准确率图，我们会看到我们的 ResNet ReZero 模型结合 MixUp 进一步提高了收敛率，最终准确率为 88.12%：
- en: '[PRE23]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](../Images/CH14_UN13_Raff.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH14_UN13_Raff.png)'
- en: Looking at the results as a function of time, we see that the ReZero and MixUp
    methods are only incremental increases in runtime. Just using a deeper model with
    the ResNet approach is where most of the computational cost comes from. So if
    you are building a deeper network, both of these approaches are easy to add and
    can increase your model’s accuracy.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 将结果视为时间的函数，我们看到 ReZero 和 MixUp 方法只是运行时间的增量增加。仅使用 ResNet 方法更深的模型是大部分计算成本来源。因此，如果您正在构建更深的网络，这两种方法都很容易添加，并且可以提高模型的准确性。
- en: Warning The first two approaches we learned in this chapter are almost always
    worth using without worry. MixUp sometimes hurts accuracy but is usually a decent
    improvement, so it’s worth trying a new architecture once with and without MixUp
    to see how it does for your problem. MixUp is also trickier to apply to things
    like transformers and RNNs, although its extensions will help (with some uglier
    code). I’m sticking with standard MixUp for simplicity for now, but I know I can
    look at its extensions if I need to.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：本章我们学到的前两种方法几乎总是值得放心使用。MixUp有时会损害准确性，但通常是一个不错的改进，所以值得一试一次新的架构，一次带MixUp，一次不带MixUp，看看它对你的问题表现如何。MixUp在应用于像transformers和RNNs这样的东西时也更为复杂，尽管它的扩展会有帮助（代码可能有些丑陋）。为了简单起见，我现在坚持使用标准的MixUp，但我知道如果需要，我可以查看它的扩展。
- en: The only downside to these approaches is that their benefit is often only seen
    when working with bigger models or when we are already at risk of overfitting
    due to the complexity of our networks. If they hurt your accuracy, there is a
    good chance you need to make your network deeper and/or widen the layers in order
    for them to help.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法的唯一缺点是，它们的益处通常只有在处理更大的模型或我们由于网络的复杂性而已经面临过拟合风险时才能看到。如果它们损害了你的准确性，那么很可能你需要使你的网络更深，或者加宽层，以便它们能够有所帮助。
- en: Exercises
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: Share and discuss your solutions on the Manning online platform at Inside Deep
    Learning Exercises ([https://liveproject.manning.com/project/945](https://liveproject.manning.com/project/945)).
    Once you submit your own answers, you will be able to see the solutions submitted
    by other readers, and see which ones the author judges to be the best.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在Manning在线平台Inside Deep Learning Exercises上分享和讨论你的解决方案（[https://liveproject.manning.com/project/945](https://liveproject.manning.com/project/945)）。一旦你提交了自己的答案，你将能够看到其他读者提交的解决方案，并看到作者认为哪些是最好的。
- en: We looked at the change in probability of translating (shifting) CIFAR-10 images
    for a specific example. Instead, compute the median deviation of change in class
    probability over all of the test set of CIFAR-10 for both the original CNN and
    the anti-aliased version (i.e., for every image, compute the 64 probability values
    and the standard deviations of those probabilities. Compute that value for every
    image, and take the median). Does the result show what you expect, that anti-aliasing
    reduces the median change in probability?
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们查看了一个特定示例中CIFAR-10图像翻译（移动）概率的变化。相反，计算CIFAR-10测试集中所有类别概率变化的中间偏差，对于原始CNN和抗锯齿版本（即，对于每张图像，计算64个概率值及其概率的标准偏差。为每张图像计算该值，并取中间值）。结果是否显示了你预期的，即抗锯齿减少了概率变化的中间值？
- en: Implement the anti-aliased version of strided convolution and average pooling
    based on the descriptions in this chapter. Then implement new convolutional networks
    that replace max pooling with the standard and anti-aliased versions of strided
    convolution and average pooling. Test them yourself using the same CIFAR-10 example
    we used for `MaxPool2dAA`.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据本章描述，实现具有抗锯齿版本的步长卷积和平均池化的版本。然后实现新的卷积网络，用标准步长卷积和抗锯齿版本的步长卷积以及平均池化来替换最大池化。使用与`MaxPool2dAA`相同的CIFAR-10示例自行测试它们。
- en: Implement a ReZero version of the bottleneck class from chapter 6 and a ReZero
    version of a fully connected residual block. Test them both on CIFAR-100 and see
    how they compare to non-ReZero counterparts.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现第6章中瓶颈类的ReZero版本以及一个全连接残差块的ReZero版本。在CIFAR-100上对它们进行测试，看看它们与非ReZero版本相比如何。
- en: Our ReZero residual network has 6 blocks of residual layers between each section
    of its definition. Try training both a ReZero and a normal residual block with
    18 blocks, instead. How does the performance of each approach change?
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的ReZero残差网络在其定义的每个部分之间有6个残差层块。尝试训练一个具有18个块的ReZero和一个普通残差块，看看每种方法的表现如何变化？
- en: Implement the anti-aliased version of strided convolution for the ReZero residual
    network, and train it on CIFAR-10\. How does it impact accuracy and convergence?
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为ReZero残差网络实现具有抗锯齿版本的步长卷积，并在CIFAR-10上对其进行训练。它如何影响准确性和收敛性？
- en: '**Challenging:** The paper “Manifold mixup: better representations by interpolating
    hidden states”[⁵](#fn58) describes an improved version of MixUp that performs
    the mixing at a randomly selected hidden layer of the network rather than at the
    input. Try to implement this yourself, and test it on CIFAR-10 and CIFAR-100\.
    Hint: this will be easier to do by defining a custom `Module` for the network
    and using a `ModuleList` to store the sequence of layers that are candidates for
    mixing (i.e., you don’t need *every* possible hidden layer to be an option).'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**挑战性：** 论文“Manifold mixup: better representations by interpolating hidden
    states”[⁵](#fn58)描述了MixUp的一个改进版本，该版本在网络的随机选择隐藏层而不是输入层进行混合。尝试自己实现它，并在CIFAR-10和CIFAR-100上测试。提示：通过定义一个自定义的`Module`为网络，并使用`ModuleList`来存储候选混合的层序列（即，你不需要*每一个*可能的隐藏层都是选项）。'
- en: Summary
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Aliasing occurs when naive pooling is used. It interferes with a model’s translation
    invariance.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用简单的池化时会发生混叠。它干扰了模型的平移不变性。
- en: Incorporating a blur operation helps mitigate the aliasing problem, which in
    turn helps improve our model’s accuracy.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合模糊操作有助于缓解混叠问题，这反过来又有助于提高我们模型的准确性。
- en: Adding a kind of gate α to the subnetwork of a residual block gives the model
    a chance to incorporate complexity over time, improving convergence speed and
    causing the model to converge to more accurate solutions.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在残差块的子网络中添加一种门控α，给模型一个在时间上引入复杂性的机会，从而提高收敛速度，并使模型收敛到更精确的解。
- en: Cross-entropy and other losses can overfit when they get overconfident about
    predicting classes.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当交叉熵和其他损失对预测类别过于自信时，它们可能会过拟合。
- en: MixUp combats overconfident predictions by penalizing them, forcing the model
    to learn how to hedge its bets.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MixUp通过惩罚过自信的预测来对抗它们，迫使模型学习如何权衡其赌注。
- en: Anti-aliased pooling, ReZero residuals, and MixUp are widely useful and can
    be used together, but their strength is most apparent with large data sets and
    when training for 100+ epochs.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反走样池化、ReZero残差和MixUp非常有用，可以一起使用，但它们的优势在大型数据集和训练100+个epoch时最为明显。
- en: '* * *'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '¹ Image by Sajjad Fazel: [https://commons.wikimedia.org/wiki/User:SajjadF](https://commons.wikimedia.org/wiki/User:SajjadF).[↩](#fnref54)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 图片由Sajjad Fazel提供：[https://commons.wikimedia.org/wiki/User:SajjadF](https://commons.wikimedia.org/wiki/User:SajjadF)。[↩](#fnref54)
- en: ² R. Zhang, “Making convolutional networks shift-invariant again,” in *Proceedings
    of the 36th International Conference on Machine Learning*, vol. 97, pp. 7324–7334),
    2019.[↩](#fnref55)
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ² R. Zhang，“使卷积网络再次具有平移不变性，”在第36届国际机器学习会议论文集中，第97卷，第7324–7334页，2019。[↩](#fnref55)
- en: '³ T. Bachlechner et al., “ReZero is all you need: fast convergence at large
    depth," [https://arxiv.org/abs/2003.04887](https://arxiv.org/abs/2003.04887),
    2020.[↩](#fnref56)'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '³ T. Bachlechner等人，“ReZero is all you need: fast convergence at large depth,"
    [https://arxiv.org/abs/2003.04887](https://arxiv.org/abs/2003.04887)，2020。[↩](#fnref56)'
- en: '⁴ H. Zhang et al., “Mixup: beyond empirical risk minimization," ICLR, 2018.[↩](#fnref57)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '⁴ H. Zhang等人，“Mixup: beyond empirical risk minimization," ICLR，2018。[↩](#fnref57)'
- en: ⁵ V. Verma et al., *Proceedings of the 36th International Conference on Machine
    Learning*, vol. 97, pp. 6438–6447, 2019.[↩](#fnref58)
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵ V. Verma等人，“第36届国际机器学习会议论文集”，第97卷，第6438–6447页，2019。[↩](#fnref58)
