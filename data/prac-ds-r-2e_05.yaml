- en: Chapter 4\. Managing data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 4 章\. 管理数据
- en: '***This chapter covers***'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '***本章涵盖***'
- en: Fixing data quality problems
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复数据质量问题
- en: Transforming data before modeling
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在建模前转换数据
- en: Organizing your data for the modeling process
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为建模过程组织你的数据
- en: In [chapter 3](../Text/03.xhtml#ch03), you learned how to explore your data
    and how to identify common data issues. In this chapter, you’ll see how to fix
    the data issues that you’ve discovered. After that, we’ll talk about transforming
    and organizing the data for the modeling process. Most of the examples in this
    chapter use the same customer data that you used in the previous chapter.^([[1](../Text/04.xhtml#ch04fn1)])
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 3 章](../Text/03.xhtml#ch03) 中，你学习了如何探索你的数据以及如何识别常见的数据问题。在本章中，你将看到如何修复你发现的数据问题。之后，我们将讨论在建模过程中转换和组织数据。本章的大部分例子都使用了你在上一章中使用过的相同客户数据.^([[1](../Text/04.xhtml#ch04fn1)])
- en: ¹
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The data can be loaded by saving the file custdata.RDS from [https://github.com/WinVector/PDSwR2/tree/master/Custdata](https://github.com/WinVector/PDSwR2/tree/master/Custdata)
    and then running `readRDS("custdata.RDS")` in R.
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 数据可以通过保存文件 custdata.RDS 到 [https://github.com/WinVector/PDSwR2/tree/master/Custdata](https://github.com/WinVector/PDSwR2/tree/master/Custdata)
    并然后在 R 中运行 `readRDS("custdata.RDS")` 来加载。
- en: As shown in the mental model ([figure 4.1](../Text/04.xhtml#ch04fig01)), this
    chapter again emphasizes the science of managing the data in a statistically valid
    way, prior to the model-building step.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如心智模型 ([图 4.1](../Text/04.xhtml#ch04fig01)) 所示，本章再次强调了在建模步骤之前以统计有效的方式管理数据的重要性。
- en: Figure 4.1\. [Chapter 4](../Text/04.xhtml#ch04) mental model
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1\. [第 4 章](../Text/04.xhtml#ch04) 心智模型
- en: '![](Images/04fig01.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig01.jpg)'
- en: 4.1\. Cleaning data
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1\. 数据清洗
- en: 'In this section, we’ll address issues that you discovered during the data exploration/visualization
    phase, in particular, invalid and missing values. Missing values in data happen
    quite commonly, and the way you treat them is generally the same from project
    to project. Handling invalid values is often *domain-specific*: which values are
    invalid, and what you do about them, depends on the problem that you are trying
    to solve.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将解决你在数据探索/可视化阶段发现的问题，特别是无效和缺失值。数据中的缺失值很常见，你处理它们的方式通常从项目到项目都是一样的。处理无效值通常是
    *领域特定的*：哪些值是无效的，你将如何处理它们，取决于你试图解决的问题。
- en: '* * *'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*Suppose you have a numeric variable called* `credit_score`*. Domain knowledge
    will tell you what the valid range for that variable should be. If the credit
    score is supposed to be a customer’s “classic FICO score,” then any value outside
    the range 300–850 should be treated as invalid. Other types of credit scores will
    have different ranges of valid values.*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设你有一个名为* `credit_score`* 的数值变量。领域知识将告诉你该变量的有效范围。如果信用评分应该是客户的“经典 FICO 评分”，那么任何在
    300–850 范围之外的值都应该被视为无效。其他类型的信用评分将有不同的有效值范围。*'
- en: '* * *'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We’ll look at an example of domain-specific data cleaning first.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先来看一个领域特定数据清洗的例子。
- en: 4.1.1\. Domain-specific data cleaning
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.1\. 领域特定数据清洗
- en: 'From our data exploration in the previous chapter, we know of some issues with
    our data:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一章的数据探索中，我们知道我们的数据存在一些问题：
- en: 'The variable `gas_usage` mixes numeric and symbolic data: values greater than
    `3` are monthly `gas_bills`, but values from `1` to `3` are special codes. In
    addition, `gas_usage` has some missing values.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量 `gas_usage` 混合了数值和符号数据：大于 `3` 的值是月度 `gas_bills`，但 `1` 到 `3` 的值是特殊代码。此外，`gas_usage`
    还有一些缺失值。
- en: The variable `age` has the problematic value `0`, which probably means that
    the age is unknown. In addition, there are a few customers with ages older than
    100 years, which may also be an error. However, for this project, we'll treat
    the value `0` as invalid, and assume ages older than 100 years are valid.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量 `age` 有问题值 `0`，这可能意味着年龄未知。此外，还有一些客户的年龄超过 100 岁，这也可能是一个错误。然而，对于这个项目，我们将值 `0`
    视为无效，并假设年龄超过 100 岁是有效的。
- en: The variable `income` has negative values. We’ll assume for this discussion
    that those values are invalid.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量 `income` 有负值。我们假设在这次讨论中这些值是无效的。
- en: These sorts of issues are quite common. In fact, most of the preceding problems
    were already in the actual census data that our notional customer data example
    is based on.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这类问题相当常见。事实上，前面提到的大部分问题都已经在我们的假设客户数据示例所基于的实际人口普查数据中存在。
- en: A quick way to treat the `age` and `income` variables is to convert the invalid
    values to `NA`, as if they were missing variables. You can then treat the `NA`s
    using the automatic missing-value treatment discussed in [section 4.1.2](../Text/04.xhtml#ch04lev2sec2).^([[2](../Text/04.xhtml#ch04fn2)])
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 处理`age`和`income`变量的快速方法是将其无效值转换为`NA`，就像它们是缺失变量一样。然后您可以使用在[4.1.2节](../Text/04.xhtml#ch04lev2sec2)中讨论的自动缺失值处理方法来处理`NA`。^([[2](../Text/04.xhtml#ch04fn2)])
- en: ²
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ²
- en: ''
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If you haven’t already done so, we suggest you follows the steps in [section
    A.1](../Text/A.xhtml#app01lev1sec1) of [appendix A](../Text/A.xhtml#app01) to
    install R, packages, tools, and the book examples.
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果您还没有这样做，我们建议您按照[附录A的A.1节](../Text/A.xhtml#app01lev1sec1)和[附录A](../Text/A.xhtml#app01)中的步骤安装R、包、工具和本书的示例。
- en: Listing 4.1\. Treating the age and income variables
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.1\. 处理年龄和收入变量
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Loads the data
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载数据
- en: ❷ The function mutate() from the dplyr package adds columns to a data frame,
    or modifies existing columns. The function na_if (), also from dplyr, turns a
    specific problematic value (in this case, 0) to NA.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ dplyr包中的mutate()函数向数据框中添加列，或修改现有列。来自dplyr的函数na_if()将特定的有问题值（在本例中为0）转换为NA。
- en: ❸ Converts negative incomes to NA
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将负收入转换为NA
- en: 'The `gas_usage` variable has to be treated specially. Recall from [chapter
    3](../Text/03.xhtml#ch03) that the values `1`, `2`, and `3` aren’t numeric values,
    but codes:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`gas_usage`变量需要特殊处理。回想一下[第3章](../Text/03.xhtml#ch03)，值`1`、`2`和`3`不是数值，而是代码：'
- en: The value `1` means “Gas bill included in rent or condo fee.”
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值`1`表示“燃气账单包含在租金或公寓费中。”
- en: The value `2` means “Gas bill included in electricity payment.”
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值`2`表示“燃气账单包含在电费中。”
- en: The value `3` means “No charge or gas not used.”
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值`3`表示“无费用或未使用燃气。”
- en: One way to treat `gas_usage` is to convert all the special codes (`1`, `2`,
    `3`) to `NA`, and to add three new *indicator variables*, one for each code. For
    example, the indicator variable `gas_with_electricity` will have the value `1`
    (or `TRUE`) whenever the original `gas_usage` variable had the value `2`, and
    the value `0` otherwise. In the following listing, you will create the three new
    indicator variables, `gas_with_rent`, `gas_with_electricity`, and `no_ gas_bill`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 处理`gas_usage`的一种方法是将所有特殊代码（`1`、`2`、`3`）转换为`NA`，并添加三个新的*指示变量*，每个代码一个。例如，指示变量`gas_with_electricity`将在原始`gas_usage`变量值为`2`时具有值`1`（或`TRUE`），否则为`0`。在下面的列表中，您将创建三个新的指示变量，`gas_with_rent`、`gas_with_electricity`和`no_gas_bill`。
- en: Listing 4.2\. Treating the `gas_usage` variable
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.2\. 处理`gas_usage`变量
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Creates the three indicator variables
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建三个指示变量
- en: ❷ Converts the special codes in the gas_usage column to NA
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将`gas_usage`列中的特殊代码转换为NA
- en: 4.1.2\. Treating missing values
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.2\. 处理缺失值
- en: Let’s take another look at some of the variables with missing values in our
    customer dataset from the previous chapter. One way to find these variables programmatically
    is to count how many missing values are in each column of the customer data frame,
    and look for the columns where that count is greater than zero. The next listing
    counts the number of missing values in each column of the dataset.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次看看上一章中客户数据集中一些具有缺失值的变量。一种通过编程查找这些变量的方法是计算客户数据框中每列的缺失值数量，并查找计数大于零的列。下一个列表计算数据集中每列的缺失值数量。
- en: Listing 4.3\. Counting the missing values in each variable
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.3\. 计算每个变量的缺失值数量
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Defines a function that counts the number of NAs in each column of a data
    frame
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义了一个函数，用于计算数据框中每列的NA值数量
- en: ❷ Applies the function to customer_data, identifies which columns have missing
    values, and prints the columns and counts
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将函数应用于customer_data，识别具有缺失值的列，并打印列和计数
- en: 'Fundamentally, there are two things you can do with these variables: drop the
    rows with missing values, or convert the missing values to a meaningful value.
    For variables like `income` or `age` that have very few missing values relative
    to the size of the data (`customer_data` has 73,262 rows), it could be safe to
    drop the rows. It wouldn’t be safe to drop rows from variables like `is_employed`
    or `gas_usage`, where a large fraction of the values is missing.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，您可以使用这些变量做两件事：删除包含缺失值的行，或将缺失值转换为有意义的值。对于`income`或`age`这样的变量，相对于数据的大小（`customer_data`有73,262行），缺失值非常少，删除行可能是安全的。对于`is_employed`或`gas_usage`这样的变量，其中很大一部分值是缺失的，删除行可能是不安全的。
- en: In addition, remember that many modeling algorithms in R (and in other languages)
    will quietly drop rows that have missing values. So if you have wide data, and
    many columns have missing values, it may not be safe to drop rows with missing
    values. This is because the fraction of rows with at least one missing value can
    be high in that situation, and you can lose most of your data, as [figure 4.2](../Text/04.xhtml#ch04fig02)
    shows. So for this discussion, we will convert all the missing values to meaningful
    values.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，记住，R（以及其他语言）中的许多建模算法会静默地删除具有缺失值的行。所以如果你有宽数据，并且许多列有缺失值，删除具有缺失值的行可能并不安全。这是因为在这种情况下，至少有一个缺失值的行比例可能很高，你可能会丢失大部分数据，如图4.2([figure
    4.2](../Text/04.xhtml#ch04fig02))所示。因此，为了这次讨论，我们将所有缺失值转换为有意义的值。
- en: Figure 4.2\. Even a few missing values can lose all your data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2\. 即使只有几个缺失值也可能丢失所有数据。
- en: '![](Images/04fig02_alt.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片描述](Images/04fig02_alt.jpg)'
- en: Missing data in categorical variables
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 分类变量中的缺失数据
- en: When the variable with missing values is categorical, an easy solution is to
    create a new category for the variable, called, for instance, `missing` or `_invalid_`.
    This is shown schematically for the variable `housing_type` in [figure 4.3](../Text/04.xhtml#ch04fig03).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当缺失值的变量是分类变量时，一个简单的解决方案是为该变量创建一个新的类别，例如，称为`missing`或`_invalid_`。这在图4.3([figure
    4.3](../Text/04.xhtml#ch04fig03))中 schematically 展示了`housing_type`变量。
- en: Figure 4.3\. Creating a new level for missing categorical values
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3\. 为缺失的分类值创建新级别
- en: '![](Images/04fig03_alt.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片描述](Images/04fig03_alt.jpg)'
- en: Missing values in numeric or logical variables
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数值或逻辑变量中的缺失值
- en: Suppose your income variable were missing substantial data, as in [figure 4.4](../Text/04.xhtml#ch04fig04).
    You believe that income is still an important predictor of the probability of
    health insurance coverage, so you still want to use the variable. What do you
    do? This can depend on *why* you think the data is missing.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的收入变量缺失大量数据，如图4.4([figure 4.4](../Text/04.xhtml#ch04fig04))所示。你认为收入仍然是健康保险覆盖概率的重要预测因子，因此你仍然想使用该变量。你该怎么办？这可以取决于你为什么认为数据缺失。
- en: Figure 4.4\. Income data with missing values
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4\. 具有缺失值的收入数据
- en: '![](Images/04fig04.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片描述](Images/04fig04.jpg)'
- en: The nature of missing values
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值的性质
- en: You might believe that the data is missing because the data collection failed
    at random, independent of the situation and of the other values. In this case,
    you can replace the missing values with a “reasonable estimate,” or *imputed value*.
    Statistically, one commonly used estimate is the expected, or mean, income, as
    shown in [figure 4.5](../Text/04.xhtml#ch04fig05).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能认为数据缺失是因为数据收集失败是随机的，独立于情况和其他值。在这种情况下，你可以用“合理的估计”或*插补值*来替换缺失值。从统计学的角度来看，一个常用的估计是期望值或平均值，如图4.5([figure
    4.5](../Text/04.xhtml#ch04fig05))所示。
- en: Figure 4.5\. Replacing missing values with the mean
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5\. 用平均值替换缺失值
- en: '![](Images/04fig05_alt.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片描述](Images/04fig05_alt.jpg)'
- en: Assuming that the customers with missing income are distributed the same way
    as the others, replacing missing values with the mean will be correct on average.
    It’s also an easy fix to implement.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 假设缺失收入的客户与其他客户的分布方式相同，用平均值替换缺失值在平均意义上将是正确的。这也是一个容易实施的解决方案。
- en: You can improve this estimate when you remember that income is related to other
    variables in your data—for instance, you know from your data exploration in the
    previous chapter that there’s a relationship between age and income. There might
    be a relationship between state of residence or marital status and income, as
    well. If you have this information, you can use it. The method of imputing a missing
    value of an input variable based on the other input variables can be applied to
    categorical data, as well.^([[3](../Text/04.xhtml#ch04fn3)])
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当你记得收入与你的数据中的其他变量相关时，你可以改进这个估计——例如，根据前一章的数据探索，你知道年龄和收入之间存在关系。居住地或婚姻状况与收入之间也可能存在关系。如果你有这些信息，你可以使用它。基于其他输入变量对输入变量的缺失值进行插补的方法也可以应用于分类数据。[^([3](../Text/04.xhtml#ch04fn3))]
- en: ³
  id: totrans-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ³
- en: ''
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The text *R in Action,* Second Edition (Robert Kabacoff, 2014, [http://mng.bz/ybS4](http://mng.bz/ybS4))
    includes an extensive discussion of several value imputation methods available
    in R.
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 《R in Action，第二版》（Robert Kabacoff，2014，[http://mng.bz/ybS4](http://mng.bz/ybS4)）包括对R中可用的几种值插补方法的广泛讨论。
- en: It’s important to remember that replacing missing values by the mean, as well
    as other more sophisticated methods for imputing missing values, assumes that
    the customers with missing income are in some sense typical. It’s possible that
    the customers with missing income data are *systematically* different from the
    others. For instance, it could be the case that the customers with missing income
    information truly have no income, because they are full-time students or stay-at-home
    spouses or otherwise not in the active workforce. If this is so, then “filling
    in” their income information by using one of the preceding methods is an insufficient
    treatment, and may lead to false conclusions.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，用平均值替换缺失值，以及其他更复杂的缺失值插补方法，假设缺失收入的客户在某种程度上是典型的。可能缺失收入数据的客户与其他客户在系统上有所不同。例如，可能的情况是，缺失收入信息的客户确实没有收入，因为他们是全职学生或全职主妇，或者他们不是活跃的劳动力。如果是这样，那么使用上述方法之一“填补”他们的收入信息是不充分的处理，可能会导致错误的结论。
- en: Treating missing values as information
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 将缺失值视为信息
- en: You still need to replace the `NA`s with a stand-in value, perhaps the mean.
    But the modeling algorithm should know that these values are possibly different
    from the others. A trick that has worked well for us is to replace the `NA`s with
    the mean, and add an additional indicator variable to keep track of which data
    points have been altered. This is shown in [figure 4.6](../Text/04.xhtml#ch04fig06).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你仍然需要将 `NA` 替换为一个替代值，比如平均值。但是建模算法应该知道这些值可能与其他值不同。对我们来说，一个有效的方法是将 `NA` 替换为平均值，并添加一个额外的指示变量来跟踪哪些数据点已被更改。这如图
    4.6 所示。
- en: Figure 4.6\. Replacing missing values with the mean and adding an indicator
    column to track the altered values
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6\. 用平均值替换缺失值并添加指示列以跟踪更改的值
- en: '![](Images/04fig06_alt.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/04fig06_alt.jpg)'
- en: 'The `income_isBAD` variable lets you differentiate the two kinds of values
    in the data: the ones that you are about to add, and the ones that were already
    there.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`income_isBAD` 变量让你能够区分数据中的两种值：你即将添加的值和已经存在的值。'
- en: 'You’ve seen a variation of this approach already, in another example of systematic
    missing values: the `gas_usage` variable. Most of the customers with missing `gas_usage`
    values aren’t random: they either pay for gas together with another bill, such
    as electricity or rent, or they don’t use gas. You identified those customers
    by adding additional indicator variables: `no_gas_bill`, `gas_with_rent`, and
    so on. Now you can fill in the “missing” values in `gas_usage` with a stand-in
    value, such as zero, or the average value of `gas_usage`.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经在另一个关于系统缺失值的例子中看到了这种方法的变化，那就是 `gas_usage` 变量。大多数缺失 `gas_usage` 值的客户并不是随机的：他们要么与其他账单一起支付燃气费，比如电费或租金，要么他们不使用燃气。你通过添加额外的指示变量来识别这些客户：`no_gas_bill`、`gas_with_rent`
    等。现在你可以在 `gas_usage` 中的“缺失”值用替代值填充，比如零，或者 `gas_usage` 的平均值。
- en: The idea is that at the modeling step, you give all the variables—`income`,
    `income_isBAD`, `gas_usage`, `no_gas_bill`, and so on—to the modeling algorithm,
    and it can determine how to best use the information to make predictions. If the
    missing values really are missing randomly, then the indicator variables that
    you added are uninformative, and the model should ignore them. If the missing
    values are missing systematically, then the indicator variables provide useful
    additional information to the modeling algorithm.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 策略是在建模步骤中，将所有变量——`income`、`income_isBAD`、`gas_usage`、`no_gas_bill` 等——都提供给建模算法，它可以确定如何最好地使用这些信息进行预测。如果缺失值确实是随机缺失的，那么你添加的指示变量就是无信息的，模型应该忽略它们。如果缺失值是系统缺失的，那么指示变量为建模算法提供了有用的额外信息。
- en: '* * *'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Missingness indicators can be useful
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失指示器可能很有用
- en: We’ve observed in many situations that the `isBAD` variables are sometimes even
    *more* informative and useful than the original variables!
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在许多情况下观察到，`isBAD` 变量有时甚至比原始变量更有信息和有用！
- en: '* * *'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: If you don’t know whether the missing values are random or systematic, we recommend
    assuming that the difference is systematic, rather than working hard to impute
    values to the variables based on the random missingness assumption. As we said
    earlier, treating missing values as if they are missing at random when they really
    indicate a systematic difference in some of the datums may lead to false conclusions.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不知道缺失值是随机的还是系统的，我们建议假设差异是系统的，而不是努力根据随机缺失假设对变量进行值填充。正如我们之前所说的，当缺失值实际上指示某些数据点的系统性差异时，将其视为随机缺失可能会得出错误的结论。
- en: 4.1.3\. The vtreat package for automatically treating missing variables
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.3\. 用于自动处理缺失变量的 vtreat 包
- en: 'Since missing values are such a common problem with data, it’s useful to have
    an automatic and repeatable process for dealing with them. We recommend using
    the `vtreat` variable treatment package. The `vtreat` process creates a *treatment
    plan* that records all the information needed to repeat the data treatment process:
    for example, the average observed income, or all the observed values of a categorical
    variable like `housing_type`. You then use this treatment plan to “prepare” or
    treat your training data before you fit a model, and then again to treat new data
    before feeding it into the model. The idea is that treated data is “safe,” with
    no missing or unexpected values, and shouldn’t ruin the model.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于缺失值是数据中如此常见的问题，因此有一个自动且可重复的处理过程来处理它们是非常有用的。我们建议使用 `vtreat` 变量处理包。`vtreat`
    处理过程创建一个 *处理计划*，记录重复数据处理过程所需的所有信息：例如，观察到的平均收入，或像 `housing_type` 这样的分类变量的所有观察值。然后，你使用这个处理计划在拟合模型之前“准备”或处理你的训练数据，然后再在将新数据输入模型之前再次处理。其想法是处理过的数据是“安全的”，没有缺失或意外的值，并且不应该破坏模型。
- en: 'You’ll see more-sophisticated examples of using `vtreat` in later chapters,
    but for now you will just create a simple treatment plan to manage the missing
    values in `customer_data`. [Figure 4.7](../Text/04.xhtml#ch04fig07) shows the
    processes of creating and applying this simple treatment plan. First, you have
    to designate which columns of the data are the input variables: all of them except
    `health_ins` (which is the outcome to be predicted) and `custid`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在后面的章节中看到使用 `vtreat` 的更复杂示例，但到目前为止，你将只创建一个简单的处理计划来管理 `customer_data` 中的缺失值。[图
    4.7](../Text/04.xhtml#ch04fig07) 显示了创建和应用此简单处理计划的过程。首先，你必须指定数据中的哪些列是输入变量：除了 `health_ins`（要预测的结果）和
    `custid` 之外的所有列：
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Figure 4.7\. Creating and applying a simple treatment plan
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7\. 创建和应用简单处理计划
- en: '![](Images/04fig07_alt.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig07_alt.jpg)'
- en: Then, you create the treatment plan, and “prepare” the data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你创建处理计划，并“准备”数据。
- en: Listing 4.4\. Creating and applying a treatment plan
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.4\. 创建和应用处理计划
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The data frame `training_prepared` is the treated data that you would use to
    train a model. Let’s compare it to the original data.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框 `training_prepared` 是用于训练模型的处理数据。让我们将其与原始数据进行比较。
- en: Listing 4.5\. Comparing the treated data to the original
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.5\. 比较处理数据与原始数据
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ The prepared data has additional columns that are not in the original data,
    most importantly those with the _isBAD designation.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 准备好的数据有额外的列，这些列在原始数据中不存在，最重要的是那些带有 _isBAD 标记的列。
- en: ❷ The prepared data has no missing values.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 准备好的数据没有缺失值。
- en: Now examine a few columns that you know had missing values.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在检查一些你知道有缺失值的列。
- en: Listing 4.6\. Examining the data treatment
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.6\. 检查数据处理
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Finds the rows where housing_type was missing
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 找到 `housing_type` 缺失的行
- en: ❷ Looks at a few columns from those rows in the original data
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 查看原始数据中那些行的几个列
- en: ❸ Looks at those rows and columns in the treated data (along with the isBADs)
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 查看处理数据中的那些行和列（包括 isBADs）
- en: ❹ Verifies the expected number of vehicles and the expected unemployment rate
    in the dataset
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 验证数据集中预期的车辆数量和预期的失业率
- en: You see that `vtreat` replaced missing values of the categorical variable `housing_type`
    with the token `_invalid_`, and missing values of the numerical column `num_vehicles`
    with its average value in the original data. It also converted the logical variable
    `is_ employed` to a numeric variable, and replaced missing values with its average
    value in the original data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到 `vtreat` 将分类变量 `housing_type` 的缺失值替换为 `_invalid_`，并将数值列 `num_vehicles`
    的缺失值替换为原始数据中的平均值。它还将逻辑变量 `is_ employed` 转换为数值变量，并用原始数据中的平均值替换缺失值。
- en: In addition to fixing missing data, there are other ways that you can transform
    the data to address issues that you found during the exploration phase. In the
    next section, we’ll examine some additional common transformations.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 除了修复缺失数据外，还有其他方法可以转换数据，以解决你在探索阶段发现的问题。在下一节中，我们将检查一些其他常见的转换。
- en: 4.2\. Data transformations
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2\. 数据转换
- en: The purpose of data transformation is to make data easier to model, and easier
    to understand. Machine learning works by learning meaningful patterns in training
    data, and then making predictions by exploiting those patterns in new data. Therefore,
    a data transformation that makes it easier to match patterns in the training data
    to patterns in new data can be a benefit.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换的目的是使数据更容易建模，也更容易理解。机器学习通过学习训练数据中的有意义模式来工作，然后通过利用这些模式在新数据中进行预测。因此，使训练数据中的模式与新数据中的模式更容易匹配的数据转换可以带来好处。
- en: '* * *'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*Suppose you are considering the use of income as an input to your insurance
    model. The cost of living will vary from state to state, so what would be a high
    salary in one region could be barely enough to scrape by in another. Because of
    this, it might be more meaningful to normalize a customer’s income by the typical
    income in the area where they live. This is an example of a relatively simple
    (and common) transformation.*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设你正在考虑将收入作为保险模型的输入。生活成本会因州而异，所以在一个地区可能是高薪，而在另一个地区可能几乎不足以维持生计。因此，可能更有意义的是，通过他们居住地区的典型收入来归一化客户的收入。这是一个相对简单（且常见）的转换例子。*'
- en: '* * *'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: For this example, you have external information about the median income in each
    state, in a file called median_income.RDS. [Listing 4.7](../Text/04.xhtml#ch04ex07)
    uses this information to normalize the incomes. The code uses a join operation
    to match the information from median_ income.RDS to the existing customer data.
    We will discuss joining tables in the next chapter, but for now, you should understand
    joining as copying data into a data frame from another data frame with matching
    rows.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，你有一个名为median_income.RDS的文件，其中包含每个州的中位数收入的外部信息。[列表4.7](../Text/04.xhtml#ch04ex07)使用这些信息来归一化收入。代码使用连接操作将median_income.RDS中的信息与现有的客户数据进行匹配。我们将在下一章讨论连接表，但就目前而言，你应该理解连接是将数据从另一个数据框复制到具有匹配行的数据框中。
- en: Listing 4.7\. Normalizing income by state
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.7\. 按州归一化收入
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ If you have downloaded the PDSwR2 code example directory, then median_income.RDS
    is in the directory PDSwR2/Custdata. We assume that this is your working directory.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如果你已下载PDSwR2代码示例目录，那么median_income.RDS位于PDSwR2/Custdata目录中。我们假设这是你的工作目录。
- en: ❷ Joins median_income_table into the customer data, so you can normalize each
    person’s income by the median income of their state
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将median_income_table连接到客户数据中，以便你可以按其所在州的中位数收入归一化每个人的收入
- en: ❸ Compares the values of income and income_normalized
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 比较收入和income_normalized的值
- en: Looking at the results in [listing 4.7](../Text/04.xhtml#ch04ex07), you see
    that customers with an income higher than the median income of their state have
    an `income_normalized` value larger than `1`, and customers with an income lower
    than the median income of their state have an `income_normalized` value less than
    `1`. Because customers in different states get a different normalization, we call
    this a *conditional* transform. A long way to say this is that “the normalization
    is conditioned on the customer’s state of residence.” We would call scaling all
    the customers by the same value an *unconditioned* transform.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 查看第[4.7表](../Text/04.xhtml#ch04ex07)的结果，你会发现收入高于其所在州中位数收入的客户，其`income_normalized`值大于`1`，而收入低于其所在州中位数收入的客户，其`income_normalized`值小于`1`。由于不同州的客户得到不同的归一化处理，我们称这种处理为*条件性*转换。换句话说，这种归一化是基于客户居住地的状态。我们称通过相同值对所有客户进行缩放为*非条件性*转换。
- en: The need for data transformation can also depend on which modeling method you
    plan to use. For linear and logistic regression, for example, you ideally want
    to make sure that the relationship between the input variables and the output
    variable is approximately linear, and that the output variable is constant variance
    (the variance of the output variable is independent of the input variables). You
    may need to transform some of your input variables to better meet these assumptions.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换的需要也可能取决于你计划使用的建模方法。例如，对于线性回归和逻辑回归，理想情况下，你希望确保输入变量与输出变量之间的关系大致是线性的，并且输出变量的方差是恒定的（输出变量的方差与输入变量无关）。你可能需要转换一些输入变量以更好地满足这些假设。
- en: 'In this section, we’ll look at some useful data transformations and when to
    use them:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一些有用的数据转换及其应用场景：
- en: Normalization
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化
- en: Centering and scaling
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中心化和缩放
- en: Log transformations
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数转换
- en: 4.2.1\. Normalization
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1\. 标准化
- en: Normalization (or rescaling) is useful when absolute quantities are less meaningful
    than relative ones. You’ve already seen an example of normalizing income relative
    to another meaningful quantity (median income). In that case, the meaningful quantity
    was external (it came from outside information), but it can also be internal (derived
    from the data itself).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化（或缩放）在绝对量不如相对量有意义时很有用。你已经看到了一个将收入相对于另一个有意义的量（中位数收入）进行标准化的例子。在这种情况下，有意义的量是外部的（它来自外部信息），但它也可以是内部的（从数据本身导出）。
- en: For example, you might be less interested in a customer’s absolute age than
    you are in how old or young they are relative to a “typical” customer. Let’s take
    the mean age of your customers to be the typical age. You can normalize by that,
    as shown in the following listing.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可能对客户的绝对年龄不如对客户相对于“典型”客户的年龄大小感兴趣。让我们以客户的平均年龄作为典型年龄。你可以通过以下列表进行标准化。
- en: Listing 4.8\. Normalizing by mean age
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.8\. 通过平均年龄进行标准化
- en: '[PRE8]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: A value for `age_normalized` that is much less than `1` signifies an unusually
    young customer; much greater than `1` signifies an unusually old customer. But
    what constitutes “much less” or “much greater” than `1`? That depends on how wide
    an age spread your customers tend to have. See [figure 4.8](../Text/04.xhtml#ch04fig08)
    for an example.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`age_normalized`的值远小于`1`表示客户异常年轻；远大于`1`表示客户异常年长。但“远小于”或“远大于`1`”是什么意思？这取决于你的客户倾向于有多大的年龄分布。参见[图4.8](../Text/04.xhtml#ch04fig08)以获取示例。'
- en: Figure 4.8\. Is a 35-year-old young?
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8\. 35岁的人算年轻吗？
- en: '![](Images/04fig08_alt.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/04fig08_alt.jpg)'
- en: The average customer in both populations is 50\. The *population 1* group has
    a fairly wide age spread, so a 35-year-old still seems fairly typical (perhaps
    a little young). That same 35-year-old seems unusually young in *population 2*,
    which has a narrow age spread. The typical age spread of your customers is summarized
    by the standard deviation. This leads to another way of expressing the relative
    ages of your customers.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 两个群体中的平均客户年龄都是50岁。*群体1*的年龄分布相对较广，所以35岁的人仍然看起来相当典型（可能有点年轻）。同样的35岁的人在*群体2*中看起来异常年轻，因为群体2的年龄分布较窄。你的客户的典型年龄分布可以通过标准差来总结。这导致了一种表达客户相对年龄的另一种方式。
- en: 4.2.2\. Centering and scaling
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.2\. 中心化和缩放
- en: You can rescale your data by using the standard deviation as a unit of distance.
    A customer who is within one standard deviation of the mean age is considered
    not much older or younger than typical. A customer who is more than one or two
    standard deviations from the mean can be considered much older, or much younger.
    To make the relative ages even easier to understand, you can also center the data
    by the mean, so a customer of “typical age” has a centered age of 0.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用标准差作为距离单位来缩放你的数据。一个年龄在平均年龄加减一个标准差范围内的客户被认为与典型年龄相差不大。一个年龄比平均年龄多一个或两个标准差的客户可以被认为是年龄较大或较小。为了使相对年龄更容易理解，你还可以通过平均值来中心化数据，这样“典型年龄”的客户中心化年龄为0。
- en: Listing 4.9\. Centering and scaling age
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.9\. 中心化和缩放年龄
- en: '[PRE9]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Takes the mean
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算平均值
- en: ❷ Takes the standard deviation
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算标准差
- en: ❸ The typical age range for this population is from about 31 to 67.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 这个群体的典型年龄范围大约在31岁到67岁之间。
- en: ❹ Uses the mean value as the origin (or reference point) and rescales the distance
    from the mean by the standard deviation
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 以平均值作为起点（或参考点），并通过标准差缩放与平均值的距离
- en: ❺ Customers in the typical age range have a scaled_age with magnitude less than
    1.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 典型年龄范围内的客户具有小于1的缩放年龄值。
- en: ❻ Customers outside the typical age range have a scaled_age with magnitude greater
    than 1.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 在典型年龄范围之外的客户具有大于1的缩放年龄值。
- en: Now, values less than `-1` signify customers younger than typical; values greater
    than `1` signify customers older than typical.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，小于 `-1` 的值表示比典型客户年轻的客户；大于 `1` 的值表示比典型客户年长的客户。
- en: '* * *'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**A technicality**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个技术细节**'
- en: The common interpretation of standard deviation as a unit of distance implicitly
    assumes that the data is distributed normally. For a normal distribution, roughly
    two-thirds of the data (about 68%) is within plus/minus one standard deviation
    from the mean. About 95% of the data is within plus/minus two standard deviations
    from the mean. In [figure 4.8](../Text/04.xhtml#ch04fig08) (reproduced as a faceted
    graph in [figure 4.9](../Text/04.xhtml#ch04fig09)), a 35-year-old is within one
    standard deviation from the mean in *population 1*, but more than one (in fact,
    more than two) standard deviations from the mean in *population 2*.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 标准差作为距离单位的常见解释隐含地假设数据是正态分布的。对于正态分布，大约三分之二的数据（大约68%）在均值加减一个标准差范围内。大约95%的数据在均值加减两个标准差范围内。在
    [figure 4.8](../Text/04.xhtml#ch04fig08)（在 [figure 4.9](../Text/04.xhtml#ch04fig09)
    中作为分面图重现）中，一个35岁的人在 *population 1* 中距离均值一个标准差，但在 *population 2* 中超过一个（实际上，超过两个）标准差。
- en: 'Figure 4.9\. Faceted graph: is a 35-year-old young?'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 4.9\. 分面图：35岁的人年轻吗？
- en: '![](Images/04fig09_alt.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig09_alt.jpg)'
- en: You can still use this transformation if the data isn’t normally distributed,
    but the standard deviation is most meaningful as a unit of distance if the data
    is unimodal and roughly symmetric around the mean.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 即使数据不是正态分布的，你仍然可以使用这种变换，但标准差作为距离的单位在数据单峰且大致围绕均值对称时最有意义。
- en: '* * *'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'When you have multiple numeric variables, you can use the `scale()` function
    to center and scale all of them simultaneously. This has the advantage that the
    numeric variables now all have similar and more-compatible ranges. To make this
    concrete, compare the variable *age* in years to the variable *income* in dollars.
    A 10-year difference in age between two customers could be a lot, but a 10-dollar
    difference in income is quite small. If you center and scale both variables, then
    the value 0 means the same thing for both scaled variables: the mean age or mean
    income. And the value 1.5 also means the same thing: a person who is 1.5 standard
    deviations older than the mean age, or who makes 1.5 standard deviations more
    than the mean income. In both situations, the value 1.5 can be considered a big
    difference from the average.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有多个数值变量时，你可以使用 `scale()` 函数同时将它们居中和缩放。这有一个优点，即现在所有数值变量都具有相似且更兼容的范围。为了具体说明，比较变量
    *age*（以年为单位）和变量 *income*（以美元为单位）。两个客户之间10岁的年龄差异可能很大，但10美元的收入差异却相当小。如果你对这两个变量都进行居中和缩放，那么值
    `0` 对两个缩放变量意味着相同的事情：平均年龄或平均收入。而值 `1.5` 也意味着相同的事情：一个比平均年龄高1.5个标准差的个人，或者比平均收入高1.5个标准差的个人。在这两种情况下，值
    `1.5` 可以被认为是从平均值的一个较大差异。
- en: The following listing demonstrates centering and scaling four numerical variables
    from the data with `scale()`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了如何使用 `scale()` 对数据中的四个数值变量进行居中和缩放。
- en: Listing 4.10\. Centering and scaling multiple numeric variables
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Listing 4.10\. 居中和缩放多个数值变量
- en: '[PRE10]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Centers the data by its mean and scales it by its standard deviation
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 通过其均值居中数据，并通过其标准差进行缩放
- en: ❷ Gets the means and standard deviations of the original data, which are stored
    as attributes of dataf_scaled
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取原始数据的均值和标准差，这些值存储为 dataf_scaled 的属性
- en: Because the `scale()` transformation puts all the numeric variables in compatible
    units, it’s a recommended preprocessing step for some data analysis and machine
    learning techniques like principal component analysis and deep learning.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `scale()` 变换将所有数值变量放入兼容的单位，因此它是主成分分析和深度学习等一些数据分析和技术推荐的预处理步骤。
- en: Keep the training transformation
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 保持训练变换
- en: When you use parameters derived from the data (like means, medians, or standard
    deviations) to transform the data before modeling, you generally should keep those
    parameters and use them when transforming new data that will be input to the model.
    When you used the `scale()` function in [listing 4.10](../Text/04.xhtml#ch04ex10),
    you kept the values of the `scaled:center` and `scaled:scale` attributes as the
    variables `means` and `sds`, respectively. This is so that you can use these values
    to scale new data, as shown in [listing 4.11](../Text/04.xhtml#ch04ex11). This
    makes sure that the new scaled data is in the same units as the training data.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用从数据中导出的参数（如均值、中位数或标准差）在建模之前转换数据时，你通常应该保留这些参数，并在转换将输入到模型的新数据时使用它们。当你使用[列表
    4.10](../Text/04.xhtml#ch04ex10)中的`scale()`函数时，你保留了`scaled:center`和`scaled:scale`属性的值作为变量`means`和`sds`。这样做是为了你可以使用这些值来缩放新数据，正如[列表
    4.11](../Text/04.xhtml#ch04ex11)中所示。这确保了新的缩放数据与训练数据具有相同的单位。
- en: The same principle applies when cleaning missing values using the `design_missingness_treatment()`
    function from the `vtreat` package, as you did in [section 4.1.3](../Text/04.xhtml#ch04lev2sec3).
    The resulting treatment plan (called `treatment_plan` in [listing 4.1](../Text/04.xhtml#ch04ex01).3)
    keeps the information from the training data in order to clean missing values
    from new data, as you saw in [listing 4.5](../Text/04.xhtml#ch04ex05).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用`vtreat`包中的`design_missingness_treatment()`函数清理缺失值时，与你在[第 4.1.3 节](../Text/04.xhtml#ch04lev2sec3)中所做的一样，同样的原则适用。产生的处理计划（在[列表
    4.1](../Text/04.xhtml#ch04ex01).3)中称为`treatment_plan`）保留了训练数据中的信息，以便从新数据中清理缺失值，正如你在[列表
    4.5](../Text/04.xhtml#ch04ex05)中所看到的。
- en: Listing 4.11\. Treating new data before feeding it to a model
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.11\. 在将新数据输入模型之前对其进行处理
- en: '[PRE11]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Simulates having a new customer dataset
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 模拟拥有一个新的客户数据集
- en: ❷ Cleans it using the treatment plan from the original dataset
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用原始数据集的处理计划对其进行清理
- en: ❸ Scales age, income, num_vehicles, and gas_usage using the means and standard
    deviations from the original dataset
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用原始数据集的均值和标准差来缩放年龄、收入、车辆数量和油耗
- en: However, there are some situations when you may wish to use new parameters.
    For example, if the important information in the model is how a subject’s income
    relates to the *current* median income, then when preparing new data for modeling,
    you would want to normalize income by the current median income, rather than the
    median income from the time when the model was trained. The implication here is
    that the characteristics of someone who earns three times the median income will
    be different from those of someone who earns less than the median income, and
    that these differences are the same independent of the actual dollar amount of
    the income.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些情况下你可能希望使用新的参数。例如，如果模型中的重要信息是某个主体的收入与*当前*中位数收入的关系，那么在为建模准备新数据时，你将希望使用当前的中位数收入来归一化收入，而不是模型训练时的中位数收入。这里的含义是，收入是中位数三倍的人的特征将不同于收入低于中位数的人的特征，并且这些差异与实际收入金额无关。
- en: 4.2.3\. Log transformations for skewed and wide distributions
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.3\. 对偏斜和宽分布进行对数转换
- en: Normalizing by mean and standard deviation, as you did in [section 4.2.2](../Text/04.xhtml#ch04lev2sec5),
    is most meaningful when the data distribution is roughly symmetric. Next, we’ll
    look at a transformation that can make some distributions more symmetric.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 通过均值和标准差进行归一化，正如你在[第 4.2.2 节](../Text/04.xhtml#ch04lev2sec5)中所做的那样，当数据分布大致对称时最有意义。接下来，我们将探讨一种可以使某些分布更加对称的转换方法。
- en: 'Monetary amounts—incomes, customer value, account values, or purchase sizes—are
    some of the most commonly encountered sources of skewed distributions in data
    science applications. In fact, as we''ll discuss in [appendix B](../Text/B.xhtml#app02),
    monetary amounts are often *lognormally distributed*: the log of the data is normally
    distributed. This leads us to the idea that taking the log of monetary data can
    restore symmetry and scale to the data, by making it look “more normal.” We demonstrate
    this in [figure 4.11](../Text/04.xhtml#ch04fig11).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 货币金额——如收入、客户价值、账户价值或购买大小——是数据科学应用中最常见的偏斜分布来源之一。事实上，正如我们将在[附录 B](../Text/B.xhtml#app02)中讨论的那样，货币金额通常是*对数正态分布*：数据的对数是正态分布的。这导致我们想到，通过对货币数据取对数可以恢复数据的对称性和规模，使其看起来“更正常”。我们在[图
    4.11](../Text/04.xhtml#ch04fig11)中展示了这一点。
- en: 'For the purposes of modeling, it’s generally not too critical which logarithm
    you use, whether the natural logarithm, log base 10, or log base 2\. In regression,
    for example, the choice of logarithm affects the magnitude of the coefficient
    that corresponds to the logged variable, but it doesn’t affect the structure of
    the model. We like to use log base 10 for monetary amounts, because orders of
    ten seem natural for money: $100, $1000, $10,000, and so on. The transformed data
    is easy to read.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于建模的目的，通常使用哪种对数并不太关键，无论是自然对数、以10为底的对数还是以2为底的对数。例如，在回归分析中，对数的选择会影响对应于对数变量的系数的大小，但它不会影响模型的架构。我们喜欢使用以10为底的对数来表示货币金额，因为十进制对于金钱来说似乎是自然的：$100，$1000，$10,000等等。变换后的数据易于阅读。
- en: '* * *'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '***'
- en: An aside on graphing
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 关于图形的一个补充
- en: Notice that the bottom panel of [figure 4.10](../Text/04.xhtml#ch04fig10) has
    the same shape as [figure 3.7](../Text/03.xhtml#ch03fig07). The difference between
    using the `ggplot` layer `scale_x_log10` on a density plot of *income* and plotting
    a density plot of *log10(income)* is primarily axis labeling. Using `scale_x_log10`
    will label the x-axis in dollar amounts, rather than in logs.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到[图4.10](../Text/04.xhtml#ch04fig10)的底部面板与[图3.7](../Text/03.xhtml#ch03fig07)具有相同的形状。在*收入*的密度图上使用`ggplot`层的`scale_x_log10`与绘制*log10(income)*的密度图之间的主要区别是轴标签。使用`scale_x_log10`将对x轴进行美元金额的标注，而不是对数。
- en: '* * *'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '***'
- en: Figure 4.10\. A nearly lognormal distribution and its log
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.10。一个近似对数正态分布及其对数
- en: '![](Images/04fig10_alt.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/04fig10_alt.jpg)'
- en: It’s also generally a good idea to log transform data containing values that
    range over several orders of magnitude, for example, the population of towns and
    cities, which may range from a few hundred to several million. One reason for
    this is that modeling techniques often have a difficult time with very wide data
    ranges. Another reason is because such data often comes from multiplicative processes
    rather than from an additive one, so log units are in some sense more natural.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 对于包含跨越几个数量级的值的数值数据，通常进行对数变换也是一个好主意，例如城镇和城市的居民数量，可能从几百到几百万不等。这样做的一个原因是因为建模技术往往难以处理非常宽的数据范围。另一个原因是，这类数据通常来自乘法过程，而不是加法过程，因此对数单位在某种程度上更为自然。
- en: As an example of an *additive* process, suppose you are studying weight loss.
    If you weigh 150 pounds and your friend weighs 200, you’re equally active, and
    you both go on the exact same restricted-calorie diet, then you’ll probably both
    lose about the same number of pounds. How much weight you lose doesn’t depend
    on how much you weighed in the first place, only on calorie intake. The natural
    unit of measurement in this situation is absolute pounds (or kilograms) lost.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种**加法**过程的例子，假设你正在研究减肥。如果你体重150磅，而你的朋友体重200磅，你们两人同样活跃，并且你们都采取了完全相同的限制卡路里饮食，那么你们可能都会减掉大约相同数量的磅数。你减掉的体重并不取决于你最初体重有多少，而只取决于卡路里摄入量。在这种情况下，自然单位是绝对磅数（或千克）的减少。
- en: 'As an example of a *multiplicative* process, consider salary increases. If
    management gives everyone in the department a raise, it probably isn’t giving
    everyone $5,000 extra. Instead, everyone gets a 2% raise: how much extra money
    ends up in your paycheck depends on your initial salary. In this situation, the
    natural unit of measurement is percentage, not absolute dollars. Other examples
    of multiplicative processes:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 作为乘法过程的例子，考虑工资增长。如果管理层给部门里的每个人都加薪，那么它可能并不是给每个人都额外加$5,000。相反，每个人都得到2%的加薪：你最终工资中增加的金额取决于你的初始工资。在这种情况下，自然单位是百分比，而不是绝对美元。其他乘法过程的例子：
- en: A change to an online retail site increases conversion (purchases) for each
    item by 2% (not by exactly two purchases).
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线零售网站的变化会使每个商品的转化率（购买）增加2%（而不是每晚正好增加两个购买）。
- en: A change to a restaurant menu increases patronage every night by 5% (not by
    exactly five customers every night).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 餐厅菜单的任何变化都会使每晚的顾客数量增加5%（而不是每晚正好增加五个顾客）。
- en: When the process is multiplicative, log transforming the process data can make
    modeling easier.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当过程是乘法时，对数变换过程数据可以使建模更容易。
- en: 'Unfortunately, taking the logarithm only works if the data is non-negative,
    because the log of zero is –Infinity and the log of negative values isn’t defined
    (R marks the log of negative numbers as `NaN`: not a number). There are other
    transforms, such as *arcsinh*, that you can use to decrease data range if you
    have zero or negative values. We don’t always use *arcsinh*, because we don’t
    find the values of the transformed data to be meaningful. In applications where
    the skewed data is monetary (like account balances or customer value), we instead
    use what we call a *signed logarithm*. A signed logarithm takes the logarithm
    of the absolute value of the variable and multiplies by the appropriate sign.
    Values strictly between `-1` and `1` are mapped to zero. The difference between
    log and signed log is shown in [figure 4.11](../Text/04.xhtml#ch04fig11).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，只有当数据是非负的时，取对数才有效，因为零的对数是负无穷大，负数的对数没有定义（R将负数的对数标记为`NaN`：不是一个数字）。还有其他转换，如*arcsinh*，可以在你有零或负值时用来减少数据范围。我们并不总是使用*arcsinh*，因为我们发现转换后的数据值并不具有意义。在数据偏斜是货币（如账户余额或客户价值）的应用中，我们使用我们称之为*带符号对数*的方法。带符号对数取变量的绝对值对数并乘以适当的符号。严格位于`-1`和`1`之间的值被映射到零。对数和带符号对数之间的区别在[图4.11](../Text/04.xhtml#ch04fig11)中显示。
- en: Figure 4.11\. Signed log lets you visualize non-positive data on a logarithmic
    scale.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11. 带符号的对数可以将非正值数据可视化在对数尺度上。
- en: '![](Images/04fig11_alt.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图4.11的替代图片](Images/04fig11_alt.jpg)'
- en: 'Here’s how to calculate signed log base 10 in R:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在R中计算带符号的对数底数为10的方法：
- en: '[PRE12]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This maps all datums between -1 and 1 to zero, so clearly this transformation
    isn’t useful if values with magnitude less than 1 are important. But with many
    monetary variables (in US currency), values less than a dollar aren’t much different
    from zero (or 1), for all practical purposes. So, for example, mapping account
    balances that are less than or equal to $1 (the equivalent of every account always
    having a minimum balance of $1) is probably okay. You can also pick a larger threshold
    for “small,” such as $100\. This would map the small accounts of less than $100
    to the same value, and eliminate the long left tail in [figures 4.10](../Text/04.xhtml#ch04fig10)
    and [4.11](../Text/04.xhtml#ch04fig11). In some situations, eliminating this long
    tail can be desirable—for one thing, it makes a graph of the data less visually
    skewed.^([[4](../Text/04.xhtml#ch04fn4)])
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法将-1和1之间的所有数据映射到零，因此如果小于1的数值很重要，这种转换显然是不实用的。但是，对于许多货币变量（如美元），实际上小于一美元的数值与零（或1）没有太大区别。因此，例如，将账户余额小于或等于1美元（相当于每个账户始终有最低余额1美元）进行映射可能是可以的。您还可以为“小”选择一个更大的阈值，例如100美元。这将把小于100美元的小账户映射到相同的值，并消除[图4.10](../Text/04.xhtml#ch04fig10)和[4.11](../Text/04.xhtml#ch04fig11)中的长左尾。在某些情况下，消除这个长尾可能是希望的——一方面，它使数据图表的视觉偏差减少。[4](../Text/04.xhtml#ch04fn4)]
- en: ⁴
  id: totrans-189
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ⁴
- en: ''
  id: totrans-190
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There are methods other than capping to deal with signed logarithms, such as
    the arcsinh function (see [http://mng.bz/ZWQa](http://mng.bz/ZWQa)), but they
    also distort data near zero and make almost any data appear to be bimodal, which
    can be deceiving.
  id: totrans-191
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 除了截断之外，还有其他方法可以处理带符号的对数，例如反正弦函数（见[http://mng.bz/ZWQa](http://mng.bz/ZWQa)），但它们也会扭曲接近零的数据，并使几乎任何数据看起来是双峰的，这可能具有欺骗性。
- en: Once you’ve got the data suitably cleaned and transformed, you’re almost ready
    to start the modeling stage. Before we get there, we have one more step.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据得到了适当的清理和转换，你几乎可以开始建模阶段了。在我们到达那里之前，我们还有一步。
- en: 4.3\. Sampling for modeling and validation
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3. 用于建模和验证的抽样
- en: Sampling is the process of selecting a subset of a population to represent the
    whole during analysis and modeling. In the current era of big datasets, some people
    argue that computational power and modern algorithms let us analyze the entire
    large dataset without the need to sample. But keep in mind even “big data” is
    usually itself a sample from a larger universe. So some understanding of sampling
    is always needed to work with data.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样是选择一个子集来代表总体，在分析和建模过程中的过程。在当前的大数据集时代，有些人认为计算能力和现代算法让我们能够分析整个大型数据集，而不需要抽样。但请记住，“大数据”本身通常是从更大的宇宙中抽取的样本。因此，了解抽样对于处理数据总是必要的。
- en: We can certainly analyze larger datasets than we could before, but sampling
    is still a useful tool. When you’re in the middle of developing or refining a
    modeling procedure, it’s easier to test and debug the code on small subsamples
    before training the model on the entire dataset. Visualization can be easier with
    a subsample of the data; `ggplot` runs faster on smaller datasets, and too much
    data will often obscure the patterns in a graph, as we mentioned in [chapter 3](../Text/03.xhtml#ch03).
    And often it’s not feasible to use your entire customer base to train a model.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然可以分析比以前更大的数据集，但抽样仍然是一个有用的工具。当你处于开发或改进建模过程的中途时，在训练整个数据集之前，在小子样本上测试和调试代码会更简单。使用数据子样本进行可视化可能更容易；`ggplot`
    在较小的数据集上运行得更快，过多的数据往往会模糊图表中的模式，正如我们在[第 3 章](../Text/03.xhtml#ch03) 中提到的。而且，通常不可能使用你的整个客户群来训练一个模型。
- en: It’s important that the dataset that you do use is an accurate representation
    of your population as a whole. For example, your customers might come from all
    over the United States. When you collect your customer data, it might be tempting
    to use all the customers from one state, say Connecticut, to train the model.
    But if you plan to use the model to make predictions about customers all over
    the country, it’s a good idea to pick customers randomly from all the states,
    because what predicts health insurance coverage for Texas customers might be different
    from what predicts health insurance coverage in Connecticut. This might not always
    be possible (perhaps only your Connecticut and Massachusetts branches currently
    collect the customer health insurance information), but the shortcomings of using
    a nonrepresentative dataset should be kept in mind.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你使用的整个数据集能够准确代表你的整体人群是很重要的。例如，你的客户可能来自美国的各个地方。当你收集客户数据时，可能会倾向于使用一个州的所有客户，比如康涅狄格州，来训练模型。但如果你计划使用该模型来预测全国各地的客户，那么随机从所有州选择客户是一个好主意，因为预测德克萨斯州客户健康保险覆盖率的因素可能与预测康涅狄格州健康保险覆盖率的因素不同。这可能并不总是可行的（也许只有康涅狄格州和马萨诸塞州的分支机构目前收集客户健康保险信息），但使用非代表性数据集的缺点应该引起注意。
- en: Another reason to sample your data is to create test and training splits.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个对数据进行抽样的原因是创建测试和训练分割。
- en: 4.3.1\. Test and training splits
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1\. 测试和训练分割
- en: When you’re building a model to make predictions, like our model to predict
    the probability of health insurance coverage, you need data to build the model.
    You also need data to test whether the model makes correct predictions on new
    data. The first set is called the *training set*, and the second set is called
    the *test* (or *holdout*) set. [Figure 4.12](../Text/04.xhtml#ch04fig12) shows
    the splitting process (along with an optional split for a calibration set, which
    is discussed in the sidebar “[Train/calibration/test splits](../Text/04.xhtml#ch04sb03)”).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当你构建一个用于预测的模型，比如我们预测健康保险覆盖概率的模型时，你需要数据来构建模型。你还需要数据来测试模型是否能在新数据上做出正确的预测。第一个集合被称为**训练集**，第二个集合被称为**测试集**（或**保留集**）。[图
    4.12](../Text/04.xhtml#ch04fig12) 展示了分割过程（以及可选的校准集分割，详见侧边栏 “[训练/校准/测试分割](../Text/04.xhtml#ch04sb03)”）。
- en: Figure 4.12\. Splitting data into training and test (or training, calibration,
    and test) sets
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12\. 将数据分割成训练集和测试集（或训练、校准和测试集）
- en: '![](Images/04fig12_alt.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig12_alt.jpg)'
- en: The training set is the data that you feed to the model-building algorithm (we'll
    cover specific algorithms in [part 2](../Text/p2.xhtml#part02)) so that the algorithm
    can fit the correct structure to best predict the outcome variable. The test set
    is the data that you feed into the resulting model, to verify that the model’s
    predictions will be accurate on new data. We’ll go into detail about the kinds
    of modeling issues that you can detect by using holdout data in [chapter 6](../Text/06.xhtml#ch06).
    For now, we’ll get our data ready for doing holdout experiments at a later stage.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集是提供给模型构建算法（我们将在[第 2 部分](../Text/p2.xhtml#part02)中介绍具体算法）的数据，以便算法能够拟合正确的结构以最佳预测结果变量。测试集是输入到最终模型中的数据，以验证模型在新数据上的预测是否准确。我们将在[第
    6 章](../Text/06.xhtml#ch06)中详细介绍你可以通过使用保留数据检测到的建模问题。现在，我们将为稍后进行的保留实验准备数据。
- en: '* * *'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Train/calibration/test splits**'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练/校准/测试分割**'
- en: 'Many writers recommend train/calibration/test splits, where the *calibration
    set* is used to set parameters that the model-fitting algorithm needs, and the
    training set is used to fit the model. This is also good advice. Our philosophy
    is this: split the data into train/test early, don’t look at test until final
    evaluation, and if you need calibration data, resplit it from your training subset.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 许多作家推荐使用训练/校准/测试分割，其中 *校准集* 用于设置模型拟合算法需要的参数，而训练集用于拟合模型。这也是一条很好的建议。我们的理念是这样的：尽早将数据分割为训练/测试，直到最终评估前不要查看测试数据，如果您需要校准数据，则从您的训练子集中重新分割。
- en: '* * *'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 4.3.2\. Creating a sample group column
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.2\. 创建样本组列
- en: A convenient way to manage random sampling is to add a sample group column to
    the data frame. The sample group column contains a number generated uniformly
    from zero to one, using the `runif()` function. You can draw a random sample of
    arbitrary size from the data frame by using the appropriate threshold on the sample
    group column.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 管理随机采样的便捷方法是在数据框中添加一个样本组列。该样本组列包含使用 `runif()` 函数生成的从零到一的均匀数。您可以通过对样本组列使用适当的阈值从数据框中抽取任意大小的随机样本。
- en: For example, once you’ve labeled all the rows of your data frame with your sample
    group column (let’s call it `gp`), then the set of all rows such that `gp` < 0.4
    will be about four-tenths, or 40%, of the data. The set of all rows where `gp`
    is between 0.55 and 0.70 is about 15% of the data (0.7 – 0.55 = 0.15). So you
    can repeatably generate a random sample of the data of any size by using `gp`.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一旦您已经使用样本组列（让我们称它为 `gp`）标记了数据框的所有行，那么 `gp` < 0.4 的所有行将大约是四分之一，即 40% 的数据。`gp`
    在 0.55 和 0.70 之间的所有行大约是数据的 15%（0.7 – 0.55 = 0.15）。因此，您可以通过使用 `gp` 可重复地生成任何大小的数据随机样本。
- en: Listing 4.12\. Splitting into test and training using a random group mark
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.12\. 使用随机分组标记分割为测试集和训练集
- en: '[PRE13]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Sets the random seed so this example is reproducible
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置随机种子，以确保此示例可重复
- en: ❷ Creates the grouping column
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建分组列
- en: ❸ Here we generate a test set of about 10% of the data.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在这里，我们生成大约 10% 的数据测试集。
- en: ❹ Here we generate a training set using the remaining data.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在这里，我们使用剩余的数据生成一个训练集。
- en: '[Listing 4.12](../Text/04.xhtml#ch04ex12) generates a test set of approximately
    10% of the data and allocates the remaining 90% of the data to the training set.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 4.12](../Text/04.xhtml#ch04ex12) 生成大约 10% 的数据测试集，并将剩余的 90% 数据分配给训练集。'
- en: The `dplyr` package also has functions called `sample_n()` and `sample_frac()`
    that draw a random sample (a uniform random sample, by default) from a data frame.
    Why not just use one of these to draw training and test sets? You could, but you
    should make sure to set the random seed via the `set.seed()` command (as we did
    in [listing 4.12](../Text/04.xhtml#ch04ex12)) to guarantee that you’ll draw the
    same sample group every time. Reproducible sampling is essential when you’re debugging
    code. In many cases, code will crash because of a corner case that you forgot
    to guard against. This corner case might show up in your random sample. If you’re
    using a different random input sample every time you run the code, you won’t know
    if you will tickle the bug again. This makes it hard to track down and fix errors.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`dplyr` 包也有名为 `sample_n()` 和 `sample_frac()` 的函数，可以从数据框中抽取随机样本（默认为均匀随机样本）。为什么不直接使用这些中的一个来抽取训练集和测试集呢？您可以这样做，但您应该确保通过
    `set.seed()` 命令（就像我们在[列表 4.12](../Text/04.xhtml#ch04ex12)中所做的那样）设置随机种子，以确保您每次都会抽取相同的样本组。在调试代码时，可重复采样是必不可少的。在许多情况下，代码会因为您忘记防范的边缘情况而崩溃。这个边缘情况可能会出现在您的随机样本中。如果您每次运行代码时都使用不同的随机输入样本，您将不知道是否会再次触发该错误。这使得跟踪和修复错误变得困难。'
- en: You also want repeatable input samples for what software engineers call *regression
    testing* (not to be confused with statistical regression). In other words, when
    you make changes to a model or to your data treatment, you want to make sure you
    don’t break what was already working. If model version 1 was giving “the right
    answer” for a certain input set, you want to make sure that model version 2 does
    so also.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 您还希望对于软件工程师所说的 *回归测试*（不要与统计回归混淆）有可重复的输入样本。换句话说，当您对模型或数据处理进行更改时，您想确保您不会破坏已经正常工作的事物。如果模型版本
    1 为某个输入集提供了“正确答案”，您想确保模型版本 2 也能这样做。
- en: We find that storing a sample group column with the data is a more reliable
    way to guarantee reproducible sampling during development and testing.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，将样本组列与数据一起存储是保证在开发和测试期间可重复采样的一种更可靠的方法。
- en: '* * *'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Reproducible sampling is not just a trick for R
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 可重复抽样的技巧不仅适用于R
- en: If your data is in a database or other external store, and you only want to
    pull a subset of the data into R for analysis, you can draw a reproducible random
    sample by generating a sample group column in an appropriate table in the database,
    using the SQL command `RAND`.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据存储在数据库或其他外部存储中，而你只想将数据的一个子集拉入R进行分析，你可以在数据库中适当表中生成一个样本组列，使用SQL命令`RAND`来抽取一个可重复的随机样本。
- en: '* * *'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 4.3.3\. Record grouping
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.3\. 记录分组
- en: One caveat is that the preceding trick works if every object of interest (every
    customer, in this case) corresponds to a unique row. But what if you’re interested
    less in which customers don’t have health insurance, and more in which households
    have uninsured members? If you’re modeling a question at the household level rather
    than the customer level, then every member of a household should be in the same
    group (test or training). In other words, the random sampling also has to be at
    the household level.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 一个注意事项是，前面的技巧在感兴趣的每个对象（在这种情况下是每个客户）对应一个唯一行时才有效。但如果你对哪些客户没有健康保险的兴趣较少，而对哪些家庭有未投保成员的兴趣更多呢？如果你在家庭层面而不是客户层面建模问题，那么家庭中的每个成员都应该在同一组（测试或训练）中。换句话说，随机抽样也必须在家庭层面进行。
- en: Suppose your customers are marked both by a household ID and a customer ID.
    This is shown in [figure 4.13](../Text/04.xhtml#ch04fig13). We want to split the
    households into a training set and a test set. [Listing 4.13](../Text/04.xhtml#ch04ex13)
    shows one way to generate an appropriate sample group column.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的客户既由家庭ID标记，也由客户ID标记。这显示在[图4.13](../Text/04.xhtml#ch04fig13)中。我们想要将家庭分成训练集和测试集。[列表4.13](../Text/04.xhtml#ch04ex13)显示了一种生成适当的样本组列的方法。
- en: Figure 4.13\. Example of a dataset with customers and households
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13\. 具有客户和家庭的示例数据集
- en: '![](Images/04fig13.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig13.jpg)'
- en: Listing 4.13\. Ensuring test/train split doesn’t split inside a household
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.13\. 确保测试/训练分割不会在家庭内部分割
- en: '[PRE14]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ If you have downloaded the PDSwR2 code example directory, then the household
    dataset is in the directory PDSwR2/Custdata. We assume that this is your working
    directory.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如果你已下载了PDSwR2代码示例目录，那么家庭数据集位于PDSwR2/Custdata目录中。我们假设这是你的工作目录。
- en: ❷ Gets the unique household IDs
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取唯一的家庭ID
- en: ❸ Generates a unique sampling group ID per household, and puts in a column named
    gp
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 为每个家庭生成唯一的抽样组ID，并将其放入名为gp的列中
- en: ❹ Joins the household IDs back into the original data
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将家庭ID重新合并到原始数据中
- en: The resulting sample group column is shown in [figure 4.14](../Text/04.xhtml#ch04fig14).
    Everyone in a household has the same sampling group number.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 结果样本组列显示在[图4.14](../Text/04.xhtml#ch04fig14)。家庭中的每个人都有相同的样本组编号。
- en: Figure 4.14\. Sampling the dataset by household rather than customer
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14\. 按家庭而非客户进行数据集抽样
- en: '![](Images/04fig14_alt.jpg)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig14_alt.jpg)'
- en: Now we can generate the test and training sets as before. This time, however,
    the threshold 0.1 doesn’t represent 10% of the data rows, but 10% of the households,
    which may be more or less than 10% of the data, depending on the sizes of the
    households.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以像以前一样生成测试集和训练集。然而，这次阈值0.1并不代表数据行的10%，而是家庭的10%，这可能会多或少于10%的数据，具体取决于家庭的大小。
- en: 4.3.4\. Data provenance
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.4\. 数据来源
- en: 'You’ll also want to add a column (or columns) to record data provenance: when
    your dataset was collected, perhaps what version of your data-cleaning procedure
    was used on the data before modeling, and so on. This metadata is akin to version
    control for data. It’s handy information to have, to make sure that you’re comparing
    apples to apples when you’re in the process of improving your model, or comparing
    different models or different versions of a model.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可能想要添加一个（或多个）列来记录数据来源：你的数据集何时收集的，也许在建模之前使用了哪个版本的数据清理程序，等等。这种元数据类似于数据的版本控制。当你正在改进模型或比较不同模型或模型的不同版本时，这是一些方便的信息，以确保你是在比较苹果和苹果。
- en: '[Figure 4.15](../Text/04.xhtml#ch04fig15) shows an example of some possible
    metadata added to training data. In this example, you have recorded the original
    data source (called “data pull 8/2/18”), when the data was collected, and when
    it was treated. If, for example, the treatment date on the data is earlier than
    the most recent version of your data treatment procedures, then you know that
    this treated data is possibly obsolete. Thanks to the metadata, you can go back
    to the original data source and treat it again.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4.15](../Text/04.xhtml#ch04fig15) 展示了添加到训练数据中的一些可能的元数据示例。在这个例子中，你记录了原始数据源（称为“数据提取8/2/18”），数据收集的时间以及处理的时间。例如，如果数据上的处理日期早于你最近的数据处理程序版本，那么你知道这个处理过的数据可能是过时的。多亏了元数据，你可以回到原始数据源并再次处理它。'
- en: Figure 4.15\. Recording the data source, collection date, and treatment date
    with data
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.15\. 使用数据记录数据源、收集日期和处理日期
- en: '![](Images/04fig15_alt.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig15_alt.jpg)'
- en: Summary
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: At some point, you’ll have data quality that is as good as you can make it.
    You’ve fixed problems with missing data and performed any needed transformations.
    You’re ready to go on to the modeling stage.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时候，你将拥有尽可能好的数据质量。你已经解决了缺失数据的问题，并执行了任何需要的转换。你现在可以进入建模阶段。
- en: Remember, though, that data science is an iterative process. You may discover
    during the modeling process that you have to do additional data cleaning or transformation.
    You may have to go back even further and collect different types of data. That’s
    why we recommend adding columns for sample groups and data provenance to your
    datasets (and, later, to the models and model output), so you can keep track of
    the data management steps as the data and the models evolve.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，请记住，数据科学是一个迭代的过程。在建模过程中，你可能会发现你需要进行额外的数据清理或转换。你可能需要回溯得更远，收集不同类型的数据。这就是为什么我们建议在你的数据集中添加样本组和数据来源的列（稍后，在模型和模型输出中），这样你就可以在数据和模型演变过程中跟踪数据管理步骤。
- en: In this chapter you have learned
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了
- en: Different ways of handling missing values may be more suitable for a one purpose
    or another.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理缺失值的不同方法可能更适合某个特定的目的或另一个目的。
- en: You can use the `vtreat` package to manage missing values automatically.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用`vtreat`包来自动管理缺失值。
- en: How to normalize or rescale data, and when normalization/rescaling are appropriate.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何归一化或缩放数据，以及何时进行归一化/缩放是合适的。
- en: How to log transform data, and when log transformations are appropriate.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何进行对数转换数据，以及何时对数转换是合适的。
- en: How to implement a reproducible sampling scheme for creating test/train splits
    of your data.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何实现一个可重复的采样方案来创建你的数据的测试/训练分割。
