- en: 14 Monitoring applications and Kubernetes with Prometheus
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14 使用 Prometheus 监控应用程序和 Kubernetes
- en: 'Monitoring is the companion to logging: your monitoring system tells you something
    is wrong, and then you can dig into the logs to find out the details. Like logging,
    you want to have a centralized system to collect and visualize metrics about all
    your application components. An established approach for monitoring in Kubernetes
    uses another CNCF project: Prometheus, which is a server application that collects
    and stores metrics. In this chapter, you’ll learn how to deploy a shared monitoring
    system in Kubernetes with dashboards that show the health of individual applications
    and the cluster as a whole.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 监控是日志记录的伴侣：你的监控系统会告诉你有什么问题，然后你可以深入日志以找出详细信息。像日志记录一样，你希望有一个集中式系统来收集和可视化所有应用组件的指标。在
    Kubernetes 中进行监控的一种既定方法使用另一个 CNCF 项目：Prometheus，它是一个收集和存储指标的服务器应用程序。在本章中，你将学习如何在
    Kubernetes 中部署一个共享的监控系统，该系统包含显示单个应用程序和整个集群健康状况的仪表板。
- en: Prometheus runs on many platforms, but it’s particularly well suited to Kubernetes.
    You run Prometheus in a Pod that has access to the Kubernetes API server, and
    then Prometheus queries the API to find all the targets it needs to monitor. When
    you deploy new apps, you don’t need to make any setup changes—Prometheus discovers
    them automatically and starts collecting metrics. Kubernetes apps are particularly
    well suited to Prometheus, too. You’ll see in this chapter how to make good use
    of the sidecar pattern, so every app can provide some metrics to Prometheus, even
    if the application itself isn’t Prometheus-ready.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 在许多平台上运行，但它特别适合 Kubernetes。你在具有访问 Kubernetes API 服务器的 Pod 中运行 Prometheus，然后
    Prometheus 查询 API 以找到它需要监控的所有目标。当你部署新应用时，你不需要进行任何设置更改——Prometheus 会自动发现它们并开始收集指标。Kubernetes
    应用程序也非常适合 Prometheus。你将在本章中看到如何充分利用边车模式，以便每个应用程序都可以向 Prometheus 提供一些指标，即使应用程序本身不是
    Prometheus 准备好的。
- en: 14.1 How Prometheus monitors Kubernetes workloads
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.1 Prometheus 如何监控 Kubernetes 工作负载
- en: 'Metrics in Prometheus are completely generic: each component you want to monitor
    has an HTTP endpoint, which returns all the values that are important to that
    component. A web server includes metrics for the number of requests it serves,
    and a Kubernetes node includes metrics for how much memory is available. Prometheus
    doesn’t care what’s in the metrics; it just stores everything the component returns.
    What’s important to Prometheus is a list of targets it needs to collect from.
    Figure 14.1 shows how that works in Kubernetes, using Prometheus’s built-in service
    discovery.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 中的指标是完全通用的：你想要监控的每个组件都有一个 HTTP 端点，它返回对该组件重要的所有值。一个 Web 服务器包括它服务的请求数量的指标，而
    Kubernetes 节点包括可用内存的指标。Prometheus 不关心指标中有什么；它只是存储组件返回的所有内容。对 Prometheus 来说重要的是它需要收集的目标列表。图
    14.1 显示了在 Kubernetes 中它是如何使用 Prometheus 内置的服务发现来工作的。
- en: '![](../Images/14-1.jpg)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/14-1.jpg)'
- en: Figure 14.1 Prometheus uses a pull model to collect metrics, automatically finding
    targets.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1 Prometheus 使用拉模型收集指标，自动查找目标。
- en: The focus in this chapter is getting Prometheus working nicely with Kubernetes,
    to give you a dynamic monitoring system that keeps working as your cluster expands
    with more nodes running more applications. I won’t go into much detail on how
    you add monitoring to your applications or what metrics you should record—appendix
    B in the ebook is the chapter “Adding Observability with Containerized Monitoring”
    from *Learn Docker in a Month of Lunches*, which will give you that additional
    detail.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点是让 Prometheus 与 Kubernetes 顺利配合，为你提供一个动态的监控系统，随着你的集群随着更多运行更多应用的节点而扩展时，它仍然可以正常工作。我不会过多地详细介绍如何将监控添加到你的应用程序中或你应该记录哪些指标——电子书附录
    B 中的章节“使用容器化监控添加可观察性”来自《一个月午餐学 Docker》，它将提供这些额外的细节。
- en: We’ll start by getting Prometheus up and running. The Prometheus server is a
    single component that takes care of service discovery and metrics collection and
    storage, and it has a basic web UI that you can use to check the status of the
    system and run simple queries.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先让 Prometheus 启动并运行。Prometheus 服务器是一个负责服务发现和指标收集及存储的单个组件，它有一个基本的 Web UI，你可以使用它来检查系统状态并运行简单的查询。
- en: Try it now Deploy Prometheus in a dedicated monitoring namespace, configured
    to find apps in a test namespace (the test namespace doesn’t exist yet).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：在专用的监控命名空间中部署 Prometheus，配置为在测试命名空间中查找应用（测试命名空间尚不存在）。
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Prometheus calls metrics collection *scraping*. When you browse to the Prometheus
    UI, you’ll see there are no scrape targets, although there is a category called
    `test-pods`, which lists zero targets. Figure 14.2 shows my output. The `test-pods`
    name comes from the Prometheus configuration you deployed in a ConfigMap, which
    the Pod reads from.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 将指标收集称为 *scraping*。当你浏览到 Prometheus UI 时，你会看到没有抓取目标，尽管有一个名为 `test-pods`
    的类别，其中列出零个目标。图 14.2 显示了我的输出。`test-pods` 的名称来自你在 ConfigMap 中部署的 Prometheus 配置，Pod
    会从中读取。
- en: '![](../Images/14-2.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/14-2.jpg)'
- en: Figure 14.2 No targets yet, but Prometheus will keep checking the Kubernetes
    API for new Pods.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2 目前没有目标，但 Prometheus 会持续检查 Kubernetes API 中的新 Pods。
- en: Configuring Prometheus to find targets in Kubernetes is fairly straightforward,
    although the terminology is confusing at first. Prometheus uses *jobs* to define
    a related set of targets to scrape, which could be multiple components of an application.
    The scrape configuration can be as simple as a static list of domain names, which
    Prometheus polls to grab the metrics, or it can use dynamic service discovery.
    Listing 14.1 shows the beginning of the `test-pods` job configuration, which uses
    the Kubernetes API for service discovery.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 配置 Prometheus 在 Kubernetes 中查找目标是相当直接的，尽管一开始术语可能令人困惑。Prometheus 使用 *jobs* 来定义一组相关的目标以进行抓取，这些目标可能是应用程序的多个组件。抓取配置可以是一个静态域名列表，Prometheus
    会轮询以抓取指标，或者它可以使用动态服务发现。列表 14.1 显示了 `test-pods` 作业配置的开始，它使用 Kubernetes API 进行服务发现。
- en: Listing 14.1 prometheus-config.yaml, scrape configuration with Kubernetes
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.1 prometheus-config.yaml，带有 Kubernetes 的抓取配置
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It’s the `relabel_configs` section that needs explanation. Prometheus stores
    metrics with *labels*, which are key-value pairs that identify the source system
    and other relevant information. You’ll use labels in queries to select or aggregate
    metrics, and you can also use them to filter or modify metrics before they are
    stored in Prometheus. This is *relabeling*, and conceptually, it’s similar to
    the data pipeline in Fluent Bit—it’s your chance to discard data you don’t want
    and reshape the data you do want.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 需要解释的是 `relabel_configs` 部分。Prometheus 使用 *labels* 存储指标，这些是标识源系统和其他相关信息的键值对。你将在查询中使用标签来选择或聚合指标，你还可以在它们存储在
    Prometheus 之前使用它们来过滤或修改指标。这是 *relabeling*，从概念上讲，它与 Fluent Bit 中的数据管道相似——这是你丢弃不需要的数据和重塑你想要的数据的机会。
- en: 'Regular expressions rear their unnecessarily complicated heads in Prometheus,
    too, but it’s rare that you need to make changes. The pipeline you set up in the
    relabeling phase should be generic enough to work for all your apps. The full
    pipeline in the configuration file applies the following rules:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式在 Prometheus 中也显得过于复杂，但通常不需要进行更改。你在重命名阶段设置的管道应该足够通用，以适用于所有应用程序。配置文件中的完整管道应用以下规则：
- en: Include Pods only from the namespace `kiamol-ch14-test`.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅包括来自 `kiamol-ch14-test` 命名空间的 Pods。
- en: Use the Pod name as the value of the Prometheus `instance` label.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Pod 名称用作 Prometheus `instance` 标签的值。
- en: Use the app label in the Pod metadata as the value of the Prometheus `job` label.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Pod 元数据中的应用程序标签用作 Prometheus `job` 标签的值。
- en: Use optional annotations in the Pod metadata to configure the scrape target.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Pod 元数据中使用可选的注释来配置抓取目标。
- en: This approach is convention-driven—as long as your apps are modeled to suit
    the rules, they’ll automatically be picked up as monitoring targets. Prometheus
    uses the rules to find Pods that match, and for each target, it collects metrics
    by making an HTTP GET request to the `/metrics` path. Prometheus needs to know
    which network port to use, so the Pod spec needs to explicitly include the container
    port. That’s a good practice anyway because it helps to document your application’s
    setup. Let’s deploy a simple app to the test namespace and see what Prometheus
    does with it.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法是由约定驱动的——只要你的应用程序按照规则建模，它们就会自动被识别为监控目标。Prometheus 使用规则来查找匹配的 Pods，并为每个目标，通过向
    `/metrics` 路径发起 HTTP GET 请求来收集指标。Prometheus 需要知道使用哪个网络端口，因此 Pod 规范需要明确包含容器端口。这始终是一个好的做法，因为它有助于记录你的应用程序的设置。让我们将一个简单的应用程序部署到测试命名空间，看看
    Prometheus 会如何处理它。
- en: Try it now Deploy the timecheck application to the test namespace. The spec
    matches all the Prometheus scrape rules, so the new Pod should be found and added
    as a scrape target.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：将 timecheck 应用程序部署到测试命名空间。规范与所有 Prometheus 抓取规则匹配，因此新的 Pod 应该会被找到并添加为抓取目标。
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: My output is shown in figure 14.3, where I’ve opened two browser windows so
    you can see what happened when the app was deployed. Prometheus saw the timecheck
    Pod being created, and it matched all the rules in the relabel stage, so it was
    added as a target. The Prometheus configuration is set to scrape targets every
    30 seconds. The timecheck app has a `/metrics` endpoint, which returns a count
    for how many timecheck logs it has written. When I queried that metric in Prometheus,
    the app had written 22 log entries.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我的输出如图 14.3 所示，我在其中打开了两个浏览器窗口，以便你可以看到应用程序部署时发生了什么。Prometheus 看到了 timecheck Pod
    的创建，并且它在重命名阶段匹配了所有规则，因此它被添加为目标。Prometheus 配置设置为每 30 秒抓取一次目标。timecheck 应用程序有一个
    `/metrics` 端点，它返回已写入的时间检查日志的数量。当我查询 Prometheus 中的该指标时，应用程序已写入 22 条日志条目。
- en: '![](../Images/14-3.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/14-3.jpg)'
- en: Figure 14.3 Deploying an app to the test namespace-Prometheus finds it and starts
    collecting metrics.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.3 将应用程序部署到测试命名空间-Prometheus 发现它并开始收集指标。
- en: 'You should realize two important things here: the application itself needs
    to provide the metrics because Prometheus is just a collector, and those metrics
    represent the activity for one instance of the application. The timecheck app
    isn’t a web application—it’s just a background process—so there’s no Service directing
    traffic to it. Prometheus gets the Pod IP address when it queries the Kubernetes
    API, and it makes the HTTP request directly to the Pod. You can configure Prometheus
    to query Services, too, but then you’d get a target that is a load balancer across
    multiple Pods, and you want Prometheus to scrape each Pod independently.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你应该意识到两个重要的事情：应用程序本身需要提供指标，因为 Prometheus 只是一个收集器，并且这些指标代表应用程序一个实例的活动。timecheck
    应用程序不是一个 Web 应用程序——它只是一个后台进程——因此没有 Service 将流量导向它。当 Prometheus 查询 Kubernetes API
    时，它会获取 Pod IP 地址，并直接向 Pod 发送 HTTP 请求。你也可以配置 Prometheus 查询 Service，但那样你会得到一个跨越多个
    Pod 的负载均衡器目标，而你希望 Prometheus 独立抓取每个 Pod。
- en: You’ll use the metrics in Prometheus to power dashboards showing the overall
    health of your apps, and you may aggregate across all the Pods to get the headline
    values. You need to be able to drill down, too, to see if there are differences
    between the Pods. That will help you identify if some instances are performing
    badly, and that will feed back into your health checks. We can scale up the timecheck
    app to see the importance of collecting at the individual Pod level.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用 Prometheus 中的指标来驱动显示应用程序整体健康状况的仪表板，并且你可以跨所有 Pod 进行聚合以获取关键值。你还需要能够深入挖掘，以查看
    Pod 之间是否存在差异。这将帮助你识别某些实例是否表现不佳，并将这些信息反馈到你的健康检查中。我们可以将 timecheck 应用程序扩展以查看在单个 Pod
    级别收集的重要性。
- en: Try it now Add another replica to the timecheck app. It’s a new Pod that matches
    the Prometheus rules, so it will be discovered and added as another scrape target.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：向 timecheck 应用程序添加另一个副本。这是一个新的 Pod，它符合 Prometheus 规则，因此它将被发现并作为另一个抓取目标添加。
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You’ll see in this exercise that Prometheus finds the new Pod and starts scraping
    it. Both Pods record the same metrics, and the Pod name is set as a label on each
    metric. The query for the `timecheck_total` metric now returns two results—one
    for each Pod—and you can see in figure 14.4 that one Pod has done a lot more work
    than the other.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你会看到 Prometheus 找到了新的 Pod 并开始抓取它。两个 Pod 记录了相同的指标，并且 Pod 名称被设置为每个指标的标签。对
    `timecheck_total` 指标的查询现在返回两个结果——每个 Pod 一个——你可以在图 14.4 中看到其中一个 Pod 做了比另一个 Pod
    多得多的工作。
- en: '![](../Images/14-4.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/14-4.jpg)'
- en: Figure 14.4 Every instance records its own metrics so you need to collect from
    every Pod.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.4 每个实例都会记录自己的指标，因此你需要从每个 Pod 收集。
- en: The timecheck counter is a metric that is explicitly captured in the application
    code. Most languages have a Prometheus client library, which you can plug into
    your build. The libraries let you capture application-specific details like this,
    and they also collect generic information about the application run time. This
    is a .NET application, and the Prometheus client library records run-time details,
    like the amount of memory and CPU in use and the number of threads running. In
    the next section, we’ll run a distributed application where every component exposes
    Prometheus metrics, and we’ll see how useful an application dashboard is when
    it includes run-time performance as well as application details.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: timecheck 计数器是一个在应用程序代码中明确捕获的指标。大多数语言都有 Prometheus 客户端库，您可以将它集成到您的构建中。这些库允许您捕获特定于应用程序的详细信息，例如这些，并且它们还收集关于应用程序运行时的一般信息。这是一个
    .NET 应用程序，Prometheus 客户端库记录运行时细节，如使用的内存和 CPU 数量以及正在运行的线程数。在下一节中，我们将运行一个分布式应用程序，其中每个组件都暴露
    Prometheus 指标，我们将看到当应用程序仪表板包括运行时性能以及应用程序细节时是多么有用。
- en: 14.2 Monitoring apps built with Prometheus client libraries
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.2 使用 Prometheus 客户端库构建的应用监控
- en: Appendix B in the ebook walks through adding metrics to an app that shows a
    picture from NASA’s Astronomy Photo of the Day (APOD) service. The components
    of that app are in Java, Go, and Node.js, and they each use a Prometheus client
    library to expose run-time and application metrics. This chapter includes Kubernetes
    manifests for the app that deploy to the test namespace, so all the application
    Pods will be discovered by Prometheus.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 电子书附录 B 介绍了如何向一个展示 NASA 天文每日照片（APOD）服务图片的应用添加指标。该应用的组件使用 Java、Go 和 Node.js 编写，并且每个组件都使用
    Prometheus 客户端库来暴露运行时和应用指标。本章包括将应用部署到测试命名空间的 Kubernetes 清单，因此所有应用 Pod 都将被 Prometheus
    发现。
- en: Try it now Deploy the APOD app to the test namespace, and confirm that the three
    components of the app are added as Prometheus targets.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看：将 APOD 应用部署到测试命名空间，并确认应用的三部分组件已添加为 Prometheus 目标。
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can see my output in figure 14.5, with a very pleasant image of something
    called Lynds Dark Nebula 1251\. The application is working as expected, and Prometheus
    has discovered all of the new Pods. Within 30 seconds of deploying the app, you
    should see that the state of all of the new targets is up, which means Prometheus
    has successfully scraped them.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在图 14.5 中看到我的输出，其中展示了一幅名为 Lynds Dark Nebula 1251 的非常令人愉悦的图像。应用按预期工作，Prometheus
    已经发现了所有新的 Pod。在部署应用后的 30 秒内，您应该看到所有新目标的状态都是“up”，这意味着 Prometheus 已经成功抓取了它们。
- en: '![](../Images/14-5.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/14-5.jpg)'
- en: Figure 14.5 The APOD components all have Services, but they are still scraped
    at the Pod level.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.5 APOD 组件都有服务，但它们仍然在 Pod 级别被抓取。
- en: I have two additional important things to point out in this exercise. First,
    the Pod specs all include a container port, which states that the application
    container is listening on port 80, and that’s how Prometheus finds the target
    to scrape. The Service for the web UI actually listens on port 8014, but Prometheus
    goes directly to the Pod port. Second, the API target isn’t using the standard
    `/metrics` path, because the Java client library uses a different path. I’ve used
    an annotation in the Pod spec to state the correct path.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我有两个额外的重要事项要指出。首先，Pod 规范都包含一个容器端口，这表示应用程序容器正在监听端口 80，这也是 Prometheus 找到要抓取的目标的方式。实际上，用于
    Web UI 的服务是在端口 8014 上监听的，但 Prometheus 直接连接到 Pod 端口。其次，API 目标没有使用标准的 `/metrics`
    路径，因为 Java 客户端库使用不同的路径。我在 Pod 规范中使用了注解来指明正确的路径。
- en: Convention-based discovery is great because it removes a lot of repetitive configuration
    and the potential for mistakes, but not every app will fit with the conventions.
    The relabeling pipeline we’re using in Prometheus gives us a nice balance. The
    default values will work for any apps that meet the convention, but any that don’t
    can override the defaults with annotations. Listing 14.2 shows how the override
    is configured to set the path to the metrics.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基于约定的发现方式非常棒，因为它减少了大量重复配置和错误的可能性，但并非每个应用都符合这些约定。我们在 Prometheus 中使用的重命名管道提供了一个很好的平衡。默认值适用于符合约定的任何应用，但不符合约定的应用可以通过注解覆盖默认值。列表
    14.2 展示了如何配置覆盖以设置指标路径。
- en: Listing 14.2 prometheus-config.yaml, using annotations to override default values
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.2 prometheus-config.yaml，使用注解覆盖默认值
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This is way less complicated than it looks. The rule says: if the Pod has an
    annotation called `promet``heus.io/path`, then use the value of that annotation
    as the metrics path. Prometheus does it all with labels, so every Pod annotation
    becomes a label with the name `meta_kubernetes_pod_annotation_<annotation-name>`,
    and there’s an accompanying label called `meta_kubernetes_pod_annotationpresent_<annotation-name>`,
    which you can use to check if the annotation exists. Any apps that use a custom
    metrics path need to add the annotation. Listing 14.3 shows that for the APOD
    API.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这比看起来要简单得多。规则说明：如果 Pod 有一个名为 `prometheus.io/path` 的注解，则使用该注解的值作为指标路径。Prometheus
    使用标签完成所有操作，因此每个 Pod 注解都成为名为 `meta_kubernetes_pod_annotation_<annotation-name>`
    的标签，还有一个伴随的标签名为 `meta_kubernetes_pod_annotationpresent_<annotation-name>`，你可以用它来检查注解是否存在。任何使用自定义指标路径的应用程序都需要添加注解。列表
    14.3 显示了 APOD API 的示例。
- en: Listing 14.3 api.yaml, the path annotation in the API spec
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.3 api.yaml，API 规范中的路径注解
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The complexity is centralized in the Prometheus configuration, and it’s really
    easy for application manifests to specify overrides. The relabeling rules aren’t
    so complex when you work with them a little more, and you’re usually following
    exactly the same pattern. The full Prometheus configuration includes similar rules
    for apps to override the metrics port and to opt out of scraping altogether.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂性集中在 Prometheus 配置中，并且为应用清单指定覆盖项非常简单。当你稍微熟悉一些后，重命名规则并不复杂，你通常遵循的是完全相同的模式。完整的
    Prometheus 配置包括类似规则，用于应用覆盖指标端口和完全退出抓取。
- en: While you’ve been reading this, Prometheus has been busily scraping the timecheck
    and APOD apps. Take a look at the metrics on the Graph page of the Prometheus
    UI to see around 200 metrics being collected. The UI is great for running queries
    and quickly seeing the results, but you can’t use it to build a dashboard showing
    all the key metrics for your app in a single screen. For that you can use Grafana,
    another open source project in the container ecosystem, which comes recommended
    by the Prometheus team.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在阅读这段内容时，Prometheus 一直在忙于抓取 timecheck 和 APOD 应用程序。查看 Prometheus UI 的“图形”页面，可以看到大约
    200 个指标正在收集。UI 非常适合运行查询并快速查看结果，但你不能用它来构建一个在单个屏幕上显示应用程序所有关键指标的仪表板。为此，你可以使用 Grafana，这是容器生态系统中另一个开源项目，由
    Prometheus 团队推荐。
- en: Try it now Deploy Grafana with ConfigMaps that set up the connection to Prometheus,
    and include a dashboard for the APOD app.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看：部署 Grafana，使用 ConfigMaps 设置与 Prometheus 的连接，并包含 APOD 应用程序的仪表板。
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The dashboard shown in figure 14.6 is tiny, but it gives you an idea of how
    you can transform raw metrics into an informative view of system activity. Each
    visualization in the dashboard is powered by a Prometheus query, which Grafana
    runs in the background. There’s a row for each component, and that includes a
    mixture of run-time metrics—processor and memory usage—and application metrics—HTTP
    requests and cache usage.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.6 中显示的仪表板虽小，但它能让你了解如何将原始指标转换为系统活动的信息视图。仪表板中的每个可视化都是由 Prometheus 查询驱动的，Grafana
    在后台运行。每个组件都有一个行，这包括运行时指标——处理器和内存使用情况——以及应用程序指标——HTTP 请求和缓存使用情况。
- en: '![](../Images/14-6.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/14-6.jpg)'
- en: Figure 14.6 Application dashboards give a quick insight into performance. The
    graphs are all powered from Prometheus metrics.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.6 应用程序仪表板可以快速了解性能。所有图表都是由 Prometheus 指标驱动的。
- en: Dashboards like this will be a joint effort that cuts across the organization.
    The support team will set the requirements for what they need to see, and the
    application development and operations teams ensure the app captures the data
    and the dashboard shows it. Just like the logging system we looked at in chapter
    13, this is a solution built from lightweight open source components, so developers
    can run the same monitoring system on their laptops that runs in production. That
    helps with performance testing and debugging in development and test.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的仪表板将是跨组织的共同努力。支持团队将设定他们需要查看的要求，应用开发和运维团队确保应用程序捕获数据，仪表板显示数据。就像我们在第 13 章中查看的日志系统一样，这是一个由轻量级开源组件构建的解决方案，因此开发者可以在他们的笔记本电脑上运行与生产环境中相同的监控系统。这有助于开发中的性能测试和调试。
- en: Moving to centralized monitoring with Prometheus will require development effort,
    but it can be an incremental process where you start with basic metrics and add
    to them as teams start to come up with more requirements. I’ve added Prometheus
    support to the to-do list app for this chapter, and it took about a dozen lines
    of code. There’s a simple dashboard for the app ready to use in Grafana, so when
    you deploy the app, you’ll be able to see the starting point for a dashboard that
    will improve with future releases.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 转向使用 Prometheus 的集中式监控将需要开发工作，但可以是一个逐步的过程，从基本的指标开始，随着团队提出更多要求，逐渐添加。我为本章的待办事项列表应用添加了
    Prometheus 支持，大约需要 dozen 行代码。Grafana 中已经有一个简单的仪表板可以立即使用，所以当你部署应用时，你将能够看到仪表板的起点，该仪表板将随着未来的版本更新而改进。
- en: Try it now Run the to-do list app with metrics enabled, and use the app to produce
    some metrics. There’s already a dashboard in Grafana to visualize the metrics.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 运行带有指标启用的待办事项应用，并使用该应用生成一些指标。Grafana 中已经有一个仪表板可以用来可视化这些指标。
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: There’s not much in that dashboard, but it’s a lot more information than no
    dashboard at all. It tells you how much CPU and memory the app is using inside
    the container, the rate at which tasks are being created, and the average response
    time for HTTP requests. You can see my output in figure 14.7 where I’ve added
    some tasks and sent some traffic in with the load generation script.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在那个仪表板上没有太多内容，但比完全没有仪表板要提供的信息多得多。它告诉你应用在容器内使用的 CPU 和内存量，任务创建的速率，以及 HTTP 请求的平均响应时间。你可以在图
    14.7 中看到我的输出，我在那里添加了一些任务，并使用负载生成脚本来发送了一些流量。
- en: '![](../Images/14-7.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/14-7.jpg)'
- en: Figure 14.7 A simple dashboard powered by the Prometheus client library and
    a few lines of code
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.7 由 Prometheus 客户端库和几行代码驱动的简单仪表板
- en: 'All of those metrics are coming from the to-do application Pod. There are two
    other components to the app in this release: a Postgres database for storage and
    an Nginx proxy. Neither of those components has native support for Prometheus,
    so they’re excluded from the target list. Otherwise, Prometheus would keep trying
    to scrape metrics and failing. It’s the job of whoever models the application
    to know that a component doesn’t expose metrics and to specify that it should
    be excluded. Listing 14.4 shows that done with a simple annotation.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些指标都来自待办事项应用的 Pod。在这个版本的应用中还有另外两个组件：用于存储的 Postgres 数据库和 Nginx 代理。这些组件都没有对
    Prometheus 的原生支持，因此它们被排除在目标列表之外。否则，Prometheus 会不断尝试抓取指标并失败。知道某个组件不暴露指标并指定应该排除它的责任在于建模应用的人。列表
    14.4 显示了如何通过简单的注解来完成这项工作。
- en: Listing 14.4 proxy.yaml, a Pod spec that excludes itself from monitoring
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.4 proxy.yaml，一个排除自身监控的 Pod 规范
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Components don’t need to have native support for Prometheus and provide their
    own metrics endpoint to be included in your monitoring system. Prometheus has
    its own ecosystem—in addition to client libraries that you can use to add metrics
    to your own applications, a whole set of exporters can extract and publish metrics
    for third-party applications. We can use exporters to add the missing metrics
    for the proxy and database components.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 组件不需要有 Prometheus 的原生支持并提供自己的指标端点，以便包含在你的监控系统中。Prometheus 有自己的生态系统——除了你可以用来向自己的应用程序添加指标的客户端库之外，还有一套导出器可以提取和发布第三方应用的指标。我们可以使用导出器来添加代理和数据库组件缺失的指标。
- en: 14.3 Monitoring third-party apps with metrics exporters
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.3 使用指标导出器监控第三方应用
- en: Most applications record metrics in some way, but older apps won’t collect and
    expose them in Prometheus format. Exporters are separate applications that understand
    how the target app does its monitoring and can convert those metrics to Prometheus
    format. Kubernetes provides the perfect way to run an exporter alongside every
    instance of an application using a sidecar container. This is the adapter pattern
    we covered in chapter 7.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数应用都以某种方式记录指标，但旧应用不会以 Prometheus 格式收集和暴露它们。导出器是独立的应用程序，了解目标应用如何进行监控，并能将这些指标转换为
    Prometheus 格式。Kubernetes 提供了一种完美的方式，通过在每个应用实例旁边运行一个边车容器来运行导出器。这是我们第 7 章中提到的适配器模式。
- en: Nginx and Postgres both have exporters available that we can run as sidecars
    to improve the monitoring dashboard for the to-do app. The Nginx exporter reads
    from a status page on the Nginx server and converts the data to Prometheus format.
    Remember that all the containers in a Pod share the network namespace, so the
    exporter container can access the Nginx container at the localhost address. The
    exporter provides its own HTTP endpoint for metrics on a custom port, so the full
    Pod spec includes the sidecar container and an annotation to specify the metrics
    port. Listing 14.5 shows the key parts.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx 和 Postgres 都有可用的导出器，我们可以将其作为边车运行以改进待办事项应用程序的监控仪表板。Nginx 导出器从 Nginx 服务器上的状态页面读取数据并将其转换为
    Prometheus 格式。请记住，Pod 中的所有容器都共享网络命名空间，因此导出器容器可以访问 localhost 地址上的 Nginx 容器。导出器在其自定义端口上提供了一个自己的
    HTTP 端点用于指标，因此完整的 Pod 规范包括边车容器和一个注释来指定指标端口。列表 14.5 显示了关键部分。
- en: Listing 14.5 proxy-with-exporter.yaml, adding a metrics exporter container
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.5 proxy-with-exporter.yaml，添加指标导出器容器
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The scrape exclusion has been removed, so when you deploy this update, Prometheus
    will scrape the Nginx Pod on port 9113, where the exporter is listening. All the
    Nginx metrics will be stored by Prometheus, and the Grafana dashboard can be updated
    to add a row for the proxy. We’re not going to get into the Prometheus query language
    (PromQL) or building Grafana dashboards in this chapter—dashboards can be imported
    from JSON files, and there’s an updated dashboard ready to be deployed.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 刮擦排除已移除，因此当您部署此更新时，Prometheus 将在端口 9113 上抓取 Nginx Pod，那里有导出器正在监听。所有 Nginx 指标都将由
    Prometheus 存储，并且 Grafana 仪表板可以更新以添加一行用于代理。我们不会在本章中详细介绍 Prometheus 查询语言（PromQL）或构建
    Grafana 仪表板——仪表板可以从 JSON 文件中导入，并且有一个准备就绪的仪表板可供部署。
- en: Try it now Update the proxy Deployment to add the exporter sidecar, and load
    an updated dashboard into the Grafana ConfigMap.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 更新代理部署以添加导出器边车，并将更新的仪表板加载到 Grafana ConfigMap 中。
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The Nginx exporter doesn’t provide a huge amount of information, but the basic
    details are there. You can see in figure 14.8 that we get the number of HTTP requests
    and a lower-level breakdown of how Nginx handles connection requests. Even with
    this simple dashboard, you can see a correlation between the traffic Nginx is
    handling and the traffic the web app is handling, which suggests the proxy isn’t
    caching responses and is calling the web app for every request.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx 导出器不提供大量信息，但基本细节都在那里。您可以在图 14.8 中看到我们获取了 HTTP 请求的数量以及 Nginx 处理连接请求的更低级别的分解。即使在这个简单的仪表板中，您也可以看到
    Nginx 处理的流量与 Web 应用处理的流量之间的相关性，这表明代理没有缓存响应，并且对每个请求都调用 Web 应用。
- en: '![](../Images/14-8.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/14-8.jpg)'
- en: Figure 14.8 Collecting proxy metrics with an exporter adds another level of
    detail to the dashboard.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.8 使用导出器收集代理指标为仪表板增加了另一个细节级别。
- en: It would be nice to get a bit more information from Nginx—like the breakdown
    of HTTP status codes in the response—but exporters can relay only the information
    available from the source system, which isn’t much for Nginx. Other exporters
    provide far more detail, but you need to focus your dashboard so it shows key
    indicators. More than a dozen or so visualizations and the dashboard becomes overwhelming,
    and, if it doesn’t convey useful information at a glance, then it’s not doing
    a very good job.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Nginx 获取更多信息的想法很好——比如响应中 HTTP 状态码的分解——但导出器只能传递来自源系统的信息，对于 Nginx 来说这并不多。其他导出器提供了更多的细节，但您需要集中仪表板以显示关键指标。超过十几项可视化后，仪表板会变得令人不知所措，而且如果它不能一眼看出有用的信息，那么它的工作效果就不太好了。
- en: 'There’s one more component to add to the to-do list dashboard: the Postgres
    database. Postgres stores all sorts of useful information in tables and functions
    inside the database, and the exporter runs queries to power its metrics endpoint.
    The setup for the Postgres exporter follows the same pattern we’ve seen in Nginx.
    In this case, the sidecar is configured to access Postgres on localhost, using
    the same Kubernetes Secret that the Postgres container uses for the admin password.
    We’ll make a final update to the application dashboard to show the key database
    metrics from the exporter.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 需要添加到待办事项仪表板的一个更多组件是：Postgres 数据库。Postgres 在数据库内部存储各种有用的信息，包括表和函数，导出器运行查询以提供其指标端点。Postgres
    导出器的设置与我们在 Nginx 中看到的模式相同。在这种情况下，边车配置为通过 localhost 访问 Postgres，使用与 Postgres 容器用于管理员密码相同的
    Kubernetes Secret。我们将对应用程序仪表板进行最终更新，以显示导出器中的关键数据库指标。
- en: Try it now Update the database Deployment spec, adding the Postgres exporter
    as a sidecar container. Then update the to-do list dashboard with a new row to
    show database performance.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 更新数据库部署规范，添加Postgres导出器作为侧车容器。然后更新待办事项列表仪表板，添加一行以显示数据库性能。
- en: '[PRE12]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: I’ve zoomed out and scrolled down in figure 14.9 so you can see the new visualizations,
    but the whole dashboard is a joy to behold in full-screen mode. A single page
    shows you how much traffic is coming to the proxy, how hard the app is working
    and what users are actually doing, and what’s happening inside the database. You
    can get the same level of detail in your own apps with client libraries and exporters,
    and you’re looking at just a few days’ effort.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我在图14.9中放大并向下滚动，以便您可以看到新的可视化，但整个仪表板在全屏模式下观看非常愉快。单页显示有多少流量进入代理，应用程序工作有多努力，用户实际上在做什么，以及数据库内部发生了什么。您可以通过客户端库和导出器在您自己的应用程序中获得相同级别的详细程度，而这只需要几天的工作。
- en: '![](../Images/14-9.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图14-9](../Images/14-9.jpg)'
- en: Figure 14.9 The database exporter records metrics about data activity, which
    add detail to the dashboard.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.9 数据库导出器记录有关数据活动的指标，这些指标为仪表板增添了细节。
- en: Exporters are there to add metrics to apps that don’t have Prometheus support.
    If your goal is to move a set of existing applications onto Kubernetes, then you
    may not have the luxury of a development team to add custom metrics. For those
    apps, you can use the Prometheus blackbox exporter, taking to the extreme the
    approach that some monitoring is better than none.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 导出器用于向没有Prometheus支持的应用程序添加指标。如果您的目标是将一组现有应用程序迁移到Kubernetes，那么您可能没有开发团队添加自定义指标的奢侈。对于这些应用程序，您可以使用Prometheus黑盒导出器，将某些监控优于无监控的方法推向极致。
- en: The blackbox exporter can run in a sidecar and make TCP or HTTP requests to
    your application container as well as provide a basic metrics endpoint to say
    whether the application is up. This approach is similar to adding container probes
    to your Pod spec, except that the blackbox exporter is for information only. You
    can run a dashboard to show the status of an app if it isn’t a good fit for Kubernetes’s
    self-healing mechanisms, like the random-number API we’ve used in this book.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 黑盒导出器可以在侧车容器中运行，并向您的应用程序容器发送TCP或HTTP请求，同时提供一个基本的指标端点来表示应用程序是否正在运行。这种方法类似于在Pod规范中添加容器探针，但黑盒导出器仅用于信息目的。如果您觉得Kubernetes的自愈机制，如本书中使用的随机数API，不适合应用程序，您可以通过运行仪表板来显示应用程序的状态。
- en: Try it now Deploy the random-number API with a blackbox exporter and the simplest
    possible Grafana dashboard. You can break the API by using it repeatedly and then
    reset it so it works again, and the dashboard tracks the status.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 部署随机数API，使用黑盒导出器和最简单的Grafana仪表板。您可以通过重复使用API来破坏它，然后重置它使其再次工作，仪表板会跟踪状态。
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The random-number API doesn’t have Prometheus support, but running the blackbox
    exporter as a sidecar container gives basic insight into the application status.
    Figure 14.10 shows a dashboard that is mostly empty, but the two visualizations
    show whether the app is healthy and the historical trend of the status as the
    app flips between unhealthy and being reset.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 随机数API没有Prometheus支持，但将黑盒导出器作为侧车容器运行可以提供对应用程序状态的基本洞察。图14.10显示了一个大部分为空的仪表板，但两个可视化显示了应用程序在健康和不健康状态之间切换时的历史趋势。
- en: '![](../Images/14-10.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图14-10](../Images/14-10.jpg)'
- en: Figure 14.10 Even a simple dashboard is useful. This shows the current and historical
    status of the API.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.10 即使是一个简单的仪表板也是有用的。这显示了API的当前和历史状态。
- en: 'The Pod spec for the random-number API follows a similar pattern to Nginx and
    Postgres in the to-do app: the blackbox exporter is configured as an additional
    container and specifies the port where metrics are exposed. The Pod annotations
    customize the path to the metrics URL, so when Prometheus scrapes metrics from
    the sidecar, it calls the blackbox exporter, which checks that the API is responding
    to HTTP requests.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 随机数API的Pod规范与待办事项应用程序中的Nginx和Postgres类似：黑盒导出器配置为附加容器，并指定了指标暴露的端口。Pod注解自定义了指标URL的路径，因此当Prometheus从侧车抓取指标时，它会调用黑盒导出器，该导出器会检查API是否对HTTP请求做出响应。
- en: 'Now we have dashboards for three different apps that have different levels
    of detail, because the application components aren’t consistent with the data
    they collect. But all the components have something in common: they’re all running
    in containers on Kubernetes. In the next section, you’ll learn how to get the
    next level of detail by configuring Prometheus to collect platform metrics from
    the cluster itself.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有三个不同应用的仪表板，它们的详细程度不同，因为应用程序组件与它们收集的数据不一致。但所有组件都有一个共同点：它们都在 Kubernetes 上的容器中运行。在下一节中，您将学习如何通过配置
    Prometheus 从集群本身收集平台指标来获取更详细的级别。
- en: 14.4 Monitoring containers and Kubernetes objects
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.4 监控容器和 Kubernetes 对象
- en: 'Prometheus integrates with Kubernetes for service discovery, but it doesn’t
    collect any metrics from the API. You can get metrics about Kubernetes objects
    and container activity from two additional components: *cAdvisor*, a Google open
    source project, and *kube-state-metrics*, which is part of the wider Kubernetes
    organization on GitHub. Both run as containers in the cluster, but they collect
    data from different sources. cAdvisor collects metrics from the container runtime,
    so it runs as a DaemonSet with a Pod on each node to report on that node’s containers.
    kube-state-metrics queries the Kubernetes API so it can run as a Deployment with
    a single replica on any node.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 与 Kubernetes 集成以进行服务发现，但它不会从 API 收集任何指标。您可以从两个额外的组件中获取有关 Kubernetes
    对象和容器活动的指标：*cAdvisor*，一个谷歌开源项目，以及*kube-state-metrics*，它是 GitHub 上更广泛的 Kubernetes
    组织的一部分。这两个组件都在集群中以容器的形式运行，但它们从不同的来源收集数据。cAdvisor 从容器运行时收集指标，因此它作为每个节点的 Pod 上的
    DaemonSet 运行以报告该节点的容器。kube-state-metrics 查询 Kubernetes API，因此它可以在任何节点上作为具有单个副本的
    Deployment 运行。
- en: Try it now Deploy the metric collectors for cAdvisor and kube-state-metrics,
    and update the Prometheus configuration to include them as scrape targets.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：部署 cAdvisor 和 kube-state-metrics 的指标收集器，并更新 Prometheus 配置以将它们包括为抓取目标。
- en: '[PRE14]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In this exercise, you’ll see that Prometheus is collecting thousands of new
    metrics. The raw data includes the compute resources used by every container and
    the status of every Pod. My output is shown in figure 14.11\. When you run this
    exercise, you can check the Targets page in the Prometheus UI to confirm that
    the new targets are being scraped. Prometheus doesn’t automatically reload configuration,
    so in the exercise, there’s a delay to give Kubernetes time to propagate the ConfigMap
    update, and the `curl` command forces a configuration reload in Prometheus.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您将看到 Prometheus 正在收集数千个新的指标。原始数据包括每个容器使用的计算资源以及每个 Pod 的状态。我的输出显示在图 14.11
    中。当您运行此练习时，您可以在 Prometheus UI 中的“目标”页面检查以确认新的目标是正在被抓取的。Prometheus 不会自动重新加载配置，因此在此练习中，有一个延迟以给
    Kubernetes 时间传播 ConfigMap 更新，而 `curl` 命令强制 Prometheus 重新加载配置。
- en: '![](../Images/14-11.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/14-11.jpg)'
- en: Figure 14.11 New metrics show activity at the cluster and container levels.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.11 新指标显示集群和容器级别的活动。
- en: The updated Prometheus configuration you just deployed includes two new job
    definitions, shown in listing 14.6\. kube-state-metrics is specified as a static
    target using the full DNS name of the Service. A single Pod collects all of the
    metrics so there’s no load-balancing issue here. cAdvisor uses Kubernetes service
    discovery to find every Pod in the DaemonSet, which would present one target for
    each node in a multinode cluster.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 您刚刚部署的更新后的 Prometheus 配置包括两个新的作业定义，如列表 14.6 所示。kube-state-metrics 使用服务的完整 DNS
    名称指定为静态目标。单个 Pod 收集所有指标，因此这里没有负载均衡问题。cAdvisor 使用 Kubernetes 服务发现来找到每个 DaemonSet
    中的每个 Pod，在多节点集群中每个节点将提供一个目标。
- en: Listing 14.6 prometheus-config-kube.yaml, new scrape targets in Prometheus
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 14.6 prometheus-config-kube.yaml，Prometheus 中的新抓取目标
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now we have the opposite problem from the random-number dashboard: there’s
    far too much information in the new metrics, so the platform dashboard will need
    to be highly selective if it’s going to be useful. I have a sample dashboard prepared
    that is a good starter. It includes current resource usage and all available resource
    quantities for the cluster, together with some high-level breakdowns by namespace
    and warning indicators for the health of the nodes.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们面临与随机数仪表板相反的问题：新的指标中信息量过多，因此如果平台仪表板要发挥作用，它需要非常具有选择性。我已经准备了一个示例仪表板，这是一个很好的起点。它包括集群当前资源使用情况和所有可用的资源数量，以及按命名空间进行的一些高级分解和节点健康警告指标。
- en: Try it now Deploy a dashboard for key cluster metrics and with an update to
    Grafana so it loads the new dashboard.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 部署一个关键集群指标的仪表板，并更新 Grafana 以加载新的仪表板。
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This is another dashboard that is meant for the big screen, so the screenshot
    in figure 14.12 doesn’t do it justice. When you run the exercise, you can examine
    it more closely. The top row shows memory usage, the middle row displays CPU usage,
    and the bottom row shows the status of Pod containers.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这又是一个旨在大屏幕上的仪表板，所以图 14.12 中的截图并不能公正地展示它。当您运行练习时，您可以更仔细地检查它。最上面一行显示内存使用情况，中间一行显示
    CPU 使用情况，最下面一行显示 Pod 容器的状态。
- en: '![](../Images/14-12.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.12](../Images/14-12.jpg)'
- en: Figure 14.12 Another tiny screenshot—run the exercise in your own cluster to
    see it full size.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.12 另一个小截图——在自己的集群中运行练习以查看全尺寸。
- en: A platform dashboard like this is pretty low level—it’s really just showing
    you if your cluster is near its saturation point. The queries that power this
    dashboard will be more useful as alerts, warning you if resource usage is getting
    out of hand. Kubernetes has pressure indicators that are useful there. The memory
    pressure and process pressure values are shown in the dashboard, as well as a
    disk pressure indicator. Those values are significant because if a node comes
    under compute pressure, it can terminate Pod containers. Those would be good metrics
    to alert on because if you reach that stage, you probably need to page someone
    to come and nurse the cluster back to health.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的平台仪表板相当底层——它实际上只是显示您的集群是否接近饱和点。驱动这个仪表板的查询将作为警报更有用，警告您资源使用是否失控。Kubernetes
    有一些有用的压力指标。仪表板中显示了内存压力和进程压力值，以及磁盘压力指示器。这些值很重要，因为如果一个节点承受计算压力，它可能会终止 Pod 容器。这些将是很好的警报指标，因为如果您达到那个阶段，您可能需要叫人来帮助集群恢复健康。
- en: 'Platform metrics have another use: adding detail to application dashboards
    where the app itself doesn’t provide detailed enough metrics. The platform dashboard
    shows compute resource usage aggregated across the whole cluster, but cAdvisor
    collects it at the container level. It’s the same with kube-state-metrics, where
    you can filter metrics for a specific workload to add platform information to
    the application dashboard. We’ll make a final dashboard update in this chapter,
    adding details from the platform to the random-number app.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 平台指标还有另一个用途：为应用程序仪表板添加细节，其中应用程序本身没有提供足够详细的指标。平台仪表板显示了整个集群的计算资源使用情况汇总，但 cAdvisor
    在容器级别收集它。kube-state-metrics 也是如此，您可以为特定的工作负载过滤指标，将平台信息添加到应用程序仪表板中。我们将在本章中做一个最终的仪表板更新，将平台细节添加到随机数应用程序中。
- en: Try it now Update the dashboard for the random-number API to add metrics from
    the platform. This is just a Grafana update; there are no changes to the app itself
    or to Prometheus.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 更新随机数 API 的仪表板以添加平台指标。这只是一个 Grafana 更新；应用程序本身或 Prometheus 没有发生变化。
- en: '[PRE17]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As shown in figure 14.13, the dashboard is still basic, but at least we now
    have some detail that could help correlate any issues. If the HTTP status code
    shows as 503, we can quickly see if the CPU is spiking, too. If the Pod labels
    contain an application version (which they should), we could identify which release
    of the app was experiencing the problem.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 14.13 所示，仪表板仍然是基本的，但至少我们现在有一些细节可以帮助关联任何问题。如果 HTTP 状态码显示为 503，我们可以快速查看 CPU
    是否也在激增。如果 Pod 标签包含应用程序版本（它们应该包含），我们可以确定哪个应用程序版本遇到了问题。
- en: '![](../Images/14-13.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图 14.13](../Images/14-13.jpg)'
- en: Figure 14.13 Augmenting basic health stats with container and Pod metrics adds
    correlation.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.13 通过容器和 Pod 指标增强基本健康状态增加了相关性。
- en: There’s a lot more to monitoring that I won’t cover here, but now you have a
    solid grounding in how Kubernetes and Prometheus work together. The main pieces
    you’re missing are collecting metrics at the server level and configuring alerts.
    Server metrics supply data like disk and network usage. You collect them by running
    exporters directly on the nodes (using the Node Exporter for Linux servers and
    the Windows Exporter for Windows servers), and you use service discovery to add
    the nodes as scrape targets. Prometheus has a sophisticated alerting system that
    uses PromQL queries to define alerting rules. You configure alerts so that when
    rules are triggered, Prometheus will send emails, create Slack messages, or send
    a notification through PagerDuty.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 监控还有很多内容我没有在这里涵盖，但现在你已经对Kubernetes和Prometheus如何协同工作有了坚实的基础。你所缺少的主要是服务器级别的指标收集和配置警报。服务器指标提供如磁盘和网络使用等数据。你通过在节点上直接运行导出器来收集它们（使用Linux服务器的Node
    Exporter和Windows服务器的Windows Exporter），并使用服务发现来将节点添加为抓取目标。Prometheus有一个复杂的警报系统，它使用PromQL查询来定义警报规则。你配置警报，以便当规则被触发时，Prometheus会发送电子邮件、创建Slack消息或通过PagerDuty发送通知。
- en: We’ll wrap up the chapter by looking at the full architecture of Prometheus
    in Kubernetes and digging into which pieces need custom work and where the effort
    needs to go.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过查看Prometheus在Kubernetes中的完整架构，并深入研究哪些部分需要定制工作以及努力的方向来结束本章。
- en: 14.5 Understanding the investment you make in monitoring
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.5 理解你在监控上的投资
- en: When you step outside of core Kubernetes and into the ecosystem, you need to
    understand whether the project you take a dependency on will still exist in five
    years, or one year, or by the time the chapter you’re writing makes it to the
    printing press. I’ve been careful in this book to include only those ecosystem
    components that are open source, are heavily used, and have an established history
    and governance model. The monitoring architecture in figure 14.14 uses components
    that all meet those criteria.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 当你走出核心Kubernetes并进入生态系统时，你需要了解你所依赖的项目在五年后、一年后，或者在你所写的章节被印刷出来之前是否仍然存在。我在这本书中非常小心地只包括那些开源、使用广泛、有既定历史和治理模式的生态系统组件。图14.14中的监控架构使用的组件都符合这些标准。
- en: '![](../Images/14-14.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图14-14](../Images/14-14.jpg)'
- en: Figure 14.14 Monitoring doesn’t come for free—it needs development and dependencies
    on open source projects.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.14 监控并非免费提供——它需要开发和依赖开源项目。
- en: I make that point because the move to Prometheus will involve development work.
    You need to record interesting metrics for your applications to make your dashboards
    truly useful. You should feel confident about making that investment because Prometheus
    is the most popular tool for monitoring containerized applications, and the project
    was the second to graduate in the CNCF—after Kubernetes itself. There’s also work
    underway to take the Prometheus metric format into an open standard (called OpenMetrics),
    so other tools will be able to read application metrics exposed in the Prometheus
    format.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我提出这一点是因为向Prometheus的迁移将涉及开发工作。你需要记录你应用程序中的有趣指标，以便使你的仪表板真正有用。你应该对自己的投资有信心，因为Prometheus是监控容器化应用程序最受欢迎的工具，该项目是CNCF的第二批毕业项目——在Kubernetes本身之后。还有工作正在进行中，将Prometheus指标格式纳入一个开放标准（称为OpenMetrics），这样其他工具就能读取以Prometheus格式公开的应用程序指标。
- en: 'What you include in those metrics will depend on the nature of your applications,
    but a good general approach is to follow the guidelines from Google’s Site Reliability
    Engineering practice. It’s usually pretty simple to add the four g*olden signals*
    to your app metrics: latency, traffic, errors, and saturation. (Appendix B in
    the ebook walks through how those look in Prometheus.) But the real value comes
    when you think about application performance from the user experience perspective.
    A graph that shows heavy disk usage in your database doesn’t tell you much, but
    if you can see that a high percentage of users don’t complete a purchase because
    your website’s checkout page takes too long to load, that’s worth knowing.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你包含在那些指标中的内容将取决于你应用程序的性质，但一个好的通用方法是从谷歌的站点可靠性工程实践指南中获取指导。通常，将四个“黄金信号”添加到你的应用程序指标中相当简单：延迟、流量、错误和饱和度。（电子书的附录B介绍了这些在Prometheus中的样子。）但真正的价值在于从用户体验的角度思考应用程序性能。一个显示你的数据库磁盘使用量高的图表并不能告诉你太多，但如果你能看到由于你的网站结账页面加载时间过长，导致高比例的用户无法完成购买，那么这一点就值得了解。
- en: That’s all for monitoring now, so we can clear down the cluster to get ready
    for the lab.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在监控部分就到这里，我们可以清理集群，为实验室做准备。
- en: Try it now Delete the namespaces for this chapter, and the objects created in
    the system namespace.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：删除本章的命名空间，以及系统命名空间中创建的对象。
- en: '[PRE18]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 14.6 Lab
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.6 实验室
- en: 'Another investigative lab for this chapter. In the lab folder, there’s a set
    of manifests for a slightly simpler deployment of Prometheus and a basic deployment
    of Elasticsearch. The goal is to run Elasticsearch with metrics flowing into Prometheus.
    Here are the details:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的另一个调查实验室。在实验室文件夹中，有一组用于稍微简单一些的 Prometheus 部署和 Elasticsearch 基础部署的清单。目标是让
    Elasticsearch 将指标流到 Prometheus。以下是详细信息：
- en: Elasticsearch doesn’t provide its own metrics, so you’ll need to find a component
    that does that for you.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch 不提供自己的指标，因此你需要找到一个为你完成这一功能的组件。
- en: The Prometheus configuration will tell you which namespace you need to use for
    Elasticsearch and the annotation you need for the metrics path.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus 的配置会告诉你需要使用哪个命名空间来部署 Elasticsearch 以及需要用于指标路径的注解。
- en: You should include a version label in your Elasticsearch Pod spec, so Prometheus
    will pick that up and add it to the metric labels.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该在 Elasticsearch Pod 规范中包含一个版本标签，这样 Prometheus 就会捕获它并将其添加到指标标签中。
- en: 'You’ll need to hunt around the documentation for Prometheus to get started,
    and that should show you the way. My solution is on GitHub for you to check in
    the usual place: [https://github.com/sixeyed/kiamol/blob/master/ch14/lab/README.md](https://github.com/sixeyed/kiamol/blob/master/ch14/lab/README.md).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要查阅 Prometheus 的文档来开始，这应该会指引你的方向。我的解决方案在 GitHub 上，你可以像往常一样在以下位置检查：[https://github.com/sixeyed/kiamol/blob/master/ch14/lab/README.md](https://github.com/sixeyed/kiamol/blob/master/ch14/lab/README.md)。
