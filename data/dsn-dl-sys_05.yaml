- en: 5 Hyperparameter optimization service
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 超参数优化服务
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节涵盖
- en: Hyperparameters and why they are important
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数及其重要性
- en: Two common approaches to hyperparameter optimization (HPO)
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两种常见的超参数优化（HPO）方法
- en: Designing an HPO service
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个HPO服务
- en: 'Three popular HPO libraries: Hyperopt, Optuna, and Ray Tune'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个流行的HPO库：Hyperopt、Optuna和Ray Tune
- en: 'In the previous two chapters, we saw how models are trained: a training service
    manages training processes in a remote compute cluster with given model algorithms.
    But model algorithms and training services aren’t all there is to model training.
    There’s one more component we haven’t discussed yet—hyperparameter optimization
    (HPO). Data scientists often overlook the fact that hyperparameter choices can
    influence model training results significantly, especially when these decisions
    can be automated using engineering methods.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两个章节中，我们看到了模型是如何被训练的：一个训练服务在远程计算集群中管理使用给定模型算法的训练过程。但模型算法和训练服务并不是模型训练的全部。还有一个我们尚未讨论的组件——超参数优化（HPO）。数据科学家往往忽视了这样一个事实：超参数的选择可以显著影响模型训练结果，尤其是在这些决策可以通过工程方法自动化的情况下。
- en: Hyperparameters are parameters whose value must be set before the model training
    process starts. Learning rate, batch size, and number of hidden layers are all
    examples of hyperparameters. Unlike the value of *model parameters*—weights and
    bias, for example—hyperparameters cannot be learned during the training process.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数是在模型训练过程开始之前必须设置的参数。学习率、批量大小和隐藏层数量都是超参数的例子。与*模型参数*的值——例如权重和偏差——不同，超参数在训练过程中不能被学习。
- en: Research reveals that the chosen value of hyperparameters can affect both the
    quality of the model training as well as the time and memory requirements of the
    training algorithm. Therefore, hyperparameters must be tuned to be optimal for
    model training. Nowadays, HPO has become a standard step in the deep learning
    model development process.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 研究表明，超参数的选择可以影响模型训练的质量以及训练算法的时间和内存需求。因此，必须调整超参数以使其对模型训练最优。如今，HPO已成为深度学习模型开发过程中的一个标准步骤。
- en: As one of the deep learning components, HPO is very important to software engineers.
    This is because HPO doesn’t require a deep understanding of deep learning algorithms,
    so engineers are often assigned to this task. Most of the time, HPO can run like
    a black box, and the training code does not need to be modified. Furthermore,
    engineers have the capability of building an automatic HPO mechanism, making HPO
    possible. As there are so many hyperparameters to tune (learning rate, number
    of epochs, data batch size, and more) and so many values to try, it is simply
    impractical to manually adjust each hyperparameter value. Software engineers are
    well-suited to create an automated system because of their expertise in microservices,
    distributed computing, and resource management.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 作为深度学习组件之一，HPO对软件工程师来说非常重要。这是因为HPO不需要对深度学习算法有深入的了解，因此工程师通常被分配这项任务。大多数时候，HPO可以像黑盒一样运行，训练代码不需要修改。此外，工程师有能力构建一个自动HPO机制，使HPO成为可能。由于有如此多的超参数需要调整（学习率、训练轮数、数据批量大小等）以及如此多的值需要尝试，手动调整每个超参数值是不切实际的。软件工程师因其对微服务、分布式计算和资源管理的专业知识而非常适合创建自动化系统。
- en: 'In this chapter, we will focus on the engineering of automatic HPO. We first
    introduce the background information necessary to feel comfortable working with
    HPO. We delve into a deeper understanding of hyperparameters and the process of
    tuning or optimizing them. We’ll also meet some popular HPO algorithms and compare
    two common approaches to automating HPO: using a library and building a service.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注自动HPO的工程。我们首先介绍与HPO一起工作的必要背景信息。我们将深入了解超参数以及调整或优化它们的过程。我们还将介绍一些流行的HPO算法，并比较两种常见的自动化HPO方法：使用库和构建服务。
- en: Then we’ll start designing. We will look at how to design an HPO service, including
    five design principles for creating an HPO service, as well as one general design
    proposal that is particularly important at this stage. Finally, we show you three
    popular open source HPO frameworks that would be a perfect fit if you want to
    optimize your training code locally.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将开始设计。我们将探讨如何设计一个HPO服务，包括创建HPO服务的五个设计原则，以及一个在此阶段特别重要的通用设计提案。最后，我们将向您展示三个流行的开源HPO框架，如果您想本地优化您的训练代码，它们将是一个完美的选择。
- en: Unlike previous chapters, we will not be building a brand new sample service
    in this chapter. Instead, we suggest you use the open source Kubeflow Katib (discussed
    in appendix C). Katib is a well-designed, extensible, and highly portable HPO
    service that can be used for almost any HPO project. Thus, we do not have to build
    one if it is a low-hanging fruit for you.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 与前几章不同，我们本章不会构建一个新的示例服务。相反，我们建议您使用开源的Kubeflow Katib（在第C部分讨论）。Katib是一个设计良好、可扩展且高度可移植的HPO服务，几乎可以用于任何HPO项目。因此，如果您认为这是一个低垂的果实，我们就不必构建它。
- en: This chapter should give you a holistic view of the HPO domain while also providing
    you with a practical understanding of how to run HPO for your specific needs.
    Whether you decide to run HPO with a remote service or at your local machine with
    libraries/frameworks like Hyperopt, Optuna, or Ray Tune, we’ve got you covered.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章应为您提供一个对HPO领域的整体视角，同时向您提供如何针对您的特定需求运行HPO的实用理解。无论您决定使用远程服务还是使用Hyperopt、Optuna或Ray
    Tune等库/框架在本地机器上运行HPO，我们都能为您提供支持。
- en: 5.1 Understanding hyperparameters
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 理解超参数
- en: Before we look at how to tune hyperparameters, let’s get a clearer understanding
    of what hyperparameters are and why they are important.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨如何调整超参数之前，让我们先更清楚地了解超参数是什么以及为什么它们很重要。
- en: 5.1.1 What is a hyperparameter?
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 什么是超参数？
- en: 'The process of training deep learning models uses two types of parameters,
    or values: *model parameters* and *hyperparameters*. Model parameters are trainable—that
    is, their values are learned during model training—and they change as the model
    iterates. Hyperparameters, in contrast, are static; these configurations are defined
    and set before the training starts. For example, we can set the training epoch
    as 30 and the activation function of the neural network as ReLU (rectified linear
    unit) in the input parameters to kick off a model training process.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型的训练过程使用两种类型的参数或值：*模型参数*和*超参数*。模型参数是可训练的——也就是说，它们的值在模型训练期间学习到——并且随着模型的迭代而改变。相比之下，超参数是静态的；这些配置在训练开始之前就定义和设置了。例如，我们可以将训练轮数设置为30，并将神经网络的激活函数设置为ReLU（修正线性单元）作为输入参数，以启动模型训练过程。
- en: 'In other words, any model training configuration that affects model training
    performance but can’t be estimated from data is a hyperparameter. There can be
    hundreds of hyperparameters in a model training algorithm, including, for example,
    the choice of model optimizer—ADAM (see “Adam: A Method for Stochastic Optimization,”
    by Diederik P. Kingma and Jimmy Ba; [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980))
    or RMSprop (see “A Look at Gradient Descent and RMSprop Optimizers,” by Rohith
    Gandhi; [http://mng.bz/xdZX](http://mng.bz/xdZX))—the number of layers in the
    neural network, the embedding dimensions, the minibatch size, and the learning
    rate.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '换句话说，任何影响模型训练性能但无法从数据中估计的模型训练配置都是超参数。模型训练算法中可能有数百个超参数，包括例如模型优化器的选择——ADAM（参见Diederik
    P. Kingma和Jimmy Ba的“Adam: A Method for Stochastic Optimization”；[https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980))或RMSprop（参见Rohith
    Gandhi的“A Look at Gradient Descent and RMSprop Optimizers”；[http://mng.bz/xdZX](http://mng.bz/xdZX))——神经网络中的层数、嵌入维度、小批量大小和学习率。'
- en: 5.1.2 Why are hyperparameters important?
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.2 为什么超参数很重要？
- en: The choice of values for hyperparameters can have a tremendous effect on model
    training results. Typically set manually, the values control the behavior of training
    algorithm execution and determine the speed of model training and the model accuracy.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数值的选取可以对模型训练结果产生巨大影响。通常手动设置，这些值控制训练算法的执行行为，并决定了模型训练的速度和模型精度。
- en: To see this effect for yourself, you can experiment with hyperparameter values
    by running model training in the TensorFlow playground ([https://playground.tensorflow.org](https://playground.tensorflow.org)).
    In this online playground, you can design your own neural network and train it
    to recognize four types of graphic patterns. By setting different hyperparameters,
    such as learning rate, regularization method, activation function, neural network
    layer count, and neuron count, you will see not only how the model performance
    varies but also how the learning behavior, such as training time and learning
    curve, can differ. To train a model to recognize a complicated data pattern like
    a spiral shape in this playground, we need to select the hyperparameters very
    carefully. For example, try setting the hidden layer count to 6, the neuron count
    per layer to 5, the activation function to `ReLU`, the data batch size to 10,
    and the regularization method to `L1`. After nearly 500 epochs of training, you’ll
    see that the model can make an accurate classification prediction on a spiral-shaped
    graph.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了亲自体验这种效果，你可以在TensorFlow playground中通过运行模型训练来实验超参数值（[https://playground.tensorflow.org](https://playground.tensorflow.org)）。在这个在线playground中，你可以设计自己的神经网络，并训练它来识别四种类型的图形模式。通过设置不同的超参数，例如学习率、正则化方法、激活函数、神经网络层数和神经元数量，你将不仅看到模型性能的变化，还能看到学习行为，如训练时间和学习曲线，如何不同。为了在这个playground中训练一个能够识别复杂数据模式（如螺旋形状）的模型，我们需要非常仔细地选择超参数。例如，尝试将隐藏层数量设置为6，每层的神经元数量设置为5，激活函数设置为`ReLU`，数据批量大小设置为10，正则化方法设置为`L1`。经过近500个epoch的训练后，你会发现模型可以在螺旋形状的图上做出准确的分类预测。
- en: In the research field, the effect of hyperparameter selection on model performance
    has long been documented. Take natural language processing embedding training,
    for instance. One paper, “Improving Distributional Similarity with Lessons Learned
    from Word Embeddings,” by Levy et al. ([https://aclanthology.org/Q15-1016.pdf](https://aclanthology.org/Q15-1016.pdf)),
    reveals that much of the performance gains of word embeddings are due to certain
    system design choices along with the HPOs rather than the embedding algorithms
    themselves. In NLP embedding training, these authors found the selection of hyperparameters
    has more effect than the selection of the training algorithm! Because the hyperparameter
    selection is so crucial to model training performance, hyperparameter tuning has
    now become a standard step in the model training process.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究领域，超参数选择对模型性能的影响已经长期被记录。以自然语言处理嵌入训练为例。一篇论文，“从词嵌入中学习到的分布相似性改进”，由Levy等人撰写（[https://aclanthology.org/Q15-1016.pdf](https://aclanthology.org/Q15-1016.pdf)），揭示了词嵌入性能提升的大部分原因是由于某些系统设计选择以及HPO，而不是嵌入算法本身。在NLP嵌入训练中，这些作者发现超参数的选择比训练算法的选择更有影响！因为超参数选择对模型训练性能至关重要，超参数调优现在已成为模型训练过程中的一个标准步骤。
- en: 5.2 Understanding hyperparameter optimization
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 理解超参数优化
- en: Now that you have a solid idea of what hyperparameters are and why they are
    so important to model training, let’s turn to the process of optimizing them for
    your model. In this section, we will walk you through the steps for HPO. We will
    also look at HPO algorithms, which are used to optimize hyperparameters, as well
    as common approaches to performing HPO.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你对超参数有了清晰的认识，并且知道它们对模型训练的重要性，那么让我们转向优化它们的过程。在本节中，我们将向您介绍HPO的步骤。我们还将探讨用于优化超参数的HPO算法，以及执行HPO的常见方法。
- en: 5.2.1 What is HPO?
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 什么是HPO？
- en: HPO, or tuning, is the process of discovering a set of hyperparameters that
    yields an optimal model. Optimal here means a model that minimizes a predefined
    loss function on a given dataset. In figure 5.1, you can see a high-level view
    of the generic workflow of HPO on the model training process.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: HPO，或调优，是发现一组能够产生最优模型的超参数的过程。这里的“最优”意味着在给定数据集上最小化预定义损失函数的模型。在图5.1中，你可以看到HPO在模型训练过程中的通用工作流程的高级视图。
- en: '![](../Images/05-01.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1](../Images/05-01.png)'
- en: Figure 5.1 This high-level view of the HPO workflow shows that the process is
    essentially an experiment to find the optimal hyperparameter values.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 高级视图展示了HPO工作流程，表明该过程本质上是一个寻找最优超参数值的实验。
- en: From figure 5.1, we see that an HPO workflow can be visualized as a loop made
    with four steps. It shows us that the HPO process is a repetitive model training
    process, except that the neural network is trained each time with a different
    set of hyperparameters. The optimal set of hyperparameters will be discovered
    in this process. We normally call each run of the model training a *trial*. The
    whole HPO experiment is a trial loop in which we run one trial after another until
    the end criteria are met.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从图5.1中，我们看到HPO工作流程可以可视化为由四个步骤组成的循环。它表明HPO过程是一个重复的模型训练过程，只不过每次训练神经网络时使用的是不同的一组超参数。最佳的超参数集将在这一过程中被发现。我们通常将每次模型训练的运行称为*试验*。整个HPO实验是一个试验循环，我们在满足结束条件之前，一个接一个地运行试验。
- en: Note To have a fair evaluation, the same dataset is used for each HPO trial.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：为了进行公平评估，每个HPO试验都使用相同的数据集。
- en: Each trial has four steps, as shown in figure 5.1\. Step 1 is training the neural
    network with a set of hyperparameter values. Step 2 is evaluating the training
    output (the model).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每个试验有四个步骤，如图5.1所示。步骤1是使用一组超参数值训练神经网络。步骤2是评估训练输出（即模型）。
- en: In step 3, the HPO process checks whether the end criteria have been met—for
    example, whether we have run out of our trial budget or whether the model produced
    in this trial has reached our performance evaluation target. If the trial result
    meets the end condition, the trial loop breaks and the experiment ends. The hyperparameter
    values that produced the best model evaluation result are considered the optimal
    hyperparameters.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3步中，HPO过程检查是否满足结束标准——例如，是否已经耗尽我们的试验预算，或者在这个试验中生成的模型是否达到了我们的性能评估目标。如果试验结果满足结束条件，试验循环将中断，实验结束。产生最佳模型评估结果的超参数值被认为是最佳超参数。
- en: 'If the end condition is not met, the process moves to step 4: the HPO process
    will produce a new set of hyperparameter values and start a new trial by triggering
    a model training run. The hyperparameter values used in each trial are generated
    either manually or automatically by an HPO algorithm. Let’s look closer at these
    two approaches and the HPO algorithms in the next two sections.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未满足结束条件，流程将移动到第4步：HPO过程将生成一组新的超参数值，并通过触发模型训练运行来启动一个新的试验。每个试验中使用的超参数值是由人工生成或由HPO算法自动生成的。让我们在下一节中更详细地看看这两种方法和HPO算法。
- en: Manual HPO
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 手动HPO
- en: As data scientists, we often manually pick the hyperparameter values to run
    the HPO process shown in figure 5.1\. Though, admittedly, choosing the optimal
    hyperparameter values manually is more like improvisation than science. But we
    are also drawing from our experience and the intuition that comes from that experience.
    We tend to start training a model with empirical hyperparameter values, such as
    the values used in a relevant published paper, and then make some small adjustments
    and test the model. After a few trials, we manually compare the model performance
    and choose the best-performing model from these trials. Figure 5.2 illustrates
    this workflow.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，我们经常手动选择超参数值来运行图5.1所示的HPO过程。诚然，手动选择最佳超参数值更像是一种即兴发挥而不是科学。但我们也在借鉴我们的经验和由此产生的直觉。我们倾向于使用经验超参数值开始训练模型，例如在相关已发表论文中使用的值，然后进行一些小的调整并测试模型。经过几次试验后，我们手动比较模型性能，并从这些试验中选择表现最好的模型。图5.2说明了这个工作流程。
- en: '![](../Images/05-02.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1](../Images/05-02.png)'
- en: Figure 5.2 Manually picking hyperparameter values can be tedious and time-consuming.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 手动选择超参数值可能会很繁琐且耗时。
- en: 'The biggest problem with manual HPO is not knowing whether our hyperparameter
    values are optimal because we just choose some empirical values and tweak them.
    To get the optimal values, we need to try all possible hyperparameter values,
    aka search spaces. In the example of figure 5.2, we want to optimize two hyperparameters:
    learning rate and dataset batch size. In the HPO process, the goal is to find
    the pair of `batch_size` and `learning_rate` that produces the best model. Let’s
    say we define a search space for `batch_size` as {8, 16, 32, 64, 128, 256} and
    define another search space for `learning_rate` as {0.1, 0.01, 0.001, 0.5, 0.05,
    0.005}. Then the total number of hyperparameter values we need to verify is 36
    (62).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 手动 HPO 的最大问题是我们不知道我们的超参数值是否最优，因为我们只是选择了一些经验值并进行调整。为了获得最优值，我们需要尝试所有可能的超参数值，即搜索空间。在图
    5.2 的例子中，我们想要优化两个超参数：学习率和数据集批量大小。在 HPO 过程中，目标是找到产生最佳模型的 `batch_size` 和 `learning_rate`
    的配对。假设我们为 `batch_size` 定义了一个搜索空间为 {8, 16, 32, 64, 128, 256}，并为 `learning_rate`
    定义了另一个搜索空间为 {0.1, 0.01, 0.001, 0.5, 0.05, 0.005}。那么我们需要验证的超参数值总数是 36（62）。
- en: Because we run the HPO manually, we have to run the model training process (HPO
    trial) 36 times and record the model evaluation result and the hyperparameters’
    values used in each trial. After completing all 36 trials and comparing the results,
    which is usually the model accuracy, we find the optimal `batch_size` and `learning_rate`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们手动运行 HPO，我们必须运行模型训练过程（HPO 试验）36 次，并记录每次试验的模型评估结果和使用的超参数值。完成所有 36 次试验并比较结果后，通常是模型准确率，我们发现最佳的
    `batch_size` 和 `learning_rate`。
- en: Manually running HPO for the entire hyperparameter search space can be time-consuming,
    error prone, and tedious, as you can see. Moreover, deep learning hyperparameters
    usually have a complex configuration space, which often consists of a combination
    of continuous, categorical, and conditional hyperparameters as well as high dimensions.
    The deep learning industry is currently moving toward automatic HPO because manual
    HPO is simply not feasible.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，手动运行整个超参数搜索空间中的 HPO 可能会耗时、易出错且繁琐。此外，深度学习的超参数通常具有复杂的配置空间，这通常包括连续、分类和条件超参数的组合以及高维度。深度学习行业目前正朝着自动化
    HPO 发展，因为手动 HPO 简直不可行。
- en: Automatic HPO
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化超参数优化（Automatic HPO）
- en: Automatic HPO is the process of using compute power and algorithms to automatically
    find the optimal hyperparameters for a training code. The idea is to use an efficient
    search algorithm to discover the optimal hyperparameters without human intervention.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化 HPO 是使用计算能力和算法自动找到训练代码最佳超参数的过程。其理念是使用高效的搜索算法来发现最佳超参数，而不需要人为干预。
- en: We also want the automatic HPO to run in a black-box fashion, so it is agnostic
    about the training code it is optimizing, and therefore we can easily onboard
    existing model training code to the HPO system. Figure 5.3 shows the automatic
    HPO workflow.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望自动化 HPO 以黑盒方式运行，因此它对其优化的训练代码一无所知，因此我们可以轻松地将现有的模型训练代码集成到 HPO 系统中。图 5.3 展示了自动化
    HPO 工作流程。
- en: '![](../Images/05-03.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-03.png)'
- en: Figure 5.3 An automatic HPO workflow
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 自动化 HPO 工作流程
- en: In step 1, data scientists submit HPO requests to the automatic HPO system,
    which runs the HPO process in a black-box fashion (figure 5.3). They input the
    hyperparameters to be optimized and their value search space into the black box
    (the “automatic HPO” box in figure 5.3)—for example, the learning rate’s search
    space may be [0.005, 0.1] and dataset batch size’s search space may be {8, 16,
    32, 64, 128, 256}. Data scientists also need to configure the training execution,
    such as the training code; an evaluation method; an exit objective; and a trial
    budget, such as 24 total trials for this experiment.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 1 中，数据科学家向自动化 HPO 系统提交 HPO 请求，该系统以黑盒方式运行 HPO 过程（图 5.3）。他们将需要优化的超参数及其值搜索空间输入到黑盒中（图
    5.3 中的“自动化 HPO”框）——例如，学习率的搜索空间可能是 [0.005, 0.1]，数据集批量大小的搜索空间可能是 {8, 16, 32, 64,
    128, 256}。数据科学家还需要配置训练执行，例如训练代码；评估方法；退出目标；以及试验预算，例如本实验的 24 个总试验。
- en: Once users submit the HPO request, the HPO experiment (step 2) starts. The HPO
    system schedules all the trials and manages their training executions; it also
    runs an HPO algorithm to generate hyperparameter values (picking values from the
    search space) for each trial. When the trial budget runs out or the training objective
    is met, the system returns a set of optimal hyperparameter values (step 3).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦用户提交HPO请求，HPO实验（步骤2）就开始了。HPO系统安排所有试验并管理它们的训练执行；它还运行HPO算法为每个试验生成超参数值（从搜索空间中选择值）。当试验预算耗尽或训练目标达成时，系统返回一组最佳超参数值（步骤3）。
- en: 'Automatic HPO relies on two key components: the HPO algorithm and trial training
    execution management. We can find the optimal hyperparameter values with fewer
    compute resources using an efficient HPO algorithm. By using a sophisticated training
    management system, data scientists can be hands-free for the entire HPO process.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 自动超参数优化（HPO）依赖于两个关键组件：HPO算法和试验训练执行管理。我们可以通过高效的HPO算法使用更少的计算资源来找到最佳的超参数值。通过使用复杂的训练管理系统，数据科学家在整个HPO过程中可以无需手动操作。
- en: NOTE Because of the inefficiency of manual HPO, automatic HPO is the mainstream
    approach. To keep things concise, we will use the term *HPO* to refer to “automatic
    hyperparameter optimization” in the rest of this chapter.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：由于手动HPO的低效性，自动HPO是主流方法。为了简洁起见，在本章的其余部分我们将使用术语*HPO*来指代“自动超参数优化”。
- en: 5.2.2 Popular HPO algorithms
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 流行的HPO算法
- en: 'Most of the HPO algorithms can be categorized into three buckets: model-free
    optimization, Bayesian optimization, and multifidelity optimization.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数HPO算法可以分为三个类别：无模型优化、贝叶斯优化和多保真优化。
- en: 'Note Because the main goal of this chapter is teaching HPO engineering, the
    HPO algorithms discussed here will stay at a high level. The goal of this section
    is to provide you with enough background knowledge on HPO algorithms to be able
    to build or set up an HPO system. If you want to know the mathematical reasoning
    behind the algorithms, please check out chapter 1, “Hyperparameter Optimization,”
    by Matthias Feurer and Frank Hutter, of *AutoML: Methods, Systems, Challenges*
    ([http://mng.bz/AlGx](http://mng.bz/AlGx)) and the paper “Algorithms for Hyper-Parameter
    Optimization,” by Bergstra et al. ([http://mng.bz/Zo9A](http://mng.bz/Zo9A)).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '注意：由于本章的主要目标是教授HPO工程，因此这里讨论的HPO算法将保持在一个较高的层次。本节的目标是提供足够关于HPO算法的背景知识，以便能够构建或设置一个HPO系统。如果您想了解算法背后的数学原理，请参阅Matthias
    Feurer和Frank Hutter所著的*AutoML: Methods, Systems, Challenges*一书中的第1章“超参数优化”（[http://mng.bz/AlGx](http://mng.bz/AlGx)）以及Bergstra等人撰写的论文“Algorithms
    for Hyper-Parameter Optimization”（[http://mng.bz/Zo9A](http://mng.bz/Zo9A)）。'
- en: Model-free optimization methods
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 无模型优化方法
- en: In model-free methods, data scientists make no assumptions about training code,
    and the correlation between HPO trials is ignored. Grid search and random search
    are the most commonly used methods.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在无模型方法中，数据科学家不对训练代码做出假设，并且忽略HPO试验之间的相关性。网格搜索和随机搜索是最常用的方法。
- en: In grid search, users specify a limited set of values for each hyperparameter
    and then choose trial hyperparameters from the Cartesian product of those values.
    For example, we can first specify value sets (search space) for the learning rate
    as {0.1, 0.005, 0.001} and data batch size as {10, 40, 100} and then build the
    grid with Cartesian products (as grid value) of these sets, such as (0.1, 10),
    (0.1, 40), and (0.1, 100). After the grid is built, we can start the HPO trial
    with the grid values.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在网格搜索中，用户为每个超参数指定一组有限的值，然后从这些值的笛卡尔积中选择试验超参数。例如，我们可以首先指定学习率的值集（搜索空间）为{0.1, 0.005,
    0.001}和数据批量大小为{10, 40, 100}，然后通过这些集合的笛卡尔积（作为网格值）构建网格，例如(0.1, 10)，(0.1, 40)，和(0.1,
    100)。网格构建完成后，我们可以开始使用网格值启动HPO试验。
- en: Grid search suffers when the number of hyperparameters becomes larger or the
    parameter’s search space becomes bigger because the required number of evaluations
    will grow exponentially in this case. Another problem with grid search is its
    ineffectiveness. Because grid search treats each set of hyperparameter candidates
    equally, it will waste a lot of compute resources in the nonoptimal configuration
    space while not spending enough compute power on the optimal space.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当超参数的数量变得更大或参数的搜索空间变得更大时，网格搜索会受到影响，因为在这种情况下所需的评估数量将以指数级增长。网格搜索的另一个问题是其低效性。因为网格搜索将每一组超参数候选者视为同等重要，所以在非最佳配置空间上会浪费大量的计算资源，而在最佳空间上则没有足够的计算能力。
- en: Random search works by sampling the hyperparameter configuration space at random
    until a certain budget for the search is run out. For example, we can set the
    search space for the learning rate to [0.001, 0.1] and data batch size to [10,
    100] and then set the search budget to 100, which means it will run up to a total
    of 100 HPO trials. In each trial, a random value is selected between 0.001 and
    0.1 as the learning rate, and a random value is selected between 10 and 100 as
    the data batch size.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索通过随机采样超参数配置空间直到搜索预算耗尽来工作。例如，我们可以将学习率的搜索空间设置为[0.001, 0.1]，数据批量大小设置为[10, 100]，然后设置搜索预算为100，这意味着它将运行总共100次HPO试验。在每次试验中，从0.001到0.1之间随机选择一个值作为学习率，从10到100之间随机选择一个值作为数据批量大小。
- en: This approach has two advantages over grid search. First, random search can
    evaluate more values for each hyperparameter, which increases the chance of finding
    the optimal hyperparameter set. Second, random search has easier parallelization
    requirements; because all evaluation workers can run completely parallel, they
    don’t need to communicate with each other, and a failed worker doesn’t leave holes
    in the search space. But in grid search, a failed worker can skip the trial hyperparameters
    assigned to the worker in the HPO.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与网格搜索相比，这种方法有两个优点。首先，随机搜索可以为每个超参数评估更多的值，这增加了找到最优超参数集的机会。其次，随机搜索的并行化要求更容易；因为所有评估工作者可以完全并行运行，它们不需要相互通信，失败的工作者不会在搜索空间中留下空缺。但在网格搜索中，失败的工作者可能会跳过分配给工作者的HPO中的试验超参数。
- en: The downside of random search is uncertainty; there is no guarantee an optimal
    set of hyperparameters can be found within a finite computing budget. In theory,
    if we allow for enough resources, random search can add sufficient random points
    in the search, so it will, as expected, find the optimum hyperparameter set. In
    practice, random search is used as a baseline.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 随机搜索的缺点是不确定性；无法保证在有限的计算预算内找到最优的超参数集。理论上，如果我们允许足够的资源，随机搜索可以在搜索中添加足够的随机点，因此它将像预期的那样找到最优的超参数集。在实践中，随机搜索被用作基线。
- en: '![](../Images/05-04.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-04.png)'
- en: 'Figure 5.4 Comparison of grid search and random search for minimizing a function
    with one important and one unimportant parameter. (Source: Figure 1.1\. of “Hyperparameter
    Optimization,” by Matthias Feurer and Frank Hutter, in *AutoML: Methods, Systems,
    Challenges*, eds. Frank Hutter, Lars Kotthoff, and Joaquin Vanschoren; Springer,
    2019\. [www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf](http://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf))'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4展示了具有一个重要参数和一个不重要参数的函数最小化过程中网格搜索和随机搜索的比较。（来源：“超参数优化”，作者Matthias Feurer和Frank
    Hutter，收录于《AutoML：方法、系统、挑战》，由Frank Hutter、Lars Kotthoff和Joaquin Vanschoren编辑；Springer，2019年。[www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf](http://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf))
- en: Figure 5.4 illustrates the comparison between grid search and random search.
    The trial hyperparameter candidates (black dots) in grid search are Cartesian
    products of important parameter values (in rows) and unimportant value points
    (in columns). Their distribution can be seen as a grid in the search space (the
    white square canvas). The random search algorithm obtains the hyperparameter candidates
    randomly from the search space. When given enough of a search budget, its search
    point has a better chance of getting closer to the optimal position.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4说明了网格搜索和随机搜索之间的比较。网格搜索中的试验超参数候选者（黑色点）是重要参数值（行）和不重要值点（列）的笛卡尔积。它们的分布可以看作是搜索空间中的网格（白色正方形画布）。随机搜索算法从搜索空间中随机获取超参数候选者。当给定足够的搜索预算时，它的搜索点有更好的机会接近最优位置。
- en: Model-based Bayesian optimization
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模型的贝叶斯优化
- en: Bayesian optimization is a state-of-the-art optimization framework for the global
    optimization of expensive black-box functions. It’s used widely for various problem
    settings, such as image classification, speech recognition, and neural language
    modeling.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化是用于全局优化昂贵黑盒函数的最先进优化框架。它被广泛应用于各种问题设置，如图像分类、语音识别和神经语言建模。
- en: The Bayesian optimization methods can use different samplers, such as Gaussian
    process regression (see “An Intuitive Tutorial to Gaussian Processes Regression,”
    by Jie Wang; [https://arxiv.org/abs/2009.10862](https://arxiv.org/abs/2009.10862))
    and tree-structured Parzen estimator approach (TPE), to calculate hyperparameter
    candidates in the search space. In less rigorous words, the Bayesian optimization
    methods use statistical methods to calculate new hyperparameter value suggestions
    from the values used in past trials and their evaluation results.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化方法可以使用不同的采样器，例如高斯过程回归（参见 Jie Wang 的“高斯过程回归直观教程”；[https://arxiv.org/abs/2009.10862](https://arxiv.org/abs/2009.10862)）和树结构帕雷茨估计方法（TPE），来计算搜索空间中的超参数候选值。用不那么严谨的话来说，贝叶斯优化方法使用统计方法从过去试验中使用的值及其评估结果中计算新的超参数值建议。
- en: Note Why is it called Bayesian optimization? Bayesian analysis ([https://www.britannica.com/science/Bayesian-analysis](https://www.britannica.com/science/Bayesian-analysis))
    is a widely used statistical inference method, named after English mathematician
    Thomas Bayes ([https://www.britannica.com/biography/Thomas-Bayes](https://www.britannica.com/biography/Thomas-Bayes)),
    that allows you to combine prior information about a population parameter with
    evidence from information contained in a sample to guide the statistical inference
    process. Based on this method, Jonas Mockus introduced the term Bayesian optimization
    (see “Bayesian Linear Regression,” Bruna Wundervald; [https://www.researchgate.net/publication/333917874_Bayesian_Linear_
    Regression](https://www.researchgate.net/publication/333917874_Bayesian_Linear_Regressionin))
    in his 1970s and 1980s work on global optimization.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意为什么叫贝叶斯优化？贝叶斯分析（[https://www.britannica.com/science/Bayesian-analysis](https://www.britannica.com/science/Bayesian-analysis)）是一种广泛使用的统计推断方法，以英国数学家托马斯·贝叶斯（[https://www.britannica.com/biography/Thomas-Bayes](https://www.britannica.com/biography/Thomas-Bayes)）的名字命名，它允许你将关于总体参数的先验信息与样本中包含的证据结合起来，以指导统计推断过程。基于这种方法，Jonas
    Mockus 在 1970 年代和 1980 年代关于全局优化工作的基础上，引入了贝叶斯优化（参见 Bruna Wundervald 的“贝叶斯线性回归”；[https://www.researchgate.net/publication/333917874_Bayesian_Linear_Regression](https://www.researchgate.net/publication/333917874_Bayesian_Linear_Regression)）这一术语。
- en: The concept behind Bayesian optimization methods is that the optimal hyperparameters
    search would be more efficient if the algorithm could learn from past trials.
    In practice, the Bayesian optimization method can find the optimal hyperparameters
    set with fewer evaluation runs (trials) and is more stable than the other search
    methods. Figure 5.5 shows the data sampling difference between random search and
    the Bayesian approach.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯优化方法背后的概念是，如果算法能够从过去的试验中学习，那么最优超参数搜索将更加高效。在实践中，贝叶斯优化方法可以在更少的评估运行（试验）中找到最优超参数集，并且比其他搜索方法更稳定。图
    5.5 显示了随机搜索和贝叶斯方法之间的数据采样差异。
- en: '![](../Images/05-05.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-05.png)'
- en: Figure 5.5 A data sampler comparison of random search (a) and Bayesian approach
    (b) using 10 trials
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 随机搜索（a）和贝叶斯方法（b）使用 10 次试验的数据采样比较
- en: Let’s assume the optimal hyperparameter value is at (x,y) = (0.5, 1), and we
    try to use random search and Bayesian search to find it. In figure 5.5 (a), we
    see the data is randomly sampled in the search space where x := [–1.0, 1.0] and
    y := [1, 5]. In figure 5.5 (b), we see that the data is sampled heavily in the
    area (x := [0.3, 0.7] and y := [1,1.5]), where the optimal value is located. This
    comparison shows that the Bayesian search is more likely to find the optimal hyperparameters
    in the given search space, and with a limited execution budget, the selected (sampled)
    hyperparameter values become closer and closer to the optimal value after each
    experiment in the search process.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 假设最优超参数值位于 (x,y) = (0.5, 1)，我们尝试使用随机搜索和贝叶斯搜索来找到它。在图 5.5 (a) 中，我们看到数据在搜索空间中随机采样，其中
    x := [–1.0, 1.0] 和 y := [1, 5]。在图 5.5 (b) 中，我们看到数据在区域 (x := [0.3, 0.7] 和 y :=
    [1,1.5]) 中采样密集，该区域包含最优值。这种比较表明，贝叶斯搜索更有可能在给定的搜索空间中找到最优超参数，并且在有限的执行预算下，所选（采样）的超参数值在搜索过程中的每次实验后越来越接近最优值。
- en: 'There are other advanced HPO algorithms, such as Hyperband ([http://mng.bz/Rlwv](http://mng.bz/Rlwv)),
    TPE ([http://mng.bz/2a6a](http://mng.bz/2a6a)), and covariance matrix adaptation
    evolution strategy (CMA-ES; [http://mng.bz/1M5q](http://mng.bz/1M5q)). Although
    they do not follow the exact same mathematical theory as the Bayesian–Gaussian
    process method, they share the same hyperparameter selection strategy: calculating
    the next suggested value by considering the historical evaluation results.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他高级HPO算法，例如Hyperband（链接为[http://mng.bz/Rlwv](http://mng.bz/Rlwv))，TPE（链接为[http://mng.bz/2a6a](http://mng.bz/2a6a))，以及协方差矩阵自适应进化策略（CMA-ES；链接为[http://mng.bz/1M5q](http://mng.bz/1M5q))。尽管它们不遵循与贝叶斯-高斯过程方法完全相同的数学理论，但它们共享相同的超参数选择策略：通过考虑历史评估结果来计算下一个建议值。
- en: Multifidelity optimization
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 多保真优化
- en: Multifidelity methods improve the efficiency of model-free and Bayesian optimization
    methods. Nowadays, tuning hyperparameters on large datasets can take several hours
    and even days. To speed up the HPO, multifidelity methods were developed. With
    this approach, we minimize the loss function using so-called low-fidelity approximations
    of the actual loss function. As a result, we can skip a lot of computations during
    HPO.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 多保真方法提高了无模型和贝叶斯优化方法的效率。如今，在大数据集上调整超参数可能需要几个小时甚至几天。为了加速HPO，开发了多保真方法。采用这种方法，我们使用所谓的低保真近似来最小化实际损失函数的损失函数。因此，在HPO过程中我们可以跳过大量的计算。
- en: Note In the machine learning context, the loss function ([https://www.datarobot.com/blog/introduction-to-loss-functions/](https://www.datarobot.com/blog/introduction-to-loss-functions/))
    is a method of evaluating how well a training algorithm models your dataset. If
    the model output (predictions) is far off from the expected results, the loss
    function should output a higher number; otherwise, it should output a lower number.
    The loss function is a key component of ML algorithm development; the design of
    the loss function directly affects model accuracy.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在机器学习背景下，损失函数（链接为[https://www.datarobot.com/blog/introduction-to-loss-functions/](https://www.datarobot.com/blog/introduction-to-loss-functions/))是评估训练算法如何模拟你的数据集的一种方法。如果模型输出（预测）与预期结果相差甚远，损失函数应输出一个较高的数值；否则，它应输出一个较低的数值。损失函数是ML算法开发的关键组成部分；损失函数的设计直接影响模型精度。
- en: Although the approximation introduces a tradeoff between optimization performance
    and run time, in practice, the speedups often outweigh the approximation errors.
    For more details, refer to “Hyperparameter Optimization,” by Matthias Feurer and
    Frank Hutter ([www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf](http://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf)).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然近似引入了优化性能和运行时间之间的权衡，但在实践中，速度提升往往超过近似误差。更多细节请参考Matthias Feurer和Frank Hutter合著的“超参数优化”（链接为[www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf](http://www.automl.org/wp-content/uploads/2019/05/AutoML_Book_Chapter1.pdf))。
- en: Why does the Bayesian-like HPO algorithm work?
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么贝叶斯优化算法有效？
- en: The blog post “Intuition behind Gaussian Processes,” by Michael McCourt ([https://sigopt.com/blog/intuition-behind-gaussian-processes/](https://sigopt.com/blog/intuition-behind-gaussian-processes/))
    gives an excellent explanation for why the Bayesian-like optimization algorithm
    can find the optimum hyperparameter set without checking every possible value
    in the search space. In some settings, the experiments we observe are independent,
    such as flipping a coin 50 times; knowledge of one does not imply knowledge of
    others. But, fortunately, many settings have a more helpful structure from which
    previous observations provide insight into unobserved outcomes.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 由Michael McCourt撰写的博客文章“高斯过程的直觉”，链接为[https://sigopt.com/blog/intuition-behind-gaussian-processes/](https://sigopt.com/blog/intuition-behind-gaussian-processes/)，对为什么贝叶斯优化算法可以在不检查搜索空间中每个可能值的情况下找到最佳超参数集给出了出色的解释。在某些设置中，我们观察到的实验是独立的，例如抛硬币50次；对其中一个的了解并不意味着对其他也了解。但是，幸运的是，许多设置具有更有帮助的结构，从先前的观察中可以提供对未观察到的结果的洞察。
- en: In the machine learning context, we assume there is some relationship between
    historical experiment (training trial) results and future experiment results.
    More specifically, we believe there is a math model for this relationship. Although
    using the Bayesian approach—for example, in the Gaussian process—to model this
    relationship is a very strong assumption, we are given great power to make provable
    optimal predictions. A side bonus is we now have a way to handle the uncertainty
    of the model prediction result.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习背景下，我们假设历史实验（训练试验）结果和未来实验结果之间存在某种关系。更具体地说，我们相信存在一个描述这种关系的数学模型。尽管使用贝叶斯方法——例如，高斯过程——来建模这种关系是一个非常强的假设，但我们获得了强大的能力来进行可证明的最优预测。一个额外的优势是我们现在有了一种处理模型预测结果不确定性的方法。
- en: Note If you are interested in applying Bayesian optimization to deep learning
    projects, Quan Nguyen’s book *Bayesian Optimization in Action* (Manning, 2022;
    [https://www.manning.com/books/bayesian-optimization-in-action](https://www.manning.com/books/bayesian-optimization-in-action))
    is a good resource.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您对将贝叶斯优化应用于深度学习项目感兴趣，Quan Nguyen的书籍《贝叶斯优化实战》（Manning，2022；[https://www.manning.com/books/bayesian-optimization-in-action](https://www.manning.com/books/bayesian-optimization-in-action)）是一个很好的资源。
- en: Which HPO algorithm works the best?
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 哪种HPO算法效果最好？
- en: No single HPO algorithm works best. Different optimization algorithms may fit
    different tuning tasks under different constraints. Some of those variables might
    include how the search space looks (e.g., hyperparameter types, value ranges),
    how the trial budget looks, and what the goal is (eventual optimality or optimal
    anytime performance). Figure 5.6 shows an HPO algorithm selection guideline from
    the Optuna ([https://optuna.org/](https://optuna.org/)) HPO framework.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 没有单一的HPO算法效果最好。不同的优化算法可能在不同的约束条件下适合不同的调整任务。这些变量可能包括搜索空间的外观（例如，超参数类型、值范围）、试验预算的外观以及目标是什么（最终最优性或最优任意性能）。图5.6展示了Optuna
    ([https://optuna.org/](https://optuna.org/)) HPO框架的HPO算法选择指南。
- en: '![](../Images/05-06.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-06.png)'
- en: Figure 5.6 A HPO algorithm selection cheat sheet from the Optuna HPO framework
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 Optuna HPO框架的HPO算法选择速查表
- en: 'In figure 5.6, we see a decision graph for when to use the following three
    HPO algorithms: Gaussian process, TPE, and CMA-ES. Because HPO is a fast-developing
    field, new efficient algorithms can be published at any time, so algorithm selection
    cheat sheets like this will quickly become outdated. For example, FLAML ([https://github.com/microsoft/FLAML](https://github.com/microsoft/FLAML))
    is a newly developed Python HPO library that checks the hyperparameter correlation
    during the HPO process; it is definitely worth a try. So please check with your
    data science team for the latest HPO algorithm selection guideline.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在图5.6中，我们看到一个用于决定何时使用以下三个HPO算法（高斯过程、TPE和CMA-ES）的决策图。因为HPO是一个快速发展的领域，新的高效算法可以随时发布，所以这样的算法选择速查表会很快过时。例如，FLAML
    ([https://github.com/microsoft/FLAML](https://github.com/microsoft/FLAML)) 是一个新开发的Python
    HPO库，它在HPO过程中检查超参数相关性；它绝对值得一试。所以请咨询您的数据科学团队以获取最新的HPO算法选择指南。
- en: Note The HPO algorithm is not the primary focus of HPO engineering. The math
    behind the HPO algorithm can be intimidating, but luckily, it is not the engineer’s
    focus. Normally, it’s the data scientist’s job to determine which HPO algorithm
    to use for a certain training job. As engineers, our role is to build a flexible,
    extensible, black-box–fashion HPO system, so data scientists can run their model
    training code with arbitrary HPO algorithms easily.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：HPO算法不是HPO工程的主要焦点。HPO算法背后的数学可能令人畏惧，但幸运的是，这不是工程师的关注点。通常，数据科学家的工作是确定针对某个训练任务使用哪种HPO算法。作为工程师，我们的角色是构建一个灵活、可扩展的、黑盒式的HPO系统，以便数据科学家可以轻松地使用任意的HPO算法运行他们的模型训练代码。
- en: 5.2.3 Common automatic HPO approaches
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.3 常见的自动HPO方法
- en: 'Fortunately, many mature frameworks and systems already exist today for conducting
    HPO. Depending on the usage, they fall into two different categories: the HPO
    library approach and the HPO service approach. Figure 5.7 illustrates the two
    approaches. Let’s now discuss them one by one.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，今天已经存在许多成熟的框架和系统用于执行HPO。根据使用情况，它们可以分为两类：HPO库方法和HPO服务方法。图5.7展示了这两种方法。现在让我们逐一讨论它们。
- en: HPO library approach
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: HPO库方法
- en: In figure 5.7 (a), the library approach, we see that data scientists manage
    the HPO process themselves, from coding to execution. They code the entire HPO
    flow by using an HPO library, such as Hyperopt—an open source Python HPO library—and
    integrate it with the training code together in one training application. Next,
    data scientists run this application on their local machine or on the servers
    to which they have direct access. The HPO library inside the application will
    execute the HPO workflow that we see in figure 5.3.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在图5.7（a）的库方法中，我们看到数据科学家自己管理HPO流程，从编码到执行。他们使用HPO库（如Hyperopt——一个开源的Python HPO库）编写整个HPO流程，并将其与训练代码一起集成在一个训练应用程序中。接下来，数据科学家在他们的本地机器或他们可以直接访问的服务器上运行此应用程序。应用程序内的HPO库将执行我们在图5.3中看到的HPO工作流程。
- en: '![](../Images/05-07.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-07.png)'
- en: 'Figure 5.7 Two different HPO approaches: library vs. service. (a) HPO libraries
    can run HPO experiments (training) on a local machine or a group of servers with
    preconfiguration; (b) HPO service can run HPO experiments in a fully remote and
    automatic fashion.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 两种不同的HPO方法：库与服务。（a）HPO库可以在本地机器或预配置的一组服务器上运行HPO实验（训练）；（b）HPO服务可以以完全远程和自动的方式运行HPO实验。
- en: Flexibility and agility are the biggest advantages of the library approach;
    you can choose any HPO algorithm/libraries you like, integrate them into your
    training code, and start the HPO process right away because everything (training
    plus hyperparameter calculation) happens on your local machine. Some HPO libraries—for
    example, Ray Tune (section 5.4.3)—also support parallel distributed execution
    but not in a fully automatic manner. This requires setting up a distributed computing
    group with specific software that allows cross-machine communication, and it also
    requires manually kicking off the parallel process on each server.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 灵活性和敏捷性是库方法最大的优点；你可以选择你喜欢的任何HPO算法/库，将其集成到你的训练代码中，并立即开始HPO流程，因为所有事情（训练加上超参数计算）都发生在你的本地机器上。一些HPO库（例如，Ray
    Tune（第5.4.3节））也支持并行分布式执行，但不是完全自动的。这需要设置一个具有跨机通信特定软件的分布式计算组，并且还需要在每台服务器上手动启动并行过程。
- en: The biggest challenges for the library approach are scalability, reusability,
    and stability. HPO requires lots of compute resources to execute its trials, so
    a single server is often not capable of HPO. Even with the distributed functionality,
    it still can’t scale. Imagine we want to use 20 servers for an HPO task that requires
    10,000 trial runs; we need to manually set up the HPO process on 20 servers and
    redo the setup every time the training or HPO code changes. Also, if 1 of the
    20 parallel workers fails, the entire HPO work group comes to a halt. To address
    these problems, the HPO service approach is introduced.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图书馆方法面临的最大挑战是可扩展性、可重用性和稳定性。HPO需要大量的计算资源来执行其试验，因此单个服务器通常无法胜任HPO。即使有分布式功能，它仍然无法扩展。想象一下，如果我们想为需要10,000次试验运行的HPO任务使用20台服务器；我们需要在20台服务器上手动设置HPO流程，并且每次训练或HPO代码更改时都需要重新设置。此外，如果20个并行工作者中的任何一个失败，整个HPO工作组都会停止。为了解决这些问题，引入了HPO服务方法。
- en: HPO service approach
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: HPO服务方法
- en: Now let’s take a closer look at the HPO service approach; we repeat figure 5.7
    for clarity, presented here as figure 5.8\. In figure 5.8 (b), the service approach,
    we see that the HPO happens in a remote compute cluster, managed by a service—the
    HPO service. A data scientist only provides training code and a selected HPO algorithm
    configuration to the service and starts the HPO job. The service manages both
    compute resource allocation and the HPO workflow (figure 5.3) execution; it tracks
    each trial’s result (model performance metric, such as accuracy) and returns the
    final optimal hyperparameters to the data scientist when all trials are complete.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们更详细地看看HPO服务方法；为了清晰起见，我们重复图5.7，这里展示为图5.8。在图5.8（b）的服务方法中，我们看到HPO在一个由服务——HPO服务管理的远程计算集群中发生。数据科学家只需向服务提供训练代码和选定的HPO算法配置，然后启动HPO作业。服务管理计算资源分配和HPO工作流程（图5.3）的执行；它跟踪每个试验的结果（如准确率等模型性能指标），并在所有试验完成后将最终最优超参数返回给数据科学家。
- en: '![](../Images/05-08.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-08.png)'
- en: 'Figure 5.8 Two different HPO approaches: library vs. service'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 两种不同的HPO方法：库与服务
- en: The service approach provides a real black-box experience. Data scientists don’t
    need to worry about managing their own servers, setting up trial workers, and
    learning how to modify training code to work with different HPO algorithms. The
    HPO service takes care of all of these tasks. As the HPO service user, we just
    pass parameters into the service, and then the service runs the HPO automatically
    and returns the optimal hyperparameters at the end. The service also takes care
    of autoscaling and failure recovery of failed trial jobs. Because of these advantages,
    the service approach is now the dominant HPO approach in the deep learning production
    environment. Because you are now familiar with HPO concepts and approaches, let’s
    look at how to design an HPO service and how to use HPO libraries in the next
    two sections.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 服务方法提供了一种真正的黑盒体验。数据科学家无需担心管理自己的服务器、设置试验工作者以及学习如何修改训练代码以与不同的 HPO 算法协同工作。HPO 服务负责所有这些任务。作为
    HPO 服务的用户，我们只需将参数传递给服务，然后服务会自动运行 HPO 并在最后返回最优的超参数。服务还会处理失败试验作业的自动扩展和故障恢复。由于这些优势，服务方法现在是深度学习生产环境中占主导地位的
    HPO 方法。由于你现在已经熟悉了 HPO 概念和方法，让我们看看如何设计 HPO 服务以及如何在下一节中使用 HPO 库。
- en: Note HPO is *not* a one-time job. If training with a different dataset, you
    need to redo the HPO even if the model architecture didn’t change. If the dataset
    changes, the optimal set model weights that fit best with the given data change
    as well, so you need a new HPO searching effort.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：HPO 并非一次性工作。如果使用不同的数据集进行训练，即使模型架构没有改变，也需要重新进行 HPO。如果数据集发生变化，与给定数据最匹配的最优模型权重也会发生变化，因此你需要进行新的
    HPO 搜索工作。
- en: 5.3 Designing an HPO service
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 设计 HPO 服务
- en: Now that you have a good understanding of the HPO library approach, let’s review
    the HPO service approach. In this section, we will look at how to design an HPO
    service to support HPO for arbitrary model training in an automatic and black-box
    fashion.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经很好地理解了 HPO 库方法，让我们回顾一下 HPO 服务方法。在本节中，我们将探讨如何设计一个 HPO 服务以自动且黑盒方式支持任意模型训练的
    HPO。
- en: 5.3.1 HPO design principles
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 HPO 设计原则
- en: Before we look at the concrete design proposal, let’s first check out the five
    design principles for building an HPO service.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看具体的设计提案之前，让我们首先了解一下构建 HPO 服务的设计原则。
- en: 'Principle 1: Training code agnostic'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 原则 1：训练代码无关
- en: The HPO service needs to be agnostic to training code and model training frameworks.
    In addition to supporting arbitrary machine learning frameworks like TensorFlow,
    PyTorch, and MPI, we would like the service to be able to tune hyperparameters
    of training code written in any programming language.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: HPO 服务需要对训练代码和模型训练框架无关。除了支持 TensorFlow、PyTorch 和 MPI 等任意机器学习框架外，我们希望服务能够调整用任何编程语言编写的训练代码的超参数。
- en: 'Principle 2: Extensibility and consistency in supporting different HPO algorithms'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 原则 2：支持不同 HPO 算法的可扩展性和一致性
- en: From the HPO algorithms discussion in section 5.2.2, we know the hyperparameters
    search algorithm is the brain of the HPO process. The efficiency of the hyperparameter
    search decides the HPO performance. A good HPO algorithm can find optimal hyperparameters
    with a large hyperparameter number and arbitrary search spaces in a small number
    of trials.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从 5.2.2 节中关于 HPO 算法的讨论中，我们知道超参数搜索算法是 HPO 过程的大脑。超参数搜索的效率决定了 HPO 的性能。一个好的 HPO
    算法可以在少量试验中找到具有大量超参数和任意搜索空间的最优超参数。
- en: Because HPO algorithm research is an active field, a new effective algorithm
    is published every few months. Our HPO service needs to integrate with these new
    algorithms easily and expose them as algorithm options to customers (data scientists).
    Also, the newly added algorithm should behave consistently with the existing algorithms
    in terms of user experience.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 HPO 算法研究是一个活跃的领域，每几个月就会发表一个新的有效算法。我们的 HPO 服务需要能够轻松地集成这些新算法，并将它们作为算法选项向客户（数据科学家）展示。此外，新添加的算法在用户体验方面应与现有算法保持一致。
- en: 'Principle 3: Scalability and fault tolerance'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 原则 3：可扩展性和容错性
- en: Besides HPO algorithms, another important responsibility of an HPO service is
    to manage the computing resources used for HPO—the model training with various
    hyperparameter values. From an HPO experiment perspective, we want distributed
    execution at both the experiment level and trial level. More specifically, we
    want to not only run trials in a distributed and parallel manner but also be able
    to run a single training trial distributedly—for example, running distributed
    training for the model training in one trial. From a resource utilization perspective,
    the system needs to support autoscaling, which allows the compute cluster size
    to be automatically adjusted to the current workload, so there is no under- or
    overutilization of resources.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 除了HPO算法之外，HPO服务的另一个重要责任是管理用于HPO的计算资源——具有各种超参数值的模型训练。从HPO实验的角度来看，我们希望在实验级和试验级都实现分布式执行。更具体地说，我们不仅希望以分布式和并行的方式运行试验，还希望能够以分布式的方式运行单个训练试验——例如，在一个试验中对模型训练进行分布式训练。从资源利用的角度来看，系统需要支持自动扩展，这允许计算集群的大小自动调整到当前的工作负载，从而避免资源的过度或不足利用。
- en: Fault tolerance is also another important aspect of HPO trial execution management.
    Fault tolerance is important because some HPO algorithms are required to execute
    trials sequentially. For example, trial 2 must happen after trial 1 because the
    algorithm needs the past hyperparameter values and results to deduce the hyperparameters
    before the next trial starts. In this case, when one trial fails unexpectedly—for
    example, because of a node restart or a network problem—the entire HPO process
    fails. The system should recover from the previous failure automatically. The
    common approach is to record the latest state of each trial, so we can resume
    from the last recorded checkpoint.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 容错性也是HPO试验执行管理的重要方面之一。容错性之所以重要，是因为某些HPO算法需要按顺序执行试验。例如，试验2必须在试验1之后进行，因为算法需要过去的超参数值和结果来推断下一个试验开始前的超参数。在这种情况下，当某个试验意外失败时——例如，由于节点重启或网络问题——整个HPO过程就会失败。系统应该能够自动从之前的失败中恢复。常见的做法是记录每个试验的最新状态，这样我们就可以从最后一个记录的检查点恢复。
- en: 'Principle 4: Multitenancy'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 原则4：多租户
- en: An HPO process is essentially a set of model training executions. Similar to
    model training, HPO services must provide resource isolation for various users
    or groups. This will ensure that different user activities stay within their boundaries.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: HPO过程本质上是一系列模型训练执行。与模型训练类似，HPO服务必须为不同的用户或组提供资源隔离。这将确保不同的用户活动保持在各自的边界内。
- en: 'Principle 5: Portability'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 原则5：可移植性
- en: Nowadays, the concept of “cloud neutral” has become very popular. People want
    to run their model training job in different environments—Amazon Web Services,
    Google Cloud Platform, and Azure—so the HPO service we build needs to decouple
    from the underlying infrastructure. Running HPO service on Kubernetes is a good
    choice here.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，“云中立”的概念已经变得非常流行。人们希望在不同的环境中运行他们的模型训练作业——亚马逊网络服务、谷歌云平台和Azure——因此我们构建的HPO服务需要与底层基础设施解耦。在Kubernetes上运行HPO服务是一个不错的选择。
- en: 5.3.2 A general HPO service design
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 一般HPO服务设计
- en: 'Because the HPO workflow (figure 5.3) is quite standard and there are not many
    variations, the HPO service system design (figure 5.9) can be applied to most
    of the HPO scenarios. It consists of three main components: an API interface,
    HPO job manager, and hyperparameter (HP) suggestion maker. (They are marked as
    A, B, and C in figure 5.9.)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 由于HPO工作流（图5.3）相当标准，并且变化不多，因此HPO服务系统设计（图5.9）可以应用于大多数HPO场景。它由三个主要组件组成：API接口、HPO作业管理器和超参数（HP）建议生成器。（它们在图5.9中标记为A、B和C。）
- en: '![](../Images/05-09.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-09.png)'
- en: Figure 5.9 A general system design of an HPO service
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9 HPO服务的一般系统设计
- en: The API interface (component A) is the entrance point for users to submit HPO
    jobs. To start an HPO experiment, users submit an API request (step 1) to the
    interface; the request provides model training code, such as a Docker image; hyperparameters
    and their search space; and an HPO algorithm.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: API接口（组件A）是用户提交HPO作业的入口点。要启动HPO实验，用户需要向接口提交API请求（步骤1）；请求提供模型训练代码，例如Docker镜像；超参数及其搜索空间；以及HPO算法。
- en: The HP suggestion maker (component C) is a wrapper/adapter for different HPO
    algorithms. It provides a unified interface for users to run each different HPO
    algorithm, so users can select an algorithm without worrying about the execution
    details. To add a new HPO algorithm, it must be registered in this suggestion-maker
    component to become an algorithm option for users.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: HP建议生成器（组件C）是不同HPO算法的包装器/适配器。它为用户提供了一个统一的接口来运行每个不同的HPO算法，因此用户可以选择算法而无需担心执行细节。要添加新的HPO算法，它必须在此建议生成器组件中注册，以便成为用户的算法选项。
- en: The HPO job manager (component B) is the core component of the HPO service;
    it manages the HPO experiments for customer requests. For each HPO request, the
    job manager starts an HPO trial loop (step 2). Within the loop, it first calls
    the HP suggestion maker to obtain a set of suggested hyperparameter values (step
    2.a) and then creates a trial to run model training with these hyperparameter
    values (steps 2.b and 2.c).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: HPO作业管理器（组件B）是HPO服务的核心组件；它管理客户请求的HPO实验。对于每个HPO请求，作业管理器启动一个HPO试验循环（步骤2）。在循环中，它首先调用HP建议生成器以获得一组建议的超参数值（步骤2.a），然后创建一个试验来使用这些超参数值运行模型训练（步骤2.b和2.c）。
- en: 'For each training trial, the HPO job manager creates a trial object. This object
    has two responsibilities: first, it collects the output of a trial execution,
    such as the training progress, model metrics, model accuracy, and tried hyperparameters;
    second, it manages the training process. It handles the training process launching,
    distributed training setup, and failure recovery.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个训练试验，HPO作业管理器创建一个试验对象。此对象有两个职责：首先，它收集试验执行的输出，例如训练进度、模型指标、模型准确率和尝试过的超参数；其次，它管理训练过程。它处理训练过程启动、分布式训练设置和故障恢复。
- en: HPO service end-to-end execution workflow
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: HPO服务端到端执行工作流程
- en: Let’s walk through the end-to-end user workflow, as shown in figure 5.9\. For
    your convenience, we repeat figure 5.9, shown here as figure 5.10.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步了解端到端用户工作流程，如图5.9所示。为了方便起见，我们在此重复图5.9，此处作为图5.10。
- en: '![](../Images/05-10.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-10.png)'
- en: Figure 5.10 A general system design of an HPO service
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.10 HPO服务的一般系统设计
- en: First, the user submits an HPO request to the API interface (step 1). The request
    defines the training code, a list of hyperparameters and their value search space,
    the training objective, and an HPO algorithm. Then, the HPO job manager starts
    an HPO trial loop for this request (step 2). This loop launches a set of trials
    to determine which set of hyperparameter values works the best. In the end, when
    the trial budgets run out or one trial meets the training objective, the trial
    loop breaks, and the best hyperparameters are returned (step 3).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，用户向API接口提交HPO请求（步骤1）。请求定义了训练代码、一组超参数及其值搜索空间、训练目标和HPO算法。然后，HPO作业管理器为该请求启动HPO试验循环（步骤2）。此循环启动一系列试验以确定哪组超参数值效果最佳。最后，当试验预算耗尽或某个试验达到训练目标时，试验循环终止，并返回最佳超参数（步骤3）。
- en: Within a trial loop, the job manager first queries the HP suggestion maker to
    recommend hyperparameter candidates (step 2.a). The suggestion maker will run
    the selected HPO algorithm to calculate a set of hyperparameter values and return
    it to the job manager (step 2.b). The job manager then creates a trial object
    that launches a model training process with the suggested hyperparameter values
    (step 2.c). The trial object will also monitor the training process and continue
    reporting training metrics to the trial history database until the training completes
    (step 2.d). When the job manager notices the current trial is complete, it pulls
    the trial history (trial metrics and hyperparameter values used in past trials)
    and passes it to the HP suggestion maker to obtain a new set of HP candidates
    (step 2.e).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在试验循环中，作业管理器首先查询HP建议生成器以推荐超参数候选值（步骤2.a）。建议生成器将运行选定的HPO算法来计算一组超参数值并将其返回给作业管理器（步骤2.b）。然后，作业管理器创建一个试验对象，使用建议的超参数值启动模型训练过程（步骤2.c）。试验对象还将监控训练过程，并在训练完成后继续向试验历史数据库报告训练指标（步骤2.d）。当作业管理器注意到当前试验已完成时，它将拉取试验历史（过去试验中使用的试验指标和超参数值）并将其传递给HP建议生成器以获得一组新的HP候选值（步骤2.e）。
- en: Because the HPO use cases are quite standard and generic and there are already
    multiple open source HPO projects that work out of the box, we think it’s better
    to learn how to use them instead of rebuilding a new system that has no added
    value. So in appendix C, we will introduce you to a powerful and highly portable
    Kubernetes-based HPO service—Kubeflow Katib.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 由于HPO用例相当标准和通用，并且已经有多个开箱即用的开源HPO项目，我们认为学习如何使用它们而不是重建一个没有额外价值的新系统会更好。因此，在附录C中，我们将向您介绍一个强大且高度可移植的基于Kubernetes的HPO服务——Kubeflow
    Katib。
- en: 5.4 Open source HPO libraries
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 开源HPO库
- en: The HPO service might seem like too much overhead for a small data scientist
    team, especially if all their models are trained on a few servers they manage
    themselves. In this case, using HPO libraries to optimize model training in local
    machines or managed clusters (small scale, 1–10 servers) is a better option.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个小型数据科学家团队来说，HPO服务可能显得有些开销过大，尤其是如果他们所有的模型都是在他们自己管理的几台服务器上训练的话。在这种情况下，使用HPO库在本地机器或管理的集群（小规模，1-10台服务器）中优化模型训练是一个更好的选择。
- en: 'In this section, we will introduce three useful HPO open source libraries:
    Optuna, Hyperopt, and Ray Tune. They all run as HPO libraries, and they are easy
    to learn and simple to use. Because Optuna, Hyperopt, and Ray Tune all have clear
    onboarding docs and suitable examples, we will focus on the general overview and
    feature introduction so you can decide which one to use based on your own circumstances.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍三个有用的HPO开源库：Optuna、Hyperopt和Ray Tune。它们都作为HPO库运行，易于学习和使用。由于Optuna、Hyperopt和Ray
    Tune都有清晰的入门文档和合适的示例，我们将重点关注概述和功能介绍，以便您可以根据自己的情况决定使用哪一个。
- en: In the following discussion about different HPO libraries, especially in the
    “How to Use” sections, you will see the term *objective function* a lot. What
    is an objective function? Figure 5.11 demonstrates the process.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下关于不同HPO库的讨论中，尤其是在“如何使用”部分，您会经常看到“目标函数”这个术语。什么是目标函数？图5.11展示了这个过程。
- en: For an HPO algorithm, such as Bayesian search, to generate a hyperparameter
    suggestion so that the next trial works better, it needs to know how well the
    previous HPO trial operated. Therefore, the HPO algorithm requires that we define
    a function to score each training trial and continue minimizing or maximizing
    the return value of the function (score) in the subsequent trials. We named this
    the objective function.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于HPO算法，如贝叶斯搜索，为了生成超参数建议，以便下一个试验表现更好，它需要知道先前的HPO试验运行得有多好。因此，HPO算法要求我们定义一个函数来评分每个训练试验，并在后续试验中继续最小化或最大化该函数（评分）的返回值。我们将其命名为目标函数。
- en: In figure 5.11, we see that an objective function receives hyperparameters as
    input and returns a float value, or score. The objective function executes the
    model training with given hyperparameters and evaluates the output model when
    the training completes.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在图5.11中，我们看到目标函数接收超参数作为输入并返回一个浮点值或分数。目标函数使用给定的超参数执行模型训练，并在训练完成后评估输出模型。
- en: '![](../Images/05-11.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-11.png)'
- en: Figure 5.11 An objective function receives the hyperparameters as input and
    returns a score.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11 目标函数接收超参数作为输入并返回一个分数。
- en: 5.4.1 Hyperopt
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 Hyperopt
- en: Hyperopt ([http://hyperopt.github.io/hyperopt/#getting-started](http://hyperopt.github.io/hyperopt/#getting-started))
    is a lightweight and easy-to-use Python library for serial and parallel HPO. Random
    search, TPE, and adaptive TPE are the three HPO algorithms implemented in Hyperopt.
    Bayesian optimization algorithms (based on Gaussian processes) and regression
    trees have been designed to accommodate but were not yet implemented at the time
    this book was written.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Hyperopt ([http://hyperopt.github.io/hyperopt/#getting-started](http://hyperopt.github.io/hyperopt/#getting-started))
    是一个轻量级且易于使用的Python库，用于序列和并行HPO。Hyperopt实现了三种HPO算法：随机搜索、TPE和自适应TPE。基于高斯过程的贝叶斯优化算法和回归树已被设计出来，但截至本书编写时尚未实现。
- en: How to use
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用
- en: Let’s say you want to know which classifiers work best for your deep learning
    case. We can use Hyperopt to obtain the answer in three steps.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您想知道哪些分类器最适合您的深度学习案例。我们可以通过Hyperopt在三个步骤中获取答案。
- en: First, we create an objective function that is basically a wrapper function
    of the actual training code but reads the hyperparameter values from the `args`
    variable. Second, we define search space for the selected hyperparameter. Third,
    we choose an HPO algorithm, which selects hyperparameter values from the search
    space and passes them to the objective function to start the optimization process.
    Listing 5.1 implements this scenario.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个目标函数，它基本上是实际训练代码的包装函数，但读取`args`变量中的超参数值。其次，我们为选定的超参数定义搜索空间。第三，我们选择一个HPO算法，它从搜索空间中选择超参数值并将它们传递给目标函数以启动优化过程。列表5.1实现了这一场景。
- en: 'In this example, we want to determine which classifier leads to the best model
    accuracy, so we choose to optimize the `classifier_type` hyperparameter among
    three candidates: `naive_bayes`, `svm`, and `dtree`. You may also notice that
    each classifier has its own value search space, such as `hp.lognormal(''svm_rbf_width'',`
    `0,` `1)` for the `svm` classifier. In the `fmin` function (in step 3), we specify
    TPE as the HPO algorithm with 10 max trials and pass in the objective function
    and search space as the required parameters.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们想要确定哪种分类器能导致最佳模型准确率，所以我们选择在三个候选者中优化`classifier_type`超参数：`naive_bayes`、`svm`和`dtree`。你也许还会注意到每个分类器都有自己的值搜索空间，例如`svm`分类器的`hp.lognormal('svm_rbf_width',
    0, 1)`。在`fmin`函数（在第3步中），我们指定TPE作为HPO算法，最大试验次数为10，并将目标函数和搜索空间作为必需的参数传入。
- en: Listing 5.1 Getting started with Hyperopt
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.1 Hyperopt入门
- en: '[PRE0]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Trains the model with the passed in hyperparameters and evaluates the result
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用传递的超参数训练模型并评估结果
- en: ❷ Declares three classifier candidates
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 声明三个分类器候选者
- en: ❸ Defines search space for the parameters of the SVM classifier
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义了SVM分类器参数的搜索空间
- en: ❹ The fmin function minimizes the objective over the space with the selected
    algorithm.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ fmin函数通过选定的算法在空间上最小化目标函数。
- en: Parallelization
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化
- en: 'Although Hyperopt is a standalone library, we can run it parallelly in a cluster
    of machines. The basic idea is to run Hyperopt workers on different machines and
    let them talk to a central database for coordination. Hyperopt can also use Spark
    computing to run HPO parallelly. You can check out the following two articles
    for more details: “On Using Hyperopt: Advanced Machine Learning,” by Tanay Agrawal
    ([http://mng.bz/PxwR](http://mng.bz/PxwR)) and “Scaling Out Search with Apache
    Spark” ([http://hyperopt.github.io/hyperopt/scaleout/spark/](http://hyperopt.github.io/hyperopt/scaleout/spark/)).'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Hyperopt是一个独立的库，但我们可以在机器集群中并行运行它。基本思路是在不同的机器上运行Hyperopt工作进程，并让他们与一个中央数据库进行协调。Hyperopt还可以使用Spark计算来并行运行HPO。你可以查看以下两篇文章以获取更多详细信息：“使用Hyperopt：高级机器学习”由Tanay
    Agrawal撰写([http://mng.bz/PxwR](http://mng.bz/PxwR))和“使用Apache Spark扩展搜索”([http://hyperopt.github.io/hyperopt/scaleout/spark/](http://hyperopt.github.io/hyperopt/scaleout/spark/))。
- en: When to use
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 何时使用
- en: Hyperopt is a good option for small or early-phase model training projects.
    First, it’s easy to use. You can run HPO in three steps on a local machine or
    on servers to which you have direct access. Second, it’s friendly to modification.
    Because it takes a library approach, the HPO code is placed with training code
    in the same code project. So, trying different optimization plans, such as choosing
    various hyperparameters to tune, is very convenient.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Hyperopt是小型或早期阶段模型训练项目的良好选择。首先，它易于使用。你可以在本地机器或直接访问的服务器上分三步运行HPO。其次，它对修改友好。因为它采用库方法，HPO代码与训练代码放在同一个代码项目中。因此，尝试不同的优化计划，例如选择不同的超参数进行调整，非常方便。
- en: 5.4.2 Optuna
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.2 Optuna
- en: Similar to Hyperopt, Optuna is also a lightweight Python library designed to
    automate hyperparameter searches. It supports large space search and early pruning
    on the unpromising trials, as well as parallelization on multiple threads or processes
    without modifying code.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 与Hyperopt类似，Optuna也是一个轻量级的Python库，旨在自动化超参数搜索。它支持大范围搜索，对无望的试验进行早期剪枝，以及在不修改代码的情况下在多个线程或进程上并行化。
- en: In our opinion, Optuna is an advanced version of Hyperopt, and its visualization
    capabilities are much better. By examining the interactions between parameters
    in a graph, the visualization in hyperparameter search gives you a lot of insight,
    so you can easily determine which parameters are more effective than others. Optuna’s
    visualization is beautiful and interactive.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们看来，Optuna 是 Hyperopt 的高级版本，其可视化能力要强得多。通过在图中检查参数之间的交互，超参数搜索的可视化能给你带来很多洞察，因此你可以轻松地确定哪些参数比其他参数更有效。Optuna
    的可视化既美观又交互性强。
- en: Optuna has another advantage over Hyperopt concerning its documentation. Optuna’s
    documentation is excellent. In addition to its detailed API doc and well-organized
    tutorials, it has well-maintained source code. If you look at its GitHub project
    issue section, you will find a very active and growing community, and great features
    and GitHub pull requests are still to come.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna 在文档方面相较于 Hyperopt 也有另一个优势。Optuna 的文档非常出色。除了其详细的 API 文档和有组织的教程外，它还有良好维护的源代码。如果你查看其
    GitHub 项目问题部分，你会找到一个非常活跃且不断发展的社区，以及更多精彩功能和 GitHub pull 请求即将到来。
- en: How to use
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用
- en: 'Listing 5.2 shows a quick three-step example of how to use Optuna: step 1,
    define the objective function; step 2, create a study object to represent the
    HPO process; and step 3, start the HPO process with a max trials quota.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.2 展示了如何使用 Optuna 的快速三步示例：第一步，定义目标函数；第二步，创建一个表示 HPO 过程的研究对象；第三步，以最大试验配额启动
    HPO 过程。
- en: Compared to Hyperopt, Optuna requires most of the HPO logic to be defined in
    the objective function. The general code pattern is as follows. First, define
    the search space and generate the hyperparameter values by `trial.suggest_xxx`
    function. Next, start the model training with the sampled hyperparameter values.
    Then run the evaluation method to calculate model performance and return the objective
    value. In the following example, the evaluation score is calculated by `mean_squared_error`.
    You can find more Optuna examples at [https://github.com/optuna/optuna-examples](https://github.com/optuna/optuna-examples).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Hyperopt 相比，Optuna 需要将大部分 HPO 逻辑定义在目标函数中。一般的代码模式如下。首先，定义搜索空间并通过 `trial.suggest_xxx`
    函数生成超参数值。接下来，使用采样到的超参数值开始模型训练。然后运行评估方法来计算模型性能并返回目标值。在下面的示例中，评估分数是通过 `mean_squared_error`
    计算的。你可以在 [https://github.com/optuna/optuna-examples](https://github.com/optuna/optuna-examples)
    找到更多 Optuna 示例。
- en: Listing 5.2 Getting started with Optuna
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.2 Optuna 入门
- en: '[PRE1]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Sets classifier candidates
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置分类器候选者
- en: ❷ Invokes suggest_XXX methods to generate the hyperparameters
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 调用 suggest_XXX 方法生成超参数
- en: ❸ Chooses max_depth in the range of 2 and 32
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在 2 和 32 的范围内选择 max_depth
- en: ❹ Runs model training with the Optuna regressor
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用 Optuna 回归器进行模型训练
- en: ❺ Sets mean square error as the objective value and links to the trial object
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将均方误差设置为目标值并链接到试验对象
- en: Parallelization
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化
- en: 'We can run distributed HPO on one machine or a cluster of machines with Optuna.
    The distributed execution setup is fairly simple and can be done in three steps:
    first, start a relational database server, such as MySQL; second, create a study
    with storage argument; and third, share the study among multiple nodes and processes.
    Compared to Hyperopt, Optuna’s distributed execution setup is simpler, and it
    can scale up from a single machine to multiple machines without code modifications.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 Optuna 在一台机器或机器集群上运行分布式 HPO。分布式执行设置相当简单，可以分三步完成：首先，启动一个关系数据库服务器，例如 MySQL；其次，使用存储参数创建一个研究；第三，在多个节点和进程间共享研究。与
    Hyperopt 相比，Optuna 的分布式执行设置更简单，并且可以从单机扩展到多机，无需代码修改。
- en: When to use
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 何时使用
- en: Optuna can be seen as the successor of Hyperopt; it has better documentation,
    visualization, and parallel execution. For any deep learning model training project
    that can run on one or more machines, you can use Optuna to find the optimal hyperparameters.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna 可以被视为 Hyperopt 的继任者；它具有更好的文档、可视化和并行执行。对于任何可以在一台或多台机器上运行的深度学习模型训练项目，你都可以使用
    Optuna 来寻找最佳超参数。
- en: Optuna will hit its limit with a large data science team or multiple HPO projects
    to support because it requires managing a central machine cluster to provide the
    computing resource. But Optuna’s parallel/distributed execution is manual; people
    need to distribute the code to each server and execute it one server at a time,
    manually. To manage distributed computing jobs in an automatic and programmatic
    fashion, we can use Kubeflow Katib (appendix C) or Ray Tune.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna在大型数据科学团队或多个HPO项目支持时将达到其限制，因为它需要管理一个中央机器集群以提供计算资源。但是Optuna的并行/分布式执行是手动的；人们需要将代码分发到每个服务器，并逐个服务器执行，手动。为了以自动和程序化的方式管理分布式计算作业，我们可以使用Kubeflow
    Katib（附录C）或Ray Tune。
- en: 5.4.3 Ray Tune
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.3 Ray Tune
- en: Ray ([https://docs.ray.io/en/latest/index.html](https://docs.ray.io/en/latest/index.html))
    provides a simple, universal API for building distributed applications. Ray Tune
    ([https://docs.ray.io/en/latest/tune/index.html](https://docs.ray.io/en/latest/tune/index.html))
    is a Python library built on top of Ray for HPO at any scale.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Ray ([https://docs.ray.io/en/latest/index.html](https://docs.ray.io/en/latest/index.html))
    提供了一个简单、通用的API，用于构建分布式应用程序。Ray Tune ([https://docs.ray.io/en/latest/tune/index.html](https://docs.ray.io/en/latest/tune/index.html))
    是一个基于Ray构建的Python库，用于任何规模的HPO。
- en: The Ray Tune library supports almost any machine learning framework, including
    PyTorch, XGBoost, MXNet, and Keras. It also supports state-of-the-art HPO algorithms
    such as Population Based Training (PBT), BayesOptSearch, and HyperBand/ ASHA.
    In addition, Tune provides a mechanism to integrate HPO algorithms from other
    HPO libraries, such as Hyperopt integration.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Ray Tune库支持几乎所有机器学习框架，包括PyTorch、XGBoost、MXNet和Keras。它还支持最先进的HPO算法，如基于群体的训练（PBT）、BayesOptSearch和HyperBand/
    ASHA。此外，Tune提供了一种机制来集成来自其他HPO库的HPO算法，例如Hyperopt集成。
- en: By using Ray as its distributed executing support, we can launch a multinode
    HPO experimentation in a few lines of code. Ray will take care of code distribution,
    distributed computing management, and fault tolerance.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用Ray作为其分布式执行支持，我们可以在几行代码中启动一个多节点HPO实验。Ray将负责代码分发、分布式计算管理和容错。
- en: How to use
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如何使用
- en: Using Ray Tune to execute an HPO task is very straightforward. First, define
    an objective function. In the function, read hyperparameter values from the `config`
    variable, start model training, and return the evaluation score. Second, define
    hyperparameters and their value search space. Third, start the HPO execution by
    linking the objective function and search space together. Listing 5.3 implements
    the aforementioned three steps.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Ray Tune执行HPO任务非常简单。首先，定义一个目标函数。在函数中，从`config`变量中读取超参数值，开始模型训练，并返回评估分数。其次，定义超参数及其值搜索空间。第三，通过将目标函数和搜索空间链接在一起来启动HPO执行。列表5.3实现了上述三个步骤。
- en: Listing 5.3 Getting started with Ray Tune
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.3 Ray Tune入门
- en: '[PRE2]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ ConvNet is a self-defined neural network.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ ConvNet是一个自定义的神经网络。
- en: ❷ Reads the hyperparameter value from the input config
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从输入配置中读取超参数值
- en: ❸ Starts model training
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 开始模型训练
- en: ❹ Sends the evaluation result (accuracy) back to Tune
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将评估结果（准确率）发送回Tune
- en: ❺ Samples a float value uniformly between 0.1 and 0.9 for "momentum"
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 为“动量”均匀采样0.1到0.9之间的浮点值
- en: You may notice a scheduler object, `ASHAScheduler``,` is passed to the `tune.run`
    function in step 3\. ASHA ([http://mng.bz/JlwZ](http://mng.bz/JlwZ)) is a scalable
    algorithm for principled early stopping (see “Massively Parallel Hyperparameter
    Optimization,” by Liam Li; [http://mng.bz/wPZ5](http://mng.bz/wPZ5)). At a high
    level, ASHA terminates trials that are less promising and allocates time and resources
    to more promising trials. By properly adjusting the parameter `num_samples`, the
    search can be much more efficient, and it can support a larger search space.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到在步骤3中将调度器对象`ASHAScheduler`传递给`tune.run`函数。ASHA ([http://mng.bz/JlwZ](http://mng.bz/JlwZ))
    是一种用于原则性早期停止的可扩展算法（参见Liam Li的“大规模并行超参数优化”，[http://mng.bz/wPZ5](http://mng.bz/wPZ5)）。从高层次来看，ASHA终止前景不佳的试验，并将时间和资源分配给更有前景的试验。通过适当调整参数`num_samples`，搜索可以更加高效，并且可以支持更大的搜索空间。
- en: Parallelization
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化
- en: Distributed execution is Ray Tune’s biggest advantage compared with Optuna.
    Ray Tune allows you to transparently parallelize across multiple GPUs and multiple
    nodes (see Ray documentation at [http://mng.bz/qdRx](http://mng.bz/qdRx)). Tune
    even has seamless fault tolerance and cloud support. Unlike Optuna and Hyperopt,
    we don’t need to manually set up a distributed environment and execute worker
    scripts one machine after another. Ray Tune takes care of these steps automatically.
    Figure 5.12 shows how Ray Tune distributes HPO Python code to a cluster of machines.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 与Optuna相比，分布式执行是Ray Tune的最大优势。Ray Tune允许你透明地跨多个GPU和多个节点并行化（参见[http://mng.bz/qdRx](http://mng.bz/qdRx)上的Ray文档）。Tune甚至具有无缝容错和云支持。与Optuna和Hyperopt不同，我们不需要手动设置分布式环境并逐台执行工作脚本。Ray
    Tune会自动处理这些步骤。图5.12显示了Ray Tune如何将HPO Python代码分发到机器集群。
- en: '![](../Images/05-12.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图5.12](../Images/05-12.png)'
- en: Figure 5.12 Ray Tune running distributed HPO on a cluster of machines
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.12 Ray Tune在机器集群上运行分布式HPO
- en: 'First, we set up a Ray cluster with the command `"ray` `up` `tune-cluster.yaml"`;
    the `tune-cluster.yaml` is a cluster configuration that declares the computing
    resources for the cluster. Then we run the following command to submit the HPO
    code from the local machine to the head node of the cluster: `"ray` `submit` `tune-cluster.yaml`
    `tune_ script.py` `--start` `--` `--ray-address={server_address}"`. Next, Ray
    assigns resources, copies the HPO code to the servers, and starts the distributed
    execution. For further details, please see “Tune Distributed Experiments” ([http://mng.bz/71QQ](http://mng.bz/71QQ)).'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用命令`"ray up tune-cluster.yaml"`设置一个Ray集群；`tune-cluster.yaml`是一个集群配置，它声明了集群的计算资源。然后，我们运行以下命令将HPO代码从本地机器提交到集群的头部节点：`"ray
    submit tune-cluster.yaml tune_script.py --start -- --ray-address={server_address}"`。接下来，Ray分配资源，将HPO代码复制到服务器，并开始分布式执行。有关更多详细信息，请参阅“Tune分布式实验”([http://mng.bz/71QQ](http://mng.bz/71QQ))。
- en: Besides distributed HPO execution, Ray Tune also supports running distributed
    training for single-trial, automatic checkpoint management and TensorBoard logging.
    These features add great value to Ray Tune for their high fault tolerance and
    simple troubleshooting.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分布式HPO执行外，Ray Tune还支持运行单个试验的分布式训练、自动检查点管理和TensorBoard日志记录。这些功能因其高容错性和简单的故障排除而极大地增加了Ray
    Tune的价值。
- en: When to use
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 何时使用
- en: Compared with other HPO libraries, is Ray Tune the way to go for HPO? Provisionally,
    yes. As this book is being written, Ray provides integration between the underlying
    training framework (such as TensorFlow and PyTorch) and the cutting-edge HPO algorithm
    (such as Bayesian search and TPE), as well as early stopping (ASHA). It allows
    us to run HPO searches distributedly in a straightforward and reliable manner.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他HPO库相比，Ray Tune是否是HPO的最佳选择？暂时来说，是的。在本书编写时，Ray提供了底层训练框架（如TensorFlow和PyTorch）与前沿HPO算法（如贝叶斯搜索和TPE）以及早期停止（ASHA）之间的集成。它允许我们以简单和可靠的方式分布式运行HPO搜索。
- en: 'For most of the data science team, who don’t want to own an HPO service, Ray
    Tune is the suggested approach. It’s simple to use, and it meets almost every
    model training project’s HPO requirement: great documents, cutting-edge HPO algorithms,
    and efficient and simple distributed execution management.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数不想拥有HPO服务的数据科学团队来说，Ray Tune是建议的方法。它使用简单，几乎满足每个模型训练项目的HPO要求：优秀的文档、前沿的HPO算法，以及高效且简单的分布式执行管理。
- en: 'Note We recommend using Ray Tune over other HPO libraries for the following
    five reasons: (1) it is simple to use; (2) it has great documents and examples;
    (3) its distributed execution is automatic and programmatic; (4) Ray Tune supports
    distributed training for a single trial; and (5) Ray Tune has a scheduler feature
    (for example, `ASHAScheduler`) that can greatly reduce computing cost by terminating
    unpromising trials earlier.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们推荐使用Ray Tune而不是其他HPO库，以下五个原因：（1）使用简单；（2）拥有优秀的文档和示例；（3）其分布式执行是自动和程序化的；（4）Ray
    Tune支持单个试验的分布式训练；（5）Ray Tune具有调度器功能（例如，`ASHAScheduler`），可以通过提前终止无望的试验来大大降低计算成本。
- en: The limitation of Ray Tune
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Ray Tune的限制
- en: Ray Tune and other HPO libraries will hit their limits when we need to support
    different teams and different deep learning projects in one shared HPO system.
    Ray Tune is missing computing isolation, which leads to two big problems.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要在一个共享的HPO系统中支持不同的团队和不同的深度学习项目时，Ray Tune和其他HPO库将触及它们的极限。Ray Tune缺少计算隔离，这导致了两个大问题。
- en: First, package versions of different training codes can cause conflicts between
    Ray workers. When performing distributed HPO in Ray Tune, we submit the HPO code
    to the Ray cluster’s head server and then run this code in the cluster workers
    in parallel. This means every Ray worker server needs to install the dependent
    libraries for every training code that it needs to run. Imagine how we manage
    the package installation and potential version conflicts when you have to run
    10 different HPO tasks in one Ray cluster; the worker machine needs to install
    hundreds of packages for these 10 different training codes and also resolve their
    version conflicts. Second, Ray Tune doesn’t enforce user segregation. It’s very
    difficult to build a virtual boundary in Ray Tune for different data science teams
    to limit their computing resource usage.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，不同训练代码的包版本可能在Ray工作节点之间引起冲突。当在Ray Tune中进行分布式HPO时，我们将HPO代码提交给Ray集群的头部服务器，然后在集群工作节点上并行运行此代码。这意味着每个Ray工作节点都需要安装它需要运行的每个训练代码的依赖库。想象一下，当您必须在单个Ray集群中运行10个不同的HPO任务时，我们如何管理包安装和潜在的版本冲突；工作节点需要为这10个不同的训练代码安装数百个包，并解决它们的版本冲突。其次，Ray
    Tune不强制执行用户隔离。在Ray Tune中为不同的数据科学团队建立虚拟边界以限制他们的计算资源使用是非常困难的。
- en: 5.4.4 Next steps
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.4 下一步
- en: When you encounter the aforementioned problems with HPO libraries, it’s time
    to switch to an HPO service. We strongly recommend you read appendix C before
    you consider building your own HPO. It introduces a solid open source HPO service
    called Kubeflow Katib, which is a well-designed, general-purpose HPO service.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 当您遇到上述HPO库的问题时，是时候切换到HPO服务了。我们强烈建议在考虑构建自己的HPO之前阅读附录C。它介绍了一个名为Kubeflow Katib的可靠开源HPO服务，这是一个设计良好的通用HPO服务。
- en: Summary
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A hyperparameter is a parameter whose value is used to control the learning
    process. This type of parameter is not learnable in model training; therefore,
    we need to tune it.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超参数是一个用于控制学习过程的参数。这种类型的参数在模型训练中是不可学习的；因此，我们需要对其进行调整。
- en: HPO is a process to discover a set of hyperparameters that yields an optimal
    model, which minimizes a predefined loss function on a given dataset.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HPO是一个发现一组超参数的过程，这些超参数能够产生最优模型，在给定的数据集上最小化预定义的损失函数。
- en: Automatic HPO is the process of using compute power and algorithms (HPO algorithms)
    to automatically find the optimal hyperparameters for a training code.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化HPO是使用计算能力和算法（HPO算法）自动寻找训练代码最佳超参数的过程。
- en: Automatic HPO now is a standard step for model training.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化超参数优化（HPO）现在已成为模型训练的标准步骤。
- en: 'Most HPO algorithms can be categorized into one of three buckets: model-free
    optimization, Bayesian optimization, or multifidelity optimization.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数HPO算法可以分为三类：无模型优化、贝叶斯优化或多保真优化。
- en: There is no single best HPO algorithm. Different optimization algorithms may
    fit different HPO tasks under different constraints.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有单一的最好HPO算法。不同的优化算法可能在不同的约束条件下适合不同的HPO任务。
- en: HPO can run with a library or in a remote service. The library approach is simple,
    flexible, and suitable for small teams and projects in the prototyping phase whereas
    the service approach is for large organizations and production use cases.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HPO可以与库或远程服务一起运行。库方法简单、灵活，适用于小型团队和原型设计阶段的项目，而服务方法适用于大型组织和生产用例。
- en: The HPO service approach provides a fully automatic black-box HPO experience,
    including computing resource management; therefore, we recommend taking a service
    approach if you are building a deep learning system for large teams.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HPO服务方法提供了一个完全自动的黑盒HPO体验，包括计算资源管理；因此，如果您正在为大型团队构建深度学习系统，我们建议采用服务方法。
- en: The five design principles for building an HPO service are training code agnostic,
    high extensibility, high scalability and reliability, HPO execution and resource
    consumption segregation, and high portability.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建HPO服务的五个设计原则是：训练代码无关性、高可扩展性、高可伸缩性和可靠性、HPO执行和资源消耗分离，以及高可移植性。
- en: To expedite an HPO experiment, we can parallelize training executions of different
    trials, introduce distributed training, and stop the unpromising trials early.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了加速HPO实验，我们可以并行化不同试验的训练执行，引入分布式训练，并提前停止没有希望的试验。
- en: We encourage you to adopt Kubeflow Katib as your HPO service instead of building
    a new service yourself.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们鼓励您采用Kubeflow Katib作为您的HPO服务，而不是自己构建新的服务。
- en: Among three commonly used open source HPO libraries—Optuma, Hyperopt, and Ray
    tune—Ray Tune has so far proven to be the best.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在三种常用的开源HPO库——Optuma、Hyperopt和Ray tune中——迄今为止，Ray Tune已被证明是最好的。
