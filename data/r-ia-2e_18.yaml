- en: 14 Principal components and factor analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 14 主成分分析与因子分析
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Principal components analysis
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主成分分析
- en: Exploratory factor analysis
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索性因子分析
- en: Understanding other latent variable models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解其他潜在变量模型
- en: One of the most challenging aspects of multivariate data is the sheer complexity
    of the information. If you have a dataset with 100 variables, how do you make
    sense of all the interrelationships present? Even with 20 variables, there are
    190 pairwise correlations to consider when you’re trying to understand how the
    individual variables relate to one another. Two related but distinct methodologies
    for exploring and simplifying complex multivariate data are principal components
    and exploratory factor analysis.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 多变量数据中最具挑战性的方面之一是信息的纯粹复杂性。如果你有一个包含 100 个变量的数据集，你如何理解所有存在的相互关系？即使有 20 个变量，当你试图理解各个变量之间的关系时，也需要考虑
    190 对相关系数。探索和简化复杂多变量数据的两种相关但不同的方法是主成分分析和探索性因子分析。
- en: '*Principal components analysis (PCA)* is a data-reduction technique that transforms
    a larger number of correlated variables into a much smaller set of uncorrelated
    variables called *principal components*. For example, you might use PCA to transform
    30 correlated (and possibly redundant) environmental variables into 5 uncorrelated
    composite variables that retain as much information from the original set of variables
    as possible.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*主成分分析 (PCA)* 是一种数据降维技术，它将大量相关变量转换成一组较小的、不相关的变量，称为 *主成分*。例如，你可能使用 PCA 将 30
    个相关（可能冗余）的环境变量转换成 5 个不相关的综合变量，尽可能保留原始变量集中的信息。'
- en: In contrast, *exploratory factor analysis (EFA)* is a collection of methods
    designed to uncover the latent structure in a given set of variables. It looks
    for a smaller set of underlying or *latent* variables that can explain the relationships
    among the observed or *manifest* variables. For example, the dataset `Harman74.cor`
    contains the correlations among 24 psychological tests given to 145 seventh- and
    eighth-grade children. If you apply EFA to this data, the results suggest that
    the 276 test intercorrelations can be explained by the children’s abilities on
    4 underlying factors (verbal ability, processing speed, deduction, and memory).
    The 24 psychological tests are the observed or manifest variables, and the four
    underlying factors or latent variables are derived from the correlations among
    these observed variables.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，*探索性因子分析 (EFA)* 是一套旨在揭示给定变量集中潜在结构的方法。它寻找一组较小的潜在或 *潜在* 变量，这些变量可以解释观测或 *显性*
    变量之间的关系。例如，数据集 `Harman74.cor` 包含了 145 名七年级和八年级儿童接受的 24 项心理测试之间的相关性。如果你对这份数据应用
    EFA，结果建议 276 个测试相关性可以由儿童在 4 个潜在因素（语言能力、处理速度、推理和记忆）上的能力来解释。这 24 项心理测试是观测或显性变量，而四个潜在因素或潜在变量是从这些观测变量的相关性中推导出来的。
- en: Figure 14.1 shows the differences between the PCA and EFA models. Principal
    components (PC1 and PC2) are linear combinations of the observed variables (X1
    to X5). The weights used to form the linear composites are chosen to maximize
    the variance each principal component accounts for, while keeping the components
    uncorrelated.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1 展示了 PCA 和 EFA 模型的差异。主成分（PC1 和 PC2）是观测变量（X1 到 X5）的线性组合。用于形成线性组合的权重被选择以最大化每个主成分所解释的方差，同时保持这些成分不相关。
- en: '![](Images/CH14_F01_Kabacoff3.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH14_F01_Kabacoff3.png)'
- en: Figure 14.1 Comparing the principal components and factor analysis models. The
    diagrams show the observed variables (X1 to X5), the principal components (PC1,
    PC2), factors (F1, F2), and errors (e1 to e5).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1 比较主成分分析和因子分析模型。图示显示了观测变量（X1 到 X5）、主成分（PC1、PC2）、因子（F1、F2）和误差（e1 到 e5）。
- en: In contrast, factors (F1 and F2) are assumed to underlie or “cause” the observed
    variables, rather than being linear combinations of them. The errors (e1 to e5)
    represent the variance in the observed variables that is unexplained by the factors.
    The circles indicate that the factors and errors aren’t directly observable but
    are inferred from the correlations among the variables. In this example, the curved
    arrow between the factors indicates that they’re correlated. Correlated factors
    are common, but not required, in the EFA model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，因素（F1和F2）被认为是观察变量的基础或“原因”，而不是它们的线性组合。误差（e1到e5）代表由因素未解释的观察变量的方差。圆圈表示因素和误差不是直接可观察的，而是从变量之间的相关性中推断出来的。在这个例子中，因素之间的弯曲箭头表示它们是相关的。在EFA模型中，相关因素是常见的，但不是必需的。
- en: The methods described in this chapter require large samples to derive stable
    solutions. What constitutes an adequate sample size is somewhat complicated. Until
    recently, analysts used rules of thumb like “factor analysis requires 5–10 times
    as many subjects as variables.” Recent studies suggest that the required sample
    size depends on the number of factors, the number of variables associated with
    each factor, and how well the set of factors explains the variance in the variables
    (Bandalos and Boehm-Kaufman, 2009). I’ll go out on a limb and say that if you
    have several hundred observations, you’re probably safe. In this chapter, we’ll
    look at artificially small problems to keep the output (and page count) manageable.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中描述的方法需要大量样本以推导出稳定的解。构成适当样本大小的问题有些复杂。直到最近，分析师使用诸如“因子分析需要比变量多5-10倍的主题”之类的经验法则。最近的研究表明，所需的样本大小取决于因素的个数、与每个因素相关的变量的个数以及因素集如何解释变量的方差（Bandalos和Boehm-Kaufman，2009）。我敢说，如果你有几百个观测值，你可能是安全的。在本章中，我们将研究人工小问题，以保持输出（和页数）可管理。
- en: We’ll start by reviewing the functions in R that can be used to perform PCA
    or EFA and give a brief overview of the steps involved. Then we’ll work carefully
    through two PCA examples, followed by an extended EFA example. A brief overview
    of other packages in R that can be used for fitting latent variable models is
    provided at the end of the chapter. This discussion includes packages for confirmatory
    factor analysis, structural equation modeling, correspondence analysis, and latent
    class analysis.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先回顾R中可用于执行PCA或EFA的函数，并简要概述涉及步骤。然后我们将仔细研究两个PCA示例，接着是一个扩展的EFA示例。本章末尾提供了R中可用于拟合潜在变量模型的其它包的简要概述。这次讨论包括用于验证性因子分析、结构方程建模、对应分析和潜在类别分析的包。
- en: 14.1 Principal components and factor analysis in R
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.1 R中的主成分分析和因子分析
- en: In the base installation of R, the functions for PCA and EFA are `princomp``()`
    and `factanal``()`, respectively. In this chapter, we’ll focus on functions provided
    in the `psych` package. They offer many more useful options than their base counterparts.
    Additionally, the results are reported in a metric that will be more familiar
    to social scientists and more likely to match the output provided by corresponding
    programs in other statistical packages such as SAS and IBM SPSS.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在R的基础安装中，PCA和EFA的函数分别是`princomp()`和`factanal()`。在本章中，我们将关注`psych`包中提供的函数。它们提供了比基础版本更多的有用选项。此外，结果将以社会科学家更熟悉的度量标准报告，更有可能与其他统计软件包（如SAS和IBM
    SPSS）中相应程序提供的输出相匹配。
- en: Table 14.1 lists the `psych` package functions that are most relevant. Be sure
    to install the package before trying the examples in this chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.1列出了与`psych`包最相关的函数。在尝试本章中的示例之前，请务必安装该包。
- en: Table 14.1 Useful factor analytic functions in the `psych` package
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.1 `psych`包中有用的因子分析函数
- en: '| Function | Description |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 函数 | 描述 |'
- en: '| `principal``()` | Principal components analysis with optional rotation |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| `principal()` | 带有可选旋转的主成分分析 |'
- en: '| `fa``()` | Factor analysis by principal axis, minimum residual, weighted
    least squares, or maximum likelihood |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| `fa()` | 通过主轴、最小残差、加权最小二乘或最大似然进行因子分析 |'
- en: '| `fa.parallel``()` | Scree plots with parallel analyses |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| `fa.parallel()` | 平行分析的光谱图 |'
- en: '| `factor.plot``()` | Plots the results of a factor or principal components
    analysis |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| `factor.plot()` | 绘制因子或主成分分析的结果 |'
- en: '| `fa.diagram``()` | Graphs factor or principal components loading matrices
    |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| `fa.diagram()` | 绘制因素或主成分加载矩阵的图形 |'
- en: '| `scree``()` | Scree plot for factor and principal components analysis |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| `scree``()` | 因子和主成分分析的 Scree 图 |'
- en: 'EFA (and to a lesser degree PCA) are often confusing to new users because they
    describe a wide range of approaches, and each approach requires several steps
    (and decisions) to achieve a final result. The most common steps are as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: EFA（以及在一定程度上 PCA）对于新用户来说常常令人困惑，因为它们描述了广泛的方法，每种方法都需要几个步骤（和决策）才能达到最终结果。最常见的步骤如下：
- en: Prepare the data. Both PCA and EFA derive their solutions from the correlations
    among the observed variables. You can input either the raw data matrix or the
    correlation matrix to the `principal``()` and `fa()` functions. If raw data is
    input, the correlation matrix is automatically calculated. Be sure to screen the
    data for missing values before proceeding. By default, the `psych` package uses
    pairwise deletion when calculating correlations.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备数据。PCA 和 EFA 都是从观测变量之间的相关性中推导出它们的解。你可以将原始数据矩阵或相关矩阵输入到 `principal``()` 和 `fa()`
    函数中。如果输入原始数据，相关矩阵将自动计算。在继续之前，务必筛选数据中的缺失值。默认情况下，`psych` 包在计算相关性时使用成对删除。
- en: Select a factor model. Decide whether PCA (data reduction) or EFA (uncovering
    latent structure) is a better fit for your research goals. If you select an EFA
    approach, you’ll also need to choose a specific factoring method (for example,
    maximum likelihood).
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个因子模型。决定 PCA（数据降维）或 EFA（揭示潜在结构）更适合你的研究目标。如果你选择 EFA 方法，你还需要选择一个特定的因子方法（例如，最大似然法）。
- en: Decide how many components/factors to extract.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决定提取多少个成分/因子。
- en: Extract the components/factors.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取成分/因子。
- en: Rotate the components/factors.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 旋转成分/因子。
- en: Interpret the results.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释结果。
- en: Compute component or factor scores.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算成分或因子得分。
- en: In the remainder of this chapter, we’ll carefully consider each step, starting
    with PCA. At the end of the chapter, you’ll find a detailed flow chart of the
    possible steps in PCA/EFA (figure 14.7). The chart will make more sense once you’ve
    read through the intervening material.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，我们将仔细考虑每个步骤，从 PCA 开始。在本章末尾，你将找到 PCA/EFA 可能步骤的详细流程图（图 14.7）。一旦你阅读了中间的材料，这张图将更有意义。
- en: 14.2 Principal components
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.2 主成分
- en: The goal of PCA is to replace a large number of correlated variables with a
    smaller number of uncorrelated variables while capturing as much information from
    the original variables as possible. These derived variables, called *principal
    components*, are linear combinations of the observed variables. Specifically,
    the first principal component
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 的目标是用尽可能多的信息替换大量相关变量，同时用更少的无关变量。这些派生变量，称为 *主成分*，是观测变量的线性组合。具体来说，第一个主成分
- en: '*PC*[1] = *a*[1]*X*[1] + *a*[2]*X*[2] + ...+ *a[k] X[k]*'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*PC*[1] = *a*[1]*X*[1] + *a*[2]*X*[2] + ...+ *a[k] X[k]*'
- en: is the weighted combination of the k observed variables that accounts for the
    most variance in the original set of variables. The second principal component
    is the linear combination that accounts for the most variance in the original
    variables, under the constraint that it’s *orthogonal* (uncorrelated) to the first
    principal component. Each subsequent component maximizes the amount of variance
    accounted for, while at the same time remaining uncorrelated with all previous
    components. Theoretically, you can extract as many principal components as there
    are variables. But from a practical viewpoint, you hope that you can approximate
    the full set of variables with a much smaller set of components. Let’s look at
    a simple example.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 是 k 个观测变量的加权组合，它解释了原始变量集中最大的方差。第二个主成分是在约束条件下解释原始变量最大方差的最小组合，即它与第一个主成分 *正交*（不相关）。每个后续成分都最大化解释的方差量，同时保持与所有先前成分的不相关性。从理论上讲，你可以提取与变量数量一样多的主成分。但从实际观点来看，你希望可以用一个更小的成分集来近似整个变量集。让我们看一个简单的例子。
- en: The dataset `USJudgeRatings` contains lawyers’ ratings of state judges in the
    US Superior Court. The data frame contains 43 observations on 12 numeric variables.
    Table 14.2 lists the variables.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集 `USJudgeRatings` 包含了美国州高级法院法官的律师评级。数据框包含 43 个观测值和 12 个数值变量。表 14.2 列出了这些变量。
- en: Table 14.2 Variables in the `USJudgeRatings` dataset
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 表 14.2 `USJudgeRatings` 数据集中的变量
- en: '| Variable | Description | Variable | Description |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 变量 | 描述 | 变量 | 描述 |'
- en: '| `CONT` | Number of contacts of lawyer with judge | `PREP` | Preparation for
    trial |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| `CONT` | 律师与法官的接触次数 | `PREP` | 诉讼准备 |'
- en: '| `INTG` | Judicial integrity | `FAMI` | Familiarity with law |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `INTG` | 司法诚信 | `FAMI` | 熟悉法律 |'
- en: '| `DMNR` | Demeanor | `ORAL` | Sound oral rulings |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `DMNR` | 行为 | `ORAL` | 声音良好的口头裁决 |'
- en: '| `DILG` | Diligence | `WRIT` | Sound written rulings |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `DILG` | 勤奋 | `WRIT` | 声音良好的书面裁决 |'
- en: '| `CFMG` | Case flow managing | `PHYS` | Physical ability |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `CFMG` | 案件流程管理 | `PHYS` | 体能 |'
- en: '| `DECI` | Prompt decisions | `RTEN` | Worthy of retention |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `DECI` | 快速决策 | `RTEN` | 值得保留 |'
- en: From a practical point of view, can you summarize the 11 evaluative ratings
    (`INTG` to `RTEN`) with a smaller number of composite variables? If so, how many
    will you need, and how will they be defined? Because the goal is to simplify the
    data, you’ll approach this problem using PCA. The data is in raw score format,
    and no values are missing. Therefore, your next step is deciding how many principal
    components you’ll need.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际的角度来看，你能用更少的组合变量来总结11个评估评分（从`INTG`到`RTEN`）吗？如果是这样，你需要多少个，它们将如何定义？因为目标是简化数据，所以你会使用PCA来解决这个问题。数据是原始分数格式，没有缺失值。因此，你的下一步是决定你需要多少个主成分。
- en: 14.2.1 Selecting the number of components to extract
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.1 选择提取成分的数量
- en: Several criteria are available for deciding how many components to retain in
    a PCA. They include
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定在主成分分析（PCA）中保留多少个成分时，有几个标准可供选择。它们包括
- en: Basing the number of components on prior experience and theory
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据先前经验和理论确定成分数量
- en: Selecting the number of components needed to account for some threshold cumulative
    amount of variance in the variables (for example, 80%)
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择需要解释变量中某些阈值累积方差数量的成分数量（例如，80%）
- en: Selecting the number of components to retain by examining the eigenvalues of
    the `k` × `k` correlation matrix among the variables
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过检查变量之间的`k` × `k`相关矩阵的特征值来选择保留成分的数量
- en: The most common approach is based on the eigenvalues. Each component is associated
    with an eigenvalue of the correlation matrix. The first PC is associated with
    the largest eigenvalue, the second PC with the second-largest eigenvalue, and
    so on. The *Kaiser–Harris criterion* suggests retaining components with eigenvalues
    greater than 1\. Components with eigenvalues less than 1 explain less variance
    than that contained in a single variable. In *Cattell’s Scree test*, the eigenvalues
    are plotted against their component numbers. Such plots typically demonstrate
    a bend or elbow, and the components above this sharp break are retained. Finally,
    you can run simulations, extracting eigenvalues from random data matrices of the
    same size as the original matrix. If an eigenvalue based on real data is larger
    than the average corresponding eigenvalues from a set of random data matrices,
    that component is retained. The approach is called *parallel analysis* (see Hayton,
    Allen, and Scarpello, 2004, for more details).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的方法是基于特征值。每个成分都与相关矩阵的特征值相关联。第一个主成分与最大的特征值相关联，第二个主成分与第二大的特征值相关联，依此类推。*凯撒-哈里斯标准*建议保留特征值大于1的成分。特征值小于1的成分解释的方差少于单个变量所包含的方差。在*卡特尔斯克皮尔测试*中，特征值与它们的成分编号相对应。此类图通常显示一个弯曲或肘部，并且保留此尖锐断裂点以上的成分。最后，你可以运行模拟，从与原始矩阵大小相同的随机数据矩阵中提取特征值。如果一个基于真实数据的特征值大于一组随机数据矩阵中相应平均特征值，则保留该成分。这种方法称为*平行分析*（参见Hayton,
    Allen, 和Scarpello，2004年，以获取更多详细信息）。
- en: 'You can assess all three eigenvalue criteria at the same time via the `fa.parallel()`
    function. For the 11 ratings (dropping the `CONT` variable), the necessary code
    is as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过`fa.parallel()`函数同时评估所有三个特征值标准。对于11个评分（不包括`CONT`变量），必要的代码如下：
- en: '[PRE0]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code produces the graph shown in figure 14.2\. The plot displays the scree
    test based on the observed eigenvalues (as straight-line segments and x’s), the
    mean eigenvalues derived from 100 random data matrices (as dashed lines), and
    the eigenvalues greater than 1 criterion (as a horizontal line at y = 1). The
    `abline()` function is used to add a horizontal line at y = 1.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码生成了图14.2所示的图形。该图显示了基于观察到的特征值的斯克皮尔测试（以直线段和x表示），从100个随机数据矩阵中推导出的平均特征值（以虚线表示），以及大于1的特征值标准（以y
    = 1的水平线表示）。使用`abline()`函数在y = 1处添加水平线。
- en: '![](Images/CH14_F02_Kabacoff3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH14_F02_Kabacoff3.png)'
- en: Figure 14.2 Assessing the number of principal components to retain for the `USJudgeRatings`
    example. A scree plot (the line with x’s), eigenvalues greater than 1 criterion
    (horizontal line), and parallel analysis with 100 simulations (dashed line) suggest
    retaining a single component.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2 评估保留`USJudgeRatings`示例中主成分的数量。折线图（带x的线）、大于1的特征值标准（水平线）和100次模拟的平行分析（虚线）表明应保留单个成分。
- en: All three criteria suggest that a single component is appropriate for summarizing
    this dataset. Your next step is to extract the principal component using the `principal()`
    function.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 所有三个标准都表明，单个成分适合总结这个数据集。你的下一步是使用`principal()`函数提取主成分。
- en: 14.2.2 Extracting principal components
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.2 提取主成分
- en: As indicated earlier, the `principal()` function performs a principal components
    analysis starting with either a raw data matrix or a correlation matrix. The format
    is
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`principal()`函数从原始数据矩阵或相关矩阵开始执行主成分分析。其格式为
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: where
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '`r` is a correlation matrix or a raw data matrix.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`r`是一个相关矩阵或原始数据矩阵。'
- en: '`nfactors` specifies the number of principal components to extract (1 by default).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nfactors`指定要提取的主成分数量（默认为1）。'
- en: '`rotate` indicates the rotation to be applied (varimax by default; see section
    14.2.3).'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rotate`表示要应用的旋转（默认为varimax；见14.2.3节）。'
- en: '`scores` specifies whether to calculate principal-component scores (false by
    default).'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scores`指定是否计算主成分得分（默认为false）。'
- en: To extract the first principal component, you can use the code in the following
    listing.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要提取第一个主成分，你可以使用以下列表中的代码。
- en: Listing 14.1 Principal components analysis of `USJudgeRatings`
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.1 `USJudgeRatings`的主成分分析
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here you’re inputting the raw data without the `CONT` variable and specifying
    that one unrotated component should be extracted. (Rotation is explained in section
    14.3.3.) Because PCA is performed on a correlation matrix, the raw data is automatically
    converted to a correlation matrix before the components are extracted.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你正在输入不带`CONT`变量的原始数据，并指定应提取一个未旋转的成分。（旋转在14.3.3节中解释。）因为PCA是在相关矩阵上进行的，所以在提取成分之前，原始数据会自动转换为相关矩阵。
- en: The column labeled PC1 contains the component *loadings,* which are the correlations
    of the observed variables with the principal component(s). If you extracted more
    than one principal component, there would be columns for PC2, PC3, and so on.
    Component loadings are used to interpret the meaning of components. You can see
    that each variable correlates highly with the first component (PC1). It therefore
    appears to be a general evaluative dimension.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 标有PC1的列包含成分的*载荷*，即观察变量与主成分（s）的相关性。如果你提取了多个主成分，则会有PC2、PC3等列。成分载荷用于解释成分的意义。你可以看到每个变量都与第一个成分（PC1）高度相关。因此，它似乎是一个一般评估维度。
- en: The column labeled h2 contains the component *communalities*—the amount of variance
    in each variable explained by the components. The u2 column contains the component
    uniqueness—the amount of variance not accounted for by the components (or 1 –
    h2). For example, 80% of the variance in physical ability (`PHYS`) ratings is
    accounted for by the first PC, and 20% isn’t. `PHYS` is the variable least well
    represented by a one-component solution.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 标有h2的列包含成分的*共同性*——每个变量由成分解释的方差量。u2列包含成分的独特性——未由成分解释的方差量（或1 – h2）。例如，物理能力（`PHYS`）评分的80%的方差由第一个主成分解释，而20%则不是。`PHYS`是单个成分解决方案表示最差的变量。
- en: The row labeled SS Loadings contains the eigenvalues associated with the components.
    The eigenvalues are the standardized variances associated with a particular component
    (in this case, the value for the first component is `10`). Finally, the row labeled
    Proportion Var represents the amount of variance accounted for by each component.
    Here you see that the first principal component accounts for 92% of the variance
    in the 11 variables.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 标有SS Loadings的行包含与成分相关的特征值。特征值是与特定成分相关的标准化方差（在这种情况下，第一个成分的值为`10`）。最后，标有Proportion
    Var的行表示每个成分解释的方差量。在这里，你可以看到第一个主成分解释了11个变量中的92%的方差。
- en: Let’s consider a second example, one that results in a solution with more than
    one principal component. The dataset `Harman23.cor` contains data on eight body
    measurements for 305 girls. In this case, the dataset consists of the correlations
    among the variables rather than the original data (see table 14.3).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑第二个例子，这个例子导致解决方案包含多个主成分。数据集`Harman23.cor`包含305名女孩的八个身体测量数据。在这种情况下，数据集由变量之间的相关性组成，而不是原始数据（见表14.3）。
- en: Table 14.3 Correlations among body measurements for 305 girls (`Harman23.cor`)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.3 305名女孩的身体测量之间的相关性（`Harman23.cor`）
- en: '|  | Height | Arm span | Forearm | Lower leg | Weight | Bitro diameter | Chest
    girth | Chest width |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '|  | 身高 | 臂展 | 前臂 | 下肢 | 体重 | 比特罗直径 | 胸围 | 胸围宽度 |'
- en: '| Height | 1.00 | 0.85 | 0.80 | 0.86 | 0.47 | 0.40 | 0.30 | 0.38 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 身高 | 1.00 | 0.85 | 0.80 | 0.86 | 0.47 | 0.40 | 0.30 | 0.38 |'
- en: '| Arm span | 0.85 | 1.00 | 0.88 | 0.83 | 0.38 | 0.33 | 0.28 | 0.41 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 臂展 | 0.85 | 1.00 | 0.88 | 0.83 | 0.38 | 0.33 | 0.28 | 0.41 |'
- en: '| Forearm | 0.80 | 0.88 | 1.00 | 0.80 | 0.38 | 0.32 | 0.24 | 0.34 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 前臂 | 0.80 | 0.88 | 1.00 | 0.80 | 0.38 | 0.32 | 0.24 | 0.34 |'
- en: '| Lower leg | 0.86 | 0.83 | 0.8 | 1.00 | 0.44 | 0.33 | 0.33 | 0.36 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 下肢 | 0.86 | 0.83 | 0.8 | 1.00 | 0.44 | 0.33 | 0.33 | 0.36 |'
- en: '| Weight | 0.47 | 0.38 | 0.38 | 0.44 | 1.00 | 0.76 | 0.73 | 0.63 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 体重 | 0.47 | 0.38 | 0.38 | 0.44 | 1.00 | 0.76 | 0.73 | 0.63 |'
- en: '| Bitro diameter | 0.40 | 0.33 | 0.32 | 0.33 | 0.76 | 1.00 | 0.58 | 0.58 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 比特罗直径 | 0.40 | 0.33 | 0.32 | 0.33 | 0.76 | 1.00 | 0.58 | 0.58 |'
- en: '| Chest girth | 0.30 | 0.28 | 0.24 | 0.33 | 0.73 | 0.58 | 1.00 | 0.54 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 胸围 | 0.30 | 0.28 | 0.24 | 0.33 | 0.73 | 0.58 | 1.00 | 0.54 |'
- en: '| Chest width | 0.38 | 0.41 | 0.34 | 0.36 | 0.63 | 0.58 | 0.54 | 1.00 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 胸围 | 0.38 | 0.41 | 0.34 | 0.36 | 0.63 | 0.58 | 0.54 | 1.00 |'
- en: '| Source: H. H. Harman, Modern Factor Analysis, Third Edition Revised (University
    of Chicago Press, 1976), Table 2.3. |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 来源：H. H. Harman，《现代因子分析》，第三版修订版（芝加哥大学出版社，1976年），表2.3。|'
- en: 'Again, you wish to replace the original physical measurements with a smaller
    number of derived variables. You can determine the number of components to extract
    using the following code. In this case, you need to identify the correlation matrix
    (the `cov` component of the `Harman23.cor` object) and specify the sample size
    (`n.obs`):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，你希望用更少的派生变量替换原始的物理测量。你可以使用以下代码确定要提取的成分数量。在这种情况下，你需要识别相关矩阵（`Harman23.cor`对象的`cov`组件）并指定样本大小（`n.obs`）：
- en: '[PRE3]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Figure 14.3 shows the resulting graph.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3显示了结果图。
- en: '![](Images/CH14_F03_Kabacoff3.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH14_F03_Kabacoff3.png)'
- en: Figure 14.3 Assessing the number of principal components to retain for the body
    measurements example. The scree plot (line with x’s), eigenvalues greater than
    1 criterion (horizontal line), and parallel analysis with 100 simulations (dashed
    line) suggest retaining two components.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3 评估保留身体测量示例的主成分数量。斯克里普图（带有x的线条）、特征值大于1的标准（水平线）以及与100次模拟的平行分析（虚线）表明应保留两个成分。
- en: You can see from the plot that a two-component solution is suggested. As in
    the first example, the Kaiser–Harris criteria, scree test, and parallel analysis
    agree. This won’t always be the case, and you may need to extract different numbers
    of components and select the solution that appears most useful. The next listing
    extracts the first two principal components from the correlation matrix.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以看出，建议使用两个成分的解决方案。与第一个例子一样，凯撒-哈里斯标准、斯克里普测试和平行分析意见一致。这并不总是如此，你可能需要提取不同数量的成分，并选择看起来最有用的解决方案。下一个列表从相关矩阵中提取了前两个主成分。
- en: Listing 14.2 Principal components analysis of body measurements
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.2 身体测量的主成分分析
- en: '[PRE4]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: If you examine the PC1 and PC2 columns in listing 14.2, you see that the first
    component accounts for 58% of the variance in the physical measurements, whereas
    the second component accounts for 22%. Together, the two components account for
    81% of the variance. The two components together account for 88% of the variance
    in the height variable.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你检查列表14.2中的PC1和PC2列，你会看到第一个成分解释了物理测量中58%的方差，而第二个成分解释了22%。这两个成分共同解释了81%的方差。这两个成分共同解释了身高变量中88%的方差。
- en: Components and factors are interpreted by examining their loadings. The first
    component correlates positively with each physical measure and appears to be a
    general size factor. The second component contrasts the first four variables (height,
    arm span, forearm, and lower leg), with the second four variables (weight, bitro
    diameter, chest girth, and chest width). It therefore appears to be a length-versus-volume
    factor. Conceptually, this isn’t an easy construct to work with. Whenever two
    or more components have been extracted, you can rotate the solution to make it
    more interpretable. This is the topic we’ll turn to next.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查载荷来解释成分和因子。第一个成分与每个物理测量值呈正相关，看起来是一个一般的大小因子。第二个成分对比前四个变量（身高、臂展、前臂和下肢），与后四个变量（体重、比特直径、胸围和胸宽）。因此，它似乎是一个长度与体积的因子。从概念上讲，这不是一个容易处理的构造。每当提取了两个或更多成分时，你可以旋转解决方案以使其更易于解释。这是我们接下来要讨论的主题。
- en: 14.2.3 Rotating principal components
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.3 旋转主成分
- en: '*Rotations* are a set of mathematical techniques for transforming the component
    loading matrix into one that’s more interpretable. They do this by *purifying*
    the components as much as possible. Rotation methods differ with regard to whether
    the resulting components remain uncorrelated (*orthogonal rotation*) or are allowed
    to correlate (*oblique rotation*). They also differ in their definition of purifying.
    The most popular orthogonal rotation is the *varimax* rotation, which attempts
    to purify the columns of the loading matrix so that each component is defined
    by a limited set of variables (that is, each column has a few large loadings and
    many very small loadings). Applying a varimax rotation to the body measurement
    data, you get the results provided in the next listing. You’ll see an example
    of an oblique rotation in section 14.4.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*旋转*是一组数学技术，用于将成分载荷矩阵转换为一个更易于解释的矩阵。它们通过尽可能*净化*成分来实现这一点。旋转方法在结果成分是否保持不相关（*正交旋转*）或允许相关（*斜交旋转*）方面有所不同。它们在净化定义上也有所不同。最流行的正交旋转是*Varimax旋转*，它试图净化载荷矩阵的列，使得每个成分由一个有限的变量集定义（也就是说，每一列有几个大的载荷和许多非常小的载荷）。将Varimax旋转应用于身体测量数据，你将得到下一列表中提供的结果。你将在14.4节中看到一个斜交旋转的例子。'
- en: Listing 14.3 Principal components analysis with varimax rotation
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.3 使用Varimax旋转的主成分分析
- en: '[PRE5]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The column names change from PC to RC to denote rotated components. Looking
    at the loadings in column RC1, you see that the first component is primarily defined
    by the first four variables (length variables). The loadings in the column RC2
    indicate that the second component is primarily defined by variables 5 through
    8 (volume variables). Note that the two components are still uncorrelated and
    that together, they still explain the variables equally well. You can see that
    the rotated solution explains the variables equally well because the variable
    communalities haven’t changed. Additionally, the cumulative variance accounted
    for by the two-component rotated solution (81%) hasn’t changed. But the proportion
    of variance accounted for by each individual component has changed (from 58% to
    44% for component 1 and from 22% to 37% for component 2). This spreading out of
    the variance across components is common, and technically, you should now call
    them components rather than principal components (because the variance-maximizing
    properties of individual components haven’t been retained).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列名从PC变为RC，以表示旋转后的成分。查看RC1列的载荷，可以看到第一个成分主要是由前四个变量（长度变量）定义的。RC2列的载荷表明第二个成分主要是由第5个到第8个变量（体积变量）定义的。请注意，这两个成分仍然是不相关的，并且它们共同解释了变量，效果相同。你可以看到旋转后的解决方案同样好地解释了变量，因为变量的共同度没有变化。此外，两个成分旋转解决方案解释的累积方差（81%）没有变化。但是，每个单独成分解释的方差比例已经改变（第1个成分从58%变为44%，第2个成分从22%变为37%）。这种方差在成分间的分散是常见的，技术上，你现在应该称它们为成分而不是主成分（因为单个成分的方差最大化特性已经保留）。
- en: The ultimate goal is to replace a larger set of correlated variables with a
    smaller set of derived variables. To do this, you need to obtain scores for each
    observation on the components.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最终目标是用一个较小的派生变量集替换一个较大的相关变量集。为此，你需要获得每个观察值在成分上的得分。
- en: 14.2.4 Obtaining principal component scores
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.2.4 获取主成分得分
- en: In the `USJudgeRatings` example, you extracted a single principal component
    from the raw data describing lawyers’ ratings on 11 variables. The `principal()`
    function makes it easy to obtain scores for each participant on this derived variable
    (see the next listing).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在`USJudgeRatings`示例中，你从原始数据中提取了一个描述律师对11个变量评分的单个主成分。`principal()`函数使得获取每个参与者在此派生变量上的得分变得容易（见下一列表）。
- en: Listing 14.4 Obtaining component scores from raw data
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.4 从原始数据中获取成分得分
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The principal component scores are saved in the `scores` element of the object
    returned by the `principal()` function when the option `scores=TRUE`. If you wanted,
    you could now get the correlation between the number of contacts occurring between
    a lawyer and a judge and their evaluation of the judge using
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 当`principal()`函数的选项`scores=TRUE`时，主成分得分保存在返回对象中的`scores`元素中。如果你愿意，现在你可以通过以下方式获取律师和法官之间发生的联系次数与他们对法官评价之间的相关性
- en: '[PRE7]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Apparently, there’s no relationship between the lawyer’s familiarity and their
    opinions!
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，律师的熟悉程度和他们的意见之间没有关系！
- en: When the principal components analysis is based on a correlation matrix and
    the raw data isn’t available, getting principal component scores for each observation
    is clearly not possible. But you can get the coefficients used to calculate the
    principal components.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 当主成分分析基于相关矩阵且原始数据不可用时，显然无法为每个观测值获得主成分得分。但你可以获得用于计算主成分的系数。
- en: In the body measurement data, you have correlations among body measurements,
    but you don’t have the individual measurements for these 305 girls. You can get
    the scoring coefficients using the code in the following listing.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在身体测量数据中，你拥有身体测量之间的相关性，但你没有这些305个女孩的个体测量数据。你可以使用以下列表中的代码来获取评分系数。
- en: Listing 14.5 Obtaining principal component scoring coefficients
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.5 获取主成分评分系数
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The component scores are obtained using the formulas
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 组件得分是通过以下公式获得的
- en: '[PRE9]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: and
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: These equations assume that the physical measurements have been standardized
    (mean = 0, sd = 1). Note that the weights for PC1 tend to be around 0.3 or 0\.
    The same is true for PC2\. As a practical matter, you could simplify your approach
    further by taking the first composite variable as the mean of the standardized
    scores for the first four variables. Similarly, you could define the second composite
    variable as the mean of the standardized scores for the second four variables.
    This is typically what I’d do in practice.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方程假设物理测量已经被标准化（均值=0，标准差=1）。请注意，PC1的权重倾向于在0.3或0.0左右。PC2也是如此。作为一个实际问题，你可以通过将第一个复合变量作为前四个变量标准化得分的平均值来进一步简化你的方法。同样，你可以将第二个复合变量定义为第二个四个变量标准化得分的平均值。在实践中，我通常会这样做。
- en: Little Jiffy conquers the world
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 小吉夫征服了世界
- en: There’s quite a bit of confusion among data analysts regarding PCA and EFA.
    One reason for this is historical and can be traced back to a program called Little
    Jiffy (no kidding). Little Jiffy was one of the most popular early programs for
    factor analysis, and it defaulted to a principal components analysis, extracting
    components with eigenvalues greater than 1 and rotating them to a varimax solution.
    The program was so widely used that many social scientists came to think of this
    default behavior as synonymous with EFA. Many later statistical packages also
    incorporated these defaults in their EFA programs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据分析师中，关于PCA和EFA存在相当多的混淆。其中一个原因是历史的，可以追溯到一个小程序叫做Little Jiffy（不是开玩笑）。Little
    Jiffy是最受欢迎的早期因子分析程序之一，它默认为主成分分析，提取特征值大于1的成分，并将它们旋转到方差最大化解。这个程序被广泛使用，以至于许多社会科学家认为这种默认行为等同于EFA。后来的许多统计软件包也将这些默认值纳入它们的EFA程序中。
- en: As I hope you’ll see in the next section, there are important and fundamental
    differences between PCA and EFA. To learn more about the PCA/EFA confusion, see
    Hayton, Allen, and Scarpello (2004).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如我在下一节中希望您看到的，PCA和EFA之间存在重要和根本性的差异。要了解更多关于PCA/EFA混淆的信息，请参阅Hayton、Allen和Scarpello（2004）。
- en: If your goal is to look for latent underlying variables that explain your observed
    variables, you can turn to factor analysis. This is the topic of the next section.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的目标是寻找解释你的观测变量的潜在潜在变量，你可以转向因子分析。这是下一节的主题。
- en: 14.3 Exploratory factor analysis
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.3 探索性因子分析
- en: The goal of EFA is to explain the correlations among a set of observed variables
    by uncovering a smaller set of more fundamental unobserved variables underlying
    the data. These hypothetical, unobserved variables are called *factors*. (Each
    factor is assumed to explain the variance shared among two or more observed variables,
    so technically, they’re called *common factors*.)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: EFA（主成分分析）的目标是通过揭示数据下更基本的未观察到的变量集合来解释一组观察变量的相关性。这些假设的、未观察到的变量被称为*因子*。（每个因子被假定为解释两个或多个观察变量之间的方差，所以技术上它们被称为*共同因子*。）
- en: The model can be represented as
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以表示为
- en: '*X[i]* = *a*[1]*F*[1] + *a*[2]*F*[2] + ... + *a[p]F[p]* + *U[i]*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*X[i]* = *a*[1]*F*[1] + *a*[2]*F*[2] + ... + *a[p]F[p]* + *U[i]*'
- en: where *X[i]* is the *i*th observed variable (*i* = 1... *k*), *F[j]* are the
    common factors (*j* = 1...*p*), and *p* < *k*. *U*[i] is the portion of variable
    *X[i]* that is unique to that variable (not explained by the common factors).
    *a[i]* is the degree to which each factor contributes to the composition of an
    observed variable. If we go back to the `Harman74.cor` example at the beginning
    of this chapter, we’d say that an individual’s scores on each of the 24 observed
    psychological tests is due to a weighted combination of their ability on 4 underlying
    psychological constructs.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *X[i]* 是第 *i* 个观察变量 (*i* = 1... *k*), *F[j]* 是共同因子 (*j* = 1...*p*), 且 *p*
    < *k*. *U*[i] 是变量 *X[i]* 中独特于该变量的部分（不是由共同因子解释的）。*a[i]* 是每个因子对观察变量组成的贡献程度。如果我们回到本章开头的`Harman74.cor`示例，我们会说，个人在24个观察到的心理测试中的得分是由于他们4个潜在心理结构能力的加权组合。
- en: Although the PCA and EFA models differ, many of the steps appear similar. To
    illustrate the process, you’ll apply EFA to the correlations among six psychological
    tests. One hundred twelve individuals were given six tests, including a nonverbal
    measure of general intelligence (general), a picture-completion test (picture),
    a block design test (blocks), a maze test (maze), a reading comprehension test
    (reading), and a vocabulary test (vocab). Can you explain the participants’ scores
    on these tests with a smaller number of underlying or latent psychological constructs?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然PCA和EFA模型不同，但许多步骤看起来很相似。为了说明这个过程，你将应用EFA到六个心理测试之间的相关性。112个人接受了六个测试，包括一个非言语的一般智力测量（一般）、一个图片完成测试（图片）、一个积木设计测试（积木）、一个迷宫测试（迷宫）、一个阅读理解测试（阅读）和一个词汇测试（词汇）。你能用更少的潜在或潜在心理结构来解释这些测试的参与者得分吗？
- en: 'The covariance matrix among the variables is provided in the dataset `ability.cov`.
    You can transform this into a correlation matrix using the `cov2cor()` function:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 变量之间的协方差矩阵在数据集`ability.cov`中提供。你可以使用`cov2cor()`函数将其转换为相关矩阵：
- en: '[PRE11]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Because you’re looking for hypothetical constructs that explain the data, you’ll
    use an EFA approach. As in PCA, the next task is to decide how many factors to
    extract.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你在寻找解释数据的假设结构，所以你会使用EFA方法。与PCA一样，下一个任务是决定提取多少个因子。
- en: 14.3.1 Deciding how many common factors to extract
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.1 决定提取多少个共同因子
- en: 'To decide on the number of factors to extract, turn to the `fa.parallel()`
    function:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要决定提取多少个因子，请转向`fa.parallel()`函数：
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Figure 14.4 shows the resulting plot. Notice you’ve requested that the function
    display results for both a principal components and a common factor approach so
    you can compare them (`fa = "both"`).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4显示了结果图。注意你已经要求函数显示主成分分析和共同因子方法的结果，以便你可以进行比较（`fa = "both"`）。
- en: There are several things to notice in this graph. If you’d taken a PCA approach,
    you might have chosen one component (scree test, parallel analysis) or two components
    (eigenvalues greater than 1). When in doubt, it’s usually better to overfactor
    than to underfactor because overfactoring tends to lead to less distortion of
    the “true” solution.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图表中要注意几个方面。如果你采用了PCA方法，你可能选择了其中一个成分（特征值测试，平行分析）或两个成分（特征值大于1）。当不确定时，通常最好是过度因子化而不是不足因子化，因为过度因子化往往会导致对“真实”解的扭曲减少。
- en: Looking at the EFA results, a two-factor solution is clearly indicated. The
    first two eigenvalues (triangles) are above the bend in the scree test and also
    above the mean eigenvalues based on 100 simulated data matrices. For EFA, the
    Kaiser–Harris criterion is number of eigenvalues above 0, rather than 1\. (Most
    people don’t realize this, so it’s a good way to win bets at parties.) In this
    case, the Kaiser–Harris criteria also suggest two factors.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 观察EFA结果，一个两因子解决方案明显指示。前两个特征值（三角形）在斯克里测试的弯曲点之上，并且也高于基于100个模拟数据矩阵的平均特征值。对于EFA，Kaiser-Harris标准是特征值超过0的数量，而不是1。\(（大多数人没有意识到这一点，所以在聚会上打赌是个好方法。）在这种情况下，Kaiser-Harris标准也建议两个因子。
- en: '![](Images/CH14_F04_Kabacoff3.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH14_F04_Kabacoff3.png)'
- en: Figure 14.4 Assessing the number of factors to retain for the psychological
    tests example. Results for both PCA and EFA are present. The PCA results suggest
    one or two components. The EFA results suggest two factors.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4评估心理测试示例中保留的因子数量。PCA和EFA的结果都显示出来。PCA结果建议一个或两个成分。EFA结果建议两个因子。
- en: 14.3.2 Extracting common factors
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.2 提取共同因子
- en: Now that you’ve decided to extract two factors, you can use the `fa()` function
    to obtain your solution. The format of the `fa()` function is
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经决定提取两个因子，你可以使用`fa()`函数来获得你的解决方案。`fa()`函数的格式是
- en: '[PRE13]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: where
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '`r` is a correlation matrix or a raw data matrix.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`r`是相关矩阵或原始数据矩阵。'
- en: '`nfactors` specifies the number of factors to extract (1 by default).'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nfactors`指定要提取的因子数量（默认为1）。'
- en: '`n.obs` is the number of observations (if a correlation matrix is input).'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n.obs`是观测数量（如果输入相关矩阵）。'
- en: '`rotate` indicates the rotation to be applied (oblimin by default).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rotate`指定要应用的旋转（默认为oblimin）。'
- en: '`scores` specifies whether to calculate factor scores (false by default).'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scores`指定是否计算因子得分（默认为false）。'
- en: '`fm` specifies the factoring method (minres by default).'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fm`指定因子化方法（默认为minres）。'
- en: Unlike PCA, there are many methods of extracting common factors, including maximum
    likelihood (`ml`), iterated principal axis (`pa`), weighted least square (`wls`),
    generalized weighted least squares (`gls`), and minimum residual (`minres`). Statisticians
    tend to prefer the maximum likelihood approach because of its well-defined statistical
    model. Sometimes this approach fails to converge, in which case the iterated principal
    axis option often works well. To learn more about the different approaches, see
    Mulaik (2009) and Gorsuch (1983).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '与PCA不同，有许多提取共同因子的方法，包括最大似然（`ml`）、迭代主轴（`pa`）、加权最小二乘（`wls`）、广义加权最小二乘（`gls`）和最小残差（`minres`）。统计学家倾向于更喜欢最大似然方法，因为它有一个定义良好的统计模型。有时这种方法无法收敛，在这种情况下，迭代主轴选项通常效果很好。要了解更多关于不同方法的信息，请参阅Mulaik
    (2009)和Gorsuch (1983)。 '
- en: For this example, you’ll extract the unrotated factors using the iterated principal
    axis (`fm` `=` `"pa"`) approach. The next listing gives the results.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，你将使用迭代主轴法（`fm` `=` `"pa"`)提取未旋转的因子。下一个列表给出了结果。
- en: Listing 14.6 Principal axis factoring without rotation
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.6无旋转的主轴因子化
- en: '[PRE14]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You can see that the two factors account for 60% of the variance in the six
    psychological tests. When you examine the loadings, though, they aren’t easy to
    interpret. Rotating them should help.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，这两个因子解释了六个心理测试中60%的方差。然而，当你检查载荷时，它们并不容易解释。旋转它们应该会有所帮助。
- en: 14.3.3 Rotating factors
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.3 旋转因子
- en: You can rotate the two-factor solution from section 14.3.2 using either an orthogonal
    rotation or an oblique rotation. Let’s try both so you can see how they differ.
    First, try an orthogonal rotation (in the next listing).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用正交旋转或斜交旋转从14.3.2节中的两因子解决方案进行旋转。让我们尝试两种方法，这样你可以看到它们之间的区别。首先，尝试正交旋转（在下一个列表中）。
- en: Listing 14.7 Factor extraction with orthogonal rotation
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.7使用正交旋转进行因子提取
- en: '[PRE15]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Looking at the factor loadings, the factors are certainly easier to interpret.
    Reading and vocabulary load on the first factor, and picture completion, block
    design, and mazes load on the second factor. The general nonverbal intelligence
    measure loads on both factors. This suggests that the correlations among the six
    psychological tests (the manifest variables) may be explained by two underlying
    latent variables (a verbal intelligence factor and a nonverbal intelligence factor).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 观察因子载荷，因子确实更容易解释。阅读和词汇负荷在第一个因子上，而图片完成、块设计和迷宫负荷在第二个因子上。一般非言语智力测量负荷在两个因子上。这表明六个心理测试（显变量）之间的相关性可能由两个潜在的潜在变量（言语智力因子和非言语智力因子）解释。
- en: By using an orthogonal rotation, you artificially force the two factors to be
    uncorrelated. What would you find if you allowed the two factors to correlate?
    You can try an oblique rotation such as `promax` (see the next listing).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用正交旋转，你人为地迫使两个因子不相关。如果你允许两个因子相关，你会找到什么？你可以尝试斜旋转，如`promax`（见下一列表）。
- en: Listing 14.8 Factor extraction with oblique rotation
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 列表14.8 斜旋转因子提取
- en: '[PRE16]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Several differences exist between the orthogonal and oblique solutions. In
    an orthogonal solution, attention focuses on the *factor structure matrix* (the
    correlations of the variables with the factors). In an oblique solution, there
    are three matrices to consider: the factor structure matrix, the factor pattern
    matrix, and the factor intercorrelation matrix.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 正交解和斜解之间存在几个差异。在正交解中，注意力集中在*因子结构矩阵*（变量与因子的相关性）。在斜解中，需要考虑三个矩阵：因子结构矩阵、因子模式矩阵和因子互相关矩阵。
- en: The *factor pattern matrix* is a matrix of standardized regression coefficients.
    They give the weights for predicting the variables from the factors. The *factor
    intercorrelation matrix* gives the correlations among the factors.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '*因子模式矩阵*是一个标准化的回归系数矩阵。它们提供了从因子预测变量的权重。*因子互相关矩阵*给出了因子之间的相关性。'
- en: In listing 14.8, the values in the PA1 and PA2 columns constitute the factor
    pattern matrix. They’re standardized regression coefficients rather than correlations.
    Examining the columns of this matrix is still used to name the factors (although
    there’s some controversy here). Again, you’d find a verbal and nonverbal factor.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表14.8中，PA1和PA2列中的值构成了因子模式矩阵。它们是标准化的回归系数，而不是相关性。检查这个矩阵的列仍然用于命名因子（尽管这里有一些争议）。再次，你会找到一个言语因子和非言语因子。
- en: The factor intercorrelation matrix indicates that the correlation between the
    two factors is 0.57, which is hefty. If the factor intercorrelations had been
    low, you might have gone back to an orthogonal solution to keep things simple.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 因子互相关矩阵表明两个因子之间的相关性为0.57，这是一个相当大的数值。如果因子互相关性较低，你可能需要回到正交解以保持简单。
- en: 'The *factor structure matrix* (or factor-loading matrix) isn’t provided, but
    you can easily calculate it using the formula *F* = *P* × *Phi*, where *F* is
    the factor-loading matrix, *P* is the factor pattern matrix, and *Phi* is the
    factor intercorrelation matrix. A simple function for carrying out the multiplication
    is as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '*因子结构矩阵*（或因子载荷矩阵）未提供，但你可以使用公式 *F* = *P* × *Phi* 容易地计算出它，其中 *F* 是因子载荷矩阵，*P*
    是因子模式矩阵，*Phi* 是因子互相关矩阵。执行乘法的一个简单函数如下：'
- en: '[PRE17]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Applying this to the example, you get
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 将此应用于示例，你得到
- en: '[PRE18]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Now you can review the correlations between the variables and the factors. Comparing
    them to the factor-loading matrix in the orthogonal solution, you see that these
    columns aren’t as pure. This is because you’ve allowed the underlying factors
    to be correlated. Although the oblique approach is more complicated, it’s often
    a more realistic model of the data.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以回顾变量与因子之间的相关性。将它们与正交解中的因子载荷矩阵进行比较，你会发现这些列并不那么纯粹。这是因为你允许潜在因子相关。尽管斜方法更复杂，但它通常是数据的更现实模型。
- en: You can graph an orthogonal or oblique solution using the `factor.plot``()`or
    `fa.diagram()` function. The code
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`factor.plot()`或`fa.diagram()`函数绘制正交或斜解。以下代码
- en: '[PRE19]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: produces the graph in figure 14.5.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 生成图14.5中的图形。
- en: '![](Images/CH14_F05_Kabacoff3.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图像](Images/CH14_F05_Kabacoff3.png)'
- en: Figure 14.5 Two-factor plot for the psychological tests in `ability.cov.vocab`
    and `reading` load on the first factor (PA1), and `blocks`, `picture`, and `maze`
    load on the second factor (PA2). The general intelligence test loads on both.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.5 `ability.cov.vocab` 和 `reading` 在第一个因子（PA1）上加载，而 `blocks`、`picture` 和
    `maze` 在第二个因子（PA2）上加载。一般智力测试同时加载在两个因子上。
- en: The code
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码
- en: '[PRE20]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: produces the diagram in figure 14.6\. If you let `simple=TRUE`, only the largest
    loading per item is displayed. The figure shows the largest loadings for each
    factor as well as the correlations between the factors. This type of diagram is
    helpful when there are several factors.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 生成图 14.6。如果你设置 `simple=TRUE`，则只显示每个项目的最大载荷。该图显示了每个因子的最大载荷以及因子之间的相关性。当存在多个因子时，此类图很有帮助。
- en: '![](Images/CH14_F06_Kabacoff3.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH14_F06_Kabacoff3.png)'
- en: Figure 14.6 Diagram of the oblique two-factor solution for the psychological
    test data in `ability.cov`
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.6 `ability.cov` 心理测试数据的斜两因子解图
- en: When you’re dealing with data in real life, it’s unlikely that you’d apply factor
    analysis to a dataset with so few variables. We’ve done it here to keep things
    manageable. If you’d like to test your skills, try factor-analyzing the 24 psychological
    tests contained in `Harman74.cor`. The code
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当你处理现实生活中的数据时，你不太可能将因子分析应用于变量如此少的数据库。我们在这里这样做是为了保持事情的可管理性。如果你想测试你的技能，尝试对包含在
    `Harman74.cor` 中的 24 个心理测试进行因子分析。以下代码
- en: '[PRE21]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: should get you started.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 应该能帮助你入门。
- en: 14.3.4 Factor scores
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.4 因子得分
- en: Compared with PCA, the goal of EFA is much less likely to be the calculation
    of factor scores. But these scores are easily obtained from the `fa()` function
    by including the `score=TRUE` option (when raw data are available). Additionally,
    the scoring coefficients (standardized regression weights) are available in the
    `weights` element of the object returned.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 与 PCA 相比，EFA 的目标不太可能是计算因子得分。但通过包括 `score=TRUE` 选项（当有原始数据时），这些得分很容易从 `fa()` 函数中获得。此外，评分系数（标准化回归权重）在返回的对象的
    `weights` 元素中可用。
- en: For the `ability.cov` dataset, you can obtain the beta weights for calculating
    the factor score estimates for the two-factor oblique solution using
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 `ability.cov` 数据集，你可以使用以下方法获得计算两因子斜解的因子得分估计的贝塔权重：
- en: '[PRE22]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Unlike component scores, which are calculated exactly, factor scores can only
    be estimated. Several methods exist. The `fa()` function uses the regression approach.
    To learn more about factor scores, see DiStefano, Zhu, and Mîndrila (2009).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 与计算精确的成分得分不同，因子得分只能进行估计。存在几种方法。`fa()` 函数使用回归方法。要了解更多关于因子得分的信息，请参阅 DiStefano、Zhu
    和 Mîndrila（2009）。
- en: Before moving on, let’s briefly review other R packages that are useful for
    exploratory factor analysis.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们简要回顾一下其他对探索性因子分析有用的 R 包。
- en: 14.3.5 Other EFA-related packages
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 14.3.5 其他 EFA 相关包
- en: R contains several other contributed packages that are useful for conducting
    factor analyses. The `FactoMineR` package provides methods for PCA and EFA as
    well as other latent variable models. It offers many options that we haven’t considered
    here, including the use of both numeric and categorical variables. The `FAiR`
    package estimates factor analysis models using a genetic algorithm that allows
    inequality restrictions on model parameters. The `GPArotation` package offers
    many additional factor rotation methods. Finally, the `nFactors` package offers
    sophisticated techniques for determining the number of factors underlying data.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: R 包含了其他几个有用的贡献包，用于进行因子分析。`FactoMineR` 包提供了 PCA 和 EFA 以及其他潜在变量模型的方法。它提供了许多我们在这里没有考虑的选项，包括使用数值和分类变量。`FAiR`
    包使用遗传算法估计因子分析模型，该算法允许对模型参数施加不等式约束。`GPArotation` 包提供了许多额外的因子旋转方法。最后，`nFactors`
    包提供了确定数据中潜在因子数量的复杂技术。
- en: 14.4 Other latent variable models
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14.4 其他潜在变量模型
- en: EFA is only one of a wide range of latent variable models used in statistics.
    We’ll end this chapter with a brief description of other models that can be fit
    within R. These include models that test a priori theories that can handle mixed
    data types (numeric and categorical), or that are based solely on categorical
    multiway tables.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: EFA 只是统计学中广泛使用的潜在变量模型之一。我们将以对 R 中可以拟合的其他模型的简要描述结束本章。这些包括测试先验理论，可以处理混合数据类型（数值和分类），或者仅基于分类多路表的模型。
- en: In EFA, you allow the data to determine the number of factors to be extracted
    and their meaning. But you could start with a theory about how many factors underlie
    a set of variables, how the variables load on those factors, and how the factors
    correlate with one another. You could then test this theory against a set of collected
    data. The approach is called *confirmatory factor analysis (CFA**)*.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在EFA中，你允许数据确定要提取的因素数量及其含义。但你可以从一个理论开始，这个理论关于一组变量背后的因素数量，变量如何加载到这些因素上，以及因素如何相互关联。然后你可以将这个理论与收集到的数据集进行测试。这种方法称为*确认性因子分析（CFA**）。
- en: CFA is a subset of a methodology called *structural equation modeling (SEM**)*.
    SEM allows you to posit not only the number and composition of underlying factors,
    but also how these factors impact one another. You can think of SEM as a combination
    of confirmatory factor analyses (for the variables) and regression analyses (for
    the factors). The resulting output includes statistical tests and fit indices.
    There are several excellent packages for CFA and SEM in R, including `sem`, `OpenMx`,
    and `lavaan`.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: CFA是称为*结构方程模型（SEM**）的方法论的一个子集。SEM不仅允许你提出潜在因素的数量和组成，还允许你提出这些因素如何相互影响。你可以将SEM视为确认性因子分析（针对变量）和回归分析（针对因素）的组合。结果输出包括统计检验和拟合指数。R中有几个用于CFA和SEM的优秀包，包括`sem`、`OpenMx`和`lavaan`。
- en: The `ltm` package can be used to fit latent models to the items contained in
    tests and questionnaires. The methodology is often used to create large-scale
    standardized tests such as the Scholastic Aptitude Test (SAT) and the Graduate
    Record Exam (GRE).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`ltm`包将潜在模型拟合到测试和问卷中的项目。这种方法通常用于创建大规模标准化测试，如学术能力评估测试（SAT）和研究生入学考试（GRE）。
- en: Latent class models (in which the underlying factors are assumed to be categorical
    rather than continuous) can be fit with the `FlexMix`, `lcmm`, `randomLCA`, and
    `poLCA` packages. The `lcda` package performs latent class discriminant analysis,
    and the `lsa` package performs latent semantic analysis, a methodology used in
    natural language processing.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在类别模型（其中假设潜在因素是分类的而不是连续的）可以使用`FlexMix`、`lcmm`、`randomLCA`和`poLCA`包进行拟合。`lcda`包执行潜在类别判别分析，而`lsa`包执行潜在语义分析，这是一种在自然语言处理中使用的方
    法。
- en: The `ca` package provides functions for simple and multiple correspondence analysis.
    These methods allow you to explore the structure of categorical variables in two-way
    and multiway tables, respectively.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`ca`包提供了简单和多重对应分析的函数。这些方法允许你分别探索双向和多向表中分类变量的结构。'
- en: Finally, R contains numerous methods for *multidimensional scaling (MDS**)*.
    MDS is designed to detect underlying dimensions that explain the similarities
    and distances between a set of measured objects (for example, countries). The
    `cmdscale()` function in the base installation performs a classical MDS, whereas
    the `isoMDS()` function in the `MASS` package performs a nonmetric MDS. The `vegan`
    package also contains functions for classical and nonmetric MDS.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，R包含了许多用于*多维尺度分析（MDS**）的方法。MDS旨在检测一组测量对象（例如，国家）之间的相似性和距离背后的潜在维度。基础安装中的`cmdscale()`函数执行经典MDS，而`MASS`包中的`isoMDS()`函数执行非度量MDS。`vegan`包也包含经典和非度量MDS的函数。
- en: Summary
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Principal components analysis (PCA) is a useful data-reduction method that can
    replace many correlated variables with a smaller number of uncorrelated composite
    variables.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）是一种有用的数据降维方法，可以用较少的无关组合变量替换许多相关变量。
- en: Exploratory factor analysis (EFA) contains a broad range of methods for identifying
    latent or unobserved constructs (factors) that may underlie a set of observed
    or manifest variables.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索性因子分析（EFA）包含了一系列用于识别潜在或未观察到的结构（因素）的方法，这些因素可能是一组观察或显性变量的基础。
- en: While the goal of PCA is typically to summarize data and reduce its dimensionality,
    EFA can be used as a hypothesis-generating tool that is useful when you’re trying
    to understand the relationships among variables. It’s often used in the social
    sciences for theory development.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然PCA的目标通常是总结数据和降低其维度，但EFA可以用作假设生成工具，这在试图理解变量之间的关系时非常有用。它通常在社会科学理论发展中使用。
- en: PCA and EFA are both multistep processes that require the data analyst to make
    choices at each step. Figure 14.7 shows these steps.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）和探索性因子分析（EFA）都是多步骤的过程，需要数据分析师在每一步做出选择。图14.7展示了这些步骤。
- en: '![](Images/CH14_F07_Kabacoff4.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH14_F07_Kabacoff4.png)'
- en: Figure 14.7 A principal components/exploratory factor analysis decision chart
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.7 主成分/探索性因素分析决策图
