- en: 17 Optimizing your Docker images for size, speed, and security
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 17 优化 Docker 镜像以实现大小、速度和安全性
- en: Once you have your apps containerized and working well in a cluster, you may
    think that you’re good to go to production, but there are some best practices
    you still need to invest time in. Optimizing your Docker images is one of the
    most important, because you need your builds and deployments to be fast, your
    application content to be secure, and your evenings free to call your own--you
    do not want to be paged at 2 a.m. when your servers have run out of disk space.
    The Dockerfile syntax is small and intuitive, but it hides some complexity that
    you need to understand to make the most of your image builds.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的应用程序被容器化并在集群中运行良好，你可能认为你可以直接进入生产环境，但还有一些最佳实践你需要投入时间。优化你的 Docker 镜像是最重要的之一，因为你需要你的构建和部署要快，你的应用程序内容要安全，你的夜晚要自由——你不想在凌晨
    2 点被叫醒，因为你的服务器磁盘空间已满。Dockerfile 语法小巧直观，但它隐藏了一些你需要理解以充分利用镜像构建的复杂性。
- en: This chapter will take you through the finer details of the image format so
    you know how and why to optimize it. We’ll be building on chapter 3, where you
    learned that Docker images are actually merged from multiple image layers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将带你深入了解镜像格式，让你知道如何以及为什么需要优化它。我们将基于第 3 章的内容，你学习了 Docker 镜像是从多个镜像层合并而成的。
- en: 17.1 How you optimize Docker images
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17.1 如何优化 Docker 镜像
- en: The Docker image format is heavily optimized. Layers are shared between images
    wherever possible, which reduces build times, network traffic, and disk usage.
    But Docker has a conservative approach towards data, and it doesn’t automatically
    remove images that you’ve pulled--that’s something you need to do explicitly.
    So when you replace containers to update your application, Docker will download
    the new image layers, but it won’t remove any of the old image layers. It’s easy
    for your disk to get swallowed up with lots of old image layers, especially on
    development or test machines that are regularly updating.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 镜像格式高度优化。尽可能地在镜像之间共享层，这减少了构建时间、网络流量和磁盘使用。但 Docker 对数据持保守态度，它不会自动删除你拉取的镜像——这是你需要明确执行的事情。所以当你替换容器以更新你的应用程序时，Docker
    会下载新的镜像层，但不会删除任何旧的镜像层。你的磁盘很容易被大量的旧镜像层吞噬，尤其是在经常更新的开发或测试机器上。
- en: 'try it now You can see how much disk space your images are physically using
    with the `system` `df` command, which also shows container, volume, and build
    cache disk usage:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 你可以使用 `system` `df` 命令查看你的镜像实际占用的磁盘空间，该命令还会显示容器、卷和构建缓存磁盘使用情况：
- en: '` docker system df`'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '` docker system df`'
- en: If you’ve never cleared out old images from your Docker Engine, you’ll probably
    be surprised at the results. My output is in figure 17.1--you can see there are
    185 images totaling 7.5 GB of storage, even though I’m not running any containers.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从未清理过 Docker 引擎中的旧镜像，你可能会对结果感到惊讶。我的输出在图 17.1 中——你可以看到有 185 个镜像，总共占用 7.5 GB
    的存储空间，尽管我没有运行任何容器。
- en: '![](../Images/17-1.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17-1.jpg)'
- en: Figure 17.1 It’s easy to see your disk swallowed up by Docker images you’re
    not even using.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.1 很容易看到你的磁盘被你甚至没有使用的 Docker 镜像吞噬了。
- en: This example is a mild one--I’ve seen unloved servers that have been running
    Docker for years wasting hundreds of gigabytes on unused images. It’s a good habit
    to run `docker` `system` `prune` regularly--it clears out image layers and the
    build cache without removing full images. You can run it with a scheduled job
    to remove unused layers, but if your images are optimized it will be less of an
    issue. Optimizing parts of your technology stack is often a cyclical process with
    many small improvements, but with Docker it’s very easy to make big improvements
    by following some simple best practices.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子是一个轻微的例子——我见过一些被忽视的服务器已经运行 Docker 几年了，浪费了数百 GB 的空间在未使用的镜像上。定期运行 `docker`
    `system` `prune` 是一个好习惯——它清除镜像层和构建缓存，而不删除完整的镜像。你可以通过计划任务来运行它以删除未使用的层，但如果你的镜像已经优化，那么这不会成为一个大问题。优化你的技术栈的部分通常是一个周期性的过程，有很多小的改进，但使用
    Docker，通过遵循一些简单的最佳实践，你可以很容易地做出大的改进。
- en: The first is not to include files in your image unless you need them. It sounds
    obvious, but you’ll often write a Dockerfile that copies in a whole folder structure
    without realizing that the folder includes documentation or images or other binaries
    that aren’t needed at runtime. Being explicit about the files you copy can be
    the first big saving you make. Compare the Dockerfiles in listing 17.1--the first
    example copies in a whole folder, whereas the second example realizes the copy
    added some extra files and includes a new step to delete them.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条规则是除非你需要它们，否则不要将文件包含在你的镜像中。这听起来很明显，但你经常会编写一个 Dockerfile，复制整个文件夹结构，而没有意识到该文件夹包含文档或图像或其他在运行时不需要的二进制文件。明确列出你复制的文件可以是你节省的第一个大步骤。比较列表
    17.1 中的 Dockerfile——第一个示例复制了整个文件夹，而第二个示例意识到复制添加了一些额外的文件，并包含了一个新步骤来删除它们。
- en: Listing 17.1 Trying to optimize a Dockerfile by removing files
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 17.1 尝试通过删除文件优化 Dockerfile
- en: '` # Dockerfile v1 - copies in the whole directory structure:` ` FROM diamol/base`
    ` CMD echo app- && ls app && echo docs- && ls docs` ` COPY . .`  ` # Dockerfile
    v2 - adds a new step to delete unused files` ` FROM diamol/base` ` CMD echo app-
    && ls app && echo docs- && ls docs` ` COPY . .` ` RUN rm -rf docs`'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '` # Dockerfile v1 - 复制整个目录结构：` ` FROM diamol/base` ` CMD echo app- && ls app
    && echo docs- && ls docs` ` COPY . .` ` # Dockerfile v2 - 添加一个新步骤来删除未使用的文件` ` FROM
    diamol/base` ` CMD echo app- && ls app && echo docs- && ls docs` ` COPY . .` ` RUN
    rm -rf docs`'
- en: In the v2 Dockerfile, you’d think the image size would be smaller because it
    deletes the extra `docs` folder, but that’s not how image layers work. The image
    is a merge of all the layers, so the files still exist from the `COPY` layer;
    they just get hidden in the delete layer, so the total image size doesn’t shrink.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在 v2 Dockerfile 中，你会认为镜像大小会更小，因为它删除了额外的 `docs` 文件夹，但图像层的工作方式并非如此。图像是所有层的合并，所以文件仍然存在于
    `COPY` 层；它们只是被隐藏在删除层中，所以总镜像大小并没有缩小。
- en: try it now Build both examples and compare the sizes
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看！构建这两个示例并比较大小
- en: '` cd ch17/exercises/build-context`  ` docker image build -t diamol/ch17-build-context:v1
    .`  ` docker image build -t diamol/ch17-build-context:v2 -f ./Dockerfile.v2 .` 
    ` docker image ls -f reference= diamol/ch17*`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '` cd ch17/exercises/build-context` ` docker image build -t diamol/ch17-build-context:v1
    .` ` docker image build -t diamol/ch17-build-context:v2 -f ./Dockerfile.v2 .`
    ` docker image ls -f reference= diamol/ch17*`'
- en: You’ll find that the v2 image is exactly the same size as the v1 image, as if
    the `rm` command to delete the folder hadn’t been run at all. You can see my output
    in figure 17.2--I’m using Linux containers, so the sizes are tiny, but almost
    half of the size is from unnecessary files in the `docs` folder.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现 v2 图像的大小与 v1 图像完全相同，就像没有运行删除文件夹的 `rm` 命令一样。你可以看到我在图 17.2 中的输出——我正在使用 Linux
    容器，所以大小非常小，但几乎一半的大小来自 `docs` 文件夹中的不必要文件。
- en: '![](../Images/17-2.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17-2.jpg)'
- en: Figure 17.2 Surprise! Deleting files doesn’t reduce the image size if the delete
    is in its own layer.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.2 惊奇！如果删除操作在其自己的图层中，删除文件并不会减少图像大小。
- en: Each instruction in a Dockerfile produces an image layer, and layers are merged
    together to form the whole image. If you write files in a layer, those files are
    permanently there; if you delete them in a subsequent layer, all Docker does is
    hide them in the filesystem. This is a fundamental thing to understand when you
    come to image optimization--it’s no good trying to remove bloat in later layers--you
    need to optimize every layer. You can easily see that the delete layer just hides
    the files by running an image from the previous layer, before the delete happened.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile 中的每条指令都会生成一个图像层，层合并在一起形成整个图像。如果你在层中写入文件，这些文件将永久存在；如果你在后续层中删除它们，Docker
    只是在文件系统中隐藏它们。这是当你进行图像优化时需要理解的一个基本概念——试图在后续层中删除冗余是没有用的——你需要优化每个层。你可以通过从删除之前运行的层中运行图像来轻松地看到删除层只是通过隐藏文件来实现的。
- en: 'try it now You can run a container from any image layer if you have those layers
    in your cache. Compare the final image with the previous image layer:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看！如果你在缓存中有这些层，你可以从任何图像层运行容器。比较最终镜像与之前的图像层：
- en: '` # run a container from the finished image:` ` docker container run diamol/ch17-build-context:v2` 
    ` # check the image history to find the previous layer ID:` ` docker history diamol/ch17-build-context:v2` 
    ` # run a container from that previous layer:` ` docker container run <previous-layer-id>`'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 从完成的镜像运行容器：` ` docker container run diamol/ch17-build-context:v2` ` # 检查图像历史记录以找到上一个层
    ID：` ` docker history diamol/ch17-build-context:v2` ` # 从那个上一个层运行容器：` ` docker
    container run <previous-layer-id>`'
- en: There’s nothing special about the final layer in an image. You can run a container
    from a layer partway through the image stack, and you’ll see the filesystem merged
    up to the point of that layer. My output is in figure 17.3--you can see that the
    deleted files are all available when I run a container from the previous image
    layer.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像的最后一层没有特殊之处。你可以从图像堆栈中的某个层运行容器，并且你会看到文件系统合并到该层。我的输出在图17.3中--你可以看到当我从上一个镜像层运行容器时，所有已删除的文件都是可用的。
- en: '![](../Images/17-3.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17-3.jpg)'
- en: Figure 17.3 The merged filesystem hides deleted files, but you can get to them
    from a previous layer.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.3 合并的文件系统隐藏了已删除的文件，但你仍然可以从之前的层访问它们。
- en: This is the first point about optimizing--don’t copy anything into the image
    that you don’t need to run the app. Even if you try to delete it in later instructions,
    it will still be there somewhere in the image stack taking up disk space. It’s
    much better to be precise in your `COPY` instructions to only bring the files
    you want into the image. That makes for smaller image sizes and also a more clearly
    documented installation in your Dockerfile. Listing 17.2 shows the optimized v3
    Dockerfile for this simple app--the only change from v1 is that it copies the
    `app` subfolder rather than the whole of the directory.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于优化的第一个要点--不要将不需要运行应用程序的任何内容复制到镜像中。即使你在后续指令中尝试删除它，它仍然会在镜像堆栈的某个地方存在，占用磁盘空间。在`COPY`指令中更精确地指定，只将你想要的文件带入镜像会更好。这会使镜像尺寸更小，并且也会使你的Dockerfile中的安装文档更加清晰。列表17.2显示了此简单应用程序的优化v3
    Dockerfile--与v1相比，唯一的更改是它复制了`app`子文件夹而不是整个目录。
- en: Listing 17.2 An optimized Dockerfile that only copies necessary files
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 列表17.2 仅复制必要文件的优化Dockerfile
- en: '` FROM diamol/base` ` CMD echo app- && ls app && echo docs- && ls docs` ` COPY
    ./app ./app`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '` FROM diamol/base` ` CMD echo app- && ls app && echo docs- && ls docs` ` COPY
    ./app ./app`'
- en: When you build this, you’ll see that the image size is smaller, but there’s
    another optimization you can make here too. Docker compresses the build context
    (the folder where you run the build) and sends it to the engine along with the
    Dockerfile when you run a build. That’s how you can build images on a remote engine
    from files on your local machine. The build context often has files you don’t
    need, so you can exclude them from the build context by listing file paths or
    wildcards in a file called `.dockerignore` .
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当你构建这个项目时，你会发现图像的大小更小，但在这里你还可以进行另一种优化。Docker在构建过程中会压缩构建上下文（即运行构建的文件夹）并将其与Dockerfile一起发送到引擎。这就是你如何从本地机器上的文件在远程引擎上构建镜像的方法。构建上下文通常包含你不需要的文件，因此你可以通过在名为`.dockerignore`的文件中列出文件路径或通配符来排除它们。
- en: 'try it now Build the optimized Docker image, and then build it again with a
    `.dockerignore` file to reduce the size of the context:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：构建优化的Docker镜像，然后使用`.dockerignore`文件再次构建，以减小上下文的大小：
- en: '` # build the optimized image; this adds unused files to the context:` ` docker
    image build -t diamol/ch17-build-context:v3 -f ./Dockerfile.v3 .`  ` # now rename
    the already prepared ignore file and check the contents:` ` mv rename.dockerignore
    .dockerignore` ` cat .dockerignore`  ` # run the same build command again:` ` docker
    image build -t diamol/ch17-build-context:v3 -f ./Dockerfile.v3 .`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 构建优化后的镜像；这会将未使用的文件添加到上下文中：` ` docker image build -t diamol/ch17-build-context:v3
    -f ./Dockerfile.v3 .`  ` # 现在重命名已准备好的忽略文件并检查其内容：` ` mv rename.dockerignore .dockerignore`
    ` cat .dockerignore`  ` # 再次运行相同的构建命令：` ` docker image build -t diamol/ch17-build-context:v3
    -f ./Dockerfile.v3 .`'
- en: You’ll see that in the first build command, Docker sends 2 MB of build context
    to the Engine. That’s not compressed, so it’s the full size of the files in that
    folder--most of which is a 2 MB picture of a whale. In the second build there’s
    a `.dockerignore` file in the current directory that tells Docker to exclude the
    docs folder and the Dockerfiles, so the build context then is only 4 KB. You can
    see my output in figure 17.4.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到在第一个构建命令中，Docker将2 MB的构建上下文发送到引擎。这没有压缩，所以它是该文件夹中文件的全尺寸--其中大部分是一个2 MB的鲸鱼图片。在第二个构建中，当前目录中有一个`.dockerignore`文件，它告诉Docker排除docs文件夹和Dockerfile，因此构建上下文现在是4
    KB。你可以在图17.4中看到我的输出。
- en: '![](../Images/17-4.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17-4.jpg)'
- en: Figure 17.4 Using a `.dockerignore` file reduces the size of the build context
    and the time to send it.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.4 使用`.dockerignore`文件减小构建上下文的大小和发送时间。
- en: A `.dockerignore` file can save you a lot of time when you count the cost of
    sending unused data in the build context, and it can save space, even when you’re
    using explicit paths in your Dockerfile. It could be you’re building the code
    locally and also using a multi-stage build to compile in Docker--you can specify
    the build binaries in your `.dockerignore` file and be sure they won’t get copied
    into the image. The file format is the same as Git’s `.gitignore` file, and you
    can use the template for your app platform from GitHub as a good starting point
    (you should include the Git history folder `.git` if your Dockerfile is at the
    root of the repo too).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`.dockerignore`文件在计算构建上下文中未使用数据的成本时可以节省你大量时间，并且它可以节省空间，即使你在Dockerfile中使用显式路径。可能你是在本地构建代码，同时也使用多阶段构建在Docker中编译--你可以在`.dockerignore`文件中指定构建的二进制文件，并确保它们不会被复制到镜像中。文件格式与Git的`.gitignore`文件相同，你可以从GitHub上的应用平台模板作为良好的起点（如果你的Dockerfile位于仓库的根目录，你应该包括Git历史文件夹`.git`）。'
- en: Now that you’ve seen the importance of managing which files make it into your
    Docker image, we’re going to take a step back and look at the image you’re using
    as a base.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了管理进入你的Docker镜像的文件的重要性，我们将退一步看看你用作基础的镜像。
- en: 17.2 Choosing the right base images
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17.2 选择合适的基镜像
- en: Base image size choice is as much about security as it is about disk space and
    network transfer time. If your base OS image is large, it probably has all sorts
    of tools that might be useful on a real machine but can be a security hole in
    a container. If your OS base image has curl installed, an attacker could use that
    to download malware or upload your data to their servers, if they manage to break
    out of your app into the container.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 基镜像大小的选择在安全性、磁盘空间和网络传输时间方面同样重要。如果你的基础操作系统镜像很大，它可能包含各种可能在真实机器上有用的工具，但在容器中可能成为安全漏洞。如果你的操作系统基础镜像安装了curl，攻击者可能利用它下载恶意软件或将你的数据上传到他们的服务器，如果他们设法从你的应用程序容器中突破出来。
- en: 'That’s also true of application platform base images. If you’re running Java
    apps, the OpenJDK official image is a good base, but there are many tags with
    different configurations of the Java runtime (the JRE) and the developer SDK (the
    JDK). Table 17.1 shows the size differences between the multi-arch images for
    the SDK versus the runtime and the most minimal versions:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这也适用于应用平台基镜像。如果你正在运行Java应用程序，OpenJDK官方镜像是一个好的基础，但有许多标签具有不同的Java运行时（JRE）和开发SDK（JDK）配置。表17.1显示了SDK与运行时以及最精简版本的多架构镜像的大小差异：
- en: Table 17.1 Size differences between compatible Java 11 images on Docker Hub
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 表17.1 Docker Hub上兼容Java 11镜像的大小差异
- en: '|  | :11-jdk | :11-jre | :11-jre-slim | :11-jre-nanoserver-1809 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | :11-jdk | :11-jre | :11-jre-slim | :11-jre-nanoserver-1809 |'
- en: '| Linux | 296 MB | 103 MB | 69 MB |  |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| Linux | 296 MB | 103 MB | 69 MB |  |'
- en: '| Windows | 2.4 GB | 2.2 GB |  | 277 MB |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| Windows | 2.4 GB | 2.2 GB |  | 277 MB |'
- en: Linux users can use a 69 MB base image instead of 296 MB, and Windows users
    can use 277 MB instead of 2.4 GB, just by checking the variants on Docker Hub
    and picking the ones with the smallest OS image and the smallest Java installation.
    The OpenJDK team are cautious with their multi-arch images. They select images
    with the widest compatibility, but it’s simple to try your app with a smaller
    variant. As a good rule, use Alpine or Debian Slim images as the base OS for Linux
    containers, and Nano Server for Windows containers (the alternative is Windows
    Server Core, which is pretty much the full Windows Server OS--that’s where the
    gigabytes of disk go). Not every app will work with the smaller variants, but
    it’s easy to switch images in your `FROM` lines and test it out.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Linux用户可以使用69 MB的基础镜像而不是296 MB，Windows用户可以使用277 MB而不是2.4 GB，只需在Docker Hub上检查变体，选择具有最小操作系统镜像和最小Java安装的镜像。OpenJDK团队对多架构镜像持谨慎态度。他们选择具有最广泛兼容性的镜像，但尝试使用较小的变体很简单。作为一个好的规则，使用Alpine或Debian
    Slim镜像作为Linux容器的基操作系统，对于Windows容器使用Nano Server（另一种选择是Windows Server Core，它几乎与完整的Windows
    Server OS相同--这就是磁盘空间达到数GB的原因）。并非每个应用程序都能与较小的变体一起工作，但很容易在`FROM`行中切换镜像并测试它。
- en: Size isn’t just about disk space--it’s also about what’s using the space. The
    largest OpenJDK images include the whole Java SDK, so there’s a nice attack vector
    there if someone manages to compromise your container. They could write some Java
    source code files into the container’s disk, compile them with the SDK, and run
    an app that does anything they want in the security context of your application
    container.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 大小不仅仅是关于磁盘空间，它还关乎占用空间的内容。最大的 OpenJDK 镜像包括了整个 Java SDK，因此如果有人设法破坏您的容器，这里就有一个很好的攻击向量。他们可以将一些
    Java 源代码文件写入容器的磁盘，使用 SDK 编译它们，并运行一个在您的应用容器安全上下文中做任何他们想做的应用。
- en: 'try it now Among the exercises for this chapter is a Java app that uses the
    default JDK image. It runs a very simple REST API that always returns the value
    `true` :'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 本章的练习之一是一个使用默认 JDK 镜像的 Java 应用程序。它运行一个非常简单的 REST API，总是返回值 `true`：
- en: '` cd ch17/exercises/truth-app`  ` # build the image - the base image uses the
    :11-jdk tag:` ` docker image build -t diamol/ch17-truth-app .`  ` # run the app
    and try it out:` ` docker container run -d -p 8010:80 --name truth diamol/ch17-truth-app`
    ` curl http://localhost:8010/truth`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '` cd ch17/exercises/truth-app`  ` # 构建镜像 - 基础镜像使用 :11-jdk 标签:` ` docker image
    build -t diamol/ch17-truth-app .`  ` # 运行应用并尝试使用它:` ` docker container run -d
    -p 8010:80 --name truth diamol/ch17-truth-app` ` curl http://localhost:8010/truth`'
- en: The container you’re running has the Java REST API, which is compiled in the
    image, but it also has all the tools to compile other Java apps. If an attacker
    manages to break out of the app and run arbitrary commands on the container, they
    could run their own code to do whatever they liked. In this image I’ve “accidentally”
    included a test code file, and a malicious user could find and run that to change
    the app’s behavior.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您正在运行的容器包含 Java REST API，该 API 在镜像中编译，但它也包含所有编译其他 Java 应用程序的工具。如果攻击者设法从应用中突破并运行任意命令，他们可以运行自己的代码，在您的应用容器安全上下文中做任何他们想做的事情。在这个镜像中，我“意外”包含了一个测试代码文件，恶意用户可以找到并运行它来改变应用的行为。
- en: 'try it now Simulate a container breakout by connecting to a shell in your API
    container. Then use the JDK to compile and run the test code and check the app
    again afterwards:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 通过连接到您的 API 容器中的 shell 来模拟容器突破。然后使用 JDK 编译并运行测试代码，之后再次检查应用：
- en: '` # connect to the API container - for Linux containers:` ` docker container
    exec -it truth sh`  ` # OR for Windows containers:` ` docker container exec -it
    truth cmd`  ` # inside the container compile and run the test Java file:` ` javac
    FileUpdateTest.java` ` java FileUpdateTest` ` exit`  ` # back on your machine,
    try the API again:` ` curl http://localhost:8010/truth`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 连接到 API 容器 - 对于 Linux 容器:` ` docker container exec -it truth sh`  ` # 或者对于
    Windows 容器:` ` docker container exec -it truth cmd`  ` # 在容器内编译并运行测试 Java 文件:`
    ` javac FileUpdateTest.java` ` java FileUpdateTest` ` exit`  ` # 回到您的机器上，再次尝试
    API:` ` curl http://localhost:8010/truth`'
- en: You’ll see that the behavior of the app has changed--the test fixture sets the
    response to be `false` instead of `true` . My output in figure 17.5 shows the
    original response and the changed response after the “hack.”
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您会看到应用的行为已经改变--测试用例将响应设置为 `false` 而不是 `true`。图 17.5 中的输出显示的是“黑客”之前的原始响应和改变后的响应。
- en: '![](../Images/17-5.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/17-5.jpg)'
- en: Figure 17.5 Having the SDK in your app image leaves you open to arbitrary code
    execution attacks.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.5 在您的应用镜像中包含 SDK 会让您面临任意代码执行攻击。
- en: This is a slightly contrived example with the handy test file lying around in
    the image to make things easy, but container breakouts are possible, and this
    illustrates an interesting attack option. The container could be locked down by
    the platform to prevent network access, and this attack would still work. The
    lesson is that your base image should have all you need to run your app, but no
    extra tooling for building apps (interpreted languages like Node.js and Python
    are an exception because the build tools are necessary for the app to run).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个稍微有些牵强的例子，因为测试文件就在镜像中，使得事情变得简单，但容器突破是可能的，这展示了有趣的攻击选项。平台可以将容器锁定以防止网络访问，但这种攻击仍然有效。教训是，您的基镜像应该包含运行您的应用所需的一切，但不要包含构建应用（如
    Node.js 和 Python 这样的解释型语言需要构建工具才能运行）的额外工具。
- en: Golden images are one way around this problem. You have a team that chooses
    the right base images and builds their own versions for your organization. I use
    that approach for this book--my Java apps are built from `diamol/openjdk` , which
    is a multi-arch image that uses the smallest variant for each OS. I can control
    how often my golden image gets updated, and I can trigger application image builds
    after the golden image builds. Another advantage of building your own golden image
    is that you can integrate additional security checks on the base layer in the
    build process, using a third-party tool like Anchore.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 金色镜像是一种绕过这个问题的方法。你有一个团队选择合适的基镜像并为你组织构建自己的版本。我在这本书中采用了这种方法--我的 Java 应用程序是从 `diamol/openjdk`
    构建的，这是一个多架构镜像，为每个操作系统使用最小的变体。我可以控制我的金色镜像更新的频率，并且可以在金色镜像构建后触发应用程序镜像的构建。自己构建金色镜像的另一个优点是，你可以在构建过程中使用第三方工具如
    Anchore 在基层集成额外的安全检查。
- en: Try It Now Anchore is an open source project for analyzing Docker images. The
    analyzer components run in Docker containers, but unfortunately they don’t have
    multi-arch support. If you’re running Linux containers on Intel (with Docker Desktop
    or Community Engine) you’re supported; otherwise you can spin up a PWD session
    and clone the book’s GitHub repo for this exercise.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 Anchore 是一个用于分析 Docker 镜像的开源项目。分析组件在 Docker 容器中运行，但不幸的是，它们没有多架构支持。如果你在
    Intel（使用 Docker Desktop 或 Community Engine）上运行 Linux 容器，你将得到支持；否则，你可以启动一个 PWD
    会话并克隆这本书的 GitHub 仓库来完成这个练习。
- en: '` cd ch17/exercises/anchore`  ` # start all the Anchore components:` ` docker-compose
    up -d`  ` # wait for Anchore to download its database - this can take 15 minutes,` 
    ` # so you might want to open a new terminal window for this command:` ` docker
    exec anchore_engine-api_1 anchore-cli system wait`  ` # now copy the Dockerfile
    for my Java golden image into the container:` ` docker container cp "$(pwd)/../../../images/openjdk/Dockerfile"
    anchore_engine-api_1:/Dockerfile`  ` # and add the image and the Dockerfile for
    Anchore to analyze:` ` docker container exec anchore_engine-api_1 anchore-cli
    image add diamol/openjdk --dockerfile /Dockerfile`  ` # wait for the analysis
    to complete:` ` docker container exec anchore_engine-api_1 anchore-cli image wait
    diamol/openjdk`'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '` cd ch17/exercises/anchore`  ` # 启动所有 Anchore 组件:` ` docker-compose up -d` 
    ` # 等待 Anchore 下载其数据库 - 这可能需要 15 分钟，`  ` # 因此你可能想为这个命令打开一个新的终端窗口:` ` docker exec
    anchore_engine-api_1 anchore-cli system wait`  ` # 现在将我的 Java 金色镜像的 Dockerfile
    复制到容器中:` ` docker container cp "$(pwd)/../../../images/openjdk/Dockerfile" anchore_engine-api_1:/Dockerfile` 
    ` # 为 Anchore 添加镜像和 Dockerfile 以进行分析:` ` docker container exec anchore_engine-api_1
    anchore-cli image add diamol/openjdk --dockerfile /Dockerfile`  ` # 等待分析完成:` ` docker
    container exec anchore_engine-api_1 anchore-cli image wait diamol/openjdk`'
- en: It takes a while for Anchore to fully start up because it downloads a database
    of known security issues on the first run. Typically you’d integrate Anchore into
    your CI/CD process, so this hit would only happen when you first deploy it. The
    `wait` commands will keep your session blocked until Anchore is ready--you can
    see in figure 17.6 that I’ve added my OpenJDK image for scanning, but it hasn’t
    been analyzed yet.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Anchore 完全启动需要一段时间，因为第一次运行时会下载已知安全问题的数据库。通常，你会将 Anchore 集成到你的 CI/CD 流程中，所以这种影响只会发生在你第一次部署它时。`wait`
    命令将保持你的会话阻塞，直到 Anchore 准备就绪--你可以在图 17.6 中看到我已经添加了我的 OpenJDK 镜像以进行扫描，但它还没有被分析。
- en: '![](../Images/17-6.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/17-6.jpg)'
- en: Figure 17.6 Using Anchore to analyze Docker images for known issues
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.6 使用 Anchore 分析已知问题的 Docker 镜像
- en: When Anchore completes its analysis, it knows an awful lot about your image,
    including the open source licenses used by all the components in the image, through
    to the operating system and application platform details, to security issues for
    any binaries in the image. Those findings could all be part of the quality gate
    for accepting an updated base image. If the new version uses an OSS license your
    organization prohibits, or if it includes critical security vulnerabilities, you
    might skip that update. Anchore has plugins for CI/CD tools like Jenkins, so you
    can apply those policies automatically in your pipeline, and you can also query
    the results directly using the Anchore API container.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Anchore 完成分析后，它对你的镜像了解得很多，包括镜像中所有组件使用的开源许可证，一直到操作系统和应用程序平台细节，以及镜像中任何二进制的安全问题。这些发现都可能成为接受更新基镜像的质量关卡的一部分。如果新版本使用了你组织禁止的
    OSS 许可证，或者它包括关键的安全漏洞，你可能会跳过这次更新。Anchore 为 Jenkins 等CI/CD 工具提供了插件，因此你可以在你的管道中自动应用这些策略，你也可以直接使用
    Anchore API 容器查询结果。
- en: 'Try It Now When the wait command from the previous exercise finishes, the image
    has been analyzed. Check what Anchore has discovered about the application platform
    and the image’s security issues:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 当上一个练习中的等待命令完成后，镜像已经被分析。检查Anchore关于应用程序平台和镜像安全问题的发现：
- en: '` # check what Java components Anchore has found in the image:` ` docker container
    exec anchore_engine-api_1 anchore-cli image content diamol/openjdk java`  ` #
    and check for known security issues:` ` docker container exec anchore_engine-api_1
    anchore-cli image vuln diamol/openjdk all`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 检查Anchore在镜像中发现的Java组件：` ` docker container exec anchore_engine-api_1 anchore-cli
    image content diamol/openjdk java`  ` # 并检查已知的安全问题：` ` docker container exec anchore_engine-api_1
    anchore-cli image vuln diamol/openjdk all`'
- en: These are just samples of the output that Anchore can give you--in this case
    it has the details of the Java runtime in the image and a large list of security
    vulnerabilities. At the time of writing, those vulnerabilities all had negligible
    severity--meaning they don’t pose a significant threat, and you can probably accept
    them in your image. The output includes a link to the details of the vulnerability
    so you can read more and decide for yourself. Figure 17.7 shows the partial output
    from my scan results.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是Anchore可以提供的一些输出样本--在这种情况下，它提供了镜像中Java运行时的详细信息以及一个庞大的安全漏洞列表。在撰写本文时，这些漏洞的严重性都是可忽略的--这意味着它们不构成重大威胁，你可能在你的镜像中接受它们。输出包括一个链接到漏洞详细信息的链接，你可以阅读更多内容并自行决定。图17.7显示了扫描结果的局部输出。
- en: '![](../Images/17-7.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/17-7.jpg)'
- en: Figure 17.7 Anchore checks all the binaries in the image against its database
    of security vulnerabilities.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.7 Anchore将其数据库中的所有安全漏洞与镜像中的所有二进制文件进行比对。
- en: These results are acceptable because I’ve selected the minimal OpenJDK base
    image for my golden image. If you add the official `openjdk:11-jdk` image to Anchore
    and check the results, you’ll see it has many more vulnerabilities, a lot with
    “unknown” severity and one “low” severity for the core SSL security library. That
    might not be acceptable, so you’ll want to stop users basing their apps on that
    image, even though it’s an official one maintained by the OpenJDK team.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果是可接受的，因为我已经为我的黄金镜像选择了最小的OpenJDK基镜像。如果你将官方的`openjdk:11-jdk`镜像添加到Anchore并检查结果，你会看到它有更多的漏洞，很多是“未知”严重性，还有一个“低”严重性的核心SSL安全库。这可能不是可接受的，所以你可能希望阻止用户基于该镜像构建他们的应用，即使它是由OpenJDK团队维护的官方镜像。
- en: Anchore is just one technology in this space--you can get similar features from
    open source projects you run yourself (like Clair), or commercial projects that
    can be integrated with your Docker registry (like Aqua). Tools like this really
    help you understand the security of your images and give you confidence in the
    set of golden images you build. You can run these tools on your app images too,
    and one of the policies you should check is that every app is building from one
    of your own golden images. That enforces the use of your curated, approved images.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Anchore只是这个领域中的一个技术--你可以从你自己运行的开源项目中获得类似的功能（如Clair），或者可以与你的Docker注册表集成的商业项目（如Aqua）。这样的工具真的可以帮助你了解镜像的安全性，并对你构建的黄金镜像集有信心。你还可以在应用镜像上运行这些工具，你应该检查的一个策略是每个应用都应从你自己的黄金镜像中构建。这强制使用你精选和批准的镜像。
- en: 17.3 Minimizing image layer count and layer size
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17.3 最小化镜像层数量和层大小
- en: A minimal and secure base image is the prerequisite for getting your app images
    optimized. The next step is really about setting up your image with everything
    your app needs and nothing else--which is a much deeper sentence than it sounds.
    Many processes for installing software leave residues behind because they cache
    package lists or deploy extra recommended packages. You can keep those under control--the
    details are different for different operating systems, but the general approach
    is the same.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一个最小化和安全的基镜像是你优化应用镜像的前提。下一步真正要做的是设置包含你应用所需一切内容且不包含其他内容的镜像--这比听起来要深奥得多。许多安装软件的过程会在后面留下残留物，因为它们缓存了软件包列表或部署了额外的推荐软件包。你可以控制这些内容--对于不同的操作系统，细节可能不同，但总体方法是一样的。
- en: 'Try it now Debian Linux uses APT (Advanced Package Tool) to install software.
    This exercise uses a simple example to show how removing unnecessary packages
    and clearing out the package list provides big savings (this exercise won’t work
    with Windows containers--Play with Docker is an option instead):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看，Debian Linux 使用 APT（高级包工具）来安装软件。本练习通过一个简单的例子来展示如何移除不必要的软件包和清理软件包列表可以节省大量空间（本练习在
    Windows 容器中无法工作--可以选择使用 Play with Docker）：
- en: '` cd ch17/exercises/socat` ` # the v1 image installs packages using standard
    apt-get commands:` ` docker image build -t diamol/ch17-socat:v1 .`  ` # v2 installs
    the same packages but using optimization tweaks:` ` docker image build -t diamol/ch17-socat:v2
    -f Dockerfile.v2 .`  ` # check the image sizes:` ` docker image ls -f reference=diamol/ch17-socat`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '` cd ch17/exercises/socat` ` # v1 镜像使用标准的 apt-get 命令安装软件包：` ` docker image
    build -t diamol/ch17-socat:v1 .`  ` # v2 镜像安装相同的软件包，但使用了优化调整：` ` docker image
    build -t diamol/ch17-socat:v2 -f Dockerfile.v2 .`  ` # 检查镜像大小：` ` docker image
    ls -f reference=diamol/ch17-socat`'
- en: Both versions of the Dockerfile install the same two tools--curl and socat--on
    top of the same Debian Slim image, and they’re both functionally exactly the same.
    But you’ll see that the v2 image is almost 20 MB smaller, as my output in figure
    17.8 shows.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 两个版本的 Dockerfile 都在相同的 Debian Slim 镜像上安装了相同的两个工具--curl 和 socat，并且它们的功能完全相同。但你将看到
    v2 镜像几乎小了 20 MB，如图 17.8 所示。
- en: I used just a couple of tweaks to the install commands to get that saving. The
    first makes use of an APT feature to install only the listed packages and not
    any recommendations. The second is to combine the install steps into a single
    `RUN` instruction, which ends with a command to delete the package list cache
    and free up that disk space. Listing 17.3 shows the difference between the Dockerfiles.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我只是对安装命令进行了一些调整，就实现了节省空间。第一个调整是利用 APT 的一个特性，只安装列出的软件包而不安装任何推荐软件包。第二个调整是将安装步骤合并为一个
    `RUN` 指令，该指令以删除软件包列表缓存并释放磁盘空间的命令结束。列表 17.3 展示了 Dockerfile 之间的差异。
- en: Listing 17.3 Installing software packages--the wrong way and the optimized way
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 17.3 安装软件包--错误的方式和优化的方式
- en: '` # Dockerfile - the naive install with APT:` ` FROM debian:stretch-slim` ` RUN
    apt-get update` ` RUN apt-get install -y curl=7.52.1-5+deb9u9` ` RUN apt-get install
    -y socat=1.7.3.1-2+deb9u1`  ` # Dockerfile.v2 - optimizing the install steps:`
    ` FROM debian:stretch-slim` ` RUN apt-get update \` ` && apt-get install -y --no-install-recommends
    \` `       curl=7.52.1-5+deb9u9 \` `       socat=1.7.3.1-2+deb9u1 \` `   && rm
    -rf /var/lib/apt/lists/*`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '` # Dockerfile - 使用 APT 的简单安装：` ` FROM debian:stretch-slim` ` RUN apt-get update`
    ` RUN apt-get install -y curl=7.52.1-5+deb9u9` ` RUN apt-get install -y socat=1.7.3.1-2+deb9u1` 
    ` # Dockerfile.v2 - 优化安装步骤：` ` FROM debian:stretch-slim` ` RUN apt-get update
    \` ` && apt-get install -y --no-install-recommends \` `       curl=7.52.1-5+deb9u9
    \` `       socat=1.7.3.1-2+deb9u1 \` `   && rm -rf /var/lib/apt/lists/*`'
- en: Another advantage of combining multiple steps in a single `RUN` instruction
    is that it produces a single image layer. Reducing the number of image layers
    isn’t really an optimization. There is a maximum layer count, but it should be
    plenty big enough--typically 127 depending on the OS. But having fewer layers
    does make it much easier to keep track of your filesystem. It would be easy to
    put the final `rm` command to delete the package lists into its own `RUN` instruction,
    and arguably that makes the Dockerfile easier to read. But you know from this
    chapter that deleting files from a previous layer simply hides them from the filesystem,
    so if you did that there would be no saving on disk space.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 将多个步骤合并到一个 `RUN` 指令中的另一个优点是它会产生一个单独的镜像层。减少镜像层的数量并不是真正的优化。镜像层的最大数量是有限的，但通常足够大--通常是
    127 层，这取决于操作系统。但拥有更少的层确实使得跟踪文件系统变得容易得多。将删除软件包列表的最终 `rm` 命令放入自己的 `RUN` 指令中是很简单的，并且可以说这使
    Dockerfile 更易于阅读。但你从本章中知道，从之前的层中删除文件只是将它们从文件系统中隐藏起来，所以如果你这样做，就不会节省磁盘空间。
- en: Let’s look at one more example of this pattern, which applies across all platforms.
    Often you need to download a package from the internet that is compressed, and
    then expand it. It’s tempting to put the download step in a separate instruction
    while you’re working on the Dockerfile, so you can work with the cached download
    layer and speed up your development time. That’s fine, but once your Dockerfile
    is working, you need to go through and tidy up afterwards, to combine the download-expand-delete
    steps into a single instruction.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看看一个适用于所有平台的这种模式的例子。通常你需要从互联网下载一个压缩的软件包，然后展开它。当你正在处理Dockerfile时，将下载步骤放在单独的指令中是很诱人的，这样你可以使用缓存的下载层并加快你的开发时间。这很好，但一旦你的Dockerfile开始工作，你需要进行整理，将下载-展开-删除步骤合并成一个指令。
- en: '![](../Images/17-8.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17-8.jpg)'
- en: Figure 17.8 Optimizing software installs reduces the image size in this exercise
    by over 20%.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.8 在这个练习中，优化软件安装将图像大小减少了20%以上。
- en: Try it now Machine-learning datasets are a good example here, because they are
    large downloads that expand to even larger folder structures. In the exercises
    for this chapter there’s an example that downloads a dataset from the University
    of California at Irvine (UCI) archives and extracts just one file from the dataset.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 机器学习数据集是一个很好的例子，因为它们是大型下载，会扩展到更大的文件夹结构。在本章的练习中，有一个例子是从加州大学欧文分校（UCI）的存档中下载一个数据集，并从中提取一个文件。
- en: '` cd ch17/exercises/ml-dataset`  ` # v1 downloads and expands the archive,
    then deletes unnecessary files:` ` docker image build -t diamol/ch17-ml-dataset:v1
    .`  ` # v2 downloads the archive but only expands the necessary file:` ` docker
    image build -t diamol/ch17-ml-dataset:v2 -f Dockerfile.v2 .`  ` # compare the
    sizes:` ` docker image ls -f reference=diamol/ch17-ml-dataset`'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '` cd ch17/exercises/ml-dataset`  ` # v1 下载并展开存档，然后删除不必要的文件：` ` docker image
    build -t diamol/ch17-ml-dataset:v1 .`  ` # v2 下载存档，但只展开必要的文件：` ` docker image
    build -t diamol/ch17-ml-dataset:v2 -f Dockerfile.v2 .`  ` # 比较大小：` ` docker image
    ls -f reference=diamol/ch17-ml-dataset`'
- en: You’ll see a massive size difference, which is purely because of the same optimization
    technique--making sure the layers don’t have any more files than they need. My
    results are in figure 17.9--both images have the same single file from the data
    download, but one is nearly 2.5 GB and the other is only 24 MB.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到巨大的大小差异，这完全是由于相同的优化技术——确保层不需要比它们需要的更多文件。我的结果在图17.9中——两个图像都有从数据下载的单个文件，但一个接近2.5
    GB，另一个只有24 MB。
- en: '![](../Images/17-9.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/17-9.jpg)'
- en: Figure 17.9 Paying close attention to how you work with files can save huge
    amounts of disk space.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细关注你如何处理文件可以节省大量的磁盘空间。
- en: This is not such a contrived example. It’s pretty common when you’re iterating
    on a Dockerfile to keep instructions separate because that makes it easier to
    debug--you can run a container from a layer partway through the build and investigate
    the filesystem, and you can work on later instructions but keep the cached download.
    You can’t do that when you’ve compressed multiple commands into one `RUN` instruction,
    but it’s important to make that optimization once you’re happy with your build.
    Listing 17.4 shows the optimized Dockerfile, which produces a single layer for
    the data file (the download URL is abbreviated here, but you’ll see it in the
    source code for the chapter).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个虚构的例子。当你迭代Dockerfile时，将指令分开是很常见的，因为这可以更容易地进行调试——你可以在构建过程中从某个层运行容器并调查文件系统，你可以在后续指令上工作，同时保留缓存的下载。当你将多个命令压缩到一个`RUN`指令中时，你无法这样做，但当你对构建满意时，进行这种优化是很重要的。列表17.4显示了优化的Dockerfile，它为数据文件生成单个层（下载URL在此处被缩写，但你将在章节的源代码中看到它）。
- en: Listing 17.4 An optimized method for downloading and extracting files
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 列表17.4 下载和提取文件的优化方法
- en: '` FROM diamol/base`  ` ARG DATASET_URL=https://archive.ics.uci.edu/.../url_svmlight.tar.gz` 
    ` WORKDIR /dataset`  ` RUN wget -O dataset.tar.gz ${DATASET_URL} && \` `       tar
    -xf dataset.tar.gz url_svmlight/Day1.svm && \` `         rm -f dataset.tar.gz`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '` FROM diamol/base`  ` ARG DATASET_URL=https://archive.ics.uci.edu/.../url_svmlight.tar.gz` 
    ` WORKDIR /dataset`  ` RUN wget -O dataset.tar.gz ${DATASET_URL} && \` `       tar
    -xf dataset.tar.gz url_svmlight/Day1.svm && \` `         rm -f dataset.tar.gz`'
- en: The biggest saving here is not actually from deleting the archive; it’s from
    extracting just the single file. The v1 approach expands the whole archive (which
    is where the 2 GB of disk space goes) and then deletes all the files except the
    desired one. Knowing how your tools behave and which features minimize disk usage
    helps you keep your layer size under control, as you’ve seen with tar in this
    example and APT in the previous one.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里最大的节省实际上并不是来自删除存档；而是仅仅提取单个文件。v1方法会展开整个存档（这就是2GB磁盘空间被占用的原因），然后删除所有文件，除了所需的那个。了解你的工具如何工作以及哪些特性可以最小化磁盘使用量，有助于你将层的大小控制在合理范围内，就像在这个例子中用tar和在之前的例子中使用APT所看到的那样。
- en: There is an alternative approach to this scenario that gives you the best developer
    workflow and an optimized final image, and that’s using multi-stage Dockerfiles
    with separate stages for all the disk-hungry steps.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种情况，还有一种替代方法可以提供最佳的开发者工作流程和优化的最终镜像，那就是使用具有单独阶段的所有磁盘密集型步骤的多阶段Dockerfile。
- en: 17.4 Taking your multi-stage builds to the next level
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17.4 将你的多阶段构建提升到下一个水平
- en: You first saw multi-stage builds in chapter 4 where we used one stage to compile
    an app from source code, and a later stage to package the compiled binaries for
    runtime. Multi-stage Dockerfiles should be a best practice for all but the simplest
    images, because they make it far easier to optimize the final image.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 你第一次在第四章中看到多阶段构建，我们使用一个阶段从源代码编译应用程序，在后面的阶段中打包编译的二进制文件以供运行时使用。对于所有除了最简单的镜像之外的所有镜像，多阶段Dockerfile应该是一个最佳实践，因为它们使得优化最终的镜像变得容易得多。
- en: We can revisit the dataset downloader and use separate stages for each of the
    steps. Listing 17.5 shows we get a much more readable Dockerfile that way (the
    download URL is abbreviated again).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以重新审视数据集下载器，并为每个步骤使用单独的阶段。列表17.5显示了这样做的Dockerfile会更加易于阅读（下载URL再次被缩写）。
- en: Listing 17.5 Multi-stage Dockerfiles aid readability and simplify optimization
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 列表17.5 多阶段Dockerfile有助于提高可读性并简化优化
- en: '` FROM diamol/base AS download` ` ARG DATASET_URL=https://archive.ics.uci.edu/.../url_svmlight.tar.gz`
    ` RUN wget -O dataset.tar.gz ${DATASET_URL}`  ` FROM diamol/base AS expand` ` COPY
    --from=download dataset.tar.gz .` ` RUN tar xvzf dataset.tar.gz`  ` FROM diamol/base`
    ` WORKDIR /dataset/url_svmlight` ` COPY --from=expand url_svmlight/Day1.svm .`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '` FROM diamol/base AS download` ` ARG DATASET_URL=https://archive.ics.uci.edu/.../url_svmlight.tar.gz`
    ` RUN wget -O dataset.tar.gz ${DATASET_URL}`  ` FROM diamol/base AS expand` ` COPY
    --from=download dataset.tar.gz .` ` RUN tar xvzf dataset.tar.gz`  ` FROM diamol/base`
    ` WORKDIR /dataset/url_svmlight` ` COPY --from=expand url_svmlight/Day1.svm .`'
- en: It’s clear in each stage what you’re doing, and you don’t need to dive into
    unusual command optimizations to save disk space, because the final image will
    only have the files explicitly copied in from earlier stages. When you build v3,
    you’ll find it’s the same size as the optimized v2 version, but it has the advantage
    of being easy to debug. Multi-stage Dockerfiles can be built up to a specific
    stage, so if you need to check the filesystem partway through the build, you can
    easily do so without trawling image histories to find layer IDs.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个阶段中都很清楚你在做什么，你不需要深入研究不寻常的命令优化来节省磁盘空间，因为最终的镜像将只包含从早期阶段显式复制进来的文件。当你构建v3版本时，你会发现它与优化后的v2版本大小相同，但它有一个优点，那就是易于调试。多阶段Dockerfile可以构建到特定的阶段，所以如果你需要在构建过程中检查文件系统，你可以轻松地做到这一点，而无需在镜像历史中搜索层ID。
- en: 'Try it Now The `target` parameters let you stop a multi-stage build at a specific
    stage. Try building that v3 image with different targets:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 `target` 参数让你可以在特定阶段停止多阶段构建。尝试使用不同的目标构建那个v3镜像：
- en: '` cd ch17/exercises/ml-dataset`  ` # build the full v3 image:` ` docker image
    build -t diamol/ch17-ml-dataset:v3 -f Dockerfile.v3 .`  ` # build to the ''download''
    target - same Dockerfile, different tag:` ` docker image build -t diamol/ch17-ml-dataset:v3-download
    -f Dockerfile.v3 --target download .`  ` # and build to the ''expand'' target:`
    ` docker image build -t diamol/ch17-ml-dataset:v3-expand -f Dockerfile.v3 --target
    expand .`  ` # check the image sizes:` ` docker image ls -f reference=diamol/ch17-ml-dataset:v3*`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '` cd ch17/exercises/ml-dataset`  ` # 构建完整的v3镜像：` ` docker image build -t diamol/ch17-ml-dataset:v3
    -f Dockerfile.v3 .`  ` # 构建到 ''download'' 目标 - 相同的Dockerfile，不同的标签：` ` docker
    image build -t diamol/ch17-ml-dataset:v3-download -f Dockerfile.v3 --target download
    .`  ` # 并构建到 ''expand'' 目标：` ` docker image build -t diamol/ch17-ml-dataset:v3-expand
    -f Dockerfile.v3 --target expand .`  ` # 检查镜像大小：` ` docker image ls -f reference=diamol/ch17-ml-dataset:v3*`'
- en: Now you’ll have three variations of the v3 image. The full build is the same
    24 MB as the optimized build, so we haven’t lost any optimization moving to a
    multi-stage Dockerfile. The other variants stop the build at specific stages,
    and you can run a container from one of those images to navigate the filesystem
    if you need to debug. The stage builds also show where the disk space is going--you
    can see in figure 17.10 that the download is around 200 MB, and it expands to
    over 2 GB.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将拥有 v3 图像的三个变体。完整的构建与优化构建相同，都是 24 MB，所以我们没有在迁移到多阶段 Dockerfile 时丢失任何优化。其他变体在特定阶段停止构建，如果你需要调试文件系统，你可以从这些镜像之一运行容器。阶段构建还显示了磁盘空间的使用情况——你可以在图
    17.10 中看到下载大约为 200 MB，并扩展到超过 2 GB。
- en: '![](../Images/17-10.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/17-10.jpg)'
- en: Figure 17.10 Building multi-stage Dockerfiles to specific stages lets you debug
    contents and check sizes.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.10 通过构建到特定阶段的多阶段 Dockerfile，你可以调试内容并检查大小。
- en: This really is the best approach--you get an optimized image, but you can keep
    your Dockerfile instructions simple because you don’t need to clean up disk in
    intermediate stages.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是最好的方法——你得到了一个优化的图像，但你仍然可以保持你的 Dockerfile 指令简单，因为你不需要在中间阶段清理磁盘。
- en: 'One final advantage of multi-stage builds really brings it home: every stage
    has its own build cache. If you need to tweak the `expand` stage, when you run
    the build, the `download` stage will still come from the cache. Maximizing the
    build cache is the final part of optimization, and this is all about the speed
    of building the image.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 多阶段构建的最后一个优点真正地让人印象深刻：每个阶段都有自己的构建缓存。如果你需要调整 `expand` 阶段，当你运行构建时，`download` 阶段仍然来自缓存。最大化构建缓存是优化的最后一部分，这完全关乎构建图像的速度。
- en: The basic way to make the most of the build cache is to order the instructions
    in your Dockerfile so the things that change least frequently are at the start,
    and the things that change most frequently are toward the end. This can take a
    few iterations to get right, because you need to understand how often the steps
    change, but you can typically put static setup like exposed ports, environment
    variables, and the application entry point at the beginning of the file. Things
    that change most are your application binaries and config files, and they can
    go toward the end. Get this right, and you can drastically reduce build times.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 充分利用构建缓存的基本方法是将你的 Dockerfile 中的指令排序，使变化最少的部分放在前面，变化最多的部分放在后面。这需要几次迭代才能正确设置，因为你需要了解步骤变化的频率，但通常你可以在文件开头放置静态设置，如暴露的端口、环境变量和应用程序入口点。变化最多的部分是你的应用程序二进制文件和配置文件，它们可以放在文件末尾。设置正确后，你可以显著减少构建时间。
- en: 'Try it Now This exercise builds a minimal Jenkins install. It’s incomplete,
    so don’t try to run it--we’re just using it for builds. The Dockerfile downloads
    the Jenkins Java file and sets up the initial config. The v2 Dockerfile makes
    good use of the cache, which you’ll see when you make a content change:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 这个练习构建了一个最小的 Jenkins 安装。它是不完整的，所以不要尝试运行它——我们只是用它来进行构建。Dockerfile 下载 Jenkins
    Java 文件并设置初始配置。v2 Dockerfile 充分利用了缓存，当你进行内容更改时你会看到：
- en: '` cd ch17/exercises/jenkins`  ` # build the v1 image and the optimized v2 image:`
    ` docker image build -t diamol/ch17-jenkins:v1 .` ` docker image build -t diamol/ch17-jenkins:v2
    -f Dockerfile.v2 .`  ` # now change the config file both Dockerfiles use:` ` echo
    2.0 > jenkins.install.UpgradeWizard.state`  ` # repeat the builds and see how
    long they run:` ` docker image build -t diamol/ch17-jenkins:v1 .` ` docker image
    build -t diamol/ch17-jenkins:v2 -f Dockerfile.v2 .`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '` cd ch17/exercises/jenkins`  ` # 构建 v1 图像和优化的 v2 图像：` ` docker image build
    -t diamol/ch17-jenkins:v1 .` ` docker image build -t diamol/ch17-jenkins:v2 -f
    Dockerfile.v2 .`  ` # 现在更改两个 Dockerfile 都使用的配置文件：` ` echo 2.0 > jenkins.install.UpgradeWizard.state`
     ` # 重复构建并查看它们运行的时间：` ` docker image build -t diamol/ch17-jenkins:v1 .` ` docker
    image build -t diamol/ch17-jenkins:v2 -f Dockerfile.v2 .`'
- en: The second round of builds is where the cache comes in. The v1 Dockerfile copies
    the config file into the image before downloading the Jenkins file (which is a
    75 MB download), so when the config file changes, that busts the cache and the
    download happens all over again. The v2 Dockerfile uses a multi-stage build and
    orders the instructions to put the config file copy last. I ran my exercise using
    the `Measure-Command` function in PowerShell to check the duration of each build
    (there’s an equivalent called `time` in Linux). You can see in figure 17.11 that
    correctly ordering instructions and using a multi-stage Dockerfile cuts the build
    time from 10+ seconds to under a second.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 第二轮构建是缓存发挥作用的地方。v1 Dockerfile在下载Jenkins文件（这是一个75 MB的下载）之前将配置文件复制到镜像中，所以当配置文件发生变化时，它会破坏缓存，下载就会重新开始。v2
    Dockerfile使用多阶段构建并将指令顺序设置为将配置文件复制放在最后。我使用PowerShell中的`Measure-Command`函数来检查每个构建的持续时间（Linux中有一个等效的`time`命令）。你可以在图17.11中看到，正确排序指令和使用多阶段Dockerfile可以将构建时间从10多秒缩短到不到一秒。
- en: '![](../Images/17-11.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图17.11](../Images/17-11.jpg)'
- en: Figure 17.11 Ordering your Dockerfile instructions correctly can mean huge savings
    in build time.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.11 正确排序Dockerfile指令可以意味着在构建时间上的巨大节省。
- en: Making good use of the cache lets you build and push Docker images from every
    change to source control without soaking up time in the CI/CD pipeline. You do
    need to make sure you don’t over-cache things, though, because if you install
    or download software using `RUN` instructions, they will be cached until the instruction
    changes in the Dockerfile (assuming the cache isn’t busted before that instruction).
    You should always use explicit versions when you add packages to your image, so
    you know exactly what you’re running, and you can choose when to update. The socat
    example in listing 17.3 used explicit version numbers in the APT commands, and
    the Jenkins example used an `ARG` instruction for the version to download--both
    approaches let you use the cache until you change the versions to install.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 充分利用缓存可以让你在每次从源代码控制中更改时构建和推送Docker镜像，而不会在CI/CD管道中消耗时间。不过，你确实需要确保不要过度缓存东西，因为如果你使用`RUN`指令安装或下载软件，它们将被缓存，直到Dockerfile中的指令发生变化（假设在那些指令之前缓存没有被破坏）。当你向你的镜像添加包时，你应该始终使用显式版本，这样你就能确切知道你在运行什么，并且你可以选择何时更新。列表17.3中的socat示例在APT命令中使用了显式版本号，而Jenkins示例使用了`ARG`指令来下载版本——这两种方法都让你能够在更改安装的版本之前使用缓存。
- en: 17.5 Understanding why optimization counts
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17.5 理解优化为何重要
- en: You’ve seen in this chapter that you can follow some simple best practices and
    make your Dockerfiles a joy to work with. Those practices boil down to
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 你在本章中看到，你可以遵循一些简单的最佳实践，让你的Dockerfile变得易于使用。这些实践归结为
- en: Choose the right base image--ideally curate your own set of golden images.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择正确的基镜像——理想情况下，精心挑选你自己的黄金镜像集合。
- en: Use multi-stage Dockerfiles for all but the simplest apps.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于所有除了最简单的应用之外，都使用多阶段Dockerfile。
- en: Don’t add any unnecessary packages or files--focus on layer size.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要添加任何不必要的包或文件——关注层的大小。
- en: Sort your Dockerfile instructions by change frequency--maximize the cache.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按变更频率对Dockerfile指令进行排序——最大化缓存。
- en: Building, pushing, and pulling images becomes a core part of your organization’s
    workflow as you move more apps to containers. Optimizing those images can remove
    a lot of pain points, speed up workflows, and prevent more serious issues. Figure
    17.12 shows the typical life cycle of an image, and the areas where optimization
    counts.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你将更多应用迁移到容器，构建、推送和拉取镜像成为你组织工作流程的核心部分。优化这些镜像可以消除许多痛点，加快工作流程，并防止更严重的问题。图17.12显示了镜像的典型生命周期以及优化起作用的地方。
- en: '![](../Images/17-12.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图17.12](../Images/17-12.jpg)'
- en: Figure 17.12 Optimizing your Docker images has beneficial impacts across the
    life cycle of your projects.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.12 优化你的Docker镜像对你的项目生命周期有积极的影响。
- en: 17.6 Lab
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 17.6 实验室
- en: Now it’s time to put your optimization skills to the test. Your goal is to optimize
    an image that installs the Docker command line. There are Linux and Windows examples
    in the lab folder for this chapter; the Dockerfiles work right now, but they produce
    unnecessarily large images. Your goals are to
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候测试你的优化技能了。你的目标是优化一个安装Docker命令行的镜像。本章的实验室文件夹中有Linux和Windows的示例；Dockerfile目前工作正常，但它们产生了不必要的大的镜像。你的目标是
- en: Optimize the filesystem so the image is under 80 MB for Linux containers, or
    under 330 MB for Windows containers.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化文件系统，使得Linux容器镜像小于80 MB，或Windows容器镜像小于330 MB。
- en: Make use of the image layer cache, so repeat builds of your image take less
    than a second.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用图像层缓存，这样你的图像重复构建所需时间将少于1秒。
- en: Produce an image that writes the Docker CLI version correctly from `docker`
    `container` `run` `<image>` `docker` `version` (the command will give you an error
    for the server because it’s not connected to a Docker Engine, but the CLI version
    should print correctly).
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成一个能够正确写入Docker CLI版本的镜像，从`docker` `container` `run` `<image>` `docker` `version`（该命令会因为服务器未连接到Docker
    Engine而报错，但CLI版本应该能够正确打印）。
- en: You shouldn’t need any hints, but you’ll need to think creatively when you look
    at the original Dockerfiles. You might not get there optimizing the existing instructions;
    it might be better to work backwards from the goals for the image.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不需要任何提示，但在查看原始Docker文件时需要具有创造性思维。你可能不会通过优化现有指令达到目标；可能从图像的目标反向工作会更好。
- en: 'My optimized files are in the same lab folder--you can also check them on GitHub:
    *[https://github.com/sixeyed/diamol/blob/master/ch17/lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch17/lab/README.md)*
    .'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我的优化文件在同一个实验文件夹中--你还可以在GitHub上查看它们：[https://github.com/sixeyed/diamol/blob/master/ch17/lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch17/lab/README.md)。
- en: You have the knowledge, now go optimize!
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经有了知识，现在去优化吧！
