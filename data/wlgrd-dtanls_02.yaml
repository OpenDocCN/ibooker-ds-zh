- en: 3 Data modeling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 数据建模
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Modeling data as a fundamental analytical activity
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据建模作为基本分析活动
- en: How to define business entities from raw data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何从原始数据中定义业务实体
- en: How to structure a data model to best suit the analytical question
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何构建数据模型以最好地适应分析问题
- en: As an analyst, you will find yourself applying the same logic to raw data over
    and over again. For example, every time you calculate revenue, you might need
    to remember to remove internal money transfers between departments. Or when you
    look at customer spending, you might need to exclude a certain customer because
    they operate differently. Whenever these business rules need to be applied constantly
    to ensure data is accurate, it is a good opportunity to build a *data model*.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名分析师，您将发现自己反复将相同的逻辑应用于原始数据。例如，每次计算收入时，您可能需要记住要删除部门之间的内部资金转移。或者当您查看客户支出时，您可能需要排除某个客户，因为他们运营方式不同。每当这些业务规则需要不断应用以确保数据准确时，这是一个构建*数据模型*的好机会。
- en: A data model is a dataset created from raw data that has been cleaned, with
    specific business rules built into it. Creating reusable data models will save
    you time and maintenance headaches in the future. Data modeling also forces you
    to think deeply about your or your stakeholder’s question, which leads to a more
    valuable answer.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据模型是从经过清洗的原始数据中创建的数据集，其中内置了特定的业务规则。创建可重用的数据模型将在未来节省您的时间和维护烦恼。数据建模还迫使您深入思考您或您的利益相关者的问题，这将导致更有价值的答案。
- en: 'Real business case: Customer deduplication'
  id: totrans-7
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 真实业务案例：客户去重
- en: Once, when working in industry, I spent months on a customer deduplication project.
    We wanted to track the number of customers over time, but our customers were spread
    across multiple databases. Deduplicating them was not a trivial task, especially
    because, in some databases, customers appeared as company names, such as “South
    West Motors,” and in others, they were recorded as individuals, such as “John
    Smith,” with no information about the company they worked for.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 曾经，在我从事行业工作时，我花费了几个月的时间在一个客户去重项目上。我们想要跟踪客户随时间的变化，但我们的客户分布在多个数据库中。去重他们不是一个简单任务，特别是在某些数据库中，客户以公司名称出现，例如“西南汽车”，而在其他数据库中，他们被记录为个人，例如“约翰·史密斯”，没有任何关于他们工作的公司的信息。
- en: In the end, our solution involved text similarity algorithms to find instances
    where “South West Motors” from one database existed as “South West Motors Limited”
    in another. We also used graph theory to link customers together across our company
    network. These are advanced algorithms for the seemingly simple task of counting
    customers. Entity resolution problems are everywhere, which is why this chapter
    explores the topic and lets you practice on a real problem.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们的解决方案涉及文本相似性算法来找到“西南汽车”在一个数据库中存在于另一个数据库中的“西南汽车有限公司”的情况。我们还使用了图论来将客户连接到我们公司的网络中。这些是针对看似简单任务（计数客户）的高级算法。实体解析问题无处不在，这就是为什么本章探讨了该主题，并让您在一个真实的问题上练习。
- en: In this chapter, we will review the fundamentals and importance of data modeling
    and practice converting raw data into a reusable data model using a real-world
    project.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将回顾数据建模的基本原理和重要性，并使用一个真实世界的项目练习将原始数据转换为可重用的数据模型。
- en: 3.1 The importance of data modeling
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 数据建模的重要性
- en: Data modeling is a foundational step in the analytical workflow. It is the process
    of taking raw data, mapping it to business-specific entities, and creating new
    data models. We can think of it as converting data in its raw state to a more
    useful form, which we can call information. Data analysis is then the process
    of converting this information into insight. The intermediate step is required
    because, in its raw form, data is often not ready for analysis. Figure 3.1 shows
    where data modeling fits into both the abstract and concrete versions of a data
    science workflow.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数据建模是分析工作流程的基础步骤。它是将原始数据映射到特定业务实体，并创建新的数据模型的过程。我们可以将其视为将原始状态的数据转换为更有用的形式，我们称之为信息。数据分析随后是将这些信息转换为洞察的过程。这个中间步骤是必需的，因为在原始形式中，数据通常还没有准备好进行分析。图3.1显示了数据建模在数据科学工作流程的抽象和具体版本中的位置。
- en: '![figure](../Images/3-1.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1](../Images/3-1.png)'
- en: Figure 3.1 Data modeling and analysis as mapped to the data science process
  id: totrans-14
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.1 数据建模与分析在数据科学流程中的映射
- en: Your data models should encode any business logic required to transform the
    raw data to be suitable for analysis. If you always need to remember to filter
    out certain rows from your raw data, you should have an intermediate data model
    where that filter has already been applied. What does a “lapsed customer” mean
    for your business? Is it someone who hasn’t purchased anything for a certain time?
    Or perhaps someone who hasn’t even logged in to your platform for a while? Whatever
    that definition, it should be encoded in a data model.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据模型应该编码任何将原始数据转换为适合分析所需的业务逻辑。如果您总是需要记住从原始数据中过滤掉某些行，您应该有一个中间数据模型，其中已经应用了该过滤器。对于您的业务，“流失客户”意味着什么？是有人在一定时间内没有购买任何东西吗？或者可能是有人很久没有登录到您的平台？无论这个定义是什么，它都应该编码在数据模型中。
- en: Creating data models increases transparency because there is a single place
    to look for how a customer, a vehicle, or a purchase event is defined. All other
    analyses should be done using these intermediate models, not the raw data. Another
    benefit is that this kind of cleaner data model could be exposed to data-savvy
    stakeholders to work with directly, thus enabling self-service. Business intelligence
    tools such as Tableau and Power BI allow power users to create their own reports.
    If that is done using centralized data models, analytical mistakes are less likely.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 创建数据模型增加了透明度，因为有一个单一的地方可以查找客户、车辆或购买事件是如何定义的。所有其他分析都应该使用这些中间模型进行，而不是原始数据。另一个好处是这种更干净的数据模型可以被数据熟练的利益相关者直接使用，从而实现自助服务。例如，Tableau和Power
    BI这样的商业智能工具允许高级用户创建自己的报告。如果使用集中式数据模型来完成这项工作，分析错误的可能性就会降低。
- en: As analysts, we should be looking out for opportunities to standardize business
    logic by encoding it in data models. These don’t have to be technically complex
    since they can simply be additional tables in our database. Let’s look at some
    tasks involved in data modeling, which we will then practice in the project.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 作为分析师，我们应该寻找机会通过在数据模型中编码来标准化业务逻辑。这些不必在技术上复杂，因为它们可以简单地是我们数据库中的附加表。让我们看看数据建模中涉及的一些任务，我们将在项目中练习这些任务。
- en: 3.1.1 Common data modeling tasks
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1.1 常见的数据建模任务
- en: Data modeling usually involves some combination of
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据建模通常涉及以下任务的组合
- en: Repetitive data cleaning tasks, such as fixing date formats or converting text
    columns into their numeric equivalents.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复的数据清理任务，例如修复日期格式或将文本列转换为它们的数值等效。
- en: Defining business entities, concepts, and activities.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义业务实体、概念和活动。
- en: Deduplicating the source data.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 去重源数据。
- en: Restructuring the raw data to be in a format more useful to the analytical questions
    it is designed to answer. This might involve making a choice between wide or long
    data, which we will discuss later in this section.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新结构化原始数据，使其更适合于它旨在回答的分析问题。这可能涉及在宽数据或长数据之间做出选择，我们将在本节稍后讨论。
- en: Zooming in or out, altering the level of granularity for different analytical
    questions.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 放大或缩小，改变不同分析问题的粒度级别。
- en: These are all tasks you do not want to perform every time you need to do some
    analysis. They should be done once, and the output should be captured in an appropriate
    data model.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是您不希望在每次进行某些分析时都执行的任务。它们应该只做一次，并且输出应该被捕获在适当的数据模型中。
- en: Agreeing on terminology
  id: totrans-26
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 就术语达成一致
- en: As a junior analyst, you might end up in an industry that you are unfamiliar
    with. It is important to ask questions to clarify the terminology because even
    everyday terms like “customer” might have ambiguous meanings. Does a customer
    mean a single person or an organization? What if your business deals with both?
    Part of the data modeling process is defining these terms so that they can be
    encoded in a data table.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 作为初级分析师，您可能会进入一个您不熟悉的行业。重要的是要提出问题以澄清术语，因为即使是像“客户”这样的日常术语也可能有模糊的含义。客户是指一个人还是一个组织？如果您的业务同时涉及两者怎么办？数据建模过程的一部分是定义这些术语，以便它们可以编码在数据表中。
- en: Note  When it comes to definitions, you cannot work in a vacuum; decisions about
    what concepts mean concretely need to be made in collaboration with your stakeholders.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在定义方面，您不能孤立地工作；关于哪些概念具体含义的决定需要与您的利益相关者合作进行。
- en: Handling duplication
  id: totrans-29
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 处理重复数据
- en: The data you will work with will inevitably contain some duplication, which
    might be in the form of duplicated rows of data or duplicate records across multiple
    systems. If you worked in the automotive industry, you could spend a nontrivial
    amount of time figuring out whether “John Smith Motors” in one database is the
    same customer as “JS Motors” in another. Time invested in reconciling this at
    the data modeling stage is time well spent.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你将要处理的数据不可避免地会包含一些重复，这可能以数据行的重复或多个系统中的重复记录的形式出现。如果你在汽车行业工作，你可能需要花费相当多的时间来确定一个数据库中的“John
    Smith Motors”是否与另一个数据库中的“JS Motors”是同一个客户。在数据建模阶段投入时间进行这种协调是值得的。
- en: Another important data modeling task is deciding the structure of your data,
    such as whether the data should be stored in a wide or a long format.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的数据建模任务是决定你的数据结构，例如数据应该以宽格式还是长格式存储。
- en: Wide vs. long data
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 宽格式与长格式数据
- en: In many cases, your data will consist of one row per entity, such as a customer.
    Each row represents a customer, and each column represents a property or attribute
    of that customer, such as their name, age, department, and so forth. This is called
    a *wide* format because as the number of measurements grows, the data gains additional
    columns.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，你的数据将包含每行一个实体，例如一个客户。每一行代表一个客户，每一列代表该客户的属性或属性，例如他们的名字、年龄、部门等等。这被称为*宽格式*，因为随着测量数量的增长，数据将增加额外的列。
- en: In contrast, *long* data is when one row represents a single measurement of
    an entity. This means an entity, such as a customer, will require multiple rows.
    When a new measurement about the entities is added, the data gains additional
    rows.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，*长格式*数据是指一行代表一个实体的单一测量值。这意味着一个实体，例如一个客户，将需要多行。当关于实体的新测量值被添加时，数据将增加额外的行。
- en: Let’s take a concrete example. Suppose you are working for a sports analytics
    company and want to analyze the factors that go into sports teams that win major
    competitions. Table 3.1 shows the dataset of football results that you have.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个具体的例子来说明。假设你为一家体育数据分析公司工作，并希望分析赢得重大比赛的体育队伍的因素。表3.1显示了你的足球比赛结果数据集。
- en: Table 3.1 Football results in a wide format
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表3.1 宽格式的足球比赛结果
- en: '| Match ID | Date | Competition | Round | Home team | Away team | Home goals
    | Away goals |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 匹配ID | 日期 | 比赛 | 轮次 | 主场球队 | 客场球队 | 主场进球 | 客场进球 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1  | 2014-07-04  | World Cup 2014  | Quarter-final  | France  | Germany  |
    0  | 1  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 1  | 2014-07-04  | 2014年世界杯  | 半决赛  | 法国  | 德国  | 0  | 1  |'
- en: '| 2  | 2014-07-04  | World Cup 2014  | Quarter-final  | Brazil  | Colombia  |
    2  | 1  |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 2  | 2014-07-04  | 2014年世界杯  | 半决赛  | 巴西  | 哥伦比亚  | 2  | 1  |'
- en: '| 3  | 2014-07-05  | World Cup 2014  | Quarter-final  | Argentina  | Belgium  |
    1  | 0  |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 3  | 2014-07-05  | 2014年世界杯  | 半决赛  | 阿根廷  | 比利时  | 1  | 0  |'
- en: This is wide data because each row represents an entity, in this case, a match.
    With some enhancement (for instance, adding a “Winner” column), this dataset would
    allow easy analysis of questions such as “Which country has won the most games
    at a World Cup?”
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种宽格式数据，因为每一行代表一个实体，在这种情况下，是一场比赛。通过一些增强（例如，添加“赢家”列），这个数据集将允许轻松分析诸如“哪个国家在世界杯上赢得的比赛最多？”等问题。
- en: However, what if someone asked, “Which country participated in the most World
    Cup games?” This is trickier because the level of granularity of each row is one
    row per match, so we would have to consider both the “Home team” and “Away team”
    columns. What we would need to answer this second question more easily is one
    row per *participant*. We could consider creating a long-format version of the
    data that would look more like table 3.2.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果有人问，“哪个国家参加了最多的世界杯比赛？”这个问题就复杂了，因为每一行的粒度级别是每场比赛一行，因此我们必须考虑“主场球队”和“客场球队”这两列。为了更容易回答这个问题，我们需要的是每行一个参与者的数据。我们可以考虑创建一个类似于表3.2的长格式数据版本。
- en: Table 3.2 The same football results in a long format, one row per match participant
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表3.2 以长格式呈现的相同足球比赛结果，每行代表一个比赛参与者
- en: '| Match ID | Date | Competition | Round | Team | Home or away? | Goals scored
    |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 匹配ID | 日期 | 比赛 | 轮次 | 球队 | 主场或客场？ | 进球数 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 1  | 2014-07-04  | World Cup 2014  | Quarter-final  | France  | Home  | 0  |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 1  | 2014-07-04  | 2014年世界杯  | 半决赛  | 法国  | 主场  | 0  |'
- en: '| 1  | 2014-07-04  | World Cup 2014  | Quarter-final  | Germany  | Away  |
    1  |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 1  | 2014-07-04  | 2014年世界杯  | 半决赛  | 德国  | 客场  | 1  |'
- en: '| 2  | 2014-07-04  | World Cup 2014  | Quarter-final  | Brazil  | Home  | 2  |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 2  | 2014-07-04  | 世界杯2014  | 半决赛  | 巴西  | 主场  | 2  |'
- en: '| 2  | 2014-07-04  | World Cup 2014  | Quarter-final  | Colombia  | Away  |
    1  |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 2  | 2014-07-04  | 世界杯2014  | 半决赛  | 哥伦比亚  | 客场  | 1  |'
- en: '| 3  | 2014-07-05  | World Cup 2014  | Quarter-final  | Argentina  | Home  |
    1  |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 3  | 2014-07-05  | 世界杯2014  | 半决赛  | 阿根廷  | 主场  | 1  |'
- en: '| 3  | 2014-07-05  | World Cup 2014  | Quarter-final  | Belgium  | Away  |
    0  |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 3  | 2014-07-05  | 世界杯2014  | 半决赛  | 比利时  | 客场  | 0  |'
- en: This is now long data because rows don’t represent unique entities. The table
    encodes the same information, but each match is duplicated on purpose. From this
    table, it is easier to focus only on the “Team” column to find the team with the
    most World Cup matches. The downside of this format is that we cannot simply count
    the number of rows to find statistics such as the number of games played at a
    World Cup because we would be double counting.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这现在变成了长数据，因为行不代表唯一的实体。这个表格编码了相同的信息，但每个比赛都是故意重复的。从这个表格中，更容易只关注“队伍”列来找到拥有最多世界杯比赛的队伍。这种格式的缺点是，我们不能简单地计数行数来找到统计数据，比如在世界杯上进行的比赛数量，因为我们将会重复计数。
- en: Neither a wide nor a long format is better than the other; the choice between
    them depends on the question you are trying to answer using the data. Assessing
    what format is best suited to your analytical question is the essence of data
    modeling.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是宽格式还是长格式，没有一个比另一个更好；它们之间的选择取决于你使用数据试图回答的问题。评估哪种格式最适合你的分析问题是数据建模的本质。
- en: Identifying the right level of granularity
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 确定合适的粒度级别
- en: Just like the football example, you will encounter datasets that have the wrong
    level of granularity for your analysis. US election result data might be at an
    individual county level, but you might have analytical questions about individual
    candidates. Having a candidate-level data model would help answer candidate-specific
    questions much faster. The information is the same; it is just stored in a format
    that is more appropriate for your analytical questions.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 就像足球示例一样，你将遇到分析粒度不合适的数据集。美国选举结果数据可能是在县一级，但你可能对个别候选人感兴趣。拥有候选人级别的数据模型将有助于更快地回答针对候选人的特定问题。信息是相同的；只是存储的格式更适合你的分析问题。
- en: When beginning this project, start by asking, “What should the structure of
    the final data model be?” Working toward that goal (in a results-focused way!)
    will guide the concrete steps you will need to take.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始这个项目时，先问自己，“最终数据模型的结构应该是什么？”朝着这个目标（以结果为导向的方式！）将指导你需要采取的具体步骤。
- en: '3.2 Project 2: Who are your customers?'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 项目2：你的客户是谁？
- en: Let’s look at our project, in which we will extract a customer database from
    a series of retail transactions. We will look at the problem statement, which
    is what our stakeholders want to achieve in their own words. I provide an overview
    of the available data and discuss some of the technical specifics of the example
    solution. Reading section 3.2 is sufficient to get started, but you may find section
    3.3 helpful to see how the results-driven approach would be applied in this scenario.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们的项目，在这个项目中，我们将从一系列零售交易中提取客户数据库。我们将查看问题陈述，这是我们利益相关者用自己的话想要实现的目标。我提供了可用数据的概述，并讨论了示例解决方案的一些技术细节。阅读第3.2节就足够开始，但你可能会发现第3.3节有助于了解在这个场景中如何应用以结果为导向的方法。
- en: The data is available at [https://davidasboth.com/book-code](https://davidasboth.com/book-code).
    You will find the datasets with which you can attempt the project, as well as
    the example solution in the form of a Jupyter notebook.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可在[https://davidasboth.com/book-code](https://davidasboth.com/book-code)找到。你将找到可以尝试项目的数据集，以及以Jupyter笔记本形式的示例解决方案。
- en: 3.2.1 Problem statement
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.1 问题陈述
- en: In this example, you have been hired by Ebuy Emporium, a new e-commerce startup.
    They have been up and running for a month and have had unexpected success. They
    are starting to have an active interest in their customer base. Who are their
    customers? What do they buy? What drives their purchasing behavior? However, before
    they do any serious analysis, they need to be able to count their customers, which
    happens to be more difficult than anticipated. One problem is there are multiple
    sources of customer data, which are
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，你被雇佣到 Ebuy Emporium，一家新的电子商务初创公司。他们已经运营了一个月，并且取得了意外的成功。他们开始对他们的客户群产生浓厚的兴趣。他们的客户是谁？他们买了什么？是什么驱使他们购买？然而，在他们对任何严肃的分析之前，他们需要能够计算他们的客户数量，这比预期的要困难得多。一个问题是有多个客户数据来源，它们是
- en: The e-commerce platform’s customer database, where customer details are recorded
    when they sign up for an account online. This is where most of the customer details
    should be found.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电子商务平台的客户数据库，当客户在线注册账户时，客户详细信息会被记录。这是大多数客户详细信息应该被找到的地方。
- en: The in-house CRM (customer relationship management) system, where customer details
    are recorded when they make a purchase over the phone or are otherwise onboarded
    as customers (except because of purchasing online with a registered account).
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内部客户关系管理（CRM）系统，当客户通过电话购买或以其他方式成为客户（除了使用注册账户在线购买）时，客户详细信息会被记录。
- en: The raw transaction data, which we will hereafter refer to as “purchases” or
    “sales,” and which also contains purchases made “as a guest,” meaning customer
    records are not explicitly created at the time of purchase.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始交易数据，我们在此之后将称之为“购买”或“销售”，其中还包含作为访客进行的购买，这意味着在购买时没有明确创建客户记录。
- en: NOTE  Original transaction data courtesy of REES46 ([https://mng.bz/6eZo](https://mng.bz/6eZo)),
    enhanced with fictitious customer data from a European Union Collaboration in
    Research and Methodology (CROS) training program on record linkage ([https://mng.bz/oKad](https://mng.bz/oKad)).
    Thank you to the dataset owners for providing permission to repurpose the original
    source data.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：原始交易数据由 REES46 提供 ([https://mng.bz/6eZo](https://mng.bz/6eZo))，并增加了来自欧盟研究与方法论合作项目（CROS）记录链接培训计划的虚构客户数据
    ([https://mng.bz/oKad](https://mng.bz/oKad))。感谢数据集所有者允许重新使用原始源数据。
- en: 'Another problem is that the existing data sources may not be mutually exclusive—there
    might be overlaps across them all. There is almost certainly some duplication,
    either because the same customer had their details entered into multiple systems
    or because they have made purchases both as a guest and with a registered account.
    Duplicate accounts may not contain exactly the same information; there may be
    typos or misspellings. These complications are why the startup needs the help
    of an analyst to answer their question: “Who are our customers?”'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题在于现有数据源可能不是相互排斥的——它们之间可能存在重叠。几乎可以肯定存在一些重复，要么是因为同一客户在多个系统中输入了他们的详细信息，要么是因为他们以访客身份和注册账户身份都进行了购买。重复账户可能不包含完全相同的信息；可能存在拼写错误或误拼。正是这些复杂情况使得初创公司需要分析师的帮助来回答他们的问题：“我们的客户是谁？”
- en: 3.2.2 Data dictionary
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.2 数据字典
- en: Tables 3.3 and 3.4 show the data dictionaries for the three data sources, and
    figures 3.2 and 3.3 show sample data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.3 和 3.4 展示了三个数据源的数据字典，图 3.2 和 3.3 展示了样本数据。
- en: Table 3.3 Data dictionary for the “purchases” dataset
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 3.3 “购买”数据集的数据字典
- en: '| Column | Definition |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 列 | 定义 |'
- en: '| --- | --- |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `event_time`  | The exact date and time the purchase occurred.  |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| `event_time`  | 购买发生的确切日期和时间。  |'
- en: '| `product_id`  | The unique identifier of the purchased product.  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| `product_id`  | 购买产品的唯一标识符。  |'
- en: '| `category_id`  | The unique identifier of the purchased product’s specific
    category.  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| `category_id`  | 购买产品特定类别的唯一标识符。  |'
- en: '| `category_code`  | A broad category for the purchased product. In a hierarchy,
    category codes contain multiple category IDs, and one `category_id` should only
    be linked to one `category_code`.  |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| `category_code`  | 购买产品的广泛类别。在层次结构中，类别代码包含多个类别 ID，且一个 `category_id` 只应与一个
    `category_code` 相关联。  |'
- en: '| `brand`  | The purchased item’s brand (if applicable).  |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| `brand`  | 购买物品的品牌（如果适用）。  |'
- en: '| `price`  | The price the item was bought for (in USD).  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| `price`  | 购买物品的价格（以美元计）。  |'
- en: '| `session_id`  | A unique identifier for a purchase session. If multiple items
    are purchased in a transaction, each item will have a row in the table, and the
    rows will share a `session_id`.  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| `session_id` | 购买会话的唯一标识符。如果在交易中购买了多个项目，则每个项目在表中将有一行，并且这些行将共享一个`session_id`。
    |'
- en: '| `customer_id`  | The unique identifier of the customer if they purchased
    using a registered account. For guest purchases, this value will be missing.  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| `customer_id` | 如果客户使用注册账户进行购买，则客户的唯一标识符。对于访客购买，此值将不存在。 |'
- en: '| `guest_first_name`  | The first name that was supplied if a purchase was
    made as a guest. For purchases made using registered accounts, this value will
    be missing.  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `guest_first_name` | 如果作为访客进行购买，提供的名字。对于使用注册账户进行的购买，此值将不存在。 |'
- en: '| `guest_surname`  | The surname that was supplied if a purchase was made as
    a guest. For purchases made using registered accounts, this value will be missing.  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `guest_surname` | 如果作为访客进行购买，提供的姓氏。对于使用注册账户进行的购买，此值将不存在。 |'
- en: '| `guest_postcode`  | The postcode that was supplied if a purchase was made
    as a guest. For purchases made using registered accounts, this value will be missing.  |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `guest_postcode` | 如果作为访客进行购买，提供的邮编。对于使用注册账户进行的购买，此值将不存在。 |'
- en: '![figure](../Images/3-2.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-2.png)'
- en: Figure 3.2 A snapshot of the purchases dataset
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.2 购买数据集的快照
- en: Table 3.4 Data dictionary for the CRM and customers datasets, which share an
    identical structure
  id: totrans-86
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表3.4 CRM和客户数据集的数据字典，它们具有相同的结构
- en: '| Column | Definition |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 列 | 定义 |'
- en: '| --- | --- |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| `customer_id`  | The unique identifier of the customer in this system  |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `customer_id` | 本系统中客户的唯一标识符 |'
- en: '| `first_name`  | The customer’s first name  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| `first_name` | 客户的姓氏 |'
- en: '| `surname`  | The customer’s surname  |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `surname` | 客户的姓氏 |'
- en: '| `postcode`  | The customer’s postal code  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `postcode` | 客户的邮政编码 |'
- en: '| `age`  | The customer’s age, in years  |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `age` | 客户的年龄，以年为单位 |'
- en: '![figure](../Images/3-3.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-3.png)'
- en: Figure 3.3 A snapshot of the customer data
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.3 客户数据的快照
- en: NOTE  It is important to remember that the data dictionary refers to the assumptions
    about what data is present in each column. It is good practice to verify some
    of these assumptions as part of the exploratory data analysis phase. For example,
    do the customer IDs provided in the purchase data always match a record in one
    of the customer databases?
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：重要的是要记住，数据字典指的是关于每个列中存在哪些数据的假设。在探索性数据分析阶段验证这些假设是良好的实践。例如，购买数据中提供的客户ID是否总是与客户数据库中的一个记录匹配？
- en: In this case, the data dictionaries are self-explanatory, but the first step
    in working with a new dataset should always be making sure we’ve read any relevant
    documentation.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，数据字典是自解释的，但处理新数据集的第一步始终是确保我们已经阅读了任何相关的文档。
- en: 3.2.3 Desired outcomes
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.3 预期结果
- en: The output of this project should be a single dataset representing your customer
    data model—your best estimate of the entire customer base the startup currently
    has. Data will come from the three sources provided, and you will need to consolidate
    and deduplicate accordingly. You will need to decide on the structure of the data
    model based on the columns available in the datasets. This data model should be
    structured so that all the logic to define customers is already in place, and
    answering the question “How many customers do we have?” should be done as simply
    as counting the rows.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的输出应是一个代表您的客户数据模型的单一数据集——这是您对初创公司目前拥有的整个客户基础的最好估计。数据将来自提供的三个来源，您需要相应地进行整合和去重。您需要根据数据集中可用的列来决定数据模型的结构。此数据模型应结构化，以便所有定义客户的逻辑都已经就绪，回答“我们有多少客户？”的问题应该像计数行一样简单。
- en: There is no single right solution you’re aiming for and no ground truth to check
    your answers against. This is partly because analysis contains so much ambiguity
    that different analysts will make different assumptions and arrive at different
    conclusions, and partly because tasks like this never have answers to check against
    in the real world. Part of being a good analyst is embracing constant uncertainty
    and ambiguity and being comfortable with an answer that may never be a complete
    one. The important thing is being able to provide an answer your stakeholders
    can use.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你并不追求一个唯一的正确解决方案，也没有一个可以用来验证你答案的基准事实。这主要是因为分析中包含了很多模糊性，不同的分析师会做出不同的假设并得出不同的结论，部分也因为这类任务在现实世界中通常没有可以用来验证答案的答案。成为一名优秀分析师的部分是接受持续的不确定性和模糊性，并对可能永远不完整的答案感到舒适。重要的是能够提供你的利益相关者可以使用答案。
- en: 3.2.4 Required tools
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.4 必需的工具
- en: Although the projects are technology agnostic, for this example solution, I
    use the Python library `pandas` to manipulate the datasets and `numpy` for numerical
    functions. I also introduce the `recordlinkage` library used for entity resolution.
    I keep the code snippets to a minimum and focus on the conceptual solution, but
    the full solution is presented as a Jupyter notebook. This is a tool for presenting
    code, data, and text in a single document, making it easy to share your findings,
    as well as the underlying methods. You can attempt this exercise with any number
    of tools as long as they satisfy the following criteria, that is, they are able
    to
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然项目是技术中立的，但在这个示例解决方案中，我使用Python库`pandas`来操作数据集，并使用`numpy`进行数值函数。我还介绍了用于实体解析的`recordlinkage`库。我将代码片段保持在最小，并专注于概念解决方案，但完整的解决方案以Jupyter笔记本的形式呈现。这是一个用于在单一文档中展示代码、数据和文本的工具，使得分享你的发现以及背后的方法变得容易。只要你使用的工具满足以下标准，即它们能够
- en: Load a dataset of tens of thousands of rows from a CSV file
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从CSV文件中加载包含数万行数据的集合
- en: Create new columns and manipulate existing ones
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建新的列并操作现有的列
- en: Join datasets together
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集合并在一起
- en: Perform basic analysis tasks such as sorting, grouping, and reshaping data
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行基本分析任务，如排序、分组和重塑数据
- en: 3.3 Planning our approach to customer data modeling
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 制定客户数据建模的方法规划
- en: Let’s use the results-driven approach to break the problem down into its logical
    components. This will give us a deeper understanding of our problem before we
    start working on it. We will also explicitly decide what not to do, that is, we
    will figure out which features of the problem are not essential to a first iteration.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以结果为导向的方法将问题分解为其逻辑组成部分。这将在我们开始工作之前，让我们对问题有更深入的理解。我们还将明确决定我们不想做的事情，也就是说，我们将找出哪些问题的特征对于第一次迭代不是必要的。
- en: 3.3.1 Applying the results-driven process to data modeling
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.1 将结果驱动过程应用于数据建模
- en: '![figure](../Images/3-unnumb-1.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-unnumb-1.png)'
- en: First, we need to understand the question. In this case, the question is vaguely
    “Who are our customers?” which would normally require some pushback for clarification.
    In this instance, whatever the actual analytical question about customers is,
    the data modeling step is fundamental to answering it. We must first consolidate
    the customer data from the three data sources.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要理解问题。在这种情况下，问题模糊地是“我们的客户是谁？”这通常需要一些反驳以澄清。在这个例子中，无论关于客户的实际分析问题是什么，数据建模步骤对于回答它是基本的。我们必须首先从三个数据源中整合客户数据。
- en: TIP  We could think about what additional data to augment it with to better
    fit the needs of the analytical questions. We know we want to end up with one
    row per customer, but we don’t yet know if a summary of the customer’s purchase
    history would be a useful addition. In this case, we don’t want to spend time
    preemptively adding information to our data model because we think someone might
    ask for it down the line.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: TIP  我们可以考虑添加哪些额外数据来更好地满足分析问题的需求。我们知道我们希望每个客户对应一行，但我们还不知道客户购买历史的总结是否会是一个有用的补充。在这种情况下，我们不希望预先花费时间在我们的数据模型中添加信息，因为我们认为将来可能会有人要求它。
- en: '*![figure](../Images/3-unnumb-2.png)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*![figure](../Images/3-unnumb-2.png)'
- en: Our end product is quite well defined, but, specifically, starting from the
    end here means having an idea of the structure of the final data model, the existence
    of which will allow us to count customers to produce our minimum viable answer.
    We know that one of its most important properties should be that it contains one
    row per customer. That’s the level of granularity we’re aiming for. Any purchase
    data we augment it with would, therefore, need to be aggregated to the customer
    level; we couldn’t include individual products purchased by a customer but could
    include their total spending, the date they first signed up, the number of unique
    purchases they made, and so forth.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的产品最终形态非常明确，但具体来说，从最终结果开始意味着对最终数据模型的结构有一个概念，其存在将使我们能够计数客户以产生我们的最小可行答案。我们知道它最重要的属性之一应该是它包含每名客户的一行。这是我们追求的粒度级别。因此，我们添加的任何购买数据都需要汇总到客户级别；我们无法包括客户购买的个别产品，但可以包括他们的总消费、他们首次注册的日期、他们做出的独特购买数量等等。
- en: Another aspect of looking ahead at our end result is to identify the schema
    of our final data model. What columns are common across our datasets? Are there
    columns we will have to drop before we combine the data sources, or are they important
    enough that we will accept some missing data in our final solution? In data modeling,
    these are all important aspects to think about up front, so we can keep them in
    mind while in the weeds of coding our solution, and we don’t spend time manipulating
    data that we cannot use in the final data model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个展望最终结果的角度是确定我们最终数据模型的模式。我们的数据集中有哪些列是通用的？在我们合并数据源之前，我们需要删除哪些列，或者它们是否足够重要，以至于我们可以在最终解决方案中接受一些缺失的数据？在数据建模中，这些都是需要提前考虑的重要方面，这样我们就可以在编码解决方案的细节中记住它们，并且不会花费时间处理最终数据模型中无法使用的数据。
- en: '![figure](../Images/3-unnumb-3.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-unnumb-3.png)'
- en: The datasets have been identified and provided for us in this case, so our “Identify”
    and “Obtain” steps have been done for us. However, in a real-world scenario, it
    would be prudent to think about any additional sources of customer data that might
    exist within our organization. This often includes spreadsheets kept by various
    sales managers on their computer desktops!
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，数据集已经被识别并为我们提供了，因此我们的“识别”和“获取”步骤已经完成。然而，在现实世界的场景中，考虑我们组织内部可能存在的任何额外客户数据来源是谨慎的。这通常包括各种销售经理在他们的电脑桌面上保存的电子表格！
- en: '![figure](../Images/3-unnumb-4.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-unnumb-4.png)'
- en: 'To actually do the data modeling task, here are some key steps to consider:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 实际进行数据建模任务时，以下是一些需要考虑的关键步骤：
- en: We would start by exploring all three datasets. We want to ascertain whether
    the columns contain what the data dictionaries have said. For example, are guest
    details always complete when we don’t have a customer ID? We also want to see
    whether the values make sense. We’re concentrating on customer data but might
    also want to see if the `price` column contains any unrealistic values. Are the
    date and time values all within the same period? Is there anything amiss with
    any of the postcode values? This is an iterative process, so we may not exhaust
    all our exploration at the beginning; some of these questions may only present
    themselves later on. We also don’t want to spend too much time exploring columns
    we won’t use.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先探索所有三个数据集。我们想要确认列是否包含数据字典中所述的内容。例如，当我们没有客户ID时，客户详情是否总是完整的？我们还想看看值是否有意义。我们专注于客户数据，但也可能想看看`价格`列是否包含任何不切实际的价值。日期和时间值是否都在同一时期内？邮编值是否有任何异常？这是一个迭代过程，所以我们可能不会在开始时就耗尽我们的探索；其中一些问题可能只有在稍后才会出现。我们也不想花费太多时间探索我们不会使用的列。
- en: Once we have verified some key assumptions about the data, one idea would be
    to deduplicate each dataset to just unique customers before merging them. This
    is especially true for purchases, where any time a customer buys multiple items,
    their details are repeated. We would also make some of the key decisions about
    differences in schema. If there is data that is only present in some of the sources,
    what do we do with it?
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们验证了关于数据的一些关键假设，一个想法是在合并之前对每个数据集进行去重，只保留唯一的客户。这在购买数据中尤其如此，因为每次客户购买多个项目时，他们的详细信息都会重复。我们还会就模式差异做出一些关键决策。如果有些数据只存在于某些来源中，我们该怎么办？
- en: The next step is to combine these separate datasets; we want a dataset that
    contains all possible customer records. The combined dataset may contain duplicates.
    We can get rid of some obvious duplication by removing exact duplicates, which
    may arise if a customer record existed in both the customer database and the CRM
    data, and the records were otherwise identical. If the information in two customer
    records is identical, but the unique identifier differs, we would need to be careful.
    Casually removing a duplicate would result in the loss of what we might refer
    to as “data lineage,” that is, the traceability of where our data originally came
    from. If we have a customer record for Jane Smith, it’s good practice to keep
    all possible identifiers for that customer that we’ve encountered across datasets.
    Perhaps she is customer 8834 in one dataset and 931 in another, and we would want
    to know that somehow in our final data model. This not only makes it easier to
    trace her accounts back to their sources, but also increases trust in our final
    solution. Anyone using our data model knows the assumptions we’ve made about which
    customer accounts make up the customer “entity” for Jane Smith.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是将这些单独的数据集合并起来；我们希望得到一个包含所有可能的客户记录的数据集。合并后的数据集可能包含重复项。我们可以通过删除精确重复项来消除一些明显的重复，这些重复项可能出现在客户数据库和CRM数据中，并且记录在其他方面完全相同。如果两个客户记录中的信息完全相同，但唯一标识符不同，我们需要小心处理。随意删除重复项可能会导致我们可能称之为“数据来源可追溯性”的丢失，即我们数据最初来源的可追溯性。如果我们有一个Jane
    Smith的客户记录，良好的做法是保留我们在各个数据集中遇到的该客户的所有可能的标识符。也许她在某个数据集中是客户8834，在另一个数据集中是931，我们希望以某种方式在我们的最终数据模型中知道这一点。这不仅使追踪她的账户回到其来源更容易，而且增加了对我们最终解决方案的信任。任何使用我们数据模型的人都知道我们关于哪些客户账户构成了Jane
    Smith的“实体”所做出的假设。
- en: Next, we could look at deduplicating our combined customer data beyond simply
    identifying exact duplicates. Fuzzy string matching might be a good approach here;
    in this case, we compare two strings and judge them as identical if they almost
    are. When using fuzzy matching, typos are taken into account, and “London” and
    “Lodnon” are seen as the same string. Research in the field of record linkage
    and entity resolution may be helpful to read up on. These are entire topics dedicated
    to figuring out whether two slightly different versions of an entity are, in fact,
    the same. We would need to make a judgment call on whether this additional work
    has tangible benefits and is a good investment of our time. It might even be a
    task we leave for a second draft, as we may prefer to show our stakeholders our
    first findings before committing to this more complex step.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们可以考虑在识别精确重复数据之外，对合并后的客户数据进行去重。模糊字符串匹配可能是一个不错的选择；在这种情况下，我们比较两个字符串，如果它们几乎相同，则判断它们为相同。在使用模糊匹配时，会考虑拼写错误，“London”和“Lodnon”被视为相同的字符串。在记录链接和实体解析领域的
    研究 可能有助于深入了解。这些是专门用于确定两个略有不同版本的实体实际上是否相同的完整主题。我们需要判断这项额外工作是否有实际效益，并且是否值得我们投入时间。这甚至可能是一个我们留给第二稿的任务，因为我们可能更愿意在承诺进行这一更复杂的步骤之前，向我们的利益相关者展示我们的初步发现。
- en: Finally, we would clean up the data model so that it has the schema we want,
    ensuring the column names are meaningful. Depending on how we choose to handle
    duplicate accounts, we may need to decide on a main account for each customer
    entity, for example.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们会清理数据模型，使其具有我们想要的架构，确保列名具有意义。根据我们选择如何处理重复账户，我们可能需要为每个客户实体决定一个主要账户，例如。
- en: '![figure](../Images/3-unnumb-5.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-unnumb-5.png)'
- en: The way to present a data model is by focusing on the implications of our work.
    Creating a small presentation outlining what we’ve done, how many customers we’ve
    found, and what assumptions our work is founded on would get more attention than
    giving access to the data model in the database. It is unlikely our stakeholders
    would ever use our data model to analyze data directly, anyway; the main benefit
    of the work is improved accuracy and more opportunities in customer analytics
    later on.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 展示数据模型的方式是关注我们工作的影响。创建一个小型演示文稿，概述我们所做的工作、我们发现了多少客户以及我们的工作基于哪些假设，这会比提供数据库中的数据模型获得更多的关注。实际上，我们的利益相关者不太可能直接使用我们的数据模型来分析数据；这项工作的主要好处是提高了准确性，并在以后的客户分析中提供了更多机会。
- en: Presenting our findings also creates an opportunity to work with our stakeholders
    to make some of the analytical decisions together. Sometimes, we don’t have the
    right intuition to choose between two seemingly similar options. A problem I have
    faced myself is when customers exist as companies in one database and individuals
    in another. I, as the analyst, shouldn’t be the one that has the final say over
    whether “Jane Smith” is the same customer as her company “JS Motors”; that’s a
    decision that needs wider business input, especially if the business is going
    to measure and track customer numbers over time. You can use the first iteration
    of your data model to present some of these key questions for your stakeholders
    to think about.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 展示我们的发现也为我们与利益相关者一起做出一些分析决策提供了机会。有时，我们可能没有足够的直觉来在两个看似相似的选择之间做出选择。我本人面临的一个问题是当客户在一个数据库中作为公司存在，而在另一个数据库中作为个人存在时。作为分析师的我，不应该是决定“简·史密斯”是否与她的公司“JS
    Motors”是同一客户的最终决定者；这是一个需要更广泛业务输入的决定，特别是如果业务将随着时间的推移来衡量和跟踪客户数量。您可以使用您数据模型的第一次迭代来向您的利益相关者展示一些这些关键问题，让他们思考。
- en: '![figure](../Images/3-unnumb-6.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-unnumb-6.png)'
- en: After getting feedback on your initial findings, it is usually apparent what
    the next iteration of your solution needs. In the context of the project, since
    we lack direct feedback from a stakeholder, iteration might mean you create a
    minimum viable data model quickly, perhaps stopping before doing any meaningful
    deduplication. Beyond allowing you to get feedback on your work quicker, getting
    to a minimum viable solution soon can give you the confidence that you’re on the
    right track. You’ll also have a solution in place that is easier to iteratively
    improve, rather than spending a long time on a more complex one, having nothing
    tangible to show for it until the end of a longer process. Alternatively, this
    might be the point at which it is apparent that there is no tangible business
    value in improving your solution further, so rather than iterating further, the
    project is considered complete.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在对您的初步发现获得反馈后，通常可以清楚地知道您解决方案的下一迭代需要什么。在项目背景下，由于我们缺乏来自利益相关者的直接反馈，迭代可能意味着您快速创建一个最小可行数据模型，也许在执行任何有意义的去重之前就停止。除了让您更快地对工作获得反馈外，尽快达到最小可行解决方案还可以让您有信心您正在正确的轨道上。您还将有一个更容易迭代改进的解决方案，而不是在一个更复杂的解决方案上花费大量时间，直到更长过程结束时才有所成果。或者，这可能是明显没有进一步改进解决方案的实质性商业价值的点，因此，而不是进一步迭代，项目被认为是完成的。
- en: 3.3.2 Questions to consider
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.2 需要考虑的问题
- en: 'As you work through this project, here are some key questions to consider:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在您处理这个项目的过程中，以下是一些需要考虑的关键问题：
- en: What are the possible ways in which customers can be represented across these
    datasets? It may be helpful to list all scenarios (customers in CRM, customers
    who made a purchase, guest checkouts, etc.) to hone in on exactly what you will
    need to code.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户可以以哪些方式在这些数据集中表示？列出所有场景（CRM中的客户、已购物的客户、匿名结账等）可能有助于精确地确定您需要编码的内容。
- en: When you consider duplicates, how will linked accounts (i.e., a main account
    versus linked accounts) be represented?
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您考虑重复项时，如何表示关联账户（即主账户与关联账户）？
- en: When deduplicating records, what fields do you want to use for deduplication?
    Are two people with the same name living at the same postcode necessarily the
    same person? How much do two customers’ details need to differ before we consider
    them different people?
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在去重记录时，您想使用哪些字段进行去重？两个同名且住在同一邮编的人是否一定是同一个人？两个客户的详细信息需要有多少差异，我们才认为他们是不同的人？
- en: '3.4 An example solution: Identifying customers from transactional data'
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.4 示例解决方案：从交易数据中识别客户
- en: Let’s dive into the details of an actual example solution. I strongly recommend
    attempting the project yourself before reviewing the example solution. As with
    every project, the data files, as described in section 3.2, are in the supplementary
    materials. I also recommend reading this section even if you’ve got a solution
    you’re happy with, not because the example solution is the only solution but because
    we can learn a lot from seeing how others approach the same problem.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨一个实际解决方案的细节。我强烈建议在审查示例解决方案之前先尝试自己完成项目。与每个项目一样，数据文件，如第3.2节所述，包含在补充材料中。我也建议即使您已经有一个满意的解决方案，也要阅读这一节，不是因为示例解决方案是唯一的解决方案，而是因为我们可以从看到他人如何处理相同的问题中学到很多东西。
- en: 3.4.1 Developing an action plan
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.1 制定行动计划
- en: We will first explore the data to see if our assumptions about it hold, whether
    any data is missing, and so on. Then, we will decide on a common schema for our
    datasets and trim them all down to this common schema, meaning we will have three
    smaller customer datasets—one from purchases, one from the customer database,
    and one from the CRM data—which are all structured the same way and can be easily
    combined. After combining the datasets, we will deduplicate our records to arrive
    at the best guess of our customer base.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将探索数据，以查看我们对它的假设是否成立，是否有任何数据缺失，等等。然后，我们将为我们的数据集决定一个共同的架构，并将它们全部裁剪到这个共同的架构中，这意味着我们将有三个较小的客户数据集——一个来自购买，一个来自客户数据库，一个来自
    CRM 数据——它们都以相同的方式结构化，可以很容易地组合。在合并数据集之后，我们将消除重复的记录，以得出我们客户群的最好猜测。
- en: 3.4.2 Exploring, extracting, and combining multiple sources of data
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.2 探索、提取和合并多个数据源
- en: We will explore each of the three datasets, extract common customer information
    from them, and combine them into one “master” view of customers. We will then
    look at deduplicating that combined dataset. Let’s start with the raw purchases.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探索这三个数据集，从中提取共同的客户信息，并将它们合并成一个“主”客户视图。然后，我们将查看消除合并数据集的重复项。让我们从原始购买数据开始。
- en: Exploring a new dataset
  id: totrans-141
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 探索新的数据集
- en: 'We start by importing the necessary libraries and reading in the sales data:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入必要的库并读取销售数据：
- en: '[PRE0]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Imports necessary libraries'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 导入必要的库'
- en: '#2 Reads in our purchases CSV file as a pandas DataFrame'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将我们的购买 CSV 文件作为 pandas DataFrame 读取'
- en: '#3 Inspects the size of the DataFrame'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 检查 DataFrame 的大小'
- en: 'The output of this code is `(71519,` `11)`, meaning just over 71,000 rows of
    data and 11 columns, so there are over 71,000 transactions in the purchases table.
    We know from the problem statement that guest checkouts will not make up all our
    transactions, so checking for missing data should at least reveal some missing
    guest information. The following code produces the output in figure 3.4, showing
    the count of missing values per column:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的输出是 `(71519,` `11)`，这意味着超过 71,000 行数据，11 列，所以购买表中有超过 71,000 笔交易。我们知道从问题陈述中，访客结账不会构成我们所有交易的全部，所以检查缺失数据至少应该揭示一些缺失的访客信息。下面的代码生成了图
    3.4 的输出，显示了每列缺失值的计数：
- en: '[PRE1]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 A pandas trick to “add up” rows with missing values'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 一个 pandas 技巧来“加总”缺失值的行'
- en: '![figure](../Images/3-4.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-4.png)'
- en: Figure 3.4 Missing values in our purchases data
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.4 我们购买数据中的缺失值
- en: 'There are 18,448 missing customer IDs, which should relate to guest checkouts,
    and 53,071 missing guest values. Adding those up gives us 71,519, which is the
    total number of records, meaning that guest checkouts and registered user checkouts
    make up our entire dataset. There are seemingly no rows with either all this information
    missing or both being present, but we should verify this. First, let’s create
    a new column to track guest checkouts, which happen when a customer ID is not
    provided:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 有 18,448 个缺失的客户 ID，这些应该与访客结账相关，还有 53,071 个缺失的访客值。将它们加起来得到 71,519，这是记录总数，这意味着访客结账和注册用户结账构成了我们的整个数据集。似乎没有一行信息全部缺失或两者都存在，但我们应该验证这一点。首先，让我们创建一个新的列来跟踪访客结账，这发生在客户
    ID 未提供时：
- en: '[PRE2]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, our `is_guest` column takes the Boolean value of `True` if the customer
    ID is missing. We can use this column to verify our assumption about the guest
    checkouts and the customer IDs being mutually exclusive. The first line of this
    code checks for cases where the transaction was a guest checkout, but we also
    had a customer ID, and the second returns cases where we had neither:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的 `is_guest` 列如果客户 ID 缺失，则取布尔值 `True`。我们可以使用这个列来验证我们对访客结账和客户 ID 互斥的假设。这段代码的第一行检查了交易是访客结账，但我们也有客户
    ID 的情况，第二行返回了既没有客户 ID 也没有访客值的情况：
- en: '[PRE3]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The output for both lines is presented in figure 3.5.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这两条线的输出都在图 3.5 中展示。
- en: '![figure](../Images/3-5.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-5.png)'
- en: Figure 3.5 The output of our code to check whether guest and registered user
    checkouts overlap
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.5 检查访客和注册用户结账是否重叠的代码输出
- en: This is Python’s way of telling us that there are no records for our criteria,
    meaning we can be sure that all rows are either a guest checkout or a purchase
    made by a registered customer. Next on our data quality agenda is checking what
    percentage of records are guest checkouts. This is not just for informational
    purposes, but also for us to get a sense of how many customer records we will
    have to infer. As guest checkouts are our weakest signal for a customer record,
    any guests we add to our customer database are assumed customers. They are inferred
    rather than concrete customer accounts.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Python告诉我们没有符合我们标准的记录的方式，这意味着我们可以确信所有行要么是访客退房，要么是注册客户做出的购买。接下来在我们的数据质量议程中，我们需要检查有多少比例的记录是访客退房。这不仅仅是为了信息目的，也是为了我们了解我们将要推断多少客户记录。由于访客退房是我们客户记录的最弱信号，我们添加到客户数据库中的任何访客都被假定为客户。他们是推断出来的，而不是具体的客户账户。
- en: 'For example, if someone entered John Smith as their guest checkout name, it
    could be because Mr. Smith was buying something on behalf of someone else, perhaps
    as a gift. Is John Smith the customer in this case? Or maybe it was someone using
    Mr. Smith’s credit card, maybe one of his children. In this case, is the customer
    John Smith or the child? Either way, we have no more information to go on than
    the guest name, John Smith, and that is what we would need to put in the customer
    database. Counting the number of guest accounts is useful to determine what percentage
    of our customer data will be “assumed” cases like this. Using the `is_guest` column
    we created earlier, we can calculate its distribution:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果有人将John Smith作为他们的访客退房名称，这可能是因为史密斯先生代表其他人购买东西，可能是作为礼物。在这种情况下，John Smith是客户吗？或者可能是有人使用史密斯先生的信用卡，可能是他的孩子之一。在这种情况下，客户是John
    Smith还是孩子？无论如何，我们除了访客名称John Smith之外没有更多的信息可以依据，这就是我们需要放入客户数据库的信息。计算访客账户的数量有助于确定我们客户数据中会有多少“假设”案例。使用我们之前创建的`is_guest`列，我们可以计算其分布：
- en: '[PRE4]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The output is shown in figure 3.6.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如图3.6所示。
- en: '![figure](../Images/3-6.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-6.png)'
- en: Figure 3.6 The proportion of guest vs. registered user purchases
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.6 客户与注册用户购买的比例
- en: 'This tells us that 25% of the rows are guest checkouts, but we need to remember
    that one row represents a purchased *item*, not a customer record, so the proportion
    of customers who checked out as guests is not necessarily 25%. We can calculate
    this actual proportion:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们有25%的行是访客退房，但我们需要记住，每一行代表的是一个购买的*项目*，而不是客户记录，所以作为访客退房的客户比例不一定为25%。我们可以计算出这个实际比例：
- en: '[PRE5]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '#1 Gets a unique combination of guest columns'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 获取访客列的唯一组合'
- en: '#2 Gets all unique customer IDs'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 获取所有唯一的客户ID'
- en: '#3 Subtracts 1 from the unique customer count because NULL is also counted'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 从唯一的客户计数中减去1，因为NULL也被计算在内'
- en: This prints a value of `8301` and another just under `0.25`, meaning we have
    8,301 unique combinations of guest columns, and once we extract unique customers,
    it turns out a quarter are indeed not registered and checked out as guests instead.
    This number won’t be exact because there could be typos. We are assuming every
    combination of name and postcode is a unique customer, but a single customer making
    a typo during one of their checkouts would result in us double-counting them here.
    This, of course, assumes they are allowed to make a typo during the checkout process.
    We would need to know more about the actual e-commerce system to understand whether
    these guest columns relate to billing or credit card information, for example,
    where typos might cause the purchase to be rejected. Knowing the data-generating
    process is vital.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这会打印出`8301`的值和另一个略低于`0.25`的值，这意味着我们有8,301种独特的访客列组合，一旦我们提取出独特的客户，结果发现确实有四分之一的人没有注册，而是以访客的身份退房。这个数字不会完全准确，因为可能会有打字错误。我们假设每个姓名和邮编的组合都是唯一的客户，但一个客户在他们的退房过程中犯了一个打字错误，就会导致我们在这里重复计算他们。当然，这是假设他们在退房过程中允许犯打字错误。我们需要了解更多关于实际电子商务系统的信息，以了解这些访客列是否与账单或信用卡信息相关，例如，打字错误可能会导致购买被拒绝。了解数据生成过程至关重要。
- en: Let’s summarize what we have so far. Figure 3.7 shows the progress we’ve made
    exploring the purchases dataset.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结到目前为止我们已经做了什么。图3.7显示了我们在探索购买数据集方面取得的进展。
- en: '![figure](../Images/3-7.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-7.png)'
- en: Figure 3.7 Progress in exploring the purchases dataset
  id: totrans-173
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.7 探索购买数据集的进展
- en: Identifying a common structure between datasets
  id: totrans-174
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 识别数据集之间的共同结构
- en: There are around 25,000 unique customer IDs, which represent registered customers,
    and another roughly 8,000 unique inferred guests, so from purchases alone, we
    estimate the upper bound of the number of customers to be around 33,000\. I say
    upper bound because we will have to investigate duplicate accounts later, and
    this number may decrease if we find any. We also know that we have a first name,
    surname, and postcode available for guest checkouts. We will need to bear this
    in mind when we look at the other customer databases.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 大约有25,000个唯一的客户ID，代表注册客户，还有大约8,000个唯一的推断访客，所以仅从购买数据来看，我们估计客户数量的上限大约为33,000。我说上限是因为我们稍后必须调查重复账户，如果发现任何重复，这个数字可能会减少。我们还知道，对于访客结账，我们有可用的名字、姓氏和邮政编码。当我们查看其他客户数据库时，我们需要记住这一点。
- en: However, before we export our first intermediate dataset, we need to decide
    on a schema for our data model. We know our guest customers have names and postcodes,
    and if we look at the data dictionary, we can see the customer and CRM datasets
    also have customer age. We don’t really want to drop that column just because
    it is missing for guest accounts, so our final schema will include it.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们导出第一个中间数据集之前，我们需要决定我们数据模型的模式。我们知道我们的访客客户有名字和邮政编码，如果我们查看数据字典，我们可以看到客户和CRM数据集也包含客户年龄。我们并不真的想因为访客账户缺失而删除该列，所以我们的最终模式将包括它。
- en: It is generally a good idea to also keep track of where our records came from
    once they are combined into a single table. We could do this by adding a `source`
    column, which could have values of `purchases`, `customer` `database`, or `CRM`,
    but this structure would assume a record can only come from one place. We may
    encounter duplication, so a better choice is an indicator column for each data
    source, that is, a column to mark whether the record is present in the purchase
    data, another to indicate whether it’s present in the customer database, and so
    on. These are mostly for data lineage purposes, so the source of the information
    is more transparent. We can also decide to explicitly track whether a record came
    from a guest checkout because this may be important later if a stakeholder wants
    to know what percentage of customers don’t register when buying. Table 3.5 shows
    the final schema, which is what each of the three datasets needs to be transformed
    into.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦记录合并到单个表中，跟踪记录的来源通常是一个好主意。我们可以通过添加一个`source`列来实现，该列可以具有`purchases`、`customer`
    `database`或`CRM`等值，但这种结构假设记录只能来自一个地方。我们可能会遇到重复，所以更好的选择是为每个数据源添加一个指示列，即标记记录是否存在于购买数据中的列，另一个指示它是否存在于客户数据库中的列，等等。这些主要用于数据溯源目的，因此信息的来源更加透明。我们还可以决定明确跟踪记录是否来自访客结账，因为这可能在利益相关者想要知道有多少比例的客户在购买时不注册时变得很重要。表3.5显示了最终的架构，这是三个数据集需要转换成的模式。
- en: Table 3.5 The data model schema that all data sources need to be transformed
    into
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表3.5 所有数据源需要转换成的数据模型模式
- en: '| Column | Description |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 列 | 描述 |'
- en: '| --- | --- |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `customer_id`  | The unique ID of the customer record, or NULL for guests.  |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| `customer_id`  | 客户记录的唯一ID，或访客为NULL。  |'
- en: '| `first_name`  | Either from the customer or CRM tables or the guest information.  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| `first_name`  | 来自客户或CRM表或访客信息。  |'
- en: '| `surname`  | Either from the customer or CRM tables or the guest information.  |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| `surname`  | 来自客户或CRM表或访客信息。  |'
- en: '| `postcode`  | Either from the customer or CRM tables or the guest information.  |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| `postcode`  | 来自客户或CRM表或访客信息。  |'
- en: '| `age`  | From the customer or CRM tables, unavailable for guests.  |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| `age`  | 来自客户或CRM表，对访客不可用。  |'
- en: '| `is_guest`  | `True` if the data comes from a guest checkout.  |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| `is_guest`  | `True` 如果数据来自访客结账。  |'
- en: '| `in_purchase_data`  | `True` if this customer record appears in the purchase
    table. It is not exclusive since the customer could also appear in the customer
    or CRM datasets.  |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| `in_purchase_data`  | `True` 如果此客户记录出现在购买表中。它不是排他的，因为客户也可能出现在客户或CRM数据集中。  |'
- en: '| `in_crm_data`  | `True` if the customer record exists in the CRM database.  |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| `in_crm_data`  | `True` 如果客户记录存在于CRM数据库中。  |'
- en: '| `in_customer_data`  | `True` if the customer record exists in the customer
    database.  |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| `in_customer_data`  | `True` 如果客户记录存在于客户数据库中。  |'
- en: Let’s go ahead and transform our first raw dataset, sales, into this desired
    structure.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续将我们的第一个原始数据集，销售数据，转换成这个期望的结构。
- en: Restructuring a dataset to the common structure
  id: totrans-191
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将数据集重构为通用结构
- en: The easiest way to export our customers from the purchase data is to extract
    the guests and non-guests separately and then combine them. These two subsets
    will not have the same structure because we have three columns for guests (first
    name, surname, and postcode) and for registered customers, we only have their
    IDs. We could join data from the customer and CRM tables to find the relevant
    names and postcodes for these IDs, or we could do that when we get around to exploring
    and manipulating the customer datasets. This choice is more personal preference
    than anything else. I’ve chosen to leave the joining until later, so for now,
    we will export incomplete data.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 从购买数据中导出我们的客户最简单的方法是分别提取访客和非访客，然后将它们合并。这两个子集的结构将不同，因为我们为访客有三个列（名、姓和邮编），而对于注册客户，我们只有他们的ID。我们可以从客户和CRM表中连接数据以找到这些ID的相关名字和邮编，或者我们可以在探索和操作客户数据集时这样做。这个选择更多的是个人偏好，我选择将连接推迟到以后，所以现在我们将导出不完整的数据。
- en: 'To export only the guests, we can filter using our `is_guest` column and export
    only the relevant columns:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 要仅导出访客信息，我们可以使用我们的`is_guest`列进行筛选，并仅导出相关列：
- en: '[PRE6]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 We drop duplicates to ensure we only have unique guest information.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 我们删除重复项以确保我们只有唯一的访客信息。'
- en: The output is as presented in figure 3.8.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如图3.8所示。
- en: '![figure](../Images/3-8.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-8.png)'
- en: Figure 3.8 Guest data from the purchases table ready to be combined with customer
    data
  id: totrans-198
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.8 购买表中的访客数据，准备与客户数据合并
- en: 'For non-guest checkouts, we won’t have these columns; we will have only a customer
    ID:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非访客结账，我们不会有这些列；我们只有客户ID：
- en: '[PRE7]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Customer ID is a single column, so we need to explicitly make it a DataFrame.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 客户ID是一个单独的列，因此我们需要明确将其转换为DataFrame。'
- en: '#2 We extract unique customer IDs from non-guest rows.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 我们从非访客行中提取唯一的客户ID。'
- en: The output is shown in figure 3.9.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果如图3.9所示。
- en: '![figure](../Images/3-9.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-9.png)'
- en: Figure 3.9 Non-guest data from purchases, which is just a column of customer
    IDs
  id: totrans-205
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.9 购买中的非访客数据，它只是一个客户ID列
- en: 'The data shown in figures 3.8 and 3.9 are of a different structure. However,
    when we combine them, we will have all the columns from both datasets and missing
    data where a column did not exist in one of the datasets:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图表3.8和3.9所示的数据结构不同。然而，当我们合并它们时，我们将拥有两个数据集的所有列，以及在一个数据集中某个列不存在时的缺失数据：
- en: '[PRE8]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'First, we concatenate (or “union” if you are used to SQL terminology) our two
    datasets. Then, we rename our columns and remove the guest prefix:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将两个数据集连接起来（如果你习惯于SQL术语，可以说“合并”）。然后，我们重命名我们的列并移除访客前缀：
- en: '[PRE9]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We also want to make sure we don’t have missing data, so we fill in the missing
    values for the `is_guest` column. Technically, we could leave it blank to indicate
    that someone isn’t a guest, but explicitly using `True`/`False` values is clearer:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还想要确保没有缺失数据，所以我们在`is_guest`列中填充缺失值。技术上，我们可以留空以表示某人不是访客，但明确使用`True`/`False`值更清晰：
- en: '[PRE10]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now we add the `in_purchase_data` column we decided on for our schema:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们添加了我们为我们的模式所决定的`in_purchase_data`列：
- en: '[PRE11]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Since we’re working with text data, another important step is to ensure there
    is no trailing whitespace and that the names all use the same capitalization.
    This is so that customer names are treated as being the same even if one is lowercase
    and the other uppercase. We can use the `pandas` built-in `.str` accessor class,
    which lets us manipulate entire string columns:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在处理文本数据，另一个重要的步骤是确保没有尾随空格，并且所有名称都使用相同的首字母大小写。这样即使一个名称是小写的而另一个是大写的，客户名称也会被视为相同。我们可以使用`pandas`内置的`.str`访问器类，它允许我们操作整个字符串列：
- en: '[PRE12]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Now, the customer data extracted from our purchases looks like figure 3.10.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，从我们的购买中提取的客户数据看起来像图3.10。
- en: '![figure](../Images/3-10.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-10.png)'
- en: Figure 3.10 A preview of our customer data extracted from purchases
  id: totrans-218
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.10 从购买中提取的客户数据预览
- en: The first rows show the non-guest checkouts and the registered customers. For
    now, we have no names or postcodes for them because we decided to join those afterward.
    The last few rows in the preview show our guests, hence the missing customer ID.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 前几行显示了非访客结账和注册客户。目前，我们没有他们的名字或邮编，因为我们决定稍后将其连接。预览中最后几行显示了我们的访客，因此缺少客户ID。
- en: Before we move on, let’s summarize what we have done so far. Figure 3.11 shows
    the steps we took when exploring and reshaping the purchases dataset. Text that
    appears without shapes represents steps and decisions from previous sections.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，让我们总结一下到目前为止我们所做的工作。图3.11显示了我们在探索和重塑购买数据集时所采取的步骤。没有形状的文本表示来自前几节中的步骤和决策。
- en: '![figure](../Images/3-11.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-11.png)'
- en: Figure 3.11 The steps we took on the purchases dataset
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.11我们在购买数据集上所采取的步骤
- en: We are now ready to move on and explore the customer datasets and merge them
    with the customer data we have just exported from our raw purchases.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好继续前进，探索客户数据集，并将它们与我们刚刚从原始购买中导出的客户数据合并。
- en: Exploring a second dataset
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 探索第二个数据集
- en: 'We know from the data dictionary that both customer datasets have the same
    schema. What we’re looking for in both datasets is whether there is any missing
    data, whether the customer IDs are all filled in, and whether there are any duplicate
    records. Since customer ID is a unique identifier, we don’t anticipate any duplicates,
    but you cannot assume anything. We start with the CRM data:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据字典中我们知道，两个客户数据集具有相同的架构。我们在两个数据集中寻找的是是否存在任何缺失数据，客户ID是否都已填写，以及是否存在任何重复记录。由于客户ID是唯一的标识符，我们预计不会出现重复，但不可假设任何事情。我们从CRM数据开始：
- en: '[PRE13]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The shape of the dataset is `(7825,` `5)`, meaning 7,825 rows and 5 columns.
    Figure 3.12 shows a preview of the CRM dataset.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的形状是`(7825,` `5`)`，意味着有7,825行和5列。图3.12显示了CRM数据集的预览。
- en: '![figure](../Images/3-12.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-12.png)'
- en: Figure 3.12 The first few rows of the raw CRM data
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.12原始CRM数据的前几行
- en: 'We check for missing data with the following code, the output of which is shown
    in figure 3.13:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下代码检查缺失数据，其输出如图3.13所示：
- en: '[PRE14]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![figure](../Images/3-13.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-13.png)'
- en: Figure 3.13 No missing data in the CRM table
  id: totrans-233
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.13CRM表中没有缺失数据
- en: 'The next bit of sanity checking is ensuring that customer IDs are unique. One
    way to do this is to group by the customer ID and find instances where there are
    multiple rows in a group. If customer IDs are unique, no records should be returned.
    Let’s verify this:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步的合理性检查是确保客户ID是唯一的。一种方法是按客户ID分组，并找到组内有多行记录的实例。如果客户ID是唯一的，则不应返回任何记录。让我们验证这一点：
- en: '[PRE15]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Here we use `groupby` and `size` to count how many records we have per customer
    ID and use `loc` to filter instances where there is more than one. The Python
    output is `Series([],` `dtype:` `int64),` which indicates no records were found,
    as the empty square brackets represent an empty collection in Python. This means
    customer IDs are indeed unique.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们使用`groupby`和`size`来计算每个客户ID的记录数，并使用`loc`来过滤出有多条记录的实例。Python输出是`Series([],`
    `dtype:` `int64),`这表示没有找到记录，因为空方括号在Python中表示一个空集合。这意味着客户ID确实是唯一的。
- en: 'However, this does not mean that customer *details* are unique in the table.
    If we look at how many unique combinations of name, postcode, and age we have,
    we can see this:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这并不意味着客户*详细信息*在表中是唯一的。如果我们看看我们有多少个独特的姓名、邮编和年龄组合，我们可以看到这一点：
- en: '[PRE16]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The output is 7,825 and 7,419, respectively, meaning that while there are 7,825
    rows in the CRM data, there are only 7,419 unique combinations of columns once
    we drop the customer ID, which indicates we have about 400 duplicate customer
    details where the same information is spread across multiple IDs. This might not
    mean 400 duplicate customers because we could also have multiple people with very
    common names living at the same postcode, but because we have also factored age
    into it, it is more likely these are all redundant duplicates. Incorrect duplicates,
    if there are any, are likely to be a very small percentage when we consider the
    size of the dataset, so it makes sense not to dwell on this, and for now, say
    that every unique combination of name, postcode, and age is a unique customer.
    The nature of data modeling work is that there will always be a margin of error.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 输出分别是7,825和7,419，这意味着虽然CRM数据中有7,825行，但一旦我们删除客户ID，只有7,419个唯一的列组合，这表明我们大约有400个重复的客户详细信息，这些信息分布在多个ID上。这可能并不意味着有400个重复的客户，因为我们也可能有多个同名的人住在同一个邮编下，但由于我们也考虑了年龄，所以这些很可能是所有冗余的重复。如果存在任何错误重复，考虑到数据集的大小，它们很可能是非常小的百分比，因此没有必要过分关注这一点，现在我们可以这样说，每个姓名、邮编和年龄的唯一组合都是一个唯一的客户。数据建模工作的本质是总会有一个误差范围。
- en: Figure 3.14 summarizes what we have done so far with the CRM data.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14总结了到目前为止我们对CRM数据所做的工作。
- en: '![figure](../Images/3-14.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-14.png)'
- en: Figure 3.14 First steps in processing the CRM data
  id: totrans-242
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.14 处理CRM数据的第一步
- en: Joining datasets to enhance one with information from another
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将数据集连接起来以增强一个数据集，使用另一个数据集的信息
- en: 'The next step is to transform the CRM data to the same schema as the customers
    from the purchase table, and we also need to enhance the registered customers
    in the purchase history with details from the CRM data. So far, we only have IDs
    for those customers, but we need their names, postcodes, and ages. Not all of
    them will be found in the CRM data, but we can join the two and populate as many
    rows as we can. We will use a left join for this as that will ensure we keep all
    the rows in the original data regardless of whether we find a match in the other.
    The code for this is as follows, and the result is shown in figure 3.15:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将CRM数据转换为与购买表中的客户相同的模式，并且我们还需要用CRM数据中的详细信息增强购买历史中的注册客户。到目前为止，我们只有这些客户的ID，但我们需要他们的名字、邮编和年龄。并非所有这些信息都能在CRM数据中找到，但我们可以将两者连接起来，尽可能填充更多的行。我们将使用左连接来完成这个操作，因为这将确保无论我们在另一侧找到匹配与否，我们都保留原始数据中的所有行。以下是这个操作的代码，结果如图3.15所示：
- en: '[PRE17]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![figure](../Images/3-15.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-15.png)'
- en: Figure 3.15 Checking for missing values after merging the sales and CRM data
  id: totrans-247
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.15 合并销售和CRM数据后的缺失值检查
- en: One `pandas`-specific peculiarity is that columns that appear in both tables
    get an `_x` and `_y` suffix by default. We overrode this here to be more descriptive,
    so the ones with `_sales` are from the source data—the purchases—and the `_crm`
    suffix is given to the merged data, in this case, the CRM data.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`的一个特定特性是，同时出现在两个表中的列默认会得到一个`_x`和`_y`后缀。我们在这里覆盖了这个特性，使其更具描述性，因此带有`_sales`后缀的是源数据——购买数据，而`_crm`后缀是给合并数据的，在这种情况下，是CRM数据。'
- en: 'Given that there were around 33,000 rows in the sales data and 26,000 rows
    missing from the newly added CRM customer columns, we can see we matched around
    7,000 rows on customer ID. That is, customers in 7,000 purchases had their records
    stored in the CRM table. What we have now is a dataset where 7,000 customer records
    are in columns ending in `_crm`, which we should merge into the ones marked `_sales`,
    which contain customer data from guest checkouts. First, we define a filter to
    select only rows with a customer ID, thus excluding guests and rows with customer
    information in the `crm`-suffixed columns:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 由于销售数据中大约有33,000行，而新添加的CRM客户列中缺失了26,000行，我们可以看到我们在客户ID上匹配了大约7,000行。这意味着7,000次购买的客户记录存储在CRM表中。我们现在有一个数据集，其中7,000个客户记录位于以`_crm`结尾的列中，我们应该将这些合并到标记为`_sales`的列中，这些列包含客户结账时的客户数据。首先，我们定义一个过滤器来选择只有客户ID的行，从而排除访客和包含`crm`后缀列中客户信息的行：
- en: '[PRE18]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This filter can then be applied to identify these rows as having been found
    in the CRM data:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以使用此过滤器来识别这些行在CRM数据中已被找到：
- en: '[PRE19]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The output is shown in figure 3.16.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如图3.16所示。
- en: '![figure](../Images/3-16.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-16.png)'
- en: Figure 3.16 Number of rows with customer information coming from the CRM data,
    after merging
  id: totrans-255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.16 合并CRM数据后包含客户信息的行数
- en: 'This 7,114 number tallies with what we observed earlier, that around 7,000
    rows have now had their customer information updated. Time to copy over data from
    `crm`-suffixed columns to our `_sales` suffixed ones and only keep the latter
    to get back to our original schema:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这个7,114的数量与我们之前观察到的相符，即现在大约有7,000行客户信息已经更新。现在是时候将`crm`后缀列中的数据复制到我们`_sales`后缀列中，并且只保留后者，以回到原始模式：
- en: '[PRE20]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here, we simply copied over the first name, surname, and postcode to overwrite
    the missing values in `sales`-suffixed columns with CRM customer data in the `crm`-suffixed
    ones. Now we’re ready to remove the latter:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们简单地复制了名字、姓氏和邮编来覆盖`sales`后缀列中CRM客户数据在`crm`后缀列中的缺失值。现在我们准备移除后者：
- en: '[PRE21]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The output is shown in figure 3.17 and is what we’d expect. The schema is now
    the same as before, apart from a new `in_crm_data` flag, and the customer data
    from purchases has been enhanced with CRM data where possible.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如图3.17所示，这是我们预期的结果。模式现在与之前相同，除了一个新的`in_crm_data`标志，购买数据中的客户信息已经尽可能用CRM数据增强了。
- en: '![figure](../Images/3-17.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-17.png)'
- en: Figure 3.17 Combined purchase and CRM customer data
  id: totrans-262
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.17 合并购买和CRM客户数据
- en: Immediately in the second row, we notice an example of a customer who purchased
    with a registered account, so they are not guests, but their details have been
    filled in via the CRM dataset. What remains is to check for and add customer details
    that exist in our CRM system but do not appear in our purchases. There may be
    reasons for this; perhaps those customers bought something on the phone, and those
    sales do not get recorded in the same place. Whatever the reason, it is a possibility
    that we need to account for to ensure full coverage.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二行立即注意到一个例子，一个客户使用注册账户购买了商品，所以他们不是客人，但他们的详细信息是通过CRM数据集填充的。剩下要做的就是检查并添加存在于我们的CRM系统中但未出现在我们的购买记录中的客户详细信息。可能存在一些原因；也许那些客户在电话上购买了商品，而这些销售没有记录在同一地方。无论原因是什么，这是一个我们需要考虑的可能性，以确保全面覆盖。
- en: Using sets to cross-reference two datasets
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用集合交叉引用两个数据集
- en: 'To find these records, we employ a Python trick to subtract one set of customer
    IDs from another, leaving us with the difference:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到这些记录，我们使用Python技巧从一组客户ID中减去另一组，从而得到差集：
- en: '[PRE22]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here, “set” refers to the rigorous mathematical definition of a unique collection
    of items, and “difference” means the subtraction of one set from another, leaving
    us with only customer IDs that appear in the CRM data but not in purchases. The
    output tells us there are 711 such customers whose details need to be added to
    our growing customer dataset. We simply concatenate/union the data with the customers
    corresponding to the IDs we have just selected:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，“集合”指的是一组独特项目的严格数学定义，“差集”则意味着从一个集合中减去另一个集合，从而只留下在CRM数据中出现但不在购买记录中的客户ID。输出结果显示，有711位这样的客户需要将他们的详细信息添加到我们不断增长的客户数据集中。我们只需将数据与刚刚选定的ID对应的客户数据连接/合并：
- en: '[PRE23]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'One final aspect of this data to clean up is that for these new customers,
    we don’t have data for our source flags, so we fill them in with default values.
    Customers added from the CRM data will have their `in_crm_data` flag set to `True`,
    `in_purchase_data` as `False`, and since they weren’t guests, `is_guest` as `False`.
    The output of the following code is shown in figure 3.18:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 需要清理的此数据的最后一个方面是，对于这些新客户，我们没有源标志的数据，因此我们用默认值填充它们。从CRM数据添加的客户将他们的`in_crm_data`标志设置为`True`，`in_purchase_data`设置为`False`，因为他们不是客人，所以`is_guest`设置为`False`。以下代码的输出显示在图3.18中：
- en: '[PRE24]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![figure](../Images/3-18.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-18.png)'
- en: Figure 3.18 After merging the CRM data and cleaning it, there are no missing
    values for our source flags.
  id: totrans-272
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.18 合并并清理CRM数据后，我们的源标志没有缺失值。
- en: Let’s review what we have done with the CRM data before moving on. Figure 3.19
    shows all the steps we have taken.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们回顾一下我们对CRM数据所做的工作。图3.19显示了我们所采取的所有步骤。
- en: '![figure](../Images/3-19.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-19.png)'
- en: Figure 3.19 The steps we took to explore the CRM data and export customer information
  id: totrans-275
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.19 探索CRM数据并导出客户信息的步骤
- en: To summarize, we now have a customer dataset of all customers who made a purchase,
    including guest checkouts, as well as data from our CRM system, including customers
    who exist only in the CRM data and have no recorded purchases. We now need to
    repeat this process with data in the customer database, which is structurally
    similar to the CRM data.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们现在有一个客户数据集，包括所有进行过购买的客户，包括使用注册账户购买的客户，以及来自我们的CRM系统的数据，包括仅存在于CRM数据中且没有记录购买的客户。现在我们需要用客户数据库中的数据重复这个过程，该数据库的结构与CRM数据相似。
- en: Exploring a third dataset
  id: totrans-277
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 探索第三个数据集
- en: 'Time to look at our customer database. The code will be similar to the one
    used to manipulate the CRM data but is included for completeness:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 现在来看看我们的客户数据库。代码将与用于操作CRM数据的代码类似，但这里包含以示完整：
- en: '[PRE25]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The output is `(23476,` `5)`, meaning we have over 23,000 customer records,
    which is significantly more than in our CRM data. A preview of what this data
    looks like is shown in figure 3.20.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是`(23476,` `5`)`，这意味着我们有超过23,000个客户记录，这比我们的CRM数据中的记录多得多。此数据的外观预览显示在图3.20中。
- en: '![figure](../Images/3-20.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-20.png)'
- en: Figure 3.20 The first few rows of the customer data
  id: totrans-282
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.20 客户数据的前几行
- en: 'The following code checks for missing data and produces the output shown in
    figure 3.21:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码检查缺失数据，并产生图3.21所示的输出：
- en: '[PRE26]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![figure](../Images/3-21.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-21.png)'
- en: Figure 3.21 No missing data in the customer database
  id: totrans-286
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.21 客户数据库中没有缺失数据
- en: 'We sanitize our columns like we did for the CRM data:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们像处理CRM数据那样清理我们的列：
- en: '[PRE27]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, we can check whether customer ID is unique and how many unique combinations
    of customer information we have:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以检查客户ID是否唯一以及我们有多少独特的客户信息组合：
- en: '[PRE28]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This code yields the same output as in the CRM data, namely an empty Python
    collection, meaning there are no instances of the same customer ID appearing twice:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码产生与CRM数据相同的输出，即一个空的Python集合，这意味着没有相同的客户ID出现两次：
- en: '[PRE29]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The output of the previous code tells us that 23,476 rows represent 19,889 unique
    combinations of customer details, so we potentially have around 3,500 duplicate
    records to handle. We will do this once all the customer data has been merged
    into a single table.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 上一段代码的输出告诉我们有23,476行代表19,889个独特的客户详细信息组合，因此我们可能需要处理大约3,500个重复记录。我们将在所有客户数据合并到一个单独的表中后进行此操作。
- en: Merging all our data sources
  id: totrans-294
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 合并所有我们的数据源
- en: 'The next step is to merge the customer information into the growing customer
    data by joining them. Again, we give the duplicate column names meaningful suffixes
    to show which table they came from:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将客户信息通过连接合并到不断增长的客户数据中。同样，我们给重复的列名赋予有意义的后缀，以显示它们来自哪个表：
- en: '[PRE30]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The output of this merge is shown in figure 3.22.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 此合并的输出显示在图3.22中。
- en: '![figure](../Images/3-22.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-22.png)'
- en: Figure 3.22 The first few rows of the sales and CRM customers merged with the
    customer database
  id: totrans-299
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.22 销售和CRM客户与客户数据库合并的前几行
- en: 'As with the CRM data, we have duplicates of the customer detail columns. We
    will now identify which rows were successfully merged with the customer database,
    mark them with a final flag `in_customer_data`, and copy those details over to
    the `_sales`-suffixed columns before finally removing the redundant columns and
    arriving at our final schema. The output for the following code is shown in figure
    3.23:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 与CRM数据一样，客户详细信息列有重复项。现在我们将确定哪些行成功合并到客户数据库中，用最终的标志`in_customer_data`标记它们，并在最终删除冗余列并达到最终模式之前，将这些详细信息复制到以`_sales`后缀命名的列中。以下代码的输出显示在图3.23中：
- en: '[PRE31]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![figure](../Images/3-23.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-23.png)'
- en: Figure 3.23 The distribution of the new flag, showing whether a customer’s details
    appear in the customer database
  id: totrans-303
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.23 新标志的分布，显示客户的详细信息是否出现在客户数据库中
- en: 'Almost two-thirds of purchases relate to customers whose details are stored
    in the customer database. We can now update the original customer details, those
    with a `_sales` suffix, with details from the customer database:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎三分之二的销售与存储在客户数据库中的客户详细信息相关。我们现在可以用客户数据库中的详细信息更新原始客户详细信息，即带有`_sales`后缀的详细信息：
- en: '[PRE32]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '#1 A filter to mark customers whose details we copy over'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 一个过滤器来标记我们将复制的客户详细信息'
- en: '#2 We then overwrite those customers’ details.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 然后我们覆盖那些客户的详细信息。'
- en: '#3 Finally, we merge the columns into the final schema.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 最后，我们将列合并到最终模式中。'
- en: 'We also need to add any customers present in the customer database who do not
    appear in the purchases table:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要添加任何出现在客户数据库中但不在购买表中的客户：
- en: '[PRE33]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This returns 1,423 additional customers to add:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回1,423个额外的客户以添加：
- en: '[PRE34]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Finally, we update the source flags to reflect their correct defaults if they
    are missing. Any newly added customers are not guests, didn’t come from purchases
    or the CRM data, but are present in the customer database:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果它们缺失，我们将更新源标志以反映它们的正确默认值。任何新添加的客户都不是访客，也没有来自购买或CRM数据，但存在于客户数据库中：
- en: '[PRE35]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We can now inspect the final schema of our combined customer data model, shown
    in figure 3.24:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以检查我们合并的客户数据模型的最终模式，如图3.24所示：
- en: '[PRE36]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![figure](../Images/3-24.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-24.png)'
- en: Figure 3.24 A preview of the customer data merged from all three sources
  id: totrans-318
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.24 从所有三个来源合并的客户数据的预览
- en: From figure 3.24, we can already understand the combinations of where customer
    data comes from. The third row shows us another edge case we had to be prepared
    for—a purchase from a registered customer whose details we do not have in either
    the CRM data or the customer database. We know very little about this customer,
    but they were given an ID, so their details may be in another system. As analysts,
    we would reach out internally to the business and find an explanation. Until then,
    we should keep these rows as they are potentially legitimate customer entities
    and should thus be counted in our data model.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 从图3.24中，我们可以理解客户数据来源的组合。第三行显示我们不得不准备应对的另一个边缘情况——来自注册客户但我们在CRM数据或客户数据库中没有其详细信息的购买。我们对这位客户了解甚少，但他们被分配了一个ID，因此他们的详细信息可能存在于另一个系统中。作为分析师，我们会向业务内部寻求解释。在此之前，我们应该保留这些行，因为它们可能是合法的客户实体，因此应该在数据模型中计数。
- en: Let’s summarize all our steps so far. We explored three different sources of
    customer data, transformed them into the same schema, and finally merged them
    into a single table of customer information. Figure 3.25 shows all our steps so
    far.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结到目前为止的所有步骤。我们探索了三种不同的客户数据源，将它们转换成相同的模式，并最终将它们合并成一个客户信息表。图3.25显示了到目前为止的所有步骤。
- en: '![figure](../Images/3-25.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-25.png)'
- en: Figure 3.25 Steps to process three sources of customer data and finally merge
    them
  id: totrans-322
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.25 处理三个客户数据源并最终合并的步骤
- en: 'Taking stock of what we have so far, we have merged our three sources of customer
    data, taking care to cover all eventualities, totaling 35,395 records. One step
    we will take before moving on to deduplication is to get a sense of the size of
    our various customer record types. There are four ways we could have added customers
    to our data model:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 总结到目前为止我们所做的工作，我们已经合并了三个客户数据源，注意覆盖所有可能情况，总计35,395条记录。在继续进行去重之前，我们将先了解我们各种客户记录类型的大小。我们可能有四种方式将客户添加到我们的数据模型中：
- en: '*Identified customers*—Customers who made a purchase and their details are
    present in either the CRM data or the customer database'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*已识别的客户*—进行了购买并且他们的详细信息存在于CRM数据或客户数据库中的客户'
- en: '*Guest checkouts*—Customers whose details come from what they entered as a
    guest'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*匿名结账*—客户的详细信息来自他们作为访客输入的信息'
- en: '*Unidentified customer IDs*—Customers with a valid ID but with no corresponding
    record in either customer dataset'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*未知的客户ID*—拥有有效ID但客户数据集中没有对应记录的客户'
- en: '*Customers with no purchases*—Customers who are present in either customer
    dataset but do not appear in the purchases data'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*未购买商品的客户*—存在于客户数据集中但未出现在购买数据中的客户'
- en: 'These customer types are mutually exclusive, and their numbers should add up
    to the entire data model. We can verify this:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这些客户类型是互斥的，它们的数量应该加起来等于整个数据模型。我们可以验证这一点：
- en: '[PRE37]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The output is the following: 35,395 records in the entire data model, 23,713
    of which are identified customers, 8,300 guests, 1,248 unidentified customer IDs,
    and 2,134 customers with no purchases. The first number is the sum of the others,
    so we can be confident we did not miss any of our eventualities, and they don’t
    overlap. At this stage, we know there might be some duplication, so we move on
    to the final part of modeling our customer data—entity resolution.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：整个数据模型中有35,395条记录，其中23,713条是已识别客户，8,300条是访客，1,248条是未知的客户ID，2,134条是未购买商品的客户。第一个数字是其他数字的总和，因此我们可以确信我们没有遗漏任何可能情况，并且它们没有重叠。在这个阶段，我们知道可能存在一些重复，因此我们继续进行客户数据建模的最后部分——实体解析。
- en: 3.4.3 Applying entity resolution to deduplicate records
  id: totrans-331
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.3 应用实体解析以去重记录
- en: 'One possible kind of duplication we might have is the same customer’s details
    appearing in both the CRM data and the customer database. In this case, we might
    have rows in our data model that are exact duplicates, which are easy to drop:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 可能的一种重复情况是同一客户的详细信息同时出现在CRM数据和客户数据库中。在这种情况下，我们的数据模型中可能有完全相同的重复行，这些行很容易删除：
- en: '[PRE38]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '#1 Checks the count of rows before deduplicating'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 在去重之前检查行数'
- en: '#2 Checks the row count again to see any impact'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 再次检查行数以查看是否有影响'
- en: The output for both statements is the same—35,395 records—meaning there are
    no exact duplicates. In this case, this is because we updated our flags along
    the way. That is, customers present in multiple data sources simply have multiple
    source flags set to `True`, so there were no exact duplicates to drop.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 两个语句的输出相同——35,395条记录——这意味着没有精确的重复项。在这种情况下，这是因为我们在过程中更新了我们的标志。也就是说，存在于多个数据源中的客户只是设置了多个源标志为`True`，因此没有精确的重复项需要删除。
- en: 'One consideration at this point is that guest checkout customers are missing
    the `age` column. There is a choice to make here: Do we drop this column because
    our final data model would contain missing data, or do we include it but avoid
    using it for deduplication? If you’re going to drop data, it’s better to do it
    as late as possible, so it makes sense to keep that column. When we deduplicate
    the records, we can decide whether two customers with otherwise identical information,
    but one has their age filled in and the other doesn’t, are the same customer.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上需要考虑的一个因素是，访客结账客户缺少`年龄`列。这里有一个选择：我们是删除这个列，因为我们的最终数据模型将包含缺失数据，还是包含它但避免在去重中使用它？如果你打算删除数据，最好尽可能晚地做，因此保留该列是有意义的。当我们去重记录时，我们可以决定两个在其他信息上完全相同的客户是否是同一客户，其中一个填写了年龄，而另一个没有。
- en: Filling in missing data with unique identifiers
  id: totrans-338
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 用唯一标识符填充缺失数据
- en: 'Another decision we can make is whether to give guest accounts fake customer
    IDs rather than leaving them as missing data. When we get to the deduplication
    step, it is a good idea to link accounts together, that is, identify customer
    IDs that relate to the same underlying customer entity. With guest accounts, we
    cannot do this unless they also have unique identifiers, so it makes sense to
    give them their own IDs. One idea is to allocate a range of integers only for
    guest accounts. We can look at the existing IDs to see the current range:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做出的另一个决定是，是否给访客账户分配虚假的客户ID，而不是让他们保持为缺失数据。当我们到达去重步骤时，将账户链接在一起是一个好主意，也就是说，识别与同一基础客户实体相关的客户ID。对于访客账户，除非它们也有唯一的标识符，否则我们无法做到这一点，因此给他们自己的ID是有意义的。一个想法是为访客账户分配一个整数范围。我们可以查看现有的ID以查看当前的范围：
- en: '[PRE39]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output tells us the current IDs range from the number 1 all the way to
    9-digit integers, so a safe range would need to be well outside this. One option
    is to use negative numbers instead to identify each unique guest (i.e., each combination
    of guest customer data points). Negative IDs are unusual for unique identifiers,
    but the alternative approach of allocating an ID range for guests, say, in the
    12-digit range, feels just as artificial. Another option could be to create alphanumeric
    identifiers, like a number preceded by a “G” for “guest,” but since customer IDs
    are otherwise all integers, it’s a personal choice not to branch out into the
    alphanumeric:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 输出告诉我们当前ID的范围从数字1一直延伸到9位数整数，因此一个安全的范围需要远远超出这个范围。一个选项是使用负数来识别每个唯一的访客（即每个访客客户数据点的组合）。对于唯一标识符来说，负ID是不寻常的，但为访客分配ID范围的替代方法，比如在12位数的范围内，感觉同样不自然。另一个选项可能是创建字母数字标识符，比如以“G”开头的数字，表示“访客”，但由于客户ID都是整数，这是一个个人选择，不扩展到字母数字：
- en: '[PRE40]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '#1 We create an automatic range of values starting from –1 and decreasing.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 我们创建一个从-1开始递减的自动值范围。'
- en: Now, our guest customers have IDs ranging from –1 to –8300\. At this stage,
    we should have no duplicate records for customers that appeared in multiple datasets.
    However, we could still have duplicate records for the same customer if they somehow
    received two different customer IDs in different systems. Customer John Smith,
    with an ID of 123, might still be the same customer as John Smith, with an ID
    of 456.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的访客客户ID范围从-1到-8300。在这个阶段，我们应该没有出现在多个数据集中的客户重复记录。然而，如果他们在不同的系统中以某种方式收到了两个不同的客户ID，我们仍然可能有相同的客户的重复记录。拥有ID为123的John
    Smith可能与拥有ID为456的John Smith是同一个人。
- en: Now, we are at the final deduplication phase; we might not be talking about
    a large percentage of duplicate records. As I mentioned when discussing iteration,
    in the first pass, we might even choose to ignore the duplication, in which case
    we already have our first customer data model. However, this is a task where we
    want to be as accurate as possible and would ideally reduce duplication to zero.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们处于最后的去重阶段；我们可能不会谈论大量重复的记录。正如我在讨论迭代时提到的，在第一次遍历中，我们甚至可以选择忽略重复项，在这种情况下，我们已经有了一个客户数据模型。然而，这是一个我们希望尽可能准确的任务，并理想地将重复项减少到零。
- en: Finding and linking duplicate records
  id: totrans-346
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 寻找和链接重复记录
- en: The most straightforward initial deduplication approach is to say that if two
    customers have the same values for first name, surname, postcode, and age, they
    are the same customer. However, this might be a problem if we have a guest account
    who is the same customer as one already in the CRM system, which we wouldn’t know
    if we included age in the comparison, as it would be missing for the guest record.
    Using only first name, surname, and postcode may be a combination good enough
    to start with. We can write some code now to find all customer IDs whose first
    name, last name, and postcode match exactly.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 最直接的最初去重方法是说，如果两个客户在名字、姓氏、邮编和年龄方面的值相同，那么他们是同一个客户。然而，如果我们有一个访客账户，它与CRM系统中的某个客户相同，而我们又没有在比较中包含年龄，因为访客记录中可能缺少年龄信息，这可能会成为一个问题。仅使用名字、姓氏和邮编可能是一个足够好的起点组合。我们现在可以编写一些代码来找到所有名字、姓氏和邮编完全匹配的客户ID。
- en: 'First, we create an object, `duplicates`, which is a list of all customer records
    that are identical to one another in the columns we specified. The `keep=False`
    parameter ensures we keep all relevant records, not just the duplicate ones. Having
    the `keep` parameter as anything else would drop the first instance and only keep
    the other rows, the duplicates:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个对象，`duplicates`，它是一个列表，包含所有在我们指定的列中彼此完全相同的客户记录。`keep=False`参数确保我们保留所有相关记录，而不仅仅是重复的记录。将`keep`参数设置为其他任何值都会丢弃第一个实例，只保留其他行，即重复项：
- en: '[PRE41]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We can now create a lookup dictionary where each customer ID is linked to all
    the other records, which are its duplicates. A sample of this dictionary is shown
    in figure 3.26:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以创建一个查找字典，其中每个客户ID都链接到所有其他记录，即它的重复记录。图3.26展示了这个字典的一个样本：
- en: '[PRE42]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![figure](../Images/3-26.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-26.png)'
- en: Figure 3.26 A sample of the duplicate lookup dictionary
  id: totrans-353
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.26重复查找字典的样本
- en: 'This dictionary tells us that, for example, there are two customer IDs for
    Aaliyah Harvey at postcode SO760SX: 22648 and 27397\. We can use this dictionary
    to create a new column, `other_customer_ids`, where we store this list for accounts
    that have duplicates. A sample of the resulting data is shown in figure 3.27:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 这个字典告诉我们，例如，在邮编为SO760SX的地方，Aaliyah Harvey有两个客户ID：22648和27397。我们可以使用这个字典来创建一个新的列，`other_customer_ids`，其中我们为具有重复项的账户存储这个列表。图3.27展示了结果数据的一个样本：
- en: '[PRE43]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![figure](../Images/3-27.png)'
  id: totrans-356
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-27.png)'
- en: Figure 3.27 A sample of rows with the new `other_customer_ids` column
  id: totrans-357
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.27具有新`other_customer_ids`列的行样本
- en: 'Figure 3.27 shows that, for example, Harley Palmer at postcode HR250EJ has
    two customer records: IDs 31266 and 5411\. Strictly speaking, our `other_customer_ids`
    column should not be self-referential, so we should remove a customer’s own ID
    from it. We can create a small function to do that and apply it to the rows with
    duplicates. Figure 3.28 shows the data after we run the following code. From this,
    we can notice an instance where a guest account for Max Moore, at postcode M902XX,
    is linked to a registered customer ID as a duplicate:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.27显示，例如，邮编为HR250EJ的Harley Palmer有两个客户记录：ID 31266和5411。严格来说，我们的`other_customer_ids`列不应该自引用，因此我们应该从其中移除客户的自身ID。我们可以创建一个小的函数来完成这个任务，并将其应用于具有重复项的行。图3.28显示了运行以下代码后的数据。从这些数据中，我们可以注意到一个实例，即邮编为M902XX的Max
    Moore的访客账户作为重复项与一个已注册的客户ID相关联：
- en: '[PRE44]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![figure](../Images/3-28.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/3-28.png)'
- en: Figure 3.28 The new `duplicate_customer_ids` column
  id: totrans-361
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.28新的`duplicate_customer_ids`列
- en: As a reminder, what we want our database to contain is one row per customer,
    and each customer who has duplicate records has this fact marked somehow. The
    data, as it stands, has multiple rows for the same customer entity, one from the
    point of view of each, an example of which is shown in figure 3.29\. Customers
    31266 and 5411 are likely the same entity, and their duplication is recorded from
    both points of view.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，我们希望我们的数据库包含每名客户一行，并且每个有重复记录的客户都以某种方式标记这一事实。目前的数据，对于同一客户实体有多个行，每个行都是从不同角度的，如图3.29所示。客户31266和5411可能是同一实体，他们的重复记录是从两个角度记录的。
- en: '![figure](../Images/3-29.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-29.png)'
- en: Figure 3.29 The same customer entity represented as two rows
  id: totrans-364
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.29 同一客户实体以两行表示
- en: There are two ways to tackle this problem. One is to delete one of the duplicate
    records entirely, thus reducing the data down to one row per entity. The `duplicate_customer_
    ids` column would still record the fact that this customer entity is referred
    to by multiple customer IDs, but the rest of the customer data for the duplicate
    ID would no longer be there. Ideally, each row would be a deduplicated customer
    record, but another option is to create an `is`_`main` flag against rows to identify
    them this way. The advantage is that all data lineage is preserved, and the downside
    is that you can’t simply count the rows anymore; you would need to remember to
    filter on `is`_`main` each time. Choosing which representation is better for your
    data model will again depend on the context in which the data model will be used.
    Technically, if customers 1480 and 1481 are the same customer, they’re the same
    customer *entity* but two distinct *records,* and my personal preference is to
    delete as little data as possible, so in the example solution, I’ve used the `is_main`
    flag approach.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题有两种方法。一种是将其中一个重复记录完全删除，从而将数据减少到每个实体一行。`duplicate_customer_ ids`列仍然会记录这个客户实体被多个客户ID引用的事实，但重复ID的客户数据的其余部分将不再存在。理想情况下，每行都是一个去重后的客户记录，但另一个选项是创建一个`is_main`标记来识别它们。优点是保留了所有数据来源，缺点是你不能再简单地计数行数了；你需要记住每次都要过滤`is_main`。选择哪种表示方式更适合你的数据模型将再次取决于数据模型将使用的上下文。技术上，如果客户1480和1481是同一客户，他们是同一客户*实体*但两个不同的*记录*，我个人的偏好是尽可能少地删除数据，所以在示例解决方案中，我使用了`is_main`标记方法。
- en: Whichever representation you choose, you still need to decide which customer
    record is the main one. One method is to simply use the first one you encounter.
    It is unlikely to make a big difference, but a more principled way would be to
    use a better metric, like number of transactions, total spending, and so forth,
    to decide which customer record deserves “main” status.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你选择哪种表示方式，你仍然需要决定哪个客户记录是主要的。一种方法是简单地使用你遇到的第一个。这不太可能造成大的差异，但更原则性的方法可能是使用更好的指标，比如交易次数、总消费等等，来决定哪个客户记录应获得“主要”状态。
- en: 'The technical trick to create the flag is to generate a column that gives each
    duplicate a rank and a row number in the order they are encountered. Anything
    with a `rank` of 1 simply becomes a main account. This approach will work for
    duplicates and unique records, as the first instance of a combination of customer
    details will always have a `rank` of 1:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 创建标记的技术技巧是生成一列，为每个重复项分配一个排名和它们被遇到的行号。任何排名为1的项简单地成为主账户。这种方法适用于重复项和唯一记录，因为客户详情组合的第一个实例总是会有一个排名为1：
- en: '[PRE45]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Figure 3.30 shows the same duplicate pair as in figure 3.24, with the new `rank`
    column added.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.30显示了与图3.24相同的重复对，并添加了新的`rank`列。
- en: '![figure](../Images/3-30.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-30.png)'
- en: Figure 3.30 Our data with a new `rank` column
  id: totrans-371
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.30 带有新`rank`列的数据
- en: 'Now, we have one row per customer record, but to count distinct customer entities,
    we can create our `is_main` flag to make the data model more obvious. Once we’ve
    done this, we no longer need our `rank` column:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们每条客户记录一行，但要计算不同的客户实体，我们可以创建我们的`is_main`标记，使数据模型更明显。一旦我们这样做，我们就不再需要我们的`rank`列：
- en: '[PRE46]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Finally, we can count the records:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以计算记录数：
- en: '[PRE47]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The output shows that out of 35,395 records, 27,394 are unique/main records.
    This assumes that two customers with the same name and postcode are the same customer
    and that there are only *exact* duplicates. To ensure our solution is as accurate
    as possible, given the data, we can try to match records that are *almost* identical.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，在35,395条记录中，有27,394条是唯一的/主要记录。这假设两个具有相同姓名和邮编的客户是同一个客户，并且只有*完全相同*的重复。为了确保我们的解决方案尽可能准确，考虑到数据，我们可以尝试匹配几乎相同的记录。
- en: Using entity resolution tools to improve deduplication
  id: totrans-377
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用实体解析工具来提高去重
- en: Once our dataset is deduplicated, around the 27,000 mark, we may wish to apply
    more advanced ideas in future iterations. One is fuzzy string matching to link
    accounts that differ by a simple typo. Another idea is to investigate whether
    you could use purchasing patterns to identify identical customers. In the case
    where two customers match on most columns but, say, differ in their age, you could
    use additional information like their purchases to decide whether they refer to
    the same customer. For this example, we’ll identify accounts that are almost identical
    and see if that makes a difference. When it comes to more complex topics, such
    as record linkage, there is often a Python package we can use rather than implement
    any algorithms ourselves. In this case, we will use the Python Record Linkage
    Toolkit, which implements multiple algorithms for record deduplication and linking
    efficiently. An important aspect of being an analyst today is identifying when
    to use the work of others. We don’t always need a deep understanding of the underlying
    algorithms and implementations before we use external libraries as long as we
    know what to expect from the output and can investigate problems when they occur.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的数据集去重完成，大约在27,000个记录左右，我们可能希望在未来的迭代中应用更高级的想法。一个是模糊字符串匹配，用于链接因简单错误而不同的账户。另一个想法是调查是否可以使用购买模式来识别相同的客户。在两个客户在大多数列上匹配但，例如，年龄不同的情况下，你可以使用额外的信息，如他们的购买记录，来决定他们是否指的是同一个客户。对于这个例子，我们将识别几乎相同的账户，看看这是否有影响。当涉及到更复杂的话题，如记录链接时，我们通常可以使用Python包而不是自己实现任何算法。在这种情况下，我们将使用Python记录链接工具包，该工具包高效地实现了多个记录去重和链接算法。作为一名分析师，一个重要的方面是确定何时使用他人的工作。只要我们知道输出应该是什么，并且能够在出现问题时进行调查，我们就不一定需要在使用外部库之前对底层算法和实现有深入的了解。
- en: 'Let’s feed our data into this toolkit, a module called `recordlinkage`:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将数据输入到这个工具包中，一个名为`recordlinkage`的模块：
- en: '[PRE48]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We can effectively follow the basic tutorial from the toolkit’s data deduplication
    page ([https://mng.bz/nRYa](https://mng.bz/nRYa)) and modify it to our needs.
    First, we index our dataset so that we don’t try to compare every pair of records
    to each other but tell the code that two records at the same postcode should be
    tested for duplication. This assumes there are no typos in the postcode, which
    may not be the case, but it will make our code run much faster as there are fewer
    comparisons to make. Sometimes, we need to trade off accuracy and performance:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以有效地遵循工具包数据去重页面上的基本教程（[https://mng.bz/nRYa](https://mng.bz/nRYa)）并根据我们的需求进行修改。首先，我们对数据集进行索引，这样我们就不需要尝试比较每一对记录，而是告诉代码在同一邮编下的两个记录应该被测试是否存在重复。这假设邮编没有错误，但这可能并不总是成立，但这样我们的代码运行速度会更快，因为需要比较的记录更少。有时，我们需要在准确性和性能之间进行权衡：
- en: '[PRE49]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '#1 Creates an Index object'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 创建一个索引对象'
- en: '#2 Marks postcode as a column to use for indexing'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将邮编标记为用于索引的列'
- en: '#3 Applies the indexing to the data'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将索引应用于数据'
- en: 'We set the index to be the `customer_id` column because that way, our final
    dataset of matches will retain this name, as we will see. Next, we set up the
    comparison rules: How should our records be compared against each other? Should
    matches be exact or allowed to be fuzzy? We can also choose the algorithm with
    which to make a fuzzy comparison between strings. Here, we use the Damerau–Levenshtein
    method, which is a measure of *edit distance*, that is, the number of individual
    character edits required to get from one string to another. The higher the distance,
    the less similar the two strings are. Here, you could experiment with different
    comparison methods and observe the results:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将索引设置为`customer_id`列，因为这样我们的最终匹配数据集将保留这个名称，正如我们将看到的。接下来，我们设置比较规则：我们的记录应该如何相互比较？匹配应该是精确的还是允许模糊匹配？我们还可以选择用于字符串之间模糊比较的算法。在这里，我们使用Damerau–Levenshtein方法，这是一种*编辑距离*的度量，即从一个字符串到另一个字符串所需的单个字符编辑次数。距离越高，两个字符串越不相似。在这里，您可以尝试不同的比较方法并观察结果：
- en: '[PRE50]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '#1 Creates a comparison object'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 创建一个比较对象'
- en: '#2 Names should be fuzzy comparisons; anything over 85% similar is a match.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 名称应该是模糊比较；任何超过85%相似度的都是匹配。'
- en: '#3 Postcodes should match exactly.'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 邮编应该完全匹配。'
- en: 'Now, we are ready to use our comparison rules to perform the pairwise comparisons.
    This creates a DataFrame containing all compared pairs and whether each of our
    comparison criteria was met. A sample of the output is shown in figure 3.31:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备使用我们的比较规则进行成对比较。这创建了一个包含所有比较对以及每个比较标准是否满足的DataFrame。输出样本如图3.31所示：
- en: '[PRE51]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![figure](../Images/3-31.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-31.png)'
- en: Figure 3.31 A sample of the output of our record linkage attempt
  id: totrans-394
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.31展示了我们的记录链接尝试的输出样本
- en: 'This sample shows that, for example, customer IDs 7523 and 7466 match on postcode
    but not on name. We can reduce this data down to only the cases where all comparisons
    returned a match:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 这个样本显示，例如，客户ID 7523和7466在邮编上匹配，但在姓名上不匹配。我们可以将数据缩减到所有比较都返回匹配的案例：
- en: '[PRE52]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The output is the same structure as figure 3.31 but with only perfect matches.
    Next, we should merge these customer IDs back to the original dataset and see
    if we’ve improved our record-linking attempts from before:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的结构与图3.31相同，但只有完美匹配。接下来，我们应该将这些客户ID合并回原始数据集，看看我们是否改进了之前的记录链接尝试：
- en: '[PRE53]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '#1 Creates a new DataFrame containing only the two columns of customer IDs'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 创建一个新的DataFrame，只包含两个客户ID列'
- en: '#2 Joins customer data on the first customer ID'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 在第一个客户ID上连接客户数据'
- en: '#3 Joins customer data on the second customer ID'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 在第二个客户ID上连接客户数据'
- en: The `matches` dataset is already deduplicated in the sense that if customers
    1 and 2 are duplicates, we do not have two records from each of their perspectives,
    so joining on both customer IDs means we ensure we have merged the main customer
    with all the duplicates found by `recordlinkage`. Figure 3.32 shows the relevant
    columns of our current merged data. There is an instance where both the `duplicate_customer_ids`
    column, created by looking for exact matches, and the new `customer_id` columns,
    created by the latest fuzzy matching attempt, agree with each other on records
    5411 and 31226.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '`matches`数据集已经去重，即如果客户1和客户2是重复的，我们不会从每个客户的角度各自有两个记录，因此在两个客户ID上连接意味着我们确保将主要客户与`recordlinkage`找到的所有重复项合并。图3.32显示了当前合并数据的相关列。有一个实例，即由查找精确匹配创建的`duplicate_customer_ids`列和由最新的模糊匹配尝试创建的新`customer_id`列在记录5411和31226上达成一致。'
- en: '![figure](../Images/3-32.png)'
  id: totrans-403
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-32.png)'
- en: Figure 3.32 New columns added by merging the linked records back to our customer
    data model
  id: totrans-404
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.32展示了将链接的记录合并回我们的客户数据模型后添加的新列
- en: One problem we need to resolve with this new merged data is that records with
    multiple duplicates are now repeated (e.g., customer ID 30730), as shown in figure
    3.33.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要解决的新合并数据的一个问题是，现在具有多个重复项的记录现在是重复的（例如，客户ID 30730），如图3.33所示。
- en: '![figure](../Images/3-33.png)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-33.png)'
- en: Figure 3.33 Three duplicates means three rows of data, which we need to merge
    into one
  id: totrans-407
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.33显示有三个重复项意味着有三行数据，我们需要将它们合并为一行
- en: 'To merge these rows into a single row, as we have in the `duplicate_customer_ids`
    column, we can write a small function to collect all linked customer IDs for a
    given customer ID. We joined our linked pairs twice, so both the `customer_id_1_customers`
    and `customer_id_2_matches` columns could refer to our customer, and the `customer_id_2_
    customers` and `customer_id_1_matches` columns could refer to the duplicate ID:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 要将这些行合并成一行，就像我们在`duplicate_customer_ids`列中所做的那样，我们可以编写一个小的函数来收集给定客户ID的所有关联客户ID。我们连接了我们的关联对两次，因此`customer_id_1_customers`和`customer_id_2_matches`列都可以引用我们的客户，而`customer_id_2_customers`和`customer_id_1_matches`列可以引用重复的ID：
- en: '[PRE54]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Our function collects the necessary values from multiple rows into a single
    list, and we apply this function to each customer ID, in turn, to reduce the dataset
    down to one row per customer ID again. The output is shown in figure 3.34.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的功能将多个行中的必要值收集到一个列表中，然后我们依次将此函数应用于每个客户ID，将数据集减少到每个客户ID一行。输出如图3.34所示。
- en: '![figure](../Images/3-34.png)'
  id: totrans-411
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-34.png)'
- en: Figure 3.34 A preview of our customer IDs linked to their duplicates
  id: totrans-412
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.34 我们客户ID与其重复项链接的预览
- en: 'We can use the `customer_id` column to merge this data back to our data model,
    so we have two sets of duplicates to compare side by side—the one that only uses
    exact matches and the latest one, which also uses fuzzy string matching:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`customer_id`列将此数据合并回我们的数据模型，这样我们就有了两组重复数据可以并排比较——只使用精确匹配的那一组，以及最新的一组，它还使用了模糊字符串匹配：
- en: '[PRE55]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Our data now looks like that in figure 3.35.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据现在看起来就像图3.35中的那样。
- en: '![figure](../Images/3-35.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-35.png)'
- en: Figure 3.35 Customer data containing results of two different deduplication
    methods
  id: totrans-417
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.35 包含两种不同去重方法结果的客户数据
- en: 'Now, we can compare instances where the two columns `duplicate_customer_ids`
    and `linked_duplicates` do not agree. Figure 3.36 shows some of the rows as the
    output of the following code:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以比较两个列`duplicate_customer_ids`和`linked_duplicates`不一致的实例。图3.36显示了以下代码的输出中的一些行：
- en: '[PRE56]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '![figure](../Images/3-36.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-36.png)'
- en: Figure 3.36 Instances where the two deduplication methods disagree
  id: totrans-421
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.36 两种去重方法不一致的实例
- en: Let’s inspect one of these cases, shown in figure 3.37\. We observe that, for
    Scarlett Jackson, two additional duplicate records were found by `recordlinkage`,
    one of them referring to a Sgarlett Jagkson and another to a Scariett Jackson.
    All of these are likely to be the same customer, so it makes sense to use the
    fuzzy method to find all possible duplicates.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查这些情况中的一个，如图3.37所示。我们观察到，对于Scarlett Jackson，`recordlinkage`找到了两个额外的重复记录，其中一个指的是Sgarlett
    Jagkson，另一个指的是Scariett Jackson。所有这些很可能是同一个客户，所以使用模糊方法来查找所有可能的重复记录是有意义的。
- en: '![figure](../Images/3-37.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-37.png)'
- en: Figure 3.37 An instance where the two deduplication methods found different
    results
  id: totrans-424
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.37 两种去重方法找到不同结果的一个实例
- en: Ultimately, there are just 13 cases where the two methods disagree, so it seems
    using `recordlinkage` only gave us a marginal improvement. However, we now have
    code for the future that can deduplicate our customer data more intelligently,
    and the accuracy of our results has improved.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，只有13种情况下两种方法不一致，所以使用`recordlinkage`似乎只给我们带来了微小的改进。然而，我们现在有了未来可以更智能地去除客户数据的代码，并且我们结果的确切性得到了提高。
- en: Before we move on to the conclusions and recommendations, let’s review the entire
    analysis process shown in figure 3.38\. As with all analyses, your specific path
    may have diverged from the ones I chose.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续到结论和建议之前，让我们回顾一下图3.38中显示的整个分析过程。与所有分析一样，你的具体路径可能已经偏离了我选择的道路。
- en: '![figure](../Images/3-38.png)'
  id: totrans-427
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/3-38.png)'
- en: Figure 3.38 The entire analytical process diagram for this project
  id: totrans-428
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.38 本项目的整个分析过程图
- en: Now that we have done the work and documented our analysis, let’s move on to
    the conclusions and recommendations.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了工作并记录了我们的分析，让我们继续到结论和建议。
- en: 3.4.4 Conclusions and recommendations
  id: totrans-430
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.4 结论和建议
- en: Our initial problem statement asked for help counting customers. Our final data
    model has 35,395 rows corresponding to 27,394 unique customers, which fits our
    original estimate of “at most 33,000 customers.” However, it is a more precise
    and therefore more useful number as it is a result of all the analysis we have
    done so far. This number may be different if you decide to use the results of
    the `recordlinkage` library to create a deduplicated data model.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最初的难题是请求帮助计数客户。我们的最终数据模型有35,395行，对应27,394个独特的客户，这与我们最初的“最多33,000名客户”的估计相符。然而，这个数字更加精确，因此更有用，因为它是我们迄今为止所做所有分析的结果。如果你决定使用`recordlinkage`库的结果来创建去重数据模型，这个数字可能会有所不同。
- en: How do we assess the quality of the final solution? This is hard to quantify
    as there is no ground truth to check against, but it’s a good idea to get a sense
    of the different amounts of completeness that exist in the data model.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何评估最终解决方案的质量？这很难量化，因为没有基准事实可以对照检查，但了解数据模型中存在的不同完整程度是个不错的主意。
- en: For example, we have around 26,000 customer IDs in the purchase data that have
    no corresponding records in either customer dataset. This means we have 26,000
    customers who have signed up to make a purchase online, but we don’t have their
    details, and because they weren’t using a guest checkout, we have nothing but
    a customer ID for them in our final data model. We could choose to drop them as
    incomplete records, but we would skew our measurement of the size of the customer
    base. It is better to understand that our data model varies in completeness and
    is suitable for some tasks—like counting customers—but is not wholly suitable
    for other tasks, such as customer segmentation.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们在购买数据中有大约26,000个客户ID，这些ID在任一客户数据集中都没有对应的记录。这意味着我们有26,000名客户已经注册在线购买，但我们没有他们的详细信息，因为他们没有使用访客结账，所以我们最终数据模型中只有他们的客户ID。我们可以选择将他们作为不完整的记录删除，但这会歪曲我们对客户群规模的测量。更好地理解我们的数据模型在完整性上有所不同，适合某些任务——如计数客户——但不完全适合其他任务，如客户细分。
- en: This is a conclusion we should share with our stakeholders when presenting an
    analysis based on our data models. It is also the kind of uncertainty and ambiguity
    we need to learn to embrace and communicate.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们基于数据模型进行分析时应该与利益相关者分享的结论。这也是我们需要学会接受和传达的不确定性和模糊性。
- en: Whatever methods you use, entity resolution is hard to automate 100%. There
    will always be edge cases that make the data model less than 100% accurate. The
    value in this task lies in the fact that once you have a “best guess” customer
    data model, you can be sure that all subsequent analyses, while not perfectly
    accurate, will be the best you can do given the data that you have. Also, each
    analysis does not have to start with defining what we mean by a customer since
    that work has already been done in the data model.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用什么方法，实体解析很难自动化达到100%。总会有一些边缘情况使得数据模型低于100%的准确性。这个任务的价值在于，一旦你有了“最佳猜测”的客户数据模型，你可以确信，所有后续的分析，虽然不是完全准确的，但将是基于你所拥有的数据的最佳分析。此外，每次分析不必从定义我们所说的客户开始，因为这项工作已经在数据模型中完成了。
- en: 'Activity: Further project ideas with this data'
  id: totrans-436
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 活动：使用这些数据的进一步项目想法
- en: 'E-commerce data is rich with patterns and trends waiting to be discovered.
    Think about some other research questions that can be answered with this data.
    Here are some ideas to get you thinking:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 电子商务数据中充满了等待被发现的模式和趋势。想想看，可以用这些数据回答的其他研究问题。以下是一些启发思考的想法：
- en: Is there a way to deduplicate customers with the same name based on their purchase
    history? If there are two John Smiths at the same postcode but different customer
    IDs and different purchasing profiles, does that make it less likely they’re the
    same person?
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有没有一种方法可以根据他们的购买历史来去重具有相同名字的客户？如果有两个在相同邮编下但客户ID和购买档案不同的John Smith，这会使得他们不是同一个人的可能性降低吗？
- en: Does the data contain any information about households? Perhaps people with
    the same surname at the same postcode?
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中是否包含关于家庭的信息？也许是在同一邮编下同姓的人？
- en: Do purchasing behaviors differ between registered customers and people who checked
    out as guests?
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 购买行为在注册客户和作为访客结账的人之间是否有差异？
- en: 3.5 Closing thoughts on data modeling
  id: totrans-441
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.5 对数据建模的总结思考
- en: In this chapter, you attempted a data modeling task, perhaps without formal
    data modeling training. If you are interested in this topic more deeply, one place
    to start is the canonical *The Data Warehouse Toolkit* by Ralph Kimball and Margy
    Ross (Wiley, 2013). There are key data modeling concepts such as “star schemas”
    and “fact tables” to explore to get a deeper understanding of data modeling best
    practices. A less technical, more business-oriented approach would be to study
    the Business Event Analysis & Modeling (BEAM) technique. The idea behind it is
    that the core business entity to focus on is events that happen in the business
    lifecycle. Your data models would take the form of “customer buys product,” where
    one record is one instance of a customer buying the product, complete with details
    about the customer, the product, and the purchasing event. Thinking in terms of
    events forces you to think about how the business actually works and, ultimately,
    the process that generated your raw data. A relevant text to explore would be
    *Agile Data Warehouse Design* (DecisionOne Press, 2011) by Lawrence Corr and Jim
    Stagnitto.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您尝试了一个数据建模任务，可能没有正式的数据建模培训。如果您对这个主题感兴趣，一个开始的地方是拉尔夫·金伯尔（Ralph Kimball）和玛吉·罗斯（Margy
    Ross）的经典著作《数据仓库工具箱》（The Data Warehouse Toolkit）（Wiley, 2013）。有一些关键的数据建模概念，如“星型模式”（star
    schemas）和“事实表”（fact tables），需要探索以获得对数据建模最佳实践的更深入理解。一种不那么技术化、更以业务为导向的方法是研究业务事件分析与建模（BEAM）技术。其背后的理念是，核心业务实体是关注业务生命周期中发生的事件。您的数据模型将采取“客户购买产品”的形式，其中一条记录是客户购买产品的单个实例，包括有关客户、产品和购买事件的所有详细信息。从事件的角度思考迫使您思考业务实际上是如何运作的，以及最终生成您原始数据的过程。一个相关的文本是劳伦斯·科尔（Lawrence
    Corr）和吉姆·斯塔吉托（Jim Stagnitto）的《敏捷数据仓库设计》（Agile Data Warehouse Design）（DecisionOne
    Press, 2011）。
- en: What is most important is that you consider the purpose, and therefore the necessary
    details, of your data and get into the habit of creating data models, which abstract
    away the complexities of the raw data into a more business-relevant form. This
    skill will come up in most of your analytical projects.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，您要考虑数据的目的，以及因此必要的细节，并养成创建数据模型的习惯，这些模型将原始数据的复杂性抽象为更相关的业务形式。这项技能将在您的大多数分析项目中出现。
- en: 3.5.1 Data modeling skills for any project
  id: totrans-444
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5.1 任何项目的数据建模技能
- en: In this chapter, we focused on the creation of new datasets, which we called
    data models. The specific skills learned for data modeling, which can be used
    for any problem, include
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们专注于创建新的数据集，我们称之为数据模型。为数据建模学习到的具体技能，可用于任何问题，包括
- en: Exploring multiple datasets to identify a common structure
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索多个数据集以识别共同的结构
- en: Reshaping a dataset to adhere to this common structure
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新塑造数据集以符合这种共同结构
- en: Identifying what form a data model should be stored in (e.g., wide or long)
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定数据模型应存储的形式（例如，宽或长）
- en: Joining multiple datasets to enhance one with information from another
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将多个数据集连接起来，以增强其中一个数据集，使其包含来自另一个数据集的信息
- en: Cross-referencing two datasets (i.e., finding rows that appear in one but not
    the other)
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉引用两个数据集（即查找只出现在其中一个数据集中的行）
- en: Combining smaller data models into a master data model
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将较小的数据模型组合成主数据模型
- en: Using simple methods to deduplicate records
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用简单方法去重记录
- en: Using advanced methods, such as entity resolution tools, to deduplicate records
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用高级方法，如实体解析工具，去重记录
- en: Summary
  id: totrans-454
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Thinking about the purpose of a dataset helps identify the right structure for
    your data model.
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思考数据集的目的有助于确定您数据模型正确的结构。
- en: Data modeling is a crucial analyst skill that should be applied to create clean,
    defined, deduplicated, restructured, and usable data from raw datasets.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据建模是分析师的一项关键技能，应应用于从原始数据集中创建干净、定义明确、去重、重构和可用的数据。
- en: Even basic analytical tasks such as counting are easier when the data is modeled
    correctly.
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使是像计数这样的基本分析任务，在数据正确建模的情况下也更容易完成。
- en: Proper data modeling provides easy reuse of the same data to answer additional
    analytical questions by adjusting the level of granularity or providing wide or
    long looks at the data.*
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确的数据建模提供了通过调整粒度级别或提供宽或长视角来轻松重用相同数据以回答额外分析问题的能力。*
