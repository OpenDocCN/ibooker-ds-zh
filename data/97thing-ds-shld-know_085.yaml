- en: Chapter 79\. Make Accountability a Priority
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第79章\. 使问责成为优先事项
- en: Yiannis Kanellopoulos
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Yiannis Kanellopoulos
- en: '![](Images/Yiannis_Kanellopoulos.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/Yiannis_Kanellopoulos.png)'
- en: Founder, Code4Thought
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 创始人，Code4Thought
- en: There is little doubt that algorithmic systems are making decisions that have
    a great impact on our daily lives. As Yuval Noah Harari notes in his book *21
    Lessons for the 21st Century* (Random House), “Already today, ‘truth’ is defined
    by the top results of the Google search.” So transparency about the function of
    these systems matters not as an end in itself but merely as a means toward accountability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，算法系统正在做出对我们日常生活产生重大影响的决策。正如尤瓦尔·诺亚·哈拉利在他的书《21世纪的21堂课》（Random House）中所述：“今天，‘真理’已由谷歌搜索的前几个结果来定义。”因此，关于这些系统功能的透明性不仅仅是目的本身，而是达到问责的手段。
- en: According to assistant professor Nicholas Diakopoulos, director of the Computational
    Journalism Lab (CJL) at Northwestern University, *accountability* in this context
    means the degree to which one decides when and how an algorithmic system should
    be guided (or restrained) in the risk of crucial or expensive errors, discrimination,
    unfair denials, or censorship.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 根据西北大学计算新闻实验室（CJL）主任、助理教授Nicholas Diakopoulos的说法，这里的“问责”意味着决定何时以及如何引导（或限制）算法系统在面临关键或昂贵错误、歧视、不公正拒绝或审查风险时的程度。
- en: 'Simply put, holding a system accountable means we should control it at a technical
    as well as an organizational level. This is important, especially if we consider
    (a bit simplistically) that an algorithmic system is nothing more than a piece
    of software that:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，对系统进行问责意味着我们应该在技术和组织层面上对其进行控制。尤其是当我们（有点简单地）考虑到算法系统仅仅是一个能够：
- en: Solves a business problem set by the organization that procures it (the system)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决组织提出的业务问题集（系统）
- en: Receives data as input that has been selected and most likely preprocessed either
    by a human or an automated process
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以由人类或自动化过程选择和预处理的数据作为输入
- en: Utilizes a model (e.g., support vector machine, deep learning, random forest,
    and others) that processes the selected data and ultimately makes a decision or
    suggests an answer/solution to the question/problem set by the organization
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用模型（例如支持向量机、深度学习、随机森林等），处理选定的数据并最终做出决策或提出组织提出的问题/问题集的答案/解决方案
- en: To be able to control this software, then, we need to gain insight into (or
    make informed decisions about) every aspect just mentioned.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够控制这种软件，我们需要深入了解（或对每个前述方面做出明智决策）。
- en: 'The organization that creates the system needs to cater to and design for the
    system’s accountability even before it starts the system’s development. More specifically,
    the organization should:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 创建该系统的组织需要在系统开始开发之前，为系统的问责性提供设计和关注。具体来说，该组织应该：
- en: Establish visible ways of redress for adverse individual or societal effects
    caused by its system.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立可见的补救方式，以应对其系统造成的不利个人或社会影响。
- en: Follow the human-in-the-loop principle and assign the proper persons for making
    the right decisions if problems appear.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遵循人在环路中的原则，并指定适当的人员在出现问题时做出正确的决策。
- en: Be able to explain the decisions of its system to end users and other stakeholders
    in nontechnical terms.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够以非技术术语向最终用户和其他利益相关者解释其系统的决策。
- en: Know the potential sources of error for its algorithms and how their effect
    is mitigated.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知道其算法的潜在误差来源及其如何减轻其影响。
- en: Enable interested third parties to probe, understand, and review the behavior
    of its algorithms.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许感兴趣的第三方探索、理解和审查其算法的行为。
- en: Ensure that algorithmic decisions do not create discriminatory or unjust impacts
    when considering different demographics (e.g., race, sex, education level, etc.).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保算法决策在考虑不同人群（例如种族、性别、教育水平等）时不会产生歧视性或不公正的影响。
- en: 'Regarding the input data of the system, the so-called “new oil” of the modern
    economy, we primarily need to care about its:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 关于系统的输入数据，即现代经济中所谓的“新油”，我们主要需要关心其：
- en: Quality, which involves accuracy, completeness, and uncertainty, as well as
    timeliness, representativeness of a sample for a specific population, and assumptions
    or other limitations
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 质量，包括准确性、完整性和不确定性，以及及时性，样本对特定人群的代表性和假设或其他限制
- en: Handling, which includes data definitions, ways of collection, vetting, and
    editing (manually or automated)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理，包括数据定义，收集方式，审查和编辑（手动或自动化）。
- en: 'Regarding the model itself, the most important things to consider are:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型本身，考虑的最重要的事情包括：
- en: Whether it is fit for the problem at hand. It may seem strange, but we have
    seen models that never get operationalized simply because they weren’t fit for
    purpose.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是否适合当前的问题。这可能看起来很奇怪，但我们看到有些模型从未被操作化，仅仅因为它们不适合特定目的。
- en: The process followed for the model’s construction, i.e., identifying its input
    and the selected features or variables, along with their weights (in case they
    are weighted).
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型构建的过程，即确定其输入和所选特征或变量，以及它们的权重（如果它们是加权的）。
- en: The way this model will be evaluated, i.e., identifying the evaluation metrics
    to be used, the reasoning behind their selection, and, most importantly, how these
    are being utilized and interpreted.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估这个模型的方式，即确定要使用的评估指标，其选择背后的理由，以及最重要的是如何使用和解释这些指标。
- en: The model’s accuracy or error margin, and the ability of a data scientist to
    benchmark it against standard datasets and standard measures of accuracy.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的准确度或误差范围，以及数据科学家能够将其与标准数据集和标准准确度度量进行基准比较的能力。
- en: 'An organization that considers accountability and designs its system with accountability
    in mind can gain the following benefits:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑责任并以责任为设计基础的组织可以获得以下好处：
- en: Trust between the organization using the system and those affected by its output
    (be they clients, citizens, or simple users), since the results can be explained
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用系统的组织与其输出受影响的人之间的信任（无论是客户、公民还是普通用户），因为结果可以解释清楚。
- en: Improvement in the system’s output, since identified weighting factors and thresholds
    can be calibrated/fine-tuned if needed
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统输出的改进，因为可以根据需要校准/微调识别的加权因子和阈值。
- en: Rendering the system more persuasive, since its reasoning will be easier to
    explain
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使系统更具说服力，因为其推理将更易于解释。
- en: Presently, the public discourse is full of examples of how automated decision
    making can go seriously wrong, from crucial (e.g., Amazon’s HR system favoring
    male candidates) to even life-and-death mistakes (e.g., the fatal accident caused
    by Uber’s self-driving car). It is obvious that we humans need to be in control
    of the technology we create. Establishing evaluation processes before we even
    start developing an autonomous decision-making system and having humans in the
    loop should be a prerequisite for organizations to deploy any system that will
    make decisions for us but without us.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，公共讨论充满了自动决策出现严重问题的例子，从关键问题（例如，亚马逊的人力资源系统偏向于男性候选人）到甚至涉及生死的错误（例如，由优步自动驾驶汽车引发的致命事故）。很明显，我们人类需要控制我们所创造的技术。在我们开始开发自主决策系统之前，建立评估流程并让人类参与其中应成为组织部署任何为我们做出决策但没有我们的系统的先决条件。
