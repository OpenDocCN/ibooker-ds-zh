- en: 9 Messaging and event streaming with Vert.x
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 使用 Vert.x 进行消息和事件流
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Messaging with AMQP
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AMQP 进行消息传递
- en: Event streaming with Apache Kafka
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Apache Kafka 进行事件流
- en: Sending emails
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发送电子邮件
- en: Integration testing with messaging and event-streaming middleware
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用消息和事件流中间件进行集成测试
- en: Reactive applications are a good fit for messaging and event-streaming technologies.
    So far we have mostly looked at services that expose HTTP APIs. But although HTTP
    is a versatile and effective protocol for interacting with a service, it should
    not be the only choice.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 反应式应用程序非常适合消息和事件流技术。到目前为止，我们主要关注的是暴露 HTTP API 的服务。但尽管 HTTP 是与服务交互的灵活和有效的协议，它不应该是唯一的选择。
- en: There are several options for integrating Vert.x-based services using messaging
    and event streaming. This chapter introduces AMQP message brokers and Apache Kafka.
    We will also discuss sending email using an SMTP server.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 使用消息和事件流集成 Vert.x 基于的服务有几种选择。本章介绍了 AMQP 消息代理和 Apache Kafka。我们还将讨论使用 SMTP 服务器发送电子邮件。
- en: In this chapter we’ll dive into the implementation of the ingester and congratulation
    services. The ingester receives step updates from devices over HTTP and AMQP,
    and it forwards them into the system as Kafka events. The congratulation service
    listens for certain Kafka events to spot when a user has reached 10,000 steps
    in a day, and it sends a congratulation email.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入了解 ingester 和祝贺服务的实现。ingester 通过 HTTP 和 AMQP 从设备接收步骤更新，并将它们作为 Kafka
    事件转发到系统中。祝贺服务监听特定的 Kafka 事件，以确定用户是否在一天内达到了 10,000 步，并发送祝贺电子邮件。
- en: 9.1 Event-driven services beyond HTTP with Vert.x
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 使用 Vert.x 超越 HTTP 的事件驱动服务
- en: HTTP is a sensible choice as a networked interface for an event-driven service,
    especially when a service offers an API. Messaging and event-streaming middleware
    offer useful tools for decoupling and integrating services. They are also typically
    better suited than HTTP for exchanging lots of events between services.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 是作为事件驱动服务的网络接口的明智选择，尤其是当服务提供 API 时。消息和事件流中间件为解耦和集成服务提供了有用的工具。它们通常比 HTTP
    更适合在服务之间交换大量事件。
- en: 9.1.1 What Vert.x provides
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 Vert.x 提供的内容
- en: Vert.x provides clients for message brokers, event streaming with Apache Kafka,
    and a general-purpose TCP protocol for the event bus.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Vert.x 提供了消息代理、与 Apache Kafka 的事件流以及用于事件总线的通用 TCP 协议的客户端。
- en: Message brokers
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 消息代理
- en: 'Messaging middleware can be more effective than HTTP for service-to-service
    communications with better throughput, and it can also provide durability guarantees
    when a consumer or producer service is temporarily unavailable. Vert.x provides
    several modules for doing integration work with messaging middleware:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 消息中间件在服务到服务的通信中可能比 HTTP 更有效，具有更好的吞吐量，并且当消费者或生产者服务暂时不可用时，还可以提供持久性保证。Vert.x 提供了几个模块来进行与消息中间件的集成工作：
- en: An *Advanced Message Queuing Protocol* (AMQP) client
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *高级消息队列协议* (AMQP) 客户端
- en: A *Simple Text Oriented Messaging Protocol* (STOMP) client
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *简单文本导向的消息协议* (STOMP) 客户端
- en: A RabbitMQ client
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 RabbitMQ 客户端
- en: A *Message Queuing Telemetry Transport* (MQTT) client
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *消息队列遥测传输* (MQTT) 客户端
- en: AMQP is a standard protocol for messaging middleware, and it’s implemented by
    a large number of brokers such as Apache ActiveMQ , JBoss A-MQ , Windows Azure
    Service Bus, RabbitMQ , and more. Vert.x provides a dedicated client for RabbitMQ
    and its extensions. Note that it is also possible to use the Vert.x AMQP client
    with RabbitMQ , since it exposes an AMQP server alongside the RabbitMQ-specific
    server.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: AMQP 是消息中间件的标准协议，由 Apache ActiveMQ、JBoss A-MQ、Windows Azure Service Bus、RabbitMQ
    等大量代理实现。Vert.x 为 RabbitMQ 和其扩展提供了一个专门的客户端。请注意，也可以使用 Vert.x AMQP 客户端与 RabbitMQ
    一起使用，因为它除了 RabbitMQ 特定的服务器外，还公开了一个 AMQP 服务器。
- en: STOMP is a text-based protocol for messaging middleware. It has fewer features
    than AMQP, but they may be enough for simple messaging. It is supported by popular
    message brokers.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: STOMP 是一种基于文本的消息中间件协议。它的功能比 AMQP 少，但对于简单的消息传递可能已经足够。它得到了流行消息代理的支持。
- en: MQTT is a protocol designed for machine-to-machine publish/subscribe interactions.
    It is quite popular for embedded/Internet of Things devices because it uses low
    bandwidth.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: MQTT 是一种为机器到机器的发布/订阅交互设计的协议。它因为使用低带宽而在嵌入式/物联网设备中非常流行。
- en: Kafka event streaming
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 事件流
- en: Vert.x provides support for Apache Kafka, a popular implementation of event-streaming
    middleware.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Vert.x 提供了对 Apache Kafka 的支持，它是事件流中间件的流行实现。
- en: At first glance, event-streaming middleware resembles messaging systems, but
    it allows for interesting architectural patterns because different services can
    consume the same set of events at their own pace. Message brokers support publish/subscribe
    mechanisms for multiple services to consume the same events, but event-streaming
    middleware also has the ability to replay events at will. Rewinding event streams
    is a distinctive feature. Event-streaming middleware also allows new services
    to be plugged into the processing pipeline without impacting other services.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 初看起来，事件流中间件类似于消息系统，但它允许有趣的架构模式，因为不同的服务可以以自己的节奏消费相同的事件集。消息代理支持发布/订阅机制，使多个服务能够消费相同的事件，但事件流中间件也有随意回放事件的能力。回滚事件流是一个独特的功能。事件流中间件还允许在不影响其他服务的情况下，将新服务插入到处理管道中。
- en: You can use event-streaming middleware just like messaging middleware, but there
    is more to it than just passing events between services.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用事件流中间件就像消息中间件一样，但它不仅仅是服务之间传递事件。
- en: Event-bus TCP bridge
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 事件总线 TCP 适配器
- en: Last but not least, Vert.x provides an event-bus bridge over a simple TCP protocol,
    with binding in JavaScript, Go, C#, C, and Python. This allows us to use the event
    bus to connect with non-Java applications. We will not cover this event-bus bridge
    in the book, but you can easily learn how to use it from the official Vert.x documentation.
    From the Vert.x side, this is really just the event bus, except that some of the
    events can be produced and consumed outside of the JVM.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，Vert.x 通过简单的 TCP 协议提供事件总线适配器，支持 JavaScript、Go、C#、C 和 Python 的绑定。这使我们能够使用事件总线与非
    Java 应用程序进行连接。本书中不会介绍此事件总线适配器，但您可以从官方 Vert.x 文档中轻松学习如何使用它。从 Vert.x 的角度来看，这实际上只是事件总线，只不过某些事件可以在
    JVM 之外产生和消费。
- en: 9.1.2 The middleware and services that we’ll use
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 我们将使用的中间件和服务
- en: 'The 10k steps challenge application allows us to explore AMQP for messaging,
    Kafka for event streaming, and sending email with an SMTP server:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 10k 步挑战应用程序使我们能够探索用于消息传递的 AMQP，用于事件流处理的 Kafka，以及通过 SMTP 服务器发送电子邮件：
- en: AMQP is used by the ingestion service because it receives pedometer device updates
    over either HTTP or AMQP.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摄取服务使用 AMQP，因为它通过 HTTP 或 AMQP 接收计步器设备更新。
- en: Kafka is used to convey events between many services of the application.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka 用于在应用程序的许多服务之间传递事件。
- en: SMTP is used to send congratulation emails to users.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SMTP 用于向用户发送祝贺邮件。
- en: 'As in the previous chapter, Docker Compose can be used to start the required
    middleware services for local development purposes: Apache Kafka (which also requires
    Apache ZooKeeper), Apache ActiveMQ Artemis, and MailHog (a test-friendly SMTP
    server). You can, of course, install and run each service by yourself if you want
    to, but starting disposable containers with Docker offers a simplified development
    experience.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，Docker Compose 可以用于启动本地开发所需的中间件服务：Apache Kafka（它还需要 Apache ZooKeeper）、Apache
    ActiveMQ Artemis 和 MailHog（一个友好的 SMTP 服务器测试）。当然，如果您想的话，您可以自己安装和运行每个服务，但使用 Docker
    启动可丢弃的容器可以提供简化的开发体验。
- en: 'On the Vert.x side, we’ll use the following modules to build our services:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Vert.x 方面，我们将使用以下模块来构建我们的服务：
- en: '`vertx-amqp-client`--The AMQP client'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vertx-amqp-client`--AMQP 客户端'
- en: '`vertx-kafka-client`--The Apache Kafka client'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vertx-kafka-client`--Apache Kafka 客户端'
- en: '`vertx-mail-client`--The SMTP client that will send emails'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vertx-mail-client`--将发送电子邮件的 SMTP 客户端'
- en: 9.1.3 What is AMQP (and a message broker)?
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3 什么是 AMQP（以及消息代理）？
- en: The *Advanced Message Queuing Protocol* (AMQP) is a widely used network protocol
    for messaging middleware backed by an open specification. The protocol itself
    is binary, based on TCP, and it supports authentication and encryption. We’ll
    use Apache ActiveMQ in the project, and it supports AMQP.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*高级消息队列协议*（AMQP）是一个广泛使用的网络协议，用于支持开放规范的消息中间件。该协议本身是二进制的，基于 TCP，并支持身份验证和加密。在项目中，我们将使用
    Apache ActiveMQ，它支持 AMQP。'
- en: Message brokers are a classic form of service integration, as they typically
    support message queues and publish/subscribe communications. They allow services
    to communicate through message passing, and the broker ensures message durability.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 消息代理是服务集成的一种经典形式，因为它们通常支持消息队列和发布/订阅通信。它们允许服务通过消息传递进行通信，并且代理确保消息的持久性。
- en: Figure 9.1 shows the interactions between a device, an AMQP queue that collects
    step events, and the ingestion service.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 展示了设备、收集步数事件的 AMQP 队列和摄取服务之间的交互。
- en: '![](../Images/CH09_F01_Ponge.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F01_Ponge.png)'
- en: Figure 9.1 Overview of an AMQP queue
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 AMQP 队列概述
- en: Messages can be made *durable*, so that they are not lost if the broker crashes.
    Producers and consumers can use acknowledgements to ensure that a message has
    been properly sent or retrieved and then processed. Brokers also offer various
    quality-of-service features, such as expiration dates and advanced routing. Depending
    on the broker, messages can be transformed from one representation to another,
    such as converting from a binary format to JSON. Some brokers also support aggregating
    multiple messages into one, or conversely splitting one message to produce many.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 消息可以被设置为 *持久化*，这样即使代理崩溃也不会丢失。生产者和消费者可以使用确认来确保消息已被正确发送或检索并处理。代理还提供各种服务质量特性，例如过期日期和高级路由。根据代理的不同，消息可以从一种表示形式转换为另一种表示形式，例如从二进制格式转换为
    JSON。一些代理还支持将多个消息聚合到一个消息中，或者相反，将一个消息分割成多个。
- en: Note If you are new to ActiveMQ, I suggest reading *ActiveMQ in Action* by Bruce
    Snyder, Dejan Bosanac, and Rob Davies (Manning, 2011).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您是 ActiveMQ 的初学者，我建议阅读 Bruce Snyder、Dejan Bosanac 和 Rob Davies 所著的 *ActiveMQ
    in Action*（Manning，2011年）。
- en: 9.1.4 What is Kafka?
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.4 什么是 Kafka？
- en: Apache Kafka is event-streaming middleware based on distributed logs. While
    that may sound complicated, all you really need to understand is that Kafka offers
    streams of event records, where producers can append new records and consumers
    can walk back and forth along streams. For instance, incoming pedometer step updates
    form a stream where each event is an update sent by a device, and the ingestion
    service produces these events. On the other hand, various consumers can look at
    the events on that stream to populate databases, compute statistics, and so on.
    Events remain in a stream for some amount of time, or until the stream is too
    big and has to discard its oldest records.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Kafka 是基于分布式日志的事件流中间件。虽然这可能听起来很复杂，但您真正需要理解的是 Kafka 提供事件记录流，其中生产者可以追加新记录，消费者可以在流中前后移动。例如，来自计步器的步数更新形成了一个流，其中每个事件都是设备发送的更新，而摄入服务生成这些事件。另一方面，各种消费者可以查看该流上的事件，以填充数据库、计算统计数据等。事件在一段时间内保持流状态，或者直到流太大而必须丢弃其最旧的记录。
- en: Kafka supports publish/subscribe interactions between distributed services,
    as illustrated in figure 9.2\. In a Kafka cluster, events are *published* and
    *consumed* from *topics* that group related events. Topics are split into *replicated
    partitions*, which are ordered sequences of events. Each event is identified by
    its *offset* position in the event log that materializes its partition.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 支持分布式服务之间的发布/订阅交互，如图 9.2 所示。在 Kafka 集群中，事件从 *topics* 中 *发布* 和 *消费*，这些
    topics 将相关事件分组。topics 被分割成 *复制分区*，它们是有序的事件序列。每个事件通过其在事件日志中的 *偏移量* 位置来标识，该位置实现了其分区。
- en: '![](../Images/CH09_F02_Ponge.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F02_Ponge.png)'
- en: Figure 9.2 Overview of a Kafka topic
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 Kafka 主题概述
- en: Consumers pull events from partitions. They can keep track of the last offset
    that they have consumed, but it is also possible to arbitrarily seek any random
    position in a partition, or even to replay all events since the beginning. Also,
    *consumer groups* can divide work by reading from different partitions and parallelizing
    event processing.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者从分区中拉取事件。它们可以跟踪最后消费的偏移量，但也可以任意地定位到分区中的任何随机位置，甚至可以重放从开始以来的所有事件。此外，*消费者组*可以通过从不同的分区读取和并行处理事件来分担工作。
- en: It is easy to think that Kafka is a *messaging* system like ActiveMQ, and in
    some cases Kafka is very fine messaging middleware, but it should still be considered
    *streaming* middleware.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 容易想到 Kafka 是一个像 ActiveMQ 一样的 *消息* 系统，在某些情况下 Kafka 确实是一个非常优秀的消息中间件，但它仍然应该被视为
    *流* 中间件。
- en: In a message broker, messages disappear when they have been consumed from a
    queue, or when they expire. Kafka partitions eventually evict records, either
    using a partition size limit (such as 2 GB) or using some eviction delay (such
    as two weeks). Kafka records should be considered “semi-durable” as they will
    eventually disappear. It is possible to configure the partitions in a topic to
    keep events forever, but this is quite rare as events are expected to produce
    durable effects when consumed. For instance, the ingestion service produces incoming
    step update records, and the activity service turns these records into long-term
    facts in a database. Another interesting feature of Kakfa is that topics can be
    replayed at will, so new services can join and consume a stream at their own pace.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在消息代理中，当消息从队列中消费或过期时，消息会消失。Kafka 分区最终会驱逐记录，要么使用分区大小限制（例如 2 GB），要么使用某些驱逐延迟（例如两周）。Kafka
    记录应被视为“半持久”，因为它们最终会消失。可以配置主题中的分区以永久保留事件，但这相当罕见，因为预期事件在消费时会产生持久效果。例如，接收服务生成传入的步数更新记录，活动服务将这些记录转换为数据库中的长期事实。Kafka
    的另一个有趣特性是，可以随意重放主题，因此新服务可以以自己的节奏加入并消费流。
- en: Note I suggest reading Dylan Scott’s *Kafka in Action* (Manning, 2017) if you
    are new to Apache Kafka.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您是 Apache Kafka 的新手，建议阅读 Dylan Scott 的《Kafka in Action》（Manning，2017）。
- en: Let’s now dive into the ingestion service.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在深入了解接收服务。
- en: 9.2 Reliably ingesting messages over HTTP and AMQP
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 通过 HTTP 和 AMQP 可靠地接收消息
- en: Everything begins with the ingestion service, as it receives step count updates
    from the pedometers. In our (fictitious) application, we can expect that several
    types of pedometers will be available, and that they have different communication
    capabilities. For example, some devices may directly talk to the ingestion service
    over the internet, while others may need to reach a gateway that forwards updates
    to the ingestion service.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都从接收服务开始，因为它接收计步器的步数更新。在我们的（虚构的）应用中，我们可以预期会有多种类型的计步器可用，并且它们具有不同的通信能力。例如，一些设备可以直接通过互联网与接收服务通信，而其他设备可能需要连接到一个网关，该网关将更新转发到接收服务。
- en: 'This is why we offer two interfaces for ingesting device updates:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 正因如此，我们提供了两个接口来接收设备更新：
- en: A device can connect to the HTTP API provided by the ingestion service.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设备可以连接到接收服务提供的 HTTP API。
- en: A device can forward an update to a message broker, and the ingestion service
    receives the updates from the broker.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设备可以将更新转发到消息代理，接收服务从代理接收更新。
- en: Once an update has been received, it must be validated and then sent to a Kafka
    topic. It is interesting to explore both the AMQP and HTTP interfaces, as we can
    see similarities in their implementations but also differences in acknowledging
    device updates.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦收到更新，就必须对其进行验证，然后发送到 Kafka 主题。探索 AMQP 和 HTTP 接口都很有趣，因为我们可以在它们的实现中看到相似之处，同时也能看到在确认设备更新方面的差异。
- en: 9.2.1 Ingesting from AMQP
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 从 AMQP 接收
- en: We’ll start with the AMQP ingestion. We first need to create an AMQP client
    that connects to the broker. The following listing shows the client configuration
    code.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从 AMQP 接收开始。我们首先需要创建一个连接到代理的 AMQP 客户端。以下列表显示了客户端配置代码。
- en: Listing 9.1 AMQP client configuration
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.1 AMQP 客户端配置
- en: '[PRE0]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ The credentials are the default ones from the Docker image.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 凭证是 Docker 镜像中的默认凭证。
- en: ❷ We will manually acknowledge incoming messages.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们将手动确认传入的消息。
- en: ❸ We want durable messaging.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 我们希望使用持久消息。
- en: The `amqpConfig` method that we use here provides a configuration with hardcoded
    values. This is great for the testing we do in this book, but for production you
    would, of course, resolve credentials, hostnames, and port numbers from some external
    source. These could be environment variables or a registry service, such as Apache
    ZooKeeper or Consul. We also set up the connection for durable messaging and declare
    manual acknowledgment, as we want to retry message processing if writing to a
    Kafka topic fails.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的 `amqpConfig` 方法提供了一个具有硬编码值的配置。这对于我们在本书中进行的测试来说很棒，但当然，对于生产环境，您需要从外部来源解决凭证、主机名和端口号。这些可以是环境变量或注册服务，例如
    Apache ZooKeeper 或 Consul。我们还设置了持久消息的连接，并声明了手动确认，因为我们希望在写入 Kafka 主题失败时重试消息处理。
- en: The next step is to set up the event-processing pipeline for incoming AMQP messages.
    We use RxJava to dispatch messages to a processing function, log errors, and recover
    from errors, as shown in the following listing.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是设置用于传入 AMQP 消息的事件处理管道。我们使用 RxJava 将消息调度到处理函数，记录错误并从错误中恢复，如下面的列表所示。
- en: Listing 9.2 AMQP event-processing pipeline
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.2 AMQP 事件处理管道
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Create an AMQP client.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个 AMQP 客户端。
- en: ❷ Create a message receiver from the step-events destination.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从步骤事件目的地创建一个消息接收器。
- en: ❸ Create a Flowable of AMQP messages.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建一个 AMQP 消息的 `Flowable`。
- en: ❹ Error logging
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 错误记录
- en: ❺ Retry logic
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 重试逻辑
- en: ❻ Subscription that dispatches incoming messages
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 分发传入消息的订阅
- en: This pipeline is interesting as it is purely declarative. It starts with the
    creation of a client, and then it obtains a receiver for the `step-events` durable
    queue and a flow of messages. From there we declare what to do upon receiving
    a message or an error. We also keep the code short and clean by using Java method
    references rather than lambdas. But what do the `logAmqpError`, `retryLater`,
    and `handleAmqpMessage` methods do?
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这个管道很有趣，因为它完全是声明式的。它从创建客户端开始，然后获取 `step-events` 持久队列的接收器和消息流。从那里我们声明在接收到消息或错误时要做什么。我们还通过使用
    Java 方法引用而不是 lambda 表达式来保持代码简短和干净。但 `logAmqpError`、`retryLater` 和 `handleAmqpMessage`
    方法具体做什么呢？
- en: Logging messages is not very complicated.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 记录消息并不复杂。
- en: Listing 9.3 Logging AMQP errors
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.3 记录 AMQP 错误
- en: '[PRE2]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Log the error and stack trace.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 记录错误和堆栈跟踪。
- en: Errors happen. For instance, we can lose the connection to the AMQP broker.
    In this case, an error passes along the pipeline, and `logAmqpError` logs it,
    but `doOnError` lets the error propagate to subscribers.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 错误是会发生的。例如，我们可能会失去与 AMQP 代理的连接。在这种情况下，错误会沿着管道传递，`logAmqpError` 会记录它，但 `doOnError`
    允许错误传播给订阅者。
- en: We then need to retry connecting to the AMQP broker and resume receiving events,
    which translates to resubscribing to the source in RxJava. We can do that with
    the `retryWhen` operator, as it allows us to define our own policy. If you just
    want to retry a number of times, or even always, then `retry` is simpler. The
    following listing shows how we introduce a 10-second delay before resubscribing.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要重新连接到 AMQP 代理并继续接收事件，这在 RxJava 中相当于重新订阅源。我们可以使用 `retryWhen` 操作符来实现，因为它允许我们定义自己的策略。如果你只想重试几次，甚至总是重试，那么
    `retry` 就更简单。下面的列表显示了我们在重新订阅之前引入了 10 秒的延迟。
- en: Listing 9.4 Recovering from errors with a delayed resubscription
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.4 使用延迟重新订阅从错误中恢复
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ It is important to use the scheduler parameter to process events on a Vert.x
    event loop.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用调度器参数在 Vert.x 事件循环上处理事件是很重要的。
- en: 'The `retryLater` operator works as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '`retryLater` 操作符的工作方式如下：'
- en: It takes a `Flowable` of errors as its input, since we are in a `Flowable` of
    AMQP messages.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它接受一个错误 `Flowable` 作为输入，因为我们处于 AMQP 消息的 `Flowable` 中。
- en: It returns a `Flowable` of *anything*, where
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它返回一个 `Flowable` 的 *任何东西*，其中
- en: Emitting `onComplete` or `onError` does not trigger a resubscription.
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发出 `onComplete` 或 `onError` 不会触发重新订阅。
- en: Emitting `onNext` (no matter what the value is) triggers a resubscription.
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发出 `onNext`（无论值是什么）都会触发重新订阅。
- en: To delay the resubscription by 10 seconds, we use the `delay` operator. It will
    eventually emit a value, so `onNext` will be called and a resubscription will
    happen. You can, of course, think of more elaborate handlers, like limiting the
    number of retries or using an exponential back-off strategy. We will use this
    pattern a lot, as it greatly simplifies the error-recovery logic.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了延迟重新订阅 10 秒，我们使用 `delay` 操作符。它最终会发出一个值，因此 `onNext` 会被调用，并发生重新订阅。当然，你可以考虑更复杂的处理程序，比如限制重试次数或使用指数退避策略。我们将大量使用这种模式，因为它极大地简化了错误恢复逻辑。
- en: 9.2.2 Translating AMQP messages to Kafka records
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 将 AMQP 消息转换为 Kafka 记录
- en: The following listing contains the method that handles incoming AMQP messages,
    validates them, and then pushes them as Kafka records.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表包含处理传入 AMQP 消息、验证它们并将它们作为 Kafka 记录推送的方法。
- en: Listing 9.5 Handling AMQP messages
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.5 处理 AMQP 消息
- en: '[PRE4]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Check for a valid JSON message.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 检查有效的 JSON 消息。
- en: ❷ Prepare a Kafka record.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 准备 Kafka 记录。
- en: ❸ Acknowledge the AMQP message.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 确认 AMQP 消息。
- en: ❹ Reject the AMQP message.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 拒绝 AMQP 消息。
- en: The `handleAmqpMessage` method first performs some validation on the incoming
    AMQP message and then prepares a Kafka record. The AMQP message is acknowledged
    when the Kafka record is written, and it is rejected if the record could not be
    written.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`handleAmqpMessage`方法首先对传入的AMQP消息进行一些验证，然后准备一个Kafka记录。当Kafka记录被写入时，AMQP消息被确认，如果记录无法写入，则被拒绝。'
- en: tip In listing 9.5 and all subsequent services, we will directly work with `JsonObject`
    data representation. There is little point in converting the JSON representation
    to Java domain classes (such as an `IngestionData` class) given that we mostly
    copy and transform data. You can, of course, perform such mapping if you have
    to do some more complex business logic and the cost of abstraction is justified.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：在列表9.5及其后续服务中，我们将直接处理`JsonObject`数据表示。鉴于我们主要复制和转换数据，将JSON表示转换为Java域类（如`IngestionData`类）几乎没有意义。当然，如果您必须执行一些更复杂的业务逻辑，并且抽象的成本是合理的，您当然可以执行此类映射。
- en: The `invalidIngestedJson` method checks that the JSON data contains all required
    entries, as follows.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`invalidIngestedJson`方法检查JSON数据是否包含所有必需条目，如下所示。'
- en: Listing 9.6 Checking for valid JSON data
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.6 检查有效JSON数据
- en: '[PRE5]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Checking for JSON entries
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 检查JSON条目
- en: The `makeKafkaRecord` method in the following listing converts the AMQP message
    JSON to a Kafka record aimed at the `incoming-steps` topic.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表中的`makeKafkaRecord`方法将AMQP消息的JSON转换为针对`incoming-steps`主题的Kafka记录。
- en: Listing 9.7 Preparing a Kafka record
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.7 准备Kafka记录
- en: '[PRE6]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ We copy JSON data.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们复制JSON数据。
- en: ❷ Record with key deviceId and JSON data
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 包含deviceId键和JSON数据的记录
- en: We could avoid copying all JSON entries manually and just pass the JSON from
    the AMQP message to the Kafka record. This, however, helps ensure that no extra
    data ends up in the Kafka record.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以避免手动复制所有JSON条目，只需将AMQP消息中的JSON传递到Kafka记录中。然而，这有助于确保没有额外数据最终出现在Kafka记录中。
- en: The `updateProducer` field is of type `KafkaProducer<String, JsonObject>` because
    it produces messages with string keys and JSON payloads. Instances of `KafkaProducer`
    are created by passing configuration from a `Map` as follows.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`updateProducer`字段的数据类型为`KafkaProducer<String, JsonObject>`，因为它使用字符串键和JSON有效负载来生成消息。通过以下方式传递来自`Map`的配置来创建`KafkaProducer`实例。'
- en: Listing 9.8 Configuring a Kafka producer
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.8 配置Kafka生产者
- en: '[PRE7]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Class to serialize values from strings
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 用于从字符串序列化值的类
- en: ❷ Class to serialize values from Vert.x JsonObject
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 用于从Vert.x JsonObject序列化值的类
- en: ❸ Create a Vert.x Kafka producer.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建一个Vert.x Kafka生产者。
- en: The configuration especially specifies the *serializer* (or *deserializer*)
    classes, as Kafka records need to be mapped to Java types. `StringSerializer`
    comes from the Kafka client library, and it serializes Java strings to Kafka data,
    whereas `JsonObjectSerializer` comes from Vert.x and serializes `JsonObject` data.
    You need to specify correct serializer classes for both your keys and values.
    Similarly, you will need to configure deserializers when reading from Kafka topics.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 配置特别指定了*序列化器*（或*反序列化器*）类，因为Kafka记录需要映射到Java类型。`StringSerializer`来自Kafka客户端库，它将Java字符串序列化为Kafka数据，而`JsonObjectSerializer`来自Vert.x，它序列化`JsonObject`数据。您需要为您的键和值指定正确的序列化器类。类似地，当从Kafka主题读取时，您还需要配置反序列化器。
- en: tip The Vert.x Kafka module wraps the Java client from the Apache Kafka project,
    and all configuration key/value pairs match those from the Kafka Java client documentation.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：Vert.x Kafka模块封装了Apache Kafka项目的Java客户端，所有配置键/值对都与Kafka Java客户端文档中的匹配。
- en: 9.2.3 Ingesting from HTTP
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 从HTTP摄取
- en: The code to ingest from HTTP is very similar to that of ingesting with AMQP.
    The most notable difference is that an HTTP status code needs to be set, so that
    the device that sent an update knows that ingestion has failed and must be retried
    later.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 从HTTP摄取的代码与使用AMQP摄取的代码非常相似。最显著的区别是需要设置HTTP状态码，以便发送更新的设备知道摄取已失败，必须稍后重试。
- en: We first need an HTTP server and router.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要一个HTTP服务器和路由器。
- en: Listing 9.9 HTTP server for ingestion
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.9 HTTP服务器用于摄取
- en: '[PRE8]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ BodyHandler decodes HTTP request bodies.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ BodyHandler解码HTTP请求体。
- en: The `httpIngest` method is shown in the next listing, and it’s quite similar
    to `handleAmqpMessage`.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表显示了`httpIngest`方法，它与`handleAmqpMessage`非常相似。
- en: Listing 9.10 Ingesting updates from HTTP
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.10 从HTTP摄取更新
- en: '[PRE9]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Check the JSON entries.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 检查JSON条目。
- en: ❷ Bad JSON; let the requester know that.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 坏JSON；让请求者知道这一点。
- en: ❸ Successful ingestion
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 成功摄取
- en: ❹ The ingestion failed; let the requester know that.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 摄取失败；让请求者知道这一点。
- en: HTTP status codes are important for letting the client know if the payload is
    incorrect (400), if the ingestion failed due to some (temporary) error (500),
    or if the ingestion succeeded (200).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 状态码对于让客户端知道负载是否不正确（400），摄入是否由于某些（暂时性）错误而失败（500），或者摄入是否成功（200）非常重要。
- en: The ingestion service is a good example of integration using different input
    protocols. Let’s now explore more of Apache Kafka with Vert.x through the congratulation
    service.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 摄入服务是使用不同输入协议进行集成的一个很好的例子。现在让我们通过祝贺服务来探索更多 Apache Kafka 与 Vert.x 的集成。
- en: 9.3 Sending congratulation emails
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 发送祝贺邮件
- en: While the ingestion service *produces* Kafka events, the congratulation service
    *consumes* Kafka events.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当摄入服务 *生产* Kafka 事件时，祝贺服务 *消费* Kafka 事件。
- en: The activity service generates daily step events whenever a device update has
    been received. Each event contains the number of steps recorded for the originating
    device on the current day. The congratulation service can observe these events
    as they are sent to the `daily.step.updates` Kafka topic, and it can target the
    events where the number of steps is above 10,000.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 活动服务在收到设备更新时生成每日步数事件。每个事件包含当天为原始设备记录的步数。祝贺服务可以观察这些事件，当它们发送到 `daily.step.updates`
    Kafka 主题时，并且它可以针对步数超过 10,000 的事件。
- en: 9.3.1 Listening for daily step update events
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 监听每日步数更新事件
- en: 'The events sent to the `daily.step.updates` Kafka topic are JSON data with
    the following content:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 发送到 `daily.step.updates` Kafka 主题的事件是包含以下内容的 JSON 数据：
- en: '`deviceId` is the device identifier.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deviceId` 是设备标识符。'
- en: '`timestamp` is the timestamp when the event was produced in the activity service.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timestamp` 是事件在活动服务中被生产时的戳记。'
- en: '`stepsCount` is the number of steps for the current day.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stepsCount` 是当天的步数。'
- en: 'The Kafka records also have a key, which is the concatenation of several parameters:
    `deviceId:year-month-day`. In this scheme, all records of device `1a2b` produced
    on October 6th 2019 have the key `1a2b:2019-10-06`. As you will shortly see, the
    key will be useful not just to ensure that events for a given device are consumed
    in order, but also to ensure that we don’t send more than one congratulation email
    per day.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 记录还有一个键，它是几个参数的连接：`deviceId:year-month-day`。在这个方案中，2019 年 10 月 6 日生产的设备
    `1a2b` 的所有记录都有键 `1a2b:2019-10-06`。正如你很快就会看到的，键不仅有助于确保给定设备的事件按顺序消费，而且还有助于确保我们每天不会发送超过一封祝贺邮件。
- en: The pipeline for processing daily steps event is shown in figure 9.3.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 处理每日步数事件的管道如图 9.3 所示。
- en: '![](../Images/CH09_F03_Ponge.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F03_Ponge.png)'
- en: Figure 9.3 Pipeline from daily step counts to congratulation emails
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 从每日步数到祝贺邮件的管道
- en: Daily step updates flow from the `daily.step.updates` Kafka topic, and then
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 每日步数更新从 `daily.step.updates` Kafka 主题流出来，然后
- en: We discard events where the number of steps is less than 10,000.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们丢弃步数少于 10,000 的事件。
- en: We discard events for which an event with the same key has already been processed.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们丢弃已经处理过相同键的事件。
- en: We send an email.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们发送邮件。
- en: The following listing contains the corresponding RxJava pipeline.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表包含相应的 RxJava 管道。
- en: Listing 9.11 Kafka RxJava pipeline for receiving and processing daily step updates
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.11 接收和处理每日步数更新的 Kafka RxJava 管道
- en: '[PRE10]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Subscribe to the Kafka topic.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 订阅 Kafka 主题。
- en: ❷ Filter out events with less than 10,000 steps.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 过滤掉步数少于 10,000 的事件。
- en: ❸ Discard events for which a previous event with the same key has been processed.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 丢弃已经处理过相同键的先前事件。
- en: ❹ Asynchronous operation to send an email
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 异步操作发送邮件
- en: ❺ Retry on error.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 错误时重试。
- en: ❻ Log each successful congratulation.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 记录每次成功的祝贺。
- en: The preceding listing uses the RxJava binding to subscribe to a Kafka topic
    as a `Flowable` for Kafka records. We then use the `filter` combinator to filter
    out records with less than 10,000 steps, and use the predicate method in the following
    listing.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的列表使用 RxJava 绑定将 Kafka 主题订阅为 `Flowable` Kafka 记录。然后我们使用 `filter` 组合器过滤掉步数少于
    10,000 的记录，并使用以下列表中的断言方法。
- en: Listing 9.12 Predicate for events with at least 10,000 steps
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.12 至少有 10,000 步事件的断言
- en: '[PRE11]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Predicate on JSON data.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 对 JSON 数据进行断言。
- en: The `distinct` combinator in listing 9.11 ensures that only one event for each
    Kafka record key is retained, right after `filter`. This is to avoid sending more
    than one congratulation email to a user on a given day, as we could easily have
    a first event with, say, 10,100 steps, followed later by another event with 10,600
    steps, and so on. Note that this design is not 100% bulletproof, as it requires
    storing already-processed key values in memory, and upon a service restart we
    could accidentally send a second email. This is a reasonable trade-off in our
    example, compared to using a persistent data store just to keep track of when
    an email was last sent to a user.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.11 中的 `distinct` 组合器确保在 `filter` 之后仅保留每个 Kafka 记录键的一个事件，这是为了避免在给定的一天向用户发送超过一封祝贺邮件，因为我们很容易有一个包含
    10,100 步的第一事件，随后又有一个包含 10,600 步的另一个事件，等等。请注意，这种设计并非 100% 无懈可击，因为它需要在内存中存储已处理的键值，并且在服务重启时可能会意外地发送第二封电子邮件。与仅为了跟踪用户最后一次收到电子邮件的时间而使用持久数据存储相比，在我们的示例中这是一个合理的权衡。
- en: The rest of the pipeline uses similar event processing and `retryWhen` logic
    to resubscribe on errors. The `sendmail` method is an asynchronous operation to
    send an email--let’s look at how it works.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 管道中的其余部分使用类似的事件处理和 `retryWhen` 逻辑来在错误发生时重新订阅。`sendmail` 方法是一个发送电子邮件的异步操作——让我们看看它是如何工作的。
- en: 9.3.2 Sending emails
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 发送电子邮件
- en: The `vertx-mail-client` module offers an SMTP client. The following listing
    shows how to create such a client.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`vertx-mail-client` 模块提供了一个 SMTP 客户端。以下列表显示了如何创建这样的客户端。'
- en: Listing 9.13 Creating an SMTP client
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.13 创建 SMTP 客户端
- en: '[PRE12]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Create a shared instance
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个共享实例
- en: As with many other Vert.x clients, we obtain an instance through a factory method,
    passing a `Vertx` context as well as some parameters.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多其他 Vert.x 客户端一样，我们通过工厂方法获取一个实例，传递一个 `Vertx` 上下文以及一些参数。
- en: The `MailerConfig` class provides a method to retrieve configuration data, as
    shown next.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '`MailerConfig` 类提供了一个方法来检索配置数据，如下所示。'
- en: Listing 9.14 Mail client configuration
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.14 邮件客户端配置
- en: '[PRE13]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Server host
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 服务器主机
- en: ❷ Server port
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 服务器端口
- en: Again, these hardcoded values are fine for testing purposes and for keeping
    our code simple. The values are for connecting to MailHog, the testing SMTP server
    that we’re using from a Docker container. The `MailConfig` class supports more
    configuration options like SSL, authentication method, credentials, and so on.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，这些硬编码的值对于测试目的和保持我们的代码简单是合适的。这些值是用于连接到 MailHog，即我们从 Docker 容器中使用的测试 SMTP 服务器。`MailConfig`
    类支持更多的配置选项，如 SSL、认证方法、凭证等。
- en: 'A daily-steps update Kafka event applies to a device; it does not contain the
    name of the owner or the email address. Before we can send an email, we must first
    fetch the missing information (name and email) from the user profile service.
    We thus need two requests to that service:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 每日步骤更新 Kafka 事件适用于一个设备；它不包含所有者名称或电子邮件地址。在我们能够发送电子邮件之前，我们必须首先从用户配置文件服务中获取缺失的信息（名称和电子邮件）。因此，我们需要对该服务发出两个请求：
- en: A request of the form `/owns/deviceId` to get the user name
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个形式为 `/owns/deviceId` 的请求，用于获取用户名
- en: A request of the form `/username` to get the user profile and retrieve the email
    address
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个形式为 `/username` 的请求，用于获取用户配置文件并检索电子邮件地址
- en: The `sendmail` method is shown in the following listing.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`sendmail` 方法如下所示。'
- en: Listing 9.15 Implementation of the `sendmail` method
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.15 `sendmail` 方法的实现
- en: '[PRE14]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Extract the device identifier.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 提取设备标识符。
- en: ❷ Prepare a request to find who owns the device.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 准备一个请求以查找设备的所有者。
- en: ❸ Extract the body, which is a JsonObject.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 提取正文，它是一个 JsonObject。
- en: ❹ Extract the username value.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 提取用户名值。
- en: ❺ Asynchronous operation to fetch the email for the user
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 获取用户电子邮件的异步操作
- en: ❻ Prepare an email message.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 准备电子邮件消息。
- en: ❼ Asynchronously send the email.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 异步发送电子邮件。
- en: The `sendmail` method is another RxJava pipeline that composes asynchronous
    operations and data processing, illustrated in figure 9.4.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`sendmail` 方法是另一个 RxJava 管道，它组合了异步操作和数据处理，如图 9.4 所示。'
- en: '![](../Images/CH09_F04_Ponge.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F04_Ponge.png)'
- en: Figure 9.4 Asynchronous operations to prepare and then send a congratulation
    email
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 准备并发送祝贺邮件的异步操作
- en: It starts by issuing an HTTP request to the user profile service and finding
    the user name of the device owner. It then prepares another request to fetch the
    user profile data to get the email address. The following listing provides the
    implementation of the `getEmail` method.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 它首先向用户配置文件服务发出HTTP请求，找到设备所有者的用户名。然后准备另一个请求以获取用户配置文件数据以获取电子邮件地址。以下列表提供了`getEmail`方法的实现。
- en: Listing 9.16 Request to retrieve the email address
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.16 请求检索电子邮件地址
- en: '[PRE15]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Send the request.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 发送请求。
- en: ❷ Keep only the email address.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 仅保留电子邮件地址。
- en: The next step is to prepare an email, enclosed in a `MailMessage` instance,
    as shown in the following implementation of the `makeEmail` method.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是准备一个电子邮件，封装在`MailMessage`实例中，如下面的`makeEmail`方法的实现所示。
- en: Listing 9.17 Preparing an email message
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.17 准备电子邮件消息
- en: '[PRE16]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Address of the sender
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 发送者地址
- en: ❷ Recipient address
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 收件人地址
- en: ❸ Subject
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 主题
- en: ❹ Body
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 消息体
- en: Note that for more advanced email formatting, you could use a template engine
    rather than text.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于更高级的电子邮件格式化，你可以使用模板引擎而不是文本。
- en: Now that you know how to do messaging and event streaming with Vert.x, let’s
    not forget integration testing, to ensure that both the ingestion and congratulation
    services work correctly.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何在Vert.x中执行消息传递和事件流，让我们不要忘记集成测试，以确保摄入和祝贺服务都能正确工作。
- en: 9.4 Integration tests
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 集成测试
- en: Testing the ingestion service involves sending device updates over AMQP and
    HTTP, and observing the Kafka topics. Conversely, testing the congratulation service
    involves sending events to Kafka topics, and observing the emails.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 测试摄入服务包括通过AMQP和HTTP发送设备更新，并观察Kafka主题。相反，测试祝贺服务包括向Kafka主题发送事件，并观察电子邮件。
- en: 9.4.1 Ingestion testing
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.1 摄入测试
- en: Testing the ingestion service requires sending a message over AMQP or HTTP,
    and then checking that a Kafka record has been emitted, as shown in figure 9.5.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 测试摄入服务需要通过AMQP或HTTP发送消息，然后检查是否已发出Kafka记录，如图9.5所示。
- en: '![](../Images/CH09_F05_Ponge.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![图9.5 Ponge](../Images/CH09_F05_Ponge.png)'
- en: Figure 9.5 Ingestion integration-test overview
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5 摄入集成测试概述
- en: The `IntegrationTest` class in the ingestion service source code uses JUnit
    5 and Docker containers to start an AMQP broker, Apache Kafka, and Apache ZooKeeper.
    The following listing shows the test preparation.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 摄入服务源代码中的`IntegrationTest`类使用JUnit 5和Docker容器启动AMQP代理、Apache Kafka和Apache ZooKeeper。以下列表显示了测试准备。
- en: Listing 9.18 Ingestion test preparation
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.18 摄入测试准备
- en: '[PRE17]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Kafka consumer
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Kafka消费者
- en: ❷ AMQP client
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ AMQP客户端
- en: ❸ Client to administer Kafka
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 客户端管理Kafka
- en: ❹ Deploy the ingestion verticle.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 部署摄入verticle。
- en: ❺ Delete all incoming.steps topics if they exist.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 如果存在，删除所有`incoming.steps`主题。
- en: 'The preparation consists of deploying the `IngesterVerticle` verticle, and
    then deleting any existing `incoming.steps` topic. This ensures that tests do
    not pollute each other with remaining Kafka events. Note the `onErrorComplete`
    combinator: it ensures progress, because deleting topics raises an error when
    they don’t exist. We want to run the tests when `incoming.steps` does not exist,
    which is typically the case of the first test being run. Of course, `onErrorComplete`
    can mask a deployment failure of `IngesterVerticle`, but we will find that out
    in test executions.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 准备包括部署`IngesterVerticle` verticle，然后删除任何现有的`incoming.steps`主题。这确保测试不会因剩余的Kafka事件而相互污染。注意`onErrorComplete`组合器：它确保进度，因为删除主题在它们不存在时会引发错误。我们希望在`incoming.steps`不存在时运行测试，这通常是第一个测试运行的情况。当然，`onErrorComplete`可能会掩盖`IngesterVerticle`部署失败，但我们在测试执行中会发现这一点。
- en: The following listing shows the preamble of the test case where a well-formed
    AMQP message is being ingested.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了测试案例的前言，其中正在摄入格式良好的AMQP消息。
- en: Listing 9.19 AMQP ingestion test preamble
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.19 AMQP摄入测试前言
- en: '[PRE18]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Open an AMQP client connection.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 打开AMQP客户端连接。
- en: ❷ Create a sender to the step-events destination.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建一个发送到步骤事件目标的发送者。
- en: ❸ Create an AMQP message.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建一个AMQP消息。
- en: ❹ Send the message.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 发送消息。
- en: The AMQP client sends a message that we know is well-formed, as its body contains
    all the required JSON entries.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: AMQP客户端发送的消息格式良好，因为其体中包含所有必需的JSON条目。
- en: Once this is done, we need to check that a Kafka record has been sent, as follows.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此操作后，我们需要检查是否已发送Kafka记录，如下所示。
- en: 'Listing 9.20 AMQP ingestion test: checking for a Kafka record'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.20 AMQP摄入测试：检查Kafka记录
- en: '[PRE19]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Subscribe to the Kafka topic.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 订阅Kafka主题。
- en: ❷ Perform assertions on the Kafka record.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 对 Kafka 记录执行断言。
- en: ❸ The test passes.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 测试通过。
- en: ❹ Fail the test on any error.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在任何错误发生时失败测试。
- en: Of course, we also need to test what happens when an incorrect message is sent,
    like an empty JSON document. We must check that no Kafka record is being emitted,
    as in the following listing.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们还需要测试发送不正确的消息会发生什么，比如一个空的 JSON 文档。我们必须检查没有 Kafka 记录被发出，如下所示。
- en: Listing 9.21 Ingesting a bad JSON document
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.21 摄取一个坏的 JSON 文档
- en: '[PRE20]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ Empty JSON
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 空的 JSON
- en: ❷ Send it (same code as in listing 9.20)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 发送它（与列表 9.20 中的代码相同）
- en: ❸ Wait for three seconds.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 等待三秒钟。
- en: ❹ Check that this is the error we expected!
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 检查这确实是我们预期的错误！
- en: 'The timeout in the RxJava pipeline is important, as we need to let some time
    lapse to be sure that no Kafka record has been sent. The remainder of the `IntegrationTest`
    class is quite similar, with two test cases for the HTTP ingestion: one that checks
    what happens when a correct payload is sent, and one where the payload is an empty
    JSON document.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RxJava 管道中的超时很重要，因为我们需要留出一些时间来确保没有 Kafka 记录被发送。`IntegrationTest` 类的其余部分相当相似，有两个针对
    HTTP 摄取的测试用例：一个检查当发送正确的有效负载时会发生什么，另一个是有效负载是一个空的 JSON 文档。
- en: 9.4.2 Congratulation email testing
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.2 庆祝邮件测试
- en: Testing the behavior of the congratulation service is more involved than the
    ingestion, as there are more moving parts in the test environment, as illustrated
    in figure 9.6.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 测试庆祝服务的功能比摄取更复杂，因为测试环境中涉及更多的组件，如图 9.6 所示。
- en: '![](../Images/CH09_F06_Ponge.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F06_Ponge.png)'
- en: Figure 9.6 Congratulation service integration-test overview
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6 庆祝服务集成测试概览
- en: The goal is to send Kafka records and then observe the emails that have been
    sent (or not sent). Interestingly, MailHog is not just an SMTP server; it also
    provides a web interface and an HTTP API to simulate an email inbox. This allows
    us to perform tests by sending Kafka records, and then checking what emails have
    been received in the inbox.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是发送 Kafka 记录，然后观察发送的（或未发送的）电子邮件。有趣的是，MailHog 不仅仅是一个 SMTP 服务器；它还提供了一个 Web 界面和
    HTTP API 来模拟电子邮件收件箱。这允许我们通过发送 Kafka 记录来执行测试，然后检查收件箱中接收到的电子邮件。
- en: The `CongratsTest` class features a `prepare` initialization method that creates
    a Kafka producer (to send Kafka events) and a Vert.x web client (to query the
    inbox). The steps in the `prepare` method to prepare the environment are shown
    in the following listing.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '`CongratsTest` 类具有一个 `prepare` 初始化方法，该方法创建一个 Kafka 生产者（用于发送 Kafka 事件）和一个 Vert.x
    Web 客户端（用于查询收件箱）。`prepare` 方法中准备环境的步骤如下所示。'
- en: Listing 9.22 Preparing the congratulation service integration test
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.22 准备庆祝服务集成测试
- en: '[PRE21]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Delete Kafka topics.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 删除 Kafka 主题。
- en: ❷ Deploy the verticle.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 部署 verticle。
- en: ❸ Deploy a mock user account service.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 部署一个模拟用户账户服务。
- en: ❹ Delete all messages from the inbox.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 从收件箱中删除所有消息。
- en: We first delete existing Kafka topics, and then we deploy the verticle under
    test. We also deploy a verticle to mock the user profile service and delete all
    messages from the inbox by making an HTTP `DELETE` query to the MailHog instance.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先删除现有的 Kafka 主题，然后部署要测试的 verticle。我们还部署了一个 verticle 来模拟用户配置文件服务，并通过向 MailHog
    实例发送 HTTP `DELETE` 请求来删除收件箱中的所有消息。
- en: The `FakeUserService` verticle found in the test source exposes an HTTP service
    with the minimal level of functionality to replace the real user profile service
    in our tests. All requests to find out who owns a device point to user `Foo`,
    and retrieving the details of user `Foo` gives just the username and email. The
    following listing shows an excerpt with the code for answering a user details
    request with information for user `Foo` and just the JSON entries needed for `CongratsVerticle`
    to operate.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试源中找到的 `FakeUserService` verticle 提供了一个具有最小功能级别的 HTTP 服务，以替换我们的测试中真实的用户配置文件服务。所有查找设备所有者的请求都指向用户
    `Foo`，检索用户 `Foo` 的详细信息只提供用户名和电子邮件。以下列表显示了包含用于回答用户详细信息请求的 `Foo` 用户信息和 `CongratsVerticle`
    运作所需的 JSON 条目的代码摘录。
- en: Listing 9.23 Excerpt from the `FakeUserService` class
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.23 `FakeUserService` 类摘录
- en: '[PRE22]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Route for a user profile info
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 用户配置文件信息路由
- en: ❷ JSON with just the required data for the service and test
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 只包含服务测试所需数据的 JSON
- en: This way we have good isolation of the congratulation service for testing. We
    could also have deployed the real user profile service, but that would have involved
    preparing a database with some data. It is always better to replace dependent
    services with mock ones when you can.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 这样我们就能为测试提供良好的祝贺服务隔离。我们也可以部署真实用户配置文件服务，但这将涉及到准备包含一些数据的数据库。当你能够这样做时，总是用模拟服务替换依赖服务更好。
- en: The next listing shows the full test case for checking that no email is sent
    on a Kafka record with less than 10,000 steps.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表显示了检查在 Kafka 记录中少于 10,000 步的情况下没有发送电子邮件的完整测试用例。
- en: Listing 9.24 Checking that no mail has been sent for less than 10,000 steps
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.24 检查在少于 10,000 步的情况下没有发送邮件
- en: '[PRE23]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Kafka record for device 123 and 5000 steps
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设备 123 的 Kafka 记录和 5000 步
- en: ❷ Wait for three seconds after the message has been sent.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在消息发送后等待三秒钟。
- en: ❸ Query all messages for email foo@mail.tld.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 查询所有邮件，查找 foo@mail.tld 的电子邮件。
- en: ❹ Check that there is no message.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 检查没有消息。
- en: The MailHog API allows us to check what messages have been sent. The next listing
    checks whether an email was sent for more than 10,000 steps.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: MailHog API 允许我们检查发送了哪些消息。接下来的列表检查是否发送了超过 10,000 步的电子邮件。
- en: Listing 9.25 Checking whether an email was sent for more than 10,000 steps
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.25 检查是否发送了超过 10,000 步的电子邮件
- en: '[PRE24]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ❶ A record with 11,000 steps
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 包含 11,000 步的记录
- en: ❷ We must have one message.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们必须有一个消息。
- en: The last test case in the `checkNotTwiceToday` method checks that only one email
    was sent for two successive records with more than 10,000 steps. I haven’t reproduced
    the code here due to its verbosity, but you can get it from the book’s source
    code repository.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '`checkNotTwiceToday` 方法中的最后一个测试用例检查了对于超过 10,000 步的两个连续记录只发送了一封电子邮件。由于代码的冗长，我没有在这里重现代码，但你可以从书籍的源代码仓库中获取它。'
- en: This concludes the design, implementation, and testing of two services that
    use messaging and event streaming. The next chapter focuses on Vert.x and data
    sources.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了使用消息和事件流设计的两个服务的实现和测试。下一章将专注于 Vert.x 和数据源。
- en: Summary
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: AMQP is a standard protocol for message brokers, and you saw how to consume
    and produce AQMP messages with Vert.x and Apache ActiveMQ.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AMQP 是一个用于消息代理的标准协议，你看到了如何使用 Vert.x 和 Apache ActiveMQ 消费和产生 AMQP 消息。
- en: Apache Kafka is event-streaming middleware that allows services to replay events
    at will. Vert.x provides efficient integration with Kafka.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Apache Kafka 是一种允许服务随意回放事件的流式事件中间件。Vert.x 提供了与 Kafka 的高效集成。
- en: RxJava allows you to write event-processing pipelines in a declarative fashion,
    and with built-in error recovery.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RxJava 允许你以声明式的方式编写事件处理管道，并具有内置的错误恢复功能。
- en: We explored strategies for writing integration tests with AMQP, Kafka, and test
    containers by sending messages from tests to replace external components.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过从测试中发送消息来替换外部组件，探索了使用 AMQP、Kafka 和测试容器编写集成测试的策略。
- en: MailHog is a test-friendly SMTP server that exposes a convenient API for inspecting
    what emails have been sent.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MailHog 是一个测试友好的 SMTP 服务器，它提供了一个方便的 API 来检查发送了哪些电子邮件。
