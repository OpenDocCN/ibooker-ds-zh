- en: 8 Overview of relevant technologies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 相关技术的概述
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Getting familiar with model building using TensorFlow
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熟悉使用TensorFlow进行模型构建
- en: Understanding key terminologies on Kubernetes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Kubernetes上的关键术语
- en: Running distributed machine learning workloads with Kubeflow
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kubeflow运行分布式机器学习工作负载
- en: Deploying container-native workflows using Argo Workflows
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Argo Workflows部署容器原生工作流程
- en: In the previous chapter, we went through the project background and system components
    to understand our strategies for implementing each component. We also discussed
    the challenges related to each component and discussed the patterns we will apply
    to address them. As previously mentioned, we will dive into the project’s implementation
    details in chapter 9, the book’s last chapter. However, since we will use different
    technologies in the project and it’s not easy to cover all the basics on the fly,
    in this chapter, you will learn the basic concepts of the four technologies (TensorFlow,
    Kubernetes, Kubeflow, and Argo Workflows) and gain hands-on experience.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解了项目背景和系统组件，以理解我们实现每个组件的策略。我们还讨论了与每个组件相关的挑战，并讨论了我们将应用的解决模式。如前所述，我们将在第9章，即本书的最后一章中深入探讨项目的实现细节。然而，由于项目将使用不同的技术，且难以即时涵盖所有基础知识，因此在本章中，你将学习四种技术（TensorFlow、Kubernetes、Kubeflow和Argo
    Workflows）的基本概念，并获得实践经验。
- en: Each of these four technologies has a different purpose, but all will be used
    to implement the final project in chapter 9\. TensorFlow will be used for data
    processing, model building, and evaluation. We will use Kubernetes as our core
    distributed infrastructure. On top of that, Kubeflow will be used for submitting
    distributed model training jobs to the Kubernetes cluster, and Argo Workflows
    will be used to construct and submit the end-to-end machine learning workflows.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这四种技术各有不同的用途，但都将用于在第9章中实现最终项目。TensorFlow将用于数据处理、模型构建和评估。我们将使用Kubernetes作为我们的核心分布式基础设施。在此基础上，我们将使用Kubeflow将分布式模型训练作业提交到Kubernetes集群，并使用Argo
    Workflows构建和提交端到端的机器学习工作流程。
- en: '8.1 TensorFlow: The machine learning framework'
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 TensorFlow：机器学习框架
- en: TensorFlow is an end-to-end machine learning platform. It has been widely adopted
    in academia and industries for different applications and uses cases, such as
    image classification, recommendation systems, natural language processing, etc.
    TensorFlow is highly portable, deployable on different hardware, and has multilanguage
    support.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是一个端到端的机器学习平台。它已被广泛采用于学术界和工业界，用于各种应用和用例，例如图像分类、推荐系统、自然语言处理等。TensorFlow具有高度的便携性和可部署性，可以在不同的硬件上运行，并支持多种语言。
- en: 'TensorFlow has a large ecosystem. The following are some highlighted projects
    in this ecosystem:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow拥有庞大的生态系统。以下是一些该生态系统中的重点项目：
- en: TensorFlow.js is a library for machine learning in JavaScript. Users can use
    machine learning directly in the browser or in Node.js.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow.js是一个用于JavaScript的机器学习库。用户可以直接在浏览器或Node.js中使用机器学习。
- en: TensorFlow Lite is a mobile library for deploying models on mobile, microcontrollers,
    and other edge devices.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Lite是一个移动库，用于在移动设备、微控制器和其他边缘设备上部署模型。
- en: TFX is an end-to-end platform for deploying production machine learning pipelines.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TFX是一个端到端平台，用于部署生产机器学习管道。
- en: TensorFlow Serving is a flexible, high-performance serving system for machine
    learning models designed for production environments.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Serving是一个灵活、高性能的机器学习模型服务系统，专为生产环境设计。
- en: TensorFlow Hub is a repository of trained machine learning models ready for
    fine-tuning and deployable anywhere. Reuse trained models like BERT and Faster
    R-CNN with just a few lines of code.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Hub是一个存储库，包含经过训练的机器学习模型，可用于微调和部署到任何地方。只需几行代码即可重用BERT和Faster R-CNN等训练模型。
- en: More can be found in the TensorFlow GitHub organization ([https://github.com/tensorflow](https://github.com/tensorflow)).
    We will use TensorFlow Serving in our model serving component. In the next section,
    we’ll walk through some basic examples in TensorFlow to train a machine learning
    model locally using the MNIST dataset.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 更多信息可以在TensorFlow GitHub组织（[https://github.com/tensorflow](https://github.com/tensorflow)）中找到。我们将在模型服务组件中使用TensorFlow
    Serving。在下一节中，我们将通过一些TensorFlow的基本示例来训练机器学习模型，使用MNIST数据集进行本地训练。
- en: 8.1.1 The basics
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.1 基础知识
- en: Let’s first install Anaconda for Python 3 for the basic examples we will use.
    Anaconda ([https://www.anaconda.com](https://www.anaconda.com)) is a distribution
    of the Python and R programming languages for scientific computing that aims to
    simplify package management and deployment. The distribution includes data-science
    packages suitable for Windows, Linux, and macOS. Once Anaconda is installed, use
    the following command in your console to install a Conda environment with Python
    3.9.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先为我们将要使用的示例安装Python 3的Anaconda。Anaconda（[https://www.anaconda.com](https://www.anaconda.com)）是Python和R编程语言的科学计算发行版，旨在简化包管理和部署。该发行版包括适用于Windows、Linux和macOS的数据科学包。一旦安装了Anaconda，请在您的控制台中使用以下命令安装Python
    3.9的Conda环境。
- en: Listing 8.1 Creating a Conda environment
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.1 创建Conda环境
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, we can activate this environment with the following code.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用以下代码激活此环境。
- en: Listing 8.2 Activating a Conda environment
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.2 激活Conda环境
- en: '[PRE1]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Then, we can install TensorFlow in this Python environment.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以在这个Python环境中安装TensorFlow。
- en: Listing 8.3 Installing TensorFlow
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.3 安装TensorFlow
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you encounter any problems, please refer to the installation guide ([https://www.tensorflow.org/install](https://www.tensorflow.org/install)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您遇到任何问题，请参阅安装指南（[https://www.tensorflow.org/install](https://www.tensorflow.org/install)）。
- en: In some cases, you may need to uninstall your existing NumPy and reinstall it.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，您可能需要卸载现有的NumPy并重新安装它。
- en: Listing 8.4 Installing NumPy
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.4 安装NumPy
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you are on Mac, check out the Metal plugin for acceleration ([https://developer.apple.com/metal/tensorflow-plugin/](https://developer.apple.com/metal/tensorflow-plugin/)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用的是Mac，请查看Metal插件以实现加速（[https://developer.apple.com/metal/tensorflow-plugin/](https://developer.apple.com/metal/tensorflow-plugin/)）。
- en: Once we’ve successfully installed TensorFlow, we can start with a basic image
    classification example! Let’s first load and preprocess our simple MNIST dataset.
    Recall that the MNIST dataset contains images for handwritten digits from 0 to
    9\. Each row represents images for a particular handwritten digit, as shown in
    figure 8.1.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们成功安装了TensorFlow，我们就可以从一个基本的图像分类示例开始！让我们首先加载并预处理我们的简单MNIST数据集。回想一下，MNIST数据集包含从0到9的手写数字图像。每一行代表特定手写数字的图像，如图8.1所示。
- en: '![08-01](../../OEBPS/Images/08-01.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![08-01](../../OEBPS/Images/08-01.png)'
- en: Figure 8.1 Some example images for handwritten digits from 0 to 9 where each
    row represents images for a particular handwritten digit
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 从0到9的手写数字示例图像，其中每一行代表特定手写数字的图像
- en: Keras API (tf.keras) is a high-level API for model training in TensorFlow, and
    we will use it for both loading the built-in datasets and model training and evaluation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Keras API（tf.keras）是TensorFlow中模型训练的高级API，我们将用它来加载内置数据集以及模型训练和评估。
- en: Listing 8.5 Loading the MNIST dataset
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.5 加载MNIST数据集
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The function load_data()uses a default path to save the MNIST dataset if we
    don’t specify a path. This function will return NumPy arrays for training and
    testing images and labels. We split the dataset into training and testing so we
    can run both model training and evaluation in our example.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有指定路径，函数load_data()将使用默认路径保存MNIST数据集。此函数将返回训练和测试图像及标签的NumPy数组。我们将数据集分为训练和测试，以便我们可以在示例中运行模型训练和评估。
- en: 'A NumPy array is a common data type in Python’s scientific computing ecosystem.
    It describes multidimensional arrays and has three properties: data, shape, and
    dtype. Let’s use our training images as an example.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy数组是Python科学计算生态系统中常见的数据类型。它描述多维数组，并具有三个属性：数据、形状和数据类型。让我们以我们的训练图像为例。
- en: Listing 8.6 Inspecting the dataset
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.6 检查数据集
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: x_train is a 60,000 × 28 × 28 three-dimensional array. The data type is uint8
    from 0 to 255. In other words, this object contains 60,000 grayscale images with
    a resolution of 28 × 28.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: x_train是一个60,000 × 28 × 28的三维数组。数据类型是uint8，范围从0到255。换句话说，这个对象包含60,000个28 × 28分辨率的灰度图像。
- en: Next, we can perform some feature preprocessing on our raw images. Since many
    algorithms and models are sensitive to the scale of the features, we often center
    and scale features into a range such as [0, 1] or [-1, 1]. In our case, we can
    do this easily by dividing the images by 255.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以在原始图像上执行一些特征预处理。由于许多算法和模型对特征的规模很敏感，我们通常将特征中心化和缩放到[0, 1]或[-1, 1]的范围。在我们的例子中，我们可以通过将图像除以255来实现这一点。
- en: Listing 8.7 The preprocessing function
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.7 预处理函数
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After preprocessing the images in the training and testing set, we can instantiate
    a simple multilayer neural network model. We use tf.keras to define the model
    architecture. First, we use Flatten to expand the two-dimensional images into
    a one-dimensional array by specifying the input shape as 28 × 28\. The second
    layer is densely connected and uses the 'relu' activation function to introduce
    some nonlinearity. The third layer is a dropout layer to reduce overfitting and
    make the model more generalizable. Since the handwritten digits consist of 10
    different digits from 0 to 9, our last layer is densely connected for 10-class
    classification with softmax activation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在对训练集和测试集中的图像进行预处理后，我们可以实例化一个简单的多层神经网络模型。我们使用 tf.keras 定义模型架构。首先，我们使用 Flatten
    将二维图像扩展成一维数组，指定输入形状为 28 × 28。第二层是密集连接层，并使用 'relu' 激活函数引入一些非线性。第三层是一个 dropout 层，用于减少过拟合并使模型更具泛化能力。由于手写数字由
    0 到 9 的 10 个不同数字组成，我们的最后一层是密集连接层，用于 10 类分类，并使用 softmax 激活。
- en: Listing 8.8 The sequential model definition
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.8 顺序模型定义
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After we’ve defined the model architecture, we need to specify three different
    components: the evaluation metric, loss function, and optimizer.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们定义了模型架构之后，我们需要指定三个不同的组件：评估指标、损失函数和优化器。
- en: Listing 8.9 Model compilation with optimizer, loss function, and optimizer
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.9 使用优化器、损失函数和优化器编译模型
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can then start our model training with five epochs as well as evaluation
    via the following.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过以下方式开始我们的模型训练，包括五个周期以及评估。
- en: Listing 8.10 Model training using the training data
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.10 使用训练数据训练模型
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We should see training progress in the log:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该在日志中看到训练进度：
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And the log from the model evaluation should look like the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 并且模型评估的日志应该看起来像以下这样：
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We should observe that as the loss decreases during training, the accuracy increases
    to 97.8% on training data. The final trained model has an accuracy of 97.6% on
    the testing data. Your result might be slightly different due to the randomness
    in the modeling process.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该观察到，在训练过程中损失下降时，训练数据的准确率增加到 97.8%。最终训练好的模型在测试数据上的准确率为 97.6%。由于建模过程中的随机性，你的结果可能会有所不同。
- en: After we’ve trained the model and are happy with its performance, we can save
    it using the following code so that we don’t have to retrain it from scratch next
    time.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们训练好模型并对它的性能感到满意后，我们可以使用以下代码保存它，这样我们下次就不需要从头开始重新训练。
- en: Listing 8.11 Saving the trained model
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.11 保存训练好的模型
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This code saves the model as file my_model.h5 in the current working directory.
    When we start a new Python session, we can import TensorFlow and load the model
    object from the my_model.h5 file.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将模型保存为当前工作目录下的文件 my_model.h5。当我们启动一个新的 Python 会话时，我们可以导入 TensorFlow 并从 my_model.h5
    文件中加载模型对象。
- en: Listing 8.12 Loading the saved model
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.12 加载已保存的模型
- en: '[PRE13]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We’ve learned how to train a model using TensorFlow’s Keras API for a single
    set of hyperparameters. These hyperparameters remain constant over the training
    process and directly affect the performance of your machine learning program.
    Let’s learn how to tune hyperparameters for your TensorFlow program with Keras
    Tuner ([https://keras.io/keras_tuner/](https://keras.io/keras_tuner/)). First,
    install the Keras Tuner library.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学习了如何使用 TensorFlow 的 Keras API 训练一个具有单个超参数集的模型。这些超参数在整个训练过程中保持不变，并直接影响机器学习程序的性能。让我们学习如何使用
    Keras Tuner 调整 TensorFlow 程序的超参数（[https://keras.io/keras_tuner/](https://keras.io/keras_tuner/)）。首先，安装
    Keras Tuner 库。
- en: Listing 8.13 Installing the Keras Tuner package
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.13 安装 Keras Tuner 包
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Once it’s installed, you should be able to import all the required libraries.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装完成，你应该能够导入所有必需的库。
- en: Listing 8.14 Importing necessary packages
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.14 导入必要的包
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We will use the same MNIST dataset and the preprocessing functions for our hyperparameter
    tuning example. We then wrap our model definition into a Python function.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用相同的 MNIST 数据集和预处理函数来演示超参数调整示例。然后，我们将模型定义包装成一个 Python 函数。
- en: Listing 8.15 The model building function using TensorFlow and Keras Tuner
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.15 使用 TensorFlow 和 Keras Tuner 构建模型的功能
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This code is essentially the same as what we used previously for training a
    model with a single set of hyperparameters, except that we also defined hp_units
    and hp_learning_rate objects that are used in our dense layer and optimizer.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码基本上与我们之前用于训练具有单个超参数集的模型相同，不同之处在于我们还定义了 hp_units 和 hp_learning_rate 对象，这些对象用于我们的密集层和优化器。
- en: 'The hp_units object instantiates an integer that will be tuned between 32 and
    512 and used as the number of units in the first densely connected layer. The
    hp_learning_rate object will tune the learning rate for the adam optimizer that
    will be chosen from among these values: 0.01, 0.001, or 0.0001.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: hp_units 对象实例化一个整数，该整数将在 32 和 512 之间调整，并用作第一个密集连接层的单元数。hp_learning_rate 对象将调整用于
    adam 优化器的学习率，该学习率将从以下值中选择：0.01、0.001 或 0.0001。
- en: Once the model builder is defined, we can then instantiate our tuner. There
    are several tuning algorithms we can use (e.g., random search, Bayesian optimization,
    Hyperband). Here we use the hyperband tuning algorithm. It uses adaptive resource
    allocation and early stopping to converge faster on a high-performing model.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了模型构建器，我们就可以实例化我们的调优器。我们可以使用几种调优算法（例如，随机搜索、贝叶斯优化、Hyperband）。这里我们使用 hyperband
    调优算法。它使用自适应资源分配和早期停止来更快地收敛到高性能模型。
- en: Listing 8.16 The Hyperband model tuner
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.16 Hyperband 模型调优器
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We use the validation accuracy as the objective, and the maximum number of epochs
    is 10 during model tuning.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用验证准确率作为目标，在模型调优期间最大迭代次数为 10。
- en: To reduce overfitting, we can create an EarlyStopping callback to stop training
    as soon as the model reaches a threshold for the validation loss. Make sure to
    reload the dataset into memory if you’ve started a new Python session.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少过拟合，我们可以创建一个 EarlyStopping 回调，一旦模型达到验证损失的阈值，就停止训练。如果你已经启动了一个新的 Python 会话，请确保重新将数据集加载到内存中。
- en: Listing 8.17 The EarlyStopping callback
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.17 EarlyStopping 回调
- en: '[PRE18]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Now we can start our hyperparameter search via tuner.search().
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以通过 tuner.search() 开始我们的超参数搜索。
- en: Listing 8.18 The Hyperparameter search with early-stopping
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.18 带有早期停止的超参数搜索
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Once the search is complete, we can identify the optimal hyperparameters and
    train the model on the data for 30 epochs.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦搜索完成，我们可以识别最佳超参数，并在数据上训练模型 30 个周期。
- en: Listing 8.19 Obtaining the best hyperparameters and training the model
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.19 获取最佳超参数并训练模型
- en: '[PRE20]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: When we evaluate the model on our test data, we should see it’s more performant
    than our baseline model without hyperparameter tuning.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在测试数据上评估模型时，我们应该看到它比没有超参数调整的基线模型性能更好。
- en: Listing 8.20 Model evaluation on the test data
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.20 在测试数据上评估模型
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You’ve learned how to run TensorFlow locally on a single machine. To take the
    most advantage of TensorFlow, the model training process should be run in a distributed
    cluster, which is where Kubernetes comes into play. In the next section, I will
    introduce Kubernetes and provide hands-on examples of the fundamentals.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学会了如何在单机上运行 TensorFlow。为了最大限度地利用 TensorFlow，模型训练过程应该在分布式集群中运行，这就是 Kubernetes
    发挥作用的地方。在下一节中，我将介绍 Kubernetes 并提供基础知识的实战示例。
- en: 8.1.2 Exercises
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.2 练习
- en: Can you use the previously saved model directly for model evaluation?
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以直接使用之前保存的模型进行模型评估吗？
- en: Instead of using the Hyperband tuning algorithm, could you try the random search
    algorithm?
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了使用 Hyperband 调优算法，你能尝试随机搜索算法吗？
- en: '8.2 Kubernetes: The distributed container orchestration system'
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 Kubernetes：分布式容器编排系统
- en: '*Kubernetes* (also known as K8s) is an open source system for automating the
    deployment, scaling, and management of containerized applications. It abstracts
    away complex container management and provides declarative configurations to orchestrate
    containers in different computing environments.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*Kubernetes*（也称为 K8s）是一个用于自动化容器化应用程序部署、扩展和管理的开源系统。它抽象了复杂的容器管理，并为不同计算环境中的容器编排提供了声明性配置。'
- en: Containers are grouped into logical units for a particular application for easy
    management and discovery. Kubernetes builds upon more than 16 years of experience
    running production workloads at Google, combined with best-in-class ideas and
    practices from the community. Its main design goal is to make it easy to deploy
    and manage complex distributed systems, while still benefiting from the improved
    utilization that containers enable. It’s open source, which gives the community
    the freedom to take advantage of on-premises, hybrid, or public cloud infrastructure
    and lets you effortlessly move workloads to where it matters.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 容器被分组为特定应用的逻辑单元，以便于管理和发现。Kubernetes建立在谷歌16年以上的生产工作负载经验之上，结合了社区中最佳的想法和实践。其主要设计目标是使部署和管理复杂的分布式系统变得容易，同时仍然能够从容器带来的改进利用率中受益。它是开源的，这给了社区利用本地、混合或公共云基础设施的自由，并允许你轻松地将工作负载迁移到需要的地方。
- en: Kubernetes is designed to scale without increasing your operations team. Figure
    8.2 is an architecture diagram of Kubernetes and its components. However, we won’t
    be discussing those components because they are not the focus of this book. We
    will, however, use kubectl (on the left-hand side of the diagram), a command-line
    interface of Kubernetes, to interact with the Kubernetes cluster and obtain information
    that we are interested in.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes的设计旨在在不增加你的运维团队的情况下进行扩展。图8.2是Kubernetes及其组件的架构图。然而，我们不会讨论这些组件，因为它们不是本书的重点。不过，我们将使用kubectl（位于图左侧），Kubernetes的命令行界面，来与Kubernetes集群交互并获取我们感兴趣的信息。
- en: '![08-02](../../OEBPS/Images/08-02.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![08-02](../../OEBPS/Images/08-02.png)'
- en: Figure 8.2 An architecture diagram of Kubernetes
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 Kubernetes的架构图
- en: We will go through some basic concepts and examples to build our knowledge and
    prepare the following sections on Kubeflow and Argo Workflows.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一些基本概念和示例来构建我们的知识，并为Kubeflow和Argo Workflows的后续章节做准备。
- en: 8.2.1 The basics
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 基础知识
- en: First, let’s set up a local Kubernetes cluster. We’ll use k3d ([https://k3d.io](https://k3d.io))
    to bootstrap the local cluster. k3d is a lightweight wrapper to run k3s (a minimal
    Kubernetes distribution provided by Rancher Lab) in Docker. k3d makes it very
    easy to create either single-node or multinode k3s clusters in Docker for local
    development that requires a Kubernetes cluster. Let’s create a Kubernetes cluster
    called distml via k3s.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们设置一个本地Kubernetes集群。我们将使用k3d（[https://k3d.io](https://k3d.io)）来引导本地集群。k3d是一个轻量级的包装器，用于在Docker中运行Rancher
    Lab提供的最小Kubernetes发行版k3s。k3d使得在Docker中创建单节点或多节点k3s集群以进行需要Kubernetes集群的本地开发变得非常容易。让我们通过k3s创建一个名为distml的Kubernetes集群。
- en: Listing 8.21 Creating a local Kubernetes cluster
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.21 创建本地Kubernetes集群
- en: '[PRE22]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We can get the list of nodes for the cluster we created via the following listing.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下列表获取我们创建的集群的节点列表。
- en: Listing 8.22 Obtaining the list of nodes in the cluster
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.22 获取集群中节点的列表
- en: '[PRE23]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In this case, the node was created 1 minute ago, and we are running the v1.25.3+k3s1
    version of the k3s distribution. The status is ready so that we can proceed to
    the next steps.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，节点是在1分钟前创建的，我们正在运行k3s发行版的v1.25.3+k3s1版本。状态为就绪，这样我们就可以进行下一步了。
- en: 'We can also look at the node’s details via kubectl describe node k3d-distml-server-0.
    For example, the labels and system info contain information on the operating system
    and its architecture, whether this node is a master node, etc.:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过kubectl describe node k3d-distml-server-0查看节点的详细信息。例如，标签和系统信息包含有关操作系统及其架构的信息，是否该节点是主节点等信息：
- en: '[PRE24]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Then we’ll create a *namespace* called basics in this cluster for our project.
    Namespaces in Kubernetes provide a mechanism for isolating groups of resources
    within a single cluster (see [http://mng.bz/BmN1](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/)).
    Names of resources need to be unique within a namespace but not across namespaces.
    The following examples will be in this single namespace.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将在该集群中创建一个名为basics的*命名空间*用于我们的项目。Kubernetes中的命名空间提供了一种机制，用于在单个集群内隔离资源组（见[http://mng.bz/BmN1](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/)）。资源名称需要在命名空间内是唯一的，但不同命名空间之间不需要唯一。以下示例将在这个单一命名空间内。
- en: Listing 8.23 Creating a new namespace
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.23 创建新的命名空间
- en: '[PRE25]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Once the cluster and namespace are set up, we’ll use a convenient tool called
    kubectx to help us inspect and navigate between namespaces and clusters ([https://github.com/ahmetb/kubectx](https://github.com/ahmetb/kubectx)).
    Note that this tool is not required for day-to-day work with Kubernetes, but it
    should make Kubernetes much easier to work with for developers. For example, we
    can obtain a list of clusters and namespaces that we can connect to via the following
    listing.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦集群和命名空间设置完成，我们将使用一个名为 kubectx 的便捷工具来帮助我们检查和在不同命名空间和集群之间导航 ([https://github.com/ahmetb/kubectx](https://github.com/ahmetb/kubectx)).
    注意，这个工具在日常使用 Kubernetes 时不是必需的，但它应该会使开发者更容易与 Kubernetes 一起工作。例如，我们可以通过以下列表获取可以连接到的集群和命名空间列表。
- en: Listing 8.24 Switching contexts and namespaces
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.24 切换上下文和命名空间
- en: '[PRE26]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: For example, we can switch to the distml cluster via the k3d-distml context
    and the basics namespace that we just created using the following listing.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以通过以下列表切换到 distml 集群和刚刚创建的 basics 命名空间：k3d-distml 上下文。
- en: Listing 8.25 Activate context
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.25 激活上下文
- en: '[PRE27]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Switching contexts and namespaces is often needed when working with multiple
    clusters and namespaces. We are using the basics namespace to run the examples
    in this chapter, but we will switch to another namespace dedicated to our project
    in the next chapter.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 当与多个集群和命名空间一起工作时，切换上下文和命名空间通常是必需的。我们在这个章节中使用基本命名空间来运行示例，但在下一章中，我们将切换到另一个专门为我们项目设置的命名空间。
- en: Next, we will create a Kubernetes *Pod*. Pods are the smallest deployable units
    of computing that you can create and manage in Kubernetes. A Pod may consist of
    one or more containers with shared storage and network resources and a specification
    for how to run the containers. A Pod’s contents are always co-located and co-scheduled
    and run in a shared context. The concept of the Pod models an application-specific
    “logical host,” meaning that it contains one or more application containers that
    are relatively tightly coupled. In noncloud contexts, applications executed on
    the same physical or virtual machine are analogous to cloud applications executed
    on the same logical host. In other words, a Pod is similar to a set of containers
    with shared namespaces and shared filesystem volumes.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个 Kubernetes *Pod*。Pod 是您在 Kubernetes 中可以创建和管理的最小可部署计算单元。一个 Pod 可能包含一个或多个容器，具有共享的存储和网络资源以及运行容器的规范。Pod
    的内容始终位于同一位置，并具有相同的调度，在共享上下文中运行。Pod 的概念模拟了一个特定应用的“逻辑主机”，这意味着它包含一个或多个相对紧密耦合的应用容器。在非云环境中，在同一物理或虚拟机上执行的应用程序类似于在相同逻辑主机上执行的云应用程序。换句话说，Pod
    类似于具有共享命名空间和共享文件系统卷的一组容器。
- en: The following listing provides an example of a Pod that consists of a container
    running the image whalesay to print out a “hello world” message. We save the following
    Pod spec in a file named hello-world.yaml.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表提供了一个示例 Pod，该 Pod 运行 whalesay 镜像以打印出“hello world”消息。我们将以下 Pod 规范保存在名为 hello-world.yaml
    的文件中。
- en: Listing 8.26 An example Pod
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.26 一个示例 Pod
- en: '[PRE28]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: To create the Pod, run the following command.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建 Pod，请运行以下命令。
- en: Listing 8.27 Creating the example Pod in the cluster
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.27 在集群中创建示例 Pod
- en: '[PRE29]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We can then check whether the Pod has been created by retrieving the list of
    Pods. Note that pods is plural so we can get the full list of created Pods. We
    will use the singular form to get the details of this particular Pod later.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过检索 Pod 列表来检查 Pod 是否已创建。请注意，pods 是复数形式，因此我们可以获取创建的所有 Pod 的完整列表。稍后我们将使用单数形式来获取这个特定
    Pod 的详细信息。
- en: Listing 8.28 Getting the list of Pods in the cluster
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.28 获取集群中 Pod 列表
- en: '[PRE30]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The Pod status is Completed so we can look at what’s being printed out in the
    whalesay container like in the following listing.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 状态为 Completed，因此我们可以查看 whalesay 容器中打印的内容，如下所示。
- en: Listing 8.29 Checking the Pod logs
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.29 检查 Pod 日志
- en: '[PRE31]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We can also retrieve the raw YAML of the Pod via kubectl. Note that we use -o
    yaml here to get the plain YAML, but other formats, such as JSON, are also supported.
    We use the singular pod to get the details of this particular Pod instead of the
    full list of existing Pods, as mentioned earlier.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过 kubectl 获取 Pod 的原始 YAML。请注意，我们在这里使用 -o yaml 来获取纯 YAML 格式，但还支持其他格式，如
    JSON。我们使用单数 pod 来获取这个特定 Pod 的详细信息，而不是获取现有 Pod 的完整列表，如前所述。
- en: Listing 8.30 Getting the raw Pod YAML
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.30 获取原始 Pod YAML
- en: '[PRE32]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: You may be surprised how much additional content, such as status and conditions,
    has been added to the original YAML we used to create the Pod. The additional
    information is appended and updated via the Kubernetes server so that client-side
    applications know the current status of the Pod. Even though we didn’t specify
    the namespace explicitly, the Pod was created in the basics namespace since we
    have used the kubens command to set the current namespace.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会惊讶，我们为创建Pod所使用的原始YAML中添加了多少额外的内容，比如状态和条件。这些附加信息通过Kubernetes服务器附加和更新，以便客户端应用程序知道Pod的当前状态。尽管我们没有明确指定命名空间，但由于我们使用了kubens命令设置了当前命名空间，Pod是在基本命名空间中创建的。
- en: That’s it for the basics of Kubernetes! In the next section, we will study how
    to use Kubeflow to run distributed model training jobs in the local Kubernetes
    cluster we just set up.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes的基础知识就到这里！在下一节中，我们将学习如何使用Kubeflow在我们刚刚设置的本地Kubernetes集群中运行分布式模型训练作业。
- en: 8.2.2 Exercises
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 练习
- en: How do you get the Pod information in JSON format?
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你如何获取Pod的JSON格式信息？
- en: Can a Pod contain multiplier containers?
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod是否可以包含多个容器？
- en: '8.3 Kubeflow: Machine learning workloads on Kubernetes'
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 Kubeflow：在Kubernetes上的机器学习工作负载
- en: The Kubeflow project is dedicated to making deployments of machine learning
    workflows on Kubernetes simple, portable, and scalable. The goal of Kubeflow is
    not to re-create other services but to provide a straightforward way to deploy
    best-in-class open source systems for machine learning to diverse infrastructures.
    Anywhere you run Kubernetes, you should be able to run Kubeflow. We will use Kubeflow
    to submit distributed machine learning model training jobs to a Kubernetes cluster.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow项目致力于使在Kubernetes上部署机器学习工作流程变得简单、可移植和可扩展。Kubeflow的目标不是重新创建其他服务，而是为将一流的开源机器学习系统部署到各种基础设施提供一种简单直接的方式。无论你在哪里运行Kubernetes，都应该能够运行Kubeflow。我们将使用Kubeflow将分布式机器学习模型训练作业提交到Kubernetes集群。
- en: Let’s first take a look at what components Kubeflow provides. Figure 8.3 is
    a diagram that consists of the main components.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看Kubeflow提供了哪些组件。图8.3是一个包含主要组件的图表。
- en: '![08-03](../../OEBPS/Images/08-03.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![08-03](../../OEBPS/Images/08-03.png)'
- en: Figure 8.3 Main components of Kubeflow
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 Kubeflow的主要组件
- en: 'Kubeflow Pipelines (KFP; [https://github.com/kubeflow/pipelines](https://github.com/kubeflow/pipelines))
    provides Python SDK to make machine learning pipelines easier. It is a platform
    for building and deploying portable and scalable machine learning workflows using
    Docker containers. The primary objectives of KFP are to enable the following:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow Pipelines (KFP; [https://github.com/kubeflow/pipelines](https://github.com/kubeflow/pipelines))提供了Python
    SDK，使机器学习管道更容易使用。它是一个使用Docker容器构建和部署可移植和可扩展机器学习工作流程的平台。KFP的主要目标包括以下内容：
- en: End-to-end orchestration of ML workflows
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ML工作流程的端到端编排
- en: Pipeline composability through reusable components and pipelines
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过可重用组件和管道实现管道可组合性
- en: Easy management, tracking, and visualization of pipeline definitions, runs,
    experiments, and machine learning artifacts
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单管理、跟踪和可视化管道定义、运行、实验和机器学习工件
- en: Efficient use of computing resources by eliminating redundant executions through
    caching
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过缓存消除冗余执行来有效利用计算资源
- en: Cross-platform pipeline portability through a platform-neutral IR YAML pipeline
    definition
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过平台中立的IR YAML管道定义实现跨平台管道可移植性
- en: KFP uses Argo Workflows as the backend workflow engine, which I will introduce
    in the next section, and we’ll use Argo Workflows directly instead of using a
    higher-level wrapper like KFP. The ML metadata project has been merged into KFP
    and serves as the backend for logging metadata produced in machine learning workflows
    written in KFP.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: KFP使用Argo Workflows作为后端工作流程引擎，我将在下一节介绍它，我们将直接使用Argo Workflows而不是使用像KFP这样的高级包装器。ML元数据项目已合并到KFP中，并作为在KFP中编写的机器学习工作流程中产生的元数据的后端。
- en: Next is Katib ([https://github.com/kubeflow/katib](https://github.com/kubeflow/katib)).
    Katib is a Kubernetes-native project for automated machine learning. Katib supports
    hyperparameter tuning, early stopping, and neural architecture search. Katib is
    agnostic to machine learning frameworks. It can tune hyperparameters of applications
    written in any language of the users’ choice and natively supports many machine
    learning frameworks, such as TensorFlow, Apache MXNet, PyTorch, XGBoost, and others.
    Katib can perform training jobs using any Kubernetes custom resource with out-of-the-box
    support for Kubeflow Training Operator, Argo Workflows, Tekton Pipelines, and
    many more. Figure 8.4 is a screenshot of the Katib UI that performs experiment
    tracking.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是 Katib ([https://github.com/kubeflow/katib](https://github.com/kubeflow/katib))。Katib
    是一个针对自动化机器学习的 Kubernetes 原生项目。Katib 支持超参数调整、早期停止和神经架构搜索。Katib 对机器学习框架是中立的。它可以调整用户选择任何语言的任何应用程序的超参数，并原生支持许多机器学习框架，如
    TensorFlow、Apache MXNet、PyTorch、XGBoost 等。Katib 可以使用任何 Kubernetes 自定义资源执行训练作业，并自带对
    Kubeflow 训练操作员、Argo 工作流、Tekton 流水线等的支持。图 8.4 是执行实验跟踪的 Katib UI 的截图。
- en: '![08-04](../../OEBPS/Images/08-04.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![08-04](../../OEBPS/Images/08-04.png)'
- en: Figure 8.4 A screenshot of the Katib UI that performs experiment tracking
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 执行实验跟踪的 Katib UI 的截图
- en: KServe ([https://github.com/kserve/kserve](https://github.com/kserve/kserve))
    was born as part of the Kubeflow project and was previously known as KFServing.
    KServe provides a Kubernetes custom resource definition (CRD) for serving machine
    learning models on arbitrary frameworks. It aims to solve production model serving
    use cases by providing performant, high-abstraction interfaces for common ML frameworks.
    It encapsulates the complexity of autoscaling, networking, health checking, and
    server configuration to bring cutting-edge serving features like GPU autoscaling,
    scale to zero, and canary rollouts to your machine learning deployments. Figure
    8.5 is a diagram that illustrates the position of KServe in the ecosystem.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: KServe ([https://github.com/kserve/kserve](https://github.com/kserve/kserve))
    是作为 Kubeflow 项目的一部分诞生的，之前被称为 KFServing。KServe 为在任意框架上提供机器学习模型服务提供了 Kubernetes
    自定义资源定义 (CRD)。它旨在通过提供高性能、高抽象接口来解决生产模型服务用例，这些接口适用于常见的机器学习框架。它封装了自动缩放、网络、健康检查和服务器配置的复杂性，将前沿的服务功能如
    GPU 自动缩放、零扩展和金丝雀发布带到机器学习部署中。图 8.5 是一个说明 KServe 在生态系统中的位置的图。
- en: '![08-05](../../OEBPS/Images/08-05.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![08-05](../../OEBPS/Images/08-05.png)'
- en: Figure 8.5 KServe positioning in the ecosystem
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 KServe 在生态系统中的定位
- en: Kubeflow provides web UI. Figure 8.6 provides a screenshot of the UI. Users
    can access the models, pipelines, experiments, artifacts, etc. to facilitate the
    iterative process of the end-to-end model machine life cycle in each tab on the
    left side.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 提供了网页用户界面。图 8.6 展示了该界面的截图。用户可以通过左侧每个标签页访问模型、流水线、实验、工件等，以促进端到端模型机器生命周期迭代的便捷性。
- en: '![08-06](../../OEBPS/Images/08-06.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![08-06](../../OEBPS/Images/08-06.png)'
- en: Figure 8.6 A screenshot of the Kubeflow UI
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 Kubeflow UI 的截图
- en: The web UI is integrated with Jupyter Notebooks to be easily accessible. There
    are also SDKs in different languages to help users integrate with any internal
    systems. In addition, users can interact with all the Kubeflow components via
    kubectl since they are all native Kubernetes custom resources and controllers.
    The training operator ([https://github.com/kubeflow/training-operator](https://github.com/kubeflow/training-operator))
    provides Kubernetes custom resources that make it easy to run distributed or nondistributed
    TensorFlow, PyTorch, Apache MXNet, XGBoost, or MPI jobs on Kubernetes.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 网页用户界面与 Jupyter 笔记本集成，便于访问。还有不同语言的 SDK，以帮助用户与任何内部系统集成。此外，由于所有这些都是原生 Kubernetes
    自定义资源和控制器，用户可以通过 kubectl 与所有 Kubeflow 组件交互。训练操作员 ([https://github.com/kubeflow/training-operator](https://github.com/kubeflow/training-operator))
    提供了 Kubernetes 自定义资源，使得在 Kubernetes 上运行分布式或非分布式 TensorFlow、PyTorch、Apache MXNet、XGBoost
    或 MPI 作业变得容易。
- en: The Kubeflow project has accumulated more than 500 contributors and 20,000 GitHub
    stars. It’s heavily adopted in various companies and has more than 10 vendors,
    including Amazon AWS, Azure, Google Cloud, IBM, etc. Seven working groups maintain
    different subprojects independently. We will use the training operator to submit
    distributed model training jobs and KServe to build our model serving component.
    Once you complete the next chapter, I recommend trying out the other subprojects
    in the Kubeflow ecosystem on your own when needed. For example, if you’d like
    to tune the performance of the model, you can use Katib’s automated machine learning
    and hyperparameter tuning functionalities.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow项目已积累超过500位贡献者和20,000个GitHub星标。它在各种公司中得到广泛采用，拥有超过10个供应商，包括Amazon AWS、Azure、Google
    Cloud、IBM等。七个工作组独立维护不同的子项目。我们将使用训练操作员提交分布式模型训练作业，并使用KServe构建我们的模型服务组件。一旦你完成下一章，我建议在需要时尝试Kubeflow生态系统中的其他子项目。例如，如果你想调整模型的性能，你可以使用Katib的自动化机器学习和超参数调整功能。
- en: 8.3.1 The basics
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.1 基础知识
- en: Next, we’ll take a closer look at the distributed training operator of Kubeflow
    and submit a distributed model training job that runs locally in the Kubernetes
    local cluster we created in the previous section. Let’s first create and activate
    a dedicated kubeflow namespace for our examples and reuse the existing cluster
    we created earlier.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将更详细地了解Kubeflow的分布式训练操作员，并提交一个在上一节创建的Kubernetes本地集群中本地运行的分布式模型训练作业。让我们首先创建并激活一个专用的kubeflow命名空间用于我们的示例，并重用我们之前创建的现有集群。
- en: Listing 8.31 Creating and switching to a new namespace
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.31 创建并切换到新的命名空间
- en: '[PRE33]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Then, we must go back to our project folder and apply all the manifests to install
    all the tools we need.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须回到我们的项目文件夹，应用所有清单来安装我们需要的所有工具。
- en: Listing 8.32 Applying all manifests and installing all the tools
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.32 应用所有清单并安装所有工具
- en: '[PRE34]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Note that we’ve bundled all the necessary tools in this manifests folder:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们已将所有必要的工具打包在这个清单文件夹中：
- en: Kubeflow Training Operator, which we will use in this chapter for distributed
    model training.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将在本章中使用Kubeflow训练操作员进行分布式模型训练。
- en: Argo Workflows ([https://github.com/argoproj/argo-workflows](https://github.com/argoproj/argo-workflows)),
    which we address in chapter 9 when we discuss workflow orchestration and chain
    all the components together in a machine learning pipeline. We can ignore Argo
    Workflows for now.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Argo Workflows ([https://github.com/argoproj/argo-workflows](https://github.com/argoproj/argo-workflows))，我们将在第9章讨论工作流编排时提到，并将所有组件在一个机器学习管道中串联起来。现在我们可以忽略Argo
    Workflows。
- en: As introduced earlier, the Kubeflow Training Operator provides Kubernetes custom
    resources that make it easy to run distributed or nondistributed jobs on Kubernetes,
    including TensorFlow, PyTorch, Apache MXNet, XGBoost, MPI jobs, etc.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Kubeflow训练操作员提供了Kubernetes自定义资源，这使得在Kubernetes上运行分布式或非分布式作业变得容易，包括TensorFlow、PyTorch、Apache
    MXNet、XGBoost、MPI作业等。
- en: Before we dive into Kubeflow, we need to understand what *custom resources*
    are. A custom resource is an extension of the Kubernetes API not necessarily available
    in a default Kubernetes installation. It is a customization of a particular Kubernetes
    installation. However, many core Kubernetes functions are now built using custom
    resources, making Kubernetes more modular ([http://mng.bz/lWw2](http://mng.bz/lWw2)).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨Kubeflow之前，我们需要了解什么是*自定义资源*。自定义资源是Kubernetes API的扩展，不一定在默认的Kubernetes安装中可用。它是特定Kubernetes安装的定制化。然而，现在许多核心Kubernetes功能都是使用自定义资源构建的，这使得Kubernetes更加模块化([http://mng.bz/lWw2](http://mng.bz/lWw2))。
- en: Custom resources can appear and disappear in a running cluster through dynamic
    registration, and cluster admins can update custom resources independently of
    the cluster. Once a custom resource is installed, users can create and access
    its objects using kubectl, just as they do for built-in resources like Pods. For
    example, the following listing defines the TFJob custom resource that allows us
    to instantiate and submit a distributed TensorFlow training job to the Kubernetes
    cluster.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义资源可以通过动态注册在运行中的集群中出现和消失，集群管理员可以独立于集群更新自定义资源。一旦安装了自定义资源，用户就可以使用kubectl创建和访问其对象，就像它们对内置资源（如Pods）所做的那样。例如，以下列表定义了TFJob自定义资源，它允许我们实例化和提交一个分布式TensorFlow训练作业到Kubernetes集群。
- en: Listing 8.33 TFJob CRD
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.33 TFJob CRD
- en: '[PRE35]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: All instantiated TFJob custom resource objects (tfjobs) will be handled by the
    training operator. The following listing provides the definition of the deployment
    of the training operator that runs a stateful controller to continuously monitor
    and process any submitted tfjobs.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 所有实例化的TFJob自定义资源对象（tfjobs）将由训练操作员处理。以下列表提供了运行状态控制器以持续监控和处理任何提交的tfjobs的训练操作员的部署定义。
- en: Listing 8.34 Training operator deployment
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.34 训练操作员部署
- en: '[PRE36]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: With this abstraction, data science teams can focus on writing the Python code
    in TensorFlow that will be used as part of a TFJob specification and don’t have
    to manage the infrastructure themselves. For now, we can skip the low-level details
    and use TFJob to implement our distributed model training. Next, let’s define
    our TFJob in a file named tfjob.yaml.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种抽象，数据科学团队能够专注于编写将作为TFJob规范一部分使用的TensorFlow Python代码，而无需自己管理基础设施。目前，我们可以跳过底层细节，使用TFJob来实现我们的分布式模型训练。接下来，让我们在名为tfjob.yaml的文件中定义我们的TFJob。
- en: Listing 8.35 An example TFJob definition
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.35 TFJob定义示例
- en: '[PRE37]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In this spec, we are asking the controller to submit a distributed TensorFlow
    model training model with two worker replicas where each worker replica follows
    the same container definition, running the MNIST image classification example.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个规范中，我们要求控制器提交一个具有两个工作副本的分布式TensorFlow模型训练模型，每个工作副本遵循相同的容器定义，运行MNIST图像分类示例。
- en: Once it’s defined, we can submit it to our local Kubernetes cluster via the
    following listing.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义，我们就可以通过以下列表将其提交到我们的本地Kubernetes集群。
- en: Listing 8.36 Submitting TFJob
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.36 提交TFJob
- en: '[PRE38]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We can see whether the TFJob has been submitted successfully by getting the
    TFJob list.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过获取TFJob列表来查看TFJob是否已成功提交。
- en: Listing 8.37 Getting the TFJob list
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.37 获取TFJob列表
- en: '[PRE39]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: When we get the list of Pods, we can see two worker Pods, distributed-tfjob-qc8fh-worker-1
    and distributed-tfjob-qc8fh-worker-0, have been created and started running. The
    other Pods can be ignored since they are the Pods that are running the Kubeflow
    and Argo Workflow operators.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们获取Pod列表时，我们可以看到已经创建了两个工作Pod，分别是distributed-tfjob-qc8fh-worker-1和distributed-tfjob-qc8fh-worker-0，并且已经开始运行。其他Pod可以忽略，因为它们是运行Kubeflow和Argo
    Workflow操作员的Pod。
- en: Listing 8.38 Getting the list of Pods
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.38 获取Pod列表
- en: '[PRE40]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: A machine learning system consists of many different components. We only used
    Kubeflow to submit distributed model training jobs, but it’s not connected to
    other components yet. In the next section, we’ll explore the basic functionalities
    of Argo Workflows to connect different steps in a single workflow so that they
    can be executed in a particular order.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统由许多不同的组件组成。我们只使用了Kubeflow来提交分布式模型训练作业，但尚未与其他组件连接。在下一节中，我们将探讨Argo Workflows的基本功能，以便将单个工作流中的不同步骤连接起来，以便它们可以按特定顺序执行。
- en: 8.3.2 Exercises
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.2 练习
- en: If your model training requires parameter servers, can you express that in a
    TFJob?
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您的模型训练需要参数服务器，您能否在TFJob中表达这一点？
- en: '8.4 Argo Workflows: Container-native workflow engine'
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 Argo Workflows：容器原生工作流引擎
- en: 'The Argo Project is a suite of open-source tools for deploying and running
    applications and workloads on Kubernetes. It extends the Kubernetes APIs and unlocks
    new and powerful capabilities in application deployment, container orchestration,
    event automation, progressive delivery, and more. It consists of four core projects:
    Argo CD, Argo Rollouts, Argo Events, and Argo Workflows. Besides these core projects,
    many other ecosystem projects are based on, extend, or work well with Argo. A
    complete list of resources related to Argo can be found at [https://github.com/terrytangyuan/awesome-argo](https://github.com/terrytangyuan/awesome-argo).'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Argo项目是一套开源工具，用于在Kubernetes上部署和运行应用程序和工作负载。它扩展了Kubernetes API，并为应用程序部署、容器编排、事件自动化、渐进式交付等解锁了新的强大功能。它包括四个核心项目：Argo
    CD、Argo Rollouts、Argo Events和Argo Workflows。除了这些核心项目之外，许多其他生态系统项目都是基于、扩展或与Argo兼容的。有关Argo的完整资源列表可以在[https://github.com/terrytangyuan/awesome-argo](https://github.com/terrytangyuan/awesome-argo)找到。
- en: Argo CD is a declarative, GitOps application delivery tool for Kubernetes. It
    manages application definitions, configurations, and environments declaratively
    in Git. Argo CD user experience makes Kubernetes application deployment and life-cycle
    management automated, auditable, and easy to grasp. It comes with a UI so engineers
    can see what’s happening in their clusters and watch for applications deployments,
    etc. Figure 8.7 is a screenshot of the resource tree in the Argo CD UI.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Argo CD是一个用于Kubernetes的声明式GitOps应用程序交付工具。它在Git中以声明方式管理应用程序定义、配置和环境。Argo CD的用户体验使得Kubernetes应用程序部署和生命周期管理自动化、可审计且易于理解。它附带了一个UI，工程师可以通过它查看其集群中的情况，并监视应用程序部署等。图8.7是Argo
    CD UI中资源树的截图。
- en: '![08-07](../../OEBPS/Images/08-07.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![08-07](../../OEBPS/Images/08-07.png)'
- en: Figure 8.7 A screenshot of the resources tree in Argo CD UI
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 Argo CD UI中的资源树截图
- en: Argo Rollouts is a Kubernetes controller and set of CRDs that provides progressive
    deployment capabilities. It introduces blue-green and canary deployments, canary
    analysis, experimentation, and progressive delivery features to your Kubernetes
    cluster.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Argo Rollouts是一个Kubernetes控制器和一组CRDs，它提供了渐进式部署功能。它引入了蓝绿和金丝雀部署、金丝雀分析、实验和渐进式交付功能到您的Kubernetes集群中。
- en: Next is Argo Events. It’s an event-based dependency manager for Kubernetes.
    It can define multiple dependencies from various event sources like webhooks,
    Amazon S3, schedules, and streams and trigger Kubernetes objects after successful
    event dependencies resolution. A complete list of available event sources can
    be found in figure 8.8.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是Argo Events。它是一个基于事件的Kubernetes依赖管理器。它可以定义来自各种事件源（如webhooks、Amazon S3、计划和时间流）的多个依赖关系，并在成功解决事件依赖关系后触发Kubernetes对象。可用的完整事件源列表可以在图8.8中找到。
- en: '![08-08](../../OEBPS/Images/08-08.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![08-08](../../OEBPS/Images/08-08.png)'
- en: Figure 8.8 Available event sources in Argo Events
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8 Argo Events中可用的事件源
- en: Finally, Argo Workflows is a container-native workflow engine for orchestrating
    parallel jobs, implemented as Kubernetes CRD. Users can define workflows where
    each step is a separate container, model multistep workflows as a sequence of
    tasks or capture the dependencies between tasks using a graph, and run compute-intensive
    jobs for machine learning or data processing. Users often use Argo Workflows together
    with Argo Events to trigger event-based workflows. The main use cases for Argo
    Workflows are machine learning pipelines, data processing, ETL (extract, transform,
    load), infrastructure automation, continuous delivery, and integration.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Argo Workflows是一个用于编排并行作业的容器原生工作流引擎，作为Kubernetes CRD实现。用户可以定义工作流，其中每个步骤都是一个独立的容器，将多步骤工作流建模为任务序列，或使用图来捕获任务之间的依赖关系，并运行用于机器学习或数据处理的高计算量作业。用户通常将Argo
    Workflows与Argo Events一起使用，以触发基于事件的 workflows。Argo Workflows的主要用例包括机器学习管道、数据处理、ETL（提取、转换、加载）、基础设施自动化、持续交付和集成。
- en: Argo Workflows also provides interfaces such as a command-line interface (CLI),
    server, UI, and SDKs for different languages. The CLI is useful for managing workflows
    and performing operations such as submitting, suspending, and deleting workflows
    through the command line. The server is used for integrating with other services.
    There are both REST and gRPC service interfaces. The UI is useful for managing
    and visualizing workflows and any artifacts/logs created by the workflows, as
    well as other useful information, such as resource usage analytics. We will walk
    through some examples of Argo Workflows to prepare for our project.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Argo Workflows还提供了命令行界面（CLI）、服务器、UI和不同语言的SDK等接口。CLI用于通过命令行管理工作流和执行提交、暂停和删除工作流等操作。服务器用于与其他服务集成。存在REST和gRPC服务接口。UI用于管理和可视化工作流以及工作流创建的任何工件/日志，以及其他有用的信息，例如资源使用分析。我们将通过一些Argo
    Workflows的示例来准备我们的项目。
- en: 8.4.1 The basics
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.1 基础知识
- en: Before we look at some examples, let’s make sure we have the Argo Workflows
    UI at hand. It’s optional since you can still be successful in these examples
    in the command line to interact directly with Kubernetes via kubectl, but it’s
    nice to see the directed-acyclic graph (DAG) visualizations in the UI as well
    as access additional functionalities. By default, the Argo Workflows UI service
    is not exposed to an external IP. To access the UI, use the method in the following
    listing.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看一些示例之前，让我们确保我们手头有 Argo Workflows UI。这是可选的，因为您仍然可以通过命令行直接使用 kubectl 与 Kubernetes
    交互来在这些示例中成功，但看到 UI 中的有向无环图 (DAG) 可视化以及访问其他功能也很不错。默认情况下，Argo Workflows UI 服务未公开到外部
    IP。要访问 UI，请使用以下列表中的方法。
- en: Listing 8.39 Port-forwarding the Argo server
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.39 Argo 服务器端口转发
- en: '[PRE41]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Next, visit the following URL to access the UI: https:/ /localhost:2746\. Alternatively,
    you can expose a load balancer to get an external IP to access the Argo Workflows
    UI in your local cluster. Check out the official documentation for more details:
    [https://argoproj.github.io/argo-workflows/argo-server/](https://argoproj.github.io/argo-workflows/argo-server/).
    Figure 8.9 is a screenshot of what the Argo Workflows UI looks like for a map-reduce-style
    workflow.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，访问以下 URL 以访问 UI：https://localhost:2746。或者，您可以将负载均衡器公开以获取外部 IP，以便在本地集群中访问
    Argo Workflows UI。有关更多详细信息，请参阅官方文档：[https://argoproj.github.io/argo-workflows/argo-server/](https://argoproj.github.io/argo-workflows/argo-server/)。图
    8.9 是 Argo Workflows UI 的截图，展示了类似 map-reduce 的工作流程。
- en: '![08-09](../../OEBPS/Images/08-09.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![08-09](../../OEBPS/Images/08-09.png)'
- en: Figure 8.9 Argo Workflows UI illustrating a map-reduce-style workflow
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.9 展示类似 map-reduce 风格工作流程的 Argo Workflows UI
- en: The following listing is a basic “hello world” example of Argo Workflows. We
    can specify the container image and the command to run for this workflow and print
    out a “hello world” message.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表是 Argo Workflows 的基本“hello world”示例。我们可以指定此工作流程的容器镜像和要运行的命令，并打印出“hello world”消息。
- en: Listing 8.40 “Hello world” example
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.40 “Hello world” 示例
- en: '[PRE42]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Let’s go ahead and submit the workflow to our cluster.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续将工作流程提交到我们的集群。
- en: Listing 8.41 Submitting the workflow
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.41 提交工作流程
- en: '[PRE43]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We can then check whether it was submitted successfully and has started running.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以检查它是否已成功提交并开始运行。
- en: Listing 8.42 Getting the list of workflows
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.42 获取工作流程列表
- en: '[PRE44]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Once the workflow status has changed to Succeeded, we can check the statuses
    of the Pods created by the workflow. First, let’s find all the Pods associated
    with the workflow. We can use a label selector to get the list of Pods.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦工作流程状态变为成功，我们就可以检查由工作流程创建的 Pod 的状态。首先，让我们找到与工作流程相关联的所有 Pod。我们可以使用标签选择器来获取
    Pod 列表。
- en: Listing 8.43 Getting the list of Pods belonging to this workflow
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.43 获取属于此工作流程的 Pod 列表
- en: '[PRE45]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Once we know the Pod name, we can get the logs of that Pod.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们知道 Pod 名称，我们就可以获取该 Pod 的日志。
- en: Listing 8.44 Checking the Pod logs
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.44 检查 Pod 日志
- en: '[PRE46]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: As expected, we get the same logs as the ones we had with the simple Kubernetes
    Pod in the previous sections since this workflow only runs one “hello world” step.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，我们得到了与之前章节中简单的 Kubernetes Pod 相同的日志，因为此工作流程只运行了一个“hello world”步骤。
- en: The next example uses a resource template where you can specify a Kubernetes
    custom resource that will be submitted by the workflow to the Kubernetes cluster.
    Here we create a Kubernetes config map named cm-example with a simple key-value
    pair. The config map is a Kubernetes-native object to store key-value pairs.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例使用资源模板，您可以在其中指定工作流程将提交给 Kubernetes 集群的 Kubernetes 自定义资源。在这里，我们创建了一个名为 cm-example
    的 Kubernetes 配置映射，其中包含一个简单的键值对。配置映射是 Kubernetes 原生对象，用于存储键值对。
- en: Listing 8.45 Resource template
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.45 资源模板
- en: '[PRE47]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This example is perhaps most useful to Python users. You can write a Python
    script as part of the template definition. We can generate some random numbers
    using the built-in random Python module. Alternatively, you can specify the execution
    logic of the script inside a container template without writing inline Python
    code, as seen in the “hello world” example.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例对 Python 用户可能最有用。您可以将 Python 脚本作为模板定义的一部分来编写。我们可以使用内置的 Python 随机模块生成一些随机数。或者，您可以在容器模板内部指定脚本的执行逻辑，而不需要编写内联
    Python 代码，就像在“hello world”示例中看到的那样。
- en: Listing 8.46 Script template
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.46 脚本模板
- en: '[PRE48]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Let’s submit it.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们提交它。
- en: Listing 8.47 Submitting the script template workflow
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.47 提交脚本模板工作流程
- en: '[PRE49]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Now, let’s check its logs to see whether a random number was generated.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查其日志以查看是否生成了一个随机数。
- en: Listing 8.48 Check the Pod logs
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.48 检查 Pod 日志
- en: '[PRE50]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: So far, we’ve only seen examples of single-step workflows. Argo Workflow also
    allows users to define the workflow as a DAG by specifying the dependencies of
    each task. The DAG can be simpler to maintain for complex workflows and allows
    maximum parallelism when running tasks.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只看到了单步工作流的示例。Argo Workflow 还允许用户通过指定每个任务的依赖关系来定义工作流为一个 DAG。对于复杂的工作流，DAG
    可以更容易地维护，并且在运行任务时允许最大并行性。
- en: Let’s look at an example of a diamond-shaped DAG created by Argo Workflows.
    This DAG consists of four steps (A, B, C, and D), and each has its own dependencies.
    For example, step C depends on step A, and step D depends on steps B and C.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 Argo Workflows 创建的菱形 DAG 的一个示例。这个 DAG 由四个步骤（A、B、C 和 D）组成，每个步骤都有自己的依赖关系。例如，步骤
    C 依赖于步骤 A，步骤 D 依赖于步骤 B 和 C。
- en: Listing 8.49 A diamond example using DAG
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.49 使用 DAG 的菱形示例
- en: '[PRE51]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Let’s submit it.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们提交它。
- en: Listing 8.50 Submitting the DAG workflow
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.50 提交 DAG 工作流
- en: '[PRE52]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: When the workflow is completed, we will see four Pods for each of the steps
    where each step prints out its step name—A, B, C, and D.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 当工作流完成时，我们将看到每个步骤都有四个 Pod，每个步骤都会打印出其步骤名称——A、B、C 和 D。
- en: Listing 8.51 Getting the list of Pods belonging to this workflow
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.51 获取属于此工作流的 Pod 列表
- en: '[PRE53]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The visualization of the DAG is available in the Argo Workflows UI. It’s usually
    more intuitive to see how the workflow is executed in a diamond-shaped flow in
    the UI, as seen in figure 8.10.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: DAG 的可视化可在 Argo Workflows UI 中查看。在 UI 中，通常更直观地看到工作流是如何以菱形流程执行，如图 8.10 所示。
- en: '![08-10](../../OEBPS/Images/08-10.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![08-10](../../OEBPS/Images/08-10.png)'
- en: Figure 8.10 A screenshot of a diamond-shaped workflow in the UI
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.10 UI 中菱形工作流的截图
- en: Next, we will look at a simple coin-flip example to showcase the conditional
    syntax provided by Argo Workflows. We can specify a condition to indicate whether
    we want to run the next step. For example, we run the flip-coin step first, which
    is the Python script we saw earlier, and if the result returns heads, we run the
    template called heads, which prints another log saying it was heads. Otherwise,
    we print that it was tails. So we can specify these conditionals inside the when
    clause in the different steps.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看一个简单的硬币翻转示例，以展示 Argo Workflows 提供的条件语法。我们可以指定一个条件来指示我们是否要运行下一个步骤。例如，我们首先运行
    flip-coin 步骤，这是我们之前看到的 Python 脚本，如果结果返回正面，我们运行名为 heads 的模板，它打印出另一个日志说它是正面。否则，我们打印出它是反面。因此，我们可以在不同步骤的
    when 子句中指定这些条件。
- en: Listing 8.52 Coin-flip example
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.52 硬币翻转示例
- en: '[PRE54]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Let’s submit the workflow.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们提交工作流。
- en: Listing 8.53 Submitting the coin-flip example
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.53 提交硬币翻转示例
- en: '[PRE55]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Figure 8.11 is a screenshot of what this flip-coin workflow looks like in the
    UI.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11 是 UI 中 flip-coin 工作流的外观截图。
- en: '![08-11](../../OEBPS/Images/08-11.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![08-11](../../OEBPS/Images/08-11.png)'
- en: Figure 8.11 Screenshot of the flip-coin workflow in the UI
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.11 UI 中 flip-coin 工作流的截图
- en: When we get the list of workflows, we find only two Pods.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们获取工作流列表时，我们发现只有两个 Pod。
- en: Listing 8.54 Getting the list of Pods belonging to this workflow
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.54 获取属于此工作流的 Pod 列表
- en: '[PRE56]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We can check the logs of the flip-coin step to see whether it prints out tails
    since the next step executed is the tails step:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查 flip-coin 步骤的日志，以查看它是否打印出反面，因为接下来执行的是反面步骤：
- en: '[PRE57]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: That’s a wrap! We’ve just learned the basic syntax of Argo Workflows, which
    should cover all the prerequisites for the next chapter! In the next chapter,
    we will use Argo Workflows to implement the end-to-end machine learning workflow
    that consists of the actual system components introduced in chapter 7\.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们刚刚学习了 Argo Workflows 的基本语法，这应该涵盖了下一章的所有先决条件！在下一章中，我们将使用 Argo Workflows
    来实现由第 7 章中介绍的真正系统组件组成的端到端机器学习工作流。
- en: 8.4.2 Exercises
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.2 练习
- en: Besides accessing the output of each step like {{steps.flip-coin.outputs .result}},
    what are other available variables?
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了像 {{steps.flip-coin.outputs .result}} 这样访问每个步骤的输出之外，还有哪些其他可用的变量？
- en: Can you trigger workflows automatically by Git commits or other events?
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过 Git 提交或其他事件自动触发工作流吗？
- en: 8.5 Answers to exercises
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 练习答案
- en: Section 8.1
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 8.1 节
- en: Yes, via model = tf.keras.models.load_model('my_model.h5'); modele .evaluate(x_test,
    y_test)
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是的，通过 model = tf.keras.models.load_model('my_model.h5'); modele .evaluate(x_test,
    y_test)
- en: You should be able to do it easily by changing the tuner to kt.RandomSearch
    (model_builder).
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该可以通过将调谐器更改为 kt.RandomSearch (model_builder) 来轻松完成它。
- en: Section 8.2
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 8.2 节
- en: kubectl get pod <pod-name> -o json
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: kubectl get pod <pod-name> -o json
- en: Yes, you can define additional containers in the pod.spec.containers in addition
    to the existing single container.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是的，你可以在pod.spec.containers中定义额外的容器，除了现有的单个容器。
- en: Section 8.3
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第8.3节
- en: Similar to worker replicas, define parameterServer replicas in your TFJob spec
    to specify the number of parameter servers.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与工作副本类似，在你的TFJob规范中定义parameterServer副本以指定参数服务器数量。
- en: Section 8.4
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第8.4节
- en: 'The complete list is available here: [http://mng.bz/d1Do](http://mng.bz/d1Do).'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完整的列表在此处可用：[http://mng.bz/d1Do](http://mng.bz/d1Do)。
- en: Yes, you can use Argo Events to watch Git events and trigger workflows.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是的，你可以使用Argo Events来监视Git事件并触发工作流。
- en: Summary
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: We used TensorFlow to train a machine learning model for the MNIST dataset in
    a single machine.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用TensorFlow在单台机器上训练了MNIST数据集的机器学习模型。
- en: We learned the basic concepts in Kubernetes and gained hands-on experience by
    implementing them in a local Kubernetes cluster.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们学习了Kubernetes的基本概念，并通过在本地Kubernetes集群中实施它们来获得实践经验。
- en: We submitted distributed model training jobs to Kubernetes via Kubeflow.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过Kubeflow将分布式模型训练作业提交到Kubernetes。
- en: We learned about different types of templates and how to define either DAGs
    or sequential steps using Argo Workflows.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们学习了不同类型的模板以及如何使用Argo Workflows定义DAGs或顺序步骤。
