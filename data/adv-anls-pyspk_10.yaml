- en: Chapter 10\. Image Similarity Detection with Deep Learning and PySpark LSH
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章。使用深度学习和PySpark LSH进行图像相似度检测
- en: Whether you encounter them on social media or e-commerce stores, images are
    integral to our digital lives. In fact, it was an image dataset—ImageNet—which
    was a key component for sparking the current deep learning revolution. A remarkable
    performance by a classification model in the ImageNet 2012 challenge was an important
    milestone and led to widespread attention. It is no wonder then that you are likely
    to encounter image data at some point as a data science practitioner.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是在社交媒体还是电子商务平台上遇到它们，图像都是我们数字生活中不可或缺的一部分。事实上，正是一个图像数据集——ImageNet——成为引发当前深度学习革命的关键组成部分。在ImageNet
    2012挑战中，分类模型的显著表现是一个重要的里程碑，引起了广泛关注。因此，作为数据科学从业者，您很可能会在某个时候遇到图像数据。
- en: In this chapter, you will gain experience scaling a deep learning workflow for
    a visual task, namely, image similarity detection, with PySpark. The task of identifying
    images that are similar to each other comes intuitively to humans, but it is a
    complex computational task. At scale, it becomes even more difficult. In this
    chapter, we will introduce an approximate method for finding similar items called
    locality sensitive hashing, or LSH, and apply it to images. We’ll use deep learning
    to convert image data into a numerical vector representation. PySpark’s LSH algorithm
    will be applied to the resulting vectors, which will allow us to find similar
    images given a new input image.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将获得扩展深度学习工作流程的经验，特别是使用PySpark进行图像相似度检测的视觉任务。识别相似图像的任务对人类来说很直观，但是在计算上是一个复杂的任务。在大规模上，这变得更加困难。在本章中，我们将介绍一种用于寻找相似项的近似方法，称为局部敏感哈希（LSH），并将其应用于图像。我们将使用深度学习将图像数据转换为数值向量表示。然后，将PySpark的LSH算法应用于生成的向量，这将允许我们在给定新输入图像的情况下找到相似的图像。
- en: On a high level, this example mirrors one of the approaches used by photo sharing
    apps such as Instagram and Pinterest for image similarity detection. This helps
    their users make sense of the deluge of visual data that exists on their platforms.
    This also depicts how a deep learning workflow can benefit from PySpark’s scalability.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，这个示例反映了类似于Instagram和Pinterest等照片分享应用程序用于图像相似度检测的方法之一。这有助于他们的用户理解其平台上存在的大量视觉数据。这也展示了深度学习工作流如何从PySpark的可伸缩性中受益。
- en: We’ll start by briefly introducing PyTorch, a deep learning framework. It has
    gained prominence in recent years for its relatively easier learning curve compared
    to other major low-level deep learning libraries. Then we’ll download and prepare
    our dataset. The dataset being used for our task is the Cars dataset released
    in 2013 by Stanford AI Lab. PyTorch will be used for image preprocessing. This
    will be followed by conversion of our input image data into a vector representation
    (image embeddings). We’ll then import the resulting embeddings into PySpark and
    transform them using the LSH algorithm. We’ll finish up by taking a new image
    and performing a nearest neighbors search using our LSH-transformed dataset to
    find similar images.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将先简要介绍PyTorch，它是一个深度学习框架。与其他主要低级深度学习库相比，PyTorch因其相对较低的学习曲线而在近年来广受欢迎。然后，我们将下载并准备我们的数据集。用于我们任务的数据集是由斯坦福AI实验室在2013年发布的汽车数据集。PyTorch将用于图像预处理。接下来，我们将把我们的输入图像数据转换为向量表示（图像嵌入）。然后，我们将这些嵌入导入PySpark并使用LSH算法进行转换。最后，我们将使用LSH转换后的数据集对新图像进行最近邻搜索，以找到相似的图像。
- en: Let’s start by introducing and setting up PyTorch.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始介绍并设置PyTorch。
- en: PyTorch
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch
- en: PyTorch is a library for building deep learning projects. It emphasizes flexibility
    and allows deep learning models to be expressed in idiomatic Python. It found
    early adopters in the research community. Recently, it has grown into one of the
    most prominent deep learning tools across a broad range of applications due to
    its ease of use. Along with TensorFlow, it is the most popular library for deep
    learning as of now.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是一个用于构建深度学习项目的库。它强调灵活性，允许用Python的惯用方式表达深度学习模型。它在研究社区中找到了早期的采用者。近年来，由于其易用性，它已成为广泛应用于各种应用领域的最重要的深度学习工具之一。与TensorFlow一起，它是目前最流行的深度学习库之一。
- en: PyTorch’s simple and flexible interface enables fast experimentation. You can
    load data, apply transforms, and build models with a few lines of code. Then,
    you have the flexibility to write customized training, validation, and test loops
    and deploy trained models with ease. It is consistently being used in professional
    contexts for real-world, mission-critical work. Being able to use GPUs (graphical
    processing units) for training resource-intensive models has been a big factor
    for making deep learning popular. PyTorch provides great GPU support, although
    we won’t need that for our task.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的简单和灵活接口支持快速实验。你可以加载数据、应用变换和构建模型只需几行代码。然后，你可以灵活编写定制的训练、验证和测试循环，并轻松部署训练好的模型。它在专业环境中用于真实世界的关键工作中被广泛使用。GPU（图形处理单元）对于训练资源密集型模型的支持是使深度学习流行的重要因素。虽然我们的任务中不需要，但PyTorch提供了很好的GPU支持。
- en: Installation
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装
- en: On the [PyTorch website](https://oreil.ly/CHkJo), you can easily obtain the
    installation instructions based on your system configuration, as shown in [Figure 10-1](#pytorch_installation_cpu_support).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在[PyTorch网站](https://oreil.ly/CHkJo)上，你可以根据你的系统配置轻松获取安装说明，如[图10-1](#pytorch_installation_cpu_support)所示。
- en: '![PyTorch installation CPU support](assets/aaps_1001.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![PyTorch安装CPU支持](assets/aaps_1001.png)'
- en: Figure 10-1\. PyTorch installation, CPU support
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-1\. PyTorch安装，CPU支持
- en: 'Execute the provided command and follow the instructions for your configuration:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 执行提供的命令，并按照你的配置说明操作：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We will not be relying on a GPU and, hence, will choose CPU as a compute platform.
    If you have a GPU setup that you want to use, choose options accordingly to obtain
    the required instructions. We will not be needing Torchaudio for this chapter
    either, so we skip its installation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会依赖GPU，因此将选择CPU作为计算平台。如果你有一个GPU设置并希望使用它，请选择相应的选项获取所需的说明。本章中我们也不需要Torchaudio，因此跳过它的安装。
- en: Preparing the Data
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: We will be using the [Stanford Cars dataset](https://oreil.ly/gxo8Q). It was
    released as part of the ICCV 2013 paper “3D Object Representations for Fine-Grained
    Categorization” by Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用[斯坦福汽车数据集](https://oreil.ly/gxo8Q)。该数据集是由Jonathan Krause、Michael Stark、Jia
    Deng和李飞飞在ICCV 2013年论文“用于细粒度分类的三维物体表示”中发布的。
- en: You can download the images from Kaggle or using the source link provided by
    Stanford AI Lab.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从Kaggle下载图片，或者使用斯坦福人工智能实验室提供的源链接。
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once it’s downloaded, unzip the train and test image directories and place
    them in a directory called *cars_data*:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完成后，解压训练和测试图像目录，并将它们放在一个名为*cars_data*的目录中：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can get a CSV file containing labels for the training dataset [here](https://oreil.ly/UoHXh).
    Download it, rename it to *cars_train_data.csv*, and place it in the data directory.
    Let’s have a look at it:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里获取包含训练数据标签的CSV文件[here](https://oreil.ly/UoHXh)。下载它，重命名为*cars_train_data.csv*，并将其放在数据目录中。让我们看一下它：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Ignore all columns other than `Class` and `image`. The other columns are related
    to the original research project that this dataset was derived from and will not
    be used for our task.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略除了`Class`和`image`之外的所有列。其他列与这个数据集来源的原始研究项目相关，不会用于我们的任务。
- en: Resizing Images Using PyTorch
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用PyTorch调整图像大小
- en: Before we head further, we’ll need to preprocess our images. Preprocessing data
    is very common in machine learning since deep learning models (neural networks)
    expect the input to meet certain requirements.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进一步之前，我们需要预处理我们的图像。在机器学习中，预处理数据非常常见，因为深度学习模型（神经网络）期望输入满足特定的要求。
- en: 'We need to apply a series of preprocessing steps, called *transforms*, to convert
    input images into the proper format for the models. In our case, we need them
    to be 224 x 224-pixel JPEG-formatted images, since that is a requirement for the
    ResNet-18 model that we’ll use in the next section. We perform this transformation
    using PyTorch’s Torchvision package in the following code:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要应用一系列预处理步骤，称为*transforms*，将输入图片转换为模型所需的正确格式。在我们的情况下，我们需要它们是224 x 224像素的JPEG格式图片，因为这是我们接下来将使用的ResNet-18模型的要求。我们使用PyTorch的Torchvision包在下面的代码中执行这个转换：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here we use a single transformation that resizes the image to fit within the
    neural networks. However, we can use the `Compose` transform to define a series
    of transforms used to preprocess our image too.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们使用一个单一的转换，将图像调整大小以适应神经网络。但是，我们也可以使用`Compose`变换来定义一系列用于预处理图像的变换。
- en: Our dataset is in place now. In the next section, we will convert our image
    data into a vector representation fit for use with PySpark’s LSH algorithm.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集现在已准备就绪。在下一节中，我们将把我们的图像数据转换为适合与PySpark的LSH算法一起使用的向量表示形式。
- en: Deep Learning Model for Vector Representation of Images
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于图像向量表示的深度学习模型
- en: Convolutional neural networks, or CNNs, are the standard neural network architectures
    used for prediction when the input observations are images. We won’t be using
    them for any prediction task but rather for generating a vector representation
    of images. Specifically, we will use the ResNet-18 architecture.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络，即CNN，是用于预测的标准神经网络架构，当输入观察数据是图像时使用。我们不会将它们用于任何预测任务，而是用于生成图像的向量表示。具体来说，我们将使用ResNet-18架构。
- en: Residual Network (ResNet) was introduced by Shaoqing Ren, Kaiming He, Jian Sun,
    and Xiangyu Zhang in their 2015 paper “Deep Residual Learning for Image Recognition.”
    The 18 in ResNet-18 stands for the number of layers that exist in the neural network
    architecture. Other popular variants of ResNet include 34 and 50 layers. A larger
    number of layers results in improved performance at the cost of increased computation.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Residual Network（ResNet）是由Shaoqing Ren、Kaiming He、Jian Sun和Xiangyu Zhang在他们2015年的论文“Deep
    Residual Learning for Image Recognition”中引入的。ResNet-18中的18代表神经网络架构中存在的层数。ResNet的其他流行变体包括34层和50层。层数增加会提高性能，但也会增加计算成本。
- en: Image Embeddings
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像嵌入
- en: An *image embedding* is a representation of an image in a vector space. The
    basic idea is that if a given image is close to another image, their embedding
    will also be similar and close in the spatial dimension.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*图像嵌入*是图像在向量空间中的表示。基本思想是，如果给定图像接近另一张图像，它们的嵌入也将在空间维度上相似且接近。'
- en: The image in [Figure 10-2](#ILSVRC_2012), [released by Andrej Karpathy](https://oreil.ly/YRhhT),
    shows how images can be represented in a lower dimensional space. As an example,
    you can notice vehicles near the top and birds in the bottom-left space.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图像中的[图10-2](#ILSVRC_2012)，由Andrej Karpathy发布，展示了如何在较低维度空间中表示图像。例如，您可以注意到顶部附近的车辆和左下角的鸟类空间。
- en: '![ILSVRC 2012 image embeddings in a 2-D space](assets/aaps_1002.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![ILSVRC 2012年图像嵌入在2维空间](assets/aaps_1002.png)'
- en: Figure 10-2\. ILSVRC 2012 image embeddings in a 2-D space
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-2。ILSVRC 2012年图像嵌入在2维空间中
- en: We can obtain image embeddings from ResNet-18 by taking the output of its second-to-last,
    fully connected layer, which has a dimension of 512\. Next, we create a class
    that, provided an image, can return its numeric vector form representation.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过取其倒数第二个全连接层的输出来从ResNet-18中获得图像嵌入，该层的维度为512。接下来，我们创建一个类，提供一张图像，即可返回其数值向量形式的表示。
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_image_similarity_detection_with___span_class__keep_together__deep_learning__span__and_pyspark_lsh_CO1-1)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_image_similarity_detection_with___span_class__keep_together__deep_learning__span__and_pyspark_lsh_CO1-1)'
- en: Convert images into the PyTorch tensor format.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像转换为PyTorch张量格式。
- en: '[![2](assets/2.png)](#co_image_similarity_detection_with___span_class__keep_together__deep_learning__span__and_pyspark_lsh_CO1-2)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_image_similarity_detection_with___span_class__keep_together__deep_learning__span__and_pyspark_lsh_CO1-2)'
- en: Rescale the range of pixel values between 0 and 1\. The values for the mean
    and standard deviation (std) were precomputed based on the data used to train
    the model. Normalizing the image improves the accuracy of the classifier.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将像素值范围重新缩放到0到1之间。均值和标准差（std）的值是基于用于训练模型的数据预先计算的。归一化图像可以提高分类器的准确性。
- en: We now initialize the `Img2VecResnet18` class and apply the `getVec` method
    to all of the images to obtain their image embeddings.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们初始化`Img2VecResnet18`类，并对所有图像应用`getVec`方法，以获得它们的图像嵌入。
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For a larger dataset, you may want to sequentially write the vector output
    to a file rather than keeping it in memory to avoid an out-of-memory error. The
    data is manageable here, so we create a dictionary, which we save as a CSV file
    in the next step:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较大的数据集，您可能希望将向量输出顺序写入文件，而不是将其保留在内存中，以避免内存不足错误。这里的数据是可管理的，因此我们创建一个字典，并在下一步将其保存为CSV文件：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Since we are working locally, we went with the CSV format for saving the vector
    output. However, Parquet format is more appropriate for data of this nature. You
    could easily save the data in Parquet format by replacing `to_csv` with `to_parquet`
    in the previous code.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们是在本地工作，所以选择了CSV格式来保存向量输出。但是，Parquet格式更适合这种类型的数据。您可以通过在先前的代码中用`to_parquet`替换`to_csv`来轻松保存Parquet格式的数据。
- en: Now that we have the required image embeddings, we can import them into PySpark.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了所需的图像嵌入，可以将它们导入 PySpark 中。
- en: Import Image Embeddings into PySpark
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入图像嵌入到 PySpark
- en: 'Start the PySpark shell:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 启动 PySpark shell：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Import the image embeddings:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 导入图像嵌入：
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'PySpark’s LSH implementation requires a vector column as an input. We can create
    one by combining the relevant columns in our dataframe using the `VectorAssembler`
    transform:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: PySpark 的 LSH 实现要求矢量列作为输入。我们可以通过使用 `VectorAssembler` 转换来将数据框中的相关列组合成一个列来创建这样一个列：
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the next section, we will use the LSH algorithm to create a way for us to
    find similar images from our dataset.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将使用 LSH 算法创建一种方法来从数据集中找到相似的图像。
- en: Image Similarity Search Using PySpark LSH
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PySpark LSH 进行图像相似度搜索
- en: Locality sensitive hashing is an important class of hashing techniques, which
    is commonly used in clustering, approximate nearest neighbor search, and outlier
    detection with large datasets. Locality sensitive functions take two data points
    and decide whether or not they should be a candidate pair.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 局部敏感哈希是一种重要的哈希技术类，通常用于聚类、近似最近邻搜索和大数据集的异常值检测。局部敏感函数接受两个数据点，并决定它们是否应该成为候选对。
- en: The general idea of LSH is to use a family of functions (“LSH families”) to
    hash data points into buckets so that the data points that are close to each other
    are in the same buckets with high probability, while data points that are far
    away from each other are very likely in different buckets. The data points that
    map to the same buckets are considered a candidate pair.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: LSH 的一般思想是使用一组函数族（“LSH 家族”）将数据点哈希到桶中，以便数据点彼此靠近的概率很高地放置在同一个桶中，而数据点相距很远的概率很高地放置在不同的桶中。映射到相同桶中的数据点被视为候选对。
- en: In PySpark, different LSH families are implemented in separate classes (e.g.,
    `MinHash` and `BucketedRandomProjection`), and APIs for feature transformation,
    approximate similarity join, and approximate nearest neighbor are provided in
    each class.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PySpark 中，不同的 LSH 家族被实现为单独的类（例如 `MinHash` 和 `BucketedRandomProjection`），并且每个类都提供了用于特征转换、近似相似性连接和近似最近邻的
    API。
- en: We’ll use the BucketedRandomProjection implementation of LSH.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 BucketedRandomProjection 实现的 LSH。
- en: 'Let’s first create our model object:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先创建我们的模型对象：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the BucketedRandomProjection LSH implementation, the bucket length can be
    used to control the average size of hash buckets (and thus the number of buckets).
    A larger bucket length (i.e., fewer buckets) increases the probability of features
    being hashed to the same bucket (increasing the number of true and false positives).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在 BucketedRandomProjection LSH 实现中，桶长度可以用来控制哈希桶的平均大小（从而控制桶的数量）。较大的桶长度（即较少的桶）增加了特征被哈希到同一桶的概率（增加了真正和错误的正例数量）。
- en: 'We now transform the input DataFrame using the newly created LSH model object.
    The resulting DataFrame will contain a `hashes` column containing hashed representation
    of the image embeddings:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用新创建的 LSH 模型对象转换输入的 DataFrame。结果的 DataFrame 将包含一个 `hashes` 列，其中包含图像嵌入的哈希表示：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: With our LSH-transformed dataset ready, we’ll put our work to the test in the
    next section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有了我们的 LSH 转换后的数据集准备好了，我们将在下一部分进行测试。
- en: Nearest Neighbor Search
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最近邻搜索
- en: 'Let’s try to find a similar image using a new image. For now, we will pick
    one from the input dataset itself ([Figure 10-3](#random-car)):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用新图像找到相似的图像。目前，我们将从输入数据集中选择一个（[图 10-3](#random-car)）：
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Randomly picked car image](assets/aaps_1003.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![随机选择的汽车图像](assets/aaps_1003.png)'
- en: Figure 10-3\. Randomly picked car image from our dataset
  id: totrans-74
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-3\. 我们数据集中随机选择的汽车图像
- en: 'First, we’ll need to convert the input image into a vector format using our
    `I⁠m⁠g⁠2⁠V⁠e⁠c​R⁠e⁠s⁠n⁠e⁠t⁠1⁠8` class:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要使用我们的 `I⁠m⁠g⁠2⁠V⁠e⁠c​R⁠e⁠s⁠n⁠e⁠t⁠1⁠8` 类将输入图像转换为矢量格式：
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now we perform an approximate nearest neighbor search:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们执行近似最近邻搜索：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'You can check the images in Figures [10-4](#result-image1) through [10-8](#result-image5)
    to see that the model gets it somewhat right already:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看图 [10-4](#result-image1) 到 [10-8](#result-image5) 的图像，看到模型已经相当正确：
- en: '[PRE16]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Result image 1](assets/aaps_1003.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像 1](assets/aaps_1003.png)'
- en: Figure 10-4\. Result image 1
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-4\. 结果图像 1
- en: '![Result image 2](assets/aaps_1005.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像 2](assets/aaps_1005.png)'
- en: Figure 10-5\. Result image 2
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-5\. 结果图像 2
- en: '![Result image 3](assets/aaps_1006.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像 3](assets/aaps_1006.png)'
- en: Figure 10-6\. Result image 3
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-6\. 结果图像 3
- en: '![Result image 4](assets/aaps_1007.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像 4](assets/aaps_1007.png)'
- en: Figure 10-7\. Result image 4
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-7\. 结果图像 4
- en: '![Result image 5](assets/aaps_1008.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![结果图像 5](assets/aaps_1008.png)'
- en: Figure 10-8\. Result image 5
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-8\. 结果图像 5
- en: The input image is on top of the list as one would expect.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像如预期一样位于列表顶部。
- en: Where to Go from Here
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从这里开始
- en: In this chapter, we learned how PySpark can be combined with a modern deep learning
    framework to scale an image similarity detection workflow.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何将 PySpark 与现代深度学习框架结合起来，以扩展图像相似性检测工作流程。
- en: There are multiple ways to improve this implementation. You can try using a
    better model or improving the preprocessing to get better quality of embeddings.
    Further, the LSH model can be tweaked. In a real-life setting, you may need to
    update the reference dataset consistently to account for new images coming into
    the system. The simplest way to do this is by running a batch job at periodic
    intervals to create new LSH models. You can explore all of these depending on
    your need and interest.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以改进这个实现。你可以尝试使用更好的模型或改进预处理以获得更好的嵌入质量。此外，LSH 模型可以进行调整。在实际设置中，您可能需要定期更新参考数据集，以适应系统中新加入的图像。最简单的方法是定期运行批处理作业以创建新的LSH模型。您可以根据需求和兴趣探索所有这些方法。
