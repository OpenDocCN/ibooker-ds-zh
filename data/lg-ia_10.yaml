- en: 7 Performance and scaling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 性能和扩展
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Tuning Fluentd to maximize resources using workers
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用工作进程调整 Fluentd 以最大化资源
- en: Deploying Fluentd with fan-in and -out patterns
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用扇入和扇出模式部署 Fluentd
- en: Using deployment patterns for scaling
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用部署模式进行扩展
- en: Implementing high availability and deployments
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施高可用性和部署
- en: Using Fluentd with microservice patterns
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用微服务模式与 Fluentd 结合
- en: In previous chapters, we worked with just a single Fluentd instance. Still,
    we live in a world of distribution, virtualization, and containerization, which
    typically needs more than a single instance. In addition to distribution considerations,
    we need to support elasticity through scaling up (adding more CPUs or memory to
    a server to support more processes and threads) and scaling out (deploying additional
    server instances to have workload distributed via load balancing) to meet fluctuating
    demands (along with the reverse scale down and in). Enterprises demand resilience
    to handle failure and disaster scenarios. To provide good availability, we should
    at least have an active server and a standby server deployed, with both servers
    using configuration files that are kept synchronized. Configuration synchronization
    makes it possible to start up the standby server on short notice if the first
    instance fails (active-passive). In the more demanding cases, active-active deployments
    are needed with servers spread across multiple data centers; this is very conventional
    as a deployment pattern. A single server solution in the enterprise space is a
    rarity.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们只使用了一个 Fluentd 实例。然而，我们生活在一个分布式、虚拟化和容器化的世界中，通常需要不止一个实例。除了分布式的考虑之外，我们还需要通过扩展（向服务器添加更多
    CPU 或内存以支持更多进程和线程）和扩展（通过负载均衡部署额外的服务器实例以实现工作负载的分布）来支持弹性，以满足波动的需求（以及反向的缩放和缩减）。企业需要弹性来处理故障和灾难场景。为了提供良好的可用性，我们至少应该部署一个活动服务器和一个备用服务器，两个服务器都使用保持同步的配置文件。配置同步使得在第一个实例失败时能够迅速启动备用服务器（主动-被动）。在更严格的情况下，需要使用活动-活动部署，服务器分布在多个数据中心；这作为一种部署模式是非常常见的。在企业空间中，单服务器解决方案是非常罕见的。
- en: This chapter will explore the techniques and features available to let us scale
    Fluentd up using worker processes and resource management, and scale out with
    multiple Fluentd nodes. With scaling out, we can also factor in increased options
    for resilience. As Fluentd needs only a small footprint, we can implement some
    of the techniques and features to scale Fluentd on our desktop.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨可用的技术和功能，让我们可以使用工作进程和资源管理来扩展 Fluentd，并使用多个 Fluentd 节点进行扩展。通过扩展，我们还可以考虑增加弹性选项。由于
    Fluentd 只需要很小的占用空间，我们可以在我们的桌面上实现一些技术和功能来扩展 Fluentd。
- en: 7.1 Threading and processes to scale with workers
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 使用工作进程进行线程和进程的扩展
- en: One of the ways we can scale a Fluentd deployment is to use its ability to spawn
    additional child processes (workers) to exploit the fact that modern machines
    have multiple CPU cores available to run concurrent processes. Before configuring
    any scaling, it is vital to understand how Fluentd is impacted by its implementation
    with Ruby and how Ruby handles threads. Ruby has a *Global Interpreter Lock* (GIL),
    which means that while a process is not I/O bound, it will block other jobs (see
    appendix E for more detail on GIL and Ruby threading). Therefore, any computationally
    intensive tasks are best performed in separate OS processes and use the OS to
    provide more effective resource sharing. Some plugins do this for you (e.g., the
    AWS S3 plugin when using gzip compression), but not all, so we must be very mindful
    of this for performance optimization. Without that separation, the Fluentd process
    will effectively be locked until the process has completed or released the thread.
    Generally, Fluentd as a vehicle for routing log events is more likely to be I/O
    bound—whether that I/O is network-based or is ultimately storage (even if that
    is indirectly through physical storage for a database of some sort).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以扩展Fluentd部署的一种方式是利用其生成额外子进程（工作进程）的能力，以利用现代机器具有多个可用于运行并发进程的CPU核心的事实。在配置任何扩展之前，了解Fluentd如何受其Ruby实现的影响以及Ruby如何处理线程至关重要。Ruby有一个*全局解释器锁*（GIL），这意味着当一个进程不是I/O绑定时，它将阻塞其他任务（有关GIL和Ruby线程的更多详细信息，请参阅附录E）。因此，任何计算密集型任务最好在单独的操作系统进程中执行，并使用操作系统来提供更有效的资源共享。一些插件会为你做这件事（例如，在使用gzip压缩时使用的AWS
    S3插件），但并非所有插件都这样做，因此我们必须非常注意这一点以进行性能优化。如果没有这种分离，Fluentd进程将实际上被锁定，直到进程完成或释放线程。通常，Fluentd作为路由日志事件的工具更有可能受到I/O绑定的影响——无论这种I/O是基于网络的还是最终是存储（即使是通过某种类型的数据库的物理存储间接地）。
- en: Fluentd addresses the thread locking constraint by launching separate processes,
    known as *workers*. By default, Fluentd has one worker and one controller process,
    but we can configure the number of workers. This effectively takes advantage of
    the fact that the OS typically allocates processes to CPUs and swaps between processes
    to give them a fair proportion of the CPU’s compute capacity. As shown in figure
    7.1, each worker will pick up and execute `source`, `filter`, and `match` directives,
    depending upon the configuration.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd通过启动称为*工作进程*的独立进程来解决线程锁定限制。默认情况下，Fluentd有一个工作进程和一个控制器进程，但我们可以配置工作进程的数量。这实际上利用了操作系统通常将进程分配给CPU并在进程之间进行交换以给予它们CPU计算能力的公平比例的事实。如图7.1所示，每个工作进程将根据配置执行`source`、`filter`和`match`指令。
- en: NOTE When there are more processes than CPU cores, the processor will swap between
    the processes. More processes will mean more swapping. The activity of swapping
    requires a small amount of effort. If you have too many running processes, you’ll
    spend more effort swapping processes than performing any meaningful work.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：当进程数量多于CPU核心数时，处理器将在进程之间进行交换。进程越多，交换就越多。交换活动需要付出少量的努力。如果你有太多的运行进程，你将花费更多的时间在进程交换上，而不是进行任何有意义的工作。
- en: '![](../Images/CH07_F01_Wilkins.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH07_F01_Wilkins.png)'
- en: Figure 7.1 Default deployment and how new workers are managed
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 默认部署以及如何管理新工作进程
- en: 7.1.1 Seeing workers in action
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.1 观察工作进程的实际操作
- en: The best way to understand the behavior of worker processes is to configure
    an example and see what actually happens. The most straightforward way to illustrate
    workers is to create a variation of the Hello World configuration. We will establish
    multiple workers and attribute to the workers the application of the dummy source
    plugin. Using the dummy source plugin means the source doesn’t have I/O dependencies
    impacting behavior. The relevant `match` directives then push the output to stdout.
    Using a filter, we can inject into the log event which worker was involved in
    the process, building on what we learned in the previous chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 理解工作进程的行为的最佳方式是配置一个示例并观察实际发生了什么。展示工作进程最直接的方法是创建一个Hello World配置的变体。我们将建立多个工作进程，并将dummy源插件的应用分配给这些工作进程。使用dummy源插件意味着源没有影响行为的I/O依赖。相关的`match`指令然后将输出推送到stdout。通过使用过滤器，我们可以将涉及该过程的哪个工作进程注入到日志事件中，这基于我们在上一章中学到的内容。
- en: Let’s define how many workers we will use and add this into the system directive
    alongside the `log_level` attribute we have been setting. This is done by setting
    the attribute `workers` in the *system* directive.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义我们将使用多少个工作进程，并将其添加到系统指令中，与我们已经设置的 `log_level` 属性并列。这是通过在 *system* 指令中设置
    `workers` 属性来完成的。
- en: To define explicitly what each worker does, we wrap the directives in a directive
    of `<worker x>` where `x` represents the numeric worker ID that will execute the
    directives. For example, `<worker 2>` would use the third worker (IDs start at
    0). If we want to effectively allocate more resources (i.e., workers) to a specific
    set of directives, we can specify a range of workers in the directive. For example,
    `<worker 1-3>` would allocate workers 1, 2, and 3 to perform the same activities.
    All workers will get directives not assigned. So worker 0 in our configuration
    would process only these directives.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了明确定义每个工作进程的功能，我们将指令包裹在 `<worker x>` 指令中，其中 `x` 代表将执行指令的数字工作进程 ID。例如，`<worker
    2>` 将使用第三个工作进程（ID 从 0 开始）。如果我们想有效地将更多资源（即工作进程）分配给特定的指令集，我们可以在指令中指定工作进程的范围。例如，`<worker
    1-3>` 将将工作进程 1、2 和 3 分配以执行相同的活动。所有未分配指令的工作进程都将得到处理。因此，在我们的配置中，工作进程 0 将仅处理这些指令。
- en: In listing 7.1, we have defined four workers and have deliberately left the
    subsequent directives outside of the worker configuration. The result of this
    is that every worker will pick up the configuration. This means we can share a
    common output—but this has to be handled with care, as it can have undesirable
    side effects. These side effects can range from losing events to storage corruption,
    such as the problem of multiple processes trying to write to the same file. In
    our example, we’re just applying a filter to extract the `worker_id`, add it to
    the log event, and send it to `stdout` (console).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 7.1 中，我们定义了四个工作进程，并且故意将后续指令留在了工作进程配置之外。结果是每个工作进程都会获取配置。这意味着我们可以共享一个公共输出——但是这需要小心处理，因为它可能产生不希望的结果。这些副作用可能包括丢失事件到存储损坏，例如多个进程尝试写入同一文件的问题。在我们的例子中，我们只是应用一个过滤器来提取`worker_id`，将其添加到日志事件中，并将其发送到`stdout`（控制台）。
- en: Listing 7.1 Chapter7/Fluentd/dummy-stdout-multiworker.conf—illustrating workers
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.1 Chapter7/Fluentd/dummy-stdout-multiworker.conf—展示工作进程
- en: '[PRE0]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Declares the number of workers
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 声明工作进程的数量
- en: ❷ Activities specific to worker 0
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 特定于工作进程 0 的活动
- en: ❸ Defines activities for two workers
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义两个工作进程的活动
- en: ❹ Defines a source outside of the workers—we should see this being picked up
    by all workers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 定义工作进程之外的外部源——我们应该看到所有工作进程都会获取这个源。
- en: ❺ Uses a filter to add the ID of the worker involved in that log event
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 使用过滤器添加涉及该日志事件的 worker ID
- en: This configuration can be started up with the command
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下命令启动此配置
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Before examining the stdout console, it is worth seeing what is happening in
    terms of processes. With a command console in Windows or a Linux shell, the following
    appropriate command should be run:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查 stdout 控制台之前，了解进程方面的情况是值得的。在 Windows 的命令控制台或 Linux 的 shell 中，应运行以下适当的命令：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: These commands will show you the Ruby processes, which will include Fluentd
    processes. As a result, you should see five processes listed if Fluentd is the
    only Ruby solution running. If other Ruby solutions are running, we can differentiate
    them, as the Fluentd processes will have identical or very nearly identical start
    times. The processes are made up of four workers and one controller process.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令将显示 Ruby 进程，其中包括 Fluentd 进程。因此，如果 Fluentd 是唯一运行的 Ruby 解决方案，你应该看到列出了五个进程。如果有其他
    Ruby 解决方案正在运行，我们可以区分它们，因为 Fluentd 进程将具有相同或几乎相同的启动时间。这些进程由四个工作进程和一个控制器进程组成。
- en: TIP We can make processes easier to identify by using the `process_name` attribute
    in the `<system>` configuration (e.g., `process_name Fluentd`).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: TIP 我们可以通过在 `<system>` 配置中使用 `process_name` 属性（例如，`process_name Fluentd`）来使进程更容易识别。
- en: With the Fluentd processes having been run for a while, we’ll want to shut things
    down. This is a little more complex to do now, as we have multiple processes.
    For Windows, this can be done with the command line `taskkill /IM Ruby.exe /F`,
    and the Linux equivalent is `pkill -f ruby` as long as you don’t have any other
    Ruby processes running. If you have other Ruby processes running, you’ll have
    to isolate the processes and manually kill each one.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当Fluentd进程运行了一段时间后，我们可能想要关闭它们。现在这要复杂一些，因为我们有多个进程。对于Windows，可以使用命令行 `taskkill
    /IM Ruby.exe /F` 来完成，Linux的等效命令是 `pkill -f ruby`，前提是你没有运行其他Ruby进程。如果你有其他Ruby进程在运行，你必须隔离这些进程并手动逐个关闭它们。
- en: 'Looking through the stdout results from having run Fluentd with the `dummy
    -stdout-multiworker.conf` configuration file, you should be able to see that the
    following has occurred (but be aware there is a level of arbitrary behavior):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看使用 `dummy -stdout-multiworker.conf` 配置文件运行Fluentd的stdout结果，你应该能够看到以下情况发生（但请注意存在一定程度上的任意行为）：
- en: Log events with the tag `w-any` will appear with any of the `worker_id` entries.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带有标签 `w-any` 的日志事件将出现在任意的 `worker_id` 条目中。
- en: Logs linked to tag `w0` (including `"hello":"from worker 0"`) will only be linked
    to `"worker_id":"0"`.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与标签 `w0` 链接的日志（包括 `"hello":"from worker 0"`）将仅链接到 `"worker_id":"0"`。
- en: Logs linked to tag `w1` (including `"hello":"from worker 1-2"`) will only be
    linked to `"worker_id":"1"` or `"worker_id":"2"`.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与标签 `w1` 链接的日志（包括 `"hello":"from worker 1-2"`）将仅链接到 `"worker_id":"1"` 或 `"worker_id":"2"`。
- en: 7.1.2 Worker constraints
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.2 工作进程限制
- en: When using workers, there are some constraints that need to be considered. This
    relates to how processes can share (or not) resources such as file handles. So
    if you allocate multiple workers to a Fluentd configuration that writes to file
    output, the file needs to be separated, as only one worker can use one file properly.
    We can solve this by setting the file path to include the `worker_id`; for example,
    `path "logs/#{worker_id}/${tag}/%Y/%m/%d/logfile.out`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用工作进程时，需要考虑一些限制条件。这涉及到进程如何共享（或不能共享）资源，例如文件句柄。因此，如果你将多个工作进程分配给一个写入文件输出的Fluentd配置，文件需要被分开，因为只有一个工作进程可以正确地使用一个文件。我们可以通过设置文件路径包含
    `worker_id` 来解决这个问题；例如，`path "logs/#{worker_id}/${tag}/%Y/%m/%d/logfile.out"`。
- en: Sharing ports among workers can be realized when the plugin uses the *server*
    helper plugin or when the plugin can natively handle the sharing of ports. The
    *forward* plugin is an example of native port management. As each process cannot
    use the same port, a reliable mechanism to overcome this and select suitable ports
    is needed. When the server helper plugin is used, it will then allocate consecutive
    ports to each worker. So if we had specified the use of four workers and then
    defined the use of a *monitor_agent* plugin with a port set to 30000, then worker
    0 uses port 30000, worker 1 uses 30001, worker 2 uses 30002, and so on. If you
    are using workers, ensure that the ports being used are well separated. Separating
    the ports will avoid potential port collisions because the algorithm assigns the
    same port to different plugin instances across multiple workers. For example,
    specifying ports 30000 and then 30002 to different plugins, but then introducing
    four workers, would see ports 30002 and 30003 trying to be used by two different
    plugins.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当插件使用 *server* 辅助插件或插件能够原生地处理端口的共享时，可以在工作进程之间共享端口。*forward* 插件是原生端口管理的例子。由于每个进程不能使用相同的端口，需要一个可靠的机制来克服这一点并选择合适的端口。当使用服务器辅助插件时，它将为每个工作进程分配连续的端口。因此，如果我们指定了使用四个工作进程，并定义了使用端口设置为30000的
    *monitor_agent* 插件，那么工作进程0使用端口30000，工作进程1使用30001，工作进程2使用30002，依此类推。如果你正在使用工作进程，请确保使用的端口是分开的。分离端口将避免潜在的端口冲突，因为算法会在多个工作进程的不同插件实例之间分配相同的端口。例如，指定端口30000然后30002给不同的插件，然后引入四个工作进程，将看到端口30002和30003试图被两个不同的插件使用。
- en: 7.1.3 Controlling output plugin threads
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.3 控制输出插件线程
- en: The threading behavior of output plugins can be controlled through the use of
    a property called `num_threads`. This value defaults to one. Increasing the number
    of threads can potentially increase the performance, as it allows context switching
    between threads to occur when a thread is blocked. As a result, any in-process
    latency can be used more effectively. But this won’t overcome the constraints
    of GIL.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出插件的线程行为可以通过使用名为 `num_threads` 的属性来控制。此值默认为1。增加线程数可能会潜在地提高性能，因为它允许在某个线程被阻塞时在线程之间进行上下文切换。因此，任何进程中的延迟都可以更有效地被利用。但这也无法克服全局解释锁（GIL）的限制。
- en: You could consider using such a configuration for output plugins where the configuration
    distributes the workload to several different destinations, as one thread works
    until it ends or has to stop for I/O. Then the next thread, not I/O bound, will
    be allowed to work. This all means we gain performance—rather than waiting for
    the I/O to release and the execution to continue, we swap the thread being executed
    to where work can be done.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以考虑为输出插件使用此类配置，其中配置将工作负载分配到几个不同的目的地，因为一个线程工作直到结束或因I/O而必须停止。然后下一个线程，非I/O绑定，将被允许工作。这意味着我们获得了性能——而不是等待I/O释放和执行继续，我们交换正在执行的线程到可以进行工作的位置。
- en: Tuning the use of threads is difficult, as you must know how processes perform
    in order to recognize the potential for threads to wait on something such as I/O.
    With the thread switching overhead, there is a point at which it is more effective
    to wait on I/O rather than swap threads. This can also be compounded by the potential
    level of process switching at the OS level. Correctly tuning threads can often
    come down to running realistic workloads and measuring performance, then comparing
    test runs with different threading configurations to see where performance actually
    starts to drop off.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 调整线程的使用是困难的，因为你必须知道进程的性能才能识别线程等待I/O等事物的潜力。由于线程切换的开销，存在一个点，等待I/O比交换线程更有效。这也可以通过操作系统级别的进程切换潜在水平而加剧。正确调整线程通常取决于运行现实的工作负载并测量性能，然后比较具有不同线程配置的测试运行，以查看性能实际上开始下降的地方。
- en: 7.1.4 Memory management optimization
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.4 内存管理优化
- en: Another area that can be tuned is the Ruby VM layer. This means tuning the garbage
    collection and memory block allocation. To tune at this level, you need to have
    a good understanding of the specifics of the Ruby implementation, along with tooling
    to help you analyze how the configuration is impacting performance. In appendix
    E, we provide resources that can help with Ruby.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可以调整的区域是Ruby VM层。这意味着调整垃圾收集和内存块分配。要在这一级别进行调整，你需要对Ruby实现的具体细节有很好的理解，以及帮助您分析配置如何影响性能的工具。在附录E中，我们提供了有助于Ruby的资源。
- en: 7.2 Scaling and moving workloads
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 扩展和移动工作负载
- en: Chapter 4 looked at the output plugins’ ability to work with buffers, which
    will provide us with a means to optimize the performance around each I/O activity,
    particularly with the memory buffer. Beyond buffers and the tuning of threads
    and workers, the scaling options are about workload distribution. This could be
    achieved by
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 第四章探讨了输出插件与缓冲区一起工作的能力，这将为我们提供一种优化每个I/O活动性能的手段，尤其是与内存缓冲区相关。除了缓冲区和线程及工作者的调整之外，扩展选项是关于工作负载分配。这可以通过以下方式实现
- en: Feeding the log events to an event stream technology like Kafka.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将日志事件馈送到像Kafka这样的事件流技术。
- en: Using tools such as Redis or Memcached for large-scale caches.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Redis或Memcached等工具进行大规模缓存。
- en: Taking advantage of Fluentd’s ability to pass log events to other Fluentd nodes.
    This ability provides the opportunity to move the workload to dedicated Fluentd
    nodes, either fanning out if the workload needs a lot of additional computing
    power, or, more likely, fanning in, bringing lots of log events from many smaller
    nodes down to one or two Fluentd instances.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用Fluentd将日志事件传递到其他Fluentd节点的能力。这种能力提供了将工作负载移动到专用Fluentd节点的机会，要么是如果工作负载需要大量的额外计算能力而向外扩展，要么更可能是向内扩展，将来自许多较小节点的大量日志事件汇总到一两个Fluentd实例。
- en: In the following sections, we’ll look at the fan-in (sometimes referred to as
    *concentrator* or *aggregator networks*) and fan-out deployments, as they are
    implemented using the same core set of plugins.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下章节中，我们将探讨输入/输出（有时称为*集中器*或*聚合网络*）和输出部署，因为它们使用相同的核心插件集实现。
- en: Fluentd’s compute footprint is so small, we can run some configurations to illustrate
    the setup on a single machine.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd的计算足迹非常小，我们可以运行一些配置来展示在单台机器上的设置。
- en: 7.2.1 Fan-in/log aggregation and consolidation
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.1 输入/输出聚合和合并
- en: The most likely scenario for deploying multiple Fluentd and Fluent Bit nodes
    is supporting concentrator networks (fan-in), particularly in a containerized
    environment. This model describes two or more Fluentd nodes collecting log events
    and passing the events to a central Fluentd/Fluent Bit instance. For example,
    as we’ll see later in this section, log events may originate at the Fluentd nodes
    at the tip of each “spine” of the fan. The log events are filtered as needed,
    and then events flow down the spine to the center of the fan—hence the name *fan-in*
    or *concentrator*.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 部署多个Fluentd和Fluent Bit节点的最可能场景是支持集中器网络（扇入），尤其是在容器化环境中。此模型描述了两个或多个Fluentd节点收集日志事件并将事件传递给中央Fluentd/Fluent
    Bit实例。例如，正如我们将在本节后面看到的那样，日志事件可能起源于扇入“脊柱”末端的Fluentd节点。根据需要过滤日志事件，然后事件沿着脊柱流向扇子的中心——因此得名*扇入*或*集中器*。
- en: Let’s first start with log aggregation in a more generic form relevant to traditional
    virtualized or native hardware environments, which can also work in a containerized
    deployment. Then we’ll see how this can vary with containers.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先从更通用的形式开始，即与传统的虚拟化或原生硬件环境相关的日志聚合，这也可以在容器化部署中工作。然后我们将看到这与容器如何变化。
- en: Fan-in relation to application architecture and deployment
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 与应用程序架构和部署相关的扇入关系
- en: Environments that handle high volumes and/or need a high level of resilience
    will see application software distributed across multiple servers. We can configure
    servers so a single Fluentd instance can see every server’s log files or deploy
    a Fluentd (or Fluent Bit) instance on each server. Opening a server so parts of
    the file system can be accessed from another server creates challenges with security.
    Each server having a Fluentd node is a more robust and secure model to adopt.
    The better security comes from the fact that data flows outward from Fluentd to
    locations it knows about and with log events determined okay to share. This is
    illustrated in figure 7.2.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 处理高流量和/或需要高弹性级别的环境将看到应用程序软件分布在多个服务器上。我们可以配置服务器，使单个Fluentd实例可以看到每个服务器的日志文件，或者在每个服务器上部署Fluentd（或Fluent
    Bit）实例。打开服务器以便从其他服务器访问文件系统的一部分会带来安全挑战。每个服务器拥有Fluentd节点是一个更稳健且更安全的采用模式。更好的安全性来自于数据从Fluentd流向它所知道的位置，并且日志事件确定可以共享。这如图7.2所示。
- en: '![](../Images/CH07_F02_Wilkins.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F02_Wilkins.png)'
- en: Figure 7.2 Illustrating scaling using the full-stack model, where each server
    has all the features deployed. As a result, call sequences are more likely to
    remain within a server.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2展示了使用全栈模型进行扩展的情况，其中每个服务器都部署了所有功能。因此，调用序列更有可能保持在服务器内部。
- en: 'Scaling out can be implemented by the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展可以通过以下方式实现：
- en: Each server holding a complete solution stack (presentation layer, mid-tier,
    and sometimes even the backend storage).
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个服务器都持有完整的解决方案栈（表示层、中间层，有时甚至包括后端存储）。
- en: When this occurs, you are likely to track a single request and response from
    end to end within the logs of a single server. But linking multiple request responses
    from a single client to the same backend (known as *server affinity*) can bias
    workload to specific servers. This can impact the effectiveness of dynamic scaling,
    as the new node(s) only taking on new clients.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当这种情况发生时，你可能会在单个服务器的日志中从端到端跟踪单个请求和响应。但是，将单个客户端的多个请求响应链接到同一后端（称为*服务器亲和性*）可能会使工作负载偏向特定服务器。这可能会影响动态扩展的有效性，因为新节点（s）仅承担新客户端。
- en: Segmenting the solution into logical parts and allocating parts to one or more
    specific servers. We often talk about this as an N-tier model with servers dedicated
    to running a tier, such as the presentation tier; other servers deployed with
    business logic tier; and other servers for persistence tier; and so on. We can
    see in figure 7.3 an N-tier or three-tier deployment. Each of the different-colored
    verticals represents a tier—UI or presentation tier on the left, mid-tier in the
    middle (typically a business tier when there are three tiers), and in this case,
    a reporting tier on the right. Server affinity for user sessions is likely to
    be less of an issue, so the same server may see the same user sessions for their
    fragment of a user event.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将解决方案划分为逻辑部分并将部分分配给一个或多个特定服务器。我们经常将此称为具有服务器专门运行某一层的 N 层模型，例如，运行表示层的层；部署业务逻辑层的其他服务器；以及用于持久化层的其他服务器等。我们可以在图
    7.3 中看到 N 层或三层部署。每种不同颜色的垂直部分代表一个层——左侧的 UI 或表示层，中间的中层（通常在三层时为业务层），以及在这种情况下，右侧的报告层。用户会话的服务器亲和力可能不太成问题，因此同一服务器可能看到同一用户会话的片段。
- en: '![](../Images/CH07_F03_Wilkins.png)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F03_Wilkins.png)'
- en: Figure 7.3 In this situation, the services are grouped by a common purpose to
    target scaling more efficiently. However, following the invocations, end to end
    is more complex.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.3 在这种情况下，服务根据共同目的进行分组，以更有效地进行扩展。然而，在调用之后，端到端变得更加复杂。
- en: 'Ultimately, tracking the activities of a user’s session end to end will require
    us to bring all the logs together to see the complete picture. Sometimes the complete
    picture isn’t handled until all the logs reach an analytics platform and are periodically
    processed. This is fine, but we’ve already highlighted that we may wish to quickly
    react or be proactive and trigger actions from the log event processing. Bringing
    the logs through a centralized node presents several benefits:'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终，从端到端跟踪用户会话的活动将需要我们将所有日志汇总在一起以查看完整情况。有时，只有在所有日志达到分析平台并定期处理之后，才会处理完整情况。这没问题，但我们已经强调，我们可能希望快速反应或主动触发日志事件处理中的操作。通过一个集中节点传递日志提供了几个好处：
- en: Dedicated node(s) for handling a workload allows resources to be tuned for that
    job.
  id: totrans-68
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专门用于处理工作负载的节点允许为该工作调整资源。
- en: When configuration becomes complex, it’s easier if the logic is more centralized,
    as deploying improvements and refinements involves a smaller number of deployments—even
    with automation, fewer nodes are generally better.
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当配置变得复杂时，如果逻辑更加集中，则更容易，因为部署改进和细化涉及更少的部署——即使有自动化，通常节点越少越好。
- en: Rather than lots of nodes needing credentials and access to a repository of
    credentials (such as Vault), we keep the access to such details restricted to
    a smaller set of servers. Therefore, it is harder for the details to be exploited.
    This is essential if storing credentials (or certificates when using mutual Transport
    Layer Security [TLS]) is handled in a less-sophisticated manner than Vault.
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与需要凭证和访问凭证存储库（如 Vault）的大量节点相比，我们仅将此类细节的访问权限限制在更小的服务器集。因此，这些细节被滥用的可能性更小。如果存储凭证（或在使用相互传输层安全性
    [TLS] 时使用证书）的方式不如 Vault 复杂，这一点至关重要。
- en: It can be easier to demonstrate security if the number of points of origin for
    data is controlled. This is particularly true if the final destination of logs
    is outside the network, as it means the number of servers needing outbound access
    is constrained. It also makes it easier to handle when outbound proxy servers
    are involved.
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果控制数据来源的数量，可以更容易地证明安全性。这尤其适用于日志的最终目的地位于网络之外的情况，因为这意味着需要出站访问的服务器数量受到限制。它还使得在涉及出站代理服务器时更容易处理。
- en: Figure 7.4 illustrates how such a configuration could be deployed with the application
    servers having a relatively small-footprint Fluentd node. The outermost (top)
    instances of Fluentd are capturing log events (and maybe filtering out some of
    the low-value/unneeded log events) before passing log events onto an inner node
    (shown at the bottom) being fed by multiple Fluentd nodes.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 阐述了如何使用具有相对较小占用空间的 Fluentd 节点的应用服务器部署此类配置。最外层（顶部）的 Fluentd 实例在将日志事件（可能过滤掉一些低价值/不需要的日志事件）传递给内部节点之前捕获日志事件（内部节点显示在底部），该内部节点由多个
    Fluentd 节点提供数据。
- en: '![](../Images/CH07_F04_Wilkins.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F04_Wilkins.png)'
- en: Figure 7.4 An example concentrator network deployment with multiple Fluentd
    instances feeding a central Fluentd instance on a dedicated server doing the majority
    of the work
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 一个示例集中器网络部署，多个Fluentd实例向专用服务器上的中心Fluentd实例提供数据，该服务器执行大部分工作
- en: It is common to illustrate a fan-in configuration with a single server in the
    middle; however, this could be a cluster of servers, particularly when considering
    hyperscale environments. What continues to characterize the model as fan-in is
    that the number of log event sources is far greater than those at the center doing
    the core log event processing.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，人们会用一个位于中间的单个服务器来展示扇入配置；然而，这可能是服务器集群，尤其是在考虑超大规模环境时。这个模型作为扇入的特点是日志事件源的数量远大于中心执行核心日志事件处理的数量。
- en: Fluentd configuration for fan-in
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 扇入Fluentd配置
- en: Let’s walk through the setup of this kind of concentrator network configuration.
    We will need two Fluentd configuration files, one of which will work for as many
    source servers as we want to represent using the `forward` plugin as an output.
    A second configuration uses `forward` as an input to process and direct traffic
    to a final destination. To keep things simple, we’ll use the dummy source plugin
    rather than running the simulators. To make the origin node easy to identify,
    we need to incorporate something into the log event. Normally we could do that
    with the node hostname, but since we’re running everything on a single machine,
    that doesn’t help us. Another approach to this is to retrieve an environmental
    variable and use it for the tag name. As long as the environment variable scope
    is restricted to the scope of the shell used to launch the Fluentd instance, this
    will work. Figure 7.5 illustrates the configuration in more detail.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步了解这种集中器网络配置的设置。我们需要两个Fluentd配置文件，其中一个将用于作为输出使用`forward`插件表示的任意数量的源服务器。第二个配置使用`forward`作为输入以处理并将流量导向最终目的地。为了简化，我们将使用虚拟源插件而不是运行模拟器。为了使源节点易于识别，我们需要在日志事件中包含某些内容。通常我们可以使用节点主机名来做这件事，但由于我们是在单个机器上运行所有内容，这并没有帮助我们。另一种方法是检索环境变量并将其用作标签名称。只要环境变量的作用域限制在启动Fluentd实例所使用的shell的作用域内，这就会起作用。图7.5更详细地说明了配置。
- en: '![](../Images/CH07_F05_Wilkins.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F05_Wilkins.png)'
- en: Figure 7.5 A detailed view of how multiple Fluentd nodes running the same configuration
    feed a single instance
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 多个运行相同配置的Fluentd节点如何向单个实例提供详细视图
- en: To get the environment variable into the payload, we’ve added a filter into
    the source, which takes the tag value and is set using the Ruby command `"#{ENV["NodeName"]}"`;
    this retrieves the value of `NodeName`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将环境变量放入有效载荷中，我们在源中添加了一个过滤器，该过滤器获取标签值，并使用Ruby命令`"#{ENV["NodeName"]}"`设置；这检索了`NodeName`的值。
- en: Listing 7.2 Chapter7/Fluentd/dummy-foward1.conf—illustrating forward out
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.2 Chapter7/Fluentd/dummy-foward1.conf—展示前向输出
- en: '[PRE3]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Here, we are grabbing the environment variable to make each instance distinct.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在这里，我们正在获取环境变量以使每个实例独特。
- en: ❷ Puts the tag into the log event record
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将标签放入日志事件记录中
- en: ❸ Declares the forward plugin output
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 声明前向插件输出
- en: ❹ Buffers up events before sending; for convenience, we’re limiting this. In
    the real world, you’d probably consider a longer duration.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在发送之前缓冲事件；为了方便，我们限制了这个时间。在现实世界中，你可能考虑一个更长的持续时间。
- en: ❺ Defines the target server to direct the log event to
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 定义目标服务器以将日志事件定向到
- en: ❻ If we can’t communicate with the central Fluentd instance, we need to send
    the log events somewhere. In this configuration, we’re just sending the events
    to the console if they can’t be handled. You’ll probably want to do something
    more robust in a production scenario, like writing events to a file.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 如果我们无法与中心Fluentd实例通信，我们需要将日志事件发送到其他地方。在这个配置中，如果无法处理，我们只是将事件发送到控制台。你可能希望在生产场景中做更稳健的事情，比如将事件写入文件。
- en: Before starting Fluentd, the shell used to run Fluentd will need to `set` or
    `export` (Windows or Linux) `NodeName=Node1`. Each source node has a new number
    in the assignment. Then we can start up Fluentd with
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动Fluentd之前，用于运行Fluentd的shell需要`set`或`export`（Windows或Linux）`NodeName=Node1`。每个源节点都有一个新的编号。然后我们可以使用以下命令启动Fluentd：
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Repeat the steps of starting a shell, setting the environment variable, and
    launching the source Fluentd node to get a second Fluentd node generating log
    events and sending them to the central Fluentd node.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 重复启动shell、设置环境变量和启动源Fluentd节点的步骤，以获得第二个生成日志事件并发送到中央Fluentd节点的Fluentd节点。
- en: NOTE If the environment variable is not set up, and if Fluentd is showing its
    configuration (at the info log level), you can see if the value has been properly
    inserted. If the value is absent, depending on the attribute, you’ll observe a
    startup error at best; at worst, things will start up but not appear to do anything.
    This comes from the fact that a default value may be defined and taken. For example,
    the `port` attribute will be `0`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果环境变量未设置，并且Fluentd正在显示其配置（在info日志级别），您可以查看值是否已正确插入。如果值不存在，根据属性，您最多会观察到启动错误；最坏的情况下，系统将启动但似乎没有任何动作。这源于默认值可能被定义并被采用。例如，`port`属性将是`0`。
- en: We have used a filter to ensure that the tag is captured into the log event.
    In addition, we can also utilize the `stdout` plugin so the console from the sender
    will show us the log events that we should receive in the central node. Ideally,
    we need to run several shells and set the environment variable accordingly. Depending
    on how long it takes to start up the central (consuming) node, periodic network
    errors will be reported on the source nodes, as there is no response to the network
    calls.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经使用过滤器确保标签被捕获到日志事件中。此外，我们还可以利用`stdout`插件，以便发送者的控制台会显示我们应该在中央节点接收到的日志事件。理想情况下，我们需要运行几个shell并相应地设置环境变量。根据中央（消费）节点启动所需的时间，源节点将报告周期性网络错误，因为没有对网络调用的响应。
- en: This brings us to the consuming configuration, which is simply accepting the
    forwarded events and pushing them out to the console. We’ve seen much of this
    before, although the use of the `forward` plugin is new. For Fluentd to receive
    the events, we need to define a Fluentd source, which binds to a network address
    and port. This obviously needs to match the sender’s configuration. We can see
    all of this in the following listing.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这将我们引向消费配置，它只是接受转发的事件并将它们推送到控制台。我们之前已经看到很多这样的内容，尽管`forward`插件的使用是新的。为了使Fluentd接收事件，我们需要定义一个Fluentd源，它绑定到网络地址和端口。这显然需要与发送者的配置相匹配。我们可以在以下列表中看到所有这些内容。
- en: Listing 7.3 Chapter7/Fluentd/forward-stdout.conf—illustrating forward as a source
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.3 第7章/Fluentd/forward-stdout.conf—说明将转发作为源
- en: '[PRE5]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Defines the use of the input forward plugin
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义了输入转发插件的使用
- en: ❷ Network address to bind to (DNS or IP)—in our case localhost. This needs to
    match the sender.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 绑定的网络地址（DNS或IP）—在我们的情况下是localhost。这需要与发送者匹配。
- en: ❸ Shows on the console what log events have been sent
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 显示在控制台上已发送的日志事件
- en: With the consuming Fluentd node defined, we can fire up a single instance (for
    the more common concentrator network). Once all the Fluentd nodes are communicating,
    we’ll see all the log events in this node’s console. So, let’s start up the consumer
    node with the command
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了消费Fluentd节点后，我们可以启动单个实例（对于更常见的集中器网络）。一旦所有Fluentd节点开始通信，我们将在该节点的控制台中看到所有日志事件。因此，让我们使用以下命令启动消费者节点
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: When you look at the console output now being generated, you should see that
    the node name included in the console output will vary. The variation reflects
    that the log events are from two different Fluentd nodes, as we made the tag values
    dynamic in the configuration.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当您查看现在生成的控制台输出时，应该看到包含在控制台输出中的节点名称会有所不同。这种变化反映了日志事件来自两个不同的Fluentd节点，因为我们已在配置中使标签值动态化。
- en: NOTE The application of the msgpack plugin will help reduce network traffic,
    as a formatter can be set to msgpack for the forward plugin. The receiving forward
    plugin can recognize msgpack-formatted events and automatically unpack them. As
    a result, Fluentd-to-Fluentd traffic is transmitted very efficiently.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：msgpack插件的应用将有助于减少网络流量，因为可以将格式化器设置为msgpack用于转发插件。接收转发插件可以识别msgpack格式的事件并自动解包它们。因此，Fluentd到Fluentd的流量传输非常高效。
- en: 7.2.2 Fan-out and workload distribution
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.2 扇出和工作负载分配
- en: We can see how we can increase the compute effort available to Fluentd processes
    by offloading work from a node collocated with the application workload to one
    or more dedicated Fluentd servers, as figure 7.6 illustrates. If we’re simply
    offloading work, it may be worth using Fluent Bit as the application’s collocated
    log collector. Fluent Bit is smaller, and if it can collect the log events (remember
    Fluent Bit is more restricted in plugin options), it can easily forward to Fluentd.
    We then use the downstream Fluentd to do the hard work of processing the log events.
    Revisit chapter 1 to review Fluent Bit’s differences from Fluentd.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，通过将与应用工作负载位于同一节点的任务卸载到一个或多个专用 Fluentd 服务器上，我们可以如何增加可供 Fluentd 进程使用的计算工作量，如图
    7.6 所示。如果我们只是卸载工作，那么使用 Fluent Bit 作为应用协同日志收集器可能是有意义的。Fluent Bit 更小，如果它能收集日志事件（记住
    Fluent Bit 在插件选项上更为受限），它就可以轻松地转发到 Fluentd。然后我们使用下游的 Fluentd 来处理日志事件。回顾第 1 章以了解
    Fluent Bit 与 Fluentd 的不同之处。
- en: '![](../Images/CH07_F06_Wilkins.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F06_Wilkins.png)'
- en: Figure 7.6 Deployment options for work distribution allow the allocation of
    more compute power to Fluentd’s processing of log events without impacting the
    originating application(s), as we can route log events to more servers with dedicated
    capacity for Fluentd.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.6 工作分布的部署选项允许将更多计算能力分配给 Fluentd 处理日志事件，而不会影响原始应用程序，因为我们可以将日志事件路由到更多具有专用
    Fluentd 容量的服务器]'
- en: The application of a fan-out pattern is unusual, at least in our experience.
    If you find yourself using unusual configurations, it is worth reviewing the situation
    to ensure there isn’t a larger issue. For example, restrictive default resource
    allocation forces the need to fan out, but easing or removing the restrictions
    could eliminate some distribution complexity.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 扇出模式的运用并不常见，至少在我们经验中是这样。如果你发现自己正在使用不寻常的配置，那么审查情况以确保没有更大的问题是很值得的。例如，限制默认资源分配迫使需要扇出，但放宽或移除限制可以消除一些分布复杂性。
- en: Fluentd configuration for fan-out
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 扇出配置的 Fluentd
- en: With both fan-out and high-availability deployments, we need to have the ability
    to send workload to potentially multiple nodes. In the context of high availability,
    sending traffic to a different node will be triggered by communication loss, and
    in fan-out, the connectivity is driven by workload sharing. Let us examine both
    requirements, as there is some commonality in the configuration. As shown in figure
    7.7, this time we will deploy only one node with the dummy source generator, but
    route log events to multiple consumer nodes that will output to the console.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在扇出和高可用性部署中，我们需要有能力将工作负载发送到可能多个节点。在高可用性的上下文中，发送流量到不同的节点将由通信丢失触发，而在扇出中，连接性是由工作负载共享驱动的。让我们检查这两个要求，因为它们在配置上存在一些共性。如图
    7.7 所示，这次我们将只部署一个带有虚拟源生成器的节点，但将日志事件路由到多个消费者节点，这些节点将输出到控制台。
- en: '![](../Images/CH07_F07_Wilkins.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F07_Wilkins.png)'
- en: Figure 7.7 Our example configuration of Fluentd fan-out with one node passing
    log events to multiple nodes to process
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.7 Fluentd 扇出示例配置，一个节点将日志事件传递给多个节点进行处理]'
- en: The key difference between this and the previous source node configuration is
    that the configuration of the `forward` plugin will now need multiple servers
    specified. In high availability, which node should be considered the primary and
    which should be the standby must be addressed. For fan-out, we may want to weigh
    the workload in favor of one node over another. All of this can be done within
    the configuration through properties. For multiple servers, as shown in listing
    7.4, we can simply declare multiple contiguous blocks of attributes for the server
    helper plugin `<server>`*.* As this is a basic fan-out, we have added a `weight`
    attribute to establish a ratio of workload between the servers. In our case, that
    ratio is 10:1\. If unspecified, then all the nodes get the same weighting applied.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前源节点配置的关键区别在于，`forward` 插件的配置现在需要指定多个服务器。在高可用性中，哪个节点应被视为主节点，哪个节点应作为备用节点必须得到解决。对于扇出，我们可能希望权衡一个节点相对于另一个节点的工作负载。所有这些都可以通过属性在配置中完成。对于多个服务器，如图
    7.4 所示，我们可以简单地声明多个连续的服务器辅助插件 `<server>` 的属性块。由于这是一个基本的扇出，我们已添加一个 `weight` 属性来建立服务器之间工作负载的比例。在我们的例子中，这个比例是
    10:1。如果未指定，则所有节点将应用相同的权重。
- en: Listing 7.4 Chapter7/Fluentd/dummy-forward2.conf—illustrating forward to multiple
    servers
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.4 Chapter7/Fluentd/dummy-forward2.conf—展示向多个服务器转发
- en: '[PRE7]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ First server definition with its differing ports so we can run on the same
    host
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 首个服务器定义及其不同的端口，这样我们就可以在同一主机上运行
- en: ❷ Defining the weighting, which will favor the first server configuration. If
    unset, this value defaults to 60.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 定义权重，这将优先选择第一个服务器配置。如果未设置，此值默认为60。
- en: ❸ Defines alternate port
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义备用端口
- en: ❹ Weighting set to bias traffic away from this server
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 权重设置为将流量从该服务器偏移
- en: As we’re running everything on the same machine, the Fluentd instances forming
    the fan side will need to be configured to operate on different network ports
    to avoid conflicts. A production-like environment with the Fluentd instances is
    configured to run on separate servers but using the same network port. Utilizing
    the naming trick we saw in listing 7.2, we can make the value configuration-driven
    and avoid needing multiple configuration files with different values. As a result,
    each node will need an environment variable called `NodePort`, defining one of
    the ports used on the source side of the node configuration, as shown in the following
    listing.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将在同一台机器上运行所有内容，因此形成扇出侧的Fluentd实例需要配置为在不同的网络端口上运行，以避免冲突。类似生产环境的Fluentd实例配置为在单独的服务器上运行，但使用相同的网络端口。利用我们在7.2列表中看到的命名技巧，我们可以使值配置驱动，避免需要具有不同值的多个配置文件。因此，每个节点都需要一个名为`NodePort`的环境变量，定义节点配置源侧使用的端口之一，如下所示。
- en: Listing 7.5 Chapter7/Fluentd/forward-stdout2.conf
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.5 第7章/Fluentd/forward-stdout2.conf
- en: '[PRE8]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Setting the port number up dynamically allows us to run the same configuration
    twice.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 动态设置端口号允许我们运行相同的配置两次。
- en: Let’s see what happens with this configuration of nodes. Start the source node
    with the command
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这种节点配置会发生什么。使用命令启动源节点。
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Then we need to configure a shell with the command `set NodePort=28080` for
    Windows or `export NodePort=28080` in a Linux-based environment. Once this is
    set, we can start the Fluentd instance with the command
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要为Windows配置一个带有命令`set NodePort=28080`的shell，或者在基于Linux的环境中配置`export NodePort=28080`。一旦设置完成，我们就可以使用命令启动Fluentd实例。
- en: '[PRE10]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We then repeat the steps again, replacing `28080` with `38080` in the set/export
    step.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们然后再次重复这些步骤，在设置/导出步骤中将`28080`替换为`38080`。
- en: Once everything is running, the log events should appear on the consoles of
    the Fluentd instances running the `dummy-forward2.conf` configuration. With the
    ratio set, we should see that the logs are heavily biased to the node running
    on port 28080\. But if you count how many updates go to one console over the other,
    you’re not guaranteed to see every output on the server using the 38080 port and
    ten on the other, as the ratio is calculated every time we want to send an output.
    The calculation then yields a value that will dictate on which side of the ratio
    it will fall.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一切运行起来后，日志事件应该出现在运行`dummy-forward2.conf`配置的Fluentd实例的控制台上。设置比例后，我们应该看到日志大量偏向运行在端口28080上的节点。但是，如果你计算一个控制台到另一个控制台的更新数量，你不能保证看到使用38080端口的每个输出和另一个使用10个，因为比例是在我们想要发送输出时计算的。计算的结果将决定比例哪一侧。
- en: Roundrobin Plugin
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 轮询插件
- en: Another way of distributing the workload is to leverage the *roundrobin* plugin.
    This plugin is a core Fluentd output plugin that works with the `store` helper
    plugin. This is illustrated in the following listing, with a `roundrobin` rotating
    the outputs to each individually identified server. As this is for a fan-out implementation,
    each `store` block will use a `forward` plugin, but that isn’t mandatory.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种分配工作负载的方法是利用*轮询*插件。这是一个核心Fluentd输出插件，与`store`辅助插件一起工作。以下列表展示了这一点，其中`roundrobin`将输出轮询到每个单独识别的服务器。由于这是扇出实现，每个`store`块将使用一个`forward`插件，但这不是强制性的。
- en: Listing 7.6 Chapter7/Fluentd/dummy-forward3.conf—illustrating the use of roundrobin
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.6 第7章/Fluentd/dummy-forward3.conf—展示轮询的使用
- en: '[PRE11]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ To get the roundrobin behavior, we need to use it as the output plugin. It
    will then use each store helper plugin in turn, in the same way as the copy plugin
    uses all the store helpers.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 要获得轮询行为，我们需要将其用作输出插件。然后，它将依次使用每个存储辅助插件，就像复制插件使用所有存储辅助插件一样。
- en: ❷ Declares the store configuration, but as we want the roundrobin to use each
    target equally, the configuration for a store can have only one server.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 声明存储配置，但由于我们希望轮询平均使用每个目标，存储的配置只能有一个服务器。
- en: ❸ The server definition for the destination
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 目标服务器的定义
- en: ❹ The second server configured to be using a different port
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 配置为使用不同端口的第二个服务器
- en: Let’s look at how the `roundrobin` behaves in comparison to the weighting. We
    need to start up as before; if the console for the two fan nodes doesn’t have
    the variable set for `NodePort`*,* we need to reestablish the settings. We then
    start the event source Fluentd instance with the command
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`roundrobin`与权重的行为对比。我们需要像之前一样启动；如果两个扇出节点的控制台没有为`NodePort`设置变量，我们需要重新建立设置。然后我们使用以下命令启动事件源Fluentd实例：
- en: '[PRE12]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then start the two instances of the fan node using the same command:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用相同的命令启动两个扇出节点实例：
- en: '[PRE13]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This time the output will consistently go to the alternate console outputs as
    the `roundrobin` deliberately ensures the allocation is consistently even. The
    use of the `weight` attribute can also be applied, but this does undermine the
    `roundrobin` behavior.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这次输出将始终一致地发送到备用控制台输出，因为`roundrobin`故意确保分配始终均匀。也可以应用`weight`属性，但这会破坏`roundrobin`的行为。
- en: 7.2.3 High availability
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.3 高可用性
- en: 'The configuration for the high-availability arrangement is not that different
    from the fan-out. Rather than using the `weight` attribute to distribute the workload,
    we use the `standby` attribute and set one node to have the value true and the
    other false. An example of the server part of a match plugin can be seen here:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 高可用性配置与扇出配置并没有太大的区别。我们不是使用`weight`属性来分配工作负载，而是使用`standby`属性，并将一个节点设置为true，另一个节点设置为false。这里可以看到一个匹配插件服务器部分的示例：
- en: '[PRE14]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As the fragment shows, we have defined two servers; for example, using the forward
    output plugin would be two instances of Fluentd to send log events to. When the
    Fluentd instance with this configuration starts up, it will try to send the log
    events using the server named `myserver1`, as it is marked as not being the standby.
    However, if this Fluentd instance experiences communication issues with `myserver1`,
    it will send the log events to the `standby` called `myserver2`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如片段所示，我们定义了两个服务器；例如，使用转发输出插件将是两个Fluentd实例，将日志事件发送到。当具有此配置的Fluentd实例启动时，它将尝试使用名为`myserver1`的服务器发送日志事件，因为它被标记为不是备用服务器。然而，如果此Fluentd实例与`myserver1`出现通信问题，它将把日志事件发送到名为`myserver2`的备用服务器。
- en: In this fragment, we have used the `name` attribute. The name is normally used
    only for Fluentd logging and certificate verification. But as you can see, using
    the `name` attribute can also help you determine which server is which, particularly
    when IP addresses rather than meaningful DNS names are being used.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个片段中，我们使用了`name`属性。通常，名称仅用于Fluentd日志记录和证书验证。但如您所见，使用`name`属性也可以帮助您确定哪个服务器是哪个，尤其是在使用IP地址而不是有意义的DNS名称时。
- en: 7.2.4 Putting a high-availability comparison into action
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.4 将高可用性比较付诸实践
- en: Your customer wants to see how a high-availability configuration differs in
    setup and behavior. Your team has agreed that configuration files `Chapter7/Fluentd/dummy-forward2.conf`
    and `Chapter7/Fluentd/forward-stdout2.conf` should be refactored to provide the
    comparison.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 您的客户想了解高可用性配置在设置和行为上的差异。您的团队已同意将配置文件`Chapter7/Fluentd/dummy-forward2.conf`和`Chapter7/Fluentd/forward-stdout2.conf`重构，以提供比较。
- en: Once the configuration has been refactored, run the two configurations and shut
    down individual instances of `Chapter7/Fluentd/forward-stdout2.conf`. Note the
    resultant behavior to show the customer the differences.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦配置被重构，运行这两个配置并关闭`Chapter7/Fluentd/forward-stdout2.conf`的单个实例。注意结果行为，以向客户展示差异。
- en: Answer
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 答案
- en: The configuration to illustrate high availability based upon `Chapter7/Fluentd/dummy-forward2.conf`
    and `Chapter7/Fluentd/forward-stdout2.conf` can be found in `Chapter7/ExerciseResults/dummy-forward2-Answer.conf`
    and `Chapter7/ExerciseResults/forward-stdout2-Answer.conf`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 基于配置文件`Chapter7/Fluentd/dummy-forward2.conf`和`Chapter7/Fluentd/forward-stdout2.conf`的高可用性配置示例可以在`Chapter7/ExerciseResults/dummy-forward2-Answer.conf`和`Chapter7/ExerciseResults/forward-stdout2-Answer.conf`中找到。
- en: The only change of importance in the configuration is removing the `weight`
    attribute and introducing the attribute `standby` set to `true` or `false` in
    the relevant server configuration. The difference can be observed as soon as the
    nodes have started (it’s best to start `dummy-forward2-Answer.conf node using
    port 38080`, so it doesn’t immediately think the primary destination node is down
    and switch to the reserve). The console output will only show up on the node listening
    to port 28080\. However, when this node is shut down, the log events will pass
    to the Fluentd instance working on port 38080.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 配置中唯一重要的更改是移除`weight`属性，并在相关服务器配置中引入设置为`true`或`false`的`standby`属性。差异可以在节点启动后立即观察到（最好使用端口38080启动`dummy-forward2-Answer.conf`节点，这样它不会立即认为主目标节点已关闭并切换到备用）。控制台输出将只出现在监听端口28080的节点上。然而，当此节点关闭时，日志事件将传递到在端口38080上工作的Fluentd实例。
- en: 7.3 Fluentd scaling in containers vs. native and virtual environments
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 容器、本地和虚拟环境中的Fluentd扩展
- en: So far, we’ve looked at how we can scale Fluentd from a pure Fluentd node-to-node
    perspective. In most cases where you’re working in a virtualized or native hardware
    environment, you can use the configurations as shown with Fluentd or Fluent Bit
    instances deployed. These deployments can be described as having Fluentd collocated
    with the application running on a VM or server. Each node is capturing the application
    log events along with those from the host OS. As a result, scaling out the VMs
    or native servers will drive the scale-out of Fluentd.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了如何从纯Fluentd节点到节点的角度扩展Fluentd。在大多数你工作在虚拟化或本地硬件环境的情况下，你可以使用Fluentd或Fluent
    Bit实例部署的配置。这些部署可以描述为Fluentd与应用程序一起运行在虚拟机或服务器上。每个节点都在捕获应用程序日志事件以及来自宿主操作系统的日志事件。因此，扩展虚拟机或本地服务器将驱动Fluentd的扩展。
- en: We have more options and considerations for containerized environments such
    as Kubernetes, as containers are typically more finely grained (therefore, more
    containers are needed for a complete solution). We have an additional abstraction
    layer in the form of pods, and the orchestration is far more sophisticated. While
    we’ll focus on Kubernetes, the principles aren’t very different for OpenShift
    and other related products.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Kubernetes等容器化环境，我们有更多的选项和考虑因素，因为容器通常更细粒度（因此，需要一个完整的解决方案需要更多的容器）。我们有一个额外的抽象层，即pods，编排要复杂得多。虽然我们将专注于Kubernetes，但原则对于OpenShift和其他相关产品并没有很大不同。
- en: 7.3.1 Kubernetes worker node configuration
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.1 Kubernetes工作节点配置
- en: Not only do your applications need to log content, but so, too, does the orchestration
    layer, such as Kubernetes, Apache Mesos, Docker Swarm, and others (including the
    container engine itself). As a result, the Kubernetes engine creates special services
    that it uses on each worker node. The deployment would then look as shown in figure
    7.8\. All the log events in the individual containers must be directed to stdout
    for this deployment to work.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅你的应用程序需要记录内容，编排层，如Kubernetes、Apache Mesos、Docker Swarm等（包括容器引擎本身）也需要。因此，Kubernetes引擎在每个工作节点上创建了特殊的服务，它使用这些服务。部署将看起来如图7.8所示。所有单个容器中的日志事件都必须指向stdout，以便此部署能够工作。
- en: '![](../Images/CH07_F08_Wilkins.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![Wilkins图](../Images/CH07_F08_Wilkins.png)'
- en: Figure 7.8 Illustration of Fluentd deployed as a daemon service in a Kubernetes
    context. Fluentd collects all the pod stdout and stderr outputs.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 Fluentd作为守护进程服务在Kubernetes环境中的部署示意图。Fluentd收集所有Pod的stdout和stderr输出。
- en: 7.3.2 Per-cluster configuration
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.2 集群配置
- en: The per-cluster model looks a lot like the worker node configuration but is
    a little more structured. The structure is due to the containers writing to a
    defined location via mapping rather than simply trusting stdout and stderr and
    hoping something is listening in. It is also a little easier to segment the different
    types of logs and infer some meaning as a result. The containers now just need
    to mount the cluster-wide file system and write their logs to files as they would
    if running locally (mapping the local filesystem to shared storage is a Kubernetes
    configuration issue).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 每个集群模型看起来很像工作节点配置，但结构更严谨。这种结构是由于容器通过映射写入定义的位置，而不是简单地信任stdout和stderr，并希望有人正在监听。这也使得对不同类型的日志进行分段并从中推断出一些意义变得更容易。现在容器只需要挂载集群范围内的文件系统，并将它们的日志写入文件，就像它们在本地运行时一样（将本地文件系统映射到共享存储是Kubernetes配置问题）。
- en: With logs being written to the filesystem, a pod with a Fluentd container simply
    uses the tail plugin(s) to capture and process the log files. With good directory
    and/or file naming, we can define specific details about the log file format.
    Knowing the log file origin determines the kind of things that are particularly
    important. This approach is illustrated in figure 7.9.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 当日志被写入文件系统时，带有Fluentd容器的pod只需使用tail插件（s）来捕获和处理日志文件。通过良好的目录和/或文件命名，我们可以定义关于日志文件格式的具体细节。了解日志文件来源可以确定特别重要的事情。这种做法在图7.9中得到了说明。
- en: '![](../Images/CH07_F09_Wilkins.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![图7.3.3](../Images/CH07_F09_Wilkins.png)'
- en: Figure 7.9 Kubernetes cluster shared log capture, where pods write to the file
    system and a Fluentd pod then gathers the files and processes
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9 Kubernetes集群共享日志捕获，其中pod将数据写入文件系统，然后Fluentd pod收集文件并进行处理
- en: In figure 7.9, we reference SAN (storage attached network), which would be ideal
    for on-premises deployments. It will give you disk redundancy and, typically,
    storage allocating the physical disks, giving high performance. In a cloud context,
    you would implement this with block or file style storage and trust the quality
    of service and performance controls the cloud provider offers.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在图7.9中，我们提到了存储附加网络（SAN），这对于本地部署来说是非常理想的。它将提供磁盘冗余，并且通常情况下，存储会分配物理磁盘，从而提供高性能。在云环境中，您将使用块或文件存储样式来实现，并信任云提供商提供的质量服务和性能控制。
- en: 7.3.3 Container as virtualization
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.3 容器作为虚拟化
- en: This reflects the simple idea of taking an existing environment and configuring
    it within a container, converting a virtual machine with its own OS to a container
    that delegates OS work to the shared host. So, a logical deployment could look
    like figure 7.10, with each container hosting the application and Fluentd, or,
    more preferably, Fluent Bit if it has the right adaptors and a smaller footprint.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这反映了将现有环境作为现有环境并配置在容器中的简单想法，将具有自己操作系统的虚拟机转换为将操作系统工作委托给共享主机的容器。因此，逻辑部署可能看起来像图7.10，其中每个容器托管应用程序和Fluentd，或者更理想的是Fluent
    Bit，如果它具有适当的适配器和更小的占用空间。
- en: '![](../Images/CH07_F10_Wilkins.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图7.9](../Images/CH07_F10_Wilkins.png)'
- en: Figure 7.10 Fluentd in a container, as you might do in a virtualized application
    deployment
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10 容器中的Fluentd，正如您在虚拟化应用程序部署中所做的那样
- en: 7.3.4 Sidecar pattern
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.4 边车模式
- en: Container-based technologies such as Kubernetes have pod design patterns, such
    as the *sidecar* ([http://mng.bz/nYNK](http://mng.bz/nYNK)). The idea of the sidecar
    pattern is that within the pod of containers, there are containers added to provide
    support services; this can include a proxy layer supplying security to logging.
    This would mean a container with Fluentd or Fluent Bit would exist supporting
    all the other containers within the pod, as illustrated in figure 7.11\. This
    is the most flexible and, for Fluentd, the easiest to configure but does require
    more sophistication in the configuration of containers and pods.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 基于容器的技术，如Kubernetes，有pod设计模式，如*边车* ([http://mng.bz/nYNK](http://mng.bz/nYNK))。边车模式的想法是在容器pod内部添加容器以提供支持服务；这可以包括提供安全性的代理层；这意味着将存在一个带有Fluentd或Fluent
    Bit的容器，以支持pod内的所有其他容器，如图7.11所示。这是最灵活的，对于Fluentd来说，配置也最容易，但需要容器和pod配置的更多复杂性。
- en: '![](../Images/CH07_F11_Wilkins.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图7.11](../Images/CH07_F11_Wilkins.png)'
- en: Figure 7.11 Make Fluentd available to all the containers in a pod using the
    sidecar pattern illustrated here.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.11 使用此处所示的边车模式，使Fluentd对所有pod中的容器可用。
- en: 7.3.5 Options comparison
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.5 选项比较
- en: Having looked at the different deployment models, we should take the time to
    understand the pros and cons of the different approaches. In table 7.1, we’ve
    taken each of the patterns described and pulled out the pros and cons of both
    Fluentd and Fluent Bit.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看不同的部署模型后，我们应该花时间了解不同方法的优缺点。在表7.1中，我们提取了所描述的每个模式的优缺点，包括Fluentd和Fluent Bit。
- en: Table 7.1 Fluentd deployment options in a containerized environment
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.1 容器化环境中的Fluentd部署选项
- en: '| Approach | Pros | Cons |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 优点 | 缺点 |'
- en: '| Fluentd as part of the worker node | Simplest in terms of deployment, as
    it involves only the worker node.No need to change pods or containers to deploy
    patches to Fluentd. | Requires more work to translate logs back into more meaningful
    structures.To apply meaning to log events requires some context, such as an understanding
    of the application or service. The downside is that the application context resides
    outside the application domain (the services used).Fluentd patching configuration
    changes impact the entire worker node. |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Fluentd 作为工作节点的一部分 | 在部署方面最简单，因为它只涉及工作节点。无需更改 pod 或容器即可部署 Fluentd 的补丁。 |
    将日志转换回更有意义的结构需要更多的工作。要为日志事件赋予意义需要一些上下文，例如理解应用程序或服务。缺点是应用程序上下文位于应用程序域（使用的服务）之外。Fluentd
    补丁配置更改会影响整个工作节点。 |'
- en: '| Fluentd in the application container | Isolates configuration to the smallest
    component. | A larger compute footprint, running lots of instances of Fluentd—this
    makes Fluent Bit a better proposition. |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 应用容器中的 Fluentd | 将配置隔离到最小的组件。 | 更大的计算占用空间，运行大量 Fluentd 实例——这使得 Fluent Bit
    成为一个更好的选择。 |'
- en: '| Fluent Bit in the application container | Isolates configuration to the smallest
    component.Smaller footprint than Fluentd. | Total compute effort increases compared
    to the other models. But smaller than Fluentd.Limitations in terms of types of
    inputs that can be consumed, as the plugin options are smaller.Fluent Bit is not
    as rich as Fluentd concerning available plugs, limiting the processes performed
    on the log events. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 应用容器中的 Fluent Bit | 将配置隔离到最小的组件。比 Fluentd 占用更小的空间。 | 与其他模型相比，总计算工作量增加。但比
    Fluentd 小。在可消费的输入类型方面存在限制，因为插件选项较少。Fluent Bit 在可用的插件方面不如 Fluentd 丰富，限制了在日志事件上执行的过程。
    |'
- en: '| Fluentd as a sidecar | Minimizes the number of Fluentd instances within a
    pod.Service awareness is linked to an application’s pod (e.g., intercepting specific
    log events).Potential to use a generic Fluentd container and leverage configuration
    to dynamically retrieve configuration. | More complex pod configuration.Fluentd
    patch process is more complex, as it has an impact on the pod.The container will
    be a bit larger than a Fluent Bit variant. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Fluentd 作为边车 | 最小化 pod 内 Fluentd 实例的数量。服务意识与应用程序的 pod 相关联（例如，拦截特定的日志事件）。有可能使用通用的
    Fluentd 容器并利用配置动态检索配置。 | 更复杂的 pod 配置。Fluentd 补丁过程更复杂，因为它会影响 pod。容器将比 Fluent Bit
    变体稍大。 |'
- en: '| Fluent Bit as a sidecar | Minimizes the number of Fluentd instances within
    a pod.Service awareness is linked to an application’s pod definition (e.g., intercepting
    specific log events).Smaller footprint than Fluentd.Log event handling is within
    the application context.Potential to use a generic Fluentd container and leverage
    configuration to dynamically retrieve configuration. | More complex pod configuration.Fluentd
    patch process is more complex, as it will impact each pod. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Fluent Bit 作为边车 | 最小化 pod 内 Fluentd 实例的数量。服务意识与应用程序的 pod 定义相关联（例如，拦截特定的日志事件）。比
    Fluentd 占用更小的空间。日志事件处理在应用程序上下文中进行。有可能使用通用的 Fluentd 容器并利用配置动态检索配置。 | 更复杂的 pod 配置。Fluentd
    补丁过程更复杂，因为它会影响每个 pod。 |'
- en: 7.4 Securing traffic between Fluentd nodes
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 保护 Fluentd 节点之间的流量
- en: When communicating between Fluentd nodes, you’ll likely want to provide some
    level of security. Using unsecured network traffic can result in credentials being
    exposed, not only as part of authenticating between Fluentd nodes, but also between
    Fluentd and source or targets such as Elasticsearch. We have made it very easy
    for someone to acquire the credentials when listening to network traffic. Not
    only are credentials exposed, but the communicated log information will also provide
    an attacker with the means to work out how your solution may work, harvesting
    sensitive data if the log events are for auditing, and so on. Using HTTPS encryption
    with TLS, the successor to SSL (Secure Sockets Layer), can mitigate these issues.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当在 Fluentd 节点之间通信时，你可能希望提供一定级别的安全性。使用未加密的网络流量可能导致凭证泄露，这不仅会影响 Fluentd 节点之间的身份验证，还会影响
    Fluentd 与源或目标（如 Elasticsearch）之间的通信。我们已使获取凭证变得非常容易，当监听网络流量时。不仅凭证会泄露，而且传递的日志信息还会为攻击者提供了解决方案，了解你的解决方案可能如何工作，如果日志事件用于审计，则可能收集敏感数据等。使用
    HTTPS 加密和 TLS（安全套接字层）的继任者可以缓解这些问题。
- en: If your log events include PII data, a proactively secure configuration will
    be needed for the application and the log events during transmission and when
    stored. You have all of these considerations in addition to the possibility that
    log events may be communicated between clouds and data centers over insecure networks
    (i.e., the internet). But security should not come down to just adopting TLS or,
    better still, mutual TLS (mTLS), as we’ll see shortly.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的日志事件包含 PII 数据，则在传输和存储期间，应用程序和日志事件需要采取积极的安全配置。除了日志事件可能在云和数据中心之间通过不安全的网络（即互联网）进行通信的可能性之外，您还需要考虑所有这些因素。但安全性不应仅仅局限于采用
    TLS，或者更好的是，相互 TLS（mTLS），正如我们很快将看到的。
- en: Setting up TLS is not the scary black art that it once was, possibly in part
    because we’ve moved past the idea of SSL/TLS termination at the network edge,
    and the compute overhead of encrypting and decrypting is not seen as being so
    onerous now. But configuring SSL/TLS is still rather context-sensitive and does
    require some basic understanding of TLS ideas (a subject addressed in depth in
    other books, such as *Securing DevOps* by Julien Vehent, available at [www.manning.com/books/securing-devops](https://www.manning.com/books/securing-devops)).
    So rather than a lengthy process of going through a TLS configuration that will
    work for everyone, we’ll take a brief look at the support provided. (Appendix
    E provides links to a range of resources that can help you apply TLS yourself.)
    With contemporary security approaches adopting a trust-no-one stance, it is worth
    investing time in establishing TLS security.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 TLS 已不再是曾经那样令人畏惧的神秘技艺，部分原因可能是因为我们已经超越了在网络安全边缘终止 SSL/TLS 的想法，加密和解密的计算开销现在不再被视为如此繁重。但配置
    SSL/TLS 仍然相当依赖于上下文，并且确实需要一些对 TLS 概念的基本理解（这是在其他书籍中深入探讨的主题，例如 Julien Vehent 的《Securing
    DevOps》，可在 [www.manning.com/books/securing-devops](https://www.manning.com/books/securing-devops)
    购买）。因此，我们不会详细讨论适用于每个人的 TLS 配置过程，而是简要地看一下提供的支持。（附录 E 提供了各种资源的链接，可以帮助您自己应用 TLS。）随着当代安全方法采用“信任无一人”的立场，投入时间建立
    TLS 安全性是值得的。
- en: 7.4.1 TLS configuration
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.1 TLS 配置
- en: 'When it comes to configuring network transport, we can provide a set of transport
    configurations. Some adaptors leverage the helper plugin directly, and as a result,
    sometimes offer slightly different attribute names. For example, `secure_forward`
    uses `tls_version` in the server part of its configuration. In contrast, the attribute
    is called `version` when using the transport helper directly (which can be provided
    in source, filter, and match directives). The transport construct is represented
    in the configuration within XML brackets and includes an element indicating the
    type of transport (`udp`, `tcp`, `tls`). For example:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到配置网络传输时，我们可以提供一系列传输配置。一些适配器直接利用辅助插件，因此有时会提供略微不同的属性名称。例如，`secure_forward`
    在其配置的服务器部分使用 `tls_version`。相比之下，当直接使用传输助手时（这可以在源、过滤器和匹配指令中提供），该属性被称为 `version`。传输结构在配置中以
    XML 标签表示，并包括一个指示传输类型（`udp`、`tcp`、`tls`）的元素。例如：
- en: '[PRE15]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: While we’ve been focusing on TLS and the plugins that abstract more of the network,
    we can process TCP (Transmission Control Protocol) or UDP (User Datagram Protocol)
    traffic. Still, these require more configuration effort to use.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们一直专注于 TLS 以及抽象更多网络功能的插件，但我们也可以处理 TCP（传输控制协议）或 UDP（用户数据报协议）流量。然而，这些协议的使用需要更多的配置工作。
- en: More on TCP and UDP
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 TCP 和 UDP 的更多信息
- en: 'For more information on how these protocols can be used, the following resources
    will help:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何使用这些协议的更多信息，以下资源将有所帮助：
- en: '[www.vpnmentor.com/blog/tcp-vs-udp/](https://www.vpnmentor.com/blog/tcp-vs-udp/)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[www.vpnmentor.com/blog/tcp-vs-udp/](https://www.vpnmentor.com/blog/tcp-vs-udp/)'
- en: '[www.cs.dartmouth.edu/~campbell/cs60/socketprogramming.html](https://www.cs.dartmouth.edu/~campbell/cs60/socketprogramming.html)'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[www.cs.dartmouth.edu/~campbell/cs60/socketprogramming.html](https://www.cs.dartmouth.edu/~campbell/cs60/socketprogramming.html)'
- en: '[www.openssl.org/docs/](https://www.openssl.org/docs/)'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[www.openssl.org/docs/](https://www.openssl.org/docs/)'
- en: TLS version and algorithm
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: TLS 版本和算法
- en: The version of TLS that can be supported can be controlled through the Fluentd
    configuration. TLS 1.3 (published as RFC 8446; [https://tools.ietf.org/html/rfc8446](https://tools.ietf.org/html/rfc8446)
    in August 2018) is presently the latest version of the standard published. Currently,
    TLS 1.2 is the default version used by Fluentd, reflecting that TLS 1.2 is the
    most widely adopted. Industry practice recommends using the latest version of
    TLS possible (as it is the most secure) and accomodating lower versions only where
    necessary. The TLS compatibility and cipher options can be managed via the `version`
    and `ciphers` attributes.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过Fluentd配置来控制可以支持的TLS版本。TLS 1.3（于2018年8月发布为RFC 8446；[https://tools.ietf.org/html/rfc8446](https://tools.ietf.org/html/rfc8446)）是目前发布的最新标准版本。目前，Fluentd默认使用的版本是TLS
    1.2，这反映了TLS 1.2是最广泛采用的。行业惯例建议使用可能的最新版本的TLS（因为它是最安全的），并且仅在必要时适应较低版本。TLS兼容性和加密选项可以通过`version`和`ciphers`属性来管理。
- en: Specialized forward plugin for SSL/TLS
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 专门的前向插件用于SSL/TLS
- en: 'There is a secured version of the forward plugin for both in and out actions,
    as previously referenced. This can be deployed like all plugins using gem. For
    example:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 前向插件的安全版本适用于入站和出站操作，如前所述。这可以使用gem部署，就像所有插件一样。例如：
- en: '[PRE16]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This version of the plugin still requires certificates but simplifies the configuration
    and masks the transport layer configuration section.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 此版本的插件仍然需要证书，但简化了配置并隐藏了传输层配置部分。
- en: 7.4.2 TLS not just for encryption
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.2 TLS不仅仅是加密
- en: Using TLS isn’t just for providing an encryption key but can and should be verified
    as an authentic certificate from a certificate authority (CA) for the server using
    it. Typically, part of the handshake is when the client and server connect. If
    the effort in confirming a certificate’s authenticity with the certificate authority
    is harming latency, then you might consider disabling the check if you’re entirely
    within a trusted network environment (e.g., a physical private data center network,
    but not a cloud-hosted network). Switching such checks off does go against the
    concepts of security in-depth, so consider what risks this may bring. You’ll need
    to go further if you use self-signed certificates, as there is no CA involved.
    Additional attributes—`tls_insure_mode` and `tls_allow_self_signed_cert`—are needed
    to prevent Fluentd from checking the certificate with a CA.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TLS不仅仅是提供加密密钥，而且可以也应该验证为使用该证书的证书颁发机构（CA）提供的真实证书。通常，握手的一部分是客户端和服务器连接时。如果与证书颁发机构确认证书真实性的努力正在损害延迟，那么如果你完全处于一个受信任的网络环境中（例如，一个物理私有数据中心网络，但不是云托管网络），你可能考虑禁用检查。关闭此类检查与深度安全概念相违背，因此请考虑这可能会带来什么风险。如果你使用自签名证书，你需要走得更远，因为没有CA参与。需要额外的属性——`tls_insure_mode`和`tls_allow_self_signed_cert`——以防止Fluentd与CA检查证书。
- en: 7.4.3 Certificate and private key storage
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.3 证书和私钥存储
- en: To use a certificate, we obviously need to be able to store it and the private
    key. This information is defined as several attributes and includes accommodating
    Windows store options (for more info, see [http://mng.bz/vo6M](http://mng.bz/vo6M)).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用证书，我们显然需要能够存储它和私钥。这些信息被定义为几个属性，包括适应Windows存储选项（更多信息，请参阅[http://mng.bz/vo6M](http://mng.bz/vo6M))。
- en: Regardless of where the certificate is stored, we need to tell Fluentd where
    the certificate is located via `cert_path` (e.g., `cert_path` `./myFluentd.crt`)
    along with the private key location, via `private_key_path` (e.g., `private_key_path`
    `./myFluentd.key`). Ideally, certificates are provided by a public or private
    CA, which can be contacted to confirm the authenticity of a certificate being
    used. We can tell Fluentd whether or not it should make that verification via
    the `client_cert_auth` attribute (`true` or `false`). With a self-signed setup,
    this has to be false.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 无论证书存储在哪里，我们都需要通过`cert_path`（例如，`cert_path` `./myFluentd.crt`）告诉Fluentd证书的位置，以及私钥的位置，通过`private_key_path`（例如，`private_key_path`
    `./myFluentd.key`）。理想情况下，证书由公共或私有CA提供，可以联系以确认正在使用的证书的真实性。我们可以通过`client_cert_auth`属性（`true`或`false`）告诉Fluentd是否应该进行该验证。在自签名设置中，这必须是false。
- en: 7.4.4 Security is more than certificates
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.4 安全不仅仅是证书
- en: Securing communications is more than simply the application of TLS. Some organizations
    will require more, such as passing a username, password, and tokens. The use of
    attributes like this and token IDs can provide additional assurance. If we’re
    going to pass sensitive values like this, then the use of TLS should be considered
    mandatory.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 确保通信安全不仅仅是应用TLS。一些组织可能需要更多，例如传递用户名、密码和令牌。使用此类属性和令牌ID可以提供额外的保证。如果我们打算传递这样的敏感值，那么使用TLS应被视为强制性的。
- en: 7.5 Credentials management
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.5 凭证管理
- en: 'We have the challenge that the Fluentd configuration doesn’t have the means
    to encrypt and decrypt credentials in its configuration file. So, a username and
    password needs to appear in the configuration when Fluentd starts in cleartext.
    Any system administrator (sysadmin) aware of a file with cleartext credentials
    will not be happy, and if you work with an IT security officer, they will be even
    more concerned. Some strategies are available to limit this risk; these are the
    ones we’ve seen or adopted. The list is ordered in increasing strength of security:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们面临挑战，Fluentd配置文件没有在配置文件中加密和解密凭证的手段。因此，当Fluentd以明文形式启动时，用户名和密码需要出现在配置中。任何了解包含明文凭证的文件的系统管理员（sysadmin）都不会高兴，如果您与IT安全官员合作，他们将会更加关注。有一些策略可以限制这种风险；这些是我们看到或采用的策略。列表按照安全性的增强顺序排列：
- en: Lock down the Fluentd file so access is very tightly restricted. Remember, this
    also means blocking or restricting the use of the Fluentd UI (illustrated in chapter
    2), as well as the UI’s credentials. This approach is really the bare minimum,
    and if sensitive data such as PII is involved, it is probably not seen as acceptable.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 限制Fluentd文件的访问权限，使其非常严格。记住，这也意味着阻止或限制Fluentd UI（如图2所示）的使用，以及UI的凭证。这种方法实际上是最基本的，如果涉及敏感数据如PII，可能被认为不可接受。
- en: This is likely to need localhost users to be set up and run Fluentd or Fluent
    Bit. Such a setup brings a range of other administrative considerations.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可能需要设置和运行Fluentd或Fluent Bit的本地主机用户。这样的设置会带来一系列其他管理考虑因素。
- en: Use inclusions to separate the core configuration from the credentials. Then
    just the inclusion files need to be subject to the aggressive file access controls.
    This is an improvement, as it allows you to work with the configuration more freely.
    But this will prove to be fiddly if there are lots of credentials to handle and
    is unlikely to be considered acceptable if PII data is involved.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用包含来分离核心配置和凭证。然后只需要将包含文件提交给严格的文件访问控制。这是一个改进，因为它允许您更自由地处理配置。但如果有很多凭证要处理，这可能会变得很麻烦，如果涉及PII数据，可能被认为不可接受。
- en: Wrap the Fluentd startup with a script that, before starting Fluentd, loads
    the credentials into environmental variables within the OS session and then start
    Fluentd. The Fluentd configuration then incorporates access to the environment
    variables, as we’ve previously illustrated. As a result, the configuration file
    has no sensitive values until Fluentd parses the file. But we can incorporate
    into the script a means to source and decrypt the environment variable. This allows
    you to then utilize standard OS security features. In a containerized environment,
    this may get messy, and in a world of multiple OS types, this means potentially
    different configurations. Indeed, different scripts load the required credentials
    into memory.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用脚本包装Fluentd启动，在启动Fluentd之前，将凭证加载到OS会话中的环境变量中，然后启动Fluentd。然后Fluentd配置将包含对环境变量的访问，正如我们之前所展示的。因此，配置文件在Fluentd解析文件之前没有敏感值。但我们可以将获取和解密环境变量的方法纳入脚本中。这允许您利用标准的OS安全功能。在容器化环境中，这可能会变得复杂，在多种OS类型的世界上，这意味着可能需要不同的配置。确实，不同的脚本将所需的凭证加载到内存中。
- en: Another component typically associated with the more cloud-native approach that
    can be equally applied in traditional deployment environments is the use of Vault
    ([www.vaultproject.io](http://www.vaultproject.io)) from HashiCorp. Vault comes
    in a free (open source) version and an enterprise edition with additional features
    (synchronized distributed vaults). We can then embed it into the configuration
    file and call the Vault to retrieve the credentials needed using the Vault CLI
    or API. This alleviates the issue of needing to load into the OS environment beforehand.
    We won’t go into the detailed specifics of aligning application roles to credentials
    available in Vault, as the documentation provides an excellent explanation at
    [www.vaultproject.io/docs/auth/approle](http://www.vaultproject.io/docs/auth/approle).
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一个通常与更云原生方法相关联的组件，同样可以应用于传统部署环境，是使用 HashiCorp 的 Vault ([www.vaultproject.io](http://www.vaultproject.io))。Vault
    提供了免费（开源）版本和带有额外功能的企业版（同步分布式密钥库）。然后我们可以将其嵌入到配置文件中，并使用 Vault CLI 或 API 调用 Vault
    来检索所需的凭据。这解决了之前需要加载到操作系统环境中的问题。我们不会深入探讨如何将应用程序角色与 Vault 中可用的凭据对齐的详细具体信息，因为文档在
    [www.vaultproject.io/docs/auth/approle](http://www.vaultproject.io/docs/auth/approle)
    提供了出色的解释。
- en: If you’re working within a Kubernetes environment, then, of course, you have
    an additional option in terms of using Kubernetes secrets (more about this at
    [http://mng.bz/4j4V](http://mng.bz/4j4V)). Vault has a raft of plugins to work
    with other native credentials frameworks such as Kubernetes’s Secrets, those from
    cloud vendors, or older standards like LDAP (Lightweight Directory Access Protocol).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个 Kubernetes 环境中工作，那么当然，你还有使用 Kubernetes 机密（更多关于此的信息在 [http://mng.bz/4j4V](http://mng.bz/4j4V)）的额外选项。Vault
    有许多插件可以与其他原生凭据框架一起工作，例如 Kubernetes 的 Secrets、云供应商的凭据，或较旧的标准如 LDAP（轻量级目录访问协议）。
- en: 7.5.1 Simple credentials use case
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.1 简单凭据使用案例
- en: We can define username and password credentials as part of a security configuration
    between Fluentd nodes. This allows a Fluentd node receiving forwarded log events
    to have an increased level of trust.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将用户名和密码凭据定义为 Fluentd 节点之间安全配置的一部分。这允许接收转发日志事件的 Fluentd 节点拥有更高的信任级别。
- en: The credentials are obviously associated with a server, so in the forward output
    configuration, we provide the attributes `username` and `password` in the `server`
    attributes set. In the following listing, we have taken the `dummy-forward.conf`
    and extended it to include the credentials.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 凭据显然与服务器相关联，因此在转发输出配置中，我们在 `server` 属性集中提供了 `username` 和 `password`。在下面的列表中，我们将
    `dummy-forward.conf` 扩展以包含凭据。
- en: Listing 7.7 Chapter7/Fluentd/dummy-user-forward1.conf with user credentials
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.7 第 7 章/Fluentd/dummy-user-forward1.conf 使用用户凭据
- en: '[PRE17]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Mandatory attributes need to be provided for security, which include a logical
    name and a common key.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为了安全起见，必须提供一些必需的属性，包括逻辑名称和通用密钥。
- en: ❷ Provides the user credentials
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 提供用户凭据
- en: Building on `forward-stdout.conf`, the consumer side also needs the same credentials
    to verify against. In listing 7.8, we show the additional attributes involved.
    The consumer side will need the username and password specified and an explicit
    indication in the `security` structure using the attribute `user_auth`. The server
    logical name should expect the forwarded log event to be defined using the attribute
    `self_ hostname` and mandatory security attribute `shared_key`.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 `forward-stdout.conf`，消费者端也需要相同的凭据来验证。在列表 7.8 中，我们展示了涉及的附加属性。消费者端将需要指定的用户名和密码，并在
    `security` 结构中使用 `user_auth` 属性进行明确的指示。服务器逻辑名称应期望使用 `self_hostname` 属性定义转发日志事件，以及必需的安全属性
    `shared_key`。
- en: Listing 7.8 Chapter7/Fluentd/forward-user-stdout.conf receiving with credentials
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.8 第 7 章/Fluentd/forward-user-stdout.conf 使用凭据接收
- en: '[PRE18]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Starts the security configuration
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 启动安全配置
- en: ❷ Tells Fluentd that we must apply user authentication
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 告知 Fluentd 我们必须应用用户身份验证
- en: ❸ Declares how this node should be addressed by the client
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 声明客户端如何识别此节点
- en: ❹ Declares the credentials expected to arrive
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 声明预期到达的凭据
- en: 'We can run this configuration with one shell running:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用一个 shell 运行此配置：
- en: '[PRE19]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Along with this, we need another Fluentd running. Before starting Fluentd, the
    shell used to run Fluentd will need to `set` or `export` (Windows or Linux) `NodeName
    =Node1`. Each source node has a new number in the assignment. Then we can start
    up Fluentd with
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还需要运行另一个Fluentd。在启动Fluentd之前，用于运行Fluentd的shell需要`set`或`export`（Windows或Linux）`NodeName
    =Node1`。每个源节点都有一个新的编号。然后我们可以启动Fluentd：
- en: '[PRE20]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Everything should run as it did when we ran without the user credentials. However,
    we are validating credentials on the consumer side. Stop the client side, change
    the password, and restart that Fluentd instance. This will now fail with reported
    password issues.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都应该像我们没有运行用户凭证时一样运行。然而，我们在消费者端验证凭证。停止客户端，更改密码，然后重新启动该Fluentd实例。现在这将因报告的密码问题而失败。
- en: 7.5.2 Putting certification into action
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.2 将证书投入实际应用
- en: Your company needs the Fluentd deployment to span multiple data centers so that
    the security team can use their preferred monitoring tool across the WAN. Your
    chief security officer (CSO) is pleased that an element of security is applied
    for internode communication. But they are not happy that credentials could be
    communicated in cleartext. The CSO has approved the use of Fluentd nodes spanning
    the company-wide network as long as you can provide SSL/TLS configuration to encrypt
    the traffic. The data centers do not have direct internet connectivity to enable
    validating and direct distribution of certificates from a public CA. There isn’t
    an internal CA at present, although there are discussions about one in the future.
    The infrastructure team has said that they will distribute self-signed certificates
    for you. Therefore, we will need to configure Fluentd using self-signed certificates.
    To demonstrate that the infrastructure team can meet certificates requirement
    and that they understand what is needed, it has been agreed that `dummy-user-forward1.conf`
    and `forward-user-stdout.conf` will be modified to include the use of self-signed
    certificates to prove the process.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 您的公司需要Fluentd部署跨越多个数据中心，以便安全团队能够在WAN上使用他们偏好的监控工具。您的首席安全官（CSO）对在节点间通信中应用了安全元素感到高兴。但他们不高兴的是凭证可能会以明文形式传输。CSO批准了使用跨越公司网络的Fluentd节点，只要您能提供SSL/TLS配置来加密流量。数据中心没有直接互联网连接，无法从公共CA验证和直接分发证书。目前没有内部CA，尽管未来有关于建立CA的讨论。基础设施团队表示，他们将为您分发自签名证书。因此，我们需要使用自签名证书来配置Fluentd。为了证明基础设施团队能够满足证书要求并且他们理解需要什么，已经同意修改`dummy-user-forward1.conf`和`forward-user-stdout.conf`以包含使用自签名证书的过程，以证明这个过程。
- en: Answer
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 答案
- en: Proof that the solution will work can be achieved by running the Fluentd nodes
    by replacing the certificate or key file with a dummy file. This should cause
    the data exchange to fail.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 通过用虚拟文件替换证书或密钥文件来运行Fluentd节点，可以实现证明解决方案可行的过程。这应该会导致数据交换失败。
- en: The example configuration can be found in the configuration files `Chapter7/ExerciseResults/dummy-user-forward1-Answer.conf`
    and `Chapter7/ExerciseResults/forward-user-stdout1-Answer.conf`. We have referenced
    dummy certificate files within the Fluentd configurations (if used, this will
    trigger a failure). For this to work, you will need to replace these files with
    proper certificates. As the certificates take details and have a lifetime, you
    should create your own certificates and replace the dummy file with the certificates
    you generate. This is because certificates can be linked to identities and have
    defined lifetimes. Guidance on how to do this using OpenSSL ([www.openssl.org](https://www.openssl.org))
    can be found in the liveBook version of Understanding API Security by Justin Richer
    and Antonio Sanso (Manning, 2017) at [http://mng.bz/QWvj](http://mng.bz/QWvj).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 示例配置可以在配置文件`Chapter7/ExerciseResults/dummy-user-forward1-Answer.conf`和`Chapter7/ExerciseResults/forward-user-stdout1-Answer.conf`中找到。我们在Fluentd配置中引用了虚拟证书文件（如果使用，这将触发失败）。为了使其工作，您需要用适当的证书替换这些文件。由于证书包含详细信息并且有定义的有效期，您应该创建自己的证书并用您生成的证书替换虚拟文件。这是因为证书可以与身份相关联并且有定义的有效期。关于如何使用OpenSSL（[www.openssl.org](https://www.openssl.org)）进行此操作的指南可以在Justin
    Richer和Antonio Sanso的《理解API安全》的liveBook版本中找到（Manning，2017）在[http://mng.bz/QWvj](http://mng.bz/QWvj)。
- en: An alternative approach is to adopt Let’s Encrypt, which will provide an automated
    mechanism to renew certificates ([https://letsencrypt.org/](https://letsencrypt.org/)).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是采用Let’s Encrypt，它将提供一个自动化的机制来更新证书([https://letsencrypt.org/](https://letsencrypt.org/))。
- en: In the configuration, you’ll note that we have opted to switch from the standard
    forward plugin to the secure forward plugin, so we don’t explicitly need to set
    the transport layer attributes. We have also assumed that the passphrase used
    in creating the key and certificate is `your_secret`. To change the configuration-held
    passphrase to align with what was used, you’ll need to modify the `forward-user-stdout1
    -Answer.conf`, which contains an attribute called `ca_private_key_passphrase`
    that will need the correct value.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置中，你会注意到我们选择从标准转发插件切换到安全转发插件，因此我们不需要显式设置传输层属性。我们还假设用于创建密钥和证书的密码短语是`your_secret`。要更改配置中保留的密码短语以与所使用的密码短语一致，你需要修改包含名为`ca_private_key_passphrase`属性的`forward-user-stdout1
    -Answer.conf`，该属性需要正确的值。
- en: To run the configuration, we’d need to start the Fluentd nodes with the commands
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行配置，我们需要使用以下命令启动Fluentd节点
- en: '[PRE21]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: As we’ve seen, Fluentd is very flexible for implementing scaling, distribution,
    and resilience. But with that comes the use of network connectivity. We should
    protect our network traffic as much as we work to secure individual servers or
    containers. This does mean handling certificates both for authentication and encryption.
    Certificate use can make things more challenging, but such issues will become
    a lot easier if a well-thought-out strategy is adopted, not just for monitoring
    but for the application communications as well.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，Fluentd在实现扩展、分配和弹性方面非常灵活。但这也意味着需要使用网络连接。我们应该尽可能保护我们的网络流量，就像我们努力保护单个服务器或容器一样。这意味着我们需要处理用于认证和加密的证书。证书的使用可能会使事情更具挑战性，但如果采用周密的策略，这些问题将会变得容易得多，这不仅适用于监控，也适用于应用程序通信。
- en: Summary
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Fluentd performance can be tuned by using workers running individual CPU processes
    or through thread management constrained by how Ruby works.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluentd的性能可以通过使用运行单个CPU进程的工作者或通过受Ruby工作方式约束的线程管理来调整。
- en: Workers do require some careful consideration to avoid mistakes like putting
    log events out of sequence. There are strategies to help determine how to configure
    workers so they don’t introduce new problems.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作者确实需要仔细考虑，以避免像将日志事件顺序错乱这样的错误。有一些策略可以帮助确定如何配置工作者，以便他们不会引入新的问题。
- en: Workloads can be distributed using fan-out and fan-in patterns to distribute
    or concentrate the processing of log events.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用扇出和扇入模式来分配工作负载，以分散或集中处理日志事件。
- en: High availability can be implemented using a distributed deployment of Fluentd
    nodes.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过Fluentd节点的分布式部署来实现高可用性。
- en: The same basic distribution principles can be applied within a microservices
    environment. The use of Kubernetes allows several different ways of deploying
    and using Fluentd.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相同的基本分配原则可以在微服务环境中应用。使用Kubernetes允许以多种不同的方式部署和使用Fluentd。
- en: Communication between different Fluentd and Fluent Bit instances should be made
    secure by using SSL/TLS certificates and should be further enhanced with the use
    of credentials or tokens.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同Fluentd和Fluent Bit实例之间的通信应通过使用SSL/TLS证书来确保安全，并且应进一步通过使用凭证或令牌来增强。
- en: Security should not only address communication between Fluentd nodes but should
    also extend to sending and retrieving the log events to other services, such as
    a Mongo database or Elasticsearch.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全性不仅应该解决Fluentd节点之间的通信问题，还应该扩展到向其他服务发送和检索日志事件，例如Mongo数据库或Elasticsearch。
