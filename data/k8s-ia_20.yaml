- en: Chapter 18\. Extending Kubernetes
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第18章. 扩展Kubernetes
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Adding custom objects to Kubernetes
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自定义对象添加到Kubernetes
- en: Creating a controller for the custom object
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为自定义对象创建控制器
- en: Adding custom API servers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加自定义API服务器
- en: Self-provisioning of services with the Kubernetes Service Catalog
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kubernetes服务目录进行服务自助配置
- en: Red Hat’s OpenShift Container Platform
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Red Hat的OpenShift容器平台
- en: Deis Workflow and Helm
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deis Workflow和Helm
- en: You’re almost done. To wrap up, we’ll look at how you can define your own API
    objects and create controllers for those objects. We’ll also look at how others
    have extended Kubernetes and built Platform-as-a-Service solutions on top of it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你几乎完成了。为了总结，我们将探讨如何定义自己的API对象并为这些对象创建控制器。我们还将探讨其他人如何扩展Kubernetes，并在其上构建Platform-as-a-Service解决方案。
- en: 18.1\. Defining custom API objects
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 18.1. 定义自定义API对象
- en: Throughout the book, you’ve learned about the API objects that Kubernetes provides
    and how they’re used to build application systems. Currently, Kubernetes users
    mostly use only these objects even though they represent relatively low-level,
    generic concepts.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，你已经学习了Kubernetes提供的API对象以及它们如何用于构建应用程序系统。目前，Kubernetes用户主要只使用这些对象，尽管它们代表相对低级、通用的概念。
- en: As the Kubernetes ecosystem evolves, you’ll see more and more high-level objects,
    which will be much more specialized than the resources Kubernetes supports today.
    Instead of dealing with Deployments, Services, ConfigMaps, and the like, you’ll
    create and manage objects that represent whole applications or software services.
    A custom controller will observe those high-level objects and create low-level
    objects based on them. For example, to run a messaging broker inside a Kubernetes
    cluster, all you’ll need to do is create an instance of a Queue resource and all
    the necessary Secrets, Deployments, and Services will be created by a custom Queue
    controller. Kubernetes already provides ways of adding custom resources like this.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Kubernetes生态系统的不断发展，你将看到越来越多的高级对象，这些对象将比Kubernetes今天支持的资源更加专业化。你将不再处理Deployments、Services、ConfigMaps等资源，而是创建和管理代表整个应用程序或软件服务的对象。一个自定义控制器将观察这些高级对象，并根据它们创建低级对象。例如，要在Kubernetes集群内运行消息代理，你只需要创建一个Queue资源实例，所有必要的Secrets、Deployments和Services都将由自定义Queue控制器创建。Kubernetes已经提供了添加此类自定义资源的方法。
- en: 18.1.1\. Introducing CustomResourceDefinitions
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 18.1.1. 介绍CustomResourceDefinitions
- en: To define a new resource type, all you need to do is post a CustomResourceDefinition
    object (CRD) to the Kubernetes API server. The CustomResourceDefinition object
    is the description of the custom resource type. Once the CRD is posted, users
    can then create instances of the custom resource by posting JSON or YAML manifests
    to the API server, the same as with any other Kubernetes resource.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要定义一个新的资源类型，你所需要做的就是将CustomResourceDefinition对象（CRD）发布到Kubernetes API服务器。CustomResourceDefinition对象是自定义资源类型的描述。一旦CRD被发布，用户就可以通过将JSON或YAML清单发布到API服务器来创建自定义资源的实例，就像对任何其他Kubernetes资源一样。
- en: '|  |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Prior to Kubernetes 1.7, custom resources were defined through ThirdPartyResource
    objects, which were similar to CustomResourceDefinitions, but were removed in
    version 1.8\.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes 1.7版本之前，自定义资源是通过ThirdPartyResource对象定义的，这些对象与CustomResourceDefinitions类似，但在版本1.8中被移除。
- en: '|  |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Creating a CRD so that users can create objects of the new type isn’t a useful
    feature if those objects don’t make something tangible happen in the cluster.
    Each CRD will usually also have an associated controller (an active component
    doing something based on the custom objects), the same way that all the core Kubernetes
    resources have an associated controller, as was explained in [chapter 11](index_split_087.html#filepos1036287).
    For this reason, to properly show what CustomResourceDefinitions allow you to
    do other than adding instances of a custom object, a controller must be deployed
    as well. You’ll do that in the next example.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 创建CRD以便用户可以创建新类型的对象，如果这些对象在集群中不产生任何实际效果，那么这个功能就没有什么用处。每个CRD通常也会有一个相关的控制器（一个基于自定义对象执行某些操作的活跃组件），就像所有核心Kubernetes资源都有相关的控制器一样，这在第11章中已经解释过了。因此，为了正确展示CustomResourceDefinitions允许你做什么，除了添加自定义对象的实例之外，还需要部署一个控制器。你将在下一个示例中这样做。
- en: Introducing the example CustomResourceDefinition
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍示例CustomResourceDefinition
- en: Let’s imagine you want to allow users of your Kubernetes cluster to run static
    websites as easily as possible, without having to deal with Pods, Services, and
    other Kubernetes resources. What you want to achieve is for users to create objects
    of type Website that contain nothing more than the website’s name and the source
    from which the website’s files (HTML, CSS, PNG, and others) should be obtained.
    You’ll use a Git repository as the source of those files. When a user creates
    an instance of the Website resource, you want Kubernetes to spin up a new web
    server pod and expose it through a Service, as shown in [figure 18.1](#filepos1646750).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象一下，你希望尽可能容易地让 Kubernetes 集群的用户运行静态网站，而无需处理 Pod、Service 和其他 Kubernetes 资源。你想要实现的是用户创建类型为
    Website 的对象，这些对象除了包含网站名称和获取网站文件（HTML、CSS、PNG 等）的来源之外，不包含任何其他内容。你将使用 Git 仓库作为这些文件的来源。当用户创建
    Website 资源实例时，你希望 Kubernetes 启动一个新的 web 服务器 Pod，并通过 Service 进行暴露，如图 18.1 所示 [figure
    18.1](#filepos1646750)。
- en: Figure 18.1\. Each Website object should result in the creation of a Service
    and an HTTP server Pod.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.1\. 每个 Website 对象都应导致创建一个 Service 和一个 HTTP 服务器 Pod。
- en: '![](images/00082.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00082.jpg)'
- en: To create the Website resource, you want users to post manifests along the lines
    of the one shown in the following listing.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建 Website 资源，你希望用户提交类似于以下列表中的清单。
- en: 'Listing 18.1\. An imaginary custom resource: imaginary-kubia-website.yaml'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 18.1\. 一个假想的自定义资源：imaginary-kubia-website.yaml
- en: '`kind: Website` `1` `metadata:   name: kubia` `2` `spec:   gitRepo: https://github.com/luksa/kubia-website-example.git`
    `3`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`kind: Website` `1` `metadata:   name: kubia` `2` `spec:   gitRepo: https://github.com/luksa/kubia-website-example.git`
    `3`'
- en: 1 A custom object kind
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 一个自定义对象类型
- en: 2 The name of the website (used for naming the resulting Service and Pod)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 网站的名称（用于命名生成的 Service 和 Pod）
- en: 3 The Git repository holding the website’s files
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 存放网站文件的 Git 仓库
- en: Like all other resources, your resource contains a `kind` and a `metadata.name`
    field, and like most resources, it also contains a `spec` section. It contains
    a single field called `gitRepo` (you can choose the name)—it specifies the Git
    repository containing the website’s files. You’ll also need to include an `apiVersion`
    field, but you don’t know yet what its value must be for custom resources.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有其他资源一样，你的资源包含一个 `kind` 和 `metadata.name` 字段，并且与大多数资源一样，它还包含一个 `spec` 部分。它包含一个名为
    `gitRepo` 的单个字段（你可以选择名称）——它指定包含网站文件的 Git 仓库。你还需要包含一个 `apiVersion` 字段，但你还不清楚自定义资源需要什么值。
- en: 'If you try posting this resource to Kubernetes, you’ll receive an error because
    Kubernetes doesn’t know what a Website object is yet:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试将此资源提交到 Kubernetes，你会收到错误，因为 Kubernetes 还不知道 Website 对象是什么：
- en: '`$ kubectl create -f imaginary-kubia-website.yaml` `error: unable to recognize
    "imaginary-kubia-website.yaml": no matches for` ![](images/00006.jpg) `/, Kind=Website`'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl create -f imaginary-kubia-website.yaml` `error: unable to recognize
    "imaginary-kubia-website.yaml": no matches for` ![](images/00006.jpg) `/, Kind=Website`'
- en: Before you can create instances of your custom object, you need to make Kubernetes
    recognize them.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在你可以创建自定义对象实例之前，你需要让 Kubernetes 识别它们。
- en: Creating a CustomResourceDefinition object
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 创建自定义资源定义对象
- en: To make Kubernetes accept your custom Website resource instances, you need to
    post the CustomResourceDefinition shown in the following listing to the API server.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让 Kubernetes 接受你的自定义 Website 资源实例，你需要将以下列表中的自定义资源定义提交到 API 服务器。
- en: 'Listing 18.2\. A CustomResourceDefinition manifest: website-crd.yaml'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 18.2\. 自定义资源定义清单：website-crd.yaml
- en: '`apiVersion: apiextensions.k8s.io/v1beta1` `1` `kind: CustomResourceDefinition`
    `1` `metadata:   name: websites.extensions.example.com` `2` `spec:   scope: Namespaced`
    `3` `group: extensions.example.com` `4` `version: v1` `4` `names:` `5` `kind:
    Website` `5` `singular: website` `5` `plural: websites` `5`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion: apiextensions.k8s.io/v1beta1` `1` `kind: CustomResourceDefinition`
    `1` `metadata:   name: websites.extensions.example.com` `2` `spec:   scope: Namespaced`
    `3` `group: extensions.example.com` `4` `version: v1` `4` `names:` `5` `kind:
    Website` `5` `singular: website` `5` `plural: websites` `5`'
- en: 1 CustomResourceDefinitions belong to this API group and version.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 自定义资源定义属于此 API 组和版本。
- en: 2 The full name of your custom object
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 你的自定义对象的完整名称
- en: 3 You want Website resources to be namespaced.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 你希望 Website 资源是命名空间的。
- en: 4 Define an API group and version of the Website resource.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 定义 Website 资源的 API 组和版本。
- en: 5 You need to specify the various forms of the custom object’s name.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5 你需要指定自定义对象名称的各种形式。
- en: After you post the descriptor to Kubernetes, it will allow you to create any
    number of instances of the custom Website resource.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在你将描述符发布到 Kubernetes 之后，它将允许你创建任意数量的自定义网站资源实例。
- en: 'You can create the CRD from the website-crd.yaml file available in the code
    archive:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从代码存档中提供的 website-crd.yaml 文件创建 CRD：
- en: '`$ kubectl create -f website-crd-definition.yaml` `customresourcedefinition
    "websites.extensions.example.com" created`'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl create -f website-crd-definition.yaml` `customresourcedefinition
    "websites.extensions.example.com" created`'
- en: 'I’m sure you’re wondering about the long name of the CRD. Why not call it Website?
    The reason is to prevent name clashes. By adding a suffix to the name of the CRD
    (which will usually include the name of the organization that created the CRD),
    you keep CRD names unique. Luckily, the long name doesn’t mean you’ll need to
    create your Website resources with `kind: websites.extensions.example.com`, but
    as `kind: Website`, as specified in the `names.kind` property of the CRD. The
    `extensions.example.com` part is the API group of your resource.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '我相信你一定在好奇 CRD 的长名称。为什么不叫它网站呢？原因是为了防止名称冲突。通过在 CRD 的名称后添加后缀（通常包括创建 CRD 的组织的名称），你可以保持
    CRD 名称的唯一性。幸运的是，长名称并不意味着你需要使用 `kind: websites.extensions.example.com` 来创建你的网站资源，而是按照
    CRD 中 `names.kind` 属性指定的 `kind: Website` 来创建。`extensions.example.com` 部分是你的资源
    API 组。'
- en: You’ve seen how creating Deployment objects requires you to set `apiVersion`
    to `apps/v1beta1` instead of `v1`. The part before the slash is the API group
    (Deployments belong to the `apps` API group), and the part after it is the version
    name (`v1beta1` in the case of Deployments). When creating instances of the custom
    Website resource, the `apiVersion` property will need to be set to `extensions.example.com/v1`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了创建部署对象时需要将 `apiVersion` 设置为 `apps/v1beta1` 而不是 `v1` 的原因。斜杠之前的部分是 API 组（部署属于
    `apps` API 组），斜杠之后的部分是版本名称（在部署的情况下是 `v1beta1`）。当创建自定义网站资源的实例时，需要将 `apiVersion`
    属性设置为 `extensions.example.com/v1`。
- en: Creating an instance of a custom resource
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 创建自定义资源实例
- en: Considering what you learned, you’ll now create a proper YAML for your Website
    resource instance. The YAML manifest is shown in the following listing.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到你所学到的知识，你现在将为你网站资源实例创建适当的 YAML。YAML 清单如下所示。
- en: 'Listing 18.3\. A custom Website resource: kubia-website.yaml'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 18.3\. 自定义网站资源：kubia-website.yaml
- en: '`apiVersion: extensions.example.com/v1` `1` `kind: Website` `2` `metadata:
      name: kubia` `3` `spec:   gitRepo: https://github.com/luksa/kubia-website-example.git`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion: extensions.example.com/v1` `1` `kind: Website` `2` `metadata:
      name: kubia` `3` `spec:   gitRepo: https://github.com/luksa/kubia-website-example.git`'
- en: 1 Your custom API group and version
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 你的自定义 API 组和版本
- en: 2 This manifest describes a Website resource instance.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 此清单描述了一个网站资源实例。
- en: 3 The name of the Website instance
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 网站实例的名称
- en: The `kind` of your resource is Website, and the `apiVersion` is composed of
    the API group and the version number you defined in the CustomResourceDefinition.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你的资源类型是网站，而 `apiVersion` 是由你在自定义资源定义中定义的 API 组和版本号组成的。
- en: 'Create your Website object now:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在创建你的网站对象：
- en: '`$ kubectl create -f kubia-website.yaml` `website "kubia" created`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl create -f kubia-website.yaml` `website "kubia" created`'
- en: The response tells you that the API server has accepted and stored your custom
    Website object. Let’s see if you can now retrieve it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 响应告诉你 API 服务器已接受并存储了你的自定义网站对象。让我们看看你现在是否能检索到它。
- en: Retrieving instances of a custom resource
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 获取自定义资源实例
- en: 'List all the websites in your cluster:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 列出你集群中的所有网站：
- en: '`$ kubectl get websites` `NAME      KIND kubia     Website.v1.extensions.example.com`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl get websites` `NAME      KIND kubia     Website.v1.extensions.example.com`'
- en: As with existing Kubernetes resources, you can create and then list instances
    of custom resources. You can also use `kubectl describe` to see the details of
    your custom object, or retrieve the whole YAML with `kubectl get`, as in the following
    listing.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 与现有的 Kubernetes 资源一样，你可以创建并列出自定义资源的实例。你也可以使用 `kubectl describe` 来查看自定义对象的详细信息，或者使用
    `kubectl get` 获取整个 YAML，如下所示。
- en: Listing 18.4\. Full Website resource definition retrieved from the API server
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 18.4\. 从 API 服务器检索到的完整网站资源定义
- en: '`$ kubectl get website kubia -o yaml` `apiVersion: extensions.example.com/v1
    kind: Website metadata:   creationTimestamp: 2017-02-26T15:53:21Z   name: kubia
      namespace: default   resourceVersion: "57047"   selfLink: /apis/extensions.example.com/v1/.../default/websites/kubia
      uid: b2eb6d99-fc3b-11e6-bd71-0800270a1c50 spec:   gitRepo: https://github.com/luksa/kubia-website-example.git`'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl get website kubia -o yaml` `apiVersion: extensions.example.com/v1
    kind: Website metadata: creationTimestamp: 2017-02-26T15:53:21Z name: kubia namespace:
    default resourceVersion: "57047" selfLink: /apis/extensions.example.com/v1/.../default/websites/kubia
    uid: b2eb6d99-fc3b-11e6-bd71-0800270a1c50 spec: gitRepo: https://github.com/luksa/kubia-website-example.git`'
- en: Note that the resource includes everything that was in the original YAML definition,
    and that Kubernetes has initialized additional metadata fields the way it does
    with all other resources.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，资源包括原始YAML定义中的所有内容，以及Kubernetes以与其他所有资源相同的方式初始化了额外的元数据字段。
- en: Deleting an instance of a custom object
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 删除自定义对象的实例
- en: 'Obviously, in addition to creating and retrieving custom object instances,
    you can also delete them:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，除了创建和检索自定义对象实例之外，您还可以删除它们：
- en: '`$ kubectl delete website kubia` `website "kubia" deleted`'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl delete website kubia` `website "kubia" deleted`'
- en: '|  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You’re deleting an instance of a Website, not the Website CRD resource. You
    could also delete the CRD object itself, but let’s hold off on that for a while,
    because you’ll be creating additional Website instances in the next section.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您正在删除一个网站实例，而不是网站CRD资源。您也可以删除CRD对象本身，但让我们先暂时不这么做，因为在下一节中您将创建更多的网站实例。
- en: '|  |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Let’s go over everything you’ve done. By creating a CustomResourceDefinition
    object, you can now store, retrieve, and delete custom objects through the Kubernetes
    API server. These objects don’t do anything yet. You’ll need to create a controller
    to make them do something.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下您所做的一切。通过创建一个CustomResourceDefinition对象，您现在可以通过Kubernetes API服务器存储、检索和删除自定义对象。这些对象目前还没有做任何事情。您需要创建一个控制器来使它们执行某些操作。
- en: In general, the point of creating custom objects like this isn’t always to make
    something happen when the object is created. Certain custom objects are used to
    store data instead of using a more generic mechanism such as a ConfigMap. Applications
    running inside pods can query the API server for those objects and read whatever
    is stored in them.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，创建此类自定义对象的目的并不总是要在对象创建时发生某些操作。某些自定义对象用于存储数据，而不是使用更通用的机制，如ConfigMap。运行在Pod内的应用程序可以查询API服务器以获取这些对象，并读取它们存储的内容。
- en: But in this case, we said you wanted the existence of a Website object to result
    in the spinning up of a web server serving the contents of the Git repository
    referenced in the object. We’ll look at how to do that next.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 但在这种情况下，我们说您希望网站对象的存在导致启动一个提供Git仓库内容的web服务器。我们将在下一节中查看如何实现这一点。
- en: 18.1.2\. Automating custom resources with custom controllers
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 18.1.2. 使用自定义控制器自动化自定义资源
- en: To make your Website objects run a web server pod exposed through a Service,
    you’ll need to build and deploy a Website controller, which will watch the API
    server for the creation of Website objects and then create the Service and the
    web server Pod for each of them.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 要使您的网站对象运行一个通过Service公开的web服务器Pod，您需要构建和部署一个网站控制器，该控制器将监视API服务器以创建网站对象，然后为每个对象创建Service和web服务器Pod。
- en: To make sure the Pod is managed and survives node failures, the controller will
    create a Deployment resource instead of an unmanaged Pod directly. The controller’s
    operation is summarized in [figure 18.2](#filepos1658898).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保Pod被管理并能在节点故障中存活，控制器将创建一个Deployment资源而不是直接创建一个未管理的Pod。控制器的工作总结在[图18.2](#filepos1658898)中。
- en: Figure 18.2\. The Website controller watches for Website objects and creates
    a Deployment and a Service.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.2. 网站控制器监视网站对象，并为每个对象创建一个Deployment和一个Service。
- en: '![](images/00100.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00100.jpg)'
- en: I’ve written a simple initial version of the controller, which works well enough
    to show CRDs and the controller in action, but it’s far from being production-ready,
    because it’s overly simplified. The container image is available at docker.io/luksa/
    website-controller:latest, and the source code is at [https://github.com/luksa/k8s-website-controller](https://github.com/luksa/k8s-website-controller).
    Instead of going through its source code, I’ll explain what the controller does.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经编写了一个简单的初始版本的控制器，它足以展示CRDs和控制器的作用，但它远未达到生产就绪状态，因为它过于简化。容器镜像可在docker.io/luksa/website-controller:latest找到，源代码在[https://github.com/luksa/k8s-website-controller](https://github.com/luksa/k8s-website-controller)。我将不会通过其源代码进行说明，而是解释控制器的作用。
- en: Understanding what the Website Controller does
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 理解Website控制器的作用
- en: 'Immediately upon startup, the controller starts to watch Website objects by
    requesting the following URL:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 启动后立即，控制器开始通过请求以下URL监视Website对象：
- en: '`http://localhost:8001/apis/extensions.example.com/v1/websites?watch=true`'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`http://localhost:8001/apis/extensions.example.com/v1/websites?watch=true`'
- en: You may recognize the hostname and port—the controller isn’t connecting to the
    API server directly, but is instead connecting to the `kubectl proxy` process,
    which runs in a sidecar container in the same pod and acts as the ambassador to
    the API server (we examined the ambassador pattern in [chapter 8](index_split_070.html#filepos790863)).
    The proxy forwards the request to the API server, taking care of both TLS encryption
    and authentication (see [figure 18.3](#filepos1660588)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经识别出主机名和端口号——控制器不是直接连接到API服务器，而是连接到`kubectl proxy`进程，该进程在同一个pod中的sidecar容器中运行，并作为API服务器的使者（我们在第8章中考察了使者模式[章节8](index_split_070.html#filepos790863)）。代理将请求转发到API服务器，同时处理TLS加密和认证（见[图18.3](#filepos1660588)）。
- en: Figure 18.3\. The Website controller talks to the API server through a proxy
    (in the ambassador container).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.3\. Website控制器通过代理（在ambassador容器中）与API服务器通信
- en: '![](images/00117.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00117.jpg)'
- en: Through the connection opened by this HTTP GET request, the API server will
    send watch events for every change to any Website object.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个HTTP GET请求打开的连接，API服务器将为任何Website对象的每个更改发送监视事件。
- en: The API server sends the `ADDED` watch event every time a new Website object
    is created. When the controller receives such an event, it extracts the Website’s
    name and the URL of the Git repository from the Website object it received in
    the watch event and creates a Deployment and a Service object by posting their
    JSON manifests to the API server.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 每当创建一个新的Website对象时，API服务器都会发送`ADDED`监视事件。当控制器收到此类事件时，它会从接收到的监视事件中的Website对象中提取Website的名称和Git仓库的URL，并通过将它们的JSON清单发布到API服务器来创建Deployment和Service对象。
- en: 'The Deployment resource contains a template for a pod with two containers (shown
    in [figure 18.4](#filepos1662378)): one running an nginx server and another one
    running a gitsync process, which keeps a local directory synced with the contents
    of a Git repo. The local directory is shared with the nginx container through
    an `emptyDir` volume (you did something similar to that in [chapter 6](index_split_055.html#filepos588298),
    but instead of keeping the local directory synced with a Git repo, you used a
    `gitRepo` volume to download the Git repo’s contents at pod startup; the volume’s
    contents weren’t kept in sync with the Git repo afterward). The Service is a `NodePort`
    Service, which exposes your web server pod through a random port on each node
    (the same port is used on all nodes). When a pod is created by the Deployment
    object, clients can access the website through the node port.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment资源包含一个具有两个容器的pod模板（如图18.4所示）：一个运行nginx服务器，另一个运行gitsync进程，该进程将本地目录与Git仓库的内容同步。本地目录通过`emptyDir`卷与nginx容器共享（你在第6章中做了类似的事情[章节6](index_split_055.html#filepos588298)，但不是将本地目录与Git仓库同步，而是使用`gitRepo`卷在pod启动时下载Git仓库的内容；在之后，卷的内容没有与Git仓库保持同步）。服务是一个`NodePort`服务，它通过每个节点上的随机端口公开你的web服务器pod（所有节点上使用相同的端口）。当Deployment对象创建pod时，客户端可以通过节点端口访问网站。
- en: Figure 18.4\. The pod serving the website specified in the Website object
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.4\. 服务器端pod为Website对象指定的网站提供服务
- en: '![](images/00136.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00136.jpg)'
- en: The API server also sends a `DELETED` watch event when a Website resource instance
    is deleted. Upon receiving the event, the controller deletes the Deployment and
    the Service resources it created earlier. As soon as a user deletes the Website
    instance, the controller will shut down and remove the web server serving that
    website.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Website 资源实例被删除时，API 服务器也会发送一个 `DELETED` 观察事件。在接收到事件后，控制器会删除它之前创建的 Deployment
    和 Service 资源。一旦用户删除了 Website 实例，控制器将关闭并移除为该网站服务的 web 服务器。
- en: '|  |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: My oversimplified controller isn’t implemented properly. The way it watches
    the API objects doesn’t guarantee it won’t miss individual watch events. The proper
    way to watch objects through the API server is to not only watch them, but also
    periodically re-list all objects in case any watch events were missed.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我过于简化的控制器并没有得到适当的实现。它观察 API 对象的方式并不能保证不会错过单个观察事件。通过 API 服务器观察对象的正确方式不仅是要观察它们，还要定期重新列出所有对象，以防错过任何观察事件。
- en: '|  |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Running the controller as a pod
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以 pod 的形式运行控制器
- en: During development, I ran the controller on my local development laptop and
    used a locally running `kubectl proxy` process (not running as a pod) as the ambassador
    to the Kubernetes API server. This allowed me to develop quickly, because I didn’t
    need to build a container image after every change to the source code and then
    run it inside Kubernetes.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发过程中，我在我的本地开发笔记本电脑上运行了控制器，并使用本地运行的 `kubectl proxy` 进程（不以 pod 的形式运行）作为 Kubernetes
    API 服务器的使者。这使我能够快速开发，因为我不需要在每次更改源代码后构建容器镜像，然后再在 Kubernetes 内运行它。
- en: When I’m ready to deploy the controller into production, the best way is to
    run the controller inside Kubernetes itself, the way you do with all the other
    core controllers. To run the controller in Kubernetes, you can deploy it through
    a Deployment resource. The following listing shows an example of such a Deployment.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 当我准备将控制器部署到生产环境时，最好的方式是将控制器在 Kubernetes 本身运行，就像运行所有其他核心控制器一样。要在 Kubernetes 中运行控制器，你可以通过
    Deployment 资源部署它。以下列表显示了一个这样的 Deployment 示例。
- en: 'Listing 18.5\. A Website controller Deployment: website-controller.yaml'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 18.5\. Website 控制器 Deployment：website-controller.yaml
- en: '`apiVersion: apps/v1beta1 kind: Deployment metadata:   name: website-controller
    spec:   replicas: 1` `1` `template:     metadata:       name: website-controller
          labels:         app: website-controller     spec:       serviceAccountName:
    website-controller` `2` `containers:` `3` `- name: main` `3` `image: luksa/website-controller`
    `3` `- name: proxy` `3` `image: luksa/kubectl-proxy:1.6.2` `3`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion: apps/v1beta1 kind: Deployment metadata:   name: website-controller
    spec:   replicas: 1` `1` `template:     metadata:       name: website-controller
          labels:         app: website-controller     spec:       serviceAccountName:
    website-controller` `2` `containers:` `3` `- name: main` `3` `image: luksa/website-controller`
    `3` `- name: proxy` `3` `image: luksa/kubectl-proxy:1.6.2` `3`'
- en: 1 You’ll run a single replica of the controller.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 你将运行控制器的单个副本。
- en: 2 It will run under a special ServiceAccount.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 它将在一个特殊的 ServiceAccount 下运行。
- en: '3 Two containers: the main container and the proxy sidecar'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 两个容器：主容器和代理侧容器
- en: 'As you can see, the Deployment deploys a single replica of a two-container
    pod. One container runs your controller, whereas the other one is the ambassador
    container used for simpler communication with the API server. The pod runs under
    its own special ServiceAccount, so you’ll need to create it before you deploy
    the controller:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，Deployment 部署了一个包含两个容器的 pod 的单个副本。一个容器运行您的控制器，而另一个容器是用于与 API 服务器进行简单通信的使者容器。该
    pod 在其自己的特殊 ServiceAccount 下运行，因此您在部署控制器之前需要创建它：
- en: '`$ kubectl create serviceaccount website-controller` `serviceaccount "website-controller"
    created`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl create serviceaccount website-controller` `serviceaccount "website-controller"
    created`'
- en: 'If Role Based Access Control (RBAC) is enabled in your cluster, Kubernetes
    will not allow the controller to watch Website resources or create Deployments
    or Services. To allow it to do that, you’ll need to bind the `website-controller`
    ServiceAccount to the `cluster-admin` ClusterRole, by creating a ClusterRoleBinding
    like this:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的集群启用了基于角色的访问控制（RBAC），Kubernetes 将不允许控制器观察 Website 资源或创建 Deployment 或 Service。为了允许它这样做，你需要通过创建一个类似这样的
    ClusterRoleBinding 将 `website-controller` ServiceAccount 绑定到 `cluster-admin` ClusterRole：
- en: '`$ kubectl create clusterrolebinding website-controller`![](images/00006.jpg)`--clusterrole=cluster-admin`![](images/00006.jpg)`--serviceaccount=default:website-controller`
    `clusterrolebinding "website-controller" created`'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl create clusterrolebinding website-controller`![](images/00006.jpg)`--clusterrole=cluster-admin`![](images/00006.jpg)`--serviceaccount=default:website-controller`
    `clusterrolebinding "website-controller" created`'
- en: Once you have the ServiceAccount and ClusterRoleBinding in place, you can deploy
    the controller’s Deployment.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置了 ServiceAccount 和 ClusterRoleBinding，你就可以部署控制器的部署。
- en: Seeing the controller in action
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 观察控制器的工作情况
- en: 'With the controller now running, create the `kubia` Website resource again:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器现在正在运行，再次创建 `kubia` 网站资源：
- en: '`$ kubectl create -f kubia-website.yaml` `website "kubia" created`'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl create -f kubia-website.yaml` `website "kubia" created`'
- en: Now, let’s check the controller’s logs (shown in the following listing) to see
    if it has received the watch event.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查控制器的日志（如下所示列表）以查看它是否收到了监视事件。
- en: Listing 18.6\. Displaying logs of the Website controller
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 18.6\. 显示网站控制器的日志
- en: '`$ kubectl logs website-controller-2429717411-q43zs -c main` `2017/02/26 16:54:41
    website-controller started. 2017/02/26 16:54:47 Received watch event: ADDED: kubia:
    https://github.c... 2017/02/26 16:54:47 Creating services with name kubia-website
    in namespa... 2017/02/26 16:54:47 Response status: 201 Created 2017/02/26 16:54:47
    Creating deployments with name kubia-website in name... 2017/02/26 16:54:47 Response
    status: 201 Created`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl logs website-controller-2429717411-q43zs -c main` `2017/02/26 16:54:41
    website-controller started. 2017/02/26 16:54:47 Received watch event: ADDED: kubia:
    https://github.c... 2017/02/26 16:54:47 Creating services with name kubia-website
    in namespa... 2017/02/26 16:54:47 Response status: 201 Created 2017/02/26 16:54:47
    Creating deployments with name kubia-website in name... 2017/02/26 16:54:47 Response
    status: 201 Created`'
- en: The logs show that the controller received the `ADDED` event and that it created
    a Service and a Deployment for the `kubia-website` Website. The API server responded
    with a `201 Created` response, which means the two resources should now exist.
    Let’s verify that the Deployment, Service and the resulting Pod were created.
    The following listing lists all Deployments, Services and Pods.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 日志显示控制器收到了 `ADDED` 事件，并且它为 `kubia-website` 网站创建了服务和服务。API 服务器响应了 `201 Created`
    状态，这意味着这两个资源现在应该存在。让我们验证部署、服务和由此产生的 Pod 是否已创建。以下列表列出了所有部署、服务和 Pod。
- en: Listing 18.7\. The Deployment, Service, and Pod created for the `kubia-website`
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 18.7\. 为 `kubia-website` 创建的部署、服务和 Pod
- en: '`$ kubectl get deploy,svc,po` `NAME                        DESIRED   CURRENT  
    UP-TO-DATE   AVAILABLE  AGE` `deploy/kubia-website``1         1         1           
    1          4s deploy/website-controller   1         1         1            1         
    5m  NAME                CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE svc/kubernetes     
    10.96.0.1      <none>        443/TCP        38d` `svc/kubia-website``10.101.48.23  
    <nodes>       80:32589/TCP   4s  NAME                                     READY    
    STATUS    RESTARTS   AGE` `po/kubia-website-1029415133-rs715``        2/2      
    Running   0          4s po/website-controller-1571685839-qzmg6   2/2       Running  
    1          5m`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl get deploy,svc,po` `NAME                        DESIRED   CURRENT  
    UP-TO-DATE   AVAILABLE  AGE` `deploy/kubia-website``1         1         1           
    1          4s deploy/website-controller   1         1         1            1         
    5m  NAME                CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE svc/kubernetes     
    10.96.0.1      <none>        443/TCP        38d` `svc/kubia-website``10.101.48.23  
    <nodes>       80:32589/TCP   4s  NAME                                     READY    
    STATUS    RESTARTS   AGE` `po/kubia-website-1029415133-rs715``        2/2      
    Running   0          4s po/website-controller-1571685839-qzmg6   2/2       Running  
    1          5m`'
- en: There they are. The `kubia-website` Service, through which you can access your
    website, is available on port `32589` on all cluster nodes. You can access it
    with your browser. Awesome, right?
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 就在这里。你可以通过 `kubia-website` 服务访问你的网站，该服务在所有集群节点上的 `32589` 端口可用。你可以用浏览器访问它。太棒了，不是吗？
- en: Users of your Kubernetes cluster can now deploy static websites in seconds,
    without knowing anything about Pods, Services, or any other Kubernetes resources,
    except your custom Website resource.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 Kubernetes 集群的用户现在可以在几秒钟内部署静态网站，无需了解关于 Pod、服务或任何其他 Kubernetes 资源的信息，除了你的自定义网站资源。
- en: Obviously, you still have room for improvement. The controller could, for example,
    watch for Service objects and as soon as the node port is assigned, write the
    URL the website is accessible at into the `status` section of the Website resource
    instance itself. Or it could also create an Ingress object for each website. I’ll
    leave the implementation of these additional features to you as an exercise.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，你仍有改进的空间。例如，控制器可以监视服务对象，一旦节点端口分配，就将网站可访问的 URL 写入网站资源实例的 `status` 部分。或者它也可以为每个网站创建一个
    Ingress 对象。我将将这些额外功能的实现留给你作为练习。
- en: 18.1.3\. Validating custom objects
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 18.1.3\. 验证自定义对象
- en: You may have noticed that you didn’t specify any kind of validation schema in
    the Website CustomResourceDefinition. Users can include any field they want in
    the YAML of their Website object. The API server doesn’t validate the contents
    of the YAML (except the usual fields like `apiVersion`, `kind`, and `metadata`),
    so users can create invalid Website objects (without a `gitRepo` field, for example).
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，您在 Website CustomResourceDefinition 中没有指定任何类型的验证架构。用户可以在他们的 Website
    对象的 YAML 中包含他们想要的任何字段。API 服务器不会验证 YAML 的内容（除了通常的字段如 `apiVersion`、`kind` 和 `metadata`），因此用户可以创建无效的
    Website 对象（例如，没有 `gitRepo` 字段）。
- en: Is it possible to add validation to the controller and prevent invalid objects
    from being accepted by the API server? It isn’t, because the API server first
    stores the object, then returns a success response to the client (`kubectl`),
    and only then notifies all the watchers (the controller is one of them). All the
    controller can really do is validate the object when it receives it in a watch
    event, and if the object is invalid, write the error message to the Website object
    (by updating the object through a new request to the API server). The user wouldn’t
    be notified of the error automatically. They’d have to notice the error message
    by querying the API server for the Website object. Unless the user does this,
    they have no way of knowing whether the object is valid or not.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 是否有可能向控制器添加验证并防止无效对象被 API 服务器接受？这是不可能的，因为 API 服务器首先存储对象，然后向客户端（`kubectl`）返回成功响应，然后才通知所有监视器（控制器就是其中之一）。控制器真正能做的就是当它在一个监视事件中接收到对象时验证对象，如果对象无效，就将错误信息写入
    Website 对象（通过向 API 服务器发送一个新的请求来更新对象）。用户不会自动收到错误通知。他们必须通过查询 API 服务器以获取 Website
    对象来注意错误信息。除非用户这样做，否则他们无法知道对象是否有效。
- en: This obviously isn’t ideal. You’d want the API server to validate the object
    and reject invalid objects immediately. Validation of custom objects was introduced
    in Kubernetes version 1.8 as an alpha feature. To have the API server validate
    your custom objects, you need to enable the `CustomResourceValidation` feature
    gate in the API server and specify a JSON schema in the CRD.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这显然不是理想的。您希望 API 服务器验证对象并立即拒绝无效对象。自定义对象的验证是在 Kubernetes 版本 1.8 中作为一个 alpha 特性引入的。要使
    API 服务器验证您的自定义对象，您需要在 API 服务器中启用 `CustomResourceValidation` 功能门，并在 CRD 中指定一个 JSON
    架构。
- en: 18.1.4\. Providing a custom API server for your custom objects
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 18.1.4\. 为您的自定义对象提供自定义 API 服务器
- en: A better way of adding support for custom objects in Kubernetes is to implement
    your own API server and have the clients talk directly to it.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中添加对自定义对象支持的一种更好的方式是实现您自己的 API 服务器，并让客户端直接与其通信。
- en: Introducing API server aggregation
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 引入 API 服务器聚合
- en: In Kubernetes version 1.7, you can integrate your custom API server with the
    main Kubernetes API server, through API server aggregation. Initially, the Kubernetes
    API server was a single monolithic component. From Kubernetes version 1.7, multiple
    aggregated API servers will be exposed at a single location. Clients can connect
    to the aggregated API and have their requests transparently forwarded to the appropriate
    API server. This way, the client wouldn’t even be aware that multiple API servers
    handle different objects behind the scenes. Even the core Kubernetes API server
    may eventually end up being split into multiple smaller API servers and exposed
    as a single server through the aggregator, as shown in [figure 18.5](#filepos1674486).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 版本 1.7 中，您可以通过 API 服务器聚合将您的自定义 API 服务器与主 Kubernetes API 服务器集成。最初，Kubernetes
    API 服务器是一个单一的模块化组件。从 Kubernetes 版本 1.7 开始，多个聚合的 API 服务器将在单个位置暴露。客户端可以连接到聚合的 API，并且他们的请求将透明地转发到适当的
    API 服务器。这样，客户端甚至不会意识到有多个 API 服务器在幕后处理不同的对象。甚至核心 Kubernetes API 服务器最终也可能被分割成多个较小的
    API 服务器，并通过聚合器作为一个单独的服务器暴露，如图 18.5 所示。
- en: Figure 18.5\. API server aggregation
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.5\. API 服务器聚合
- en: '![](images/00154.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00154.jpg)'
- en: In your case, you could create an API server responsible for handling your Website
    objects. It could validate those objects the way the core Kubernetes API server
    validates them. You’d no longer need to create a CRD to represent those objects,
    because you’d implement the Website object type into the custom API server directly.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的案例中，您可以创建一个负责处理您的 Website 对象的 API 服务器。它可以像核心 Kubernetes API 服务器验证对象那样验证这些对象。您就不再需要创建
    CRD 来表示这些对象，因为您将直接在自定义 API 服务器中实现 Website 对象类型。
- en: Generally, each API server is responsible for storing their own resources. As
    shown in [figure 18.5](#filepos1674486), it can either run its own instance of
    etcd (or a whole etcd cluster), or it can store its resources in the core API
    server’s etcd store by creating CRD instances in the core API server. In that
    case, it needs to create a CRD object first, before creating instances of the
    CRD, the way you did in the example.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，每个 API 服务器负责存储它们自己的资源。如图 18.5 所示，它可以运行自己的 etcd 实例（或整个 etcd 集群），或者它可以通过在核心
    API 服务器中创建 CRD 实例将资源存储在核心 API 服务器 etcd 存储中。在这种情况下，它需要首先创建 CRD 对象，然后再创建 CRD 实例，就像您在示例中所做的那样。
- en: Registering a custom API server
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注册自定义 API 服务器
- en: To add a custom API server to your cluster, you’d deploy it as a pod and expose
    it through a Service. Then, to integrate it into the main API server, you’d deploy
    a YAML manifest describing an APIService resource like the one in the following
    listing.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要将自定义 API 服务器添加到您的集群中，您需要将其作为 pod 部署并通过服务公开。然后，为了将其集成到主 API 服务器，您需要部署一个描述 APIService
    资源（如下所示列表）的 YAML 清单。
- en: Listing 18.8\. An `APIService` YAML definition
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 18.8\. 一个 `APIService` YAML 定义
- en: '`apiVersion: apiregistration.k8s.io/v1beta1` `1` `kind: APIService` `1` `metadata:
      name: v1alpha1.extensions.example.com spec:   group: extensions.example.com`
    `2` `version: v1alpha1` `3` `priority: 150   service:` `4` `name: website-api`
    `4` `namespace: default` `4`'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion: apiregistration.k8s.io/v1beta1` `1` `kind: APIService` `1` `metadata:`
    `2` `name: v1alpha1.extensions.example.com` `2` `spec:` `3` `group: extensions.example.com`
    `3` `version: v1alpha1` `3` `priority: 150` `4` `service:` `4` `name: website-api`
    `4` `namespace: default` `4`'
- en: 1 This is an APIService resource.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 这是一个 APIService 资源。
- en: 2 The API group this API server is responsible for
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 该 API 服务器负责的 API 组
- en: 3 The supported API version
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 支持的 API 版本
- en: 4 The Service the custom API server is exposed through
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4 自定义 API 服务器通过的服务
- en: After creating the APIService resource from the previous listing, client requests
    sent to the main API server that contain any resource from the `extensions.example.com`
    API group and version `v1alpha1` would be forwarded to the custom API server pod(s)
    exposed through the `website-api` Service.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在从上一列表创建 APIService 资源之后，发送到主 API 服务器且包含来自 `extensions.example.com` API 组和版本
    `v1alpha1` 的任何资源的客户端请求将被转发到通过 `website-api` 服务公开的自定义 API 服务器 pod(s)。
- en: Creating custom clients
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 创建自定义客户端
- en: While you can create custom resources from YAML files using the regular `kubectl`
    client, to make deployment of custom objects even easier, in addition to providing
    a custom API server, you can also build a custom CLI tool. This will allow you
    to add dedicated commands for manipulating those objects, similar to how `kubectl`
    allows creating Secrets, Deployments, and other resources through resource-specific
    commands like `kubectl create secret` or `kubectl create deployment`.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以使用常规的 `kubectl` 客户端从 YAML 文件创建自定义资源，但要使自定义对象的部署更加容易，除了提供自定义 API 服务器外，您还可以构建自定义
    CLI 工具。这将允许您添加用于操作这些对象的专用命令，类似于 `kubectl` 通过资源特定的命令（如 `kubectl create secret`
    或 `kubectl create deployment`）允许创建 Secrets、Deployments 和其他资源。
- en: As I’ve already mentioned, custom API servers, API server aggregation, and other
    features related to extending Kubernetes are currently being worked on intensively,
    so they may change after the book is published. To get up-to-date information
    on the subject, refer to the Kubernetes GitHub repos at [http://github.com/kubernetes](http://github.com/kubernetes).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我已经提到的，自定义 API 服务器、API 服务器聚合以及其他与扩展 Kubernetes 相关的功能目前正在积极开发中，因此它们可能在本书出版后发生变化。要获取有关该主题的最新信息，请参阅
    Kubernetes GitHub 仓库[http://github.com/kubernetes](http://github.com/kubernetes)。
- en: 18.2\. Extending Kubernetes with the Kubernetes Service Catalog
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 18.2\. 使用 Kubernetes 服务目录扩展 Kubernetes
- en: One of the first additional API servers that will be added to Kubernetes through
    API server aggregation is the Service Catalog API server. The Service Catalog
    is a hot topic in the Kubernetes community, so you may want to know about it.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 API 服务器聚合添加到 Kubernetes 的第一个附加 API 服务器之一是服务目录 API 服务器。服务目录是 Kubernetes 社区的一个热门话题，因此您可能想了解它。
- en: Currently, for a pod to consume a service (here I use the term generally, not
    in relation to Service resources; for example, a database service includes everything
    required to allow users to use a database in their app), someone needs to deploy
    the pods providing the service, a Service resource, and possibly a Secret so the
    client pod can use it to authenticate with the service. That someone is usually
    the same user deploying the client pod or, if a team is dedicated to deploying
    these types of general services, the user needs to file a ticket and wait for
    the team to provision the service. This means the user needs to either create
    the manifests for all the components of the service, know where to find an existing
    set of manifests, know how to configure it properly, and deploy it manually, or
    wait for the other team to do it.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，为了一个Pod能够消费一个服务（这里我使用这个术语是一般性的，而不是与Service资源相关；例如，数据库服务包括允许用户在他们的应用程序中使用数据库所需的所有内容），需要有人部署提供服务的Pods、Service资源，以及可能的一个Secret，以便客户端Pod可以使用它来与该服务进行身份验证。这个人通常是部署客户端Pod的同一用户，或者如果有一个团队专门负责部署这些类型的通用服务，用户需要提交一个工单并等待团队提供该服务。这意味着用户需要创建服务所有组件的清单，知道在哪里找到现有的清单集合，知道如何正确配置它，并手动部署它，或者等待其他团队来完成。
- en: But Kubernetes is supposed to be an easy-to-use, self-service system. Ideally,
    users whose apps require a certain service (for example, a web application requiring
    a backend database), should be able to say to Kubernetes. “Hey, I need a PostgreSQL
    database. Please provision one and tell me where and how I can connect to it.”
    This will soon be possible through the Kubernetes Service Catalog.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 但Kubernetes应该是一个易于使用、自助服务的系统。理想情况下，需要特定服务的应用程序（例如，需要后端数据库的Web应用程序）的用户应该能够对Kubernetes说：“嘿，我需要一个PostgreSQL数据库。请为我提供它，并告诉我如何连接到它。”这将通过Kubernetes服务目录很快实现。
- en: 18.2.1\. Introducing the Service Catalog
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 18.2.1. 介绍服务目录
- en: As the name suggests, the Service Catalog is a catalog of services. Users can
    browse through the catalog and provision instances of the services listed in the
    catalog by themselves without having to deal with Pods, Services, ConfigMaps,
    and other resources required for the service to run. You’ll recognize that this
    is similar to what you did with the Website custom resource.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，服务目录是服务的目录。用户可以浏览目录，并自行提供目录中列出的服务的实例，而无需处理Pods、Services、ConfigMaps和其他服务运行所需的其他资源。你会认识到这与你对Website自定义资源所做的是类似的。
- en: 'Instead of adding custom resources to the API server for each type of service,
    the Service Catalog introduces the following four generic API resources:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是为每种服务向API服务器添加自定义资源，服务目录引入了以下四个通用API资源：
- en: A ClusterServiceBroker, which describes an (external) system that can provision
    services
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ClusterServiceBroker，它描述了一个可以提供服务的（外部）系统
- en: A ClusterServiceClass, which describes a type of service that can be provisioned
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ClusterServiceClass，它描述了可以提供的服务类型
- en: A ServiceInstance, which is one instance of a service that has been provisioned
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ServiceInstance，它是已经提供的服务的一个实例
- en: A ServiceBinding, which represents a binding between a set of clients (pods)
    and a ServiceInstance
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ServiceBinding，它代表了一组客户端（Pods）与ServiceInstance之间的绑定
- en: The relationships between those four resources are shown in the [figure 18.6](#filepos1681989)
    and explained in the following paragraphs.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个资源之间的关系在[图18.6](#filepos1681989)中展示，并在以下段落中解释。
- en: Figure 18.6\. The relationships between Service Catalog API resources.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.6. 服务目录API资源之间的关系。
- en: '![](images/00171.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00171.jpg)'
- en: In a nutshell, a cluster admin creates a ClusterServiceBroker resource for each
    service broker whose services they’d like to make available in the cluster. Kubernetes
    then asks the broker for a list of services that it can provide and creates a
    ClusterServiceClass resource for each of them. When a user requires a service
    to be provisioned, they create an ServiceInstance resource and then a ServiceBinding
    to bind that Service-Instance to their pods. Those pods are then injected with
    a Secret that holds all the necessary credentials and other data required to connect
    to the provisioned ServiceInstance.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，集群管理员为每个他们希望在集群中提供服务的服务代理创建一个ClusterServiceBroker资源。Kubernetes随后要求代理提供一个它可以提供的服务的列表，并为每个服务创建一个ClusterServiceClass资源。当用户需要提供一项服务时，他们创建一个ServiceInstance资源，然后创建一个ServiceBinding将Service-Instance绑定到他们的Pods上。然后，这些Pods被注入一个Secret，其中包含连接到提供的服务实例所需的所有必要凭证和其他数据。
- en: The Service Catalog system architecture is shown in [figure 18.7](#filepos1682993).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 服务目录系统架构如图 18.7 所示。
- en: Figure 18.7\. The architecture of the Service Catalog
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.7\. 服务目录的架构
- en: '![](images/00011.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00011.jpg)'
- en: The components shown in the figure are explained in the following sections.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图中所示组件将在以下章节中进行解释。
- en: 18.2.2\. Introducing the Service Catalog API server and Controller Manager
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 18.2.2\. 介绍服务目录 API 服务器和控制器管理器
- en: 'Similar to core Kubernetes, the Service Catalog is a distributed system composed
    of three components:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 与核心 Kubernetes 类似，服务目录是一个由三个组件组成的分布式系统：
- en: Service Catalog API Server
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务目录 API 服务器
- en: etcd as the storage
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: etcd 作为存储
- en: Controller Manager, where all the controllers run
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器管理器，所有控制器都在这里运行
- en: The four Service Catalog–related resources we introduced earlier are created
    by posting YAML/JSON manifests to the API server. It then stores them into its
    own etcd instance or uses CustomResourceDefinitions in the main API server as
    an alternative storage mechanism (in that case, no additional etcd instance is
    required).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前介绍的四个与服务目录相关的资源是通过向 API 服务器发送 YAML/JSON 清单创建的。然后它将它们存储到自己的 etcd 实例中，或者使用主
    API 服务器中的 CustomResourceDefinitions 作为替代存储机制（在这种情况下，不需要额外的 etcd 实例）。
- en: The controllers running in the Controller Manager are the ones doing something
    with those resources. They obviously talk to the Service Catalog API server, the
    way other core Kubernetes controllers talk to the core API server. Those controllers
    don’t provision the requested services themselves. They leave that up to external
    service brokers, which are registered by creating ServiceBroker resources in the
    Service Catalog API.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在控制器管理器中运行的控制器是那些对这些资源进行操作的控制器。它们显然会与服务目录 API 服务器通信，就像其他核心 Kubernetes 控制器与核心
    API 服务器通信一样。这些控制器不会自己提供请求的服务。它们将这项工作留给外部服务代理，这些代理通过在服务目录 API 中创建 ServiceBroker
    资源进行注册。
- en: 18.2.3\. Introducing Service Brokers and the OpenServiceBroker API
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 18.2.3\. 介绍服务代理和 OpenServiceBroker API
- en: A cluster administrator can register one or more external ServiceBrokers in
    the Service Catalog. Every broker must implement the OpenServiceBroker API.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 群集管理员可以在服务目录中注册一个或多个外部服务代理。每个代理都必须实现 OpenServiceBroker API。
- en: Introducing the OpenServiceBroker API
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍 OpenServiceBroker API
- en: 'The Service Catalog talks to the broker through that API. The API is relatively
    simple. It’s a REST API providing the following operations:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 服务目录通过该 API 与代理通信。该 API 相对简单。它是一个提供以下操作的 REST API：
- en: Retrieving the list of services with `GET /v2/catalog`
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `GET /v2/catalog` 获取服务列表
- en: Provisioning a service instance (`PUT /v2/service_instances/:id`)
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置服务实例 (`PUT /v2/service_instances/:id`)
- en: Updating a service instance (`PATCH /v2/service_instances/:id`)
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新服务实例 (`PATCH /v2/service_instances/:id`)
- en: Binding a service instance (`PUT /v2/service_instances/:id/service_bindings/:binding_id`)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绑定服务实例 (`PUT /v2/service_instances/:id/service_bindings/:binding_id`)
- en: Unbinding an instance (`DELETE /v2/service_instances/:id/service_bindings/:binding_id`)
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解除实例绑定 (`DELETE /v2/service_instances/:id/service_bindings/:binding_id`)
- en: Deprovisioning a service instance (`DELETE /v2/service_instances/:id`)
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取消配置服务实例 (`DELETE /v2/service_instances/:id`)
- en: You’ll find the OpenServiceBroker API spec at [https://github.com/openservicebrokerapi/servicebroker](https://github.com/openservicebrokerapi/servicebroker).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [https://github.com/openservicebrokerapi/servicebroker](https://github.com/openservicebrokerapi/servicebroker)
    找到 OpenServiceBroker API 规范。
- en: Registering brokers in the Service Catalog
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务目录中注册代理
- en: The cluster administrator registers a broker by posting a ServiceBroker resource
    manifest to the Service Catalog API, like the one shown in the following listing.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 群集管理员通过向服务目录 API 发送 ServiceBroker 资源清单来注册代理，如下所示。
- en: 'Listing 18.9\. A ClusterServiceBroker manifest: database-broker.yaml'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 18.9\. ClusterServiceBroker 清单：database-broker.yaml
- en: '`apiVersion: servicecatalog.k8s.io/v1alpha1` `1` `kind: ClusterServiceBroker`
    `1` `metadata:   name: database-broker` `2` `spec:   url: http://database-osbapi.myorganization.org`
    `3`'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion: servicecatalog.k8s.io/v1alpha1` `1` `kind: ClusterServiceBroker`
    `1` `metadata:` `name: database-broker` `2` `spec:` `url: http://database-osbapi.myorganization.org`
    `3`'
- en: 1 The resource kind and the API group and version
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 资源类型和 API 组及版本
- en: 2 The name of this broker
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 此代理的名称
- en: 3 Where the Service Catalog can contact the broker (its OpenServiceBroker [OSB]
    API URL)
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 服务目录可以联系代理的位置（其 OpenServiceBroker [OSB] API URL）
- en: The listing describes an imaginary broker that can provision databases of different
    types. After the administrator creates the ClusterServiceBroker resource, a controller
    in the Service Catalog Controller Manager connects to the URL specified in the
    resource to retrieve the list of services this broker can provision.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 列表描述了一个可以配置不同类型数据库的虚拟代理。在管理员创建ClusterServiceBroker资源后，Service Catalog Controller
    Manager中的控制器连接到资源中指定的URL以检索此代理可以配置的服务列表。
- en: After the Service Catalog retrieves the list of services, it creates a ClusterServiceClass
    resource for each of them. Each ClusterServiceClass resource describes a single
    type of service that can be provisioned (an example of a ClusterServiceClass is
    “PostgreSQL database”). Each ClusterServiceClass has one or more service plans
    associated with it. These allow the user to choose the level of service they need
    (for example, a database ClusterServiceClass could provide a “Free” plan, where
    the size of the database is limited and the underlying storage is a spinning disk,
    and a “Premium” plan, with unlimited size and SSD storage).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务目录检索服务列表后，它为每个服务创建一个ClusterServiceClass资源。每个ClusterServiceClass资源描述了一种可以配置的服务类型（ClusterServiceClass的一个例子是“PostgreSQL数据库”）。每个ClusterServiceClass都与一个或多个服务计划相关联。这些允许用户选择他们需要的服务的级别（例如，数据库ClusterServiceClass可以提供一个“免费”计划，其中数据库的大小有限，底层存储是旋转磁盘，以及一个“高级”计划，具有无限大小和SSD存储）。
- en: Listing the available services in a cluster
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 列出集群中的可用服务
- en: Users of the Kubernetes cluster can retrieve a list of all services that can
    be provisioned in the cluster with `kubectl get serviceclasses`, as shown in the
    following listing.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes集群的用户可以使用`kubectl get serviceclasses`检索集群中可以配置的所有服务的列表，如下所示。
- en: Listing 18.10\. List of ClusterServiceClasses in a cluster
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 列表18.10\. 集群中ClusterServiceClasses的列表
- en: '`$ kubectl get clusterserviceclasses` `NAME                KIND postgres-database  
    ClusterServiceClass.v1alpha1.servicecatalog.k8s.io mysql-database      ServiceClass.v1alpha1.servicecatalog.k8s.io
    mongodb-database    ServiceClass.v1alpha1.servicecatalog.k8s.io`'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl get clusterserviceclasses` `NAME                KIND postgres-database  
    ClusterServiceClass.v1alpha1.servicecatalog.k8s.io mysql-database      ServiceClass.v1alpha1.servicecatalog.k8s.io
    mongodb-database    ServiceClass.v1alpha1.servicecatalog.k8s.io`'
- en: The listing shows ClusterServiceClasses for services that your imaginary database
    broker could provide. You can compare ClusterServiceClasses to StorageClasses,
    which we discussed in [chapter 6](index_split_055.html#filepos588298). StorageClasses
    allow you to select the type of storage you’d like to use in your pods, while
    ClusterServiceClasses allow you to select the type of service.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 列表显示了可以为您的虚拟数据库代理提供的服务ClusterServiceClasses。您可以将ClusterServiceClasses与我们在[第6章](index_split_055.html#filepos588298)中讨论的StorageClasses进行比较。StorageClasses允许您选择在您的Pod中想要使用的存储类型，而ClusterServiceClasses允许您选择服务类型。
- en: You can see details of one of the ClusterServiceClasses by retrieving its YAML.
    An example is shown in the following listing.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过检索其YAML来查看ClusterServiceClass的详细信息。以下是一个示例。
- en: Listing 18.11\. A ClusterServiceClass definition
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 列表18.11\. ClusterServiceClass定义
- en: '`$ kubectl get serviceclass postgres-database -o yaml` `apiVersion: servicecatalog.k8s.io/v1alpha1
    bindable: true brokerName: database-broker` `1` `description: A PostgreSQL database
    kind: ClusterServiceClass metadata:   name: postgres-database   ... planUpdatable:
    false plans: - description: A free (but slow) PostgreSQL instance` `2` `name:
    free` `2` `osbFree: true` `2` `... - description: A paid (very fast) PostgreSQL
    instance` `3` `name: premium` `3` `osbFree: false` `3` `...`'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl get serviceclass postgres-database -o yaml` `apiVersion: servicecatalog.k8s.io/v1alpha1
    bindable: true brokerName: database-broker` `1` `description: A PostgreSQL database
    kind: ClusterServiceClass metadata:   name: postgres-database   ... planUpdatable:
    false plans: - description: A free (but slow) PostgreSQL instance` `2` `name:
    free` `2` `osbFree: true` `2` `... - description: A paid (very fast) PostgreSQL
    instance` `3` `name: premium` `3` `osbFree: false` `3` `...`'
- en: 1 This ClusterServiceClass is provided by the database-broker.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 此ClusterServiceClass由数据库代理提供。
- en: 2 A free plan for this service
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 此服务的免费计划
- en: 3 A paid plan
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 一个付费计划
- en: The ClusterServiceClass in the listing contains two plans—a `free` plan, and
    a `premium` plan. You can see that this ClusterServiceClass is provided by the
    `database-broker` broker.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 列表中的ClusterServiceClass包含两个计划——一个`免费`计划和一个`高级`计划。您可以看到此ClusterServiceClass是由`database-broker`代理提供的。
- en: 18.2.4\. Provisioning and using a service
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 18.2.4\. 服务配置和使用
- en: Let’s imagine the pods you’re deploying need to use a database. You’ve inspected
    the list of available ClusterServiceClasses and have chosen to use the `free`
    plan of the `postgres-database` ClusterServiceClass.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象一下你部署的Pod需要使用数据库。你已经检查了可用的ClusterServiceClasses列表，并选择了使用`postgres-database`
    ClusterServiceClass的`free`计划。
- en: Provisioning a ServiceInstance
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 配置一个ServiceInstance
- en: To have the database provisioned for you, all you need to do is create a Service-Instance
    resource, as shown in the following listing.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你使用的数据库被配置好，你所需要做的就是创建一个Service-Instance资源，如下所示。
- en: 'Listing 18.12\. A ServiceInstance manifest: database-instance.yaml'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 列表18.12. ServiceInstance清单：database-instance.yaml
- en: '`apiVersion: servicecatalog.k8s.io/v1alpha1 kind: ServiceInstance metadata:
      name: my-postgres-db` `1` `spec:   clusterServiceClassName: postgres-database`
    `2` `clusterServicePlanName: free` `2` `parameters:     init-db-args: --data-checksums`
    `3`'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion: servicecatalog.k8s.io/v1alpha1 kind: ServiceInstance metadata:
      name: my-postgres-db` `1` `spec:   clusterServiceClassName: postgres-database`
    `2` `clusterServicePlanName: free` `2` `parameters:     init-db-args: --data-checksums`
    `3`'
- en: 1 You’re giving this Instance a name.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 你正在给这个实例命名。
- en: 2 The ServiceClass and Plan you want
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 你想要的ServiceClass和Plan
- en: 3 Additional parameters passed to the broker
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 传递给代理的附加参数
- en: You created a ServiceInstance called `my-postgres-db` (that will be the name
    of the resource you’re deploying) and specified the ClusterServiceClass and the
    chosen plan. You’re also specifying a parameter, which is specific for each broker
    and ClusterServiceClass. Let’s imagine you looked up the possible parameters in
    the broker’s documentation.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 你创建了一个名为`my-postgres-db`的ServiceInstance（这将是你要部署的资源名称），并指定了ClusterServiceClass和所选的计划。你还指定了一个参数，这是针对每个代理和ClusterServiceClass特定的。让我们假设你查阅了代理文档中可能的参数。
- en: As soon as you create this resource, the Service Catalog will contact the broker
    the ClusterServiceClass belongs to and ask it to provision the service. It will
    pass on the chosen ClusterServiceClass and plan names, as well as all the parameters
    you specified.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你创建了此资源，服务目录将联系属于ClusterServiceClass的代理，并要求它配置服务。它将传递所选的ClusterServiceClass和计划名称，以及你指定的所有参数。
- en: It’s then completely up to the broker to know what to do with this information.
    In your case, your database broker will probably spin up a new instance of a PostgreSQL
    database somewhere—not necessarily in the same Kubernetes cluster or even in Kubernetes
    at all. It could run a Virtual Machine and run the database in there. The Service
    Catalog doesn’t care, and neither does the user requesting the service.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，完全取决于代理如何处理这些信息。在你的情况下，你的数据库代理可能会在某个地方启动一个新的PostgreSQL数据库实例——不一定是在同一个Kubernetes集群中，甚至可能根本不在Kubernetes中。它可以在虚拟机上运行，并在那里运行数据库。服务目录不在乎，请求服务的用户也不在乎。
- en: You can check if the service has been provisioned successfully by inspecting
    the `status` section of the my-postgres-db ServiceInstance you created, as shown
    in the following listing.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过检查你创建的my-postgres-db ServiceInstance的`status`部分来验证服务是否已成功配置，如下所示。
- en: Listing 18.13\. Inspecting the status of a ServiceInstance
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 列表18.13. 检查ServiceInstance的状态
- en: '`$ kubectl get instance my-postgres-db -o yaml` `apiVersion: servicecatalog.k8s.io/v1alpha1
    kind: ServiceInstance ... status:   asyncOpInProgress: false   conditions:   -
    lastTransitionTime: 2017-05-17T13:57:22Z     message: The instance was provisioned
    successfully` `1` `reason: ProvisionedSuccessfully` `1` `status: "True"     type:
    Ready` `2`'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl get instance my-postgres-db -o yaml` `apiVersion: servicecatalog.k8s.io/v1alpha1
    kind: ServiceInstance ... status:   asyncOpInProgress: false   conditions:   -
    lastTransitionTime: 2017-05-17T13:57:22Z     message: The instance was provisioned
    successfully` `1` `reason: ProvisionedSuccessfully` `1` `status: "True"     type:
    Ready` `2`'
- en: 1 The database was provisioned successfully.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 数据库已成功配置。
- en: 2 It’s ready to be used.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 它现在可以使用了。
- en: A database instance is now running somewhere, but how do you use it in your
    pods? To do that, you need to bind it.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库实例现在在某个地方运行，但如何在你的Pod中使用它？为了做到这一点，你需要将其绑定。
- en: Binding a ServiceInstance
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 绑定一个ServiceInstance
- en: To use a provisioned ServiceInstance in your pods, you create a ServiceBinding
    resource, as shown in the following listing.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 要在你的Pod中使用已配置的ServiceInstance，你需要创建一个ServiceBinding资源，如下所示。
- en: 'Listing 18.14\. A ServiceBinding: my-postgres-db-binding.yaml'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 列表18.14. ServiceBinding：my-postgres-db-binding.yaml
- en: '`apiVersion: servicecatalog.k8s.io/v1alpha1 kind: ServiceBinding metadata:
      name: my-postgres-db-binding spec:   instanceRef:` `1` `name: my-postgres-db`
    `1` `secretName: postgres-secret` `2`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`apiVersion: servicecatalog.k8s.io/v1alpha1 kind: ServiceBinding metadata:
      name: my-postgres-db-binding spec:   instanceRef:` `1` `name: my-postgres-db`
    `1` `secretName: postgres-secret` `2`'
- en: 1 You’re referencing the instance you created earlier.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 您正在引用您之前创建的实例。
- en: 2 You’d like the credentials for accessing the service stored in this Secret.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 您希望将访问服务的凭据存储在这个Secret中。
- en: The listing shows that you’re defining a ServiceBinding resource called `my-postgres-db-binding`,
    in which you’re referencing the `my-postgres-db` service instance you created
    earlier. You’re also specifying a name of a Secret. You want the Service Catalog
    to put all the necessary credentials for accessing the service instance into a
    Secret called `postgres-secret`. But where are you binding the ServiceInstance
    to your pods? Nowhere, actually.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 列表显示您正在定义一个名为`my-postgres-db-binding`的ServiceBinding资源，在其中您引用了您之前创建的`my-postgres-db`服务实例。您还指定了一个Secret的名称。您希望服务目录将访问服务实例所需的所有必要凭据放入名为`postgres-secret`的Secret中。但您将ServiceInstance绑定到Pod的哪里？实际上是没有地方。
- en: Currently, the Service Catalog doesn’t yet make it possible to inject pods with
    the Service-Instance’s credentials. This will be possible when a new Kubernetes
    feature called PodPresets is available. Until then, you can choose a name for
    the Secret where you want the credentials to be stored in and mount that Secret
    into your pods manually.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，服务目录还不能使Pod能够注入服务实例的凭据。当一个新的Kubernetes功能PodPresets可用时，这将成为可能。在此之前，您可以为要存储凭据的Secret选择一个名称，并将该Secret手动挂载到您的Pod中。
- en: When you submit the ServiceBinding resource from the previous listing to the
    Service Catalog API server, the controller will contact the Database broker once
    again and create a binding for the ServiceInstance you provisioned earlier. The
    broker responds with a list of credentials and other data necessary for connecting
    to the database. The Service Catalog creates a new Secret with the name you specified
    in the Service-Binding resource and stores all that data in the Secret.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将上一列表中的ServiceBinding资源提交给服务目录API服务器时，控制器将再次联系数据库代理，并为您之前配置的服务实例创建一个绑定。代理响应一个包含连接到数据库所需凭据和其他数据的列表。服务目录创建一个新的Secret，其名称与您在Service-Binding资源中指定的名称相同，并将所有这些数据存储在Secret中。
- en: Using the newly created Secret in client pods
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新创建的Secret在客户端Pod中
- en: The Secret created by the Service Catalog system can be mounted into pods, so
    they can read its contents and use them to connect to the provisioned service
    instance (a PostgreSQL database in the example). The Secret could look like the
    one in the following listing.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 服务目录系统创建的Secret可以挂载到Pod中，这样它们就可以读取其内容，并使用这些内容连接到配置的服务实例（例如，示例中的PostgreSQL数据库）。Secret可能看起来像以下列表中的那样。
- en: Listing 18.15\. A Secret holding the credentials for connecting to the service
    instance
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 列表18.15. 存储连接到服务实例凭据的Secret
- en: '`$ kubectl get secret postgres-secret -o yaml` `apiVersion: v1 data:   host:
    <base64-encoded hostname of the database>` `1` `username: <base64-encoded username>`
    `1` `password: <base64-encoded password>` `1` `kind: Secret metadata:   name:
    postgres-secret   namespace: default   ... type: Opaque`'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl get secret postgres-secret -o yaml` `apiVersion: v1 data:   host:
    <数据库的主机base64编码名称>` `1` `username: <用户名的base64编码>` `1` `password: <密码的base64编码>`
    `1` `kind: Secret metadata:   name: postgres-secret   namespace: default   ...
    type: Opaque`'
- en: 1 This is what the pod should use to connect to the database service.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 这就是Pod应该用来连接到数据库服务的内容。
- en: Because you can choose the name of the Secret yourself, you can deploy pods
    before provisioning or binding the service. As you learned in [chapter 7](index_split_063.html#filepos687721),
    the pods won’t be started until such a Secret exists.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 因为您可以自己选择Secret的名称，您可以在配置或绑定服务之前部署Pod。正如您在[第7章](index_split_063.html#filepos687721)中学到的，Pod将在这样的Secret存在之前不会启动。
- en: If necessary, multiple bindings can be created for different pods. The service
    broker can choose to use the same set of credentials in every binding, but it’s
    better to create a new set of credentials for every binding instance. This way,
    pods can be prevented from using the service by deleting the ServiceBinding resource.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，可以为不同的Pod创建多个绑定。服务代理可以选择在每个绑定中使用相同的凭据集，但为每个绑定实例创建一个新的凭据集会更好。这样，可以通过删除ServiceBinding资源来防止Pod使用服务。
- en: 18.2.5\. Unbinding and deprovisioning
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 18.2.5. 解除绑定和取消配置
- en: 'Once you no longer need a ServiceBinding, you can delete it the way you delete
    other resources:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦不再需要 ServiceBinding，您就可以像删除其他资源一样删除它：
- en: '`$ kubectl delete servicebinding my-postgres-db-binding` `servicebinding "my-postgres-db-binding"
    deleted`'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl delete servicebinding my-postgres-db-binding` `servicebinding "my-postgres-db-binding"
    deleted`'
- en: When you do this, the Service Catalog controller will delete the Secret and
    call the broker to perform an unbinding operation. The service instance (in your
    case a PostgreSQL database) is still running. You can therefore create a new ServiceBinding
    if you want.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 当您这样做时，服务目录控制器将删除 Secret 并调用代理执行解绑操作。服务实例（在您的情况下是一个 PostgreSQL 数据库）仍在运行。因此，如果您想的话，可以创建一个新的
    ServiceBinding。
- en: 'But if you don’t need the database instance anymore, you should delete the
    Service-Instance resource also:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果您不再需要数据库实例，也应该删除 Service-Instance 资源：
- en: '`$ kubectl delete serviceinstance my-postgres-db` `serviceinstance "my-postgres-db
    " deleted`'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ kubectl delete serviceinstance my-postgres-db` `serviceinstance "my-postgres-db"
    deleted`'
- en: Deleting the ServiceInstance resource causes the Service Catalog to perform
    a deprovisioning operation on the service broker. Again, exactly what that means
    is up to the service broker, but in your case, the broker should shut down the
    PostgreSQL database instance that it created when we provisioned the service instance.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 删除 ServiceInstance 资源会导致服务目录在服务代理上执行解配操作。再次强调，这具体意味着什么取决于服务代理，但在您的情况下，代理应该关闭我们在提供服务实例时创建的
    PostgreSQL 数据库实例。
- en: 18.2.6\. Understanding what the Service Catalog brings
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 18.2.6. 理解服务目录带来的好处
- en: As you’ve learned, the Service Catalog enables service providers make it possible
    to expose those services in any Kubernetes cluster by registering the broker in
    that cluster. For example, I’ve been involved with the Service Catalog since early
    on and have implemented a broker, which makes it trivial to provision messaging
    systems and expose them to pods in a Kubernetes cluster. Another team has implemented
    a broker that makes it easy to provision Amazon Web Services.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所学的，服务目录使服务提供商能够通过在该集群中注册代理来在任何 Kubernetes 集群中公开这些服务。例如，我从一开始就参与了服务目录，并实现了一个代理，这使得在
    Kubernetes 集群中提供消息系统并将其公开给 pod 变得非常简单。另一个团队实现了一个代理，使得提供亚马逊网络服务变得容易。
- en: In general, service brokers allow easy provisioning and exposing of services
    in Kubernetes and will make Kubernetes an even more awesome platform for deploying
    your applications.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，服务代理允许在 Kubernetes 中轻松提供和公开服务，这将使 Kubernetes 成为部署应用程序的更加强大的平台。
- en: 18.3\. Platforms built on top of Kubernetes
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 18.3. 基于 Kubernetes 的平台
- en: I’m sure you’ll agree that Kubernetes is a great system by itself. Given that
    it’s easily extensible across all its components, it’s no wonder companies that
    had previously developed their own custom platforms are now re-implementing them
    on top of Kubernetes. Kubernetes is, in fact, becoming a widely accepted foundation
    for the new generation of Platform-as-a-Service offerings.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信您会同意 Kubernetes 本身就是一个伟大的系统。鉴于它很容易扩展到其所有组件，也就难怪之前开发自己定制平台的公司现在正在 Kubernetes
    之上重新实现它们。实际上，Kubernetes 正在成为新一代 PaaS 提供的广泛接受的基础。
- en: Among the best-known PaaS systems built on Kubernetes are Deis Workflow and
    Red Hat’s OpenShift. We’ll do a quick overview of both systems to give you a sense
    of what they offer on top of all the awesome stuff Kubernetes already offers.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于 Kubernetes 的最知名 PaaS 系统中，有 Deis Workflow 和 Red Hat 的 OpenShift。我们将快速概述这两个系统，以便您了解它们在
    Kubernetes 已经提供的所有精彩功能之上还能提供什么。
- en: 18.3.1\. Red Hat OpenShift Container Platform
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 18.3.1. Red Hat OpenShift 容器平台
- en: Red Hat OpenShift is a Platform-as-a-Service and as such, it has a strong focus
    on developer experience. Among its goals are enabling rapid development of applications,
    as well as easy deployment, scaling, and long-term maintenance of those apps.
    OpenShift has been around much longer than Kubernetes. Versions 1 and 2 were built
    from the ground up and had nothing to do with Kubernetes, but when Kubernetes
    was announced, Red Hat decided to rebuild OpenShift version 3 from scratch—this
    time on top of Kubernetes. When a company such as Red Hat decides to throw away
    an old version of their software and build a new one on top of an existing technology
    like Kubernetes, it should be clear to everyone how great Kubernetes is.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Red Hat OpenShift是一个平台即服务（PaaS），因此它非常注重开发者体验。其目标包括实现应用程序的快速开发、易于部署、扩展以及长期维护。OpenShift的历史比Kubernetes悠久得多。版本1和2是从头开始构建的，与Kubernetes无关，但Kubernetes发布后，Red
    Hat决定从头开始重建OpenShift版本3——这次是在Kubernetes之上。当像Red Hat这样的公司决定放弃其软件的旧版本，并在现有技术如Kubernetes之上构建新版本时，对每个人来说都应该很清楚Kubernetes有多么出色。
- en: Kubernetes automates rollouts and application scaling, whereas OpenShift also
    automates the actual building of application images and their automatic deployment
    without requiring you to integrate a Continuous Integration solution into your
    cluster.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes自动化了发布和应用程序扩展，而OpenShift还自动构建应用程序镜像及其自动部署，无需您将持续集成解决方案集成到您的集群中。
- en: OpenShift also provides user and group management, which allows you to run a
    properly secured multi-tenant Kubernetes cluster, where individual users are only
    allowed to access their own Kubernetes namespaces and the apps running in those
    namespaces are also fully network-isolated from each other by default.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: OpenShift还提供了用户和组管理，这使得您可以运行一个安全的多租户Kubernetes集群，其中单个用户只能访问他们自己的Kubernetes命名空间，并且在这些命名空间中运行的应用程序默认情况下也完全网络隔离。
- en: Introducing additional resources available in OpenShift
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍OpenShift中可用的额外资源
- en: OpenShift provides some additional API objects in addition to all those available
    in Kubernetes. We’ll explain them in the next few paragraphs to give you a good
    overview of what OpenShift does and what it provides.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Kubernetes中所有可用的API对象之外，OpenShift还提供了一些额外的API对象。我们将在接下来的几段中解释它们，以便您对OpenShift做什么以及它提供什么有一个良好的概述。
- en: The additional resources include
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的资源包括
- en: Users & Groups
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Users & Groups
- en: Projects
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Projects
- en: Templates
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Templates
- en: BuildConfigs
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BuildConfigs
- en: DeploymentConfigs
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DeploymentConfigs
- en: ImageStreams
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ImageStreams
- en: Routes
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Routes
- en: And others
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及其他
- en: Understanding Users, Groups, and Projects
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 理解用户、组和项目
- en: We’ve said that OpenShift provides a proper multi-tenant environment to its
    users. Unlike Kubernetes, which doesn’t have an API object for representing an
    individual user of the cluster (but does have ServiceAccounts that represent services
    running in it), OpenShift provides powerful user management features, which make
    it possible to specify what each user can do and what they cannot. These features
    pre-date the Role-Based Access Control, which is now the standard in vanilla Kubernetes.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们说过，OpenShift为用户提供了一个合适的多租户环境。与Kubernetes不同，Kubernetes没有用于表示集群单个用户的API对象（但确实有ServiceAccounts表示在其中运行的服务），OpenShift提供了强大的用户管理功能，这使得可以指定每个用户可以做什么以及他们不能做什么。这些功能早于基于角色的访问控制，而基于角色的访问控制现在是纯Kubernetes的标准。
- en: Each user has access to certain Projects, which are nothing more than Kubernetes
    Namespaces with additional annotations. Users can only act on resources that reside
    in the projects the user has access to. Access to the project is granted by a
    cluster administrator.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 每个用户都有访问某些项目的权限，这些项目不过是带有额外注解的Kubernetes命名空间。用户只能对其有权访问的项目中的资源采取行动。项目访问权由集群管理员授予。
- en: Introducing Application Templates
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍应用程序模板
- en: Kubernetes makes it possible to deploy a set of resources through a single JSON
    or YAML manifest. OpenShift takes this a step further by allowing that manifest
    to be parameterizable. A parameterizable list in OpenShift is called a Template;
    it’s a list of objects whose definitions can include placeholders that get replaced
    with parameter values when you process and then instantiate a template (see [figure
    18.8](#filepos1707730)).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes通过单个JSON或YAML清单部署一组资源。OpenShift更进一步，允许该清单可参数化。在OpenShift中，可参数化的列表称为模板；它是一系列对象，其定义可以包括占位符，当您处理并实例化模板时，这些占位符将被参数值替换（参见[图18.8](#filepos1707730)）。
- en: Figure 18.8\. OpenShift templates
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.8\. OpenShift模板
- en: '![](images/00030.jpg)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00030.jpg)'
- en: The template itself is a JSON or YAML file containing a list of parameters that
    are referenced in resources defined in that same JSON/YAML. The template can be
    stored in the API server like any other object. Before a template can be instantiated,
    it needs to be processed. To process a template, you supply the values for the
    template’s parameters and then OpenShift replaces the references to the parameters
    with those values. The result is a processed template, which is exactly like a
    Kubernetes resource list that can then be created with a single POST request.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 模板本身是一个JSON或YAML文件，其中包含在相同JSON/YAML中定义的资源中引用的参数列表。模板可以像任何其他对象一样存储在API服务器上。在模板可以实例化之前，需要对其进行处理。要处理模板，你需要提供模板参数的值，然后OpenShift将参数的引用替换为这些值。结果是经过处理的模板，它就像一个Kubernetes资源列表，然后可以通过单个POST请求创建。
- en: OpenShift provides a long list of pre-fabricated templates that allow users
    to quickly run complex applications by specifying a few arguments (or none at
    all, if the template provides good defaults for those arguments). For example,
    a template can enable the creation of all the Kubernetes resources necessary to
    run a Java EE application inside an Application Server, which connects to a back-end
    database, also deployed as part of that same template. All those components can
    be deployed with a single command.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: OpenShift提供了一系列预先构建的模板，允许用户通过指定少量参数（如果没有提供参数，因为模板为这些参数提供了良好的默认值）快速运行复杂的应用程序。例如，一个模板可以启用创建所有必要的Kubernetes资源，以便在应用程序服务器内运行Java
    EE应用程序，该服务器连接到后端数据库，也作为该模板的一部分部署。所有这些组件都可以通过单个命令部署。
- en: Building images from source using BuildConfigs
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 BuildConfigs 从源构建镜像
- en: One of the best features of OpenShift is the ability to have OpenShift build
    and immediately deploy an application in the OpenShift cluster by pointing it
    to a Git repository holding the application’s source code. You don’t need to build
    the container image at all—OpenShift does that for you. This is done by creating
    a resource called Build-Config, which can be configured to trigger builds of container
    images immediately after a change is committed to the source Git repository.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: OpenShift最优秀的功能之一是能够通过指向包含应用程序源代码的Git仓库来构建和立即在OpenShift集群中部署应用程序。你根本不需要构建容器镜像——OpenShift会为你完成这项工作。这是通过创建一个名为Build-Config的资源来实现的，它可以配置为在源Git仓库提交更改后立即触发容器镜像的构建。
- en: Although OpenShift doesn’t monitor the Git repository itself, a hook in the
    repository can notify OpenShift of the new commit. OpenShift will then pull the
    changes from the Git repository and start the build process. A build mechanism
    called Source To Image can detect what type of application is in the Git repository
    and run the proper build procedure for it. For example, if it detects a pom.xml
    file, which is used in Java Maven-formatted projects, it runs a Maven build. The
    resulting artifacts are packaged into an appropriate container image, and are
    then pushed to an internal container registry (provided by OpenShift). From there,
    they can be pulled and run in the cluster immediately.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管OpenShift本身不监控Git仓库，但仓库中的钩子可以通知OpenShift有新的提交。然后OpenShift将从Git仓库拉取更改并开始构建过程。一种名为“源到镜像”的构建机制可以检测Git仓库中应用类型，并为其运行适当的构建过程。例如，如果检测到pom.xml文件，这是Java
    Maven格式项目使用的，它将运行Maven构建。生成的工件被打包到适当的容器镜像中，然后推送到内部容器注册库（由OpenShift提供）。从那里，它们可以立即被拉取并在集群中运行。
- en: By creating a BuildConfig object, developers can thus point to a Git repo and
    not worry about building container images. Developers have almost no need to know
    anything about containers. Once the ops team deploys an OpenShift cluster and
    gives developers access to it, those developers can develop their code, commit,
    and push it to a Git repo, the same way they used to before we started packaging
    apps into containers. Then OpenShift takes care of building, deploying, and managing
    apps from that code.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 通过创建BuildConfig对象，开发人员可以指向Git仓库，而不必担心构建容器镜像。开发人员几乎不需要了解任何关于容器的内容。一旦运维团队部署了OpenShift集群并允许开发人员访问它，那些开发人员就可以像以前一样开发他们的代码，提交并推送到Git仓库。然后OpenShift负责从该代码构建、部署和管理应用程序。
- en: Automatically deploying newly built images with DeploymentConfigs
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DeploymentConfigs 自动部署新构建的镜像
- en: Once a new container image is built, it can also automatically be deployed in
    the cluster. This is enabled by creating a DeploymentConfig object and pointing
    it to an ImageStream. As the name suggests, an ImageStream is a stream of images.
    When an image is built, it’s added to the ImageStream. This enables the DeploymentConfig
    to notice the newly built image and allows it to take action and initiate a rollout
    of the new image (see [figure 18.9](#filepos1711624)).
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦构建了新的容器镜像，它也可以在集群中自动部署。这是通过创建一个DeploymentConfig对象并将其指向ImageStream来实现的。正如其名所示，ImageStream是一系列镜像。当镜像构建时，它会被添加到ImageStream中。这使得DeploymentConfig能够注意到新构建的镜像，并允许它采取行动并启动新镜像的部署（见[图18.9](#filepos1711624)）。
- en: Figure 18.9\. BuildConfigs and DeploymentConfigs in OpenShift
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图18.9\. OpenShift中的BuildConfigs和DeploymentConfigs
- en: '![](images/00050.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00050.jpg)'
- en: A DeploymentConfig is almost identical to the Deployment object in Kubernetes,
    but it pre-dates it. Like a Deployment object, it has a configurable strategy
    for transitioning between Deployments. It contains a pod template used to create
    the actual pods, but it also allows you to configure pre- and post-deployment
    hooks. In contrast to a Kubernetes Deployment, it creates ReplicationControllers
    instead of ReplicaSets and provides a few additional features.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: DeploymentConfig几乎与Kubernetes中的Deployment对象相同，但它更早出现。像Deployment对象一样，它有一个可配置的策略，用于在部署之间进行转换。它包含一个用于创建实际Pods的Pod模板，但它还允许你配置部署前和部署后的钩子。与Kubernetes的Deployment相比，它创建ReplicationControllers而不是ReplicaSets，并提供了一些额外的功能。
- en: Exposing Services externally using Routes
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Routes公开服务
- en: Early on, Kubernetes didn’t provide Ingress objects. To expose Services to the
    outside world, you needed to use `NodePort` or `LoadBalancer`-type Services. But
    at that time, OpenShift already provided a better option through a Route resource.
    A Route is similar to an Ingress, but it provides additional configuration related
    to TLS termination and traffic splitting.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期，Kubernetes没有提供Ingress对象。要将服务暴露给外部世界，你需要使用`NodePort`或`LoadBalancer`类型的Service。但那时，OpenShift已经通过Route资源提供了一个更好的选择。Route类似于Ingress，但它提供了与TLS终止和流量分割相关的额外配置。
- en: Similar to an Ingress controller, a Route needs a Router, which is a controller
    that provides the load balancer or proxy. In contrast to Kubernetes, the Router
    is available out of the box in OpenShift.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 与Ingress控制器类似，Route需要一个Router，这是一个提供负载均衡器或代理的控制器。与Kubernetes不同，Router在OpenShift中是开箱即用的。
- en: Trying out OpenShift
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试OpenShift
- en: If you’re interested in trying out OpenShift, you can start by using Minishift,
    which is the OpenShift equivalent of Minikube, or you can try OpenShift Online
    Starter at [https://manage.openshift.com](https://manage.openshift.com), which
    is a free multi-tenant, hosted solution provided to get you started with OpenShift.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你感兴趣尝试OpenShift，你可以从使用Minishift开始，它是Minikube的OpenShift等价物，或者你可以尝试在[https://manage.openshift.com](https://manage.openshift.com)上的OpenShift
    Online Starter，这是一个免费的多租户托管解决方案，旨在帮助你开始使用OpenShift。
- en: 18.3.2\. Deis Workflow and Helm
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 18.3.2\. Deis Workflow和Helm
- en: A company called Deis, which has recently been acquired by Microsoft, also provides
    a PaaS called Workflow, which is also built on top of Kubernetes. Besides Workflow,
    they’ve also developed a tool called Helm, which is gaining traction in the Kubernetes
    community as a standard way of deploying existing apps in Kubernetes. We’ll take
    a brief look at both.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 一家名为Deis的公司，最近已被微软收购，它也提供了一种名为Workflow的PaaS服务，该服务也是建立在Kubernetes之上的。除了Workflow之外，他们还开发了一个名为Helm的工具，它在Kubernetes社区中作为一种在Kubernetes中部署现有应用的标准方式而受到欢迎。我们将简要地看看这两个工具。
- en: Introducing Deis Workflow
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍Deis Workflow
- en: You can deploy Deis Workflow to any existing Kubernetes cluster (unlike OpenShift,
    which is a complete cluster with a modified API server and other Kubernetes components).
    When you run Workflow, it creates a set of Services and ReplicationControllers,
    which then provide developers with a simple, developer-friendly environment.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将Deis Workflow部署到任何现有的Kubernetes集群中（与OpenShift不同，OpenShift是一个完整的集群，具有修改后的API服务器和其他Kubernetes组件）。当你运行Workflow时，它会创建一组服务和ReplicationControllers，然后为开发者提供一个简单、友好的环境。
- en: Deploying new versions of your app is triggered by pushing your changes with
    `git push deis master` and letting Workflow take care of the rest. Similar to
    OpenShift, Workflow also provides a source to image mechanism, application rollouts
    and rollbacks, edge routing, and also log aggregation, metrics, and alerting,
    which aren’t available in core Kubernetes.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `git push deis master` 推送您的更改并让 Workflow 处理其余部分来触发部署您应用程序的新版本。类似于 OpenShift，Workflow
    也提供了源到镜像机制、应用程序部署和回滚、边缘路由，以及核心 Kubernetes 中不可用的日志聚合、指标和警报。
- en: To run Workflow in your Kubernetes cluster, you first need to install the Deis
    Workflow and Helm CLI tools and then install Workflow into your cluster. We won’t
    go into how to do that here, but if you’d like to learn more, visit the website
    at [https://deis.com/workflow](https://deis.com/workflow). What we’ll explore
    here is the Helm tool, which can be used without Workflow and has gained popularity
    in the community.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的 Kubernetes 集群中运行 Workflow，您首先需要安装 Deis Workflow 和 Helm CLI 工具，然后将 Workflow
    安装到您的集群中。我们这里不会详细介绍如何操作，但如果您想了解更多信息，请访问 [https://deis.com/workflow](https://deis.com/workflow)
    网站。我们将在这里探讨 Helm 工具，它可以不使用 Workflow 使用，并在社区中获得了流行。
- en: Deploying resources through Helm
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Helm 部署资源
- en: Helm is a package manager for Kubernetes (similar to OS package managers like
    `yum` or `apt` in Linux or `homebrew` in MacOS).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: Helm 是 Kubernetes 的包管理器（类似于 Linux 中的 `yum` 或 `apt` 或 MacOS 中的 `homebrew` 这样的操作系统包管理器）。
- en: 'Helm is comprised of two things:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: Helm 由两部分组成：
- en: A `helm` CLI tool (the client).
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`helm` CLI 工具（客户端）。'
- en: Tiller, a server component running as a Pod inside the Kubernetes cluster.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tiller，一个在 Kubernetes 集群内部运行的 Pod 中的服务器组件。
- en: Those two components are used to deploy and manage application packages in a
    Kubernetes cluster. Helm application packages are called Charts. They’re combined
    with a Config, which contains configuration information and is merged into a Chart
    to create a Release, which is a running instance of an application (a combined
    Chart and Config). You deploy and manage Releases using the `helm` CLI tool, which
    talks to the Tiller server, which is the component that creates all the necessary
    Kubernetes resources defined in the Chart, as shown in [figure 18.10](#filepos1716552).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个组件用于在 Kubernetes 集群中部署和管理应用程序包。Helm 应用程序包被称为 Charts。它们与一个包含配置信息的 Config 结合，合并成一个
    Chart，以创建一个 Release，即应用程序的运行实例（一个结合了 Chart 和 Config 的组合）。您可以使用 `helm` CLI 工具部署和管理
    Release，该工具与 Tiller 服务器通信，Tiller 服务器是创建 Chart 中定义的所有必要 Kubernetes 资源的组件，如图 18.10
    所示。[链接](https://wiki.example.org/feynmans_learning_method)。
- en: Figure 18.10\. Overview of Helm
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18.10\. Helm 概览
- en: '![](images/00069.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00069.jpg)'
- en: You can create charts yourself and keep them on your local disk, or you can
    use any existing chart, which is available in the growing list of helm charts
    maintained by the community at [https://github.com/kubernetes/charts](https://github.com/kubernetes/charts).
    The list includes charts for applications such as PostgreSQL, MySQL, MariaDB,
    Magento, Memcached, MongoDB, OpenVPN, PHPBB, RabbitMQ, Redis, WordPress, and others.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以自己创建图表并将它们保存在本地磁盘上，或者您可以使用任何现有的图表，这些图表由社区维护的 helm 图表列表中提供，该列表在 [https://github.com/kubernetes/charts](https://github.com/kubernetes/charts)
    上不断增长。列表包括 PostgreSQL、MySQL、MariaDB、Magento、Memcached、MongoDB、OpenVPN、PHPBB、RabbitMQ、Redis、WordPress
    等应用程序的图表。
- en: Similar to how you don’t build and install apps developed by other people to
    your Linux system manually, you probably don’t want to build and manage your own
    Kubernetes manifests for such applications, right? That’s why you’ll want to use
    Helm and the charts available in the GitHub repository I mentioned.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 与您手动构建和安装其他人开发的 Linux 系统中的应用程序一样，您可能不想手动构建和管理自己的 Kubernetes 清单，对吧？这就是为什么您会想使用
    Helm 和我提到的 GitHub 仓库中可用的图表。
- en: When you want to run a PostgreSQL or a MySQL database in your Kubernetes cluster,
    don’t start writing manifests for them. Instead, check if someone else has already
    gone through the trouble and prepared a Helm chart for it.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想在 Kubernetes 集群中运行 PostgreSQL 或 MySQL 数据库时，不要开始编写它们的清单。相反，检查是否有人已经为此准备了 Helm
    图表。
- en: 'Once someone prepares a Helm chart for a specific application and adds it to
    the Helm chart GitHub repo, installing the whole application takes a single one-line
    command. For example, to run MySQL in your Kubernetes cluster, all you need to
    do is clone the charts Git repo to your local machine and run the following command
    (provided you have Helm’s CLI tool and Tiller running in your cluster):'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦有人为特定的应用程序准备了一个 Helm 图表并将其添加到 Helm 图表 GitHub 存储库中，安装整个应用程序只需要一条单行命令。例如，要在您的
    Kubernetes 集群中运行 MySQL，您只需将图表 Git 存储库克隆到您的本地机器上，并运行以下命令（假设您在集群中运行了 Helm 的 CLI
    工具和 Tiller）：
- en: '`$ helm install --name my-database stable/mysql`'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ helm install --name my-database stable/mysql`'
- en: This will create all the necessary Deployments, Services, Secrets, and PersistentVolumeClaims
    needed to run MySQL in your cluster. You don’t need to concern yourself with what
    components you need and how to configure them to run MySQL properly. I’m sure
    you’ll agree this is awesome.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建运行 MySQL 所需的所有必要的部署、服务、机密和持久卷声明。您无需担心需要哪些组件以及如何配置它们以正确运行 MySQL。我相信您会同意这很棒。
- en: '|  |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Tip
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: One of the most interesting charts available in the repo is an OpenVPN chart,
    which runs an OpenVPN server inside your Kubernetes cluster and allows you to
    enter the pod network through VPN and access Services as if your local machine
    was a pod in the cluster. This is useful when you’re developing apps and running
    them locally.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在存储库中可用的最有趣的图表之一是 OpenVPN 图表，它可以在您的 Kubernetes 集群内部运行 OpenVPN 服务器，并允许您通过 VPN
    进入 pod 网络，就像您的本地机器是集群中的 pod 一样访问服务。当您在本地开发和运行应用程序时，这很有用。
- en: '|  |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: These were several examples of how Kubernetes can be extended and how companies
    like Red Hat and Deis (now Microsoft) have extended it. Now go and start riding
    the Kubernetes wave yourself!
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是 Kubernetes 可以如何扩展以及像 Red Hat 和 Deis（现在是微软）这样的公司如何扩展它的几个例子。现在去开始自己驾驭 Kubernetes
    的浪潮吧！
- en: 18.4\. Summary
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 18.4. 摘要
- en: This final chapter has shown you how you can go beyond the existing functionalities
    Kubernetes provides and how companies like Dies and Red Hat have done it. You’ve
    learned how
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 这最后一章向您展示了如何超越 Kubernetes 提供的现有功能，以及像 Dies 和 Red Hat 这样的公司是如何做到的。您已经学会了如何
- en: Custom resources can be registered in the API server by creating a Custom-ResourceDefinition
    object.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过创建自定义资源定义对象来在 API 服务器中注册自定义资源。
- en: Instances of custom objects can be stored, retrieved, updated, and deleted without
    having to change the API server code.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以存储、检索、更新和删除自定义对象的实例，而无需更改 API 服务器代码。
- en: A custom controller can be implemented to bring those objects to life.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以实现一个自定义控制器来使这些对象变得活跃。
- en: Kubernetes can be extended with custom API servers through API aggregation.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 可以通过 API 聚合扩展到自定义 API 服务器。
- en: Kubernetes Service Catalog makes it possible to self-provision external services
    and expose them to pods running in the Kubernetes cluster.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 服务目录使得能够自助配置外部服务并将它们暴露给在 Kubernetes 集群中运行的 pod。
- en: Platforms-as-a-Service built on top of Kubernetes make it easy to build containerized
    applications inside the same Kubernetes cluster that then runs them.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立在 Kubernetes 之上的平台服务使得在同一个 Kubernetes 集群内部构建容器化应用程序变得容易，然后运行它们。
- en: A package manager called Helm makes deploying existing apps without requiring
    you to build resource manifests for them.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个名为 Helm 的包管理器使得部署现有应用程序而无需为它们构建资源清单变得容易。
- en: Thank you for taking the time to read through this long book. I hope you’ve
    learned as much from reading it as I have from writing it.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您抽出时间阅读这本长篇巨著。我希望您从阅读中学到的知识和我从写作中学到的知识一样多。
