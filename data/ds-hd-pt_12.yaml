- en: 'Chapter 10\. Linear Regression: Going Back to Basics'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章 线性回归：回归基础
- en: Linear regression (OLS^([1](ch10.html#id584))) is the first machine learning
    algorithm most data scientists learn, but it has become more of an intellectual
    curiosity with the advent of more powerful nonlinear alternatives, like gradient
    boosting regression. Because of this, many practitioners don’t know many properties
    of OLS that are very helpful to gain some intuition about learning algorithms.
    This chapter goes through some of these important properties and highlights their
    significance.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归（OLS^([1](ch10.html#id584))）是大多数数据科学家学习的第一个机器学习算法，但随着更强大的非线性替代方法（如梯度提升回归）的出现，它已经成为一种知识上的好奇心。因此，许多实践者不了解OLS的许多对于理解学习算法非常有帮助的属性。本章节介绍了其中一些重要属性，并强调了它们的重要性。
- en: What’s in a Coefficient?
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 系数中包含了什么？
- en: 'Let’s start with the simplest setting with only one feature:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从只有一个特征的最简单设置开始：
- en: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus epsilon" display="block"><mrow><mi>y</mi>
    <mo>=</mo> <msub><mi>α</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mi>ϵ</mi></mrow></math>
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus epsilon" display="block"><mrow><mi>y</mi>
    <mo>=</mo> <msub><mi>α</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mi>ϵ</mi></mrow></math>
- en: The first parameter is the *constant* or *intercept*, and the second parameter
    is the *slope*, as you may recall from the typical functional form for a line.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数是*常数*或*截距*，第二个参数是*斜率*，正如您可能从线性方程的典型函数形式中记得的那样。
- en: 'Since the residuals are mean zero, by taking partial derivatives you can see
    that:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 由于残差的均值为零，通过偏导数可以看出：
- en: <math alttext="StartLayout 1st Row 1st Column alpha 1 2nd Column equals 3rd
    Column StartFraction partial-differential upper E left-parenthesis y right-parenthesis
    Over partial-differential x 1 EndFraction 2nd Row 1st Column alpha 0 2nd Column
    equals 3rd Column upper E left-parenthesis y right-parenthesis minus alpha 1 upper
    E left-parenthesis x 1 right-parenthesis EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>α</mi> <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>∂</mi><mi>E</mi><mo>(</mo><mi>y</mi><mo>)</mo></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>α</mi> <mn>0</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>E</mi> <mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow>
    <mo>-</mo> <msub><mi>α</mi> <mn>1</mn></msub> <mi>E</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha 1 2nd Column equals 3rd
    Column StartFraction partial-differential upper E left-parenthesis y right-parenthesis
    Over partial-differential x 1 EndFraction 2nd Row 1st Column alpha 0 2nd Column
    equals 3rd Column upper E left-parenthesis y right-parenthesis minus alpha 1 upper
    E left-parenthesis x 1 right-parenthesis EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>α</mi> <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>∂</mi><mi>E</mi><mo>(</mo><mi>y</mi><mo>)</mo></mrow>
    <mrow><mi>∂</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>α</mi> <mn>0</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>E</mi> <mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow>
    <mo>-</mo> <msub><mi>α</mi> <mn>1</mn></msub> <mi>E</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
- en: As discussed in [Chapter 9](ch09.html#ch09_simulation), the first equation is
    quite useful for interpretability reasons, since it says that a one-unit change
    in the feature is associated with a change in <math alttext="alpha 1"><msub><mi>α</mi>
    <mn>1</mn></msub></math> units of the outcome, on average. However, as I will
    now show, you must be careful not to give it a *causal* interpretation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在[第9章](ch09.html#ch09_simulation)中讨论的那样，第一个方程对于可解释性来说非常有用，因为它表明特征的单位变化与结果的单位变化，平均而言，相关联。然而，正如我将要展示的，您必须小心，不要给它一个*因果*解释。
- en: 'By substituting the definition of the outcome inside the covariance, you can
    also show that:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将结果的定义代入协方差中，您还可以显示：
- en: <math alttext="StartLayout 1st Row 1st Column alpha 1 2nd Column equals 3rd
    Column StartFraction upper C o v left-parenthesis y comma x 1 right-parenthesis
    Over upper V a r left-parenthesis x 1 right-parenthesis EndFraction EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>α</mi>
    <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow> <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha 1 2nd Column equals 3rd
    Column StartFraction upper C o v left-parenthesis y comma x 1 right-parenthesis
    Over upper V a r left-parenthesis x 1 right-parenthesis EndFraction EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>α</mi>
    <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow> <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
- en: 'In a bivariate setting, the slope depends on the covariance between the outcome
    and the feature, and the variance of the feature. Since correlation is not causation,
    you must be cautious not to interpret these *causally*. A non-null covariance
    can arise from different factors:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在双变量设置中，斜率取决于结果和特征之间的协方差，以及特征的方差。由于相关性并非因果关系，您必须谨慎不要将这些*因果*解释为因果关系。非零协方差可能源自不同的因素：
- en: Direct causation
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 直接因果关系
- en: As you would like to interpret it ( <math alttext="x 1 right-arrow y"><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>→</mo> <mi>y</mi></mrow></math> ).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如您希望解释的那样（ <math alttext="x 1 right-arrow y"><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>→</mo> <mi>y</mi></mrow></math>）。
- en: Reverse causation
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 逆因果关系
- en: <math alttext="x 1 left-arrow y"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>←</mo>
    <mi>y</mi></mrow></math> , since the covariance is symmetric on the arguments.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="x 1 left-arrow y"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>←</mo>
    <mi>y</mi></mrow></math>，因为协方差在参数上是对称的。
- en: Confounders
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 混杂因素
- en: A confounder is any third variable that affects both *x* and *y*, but these
    are otherwise unrelated ([Figure 10-1](#ch10_confounder)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 混杂因素是任何第三个同时影响*x*和*y*的变量，但它们在其他方面无关（[图10-1](#ch10_confounder)）。
- en: '![Confounder](assets/dshp_1001.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![混杂因素](assets/dshp_1001.png)'
- en: Figure 10-1\. Confounders
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-1 混杂因素
- en: Warning
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Estimates from linear regression provide information about the degree of correlation
    between a feature and an outcome, and it can only be interpreted *causally* in
    very specific situations (see [Chapter 15](ch15.html#ch15_incrementality)). This
    warning also applies to other ML algorithms such as gradient boosting or random
    forests.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归的估计提供了关于特征和结果之间相关程度的信息，只能在非常特定的情况下*因果*解释（参见[第15章](ch15.html#ch15_incrementality)）。这个警告同样适用于其他机器学习算法，如梯度提升或随机森林。
- en: 'A more general result applies for multiple regression (that is, a regression
    with multiple covariates):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多重回归，一个更一般的结果适用（即具有多个协变量的回归）：
- en: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column equals
    3rd Column StartFraction upper C o v left-parenthesis y comma x overTilde Subscript
    k Baseline right-parenthesis Over upper V a r left-parenthesis x overTilde Subscript
    k Baseline right-parenthesis EndFraction EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>α</mi> <mi>k</mi></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><msub><mover
    accent="true"><mi>x</mi> <mo>˜</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mover accent="true"><mi>x</mi>
    <mo>˜</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column equals
    3rd Column StartFraction upper C o v left-parenthesis y comma x overTilde Subscript
    k Baseline right-parenthesis Over upper V a r left-parenthesis x overTilde Subscript
    k Baseline right-parenthesis EndFraction EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>α</mi> <mi>k</mi></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><msub><mover
    accent="true"><mi>x</mi> <mo>˜</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mover accent="true"><mi>x</mi>
    <mo>˜</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
- en: 'where <math alttext="x overTilde Subscript k"><msub><mover accent="true"><mi>x</mi>
    <mo>˜</mo></mover> <mi>k</mi></msub></math> is the residual from running a regression
    of the *k-th* feature on all *other* features (*–k*):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 其中<math alttext="x overTilde Subscript k"><msub><mover accent="true"><mi>x</mi>
    <mo>˜</mo></mover> <mi>k</mi></msub></math>是从在所有*其他*特征（*-k*）上运行回归的残差中获得的*k*特征的残差：
- en: <math alttext="x overTilde Subscript k Baseline equals x Subscript k Baseline
    minus bold upper X Subscript negative bold k Baseline theta Subscript negative
    bold k" display="block"><mrow><msub><mover accent="true"><mi>x</mi> <mo>˜</mo></mover>
    <mi>k</mi></msub> <mo>=</mo> <msub><mi>x</mi> <mi>k</mi></msub> <mo>-</mo> <msub><mi>𝐗</mi>
    <mrow><mo>-</mo><mi>𝐤</mi></mrow></msub> <msub><mi>θ</mi> <mrow><mo>-</mo><mi>𝐤</mi></mrow></msub></mrow></math>
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="x overTilde Subscript k Baseline equals x Subscript k Baseline
    minus bold upper X Subscript negative bold k Baseline theta Subscript negative
    bold k" display="block"><mrow><msub><mover accent="true"><mi>x</mi> <mo>˜</mo></mover>
    <mi>k</mi></msub> <mo>=</mo> <msub><mi>x</mi> <mi>k</mi></msub> <mo>-</mo> <msub><mi>𝐗</mi>
    <mrow><mo>-</mo><mi>𝐤</mi></mrow></msub> <msub><mi>θ</mi> <mrow><mo>-</mo><mi>𝐤</mi></mrow></msub></mrow></math>
- en: For the bivariate linear model, the snippet in [Example 10-1](#ch10_code_cov)
    shows that linear regression and the simpler covariance formula agree numerically.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于双变量线性模型，[示例 10-1](#ch10_code_cov)中的片段显示，线性回归和简化协方差公式在数值上是一致的。
- en: Example 10-1\. Verifying that OLS and the bivariate covariance formula agree
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-1\. 验证OLS和双变量协方差公式的一致性
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For the case of more than one feature, you can use the following function to
    verify that the more general covariance formula agrees with OLS. Note that I first
    compute the residuals of a regression of feature *k* on all other features:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多个特征的情况，可以使用以下函数验证更一般的协方差公式是否与OLS一致。注意，我首先计算对所有其他特征进行回归后的残差：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The more general covariance formula leads to an important result called the
    *Frisch-Waugh-Lovell theorem*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般的协方差公式导致了一个重要结果，称为*弗里施-瓦夫-洛维尔定理*。
- en: The Frisch-Waugh-Lovell Theorem
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弗里施-瓦夫-洛维尔定理
- en: The Frisch-Waugh-Lovell theorem (FWL) is a powerful result that helps build
    a lot of intuition about the inner workings of linear regression. It essentially
    says that you can interpret the OLS estimates as *partialled-out* effects, that
    is, effects net of any other dependencies between features.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 弗里施-瓦夫-洛维尔定理（FWL）是一个有力的结果，帮助理解线性回归的内在工作原理。它基本上表明，您可以将OLS估计解释为*控制后*的效应，即除去任何特征之间的其他依赖效应。
- en: Say that you’re running a regression of sales per customer on the price they
    paid and state dummy variables. If a stakeholder asks you if the price coefficient
    can be explained by state-wise variation in pricing, you can use the FWL theorem
    to convincingly say that these are *net effects*. The price effect has already
    been cleaned out of any differences in pricing across states (you have already
    *controlled* for state differences).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您正在运行一个关于每位客户销售量对其支付价格和状态虚拟变量的回归。如果利益相关者询问您价格系数是否可以解释为不同州定价差异的影响，您可以使用FWL定理确切地说这些是*净效应*。价格效应已经从跨州定价的任何差异中清除（您已经*控制*了州间的差异）。
- en: 'To present the theorem I’ll use the simpler two-feature linear model again,
    but the theorem applies to the more general case of any number of regressors:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示定理，我将再次使用更简单的两特征线性模型，但定理适用于任意数量的回归变量：
- en: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>α</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>ϵ</mi></mrow></math>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>α</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>ϵ</mi></mrow></math>
- en: 'FWL states that you can estimate a specific coefficient, say <math alttext="alpha
    1"><msub><mi>α</mi> <mn>1</mn></msub></math> , by using a two-step process:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: FWL指出，您可以通过两步过程来估计特定系数，比如说<math alttext="alpha 1"><msub><mi>α</mi> <mn>1</mn></msub></math>：
- en: '*Partialling out <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>*
    :'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*对<math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>进行偏离*：'
- en: 'Run a regression of <math alttext="y"><mi>y</mi></math> on <math alttext="x
    2"><msub><mi>x</mi> <mn>2</mn></msub></math> and save the residuals: <math alttext="y
    overTilde Subscript 1"><msub><mover accent="true"><mi>y</mi> <mo>˜</mo></mover>
    <mn>1</mn></msub></math> .'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对<math alttext="y"><mi>y</mi></math>在<math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>上进行回归，并保存残差：<math
    alttext="y overTilde Subscript 1"><msub><mover accent="true"><mi>y</mi> <mo>˜</mo></mover>
    <mn>1</mn></msub></math> 。
- en: 'Run a regression of <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    on <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> and save the
    residuals: <math alttext="x overTilde Subscript 1"><msub><mover accent="true"><mi>x</mi>
    <mo>˜</mo></mover> <mn>1</mn></msub></math> .'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对<math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>在<math alttext="x
    2"><msub><mi>x</mi> <mn>2</mn></msub></math>上进行回归，并保存残差：<math alttext="x overTilde
    Subscript 1"><msub><mover accent="true"><mi>x</mi> <mo>˜</mo></mover> <mn>1</mn></msub></math>。
- en: '*Regression on residuals*:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*残差回归*：'
- en: Run a regression of <math alttext="y overTilde Subscript 1"><msub><mover accent="true"><mi>y</mi>
    <mo>˜</mo></mover> <mn>1</mn></msub></math> on <math alttext="x overTilde Subscript
    1"><msub><mover accent="true"><mi>x</mi> <mo>˜</mo></mover> <mn>1</mn></msub></math>
    . The slope is an estimate of <math alttext="alpha 1"><msub><mi>α</mi> <mn>1</mn></msub></math>
    .
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对<math alttext="y overTilde Subscript 1"><msub><mover accent="true"><mi>y</mi>
    <mo>˜</mo></mover> <mn>1</mn></msub></math>在<math alttext="x overTilde Subscript
    1"><msub><mover accent="true"><mi>x</mi> <mo>˜</mo></mover> <mn>1</mn></msub></math>上进行回归。斜率是<math
    alttext="alpha 1"><msub><mi>α</mi> <mn>1</mn></msub></math>的估计量。
- en: The partialling-out step removes the effect of any other regressor on the outcome
    and the feature of interest. The second step runs a bivariate regression on these
    residuals. Since we have already partialled out the effect of *x*[2], only the
    effect of interest remains.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 偏离步骤去除了其他回归变量对结果和感兴趣特征的影响。第二步在这些残差上运行双变量回归。由于我们已经去除了*x*[2]的效应，因此只剩下感兴趣的效应。
- en: '[Example 10-2](#ch10_fw_check) shows the results when I simulate a linear model
    with three features, and estimate each coefficient using the FWL *partialling-out*
    method and plain linear regression. I use the code snippet in [Example 10-2](#ch10_fw_check)
    to make the comparison.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 10-2](#ch10_fw_check)展示了我使用三个特征模拟线性模型的结果，并使用FWL的*partialling-out*方法和普通线性回归估计每个系数。我使用[示例 10-2](#ch10_fw_check)中的代码片段进行比较。'
- en: Example 10-2\. Checking the validity of FWL
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-2\. 检验FWL的有效性
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Going back to the covariance formula presented earlier, FWL implies that:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 回到先前提出的协方差公式，FWL暗示着
- en: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column equals
    3rd Column StartFraction upper C o v left-parenthesis y overTilde Subscript k
    Baseline comma x overTilde Subscript k Baseline right-parenthesis Over upper V
    a r left-parenthesis x overTilde Subscript k Baseline right-parenthesis EndFraction
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>α</mi>
    <mi>k</mi></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mover
    accent="true"><mi>y</mi> <mo>˜</mo></mover> <mi>k</mi></msub> <mo>,</mo><msub><mover
    accent="true"><mi>x</mi> <mo>˜</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mover accent="true"><mi>x</mi>
    <mo>˜</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column equals
    3rd Column StartFraction upper C o v left-parenthesis y overTilde Subscript k
    Baseline comma x overTilde Subscript k Baseline right-parenthesis Over upper V
    a r left-parenthesis x overTilde Subscript k Baseline right-parenthesis EndFraction
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>α</mi>
    <mi>k</mi></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mover
    accent="true"><mi>y</mi> <mo>˜</mo></mover> <mi>k</mi></msub> <mo>,</mo><msub><mover
    accent="true"><mi>x</mi> <mo>˜</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mover accent="true"><mi>x</mi>
    <mo>˜</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
- en: where as before, <math alttext="x overTilde Subscript k"><msub><mover accent="true"><mi>x</mi>
    <mo>˜</mo></mover> <mi>k</mi></msub></math> denotes the residuals from a regression
    of feature *k* on all other features, and <math alttext="y overTilde Subscript
    k"><msub><mover accent="true"><mi>y</mi> <mo>˜</mo></mover> <mi>k</mi></msub></math>
    denotes the residuals from a regression of the outcome on the same set of features.
    The Python script allows you to test that both versions of the general covariance
    formula give the same results (using the `version` argument).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，<math alttext="x overTilde Subscript k"><msub><mover accent="true"><mi>x</mi>
    <mo>˜</mo></mover> <mi>k</mi></msub></math>表示特征*k*在所有其他特征上回归后的残差，而<math alttext="y
    overTilde Subscript k"><msub><mover accent="true"><mi>y</mi> <mo>˜</mo></mover>
    <mi>k</mi></msub></math>表示因变量在相同特征集上的回归残差。Python脚本允许您测试通用协方差公式的两个版本是否给出相同结果（使用`version`参数）。
- en: An important property of OLS is that the estimated residuals are orthogonal
    to the regressors (or any function of the regressors), a process also known as
    *orthogonalization*. You can use this fact to show that the two covariance formulas
    are equivalent.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: OLS的一个重要特性是估计残差与回归变量（或回归变量的任何函数）正交，这个过程也被称为*正交化*。您可以利用这个事实来表明两个协方差公式是等价的。
- en: 'Importantly, orthogonalization *always* has to be performed on the feature
    of interest. If you only orthogonalize the outcome *y*, the covariance formula
    is no longer valid, *unless* the features are already orthogonal with each other,
    so in general:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，正交化*总是*必须在感兴趣的特征上进行。如果只对因变量*y*进行正交化，那么协方差公式将不再有效，*除非*特征已经相互正交，因此一般而言：
- en: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column not-equals
    3rd Column StartFraction upper C o v left-parenthesis y overTilde Subscript k
    Baseline comma x Subscript k Baseline right-parenthesis Over upper V a r left-parenthesis
    x Subscript k Baseline right-parenthesis EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>α</mi> <mi>k</mi></msub></mtd>
    <mtd><mo>≠</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mover
    accent="true"><mi>y</mi> <mo>˜</mo></mover> <mi>k</mi></msub> <mo>,</mo><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow> <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column not-equals
    3rd Column StartFraction upper C o v left-parenthesis y overTilde Subscript k
    Baseline comma x Subscript k Baseline right-parenthesis Over upper V a r left-parenthesis
    x Subscript k Baseline right-parenthesis EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>α</mi> <mi>k</mi></msub></mtd>
    <mtd><mo>≠</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mover
    accent="true"><mi>y</mi> <mo>˜</mo></mover> <mi>k</mi></msub> <mo>,</mo><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow> <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
- en: Why Should You Care About FWL?
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么您应该关心FWL？
- en: 'I’ve presented several versions of the orthogonalization result, so you should
    expect it to be relevant. The main takeaway is this:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经呈现了几个正交化结果的版本，所以您应该期望它是相关的。主要的要点是：
- en: You can interpret each coefficient from linear regression as the net effect
    of each feature *after* cleaning it from the effects from any other feature.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 您可以将线性回归中的每个系数解释为在清理掉其他任何特征的影响之后的每个特征的净效应。
- en: 'Here’s one typical scenario where this interpretation matters a lot:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个典型的情景，解释起来非常重要：
- en: <math alttext="StartLayout 1st Row 1st Column x 1 2nd Column tilde 3rd Column
    upper N left-parenthesis 0 comma sigma 1 squared right-parenthesis 2nd Row 1st
    Column x 2 2nd Column equals 3rd Column beta 0 plus beta 1 x 1 plus epsilon 3rd
    Row 1st Column y 2nd Column equals 3rd Column alpha 0 plus alpha 1 x 1 plus alpha
    2 x 2 plus eta EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>x</mi> <mn>1</mn></msub></mtd> <mtd><mo>∼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn>0</mn> <mo>,</mo> <msubsup><mi>σ</mi>
    <mn>1</mn> <mn>2</mn></msubsup> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>x</mi>
    <mn>2</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>β</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo> <mi>ϵ</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>α</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>η</mi></mrow></mtd></mtr></mtable></math>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column x 1 2nd Column tilde 3rd Column
    upper N left-parenthesis 0 comma sigma 1 squared right-parenthesis 2nd Row 1st
    Column x 2 2nd Column equals 3rd Column beta 0 plus beta 1 x 1 plus epsilon 3rd
    Row 1st Column y 2nd Column equals 3rd Column alpha 0 plus alpha 1 x 1 plus alpha
    2 x 2 plus eta EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>x</mi> <mn>1</mn></msub></mtd> <mtd><mo>∼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn>0</mn> <mo>,</mo> <msubsup><mi>σ</mi>
    <mn>1</mn> <mn>2</mn></msubsup> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>x</mi>
    <mn>2</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>β</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo> <mi>ϵ</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>α</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>η</mi></mrow></mtd></mtr></mtable></math>
- en: In this case, <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    has a direct and an indirect effect on the outcome *y*. An example could be your
    state or geographic dummy variables. These tend to have direct and indirect effects.
    When you interpret the coefficient of <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    , it would be great if you can say that this is *net* of any state differences,
    since you’re already *controlling* for that variable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，<math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>对结果*y*有直接和间接效应。一个例子可能是您的州或地理虚拟变量。这些往往具有直接和间接效应。当您解释<math
    alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>的系数时，如果您可以说这是在已经*控制*了该变量的情况下的*净*效应，那将非常有帮助。
- en: '[Figure 10-2](#ch10_fw_state) shows the true parameter, OLS estimate, and gradient
    boosting regression (GBR) partial dependence plot (PDP) for a simulation of the
    previous data generating process. Thanks to FWL, you know that OLS will capture
    net effects correctly. GBR does well for <math alttext="x 2"><msub><mi>x</mi>
    <mn>2</mn></msub></math> , but not so well for <math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math> .'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 10-2](#ch10_fw_state)展示了前述数据生成过程的真实参数、OLS估计和梯度提升回归（GBR）的部分依赖图（PDP）的模拟结果。由于FWL，您知道OLS将正确捕捉净效应。GBR在<math
    alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>方面做得很好，但在<math alttext="x
    1"><msub><mi>x</mi> <mn>1</mn></msub></math>方面则不佳。'
- en: 'To understand what’s going on, recall how PDPs are calculated: fix one feature
    at the sample mean, create a grid for the one you care about, and make a prediction.
    When you fix <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> , <math
    alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> displays a combination
    of direct and indirect effects, and the algorithm doesn’t know how to separate
    them. This just reinforces the message that OLS is great for interpretability
    purposes, but requires quite a bit of effort to get the performance that even
    a relatively out-of-the-box GBR has with nonlinear models.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解正在发生的事情，回想一下如何计算PDP：将一个特征固定在样本均值，为你关心的特征创建一个网格，并进行预测。当你固定 <math alttext="x
    2"><msub><mi>x</mi> <mn>2</mn></msub></math> 时，<math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math> 显示出直接和间接效应的组合，算法不知道如何分离它们。这只是加强了OLS在可解释性方面的优势，但需要相当大的努力才能达到即使相对于非线性模型也能很容易得到的性能。
- en: '![state example](assets/dshp_1002.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![state example](assets/dshp_1002.png)'
- en: Figure 10-2\. OLS and gradient boosting with direct and indirect effects
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-2\. OLS和具有直接和间接效应的梯度提升
- en: Confounders
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混杂因素
- en: 'Now that I’ve described the FWL theorem, I want to go back to the problem of
    confounders ([Figure 10-1](#ch10_confounder)). Suppose that a confounder ( <math
    alttext="w"><mi>w</mi></math> ) affects two otherwise unrelated variables:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经描述了FWL定理，我想回到混杂因素的问题（[Figure 10-1](#ch10_confounder)）。假设一个混杂因素（ <math alttext="w"><mi>w</mi></math>
    ）影响了两个本来不相关的变量：
- en: <math alttext="StartLayout 1st Row 1st Column x 2nd Column equals 3rd Column
    alpha Subscript x Baseline plus beta Subscript x Baseline w plus epsilon Subscript
    x 2nd Row 1st Column y 2nd Column equals 3rd Column alpha Subscript y Baseline
    plus beta Subscript y Baseline w plus epsilon Subscript y 3rd Row 1st Column epsilon
    Subscript x 2nd Column up-tack up-tack 3rd Column epsilon Subscript y 4th Row
    1st Column epsilon Subscript x Baseline comma epsilon Subscript y Baseline 2nd
    Column up-tack up-tack 3rd Column w EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mi>x</mi></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>α</mi>
    <mi>x</mi></msub> <mo>+</mo> <msub><mi>β</mi> <mi>x</mi></msub> <mi>w</mi> <mo>+</mo>
    <msub><mi>ϵ</mi> <mi>x</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>α</mi> <mi>y</mi></msub>
    <mo>+</mo> <msub><mi>β</mi> <mi>y</mi></msub> <mi>w</mi> <mo>+</mo> <msub><mi>ϵ</mi>
    <mi>y</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>ϵ</mi>
    <mi>x</mi></msub></mtd> <mtd><mrow><mo>⊥</mo> <mo>⊥</mo></mrow></mtd> <mtd columnalign="left"><msub><mi>ϵ</mi>
    <mi>y</mi></msub></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msub><mi>ϵ</mi>
    <mi>x</mi></msub> <mo>,</mo> <msub><mi>ϵ</mi> <mi>y</mi></msub></mrow></mtd> <mtd><mrow><mo>⊥</mo>
    <mo>⊥</mo></mrow></mtd> <mtd columnalign="left"><mi>w</mi></mtd></mtr></mtable></math>
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column x 2nd Column equals 3rd Column
    alpha Subscript x Baseline plus beta Subscript x Baseline w plus epsilon Subscript
    x 2nd Row 1st Column y 2nd Column equals 3rd Column alpha Subscript y Baseline
    plus beta Subscript y Baseline w plus epsilon Subscript y 3rd Row 1st Column epsilon
    Subscript x 2nd Column up-tack up-tack 3rd Column epsilon Subscript y 4th Row
    1st Column epsilon Subscript x Baseline comma epsilon Subscript y Baseline 2nd
    Column up-tack up-tack 3rd Column w EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mi>x</mi></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>α</mi>
    <mi>x</mi></msub> <mo>+</mo> <msub><mi>β</mi> <mi>x</mi></msub> <mi>w</mi> <mo>+</mo>
    <msub><mi>ϵ</mi> <mi>x</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>α</mi> <mi>y</mi></msub>
    <mo>+</mo> <msub><mi>β</mi> <mi>y</mi></msub> <mi>w</mi> <mo>+</mo> <msub><mi>ϵ</mi>
    <mi>y</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>ϵ</mi>
    <mi>x</mi></msub></mtd> <mtd><mrow><mo>⊥</mo> <mo>⊥</mo></mrow></mtd> <mtd columnalign="left"><msub><mi>ϵ</mi>
    <mi>y</mi></msub></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msub><mi>ϵ</mi>
    <mi>x</mi></msub> <mo>,</mo> <msub><mi>ϵ</mi> <mi>y</mi></msub></mrow></mtd> <mtd><mrow><mo>⊥</mo>
    <mo>⊥</mo></mrow></mtd> <mtd columnalign="left"><mi>w</mi></mtd></mtr></mtable></math>
- en: 'where the symbol <math alttext="up-tack up-tack"><mrow><mo>⊥</mo> <mo>⊥</mo></mrow></math>
    denotes statistical independence. Using the covariance formula for the slope coefficient
    in a regression of *y* on *x*, it becomes apparent why OLS shows spurious results:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 其中符号 <math alttext="up-tack up-tack"><mrow><mo>⊥</mo> <mo>⊥</mo></mrow></math>
    表示统计独立性。使用回归中*y*对*x*的斜率系数的协方差公式，就可以明显看出为什么OLS显示出虚假结果：
- en: <math alttext="StartFraction upper C o v left-parenthesis y comma x right-parenthesis
    Over upper V a r left-parenthesis x right-parenthesis EndFraction equals StartFraction
    beta Subscript x Baseline beta Subscript y Baseline upper V a r left-parenthesis
    w right-parenthesis Over beta Subscript x Superscript 2 Baseline upper V a r left-parenthesis
    w right-parenthesis plus upper V a r left-parenthesis epsilon Subscript x Baseline
    right-parenthesis EndFraction" display="block"><mrow><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><mi>x</mi><mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><msub><mi>β</mi> <mi>x</mi></msub> <msub><mi>β</mi> <mi>y</mi></msub>
    <mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><mi>w</mi><mo>)</mo></mrow></mrow>
    <mrow><msubsup><mi>β</mi> <mi>x</mi> <mn>2</mn></msubsup> <mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><mi>w</mi><mo>)</mo></mrow><mo>+</mo><mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><msub><mi>ϵ</mi>
    <mi>x</mi></msub> <mo>)</mo></mrow></mrow></mfrac></mrow></math>
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction upper C o v left-parenthesis y comma x right-parenthesis
    Over upper V a r left-parenthesis x right-parenthesis EndFraction equals StartFraction
    beta Subscript x Baseline beta Subscript y Baseline upper V a r left-parenthesis
    w right-parenthesis Over beta Subscript x Superscript 2 Baseline upper V a r left-parenthesis
    w right-parenthesis plus upper V a r left-parenthesis epsilon Subscript x Baseline
    right-parenthesis EndFraction" display="block"><mrow><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><mi>x</mi><mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><msub><mi>β</mi> <mi>x</mi></msub> <msub><mi>β</mi> <mi>y</mi></msub>
    <mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><mi>w</mi><mo>)</mo></mrow></mrow>
    <mrow><msubsup><mi>β</mi> <mi>x</mi> <mn>2</mn></msubsup> <mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><mi>w</mi><mo>)</mo></mrow><mo>+</mo><mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><msub><mi>ϵ</mi>
    <mi>x</mi></msub> <mo>)</mo></mrow></mrow></mfrac></mrow></math>
- en: 'What if you first *cleaned* that common factor out? That’s exactly what FWL
    tells you that linear regression does, so you can safely run a regression of the
    form:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你先*清理*掉那个共同因素呢？这正是FWL告诉你线性回归所做的事情，所以你可以安全地运行以下形式的回归：
- en: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 w plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>α</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>2</mn></msub> <mi>w</mi> <mo>+</mo> <mi>ϵ</mi></mrow></math>
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 w plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>α</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>2</mn></msub> <mi>w</mi> <mo>+</mo> <mi>ϵ</mi></mrow></math>
- en: By also including the common factor *w*, OLS will effectively partial out its
    effect. [Figure 10-3](#ch10_fw_confound) shows the results of estimating the bivariate
    and spurious regression (left plot) and the partialled-out version when you also
    include the third factor as in the previous equation (right plot). I also include
    95% confidence intervals.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 通过同时包括共同因素*w*，OLS将有效地将其效果分离出来。[Figure 10-3](#ch10_fw_confound) 展示了估计的双变量和虚假回归结果（左图）以及当你像前述方程式中一样包括第三个因素时的分离版本（右图）。我还包括了95%置信区间。
- en: Without controlling for the confounder, you would conclude that *x* and *y*
    are indeed correlated (confidence interval away from zero), but once you control
    for *w*, this becomes the only relevant (statistically significant) factor.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不控制混杂因素，你会得出*x*和*y*确实相关的结论（置信区间远离零），但一旦你控制*w*，这就成为唯一相关的（统计显著）因素。
- en: '![FW + confounder](assets/dshp_1003.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![FW + 混杂因素](assets/dshp_1003.png)'
- en: Figure 10-3\. FW and controlling for confounders (estimate and 95% CI)
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-3\. FW和混杂因素的控制（估计值和95% CI）
- en: 'This result is very useful in many applications. In time series analysis, for
    example, it’s quite common to have [*trend-stationary*](https://oreil.ly/ewcVV)
    variables that can be modelled like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果在许多应用中非常有用。例如，在时间序列分析中，拥有[*趋势稳定*](https://oreil.ly/ewcVV) 的变量经常可以这样建模：
- en: <math alttext="StartLayout 1st Row  y Subscript 1 t Baseline equals alpha 1
    plus beta 1 t plus epsilon Subscript 1 t Baseline 2nd Row  y Subscript 2 t Baseline
    equals alpha 2 plus beta 2 t plus epsilon Subscript 2 t EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>y</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>α</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub>
    <mi>t</mi> <mo>+</mo> <msub><mi>ϵ</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msub><mi>y</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>α</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>2</mn></msub>
    <mi>t</mi> <mo>+</mo> <msub><mi>ϵ</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub></mrow></mtd></mtr></mtable></math>
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row  y Subscript 1 t Baseline equals alpha 1
    plus beta 1 t plus epsilon Subscript 1 t Baseline 2nd Row  y Subscript 2 t Baseline
    equals alpha 2 plus beta 2 t plus epsilon Subscript 2 t EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>y</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>α</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub>
    <mi>t</mi> <mo>+</mo> <msub><mi>ϵ</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msub><mi>y</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>α</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>2</mn></msub>
    <mi>t</mi> <mo>+</mo> <msub><mi>ϵ</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub></mrow></mtd></mtr></mtable></math>
- en: 'Thanks to FWL, you already know why these are called *trend-stationary*: once
    you control for a time trend (*t* above), thereby cleaning them from this effect,
    you end up with a stationary time series.^([2](ch10.html#id599))'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了FWL，你已经知道为什么这些被称为*趋势稳定*：一旦你控制了时间趋势（*t*以上），从而清理了它们的这种影响，你就得到了一个稳定的时间序列。^([2](ch10.html#id599))
- en: 'Suppose you run a regression of one on the other:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你对一个变量进行回归：
- en: <math alttext="y Subscript 2 t Baseline equals theta 0 plus theta 1 y Subscript
    1 t Baseline plus zeta Subscript t" display="block"><mrow><msub><mi>y</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <msub><mi>y</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub> <mo>+</mo> <msub><mi>ζ</mi>
    <mi>t</mi></msub></mrow></math>
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y Subscript 2 t Baseline equals theta 0 plus theta 1 y Subscript
    1 t Baseline plus zeta Subscript t" display="block"><mrow><msub><mi>y</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <msub><mi>y</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub> <mo>+</mo> <msub><mi>ζ</mi>
    <mi>t</mi></msub></mrow></math>
- en: Since you’re not controlling for the common trend, you will end up incorrectly
    concluding that they are correlated. [Figure 10-4](#ch10_ts_trend) shows regression
    results from a simulation of two trend-stationary AR(1) processes that are unrelated
    by design.^([3](ch10.html#id600)) The plot shows the estimated intercept (*constant*)
    and slope for the second variable (*y2*), as well as 95% confidence intervals.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你没有控制共同趋势，你最终会错误地得出它们相关的结论。[Figure 10-4](#ch10_ts_trend) 展示了两个趋势稳定的AR(1)过程的模拟回归结果，设计上它们是无关的。^([3](ch10.html#id600))
    图显示了第二个变量（*y2*）的估计截距（*常数*）和斜率，以及95%置信区间。
- en: '![trend spurious](assets/dshp_1004.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![趋势虚假](assets/dshp_1004.png)'
- en: Figure 10-4\. OLS on spurious time series regression
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-4\. OLS在虚假时间序列回归上的表现
- en: Tip
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: It’s quite common to have spurious correlation with time series, as they most
    often display a time trend. Since it can act as a confounder, it’s always recommended
    to include a linear time trend as a control. This way you *clean up* any noise
    that may arise from this potential confounder.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列常常出现与时间相关的虚假相关性，因为它们通常显示时间趋势。由于它可能作为混杂因素，建议始终包括线性时间趋势作为控制变量。这样你可以*清除*由此潜在混杂因素引起的任何噪音。
- en: Additional Variables
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 额外变量
- en: '[Chapter 9](ch09.html#ch09_simulation) described the *omitted variable bias*
    that showed that *excluding* a variable that should have been included results
    in biased OLS estimates and thus, reduced predictive performance; importantly,
    this is also true for other machine learning (ML) algorithms.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](ch09.html#ch09_simulation) 描述了*遗漏变量偏差*，表明*排除*本应包含的变量会导致OLS估计偏差，从而降低预测性能；这一点同样适用于其他机器学习（ML）算法。'
- en: 'What happens if instead of omitting important variables, you include additional
    irrelevant features? One of the nice properties of OLS is that including uninformative
    features creates no bias, and only affects the variance of the estimates. [Figure 10-5](#ch10_morevars)
    reports the mean and 90% confidence intervals for each estimated parameter from
    a Monte Carlo simulation, where:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不是省略重要变量而是包含额外无关特征会发生什么？OLS的一个优点是包含无信息特征不会引入偏差，只会影响估计的方差。[Figure 10-5](#ch10_morevars)
    报告了从蒙特卡洛模拟中估计的每个参数的均值和90%置信区间，其中：
- en: Only one feature is informative ( <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    , with true coefficient <math alttext="alpha 1 equals 3"><mrow><msub><mi>α</mi>
    <mn>1</mn></msub> <mo>=</mo> <mn>3</mn></mrow></math> ).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有一个特征是有信息的（ <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> ，其真实系数
    <math alttext="alpha 1 equals 3"><mrow><msub><mi>α</mi> <mn>1</mn></msub> <mo>=</mo>
    <mn>3</mn></mrow></math> ）。
- en: Four more uninformative controls are included when the model is trained.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当模型训练时包括了四个更多的无信息控制。
- en: 'Two models are trained: OLS and an out-of-the-box gradient boosting regression.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练了两个模型：OLS和开箱即用的梯度提升回归。
- en: 'Both algorithms perform correctly on two fronts: they are able to correctly
    estimate the true parameter, and dismiss the uninformative variables.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 两种算法在两个方面表现正确：它们能够正确估计真实参数，并排除无信息变量。
- en: '![including uninformative variables](assets/dshp_1005.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![包含无信息变量](assets/dshp_1005.png)'
- en: Figure 10-5\. Effect of including uninformative controls
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-5\. 包含无信息控制的影响
- en: 'However, you must be cautious with ensemble learning algorithms since these
    tend to be quite sensitive when uninformative features are included, if these
    are highly correlated with the real underlying variables. You can typically see
    this with the *dummy variable trap*. The typical scenario arises with models with
    a dummy variable, like the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于集成学习算法，你必须小心，因为它们在包含高度相关于真实潜在变量的无信息特征时通常非常敏感。你通常可以通过*虚拟变量陷阱*来看到这一点。这种典型的情况出现在像下面这样有虚拟变量的模型中：
- en: <math alttext="StartLayout 1st Row 1st Column y 2nd Column equals 3rd Column
    alpha 0 plus alpha 1 x plus alpha 2 upper D Subscript l plus epsilon 2nd Row 1st
    Column upper D Subscript l 2nd Column equals 3rd Column StartLayout Enlarged left-brace
    1st Row 1st Column 1 2nd Column if 3rd Column customer is left hyphen handed 2nd
    Row 1st Column 0 2nd Column if 3rd Column customer is right hyphen handed EndLayout
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>α</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>α</mi>
    <mn>2</mn></msub> <msub><mi>D</mi> <mi>l</mi></msub> <mo>+</mo> <mi>ϵ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>D</mi> <mi>l</mi></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfenced close="" open="{" separators=""><mtable><mtr><mtd
    columnalign="left"><mn>1</mn></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><mtext>customer</mtext> <mtext>is</mtext> <mtext>left-handed</mtext></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mn>0</mn></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><mtext>customer</mtext> <mtext>is</mtext> <mtext>right-handed</mtext></mrow></mtd></mtr></mtable></mfenced></mtd></mtr></mtable></math>
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column y 2nd Column equals 3rd Column
    alpha 0 plus alpha 1 x plus alpha 2 upper D Subscript l plus epsilon 2nd Row 1st
    Column upper D Subscript l 2nd Column equals 3rd Column StartLayout Enlarged left-brace
    1st Row 1st Column 1 2nd Column if 3rd Column customer is left hyphen handed 2nd
    Row 1st Column 0 2nd Column if 3rd Column customer is right hyphen handed EndLayout
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>α</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>α</mi> <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>α</mi>
    <mn>2</mn></msub> <msub><mi>D</mi> <mi>l</mi></msub> <mo>+</mo> <mi>ϵ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>D</mi> <mi>l</mi></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfenced close="" open="{" separators=""><mtable><mtr><mtd
    columnalign="left"><mn>1</mn></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><mtext>customer</mtext> <mtext>is</mtext> <mtext>left-handed</mtext></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mn>0</mn></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><mtext>customer</mtext> <mtext>is</mtext> <mtext>right-handed</mtext></mrow></mtd></mtr></mtable></mfenced></mtd></mtr></mtable></math>
- en: "In OLS, the dummy variable trap arises when you include an intercept *and*\
    \ dummies for *all* available categories. In this example, you can only include\
    \ *one* dummy variable for left- *or* right-handedness, but not both, because\
    \ the cross-product matrix <math alttext=\"upper X prime upper X\"><mrow><mi>X</mi>\
    \ <mi>â</mi> <mi>\x80</mi> <mi>\x99</mi> <mi>X</mi></mrow></math> is not invertible\
    \ (and thus the OLS estimates don’t exist).^([4](ch10.html#id604)) The solution\
    \ is to always leave out the dummy variable for a *reference category*, in the\
    \ example, the right-handed category."
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: "在OLS中，当你包括一个截距 *和* 所有可用类别的虚拟变量时，就会出现虚拟变量陷阱。在这个例子中，你只能为左右利手中的 *一个* 虚拟变量进行包含，而不能同时包含两者，因为交叉乘积矩阵\
    \ <math alttext=\"upper X prime upper X\"><mrow><mi>X</mi> <mi>â</mi> <mi>\x80\
    </mi> <mi>\x99</mi> <mi>X</mi></mrow></math> 是不可逆的（因此OLS估计不存在）。^([4](ch10.html#id604))\
    \ 解决方法是始终省略参考类别的虚拟变量，例如在本例中是右利手类别。"
- en: This computational restriction doesn’t exist with ensemble algorithms like random
    forests or gradient boosting regression, but since dummy variables like *D[l]*
    and *D[r]* = 1 − *D[l]* are perfectly correlated, it’s normal to find both ranking
    very high in terms of feature importance. Since they provide the *exact same information*,
    the performance of the algorithm doesn’t improve by including both. This is one
    useful intuitive fact that arises naturally by understanding OLS.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 与随机森林或梯度提升回归等集成算法不同，这种计算限制不存在，但由于像*D[l]*和*D[r]* = 1 − *D[l]*这样的虚拟变量完全相关，很正常会发现它们在特征重要性方面排名都很高。因为它们提供*完全相同的信息*，所以通过包括两者来提升算法的性能是无效的。这是一条有用的直观事实，通过理解OLS方法自然产生。
- en: The Central Role of Variance in ML
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习中方差的中心作用
- en: 'One central tenet in ML is that you need variation in the features *and* the
    outcome for your algorithm to *identify* the parameters, or put differently, to
    learn the correlation. You can see this directly in the covariance formulation
    presented at the beginning: if *x* or *y* are constant, the covariance is zero,
    and hence OLS can’t learn the parameter. Moreover, if *x* is constant, the denominator
    is zero, and thus the parameter doesn’t exist, a result strongly connected to
    the dummy variable trap.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的一个核心原则是，你需要在特征和结果中有变化，这样你的算法才能*识别*参数，或者换句话说，学习相关性。你可以直接在开头呈现的协方差公式中看到这一点：如果*x*或*y*是常数，协方差就为零，因此OLS无法学习参数。此外，如果*x*是常数，分母为零，因此参数不存在，这与虚拟变量陷阱密切相关的结果。
- en: Tip
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: You need variation in the inputs if you want to explain variation in the output.
    This is true for any ML algorithm.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想解释输出的变化，你需要输入中的变化。这对任何机器学习算法都是真实的。
- en: 'You may recall that in OLS, the estimates for the coefficients and the covariance
    matrix are:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能记得在OLS中，系数和协方差矩阵的估计值为：
- en: "<math alttext=\"StartLayout 1st Row 1st Column ModifyingAbove beta With bold\
    \ caret 2nd Column equals 3rd Column left-parenthesis upper X prime upper X right-parenthesis\
    \ Superscript negative 1 Baseline upper X prime upper Y 2nd Row 1st Column Var\
    \ left-parenthesis ModifyingAbove beta With bold caret bold right-parenthesis\
    \ 2nd Column equals 3rd Column s squared left-parenthesis upper X prime upper\
    \ X right-parenthesis Superscript negative 1 EndLayout\" display=\"block\"><mtable\
    \ displaystyle=\"true\"><mtr><mtd columnalign=\"right\"><mover accent=\"true\"\
    ><mi>β</mi> <mo>^</mo></mover></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign=\"\
    left\"><mrow><msup><mrow><mo>(</mo><mi>X</mi><mi>â</mi><mi>\x80</mi><mi>\x99</mi><mi>X</mi><mo>)</mo></mrow>\
    \ <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>X</mi> <mi>â</mi> <mi>\x80</mi>\
    \ <mi>\x99</mi> <mi>Y</mi></mrow></mtd></mtr> <mtr><mtd columnalign=\"right\"\
    ><mrow><mtext>Var</mtext> <mo>(</mo> <mover accent=\"true\"><mi>β</mi> <mo>^</mo></mover>\
    \ <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign=\"left\"><mrow><msup><mi>s</mi>\
    \ <mn>2</mn></msup> <msup><mrow><mo>(</mo><mi>X</mi><mi>â</mi><mi>\x80</mi><mi>\x99\
    </mi><mi>X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mtd></mtr></mtable></math>"
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: "<math alttext=\"StartLayout 1st Row 1st Column ModifyingAbove beta With bold\
    \ caret 2nd Column equals 3rd Column left-parenthesis upper X prime upper X right-parenthesis\
    \ Superscript negative 1 Baseline upper X prime upper Y 2nd Row 1st Column Var\
    \ left-parenthesis ModifyingAbove beta With bold caret bold right-parenthesis\
    \ 2nd Column equals 3rd Column s squared left-parenthesis upper X prime upper\
    \ X right-parenthesis Superscript negative 1 EndLayout\" display=\"block\"><mtable\
    \ displaystyle=\"true\"><mtr><mtd columnalign=\"right\"><mover accent=\"true\"\
    ><mi>β</mi> <mo>^</mo></mover></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign=\"\
    left\"><mrow><msup><mrow><mo>(</mo><mi>X</mi><mi>â</mi><mi>\x80</mi><mi>\x99</mi><mi>X</mi><mo>)</mo></mrow>\
    \ <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>X</mi> <mi>â</mi> <mi>\x80</mi>\
    \ <mi>\x99</mi> <mi>Y</mi></mrow></mtd></mtr> <mtr><mtd columnalign=\"right\"\
    ><mrow><mtext>Var</mtext> <mo>(</mo> <mover accent=\"true\"><mi>β</mi> <mo>^</mo></mover>\
    \ <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign=\"left\"><mrow><msup><mi>s</mi>\
    \ <mn>2</mn></msup> <msup><mrow><mo>(</mo><mi>X</mi><mi>â</mi><mi>\x80</mi><mi>\x99\
    </mi><mi>X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mtd></mtr></mtable></math>"
- en: where <math alttext="s squared"><msup><mi>s</mi> <mn>2</mn></msup></math> is
    the sample estimate of the residual variance, and <math alttext="upper X Subscript
    upper N times upper P"><msub><mi>X</mi> <mrow><mi>N</mi><mo>×</mo><mi>P</mi></mrow></msub></math>
    is the feature matrix, including the vector of ones that correspond to the intercept.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 其中<math alttext="s squared"><msup><mi>s</mi> <mn>2</mn></msup></math>是残差方差的样本估计，<math
    alttext="upper X Subscript upper N times upper P"><msub><mi>X</mi> <mrow><mi>N</mi><mo>×</mo><mi>P</mi></mrow></msub></math>是包括对应于截距的一向量的特征矩阵。
- en: 'From these equations, two results follow:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些方程中可以得出两个结果：
- en: Conditions for identification
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 识别条件
- en: "There can’t be perfect correlation between features (perfect multicollinearity)\
    \ for the cross-product matrix <math alttext=\"left-parenthesis upper X prime\
    \ upper X right-parenthesis\"><mrow><mo>(</mo> <mi>X</mi> <mi>â</mi> <mi>\x80\
    </mi> <mi>\x99</mi> <mi>X</mi> <mo>)</mo></mrow></math> to be positive definite\
    \ (full rank or invertible)."
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: "特征之间不能有完全相关（完全多重共线性），以使交叉乘积矩阵<math alttext=\"left-parenthesis upper X prime\
    \ upper X right-parenthesis\"><mrow><mo>(</mo> <mi>X</mi> <mi>â</mi> <mi>\x80\
    </mi> <mi>\x99</mi> <mi>X</mi> <mo>)</mo></mrow></math>是正定（满秩或可逆）。"
- en: Variance of the estimates
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 估计的方差
- en: The more correlated the features, the higher the variance of the estimates.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 特征相关性越高，估计的方差越大。
- en: While the first part should be straightforward, the second requires a bit of
    mathematical manipulation to show for the general case of multiple regression.
    In the [repo](https://oreil.ly/dshp-repo) for this chapter, I include a simulation
    that verifies this condition in the case of multiple regression. For a simple
    bivariate regression, it’s easy to show that the variance of the estimate is *negatively
    related* to the sample variance of the feature, so having covariates that exhibit
    more variation provides more information, thereby improving the precision of the
    estimates.^([5](ch10.html#id613))
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然第一部分应该很简单，但第二部分需要进行一些数学处理，以展示多元回归的一般情况。在这一章节的[repo](https://oreil.ly/dshp-repo)中，我包含了一个模拟，验证了在多元回归情况下这个条件。对于简单的双变量回归，很容易展示估计的方差与特征的样本方差呈*负相关*，因此具有更多变化的协变量提供更多信息，从而提高估计的精度。^([5](ch10.html#id613))
- en: '[Figure 10-6](#ch10_variance_gb) plots the average and 95% confidence intervals
    for the estimates from OLS and gradient boosting regression after simulating a
    bivariate linear DGP where Var(*x*[1]) is increased over a grid. As discussed,
    for OLS the variance of the estimate *decreases* as the covariate displays *more*
    variation. Notably, the same is true for GBR.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 10-6](#ch10_variance_gb) 展示了模拟双变量线性DGP后OLS和梯度提升回归估计的平均值和95%置信区间，其中Var(*x*[1])在一个网格上增加。正如讨论的那样，对于OLS来说，估计的方差随着协变量显示更多变化而*减少*。值得注意的是，对于GBR也是如此。'
- en: '![variance GB](assets/dshp_1006.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![方差GB](assets/dshp_1006.png)'
- en: Figure 10-6\. Variance of an estimate for OLS and GBR
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-6\. OLS和GBR估计的方差
- en: 'This principle is at play in a practice that is not uncommon among data scientists.
    Imagine that you’re running a regression like the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这个原理在数据科学家中并不罕见的实践中发挥作用。想象一下，您正在运行以下回归：
- en: <math alttext="StartLayout 1st Row 1st Column y Subscript i 2nd Column equals
    3rd Column alpha plus sigma-summation Underscript s Endscripts theta Subscript
    s Baseline upper D Subscript i s plus gamma z overbar Subscript s left-parenthesis
    i right-parenthesis plus epsilon Subscript i 2nd Row 1st Column upper D Subscript
    i s 2nd Column equals 3rd Column StartLayout Enlarged left-brace 1st Row 1st Column
    1 2nd Column if 3rd Column customer i lives in state s 2nd Row 1st Column 0 2nd
    Column Blank 3rd Column otherwise EndLayout 3rd Row 1st Column z overbar Subscript
    s left-parenthesis i right-parenthesis 2nd Column equals 3rd Column state sample
    average of z given the state where i lives EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>y</mi> <mi>i</mi></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mi>α</mi> <mo>+</mo> <munder><mo>∑</mo>
    <mi>s</mi></munder> <msub><mi>θ</mi> <mi>s</mi></msub> <msub><mi>D</mi> <mrow><mi>i</mi><mi>s</mi></mrow></msub>
    <mo>+</mo> <mi>γ</mi> <msub><mover><mi>z</mi> <mo>¯</mo></mover> <mrow><mi>s</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub>
    <mo>+</mo> <msub><mi>ϵ</mi> <mi>i</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>D</mi>
    <mrow><mi>i</mi><mi>s</mi></mrow></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfenced
    close="" open="{" separators=""><mtable><mtr><mtd columnalign="left"><mn>1</mn></mtd>
    <mtd columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><mtext>customer</mtext>
    <mi>i</mi> <mtext>lives</mtext> <mtext>in</mtext> <mtext>state</mtext> <mi>s</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mn>0</mn></mtd> <mtd><mtext>otherwise</mtext></mtd></mtr></mtable></mfenced></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mover><mi>z</mi> <mo>¯</mo></mover> <mrow><mi>s</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mtext>state</mtext> <mtext>sample</mtext>
    <mtext>average</mtext> <mtext>of</mtext> <mi>z</mi> <mtext>given</mtext> <mtext>the</mtext>
    <mtext>state</mtext> <mtext>where</mtext> <mi>i</mi> <mtext>lives</mtext></mrow></mtd></mtr></mtable></math>
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column y Subscript i 2nd Column equals
    3rd Column alpha plus sigma-summation Underscript s Endscripts theta Subscript
    s Baseline upper D Subscript i s plus gamma z overbar Subscript s left-parenthesis
    i right-parenthesis plus epsilon Subscript i 2nd Row 1st Column upper D Subscript
    i s 2nd Column equals 3rd Column StartLayout Enlarged left-brace 1st Row 1st Column
    1 2nd Column if 3rd Column customer i lives in state s 2nd Row 1st Column 0 2nd
    Column Blank 3rd Column otherwise EndLayout 3rd Row 1st Column z overbar Subscript
    s left-parenthesis i right-parenthesis 2nd Column equals 3rd Column state sample
    average of z given the state where i lives EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>y</mi> <mi>i</mi></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mi>α</mi> <mo>+</mo> <munder><mo>∑</mo>
    <mi>s</mi></munder> <msub><mi>θ</mi> <mi>s</mi></msub> <msub><mi>D</mi> <mrow><mi>i</mi><mi>s</mi></mrow></msub>
    <mo>+</mo> <mi>γ</mi> <msub><mover><mi>z</mi> <mo>¯</mo></mover> <mrow><mi>s</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub>
    <mo>+</mo> <msub><mi>ϵ</mi> <mi>i</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>D</mi>
    <mrow><mi>i</mi><mi>s</mi></mrow></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfenced
    close="" open="{" separators=""><mtable><mtr><mtd columnalign="left"><mn>1</mn></mtd>
    <mtd columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><mtext>customer</mtext>
    <mi>i</mi> <mtext>lives</mtext> <mtext>in</mtext> <mtext>state</mtext> <mi>s</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mn>0</mn></mtd> <mtd><mtext>otherwise</mtext></mtd></mtr></mtable></mfenced></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mover><mi>z</mi> <mo>¯</mo></mover> <mrow><mi>s</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mtext>state</mtext> <mtext>sample</mtext>
    <mtext>average</mtext> <mtext>of</mtext> <mi>z</mi> <mtext>given</mtext> <mtext>the</mtext>
    <mtext>state</mtext> <mtext>where</mtext> <mi>i</mi> <mtext>lives</mtext></mrow></mtd></mtr></mtable></math>
- en: If *y* denotes sales per customer and *z* household income, this model says
    that sales vary across states (dummy variables) and that there’s an independent
    effect whereby richer states also purchase more (proxied with the average household
    income for each state).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*y*表示每位顾客的销售额，*z*表示家庭收入，该模型表明销售额在各州（虚拟变量）之间变化，并且富裕的州也有独立的效应，富裕州购买更多（用每个州的平均家庭收入来代表）。
- en: While your intuition might be right, you won’t be able to train this model with
    OLS since there’s perfect multicollinearity. In other words, the state dummy variables
    and state averages *of any metric you can think of* provide the *exact same information*.
    And this is true for any ML algorithm!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您的直觉可能是正确的，但由于存在完全多重共线性，您无法用OLS训练这个模型。换句话说，州虚拟变量和任何您能想到的州平均值*提供相同的信息*。对于任何机器学习算法都是如此！
- en: To check this, I simulate a simple model using the data generating process I
    just covered, where I include three states (and thus, two dummy variables to avoid
    the dummy variable trap) drawn from a multinomial distribution (code can be found
    in the [repo](https://oreil.ly/dshp-repo)). [Example 10-3](#ch10_rankz) shows
    that the features matrix is indeed low rank, implying that there’s perfect multicollinearity.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证这一点，我使用刚才讨论的数据生成过程模拟了一个简单的模型，其中包括三个州（因此，为避免虚拟变量陷阱，有两个虚拟变量），这些州从多项分布中抽取（代码可以在[repo](https://oreil.ly/dshp-repo)中找到）。[示例 10-3](#ch10_rankz)
    表明特征矩阵确实是低秩的，意味着存在完全多重共线性。
- en: 'Example 10-3\. State dummies: effect of dropping the state average'
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 10-3\. 状态虚拟变量：删除状态平均值的影响
- en: '[PRE5]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: To check that the same point is valid for more general nonlinear algorithms,
    I ran a Monte Carlo (MC) simulation of this same model, training it with gradient
    boosting regression (no metaparameter optimization) and calculated the mean squared
    error (MSE) for the test sample using the complete set of features and after dropping
    the redundant mean feature. [Figure 10-7](#ch10_gbrstate) shows the average MSE
    along with 90% confidence intervals for MSE. You can verify that the predictive
    performance is virtually the same, as you would expect if the extra variable provides
    no additional information.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证更一般非线性算法也具有同样的观点，我对这个同样的模型进行了蒙特卡罗（MC）模拟，用梯度提升回归（没有元参数优化）进行训练，并计算了测试样本的均方误差（MSE），使用完整特征集和去掉多余均值特征后的情况。[图 10-7](#ch10_gbrstate)
    展示了MSE的平均值和90%置信区间。您可以验证预测性能几乎相同，这是您期望的，因为额外变量未提供额外信息。
- en: '![gbr state](assets/dshp_1007.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![GBR州](assets/dshp_1007.png)'
- en: Figure 10-7\. Results from MC simulation for gradient boosting
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-7\. 梯度提升MC模拟结果
- en: Key Takeaways
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 要点
- en: 'These are the key takeaways from this chapter:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是本章的要点：
- en: Why learn linear regression?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么学习线性回归？
- en: Understanding linear regression should help you build some important intuitions
    that apply more generally to other nonlinear algorithms, such as random forests
    or boosting techniques.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 理解线性回归应该帮助您建立一些重要的直觉，这些直觉更普遍适用于其他非线性算法，如随机森林或提升技术。
- en: Correlation is not causation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性不等于因果关系。
- en: In general, machine learning algorithms only provide information about the correlation
    of features and outcome. The result is clear cut in linear regression, so this
    should serve as your benchmark when thinking about other learning algorithms.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，机器学习算法只提供关于特征与结果相关性的信息。线性回归结果明确，因此在思考其他学习算法时，这应作为您的基准。
- en: Frisch-Waugh-Lovell theorem.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Frisch-Waugh-Lovell定理。
- en: This is an important result in linear regression that states that the estimates
    can be interpreted as the net effect after controlling for the remaining covariates.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这是线性回归中的一个重要结果，指出估计量可以被解释为在控制剩余协变量之后的净效应。
- en: FWL and confounders.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: FWL 和混杂因素。
- en: Thanks to FWL, you can control for confounders just by including them in your
    set of features. One common example is in time series analysis, where it’s always
    a good practice to control for a deterministic trend. This acts as a safeguard
    against getting spurious results when the outcome and features display some trend.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 FWL，你可以通过将其包含在特征集中来控制混杂因素。一个常见的例子是在时间序列分析中，总是良好的做法是控制确定性趋势。这可以防止当结果和特征显示某些趋势时产生虚假结果。
- en: Irrelevant variables.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 无关变量。
- en: In linear regression, it is safe to include uninformative controls. Ensemble
    learning algorithms might be sensitive to irrelevant variables if these are sufficiently
    correlated to informative features. You won’t bias your estimates, but this may
    lead you to conclude that some variable has predictive power when it doesn’t.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，包含无信息的控制变量是安全的。如果这些变量与信息性特征足够相关，集成学习算法可能对无关变量敏感。你不会偏置你的估计，但这可能导致你得出某个变量具有预测能力的结论，而实际上并非如此。
- en: The dummy variable trap.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟变量陷阱。
- en: In linear regression, it’s always a good practice to include an intercept or
    constant term. If you include dummy variables, you must always exclude one category
    that will serve as a reference or base. For instance, if you include a female
    dummy variable, the male category serves as a reference for interpretation purposes.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，始终包括一个截距或常数项是一个良好的实践。如果你包括虚拟变量，必须始终排除一个类别作为参考或基准。例如，如果你包括一个女性虚拟变量，则男性类别作为解释目的的参考。
- en: The dummy variable trap in ensemble learning.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 集成学习中的虚拟变量陷阱。
- en: 'Nothing forbids you from including dummy variables for all categories with
    random forest or gradient boosting machines. But you also gain *nothing* from
    it: these variables provide no extra information that can improve the predictive
    performance of your model.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何规定阻止你为随机森林或梯度提升机中的所有类别包括虚拟变量。但你也不会从中获得*任何*好处：这些变量提供的信息并不能提高模型的预测性能。
- en: Variance is critical for machine learning.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 方差对机器学习至关重要。
- en: Without sufficient variance in your features, your algorithm won’t be able to
    learn the underlying data generating process. This is true for linear regression
    and general machine learning algorithms.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的特征缺乏足够的方差，你的算法将无法学习到底层数据生成过程。这对于线性回归和一般的机器学习算法都是适用的。
- en: Further Reading
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Linear regression is covered in most statistics, machine learning, and econometrics
    textbooks. The treatment in Trevor Hastie et al., *The Elements of Statistical
    Learning: Data Mining, Inference, and Prediction*, 2nd ed. (Springer), is superb.
    It discusses *regression by successive orthogonalization*, a result that is closely
    related to the FWL theorem.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归在大多数统计学、机器学习和计量经济学教科书中都有涉及。Trevor Hastie 等人的《统计学习的要素：数据挖掘、推断与预测》第二版（Springer）中的处理非常出色。它讨论了*逐步正交化回归*，这与
    FWL 定理密切相关。
- en: 'Chapter 3 of *Mostly Harmless Econometrics: An Empiricist’s Companion* by Joshua
    Angrist and Jörn-Steffen Pischke (Princeton University Press) provides a very
    deep discussion on the fundamentals of linear regression, as well as the derivations
    for the covariance formulas presented in the chapter. This book is great if you
    want to strengthen your intuitions on regression.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Joshua Angrist 和 Jörn-Steffen Pischke 的《大多数无害的计量经济学：经验主义者的伴侣》第三章（普林斯顿大学出版社）提供了关于线性回归基础的深入讨论，以及该章节中所呈现的协方差公式的推导。如果你想加强对回归的直觉，这本书非常适合。
- en: The FWL theorem is covered in most econometrics textbooks. You can check out
    William Greene’s *Econometric Analysis*, 8th ed. (Pearson).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数计量经济学教科书都涵盖了 FWL 定理。你可以查阅 William Greene 的《计量经济分析》第八版（Pearson）。
- en: ^([1](ch10.html#id584-marker)) OLS stands for ordinary least squares, which
    is the standard method used to train linear regression. For convenience I treat
    them as equivalent, but bear in mind that there are other loss functions that
    can be used.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch10.html#id584-marker)) OLS 指的是普通最小二乘法，这是用于训练线性回归的标准方法。为方便起见，我把它们视为等效的，但请记住还有其他可以使用的损失函数。
- en: ^([2](ch10.html#id599-marker)) At a high level, a time series is *stationary*
    when its probability distribution doesn’t change in time. Weak stationarity refers
    only to the first two moments, and strong stationarity requires that the joint
    distribution is constant. The mean for a trending variable changes, so it can’t
    be stationary (unless it’s *trend-stationary*).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch10.html#id599-marker)) 在高层次上，时间序列在其概率分布随时间不变时是*平稳*的。弱平稳性仅涉及前两个时刻，而强平稳性要求联合分布恒定。趋势变量的均值变化，因此它不能是平稳的（除非是*趋势平稳*）。
- en: ^([3](ch10.html#id600-marker)) *AR(1)* denotes an autoregressive process of
    order 1.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch10.html#id600-marker)) *AR(1)* 表示一阶自回归过程。
- en: "^([4](ch10.html#id604-marker)) Recall that the OLS estimator is <math alttext=\"\
    left-parenthesis upper X prime upper X right-parenthesis Superscript negative\
    \ 1 Baseline upper X prime upper Y\"><mrow><msup><mrow><mo>(</mo><mi>X</mi><mi>â</mi><mi>\x80\
    </mi><mi>\x99</mi><mi>X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>\
    \ <mi>X</mi> <mi>â</mi> <mi>\x80</mi> <mi>\x99</mi> <mi>Y</mi></mrow></math> ."
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch10.html#id604-marker)) 请记住，OLS 估计量是 <math alttext="left-parenthesis
    upper X prime upper X right-parenthesis Superscript negative 1 Baseline upper
    X prime upper Y"><mrow><msup><mrow><mo>(</mo><mi>X</mi><mo>'</mo><mi>X</mi><mo>)</mo></mrow><mrow><mo>-1</mo></mrow></msup><mi>X</mi><mo>'</mo><mi>Y</mi></mrow></math>
    。
- en: ^([5](ch10.html#id613-marker)) In a bivariate setting, <math alttext="Var left-parenthesis
    beta 1 right-parenthesis equals Var left-parenthesis r e s i d u a l right-parenthesis
    slash Var left-parenthesis x right-parenthesis"><mrow><mtext>Var</mtext> <mrow><mo>(</mo>
    <msub><mi>β</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <mtext>Var</mtext>
    <mrow><mo>(</mo> <mi>r</mi> <mi>e</mi> <mi>s</mi> <mi>i</mi> <mi>d</mi> <mi>u</mi>
    <mi>a</mi> <mi>l</mi> <mo>)</mo></mrow> <mo>/</mo> <mtext>Var</mtext> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math> .
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch10.html#id613-marker)) 在双变量设置中，<math alttext="Var left-parenthesis beta
    1 right-parenthesis equals Var left-parenthesis r e s i d u a l right-parenthesis
    slash Var left-parenthesis x right-parenthesis"><mrow><mtext>Var</mtext> <mrow><mo>(</mo>
    <msub><mi>β</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <mtext>Var</mtext>
    <mrow><mo>(</mo> <mi>r</mi> <mi>e</mi> <mi>s</mi> <mi>i</mi> <mi>d</mi> <mi>u</mi>
    <mi>a</mi> <mi>l</mi> <mo>)</mo></mrow> <mo>/</mo> <mtext>Var</mtext> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math> 。
