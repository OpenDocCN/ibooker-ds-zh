- en: 'Chapter 10\. Linear Regression: Going Back to Basics'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬10ç«  çº¿æ€§å›å½’ï¼šå›å½’åŸºç¡€
- en: Linear regression (OLS^([1](ch10.html#id584))) is the first machine learning
    algorithm most data scientists learn, but it has become more of an intellectual
    curiosity with the advent of more powerful nonlinear alternatives, like gradient
    boosting regression. Because of this, many practitioners donâ€™t know many properties
    of OLS that are very helpful to gain some intuition about learning algorithms.
    This chapter goes through some of these important properties and highlights their
    significance.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§å›å½’ï¼ˆOLS^([1](ch10.html#id584))ï¼‰æ˜¯å¤§å¤šæ•°æ•°æ®ç§‘å­¦å®¶å­¦ä¹ çš„ç¬¬ä¸€ä¸ªæœºå™¨å­¦ä¹ ç®—æ³•ï¼Œä½†éšç€æ›´å¼ºå¤§çš„éçº¿æ€§æ›¿ä»£æ–¹æ³•ï¼ˆå¦‚æ¢¯åº¦æå‡å›å½’ï¼‰çš„å‡ºç°ï¼Œå®ƒå·²ç»æˆä¸ºä¸€ç§çŸ¥è¯†ä¸Šçš„å¥½å¥‡å¿ƒã€‚å› æ­¤ï¼Œè®¸å¤šå®è·µè€…ä¸äº†è§£OLSçš„è®¸å¤šå¯¹äºç†è§£å­¦ä¹ ç®—æ³•éå¸¸æœ‰å¸®åŠ©çš„å±æ€§ã€‚æœ¬ç« èŠ‚ä»‹ç»äº†å…¶ä¸­ä¸€äº›é‡è¦å±æ€§ï¼Œå¹¶å¼ºè°ƒäº†å®ƒä»¬çš„é‡è¦æ€§ã€‚
- en: Whatâ€™s in a Coefficient?
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç³»æ•°ä¸­åŒ…å«äº†ä»€ä¹ˆï¼Ÿ
- en: 'Letâ€™s start with the simplest setting with only one feature:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»åªæœ‰ä¸€ä¸ªç‰¹å¾çš„æœ€ç®€å•è®¾ç½®å¼€å§‹ï¼š
- en: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus epsilon" display="block"><mrow><mi>y</mi>
    <mo>=</mo> <msub><mi>Î±</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></math>
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus epsilon" display="block"><mrow><mi>y</mi>
    <mo>=</mo> <msub><mi>Î±</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></math>
- en: The first parameter is the *constant* or *intercept*, and the second parameter
    is the *slope*, as you may recall from the typical functional form for a line.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯*å¸¸æ•°*æˆ–*æˆªè·*ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯*æ–œç‡*ï¼Œæ­£å¦‚æ‚¨å¯èƒ½ä»çº¿æ€§æ–¹ç¨‹çš„å…¸å‹å‡½æ•°å½¢å¼ä¸­è®°å¾—çš„é‚£æ ·ã€‚
- en: 'Since the residuals are mean zero, by taking partial derivatives you can see
    that:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæ®‹å·®çš„å‡å€¼ä¸ºé›¶ï¼Œé€šè¿‡åå¯¼æ•°å¯ä»¥çœ‹å‡ºï¼š
- en: <math alttext="StartLayout 1st Row 1st Column alpha 1 2nd Column equals 3rd
    Column StartFraction partial-differential upper E left-parenthesis y right-parenthesis
    Over partial-differential x 1 EndFraction 2nd Row 1st Column alpha 0 2nd Column
    equals 3rd Column upper E left-parenthesis y right-parenthesis minus alpha 1 upper
    E left-parenthesis x 1 right-parenthesis EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>Î±</mi> <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>âˆ‚</mi><mi>E</mi><mo>(</mo><mi>y</mi><mo>)</mo></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>Î±</mi> <mn>0</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>E</mi> <mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow>
    <mo>-</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <mi>E</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha 1 2nd Column equals 3rd
    Column StartFraction partial-differential upper E left-parenthesis y right-parenthesis
    Over partial-differential x 1 EndFraction 2nd Row 1st Column alpha 0 2nd Column
    equals 3rd Column upper E left-parenthesis y right-parenthesis minus alpha 1 upper
    E left-parenthesis x 1 right-parenthesis EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>Î±</mi> <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>âˆ‚</mi><mi>E</mi><mo>(</mo><mi>y</mi><mo>)</mo></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mn>1</mn></msub></mrow></mfrac></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>Î±</mi> <mn>0</mn></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>E</mi> <mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow>
    <mo>-</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <mi>E</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow></mrow></mtd></mtr></mtable></math>
- en: As discussed in [ChapterÂ 9](ch09.html#ch09_simulation), the first equation is
    quite useful for interpretability reasons, since it says that a one-unit change
    in the feature is associated with a change in <math alttext="alpha 1"><msub><mi>Î±</mi>
    <mn>1</mn></msub></math> units of the outcome, on average. However, as I will
    now show, you must be careful not to give it a *causal* interpretation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚åœ¨[ç¬¬9ç« ](ch09.html#ch09_simulation)ä¸­è®¨è®ºçš„é‚£æ ·ï¼Œç¬¬ä¸€ä¸ªæ–¹ç¨‹å¯¹äºå¯è§£é‡Šæ€§æ¥è¯´éå¸¸æœ‰ç”¨ï¼Œå› ä¸ºå®ƒè¡¨æ˜ç‰¹å¾çš„å•ä½å˜åŒ–ä¸ç»“æœçš„å•ä½å˜åŒ–ï¼Œå¹³å‡è€Œè¨€ï¼Œç›¸å…³è”ã€‚ç„¶è€Œï¼Œæ­£å¦‚æˆ‘å°†è¦å±•ç¤ºçš„ï¼Œæ‚¨å¿…é¡»å°å¿ƒï¼Œä¸è¦ç»™å®ƒä¸€ä¸ª*å› æœ*è§£é‡Šã€‚
- en: 'By substituting the definition of the outcome inside the covariance, you can
    also show that:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡å°†ç»“æœçš„å®šä¹‰ä»£å…¥åæ–¹å·®ä¸­ï¼Œæ‚¨è¿˜å¯ä»¥æ˜¾ç¤ºï¼š
- en: <math alttext="StartLayout 1st Row 1st Column alpha 1 2nd Column equals 3rd
    Column StartFraction upper C o v left-parenthesis y comma x 1 right-parenthesis
    Over upper V a r left-parenthesis x 1 right-parenthesis EndFraction EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>Î±</mi>
    <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow> <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha 1 2nd Column equals 3rd
    Column StartFraction upper C o v left-parenthesis y comma x 1 right-parenthesis
    Over upper V a r left-parenthesis x 1 right-parenthesis EndFraction EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>Î±</mi>
    <mn>1</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow> <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
- en: 'In a bivariate setting, the slope depends on the covariance between the outcome
    and the feature, and the variance of the feature. Since correlation is not causation,
    you must be cautious not to interpret these *causally*. A non-null covariance
    can arise from different factors:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åŒå˜é‡è®¾ç½®ä¸­ï¼Œæ–œç‡å–å†³äºç»“æœå’Œç‰¹å¾ä¹‹é—´çš„åæ–¹å·®ï¼Œä»¥åŠç‰¹å¾çš„æ–¹å·®ã€‚ç”±äºç›¸å…³æ€§å¹¶éå› æœå…³ç³»ï¼Œæ‚¨å¿…é¡»è°¨æ…ä¸è¦å°†è¿™äº›*å› æœ*è§£é‡Šä¸ºå› æœå…³ç³»ã€‚éé›¶åæ–¹å·®å¯èƒ½æºè‡ªä¸åŒçš„å› ç´ ï¼š
- en: Direct causation
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´æ¥å› æœå…³ç³»
- en: As you would like to interpret it ( <math alttext="x 1 right-arrow y"><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>â†’</mo> <mi>y</mi></mrow></math> ).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æ‚¨å¸Œæœ›è§£é‡Šçš„é‚£æ ·ï¼ˆ <math alttext="x 1 right-arrow y"><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>â†’</mo> <mi>y</mi></mrow></math>ï¼‰ã€‚
- en: Reverse causation
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: é€†å› æœå…³ç³»
- en: <math alttext="x 1 left-arrow y"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>â†</mo>
    <mi>y</mi></mrow></math> , since the covariance is symmetric on the arguments.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="x 1 left-arrow y"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>â†</mo>
    <mi>y</mi></mrow></math>ï¼Œå› ä¸ºåæ–¹å·®åœ¨å‚æ•°ä¸Šæ˜¯å¯¹ç§°çš„ã€‚
- en: Confounders
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ··æ‚å› ç´ 
- en: A confounder is any third variable that affects both *x* and *y*, but these
    are otherwise unrelated ([FigureÂ 10-1](#ch10_confounder)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æ··æ‚å› ç´ æ˜¯ä»»ä½•ç¬¬ä¸‰ä¸ªåŒæ—¶å½±å“*x*å’Œ*y*çš„å˜é‡ï¼Œä½†å®ƒä»¬åœ¨å…¶ä»–æ–¹é¢æ— å…³ï¼ˆ[å›¾10-1](#ch10_confounder)ï¼‰ã€‚
- en: '![Confounder](assets/dshp_1001.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![æ··æ‚å› ç´ ](assets/dshp_1001.png)'
- en: Figure 10-1\. Confounders
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾10-1 æ··æ‚å› ç´ 
- en: Warning
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: è­¦å‘Š
- en: Estimates from linear regression provide information about the degree of correlation
    between a feature and an outcome, and it can only be interpreted *causally* in
    very specific situations (see [ChapterÂ 15](ch15.html#ch15_incrementality)). This
    warning also applies to other ML algorithms such as gradient boosting or random
    forests.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§å›å½’çš„ä¼°è®¡æä¾›äº†å…³äºç‰¹å¾å’Œç»“æœä¹‹é—´ç›¸å…³ç¨‹åº¦çš„ä¿¡æ¯ï¼Œåªèƒ½åœ¨éå¸¸ç‰¹å®šçš„æƒ…å†µä¸‹*å› æœ*è§£é‡Šï¼ˆå‚è§[ç¬¬15ç« ](ch15.html#ch15_incrementality)ï¼‰ã€‚è¿™ä¸ªè­¦å‘ŠåŒæ ·é€‚ç”¨äºå…¶ä»–æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå¦‚æ¢¯åº¦æå‡æˆ–éšæœºæ£®æ—ã€‚
- en: 'A more general result applies for multiple regression (that is, a regression
    with multiple covariates):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤šé‡å›å½’ï¼Œä¸€ä¸ªæ›´ä¸€èˆ¬çš„ç»“æœé€‚ç”¨ï¼ˆå³å…·æœ‰å¤šä¸ªåå˜é‡çš„å›å½’ï¼‰ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column equals
    3rd Column StartFraction upper C o v left-parenthesis y comma x overTilde Subscript
    k Baseline right-parenthesis Over upper V a r left-parenthesis x overTilde Subscript
    k Baseline right-parenthesis EndFraction EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>Î±</mi> <mi>k</mi></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><msub><mover
    accent="true"><mi>x</mi> <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mover accent="true"><mi>x</mi>
    <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column equals
    3rd Column StartFraction upper C o v left-parenthesis y comma x overTilde Subscript
    k Baseline right-parenthesis Over upper V a r left-parenthesis x overTilde Subscript
    k Baseline right-parenthesis EndFraction EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>Î±</mi> <mi>k</mi></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><msub><mover
    accent="true"><mi>x</mi> <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mover accent="true"><mi>x</mi>
    <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
- en: 'where <math alttext="x overTilde Subscript k"><msub><mover accent="true"><mi>x</mi>
    <mo>Ëœ</mo></mover> <mi>k</mi></msub></math> is the residual from running a regression
    of the *k-th* feature on all *other* features (*â€“k*):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­<math alttext="x overTilde Subscript k"><msub><mover accent="true"><mi>x</mi>
    <mo>Ëœ</mo></mover> <mi>k</mi></msub></math>æ˜¯ä»åœ¨æ‰€æœ‰*å…¶ä»–*ç‰¹å¾ï¼ˆ*-k*ï¼‰ä¸Šè¿è¡Œå›å½’çš„æ®‹å·®ä¸­è·å¾—çš„*k*ç‰¹å¾çš„æ®‹å·®ï¼š
- en: <math alttext="x overTilde Subscript k Baseline equals x Subscript k Baseline
    minus bold upper X Subscript negative bold k Baseline theta Subscript negative
    bold k" display="block"><mrow><msub><mover accent="true"><mi>x</mi> <mo>Ëœ</mo></mover>
    <mi>k</mi></msub> <mo>=</mo> <msub><mi>x</mi> <mi>k</mi></msub> <mo>-</mo> <msub><mi>ğ—</mi>
    <mrow><mo>-</mo><mi>ğ¤</mi></mrow></msub> <msub><mi>Î¸</mi> <mrow><mo>-</mo><mi>ğ¤</mi></mrow></msub></mrow></math>
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="x overTilde Subscript k Baseline equals x Subscript k Baseline
    minus bold upper X Subscript negative bold k Baseline theta Subscript negative
    bold k" display="block"><mrow><msub><mover accent="true"><mi>x</mi> <mo>Ëœ</mo></mover>
    <mi>k</mi></msub> <mo>=</mo> <msub><mi>x</mi> <mi>k</mi></msub> <mo>-</mo> <msub><mi>ğ—</mi>
    <mrow><mo>-</mo><mi>ğ¤</mi></mrow></msub> <msub><mi>Î¸</mi> <mrow><mo>-</mo><mi>ğ¤</mi></mrow></msub></mrow></math>
- en: For the bivariate linear model, the snippet in [ExampleÂ 10-1](#ch10_code_cov)
    shows that linear regression and the simpler covariance formula agree numerically.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºåŒå˜é‡çº¿æ€§æ¨¡å‹ï¼Œ[ç¤ºä¾‹Â 10-1](#ch10_code_cov)ä¸­çš„ç‰‡æ®µæ˜¾ç¤ºï¼Œçº¿æ€§å›å½’å’Œç®€åŒ–åæ–¹å·®å…¬å¼åœ¨æ•°å€¼ä¸Šæ˜¯ä¸€è‡´çš„ã€‚
- en: Example 10-1\. Verifying that OLS and the bivariate covariance formula agree
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 10-1\. éªŒè¯OLSå’ŒåŒå˜é‡åæ–¹å·®å…¬å¼çš„ä¸€è‡´æ€§
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For the case of more than one feature, you can use the following function to
    verify that the more general covariance formula agrees with OLS. Note that I first
    compute the residuals of a regression of feature *k* on all other features:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºå¤šä¸ªç‰¹å¾çš„æƒ…å†µï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‡½æ•°éªŒè¯æ›´ä¸€èˆ¬çš„åæ–¹å·®å…¬å¼æ˜¯å¦ä¸OLSä¸€è‡´ã€‚æ³¨æ„ï¼Œæˆ‘é¦–å…ˆè®¡ç®—å¯¹æ‰€æœ‰å…¶ä»–ç‰¹å¾è¿›è¡Œå›å½’åçš„æ®‹å·®ï¼š
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The more general covariance formula leads to an important result called the
    *Frisch-Waugh-Lovell theorem*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´ä¸€èˆ¬çš„åæ–¹å·®å…¬å¼å¯¼è‡´äº†ä¸€ä¸ªé‡è¦ç»“æœï¼Œç§°ä¸º*å¼—é‡Œæ–½-ç“¦å¤«-æ´›ç»´å°”å®šç†*ã€‚
- en: The Frisch-Waugh-Lovell Theorem
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¼—é‡Œæ–½-ç“¦å¤«-æ´›ç»´å°”å®šç†
- en: The Frisch-Waugh-Lovell theorem (FWL) is a powerful result that helps build
    a lot of intuition about the inner workings of linear regression. It essentially
    says that you can interpret the OLS estimates as *partialled-out* effects, that
    is, effects net of any other dependencies between features.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¼—é‡Œæ–½-ç“¦å¤«-æ´›ç»´å°”å®šç†ï¼ˆFWLï¼‰æ˜¯ä¸€ä¸ªæœ‰åŠ›çš„ç»“æœï¼Œå¸®åŠ©ç†è§£çº¿æ€§å›å½’çš„å†…åœ¨å·¥ä½œåŸç†ã€‚å®ƒåŸºæœ¬ä¸Šè¡¨æ˜ï¼Œæ‚¨å¯ä»¥å°†OLSä¼°è®¡è§£é‡Šä¸º*æ§åˆ¶å*çš„æ•ˆåº”ï¼Œå³é™¤å»ä»»ä½•ç‰¹å¾ä¹‹é—´çš„å…¶ä»–ä¾èµ–æ•ˆåº”ã€‚
- en: Say that youâ€™re running a regression of sales per customer on the price they
    paid and state dummy variables. If a stakeholder asks you if the price coefficient
    can be explained by state-wise variation in pricing, you can use the FWL theorem
    to convincingly say that these are *net effects*. The price effect has already
    been cleaned out of any differences in pricing across states (you have already
    *controlled* for state differences).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æ‚¨æ­£åœ¨è¿è¡Œä¸€ä¸ªå…³äºæ¯ä½å®¢æˆ·é”€å”®é‡å¯¹å…¶æ”¯ä»˜ä»·æ ¼å’ŒçŠ¶æ€è™šæ‹Ÿå˜é‡çš„å›å½’ã€‚å¦‚æœåˆ©ç›Šç›¸å…³è€…è¯¢é—®æ‚¨ä»·æ ¼ç³»æ•°æ˜¯å¦å¯ä»¥è§£é‡Šä¸ºä¸åŒå·å®šä»·å·®å¼‚çš„å½±å“ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨FWLå®šç†ç¡®åˆ‡åœ°è¯´è¿™äº›æ˜¯*å‡€æ•ˆåº”*ã€‚ä»·æ ¼æ•ˆåº”å·²ç»ä»è·¨å·å®šä»·çš„ä»»ä½•å·®å¼‚ä¸­æ¸…é™¤ï¼ˆæ‚¨å·²ç»*æ§åˆ¶*äº†å·é—´çš„å·®å¼‚ï¼‰ã€‚
- en: 'To present the theorem Iâ€™ll use the simpler two-feature linear model again,
    but the theorem applies to the more general case of any number of regressors:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å±•ç¤ºå®šç†ï¼Œæˆ‘å°†å†æ¬¡ä½¿ç”¨æ›´ç®€å•çš„ä¸¤ç‰¹å¾çº¿æ€§æ¨¡å‹ï¼Œä½†å®šç†é€‚ç”¨äºä»»æ„æ•°é‡çš„å›å½’å˜é‡ï¼š
- en: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>Ïµ</mi></mrow></math>
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>Ïµ</mi></mrow></math>
- en: 'FWL states that you can estimate a specific coefficient, say <math alttext="alpha
    1"><msub><mi>Î±</mi> <mn>1</mn></msub></math> , by using a two-step process:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: FWLæŒ‡å‡ºï¼Œæ‚¨å¯ä»¥é€šè¿‡ä¸¤æ­¥è¿‡ç¨‹æ¥ä¼°è®¡ç‰¹å®šç³»æ•°ï¼Œæ¯”å¦‚è¯´<math alttext="alpha 1"><msub><mi>Î±</mi> <mn>1</mn></msub></math>ï¼š
- en: '*Partialling out <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>*
    :'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å¯¹<math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>è¿›è¡Œåç¦»*ï¼š'
- en: 'Run a regression of <math alttext="y"><mi>y</mi></math> on <math alttext="x
    2"><msub><mi>x</mi> <mn>2</mn></msub></math> and save the residuals: <math alttext="y
    overTilde Subscript 1"><msub><mover accent="true"><mi>y</mi> <mo>Ëœ</mo></mover>
    <mn>1</mn></msub></math> .'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹<math alttext="y"><mi>y</mi></math>åœ¨<math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>ä¸Šè¿›è¡Œå›å½’ï¼Œå¹¶ä¿å­˜æ®‹å·®ï¼š<math
    alttext="y overTilde Subscript 1"><msub><mover accent="true"><mi>y</mi> <mo>Ëœ</mo></mover>
    <mn>1</mn></msub></math> ã€‚
- en: 'Run a regression of <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    on <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> and save the
    residuals: <math alttext="x overTilde Subscript 1"><msub><mover accent="true"><mi>x</mi>
    <mo>Ëœ</mo></mover> <mn>1</mn></msub></math> .'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹<math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>åœ¨<math alttext="x
    2"><msub><mi>x</mi> <mn>2</mn></msub></math>ä¸Šè¿›è¡Œå›å½’ï¼Œå¹¶ä¿å­˜æ®‹å·®ï¼š<math alttext="x overTilde
    Subscript 1"><msub><mover accent="true"><mi>x</mi> <mo>Ëœ</mo></mover> <mn>1</mn></msub></math>ã€‚
- en: '*Regression on residuals*:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ®‹å·®å›å½’*ï¼š'
- en: Run a regression of <math alttext="y overTilde Subscript 1"><msub><mover accent="true"><mi>y</mi>
    <mo>Ëœ</mo></mover> <mn>1</mn></msub></math> on <math alttext="x overTilde Subscript
    1"><msub><mover accent="true"><mi>x</mi> <mo>Ëœ</mo></mover> <mn>1</mn></msub></math>
    . The slope is an estimate of <math alttext="alpha 1"><msub><mi>Î±</mi> <mn>1</mn></msub></math>
    .
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹<math alttext="y overTilde Subscript 1"><msub><mover accent="true"><mi>y</mi>
    <mo>Ëœ</mo></mover> <mn>1</mn></msub></math>åœ¨<math alttext="x overTilde Subscript
    1"><msub><mover accent="true"><mi>x</mi> <mo>Ëœ</mo></mover> <mn>1</mn></msub></math>ä¸Šè¿›è¡Œå›å½’ã€‚æ–œç‡æ˜¯<math
    alttext="alpha 1"><msub><mi>Î±</mi> <mn>1</mn></msub></math>çš„ä¼°è®¡é‡ã€‚
- en: The partialling-out step removes the effect of any other regressor on the outcome
    and the feature of interest. The second step runs a bivariate regression on these
    residuals. Since we have already partialled out the effect of *x*[2], only the
    effect of interest remains.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: åç¦»æ­¥éª¤å»é™¤äº†å…¶ä»–å›å½’å˜é‡å¯¹ç»“æœå’Œæ„Ÿå…´è¶£ç‰¹å¾çš„å½±å“ã€‚ç¬¬äºŒæ­¥åœ¨è¿™äº›æ®‹å·®ä¸Šè¿è¡ŒåŒå˜é‡å›å½’ã€‚ç”±äºæˆ‘ä»¬å·²ç»å»é™¤äº†*x*[2]çš„æ•ˆåº”ï¼Œå› æ­¤åªå‰©ä¸‹æ„Ÿå…´è¶£çš„æ•ˆåº”ã€‚
- en: '[ExampleÂ 10-2](#ch10_fw_check) shows the results when I simulate a linear model
    with three features, and estimate each coefficient using the FWL *partialling-out*
    method and plain linear regression. I use the code snippet in [ExampleÂ 10-2](#ch10_fw_check)
    to make the comparison.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç¤ºä¾‹Â 10-2](#ch10_fw_check)å±•ç¤ºäº†æˆ‘ä½¿ç”¨ä¸‰ä¸ªç‰¹å¾æ¨¡æ‹Ÿçº¿æ€§æ¨¡å‹çš„ç»“æœï¼Œå¹¶ä½¿ç”¨FWLçš„*partialling-out*æ–¹æ³•å’Œæ™®é€šçº¿æ€§å›å½’ä¼°è®¡æ¯ä¸ªç³»æ•°ã€‚æˆ‘ä½¿ç”¨[ç¤ºä¾‹Â 10-2](#ch10_fw_check)ä¸­çš„ä»£ç ç‰‡æ®µè¿›è¡Œæ¯”è¾ƒã€‚'
- en: Example 10-2\. Checking the validity of FWL
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 10-2\. æ£€éªŒFWLçš„æœ‰æ•ˆæ€§
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Going back to the covariance formula presented earlier, FWL implies that:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: å›åˆ°å…ˆå‰æå‡ºçš„åæ–¹å·®å…¬å¼ï¼ŒFWLæš—ç¤ºç€
- en: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column equals
    3rd Column StartFraction upper C o v left-parenthesis y overTilde Subscript k
    Baseline comma x overTilde Subscript k Baseline right-parenthesis Over upper V
    a r left-parenthesis x overTilde Subscript k Baseline right-parenthesis EndFraction
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>Î±</mi>
    <mi>k</mi></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mover
    accent="true"><mi>y</mi> <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>,</mo><msub><mover
    accent="true"><mi>x</mi> <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mover accent="true"><mi>x</mi>
    <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column equals
    3rd Column StartFraction upper C o v left-parenthesis y overTilde Subscript k
    Baseline comma x overTilde Subscript k Baseline right-parenthesis Over upper V
    a r left-parenthesis x overTilde Subscript k Baseline right-parenthesis EndFraction
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>Î±</mi>
    <mi>k</mi></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mover
    accent="true"><mi>y</mi> <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>,</mo><msub><mover
    accent="true"><mi>x</mi> <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mover accent="true"><mi>x</mi>
    <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
- en: where as before, <math alttext="x overTilde Subscript k"><msub><mover accent="true"><mi>x</mi>
    <mo>Ëœ</mo></mover> <mi>k</mi></msub></math> denotes the residuals from a regression
    of feature *k* on all other features, and <math alttext="y overTilde Subscript
    k"><msub><mover accent="true"><mi>y</mi> <mo>Ëœ</mo></mover> <mi>k</mi></msub></math>
    denotes the residuals from a regression of the outcome on the same set of features.
    The Python script allows you to test that both versions of the general covariance
    formula give the same results (using the `version` argument).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼Œ<math alttext="x overTilde Subscript k"><msub><mover accent="true"><mi>x</mi>
    <mo>Ëœ</mo></mover> <mi>k</mi></msub></math>è¡¨ç¤ºç‰¹å¾*k*åœ¨æ‰€æœ‰å…¶ä»–ç‰¹å¾ä¸Šå›å½’åçš„æ®‹å·®ï¼Œè€Œ<math alttext="y
    overTilde Subscript k"><msub><mover accent="true"><mi>y</mi> <mo>Ëœ</mo></mover>
    <mi>k</mi></msub></math>è¡¨ç¤ºå› å˜é‡åœ¨ç›¸åŒç‰¹å¾é›†ä¸Šçš„å›å½’æ®‹å·®ã€‚Pythonè„šæœ¬å…è®¸æ‚¨æµ‹è¯•é€šç”¨åæ–¹å·®å…¬å¼çš„ä¸¤ä¸ªç‰ˆæœ¬æ˜¯å¦ç»™å‡ºç›¸åŒç»“æœï¼ˆä½¿ç”¨`version`å‚æ•°ï¼‰ã€‚
- en: An important property of OLS is that the estimated residuals are orthogonal
    to the regressors (or any function of the regressors), a process also known as
    *orthogonalization*. You can use this fact to show that the two covariance formulas
    are equivalent.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: OLSçš„ä¸€ä¸ªé‡è¦ç‰¹æ€§æ˜¯ä¼°è®¡æ®‹å·®ä¸å›å½’å˜é‡ï¼ˆæˆ–å›å½’å˜é‡çš„ä»»ä½•å‡½æ•°ï¼‰æ­£äº¤ï¼Œè¿™ä¸ªè¿‡ç¨‹ä¹Ÿè¢«ç§°ä¸º*æ­£äº¤åŒ–*ã€‚æ‚¨å¯ä»¥åˆ©ç”¨è¿™ä¸ªäº‹å®æ¥è¡¨æ˜ä¸¤ä¸ªåæ–¹å·®å…¬å¼æ˜¯ç­‰ä»·çš„ã€‚
- en: 'Importantly, orthogonalization *always* has to be performed on the feature
    of interest. If you only orthogonalize the outcome *y*, the covariance formula
    is no longer valid, *unless* the features are already orthogonal with each other,
    so in general:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: é‡è¦çš„æ˜¯ï¼Œæ­£äº¤åŒ–*æ€»æ˜¯*å¿…é¡»åœ¨æ„Ÿå…´è¶£çš„ç‰¹å¾ä¸Šè¿›è¡Œã€‚å¦‚æœåªå¯¹å› å˜é‡*y*è¿›è¡Œæ­£äº¤åŒ–ï¼Œé‚£ä¹ˆåæ–¹å·®å…¬å¼å°†ä¸å†æœ‰æ•ˆï¼Œ*é™¤é*ç‰¹å¾å·²ç»ç›¸äº’æ­£äº¤ï¼Œå› æ­¤ä¸€èˆ¬è€Œè¨€ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column not-equals
    3rd Column StartFraction upper C o v left-parenthesis y overTilde Subscript k
    Baseline comma x Subscript k Baseline right-parenthesis Over upper V a r left-parenthesis
    x Subscript k Baseline right-parenthesis EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>Î±</mi> <mi>k</mi></msub></mtd>
    <mtd><mo>â‰ </mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mover
    accent="true"><mi>y</mi> <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>,</mo><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow> <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column alpha Subscript k 2nd Column not-equals
    3rd Column StartFraction upper C o v left-parenthesis y overTilde Subscript k
    Baseline comma x Subscript k Baseline right-parenthesis Over upper V a r left-parenthesis
    x Subscript k Baseline right-parenthesis EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>Î±</mi> <mi>k</mi></msub></mtd>
    <mtd><mo>â‰ </mo></mtd> <mtd columnalign="left"><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mover
    accent="true"><mi>y</mi> <mo>Ëœ</mo></mover> <mi>k</mi></msub> <mo>,</mo><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow> <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>)</mo></mrow></mfrac></mtd></mtr></mtable></math>
- en: Why Should You Care About FWL?
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆæ‚¨åº”è¯¥å…³å¿ƒFWLï¼Ÿ
- en: 'Iâ€™ve presented several versions of the orthogonalization result, so you should
    expect it to be relevant. The main takeaway is this:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å·²ç»å‘ˆç°äº†å‡ ä¸ªæ­£äº¤åŒ–ç»“æœçš„ç‰ˆæœ¬ï¼Œæ‰€ä»¥æ‚¨åº”è¯¥æœŸæœ›å®ƒæ˜¯ç›¸å…³çš„ã€‚ä¸»è¦çš„è¦ç‚¹æ˜¯ï¼š
- en: You can interpret each coefficient from linear regression as the net effect
    of each feature *after* cleaning it from the effects from any other feature.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ‚¨å¯ä»¥å°†çº¿æ€§å›å½’ä¸­çš„æ¯ä¸ªç³»æ•°è§£é‡Šä¸ºåœ¨æ¸…ç†æ‰å…¶ä»–ä»»ä½•ç‰¹å¾çš„å½±å“ä¹‹åçš„æ¯ä¸ªç‰¹å¾çš„å‡€æ•ˆåº”ã€‚
- en: 'Hereâ€™s one typical scenario where this interpretation matters a lot:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ä¸€ä¸ªå…¸å‹çš„æƒ…æ™¯ï¼Œè§£é‡Šèµ·æ¥éå¸¸é‡è¦ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column x 1 2nd Column tilde 3rd Column
    upper N left-parenthesis 0 comma sigma 1 squared right-parenthesis 2nd Row 1st
    Column x 2 2nd Column equals 3rd Column beta 0 plus beta 1 x 1 plus epsilon 3rd
    Row 1st Column y 2nd Column equals 3rd Column alpha 0 plus alpha 1 x 1 plus alpha
    2 x 2 plus eta EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>x</mi> <mn>1</mn></msub></mtd> <mtd><mo>âˆ¼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn>0</mn> <mo>,</mo> <msubsup><mi>Ïƒ</mi>
    <mn>1</mn> <mn>2</mn></msubsup> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>x</mi>
    <mn>2</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î²</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>Î·</mi></mrow></mtd></mtr></mtable></math>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column x 1 2nd Column tilde 3rd Column
    upper N left-parenthesis 0 comma sigma 1 squared right-parenthesis 2nd Row 1st
    Column x 2 2nd Column equals 3rd Column beta 0 plus beta 1 x 1 plus epsilon 3rd
    Row 1st Column y 2nd Column equals 3rd Column alpha 0 plus alpha 1 x 1 plus alpha
    2 x 2 plus eta EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><msub><mi>x</mi> <mn>1</mn></msub></mtd> <mtd><mo>âˆ¼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn>0</mn> <mo>,</mo> <msubsup><mi>Ïƒ</mi>
    <mn>1</mn> <mn>2</mn></msubsup> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>x</mi>
    <mn>2</mn></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î²</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>Î·</mi></mrow></mtd></mtr></mtable></math>
- en: In this case, <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    has a direct and an indirect effect on the outcome *y*. An example could be your
    state or geographic dummy variables. These tend to have direct and indirect effects.
    When you interpret the coefficient of <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    , it would be great if you can say that this is *net* of any state differences,
    since youâ€™re already *controlling* for that variable.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œ<math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>å¯¹ç»“æœ*y*æœ‰ç›´æ¥å’Œé—´æ¥æ•ˆåº”ã€‚ä¸€ä¸ªä¾‹å­å¯èƒ½æ˜¯æ‚¨çš„å·æˆ–åœ°ç†è™šæ‹Ÿå˜é‡ã€‚è¿™äº›å¾€å¾€å…·æœ‰ç›´æ¥å’Œé—´æ¥æ•ˆåº”ã€‚å½“æ‚¨è§£é‡Š<math
    alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>çš„ç³»æ•°æ—¶ï¼Œå¦‚æœæ‚¨å¯ä»¥è¯´è¿™æ˜¯åœ¨å·²ç»*æ§åˆ¶*äº†è¯¥å˜é‡çš„æƒ…å†µä¸‹çš„*å‡€*æ•ˆåº”ï¼Œé‚£å°†éå¸¸æœ‰å¸®åŠ©ã€‚
- en: '[FigureÂ 10-2](#ch10_fw_state) shows the true parameter, OLS estimate, and gradient
    boosting regression (GBR) partial dependence plot (PDP) for a simulation of the
    previous data generating process. Thanks to FWL, you know that OLS will capture
    net effects correctly. GBR does well for <math alttext="x 2"><msub><mi>x</mi>
    <mn>2</mn></msub></math> , but not so well for <math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math> .'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 10-2](#ch10_fw_state)å±•ç¤ºäº†å‰è¿°æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„çœŸå®å‚æ•°ã€OLSä¼°è®¡å’Œæ¢¯åº¦æå‡å›å½’ï¼ˆGBRï¼‰çš„éƒ¨åˆ†ä¾èµ–å›¾ï¼ˆPDPï¼‰çš„æ¨¡æ‹Ÿç»“æœã€‚ç”±äºFWLï¼Œæ‚¨çŸ¥é“OLSå°†æ­£ç¡®æ•æ‰å‡€æ•ˆåº”ã€‚GBRåœ¨<math
    alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>æ–¹é¢åšå¾—å¾ˆå¥½ï¼Œä½†åœ¨<math alttext="x
    1"><msub><mi>x</mi> <mn>1</mn></msub></math>æ–¹é¢åˆ™ä¸ä½³ã€‚'
- en: 'To understand whatâ€™s going on, recall how PDPs are calculated: fix one feature
    at the sample mean, create a grid for the one you care about, and make a prediction.
    When you fix <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> , <math
    alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> displays a combination
    of direct and indirect effects, and the algorithm doesnâ€™t know how to separate
    them. This just reinforces the message that OLS is great for interpretability
    purposes, but requires quite a bit of effort to get the performance that even
    a relatively out-of-the-box GBR has with nonlinear models.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ç†è§£æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…ï¼Œå›æƒ³ä¸€ä¸‹å¦‚ä½•è®¡ç®—PDPï¼šå°†ä¸€ä¸ªç‰¹å¾å›ºå®šåœ¨æ ·æœ¬å‡å€¼ï¼Œä¸ºä½ å…³å¿ƒçš„ç‰¹å¾åˆ›å»ºä¸€ä¸ªç½‘æ ¼ï¼Œå¹¶è¿›è¡Œé¢„æµ‹ã€‚å½“ä½ å›ºå®š <math alttext="x
    2"><msub><mi>x</mi> <mn>2</mn></msub></math> æ—¶ï¼Œ<math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math> æ˜¾ç¤ºå‡ºç›´æ¥å’Œé—´æ¥æ•ˆåº”çš„ç»„åˆï¼Œç®—æ³•ä¸çŸ¥é“å¦‚ä½•åˆ†ç¦»å®ƒä»¬ã€‚è¿™åªæ˜¯åŠ å¼ºäº†OLSåœ¨å¯è§£é‡Šæ€§æ–¹é¢çš„ä¼˜åŠ¿ï¼Œä½†éœ€è¦ç›¸å½“å¤§çš„åŠªåŠ›æ‰èƒ½è¾¾åˆ°å³ä½¿ç›¸å¯¹äºéçº¿æ€§æ¨¡å‹ä¹Ÿèƒ½å¾ˆå®¹æ˜“å¾—åˆ°çš„æ€§èƒ½ã€‚
- en: '![state example](assets/dshp_1002.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![state example](assets/dshp_1002.png)'
- en: Figure 10-2\. OLS and gradient boosting with direct and indirect effects
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾10-2\. OLSå’Œå…·æœ‰ç›´æ¥å’Œé—´æ¥æ•ˆåº”çš„æ¢¯åº¦æå‡
- en: Confounders
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ··æ‚å› ç´ 
- en: 'Now that Iâ€™ve described the FWL theorem, I want to go back to the problem of
    confounders ([FigureÂ 10-1](#ch10_confounder)). Suppose that a confounder ( <math
    alttext="w"><mi>w</mi></math> ) affects two otherwise unrelated variables:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘å·²ç»æè¿°äº†FWLå®šç†ï¼Œæˆ‘æƒ³å›åˆ°æ··æ‚å› ç´ çš„é—®é¢˜ï¼ˆ[FigureÂ 10-1](#ch10_confounder)ï¼‰ã€‚å‡è®¾ä¸€ä¸ªæ··æ‚å› ç´ ï¼ˆ <math alttext="w"><mi>w</mi></math>
    ï¼‰å½±å“äº†ä¸¤ä¸ªæœ¬æ¥ä¸ç›¸å…³çš„å˜é‡ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column x 2nd Column equals 3rd Column
    alpha Subscript x Baseline plus beta Subscript x Baseline w plus epsilon Subscript
    x 2nd Row 1st Column y 2nd Column equals 3rd Column alpha Subscript y Baseline
    plus beta Subscript y Baseline w plus epsilon Subscript y 3rd Row 1st Column epsilon
    Subscript x 2nd Column up-tack up-tack 3rd Column epsilon Subscript y 4th Row
    1st Column epsilon Subscript x Baseline comma epsilon Subscript y Baseline 2nd
    Column up-tack up-tack 3rd Column w EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mi>x</mi></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi>
    <mi>x</mi></msub> <mo>+</mo> <msub><mi>Î²</mi> <mi>x</mi></msub> <mi>w</mi> <mo>+</mo>
    <msub><mi>Ïµ</mi> <mi>x</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mi>y</mi></msub>
    <mo>+</mo> <msub><mi>Î²</mi> <mi>y</mi></msub> <mi>w</mi> <mo>+</mo> <msub><mi>Ïµ</mi>
    <mi>y</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>Ïµ</mi>
    <mi>x</mi></msub></mtd> <mtd><mrow><mo>âŠ¥</mo> <mo>âŠ¥</mo></mrow></mtd> <mtd columnalign="left"><msub><mi>Ïµ</mi>
    <mi>y</mi></msub></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msub><mi>Ïµ</mi>
    <mi>x</mi></msub> <mo>,</mo> <msub><mi>Ïµ</mi> <mi>y</mi></msub></mrow></mtd> <mtd><mrow><mo>âŠ¥</mo>
    <mo>âŠ¥</mo></mrow></mtd> <mtd columnalign="left"><mi>w</mi></mtd></mtr></mtable></math>
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column x 2nd Column equals 3rd Column
    alpha Subscript x Baseline plus beta Subscript x Baseline w plus epsilon Subscript
    x 2nd Row 1st Column y 2nd Column equals 3rd Column alpha Subscript y Baseline
    plus beta Subscript y Baseline w plus epsilon Subscript y 3rd Row 1st Column epsilon
    Subscript x 2nd Column up-tack up-tack 3rd Column epsilon Subscript y 4th Row
    1st Column epsilon Subscript x Baseline comma epsilon Subscript y Baseline 2nd
    Column up-tack up-tack 3rd Column w EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mi>x</mi></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi>
    <mi>x</mi></msub> <mo>+</mo> <msub><mi>Î²</mi> <mi>x</mi></msub> <mi>w</mi> <mo>+</mo>
    <msub><mi>Ïµ</mi> <mi>x</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mi>y</mi></msub>
    <mo>+</mo> <msub><mi>Î²</mi> <mi>y</mi></msub> <mi>w</mi> <mo>+</mo> <msub><mi>Ïµ</mi>
    <mi>y</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>Ïµ</mi>
    <mi>x</mi></msub></mtd> <mtd><mrow><mo>âŠ¥</mo> <mo>âŠ¥</mo></mrow></mtd> <mtd columnalign="left"><msub><mi>Ïµ</mi>
    <mi>y</mi></msub></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msub><mi>Ïµ</mi>
    <mi>x</mi></msub> <mo>,</mo> <msub><mi>Ïµ</mi> <mi>y</mi></msub></mrow></mtd> <mtd><mrow><mo>âŠ¥</mo>
    <mo>âŠ¥</mo></mrow></mtd> <mtd columnalign="left"><mi>w</mi></mtd></mtr></mtable></math>
- en: 'where the symbol <math alttext="up-tack up-tack"><mrow><mo>âŠ¥</mo> <mo>âŠ¥</mo></mrow></math>
    denotes statistical independence. Using the covariance formula for the slope coefficient
    in a regression of *y* on *x*, it becomes apparent why OLS shows spurious results:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ç¬¦å· <math alttext="up-tack up-tack"><mrow><mo>âŠ¥</mo> <mo>âŠ¥</mo></mrow></math>
    è¡¨ç¤ºç»Ÿè®¡ç‹¬ç«‹æ€§ã€‚ä½¿ç”¨å›å½’ä¸­*y*å¯¹*x*çš„æ–œç‡ç³»æ•°çš„åæ–¹å·®å…¬å¼ï¼Œå°±å¯ä»¥æ˜æ˜¾çœ‹å‡ºä¸ºä»€ä¹ˆOLSæ˜¾ç¤ºå‡ºè™šå‡ç»“æœï¼š
- en: <math alttext="StartFraction upper C o v left-parenthesis y comma x right-parenthesis
    Over upper V a r left-parenthesis x right-parenthesis EndFraction equals StartFraction
    beta Subscript x Baseline beta Subscript y Baseline upper V a r left-parenthesis
    w right-parenthesis Over beta Subscript x Superscript 2 Baseline upper V a r left-parenthesis
    w right-parenthesis plus upper V a r left-parenthesis epsilon Subscript x Baseline
    right-parenthesis EndFraction" display="block"><mrow><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><mi>x</mi><mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><msub><mi>Î²</mi> <mi>x</mi></msub> <msub><mi>Î²</mi> <mi>y</mi></msub>
    <mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><mi>w</mi><mo>)</mo></mrow></mrow>
    <mrow><msubsup><mi>Î²</mi> <mi>x</mi> <mn>2</mn></msubsup> <mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><mi>w</mi><mo>)</mo></mrow><mo>+</mo><mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><msub><mi>Ïµ</mi>
    <mi>x</mi></msub> <mo>)</mo></mrow></mrow></mfrac></mrow></math>
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction upper C o v left-parenthesis y comma x right-parenthesis
    Over upper V a r left-parenthesis x right-parenthesis EndFraction equals StartFraction
    beta Subscript x Baseline beta Subscript y Baseline upper V a r left-parenthesis
    w right-parenthesis Over beta Subscript x Superscript 2 Baseline upper V a r left-parenthesis
    w right-parenthesis plus upper V a r left-parenthesis epsilon Subscript x Baseline
    right-parenthesis EndFraction" display="block"><mrow><mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><mi>y</mi><mo>,</mo><mi>x</mi><mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><msub><mi>Î²</mi> <mi>x</mi></msub> <msub><mi>Î²</mi> <mi>y</mi></msub>
    <mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><mi>w</mi><mo>)</mo></mrow></mrow>
    <mrow><msubsup><mi>Î²</mi> <mi>x</mi> <mn>2</mn></msubsup> <mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><mi>w</mi><mo>)</mo></mrow><mo>+</mo><mi>V</mi><mi>a</mi><mi>r</mi><mrow><mo>(</mo><msub><mi>Ïµ</mi>
    <mi>x</mi></msub> <mo>)</mo></mrow></mrow></mfrac></mrow></math>
- en: 'What if you first *cleaned* that common factor out? Thatâ€™s exactly what FWL
    tells you that linear regression does, so you can safely run a regression of the
    form:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å…ˆ*æ¸…ç†*æ‰é‚£ä¸ªå…±åŒå› ç´ å‘¢ï¼Ÿè¿™æ­£æ˜¯FWLå‘Šè¯‰ä½ çº¿æ€§å›å½’æ‰€åšçš„äº‹æƒ…ï¼Œæ‰€ä»¥ä½ å¯ä»¥å®‰å…¨åœ°è¿è¡Œä»¥ä¸‹å½¢å¼çš„å›å½’ï¼š
- en: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 w plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <mi>w</mi> <mo>+</mo> <mi>Ïµ</mi></mrow></math>
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 w plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <mi>w</mi> <mo>+</mo> <mi>Ïµ</mi></mrow></math>
- en: By also including the common factor *w*, OLS will effectively partial out its
    effect. [FigureÂ 10-3](#ch10_fw_confound) shows the results of estimating the bivariate
    and spurious regression (left plot) and the partialled-out version when you also
    include the third factor as in the previous equation (right plot). I also include
    95% confidence intervals.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡åŒæ—¶åŒ…æ‹¬å…±åŒå› ç´ *w*ï¼ŒOLSå°†æœ‰æ•ˆåœ°å°†å…¶æ•ˆæœåˆ†ç¦»å‡ºæ¥ã€‚[FigureÂ 10-3](#ch10_fw_confound) å±•ç¤ºäº†ä¼°è®¡çš„åŒå˜é‡å’Œè™šå‡å›å½’ç»“æœï¼ˆå·¦å›¾ï¼‰ä»¥åŠå½“ä½ åƒå‰è¿°æ–¹ç¨‹å¼ä¸­ä¸€æ ·åŒ…æ‹¬ç¬¬ä¸‰ä¸ªå› ç´ æ—¶çš„åˆ†ç¦»ç‰ˆæœ¬ï¼ˆå³å›¾ï¼‰ã€‚æˆ‘è¿˜åŒ…æ‹¬äº†95%ç½®ä¿¡åŒºé—´ã€‚
- en: Without controlling for the confounder, you would conclude that *x* and *y*
    are indeed correlated (confidence interval away from zero), but once you control
    for *w*, this becomes the only relevant (statistically significant) factor.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸æ§åˆ¶æ··æ‚å› ç´ ï¼Œä½ ä¼šå¾—å‡º*x*å’Œ*y*ç¡®å®ç›¸å…³çš„ç»“è®ºï¼ˆç½®ä¿¡åŒºé—´è¿œç¦»é›¶ï¼‰ï¼Œä½†ä¸€æ—¦ä½ æ§åˆ¶*w*ï¼Œè¿™å°±æˆä¸ºå”¯ä¸€ç›¸å…³çš„ï¼ˆç»Ÿè®¡æ˜¾è‘—ï¼‰å› ç´ ã€‚
- en: '![FW + confounder](assets/dshp_1003.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![FW + æ··æ‚å› ç´ ](assets/dshp_1003.png)'
- en: Figure 10-3\. FW and controlling for confounders (estimate and 95% CI)
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾10-3\. FWå’Œæ··æ‚å› ç´ çš„æ§åˆ¶ï¼ˆä¼°è®¡å€¼å’Œ95% CIï¼‰
- en: 'This result is very useful in many applications. In time series analysis, for
    example, itâ€™s quite common to have [*trend-stationary*](https://oreil.ly/ewcVV)
    variables that can be modelled like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç»“æœåœ¨è®¸å¤šåº”ç”¨ä¸­éå¸¸æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨æ—¶é—´åºåˆ—åˆ†æä¸­ï¼Œæ‹¥æœ‰[*è¶‹åŠ¿ç¨³å®š*](https://oreil.ly/ewcVV) çš„å˜é‡ç»å¸¸å¯ä»¥è¿™æ ·å»ºæ¨¡ï¼š
- en: <math alttext="StartLayout 1st Row  y Subscript 1 t Baseline equals alpha 1
    plus beta 1 t plus epsilon Subscript 1 t Baseline 2nd Row  y Subscript 2 t Baseline
    equals alpha 2 plus beta 2 t plus epsilon Subscript 2 t EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>y</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub>
    <mi>t</mi> <mo>+</mo> <msub><mi>Ïµ</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msub><mi>y</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>2</mn></msub>
    <mi>t</mi> <mo>+</mo> <msub><mi>Ïµ</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub></mrow></mtd></mtr></mtable></math>
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row  y Subscript 1 t Baseline equals alpha 1
    plus beta 1 t plus epsilon Subscript 1 t Baseline 2nd Row  y Subscript 2 t Baseline
    equals alpha 2 plus beta 2 t plus epsilon Subscript 2 t EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msub><mi>y</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub>
    <mi>t</mi> <mo>+</mo> <msub><mi>Ïµ</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msub><mi>y</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>2</mn></msub>
    <mi>t</mi> <mo>+</mo> <msub><mi>Ïµ</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub></mrow></mtd></mtr></mtable></math>
- en: 'Thanks to FWL, you already know why these are called *trend-stationary*: once
    you control for a time trend (*t* above), thereby cleaning them from this effect,
    you end up with a stationary time series.^([2](ch10.html#id599))'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šäºäº†FWLï¼Œä½ å·²ç»çŸ¥é“ä¸ºä»€ä¹ˆè¿™äº›è¢«ç§°ä¸º*è¶‹åŠ¿ç¨³å®š*ï¼šä¸€æ—¦ä½ æ§åˆ¶äº†æ—¶é—´è¶‹åŠ¿ï¼ˆ*t*ä»¥ä¸Šï¼‰ï¼Œä»è€Œæ¸…ç†äº†å®ƒä»¬çš„è¿™ç§å½±å“ï¼Œä½ å°±å¾—åˆ°äº†ä¸€ä¸ªç¨³å®šçš„æ—¶é—´åºåˆ—ã€‚^([2](ch10.html#id599))
- en: 'Suppose you run a regression of one on the other:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ä½ å¯¹ä¸€ä¸ªå˜é‡è¿›è¡Œå›å½’ï¼š
- en: <math alttext="y Subscript 2 t Baseline equals theta 0 plus theta 1 y Subscript
    1 t Baseline plus zeta Subscript t" display="block"><mrow><msub><mi>y</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>Î¸</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î¸</mi> <mn>1</mn></msub>
    <msub><mi>y</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub> <mo>+</mo> <msub><mi>Î¶</mi>
    <mi>t</mi></msub></mrow></math>
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y Subscript 2 t Baseline equals theta 0 plus theta 1 y Subscript
    1 t Baseline plus zeta Subscript t" display="block"><mrow><msub><mi>y</mi> <mrow><mn>2</mn><mi>t</mi></mrow></msub>
    <mo>=</mo> <msub><mi>Î¸</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î¸</mi> <mn>1</mn></msub>
    <msub><mi>y</mi> <mrow><mn>1</mn><mi>t</mi></mrow></msub> <mo>+</mo> <msub><mi>Î¶</mi>
    <mi>t</mi></msub></mrow></math>
- en: Since youâ€™re not controlling for the common trend, you will end up incorrectly
    concluding that they are correlated. [FigureÂ 10-4](#ch10_ts_trend) shows regression
    results from a simulation of two trend-stationary AR(1) processes that are unrelated
    by design.^([3](ch10.html#id600)) The plot shows the estimated intercept (*constant*)
    and slope for the second variable (*y2*), as well as 95% confidence intervals.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºä½ æ²¡æœ‰æ§åˆ¶å…±åŒè¶‹åŠ¿ï¼Œä½ æœ€ç»ˆä¼šé”™è¯¯åœ°å¾—å‡ºå®ƒä»¬ç›¸å…³çš„ç»“è®ºã€‚[FigureÂ 10-4](#ch10_ts_trend) å±•ç¤ºäº†ä¸¤ä¸ªè¶‹åŠ¿ç¨³å®šçš„AR(1)è¿‡ç¨‹çš„æ¨¡æ‹Ÿå›å½’ç»“æœï¼Œè®¾è®¡ä¸Šå®ƒä»¬æ˜¯æ— å…³çš„ã€‚^([3](ch10.html#id600))
    å›¾æ˜¾ç¤ºäº†ç¬¬äºŒä¸ªå˜é‡ï¼ˆ*y2*ï¼‰çš„ä¼°è®¡æˆªè·ï¼ˆ*å¸¸æ•°*ï¼‰å’Œæ–œç‡ï¼Œä»¥åŠ95%ç½®ä¿¡åŒºé—´ã€‚
- en: '![trend spurious](assets/dshp_1004.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![è¶‹åŠ¿è™šå‡](assets/dshp_1004.png)'
- en: Figure 10-4\. OLS on spurious time series regression
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾10-4\. OLSåœ¨è™šå‡æ—¶é—´åºåˆ—å›å½’ä¸Šçš„è¡¨ç°
- en: Tip
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æç¤º
- en: Itâ€™s quite common to have spurious correlation with time series, as they most
    often display a time trend. Since it can act as a confounder, itâ€™s always recommended
    to include a linear time trend as a control. This way you *clean up* any noise
    that may arise from this potential confounder.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¶é—´åºåˆ—å¸¸å¸¸å‡ºç°ä¸æ—¶é—´ç›¸å…³çš„è™šå‡ç›¸å…³æ€§ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸æ˜¾ç¤ºæ—¶é—´è¶‹åŠ¿ã€‚ç”±äºå®ƒå¯èƒ½ä½œä¸ºæ··æ‚å› ç´ ï¼Œå»ºè®®å§‹ç»ˆåŒ…æ‹¬çº¿æ€§æ—¶é—´è¶‹åŠ¿ä½œä¸ºæ§åˆ¶å˜é‡ã€‚è¿™æ ·ä½ å¯ä»¥*æ¸…é™¤*ç”±æ­¤æ½œåœ¨æ··æ‚å› ç´ å¼•èµ·çš„ä»»ä½•å™ªéŸ³ã€‚
- en: Additional Variables
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é¢å¤–å˜é‡
- en: '[ChapterÂ 9](ch09.html#ch09_simulation) described the *omitted variable bias*
    that showed that *excluding* a variable that should have been included results
    in biased OLS estimates and thus, reduced predictive performance; importantly,
    this is also true for other machine learning (ML) algorithms.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[ç¬¬9ç« ](ch09.html#ch09_simulation) æè¿°äº†*é—æ¼å˜é‡åå·®*ï¼Œè¡¨æ˜*æ’é™¤*æœ¬åº”åŒ…å«çš„å˜é‡ä¼šå¯¼è‡´OLSä¼°è®¡åå·®ï¼Œä»è€Œé™ä½é¢„æµ‹æ€§èƒ½ï¼›è¿™ä¸€ç‚¹åŒæ ·é€‚ç”¨äºå…¶ä»–æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ç®—æ³•ã€‚'
- en: 'What happens if instead of omitting important variables, you include additional
    irrelevant features? One of the nice properties of OLS is that including uninformative
    features creates no bias, and only affects the variance of the estimates. [FigureÂ 10-5](#ch10_morevars)
    reports the mean and 90% confidence intervals for each estimated parameter from
    a Monte Carlo simulation, where:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä¸æ˜¯çœç•¥é‡è¦å˜é‡è€Œæ˜¯åŒ…å«é¢å¤–æ— å…³ç‰¹å¾ä¼šå‘ç”Ÿä»€ä¹ˆï¼ŸOLSçš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯åŒ…å«æ— ä¿¡æ¯ç‰¹å¾ä¸ä¼šå¼•å…¥åå·®ï¼Œåªä¼šå½±å“ä¼°è®¡çš„æ–¹å·®ã€‚[FigureÂ 10-5](#ch10_morevars)
    æŠ¥å‘Šäº†ä»è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿä¸­ä¼°è®¡çš„æ¯ä¸ªå‚æ•°çš„å‡å€¼å’Œ90%ç½®ä¿¡åŒºé—´ï¼Œå…¶ä¸­ï¼š
- en: Only one feature is informative ( <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    , with true coefficient <math alttext="alpha 1 equals 3"><mrow><msub><mi>Î±</mi>
    <mn>1</mn></msub> <mo>=</mo> <mn>3</mn></mrow></math> ).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åªæœ‰ä¸€ä¸ªç‰¹å¾æ˜¯æœ‰ä¿¡æ¯çš„ï¼ˆ <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> ï¼Œå…¶çœŸå®ç³»æ•°
    <math alttext="alpha 1 equals 3"><mrow><msub><mi>Î±</mi> <mn>1</mn></msub> <mo>=</mo>
    <mn>3</mn></mrow></math> ï¼‰ã€‚
- en: Four more uninformative controls are included when the model is trained.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“æ¨¡å‹è®­ç»ƒæ—¶åŒ…æ‹¬äº†å››ä¸ªæ›´å¤šçš„æ— ä¿¡æ¯æ§åˆ¶ã€‚
- en: 'Two models are trained: OLS and an out-of-the-box gradient boosting regression.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®­ç»ƒäº†ä¸¤ä¸ªæ¨¡å‹ï¼šOLSå’Œå¼€ç®±å³ç”¨çš„æ¢¯åº¦æå‡å›å½’ã€‚
- en: 'Both algorithms perform correctly on two fronts: they are able to correctly
    estimate the true parameter, and dismiss the uninformative variables.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¤ç§ç®—æ³•åœ¨ä¸¤ä¸ªæ–¹é¢è¡¨ç°æ­£ç¡®ï¼šå®ƒä»¬èƒ½å¤Ÿæ­£ç¡®ä¼°è®¡çœŸå®å‚æ•°ï¼Œå¹¶æ’é™¤æ— ä¿¡æ¯å˜é‡ã€‚
- en: '![including uninformative variables](assets/dshp_1005.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![åŒ…å«æ— ä¿¡æ¯å˜é‡](assets/dshp_1005.png)'
- en: Figure 10-5\. Effect of including uninformative controls
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾10-5\. åŒ…å«æ— ä¿¡æ¯æ§åˆ¶çš„å½±å“
- en: 'However, you must be cautious with ensemble learning algorithms since these
    tend to be quite sensitive when uninformative features are included, if these
    are highly correlated with the real underlying variables. You can typically see
    this with the *dummy variable trap*. The typical scenario arises with models with
    a dummy variable, like the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå¯¹äºé›†æˆå­¦ä¹ ç®—æ³•ï¼Œä½ å¿…é¡»å°å¿ƒï¼Œå› ä¸ºå®ƒä»¬åœ¨åŒ…å«é«˜åº¦ç›¸å…³äºçœŸå®æ½œåœ¨å˜é‡çš„æ— ä¿¡æ¯ç‰¹å¾æ—¶é€šå¸¸éå¸¸æ•æ„Ÿã€‚ä½ é€šå¸¸å¯ä»¥é€šè¿‡*è™šæ‹Ÿå˜é‡é™·é˜±*æ¥çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚è¿™ç§å…¸å‹çš„æƒ…å†µå‡ºç°åœ¨åƒä¸‹é¢è¿™æ ·æœ‰è™šæ‹Ÿå˜é‡çš„æ¨¡å‹ä¸­ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column y 2nd Column equals 3rd Column
    alpha 0 plus alpha 1 x plus alpha 2 upper D Subscript l plus epsilon 2nd Row 1st
    Column upper D Subscript l 2nd Column equals 3rd Column StartLayout Enlarged left-brace
    1st Row 1st Column 1 2nd Column if 3rd Column customer is left hyphen handed 2nd
    Row 1st Column 0 2nd Column if 3rd Column customer is right hyphen handed EndLayout
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>Î±</mi>
    <mn>2</mn></msub> <msub><mi>D</mi> <mi>l</mi></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>D</mi> <mi>l</mi></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfenced close="" open="{" separators=""><mtable><mtr><mtd
    columnalign="left"><mn>1</mn></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><mtext>customer</mtext> <mtext>is</mtext> <mtext>left-handed</mtext></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mn>0</mn></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><mtext>customer</mtext> <mtext>is</mtext> <mtext>right-handed</mtext></mrow></mtd></mtr></mtable></mfenced></mtd></mtr></mtable></math>
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column y 2nd Column equals 3rd Column
    alpha 0 plus alpha 1 x plus alpha 2 upper D Subscript l plus epsilon 2nd Row 1st
    Column upper D Subscript l 2nd Column equals 3rd Column StartLayout Enlarged left-brace
    1st Row 1st Column 1 2nd Column if 3rd Column customer is left hyphen handed 2nd
    Row 1st Column 0 2nd Column if 3rd Column customer is right hyphen handed EndLayout
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <mi>x</mi> <mo>+</mo> <msub><mi>Î±</mi>
    <mn>2</mn></msub> <msub><mi>D</mi> <mi>l</mi></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mi>D</mi> <mi>l</mi></msub></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mfenced close="" open="{" separators=""><mtable><mtr><mtd
    columnalign="left"><mn>1</mn></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><mtext>customer</mtext> <mtext>is</mtext> <mtext>left-handed</mtext></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mn>0</mn></mtd> <mtd columnalign="left"><mtext>if</mtext></mtd>
    <mtd><mrow><mtext>customer</mtext> <mtext>is</mtext> <mtext>right-handed</mtext></mrow></mtd></mtr></mtable></mfenced></mtd></mtr></mtable></math>
- en: "In OLS, the dummy variable trap arises when you include an intercept *and*\
    \ dummies for *all* available categories. In this example, you can only include\
    \ *one* dummy variable for left- *or* right-handedness, but not both, because\
    \ the cross-product matrix <math alttext=\"upper X prime upper X\"><mrow><mi>X</mi>\
    \ <mi>Ã¢</mi> <mi>\x80</mi> <mi>\x99</mi> <mi>X</mi></mrow></math> is not invertible\
    \ (and thus the OLS estimates donâ€™t exist).^([4](ch10.html#id604)) The solution\
    \ is to always leave out the dummy variable for a *reference category*, in the\
    \ example, the right-handed category."
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: "åœ¨OLSä¸­ï¼Œå½“ä½ åŒ…æ‹¬ä¸€ä¸ªæˆªè· *å’Œ* æ‰€æœ‰å¯ç”¨ç±»åˆ«çš„è™šæ‹Ÿå˜é‡æ—¶ï¼Œå°±ä¼šå‡ºç°è™šæ‹Ÿå˜é‡é™·é˜±ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œä½ åªèƒ½ä¸ºå·¦å³åˆ©æ‰‹ä¸­çš„ *ä¸€ä¸ª* è™šæ‹Ÿå˜é‡è¿›è¡ŒåŒ…å«ï¼Œè€Œä¸èƒ½åŒæ—¶åŒ…å«ä¸¤è€…ï¼Œå› ä¸ºäº¤å‰ä¹˜ç§¯çŸ©é˜µ\
    \ <math alttext=\"upper X prime upper X\"><mrow><mi>X</mi> <mi>Ã¢</mi> <mi>\x80\
    </mi> <mi>\x99</mi> <mi>X</mi></mrow></math> æ˜¯ä¸å¯é€†çš„ï¼ˆå› æ­¤OLSä¼°è®¡ä¸å­˜åœ¨ï¼‰ã€‚^([4](ch10.html#id604))\
    \ è§£å†³æ–¹æ³•æ˜¯å§‹ç»ˆçœç•¥å‚è€ƒç±»åˆ«çš„è™šæ‹Ÿå˜é‡ï¼Œä¾‹å¦‚åœ¨æœ¬ä¾‹ä¸­æ˜¯å³åˆ©æ‰‹ç±»åˆ«ã€‚"
- en: This computational restriction doesnâ€™t exist with ensemble algorithms like random
    forests or gradient boosting regression, but since dummy variables like *D[l]*
    and *D[r]* = 1 âˆ’ *D[l]* are perfectly correlated, itâ€™s normal to find both ranking
    very high in terms of feature importance. Since they provide the *exact same information*,
    the performance of the algorithm doesnâ€™t improve by including both. This is one
    useful intuitive fact that arises naturally by understanding OLS.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸éšæœºæ£®æ—æˆ–æ¢¯åº¦æå‡å›å½’ç­‰é›†æˆç®—æ³•ä¸åŒï¼Œè¿™ç§è®¡ç®—é™åˆ¶ä¸å­˜åœ¨ï¼Œä½†ç”±äºåƒ*D[l]*å’Œ*D[r]* = 1 âˆ’ *D[l]*è¿™æ ·çš„è™šæ‹Ÿå˜é‡å®Œå…¨ç›¸å…³ï¼Œå¾ˆæ­£å¸¸ä¼šå‘ç°å®ƒä»¬åœ¨ç‰¹å¾é‡è¦æ€§æ–¹é¢æ’åéƒ½å¾ˆé«˜ã€‚å› ä¸ºå®ƒä»¬æä¾›*å®Œå…¨ç›¸åŒçš„ä¿¡æ¯*ï¼Œæ‰€ä»¥é€šè¿‡åŒ…æ‹¬ä¸¤è€…æ¥æå‡ç®—æ³•çš„æ€§èƒ½æ˜¯æ— æ•ˆçš„ã€‚è¿™æ˜¯ä¸€æ¡æœ‰ç”¨çš„ç›´è§‚äº‹å®ï¼Œé€šè¿‡ç†è§£OLSæ–¹æ³•è‡ªç„¶äº§ç”Ÿã€‚
- en: The Central Role of Variance in ML
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ä¸­æ–¹å·®çš„ä¸­å¿ƒä½œç”¨
- en: 'One central tenet in ML is that you need variation in the features *and* the
    outcome for your algorithm to *identify* the parameters, or put differently, to
    learn the correlation. You can see this directly in the covariance formulation
    presented at the beginning: if *x* or *y* are constant, the covariance is zero,
    and hence OLS canâ€™t learn the parameter. Moreover, if *x* is constant, the denominator
    is zero, and thus the parameter doesnâ€™t exist, a result strongly connected to
    the dummy variable trap.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ä¸ªæ ¸å¿ƒåŸåˆ™æ˜¯ï¼Œä½ éœ€è¦åœ¨ç‰¹å¾å’Œç»“æœä¸­æœ‰å˜åŒ–ï¼Œè¿™æ ·ä½ çš„ç®—æ³•æ‰èƒ½*è¯†åˆ«*å‚æ•°ï¼Œæˆ–è€…æ¢å¥è¯è¯´ï¼Œå­¦ä¹ ç›¸å…³æ€§ã€‚ä½ å¯ä»¥ç›´æ¥åœ¨å¼€å¤´å‘ˆç°çš„åæ–¹å·®å…¬å¼ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ï¼šå¦‚æœ*x*æˆ–*y*æ˜¯å¸¸æ•°ï¼Œåæ–¹å·®å°±ä¸ºé›¶ï¼Œå› æ­¤OLSæ— æ³•å­¦ä¹ å‚æ•°ã€‚æ­¤å¤–ï¼Œå¦‚æœ*x*æ˜¯å¸¸æ•°ï¼Œåˆ†æ¯ä¸ºé›¶ï¼Œå› æ­¤å‚æ•°ä¸å­˜åœ¨ï¼Œè¿™ä¸è™šæ‹Ÿå˜é‡é™·é˜±å¯†åˆ‡ç›¸å…³çš„ç»“æœã€‚
- en: Tip
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æç¤º
- en: You need variation in the inputs if you want to explain variation in the output.
    This is true for any ML algorithm.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æƒ³è§£é‡Šè¾“å‡ºçš„å˜åŒ–ï¼Œä½ éœ€è¦è¾“å…¥ä¸­çš„å˜åŒ–ã€‚è¿™å¯¹ä»»ä½•æœºå™¨å­¦ä¹ ç®—æ³•éƒ½æ˜¯çœŸå®çš„ã€‚
- en: 'You may recall that in OLS, the estimates for the coefficients and the covariance
    matrix are:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½è®°å¾—åœ¨OLSä¸­ï¼Œç³»æ•°å’Œåæ–¹å·®çŸ©é˜µçš„ä¼°è®¡å€¼ä¸ºï¼š
- en: "<math alttext=\"StartLayout 1st Row 1st Column ModifyingAbove beta With bold\
    \ caret 2nd Column equals 3rd Column left-parenthesis upper X prime upper X right-parenthesis\
    \ Superscript negative 1 Baseline upper X prime upper Y 2nd Row 1st Column Var\
    \ left-parenthesis ModifyingAbove beta With bold caret bold right-parenthesis\
    \ 2nd Column equals 3rd Column s squared left-parenthesis upper X prime upper\
    \ X right-parenthesis Superscript negative 1 EndLayout\" display=\"block\"><mtable\
    \ displaystyle=\"true\"><mtr><mtd columnalign=\"right\"><mover accent=\"true\"\
    ><mi>Î²</mi> <mo>^</mo></mover></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign=\"\
    left\"><mrow><msup><mrow><mo>(</mo><mi>X</mi><mi>Ã¢</mi><mi>\x80</mi><mi>\x99</mi><mi>X</mi><mo>)</mo></mrow>\
    \ <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>X</mi> <mi>Ã¢</mi> <mi>\x80</mi>\
    \ <mi>\x99</mi> <mi>Y</mi></mrow></mtd></mtr> <mtr><mtd columnalign=\"right\"\
    ><mrow><mtext>Var</mtext> <mo>(</mo> <mover accent=\"true\"><mi>Î²</mi> <mo>^</mo></mover>\
    \ <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign=\"left\"><mrow><msup><mi>s</mi>\
    \ <mn>2</mn></msup> <msup><mrow><mo>(</mo><mi>X</mi><mi>Ã¢</mi><mi>\x80</mi><mi>\x99\
    </mi><mi>X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mtd></mtr></mtable></math>"
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: "<math alttext=\"StartLayout 1st Row 1st Column ModifyingAbove beta With bold\
    \ caret 2nd Column equals 3rd Column left-parenthesis upper X prime upper X right-parenthesis\
    \ Superscript negative 1 Baseline upper X prime upper Y 2nd Row 1st Column Var\
    \ left-parenthesis ModifyingAbove beta With bold caret bold right-parenthesis\
    \ 2nd Column equals 3rd Column s squared left-parenthesis upper X prime upper\
    \ X right-parenthesis Superscript negative 1 EndLayout\" display=\"block\"><mtable\
    \ displaystyle=\"true\"><mtr><mtd columnalign=\"right\"><mover accent=\"true\"\
    ><mi>Î²</mi> <mo>^</mo></mover></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign=\"\
    left\"><mrow><msup><mrow><mo>(</mo><mi>X</mi><mi>Ã¢</mi><mi>\x80</mi><mi>\x99</mi><mi>X</mi><mo>)</mo></mrow>\
    \ <mrow><mo>-</mo><mn>1</mn></mrow></msup> <mi>X</mi> <mi>Ã¢</mi> <mi>\x80</mi>\
    \ <mi>\x99</mi> <mi>Y</mi></mrow></mtd></mtr> <mtr><mtd columnalign=\"right\"\
    ><mrow><mtext>Var</mtext> <mo>(</mo> <mover accent=\"true\"><mi>Î²</mi> <mo>^</mo></mover>\
    \ <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign=\"left\"><mrow><msup><mi>s</mi>\
    \ <mn>2</mn></msup> <msup><mrow><mo>(</mo><mi>X</mi><mi>Ã¢</mi><mi>\x80</mi><mi>\x99\
    </mi><mi>X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></mtd></mtr></mtable></math>"
- en: where <math alttext="s squared"><msup><mi>s</mi> <mn>2</mn></msup></math> is
    the sample estimate of the residual variance, and <math alttext="upper X Subscript
    upper N times upper P"><msub><mi>X</mi> <mrow><mi>N</mi><mo>Ã—</mo><mi>P</mi></mrow></msub></math>
    is the feature matrix, including the vector of ones that correspond to the intercept.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­<math alttext="s squared"><msup><mi>s</mi> <mn>2</mn></msup></math>æ˜¯æ®‹å·®æ–¹å·®çš„æ ·æœ¬ä¼°è®¡ï¼Œ<math
    alttext="upper X Subscript upper N times upper P"><msub><mi>X</mi> <mrow><mi>N</mi><mo>Ã—</mo><mi>P</mi></mrow></msub></math>æ˜¯åŒ…æ‹¬å¯¹åº”äºæˆªè·çš„ä¸€å‘é‡çš„ç‰¹å¾çŸ©é˜µã€‚
- en: 'From these equations, two results follow:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™äº›æ–¹ç¨‹ä¸­å¯ä»¥å¾—å‡ºä¸¤ä¸ªç»“æœï¼š
- en: Conditions for identification
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: è¯†åˆ«æ¡ä»¶
- en: "There canâ€™t be perfect correlation between features (perfect multicollinearity)\
    \ for the cross-product matrix <math alttext=\"left-parenthesis upper X prime\
    \ upper X right-parenthesis\"><mrow><mo>(</mo> <mi>X</mi> <mi>Ã¢</mi> <mi>\x80\
    </mi> <mi>\x99</mi> <mi>X</mi> <mo>)</mo></mrow></math> to be positive definite\
    \ (full rank or invertible)."
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: "ç‰¹å¾ä¹‹é—´ä¸èƒ½æœ‰å®Œå…¨ç›¸å…³ï¼ˆå®Œå…¨å¤šé‡å…±çº¿æ€§ï¼‰ï¼Œä»¥ä½¿äº¤å‰ä¹˜ç§¯çŸ©é˜µ<math alttext=\"left-parenthesis upper X prime\
    \ upper X right-parenthesis\"><mrow><mo>(</mo> <mi>X</mi> <mi>Ã¢</mi> <mi>\x80\
    </mi> <mi>\x99</mi> <mi>X</mi> <mo>)</mo></mrow></math>æ˜¯æ­£å®šï¼ˆæ»¡ç§©æˆ–å¯é€†ï¼‰ã€‚"
- en: Variance of the estimates
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼°è®¡çš„æ–¹å·®
- en: The more correlated the features, the higher the variance of the estimates.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹å¾ç›¸å…³æ€§è¶Šé«˜ï¼Œä¼°è®¡çš„æ–¹å·®è¶Šå¤§ã€‚
- en: While the first part should be straightforward, the second requires a bit of
    mathematical manipulation to show for the general case of multiple regression.
    In the [repo](https://oreil.ly/dshp-repo) for this chapter, I include a simulation
    that verifies this condition in the case of multiple regression. For a simple
    bivariate regression, itâ€™s easy to show that the variance of the estimate is *negatively
    related* to the sample variance of the feature, so having covariates that exhibit
    more variation provides more information, thereby improving the precision of the
    estimates.^([5](ch10.html#id613))
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ç¬¬ä¸€éƒ¨åˆ†åº”è¯¥å¾ˆç®€å•ï¼Œä½†ç¬¬äºŒéƒ¨åˆ†éœ€è¦è¿›è¡Œä¸€äº›æ•°å­¦å¤„ç†ï¼Œä»¥å±•ç¤ºå¤šå…ƒå›å½’çš„ä¸€èˆ¬æƒ…å†µã€‚åœ¨è¿™ä¸€ç« èŠ‚çš„[repo](https://oreil.ly/dshp-repo)ä¸­ï¼Œæˆ‘åŒ…å«äº†ä¸€ä¸ªæ¨¡æ‹Ÿï¼ŒéªŒè¯äº†åœ¨å¤šå…ƒå›å½’æƒ…å†µä¸‹è¿™ä¸ªæ¡ä»¶ã€‚å¯¹äºç®€å•çš„åŒå˜é‡å›å½’ï¼Œå¾ˆå®¹æ˜“å±•ç¤ºä¼°è®¡çš„æ–¹å·®ä¸ç‰¹å¾çš„æ ·æœ¬æ–¹å·®å‘ˆ*è´Ÿç›¸å…³*ï¼Œå› æ­¤å…·æœ‰æ›´å¤šå˜åŒ–çš„åå˜é‡æä¾›æ›´å¤šä¿¡æ¯ï¼Œä»è€Œæé«˜ä¼°è®¡çš„ç²¾åº¦ã€‚^([5](ch10.html#id613))
- en: '[FigureÂ 10-6](#ch10_variance_gb) plots the average and 95% confidence intervals
    for the estimates from OLS and gradient boosting regression after simulating a
    bivariate linear DGP where Var(*x*[1]) is increased over a grid. As discussed,
    for OLS the variance of the estimate *decreases* as the covariate displays *more*
    variation. Notably, the same is true for GBR.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 10-6](#ch10_variance_gb) å±•ç¤ºäº†æ¨¡æ‹ŸåŒå˜é‡çº¿æ€§DGPåOLSå’Œæ¢¯åº¦æå‡å›å½’ä¼°è®¡çš„å¹³å‡å€¼å’Œ95%ç½®ä¿¡åŒºé—´ï¼Œå…¶ä¸­Var(*x*[1])åœ¨ä¸€ä¸ªç½‘æ ¼ä¸Šå¢åŠ ã€‚æ­£å¦‚è®¨è®ºçš„é‚£æ ·ï¼Œå¯¹äºOLSæ¥è¯´ï¼Œä¼°è®¡çš„æ–¹å·®éšç€åå˜é‡æ˜¾ç¤ºæ›´å¤šå˜åŒ–è€Œ*å‡å°‘*ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¯¹äºGBRä¹Ÿæ˜¯å¦‚æ­¤ã€‚'
- en: '![variance GB](assets/dshp_1006.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![æ–¹å·®GB](assets/dshp_1006.png)'
- en: Figure 10-6\. Variance of an estimate for OLS and GBR
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 10-6\. OLSå’ŒGBRä¼°è®¡çš„æ–¹å·®
- en: 'This principle is at play in a practice that is not uncommon among data scientists.
    Imagine that youâ€™re running a regression like the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåŸç†åœ¨æ•°æ®ç§‘å­¦å®¶ä¸­å¹¶ä¸ç½•è§çš„å®è·µä¸­å‘æŒ¥ä½œç”¨ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œæ‚¨æ­£åœ¨è¿è¡Œä»¥ä¸‹å›å½’ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column y Subscript i 2nd Column equals
    3rd Column alpha plus sigma-summation Underscript s Endscripts theta Subscript
    s Baseline upper D Subscript i s plus gamma z overbar Subscript s left-parenthesis
    i right-parenthesis plus epsilon Subscript i 2nd Row 1st Column upper D Subscript
    i s 2nd Column equals 3rd Column StartLayout Enlarged left-brace 1st Row 1st Column
    1 2nd Column if 3rd Column customer i lives in state s 2nd Row 1st Column 0 2nd
    Column Blank 3rd Column otherwise EndLayout 3rd Row 1st Column z overbar Subscript
    s left-parenthesis i right-parenthesis 2nd Column equals 3rd Column state sample
    average of z given the state where i lives EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>y</mi> <mi>i</mi></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mi>Î±</mi> <mo>+</mo> <munder><mo>âˆ‘</mo>
    <mi>s</mi></munder> <msub><mi>Î¸</mi> <mi>s</mi></msub> <msub><mi>D</mi> <mrow><mi>i</mi><mi>s</mi></mrow></msub>
    <mo>+</mo> <mi>Î³</mi> <msub><mover><mi>z</mi> <mo>Â¯</mo></mover> <mrow><mi>s</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub>
    <mo>+</mo> <msub><mi>Ïµ</mi> <mi>i</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>D</mi>
    <mrow><mi>i</mi><mi>s</mi></mrow></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfenced
    close="" open="{" separators=""><mtable><mtr><mtd columnalign="left"><mn>1</mn></mtd>
    <mtd columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><mtext>customer</mtext>
    <mi>i</mi> <mtext>lives</mtext> <mtext>in</mtext> <mtext>state</mtext> <mi>s</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mn>0</mn></mtd> <mtd><mtext>otherwise</mtext></mtd></mtr></mtable></mfenced></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mover><mi>z</mi> <mo>Â¯</mo></mover> <mrow><mi>s</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mtext>state</mtext> <mtext>sample</mtext>
    <mtext>average</mtext> <mtext>of</mtext> <mi>z</mi> <mtext>given</mtext> <mtext>the</mtext>
    <mtext>state</mtext> <mtext>where</mtext> <mi>i</mi> <mtext>lives</mtext></mrow></mtd></mtr></mtable></math>
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column y Subscript i 2nd Column equals
    3rd Column alpha plus sigma-summation Underscript s Endscripts theta Subscript
    s Baseline upper D Subscript i s plus gamma z overbar Subscript s left-parenthesis
    i right-parenthesis plus epsilon Subscript i 2nd Row 1st Column upper D Subscript
    i s 2nd Column equals 3rd Column StartLayout Enlarged left-brace 1st Row 1st Column
    1 2nd Column if 3rd Column customer i lives in state s 2nd Row 1st Column 0 2nd
    Column Blank 3rd Column otherwise EndLayout 3rd Row 1st Column z overbar Subscript
    s left-parenthesis i right-parenthesis 2nd Column equals 3rd Column state sample
    average of z given the state where i lives EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><msub><mi>y</mi> <mi>i</mi></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mi>Î±</mi> <mo>+</mo> <munder><mo>âˆ‘</mo>
    <mi>s</mi></munder> <msub><mi>Î¸</mi> <mi>s</mi></msub> <msub><mi>D</mi> <mrow><mi>i</mi><mi>s</mi></mrow></msub>
    <mo>+</mo> <mi>Î³</mi> <msub><mover><mi>z</mi> <mo>Â¯</mo></mover> <mrow><mi>s</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub>
    <mo>+</mo> <msub><mi>Ïµ</mi> <mi>i</mi></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>D</mi>
    <mrow><mi>i</mi><mi>s</mi></mrow></msub></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfenced
    close="" open="{" separators=""><mtable><mtr><mtd columnalign="left"><mn>1</mn></mtd>
    <mtd columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><mtext>customer</mtext>
    <mi>i</mi> <mtext>lives</mtext> <mtext>in</mtext> <mtext>state</mtext> <mi>s</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mn>0</mn></mtd> <mtd><mtext>otherwise</mtext></mtd></mtr></mtable></mfenced></mtd></mtr>
    <mtr><mtd columnalign="right"><msub><mover><mi>z</mi> <mo>Â¯</mo></mover> <mrow><mi>s</mi><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msub></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mtext>state</mtext> <mtext>sample</mtext>
    <mtext>average</mtext> <mtext>of</mtext> <mi>z</mi> <mtext>given</mtext> <mtext>the</mtext>
    <mtext>state</mtext> <mtext>where</mtext> <mi>i</mi> <mtext>lives</mtext></mrow></mtd></mtr></mtable></math>
- en: If *y* denotes sales per customer and *z* household income, this model says
    that sales vary across states (dummy variables) and that thereâ€™s an independent
    effect whereby richer states also purchase more (proxied with the average household
    income for each state).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœ*y*è¡¨ç¤ºæ¯ä½é¡¾å®¢çš„é”€å”®é¢ï¼Œ*z*è¡¨ç¤ºå®¶åº­æ”¶å…¥ï¼Œè¯¥æ¨¡å‹è¡¨æ˜é”€å”®é¢åœ¨å„å·ï¼ˆè™šæ‹Ÿå˜é‡ï¼‰ä¹‹é—´å˜åŒ–ï¼Œå¹¶ä¸”å¯Œè£•çš„å·ä¹Ÿæœ‰ç‹¬ç«‹çš„æ•ˆåº”ï¼Œå¯Œè£•å·è´­ä¹°æ›´å¤šï¼ˆç”¨æ¯ä¸ªå·çš„å¹³å‡å®¶åº­æ”¶å…¥æ¥ä»£è¡¨ï¼‰ã€‚
- en: While your intuition might be right, you wonâ€™t be able to train this model with
    OLS since thereâ€™s perfect multicollinearity. In other words, the state dummy variables
    and state averages *of any metric you can think of* provide the *exact same information*.
    And this is true for any ML algorithm!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æ‚¨çš„ç›´è§‰å¯èƒ½æ˜¯æ­£ç¡®çš„ï¼Œä½†ç”±äºå­˜åœ¨å®Œå…¨å¤šé‡å…±çº¿æ€§ï¼Œæ‚¨æ— æ³•ç”¨OLSè®­ç»ƒè¿™ä¸ªæ¨¡å‹ã€‚æ¢å¥è¯è¯´ï¼Œå·è™šæ‹Ÿå˜é‡å’Œä»»ä½•æ‚¨èƒ½æƒ³åˆ°çš„å·å¹³å‡å€¼*æä¾›ç›¸åŒçš„ä¿¡æ¯*ã€‚å¯¹äºä»»ä½•æœºå™¨å­¦ä¹ ç®—æ³•éƒ½æ˜¯å¦‚æ­¤ï¼
- en: To check this, I simulate a simple model using the data generating process I
    just covered, where I include three states (and thus, two dummy variables to avoid
    the dummy variable trap) drawn from a multinomial distribution (code can be found
    in the [repo](https://oreil.ly/dshp-repo)). [ExampleÂ 10-3](#ch10_rankz) shows
    that the features matrix is indeed low rank, implying that thereâ€™s perfect multicollinearity.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†éªŒè¯è¿™ä¸€ç‚¹ï¼Œæˆ‘ä½¿ç”¨åˆšæ‰è®¨è®ºçš„æ•°æ®ç”Ÿæˆè¿‡ç¨‹æ¨¡æ‹Ÿäº†ä¸€ä¸ªç®€å•çš„æ¨¡å‹ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸‰ä¸ªå·ï¼ˆå› æ­¤ï¼Œä¸ºé¿å…è™šæ‹Ÿå˜é‡é™·é˜±ï¼Œæœ‰ä¸¤ä¸ªè™šæ‹Ÿå˜é‡ï¼‰ï¼Œè¿™äº›å·ä»å¤šé¡¹åˆ†å¸ƒä¸­æŠ½å–ï¼ˆä»£ç å¯ä»¥åœ¨[repo](https://oreil.ly/dshp-repo)ä¸­æ‰¾åˆ°ï¼‰ã€‚[ç¤ºä¾‹Â 10-3](#ch10_rankz)
    è¡¨æ˜ç‰¹å¾çŸ©é˜µç¡®å®æ˜¯ä½ç§©çš„ï¼Œæ„å‘³ç€å­˜åœ¨å®Œå…¨å¤šé‡å…±çº¿æ€§ã€‚
- en: 'Example 10-3\. State dummies: effect of dropping the state average'
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç¤ºä¾‹ 10-3\. çŠ¶æ€è™šæ‹Ÿå˜é‡ï¼šåˆ é™¤çŠ¶æ€å¹³å‡å€¼çš„å½±å“
- en: '[PRE5]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: To check that the same point is valid for more general nonlinear algorithms,
    I ran a Monte Carlo (MC) simulation of this same model, training it with gradient
    boosting regression (no metaparameter optimization) and calculated the mean squared
    error (MSE) for the test sample using the complete set of features and after dropping
    the redundant mean feature. [FigureÂ 10-7](#ch10_gbrstate) shows the average MSE
    along with 90% confidence intervals for MSE. You can verify that the predictive
    performance is virtually the same, as you would expect if the extra variable provides
    no additional information.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†éªŒè¯æ›´ä¸€èˆ¬éçº¿æ€§ç®—æ³•ä¹Ÿå…·æœ‰åŒæ ·çš„è§‚ç‚¹ï¼Œæˆ‘å¯¹è¿™ä¸ªåŒæ ·çš„æ¨¡å‹è¿›è¡Œäº†è’™ç‰¹å¡ç½—ï¼ˆMCï¼‰æ¨¡æ‹Ÿï¼Œç”¨æ¢¯åº¦æå‡å›å½’ï¼ˆæ²¡æœ‰å…ƒå‚æ•°ä¼˜åŒ–ï¼‰è¿›è¡Œè®­ç»ƒï¼Œå¹¶è®¡ç®—äº†æµ‹è¯•æ ·æœ¬çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œä½¿ç”¨å®Œæ•´ç‰¹å¾é›†å’Œå»æ‰å¤šä½™å‡å€¼ç‰¹å¾åçš„æƒ…å†µã€‚[å›¾Â 10-7](#ch10_gbrstate)
    å±•ç¤ºäº†MSEçš„å¹³å‡å€¼å’Œ90%ç½®ä¿¡åŒºé—´ã€‚æ‚¨å¯ä»¥éªŒè¯é¢„æµ‹æ€§èƒ½å‡ ä¹ç›¸åŒï¼Œè¿™æ˜¯æ‚¨æœŸæœ›çš„ï¼Œå› ä¸ºé¢å¤–å˜é‡æœªæä¾›é¢å¤–ä¿¡æ¯ã€‚
- en: '![gbr state](assets/dshp_1007.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![GBRå·](assets/dshp_1007.png)'
- en: Figure 10-7\. Results from MC simulation for gradient boosting
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 10-7\. æ¢¯åº¦æå‡MCæ¨¡æ‹Ÿç»“æœ
- en: Key Takeaways
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¦ç‚¹
- en: 'These are the key takeaways from this chapter:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯æœ¬ç« çš„è¦ç‚¹ï¼š
- en: Why learn linear regression?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆå­¦ä¹ çº¿æ€§å›å½’ï¼Ÿ
- en: Understanding linear regression should help you build some important intuitions
    that apply more generally to other nonlinear algorithms, such as random forests
    or boosting techniques.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è§£çº¿æ€§å›å½’åº”è¯¥å¸®åŠ©æ‚¨å»ºç«‹ä¸€äº›é‡è¦çš„ç›´è§‰ï¼Œè¿™äº›ç›´è§‰æ›´æ™®éé€‚ç”¨äºå…¶ä»–éçº¿æ€§ç®—æ³•ï¼Œå¦‚éšæœºæ£®æ—æˆ–æå‡æŠ€æœ¯ã€‚
- en: Correlation is not causation.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ç›¸å…³æ€§ä¸ç­‰äºå› æœå…³ç³»ã€‚
- en: In general, machine learning algorithms only provide information about the correlation
    of features and outcome. The result is clear cut in linear regression, so this
    should serve as your benchmark when thinking about other learning algorithms.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸ï¼Œæœºå™¨å­¦ä¹ ç®—æ³•åªæä¾›å…³äºç‰¹å¾ä¸ç»“æœç›¸å…³æ€§çš„ä¿¡æ¯ã€‚çº¿æ€§å›å½’ç»“æœæ˜ç¡®ï¼Œå› æ­¤åœ¨æ€è€ƒå…¶ä»–å­¦ä¹ ç®—æ³•æ—¶ï¼Œè¿™åº”ä½œä¸ºæ‚¨çš„åŸºå‡†ã€‚
- en: Frisch-Waugh-Lovell theorem.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Frisch-Waugh-Lovellå®šç†ã€‚
- en: This is an important result in linear regression that states that the estimates
    can be interpreted as the net effect after controlling for the remaining covariates.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯çº¿æ€§å›å½’ä¸­çš„ä¸€ä¸ªé‡è¦ç»“æœï¼ŒæŒ‡å‡ºä¼°è®¡é‡å¯ä»¥è¢«è§£é‡Šä¸ºåœ¨æ§åˆ¶å‰©ä½™åå˜é‡ä¹‹åçš„å‡€æ•ˆåº”ã€‚
- en: FWL and confounders.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: FWL å’Œæ··æ‚å› ç´ ã€‚
- en: Thanks to FWL, you can control for confounders just by including them in your
    set of features. One common example is in time series analysis, where itâ€™s always
    a good practice to control for a deterministic trend. This acts as a safeguard
    against getting spurious results when the outcome and features display some trend.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äº FWLï¼Œä½ å¯ä»¥é€šè¿‡å°†å…¶åŒ…å«åœ¨ç‰¹å¾é›†ä¸­æ¥æ§åˆ¶æ··æ‚å› ç´ ã€‚ä¸€ä¸ªå¸¸è§çš„ä¾‹å­æ˜¯åœ¨æ—¶é—´åºåˆ—åˆ†æä¸­ï¼Œæ€»æ˜¯è‰¯å¥½çš„åšæ³•æ˜¯æ§åˆ¶ç¡®å®šæ€§è¶‹åŠ¿ã€‚è¿™å¯ä»¥é˜²æ­¢å½“ç»“æœå’Œç‰¹å¾æ˜¾ç¤ºæŸäº›è¶‹åŠ¿æ—¶äº§ç”Ÿè™šå‡ç»“æœã€‚
- en: Irrelevant variables.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: æ— å…³å˜é‡ã€‚
- en: In linear regression, it is safe to include uninformative controls. Ensemble
    learning algorithms might be sensitive to irrelevant variables if these are sufficiently
    correlated to informative features. You wonâ€™t bias your estimates, but this may
    lead you to conclude that some variable has predictive power when it doesnâ€™t.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çº¿æ€§å›å½’ä¸­ï¼ŒåŒ…å«æ— ä¿¡æ¯çš„æ§åˆ¶å˜é‡æ˜¯å®‰å…¨çš„ã€‚å¦‚æœè¿™äº›å˜é‡ä¸ä¿¡æ¯æ€§ç‰¹å¾è¶³å¤Ÿç›¸å…³ï¼Œé›†æˆå­¦ä¹ ç®—æ³•å¯èƒ½å¯¹æ— å…³å˜é‡æ•æ„Ÿã€‚ä½ ä¸ä¼šåç½®ä½ çš„ä¼°è®¡ï¼Œä½†è¿™å¯èƒ½å¯¼è‡´ä½ å¾—å‡ºæŸä¸ªå˜é‡å…·æœ‰é¢„æµ‹èƒ½åŠ›çš„ç»“è®ºï¼Œè€Œå®é™…ä¸Šå¹¶éå¦‚æ­¤ã€‚
- en: The dummy variable trap.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è™šæ‹Ÿå˜é‡é™·é˜±ã€‚
- en: In linear regression, itâ€™s always a good practice to include an intercept or
    constant term. If you include dummy variables, you must always exclude one category
    that will serve as a reference or base. For instance, if you include a female
    dummy variable, the male category serves as a reference for interpretation purposes.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çº¿æ€§å›å½’ä¸­ï¼Œå§‹ç»ˆåŒ…æ‹¬ä¸€ä¸ªæˆªè·æˆ–å¸¸æ•°é¡¹æ˜¯ä¸€ä¸ªè‰¯å¥½çš„å®è·µã€‚å¦‚æœä½ åŒ…æ‹¬è™šæ‹Ÿå˜é‡ï¼Œå¿…é¡»å§‹ç»ˆæ’é™¤ä¸€ä¸ªç±»åˆ«ä½œä¸ºå‚è€ƒæˆ–åŸºå‡†ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ åŒ…æ‹¬ä¸€ä¸ªå¥³æ€§è™šæ‹Ÿå˜é‡ï¼Œåˆ™ç”·æ€§ç±»åˆ«ä½œä¸ºè§£é‡Šç›®çš„çš„å‚è€ƒã€‚
- en: The dummy variable trap in ensemble learning.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: é›†æˆå­¦ä¹ ä¸­çš„è™šæ‹Ÿå˜é‡é™·é˜±ã€‚
- en: 'Nothing forbids you from including dummy variables for all categories with
    random forest or gradient boosting machines. But you also gain *nothing* from
    it: these variables provide no extra information that can improve the predictive
    performance of your model.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰ä»»ä½•è§„å®šé˜»æ­¢ä½ ä¸ºéšæœºæ£®æ—æˆ–æ¢¯åº¦æå‡æœºä¸­çš„æ‰€æœ‰ç±»åˆ«åŒ…æ‹¬è™šæ‹Ÿå˜é‡ã€‚ä½†ä½ ä¹Ÿä¸ä¼šä»ä¸­è·å¾—*ä»»ä½•*å¥½å¤„ï¼šè¿™äº›å˜é‡æä¾›çš„ä¿¡æ¯å¹¶ä¸èƒ½æé«˜æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½ã€‚
- en: Variance is critical for machine learning.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹å·®å¯¹æœºå™¨å­¦ä¹ è‡³å…³é‡è¦ã€‚
- en: Without sufficient variance in your features, your algorithm wonâ€™t be able to
    learn the underlying data generating process. This is true for linear regression
    and general machine learning algorithms.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ çš„ç‰¹å¾ç¼ºä¹è¶³å¤Ÿçš„æ–¹å·®ï¼Œä½ çš„ç®—æ³•å°†æ— æ³•å­¦ä¹ åˆ°åº•å±‚æ•°æ®ç”Ÿæˆè¿‡ç¨‹ã€‚è¿™å¯¹äºçº¿æ€§å›å½’å’Œä¸€èˆ¬çš„æœºå™¨å­¦ä¹ ç®—æ³•éƒ½æ˜¯é€‚ç”¨çš„ã€‚
- en: Further Reading
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥é˜…è¯»
- en: 'Linear regression is covered in most statistics, machine learning, and econometrics
    textbooks. The treatment in Trevor Hastie et al., *The Elements of Statistical
    Learning: Data Mining, Inference, and Prediction*, 2nd ed. (Springer), is superb.
    It discusses *regression by successive orthogonalization*, a result that is closely
    related to the FWL theorem.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§å›å½’åœ¨å¤§å¤šæ•°ç»Ÿè®¡å­¦ã€æœºå™¨å­¦ä¹ å’Œè®¡é‡ç»æµå­¦æ•™ç§‘ä¹¦ä¸­éƒ½æœ‰æ¶‰åŠã€‚Trevor Hastie ç­‰äººçš„ã€Šç»Ÿè®¡å­¦ä¹ çš„è¦ç´ ï¼šæ•°æ®æŒ–æ˜ã€æ¨æ–­ä¸é¢„æµ‹ã€‹ç¬¬äºŒç‰ˆï¼ˆSpringerï¼‰ä¸­çš„å¤„ç†éå¸¸å‡ºè‰²ã€‚å®ƒè®¨è®ºäº†*é€æ­¥æ­£äº¤åŒ–å›å½’*ï¼Œè¿™ä¸
    FWL å®šç†å¯†åˆ‡ç›¸å…³ã€‚
- en: 'Chapter 3 of *Mostly Harmless Econometrics: An Empiricistâ€™s Companion* by Joshua
    Angrist and JÃ¶rn-Steffen Pischke (Princeton University Press) provides a very
    deep discussion on the fundamentals of linear regression, as well as the derivations
    for the covariance formulas presented in the chapter. This book is great if you
    want to strengthen your intuitions on regression.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Joshua Angrist å’Œ JÃ¶rn-Steffen Pischke çš„ã€Šå¤§å¤šæ•°æ— å®³çš„è®¡é‡ç»æµå­¦ï¼šç»éªŒä¸»ä¹‰è€…çš„ä¼´ä¾£ã€‹ç¬¬ä¸‰ç« ï¼ˆæ™®æ—æ–¯é¡¿å¤§å­¦å‡ºç‰ˆç¤¾ï¼‰æä¾›äº†å…³äºçº¿æ€§å›å½’åŸºç¡€çš„æ·±å…¥è®¨è®ºï¼Œä»¥åŠè¯¥ç« èŠ‚ä¸­æ‰€å‘ˆç°çš„åæ–¹å·®å…¬å¼çš„æ¨å¯¼ã€‚å¦‚æœä½ æƒ³åŠ å¼ºå¯¹å›å½’çš„ç›´è§‰ï¼Œè¿™æœ¬ä¹¦éå¸¸é€‚åˆã€‚
- en: The FWL theorem is covered in most econometrics textbooks. You can check out
    William Greeneâ€™s *Econometric Analysis*, 8th ed. (Pearson).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°è®¡é‡ç»æµå­¦æ•™ç§‘ä¹¦éƒ½æ¶µç›–äº† FWL å®šç†ã€‚ä½ å¯ä»¥æŸ¥é˜… William Greene çš„ã€Šè®¡é‡ç»æµåˆ†æã€‹ç¬¬å…«ç‰ˆï¼ˆPearsonï¼‰ã€‚
- en: ^([1](ch10.html#id584-marker)) OLS stands for ordinary least squares, which
    is the standard method used to train linear regression. For convenience I treat
    them as equivalent, but bear in mind that there are other loss functions that
    can be used.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch10.html#id584-marker)) OLS æŒ‡çš„æ˜¯æ™®é€šæœ€å°äºŒä¹˜æ³•ï¼Œè¿™æ˜¯ç”¨äºè®­ç»ƒçº¿æ€§å›å½’çš„æ ‡å‡†æ–¹æ³•ã€‚ä¸ºæ–¹ä¾¿èµ·è§ï¼Œæˆ‘æŠŠå®ƒä»¬è§†ä¸ºç­‰æ•ˆçš„ï¼Œä½†è¯·è®°ä½è¿˜æœ‰å…¶ä»–å¯ä»¥ä½¿ç”¨çš„æŸå¤±å‡½æ•°ã€‚
- en: ^([2](ch10.html#id599-marker)) At a high level, a time series is *stationary*
    when its probability distribution doesnâ€™t change in time. Weak stationarity refers
    only to the first two moments, and strong stationarity requires that the joint
    distribution is constant. The mean for a trending variable changes, so it canâ€™t
    be stationary (unless itâ€™s *trend-stationary*).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch10.html#id599-marker)) åœ¨é«˜å±‚æ¬¡ä¸Šï¼Œæ—¶é—´åºåˆ—åœ¨å…¶æ¦‚ç‡åˆ†å¸ƒéšæ—¶é—´ä¸å˜æ—¶æ˜¯*å¹³ç¨³*çš„ã€‚å¼±å¹³ç¨³æ€§ä»…æ¶‰åŠå‰ä¸¤ä¸ªæ—¶åˆ»ï¼Œè€Œå¼ºå¹³ç¨³æ€§è¦æ±‚è”åˆåˆ†å¸ƒæ’å®šã€‚è¶‹åŠ¿å˜é‡çš„å‡å€¼å˜åŒ–ï¼Œå› æ­¤å®ƒä¸èƒ½æ˜¯å¹³ç¨³çš„ï¼ˆé™¤éæ˜¯*è¶‹åŠ¿å¹³ç¨³*ï¼‰ã€‚
- en: ^([3](ch10.html#id600-marker)) *AR(1)* denotes an autoregressive process of
    order 1.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch10.html#id600-marker)) *AR(1)* è¡¨ç¤ºä¸€é˜¶è‡ªå›å½’è¿‡ç¨‹ã€‚
- en: "^([4](ch10.html#id604-marker)) Recall that the OLS estimator is <math alttext=\"\
    left-parenthesis upper X prime upper X right-parenthesis Superscript negative\
    \ 1 Baseline upper X prime upper Y\"><mrow><msup><mrow><mo>(</mo><mi>X</mi><mi>Ã¢</mi><mi>\x80\
    </mi><mi>\x99</mi><mi>X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>\
    \ <mi>X</mi> <mi>Ã¢</mi> <mi>\x80</mi> <mi>\x99</mi> <mi>Y</mi></mrow></math> ."
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch10.html#id604-marker)) è¯·è®°ä½ï¼ŒOLS ä¼°è®¡é‡æ˜¯ <math alttext="left-parenthesis
    upper X prime upper X right-parenthesis Superscript negative 1 Baseline upper
    X prime upper Y"><mrow><msup><mrow><mo>(</mo><mi>X</mi><mo>'</mo><mi>X</mi><mo>)</mo></mrow><mrow><mo>-1</mo></mrow></msup><mi>X</mi><mo>'</mo><mi>Y</mi></mrow></math>
    ã€‚
- en: ^([5](ch10.html#id613-marker)) In a bivariate setting, <math alttext="Var left-parenthesis
    beta 1 right-parenthesis equals Var left-parenthesis r e s i d u a l right-parenthesis
    slash Var left-parenthesis x right-parenthesis"><mrow><mtext>Var</mtext> <mrow><mo>(</mo>
    <msub><mi>Î²</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <mtext>Var</mtext>
    <mrow><mo>(</mo> <mi>r</mi> <mi>e</mi> <mi>s</mi> <mi>i</mi> <mi>d</mi> <mi>u</mi>
    <mi>a</mi> <mi>l</mi> <mo>)</mo></mrow> <mo>/</mo> <mtext>Var</mtext> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math> .
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch10.html#id613-marker)) åœ¨åŒå˜é‡è®¾ç½®ä¸­ï¼Œ<math alttext="Var left-parenthesis beta
    1 right-parenthesis equals Var left-parenthesis r e s i d u a l right-parenthesis
    slash Var left-parenthesis x right-parenthesis"><mrow><mtext>Var</mtext> <mrow><mo>(</mo>
    <msub><mi>Î²</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>=</mo> <mtext>Var</mtext>
    <mrow><mo>(</mo> <mi>r</mi> <mi>e</mi> <mi>s</mi> <mi>i</mi> <mi>d</mi> <mi>u</mi>
    <mi>a</mi> <mi>l</mi> <mo>)</mo></mrow> <mo>/</mo> <mtext>Var</mtext> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow></mrow></math> ã€‚
