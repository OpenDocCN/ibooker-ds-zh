- en: front matter
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前置内容
- en: preface
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前言
- en: 'Once upon a time, I was a graduate student, adrift and rudderless in an ocean
    of unfulfilling research directions and uncertain futures. Then I stumbled upon
    a remarkable article titled “Support Vector Machines: Hype or Hallelujah?” This
    being the early 2000s, support vector machines (SVMs) were, of course, the preeminent
    machine-learning technique of the time.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 从前，我是一名研究生，在充满不尽人意的科研方向和不确定的未来中迷失方向。然后，我偶然发现了一篇题为“支持向量机：炒作还是赞美？”的杰出文章。在21世纪初，支持向量机（SVMs）当然是当时领先的机器学习技术。
- en: In the article, the authors (one of whom would later become my PhD advisor)
    took a rather reductionist approach to explaining the considerably complex topic
    of SVMs, interleaving intuition and geometry with theory and application. The
    article made a powerful impression on me, at once igniting a lifelong fascination
    with machine learning and an obsession with understanding how such methods work
    under the hood. Indeed, the title of the first chapter pays homage to that paper
    that had so profound an influence over my life.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，作者们（其中一位后来成为我的博士导师）采取了一种相当简约的方法来解释相当复杂的话题——SVMs，将直觉和几何与理论和应用交织在一起。这篇文章给我留下了深刻的印象，它不仅点燃了我对机器学习终身的好奇心，还让我着迷于理解这些方法在底层是如何工作的。确实，第一章的标题是对那篇对我的生活产生深远影响的文章的致敬。
- en: 'Much like SVMs then, ensemble methods are widely considered a preeminent machine-learning
    technique today. But what many people don’t realize is that some ensemble method
    or another has always been considered state of the art over the decades: bagging
    in the 1990s, random forests and boosting in the 2000s, gradient boosting in the
    2010s, and XGBoost in the 2020s. In the ever-mutable world of the best machine-learning
    models, ensemble methods, it seems, are indeed worth the hype.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 就像SVMs一样，集成方法今天被广泛认为是领先的机器学习技术。但许多人没有意识到的是，几十年来，某种集成方法或另一种方法一直被认为是最佳水平：20世纪90年代的bagging，21世纪初的随机森林和boosting，2010年代的梯度提升，以及2020年代的XGBoost。在最佳机器学习模型不断变化的世界上，集成方法似乎确实值得这样的炒作。
- en: 'I’ve been fortunate to spend a good deal of the past decade training many kinds
    of ensemble models, making industry applications out of them, and writing academic
    research papers on them. In this book, I try to showcase as many of these ensemble
    methods as possible: some that you’ve definitely heard of and some new ones that
    you should really hear about.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我很幸运，在过去十年中，我训练了许多种集成模型，将它们应用于工业，并撰写了关于它们的学术论文。在这本书中，我试图展示尽可能多的这些集成方法：一些你肯定听说过的，以及一些你应该真正了解的新方法。
- en: This book was never intended to be just a tutorial with step-by-step instructions
    and cut-and-paste code (although you can use it that way, too). There are dozens
    of such fantastic tutorials on the web, and they can get you going on your data
    set in an instant. Instead, I talk about each new method using an immersive approach
    inspired by that first machine-learning paper I ever read and refined in college
    classrooms during my time as a graduate lecturer.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的初衷并不是仅仅是一本带有逐步指令和剪切粘贴代码的教程（尽管你也可以这样使用它）。网上有数十个这样的优秀教程，它们可以让你瞬间开始处理你的数据集。相反，我使用一种沉浸式的方法来讨论每种新的方法，这种方法灵感来源于我第一次阅读的那篇机器学习论文，并在大学课堂中作为研究生讲师期间进行了完善。
- en: 'I’ve always felt that to understand a technical topic deeply, it helps to strip
    it down, take it apart, and try to put it back together again. I adopt the same
    approach in this book: we’ll take ensemble methods apart and (re)create them ourselves.
    We’ll tweak them and poke them to see how they change. And, in doing so, we’ll
    see exactly what makes them tick!'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我一直觉得，要深入理解一个技术主题，将其拆解、拆分并尝试重新组合是很有帮助的。在这本书中，我采用了同样的方法：我们将拆解集成方法并（重新）自己创造它们。我们将调整它们并探究它们的变化。通过这样做，我们将确切地看到是什么让它们运转！
- en: I hope this book will be helpful in demystifying those technical and algorithmic
    details and get you into the ensemble mindset, be it for your class project, Kaggle
    competition, or production-quality application.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这本书能帮助你揭开那些技术和算法细节的神秘面纱，并让你进入集成思维模式，无论是为了你的课堂项目、Kaggle竞赛，还是生产质量的软件应用。
- en: acknowledgments
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: I never thought that a book on ensemble methods would itself turn into an ensemble
    effort of family and friends, colleagues, and collaborators, all of whom had a
    lot to do with this book, from conception to completion.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我从未想过一本关于集成方法的书籍本身会变成一个由家人、朋友、同事和合作者组成的集成努力，他们从构思到完成都与这本书有很大关系。
- en: 'To Brian Sawyer, who let me pitch the idea of this book, for believing in this
    project, for being patient, and for keeping me on track: thank you for giving
    me this opportunity to do this thing that I’ve always wanted to do.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 致Brian Sawyer，感谢你让我提出这本书的想法，感谢你相信这个项目，感谢你的耐心，以及保持我按计划进行：感谢你给我这个机会去做我一直想做的事情。
- en: 'To my first development editor, Katherine Olstein, second development editor,
    Karen Miller, and technical development editor, Alain Couniot: I had a vision
    for what this book would look like when I started, and you helped make it better.
    Thank you for the hours and days of meticulous reviews, for your eagle-eyed edits,
    and for challenging me always to be a better writer. Your efforts have much to
    do with the final quality of this book.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 致我的第一位发展编辑Katherine Olstein、第二位发展编辑Karen Miller和技术发展编辑Alain Couniot：当我开始时，我对这本书的样貌有一个愿景，你们帮助让它变得更好。感谢你们细致入微的审阅，感谢你们敏锐的编辑，以及你们总是挑战我成为一个更好的作家。你们的努力与这本书的最终质量有很大关系。
- en: 'To Manish Jain: thank you for painstakingly proofreading the code line by line.
    To Marija Tudor: thank you for designing this absolutely fantastic cover (which
    I still think is the best part of this book), for making it orange at my request,
    and for typesetting it from cover to cover. To the proofing and production team
    at Manning: thank you for your exceptional craft—this book looks perfect—review
    editor Mihaela Batinic, production editor Kathleen Rossland, copy editor Julie
    McNamee, and proofreader Katie Tennant.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 致Manish Jain：感谢你逐行仔细校对代码。致Marija Tudor：感谢你设计这个绝对出色的封面（我认为这是这本书最好的部分），按照我的要求将其设计成橙色，并且从封面到封底进行了排版。感谢Manning出版社的校对和生产团队：感谢你们卓越的工艺——这本书看起来完美——审稿编辑Mihaela
    Batinic、生产编辑Kathleen Rossland、校对编辑Julie McNamee和校对员Katie Tennant。
- en: 'To my reviewers, Al Krinker, Alain Lompo, Biswanath Chowdhury, Chetan Saran
    Mehra, Eric Platon, Gustavo A. Patino, Joaquin Beltran, Lucian Mircea Sasu, Manish
    Jain, McHugson Chambers, Ninoslav Cerkez, Noah Flynn, Oliver Korten, Or Golan,
    Peter V. Henstock, Philip Best, Sergio Govoni, Simon Seyag, Stephen John Warnett,
    Subhash Talluri, Todd Cook, and Xiangbo Mao: thank you for your fabulous feedback
    and some truly terrific insights and comments. I tried to take in all of your
    advice (I really did), and much of it has worked its way into the book.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 致我的审稿人，Al Krinker、Alain Lompo、Biswanath Chowdhury、Chetan Saran Mehra、Eric Platon、Gustavo
    A. Patino、Joaquin Beltran、Lucian Mircea Sasu、Manish Jain、McHugson Chambers、Ninoslav
    Cerkez、Noah Flynn、Oliver Korten、Or Golan、Peter V. Henstock、Philip Best、Sergio
    Govoni、Simon Seyag、Stephen John Warnett、Subhash Talluri、Todd Cook和Xiangbo Mao：感谢你们精彩的反馈，以及一些真正出色的洞察和评论。我尽量吸收了你们的所有建议（我真的这么做了），其中许多已经融入到这本书中。
- en: To the readers who read the book during early access and who left many comments,
    corrections, and words of encouragement—you know who you are—thank you for the
    support!
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 致在早期访问期间阅读这本书并留下许多评论、更正和鼓励话语的读者——你知道你是谁——感谢你的支持！
- en: 'To my mentors, Kristin Bennett, Jong-Shi Pang, Jude Shavlik, Sriraam Natarajan,
    and Maneesh Singh, who have each shaped my thinking profoundly at different stages
    of my journey as a student, postdoc, professor, and professional: thank you for
    teaching me how to think in machine learning, how to speak machine learning, and
    how to build with machine learning. Much of your wisdom and many of your lessons
    endure in this book. And Kristin, I hope you like the title of the first chapter.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 致我的导师，Kristin Bennett、Jong-Shi Pang、Jude Shavlik、Sriraam Natarajan和Maneesh Singh，他们在我的学生、博士后、教授和专业人士的不同阶段深刻地塑造了我的思考：感谢你们教我如何用机器学习思考，如何用机器学习说话，以及如何用机器学习构建。你们的大部分智慧和许多教训都体现在这本书中。Kristin，我希望你喜欢第一章的标题。
- en: 'To Jenny and Guilherme de Oliveira, for your friendship over the years, but
    especially during the great pandemic, when much of this book was written: thank
    you for keeping me sane. I will always treasure our afternoons and evenings in
    that summer and fall of 2020, tucked away in your little backyard, our pod and
    sanctuary.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 致Jenny和Guilherme de Oliveira，感谢你们多年来建立的友谊，尤其是在这场大流行期间，当时这本书的大部分内容都在撰写中：感谢你们让我保持理智。我永远珍视我们2020年那个夏天和秋天的下午和晚上，在你们的小后院里，我们的避难所。
- en: 'To my parents, Vijaya and Shivakumar, and my brother, Anupam: thank you for
    always believing in me, and for always supporting me, even from tens of thousands
    of miles away. I know you’re proud of me. This book is finally finished, and now
    we can do all those other things we’re always talking about . . . until I start
    writing the next one, anyway.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 致我的父母，Vijaya和Shivakumar，以及我的兄弟，Anupam：感谢你们一直相信我，并一直支持我，即使相隔数万公里。我知道你们为我感到骄傲。这本书终于完成了，现在我们可以做那些我们一直谈论的其他事情了……至少在我开始写下一本书之前。
- en: 'To my wife, best friend, and biggest champion, Kristine: you’ve been an inexhaustible
    source of comfort and encouragement, especially when things got tough. Thank you
    for bouncing ideas with me, for proofreading with me, for the tea and snacks,
    for the Gus, for sacrificing all those weekends (and, sometimes, weeknights) when
    I was writing. Thank you for hanging in there with me, for always being there
    for me, and for never once doubting that I could do this. I love you!'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 致我的妻子、最好的朋友和最大的支持者，Kristine：你是我无尽的安慰和鼓励的源泉，尤其是在事情变得艰难的时候。感谢你和我一起头脑风暴，感谢你和我一起校对，感谢茶点和零食，感谢Gus，感谢你牺牲所有周末（有时甚至是工作日夜晚）来陪我写作。感谢你一直支持我，一直在我身边，从未怀疑过我能做到这一点。我爱你！
- en: about this book
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于本书
- en: 'There has never been a better time to learn about ensemble methods. The models
    covered in this book fall into three broad categories:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 学习集成方法从未有过更好的时机。本书涵盖的模型分为三大类：
- en: '*Foundational ensemble methods*—The classics that everyone has heard of, including
    historical ensemble techniques such as bagging, random forests, and AdaBoost'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基础集成方法*——大家耳熟能详的经典方法，包括历史性的集成技术，如Bagging、随机森林和AdaBoost'
- en: '*State-of-the-art ensemble methods*—The tried and tested powerhouses of the
    modern ensemble era that form the core of many real-world, in-production prediction,
    recommendation, and search systems'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*最先进的集成方法*——现代集成时代的经过检验的强大工具，是许多真实世界、在生产中的预测、推荐和搜索系统的核心'
- en: '*Emerging ensemble methods*—The latest methods fresh out of the research foundries
    to handle new needs and emerging priorities such as explainability and interpretability'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*新兴集成方法*——最新方法，刚刚从研究熔炉中出炉，用于处理新的需求，如可解释性和可理解性'
- en: Each chapter will introduce a different ensembling technique, using a three-pronged
    approach. First, you’ll learn the *intuition* behind each ensemble method by visualizing
    step by step how learning actually takes place. Second, you’ll *implement* a basic
    version of each ensemble method yourself to fully understand the algorithmic nuts
    and bolts. Third, you’ll learn how to *apply* powerful ensemble libraries and
    tools practically.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 每一章都将介绍不同的集成技术，采用三管齐下的方法。首先，通过逐步可视化学习过程，你将了解每个集成方法的*直觉*。其次，你将*实现*每个集成方法的基本版本，以全面理解算法的细节。第三，你将学习如何实际应用强大的集成库和工具。
- en: Most chapters also come with their own case study on real-world data, drawn
    from applications such as handwritten digit prediction, recommendation systems,
    sentiment analysis, demand forecasting, and others. These case studies tackle
    several real-world issues where appropriate, including preprocessing and feature
    engineering, hyperparameter selection, efficient training techniques, and effective
    model evaluation.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数章节还附带了自己在真实世界数据上的案例研究，这些数据来自手写数字预测、推荐系统、情感分析、需求预测等领域。这些案例研究在适当的时候解决了几种真实世界问题，包括预处理和特征工程、超参数选择、高效训练技术和有效模型评估。
- en: Who should read this book
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应该阅读这本书的人
- en: 'This book is intended for a broad audience:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本书面向广泛的读者：
- en: Data scientists who are interested in using ensemble methods to get the best
    out of their data for real-world applications
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对使用集成方法从数据中获取最佳实际应用效果感兴趣的数据科学家
- en: MLOps and DataOps engineers who are building, evaluating, and deploying ensemble-based,
    production-ready applications and pipelines
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建、评估和部署基于集成、生产就绪的应用程序和管道的MLOps和DataOps工程师
- en: Students of data science and machine learning who want to use this book as a
    learning resource or as a practical reference to supplement textbooks
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 希望将本书作为学习资源或作为补充教科书的实际参考的数据科学和机器学习的学生
- en: Kagglers and data science enthusiasts who can use this book as an entry point
    into learning about the endless modeling possibilities with ensemble methods
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用本书作为学习关于使用集成方法探索无限建模可能性的入门点的Kagglers和数据科学爱好者
- en: This book is *not* an introduction to machine learning and data science. This
    book assumes that you have some basic working knowledge of machine learning and
    that you’ve used or played around with at least one fundamental learning technique
    (e.g., decision trees).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本书**不是**机器学习和数据科学的入门书。本书假设你有一些基本的机器学习工作知识，并且你已经使用或尝试过至少一种基本的学习技术（例如，决策树）。
- en: A basic working knowledge of Python is also assumed. Examples, visualizations,
    and chapter case studies all use Python and Jupyter Notebooks. Knowledge of other
    commonly used Python packages such as NumPy (for mathematical computations), pandas
    (for data manipulation), and Matplotlib (for visualization) is useful, but not
    necessary. In fact, you can learn how to use these packages through the examples
    and case studies.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 假设读者具备基本的Python工作知识。示例、可视化和章节案例研究都使用Python和Jupyter Notebooks。了解其他常用Python包，如NumPy（用于数学计算）、pandas（用于数据处理）和Matplotlib（用于可视化）是有用的，但不是必需的。实际上，你可以通过示例和案例研究来学习如何使用这些包。
- en: 'How this book is organized: A road map'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本书是如何组织的：一个路线图
- en: This book is organized into nine chapters in three parts. Part 1 is a gentle
    introduction to ensemble methods, part 2 introduces and explains several essential
    ensemble methods, and part 3 covers advanced topics.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本书分为三部分，共九章。第一部分是对集成方法的温和介绍，第二部分介绍并解释了几个重要的集成方法，第三部分涵盖了高级主题。
- en: 'Part 1, “The basics of ensembles,” introduces ensemble methods and why you
    should care about them. This part also contains a road map of ensemble methods
    covered in the rest of the book:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 第一部分，“集成的基础”，介绍了集成方法以及为什么你应该关注它们。本部分还包含本书其余部分涵盖的集成方法的路线图：
- en: Chapter 1 discusses ensemble methods and basic ensemble terminology. It also
    introduces the fit-versus-complexity tradeoff (or the bias-variance tradeoff,
    as it’s more formally called). You’ll build your very first ensemble in this chapter.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第1章讨论了集成方法和基本集成术语。它还介绍了拟合与复杂度权衡（或称为偏差-方差权衡，更为正式的称呼）。你将在本章构建你的第一个集成。
- en: 'Part 2, “Essential ensemble methods,” covers several important families of
    ensemble methods, many of which are considered “essential” and are widely used
    in real-world applications. In each chapter, you’ll learn how to implement different
    ensemble methods from scratch, how they work, and how to apply them to real-world
    problems:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分，“基本集成方法”，涵盖了几个重要的集成方法家族，其中许多被认为是“基本”的，并且在现实世界的应用中得到了广泛使用。在每一章中，你将学习如何从头开始实现不同的集成方法，了解它们的工作原理以及如何将它们应用于现实世界问题：
- en: Chapter 2 begins our journey with parallel ensemble methods, specifically, parallel
    homogeneous ensembles. Ensemble methods covered include bagging, random forests,
    pasting, random subspaces, random patches, and Extra Trees.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第2章以并行集成方法开始我们的旅程，具体来说是并行同质集成。涵盖的集成方法包括bagging、随机森林、pasting、随机子空间、随机补丁和Extra
    Trees。
- en: Chapter 3 continues the journey with more parallel ensembles, but the focus
    in this chapter is on parallel heterogeneous ensembles. Ensemble methods covered
    include combining base models by majority voting, combining by weighting, prediction
    fusion with Dempster-Shafer, and meta-learning by stacking.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第3章继续旅程，引入了更多的并行集成，但本章的重点在于并行异构集成。涵盖的集成方法包括通过多数投票组合基础模型、通过加权组合、Dempster-Shafer预测融合以及通过堆叠进行元学习。
- en: Chapter 4 introduces another family of ensemble methods—sequential adaptive
    ensembles—in particular, the fundamental concept of boosting many weak models
    into one powerful model. Ensemble methods covered include AdaBoost and LogitBoost.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第4章介绍了另一类集成方法——顺序自适应集成，特别是将许多弱模型提升为一个强大模型的基本概念。涵盖的集成方法包括AdaBoost和LogitBoost。
- en: Chapter 5 builds on the foundational concepts of boosting and covers another
    fundamental sequential ensemble method, gradient boosting, which combines gradient
    descent with boosting. This chapter discusses how we can train gradient-boosting
    ensembles with scikit-learn and LightGBM.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第5章建立在提升的基础概念之上，并涵盖了另一个基本的顺序集成方法——梯度提升，它将梯度下降与提升相结合。本章讨论了如何使用scikit-learn和LightGBM训练梯度提升集成。
- en: Chapter 6 continues to explore sequential ensemble methods with Newton boosting,
    an efficient and effective extension of gradient boosting that combines Newton’s
    descent with boosting. This chapter discusses how we can train Newton boosting
    ensembles with XGBoost.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第6章继续探讨使用牛顿提升的顺序集成方法，牛顿提升是梯度提升的一个高效且有效扩展，它结合了牛顿下降和提升。本章讨论了如何使用XGBoost训练牛顿提升集成。
- en: 'Part 3, “Ensembles in the wild: Adapting ensemble methods to your data,” shows
    you how to apply ensemble methods to many scenarios, including data sets with
    continuous and count-valued labels and data sets with categorical features. You’ll
    also learn how to interpret your ensembles and explain their predictions:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 第3部分，“野外的集成：将集成方法应用于您的数据”，展示了如何将集成方法应用于许多场景，包括具有连续和计数值标签的数据集以及具有分类特征的数据集。您还将学习如何解释您的集成并解释其预测：
- en: Chapter 7 shows how we can train ensembles for different types of regression
    problems and generalized linear models, where training labels are continuous-
    or count-valued. Parallel and sequential ensembles for linear regression, Poisson
    regression, gamma regression, and Tweedie regression are covered.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7章展示了我们如何为不同类型的回归问题和广义线性模型训练集成，其中训练标签是连续值或计数值。本章涵盖了线性回归、泊松回归、伽马回归和Tweedie回归的并行和顺序集成。
- en: 'Chapter 8 identifies challenges in learning with nonnumeric features, specifically,
    categorical features, and encoding schemes that will help us train effective ensembles
    for this kind of data. This chapter also discusses two important practical issues:
    data leakage and prediction shift. Finally, we’ll see how to overcome these issues
    with ordered boosting and CatBoost.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8章确定了使用非数值特征学习时的挑战，特别是分类特征和编码方案，这些方案将帮助我们为这类数据训练有效的集成。本章还讨论了两个重要的实际问题：数据泄露和预测偏移。最后，我们将看到如何使用有序提升和CatBoost克服这些问题。
- en: Chapter 9 covers the newly emerging and very important topic of explainable
    AI from the perspective of ensemble methods. This chapter introduces the notion
    of explainability and why it’s important. Several common black-box explainability
    methods are also discussed, including permutation feature importance, partial
    dependence plots, surrogate methods, Locally Interpretable Model-Agnostic Explanation,
    Shapley values, and SHapley Additive exPlanations. The glass-box ensemble method,
    explainable boosting machines, and the InterpretML package are also introduced.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9章从集成方法的角度覆盖了新兴且非常重要的可解释人工智能（Explainable AI）主题。本章介绍了可解释性的概念以及为什么它很重要。还讨论了几种常见的黑盒可解释性方法，包括排列特征重要性、部分依赖图、代理方法、局部可解释模型无关解释（Locally
    Interpretable Model-Agnostic Explanation）、Shapley值和SHapley加性解释（SHapley Additive
    exPlanations）。还介绍了玻璃盒集成方法、可解释提升机（Explainable Boosting Machines）和InterpretML包。
- en: The epilogue concludes our journey with additional topics for further exploration
    and reading.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序言以进一步探索和阅读的额外主题结束了我们的旅程。
- en: While most of the chapters in the book can reasonably be read in a standalone
    manner, chapters 7, 8, and 9 build on part 2 of the book.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本书的大部分章节可以独立阅读，但第7章、第8章和第9章建立在本书的第二部分基础上。
- en: About the code
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关于代码
- en: All the code and examples in this book are written in Python 3\. The code is
    organized into Jupyter Notebooks and is available in an online GitHub repository
    ([https://github.com/gkunapuli/ensemble-methods-notebooks](https://github.com/gkunapuli/ensemble-methods-notebooks))
    and for download from the Manning website ([www.manning.com/books/ensemble-methods-for-machine-learning](https://www.manning.com/books/ensemble-methods-for-machine-learning)).
    You can get executable snippets of code from the liveBook (online) version of
    this book at [https://livebook.manning.com/book/ensemble-methods-for-machine-learning](https://livebook.manning.com/book/ensemble-methods-for-machine-learning).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有代码和示例都是用Python 3编写的。代码组织成Jupyter Notebooks，可在在线GitHub仓库（[https://github.com/gkunapuli/ensemble-methods-notebooks](https://github.com/gkunapuli/ensemble-methods-notebooks)）和Manning网站（[www.manning.com/books/ensemble-methods-for-machine-learning](https://www.manning.com/books/ensemble-methods-for-machine-learning)）上下载。您可以从本书的liveBook（在线）版本中获取可执行的代码片段，网址为[https://livebook.manning.com/book/ensemble-methods-for-machine-learning](https://livebook.manning.com/book/ensemble-methods-for-machine-learning)。
- en: Several Python scientific and visualization libraries are also used, including
    NumPy ([https://numpy.org/](https://numpy.org/)), SciPy ([https://scipy.org/](https://scipy.org/)),
    pandas ([https://pandas.pydata.org/](https://pandas.pydata.org/)), and Matplotlib
    ([https://matplotlib.org/](https://matplotlib.org/)). The code also uses several
    Python machine-learning and ensemble-method libraries, including scikit-learn
    ([https:// scikit-learn.org/stable/](https://scikit-learn.org/stable/)), LightGBM
    ([https://lightgbm.readthedocs.io/](https://lightgbm.readthedocs.io/)), XGBoost
    ([https://xgboost.readthedocs.io/](https://xgboost.readthedocs.io/)), CatBoost
    ([https://catboost.ai/](https://catboost.ai/)), and InterpretML ([https://interpret.ml/](https://interpret.ml/)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本书还使用了几个Python科学和可视化库，包括NumPy ([https://numpy.org/](https://numpy.org/))、SciPy
    ([https://scipy.org/](https://scipy.org/))、pandas ([https://pandas.pydata.org/](https://pandas.pydata.org/))和Matplotlib
    ([https://matplotlib.org/](https://matplotlib.org/))。代码还使用了几个Python机器学习和集成方法库，包括scikit-learn
    ([https://scikit-learn.org/stable/](https://scikit-learn.org/stable/))、LightGBM
    ([https://lightgbm.readthedocs.io/](https://lightgbm.readthedocs.io/))、XGBoost
    ([https://xgboost.readthedocs.io/](https://xgboost.readthedocs.io/))、CatBoost
    ([https://catboost.ai/](https://catboost.ai/))和InterpretML ([https://interpret.ml/](https://interpret.ml/))。
- en: This book contains many examples of source code both in numbered listings and
    in line with normal text. In both cases, source code is formatted in a fixed-width
    font like this to separate it from ordinary text. In many cases, the original
    source code has been reformatted; we’ve added line breaks and reworked indentation
    to accommodate the available page space in the book. Additionally, comments in
    the source code have often been removed from the listings when the code is described
    in the text. Code annotations accompany many of the listings, highlighting important
    concepts.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本书包含许多源代码示例，既有编号列表中的，也有与普通文本并行的。在这两种情况下，源代码都使用固定宽度字体格式化，如这样，以将其与普通文本区分开来。在许多情况下，原始源代码已被重新格式化；我们添加了换行并重新调整了缩进，以适应书中的可用页面空间。此外，当代码在文本中描述时，源代码中的注释通常已被从列表中删除。许多列表都伴随着代码注释，突出显示重要概念。
- en: liveBook discussion forum
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: liveBook讨论论坛
- en: Purchase of *Ensemble Methods for Machine Learning* includes free access to
    liveBook, Manning’s online reading platform. Using liveBook’s exclusive discussion
    features, you can attach comments to the book globally or to specific sections
    or paragraphs. It’s a snap to make notes for yourself, ask and answer technical
    questions, and receive help from the author and other users. To access the forum,
    go to [https://livebook.manning.com/book/ensemble-methods-for-machine-learning/discussion](https://livebook.manning.com/book/ensemble-methods-for-machine-learning/discussion).
    You can also learn more about Manning’s forums and the rules of conduct at [https://livebook.manning.com/discussion](https://livebook.manning.com/discussion).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 购买《机器学习集成方法》包括免费访问Manning的在线阅读平台liveBook。使用liveBook的独家讨论功能，您可以在全球范围内或针对特定章节或段落添加评论。为自己做笔记、提问和回答技术问题以及从作者和其他用户那里获得帮助都非常简单。要访问论坛，请访问[https://livebook.manning.com/book/ensemble-methods-for-machine-learning/discussion](https://livebook.manning.com/book/ensemble-methods-for-machine-learning/discussion)。您还可以在[https://livebook.manning.com/discussion](https://livebook.manning.com/discussion)了解更多关于Manning论坛和行为准则的信息。
- en: Manning’s commitment to our readers is to provide a venue where a meaningful
    dialogue between individual readers and between readers and the author can take
    place. It’s not a commitment to any specific amount of participation on the part
    of the author, whose contribution to the forum remains voluntary (and unpaid).
    We suggest you try asking the author some challenging questions lest his interest
    stray! The forum and the archives of previous discussions will be accessible from
    the publisher’s website as long as the book is in print.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Manning对我们读者的承诺是提供一个场所，让读者之间以及读者与作者之间可以进行有意义的对话。这不是对作者参与特定数量活动的承诺，作者对论坛的贡献仍然是自愿的（且未付费）。我们建议您尝试向作者提出一些挑战性的问题，以免他的兴趣转移！只要本书有售，论坛和先前讨论的存档将可通过出版社的网站访问。
- en: about the author
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于作者
- en: '![FM_UN01_Kunapuli](../Images/FM_UN01_Kunapuli.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![FM_UN01_Kunapuli](../Images/FM_UN01_Kunapuli.png)'
- en: Gautam Kunapuli has more than 15 years of experience in both academia and the
    machine-learning industry. His work focuses on human-in-the-loop learning, knowledge-based
    and advice-taking learning algorithms, and scalable learning for difficult machine-learning
    problems. Gautam has developed several novel algorithms for diverse application
    domains, including social network analysis, text and natural language processing,
    computer vision, behavior mining, educational data mining, insurance and financial
    analytics, and biomedical applications. He has also published papers exploring
    ensemble methods in relational domains and with imbalanced data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 戈塔姆·库纳普利在学术界和机器学习行业拥有超过15年的经验。他的工作专注于人机交互学习、基于知识和采纳建议的学习算法，以及针对困难机器学习问题的可扩展学习。戈塔姆为多个应用领域开发了几个新颖的算法，包括社交网络分析、文本和自然语言处理、计算机视觉、行为挖掘、教育数据挖掘、保险和金融分析以及生物医学应用。他还发表了关于关系域和失衡数据中集成方法的论文。
- en: about the cover illustration
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于封面插图
- en: The figure on the cover of *Ensemble Methods for Machine Learning* is "Huonv
    ou Musiciene Chinoise," or "Huonv or Chinese musician," from a collection by Jacques
    Grasset de Saint-Sauveur, published in 1788\. Each illustration is finely drawn
    and colored by hand.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 《机器学习集成方法》封面上的图像是“胡安或中国音乐家”，或“胡安或中国音乐家”，来自雅克·格拉塞·德·圣索沃尔的收藏，1788年出版。每一幅插图都是手工精细绘制和着色的。
- en: In those days, it was easy to identify where people lived and what their trade
    or station in life was just by their dress. Manning celebrates the inventiveness
    and initiative of the computer business with book covers based on the rich diversity
    of regional culture centuries ago, brought back to life by pictures from collections
    such as this one.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在那些日子里，仅凭人们的服饰就能轻易识别出他们居住的地方以及他们的职业或社会地位。曼宁通过基于几个世纪前丰富多样的地域文化的书封面来庆祝计算机行业的创新精神和主动性，这些文化通过如这一系列图片的图片被重新带回生活。
