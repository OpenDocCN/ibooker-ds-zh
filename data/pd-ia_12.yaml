- en: 10 Merging, joining, and concatenating
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 合并、连接和连接
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Concatenating `DataFrames` on the vertical and horizontal axes
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在垂直和水平轴上连接`DataFrames`
- en: Merging `DataFrames` with inner joins, outer joins, and left joins
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内连接、外连接和左连接合并`DataFrames`
- en: Finding unique and shared values between `DataFrames`
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`DataFrames`之间查找唯一和共享值
- en: Joining `DataFrames` by index labels
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过索引标签连接`DataFrames`
- en: As a business domain grows in complexity, it becomes increasingly difficult
    to store all data in a single collection. To solve this problem, data administrators
    split data across multiple tables. Then they associate the tables with one another
    so it is easy to identify the relationships among them.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 随着业务领域的复杂性增长，将所有数据存储在单个集合中变得越来越困难。为了解决这个问题，数据管理员将数据分散到多个表中。然后他们将这些表相互关联，以便容易识别它们之间的关系。
- en: You may have previously worked with a database such as PostgreSQL, MySQL, or
    Oracle. Relational database management systems (RDBMS) follow the paradigm described
    in the preceding paragraph. A database consists of tables. A table holds records
    for one domain model. A table consists of rows and columns. A row stores information
    for one record. A column stores an attribute for that record. Tables connect through
    column keys. If you haven’t worked with databases before, you can consider a table
    to be effectively equivalent to a pandas `DataFrame`.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能之前使用过像PostgreSQL、MySQL或Oracle这样的数据库。关系数据库管理系统（RDBMS）遵循前面段落中描述的范式。数据库由表组成。一个表包含一个领域模型的记录。一个表由行和列组成。一行存储一个记录的信息。一列存储该记录的属性。表通过列键连接。如果你之前没有使用过数据库，你可以将表视为与pandas
    `DataFrame`等效。
- en: Here’s a real-world example. Imagine that we’re building an e-commerce site
    and want to create a `users` table to store the website’s registered users. Following
    relational database conventions, we would assign a unique numeric identifier to
    each record. We’ll store the values in an id column. The id column’s values are
    called *primary keys* because they are the primary identifiers for specific rows.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个现实世界的例子。想象一下，我们正在构建一个电子商务网站，并希望创建一个`users`表来存储网站的注册用户。遵循关系数据库的惯例，我们将为每条记录分配一个唯一的数字标识符。我们将值存储在`id`列中。`id`列的值被称为*主键*，因为它们是特定行的唯一标识符。
- en: '| Users |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 用户 |'
- en: '| id | first_name | last_name | email | gender |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| id | 姓氏 | 名字 | 邮箱 | 性别 |'
- en: '| 1 | Homer | Simpson | donutfan@simpson.com | Male |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Homer | Simpson | donutfan@simpson.com | Male |'
- en: '| 2 | Bart | Simpson | troublemaker@simpson.com | Male |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Bart | Simpson | troublemaker@simpson.com | Male |'
- en: 'Let’s imagine that our next goal is to keep track of users’ orders on our site.
    We’ll create an `orders` table to store order details such as item name and price.
    But how do we connect each order to the user who placed it? Take a peek at the
    following table:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们设想我们的下一个目标是跟踪我们网站上用户的订单。我们将创建一个`orders`表来存储订单详情，例如项目名称和价格。但我们如何将每个订单与其下单的用户关联起来？看看下面的表格：
- en: '| Orders |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 订单 |'
- en: '| id | item | price | quantity | user_id |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| id | 项目 | 价格 | 数量 | 用户_id |'
- en: '| 1 | Donut Box | 4.99 | 4 | 1 |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 1 | Donut Box | 4.99 | 4 | 1 |'
- en: '| 2 | Slingshot | 19.99 | 1 | 2 |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Slingshot | 19.99 | 1 | 2 |'
- en: To establish a relationship between two tables, database administrators create
    a column of foreign keys. A *foreign key* is a reference to a record in another
    table. It is labeled *foreign* because the key exists outside the current table’s
    scope.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在两个表之间建立关系，数据库管理员创建一个外键列。*外键*是对另一个表中记录的引用。它被标记为*外键*，因为键存在于当前表的作用域之外。
- en: Each `orders` table row stores the ID of the *user* who placed the order in
    the user_id column. Thus, the user_id column stores foreign keys; its values are
    references to records in another table, the `users` table. Using the established
    relationship between the two tables, we can determine that order 1 was placed
    by the user with an id of 1, Homer Simpson.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 每个`orders`表行存储了在`user_id`列中下单的*用户*的ID。因此，`user_id`列存储外键；其值是对另一个表，即`users`表中记录的引用。使用两个表之间建立的关系，我们可以确定订单1是由ID为1的Homer
    Simpson用户下的。
- en: The advantage of foreign keys is the reduction of data duplication. The `orders`
    table does not need to copy the user’s first name, last name, and email for each
    order, for example. Rather, it needs only to store a single reference to the correct
    `users` record. The business entities of users and orders live separately, but
    we can connect them when necessary.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 外键的优势在于减少了数据重复。例如，`orders` 表不需要为每个订单复制用户的姓名、姓氏和电子邮件。相反，它只需要存储对正确的 `users` 记录的单个引用。用户和订单的业务实体分别存在，但我们在需要时可以将它们连接起来。
- en: When it comes time to combine tables, we can always turn to pandas. The library
    excels at appending, concatenating, joining, merging, and combining `DataFrame`s
    in both vertical and horizontal directions. It can identify unique and shared
    records between `DataFrame`s. It can perform SQL operations such as inner joins,
    outer joins, left joins, and right joins. In this chapter, we’ll explore the differences
    among these joins and the situations in which each one can prove to be advantageous.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要合并表时，我们总是可以转向 pandas。这个库在追加、连接、连接、合并和垂直和水平方向上合并 `DataFrame`s 方面表现出色。它可以识别
    `DataFrame`s 之间的唯一和共享记录。它可以执行 SQL 操作，如内连接、外连接、左连接和右连接。在本章中，我们将探讨这些连接之间的差异以及每种连接可以证明是有益的情况。
- en: 10.1 Introducing the data sets
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 数据集介绍
- en: 'Let’s import the pandas library and assign it an alias of `pd`:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们导入 pandas 库并将其分配一个别名 `pd`：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This chapter’s data sets come from the online social service Meetup, a website
    where users join groups for common interests such as hiking, literature, and board
    games. Group organizers schedule remote or in-person events that group members
    attend. Meetup’s domain has several data models, including groups, categories,
    and cities.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的数据集来自在线社交服务 Meetup，这是一个用户加入具有共同兴趣如远足、文学和桌面游戏的组网站。组组织者安排远程或现场活动，组员参加。Meetup
    的域有几个数据模型，包括组、分类和城市。
- en: 'The meetup directory houses all data sets for this chapter. Let’s begin our
    exploration by importing the groups1.csv and groups2.csv files. These files hold
    a sample of Meetup’s registered groups. Each group includes an ID, name, associated
    category ID, and associated city ID. Here’s what groups1 looks like:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Meetup 目录包含本章的所有数据集。让我们通过导入 groups1.csv 和 groups2.csv 文件开始我们的探索。这些文件包含 Meetup
    注册组的样本。每个组包括一个 ID、名称、关联的分类 ID 和关联的城市 ID。以下是 groups1 的样子：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s also import groups2.csv. Notice that both CSVs have the same four columns.
    We can imagine that the groups data was somehow split and stored across two files
    instead of one:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 同时导入 groups2.csv 文件。注意，这两个 CSV 文件都有相同的四个列。我们可以想象，groups 数据是以某种方式分割并存储在两个文件中而不是一个文件中：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Each group has a `category_id` foreign key. We can find information on categories
    in the categories.csv file. Each row in this file stores the category’s ID and
    name:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组还有一个 `category_id` 外键。我们可以在 categories.csv 文件中找到有关分类的信息。该文件中的每一行存储分类的 ID
    和名称：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Each group also has a `city_id` foreign key. The cities.csv data set stores
    the city information. A city has a unique ID, name, state, and zip code. Let’s
    take a look:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组还有一个 `city_id` 外键。cities.csv 数据集存储城市信息。一个城市有一个唯一的 ID、名称、州和邮政编码。让我们看一下：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The cities data set has a small issue. Look at the zip value in the first row.
    7093 is an invalid zip code; the value in the CSV is in fact 07093\. Zip codes
    can start with a leading zero. Unfortunately, pandas assumes that the zip codes
    are integers and thus strips the leading zeroes from the values. To solve this
    problem, we can add the `dtype` parameter to the `read_csv` function. `dtype`
    accepts a dictionary in which keys denote column names and values denote the data
    type to assign to that column. Let’s make sure that pandas imports the zip column’s
    values as strings:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: cities 数据集有一个小问题。看看第一行的 zip 值。7093 是一个无效的邮政编码；CSV 中的值实际上是 07093。邮政编码可以以一个前导零开头。不幸的是，pandas
    假设邮政编码是整数，因此从值中删除了前导零。为了解决这个问题，我们可以在 `read_csv` 函数中添加 `dtype` 参数。`dtype` 接受一个字典，其中键表示列名，值表示要分配给该列的数据类型。让我们确保
    pandas 将 zip 列的值作为字符串导入：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Excellent; we’re ready to proceed. To summarize, each group in groups1 and groups2
    belongs to a category and a city. The category_id and group_id columns store foreign
    keys. The category_id column values map to the category_id column in `categories`.
    The city_id column values map to the id column in cities. With our data tables
    loaded into Jupyter, we’re ready to start joining them.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 优秀；我们准备继续。为了总结，groups1 和 groups2 中的每个组都属于一个类别和一个城市。category_id 和 group_id 列存储外键。category_id
    列的值映射到 `categories` 中的 category_id 列。city_id 列的值映射到 cities 中的 id 列。在我们的数据表加载到
    Jupyter 中后，我们准备开始连接它们。
- en: 10.2 Concatenating data sets
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 连接数据集
- en: The simplest way to combine two data sets is with c*oncatenation*—appending
    one `DataFrame` to the end of another.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将两个数据集合并的最简单方法是使用连接——将一个 `DataFrame` 添加到另一个 `DataFrame` 的末尾。
- en: 'The groups1 and groups2 `DataFrame`s both have the same four column names.
    Let’s assume that they are two halves of a greater whole. We’d like to combine
    their rows into a single `DataFrame`. Pandas has a convenient `concat` function
    at the top level of the library. We can pass its `objs` parameter a list of `DataFrame`s.
    Pandas will concatenate the objects in the order in which they appear in the `objs`
    list. The next example concatenates the rows in groups2 to the end of groups1:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: groups1 和 groups2 `DataFrame`s 都有相同的四个列名。让我们假设它们是一个更大整体的两半。我们希望将它们的行合并到一个 `DataFrame`
    中。Pandas 库的顶层有一个方便的 `concat` 函数。我们可以传递一个 `DataFrame`s 列表给它的 `objs` 参数。Pandas 将按照
    `objs` 列表中出现的顺序连接对象。下一个示例将 groups2 的行连接到 groups1 的末尾：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The concatenated `DataFrame` has 16,330 rows! As you might have guessed, its
    length is equal to the sum of the lengths of the groups1 and groups2 `DataFrame`s:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 连接后的 `DataFrame` 有 16,330 行！正如你可能猜到的，它的长度等于 groups1 和 groups2 `DataFrame`s 长度的总和：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Pandas preserves the original index labels from both `DataFrame`s in the concatenation,
    which is why we see a final index position of 8,330 in the concatenated `DataFrame`
    even though it has more than 16,000 rows. What we are seeing is the 8,330 index
    from the end of the groups2 `DataFrame`. Pandas does not care that the same index
    number appears in both groups1 and groups2\. As a result, the concatenated index
    has duplicate index labels.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 在连接中保留了两个 `DataFrame` 的原始索引标签，这就是为什么我们看到连接后的 `DataFrame` 中有一个最终的索引位置为
    8,330，尽管它有超过 16,000 行。我们看到的是 groups2 `DataFrame` 末尾的 8,330 索引。Pandas 不关心相同的索引号是否出现在
    groups1 和 groups2 中。因此，连接后的索引有重复的索引标签。
- en: 'We can pass the `concat` function’s `ignore_index` parameter an argument of
    `True` to generate pandas’ standard numeric index. The concatenated `DataFrame`
    will discard the original index labels:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将 `concat` 函数的 `ignore_index` 参数设置为 `True` 以生成 pandas 的标准数值索引。连接后的 `DataFrame`
    将丢弃原始的索引标签：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'What if we wanted the best of both worlds: to create a nonduplicate index but
    also preserve which `DataFrame` each row of data came from? One solution is to
    add a `keys` parameter and pass it a list of strings. Pandas will associate each
    string in the `keys` list with the `DataFrame` at the same index position in the
    `objs` list. The `keys` and `objs` lists must be of equal length.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要两者兼得：创建一个非重复索引，同时保留每行数据来自哪个 `DataFrame`？一个解决方案是添加一个 `keys` 参数，并传递一个字符串列表。Pandas
    将将 `keys` 列表中的每个字符串与 `objs` 列表中相同索引位置的 `DataFrame` 关联起来。`keys` 和 `objs` 列表必须具有相同的长度。
- en: 'The next example assigns the groups1 `DataFrame` a key of `"G1"` and the `groups2`
    `DataFrame` a key of `"G2"`. The `concat` function returns a `MultiIndex DataFrame`.
    The `MultiIndex`’s first level stores the keys, and its second level stores the
    index labels from the respective `DataFrame`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例将 groups1 `DataFrame` 分配一个键 `"G1"`，将 `groups2` `DataFrame` 分配一个键 `"G2"`。`concat`
    函数返回一个 `MultiIndex DataFrame`。`MultiIndex` 的第一级存储键，第二级存储来自相应 `DataFrame` 的索引标签：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can extract the original `DataFrame`s by accessing the `G1` or `G2` keys
    on the first level of the `MultiIndex`. (See chapter 7 for a refresher on using
    the `loc` accessor on `MultiIndex` `DataFrame`s.) Before we proceed, let’s assign
    the concatenated `DataFrame` to a `groups` variable:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过访问 `MultiIndex` 第一级的 `G1` 或 `G2` 键来提取原始 `DataFrame`s。（参见第 7 章以复习在 `MultiIndex`
    `DataFrame`s 上使用 `loc` 访问器。）在我们继续之前，让我们将连接后的 `DataFrame` 分配给一个 `groups` 变量：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We’ll come back to `groups` in section 10.4.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第 10.4 节回到 `groups`。
- en: 10.3 Missing values in concatenated DataFrames
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 连接后的 DataFrames 中的缺失值
- en: 'When concatenating two `DataFrame`s, pandas places `NaN`s at intersections
    of row labels and column labels that the data sets do not share. Consider the
    following two `DataFrame`s, both of which have a Football column. The sports_champions_A
    `DataFrame` has an exclusive Baseball column, and the sports_champions_B `DataFrame`
    has an exclusive Hockey column:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当连接两个`DataFrame`时，pandas会在数据集不共享的行标签和列标签的交叉处放置`NaN`。考虑以下两个`DataFrame`，它们都有一个足球列。`sports_champions_A`
    `DataFrame`有一个独有的棒球列，而`sports_champions_B` `DataFrame`有一个独有的曲棍球列：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If we concatenate the `DataFrames`, we will create missing values in the Baseball
    and Hockey columns. The sports_champions_A `DataFrame` has no values to place
    in the Hockey column, and the sports_champions_B `DataFrame` has no values to
    place in the Baseball column:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将`DataFrames`连接起来，将在棒球和曲棍球列中创建缺失值。`sports_champions_A` `DataFrame`在曲棍球列中没有值可以放置，而`sports_champions_B`
    `DataFrame`在棒球列中没有值可以放置：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'By default, pandas concatenates rows on the horizontal axis. Sometimes, we
    want to append the rows on the vertical axis instead. Consider the sports_champions_C
    `DataFrame`, which has the same two index labels as sports_champions_A (2017 and
    2018) but two different columns, Hockey and Basketball:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，pandas在水平轴上连接行。有时，我们希望垂直轴上追加行。考虑`sports_champions_C` `DataFrame`，它具有与`sports_champions_A`相同的两个索引标签（2017年和2018年），但有两列不同的数据，分别是曲棍球和篮球：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'When we concatenate sports_champions_A and sports_champions_C, pandas appends
    the rows of the second `DataFrame` to the end of the first. The process creates
    duplicate 2017 and 2018 index labels:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将`sports_champions_A`和`sports_champions_C`连接起来时，pandas会将第二个`DataFrame`的行追加到第一个`DataFrame`的末尾。这个过程会创建重复的2017年和2018年索引标签：
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This result is not what we want. Rather, we’d like to align the duplicate index
    labels (2017 and 2018) so that the columns have no missing values.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果并不是我们想要的。相反，我们希望对齐重复的索引标签（2017年和2018年），使得列没有缺失值。
- en: 'The `concat` function includes an `axis` parameter. We can pass that parameter
    an argument of either `1` or `"columns"` to concatenate the `DataFrame`s across
    the column axis:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`concat`函数包含一个`axis`参数。我们可以传递该参数一个`1`或`"columns"`的参数，以在列轴上连接`DataFrame`：'
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Much better!
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！
- en: In summary, the `concat` function combines two `DataFrame`s by appending one
    to the end of the other on either the horizontal axis or the vertical axis. I
    like to describe the process as "gluing" two data sets together.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，`concat`函数通过将一个`DataFrame`追加到另一个的末尾，在水平轴或垂直轴上组合两个`DataFrame`。我喜欢将这个过程描述为“将两个数据集粘合在一起”。
- en: 10.4 Left joins
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 左连接
- en: 'Compared with a concatenation, a *join* uses a logical criterion to determine
    which rows or columns to merge between two data sets. A join can target only rows
    with shared values between both data sets, for example. The following sections
    cover three types of joins: left, inner, and outer. Let’s walk through them one
    by one.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 与连接相比，*连接*使用逻辑标准来确定两个数据集之间合并的行或列。例如，连接可以仅针对两个数据集之间具有共享值的行。以下几节将介绍三种类型的连接：左连接、内连接和外连接。让我们逐一了解它们。
- en: A *left join* uses keys from one data set to pull in values from another. It
    is equivalent to a `VLOOKUP` operation in Excel. A left join is optimal when one
    data set is the focal point of the analysis. We pull in the second data set to
    provide supplemental information related to the primary data set. Consider the
    diagram in figure 10.1\. Think of each circle as being a `DataFrame`. The `DataFrame`
    on the left is the focus of the analysis.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*左连接*使用一个数据集的键来从另一个数据集中提取值。它在Excel中的`VLOOKUP`操作中是等效的。当一个数据集是分析的重点时，左连接是最优的。我们引入第二个数据集以提供与主要数据集相关的补充信息。考虑图10.1中的图表。将每个圆圈视为一个`DataFrame`。左边的`DataFrame`是分析的重点。'
- en: '![](../Images/CH10_F01_Paskhaver.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F01_Paskhaver.png)'
- en: Figure 10.1 Left join diagram
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 左连接图
- en: 'Here’s a quick reminder of what our groups data set looks like:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这里快速回顾一下我们的组数据集的样子：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The foreign keys in the category_id column reference the IDs in the categories
    data set:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`category_id`列中的外键引用了`categories`数据集中的ID：'
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let’s execute a left join on groups to add category information for each group.
    We’ll use the `merge` method to merge one `DataFrame` into another. The method’s
    first parameter, `right`, accepts a `DataFrame`. The terminology comes from the
    previous diagram. The right `DataFrame` is the circle on the right, the “second”
    data set. We can pass a string denoting the type of join to the method’s `how`
    parameter; we’ll pass in `"left"`. We also must tell pandas which columns to use
    to match values between the two `DataFrame`s. Let’s add an `on` parameter with
    a value of `"category_id"`. We can use the `on` parameter only when the column
    name is equal between `DataFrame`s. In our case, both the groups and categories
    `DataFrame`s have a category_id column:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在groups上执行左连接，为每个组添加类别信息。我们将使用`merge`方法将一个`DataFrame`合并到另一个中。该方法的第一参数`right`接受一个`DataFrame`。这个术语来自之前的图表。右边的`DataFrame`是右边的圆圈，即“第二个”数据集。我们可以将表示连接类型的字符串传递给方法的`how`参数；我们将传递`"left"`。我们还必须告诉pandas使用哪些列来匹配两个`DataFrame`之间的值。让我们添加一个`on`参数，其值为`"category_id"`。我们只能在两个`DataFrame`的列名相等时使用`on`参数。在我们的情况下，groups和categories
    `DataFrame`s都有category_id列：
- en: '[PRE18]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: There it is! Pandas pulls in the categories table’s columns whenever it finds
    a match for the category_id value in groups. The one exception is the category_id
    column, which is listed only once. Note that when the library does not find a
    category_id in categories, it displays `NaN` values in the category_name column
    from categories. We can see an example on rows 2 and 4 of the previous output.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 就在这里！当Pandas找到与groups中的category_id值匹配时，它会拉入categories表的列。唯一的例外是category_id列，它只列了一次。请注意，当库在categories中找不到category_id时，它会在categories的category_name列中显示`NaN`值。我们可以在上一个输出的第2行和第4行看到一个例子。
- en: 10.5 Inner joins
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 内连接
- en: An *inner join* targets values that exist across two `DataFrame`s. Consider
    figure 10.2; an inner join targets the colored overlap in the middle of the circles.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 内连接的目标是存在于两个`DataFrame`中的值。考虑图10.2；内连接的目标是两个圆圈中间的彩色重叠部分。
- en: '![](../Images/CH10_F02_Paskhaver.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F02_Paskhaver.png)'
- en: Figure 10.2 Inner join diagram
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 内连接图
- en: In an inner join, pandas excludes values that exist only in the first `DataFrame`
    and only in the second `DataFrame`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在内连接中，pandas排除了只存在于第一个`DataFrame`和只存在于第二个`DataFrame`中的值。
- en: 'Here’s a reminder of what the groups and categories data sets look like:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个提醒，关于groups和categories数据集看起来是什么样子：
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Let’s identify the categories that exist in both data sets. From a technical
    perspective, we once again want to target the rows from the two `DataFrame`s with
    equal values in the category_id columns. In this situation, it doesn’t matter
    whether we invoke the `merge` method on group or categories. An inner join identifies
    common elements in both data sets; the results will be the same regardless. For
    the next example, let’s call the `merge` method on groups:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们确定存在于两个数据集中的类别。从技术角度来看，我们再次想要针对两个`DataFrame`中category_id列值相等的行。在这种情况下，我们是否在group或categories上调用`merge`方法无关紧要。内连接确定两个数据集中的共同元素；结果将是一样的。对于下一个示例，让我们在groups上调用`merge`方法：
- en: '[PRE20]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The merged `DataFrame` includes all columns from both the groups and categories
    `DataFrame`s. The values in the category_id column appear in both groups and categories.
    The category_id column is listed only once. We don’t need a duplicate column because
    the values in category_id are the same for groups and categories in an inner join.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 合并的`DataFrame`包括groups和categories `DataFrame`s的所有列。category_id列的值在groups和categories中都出现。category_id列只列了一次。我们不需要重复的列，因为在内连接中，category_id的值对于groups和categories是相同的。
- en: 'Let’s add some context to what pandas did. The first four rows in the merged
    `DataFrame` have a category_id of 14\. We can filter for that ID in the groups
    and categories `DataFrame`s:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们添加一些上下文来解释pandas做了什么。合并的`DataFrame`的前四行有一个category_id值为14。我们可以在groups和categories
    `DataFrame`s中过滤出这个ID：
- en: '[PRE21]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The merged `DataFrame` creates one row for each group_id match across the two
    `DataFrame`s. There are 870 rows in groups and one row in categories with a group_id
    of 14\. Pandas pairs each of the 870 rows in groups with the single row in categories
    and creates a total of 870 rows in the merged `DataFrame`. Because an inner join
    creates a new row for each value match, the merged `DataFrame` can be significantly
    larger than the original ones. If there were three categories with an ID of 14,
    for example, pandas would create 2610 rows (870 x 3).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 合并后的`DataFrame`为两个`DataFrame`之间的每个`group_id`匹配创建一行。组中有870行，类别中有1行，`group_id`为14。Pandas将组中的870行与类别中的单行配对，并在合并的`DataFrame`中创建总共870行。因为内连接为每个值匹配创建新行，所以合并的`DataFrame`可以比原始的`DataFrame`大得多。例如，如果有三个ID为14的类别，pandas将创建2610行（870
    x 3）。
- en: 10.6 Outer joins
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.6 外连接
- en: An *outer join* combines all records across two data sets. Exclusivity does
    not matter with an outer join. Figure 10.3 shows the results of an outer join;
    pandas includes all values irrespective of whether they belong in one data set
    or both data sets.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*外连接*将两个数据集中的所有记录组合在一起。在外连接中，唯一性并不重要。图10.3显示了外连接的结果；pandas包括所有值，无论它们是否属于一个数据集或两个数据集。'
- en: '![](../Images/CH10_F03_Paskhaver.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图10.3 外连接图](../Images/CH10_F03_Paskhaver.png)'
- en: Figure 10.3 Outer join diagram
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 外连接图
- en: 'Here’s a reminder of what the groups and cities `DataFrame`s look like:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是关于组和城市`DataFrame`的提醒：
- en: '[PRE22]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let’s merge groups and cities with an outer join. We’ll pull in all cities:
    the ones exclusive to groups, the ones exclusive to cities, and the ones common
    to both.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用外连接合并组和城市。我们将拉入所有城市：仅属于组的城市，仅属于城市的城市，以及两者都有的城市。
- en: 'So far, we’ve used only shared column names to merge data sets. When column
    names differ between data sets, we must pass different parameters to the `merge`
    method. Instead of the `on` parameter, we can use the `merge` method’s `left_on`
    and `right_on` parameters. We pass `left_on` the column name in the left `DataFrame`
    and `right_on` the column name in the right `DataFrame`. Here, we perform an outer
    join to merge city information from cities into the groups `DataFrame`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只使用共享列名来合并数据集。当数据集之间的列名不同时，我们必须向`merge`方法传递不同的参数。而不是使用`on`参数，我们可以使用`merge`方法的`left_on`和`right_on`参数。我们将`left_on`传递给左边的`DataFrame`中的列名，将`right_on`传递给右边的`DataFrame`中的列名。在这里，我们执行外连接以将城市信息合并到组`DataFrame`中：
- en: '[PRE23]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The final `DataFrame` has all city IDs from both data sets. If pandas finds
    a values match between the city_id and id columns, it merges the columns from
    the two `DataFrame`s in a single row. We can see some examples in the first five
    rows. The city_id column stores the common id.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的`DataFrame`包含来自两个数据集的所有城市ID。如果pandas在`city_id`和`id`列之间找到值匹配，它将在单行中合并两个`DataFrame`的列。我们可以在前五行中看到一些示例。`city_id`列存储共同的id。
- en: If one `DataFrame` has a value that the other does not, pandas places a `NaN`
    value in the city_id column. We can see some examples at the end of the data set.
    This placement will happen irrespective of whether groups or cities has the exclusive
    value.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个`DataFrame`有一个另一个`DataFrame`没有的值，pandas将在`city_id`列中放置一个`NaN`值。我们可以在数据集的末尾看到一些示例。这种放置将不受组或城市是否有唯一值的影响。
- en: 'We can pass `True` to the `merge` method’s `indicator` parameter to identify
    which `DataFrame` a value belongs to. The merged `DataFrame` will include a _merge
    column that stores the values `"both"`, `"left_only"`, and `"right_only"`:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将`True`传递给`merge`方法的`indicator`参数，以识别一个值属于哪个`DataFrame`。合并后的`DataFrame`将包含一个`_merge`列，该列存储值`"both"`、`"left_only"`和`"right_only"`：
- en: '[PRE24]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can use the _merge column to filter rows that belong to either of the `DataFrame`s.
    The next example extracts rows with a value of `"right_only"` in the _merge column
    or, equivalently, the city IDs that are present only in cities, the right `DataFrame`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`_merge`列来过滤属于任一`DataFrame`的行。下一个示例提取`_merge`列中值为`"right_only"`的行，或者等价地，仅存在于城市中的城市ID，即右边的`DataFrame`：
- en: '[PRE25]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: With a few lines of code, we can easily filter out exclusive values in each
    data set.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 通过几行代码，我们可以轻松过滤出每个数据集中的唯一值。
- en: 10.7 Merging on index labels
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.7 在索引标签上合并
- en: 'Imagine that a `DataFrame` we’d like to join stores its primary keys in its
    index. Let’s simulate this scenario. We can invoke the `set_index` method on cities
    to set its id column as its `DataFrame` index:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们想要连接的`DataFrame`将其主键存储在其索引中。让我们模拟这种情况。我们可以在城市上调用`set_index`方法，将其id列设置为`DataFrame`的索引：
- en: '[PRE26]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let’s use a left join to merge cities into groups again. Here’s a quick reminder
    of what `groups` looks like:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用左连接将城市合并到组中。这里是一个关于 `groups` 的快速提醒：
- en: '[PRE27]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now we want to compare the values in the city_id column in groups with the
    index labels of cities. When we invoke the `merge` method, we’ll pass the `how`
    parameter an argument of `"left"` for a left join. We’ll use the `left_on` parameter
    to tell pandas to look for matches in the city_id column in groups, the left `DataFrame`.
    To look for matches in the index of the right `DataFrame`, we can provide a different
    parameter, `right_index`, and set it to `True`. The argument tells pandas to look
    for city_id matches in the right `DataFrame`’s index:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想比较组中 city_id 列的值与城市索引标签。当我们调用 `merge` 方法时，我们将 `how` 参数的参数设置为 `"left"` 以进行左连接。我们将使用
    `left_on` 参数告诉 pandas 在组中的 city_id 列中查找匹配项，在左 `DataFrame` 中。为了在右 `DataFrame` 的索引中查找匹配项，我们可以提供一个不同的参数，`right_index`，并将其设置为
    `True`。该参数告诉 pandas 在右 `DataFrame` 的索引中查找 city_id 匹配项：
- en: '[PRE28]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The method also supports a complementary `left_index` parameter. Pass that parameter
    an argument of `True` to tell pandas to look for matches in the left `DataFrame`’s
    index. The left `DataFrame` is the one that we invoke the `merge` method on.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法还支持一个互补的 `left_index` 参数。将参数传递一个 `True` 的参数，告诉 pandas 在左 `DataFrame` 的索引中查找匹配项。左
    `DataFrame` 是我们调用 `merge` 方法的那个。
- en: 10.8 Coding challenge
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.8 编程挑战
- en: We’ve reached the end of our exploration; thanks for joining us (pun intended)!
    Let’s practice the concepts introduced in this chapter.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的探索已经结束；感谢您的参与（有意为之！）让我们练习本章介绍的概念。
- en: 'This coding challenge’s tables summarize sales in a fictional restaurant. The
    week_1_sales.csv and week_2_sales.csv files hold listings of weekly transactions.
    Each restaurant order includes the ID of a customer who placed an order and the
    ID of the food item they purchased. Here’s a preview of the first five rows of
    week_1_sales:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这个编程挑战的表格总结了虚构餐厅的销售情况。week_1_sales.csv 和 week_2_sales.csv 文件包含每周交易的列表。每个餐厅订单包括下订单的客户的
    ID 和他们购买的食品项的 ID。以下是 week_1_sales 的前五行预览：
- en: '[PRE29]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The week_2_sales data set has an identical shape. Let’s import the two CSVs
    and assign them to `week1` and `week2` variables:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: week_2_sales 数据集具有相同的形状。让我们导入这两个 CSV 文件，并将它们分配给 `week1` 和 `week2` 变量：
- en: '[PRE30]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The Customer ID columns hold foreign keys that reference values in the ID column
    in customers.csv. Each record in customers.csv includes a customer’s first name,
    last name, gender, company, and occupation. Let’s import that data set with the
    `read_csv` function and set its ID column as the `DataFrame` index with the `index_col`
    parameter:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 客户 ID 列包含外键，它们引用 customers.csv 中的 ID 列的值。customers.csv 中的每条记录都包含一个客户的姓氏、名字、性别、公司和职业。让我们使用
    `read_csv` 函数导入该数据集，并使用 `index_col` 参数将其 ID 列设置为 `DataFrame` 的索引：
- en: '[PRE31]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'There’s another column of foreign keys in the weeks1 and weeks2 `DataFrame`s.
    The Food ID foreign key connects to the ID column in foods.csv. A food item includes
    an ID, a name, and a price. When we import this data set, let’s set its Food ID
    column as the `DataFrame` index:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: weeks1 和 weeks2 `DataFrame`s 中还有另一列外键。食品 ID 外键连接到 foods.csv 中的 ID 列。一个食品项目包括一个
    ID、一个名称和一个价格。当我们导入这个数据集时，让我们将其食品 ID 列设置为 `DataFrame` 的索引：
- en: '[PRE32]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: With the data sets imported, we’re ready to tackle the exercises.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集导入后，我们就可以开始解决练习了。
- en: 10.8.1 Problems
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.8.1 问题
- en: 'Here are the challenges:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是挑战：
- en: Concatenate the two weeks of sales data into one `DataFrame`. Assign the week1
    `DataFrame` a key of `"Week 1"` and the week2 `DataFrame` a key of `"Week 2"`.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将两周的销售数据合并到一个 `DataFrame` 中。将 week1 `DataFrame` 分配一个键 `"Week 1"`，将 week2 `DataFrame`
    分配一个键 `"Week 2"`。
- en: Find the customers who ate at the restaurant both weeks.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出两个星期都在餐厅就餐的客户。
- en: Find the customers who ate at the restaurant both weeks and ordered the same
    item each week.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出两个星期都在餐厅就餐且每周都订购相同食品的客户。
- en: HINT You can join data sets on multiple columns by passing the `on` parameter
    a list of columns.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示：您可以通过传递一个列列表给 `on` 参数来在多个列上连接数据集。
- en: Identify which customers came in only on Week 1 and only on Week 2.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别哪些客户只在第1周和只在第2周来过。
- en: Each row in the week1 DataFrame identifies a customer who purchased a food item.
    For each row, pull in the customer’s information from the customers `DataFrame`.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: week1 `DataFrame` 中的每一行都标识了一个购买食品项目的客户。对于每一行，从 customers `DataFrame` 中提取客户信息。
- en: 10.8.2 Solutions
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.8.2 解决方案
- en: 'Let’s explore the solutions:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索解决方案：
- en: 'Our first challenge is to combine the two weeks of restaurant sales data into
    a single `DataFrame`. The `concat` function at the top level of pandas offers
    a perfect solution. We can pass the two `DataFrame`s in a list to the function’s
    `objs` parameter. To assign a `MultiIndex` level to each `DataFrame` in the result,
    we’ll also provide the `keys` parameter a list with the level labels:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的首要挑战是将两周的餐厅销售数据合并到一个`DataFrame`中。pandas顶级层的`concat`函数提供了一个完美的解决方案。我们可以将两个`DataFrame`作为一个列表传递给函数的`objs`参数。为了将`MultiIndex`级别分配给结果中的每个`DataFrame`，我们还将提供`keys`参数一个包含级别标签的列表：
- en: '[PRE33]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, we want to identify customers who visited the restaurant both weeks.
    From a technical perspective, we need to find the Customer IDs present in both
    the week1 and week2 `DataFrame`s. An inner join is what we’re looking for here.
    Let’s invoke the `merge` method on week1 and pass in week2 as the right `DataFrame`.
    We’ll declare the join type as `"inner"` and tell pandas to look for shared values
    in the Customer ID columns:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们希望识别出在两周内都访问过餐厅的客户。从技术角度来看，我们需要找到存在于week1和week2 `DataFrame`中的客户ID。这里我们需要的是内连接。让我们在week1上调用`merge`方法，并将week2作为右边的`DataFrame`传入。我们将连接类型声明为`"inner"`，并告诉pandas在客户ID列中查找共享值：
- en: '[PRE34]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Remember that the inner join shows all matches of customer IDs across the week1
    and week2 `DataFrames`s. Thus, there are duplicates in the result (customers 155
    and 503). If we wanted to remove duplicates, we could invoke the `drop_duplicates`
    method introduced in chapter 5:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 记住，内连接显示了week1和week2 `DataFrames`中所有客户ID的匹配。因此，结果中有重复（客户155和503）。如果我们想删除重复项，我们可以调用第5章中引入的`drop_duplicates`方法：
- en: '[PRE35]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The third challenge asks to find the customers who visited the restaurant both
    weeks and ordered the same item. Once again, an inner join is the right option
    for finding values present in both the left and right `DataFrame`s. This time
    around, however, we have to pass the `on` parameter a list with two columns. The
    values in both the Customer ID and Food ID columns must match between week1 and
    week2:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三个挑战要求找到在两周内都访问过餐厅并且点了相同菜品的客户。同样，内连接是找到左和右`DataFrame`中存在的值的正确选项。然而，这一次，我们必须将`on`参数传递为一个包含两个列的列表。在week1和week2的客户ID和食品ID列中的值必须匹配：
- en: '[PRE36]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'One solution to identify the customers who came in only one week is to use
    an outer join. We can match records across the two `DataFrame`s by using values
    in the Customer ID column. Let’s pass the `indicator` parameter a value of `True`
    to add a _merge column. Pandas will indicate whether the Customer ID exists in
    only the left table `("left_only"`), only the right table (`"right_only"),` or
    both tables (`"both"`):'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '识别只在一周内来过的客户的一个解决方案是使用外连接。我们可以通过客户ID列中的值在两个`DataFrame`之间匹配记录。让我们将`indicator`参数的值设置为`True`以添加一个_merge列。Pandas将指示客户ID是否仅存在于左表(`"left_only"`)、仅存在于右表(`"right_only"`)，还是两个表都存在(`"both"`):'
- en: '[PRE37]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The final challenge asks to pull customer information into the week1 table.
    A left join is an optimal solution. Invoke the `merge` method on the week1 `DataFrame`,
    passing in the customers `DataFrame` as the right data set. Pass the `how` parameter
    an argument of `"left"`.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一个挑战要求将客户信息拉入week1表中。左连接是一个最优解。在week1 `DataFrame`上调用`merge`方法，传入客户`DataFrame`作为右数据集。将`how`参数的值传递为`"left"`。
- en: 'The tricky part of this challenge is that the week1 `DataFrame` stores the
    customer IDs in its Customer ID column, whereas the customers `DataFrame` stores
    them in its index labels. To solve the problem, we can pass the `left_on` parameter
    the column name from the week1 `DataFrame` and the `right_index` parameter a value
    of `True`:'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个挑战的难点在于，week1 `DataFrame`将其客户ID存储在其客户ID列中，而客户`DataFrame`将其存储在其索引标签中。为了解决这个问题，我们可以将`left_on`参数传递给week1
    `DataFrame`中的列名，并将`right_index`参数的值设置为`True`：
- en: '[PRE38]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Congratulations on completing the coding challenge!
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了编码挑战！
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A *primary key* is a unique identifier for a record in a data set.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*主键*是数据集中记录的唯一标识符。'
- en: A *foreign key* is a reference to a record in another data set.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*外键*是另一个数据集中记录的引用。'
- en: The `concat` function concatenates `DataFrame`s on either the horizontal or
    vertical axis.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`concat`函数在水平或垂直轴上连接`DataFrame`。'
- en: The `merge` method joins two `DataFrame`s based on some logical criterion.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`merge`方法基于某些逻辑标准连接两个`DataFrame`。'
- en: An *inner join* identifies common values between two `DataFrame`s. For any matches,
    pandas pulls all columns from the right `DataFrame` into the left `DataFrame`.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内连接（*inner join*）识别两个 `DataFrame` 之间的共同值。对于任何匹配项，pandas 会将右侧 `DataFrame` 的所有列拉入左侧
    `DataFrame`。
- en: An *outer join* merges two `DataFrame`s. Pandas includes values whether they
    are exclusive to one data set or shared.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外连接（*outer join*）合并两个 `DataFrame`。Pandas 包含那些仅属于一个数据集或共享的值。
- en: A *left join* pulls in columns from the right `DataFrame` when their values
    exist in the left `DataFrame`. The operation is equivalent to a `VLOOKUP` in Excel.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左连接（*left join*）在右侧 `DataFrame` 的值存在于左侧 `DataFrame` 时，会拉入列。这个操作在 Excel 中相当于
    `VLOOKUP`。
- en: A left join is ideal when the second `DataFrame` contains supplemental information
    that we’d like to attach to the primary `DataFrame`.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当第二个 `DataFrame` 包含我们希望附加到主 `DataFrame` 的补充信息时，左连接是理想的。
