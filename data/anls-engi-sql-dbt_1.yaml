- en: Chapter 1\. Analytics Engineering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章．分析工程
- en: The historical development of analytics includes significant milestones and
    technologies that have shaped the field into what it is today. It began with the
    advent of data warehousing in the 1980s, which created the foundational framework
    for organizing and analyzing business data. Bill Inmon, a computer scientist who
    continued to publish throughout the 1980s and 1990s, is widely regarded as providing
    the first solid theoretical foundation for data warehousing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分析的发展历程包括许多重要的里程碑和技术，这些里程碑和技术塑造了今天的分析领域。它始于1980年代数据仓库的出现，为组织和分析商业数据建立了基础框架。计算机科学家比尔·因蒙（Bill
    Inmon）在1980和1990年代持续发表作品，被广泛认为是为数据仓库提供了第一个坚实的理论基础。
- en: A subsequent wave of development occurred when Ralph Kimball, another leading
    contributor to data warehousing and business intelligence (BI), published his
    influential work, *The Data Warehouse Toolkit,* in 1996\. Kimball’s work laid
    the foundation for dimensional modeling, marking another crucial milestone in
    the evolution of analytics. Together, the contributions of Inmon and Kimball,
    spanning the late 20th century, played pivotal roles in shaping the landscape
    of data warehousing and analytics.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随后的发   在 Ralph Kimball，另一位数据仓库和商业智能（BI）领域的主要贡献者，于1996年发表了他的影响力巨著《数据仓库工具箱》之后，数据仓库和商业智能的发展迎来了又一波浪潮。Kimball的工作为维度建模奠定了基础，标志着分析发展中的另一个关键里程碑。Inmon
    和 Kimball 的贡献，跨越20世纪末，发挥了在塑造数据仓库和分析领域的关键作用。
- en: In the early 2000s, the emergence of tech giants like Google and Amazon created
    the need for more advanced solutions for processing massive amounts of data, leading
    to the release of the Google File System and Apache Hadoop. This marked the era
    of Big Data Engineering, in which professionals used the Hadoop framework to process
    large amounts of data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2000 年初，谷歌和亚马逊等科技巨头的崛起，催生了对更先进的数据处理解决方案的需求，促成了 Google 文件系统和 Apache Hadoop
    的发布。这标志着大数据工程时代的到来，专业人士利用 Hadoop 框架处理海量数据。
- en: The rise of public cloud providers like Amazon Web Services (AWS) revolutionized
    the way software and data applications were developed and deployed. One of the
    pioneering offerings from AWS was Amazon Redshift, introduced in 2012\. It represented
    an interesting blend of online analytical processing (OLAP) and traditional database
    technologies. In its early days, Redshift required database administrators to
    manage tasks like vacuuming and scaling to maintain optimal performance.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 像亚马逊网络服务（AWS）这样的公共云提供商的崛起，彻底改变了软件和数据应用的开发与部署方式。AWS 的一个开创性产品是亚马逊 Redshift，于2012年推出。它代表了一种在线分析处理（OLAP）与传统数据库技术的有趣结合。在
    Redshift 的早期阶段，数据库管理员需要管理如清理和扩展等任务，以维持最佳性能。
- en: Over time, cloud native technologies have continued to evolve, and Redshift
    itself has undergone significant enhancements. While retaining its core strengths,
    newer versions of Redshift, along with cloud native platforms like Google BigQuery
    and Snowflake, have streamlined many of these administrative tasks, offering advanced
    data processing capabilities to enterprises of all sizes. This evolution highlights
    the ongoing innovation within the cloud data processing ecosystem.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，云原生技术不断发展，Redshift 本身也经历了重大提升。在保留其核心优势的同时，Redshift 的新版本，以及 Google BigQuery
    和 Snowflake 等云原生平台，简化了许多管理任务，向各类企业提供了先进的数据处理能力。这一发展突显了云数据处理生态系统内持续的创新。
- en: The modern data stack, consisting of tools like Apache Airflow, data build tool
    (dbt), and Looker, further transformed data workflows. With these advances, the
    term “Big Data engineer” became obsolete, making way for a data engineer’s broader
    and more inclusive role. This shift was recognized in the influential articles
    of Maxime Beauchemin—creator of Apache Superset and Airflow and one of the first
    data engineers at Facebook and Airbnb—particularly in his article [“The Rise of
    the Data Engineer”](https://oreil.ly/Sc-94), which highlighted the growing importance
    of data engineering in the industry. All of these rapid developments in the data
    field have led to significant changes in the role of data professionals. With
    the advent of data tools, simple tasks are becoming strategic tasks.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 现代数据堆栈，包括诸如Apache Airflow、数据构建工具（dbt）和Looker等工具，进一步改变了数据工作流。随着这些进步，"大数据工程师"这个术语已经过时，为数据工程师更广泛和更包容的角色让路。这种转变得到了Maxime
    Beauchemin的影响深远的文章的认可——他是Apache Superset和Airflow的创造者之一，也是Facebook和Airbnb的首批数据工程师之一——尤其是他的文章["数据工程师的崛起"](https://oreil.ly/Sc-94)，强调了数据工程在行业中日益重要的地位。所有这些数据领域的快速发展都导致了数据专业人员角色的重大变化。随着数据工具的出现，简单任务正变成战略任务。
- en: Today’s data engineers have a multifaceted role that encompasses data modeling,
    quality assurance, security, data management, architectural design, and orchestration.
    They are increasingly adopting software engineering practices and concepts, such
    as functional data engineering and declarative programming, to enhance their workflows.
    While Python and structured query language (SQL) stand out as indispensable languages
    for data engineers, it’s important to note that the choice of programming languages
    can vary widely in this field. Engineers may leverage other languages such as
    Java (commonly used for managing Apache Spark and Beam), Scala (also prevalent
    in the Spark and Beam ecosystem), Go, and more, depending on the specific needs
    and preferences of their projects. The combination of languages like Java and
    SQL is also common among data engineers at large organizations.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如今的数据工程师拥有多方面的角色，包括数据建模、质量保证、安全性、数据管理、架构设计和编排。他们越来越多地采纳软件工程的实践和概念，如功能化数据工程和声明式编程，以增强他们的工作流程。虽然Python和结构化查询语言（SQL）在数据工程师中表现突出，但值得注意的是，程序设计语言的选择在这个领域可以因项目的具体需求和偏好而广泛变化。工程师们可能利用其他语言，如Java（通常用于管理Apache
    Spark和Beam）、Scala（在Spark和Beam生态系统中也很普遍）、Go等。在大型组织中，Java和SQL等语言的组合也是数据工程师中常见的。
- en: Organizations are increasingly moving toward decentralized data teams, self-service
    platforms, and alternative data storage options. As data engineers are forced
    to adapt to all these market changes, we often see some taking on a more technical
    role, focusing on platform enablement. Other data engineers work closer to the
    business, designing, implementing, and maintaining systems that turn raw data
    into high-value information as they adapt to this accelerated industry that is
    bringing new tools to market every day and spawning the fantastic world of analytics
    engineering.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 组织日益向分散的数据团队、自助服务平台和替代数据存储选项转移。随着数据工程师不得不适应所有这些市场变化，我们经常看到一些人承担更加技术化的角色，专注于平台的启用。其他数据工程师更接近业务，设计、实施和维护将原始数据转化为高价值信息的系统，因此适应这个快速发展的行业，每天都为市场带来新工具，促使了分析工程的奇妙世界的产生。
- en: In this chapter, we provide an introduction to the field of analytics engineering
    and its role in the data-driven decision-making process. We discuss the importance
    of analytics engineering in today’s data-driven world and the primary roles of
    an analytics engineer. In addition, we will explore how the analytics engineering
    lifecycle is used to manage the analytics process and how it ensures the quality
    and accuracy of the data and insights generated. We will also address the current
    trends and technologies shaping the field of analytics engineering, from history
    to the present, touching on emerging concepts like data mesh, and discussing the
    fundamental choices between extract, load, and transform (ELT) and extract, transform,
    and load (ETL) strategies as well as the many data modeling techniques being adopted
    around the world.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了分析工程领域及其在数据驱动决策过程中的角色。我们讨论了分析工程在今天数据驱动世界中的重要性，以及分析工程师的主要角色。此外，我们将探讨分析工程生命周期如何用于管理分析过程，并如何确保生成的数据和见解的质量和准确性。我们还将讨论正在塑造分析工程领域的当前趋势和技术，从历史到现在，涉及到像数据网格这样的新兴概念，并讨论全球采用的诸多数据建模技术之间的基本选择，同时也触及了抽取、加载和转换（ELT）与抽取、转换和加载（ETL）策略。
- en: Databases and Their Impact on Analytics Engineering
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据库及其对分析工程的影响
- en: For a long time now, data has increasingly become the focus of interest for
    companies that want to stay one step ahead of the competition, improve their internal
    processes, or merely understand the behavior of their customers. With new tools,
    new ways of working, and new areas of knowledge such as data science and BI, it’s
    becoming increasingly difficult to fully survey and understand the data landscape
    these days.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 长期以来，数据越来越成为公司关注的焦点，这些公司希望在竞争中保持领先、改善内部流程，或仅仅理解其客户的行为。随着新工具、新工作方式和数据科学、商业智能等新知识领域的出现，如今完全调查和理解数据景观变得越来越困难。
- en: The natural progress of technology has caused an oversupply of data analysis,
    visualization, and storage tools, each offering unique features and capabilities.
    Nevertheless, an accelerated deployment of those tools has resulted in a fragmented
    landscape, requiring individuals and organizations to remain up-to-date with the
    most recent technological developments while at the same time having to make prudent
    choices on how to use them. Sometimes this abundance creates confusion and requires
    a continuous cycle of learning and adaptation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 技术的自然进步导致了数据分析、可视化和存储工具的过剩供应，每种工具都提供独特的功能和能力。然而，这些工具的加速部署导致了碎片化的景观，个人和组织需要保持与最新技术发展的同步，同时在如何使用它们上做出明智选择。有时这种丰富会造成困惑，并需要持续的学习和适应。
- en: The evolution of work practices is accompanied by a diversification of tools.
    Dynamic and Agile methodologies have replaced traditional approaches to data management
    and analysis. Iterative practices and cross-functional collaboration introduce
    flexibility and speed to data projects, but they also pose a challenge in harmonizing
    workflows across diverse teams and roles. Effective communication and alignment
    are crucial as diverse facets of the data process converge, creating a need for
    a comprehensive understanding of these novel work practices.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 工作实践的演变伴随着工具的多样化。动态和敏捷的方法论取代了数据管理和分析的传统方法。迭代实践和跨功能协作为数据项目引入了灵活性和速度，但同时也在协调各种团队和角色之间的工作流程上带来挑战。有效的沟通和对齐至关重要，因为数据流程的各个方面融合在一起，这要求对这些新型工作实践有全面的理解。
- en: Specialized areas such as data science and BI have increased the complexity
    of the data field as well. Data scientists apply advanced statistical and machine
    learning techniques to detect complex patterns, whereas BI experts extract valuable
    information from raw data to produce practical insights. Such specialized areas
    introduce refined techniques that require regular skill development and learning.
    A successful adoption of these practices necessitates a dedicated commitment to
    education and a flexible approach to skill acquisition.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学和商业智能（BI）等专业领域也增加了数据领域的复杂性。数据科学家应用先进的统计和机器学习技术来检测复杂模式，而商业智能专家则从原始数据中提取有价值的信息，产生实用的见解。这些专业领域引入了精细的技术，需要定期的技能发展和学习。成功采用这些实践需要致力于教育，并灵活掌握技能获取的方法。
- en: As data spreads across the digital domain, it carries with it unforeseen amounts,
    varieties, and speeds. The flood of data, along with the complex features of present-day
    data sources, such as Internet of things (IoT) gadgets and unorganized text, makes
    data management even more demanding. The details of incorporating, converting,
    and assessing data precision become more apparent, emphasizing the need for strong
    methods that guarantee reliable and precise insights.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据在数字领域的传播，它带来了意想不到的数量、种类和速度。数据的涌入，以及现代数据源（如物联网设备和无组织文本）的复杂特性，使得数据管理变得更加严峻。将数据整合、转换和评估数据精度的细节变得更加明显，强调了需要确保可靠和精确洞见的强大方法。
- en: The multifaceted nature of the data world compounds its complexity. As an outcome
    of converging skills from various domains, including computer science, statistics,
    and field-specific proficiency, a cooperative and communicative strategy is necessary.
    This multidisciplinary interaction accentuates the significance of efficient teamwork
    and knowledge sharing.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据世界的多面性增加了其复杂性。作为各个领域技能汇聚的结果，包括计算机科学、统计学和领域特定的熟练程度，需要一种协作和沟通的策略。这种跨学科的互动突显了有效团队合作和知识分享的重要性。
- en: But that has not always been the case. For decades, spreadsheets were the standard
    technology for storing, managing, and analyzing data at all levels, both for business
    operational management and for analytics to understand it. However, as businesses
    have become more complex, so has the need for data-related decision making. And
    the first of these came in the form of a revolution called databases. *Databases*
    can be defined as an organized collection of structured information or data, usually
    stored electronically in a computer system. This data can be in the form of text,
    numbers, images, or other types of digital information. Data is stored in a way
    that facilitates access and retrieval using a set of predefined rules and structures
    called a *schema*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但情况并非始终如此。几十年来，电子表格一直是存储、管理和分析各级别数据的标准技术，无论是用于业务运营管理还是用于分析以理解它。然而，随着企业变得更加复杂，对数据相关决策的需求也在增加。其中第一个改变的形式是被称为数据库的革命。*数据库*可以定义为有组织的、结构化信息或数据的集合，通常以电子方式存储在计算机系统中。这些数据可以是文本、数字、图像或其他类型的数字信息。数据以一种便于访问和检索的方式存储，使用一组预定义的规则和结构，称为*模式*。
- en: Databases are an essential part of analytics because they provide a way to efficiently
    store, organize, and retrieve large amounts of data, allowing analysts to easily
    access the data they need to perform complex analyses to gain insights that would
    otherwise be difficult or impossible to obtain. In addition, databases can be
    configured to ensure data integrity, which guarantees that the data being analyzed
    is accurate and consistent and thus makes the analysis more reliable and trustworthy.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库在分析中是不可或缺的，因为它们提供了一种有效存储、组织和检索大量数据的方式，允许分析人员轻松访问他们需要进行复杂分析所需的数据，以获得其他情况下难以获得的洞见。此外，可以配置数据库以确保数据完整性，这保证了正在分析的数据准确和一致，从而使分析更可靠和值得信赖。
- en: One of the most common ways to use databases for analytics is the data warehousing
    technique, that is, to construct and use a data warehouse. A *data warehouse*
    is a large, centralized data store designed to simplify data use. The data in
    a data warehouse is typically extracted from a variety of sources, such as transactional
    systems, external data feeds, and other databases. The data is then cleansed,
    transformed, and integrated into a single, consistent data model that typically
    follows a dimensional modeling technique such as the star schema or Data Vault.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析中使用数据库的最常见方法之一是数据仓库技术，即构建和使用数据仓库。*数据仓库*是一个大型的、集中式的数据存储，旨在简化数据使用。数据仓库中的数据通常来自多种来源，例如事务系统、外部数据源和其他数据库。然后对数据进行清洗、转换，并集成到一个统一的数据模型中，通常遵循星型模式或数据仓库等维度建模技术。
- en: Another important use of databases in analytics is the process of data mining.
    *Data mining* uses statistical and machine learning techniques to uncover patterns
    and relationships in large datasets. In this way, trends can be identified, future
    behavior can be predicted, and other types of predictions can be made.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库在分析中的另一个重要用途是数据挖掘过程。*数据挖掘*使用统计和机器学习技术来发现大型数据集中的模式和关系。通过这种方式，可以识别趋势、预测未来行为以及进行其他类型的预测。
- en: 'Database technologies and data scientists have thus played a crucial role in
    the emergence of data science by providing a way to efficiently store, organize,
    and retrieve large amounts of data, enabling data scientists to work with large
    datasets and focus on what matters: gaining knowledge from data.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库技术和数据科学家在数据科学的兴起中发挥了关键作用，通过提供一种有效存储、组织和检索大量数据的方式，使数据科学家能够处理大数据集并专注于重要的事务：从数据中获取知识。
- en: The use of SQL and other programming languages, such as Python or Scala, that
    allow interaction with databases has enabled data scientists to perform complex
    data queries and manipulations. Also, the use of data visualization tools such
    as Tableau and Microsoft Power BI, which easily integrate with database engines,
    has made it easier for data scientists to present their findings in a clear and
    intuitive way.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SQL和其他编程语言（如Python或Scala），可以与数据库进行交互，使数据科学家能够执行复杂的数据查询和操作。此外，数据可视化工具如Tableau和Microsoft
    Power BI与数据库引擎轻松集成，使数据科学家能够以清晰直观的方式呈现其发现。
- en: With the advent of Big Data and the growing demand to store and process vast
    datasets, various database technologies have emerged to meet diverse needs. For
    instance, data analysts often rely on databases for a wide range of applications,
    including data warehousing, data mining, and integration with BI tools like Tableau.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大数据的出现和存储及处理大规模数据集的需求增长，出现了各种数据库技术以满足不同的需求。例如，数据分析师经常依赖数据库进行广泛的应用，包括数据仓库、数据挖掘以及与Tableau等BI工具的集成。
- en: However, it’s important to delve deeper into these use cases to understand the
    need for analytics engineering. When connecting BI tools directly to operational
    databases (online transaction processing [OLTP] replicas), performance and scalability
    can be limited. This approach may work well for smaller datasets and simple queries,
    but as data volumes grow and the complexity of analytics increases, it can lead
    to performance bottlenecks and suboptimal query response times.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，深入探讨这些用例以理解分析工程的必要性至关重要。当将BI工具直接连接到运营数据库（在线事务处理[OLTP]副本）时，性能和可伸缩性可能受到限制。这种方法对于较小的数据集和简单的查询可能效果良好，但随着数据量的增长和分析复杂性的增加，可能会导致性能瓶颈和子优化的查询响应时间。
- en: This is where analytics engineering comes into play. Analytics engineers are
    experts in optimizing data workflows, transforming and aggregating data to ensure
    it’s in the right format for analytical tasks. They design and maintain data pipelines
    that ETL data from various sources into optimized data warehouses or data lakes.
    By doing so, they help organizations overcome the limitations of direct OLTP connections,
    enabling faster and more efficient data analysis with tools like Tableau. In essence,
    analytics engineering bridges the gap between raw data and actionable insights,
    ensuring that data analysts and scientists can work with large, complex datasets
    effectively.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是分析工程的发挥作用之处。分析工程师是优化数据工作流程、转换和聚合数据的专家，确保数据以适合分析任务的正确格式存在。他们设计和维护数据管道，从各种来源ETL数据到优化的数据仓库或数据湖中。通过这样做，他们帮助组织克服直接OLTP连接的限制，利用像Tableau这样的工具进行更快速、更高效的数据分析。本质上，分析工程弥合了原始数据与可操作洞见之间的差距，确保数据分析师和科学家能够有效地处理大规模、复杂的数据集。
- en: Cloud Computing and Its Impact on Analytics Engineering
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云计算及其对分析工程的影响
- en: In recent decades, the world has faced a series of complicated challenges with
    significant technical implications. Economic downturns have driven innovations
    in financial technologies and risk management systems. Geopolitical tensions have
    required advances in cybersecurity to protect critical infrastructure and sensitive
    data. Global health crises have underscored the importance of advanced data analytics
    and predictive modeling for disease surveillance and management. In addition,
    the urgent need to combat climate change has driven the development of cutting-edge
    renewable energy technologies and sustainable engineering solutions to meet climate
    goals.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几十年中，世界面临了一系列具有重大技术影响的复杂挑战。经济衰退推动了金融技术和风险管理系统的创新。地缘政治紧张局势要求在保护关键基础设施和敏感数据方面进行网络安全的进步。全球健康危机凸显了先进数据分析和预测建模在疾病监测和管理中的重要性。此外，迫切需要应对气候变化推动了先进的可再生能源技术和可持续工程解决方案的发展，以实现气候目标。
- en: Amid these challenges, the pursuit of profit and growth remains a key driver
    for businesses worldwide. However, the value of human labor time has taken on
    a new dimension, leading to significant changes in the way businesses operate
    and how cloud computing accommodates them. This change is reflected in the increasing
    adoption of managed and serverless offerings that reduce reliance on full-time
    support staff such as database administrators.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在面对这些挑战时，追求利润和增长仍然是全球企业的关键驱动力。然而，人力劳动时间的价值已经具备了新的维度，这导致企业运营方式和云计算如何容纳它们发生了显著变化。这种变化反映在越来越多地采用减少对全职支持人员（如数据库管理员）依赖的托管和无服务器产品上。
- en: As companies adapt to this changing landscape, innovation, differentiation,
    and sustainability of business models and strategies have become essential considerations
    for companies seeking to succeed in a rapidly changing world. The information
    technology and systems industry found in this context a good opportunity to grow
    its capabilities in helping organizations overcome this world of uncertainty and
    pressure. The rationalization of operating models has become urgent, requiring
    a re-evaluation of data centers and pricing structures. In addition, product and
    service offerings must focus primarily on ease of use, lower latency, improved
    security, a broader range of real-time tools, more integration, more intelligence,
    less code, and a faster time to market.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 随着公司适应这一变化的格局，创新、差异化和商业模型与战略的可持续性已成为寻求在快速变化的世界中成功的公司的重要考量。在这种情况下，信息技术和系统行业发现了在帮助组织克服这个充满不确定性和压力的世界中增强其能力的好机会。操作模型的合理化变得迫在眉睫，需要重新评估数据中心和定价结构。此外，产品和服务的提供必须主要侧重于易用性、低延迟、提高安全性、更广泛的实时工具、更多的集成、更智能化、更少的代码以及更快的上市时间。
- en: Organizations have recognized the importance of investing in innovative tools,
    driving digital transformation, and adopting a data-centric approach to decision
    making to achieve greater agility and competitive advantage. To achieve these
    goals, many are focusing on leveraging well-curated data from internal and external
    sources. This carefully structured data can provide valuable insights into business
    performance.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 组织已经意识到投资于创新工具、推动数字转型以及采用以数据为中心的决策方法的重要性，以实现更大的灵活性和竞争优势。为实现这些目标，许多公司正在专注于利用来自内部和外部来源的精心策划的数据。这些精心构建的数据可以为业务绩效提供宝贵的见解。
- en: In the industry, the practice of creating, visualizing, and analyzing interconnected
    business data in an accessible format is commonly referred to as *data analytics*.
    Historically, it has also been known as *business intelligence*, and the two terms
    are closely related. While BI is a subset of analytics and focuses on business-oriented
    decision making, data analytics encompasses a broader spectrum that includes product
    analytics, operational analytics, and several other specialized areas. Both BI
    and data analytics play pivotal roles in helping organizations gain a competitive
    edge through data-driven insights.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在行业中，以可访问的格式创建、可视化和分析互联的业务数据的做法通常被称为*数据分析*。从历史上看，它也被称为*商业智能*，这两个术语密切相关。虽然商业智能是分析的一个子集，专注于面向业务的决策，但数据分析涵盖了更广泛的范围，包括产品分析、运营分析和其他几个专业领域。商业智能和数据分析在通过数据驱动的见解帮助组织获得竞争优势方面都发挥着关键作用。
- en: Although data analytics offers numerous benefits for improving and reshaping
    business strategies and monitoring performance, it requires significant financial
    investment in servers, software licenses, and specialized staff such as data engineers,
    data scientists, and data visualization specialists. In times of economic crisis,
    the high up-front and operational costs associated with IT hardware, software,
    and specialists can be perceived as impractical and unattractive.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据分析为改进和重塑业务战略、监控绩效提供了诸多好处，但其需要在服务器、软件许可证以及数据工程师、数据科学家和数据可视化专家等专业人员方面进行重大的财务投入。在经济危机期间，与IT硬件、软件和专业人员相关的高前期和运营成本被认为是不切实际和不吸引人的。
- en: As a result, on-premises solutions, where the infrastructure for data analytics
    is set up and managed on a company’s own premises, often lose their appeal. This
    is especially true for newcomers to analytics who are unfamiliar with the concept.
    On-premises solutions typically require significant investment in hardware, software,
    and ongoing maintenance. They are also less flexible and scalable compared to
    cloud-based data analytics solutions. This shift in preferences is clearing the
    way for new cloud-based data analytics solutions that meet similar business needs
    as traditional data analytics. However, instead of relying on on-premises servers
    and software, cloud-based solutions leverage cloud computing services to accelerate
    deployment and minimize infrastructure costs.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，设在公司自有场地上并由公司自行管理数据分析基础设施的本地解决方案，对于对此概念不熟悉的分析新手来说，吸引力已大不如前。本地解决方案通常需要大量投资于硬件、软件和持续维护。与基于云的数据分析解决方案相比，它们也缺乏灵活性和可伸缩性。偏好转移促使新的基于云的数据分析解决方案为满足传统数据分析的类似业务需求铺平了道路。然而，与基于本地服务器和软件依赖相比，基于云的解决方案利用云计算服务加速部署并减少基础设施成本。
- en: The increasing adoption of cloud computing in various industries has led software
    vendors such as Microsoft, Google, and Amazon to develop advanced tools for data
    analysis and data warehousing. These tools are designed to operate in the cloud
    computing paradigm and leverage shared network resources to enable greater accessibility
    and streamlined deployment. A vivid example of this trend is Microsoft’s comprehensive
    data analytics platform, Microsoft Fabric.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算在各行各业的日益普及，促使微软、谷歌和亚马逊等软件供应商开发了先进的数据分析和数据仓库工具。这些工具设计为在云计算范式下运行，并利用共享网络资源，以实现更大的可访问性和简化的部署。这一趋势的生动例子是微软的综合数据分析平台，Microsoft
    Fabric。
- en: In parallel, dbt from dbt Labs, which we discuss in more detail later in this
    book, stands out as a versatile hybrid product. dbt, like Hadoop, is an open source
    solution that gives users the flexibility to deploy it according to their specific
    needs, whether in the cloud or on premises. In its cloud version, dbt integrates
    seamlessly with leading cloud platforms, including Microsoft Azure, Google Cloud
    Platform (GCP), and AWS. This open source nature gives organizations the ability
    to customize their deployment to their unique requirements and infrastructure
    preferences.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，dbt Labs 的 dbt 产品，在本书稍后会详细讨论，作为一种多功能混合产品脱颖而出。dbt 与 Hadoop 类似，是一种开源解决方案，使用户能够根据其特定需求进行部署，无论是在云端还是本地。在其云端版本中，dbt
    与包括 Microsoft Azure、Google Cloud Platform (GCP) 和 AWS 在内的主要云平台无缝集成。这种开源性质使得组织能够根据其独特的需求和基础设施偏好定制其部署方案。
- en: While cloud-based data analytics solutions and platforms are a global trend
    and a central concept of the modern data platform, it’s important to recognize
    that cloud computing solutions bring both benefits and risks that shouldn’t be
    overlooked. These risks include potential security issues, the physical location
    of servers, and the costs associated with moving away from a particular provider.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于云的数据分析解决方案和平台是全球趋势和现代数据平台的核心概念，但重要的是要认识到，云计算解决方案带来了既有利也有风险的影响，这些风险不容忽视。这些风险包括潜在的安全问题、服务器的物理位置以及从特定提供商迁移所带来的成本。
- en: Nonetheless, cloud technologies are currently changing the way organizations
    deploy and construct information systems and technology solutions, and data analytics
    is no exception. That’s why it’s essential to recognize that moving to the cloud
    will soon no longer be an option but a necessity. Understanding the benefits of
    analytics solutions in the form of services is important. Otherwise, providing
    timely information to decision-makers with on-premises solutions that lack flexibility
    and scalability could become increasingly challenging if this transition isn’t
    addressed.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，云技术目前正在改变组织部署和构建信息系统和技术解决方案的方式，数据分析也不例外。因此，认识到转向云端不久将不再是一种选择，而是一种必要性，变得至关重要。理解作为服务的分析解决方案的好处至关重要。否则，如果不解决这一过渡问题，提供给决策者的及时信息在缺乏灵活性和可伸缩性的本地解决方案中可能会变得越来越具挑战性。
- en: However, although cloud technologies bring several benefits, such as economies
    of scale and flexibility, they also bring information security issues. The concentration
    of data in cloud infrastructures makes them attractive targets for unauthorized
    attacks. To succeed in the cloud in the data context, organizations must understand
    and mitigate the risks associated with cloud computing. Key risks include data
    privacy, loss of control, incomplete or insecure deletion of data, unauthorized
    internal access, data availability, and complex costing.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管云技术带来了多种好处，如规模经济和灵活性，它们也带来了信息安全问题。数据集中存储在云基础设施中，使其成为未经授权攻击的吸引目标。在云数据环境中成功，组织必须理解并减轻与云计算相关的风险。关键风险包括数据隐私、控制丧失、数据不完整或不安全删除、未经授权的内部访问、数据可用性和复杂的成本计算。
- en: Data privacy is a significant concern because it’s challenging to verify that
    vendors are handling data in compliance with laws and standards, even though public
    audit reports from vendors can help build trust. In nonintegrated scenarios, data
    security risks multiply as data flows among various systems and data centers,
    increasing the risk of interception and synchronization. Another important risk
    is vendor dependency, which occurs when responsibility for data management rests
    solely within one service provider in such a way that it limits the ability to
    migrate to other solutions. This kind of dependency ends up limiting an organization’s
    control over decision making and authority over data. While these are just a few
    known risks, we can already understand that organizations need to get a handle
    on these risks to effectively reap the benefits of cloud-based data analytics
    solutions. This requires careful consideration, adherence to security standards
    and best practices, and ongoing cost control to measure the return on investment.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 数据隐私是一个重大关注点，因为验证供应商是否按照法律和标准处理数据是具有挑战性的，尽管供应商的公共审计报告可以帮助建立信任。在非集成的场景中，数据在各种系统和数据中心之间流动，数据安全风险倍增，增加了截取和同步化的风险。另一个重要的风险是供应商依赖性，这种依赖性发生在数据管理责任完全落在一个服务提供商身上，从而限制了迁移到其他解决方案的能力。这种依赖性最终限制了组织对决策的控制和对数据的授权。虽然这些只是一些已知的风险，但我们已经可以理解，组织需要有效地掌握这些风险，以有效地享受基于云的数据分析解决方案的好处。这需要仔细考虑、遵循安全标准和最佳实践，并持续控制成本以衡量投资回报。
- en: If all risks are correctly addressed and mitigated in a proper data strategy
    that outlines how an organization will manage its information assets, including
    the cloud strategy, technology, processes, people, and rules involved, an organization
    can gain a substantial competitive advantage when compared to one that doesn’t
    have a data strategy. By focusing on cloud computing and leveraging a cloud data
    platform, organizations can transform raw data into meaningful insights, accelerating
    the process of building a solid data foundation. This enables efficient sourcing,
    structuring, and analysis of relevant data, and it even supports the adoption
    of AI technologies while driving value in less time and at a lower cost than traditional
    methods.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所有风险在正确的数据战略中得到有效解决和缓解，这份战略详细描述了组织如何管理其信息资产，包括云战略、技术、流程、人员和相关规则，那么相比没有数据战略的组织，组织可以获得显著的竞争优势。通过专注于云计算并利用云数据平台，组织可以将原始数据转化为有意义的见解，加速建立坚实的数据基础的过程。这使得相关数据的高效采集、结构化和分析成为可能，甚至支持AI技术的采用，同时在比传统方法更短的时间内和更低的成本下创造价值。
- en: Interestingly, the relationship between a cloud data platform, analytics, and
    AI is symbiotic. Implementing a cloud data platform accelerates the adoption of
    an analytics-driven architecture and enables the full operationalization of AI
    initiatives. It empowers organizations to use all relevant data, gain enterprise-wide
    insights, and unlock new business opportunities. By eliminating the need to manage
    multiple tools, organizations can focus on data modernization, accelerate insight
    discovery, and benefit from existing technology partnerships, thereby advancing
    their AI journey.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，云数据平台、分析和AI之间的关系是相互促进的。实施云数据平台加速了分析驱动的架构的采用，并实现了AI计划的全面运作。它赋予组织使用所有相关数据的能力，获得企业范围的见解，并开启新的商业机会。通过消除管理多个工具的需求，组织可以专注于数据现代化，加速洞察的发现，并从现有技术合作中获益，从而推动其AI之旅。
- en: This is why it’s fair to say that cloud computing has been a core component
    of both modern data platforms and the cloud-based analytics and AI platforms that
    continuously grow in volume every day and thus contribute to the disruption of
    this industry.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是为什么说，云计算已经成为现代数据平台以及基于云的分析和人工智能平台的核心组成部分，这些平台每天都在不断增长，从而促成了这个行业的颠覆。
- en: The Data Analytics Lifecycle
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析生命周期
- en: The *data analytics lifecycle* is a series of steps to transform raw data into
    valuable and easily consumable data products. These can range from well-managed
    datasets to dashboards, reports, APIs, or even web applications. In other words,
    it describes how data is created, collected, processed, used, and analyzed to
    achieve a specific product or business goal.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据分析生命周期*是将原始数据转化为有价值且易消化的数据产品的一系列步骤。这些产品可以是良好管理的数据集，仪表盘，报告，API甚至是Web应用程序。换句话说，它描述了如何创建，收集，处理，使用和分析数据，以实现特定的产品或业务目标。'
- en: The increasing complexity in organizational dynamics directly impacts how data
    is handled. Numerous people must use the same data but with different goals. While
    a top executive might need to know just a few top-level key performance indicators
    to track business performance, a middle manager might need a more granular report
    to support daily decisions.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 组织动态的不断复杂化直接影响数据处理方式。许多人必须使用相同的数据，但目标不同。虽然高级主管可能只需了解几个顶层关键绩效指标来跟踪业务绩效，而中级管理人员可能需要更详细的报告来支持日常决策。
- en: This highlights the need for a governed and standardized approach to creating
    and maintaining data products based on the same data foundation. Given the many
    decisions an organization must make regarding its data governance, technologies,
    and management processes, following a structured approach is fundamental to documenting
    and continuously updating an organization’s data strategy.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这突显了基于相同数据基础创建和维护数据产品时需要一种受管制和标准化方法的必要性。鉴于组织必须在其数据治理，技术和管理流程方面做出许多决策，遵循一种结构化方法对于记录和持续更新组织的数据战略至关重要。
- en: The data analytics lifecycle is, therefore, an essential framework for understanding
    and mapping the phases and processes involved in creating and maintaining an analytics
    solution ([Figure 1-1](#analytics_lifecycle)). It is an essential concept in data
    science and analytics and provides a structured approach to managing the various
    tasks and activities required to create an effective analytics solution.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据分析生命周期是理解和映射创建和维护分析解决方案涉及的阶段和过程的重要框架（[图1-1](#analytics_lifecycle)）。它是数据科学和分析的重要概念，并提供了一种结构化方法来管理创建有效分析解决方案所需的各种任务和活动。
- en: '![diagrama_analytics_life](assets/aesd_0101.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![diagrama_analytics_life](assets/aesd_0101.png)'
- en: Figure 1-1\. Data analytics lifecycle
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 数据分析生命周期
- en: 'The data analytics lifecycle typically includes the following stages:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析生命周期通常包括以下阶段：
- en: Problem definition
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 问题定义
- en: The first phase of the analytics cycle is about understanding the problem that
    needs to be solved. This includes identifying the business objectives, the available
    data, and the resources needed to solve the problem.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 分析周期的第一阶段涉及理解需要解决的问题。这包括识别业务目标，可用数据以及解决问题所需的资源。
- en: Data modeling
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 数据建模
- en: After the business requirements are identified, and an assessment of data sources
    is completed, you can begin modeling your data according to the modeling technique
    that best meets your needs. You can choose a diamond strategy, a star schema,
    a Data Vault, or even a fully denormalized technique. All these concepts will
    be discussed in [Chapter 2](ch02.html#chapter_id_02).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定业务需求并完成数据源评估后，您可以根据最符合您需求的建模技术开始对数据进行建模。您可以选择菱形策略，星型模式，数据仓库或完全非规范化技术。所有这些概念将在[第2章](ch02.html#chapter_id_02)中讨论。
- en: Data ingestion and transformation
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 数据摄入和转换
- en: The next phase is to ingest and prepare the data that’s coming from the source
    systems to match the models created. Depending on the overall information architecture,
    you can opt for a schema-on-write strategy, where you put more effort into transforming
    the raw data directly into your models, or a schema-on-read strategy, where you
    ingest and store the data with minimal transformations and move heavy transformations
    to the downstream layers of your data platform.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 下一阶段是摄取和准备来自源系统的数据，以匹配创建的模型。根据整体信息架构，您可以选择写入模式，其中您将更多的精力放在将原始数据直接转换为您的模型中，或者读取模式，在这种模式下，您摄取和存储数据的时候进行最小的转换，并将大量转换移到数据平台的下游层面。
- en: Data storage and structuring
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据存储和结构化
- en: Once the data pipelines are designed and potentially implemented, you need to
    decide on the file formats to use—simple Apache Parquet or more advanced formats
    like Delta Lake or Apache Iceberg—as well as the partitioning strategies and storage
    components to use—a cloud-based object store like Amazon Simple Storage Service
    (S3) or a more data warehouse–like platform like Redshift, BigQuery, or Snowflake.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设计并可能实施数据管道，您需要决定使用的文件格式——简单的Apache Parquet或更高级的格式如Delta Lake或Apache Iceberg——以及分区策略和存储组件——基于云的对象存储如Amazon
    Simple Storage Service (S3)，或者像Redshift、BigQuery或Snowflake这样的更类似数据仓库的平台。
- en: Data visualization and analysis
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可视化和分析
- en: Once the data is available, the next step is to explore it, visualize it, or
    create dashboards that directly support decision making or enable business process
    monitoring. This phase is very business oriented and should be created in close
    coordination with business stakeholders.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据可用，下一步是探索它、可视化它，或者创建直接支持决策或启用业务流程监控的仪表板。这个阶段非常业务导向，应与业务利益相关者密切协调。
- en: Data quality monitoring, testing, and documentation
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量监控、测试和文档化
- en: Although illustrated as the final phase of the analytics lifecycle, data quality
    should be an end-to-end concern and ensured by design across the whole flow. It
    involves implementing all quality controls to ensure that stakeholders can trust
    your exposed data models, documenting all transformations and semantic meanings,
    and ensuring proper testing along the pipelines as the data continues to flow.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在分析生命周期的最后阶段，数据质量应该是一个端到端的关注点，并且在整个流程中通过设计来保证。它涉及实施所有质量控制，以确保利益相关者可以信任您的公开数据模型，记录所有转换和语义含义，并确保在数据继续流动的过程中沿着管道进行适当的测试。
- en: Note
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: With dbt, several of these components are deployed more easily and efficiently
    because it allows us to build them in parallel and across the lifecycle. Documentation,
    testing, and quality become common tasks performed in parallel. This will be extensively
    elaborated in [Chapter 4](ch04.html#chapter_id_04).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用dbt，这些组件中的几个可以更轻松、更高效地部署，因为它允许我们并行跨生命周期构建它们。文档编制、测试和质量成为并行执行的常见任务。这将在[第四章](ch04.html#chapter_id_04)中广泛阐述。
- en: The analytics lifecycle is a key concept that enables organizations to approach
    data engineering, science, and analytics processes in a structured and consistent
    manner. By following a structured process, organizations can ensure they are solving
    the right problem, using the right data, and building data products that are accurate
    and reliable, ultimately leading to better decision making and better business
    results.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 分析生命周期是一个关键概念，使组织能够以结构化和一致的方式处理数据工程、科学和分析过程。通过遵循结构化的过程，组织可以确保他们解决正确的问题，使用正确的数据，并构建准确可靠的数据产品，最终实现更好的决策和更好的业务结果。
- en: The New Role of Analytics Engineer
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析工程师的新角色
- en: As mentioned in previous sections, data scientists and analysts can now easily
    access the data they need to perform complex analyses and gain insights that would
    otherwise be difficult or impossible to obtain. However, as the amount of data
    stored and analyzed continues to grow, it is becoming increasingly important for
    organizations to have data specialists to help them manage that data and provide
    the infrastructure needed.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，数据科学家和分析师现在可以轻松访问他们需要执行复杂分析并获得洞察力的数据。然而，随着存储和分析的数据量继续增长，对组织来说拥有数据专家来帮助他们管理数据并提供所需的基础设施变得越来越重要。
- en: The recently created branch of specialized data engineers, called *analytics
    engineers*, plays an integral role in developing and maintaining databases and
    data pipelines, allowing data scientists and analysts to focus on more advanced
    analytics tasks. Analytics engineers are responsible for designing, building,
    and maintaining the data architecture that enables organizations to turn data
    into valuable insights and make data-driven decisions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最近成立的一类专门数据工程师分支，称为*分析工程师*，在开发和维护数据库和数据管道中发挥着重要作用，使数据科学家和分析师能够专注于更高级的分析任务。分析工程师负责设计、构建和维护数据架构，使组织能够将数据转化为有价值的见解，并做出数据驱动的决策。
- en: In addition, the move from traditional ETL processes with enforced schemas-on-write
    to an ELT with schema-on-read approach means that data now ends up in the data
    repositories before it has been transformed. This is an opportunity for super-technical
    analysts who both know the business very well and have the technical skills to
    model the raw data into clean, well-defined datasets—analytics engineers. If you
    were looking for these types of skills in the world of data warehouses and the
    ETL paradigm, there would need to be specialists with both software engineering
    and data analytics skills—which would be much harder to find.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，从传统的强制写入模式的ETL过程转向ELT模式，即先写后读的方法，意味着数据现在在被转换之前就已经进入了数据仓库。这为那些既非常了解业务又具备技术技能，能将原始数据建模为清洁、明确定义数据集的超级技术分析师，即分析工程师，提供了机会。如果您在数据仓库和ETL范式的世界中寻找这些类型的技能，将需要同时具备软件工程和数据分析技能——这将更难找到。
- en: The analytics engineer acts as a bridge between data platform engineers, focused
    on building the technical infrastructure to enable data platforms, and data analysts,
    focused on converting data into insightful data products. Their job is to create
    well-tested, up-to-date, and documented datasets that the rest of the organization
    can use to answer their own questions. They are technically savvy enough to apply
    software development best practices such as version control and continuous integration
    and continuous deployment (CI/CD) but also need to be able to communicate effectively
    with stakeholders.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 分析工程师充当了数据平台工程师和专注于将数据转化为见解型数据产品的数据分析师之间的桥梁。他们的工作是创建经过良好测试、最新、有文档记录的数据集，整个组织可以用来回答他们自己的问题。他们具备足够的技术能力，能够应用软件开发最佳实践，如版本控制和持续集成/持续部署（CI/CD），但也需要能够有效地与利益相关者沟通。
- en: 'We can draw an analogy to civil engineering: data platform engineers are the
    foundation of an analytics project, responsible for ensuring that the infrastructure
    is robust, including plumbing, electrical systems, and the structural foundation.
    They lay the groundwork for everything to come.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以类比到土木工程：数据平台工程师是分析项目的基础，负责确保基础设施的稳固性，包括管道、电气系统和结构基础。他们为接下来的所有工作奠定了基础。
- en: Analytics engineers can be likened to architects. They take the solid foundation
    created by data engineers and design structures that align with the business model,
    constructing everything from exceptional dashboards to valuable data models. They
    bridge the gap between the technical infrastructure and the business objectives.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 分析工程师可以被类比为建筑师。他们利用数据工程师创建的坚实基础，设计符合业务模型的结构，从出色的仪表板到有价值的数据模型，构建一切。他们弥合了技术基础设施与业务目标之间的差距。
- en: Data analysts, in this analogy, serve as interior designers. They step inside
    the constructed buildings, not only ensuring that the content is aligned with
    users but also making it user-friendly and tailored to the specific needs of data
    consumers. Together, these roles collaborate to create a holistic and functional
    analytics environment.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类比中，数据分析师则扮演室内设计师的角色。他们步入建筑内部，不仅确保内容与用户一致，而且使其用户友好并根据数据消费者的特定需求定制。这些角色共同合作，创建一个全面和功能齐全的分析环境。
- en: Looking at the data analytics lifecycle, data platform engineers build platforms
    and ingest raw data into enterprise-wide data stores. On the other hand, analytics
    engineers take the raw data and transform it to match the analytical data models
    the business needs to support decision making.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 看看数据分析生命周期，数据平台工程师建立平台并将原始数据导入企业级数据存储中。另一方面，分析工程师将原始数据转换，以匹配业务需要支持决策的分析数据模型。
- en: Responsibilities of an Analytics Engineer
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析工程师的责任
- en: The role of an analytics engineer is becoming increasingly important as both
    the volume and complexity of data, as well as its diverse applications, continue
    to grow. This includes everything from designing and implementing data storage
    and retrieval systems, to creating and maintaining data pipelines, and developing
    and deploying machine learning models. In this dynamic landscape, analytics engineers
    play a vital role in harnessing the increasing data resources and maximizing their
    value across a wide range of applications.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据量和复杂性以及其多样化应用的增长，分析工程师的角色变得越来越重要。这包括从设计和实现数据存储和检索系统，到创建和维护数据管道，再到开发和部署机器学习模型。在这个动态的景观中，分析工程师在利用日益增长的数据资源并在各种应用中最大化其价值方面发挥着关键作用。
- en: Based on the latest role trends, one of the main responsibilities is to design
    and implement efficient data storage and retrieval systems. This includes working
    with databases and data warehousing technologies to design data models and structures
    that can handle large and complex datasets. Another immediate responsibility is
    creating and maintaining data pipelines that extract data from various sources,
    transform it, and load it into a central repository for analysis.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 基于最新的角色趋势，主要职责之一是设计和实现高效的数据存储和检索系统。这包括与数据库和数据仓库技术合作，设计能处理大型和复杂数据集的数据模型和结构。另一个直接的职责是创建和维护数据管道，从各种来源提取数据，进行转换，并将其加载到中央库进行分析。
- en: For most analytics engineers, the development and use of machine learning models
    is somewhat less observable but still happening. This includes working with data
    scientists to understand their requirements, selecting and implementing the appropriate
    algorithms, and ensuring that the models are properly trained and deployed with
    the correct set of training and testing data. When this is not the case, analytics
    engineers collaborate on building the proper data pipelines to continuously feed
    data scientists with proper training and testing data.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数分析工程师来说，开发和使用机器学习模型的过程可能不太明显，但仍在进行中。这包括与数据科学家合作，理解他们的需求，选择和实现适当的算法，并确保模型经过正确的训练和部署，并使用正确的训练和测试数据集。在这种情况下，分析工程师会合作建立适当的数据管道，以持续提供适当的训练和测试数据给数据科学家。
- en: In addition, analytics engineers are responsible for monitoring and maintaining
    the performance of machine learning models, both by helping to structure offline
    evaluation and by combining model-specific metrics with business metrics for online
    monitoring.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，分析工程师还负责监控和维护机器学习模型的性能，通过帮助结构化离线评估和将模型特定的指标与业务指标结合，进行在线监控。
- en: An analytics engineer is typically proficient in programming languages and tools
    such as Python, R, SQL, and Spark to implement data pipelines, data models, and
    machine learning models. They should also be familiar with cloud computing platforms
    like AWS, GCP, or Azure to deploy and scale their solutions.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 分析工程师通常精通编程语言和工具，如Python、R、SQL和Spark，用于实施数据管道、数据模型和机器学习模型。他们还应熟悉像AWS、GCP或Azure等云计算平台，以部署和扩展他们的解决方案。
- en: 'When observing the responsibilities analytics engineers have in several companies,
    they can include the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在观察分析工程师在几家公司中的职责时，可以包括以下内容：
- en: Design and implement data storage and retrieval systems, such as databases and
    data warehouses, that can handle large and complex datasets. Create and maintain
    data pipelines to extract, transform, and load data from various sources into
    a central repository for analysis.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计和实现数据存储和检索系统，如数据库和数据仓库，以处理大型和复杂数据集。创建和维护数据管道，从各种来源提取、转换和加载数据到中央库进行分析。
- en: Ensure data is accurate, complete, consistent, and accessible by performing
    data quality checks, tracking data flows, and implementing data security measures.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过执行数据质量检查、跟踪数据流动并实施数据安全措施，确保数据准确、完整、一致和可访问。
- en: Leverage cloud computing platforms such as AWS, GCP, or Azure to deploy and
    scale analytics solutions, as well as scalability, security, and cost optimization
    of data infrastructure.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用AWS、GCP或Azure等云计算平台部署和扩展分析解决方案，以及数据基础设施的可伸缩性、安全性和成本优化。
- en: Optimize the performance of data storage and retrieval systems, data pipelines,
    and machine learning models to ensure they can handle the volume and complexity
    of data.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化数据存储和检索系统的性能，数据管道以及机器学习模型，确保它们能够处理大量和复杂性的数据。
- en: Use programming languages and tools such as Python, R, SQL, and Spark to implement
    data pipelines, data models, and machine learning models.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python、R、SQL和Spark等编程语言和工具实现数据管道、数据模型和机器学习模型。
- en: Collaborate with data scientists to understand their requirements, select and
    implement appropriate algorithms, and ensure machine learning models are properly
    trained and deployed. Monitor and maintain the performance of machine learning
    models and troubleshoot and optimize as needed.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与数据科学家合作，了解他们的需求，选择并实施适当的算法，确保机器学习模型得到正确训练和部署。监控和维护机器学习模型的性能，并根据需要进行故障排除和优化。
- en: Keep up-to-date with the latest technologies and trends in data engineering,
    machine learning, and analytics, and continually seek opportunities to improve
    the organization’s data infrastructure and analytics capabilities.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持与数据工程、机器学习和分析的最新技术和趋势同步，并持续寻求改进组织的数据基础设施和分析能力的机会。
- en: The role of an analyst is broad and requires a combination of technical skills,
    problem-solving skills, and an understanding of business needs. Analytics engineers
    must be comfortable with data science’s technical and business aspects and should
    be able to bridge the gap between data scientists and IT.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 分析师的角色广泛，需要结合技术技能、问题解决能力和对业务需求的理解。分析工程师必须熟悉数据科学的技术和业务方面，并能够弥合数据科学家和IT之间的鸿沟。
- en: Enabling Analytics in a Data Mesh
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在数据网格中启用分析
- en: A *data mesh* is a modern framework outlining an organization’s data strategy.
    It enables business domain teams to take ownership of their data and the services
    that provide access to it instead of relying only on a central data team. It decomposes
    a monolithic data architecture into a set of independent, autonomous data services,
    enabling finer scaling, more autonomy, and better data management. It provides
    more flexibility in handling different types of data and enables a culture of
    experimentation, innovation, and collaboration. With a data mesh, enterprises
    should be able to move faster and respond more quickly to changing business needs.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据网格*是一种现代框架，概述了组织的数据战略。它使业务域团队能够负责其数据及提供对其的访问的服务，而不仅仅依赖于中心数据团队。它将单片数据架构分解为一组独立的、自治的数据服务，实现了更精细的扩展、更多的自治和更好的数据管理。它在处理不同类型的数据时提供了更大的灵活性，并促进了实验、创新和协作文化。借助数据网格，企业应能更快速地移动并更快速地响应业务变化的需求。'
- en: The emergence of data mesh methodology as an architectural pattern has revolutionized
    the way analysts interact with data infrastructure. By decomposing a monolithic
    data architecture into a series of independent, autonomous data services that
    can be developed, deployed, and operated independently, teams can address the
    challenges of scalability, manageability, and autonomy of the data architecture
    in a more granular and effortless way.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 数据网格方法论作为一种架构模式的出现，彻底改变了分析师与数据基础设施互动的方式。通过将单片数据架构分解为一系列独立的、自治的数据服务，这些服务可以独立开发、部署和运营，团队可以更细粒度和轻松地解决可扩展性、可管理性和数据架构自治性的挑战。
- en: With this novel approach, teams can scale their data infrastructure more granularly,
    reducing the risk of data silos and duplication. Each business domain team also
    has more autonomy, allowing them to choose the best tools and technologies for
    their specific needs but leverage centrally offered services to manage the whole
    data lifecycle. This permits them to move faster, be more agile, and respond quickly
    to changing business needs. In addition, a data mesh approach provides more flexibility
    in handling different types of data, such as structured, semi-structured, and
    unstructured data. It also enables better data governance practices by breaking
    down the monolithic data architecture and enabling clear mapping of data services.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种新颖的方法，团队可以更细粒度地扩展其数据基础设施，降低数据孤岛和重复数据的风险。每个业务域团队也拥有更多的自治权，可以根据特定需求选择最佳工具和技术，但利用中心提供的服务来管理整个数据生命周期。这使他们能够更快速、更灵活地响应业务变化的需求。此外，数据网格方法还提供了处理结构化、半结构化和非结构化数据的更大灵活性。通过分解单片数据架构并实现数据服务的清晰映射，还能促进更好的数据治理实践。
- en: An analytics engineer can deliver value in a data mesh organization by focusing
    on building and maintaining independent, autonomous data services that support
    the needs of multiple teams and applications, such as shared data models, well-governed
    and documented to ensure effortless data discoverability, accessibility, and security.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据网格组织中，分析工程师可以通过专注于构建和维护支持多个团队和应用程序需求的独立、自治的数据服务来提供价值，例如共享数据模型，良好治理和文档化，以确保数据的轻松发现、可访问性和安全性。
- en: Another meaningful aspect of working on a data mesh is ensuring data governance
    and security, which can include implementing data policies and procedures, such
    as data access controls, data sequencing, and data quality checks, to ensure that
    data is secure and of high quality. In addition, analytics engineers should work
    with data owners and stakeholders to understand and comply with all data storage
    and management regulatory requirements.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据网格工作的另一个有意义的方面是确保数据治理和安全性，这可能包括实施数据访问控制、数据排序和数据质量检查等数据政策和程序，以确保数据安全和高质量。此外，分析工程师应与数据所有者和利益相关者合作，了解并遵守所有数据存储和管理的法规要求。
- en: Working in a data mesh requires a different mindset than in traditional monolithic
    data architectures. Analytics engineers must move away from the notion that data
    is a centralized resource and consider it as distributed autonomous services that
    various teams can use.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据网格中工作需要与传统的单片式数据架构有不同的思维方式。分析工程师必须摆脱数据是集中资源的观念，而将其视为分布式自治服务，各团队可以使用。
- en: Data Products
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据产品
- en: Another concept we have been using that is important to define is that of a
    *data product*. These are accessible applications providing access to data-driven
    insights that will support business decision-making processes or even automate
    them. Internally they may contain components for retrieving, transforming, analyzing,
    and interpreting data. Another important aspect is that data products should expose
    their data in such a way that it can be accessed and used by other internal or
    external applications or services.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在使用的另一个重要概念是*数据产品*。这些是可访问的应用程序，提供访问数据驱动洞见的支持，将支持业务决策过程甚至自动化它们。在内部，它们可能包含用于检索、转换、分析和解释数据的组件。另一个重要方面是，数据产品应该以一种方式暴露它们的数据，使其可以被其他内部或外部应用程序或服务访问和使用。
- en: 'Some examples of data products are as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据产品的例子如下：
- en: A REST API that allows users to query a specific business data model
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 REST API，允许用户查询特定的业务数据模型。
- en: A data pipeline that ingests and processes data from various sources
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从各种来源摄取和处理数据的数据管道。
- en: A data lake that stores and manages large amounts of structured and unstructured
    data
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储和管理大量结构化和非结构化数据的数据湖。
- en: A data visualization tool that helps users understand and communicate data insights
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帮助用户理解和传达数据洞见的数据可视化工具。
- en: Data products can also consist of microservices. These are small, independent,
    and focused services that can be developed, deployed, and scaled independently.
    They can be accessed via an API and reused across the enterprise.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 数据产品也可以包括微服务。这些是小型、独立和专注的服务，可以独立开发、部署和扩展。它们可以通过 API 访问，并在整个企业中重复使用。
- en: dbt as a Data Mesh Enabler
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: dbt 作为数据网格的促进者。
- en: '*dbt* is an open source tool that helps data engineers, analytics engineers,
    and data analysts build a data mesh by providing a way to create, test, and manage
    data services. It allows teams to define, test, and build data models and create
    a clear and well-defined interface for these models so that other teams and applications
    can easily use them.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*dbt* 是一个开源工具，帮助数据工程师、分析工程师和数据分析师通过提供创建、测试和管理数据服务的方式构建数据网格。它允许团队定义、测试和构建数据模型，并为这些模型创建清晰和明确定义的接口，以便其他团队和应用程序可以轻松使用。'
- en: 'The dbt features that support the creation of a data mesh include the following:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 支持创建数据网格的 dbt 特性包括以下内容：
- en: Data modeling capabilities
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 数据建模能力
- en: Data modeling capabilities allow teams to define their data models by using
    a simple and familiar SQL-based syntax that makes it easy for data engineers and
    data analysts to define and test data models together.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 数据建模能力允许团队使用简单且熟悉的基于 SQL 的语法定义其数据模型，使得数据工程师和数据分析师可以轻松地共同定义和测试数据模型。
- en: Data testing capabilities
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 数据测试能力
- en: dbt provides a testing framework that allows teams to test their data models
    and ensure that they are accurate and reliable. This helps identify errors early
    in the development process and ensures that data services are of high quality.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: dbt提供了一个测试框架，允许团队测试其数据模型，并确保其准确和可靠。这有助于在开发过程的早期发现错误，并确保数据服务的高质量。
- en: Data documentation
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 数据文档
- en: dbt enables data models and services to be documented so that they can be easily
    understood and used by other teams and applications.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: dbt使数据模型和服务能够被文档化，以便其他团队和应用程序能够轻松理解和使用。
- en: Data tracking capabilities
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 数据跟踪能力
- en: Data tracking capabilities allow teams to trace the origin of data models. This
    makes it easy to understand how data is used and where it came from.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 数据跟踪能力使团队能够追踪数据模型的来源。这使得理解数据的使用方式和来源变得容易。
- en: Data governance capabilities
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 数据治理能力
- en: Data governance capabilities make it possible to enforce data governance policies
    such as data access controls, data lineage, and data quality checks, which help
    ensure that data is secure and of high quality.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 数据治理能力使得执行数据访问控制、数据血统和数据质量检查等数据治理政策成为可能，有助于确保数据安全和高质量。
- en: While the primary focus of analytics engineering is on designing and implementing
    data models, it’s important to note that data tracking and governance capabilities
    can significantly enhance the effectiveness of analytics engineering processes.
    These capabilities can be particularly valuable in scenarios where data models
    need to trace the origin of data and adhere to stringent data governance policies.
    Adoption of such practices and governance models, including a data mesh, may vary
    depending on the specific needs and complexity of the data environment. Many successful
    dbt deployments start with simpler single-star schema data models and may explore
    advanced concepts like data mesh as their data needs evolve over time.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据分析工程的主要焦点是设计和实施数据模型，但重要的是要注意，数据跟踪和治理能力可以显著增强分析工程流程的有效性。在需要数据模型追踪数据来源并遵守严格的数据治理政策的情况下，这些能力尤其有价值。采用这些实践和治理模型，包括数据网格，可能会因数据环境的具体需求和复杂性而有所不同。许多成功的dbt部署从较简单的单星模式数据模型开始，并且随着时间推移可能探索像数据网格这样的高级概念。
- en: The Heart of Analytics Engineering
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析工程的核心
- en: '*Data transformation* converts data from one format or structure to another
    to make it more useful or suitable for a particular application or purpose. This
    process is necessary because it enables organizations to transform raw, unstructured
    data into valuable insights that can inform business decisions, improve operations,
    and drive growth.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据转换* 将数据从一种格式或结构转换为另一种，使其更加有用或适合特定的应用或目的。这个过程是必要的，因为它使组织能够将原始、非结构化的数据转换为有价值的见解，从而可以指导业务决策，改进运营并推动增长。'
- en: Data transformation is a critical step in the analytics lifecycle, and it is
    important that organizations have the tools and technology to perform this task
    efficiently and effectively. Some examples of data transformation include cleaning
    and preparing data, aggregating and summarizing data, and enriching data with
    additional information. The use of dbt is widespread for data transformation because
    it allows organizations to perform complex data transformation tasks quickly and
    easily, and it can be integrated with other tools, such as Airflow, for end-to-end
    data pipeline management.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换是分析生命周期中的关键步骤，组织必须拥有有效和高效执行此任务的工具和技术非常重要。数据转换的一些示例包括数据清理和准备、数据聚合和汇总，以及通过添加额外信息丰富数据。由于dbt允许组织快速、轻松地执行复杂的数据转换任务，并且可以与其他工具（如Airflow）集成用于端到端数据管道管理，因此dbt在数据转换中的使用非常广泛。
- en: dbt is the *gemba* for analysts and enterprise stakeholders. The value to businesses
    and stakeholders comes when data is transformed and delivered in an easy-to-use
    form.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分析师和企业利益相关者来说，dbt是*现场*。当数据被转换并以易于使用的形式交付时，对企业和利益相关者的价值得以体现。
- en: Tip
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: '*Gemba* is a Japanese term meaning “the real place.” In the corporate world,
    gemba refers to the place where value is created.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*现场（Gemba）* 是一个日语术语，意思是“真实的地方”。在企业界，现场指的是价值创造的地方。'
- en: In an ETL strategy, data transformation is typically performed before the data
    is loaded into a target system, such as a data warehouse or data lake. Data is
    extracted from various sources, transformed to match the structure and format
    of the target system, and then loaded into the target system. This process ensures
    that the data is consistent and usable across systems and applications.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在ETL策略中，数据转换通常在数据加载到目标系统（如数据仓库或数据湖）之前执行。数据从各种来源提取，转换以匹配目标系统的结构和格式，然后加载到目标系统中。这个过程确保数据在系统和应用程序之间是一致且可用的。
- en: In contrast, an ELT strategy represents a newer and more flexible approach to
    data processing. In this strategy, data is first extracted and loaded into a target
    system before undergoing transformation. ELT offers several advantages, including
    increased flexibility and the ability to support a wider range of data applications
    than the traditional ETL paradigm. One significant benefit is its versatility
    in accommodating various data transformations and real-time insights directly
    within the target system. This flexibility empowers organizations to derive actionable
    insights from their data more rapidly and adapt to changing analytical needs.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，ELT策略代表了一种更新颖、更灵活的数据处理方法。在这种策略中，数据首先被提取并加载到目标系统中，然后再进行转换。ELT提供了多种优势，包括增加的灵活性和支持更广泛数据应用能力，超过了传统ETL范式。其一个显著的优势在于，它能够在目标系统内直接进行各种数据转换和实时洞察。这种灵活性使组织能够更快速地从数据中获得可操作的洞察，并适应不断变化的分析需求。
- en: However, it’s important to acknowledge that ELT can come with higher storage
    and ingestion costs, given the storage of raw or minimally transformed data. Many
    businesses find these costs justifiable because of the substantial value—in particular,
    the flexibility it brings to their operations. Therefore, ELT has gained popularity,
    especially with the emergence of cloud-based data warehousing solutions and the
    improved data transformation and processing capabilities they offer.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要指出的是，ELT可能伴随着更高的存储和摄入成本，因为需要存储原始或最小转换后的数据。许多企业认为这些成本是合理的，因为它们为其运营带来了重大价值，特别是灵活性。因此，随着基于云的数据仓库解决方案的出现以及它们提供的改进的数据转换和处理能力，ELT越来越受欢迎。
- en: Regardless of the strategy used, without proper data cleaning, transformation,
    and standardization, data may end up inaccurate, incomplete, or difficult to use,
    resulting in poor decision making.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 无论使用哪种策略，如果没有适当的数据清洗、转换和标准化，数据可能会变得不准确、不完整或难以使用，从而导致糟糕的决策。
- en: The Legacy Processes
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统流程
- en: Traditionally, legacy ETL processes were often complex, time-consuming, and
    required specialized skills to develop, implement, and maintain. They also typically
    required significant manual coding and data manipulation, making them error-prone
    and difficult to scale.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，传统的ETL过程往往复杂、耗时，并需要专门的技能来开发、实施和维护。它们通常还需要大量的手工编码和数据操作，使其容易出错且难以扩展。
- en: In addition, these processes were often inflexible and could not be adapted
    to changing business needs or new data sources. With the growing volume, variety,
    and velocity of data, legacy ETL processes are becoming increasingly inadequate
    and, so, are being replaced by more modern and flexible approaches such as ELT.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些过程通常缺乏灵活性，无法适应不断变化的业务需求或新的数据来源。随着数据量、种类和速度的增长，传统的ETL（抽取-转换-加载）过程变得越来越不足够，因此正在被更现代、更灵活的ELT（抽取-加载-转换）方法所取代。
- en: In the past, ETL was usually performed using custom scripts or specialized visual-based
    ETL tools. These scripts or tools extracted data from various sources, such as
    flat files or databases, performed the necessary transformations on the data,
    and then loaded the data into a target system, such as a data warehouse.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 过去，通常使用自定义脚本或专门的基于可视化的ETL工具来执行ETL。这些脚本或工具从各种来源（如平面文件或数据库）提取数据，对数据进行必要的转换，然后将数据加载到目标系统，如数据仓库中。
- en: An example of a legacy ETL process would be using a combination of SQL scripts
    and programming languages such as Java or C# to extract data from a relational
    database, transforming the data using the programming language, and then loading
    the transformed data into a data warehouse. Another example is using specialized
    ETL tools such as Oracle Data Integrator or IBM InfoSphere DataStage to extract,
    transform, and load data across systems. These legacy ETL processes can be complex,
    challenging to maintain and scale, and often require a dedicated team of developers.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一个传统ETL过程的示例可能是使用SQL脚本和编程语言（如Java或C#）来从关系数据库提取数据，使用编程语言转换数据，然后将转换后的数据加载到数据仓库中。另一个例子是使用专用ETL工具如Oracle
    Data Integrator或IBM InfoSphere DataStage来在系统间提取、转换和加载数据。这些传统ETL过程可能很复杂，难以维护和扩展，并且通常需要专门的开发团队。
- en: Using SQL and Stored Procedures for ETL/ELT
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SQL和存储过程进行ETL/ELT
- en: In the past, specific data platforms used stored procedures in a relational
    database management system (RDBMS) such as SQL Server or Oracle for ETL purposes.
    *Stored procedures* are prepared SQL code that you can store in your database
    engine so that the code can be used repeatedly. Depending on whether it is a data
    inflow or outflow, the scripts are executed either in the source or the target
    database.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，特定的数据平台使用存储过程在关系数据库管理系统（RDBMS）如SQL Server或Oracle中进行ETL。*存储过程*是预先编写的SQL代码，可以存储在数据库引擎中，以便可以重复使用该代码。根据是数据流入还是流出，脚本会在源数据库或目标数据库中执行。
- en: Suppose you want to create a simple stored procedure to extract from a table,
    transform the data, and load it into another table, as shown in [Example 1-1](#reference_simple_sql_proc_statement).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要创建一个简单的存储过程来从表中提取数据，转换数据，并将其加载到另一个表中，如[示例 1-1](#reference_simple_sql_proc_statement)所示。
- en: Example 1-1\. SQL procedure to extract data
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 1-1\. 提取数据的SQL过程
- en: '[PRE0]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This stored procedure first uses the `SELECT INTO` statement to extract all
    data from the source table and store it in a temporary table (`#temp_table`).
    Then it uses the `UPDATE` statement to change the values of `column1` to uppercase
    and double the value of `column2`. Finally, the stored procedure uses the `INSERT
    INTO` statement to load the data from the `#temp_table` into the `target_table`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 该存储过程首先使用`SELECT INTO`语句从源表中提取所有数据并将其存储在临时表(`#temp_table`)中。然后它使用`UPDATE`语句将`column1`的值改为大写并将`column2`的值加倍。最后，存储过程使用`INSERT
    INTO`语句将`#temp_table`中的数据加载到`target_table`中。
- en: Note
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Don’t be afraid if you aren’t familiar with the SQL syntax. [Chapter 3](ch03.html#chapter_id_03)
    is fully dedicated to giving you the foundations to working with it.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对SQL语法不熟悉，不必担心。[第三章](ch03.html#chapter_id_03)专门为您提供使用基础知识。
- en: It is important to note that this is an elementary example and that actual ETL
    processes are often much more complex and involve many more steps, such as data
    validation, handling null values and errors, and logging process results.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是这只是一个基础示例，实际的ETL过程通常要复杂得多，并涉及许多步骤，如数据验证、处理空值和错误以及记录处理结果。
- en: Although it is possible to use stored procedures for ETL processes, it is essential
    to note that using them may have some implications, such as the need for specialized
    knowledge and expertise to write and maintain those procedures and the lack of
    flexibility and scalability. In addition, using stored procedures for ETL can
    make it challenging to integrate with other systems and technologies and troubleshoot
    problems that arise during the ETL process.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以使用存储过程进行ETL过程，但需要注意使用它们可能会有一些影响，比如需要专业知识和专长来编写和维护这些过程，以及灵活性和可扩展性的缺乏。此外，使用存储过程进行ETL可能会使与其他系统和技术集成以及解决ETL过程中出现的问题变得困难。
- en: Using ETL Tools
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用ETL工具
- en: As previously mentioned, ETL tools are software applications that accelerate
    the process of building ingestion and transformation pipelines by providing a
    visual interface, a software development kit (SDK), or a programming library with
    prepackaged code and artifacts that can be used for extracting, transforming,
    and loading data from various sources into a target, such as a data warehouse
    or data lake. They are generally used in many organizations to automate the process
    of transferring data from various systems and databases to a central data warehouse
    or data lake, where it can be analyzed.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正如先前提到的，ETL工具是一种软件应用程序，通过提供可视化界面、软件开发工具包（SDK）或编程库以及预打包的代码和工件，加速构建摄取和转换管道的过程。这些工具可以用于从各种来源提取、转换和加载数据到目标位置，如数据仓库或数据湖。许多组织通常使用它们来自动化将数据从各个系统和数据库传输到中央数据仓库或数据湖的过程，以便进行分析。
- en: Airflow is a popular open source platform for managing and scheduling data pipelines.
    Developed by Airbnb, it has gained popularity in recent years because of its flexibility
    and scalability. Airflow allows users to define, schedule, and monitor data pipelines
    using Python code, making them easy for data engineers and scientists to create.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Airflow是一个流行的开源平台，用于管理和调度数据管道。由Airbnb开发，近年来因其灵活性和可伸缩性而广受欢迎。Airflow允许用户使用Python代码定义、调度和监视数据管道，使其对数据工程师和科学家而言易于创建。
- en: '[Example 1-2](#reference_aiflof_dag_sample) presents a simple Airflow DAG.
    A *directed acyclic graph* (DAG) is a directed graph with no directed cycles.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 1-2](#reference_aiflof_dag_sample)展示了一个简单的Airflow DAG。一个*有向无环图*（DAG）是一个没有有向环路的有向图。'
- en: Example 1-2\. An Airflow DAG
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 1-2\. 一个Airflow DAG
- en: '[PRE1]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This code defines a DAG named `simple_dag` that runs every hour. It has two
    tasks, `print_date` and `sleep`. The first task executes the `date` command, which
    prints the current date and time. The second task executes the `sleep 5` command,
    which makes the task sleep for five seconds. The second task has the number of
    retries set to 3\. So if it fails, it will retry three times before giving up.
    The two tasks are connected by the operator `>>`. This also means `task2` depends
    on `task1` and will be executed only after `task1` completes successfully.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码定义了一个名为`simple_dag`的DAG，每小时运行一次。它有两个任务，`print_date`和`sleep`。第一个任务执行`date`命令，打印当前日期和时间。第二个任务执行`sleep
    5`命令，使任务休眠五秒。第二个任务的重试次数设置为3次。因此，如果任务失败，它将在放弃之前重试三次。这两个任务由运算符`>>`连接。这也意味着`task2`依赖于`task1`，并且只有在`task1`成功完成后才会执行。
- en: Airflow is a productive tool for scheduling and managing ETL pipelines, but
    it has some limitations. First, Airflow can be very complex to set up and manage,
    especially for large or complicated pipelines. Second, it is not explicitly designed
    for data transformation and may require additional tools or custom code to perform
    certain types of data manipulation.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Airflow是一个用于调度和管理ETL管道的高效工具，但它也有一些局限性。首先，Airflow的设置和管理可能非常复杂，特别是对于大型或复杂的管道。其次，它并没有专门为数据转换而设计，可能需要额外的工具或定制代码来执行某些类型的数据操作。
- en: Note
  id: totrans-152
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: dbt can address these Airflow limitations by providing a set of best practices
    and conventions for data transformation and a simple, straightforward interface
    for performing and managing data transformation. It can also be integrated with
    Airflow to supply a complete ETL/ELT solution that is easy to set up and manage
    while providing high flexibility and control over data pipelines.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: dbt可以通过提供一组最佳实践和数据转换的约定，以及用于执行和管理数据转换的简单直接的界面，来解决这些Airflow的局限性。它还可以与Airflow集成，提供一个易于设置和管理的完整的ETL/ELT解决方案，同时提供对数据管道的高度灵活性和控制。
- en: The dbt Revolution
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: dbt革命
- en: dbt is an open source command-line tool that is becoming increasingly popular
    in the data analytics industry because it simplifies and streamlines the process
    of data transformation and modeling. On the other hand, Airflow is a powerful
    open source platform for programmatically creating, scheduling, and monitoring
    workflows. When dbt is integrated with Airflow, the data pipeline can be more
    efficiently managed and automated. Airflow can be used to schedule dbt runs, and
    dbt can be used to perform the data transformation tasks in the pipeline.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: dbt是一个开源的命令行工具，在数据分析行业中越来越受欢迎，因为它简化和优化了数据转换和建模的过程。另一方面，Airflow是一个强大的开源平台，用于以编程方式创建、调度和监控工作流。当dbt与Airflow集成时，数据管道可以更高效地管理和自动化。Airflow可以用来调度dbt运行，而dbt可以用来执行管道中的数据转换任务。
- en: This integration enables teams to manage the entire data pipeline from data
    extraction to loading into a data warehouse, ensuring that data is always up-to-date
    and accurate. The integration makes it easier to automate data pipeline tasks,
    schedule and monitor the pipeline, and troubleshoot issues as they arise.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这种集成使团队能够管理从数据提取到加载到数据仓库的整个数据管道，确保数据始终保持最新和准确。集成使得自动化数据管道任务、调度和监控管道以及及时解决问题变得更加容易。
- en: To illustrate the simplicity of building a simple dbt model, imagine that you
    want to build a model that calculates a company’s total revenue by adding the
    revenue for each order. The model could be defined using a dbt model file specifying
    the calculation’s SQL code and any required dependencies or parameters. [Example 1-3](#reference_dbt_model_sample)
    presents what the model file could look like.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明构建简单 dbt 模型的简易性，想象一下你想要建立一个模型，通过将每个订单的收入相加来计算公司的总收入。模型可以通过一个 dbt 模型文件来定义，该文件指定了计算的
    SQL 代码以及任何所需的依赖关系或参数。[示例 1-3](#reference_dbt_model_sample) 展示了模型文件可能的样子。
- en: Example 1-3\. A dbt model
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 1-3\. 一个 dbt 模型
- en: '[PRE2]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: One of the main advantages of dbt is that analytics engineers can write reusable,
    maintainable, and testable code for data transformations in a simple high-level
    language that eliminates the complexity of writing SQL. This facilitates team
    collaboration on data projects and reduces the risk of errors in the data pipeline.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: dbt 的主要优势之一是，分析工程师可以使用一种简单的高级语言编写可重用、可维护和可测试的数据转换代码，从而消除了编写 SQL 的复杂性。这促进了团队在数据项目上的协作，并减少了数据管道中错误的风险。
- en: Another benefit of dbt is that it enables more efficient data pipeline management.
    By integrating with orchestration tools like Airflow and others such as Dagster
    or Prefect, as well as dbt Labs’ own dbt Cloud product, dbt empowers teams to
    effectively plan, schedule, and monitor data pipelines. This ensures that data
    remains consistently up-to-date and accurate. The synergy between dbt and orchestration
    tools like Airflow allows for seamless data refresh and the deployment of new
    logic, akin to CI/CD practices in software engineering. This integration ensures
    that as new data becomes available or transformations are updated, the data pipeline
    can be orchestrated and executed efficiently to deliver reliable and timely insights.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: dbt 的另一个好处是，它能够实现更高效的数据管道管理。通过与像 Airflow、Dagster 或 Prefect 等编排工具以及 dbt Labs
    自己的 dbt Cloud 产品集成，dbt 赋予团队有效地规划、调度和监控数据管道的能力。这确保数据始终保持最新和准确。dbt 与 Airflow 等编排工具的协同作用允许无缝地刷新数据并部署新的逻辑，类似于软件工程中的
    CI/CD 实践。这种集成确保了随着新数据的可用性或转换的更新，数据管道可以有效地编排和执行，以提供可靠和及时的洞察。
- en: Overall, dbt is becoming widespread for organizations looking to improve their
    data analytics capabilities and streamline their data pipelines. Although it is
    still a relatively new technology, it is being used by many companies and is considered
    a valuable tool for data professionals. [Chapter 4](ch04.html#chapter_id_04) will
    provide a more in-depth view of dbt and its capabilities and features.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，对于希望提高其数据分析能力并简化数据管道的组织来说，dbt 正变得越来越普及。尽管它仍然是一种相对较新的技术，但许多公司正在使用它，并认为它是数据专业人士的宝贵工具。[第 4
    章](ch04.html#chapter_id_04) 将更深入地介绍 dbt 及其能力和特性。
- en: Summary
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In recent decades, the field of data management has undergone profound transformations,
    transitioning from structured methods of data storage and access, such as SQL-based
    stored procedures, to more flexible and scalable workflows. These modern workflows
    are supported by powerful tools like Airflow and dbt. Airflow facilitates dynamic
    orchestration, while dbt elevates analytics code to the level of production-grade
    software, introducing innovative approaches to data testing and transformation.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近几十年中，数据管理领域经历了深刻的变革，从基于结构化方法的数据存储和访问（如基于 SQL 的存储过程）转向了更灵活和可扩展的工作流。这些现代工作流得到了像
    Airflow 和 dbt 这样强大工具的支持。Airflow 支持动态编排，而 dbt 将分析代码提升到了生产级软件的水平，引入了数据测试和转换的创新方法。
- en: Amid this dynamic environment, new roles have emerged, with the analytics engineer
    standing at the intersection of data engineering and data analytics, ensuring
    the delivery of robust insights. Despite the evolution of tools and roles, the
    intrinsic value of data remains unchanged. However, data management is evolving
    into a discipline that focuses not only on data itself but also on the professionals
    who wield it.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个充满活力的环境中，新角色如数据分析工程师应运而生，站在数据工程与数据分析的交汇点上，确保提供强大的洞察力。尽管工具和角色不断演进，数据的内在价值仍然不变。然而，数据管理正在演变为一门不仅关注数据本身，还关注运用数据的专业人士的学科。
- en: 'Even with these advancements, the core challenges persist: acquiring critical
    data, maintaining the highest data-quality standards, storing data efficiently,
    and meeting stakeholder expectations in data delivery. At the heart of the data
    value chain lies the revitalization of data modeling. Efficient data modeling
    goes beyond data gathering; it structures and organizes data to reflect real-world
    relationships and hierarchies. [Chapter 2](ch02.html#chapter_id_02) will delve
    into data modeling and its pivotal role in analytics engineering.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了这些进展，核心挑战仍然存在：获取关键数据、维护最高的数据质量标准、高效存储数据以及在数据交付中满足利益相关者的期望。数据价值链的核心在于数据建模的复兴。高效的数据建模不仅限于数据收集；它将数据结构化和组织起来，以反映现实世界的关系和层次。[第二章](ch02.html#chapter_id_02)
    将深入探讨数据建模及其在分析工程中的关键角色。
- en: Throughout this chapter, we have explored the evolution of data management,
    the emergence of the analytics engineer role, and concepts like data mesh and
    the distinction between ELT and ETL strategies. This diverse set of topics aims
    to provide a comprehensive overview of the data landscape.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了数据管理的演变、数据分析工程师角色的出现，以及数据网格和ELT与ETL策略之间的区别。这一多样的主题旨在提供对数据领域的全面概述。
