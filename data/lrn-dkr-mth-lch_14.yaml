- en: '12 Understanding orchestration: Docker Swarm and Kubernetes'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 理解编排：Docker Swarm 和 Kubernetes
- en: We’re halfway through our container journey together, and by now you should
    be pretty comfortable packaging and running applications with Docker and Docker
    Compose. The next step is understanding how those applications run in a production
    environment, where you have many machines running Docker to give you high availability
    and the power to handle lots of incoming traffic.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一起的容器之旅已经过半，到现在您应该已经非常熟悉使用 Docker 和 Docker Compose 打包和运行应用程序了。下一步是了解这些应用程序如何在生产环境中运行，在那里有许多机器运行
    Docker，以提供高可用性和处理大量 incoming traffic 的能力。
- en: In that environment your apps still run in containers using the same Docker
    images you run locally, but there’s a management layer that takes care of coordinating
    all the machines and running the containers for you. That’s called orchestration
    and the two main container orchestrators are Docker Swarm and Kubernetes. They
    share a lot of the same features and capabilities, but Kubernetes is a complex
    system with its own learning journey--Learn Kubernetes in a Month of Lunches will
    be your guide there. In this chapter you’re going to learn about orchestration
    using Docker Swarm, which is a powerful production-grade container orchestrator
    built right into Docker. Even if your ultimate goal is to learn Kubernetes, it’s
    good to start with Swarm--the Kubernetes learning curve is steep, but it’s much
    easier when you already know Swarm.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在那个环境中，您的应用程序仍然使用与您本地运行相同的 Docker 镜像在容器中运行，但有一个管理层负责协调所有机器并为您运行容器。这被称为编排，两个主要的容器编排器是
    Docker Swarm 和 Kubernetes。它们共享许多相同的功能和能力，但 Kubernetes 是一个复杂的系统，有自己的学习路径——《一个月午餐学
    Kubernetes》将是您的指南。在本章中，您将学习如何使用 Docker Swarm 进行编排，这是一个内置在 Docker 中的强大生产级容器编排器。即使您的最终目标是学习
    Kubernetes，从 Swarm 开始也是好的——Kubernetes 的学习曲线很陡峭，但如果你已经知道 Swarm，那么学习起来会容易得多。
- en: 12.1 What is a container orchestrator?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 容器编排器是什么？
- en: Docker Compose is great for running containers on a single machine, but that
    doesn’t work in a production environment--if that machine goes offline, you lose
    all your applications. Production systems need high availability, which is where
    orchestration comes in. An orchestrator is basically a lot of machines all grouped
    together to form a cluster; the orchestrator manages containers, distributing
    work among all the machines, load-balancing network traffic, and replacing any
    containers that become unhealthy.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose 适用于在单台机器上运行容器，但在生产环境中并不适用——如果该机器离线，您将丢失所有应用程序。生产系统需要高可用性，这就是编排发挥作用的地方。编排器基本上是将许多机器分组在一起形成一个集群；编排器管理容器，在所有机器之间分配工作，平衡网络流量，并替换任何变得不健康的容器。
- en: You create a cluster by installing Docker on each of your machines, and then
    you join them together with the orchestration platform--Swarm or Kubernetes. From
    then on you manage the cluster remotely using command-line tools or web UIs. Figure
    12.1 shows how that looks from the infrastructure view.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在每个机器上安装 Docker 来创建一个集群，然后使用编排平台——Swarm 或 Kubernetes 将它们连接起来。从那时起，您可以使用命令行工具或
    Web UI 远程管理集群。图 12.1 展示了从基础设施视图看它是如何呈现的。
- en: '![](../Images/12-1.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12-1.jpg)'
- en: Figure 12.1 An orchestrator turns many servers into a single cluster, and it
    manages containers for you.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.1 一个编排器将许多服务器转换成一个单一的集群，并为您管理容器。
- en: The orchestrator offers a set of extra capabilities that take your containers
    to the next level. There’s a distributed database in the cluster that stores all
    the information about the applications you deploy. Then there’s a scheduler that
    works out where to run containers, and a system to send heartbeats between all
    the servers in the cluster. Those are the basic building blocks for reliability.
    You deploy applications by sending your YAML file to the cluster; it stores that
    information and then schedules containers to run the app--distributing the work
    to servers with available capacity. When the app is running, the cluster makes
    sure it keeps running. If a server goes offline and you lose a bunch of containers,
    the cluster will start replacement containers on other servers.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Orchestrator提供了一套额外的功能，将你的容器提升到新的水平。集群中有一个分布式数据库，存储了你部署的所有应用程序的信息。然后有一个调度器来确定容器的运行位置，还有一个系统在集群中的所有服务器之间发送心跳。这些都是可靠性的基本构建块。你通过将YAML文件发送到集群来部署应用程序；它存储这些信息，然后调度容器运行应用程序——将工作分配给具有可用容量的服务器。当应用程序运行时，集群确保它持续运行。如果服务器离线并且你丢失了一大批容器，集群将在其他服务器上启动替换容器。
- en: Orchestrators do all the hard work of managing containers; you just define the
    desired state in your YAML files, and you don’t have to know or care how many
    servers are in the cluster or where your containers are running. The orchestrator
    also provides features for networking, configuring applications, and storing data.
    Figure 12.2 shows how network traffic is routed into and within the cluster and
    how containers can read configuration objects and secrets, and write to shared
    storage.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Orchestrators负责管理容器的所有繁重工作；你只需在YAML文件中定义所需的状态，无需了解或关心集群中有多少服务器或容器运行的位置。orchestrator还提供了网络、配置应用程序和存储数据的功能。图12.2展示了网络流量如何路由到集群内部以及容器如何读取配置对象和秘密，并将数据写入共享存储。
- en: '![](../Images/12-2.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-2.jpg)'
- en: Figure 12.2 Orchestrators provide extra features for containers--networking,
    configuration, and storage.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 orchestrators为容器提供了额外的功能——网络、配置和存储。
- en: There’s an important thing missing from the diagram in figure 12.2--the servers.
    The orchestrator hides away the details of the individual machines, networks,
    and storage devices. You work with the cluster as a single unit, sending commands
    and running queries through the API, which the command line connects to. The cluster
    could be 1,000 machines or a single machine--you work with it in the same way
    and send the same commands and YAML files to manage your apps. Users of your application
    could connect to any server in the cluster, and the orchestration layer takes
    care of routing traffic to containers.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2中的图示缺少一个重要的元素——服务器。orchestrator隐藏了单个机器、网络和存储设备的细节。你将集群作为一个单一单元来工作，通过API发送命令和运行查询，命令行连接到该API。集群可以是1000台机器或一台机器——你以相同的方式与之交互，发送相同的命令和YAML文件来管理你的应用程序。你的应用程序的用户可以连接到集群中的任何服务器，编排层负责将流量路由到容器。
- en: 12.2 Setting up a Docker Swarm cluster
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 设置Docker Swarm集群
- en: Let’s get started now. It’s super easy to deploy a container orchestrator with
    Docker Swarm, because the features are built into the Docker Engine. All you need
    to do is switch to Swarm mode by initializing the cluster.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们开始吧。使用Docker Swarm部署容器orchestrator非常简单，因为所有功能都内置在Docker Engine中。你只需要通过初始化集群来切换到Swarm模式。
- en: 'Try it now The Docker CLI has a set of commands to manage cluster operations.
    The `swarm` `init` command switches to Swarm mode. You can usually run it without
    any arguments, but if your machine is connected to more than one network, you’ll
    get an error and Docker will ask you which IP address to use for the Swarm communication:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看。Docker CLI有一组用于管理集群操作的命令。`swarm init`命令切换到Swarm模式。通常你可以在没有任何参数的情况下运行它，但如果你的机器连接到多个网络，你会得到一个错误，Docker会询问你哪个IP地址用于Swarm通信：
- en: '` docker swarm init`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '` docker swarm init`'
- en: 'You can see my output in figure 12.3, which tells me that the Swarm is initialized
    and my machine is a manager. Machines in a cluster can have different roles: they
    can either be a manager or a worker. The output from running `swarm` `init` shows
    the command you need to run on other machines for them to join the Swarm as workers.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图12.3中看到我的输出，它告诉我Swarm已初始化，我的机器是管理器。集群中的机器可以有不同的角色：它们可以是管理器或工作节点。运行`swarm
    init`的输出显示了需要在其他机器上运行的命令，以便它们作为工作节点加入Swarm。
- en: '![](../Images/12-3.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-3.jpg)'
- en: Figure 12.3 Switching to Swarm mode creates a cluster with a single node, which
    is the manager.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 切换到Swarm模式创建了一个包含单个节点的集群，这个节点是管理员。
- en: The difference between managers and workers is that the managers run the show--the
    cluster database is stored on the managers, you send your commands and YAML files
    to the API hosted on the managers, and the scheduling and monitoring is all done
    by the managers. Workers typically just run containers when the managers schedule
    them, and they report back on their status, although you can have managers running
    workloads too (insert your own joke here, comparing that to human managers).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员和工人的区别在于管理员负责整个流程——集群数据库存储在管理员上，你将命令和YAML文件发送到托管在管理员上的API，所有的调度和监控都由管理员完成。工人通常只在管理员调度时运行容器，并报告其状态，尽管你也可以让管理员运行工作负载（在这里插入你自己的笑话，将其与人类管理员进行比较）。
- en: Initializing the Swarm is something you do once, and then you can join any number
    of machines--Docker calls machines in the Swarm nodes. To join a node to the Swarm,
    it needs to be on the same network, and you need the join token from the manager,
    which acts like a password to secure the Swarm from rogue nodes. If you have access
    to the manager, you can print out the tokens for nodes to join as workers or additional
    managers, and you can list the nodes in the swarm.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化Swarm是一次性完成的，然后你可以加入任意数量的机器——Docker将Swarm中的机器称为节点。要将节点加入Swarm，它需要处于同一网络中，并且你需要管理员的加入令牌，这就像是一个密码，用于保护Swarm免受恶意节点的侵害。如果你可以访问管理员，你可以打印出节点加入作为工作节点或额外管理员的令牌，并且你可以列出Swarm中的节点。
- en: 'Try it now Once you’re in Swarm mode, there are a lot more commands available
    from the Docker CLI. Run these to find the join tokens for worker or manager nodes,
    and to list all the nodes in the Swarm:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在就试试看吧！一旦进入Swarm模式，Docker CLI将提供更多命令。运行这些命令以找到工作节点或管理节点的加入令牌，并列出Swarm中的所有节点：
- en: '` # print the command to join a new worker node` ` docker swarm join-token
    worker`  ` # print the command to join a new manager node` ` docker swarm join-token
    manager`  ` # list all the nodes in the swarm` ` docker node ls`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 打印加入新工作节点命令` ` docker swarm join-token worker`  ` # 打印加入新管理节点命令` ` docker
    swarm join-token manager`  ` # 列出Swarm中的所有节点` ` docker node ls`'
- en: You can see my output in figure 12.4\. There’s only one node in my Swarm, but
    I can add any other machines on my network to the Swarm using the manager’s IP
    address in the `join` command.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图12.4中看到我的输出。我的Swarm中只有一个节点，但我可以使用`join`命令中的管理员的IP地址将网络上的任何其他机器添加到Swarm中。
- en: '![](../Images/12-4.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-4.jpg)'
- en: Figure 12.4 In Swarm mode you have extra commands to manage the nodes in the
    cluster.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 在Swarm模式下，你可以使用额外的命令来管理集群中的节点。
- en: A single-node Swarm works in exactly the same way as a multi-node Swarm, except
    that you don’t get high availability from having spare machines, or the option
    to scale out containers to use the capacity of many machines. Figure 12.5 compares
    the architecture of a single-node Swarm, which you can use for development and
    test environments, and a multi-node cluster, which you would use in production.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 单节点Swarm的工作方式与多节点Swarm完全相同，只是你没有从备用机器中获得高可用性，或者将容器扩展到多个机器以使用其容量的选项。图12.5比较了单节点Swarm的架构，你可以用于开发和测试环境，以及多节点集群，你会在生产中使用。
- en: '![](../Images/12-5.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-5.jpg)'
- en: Figure 12.5 Test and production Swarms have different numbers of nodes, but
    the same feature set.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 测试和生产Swarm具有不同数量的节点，但具有相同的功能集。
- en: One of the big advantages of Docker Swarm over Kubernetes is the simplicity
    of setting up and managing the cluster. You can build a Swarm with dozens of nodes
    just by installing Docker on every server, running `docker` `swarm` `init` once,
    and `docker` `swarm` `join` for all the other nodes. There’s no hidden complexity--the
    process is the same for production and test environments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm相对于Kubernetes的一个重大优势是集群设置和管理的简单性。你只需在每个服务器上安装Docker，运行一次`docker
    swarm init`，然后对其他所有节点运行`docker swarm join`，就可以构建一个包含数十个节点的Swarm。没有隐藏的复杂性——生产环境和测试环境的过程是相同的。
- en: Now that you have your single-node Swarm, you can explore how applications work
    when you have an orchestrator managing containers for you.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了单节点Swarm，你可以探索当有编排器为你管理容器时应用程序是如何工作的。
- en: 12.3 Running applications as Docker Swarm services
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 以Docker Swarm服务运行应用程序
- en: 'You don’t run containers in Docker Swarm--you deploy services, and the Swarm
    runs containers for you. A service is just an abstraction over the idea of individual
    containers. Swarm uses the same terminology here as Docker Compose for the same
    reason: a service could be deployed as multiple containers.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在Docker Swarm中，你不会直接运行容器——你部署服务，Swarm会为你运行容器。服务只是对单个容器概念的抽象。Swarm在这里使用与Docker
    Compose相同的术语，原因相同：服务可以部署为多个容器。
- en: Services are defined with a lot of the same information you use to run containers.
    You specify the image to use, environment variables to set, ports to publish,
    and a name for the service that becomes its DNS name on the network. The difference
    is that a service can have many replicas--individual containers that all use the
    same specification from the service and can be run on any node in the Swarm.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 服务定义中包含了很多你用来运行容器时使用的信息。你指定要使用的镜像、要设置的环境变量、要发布的端口以及服务的名称，该名称将成为网络上的DNS名称。区别在于，一个服务可以有多个副本——这些副本是使用服务相同规范的单个容器，可以在Swarm中的任何节点上运行。
- en: 'Try it now Create a service that runs one container using a simple application
    image from Docker Hub, and then list the services to check that it’s running correctly:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：创建一个运行一个容器的服务，使用来自Docker Hub的简单应用程序镜像，然后列出服务以检查其是否正确运行：
- en: '` docker service create --name timecheck --replicas 1 diamol/ch12-timecheck:1.0`
    ` docker service ls`'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '` docker service create --name timecheck --replicas 1 diamol/ch12-timecheck:1.0`
    ` docker service ls`'
- en: Services are first-class objects in Docker Swarm, but you need to be running
    in Swarm mode--or be connected to a Swarm manager--to work with them. My output
    is in figure 12.6, where you can see that the service gets created and the basic
    details are shown from the service list command, which shows there is one replica
    running.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在Docker Swarm中，服务是一等对象，但你需要运行在Swarm模式下——或者连接到Swarm管理器——才能与之交互。我的输出如图12.6所示，你可以看到服务被创建，并且从服务列表命令中显示了基本详情，显示有一个副本正在运行。
- en: '![](../Images/12-6.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-6.jpg)'
- en: Figure 12.6 Creating a service is how you ask the Swarm to run containers for
    you.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 创建服务是请求Swarm为你运行容器的做法。
- en: The containers that make up a service are called replicas, but they’re just
    ordinary Docker containers. You can connect to the node that’s running a replica
    and work with it using the usual Docker container commands. On a single-node Swarm,
    every replica will run on that machine, so you can work with the service container
    you just created. It’s not something you would normally do, though, because the
    containers are being managed by the Swarm. If you try to manage them yourself,
    what happens may not be what you expect.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 构成服务的容器被称为副本，但它们只是普通的Docker容器。你可以连接到运行副本的节点，并使用常规的Docker容器命令与之交互。在单节点Swarm中，每个副本都会在该机器上运行，因此你可以与刚刚创建的服务容器一起工作。尽管如此，这通常不是你想要做的事情，因为容器是由Swarm管理的。如果你尝试自己管理它们，结果可能不会如你所预期。
- en: Try it now The service replica is running on your machine, but it’s being managed
    by the Swarm. You can delete the container, but the Swarm will see that the service
    is running below the desired replica count, and it will create a replacement.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：服务副本正在你的机器上运行，但它由Swarm管理。你可以删除容器，但Swarm会看到服务的副本数低于期望值，并将创建一个替代品。
- en: '` # list the replicas for the service:` ` docker service ps timecheck`  ` #
    check the containers on the machine:` ` docker container ls`  ` # remove the most
    recent container (which is the service replica):` ` docker container rm -f $(
    docker container ls --last 1 -q)`  ` # check the replicas again:` ` docker service
    ps timecheck`'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 列出服务的副本：` ` docker service ps timecheck`  ` # 检查机器上的容器：` ` docker container
    ls`  ` # 删除最新的容器（即服务副本）：` ` docker container rm -f $( docker container ls --last
    1 -q)`  ` # 再次检查副本：` ` docker service ps timecheck`'
- en: You can see my output in figure 12.7\. I had one container running the replica
    for my service, and I manually removed it. But the service still exists in the
    Swarm, and it should have a replica level of one. When I removed the container,
    the Swarm saw there weren’t enough replicas running, and it started a replacement.
    You see in the final replica list that the original container is shown as failed,
    because the Swarm doesn’t know why the container stopped. The running replica
    is a new container that has only been up for 10 seconds.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图12.7中看到我的输出。我有一个容器正在运行我的服务的副本，我手动将其删除。但是服务仍然存在于Swarm中，并且它应该有一个副本级别为1。当我删除容器时，Swarm看到运行的副本不足，并启动了一个替换。你在最终的副本列表中看到原始容器被显示为失败，因为Swarm不知道容器停止的原因。正在运行的副本是一个只运行了10秒的新容器。
- en: '![](../Images/12-7.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图12.7](../Images/12-7.jpg)'
- en: Figure 12.7 Service replicas are normal containers, but they’re managed by the
    Swarm--not by you.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 服务副本是普通容器，但它们是由Swarm管理的——而不是由你管理。
- en: When you’re running in Swarm mode, you manage your applications as services,
    and you let the Swarm manage individual containers. That has to be the case because
    it would be unmanageable to manage containers yourself--you’d have to connect
    to each of the nodes in the Swarm, find out if it’s running any replicas for your
    service, and work with the containers directly if you wanted to check the status
    or print out logs. Docker supports you by providing commands that operate on the
    Swarm resources. You can use `docker` `service` commands to print out log entries
    from all the replicas and to inspect the service to read its specification.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在Swarm模式下运行时，你将你的应用程序作为服务来管理，并且让Swarm管理单个容器。这必须是这样，因为自己管理容器是不可管理的——你不得不连接到Swarm中的每个节点，找出它是否运行了你的服务的副本，如果你想要检查状态或打印日志，你还需要直接与容器打交道。Docker通过提供操作Swarm资源的命令来支持你。你可以使用`docker`
    `service`命令来打印出所有副本的日志条目，并检查服务以读取其规范。
- en: 'Try it now The `docker` `service` commands are how you should work with applications
    in Swarm mode. You can get information from the replicas, like all the log entries,
    and information about the service as a whole:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 The `docker` `service`命令是你在Swarm模式下应该使用的方式来处理应用程序。你可以从副本中获取信息，比如所有的日志条目，以及关于整个服务的相关信息：
- en: '` # print the service logs for the last 10 seconds:` ` docker service logs
    --since 10s timecheck`  ` # get the service details, showing just the image:`
    ` docker service inspect timecheck -f ''{{.Spec.TaskTemplate.ContainerSpec.Image}}''`'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 打印过去10秒的服务日志:` ` docker service logs --since 10s timecheck`  ` # 获取服务详情，仅显示镜像:`
    ` docker service inspect timecheck -f ''{{.Spec.TaskTemplate.ContainerSpec.Image}}''`'
- en: My output is in figure 12.8\. It shows the most recent log entries from the
    service replicas and part of the service specification.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我的输出在图12.8中。它显示了服务副本的最新日志条目以及部分服务规范。
- en: '![](../Images/12-8.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图12.8](../Images/12-8.jpg)'
- en: Figure 12.8 You work with the service as a single unit to print out replica
    logs or check the specification.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 你将服务作为一个单一单元来打印副本日志或检查规范。
- en: The whole specification is saved in the cluster, and you can see it by running
    that same `service` `inspect` command but without the format parameter. There’s
    a lot of information there, securely stored in the cluster’s database, which is
    replicated across all the manager nodes. This is one of the big differences between
    Docker Swarm and Docker Compose, which doesn’t have a data store for application
    definitions. You can only manage applications with Docker Compose if you have
    the Compose file(s) available, because that’s the source of the app definition.
    In Swarm mode the app definition is stored in the cluster, so you can manage apps
    without a local YAML file.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 整个规范保存在集群中，你可以通过运行相同的`service` `inspect`命令（但不带格式参数）来查看它。那里有很多信息，安全地存储在集群数据库中，该数据库在所有管理节点之间进行了复制。这是Docker
    Swarm和Docker Compose之间的一大区别，因为Docker Compose没有用于应用程序定义的数据存储。只有当你有可用的Compose文件时，你才能使用Docker
    Compose来管理应用程序，因为那是应用程序定义的来源。在Swarm模式下，应用程序定义存储在集群中，因此你可以不使用本地YAML文件来管理应用程序。
- en: You can try that by updating your running service. You can specify a new image
    version, but you don’t need to repeat any of the other information from the service
    spec. This is how you deploy application updates in the cluster. When you update
    the service definition, Swarm rolls out the change, replacing the replicas by
    removing the old containers and starting new ones.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过更新正在运行的服务来尝试此操作。您可以指定新的镜像版本，但不需要重复服务规范中的任何其他信息。这就是在集群中部署应用程序更新的方法。当您更新服务定义时，Swarm会推出更改，通过移除旧容器并启动新的容器来替换副本。
- en: 'Try it now Update the timecheck service to use a new image version. It’s the
    same simple app that writes a timestamp every few seconds, but the update prints
    a new application version in the logs:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：将timecheck服务更新为使用新的镜像版本。这是一个简单的应用程序，每隔几秒写入一个时间戳，但更新会在日志中打印新的应用程序版本：
- en: '` # update the service to use a new application image:` ` docker service update
    --image diamol/ch12-timecheck:2.0 timecheck`  ` # list the service replicas:`
    ` docker service ps timecheck`  ` # and check the logs:` ` docker service logs
    --since 20s timecheck`'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 更新服务以使用新的应用程序镜像:` ` docker service update --image diamol/ch12-timecheck:2.0
    timecheck`  ` # 列出服务副本:` ` docker service ps timecheck`  ` # 并检查日志:` ` docker
    service logs --since 20s timecheck`'
- en: You’ll see when you list the replicas with `service` `ps` that there are two
    instances--the old replica running from the image tag 1.0, and the replacement
    running from the image tag 2.0\. Service logs include an ID so you can see which
    replica produces the log entries. These are just the application logs being written
    out to the container, collected by the Swarm and shown with the replica ID. You
    can see mine in figure 12.9.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用`service ps`列出副本时，您会看到有两个实例--一个是从镜像标签1.0运行的旧副本，另一个是从镜像标签2.0运行的替换副本。服务日志包括一个ID，这样您就可以看到哪个副本产生了日志条目。这些只是被写入容器的应用程序日志，由Swarm收集，并带有副本ID显示出来。您可以在图12.9中看到我的示例。
- en: '![](../Images/12-9.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-9.jpg)'
- en: Figure 12.9 Updating a service starts a gradual rollout of a new application
    version.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 显示了更新服务开始逐步推出新的应用程序版本。
- en: All container orchestrators use the approach of staged rollouts for application
    updates, which keeps your app online during the upgrade. Swarm implements this
    by replacing replicas one at a time, so if you have multiple replicas hosting
    your application, there are always containers running to service incoming requests.
    The actual behavior of the rolling upgrade can be configured for your individual
    service. You might have 10 replicas providing your web application, and when you
    roll out an upgrade you could have Docker replace two replicas at a time, checking
    that the new containers are healthy before moving on to replace the next two replicas,
    until all 10 are replaced.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 所有容器编排器都使用分阶段推出的方法来更新应用程序，这可以在升级期间保持您的应用程序在线。Swarm通过一次替换一个副本来实现这一点，所以如果您有多个副本托管您的应用程序，总有容器在运行以处理传入的请求。实际滚动升级的行为可以为您自己的服务进行配置。您可能有10个副本提供您的Web应用程序，当您推出升级时，Docker可以一次替换两个副本，在替换下一个两个副本之前检查新容器是否健康，直到所有10个副本都被替换。
- en: Figure 12.10 shows how that rolling upgrade looks when it’s partway through
    the deployment--some replicas are running the old version of the application image
    and some are running the new one. During the rollout, both versions of your app
    are live and users could hit either one--you need to manage the user experience
    side of the update yourself.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.10显示了在部署过程中滚动升级的外观--一些副本正在运行应用程序镜像的旧版本，而一些副本正在运行新版本。在推出过程中，您的应用程序的两个版本都是活跃的，用户可能会击中任何一个--您需要自己管理更新的用户体验方面。
- en: '![](../Images/12-10.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-10.jpg)'
- en: Figure 12.10 Service updates are incremental in Docker Swarm and Kubernetes.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.10 显示了在Docker Swarm和Kubernetes中，服务更新是增量进行的。
- en: Automated rolling updates are a huge improvement on manual application releases,
    and they’re another feature for supporting self-healing applications. The update
    process checks that new containers are healthy as it is rolling them out; if there’s
    a problem with the new version, and the containers are failing, the update can
    be automatically paused to prevent breaking the whole application. Swarm also
    stores the previous specification of a service in its database, so if you need
    to manually roll back to the previous version, you can do that with a single command.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 自动滚动更新是手动应用发布的一个巨大改进，并且它是支持自愈应用的另一个特性。在滚动部署新容器的同时，更新过程会检查这些新容器是否健康；如果新版本存在问题，并且容器正在失败，更新可以自动暂停以防止整个应用崩溃。Swarm还会将其数据库中存储的服务的上一个版本规格，因此如果您需要手动回滚到上一个版本，您只需一个命令即可完成。
- en: 'Try it now You normally manage app deployments with YAML files, but if you
    have a deployment go wrong, it’s very useful just to roll back to the previous
    state. Docker Swarm can do this because it stores the current and previous state
    of the service in its database:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 您通常使用YAML文件来管理应用部署，但如果部署出现错误，仅回滚到之前的状态就非常有用。Docker Swarm可以做到这一点，因为它将其数据库中存储了服务的当前和上一个状态：
- en: '` # rollback the previous update:` ` docker service update --rollback timecheck` 
    ` # list all the service replicas:` ` docker service ps timecheck`  ` # print
    the logs from all replicas for the last 25 seconds:` ` docker service logs --since
    25s timecheck`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 回滚上一个更新：` ` docker service update --rollback timecheck`  ` # 列出所有服务副本：`
    ` docker service ps timecheck`  ` # 打印所有副本过去25秒的日志：` ` docker service logs --since
    25s timecheck`'
- en: The rollback process works in the same way as the update process, with a staged
    rollout, but it uses the service specification from before the most recent update,
    so you don’t need to provide the image tag. That’s very useful if an update breaks
    the application in a way that Docker doesn’t notice, which could happen if you
    don’t have health checks or if your checks aren’t detailed enough. In that case,
    when you discover the app is broken, you just run the rollback command and you
    don’t need to frantically try and find the details of the previous service spec.
    My output is in figure 12.11, where you can see the replicas from all the deployments,
    and the service logs from the most recent replicas--the update to 2.0 and the
    rollback to 1.0.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 回滚过程与更新过程类似，采用分阶段部署，但它使用的是最近一次更新之前的服务的规格，因此您不需要提供镜像标签。这在更新以某种方式破坏了应用，而Docker没有注意到的情况下非常有用，这可能发生在您没有健康检查或检查不够详细的情况下。在这种情况下，当您发现应用已损坏时，只需运行回滚命令，您就不需要疯狂地尝试找到上一个服务规格的详细信息。我的输出如图12.11所示，您可以看到所有部署的副本，以及最近副本的服务日志——从2.0更新回滚到1.0。
- en: '![](../Images/12-11.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-11.jpg)'
- en: Figure 12.11 You can roll back a service update to return to the previous specification
    with one command.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.11 您可以使用一个命令回滚服务更新以返回到之前的规格。
- en: Services are the resources you manage when you’re in Swarm mode, rather than
    containers. There are some new types of resources you can manage too, but some
    of the key Docker resources work in the same way. When containers need to communicate
    in Swarm mode, they do it over Docker networks, and you publish ports to let external
    traffic into your application.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在Swarm模式下，您管理的是服务资源，而不是容器。您还可以管理一些新的资源类型，但一些关键的Docker资源以相同的方式工作。当容器需要在Swarm模式下进行通信时，它们通过Docker网络进行通信，并且您发布端口以允许外部流量进入您的应用。
- en: 12.4 Managing network traffic in the cluster
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 在集群中管理网络流量
- en: Networking in Swarm mode is standard TCP/IP, as far as the applications inside
    containers are concerned. Components look for each other by DNS name, the DNS
    server in Docker returns an IP address, and the container sends network traffic
    to that IP address. Ultimately the traffic is received by a container and it responds.
    In Swarm mode, the container sending the request and the container sending the
    response could be running on different nodes, but that’s all transparent to the
    containers and the applications inside.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在Swarm模式下，对于容器内的应用而言，网络是标准的TCP/IP。组件通过DNS名称相互查找，Docker中的DNS服务器返回一个IP地址，容器将网络流量发送到该IP地址。最终，流量被一个容器接收并响应。在Swarm模式下，发送请求的容器和发送响应的容器可能运行在不同的节点上，但对于容器以及容器内的应用来说，这一切都是透明的。
- en: There’s all sorts of clever networking logic happening behind the scenes to
    make cross-cluster communication seamless, but you don’t need to dig into any
    of that because it All Just Works. Swarm mode provides a new type of Docker network
    called the overlay network. It’s a virtual network that spans all the nodes in
    the cluster, and when services are attached to an overlay network, they can communicate
    with each other using the service name as the DNS name.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后发生着各种巧妙的网络逻辑，以使跨集群通信无缝，但你不需要深入研究任何这些，因为“一切正常工作”。Swarm 模式提供了一种新的 Docker 网络类型，称为覆盖网络。这是一个跨越集群中所有节点的虚拟网络，当服务附加到覆盖网络时，它们可以使用服务名称作为
    DNS 名称相互通信。
- en: Figure 12.12 shows how that works with two overlay networks supporting different
    applications, where each application runs across multiple services on many nodes.
    The overlay network allows services to communicate when they form part of the
    same application, but the networks are isolated so services on different networks
    can’t access each other.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.12 展示了两个支持不同应用程序的覆盖网络如何工作，其中每个应用程序在许多节点上的多个服务上运行。覆盖网络允许服务在形成同一应用程序的一部分时进行通信，但网络是隔离的，因此不同网络上的服务无法相互访问。
- en: '![](../Images/12-12.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12-12.jpg)'
- en: Figure 12.12 Networks in the Swarm span the whole cluster and still provide
    isolation between apps.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.12 Swarm 中的网络覆盖整个集群，同时仍为应用程序提供隔离。
- en: There’s one other difference with services on overlay networks, compared to
    containers on ordinary Docker networks. You’ve seen in chapter 7 that you can
    use Docker Compose to scale up and run many instances of a container for a single
    Compose service. A DNS query to Docker for that Compose service will return the
    IP addresses for all the containers, and it will rely on the consumer to pick
    one to send the traffic to. That doesn’t scale well when you have hundreds of
    replicas in a Swarm service, so overlay networks use a different approach and
    return a single virtual IP address for the service.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 与普通 Docker 网络上的容器相比，覆盖网络上的服务还有一个不同之处。你在第 7 章中看到，你可以使用 Docker Compose 来扩展并运行单个
    Compose 服务的一个容器实例的多个实例。对该 Compose 服务的 Docker 进行 DNS 查询将返回所有容器的 IP 地址，并且它将依赖于消费者选择一个来发送流量。当你有一个
    Swarm 服务中有数百个副本时，这并不容易扩展，因此覆盖网络采用不同的方法，并为服务返回一个单独的虚拟 IP 地址。
- en: Try it now Let’s remove the simple app from the previous exercises and create
    a network and the API services for the NASA image of the day application we’ve
    used in previous chapters.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下。让我们从之前的练习中删除简单的应用程序，并为我们在前几章中使用过的 NASA 每日图像应用程序创建网络和 API 服务。
- en: '` # remove the original app:` ` docker service rm timecheck` ` # create an
    overlay network for the new app:` ` docker network create --driver overlay iotd-net`
    ` # create the API service, attaching it to the network:` ` docker service create
    --detach --replicas 3 --network iotd-net --name iotd diamol/ch09-image-of-the-day`
    ` # and the log API, attached to the same network:` ` docker service create --detach
    --replicas 2 --network iotd-net --name accesslog diamol/ch09-access-log` ` # check
    the services:` ` docker service ls`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 删除原始应用程序：` ` docker service rm timecheck` ` # 为新应用程序创建覆盖网络：` ` docker network
    create --driver overlay iotd-net` ` # 创建 API 服务，将其附加到网络：` ` docker service create
    --detach --replicas 3 --network iotd-net --name iotd diamol/ch09-image-of-the-day`
    ` # 以及日志 API，附加到同一网络：` ` docker service create --detach --replicas 2 --network
    iotd-net --name accesslog diamol/ch09-access-log` ` # 检查服务：` ` docker service
    ls`'
- en: Now you have services running the NASA image of the day APIs, and the services
    are attached to an overlay network. There are three replicas running the image
    API service and two running the access log service, as you can see from my output
    in figure 12.13\. This is still running on my single-node Swarm using Docker Desktop,
    but I could run the same set of commands on a Swarm with 500 nodes and the output
    would be the same--except that the replicas would be running on different nodes.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你正在运行 NASA 每日图像 API 服务，并且这些服务附加到了覆盖网络上。正如你在图 12.13 的输出中可以看到的那样，有三个副本正在运行图像
    API 服务，两个副本正在运行访问日志服务。这仍然是在我的单节点 Swarm 上使用 Docker Desktop 运行的，但我可以在有 500 个节点的
    Swarm 上运行相同的命令集，输出将相同——只是副本将在不同的节点上运行。
- en: '![](../Images/12-13.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/12-13.jpg)'
- en: Figure 12.13 Running services in Swarm mode and connecting them to an overlay
    network
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.13 在 Swarm 模式下运行服务并将它们连接到覆盖网络
- en: The easiest way to see the virtual IP address (this is called VIP networking)
    is to connect to a terminal session in any of the container replicas. You can
    run some network commands to perform DNS queries on the service names and check
    what IP addresses are returned.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看虚拟IP地址（这称为VIP网络），最简单的方法是连接到任何容器副本的终端会话。您可以通过运行一些网络命令来对服务名称执行DNS查询，并检查返回的IP地址。
- en: 'Try it now Execute an interactive terminal session in the most recent container,
    and run DNS lookups for the API services. The first commands are different for
    Linux and Windows containers, but once you’re connected to the terminal in the
    container, they’re the same:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：在最新的容器中执行一个交互式终端会话，并运行API服务的DNS查找。对于Linux和Windows容器，前几个命令是不同的，但一旦您连接到容器中的终端，它们就是相同的：
- en: '` # run a terminal session - Windows containers:` ` docker container exec -it
    $(docker container ls --last 1 -q) cmd`  ` # OR on Linux containers:` ` docker
    container exec -it $(docker container ls --last 1 -q) sh`  ` # run DNS lookups:`
    ` nslookup iotd` ` nslookup accesslog`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 运行终端会话 - Windows容器：` ` docker container exec -it $(docker container ls
    --last 1 -q) cmd`  ` # 或者Linux容器：` ` docker container exec -it $(docker container
    ls --last 1 -q) sh`  ` # 运行DNS查找：` ` nslookup iotd` ` nslookup accesslog`'
- en: You can see from my output in figure 12.14 that there is a single IP address
    for each of the services, even though there are multiple containers running those
    services. The service IP address is a virtual IP address that is shared across
    all the replicas.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从图12.14中的我的输出中看到，每个服务都有一个单独的IP地址，即使有多个容器运行这些服务。服务IP地址是一个虚拟IP地址，它在所有副本之间共享。
- en: '![](../Images/12-14.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图12-14](../Images/12-14.jpg)'
- en: Figure 12.14 Services use VIP networking, so there’s a single IP address for
    any number of replicas.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.14：服务使用VIP网络，因此无论有多少副本，都有一个单独的IP地址。
- en: This is VIP networking, which is supported in Linux and Windows and is a much
    more efficient way to load-balance network traffic. There is a single IP address
    from the DNS lookup, which stays constant even when the service is scaled up or
    down. Clients send traffic to that IP address, and the networking layer in the
    operating system discovers there are actually multiple destinations for the address,
    and it decides which one to use.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是VIP网络，它在Linux和Windows上得到支持，是一种更有效的负载均衡网络流量的方式。DNS查找只有一个IP地址，即使服务扩展或缩减，这个地址也保持不变。客户端将流量发送到该IP地址，操作系统的网络层发现实际上有多个地址目标，并决定使用哪一个。
- en: Docker Swarm uses VIP networking between services to provide reliable and load-balanced
    access to services. You only need to know that because it’s useful if you’re trying
    to debug communication issues--otherwise you might run a DNS lookup for a service
    with many replicas and be surprised to see a single IP address returned. Applications
    running as Swarm services just use DNS names in the usual way, so the complexity
    of the overlay network is completely hidden.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm使用VIP网络在服务之间提供可靠和负载均衡的访问。您只需要知道这一点，因为如果您正在尝试调试通信问题，这会很有用——否则，您可能会对具有许多副本的服务运行DNS查找，并惊讶地看到一个IP地址返回。作为Swarm服务运行的应用程序将像往常一样使用DNS名称，因此覆盖网络的复杂性完全被隐藏。
- en: Swarm mode takes that same approach of simplifying complex network patterns
    to handle traffic coming into the cluster. This is a much more complicated problem,
    if you think about the scale of the cluster and the scale of your application.
    You might have a web app running with 10 replicas. If there are 20 nodes in your
    cluster, some nodes aren’t running any of your web containers, and the Swarm needs
    to direct requests to nodes that are running containers. If there are only five
    nodes in your cluster, each node will be running multiple replicas, and the Swarm
    needs to load-balance between containers on the node. Swarm uses ingress networking
    to deal with this--the diagram in figure 12.15 shows how the ingress works, with
    every node listening on the same port externally and Docker directing traffic
    internally within the cluster.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm模式采用简化复杂网络模式的方法来处理进入集群的流量。如果您考虑集群的规模和应用程序的规模，这是一个更复杂的问题。您可能有10个副本运行的Web应用程序。如果您的集群中有20个节点，一些节点没有运行您的任何Web容器，Swarm需要将请求定向到运行容器的节点。如果您的集群中只有五个节点，每个节点将运行多个副本，Swarm需要在节点上的容器之间进行负载均衡。Swarm使用入口网络来处理这个问题——图12.15中的图显示了入口的工作方式，每个节点在外部监听相同的端口，Docker在集群内部内部转发流量。
- en: '![](../Images/12-15.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图12-15](../Images/12-15.jpg)'
- en: Figure 12.15 Docker Swarm uses ingress networking to route traffic to containers
    on nodes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.15 Docker Swarm使用入口网络将流量路由到节点上的容器。
- en: Ingress networking is the default in Swarm mode when you publish ports for a
    service, so it’s the same as overlay networking--complex technology that is incredibly
    easy to use. You can publish ports when you create a service, and that’s all you
    need to do to make use of the ingress network.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 当您为服务发布端口时，入口网络是Swarm模式下的默认设置，所以它与overlay网络相同——这是一种复杂的技术，但使用起来却非常简单。您可以在创建服务时发布端口，这就是您需要做的全部事情来利用入口网络。
- en: 'Try it now The final component of the image gallery app is the website itself.
    When you run it as a Swarm service and publish the port, it uses the ingress network:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看图像库应用的最后一个组件就是网站本身。当您将其作为Swarm服务运行并发布端口时，它使用入口网络：
- en: '` # create the web front end for the app:` ` docker service create --detach
    --name image-gallery --network iotd-net --publish 8010:80 --replicas 2 diamol/ch09-image-gallery`
    ` # list all services:` ` docker service ls`'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 为应用创建Web前端：` ` docker service create --detach --name image-gallery --network
    iotd-net --publish 8010:80 --replicas 2 diamol/ch09-image-gallery` ` # 列出所有服务：`
    ` docker service ls`'
- en: Now you have a service with multiple replicas, listening on a single port. You’re
    not able to do this with Docker Compose because you can’t have several containers
    all listening on the same port, but you can in Docker Swarm because it’s the service
    that listens on the port using the ingress network. When a request comes in to
    the cluster, the ingress network sends it to one of the service replicas, which
    could be running on the node that received the request or a different node in
    the cluster. Figure 12.16 shows the service running with two replicas and the
    published port.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您有一个具有多个副本的服务，监听单个端口。您无法使用Docker Compose做到这一点，因为您不能让多个容器都监听相同的端口，但在Docker
    Swarm中可以，因为它是使用入口网络监听端口的那个服务。当一个请求进入集群时，入口网络会将它发送到服务的一个副本，这个副本可能运行在接收请求的节点上，也可能是集群中的另一个节点。图12.16显示了运行着两个副本并已发布端口的该服务。
- en: '![](../Images/12-16.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图12-16](../Images/12-16.jpg)'
- en: Figure 12.16 Enlisting a service in the ingress network is as simple as publishing
    a port.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.16 在入口网络中注册一个服务就像发布一个端口一样简单。
- en: You can browse to the port and you’ll see the NASA image app from chapter 4--unless
    you’re running Windows containers. I’ve managed to avoid any big differences for
    Windows and Linux readers up till now, other than the odd difference in commands,
    but there’s no getting around this one. If you’re running Linux containers--on
    a Linux machine or a Mac or with Linux container mode on Windows 10--you can go
    right ahead and browse to http:/ /localhost:8010 to see the app. If you’re running
    Windows containers--either on Windows Server or Windows container mode on Windows
    10--you can’t do that because Swarm services aren’t accessible using localhost.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以浏览到该端口，并看到第4章中的NASA图像应用——除非您正在运行Windows容器。到目前为止，我设法避免了Windows和Linux读者之间任何大的差异，除了命令的细微差别，但这个问题是无法回避的。如果您正在运行Linux容器——在Linux机器上、Mac上，或者在Windows
    10上的Linux容器模式下——您可以直接浏览到http://localhost:8010来查看该应用。如果您正在运行Windows容器——无论是在Windows
    Server上还是在Windows 10的容器模式下——您无法这样做，因为Swarm服务无法通过localhost访问。
- en: This is one of the few situations where Windows containers don’t work in the
    same way as Linux containers, and it’s down to limitations in the Windows networking
    stack. In practice, it’s not usually an issue because your Swarm clusters will
    be remote servers in test or production environments, and ingress networking does
    work when you access a remote machine. But on your local single-node Windows Swarm,
    you can only access services by browsing to them from a different machine. I know
    it’s not good, but at least we got 12 chapters in before we hit the “this sucks
    on Windows” moment, and I don’t think there are any more coming.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在Windows容器和Linux容器工作方式不完全相同的情况之一，这归因于Windows网络堆栈的限制。在实践中，这通常不是一个问题，因为您的Swarm集群将是测试或生产环境中的远程服务器，并且当您访问远程机器时，入口网络确实可以工作。但在您本地的单节点Windows
    Swarm上，您只能通过从不同的机器浏览来访问服务。我知道这并不好，但至少在我们遇到“Windows上这很糟糕”的时刻之前，我们已经有12章了，而且我认为不会再有更多了。
- en: I’ve switched to Linux containers for this chapter, and in figure 12.17 you
    can see the image of the day app. My network request is being routed to one of
    the two replicas for the web service, which is in turn fetching data from one
    of the three replicas for the API service.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我在本章中切换到了Linux容器，如图12.17所示，你可以看到day应用的镜像。我的网络请求被路由到web服务的两个副本之一，然后它会从API服务的三个副本之一获取数据。
- en: '![](../Images/12-17.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-17.jpg)'
- en: Figure 12.17 Published ports in services use the ingress network, and Swarm
    routes requests to replicas.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.17 服务中使用的发布端口使用ingress网络，Swarm将请求路由到副本。
- en: I’ve said it before in this chapter, but it’s coming once more to make it clear--the
    size of the cluster doesn’t matter as far as deploying and managing applications
    goes. I could run the exact same commands on a cluster running with 50 nodes in
    the cloud, and the result would be the same--two replicas of the web service that
    I can access from any node, working with three replicas of the API service that
    the web containers can access on any node.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我在本章中已经说过，但再次强调——就部署和管理应用程序而言，集群的大小并不重要。我可以在运行在云中50个节点的集群上运行完全相同的命令，结果将会相同——两个我可以从任何节点访问的web服务副本，以及web容器可以在任何节点上访问的三个API服务副本。
- en: 12.5 Understanding the choice between Docker Swarm and Kubernetes
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.5 理解Docker Swarm和Kubernetes之间的选择
- en: Docker Swarm was designed to be a simple container orchestrator. It took the
    concepts of networks and services from Docker Compose, which was already hugely
    popular, and built them into an orchestrator that became part of the Docker Engine.
    Other orchestrators have been released as commercial or open source projects,
    but most of those efforts have been shelved, and now the choice comes down to
    Docker Swarm and Kubernetes.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm被设计成一个简单的容器编排器。它从已经非常受欢迎的Docker Compose中吸取了网络和服务的概念，并将其构建成一个成为Docker
    Engine一部分的编排器。其他编排器作为商业或开源项目被发布，但其中大部分努力都已被搁置，现在选择就只剩下Docker Swarm和Kubernetes。
- en: Kubernetes is the more popular option because it’s offered as a managed service
    by all the major public clouds. You can spin up a multi-node Kubernetes cluster
    in Microsoft Azure, Amazon Web Services, or Google Cloud with just a single command
    from their CLI or a few clicks on their web portal. They take care of initializing
    the cluster--which is nothing like as simple as with Docker Swarm--and managing
    the virtual machines that are the nodes. Kubernetes is easily extensible, so the
    cloud providers can integrate it with their other products, like load balancers
    and storage, which make it easy to deploy full-featured applications.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是更受欢迎的选择，因为它被所有主要公共云提供商作为托管服务提供。您只需从它们的CLI或在其网络门户上点击几个按钮，就可以在Microsoft
    Azure、Amazon Web Services或Google Cloud中启动一个多节点Kubernetes集群。它们负责初始化集群——这并不像Docker
    Swarm那样简单——以及管理作为节点的虚拟机。Kubernetes易于扩展，因此云提供商可以将其与其其他产品（如负载均衡器和存储）集成，这使得部署功能齐全的应用程序变得容易。
- en: Docker Swarm doesn’t exist as a managed service from the cloud providers, partly
    because it has fewer moving parts, so its harder to integrate with other services.
    If you want to run a Docker Swarm cluster in the cloud, you’ll need to provision
    the VMs and initialize the Swarm yourself. It can all be automated, but it’s not
    as simple as using a managed service. Figure 12.18 shows the main cloud resources
    you’d need to provision and manage yourself if you wanted to run a Docker Swarm
    cluster in Azure.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm不是云提供商提供的托管服务，部分原因是因为它包含的组件较少，因此更难与其他服务集成。如果您想在云中运行Docker Swarm集群，您将需要自行配置虚拟机并初始化Swarm。所有这些都可以自动化，但并不像使用托管服务那样简单。图12.18显示了如果您想在Azure中运行Docker
    Swarm集群，您需要自行配置和管理的主要云资源。
- en: '![](../Images/12-18.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/12-18.jpg)'
- en: Figure 12.18 Just some of the cloud resources you have to manage for a production-grade
    Swarm
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.18 展示了您需要管理的部分云资源，以运行一个生产级别的Swarm。
- en: You’ll deploy clusters less often than you’ll deploy applications, though, and
    for ongoing operations, Docker Swarm is far simpler. It doesn’t have all the features
    of Kubernetes, but it has everything most organizations need with a fraction of
    the complexity of Kubernetes. The YAML you send to a Swarm cluster is an extension
    of the Docker Compose syntax, which is concise and logical. The Kubernetes YAML
    specification is far more complex and verbose, partly because of the additional
    resources Kubernetes supports. Both orchestrators ultimately have the job of running
    Docker containers, and they use the same Docker images, but the Kubernetes version
    of the app definition can easily involve 5 to 10 times as much YAML.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，您部署集群的频率将低于部署应用程序的频率，对于持续运营，Docker Swarm要简单得多。它没有Kubernetes的所有功能，但它拥有大多数组织所需的一切，而Kubernetes的复杂性却小得多。您发送到Swarm集群的YAML是Docker
    Compose语法的扩展，它简洁且逻辑性强。Kubernetes的YAML规范要复杂得多，部分原因是它支持了额外的资源。这两个编排器最终都有运行Docker容器的任务，并且使用相同的Docker镜像，但Kubernetes应用程序定义的版本可以包含5到10倍的YAML。
- en: 'My advice for teams who are new to orchestration is to start with Docker Swarm
    and move on to Kubernetes if they need a feature that Swarm doesn’t have. You
    have to make some investment in your apps to move them to Docker, and that investment
    isn’t wasted if you move to Kubernetes--you’ll be running containers from the
    same images. It’s not always a straightforward decision, though, and there are
    a few factors you’ll need to add in:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 对于刚开始使用编排的新团队，我的建议是先从Docker Swarm开始，如果需要Swarm没有的功能，再转向Kubernetes。您必须对您的应用程序进行一些投资才能将它们迁移到Docker，但如果转向Kubernetes，这些投资就不会浪费--您将运行来自相同镜像的容器。但这并不是一个简单的决定，您还需要考虑以下几个因素：
- en: Infrastructure --If you’re deploying to the cloud, Kubernetes is a simpler option,
    but if you’re in the datacenter, Swarm is far easier to manage. Also, if your
    team’s background is 100% Windows, you can use Swarm without taking on Linux.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施 -- 如果您要将应用程序部署到云端，Kubernetes是一个更简单的选择，但如果您在数据中心，Swarm则更容易管理。此外，如果您的团队背景是100%
    Windows，您可以使用Swarm而无需承担Linux的负担。
- en: Learning curve --Moving to Swarm is straightforward because it’s an extension
    of the Docker and Compose experience that you’ll already have. Kubernetes is a
    whole new set of things to learn, and not everyone on the team will make that
    investment.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习曲线 -- 转向Swarm很简单，因为它是对您已经拥有的Docker和Compose体验的扩展。Kubernetes是一套全新的学习内容，团队中并非每个人都会做出这种投资。
- en: Feature set --The complexity of Kubernetes is partly the result of it being
    hugely configurable. You can do things with Kubernetes that you can’t easily do
    in Swarm, like blue/green deployments, automatic service scaling, and role-based
    access control.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 功能集 -- Kubernetes的复杂性部分是由于它具有巨大的可配置性。您可以使用Kubernetes做Swarm中难以做到的事情，比如蓝/绿部署、自动服务扩展和基于角色的访问控制。
- en: Future investment --Kubernetes has one of the largest open source communities,
    and it’s extremely active. Changes and new features are coming all the time, whereas
    Swarm has been a stable product without large new features for a while now.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未来投资 -- Kubernetes拥有最大的开源社区之一，并且非常活跃。不断有变化和新功能出现，而Swarm已经是一个稳定的产品，一段时间以来没有推出大型新功能。
- en: Ultimately your roadmap will probably take you to Kubernetes, via Learn Kubernetes
    in a Month of Lunches, but there’s no rush to get there. Swarm is a great product
    that will introduce you to container orchestration in production and make it easy
    to run your workloads, however large they may be. Visa has talked at Docker’s
    conferences about using their Swarm cluster to power all the payments through
    their system, including huge spikes on Black Friday.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，您的路线图可能会通过《在一个月的午餐时间学习Kubernetes》带您走向Kubernetes，但到达那里并不急迫。Swarm是一个优秀的产品，它将向您介绍生产中的容器编排，并使运行工作负载变得容易，无论它们可能有多大。Visa在Docker的会议上谈到过使用他们的Swarm集群来支持他们系统中所有的支付，包括黑色星期五的巨大峰值。
- en: 12.6 Lab
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.6 实验室
- en: 'It’s a pretty simple lab this time, just to increase your experience working
    with applications running as Docker Swarm services. I’d like you to run the random
    number app from chapter 8 in your Swarm cluster. You’ll need two services and
    a network to connect them, and the services will need to be using these Docker
    images (which are on Docker Hub, so you don’t need to build them yourself):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这次实验室相当简单，只是为了增加您使用作为Docker Swarm服务的应用程序的工作经验。我希望您在Swarm集群中运行第8章中的随机数应用程序。您需要两个服务和连接它们的网络，并且这些服务需要使用以下Docker镜像（这些镜像在Docker
    Hub上，因此您不需要自己构建它们）：
- en: '`diamol/ch08-numbers-api:v3`'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`diamol/ch08-numbers-api:v3`'
- en: '`diamol/ch08-numbers-web:v3`'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`diamol/ch08-numbers-web:v3`'
- en: 'My solution is on GitHub in the usual place, but it’s only a few commands,
    so you shouldn’t really need to look: *[https://github.com/sixeyed/diamol/blob/master/ch12/
    lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch12/lab/README.md)*
    .'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我的解决方案在GitHub的常规位置，但只有几个命令，所以你实际上并不需要查找：*[https://github.com/sixeyed/diamol/blob/master/ch12/lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch12/lab/README.md)*。
