- en: Part 2\. Basic design pattern
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2部分\. 基本设计模式
- en: In this second part, you’ll learn how to design and code models using the procedural
    reuse design pattern. I will show you how simple and easy it is to apply procedural
    reuse, which is a fundamental principle in software engineering, to deep learning
    models. You’ll see how to decompose the model into its standard three components—stem,
    learner, and task—along with the interface between the components, and how to
    apply a procedural reuse pattern for coding each piece.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你将学习如何使用过程重用设计模式设计和编码模型。我将向你展示如何简单易行地将过程重用，这是软件工程中的一个基本原理，应用于深度学习模型。你将看到如何将模型分解为其标准三个组件——主干、学习者和任务——以及组件之间的接口，以及如何为每个部分应用过程重用模式。
- en: 'Next, you’ll see how to apply this design pattern to a variety of seminal state-of-the-art
    (SOTA) computer vision models as well as several examples from structured data
    and NLP. I’ll walk you through coding a progression of SOTA models, and cover
    their contributions to the development of deep learning: VGG, ResNet, ResNeXt,
    Inception, DenseNet, WRN, Xception, and SE-Net. Then we will turn our attention
    to mobile models for memory-constrained devices, such as a mobile phones or IoT
    sensors. We’ll look at the progression in design principles that were developed
    to make models run in memory-constrained devices, starting with MobileNet, then
    SqueezeNet and ShuffleNet. Again, we’ll code each of these mobile models with
    the procedural reuse design pattern, and then you’ll see how to deploy and serve
    these models using TensorFlow Lite.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将看到如何将这种设计模式应用于各种开创性的最先进（SOTA）计算机视觉模型以及一些结构化数据和NLP的示例。我将带你通过编码一系列SOTA模型，并涵盖它们对深度学习发展的贡献：VGG、ResNet、ResNeXt、Inception、DenseNet、WRN、Xception和SE-Net。然后我们将关注内存受限设备（如智能手机或物联网传感器）的移动模型。我们将探讨为使模型在内存受限设备上运行而开发的设计原则的进展，从MobileNet开始，然后是SqueezeNet和ShuffleNet。同样，我们将使用过程重用设计模式编码这些移动模型，然后你将看到如何使用TensorFlow
    Lite部署和提供这些模型。
- en: Most of the chapters in part 2 focus on models for supervised learning, where
    the data is labeled. But the final chapter introduces autoencoders, which do unsupervised
    learning—training a model with data that has not been labeled by a human. You
    learn to design and code autoencoders for compression, image denoising, super
    resolution, and pretext tasks.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 第2部分的大部分章节都专注于监督学习模型，其中数据被标记。但最后一章介绍了自动编码器，它进行无监督学习——用未由人类标记的数据训练模型。你将学习设计并编码用于压缩、图像去噪、超分辨率和预训练任务的自动编码器。
