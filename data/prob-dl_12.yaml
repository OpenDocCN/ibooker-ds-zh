- en: Glossary of terms and abbreviations
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语和缩写词表
- en: '| Abbreviation/Term | Definition/Meaning |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '| 缩写/术语 | 定义/含义 |'
- en: '| Aleatoric uncertainty | Data-inherent uncertainty that cannot be further
    reduced. For example, you can’t tell on which side a coin will land. |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '| 随机不确定性 | 无法进一步减少的数据固有的不确定性。例如，你无法预测硬币会落在哪一边。 |'
- en: '| API | Application programming interface. |'
  id: totrans-3
  prefs: []
  type: TYPE_TB
  zh: '| API | 应用程序编程接口。 |'
- en: '| Bayesian mantra | The posterior is proportional to the likelihood times the
    prior. |'
  id: totrans-4
  prefs: []
  type: TYPE_TB
  zh: '| 贝叶斯咒语 | 后验与似然乘以先验成正比。 |'
- en: '| BNN | Bayesian neural network. An NN with its weights replaced by distributions.
    Solved with VI or MC dropout. |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '| BNN | 贝叶斯神经网络。一种其权重被分布替换的神经网络。通过变分推断（VI）或蒙特卡洛dropout（MC dropout）来解决。 |'
- en: '| Bayesian probabilistic models | Probabilistic models that can state their
    epistemic uncertainty by characterizing all parameters of a distribution. |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| 贝叶斯概率模型 | 可以通过描述分布的所有参数来表示其认知不确定性的概率模型。 |'
- en: '| Bayesian view of statistics | In the Bayesian view of statistics, the parameters
    θ are not fixed but follow a distribution. |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| 贝叶斯统计学观点 | 在贝叶斯统计学的观点中，参数θ不是固定的，而是遵循一个分布。 |'
- en: '| Bayesian theorem | P(A&#124;B) = *P*(B&#124;A) · *P*(A) / *P*(B). This famous
    formula tells how to invert a conditional probability. |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 贝叶斯定理 | P(A|B) = *P*(B|A) · *P*(A) / *P*(B)。这个著名的公式说明了如何逆转条件概率。 |'
- en: '| Bayesian learning | P(θ &#124;*D*) = *P*(*D*&#124;θ ) · *P*(θ ) / *P*(*D*).
    This formula tells you how to determine the posterior *P*(θ &#124;*D*) from the
    likelihood *P*(*D*&#124;θ ), the prior *P*(θ ), and the marginal likelihood (a.k.a.
    evidence) *P*(*D*). It is a special form of the Bayesian theorem with *a* = θ
    and *b* = D, where θ is the parameters of a model and D the data. |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 贝叶斯学习 | P(θ|*D*) = *P*(*D*|θ) · *P*(θ) / *P*(*D*)。这个公式告诉你如何从似然*P*(*D*|θ)，先验*P*(θ)和边缘似然（也称为证据）*P*(*D*)中确定后验*P*(θ|*D*)。它是贝叶斯定理的一种特殊形式，其中*a*
    = θ，*b* = D，θ是模型的参数，D是数据。 |'
- en: '| Backpropagation | Method to efficiently calculate the gradients of the loss
    function with respect to (w.r.t.) the weights of an NN. |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 反向传播 | 一种高效计算损失函数相对于神经网络权重梯度的方法。 |'
- en: '| Bijector | TFP package for invertible (bijective) functions needed for normalizing
    flows (NF). |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| Bijector | TFP包中用于正则化流（NF）所需的可逆（双射）函数。 |'
- en: '| CIFAR-10 | A popular benchmark data set containing 60,000, 32 × 32 color
    images of 10 classes. |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-10 | 包含60,000个10类32 × 32彩色图像的流行基准数据集。 |'
- en: '| CNN | Convolutional neural network. An NN especially suited for vision applications.
    |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 卷积神经网络。一种特别适合视觉应用的神经网络。 |'
- en: '| Computational graph | A graph that encodes all calculations in an NN. |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 计算图 | 编码神经网络中所有计算的图。 |'
- en: '| Abbreviation/Term | Definition/Meaning |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 缩写/术语 | 定义/含义 |'
- en: '| CPD | Conditional probability distribution. We also sloppily call the density
    *P*(*y*&#124;*x*) of an outcome *y*(e.g., the age of a person) given some input
    *x*(e.g., the image of a person) a CPD. |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| CPD | 条件概率分布。我们也不严谨地称一个结果（例如，一个人的年龄）的密度*P*(*y*|*x*）（例如，一个人的图像）为给定某些输入（例如，一个人的图像）的CPD。
    |'
- en: '| Cross entropy | Another name for negative log likelihood (NLL) in classification
    tasks. |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 交叉熵 | 分类任务中负对数似然（NLL）的另一个名称。 |'
- en: '| Deterministic model | A non-probabilistic model that returns no distribution
    for the outcome but only one best guess. |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 确定性模型 | 一种非概率模型，它不返回结果分布，而只返回一个最佳猜测。 |'
- en: '| Dropout | Dropout refers to randomly deleting nodes in an NN. Dropout during
    training typically yields NNs that show reduced overfitting. Performing dropout
    also during test time (see MC dropout) is interpreted as an approximation of a
    BNN. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| Dropout | Dropout指的是随机删除神经网络中的节点。训练期间的Dropout通常会产生表现出较少过拟合的神经网络。在测试时间（参见MC
    dropout）期间执行Dropout也被解释为BNN的近似。 |'
- en: '| DL | Deep learning. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| DL | 深度学习。 |'
- en: '| Extrapolation | Leaves the range of data with which a model was trained.
    |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 外推法 | 超出模型训练数据范围。 |'
- en: '| Epistemic uncertainty | Uncertainty of the model caused by the uncertainty
    about the model parameters. This can, in principle, be reduced by providing more
    data. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 认知不确定性 | 由模型参数的不确定性引起的模型不确定性。原则上，可以通过提供更多数据来减少这种不确定性。 |'
- en: '| fcNN | Fully connected neural network. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| fcNN | 全连接神经网络。 |'
- en: '| Glow | A certain CNN network based on NF that generates realistic looking
    faces. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| Glow | 基于NF的特定CNN网络，用于生成逼真的面部。 |'
- en: '| ImageNet | A famous data set with 1 million labeled images of 1,000 classes.
    |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| ImageNet | 一个包含1,000个类别的1百万个标记图像的著名数据集。 |'
- en: '| Jacobian matrix | The Jacobian matrix of a multidimensional function or transformation
    in several variables is the matrix of all its first-order partial derivatives.
    |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 雅可比矩阵 | 多维函数或多个变量变换的雅可比矩阵是其所有一阶偏导数的矩阵。|'
- en: '| Jacobian determinant | The determinant of the Jacobian matrix. It is used
    to calculate the change in volume during transformations and is needed for NF.
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 雅可比行列式 | 雅可比矩阵的行列式。它用于计算变换过程中的体积变化，并且对于NF是必需的。|'
- en: '| Keras | Keras is a high-level NN API that we use in this book in conjunction
    with TensorFlow. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Keras | Keras是一个高级神经网络API，我们在本书中使用它配合TensorFlow。|'
- en: '| KL divergence | A kind of measure for the distance between two probability
    density functions (PDFs). |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| KL散度 | 一种衡量两个概率密度函数（PDFs）之间距离的度量。|'
- en: '| Likelihood | The probability *P*(*D*&#124;θ ) that sampling from a density
    specified by a parameter value θ produces the data. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 似然 | 从由参数值θ指定的密度函数中采样的概率P(D|θ)，即产生数据的概率。|'
- en: '| Loss function | A function that quantifies the badness of a model and that
    which is optimized during the training of a DL model. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 损失函数 | 一种量化模型不良程度的函数，以及在深度学习模型训练过程中优化的函数。|'
- en: '| MAE | Mean absolute error. The MAE is a performance measure that is computed
    as the mean of absolute values of the residuals. It is not sufficient to quantify
    the performance of probabilistic models (here the NLL should be used as performance
    measure). |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| MAE | 均绝对误差。MAE是一种性能度量，它是残差的绝对值的平均值。它不足以量化概率模型（这里应使用NLL作为性能度量）。|'
- en: '| MaxLike | Maximum likelihood. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| MaxLike | 最大似然。|'
- en: '| MaxLike learning | A likelihood-based method to determine the parameter values
    θ of a model (for example, the weight in an NN). The objective is to maximize
    the likelihood of the observed data *P*(*D*&#124;θ ). This corresponds to minimizing
    the NLL. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| MaxLike学习 | 一种基于似然的方法，用于确定模型的参数值θ（例如，神经网络中的权重）。目标是最大化观察数据的似然P(D|θ)。这对应于最小化NLL。|'
- en: '| ML | Machine learning. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| ML | 机器学习。|'
- en: '| MC dropout | Monte Carlo dropout. This refers to dropout during test time.
    A method that is interpreted as an approximation to a BNN. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| MC dropout | 摩尔卡洛dropout。这指的是测试时间中的dropout。这是一种被解释为贝叶斯神经网络（BNN）近似的方法。|'
- en: '| MNIST | More correctly, the MNIST database of handwritten digits. A data
    set of 60,000, 28 × 28 gray-scaled 10 classes (the digits 0-9). |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| MNIST | 更确切地说，是手写数字的MNIST数据库。一个包含60,000个28×28灰度10类（数字0-9）的数据集。|'
- en: '| MSE | Mean squared error. The MSE is a performance measure that is computed
    as the average of the squared residuals. It’s not sufficient to quantify the performance
    of probabilistic models (here the NLL should be used as a performance measure).
    |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| MSE | 均方误差。MSE是一种性能度量，它是残差的平方的平均值。它不足以量化概率模型（这里应使用NLL作为性能度量）。|'
- en: '| NF | Normalizing flow. NF is an NN-based method to fit complex probability
    distributions. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| NF | 归一化流。NF是一种基于神经网络的拟合复杂概率分布的方法。|'
- en: '| NLL | Negative log-likelihood. Used as a loss function when fitting probabilistic
    models. The NLL on the validation set is the optimal measure to quantify the prediction
    performance of a probabilistic model. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| NLL | 负对数似然。在拟合概率模型时用作损失函数。验证集上的NLL是量化概率模型预测性能的最佳度量。|'
- en: '| NN | Neural network. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| NN | 神经网络。|'
- en: '| Observed outcome | The observed outcome or *y**[i]* value that is measured
    for a certain instance i. In a probabilistic model, we aim to predict a CPD for
    *y*, based on some features that characterize the instance i. Sometimes *y**[i]*
    is also bewilderingly called the “true” value. We don’t like that expression because
    in the presence of aleatoric uncertainty, there is no true outcome. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 观察到的结果 | 对于某个实例i测量的观察到的结果或*y*[i]值。在概率模型中，我们旨在根据一些描述实例i的特征来预测*y*的条件概率分布。有时*y*[i]也被称为“真实”值。我们不赞成这种说法，因为在存在随机不确定性的情况下，没有真正的结果。|'
- en: '| PDF | Probability density function. The PDF is also sometimes referred to
    as probability density distribution. See CPD for a conditional version. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| PDF | 概率密度函数。PDF有时也被称为概率密度分布。参见CPD以了解条件版本。|'
- en: '| PixelCNN++ | A certain CNN model capturing the probability distribution of
    pixel values. The “++ version” uses advanced CPDs for performance. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| PixelCNN++ | 一种捕捉像素值概率分布的特定卷积神经网络模型。“++版本”使用高级条件概率分布（CPD）以提高性能。|'
- en: '| Posterior | The distribution *P*(θ &#124;*D*) of a parameter θ after seeing
    the data D. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| Posterior | 在看到数据 D 后参数 θ 的分布 *P*(θ |*D*)。|'
- en: '| Posterior predictive distribution | The CPD *P*(*y*&#124;*x*, *D*) given
    the data D that results from a Bayesian probabilistic model. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| Posterior predictive distribution | 给定数据 D，由贝叶斯概率模型产生的 CPD *P*(*y*|*x*, *D*)。|'
- en: '| Prediction interval | Interval in which a certain fraction of all data are
    expected, typically 95%. |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| Prediction interval | 预期包含所有数据中一定比例的区间，通常是 95%。|'
- en: '| Prior | The distribution *P*(θ ) that is assigned to a model parameter θ
    before seeing any data D. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| Prior | 在看到任何数据 D 之前分配给模型参数 θ 的分布 *P*(θ )。|'
- en: '| Probabilistic model | A model returning a distribution for the outcome. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| Probabilistic model | 返回结果分布的模型。|'
- en: '| Residuals | Differences between the observed value *y**[i]* and the deterministic
    model output yˆi (the expected value of the outcome). |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| Residuals | 观测值 *y**[i]* 与确定性模型输出 yˆi（结果的期望值）之间的差异。|'
- en: '| RMSE | Root mean squared error. The square root of the MSE. |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| RMSE | 均方根误差。均方误差的平方根。|'
- en: '| RealNVP | A specific NF model called real non-volume preserving. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| RealNVP | 一种称为真实非体积保持的特定 NF 模型。|'
- en: '| softmax | An activation function enforcing the output of the NN, which sums
    up to 1 and can be interpreted as a probability. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| softmax | 一种强制神经网络输出总和为 1 的激活函数，它可以被解释为概率。|'
- en: '| softplus | An activation function, which after its application, ensures positive
    values. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| softplus | 一种激活函数，应用后确保值为正。|'
- en: '| SGD | Stochastic gradient descent. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| SGD | 随机梯度下降。|'
- en: '| Tensor | Multidimensional array. This is the main data structure in DL. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Tensor | 多维数组。这是深度学习中的主要数据结构。|'
- en: '| TF | TensorFlow is a low-level library used in this book for DL. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| TF | TensorFlow 是本书中用于深度学习的低级库。|'
- en: '| The big lie of DL | The assumption *P*(train) = *P*(test), meaning that the
    test data stems from the same distributions as the training data. In many DL/ML
    applications, this is assumed but often not true. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| The big lie of DL | 假设 *P*(train) = *P*(test)，意味着测试数据来自与训练数据相同的分布。在许多深度学习/机器学习应用中，这被假设但往往并不真实。|'
- en: '| TFP | TensorFlow Probability. An add-on to TF facilitating probabilistic
    modeling of DL. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| TFP | TensorFlow Probability。一个用于促进深度学习概率建模的 TF 扩展。|'
- en: '| VGG16 | A traditional CNN with a specific architecture that ranked second
    place in the ImageNet competition in 2014\. It is often used with weights that,
    after training on the ImageNet data, extracted features from an image. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| VGG16 | 一种具有特定架构的传统卷积神经网络，在 2014 年 ImageNet 竞赛中排名第二。它通常与在 ImageNet 数据上训练后从图像中提取特征的权重一起使用。|'
- en: '| VI | Variational inference. A method for which it can be shown that it yields
    an approximation to a BNN. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| VI | 变分推断。一种可以证明它产生近似贝叶斯神经网络的方法。|'
- en: '| w.r.t. | Acronym meaning with respect to. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| w.r.t. | 缩写，意为“关于”。|'
- en: '| WaveNet | A specific NN model for text to speech. |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| WaveNet | 一种用于文本到语音的特定神经网络模型。|'
- en: '| ZIP | Zero-inflated Poisson. A special distribution for count data taking
    care of an excess of the value 0. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| ZIP | 零膨胀泊松分布。一种针对计数数据且关注值 0 过多的特殊分布。|'
