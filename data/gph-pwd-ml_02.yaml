- en: '1 Machine learning and graphs: An introduction'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 机器学习与图：简介
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: An introduction to machine learning
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: An introduction to graphs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图的简介
- en: The role of graphs in machine learning applications
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图在机器学习应用中的作用
- en: 'Machine learning is a core branch of artificial intelligence: it is the field
    of study in computer science that allows computer programs to learn from data.
    The term was coined in 1959, when Arthur Samuel, an IBM computer scientist, wrote
    the first computer program to play checkers [Samuel, 1959]. He had a clear idea
    in mind:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是人工智能的核心分支：它是计算机科学中研究计算机程序如何从数据中学习的领域。这个术语是在1959年提出的，当时IBM的计算机科学家亚瑟·塞缪尔（Arthur
    Samuel）编写了第一个玩跳棋的计算机程序[塞缪尔，1959]。他心中有一个明确的想法：
- en: '*Programming computers to learn from experience should eventually eliminate
    the need for much of this detailed programming effort.*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*编程计算机从经验中学习最终应该消除大部分这种详细的编程工作。*'
- en: Samuel wrote his initial program by assigning a score to each board position
    based on a fixed formula. This program worked quite well, but in a second approach,
    he had the program execute thousands of games against itself and used the results
    to refine the board scoring. Eventually, the program reached the proficiency of
    a human player, and machine learning took its first steps.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 塞缪尔通过为每个棋盘位置分配基于固定公式的分数来编写他的初始程序。这个程序工作得相当好，但在第二种方法中，他让程序与自己执行数千场比赛，并使用结果来细化棋盘评分。最终，程序达到了人类玩家的水平，机器学习迈出了第一步。
- en: An entity—such as a person, an animal, an algorithm, or a generic computer agent[¹](Ch01.htm#pgfId-1005999)—is
    *learning* if, after making observations about the world, it is able to improve
    its performance on future tasks. In other words, learning is the process of converting
    *experience* to *expertise* or knowledge [Shalev-Shwartz and Ben-David, 2014].
    Learning algorithms use training data that represents experience as input and
    create expertise as output. That output can be a computer program, a complex predictive
    model, or tuning of internal variables. The definition of performance depends
    on the specific algorithm or goal to be achieved; in general, we consider it to
    be the extent to which the prediction matches specific needs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一个实体——如人、动物、算法或通用计算机代理[¹](Ch01.htm#pgfId-1005999)——如果在观察世界之后能够提高其在未来任务上的表现，那么它就是在*学习*。换句话说，学习是将*经验*转化为*专业知识*或知识的过程[沙莱夫-舒瓦茨和本-大卫，2014]。学习算法使用代表经验的训练数据作为输入，并创建专业知识作为输出。这种输出可以是计算机程序、复杂的预测模型或内部变量的调整。性能的定义取决于特定的算法或要实现的目标；一般来说，我们认为它是预测与特定需求匹配的程度。
- en: Let’s describe the learning process with an example. Consider the implementation
    of a spam filter for emails. A pure programming solution would be to write a program
    to *memorize* all the emails labeled as spam by a human user. When a new email
    arrives, the pseudoagent will search for a similar match in the previous spam
    emails, and if it finds any matches, the new email will be rerouted to the trash
    folder. Otherwise, the email will pass through the filter untouched.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来描述学习过程。考虑实现电子邮件的垃圾邮件过滤器。一个纯粹的编程解决方案是编写一个程序来*记忆*由人类用户标记为垃圾邮件的所有电子邮件。当一封新电子邮件到达时，伪代理将在之前的垃圾邮件中搜索相似匹配，如果找到任何匹配项，新电子邮件将被重定向到垃圾文件夹。否则，电子邮件将未经修改地通过过滤器。
- en: 'This approach could work and, in some scenarios, be useful. Yet it is not a
    learning process because it lacks an important aspect of learning: the ability
    to generalize, to transform the individual examples into a broader model. In this
    specific use case, it means the ability to label unseen emails even though they
    are dissimilar to previously labeled emails. This process is also referred to
    as *inductive reasoning* or *inductive inference*.[²](Ch01.htm#pgfId-1006031)
    To generalize, the algorithm should scan the training data and extract a set of
    words whose appearance in an email message is indicative of spam. Then, for a
    new email, the agent would check whether one or more of the suspicious words appear
    and predict its label accordingly.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可能有效，在某些情况下可能有用。然而，它不是一个学习过程，因为它缺少学习的一个重要方面：概括的能力，将个别例子转化为更广泛模型的能力。在这个特定用例中，这意味着即使它们与之前标记的电子邮件不同，也能标记未见过的电子邮件。这个过程也被称为*归纳推理*或*归纳推理*。[²](Ch01.htm#pgfId-1006031)
    为了概括，算法应该扫描训练数据，提取一组在电子邮件消息中出现可指示垃圾邮件的单词。然后，对于一封新的电子邮件，代理会检查是否有可疑的单词出现，并据此预测其标签。
- en: 'If you are an experienced developer, you might be wondering, “Why should I
    write a program that learns how to program itself, when I can instruct the computer
    to carry out the task at hand?” Taking the example of the spam filter, it is possible
    to write a program that checks for the occurrence of some words and classifies
    an email as spam if those words are present. But this approach has three primary
    disadvantages:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一位经验丰富的开发者，你可能想知道：“为什么我要编写一个学习如何编程的程序，当我可以指示计算机执行当前任务时？”以垃圾邮件过滤器为例，可以编写一个程序来检查某些单词的出现，如果这些单词存在，则将电子邮件分类为垃圾邮件。但这种方法有三个主要缺点：
- en: A developer cannot anticipate all possible situations. In the spam-filter use
    case, all the words that might be used in a spam email cannot be predicted up
    front.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发者无法预见到所有可能的情况。在垃圾邮件过滤用例中，不能事先预测出可能用于垃圾邮件的所有单词。
- en: A developer cannot anticipate all changes over time. In spam emails, new words
    can be used, or techniques can be adopted to avoid easy recognition, such as adding
    hyphens or spaces between characters.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发者无法预见到所有随时间的变化。在垃圾邮件中，可能会使用新词，或者采用一些技术来避免容易被识别，例如在字符之间添加连字符或空格。
- en: Sometimes, a developer cannot write a program to accomplish the task. Even though
    recognizing the face of a friend is a simple task for a human, for example, it
    is impossible to program software to accomplish this task without the use of machine
    learning.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有时候，开发者无法编写程序来完成这项任务。例如，识别朋友的 faces 对于人类来说是一个简单的任务，但如果没有使用机器学习，编写软件来完成这个任务是不可能的。
- en: 'Therefore, when you face new problems or tasks that you would like to solve
    with a computer program, the following questions can help you decide whether to
    use machine learning:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当你面对新的问题或任务，希望用计算机程序来解决时，以下问题可以帮助你决定是否使用机器学习：
- en: Is the specific task too complex to be programmed?
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个特定任务是否过于复杂而无法编程？
- en: Does the task require any sort of adaptivity throughout its life?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任务的生命周期中是否需要任何形式的适应性？
- en: A crucial aspect of any machine learning task is the training data on which
    the knowledge is built. Starting from the wrong data leads to the wrong results,
    regardless of the potential performance or the quality of the learning algorithm
    used.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 任何机器学习任务的一个关键方面是构建知识所依赖的训练数据。从错误的数据开始会导致错误的结果，无论潜在的性能或学习算法的质量如何。
- en: 'The aim of this book is to help data scientists and data engineers approach
    the machine learning process from two sides: the *learning algorithm* and the
    *data*. In both perspectives, we will use the graph (let me introduce it now as
    a set of nodes and relationships connecting them) as a valuable mental and technological
    model. A lot of learning algorithms based on data represented as graphs can deliver
    efficient predictive models, and other algorithms can be improved by using either
    data represented as graphs or graph algorithms in the workflow. The use of graphs
    also provides many other benefits: graphics are a valuable storage model for representing
    knowledge from the input of the process, managing the training data, and storing
    the output of the predictive model, providing multiple ways to access it quickly.
    This book walks the reader through the entire machine learning project life cycle,
    showing step by step all cases in which graphs could be valuable and reliable
    friends.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的目的是帮助数据科学家和数据工程师从两个角度来接近机器学习过程：*学习算法*和*数据*。在这两个视角中，我们将使用图（我现在将其介绍为一组节点及其相互连接的关系）作为一个有价值的心理和技术模型。许多基于以图表示的数据的学习算法可以提供高效的预测模型，而其他算法可以通过使用以图表示的数据或在工作流程中使用图算法来改进。图的使用还提供了许多其他好处：图形是表示过程输入知识的有价值存储模型，管理训练数据，以及存储预测模型的输出，提供多种快速访问它的方式。这本书将引导读者通过整个机器学习项目生命周期，逐步展示所有可能有用和可靠的图案例。
- en: But graphs are not a panacea for all machine learning projects. In stream analytics,
    in which it is necessary to process a stream of data to reveal short-term anomalies,
    storing data in the form of a graph could be useless. Furthermore, other algorithms
    require data in a format that cannot fit in a graph, either during training or
    for model storage and access. This book gives the reader the capability to discern
    whether using a graph in the process would be an advantage or a burden.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 但图表并不是所有机器学习项目的万能药。在流分析中，需要处理数据流以揭示短期异常，以图表形式存储数据可能毫无用处。此外，其他算法需要的数据格式可能无法适应图表，无论是在训练期间还是模型存储和访问时。本书使读者能够判断在过程中使用图表是否会成为优势或负担。
- en: 1.1 Machine learning project life cycle
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 机器学习项目生命周期
- en: A machine learning project is a human process as well as a software project.
    It involves a large number of people, a lot of communication, a great deal of
    work, and a mixed set of skills, and it requires a well-defined approach to be
    effective. We’ll start our long journey by defining a workflow with clear steps
    and components that will be used throughout the book. The mental schema proposed
    here, which is one of many possible schemas, will help you better understand the
    role of graphs in the development and deployment of a successful machine learning
    project.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目既是一个人类过程，也是一个软件项目。它涉及大量人员、大量沟通、大量工作和一系列混合技能，并且需要一个明确的方法才能有效。我们将通过定义一个清晰的步骤和组件的流程来开始我们的漫长旅程，这些步骤和组件将在整本书中使用。这里提出的心理模型，即许多可能模型之一，将帮助您更好地理解图表在成功机器学习项目开发和部署中的作用。
- en: Delivering machine learning solutions is a complex process that requires more
    than selecting the right algorithm(s). Such projects include numerous tasks related
    to [Sculley, 2015]
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 提供机器学习解决方案是一个复杂的过程，它需要的不仅仅是选择正确的算法（s）。这些项目包括与[Sculley, 2015]相关的众多任务
- en: Selecting the data sources
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择数据源
- en: Gathering data
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集数据
- en: Understanding the data
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据
- en: Cleaning and transforming the data
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清洗和转换数据
- en: Processing the data to create ML models
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理数据以创建机器学习模型
- en: Evaluating the results
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估结果
- en: Deploying
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署
- en: After deployment, it is necessary to monitor the application and tune it. The
    entire process involves multiple tools, a lot of data, and different people.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 部署后，有必要监控应用程序并对其进行调整。整个过程涉及多个工具、大量数据和不同的人员。
- en: One of the most commonly used processes for data mining projects is the Cross-Industry
    Standard Process for Data Mining, or CRISP-DM [Wirth and Hipp, 2000]. Although
    the CRISP-DM model was designed for data mining, it can also be applied to generic
    machine learning projects. Key features of the CRISP-DM that make it attractive
    as part of the base workflow model are
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据挖掘项目中最常用的过程之一是跨行业标准数据挖掘流程，或称CRISP-DM [Wirth和Hipp, 2000]。尽管CRISP-DM模型是为数据挖掘设计的，但它也可以应用于通用的机器学习项目。CRISP-DM的关键特性使其成为基础工作流程模型的有吸引力的部分包括
- en: It is not proprietary.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不是专有的。
- en: It is application, industry, and tool neutral.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是应用、行业和工具中立的。
- en: It explicitly views the data analytics process from both an application-focused
    and a technical perspective.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它明确地从应用和技术两个角度来审视数据分析过程。
- en: This method can be used for project planning and management, for communicating,
    and for documentation purposes.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法可用于项目规划和管理、沟通以及文档编制。
- en: The CRISP-DM reference model offers an overview of the life cycle of a machine
    learning project. This schema or mental model helps in approaching the machine
    learning project from a data perspective before taking an algorithmic point of
    view and provides the baseline for the definition of a clear workflow. Figure
    1.1 shows the six phases of the process. It is worth noting that data is at the
    core of this process.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: CRISP-DM参考模型概述了机器学习项目生命周期。这个框架或心理模型有助于在从数据角度接近机器学习项目之前，从算法角度出发，并为定义清晰的流程提供基准。图1.1展示了过程的六个阶段。值得注意的是，数据是这个过程的核心。
- en: Looking at figure 1.1, we see that the sequence of the phases is fluid. The
    arrows indicate only the most important and frequent dependencies between phases;
    in a particular project, the outcome of each phase determines which phase, or
    which particular task of a phase, has to be performed next.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 观察图1.1，我们看到阶段的顺序是流动的。箭头仅表示阶段之间最重要的和最频繁的依赖关系；在特定项目中，每个阶段的成果决定了下一个要执行的阶段或阶段的具体任务。
- en: '![CH01_F01_Negro](../Images/CH01_F01_Negro.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F01_Negro](../Images/CH01_F01_Negro.png)'
- en: Figure 1.1 The six phases of the CRISP-DM process
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 CRISP-DM过程的六个阶段
- en: The outer circle symbolizes the cyclic nature of the process, which is not finished
    when a solution is deployed. Subsequent machine learning processes can benefit
    not only from the experiences of previous ones (the virtuous cycle of Linoff and
    Berry [2011]), but also from the outcomes of the previous processes. Let’s outline
    each phase in more detail.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 外圈符号表示过程的循环性质，解决方案部署后并不意味着结束。后续的机器学习过程不仅可以从先前过程的经验中受益（Linoff和Berry [2011] 的良性循环），还可以从先前过程的结果中受益。让我们更详细地概述每个阶段。
- en: 1.1.1 Business understanding
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 业务理解
- en: 'The first phase requires defining the goals of the machine learning project.
    These objectives are often expressed in general terms: increase revenue, improve
    the customer experience, get better and customized search results, sell more products,
    and so on. To convert these high-level problem definitions to concrete requirements
    and constraints for the machine learning project, it is necessary to understand
    the business and the domain.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 第一阶段需要定义机器学习项目的目标。这些目标通常用一般术语表达：增加收入、改善客户体验、获得更好的定制搜索结果、销售更多产品等等。为了将这些高级问题定义转换为机器学习项目的具体需求和约束，有必要了解业务和领域。
- en: Machine learning projects are software projects, and during this phase, it is
    also important to learn the language and domain concepts. This knowledge will
    not only help with communication between the data scientist and the internal team
    during subsequent phases, but also improve the quality of the documentation and
    the presentation of the results.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目是软件项目，在这个阶段，学习语言和领域概念也很重要。这种知识不仅有助于数据科学家在后续阶段与内部团队之间的沟通，还能提高文档和结果展示的质量。
- en: The outcomes of this phase are
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个阶段的结果是
- en: A clear understanding of the domain and the business perspective
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对领域和业务视角有清晰的理解
- en: A definition of the goals, requirements, and constraints
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义目标、需求和约束
- en: The conversion of this knowledge to a machine learning problem definition
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将这些知识转换为机器学习问题定义
- en: A preliminary and reasonable project plan designed to achieve the objectives
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个初步且合理的项目计划，旨在实现目标
- en: The goals of the first iteration shouldn’t be too broad, because this round
    requires a lot of effort related to the injection of the machine learning process
    into the existing infrastructure. At the same time, it is important to keep future
    extensions in mind while designing the first iteration.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 第一轮的目标不应该过于宽泛，因为这一轮需要大量与将机器学习过程注入现有基础设施相关的工作。同时，在设计第一轮时，也要考虑到未来的扩展。
- en: 1.1.2 Data understanding
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 数据理解
- en: 'The data-understanding phase starts by inquiring about the data sources and
    collecting some data from each of them, and proceeds with these activities:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 数据理解阶段首先从询问数据源开始，并从每个数据源收集一些数据，然后继续以下活动：
- en: Get familiar with the data.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熟悉数据。
- en: Identify data quality problems.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别数据质量问题。
- en: Get first insights into the data.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得对数据的初步洞察。
- en: Detect interesting subsets to form hypotheses about hidden information.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测有趣的子集，以形成关于隐藏信息的假设。
- en: Data understanding requires domain and business understanding. Moreover, looking
    at the data helps build understanding of the domain and the business perspective,
    which is why there is a feedback loop between this phase and the previous one.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据理解需要领域和业务理解。此外，查看数据有助于建立对领域和业务视角的理解，这就是为什么这个阶段和前一个阶段之间存在反馈循环。
- en: The outcomes of this phase are
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这个阶段的结果是
- en: A clear understanding of the data sources available
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对可用的数据源有清晰的理解
- en: A clear understanding of the different kinds of data and their content (or at
    least of all the significant parts of the machine learning goals)
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对不同类型的数据及其内容（或至少对机器学习目标的所有重要部分）有清晰的理解
- en: An architecture design to get or extract this data and feed it into the next
    steps of the machine learning workflow
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计架构以获取或提取这些数据并将其输入到机器学习工作流程的下一步
- en: 1.1.3 Data preparation
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.3 数据准备
- en: This phase covers all the activities to gather data from multiple sources and
    organize it in the specific kind of structure required by the algorithm in the
    modeling phase. Data preparation tasks include record and attribute selection,
    feature engineering, data merging, data cleaning, construction of new attributes,
    and enrichment of existing data. As pointed out before, the quality of the data
    has an enormous impact on the final results of the next phases, so this phase
    is crucial.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段涵盖了从多个来源收集数据并将其组织成模型阶段算法所需的具体结构的所有活动。数据准备任务包括记录和属性选择、特征工程、数据合并、数据清理、构建新属性和现有数据的丰富。正如之前指出的，数据的质量对下一阶段最终结果的影响巨大，因此这一阶段至关重要。
- en: The outcomes of this phase are
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段的结果是
- en: One or more data structure definitions, using adequate design techniques
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用适当的设计技术定义一个或多个数据结构
- en: A well-defined data pipeline for feeding the machine learning algorithm training
    data
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为喂养机器学习算法训练数据而定义的清晰数据管道
- en: A set of procedures for merging, cleaning, and enriching data
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一套合并、清理和丰富数据的程序
- en: Another outcome of this phase is the identification of the database management
    system where this data will be stored while waiting to be processed.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段另一个结果是确定在等待处理期间将存储这些数据的数据库管理系统。
- en: For the sake of completeness, it is not always required to have an explicit
    data store for persisting data before further processing. It is possible to extract
    data and convert it before the processing phase. Having such an intermediate step,
    however, has a lot of advantages related to performance and data quality as well
    as to further extensibility.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完整性，在进一步处理之前，并不总是需要有一个明确的数据存储来持久化数据。在处理阶段之前，可以提取数据并转换它。然而，这样的中间步骤在性能、数据质量以及进一步的可扩展性方面有很多优点。
- en: 1.1.4 Modeling
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.4 模型
- en: The modeling phase is where machine learning occurs. Different algorithms are
    selected and applied, and their parameters are calibrated to optimal values. The
    algorithms are used to build a range of prediction models from which the best
    is selected for deployment when the evaluation phase is complete. An interesting
    aspect is that some algorithms produce a prediction model, but others do not.[³](Ch01.htm#pgfId-1006078)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模型阶段是机器学习发生的地方。选择并应用不同的算法，并将它们的参数校准到最佳值。算法被用来构建一系列预测模型，当评估阶段完成后，从中选择最佳的模型进行部署。一个有趣的现象是，一些算法产生预测模型，而另一些则不产生。[³](Ch01.htm#pgfId-1006078)
- en: The outcomes of this phase are
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段的结果是
- en: The set of algorithms to be tested in the next phase
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下一个阶段要测试的算法集
- en: The related predictive models (where applicable)
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关的预测模型（如果适用）
- en: There is a close link between data preparation and modeling, because you often
    identify problems with the data and get ideas for constructing new data points
    while modeling. Moreover, some techniques require specific data formats.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备和建模之间存在紧密的联系，因为在建模过程中，你经常发现数据问题并获得构建新数据点的想法。此外，一些技术需要特定的数据格式。
- en: 1.1.5 Evaluation
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.5 评估
- en: At this stage in a machine learning project, you have built one or more predictive
    models that appear to be of high quality. Before a model can be deployed, it is
    important to evaluate it thoroughly and review the steps executed to construct
    the model, so that you can be certain it properly achieves the business objectives
    defined at the beginning of the process.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习项目的这个阶段，你已经构建了一个或多个看起来质量很高的预测模型。在模型可以部署之前，重要的是要彻底评估它，并回顾构建模型的步骤，以确保你确信它正确地实现了在过程开始时定义的业务目标。
- en: This evaluation is conducted in a formal way, such as splitting the available
    data into a training set (80%) and a testing set (20%). Another primary objective
    is to determine whether any important business issues have not been sufficiently
    considered.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这种评估是以正式的方式进行，例如将可用的数据分成训练集（80%）和测试集（20%）。另一个主要目标是确定是否已经充分考虑了任何重要的业务问题。
- en: The outcomes of this phase are
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段的结果是
- en: A set of values that allows measurement of performance. (The specific measure
    of success depends on the algorithm type and the scope.)
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组允许测量性能的值。（成功的具体衡量标准取决于算法类型和范围。）
- en: A thorough evaluation of whether the business goals are achieved.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对是否实现业务目标进行彻底评估。
- en: Authorization for using the solution in a production environment.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生产环境中使用解决方案的授权。
- en: 1.1.6 Deployment
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.6 部署
- en: Because machine learning models are built to serve some purpose in an organization,
    the creation of a model is generally not the end of the project. Depending on
    the requirements, the deployment phase can be as simple as generating a report
    or as complex as releasing a complete infrastructure that delivers a service to
    end users. In many cases, the customer—not the data scientist—carries out the
    deployment steps. In any event, it is important to understand up front what actions
    will need to be carried out to make use of the created models.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于机器学习模型是为了在组织中发挥某种作用而构建的，因此模型的创建通常不是项目的终点。根据需求，部署阶段可能只是生成报告那么简单，也可能像发布一个为最终用户提供服务的完整基础设施那么复杂。在许多情况下，客户——而不是数据科学家——执行部署步骤。无论如何，重要的是事先了解需要执行哪些操作才能利用创建的模型。
- en: 'The outcomes of this phase are as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此阶段的结果如下：
- en: One or multiple reports with the results of the prediction models
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个或多个包含预测模型结果的报告
- en: The predictive models themselves, used for predicting the future and supporting
    decisions
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于预测未来和辅助决策的预测模型本身
- en: An infrastructure to provide a specific set of services to the end users
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为最终用户提供特定服务的基础设施
- en: When the project is in production, it is necessary to monitor it constantly
    (evaluating performance, for example).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 当项目处于生产状态时，需要持续对其进行监控（例如评估性能）。
- en: 1.2 Machine learning challenges
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 机器学习挑战
- en: Machine learning projects have some intrinsic challenges that make them complex
    to accomplish. This section summarizes the main aspects you need to take into
    account when approaching a new machine learning project.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目有一些固有的挑战，使得它们难以完成。本节总结了在接近新的机器学习项目时需要考虑的主要方面。
- en: 1.2.1 The source of truth
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 真实来源
- en: The CRISP-DM model puts data at the center of the machine learning process by
    describing the life cycle from a data perspective. The training data represents
    the *source of truth* from which any insight can be extracted and any prediction
    can be made. Managing the training requires a lot of effort. To quote Jeffrey
    Heer, professor of computer science at the University of Washington, “It’s an
    absolute myth that you can send an algorithm over raw data and have insights pop
    up.” As a case in point, it has been estimated that data scientists spend up to
    80% of their time on data preparation [Lohr, 2014].
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: CRISP-DM 模型通过从数据的角度描述生命周期，将数据置于机器学习过程的核心。训练数据代表任何洞察都可以从中提取，任何预测都可以做出的*真实来源*。管理训练数据需要大量的努力。正如华盛顿大学计算机科学教授
    Jeffrey Heer 所说：“将算法发送到原始数据并让洞察浮现出来是一个绝对的神话。”作为一个案例，据估计，数据科学家将高达 80% 的时间用于数据准备
    [Lohr, 2014]。
- en: 'I often use the following statement to shift the focus to data before discussing
    the details of the algorithms:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论算法的细节之前，我经常使用以下陈述来将重点转移到数据上：
- en: '*Even the best learning algorithm on the wrong data produces the wrong results.*'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*即使是最优秀的机器学习算法在错误的数据上也会产生错误的结果。*'
- en: The seminal papers by Banko and Brill [2001] and Halevy, Norvig, and Pereira
    [2009] point out how, for complex problems, data often matters more than algorithms.
    Both articles consider natural language processing, but the concept can be generalized
    to machine learning in general [Sculley, 2015].
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Banko 和 Brill [2001] 以及 Halevy、Norvig 和 Pereira [2009] 的开创性论文指出，对于复杂问题，数据往往比算法更重要。这两篇文章都考虑了自然语言处理，但这个概念可以推广到机器学习的一般性
    [Sculley, 2015]。
- en: Figure 1.2, from Banko and Brill [2001], shows the learning curves for a set
    of learners, considering the average performance of each on different sizes of
    training data (up to 1 billion words). The specific algorithms used are not important
    here; the key takeaway is that, as is clear from the image, increasing the amount
    of data available during the training phase improved the performance of all the
    learners. These results suggest that it’s worth reconsidering spending time and
    money on corpus development versus spending it on algorithm development. From
    another perspective, as a data scientist you can focus on the vertical dimension—finding
    a better algorithm—but the graph shows that there is more room for improvement
    in the horizontal direction—gathering more data. As proof, the worst-performing
    algorithm in figure 1.2 performs much better with 10 million elements than the
    best one with 1 million elements.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2，来自Banko和Brill [2001]的研究，展示了针对一组学习者的学习曲线，考虑了每个学习者在不同大小的训练数据（高达10亿单词）上的平均性能。这里使用的具体算法并不重要；关键点是，如图像所示，在训练阶段增加可用数据量提高了所有学习者的性能。这些结果表明，重新考虑在语料库开发与算法开发之间分配时间和金钱是值得的。从另一个角度来看，作为一名数据科学家，你可以专注于垂直维度——寻找更好的算法——但图表显示，在水平方向上还有更多的改进空间——收集更多数据。作为证据，图1.2中表现最差的算法在拥有1000万个元素时比表现最好的算法在拥有100万个元素时表现要好得多。
- en: '![CH01_F02_Negro](../Images/CH01_F02_Negro.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F02_Negro](../Images/CH01_F02_Negro.png)'
- en: Figure 1.2 Learning curves for confusion set disambiguation
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 混淆集去歧义的学习曲线
- en: Collecting data from multiple sources allows you not only to access a huge set
    of data, but also to improve the quality of the data, solving problems such as
    sparsity, misspellings, correctness, and so on. Gathering data from a variety
    of sources is not an issue; we live in the big data era, and an abundance of digital
    data is available from the web, sensors, smartphones, corporate databases, and
    open data sources. But if there is value in combining different datasets, there
    are problems too. Data from different sources comes in different formats. Before
    the learner can analyze it, the data must be cleaned up, merged, and normalized
    into a unified and homogeneous schema that the algorithm can understand. Furthermore,
    obtaining additional training data has a nonzero cost for many problems, and for
    supervised learning, this cost may be high.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从多个来源收集数据不仅允许你访问大量数据，还可以提高数据质量，解决稀疏性、拼写错误、正确性等问题。从各种来源收集数据不是问题；我们生活在大数据时代，网络、传感器、智能手机、企业数据库和公开数据源提供了大量的数字数据。但如果将不同数据集组合起来有价值，也会出现问题。来自不同来源的数据格式不同。在学习者分析之前，数据必须被清理、合并并规范化为算法可以理解的统一和同质化的模式。此外，对于许多问题，获取额外的训练数据都有非零成本，对于监督学习，这种成本可能很高。
- en: 'For these reasons, the data represents the first big challenge in the machine
    learning process. Data concerns can be summarized in four categories:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些原因，数据代表了机器学习过程中的第一个重大挑战。数据问题可以总结为四个类别：
- en: '*Insufficient quantity of data*—Machine learning requires a lot of training
    data to work properly. Even for simple use cases, it needs thousands of examples,
    and for complex problems such as deep learning or for nonlinear algorithms, you
    may need millions of examples.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据量不足*—机器学习需要大量的训练数据才能正常工作。即使是简单的用例，也需要数千个示例，而对于深度学习或非线性算法等复杂问题，你可能需要数百万个示例。'
- en: '*Poor quality of data*—Data sources are always full of errors, outliers, and
    noise. Poor data quality directly affects the quality of the results of the machine
    learning process because it is hard for many algorithms to discard wrong (incorrect,
    unrelated, or irrelevant) values and to then detect underlying patterns in this
    mess.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据质量差*—数据来源总是充满了错误、异常值和噪声。差的数据质量会直接影响机器学习过程的结果质量，因为许多算法难以丢弃错误（不正确、无关或无关）的值，并在这种混乱中检测到潜在的规律。'
- en: '*Nonrepresentative data*—Machine learning is a process of induction: the model
    makes inferences from what it has observed and will likely not support edge cases
    that your training data does not include. Furthermore, if the training data is
    too noisy or is related only to a subset of possible cases, the learner might
    generate bias or overfit the training data and will not be able to generalize
    to all the possible cases. This is true for both instance-based and model-based
    learning algorithms.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*非代表性数据*—机器学习是一个归纳过程：模型从其观察到的内容进行推断，并且不太可能支持训练数据中未包含的边缘情况。此外，如果训练数据太嘈杂或仅与可能情况的子集相关，学习者可能会产生偏差或过度拟合训练数据，并且无法推广到所有可能的情况。这对于基于实例和基于模型的机器学习算法都是正确的。'
- en: '*Irrelevant features*—The algorithm will learn in the right way if the data
    contains a good set of relevant features and not too many irrelevant features.
    Although it is often a useful strategy to select more features, with the goal
    of increasing the accuracy of the model, more is not always better. Using more
    features will enable the learner to find a more detailed mapping from feature
    to target, which increases the risk that the model computed will overfit the data.
    Feature selection and feature extraction represent two important tasks during
    the preparation of data.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无关特征*—如果数据包含一组良好的相关特征而不是太多无关特征，算法将以正确的方式学习。尽管选择更多特征通常是一种有用的策略，目的是提高模型的准确性，但更多并不总是更好。使用更多特征将使学习者能够找到从特征到目标的更详细的映射，这增加了模型计算将过度拟合数据的可能性。特征选择和特征提取是数据准备阶段两项重要的任务。'
- en: To overcome these issues, data scientists have to gather and merge data from
    multiple sources, clean it, and enrich it by using external sources. (Moreover,
    it often happens that data is prepared for a certain purpose, but along the way,
    you discover something new, and the desired purpose changes.) These tasks are
    not simple ones; they require not only a significant amount of professional skill,
    but also a data management platform that allows the changes to be performed in
    a convenient way.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些问题，数据科学家必须从多个来源收集和合并数据，对其进行清理，并通过使用外部来源来丰富它。（此外，数据往往是为了某个特定目的而准备的，但在过程中，你可能会发现一些新东西，而预期的目的会发生变化。）这些任务并不简单；它们不仅需要大量的专业技能，还需要一个数据管理平台，以便以方便的方式执行更改。
- en: 'The issues related to the quality of the training examples determine a set
    of data management constraints and requirements for the infrastructure of the
    machine learning project. The problems can be summarized as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 与训练示例质量相关的问题决定了机器学习项目基础设施的一组数据管理约束和要求。这些问题可以总结如下：
- en: '*Managing big data*—Gathering data from multiple data sources and merging it
    into a unified source of truth will generate a huge dataset, and as pointed out
    before, increasing the amount of (quality) data will improve the quality of the
    learning process. Chapter 2 considers the characteristics of a big data platform
    and shows how graphs can play a prominent role in taming such a beast.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*管理大数据*—从多个数据源收集数据并将其合并到一个统一的事实来源将生成一个庞大的数据集，正如之前所指出的，增加（质量）数据的数量将提高学习过程的质量。第二章考虑了大数据平台的特点，并展示了图如何在这种巨兽的驯服中发挥突出作用。'
- en: '*Designing a flexible schema*—Try to create a schema model that provides the
    capabilities to merge multiple heterogeneous schemas into a unified and homogeneous
    data structure that satisfies the informational and navigational requirements.
    The schema should evolve easily according to changes in the purpose of the machine
    learning project. Chapter 4 introduces multiple data model schemas and best practices
    to model the data for several scenarios.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设计灵活的架构*—尝试创建一个架构模型，它能够将多个异构架构合并到一个统一且同质化的数据结构中，以满足信息和导航需求。架构应根据机器学习项目目的的变化轻松演进。第四章介绍了多种数据模型架构和最佳实践，用于对几种场景进行数据建模。'
- en: '*Developing efficient access patterns*—Fast data reads boost the performance,
    in terms of processing time, of the training process. Tasks such as feature extraction,
    filtering, cleaning, merging, and other preprocessing of the training data will
    benefit from the use of a data platform that provides multiple and flexible access
    patterns.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开发高效的访问模式*—快速的数据读取可以提高训练过程的性能，从处理时间来看。特征提取、过滤、清理、合并以及其他训练数据的预处理任务将受益于使用提供多种灵活访问模式的数据平台。'
- en: 1.2.2 Performance
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 性能
- en: 'Performance is a complex topic in machine learning because it can be related
    to multiple factors:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 性能在机器学习中是一个复杂的话题，因为它可以与多个因素相关：
- en: '*Predictive accuracy*, which can be evaluated by using different performance
    measures. A typical performance measure for regression problems is the root mean
    squared error (RMSE), which measures the standard deviation[⁴](Ch01.htm#pgfId-1006098)
    of the errors the system makes in its predictions. In other words, it looks at
    the difference between the estimated value and the known value for all the samples
    in the test dataset and calculates the average value. I present other techniques
    for measuring performance later in the book, when discussing the different algorithms.
    Accuracy depends on several factors, such as the amount of data available for
    training the model, the quality of the data, and the algorithm selected. As discussed
    in section 1.2.1, the data plays a primary role in guaranteeing a proper level
    of accuracy.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测准确性*，可以通过使用不同的性能指标来评估。回归问题的一个典型性能指标是均方根误差（RMSE），它衡量系统在预测中犯错的均方差[⁴](Ch01.htm#pgfId-1006098)。换句话说，它查看测试数据集中所有样本的估计值与已知值之间的差异，并计算平均值。我在本书后面的章节中介绍了其他测量性能的技术，当讨论不同的算法时。准确性取决于几个因素，例如用于训练模型的数据量、数据的质量以及所选的算法。如1.2.1节所述，数据在保证适当准确度水平方面起着主要作用。'
- en: '*Training performance*, which refers to the time required to compute the model.
    The amount of data to be processed and the type of algorithm used determine the
    processing time and the storage required for computing the prediction model. Clearly,
    this problem affects more the algorithms that produce a model as a result of the
    training phase. For instance-based learners,[⁵](Ch01.htm#pgfId-1006125) performance
    problems will appear later in the process, such as during prediction. In batch
    learning, the training time is generally longer, due to the amount of data to
    be processed (compared with the online learning approach, in which the algorithm
    learns incrementally from a smaller amount of data). Although in online learning,
    the amount of data to be processed is small, the speed at which it is crunched
    affects the capacity of the system to be aligned with the latest data available,
    which directly affects the accuracy of the predictions.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*训练性能*，指的是计算模型所需的时间。要处理的数据量以及所使用的算法类型决定了处理时间和预测模型所需的存储空间。显然，这个问题更多地影响那些在训练阶段产生模型的算法。例如，基于实例的学习者[⁵](Ch01.htm#pgfId-1006125)的性能问题会在处理过程的后期出现，比如在预测阶段。在批量学习中，由于要处理的数据量较大（与在线学习方法相比，在线学习方法是从较少的数据量中增量学习算法），训练时间通常较长。虽然在在线学习中，要处理的数据量较小，但处理速度会影响系统与最新数据的同步能力，这直接影响到预测的准确性。'
- en: '*Prediction performance*, which refers to the response time required to provide
    predictions. The output of the machine learning project could be a static one-time
    report to help managers make strategic decisions or an online service for end
    users. In the first case, the time required to complete the prediction phase and
    compute the model is not a significant concern, so long as the work is completed
    in a reasonable time frame (that is, not years). In the second case, prediction
    speed does matter, because it affects the user experience and the efficacy of
    the prediction. Suppose that you are developing a recommendation engine that recommends
    products similar to what the user is currently viewing according to their interests.
    The user navigation speed is quite high, which implies the need for a significant
    number of predictions in a short time interval; only a few milliseconds are available
    to suggest something useful before the user proceeds to the next item. In this
    scenario, the speed of prediction is the key to success.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测性能*，指的是提供预测所需的时间响应。机器学习项目的输出可能是一个静态的一次性报告，以帮助管理者做出战略决策，或者是一个面向最终用户的在线服务。在前一种情况下，完成预测阶段和计算模型所需的时间不是主要问题，只要在合理的时间内完成工作（即，不是几年）。在后一种情况下，预测速度确实很重要，因为它会影响用户体验和预测的有效性。假设你正在开发一个推荐引擎，该引擎根据用户的兴趣推荐与用户当前查看的产品相似的产品。用户的导航速度相当快，这意味着在用户继续浏览下一个项目之前，需要在短时间内进行大量的预测；只有几毫秒的时间可以建议一些有用的东西。在这种情况下，预测速度是成功的关键。'
- en: These factors can be translated into multiple requirements for machine learning
    projects, such as fast access to the data source during training, high data quality,
    an efficient access pattern for the model to accelerate predictions, and so on.
    In this context, graphs could provide the proper storage mechanism for both source
    and model data, reducing the access time required to read data as well as offering
    multiple algorithmic techniques for improving the accuracy of the predictions.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素可以转化为对机器学习项目的多个要求，例如在训练期间快速访问数据源、高数据质量、高效的模型访问模式以加速预测等。在这种情况下，图可以提供适当的存储机制，用于源数据和模型数据，减少读取数据所需的访问时间，并提供多种算法技术来提高预测的准确性。
- en: 1.2.3 Storing the model
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 存储模型
- en: In the model-based learner approach, the output of the training phase is a model
    that will be used for making predictions. This model requires time to be computed
    and has to be stored in a persistence layer to avoid recomputation at every system
    restart.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于模型的学习者方法中，训练阶段的输出是一个用于进行预测的模型。此模型需要时间来计算，并且必须存储在持久化层中，以避免每次系统重启时重新计算。
- en: The model’s structure is related directly to the specific algorithm or the algorithm
    class employed. Examples include
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的结构直接相关于所使用的特定算法或算法类。例如包括
- en: Item-to-item similarities for a recommendation engine that uses a nearest-neighbor
    approach
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用最近邻方法的推荐引擎的项目到项目相似性
- en: An item-cluster mapping that expresses how the elements are grouped in clusters
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表达元素如何分组到簇中的项目到簇映射
- en: The sizes of the two models differ enormously. Consider a system that contains
    100 items. As a first effort, item-to-item similarities would require 100 x 100
    entries to be stored. Taking advantage of optimizations, this number can be reduced
    to consider only the top k similar items, in which case the model will require
    100 x k entries. By contrast, item-cluster mapping requires only 100 entries;
    hence, the space required to store the model in memory or on disk could be huge
    or relatively modest. Moreover, as pointed out earlier, model access/query time
    affects global performance during the prediction phase. For these reasons, model
    storage management represents a significant challenge in machine learning.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 两个模型的尺寸差异极大。考虑一个包含100个项目的系统。作为初步尝试，项目到项目的相似性需要存储100 x 100个条目。利用优化，这个数字可以减少到只考虑前k个相似项，在这种情况下，模型将需要100
    x k个条目。相比之下，项目到簇映射只需要100个条目；因此，存储模型在内存或磁盘上的空间可能是巨大的或相对适中。此外，如前所述，模型访问/查询时间会影响预测阶段的整体性能。因此，模型存储管理是机器学习中的一个重大挑战。
- en: 1.2.4 Real time
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.4 实时
- en: Machine learning is being used more and more frequently to deliver real-time
    services to users. Examples run the full spectrum from simple recommendation engines
    that react to the user’s last clicks all the way to self-driving cars that have
    been instructed not to injure a pedestrian crossing the street. Although the outcomes
    in case of failure are vastly different in these two examples, in both cases the
    capability of the learner to react quickly (or in an appropriate timely manner)
    to new stimuli coming from the environment is fundamental for the quality of the
    final results.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习越来越多地被用于向用户提供实时服务。例子涵盖了从简单的响应用户最后点击的推荐引擎到被指示不要伤害过街行人的自动驾驶汽车的全范围。尽管这两个例子中失败的结果差异很大，但在两种情况下，学习者对来自环境的新刺激做出快速（或适当及时）反应的能力对于最终结果的质量是基本的。
- en: 'Consider a recommendation engine that provides real-time recommendations for
    anonymous users. This anonymity (the user is not registered or logged in) means
    that there is no long-term history of previous interactions—only short-term, session-based
    information provided by the use of cookies. This task is a complex one that involves
    multiple aspects and affects several phases of a machine learning project. The
    approaches taken could differ according to the learner(s) used, but the goals
    can be described as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个为匿名用户提供实时推荐的推荐引擎。这种匿名性（用户未注册或登录）意味着没有长期的历史交互记录——只有通过使用cookies提供的短期、基于会话的信息。这是一个复杂的任务，涉及多个方面，并影响机器学习项目的多个阶段。所采取的方法可能因使用的学习者而异，但目标可以描述如下：
- en: '*Learn fast.* The online learner should be able to update the model as soon
    as new data is available. This capability will reduce the time gap between events
    or generic feedback, such as navigational clicks or interaction with a search
    session and updating of the model. The more the model is aligned to the latest
    events, the more it is able to meet the current needs of the user.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*快速学习*。在线学习者应该能够在新数据可用时立即更新模型。这种能力将减少事件或通用反馈（如导航点击或与搜索会话的交互以及模型的更新）之间的时间差距。模型与最新事件越一致，就越能满足用户的当前需求。'
- en: '*Predict fast.* When the model is updated, the prediction should be fast—a
    maximum of a few milliseconds—because the user may navigate away from the current
    page or even change their opinion quite rapidly.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*快速预测*。当模型更新时，预测应该很快——最多几毫秒——因为用户可能已经离开当前页面，甚至可能迅速改变他们的观点。'
- en: Both of these goals require algorithms that can align the model quickly, as
    well as a storage mechanism (in memory, on disk, or a combined version) that provides
    fast memorization and efficient access patterns.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个目标都需要能够快速对齐模型的算法，以及提供快速记忆和高效访问模式的存储机制（在内存中、在磁盘上或两者的组合版本）。
- en: 1.3 Graphs
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 图
- en: As stated at the introduction of this chapter, graphs provide models and algorithms
    that can heavily support machine learning projects. Even though a graph is a simple
    concept, it is important to understand how to represent it and how to use the
    main concepts around it. This section introduces the key elements of the graph
    world. If you already dominate such concepts, you can skip this part.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章引言所述，图提供了可以极大地支持机器学习项目的模型和算法。尽管图是一个简单的概念，但了解如何表示它以及如何使用其周围的主要概念是很重要的。本节介绍了图世界的关键元素。如果您已经掌握了这些概念，可以跳过这部分内容。
- en: 1.3.1 What is a graph?
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 什么是图？
- en: 'A *graph* is a simple and quite old mathematical concept: a data structure
    consisting of a set of vertices (or nodes/points) and edges (or relationships/lines)
    that can be used to model relationships among a collection of objects. Legend
    says that the lazy Leonhard Euler first started talking about graphs in 1736\.
    While visiting Königsberg in Prussia (now Kaliningrad, Russia), Euler didn’t want
    to spend too much time walking in the city, which sat on both sides of the Pregel
    River and included two large islands that were connected to each other and to
    the two mainland portions of the city by seven bridges. Euler formalized the problem
    as planning a walk through the city that would cross each of those bridges once
    and only once. He proved that doing so was impossible, which led to the invention
    of graphs and graph theory [Euler, 1736]. So he stayed home instead. Figure 1.3
    shows an old map of Königsberg and a representation of the graph that Euler used
    to prove his thesis.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*图*是一个简单且相当古老的数学概念：由一组顶点（或节点/点）和边（或关系/线）组成的数据结构，可以用来模拟一组对象之间的关系。传说懒惰的莱昂哈德·欧拉于
    1736 年首次开始谈论图。当访问普鲁士的柯尼斯堡（现俄罗斯加里宁格勒）时，欧拉不想在城市里花费太多时间散步，该城市位于普雷格尔河两侧，包括两个通过七座桥梁连接到彼此和城市两个大陆部分的两个大岛。欧拉将问题形式化为计划一次穿过所有这些桥梁一次且仅一次的散步。他证明了这样做是不可能的，这导致了图和图论的发明确立
    [Euler, 1736]。因此，他留在了家里。图 1.3 显示了柯尼斯堡的一张旧地图和欧拉用来证明其论文的图的表示。'
- en: '![CH01_F03a_Negro](../Images/CH01_F03a_Negro.png)![CH01_F03b_Negro](../Images/CH01_F03b_Negro.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F03a_Negro](../Images/CH01_F03a_Negro.png)![CH01_F03b_Negro](../Images/CH01_F03b_Negro.png)'
- en: Figure 1.3 The bridges in Königsberg that led to the invention of graph theory
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 带领图论发明的柯尼斯堡桥梁
- en: More formally, a graph is a pair G = (V, E), where V is a collection of vertices
    V = {V[i], i = 1,n} and E is a collection of edges over V, E[ij] = {(V[i], V[j]),
    V[i] ∊ V, V[j] ∊ V}. E ⊆ [V]²; thus, the elements of E are two-element subsets
    of V [Diestel, 2017].
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，一个图是一个对 G = (V, E)，其中 V 是顶点的集合 V = {V[i], i = 1,n}，E 是 V 上的边的集合，E[ij]
    = {(V[i], V[j]), V[i] ∊ V, V[j] ∊ V}。E ⊆ [V]²；因此，E 的元素是 V 的两个元素子集 [Diestel, 2017]。
- en: The simplest way to represent a graph is to draw a dot or a small circle for
    each vertex and then join two of those vertices by a line if they form an edge.
    This more formalized description is shown in figure 1.4.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 表示图的最简单方法是为每个顶点画一个点或一个小圆圈，如果它们形成一个边，则通过一条线连接两个这样的顶点。这种更正式的描述如图 1.4 所示。
- en: '![CH01_F04_Negro](../Images/CH01_F04_Negro.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F04_Negro](../Images/CH01_F04_Negro.png)'
- en: Figure 1.4 The undirected graph on *V* = {1, 2, 3, 4, 5} with edge set *E* =
    {(1,2), (1,5), (2,5), (2,4), (4,3)}
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 在 *V* = {1, 2, 3, 4, 5} 上的无向图，其边集 *E* = {(1,2), (1,5), (2,5), (2,4), (4,3)}
- en: Graphs can be directed or undirected, depending on whether a direction of traversal
    is defined on the edges. In *directed* graphs, an edge E[ij] can be traversed
    from Vi to Vj but not in the opposite direction; V[i] is called the *tail*, or
    *start node*, and V[j] is called the *head*, or *end node*. In *undirected* graphs,
    edge traversals in both directions are valid. Figure 1.4 represents an undirected
    graph, and figure 1.5 represents a directed graph.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图可以是**有向**的或**无向**的，这取决于是否在边上定义了遍历方向。在**有向图**中，边 E[ij] 可以从 Vi 遍历到 Vj，但不能反向遍历；V[i]
    被称为**尾**或**起始节点**，V[j] 被称为**头**或**终止节点**。在**无向图**中，两个方向的边遍历都是有效的。图1.4表示一个无向图，图1.5表示一个有向图。
- en: '![CH01_F05_Negro](../Images/CH01_F05_Negro.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F05_Negro](../Images/CH01_F05_Negro.png)'
- en: Figure 1.5 The directed graph on *V* = {1, ..., 5} with edge set *E* = {(1,2),
    (2,5), (5,1), (2,4), (3,4)}
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 在 *V* = {1, ..., 5} 上的有向图，其边集 *E* = {(1,2), (2,5), (5,1), (2,4), (3,4)}
- en: The arrow indicates the direction of the relationship. By default, edges in
    a graph are unweighted; thus, the corresponding graphs are said to be *unweighted*.
    When a weight—a numerical value used to convey some significance—is assigned to
    the edges, the graph is said to be *weighted*. Figure 1.6 shows the same graphs
    as figures 1.4 and 1.5 with a weight assigned to each edge.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 箭头表示关系的方向。默认情况下，图中的边是无权重的；因此，相应的图被称为**无权图**。当给边分配一个权重——一个用于传达某些意义的数值时，该图被称为**加权图**。图1.6显示了与图1.4和图1.5相同的图，并为每条边分配了权重。
- en: '![CH01_F06_Negro](../Images/CH01_F06_Negro.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F06_Negro](../Images/CH01_F06_Negro.png)'
- en: Figure 1.6 An undirected weighted graph (a) and a directed weighted graph (b)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 一个无向加权图（a）和一个有向加权图（b）
- en: Two vertices x and y of G are defined as *adjacent*, or *neighbors*, if {x,y}
    is an edge of G. The edge E[ij] connecting them is said to be *incident on* the
    two vertices V[i] and V[j]. Two distinct edges e and f are adjacent if they have
    a vertex in common. If all the vertices of G are pairwise adjacent, G is *complete*.
    Figure 1.7 shows a complete graph in which each vertex is connected to all the
    other vertices.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果图G中的两个顶点x和y通过边 {x,y} 相连，则称这两个顶点为**相邻**或**邻居**。连接它们的边 E[ij] 被称为在两个顶点 V[i] 和
    V[j] 上**关联**。如果两个不同的边e和f有一个共同的顶点，则称它们为**相邻**。如果G的所有顶点都是成对相邻的，则G是**完全图**。图1.7显示了一个完全图，其中每个顶点都与所有其他顶点相连。
- en: '![CH01_F07_Negro](../Images/CH01_F07_Negro.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F07_Negro](../Images/CH01_F07_Negro.png)'
- en: Figure 1.7 A complete graph in which each vertex is connected to all the others
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 每个顶点都与所有其他顶点相连的完全图
- en: One of the most important properties of a vertex in a graph is its *degree*,
    defined as the total number of edges incident to that vertex, which is also equal
    to the number of neighbors of that vertex. In the undirected graph of figure 1.4,
    for example, the vertex 2 has degree 3 (it has the vertices 1, 4, and 5 as neighbors);
    the vertices 1 (neighbors are 2, 5), 4 (neighbors are 2, 3), and 5 (neighbors
    are 1, 2) have degree 2, whereas vertex 3 has degree 1 (is connected only with
    4).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的顶点的一个重要属性是其**度**，定义为与该顶点相连的边的总数，这也等于该顶点的邻居数量。例如，在图1.4的无向图中，顶点2的度数为3（它有顶点1、4和5作为邻居）；顶点1（邻居是2、5）、4（邻居是2、3）和5（邻居是1、2）的度数为2，而顶点3的度数为1（仅与顶点4相连）。
- en: In a directed graph, the degree of a vertex V[i] is split into the *in-degree*
    of the vertex, defined as the number of edges for which V[i] is their end node
    (the head of the arrow) and the *out-degree* of the vertex, which is the number
    of edges for which V[i] is their start node (the tail of the arrow). In the directed
    graph of figure 1.5, vertices 1 and 5 have an in-degree and out-degree of 1 (they
    each have two relationships, one ingoing and one outgoing), vertex 2 has an in-degree
    of 1 and an out-degree of 2 (one ingoing relationship from 1 and two outgoing
    to 4 and 5), vertex 4 has an in-degree of 2 and an out-degree of 0 (two ingoing
    relationships from 2 and 3), and vertex 3 has an out-degree of 1 and in-degree
    of 0 (one outgoing relationship to 4).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在有向图中，顶点V[i]的度数分为顶点的*入度*，定义为以V[i]为终端节点（箭头的头部）的边的数量，以及顶点的*出度*，即以V[i]为起始节点的边的数量。在图1.5的有向图中，顶点1和5的入度和出度都是1（它们各自有两个关系，一个进入和一个出去），顶点2的入度是1，出度是2（从1进入一个关系，向4和5各出去两个关系），顶点4的入度是2，出度是0（从2和3进入两个关系），顶点3的出度是1，入度是0（向4出去一个关系）。
- en: The average degree of a graph is computed as follows,
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图的平均度数计算如下，
- en: '![CH01_F07_EQ01_Negro](../Images/CH01_F07_EQ01_Negro.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F07_EQ01_Negro](../Images/CH01_F07_EQ01_Negro.png)'
- en: where N is the number of vertices in the graph.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 其中N是图中顶点的数量。
- en: A sequence of vertices with the property that each consecutive pair in the sequence
    is connected by an edge is called a *path*. A path with no repeating vertices
    is called a *simple path*. A *cycle* is a path in which the first and the last
    vertex coincide. In figure 1.4, [1,2,4], [1,2,4,3], [1,5,2,4,3], and so on are
    paths; in particular, the path of vertices [1,2,5] represents a cycle.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 具有性质，即序列中的每对连续顶点都通过一条边连接的顶点序列称为*路径*。没有重复顶点的路径称为*简单路径*。*环*是首尾顶点相同的路径。在图1.4中，[1,2,4]、[1,2,4,3]、[1,5,2,4,3]等都是路径；特别是顶点序列[1,2,5]的路径代表一个环。
- en: 1.3.2 Graphs as models of networks
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 图作为网络模型
- en: Graphs are useful for representing how things are either physically or logically
    linked in simple or complex structures. A graph in which we assign names and meanings
    to the edges and vertices becomes what is known as a network. In these cases,
    a graph is the mathematical model for describing a network, whereas a network
    is a set of relations between objects, which could include people, organizations,
    nations, items found in a Google search, brain cells, or electrical transformers.
    This diversity illustrates the great power of graphs and their simple structure
    (which also means that they require a small amount of disk storage capacity) that
    can be used to model[⁶](Ch01.htm#pgfId-1006147) a complex system.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图对于表示事物在简单或复杂结构中如何物理上或逻辑上相互连接非常有用。当我们给边和顶点分配名称和意义时，这样的图就变成了所谓的网络。在这些情况下，图是描述网络的数学模型，而网络是对象之间的一系列关系，这些对象可能包括人、组织、国家、Google搜索中找到的项目、脑细胞或电力变压器。这种多样性展示了图及其简单结构（这也意味着它们需要很少的磁盘存储空间）的巨大力量，这些结构可以用来模拟[⁶](Ch01.htm#pgfId-1006147)复杂系统。
- en: Let’s explore this concept by using an example. Suppose that we have the graph
    shown in figure 1.8.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来探讨这个概念。假设我们有一个如图1.8所示的图。
- en: '![CH01_F08_Negro](../Images/CH01_F08_Negro.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F08_Negro](../Images/CH01_F08_Negro.png)'
- en: Figure 1.8 A nontrivial generic graph
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8 一个非平凡的通用图
- en: 'This graph, which is pure in the mathematical definition, can be used to model
    several types of networks, according to the types of edges and vertices:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这个在数学定义上纯粹的图可以根据边的类型和顶点的类型来模拟几种类型的网络：
- en: A *social network*, if the vertices are people and each edge represents any
    sort of relationship between humans (friendship, family member, coworker)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果顶点是人们，而每条边代表人类之间任何类型的关系（友谊、家庭成员、同事），则称为*社交网络*。
- en: An *informational network*, if the vertices are information structures such
    as web pages, documents, or papers and the edges represent logical connections
    such as hyperlinks, citations, or cross-references
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果顶点是信息结构，如网页、文档或论文，而边代表逻辑连接，如超链接、引用或交叉引用，则称为*信息网络*。
- en: A *communication network*, if the vertices are computers or other devices that
    can relay messages and the edges represent direct links along which messages can
    be transmitted
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果顶点是能够中继消息的计算机或其他设备，而边代表可以传输消息的直接链接，则称为*通信网络*。
- en: A *transportation network*, if the vertices are cities and the edges represent
    direct connections using flights or trains or roads
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种 *交通网络*，如果顶点是城市，而边代表使用航班、火车或道路的直接连接
- en: This small set of examples demonstrates how the same graph can represent multiple
    networks by assigning different semantics to edges and vertices. Figure 1.9 illustrates
    different types of networks.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这一小组示例展示了如何通过为边和顶点分配不同的语义，同一个图可以表示多个网络。图1.9展示了不同类型的网络。
- en: 'Looking at figure 1.9, we can spot another interesting characteristic of graphs:
    they are highly communicative. Graphics are able to display information in a clear
    manner, which is why they are often used as *information maps*. Representing data
    as networks and using graph algorithms, it is possible to'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 观察图1.9，我们可以发现图形的另一个有趣特征：它们具有很强的沟通能力。图形能够以清晰的方式展示信息，这也是为什么它们经常被用作*信息地图*。将数据表示为网络并使用图算法，可以
- en: Find complex patterns
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找复杂模式
- en: Make them visible for further investigation and interpretation
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使其可见以便进行进一步调查和解读
- en: '![CH01_F09a_Negro](../Images/CH01_F09a_Negro.png)![CH01_F09b_Negro](../Images/CH01_F09b_Negro.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F09a_Negro](../Images/CH01_F09a_Negro.png)![CH01_F09b_Negro](../Images/CH01_F09b_Negro.png)'
- en: '![CH01_F09c_Negro](../Images/CH01_F09c_Negro.png)![CH01_F09d_Negro](../Images/CH01_F09d_Negro.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F09c_Negro](../Images/CH01_F09c_Negro.png)![CH01_F09d_Negro](../Images/CH01_F09d_Negro.png)'
- en: 'Figure 1.9 Clockwise from top left: a co-occurrence network,[⁷](Ch01.htm#pgfId-1011526)
    ARPA network 1974,[⁸](Ch01.htm#pgfId-1006197) London Tube network,[⁹](Ch01.htm#pgfId-1006212)
    and electrical grid[^(10)](Ch01.htm#pgfId-1006225)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9 从左上角顺时针方向：共现网络[⁷](Ch01.htm#pgfId-1011526)、1974年的ARPA网络[⁸](Ch01.htm#pgfId-1006197)、伦敦地铁网络[⁹](Ch01.htm#pgfId-1006212)和电网[^(10)](Ch01.htm#pgfId-1006225)
- en: When the power of machine learning is combined with the power of the human brain,
    it enables efficient, advanced, and sophisticated data processing and pattern
    recognition. Networks are useful for displaying data by highlighting connections
    among elements. Newspapers and news websites are increasingly using networks,
    not only to help people navigate the data, but also as a powerful investigation
    tool. Recently (at the time of this writing), the Panama Papers[^(11)](Ch01.htm#pgfId-1006243)
    showcased the astonishing features of networks. The International Consortium of
    Investigative Journalists (ICIJ) analyzed the leaked financial documents to expose
    highly connected networks of offshore tax structures used by the world’s richest
    elites. The journalists extracted the entities (people, organizations, and any
    sort of intermediaries) and relationships (protector, beneficiary, shareholder,
    director, and so on) from the documents, stored them in a network, and analyzed
    them by using visual tools. The results looked like figure 1.10\. Here, networks,
    graph algorithms, and graph visualization made evident something that otherwise
    would have been impossible to discover by using traditional data mining tools.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![CH01_F10_Negro](../Images/CH01_F10_Negro.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F10_Negro](../Images/CH01_F10_Negro.png)'
- en: Figure 1.10 An example of the graph visualization for the Panama Papers
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: A lot of interesting examples in this direction are also available in blog posts
    by Valdis Krebs,[^(12)](Ch01.htm#pgfId-1006259) an organization consultant who
    specializes in social network applications. His work contains examples of mixing
    graph-powered machine learning with the human mind, passing through graph visualization.
    Here, we consider one of the most famous examples.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方向上，许多有趣的例子也可以在组织顾问Valdis Krebs的博客文章中找到，[^(12)](Ch01.htm#pgfId-1006259) 他专注于社交网络应用。他的工作中包含了将图增强的机器学习与人类思维相结合的例子，通过图可视化来实现。在这里，我们考虑其中一个最著名的例子。
- en: The data in figure 1.11 was gathered from Amazon.com and represents its list
    of the top political books purchased in the United States in 2008 [Krebs, 2012].
    Krebs employed network analysis principles to the data to create a map of books
    related to that year’s presidential election. Two books are linked if they were
    often purchased by the same customer. These books are known as *also-bought* pairs
    (in that a customer who bought this book *also bought* that book).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11中的数据来自Amazon.com，代表了2008年美国购买的前政治书籍列表 [Krebs, 2012]。Krebs将网络分析原理应用于数据，创建了一个与那年总统选举相关的书籍地图。如果两本书经常被同一顾客购买，则它们之间有链接。这些书籍被称为*也购买*对（在那个顾客购买了这本书*也购买了*那本书）。
- en: '![CH01_F11_Negro](../Images/CH01_F11_Negro.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F11_Negro](../Images/CH01_F11_Negro.png)'
- en: Figure 1.11 Network map of US political books in 2008 (Krebs, 2012)
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11 2008年美国政治书籍网络图（Krebs, 2012）
- en: 'There are three different and nonoverlapping clusters:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个不同且不重叠的集群：
- en: An Obama cluster of books in the top-left corner
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左上角的奥巴马书籍集群
- en: A Democratic (blue) cluster in the middle
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中间的民主党（蓝色）集群
- en: A Republican (red) cluster in the bottom-right corner
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右下角的共和党（红色）集群
- en: In 2008, the US political climate was highly polarized. This fact is mirrored
    in Amazon’s political-book data, with figure 1.11 showing a deep divide between
    conservative and liberal voters. There were no connections or intermediaries between
    red and blue books; each cluster was completely distinct from the others. As mentioned,
    there was a separate cluster of people reading biographies of presidential hopeful
    Barack Obama, but they were apparently not interested in reading or purchasing
    other political books.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 2008年，美国政治气候高度两极分化。这一事实在Amazon的政治书籍数据中得到了反映，图1.11显示了保守派和自由派选民之间的深刻分歧。红色和蓝色书籍之间没有联系或中间人；每个集群与其他集群完全不同。如前所述，有一个单独的阅读总统候选人巴拉克·奥巴马传记的人的集群，但他们显然对阅读或购买其他政治书籍不感兴趣。
- en: Four years later, in 2012, the same analysis produced a network that appeared
    to be substantially different (figure 1.12). This network shows a lot of books
    that act as bridges between clusters. Moreover, potential voters appear to be
    reading books about both major candidates. The result is a more complex network
    that has no isolated clusters.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 四年后，在2012年，同样的分析产生了一个看起来实质上不同的网络（图1.12）。这个网络显示了许多作为集群之间桥梁的书籍。此外，潜在的选民似乎在阅读关于两位主要候选人的书籍。结果是，一个更复杂的网络，没有孤立的集群。
- en: '![CH01_F12_Negro](../Images/CH01_F12_Negro.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F12_Negro](../Images/CH01_F12_Negro.png)'
- en: Figure 1.12 Network map of US political books in 2012 [Krebs, 2012]
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.12 2012年美国政治书籍网络图 [Krebs, 2012]
- en: 'The example of a network of political books introduces an important aspect
    of networks. If a graph is a pure mathematical concept that lives in its own Platonic
    world,[^(13)](Ch01.htm#pgfId-1006275) networks, as abstractions of some concrete
    system or ecosystem, are subjected to *forces* that, acting on them, change their
    structure. We refer to these forces as *surrounding contexts* : factors that exist
    outside the vertices and edges of a network but nonetheless affect how the network’s
    structure evolves over time. The nature of such contexts and the types of forces
    are specific to the kind of network. In social networks, for example, each individual
    has a distinctive set of personal characteristics, and similarities and compatibilities
    between two people’s characteristics influence link creation or deletion [Easley
    and Kleinberg, 2010].'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 政治书籍网络示例引入了网络的一个重要方面。如果图是一个纯粹数学概念，存在于它自己的柏拉图世界中，那么网络，作为某些具体系统或生态系统的抽象，会受到*力量*的影响，这些力量作用于它们，改变它们的结构。我们将这些力量称为*周围环境*：存在于网络顶点和边之外的因素，但仍然会影响网络结构随时间演化的方式。这种环境的性质和力量的类型是特定于网络类型的。例如，在社会网络中，每个人都有一个独特的个人特征集合，两个人之间的特征相似性和兼容性会影响链接的创建或删除
    [Easley and Kleinberg, 2010]。
- en: 'One of the most basic notions governing the structure of social networks is
    *homophily* (from the Greek, meaning love of the same): links in a social network
    tend to connect people who are similar. More formally, if two people have characteristics
    that match in a proportion greater than expected in the population from which
    they are drawn or the network of which they are part, they are more likely to
    be connected [Verbrugge, 1977]. The converse is also true: if two people are connected,
    they are more likely to have common characteristics or attributes. For this reason,
    our friends on Facebook (for example) don’t look like a random sample of people,
    but are generally similar to us along ethnic, racial, and geographic dimensions;
    they tend to be similar to us in age, occupation, interests, beliefs, and opinions.
    This observation has a long history, with origins long before Mark Zuckerberg
    wrote his first line of code. The underlying idea can be found in the writings
    of Plato (“Similarity begets friendship”) and Aristotle (people “love those who
    are like themselves”), as well as in folk propositions such as “Birds of a feather
    flock together.” The homophily principle also applies to groups, organizations,
    countries, or any aspect of social units.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 社会网络结构的基本观念之一是*同质性*（源自希腊语，意为对相同事物的喜爱）：社会网络中的链接倾向于连接相似的人。更正式地说，如果两个人的特征在比例上大于他们所来自的群体或他们所属的网络中的预期比例，他们更有可能被连接[Verbrugge,
    1977]。反之亦然：如果两个人是连接的，他们更有可能拥有共同的特征或属性。因此，我们的Facebook（例如）朋友并不像随机抽样的人群，他们在种族、种族和地理维度上通常与我们相似；他们在年龄、职业、兴趣、信仰和观点上往往与我们相似。这一观察已有悠久的历史，其起源远在马克·扎克伯格写下第一行代码之前。这一基本思想可以在柏拉图（“相似性产生友谊”）和亚里士多德（人们“爱那些与自己相似的人”）的著作中找到，以及民间命题如“物以类聚”中。同质性原则也适用于群体、组织、国家或社会单位的任何方面。
- en: 'Understanding the surrounding contexts and the related forces that act on a
    network helps with machine learning tasks in multiple ways:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 理解网络周围的上下文以及作用于网络的相关力量，以多种方式帮助机器学习任务：
- en: Networks are conduits for both wanted and unwanted flows. Marketers are always
    trying to reach and persuade people. Personal contact is most effective, if one
    can find a way to start a snowball rolling. This concept is at the base of so-called
    *viral marketing*.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络是既受欢迎又不受欢迎的流动的渠道。营销人员总是在尝试接触和说服人们。如果能够找到一种方法来启动雪球滚动，个人接触是最有效的。这个概念是所谓*病毒式营销*的基础。
- en: Understanding such forces allows the prediction of how the network will evolve
    over time, and enables data scientists to proactively react to such changes or
    use them for specific business purposes.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解这些力量可以使我们预测网络随时间如何演变，并使数据科学家能够积极应对这些变化或将其用于特定的商业目的。
- en: 'Findings in sociological and psychological disciplines point to the relevance
    of a person’s social network in determining their tastes, preferences, and activities.
    This information is useful for building recommendation engines. One of the problems
    related to recommendation engines is the cold-start problem: you can’t predict
    anything for a new user because you have no history for them. Social networks
    and the homophily principle can be used to make a recommendation based on the
    tastes of connected users.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社会学和心理学学科的研究结果表明，一个人的社交网络在决定他们的品味、偏好和活动方面具有相关性。这些信息对于构建推荐引擎很有用。与推荐引擎相关的一个问题是冷启动问题：由于没有他们的历史，你无法为新用户预测任何事情。社交网络和同质性原则可以用来根据连接用户的品味进行推荐。
- en: 1.4 The role of graphs in machine learning
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 图在机器学习中的作用
- en: Graphs are used to characterize interactions between objects of interest, to
    model simple and complex networks, or in general to represent real-world problems.
    Because they are based on a rigorous but straightforward formalism, they are used
    in many scientific fields, from computer science to historical sciences. We shouldn’t
    be surprised to see them being widely used in machine learning as a powerful tool
    that can enable intuition and power a lot of useful features. Graph-based machine
    learning is becoming more common over time, transcending numerous traditional
    techniques.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图被用来表征感兴趣对象之间的交互，用于建模简单和复杂的网络，或一般地用于表示现实世界问题。因为它们基于严格但简单的形式化，所以在许多科学领域中被使用，从计算机科学到历史科学。我们不应该对它们在机器学习中作为强大的工具被广泛使用感到惊讶，这个工具可以启发直觉并推动许多有用的功能。基于图的机器学习随着时间的推移变得越来越普遍，超越了众多传统技术。
- en: Many companies of all sizes are using this approach to provide more advanced
    machine learning features to their customers. One prominent example is Google,
    which is using graph-based machine learning as the core of its Expander platform.
    This technology is behind many of the Google products and features you may use
    every day, such as reminders in your Gmail inbox or the latest image-recognition
    system in Google Photos.[^(14)](Ch01.htm#pgfId-1006296)
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 许多不同规模的公司都在使用这种方法为他们的客户提供更高级的机器学习功能。一个突出的例子是谷歌，它正在使用基于图的机器学习作为其Expander平台的核心。这项技术背后支撑着许多你可能每天都在使用的谷歌产品和服务，例如Gmail收件箱中的提醒或Google
    Photos中的最新图像识别系统。[^(14)](Ch01.htm#pgfId-1006296)
- en: Building a graph-powered machine learning platform has numerous benefits, because
    graphs can be valuable tools not only for overcoming the previously described
    challenges, but also for delivering more advanced features that are impossible
    to implement without graph support.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个图驱动机器学习平台有许多好处，因为图不仅可以作为克服先前描述的挑战的有价值工具，还可以提供没有图支持无法实现的高级功能。
- en: Figure 1.13 illustrates the main contact points between machine learning and
    graphs, considering the goals of the different tasks.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.13展示了机器学习和图之间的主要接触点，考虑了不同任务的目标。
- en: '![CH01_F13_Negro](../Images/CH01_F13_Negro.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F13_Negro](../Images/CH01_F13_Negro.png)'
- en: Figure 1.13 Graph-powered machine learning mind map
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.13 图驱动机器学习思维导图
- en: 'This mind map can be used to immediately visualize conceptually the role of
    graphs in the machine learning panorama. In figure 1.13, graph features are grouped
    into three main areas:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这个思维导图可以立即直观地展示图在机器学习全景中的角色。在图1.13中，图特征被分为三个主要区域：
- en: '*Data management*—This area contains the features provided by graphs that help
    machine learning projects deal with the data.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据管理*——这个区域包含图提供的帮助机器学习项目处理数据的特性。'
- en: '*Data analysis*—This area contains graph features and algorithms useful for
    learning and predicting.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据分析*——这个区域包含对学习和预测有用的图特征和算法。'
- en: '*Data visualization*—This area highlights the utility of graphs as a visual
    tool that helps people communicate, interact with data, and discover insights
    by using the human brain.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据可视化*——这个区域突出了图作为视觉工具的实用性，它帮助人们通过使用人脑来沟通、与数据互动并发现洞察。'
- en: The schema also shows the mapping between the graph-based techniques and the
    phases in the CRISP-DM model.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 模式还显示了基于图的技术与CRISP-DM模型阶段之间的映射。
- en: 1.4.1 Data management
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.1 数据管理
- en: Graphs allow the learning system to explore more of your data, to access it
    faster, and to clean and enrich it easily. Traditional learning systems train
    on a single table prepared by the researcher, whereas a graph-native system can
    access more than that table.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图允许学习系统探索更多你的数据，更快地访问它，并轻松地进行清理和丰富。传统的学习系统在研究者准备的单个表格上训练，而图原生系统可以访问的不仅仅是这个表格。
- en: Graph-powered data management features include
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图驱动数据管理功能包括
- en: '*Connected sources of truth*—Graphs allow you to merge multiple data sources
    into a single uniform, connected dataset ready for the training phase. This feature
    represents a great advantage by reducing data sparsity, increasing the amount
    of data available, and simplifying data management.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*连接的真实数据源*——图允许你将多个数据源合并成一个单一、统一、连接的数据集，为训练阶段做好准备。通过减少数据稀疏性、增加可用数据量以及简化数据管理，这一特性带来了巨大的优势。'
- en: '*Knowledge graphs*—Building on the previous idea, knowledge graphs provide
    a homogeneous data structure for combining not only data sources, but also prediction
    models, manually provided data, and external sources of knowledge. The resulting
    data is machine ready and can be used during training, prediction, or visualization.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*知识图谱*——基于前面的想法，知识图谱提供了一个统一的数据结构，不仅可以将数据源合并，还可以将预测模型、手动提供的数据和外部知识来源合并。结果数据是机器可用的，可以在训练、预测或可视化过程中使用。'
- en: '*Fast data access*—Tables provide a single access pattern related to row and
    column filters. Graphs, on the other hand, provide multiple access points to the
    same set of data. This feature improves performance by reducing the amount of
    data to be accessed to the baseline minimum for the specific set of needs.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*快速数据访问*——表格提供与行和列过滤器相关的单一访问模式。另一方面，图提供了对同一数据集的多个访问点。通过减少需要访问的数据量到特定需求的基本最小值，这一特性提高了性能。'
- en: '*Data enrichment*—In addition to making it easy to extend existing data with
    external sources, the schemaless nature of graphs and the access patterns provided
    within graph databases help with data cleaning and merging.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据丰富*—除了使扩展现有数据与外部源变得容易外，图的无模式性质和图数据库内提供的访问模式有助于数据清理和合并。'
- en: '*Feature selection*—Identifying relevant features in a dataset is key in several
    machine learning tasks, such as classification. By providing fast access to data
    and multiple query patterns, graphs speed feature identification and extraction.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征选择*—在数据集中识别相关特征是几个机器学习任务（如分类）的关键。通过提供快速访问数据和多种查询模式，图加速了特征识别和提取。'
- en: Connected sources of truth and knowledge graphs are valuable aids during the
    data understanding and data preparation phases of the CRISP-DM model, whereas
    fast data access, data enrichment, and feature selection are useful in the data
    preparation phase.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在CRISP-DM模型的“数据理解”和“数据准备”阶段，连接的真相来源和知识图是宝贵的辅助工具，而快速数据访问、数据丰富和特征选择在数据准备阶段很有用。
- en: 1.4.2 Data analysis
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.2 数据分析
- en: Graphs can be used to model and analyze the relationships between entities as
    well as their properties. This aspect brings an additional dimension of information
    that graph-powered machine learning can harness for prediction and categorization.
    The schema flexibility provided by graphs also allows different models to coexist
    in the same dataset.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图可以用来建模和分析实体之间的关系以及它们的属性。这一方面为图驱动的机器学习带来了额外的信息维度，可以用于预测和分类。图提供的模式灵活性还允许不同的模型在同一个数据集中共存。
- en: Graph-powered data analysis features include
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图像驱动的数据分析功能包括
- en: '*Graph algorithms*—Several types of graph algorithms, such as clustering, page
    ranking, and link analysis algorithms, are useful for identifying insights in
    the data and for analysis purposes. Moreover, they can be used as a first data
    preprocessing step in a more complex analysis process.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图算法*—几种类型的图算法，如聚类、页面排名和链接分析算法，对于在数据中识别洞察和分析目的很有用。此外，它们可以用作更复杂分析过程中的第一个数据预处理步骤。'
- en: '*Graph-accelerated machine learning*—The graph-powered feature extraction discussed
    earlier is an example of how graphs can speed or improve the quality of the learning
    system. Graphs can help in filtering, cleaning, enriching, and merging data before
    or during training phases.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图加速机器学习*—前面讨论的图驱动的特征提取是图如何加速或提高学习系统质量的一个例子。图可以帮助在训练阶段之前或期间过滤、清理、丰富和合并数据。'
- en: '*Network dynamics*—Awareness of the surrounding contexts and related forces
    that act on networks allows you not only to understand network dynamics, but also
    to use them to improve the quality of the predictions.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*网络动态*—对网络周围环境和相关作用力的认识不仅使你能够理解网络动态，而且还可以利用它们来提高预测质量。'
- en: '*Mixing models*—Multiple models can coexist in the same graph, taking advantage
    of flexible and fast access patterns, provided that they can be merged during
    the prediction phase. This feature improves final accuracy. Moreover, the same
    model sometimes can be used in different ways.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*混合模型*—在同一个图中可以共存多个模型，利用灵活且快速的访问模式，只要它们在预测阶段可以合并。这一特性提高了最终精度。此外，同一个模型有时可以用不同的方式使用。'
- en: '*Fast model access*—Real-time use requires fast predictions, which implies
    a model that can be accessed as fast as possible. Graphs provide the right patterns
    for these scopes.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*快速模型访问*—实时使用需要快速预测，这意味着需要一个尽可能快就能访问的模型。图提供了这些范围所需的正确模式。'
- en: Graph algorithms, graph-accelerated machine learning, and network dynamics are
    involved principally in the modeling phase because they are connected to the learning
    process more than other features. The deployment phase makes use of mixing models
    and fast model-access methods because they operate during the prediction stage.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图算法、图加速机器学习和网络动态主要涉及建模阶段，因为它们比其他特性更多地与学习过程相关。部署阶段利用混合模型和快速模型访问方法，因为它们在预测阶段运行。
- en: 1.4.3 Data visualization
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.3 数据可视化
- en: Graphs have high communication power, and they can display multiple types of
    information at the same time in a way the human brain can easily understand. This
    feature is greatly important in a machine learning project, whether for sharing
    results, analyzing them, or helping people navigate the data.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图表具有强大的沟通能力，它们能够以人类大脑易于理解的方式同时展示多种类型的信息。这一特性在机器学习项目中非常重要，无论是用于分享结果、分析它们，还是帮助人们导航数据。
- en: Graph-powered data visualization features include
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图表驱动的数据可视化特性包括
- en: '*Data navigation*—Networks are useful for displaying data by highlighting connections
    between elements. They can be used both as aids to help people navigate the data
    properly and as powerful investigation tools.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据导航*—网络通过突出元素之间的连接来显示数据。它们既可以作为帮助人们正确导航数据的辅助工具，也可以作为强大的调查工具。'
- en: '*Human-brain analysis*—Displaying data in the form of a graph unleashes the
    power of machine learning by combining it with the power of the human brain, enabling
    efficient, advanced, and sophisticated data processing and pattern recognition.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人类大脑分析*—以图表的形式展示数据通过结合人类大脑的力量和机器学习的力量，释放了机器学习的潜力，实现了高效、高级和复杂的数据处理和模式识别。'
- en: '*Improved communication*—Graphs—in particular, property graphs—are “whiteboard
    friendly,” which means they are conceptually represented on a board as they are
    stored in the database. This feature reduces the gap between the technicalities
    of a complex model and the way in which it is communicated to the domain experts
    or stakeholders. Effective communication improves the quality of the final results
    because it reduces issues with the comprehension of the domain, the business goals,
    and the needs and constraints of the project.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*改进沟通*—图表—特别是属性图—是“白板友好”的，这意味着它们在数据库中存储的方式与在白板上表示的方式概念上是一致的。这一特性缩小了复杂模型的技术细节与将其传达给领域专家或利益相关者之间的差距。有效的沟通提高了最终结果的质量，因为它减少了领域理解、业务目标、项目需求和限制方面的问题。'
- en: Improved communication is particularly important during the business and data
    understanding phases, whereas data navigation and human-brain analysis are related
    mostly to the evaluation phase.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在业务和数据理解阶段，改进沟通尤为重要，而数据导航和人类大脑分析主要与评估阶段相关。
- en: 1.5 Book mental model
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 书籍心智模型
- en: The mind map presented in this chapter helps you visualize easily where graphs
    fit in machine learning projects. It doesn’t mean that, in all the projects, you
    will use graphs for everything listed there. In several examples throughout this
    book, graphs are used to overcome some issues or improve performance (both in
    terms of quality and quantity); it would be useful to have a mental model that
    helps you understand, by looking at a simple image, the role of graphs in that
    specific case.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中展示的心智图帮助您轻松地可视化图表在机器学习项目中的位置。这并不意味着在所有项目中，您都会使用图表来完成那里列出的所有事情。在本书的几个示例中，图表被用来克服一些问题或提高性能（无论是质量还是数量）；拥有一个帮助您通过简单的图像了解图表在特定情况下作用的思维模型将是有用的。
- en: 'The next schema organizes the key features (*contact points*) in the graph-powered
    machine learning mind map into the four main tasks of a machine learning workflow:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个架构将图表驱动的机器学习心智图中的关键特征（*接触点*）组织成机器学习工作流程的四个主要任务：
- en: '*Managing the data sources*, which refers to all the tasks of gathering, merging,
    cleaning, and preparing the training dataset for the learning phase'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*管理数据源*，指的是收集、合并、清理和准备训练数据集以供学习阶段的所有任务'
- en: '*Learning*, which involves the application of machine learning algorithms to
    the training dataset'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习*，涉及将机器学习算法应用于训练数据集'
- en: '*Storing and accessing the model*, which includes approaches for storing the
    predictive model and the access pattern for providing predictions'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*存储和访问模型*，包括存储预测模型的方法以及提供预测的访问模式'
- en: '*Visualizing*, which refers to the way in which data can be visualized to support
    the analysis'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可视化*，指的是数据可视化的方式，以支持分析'
- en: These points are summarized in the mental map shown in figure 1.14.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这些要点总结在图1.14中展示的心智图中。
- en: '![CH01_F14_Negro](../Images/CH01_F14_Negro.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![CH01_F14_Negro](../Images/CH01_F14_Negro.png)'
- en: Figure 1.14 A mental model describing the four stages of a machine learning
    project
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.14 描述机器学习项目四个阶段的思维模型
- en: This figure will recur often in the book. The schema will help you figure out
    immediately where the current discussion fits in the project workflow.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 此图将在书中反复出现。该方案将帮助您立即了解当前讨论在项目工作流程中的位置。
- en: This mental model presents the machine learning project from a process perspective
    and is the best way to figure out where you are in the life cycle. But it is also
    useful to think about the project from a broader, task-oriented perspective.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这种心智模型从过程角度展示了机器学习项目，这是确定你在生命周期中处于何种位置的最佳方式。但同时也从更广泛、以任务为导向的角度思考项目也是有用的。
- en: Summary
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Machine learning aims to develop computer programs that gain experience from
    sample data autonomously, converting it to expertise without being explicitly
    programmed.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的目标是开发计算机程序，这些程序可以从样本数据中自主获得经验，将其转化为专业知识，而无需明确编程。
- en: A machine learning project is not only a software project, but also a human
    process that involves a bunch of people with different skills and a lot of work.
    It requires a well-defined and systematic approach to succeed. CRISP-DM provides
    the formal project life cycle to drive such a project, helping deliver the right
    results.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习项目不仅是一个软件项目，也是一个涉及众多不同技能的人的复杂的人类过程。它需要一种明确和系统的方法才能成功。CRISP-DM提供了正式的项目生命周期来推动这样的项目，帮助实现正确的结果。
- en: The challenges that any machine learning project has to deal with are related
    mostly to data management—either in terms of the training dataset or the prediction
    model—and the performance of the learning algorithm.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何机器学习项目必须应对的挑战主要与数据管理相关——无论是训练数据集还是预测模型——以及学习算法的性能。
- en: Graphs are simple mathematical concepts that can be used to model and analyze
    complex networks. The surrounding context outside the network operates on it,
    determining how it evolves.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图是简单的数学概念，可以用来模拟和分析复杂网络。网络外的周围环境对其产生影响，决定了其如何演变。
- en: 'Graphs and networks can empower machine learning projects in several ways,
    in three dimensions: data management, data analysis, and data visualization.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图和网络可以从数据管理、数据分析、数据可视化三个维度提升机器学习项目的能力。
- en: References
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Banko and Brill, 2001] Banko, Michele, and Eric Brill. “Scaling to Very Very
    Large Corpora for Natural Language Disambiguation.” Proceedings of the 39th Annual
    Meeting on Association for Computational Linguistics (2001): 26-33.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[Banko and Brill, 2001] Banko, Michele, and Eric Brill. “Scaling to Very Very
    Large Corpora for Natural Language Disambiguation.” Proceedings of the 39th Annual
    Meeting on Association for Computational Linguistics (2001): 26-33.'
- en: '[Diestel, 2017] Diestel, Reinhard. *Graph Theory*. 5th ed. New York: Springer,
    2017.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[Diestel, 2017] Diestel, Reinhard. *Graph Theory*. 5th ed. New York: Springer,
    2017.'
- en: '[Easley and Kleinberg, 2010] Easley, David, and Jon Kleinberg. *Networks, Crowds,
    and Markets: Reasoning About a Highly Connected World*. Cambridge, UK: Cambridge
    University Press, 2010.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[Easley and Kleinberg, 2010] Easley, David, and Jon Kleinberg. *Networks, Crowds,
    and Markets: Reasoning About a Highly Connected World*. Cambridge, UK: Cambridge
    University Press, 2010.'
- en: '[Euler, 1736] Euler, Leonhard. “Solutio Problematis ad Geometriam Situs Pertinentis.”
    *Comment. Acad. Sci. U. Petrop* 8 (1736): 128-40.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '[Euler, 1736] Euler, Leonhard. “Solutio Problematis ad Geometriam Situs Pertinentis.”
    *Comment. Acad. Sci. U. Petrop* 8 (1736): 128-40.'
- en: '[Halevy, Norvig, and Pereria, 2009] Halevy, Alon, Peter Norvig, and Fernando
    Pereira. “The Unreasonable Effectiveness of Data.” Intelligent Systems, IEEE 24:2
    (2009): 8-12.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[Halevy, Norvig, and Pereria, 2009] Halevy, Alon, Peter Norvig, and Fernando
    Pereira. “The Unreasonable Effectiveness of Data.” Intelligent Systems, IEEE 24:2
    (2009): 8-12.'
- en: '[Krebs, 2012] Krebs, Valdis. “Political Book Networks.” TNT: The Network Thinkers,
    October 2012\. [http://www.thenetworkthinkers.com/2012/10/2012-political-book-network.html](http://www.thenetworkthinkers.com/2012/10/2012-political-book-network.html).'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[Krebs, 2012] Krebs, Valdis. “Political Book Networks.” TNT: The Network Thinkers,
    October 2012\. [http://www.thenetworkthinkers.com/2012/10/2012-political-book-network.html](http://www.thenetworkthinkers.com/2012/10/2012-political-book-network.html).'
- en: '[Linoff and Berry, 2011] Linoff, Gordon S., and Michael J. A. Berry. *Data
    Mining Techniques: For Marketing, Sales, and Customer Relationship Management*.
    3rd ed. Hoboken, NJ: Wiley, 2011.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '[Linoff and Berry, 2011] Linoff, Gordon S., and Michael J. A. Berry. *Data
    Mining Techniques: For Marketing, Sales, and Customer Relationship Management*.
    3rd ed. Hoboken, NJ: Wiley, 2011.'
- en: '[Lohr, 2014] Lohr, Steve. “For Big-Data Scientists, ‘Janitor Work’ Is Key Hurdle
    to Insights.” New York Times, August 15, 2014\. [http://mng.bz/K4wn](https://shortener.manning.com/K4wn).'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '[Lohr, 2014] Lohr, Steve. “For Big-Data Scientists, ‘Janitor Work’ Is Key Hurdle
    to Insights.” New York Times, August 15, 2014\. [http://mng.bz/K4wn](https://shortener.manning.com/K4wn).'
- en: '[Mihalcea et al., 2011] Mihalcea, Rada, and Dragomir Radev. *Graph-Based Natural
    Language Processing and Information Retrieval*. Cambridge, UK: Cambridge University
    Press, 2011.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mihalcea 等人，2011] Mihalcea, Rada，和 Dragomir Radev. *基于图的自然语言处理和信息检索*。英国剑桥：剑桥大学出版社，2011年。'
- en: '[Russell and Norvig, 2009] Russell, Stuart J., and Peter Norvig. *Artificial
    Intelligence: A Modern Approach*. 3rd ed. Upper Saddle River, NJ: Pearson, 2009.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '[Russell 和 Norvig, 2009] Russell, Stuart J.，和 Peter Norvig. *人工智能：现代方法*。第3版。新泽西州上萨德尔河：皮尔逊，2009年。'
- en: '[Samuel, 1959] Samuel, Arthur L. “Some Studies in Machine Learning Using the
    Game of Checkers.” *IBM Journal of Research and Development* 3:3 (July 1959):
    210-229.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '[Samuel, 1959] Samuel, Arthur L. “使用国际象棋游戏进行机器学习的一些研究。” *IBM 研究与发展杂志* 3:3（1959年7月）：210-229.'
- en: '[Sculley, 2015] Sculley, D. , Gary Holt, Daniel Golovin, Eugene Davydov, Todd
    Phillips, Dietmar Ebner, Vinay Chaudhary, Michael Young, Jean-Francois Crespo,
    and Dan Dennison. 2015\. “Hidden technical debt in Machine learning systems.”
    In Proceedings of the 28th International Conference on Neural Information Processing
    Systems—Volume 2 (NIPS15). MIT Press, Cambridge, MA, USA, 2503-2511.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sculley, 2015] Sculley, D.，Gary Holt，Daniel Golovin，Eugene Davydov，Todd Phillips，Dietmar
    Ebner，Vinay Chaudhary，Michael Young，Jean-Francois Crespo，和 Dan Dennison. 2015.
    “机器学习系统中的隐藏技术债务。” 第28届国际神经网络信息处理系统会议——第2卷（NIPS15）。麻省理工学院出版社，美国剑桥，马萨诸塞州，2503-2511.'
- en: '[Shalev-Shwartz and Ben-David, 2014] Shalev-Shwartz, Shai, and Shai Ben-David.
    *Understanding Machine Learning: From Theory to Algorithms*. Cambridge, UK: Cambridge
    University Press, 2014.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '[Shalev-Shwartz 和 Ben-David, 2014] Shalev-Shwartz, Shai，和 Shai Ben-David. *理解机器学习：从理论到算法*。英国剑桥：剑桥大学出版社，2014年。'
- en: '[Verbrugge, 1977] Verbrugge, Lois M. “The Structure of Adult Friendship Choices.”
    *Social Forces* 56 (1977): 576-597.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '[Verbrugge, 1977] Verbrugge, Lois M. “成年友谊选择的结构。” *社会力量* 56（1977年）：576-597.'
- en: '[Wirth and Hipp, 2000] Wirth, R., and J. Hipp. “CRISP-DM: Towards a Standard
    Process Model for Data Mining.” Proceedings of the Fourth International Conference
    on the Practical Application of Knowledge Discovery and Data Mining (2000): 29-39.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '[Wirth 和 Hipp, 2000] Wirth, R., 和 J. Hipp. “CRISP-DM：数据挖掘的标准流程模型。” 第四届国际知识发现和数据挖掘实际应用会议论文集（2000年）：29-39.'
- en: '* * *'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '^(1.)According to Russell and Norvig [2009], an agent is something that acts.
    (*Agent* comes from the Latin *agere*, to do.) All computer programs do something,
    but computer agents are expected to do more: operate autonomously, perceive their
    environment, persist over a prolonged period, adapt to change, and create and
    pursue goals.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ^(1.)根据 Russell 和 Norvig [2009] 的说法，一个智能体是某种能够行动的东西。（“智能体”一词来源于拉丁语“agere”，意为“做。”）所有计算机程序都会做某些事情，但计算机智能体被期望做更多：自主操作、感知其环境、在长时间内持续存在、适应变化，并创造和追求目标。
- en: ^(2.)According to the Stanford Encyclopedia of Philosophy website ([https://plato.stanford.edu/entries/logic-inductive](https://plato.stanford.edu/entries/logic-inductive)),
    in *inductive* logic, the premises should provide support for the conclusion to
    some extent. By contrast, in *deductive* reasoning, the premises logically entail
    the conclusion. For this reason (although some people disagree with this definition),
    *induction* is sometimes defined as the process of deriving general principles
    from specific observation.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ^(2.)根据斯坦福哲学百科全书网站（[https://plato.stanford.edu/entries/logic-inductive](https://plato.stanford.edu/entries/logic-inductive)）的说法，在*归纳*逻辑中，前提应在一定程度上支持结论。相比之下，在*演绎*推理中，前提逻辑上蕴含结论。因此（尽管有些人不同意这个定义），*归纳*有时被定义为从具体观察中推导出一般原则的过程。
- en: ^(3.)Appendix A (about machine learning taxonomy) contains some examples of
    algorithms that create a prediction model.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ^(3.)附录A（关于机器学习分类）包含了一些创建预测模型的算法示例。
- en: ^(4.)*Standard deviation* is a measure expressing how much the members of a
    group differ from the mean value for the group.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ^(4.)“标准差”是一个衡量组内成员与组平均值的差异程度的度量。
- en: ^(5.)If concepts such as instance-based algorithms and batch learning are new
    to you, please refer to appendix A, which covers machine learning taxonomy.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ^(5.)如果您对实例化算法和批量学习等概念不熟悉，请参阅附录A，它涵盖了机器学习分类。
- en: ^(6.)In this context, the verb *model* is used in terms of representing a system
    or phenomenon in a simplified way. Modeling also aims at representing the data
    in such a way that it can be processed easily by a computer system.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ^(6.)在此语境中，动词“模型”是指以简化的方式表示一个系统或现象。建模还旨在以计算机系统易于处理的方式表示数据。
- en: ^(7.)Higuchi Koichi—Co-occurrence screen shot of KH Coder ([https://en.wikipedia.org/wiki/Co-occurrence_
    network](https://en.wikipedia.org/wiki/Co-occurrence_network)).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: (7.)Higuchi Koichi—KH Coder 的共现屏幕截图 ([https://en.wikipedia.org/wiki/Co-occurrence_network](https://en.wikipedia.org/wiki/Co-occurrence_network)).
- en: ^(8.)Yngvar—Symbolic representation of the ARPANET as of September 1974 ([https://en.wikipedia.org/wiki/
    ARPANET](https://en.wikipedia.org/wiki/ARPANET)).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: (8.)Yngvar—1974年9月ARPANET的符号表示 ([https://en.wikipedia.org/wiki/ARPANET](https://en.wikipedia.org/wiki/ARPANET)).
- en: ^(9.)Courtesy Transport for London ([http://mng.bz/G6wN](https://shortener.manning.com/G6wN)).
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: (9.)伦敦交通局提供 ([http://mng.bz/G6wN](https://shortener.manning.com/G6wN)).
- en: ^(10.)Paul Cuffe—Network diagram of a high voltage transmission system, showing
    the interconnection between the different voltage levels ([https://en.wikipedia.org/wiki/Electrical_grid](https://en.wikipedia.org/wiki/Electrical_grid)).
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: (10.)Paul Cuffe—高压输电系统的网络图，显示了不同电压级别之间的互联 ([https://en.wikipedia.org/wiki/Electrical_grid](https://en.wikipedia.org/wiki/Electrical_grid)).
- en: ^(11.)[https://panamapapers.icij.org](https://panamapapers.icij.org).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: (11.)[https://panamapapers.icij.org](https://panamapapers.icij.org).
- en: ^(12.)[http://www.thenetworkthinkers.com](http://www.thenetworkthinkers.com).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: (12.)[http://www.thenetworkthinkers.com](http://www.thenetworkthinkers.com).
- en: ^(13.)Mathematical *Platonism* ([http://mng.bz/zG2Z](https://shortener.manning.com/zG2Z))
    is the metaphysical view that there are abstract mathematical objects whose existence
    is independent of us and our language, thought, and practices.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: (13.)数学*柏拉图主义* ([http://mng.bz/zG2Z](https://shortener.manning.com/zG2Z)) 是一种形而上学观点，认为存在抽象的数学对象，其存在独立于我们以及我们的语言、思想和实践。
- en: ^(14.)[http://mng.bz/0rzz](https://shortener.manning.com/0rzz)
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: (14.)[http://mng.bz/0rzz](https://shortener.manning.com/0rzz)
