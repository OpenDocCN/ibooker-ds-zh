- en: Chapter 2\. Data and Sampling Distributions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章 数据和抽样分布
- en: A popular misconception holds that the era of big data means the end of a need
    for sampling. In fact, the proliferation of data of varying quality and relevance
    reinforces the need for sampling as a tool to work efficiently with a variety
    of data and to minimize bias. Even in a big data project, predictive models are
    typically developed and piloted with samples. Samples are also used in tests of
    various sorts (e.g., comparing the effect of web page designs on clicks).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 一种普遍的误解认为大数据时代意味着不再需要抽样。事实上，各种质量和相关性的数据大量增加反而强化了抽样作为一种工具，以有效处理各种数据并尽量减少偏差。即使在大数据项目中，预测模型通常也是通过样本进行开发和试验的。样本也用于各种测试中（例如，比较网页设计对点击效果的影响）。
- en: '[Figure 2-1](#sampling_schematic) shows a schematic that underpins the concepts
    we will discuss in this chapter—data and sampling distributions. The lefthand
    side represents a population that, in statistics, is assumed to follow an underlying
    but *unknown* distribution. All that is available is the *sample* data and its
    empirical distribution, shown on the righthand side. To get from the lefthand
    side to the righthand side, a *sampling* procedure is used (represented by an
    arrow). Traditional statistics focused very much on the lefthand side, using theory
    based on strong assumptions about the population. Modern statistics has moved
    to the righthand side, where such assumptions are not needed.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-1](#sampling_schematic)展示了本章讨论的概念的基础图示——数据和抽样分布。左侧代表了一个在统计学中假定遵循某种未知分布的总体。右侧展示了仅有的*样本*数据及其经验分布。从左侧到右侧，使用了一个*抽样*过程（用箭头表示）。传统统计学非常关注左侧，使用基于总体强假设的理论。现代统计学转向右侧，这里不需要这样的假设。'
- en: 'In general, data scientists need not worry about the theoretical nature of
    the lefthand side and instead should focus on the sampling procedures and the
    data at hand. There are some notable exceptions. Sometimes data is generated from
    a physical process that can be modeled. The simplest example is flipping a coin:
    this follows a binomial distribution. Any real-life binomial situation (buy or
    don’t buy, fraud or no fraud, click or don’t click) can be modeled effectively
    by a coin (with modified probability of landing heads, of course). In these cases,
    we can gain additional insight by using our understanding of the population.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，数据科学家无需关注左侧的理论性质，而应集中精力于抽样程序和手头的数据。当然也有一些显著的例外情况。有时数据来自可以建模的物理过程。最简单的例子是抛硬币：这遵循二项分布。任何真实的二项式情况（购买或不购买、欺诈或无欺诈、点击或不点击）都可以通过抛硬币（当然要考虑到头朝上的概率被修改）有效地建模。在这些情况下，通过理解总体，我们可以获得额外的洞察。
- en: '![images/sampling_schematic.png](Images/psd2_0201.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![images/sampling_schematic.png](Images/psd2_0201.png)'
- en: Figure 2-1\. Population versus sample
  id: totrans-5
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-1 总体与样本
- en: Random Sampling and Sample Bias
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机抽样和样本偏差
- en: A *sample* is a subset of data from a larger data set; statisticians call this
    larger data set the *population*. A population in statistics is not the same thing
    as in biology—it is a large, defined (but sometimes theoretical or imaginary)
    set of data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*样本*是从较大数据集中取出的一部分数据；统计学家称这个较大的数据集为*总体*。在统计学中，总体与生物学中的概念不同——它是一个大的、定义明确（但有时是理论的或想象的）的数据集。'
- en: '*Random sampling* is a process in which each available member of the population
    being sampled has an equal chance of being chosen for the sample at each draw.
    The sample that results is called a *simple random sample*. Sampling can be done
    *with replacement*, in which observations are put back in the population after
    each draw for possible future reselection. Or it can be done *without replacement*,
    in which case observations, once selected, are unavailable for future draws.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*随机抽样*是一个过程，其中总体中每个可用成员在每次抽样中被选中的机会都是相等的。结果得到的样本称为*简单随机样本*。抽样可以*有放回*进行，即在每次抽样后将观察结果放回总体，以便可能在未来再次选择。或者可以*无放回*进行，此时一旦选择了观察结果，它们就不再可用于未来的抽样。'
- en: Data quality often matters more than data quantity when making an estimate or
    a model based on a sample. Data quality in data science involves completeness,
    consistency of format, cleanliness, and accuracy of individual data points. Statistics
    adds the notion of *representativeness*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于样本进行估计或建模时，数据质量通常比数据量更重要。数据质量在数据科学中涉及数据点的完整性、格式的一致性、数据的清洁度和准确性。统计学则增加了*代表性*的概念。
- en: The classic example is the *Literary Digest* poll of 1936 that predicted a victory
    of Alf Landon over Franklin Roosevelt. The *Literary Digest*, a leading periodical
    of the day, polled its entire subscriber base plus additional lists of individuals,
    a total of over 10 million people, and predicted a landslide victory for Landon.
    George Gallup, founder of the Gallup Poll, conducted biweekly polls of just 2,000
    people and accurately predicted a Roosevelt victory. The difference lay in the
    selection of those polled.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 经典例子是1936年的*文学文摘*民意测验，预测阿尔夫·兰登将战胜富兰克林·罗斯福。当时的主要期刊*文学文摘*对其所有订阅者以及额外的个人名单进行了民意调查，总计超过1000万人，并预测兰登将大获全胜。盖洛普民意调查创始人乔治·盖洛普每两周对仅2000人进行调查，并准确预测了罗斯福的胜利。差异在于被调查者的选择。
- en: The *Literary Digest* opted for quantity, paying little attention to the method
    of selection. They ended up polling those with relatively high socioeconomic status
    (their own subscribers, plus those who, by virtue of owning luxuries like telephones
    and automobiles, appeared in marketers’ lists). The result was *sample bias*;
    that is, the sample was different in some meaningful and nonrandom way from the
    larger population it was meant to represent. The term *nonrandom* is important—hardly
    any sample, including random samples, will be exactly representative of the population.
    Sample bias occurs when the difference is meaningful, and it can be expected to
    continue for other samples drawn in the same way as the first.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*文学文摘*选择了数量，几乎没有关注选择方法。他们最终对具有相对较高社会经济地位的人群进行了调查（他们自己的订阅者，加上那些由于拥有电话和汽车等奢侈品而出现在市场营销名单中的人）。结果产生了*样本偏差*；即样本在某些有意义且非随机方式上与其所代表的更大人口不同。术语*非随机*很重要——几乎没有一个样本，包括随机样本，在精确代表整体人口方面都是完全代表性的。样本偏差发生在差异有意义时，并且预计在以与第一个样本相同方式抽取的其他样本中将继续存在。'
- en: Self-Selection Sampling Bias
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自我选择抽样偏见
- en: The reviews of restaurants, hotels, cafés, and so on that you read on social
    media sites like Yelp are prone to bias because the people submitting them are
    not randomly selected; rather, they themselves have taken the initiative to write.
    This leads to self-selection bias—the people motivated to write reviews may have
    had poor experiences, may have an association with the establishment, or may simply
    be a different type of person from those who do not write reviews. Note that while
    self-selection samples can be unreliable indicators of the true state of affairs,
    they may be more reliable in simply comparing one establishment to a similar one;
    the same self-selection bias might apply to each.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在像Yelp这样的社交媒体网站上读到的餐厅、酒店、咖啡馆等的评论往往带有偏见，因为提交评论的人并非随机选取，而是自愿撰写评论。这导致了自我选择偏见——那些有动力撰写评论的人可能有不好的经历，可能与该机构有关联，或者可能只是与不撰写评论的人群不同类型的人。需要注意的是，虽然自我选择样本可能不可靠地反映真实情况，但在简单比较一个机构与类似机构时可能更可靠；同样的自我选择偏见可能适用于每个样本。
- en: Bias
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏差
- en: Statistical bias refers to measurement or sampling errors that are systematic
    and produced by the measurement or sampling process. An important distinction
    should be made between errors due to random chance and errors due to bias. Consider
    the physical process of a gun shooting at a target. It will not hit the absolute
    center of the target every time, or even much at all. An unbiased process will
    produce error, but it is random and does not tend strongly in any direction (see
    [Figure 2-2](#gun1)). The results shown in [Figure 2-3](#gun2) show a biased process—there
    is still random error in both the x and y direction, but there is also a bias.
    Shots tend to fall in the upper-right quadrant.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 统计偏差是指由测量或抽样过程中产生的系统性测量或抽样误差。重要的区别应该在于由随机机会引起的错误与由偏差引起的错误。考虑一支枪射击目标的物理过程。它不会每次都精确命中目标的中心，甚至几乎不会。一个无偏的过程会产生误差，但是这些误差是随机的，并且不会明显偏向任何方向（见[图 2-2](#gun1)）。在[图 2-3](#gun2)中展示的结果显示了一个有偏的过程——在x和y方向上仍然存在随机误差，但也存在偏差。子弹倾向于落在右上象限。
- en: '![images/Target-scatter.png](Images/psd2_0202.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![images/Target-scatter.png](Images/psd2_0202.png)'
- en: Figure 2-2\. Scatterplot of shots from a gun with true aim
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-2\. 有真实瞄准的枪击散点图
- en: '![images/Target-scatter-bias.png](Images/psd2_0203.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![images/Target-scatter-bias.png](Images/psd2_0203.png)'
- en: Figure 2-3\. Scatterplot of shots from a gun with biased aim
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-3\. 有偏瞄准的枪击散点图
- en: Bias comes in different forms, and may be observable or invisible. When a result
    does suggest bias (e.g., by reference to a benchmark or actual values), it is
    often an indicator that a statistical or machine learning model has been misspecified,
    or an important variable left out.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差有不同的形式，可以是可观察的，也可以是看不见的。当结果确实表明偏差时（例如，通过参考基准或实际值），这通常表明统计模型或机器学习模型被错误规定，或者遗漏了重要变量。
- en: Random Selection
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机选择
- en: To avoid the problem of sample bias that led the *Literary Digest* to predict
    Landon over Roosevelt, George Gallup (shown in [Figure 2-4](#Gallup)) opted for
    more scientifically chosen methods to achieve a sample that was representative
    of the US voting electorate. There are now a variety of methods to achieve representativeness,
    but at the heart of all of them lies *random sampling*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免样本偏差问题，这也导致*文摘*预测兰登胜过罗斯福，乔治·盖洛普（如图[2-4](#Gallup)所示）选择了更科学的方法来实现代表美国选民的样本。现在有各种方法来实现代表性，但所有方法的核心都是*随机抽样*。
- en: '![Gallup](Images/psd2_0204.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![盖洛普](Images/psd2_0204.png)'
- en: Figure 2-4\. George Gallup, catapulted to fame by the *Literary Digest’s* “big
    data” failure
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-4\. 乔治·盖洛普，通过*文摘*的“大数据”失败而声名鹊起
- en: Random sampling is not always easy. Proper definition of an accessible population
    is key. Suppose we want to generate a representative profile of customers and
    we need to conduct a pilot customer survey. The survey needs to be representative
    but is labor intensive.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 随机抽样并不总是容易。正确定义可访问人口是关键。假设我们想生成客户的代表性概况，我们需要进行一项试点客户调查。这项调查需要具有代表性，但工作量很大。
- en: First, we need to define who a customer is. We might select all customer records
    where purchase amount > 0. Do we include all past customers? Do we include refunds?
    Internal test purchases? Resellers? Both billing agent and customer?
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要定义谁是客户。我们可能选择所有购买金额大于 0 的客户记录。我们是否包括所有过去的客户？是否包括退款？内部测试购买？经销商？无论是结算代理还是客户？
- en: Next, we need to specify a sampling procedure. It might be “select 100 customers
    at random.” Where a sampling from a flow is involved (e.g., real-time customer
    transactions or web visitors), timing considerations may be important (e.g., a
    web visitor at 10 a.m. on a weekday may be different from a web visitor at 10
    p.m. on a weekend).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要指定抽样程序。可以是“随机选择 100 名客户”。如果涉及从流量中抽样（例如实时客户交易或网页访问者），时间考虑可能很重要（例如工作日上午
    10 点的网页访问者可能与周末晚上 10 点的网页访问者有所不同）。
- en: In *stratified sampling*, the population is divided up into *strata*, and random
    samples are taken from each stratum. Political pollsters might seek to learn the
    electoral preferences of whites, blacks, and Hispanics. A simple random sample
    taken from the population would yield too few blacks and Hispanics, so those strata
    could be overweighted in stratified sampling to yield equivalent sample sizes.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在*分层抽样*中，将人口分成*分层*，并从每个分层中进行随机抽样。政治民意调查员可能希望了解白人、黑人和西班牙裔的选举偏好。从总体中进行简单随机抽样可能会产生过少的黑人和西班牙裔样本，因此在分层抽样中，这些分层可以加权，以获得等效的样本量。
- en: 'Size Versus Quality: When Does Size Matter?'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规模与质量：什么时候规模重要？
- en: In the era of big data, it is sometimes surprising that smaller is better. Time
    and effort spent on random sampling not only reduces bias but also allows greater
    attention to data exploration and data quality. For example, missing data and
    outliers may contain useful information. It might be prohibitively expensive to
    track down missing values or evaluate outliers in millions of records, but doing
    so in a sample of several thousand records may be feasible. Data plotting and
    manual inspection bog down if there is too much data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在大数据时代，有时候较小的数据量更好。花在随机抽样上的时间和精力不仅可以减少偏差，还可以更多地关注数据探索和数据质量。例如，缺失数据和异常值可能包含有用的信息。追踪数百万条记录中的缺失值或评估异常值可能成本过高，但在数千条记录的样本中进行这样的操作可能是可行的。数据绘图和手动检查在数据量过大时会拖累工作进度。
- en: So when *are* massive amounts of data needed?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要大量数据时*呢*？
- en: The classic scenario for the value of big data is when the data is not only
    big but sparse as well. Consider the search queries received by Google, where
    columns are terms, rows are individual search queries, and cell values are either
    0 or 1, depending on whether a query contains a term. The goal is to determine
    the best predicted search destination for a given query. There are over 150,000
    words in the English language, and Google processes over one trillion queries
    per year. This yields a huge matrix, the vast majority of whose entries are “0.”
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据的价值经典场景是当数据不仅大而且稀疏时。考虑到谷歌收到的搜索查询，其中列是术语，行是单个搜索查询，单元格的值要么是0，要么是1，这取决于查询是否包含术语。目标是确定给定查询的最佳预测搜索目的地。英语语言中有超过15万个词汇，谷歌每年处理超过一万亿次查询。这产生了一个巨大的矩阵，其中绝大多数条目都是“0”。
- en: This is a true big data problem—only when such enormous quantities of data are
    accumulated can effective search results be returned for most queries. And the
    more data accumulates, the better the results. For popular search terms this is
    not such a problem—effective data can be found fairly quickly for the handful
    of extremely popular topics trending at a particular time. The real value of modern
    search technology lies in the ability to return detailed and useful results for
    a huge variety of search queries, including those that occur with a frequency,
    say, of only one in a million.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个真正的大数据问题——只有当积累了如此庞大的数据量时，才能为大多数查询返回有效的搜索结果。而且数据积累得越多，结果就越好。对于热门搜索词来说，这并不是问题——针对某个特定时间流行的几个极为热门主题，可以相对快速地找到有效数据。现代搜索技术的真正价值在于能够为各种各样的搜索查询返回详细和有用的结果，包括那些频率可能只有百万分之一的查询。
- en: Consider the search phrase “Ricky Ricardo and Little Red Riding Hood.” In the
    early days of the internet, this query would probably have returned results on
    the bandleader Ricky Ricardo, the television show *I Love Lucy* in which that
    character appeared, and the children’s story *Little Red Riding Hood*. Both of
    those individual items would have had many searches to refer to, but the combination
    would have had very few. Later, now that trillions of search queries have been
    accumulated, this search query returns the exact *I Love Lucy* episode in which
    Ricky narrates, in dramatic fashion, the *Little Red Riding Hood* story to his
    infant son in a comic mix of English and Spanish.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑搜索短语“瑞奇·里卡多和小红帽”。在互联网早期，这个查询可能会返回有关乐队领队瑞奇·里卡多以及他出现的电视节目*I Love Lucy*和儿童故事*小红帽*的结果。这两个单独的项目可能有很多搜索引用，但组合查询的结果可能非常少。现在，随着积累了数万亿个搜索查询，这个搜索查询返回的是确切的*I
    Love Lucy*集，其中瑞奇用戏剧化的方式向他的婴儿儿子讲述*小红帽*的故事，混合了英语和西班牙语。
- en: Keep in mind that the number of actual *pertinent* records—ones in which this
    exact search query, or something very similar, appears (together with information
    on what link people ultimately clicked on)—might need only be in the thousands
    to be effective. However, many trillions of data points are needed to obtain these
    pertinent records (and random sampling, of course, will not help). See also [“Long-Tailed
    Distributions”](#LongTailedData).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，实际*相关*记录的数量可能只需数千个就足够有效。然而，需要数万亿的数据点来获取这些相关记录（当然，随机抽样是无助的）。另请参见[“长尾分布”](#LongTailedData)。
- en: Sample Mean Versus Population Mean
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 样本均值与总体均值
- en: The symbol <math alttext="x overbar"><mover accent="true"><mi>x</mi> <mo>¯</mo></mover></math>
    (pronounced “x-bar”) is used to represent the mean of a sample from a population,
    whereas <math alttext="mu"><mi>μ</mi></math> is used to represent the mean of
    a population. Why make the distinction? Information about samples is observed,
    and information about large populations is often inferred from smaller samples.
    Statisticians like to keep the two things separate in the symbology.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 符号 <math alttext="x overbar"><mover accent="true"><mi>x</mi> <mo>¯</mo></mover></math>（发音为“x-bar”）用于表示来自总体的样本的均值，而
    <math alttext="mu"><mi>μ</mi></math> 用于表示总体的均值。为什么要区分？关于样本的信息是观察到的，而关于大群体的信息通常是从较小的样本中推断出来的。统计学家喜欢在符号中保持这两者的区分。
- en: Further Reading
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: A useful review of sampling procedures can be found in Ronald Fricker’s chapter
    “Sampling Methods for Online Surveys” in *The SAGE Handbook of Online Research
    Methods*, 2nd ed., edited by Nigel G. Fielding, Raymond M. Lee, and Grant Blank
    (SAGE Publications, 2016). This chapter includes a review of the modifications
    to random sampling that are often used for practical reasons of cost or feasibility.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Ronald Fricker的章节“在线调查的抽样方法”中，《The SAGE Handbook of Online Research Methods》第2版，由Nigel
    G. Fielding、Raymond M. Lee和Grant Blank编辑（SAGE Publications，2016）中可以找到有关抽样程序的有用审查。这一章节包括通常基于成本或可行性原因而使用的随机抽样修改的审查。
- en: The story of the *Literary Digest* poll failure can be found on the [Capital
    Century website](https://oreil.ly/iSoQT).
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文学文摘*投票失败的故事可以在[Capital Century website](https://oreil.ly/iSoQT)找到。'
- en: Selection Bias
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择偏差
- en: 'To paraphrase Yogi Berra: if you don’t know what you’re looking for, look hard
    enough and you’ll find it.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 引用约基·贝拉的话：如果你不知道在找什么，那就努力找，你会找到的。
- en: Selection bias refers to the practice of selectively choosing data—consciously
    or unconsciously—in a way that leads to a conclusion that is misleading or ephemeral.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 选择偏差是指有意或无意地选择数据的做法，以导致误导性或短暂的结论。
- en: 'If you specify a hypothesis and conduct a well-designed experiment to test
    it, you can have high confidence in the conclusion. This is frequently not what
    occurs, however. Often, one looks at available data and tries to discern patterns.
    But are the patterns real? Or are they just the product of *data snooping*—that
    is, extensive hunting through the data until something interesting emerges? There
    is a saying among statisticians: “If you torture the data long enough, sooner
    or later it will confess.”'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你提出一个假设并进行设计良好的实验来测试它，你可以对结论有很高的信心。然而，情况往往并非如此。通常，人们会查看现有数据并尝试识别模式。但这些模式是真实的吗？还是它们只是*数据窥探*的产物——即在数据中进行广泛搜索，直到发现有趣的东西？统计学家有一句话说：“如果你折磨数据足够长时间，迟早它会招供。”
- en: The difference between a phenomenon that you verify when you test a hypothesis
    using an experiment and a phenomenon that you discover by perusing available data
    can be illuminated with the following thought experiment.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用实验验证假设时，你可以发现一种现象，与通过浏览现有数据发现的现象有所不同，这可以通过以下思想实验来阐明。
- en: Imagine that someone tells you they can flip a coin and have it land heads on
    the next 10 tosses. You challenge them (the equivalent of an experiment), and
    they proceed to toss the coin 10 times, with all flips landing heads. Clearly
    you ascribe some special talent to this person—the probability that 10 coin tosses
    will land heads just by chance is 1 in 1,000.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，有人告诉你他们可以抛硬币，使其在接下来的10次抛掷中都能正面朝上。你对此提出质疑（相当于一个实验），他们继续抛掷硬币10次，所有抛掷都正面朝上。显然，你会认为这个人有些特殊的天赋——10次硬币抛掷都正面朝上的概率仅为1/1,000。
- en: Now imagine that the announcer at a sports stadium asks the 20,000 people in
    attendance each to toss a coin 10 times, and to report to an usher if they get
    10 heads in a row. The chance that *somebody* in the stadium will get 10 heads
    is extremely high (more than 99%—it’s 1 minus the probability that nobody gets
    10 heads). Clearly, selecting after the fact the person (or persons) who gets
    10 heads at the stadium does not indicate they have any special talent—it’s most
    likely luck.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下，体育场的播音员要求出席的20,000人每人抛硬币10次，并在抛出10次正面时向礼官报告。在体育场中，*某人*得到10次正面的机会非常高（超过99%——这是没有人得到10次正面的概率）。显然，事后选择体育场中得到10次正面的人（或人们）并不表示他们有任何特殊的天赋——这很可能是运气。
- en: Since repeated review of large data sets is a key value proposition in data
    science, selection bias is something to worry about. A form of selection bias
    of particular concern to data scientists is what John Elder (founder of Elder
    Research, a respected data mining consultancy) calls the *vast search effect*.
    If you repeatedly run different models and ask different questions with a large
    data set, you are bound to find something interesting. But is the result you found
    truly something interesting, or is it the chance outlier?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于反复审查大数据集是数据科学的一个重要价值主张，选择偏差是一个需要担心的问题。数据科学家特别关注的一种选择偏差形式是约翰·埃尔德（Elder Research创始人，一家著名的数据挖掘咨询公司）所称的*vast
    search effect*。如果你反复运行不同的模型并使用大数据集提出不同的问题，你必定会找到一些有趣的东西。但你找到的结果是否真的有趣，还是偶然的离群值？
- en: We can guard against this by using a holdout set, and sometimes more than one
    holdout set, against which to validate performance. Elder also advocates the use
    of what he calls *target shuffling* (a permutation test, in essence) to test the
    validity of predictive associations that a data mining model suggests.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用一个保留集，有时甚至多个保留集，来验证性能。埃尔德还提倡使用他所称的*目标洗牌*（本质上是一种排列检验）来测试数据挖掘模型暗示的预测关联的有效性。
- en: Typical forms of selection bias in statistics, in addition to the vast search
    effect, include nonrandom sampling (see [“Random Sampling and Sample Bias”](#randomSampling_bias)),
    cherry-picking data, selection of time intervals that accentuate a particular
    statistical effect, and stopping an experiment when the results look “interesting.”
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学中典型的选择偏差形式，除了广泛的搜索效应外，还包括非随机抽样（见[“随机抽样和样本偏差”](#randomSampling_bias)）、挑选数据、选择强调特定统计效应的时间间隔以及在结果看起来“有趣”时停止实验。
- en: Regression to the Mean
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归到平均
- en: '*Regression to the mean* refers to a phenomenon involving successive measurements
    on a given variable: extreme observations tend to be followed by more central
    ones. Attaching special focus and meaning to the extreme value can lead to a form
    of selection bias.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*回归到平均*是指在给定变量上连续测量的现象：极端观察往往会被更加中心的观察所跟随。对极端值给予特殊关注和意义可能导致一种形式的选择偏差。'
- en: Sports fans are familiar with the “rookie of the year, sophomore slump” phenomenon.
    Among the athletes who begin their career in a given season (the rookie class),
    there is always one who performs better than all the rest. Generally, this “rookie
    of the year” does not do as well in his second year. Why not?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 体育迷熟悉“年度最佳新秀，第二年低迷”现象。在一个赛季开始职业生涯的运动员中（新秀班），总会有一个表现比其他所有人都好的。一般来说，这个“年度最佳新秀”在他的第二年表现不会那么好。为什么呢？
- en: 'In nearly all major sports, at least those played with a ball or puck, there
    are two elements that play a role in overall performance:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有主要的体育运动，至少那些使用球或冰球的运动，都有两个因素影响整体表现：
- en: Skill
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技巧
- en: Luck
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运气
- en: Regression to the mean is a consequence of a particular form of selection bias.
    When we select the rookie with the best performance, skill and good luck are probably
    contributing. In his next season, the skill will still be there, but very often
    the luck will not be, so his performance will decline—it will regress. The phenomenon
    was first identified by Francis Galton in 1886 [[Galton-1886]](bibliography01.xhtml#Galton-1886),
    who wrote of it in connection with genetic tendencies; for example, the children
    of extremely tall men tend not to be as tall as their father (see [Figure 2-5](#Galton)).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 回归到平均是特定形式选择偏差的结果。当我们选择表现最好的新秀时，技巧和好运可能都起到了作用。在他的下个赛季，技巧仍将存在，但很多时候好运不会再出现，所以他的表现会下降——即会回归。这种现象最早由弗朗西斯·高尔顿在1886年首次发现[[高尔顿-1886]](bibliography01.xhtml#Galton-1886)，他在与遗传倾向的关联中写到了它；例如，极端高个子男子的子女往往不会像他们的父亲那样高（见[图2-5](#Galton)）。
- en: '![Galton](Images/psd2_0205.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![高尔顿](Images/psd2_0205.png)'
- en: Figure 2-5\. Galton’s study that identified the phenomenon of regression to
    the mean
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-5\. 高尔顿的研究发现了回归到平均现象。
- en: Warning
  id: totrans-60
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Regression to the mean, meaning to “go back,” is distinct from the statistical
    modeling method of linear regression, in which a linear relationship is estimated
    between predictor variables and an outcome variable.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 回归到平均，意思是“回到原点”，与统计建模方法线性回归是不同的，线性回归是估计预测变量与结果变量之间的线性关系。
- en: Further Reading
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Christopher J. Pannucci and Edwin G. Wilkins’ article “Identifying and Avoiding
    Bias in Research” in (surprisingly not a statistics journal) *Plastic and Reconstructive
    Surgery* (August 2010) has an excellent review of various types of bias that can
    enter into research, including selection bias.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克里斯托弗·J·帕努奇和埃德温·G·威尔金斯在（令人惊讶的不是统计学期刊）*整形外科*（2010年8月）中的文章“识别和避免研究中的偏差”对可以进入研究的各种类型的偏差进行了优秀的回顾，包括选择偏差。
- en: Michael Harris’s article [“Fooled by Randomness Through Selection Bias”](https://oreil.ly/v_Q0u)
    provides an interesting review of selection bias considerations in stock market
    trading schemes, from the perspective of traders.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迈克尔·哈里斯的文章[“被随机性愚弄：通过选择偏差”](https://oreil.ly/v_Q0u)提供了对股市交易方案中选择偏差考虑的有趣回顾，从交易者的角度。
- en: Sampling Distribution of a Statistic
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 统计量的抽样分布
- en: The term *sampling distribution* of a statistic refers to the distribution of
    some sample statistic over many samples drawn from the same population. Much of
    classical statistics is concerned with making inferences from (small) samples
    to (very large) populations.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学术语中，一个统计量的*抽样分布*指的是同一总体中许多样本统计量的分布。经典统计学很大一部分关注于从（小）样本推断出（非常大）总体。
- en: Typically, a sample is drawn with the goal of measuring something (with a *sample
    statistic*) or modeling something (with a statistical or machine learning model).
    Since our estimate or model is based on a sample, it might be in error; it might
    be different if we were to draw a different sample. We are therefore interested
    in how different it might be—a key concern is *sampling variability*. If we had
    lots of data, we could draw additional samples and observe the distribution of
    a sample statistic directly. Typically, we will calculate our estimate or model
    using as much data as is easily available, so the option of drawing additional
    samples from the population is not readily available.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，样本是为了测量某些东西（使用*样本统计量*）或者建模某些东西（使用统计或机器学习模型）而抽取的。由于我们的估计或模型是基于样本的，所以可能存在误差；如果我们抽取不同的样本，可能会有所不同。因此，我们对可能存在的不同情况感兴趣—一个关键问题是*抽样变异性*。如果我们有大量数据，我们可以抽取额外的样本并直接观察样本统计量的分布。通常，我们将使用尽可能多的容易获取的数据来计算我们的估计或模型，因此从总体中抽取额外样本的选择并不容易。
- en: Warning
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: It is important to distinguish between the distribution of the individual data
    points, known as *the data distribution*, and the distribution of a sample statistic,
    known as the *sampling distribution*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要区分个别数据点的分布，称为*数据分布*，和样本统计量的分布，称为*抽样分布*。
- en: The distribution of a sample statistic such as the mean is likely to be more
    regular and bell-shaped than the distribution of the data itself. The larger the
    sample the statistic is based on, the more this is true. Also, the larger the
    sample, the narrower the distribution of the sample statistic.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 样本统计量如均值的分布可能比数据本身的分布更加规则和钟形。统计量基于的样本越大，这种情况就越明显。此外，样本越大，样本统计量的分布就越窄。
- en: 'This is illustrated in an example using annual income for loan applicants to
    LendingClub (see [“A Small Example: Predicting Loan Default”](ch06.xhtml#LoanExampleKNN)
    for a description of the data). Take three samples from this data: a sample of
    1,000 values, a sample of 1,000 means of 5 values, and a sample of 1,000 means
    of 20 values. Then plot a histogram of each sample to produce [Figure 2-6](#loans-mean-hist).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这在一个使用 LendingClub 的贷款申请人年收入的例子中进行了说明（见[“一个小例子：预测贷款违约”](ch06.xhtml#LoanExampleKNN)中对数据的描述）。从这些数据中取三个样本：1,000
    个值的样本，5 个值均值的 1,000 个样本，以及 20 个值均值的 1,000 个样本。然后绘制每个样本的直方图，生成[图 2-6](#loans-mean-hist)。
- en: '![Loans histogram](Images/psd2_0206.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![贷款直方图](Images/psd2_0206.png)'
- en: Figure 2-6\. Histogram of annual incomes of 1,000 loan applicants (top), then
    1,000 means of n=5 applicants (middle), and finally 1,000 means of n=20 applicants
    (bottom)
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-6\. 1,000 名贷款申请人年收入的直方图（顶部），然后 5 个申请人的 1,000 个均值（中部），最后是 20 个申请人的 1,000
    个均值（底部）
- en: 'The histogram of the individual data values is broadly spread out and skewed
    toward higher values, as is to be expected with income data. The histograms of
    the means of 5 and 20 are increasingly compact and more bell-shaped. Here is the
    *R* code to generate these histograms, using the visualization package `ggplot2`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 个别数据值的直方图广泛分布且向较高值倾斜，这在收入数据中是可以预期的。5 和 20 的均值直方图越来越紧凑，更呈钟形。以下是用可视化包`ggplot2`生成这些直方图的*R*代码：
- en: '[PRE0]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The *Python* code uses `seaborn`’s `FacetGrid` to show the three histograms:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*代码使用`seaborn`的`FacetGrid`来显示这三个直方图：'
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Central Limit Theorem
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 中心极限定理
- en: The phenomenon we’ve just described is termed the *central limit theorem*. It
    says that the means drawn from multiple samples will resemble the familiar bell-shaped
    normal curve (see [“Normal Distribution”](#NormalDist)), even if the source population
    is not normally distributed, provided that the sample size is large enough and
    the departure of the data from normality is not too great. The central limit theorem
    allows normal-approximation formulas like the t-distribution to be used in calculating
    sampling distributions for inference—that is, confidence intervals and hypothesis
    tests.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才描述的现象被称为*中心极限定理*。它表明，从多个样本中抽取的均值将类似于熟悉的钟形正态曲线（见[“正态分布”](#NormalDist)），即使源总体不服从正态分布，只要样本大小足够大且数据的偏离程度不是太大。中心极限定理允许使用类似t分布的正态近似公式来计算推断的抽样分布，例如置信区间和假设检验。
- en: The central limit theorem receives a lot of attention in traditional statistics
    texts because it underlies the machinery of hypothesis tests and confidence intervals,
    which themselves consume half the space in such texts. Data scientists should
    be aware of this role; however, since formal hypothesis tests and confidence intervals
    play a small role in data science, and the *bootstrap* (see [“The Bootstrap”](#bootstrap))
    is available in any case, the central limit theorem is not so central in the practice
    of data science.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 中心极限定理在传统统计学教材中受到广泛关注，因为它是假设检验和置信区间机制的基础，这些机制本身在这些教材中占据了相当大的篇幅。数据科学家应该意识到这一角色；然而，由于正式的假设检验和置信区间在数据科学中的作用不大，而*自助法*（见[“自助法”](#bootstrap)）在任何情况下都可用，因此中心极限定理在数据科学实践中并不如此核心。
- en: Standard Error
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标准误差
- en: 'The *standard error* is a single metric that sums up the variability in the
    sampling distribution for a statistic. The standard error can be estimated using
    a statistic based on the standard deviation *s* of the sample values, and the
    sample size *n*:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*标准误差*是用于统计量抽样分布中的变异性的单一度量。可以使用基于样本值标准偏差*s*和样本大小*n*的统计量来估计标准误差：'
- en: <math display="block"><mrow><mtext>Standard</mtext> <mtext>error</mtext> <mo>=</mo>
    <mi>S</mi> <mi>E</mi> <mo>=</mo> <mfrac><mi>s</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mtext>Standard</mtext> <mtext>error</mtext> <mo>=</mo>
    <mi>S</mi> <mi>E</mi> <mo>=</mo> <mfrac><mi>s</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
- en: 'As the sample size increases, the standard error decreases, corresponding to
    what was observed in [Figure 2-6](#loans-mean-hist). The relationship between
    standard error and sample size is sometimes referred to as the *square root of
    n* rule: to reduce the standard error by a factor of 2, the sample size must be
    increased by a factor of 4.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 随着样本大小的增加，标准误差减小，这与[图2-6](#loans-mean-hist)中观察到的情况相对应。标准误差与样本大小之间的关系有时被称为*n的平方根规则*：要将标准误差减少一半，样本大小必须增加四倍。
- en: 'The validity of the standard error formula arises from the central limit theorem.
    In fact, you don’t need to rely on the central limit theorem to understand standard
    error. Consider the following approach to measuring standard error:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 标准误差公式的有效性源于中心极限定理。实际上，你不需要依赖中心极限定理来理解标准误差。考虑以下测量标准误差的方法：
- en: Collect a number of brand-new samples from the population.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从总体中收集一些全新的样本。
- en: For each new sample, calculate the statistic (e.g., mean).
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个新样本，计算统计量（例如平均值）。
- en: Calculate the standard deviation of the statistics computed in step 2; use this
    as your estimate of standard error.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算步骤2中计算出的统计量的标准偏差；将其用作标准误差的估计值。
- en: In practice, this approach of collecting new samples to estimate the standard
    error is typically not feasible (and statistically very wasteful). Fortunately,
    it turns out that it is not necessary to draw brand new samples; instead, you
    can use *bootstrap* resamples. In modern statistics, the bootstrap has become
    the standard way to estimate standard error. It can be used for virtually any
    statistic and does not rely on the central limit theorem or other distributional
    assumptions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，收集新样本来估计标准误差通常是不可行的（并且在统计上非常浪费）。幸运的是，事实证明，不必抽取全新样本；相反，可以使用*自助法*重新取样。在现代统计学中，自助法已成为估计标准误差的标准方法。它可用于几乎任何统计量，并不依赖于中心极限定理或其他分布假设。
- en: Standard Deviation Versus Standard Error
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准差与标准误差
- en: Do not confuse standard deviation (which measures the variability of individual
    data points) with standard error (which measures the variability of a sample metric).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 不要混淆标准偏差（用于衡量单个数据点的变异性）与标准误差（用于衡量样本统计量的变异性）。
- en: Further Reading
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: David Lane’s [online multimedia resource in statistics](https://oreil.ly/pe7ra)
    has a useful simulation that allows you to select a sample statistic, a sample
    size, and the number of iterations and visualize a histogram of the resulting
    frequency distribution.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: David Lane的[在线统计多媒体资源](https://oreil.ly/pe7ra)具有一个有用的模拟，允许您选择一个样本统计量、一个样本大小和迭代次数，并可视化生成的频率分布直方图。
- en: The Bootstrap
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自举法
- en: One easy and effective way to estimate the sampling distribution of a statistic,
    or of model parameters, is to draw additional samples, with replacement, from
    the sample itself and recalculate the statistic or model for each resample. This
    procedure is called the *bootstrap*, and it does not necessarily involve any assumptions
    about the data or the sample statistic being normally distributed.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单而有效的估计统计分布或模型参数的方法是从样本本身进行额外抽样，有放回地，然后对每个重新抽样计算统计量或模型。这个过程称为*bootstrap*，并不一定涉及数据或样本统计量正态分布的任何假设。
- en: Conceptually, you can imagine the bootstrap as replicating the original sample
    thousands or millions of times so that you have a hypothetical population that
    embodies all the knowledge from your original sample (it’s just larger). You can
    then draw samples from this hypothetical population for the purpose of estimating
    a sampling distribution; see [Figure 2-7](#bootstrap-schematic-1).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，你可以将bootstrap想象成复制原始样本成千上万次或百万次，这样你就有一个假设的总体，它包含来自原始样本的所有知识（只是更大）。然后，您可以从这个假设的总体中抽样，以估计抽样分布；参见[图2-7](#bootstrap-schematic-1)。
- en: '![images/Bootstrap-schematic-1.png](Images/psd2_0207.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![images/Bootstrap-schematic-1.png](Images/psd2_0207.png)'
- en: Figure 2-7\. The idea of the bootstrap
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-7。bootstrap的概念
- en: 'In practice, it is not necessary to actually replicate the sample a huge number
    of times. We simply replace each observation after each draw; that is, we *sample
    with replacement*. In this way we effectively create an infinite population in
    which the probability of an element being drawn remains unchanged from draw to
    draw. The algorithm for a bootstrap resampling of the mean, for a sample of size
    *n*, is as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，并不需要大量复制样本。我们只需在每次抽取后替换每个观察值；也就是说，我们是*有放回地抽样*。通过这种方式，我们有效地创建了一个无限的总体，在这个总体中，从一个抽样到另一个抽样中抽取元素的概率保持不变。对于样本量为*n*的自举重新抽样平均值，算法如下：
- en: Draw a sample value, record it, and then replace it.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 抽取一个样本值，记录它，然后替换它。
- en: Repeat *n* times.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*n*次。
- en: Record the mean of the *n* resampled values.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记录*n*个重新抽样值的平均值。
- en: Repeat steps 1–3 *R* times.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤1–3 *R*次。
- en: 'Use the *R* results to:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 利用*R*的结果来：
- en: Calculate their standard deviation (this estimates sample mean standard error).
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算它们的标准差（这估计了样本均值的标准误差）。
- en: Produce a histogram or boxplot.
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制直方图或箱线图。
- en: Find a confidence interval.
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 寻找置信区间。
- en: '*R*, the number of iterations of the bootstrap, is set somewhat arbitrarily.
    The more iterations you do, the more accurate the estimate of the standard error,
    or the confidence interval. The result from this procedure is a bootstrap set
    of sample statistics or estimated model parameters, which you can then examine
    to see how variable they are.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*R*，bootstrap迭代次数，有些是任意设置的。你做的迭代次数越多，标准误差或置信区间的估计就越准确。此过程的结果是一组bootstrap样本统计或估计的模型参数，您可以检查它们的变化程度。'
- en: 'The *R* package `boot` combines these steps in one function. For example, the
    following applies the bootstrap to the incomes of people taking out loans:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*R*包`boot`将这些步骤结合在一个函数中。例如，以下将bootstrap应用于贷款人收入的情况：'
- en: '[PRE2]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The function `stat_fun` computes the median for a given sample specified by
    the index `idx`. The result is as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`stat_fun`计算给定索引`idx`的样本中位数。结果如下：
- en: '[PRE3]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The original estimate of the median is $62,000. The bootstrap distribution indicates
    that the estimate has a *bias* of about –$70 and a standard error of $209\. The
    results will vary slightly between consecutive runs of the algorithm.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的中位数估计值为$62,000。自举分布表明，估计值存在约为–$70的*bias*，标准误差为$209。算法连续运行的结果会略有不同。
- en: 'The major *Python* packages don’t provide implementations of the bootstrap
    approach. It can be implemented using the `scikit-learn` method `resample`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的*Python*包不提供bootstrap方法的实现。可以使用`scikit-learn`中的`resample`方法来实现：
- en: '[PRE4]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The bootstrap can be used with multivariate data, where the rows are sampled
    as units (see [Figure 2-8](#bootstrap-multivariate)). A model might then be run
    on the bootstrapped data, for example, to estimate the stability (variability)
    of model parameters, or to improve predictive power. With classification and regression
    trees (also called *decision trees*), running multiple trees on bootstrap samples
    and then averaging their predictions (or, with classification, taking a majority
    vote) generally performs better than using a single tree. This process is called
    *bagging* (short for “bootstrap aggregating”; see [“Bagging and the Random Forest”](ch06.xhtml#Bagging)).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 引导式自举可用于多变量数据，其中行作为单位进行抽样（见[图 2-8](#bootstrap-multivariate)）。例如，可以在引导样本数据上运行模型，以估计模型参数的稳定性（变异性），或者提高预测能力。对于分类和回归树（也称为*决策树*），在引导样本上运行多棵树，然后对它们的预测进行平均（或者在分类中进行多数投票），通常比使用单棵树效果更好。这个过程称为*装袋*（缩写为“引导聚合”；见[“装袋和随机森林”](ch06.xhtml#Bagging)）。
- en: '![images/Bootstrap-multivariate-schematic.png](Images/psd2_0208.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![images/Bootstrap-multivariate-schematic.png](Images/psd2_0208.png)'
- en: Figure 2-8\. Multivariate bootstrap sampling
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-8\. 多变量引导式抽样
- en: The repeated resampling of the bootstrap is conceptually simple, and Julian
    Simon, an economist and demographer, published a compendium of resampling examples,
    including the bootstrap, in his 1969 text *Basic Research Methods in Social Science*
    (Random House). However, it is also computationally intensive and was not a feasible
    option before the widespread availability of computing power. The technique gained
    its name and took off with the publication of several journal articles and a book
    by Stanford statistician Bradley Efron in the late 1970s and early 1980s. It was
    particularly popular among researchers who use statistics but are not statisticians,
    and for use with metrics or models where mathematical approximations are not readily
    available. The sampling distribution of the mean has been well established since
    1908; the sampling distribution of many other metrics has not. The bootstrap can
    be used for sample size determination; experiment with different values for *n*
    to see how the sampling distribution is affected.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 引导式自举的重复重抽样在概念上很简单，经济学家兼人口统计学家朱利安·西蒙（Julian Simon）在他1969年的文本《社会科学基础研究方法》（Random
    House）中发表了包括引导式自举在内的多种重抽样实例汇编。然而，它在计算上是非常密集的，而在广泛可用计算能力之前并不可行。该技术因斯坦福统计学家布拉德利·埃弗隆在1970年代末至1980年代初的几篇期刊文章和一本书的出版而得名并流行起来。它特别受到那些使用统计学但不是统计学家的研究人员欢迎，适用于数学近似不容易得到的指标或模型。均值的抽样分布自1908年已得到很好的建立；许多其他指标的抽样分布并未。引导式自举可以用于样本量的确定；尝试不同的*n*值以查看抽样分布如何受影响。
- en: The bootstrap was met with considerable skepticism when it was first introduced;
    it had the aura to many of spinning gold from straw. This skepticism stemmed from
    a misunderstanding of the bootstrap’s purpose.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 当引导式自举首次提出时，它遭遇了相当多的怀疑；对许多人来说，它具有从稻草中纺出金的神奇色彩。这种怀疑源于对引导式自举目的的误解。
- en: Warning
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: The bootstrap does not compensate for a small sample size; it does not create
    new data, nor does it fill in holes in an existing data set. It merely informs
    us about how lots of additional samples would behave when drawn from a population
    like our original sample.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 引导式自举不能补偿样本量不足；它不会创建新数据，也不会填补现有数据集中的空缺。它仅仅告诉我们，当从类似于我们原始样本的总体中抽取大量额外样本时，它们会如何行为。
- en: Resampling Versus Bootstrapping
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重抽样与引导式自举
- en: Sometimes the term *resampling* is used synonymously with the term *bootstrapping*,
    as just outlined. More often, the term *resampling* also includes permutation
    procedures (see [“Permutation Test”](ch03.xhtml#Permutation)), where multiple
    samples are combined and the sampling may be done without replacement. In any
    case, the term *bootstrap* always implies sampling with replacement from an observed
    data set.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 有时术语*重抽样*与*引导式自举*可以作为同义词使用，正如刚才所概述的。更多情况下，*重抽样*还包括置换程序（见[“置换检验”](ch03.xhtml#Permutation)），其中多个样本被合并，并且抽样可以无替换地进行。无论如何，术语*引导式自举*总是指从观察数据集中有替换地抽样。
- en: Further Reading
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*An Introduction to the Bootstrap* by Bradley Efron and Robert Tibshirani (Chapman
    & Hall, 1993) was the first book-length treatment of the bootstrap. It is still
    widely read.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*引导式自举法*，由布拉德利·埃弗隆（Bradley Efron）和罗伯特·蒂布什拉尼（Robert Tibshirani）合著（查普曼与霍尔出版社，1993年），是第一本有关引导式自举法的书籍。至今仍广受欢迎。'
- en: The retrospective on the bootstrap in the May 2003 issue of *Statistical Science*
    (vol. 18, no. 2), discusses (among other antecedents, in Peter Hall’s “A Short
    Prehistory of the Bootstrap”) Julian Simon’s initial publication of the bootstrap
    in 1969.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《统计科学》（第18卷，第2期）2003年5月份关于Bootstrap的回顾（在彼得·霍尔的“Bootstrap的简短前史”中讨论了其他先例，朱利安·西蒙于1969年首次发表了Bootstrap的初始论文）。
- en: See *An Introduction to Statistical Learning* by Gareth James, Daniela Witten,
    Trevor Hastie, and Robert Tibshirani (Springer, 2013) for sections on the bootstrap
    and, in particular, bagging.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参见《统计学习导论》（Springer，2013）由加雷斯·詹姆斯、丹妮拉·威特、特雷弗·哈斯蒂和罗伯特·蒂布沙尼编写，关于Bootstrap和尤其是装袋的章节。
- en: Confidence Intervals
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 置信区间
- en: Frequency tables, histograms, boxplots, and standard errors are all ways to
    understand the potential error in a sample estimate. Confidence intervals are
    another.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 频率表、直方图、箱线图和标准误差都是了解样本估计误差潜在误差的方式。置信区间是另一种方式。
- en: There is a natural human aversion to uncertainty; people (especially experts)
    say “I don’t know” far too rarely. Analysts and managers, while acknowledging
    uncertainty, nonetheless place undue faith in an estimate when it is presented
    as a single number (a *point estimate*). Presenting an estimate not as a single
    number but as a range is one way to counteract this tendency. Confidence intervals
    do this in a manner grounded in statistical sampling principles.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 人类天生对不确定性有抵触情绪；人们（尤其是专家）很少说“我不知道”。分析师和经理在承认不确定性的同时，当将估计呈现为单一数字（*点估计*）时，仍然过度信任估计。将估计呈现为一个范围而不是单一数字是抵消这种倾向的一种方式。置信区间以一种根植于统计抽样原理的方式来做到这一点。
- en: 'Confidence intervals always come with a coverage level, expressed as a (high)
    percentage, say 90% or 95%. One way to think of a 90% confidence interval is as
    follows: it is the interval that encloses the central 90% of the bootstrap sampling
    distribution of a sample statistic (see [“The Bootstrap”](#bootstrap)). More generally,
    an *x*% confidence interval around a sample estimate should, on average, contain
    similar sample estimates *x*% of the time (when a similar sampling procedure is
    followed).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 置信区间始终带有一个覆盖水平，以百分比（高）表示，例如90%或95%。将90%置信区间视为以下方式之一：它是包围样本统计的自助抽样分布的中心90%的区间（参见[“Bootstrap”](#bootstrap)）。更一般地，样本估计周围的*x*%置信区间应该在平均情况下，包含相似的样本估计*x*%的时间（当遵循类似的抽样过程时）。
- en: 'Given a sample of size *n*, and a sample statistic of interest, the algorithm
    for a bootstrap confidence interval is as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 给定大小为*n*的样本和感兴趣的样本统计量，Bootstrap置信区间的算法如下：
- en: Draw a random sample of size *n* with replacement from the data (a resample).
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据中有放回地抽取大小为*n*的随机样本（重新抽样）。
- en: Record the statistic of interest for the resample.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记录所重新抽样的兴趣统计量。
- en: Repeat steps 1–2 many (*R*) times.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤1至2多（*R*）次。
- en: For an *x*% confidence interval, trim [(100-*x*) / 2]% of the *R* resample results
    from either end of the distribution.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于*x*%置信区间，从分布的两端修剪[(100-*x*) / 2]%的*R*重新抽样结果。
- en: The trim points are the endpoints of an *x*% bootstrap confidence interval.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修剪点是*x*%自助法置信区间的端点。
- en: '[Figure 2-9](#bootstrap-ci) shows a 90% confidence interval for the mean annual
    income of loan applicants, based on a sample of 20 for which the mean was $62,231.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-9](#bootstrap-ci)显示了一个90%置信区间，用于贷款申请人的年收入均值，基于一个样本，样本容量为20，均值为$62,231。'
- en: '![images/bootstrap-CI.png](Images/psd2_0209.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![images/bootstrap-CI.png](Images/psd2_0209.png)'
- en: Figure 2-9\. Bootstrap confidence interval for the annual income of loan applicants,
    based on a sample of 20
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-9\. 基于20个样本的贷款申请人年收入的Bootstrap置信区间
- en: The bootstrap is a general tool that can be used to generate confidence intervals
    for most statistics, or model parameters. Statistical textbooks and software,
    with roots in over a half century of computerless statistical analysis, will also
    reference confidence intervals generated by formulas, especially the t-distribution
    (see [“Student’s t-Distribution”](#t-distribution)).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Bootstrap是一个通用工具，可用于生成大多数统计数据或模型参数的置信区间。根据半个世纪以上的无计算机统计分析的历史，统计教材和软件还将引用由公式生成的置信区间，特别是t分布（参见[“学生t分布”](#t-distribution)）。
- en: Note
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Of course, what we are really interested in when we have a sample result is,
    “What is the probability that the true value lies within a certain interval?”
    This is not really the question that a confidence interval answers, but it ends
    up being how most people interpret the answer.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，当我们有样本结果时，我们真正感兴趣的是，“真实值位于某个区间的概率是多少？”这实际上并不是置信区间回答的问题，但却是大多数人解释答案的方式。
- en: The probability question associated with a confidence interval starts out with
    the phrase “Given a sampling procedure and a population, what is the probability
    that…” To go in the opposite direction, “Given a sample result, what is the probability
    that (something is true about the population)?” involves more complex calculations
    and deeper imponderables.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 与置信区间相关的概率问题始于短语“给定抽样程序和人口，什么是……的概率？”要反过来，“给定样本结果，什么是（人群的真实情况）的概率？”涉及到更复杂的计算和更深层次的难题。
- en: 'The percentage associated with the confidence interval is termed the *level
    of confidence*. The higher the level of confidence, the wider the interval. Also,
    the smaller the sample, the wider the interval (i.e., the greater the uncertainty).
    Both make sense: the more confident you want to be, and the less data you have,
    the wider you must make the confidence interval to be sufficiently assured of
    capturing the true value.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 与置信区间相关联的百分比被称为*置信水平*。置信水平越高，区间越宽。此外，样本越小，区间越宽（即不确定性越大）。这两者都是有道理的：你希望越有信心，而且数据越少，你必须使置信区间足够宽以确保捕捉真实值。
- en: Note
  id: totrans-147
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For a data scientist, a confidence interval is a tool that can be used to get
    an idea of how variable a sample result might be. Data scientists would use this
    information not to publish a scholarly paper or submit a result to a regulatory
    agency (as a researcher might) but most likely to communicate the potential error
    in an estimate, and perhaps to learn whether a larger sample is needed.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据科学家而言，置信区间是一个工具，用于了解样本结果可能的变异程度。数据科学家会利用这些信息，不是为了发表学术论文或向监管机构提交结果（像研究员可能会做的那样），而更有可能是为了传达估计误差的潜在风险，并且也许了解是否需要更大的样本。
- en: Further Reading
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For a bootstrap approach to confidence intervals, see *Introductory Statistics
    and Analytics: A Resampling Perspective* by Peter Bruce (Wiley, 2014) or *Statistics:
    Unlocking the Power of Data*, 2nd ed., by Robin Lock and four other Lock family
    members (Wiley, 2016).'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '有关置信区间的自举方法，请参见*Introductory Statistics and Analytics: A Resampling Perspective*（Peter
    Bruce著，Wiley，2014）或*Statistics: Unlocking the Power of Data*，第2版，由Robin Lock及其四位家庭成员（Wiley，2016）撰写。'
- en: 'Engineers, who have a need to understand the precision of their measurements,
    use confidence intervals perhaps more than most disciplines, and *Modern Engineering
    Statistics* by Thomas Ryan (Wiley, 2007) discusses confidence intervals. It also
    reviews a tool that is just as useful and gets less attention: *prediction intervals*
    (intervals around a single value, as opposed to a mean or other summary statistic).'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工程师需要了解其测量精度的需求，或许比大多数学科更多地使用置信区间，*Modern Engineering Statistics*（Thomas Ryan著，Wiley，2007）讨论了置信区间。它还审视了一种同样有用但受到较少关注的工具：*预测区间*（围绕单个值的区间，与平均值或其他摘要统计不同）。
- en: Normal Distribution
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正态分布
- en: The bell-shaped normal distribution is iconic in traditional statistics.^([1](ch02.xhtml#idm46522862237288))
    The fact that distributions of sample statistics are often normally shaped has
    made it a powerful tool in the development of mathematical formulas that approximate
    those distributions.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 传统统计学中标志性的钟形正态分布。^([1](ch02.xhtml#idm46522862237288)) 样本统计量的分布通常呈正态分布的事实使其成为开发数学公式以近似这些分布的强大工具。
- en: In a normal distribution ([Figure 2-10](#normal-curve)), 68% of the data lies
    within one standard deviation of the mean, and 95% lies within two standard deviations.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在正态分布中（[图2-10](#normal-curve)），数据的68%位于平均值的一个标准偏差范围内，95%位于两个标准偏差范围内。
- en: Warning
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: 'It is a common misconception that the normal distribution is called that because
    most data follows a normal distribution—that is, it is the normal thing. Most
    of the variables used in a typical data science project—in fact, most raw data
    as a whole—are *not* normally distributed: see [“Long-Tailed Distributions”](#LongTailedData).
    The utility of the normal distribution derives from the fact that many statistics
    *are* normally distributed in their sampling distribution. Even so, assumptions
    of normality are generally a last resort, used when empirical probability distributions,
    or bootstrap distributions, are not available.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通常存在一个误解，即正态分布之所以叫正态分布，是因为大多数数据都遵循正态分布——即它是正常的。大多数在典型数据科学项目中使用的变量——事实上，大部分原始数据——*并不是*正态分布的：参见[“长尾分布”](#LongTailedData)。正态分布的实用性源于许多统计量在其抽样分布中*是*正态分布的。即便如此，正态性假设通常是最后的手段，当没有经验概率分布或自助抽样分布时才使用。
- en: '![Normal_dist.PNG](Images/psd2_0210.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![Normal_dist.PNG](Images/psd2_0210.png)'
- en: Figure 2-10\. Normal curve
  id: totrans-158
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-10\. 正态曲线
- en: Note
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The normal distribution is also referred to as a *Gaussian* distribution after
    Carl Friedrich Gauss, a prodigious German mathematician from the late 18th and
    early 19th centuries. Another name previously used for the normal distribution
    was the “error” distribution. Statistically speaking, an *error* is the difference
    between an actual value and a statistical estimate like the sample mean. For example,
    the standard deviation (see [“Estimates of Variability”](ch01.xhtml#Variability))
    is based on the errors from the mean of the data. Gauss’s development of the normal
    distribution came from his study of the errors of astronomical measurements that
    were found to be normally distributed.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 正态分布也称为*高斯*分布，以18世纪末至19世纪初的杰出德国数学家卡尔·弗里德里希·高斯（Carl Friedrich Gauss）的名字命名。正态分布以前的另一个名称是“误差”分布。从统计学角度看，*误差*是实际值与样本均值等统计估计值之间的差异。例如，标准差（参见[“变异性估计”](ch01.xhtml#Variability)）基于数据均值的误差。高斯对正态分布的研究源于他对天文测量误差的研究，这些误差被发现是正态分布的。
- en: Standard Normal and QQ-Plots
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标准正态分布和QQ图
- en: A *standard normal* distribution is one in which the units on the x-axis are
    expressed in terms of standard deviations away from the mean. To compare data
    to a standard normal distribution, you subtract the mean and then divide by the
    standard deviation; this is also called *normalization* or *standardization* (see
    [“Standardization (Normalization, z-Scores)”](ch06.xhtml#Standardization)). Note
    that “standardization” in this sense is unrelated to database record standardization
    (conversion to a common format). The transformed value is termed a *z-score*,
    and the normal distribution is sometimes called the *z-distribution*.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*标准正态*分布是指x轴上的单位以标准差表示离均值的距离。要将数据与标准正态分布进行比较，您需要减去均值，然后除以标准差；这也称为*归一化*或*标准化*（参见[“标准化（归一化，z分数）”](ch06.xhtml#Standardization)）。请注意，这里的“标准化”与数据库记录标准化（转换为通用格式）无关。变换后的值称为*z分数*，正态分布有时也称为*z分布*。
- en: 'A *QQ-Plot* is used to visually determine how close a sample is to a specified
    distribution—in this case, the normal distribution. The QQ-Plot orders the *z*-scores
    from low to high and plots each value’s *z*-score on the y-axis; the x-axis is
    the corresponding quantile of a normal distribution for that value’s rank. Since
    the data is normalized, the units correspond to the number of standard deviations
    away from the mean. If the points roughly fall on the diagonal line, then the
    sample distribution can be considered close to normal. [Figure 2-11](#qqnorm)
    shows a QQ-Plot for a sample of 100 values randomly generated from a normal distribution;
    as expected, the points closely follow the line. This figure can be produced in
    *R* with the `qqnorm` function:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '*QQ图*用于直观地确定样本与指定分布（在本例中是正态分布）有多接近。QQ图将*z*分数按从低到高的顺序排列，并在y轴上绘制每个值的*z*分数；x轴是该值排名对应的正态分布的分位数。由于数据已经标准化，单位对应于离均值的标准差数目。如果点大致落在对角线上，那么样本分布可以视为接近正态分布。[图2-11](#qqnorm)显示了从正态分布中随机生成的100个值的QQ图；如预期的，点紧密跟随直线。可以使用*R*中的`qqnorm`函数生成此图：'
- en: '[PRE5]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In *Python*, use the method `scipy.stats.probplot` to create the QQ-Plot:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Python*中，使用方法`scipy.stats.probplot`来创建QQ图：
- en: '[PRE6]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![qqnorm.png](Images/psd2_0211.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![qqnorm.png](Images/psd2_0211.png)'
- en: Figure 2-11\. QQ-Plot of a sample of 100 values drawn from a standard normal
    distribution
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-11\. QQ图，显示从标准正态分布中抽取的100个样本的样本
- en: Warning
  id: totrans-169
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Converting data to *z*-scores (i.e., standardizing or normalizing the data)
    does *not* make the data normally distributed. It just puts the data on the same
    scale as the standard normal distribution, often for comparison purposes.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据转换为*z*-分数（即标准化或归一化数据）并不会使数据呈正态分布。它只是将数据放置在与标准正态分布相同的比例上，通常用于比较目的。
- en: Long-Tailed Distributions
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 长尾分布
- en: Despite the importance of the normal distribution historically in statistics,
    and in contrast to what the name would suggest, data is generally not normally
    distributed.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管正态分布在统计学上具有重要历史意义，并与名称所暗示的相反，数据通常不服从正态分布。
- en: While the normal distribution is often appropriate and useful with respect to
    the distribution of errors and sample statistics, it typically does not characterize
    the distribution of raw data. Sometimes, the distribution is highly *skewed* (asymmetric),
    such as with income data; or the distribution can be discrete, as with binomial
    data. Both symmetric and asymmetric distributions may have *long tails*. The tails
    of a distribution correspond to the extreme values (small and large). Long tails,
    and guarding against them, are widely recognized in practical work. Nassim Taleb
    has proposed the *black swan* theory, which predicts that anomalous events, such
    as a stock market crash, are much more likely to occur than would be predicted
    by the normal distribution.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管正态分布通常适用且有用于误差分布和样本统计数据的分布，但它通常不描述原始数据的分布。有时，分布是高度*偏斜*的（不对称的），例如收入数据；或者分布可以是离散的，例如二项数据。对称和非对称的分布可能都有*长尾*。分布的尾部对应于极端值（小和大）。长尾及其防范在实际工作中广为认可。纳西姆·塔勒布提出了*黑天鹅*理论，预测异常事件，如股市崩盘，比正态分布预测的更有可能发生。
- en: 'A good example to illustrate the long-tailed nature of data is stock returns.
    [Figure 2-12](#nflx_qnorm) shows the QQ-Plot for the daily stock returns for Netflix
    (NFLX). This is generated in *R* by:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 说明数据长尾特性的一个很好的例子是股票收益。[图 2-12](#nflx_qnorm) 显示了Netflix（NFLX）每日股票收益的QQ图。这是通过
    *R* 生成的：
- en: '[PRE7]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The corresponding *Python* code is:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的 *Python* 代码是：
- en: '[PRE8]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![nflx_qnorm.png](Images/psd2_0212.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![nflx_qnorm.png](Images/psd2_0212.png)'
- en: Figure 2-12\. QQ-Plot of the returns for Netflix (NFLX)
  id: totrans-179
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-12\. Netflix（NFLX）的收益的QQ图
- en: 'In contrast to [Figure 2-11](#qqnorm), the points are far below the line for
    low values and far above the line for high values, indicating the data are not
    normally distributed. This means that we are much more likely to observe extreme
    values than would be expected if the data had a normal distribution. [Figure 2-12](#nflx_qnorm)
    shows another common phenomenon: the points are close to the line for the data
    within one standard deviation of the mean. Tukey refers to this phenomenon as
    data being “normal in the middle” but having much longer tails (see [[Tukey-1987]](bibliography01.xhtml#Tukey-1987)).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 与[图 2-11](#qqnorm) 相比，低值的点远低于线，高值的点远高于线，表明数据不服从正态分布。这意味着我们更有可能观察到极端值，而不是数据具有正态分布时所预期的。[图 2-12](#nflx_qnorm)
    显示了另一个常见现象：在距离均值一个标准差内的数据点接近线。Tukey 将此现象称为数据在中间部分“正常”，但尾部较长（见[[Tukey-1987]](bibliography01.xhtml#Tukey-1987)）。
- en: Note
  id: totrans-181
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There is much statistical literature about the task of fitting statistical distributions
    to observed data. Beware an excessively data-centric approach to this job, which
    is as much art as science. Data is variable, and often consistent, on its face,
    with more than one shape and type of distribution. It is typically the case that
    domain and statistical knowledge must be brought to bear to determine what type
    of distribution is appropriate to model a given situation. For example, we might
    have data on the level of internet traffic on a server over many consecutive five-second
    periods. It is useful to know that the best distribution to model “events per
    time period” is the Poisson (see [“Poisson Distributions”](#Poisson)).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 关于将统计分布拟合到观察数据的任务，有大量的统计文献。要警惕对这项工作过于依赖数据的方法，这既是艺术也是科学。数据是变量，通常表面上看，可以符合多种形状和类型的分布。通常情况下，必须运用领域和统计知识来确定适合模拟给定情况的分布类型。例如，我们可能有关于服务器在许多连续五秒时间段内的互联网流量水平的数据。了解到“每个时间段事件”的最佳分布是泊松分布（见[“泊松分布”](#Poisson)）是有用的。
- en: Further Reading
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*The Black Swan*, 2nd ed., by Nassim Nicholas Taleb (Random House, 2010)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*黑天鹅*，纳西姆·尼古拉斯·塔勒布著（Random House，2010年）'
- en: '*Handbook of Statistical Distributions with Applications*, 2nd ed., by K. Krishnamoorthy
    (Chapman & Hall/CRC Press, 2016)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*统计分布及其应用手册*，K. Krishnamoorthy著（Chapman & Hall/CRC Press，2016年）'
- en: Student’s t-Distribution
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学生t-分布
- en: The *t-distribution* is a normally shaped distribution, except that it is a
    bit thicker and longer on the tails. It is used extensively in depicting distributions
    of sample statistics. Distributions of sample means are typically shaped like
    a t-distribution, and there is a family of t-distributions that differ depending
    on how large the sample is. The larger the sample, the more normally shaped the
    t-distribution becomes.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*t-分布*是一个形状类似正态分布的分布，不过在尾部略微厚一些且更长。它被广泛用于描述样本统计量的分布。样本均值的分布通常呈现出t-分布的形状，并且根据样本大小的不同有一系列不同的t-分布。样本越大，t-分布就越接近正态分布。'
- en: The t-distribution is often called *Student’s t* because it was published in
    1908 in *Biometrika* by W. S. Gosset under the name “Student.” Gosset’s employer,
    the Guinness brewery, did not want competitors to know that it was using statistical
    methods, so it insisted that Gosset not use his name on the article.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: t-分布通常被称为*学生t*，因为它是由W. S. 戈塞特于1908年在《生物统计学》上以“学生”名义发表的。戈塞特的雇主，吉尼斯啤酒厂，不希望竞争对手知道它正在使用统计方法，因此坚持要求戈塞特不在文章上使用自己的名字。
- en: Gosset wanted to answer the question “What is the sampling distribution of the
    mean of a sample, drawn from a larger population?” He started out with a resampling
    experiment—drawing random samples of 4 from a data set of 3,000 measurements of
    criminals’ height and left-middle-finger length. (This being the era of eugenics,
    there was much interest in data on criminals, and in discovering correlations
    between criminal tendencies and physical or psychological attributes.) Gosset
    plotted the standardized results (the *z*-scores) on the x-axis and the frequency
    on the y-axis. Separately, he had derived a function, now known as *Student’s
    t*, and he fit this function over the sample results, plotting the comparison
    (see [Figure 2-13](#Gosset-curve)).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 戈塞特想要回答的问题是“从一个更大的人口中抽取样本的均值的抽样分布是什么？”他首先进行了一项重采样实验——从一个包含3000个罪犯身高和左中指长度测量值的数据集中随机抽取了4个样本。（在这个时代，有很多关于罪犯数据的兴趣，以及发现犯罪倾向与生理或心理属性之间的相关性。）戈塞特将标准化的结果（*z*-分数）绘制在x轴上，频率绘制在y轴上。此外，他还推导出一个函数，现在被称为*学生t*，并将这个函数拟合到样本结果上，绘制出比较（见[图2-13](#Gosset-curve)）。
- en: '![Gosset-curve](Images/psd2_0213.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![Gosset-curve](Images/psd2_0213.png)'
- en: Figure 2-13\. Gosset’s resampling experiment results and fitted t-curve (from
    his 1908 *Biometrika* paper)
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-13。戈塞特的重采样实验结果和拟合的t-曲线（来自他1908年的《生物统计学》论文）
- en: 'A number of different statistics can be compared, after standardization, to
    the t-distribution, to estimate confidence intervals in light of sampling variation.
    Consider a sample of size *n* for which the sample mean <math alttext="x overbar"><mover
    accent="true"><mi>x</mi> <mo>¯</mo></mover></math> has been calculated. If *s*
    is the sample standard deviation, a 90% confidence interval around the sample
    mean is given by:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑到抽样变异性后，可以将多种不同的统计量标准化到t-分布上，以估计置信区间。考虑一个样本大小为*n*的样本，已计算出样本均值<math alttext="x
    overbar"><mover accent="true"><mi>x</mi> <mo>¯</mo></mover></math>。如果*s*是样本标准偏差，那么样本均值周围的90%置信区间为：
- en: <math alttext="x overbar plus-or-minus t Subscript n minus 1 Baseline left-parenthesis
    0.05 right-parenthesis dot StartFraction s Over StartRoot n EndRoot EndFraction"
    display="block"><mrow><mover accent="true"><mi>x</mi> <mo>¯</mo></mover> <mo>±</mo>
    <msub><mi>t</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <mrow><mo>(</mo>
    <mn>0</mn> <mo>.</mo> <mn>05</mn> <mo>)</mo></mrow> <mo>·</mo> <mfrac><mi>s</mi>
    <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="x overbar plus-or-minus t Subscript n minus 1 Baseline left-parenthesis
    0.05 right-parenthesis dot StartFraction s Over StartRoot n EndRoot EndFraction"
    display="block"><mrow><mover accent="true"><mi>x</mi> <mo>¯</mo></mover> <mo>±</mo>
    <msub><mi>t</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <mrow><mo>(</mo>
    <mn>0</mn> <mo>.</mo> <mn>05</mn> <mo>)</mo></mrow> <mo>·</mo> <mfrac><mi>s</mi>
    <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
- en: where <math alttext="t Subscript n minus 1 Baseline left-parenthesis .05 right-parenthesis"><mrow><msub><mi>t</mi>
    <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <mrow><mo>(</mo> <mo>.</mo>
    <mn>05</mn> <mo>)</mo></mrow></mrow></math> is the value of the t-statistic, with
    (*n* – 1) degrees of freedom (see [“Degrees of Freedom”](ch03.xhtml#DOF)), that
    “chops off” 5% of the t-distribution at either end. The t-distribution has been
    used as a reference for the distribution of a sample mean, the difference between
    two sample means, regression parameters, and other statistics.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 其中<math alttext="t Subscript n minus 1 Baseline left-parenthesis .05 right-parenthesis"><mrow><msub><mi>t</mi>
    <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <mrow><mo>(</mo> <mo>.</mo>
    <mn>05</mn> <mo>)</mo></mrow></mrow></math>是t-统计量的值，具有(*n* – 1)个自由度（见[“自由度”](ch03.xhtml#DOF)），在t-分布的两端“截取”了5%。t-分布已被用作样本均值、两个样本均值之间的差异、回归参数和其他统计量的分布的参考。
- en: Had computing power been widely available in 1908, statistics would no doubt
    have relied much more heavily on computationally intensive resampling methods
    from the start. Lacking computers, statisticians turned to mathematics and functions
    such as the t-distribution to approximate sampling distributions. Computer power
    enabled practical resampling experiments in the 1980s, but by then, use of the
    t-distribution and similar distributions had become deeply embedded in textbooks
    and software.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 1908 年计算能力普遍存在，统计学无疑会更多地依赖计算密集型的重新采样方法。由于缺乏计算机，统计学家转向数学和函数，如 t-分布，来近似抽样分布。计算机能力使得在
    1980 年代实现了实际的重新采样实验，但到那时，t-分布和类似分布的使用已经深入嵌入教科书和软件中。
- en: The t-distribution’s accuracy in depicting the behavior of a sample statistic
    requires that the distribution of that statistic for that sample be shaped like
    a normal distribution. It turns out that sample statistics *are* often normally
    distributed, even when the underlying population data is not (a fact which led
    to widespread application of the t-distribution). This brings us back to the phenomenon
    known as the *central limit theorem* (see [“Central Limit Theorem”](#central-limit-theorem)).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: t-分布准确地描述样本统计量的行为需要该样本统计量的分布形状类似于正态分布。事实证明，样本统计量通常是正态分布的，即使底层总体数据不是（这一事实导致广泛应用
    t-分布）。这使我们回到了众所周知的*中心极限定理*现象（参见 [“中心极限定理”](#central-limit-theorem)）。
- en: Note
  id: totrans-197
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: What do data scientists need to know about the t-distribution and the central
    limit theorem? Not a whole lot. The t-distribution is used in classical statistical
    inference but is not as central to the purposes of data science. Understanding
    and quantifying uncertainty and variation are important to data scientists, but
    empirical bootstrap sampling can answer most questions about sampling error. However,
    data scientists will routinely encounter t-statistics in output from statistical
    software and statistical procedures in *R*—for example, in A/B tests and regressions—so
    familiarity with its purpose is helpful.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家需要了解 t-分布和中心极限定理吗？其实并不需要太多。t-分布用于经典统计推断，但并不是数据科学目的的核心。理解和量化不确定性和变化对数据科学家非常重要，但经验性的自助法抽样可以回答大多数有关抽样误差的问题。然而，数据科学家经常会在统计软件和*R*中的输出中遇到
    t-统计量—例如，在A/B测试和回归中—因此熟悉其用途是有帮助的。
- en: Further Reading
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: The original W.S. Gosset paper as published in *Biometrika* in 1908 is available
    [as a PDF](https://oreil.ly/J6gDg).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始的 W.S. Gosset 论文于 1908 年发表在 *Biometrika* 上，可作为[PDF](https://oreil.ly/J6gDg)获得。
- en: A standard treatment of the t-distribution can be found in David Lane’s [online
    resource](https://oreil.ly/QxUkA).
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于 t-分布的标准处理可以在 David Lane 的[在线资源](https://oreil.ly/QxUkA)中找到。
- en: Binomial Distribution
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二项分布
- en: Yes/no (binomial) outcomes lie at the heart of analytics since they are often
    the culmination of a decision or other process; buy/don’t buy, click/don’t click,
    survive/die, and so on. Central to understanding the binomial distribution is
    the idea of a set of *trials*, each trial having two possible outcomes with definite
    probabilities.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 是/否（二项）结果是分析的核心，因为它们常常是决策或其他过程的最终结果；买/不买，点击/不点击，存活/死亡等。理解二项分布的核心是一组*试验*的概念，每个试验都有两种可能的结果和明确的概率。
- en: For example, flipping a coin 10 times is a binomial experiment with 10 trials,
    each trial having two possible outcomes (heads or tails); see [Figure 2-14](#nickel).
    Such yes/no or 0/1 outcomes are termed *binary* outcomes, and they need not have
    50/50 probabilities. Any probabilities that sum to 1.0 are possible. It is conventional
    in statistics to term the “1” outcome the *success* outcome; it is also common
    practice to assign “1” to the more rare outcome. Use of the term *success* does
    not imply that the outcome is desirable or beneficial, but it does tend to indicate
    the outcome of interest. For example, loan defaults or fraudulent transactions
    are relatively uncommon events that we may be interested in predicting, so they
    are termed “1s” or “successes.”
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，抛硬币 10 次是一个二项实验，共有 10 次试验，每次试验有两种可能的结果（正面或反面）；见 [图 2-14](#nickel)。此类是*二元*结果，无需具有
    50/50 的概率。任何总和为 1.0 的概率都是可能的。在统计学中，将“1”结果称为*成功*结果是传统做法；同时，也普遍将“1”分配给更为罕见的结果。使用术语*成功*并不意味着结果是理想的或有益的，但确实表明了感兴趣的结果。例如，贷款违约或欺诈交易是相对不常见的事件，我们可能对其进行预测，因此它们被称为“1s”或“成功”。
- en: '![images/Indian_Head_Buffalo_Nickel.png](Images/psd2_0214.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![images/Indian_Head_Buffalo_Nickel.png](Images/psd2_0214.png)'
- en: Figure 2-14\. The tails side of a buffalo nickel
  id: totrans-206
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-14。美国五分镍的反面
- en: 'The binomial distribution is the frequency distribution of the number of successes
    (*x*) in a given number of trials (*n*) with specified probability (*p*) of success
    in each trial. There is a family of binomial distributions, depending on the values
    of *n* and *p*. The binomial distribution would answer a question like:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 二项分布是在给定试验次数(*n*)中的成功次数(*x*)的频率分布，每次试验中成功的指定概率(*p*)。有一系列的二项分布，取决于*n*和*p*的值。二项分布可以回答如下问题：
- en: If the probability of a click converting to a sale is 0.02, what is the probability
    of observing 0 sales in 200 clicks?
  id: totrans-208
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果点击转化为销售的概率为0.02，观察到200次点击中没有销售的概率是多少？
- en: 'The *R* function `dbinom` calculates binomial probabilities. For example:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 函数*R* `dbinom` 计算二项概率。例如：
- en: '[PRE9]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: would return 0.0729, the probability of observing exactly *x* = 2 successes
    in *size* = 5 trials, where the probability of success for each trial is *p* =
    0.1\. For our example above, we use *x* = 0, *size* = 200, and *p* = 0.02\. With
    these arguments, `dbinom` returns a probability of 0.0176.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 将返回0.0729，即在*size*=5次试验中观察到*x*=2次成功的概率，每次试验成功的概率为*p*=0.1。对于上述示例，我们使用*x*=0，*size*=200，*p*=0.02。使用这些参数，`dbinom`返回概率为0.0176。
- en: 'Often we are interested in determining the probability of *x* or fewer successes
    in *n* trials. In this case, we use the function `pbinom`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常有兴趣确定在*n*次试验中观察到*x*或更少成功的概率。在这种情况下，我们使用函数`pbinom`：
- en: '[PRE10]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This would return 0.9914, the probability of observing two or fewer successes
    in five trials, where the probability of success for each trial is 0.1.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回0.9914，即在五次试验中观察到两次或更少成功的概率，每次试验成功的概率为0.1。
- en: 'The `scipy.stats` module implements a large variety of statistical distributions.
    For the binomial distribution, use the functions `stats.binom.pmf` and `stats.binom.cdf`:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`scipy.stats`模块实现了大量的统计分布。对于二项分布，可以使用函数`stats.binom.pmf`和`stats.binom.cdf`：'
- en: '[PRE11]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The mean of a binomial distribution is <math alttext="n times p"><mrow><mi>n</mi>
    <mo>×</mo> <mi>p</mi></mrow></math> ; you can also think of this as the expected
    number of successes in *n* trials, for success probability = *p*.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 二项分布的均值为<math alttext="n times p"><mrow><mi>n</mi> <mo>×</mo> <mi>p</mi></mrow></math>；你也可以把这看作是*n*次试验中成功的预期数量，成功概率=*p*。
- en: The variance is <math alttext="n times p left-parenthesis 1 minus p right-parenthesis"><mrow><mi>n</mi>
    <mo>×</mo> <mi>p</mi> <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>p</mi> <mo>)</mo></mrow></math>
    . With a large enough number of trials (particularly when *p* is close to 0.50),
    the binomial distribution is virtually indistinguishable from the normal distribution.
    In fact, calculating binomial probabilities with large sample sizes is computationally
    demanding, and most statistical procedures use the normal distribution, with mean
    and variance, as an approximation.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 方差为<math alttext="n times p left-parenthesis 1 minus p right-parenthesis"><mrow><mi>n</mi>
    <mo>×</mo> <mi>p</mi> <mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>p</mi> <mo>)</mo></mrow></math>。当试验次数足够多时（特别是当*p*接近0.50时），二项分布几乎与正态分布无法区分。事实上，使用大样本量计算二项概率是计算密集型的，大多数统计过程使用正态分布进行近似，具有均值和方差。
- en: Further Reading
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Read about [the “quincunx”](https://oreil.ly/nmkcs), a pinball-like simulation
    device for illustrating the binomial distribution.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读有关[“四叶玫瑰”](https://oreil.ly/nmkcs)的介绍，这是一种类似弹球的模拟设备，用于说明二项分布。
- en: The binomial distribution is a staple of introductory statistics, and all introductory
    statistics texts will have a chapter or two on it.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二项分布是统计学入门的重要内容，所有统计学入门教材都会有一两章讲解它。
- en: Chi-Square Distribution
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卡方分布
- en: An important idea in statistics is *departure from expectation*, especially
    with respect to category counts. Expectation is defined loosely as “nothing unusual
    or of note in the data” (e.g., no correlation between variables or predictable
    patterns). This is also termed the “null hypothesis” or “null model” (see [“The
    Null Hypothesis”](ch03.xhtml#Null_hypothesis)). For example, you might want to
    test whether one variable (say, a row variable representing gender) is independent
    of another (say, a column variable representing “was promoted in job”), and you
    have counts of the number in each of the cells of the data table. The statistic
    that measures the extent to which results depart from the null expectation of
    independence is the chi-square statistic. It is the difference between the observed
    and expected values, divided by the square root of the expected value, squared,
    then summed across all categories. This process standardizes the statistic so
    it can be compared to a reference distribution. A more general way of putting
    this is to note that the chi-square statistic is a measure of the extent to which
    a set of observed values “fits” a specified distribution (a “goodness-of-fit”
    test). It is useful for determining whether multiple treatments (an “A/B/C… test”)
    differ from one another in their effects.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学中的一个重要概念是*偏离期望*，特别是关于类别计数。期望松散地定义为“数据中没有异常或值得注意的事物”（例如，变量之间没有相关性或可预测的模式）。这也称为“零假设”或“零模型”（参见[“零假设”](ch03.xhtml#Null_hypothesis)）。例如，您可能希望测试一个变量（例如，表示性别的行变量）是否独立于另一个变量（例如，表示“在工作中被提升”的列变量），并且您有数据表单元格中每个计数的计数。衡量结果偏离独立性零期望程度的统计量是卡方统计量。它是观察到的值与预期值之间的差异，除以预期值的平方根，再平方，然后在所有类别上求和。这个过程标准化了统计量，使其可以与参考分布进行比较。更一般地说，卡方统计量是衡量一组观察值“适合”指定分布的程度的指标（“拟合优度检验”）。它对于确定多个处理（“A/B/C...测试”）在其效果上是否不同非常有用。
- en: The chi-square distribution is the distribution of this statistic under repeated
    resampled draws from the null model—see [“Chi-Square Test”](ch03.xhtml#chi-square)
    for a detailed algorithm, and the chi-square formula for a data table. A low chi-square
    value for a set of counts indicates that they closely follow the expected distribution.
    A high chi-square indicates that they differ markedly from what is expected. There
    are a variety of chi-square distributions associated with different degrees of
    freedom (e.g., number of observations—see [“Degrees of Freedom”](ch03.xhtml#DOF)).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 卡方分布是从零模型中重复重新抽取的数据的统计分布——详见[“卡方检验”](ch03.xhtml#chi-square)以获取详细算法，以及数据表的卡方公式。一组计数的低卡方值表明它们与预期分布非常接近。高卡方值表明它们与预期值有显著差异。与不同自由度相关的各种卡方分布存在（例如，观测数——参见[“自由度”](ch03.xhtml#DOF)）。
- en: Further Reading
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The chi-square distribution owes its place in modern statistics to the great
    statistician Karl Pearson and the birth of hypothesis testing—read about this
    and more in David Salsburg’s *The Lady Tasting Tea: How Statistics Revolutionized
    Science in the Twentieth Century* (W. H. Freeman, 2001).'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卡尔·皮尔逊和假设检验的诞生让卡方分布在现代统计学中占有重要位置——详细内容请参阅大卫·萨尔斯伯格的《*品茶的女士：统计学如何在二十世纪改变科学*》（W.
    H. Freeman，2001年）。
- en: For a more detailed exposition, see the section in this book on the chi-square
    test ([“Chi-Square Test”](ch03.xhtml#chi-square)).
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欲了解更详细内容，请参阅本书中关于卡方检验的章节（[“卡方检验”](ch03.xhtml#chi-square)）。
- en: F-Distribution
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: F-分布
- en: A common procedure in scientific experimentation is to test multiple treatments
    across groups—say, different fertilizers on different blocks of a field. This
    is similar to the A/B/C test referred to in the chi-square distribution (see [“Chi-Square
    Distribution”](#chi-square-dist)), except we are dealing with measured continuous
    values rather than counts. In this case we are interested in the extent to which
    differences among group means are greater than we might expect under normal random
    variation. The F-statistic measures this and is the ratio of the variability among
    the group means to the variability within each group (also called residual variability).
    This comparison is termed an *analysis of variance* (see [“ANOVA”](ch03.xhtml#ANOVA)).
    The distribution of the F-statistic is the frequency distribution of all the values
    that would be produced by randomly permuting data in which all the group means
    are equal (i.e., a null model). There are a variety of F-distributions associated
    with different degrees of freedom (e.g., numbers of groups—see [“Degrees of Freedom”](ch03.xhtml#DOF)).
    The calculation of F is illustrated in the section on ANOVA. The F-statistic is
    also used in linear regression to compare the variation accounted for by the regression
    model to the overall variation in the data. F-statistics are produced automatically
    by *R* and *Python* as part of regression and ANOVA routines.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学实验中的常见程序是在多个组中测试多种处理方法——比如在田地的不同区块上使用不同的肥料。这类似于卡方分布中提到的A/B/C测试（参见[“卡方分布”](#chi-square-dist)），但我们处理的是连续测量值而不是计数。在这种情况下，我们关心的是组间均值差异是否超出了正常随机变异的预期。F统计量衡量了这一点，是组间均值变异性与每个组内变异性（也称为残差变异性）之比。这种比较称为*方差分析*（见[“ANOVA”](ch03.xhtml#ANOVA)）。F统计量的分布是所有在空模型中通过随机排列数据时产生的值的频率分布，其中所有组均值相等。与不同自由度相关的多种F分布（例如，组数——见[“自由度”](ch03.xhtml#DOF)）存在。F的计算在ANOVA部分有详细说明。F统计量还用于线性回归中，用于比较回归模型解释的变异与数据整体变异的比例。在回归和ANOVA例程中，*R*和*Python*会自动产生F统计量。
- en: Further Reading
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: George Cobb’s *Introduction to Design and Analysis of Experiments* (Wiley, 2008)
    contains an excellent exposition of the decomposition of variance components,
    which helps in understanding ANOVA and the F-statistic.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 乔治·科布的《*实验设计与分析导论*》（Wiley，2008）详细阐述了方差分解，有助于理解方差分析（ANOVA）和F统计量。
- en: Poisson and Related Distributions
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 泊松及相关分布
- en: Many processes produce events randomly at a given overall rate—visitors arriving
    at a website, or cars arriving at a toll plaza (events spread over time); imperfections
    in a square meter of fabric, or typos per 100 lines of code (events spread over
    space).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 许多过程以给定的总体速率随机产生事件——例如访问者访问网站或汽车通过收费站（时间分布的事件）；或者在一平方米布料中的瑕疵或每100行代码中的错别字（空间分布的事件）。
- en: Poisson Distributions
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 泊松分布
- en: From prior aggregate data (for example, number of flu infections per year),
    we can estimate the average number of events per unit of time or space (e.g.,
    infections per day, or per census unit). We might also want to know how different
    this might be from one unit of time/space to another. The Poisson distribution
    tells us the distribution of events per unit of time or space when we sample many
    such units. It is useful when addressing queuing questions such as “How much capacity
    do we need to be 95% sure of fully processing the internet traffic that arrives
    on a server in any five-second period?”
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 通过先前的聚合数据（例如，每年的流感感染数），我们可以估计单位时间或空间内事件的平均数（例如每天的感染数或每个人口普查单位的感染数）。我们可能还想知道一个单位的时间/空间与另一个单位相比有多大的不同。泊松分布告诉我们，当我们抽样许多这样的单位时，单位时间或空间内的事件分布。在处理排队问题时很有用，例如“我们需要多少能力才能确保在任何五秒内完全处理到达服务器上的互联网流量的95%？”
- en: The key parameter in a Poisson distribution is <math alttext="lamda"><mi>λ</mi></math>
    , or lambda. This is the mean number of events that occurs in a specified interval
    of time or space. The variance for a Poisson distribution is also <math alttext="lamda"><mi>λ</mi></math>
    .
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 泊松分布中的关键参数是<math alttext="lambda"><mi>λ</mi></math>，即lambda。这是在指定的时间或空间间隔内发生的事件平均数。泊松分布的方差也是<math
    alttext="lambda"><mi>λ</mi></math>。
- en: 'A common technique is to generate random numbers from a Poisson distribution
    as part of a queuing simulation. The `rpois` function in *R* does this, taking
    only two arguments—the quantity of random numbers sought, and lambda:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 作为排队仿真的一部分，从泊松分布生成随机数是一种常见的技术。*R* 中的`rpois`函数完成这一任务，只需两个参数：所需的随机数数量和 lambda
    值：
- en: '[PRE12]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The corresponding `scipy` function is `stats.poisson.rvs`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的`scipy`函数是`stats.poisson.rvs`：
- en: '[PRE13]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This code will generate 100 random numbers from a Poisson distribution with
    <math alttext="lamda"><mi>λ</mi></math> = 2. For example, if incoming customer
    service calls average two per minute, this code will simulate 100 minutes, returning
    the number of calls in each of those 100 minutes.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下代码将从均值为 2 的泊松分布生成 100 个随机数。例如，如果客户服务电话平均每分钟两次，此代码将模拟 100 分钟，返回这 100 分钟内每分钟的呼叫次数。
- en: Exponential Distribution
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指数分布
- en: 'Using the same parameter <math alttext="lamda"><mi>λ</mi></math> that we used
    in the Poisson distribution, we can also model the distribution of the time between
    events: time between visits to a website or between cars arriving at a toll plaza.
    It is also used in engineering to model time to failure, and in process management
    to model, for example, the time required per service call. The *R* code to generate
    random numbers from an exponential distribution takes two arguments: `n` (the
    quantity of numbers to be generated) and `rate` (the number of events per time
    period). For example:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与泊松分布中相同的参数 lambda，我们还可以对事件之间的时间分布进行建模：例如网站访问之间的时间或汽车抵达收费站之间的时间。它也用于工程学中的故障时间建模以及过程管理中的模拟，例如每个服务呼叫所需的时间。从指数分布生成随机数的*R*代码需要两个参数：`n`（要生成的数的数量）和`rate`（每个时间段的事件数量）。例如：
- en: '[PRE14]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In the function `stats.expon.rvs`, the order of the arguments is reversed:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数`stats.expon.rvs`中，参数的顺序是颠倒的：
- en: '[PRE15]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This code would generate 100 random numbers from an exponential distribution
    where the mean number of events per time period is 0.2. So you could use it to
    simulate 100 intervals, in minutes, between service calls, where the average rate
    of incoming calls is 0.2 per minute.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码将从均值为 0.2 的指数分布生成 100 个随机数。因此，您可以用它来模拟 100 个时间间隔（以分钟为单位），表示服务电话之间的时间间隔，其中平均呼叫率为每分钟
    0.2 次。
- en: A key assumption in any simulation study for either the Poisson or exponential
    distribution is that the rate, <math alttext="lamda"><mi>λ</mi></math> , remains
    constant over the period being considered. This is rarely reasonable in a global
    sense; for example, traffic on roads or data networks varies by time of day and
    day of week. However, the time periods, or areas of space, can usually be divided
    into segments that are sufficiently homogeneous so that analysis or simulation
    within those periods is valid.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 任何模拟研究中的关键假设，无论是对泊松分布还是指数分布，都是速率 lambda 在考虑的时间段内保持恒定。从全局角度来看，这很少是合理的；例如，道路交通或数据网络的流量会随着一天中的时间和一周中的日期变化。然而，时间段或空间区域通常可以分成足够均匀的片段，以使得在这些时间段内的分析或模拟是有效的。
- en: Estimating the Failure Rate
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 估计故障率
- en: 'In many applications, the event rate, <math alttext="lamda"><mi>λ</mi></math>
    , is known or can be estimated from prior data. However, for rare events, this
    is not necessarily so. Aircraft engine failure, for example, is sufficiently rare
    (thankfully) that, for a given engine type, there may be little data on which
    to base an estimate of time between failures. With no data at all, there is little
    basis on which to estimate an event rate. However, you can make some guesses:
    if no events have been seen after 20 hours, you can be pretty sure that the rate
    is not 1 per hour. Via simulation, or direct calculation of probabilities, you
    can assess different hypothetical event rates and estimate threshold values below
    which the rate is very unlikely to fall. If there is some data but not enough
    to provide a precise, reliable estimate of the rate, a goodness-of-fit test (see
    [“Chi-Square Test”](ch03.xhtml#chi-square)) can be applied to various rates to
    determine how well they fit the observed data.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多应用中，事件率 <math alttext="lamda"><mi>λ</mi></math> 已知或可以从先前的数据中估算出来。然而，对于罕见的事件，情况可能并非如此。例如，飞机发动机故障是足够罕见的（幸好），对于特定类型的发动机，可能没有足够的数据用于基于故障间隔时间的估计。如果根本没有数据，那么几乎没有依据可以估计事件率。不过，你可以进行一些猜测：如果在20小时后没有发生任何事件，那么可以相当肯定速率不是每小时1次。通过模拟或直接计算概率，你可以评估不同假设的事件率，并估计在其下的速率很不可能达到的阈值。如果有一些数据但不足以提供精确可靠的速率估计，可以应用拟合度检验（参见[“卡方检验”](ch03.xhtml#chi-square)）来评估各种速率与观察数据的拟合程度。
- en: Weibull Distribution
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 威布尔分布
- en: In many cases, the event rate does not remain constant over time. If the period
    over which it changes is much longer than the typical interval between events,
    there is no problem; you just subdivide the analysis into the segments where rates
    are relatively constant, as mentioned before. If, however, the event rate changes
    over the time of the interval, the exponential (or Poisson) distributions are
    no longer useful. This is likely to be the case in mechanical failure—the risk
    of failure increases as time goes by. The *Weibull* distribution is an extension
    of the exponential distribution in which the event rate is allowed to change,
    as specified by a *shape parameter*, <math alttext="beta"><mi>β</mi></math> .
    If <math alttext="beta"><mi>β</mi></math> > 1, the probability of an event increases
    over time; if <math alttext="beta"><mi>β</mi></math> < 1, the probability decreases.
    Because the Weibull distribution is used with time-to-failure analysis instead
    of event rate, the second parameter is expressed in terms of characteristic life,
    rather than in terms of the rate of events per interval. The symbol used is <math
    alttext="eta"><mi>η</mi></math> , the Greek letter eta. It is also called the
    *scale* parameter.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，事件率并不会随时间保持恒定。如果变化的时间段远远长于事件之间的典型间隔，那就没有问题；你只需将分析分成相对恒定的速率的段落，如前所述。然而，如果事件率在时间间隔内发生变化，指数（或泊松）分布就不再有用。在机械故障中很可能会出现这种情况——随着时间的推移，故障风险增加。*威布尔*分布是指数分布的一种扩展，其中允许事件率随时间变化，由*形状参数*
    <math alttext="beta"><mi>β</mi></math> 指定。如果 <math alttext="beta"><mi>β</mi></math>
    > 1，则事件发生的概率随时间增加；如果 <math alttext="beta"><mi>β</mi></math> < 1，则概率减少。因为威布尔分布用于失效时间分析而不是事件率，所以第二个参数用特征寿命表示，而不是事件每个间隔的速率。所使用的符号是
    <math alttext="eta"><mi>η</mi></math> ，希腊字母 eta。它也称为*比例*参数。
- en: With the Weibull, the estimation task now includes estimation of both parameters,
    <math alttext="beta"><mi>β</mi></math> and <math alttext="eta"><mi>η</mi></math>
    . Software is used to model the data and yield an estimate of the best-fitting
    Weibull distribution.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 使用威布尔分布，估计任务现在包括估计两个参数，<math alttext="beta"><mi>β</mi></math> 和 <math alttext="eta"><mi>η</mi></math>
    。软件用于建模数据并给出最佳拟合威布尔分布的估计。
- en: 'The *R* code to generate random numbers from a Weibull distribution takes three
    arguments: `n` (the quantity of numbers to be generated), `shape`, and `scale`.
    For example, the following code would generate 100 random numbers (lifetimes)
    from a Weibull distribution with shape of 1.5 and characteristic life of 5,000:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 生成威布尔分布随机数的*R*代码需要三个参数：`n`（要生成的数字的数量）、`shape`和`scale`。例如，以下代码将从形状为1.5和特征寿命为5,000的威布尔分布中生成100个随机数（寿命）：
- en: '[PRE16]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To achieve the same in *Python*, use the function `stats.weibull_min.rvs`:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 要在*Python*中实现相同的功能，可以使用函数`stats.weibull_min.rvs`：
- en: '[PRE17]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Further Reading
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*Modern Engineering Statistics* by Thomas Ryan (Wiley, 2007) has a chapter
    devoted to the probability distributions used in engineering applications.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*现代工程统计*由Thomas Ryan（Wiley，2007）撰写，其中有一章专门讨论工程应用中使用的概率分布。'
- en: Read an engineering-based perspective on the use of the Weibull distribution
    [here](https://oreil.ly/1x-ga) and [here](https://oreil.ly/9bn-U).
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这里阅读关于威布尔分布的工程视角的内容[here](https://oreil.ly/1x-ga)和[here](https://oreil.ly/9bn-U)。
- en: Summary
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In the era of big data, the principles of random sampling remain important when
    accurate estimates are needed. Random selection of data can reduce bias and yield
    a higher quality data set than would result from just using the conveniently available
    data. Knowledge of various sampling and data-generating distributions allows us
    to quantify potential errors in an estimate that might be due to random variation.
    At the same time, the bootstrap (sampling with replacement from an observed data
    set) is an attractive “one size fits all” method to determine possible error in
    sample estimates.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在大数据时代，当需要准确估计时，随机抽样原则仍然很重要。数据的随机选择可以减少偏差，并产生比仅使用方便获得的数据更高质量的数据集。了解各种抽样和数据生成分布的知识使我们能够量化由随机变异可能导致的估计误差。与此同时，自助法（从观察到的数据集中带有替换地抽样）是一种吸引人的“一刀切”方法，用于确定样本估计中可能的误差。
- en: ^([1](ch02.xhtml#idm46522862237288-marker)) The bell curve is iconic but perhaps
    overrated. George W. Cobb, the Mount Holyoke statistician noted for his contribution
    to the philosophy of teaching introductory statistics, argued in a November 2015
    editorial in the *American Statistician* that the “standard introductory course,
    which puts the normal distribution at its center, had outlived the usefulness
    of its centrality.”
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch02.xhtml#idm46522862237288-marker)) 钟形曲线具有标志性意义，但也许有些被高估了。乔治·W·科布，这位以其对教授统计学初级课程的贡献而闻名的马萨诸塞州圣女大学统计学家，在2015年11月的《美国统计学家》编辑中辩称，“以正态分布为核心的标准初级课程已经超越了其核心性的有用性。”
