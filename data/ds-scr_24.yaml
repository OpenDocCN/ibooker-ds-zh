- en: Chapter 23\. Recommender Systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Chapter 23\. 推荐系统
- en: O nature, nature, why art thou so dishonest, as ever to send men with these
    false recommendations into the world!
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: O nature, nature, why art thou so dishonest, as ever to send men with these
    false recommendations into the world!
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Henry Fielding
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Henry Fielding
- en: Another common data problem is producing *recommendations* of some sort. Netflix
    recommends movies you might want to watch. Amazon recommends products you might
    want to buy. Twitter recommends users you might want to follow. In this chapter,
    we’ll look at several ways to use data to make recommendations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Another common data problem is producing *recommendations* of some sort. Netflix
    recommends movies you might want to watch. Amazon recommends products you might
    want to buy. Twitter recommends users you might want to follow. In this chapter,
    we’ll look at several ways to use data to make recommendations.
- en: 'In particular, we’ll look at the dataset of `users_interests` that we’ve used
    before:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 'In particular, we’ll look at the dataset of `users_interests` that we’ve used
    before:'
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: And we’ll think about the problem of recommending new interests to a user based
    on her currently specified interests.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: And we’ll think about the problem of recommending new interests to a user based
    on her currently specified interests.
- en: Manual Curation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Manual Curation
- en: Before the internet, when you needed book recommendations you would go to the
    library, where a librarian was available to suggest books that were relevant to
    your interests or similar to books you liked.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Before the internet, when you needed book recommendations you would go to the
    library, where a librarian was available to suggest books that were relevant to
    your interests or similar to books you liked.
- en: Given DataSciencester’s limited number of users and interests, it would be easy
    for you to spend an afternoon manually recommending interests for each user. But
    this method doesn’t scale particularly well, and it’s limited by your personal
    knowledge and imagination. (Not that I’m suggesting that your personal knowledge
    and imagination are limited.) So let’s think about what we can do with *data*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Given DataSciencester’s limited number of users and interests, it would be easy
    for you to spend an afternoon manually recommending interests for each user. But
    this method doesn’t scale particularly well, and it’s limited by your personal
    knowledge and imagination. (Not that I’m suggesting that your personal knowledge
    and imagination are limited.) So let’s think about what we can do with *data*.
- en: Recommending What’s Popular
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Recommending What’s Popular
- en: 'One easy approach is to simply recommend what’s popular:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 'One easy approach is to simply recommend what’s popular:'
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'which looks like:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 'which looks like:'
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Having computed this, we can just suggest to a user the most popular interests
    that he’s not already interested in:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 'Having computed this, we can just suggest to a user the most popular interests
    that he’s not already interested in:'
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'So, if you are user 1, with interests:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 'So, if you are user 1, with interests:'
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'then we’d recommend you:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 'then we’d recommend you:'
- en: '[PRE5]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If you are user 3, who’s already interested in many of those things, you’d
    instead get:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 'If you are user 3, who’s already interested in many of those things, you’d
    instead get:'
- en: '[PRE6]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Of course, “lots of people are interested in Python, so maybe you should be
    too” is not the most compelling sales pitch. If someone is brand new to our site
    and we don’t know anything about them, that’s possibly the best we can do. Let’s
    see how we can do better by basing each user’s recommendations on her existing
    interests.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Of course, “lots of people are interested in Python, so maybe you should be
    too” is not the most compelling sales pitch. If someone is brand new to our site
    and we don’t know anything about them, that’s possibly the best we can do. Let’s
    see how we can do better by basing each user’s recommendations on her existing
    interests.
- en: User-Based Collaborative Filtering
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于用户的协同过滤
- en: One way of taking a user’s interests into account is to look for users who are
    somehow *similar* to her, and then suggest the things that those users are interested
    in.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: One way of taking a user’s interests into account is to look for users who are
    somehow *similar* to her, and then suggest the things that those users are interested
    in.
- en: In order to do that, we’ll need a way to measure how similar two users are.
    Here we’ll use cosine similarity, which we used in [Chapter 21](ch21.html#natural_language_processing)
    to measure how similar two word vectors were.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: In order to do that, we’ll need a way to measure how similar two users are.
    Here we’ll use cosine similarity, which we used in [第21章](ch21.html#natural_language_processing)
    to measure how similar two word vectors were.
- en: We’ll apply this to vectors of 0s and 1s, each vector `v` representing one user’s
    interests. `v[i]` will be 1 if the user specified the *i*th interest, and 0 otherwise.
    Accordingly, “similar users” will mean “users whose interest vectors most nearly
    point in the same direction.” Users with identical interests will have similarity
    1\. Users with no identical interests will have similarity 0\. Otherwise, the
    similarity will fall in between, with numbers closer to 1 indicating “very similar”
    and numbers closer to 0 indicating “not very similar.”
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: We’ll apply this to vectors of 0s and 1s, each vector `v` representing one user’s
    interests. `v[i]` will be 1 if the user specified the *i*th interest, and 0 otherwise.
    Accordingly, “similar users” will mean “users whose interest vectors most nearly
    point in the same direction.” Users with identical interests will have similarity
    1\. Users with no identical interests will have similarity 0\. Otherwise, the
    similarity will fall in between, with numbers closer to 1 indicating “very similar”
    and numbers closer to 0 indicating “not very similar.”
- en: 'A good place to start is collecting the known interests and (implicitly) assigning
    indices to them. We can do this by using a set comprehension to find the unique
    interests, and then sorting them into a list. The first interest in the resulting
    list will be interest 0, and so on:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的开始是收集已知的兴趣，并（隐式地）为它们分配索引。我们可以通过使用集合推导来找到唯一的兴趣，并将它们排序成一个列表。结果列表中的第一个兴趣将是兴趣0，依此类推：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This gives us a list that starts:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们一个以这样开始的列表：
- en: '[PRE8]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next we want to produce an “interest” vector of 0s and 1s for each user. We
    just need to iterate over the `unique_interests` list, substituting a 1 if the
    user has each interest, and a 0 if not:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们想为每个用户生成一个“兴趣”向量，其中包含0和1。我们只需遍历`unique_interests`列表，如果用户具有每个兴趣，则替换为1，否则为0：
- en: '[PRE9]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'And now we can make a list of user interest vectors:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以制作一个用户兴趣向量的列表：
- en: '[PRE10]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now `user_interest_vectors[i][j]` equals 1 if user `i` specified interest `j`,
    and 0 otherwise.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果用户`i`指定了兴趣`j`，那么`user_interest_vectors[i][j]`等于1，否则为0。
- en: 'Because we have a small dataset, it’s no problem to compute the pairwise similarities
    between all of our users:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们有一个小数据集，计算所有用户之间的成对相似性是没有问题的：
- en: '[PRE11]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'after which `user_similarities[i][j]` gives us the similarity between users
    `i` and `j`:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，`user_similarities[i][j]`给出了用户`i`和`j`之间的相似性：
- en: '[PRE12]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In particular, `user_similarities[i]` is the vector of user `i`’s similarities
    to every other user. We can use this to write a function that finds the most similar
    users to a given user. We’ll make sure not to include the user herself, nor any
    users with zero similarity. And we’ll sort the results from most similar to least
    similar:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 特别地，`user_similarities[i]`是用户`i`与每个其他用户的相似性向量。我们可以使用这个来编写一个函数，找出与给定用户最相似的用户。我们会确保不包括用户本身，也不包括任何相似性为零的用户。并且我们会按照相似性从高到低对结果进行排序：
- en: '[PRE13]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'For instance, if we call `most_similar_users_to(0)` we get:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们调用`most_similar_users_to(0)`，我们会得到：
- en: '[PRE14]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'How do we use this to suggest new interests to a user? For each interest, we
    can just add up the user similarities of the other users interested in it:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何利用这个来向用户建议新的兴趣？对于每个兴趣，我们可以简单地加上对它感兴趣的其他用户的用户相似性：
- en: '[PRE15]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If we call `user_based_suggestions(0)`, the first several suggested interests
    are:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们调用`user_based_suggestions(0)`，那么前几个建议的兴趣是：
- en: '[PRE16]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: These seem like pretty decent suggestions for someone whose stated interests
    are “Big Data” and database-related. (The weights aren’t intrinsically meaningful;
    we just use them for ordering.)
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些声称兴趣是“大数据”和数据库相关的人来说，这些看起来是相当不错的建议。（权重本质上没有意义；我们只是用它们来排序。）
- en: This approach doesn’t work as well when the number of items gets very large.
    Recall the curse of dimensionality from [Chapter 12](ch12.html#nearest_neighbors)—in
    large-dimensional vector spaces most vectors are very far apart (and also point
    in very different directions). That is, when there are a large number of interests
    the “most similar users” to a given user might not be similar at all.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当项目数量变得非常大时，这种方法效果不佳。回想一下[第12章](ch12.html#nearest_neighbors)中的维度诅咒 —— 在高维向量空间中，大多数向量相距甚远（并且指向非常不同的方向）。也就是说，当兴趣的数量很多时，对于给定用户，“最相似的用户”可能完全不相似。
- en: Imagine a site like Amazon.com, from which I’ve bought thousands of items over
    the last couple of decades. You could attempt to identify similar users to me
    based on buying patterns, but most likely in all the world there’s no one whose
    purchase history looks even remotely like mine. Whoever my “most similar” shopper
    is, he’s probably not similar to me at all, and his purchases would almost certainly
    make for lousy recommendations.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个像Amazon.com这样的网站，我在过去几十年里购买了成千上万件物品。你可以基于购买模式尝试识别与我类似的用户，但在全世界范围内，几乎没有人的购买历史看起来像我的。无论我的“最相似”的购物者是谁，他可能与我完全不相似，他的购买几乎肯定不会提供好的推荐。
- en: Item-Based Collaborative Filtering
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于物品的协同过滤
- en: An alternative approach is to compute similarities between interests directly.
    We can then generate suggestions for each user by aggregating interests that are
    similar to her current interests.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是直接计算兴趣之间的相似性。然后我们可以通过聚合与她当前兴趣相似的兴趣来为每个用户生成建议。
- en: 'To start with, we’ll want to *transpose* our user-interest matrix so that rows
    correspond to interests and columns correspond to users:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，我们将希望*转置*我们的用户-兴趣矩阵，以便行对应于兴趣，列对应于用户：
- en: '[PRE17]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: What does this look like? Row `j` of `interest_user_matrix` is column `j` of
    `user_interest_matrix`. That is, it has 1 for each user with that interest and
    0 for each user without that interest.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是什么样子？`interest_user_matrix` 的第 `j` 行就是 `user_interest_matrix` 的第 `j` 列。也就是说，对于每个具有该兴趣的用户，它的值为
    1，对于每个没有该兴趣的用户，它的值为 0。
- en: 'For example, `unique_interests[0]` is Big Data, and so `interest_user_matrix[0]`
    is:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`unique_interests[0]` 是大数据，所以 `interest_user_matrix[0]` 是：
- en: '[PRE18]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: because users 0, 8, and 9 indicated interest in Big Data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因为用户 0、8 和 9 表示对大数据感兴趣。
- en: 'We can now use cosine similarity again. If precisely the same users are interested
    in two topics, their similarity will be 1\. If no two users are interested in
    both topics, their similarity will be 0:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以再次使用余弦相似度。如果完全相同的用户对两个主题感兴趣，它们的相似度将为 1。如果没有两个用户对两个主题感兴趣，它们的相似度将为 0：
- en: '[PRE19]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'For example, we can find the interests most similar to Big Data (interest 0)
    using:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以使用以下方法找到与大数据（兴趣 0）最相似的兴趣：
- en: '[PRE20]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'which suggests the following similar interests:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明以下类似的兴趣：
- en: '[PRE21]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now we can create recommendations for a user by summing up the similarities
    of the interests similar to his:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以通过累加与其相似的兴趣的相似性来为用户创建推荐：
- en: '[PRE22]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'For user 0, this generates the following (seemingly reasonable) recommendations:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于用户 0，这将生成以下（看起来合理的）推荐：
- en: '[PRE23]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Matrix Factorization
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 矩阵分解
- en: As we’ve seen, we can represent our users’ preferences as a `[num_users, num_items]`
    matrix of 0s and 1s, where the 1s represent liked items and the 0s unliked items.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们可以将用户的偏好表示为一个 `[num_users, num_items]` 的矩阵，其中 1 表示喜欢的项目，0 表示不喜欢的项目。
- en: Sometimes you might actually have numeric *ratings*; for example, when you write
    an Amazon review you assign the item a score ranging from 1 to 5 stars. You could
    still represent these by numbers in a `[num_users, num_items]` matrix (ignoring
    for now the problem of what to do about unrated items).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有时您实际上可能有数值型的 *评分*；例如，当您写亚马逊评论时，您为物品分配了从 1 到 5 星的评分。您仍然可以通过数字在一个 `[num_users,
    num_items]` 的矩阵中表示这些（暂时忽略未评分项目的问题）。
- en: In this section we’ll assume we have such ratings data and try to learn a model
    that can predict the rating for a given user and item.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们假设已经有了这样的评分数据，并尝试学习一个能够预测给定用户和项目评分的模型。
- en: One way of approaching the problem is to assume that every user has some latent
    “type,” which can be represented as a vector of numbers, and that each item similarly
    has some latent “type.”
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一种方法是假设每个用户都有一些潜在的“类型”，可以表示为一组数字向量，而每个项目同样也有一些潜在的“类型”。
- en: If the user types are represented as a `[num_users, dim]` matrix, and the transpose
    of the item types is represented as a `[dim, num_items]` matrix, their product
    is a `[num_users, num_items]` matrix. Accordingly, one way of building such a
    model is by “factoring” the preferences matrix into the product of a user matrix
    and an item matrix.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将用户类型表示为 `[num_users, dim]` 矩阵，将项目类型的转置表示为 `[dim, num_items]` 矩阵，则它们的乘积是一个
    `[num_users, num_items]` 矩阵。因此，构建这样一个模型的一种方式是将偏好矩阵“因子化”为用户矩阵和项目矩阵的乘积。
- en: (Possibly this idea of latent types reminds you of the word embeddings we developed
    in [Chapter 21](ch21.html#natural_language_processing). Hold on to that idea.)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: （也许这种潜在类型的想法会让你想起我们在 [第 21 章](ch21.html#natural_language_processing) 中开发的词嵌入。记住这个想法。）
- en: Rather than working with our made-up 10-user dataset, we’ll work with the MovieLens
    100k dataset, which contains ratings from 0 to 5 for many movies from many users.
    Each user has only rated a small subset of the movies. We’ll use this to try to
    build a system that can predict the rating for any given (user, movie) pair. We’ll
    train it to predict well on the movies each user has rated; hopefully then it
    will generalize to movies the user hasn’t rated.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是使用我们虚构的 10 用户数据集，我们将使用 MovieLens 100k 数据集，其中包含许多用户对许多电影的评分，评分从 0 到 5 不等。每个用户只对少数电影进行了评分。我们将尝试构建一个系统，可以预测任意给定的（用户，电影）对的评分。我们将训练它以在每个用户评分的电影上表现良好；希望它能推广到用户未评分的电影。
- en: To start with, let’s acquire the dataset. You can download it from [*http://files.grouplens.org/datasets/movielens/ml-100k.zip*](http://files.grouplens.org/datasets/movielens/ml-100k.zip).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们获取数据集。您可以从 [*http://files.grouplens.org/datasets/movielens/ml-100k.zip*](http://files.grouplens.org/datasets/movielens/ml-100k.zip)
    下载它。
- en: 'Unzip it and extract the files; we’ll only use two of them:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 解压并提取文件；我们仅使用其中两个：
- en: '[PRE24]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As is often the case, we’ll introduce a `NamedTuple` to make things easier
    to work with:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 常见情况下，我们会引入 `NamedTuple` 来使工作更加简便：
- en: '[PRE25]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The movie ID and user IDs are actually integers, but they’re not consecutive,
    which means if we worked with them as integers we’d end up with a lot of wasted
    dimensions (unless we renumbered everything). So to keep it simpler we’ll just
    treat them as strings.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 电影ID和用户ID实际上是整数，但它们不是连续的，这意味着如果我们将它们作为整数处理，将会有很多浪费的维度（除非我们重新编号所有内容）。因此，为了简化起见，我们将它们视为字符串处理。
- en: 'Now let’s read in the data and explore it. The movies file is pipe-delimited
    and has many columns. We only care about the first two, which are the ID and the
    title:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们读取数据并探索它。电影文件是管道分隔的，并且有许多列。我们只关心前两列，即ID和标题：
- en: '[PRE26]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The ratings file is tab-delimited and contains four columns for `user_id`,
    `movie_id`, `rating` (1 to 5), and `timestamp`. We’ll ignore the timestamp, as
    we don’t need it:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 评分文件是制表符分隔的，包含四列：`user_id`、`movie_id`、评分（1到5），以及`timestamp`。我们将忽略时间戳，因为我们不需要它：
- en: '[PRE27]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'There’s a lot of interesting exploratory analysis you can do on this data;
    for instance, you might be interested in the average ratings for *Star Wars* movies
    (the dataset is from 1998, which means it predates *The Phantom Menace* by a year):'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多有趣的探索性分析可以在这些数据上进行；例如，您可能对*星球大战*电影的平均评分感兴趣（该数据集来自1998年，比*星球大战：幽灵的威胁*晚一年）：
- en: '[PRE28]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'They’re all pretty highly rated:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 它们都评分很高：
- en: '[PRE29]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'So let’s try to come up with a model to predict these ratings. As a first step,
    let’s split the ratings data into train, validation, and test sets:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们尝试设计一个模型来预测这些评分。作为第一步，让我们将评分数据分成训练集、验证集和测试集：
- en: '[PRE30]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'It’s always good to have a simple baseline model and make sure that ours does
    better than that. Here a simple baseline model might be “predict the average rating.”
    We’ll be using mean squared error as our metric, so let’s see how the baseline
    does on our test set:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个简单的基线模型总是好的，并确保我们的模型比它表现更好。这里一个简单的基线模型可能是“预测平均评分”。我们将使用均方误差作为我们的指标，所以让我们看看基线在我们的测试集上表现如何：
- en: '[PRE31]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Given our embeddings, the predicted ratings are given by the matrix product
    of the user embeddings and the movie embeddings. For a given user and movie, that
    value is just the dot product of the corresponding embeddings.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 给定我们的嵌入，预测的评分由用户嵌入和电影嵌入的矩阵乘积给出。对于给定的用户和电影，该值只是对应嵌入的点积。
- en: 'So let’s start by creating the embeddings. We’ll represent them as `dict`s
    where the keys are IDs and the values are vectors, which will allow us to easily
    retrieve the embedding for a given ID:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们从创建嵌入开始。我们将它们表示为`dict`，其中键是ID，值是向量，这样可以轻松地检索给定ID的嵌入：
- en: '[PRE32]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'By now we should be pretty expert at writing training loops:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们应该相当擅长编写训练循环：
- en: '[PRE33]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'And now we can train our model (that is, find the optimal embeddings). For
    me it worked best if I decreased the learning rate a little each epoch:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以训练我们的模型（即找到最优的嵌入）。对我来说，如果我每个时期都稍微降低学习率，效果最好：
- en: '[PRE34]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This model is pretty apt to overfit the training set. I got the best results
    with `EMBEDDING_DIM=2`, which got me an average loss on the test set of about
    0.89.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型很容易过拟合训练集。我在测试集上的平均损失是大约0.89，这时`EMBEDDING_DIM=2`的情况下取得最佳结果。
- en: Note
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you wanted higher-dimensional embeddings, you could try regularization like
    we used in [“Regularization”](ch15.html#regularization). In particular, at each
    gradient update you could shrink the weights toward 0. I was not able to get any
    better results that way.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要更高维度的嵌入，您可以尝试像我们在[“正则化”](ch15.html#regularization)中使用的正则化。特别是，在每次梯度更新时，您可以将权重收缩至0附近。但我没能通过这种方式获得更好的结果。
- en: 'Now, inspect the learned vectors. There’s no reason to expect the two components
    to be particularly meaningful, so we’ll use principal component analysis:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，检查学习到的向量。没有理由期望这两个组件特别有意义，因此我们将使用主成分分析：
- en: '[PRE35]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let’s transform our vectors to represent the principal components and join
    in the movie IDs and average ratings:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将我们的向量转换为表示主成分，并加入电影ID和平均评分：
- en: '[PRE36]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The top 25 are all highly rated, while the bottom 25 are mostly low-rated (or
    unrated in the training data), which suggests that the first principal component
    is mostly capturing “how good is this movie?”
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 前25个电影评分都很高，而后25个大部分是低评分的（或在训练数据中未评级），这表明第一个主成分主要捕捉了“这部电影有多好？”
- en: It’s hard for me to make much sense of the second component; and, indeed the
    two-dimensional embeddings performed only slightly better than the one-dimensional
    embeddings, suggesting that whatever the second component captured is possibly
    very subtle. (Presumably one of the larger MovieLens datasets would have more
    interesting things going on.)
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我来说，很难理解第二个组件的意义；而且二维嵌入的表现只比一维嵌入略好，这表明第二个组件捕捉到的可能是非常微妙的内容。（可以推测，在较大的MovieLens数据集中可能有更有趣的事情发生。）
- en: For Further Exploration
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步探索
- en: '[Surprise](http://surpriselib.com/) is a Python library for “building and analyzing
    recommender systems” that seems reasonably popular and up-to-date.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[惊喜](http://surpriselib.com/)是一个用于“构建和分析推荐系统”的Python库，似乎相当受欢迎且更新及时。'
- en: The [Netflix Prize](http://www.netflixprize.com) was a somewhat famous competition
    to build a better system to recommend movies to Netflix users.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Netflix Prize](http://www.netflixprize.com) 是一个相当有名的比赛，旨在构建更好的系统，向Netflix用户推荐电影。'
