- en: 1 An urgent need for efficiency in data processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 数据处理效率的迫切需求
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The challenges of dealing with the exponential growth of data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应对数据指数级增长带来的挑战
- en: Comparing traditional and recent computing architectures
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较传统和最近的计算架构
- en: The role and shortcomings of Python in modern data analytics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python在现代数据分析中的角色和不足
- en: Techniques for delivering efficient Python computing solutions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供高效Python计算解决方案的技术
- en: An enormous amount of data is being collected all the time, at intense speeds,
    and from a broad scope of sources. It is collected whether or not there is currently
    a use for it. It is collected whether or not there is a way to process, store,
    access, or learn from it. Before data scientists can analyze it, before designers
    and developers and policymakers can use it to create products, services, and programs,
    software engineers must find ways to store and process it. Now more than ever
    those engineers need efficient ways to improve performance and optimize storage.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 每时每刻都在以极高的速度从广泛的来源收集大量数据。无论是否有当前的使用需求，都会被收集。无论是否有处理、存储、访问或从中学习的方法，都会被收集。在数据科学家能够分析它之前，在设计师、开发人员和政策制定者能够用它来创建产品、服务和计划之前，软件工程师必须找到存储和处理它的方法。现在比以往任何时候，这些工程师都需要更有效的方法来提高性能和优化存储。
- en: 'In this book, I share a collection of strategies for performance and storage
    optimization that I use in my own work. Simply throwing more machines at the problem
    is often neither possible nor helpful. So the solutions I introduce here rely
    more on understanding and exploiting what we all have at hand: coding approaches,
    hardware and system architectures, available software, and, of course, nuances
    of the Python language, libraries, and ecosystem.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我分享了我自己在工作中使用的性能和存储优化策略的集合。简单地向问题投入更多的机器通常既不可能也不有帮助。因此，我在这里介绍的方法更多地依赖于理解和利用我们手头拥有的东西：编码方法、硬件和系统架构、可用的软件，当然还有Python语言、库和生态系统的细微差别。
- en: Python has emerged as the language of choice to do, or at least glue, all the
    heavy lifting around this data *deluge*, as the cliches call it. Indeed, Python’s
    popularity in data science and data engineering is one of the main drivers of
    the language’s growth, helping to push it to one of the top three most popular
    languages, according to a majority of developer surveys. Python has its own unique
    set of advantages and limitations for dealing with big data, and its lack of speed
    certainly presents challenges. On the plus side, as you’ll see, there are many
    different angles, approaches, and workarounds to making Python work more efficiently
    with large amounts of data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正如俗语所说，Python已经成为处理或至少粘合围绕这一数据*洪流*的重型工作的首选语言。确实，Python在数据科学和数据工程中的流行是推动语言增长的主要驱动力之一，帮助它成为大多数开发者调查中排名前三的最受欢迎的语言之一。Python在处理大数据方面有其独特的优势和局限性，其缺乏速度无疑带来了挑战。从积极的一面来看，正如您将看到的，有许多不同的角度、方法和解决方案可以使Python更有效地处理大量数据。
- en: Before we get to the solutions, we need to fully comprehend the problem(s),
    and that is what we’ll do in much of this first chapter. We will spend a few moments
    looking more closely at the computing challenges presented by the deluge of data
    to orient ourselves to what exactly we are dealing with. Next, we’ll examine the
    role of hardware, network, and cloud architectures to see why the old solutions,
    such as increasing CPU speed, are no longer adequate. Then we’ll turn to the particular
    challenges that Python faces when dealing with big data, including Python’s threading
    and CPython’s Global Interpreter Lock (GIL). Once we’ve fully understood the need
    for new approaches to making Python perform better, I’ll present an overview of
    the solutions that you’ll learn in this book.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们到达解决方案之前，我们需要完全理解问题（s），这正是我们在第一章的大部分内容中将要做的。我们将花几分钟时间更仔细地看看数据洪流带来的计算挑战，以便我们能够确定我们正在处理的是什么。接下来，我们将检查硬件、网络和云架构在其中的作用，以了解为什么像增加CPU速度这样的旧解决方案已经不再足够。然后，我们将转向Python在处理大数据时面临的特定挑战，包括Python的线程和CPython的全局解释器锁（GIL）。一旦我们完全理解了需要新的方法来提高Python的性能，我将在本书中概述您将学习的解决方案。
- en: 1.1 How bad is the data deluge?
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 数据洪流有多糟糕？
- en: You may be aware of two computing laws, Moore’s and Edholm’s, that together
    offer a dramatic picture of the exponential growth of data along with the lagging
    ability of computing systems to deal with that data. Edholm’s Law states that
    data rates in telecommunications double every 18 months, while Moore’s law predicts
    that the number of transistors that can fit on a microchip doubles every two years.
    We can take Edholm’s data transfer rate as a proxy for the amount of data collected
    and Moore’s transistor density as an indicator of speed and capacity in computing
    hardware. When we put them together we find a six-month lag between how fast and
    how much data we collect, and our ability to process and store it. Because exponential
    growth can be tricky to understand in words, I’ve plotted the two laws against
    each other in one graph, shown in figure 1.1
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经知道两个计算定律，摩尔定律和埃德霍尔姆定律，它们共同描绘了数据指数增长以及计算系统处理这些数据的滞后能力。埃德霍尔姆定律指出，电信中的数据速率每18个月翻一番，而摩尔定律预测，每两年可以在微芯片上放置的晶体管数量翻一番。我们可以将埃德霍尔姆的数据传输速率视为收集数据量的代理，将摩尔定律的晶体管密度视为计算硬件的速度和容量的指标。当我们把它们放在一起时，我们发现我们收集数据速度和存储处理数据的能力之间存在六个月的滞后。由于指数增长在文字上难以理解，我在一张图表中绘制了这两个定律，如图1.1所示。
- en: '![](../Images/CH01_F01_Antao.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F01_Antao.png)'
- en: Figure 1.1 The ratio between Moore’s law and Edholm’s law suggests that hardware
    will always lag behind the amount of data being generated. Moreover, the gap will
    increase over time.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 摩尔定律与埃德霍尔姆定律的比例表明，硬件将始终落后于生成数据的数量。此外，随着时间的推移，差距将会增大。
- en: The situation described by this graph can be seen as a fight between what we
    need to analyze (Edholm’s law) versus the power that we have to do that analysis
    (Moore’s law). The graph actually paints a rosier picture than what we have in
    reality. We will see why in chapter 6 when we discuss Moore’s law in the context
    of modern CPU architectures. To focus here on data growth, let’s look at one example,
    internet traffic, which is an indirect measure of data available. As you can see
    in figure 1.2, the growth of internet traffic over the years tracks Edholm’s law
    quite well.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表所描述的情况可以看作是我们需要分析的内容（埃德霍尔姆定律）与我们进行该分析的能力（摩尔定律）之间的斗争。实际上，这个图表描绘的比现实中的情况更加乐观。我们将在第6章讨论摩尔定律与现代CPU架构的背景下了解这一点。为了集中讨论数据增长，让我们看看一个例子，即互联网流量，它是可用数据的间接衡量标准。如图1.2所示，多年来互联网流量的增长与埃德霍尔姆定律非常吻合。
- en: '![](../Images/CH01_F02_Antao.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F02_Antao.png)'
- en: 'Figure 1.2 The growth of global internet traffic over the years, measured in
    petabytes per month. (Source: [https://en.wikipedia.org/wiki/Internet_traffic](https://en.wikipedia.org/wiki/Internet_traffic).)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 过去几年全球互联网流量的增长，以每月千兆字节为单位。（来源：[https://en.wikipedia.org/wiki/Internet_traffic](https://en.wikipedia.org/wiki/Internet_traffic).）
- en: In addition, 90% of the data humankind has produced happened in the last two
    years (see “Big Data and What It Means,” [http://mng.bz/v1ya](http://mng.bz/v1ya)).
    Whether the quality of this new data is proportional to its size is another matter
    altogether. The point is that data produced will need to be processed and that
    processing will require resources.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，人类在过去两年内产生的90%的数据（参见“大数据及其意义”，[http://mng.bz/v1ya](http://mng.bz/v1ya)）。这些新数据的品质是否与其规模成比例是另一个问题。重要的是，产生出的数据需要被处理，而处理则需要资源。
- en: It’s not just the amount of available data that presents software engineers
    with obstacles. The way all this new data is represented is also changing in nature.
    Some project that by 2025, around 80% of data could be unstructured, (“Tapping
    the power of unstructured data,” [http://mng.bz/BlP0](http://mng.bz/BlP0)). We
    will get into the details later in the book, but simply put, unstructured data
    makes data processing more demanding from a computational perspective.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅可用的数据量给软件工程师带来了障碍，这些新数据的表示方式也在本质上发生变化。一些预测到2025年，大约80%的数据将是非结构化的（“挖掘非结构化数据的力量”，[http://mng.bz/BlP0](http://mng.bz/BlP0)）。我们将在本书的后面部分详细讨论这个问题，但简单来说，非结构化数据从计算的角度来看使得数据处理更加复杂。
- en: How do we deal with all this growth in data? It turns out that we mostly don’t.
    More than 99% of data produced is never analyzed, according to *The Guardian*
    ([http://mng.bz/Q8M4](http://mng.bz/Q8M4)). Part of what holds us back from making
    use of so much of our data is that we lack efficient procedures to analyze it.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何处理所有这些数据增长？据《卫报》报道，超过 99% 产生出来的数据从未被分析。[http://mng.bz/Q8M4](http://mng.bz/Q8M4)。阻碍我们利用如此多的数据的一部分原因是，我们缺乏分析它的有效程序。
- en: 'The growth of data and the concomitant need for more processing has developed
    into one of the most pernicious mantras about computing: “If you have more data,
    just throw more servers at it.” For many reasons, that is not often a viable or
    appropriate solution. Instead, when we need to increase the performance of an
    existing system, we can look at the system architecture and implementation and
    find places where we can optimize for performance. I have lost count of how many
    times I have been able to get ten-fold increases in performance just by being
    mindful of efficiency problems when reviewing existing code.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的增长以及随之而来的对更多处理的需求已经发展成为关于计算的最有害的咒语之一：“如果你有更多的数据，只需向它投入更多的服务器。”由于许多原因，这通常不是一个可行或适当的解决方案。相反，当我们需要提高现有系统的性能时，我们可以查看系统架构和实现，并找到我们可以优化性能的地方。我已经数不清有多少次只是通过在审查现有代码时关注效率问题，就能实现性能的十倍提升。
- en: 'What is crucial to understand is that the relationship between the amount of
    increased data to analyze, and the complexity of the infrastructure needed to
    analyze it, is hardly linear. Solving these problems requires more time and ingenuity
    on the developer’s part than in machines. This is true not only with cloud environments
    but also with in-house clusters and even with single-machine implementations.
    A few use cases will help to make this clear. For example:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 非常重要的是要理解，需要分析的数据量增加与分析所需的基础设施复杂度之间的关系几乎不是线性的。解决这些问题需要开发者投入更多的时间和创造力，而不仅仅是机器。这不仅适用于云环境，也适用于内部集群，甚至适用于单机实现。一些用例将有助于阐明这一点。例如：
- en: '*Your solution requires only a single computer, but suddenly you need more
    machines.* Adding machines means you will have to manage the number of machines,
    distribute the workload across them, and make sure the data is partitioned correctly.
    You might also need a file system server to add to your list of machines. The
    cost of maintaining a server farm, or just a cloud, is *qualitatively* much more
    than maintaining a single computer.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你的解决方案只需要一台计算机，但突然你需要更多的机器。* 添加机器意味着你将不得不管理机器的数量，在它们之间分配工作负载，并确保数据被正确分区。你可能还需要添加一个文件系统服务器到你的机器列表中。维护一个服务器农场或仅仅是云的成本，在质量上远比维护一台计算机的成本要高得多。'
- en: '*Your solution works well in-memory but then the amount of data increases and
    no longer fits your memory.* To handle the new amount of data stored in disk will
    normally entail a major rewrite of your code. And, of course, the code itself
    will grow in complexity. For instance, if the main database is now on disk, you
    may need to create a cache policy. Or you may need to do concurrent reads from
    multiple processes, or, even worse, concurrent writes.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你的解决方案在内存中运行良好，但随着数据量的增加，它不再适合你的内存。* 处理存储在磁盘中的新数据量通常需要重写你的代码。当然，代码本身的复杂性也会增加。例如，如果主数据库现在在磁盘上，你可能需要创建一个缓存策略。或者你可能需要从多个进程中并发读取，或者更糟糕的是，并发写入。'
- en: '*You use a SQL database and suddenly you reach the maximum throughput capacity
    of the server.* If it’s only a read capacity problem, then you might survive by
    just creating a few read replicas. But if it is a write problem, what do you do?
    Maybe you set up sharding.[¹](#pgfId-1012022) Or do you decide to completely change
    your database technology in favor of some supposedly better performant NoSQL variant?'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*你使用的是 SQL 数据库，突然你达到了服务器的最大吞吐量容量。* 如果只是读取容量问题，那么你可能会通过仅仅创建几个读取副本来存活。但如果是写入问题，你该怎么办？也许你会设置分片。[¹](#pgfId-1012022)
    或者你决定完全改变你的数据库技术，以支持一些据说性能更好的 NoSQL 变体？'
- en: '*If you are dependent on a system in the cloud based on vendor proprietary
    technologies, you might discover that the ability to scale indefinitely is more
    marketing talk than technological reality.* In many cases, if you hit performance
    limits, the only realistic solution is to change the technology that you are using,
    a change that requires enormous time, money, and human energy.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如果你依赖于基于供应商专有技术的云系统，你可能会发现无限扩展的能力更多的是营销话术而不是技术现实。* 在许多情况下，如果你遇到性能限制，唯一现实的解决方案是改变你正在使用的科技，这种改变需要巨大的时间、金钱和人力。'
- en: I hope these examples make the case that growth is not just a question of “adding
    more machines,” but instead entails substantial work on several fronts to deal
    with the increased complexity. Even something as “simple” as a parallel solution
    implemented on a single computer can bring with it all the problems of parallel
    processing (races, deadlocks, and more). These more efficient solutions can have
    a dramatic effect on complexity, reliability, and cost.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这些例子能说明，增长不仅仅是“增加更多机器”的问题，而是需要在多个方面进行大量工作以应对增加的复杂性。即使是“简单”如在一个计算机上实现的并行解决方案，也可能带来并行处理的所有问题（竞争、死锁等）。这些更有效的解决方案可以对复杂性、可靠性和成本产生重大影响。
- en: 'Finally, we could make the case that even if we *could* scale our infrastructure
    linearly (we can’t, really), there would be ethical and ecological problems to
    consider: forecasts put energy consumption related to a “tsunami of data” at 20%
    of global electricity production (“Tsunami of Data,” [http://mng.bz/X5GE](http://mng.bz/X5GE)),
    and there is also a problem of landfill disposal as we update hardware.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以提出这样的观点：即使我们*能够*线性扩展我们的基础设施（实际上我们做不到），我们也需要考虑伦理和生态问题：预测表明与“数据海啸”相关的能源消耗占全球电力生产的20%（《数据海啸》，[http://mng.bz/X5GE](http://mng.bz/X5GE)），而且在我们更新硬件时，也存在垃圾填埋处理的问题。
- en: The good news is that becoming computationally more efficient when handling
    big data helps us to reduce our computing bill, the complexity of the architecture
    for our solution, our storage needs, our time to market, and our energy footprint.
    And sometimes, more efficient solutions might even come with minimal implementation
    costs. For example, the judicious use of data structures might reduce computing
    time at no substantial development cost.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，在处理大数据时提高计算效率可以帮助我们降低计算账单、解决方案架构的复杂性、我们的存储需求、我们的上市时间和我们的能源足迹。有时，更有效的解决方案甚至可能带来最低的实施成本。例如，合理使用数据结构可能在没有显著开发成本的情况下减少计算时间。
- en: 'On the other hand, many of the solutions we’ll look at will have a development
    cost and will add an amount of complexity themselves. When you look at *your*
    data and forecasts for its growth, you will have to make a judgment call on where
    to optimize, as there are no clear-cut recipes or one-size-fits-all solutions.
    That being said, there might be just one rule that can be applied across the board:
    if the solution is good for Netflix, Google, Amazon, Apple, or Facebook, then
    probably it is *not* good for you, unless, of course, you work for one of these
    companies.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们将要探讨的许多解决方案都会有开发成本，并且它们自身也会增加一定的复杂性。当你查看*你的*数据和其增长预测时，你将不得不做出判断，决定在哪里进行优化，因为没有明确的食谱或适合所有情况的解决方案。尽管如此，可能只有一条普遍适用的规则：如果这个解决方案对Netflix、Google、Amazon、Apple或Facebook有益，那么很可能它对你来说*不是*一个好的选择，除非，当然，你在这家公司工作。
- en: The amount of data that most of us will see will be substantially lower than
    the biggest technological companies use. It will still be enormous, and it will
    still be hard, but it will probably be a few orders of magnitude lower. The somewhat
    prevailing wisdom that what works for those companies is also a good fit for the
    rest of us is, in my opinion, just wrong. Generally, less complex solutions will
    be more appropriate for most of us.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们大多数人将看到的数据量将远远低于最大的科技公司使用的量。它仍然会很大，仍然很难处理，但可能低几个数量级。在我看来，普遍认为那些公司适用的解决方案也适合我们所有人的观点是错误的。通常，更简单的解决方案对我们大多数人来说更合适。
- en: 'As you can see, this new world with extreme growth, both in quantity and complexity,
    of both data and algorithms requires more sophisticated techniques to perform
    computation and storage in an efficient and cost-conscious way. Don’t get me wrong:
    sometimes you *will* need to scale up your infrastructure. But when you architect
    and implement your solution, you can still use the same mindset of focusing on
    efficiency. It’s just that the techniques will be different.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，这个新世界，数据量和算法的复杂度都在极端增长，需要更复杂的技巧来高效且成本意识地进行计算和存储。请别误会我：有时你*确实*需要扩展你的基础设施。但在架构和实现你的解决方案时，你仍然可以使用关注效率的相同思维方式。只是技术将不同。
- en: 1.2 Modern computing architectures and high-performance computing
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 现代计算机架构和高性能计算
- en: Creating more efficient solutions does not happen in an abstract void. First,
    we have our domain problem to consider—that is, what real problem you are trying
    to solve. Equally important is the computing architecture where our solution will
    be run. Computing architectures play a major role in determining the best optimization
    techniques, so we have to take them into consideration when we devise our software
    solutions. In this section, we will take a look at the main architectural problems
    that affect the design and implementation of our solutions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 创建更有效的解决方案并不是在抽象的虚空中发生的。首先，我们必须考虑我们的领域问题——也就是说，你正在尝试解决什么实际问题。同样重要的是我们的解决方案将运行的计算架构。计算架构在确定最佳优化技术方面发挥着重要作用，因此在我们设计软件解决方案时必须考虑它们。在本节中，我们将探讨影响我们解决方案设计和实现的
    主要架构问题。
- en: 1.2.1 Changes inside the computer
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 计算机内部的变化
- en: 'Radical changes are happening *inside* the computer. First, we have CPUs that
    are increasing processing power mostly in the number of parallel units, not raw
    speed, as they did in the past. Computers can also be equipped with graphics processing
    units (GPUs), which were originally developed for graphics processing only but
    now can be used for general computing as well. Indeed, many efficient implementations
    of AI algorithms are done for GPUs. Unfortunately, at least from our perspective,
    GPUs have a completely different architecture than CPUs: they are composed of
    thousands of computing units that are expected to do the same “simple” computation
    across all units. The memory model is also completely different. These differences
    mean that programming GPUs require a radically different approach from programming
    CPUs.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机内部正在发生激进的变化。首先，我们有CPU，它们主要通过增加并行单元的数量来提高处理能力，而不是像过去那样单纯提高速度。计算机还可以配备图形处理单元（GPU），这些单元最初是为了图形处理而开发的，但现在也可以用于通用计算。实际上，许多高效的AI算法实现都是针对GPU进行的。不幸的是，至少从我们的角度来看，GPU的架构与CPU完全不同：它们由成千上万的计算单元组成，这些单元预计将在所有单元上执行相同的“简单”计算。内存模型也完全不同。这些差异意味着编程GPU需要与编程CPU截然不同的方法。
- en: To understand how we can use GPUs for data processing, we need to understand
    their original purpose and architectural implications. GPUs, as the name indicates,
    were developed to help with graphics processing. Some of the most computationally
    demanding applications are actually games. Games, and graphic applications in
    general, are constantly updating millions of pixels on the screen. The hardware
    architecture devised to solve this problem has many small processing cores. Its
    quite easy for a GPU to have thousands of cores, while a CPU typically has less
    than 10\. GPU cores are substantially simpler and mostly run the same code on
    each core. They are thus very good for running a massive number of similar tasks,
    like updating pixels.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解我们如何使用GPU进行数据处理，我们需要了解它们的原始用途和架构影响。正如其名所示，GPU是为了帮助图形处理而开发的。一些计算需求最密集的应用实际上是游戏。游戏以及一般的图形应用，都在不断更新屏幕上的数百万个像素。为了解决这个问题而设计的硬件架构拥有许多小的处理核心。GPU拥有数千个核心是很常见的，而CPU通常只有不到10个。GPU核心相对简单，每个核心上运行的是相同的代码。因此，它们非常适合运行大量的相似任务，比如更新像素。
- en: Given the sheer amount of processing power in GPUs, there was an attempt to
    try to use that power for other tasks with the appearance of general-purpose computing
    on graphics processing units (GPGPU). Because of the way GPU architectures are
    organized, they are mostly applicable to tasks that are massively parallel in
    nature. It turns out that many modern AI algorithms, like ones based on neural
    networks, tend to be massively parallel. So there was a natural fit between the
    two.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GPU中处理能力的巨大，人们试图利用这种能力来完成其他任务，这看起来是通用计算在图形处理单元（GPGPU）上的出现。由于GPU架构的组织方式，它们主要适用于本质上是大规模并行的任务。结果发现，许多现代AI算法，如基于神经网络的算法，往往具有大规模并行性。因此，两者之间有一个自然契合点。
- en: Unfortunately, the difference between CPUs and GPUs is not only in the number
    of cores and their complexity. GPU memory, especially on the most computationally
    powerful, is separated from the main memory. Thus, there is also the problem of
    transferring data between the main memory and GPU memory. So we have two massive
    problems to consider when targeting GPUs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，CPU和GPU之间的区别不仅仅是核心数量和它们的复杂性。GPU内存，尤其是在计算能力最强的GPU上，与主内存是分开的。因此，也存在在主内存和GPU内存之间传输数据的问题。所以，当我们针对GPU时，我们必须考虑两个巨大的问题。
- en: For reasons that will become clear in chapter 9, programming GPUs with Python
    is substantially more difficult and less practical than targeting CPUs. Nonetheless,
    there is still more than enough scope to make use of GPUs from Python.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在第9章中将会变得清晰的原因，使用Python编程GPU比针对CPU要困难得多，也不太实用。尽管如此，仍然有足够的空间从Python中利用GPU。
- en: 'While less fashionable than the advances in GPUs, monumental changes have also
    come to how CPUs can be programmed. And, unlike GPUs, we can easily use most of
    these CPU changes in Python. CPU performance increases are being delivered differently
    by manufacturers than in the past. Their solution, driven by the laws of physics,
    is to build in more parallel processing, not more speed. Moore’s law is sometimes
    stated as the doubling of speed every 24 months, but that is actually not the
    correct definition: it relates instead to the transistor density doubling every
    two years. The linear relationship between increased speed and transistor density
    broke more than a decade ago, and speed has mostly plateaued since then. Given
    that data has continued to grow along with algorithm complexity, we are in a pernicious
    situation. The first line of solutions coming from CPU manufacturers is allowing
    more parallelism: more CPUs per computer, more cores per CPU, and simultaneous
    multithreading. Processors are not really accelerating sequential computations
    anymore but allowing for more concurrent execution. This concurrent execution
    requires a paradigm shift in how we program computers. Before, the speed of a
    program would “magically” increase when you changed CPUs. Now, increasing speed
    depends on the programmer being aware of the shift in the underlying architecture
    to the parallel programming paradigm.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然不如GPU的进步那么时尚，但CPU编程的方式也经历了巨大的变化。而且，与GPU不同，我们可以很容易地在Python中使用这些CPU的大部分变化。制造商现在提供CPU性能提升的方式与过去不同。受物理定律驱动的解决方案是内置更多的并行处理，而不是更多的速度。摩尔定律有时被表述为每24个月速度翻倍，但实际上这并不是正确的定义：它实际上与每两年晶体管密度翻倍相关。速度和晶体管密度之间的线性关系在十多年前就已经破裂，速度自那时以来基本上已经达到了平台期。鉴于数据量和算法复杂性的持续增长，我们陷入了危险的境地。CPU制造商提出的第一个解决方案是允许更多的并行性：每台计算机更多的CPU，每个CPU更多的核心，以及同时多线程。处理器不再真正加速顺序计算，而是允许更多的并发执行。这种并发执行需要我们在编程计算机时进行范式转变。以前，当你更换CPU时，程序的速度会“神奇地”增加。现在，提高速度取决于程序员是否意识到底层架构向并行编程范式的转变。
- en: 'There are many changes in the way we program modern CPUs, and as you will see
    in chapter 6, some of them are so counterintuitive they are worth keeping an eye
    on from the onset. For example, while CPU speeds have leveled in recent years,
    CPUs are still orders of magnitude faster than RAM. If CPU caches did not exist,
    then CPUs would be mostly idle, as they would spend most of the time waiting for
    RAM. This means that sometimes it is *faster* to work with compressed data, including
    the cost of decompression, than with raw data. Why? If you can put a compressed
    block on the CPU cache, then those cycles that otherwise would be idle waiting
    for RAM access could be used to decompress the data with CPU cycles to spare that
    could be used for computation! A similar argument could work for compressed file
    systems: they sometimes can be faster than raw file systems. There are direct
    applications of this in the Python world; for example, by changing a simple Boolean
    flag regarding the choice of the internal representation of NumPy arrays, you
    take advantage of cache locality problems and speed up your NumPy processing considerably.
    We have some access times and sizes for different kinds of memory in table 1.1,
    including CPU cache, RAM, local disk, and remote storage. The key point here is
    not the precise numbers but the orders of magnitude in difference in both size
    and access time.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在编程现代 CPU 方式上有很多变化，正如你将在第 6 章中看到的，其中一些变化非常不符合直觉，值得从一开始就密切关注。例如，尽管近年来 CPU 速度已经趋于平稳，但
    CPU 仍然比 RAM 快几个数量级。如果没有 CPU 缓存，那么 CPU 将大部分时间都处于空闲状态，因为它们会花费大部分时间等待 RAM。这意味着有时与压缩数据（包括解压缩成本）相比，使用原始数据**更快**。为什么？如果你可以将压缩块放在
    CPU 缓存中，那么那些原本会空闲等待 RAM 访问的周期就可以用来使用 CPU 周期解压缩数据，而此时还有富余的 CPU 周期可以用于计算！类似的论点也可以适用于压缩文件系统：它们有时可能比原始文件系统更快。在
    Python 世界中有直接的应用；例如，通过更改一个简单的布尔标志，关于 NumPy 数组内部表示的选择，你可以利用缓存局部性问题，显著加快你的 NumPy
    处理速度。表 1.1 包含了不同类型内存的访问时间和大小，包括 CPU 缓存、RAM、本地磁盘和远程存储。这里的关键点不是精确的数字，而是大小和访问时间上的数量级差异。
- en: Table 1.1 Memory hierarchy with sizes and access times for a hypothetical, but
    realistic modern desktop
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.1 假设但现实的现代桌面内存层次结构，包括大小和访问时间
- en: '| Type | Size | Access time |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 大小 | 访问时间 |'
- en: '| **CPU** |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| **CPU** |'
- en: '| L1 cache | 256 KB | 2 ns |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| L1 缓存 | 256 KB | 2 ns |'
- en: '| L2 cache | 1 MB | 5 ns |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| L2 缓存 | 1 MB | 5 ns |'
- en: '| L3 cache | 6 MB | 30 ns |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| L3 缓存 | 6 MB | 30 ns |'
- en: '| **RAM** |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| **RAM** |'
- en: '| DIMM | 8 GB | 100 ns |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| DIMM | 8 GB | 100 ns |'
- en: '| **Secondary storage** |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| **二级存储** |'
- en: '| SSD | 256 GB | 50 µs |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| SSD | 256 GB | 50 µs |'
- en: '| HDD | 2 TB | 5 ms |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| HDD | 2 TB | 5 ms |'
- en: '| **Tertiary storage** |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| **三级存储** |'
- en: '| NAS - Network Access Server | 100 TB | Network dependent |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| NAS - 网络访问服务器 | 100 TB | 网络依赖 |'
- en: '| Cloud proprietary | 1 PB | Provider dependent |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 云专有 | 1 PB | 提供商依赖 |'
- en: Table 1.1 includes tertiary storage, which happens *outside* the computer. There
    have also been changes there, which we will address in the next section.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.1 包含了三级存储，它发生在计算机**外部**。那里也发生了变化，我们将在下一节中讨论。
- en: 1.2.2 Changes in the network
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 网络的变化
- en: In high-performance computing settings, we use the network as both a way to
    add more storage and, especially, to increase computing power. While we would
    like to solve our problems using a single computer, sometimes relying on a compute
    cluster is inevitable. Optimizing for the architectures with multiple computers—be
    it in the cloud or on-premises—will be a part of our journey to high performance.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在高性能计算环境中，我们使用网络作为添加更多存储的方式，特别是增加计算能力的方式。虽然我们希望使用单台计算机解决问题，但有时依赖计算集群是不可避免的。针对具有多台计算机的架构进行优化——无论是在云端还是在本地——将是我们追求高性能旅程的一部分。
- en: 'Using many computers and external storage brings a whole new class of problems
    related to distributed computing: network topologies, sharing data across machines,
    and managing processes running across the network. There are many examples. For
    instance, what is the price of using REST APIs on services that require high performance
    and low latency? How can we deal with the penalties of having remote filesystems;
    can we mitigate those?'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用许多计算机和外部存储会带来与分布式计算相关的一系列新问题：网络拓扑、跨机器共享数据以及管理跨网络的进程。有许多例子。例如，在需要高性能和低延迟的服务上使用
    REST API 的成本是多少？我们如何处理远程文件系统的惩罚；能否减轻这些惩罚？
- en: We will be trying to optimize our usage of the network stack and for that, we
    will have to be aware of it at all levels shown in figure 1.3\. Outside the network,
    we have our code and Python libraries, which make choices about the layers below.
    At the top of the network stack, a typical choice for data transport is HTTPS
    with a payload based on JSON.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试优化我们对网络堆栈的使用，为此，我们必须了解图1.3中显示的所有级别。在网络之外，我们有我们的代码和Python库，它们对下面的层做出选择。在网络堆栈的顶部，数据传输的一个典型选择是基于JSON的有效负载的HTTPS。
- en: 'While this is a perfectly reasonable choice for many applications, there are
    more performant alternatives for cases where network speed and lag matter. For
    example, a binary payload might be more efficient than JSON. Also, HTTP might
    be replaced by a direct TCP socket. But there are more radical alternatives like
    replacing the TCP transport layer: most internet application protocols use TCP,
    although there are a few exceptions like DNS and DHCP, which are both UDP based.
    The TCP protocol is highly reliable, but there is a performance penalty to be
    paid for that reliability. There will be times when the smaller overhead of UDP
    will be a more efficient alternative and the extra reliability is not needed.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这对于许多应用来说是一个完全合理的选择，但在网络速度和延迟很重要的案例中，有更高效的替代方案。例如，二进制有效负载可能比JSON更有效。此外，HTTP可能被直接TCP套接字所取代。但还有更激进的替代方案，比如替换TCP传输层：大多数互联网应用协议都使用TCP，尽管有一些例外，如DNS和DHCP，它们都是基于UDP的。TCP协议非常可靠，但为了这种可靠性，必须付出性能的代价。有时，UDP较小的开销将是一个更有效的替代方案，而额外的可靠性是不需要的。
- en: '![](../Images/CH01_F03_Antao.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F03_Antao.png)'
- en: Figure 1.3 API calls via the network stack. Understanding the alternatives available
    for network communication can dramatically increase the speed of internet-based
    applications.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 通过网络堆栈的API调用。了解网络通信的可用的替代方案可以显著提高基于互联网的应用程序的速度。
- en: Below transport protocols, we have the internet protocol (IP) and the physical
    infrastructure. The physical infrastructure can be important when we design our
    solutions. For example, if we have a very reliable local network, then UDP, which
    can lose data, will be more of an alternative than it would be in an unreliable
    network.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在传输协议之下，我们有互联网协议（IP）和物理基础设施。在设计我们的解决方案时，物理基础设施可能很重要。例如，如果我们有一个非常可靠的本地网络，那么可以丢失数据的UDP将比在不可靠的网络中更有可能成为一个替代方案。
- en: 1.2.3 The cloud
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 云
- en: In the past, most data processing implementations were made to function on a
    single computer or on an on-premises cluster maintained by the same organization
    that runs the workload. Currently, cloud-based infrastructure where all servers
    are “virtual” and maintained by an external entity, is becoming increasingly common.
    Sometimes, as with so-called serverless computing, we do not even deal with servers
    directly.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，大多数数据处理实现都是为了在单个计算机或由运行工作负载的同一家组织维护的本地集群上运行。目前，所有服务器都是“虚拟”的，并由外部实体维护的基于云的基础设施越来越普遍。有时，就像所谓的无服务器计算一样，我们甚至不直接处理服务器。
- en: The cloud is not just about adding more computers or network storage. It’s also
    about a set of proprietary extensions on how to deal with storage and compute
    resources, and those extensions have consequences in terms of performance. Furthermore,
    virtual computers can throw a wrench in some CPU optimizations. For example, in
    a bare metal machine, you can devise a solution that is considerate of cache locality
    problems, but in a virtual machine, you have no way of knowing whether your cache
    is being preempted by another virtual machine being executed concurrently. How
    do we keep our algorithms efficient in such an environment? Also, the cost model
    of cloud computing is completely different—time is literally money—and, as such,
    efficient solutions become even more important.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 云不仅仅是增加更多的计算机或网络存储。它还涉及一系列关于如何处理存储和计算资源的专有扩展，这些扩展在性能方面有影响。此外，虚拟计算机可能会对某些CPU优化造成干扰。例如，在裸机机器上，你可以设计出考虑缓存局部性问题的解决方案，但在虚拟机上，你无法知道你的缓存是否被同时执行的其他虚拟机抢占。我们如何在这样的环境中保持算法的高效性？此外，云计算的成本模型完全不同——时间就是金钱——因此，高效的解决方案变得更加重要。
- en: Many of the compute and storage solutions in the cloud are also proprietary
    and have very specific APIs and behaviors. Using such proprietary solutions also
    has consequences on performance that should be considered. As such, and while
    most problems pertaining to traditional clusters are also applicable to the cloud,
    sometimes there will be specific problems that will need to be dealt with separately.
    Now that we have a view of the architectural possibilities and limitations that
    will shape our applications, let’s turn to the advantages and disadvantages of
    Python for high-performance computing.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 云端中的许多计算和存储解决方案也是专有的，并且具有非常具体的 API 和行为。使用这些专有解决方案也会对性能产生后果，这是需要考虑的。因此，尽管大多数与传统集群相关的问题也适用于云端，但有时会有一些特定的问题需要单独处理。现在我们已经了解了将塑造我们应用程序的架构可能性和限制，让我们转向
    Python 在高性能计算中的优缺点。
- en: 1.3 Working with Python’s limitations
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 与 Python 的限制共事
- en: Python is widely used in modern data process applications. As with any language,
    it has its advantages and its drawbacks. There are great reasons to use Python,
    but here we are more concerned with dealing with Python’s limitations for high-performance
    data processing.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Python 在现代数据处理应用中被广泛使用。与任何语言一样，它都有其优点和缺点。使用 Python 有很多很好的理由，但在这里我们更关注处理 Python
    在高性能数据处理中的限制。
- en: 'Let’s not sugarcoat reality: Python is spectacularly ill-equipped to handle
    high-performance computing. If performance and parallelism were the only consideration,
    nobody would use Python. Python has an amazing ecology of libraries for doing
    data analysis, great documentation, and a wonderfully supportive community. That
    is why we use it, not computational performance.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们不要美化现实：Python 在处理高性能计算方面明显准备不足。如果性能和并行性是唯一考虑因素，没有人会使用 Python。Python 有一个惊人的用于数据分析的库生态系统、优秀的文档和令人惊叹的支持社区。这就是我们使用它的原因，而不是计算性能。
- en: There is a saying that goes something like this “There are no slow languages,
    only slow language implementations.” I hope you allow me to disagree. It is not
    fair to ask the implementors of a dynamic, high-level language like Python (or,
    say, JavaScript for that matter) to compete in terms of speed with lower-level
    languages like C, C++, Rust, or Go.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种说法，大意是这样的：“没有慢的语言，只有慢的语言实现。”我希望你能允许我不同意这一点。要求像 Python（或者，比如说，JavaScript）这样的动态、高级语言的实现者与像
    C、C++、Rust 或 Go 这样的低级语言在速度上进行竞争是不公平的。
- en: 'Features like dynamic typing and garbage collection will pay a price in terms
    of performance. And that is fine: there are many cases where programmer time is
    more valuable than compute time. But let’s not bury our heads in the sand: more
    declarative and dynamic languages will pay a price in computation and memory.
    It’s a balance.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 像动态类型和垃圾回收这样的特性会在性能上付出代价。这是可以接受的：在许多情况下，程序员的时间比计算时间更有价值。但让我们不要逃避现实：更声明性和动态的语言在计算和内存上也会付出代价。这是一个平衡。
- en: 'That being said, this is no excuse for poorly performant language implementations.
    In this regard, how does CPython, the flagship Python implementation that you
    are probably using, fare? A complete analysis would not be easy, but you can do
    a simple exercise: write a matrix multiplication function and time it. Then, for
    example, run it with another Python implementation like PyPy. Then convert your
    code to JavaScript (a fair comparison as the language is also dynamic; an unfair
    comparison would be would C) and time it again.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，这并不是表现不佳的语言实现的借口。在这方面，作为你可能正在使用的旗舰 Python 实现，CPython 的表现如何？进行完整分析并不容易，但你可以做一个简单的练习：编写一个矩阵乘法函数并计时。然后，例如，用另一个
    Python 实现（如 PyPy）运行它。然后，将你的代码转换为 JavaScript（由于语言也是动态的，这是一个公平的比较；不公平的比较将是 C 语言）并再次计时。
- en: 'Spoiler alert: CPython will not fare well. We have a language that is naturally
    slow and a flagship implementation that does not seem to have speed as its main
    consideration. Now, the good news is that most of these problems can be overcome.
    Many people have produced applications and libraries that will mitigate most performance
    problems. You can still write code in Python that will perform very well with
    a small memory footprint. You just have to write code while attending to Python’s
    warts.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 提前剧透：CPython 的表现不会太好。我们有一个自然速度较慢的语言，以及一个似乎没有将速度作为主要考虑的旗舰实现。现在，好消息是大多数这些问题都可以克服。许多人已经开发出了应用程序和库，可以缓解大多数性能问题。你仍然可以用
    Python 编写代码，使其具有非常小的内存占用并表现出色。你只需在编写代码时注意 Python 的瑕疵即可。
- en: Note In most of the book, when we talk about Python, we are referring to the
    CPython implementation. All exceptions to this rule will be explicitly called
    out.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在本书的大部分内容中，当我们提到Python时，我们指的是CPython实现。所有违反此规则的例外都将明确指出。
- en: 'Given Python’s limitations regarding performance, optimizing our Python code
    sometimes will not be enough. In those cases, we will end up rewriting that part
    in a lower-level language or, at the very least, annotating our code so that it
    gets rewritten in a lower-level language by some code conversion tool. The part
    of the code that we will need to rewrite is normally very small, so we are decidedly
    *not* ditching Python. When we do this last stage of optimization, probably more
    than 90% of the code will still be Python. This is what many core scientific libraries
    like NumPy, scikit-learn, and SciPy actually do: their most computationally demanding
    parts are usually implemented in C or Fortran.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Python在性能方面的限制，有时仅仅优化我们的Python代码可能是不够的。在这种情况下，我们最终将不得不用更低级的语言重写那部分代码，或者至少用注释来标记我们的代码，以便通过某些代码转换工具将其重写为更低级的语言。我们需要重写的代码部分通常非常小，所以我们绝对不是要放弃Python。当我们进行这个最后的优化阶段时，可能超过90%的代码仍然是Python。这正是许多核心科学库（如NumPy、scikit-learn和SciPy）实际的做法：它们最计算密集的部分通常是用C或Fortran实现的。
- en: 1.3.1 The Global Interpreter Lock
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 全局解释器锁
- en: In discussions about Python’s performance, its GIL, or Global Interpreter Lock,
    inevitably comes up. What exactly is the GIL? While Python has the concept of
    threads, CPython has a GIL, which only allows a single thread to execute at a
    point in time. Even on a multicore processor, you only get a single thread executing
    at a single point in time.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在关于Python性能的讨论中，其GIL（全局解释器锁）不可避免地会被提及。GIL究竟是什么？虽然Python有线程的概念，但CPython有一个GIL，它只允许在某个时间点只有一个线程执行。即使在多核处理器上，你也只能得到一个在某个时间点执行的线程。
- en: Other implementations of Python, like Jython and IronPython, do not have a GIL
    and can use all cores in modern multiprocessors. But CPython is still the reference
    implementation for which all the main libraries are developed. In addition, Jython
    and IronPython are, respectively, JVM and .NET dependent. As such, CPython, given
    its massive library base, ends up being the default Python implementation. We
    will briefly discuss other implementations in the book, most notably PyPy, but
    in practice, CPython is queen.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Python的其他实现，如Jython和IronPython，没有GIL，并且可以使用现代多处理器的所有核心。但CPython仍然是所有主要库开发的基础实现。此外，Jython和IronPython分别依赖于JVM和.NET。因此，鉴于其庞大的库基础，CPython最终成为默认的Python实现。我们将在书中简要讨论其他实现，特别是PyPy，但在实践中，CPython是女王。
- en: To understand how to work around the GIL, it is useful to remember the difference
    between *concurrency* and *parallelism*. Concurrency, you may recall, is when
    a certain number of tasks can *overlap* in time, though they may not be *running*
    at the same time. They can, for example, interleave. Parallelism is when tasks
    are executed at the same time. So, in Python, concurrency is possible, but parallelism
    is not . . . or is it?
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何绕过GIL，记住并发和并行之间的区别是有用的。你可能记得，并发是指一定数量的任务可以在时间上重叠，尽管它们可能不是同时运行的。例如，它们可以交错。并行是指任务同时执行。因此，在Python中，并发是可能的，但并行性不是……或者它是吗？
- en: Concurrency without parallelism is still quite useful. The best example of this
    comes from the JavaScript world and Node.JS, which is overwhelmingly used to implement
    the backend of web servers. In many server-side web tasks, most of the time is
    actually spent waiting for IO; that is a great time for a thread to *voluntarily*
    relinquish control so that other threads can continue with computation. Modern
    Python has similar asynchronous facilities, and we will be discussing them.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 没有并行性的并发仍然非常有用。最好的例子来自JavaScript世界和Node.JS，它被广泛用于实现Web服务器的后端。在许多服务器端Web任务中，大部分时间实际上都花在等待I/O上；这是一个线程自愿放弃控制权以便其他线程可以继续计算的好时机。现代Python有类似的异步功能，我们将会讨论它们。
- en: 'But back to the main problem: does the GIL impose a serious performance penalty?
    In most cases, the answer is a surprising no. There are two main reasons for this:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 但回到主要问题：GIL是否会对性能造成严重的惩罚？在大多数情况下，答案是令人惊讶的“不”。这有两个主要原因：
- en: Most of the high-performance code, those tight inner loops, will probably have
    to be written in a lower-level language as we’ve discussed.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数高性能代码，那些紧密的内循环，可能需要用更低级的语言来编写，正如我们之前讨论的那样。
- en: Python provides mechanisms for lower-level languages to release the GIL.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 为底层语言提供了释放 GIL 的机制。
- en: This means that when you enter a part of the code rewritten in a lower-level
    language, you can instruct Python to continue with other Python threads in parallel
    with your low-level implementation. You should only release the GIL if that is
    safe—for example, if you do not write to objects that may be in use by other threads.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着当您进入用底层语言重写的代码部分时，您可以指示 Python 与您的底层实现并行继续其他 Python 线程。您只有在安全的情况下才应该释放 GIL——例如，如果您不写入可能被其他线程使用的对象。
- en: Also, *multiprocessing* (i.e., running multiple processes simultaneously) is
    not affected by the GIL, which only affects threads, so there is still plenty
    of space to deploy parallel solutions even in pure Python.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，*多进程*（即同时运行多个进程）不受 GIL 的影响，GIL 只影响线程，因此在纯 Python 中仍有大量空间来部署并行解决方案。
- en: So, in theory, the GIL is a concern with regard to performance, but in practice,
    it rarely is the source of problems that cannot be overcome. We will dive deep
    into this subject in chapter 3\.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从理论上讲，GIL 是与性能相关的问题，但在实践中，它很少是造成无法克服问题的根源。我们将在第 3 章深入探讨这个主题。
- en: 1.4 A summary of the solutions
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 解决方案的总结
- en: This book is about getting high performance from Python, but code does not run
    in a vacuum. You can only devise efficient code if you take into consideration
    the broader perspective of data and algorithm demands as well as computing architectures.
    While it’s impossible to go into every architectural and algorithmic detail in
    one book, my aim with these is to help you understand the implications of CPU
    design, GPUs, storage alternatives, network protocols and cloud architectures,
    and other system considerations (figure 1.4) so you can make sound decisions for
    improving the performance of your Python code. This book should equip you to assess
    the advantages and drawbacks of your computing architecture, whether it is a single
    computer, a GPU-enabled computer, a cluster, or a cloud environment, and implement
    the necessary changes to take full advantage of it.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是关于从 Python 中获得高性能的，但代码不是在真空中运行的。只有当您考虑数据、算法需求以及计算架构的更广泛视角时，您才能设计出高效的代码。虽然在一本书中不可能详细讨论每个架构和算法细节，但我的目标是帮助您理解
    CPU 设计、GPU、存储替代方案、网络协议和云架构以及其他系统考虑（图 1.4）的影响，以便您可以为提高 Python 代码的性能做出明智的决定。本书应该使您能够评估您的计算架构的优点和缺点，无论它是单台计算机、带
    GPU 的计算机、集群还是云环境，并实施必要的更改以充分利用它。
- en: '![](../Images/CH01_F04_Antao.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F04_Antao.png)'
- en: Figure 1.4 Underlying hardware architectures must be taken into account when
    choosing high-performance coding solutions.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 在选择高性能编码解决方案时必须考虑底层硬件架构。
- en: The goal of this book is to introduce you to a range of solutions and show you
    how and where each one is best applied, so you can select and implement the most
    efficient solution for your particular set of resources, goals, and problems.
    We will spend considerable time working through examples so you can see for yourself
    the effects, both positive and negative, of these approaches. There is no mandate
    to apply all the approaches, nor is there a prescribed order in which to apply
    them. Each approach has its greater or lesser gains in performance and efficiency,
    along with its tradeoffs. If you understand what you have at your disposal in
    your system and in available strategies for improving aspects of that system,
    you can pick and choose where to spend your time and resources. To help you make
    sense of the approaches, table 1.2 presents a summary of the techniques presented
    in the book and the component or domain of the system development process that
    they target.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是向您介绍一系列解决方案，并展示每个解决方案的最佳应用方式和地点，以便您可以根据自己的资源、目标和问题选择并实施最有效的解决方案。我们将花费大量时间通过实例来让您亲自看到这些方法的效果，无论是积极的还是消极的。没有强制要求应用所有方法，也没有规定应用它们的顺序。每种方法在性能和效率方面都有其更大的或较小的收益，以及其权衡。如果您了解您系统中的资源和可用于改进该系统方面的策略，您就可以选择在哪里花费时间和资源。为了帮助您理解这些方法，表
    1.2 总结了本书中介绍的技术及其针对的系统开发过程组件或领域。
- en: Table 1.2 Purpose of each chapter in the book
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1.2 书中每章的目的
- en: '| Domain | Application | Chapter |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 领域 | 应用 | 章节 |'
- en: '| Getting the most of your Python interpreter | Python interpreter | 2 Extracting
    maximum performance from built-in features |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 充分利用您的 Python 解释器 | Python 解释器 | 2 从内置功能中提取最大性能 |'
- en: '| Understanding Python’s internal functionality to extract the most computing
    power from your computer | Python interpreter | 3 Concurrency, parallelism, and
    asynchronous processing |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 理解 Python 的内部功能以从您的计算机中提取最大计算能力 | Python 解释器 | 3 并发、并行和异步处理 |'
- en: '| Extracting the most performance from the fundamental library in data science
    | Python libraries | 4 High-performance NumPy |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 从数据科学的基本库中提取最大性能 | Python 库 | 4 高性能 NumPy |'
- en: '| Exploring the performance of low-level languages when Python is not enough
    | Python libraries | 5 Re-implementing critical code with Cython |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 探索当 Python 不够用时低级语言的性能 | Python 库 | 5 使用 Cython 重新实现关键代码 |'
- en: '| Understanding the implications of hardware on computational performance |
    Hardware | 6 Memory hierarchy, storage, and networking |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 理解硬件对计算性能的影响 | 硬件 | 6 内存层次结构、存储和网络 |'
- en: '| Extracting the most performance from tabular data | Python libraries | 7
    High-performance pandas and Apache Arrow |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 从表格数据中提取最大性能 | Python 库 | 7 高性能 pandas 和 Apache Arrow |'
- en: '| Increasing storage efficiency by using modern Python persistence libraries
    | Python libraries | 8 Storing big data |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 通过使用现代 Python 持久化库提高存储效率 | Python 库 | 8 存储大数据 |'
- en: '| Understanding the importance and using GPU computing from Python | Hardware
    | 9 Data analysis using GPU computing |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 从 Python 理解 GPU 计算的重要性及其使用 | 硬件 | 9 使用 GPU 计算进行数据分析 |'
- en: '| Dealing with applications that require more than a single computer to process
    | Python libraries and hardware | 10 Analyzing big data with Dask |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 处理需要多台计算机处理的应用程序 | Python 库和硬件 | 10 使用 Dask 分析大数据 |'
- en: 'There’s a lot in that table, so let me emphasize the practical applications
    of the major focus areas. After reading this book, you will be able to look at
    native Python code and understand the performance implications of built-in data
    structures and algorithms. You will be able to detect and replace inefficient
    structures with more appropriate solutions: for example, replace lists with sets
    where a search is being repeated on a constant list or use nonobject arrays instead
    of lists of objects for speed. You will also be able to take an existing algorithm
    that is nonperformant and (1) profile the code to find the pieces that are causing
    performance problems and (2) determine the best way to optimize those pieces of
    code.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 那张表格中有很多内容，所以让我强调一下主要关注领域的实际应用。阅读这本书后，您将能够查看原生 Python 代码并理解内置数据结构和算法的性能影响。您将能够检测并替换效率低下的结构，以更合适的解决方案：例如，在重复搜索固定列表时用集合替换列表，或者为了速度使用非对象数组而不是对象列表。您还将能够对现有性能不佳的算法进行以下操作：（1）分析代码以找到导致性能问题的部分，以及（2）确定优化这些代码片段的最佳方式。
- en: As stated, the book addresses the widely used Python ecology of libraries for
    data processing and analysis (such as pandas and NumPy) with the aim of improving
    how we use them. On the computing side, this is a lot of material, so we will
    not discuss very high-level libraries. For example, we will not talk about optimizing
    the usage of, say, TensorFlow, but we will discuss techniques to make the underlying
    algorithms more efficient.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 正如所述，本书旨在通过改进我们使用它们的方式，解决广泛使用的 Python 数据处理和分析库生态系统（如 pandas 和 NumPy）。在计算方面，这是一大块材料，所以我们不会讨论非常高级的库。例如，我们不会讨论优化
    TensorFlow 的使用，但我们会讨论使底层算法更有效的技术。
- en: With regard to data storage and transformation, you will be able to look at
    a data source and understand its drawbacks for efficient processing and storage.
    Then you will be able to transform the data in a way that all required information
    is still maintained but access patterns to the data will be substantially more
    efficient. Finally, you will also learn about Dask, a Python-based framework that
    allows you to develop parallel solutions that can scale from a single machine
    to very large clusters of computers or cloud computing solutions.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数据存储和转换，您将能够查看数据源并理解其在高效处理和存储方面的不足。然后您将能够以这种方式转换数据，即所有所需信息仍然保持不变，但数据的访问模式将大大提高效率。最后，您还将了解
    Dask，这是一个基于 Python 的框架，允许您开发可以从小型单机扩展到非常大的计算机集群或云计算解决方案的并行解决方案。
- en: This is not a recipe book so much as an introduction to ways of thinking about
    optimization and areas to investigate for performance gains. As such, the approaches
    discussed should, for the most part, weather changes in hardware, software, networking,
    systems, and even data itself. Although not every technique will be profitable,
    or even usable in every situation, reading the book from start to finish is the
    surest way to understand your options, open up your thinking, and perhaps come
    up with some solutions of your own. Once you have exposed yourself to the range
    of possibilities, you can use the book as a reference and cherry-pick the techniques
    you want to implement.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这与其说是一本食谱书，不如说是一本关于优化思考方式以及性能提升研究领域的介绍。因此，讨论的方法应该大部分能够适应硬件、软件、网络、系统甚至数据本身的变更。尽管并非每种技术都会在每个情况下都盈利，甚至可用，但从头到尾阅读这本书是理解您选项、开阔思路并可能提出一些自己解决方案的最可靠方式。一旦您接触到了各种可能性，您就可以将这本书作为参考，挑选您想要实施的技术。
- en: 'Note Setting up the software: Before you continue, be sure to check appendix
    A for a description of options to set up your environment so you can run the code
    samples with each exercise. The code listings themselves are located at [https://github.com/tiagoantao/python-performance](https://github.com/tiagoantao/python-performance).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 注意软件设置：在继续之前，请务必查看附录A，了解设置环境选项的描述，这样您就可以在每个练习中运行代码示例。代码列表本身位于[https://github.com/tiagoantao/python-performance](https://github.com/tiagoantao/python-performance)。
- en: Summary
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Yes, the cliche is true: there is a lot of data, and we have to increase the
    efficiency in processing it if we want to stand a chance to extract the most value
    from it.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是的，这个陈词滥调是正确的：数据量很大，如果我们想从数据中提取最大价值，就必须提高处理数据的效率。
- en: Increased algorithm complexity adds an extra strain to the computation cost,
    and we will have to find ways to mitigate the computational effect.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法复杂性的增加给计算成本带来了额外的压力，我们将不得不找到减轻计算影响的方法。
- en: 'There is a large heterogeneity of computing architectures: the network now
    also includes cloud-based approaches. Inside our computers, there are now powerful
    GPUs whose computing paradigm is substantially different from CPUs. We need to
    be able to harness those.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算架构存在很大的异质性：网络现在也包括基于云的方法。在我们的计算机内部，现在有强大的GPU，其计算范式与CPU大不相同。我们需要能够利用这些资源。
- en: Python is an amazing language for data analysis surrounded by a complete ecology
    of data processing libraries and frameworks. But it also suffers from serious
    problems on the performance side. We will need to be able to circumvent those
    problems to process lots of data with sophisticated algorithms.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python是一种用于数据分析的出色语言，周围环绕着完整的数据处理库和框架生态系统。但它在性能方面也存在严重问题。我们需要能够绕过这些问题，以便使用复杂的算法处理大量数据。
- en: While some of the problems that we will be dealing with can be hard, they are
    mostly solvable. The goal of this book is to introduce you to plenty of alternative
    solutions and teach you how and where each one is best applied, so you can choose
    and implement the most efficient solution for any problem you encounter.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然我们将要处理的一些问题可能很困难，但它们大多是可解决的。本书的目标是向您介绍大量的替代解决方案，并教会您如何以及在哪里最好地应用每个解决方案，以便您可以选择并实施您遇到任何问题的最有效解决方案。
- en: '* * *'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ¹  *Sharding* is the partitioning of data so that parts of it reside in different
    servers.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ¹  *分片*是指将数据分割，使其部分存储在不同的服务器上。
