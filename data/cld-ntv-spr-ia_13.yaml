- en: 10 Event-driven applications and functions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 个事件驱动应用程序和函数
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Understanding event-driven architectures
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解事件驱动架构
- en: Using RabbitMQ as a message broker
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 RabbitMQ 作为消息代理
- en: Implementing functions with Spring Cloud Function
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Cloud Function 实现函数
- en: Processing events with Spring Cloud Stream
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Cloud Stream 处理事件
- en: Producing and consuming events with Spring Cloud Stream
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Cloud Stream 产生和消费事件
- en: In the previous chapters, we worked on a system of distributed applications
    that interact according to the request/response pattern, a type of synchronous
    communication. You saw how to design the interaction both in an imperative and
    a reactive way. In the first case, processing threads would block, waiting for
    a response from an I/O operation. In the second case, threads would not wait.
    A response would be processed by any available thread asynchronously once it was
    received.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们构建了一个分布式应用程序系统，该系统根据请求/响应模式进行交互，这是一种同步通信类型。你看到了如何以命令式和反应式的方式设计交互。在前一种情况下，处理线程会阻塞，等待
    I/O 操作的响应。在后一种情况下，线程不会等待。一旦收到响应，任何可用的线程都会异步处理响应。
- en: Even if the reactive programming paradigm lets you subscribe to producers and
    process the incoming data asynchronously, the interaction between the two applications
    is synchronous. The first application (the client) sends a request to the second
    one (the server) and expects a response to arrive in a short time. How the client
    processes the response (imperative or reactive) is an implementation detail that
    doesn’t affect the interaction itself. No matter what, a response is expected
    to arrive.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 即使反应式编程范式允许你订阅生产者并异步处理传入的数据，但两个应用程序之间的交互仍然是同步的。第一个应用程序（客户端）向第二个应用程序（服务器）发送请求，并期望在短时间内收到响应。客户端如何处理响应（命令式或反应式）是实现的细节，不影响交互本身。无论如何，都期望收到响应。
- en: Cloud native applications should be loosely coupled. The microservices expert
    Sam Newman identifies a few different types of coupling, including *implementation*,
    *deployment*, and *temporal* coupling.[¹](#pgfId-1011903) Let’s consider the Polar
    Bookshop system we’ve been working on so far.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生应用程序应该是松耦合的。微服务专家山姆·纽曼（Sam Newman）识别了几种不同的耦合类型，包括*实现*、*部署*和*时间*耦合。[¹](#pgfId-1011903)
    让我们考虑我们迄今为止一直在工作的 Polar Bookshop 系统。
- en: We can change the implementation of any of the applications without having to
    change the others. For example, we can re-implement Catalog Service using the
    reactive paradigm without affecting Order Service. Using a service interface like
    a REST API, we hide the implementation details, improving loose coupling. All
    the applications can be deployed independently. They’re not coupled, reducing
    risks and increasing agility.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以更改任何应用程序的实现，而无需更改其他应用程序。例如，我们可以使用反应式范式重新实现目录服务（Catalog Service），而不会影响订单服务（Order
    Service）。使用像 REST API 这样的服务接口，我们可以隐藏实现细节，提高松耦合。所有应用程序都可以独立部署。它们不是耦合的，这降低了风险并提高了敏捷性。
- en: 'However, if you think about how the applications we built so far interact,
    you’ll notice that they need other components of the system to be available. Order
    Service needs Catalog Service to ensure that a user can order a book successfully.
    We know that failures happen all the time, so we adopted several strategies to
    ensure resilience even in the face of adversity, or at least ensuring a graceful
    degradation of functionality. That’s a consequence of *temporal coupling*: Order
    Service and Catalog Service need to be available at the same time to fulfill the
    system requirements.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你思考一下我们迄今为止构建的应用程序之间的交互，你会注意到它们需要系统中的其他组件可用。订单服务（Order Service）需要目录服务（Catalog
    Service）以确保用户可以成功订购书籍。我们知道失败是经常发生的，因此我们采用了几种策略来确保即使在逆境中也能保证弹性，或者至少确保功能的优雅降级。这是*时间耦合*的后果：订单服务（Order
    Service）和目录服务（Catalog Service）需要同时可用，以满足系统要求。
- en: Event-driven architectures describe distributed systems that interact by *producing*
    and *consuming* events. The interaction is asynchronous, solving the problem of
    temporal coupling. This chapter will cover the basics of event-driven architectures
    and event brokers. You’ll then learn how to implement business logic using the
    functional programming paradigm and Spring Cloud Function. Finally, you’ll use
    Spring Cloud Stream to expose the functions as message channels via RabbitMQ,
    building event-driven applications through the publisher/subscriber (pub/sub)
    model.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 事件驱动架构描述了通过 *产生* 和 *消费* 事件进行交互的分布式系统。这种交互是异步的，解决了时间耦合问题。本章将涵盖事件驱动架构和事件代理的基础知识。然后，你将学习如何使用函数式编程范式和Spring
    Cloud Function实现业务逻辑。最后，你将使用Spring Cloud Stream通过RabbitMQ将函数作为消息通道暴露出来，通过发布/订阅（pub/sub）模型构建事件驱动应用程序。
- en: Note The source code for the examples in this chapter is available in the Chapter10/10-begin,
    Chapter10/10-intermediate, and Chapter10/10-end folders, containing the initial,
    intermediate, and final state of the project ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章示例的源代码可在Chapter10/10-begin、Chapter10/10-intermediate和Chapter10/10-end文件夹中找到，包含项目的初始、中间和最终状态（[https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action)）。
- en: 10.1 Event-driven architectures
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 事件驱动架构
- en: An event is an occurrence. It’s something relevant that happened in a system,
    like a state change, and there can be many sources of events. This chapter will
    focus on applications, but events can very well be happening in IoT devices, sensors,
    or networks. When an event occurs, interested parties can be notified. Event notification
    is usually done through messages, which are data representations of events.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 事件是一个发生的事件。它是在系统中发生的相关事情，比如状态变化，并且可能有多个事件来源。本章将专注于应用程序，但事件也可能在物联网设备、传感器或网络中发生。当事件发生时，感兴趣的各方可以被通知。事件通知通常通过消息来完成，这些消息是事件的数据表示。
- en: In an event-driven architecture, we identify *event producers* and *event consumers*.
    A producer is a component that detects the event and sends a notification. A consumer
    is a component that is notified when a specific event occurs. Producers and consumers
    don’t know each other and work independently. A producer sends an event notification
    by publishing a message to a channel operated by an event broker that’s responsible
    for collecting and routing messages to consumers. A consumer is notified by the
    broker when an event occurs and can act upon it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件驱动架构中，我们识别 *事件生产者* 和 *事件消费者*。生产者是一个检测事件并发送通知的组件。消费者是一个在特定事件发生时被通知的组件。生产者和消费者彼此不了解，独立工作。生产者通过向由事件代理操作的消息通道发布消息来发送事件通知，该代理负责收集和路由消息到消费者。当事件发生时，代理会通知消费者，并可以对其采取行动。
- en: Producers and consumers have minimal coupling when using a broker that takes
    the processing and distribution of events on itself. In particular, they are temporally
    decoupled, because the interaction is asynchronous. Consumers can fetch and process
    messages at any time without affecting the producers whatsoever.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用自行处理和分发事件的代理时，生产者和消费者之间的耦合最小。特别是，它们在时间上是解耦的，因为交互是异步的。消费者可以在任何时间获取和处理消息，而不会对生产者产生任何影响。
- en: In this section, you’ll learn the fundamentals of event-driven models and how
    they can help build more resilient and loosely coupled applications in the cloud.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习事件驱动模型的基本知识以及它们如何帮助在云中构建更健壮和松散耦合的应用程序。
- en: 10.1.1 Understanding the event-driven models
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 理解事件驱动模型
- en: 'Event-driven architectures can be based on two main models:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 事件驱动架构可以基于两种主要模型：
- en: '*Publisher/subscriber (pub/sub)*—This model is based on subscriptions. Producers
    publish events that are sent to all subscribers to be consumed. Events cannot
    be replayed after being received, so new consumers joining will not be able to
    get the past events.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*发布/订阅（pub/sub）*—此模型基于订阅。生产者发布事件，这些事件被发送到所有订阅者进行消费。事件在接收后不能重放，因此新加入的消费者将无法获取过去的事件。'
- en: '*Event streaming*—In this model, events are written to a log. Producers publish
    events as they occur, and they are all stored in an ordered fashion. Consumers
    don’t subscribe to them, but they can read from any part of the event stream.
    In this model, events can be replayed. Clients can join at any time and receive
    all the past events.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*事件流*—在这个模型中，事件被写入日志。生产者按事件发生时发布事件，并且它们以有序的方式存储。消费者不需要订阅它们，但可以从事件流的任何部分读取。在这个模型中，事件可以被重放。客户端可以随时加入并接收所有过去的事件。'
- en: In a basic scenario, consumers receive and process events as they arrive. For
    specific use cases like pattern matching, they can also process a series of events
    over a time window. In the event streaming model, consumers have the additional
    possibility of processing event streams. At the core of event-driven architectures
    are platforms that can process and route events. For example, RabbitMQ is a common
    choice to use with the pub/sub model. Apache Kafka is a powerful platform for
    event stream processing.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在基本场景中，消费者接收并处理到达的事件。对于像模式匹配这样的特定用例，他们也可以在时间窗口内处理一系列事件。在事件流模型中，消费者有额外的可能性处理事件流。事件驱动架构的核心是能够处理和路由事件的平台。例如，RabbitMQ是常用于pub/sub模型的常见选择。Apache
    Kafka是事件流处理的一个强大平台。
- en: The event streaming model is fascinating and growing in popularity, thanks to
    the many technologies developed in the last few years, allowing you to build real-time
    data pipelines. It’s a complex model, though, that deserves its own book to be
    taught effectively. In this chapter, I will cover the pub/sub model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 事件流模型非常吸引人，并且越来越受欢迎，这得益于过去几年中开发出的许多技术，允许你构建实时数据管道。然而，这是一个复杂的模型，它值得有一本自己的书来有效地教授。在本章中，我将介绍pub/sub模型。
- en: Before we analyze this model in more detail, I’ll define some requirements for
    the Polar Bookshop system, and we’ll use them as a means to explore event-driven
    architectures with the pub/sub model.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们更详细地分析这个模型之前，我将为Polar书店系统定义一些需求，并将它们用作探索使用pub/sub模型的事件驱动架构的手段。
- en: 10.1.2 Using the pub/sub model
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.2 使用pub/sub模型
- en: 'In the Polar Bookshop system, we need to implement an event-driven solution
    to allow different applications to communicate with each other asynchronously
    while reducing their coupling. These are the requirements:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在Polar书店系统中，我们需要实现一个事件驱动解决方案，以允许不同的应用程序以异步方式相互通信，同时减少它们的耦合。以下是这些需求：
- en: 'When an order is accepted:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当一个订单被接受时：
- en: Order Service should notify interested consumers of the event.
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订单服务应该通知对事件感兴趣的消费者。
- en: Dispatcher Service should execute some logic to dispatch the order.
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分发服务应该执行一些逻辑来分发订单。
- en: 'When an order is dispatched:'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当一个订单被分发时：
- en: Dispatcher Service should notify consumers interested in such an event.
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分发服务应该通知对这类事件感兴趣的消费者。
- en: Order Service should update the order status in the database.
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订单服务应该更新数据库中的订单状态。
- en: If you paid attention, you probably noticed that the requirements don’t specify
    which applications Order Service should notify upon order creation. In our example,
    only the new Dispatcher Service application will be interested in those events.
    Still, more applications might subscribe to the order creation events in the future.
    The beauty of this design is that you can evolve a software system and add more
    applications without affecting the existing ones at all. For example, you could
    add a Mail Service that sends an email to users whenever an order they made has
    been accepted, and Order Service wouldn’t even be aware of it.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你注意到了，你可能已经注意到需求没有指定在订单创建时Order Service应该通知哪些应用程序。在我们的例子中，只有新的分发服务应用程序会对这些事件感兴趣。然而，未来可能有更多的应用程序订阅订单创建事件。这种设计的美丽之处在于，你可以演进软件系统并添加更多应用程序，而不会对现有的应用程序造成任何影响。例如，你可以添加一个邮件服务，当用户创建的订单被接受时，它会向用户发送电子邮件，而订单服务甚至不会意识到这一点。
- en: This type of interaction should be asynchronous and can be modeled with the
    pub/sub model. Figure 10.1 illustrates the interaction and describes three flows
    for accepting, dispatching, and updating an order. They are temporally decoupled
    and executed asynchronously. You will probably notice that the operations for
    persisting data into a database and for producing events have the same numbered
    step. That’s because they belong to the same unit of work (a *transaction*), as
    I’ll explain later in the chapter.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这种交互应该是异步的，可以用 pub/sub 模型来建模。图 10.1 展示了这种交互，并描述了接受、调度和更新订单的三个流程。它们在时间上是解耦的，并且异步执行。你可能注意到将数据持久化到数据库的操作和产生事件的操作具有相同的编号步骤。这是因为它们属于同一个工作单元（一个
    *事务*），正如我将在本章后面解释的那样。
- en: '![10-01](../Images/10-01.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![10-01](../Images/10-01.png)'
- en: Figure 10.1 Order Service and Dispatcher Service communicate asynchronously
    and indirectly by producing and consuming events that are collected and distributed
    by an event broker (RabbitMQ).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 订单服务和调度服务通过产生和消费由事件代理（RabbitMQ）收集和分发的事件，以异步和间接的方式通信。
- en: In the rest of the chapter, you’ll learn a few technologies and patterns you
    can use to implement this event-driven design for Polar Bookshop. RabbitMQ will
    be the event-processing platform responsible for collecting, routing, and distributing
    messages to consumers. Figure 10.2 highlights the event-driven part of the Polar
    Bookshop system after we introduce the Dispatcher Service application and RabbitMQ.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，你将学习一些可以用于实现 Polar Bookshop 事件驱动设计的技伎和模式。RabbitMQ 将作为负责收集、路由和向消费者分发消息的事件处理平台。图
    10.2 在我们介绍了 Dispatcher Service 应用和 RabbitMQ 之后，突出了 Polar Bookshop 系统的事件驱动部分。
- en: '![10-02](../Images/10-02.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![10-02](../Images/10-02.png)'
- en: Figure 10.2 In the Polar Bookshop system, Order Service and Dispatcher Service
    communicate asynchronously based on events distributed by RabbitMQ.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 在 Polar Bookshop 系统中，订单服务和调度服务基于 RabbitMQ 分发的事件进行异步通信。
- en: The following section will introduce the basic concepts of RabbitMQ, its protocol,
    and how to run it in your local environment.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分将介绍 RabbitMQ 的基本概念、其协议以及如何在本地环境中运行它。
- en: 10.2 Message brokers with RabbitMQ
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 基于 RabbitMQ 的消息代理
- en: 'A messaging system requires two main things: a message broker and a protocol.
    The Advanced Message Queuing Protocol (AMQP) ensures interoperability across platforms
    and reliable message delivery. It has become widely used in modern architectures,
    and it’s a good fit in the cloud, where we need resilience, loose coupling, and
    scalability. RabbitMQ is a popular open source message broker that relies on AMQP
    and provides flexible asynchronous messaging, distributed deployment, and monitoring.
    Recent RabbitMQ versions have also introduced event streaming features.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个消息系统需要两个主要的东西：一个消息代理和一个协议。高级消息队列协议 (AMQP) 确保了跨平台的互操作性和可靠的消息传递。它已成为现代架构中广泛使用的一种协议，非常适合云环境，在那里我们需要弹性、松散耦合和可伸缩性。RabbitMQ
    是一个流行的开源消息代理，它依赖于 AMQP，并提供灵活的异步消息、分布式部署和监控。最近的 RabbitMQ 版本还引入了事件流功能。
- en: Spring provides broad support for the most-used messaging solutions. The Spring
    Framework itself has built-in support for the Java Message Service (JMS) API.
    The Spring AMQP project ([https://spring.io/projects/spring-amqp](https://spring.io/projects/spring-amqp))
    adds support for this messaging protocol and provides integration with RabbitMQ.
    Apache Kafka is another technology that has become increasingly used in the last
    few years, such as to implement the event sourcing pattern or real-time stream
    processing. The Spring for Apache Kafka project ([https://spring.io/projects/spring-kafka](https://spring.io/projects/spring-kafka))
    provides that integration.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Spring 为最常用的消息解决方案提供了广泛的支持。Spring 框架本身内置了对 Java 消息服务 (JMS) API 的支持。Spring AMQP
    项目 ([https://spring.io/projects/spring-amqp](https://spring.io/projects/spring-amqp))
    为此消息协议添加了支持，并提供了与 RabbitMQ 的集成。Apache Kafka 是另一种在最近几年越来越受欢迎的技术，例如用于实现事件源模式或实时流处理。Spring
    for Apache Kafka 项目 ([https://spring.io/projects/spring-kafka](https://spring.io/projects/spring-kafka))
    提供了这种集成。
- en: This section will cover the fundamental aspects of the AMQP protocol and RabbitMQ,
    which is the message broker we’ll use to implement messaging in the Polar Bookshop
    system. On the application side, we’ll use Spring Cloud Stream, which offers convenient
    and robust integration with RabbitMQ by relying on the Spring AMQP project.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将涵盖AMQP协议和RabbitMQ的基本方面，我们将使用它来实现Polar Bookshop系统的消息传递。在应用层面，我们将使用Spring Cloud
    Stream，它通过依赖Spring AMQP项目提供了与RabbitMQ的便捷且健壮的集成。
- en: 10.2.1 Understanding AMQP for messaging systems
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 理解AMQP消息系统
- en: 'When using an AMQP-based solution like RabbitMQ, the actors involved in the
    interaction can be categorized as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用基于AMQP的解决方案如RabbitMQ时，参与交互的参与者可以分为以下类别：
- en: '*Producer*—The entity sending messages (publisher)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*生产者*——发送消息的实体（发布者）'
- en: '*Consumer*—The entity receiving messages (subscriber)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*消费者*——接收消息的实体（订阅者）'
- en: '*Message broker*—The middleware accepting messages from producers and routing
    them to consumers'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*消息代理*——接受生产者消息并将它们路由到消费者的中间件'
- en: Figure 10.3 illustrates the interaction between the actors. From the protocol
    point of view, we can also say that the broker is the *server*, while producers
    and consumers are the *clients*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3说明了参与者之间的交互。从协议的角度来看，我们也可以说代理是*服务器*，而生产者和消费者是*客户端*。
- en: '![10-03](../Images/10-03.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![10-03](../Images/10-03.png)'
- en: Figure 10.3 In AMQP, a broker accepts messages from producers and routes them
    to consumers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 在AMQP中，代理接受生产者的消息并将它们路由到消费者。
- en: Note RabbitMQ was initially developed to support AMQP, but it also supports
    other protocols, including STOMP, MQTT, and even WebSockets for delivering messages
    over HTTP. Since version 3.9, it also supports event streaming.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，RabbitMQ最初是为了支持AMQP而开发的，但它也支持其他协议，包括STOMP、MQTT，甚至WebSocket，用于通过HTTP传递消息。从版本3.9开始，它还支持事件流。
- en: The AMQP messaging model is based on *exchanges* and *queues*, as illustrated
    in figure 10.4\. Producers send messages to an exchange. RabbitMQ computes which
    queues should receive a copy of the message according to a given routing rule.
    Consumers read messages from a queue.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: AMQP消息模型基于*交换*和*队列*，如图10.4所示。生产者向交换发送消息。RabbitMQ根据给定的路由规则计算哪些队列应该接收消息的副本。消费者从队列中读取消息。
- en: '![10-04](../Images/10-04.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![10-04](../Images/10-04.png)'
- en: Figure 10.4 Producers publish messages to an exchange. Consumers subscribe to
    queues. Exchanges route messages to queues according to a routing algorithm.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 生产者向交换发布消息。消费者订阅队列。交换根据路由算法将消息路由到队列。
- en: The protocol establishes that a message comprises attributes and a payload,
    as shown in figure 10.5\. AMQP defines some attributes, but you can add your own
    to pass the information that’s needed to route the message correctly. The payload
    must be of a binary type and has no constraints besides that.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 该协议规定消息由属性和有效负载组成，如图10.5所示。AMQP定义了一些属性，但你可以添加自己的属性来传递正确路由消息所需的信息。有效负载必须是二进制类型，除此之外没有约束。
- en: '![10-05](../Images/10-05.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![10-05](../Images/10-05.png)'
- en: Figure 10.5 An AMQP Message is composed of attributes and a payload.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 AMQP消息由属性和有效负载组成。
- en: Now that you know the basics of AMQP, let’s get RabbitMQ up and running.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了AMQP的基础知识，让我们启动RabbitMQ。
- en: 10.2.2 Using RabbitMQ for publish/subscribe communications
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 使用RabbitMQ进行发布/订阅通信
- en: RabbitMQ, on top of AMQP, provides a simple yet effective solution for implementing
    a publish/subscribe interaction that is precisely the one we want to establish
    between Order Service and Dispatcher Service. Besides the functionality itself,
    it’s essential to look for those properties I addressed in previous chapters for
    cloud systems and data services, including resilience, high availability, and
    data replication. RabbitMQ offers all of that. For example, it provides delivery
    acknowledgment, clustering, monitoring, queue durability, and replication. Furthermore,
    several cloud providers offer integrations with managed RabbitMQ services.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ在AMQP之上提供了一个简单而有效的解决方案，用于实现我们希望在订单服务和调度服务之间建立的发布/订阅交互。除了功能本身之外，寻找我在前几章中提到的云系统和数据服务的属性也很重要，包括弹性、高可用性和数据复制。RabbitMQ提供了所有这些。例如，它提供交付确认、集群、监控、队列持久性和复制。此外，几个云服务提供商还提供与托管RabbitMQ服务的集成。
- en: For now, you’ll run RabbitMQ as a container on your local machine. First, make
    sure your Docker Engine is running. Then open the docker-compose.yml file located
    in your polar-deployment repository.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，你将在本地机器上以容器形式运行 RabbitMQ。首先，确保你的 Docker 引擎正在运行。然后打开位于你的 polar-deployment
    仓库中的 docker-compose.yml 文件。
- en: Note If you haven’t followed along with the examples, you can use Chapter10/10-begin/polar-deployment/docker/docker-compose.yml
    from the source code accompanying the book as a starting point.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果你没有跟随示例进行操作，你可以使用书中附带的源代码中的 Chapter10/10-begin/polar-deployment/docker/docker-compose.yml
    作为起点。
- en: In your docker-compose.yml file, add a new service definition using the RabbitMQ
    official image (including the management plugin) and expose it through port 5672
    (for AMQP) and 15672 (for the management console). The RabbitMQ management plugin
    is convenient for inspecting exchanges and queues from a browser-based UI.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的 docker-compose.yml 文件中，添加一个新的服务定义，使用 RabbitMQ 官方镜像（包括管理插件），并通过端口 5672（用于
    AMQP）和 15672（用于管理控制台）暴露它。RabbitMQ 管理插件通过基于浏览器的用户界面检查交换和队列非常方便。
- en: Listing 10.1 Defining a container for RabbitMQ
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.1 定义 RabbitMQ 容器
- en: '[PRE0]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ The official RabbitMQ image with the management plugin enabled
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 启用管理插件的官方 RabbitMQ 镜像
- en: ❷ The port where RabbitMQ listens for AMQP requests
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ RabbitMQ 监听 AMQP 请求的端口
- en: ❸ The port that exposes the management GUI
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 暴露管理 GUI 的端口
- en: ❹ Configuration file mounted as a volume
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 作为卷挂载的配置文件
- en: The configuration is based on a file mounted as a volume, similar to how we
    configured PostgreSQL. Create a docker/rabbitmq folder within your polar-deployment
    repository, and add a new rabbitmq.conf file to configure the default account.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 配置基于一个作为卷挂载的文件，类似于我们配置 PostgreSQL 的方式。在你的 polar-deployment 仓库中创建一个 docker/rabbitmq
    文件夹，并添加一个新的 rabbitmq.conf 文件来配置默认账户。
- en: Listing 10.2 Configuring RabbitMQ default account
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.2 配置 RabbitMQ 默认账户
- en: '[PRE1]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, open a Terminal window, navigate to the folder where your docker-compose.yml
    file is located, and run the following command to start RabbitMQ:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，打开一个终端窗口，导航到你的 docker-compose.yml 文件所在的文件夹，并运行以下命令以启动 RabbitMQ：
- en: '[PRE2]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Finally, open a browser window and navigate to http://localhost:15672 to access
    the RabbitMQ management console. Log in using the credentials we defined in the
    configuration file (user/password) and have a look around. In the following sections
    you’ll be able to follow the message flows between Order Service and Dispatcher
    Service in the Exchanges and Queues areas of the management console.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，打开一个浏览器窗口，导航到 http://localhost:15672 以访问 RabbitMQ 管理控制台。使用我们在配置文件中定义的凭据（用户/密码）登录，并四处看看。在接下来的章节中，你将能够在管理控制台的交换和队列区域中跟踪订单服务与调度服务之间的消息流。
- en: 'When you’re done exploring the RabbitMQ management console, you can shut it
    down as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成对 RabbitMQ 管理控制台的探索后，你可以按照以下方式关闭它：
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Spring Cloud Stream helps integrate applications with event brokers like RabbitMQ
    seamlessly. But before we get to it, we need to define the logic that will process
    messages. In the next section, you’ll learn about Spring Cloud Function and how
    to implement the business logic of the new order flow in terms of suppliers, functions,
    and consumers.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream 帮助应用程序与像 RabbitMQ 这样的事件代理无缝集成。但在我们深入之前，我们需要定义将处理消息的逻辑。在下一节中，你将了解
    Spring Cloud Function 以及如何用供应商、函数和消费者来实现新订单流业务逻辑。
- en: 10.3 Functions with Spring Cloud Function
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 使用 Spring Cloud Function 的函数
- en: 'Oleg Zhurakousky, project lead for Spring Cloud Function and Spring Cloud Stream,
    often asks conference audiences this question: Is there any business feature that
    you cannot define in terms of suppliers, functions, and consumers? It’s an interesting
    and challenging question. Can you think of anything? Most software requirements
    can be expressed with functions.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Function 和 Spring Cloud Stream 的项目负责人 Oleg Zhurakousky 经常向会议听众提出这个问题：有没有任何业务功能是你不能用供应商、函数和消费者来定义的？这是一个有趣且具有挑战性的问题。你能想到什么吗？大多数软件需求都可以用函数来表示。
- en: Why use functions in the first place? They are a simple, uniform, and portable
    programming model that is a perfect fit for event-driven architectures, inherently
    based on these concepts.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么一开始就要使用函数呢？它们是一个简单、统一且可移植的编程模型，非常适合基于这些概念的事件驱动架构。
- en: 'Spring Cloud Function promotes the implementation of business logic via functions
    based on the standard interfaces introduced by Java 8: Supplier, Function, and
    Consumer.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Function 推崇通过基于 Java 8 引入的标准接口实现业务逻辑的函数化实现：Supplier、Function 和
    Consumer。
- en: '*Supplier*—A supplier is a function with only output, no input. It’s also known
    as a *producer*, *publisher*, or *source*.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*供应商*—供应商是一个只有输出没有输入的函数。它也被称为*生产者*、*发布者*或*源*。'
- en: '*Function*—A function has both input and output. It’s also known as a *processor*.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*函数*—函数既有输入也有输出。它也被称为*处理器*。'
- en: '*Consumer*—A consumer is a function with input but no output. It’s also known
    as a *subscriber* or *sink*.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*消费者*—消费者是一个有输入但没有输出的函数。它也被称为*订阅者*或*汇*。'
- en: In this section, you’ll learn how Spring Cloud Function works and how to implement
    business logic via functions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将了解Spring Cloud Function是如何工作的，以及如何通过函数实现业务逻辑。
- en: 10.3.1 Using the functional paradigm in Spring Cloud Function
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.1 在Spring Cloud Function中使用函数范式
- en: Let’s get started with functions by considering the business requirements I
    listed earlier for the Dispatcher Service application. Whenever an order is accepted,
    Dispatcher Service should be responsible for packing and labeling the order, and
    for notifying interested parties (in this case, the Order Service) once the order
    has been dispatched. For simplicity, let’s assume that both the *pack* and *label*
    actions are performed by the application itself, and we’ll consider how to implement
    the business logic via functions before even thinking about frameworks.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从考虑Dispatcher Service应用程序之前列出的业务需求开始，了解函数。每当接受订单时，Dispatcher Service应负责打包和标记订单，并在订单派发后通知相关方（在这种情况下，是Order
    Service）。为了简单起见，让我们假设*打包*和*标记*动作都由应用程序本身执行，我们将在考虑框架之前先考虑如何通过函数实现业务逻辑。
- en: 'The two actions to be performed as part of dispatching an order could be represented
    as functions:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 作为派发订单的一部分要执行的两个动作可以表示为函数：
- en: The *pack* function takes the identifier of an accepted order as input, packs
    the order (in the example, the processing is represented by a log message), and
    returns the order identifier as output, ready to be labeled.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*打包*函数以接受的订单标识符作为输入，打包订单（在示例中，处理通过日志消息表示），并返回订单标识符作为输出，准备进行标记。'
- en: The *label* function takes the identifier of a packed order as input, labels
    the order (in the example, the processing is represented by a log message), and
    returns the order identifier as output, completing the dispatch.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*标签*函数以打包订单的标识符作为输入，标记订单（在示例中，处理通过日志消息表示），并返回订单标识符作为输出，完成派发。'
- en: The composition of these two functions in sequence gives the full implementation
    of the business logic for Dispatcher Service, as shown in figure 10.6.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个函数按顺序组合给出了Dispatcher Service的业务逻辑的完整实现，如图10.6所示。
- en: '![10-06](../Images/10-06.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![10-06](../Images/10-06.png)'
- en: 'Figure 10.6 The business logic for Dispatcher Service is implemented as a composition
    of two functions: pack and label.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 Dispatcher Service的业务逻辑是通过两个函数：pack和label的组合来实现的。
- en: Let’s see how we can implement these functions and what Spring Cloud Function
    brings to the table.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何实现这些功能，以及Spring Cloud Function带来了哪些功能。
- en: Initializing a Spring Cloud Function project
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化Spring Cloud Function项目
- en: You can initialize the Dispatcher Service project from Spring Initializr ([https://start.spring.io](https://start.spring.io))
    and store the result in a new dispatcher-service Git repository. The parameters
    for the initialization are shown in figure 10.7.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从Spring Initializr ([https://start.spring.io](https://start.spring.io))初始化Dispatcher
    Service项目，并将结果存储在一个新的dispatcher-service Git仓库中。初始化的参数如图10.7所示。
- en: '![10-07](../Images/10-07.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![10-07](../Images/10-07.png)'
- en: Figure 10.7 The parameters for initializing the Dispatcher Service project
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 初始化Dispatcher Service项目的参数
- en: Tip In the begin folder for this chapter, you can find a curl command that you
    can run in a Terminal window. It downloads a zip file containing all the code
    you need to get started, without going through the manual generation on the Spring
    Initializr website.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：在本章的开始文件夹中，你可以找到一个可以在终端窗口中运行的curl命令。它下载一个包含所有启动所需代码的zip文件，无需通过Spring Initializr网站上的手动生成。
- en: 'The resulting dependencies section of the build.gradle file looks like this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: build.gradle文件的最终依赖项部分看起来像这样：
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The main dependencies are
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 主要依赖项包括
- en: '*Spring Boot* (org.springframework.boot:spring-boot-starter)—Provides basic
    Spring Boot libraries and auto-configuration.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Spring Boot* (org.springframework.boot:spring-boot-starter)—提供基本的Spring Boot库和自动配置功能。'
- en: '*Spring Cloud Function* (org.springframework.cloud:spring-cloud-function-context)—Provides
    the Spring Cloud Function libraries that promote and support business logic implementation
    via functions.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Spring Cloud Function* (org.springframework.cloud:spring-cloud-function-context)—提供促进和支持通过函数实现业务逻辑的
    Spring Cloud Function 库。'
- en: '*Spring Boot Test* (org.springframework.boot:spring-boot-starter-test)—Provides
    several libraries and utilities for testing applications, including Spring Test,
    JUnit, AssertJ, and Mockito. It’s automatically included in every Spring Boot
    project.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Spring Boot Test* (org.springframework.boot:spring-boot-starter-test)—提供了一些用于测试应用程序的库和实用工具，包括
    Spring Test、JUnit、AssertJ 和 Mockito。它自动包含在每一个 Spring Boot 项目中。'
- en: Next, rename the autogenerated application.properties file to application.yml,
    and configure the server port and application name. At present, the application
    doesn’t contain a web server. Nevertheless, we’ll configure the server port number
    because it will be used when we add monitoring capabilities to the application
    in chapter 13.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将自动生成的 application.properties 文件重命名为 application.yml，并配置服务器端口和应用程序名称。目前，应用程序不包含
    Web 服务器。尽管如此，我们仍将配置服务器端口号，因为当我们在第 13 章中向应用程序添加监控功能时，它将被使用。
- en: Listing 10.3 Configuring server and application name
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.3 配置服务器和应用程序名称
- en: '[PRE5]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ The port that will be used by the embedded web server
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将由嵌入式 Web 服务器使用的端口
- en: ❷ The name of the application
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 应用程序名称
- en: Next, let’s see how we can implement the business logic using functions.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何使用函数来实现业务逻辑。
- en: Implementing the business logic via functions
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 通过函数实现业务逻辑
- en: The business logic can be implemented in a standard way by using the Java Function
    interface. No Spring needed.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 业务逻辑可以通过使用 Java Function 接口以标准方式实现。不需要 Spring。
- en: Let’s first consider the *pack* function. The input of the function should provide
    the identifier of an order that has previously been accepted. We can model this
    data via a simple DTO.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先考虑 *pack* 函数。函数的输入应提供先前已接受的订单的标识符。我们可以通过简单的 DTO 来模拟这些数据。
- en: In the com.polarbookshop.dispatcherservice package, create an OrderAcceptedMessage
    record to hold the order identifier.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在 com.polarbookshop.dispatcherservice 包中，创建一个 OrderAcceptedMessage 记录来保存订单标识符。
- en: Listing 10.4 A DTO representing the event about orders being accepted
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.4 表示接受订单事件的 DTO
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ DTO containing the order identifier as a Long field
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 包含订单标识符作为 Long 字段的 DTO
- en: 'Note Modeling events is a fascinating topic that goes beyond Spring and would
    require a few chapters to cover properly. If you’d like to learn more about this
    subject, I recommend reading these articles by Martin Fowler: “Focusing on Events”
    ([https://martinfowler.com/eaaDev/EventNarrative.html](https://martinfowler.com/eaaDev/EventNarrative.html));
    “Domain Event” ([https://martinfowler.com/eaaDev/DomainEvent.html](https://martinfowler.com/eaaDev/DomainEvent.html));
    and “What do you mean by ‘Event-Driven’?” ([https://martinfowler.com/articles/
    201701-event-driven.html](https://martinfowler.com/articles/201701-event-driven.html)),
    all on his [MartinFowler.com](http://MartinFowler.com) blog.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，建模事件是一个有趣的话题，它超越了 Spring，需要几章才能正确地涵盖。如果您想了解更多关于这个主题的信息，我建议阅读 Martin Fowler
    在他的 [MartinFowler.com](http://MartinFowler.com) 博客上的这些文章：“关注事件” ([https://martinfowler.com/eaaDev/EventNarrative.html](https://martinfowler.com/eaaDev/EventNarrative.html))；“领域事件”
    ([https://martinfowler.com/eaaDev/DomainEvent.html](https://martinfowler.com/eaaDev/DomainEvent.html))；“你说的‘事件驱动’是什么意思？”
    ([https://martinfowler.com/articles/201701-event-driven.html](https://martinfowler.com/articles/201701-event-driven.html))。
- en: The output of the function can be the simple identifier of the packed order
    represented as a Long object.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 函数的输出可以是表示为 Long 对象的打包订单的简单标识符。
- en: Now that input and output are clear, it’s time to define the function. Create
    a new DispatchingFunctions class, and add a pack() method to implement order packing
    as a function.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在输入和输出都明确了，是时候定义函数了。创建一个新的 DispatchingFunctions 类，并添加一个 pack() 方法来实现订单打包作为函数。
- en: Listing 10.5 Implementing the “pack” action as a function
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.5 将“pack”操作作为函数实现
- en: '[PRE7]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Function implementing the order-packing business logic
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 实现订单打包业务逻辑的函数
- en: ❷ It takes an OrderAcceptedMessage object as input.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 它接受一个 OrderAcceptedMessage 对象作为输入。
- en: ❸ Returns an order identifier (Long) as output
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 返回一个订单标识符（Long）
- en: 'You can see how there’s only standard Java code in this listing. I strive to
    provide real-world examples in this book, so you might wonder what’s happening
    here. In this case, I decided to focus on the essential aspects of using the functional
    programming paradigm in the context of an event-driven application. Inside the
    function, you can add any processing logic you like. What matters here is the
    contract provided by the function, its signature: inputs and outputs. After defining
    that, you’re free to implement the function as needed. I could have provided a
    more real-world implementation of this function, but it would have added nothing
    valuable considering the goal of this chapter. It doesn’t even have to be Spring-based
    code. And in this example, it’s not: it’s plain Java code.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到这个列表中只有标准的 Java 代码。我努力在这个书中提供真实世界的例子，所以您可能会想知道这里发生了什么。在这种情况下，我决定专注于在事件驱动应用程序的上下文中使用函数式编程范式的基本方面。在函数内部，您可以添加任何喜欢的处理逻辑。这里重要的是函数提供的契约，其签名：输入和输出。在定义了这些之后，您可以自由地按需实现函数。我本可以提供这个函数的更真实世界的实现，但考虑到本章的目标，这并不会增加任何有价值的见解。甚至它不必是基于
    Spring 的代码。在这个例子中，它不是：它是纯 Java 代码。
- en: Spring Cloud Function is capable of managing functions defined in different
    ways, as long as they adhere to the standard Java interfaces Function, Supplier,
    and Consumer. You can make Spring Cloud Function aware of your functions by registering
    them as beans. Go ahead and do that for the pack() function by annotating the
    DispatchingFunctions class as @Configuration and the method as @Bean.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Function 能够管理以不同方式定义的函数，只要它们遵循标准的 Java 接口 Function、Supplier 和 Consumer。您可以通过将函数注册为
    bean 来让 Spring Cloud Function 了解您的函数。现在就为 pack() 函数做这件事，通过将 DispatchingFunctions
    类标注为 @Configuration 和方法标注为 @Bean。
- en: Listing 10.6 Configuring the function as a bean
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.6 将函数配置为 bean
- en: '[PRE8]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Functions are defined in a configuration class.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 函数在配置类中定义。
- en: ❷ Functions defined as beans can be discovered and managed by Spring Cloud Function.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 定义为 bean 的函数可以被 Spring Cloud Function 发现和管理。
- en: As you’ll see later, functions registered as beans are enhanced with extra features
    by the Spring Cloud Function framework. The beauty of this is that the business
    logic itself is not aware of the surrounding framework. You can evolve it independently
    and test it without being concerned about framework-related issues.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您稍后看到的，注册为 bean 的函数通过 Spring Cloud Function 框架增强了额外的功能。这种美妙的特性在于业务逻辑本身并不了解周围的框架。您可以独立地对其进行演进和测试，而无需担心框架相关的问题。
- en: Using imperative and reactive functions
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令式和反应式函数
- en: Spring Cloud Function supports both imperative and reactive code, so you’re
    free to implement functions using reactive APIs like Mono and Flux. You can also
    mix and match. For the sake of the example, let’s implement the *label* function
    using Project Reactor. The input of the function will be the identifier of an
    order that has been packed, represented as a Long object. The output of the function
    will be the identifier of the order that has been labeled, resulting in the dispatching
    process being complete. We can model such data via a simple DTO, just like we
    did for OrderAcceptedMessage.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Function 支持命令式和反应式代码，因此您可以自由地使用像 Mono 和 Flux 这样的反应式 API 来实现函数。您也可以混合使用。为了举例，让我们使用
    Project Reactor 实现标签 *label* 函数。函数的输入将是已打包订单的标识符，表示为一个 Long 对象。函数的输出将是已标签化的订单标识符，从而完成派送过程。我们可以通过一个简单的
    DTO 来模拟此类数据，就像我们对 OrderAcceptedMessage 所做的那样。
- en: In the com.polarbookshop.dispatcherservice package, create an OrderDispatchedMessage
    record to hold the identifier for a dispatched order.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在 com.polarbookshop.dispatcherservice 包中，创建一个 OrderDispatchedMessage 记录来保存已派送订单的标识符。
- en: Listing 10.7 A DTO representing the event about orders being dispatched
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.7 表示订单派送事件的 DTO
- en: '[PRE9]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ DTO containing the order identifier as a Long field
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 包含订单标识符作为 Long 字段的 DTO
- en: Now that the input and output are clear, it’s time to define the function. Open
    the DispatchingFunctions class and add a label() method to implement the order
    labeling as a function. Since we want it to be reactive, both input and output
    are wrapped in a Flux publisher.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 既然输入和输出都明确了，是时候定义函数了。打开 DispatchingFunctions 类，并添加一个 label() 方法来实现订单标签化作为函数。由于我们希望它是反应式的，输入和输出都被包装在一个
    Flux 发布者中。
- en: Listing 10.8 Implementing the “label” action as a function
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.8 将“标签”操作实现为函数
- en: '[PRE10]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Function implementing the order-labeling business logic
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 实现订单标签化业务逻辑的函数
- en: ❷ It takes an order identifier (Long) as input.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 它接受一个订单标识符（Long）作为输入。
- en: ❸ Returns an OrderDispatchedMessage as output
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 返回 OrderDispatchedMessage 作为输出
- en: We have just implemented both functions, so let’s see how we can combine and
    use them.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经实现了这两个函数，现在让我们看看我们如何将它们组合并使用。
- en: '10.3.2 Composing and integrating functions: REST, serverless, data streams'
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.2 组合和集成函数：REST、无服务器、数据流
- en: 'The implementation of the business logic for Dispatcher Service is almost done.
    We still need a way to compose the two functions. Based upon our requirements,
    dispatching an order consists of two steps to be executed in sequence: pack()
    first and label() after.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Dispatcher Service 的业务逻辑实现几乎完成。我们仍然需要一种方法来组合这两个函数。根据我们的要求，派发订单包括两个按顺序执行的步骤：首先打包（pack()），然后贴标签（label()）。
- en: Java provides features to compose Function objects in sequence using the andThen()
    or compose() operators. The problem is that you can use them only when the output
    type of the first function is the same as the second function’s input. Spring
    Cloud Function provides a solution to that problem and lets you compose functions
    seamlessly through transparent type conversion, even between imperative and reactive
    functions like those we defined earlier.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Java 提供了使用 andThen() 或 compose() 操作符按顺序组合 Function 对象的功能。问题是您只能在第一个函数的输出类型与第二个函数的输入类型相同时使用它们。Spring
    Cloud Function 提供了解决这个问题的方案，并允许您通过透明类型转换无缝地组合函数，即使在像我们之前定义的命令式和响应式函数之间也是如此。
- en: Composing functions with Spring Cloud is as simple as defining a property in
    your application.yml (or application.properties) file. Open the application.yml
    file in your Dispatcher Service project, and configure Spring Cloud Function to
    manage and compose the pack() and label() functions as follows.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Spring Cloud 组合函数就像在 application.yml（或 application.properties）文件中定义一个属性一样简单。在您的
    Dispatcher Service 项目中打开 application.yml 文件，并配置 Spring Cloud Function 以管理并组合 pack()
    和 label() 函数，如下所示。
- en: Listing 10.9 Declaring the functions managed by Spring Cloud
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.9 声明由 Spring Cloud 管理的函数
- en: '[PRE11]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Definition of the function managed by Spring Cloud Function
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Spring Cloud Function 管理的函数定义
- en: The spring.cloud.function.definition property lets you declare which functions
    you want Spring Cloud Function to manage and integrate, resulting in a specific
    data flow. In the previous section, we implemented the basic pack() and label()
    functions. Now we can instruct Spring Cloud Function to use them as building blocks
    and produce a new function that comes from the composition of those two.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: spring.cloud.function.definition 属性允许您声明您希望 Spring Cloud Function 管理和集成的函数，从而产生特定的数据流。在前一节中，我们实现了基本的
    pack() 和 label() 函数。现在我们可以指示 Spring Cloud Function 将它们用作构建块，并生成一个由这两个函数组合而成的新函数。
- en: In a serverless application like those meant to be deployed on a FaaS platform
    (such as AWS Lambda, Azure Functions, Google Cloud Functions, or Knative), you
    would usually have one function defined per application. The cloud function definition
    can be mapped one-to-one to a function declared in your application, or you can
    use the *pipe* (|) operator to compose functions together in a data flow. If you
    need to define multiple functions, you can use the semicolon (;) character as
    the separator instead of the pipe (|).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在像 AWS Lambda、Azure Functions、Google Cloud Functions 或 Knative 这样的无服务器应用程序中，您通常为每个应用程序定义一个函数。云函数定义可以一对一地映射到您的应用程序中声明的函数，或者您可以使用
    *pipe*（|）操作符在数据流中将函数组合在一起。如果您需要定义多个函数，可以使用分号（;）字符作为分隔符而不是管道（|）。
- en: To sum up, you only need to implement standard Java functions, and you can then
    configure Spring Cloud Function to use them as they are or after combining them.
    The framework will do the rest, including transparently converting input and output
    types to make the composition possible. Figure 10.8 illustrates the function composition.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，您只需要实现标准的 Java 函数，然后您可以配置 Spring Cloud Function 使用它们，或者在使用前将它们组合起来。框架将完成其余工作，包括透明地转换输入和输出类型，以便组合成为可能。图
    10.8 阐述了函数组合。
- en: '![10-08](../Images/10-08.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![10-08](../Images/10-08.png)'
- en: Figure 10.8 You can combine functions with different input and output types
    and mix imperative and reactive types as well. Spring Cloud Function will transparently
    handle any type conversion.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 您可以组合具有不同输入和输出类型的函数，并且可以混合命令式和响应式类型。Spring Cloud Function 将透明地处理任何类型转换。
- en: 'At this point you’re probably wondering how you can use these functions. That’s
    my favorite part. Once you define the functions, the framework can expose them
    in different ways depending on your needs. For example, Spring Cloud Function
    can automatically expose the functions defined in spring.cloud.function.definition
    as REST endpoints. Then you can directly package the application, deploy it on
    a FaaS platform like Knative, and voilà: you’ve got your first serverless Spring
    Boot application. That’s what we’ll do in chapter 16 when we build serverless
    applications. Or you can use one of the adapters provided by the framework to
    package the application and deploy it on AWS Lambda, Azure Functions, or Google
    Cloud Functions. Or you can combine it with Spring Cloud Stream and bind the function
    to message channels in an event broker like RabbitMQ or Kafka.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能想知道如何使用这些函数。那是我最喜欢的一部分。一旦你定义了函数，框架可以根据你的需求以不同的方式暴露它们。例如，Spring Cloud
    Function 可以自动将定义在 spring.cloud.function.definition 中的函数暴露为 REST 端点。然后你可以直接打包应用程序，部署到
    Knative 这样的 FaaS 平台，然后 voilà：你就得到了你的第一个无服务器 Spring Boot 应用程序。这就是我们在第 16 章构建无服务器应用程序时将要做的。或者，你可以使用框架提供的适配器之一来打包应用程序，并在
    AWS Lambda、Azure Functions 或 Google Cloud Functions 上部署它。或者，你可以将其与 Spring Cloud
    Stream 结合使用，并将函数绑定到事件代理（如 RabbitMQ 或 Kafka）中的消息通道。
- en: Before we explore the integration with RabbitMQ using Spring Cloud Stream, I
    want to show you how to test the functions and their composition in isolation.
    Once the business logic is implemented as functions and tested, we can be sure
    it will work the same way, whether it’s triggered by a REST endpoint or an event
    notification.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探索使用 Spring Cloud Stream 与 RabbitMQ 集成之前，我想向你展示如何单独测试函数及其组合。一旦业务逻辑被实现为函数并经过测试，我们可以确信它将以相同的方式工作，无论是通过
    REST 端点触发还是通过事件通知。
- en: 10.3.3 Writing integration tests with @FunctionalSpringBootTest
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.3 使用 @FunctionalSpringBootTest 编写集成测试
- en: Using the functional programming paradigm, we can implement business logic in
    standard Java and write unit tests with JUnit without being affected by the framework.
    At that level there is no Spring code, just plain Java. Once you’ve ensured that
    each function works, you’ll want to write some integration tests to verify your
    application’s overall behavior when your functions are processed by Spring Cloud
    Function and exposed the way you configured.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 使用函数式编程范式，我们可以在标准 Java 中实现业务逻辑，并使用 JUnit 编写单元测试，而不会受到框架的影响。在那个层面，没有 Spring 代码，只有纯
    Java。一旦你确保每个函数都正常工作，你将想要编写一些集成测试来验证当你的函数由 Spring Cloud Function 处理并以你配置的方式暴露时，应用程序的整体行为。
- en: Spring Cloud Function provides a @FunctionalSpringBootTest annotation you can
    use to set up the context for your integration tests. Unlike unit tests, you don’t
    want to invoke the function directly but rather ask the framework to provide that
    for you. All the functions managed by the framework are available through the
    FunctionCatalog, an object that acts as a function registry. When the framework
    serves the function, it doesn’t only contain the implementation you wrote; it’s
    enhanced with extra features offered by Spring Cloud Function, like transparent
    type conversion and function composition. Let’s see how this works.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Function 提供了一个 @FunctionalSpringBootTest 注解，你可以使用它来设置集成测试的上下文。与单元测试不同，你不想直接调用函数，而是要求框架为你提供。框架管理的所有函数都通过
    FunctionCatalog 对象可用，该对象充当函数注册表。当框架提供函数时，它不仅包含你编写的实现，还增加了 Spring Cloud Function
    提供的额外功能，如透明类型转换和函数组合。让我们看看它是如何工作的。
- en: First, you need to add a test dependency on Reactor Test in the build.gradle
    file, since part of the business logic is implemented using Reactor. Remember
    to refresh or reimport the Gradle dependencies after the new addition.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要在 build.gradle 文件中添加 Reactor Test 的测试依赖，因为部分业务逻辑是使用 Reactor 实现的。记得在添加新依赖后刷新或重新导入
    Gradle 依赖。
- en: Listing 10.10 Adding dependency for Reactor Test in Dispatcher Service
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.10 在 Dispatcher Service 中添加 Reactor Test 依赖
- en: '[PRE12]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Then, in the src/test/java folder of your Dispatcher Service project, create
    a new DispatchingFunctionsIntegrationTests class. You can write integration tests
    for the two functions individually, but it’s more interesting verifying the behavior
    of the composed function, pack() + label(), as provided by Spring Cloud Function.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 Dispatcher Service 项目的 src/test/java 文件夹中，创建一个新的 DispatchingFunctionsIntegrationTests
    类。你可以为两个函数分别编写集成测试，但验证由 Spring Cloud Function 提供的组合函数 pack() + label() 的行为更有趣。
- en: Listing 10.11 Integration tests for a function composition
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.11 函数组合的集成测试
- en: '[PRE13]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Gets the composed function from the FunctionCatalog
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从 FunctionCatalog 获取复合函数
- en: ❷ Defines an OrderAccepted-Message, which is the input to the function
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 定义一个 OrderAccepted-Message，它是函数的输入
- en: ❸ Asserts that the output of the function is the expected OrderDispatchedMessage
    object
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 断言函数的输出是预期的 OrderDispatchedMessage 对象
- en: 'Finally, open a Terminal window, navigate to the Dispatcher Service project
    root folder, and run the tests:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，打开一个终端窗口，导航到 Dispatcher Service 项目的根目录，并运行测试：
- en: '[PRE14]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This type of integration test ensures the correct behavior of the defined cloud
    function, independently of how it will be exposed. In the source code accompanying
    the book, you’ll find a broader set of autotests (Chapter10/10-intermediate/dispatcher-service).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这种集成测试确保了定义的云函数的正确行为，而不管它将以何种方式公开。在本书的源代码中，你可以找到一个更广泛的自动测试集（第10章/10-intermediate/dispatcher-service）。
- en: Functions are a simple yet effective way to implement business logic and delegate
    infrastructural concerns to the framework. In the next section you’ll learn how
    to bind functions to message channels on RabbitMQ using Spring Cloud Stream.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 函数是实现业务逻辑和将基础设施关注点委托给框架的简单而有效的方法。在下一节中，你将学习如何使用 Spring Cloud Stream 将函数绑定到 RabbitMQ
    上的消息通道。
- en: 10.4 Processing messages with Spring Cloud Stream
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 使用 Spring Cloud Stream 处理消息
- en: The principles that drive the Spring Cloud Function framework can also be found
    in Spring Cloud Stream. The idea is that you, as a developer, are responsible
    for the business logic, while the framework handles infrastructural concerns like
    how to integrate a message broker.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动 Spring Cloud Function 框架的原则也可以在 Spring Cloud Stream 中找到。想法是，作为开发者，你负责业务逻辑，而框架处理基础设施关注点，比如如何集成消息代理。
- en: Spring Cloud Stream is a framework for building scalable, event-driven, and
    streaming applications. It’s built on top of Spring Integration, which offers
    the communication layer with message brokers; Spring Boot, which provides auto-configuration
    for the middleware integration; and Spring Cloud Function, which produces, processes,
    and consumes events. Spring Cloud Stream relies on the native features of each
    message broker, but it also provides an abstraction to ensure a seamless experience
    independently of the underlying middleware. For example, features like consumer
    groups and partitions (native in Apache Kafka) are not present in RabbitMQ, but
    you can still use them thanks to the framework providing them for you.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream 是一个用于构建可扩展、事件驱动和流式应用程序的框架。它建立在 Spring Integration 之上，该集成提供了与消息代理的通信层；Spring
    Boot，它为中间件集成提供自动配置；以及 Spring Cloud Function，它产生、处理和消费事件。Spring Cloud Stream 依赖于每个消息代理的本地功能，但它还提供了一个抽象层，以确保无论底层中间件如何，都能提供无缝的体验。例如，像消费者组和分区（Apache
    Kafka 中是本地的）这样的功能在 RabbitMQ 中不存在，但你可以通过框架为你提供它们来使用它们。
- en: My favorite Spring Cloud Stream feature is that you can drop a dependency in
    a project like Dispatcher Service and get functions automatically bound to an
    external message broker. The best part of it? You don’t have to change any code
    in the application, just the configuration in application.yml or application.properties.
    In previous versions of the framework, it was necessary to use dedicated annotations
    to match the business logic with the Spring Cloud Stream components. Now it’s
    completely transparent.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我最喜欢的 Spring Cloud Stream 功能是，你可以在项目中删除对 Dispatcher Service 的依赖，并自动将功能绑定到外部消息代理。最好的部分是？你不需要在应用程序中更改任何代码，只需更改
    application.yml 或 application.properties 中的配置。在框架的先前版本中，必须使用专用注解来匹配业务逻辑与 Spring
    Cloud Stream 组件。现在它完全透明。
- en: The framework supports integrations with RabbitMQ, Apache Kafka, Kafka Streams,
    and Amazon Kinesis. There are also integrations maintained by partners for Google
    PubSub, Solace PubSub+, Azure Event Hubs, and Apache RocketMQ.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 框架支持与 RabbitMQ、Apache Kafka、Kafka Streams 和 Amazon Kinesis 的集成。还有合作伙伴维护的集成，包括
    Google PubSub、Solace PubSub+、Azure Event Hubs 和 Apache RocketMQ。
- en: This section will cover how to expose the composed function we defined in Dispatcher
    Service through message channels in RabbitMQ.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何通过 RabbitMQ 的消息通道公开我们在 Dispatcher Service 中定义的复合函数。
- en: 10.4.1 Configuring the integration with RabbitMQ
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.1 配置与 RabbitMQ 的集成
- en: 'Spring Cloud Stream is based on a few essential concepts:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream 基于几个基本概念：
- en: '*Destination binder*—The component providing the integration with external
    messaging systems, like RabbitMQ or Kafka'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*目标绑定器*——提供与外部消息系统（如 RabbitMQ 或 Kafka）集成的组件'
- en: '*Destination binding*—The bridge between the external messaging system entities,
    like queues and topics, and the application-provided producers and consumers'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*目标绑定*——外部消息系统实体（如队列和主题）与应用程序提供的生产者和消费者之间的桥梁'
- en: '*Message*—The data structure used by the application producers and consumers
    to communicate with the destination binders, and therefore with the external messaging
    systems'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*消息*——应用程序生产者和消费者用于与目标绑定器以及外部消息系统通信的数据结构'
- en: All three of these are handled by the framework itself. The core of your application,
    the business logic, is not aware of the external messaging system. Destination
    binders are responsible for letting the application communicate with the external
    message brokers, including any vendor-specific concerns. The bindings are auto-configured
    by the framework, but you can still provide your own configuration to adapt them
    to your needs, as we’ll do for Dispatcher Service. Figure 10.9 shows a model of
    a Spring Boot application using Spring Cloud Stream.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这三项都由框架本身处理。您应用程序的核心，即业务逻辑，并不知道外部消息系统。目标绑定器负责让应用程序能够与外部消息代理进行通信，包括任何供应商特定的关注点。绑定由框架自动配置，但您仍然可以提供自己的配置来适应您的需求，就像我们对
    Dispatcher 服务所做的那样。图 10.9 展示了一个使用 Spring Cloud Stream 的 Spring Boot 应用程序模型。
- en: '![10-09](../Images/10-09.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![10-09](../Images/10-09.png)'
- en: Figure 10.9 In Spring Cloud Stream, a destination binder provides integration
    with external messaging systems and establishes message channels with them.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 在 Spring Cloud Stream 中，目标绑定器提供与外部消息系统的集成，并与之建立消息通道。
- en: Once you have defined the business logic of your application as functions, and
    you’ve configured Spring Cloud Function to manage them (like we did for Dispatcher
    Service), you can expose the functions through a message broker by adding a dependency
    on the Spring Cloud Stream binder project specific to the broker you want to use.
    I’ll show you how to work with RabbitMQ both for input and output message channels,
    but you can also bind to multiple messaging systems within the same application.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将应用程序的业务逻辑定义为函数，并且您已配置 Spring Cloud Function 来管理它们（就像我们对 Dispatcher 服务所做的那样），您可以通过添加特定于您想要使用的代理的
    Spring Cloud Stream 绑定器项目依赖项来通过消息代理公开这些函数。我将向您展示如何处理 RabbitMQ 的输入和输出消息通道，但您也可以在同一个应用程序中将绑定到多个消息系统。
- en: Integrating RabbitMQ with Spring
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 将 RabbitMQ 集成到 Spring 中
- en: First, open the build.gradle file for the Dispatcher Service project (dispatcher-service),
    and replace the Spring Cloud Function dependency with the RabbitMQ binder for
    Spring Cloud Stream. Since Spring Cloud Function is already included in Spring
    Cloud Stream, you don’t need to add it explicitly. You can also remove the dependency
    on Spring Boot Starter, which is also included in the Spring Cloud Stream dependency.
    Remember to refresh or reimport the Gradle dependencies after the new addition.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开 Dispatcher 服务项目（dispatcher-service）的 build.gradle 文件，并将 Spring Cloud Function
    依赖项替换为 Spring Cloud Stream 的 RabbitMQ 绑定器。由于 Spring Cloud Function 已经包含在 Spring
    Cloud Stream 中，因此您不需要显式添加它。您还可以删除对 Spring Boot Starter 的依赖，因为它也包含在 Spring Cloud
    Stream 依赖中。请记住，在添加新依赖后，刷新或重新导入 Gradle 依赖项。
- en: Listing 10.12 Updating dependencies in Dispatcher Service
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.12 更新 Dispatcher 服务中的依赖项
- en: '[PRE15]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Next, open the application.yml file and add the following configuration for
    the RabbitMQ integration. Port, username, and password are the same ones we previously
    defined in Docker Compose (listings 10.1 and 10.2).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，打开 application.yml 文件，并添加以下配置以实现 RabbitMQ 集成。端口、用户名和密码与我们在 Docker Compose
    中之前定义的相同（列表 10.1 和 10.2）。
- en: Listing 10.13 Configuring the RabbitMQ integration
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.13 配置 RabbitMQ 集成
- en: '[PRE16]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: That’s it. If you run the Dispatcher Service, you’ll notice it already works
    perfectly without further configuration. Spring Cloud Stream will auto-generate
    and configure the bindings to exchanges and queues in RabbitMQ.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。如果您运行 Dispatcher 服务，您会注意到它已经完美运行，无需进一步配置。Spring Cloud Stream 将自动生成并配置 RabbitMQ
    中的绑定到交换机和队列。
- en: That’s great for getting up and running quickly, but you will probably want
    to add your own configuration to customize the behavior for a production scenario.
    The following section will show you how to do that, again without changing any
    code in your business logic. How great is that?
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于快速启动和运行非常不错，但你可能希望添加自己的配置来定制生产场景的行为。接下来的部分将向您展示如何做到这一点，而且无需更改您的业务逻辑中的任何代码。这有多棒？
- en: 10.4.2 Binding functions to message channels
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.2 将绑定函数绑定到消息通道
- en: Getting started with Spring Cloud Stream is straightforward, but there’s a chance
    of confusing concepts with similar names. In the context of message brokers and
    Spring Cloud Stream, the term *binding* and its variations are used a lot and
    can lead to misunderstandings. Figure 10.10 shows all the entities in place.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用 Spring Cloud Stream 非常简单，但可能会因为相似名称的概念混淆。在消息代理和 Spring Cloud Stream 的上下文中，术语
    *binding* 及其变体被大量使用，可能会导致误解。图 10.10 展示了所有实体。
- en: '![10-10](../Images/10-10.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![10-10](../Images/10-10.png)'
- en: Figure 10.10 In Spring Cloud Stream, bindings establish message channels between
    applications and message brokers.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10 在 Spring Cloud Stream 中，绑定在应用程序和消息代理之间建立了消息通道。
- en: Spring Cloud Stream provides a Spring Boot application with a *destination binder*
    that integrates with an external messaging system. The binder is also responsible
    for establishing communication channels between the application producers and
    consumers and the messaging system entities (exchanges and queues for RabbitMQ).
    These communication channels are called *destination bindings*, and they are bridges
    between applications and brokers.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream 提供了一个带有 *目标绑定器* 的 Spring Boot 应用程序，该绑定器与外部消息系统集成。绑定器还负责在应用程序生产者和消费者与消息系统实体（RabbitMQ
    的交换和队列）之间建立通信通道。这些通信通道被称为 *目标绑定*，它们是应用程序和代理之间的桥梁。
- en: A *destination binding* can be either an input channel or an output channel.
    By default, Spring Cloud Stream maps each binding (both input and output) to an
    exchange in RabbitMQ (a *topic exchange*, to be more precise). Furthermore, for
    each input binding, it binds a queue to the related exchange. That’s the queue
    from which consumers receive and process events. This setup provides all the plumbing
    for implementing event-driven architectures based on the pub/sub model.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*目标绑定* 可以是输入通道或输出通道。默认情况下，Spring Cloud Stream 将每个绑定（输入和输出）映射到 RabbitMQ 中的一个交换（更确切地说，是一个
    *主题交换*）。此外，对于每个输入绑定，它将一个队列绑定到相关的交换。这就是消费者从中接收和处理事件的队列。这种设置提供了基于发布/订阅模型实现事件驱动架构的所有管道。'
- en: In the following sections, I’ll tell you more about destination bindings in
    Spring Cloud Stream and how they relate to exchanges and queues in RabbitMQ.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我将向您介绍 Spring Cloud Stream 中的目标绑定以及它们如何与 RabbitMQ 中的交换和队列相关联。
- en: Understanding destination bindings
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 理解目标绑定
- en: 'As you can see in figure 10.10, destination bindings are an abstraction representing
    a bridge between application and broker. When using the functional programming
    model, Spring Cloud Stream generates an input binding for each function accepting
    input data, and an output binding for each function returning output data. Each
    binding is assigned a logical name following this convention:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 10.10 所示，目标绑定是一个抽象，表示应用程序和代理之间的桥梁。在使用函数式编程模型时，Spring Cloud Stream 为每个接受输入数据的函数生成一个输入绑定，并为每个返回输出数据的函数生成一个输出绑定。每个绑定都按照以下约定分配一个逻辑名称：
- en: 'Input binding: <functionName> + -in- + <index>'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入绑定：<functionName> + -in- + <index>
- en: 'Output binding: <functionName> + -out- + <index>'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出绑定：<functionName> + -out- + <index>
- en: 'Unless you use partitions (for example, with Kafka), the <index> part of the
    name will always be 0. The <functionName> is computed from the value of the spring.cloud.function.definition
    property. In case of a single function, there is a one-to-one mapping. For example,
    if in Dispatcher Service we only had one function called dispatch, the related
    binding would be named dispatch-in-0 and dispatch-out-0. We actually used a composed
    function (pack|label), so the binding names are generated by combining the names
    of all the functions involved in the composition:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你使用分区（例如，与 Kafka 一起使用），否则名称中的 <index> 部分始终为 0。《functionName》是从 spring.cloud.function.definition
    属性的值计算得出的。对于单个函数，存在一对一的映射。例如，如果在 Dispatcher Service 中我们只有一个名为 dispatch 的函数，相关的绑定将被命名为
    dispatch-in-0 和 dispatch-out-0。我们实际上使用了一个组合函数（pack|label），因此绑定名称是通过组合组成中涉及的所有函数的名称生成的：
- en: 'Input binding: packlabel-in-0'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入绑定：packlabel-in-0
- en: 'Output binding: packlabel-out-0'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出绑定：packlabel-out-0
- en: These names are only relevant for configuring the bindings themselves in the
    application. They’re like unique identifiers that let you reference a specific
    binding and apply custom configuration. Notice that these names exist only in
    Spring Cloud Stream—they’re logical names. RabbitMQ doesn’t know about them.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这些名称仅与在应用程序中配置绑定本身相关。它们就像唯一的标识符，让您能够引用特定的绑定并应用自定义配置。请注意，这些名称仅在Spring Cloud Stream中存在——它们是逻辑名称。RabbitMQ不了解它们。
- en: Configuring destination bindings
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 配置目的地绑定
- en: By default, Spring Cloud Stream uses the binding names to generate the names
    for exchanges and queues in RabbitMQ, but in a production scenario you’d probably
    want to manage them explicitly for several reasons. For example, it’s likely that
    both exchanges and queues already exist in production. You will also want to control
    different options for exchanges and queues, like durability or routing algorithms.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Cloud Stream使用绑定名称来生成RabbitMQ中交换和队列的名称，但在生产环境中，你可能出于几个原因而希望显式地管理它们。例如，交换和队列很可能已经在生产环境中存在。你还将想要控制交换和队列的不同选项，如持久性或路由算法。
- en: For Dispatcher Service, I’ll show you how to configure input and output bindings.
    At startup, Spring Cloud Stream will check if the related exchanges and queues
    already exist in RabbitMQ. If they don’t, it will create them according to your
    configuration.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Dispatcher Service，我将向您展示如何配置输入和输出绑定。在启动时，Spring Cloud Stream将检查相关的交换和队列是否已经在RabbitMQ中存在。如果它们不存在，它将根据您的配置创建它们。
- en: Let’s start by defining the destination names that will be used to name exchanges
    and queues in RabbitMQ. In your Dispatcher Service project, update the application.yml
    file as follows.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先定义将要用于在RabbitMQ中命名交换和队列的目的地名称。在你的Dispatcher Service项目中，按照以下方式更新application.yml文件。
- en: Listing 10.14 Configuring Cloud Stream bindings and RabbitMQ destinations
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.14 配置Cloud Stream绑定和RabbitMQ目的地
- en: '[PRE17]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Section for configuring destination bindings
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 配置目的地绑定的部分
- en: ❷ The input binding
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 输入绑定
- en: ❸ The actual name at the broker that the binder binds to (the exchange in RabbitMQ)
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在代理中实际绑定的名称（RabbitMQ中的交换）
- en: ❹ The consumer group interested in the destination (same as the application
    name)
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 对目的地（与应用程序名称相同）感兴趣的消费者组
- en: ❺ The output binding
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 输出绑定
- en: ❻ The actual name at the broker that the binder binds to (the exchange in RabbitMQ)
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 在代理中实际绑定的名称（RabbitMQ中的交换）
- en: The output binding (packlabel-out-0) will be mapped to an order-dispatched exchange
    in RabbitMQ. The input binding (packlabel-in-0) will be mapped to an order-accepted
    exchange and an order-accepted.dispatcher-service queue in RabbitMQ. If they don’t
    exist already in RabbitMQ, the binder will create them. The queue-naming strategy
    (<destination>.<group>) includes a parameter called *consumer group*.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 输出绑定（packlabel-out-0）将被映射到RabbitMQ中的order-dispatched交换。输入绑定（packlabel-in-0）将被映射到order-accepted交换和order-accepted.dispatcher-service队列在RabbitMQ中。如果它们在RabbitMQ中尚未存在，绑定器将创建它们。队列命名策略（<destination>.<group>）包括一个名为*消费者组*的参数。
- en: The idea of *consumer groups* has been borrowed from Kafka and is very useful.
    In a standard pub/sub model, all consumers receive a copy of the messages sent
    to the queues they’re subscribed to. That is convenient when different applications
    need to process the messages. But in a cloud native context, where multiple instances
    of an application are running simultaneously for scaling and resilience, that
    would be a problem. If you have numerous Dispatcher Service instances, you don’t
    want an order to be dispatched from all of them. That would lead to errors and
    an inconsistent state.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '*消费者组* 的概念是从Kafka借用的，非常有用。在标准的发布/订阅模型中，所有消费者都会接收到发送到他们订阅队列的消息副本。当不同的应用程序需要处理消息时，这很方便。但在云原生环境中，由于为了扩展和弹性，应用程序的多个实例同时运行，这可能会成为一个问题。如果你有大量的Dispatcher
    Service实例，你不想所有实例都从它们那里分发订单。这会导致错误和不一致的状态。'
- en: Consumer groups solve the problem. All consumers in the same group share a single
    subscription. As a consequence, each message arriving at the queue to which they’re
    subscribed will be processed by one consumer only. Assume we have two applications
    (Dispatcher Service and Mail Service) interested in receiving events about accepted
    orders and deployed in a replicated fashion. Using the application name to configure
    consumer groups, we can ensure that each event is received and processed by a
    single instance of Dispatcher Service and a single instance of Mail Service, as
    shown in figure 10.11\.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者组解决了这个问题。同一组中的所有消费者共享一个单独的订阅。因此，到达他们订阅的队列的每条消息都只由一个消费者处理。假设我们有两个应用程序（Dispatcher
    Service和Mail Service）对接收已接受订单的事件感兴趣，并且以复制的方式部署。使用应用程序名称来配置消费者组，我们可以确保每个事件都由Dispatcher
    Service的单个实例和Mail Service的单个实例接收和处理，如图10.11所示。
- en: '![10-11](../Images/10-11.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![10-11](../Images/10-11.png)'
- en: Figure 10.11 Consumer groups ensure that each message is received and processed
    by only one consumer within the same group.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11 消费者组确保同一组内只有单个消费者接收和处理每条消息。
- en: Exploring exchanges and queues in RabbitMQ
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 探索RabbitMQ中的交换机和队列
- en: After configuring the integration with RabbitMQ through Spring Cloud Stream,
    it’s time to try running Dispatcher Service.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过Spring Cloud Stream配置了与RabbitMQ的集成之后，现在是时候尝试运行Dispatcher Service了。
- en: 'First, start a RabbitMQ container. Open a Terminal window, navigate to the
    folder in your polar-deployment repository where you keep your docker-compose.yml
    file (polar-deployment/docker), and run the following command:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，启动一个RabbitMQ容器。打开一个终端窗口，导航到你的polar-deployment仓库中保存docker-compose.yml文件的文件夹（polar-deployment/docker），并运行以下命令：
- en: '[PRE18]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then open another Terminal window, navigate to the Dispatcher Service project’s
    root folder (dispatcher-service), and run the application as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 然后打开另一个终端窗口，导航到Dispatcher Service项目的根目录（dispatcher-service），并按以下方式运行应用程序：
- en: '[PRE19]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The application logs will already give you a hint of what happened, but for
    a clearer understanding, let’s check the RabbitMQ management console (exposed
    through port 15672).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序日志已经为你提供了发生事件的线索，但为了更清晰地理解，让我们检查RabbitMQ管理控制台（通过端口15672暴露）。
- en: 'Open a browser window and navigate to http://localhost:15672\. The credentials
    are the same that we defined in Docker Compose (user/password). Then go to the
    Exchanges section. Figure 10.12 shows a list of default exchanges provided by
    RabbitMQ and the two exchanges generated by our application: order-accepted and
    order-dispatched. Spring Cloud Stream maps them to the packlabel-in-0 and packlabel-out-0
    bindings respectively. The exchanges are *durable* (denoted by the D icon in the
    management console), meaning that they will survive a broker restart.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 打开一个浏览器窗口，导航到http://localhost:15672。凭证与我们在Docker Compose中定义的相同（用户/密码）。然后转到交换机部分。图10.12显示了RabbitMQ提供的默认交换机以及我们应用程序生成的两个交换机：order-accepted和order-dispatched。Spring
    Cloud Stream将它们分别映射到packlabel-in-0和packlabel-out-0绑定。交换机是*持久的*（在管理控制台中用D图标表示），这意味着它们将在代理重启后继续存在。
- en: '![10-12](../Images/10-12.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![10-12](../Images/10-12.png)'
- en: Figure 10.12 Spring Cloud Stream maps the two destination binding to two exchanges
    in RabbitMQ.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12 Spring Cloud Stream将两个目标绑定映射到RabbitMQ中的两个交换机。
- en: Next, let’s take a look at the queues. In Dispatcher Service we configured a
    packlabel-in-0 binding and a consumer group. That’s the only input channel for
    the application, so it should result in a single queue. Let’s verify that. In
    the RabbitMQ management console, as illustrated in figure 10.13, you can see a
    durable order-accepted.dispatcher-service queue in the Queues section.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看队列。在Dispatcher Service中，我们配置了一个packlabel-in-0绑定和一个消费者组。这是应用程序的唯一输入通道，因此应该只有一个队列。让我们来验证一下。在RabbitMQ管理控制台中，如图10.13所示，你可以在队列部分看到一个持久的order-accepted.dispatcher-service队列。
- en: '![10-13](../Images/10-13.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![10-13](../Images/10-13.png)'
- en: Figure 10.13 Spring Cloud Stream maps each input binding to a queue, named according
    to the configured consumer group.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13 Spring Cloud Stream将每个输入绑定映射到一个队列，队列名称根据配置的消费者组命名。
- en: Note No queue has been created for the packlabel-out-0 binding because no consumer
    subscribed to it. Later you’ll see that a queue will be created after configuring
    Order Service to listen to it.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：由于没有消费者订阅，尚未为packlabel-out-0绑定创建队列。稍后你将看到在配置Order Service以监听它之后，将创建一个队列。
- en: We can verify that the integration works by manually sending a message to the
    order-accepted exchange. If everything is configured correctly, Dispatcher Service
    will read the message from the order-accepted.dispatcher-service queue, process
    it through the composed function pack|label, and finally send it to the order-dispatched
    exchange.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过手动向订单接受交换机发送消息来验证集成是否正常工作。如果一切配置正确，调度服务将从order-accepted.dispatcher-service队列中读取消息，通过组合函数pack|label进行处理，最终将其发送到订单调度交换机。
- en: Go to the Exchanges section again, select the order-accepted exchange, and in
    the Publish Message panel, insert an OrderAcceptedMessage object in JSON format,
    as shown in figure 10.14\. When you’re done, click the Publish Message button.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 再次转到交换机部分，选择订单接受交换机，在发布消息面板中，插入一个JSON格式的OrderAcceptedMessage对象，如图10.14所示。完成操作后，点击发布消息按钮。
- en: '![10-14](../Images/10-14.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![10-14](../Images/10-14.png)'
- en: Figure 10.14 You can trigger the data flow in Dispatcher Service by sending
    a message to the order-accepted exchange.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14 你可以通过向订单接受交换机发送消息来触发调度服务中的数据流。
- en: 'In the application logs, you should see the following messages signaling that
    the data flow happened correctly:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序日志中，你应该看到以下消息，表明数据流发生正确：
- en: '[PRE20]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The output message has been sent to the order-dispatched exchange, but it has
    not been routed to any queue because no consumer has subscribed. In the final
    part of this chapter, we’ll complete the flow by defining a supplier in Order
    Service to publish messages to the order-accepted exchange whenever an order is
    accepted, and a consumer to read messages from the order-dispatched queue whenever
    an order is dispatched. But first, let’s add some tests to verify the integration
    with the Spring Cloud Stream binder.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 输出消息已经发送到订单调度交换机，但由于没有消费者订阅，它尚未被路由到任何队列。在本章的最后部分，我们将通过在订单服务中定义一个供应商来发布消息到订单接受交换机，以及定义一个消费者来读取订单调度队列中的消息，从而完成流程。但在那之前，让我们添加一些测试来验证与Spring
    Cloud Stream绑定器的集成。
- en: Before moving on, stop the application process with Ctrl-C and the RabbitMQ
    container with docker-compose down.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，使用Ctrl-C停止应用程序进程，并使用docker-compose down停止RabbitMQ容器。
- en: 10.4.3 Writing integration tests with a test binder
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.3 使用测试绑定器编写集成测试
- en: As I have stressed several times, Spring Cloud Function and Spring Cloud Stream’s
    whole philosophy is about keeping the application’s business logic infrastructure—and
    middleware—neutral. After defining the original pack() and label() functions,
    all we did was update dependencies in Gradle and modify the configuration in application.yml.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 如我多次强调的那样，Spring Cloud Function和Spring Cloud Stream的整个哲学是保持应用程序的业务逻辑基础设施和中间件的中立性。在定义了原始的pack()和label()函数之后，我们所做的就是更新Gradle中的依赖关系和修改application.yml中的配置。
- en: It’s a good idea to have unit tests covering the business logic, independent
    of the framework. But it’s worth adding a few integration tests to cover the application’s
    behavior in a Spring Cloud Stream context. You should disable the integration
    tests you wrote earlier in the DispatchingFunctionsIntegrationTests class, since
    now you’ll want to test the integration with the external messaging system.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个很好的主意是编写覆盖业务逻辑的单元测试，与框架无关。但添加一些集成测试来覆盖Spring Cloud Stream上下文中应用程序的行为也是值得的。你应该禁用之前在DispatchingFunctionsIntegrationTests类中编写的集成测试，因为你现在想测试与外部消息系统的集成。
- en: The framework provides a binder specifically for implementing integration tests
    focusing on the business logic rather than the middleware. Let’s see how it works,
    using Dispatcher Service as an example.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架提供了一个专门用于实现集成测试的绑定器，该测试侧重于业务逻辑而不是中间件。让我们看看它是如何工作的，以调度服务为例。
- en: Note The test binder provided by Spring Cloud Stream is meant to verify the
    correct configuration and integration with a technology-agnostic destination binder.
    If you want to test the application against a specific broker (in our case, it
    would be for RabbitMQ), you can rely on Testcontainers, as you learned in the
    previous chapter. I’ll leave that up to you as an exercise.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：Spring Cloud Stream提供的测试绑定器旨在验证与一个技术无关的目标绑定器的正确配置和集成。如果你想针对特定的代理（在我们的例子中，将是RabbitMQ）测试应用程序，你可以依赖Testcontainers，正如你在上一章中学到的。我将把这个留给你作为练习。
- en: First, add a dependency to the test binder in the build.gradle file of your
    Dispatcher Service project. Unlike the other dependencies we’ve been working on
    so far, the test binder requires a more elaborate syntax to be included. For more
    information, refer to the Spring Cloud Stream documentation ([https://spring.io/projects/spring-cloud-stream](https://spring.io/projects/spring-cloud-stream)).
    Remember to refresh or reimport the Gradle dependencies after the new addition.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在Dispatcher Service项目的build.gradle文件中添加对测试绑定的依赖项。与迄今为止我们一直在工作的其他依赖项不同，测试绑定需要更复杂的语法来包含。有关更多信息，请参阅Spring
    Cloud Stream文档（[https://spring.io/projects/spring-cloud-stream](https://spring.io/projects/spring-cloud-stream)）。请记住，在添加新依赖项后刷新或重新导入Gradle依赖项。
- en: Listing 10.15 Adding a dependency for the test binder in Dispatcher Service
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.15 在Dispatcher Service中添加测试绑定的依赖项
- en: '[PRE21]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, create a new FunctionsStreamIntegrationTests class for testing. The test
    setup consists of three steps:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个新的FunctionsStreamIntegrationTests类进行测试。测试设置包括三个步骤：
- en: Import the TestChannelBinderConfiguration class providing configuration for
    the test binder.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入提供测试绑定配置的TestChannelBinderConfiguration类。
- en: Inject an InputDestination bean representing the input binding packlabel-in-0
    (by default, since it’s the only one).
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注入一个表示输入绑定包标签-in-0的InputDestination Bean（默认情况下，因为它只有一个）。
- en: Inject an OutputDestination bean representing the output binding packlabel-out-0
    (by default, since it’s the only one).
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注入一个表示输出绑定包标签-out-0的OutputDestination Bean（默认情况下，因为它只有一个）。
- en: The data flow is based on Message objects (from the org.springframework.messaging
    package). The framework handles type conversion for you transparently when running
    the application. However, in this type of test, you need to provide Message objects
    explicitly. You can use MessageBuilder to create the input message, and use the
    ObjectMapper utility to perform the type conversion from the binary format used
    for storing message payloads in a broker.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 数据流基于Message对象（来自org.springframework.messaging包）。当运行应用程序时，框架会为您透明地处理类型转换。然而，在这种类型的测试中，您需要明确提供Message对象。您可以使用MessageBuilder创建输入消息，并使用ObjectMapper实用工具执行用于在代理中存储消息有效载荷的二进制格式与类型之间的转换。
- en: Listing 10.16 Testing the integration with external messaging systems
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.16 测试与外部消息系统的集成
- en: '[PRE22]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Configures the test binder
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 配置测试绑定
- en: ❷ Represents the input binding packlabel-in-0
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 表示输入绑定包标签-in-0
- en: ❸ Represents the output binding packlabel-out-0
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 表示输出绑定包标签-out-0
- en: ❹ Uses Jackson to deserialize JSON message payloads to Java objects
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用Jackson将JSON消息有效载荷反序列化为Java对象
- en: ❺ Sends a message to the input channel
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 向输入通道发送消息
- en: ❻ Receives and asserts a message from the output channel
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 接收并断言来自输出通道的消息
- en: Warning If you use IntelliJ IDEA, you might get a warning that InputDestination,
    OutputDestination, and ObjectMapper cannot be autowired. Don’t worry. It’s a false
    positive. You can get rid of the warning by annotating the field with @SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection").
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：如果您使用IntelliJ IDEA，可能会收到一个警告，指出InputDestination、OutputDestination和ObjectMapper无法自动装配。不要担心，这是一个误报。您可以通过在字段上注解@SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")来消除警告。
- en: Message brokers like RabbitMQ deal with binary data, so any data flowing through
    them is mapped to byte[] in Java. The conversion between bytes and DTOs is handled
    by Spring Cloud Stream transparently. But just like for messages, we need to handle
    that explicitly in this test scenario when asserting the content of the message
    received from the output channel.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 消息代理如RabbitMQ处理二进制数据，因此通过它们流动的任何数据在Java中都被映射到byte[]。字节和DTO之间的转换由Spring Cloud
    Stream透明处理。但是，就像消息一样，在这个测试场景中，我们需要明确处理从输出通道接收到的消息的内容。
- en: 'After writing the integration tests, open a Terminal window, navigate to the
    Dispatcher Service project’s root folder, and run the tests:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写集成测试后，打开一个终端窗口，导航到Dispatcher Service项目的根目录，并运行测试：
- en: '[PRE23]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The next section will go through some points to consider regarding resilient
    integrations with messaging systems.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个部分将讨论关于与消息系统进行弹性集成时需要考虑的一些要点。
- en: 10.4.4 Making messaging resilient to failures
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.4 使消息对失败具有弹性
- en: Event-driven architectures solve some issues affecting synchronous request/response
    interactions. For example, if you remove the temporal coupling between applications,
    you won’t need to adopt patterns like circuit breakers, since the communication
    will be asynchronous. If the consumer is momentarily unavailable while the producer
    sends a message, it doesn’t matter. The consumer will receive the message once
    it’s up and running again.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 事件驱动的架构解决了影响同步请求/响应交互的一些问题。例如，如果你消除了应用程序之间的时间耦合，你就不需要采用像断路器这样的模式，因为通信将是异步的。如果消费者在生产者发送消息时暂时不可用，这无关紧要。消费者一旦恢复运行，就会收到消息。
- en: 'In software engineering, there are no silver bullets. Everything comes at a
    cost. On the one hand, applications that are decoupled can operate more independently.
    On the other hand, you introduced a new component in your system that needs to
    be deployed and maintained: the message broker.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件工程中，没有银弹。每件事都有代价。一方面，解耦的应用程序可以更独立地运行。另一方面，你在系统中引入了一个新的组件，需要部署和维护：消息代理。
- en: Assuming that part is taken care of by the platform, there’s still something
    for you to do as the application developer. When an event happens and your application
    wants to publish a message, something might go wrong. Retries and timeouts are
    still helpful, but this time we’ll use them to make the interaction between application
    and broker more resilient. Spring Cloud Stream uses the retry pattern with an
    exponential backoff strategy by default, relying on the Spring Retry library for
    imperative consumers and the retryWhen() Reactor operator for reactive consumers
    (the one you learned about in chapter 8). As usual, you can customize it via configuration
    properties.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这部分由平台处理，作为应用程序开发者，你仍然有一些事情要做。当发生事件并且你的应用程序想要发布消息时，可能会出错。重试和超时仍然很有帮助，但这次我们将使用它们来使应用程序和代理之间的交互更具弹性。Spring
    Cloud Stream默认使用指数退避策略的retry模式，依赖于Spring Retry库来处理命令式消费者，以及retryWhen() Reactor操作符来处理响应式消费者（你在第8章中学到的）。像往常一样，你可以通过配置属性来自定义它。
- en: Spring Cloud Stream defines several defaults to make the interaction more resilient,
    including error channels and graceful shutdown. You can configure different aspects
    of message processing, including dead-letter queues, acknowledgment flows, and
    republishing messages on error.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream定义了几个默认值来提高交互的弹性，包括错误通道和优雅关闭。你可以配置消息处理的各个方面，包括死信队列、确认流和错误时的消息重新发布。
- en: RabbitMQ itself has several features in place to improve reliability and resilience.
    Among other things, it guarantees that each message is delivered at least once.
    Be aware that consumers in your applications might receive the same message twice,
    so your business logic should know how to identify and handle duplicates.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ本身就有几个功能来提高可靠性和弹性。其中之一是保证每条消息至少被投递一次。请注意，你的应用程序中的消费者可能会收到相同的消息两次，因此你的业务逻辑应该知道如何识别和处理重复项。
- en: 'I won’t go further into the details, since this is an extensive subject that
    would require several dedicated chapters to cover it adequately. Instead, I encourage
    you to read the documentation for the different projects involved in your event-driven
    architecture: RabbitMQ ([https://rabbitmq.com](https://rabbitmq.com)), Spring
    AMQP ([https://spring.io/projects/spring-amqp](https://spring.io/projects/spring-amqp)),
    and Spring Cloud Stream ([https://spring.io/projects/spring-cloud-stream](https://spring.io/projects/spring-cloud-stream)).
    You can also check out the event-driven patterns described in Sam Newman’s *Building
    Microservices* (O’Reilly, 2021) and Chris Richardson’s *Microservices Patterns*
    (Manning, 2018).'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会进一步深入细节，因为这是一个广泛的主题，需要几个专门的章节才能充分涵盖。相反，我鼓励你阅读涉及你事件驱动架构的不同项目的文档：RabbitMQ ([https://rabbitmq.com](https://rabbitmq.com))、Spring
    AMQP ([https://spring.io/projects/spring-amqp](https://spring.io/projects/spring-amqp))
    和 Spring Cloud Stream ([https://spring.io/projects/spring-cloud-stream](https://spring.io/projects/spring-cloud-stream))。你还可以查看Sam
    Newman在《Building Microservices》（O’Reilly，2021）和Chris Richardson的《Microservices
    Patterns》（Manning，2018）中描述的事件驱动模式。
- en: In the last part of the chapter, you’ll work with suppliers and consumers and
    complete the order flow for the Polar Bookshop system.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后部分，你将与供应商和消费者合作，完成Polar书店系统的订单流程。
- en: 10.5 Producing and consuming messages with Spring Cloud Stream
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 使用Spring Cloud Stream生产和消费消息
- en: In previous sections, you learned about the functional programming paradigm
    and how it fits in the Spring ecosystem, using Spring Cloud Function and Spring
    Cloud Stream. This last section will guide you through the implementation of producers
    and consumers.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，你学习了函数式编程范式以及它是如何适应 Spring 生态系统的，使用了 Spring Cloud Function 和 Spring
    Cloud Stream。本节最后将指导你实现生产者和消费者。
- en: As you’ll see, consumers are not that different from the functions you wrote
    in Dispatcher Service. On the other hand, producers are slightly different because,
    unlike functions and consumers, they are not naturally activated. I’ll show you
    how to use them both in Order Service while implementing the last part of the
    order flow for the Polar Bookshop system.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，消费者与你在分发服务中编写的函数并没有太大的不同。另一方面，生产者略有不同，因为与函数和消费者不同，它们不是自然激活的。我将向你展示如何在订单服务中同时使用它们，以实现
    Polar Bookshop 系统订单流程的最后部分。
- en: 10.5.1 Implementing event consumers, and the problem of idempotency
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.1 实现事件消费者，以及幂等性问题
- en: The Dispatcher Service application we previously built produces messages when
    orders are dispatched. The Order Service should be notified when that happens
    so that it can update the order status in the database.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前构建的分发服务应用程序在订单派发时会产生消息。当这种情况发生时，订单服务应该被通知，以便它可以更新数据库中的订单状态。
- en: First, open your Order Service project (order-service), and add the dependencies
    on Spring Cloud Stream and the test binder in the build.gradle file. Remember
    to refresh or reimport the Gradle dependencies after the new addition.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开你的订单服务项目（order-service），并在 build.gradle 文件中添加对 Spring Cloud Stream 和测试绑定的依赖。记得在添加新依赖后刷新或重新导入
    Gradle 依赖。
- en: Listing 10.17 Adding dependency for Spring Cloud Stream and test binder
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.17 为 Spring Cloud Stream 和测试绑定添加依赖
- en: '[PRE24]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Next we need to model the event we’d like Order Service to listen to. Create
    a new com.polarbookshop.orderservice.order.event package, and add an OrderDispatchedMessage
    class to hold the identifier for a dispatched order.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要为 Order Service 想要监听的事件建模。创建一个新的 com.polarbookshop.orderservice.order.event
    包，并添加一个 OrderDispatchedMessage 类来保存派发订单的标识符。
- en: Listing 10.18 A DTO representing the event about orders being dispatched
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.18 表示订单派发事件的 DTO
- en: '[PRE25]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Now we’ll implement the business logic using a functional approach. Create an
    OrderFunctions class (com.polarbookshop.orderservice.order.event package), and
    implement a function to consume the messages produced by the Dispatcher Service
    application when an order is dispatched. The function will be a Consumer responsible
    for listening to the incoming messages and updating the database entities accordingly.
    Consumer objects are functions with input but no output. To keep the function
    clean and readable, we’ll move the processing of OrderDispatchedMessage objects
    to the OrderService class (which we’ll implement in a minute).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用函数式方法实现业务逻辑。创建一个 OrderFunctions 类（com.polarbookshop.orderservice.order.event
    包），并实现一个函数来消费分发服务应用程序在订单派发时产生的消息。该函数将是一个 Consumer，负责监听传入的消息并相应地更新数据库实体。消费者对象是带有输入但没有输出的函数。为了保持函数的简洁和可读性，我们将
    OrderDispatchedMessage 对象的处理移动到 OrderService 类（我们将在下一分钟实现）。
- en: Listing 10.19 Consuming messages from RabbitMQ
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.19 从 RabbitMQ 消费消息
- en: '[PRE26]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ For each dispatched message, it updates the related order in the database.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 对于每个派发的消息，它会在数据库中更新相关的订单。
- en: ❷ For each order updated in the database, it logs a message.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 对于数据库中更新的每个订单，它会记录一条消息。
- en: ❸ Subscribes to the reactive stream in order to activate it. Without a subscriber,
    no data flows through the stream.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 订阅反应式流以激活它。如果没有订阅者，则没有数据通过流传输。
- en: Order Service is a reactive application, so the dispatchOrder function will
    consume messages as a reactive stream (a Flux of OrderDispatchedMessage). Reactive
    streams are *activated* only if there’s a subscriber interested in receiving the
    data. For that reason, it’s critical that we end the reactive stream by subscribing
    to it, or else no data will ever be processed. In previous examples, the subscription
    part was handled transparently by the framework (for example, when using reactive
    streams to return data via a REST endpoint or to send data to a backing service).
    In this case, we have to explicitly do that with the subscribe() clause.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: Order Service 是一个响应式应用程序，因此 dispatchOrder 函数将作为响应式流（OrderDispatchedMessage 的
    Flux）消费消息。响应式流仅在存在订阅者感兴趣接收数据时才会被激活。因此，我们通过订阅它来结束响应式流至关重要，否则将不会处理任何数据。在之前的示例中，订阅部分由框架透明处理（例如，当使用响应式流通过
    REST 端点返回数据或向后端服务发送数据时）。在这种情况下，我们必须使用 subscribe() 子句显式地执行此操作。
- en: Next, let’s implement the consumeOrderDispatchedMessageEvent() method in the
    OrderService class to update the status in the database for an existing order
    after it’s dispatched.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们在 OrderService 类中实现 consumeOrderDispatchedMessageEvent() 方法，以便在订单派发后更新数据库中现有订单的状态。
- en: Listing 10.20 Implementing the logic for updating an order as dispatched
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.20 实现更新订单为派发状态的逻辑
- en: '[PRE27]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ Accepts a reactive stream of OrderDispatchedMessage objects as input
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 接受一个包含 OrderDispatchedMessage 对象的响应式流作为输入
- en: ❷ For each object emitted to the stream, it reads the related order from the
    database.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 对于流中发出的每个对象，它从数据库中读取相关的订单。
- en: ❸ Updates the order with the “dispatched” status
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 更新订单为“已派发”状态
- en: ❹ Saves the updated order in the database
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将更新后的订单保存到数据库中
- en: ❺ Given an order, it returns a new record with the “dispatched” status.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 给定一个订单，它返回一个具有“已派发”状态的新记录。
- en: Consumers are triggered by a message arriving in the queue. RabbitMQ provides
    an *at-least-one delivered* guarantee, so you need to be aware of possible duplicates.
    The code we implemented updates the status of the specific order to be DISPATCHED,
    an operation that can be executed several times with the same result. Since the
    operation is idempotent, the code is resilient to duplicates. A further optimization
    would be to check for the status and skip the update operation if it’s already
    dispatched.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 当消息到达队列时，消费者会被触发。RabbitMQ 提供了*至少一次投递*的保证，因此你需要注意可能的重复。我们实现的代码更新特定订单的状态为DISPATCHED，这个操作可以多次执行并得到相同的结果。由于该操作是幂等的，代码对重复具有容错性。进一步的优化是检查状态，如果已经派发则跳过更新操作。
- en: Finally, we need to configure Spring Cloud Stream in the application.yml file
    so that the dispatchOrder-in-0 binding (inferred from the dispatchOrder function
    name) is mapped to the order-dispatched exchange in RabbitMQ. Also, remember to
    define dispatchOrder as the function that Spring Cloud Function should manage,
    and the integration with RabbitMQ.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要在 application.yml 文件中配置 Spring Cloud Stream，以便将 dispatchOrder-in-0 绑定（从
    dispatchOrder 函数名称推断）映射到 RabbitMQ 中的 order-dispatched 交换机。同时，请记住将 dispatchOrder
    定义为 Spring Cloud Function 应该管理的函数，以及与 RabbitMQ 的集成。
- en: Listing 10.21 Configuring Cloud Stream bindings and RabbitMQ integration
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.21 配置 Cloud Stream 绑定和 RabbitMQ 集成
- en: '[PRE28]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: ❶ Definition of the function managed by Spring Cloud Function
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Spring Cloud Function管理的函数定义
- en: ❷ The input binding
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 输入绑定
- en: ❸ The actual name at the broker that the binder binds to (the exchange in RabbitMQ)
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 绑定器绑定到代理的实际名称（RabbitMQ 中的交换机）
- en: ❹ The consumer group interested in the destination (the same as the application
    name)
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 对该目的地感兴趣的消费群体（与应用程序名称相同）
- en: ❺ Configures the integrations with RabbitMQ
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 配置与 RabbitMQ 的集成
- en: As you can see, it works the same way as the functions in Dispatcher Service.
    The consumers in Order Service will be part of the order-service consumer group,
    and Spring Cloud Stream will define a message channel between them and an order-dispatched.order-service
    queue in RabbitMQ.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，它的工作方式与 Dispatcher Service 中的函数相同。Order Service 中的消费者将成为 order-service
    消费者群体的一部分，Spring Cloud Stream 将在它们之间定义一个消息通道，以及 RabbitMQ 中的 order-dispatched.order-service
    队列。
- en: Next, we’ll complete the order flow by defining a supplier responsible for triggering
    the whole procedure.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过定义一个负责触发整个流程的供应商来完成订单流程。
- en: 10.5.2 Implementing event producers, and the problem of atomicity
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.2 实现事件生产者，以及原子性问题
- en: Suppliers are message sources. They produce messages when an event happens.
    In Order Service, a supplier should notify the interested parties (in this case,
    Dispatcher Service) whenever an order has been accepted. Unlike functions and
    consumers, suppliers need to be activated. They act only upon invocation.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: Suppliers 是消息源。当事件发生时，它们产生消息。在 Order Service 中，供应商应在订单被接受时通知感兴趣的各方（在这种情况下，Dispatcher
    Service）。与函数和消费者不同，供应商需要被激活。它们仅在调用时才起作用。
- en: Spring Cloud Stream provides a few ways to define suppliers and cover different
    scenarios. In our case, the event source is not a message broker, but a REST endpoint.
    When a user sends a POST request to Order Service for purchasing a book, we want
    to publish an event signaling whether the order has been accepted.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Stream 提供了几种定义供应商的方法，以覆盖不同的场景。在我们的案例中，事件源不是一个消息代理，而是一个 REST 端点。当用户向
    Order Service 发送 POST 请求以购买书籍时，我们希望发布一个事件，指示订单是否已被接受。
- en: Let’s start by modeling that event as a DTO. It will be the same as the OrderAcceptedMessage
    record we used in Dispatcher Service. Add the record to the com.polarbookshop.orderservice.order.event
    package in your Order Service project (order-service).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先以 DTO 的形式建模这个事件。它将与我们在 Dispatcher Service 中使用的 OrderAcceptedMessage 记录相同。将记录添加到您的
    Order Service 项目（order-service）中的 com.polarbookshop.orderservice.order.event 包中。
- en: Listing 10.22 A DTO representing the event about orders being accepted
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.22 代表订单接受事件的 DTO
- en: '[PRE29]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We can bridge the REST layer with the stream part of the application using a
    StreamBridge object that allows us to send data to a specific destination imperatively.
    Let’s break this new functionality down. First, we can implement a method that
    accepts an Order object as input, verifies it’s accepted, builds an OrderAcceptedMessage
    object, and sends it to a RabbitMQ destination using StreamBridge.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用允许我们强制性地将数据发送到特定目标的 StreamBridge 对象，将 REST 层与应用程序的流部分桥接起来。让我们分解这个新功能。首先，我们可以实现一个方法，该方法接受一个
    Order 对象作为输入，验证它是否已被接受，构建一个 OrderAcceptedMessage 对象，并使用 StreamBridge 将其发送到 RabbitMQ
    目标。
- en: Open the OrderService class, autowire a StreamBridge object, and define a new
    publishOrderAcceptedEvent method.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 OrderService 类，自动装配一个 StreamBridge 对象，并定义一个新的 publishOrderAcceptedEvent 方法。
- en: Listing 10.23 Implementing the logic for publishing events to a destination
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.23 实现将事件发布到目标地的逻辑
- en: '[PRE30]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ❶ If the order is not accepted, it does nothing.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如果订单未被接受，它将不执行任何操作。
- en: ❷ Builds a message to notify that an order has been accepted
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 构建一条消息以通知订单已被接受
- en: ❸ Explicitly sends a message to the acceptOrder-out-0 binding
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 明确发送消息到 acceptOrder-out-0 绑定
- en: Since the data source is a REST endpoint, there is no Supplier bean we can register
    with Spring Cloud Function, and therefore there is no trigger for the framework
    to create the necessary bindings with RabbitMQ. Yet, in listing 10.23, StreamBridge
    is used to send data to an acceptOrder-out-0 binding. Where does it come from?
    There is no acceptOrder function!
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据源是一个 REST 端点，我们无法在 Spring Cloud Function 中注册 Supplier bean，因此没有触发框架创建与 RabbitMQ
    所需绑定的框架。然而，在列表 10.23 中，StreamBridge 被用来将数据发送到 acceptOrder-out-0 绑定。它从哪里来？没有 acceptOrder
    函数！
- en: At startup time, Spring Cloud Stream will notice that StreamBridge wants to
    publish messages via an acceptOrder-out-0 binding, and it will create one automatically.
    Similar to the bindings created from functions, we can configure the destination
    name in RabbitMQ. Open the application.yml file and configure the binding as follows.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动时，Spring Cloud Stream 会注意到 StreamBridge 想要通过 acceptOrder-out-0 绑定发布消息，并且它会自动创建一个。类似于从函数创建的绑定，我们可以在
    RabbitMQ 中配置目标名称。打开 application.yml 文件，并按以下方式配置绑定。
- en: Listing 10.24 Configuring Cloud Stream output binding
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.24 配置 Cloud Stream 输出绑定
- en: '[PRE31]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: ❶ Output binding created and managed by StreamBridge
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 由 StreamBridge 创建和管理输出绑定
- en: ❷ The actual name at the broker that the binder binds to (the exchange in RabbitMQ)
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 绑定器绑定的实际名称（RabbitMQ 中的交换机）
- en: All that’s left now is calling the method whenever a submitted order is accepted.
    That’s a critical point and one of the aspects characterizing the *saga pattern*,
    a popular alternative to distributed transactions in microservice architectures.
    To ensure consistency in your system, persisting an order in the database and
    sending a message about it must be done atomically. Either both operations succeed,
    or they both must fail. A simple yet effective way to ensure atomicity is by wrapping
    the two operations in a local transaction. To do that, we can rely on the built-in
    Spring transaction management functionality.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 现在剩下的只是当提交的订单被接受时调用该方法。这是一个关键点，也是表征 *saga 模式* 的一个方面，saga 模式是微服务架构中分布式事务的一个流行替代方案。为了确保系统的一致性，必须在数据库中持久化订单并发送关于它的消息，这两个操作必须原子性地完成。要么两个操作都成功，要么它们都必须失败。确保原子性的简单而有效的方法是将这两个操作包装在一个本地事务中。为此，我们可以依赖内置的
    Spring 事务管理功能。
- en: Note The saga pattern is described extensively in chapter 4 of Chris Richardson’s
    book, *Microservices Patterns* (Manning, 2018; [https://livebook.manning.com/book/microservices-patterns/chapter-4](https://livebook.manning.com/book/microservices-patterns/chapter-4)).
    I recommend you check it out if you’re interested in designing business transactions
    that span multiple applications.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：saga 模式在 Chris Richardson 的书《微服务模式》的第 4 章中进行了详细描述（Manning，2018；[https://livebook.manning.com/book/microservices-patterns/chapter-4](https://livebook.manning.com/book/microservices-patterns/chapter-4)）。如果您对设计跨多个应用程序的业务事务感兴趣，我建议您查看它。
- en: In the OrderService class, modify the submitOrder() method to call the publishOrderAcceptedEvent
    method, and annotate it with @Transactional.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在 OrderService 类中，修改 submitOrder() 方法以调用 publishOrderAcceptedEvent 方法，并使用 @Transactional
    注解。
- en: Listing 10.25 Defining a saga transaction with database and event broker
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.25 使用数据库和事件代理定义 saga 事务
- en: '[PRE32]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ Executes the method in a local transaction
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在本地事务中执行方法
- en: ❷ Saves the order in the database
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在数据库中保存订单
- en: ❸ Publishes an event if the order is accepted
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 如果订单被接受则发布事件
- en: Spring Boot comes preconfigured with transaction management functionality and
    can handle transactional operations involving relational databases (as you learned
    in chapter 5). However, the channel established with RabbitMQ for the message
    producer is not transactional by default. To make the event-publishing operation
    join the existing transaction, we need to enable RabbitMQ’s transactional support
    for the message producer in the application.yml file.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot 默认配置了事务管理功能，可以处理涉及关系数据库的事务性操作（如您在第 5 章中学到的）。然而，与消息生产者建立的 RabbitMQ
    通道默认不是事务性的。为了使事件发布操作加入现有事务，我们需要在 application.yml 文件中启用 RabbitMQ 的消息生产者的事务性支持。
- en: Listing 10.26 Configuring the output binding to be transactional
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.26 配置输出绑定为事务性
- en: '[PRE33]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ RabbitMQ-specific configuration for the Spring Cloud Stream bindings
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ RabbitMQ 特定的 Spring Cloud Stream 绑定配置
- en: ❷ Makes the acceptOrder-out-0 binding transactional
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使 acceptOrder-out-0 绑定事务性
- en: Now you can write new integration tests for the supplier and the consumer, like
    we did for the functions in Dispatcher Service. I’ll leave the autotests to you,
    since you have the necessary tools now. If you need inspiration, check out the
    source code accompanying this book (Chapter10/10-end/order-service).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以编写针对供应商和消费者的新集成测试，就像我们在调度服务的函数中做的那样。我将自动测试留给您，因为您现在有了必要的工具。如果您需要灵感，请查看本书附带源代码（第
    10 章/10-end/order-service）。
- en: You will also need to import the configuration for the test binder (@Import(TestChannelBinderConfiguration.class))
    in the existing OrderServiceApplicationTests class to make it work.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要在现有的 OrderServiceApplicationTests 类中导入测试绑定器的配置（@Import(TestChannelBinderConfiguration.class)）以使其工作。
- en: We’ve had a nice journey through event-driven models, functions, and messaging
    systems. Before wrapping up, let’s look at the order flow in action. First, start
    RabbitMQ, PostgreSQL (docker-compose up -d polar-rabbitmq polar-postgres), and
    Dispatcher Service (./gradlew bootRun). Then run Catalog Service and Order Service
    (./gradlew bootRun or from Docker Compose after building the images first).
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经愉快地穿越了事件驱动模型、函数和消息系统。在结束之前，让我们看看订单流程的实际操作。首先，启动 RabbitMQ、PostgreSQL（docker-compose
    up -d polar-rabbitmq polar-postgres）和调度服务（./gradlew bootRun）。然后运行目录服务和订单服务（./gradlew
    bootRun 或在构建镜像后从 Docker Compose 运行）。
- en: 'Once all those services are up and running, add a new book to the catalog:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有这些服务都启动并运行，向目录中添加一本新书：
- en: '[PRE34]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Then order three copies of that book:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 然后订购三本该书：
- en: '[PRE35]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: If you order a book that exists, the order will be accepted, and Order Service
    will publish an OrderAcceptedEvent message. Dispatcher Service, subscribed to
    that same event, will process the order and publish an OrderDispatchedEvent message.
    Order Service will be notified and update the order status in the database.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您订购了存在的书籍，订单将被接受，并且订单服务将发布一个 OrderAcceptedEvent 消息。订阅了相同事件的分发服务将处理订单并发布一个
    OrderDispatchedEvent 消息。订单服务将收到通知并更新数据库中的订单状态。
- en: Tip You can follow the message flow by checking the application logs from Order
    Service and Dispatcher Service.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：您可以通过检查订单服务和分发服务的应用程序日志来跟踪消息流。
- en: 'Now the moment of the truth. Fetch the order from Order Service:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是检验真伪的时刻。从订单服务获取订单：
- en: '[PRE36]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The status should be DISPATCHED:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 状态应为已分发：
- en: '[PRE37]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: And it is. Great job! When you’re done testing the system, stop all the applications
    (Ctrl-C) and Docker containers (docker-compose down).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 确实如此。做得好！当您完成系统测试后，停止所有应用程序（Ctrl-C）和 Docker 容器（docker-compose down）。
- en: That concludes the main implementation of the business logic for the Polar Bookshop
    system. The next chapter will cover security for cloud native applications using
    Spring Security, OAuth 2.1, and OpenID Connect.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了 Polar 书店系统业务逻辑的主要实现。下一章将介绍使用 Spring Security、OAuth 2.1 和 OpenID Connect
    为云原生应用程序提供的安全性。
- en: Polar Labs
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: Polar Labs
- en: Feel free to apply what you’ve learned in the previous chapters and prepare
    the Dispatcher Service application for deployment.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 随意应用您在前几章中学到的知识，并为部署准备分发服务应用程序。
- en: Add Spring Cloud Config Client to Dispatcher Service to make it fetch configuration
    data from Config Service.
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 Spring Cloud Config Client 添加到分发服务中，使其能够从配置服务获取配置数据。
- en: Configure the Cloud Native Buildpacks integration, containerize the application,
    and define the commit stage of the deployment pipeline.
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置云原生构建包集成，容器化应用程序，并定义部署管道的提交阶段。
- en: Write the Deployment and Service manifests for deploying Dispatcher Service
    to a Kubernetes cluster.
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写部署和服务清单，以便将分发服务部署到 Kubernetes 集群。
- en: Configure Tilt to automate the Dispatcher Service’s deployment to your local
    Kubernetes cluster initialized with minikube.
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置 Tilt 以自动化将分发服务部署到使用 minikube 初始化的本地 Kubernetes 集群。
- en: Then update the Docker Compose specification and the Kubernetes manifests to
    configure the RabbitMQ integration for Order Service.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 然后更新 Docker Compose 规范和 Kubernetes 清单，以配置订单服务的 RabbitMQ 集成。
- en: You can refer to the Chapter10/10-end folder in the code repository accompanying
    the book to check on the final result ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action)).
    Deploy the backing services from the manifests, available in the Chapter10/10-end/polar-deployment/kubernetes/platform/development
    folder, with kubectl apply -f services.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考书中附带的代码仓库中的 Chapter10/10-end 文件夹来检查最终结果 ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action))。使用
    kubectl apply -f services 从 Chapter10/10-end/polar-deployment/kubernetes/platform/development
    文件夹中的清单部署支持服务。
- en: Summary
  id: totrans-385
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Event-driven architectures are distributed systems that interact with each other
    by producing and consuming events.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件驱动架构是相互交互的分布式系统，通过产生和消费事件进行交互。
- en: An event is something relevant that happened in a system.
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件是在系统中发生的相关事情。
- en: In the pub/sub model, producers publish events, which are sent to all subscribers
    to be consumed.
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 pub/sub 模型中，生产者发布事件，这些事件被发送到所有订阅者进行消费。
- en: Event processing platforms like RabbitMQ and Kafka are responsible for collecting
    events from the producers, routing, and distributing them to the interested consumers.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件处理平台，如 RabbitMQ 和 Kafka，负责从生产者收集事件，路由并将它们分发到感兴趣的消费者。
- en: In the AMQP protocol, producers send messages to an exchange in a broker that
    forwards them to queues according to specific routing algorithms.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AMQP 协议中，生产者将消息发送到代理中的交换机，该交换机根据特定的路由算法将它们转发到队列。
- en: In the AMQP protocol, consumers receive messages from the queues in the broker.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AMQP 协议中，消费者从代理中的队列接收消息。
- en: In the AMQP protocol, messages are data structures composed of key/value attributes
    and a binary payload.
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AMQP 协议中，消息是由键/值属性和二进制有效负载组成的数据结构。
- en: RabbitMQ is a message broker based on the AMQP protocol that you can use to
    implement event-driven architectures based on the pub/sub model.
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RabbitMQ 是一个基于 AMQP 协议的消息代理，您可以使用它来实现基于 pub/sub 模型的事件驱动架构。
- en: RabbitMQ provides high availability, resilience, and data replication.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RabbitMQ 提供了高可用性、弹性和数据复制。
- en: Spring Cloud Function enables you to implement your business logic using the
    standard Java Function, Supplier, and Consumer interfaces.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Cloud Function 允许你使用标准的 Java Function、Supplier 和 Consumer 接口实现你的业务逻辑。
- en: Spring Cloud Function wraps your function and provides several exciting features
    like transparent type conversion and function composition.
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Cloud Function 将你的函数封装并提供了一些令人兴奋的功能，如透明的类型转换和函数组合。
- en: Functions implemented in the context of Spring Cloud Function can be exposed
    and integrated with external systems in different ways.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Spring Cloud Function 的上下文中实现的函数可以通过不同的方式公开和集成到外部系统中。
- en: Functions can be exposed as REST endpoints, packaged, and deployed in a FaaS
    platform as serverless applications (Knative, AWS Lambda, Azure Function, Google
    Cloud Functions), or they can be bound to message channels.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数可以作为 REST 端点公开，打包并在 FaaS 平台上作为无服务器应用程序（Knative、AWS Lambda、Azure Function、Google
    Cloud Functions）部署，或者它们可以绑定到消息通道。
- en: Spring Cloud Stream, built on top of Spring Cloud Function, provides you with
    all the necessary plumbing to integrate your functions with external messaging
    systems like RabbitMQ or Kafka.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于 Spring Cloud Function 构建的 Spring Cloud Stream 为你提供了所有必要的管道，以将你的函数与外部消息系统（如
    RabbitMQ 或 Kafka）集成。
- en: Once you implement your functions, you don’t have to make any changes to your
    code. You only need to add a dependency on Spring Cloud Stream and configure it
    to adapt to your needs.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦你实现了你的函数，你不需要对你的代码进行任何更改。你只需要添加对 Spring Cloud Stream 的依赖，并配置它以适应你的需求。
- en: In Spring Cloud Stream, destination binders provide integration with external
    messaging systems.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Spring Cloud Stream 中，目标绑定器提供了与外部消息系统的集成。
- en: In Spring Cloud Stream, destination bindings (input and output) bridge the producers
    and consumers in your applications with exchanges and queues in a message broker
    like RabbitMQ.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Spring Cloud Stream 中，目标绑定（输入和输出）通过消息代理（如 RabbitMQ）中的交换和队列将你的应用程序中的生产者和消费者连接起来。
- en: Functions and consumers are activated automatically when new messages arrive.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当新消息到达时，函数和消费者会自动激活。
- en: Suppliers need to be explicitly activated, such as by explicitly sending a message
    to a destination binding.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 供应商需要被显式激活，例如通过显式地向目标绑定发送消息。
- en: '* * *'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.) See Sam Newman, *Monolith to Microservices* (O’Reilly, 2019).
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: ^（1.）参见 Sam Newman 的《单体到微服务》（O’Reilly，2019）。
