- en: 8 Using probability to its maximum: The naive Bayes model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 利用概率达到极致：朴素贝叶斯模型
- en: In this chapter
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中
- en: what is Bayes theorem
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是贝叶斯定理
- en: dependent and independent events
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关事件和独立事件
- en: the prior and posterior probabilities
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先验概率和后验概率
- en: calculating conditional probabilities based on events
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据事件计算条件概率
- en: using the naive Bayes model to predict whether an email is spam or ham, based
    on the words in the email
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用朴素贝叶斯模型来预测一封电子邮件是否为垃圾邮件或正常邮件，基于邮件中的文字
- en: coding the naive Bayes algorithm in Python
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Python中编码朴素贝叶斯算法
- en: '![](../Images/8-unnumb.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-unnumb.png)'
- en: Naive Bayes is an important machine learning model used for classification.
    The naive Bayes model is a purely probabilistic model, which means the prediction
    is a number between 0 and 1, indicating the probability that a label is positive.
    The main component of the naive Bayes model is Bayes’ theorem.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 朴素贝叶斯是一种重要的机器学习模型，用于分类。朴素贝叶斯模型是一个纯粹的概率模型，这意味着预测是一个介于0和1之间的数字，表示标签为正的概率。朴素贝叶斯模型的主要组成部分是贝叶斯定理。
- en: Bayes’ theorem plays a fundamental role in probability and statistics, because
    it helps calculate probabilities. It is based on the premise that the more information
    we gather about an event, the better estimate of the probability we can make.
    For example, let’s say we want to find the probability that it will snow today.
    If we have no information of where we are and what time of the year it is, we
    can only come up with a vague estimate. However, if we are given information,
    we can make a better estimate of the probability. Imagine that I tell you that
    I am thinking of a type of animal, and I would like you to guess it. What is the
    probability that the animal I’m thinking of is a dog? Given that you don’t know
    any information, the probability is quite small. However, if I tell you that the
    animal I’m thinking of is a house pet, the probability increases quite a bit.
    However, if I now tell you that the animal I’m thinking of has wings, the probability
    is now zero. Each time I tell you a new piece of information, your estimate for
    the probability that it’s a dog becomes more and more accurate. Bayes’ theorem
    is a way to formalize this type of logic and put it into formulas.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理在概率论和统计学中起着根本的作用，因为它有助于计算概率。它基于这样一个前提：我们收集关于一个事件的信息越多，我们对其概率的估计就越准确。例如，假设我们想要找到今天会下雪的概率。如果我们没有关于我们所在的位置和现在是哪一年的信息，我们只能给出一个模糊的估计。然而，如果我们得到信息，我们就可以对概率做出更好的估计。想象一下，我告诉你我在想一种动物，并希望你能猜出它是什么。我想的动物是狗的概率是多少？鉴于你不知道任何信息，这个概率相当小。然而，如果我现在告诉你我想的动物是家养宠物，这个概率就会大大增加。然而，如果我现在告诉你我想的动物有翅膀，这个概率现在为零。每次我告诉你一条新信息，你对它是狗的概率估计就会越来越准确。贝叶斯定理就是将这种逻辑形式化并放入公式中的方法。
- en: More specifically, Bayes’ theorem answers the question, “What is the probability
    of *Y* given that *x* occurred?” which is called a *conditional probability*.
    As you can imagine, answering this type of question is useful in machine learning,
    because if we can answer the question, “What is the probability that *the label
    is positive* given *the features*?” we have a classification model. For example,
    we can build a sentiment analysis model (just like we did in chapter 6) by answering
    the question, “What is the probability that *this sentence is happy* given *the
    words that it contains*?” However, when we have too many features (in this case,
    words), the computation of the probability using Bayes’ theorem gets very complicated.
    This is where the naive Bayes algorithm comes to our rescue. The naive Bayes algorithm
    uses a slick simplification of this calculation to help us build our desired classification
    model, called the *naive Bayes model*. It’s called *naive* Bayes because to simplify
    the calculations, we make a slightly naive assumption that is not necessarily
    true. However, this assumption helps us come up with a good estimate of the probability.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，贝叶斯定理回答了“在发生x的情况下，Y的概率是多少？”这个问题，这被称为条件概率。你可以想象，回答这类问题在机器学习中很有用，因为如果我们能回答“在给定特征的情况下，标签为正的概率是多少？”这个问题，我们就有一个分类模型。例如，我们可以通过回答“给定包含的单词，这句话是快乐的概率是多少？”这个问题来构建情感分析模型（就像我们在第6章中做的那样）。然而，当我们有太多的特征（在这种情况下，是单词）时，使用贝叶斯定理计算概率会变得非常复杂。这就是朴素贝叶斯算法拯救我们的地方。朴素贝叶斯算法通过简化这种计算来帮助我们构建所需的分类模型，称为朴素贝叶斯模型。它被称为朴素贝叶斯是因为为了简化计算，我们做出了一个稍微有些天真且不一定正确的假设。然而，这个假设帮助我们得到了一个很好的概率估计。
- en: 'In this chapter, we see Bayes theorem used with some real-life examples. We
    start by studying an interesting and slightly surprising medical example. Then
    we dive deep into the naive Bayes model by applying it to a common problem in
    machine learning: spam classification. We finalize by coding the algorithm in
    Python and using it to make predictions in a real spam email dataset.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们看到了贝叶斯定理与一些现实生活中的例子结合使用。我们首先研究一个有趣且略带惊讶的医疗案例。然后，我们深入探讨朴素贝叶斯模型，通过将其应用于机器学习中的一个常见问题：垃圾邮件分类。最后，我们用Python编写算法，并在真实的垃圾邮件数据集中使用它进行预测。
- en: 'All the code for this chapter is available at this GitHub repository: [https://github.com/luisguiserrano/manning/tree/master/Chapter_8_Naive_Bayes](https://github.com/luisguiserrano/manning/tree/master/Chapter_8_Naive_Bayes).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码都可以在这个GitHub仓库中找到：[https://github.com/luisguiserrano/manning/tree/master/Chapter_8_Naive_Bayes](https://github.com/luisguiserrano/manning/tree/master/Chapter_8_Naive_Bayes)。
- en: Sick or healthy? A story with Bayes’ theorem as the hero
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 病了还是健康？一个以贝叶斯定理为主角的传奇故事
- en: 'Consider the following scenario. Your (slightly hypochondriac) friend calls
    you, and the following conversation unfolds:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下场景。你的（有点疑病症的）朋友给你打电话，接下来的对话是这样的：
- en: '**You**: Hello!'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**你**：你好！'
- en: '**Friend**: Hi. I have some terrible news!'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**朋友**：嗨。我有个可怕的消息！'
- en: '**You**: Oh no, what is it?'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**你**：哎呀，怎么了？'
- en: '**Friend**: I heard about this terrible and rare disease, and I went to the
    doctor to be tested for it. The doctor said she would administer a very accurate
    test. Then today, she called me and told me that I tested positive! I must have
    the disease!'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**朋友**：我听说了一种可怕且罕见的疾病，我去医生那里做了检测。医生说她将进行一个非常准确的测试。然后今天，她给我打电话告诉我，我检测呈阳性！我肯定有病！'
- en: Oh no! What should you say to your friend? First of all, let’s calm him down,
    and try to figure out if it is likely that he has the disease.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀！你该对你的朋友说些什么呢？首先，让我们让他冷静下来，并试图弄清楚他是否可能患有这种疾病。
- en: '**You**: First, let’s calm down. Mistakes happen in medicine. Let’s try to
    see how likely it is that you actually have the disease. How accurate did the
    doctor say the test was?'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**你**：首先，让我们冷静下来。医学中会出错。让我们看看你实际上患病的可能性有多大。医生说测试的准确率有多高？'
- en: '**Friend**: She said it was 99% accurate. That means I’m 99% likely to have
    the disease!'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**朋友**：她说准确率达到了99%。这意味着我患病的可能性是99%！'
- en: '**You**: Wait, let’s look at *all* the numbers. How likely is it to have the
    disease, regardless of the test? How many people have the disease?'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**你**：等等，让我们看看所有的数字。不考虑测试结果，患病的可能性有多大？有多少人患有这种疾病？'
- en: '**Friend**: I was reading online, and it says that on average, one out of every
    10,000 people have the disease.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**朋友**：我在网上看到，平均每10,000人中就有一个人患有这种疾病。'
- en: '**You**: OK, let me get a piece of paper (*puts friend on hold*).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**你**：好的，让我拿张纸（把朋友放在一边）。'
- en: Let’s stop for a quiz.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们停下来做一个测验。
- en: quiz In what range do you think is the probability that your friend has the
    disease, given that he has tested positive?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 测验：你认为你朋友测试呈阳性时患病的概率在什么范围内？
- en: 0–20%
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 0–20%
- en: 20–40%
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 20–40%
- en: 40–60%
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 40–60%
- en: 60–80%
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 60–80%
- en: 80–100%
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 80–100%
- en: 'Let’s calculate this probability. To summarize, we have the following two pieces
    of information:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算这个概率。总结一下，我们有以下两条信息：
- en: The test is correct 99% of the time. To be more exact (we checked with the doctor
    to confirm this), on average, out of every 100 healthy people, the test correctly
    diagnoses 99 of them, and out of every 100 sick people, the test correctly diagnoses
    99 of them. Therefore, both on healthy and sick people, the test has an accuracy
    of 99%.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试正确率是99%。更准确地说（我们向医生确认过这一点），平均来说，在每100个健康人中，测试正确诊断了99人，在每100个病人中，测试也正确诊断了99人。因此，在健康人和病人中，测试的准确率都是99%。
- en: On average, 1 out of every 10,000 people has the disease.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均来说，每10,000人中就有1人患病。
- en: Let’s do some rough calculations to see what the probability would be. These
    are summarized in the confusion matrix shown in figure 8.1\. For reference, we
    can pick a random group of one million people. On average, one out of every 10,000
    people are sick, so we expect 100 of these people to have the disease and 999,900
    to be healthy.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一些粗略的计算，看看概率会是多少。这些计算总结在图8.1所示的混淆矩阵中。为了参考，我们可以随机选择一百万人的一个群体。平均来说，每10,000人中就有1人患病，所以我们预计这100人中有1人患病，999,900人健康。
- en: First, let’s run the test on the 100 sick ones. Because the test is correct
    99% of the time, we expect 99 of these 100 people to be correctly diagnosed as
    sick—that is, 99 sick people who test positive.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们对这100个生病的进行测试。因为测试正确率是99%，我们预计这100人中有99人会被正确诊断为生病——即99个测试呈阳性的病人。
- en: Now, let’s run the test on the 999,900 healthy ones. The test makes mistakes
    1% of the time, so we expect 1% of these 999,900 healthy people to be misdiagnosed
    as sick. That is 9,999 healthy people who test positive.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们对这999,900个健康的人进行测试。测试有1%的错误率，所以我们预计这999,900个健康人中会有1%的人被误诊为生病。这意味着有9,999个健康人测试呈阳性。
- en: This means that the total number of people who tested positive is 99 + 9,999
    = 10,098\. Out of these, only 99 are sick. Therefore, the probability that your
    friend is sick, given that he tested positive, is 99/10.098 = 0.0098, or 0.98%.
    That is less than 1%! So we can get back to our friend.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着测试呈阳性的总人数是99 + 9,999 = 10,098人。在这些人中，只有99人是生病的。因此，在你朋友测试呈阳性时，他生病的概率是99/10.098
    = 0.0098，或者0.98%。这还不到1%！所以我们可以回到我们朋友身边。
- en: '**You:** Don’t worry, based on the numbers you gave me, the probability that
    you have the disease given that you tested positive is less than 1%!'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**你**：别担心，根据你给我的数据，你测试呈阳性时生病的概率不到1%！'
- en: '**Friend:** Oh, my God, really? That’s such a relief, thank you!'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**朋友**：哦，我的天哪，真的吗？这真是太好了，谢谢你！'
- en: '**You:** Don’t thank me, thank math (*winks eye*).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**你**：不用谢我，感谢数学（眨眼）。'
- en: 'Let’s summarize our calculation. These are our facts:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下我们的计算。以下是我们的事实：
- en: '**Fact 1**: Out of every 10,000 people, one has the disease.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事实1**：在每10,000人中，有1人患有疾病。'
- en: '**Fact 2**: Out of every 100 sick people who take the test, 99 test positive,
    and one tests negative.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事实2**：在每100个接受测试的病人中，有99个测试呈阳性，1个测试呈阴性。'
- en: '**Fact 3**: Out of every 100 healthy people who take the test, 99 test negative,
    and one tests positive.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事实3**：在每100个接受测试的健康人中，有99个测试呈阴性，1个测试呈阳性。'
- en: 'We pick a sample population of one million people, which is broken down in
    figure 8.1, as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了一百万人的样本群体，如图8.1所示，分解如下：
- en: According to fact 1, we expect 100 people in our sample population to have the
    disease, and 999,900 to be healthy.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据事实1，我们预计在我们的样本人群中，有100人患病，999,900人健康。
- en: According to fact 2, out of the 100 sick people, 99 tested positive and one
    tested negative.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据事实2，在100个病人中，有99个测试呈阳性，1个测试呈阴性。
- en: According to fact 3, out of the 999,900 healthy people, 9,999 tested positive
    and 989,901 tested negative
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据事实3，在999,900个健康人中，有9,999个测试呈阳性，989,901个测试呈阴性。
- en: '![](../Images/8-11.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8-11.png)'
- en: Figure 8.1 Among our 1,000,000 patients, only 100 of them are sick (bottom row).
    Among the 10,098 diagnosed as sick (left column), only 99 of them are actually
    sick. The remaining 9,999 are healthy, yet were misdiagnosed as sick. Therefore,
    if our friend was diagnosed as sick, he has a much higher chance to be among the
    9,999 healthy (top left) than to be among the 99 sick (bottom left).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 在我们的100万患者中，只有100人患病（底部行）。在诊断为患病的10,098人中（左侧列），实际上只有99人患病。其余的9,999人都是健康的，却被误诊为患病。因此，如果我们的朋友被诊断为患病，他更有可能属于那9,999个健康的（左上角）而不是那99个患病的（左下角）。
- en: Because our friend tested positive, he must be in the left column of figure
    8.1\. This column has 9,999 healthy people who were misdiagnosed as sick and 99
    sick people who were correctly diagnosed. The probability that your friend is
    sick is 99/9.999 = 0.0089, which is less than 1%.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的朋友测试结果呈阳性，他必须在图8.1的左侧列。这一列有9,999个被误诊为患病的健康人和99个被正确诊断为患病的患者。你的朋友患病的概率是99/9,999
    = 0.0089，这不到1%。
- en: 'This is a bit surprising, if the test is correct 99% of the time, why on earth
    is it so wrong? Well, the test is not bad if it’s wrong only 1% of the time. But
    because one person out of every 10,000 is sick with the disease, that means a
    person is sick 0.01% of the time. What is more likely, to be among the 1% of the
    population that got misdiagnosed or to be among the 0.01% of the population that
    is sick? The 1%, although a small group, is much larger than the 0.01%. The test
    has a problem; it has an error rate much larger than the rate of being sick. We
    have a similar problem in the section “Two examples of models: Coronavirus and
    spam email” in chapter 7—we can’t rely on accuracy to measure this model.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这有点令人惊讶，如果测试正确率是99%，那么为什么会这么错误？好吧，如果测试只有1%的时间出错，那么它并不差。但是，因为每10,000人中就有一个人患有这种疾病，这意味着一个人患病的概率是0.01%。更有可能的是，成为那1%被误诊的人群，还是成为那0.01%患病的人群？尽管1%是一个小群体，但它比0.01%大得多。测试有问题；它的错误率比患病率大得多。我们在第7章的“两个模型示例：冠状病毒和垃圾邮件”部分也有类似的问题——我们不能依赖准确性来衡量这个模型。
- en: 'A way to look at this is using treelike diagrams. In our diagram, we start
    with a root at the left, which branches out into two possibilities: that your
    friend is sick or healthy. Each of these two possibilities branches out into two
    more possibilities: that your friend gets diagnosed as healthy or diagnosed as
    sick. The tree is illustrated in figure 8.2, together with the count of patients
    in each branch.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一种看待这个问题的方式是使用树状图。在我们的图中，我们从左侧的一个根开始，它分支成两种可能性：你的朋友是患病或健康。这两种可能性中的每一种又分支成两种更进一步的可能性：你的朋友被诊断为健康或被诊断为患病。这个树状图在图8.2中展示，并附有每个分支的患者数量。
- en: '![](../Images/8-21.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-21.png)'
- en: 'Figure 8.2 The tree of possibilities. Each patient can be sick or healthy.
    For each of the possibilities, the patient can be diagnosed as sick or healthy,
    which gives us four possibilities. We start with one million patients: 100 of
    them are sick, and the remaining 999,900 are healthy. Out of the 100 sick, one
    gets misdiagnosed as healthy, and the remaining 99 get correctly diagnosed as
    sick. Out of the 999,900 healthy patients, 9,999 get misdiagnosed as sick, and
    the remaining 989,901 are correctly diagnosed as healthy.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 可能性的树状图。每个患者可以是患病或健康。对于每一种可能性，患者可以被诊断为患病或健康，这给我们提供了四种可能性。我们从一百万患者开始：其中100人患病，其余的999,900人健康。在这100个患病的人中，有一个人被误诊为健康，其余的99人被正确诊断为患病。在999,900个健康患者中，有9,999人被误诊为患病，其余的989,901人被正确诊断为健康。
- en: From figure 8.2, we can again see that the probability that your friend is sick
    given that he tested positive is 99/99+9.999 = 0.0098, given that he can only
    be in the first and third groups at the right.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 从图8.2中，我们再次可以看到，如果你的朋友测试结果呈阳性，他患病的概率是99/99+9,999 = 0.0098，前提是他只能位于右侧的第一和第三组。
- en: 'Prelude to Bayes’ theorem: The prior, the event, and the posterior'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理的序言：先验、事件和后验
- en: We now have all the tools to state Bayes’ theorem. The main goal of Bayes’ theorem
    is calculating a probability. At the beginning, with no information in our hands,
    we can calculate only an initial probability, which we call the *prior*. Then,
    an event happens, which gives us information. After this information, we have
    a much better estimate of the probability we want to calculate. We call this better
    estimate the *posterior*. The prior, event, and posterior, are illustrated in
    figure 8.3.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了陈述贝叶斯定理的所有工具。贝叶斯定理的主要目标是计算一个概率。一开始，如果我们手中没有任何信息，我们只能计算出初始概率，我们称之为*先验概率*。然后，发生了一个事件，它给我们提供了信息。在这个信息之后，我们对想要计算的概率有了更好的估计。我们称这个更好的估计为*后验概率*。先验、事件和后验在图8.3中得到了说明。
- en: prior The initial probability
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 先验 初始概率
- en: event Something that occurs, which gives us information
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 事件 发生的事情，它给我们提供信息
- en: posterior The final (and more accurate) probability that we calculate using
    the prior probability and the event
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 后验 使用先验概率和事件计算出的最终（更准确）的概率
- en: An example follows. Imagine that we want to find out the probability that it
    will rain today. If we don’t know anything, we can come up with only a rough estimate
    for the probability, which is the prior. If we look around and find out that we
    are in the Amazon rain forest (the event), then we can come up with a much more
    exact estimate. In fact, if we are in the Amazon rain forest, it will probably
    rain today. This new estimate is the posterior.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个例子。想象一下，我们想要找出今天下雨的概率。如果我们一无所知，我们只能对概率给出一个粗略的估计，这就是先验概率。如果我们四处看看，发现我们身处亚马逊雨林（这个事件），那么我们可以给出一个更加精确的估计。事实上，如果我们身处亚马逊雨林，今天很可能下雨。这个新的估计就是后验概率。
- en: '![](../Images/8-31.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8-31.png)'
- en: Figure 8.3 The prior, the event, and the posterior. The prior is the “raw” probability,
    namely, the probability we calculate when we know very little. The event is the
    information that we obtain, which will help us refine our calculation of the probability.
    The posterior is the “cooked” probability, or the much more accurate probability
    that we calculate when we have more information.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 先验、事件和后验。先验是“原始”概率，即当我们知道很少信息时计算的概率。事件是我们获得的信息，它将帮助我们完善对概率的计算。后验是“加工后”的概率，或者是我们拥有更多信息时计算出的更加准确的概率。
- en: 'In our ongoing medical example, we need to calculate the probability that a
    patient is sick. The prior, the event, and the posterior follow:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们正在进行的医学例子中，我们需要计算一个病人生病的概率。先验概率、事件和后验概率如下：
- en: '**Prior**: Initially, this probability is 1/10,000, because we don’t have any
    other information, other than the fact that one out of every 10,000 patients is
    sick. This 1/10,000, or 0.0001, is the prior.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**先验**：最初，这个概率是1/10,000，因为我们没有其他信息，除了知道每10,000个病人中有一个人生病。这个1/10,000，或者说0.0001，就是先验概率。'
- en: '**Event**: All of a sudden, new information comes to light. In this case, the
    patient took a test and tested positive.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件**：突然，新的信息出现了。在这种情况下，病人做了一次测试，并且测试结果呈阳性。'
- en: '**Posterior**: After coming out positive, we recalculate the probability that
    the patient is sick, and that comes out to be 0.0098\. This is the posterior.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后验**：在测试结果呈阳性之后，我们重新计算病人生病的概率，结果是0.0098。这就是后验概率。'
- en: 'Bayes’ theorem is one of the most important building blocks of probability
    and of machine learning. It is so important that several fields are named after
    it, such as *Bayesian learning*, *Bayesian statistics*, and *Bayesian analysis*.
    In this chapter, we learn Bayes’ theorem and an important classification model
    derived from it: the naive Bayes model. In a nutshell, the naive Bayes model does
    what most classification models do, which is predict a label out of a set of'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理是概率论和机器学习最重要的基石之一。它的重要性如此之高，以至于有多个领域以它的名字命名，例如*贝叶斯学习*、*贝叶斯统计学*和*贝叶斯分析*。在本章中，我们将学习贝叶斯定理以及由此派生出的一个重要分类模型：朴素贝叶斯模型。简而言之，朴素贝叶斯模型做的是大多数分类模型都会做的事情，即从一组
- en: features. The model returns the answer in the form of a probability, which is
    calculated using Bayes’ theorem.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 特征。模型以概率的形式返回答案，这个概率是使用贝叶斯定理计算得出的。
- en: 'Use case: Spam-detection model'
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例：垃圾邮件检测模型
- en: The use case that we study in this chapter is a spam-detection model. This model
    helps us separate spam from ham emails. As we discussed in chapters 1 and 7, spam
    is the name given to junk email, and ham is the name given to email that isn’t
    junk.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们研究的用例是一个垃圾邮件检测模型。这个模型帮助我们区分垃圾邮件和正常邮件。正如我们在第1章和第7章所讨论的，垃圾邮件是指垃圾邮件，而正常邮件是指非垃圾邮件。
- en: The naive Bayes model outputs the probability that an email is spam or ham.
    In that way, we can send the emails with the highest probability of being spam
    directly to the spam folder and keep the rest in our inbox. This probability should
    depend on the features of the email, such as its words, sender, size, and so on.
    For this chapter, we consider only the words as features. This example is not
    that different from the sentiment analysis example we studied in chapters 5 and
    6\. The key for this sentiment analysis classifier is that each word has a certain
    probability of appearing in a spam email. For example, the word *lottery* is more
    likely to appear in a spam email than the word *meeting*. This probability is
    the basis of our calculations.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 基于朴素贝叶斯模型，我们可以输出一封邮件是垃圾邮件或正常邮件的概率。这样，我们可以将概率最高的垃圾邮件直接发送到垃圾邮件文件夹，其余的保留在收件箱中。这个概率应该取决于邮件的特征，例如其文字、发件人、大小等。对于本章，我们只考虑文字作为特征。这个例子与我们在第5章和第6章研究的情感分析例子并没有太大的不同。这个情感分析分类器的关键是每个单词在垃圾邮件中出现的概率。例如，单词“彩票”在垃圾邮件中出现的概率比“会议”要高。这个概率是我们计算的基础。
- en: 'Finding the prior: The probability that any email is spam'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找先验概率：任何一封邮件是垃圾邮件的概率
- en: What is the probability that an email is spam? That is a hard question, but
    let’s try to make a rough estimate, which we call the prior. We look at our current
    inbox and count how many emails are spam and ham. Imagine that in 100 emails,
    20 are spam and 80 are ham. Thus, 20% of the emails are spam. If we want to make
    a decent estimate, we can say that *to the best of our knowledge*, the probability
    that a new email is spam is 0.2\. This is the prior probability. The calculation
    is illustrated in figure 8.4, where the spam emails are colored dark gray and
    the ham emails white.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一封邮件是垃圾邮件的概率是多少？这是一个难题，但让我们尝试做出一个粗略的估计，我们称之为先验概率。我们查看当前的收件箱，统计垃圾邮件和正常邮件的数量。想象一下，在100封邮件中，有20封是垃圾邮件，80封是正常邮件。因此，20%的邮件是垃圾邮件。如果我们想要做出一个合理的估计，我们可以认为“据我们所知”，新邮件是垃圾邮件的概率是0.2。这是先验概率。计算过程在图8.4中进行了说明，其中垃圾邮件用深灰色表示，正常邮件用白色表示。
- en: '![](../Images/8-4.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-4.png)'
- en: Figure 8.4 We have a dataset with 100 emails, 20 of which are spam. An estimate
    for the probability that an email is spam is 0.2\. This is the prior probability.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 我们有一个包含100封邮件的数据集，其中20封是垃圾邮件。对一封邮件是垃圾邮件的概率的估计是0.2。这是先验概率。
- en: 'Finding the posterior: The probability that an email is spam, knowing that
    it contains a particular word'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找后验概率：已知邮件包含特定单词时，邮件是垃圾邮件的概率
- en: Of course, not all emails are created equally. We’d like to come up with a more
    educated guess for the probability, using the properties of the email. We can
    use many properties, such as sender, size, or words in the email. For this application,
    we use only the words in the email. However, I encourage you to go through the
    example thinking how this could be used with other properties.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，并不是所有的邮件都是同等重要的。我们希望利用邮件的特性来做出一个更合理的猜测。我们可以使用许多特性，如发件人、大小或邮件中的单词。对于这个应用，我们只使用邮件中的单词。然而，我鼓励你在思考这个例子时，考虑如何使用其他特性。
- en: Let’s say that we find a particular word, say, the word *lottery*, which tends
    to appear more often in spam emails than in ham emails. That word represents our
    event. Among the spam emails, the word *lottery* appears in 15 of them, whereas
    it appears in only 5 of the ham emails. Therefore, among the 20 emails containing
    the word *lottery*, 15 of them are spam, and 5 of them are ham. Thus, the probability
    that an email containing the word *lottery* is spam, is precisely 15/20 = 0.75. That
    is the posterior probability. The process of calculating this probability is illustrated
    in figure 8.5.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们找到一个特定的单词，比如说“彩票”，这个单词在垃圾邮件中比在正常邮件中出现的频率更高。这个单词代表我们的事件。在垃圾邮件中，“彩票”这个单词出现在15封邮件中，而在正常邮件中只出现在5封邮件中。因此，在包含“彩票”这个单词的20封邮件中，有15封是垃圾邮件，5封是正常邮件。因此，包含“彩票”这个单词的邮件是垃圾邮件的概率正好是15/20
    = 0.75。这就是后验概率。计算这个概率的过程在图8.5中进行了说明。
- en: '![](../Images/8-5.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-5.png)'
- en: Figure 8.5 We have removed (grayed out) the emails that don’t contain the word
    *lottery*. All of a sudden, our probabilities change. Among the emails that contain
    the word *lottery*, there are 15 spam emails and 5 ham emails, so the probability
    that an email containing the word *lottery* is spam, is 15/20 = 0.75.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5 我们移除了（灰色显示）不包含单词*lottery*的邮件。突然之间，我们的概率发生了变化。在包含单词*lottery*的邮件中，有15封是垃圾邮件，5封是正常邮件，所以包含单词*lottery*的邮件是垃圾邮件的概率是15/20
    = 0.75。
- en: 'There we have it: we’ve calculated the probability that an email is spam given
    that it contains the word *lottery*. To summarize:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样：我们计算了包含单词*lottery*的邮件是垃圾邮件的概率。为了总结：
- en: The **prior** probability is 0.2\. This is the probability that an email is
    spam, knowing nothing about the email.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**先验**概率是0.2。这是在不知道任何关于邮件信息的情况下，邮件是垃圾邮件的概率。'
- en: The **event** is that the email contains the word *lottery*. This helps us make
    a better estimate of the probability.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件**是邮件包含单词*lottery*。这有助于我们更好地估计概率。'
- en: The **posterior** probability is 0.75\. This is the probability that the email
    is spam, *given that* it contains the word *lottery*.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后验**概率是0.75。这是在知道邮件包含单词*lottery*的情况下，邮件是垃圾邮件的概率。'
- en: In this example, we calculated the probability by counting emails and dividing.
    This is mostly done for pedagogical purposes, but in real life, we can use a shortcut
    to calculate this probability using a formula. This formula is called Bayes’ theorem,
    and we see it next.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们通过计数邮件并除以来计算概率。这主要是为了教学目的，但在现实生活中，我们可以使用一个公式来计算这个概率的捷径。这个公式被称为贝叶斯定理，我们将在下一部分看到。
- en: What the math just happened? Turning ratios into probabilities
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 数学刚刚发生了什么？将比率转换为概率
- en: 'One way to visualize the previous example is with a tree of all four possibilities,
    just as we did with the medical example in figure 8.2\. The possibilities are
    that the email is spam or ham, and that it contains the word *lottery* or not.
    We draw it in the following way: we start with the root, which splits into two
    branches. The top branch corresponds to spam, and the bottom branch corresponds
    to ham. Each of the branches splits into two more branches, namely, when the email
    contains the word *lottery* and when it does not. The tree is illustrated in figure
    8.6\. Notice that in this tree, we’ve also indicated how many emails out of the
    total 100 belong to each particular group.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可视化前一个例子方法是使用所有四种可能性的树形图，就像我们在图8.2中的医疗例子中所做的那样。可能性是邮件是垃圾邮件或正常邮件，以及它是否包含单词*lottery*。我们这样绘制它：我们从根节点开始，它分为两个分支。上面的分支对应垃圾邮件，下面的分支对应正常邮件。每个分支再分为两个更小的分支，即邮件包含单词*lottery*和不包含时。树形图如图8.6所示。注意，在这个树形图中，我们还指出了在总共100封邮件中，每个特定组有多少封邮件。
- en: '![](../Images/8-6.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-6.png)'
- en: 'Figure 8.6 The tree of possibilities. The root splits into two branches: spam
    and ham. Then each of these splits into two branches: when the email contains
    the word *lottery*, and when it doesn’t.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6 可能性树。根节点分为两个分支：垃圾邮件和正常邮件。然后每个分支再分为两个分支：当邮件包含单词*lottery*时，和不包含时。
- en: Once we have this tree, and we want to calculate the probability that an email
    is spam *given that* it contains the word *lottery*, we simply remove all the
    branches in which the emails don’t contain the word *lottery*. This is illustrated
    in figure 8.7.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了这个树形图，并且想要计算包含单词*lottery*的邮件是垃圾邮件的概率，我们只需移除所有不包含单词*lottery*的分支。这如图8.7所示。
- en: '![](../Images/8-7.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-7.png)'
- en: Figure 8.7 From the previous tree, we have removed the two branches where the
    emails don’t contain the word *lottery*. Out of the original 100 emails, we have
    20 left that contain *lottery*. Because of these 20 emails, 15 are spam, we conclude
    that the probability that an email is spam given that it contains the word  *lottery*
    is 0.75.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 从之前的树形图中，我们移除了不包含单词*lottery*的两个分支。在最初的100封邮件中，我们剩下20封包含*lottery*。由于这20封邮件，其中15封是垃圾邮件，我们得出结论，包含单词*lottery*的邮件是垃圾邮件的概率是0.75。
- en: Now, we have 20 emails, and of them, 15 are spam and 5 are ham. Thus, the probability
    that an email is spam given that it contains the word *lottery* is ![](../Images/08_07_E01.png).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有20封邮件，其中15封是垃圾邮件，5封是正常邮件。因此，包含单词*lottery*的邮件是垃圾邮件的概率是![图片](../Images/08_07_E01.png)。
- en: 'But we’ve already done that, so what is the benefit of the diagram? Aside from
    making things simpler, the benefit is that normally, the information we have is
    based on probabilities, and not on the number of emails. Many times, we don’t
    know how many emails are spam or ham. All we know is the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们已经计算过了，那么图表有什么好处呢？除了使事情更简单之外，好处是通常我们所拥有的信息是基于概率的，而不是基于邮件的数量。很多时候，我们不知道垃圾邮件或正常邮件的数量。我们所知道的是以下信息：
- en: The probability that an email is spam is ![](../Images/08_07_E02.png).
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一封邮件是垃圾邮件的概率是 ![图片](../Images/08_07_E02.png)。
- en: The probability that a spam email contains the word *lottery* is ![](../Images/08_07_E03.png) .
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垃圾邮件包含单词*lottery*的概率是 ![图片](../Images/08_07_E03.png)。
- en: The probability that a ham email contains the word *lottery* is ![](../Images/08_07_E04.png).
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一封正常邮件包含单词*lottery*的概率是 ![图片](../Images/08_07_E04.png)。
- en: '**Question**: What is the probability that an email that contains the word
    lottery is spam?'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问题**：包含单词*lottery*的邮件是垃圾邮件的概率是多少？'
- en: First, let’s check if this is enough information. Do we know the probability
    that an email is ham? Well, we know that the probability that it is spam is ![](../Images/08_07_E05.png).
    The *only* other possibility is that an email is ham, so it must be the complement,
    or ![](../Images/08_07_E06.png). This is an important rule—the rule of complementary
    probabilities.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们检查这些信息是否足够。我们知道邮件是正常邮件的概率吗？嗯，我们知道邮件是垃圾邮件的概率是 ![图片](../Images/08_07_E05.png)。唯一的另一种可能性是邮件是正常邮件，所以它必须是补集，即
    ![图片](../Images/08_07_E06.png)。这是一条重要的规则——互补概率规则。
- en: rule of complementary probabilities For an event *E*, the complement of the
    event *E*, denoted *E*^c, is the event opposite to *E*. The probability of *E*^c
    is 1 minus the probability of *E*, namely,
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 互补概率规则 对于事件*E*，事件*E*的补集，表示为*E*^c，是与*E*相反的事件。*E*^c的概率是1减去*E*的概率，即，
- en: '*P*(*E*^c) = 1 − *P*(*E*)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*P*(*E*^c) = 1 − *P*(*E*)'
- en: 'Therefore, we have the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有以下：
- en: '![](../Images/08_07_Eb01.png): the probability of an email being spam'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![图片](../Images/08_07_Eb01.png)：邮件是垃圾邮件的概率'
- en: '![](../Images/08_07_Eb02.png): the probability of an email being ham'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![图片](../Images/08_07_Eb02.png)：邮件是正常邮件的概率'
- en: 'Now let’s look at the other information. The probability that a spam email
    contains the word *lottery* is ![](../Images/08_07_E03.png). This can be read
    as, the probability that an email contains the word *lottery* *given that* it
    is spam, is 0.75\. This is a conditional probability, where the condition is that
    the email is spam. We denote condition by a vertical bar, so this can be written
    as *P*(*''lottery''*|*spam*). The complement of this is *P*(*no ''lottery''*|*spam*),
    namely, the probability that a spam email does *not* contain the word *lottery*.
    This probability is 1 – *P*(*''lottery''*|*spam*). This way, we can calculate
    other probabilities as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看其他信息。垃圾邮件包含单词*lottery*的概率是 ![图片](../Images/08_07_E03.png)。这可以理解为，邮件包含单词*lottery*且邮件是垃圾邮件的概率是0.75。这是一个条件概率，条件是邮件是垃圾邮件。我们用竖线表示条件，所以这可以写成*P*(*'lottery'*|*spam*)。这个条件的补集是*P*(*no
    'lottery'*|*spam*)，即垃圾邮件不包含单词*lottery*的概率。这个概率是1 – *P*(*'lottery'*|*spam*)。这样，我们可以计算出其他概率，如下所示：
- en: '![](../Images/08_07_Eb03.png): the probability that a spam email contains the
    word *lottery*.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![图片](../Images/08_07_Eb03.png)：垃圾邮件包含单词*lottery*的概率。'
- en: '![](../Images/08_07_Eb04.png): the probability that a spam email does not contain
    the word *lottery*.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![图片](../Images/08_07_Eb04.png)：垃圾邮件不包含单词*lottery*的概率。'
- en: '![](../Images/08_07_Eb05.png): the probability that a ham email contains the
    word *lottery*.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![图片](../Images/08_07_Eb05.png)：正常邮件包含单词*lottery*的概率。'
- en: '![](../Images/08_07_Eb06.png): the probability that a ham email does not contain
    the word *lottery*.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![图片](../Images/08_07_Eb06.png)：正常邮件不包含单词*lottery*的概率。'
- en: 'The next thing we do is find the probabilities of two events happening *at
    the same time*. More specifically, we want the following four probabilities:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来要做的是找到两个事件同时发生的概率。更具体地说，我们想要以下四个概率：
- en: The probability that an email is spam and contains the word *lottery*
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一封邮件是垃圾邮件且包含单词*lottery*的概率
- en: The probability that an email is spam *and* does not contain the word *lottery*
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一封邮件是垃圾邮件且不包含单词*lottery*的概率
- en: The probability that an email is ham *and* contains the word *lottery*
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一封邮件是正常邮件且包含单词*lottery*
- en: The probability that an email is ham and does not contain the word *lottery*
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一封邮件是正常邮件且不包含单词*lottery*的概率
- en: 'These events are called *intersections* of events and denoted with the symbol
    ∩. Thus, we need to find the following probabilities:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这些事件被称为事件的*交集*，并用符号∩表示。因此，我们需要找到以下概率：
- en: '*P*(*''lottery''* ∩ *spam*)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*''lottery''* ∩ *spam*)'
- en: '*P*(*no ''lottery''* ∩ *spam*)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*no ''lottery''* ∩ *spam*)'
- en: '*P*(*''lottery''* ∩ *ham*)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*''lottery''* ∩ *ham*)'
- en: '*P*(*no ''lottery''* ∩ *ham*)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*no ''lottery''* ∩ *ham*)'
- en: 'Let’s look at some numbers. We know that ![](../Images/08_07_Ec_frac1-5.png),
    or 20 out of 100, of emails are spam. Out of those 20, ![](../Images/08_07_Ec_frac3-4.png)
    of them contain the word *lottery*. At the end, we multiply these two numbers,
    ![](../Images/08_07_Ec_frac1-5.png) times ![](../Images/08_07_Ec_frac3-4.png),
    to obtain ![](../Images/08_07_Ec_frac3-20.png), which is the same as ![](../Images/08_07_Ec_frac15-100.png)
    , the proportion of emails that are spam and contain the word lottery. What we
    did was the following: we multiplied the probability that an email is spam times
    the probability that a spam email contains the word lottery, to obtain the probability
    that an email is spam and contains the word lottery. The probability that a spam
    email contains the word *lottery* is precisely the conditional probability, or
    the probability that an email contains the word *lottery* *given that* it is a
    spam email. This gives rise to the multiplication rule for probabilities.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些数字。我们知道![图片](../Images/08_07_Ec_frac1-5.png)，或者说100封邮件中有20封是垃圾邮件。在这20封中，![图片](../Images/08_07_Ec_frac3-4.png)包含单词*lottery*。最后，我们将这两个数字相乘，![图片](../Images/08_07_Ec_frac1-5.png)乘以![图片](../Images/08_07_Ec_frac3-4.png)，得到![图片](../Images/08_07_Ec_frac3-20.png)，这与![图片](../Images/08_07_Ec_frac15-100.png)相同，即包含单词*lottery*的垃圾邮件的比例。我们所做的是以下：我们将邮件是垃圾邮件的概率乘以垃圾邮件包含单词*lottery*的概率，以获得邮件是垃圾邮件且包含单词*lottery*的概率。垃圾邮件包含单词*lottery*的概率正是条件概率，即邮件包含单词*lottery*的条件概率。这导致了概率的乘法法则。
- en: Product rule of probabilities For events *E* and *F*, the probability of their
    intersection is the product of the conditional probability of F given E, times
    the probability of F, namely, *P*(*E* ∩ *F*) = *P*(*E*|*F*) ∩ *P*(*F*).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 概率的乘法法则 对于事件*E*和*F*，它们交集的概率是F在E条件下的条件概率乘以F的概率，即*P*(*E* ∩ *F*) = *P*(*E*|*F*)
    ∩ *P*(*F*)。
- en: 'Now we can calculate these probabilities as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以按照以下方式计算这些概率：
- en: '![](../Images/08_07_Ed01.png)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图片](../Images/08_07_Ed01.png)'
- en: '![](../Images/08_07_Ed02.png)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图片](../Images/08_07_Ed02.png)'
- en: '![](../Images/08_07_Ed03.png)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图片](../Images/08_07_Ed03.png)'
- en: '![](../Images/08_07_Ed04.png)'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图片](../Images/08_07_Ed04.png)'
- en: These probabilities are summarized in figure 8.8\. Notice that the product of
    the probabilities on the edges are the probabilities at the right. Furthermore,
    notice that the sum of all these four probabilities is one, because they encompass
    all the possible scenarios.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概率总结在图8.8中。请注意，边上的概率乘积是右侧的概率。此外，请注意，所有这些四个概率的总和为1，因为它们涵盖了所有可能的场景。
- en: '![](../Images/8-81.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-81.png)'
- en: 'Figure 8.8 The same tree from figure 8.6, but now with probabilities. From
    the root, two branches emerge, one for spam emails and one for ham emails. In
    each one, we record the corresponding probability. Each branch again splits into
    two leaves: one for emails containing the word *lottery*, and one for emails not
    containing it. In each branch we record the corresponding probability. Notice
    that the product of these probabilities is the probability at the right of each
    leaf. For example, for the top leaf, 1/5 · 3/4 = 3/20 = 0.15.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8 8.6图中的同一棵树，但现在加入了概率。从根节点出发，有两个分支，一个用于垃圾邮件，一个用于正常邮件。在每个分支中，我们记录相应的概率。每个分支再次分为两个叶子节点：一个用于包含单词*lottery*的邮件，另一个用于不包含它的邮件。在每个分支中，我们记录相应的概率。请注意，这些概率的乘积是每个叶子节点右侧的概率。例如，对于顶部的叶子节点，1/5
    · 3/4 = 3/20 = 0.15。
- en: 'We’re almost done. We want to find *P*(*spam*|*''lottery''*), which is the
    probability that an email is spam *given that* it contains the word *lottery*.
    Among the four events we just studied, in only two of them does the word *lottery*
    appear. Thus, we need to consider only those, namely:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎完成了。我们想要找到*P*(*spam*|*'lottery'*)，即在邮件包含单词*lottery*的情况下邮件是垃圾邮件的概率。在我们刚刚研究的四个事件中，只有两个事件出现了单词*lottery*。因此，我们只需要考虑这些，即：
- en: '![](../Images/08_08_Ea01.png)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图片](../Images/08_08_Ea01.png)'
- en: '![](../Images/08_08_Ea02.png)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图片](../Images/08_08_Ea02.png)'
- en: In other words, we need to consider only the two branches shown in figure 8.9—the
    first and the third, namely, those in which the email contains the word *lottery*.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们只需要考虑图8.9中显示的两个分支——第一个和第三个，即包含单词*lottery*的邮件。
- en: '![](../Images/8-91.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-91.png)'
- en: Figure 8.9 From the tree in figure 8.8, we have removed the two branches where
    the emails don’t contain the word *lottery*.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9 从图8.8中的树中，我们移除了不包含单词 *lottery* 的两个分支。
- en: 'The first one is the probability that an email is spam, and the second one
    is the probability that the email is ham. These two probabilities don’t add to
    one. However, because we now live in a world in which the email contains the word
    lottery, then these two are the only possible scenarios. Thus, their probabilities
    should add to 1\. Furthermore, they should still have the same relative ratio
    with respect to each other. The way to fix this is to normalize—to find two numbers
    that are in the same relative ratio with respect to each other as ![](../Images/08_09_Ea_frac3-20.png)
    and ![](../Images/08_09_Ea_frac1-20.png) but that add to one. The way to find
    these is to divide both by the sum. In this case, the numbers become ![](../Images/08_09_E01.png)
    and ![](../Images/08_09_E02.png). These simplify to 3/4 and 1/4 , which are the
    desired probabilities. Thus, we conclude the following:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个是一个邮件是垃圾邮件的概率，第二个是邮件是正常邮件（ham）的概率。这两个概率相加不等于1。然而，因为我们现在生活在一个邮件包含单词 *lottery*
    的世界里，所以这两个是唯一可能的场景。因此，它们的概率应该相加等于1。此外，它们应该仍然保持相同的相对比例。解决这个问题的方式是归一化——找到两个彼此之间保持相同相对比例的数字，就像
    ![图片](../Images/08_09_Ea_frac3-20.png) 和 ![图片](../Images/08_09_Ea_frac1-20.png)
    那样，但它们的和为1。找到这些数字的方法是将它们各自除以它们的和。在这种情况下，数字变成了 ![图片](../Images/08_09_E01.png) 和
    ![图片](../Images/08_09_E02.png)。它们简化为 3/4 和 1/4，这就是我们想要的概率。因此，我们得出以下结论：
- en: '![](../Images/08_09_E03.png)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图片](../Images/08_09_E03.png)'
- en: '![](../Images/08_09_E04.png)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![图片](../Images/08_09_E04.png)'
- en: 'This is exactly what we figured out when we counted the emails. To wrap up
    this information, we need a formula. We had two probabilities: the probability
    that an email is spam *and* contains the word *lottery*, and the probability that
    an email is spam *and* does not contain the word *lottery*. To get them to add
    to one, we normalized them. This is the same thing as dividing each one of them
    by their sum. In math terms, we did the following:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们在计算邮件时得出的结论。为了总结这些信息，我们需要一个公式。我们有两个概率：一封邮件是垃圾邮件并且包含单词 *lottery* 的概率，以及一封邮件是垃圾邮件但不包含单词
    *lottery* 的概率。为了使它们相加等于1，我们对它们进行了归一化。这相当于将它们各自除以它们的和。用数学术语来说，我们做了以下操作：
- en: '![](../Images/08_09_E05.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_09_E05.png)'
- en: 'If we remember what these two probabilities were, using the product rule, we
    get the following:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们记得这两个概率是什么，使用乘法法则，我们得到以下结果：
- en: '![](../Images/08_09_E06.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_09_E06.png)'
- en: 'To verify, we plug in the numbers to get:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证，我们将数字代入得到：
- en: '![](../Images/08_09_E07.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_09_E07.png)'
- en: 'This is the formula for Bayes’ theorem! More formally:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是贝叶斯定理的公式！更正式地说：
- en: Bayes theorem For events E and F,
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理 对于事件 E 和 F，
- en: '![](../Images/08_09_E08.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_09_E08.png)'
- en: Because the event *F* can be broken down into the two disjoint events *F*|*E*
    and *F*|*E*^c, then
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 因为事件 *F* 可以分解为两个不相交的事件 *F*|*E* 和 *F*|*E*^c，所以
- en: '![](../Images/08_09_E09.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_09_E09.png)'
- en: What about two words? The naive Bayes algorithm
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 那么对于两个单词呢？朴素贝叶斯算法
- en: In the previous section we calculated the probability that an email is spam
    given that it contains the keyword *lottery*. However, the dictionary contains
    many more words, and we’d like to calculate the probability that an email is spam
    given that it contains several words. As you can imagine, the calculations get
    more complicated, but in this section, we learn a trick that helps us estimate
    this probability.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们计算了当邮件包含关键字 *lottery* 时，邮件是垃圾邮件的概率。然而，字典中包含许多更多的单词，我们希望计算邮件包含几个单词时，邮件是垃圾邮件的概率。正如你所想象的那样，计算变得更加复杂，但在本节中，我们学习了一个帮助我们估计这个概率的技巧。
- en: 'In general, the trick helps us calculate a posterior probability based on two
    events instead of one (and it easily generalizes to more than two events). It
    is based on the premise that when events are independent, the probability of both
    occurring at the same time is the product of their probabilities. Events are not
    always independent, but assuming they are sometimes helps us make good approximations.
    For example, imagine the following scenario: there is an island with 1,000 people.
    Half of the inhabitants (500) are women, and one-tenth of the inhabitants (100)
    have brown eyes. How many of the inhabitants do you think are women with brown
    eyes? If all we know is this information, we can’t find out unless we count them
    in person. However, if we assume that gender and eye color are independent, then
    we can estimate that half of one tenth of the population consists of women with
    brown eyes. That is ![](../Images/08_09_Eb01.png) of the population. Because the
    total population is 1,000 people, our estimate for the number of women with brown
    eyes is ![](../Images/08_09_Eb02.png) people. Maybe we go to the island and find
    out that that’s not the case, but *to the* *best of our knowledge*, 50 is a good
    estimate. One may say that our assumption about the independence of gender and
    eye color was *naive*, and maybe it was, but it was the best estimate we could
    come up with given the information we had.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这个技巧帮助我们基于两个事件而不是一个事件来计算后验概率（并且它很容易推广到两个以上事件）。它基于以下前提：当事件是独立的，两个事件同时发生的概率是它们概率的乘积。事件并不总是独立的，但假设它们有时是独立的，这有助于我们做出良好的近似。例如，想象以下场景：有一个有1000人的岛屿。岛上的居民中有一半（500人）是女性，十分之一（100人）有棕色眼睛。你认为有多少居民是女性且有棕色眼睛？如果我们只知道这些信息，我们就无法找出答案，除非我们亲自计数。然而，如果我们假设性别和眼睛颜色是独立的，那么我们可以估计，十分之一的一半的人口是由女性和棕色眼睛的人组成。也就是说，![图片](../Images/08_09_Eb01.png)的人口。因为总人口是1000人，我们对于女性棕色眼睛人数的估计是![图片](../Images/08_09_Eb02.png)人。也许我们会去岛屿上并发现情况并非如此，但根据我们*所知最好的情况*，50是一个很好的估计。有人可能会说，我们对性别和眼睛颜色独立性的假设是*天真*的，也许它确实是，但这是在给定信息的情况下我们能做出的最佳估计。
- en: 'The rule we used in the previous example is the product rule for independent
    probabilities, which states the following:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个例子中我们使用的规则是独立概率的乘法法则，它表述如下：
- en: product rule for independent probabilities If two events *E* and *F* are independent,
    namely, the occurrence of one doesn’t influence in any way the occurrence of the
    other one, then the probability of both happening (the intersection of the events)
    is the product of the probabilities of each of the events. In other words,
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 独立概率的乘法法则 如果两个事件 *E* 和 *F* 是独立的，即一个事件的发生不会以任何方式影响另一个事件的发生，那么两个事件同时发生的概率（事件的交集）是每个事件概率的乘积。换句话说，
- en: '*P*(*E* ∩ *F*) = *P*(*E*) · *P*(*F*).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*P*(*E* ∩ *F*) = *P*(*E*) · *P*(*F*).'
- en: 'Back to the email example. After we figured out the probability that an email
    is spam given that it contains the word *lottery*, we noticed that another word,
    *sale*, also tends to appear a lot in spam email. We’d like to figure out the
    probability that an email is spam given that it contains both *lottery* and *sale*.
    We begin by counting how many spam and ham emails contain the word *sale* and
    find that it appears in 6 of the 20 spam emails and 4 of the 80 ham emails. Thus,
    the probabilities are the following (illustrated in figure 8.10):'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 回到电子邮件的例子。在我们计算出包含“彩票”一词的电子邮件是垃圾邮件的概率后，我们注意到另一个词“销售”也经常出现在垃圾邮件中。我们想要找出包含“彩票”和“销售”两个词的电子邮件是垃圾邮件的概率。我们首先计算包含“销售”一词的垃圾邮件和正常邮件的数量，发现它在20封垃圾邮件中的6封和80封正常邮件中的4封中出现。因此，概率如下（如图8.10所示）：
- en: '![](../Images/08_09_Ec01.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_09_Ec01.png)'
- en: '![](../Images/8-101.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-101.png)'
- en: Figure 8.10 In a similar calculation as for the word *lottery*, we look at the
    emails containing the word *sale*. Among these (not grayed-out) emails, there
    are six spam and four ham.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10 在与“彩票”一词类似的计算中，我们查看包含“销售”一词的电子邮件。在这些（未灰显的）电子邮件中，有六个垃圾邮件和四个正常邮件。
- en: 'One can use Bayes’ theorem again to conclude that the probability that an email
    is spam given that it contains the word *sale* is 0.6, and I encourage you to
    go through the calculations yourself. However, the more important question is:
    what is the probability that an email is spam given that it contains the words
    *lottery* and *sale* at the same time? Before we do this, let’s find the probability
    that an email contains the words *lottery* and *sale* given that it is spam. This
    should be easy: we go through all our emails and find how many of the spam emails
    have the words *lottery* and *sale*.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 可以再次使用贝叶斯定理来得出结论，即一个电子邮件包含单词 *销售* 时是垃圾邮件的概率为 0.6，我鼓励你自己进行计算。然而，更重要的问题是：一个电子邮件同时包含单词
    *彩票* 和 *销售* 时是垃圾邮件的概率是多少？在我们进行这个计算之前，让我们先找出一个电子邮件包含单词 *彩票* 和 *销售* 时它是垃圾邮件的概率。这应该很容易：我们查看所有电子邮件，找出有多少垃圾邮件包含这两个单词。
- en: However, we may run into the problem that there are no emails with the words
    *lottery* and *sale*. We have only 100 emails, and when we are trying to find
    two words on them, we may not have enough to be able to properly estimate a probability.
    What can we do? One possible solution is to collect more data, until we have so
    many emails that it’s likely that the two words appear in some of them. However,
    the case may be that we can’t collect any more data, so we have to work with what
    we have. This is where the naive assumption will help us.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可能会遇到没有包含单词 *彩票* 和 *销售* 的电子邮件的问题。我们只有 100 封电子邮件，当我们试图在这封电子邮件上找到两个单词时，我们可能没有足够的样本来正确估计概率。我们能做什么呢？一个可能的解决方案是收集更多的数据，直到我们拥有如此多的电子邮件，以至于有可能其中一些包含这两个单词。然而，可能的情况是我们无法收集更多的数据，所以我们只能利用我们已有的数据。这就是天真假设能帮到我们的地方。
- en: 'Let’s try to estimate this probability in the same way that we estimated the
    number of women with brown eyes on the island at the beginning of this section.
    We know that the probability that the word *lottery* appears in a spam email is
    0.75, from the previous section. From earlier in this section, the probability
    that *sale* appears in a spam email is 0.6\. Thus, if we naively assume that the
    appearances of these two words are independent, the probability that both words
    appear in a spam email is 0.75 · 0.3 = 0.225\. In a similar fashion, because we
    calculated that the probabilities of a ham email containing the word *lottery*
    is 0.0625 and containing the word *sale* is 0.05, then the probability of a ham
    email containing both is 0.0625 · 0.05 = 0.003125\. In other words, we’ve done
    the following estimations:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试以与我们在本节开头估计岛屿上棕色眼睛女性数量相同的方式估计这个概率。我们知道，根据前一小节，单词 *彩票* 出现在垃圾邮件中的概率是 0.75。在本节较早的部分，*销售*
    出现在垃圾邮件中的概率是 0.6。因此，如果我们天真地假设这两个单词的出现是独立的，那么这两个单词同时出现在垃圾邮件中的概率是 0.75 · 0.3 = 0.225。以类似的方式，因为我们计算出包含单词
    *彩票* 的火腿邮件的概率是 0.0625，包含单词 *销售* 的概率是 0.05，那么包含这两个单词的火腿邮件的概率是 0.0625 · 0.05 = 0.003125。换句话说，我们已经做了以下估计：
- en: '*P*(*''lottery''*, *''sale''*|*spam*) = *P*(*''lottery''*|*spam*) *P*(*''sale''*|*spam*)
    = 0.75 · 0.3      = 0.225'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*''彩票''*, *''销售''*|*垃圾邮件*) = *P*(*''彩票''*|*垃圾邮件*) *P*(*''销售''*|*垃圾邮件*)
    = 0.75 · 0.3 = 0.225'
- en: '*P*(*''lottery''* , *''sale''*|*ham*) = *P*(*''lottery''*|*ham*) *P*(*''sale''*|*ham*)
      = 0.0625 · 0.05 = 0.003125'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*P*(*''彩票''* , *''销售''*|*火腿*) = *P*(*''彩票''*|*火腿*) *P*(*''销售''*|*火腿*) = 0.0625
    · 0.05 = 0.003125'
- en: 'The naive assumption we’ve made follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所做天真假设如下：
- en: naive assumption The words appearing in an email are completely independent
    of each other. In other words, the appearance of a particular word in an email
    in no way affects the appearance of another one.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 天真假设：电子邮件中出现的单词彼此完全独立。换句话说，一个特定单词在电子邮件中的出现不会以任何方式影响另一个单词的出现。
- en: Most likely, the naive assumption is not true. The appearance of one word can
    sometimes heavily influence the appearance of another. For example, if an email
    contains the word *salt*, then the word *pepper* is more likely to appear in this
    email, because many times they go together. This is why our assumption is naive.
    However, it turns out that this assumption works well in practice, and it simplifies
    our math a lot. It is called the product rule for probabilities and is illustrated
    in figure 8.11.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，这种天真假设是不正确的。一个词的出现有时会极大地影响另一个词的出现。例如，如果一个电子邮件包含单词 *盐*，那么在这个电子邮件中出现 *胡椒*
    的可能性就更大，因为它们经常一起出现。这就是我们的假设之所以天真。然而，实际上这个假设效果很好，它极大地简化了我们的数学计算。这被称为概率乘法定律，如图 8.11
    所示。
- en: Now that we have estimates for the probabilities, we proceed to find the expected
    number of spam and ham emails that contain the words *lottery* and *sale*.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了概率的估计值，我们继续寻找包含单词*lottery*和*sale*的垃圾邮件和正常邮件的期望数量。
- en: Because there are 20 spam emails, and the probability that a spam email contains
    both words is 0.45, the expected number of spam emails containing both words is
    20 · 0.225 = 4.5.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为有20封垃圾邮件，且垃圾邮件同时包含这两个单词的概率是0.45，所以同时包含这两个单词的垃圾邮件的期望数量是20 · 0.225 = 4.5。
- en: Similarly, there are 80 ham emails, and the probability that a ham email contains
    both words is 0.00325, so the expected number of ham emails containing both words
    is 80 · 0.00325 = 0.25.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同样，有80封正常邮件，且正常邮件同时包含这两个单词的概率是0.00325，所以同时包含这两个单词的正常邮件的期望数量是80 · 0.00325 = 0.25。
- en: '![](../Images/8-112.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-112.png)'
- en: Figure 8.11 Say 20% of the emails contain the word *lottery*, and 10% of the
    emails contain the word *sale*. We make the naive assumption that these two words
    are independent of each other. Under this assumption, the percentage of emails
    that contain both words can be estimated as 2%, namely, the product of 20% and
    10%.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11 假设有20%的邮件包含单词*lottery*，10%的邮件包含单词*sale*。我们做出一个简单的假设，即这两个单词相互独立。在这个假设下，包含这两个单词的邮件的百分比可以估计为2%，即20%和10%的乘积。
- en: The previous calculations imply that if we restrict our dataset to only emails
    that contain both the words *lottery* and *sale*, we expect 4.5 of them to be
    spam and 0.25 to be ham. Thus, if we were to pick one at random among these, what
    is the probability that we pick one that is spam? This may look harder with nonintegers
    than with integers, but if we look at figure 8.12, this may be more clear. We
    have 4.5 spam emails and 0.25 ham emails (this is exactly one-fourth of an email).
    If we throw a dart and it falls in one of the emails, what’s the probability that
    it landed on a spam email? Well, the total number of emails (or the total area,
    if you’d like to imagine it that way) is 4.5 + 0.25 = 4.75\. Because 4.5 are spam,
    the probability that the dart landed on spam is 4.5/4.75 = 0.9474\. This means
    that an email with the words *lottery* and *sale* has a 94.74% probability of
    being spam. That is quite high!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的计算表明，如果我们只将数据集限制为包含单词*lottery*和*sale*的邮件，我们预计其中4.5封是垃圾邮件，0.25封是正常邮件。因此，如果我们随机从中选择一封，选择到垃圾邮件的概率是多少？这看起来可能比整数更难，但如果我们看图8.12，这可能会更清楚。我们有4.5封垃圾邮件和0.25封正常邮件（这正好是四分之一封邮件）。如果我们扔一个飞镖，它落在邮件上，那么它落在垃圾邮件上的概率是多少？嗯，邮件的总数（或者如果你愿意这样想象，总面积）是4.5
    + 0.25 = 4.75。因为4.5是垃圾邮件，飞镖落在垃圾邮件上的概率是4.5/4.75 = 0.9474。这意味着包含单词*lottery*和*sale*的邮件有94.74%的概率是垃圾邮件。这相当高！
- en: '![](../Images/8-121.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/8-121.png)'
- en: Figure 8.12 We have 4.5 spam emails and 0.25 ham emails. We throw a dart, and
    it hits one of the emails. What is the probability that it hit a spam email? The
    answer is 94.74%.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12 我们有4.5封垃圾邮件和0.25封正常邮件。我们扔一个飞镖，它击中了一封邮件。击中垃圾邮件的概率是多少？答案是94.74%。
- en: What we did here, using probability, was employing Bayes’ theorem, except with
    the events
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用概率论，运用贝叶斯定理，除了事件
- en: '*E* = *lottery* ∩ *sale*'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*E* = *lottery* ∩ *sale*'
- en: '*F* = *spam*'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*F* = *spam*'
- en: to get the formula
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 得到公式
- en: '![](../Images/08_12_E01.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_12_E01.png)'
- en: 'Then we (naively) assumed that the appearances of the words *lottery* and *sale*
    were independent among spam (and ham) emails, to get the following two formulas:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们（天真地）假设单词*lottery*和*sale*在垃圾邮件（和正常邮件）中的出现是独立的，得到以下两个公式：
- en: '*P*(*lottery* ∩ *sale*|*spam*) = *P*(*lottery*|*spam*) · *P*(*sale*|*spam*)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*P*(*lottery* ∩ *sale*|*spam*) = *P*(*lottery*|*spam*) · *P*(*sale*|*spam*)'
- en: '*P(lottery* ∩ *sale | ham) = P(lottery | ham)* · *P(sale | ham)*'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '*P(lottery* ∩ *sale | ham) = P(lottery | ham)* · *P(sale | ham)*'
- en: Plugging them into the previous formula, we get
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 将它们代入前面的公式，我们得到
- en: '![](../Images/08_12_E02.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_12_E02.png)'
- en: 'Finally, plugging in the following values:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，代入以下值：
- en: '![](../Images/08_12_E02b.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_12_E02b.png)'
- en: we get
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到
- en: '![](../Images/08_12_E03.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_12_E03.png)'
- en: What about more than two words?
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果有超过两个单词呢？
- en: In the general case, the email has *n* words *x*[1], *x*[2], … , *x*[n]. Bayes’
    theorem states that the probability of an email being spam given that it contains
    the words *x*[1], *x*[2], … , *x*[n] is
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在一般情况下，邮件有*n*个单词*x*[1]，*x*[2]，… ，*x*[n]。贝叶斯定理表明，给定邮件包含单词*x*[1]，*x*[2]，… ，*x*[n]，邮件是垃圾邮件的概率是
- en: '![](../Images/08_12_E04.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08_12_E04.png)'
- en: In the previous equation we removed the intersection sign and replaced it with
    a comma. The naive assumption is that the appearances of all these words are independent.
    Therefore,
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，我们移除了交集符号，并用逗号替换了它。朴素假设是所有这些单词的出现是独立的。因此，
- en: '*P*(*x*[1], *x*[2], … , *x*[n] | *spam*) = *P*(*x*[1] | *spam*) *P*(*x*[2]
    | *spam*) … *P*(*x*[n] | *spam*)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '*P*(*x*[1], *x*[2], … , *x*[n] | *spam*) = *P*(*x*[1] | *spam*) *P*(*x*[2]
    | *spam*) … *P*(*x*[n] | *spam*)'
- en: and
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '*P*(*x*[1], *x*[2], … , *x*[n] | *ham*) = *P*(*x*[1] | *ham*) *P*(*x*[2] |
    ham) … *P*(*x*[n] | *ham*).'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '*P*(*x*[1], *x*[2], … , *x*[n] | *ham*) = *P*(*x*[1] | *ham*) *P*(*x*[2] |
    ham) … *P*(*x*[n] | *ham*).'
- en: Putting together the last three equations, we get
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 将最后三个方程组合起来，我们得到
- en: '![](../Images/08_12_E05.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08_12_E05.png)'
- en: Each of these quantities on the right-hand side is easy to estimate as a ratio
    between numbers of emails. For example, *P*(*x*[i] | *spam*) is the ratio between
    the number of spam emails that contain the word *x*[i] and the total number of
    spam emails.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 右侧的每个量都很容易估计为电子邮件数量的比率。例如，*P*(*x*[i] | *spam*) 是包含单词 *x*[i] 的垃圾邮件数量与垃圾邮件总数之间的比率。
- en: 'As a small example, let’s say that the email contains the words *lottery*,
    *sale*, and *mom*. We examine the word *mom* and notice that it occurs in only
    one out of the 20 spam emails and in 10 out of the 80 ham emails. Therefore, *P*(*''mom''*|*spam*)
    = 1/20 and *P*(*''mom''*|*ham*) = 1/8\. Using the same probabilities for the words
    *lottery* and *sale* as in the previous section, we get the following:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个小例子，假设电子邮件中包含单词 *lottery*、*sale* 和 *mom*。我们检查单词 *mom* 并注意到它在20封垃圾邮件中只出现了一次，在80封正常邮件中有10次。因此，*P*(*'mom'*|*spam*)
    = 1/20 和 *P*(*'mom'*|*ham*) = 1/8。使用与上一节相同的单词 *lottery* 和 *sale* 的概率，我们得到以下结果：
- en: '![](../Images/08_12_E06.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08_12_E06.png)'
- en: Notice that adding the word *mom* into the equation reduced the probability
    of spam from 94.74% to 87.80%, which makes sense, because this word is more likely
    to appear in ham emails than in spam emails.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，将单词 *mom* 加入方程中，将垃圾邮件的概率从94.74%降低到87.80%，这是有道理的，因为这个单词在正常邮件中比在垃圾邮件中更可能出现。
- en: Building a spam-detection model with real data
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用真实数据构建垃圾邮件检测模型
- en: 'Now that we have developed the algorithm, let’s roll up our sleeves and code
    the naive Bayes algorithm. Several packages such as Scikit-Learn have great implementations
    of this algorithm, and I encourage you to look at them. However, we’ll code it
    by hand. The dataset we use is from Kaggle, and for a link to download it, please
    check the resources for this chapter in appendix C. Here is the code for this
    section:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经开发出了算法，让我们挽起袖子编写朴素贝叶斯算法。Scikit-Learn 等几个包对这个算法有很好的实现，我鼓励你看看它们。然而，我们将手动编写它。我们使用的数据集来自
    Kaggle，有关下载链接，请查看附录C中本章的资源。以下是本节的代码：
- en: '**Notebook**: Coding_naive_Bayes.ipynb'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**笔记**: Coding_naive_Bayes.ipynb'
- en: '[https://github.com/luisguiserrano/manning/blob/master/Chapter_8_Naive_Bayes/Coding_naive_Bayes.ipynb](https://github.com/luisguiserrano/manning/blob/master/Chapter_8_Naive_Bayes/Coding_naive_Bayes.ipynb)'
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/luisguiserrano/manning/blob/master/Chapter_8_Naive_Bayes/Coding_naive_Bayes.ipynb](https://github.com/luisguiserrano/manning/blob/master/Chapter_8_Naive_Bayes/Coding_naive_Bayes.ipynb)'
- en: '**Dataset**: emails.csv'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集**: emails.csv'
- en: 'For this example, we’ll introduce a useful package for handling large datasets
    called Pandas (to learn more about it, please check out the section “Using Pandas
    to load the dataset” in chapter 13). The main object used to store datasets in
    pandas is the DataFrame. To load our data into a Pandas DataFrame, we use the
    following command:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们将介绍一个用于处理大型数据集的有用包，称为 Pandas（要了解更多信息，请查看第13章中的“使用Pandas加载数据集”部分）。在
    pandas 中存储数据集的主要对象是 DataFrame。要将我们的数据加载到 Pandas DataFrame 中，我们使用以下命令：
- en: '[PRE0]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In table 8.1, you can see the first five rows of the dataset.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在表8.1中，你可以看到数据集的前五行。
- en: This dataset has two columns. The first column is the text of the email (together
    with its subject line), in string format. The second column tells us if the email
    is spam (1) or ham (0). First we need to do some data preprocessing.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集有两个列。第一列是电子邮件的文本（包括其主题行），以字符串格式表示。第二列告诉我们电子邮件是否是垃圾邮件（1）或正常邮件（0）。首先我们需要做一些数据预处理。
- en: Table 8.1 The first five rows of our email dataset. The Text column shows the
    text in each email, and the Spam column shows a 1 if the email is spam and a 0
    if the email is ham. Notice that the first five emails are all spam.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.1：我们电子邮件数据集的前五行。文本列显示了每封电子邮件中的文本，垃圾邮件列显示如果电子邮件是垃圾邮件则为1，如果是正常邮件则为0。请注意，前五封电子邮件都是垃圾邮件。
- en: '| Text | Spam |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 垃圾邮件 |'
- en: '| Subject: naturally irresistible your corporate... | 1 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 主题：自然吸引你的企业... | 1 |'
- en: '| Subject: the stock trading gunslinger fanny i... | 1 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 主题：股票交易枪手fanny i... | 1 |'
- en: '| Subject: unbelievable new homes made easy im ... | 1 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 主题：难以置信的新家园制作简单... | 1 |'
- en: '| Subject: 4 color printing special request add... | 1 |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 主题：4色打印特殊请求添加... | 1 |'
- en: '| Subject: do not have money, get software cds ... | 1 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 主题：没有钱，获取软件cds... | 1 |'
- en: Data preprocessing
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Let’s start by turning the text string into a list of words. We do this using
    the following function, which uses the `lower()` function to turn all the words
    into lowercase and the `split()` function to turn the words into a list. We check
    only whether each word appears in the email, regardless of how many times it appears,
    so we turn it into a set and then into a list.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先从将文本字符串转换为单词列表开始。我们使用以下函数来完成这项工作，该函数使用`lower()`函数将所有单词转换为小写，并使用`split()`函数将单词转换为列表。我们只检查每个单词是否出现在电子邮件中，而不管它出现多少次，所以我们将其转换为集合，然后再转换为列表。
- en: '[PRE1]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now we use the apply() function to apply this change to the entire column. We
    call the new column emails['words'].
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用`apply()`函数将此更改应用于整个列。我们将新列命名为emails['words']。
- en: '[PRE2]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first five rows of the modified email dataset are shown in table 8.2.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 修改后的电子邮件数据集的前五行如表8.2所示。
- en: Table 8.2 The email dataset with a new column called Words, which contains a
    list of the words in the email (without repetition) and subject line
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.2 带有新列“Words”的电子邮件数据集，其中包含电子邮件中的单词列表（不重复）和主题行
- en: '| Text | Spam | Words |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | 垃圾邮件 | 单词 |'
- en: '| Subject: naturally irresistible your corporate... | 1 | [letsyou, all, do,
    but, list, is, information,... |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 主题：自然吸引你的企业... | 1 | [letsyou, all, do, but, list, is, information,... |'
- en: '| Subject: the stock trading gunslinger fanny i... | 1 | [not, like, duane,
    trading, libretto, attainde... |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 主题：股票交易枪手fanny i... | 1 | [not, like, duane, trading, libretto, attainde...
    |'
- en: '| Subject: unbelievable new homes made easy im ... | 1 | [im, have, $, take,
    foward, all, limited, subj... |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 主题：难以置信的新家园制作简单... | 1 | [im, have, $, take, foward, all, limited, subj...
    |'
- en: '| Subject: 4 color printing special request add... | 1 | [color, azusa, pdf,
    printable, 8102, subject:,... |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 主题：4色打印特殊请求添加... | 1 | [color, azusa, pdf, printable, 8102, subject:,...
    |'
- en: '| Subject: do not have money, get software cds ... | 1 | [get, not, have, all,
    do, subject:, be, by, me... |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 主题：没有钱，获取软件cds... | 1 | [get, not, have, all, do, subject:, be, by, me...
    |'
- en: Finding the priors
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找先验概率
- en: 'Let’s first find the probability that an email is spam (the prior). For this,
    we calculate the number of emails that are spam and divide it by the total number
    of emails. Notice that the number of emails that are spam is the sum of entries
    in the Spam column. The following line will do the job:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要找到一封电子邮件是垃圾邮件的概率（即先验概率）。为此，我们计算垃圾邮件的数量，并将其除以总邮件数量。请注意，垃圾邮件的数量是垃圾邮件列中条目的总和。以下行将完成这项工作：
- en: '[PRE3]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We deduce that the prior probability that the email is spam is around 0.24\.
    This is the probability that an email is spam if we don’t know anything about
    the email. Likewise, the prior probability that an email is ham is around 0.76.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们推断出，电子邮件是垃圾邮件的先验概率大约为0.24。这是如果我们对电子邮件一无所知时，电子邮件是垃圾邮件的概率。同样，电子邮件是正常邮件的先验概率大约为0.76。
- en: Finding the posteriors with Bayes’ theorem
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 使用贝叶斯定理寻找后验概率
- en: 'We need to find the probabilities that spam (and ham) emails contain a certain
    word. We do this for all words at the same time. The following function creates
    a dictionary called model, which records each word, together with the number of
    appearances of the word in spam emails and in ham emails:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要找到垃圾邮件（和正常邮件）包含特定单词的概率。我们同时为所有单词计算这些概率。以下函数创建了一个名为model的字典，记录了每个单词，以及该单词在垃圾邮件和正常邮件中出现的次数：
- en: '[PRE4]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note that the counts are initialized at 1, so in reality, we are recording
    one more appearance of the email as spam and ham. We use this small hack to avoid
    having zero counts, because we don’t want to accidentally divide by zero. Now
    let’s examine some rows of the dictionary as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，计数初始化为1，因此实际上我们记录了垃圾邮件和正常邮件各多一次的出现次数。我们使用这个小技巧来避免出现零计数，因为我们不希望意外地除以零。现在让我们按照以下方式检查字典的一些行：
- en: '[PRE5]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This means that the word *lottery* appears in 1 ham email and 9 spam emails,
    whereas the word *sale* appears in 42 ham emails and 39 spam emails. Although
    this dictionary doesn’t contain any probabilities, these can be deduced by dividing
    the first entry by the sum of both entries. Thus, if an email contains the word
    lottery, the probability of it being spam is ![](../Images/08_12_E07.png), and
    if it contains the word sale, the probability of it being spam is ![](../Images/08_12_E08.png).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着单词*lottery*出现在1封正常邮件和9封垃圾邮件中，而单词*sale*出现在42封正常邮件和39封垃圾邮件中。尽管这个字典没有包含任何概率，但可以通过将第一个条目除以两个条目的总和来推断这些概率。因此，如果一封邮件包含单词lottery，那么它是垃圾邮件的概率是
    ![](../Images/08_12_E07.png)，如果它包含单词sale，那么它是垃圾邮件的概率是 ![](../Images/08_12_E08.png)。
- en: Implementing the naive Bayes algorithm
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 实现朴素贝叶斯算法
- en: 'The input of the algorithm is the email. It goes through all the words in the
    email, and for each word, it calculates the probabilities that a spam email contains
    it and that a ham email contains it. These probabilities are calculated using
    the dictionary we defined in the previous section. Then we multiply these probabilities
    (the naive assumption) and apply Bayes’ theorem to find the probability that an
    email is spam given that it contains the words on this particular email. The code
    to make a prediction using this model follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的输入是邮件。它遍历邮件中的所有单词，并对每个单词计算包含该单词的垃圾邮件概率和正常邮件概率。这些概率是使用我们在上一节中定义的字典计算的。然后我们乘以这些概率（朴素假设）并应用贝叶斯定理来找到包含特定邮件中单词的邮件是垃圾邮件的概率。使用此模型进行预测的代码如下：
- en: '[PRE6]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Calculates the total number of emails, spam emails, and ham emails
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算总邮件数、垃圾邮件数和正常邮件数
- en: ❷ Processes each email by turning it into a list of its words in lowercase
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 通过将其转换为单词列表（小写）来处理每封邮件
- en: ❸ For each word, computes the conditional probability that an email containing
    that word is spam (or ham), as a ratio
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 对于每个单词，计算包含该单词的邮件是垃圾邮件（或正常邮件）的条件概率，作为一个比率
- en: ❹ Multiplies all the previous probabilities times the prior probability of the
    email being spam, and calls this prod_spams. Does a similar process for prod_hams.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将所有之前的概率乘以邮件是垃圾邮件的先验概率，并称这个结果为prod_spams。对prod_hams执行类似的过程。
- en: ❺ Normalizes these two probabilities to get them to add to one (using Bayes’
    theorem) and returns the result
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 对这两个概率进行归一化，使它们相加等于1（使用贝叶斯定理），并返回结果
- en: You may note that in the previous code, we used another small hack. Every probability
    is multiplied by the total number of emails in the dataset. This won’t affect
    our calculations because this factor appears in the numerator and the denominator.
    However, it does ensure that our products of probabilities are not too small for
    Python to handle.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，在前面的代码中，我们使用了另一个小的技巧。每个概率都乘以数据集中邮件的总数。这个因素不会影响我们的计算，因为该因素同时出现在分子和分母中。然而，它确实确保了我们的概率乘积对于Python来说不是太小，可以处理。
- en: 'Now that we have built the model, let’s test it by making predictions on some
    emails as follows:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了模型，让我们通过在邮件上进行预测来测试它，如下所示：
- en: '[PRE7]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It seems to work well. Emails like ‘hi mom how are you’ get a low probability
    (about 0.12) of being spam, and emails like ‘buy cheap lottery easy money now’
    get a very high probability (over 0.99) of being spam. Notice that the last email,
    which doesn’t contain any of the words in the dictionary, gets a probability of
    0.2388, which is precisely the prior.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 它似乎工作得很好。像“hi mom how are you”这样的邮件被判定为垃圾邮件的概率很低（大约0.12），而像“buy cheap lottery
    easy money now”这样的邮件被判定为垃圾邮件的概率非常高（超过0.99）。注意，最后一封邮件没有包含字典中的任何单词，其概率为0.2388，这正是先验概率。
- en: Further work
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步工作
- en: This was a quick implementation of the naive Bayes algorithm. But for larger
    datasets, and larger emails, we should use a package. Packages like Scikit-Learn
    offer great implementations of the naive Bayes algorithm, with many parameters
    to play with. Explore this and other packages, and use the naive Bayes algorithm
    on all types of datasets!
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对朴素贝叶斯算法的快速实现。但对于更大的数据集和更大的邮件，我们应该使用一个包。像Scikit-Learn这样的包提供了对朴素贝叶斯算法的优秀实现，具有许多可调整的参数。探索这个和其他包，并在所有类型的数据集上使用朴素贝叶斯算法！
- en: Summary
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Bayes’ theorem is a technique widely used in probability, statistics, and machine
    learning.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯定理是概率论、统计学和机器学习中广泛使用的技术。
- en: Bayes’ theorem consists of calculating a posterior probability, based on a prior
    probability and an event.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯定理包括根据先验概率和事件来计算后验概率。
- en: The prior probability is a basic calculation of a probability, given very little
    information.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先验概率是在信息非常有限的情况下对概率的基本计算。
- en: Bayes’ theorem uses the event to make a much better estimate of the probability
    in question.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯定理使用事件来对所讨论的概率做出更好的估计。
- en: The naive Bayes algorithm is used when one wants to combine a prior probability
    together with several events.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当想要将先验概率与几个事件结合起来时，使用朴素贝叶斯算法。
- en: The word *naive* comes from the fact that we are making a naive assumption,
    namely, that the events in question are all independent.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “天真”这个词来源于我们做出了一个天真的假设，即所讨论的事件都是独立的。
- en: Exercises
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习
- en: Exercise 8.1
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 8.1
- en: For each pair of events A and B, determine if they are independent or dependent.
    For (a) to (d), provide mathematical justification. For (e) and (f) provide verbal
    justification.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一对事件 A 和 B，确定它们是独立的还是依赖的。对于 (a) 到 (d)，提供数学证明。对于 (e) 和 (f)，提供口头证明。
- en: 'Throwing three fair coins:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 抛掷三个公平的硬币：
- en: 'A: First one falls on heads. B: Third one falls on tails.'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 第一个落地为正面。B: 第三个落地为反面。'
- en: 'A: First one falls on heads. B: There is an odd number of heads among the three
    throws.'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 第一个落地为正面。B: 三次抛掷中有奇数个正面。'
- en: 'Rolling two dice:'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 抛掷两个骰子：
- en: 'A: First one shows a 1\. B: Second one shows a 2.'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 第一个显示 1。B: 第二个显示 2。'
- en: 'A: First one shows a 3\. B: Second one shows a higher value than the first
    one.'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 第一个显示 3。B: 第二个显示的值比第一个高。'
- en: For the following, provide a verbal justification. Assume that for this problem,
    we live in a place with seasons.
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于以下内容，提供口头证明。假设对于这个问题，我们生活在一个有季节的地方。
- en: 'A: It’s raining outside. B: It’s Monday.'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 外面在下雨。B: 今天是星期一。'
- en: 'A: It’s raining outside. B: It’s June.'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'A: 外面在下雨。B: 今天是六月。'
- en: Exercise 8.2
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 8.2
- en: There is an office where we have to go regularly for some paperwork. This office
    has two clerks, Aisha and Beto. We know that Aisha works there three days a week,
    and Beto works the other two. However, the schedules change every week, so we
    never know which three days Aisha is there, and which two days Beto is there.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须定期去一个办公室办理一些文件。这个办公室有两个职员，Aisha 和 Beto。我们知道 Aisha 每周工作三天，Beto 工作其他两天。然而，每周的日程都会改变，所以我们永远不知道
    Aisha 在哪三天，Beto 在哪两天。
- en: If we show up on a random day to the office, what is the probability that Aisha
    is the clerk?
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们在一个随机日子里去办公室，Aisha 是职员的可能性是多少？
- en: We look from outside and notice that the clerk is wearing a red sweater, although
    we can’t tell who the clerk is. We’ve been going to that office a lot, so we know
    that Beto tends to wear red more often than Aisha. In fact, Aisha wears red one
    day out of three (one-third of the time), and Beto wears red one day out of two
    (half of the time).
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们从外面看，注意到职员穿着红色的毛衣，尽管我们无法确定谁是职员。我们经常去那个办公室，所以知道 Beto 比 Aisha 更经常穿红色。事实上，Aisha
    每三天穿一次红色（三分之一的时间），Beto 每两天穿一次红色（一半的时间）。
- en: What is the probability that Aisha is the clerk, knowing that the clerk is wearing
    red today?
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 知道今天职员穿着红色毛衣的情况下，Aisha 是职员的可能性是多少？
- en: Exercise 8.3
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 8.3
- en: The following is a dataset of patients who have tested positive or negative
    for COVID-19\. Their symptoms are cough (C), fever (F), difficulty breathing (B),
    and tiredness (T).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一组测试过 COVID-19 阳性或阴性的病人的数据集。他们的症状是咳嗽（C）、发烧（F）、呼吸困难（B）和疲劳（T）。
- en: '|  | Cough (C) | Fever (F) | Difficulty breathing (B) | Tiredness (T) | Diagnosis
    |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '|  | 咳嗽（C） | 发烧（F） | 呼吸困难（B） | 疲劳（T） | 诊断 |'
- en: '| Patient 1 |  | X | X | X | Sick |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 病人 1 |  | X | X | X | 病人 |'
- en: '| Patient 2 | X | X |  | X | Sick |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 病人 2 | X | X |  | X | 病人 |'
- en: '| Patient 3 | X |  | X | X | Sick |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 病人 3 | X |  | X | X | 病人 |'
- en: '| Patient 4 | X | X | X |  | Sick |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 病人 4 | X | X | X |  | 病人 |'
- en: '| Patient 5 | X |  |  | X | Healthy |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 病人 5 | X |  |  | X | 健康 |'
- en: '| Patient 6 |  | X | X |  | Healthy |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 病人 6 |  | X | X |  | 健康 |'
- en: '| Patient 7 |  | X |  |  | Healthy |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 病人 7 |  | X |  |  | 健康 |'
- en: '| Patient 8 |  |  |  | X | Healthy |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 病人 8 |  |  |  | X | 健康 |'
- en: 'The goal of this exercise is to build a naive Bayes model that predicts the
    diagnosis from the symptoms. Use the naive Bayes algorithm to find the following
    probabilities:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的目的是构建一个朴素贝叶斯模型，从症状预测诊断。使用朴素贝叶斯算法找到以下概率：
- en: note For the following questions, the symptoms that are not mentioned are completely
    unknown to us. For example, if we know that the patient has a cough, but nothing
    is said about their fever, it does not mean the patient doesn’t have a fever.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：对于以下问题，我们没有提到的症状对我们来说完全未知。例如，如果我们知道病人有咳嗽，但没有提到他们的发烧，这并不意味着病人没有发烧。
- en: The probability that a patient is sick given that the patient has a cough
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 患者咳嗽的情况下生病的概率
- en: The probability that a patient is sick given that the patient is not tired
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 患者不疲劳的情况下生病的概率
- en: The probability that a patient is sick given that the patient has a cough and
    a fever
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 患者咳嗽且有发烧的情况下生病的概率
- en: The probability that a patient is sick given that the patient has a cough and
    a fever, but no difficulty breathing
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 患者咳嗽且有发烧，但没有呼吸困难的情况下生病的概率
