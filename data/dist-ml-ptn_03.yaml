- en: 3 Distributed training patterns
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 分布式训练模式
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Distinguishing the traditional model training process from the distributed training
    process
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分传统模型训练过程与分布式训练过程
- en: Using parameter servers to build models that cannot fit in a single machine
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用参数服务器构建无法适应单个机器的模型
- en: Improving distributed model training performance using the collective communication
    pattern
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用集体通信模式提高分布式模型训练性能
- en: Handling unexpected failures during the distributed model training process
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理分布式模型训练过程中出现的意外故障
- en: The previous chapter introduced a couple of practical patterns that can be incorporated
    into the data ingestion process, which is usually the beginning process in a distributed
    machine learning system that’s responsible for monitoring any incoming data and
    performing necessary preprocessing steps to prepare model training.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章介绍了几种可以融入数据摄入过程的实用模式，这通常是分布式机器学习系统中的开始过程，该过程负责监控任何传入的数据并执行必要的预处理步骤以准备模型训练。
- en: Distributed training, the next step after the data ingestion process, is what
    distinguishes distributed machine learning systems from other distributed systems.
    It’s the most critical part of a distributed machine learning system.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式训练，数据摄入过程之后的下一步，是区分分布式机器学习系统与其他分布式系统的关键因素。它是分布式机器学习系统中最关键的部分。
- en: The system design needs to be scalable and reliable to handle datasets and models
    of different sizes and various levels of complexity. Some large and complex models
    cannot fit in a single machine, and some medium-size models that are small enough
    to fit in single machines struggle to improve the computational performance of
    distributed training.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 系统设计需要可扩展和可靠，以处理不同大小和复杂程度的数据库和模型。一些大型且复杂的模型无法适应单个机器，而一些中型模型虽然足够小可以适应单个机器，但难以提高分布式训练的计算性能。
- en: It’s also essential to know what to do when we see performance bottlenecks and
    unexpected failures. Parts of the dataset may be corrupted or cannot be used to
    train the model successfully, or the distributed cluster that the distributed
    training depends on may experience an unstable or even disconnected network due
    to weather conditions or human error.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 知道在遇到性能瓶颈和意外故障时应该做什么也是至关重要的。数据集的部分可能已损坏或无法成功用于训练模型，或者依赖于分布式训练的分布式集群可能因天气条件或人为错误而出现不稳定或甚至断开连接的网络。
- en: In this chapter, I’ll explore some of the challenges involved in the distributed
    training process and introduce a few established patterns adopted heavily in industries.
    Section 3.2 discusses challenges in training large machine learning models that
    tag main themes in new YouTube videos but cannot fit in a single machine; it also
    shows how to overcome the difficulty using the parameter server pattern. Section
    3.3 shows how to use the collective communication pattern to speed up distributed
    training for smaller models and avoid unnecessary communication overhead among
    parameter servers and workers. The last section discusses some of the vulnerabilities
    of distributed machine learning systems due to corrupted datasets, unstable networks,
    and preemptive worker machines, as well as ways to address those problems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将探讨分布式训练过程中的一些挑战，并介绍一些在行业中广泛采用的既定模式。第3.2节讨论了训练大型机器学习模型的挑战，这些模型标记了新YouTube视频中的主要主题，但无法适应单个机器；它还展示了如何使用参数服务器模式克服这一困难。第3.3节展示了如何使用集体通信模式加快小型模型的分布式训练，并避免参数服务器和工作之间不必要的通信开销。最后一节讨论了由于数据集损坏、不稳定网络和抢占式工作机等原因导致的分布式机器学习系统的某些漏洞，以及解决这些问题的方法。
- en: 3.1 What is distributed training?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 什么是分布式训练？
- en: '*Distributed training* is the process of taking the data that has already been
    processed by data ingestion (discussed in chapter 2), initializing the machine
    learning model, and then training the model with the processed data in a distributed
    environment such as multiple nodes. It’s easy to get this process confused with
    the traditional training process of machine learning models, which takes place
    in a single-node environment where the datasets and the machine learning model
    objects are on the same machine, such as a laptop. By contrast, distributed model
    training usually happens in a cluster of machines that could work concurrently
    to greatly speed up the training process.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*分布式训练* 是指将数据摄入（在第2章中讨论）处理后的数据，初始化机器学习模型，然后在分布式环境中（如多个节点）使用处理后的数据进行模型训练的过程。这个过程很容易与机器学习模型的传统训练过程混淆，后者发生在单节点环境中，数据集和机器学习模型对象在同一台机器上，例如笔记本电脑。相比之下，分布式模型训练通常发生在由多个机器组成的集群中，这些机器可以并行工作，从而大大加快训练过程。'
- en: In addition, the dataset is often located on the local disk of a single laptop
    or machine in traditional model training, whereas in distributed model training,
    a remote distributed database is used to store the dataset, or the dataset has
    to be partitioned on disks of multiple machines. If the model is not small enough
    to fit on a single machine, it’s not possible to train the model in a traditional
    way with a single machine. From a network infrastructure perspective, an InfiniBand
    ([https://wiki.archlinux.org/title/InfiniBand](https://wiki.archlinux.org/title/InfiniBand))
    or remote direct memory access (RDMA; [https://www.geeksforgeeks.org/remote-direct-memory-access-rdma/](https://www.geeksforgeeks.org/remote-direct-memory-access-rdma/))
    network is often preferred for distributed training instead of a single local
    host. Table 3.1 provides a comparison of these training methods.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在传统的模型训练中，数据集通常位于单个笔记本电脑或机器的本地磁盘上，而在分布式模型训练中，使用远程分布式数据库来存储数据集，或者数据集必须在多台机器的磁盘上进行分区。如果模型太大，无法适应单台机器，则无法使用单台机器以传统方式训练模型。从网络基础设施的角度来看，InfiniBand
    ([https://wiki.archlinux.org/title/InfiniBand](https://wiki.archlinux.org/title/InfiniBand))
    或远程直接内存访问（RDMA；[https://www.geeksforgeeks.org/remote-direct-memory-access-rdma/](https://www.geeksforgeeks.org/remote-direct-memory-access-rdma/))
    网络通常比单个本地主机更适合分布式训练。表3.1提供了这些训练方法的比较。
- en: Table 3.1 Comparison of traditional (nondistributed) training and distributed
    training for machine learning models
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.1 机器学习模型的传统（非分布式）训练与分布式训练比较
- en: '|  | Traditional model training | Distributed model training |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '|  | 传统模型训练 | 分布式模型训练 |'
- en: '| Computational resources | Laptop or single remote server | Cluster of machines
    |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 计算资源 | 笔记本电脑或单个远程服务器 | 机器集群 |'
- en: '| Dataset location | Local disk on a single laptop or machine | Remote distributed
    database or partitions on disks of multiple machines |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 数据集位置 | 单个笔记本电脑或机器上的本地磁盘 | 远程分布式数据库或多个机器磁盘上的分区 |'
- en: '| Network infrastructure | Local hosts | InfiniBand or RDMA |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 网络基础设施 | 本地主机 | InfiniBand或RDMA |'
- en: '| Model size | Small enough to fit on a single machine | Medium to large |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 模型大小 | 足够小，可以适应单台机器 | 中等到大型 |'
- en: InfiniBand and RDMA
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: InfiniBand和RDMA
- en: InfiniBand is a computer networking communications standard used in high-performance
    computing. It features high throughput and low latency for data interconnecting
    both among and within computers or storage systems, which is often required for
    distributed training.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: InfiniBand是一种用于高性能计算的计算机网络通信标准。它具有高吞吐量和低延迟的数据互联功能，这对于分布式训练通常是有要求的。
- en: RDMA provides direct access from the memory of multiple machines without involving
    any machine’s operating system. This standard permits high-throughput, low-latency
    networking--especially useful in the distributed training process, in which communications
    among machines are frequent.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: RDMA提供了从多台机器的内存中直接访问，而不涉及任何机器的操作系统。这个标准允许高吞吐量、低延迟的网络连接——这在分布式训练过程中特别有用，因为在分布式训练过程中，机器之间的通信频繁。
- en: '3.2 Parameter server pattern: Tagging entities in 8 million YouTube videos'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 参数服务器模式：对800万YouTube视频中的实体进行标记
- en: Suppose that we have a dataset called YouTube-8M ([http://research.google.com/youtube8m](http://research.google.com/youtube8m);
    figure 3.1) that consists of millions of YouTube video IDs, with high-quality
    machine-generated annotations from a diverse vocabulary of more than 3,800 visual
    entities (such as Food, Car, and Music). We’d like to train a machine learning
    model to tag the main themes of YouTube videos that the model hasn’t seen.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个名为YouTube-8M的数据集([http://research.google.com/youtube8m](http://research.google.com/youtube8m);
    图3.1)，它包含数百万个YouTube视频ID，以及来自超过3,800个视觉实体（如食品、汽车和音乐）的优质机器生成注释。我们希望训练一个机器学习模型，以标记模型尚未见过的YouTube视频的主要主题。
- en: '![03-01](../../OEBPS/Images/03-01.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![03-01](../../OEBPS/Images/03-01.png)'
- en: 'Figure 3.1 The website that hosts the YouTube-8M dataset, featuring millions
    of YouTube videos from a diverse vocabulary of more than 3,800 visual entities
    (Source: Sudheendra Vijayanarasimhan et al. Licensed under Nonexclusive License
    1.0)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 托管YouTube-8M数据集的网站，展示了来自超过3,800个视觉实体的数百万个YouTube视频（来源：Sudheendra Vijayanarasimhan等人。根据非独占许可1.0授权）
- en: This dataset consists of both coarse and fine-grained entities. *Coarse entities*
    are the ones nondomain experts can recognize after studying some existing examples,
    and *fine-grained entities* can be identified by domain experts who know how to
    differentiate among extremely similar entities. These entities have been semiautomatically
    curated and manually verified by three raters to be visually recognizable. Each
    entity has at least 200 corresponding video examples, with an average 3,552 training
    videos. When the raters identify the entities in the videos, they are given a
    guideline to assess how specific and visually recognizable each entity is, using
    a discrete scale from 1 to 5, where 1 represents an entity that a layperson can
    easily identify (figure 3.2).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集包含粗粒度和细粒度实体。*粗粒度实体*是非领域专家在研究一些现有示例后可以识别的实体，而*细粒度实体*可以通过了解如何区分极其相似实体的领域专家识别。这些实体已经由三位评分者半自动整理并人工验证，以确保视觉可识别性。每个实体至少有200个相应的视频示例，平均有3,552个训练视频。当评分者识别视频中的实体时，他们会被提供一份指南，以使用从1到5的离散量表来评估每个实体的具体性和视觉识别度，其中1代表一个外行人可以轻易识别的实体（图3.2）。
- en: '![03-02](../../OEBPS/Images/03-02.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![03-02](../../OEBPS/Images/03-02.png)'
- en: 'Figure 3.2 A screenshot of a question and guideline displayed to human raters
    for identifying the entities in the YouTube videos to assess how visually recognizable
    each entity is (Source: Sudheendra Vijayanarasimhan et al. Licensed under Nonexclusive
    License 1.0)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 显示给人类评分者的问题和指南的截图，用于识别YouTube视频中的实体，以评估每个实体的视觉识别度（来源：Sudheendra Vijayanarasimhan等人。根据非独占许可1.0授权）
- en: In the online dataset explorer provided by YouTube-8M ([http://research.google.com/youtube8m/explore.xhtml](http://research.google.com/youtube8m/explore.xhtml)),
    the list of entities appears on the left side, and the number of videos that belong
    to each entity appears next to the entity name (figure 3.3).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在YouTube-8M提供的在线数据集浏览器([http://research.google.com/youtube8m/explore.xhtml](http://research.google.com/youtube8m/explore.xhtml))中，实体列表显示在左侧，每个实体的视频数量显示在实体名称旁边（图3.3）。
- en: '![03-03](../../OEBPS/Images/03-03.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![03-03](../../OEBPS/Images/03-03.png)'
- en: 'Figure 3.3 A screenshot of the dataset explorer provided by the YouTube-8M
    website, ordering the entities by number of videos (Source: Sudheendra Vijayanarasimhan
    et al. Licensed under Nonexclusive License 1.0)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 YouTube-8M网站提供的数据集浏览器截图，按视频数量排序实体（来源：Sudheendra Vijayanarasimhan等人。根据非独占许可1.0授权）
- en: Note that in the dataset explorer, the entities are ordered by the number of
    videos in each entity. In figure 3.3, the three most popular entities are Games,
    Video game, and Vehicle, respectively, ranging from 415,890 to 788,288 training
    examples. The least popular entities (not shown in the figure) are Cylinder and
    Mortar, with 123 and 127 training videos, respectively.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在数据集浏览器中，实体按每个实体中的视频数量排序。在图3.3中，最受欢迎的三个实体分别是游戏、视频游戏和车辆，分别有415,890到788,288个训练示例。最不受欢迎的实体（图中未显示）是圆柱体和灰浆，分别有123和127个训练视频。
- en: 3.2.1 The problem
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.1 问题
- en: With this dataset, we’d like to train a machine learning model to tag the main
    themes of new YouTube videos that the model hasn’t seen. This task may be trivial
    for a simpler dataset and machine learning model, but that’s certainly not the
    case for the YouTube-8M dataset. This dataset comes with precomputed audiovisual
    features from billions of frames and audio segments, so we don’t have to calculate
    and obtain them on our own--tasks that often take a long time and require a large
    amount of computational resources.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个数据集，我们希望训练一个机器学习模型来标记模型尚未见过的新的YouTube视频的主要主题。对于更简单的数据集和机器学习模型来说，这个任务可能是微不足道的，但对于YouTube-8M数据集来说，情况肯定不是这样。这个数据集包含了从数十亿帧和音频片段中预先计算出的视听特征，所以我们不必自己计算和获取它们——这些任务通常需要很长时间，并且需要大量的计算资源。
- en: Even though it is possible to train a strong baseline model on this dataset
    in less than a day on a single GPU, the dataset’s scale and diversity can enable
    deep exploration of complex audiovisual models that can take weeks to train. Is
    there any solution for training this potentially large model efficiently?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在单个GPU上不到一天的时间内就可以在这个数据集上训练出一个强大的基线模型，但数据集的规模和多样性可以使得对复杂音频视觉模型的深入探索成为可能，这些模型的训练可能需要几周时间。有没有什么解决方案可以高效地训练这个可能很大的模型？
- en: 3.2.2 The solution
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.2 解决方案
- en: First, let’s take a look at some of the entities using the data explorer on
    the YouTube-8M website and see whether any relationships exist among the entities.
    Are these entities unrelated, for example, or do they have some level of overlap
    in content? After some exploration, we will make necessary adjustments to the
    model to take those relationships into account.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们使用YouTube-8M网站上的数据探索器查看一些实体，并看看这些实体之间是否存在任何关系。这些实体是否无关，例如，或者它们在内容上存在某种程度的重叠？经过一些探索后，我们将对模型进行必要的调整，以考虑这些关系。
- en: Figure 3.4 shows a list of YouTube videos that belong to the Pet entity. In
    the third video of the first row, a child is playing with a dog.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4展示了属于宠物实体的YouTube视频列表。在第一行的第三个视频中，一个孩子正在和一只狗玩耍。
- en: '![03-04](../../OEBPS/Images/03-04.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![03-04](../../OEBPS/Images/03-04.png)'
- en: 'Figure 3.4 Example videos that belong to the Pet entity (Source: Sudheendra
    Vijayanarasimhan et al. Licensed under Nonexclusive License 1.0)'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4属于宠物实体的示例视频（来源：Sudheendra Vijayanarasimhan等人，许可协议为非独占许可1.0）
- en: Let’s a look a similar entity. Figure 3.5 shows a list of YouTube videos that
    belong to the Animal entity, in which we can see animals such as fish, horses,
    and pandas. Interestingly, a cat is getting cleaned by a vacuum in the third video
    of the fifth row. One might guess that this video is in the Pet entity as well
    because a cat can be a pet if it’s adopted by human beings.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个类似的实体。图3.5展示了属于动物实体的YouTube视频列表，其中我们可以看到鱼类、马和熊猫等动物。有趣的是，在第五行的第三个视频中，一只猫正在被吸尘器清理。有人可能会猜测这个视频也属于宠物实体，因为如果猫被人类收养，它就可以成为宠物。
- en: '![03-05](../../OEBPS/Images/03-05.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![03-05](../../OEBPS/Images/03-05.png)'
- en: 'Figure 3.5 Example videos that belong to the Animal entity (Source: Sudheendra
    Vijayanarasimhan et al. Licensed under Nonexclusive License 1.0)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5属于动物实体的示例视频（来源：Sudheendra Vijayanarasimhan等人，许可协议为非独占许可1.0）
- en: If we’d like to build machine learning models for this dataset, we may need
    to do some additional feature engineering before fitting the model directly to
    the dataset. We might combine the audiovisual features of these two entities (Animal
    and Pet) into a derived feature because they provide similar information and overlap,
    which can boost the model’s performance depending on the specific machine learning
    model we selected. If we continue exploring the combinations of the existing audiovisual
    features in the entities or perform a huge number of feature engineering steps,
    we may no longer be able to train a machine learning model on this dataset in
    less than a day on a single GPU.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想为这个数据集构建机器学习模型，我们可能需要在直接将模型拟合到数据集之前进行一些额外的特征工程。我们可能将这两个实体（动物和宠物）的视听特征组合成一个派生特征，因为它们提供类似的信息并存在重叠，这可以根据我们选择的特定机器学习模型来提高模型的表现。如果我们继续探索实体中现有视听特征的组合，或者执行大量的特征工程步骤，我们可能就不再能够在单个GPU上不到一天的时间内训练出机器学习模型。
- en: If we are using a deep learning model instead of a traditional machine learning
    model that requires a lot of feature engineering and exploration of the dataset,
    the model itself learns the underlying relationships among features, such as audiovisual
    features of similar entities. Each neural network layer in the model architecture
    consists of vectors of weights and biases representing a trained neural network
    layer that gets updated over training iterations as the model gathers more knowledge
    from the dataset.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用深度学习模型而不是需要大量特征工程和数据集探索的传统机器学习模型，模型本身会学习特征之间的底层关系，例如相似实体的视听特征。模型架构中的每一层神经网络都由权重和偏置的向量组成，代表一个经过训练的神经网络层，在训练迭代过程中，随着模型从数据集中获取更多知识，这些层会得到更新。
- en: If we use only 10 of the 3,862 entities, we could build a LeNet model (figure
    3.6) that classifies new YouTube videos into 1 of the 10 selected entities. At
    a high level, LeNet consists of a convolutional encoder consisting of two convolutional
    layers and a dense block consisting of three fully connected layers. For simplicity,
    we assume that each individual frame from the videos is a 28 × 28 image and that
    it will be processed by various convolution and pooling layers that learn the
    underlying feature mapping between the audiovisual features and the entities.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只使用3,862个实体中的10个，我们就可以构建一个LeNet模型（图3.6），将新的YouTube视频分类为10个选定实体之一。从高层次来看，LeNet由一个包含两个卷积层的卷积编码器和一个包含三个全连接层的密集块组成。为了简化，我们假设视频的每个单独帧是一个28
    × 28的图像，并且它将通过各种卷积和池化层进行处理，这些层学习视听特征和实体之间的底层特征映射。
- en: '![03-06](../../OEBPS/Images/03-06.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![03-06](../../OEBPS/Images/03-06.png)'
- en: 'Figure 3.6 LeNet model architecture that could be used to classify new YouTube
    videos in 1 of 10 selected entities. (Source: Aston Zhang et al. Licensed under
    Creative Commons Attribution-ShareAlike 4.0 International Public License)'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 LeNet模型架构，可用于将新的YouTube视频分类为10个选定实体之一。（来源：Aston Zhang等人。根据Creative Commons
    Attribution-ShareAlike 4.0国际公共许可证授权）
- en: Brief history of LeNet
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet的简要历史
- en: LeNet ([https://en.wikipedia.org/wiki/LeNet](https://en.wikipedia.org/wiki/LeNet))
    is one of the first published convolutional neural networks (CNNs; [https://en.wikipedia.org/wiki/Convolutional_neural_
    network](https://en.wikipedia.org/wiki/Convolutional_neural_network)) to capture
    wide attention for its performance on computer vision tasks. It was introduced
    by Yann LeCun, a researcher at AT&T Bell Labs, to recognize handwritten digits
    in images. In 1989, LeCun published the first study that successfully trained
    CNNs via backpropagation after a decade of research and development.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet ([https://en.wikipedia.org/wiki/LeNet](https://en.wikipedia.org/wiki/LeNet))
    是最早发布的卷积神经网络（CNNs；[https://en.wikipedia.org/wiki/Convolutional_neural_network](https://en.wikipedia.org/wiki/Convolutional_neural_network)）之一，因其计算机视觉任务上的性能而受到广泛关注。它由AT&T
    Bell Labs的研究员Yann LeCun提出，用于识别图像中的手写数字。在经过十年的研究和发展后，1989年，LeCun发表了第一篇成功通过反向传播训练CNNs的研究。
- en: At that time, LeNet achieved outstanding results matching the performance of
    support vector machines, the dominant approach in supervised machine learning
    algorithms.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当时，LeNet取得了与支持向量机（监督机器学习算法中的主导方法）相匹配的卓越成果。
- en: In fact, those learned feature maps contain parameters that are related to the
    model. These parameters are numeric vectors that are used as weights and biases
    for this layer of model representation. For each training iteration, the model
    takes every frame in the YouTube videos as features, calculates the loss, and
    then updates those model parameters to optimize the model’s objective so that
    the relationships between features and the entities can be modeled more closely.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，那些学习到的特征图包含与模型相关的参数。这些参数是作为该层模型表示的权重和偏置使用的数值向量。对于每个训练迭代，模型将YouTube视频中的每一帧作为特征，计算损失，然后更新那些模型参数以优化模型的目标，从而使特征和实体之间的关系能够更紧密地建模。
- en: Unfortunately, this training process is slow, as it involves updating all the
    parameters in different layers. We have two potential solutions to speed up the
    training process.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这个训练过程很慢，因为它涉及到更新不同层的所有参数。我们有两个潜在的解决方案来加速训练过程。
- en: Let’s take a look at the first approach. We want to make an assumption here,
    and we’ll remove it later when we discuss a better approach. Let’s assume that
    the model is not too large and we can fit the entire model using existing resources
    without any possibility of out-of-memory or disk errors.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看第一种方法。这里我们想要做一个假设，我们将在讨论更好的方法时将其移除。让我们假设模型不是太大，我们可以使用现有资源来拟合整个模型，没有任何内存不足或磁盘错误的可能性。
- en: In this case, we can use one dedicated server to store all the LeNet model parameters
    and use multiple worker machines to split the computational workloads. Figure
    3.7 shows an architecture diagram.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以使用一台专用服务器来存储所有LeNet模型参数，并使用多台工作机来分配计算工作负载。图3.7展示了架构图。
- en: '![03-07](../../OEBPS/Images/03-07.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![03-07](../../OEBPS/Images/03-07.png)'
- en: Figure 3.7 A machine learning training component with a single parameter server
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 单参数服务器的机器学习训练组件
- en: Each worker node takes a particular part of the dataset to calculate the gradients
    and then sends the results to the dedicated server to update the LeNet model parameters.
    Because the worker nodes use isolated computational resources, they can perform
    the heavy computations asynchronously without having to communicate. Therefore,
    we’ve achieved around a triple speedup simply by introducing additional worker
    nodes if costs such as message passing among nodes are neglected.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 每个工作节点处理数据集的特定部分来计算梯度，然后将结果发送到专用服务器以更新LeNet模型参数。因为工作节点使用隔离的计算资源，它们可以在无需通信的情况下异步执行繁重的计算。因此，如果我们忽略节点间消息传递等成本，仅通过引入额外的工人节点就实现了大约三倍的速度提升。
- en: This dedicated single server responsible for storing and updating the model
    parameters is called a *parameter server.* We’ve designed a more efficient distributed
    machine learning training system by incorporating the *parameter server pattern*.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 负责存储和更新模型参数的专用单服务器被称为*参数服务器。*我们通过整合*参数服务器模式*设计了一个更高效的分布式机器学习训练系统。
- en: Next comes the real-world challenge. Deep learning models often get complex;
    additional layers with custom structures can be added on top of a baseline model.
    Those complex models usually take up a lot of disk space due to the large number
    of model parameters in those additional layers. A lot of computational resources
    are required to meet the memory footprint requirement for successful training.
    What if the model is large, and we cannot fit all of its parameters on a single
    parameter server?
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是现实世界的挑战。深度学习模型通常很复杂；可以在基线模型之上添加具有自定义结构的额外层。这些复杂模型通常由于额外层中大量模型参数而占用大量磁盘空间。为了满足成功训练所需的内存占用要求，需要大量的计算资源。如果模型很大，而我们无法将所有参数都拟合到一个参数服务器上，那会怎样呢？
- en: A second solution could address the challenges in this situation. We can introduce
    additional parameter servers, each responsible for storing and updating a particular
    *model partition.* Each worker node is responsible for taking a particular part
    of the dataset to update the model parameters in a model partition.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种解决方案可以解决这种情况下的挑战。我们可以引入额外的参数服务器，每个服务器负责存储和更新特定的*模型分区。*每个工作节点负责处理数据集的特定部分以更新模型分区的模型参数。
- en: Figure 3.8 shows an architecture diagram of this pattern using multiple parameter
    servers. This diagram is different from figure 3.7, in which a single server stores
    all the LeNet model parameters and use worker machines split the computational
    workloads. Each worker node takes a subset of the dataset, performs the calculations
    required in each neural network layer, and then sends the calculated gradients
    to update one model partition that’s stored in one of the parameter servers. Note
    that because all workers perform calculations in an asynchronous fashion, the
    model partitions that each worker node uses to calculate the gradients may not
    be up to date. To guarantee that the model partitions each worker node is using
    or each parameter server is storing are the most recent ones, we constantly have
    to pull and push updates of the model among the worker nodes.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8展示了使用多个参数服务器构建此模式的架构图。此图与图3.7不同，图3.7中只有一个服务器存储了所有LeNet模型参数，并通过工作机器分配计算工作负载。每个工作节点处理数据集的一个子集，执行每个神经网络层所需的计算，然后将计算出的梯度发送到更新存储在参数服务器中的一个模型分区。请注意，由于所有工作节点都以异步方式执行计算，因此每个工作节点用于计算梯度的模型分区可能不是最新的。为了保证每个工作节点使用的模型分区或每个参数服务器存储的模型分区是最新的，我们不得不在节点之间不断拉取和推送模型更新。
- en: '![03-08](../../OEBPS/Images/03-08.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![03-08](../../OEBPS/Images/03-08.png)'
- en: Figure 3.8 A machine learning training component with multiple parameter servers
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 带有多个参数服务器的机器学习训练组件
- en: With the help of parameter servers, we could effectively resolve the challenges
    of building a machine learning model to tag the main themes of new YouTube videos
    that the model hasn’t seen. Figure 3.9 shows a list of YouTube videos that are
    not used for model training, tagged with the Aircraft theme by the trained machine
    learning model. Even when the model is too large to fit on a single machine, we
    could train the model efficiently. Note that although the parameter server pattern
    would be useful in this scenario, it is specially designed to train models with
    a lot of parameters.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在参数服务器的帮助下，我们可以有效地解决构建机器学习模型以标记模型尚未见过的YouTube新视频主要主题的挑战。图3.9显示了未用于模型训练的YouTube视频列表，由训练好的机器学习模型标记为飞机主题。即使模型太大而无法适应单个机器，我们也能有效地训练模型。请注意，尽管参数服务器模式在这种情况下可能很有用，但它特别设计用于训练具有大量参数的模型。
- en: '![03-09](../../OEBPS/Images/03-09.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![03-09](../../OEBPS/Images/03-09.png)'
- en: 'Figure 3.9 A list of new YouTube videos not used for model training, tagged
    with the Aircraft theme (Source: Sudheendra Vijayanarasimhan et al. Licensed under
    Nonexclusive License 1.0)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 列出了未用于模型训练的新YouTube视频，标记为飞机主题（来源：Sudheendra Vijayanarasimhan等人，许可协议为非独占许可1.0）
- en: 3.2.3 Discussion
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.3 讨论
- en: The previous section introduced the parameter server pattern and showed how
    it can be used to address potential challenges in the YouTube-8M video identification
    application. Even though the parameter server pattern is useful when the model
    is too large to fit on a single machine and even though the patterns seem like
    a straightforward approach to the challenge, in real-world applications, we still
    have to make decisions to make the distributed training system efficient.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节介绍了参数服务器模式，并展示了如何使用它来解决YouTube-8M视频识别应用中的潜在挑战。尽管参数服务器模式在模型太大而无法适应单个机器时很有用，而且这些模式似乎是对挑战的直接方法，但在实际应用中，我们仍然需要做出决策，以使分布式训练系统高效。
- en: Machine learning researchers and DevOps engineers often struggle to figure out
    a good ratio between the number of parameter servers and the number of workers
    for different machine learning applications. There are nontrivial communication
    costs to send the calculated gradients from workers to parameter servers, as well
    as costs for pulling and pushing the updates of the most recent model partitions.
    If we find that the model is getting larger and adds too many parameter servers
    to the system, the system will end up spending a lot of time communicating among
    nodes and a small amount of time making the computations among neural network
    layers.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习研究人员和DevOps工程师经常难以确定不同机器学习应用中参数服务器数量和工作节点数量的良好比例。从工作节点向参数服务器发送计算出的梯度存在非平凡的通信成本，以及拉取和推送最新模型分区更新的成本。如果我们发现模型变得越来越大，并向系统中添加过多的参数服务器，系统最终将花费大量时间在节点之间进行通信，而在神经网络层之间进行计算的时间却很少。
- en: Section 3.3 discusses these practical challenges in more detail. The section
    introduces a pattern that addresses these challenges so that engineers no longer
    need to spend time tuning the performance of workers and parameter servers for
    different types of models.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第3.3节更详细地讨论了这些实际挑战。该节介绍了一种模式，以解决这些挑战，这样工程师就不再需要花费时间调整不同类型模型的工作者和参数服务器的性能。
- en: 3.2.4 Exercises
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.4 练习
- en: If we’d like to train a model with multiple CPUs or GPUs on a single laptop,
    is this process considered distributed training?
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们想在单台笔记本电脑上使用多个CPU或GPU训练模型，这个过程是否被认为是分布式训练？
- en: What’s the result of increasing the number of workers or parameter servers?
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增加工人或参数服务器数量会有什么结果？
- en: What types of computational resources (such as CPUs, GPUs, memory, or disk)
    should we allocate to parameter servers, and how much of those types of resources
    should we allocate?
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们应该为参数服务器分配哪些类型的计算资源（如CPU、GPU、内存或磁盘），以及应该分配多少这类资源？
- en: 3.3 Collective communication pattern
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 集体通信模式
- en: Section 3.2.2 introduced the parameter server pattern, which comes in handy
    when the model is too large to fit in a single machine, such as the one we would
    have to build to tag entities in 8 million YouTube videos. Although we could use
    parameter servers to handle extremely large and complex models with a large number
    of parameters, it’s nontrivial to incorporate the pattern into the design of an
    efficient distributed training system.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 第3.2.2节介绍了参数服务器模式，当模型太大而无法适应单个机器时，该模式非常有用，例如，我们需要构建一个系统来标记800万YouTube视频中的实体。尽管我们可以使用参数服务器来处理具有大量参数的极其大型和复杂的模型，但将此模式纳入高效分布式训练系统的设计并非易事。
- en: Section 3.2.3 stated that DevOps engineers, who support the distributed machine
    learning infrastructure for data scientists or analysts, often have a hard time
    figuring out a good ratio between the number of parameter servers and the number
    of workers for different machine learning applications. Suppose that there are
    three parameter servers and three workers in the model training component of our
    machine learning system, as shown in figure 3.10\. All three workers perform intensive
    computations asynchronously and then send the calculated gradients to the parameter
    servers to update different partitions of the model’s parameters.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 第3.2.3节指出，支持数据科学家或分析师分布式机器学习基础设施的DevOps工程师，往往很难确定不同机器学习应用中参数服务器数量和工作者数量之间的良好比例。假设在我们的机器学习系统的模型训练组件中有三个参数服务器和三个工作者，如图3.10所示。所有三个工作者异步执行密集计算，然后将计算出的梯度发送到参数服务器以更新模型参数的不同分区。
- en: '![03-10](../../OEBPS/Images/03-10.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![03-10](../../OEBPS/Images/03-10.png)'
- en: Figure 3.10 A distributed model training component that consists of three parameter
    servers and three worker nodes
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10显示了一个由三个参数服务器和三个工作节点组成的分布式模型训练组件
- en: In reality, worker nodes and parameter servers do not provide one-on-one mapping,
    particularly if the number of worker nodes is different from the number of parameter
    servers. In other words, multiple workers may send updates to the same subset
    of parameter servers. Now suppose that two workers have finished calculating the
    gradients at the same time, and they both want to update the model parameters
    stored on the same parameter server (figure 3.11).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实中，工作节点和参数服务器并不提供一对一的映射，尤其是当工作节点数量与参数服务器数量不同时。换句话说，多个工作者可能向同一子集的参数服务器发送更新。现在假设有两个工作者同时完成了梯度的计算，并且他们都想更新存储在相同参数服务器上的模型参数（图3.11）。
- en: '![03-11](../../OEBPS/Images/03-11.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![03-11](../../OEBPS/Images/03-11.png)'
- en: Figure 3.11 Two of the worker nodes have finished calculating gradients and
    want to push updates to the first parameter server at the same time.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11显示，两个工作节点已经完成了梯度的计算，并希望同时将更新推送到第一个参数服务器。
- en: As a result, the two workers are *blocking* each other from sending the gradients
    to the parameter server. In other words, the gradients from both worker nodes
    cannot be accepted by the same parameter server simultaneously.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，两个工人正在互相阻塞，无法同时将梯度发送到参数服务器。换句话说，来自两个工作节点的梯度不能同时被同一个参数服务器接受。
- en: '3.3.1 The problem: Improving performance when parameter servers become a bottleneck'
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.1 问题：当参数服务器成为瓶颈时提高性能
- en: In this case, only two workers are blocking each other when sending gradients
    to the same parameter server, which makes it hard to gather the calculated gradients
    on time and which requires a strategy to resolve the blocking problem. Unfortunately,
    in real-world distributed training systems that incorporate parameter servers,
    multiple workers may be sending the gradients at the same time; thus, we must
    resolve many communications blocks.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，只有两个工作者在向同一个参数服务器发送梯度时相互阻塞，这使得及时收集计算出的梯度变得困难，并需要一种策略来解决阻塞问题。不幸的是，在包含参数服务器的现实世界分布式训练系统中，多个工作者可能同时发送梯度；因此，我们必须解决许多通信阻塞。
- en: When the ratio between the number of workers and the number of parameter servers
    is not optimal, for example, many workers are sending gradients to the same parameter
    server at the same time. The problem gets even worse, and eventually, the blocking
    of communications among different workers or parameter servers becomes a bottleneck.
    Is there a way to prevent this problem?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当工作者数量与参数服务器数量之间的比例不理想时，例如，许多工作者同时向同一个参数服务器发送梯度。问题变得更糟，最终，不同工作者或参数服务器之间的通信阻塞成为瓶颈。有没有办法防止这个问题？
- en: 3.3.2 The solution
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.2 解决方案
- en: In this situation, the two workers need to figure out an approach to continue.
    They have to reconcile, decide which worker will take the next step first, and
    then take turns sending the calculated gradients to that particular parameter
    server. In addition, when one worker finishes sending gradients to update the
    model parameters on that parameter server, the parameter server starts sending
    the updated model partition back to that worker. Thus, the worker has the most
    up-to-date model to be fine-tuned as it’s fed incoming data. If, at the same time,
    another worker is also sending calculated gradients to that parameter server,
    as shown in figure 3.12, another blocking communication occurs, and the workers
    need to reconcile again.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，两个工作者需要找出一种继续的方法。他们必须协调，决定哪个工作者将首先采取下一步，然后轮流向该特定参数服务器发送计算出的梯度。此外，当一个工作者完成向该参数服务器发送梯度以更新模型参数后，该参数服务器开始将更新的模型分区发送回该工作者。因此，工作者拥有最新的模型以进行微调，因为它接收传入的数据。如果同时，另一个工作者也在向该参数服务器发送计算出的梯度，如图3.12所示，将发生另一个阻塞通信，工作者需要再次协调。
- en: '![03-12](../../OEBPS/Images/03-12.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![03-12](../../OEBPS/Images/03-12.png)'
- en: Figure 3.12 One worker is pulling updates while another worker is pushing updates
    to the same parameter server.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 一个工作者正在拉取更新，而另一个工作者正在将更新推送到相同的参数服务器。
- en: This time, unfortunately, the reconciliation may not be easy to resolve, as
    the worker that is trying to send the calculated gradients may not have used the
    latest model when calculating the gradients. This situation may be fine when the
    differences among model versions are small, but eventually, it may cause a huge
    difference in the statistical performance of the trained model.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，不幸的是，协调可能不容易解决，因为试图发送计算出的梯度的工作者在计算梯度时可能没有使用最新的模型。当模型版本之间的差异较小时，这种情况可能还可以，但最终，它可能对训练模型的统计性能造成巨大差异。
- en: If each parameter server stores different model partitions unevenly--perhaps
    the first parameter server stores two-thirds of the model parameters, as shown
    in figure 3.13--calculated gradients using this outdated model partition will
    have a huge effect on the final trained model. In such cases, we may want to drop
    the calculated gradients and let the other worker send the updated gradients to
    the parameter servers.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果每个参数服务器存储不同的模型分区不均匀——也许第一个参数服务器存储了三分之二的模型参数，如图3.13所示——使用这个过时的模型分区计算出的梯度将对最终训练模型产生巨大影响。在这种情况下，我们可能希望丢弃计算出的梯度，让其他工作者将更新的梯度发送到参数服务器。
- en: '![03-13](../../OEBPS/Images/03-13.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![03-13](../../OEBPS/Images/03-13.png)'
- en: Figure 3.13 An example of imbalanced model partitions in which the first parameter
    server contains two-thirds of the entire set of model parameters.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13 不平衡模型分区的一个例子，其中第一个参数服务器包含整个模型参数集的三分之二。
- en: Now another challenge arises. What if the dropped gradients that we consider
    to be outdated were calculated from a larger portion of the entire training data,
    and it could take a long time to recalculate them using the latest model partition
    (figure 3.14)? In this case, we probably want to keep those gradients so we don’t
    waste too much time recalculating them.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在又出现了一个挑战。如果我们认为丢失的梯度是过时的，并且它们是从整个训练数据的大部分计算出来的，那么使用最新的模型分区重新计算它们可能需要很长时间（如图3.14所示）？在这种情况下，我们可能希望保留这些梯度，以免浪费太多时间重新计算它们。
- en: '![03-14](../../OEBPS/Images/03-14.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![03-14](../../OEBPS/Images/03-14.png)'
- en: Figure 3.14 The second worker is trying to push gradients calculated from half
    of the training data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 第二个工人正在尝试推动从训练数据的一半计算得到的梯度。
- en: In real-world distributed machine learning systems with parameter servers, we
    may encounter many challenges and problems that cannot be resolved completely.
    When those situations happen, we have to consider reconciliation and tradeoff
    approaches. As the numbers of workers and parameter servers increase, the cost
    of reconciliation and communication required to pull and push model parameters
    among workers and parameter servers becomes nontrivial. The system will end up
    spending a lot of time communicating between nodes and a small amount of making
    computations among neural network layers.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界的具有参数服务器的分布式机器学习系统中，我们可能会遇到许多无法完全解决的问题和挑战。当这些情况发生时，我们必须考虑协调和权衡方法。随着工作节点和参数服务器的数量增加，在节点之间和参数服务器之间拉取和推送模型参数所需的协调和通信成本变得相当大。系统最终会在节点之间花费大量时间进行通信，而在神经网络层之间进行少量计算。
- en: Even though we may have a lot of experience with the tradeoffs and performance
    differences involved in applying different ratios and computational resources
    for parameter servers and workers to our system, it still seems counterintuitive
    and time-consuming to tune toward a perfect system. In some circumstances, some
    of the workers or parameters fail during training, or the network becomes unstable,
    causing problems when nodes are communicating with push and pull updates. In other
    words, the parameter server pattern may not be suitable for a particular use case
    due to our lack of expertise or available time to work with the underlying distributed
    infrastructure.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们可能对将不同比例和计算资源应用于参数服务器和工作节点的权衡和性能差异有丰富的经验，但调整到一个完美的系统仍然似乎反直觉且耗时。在某些情况下，一些工作节点或参数在训练过程中失败，或者网络变得不稳定，当节点在推送和拉取更新时，会导致问题。换句话说，由于我们缺乏专业知识或可用时间来处理底层分布式基础设施，参数服务器模式可能不适合特定的用例。
- en: Is there any alternative to this problem? The parameter server pattern may be
    one of the few good options for large models, but for simplicity and demonstration
    purposes, let’s assume that the model size does not change. The whole model is
    small enough to fit on a single machine. In other words, each machine has enough
    disk space to store the model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题有没有什么替代方案？参数服务器模式可能是大型模型少数几个好的选择之一，但为了简单和演示目的，让我们假设模型大小不会改变。整个模型足够小，可以放在单个机器上。换句话说，每台机器都有足够的磁盘空间来存储模型。
- en: With that assumption in mind, what would be an alternative to parameter servers
    if we want only to improve the performance of distributed training? Without parameter
    servers, we have only worker nodes, each of which node stores a copy of the entire
    set of model parameters, as shown in figure 3.15.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个假设下，如果我们只想提高分布式训练的性能，参数服务器之外的替代方案会是什么？没有参数服务器，我们只有工作节点，每个节点存储整个模型参数集的一个副本，如图3.15所示。
- en: '![03-15](../../OEBPS/Images/03-15.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![03-15](../../OEBPS/Images/03-15.png)'
- en: Figure 3.15 A distributed model training component with only worker nodes. Every
    worker stores a copy of the entire set of model parameters and consumes partitions
    of data to calculate the gradients.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 仅包含工作节点的分布式模型训练组件。每个工作节点存储整个模型参数集的一个副本，并消费数据分区来计算梯度。
- en: How do we perform model training in this case? Recall that every worker consumes
    some portions of data and calculates the gradients required to update the model
    parameters stored locally on this worker node. When all the worker nodes have
    successfully completed their calculations of gradients, we need to aggregate all
    the gradients and make sure that every worker’s entire set of model parameters
    is updated based on the aggregated gradients. In other words, each worker should
    store a copy of the same updated model. How do we aggregate all the gradients?
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们如何进行模型训练？回想一下，每个工作者消耗一些数据部分并计算更新存储在本工作者节点上的模型参数所需的梯度。当所有工作者节点成功完成其梯度计算后，我们需要聚合所有梯度，并确保每个工作者的整个模型参数集基于聚合梯度进行更新。换句话说，每个工作者应存储同一更新模型的副本。我们如何聚合所有梯度？
- en: We are already familiar with the process for sending gradients from one node
    to another, such as sending the calculated gradients from a worker node to a parameter
    server to update the model parameters in a particular model partition. In general,
    that process is called *point-to-point communication* (figure 3.16). No other
    process is involved.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经熟悉了将梯度从一个节点发送到另一个节点的过程，例如，将工作者节点计算出的梯度发送到参数服务器以更新特定模型分区的模型参数。通常，这个过程被称为*点对点通信*（图3.16）。没有其他进程参与。
- en: '![03-16](../../OEBPS/Images/03-16.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![03-16](../../OEBPS/Images/03-16.png)'
- en: Figure 3.16 An example of point-to-point communication with data being transferred
    between two processes. Note that no other process is involved.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16展示了两个进程之间进行点对点通信的示例，数据在这两个进程之间进行传输。请注意，没有其他进程参与。
- en: In this situation, point-to-point communication is somewhat inefficient. Only
    worker nodes are involved, and we need to perform some kind of aggregation on
    the results from all workers. Fortunately, we can use another type of communication.
    *Collective communication* allows communication patterns across all processes
    in a *group*, which is composed of a subset of all processes. Figure 3.17 illustrates
    collective communication between one process and a group that consists of three
    other processes. In this case, each worker node carries the gradients and wants
    to send them to a group, including the rest of the worker nodes, so that all worker
    nodes will obtain the results from every worker.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，点对点通信效率不高。只有工作者节点参与，我们需要对所有工作者的结果执行某种聚合操作。幸运的是，我们可以使用另一种类型的通信。*集体通信*允许在*组*中跨越所有进程的通信模式，该组由所有进程的子集组成。图3.17说明了单个进程与由三个其他进程组成的组之间的集体通信。在这种情况下，每个工作者节点携带梯度，并希望将它们发送到包括其他工作者节点在内的一个组，以便所有工作者节点都能获得每个工作者的结果。
- en: '![03-17](../../OEBPS/Images/03-17.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![03-17](../../OEBPS/Images/03-17.png)'
- en: Figure 3.17 An example of collective communication between one process and a
    group that consists of three other processes
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17展示了单个进程与由三个其他进程组成的组之间的集体通信示例
- en: For our machine learning models, we usually perform some kind of aggregate operation
    on all the received gradients before sending the aggregated result to all the
    workers. This type of aggregation is called a *reduce function*, which involves
    making a set of numbers into a smaller set of numbers. Examples of reduce functions
    are finding the sum, maximum, minimum, or average of the set of numbers--in our
    case, the gradients we received from all the workers.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的机器学习模型，我们在将聚合结果发送给所有工作者之前，通常会对所有接收到的梯度执行某种聚合操作。这种聚合类型被称为*reduce函数*，它涉及将一组数字转换成更小的数字集。reduce函数的例子包括求和、最大值、最小值或平均值——在我们的情况下，是从所有工作者接收到的梯度。
- en: Figure 3.18 illustrates a reduce operation. Vectors v0, v1, and v2 in each of
    the processes in the process group are merged with the first process via a reduce
    operation.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18说明了reduce操作。进程组中每个进程的向量v0、v1和v2通过reduce操作与第一个进程合并。
- en: '![03-18](../../OEBPS/Images/03-18.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![03-18](../../OEBPS/Images/03-18.png)'
- en: Figure 3.18 An example of a reduce operation with the sum as the reduce function
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18展示了使用求和作为reduce函数的reduce操作示例
- en: When the gradients are reduced in a distributed fashion, we send the reduced
    gradients to all the workers so that they are on the same page and can update
    the model parameters in the same way, ensuring that they have exactly the same
    models. This kind of operation is called a *broadcast* operation and is often
    used to perform collective communications. Figure 3.19 illustrates a broadcast
    operation that sends a value to every process in the process group.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 当梯度以分布式方式减少时，我们将减少后的梯度发送到所有工作节点，以便它们处于同一页面上，并可以以相同的方式更新模型参数，确保它们具有完全相同的模型。这种操作称为*广播*操作，通常用于执行集体通信。图3.19说明了向进程组中的每个进程发送值的广播操作。
- en: '![03-19](../../OEBPS/Images/03-19.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![03-19](../../OEBPS/Images/03-19.png)'
- en: Figure 3.19 An example of a broadcast operation that sends a value to every
    process in the process group
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![03-19](../../OEBPS/Images/03-19.png)'
- en: The combination of reduce and broadcast operations here is called *allreduce*,
    which reduces the results based on a specified reduce function and then distributes
    the reduced results to all processes--in our case, to all the workers so that
    the model stored on each worker is exactly the same and is up to date (figure
    3.20). When we finish a round of an allreduce operation, we start the next round
    by feeding new data to the updated model, calculating gradients, and performing
    the allreduce operation again to gather all gradients from workers to update the
    model.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这里reduce和广播操作的组合称为*allreduce*，它基于指定的reduce函数减少结果，然后将减少后的结果分布到所有进程——在我们的情况下，分布到所有工作节点，以便每个工作节点上存储的模型完全相同且是最新的（图3.20）。当我们完成一轮allreduce操作后，我们通过向更新的模型提供新数据，计算梯度，并再次执行allreduce操作来收集所有工作节点的梯度以更新模型，开始下一轮操作。
- en: '![03-20](../../OEBPS/Images/03-20.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![03-20](../../OEBPS/Images/03-20.png)'
- en: Figure 3.20 An example of an allreduce operation that reduces the results on
    each process in the group and then sends the result to every process in the group
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.20：一个全量减少操作的示例，该操作在每个组进程上减少结果，然后将结果发送到组中的每个进程
- en: Let’s take a break to see what we’ve accomplished. We’ve successfully used the
    collective communication pattern, which takes advantage of the underlying network
    infrastructure, to perform allreduce operations for communicating gradients among
    multiple workers and allows us to train a medium-sized machine learning model
    in a distributed fashion. As a result, we no longer need parameter servers; thus,
    there is no communication overhead between parameter servers and workers. The
    collective communication pattern is useful in machine learning systems and also
    in distributed and parallel computing systems, where concurrency is applied to
    computations and communication primitives such as broadcast and reduce are critical
    for communicating among different nodes. We’ll apply this pattern in section 9.2.2.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们休息一下，看看我们取得了什么成果。我们已经成功使用了集体通信模式，它利用了底层网络基础设施，来执行多个工作节点之间的梯度通信的全量减少操作，并允许我们以分布式方式训练一个中等规模的机器学习模型。因此，我们不再需要参数服务器；因此，参数服务器和工作节点之间没有通信开销。集体通信模式在机器学习系统中很有用，在分布式和并行计算系统中也很有用，在这些系统中，并发应用于计算和通信原语，如广播和减少，对于不同节点之间的通信至关重要。我们将在第9.2.2节中应用这种模式。
- en: 3.3.3 Discussion
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.3 讨论
- en: The collective communication pattern is a great alternative to parameter servers
    when the machine learning model we are building is not too large. As a result,
    there is no communication overhead among parameter servers and workers, and it’s
    no longer necessary to spend a lot of effort on tuning the ratio between the number
    of workers and parameter servers. In other words, we can easily add workers to
    speed up the model training process without worrying about performance regression.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们构建的机器学习模型不是很大时，集体通信模式是参数服务器的一个很好的替代方案。因此，参数服务器和工作节点之间没有通信开销，也就不再需要花费大量精力去调整工作节点和参数服务器之间的比例。换句话说，我们可以轻松地添加工作节点来加速模型训练过程，而不用担心性能下降。
- en: One potential problem is worth mentioning, though. After we incorporate the
    collective communication pattern by applying the allreduce operation, each worker
    will need to communicate with all its peer workers, which may slow down the entire
    training process if the number of workers becomes large. Actually, collective
    communications rely on communication over the network infrastructure, and we still
    haven’t fully used all the benefits of that yet in the allreduce operation.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，有一个潜在问题值得提及。在我们通过应用allreduce操作引入集体通信模式后，每个工作者都需要与其所有对等工作者通信，如果工作者数量变得很大，这可能会减慢整个训练过程。实际上，集体通信依赖于网络基础设施的通信，而我们尚未在allreduce操作中充分利用这些好处。
- en: Fortunately, we could use better collective communication algorithms to update
    the model more efficiently. One example is the *ring-allreduce* algorithm. The
    process is similar to that of the allreduce operation, but the data is transferred
    in ringlike fashion without the reduce operation. Each *N* worker needs to communicate
    with only two of its peer workers 2 * (*N* - 1) times to update all the model
    parameters completely. In other words, this algorithm is bandwidth-optimal; if
    the aggregated gradients are large enough, it will optimally use the underlying
    network infrastructure.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们可以使用更好的集体通信算法来更有效地更新模型。一个例子是*ring-allreduce*算法。其过程与allreduce操作类似，但数据以环形方式传输，而不进行reduce操作。每个*N*个工作者只需要与其两个对等工作者通信2
    * (*N* - 1)次，以完全更新所有模型参数。换句话说，这个算法是带宽最优的；如果聚合的梯度足够大，它将最优地使用底层网络基础设施。
- en: Both the parameter server pattern and the collective communication pattern make
    distributed training scalable and efficient. In practice, however, any of the
    workers or parameter servers may not start due to a lack of resources and may
    fail in the middle of distributed training. Section 3.4 introduces patterns that
    will help in those situations and make the entire distributed training process
    more reliable.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 参数服务器模式和集体通信模式使分布式训练可扩展且高效。然而，在实践中，任何工作者或参数服务器可能由于资源不足而无法启动，也可能在分布式训练过程中失败。第3.4节介绍了有助于这些情况并使整个分布式训练过程更可靠的模式。
- en: 3.3.4 Exercises
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.4 练习
- en: Do blocking communications happen only among the workers?
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阻塞通信是否只发生在工作者之间？
- en: Do workers update the model parameters stored on them asynchronously or synchronously?
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 工作者是以异步还是同步方式更新存储在他们那里的模型参数？
- en: Can you represent an allreduce operation with a composition of other collective
    communication operations?
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能否用其他集体通信操作的组合来表示allreduce操作？
- en: 3.4 Elasticity and fault-tolerance pattern
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.4 弹性性和容错模式
- en: Both the parameter server pattern and the collective communication pattern enable
    us to scale up the distributed model training process. Parameter servers can be
    useful for handling large models that don’t fit on a single machine; a large model
    can be partitioned and stored on multiple parameter servers, while individual
    workers can perform heavy computations and update each individual partition of
    model parameters asynchronously. When we observe too much communication overhead
    when using parameter servers, however, we can use the collective communication
    pattern to speed up the training process for medium-size models.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 参数服务器模式和集体通信模式都能使我们扩展分布式模型训练过程。参数服务器对于处理不适合单台机器的大型模型可能很有用；一个大型模型可以被分割并存储在多个参数服务器上，而单个工作者可以执行繁重的计算并异步更新模型参数的各个分区。然而，当我们使用参数服务器时观察到过多的通信开销，我们则可以使用集体通信模式来加速中等规模模型的训练过程。
- en: 'Let’s assume that our distributed training component is well designed; can
    train machine learning models efficiently; and can handle the requirements of
    different types of models, using patterns such as parameter server and collective
    communication. One thing worth mentioning is that distributed model training is
    a long-running task, usually persisting for hours, days, or even weeks. Like all
    other types of software and systems, this long-running task is vulnerable to unexpected
    intervention. Because model training is a long-running process, it may be affected
    by internal or external intervention at any minute. Following are some examples
    of interventions that often occur in a distributed model training system:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的分布式训练组件设计良好；可以高效地训练机器学习模型；并且可以使用参数服务器和集体通信等模式处理不同类型模型的请求。有一点值得提及的是，分布式模型训练是一个长期运行的任务，通常持续数小时、数天甚至数周。像所有其他类型的软件和系统一样，这个长期运行的任务容易受到意外干预的影响。由于模型训练是一个长期过程，它可能随时受到内部或外部干预的影响。以下是一些在分布式模型训练系统中经常发生的干预示例：
- en: Parts of the dataset are corrupted or cannot be used to train the model successfully.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的部分损坏或无法成功用于训练模型。
- en: The distributed cluster that the distributed training model depends on may experience
    an unstable or disconnected network due to weather conditions or human error.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式训练模型所依赖的分布式集群可能会因为天气条件或人为错误而遇到不稳定或断开连接的网络。
- en: Some of the parameter servers or worker nodes are preempted; the computational
    resources they rely on are rescheduled for tasks and nodes that have higher priority.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些参数服务器或工作节点被抢占；它们依赖的计算资源被重新安排用于具有更高优先级的任务和节点。
- en: '3.4.1 The problem: Handling unexpected failures when training with limited
    computational resources'
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.1 问题：处理有限计算资源下的意外故障
- en: When unexpected interventions happen, if no actions are taken to address them,
    problems start to accumulate. In the first example in the preceding section, all
    workers use the same logic to consume the data to fit the model; when they see
    corrupted data that the training code is not able to handle, all of them fail
    eventually. In the second example, when the network becomes unstable, communications
    among parameter servers and workers will hang until the network recovers. In the
    third example, when the parameter servers or worker nodes are preempted, the entire
    training process is forced to stop, leading to unrecoverable failure. What should
    we do to help the distributed training system recover in those situations? Do
    we have a way to prevent unexpected failures?
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当意外干预发生时，如果不采取行动解决它们，问题开始累积。在前一节的第一个例子中，所有工作节点使用相同的逻辑来消费数据以适应模型；当他们看到训练代码无法处理的损坏数据时，最终都会失败。在第二个例子中，当网络不稳定时，参数服务器和工作节点之间的通信会挂起，直到网络恢复。在第三个例子中，当参数服务器或工作节点被抢占时，整个训练过程被迫停止，导致不可恢复的故障。我们应该怎么做来帮助分布式训练系统在这些情况下恢复？我们有没有防止意外故障的方法？
- en: 3.4.2 The solution
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.2 解决方案
- en: Let’s take a look at the first situation. Assume that the training process encounters
    a batch of data that’s corrupted. In figure 3.21, some of the videos in the YouTube-8M
    dataset were accidentally modified by third-party video editing software after
    they were downloaded from the original source. The first worker node is trying
    to read those portions of the data to feed the model. The machine learning model
    object that was initialized earlier cannot be fed with the edited and incompatible
    video data.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看第一种情况。假设训练过程遇到一批损坏的数据。在图3.21中，YouTube-8M数据集中的一些视频在从原始来源下载后，被第三方视频编辑软件意外修改。第一个工作节点正在尝试读取这些数据部分以供模型使用。之前初始化的机器学习模型对象无法用编辑过的和不兼容的视频数据来喂养。
- en: '![03-21](../../OEBPS/Images/03-21.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![03-21](../../OEBPS/Images/03-21.png)'
- en: Figure 3.21 A worker encounters new batches of training data that’s being edited
    and cannot be consumed successfully.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.21 工作节点遇到正在编辑的新批次训练数据，无法成功消费。
- en: 'When this situation happens, the training process encounters an unexpected
    failure: the existing code does not contain the logic to handle an edited or corrupted
    dataset. In other words, we need to modify the distributed model training logic
    to handle this situation and then retrain the model from scratch.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当这种情况发生时，训练过程遇到意外故障：现有的代码不包含处理编辑或损坏数据集的逻辑。换句话说，我们需要修改分布式模型训练逻辑以处理这种情况，然后从头开始重新训练模型。
- en: Let’s start the distributed training process again and see whether everything
    works well. We can skip the batches of data that we found to be corrupted and
    continue to train the machine learning model with the next batches of the remaining
    data.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次开始分布式训练过程，看看是否一切正常。我们可以跳过我们发现已损坏的数据批次，并继续使用剩余数据的下一个批次来训练机器学习模型。
- en: Unfortunately, after the model has been trained for hours with half of the data,
    we realize that the new batches of data are being consumed much more slowly than
    before. After some digging and communicating with the DevOps team, we found that
    the network has become extremely unstable due to an incoming storm at one of our
    data centers--the second scenario mentioned earlier. If our dataset is residing
    on a remote machine instead of having been downloaded to a local machine, as shown
    in figure 3.22, the training process would be stuck waiting for a successful connection
    with the remote database. While waiting, we should *checkpoint* (store) the current
    trained model parameters and pause the training process. Then we can easily resume
    the training process when the network becomes stable again.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在用一半的数据训练了数小时后，我们意识到新批次的数据消耗速度比以前慢得多。经过一番调查并与DevOps团队沟通后，我们发现由于我们数据中心之一的一个风暴，网络变得极其不稳定——这是之前提到的第二种情况。如果我们的数据集驻留在远程机器上而不是下载到本地机器上，如图3.22所示，训练过程将停滞等待与远程数据库建立成功的连接。在等待期间，我们应该*检查点*（存储）当前训练的模型参数并暂停训练过程。然后，当网络再次稳定时，我们可以轻松地恢复训练过程。
- en: '![03-22](../../OEBPS/Images/03-22.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![03-22](../../OEBPS/Images/03-22.png)'
- en: Figure 3.22 A worker encounters an unstable network while fetching data from
    a remote database.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.22 一个工人在从远程数据库获取数据时遇到了一个不稳定的网络。
- en: 'Did the unstable network have other effects? We neglected one fact: we also
    rely on the network for communication between worker and parameter server nodes
    to send the calculated gradients and update the model parameters. Recall that
    if the collective communication pattern is incorporated, the training process
    is synchronous. In other words, one worker’s communication blocks other workers’
    communications; we would need to obtain all gradients from all workers to aggregate
    the results to update the model parameters. If at least one worker becomes slow
    in communicating, the cascading effect eventually leads to a stuck training process.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 不稳定的网络是否有其他影响？我们忽略了一个事实：我们也依赖网络在工人和参数服务器节点之间进行通信，以发送计算出的梯度并更新模型参数。回想一下，如果集合并行通信模式被整合，训练过程是同步的。换句话说，一个工人的通信会阻塞其他工人的通信；我们需要从所有工人那里获取所有梯度来聚合结果以更新模型参数。如果至少有一个工人在通信中变慢，级联效应最终会导致训练过程停滞。
- en: In figure 3.23, three worker processes in the same process group are performing
    an allreduce operation. Two of the communications become slow due to the unstable
    network that the underlying distributed cluster is experiencing. As a result,
    two of the processes that depend on the slow communications do not receive some
    values (denoted by question marks) on time, and the entire allreduce operation
    is stuck until everything is received.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在图3.23中，同一进程组中的三个工作进程正在执行allreduce操作。由于底层分布式集群遇到的不稳定网络，其中两个通信变得缓慢。结果，依赖于缓慢通信的两个进程没有及时接收到一些值（用问号表示），整个allreduce操作直到所有值都接收完毕才停止。
- en: '![03-23](../../OEBPS/Images/03-23.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![03-23](../../OEBPS/Images/03-23.png)'
- en: Figure 3.23 An allreduce process with slow communications due to the unstable
    network that blocks the entire training process
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.23 由于不稳定网络导致通信缓慢，整个训练过程被阻塞的全reduce过程
- en: Can we do anything to continue training without being affected by the degrading
    network performance of individual nodes? In this case, first, we can abandon the
    two worker processes that are experiencing slow network connection; then we can
    abandon the current allreduce operation. Given the nature of the collective communication
    pattern, the remaining workers still have exactly the same copy of the model,
    so we can continue the training process by reconstructing a new worker process
    group that consists of the remaining workers and then performing the allreduce
    operation again.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能做些什么来继续训练而不会受到单个节点网络性能下降的影响？在这种情况下，首先，我们可以放弃那些网络连接缓慢的两个工作进程；然后我们可以放弃当前的allreduce操作。鉴于集体通信模式的特点，剩余的工作者仍然有完全相同的模型副本，因此我们可以通过重建一个新的工作进程组（由剩余的工作者组成）并再次执行allreduce操作来继续训练过程。
- en: The approach could also deal with situations in which some worker nodes are
    preempted, with their computational resources rescheduled to higher-priority tasks
    and nodes. When those workers get preempted, we reconstruct the worker process
    group and then perform the allreduce operation. This approach allows us to avoid
    wasting resources to train the model from scratch when unexpected failures happen.
    Instead, we can pick up the training process from where it paused and use the
    existing workers to which we’ve already allocated computational resources. If
    we have additional resources, we can easily add workers and then reconstruct the
    worker process groups to train more efficiently. In other words, we can easily
    scale the distributed training system up and down so that the entire system is
    elastic in terms of available resources. Many other distributed systems apply
    the same idea to make sure that the systems in place are reliable and scalable.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法也可以处理某些工作节点被抢占的情况，它们的计算资源被重新安排到更高优先级的任务和节点。当这些工作节点被抢占时，我们重建工作进程组，然后执行allreduce操作。这种方法使我们能够在意外故障发生时避免浪费资源从头开始训练模型。相反，我们可以从暂停的地方继续训练过程，并使用我们已分配计算资源的现有工作者。如果我们有额外的资源，我们可以轻松地添加工作者，然后重建工作进程组以更有效地训练。换句话说，我们可以轻松地扩展和缩小分布式训练系统，使整个系统在可用资源方面具有弹性。许多其他分布式系统也应用同样的想法，以确保现有的系统既可靠又可扩展。
- en: 3.4.3 Discussion
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.3 讨论
- en: We’ve successfully continued and recovered the distributed training process
    without wasting the resources we used to calculate the gradients from each worker.
    What if our distributed training uses parameter servers instead of collective
    communications with only workers?
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功继续并恢复了分布式训练过程，而没有浪费我们从每个工作者计算梯度的资源。如果我们使用参数服务器而不是仅与工作者进行集体通信的分布式训练，会怎样呢？
- en: Recall that when parameter servers are used, each parameter server stores a
    model partition that contains a subset of the complete set of model parameters.
    If we need to abandon any of the workers or parameter servers, such as when some
    communications failed or got stuck due to an unstable network on one parameter
    server or when the workers got preempted, we need to checkpoint the model partition
    in the failed nodes and then repartition the model partitions to the parameter
    servers that are still alive.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，当使用参数服务器时，每个参数服务器存储一个包含模型参数完整集合子集的模型分区。如果我们需要放弃任何工作者或参数服务器，例如，当某些通信由于某个参数服务器上的不稳定网络而失败或卡住，或者当工作者被抢占时，我们需要在失败的节点上检查点模型分区，然后将模型分区重新分区到仍然存活的服务器上。
- en: In reality, many challenges are still involved. How do we checkpoint the model
    partitions, and where do we save them? How often should we checkpoint them to
    make sure that they are as recent as possible?
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实中，仍然存在许多挑战。我们如何检查点模型分区，并将它们保存在哪里？我们应该多久检查点一次，以确保它们尽可能新？
- en: 3.4.4 Exercises
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.4 练习
- en: What is the most important thing to save in a checkpoint in case any failures
    happen in the future?
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果将来发生任何故障，在检查点中保存最重要的东西是什么？
- en: When we abandon the workers that are stuck or unable to recover without having
    time to make model checkpoints, where should we obtain the latest model, assuming
    that we are using the collective communication pattern?
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们放弃那些卡住或无法在没有时间制作模型检查点的情况下恢复的工作者时，如果我们使用集体通信模式，我们应该在哪里获取最新的模型？
- en: 3.5 Answers to exercises
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.5 练习答案
- en: Section 3.2.4
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3.2.4节
- en: No, because the training happens on a single laptop.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不，因为训练是在单个笔记本电脑上进行的。
- en: The system will end up spending a lot of time communicating between nodes and
    a small amount of time making the computations among neural network layers.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 系统最终会在节点之间花费大量时间进行通信，而在神经网络层之间进行计算的时间却很少。
- en: We need more disk space for parameter servers to store large model partitions
    and less CPUs/GPUs/memory on them because parameter servers do not perform heavy
    computations.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于参数服务器不执行重计算，我们需要更多的磁盘空间来存储大型模型分区，并且需要较少的CPU/GPU/内存。
- en: Section 3.3.4
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3.3.4节
- en: No. They also appear between workers and parameter servers.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不，它们也出现在工作节点和参数服务器之间。
- en: Asynchronously
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 异步
- en: You use a reduce operation and then a broadcast operation.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您使用reduce操作，然后是broadcast操作。
- en: Section 3.4.4
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3.4.4节
- en: The most recent model parameters
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最新的模型参数
- en: Under the collective communication pattern, the remaining workers still have
    the same copy of the model, which we can use to continue training.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在集体通信模式中，剩余的工作节点仍然拥有相同的模型副本，我们可以使用它来继续训练。
- en: Summary
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Distributed model training is different from the traditional model training
    process, given the size and location of the dataset, the size of the model, the
    computational resources, and the underlying network infrastructure.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式模型训练与传统的模型训练过程不同，这取决于数据集的大小和位置、模型的大小、计算资源以及底层网络基础设施。
- en: We can use parameter servers to build large and complex models, storing partitions
    of the model parameters on each server.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用参数服务器来构建大型和复杂的模型，将模型参数的分区存储在每个服务器上。
- en: If communications between workers and parameter servers develop a bottleneck,
    we can switch to the collective communication pattern to improve distributed model
    training performance for small or medium-sized models.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果工作节点和参数服务器之间的通信出现瓶颈，我们可以切换到集体通信模式来提高小型或中型模型的分布式模型训练性能。
- en: Unexpected failures happen during distributed model training, and we can take
    various approaches to avoid wasting computational resources.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分布式模型训练过程中，可能会发生意外故障，我们可以采取各种方法来避免浪费计算资源。
