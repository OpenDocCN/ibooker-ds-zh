- en: 9 Adding observability with containerized monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 使用容器化监控添加可观察性
- en: Autonomous applications scale themselves up and down to meet incoming traffic,
    and they heal themselves when there are intermittent faults. It sounds too good
    to be true--and it probably is. The container platform can do a lot of the operations
    work for you if you build your Docker images with health checks, but you still
    need ongoing monitoring and alerting so humans can get involved when things go
    badly wrong. If you don’t have any insight into your containerized application,
    that’s going to be the number one thing that stops you going to production.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 自主应用程序会根据传入流量自动扩展和缩减，当出现间歇性故障时会自我修复。这听起来太好了，以至于不太可能是真的——而且可能确实如此。如果你在构建 Docker
    镜像时包含健康检查，容器平台可以为你做很多操作工作，但你仍然需要持续的监控和警报，以便在事情出错时人类可以介入。如果你对你的容器化应用程序没有任何洞察，这将是你无法进入生产环境的头号障碍。
- en: 'Observability is a critical piece of the software landscape when you’re running
    applications in containers--it tells you what your applications are doing and
    how well they’re performing, and it can help you pinpoint the source of problems.
    In this chapter you’ll learn how to use a well-established approach to monitoring
    with Docker: exposing metrics from your application containers and using Prometheus
    to collect them and Grafana to visualize them in user-friendly dashboards. These
    tools are open source and cross-platform, and they run in containers alongside
    your application. That means you get the same insight into your application performance
    in every environment, from development to production.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在容器中运行应用程序时，可观察性是软件景观中的一个关键部分——它告诉你应用程序在做什么以及它们的性能如何，并且可以帮助你确定问题的根源。在本章中，你将学习如何使用
    Docker 的一个成熟监控方法：从你的应用程序容器中公开指标，并使用 Prometheus 收集它们，使用 Grafana 在用户友好的仪表板中可视化它们。这些工具是开源的，跨平台的，并且与你的应用程序一起在容器中运行。这意味着你可以在每个环境中获得相同的应用程序性能洞察，从开发到生产。
- en: 9.1 The monitoring stack for containerized applications
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 容器化应用程序的监控堆栈
- en: Monitoring is different when apps are running in containers. In a traditional
    environment, you might have a monitoring dashboard showing a list of servers and
    their current utilization--disk space, memory, CPU--and alerts to tell you if
    any become overworked and are likely to stop responding. Containerized apps are
    more dynamic--they may run across dozens or hundreds of containers that are short-lived
    and are created or removed by the container platform.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 监控在容器中运行的应用程序时有所不同。在传统环境中，你可能有一个监控仪表板显示服务器列表及其当前利用率——磁盘空间、内存、CPU——以及警报来告诉你是否有任何服务器过载并且可能停止响应。容器化的应用程序更加动态——它们可能运行在数十或数百个短暂存在的容器中，这些容器由容器平台创建或删除。
- en: You need a monitoring approach that is container-aware, with tools that can
    plug into the container platform for discovery and find all the running applications
    without a static list of container IP addresses. Prometheus is an open source
    project that does just that. It’s a mature product that is overseen by the Cloud
    Native Computing Foundation (the same foundation behind Kubernetes and the containerd
    container runtime). Prometheus runs in a Docker container, so you can easily add
    a monitoring stack to your applications. Figure 9.1 shows what that stack looks
    like.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个容器感知的监控方法，使用能够连接到容器平台进行发现并找到所有运行中的应用程序的工具，而无需静态的容器 IP 地址列表。Prometheus 是一个开源项目，正是这样做的。它是一个成熟的产品，由云原生计算基金会（Kubernetes
    和 containerd 容器运行时的背后基金会）监督。Prometheus 在 Docker 容器中运行，因此你可以轻松地为应用程序添加监控堆栈。图 9.1
    展示了该堆栈的外观。
- en: '![](../Images/9-1.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-1.jpg)'
- en: Figure 9.1 Running Prometheus in a container to monitor other containers and
    Docker itself
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 在容器中运行 Prometheus 以监控其他容器和 Docker 本身
- en: 'Prometheus brings one very important aspect to monitoring: consistency. You
    can export the same type of metrics for all your applications, so you have a standard
    way to monitor them whether they’re .NET apps in Windows containers or Node.js
    apps in Linux containers. You only have one query language to learn, and you can
    apply it for your whole application stack.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 为监控带来了一个非常重要的方面：一致性。你可以为所有应用程序导出相同类型的指标，这样你就有了一个标准的方式来监控它们，无论它们是
    Windows 容器中的 .NET 应用程序还是 Linux 容器中的 Node.js 应用程序。你只需要学习一种查询语言，就可以将其应用于整个应用程序堆栈。
- en: Another good reason for using Prometheus is that the Docker Engine can also
    export metrics in that format, which gives you insight into what’s happening in
    the container platform too. You need to explicitly enable Prometheus metrics in
    your Docker Engine configuration--you saw how to update the config in chapter
    5\. You can edit the `daemon.json` file directly in `C:\ProgramData\docker\config`
    on Windows, or `/etc/docker` on Linux. Alternatively, on Docker Desktop you can
    right-click the whale icon, choose Settings, and edit the configuration in the
    Daemon section.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Prometheus的另一个好理由是Docker引擎也可以以该格式导出指标，这让你也能了解容器平台上的情况。你需要在Docker引擎配置中显式启用Prometheus指标--你可以在第5章中看到如何更新配置。在Windows上，你可以直接在`C:\ProgramData\docker\config`中编辑`daemon.json`文件，或者在Linux上的`/etc/docker`。或者，在Docker
    Desktop上，你可以右键单击鲸鱼图标，选择设置，并在守护进程部分编辑配置。
- en: 'Try it now Open your configuration settings and add two new values:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试吧 打开您的配置设置并添加两个新值：
- en: '`     "metrics-addr" : "0.0.0.0:9323",` `     "experimental": true`'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '`     "metrics-addr" : "0.0.0.0:9323",` `     "experimental": true`'
- en: These settings enable monitoring and publish metrics on port 9323.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设置启用了监控并在端口9323上发布指标。
- en: You can see my full configuration file in figure 9.2.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图9.2中看到我的完整配置文件。
- en: '![](../Images/9-2.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-2.jpg)'
- en: Figure 9.2 Configuring the Docker Engine to export metrics in Prometheus format
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 配置Docker引擎以导出Prometheus格式的指标
- en: Docker Engine metrics are currently an experimental feature, which means the
    details it provides could change. But it’s been an experimental feature for a
    long time, and it’s been stable. It’s worth including in your dashboards because
    it adds another layer of detail to the overall health of your system. Now that
    you have metrics enabled, you can browse to http:/ /localhost:9323/metrics and
    see all the information Docker provides. Figure 9.3 shows my metrics, which include
    information about the machine Docker is running on as well as the containers Docker
    is managing.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Docker引擎指标目前是一个实验性功能，这意味着它提供的详细信息可能会改变。但这个实验性功能已经有一段时间了，并且已经稳定。它值得包含在您的仪表板中，因为它为系统的整体健康状况增加了另一层细节。现在您已经启用了指标，您可以浏览到http://localhost:9323/metrics来查看Docker提供的信息。图9.3显示了我的指标，包括Docker运行的机器以及Docker管理的容器信息。
- en: '![](../Images/9-3.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-3.jpg)'
- en: Figure 9.3 Sample metrics captured by Docker and exposed through the HTTP API
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 Docker捕获的样本指标并通过HTTP API公开
- en: This output is in Prometheus format. It’s a simple text-based representation
    where each metric is shown with its name and value, and the metric is preceded
    by some help text stating what the metric is and the type of data. These basic
    lines of text are the core of your container-monitoring solution. Each component
    will expose an endpoint like this providing current metrics; when Prometheus collects
    them, it adds a timestamp to the data and stores them with all the previous collections,
    so you can query data with aggregations or track changes over time.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此输出为Prometheus格式。它是一种简单的基于文本的表示，其中每个指标都显示其名称和值，指标之前有一些帮助文本说明指标是什么以及数据类型。这些基本的文本行是您容器监控解决方案的核心。每个组件都会公开一个类似这样的端点，提供当前指标；当Prometheus收集它们时，它会给数据添加时间戳，并将它们与所有之前的收集存储在一起，这样您就可以使用聚合查询数据或跟踪随时间的变化。
- en: 'Try it now You can run Prometheus in a container to read the metrics from your
    Docker machine, but first you need to get the machine’s IP address. Containers
    don’t know the IP address of the server they’re running on, so you need to find
    it first and pass it as an environment variable to the container:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试吧 你可以在容器中运行Prometheus来读取Docker机器的指标，但首先你需要获取机器的IP地址。容器不知道它们运行的服务器的IP地址，所以你需要先找到它，并将其作为环境变量传递给容器：
- en: '`     # load your machine''s IP address into a variable - on Windows:` `     $hostIP
    = $(Get-NetIPConfiguration | Where-Object {$_.IPv4DefaultGateway -ne $null }).IPv4Address.IPAddress`
           `     # on Linux:` `     hostIP=$(ip route get 1 | awk ''{print $NF;exit}'')`
           `     # and on Mac:` `     hostIP=$(ifconfig en0 | grep -e ''inet\s'' |
    awk ''{print $2}'')`        `     # pass your IP address as an environment variable
    for the container:` `     docker container run -e DOCKER_HOST=$hostIP -d -p 9090:9090
    diamol/prometheus:2.13.1`'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`     # 将你的机器的IP地址加载到一个变量中 - 在Windows上：` `     $hostIP = $(Get-NetIPConfiguration
    | Where-Object {$_.IPv4DefaultGateway -ne $null }).IPv4Address.IPAddress` `     #
    在Linux上：` `     hostIP=$(ip route get 1 | awk ''{print $NF;exit}'')` `     # 以及在Mac上：`
    `     hostIP=$(ifconfig en0 | grep -e ''inet\s'' | awk ''{print $2}'')` `     #
    将你的IP地址作为环境变量传递给容器：` `   docker container run -e DOCKER_HOST=$hostIP -d -p 9090:9090
    diamol/prometheus:2.13.1`'
- en: The configuration in the `diamol/prometheus` Prometheus image uses the `DOCKER_
    HOST` IP address to talk to your host machine and collect the metrics you’ve configured
    in the Docker Engine. It’s rare that you’ll need to access a service on the host
    from inside the container, and if you do, you would usually use your server name
    and Docker would find the IP address. In a development environment that might
    not work, but the IP address approach should be fine.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在`diamol/prometheus` Prometheus镜像中的配置使用`DOCKER_HOST` IP地址与主机机器通信并收集你在Docker
    Engine中配置的指标。通常情况下，你不需要从容器内部访问主机上的服务，如果你需要这样做，你通常会使用你的服务器名称，Docker会找到IP地址。在开发环境中，这可能不起作用，但IP地址方法应该是可行的。
- en: 'Prometheus is running now. It does several things: it runs a scheduled job
    to pull the metrics from your Docker host, it stores those metric values alongside
    a timestamp in its own database, and it has a basic web UI you can use to navigate
    the metrics. The Prometheus UI shows all the information from Docker’s `/metrics`
    endpoint, and you can filter the metrics and display them in tables or graphs.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus现在正在运行。它做了几件事情：它运行一个计划任务从你的Docker主机拉取指标，它将这些指标值与时间戳一起存储在其自己的数据库中，并且它有一个基本的Web
    UI，你可以用它来导航指标。Prometheus UI显示了Docker `/metrics`端点的所有信息，你可以过滤指标并以表格或图形的形式显示它们。
- en: Try it now Browse to http:/ /localhost:9090 and you’ll see the Prometheus web
    interface. You can check that Prometheus can access the metrics by browsing to
    the Status > Targets menu option. Your `DOCKER_HOST` state should be green, which
    means Prometheus has found it.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 浏览到http://localhost:9090，你会看到Prometheus的Web界面。你可以通过浏览到状态 > 目标菜单选项来检查Prometheus是否可以访问指标。你的`DOCKER_HOST`状态应该是绿色的，这意味着Prometheus已经找到了它。
- en: Then switch to the Graph menu and you’ll see a dropdown list showing all the
    available metrics that Prometheus has collected from Docker. One of those is `engine_daemon_container_actions_seconds_sum`
    , which is a record of how long different container actions have taken. Select
    that metric and click Execute, and your output will be similar to mine in figure
    9.4, showing the time taken to create, delete, and start containers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 然后切换到图形菜单，你会看到一个下拉列表，显示Prometheus从Docker收集的所有可用指标。其中之一是`engine_daemon_container_actions_seconds_sum`，这是不同容器操作耗时记录。选择该指标并点击执行，你的输出将类似于图9.4，显示创建、删除和启动容器所需的时间。
- en: The Prometheus UI is a simple way to see what’s being collected and run some
    queries. Look around the metrics and you’ll see that Docker records a lot of information
    points. Some are high-level readouts, like the number of containers in each state
    and the number of health checks that have failed; others give low-level details,
    like the amount of memory the Docker Engine has allocated; and some are static
    pieces of information, like the number of CPUs Docker has available. These are
    infrastructure-level metrics, which could all be useful things to include in your
    status dashboard.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus UI是一个简单的方式来查看正在收集的内容并运行一些查询。查看指标，你会看到Docker记录了大量的信息点。有些是高级读数，如每个状态的容器数量和失败的检查数量；其他提供低级细节，如Docker
    Engine分配的内存量；还有一些是静态信息，如Docker可用的CPU数量。这些都是基础设施级别的指标，所有这些都可以包括在你的状态仪表板中。
- en: '![](../Images/9-4.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图9.4](../Images/9-4.jpg)'
- en: Figure 9.4 Prometheus has a simple web UI that you can use to find metrics and
    run queries.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 Prometheus提供了一个简单的Web界面，你可以使用它来查找指标和运行查询。
- en: Your applications will expose their own metrics, which will also record details
    at different levels. The goal is to have a metrics endpoint in each of your containers
    and have Prometheus collect metrics from them all on a regular schedule. Prometheus
    will store enough information for you to build a dashboard that shows the overall
    health of the whole system.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 您的应用程序将公开它们自己的度量，这些度量也将记录不同级别的详细信息。目标是让每个容器都有一个度量端点，并且Prometheus定期从它们中收集度量。Prometheus将存储足够的信息，以便您构建一个仪表板，显示整个系统的整体健康状况。
- en: 9.2 Exposing metrics from your application
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 从您的应用程序公开度量
- en: We’ve looked at the metrics the Docker Engine exposes, because that’s an easy
    way to get started with Prometheus. Exposing a useful set of metrics from each
    of your application containers takes more effort, because you need code to capture
    the metrics and provide the HTTP endpoint for Prometheus to call. It’s not as
    much work as it sounds, because there are Prometheus client libraries for all
    the main programming languages to do that for you.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经查看Docker Engine公开的度量，因为这是一个开始使用Prometheus的简单方法。从每个应用程序容器公开一组有用的度量需要更多的努力，因为您需要代码来捕获度量并为Prometheus提供一个HTTP端点进行调用。这并不像听起来那么困难，因为所有主要编程语言都有Prometheus客户端库来为您完成这项工作。
- en: In the code for this chapter, I’ve revisited the NASA image gallery app and
    added Prometheus metrics to each of my components. I’m using the official Prometheus
    clients for Java and Go, and the community client library for Node.js. Figure
    9.5 shows how each application container is now packaged with a Prometheus client
    that collects and exposes metrics.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的代码中，我重新审视了NASA图片库应用程序，并为我的每个组件添加了Prometheus度量。我使用Java和Go的官方Prometheus客户端，以及Node.js的社区客户端库。图9.5显示了每个应用程序容器现在都打包了一个Prometheus客户端，该客户端收集并公开度量。
- en: '![](../Images/9-5.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图9-5](../Images/9-5.jpg)'
- en: Figure 9.5 Prometheus client libraries in your apps make the metrics endpoints
    available in the container.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5 Prometheus客户端库在您的应用程序中使度量端点在容器中可用。
- en: The information points collected from a Prometheus client library are runtime-level
    metrics. They provide key information regarding what your container is doing and
    how hard it is working, in terms that are relevant to the application runtime.
    The metrics for a Go application include the number of active Goroutines; the
    metrics for a Java application include the memory used in the JVM. Each runtime
    has its own important metrics, and the client libraries do a great job of collecting
    and exporting those.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从Prometheus客户端库收集的信息点是运行时级别的度量。它们提供了关于您的容器正在做什么以及它工作有多努力的关键信息，这些信息与应用程序运行时相关。Go应用程序的度量包括活跃的Goroutines数量；Java应用程序的度量包括JVM使用的内存。每个运行时都有自己的重要度量，客户端库在收集和导出这些度量方面做得很好。
- en: 'Try it now There’s a Docker Compose file in the exercises for this chapter
    that spins up a new version of the image gallery app, with metrics in each container.
    Use the app and then browse to one of the metrics endpoints:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 这个章节的练习中有一个Docker Compose文件，它会启动一个带有每个容器中度量的新版本的图片库应用程序。使用该应用程序，然后浏览到一个度量端点：
- en: '`     cd ./ch09/exercises`        `     # clear down existing containers:`
    `     docker container rm -f $(docker container ls -aq)`        `     # create
    the nat network - if you''ve already created it` `     # you''ll get a warning
    which you can ignore:` `     docker network create nat`        `     # start the
    project` `     docker-compose up -d`        `     # browse to http://localhost:8010
    to use the app`        `     # then browse to http://localhost:8010/metrics`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`     cd ./ch09/exercises` '
- en: My output is in figure 9.6\. These are the metrics from the Go frontend web
    application--there’s no custom code required to produce this data. You can get
    all this data for free just by adding the Go client library into your application
    and setting it up.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我的输出在图9.6中。这些是从Go前端Web应用程序收集的度量——不需要自定义代码来生成这些数据。您只需将Go客户端库添加到您的应用程序中并设置它，就可以免费获得所有这些数据。
- en: '![](../Images/9-6.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图9-6](../Images/9-6.jpg)'
- en: Figure 9.6 Prometheus metrics about the Go runtime from the image gallery web
    container
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6来自图片库Web容器的Go运行时Prometheus度量
- en: You’ll see similar metrics for the Java REST API if you browse to http:/ /localhost:8011/
    actuator/prometheus. The metrics endpoints are a sea of text, but all the key
    data points are in there to build a dashboard that will show if the containers
    are running “hot”--if they’re using a lot of compute resources like CPU time,
    memory, or processor threads.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您浏览到 http:/ /localhost:8011/ actuator/prometheus，您将看到 Java REST API 的类似指标。指标端点是文本的海洋，但所有关键数据点都在那里，可以构建一个仪表板，该仪表板将显示容器是否在“热”运行--如果它们正在使用大量的计算资源，如
    CPU 时间、内存或处理器线程。
- en: Those runtime metrics are the next level of detail you want after the infrastructure
    metrics from Docker, but those two levels don’t tell you the whole story. The
    final data points are application metrics that you explicitly capture to record
    key information about your application. Those metrics could be operations-focused,
    showing the number of events a component has processed or the average time to
    process a response. Or they could be business-focused, showing the current number
    of active users or the number of people signing up to a new service.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些运行时指标是您在 Docker 的基础设施指标之后的下一个细节级别，但这两个级别并没有告诉您整个故事。最终的数据点是您明确捕获的应用程序指标，以记录有关应用程序的关键信息。这些指标可以是操作导向的，显示组件处理的事件数量或处理响应的平均时间。或者它们可以是业务导向的，显示当前活跃用户数量或注册新服务的人数。
- en: Prometheus client libraries let you record these kind of metrics too, but you
    need to explicitly write the code to capture the information in your app. It’s
    not difficult to do. Listing 9.1 shows an example using the Node.js library, which
    is in the code for the `access-log` component in the image gallery app. I don’t
    want to throw a whole bunch of code at you, but as you progress further with containers,
    you’re certain to spend more time with Prometheus, and this snippet from the `server.js`
    file illustrates a couple of key things.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 客户端库也允许您记录这类指标，但您需要显式编写代码来捕获应用程序中的信息。这并不困难。列表 9.1 展示了一个使用 Node.js
    库的示例，该示例位于图像库应用程序 `access-log` 组件的代码中。我不想向您展示一大堆代码，但随着您在容器方面进一步发展，您肯定会在 Prometheus
    上花费更多时间，而这个来自 `server.js` 文件的片段展示了几个关键点。
- en: Listing 9.1 Declaring and using custom Prometheus metric values in Node.js
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.1 在 Node.js 中声明和使用自定义 Prometheus 指标值
- en: '`     //declare custom metrics:` `     const accessCounter = new prom.Counter({`
    `         name: "access_log_total",` `         help: "Access Log - total log requests"`
    `     });`        `     const clientIpGauge = new prom.Gauge({` `         name:
    "access_client_ip_current",` `         help: "Access Log - current unique IP addresses"`
    `     });`        `     //and later, update the metrics values:` `     accessCounter.inc();`
    `     clientIpGauge.set(countOfIpAddresses);`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`     //声明自定义指标：` `     const accessCounter = new prom.Counter({` `         name:
    "access_log_total",` `         help: "Access Log - total log requests"` `     });`
    `     const clientIpGauge = new prom.Gauge({` `         name: "access_client_ip_current",`
    `         help: "Access Log - current unique IP addresses"` `     });` `     //稍后，更新指标值：`
    `     accessCounter.inc();` `     clientIpGauge.set(countOfIpAddresses);`'
- en: In the source code for the chapter, you’ll see how I’ve added metrics in the
    `image-gallery` web application written in Go, and in the `image-of-the-day` REST
    API written in Java. Each Prometheus client library works in a different way.
    In the `main.go` source file I initialize counters and gauges in a similar way
    to the Node.js app but then use instrumented handlers from the client library
    rather than setting metrics explicitly. The Java application is different again--in
    `ImageController.java` I use the `@Timed` attribute and increment a `registry.counter`
    object in the source. Each client library works in the most logical way for the
    language.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的源代码中，您将看到我是如何在用 Go 编写的 `image-gallery` 网络应用程序和用 Java 编写的 `image-of-the-day`
    REST API 中添加指标的。每个 Prometheus 客户端库的工作方式都不同。在 `main.go` 源文件中，我以类似于 Node.js 应用程序的方式初始化计数器和仪表，但随后使用来自客户端库的仪表化处理程序，而不是显式设置指标。Java
    应用程序又有所不同--在 `ImageController.java` 中，我使用了 `@Timed` 属性并在源代码中增加了一个 `registry.counter`
    对象。每个客户端库都以对语言最合理的方式工作。
- en: 'There are different types of metrics in Prometheus--I’ve used the simplest
    ones in these applications: counters and gauges. They’re both numeric values.
    Counters hold a value that increases or stays the same, and gauges hold values
    that can increase or decrease. It’s down to you or your application developers
    to choose the metric type and to set its value at the correct time; the rest is
    taken care of by Prometheus and the client library.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 中有不同的指标类型——我在这些应用程序中使用了最简单的：计数器和仪表。它们都是数值。计数器保持一个增加或保持不变的值，而仪表保持可以增加或减少的值。选择指标类型并在正确的时间设置其值取决于你或你的应用程序开发者；其余的由
    Prometheus 和客户端库处理。
- en: 'Try it now You have the image gallery app running from the last exercise, so
    these metrics are already being collected. Run some load into the app, and then
    browse to the Node.js app’s metrics endpoint:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看。你从上一个练习中运行了图像库应用程序，因此这些指标已经被收集。向应用程序运行一些负载，然后浏览到 Node.js 应用程序的指标端点：
- en: '`     # loop to make 5 HTTP GET request - on Windows:` `     for ($i=1; $i
    -le 5; $i++) { iwr -useb http://localhost:8010 | Out-Null }`        `     # or
    on Linux:` `     for i in {1..5}; do curl http://localhost:8010 > /dev/null; done`
           `     # now browse to http://localhost:8012/metrics`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`     # 循环进行 5 个 HTTP GET 请求 - 在 Windows 上：` `     for ($i=1; $i -le 5; $i++)
    { iwr -useb http://localhost:8010 | Out-Null }` `     # 或在 Linux 上：` `     for
    i in {1..5}; do curl http://localhost:8010 > /dev/null; done` `   # 现在，浏览到 http://localhost:8012/metrics`'
- en: You can see my output in figure 9.7--I ran a few more loops to send in traffic.
    The first two records show my custom metrics, recording the number of access requests
    received and the total number of IP addresses using the service. These are simple
    data points (and the IP count is actually fake), but they serve the purpose of
    collecting and showing metrics. Prometheus lets you record more complex types
    of metrics, but even with simple counters and gauges you can capture detailed
    instrumentation in your apps.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图 9.7 中看到我的输出——我运行了几个循环来发送流量。前两条记录显示了我的自定义指标，记录了接收到的访问请求数量和使用的总 IP 地址数。这些是简单的数据点（而
    IP 计数实际上是假的），但它们起到了收集和显示指标的作用。Prometheus 允许你记录更复杂的指标类型，但即使使用简单的计数器和仪表，你也能捕获应用程序中的详细仪表。
- en: '![](../Images/9-7.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-7.jpg)'
- en: Figure 9.7 A metrics endpoint that includes custom data as well as Node.js runtime
    data
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7 包含自定义数据和 Node.js 运行时数据的指标端点
- en: What you capture depends on your application, but the following list provides
    some useful guidelines--you can return to these at the end of the month when you’re
    ready to add detailed monitoring to your own apps.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你捕获的内容取决于你的应用程序，但以下列表提供了一些有用的指南——你可以在月底准备为你的应用程序添加详细监控时返回这些指南。
- en: When you talk to external systems, record how long the call took and whether
    the response was successful--you’ll quickly be able to see if another system is
    slowing yours down or breaking it.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你与外部系统通信时，记录调用花费了多长时间以及响应是否成功——你将很快就能看到是否有其他系统正在减慢你的速度或破坏它。
- en: Anything worth logging is potentially worth recording in a metric--it’s probably
    cheaper on memory, disk, and CPU to increment a counter than to write a log entry,
    and it’s easier to visualize how often things are happening.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何值得记录的内容都可能在指标中记录——在内存、磁盘和 CPU 上增加计数器可能比写入日志条目更便宜，而且更容易可视化事情发生的频率。
- en: Any details about application or user behaviors that business teams want to
    report on should be recorded as metrics--that way you can build real-time dashboards
    instead of sending historical reports.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何关于应用程序或用户行为，业务团队希望报告的详细信息都应该记录为指标——这样你就可以构建实时仪表板，而不是发送历史报告。
- en: 9.3 Running a Prometheus container to collect metrics
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 运行 Prometheus 容器以收集指标
- en: Prometheus uses a pull model to collect metrics. Rather than have other systems
    send it data, it fetches data from those systems. It calls this scraping, and
    when you deploy Prometheus you configure the endpoints you want it to scrape.
    In a production container platform, you can configure Prometheus so it automatically
    finds all the containers across the cluster. In Docker Compose on a single server,
    you use a simple list of service names, and Prometheus finds the containers through
    Docker’s DNS.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 使用拉模型来收集指标。它不是让其他系统发送数据给它，而是从这些系统中获取数据。它称之为抓取，当你部署 Prometheus 时，你需要配置它要抓取的端点。在生产容器平台上，你可以配置
    Prometheus，使其自动发现集群中的所有容器。在单服务器上的 Docker Compose 中，你使用一个简单的服务名称列表，Prometheus 通过
    Docker 的 DNS 来查找容器。
- en: Listing 9.2 shows the configuration I’ve used for Prometheus to scrape two of
    the components in my image gallery application. There’s a `global` setting that
    uses a default 10-second interval between scrapes, and then there’s a `job` for
    each component. The job has a name, and the configuration specifies the URL path
    to the metrics endpoint and a list of targets that Prometheus will query. I use
    two types here. First, `static_configs` specifies a target hostname, which is
    fine for a single container. I also use `dns_sd_configs` , which means Prometheus
    will use DNS service discovery--that will find multiple containers for a service,
    and it supports running at scale.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.2 展示了我为 Prometheus 配置的抓取图像库应用程序中两个组件的配置。有一个 `global` 设置，它使用默认的 10 秒间隔进行抓取，然后为每个组件有一个
    `job`。作业有一个名称，配置指定了指标端点的 URL 路径以及 Prometheus 将查询的目标列表。这里我使用了两种类型。首先，`static_configs`
    指定了一个目标主机名，这对于单个容器来说是可以的。我还使用了 `dns_sd_configs`，这意味着 Prometheus 将使用 DNS 服务发现——这将找到多个容器的服务，并且它支持大规模运行。
- en: Listing 9.2 Prometheus configuration for scraping application metrics
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.2 Prometheus 配置用于抓取应用程序指标
- en: '`     global:` `         scrape_interval: 10s`        `     scrape_configs:`
    `         - job_name: "image-gallery"` `             metrics_path: /metrics` `             static_configs:`
    `                 - targets: ["image-gallery"]`        `         - job_name: "iotd-api"`
    `             metrics_path: /actuator/prometheus` `             static_configs:`
    `                 - targets: ["iotd"]`        `         - job_name: "access-log"`
    `             metrics_path: /metrics` `             dns_sd_configs:` `                 -
    names:` `                         - accesslog` `                     type: A`
    `                   port: 80`'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`     global:` `         scrape_interval: 10s` `     scrape_configs:` `         -
    job_name: "image-gallery"` `             metrics_path: /metrics` `             static_configs:`
    `                 - targets: ["image-gallery"]` `         - job_name: "iotd-api"`
    `             metrics_path: /actuator/prometheus` `             static_configs:`
    `                 - targets: ["iotd"]` `         - job_name: "access-log"` `             metrics_path:
    /metrics` `             dns_sd_configs:` `                 - names:` `                         -
    accesslog` `                     type: A` `                   port: 80`'
- en: This configuration sets Prometheus to poll all the containers every 10 seconds.
    It will use DNS to get the container IP addresses, but for the `image-gallery`
    it only expects to find a single container, so you’ll get unexpected behavior
    if you scale that component. Prometheus always uses the first IP address in the
    list if the DNS response contains several, so you’ll get metrics from different
    containers when Docker load balances the request to the metrics endpoint. The
    `accesslog` component is configured to support multiple IP addresses, so Prometheus
    will build a list of all the container IP addresses and poll them all on the same
    schedule. Figure 9.8 shows how the scraping process runs.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置将 Prometheus 设置为每 10 秒轮询所有容器。它将使用 DNS 获取容器 IP 地址，但对于 `image-gallery`，它只期望找到一个容器，所以如果你扩展该组件，你会得到意外的行为。如果
    DNS 响应包含多个 IP 地址，Prometheus 总是使用列表中的第一个 IP 地址，所以当 Docker 负载均衡请求到指标端点时，你会从不同的容器中获取指标。`accesslog`
    组件配置为支持多个 IP 地址，所以 Prometheus 将构建一个包含所有容器 IP 地址的列表，并按照相同的计划轮询它们。图 9.8 展示了抓取过程是如何运行的。
- en: '![](../Images/9-8.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-8.jpg)'
- en: Figure 9.8 Prometheus running in a container, configured to scrape metrics from
    app containers
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8 在容器中运行的 Prometheus，配置为抓取应用程序容器的指标
- en: I’ve built a custom Prometheus Docker image for the image gallery application.
    It’s based on the official image that the Prometheus team publish on Docker Hub,
    and it copies in my own configuration file (you can find the Dockerfile in the
    source code for this chapter). This approach gives me a preconfigured Prometheus
    image that I can run without any extra configuration, but I can always override
    the config file in other environments if I need to.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我为图像库应用程序构建了一个定制的 Prometheus Docker 镜像。它基于 Prometheus 团队在 Docker Hub 上发布的官方镜像，并复制了我的配置文件（你可以在本章源代码中找到
    Dockerfile）。这种方法为我提供了一个预配置的 Prometheus 镜像，我可以无需任何额外配置即可运行，但如果需要，我总是可以在其他环境中覆盖配置文件。
- en: Metrics are more interesting when lots of containers are running. We can scale
    up the Node.js component of the image gallery app to run on multiple containers,
    and Prometheus will scrape and collect metrics from all the containers.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行大量容器时，指标更有趣。我们可以扩展图像库应用程序的 Node.js 组件，使其在多个容器上运行，Prometheus 将抓取并收集所有容器的指标。
- en: 'Try it now There’s another Docker Compose file in the chapter’s exercises folder
    that publishes a random port for the `access-log` service, so that service can
    be run at scale. Run it with three instances and send some more load into the
    website:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试吧。章节的练习文件夹中还有一个 Docker Compose 文件，它为 `access-log` 服务发布了一个随机端口，这样该服务就可以进行扩展运行。用三个实例运行它并向网站发送更多负载：
- en: '`     docker-compose -f docker-compose-scale.yml up -d --scale accesslog=3`
           `     # loop to make 10 HTTP GET request - on Windows:` `     for ($i=1;
    $i -le 10; $i++) { iwr -useb http://localhost:8010 | Out-Null }`        `     #
    or on Linux:` `     for i in {1..10}; do curl http://localhost:8010 > /dev/null;
    done`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker-compose -f docker-compose-scale.yml up -d --scale accesslog=3`'
- en: The website makes a call to the `access-log` service every time it processes
    a request--there are three containers running that service, so the calls should
    be load-balanced across them all. How can we check that the load balancing is
    working effectively? The metrics from that component include a label that captures
    the hostname of the machine sending the metrics--in this case that’s the Docker
    container ID. Open the Prometheus UI and check the `access-log` metrics. You should
    see three sets of data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 每当网站处理一个请求时，都会调用 `access-log` 服务--运行该服务的有三个容器，因此调用应该在这所有容器之间进行负载均衡。我们如何检查负载均衡是否有效？该组件的指标包括一个标签，用于捕获发送指标的机器的主机名--在这种情况下是
    Docker 容器 ID。打开 Prometheus UI 并检查 `access-log` 指标。你应该看到三组数据。
- en: Try it now Browse to http:/ /localhost:9090/graph. In the metrics dropdown,
    select `access_log_total` and click Execute.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试吧。浏览到 http://localhost:9090/graph。在度量下拉菜单中选择 `access_log_total` 并点击执行。
- en: You’ll see something similar to my output in figure 9.9--there’s one metric
    value for each of the containers, and the labels contain the hostname. The actual
    values for each container will show you how evenly spread the load balancing is.
    In an ideal scenario, the figures would be equal, but there are a lot of network
    factors in play (like DNS caching and HTTP keep-alive connections), which means
    you probably won’t see that if you’re running on a single machine.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到与我图 9.9 中类似的结果--每个容器都有一个度量值，标签包含主机名。每个容器的实际值将显示负载均衡的均匀程度。在理想情况下，这些数值应该是相等的，但由于存在许多网络因素（如
    DNS 缓存和 HTTP 保持连接），这意味着如果你在单机上运行，你可能看不到这种情况。
- en: '![](../Images/9-9.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-9.jpg)'
- en: Figure 9.9 Processing metrics can be used to verify that requests are being
    load-balanced.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.9 使用处理指标可以用来验证请求是否正在负载均衡。
- en: Recording extra information with labels is one of the most powerful features
    of Prometheus. It lets you work with a single metric at different levels of granularity.
    Right now you’re seeing the raw data for the metrics, with one line in the table
    for each container showing the most recent metric value. You can aggregate across
    all the containers using a `sum()` query, ignoring the individual labels and showing
    a combined total, and you can display that in a graph to see the increasing usage
    over time.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Prometheus 中使用标签记录额外信息是其最强大的功能之一。它允许你在不同粒度级别上使用单个度量。目前你看到的是指标的原始数据，表格中每行显示一个容器最近一次的度量值。你可以使用
    `sum()` 查询跨所有容器进行聚合，忽略单个标签并显示总合，你还可以在图表中显示，以查看随时间增加的使用情况。
- en: 'Try it now In the Prometheus UI, click the Add Graph button to add a new query.
    In the expression text box, paste this query:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试吧。在 Prometheus UI 中，点击添加图表按钮以添加一个新的查询。在表达式文本框中粘贴以下查询：
- en: '`sum(access_log_total) without(hostname, instance)`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`sum(access_log_total) without(hostname, instance)`'
- en: Click Execute and you’ll see a line graph with a time series, which is how Prometheus
    represents data--a set of metrics, each recorded with a timestamp.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 点击执行，你将看到一个时间序列的折线图，这是 Prometheus 表示数据的方式--一组带有时间戳记录的度量。
- en: I sent in some more HTTP requests to my local app before I added the new graph--you
    can see my output in figure 9.10.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在我添加新的图表之前，我向本地应用程序发送了一些更多的 HTTP 请求--你可以在图 9.10 中看到我的输出。
- en: '![](../Images/9-10.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-10.jpg)'
- en: Figure 9.10 Aggregating a metric to sum values from all containers and showing
    a graph of results
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.10 聚合度量，从所有容器中汇总值并显示结果图表
- en: The `sum()` query is written in Prometheus’s own query language called PromQL.
    It’s a powerful language with statistical functions that let you query changes
    over time and rate of change, and you can add subqueries to correlate different
    metrics. But you don’t need to go into any of that complexity to build useful
    dashboards. The Prometheus format is so well structured that you can visualize
    key metrics with simple queries. You can use labels to filter values, and sum
    the results to aggregate, and just those features will give you a useful dashboard.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`sum()` 查询是用 Prometheus 自有的查询语言 PromQL 编写的。它是一种功能强大的语言，包含统计函数，允许你查询随时间的变化和变化率，并且你可以添加子查询来关联不同的指标。但是，你不需要深入到任何这种复杂性中就能构建有用的仪表板。Prometheus
    的格式结构非常良好，你可以通过简单的查询来可视化关键指标。你可以使用标签来过滤值，并汇总结果以进行聚合，仅这些功能就能为你提供一个有用的仪表板。'
- en: '![](../Images/9-11.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-11.jpg)'
- en: Figure 9.11 A simple Prometheus query. You don’t need to learn much more PromQL
    than this.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11 一个简单的 Prometheus 查询。你不需要学习比这更多的 PromQL。
- en: Figure 9.11 shows a typical query that will feed into a dashboard. This aggregates
    the value for all the `image_gallery_request` metrics, filtering where the response
    code is `200` , and summing without the `instance` label, so we will get metrics
    from all the containers. The result will be the total number of 200 “OK” responses
    sent by all the containers running the image gallery web application.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11 展示了一个典型的查询，它将被用于仪表板。这个查询聚合了所有 `image_gallery_request` 指标的值，过滤出响应代码为 `200`
    的情况，并且没有使用 `instance` 标签进行汇总，因此我们将从所有容器中获取指标。结果将是所有运行图像库网络应用程序的容器发送的 200 个“OK”响应的总数。
- en: The Prometheus UI is fine for checking on your configuration, validating that
    all the scrape targets are reachable, and working out queries. But it is not meant
    to be a dashboard--that’s where Grafana comes in.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus UI 适用于检查你的配置，验证所有抓取目标是否可访问，以及制定查询。但它并不是一个仪表板——这正是 Grafana 的作用所在。
- en: 9.4 Running a Grafana container to visualize metrics
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 运行 Grafana 容器以可视化指标
- en: We’re covering a lot of ground in this chapter because monitoring is a core
    topic for containers, but we’re going quickly because the finer details are all
    very application-dependent. What metrics you need to capture will depend on your
    business and operational needs, and how you capture them will depend on the application
    runtime you’re using and the mechanics of the Prometheus client library for that
    runtime.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中涵盖了大量的内容，因为监控是容器的一个核心主题，但我们进展很快，因为更详细的内容都是非常依赖于应用程序的。你需要捕获哪些指标将取决于你的业务和运营需求，而你如何捕获它们将取决于你使用的应用程序运行时以及该运行时的
    Prometheus 客户端库的机制。
- en: Once you have your data in Prometheus, things get simpler--it becomes a pretty
    standard approach for all apps. You’ll use the Prometheus UI to navigate the metrics
    you’re recording and work on queries to get the data that you want to see. Then
    you’ll run Grafana and plug those queries into a dashboard. Each data point shows
    up as a user-friendly visualization, and the dashboard as a whole shows you what’s
    happening with your app.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的数据存储在 Prometheus 中，事情就会变得简单起来——它成为所有应用程序的一个相当标准的做法。你将使用 Prometheus UI 来导航你正在记录的指标，并针对你想要查看的数据进行查询。然后你将运行
    Grafana 并将这些查询连接到仪表板。每个数据点都以用户友好的可视化形式出现，整个仪表板展示了你的应用程序正在发生的事情。
- en: We’ve been working toward the Grafana dashboard for the image gallery app all
    through this chapter, and figure 9.12 shows the final outcome. It’s a very neat
    way to show core information from all the application components and the Docker
    runtime. These queries are also built to support scale, so the same dashboard
    can be used in a production cluster.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中一直在为图像库应用程序构建 Grafana 仪表板，图 9.12 展示了最终结果。这是一种非常整洁的方式来展示所有应用程序组件和 Docker
    运行时的核心信息。这些查询也构建来支持扩展，因此相同的仪表板可以在生产集群中使用。
- en: '![](../Images/9-12.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-12.jpg)'
- en: Figure 9.12 The Grafana dashboard for the application. Looks fancy, but it’s
    actually pretty simple to build.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12 应用程序的 Grafana 仪表板。看起来很复杂，但实际上构建起来相当简单。
- en: The Grafana dashboard conveys key information across many different levels of
    the application. It looks complicated, but each visualization is powered by a
    single PromQL query, and none of the queries do anything more complex than filtering
    and aggregating. The shrunken view in figure 9.12 doesn’t give you the full picture,
    but I’ve packaged the dashboard into a custom Grafana image so you can run it
    yourself in a container and explore.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana仪表板在应用的不同层级传达关键信息。它看起来很复杂，但每个可视化都由一个单一的PromQL查询驱动，而且没有任何查询比过滤和聚合更复杂。图9.12中的缩小视图并没有给出完整的画面，但我已经将仪表板打包成一个自定义的Grafana镜像，这样你就可以在容器中运行它并探索。
- en: 'Try it now You’ll need to capture your computer’s IP address again, this time
    as an environment variable that the Compose file looks for and injects into the
    Prometheus container. Then run the app with Docker Compose and generate some load:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试吧 你需要再次捕获你的计算机的IP地址，这次作为一个环境变量，Compose文件会查找并注入到Prometheus容器中。然后使用Docker
    Compose运行应用程序并生成一些负载：
- en: '`     # load your machine''s IP address into an environment variable - on Windows:`
    `     $env:HOST_IP = $(Get-NetIPConfiguration | Where-Object {$_.IPv4DefaultGateway
    -ne $null }).IPv4Address.IPAddress`        `     # on Linux:` `     export HOST_IP=$(ip
    route get 1 | awk ''{print $NF;exit}'')`        `     # run the app with a Compose
    file which includes Grafana:` `     docker-compose -f ./docker-compose-with-grafana.yml
    up -d --scale accesslog=3`        `     # now send in some load to prime the metrics
    - on Windows:` `     for ($i=1; $i -le 20; $i++) { iwr -useb http://localhost:8010
    | Out-Null }`        `     # or on Linux:` `     for i in {1..20}; do curl http://localhost:8010
    > /dev/null; done`        `     # and browse to http://localhost:3000`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`     # 将你的机器的IP地址加载到环境变量中 - 在Windows上：` `     $env:HOST_IP = $(Get-NetIPConfiguration
    | Where-Object {$_.IPv4DefaultGateway -ne $null }).IPv4Address.IPAddress` `     #
    在Linux上：` `     export HOST_IP=$(ip route get 1 | awk ''{print $NF;exit}'')` `     #
    使用包含Grafana的Compose文件运行应用程序：` `     docker-compose -f ./docker-compose-with-grafana.yml
    up -d --scale accesslog=3` `     # 现在发送一些负载以初始化指标 - 在Windows上：` `     for ($i=1;
    $i -le 20; $i++) { iwr -useb http://localhost:8010 | Out-Null }` `     # 或在Linux上：`
    `     for i in {1..20}; do curl http://localhost:8010 > /dev/null; done` `     #
    然后浏览到http://localhost:3000`'
- en: Grafana uses port 3000 for the web UI. When you first browse, you’ll need to
    sign in--the credentials are username `admin` , password `admin` . You’ll be asked
    to change the admin password on the first login, but I won’t judge you if you
    click Skip instead. When the UI loads, you’ll be in your “home” dashboard--click
    on the Home link at the top left, and you’ll see the dashboard list in figure
    9.13\. Click Image Gallery to load the application dashboard.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana使用端口3000用于网页UI。当你首次浏览时，你需要登录——凭据是用户名`admin`，密码`admin`。你将在首次登录时被要求更改管理员密码，但如果点击跳过，我不会评判你。当UI加载时，你将进入你的“主页”仪表板——点击左上角的“主页”链接，你将看到图9.13中的仪表板列表。点击Image
    Gallery以加载应用程序仪表板。
- en: '![](../Images/9-13.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-13.jpg)'
- en: Figure 9.13 Navigating dashboards in Grafana--recently used folders are shown
    here
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13 在Grafana中导航仪表板——最近使用的文件夹显示在此处
- en: My application dashboard is a reasonable setup for a production system. There
    are some key data points you need, to make sure you’re monitoring the right things--Google
    discusses this in the Site Reliability Engineering book ( *[http://mng.bz/EdZj](http://mng.bz/EdZj)*
    ). Their focus is on latency, traffic, errors, and saturation, which they call
    the “golden signals.”
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我的仪表板是一个合理的生产系统设置。你需要一些关键数据点，以确保你正在监控正确的事情——谷歌在《站点可靠性工程》一书中讨论了这一点（*[http://mng.bz/EdZj](http://mng.bz/EdZj)*）。他们的重点是延迟、流量、错误和饱和度，他们称之为“黄金信号”。
- en: I’ll go through the first set of my visualizations in detail so you can see
    that a smart dashboard can be built from basic queries and the right choice of
    visualization. Figure 9.14 shows the row of metrics for the Image Gallery web
    UI--I’ve chopped the row up to make it easier to see, but these appear on the
    same line in the dashboard.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我将详细说明我的第一组可视化，以便你可以看到一个智能仪表板可以由基本的查询和正确的可视化选择构建而成。图9.14显示了Image Gallery网页UI的指标行——我已经将其分割以便更容易查看，但这些在仪表板上显示在同一行。
- en: 'There are four metrics here that show how heavily the system is being used,
    and how hard the system is working to support that level of use:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里显示了四个指标，展示了系统被使用的程度以及系统为了支持这种使用水平所付出的努力：
- en: 'HTTP 200 Responses --This is a simple count of how many HTTP “OK” responses
    the website has sent over time. The PromQL query is a sum over the counter metric
    from the application: `sum(image_gallery_requests_total{code="200"})` `without(instance)`
    . I could add a similar graph with a query filtering on `code="500"` to show the
    number of errors.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP 200 响应 -- 这是对网站随时间发送的 HTTP “OK” 响应数量的简单统计。PromQL 查询是对应用程序计数器指标的求和：`sum(image_gallery_requests_total{code="200"})`
    `without(instance)`。我可以添加一个类似的图表，通过查询过滤 `code="500"` 来显示错误数量。
- en: 'In-Flight Requests --This shows the number of active requests at any given
    point. It’s a Prometheus gauge, so it can go up or down. There’s no filter for
    this, and the graph will show the total across all containers, so the query is
    another sum: `sum(image_gallery_in_flight_requests)` `without(instance)` .'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在途请求 -- 这显示了在任何给定时间点的活动请求数量。它是一个 Prometheus 仪表，因此它可以上升或下降。对此没有过滤条件，图表将显示所有容器中的总数，因此查询是另一个求和：`sum(image_gallery_in_flight_requests)`
    `without(instance)`。
- en: 'Memory In Use --This shows how much system memory the image gallery containers
    are using. It’s a bar chart, which is easier on the eye for this type of data;
    it will show a bar for each container when I scale up the web component. The PromQL
    query filters on the job name: `go_memstats_stack_inuse_bytes{job="image-gallery"}`
    . I need the filter because this is a standard Go metric, and the Docker Engine
    job returns a metric with the same name.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存使用情况 -- 这显示了图像库容器使用的系统内存量。它是一个条形图，对于此类数据来说更容易观察；当我扩展网络组件时，它将为每个容器显示一个条形。PromQL
    查询根据作业名称进行过滤：`go_memstats_stack_inuse_bytes{job="image-gallery"}`。我需要过滤条件，因为这是一个标准的
    Go 指标，并且 Docker 引擎作业返回了一个具有相同名称的指标。
- en: 'Active Goroutines --This is a rough indicator of how hard the component is
    working--a Goroutine is a unit of work in Go, and many can run concurrently. This
    graph will show if the web component suddenly has a spike of processing activity.
    It’s another standard Go metric, so the PromQL query filters stats from the web
    job and sums them: `sum(go_goroutines{job=\"image-gallery\"})` `without(instance)`
    .'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活跃 Goroutines -- 这是一个粗略的指标，表明组件工作有多努力--Goroutine 是 Go 中的一个工作单元，并且可以并发运行多个。此图表将显示网络组件是否突然出现处理活动的峰值。这是另一个标准的
    Go 指标，因此 PromQL 查询从网络作业中过滤统计信息并将它们求和：`sum(go_goroutines{job=\"image-gallery\"})`
    `without(instance)`。
- en: The visualizations in the other rows of the dashboards all use similar queries.
    There’s no need for complex PromQL--choosing the right metrics to show and the
    right visualization to display them is all you really need.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板其他行的可视化都使用类似的查询。不需要复杂的 PromQL--选择正确的指标来显示以及正确的可视化来展示它们才是您真正需要的。
- en: In these visualizations the actual values are less useful than the trends. It
    doesn’t really matter if my web app uses 200 MB of memory on average or 800 MB--what
    matters is when there’s a sudden spike that deviates from the norm. The set of
    metrics for a component should help you quickly see anomalies and find correlations.
    If the graph of error responses is on an upward trend and the number of active
    Goroutines is doubling every few seconds, it’s clear there’s something going wrong--the
    component could be saturated, so you may need to scale up with more containers
    to handle the load.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些可视化中，实际值不如趋势有用。我的网络应用平均使用 200 MB 或 800 MB 的内存并不重要--重要的是当出现突然的峰值偏离正常情况时。组件的指标集应帮助您快速看到异常并找到相关性。如果错误响应的图表呈上升趋势，并且活跃
    Goroutines 的数量每几秒翻倍，那么很明显有问题--组件可能已饱和，因此您可能需要通过添加更多容器来扩展以处理负载。
- en: '![](../Images/9-14.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-14.jpg)'
- en: Figure 9.14 A closer look at the application dashboard and how visualizations
    relate to the golden signals
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.14 仔细查看应用程序仪表板以及可视化如何与黄金信号相关
- en: Grafana is an extremely powerful tool, but it’s straightforward to use. It’s
    the most popular dashboard system for modern applications, so it’s worth learning--it
    can query lots of different data sources, and it can send alerts out to different
    systems too. Building dashboards is the same as editing existing dashboards--you
    can add or edit visualizations (called panels), resize and move them around, and
    then save your dashboard to a file.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 是一个极其强大的工具，但使用起来非常简单。它是现代应用程序最受欢迎的仪表板系统，因此值得学习--它可以查询许多不同的数据源，并且还可以将警报发送到不同的系统。构建仪表板与编辑现有仪表板相同--你可以添加或编辑可视化（称为面板），调整大小并移动它们，然后将你的仪表板保存到文件中。
- en: Try it now The Google SRE approach says that an HTTP error count is a core metric,
    and that’s missing from the dashboard, so we’ll add it to the image gallery row
    now. Run the whole image gallery app again if you don’t have it running, browse
    to Grafana at http:/ /locahost:3000, and log in with username `admin` and password
    `admin` .
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 Google SRE方法认为HTTP错误计数是一个核心指标，而这个指标在仪表板中缺失，所以我们现在将把它添加到图片库行中。如果你还没有运行整个图片库应用程序，请重新运行它，浏览到Grafana的http://localhost:3000，并使用用户名`admin`和密码`admin`登录。
- en: Open the Image Gallery dashboard and click the Add Panel icon at the top right
    of the screen--it’s the bar chart with a plus sign shown in figure 9.15.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 打开图片库仪表板，点击屏幕右上角的添加面板图标--它就是图9.15中显示的带有加号的柱状图。
- en: '![](../Images/9-15.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-15.jpg)'
- en: Figure 9.15 The Grafana toolbar for adding panels, choosing the time period,
    and saving the dashboard
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.15 用于添加面板、选择时间段和保存仪表板的Grafana工具栏
- en: 'Now click Add Query in the new panel window, and you’ll see a screen where
    you can capture all the details of the visualization. Select Prometheus as the
    data source for the query, and in the metrics field paste this PromQL expression:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在新面板窗口中点击添加查询，你将看到一个屏幕，你可以捕获可视化的所有细节。选择Prometheus作为查询的数据源，并在度量字段粘贴以下PromQL表达式：
- en: '`sum(image_gallery_requests_total{code="500"}) without(instance)`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`sum(image_gallery_requests_total{code="500"}) without(instance)`'
- en: Your panel should look like mine in figure 9.16\. The image gallery application
    returns an error response around 10% of the time, so if you make enough requests
    you’ll see some errors in your graph.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你的面板应该看起来像我图9.16中的那样。图片库应用程序大约有10%的时间会返回错误响应，所以如果你请求足够多，你会在你的图表中看到一些错误。
- en: Press the Escape key to go back to the main dashboard.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 按下Esc键返回主仪表板。
- en: You can resize panels by dragging the bottom-right corner, and move them by
    dragging the title. When you have the dashboard looking how you want, you can
    click the Share Dashboard icon from the tool panel (see figure 9.15 again), where
    you have the option to export the dashboard as a JSON file.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过拖动底右角来调整面板大小，通过拖动标题来移动它们。当你把仪表板调整到你想要的样子时，你可以从工具面板中点击分享仪表板图标（再次查看图9.15），在那里你可以选择将仪表板导出为JSON文件。
- en: '![](../Images/9-16.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-16.jpg)'
- en: Figure 9.16 Adding a new panel to the Grafana dashboard to show HTTP errors
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.16 向Grafana仪表板添加新面板以显示HTTP错误
- en: The final step with Grafana is packaging your own Docker image, which is already
    configured with Prometheus as a data source and with the application dashboard.
    I’ve done that for the `diamol/ch09-grafana` image. Listing 9.3 shows the full
    Dockerfile.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Grafana的最终步骤是打包自己的Docker镜像，该镜像已经配置了Prometheus作为数据源以及应用程序仪表板。我已经为`diamol/ch09-grafana`镜像完成了这项工作。列表9.3显示了完整的Dockerfile。
- en: Listing 9.3 The Dockerfile to package a custom Grafana image
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.3 打包自定义Grafana镜像的Dockerfile
- en: '`     FROM diamol/grafana:6.4.3`        `     COPY datasource-prometheus.yaml
    ${GF_PATHS_PROVISIONING}/datasources/` `     COPY dashboard-provider.yaml ${GF_PATHS_PROVISIONING}/dashboards/`
    `     COPY dashboard.json /var/lib/grafana/dashboards/`'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`     FROM diamol/grafana:6.4.3` '
- en: The image starts from a specific version of Grafana and then just copies in
    a set of YAML and JSON files. Grafana follows the configuration pattern I’ve promoted
    already in this book--there’s some default configuration built in, but you can
    apply your own. When the container starts, Grafana looks for files in specific
    folders, and it applies any configuration files it finds. The YAML files set up
    the Prometheus connection and load any dashboards that are in the `/var/lib/Grafana/dashboards`
    folder. The final line copies my dashboard JSON into that folder, so it gets loaded
    when the container starts.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 该镜像从一个特定的Grafana版本开始，然后只是复制一组YAML和JSON文件。Grafana遵循我在本书中已经推广的配置模式--内置了一些默认配置，但你可以应用自己的配置。当容器启动时，Grafana会在特定的文件夹中查找文件，并应用它找到的任何配置文件。YAML文件设置Prometheus连接并加载`/var/lib/Grafana/dashboards`文件夹中的任何仪表板。最后一行将我的仪表板JSON复制到该文件夹，因此容器启动时会加载它。
- en: You can do much more with Grafana provisioning, and you can also use the API
    to create users and set their preferences. It’s not much more work to build a
    Grafana image with multiple dashboards and a read-only user with access to all
    those dashboards, which can be put together in a Grafana playlist. Then you can
    browse to Grafana on a big screen in your office and have it automatically cycle
    through all your dashboards.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用Grafana配置实现更多功能，你也可以使用API来创建用户并设置他们的偏好。构建一个包含多个仪表板和具有访问所有这些仪表板权限的只读用户Grafana镜像并不需要做太多工作，这些仪表板可以组合成一个Grafana播放列表。然后你可以在办公室的大屏幕上浏览Grafana，并自动循环显示所有仪表板。
- en: 9.5 Understanding the levels of observability
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.5 理解可观察性的级别
- en: 'Observability is a key requirement when you move from simple proof-of-concept
    containers to getting ready for production. But there’s another very good reason
    I introduced Prometheus and Grafana in this chapter: learning Docker is not just
    about the mechanics of Dockerfiles and Docker Compose files. Part of the magic
    of Docker is the huge ecosystem that’s grown around containers, and the patterns
    that have emerged around that ecosystem.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 当你从简单的概念验证容器转移到准备生产时，可观察性是一个关键要求。但我在本章引入Prometheus和Grafana的另一个非常好的原因是：学习Docker不仅仅是关于Dockerfile和Docker
    Compose文件的机制。Docker的魔力部分是围绕容器成长起来的巨大生态系统，以及围绕该生态系统出现的模式。
- en: Monitoring was a real headache when containers were first getting popular. My
    production releases back then were as easy to build and deploy as they are today,
    but I had no insight into the apps when they were running. I had to rely on external
    services like Pingdom to check that my APIs were still up, and on user reporting
    to make sure the app was working correctly. Today the approach to monitoring containers
    is a tried-and-trusted path. We’ve followed that path in this chapter, and figure
    9.17 summarizes the approach.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器最初变得流行时，监控确实是个头疼的问题。我当时的生产发布与今天一样容易构建和部署，但我在应用程序运行时没有洞察力。我必须依赖外部服务如Pingdom来检查我的API是否仍然可用，并依赖用户报告来确保应用程序运行正确。今天对容器进行监控的方法是一条经过验证和值得信赖的途径。我们在本章中遵循了这条途径，图9.17总结了这种方法。
- en: '![](../Images/9-17.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图9.17](../Images/9-17.jpg)'
- en: Figure 9.17 The architecture of monitoring in a containerized application--Prometheus
    is at the center.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.17 容器化应用程序的监控架构--Prometheus位于中心。
- en: I’ve walked through a single dashboard for the image gallery application, which
    is an overall view of the app. In a production environment, you’d have additional
    dashboards that dig into extra levels of detail. There would be an infrastructure
    dashboard showing free disk space, available CPU, and memory and network saturation
    for all the servers. Each component might have its own dashboard showing additional
    information, like a breakdown of response times for serving each page of a web
    app or each API endpoint.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经为图像库应用程序走过了单个仪表板，这是一个应用程序的整体视图。在生产环境中，你会有额外的仪表板，它们会深入到更详细的级别。会有一个基础设施仪表板显示所有服务器的可用磁盘空间、可用CPU、内存和网络饱和度。每个组件可能都有自己的仪表板，显示额外的信息，例如，为Web应用程序的每一页或每个API端点提供服务的响应时间分解。
- en: The summary dashboard is the critical one. You should be able to pull together
    all the most important data points from your application metrics into a single
    screen, so you can tell at a glance if something is wrong and take evasive action
    before it gets worse.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要仪表板是关键。你应该能够将应用程序指标中的所有最重要的数据点汇总到一个屏幕上，这样你就可以一眼看出是否有问题，并在问题恶化之前采取规避措施。
- en: 9.6 Lab
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.6 实验室
- en: 'This chapter added monitoring to the image gallery app, and this lab asks you
    to do the same to the to-do list app. You don’t need to dive into source code--I’ve
    already built a new version of the application image that contains Prometheus
    metrics. Run a container from `diamol/ch09-todo-list` , browse to the app, and
    add some items, and you’ll see the metrics available at the `/metrics` URL. For
    the lab, you want to get that app to the same position we have for the image gallery:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向图像库应用程序添加了监控功能，这个实验室要求你对待办事项列表应用程序做同样的操作。你不需要深入研究源代码--我已经构建了一个包含Prometheus指标的新版本的应用程序镜像。从`diamol/ch09-todo-list`运行一个容器，浏览到应用程序，并添加一些项目，你将看到在`/metrics`
    URL上可用的指标。对于实验室，你希望将那个应用程序带到与图像库相同的位置：
- en: Write a Docker Compose file that you can use to run the app, which also starts
    a Prometheus container and a Grafana container.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写一个Docker Compose文件，你可以使用它来运行应用程序，它还会启动一个Prometheus容器和一个Grafana容器。
- en: The Prometheus container should already be configured to scrape metrics from
    the to-do list app.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus 容器应该已经配置好了从待办事项应用中抓取指标。
- en: 'The Grafana container should be configured with a dashboard to show three key
    metrics from the app: number of tasks created, total number of HTTP requests processed,
    and number of HTTP requests currently being processed.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grafana 容器应该配置一个仪表板来显示应用中的三个关键指标：创建的任务数量、处理的总 HTTP 请求数量，以及当前正在处理的 HTTP 请求数量。
- en: This sounds like a ton of work, but really it’s not--the exercises in this chapter
    cover all the details. It’s a good lab to work through, because it will give you
    experience working with metrics for a new application.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来像是一大堆工作，但实际上并不是——本章的练习涵盖了所有细节。这是一个很好的实验室练习，因为它将让你获得与新的应用程序指标一起工作的经验。
- en: 'As always, you’ll find my solution on GitHub, together with a graphic of my
    final dashboard: *[https://github.com/sixeyed/diamol/blob/master/ch09/lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch09/lab/README.md)*.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，你可以在 GitHub 上找到我的解决方案，以及我最终仪表板的图形：*[https://github.com/sixeyed/diamol/blob/master/ch09/lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch09/lab/README.md)*。
