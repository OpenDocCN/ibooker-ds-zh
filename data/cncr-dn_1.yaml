- en: Part 2
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分
- en: How to approach the different parts of a concurrent program
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如何处理并发程序的不同部分
- en: This part of the book dives into functional programming concepts and applicability.
    We’ll explore various concurrent programming models, with an emphasis on the benefits
    and advantages of this paradigm. Topics will include the Task Parallel Library
    along with parallel patterns such as Fork/Join, Divide and Conquer, and MapReduce.
    We’ll also discuss declarative composition, high-level abstraction in asynchronous
    operations, the agent programming model, and the message-passing semantic. You’ll
    see firsthand how functional programming allows you to compose program elements
    without evaluating them. These techniques parallelize work and make programs easier
    to reason about and more efficient to run due to optimal memory consumption.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书这部分深入探讨函数式编程的概念和适用性。我们将探讨各种并发编程模型，重点介绍这种范式的优势和好处。主题将包括任务并行库以及并行模式，如Fork/Join、分而治之、MapReduce。我们还将讨论声明式组合、异步操作的高级抽象、代理编程模型以及消息传递语义。你将亲身体验到函数式编程如何让你在不评估它们的情况下组合程序元素。这些技术并行化工作，使程序更容易推理，运行效率更高，因为它们优化了内存消耗。
- en: '4'
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: 'The basics of processing big data: data parallelism, part 1'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 处理大数据的基本原理：数据并行，第一部分
- en: '**This chapter covers**'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '**本章涵盖**'
- en: The importance of data parallelism in a world of big data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大数据的世界中数据并行的重要性
- en: Applying the Fork/Join pattern
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用Fork/Join模式
- en: Writing declarative parallel programs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写声明式并行程序
- en: Understanding the limitation of a parallel `for` loop
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解并行`for`循环的限制
- en: Increasing performance with data parallelism
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过数据并行提高性能
- en: Imagine you’re cooking a spaghetti for dinner for four, and let’s say it takes
    10 minutes to prepare and serve the pasta. You begin the preparation by filling
    a medium-sized pot with water to boil. Then, two more friends show up at your
    house for dinner. Clearly, you need to make more pasta. You can switch to a bigger
    pot of water with more spaghetti, which will take longer to cook, or you can use
    a second pot in tandem with the first, so that both pots of pasta will finish
    cooking at the same time. Data parallelism works in much the same way. Massive
    amounts of data can be processed if “cooked” in parallel.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你为晚餐准备四人的意大利面，假设准备和上桌需要10分钟。你开始准备时，往一个中等大小的锅中加水煮沸。然后，又有两个朋友到你家吃饭。显然，你需要做更多的意大利面。你可以换一个大锅的水，里面放更多的意大利面，但这会花费更长的时间来煮，或者你可以使用第二个锅与第一个锅一起使用，这样两个锅的意大利面就可以同时完成烹饪。数据并行的工作方式与此类似。如果“同时烹饪”，可以处理大量的数据。
- en: In the last decade, the amount of data being generated has increased exponentially.
    In 2017 it was estimated that every minute there were 4,750,000 “likes” on Facebook,
    almost 400,000 tweets, more than 2.5 million posts on Instagram, and more than
    4 million Google searches. These numbers continue to increase at the rate of 15%
    every year. This acceleration impacts businesses that now must quickly analyze
    multitudes of big data ([https://en.wikipedia.org/wiki/Big_data](https://en.wikipedia.org/wiki/Big_data)).
    How is it possible to analyze this massive amount of data while maintaining quick
    responses? The answer comes from a new breed of technologies designed with data
    parallelism in mind, specifically, with a focus on the ability to maintain performance
    in the event of continually increasing data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，生成数据的量呈指数增长。2017年估计，每分钟有4,750,000个Facebook“赞”，近40万个推文，超过250万个Instagram帖子，以及超过400万个谷歌搜索。这些数字每年以15%的速度持续增长。这种加速影响了现在必须快速分析大量大数据的企业([https://en.wikipedia.org/wiki/Big_data](https://en.wikipedia.org/wiki/Big_data))。如何在保持快速响应的同时分析如此大量的数据？答案是来自一种新的技术，这种技术旨在考虑数据并行，特别是关注在数据持续增加的情况下保持性能的能力。
- en: In this chapter, you’ll learn concepts, design patterns, and techniques to rapidly
    process tons of data. You’ll analyze the problems originating from parallel loop
    constructs and learn about solutions. You’ll also learn that by using functional
    programming in combination with data parallelism it’s possible to achieve impressive
    performance improvements in your algorithms with minimal code changes.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习概念、设计模式和技巧，以快速处理大量数据。你将分析来自并行循环结构的难题，并了解解决方案。你还将了解到，通过将函数式编程与数据并行结合使用，可以在最小代码更改的情况下实现算法性能的显著提升。
- en: 4.1 What is data parallelism?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 什么是数据并行？
- en: '*Data* *parallelism* is a programming model that performs the same set of operations
    on a large quantity of data in parallel. This programming model is gaining traction
    because it quickly processes massive volumes of data in the face of a variety
    of big data problems. Parallelism can compute an algorithm without requiring reorganization
    of its structure, thereby progressively increasing scalability.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据* *并行性* 是一种编程模型，它并行地对大量数据进行相同的操作集。这种编程模型正在获得越来越多的关注，因为它能够快速处理各种大数据问题中的大量数据。并行性可以在不要求重新组织其结构的情况下计算算法，从而逐步提高可伸缩性。'
- en: 'The two models of data parallelism are single instruction single data and single
    instruction multiple data:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行性的两种模型是单指令单数据 (SISD) 和单指令多数据 (SIMD)：
- en: '*Single instruction single data (SISD)* is used to define a single-core architecture.
    A single-core processor system executes one task per any CPU clock cycle; therefore,
    the execution is sequential and deterministic. It receives one instruction (single
    instruction), performs the work required for a single piece of data, and returns
    the results of the computation. This processor architecture will not be covered
    in this book.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*单指令单数据 (SISD)* 用于定义单核架构。单核处理器系统在每个 CPU 时钟周期执行一个任务；因此，执行是顺序和确定的。它接收一条指令（单指令），执行单个数据所需的工作，并返回计算的结果。这种处理器架构将不会在本书中介绍。'
- en: '*Single instruction multiple data (SIMD)* is a form of parallelism achieved
    by distributing the data among the available multiple cores and applies the same
    operations at any given CPU clock cycle. This type of parallel, multicore CPU
    architecture is commonly used to exploit data parallelism.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*单指令多数据 (SIMD)* 是一种通过在可用的多个核心之间分配数据并应用任何给定 CPU 时钟周期上的相同操作来实现的并行形式。这种类型的并行、多核
    CPU 架构通常用于利用数据并行性。'
- en: To achieve data parallelism, the data is split into chunks, and each chunk is
    subject to intensive computations and processed independently, either to produce
    new data to aggregate or to reduce to a scalar value. If you aren’t familiar with
    these terms, they should be clear by the end of the chapter.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现数据并行性，数据被分割成块，每个块都受到密集的计算并独立处理，无论是为了产生新的数据以聚合还是减少到标量值。如果你不熟悉这些术语，它们应该在章节结束时变得清晰。
- en: The ability to compute chunks of data independently is the key to achieving
    significant performance increase, because removing dependencies between blocks
    of data eliminates the need for synchronization to access data and any concerns
    about race conditions, as shown in [figure 4.1](#figure4.1).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 独立计算数据块的能力是实现显著性能提升的关键，因为消除数据块之间的依赖关系消除了访问数据同步的需要，以及任何关于竞争条件的担忧，如[图 4.1](#figure4.1)
    所示。
- en: '![c04-01.png](Images/c04-01.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![c04-01.png](Images/c04-01.png)'
- en: '[Figure 4.1](#figureanchor4.1) Data parallelism is achieved by splitting the
    data set into chunks and independently processing each partition in parallel,
    assigning each chunk to a separate task. When the tasks complete, the data set
    is reassembled. In this figure, the data set on the left is processed by multiple
    tasks using a lock to synchronize their access to the data as a whole. In this
    case, the synchronization is a source of contention between threads and creates
    performance overhead. The data set on the right is split into six parts, and each
    task performs against one-sixth of the total size *N* of the data set. This design
    removes the necessity of using locks to synchronize.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.1](#figureanchor4.1) 通过将数据集分割成块并独立并行处理每个分区，实现了数据并行性。将每个块分配给单独的任务。当任务完成时，数据集被重新组装。在这个图中，左侧的数据集由多个任务使用锁来同步对整个数据的访问进行处理。在这种情况下，同步是线程之间竞争的来源，并产生了性能开销。右侧的数据集被分割成六个部分，每个任务针对数据集总大小
    *N* 的六分之一进行处理。这种设计消除了使用锁来同步的必要性。'
- en: Data parallelism can be achieved in a distributed system, by dividing the work
    among multiple nodes; or in a single computer; or by partitioning the work into
    separated threads. This chapter focuses on implanting and using multicore hardware
    to perform data parallelism.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行性可以通过在分布式系统中通过多个节点分配工作来实现；或者在一个单机中；或者通过将工作分割成独立的线程。本章重点介绍实现和使用多核硬件来执行数据并行性。
- en: 4.1.1 Data and task parallelism
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.1 数据和任务并行性
- en: The goal of data parallelism is decomposing a given data set and generating
    a sufficient number of tasks to maximize the use of CPU resources. In addition,
    each task should be scheduled to compute enough operations to guarantee a faster
    execution time. This is in contrast to context switching, which could introduce
    negative overhead.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行性的目标是分解给定的数据集，并生成足够多的任务以最大化CPU资源的使用。此外，每个任务应安排足够的计算操作，以确保更快的执行时间。这与上下文切换形成对比，上下文切换可能会引入负开销。
- en: 'Data parallelism comes in two flavors:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 数据并行性有两种形式：
- en: '*Task parallelism* targets the execution of computer programs across multiple
    processors, where each thread is responsible for performing a different operation
    at the same time. It is the simultaneous execution of many different functions
    across the same or different data sets on multiple cores.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*任务并行性*旨在在多个处理器上执行计算机程序，其中每个线程负责在同一时间执行不同的操作。这是在多个核心上对相同或不同的数据集执行许多不同函数的同时执行。'
- en: '*Data parallelism* targets the distribution of a given data set into smaller
    partitions across multiple tasks, where each task performs the same instruction
    in parallel. For example, data parallelism could refer to an image-processing
    algorithm, where each image or pixel is updated in parallel by independent tasks.
    Conversely, task parallelism would compute in parallel a set of images, applying
    a different operation for each image. See [figure 4.2](#figure4.2).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据并行性*旨在将给定的数据集分配到多个任务中的较小分区，其中每个任务并行执行相同的指令。例如，数据并行性可能指图像处理算法，其中每个图像或像素由独立任务并行更新。相反，任务并行性将并行计算一系列图像，对每个图像应用不同的操作。参见[图4.2](#figure4.2)。'
- en: '![c04-02.png](Images/c04-02.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![c04-02.png](Images/c04-02.png)'
- en: '[Figure 4.2](#figureanchor4.2) Data parallelism is the simultaneous execution
    of the same function across the elements of a data set. Task parallelism is the
    simultaneous execution of multiple different functions across the same or different
    data sets.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4.2](#figureanchor4.2) 数据并行性是在数据集的元素上同时执行相同的函数。任务并行性是在相同或不同的数据集上同时执行多个不同的函数。'
- en: Is summary, task parallelism focuses on executing multiple functions (tasks),
    and aims to reduce the overall time of computation by running these tasks simultaneously.
    Data parallelism reduces the time it takes to process a data set by splitting
    the same algorithm computation among multiple CPUs to be performed in parallel.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，任务并行性侧重于执行多个函数（任务），并旨在通过同时运行这些任务来减少整体计算时间。数据并行性通过将相同的算法计算分配给多个CPU并行执行，从而减少处理数据集所需的时间。
- en: 4.1.2 The “embarrassingly parallel” concept
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.2 “令人尴尬的并行”概念
- en: In data parallelism, the algorithms applied to process the data are sometimes
    referred to as “embarrassingly parallel” and have the special property of natural
    scalability.^([1](#c04-footnote-1))  This property influences the amount of parallelism
    in the algorithm as the number of available hardware threads increases. The algorithm
    will run faster in a more powerful computer. In data parallelism, the algorithms
    should be designed to run each operation independently in a separate task associated
    with a hardware core. This structure has the advantage of automatically adapting
    the workload at runtime and adjusting the data partitioning based on the current
    computer. This behavior guarantees running the program on all available cores.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据并行性中，应用于处理数据的算法有时被称为“令人尴尬的并行”，并具有自然可扩展的特殊属性。[1](#c04-footnote-1) 这个属性会影响算法中的并行程度，随着可用硬件线程数量的增加而增加。在更强大的计算机上，算法将运行得更快。在数据并行性中，算法应设计为在关联于硬件核心的单独任务中独立运行每个操作。这种结构具有自动在运行时调整工作负载并根据当前计算机调整数据分区的优势。这种行为保证了程序在所有可用核心上运行。
- en: 'Consider summing a large array of numbers. Any part of this array may be summed
    up independently from any other part. The partial sums can then be summed together
    themselves and achieve the same result as if the array had been summed in series.
    Whether or not the partial sums are computed on the same processor or at the same
    time doesn’t matter. Algorithms like this one with a high degree of independence
    are known as embarrassingly parallel problems: the more processors that you throw
    at them, the faster they will run. In chapter 3 you saw the Divide and Conquer
    pattern that provides natural parallelism. It distributes work to numerous tasks
    and then combines (reduces) the results again. Other embarrassingly parallel designs
    don’t require a complex coordination mechanism to provide natural auto-scalability.
    Examples of design patterns that use this approach are Fork/Join, Parallel Aggregation
    (reduce), and MapReduce. We’ll discuss these designs later in this chapter.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑对大量数字数组进行求和。数组的任何部分都可以独立于其他部分进行求和。然后，这些部分和可以相互求和，达到与数组按顺序求和相同的结果。部分和是在同一处理器上还是在同一时间计算并不重要。具有高度独立性的此类算法被称为令人尴尬的并行问题：你投入的处理器越多，它们运行得越快。在第3章中，你看到了提供自然并行性的分而治之模式。它将工作分配给众多任务，然后再次组合（减少）结果。其他令人尴尬的并行设计不需要复杂的协调机制来提供自然的自扩展性。使用这种方法的设计模式示例包括Fork/Join、并行聚合（减少）和MapReduce。我们将在本章后面讨论这些设计。
- en: 4.1.3 Data parallelism support in .NET
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1.3 .NET中的数据并行支持
- en: Identifying code in your programs that can be parallelized isn’t a trivial task,
    but common rules and practices can help. The first thing to do is profiling the
    application. This analysis of the program identifies where the code spends its
    time, which is your clue for where you should start deeper investigations to improve
    performance and to detect opportunities for parallelism. As a guide, an opportunity
    for parallelism is when two or more portions of source code can be executed deterministically
    in parallel, without changing the output of the program. Alternatively, if the
    introduction of parallelism would change the output of the program, the program
    isn’t deterministic and could become unreliable; therefore, parallelism is unusable.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的程序中识别可以并行化的代码不是一项简单任务，但常见的规则和实践可以帮助。首先要做的是对应用程序进行性能分析。这种程序分析确定了代码在哪里花费时间，这是你应该开始更深入调查以改进性能和检测并行机会的线索。作为一个指导，并行机会是在两个或多个源代码部分可以在不改变程序输出的情况下并行执行时。或者，如果引入并行性会改变程序的输出，则程序不是确定的，可能会变得不可靠；因此，并行性不可用。
- en: To ensure deterministic results in a parallel program, the blocks of source
    code that run simultaneously should have no dependencies between them. In fact,
    a program can be parallelized easily when there are no dependencies or when existing
    dependencies can be eliminated. For example, in the Divide and Conquer pattern,
    there are no dependencies among the recursive executions of the functions so that
    parallelism can be accomplished.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保并行程序中的确定性结果，同时运行的源代码块之间不应存在依赖关系。实际上，当没有依赖关系或现有依赖关系可以被消除时，程序可以很容易地进行并行化。例如，在分而治之模式中，函数的递归执行之间没有依赖关系，因此可以实现并行化。
- en: A prime candidate for parallelism is a large data set where a CPU-intensive
    operation can be performed independently on each element. In general, loops in
    any form (`for` loop, `while` loop, and `for-each` loop) are great candidates
    to exploit parallelism. Using Microsoft’s TPL, reshaping a sequential loop into
    a parallel one is an easy task. This library provides a layer of abstraction that
    simplifies the implementation over common parallelizable patterns that are involved
    in data parallelism. These patterns can be materialized using the parallel constructs
    `Parallel.For` and `Parallel.ForEach` offered by the TPL `Parallel` class.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据集是并行化的一个主要候选者，其中可以在每个元素上独立执行CPU密集型操作。一般来说，任何形式的循环（`for`循环、`while`循环和`for-each`循环）都是利用并行性的优秀候选者。使用微软的TPL，将顺序循环重塑为并行循环是一项简单的任务。这个库提供了一层抽象，简化了数据并行中涉及到的常见可并行化模式的实现。这些模式可以使用TPL
    `Parallel`类提供的`Parallel.For`和`Parallel.ForEach`并行构造来具体化。
- en: 'Here are a few patterns found in programs that provide an opportunity for parallelism:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些在提供并行机会的程序中发现的模式：
- en: Sequential loops, where there are no dependencies between the iteration steps.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺序循环，其中迭代步骤之间没有依赖关系。
- en: Reduction and/or aggregation operations, where the results of the computation
    between steps are partially merged. This model can be expressed using a MapReduce
    pattern.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少和/或聚合操作，其中步骤之间的计算结果部分合并。此模型可以使用 MapReduce 模式表示。
- en: Unit of computation, where explicit dependencies can be converted into a Fork/Join
    pattern to run each step in parallel.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算单位，其中显式依赖可以被转换为 Fork/Join 模式以并行运行每个步骤。
- en: Recursive type of algorithms using a Divide and Conquer approach, where each
    iteration can be executed independently in a different thread in parallel.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分而治之方法的递归算法类型，其中每个迭代可以在不同的线程中独立并行执行。
- en: In the .NET framework, data parallelism is also supported through PLINQ, which
    I recommend. The query language offers a more declarative model for data parallelism,
    compared to the `Parallel` class, and is used for parallel evaluation of arbitrary
    queries against a data source. Declarative implies what you want to be done with
    data rather than how you want that to be done. Internally, the TPL uses sophisticated
    scheduling algorithms to distribute parallelized computations efficiently between
    the available processing cores. Both C# and F# take advantage of these technologies
    in a similar way. In the next section, you’ll see these technologies in both programming
    languages, which can be mixed and complement each other nicely.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在 .NET 框架中，数据并行性也通过 PLINQ 支持，我推荐使用它。查询语言为数据并行性提供了一个更声明性的模型，与 `Parallel` 类相比，并且用于对数据源进行任意查询的并行评估。声明性意味着你想要对数据进行什么操作，而不是如何操作。内部，TPL
    使用复杂的调度算法来有效地在可用的处理核心之间分配并行化计算。C# 和 F# 都以类似的方式利用这些技术。在下一节中，你将看到这两种编程语言中的这些技术，它们可以很好地混合和补充。
- en: '4.2 The Fork/Join pattern: parallel Mandelbrot'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 Fork/Join 模式：并行 Mandelbrot
- en: The best way to understand how to convert a sequential program into a parallel
    one is with an example. In this section, we’ll transform a program using the Fork/Join
    pattern to exploit parallel computation and to achieve faster performance.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 理解如何将顺序程序转换为并行程序的最佳方式是通过示例。在本节中，我们将使用 Fork/Join 模式转换程序以利用并行计算并实现更快的性能。
- en: 'In the Fork/Join pattern, a single thread forks and coordinates with multiple
    independent parallel workers and then merges the individual results when complete.
    Fork/Join parallelism manifests in two primary steps:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Fork/Join 模式中，单个线程分支并与多个独立的并行工作者协调，然后在完成时合并个别结果。Fork/Join 并行性体现在两个主要步骤中：
- en: Split a given task into a set of subtasks scheduled to run independently in
    parallel.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将给定的任务分割成一组子任务，这些子任务被安排独立并行运行。
- en: Wait for the forked parallel operations to complete, and then successively join
    the subtask results into the original work.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待分支的并行操作完成，然后依次将子任务结果合并到原始工作中。
- en: Regarding data parallelism, [figure 4.3](#figure4.3) shows a close resemblance
    to [figure 4.1](#figure4.1). The difference is in the last step, where the Fork/Join
    pattern merges the results back into one.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数据并行性，[图 4.3](#figure4.3) 显示与 [图 4.1](#figure4.1) 非常相似。区别在于最后一步，此时 Fork/Join
    模式将结果合并回一个整体。
- en: '![c04-03.png](Images/c04-03.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![c04-03.png](Images/c04-03.png)'
- en: '[Figure 4.3](#figureanchor4.3) The Fork/Join pattern splits a task into subtasks
    that can be executed independently in parallel. When the operations complete,
    the subtasks are joined again. It isn’t a coincidence that this pattern is often
    used to achieve data parallelism. There are clearly similarities.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.3](#figureanchor4.3) Fork/Join 模式将任务分割成可以独立并行执行的子任务。当操作完成时，子任务再次合并。这种模式经常用于实现数据并行性并非巧合。显然存在相似之处。'
- en: As you can see, this pattern fits well in data parallelism. The Fork/Join pattern
    speeds up the execution of a program by partitioning the work into chunks (fork)
    and running each chunk individually in parallel. After each parallel operation
    completes, the chunks are merged back again (join). In general, Fork/Join is a
    great pattern for encoding structured parallelism because the fork and join happen
    at once (synchronously with respect to the caller), but in parallel (from the
    perspective of performance and speed). The Fork/Join abstraction can be accomplished
    easily using the ``Parallel.For loop from the .NET `Parallel` class. This static
    method transparently deals with the partition of data and execution of tasks.``
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，这种模式非常适合数据并行。Fork/Join 模式通过将工作划分为块（fork）并在并行中单独运行每个块来加速程序的执行。在每个并行操作完成后，这些块再次合并（join）。一般来说，Fork/Join
    是一种编码结构化并行的优秀模式，因为 fork 和 join 是同时发生的（相对于调用者是同步的），但并行（从性能和速度的角度来看）。可以使用 .NET `Parallel`
    类中的 `Parallel.For` 循环轻松实现 Fork/Join 抽象。这个静态方法透明地处理数据的划分和任务的执行。
- en: '[PRE0]  [PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE0]  [PRE1]'
