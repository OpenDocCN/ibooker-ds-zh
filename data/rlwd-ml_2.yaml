- en: Appendix. Popular machine-learning algorithms
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录。流行的机器学习算法
- en: '| Name | Type | Use | Linear/nonlinear | Requires normalization |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 类型 | 用途 | 线性/非线性 | 是否需要归一化 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Linear regression | Regression | Model a scalar target with one or more quantitative
    features. Although regression computes a linear combination, features can be transformed
    by nonlinear functions if relationships are known or can be guessed. R: [www.inside-r.org/r-doc/stats/lm](http://www.inside-r.org/r-doc/stats/lm)
    Python: [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)
    | Linear | Yes |'
  id: totrans-3
  prefs: []
  type: TYPE_TB
  zh: '| 线性回归 | 回归 | 使用一个或多个定量特征来建模标量目标。尽管回归计算线性组合，但如果已知或可以猜测关系，特征可以通过非线性函数进行转换。R:
    [www.inside-r.org/r-doc/stats/lm](http://www.inside-r.org/r-doc/stats/lm) Python:
    [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)
    | 线性 | 是 |'
- en: '| Logistic regression | Classification | Categorize observations based on quantitative
    features; predict target class or probabilities of target classes. R: [www.statmethods.net/advstats/glm.html](http://www.statmethods.net/advstats/glm.html)
    Python: [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
    | Linear | Yes |'
  id: totrans-4
  prefs: []
  type: TYPE_TB
  zh: '| 逻辑回归 | 分类 | 根据定量特征对观测值进行分类；预测目标类别或目标类别的概率。R: [www.statmethods.net/advstats/glm.html](http://www.statmethods.net/advstats/glm.html)
    Python: [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
    | 线性 | 是 |'
- en: '| SVM | Classification/regression | Classification based on separation in high-dimensional
    space. Predicts target classes. Target class probabilities require additional
    computation. Regression uses a subset of the data, and performance is highly data
    dependent. R: [https://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf](https://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf)
    Python: [http://scikit-learn.org/stable/modules/svm.html](http://scikit-learn.org/stable/modules/svm.html)
    | Linear | Yes |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '| SVM | 分类/回归 | 基于高维空间中的分离进行分类。预测目标类别。目标类别的概率需要额外计算。回归使用数据的一个子集，并且性能高度依赖于数据。R:
    [https://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf](https://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf)
    Python: [http://scikit-learn.org/stable/modules/svm.html](http://scikit-learn.org/stable/modules/svm.html)
    | 线性 | 是 |'
- en: '| SVM with kernel | Classification/regression | SVM with support for a variety
    of nonlinear models. R: [https://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf](https://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf)
    Python: [http://scikit-learn.org/stable/modules/svm.html](http://scikit-learn.org/stable/modules/svm.html)
    | Nonlinear | Yes |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| 带核的SVM | 分类/回归 | 支持多种非线性模型的SVM。R: [https://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf](https://cran.r-project.org/web/packages/e1071/vignettes/svmdoc.pdf)
    Python: [http://scikit-learn.org/stable/modules/svm.html](http://scikit-learn.org/stable/modules/svm.html)
    | 非线性 | 是 |'
- en: '| K-nearest neighbors | Classification/regression | Targets are computed based
    on those of the training set that are “nearest” to the test examples via a distance
    formula (for example, Euclidean distance). For classification, training targets
    “vote.” For regression, they are averaged. Predictions are based on a “local”
    subset of the data, but are highly accurate for some datasets. R: [https://cran.r-project.org/web/packages/class/class.pdf](https://cran.r-project.org/web/packages/class/class.pdf)
    Python: [http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
    | Nonlinear | Yes |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| K最近邻 | 分类/回归 | 根据距离公式（例如，欧几里得距离）通过训练集中“最近”的示例来计算目标。对于分类，训练目标“投票”。对于回归，它们取平均值。预测基于数据的“局部”子集，但对于某些数据集来说非常准确。R:
    [https://cran.r-project.org/web/packages/class/class.pdf](https://cran.r-project.org/web/packages/class/class.pdf)
    Python: [http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)
    | 非线性 | 是 |'
- en: '| Decision trees | Classification/regression | Training data is recursively
    split into subsets based on attribute value tests, and decision trees that predict
    targets are derived. Produces understandable models, but random forest and boosting
    algorithms nearly always produce lower error rates. R: [www.statmethods.net/advstats/cart.html](http://www.statmethods.net/advstats/cart.html)
    Python: [http://scikit-learn.org/stable/modules/tree.html#tree](http://scikit-learn.org/stable/modules/tree.html#tree)
    | Nonlinear | No |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| 决策树 | 分类/回归 | 基于属性值测试递归地将训练数据分割成子集，并推导出预测目标的决策树。产生的模型易于理解，但随机森林和提升算法几乎总是产生更低的错误率。R:
    [www.statmethods.net/advstats/cart.html](http://www.statmethods.net/advstats/cart.html)
    Python: [http://scikit-learn.org/stable/modules/tree.html#tree](http://scikit-learn.org/stable/modules/tree.html#tree)
    | 非线性 | 否 |'
- en: '| Random forest | Classification/regression | An “ensemble” of decision trees
    is used to produce a stronger prediction than a single decision tree. For classification,
    multiple decision trees “vote.” For regression, their results are averaged. R:
    [https://cran.r-project.org/web/packages/randomForest/randomForest.pdf](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf)
    Python: [http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
    | Nonlinear | No |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 随机森林 | 分类/回归 | 使用“集成”的决策树来产生比单个决策树更强的预测。对于分类，多个决策树“投票”。对于回归，它们的预测结果取平均值。R:
    [https://cran.r-project.org/web/packages/randomForest/randomForest.pdf](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf)
    Python: [http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
    | 非线性 | 否 |'
- en: '| Boosting | Classification/regression | For multitree methods, boosting algorithms
    reduce generalization error by adjusting weights to give greater weight to examples
    that are misclassified or (for regression) those with larger residuals. R: [https://cran.r-project.org/web/packages/gbm/gbm.pdf](https://cran.r-project.org/web/packages/gbm/gbm.pdf)
    [https://cran.r-project.org/web/packages/adabag/adabag.pdf](https://cran.r-project.org/web/packages/adabag/adabag.pdf)
    Python: [http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)
    | Nonlinear | No |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 提升算法 | 分类/回归 | 对于多树方法，提升算法通过调整权重来减少泛化误差，给被错误分类的示例（对于回归，那些具有较大残差的示例）更大的权重。R:
    [https://cran.r-project.org/web/packages/gbm/gbm.pdf](https://cran.r-project.org/web/packages/gbm/gbm.pdf)
    [https://cran.r-project.org/web/packages/adabag/adabag.pdf](https://cran.r-project.org/web/packages/adabag/adabag.pdf)
    Python: [http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)
    | 非线性 | 否 |'
- en: '| Naïve Bayes | Classification | A simple, scalable classification algorithm
    used especially in text classification tasks (for example, spam-classification).
    It assumes independence between features (hence, naïve), which is rarely the case,
    but the algorithm works surprisingly well in specific cases. It utilizes the Bayes
    theorem, but is not “Bayesian” as used in the field of statistics. R: [https://cran.r-project.org/web/packages/e1071/](https://cran.r-project.org/web/packages/e1071/)
    Python: [http://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes)
    | Nonlinear | Yes |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| 简单贝叶斯 | 分类 | 一种简单、可扩展的分类算法，特别适用于文本分类任务（例如，垃圾邮件分类）。它假设特征之间相互独立（因此称为“简单”），这很少是实际情况，但在特定情况下算法表现惊人。它利用贝叶斯定理，但与统计学领域的“贝叶斯”不同。R:
    [https://cran.r-project.org/web/packages/e1071/](https://cran.r-project.org/web/packages/e1071/)
    Python: [http://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes)
    | 非线性 | 是 |'
- en: '| Neural network | Classification/regression | Used to estimate unknown functions
    that are based on a large number of inputs, through the back-propagation algorithm.
    Generally more complex and computationally expensive than other methods, but powerful
    for certain problems. The basis of many deep learning methods. R: [https://cran.r-project.org/web/packages/neuralnet/neuralnet.pdf](https://cran.r-project.org/web/packages/neuralnet/neuralnet.pdf)
    [https://cran.r-project.org/web/packages/nnet/nnet.pdf](https://cran.r-project.org/web/packages/nnet/nnet.pdf)
    Python: [http://scikit-learn.org/dev/modules/neural_networks_supervised.html](http://scikit-learn.org/dev/modules/neural_networks_supervised.html)
    [http://deeplearning.net/software/theano/](http://deeplearning.net/software/theano/)
    | Nonlinear | Yes |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 神经网络 | 分类/回归 | 通过反向传播算法，用于估计基于大量输入的未知函数。通常比其他方法更复杂且计算成本更高，但对于某些问题来说非常强大。许多深度学习方法的基础。R:
    [https://cran.r-project.org/web/packages/neuralnet/neuralnet.pdf](https://cran.r-project.org/web/packages/neuralnet/neuralnet.pdf)
    [https://cran.r-project.org/web/packages/nnet/nnet.pdf](https://cran.r-project.org/web/packages/nnet/nnet.pdf)
    Python: [http://scikit-learn.org/dev/modules/neural_networks_supervised.html](http://scikit-learn.org/dev/modules/neural_networks_supervised.html)
    [http://deeplearning.net/software/theano/](http://deeplearning.net/software/theano/)
    | 非线性 | 是 |'
- en: '| Vowpal Wabbit | Classification/Regression | An online ML program developed
    by John Langford at Yahoo Research, now Microsoft. It incorporates various algorithms,
    including ordinary least squares and single-layer neural nets. As an online ML
    program, it doesn’t require all data to fit in memory. It’s known for fast processing
    of large datasets. Vowpal Wabbit has a unique input format and is generally run
    from a command line rather than through APIs. [https://github.com/JohnLangford/vowpal_wabbit/wiki](https://github.com/JohnLangford/vowpal_wabbit/wiki)
    |   |   |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| Vowpal Wabbit | 分类/回归 | 由雅虎研究（现微软）的John Langford开发的在线机器学习程序。它结合了各种算法，包括普通最小二乘法和单层神经网络。作为一个在线机器学习程序，它不需要所有数据都适合内存。它以快速处理大型数据集而闻名。Vowpal
    Wabbit具有独特的输入格式，通常通过命令行而不是通过API运行。[https://github.com/JohnLangford/vowpal_wabbit/wiki](https://github.com/JohnLangford/vowpal_wabbit/wiki)
    |   |   |'
- en: '| XGBoost | Classification/Regression | A highly optimized and scalable version
    of the boosted decision trees algorithm. [https://xgboost.readthedocs.org/en/latest/](https://xgboost.readthedocs.org/en/latest/)
    |   |   |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| XGBoost | 分类/回归 | 是提升决策树算法的高度优化和可扩展版本。[https://xgboost.readthedocs.org/en/latest/](https://xgboost.readthedocs.org/en/latest/)
    |   |   |'
