- en: 8 Metadata and artifact store
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 元数据和工件存储
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Understanding and managing metadata in the deep learning context
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在深度学习环境中理解和管理元数据
- en: Designing a metadata and artifact store to manage metadata
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个元数据和工件存储库来管理元数据
- en: 'Introducing two open source metadata management tools: ML Metadata and MLflow'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍两个开源元数据管理工具：ML Metadata和MLflow
- en: To produce a high-quality model that fits business requirements, data scientists
    need to experiment with all kinds of datasets, data processing techniques, and
    training algorithms. To build and ship the best model, they spend a significant
    amount of time conducting these experiments.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生产符合业务需求的优质模型，数据科学家需要尝试各种数据集、数据处理技术和训练算法。为了构建和部署最佳模型，他们花费了大量时间进行这些实验。
- en: A variety of *artifacts* (datasets and model files) and *metadata* are produced
    from model training experiments. The metadata may include model algorithms, hyperparameters,
    training metrics, and model versions, which are very helpful in analyzing model
    performance. To be useful, this data must be persistent and retrievable.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练实验产生了各种*工件*（数据集和模型文件）和*元数据*。元数据可能包括模型算法、超参数、训练指标和模型版本，这些在分析模型性能方面非常有帮助。为了有用，这些数据必须持久化和可检索。
- en: When data scientists need to investigate a model performance problem or compare
    different training experiments, is there anything we, as engineers, can do to
    facilitate these efforts? For example, can we make model reproducing and experiment
    comparison easier?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家需要调查模型性能问题或比较不同的训练实验时，作为工程师的我们，是否可以做一些事情来促进这些工作？例如，我们能否使模型的重现和实验比较更容易？
- en: The answer is yes. As engineers, we can build a system that retains the experimental
    metadata and artifacts that data scientists need to reproduce and compare models.
    And if we design this storage and retrieval system well, with proper metadata
    management, data scientists can easily select the best model from a series of
    experiments or figure out the root cause of a model degradation quickly without
    a deep understanding of the metadata system.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是肯定的。作为工程师，我们可以构建一个系统，该系统能够保留数据科学家需要用于重现和比较模型的实验元数据和工件。如果我们设计好这个存储和检索系统，并实施适当的元数据管理，数据科学家就可以轻松地从一系列实验中选择最佳模型，或者快速找出模型退化的根本原因，而无需深入了解元数据系统。
- en: 'In previous chapters, we’ve learned about designing services to produce and
    serve models. Here, we turn our attention to the metadata and artifacts management
    system that facilitates two more key operations: troubleshooting and comparing
    experiments.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们学习了如何设计服务来生成和提供模型。在这里，我们将注意力转向促进两个更多关键操作的元数据和工件管理系统：故障排除和比较实验。
- en: 'We will start this chapter with an introduction to *artifacts* and *metadata*
    and the meaning of these concepts in the context of deep learning. Then we will
    show you how to design metadata management systems using examples and emphasizing
    design principles. Finally, we will discuss two open source metadata management
    systems: MLMD (ML Metadata) and MLflow. By reading this chapter, you will gain
    a clear vision of how to manage metadata and artifacts to facilitate experiment
    comparison and model troubleshooting.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将本章从介绍*工件*和*元数据*以及这些概念在深度学习环境中的意义开始。然后，我们将通过示例展示如何设计元数据管理系统，并强调设计原则。最后，我们将讨论两个开源元数据管理系统：MLMD（ML
    Metadata）和MLflow。通过阅读本章，您将获得如何管理元数据和工件以促进实验比较和模型故障排除的清晰视野。
- en: 8.1 Introducing artifacts
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 介绍工件
- en: People often assume that an artifact in deep learning is the model file produced
    by the model training process. This is partially true. Artifacts are actually
    the files and objects that form both the inputs and outputs of the components
    in the model training process. This is a crucial distinction, and it is important
    to keep this broader definition in mind if you want to engineer a system that
    supports model reproducibility.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人们通常认为深度学习中的工件是模型训练过程产生的模型文件。这在一定程度上是正确的。实际上，工件是构成模型训练过程中组件输入和输出的文件和对象。这是一个重要的区别，如果你想要设计一个支持模型可重现性的系统，那么记住这个更广泛的概念是非常重要的。
- en: Under this definition, artifacts can include datasets, models, code, or any
    other number of objects used in a deep learning project. For example, the raw
    input training data, the labeled dataset produced from a labeling tool, and the
    results data of a data processing pipeline are all considered artifacts.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这个定义，工件可以包括数据集、模型、代码或任何其他在深度学习项目中使用的对象。例如，原始输入训练数据、从标注工具生成的标注数据集以及数据处理管道的结果数据都被视为工件。
- en: In addition, artifacts must be preserved with metadata that describes their
    facts and lineage to allow performance comparisons, reproducibility, and troubleshooting.
    In practice, artifacts are stored as raw files on a file server or cloud storage
    service, such as Amazon Simple Storage Service or Azure Blob Storage. And we associate
    artifacts with their metadata in a *metadata store* on a separate storage service.
    See figure 8.1 for a diagram of what this arrangement typically looks like.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，工件必须与描述其事实和血统的元数据一起保存，以便进行性能比较、可重现性和故障排除。在实践中，工件以原始文件的形式存储在文件服务器或云存储服务上，例如Amazon
    Simple Storage Service或Azure Blob Storage。我们将工件与其元数据关联到单独的存储服务上的一个*元数据存储*中。请参阅图8.1了解这种安排通常是什么样的。
- en: Figure 8.1 displays the common practice of managing artifacts. The artifact
    files are saved to a file storage system, and their file URLs are saved with other
    related metadata (such as model training execution ID and model ID) in the metadata
    store. This setup allows us—or data scientists—to search for a model in the metadata
    store and easily find all the input and output artifacts of the corresponding
    model training process.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1显示了管理工件的常见做法。工件文件被保存在文件存储系统中，它们的文件URL与其他相关元数据（如模型训练执行ID和模型ID）一起保存在元数据存储中。这种设置使我们或数据科学家能够在元数据存储中搜索模型，并轻松找到相应模型训练过程的输入和输出工件。
- en: '![](../Images/08-01.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1](../Images/08-01.png)'
- en: Figure 8.1 Artifacts are associated with their metadata in the metadata store.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 工件与其元数据在元数据存储中相关联。
- en: 8.2 Metadata in a deep learning context
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 深度学习环境中的元数据
- en: In general terms, metadata is structured reference data that provides information
    about other data or objects, such as the nutrition facts label on packaged food.
    In machine learning (ML) and deep learning, however, metadata is more specific
    to models; it’s the data that describes model training executions (runs), workflows,
    models, datasets, and other artifacts.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从一般意义上讲，元数据是有结构的参考数据，它提供了关于其他数据或对象的信息，例如包装食品上的营养成分标签。然而，在机器学习（ML）和深度学习中，元数据更具体地与模型相关；它是描述模型训练执行（运行）、工作流程、模型、数据集和其他工件的数据。
- en: For any distributed system, we track service metadata in the form of logs and
    metrics at a service level. For example, we might track metrics such as CPU rate,
    number of active users, and number of failed web requests. We use these metrics
    for system/ service monitoring, troubleshooting, and observation purposes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何分布式系统，我们以日志和指标的形式在服务级别跟踪服务元数据。例如，我们可能会跟踪CPU使用率、活跃用户数量和失败的Web请求数量等指标。我们使用这些指标进行系统/服务监控、故障排除和观察。
- en: In deep learning systems, beyond the service-level metric, we collect metadata
    for model troubleshooting, comparison, and reproduction purposes. You can think
    of deep learning metadata as a special subset of logs and metrics that we use
    to monitor and track every deep learning activity in the system. These activities
    include data parsing, model training, and model serving.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习系统中，除了服务级别的指标外，我们还收集元数据以用于模型故障排除、比较和重现。你可以将深度学习元数据视为我们用来监控和跟踪系统中每个深度学习活动的特殊日志和指标子集。这些活动包括数据解析、模型训练和模型服务。
- en: 8.2.1 Common metadata categories
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 常见元数据类别
- en: 'Although we’ve just defined metadata, the term is actually somewhat arbitrary;
    there is no set guideline on which data should be considered metadata. For engineers
    of deep learning systems, we recommend defining metadata in the following four
    categories: model training run, general artifact, model file, and orchestration
    workflow. To give you a concrete feel for these categories, let’s look at each
    category and some examples of metadata that go into each one.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们刚刚定义了元数据，但这个术语实际上有些任意；没有固定的指南说明哪些数据应被视为元数据。对于深度学习系统的工程师来说，我们建议在以下四个类别中定义元数据：模型训练运行、通用工件、模型文件和编排工作流程。为了让你对这些类别有一个具体的感受，让我们来看一下每个类别以及每个类别中的一些元数据示例。
- en: Metadata for a model training run
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练运行的元数据
- en: To reproduce models, analyze model performance, and facilitate model troubleshooting,
    we need to track all the input and output data and artifacts of a model training
    run. This includes
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了重现模型、分析模型性能以及便于模型故障排除，我们需要跟踪模型训练运行的所有输入和输出数据以及文物。这包括
- en: '*Dataset ID and version*—The unique identity of the dataset used in model training.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据集ID和版本*——在模型训练中使用的数据集的唯一标识符。'
- en: '*Hyperparameters*—The hyperparameters used in the training, such as learning
    rate and number of epochs.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*超参数*——训练中使用的超参数，例如学习率和训练轮数。'
- en: '*Hardware resources*—CPU, GPU, TPU, memory, and disk size allocated in the
    training and the actual consumption of these resources.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*硬件资源*——在训练中分配的CPU、GPU、TPU、内存和磁盘大小以及这些资源的实际消耗。'
- en: '*Training code version*—The unique identity of the training code snapshot used
    in model training.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*训练代码版本*——在模型训练中使用的训练代码快照的唯一标识符。'
- en: '*Training code configuration*—The configuration for recreating the training
    code execution environment, such as conda.yml, Dockerfile, and requirement.txt.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*训练代码配置*——用于重现训练代码执行环境的配置，例如conda.yml、Dockerfile和requirement.txt。'
- en: '*Training metrics*—The metrics show how model training progresses, for example,
    the loss value at each training epoch.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*训练指标*——这些指标显示了模型训练的进度，例如每个训练轮次的损失值。'
- en: '*Model evaluation metrics*—The metrics show the model performance, such as
    F-score and root-mean-squared error (RMSE).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型评估指标*——这些指标显示了模型性能，例如F分数和均方根误差（RMSE）。'
- en: Metadata for general artifacts
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通用文物的元数据
- en: 'Artifacts can be any arbitrary files, such as datasets, models, and prediction
    results. To be able to find the artifact in artifact storage, we want to track
    below metadata for artifacts:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 文物可以是任何任意文件，例如数据集、模型和预测结果。为了能够在文物存储中找到文物，我们希望跟踪以下元数据以供文物使用：
- en: '*File location*—The path to the place where the artifact is stored, for example,
    Amazon S3 file path or internal file system path'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文件位置*——存储文物的路径，例如Amazon S3文件路径或内部文件系统路径'
- en: '*File version*—The unique identity to distinguish different file updates'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文件版本*——区分不同文件更新的唯一标识符'
- en: '*Description*—The additional information to describe what’s inside the artifact
    file'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*描述*——描述文物文件内部内容的附加信息'
- en: '*Audit history*—The information about who created the artifact version, when
    the artifact was created, and how it was created'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*审计历史*——有关创建文物版本的人员、创建时间以及创建方式的信息'
- en: Metadata for model file
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 模型文件的元数据
- en: 'Models are one kind of artifact, but because models are the main product of
    every deep learning system, we recommend tracking model metadata separately from
    other artifacts. When we define model metadata, it’s best to consider two perspectives:
    model training and model serving.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是一种文物，但由于模型是每个深度学习系统的主要产品，我们建议将模型元数据与其他文物分开跟踪。当我们定义模型元数据时，最好考虑两个角度：模型训练和模型服务。
- en: For model training, to have model lineage, we want to keep a mapping between
    a model and the model training run that produced it. Model lineage is important
    for model comparison and reproduction. For example, when comparing two models,
    by having the link of model training run and model, data scientists can easily
    determine all the details of how the model is produced, including the input datasets,
    training parameters, and training metrics. The model training metrics are very
    useful for understanding model performance.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型训练，为了有模型谱系，我们希望保持模型与其产生的模型训练运行之间的映射。模型谱系对于模型比较和重现非常重要。例如，在比较两个模型时，通过拥有模型训练运行和模型的链接，数据科学家可以轻松地确定模型产生的所有细节，包括输入数据集、训练参数和训练指标。模型训练指标对于理解模型性能非常有用。
- en: For model serving, we want to track the model execution data for future model
    performance analysis. These execution data, such as model response latency and
    prediction miss rate, are very useful for detecting model performance degradation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模型服务，我们希望跟踪模型执行数据以供未来的模型性能分析。这些执行数据，如模型响应延迟和预测误报率，对于检测模型性能退化非常有用。
- en: 'The following are a few recommended model metadata categories besides the aforementioned
    general artifact metadata:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些除上述通用文物元数据之外的推荐模型元数据类别：
- en: '*Resource consumption*—Memory, GPU, CPU, and TPU consumption for model serving'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*资源消耗*——模型服务中使用的内存、GPU、CPU和TPU消耗'
- en: '*Model training run*—The model training run ID, which is used to find the code,
    dataset, hyperparameters, and environments that create the model'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型训练运行*—模型训练运行ID，用于找到创建模型的代码、数据集、超参数和环境'
- en: '*Experiment*—Tracking the model experiment activities in production, for example,
    customer traffic distribution for different model versions'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实验*—跟踪生产中的模型实验活动，例如不同模型版本的客户流量分布'
- en: '*Production*—Model usage in production, such as query per second and model
    prediction statistics'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*生产*—在生产环境中使用模型，例如每秒查询次数和模型预测统计'
- en: '*Model performance*—Tracking model evaluation metrics for drift detection,
    such as concept drift and performance drift'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型性能*—跟踪模型评估指标以检测漂移，例如概念漂移和性能漂移'
- en: Note Models will, unavoidably, start performing worse once they are shipped
    to production. We call this behavior *model degradation*. As the statistical distribution
    of the target group changes over time, model prediction becomes less accurate.
    New popular slogans, for example, can affect the accuracy of voice recognition.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 注意模型一旦部署到生产环境中，不可避免地会开始表现得更差。我们称这种行为为*模型退化*。随着目标群体统计分布随时间变化，模型预测的准确性会降低。例如，新的流行口号可能会影响语音识别的准确性。
- en: Metadata for pipeline
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 管道元数据
- en: 'A pipeline or workflow is needed when we want to automate a multiple-step model
    training task. For example, we can use workflow management tools like Airflow,
    Kubeflow, or Metaflow to automate a model training process that contains multiple
    functional steps: data collection, feature extraction, dataset augmentation, training,
    and model deployment. We will discuss workflow in detail in the next chapter.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要自动化一个多步骤模型训练任务时，就需要一个管道或工作流。例如，我们可以使用Airflow、Kubeflow或Metaflow等工作流管理工具来自动化包含多个功能步骤（数据收集、特征提取、数据集增强、训练和模型部署）的模型训练过程。我们将在下一章详细讨论工作流。
- en: For pipeline metadata, we usually track the pipeline execution history and the
    pipeline input and output. This data can provide audit information for future
    troubleshooting.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于管道元数据，我们通常跟踪管道执行历史和管道输入输出。这些数据可以为未来的故障排除提供审计信息。
- en: Note Deep learning projects vary a lot. The model training code is dramatically
    different for voice recognition, natural language processing, and image generation.
    There are many factors specific to the project, such as the size/type of the dataset,
    type of the ML model, and input artifacts. Besides the sample metadata mentioned
    previously, we recommend you define and collect the metadata based on your project.
    When you are looking for data that helps model reproducing and troubleshooting,
    the metadata list will come to you naturally.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 注意深度学习项目差异很大。对于语音识别、自然语言处理和图像生成，模型训练代码有显著差异。有许多特定于项目的因素，例如数据集的大小/类型、ML模型的类型和输入工件。除了之前提到的示例元数据外，我们建议您根据您的项目定义和收集元数据。当您寻找帮助模型复现和故障排除的数据时，元数据列表会自然出现。
- en: 8.2.2 Why manage metadata?
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 为什么需要管理元数据？
- en: Because metadata is normally instrumented or recorded in the form of logs or
    metrics, you may wonder why we need to manage deep learning metadata separately.
    Can we simply fetch the deep learning metadata from log files? Log management
    systems like Splunk ([https://www.splunk.com/](https://www.splunk.com/)) and Sumo
    Logic ([https://www.sumologic.com/](https://www.sumologic.com/)) come in very
    handy because they allow developers to search and analyze logs and events produced
    by distributed systems.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 由于元数据通常以日志或指标的形式进行记录或记录，你可能会想知道为什么我们需要单独管理深度学习元数据。我们能否简单地从日志文件中获取深度学习元数据？像Splunk([https://www.splunk.com/](https://www.splunk.com/))和Sumo
    Logic([https://www.sumologic.com/](https://www.sumologic.com/))这样的日志管理系统非常有用，因为它们允许开发者搜索和分析分布式系统产生的日志和事件。
- en: To better explain the necessity of having a dedicated component for managing
    metadata in a deep learning system, we will convey a story. Julia (data engineer),
    Ravi (data scientist), and Jianguo (system developer) work together on a deep
    learning system to develop intent classification models for a chatbot application.
    Ravi develops intent classification algorithms, Julia works on data collection
    and parsing, and Jianguo develops and maintains the deep learning system.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地解释在深度学习系统中拥有一个专门组件来管理元数据的必要性，我们将讲述一个故事。Julia（数据工程师）、Ravi（数据科学家）和Jianguo（系统开发者）共同工作在一个深度学习系统中，为聊天机器人应用程序开发意图分类模型。Ravi开发意图分类算法，Julia负责数据收集和解析，Jianguo开发和维护深度学习系统。
- en: During the project development and test phases, Julia and Ravi work together
    to build an experimental training pipeline to produce intent models. After the
    models are built, Ravi passes them to Jianguo to deploy the experiment models
    to the prediction service and test them with real customer requests.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目开发和测试阶段，Julia和Ravi合作构建一个实验性训练管道来生成意图模型。模型构建完成后，Ravi将它们传递给Jianguo，将实验模型部署到预测服务中，并使用真实客户请求进行测试。
- en: When Ravi feels good about the experimentation, he promotes the training algorithm
    from the experimental pipeline to an automated production training pipeline. This
    pipeline runs in the production environment and produces intent models with customer
    data as input. The pipeline also deploys the models to the prediction service
    automatically. Figure 8.2 illustrates the whole story setting.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当Ravi对实验感到满意时，他将训练算法从实验管道提升到自动化的生产训练管道。这个管道在生产环境中运行，并使用客户数据作为输入生成意图模型。该管道还自动将模型部署到预测服务中。图8.2说明了整个故事设置。
- en: '![](../Images/08-02.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图8-2](../Images/08-02.png)'
- en: Figure 8.2 Model development without metadata management
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 模型开发无元数据管理
- en: A few weeks later, after Ravi released the latest intent classification algorithm,
    one chatbot customer—BestFood Inc.—reported a model performance degradation problem
    to Ravi. In the investigation request, BestFood mentioned that their bot’s intent
    classification accuracy dropped 10% after using a new dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 几周后，在Ravi发布了最新的意图分类算法后，一位聊天机器人客户——BestFood公司——向Ravi报告了一个模型性能下降问题。在调查请求中，BestFood提到，在采用新数据集后，他们的聊天机器人的意图分类准确率下降了10%。
- en: To troubleshoot the reported model performance degradation problem, Ravi needs
    to verify lots of information. He first needs to check which model version is
    currently being used by BestFood in the prediction service and then check the
    model lineage of the current model, such as the dataset version and code version
    used in the training pipeline. After that, Ravi may also need to reproduce the
    model for local debugging. He needs to compare the current model and the previous
    model to test the data distribution effect (current new dataset vs. previous dataset).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决报告中的模型性能下降问题，Ravi需要验证大量信息。他首先需要检查BestFood在预测服务中当前使用的是哪个模型版本，然后检查当前模型的模型血缘关系，例如在训练管道中使用的数据集版本和代码版本。之后，Ravi可能还需要重新生成模型进行本地调试。他需要比较当前模型和上一个模型来测试数据分布效果（当前新数据集与上一个数据集）。
- en: Ravi is a natural language process (NLP) expert, but he has very little knowledge
    about the deep learning system on which his training code runs. To continue his
    investigation, he has to ask Jianguo and Julia to obtain the relevant model, dataset,
    and code information. Because everyone has only a fragment of knowledge about
    the model training application and underlying deep learning system/infrastructure,
    for each model performance troubleshooting, Ravi, Julia, and Jianguo have to work
    together to grasp the full context, which is time-consuming and inefficient.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Ravi是一位自然语言处理（NLP）专家，但他对他的训练代码运行的深度学习系统了解甚少。为了继续他的调查，他必须请求Jianguo和Julia获取相关的模型、数据集和代码信息。由于每个人对模型训练应用和底层深度学习系统/基础设施的了解都只是一部分，对于每个模型性能故障排除，Ravi、Julia和Jianguo必须共同工作以掌握完整上下文，这既耗时又低效。
- en: This story, of course, is oversimplified. In practice, deep learning project
    development is made of data, algorithms, system/runtime development, and hardware
    management. The whole project is owned by different teams, and there is seldom
    one person who knows everything. Relying on cross-team collaboration to troubleshoot
    model-related problems is unrealistic in a corporate setting.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这个故事过于简化。在实践中，深度学习项目开发由数据、算法、系统/运行时开发和硬件管理组成。整个项目由不同的团队拥有，很少有一个人的知识涵盖所有方面。在企业环境中，依靠跨团队协作来解决与模型相关的问题是不可行的。
- en: The key factor missing in figure 8.2 is an effective method for searching and
    connecting deep learning metadata in a centralized place so that Julia, Ravi,
    and Jianguo can obtain the model metadata easily. In figure 8.3, we add the missing
    piece—a metadata and artifact store (the gray box in the middle)—to improve the
    debuggability.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在图8.2中缺失的关键因素是，在集中位置搜索和连接深度学习元数据的有效方法，以便Julia、Ravi和Jianguo可以轻松获取模型元数据。在图8.3中，我们添加了缺失的部分——一个元数据和工件存储（中间的灰色框）——以提高调试性。
- en: '![](../Images/08-03.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图8-3](../Images/08-03.png)'
- en: Figure 8.3 Model troubleshooting with metadata management
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 使用元数据管理进行模型故障排除
- en: If you compare figure 8.3 to figure 8.2, you’ll see a new component (the metadata
    and artifact store) is introduced in the middle of figure 8.3\. All the deep learning
    metadata we described in section 8.2.1, regardless of whether they are from the
    experiment pipeline or production pipeline, are collected and stored in this metadata
    store.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将图 8.3 与图 8.2 进行比较，你会在图 8.3 的中间部分看到引入了一个新的组件（元数据和工件存储库）。我们在第 8.2.1 节中描述的所有深度学习元数据，无论它们来自实验管道还是生产管道，都被收集并存储在这个元数据存储库中。
- en: The metadata store provides a holistic view of metadata for every data science
    activity in the deep learning system. Metadata of the model, pipeline/training
    run, and artifacts are not only saved but also correlated inside this store, so
    people can obtain related information easily. For example, because model files
    and model training runs are linked in the store, people can easily determine the
    model lineage of a given model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据存储为深度学习系统中每个数据科学活动提供全面的元数据视图。模型、管道/训练运行和工件的元数据不仅被保存，而且在这个存储库内部相关联，因此人们可以轻松地获取相关信息。例如，由于模型文件和模型训练运行在存储库中是链接的，人们可以轻松地确定给定模型的模型血缘。
- en: Now, Ravi, the data scientist, can use the metadata store UI to list all the
    models and training runs in the system. Then he can dive deep into the metadata
    store to find the input parameters, datasets, and training metric used in the
    past training run, which are super helpful in evaluating the model. More importantly,
    Ravi can retrieve the metadata quickly and completely on his own, without knowing
    the underlying infrastructure of model training and serving.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，数据科学家 Ravi 可以使用元数据存储库用户界面列出系统中的所有模型和训练运行。然后他可以深入元数据存储库以找到过去训练运行中使用的输入参数、数据集和训练指标，这对评估模型非常有帮助。更重要的是，Ravi
    可以快速且完整地自行检索元数据，而无需了解模型训练和服务的底层基础设施。
- en: 8.3 Designing a metadata and artifacts store
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 设计元数据和工件存储库
- en: In this section, we will first discuss the design principles for building a
    metadata and artifact store and then introduce a general design proposal that
    follows those principles. Even if you prefer to use open source technology to
    manage metadata, the discussion in this section will still benefit you; understanding
    the design requirements and solutions will help you choose the right tool for
    your needs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将首先讨论构建元数据和工件存储库的设计原则，然后介绍遵循这些原则的一般设计提案。即使你更喜欢使用开源技术来管理元数据，本节中的讨论也将对你有所帮助；理解设计需求和解决方案将帮助你选择适合你需求的正确工具。
- en: Note To keep things short, we use *metadata and artifact store* and *metadata
    store* interchangeably in this chapter. When we mention *metadata store*, it includes
    the artifacts management as well.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：为了简化内容，我们在本章中交替使用“元数据和工件存储库”和“元数据存储库”。当我们提到“元数据存储库”时，它包括工件管理。
- en: 8.3.1 Design principles
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.1 设计原则
- en: A metadata and artifact store is designed to facilitate model performance troubleshooting
    and experiment comparison. It stores all kinds of metadata and aggregates it around
    models and training runs, so data scientists can obtain the correlated model lineage
    and model training metadata quickly for an arbitrary model. A good metadata store
    should address the following four principles.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据和工件存储库旨在促进模型性能故障排除和实验比较。它存储所有类型的元数据，并将其围绕模型和训练运行进行聚合，以便数据科学家可以快速获取任意模型的关联模型血缘和模型训练元数据。一个好的元数据存储库应该遵循以下四个原则。
- en: 'Principle 1: Showing model lineage and versioning'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 原则 1：展示模型血缘和版本控制
- en: 'When receiving a model name, a metadata store should be able to determine the
    versions of that model and the lineage for each model version, such as which training
    run produced the model and what the input parameters and dataset are. Model version
    and lineage are essential to model troubleshooting. When a customer reports a
    problem on a model, such as model performance degradation, the first questions
    we ask are: When is the model produced? Has the training dataset changed? Which
    version of training code is used, and where can we find the training metric? We
    can find all the answers in the model lineage data.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当接收到一个模型名称时，元数据存储库应该能够确定该模型的版本以及每个模型版本的血缘关系，例如哪个训练运行生成了模型以及输入参数和数据集是什么。模型版本和血缘关系对于模型故障排除至关重要。当客户报告模型问题，例如模型性能下降时，我们首先询问的问题是：模型是什么时候生成的？训练数据集是否发生了变化？使用了哪个版本的训练代码，我们可以在哪里找到训练指标？我们可以在模型血缘数据中找到所有答案。
- en: 'Principle 2: Enabling model reproducibility'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 原则2：实现模型可重复性
- en: A metadata store should track all the metadata required to reproduce a model,
    such as the training pipeline/run configuration, input dataset files, and algorithm
    code version. Being able to reproduce a model is crucial for model experiment
    evaluation and troubleshooting. We need a place to capture the configuration,
    input parameters, and artifacts to kick off a model training run to reproduce
    the same model. The metadata store is the ideal place to retain such information.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据存储应该跟踪所有用于重现模型的元数据，例如训练管道/运行配置、输入数据集文件和算法代码版本。能够重现模型对于模型实验评估和故障排除至关重要。我们需要一个地方来捕获配置、输入参数和工件，以便启动模型训练运行以重现相同的模型。元数据存储是保留此类信息的理想场所。
- en: 'Principle 3: Easy access to packaged models'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 原则3：方便访问打包的模型
- en: A metadata store should let data scientists access model files easily, without
    having to understand the complex backend system. The store should have both manual
    and programmatic methods, as data scientists need to be able to run both manual
    and automated model performance testing.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据存储应该让数据科学家能够轻松访问模型文件，而无需理解复杂的后端系统。存储库应该既有手动方法也有程序化方法，因为数据科学家需要能够运行手动和自动化的模型性能测试。
- en: For example, by using a metadata store, data scientists can quickly identify
    the model file that is currently used in production service and download it for
    debugging. Data scientists can also write code to pull arbitrary versions of models
    from the metadata store to automate the model comparison between the new and old
    model versions.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，通过使用元数据存储，数据科学家可以快速识别当前在生产服务中使用的模型文件，并下载它进行调试。数据科学家还可以编写代码从元数据存储中拉取任意版本的模型，以自动化新旧模型版本之间的模型比较。
- en: 'Principle 4: Visualizing model training tracking and comparing'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 原则4：可视化模型训练跟踪和比较
- en: Good visualization can greatly improve the efficiency of the model troubleshooting
    process. Data scientists rely on a huge range of metrics to compare and analyze
    model experiments, and the metadata store needs to be equipped with visualization
    tools that can handle all (or any type of) metadata queries.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 良好的可视化可以极大地提高模型故障排除过程的效率。数据科学家依赖于大量指标来比较和分析模型实验，元数据存储需要配备能够处理所有（或任何类型）元数据查询的可视化工具。
- en: For example, it needs to be able to show the differences and trending behavior
    on the model evaluation metrics for a set of model training runs. It also needs
    to be able to show model performance trends on the latest 10 released models.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，它需要能够显示一组模型训练运行在模型评估指标上的差异和趋势行为。它还需要能够显示最新10个发布模型的模型性能趋势。
- en: 8.3.2 A general metadata and artifact store design proposal
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.2 一个通用的元数据和工件存储设计提案
- en: To address the design principles in section 8.3.1, a deep learning metadata
    store should be a metric storage system, and it needs to store all kinds of metadata
    and the relationships between them. This metadata should be aggregated around
    model and training/experiment executions, so we can find all model-correlated
    metadata quickly during troubleshooting and performance analysis. Therefore, the
    data schema of the internal metadata storage is the key to the metadata store
    design.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决第8.3.1节中的设计原则，深度学习元数据存储应该是一个指标存储系统，并且它需要存储所有种类的元数据和它们之间的关系。这些元数据应该围绕模型和训练/实验执行进行聚合，这样我们就可以在故障排除和性能分析过程中快速找到所有与模型相关的元数据。因此，内部元数据存储的数据模式是元数据存储设计的关键。
- en: Although a metadata store is a data storage system, data scaling is usually
    not a concern because the data volume of metadata for a deep learning system is
    not high. Because the metadata size depends on the number of model training executions
    and models and we don’t expect to have more than 1,000 model training runs each
    day, a single database instance should be good enough for a metadata store system.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管元数据存储是一个数据存储系统，但数据扩展通常不是问题，因为深度学习系统的元数据数据量并不高。因为元数据大小取决于模型训练执行的次数和模型数量，我们预计每天不会超过1,000次模型训练运行，因此单个数据库实例应该足够用于元数据存储系统。
- en: For user convenience, a metadata store should offer a web data ingestion interface
    and logging SDK, so deep learning metadata can be instrumented in a similar way
    as application logs and metrics. Based on the design principles and this analysis
    of the system requirements, we have come up with a sample metadata store design
    for your reference. Figure 8.4 shows the overview of this component.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便用户，元数据存储应该提供一个Web数据摄入接口和日志SDK，以便深度学习元数据可以像应用程序日志和指标一样进行度量。基于设计原则和系统需求的分析，我们为您提供了一个示例元数据存储设计供参考。图8.4展示了该组件的概览。
- en: '![](../Images/08-04.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08-04.png)'
- en: Figure 8.4 A general metadata and artifact store system design
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 通用元数据和工件存储系统设计
- en: 'In figure 8.4, the sample metadata store system is composed of four components:
    a client SDK, a web server, backend storage, and a web UI. Each component and
    step in a deep learning workflow uses the client SDK to send metadata to the metadata
    store server. The metadata store exposes a RESTful interface to metadata ingestion
    and querying. The web UI visualizes the metadata store server’s RESTful interface.
    Besides the basic metadata and artifact organizing and searching, it can also
    visualize the model performance metrics and model differences for various model
    training runs.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在图8.4中，示例元数据存储系统由四个组件组成：客户端SDK、网络服务器、后端存储和Web用户界面。深度学习工作流程中的每个组件和步骤都使用客户端SDK将元数据发送到元数据存储服务器。元数据存储提供了一个RESTful接口用于元数据摄入和查询。Web用户界面可视化元数据存储服务器的RESTful接口。除了基本的元数据和工件组织和搜索外，它还可以可视化不同模型训练运行的模型性能指标和模型差异。
- en: The metadata store server is at the center of this design. It has three layers—a
    RESTful web interface, a data aggregator, and storage. The data aggregator component
    knows how the metadata is organized and interlinked, so it knows where to add
    new metadata and how to serve different kinds of metadata-searching queries. In
    terms of storage, we recommend building an abstract metadata and artifact storage
    layer. This abstract layer works as an adapter that encapsulates the actual metadata
    and filestoring logic. So the metadata store can run on top of different types
    of storage backends, such as cloud object storage, local files, and a local or
    remote SQL server.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据存储服务器是这个设计的中心。它有三个层次——RESTful网络接口、数据聚合器和存储。数据聚合器组件知道元数据是如何组织和相互链接的，因此它知道在哪里添加新的元数据以及如何服务不同类型的元数据搜索查询。在存储方面，我们建议构建一个抽象的元数据和工件存储层。这个抽象层作为一个适配器，封装了实际的元数据和文件存储逻辑。因此，元数据存储可以在不同的存储后端上运行，例如云对象存储、本地文件和本地或远程SQL服务器。
- en: The metadata storage schema
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据存储模式
- en: Now let’s look at the data schema of the metadata storage. Whether we save the
    metadata in an SQL or noSQL database or plain files, we need to define a data
    schema for how the metadata is structured and serialized. Figure 8.4 shows the
    entity relationship diagram of our metadata storage.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看元数据存储的数据模式。无论我们是在SQL或noSQL数据库中保存元数据，还是以纯文件形式保存，我们都需要定义一个数据模式来描述元数据的结构和序列化方式。图8.4展示了我们元数据存储的实体关系图。
- en: In figure 8.5, the model training run (`Training_Runs` object) is at the central
    stage of the entity relationship map. This is because model performance troubleshooting
    always starts from the process (training runs or workflow) that produced the model,
    so we want to have a dedicated data object to track the training executions that
    produce model files.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在图8.5中，模型训练运行（`Training_Runs`对象）处于实体关系图的中心阶段。这是因为模型性能故障排除总是从产生模型的过程（训练运行或工作流）开始，因此我们希望有一个专门的数据对象来跟踪产生模型文件的训练执行。
- en: '![](../Images/08-05.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08-05.png)'
- en: Figure 8.5 An entity relationship diagram of the data schema of the metadata
    storage
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5 元数据存储数据模式的实体关系图
- en: The detailed metadata for model training is saved in the `Metrics` and `Parameters`
    objects. The `Parameters` object stores the input parameters of the training run,
    such as dataset ID, dataset version, and training hyperparameters. The `Metrics`
    object stores the training metrics produced during training, such as model F2
    score.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练的详细元数据保存在`Metrics`和`Parameters`对象中。`Parameters`对象存储训练运行的输入参数，例如数据集ID、数据集版本和训练超参数。`Metrics`对象存储训练过程中产生的训练指标，例如模型F2分数。
- en: The `Experiments` objects are used to organize and group model training runs.
    One experiment can have multiple training runs. For example, we could define our
    intent classification model development project as one training experiment and
    then associate all the intent classification model training execution with this
    experiment. Then, on the UI, we can group training executions by different experiments.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`Experiments`对象用于组织和分组模型训练运行。一个实验可以有多个训练运行。例如，我们可以将我们的意图分类模型开发项目定义为一个训练实验，然后将所有意图分类模型训练执行与此实验关联。然后，在UI上，我们可以根据不同的实验对训练执行进行分组。'
- en: The `Models` objects store the metadata of model files, such as model version,
    type, and stage. A model can have multiple stages, such as test, preproduction,
    and production, and all of these can be preserved as well.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`Models`对象存储模型文件的元数据，例如模型版本、类型和阶段。一个模型可以有多个阶段，例如测试、预生产和生产，所有这些都可以保留。'
- en: Notice also that each of the entities in figure 8.5 is linked (noted by lines
    in the diagram) to the specific training run that produces them, so they will
    all share a common `training_run_id`. By leveraging this data link, you can start
    with any training run object and find its output model, training input data, and
    model training metrics.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，图8.5中的每个实体都与产生它们的特定训练运行相关联（由图中的线条标注），因此它们都将共享一个共同的`training_run_id`。通过利用这个数据链接，您可以从任何训练运行对象开始，找到其输出模型、训练输入数据和模型训练指标。
- en: Earlier we said we may call it the metadata store for short, but it also stores
    artifacts. So where is the artifact in this design? We store the artifact URL
    in the `Training_Runs` object as the training run’s output. If we query the model
    or training execution, we will get the artifacts’ URL.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到，我们可能将其简称为元数据存储，但它也存储了工件。那么在这个设计中工件在哪里呢？我们将工件URL存储在`Training_Runs`对象中，作为训练运行的输出。如果我们查询模型或训练执行，我们将得到工件的URL。
- en: Model focus vs. pipeline focus
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 模型关注法与管道关注法
- en: 'There are two schools of thought on designing metadata systems: model focus
    and pipeline focus. The model focus method correlates metadata around model files,
    whereas the pipeline focus method aggregates metadata around the pipeline/training
    run, like what we proposed in figure 8.4.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计元数据系统方面存在两种不同的观点：模型关注法和管道关注法。模型关注法将元数据与模型文件相关联，而管道关注法则将元数据聚合在管道/训练运行周围，就像我们在图8.4中提出的那样。
- en: We think model focus and pipeline focus are equally useful to the end users
    (data scientists), and they are not mutually exclusive. We can support both of
    them.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为模型关注法和管道关注法对最终用户（数据科学家）同样有用，并且它们不是相互排斥的。我们可以支持它们两个。
- en: You can implement the metadata store’s storage layer by using the pipeline focus
    method, similar to our sample in figure 8.5, and then build search functionality
    on the web UI to support both pipeline search and model search.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过使用管道关注法来实现元数据存储的存储层，类似于我们的图8.5示例，然后在Web UI上构建搜索功能，以支持管道搜索和模型搜索。
- en: 8.4 Open source solutions
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 开源解决方案
- en: In this section, we will discuss two widely used metadata management tools,
    MLMD and MLflow. Both systems are open source and free to use. We will first give
    an overview of each of the tools and then provide a comparison to determine which
    one to use and when.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论两个广泛使用的元数据管理工具：MLMD和MLflow。这两个系统都是开源的，并且免费使用。我们将首先概述每个工具，然后提供比较以确定何时使用哪个。
- en: 8.4.1 ML Metadata
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.1 ML元数据
- en: MLMD ([https://github.com/google/ml-metadata](https://github.com/google/ml-metadata))
    is a lightweight library for recording and retrieving metadata associated with
    ML developer and data scientist workflows. MLMD is an integral part of TensorFlow
    Extended (TFX; [https://www.tensorflow.org/tfx](https://www.tensorflow.org/tfx))
    but is designed so that it can be used independently. For example, Kubeflow ([https://www.kubeflow.org/](https://www.kubeflow.org/))
    uses MLMD to manage metadata produced by its pipeline and notebook service. For
    more details, see the Kubeflow metadata documentation ([http://mng.bz/Blo1](http://mng.bz/Blo1)).
    You can consider MLMD a logging library and use it to instrument metadata in each
    step of your ML pipeline, so you can understand and analyze all the interconnecting
    parts of your workflow/ pipeline.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: MLMD ([https://github.com/google/ml-metadata](https://github.com/google/ml-metadata))
    是一个轻量级的库，用于记录和检索与 ML 开发者和数据科学家工作流程相关的元数据。MLMD 是 TensorFlow Extended (TFX; [https://www.tensorflow.org/tfx](https://www.tensorflow.org/tfx))
    的一个组成部分，但设计得可以独立使用。例如，Kubeflow ([https://www.kubeflow.org/](https://www.kubeflow.org/))
    使用 MLMD 来管理其管道和笔记本服务产生的元数据。有关更多详细信息，请参阅 Kubeflow 元数据文档 ([http://mng.bz/Blo1](http://mng.bz/Blo1))。您可以将
    MLMD 视为一个日志库，并使用它来在每个步骤中记录元数据，这样您就可以理解和分析工作流程/管道的所有相互连接的部分。
- en: System overview
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 系统概述
- en: 'The metadata instrumentation with the MLMD library can be set up with two different
    backends: an SQL or gRPC server. See figure 8.6 for the concept.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 MLMD 库进行元数据记录可以设置两种不同的后端：SQL 或 gRPC 服务器。请参阅图 8.6 了解概念。
- en: '![](../Images/08-06.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08-06.png)'
- en: 'Figure 8.6 Two different setups for instrumenting metadata with MLMD: (A) directly
    report metadata to the backend database and (B) report metadata to the gRPC server
    DB, database.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 使用 MLMD 仪器化元数据的两种不同设置：（A）直接向后端数据库报告元数据；（B）向 gRPC 服务器 DB 报告元数据。
- en: In figure 8.6, we see that each step of an ML pipeline/workflow uses MLMD library
    (MLMD client API) to instrument metadata. On the backend, MLMD will save the metadata
    in a relational database, such as mySQL or PostgreSQL.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 8.6 中，我们看到 ML pipeline/workflow 的每个步骤都使用 MLMD 库（MLMD 客户端 API）来记录元数据。在后台，MLMD
    将元数据保存到关系数据库中，例如 mySQL 或 PostgreSQL。
- en: You can choose to let each MLMD library talk directly to an SQL server (figure
    8.5, A) or use the server setup code in the MLMD library to set up a gRPC server
    and let the client libraries talk to the server (figure 8.5, B). Approach A is
    simple; you don’t need to host a dedicated logging server, but approach B is recommended
    because it avoids exposing the backend database.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择让每个 MLMD 库直接与 SQL 服务器通信（图 8.5，A）或使用 MLMD 库中的服务器设置代码来设置一个 gRPC 服务器，并让客户端库与服务器通信（图
    8.5，B）。方法 A 很简单；您不需要托管专门的日志服务器，但方法 B 更推荐，因为它避免了暴露后端数据库。
- en: 'You can check out the following two docs for detailed metadata storage configuration:
    “Metadata Storage Backends and Store Connection Configuration” ([http://mng.bz/dJMo](http://mng.bz/dJMo))
    and “Use MLMD with a Remote gRPC Server” ([http://mng.bz/rd8J](http://mng.bz/rd8J)).'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看以下两个文档以获取详细的元数据存储配置信息：“元数据存储后端和存储连接配置” ([http://mng.bz/dJMo](http://mng.bz/dJMo))
    和 “使用远程 gRPC 服务器与 MLMD 配合使用” ([http://mng.bz/rd8J](http://mng.bz/rd8J))。
- en: Logging API
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 日志 API
- en: The metadata store in MLMD uses the following data structures to record metadata
    in the storage backend. An *execution* represents a component or a step in a workflow;
    an *artifact* describes an input or output object in an execution; and an *event*
    is a record of relationships between artifacts and executions. A *context* is
    a logic group that is used to correlate artifacts and executions together in the
    same workflow.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: MLMD 中的元数据存储使用以下数据结构在存储后端记录元数据。一个 *execution* 代表工作流程中的一个组件或步骤；一个 *artifact*
    描述执行中的输入或输出对象；一个 *event* 是工件和执行之间关系的记录。一个 *context* 是一个逻辑组，用于将工件和执行关联在一起，以在同一个工作流程中。
- en: 'With this concept in mind, let’s look at some sample metadata instrumentation
    code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个概念的基础上，让我们看看一些示例元数据记录代码：
- en: '[PRE0]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ A dataset is recorded as an artifact.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将数据集记录为工件。
- en: ❷ Saves the metadata to storage
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将元数据保存到存储中
- en: ❸ A model training run is recorded as an execution.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将模型训练运行记录为执行
- en: ❹ A model is recorded as an artifact.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将模型记录为工件。
- en: ❺ Defines the logic group for the metadata of model training
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 定义模型训练元数据的逻辑组
- en: ❻ Saves the relationship between metadata
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 保存元数据之间的关系
- en: Check out the MLMD “Get Started” doc ([http://mng.bz/VpWy](http://mng.bz/VpWy))
    for the detailed code sample and local setup instructions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 查看MLMD “入门”文档([http://mng.bz/VpWy](http://mng.bz/VpWy))以获取详细的代码示例和本地设置说明。
- en: Searching metadata
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索元数据
- en: 'MLMD doesn’t provide a UI to show the metadata it stores. So, for querying
    metadata, we need to use its client API. See the following code example:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: MLMD不提供用于显示其存储的元数据的UI。因此，为了查询元数据，我们需要使用其客户端API。请参阅以下代码示例：
- en: '[PRE1]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Queries all registered artifacts
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 查询所有已注册的工件
- en: ❷ Queries artifact by ID
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 通过ID查询工件
- en: ❸ Queries artifact by uri
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 通过uri查询工件
- en: ❹ Queries artifact by using a filter
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用过滤器查询工件
- en: The MLMD “Get Started” doc ([http://mng.bz/VpWy](http://mng.bz/VpWy)) provides
    lots of query examples for fetching metadata of artifacts, executions, and context.
    If you are interested, please take a look.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: MLMD “入门”文档([http://mng.bz/VpWy](http://mng.bz/VpWy))提供了大量查询示例，用于获取工件、执行和上下文的元数据。如果您感兴趣，请查看。
- en: 'The best way to learn the data model of MLMD is to look at its database schema.
    You can first create an SQLite database and configure the MLMD metadata store
    to use that database and then run the MLMD sample code. At the end, all the entities
    and tables are created in the local SQLite database. By looking at the table schema
    and content, you will gain a deep understanding of how the metadata is organized
    in MLMD, so you can build a nice UI on top of it yourself. The following sample
    code shows how to configure the MLMD metadata store to use a local SQLite database:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 了解MLMD数据模型的最佳方式是查看其数据库模式。您首先可以创建一个SQLite数据库，并配置MLMD元数据存储以使用该数据库，然后运行MLMD示例代码。最后，所有实体和表都将在本地SQLite数据库中创建。通过查看表模式和内容，您将深入了解MLMD中元数据的组织方式，因此您可以在此基础上自己构建一个不错的UI。以下示例代码显示了如何配置MLMD元数据存储以使用本地SQLite数据库：
- en: '[PRE2]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Local files path of the SQLite database
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ SQLite数据库的本地文件路径
- en: ❷ Allows read, write, and create
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 允许读取、写入和创建
- en: 8.4.2 MLflow
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.2 MLflow
- en: MLflow ([https://mlflow.org/docs/latest/tracking.html](https://mlflow.org/docs/latest/tracking.html))
    is an open source MLOps platform. It is designed to manage the ML lifecycle, including
    experimentation, reproducibility, deployment, and central model registry.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow([https://mlflow.org/docs/latest/tracking.html](https://mlflow.org/docs/latest/tracking.html))是一个开源的MLOps平台。它旨在管理ML生命周期，包括实验、可重现性、部署和中心模型注册。
- en: 'Compared to MLMD, MLflow is a whole system, not a library. It’s composed of
    four main components:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 与MLMD相比，MLflow是一个完整的系统，而不是一个库。它由四个主要组件组成：
- en: '*MLflow Tracking (a metadata tracking server*) —For recording and querying
    metadata'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLflow跟踪（一个元数据跟踪服务器）*——用于记录和查询元数据'
- en: '*MLflow Projects*—For packaging code in a reusable and reproducible way'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLflow项目*——以可重用和可重现的方式打包代码'
- en: '*MLflow Models*—For packaging ML models that can be used for different model
    serving tools'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLflow模型*——用于打包可用于不同模型服务工具的ML模型'
- en: '*MLflow Model Registry*—For managing the full life cycle of MLflow models with
    a UI, such as model lineage, model versioning, annotation, and production promotion'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLflow模型注册表*——通过UI管理MLflow模型的整个生命周期，例如模型血缘、版本控制、注释和产品推广'
- en: In this section, we focus on the tracking server, since that’s most relevant
    to metadata management.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们重点关注跟踪服务器，因为它与元数据管理最相关。
- en: System overview
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 系统概述
- en: MLflow provides six different setup approaches. For example, the metadata of
    MLflow runs (training pipeline) can be recorded to local files, an SQL database,
    a remote server, or a remote server with proxied storage backend access. For details
    about these six different setup methods, you can check out the MLflow doc “How
    Runs and Artifacts Are Recorded” ([https://mlflow.org/docs/latest/tracking.html#id27](https://mlflow.org/docs/latest/tracking.html#id27)).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow提供了六种不同的设置方法。例如，MLflow运行的元数据（训练流程）可以记录到本地文件、SQL数据库、远程服务器或带有代理存储后端访问的远程服务器。有关这六种不同设置方法的详细信息，您可以查看MLflow文档“如何记录运行和工件”([https://mlflow.org/docs/latest/tracking.html#id27](https://mlflow.org/docs/latest/tracking.html#id27))。
- en: 'In this section, we focus on the most commonly used setup approach: remote
    server with proxied artifact storage access. See figure 8.7 for the system overview
    diagram.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们重点关注最常用的设置方法：带有代理工件存储访问的远程服务器。请参见图8.7中的系统概述图。
- en: '![](../Images/08-07.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08-07.png)'
- en: Figure 8.7 Setting up MLflow tracker server for metadata ingestion and query
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 设置MLflow跟踪服务器以进行元数据摄取和查询
- en: From figure 8.7, we see that each step/action of a deep learning pipeline (workflow)
    uses the MLflow client to instrument metadata and artifact to the MLflow tracking
    server. The tracking server saves metadata, such as metrics, parameters, and tags,
    in a specified SQL database; artifacts, such as models, images, and documents,
    are saved in a configured object storage, such as Amazon S3.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 从图 8.7 中，我们可以看到深度学习管道（工作流程）的每个步骤/操作都使用 MLflow 客户端将元数据和工件仪器化到 MLflow 跟踪服务器。跟踪服务器将元数据，如指标、参数和标签，保存在指定的
    SQL 数据库中；模型、图像和文档等工件保存在配置的对象存储中，例如 Amazon S3。
- en: 'MLflow offers two ways to upload artifacts: (1) direct upload from the client
    and (2) proxy upload through the tracking server. In figure 8.6, we illustrated
    the latter method: utilizing the tracking server as a proxy server for any operations
    involving artifacts. The advantage is the end users can have a direct path to
    access the backend remote object store without providing access credentials.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 提供两种上传工件的方法：(1) 从客户端直接上传和(2) 通过跟踪服务器代理上传。在图 8.6 中，我们说明了后者方法：利用跟踪服务器作为涉及工件操作的代理服务器。优点是最终用户可以直接访问后端远程对象存储，而无需提供访问凭证。
- en: Another nice thing about MLflow is that it offers a nice UI; data scientists
    can check and search metadata thru the website hosted in the tracking server.
    The UI allows users not only to view metadata from a pipeline execution perspective
    but also to search and operate models directly.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 的另一个优点是它提供了一个很好的 UI；数据科学家可以通过跟踪服务器托管的网站检查和搜索元数据。该 UI 允许用户不仅从管道执行的角度查看元数据，还可以直接搜索和操作模型。
- en: Logging API
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 记录 API
- en: 'Sending metadata to the MLflow tracking server is straightforward. We can start
    by creating an active run as a context manager and then call the log function
    to log artifacts or a single key-value parameter, metric, and tag. See the sample
    code as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 将元数据发送到 MLflow 跟踪服务器很简单。我们可以从创建一个作为上下文管理器的活动运行开始，然后调用日志函数来记录工件或单个键值参数、指标和标签。以下是一个示例代码：
- en: '[PRE3]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Defines the MLflow server URL
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义 MLflow 服务器 URL
- en: ❷ Logs metadata in Python context manager made by the MLflow ActiveRun object
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用 MLflow ActiveRun 对象创建的 Python 上下文管理器记录元数据
- en: Automatic logging
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 自动记录
- en: If you are tired of specifying lots of metadata yourself, MLflow supports automatic
    logging. By calling `mlflow.autolog()` or a library-specific autolog function
    before your training code, such as `mlflow.tensorflow.autolog()`, `mlflow.keras.autolog()`,
    or `mlflow.pytorch.autolog()`, MLflow will log metadata, even artifacts, automatically
    without the need for an explicit log statement. If you want to learn more about
    MLflow logging, check out the MLflow logging functions doc ([http://mng.bz/xd1d](http://mng.bz/xd1d)).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你厌倦了自己指定大量元数据，MLflow 支持自动记录。通过在训练代码之前调用 `mlflow.autolog()` 或特定库的自动记录函数，例如
    `mlflow.tensorflow.autolog()`、`mlflow.keras.autolog()` 或 `mlflow.pytorch.autolog()`，MLflow
    将自动记录元数据，甚至工件，无需显式日志语句。如果你想了解更多关于 MLflow 记录的信息，请查看 MLflow 记录函数文档 ([http://mng.bz/xd1d](http://mng.bz/xd1d))。
- en: Searching metadata
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索元数据
- en: 'The tracking UI hosted by the MLflow tracking server lets you visualize, search,
    and compare runs, as well as download run artifacts or metadata for analysis in
    other tools. The UI contains the following key features: experiment-based run
    listing and comparison, searching for runs by parameter or metric value, visualizing
    run metrics, and downloading run results. Besides UI, you can also achieve all
    the operations provided in the tracking UI programmatically, as in the following
    examples:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 由 MLflow 跟踪服务器托管的跟踪 UI 允许你可视化、搜索和比较运行，以及下载运行工件或元数据以在其他工具中进行分析。该 UI 包含以下关键功能：基于实验的运行列表和比较、通过参数或指标值搜索运行、可视化运行指标和下载运行结果。除了
    UI 之外，你还可以像以下示例那样以编程方式实现跟踪 UI 提供的所有操作：
- en: '[PRE4]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Initializes client
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 初始化客户端
- en: ❷ Prints out the execution stages of a run
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 打印出运行的执行阶段
- en: The programmatic metadata access is not only helpful when using your analysis
    tool (for example, pandas) to query and compare the model performance of different
    training runs, but also for integrating models with your model serving system
    since it allows you to fetch models from the MLflow model registry programmatically.
    For full `MLflowClient` API usage, you can check out the MLflow Tracking API doc
    ([http://mng.bz/GRzO](http://mng.bz/GRzO)).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 程序化元数据访问不仅在使用您的分析工具（例如，pandas）查询和比较不同训练运行的模型性能时很有帮助，而且对于将模型与您的模型服务系统集成也很重要，因为它允许您通过程序从MLflow模型注册表中检索模型。有关完整的`MLflowClient`
    API使用，您可以查看MLflow跟踪API文档([http://mng.bz/GRzO](http://mng.bz/GRzO))。
- en: 8.4.3 MLflow vs. MLMD
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.4.3 MLflow与MLMD
- en: From the descriptions in the previous sections, we see that MLMD is more of
    a lightweight library while MLflow is an MLOps platform. Both tools can run independently,
    offer metadata ingestion and search functionality, and track metadata on the basis
    of model training runs. But MLflow offers much more.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 从前几节的描述中，我们可以看到MLMD更像是轻量级库，而MLflow是一个MLOps平台。这两个工具都可以独立运行，提供元数据摄取和搜索功能，并在模型训练运行的基础上跟踪元数据。但MLflow提供了更多功能。
- en: In addition to MLMD’s functionality, MLflow supports automatic metadata logging
    and a well-designed UI to visualize experiment metadata (including experiment
    comparison), model registry, artifact management, code reproducibility, model
    package, and more.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 除了MLMD的功能外，MLflow还支持自动元数据记录和精心设计的UI来可视化实验元数据（包括实验比较），模型注册，工件管理，代码可重复性，模型打包等。
- en: If you need to introduce a complete, new metadata and artifact store to your
    system, MFflow is your first choice. It’s supported by an active open source community,
    and it covers most of the user requirements of ML metadata management. As a bonus,
    MLflow has a great support on MLOps, such as MLflow project management and model
    deployment.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要将一个全新的元数据和工件存储引入到您的系统中，MFlow是您的首选。它由一个活跃的开源社区支持，并覆盖了大多数ML元数据管理用户需求。作为额外的好处，MLflow在MLOps方面有很好的支持，例如MLflow项目管理模型部署。
- en: If you already have an artifact registry and a metric visualization website
    and you want to integrate metadata functionality into your existing system, then
    MLMD is a good choice. MLMD is lightweight, easy to use, and simple to learn.
    For example, the Kubeflow ([https://www.kubeflow.org/](https://www.kubeflow.org/))
    deep learning platform integrates MLMD as the metadata tracking tool into its
    components, such as Kubeflow pipeline ([https://www.kubeflow.org/docs/components/pipelines/](https://www.kubeflow.org/docs/components/pipelines/)).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经有一个工件注册库和一个指标可视化网站，并且您想将元数据功能集成到现有的系统中，那么MLMD是一个不错的选择。MLMD轻量级、易于使用，易于学习。例如，Kubeflow([https://www.kubeflow.org/](https://www.kubeflow.org/))深度学习平台将MLMD作为元数据跟踪工具集成到其组件中，如Kubeflow管道([https://www.kubeflow.org/docs/components/pipelines/](https://www.kubeflow.org/docs/components/pipelines/))。
- en: Summary
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Machine learning metadata can be categorized into four buckets: model training
    runs, general artifacts, model artifacts, and pipelines.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习元数据可以分为四个类别：模型训练运行、通用工件、模型工件和管道。
- en: A metadata and artifact store is designed to support model performance comparison,
    troubleshooting, and reproducing.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据和工件存储旨在支持模型性能比较、故障排除和重现。
- en: A good metadata management system can help to show model lineage, enable model
    reproducibility, and facilitate model comparison.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个好的元数据管理系统可以帮助展示模型血缘关系，实现模型可重复性，并促进模型比较。
- en: MLMD is a lightweight metadata management tool, which originated from the TensorFlow
    pipeline, but it can be used independently. For example, Kubeflow uses MLMD to
    manage ML metadata in its pipeline component.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLMD是一个轻量级的元数据管理工具，起源于TensorFlow管道，但它可以独立使用。例如，Kubeflow使用MLMD来管理其管道组件中的ML元数据。
- en: MLMD is good for integrating metadata management into an existing system.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLMD非常适合将元数据管理集成到现有系统中。
- en: MLflow is an MLOps platform; it’s designed to manage the ML lifecycle, including
    experimentation, reproducibility, deployment, and a central model registry.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow是一个MLOps平台；它旨在管理机器学习生命周期，包括实验、可重复性、部署以及中央模型注册。
- en: MLflow is applicable if you want to introduce a completely independent metadata
    and artifact management system.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您想引入一个完全独立的元数据和工件管理系统，MLflow适用。
