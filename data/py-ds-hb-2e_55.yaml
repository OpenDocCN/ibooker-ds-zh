- en: 'Chapter 50\. Application: A Face Detection Pipeline'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第50章。应用：一个人脸检测流水线
- en: 'This part of the book has explored a number of the central concepts and algorithms
    of machine learning. But moving from these concepts to a real-world application
    can be a challenge. Real-world datasets are noisy and heterogeneous; they may
    have missing features, and data may be in a form that is difficult to map to a
    clean `[n_samples, n_features]` matrix. Before applying any of the methods discussed
    here, you must first extract these features from your data: there is no formula
    for how to do this that applies across all domains, and thus this is where you
    as a data scientist must exercise your own intuition and expertise.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的这一部分探讨了许多机器学习的中心概念和算法。但是从这些概念到真实世界的应用可能是一个挑战。真实世界的数据集通常是嘈杂和异构的；它们可能具有缺失的特征，并且数据可能以难以映射到干净的`[n_samples,
    n_features]`矩阵的形式存在。在应用这里讨论的任何方法之前，您必须首先从您的数据中提取这些特征：没有适用于所有领域的公式，因此这是您作为数据科学家必须运用自己的直觉和专业知识的地方。
- en: 'One interesting and compelling application of machine learning is to images,
    and we have already seen a few examples of this where pixel-level features are
    used for classification. Again, the real world data is rarely so uniform, and
    simple pixels will not be suitable: this has led to a large literature on *feature
    extraction* methods for image data (see [Chapter 40](ch40.xhtml#section-0504-feature-engineering)).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的一个有趣而引人注目的应用是图像，我们已经看到了一些例子，其中像素级特征用于分类。再次强调，现实世界的数据很少是如此统一的，简单的像素将不合适：这导致了大量关于*图像数据特征提取*方法的文献（参见[第40章](ch40.xhtml#section-0504-feature-engineering)）。
- en: 'In this chapter we will take a look at one such feature extraction technique:
    the [histogram of oriented gradients (HOG)](https://oreil.ly/eiJ4X), which transforms
    image pixels into a vector representation that is sensitive to broadly informative
    image features regardless of confounding factors like illumination. We will use
    these features to develop a simple face detection pipeline, using machine learning
    algorithms and concepts we’ve seen throughout this part of the book.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一种特征提取技术：[方向梯度直方图（HOG）](https://oreil.ly/eiJ4X)，它将图像像素转换为对广泛信息的敏感向量表示，而不受照明等混淆因素的影响。我们将使用这些特征来开发一个简单的人脸检测流水线，利用本书这部分中已经介绍过的机器学习算法和概念。
- en: 'We begin with the standard imports:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从标准导入开始：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: HOG Features
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HOG特征
- en: 'HOG is a straightforward feature extraction procedure that was developed in
    the context of identifying pedestrians within images. It involves the following
    steps:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: HOG是一个简单直接的特征提取过程，最初用于图像中行人的识别。它包括以下步骤：
- en: Optionally prenormalize the images. This leads to features that resist dependence
    on variations in illumination.
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选择地对图像进行预归一化。这导致特征对照明变化的依赖性较小。
- en: Convolve the image with two filters that are sensitive to horizontal and vertical
    brightness gradients. These capture edge, contour, and texture information.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像与两个对水平和垂直亮度梯度敏感的滤波器卷积。这些捕捉边缘、轮廓和纹理信息。
- en: Subdivide the image into cells of a predetermined size, and compute a histogram
    of the gradient orientations within each cell.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像细分为预定大小的单元格，并计算每个单元格内梯度方向的直方图。
- en: Normalize the histograms in each cell by comparing to the block of neighboring
    cells. This further suppresses the effect of illumination across the image.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过与相邻单元格块比较来归一化每个单元格中的直方图。这进一步抑制了整个图像中照明效果的影响。
- en: Construct a one-dimensional feature vector from the information in each cell.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从每个单元格中的信息构建一个一维特征向量。
- en: A fast HOG extractor is built into the Scikit-Image project, and we can try
    it out relatively quickly and visualize the oriented gradients within each cell
    (see [Figure 50-1](#fig_0514-image-features_files_in_output_4_0)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-Image项目中内置了一个快速的HOG特征提取器，我们可以相对快速地尝试并可视化每个单元格内的定向梯度（见[图50-1](#fig_0514-image-features_files_in_output_4_0)）。
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![output 4 0](assets/output_4_0.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![output 4 0](assets/output_4_0.png)'
- en: Figure 50-1\. Visualization of HOG features computed from an image
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图50-1。从图像计算的HOG特征的可视化
- en: 'HOG in Action: A Simple Face Detector'
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HOG在行动：一个简单的人脸检测器
- en: 'Using these HOG features, we can build up a simple facial detection algorithm
    with any Scikit-Learn estimator; here we will use a linear support vector machine
    (refer back to [Chapter 43](ch43.xhtml#section-0507-support-vector-machines) if
    you need a refresher on this). The steps are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 利用这些 HOG 特征，我们可以使用任何 Scikit-Learn 评估器构建一个简单的面部检测算法；在这里，我们将使用线性支持向量机（如果需要恢复记忆，请参阅
    [第43章](ch43.xhtml#section-0507-support-vector-machines)）。具体步骤如下：
- en: Obtain a set of image thumbnails of faces to constitute “positive” training
    samples.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获得一组人脸缩略图，作为“正”训练样本。
- en: Obtain a set of image thumbnails of non-faces to constitute “negative” training
    samples.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获得一组非面部图像缩略图，作为“负”训练样本。
- en: Extract HOG features from these training samples.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这些训练样本中提取 HOG 特征。
- en: Train a linear SVM classifier on these samples.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这些样本上训练线性 SVM 分类器。
- en: For an “unknown” image, pass a sliding window across the image, using the model
    to evaluate whether that window contains a face or not.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为“未知”图像，通过图像上的滑动窗口，使用模型评估该窗口是否包含面部。
- en: If detections overlap, combine them into a single window.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果检测重叠，将它们合并成一个单一窗口。
- en: Let’s go through these steps and try it out.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照这些步骤进行并尝试一下。
- en: 1\. Obtain a Set of Positive Training Samples
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 获得一组正训练样本
- en: 'We’ll start by finding some positive training samples that show a variety of
    faces. We have one easy set of data to work with—the Labeled Faces in the Wild
    dataset, which can be downloaded by Scikit-Learn:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从中找出一些显示各种面部的正训练样本。我们有一个易于使用的数据集——Wild 中的带标签面部数据集，可以通过 Scikit-Learn 下载：
- en: '[PRE2]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This gives us a sample of 13,000 face images to use for training.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了一些用于训练的 13,000 张面部图像样本。
- en: 2\. Obtain a Set of Negative Training Samples
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 获得一组负训练样本
- en: 'Next we need a set of similarly sized thumbnails that *do not* have a face
    in them. One way to obtain this is to take any corpus of input images, and extract
    thumbnails from them at a variety of scales. Here we’ll use some of the images
    shipped with Scikit-Image, along with Scikit-Learn’s `PatchExtractor`:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要一组大小相似的缩略图，其中*没有*面部。获得这些的一种方法是从任何输入图像语料库中提取它们的缩略图，以多种比例。在这里，我们将使用一些随着
    Scikit-Image 提供的图像以及 Scikit-Learn 的 `PatchExtractor`：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We now have 30,000 suitable image patches that do not contain faces. Let’s visualize
    a few of them to get an idea of what they look like (see [Figure 50-2](#fig_0514-image-features_files_in_output_14_0)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有 30,000 个合适的图像补丁，不包含面部。让我们可视化其中的一些，以了解它们的外观（见 [图50-2](#fig_0514-image-features_files_in_output_14_0)）。
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Our hope is that these will sufficiently cover the space of “non-faces” that
    our algorithm is likely to see.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望这些样本足以覆盖算法可能见到的“非面部”空间。
- en: '![output 14 0](assets/output_14_0.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![output 14 0](assets/output_14_0.png)'
- en: Figure 50-2\. Negative image patches, which don’t include faces
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图50-2\. 不包含面部的负图像补丁
- en: 3\. Combine Sets and Extract HOG Features
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 合并集合并提取 HOG 特征
- en: 'Now that we have these positive samples and negative samples, we can combine
    them and compute HOG features. This step takes a little while, because it involves
    a nontrivial computation for each image:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了这些正样本和负样本，我们可以将它们合并并计算 HOG 特征。这一步骤需要一些时间，因为它涉及到每个图像的非平凡计算：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We are left with 43,000 training samples in 1,215 dimensions, and we now have
    our data in a form that we can feed into Scikit-Learn!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们剩下 43,000 个训练样本，具有 1,215 个维度，现在我们已经将数据处理成了可以输入到 Scikit-Learn 的形式！
- en: 4\. Train a Support Vector Machine
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 训练支持向量机
- en: Next we use the tools we have been exploring here to create a classifier of
    thumbnail patches. For such a high-dimensional binary classification task, a linear
    support vector machine is a good choice. We will use Scikit-Learn’s `LinearSVC`,
    because in comparison to `SVC` it often has better scaling for a large number
    of samples.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将利用这里探索的工具创建缩略图补丁的分类器。对于这种高维二元分类任务，线性支持向量机是一个很好的选择。我们将使用 Scikit-Learn
    的 `LinearSVC`，因为与 `SVC` 相比，它通常对大量样本具有更好的扩展性。
- en: 'First, though, let’s use a simple Gaussian naive Bayes estimator to get a quick
    baseline:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 不过首先，让我们使用简单的高斯朴素贝叶斯估算器得到一个快速的基准：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We see that on our training data, even a simple naive Bayes algorithm gets
    us upwards of 95% accuracy. Let’s try the support vector machine, with a grid
    search over a few choices of the `C` parameter:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到在我们的训练数据上，即使是简单的朴素贝叶斯算法也可以达到 95% 以上的准确率。让我们尝试支持向量机，并对几种 `C` 参数进行网格搜索：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This pushes us up to near 99% accuracy. Let’s take the best estimator and retrain
    it on the full dataset:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使我们的准确率提高到接近 99%。让我们选择最佳的估计器，并在完整数据集上重新训练它：
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 5\. Find Faces in a New Image
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 在新图像中查找面部
- en: 'Now that we have this model in place, let’s grab a new image and see how the
    model does. We will use one portion of the astronaut image shown in [Figure 50-3](#fig_0514-image-features_files_in_output_28_0)
    for simplicity (see discussion of this in the following section, and run a sliding
    window over it and evaluate each patch:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了这个模型，让我们拿一幅新的图像来看看模型的表现。我们将简单地使用宇航员图像中的一部分，如 [图 50-3](#fig_0514-image-features_files_in_output_28_0)
    所示，运行一个滑动窗口，并评估每个补丁：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![output 28 0](assets/output_28_0.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![output 28 0](assets/output_28_0.png)'
- en: Figure 50-3\. An image in which we will attempt to locate a face
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 50-3\. 一幅我们将尝试定位面部的图像。
- en: 'Next, let’s create a window that iterates over patches of this image, and compute
    HOG features for each patch:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建一个窗口，迭代这幅图像的补丁，并为每个补丁计算 HOG 特征：
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, we can take these HOG-featured patches and use our model to evaluate
    whether each patch contains a face:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以取这些具有 HOG 特征的补丁，并使用我们的模型评估每个补丁是否包含面部：
- en: '[PRE15]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We see that out of nearly 2,000 patches, we have found 48 detections. Let’s
    use the information we have about these patches to show where they lie on our
    test image, drawing them as rectangles (see [Figure 50-4](#fig_0514-image-features_files_in_output_34_0)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到在将近 2,000 个补丁中，我们发现了 48 个检测结果。让我们利用这些补丁的信息来显示它们在我们的测试图像中的位置，将它们绘制成矩形（参见
    [图 50-4](#fig_0514-image-features_files_in_output_34_0)）。
- en: '[PRE16]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![output 34 0](assets/output_34_0.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![output 34 0](assets/output_34_0.png)'
- en: Figure 50-4\. Windows that were determined to contain a face
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 50-4\. 被确定包含面部的窗口。
- en: All of the detected patches overlap and found the face in the image! Not bad
    for a few lines of Python.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 所有检测到的补丁都重叠并找到了图像中的面部！对于几行 Python 代码来说效果不错。
- en: Caveats and Improvements
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注意事项和改进
- en: 'If you dig a bit deeper into the preceding code and examples, you’ll see that
    we still have a bit of work to do before we can claim a production-ready face
    detector. There are several issues with what we’ve done, and several improvements
    that could be made. In particular:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你深入研究前面的代码和示例，你会发现在我们宣称拥有一个可以投入生产的人脸检测器之前，我们还有一些工作要做。我们做的工作存在几个问题，也可以做出几个改进。特别是：
- en: Our training set, especially for negative features, is not very complete
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的训练集，特别是负面特征，不太完整。
- en: 'The central issue is that there are many face-like textures that are not in
    the training set, and so our current model is very prone to false positives. You
    can see this if you try out the algorithm on the *full* astronaut image: the current
    model leads to many false detections in other regions of the image.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 中心问题在于训练集中有许多像面部的纹理，而我们当前的模型非常容易产生假阳性。如果你尝试在*完整*的宇航员图像上运行算法，就会发现这一点：当前的模型在图像的其他区域导致了许多误检测。
- en: We might imagine addressing this by adding a wider variety of images to the
    negative training set, and this would probably yield some improvement. Another
    option would be to use a more directed approach, such as *hard negative mining*,
    where we take a new set of images that our classifier has not seen, find all the
    patches representing false positives, and explicitly add them as negative instances
    in the training set before retraining the classifier.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过向负训练集添加更多类型的图像来解决这个问题，这可能会带来一些改善。另一种选择是使用更有针对性的方法，如*硬负样本挖掘*，我们采用一组分类器尚未见过的新图像，找到所有表示假阳性的补丁，并明确将它们作为负实例添加到训练集中，然后重新训练分类器。
- en: Our current pipeline searches only at one scale
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当前的流水线仅在一个尺度上进行搜索。
- en: As currently written, our algorithm will miss faces that are not approximately
    62 × 47 pixels. This can be straightforwardly addressed by using sliding windows
    of a variety of sizes, and resizing each patch using `skimage.transform.resize`
    before feeding it into the model. In fact, the `sliding_window` utility used here
    is already built with this in mind.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 按照当前的写法，我们的算法会漏掉不是大约 62 × 47 像素的面部。可以通过使用各种大小的滑动窗口，并在将每个补丁输入模型之前使用`skimage.transform.resize`来直接解决这个问题。事实上，这里使用的`sliding_window`工具已经考虑到了这一点。
- en: We should combine overlapped detection patches
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该结合重叠的检测补丁。
- en: For a production-ready pipeline, we would prefer not to have 30 detections of
    the same face, but to somehow reduce overlapping groups of detections down to
    a single detection. This could be done via an unsupervised clustering approach
    (mean shift clustering is one good candidate for this), or via a procedural approach
    such as *non-maximum suppression*, an algorithm common in machine vision.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个可投入生产的流水线，我们更希望不要有30个相同人脸的检测结果，而是将重叠的检测组减少到一个单独的检测结果。这可以通过无监督的聚类方法（均值漂移聚类是一个很好的选择），或者通过类似于*非最大抑制*这样的程序化方法来实现，这是机器视觉中常见的一种算法。
- en: The pipeline should be streamlined
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线应该被简化
- en: 'Once we address the preceding issues, it would also be nice to create a more
    streamlined pipeline for ingesting training images and predicting sliding-window
    outputs. This is where Python as a data science tool really shines: with a bit
    of work, we could take our prototype code and package it with a well-designed
    object-oriented API that gives the user the ability to use it easily. I will leave
    this as a proverbial “exercise for the reader.”'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦解决了上述问题，创建一个更简化的流水线来输入训练图像并预测滑动窗口输出也将是一个不错的选择。这就是 Python 作为数据科学工具的优势所在：通过一点工作，我们可以将我们的原型代码打包成一个设计良好的面向对象的
    API，让用户能够轻松地使用它。我将把这留给读者作为一个“练习题”。
- en: 'More recent advances: deep learning'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 更近期的进展：深度学习
- en: 'Finally, I should add that in machine learning contexts, HOG and other procedural
    feature extraction methods are not always used. Instead, many modern object detection
    pipelines use variants of deep neural networks (often referred to as *deep learning*):
    one way to think of neural networks is as estimators that determine optimal feature
    extraction strategies from the data, rather than relying on the intuition of the
    user.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我应该补充说，在机器学习环境中，HOG 和其他程序化特征提取方法并不总是被使用。相反，许多现代目标检测流水线使用深度神经网络的变体（通常称为*深度学习*）：一个思考神经网络的方式是将其视为从数据中确定最佳特征提取策略的估计器，而不是依赖用户的直觉。
- en: 'Though the field has produced fantastic results in recent years, deep learning
    is not all that conceptually different from the machine learning models explored
    in the previous chapters. The main advance is the ability to utilize modern computing
    hardware (often large clusters of powerful machines) to train much more flexible
    models on much larger corpuses of training data. But though the scale differs,
    the end goal is very much the same the same: building models from data.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然近年来该领域取得了巨大的成果，但深度学习在概念上与前几章中探讨的机器学习模型并没有太大的不同。主要进步在于利用现代计算硬件（通常是大型强大机器集群）在更大的训练数据集上训练更加灵活的模型。但尽管规模不同，最终目标仍然是非常相似的：从数据中构建模型。
- en: If you’re interested in going further, the list of references in the following
    section should provide a useful place to start!
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对更深入的了解感兴趣，以下部分的参考文献清单应该是一个很好的起点！
- en: Further Machine Learning Resources
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多机器学习资源
- en: 'This part of the book has been a quick tour of machine learning in Python,
    primarily using the tools within the Scikit-Learn library. As long as these chapters
    are, they are still too short to cover many interesting and important algorithms,
    approaches, and discussions. Here I want to suggest some resources to learn more
    about machine learning in Python, for those who are interested:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的这一部分快速介绍了 Python 中的机器学习，主要使用了 Scikit-Learn 库中的工具。尽管这些章节很长，但仍然太短，无法涵盖许多有趣和重要的算法、方法和讨论。在这里，我想为那些有兴趣的人提供一些关于在
    Python 中学习更多关于机器学习的资源：
- en: '[The Scikit-Learn website](http://scikit-learn.org)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[Scikit-Learn 网站](http://scikit-learn.org)'
- en: The Scikit-Learn website has an impressive breadth of documentation and examples
    covering some of the models discussed here, and much, much more. If you want a
    brief survey of the most important and often-used machine learning algorithms,
    this is a good place to start.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-Learn 网站拥有令人印象深刻的文档和示例，涵盖了这里讨论的一些模型，以及更多内容。如果你想要简要了解最重要和经常使用的机器学习算法，这是一个很好的开始。
- en: '*SciPy, PyCon, and PyData tutorial videos*'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*SciPy、PyCon 和 PyData 教程视频*'
- en: Scikit-Learn and other machine learning topics are perennial favorites in the
    tutorial tracks of many Python-focused conference series, in particular the PyCon,
    SciPy, and PyData conferences. Most of these conferences publish videos of their
    keynotes, talks, and tutorials for free online, and you should be able to find
    these easily via a suitable web search (for example, “PyCon 2022 videos”).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[Scikit-Learn](https://oreil.ly/kaQQs)和其他机器学习主题是许多以Python为重点的会议系列（特别是PyCon、SciPy和PyData会议）教程轨道中的常青之选。这些会议大多免费在线发布其主题演讲、讨论和教程的视频，你可以通过合适的网络搜索轻松找到（例如，“PyCon
    2022 视频”）。'
- en: '[*Introduction to Machine Learning with Python*](https://oreil.ly/kaQQs), by
    Andreas C. Müller and Sarah Guido (O’Reilly)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 《[Python机器学习导论](https://oreil.ly/kaQQs)》，作者Andreas C. Müller和Sarah Guido（O’Reilly）
- en: This book covers many of the machine learning fundamentals discussed in these
    chapters, but is particularly relevant for its coverage of more advanced features
    of Scikit-Learn, including additional estimators, model validation approaches,
    and pipelining.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 本书涵盖了这些章节讨论的许多机器学习基础知识，但特别是在涵盖Scikit-Learn更高级特性方面更具相关性，包括额外的估算器、模型验证方法和管道化。
- en: '[*Machine Learning with PyTorch and Scikit-Learn*](https://oreil.ly/p268i),
    by Sebastian Raschka (Packt)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 《[使用PyTorch和Scikit-Learn的机器学习](https://oreil.ly/p268i)》，作者Sebastian Raschka（Packt）
- en: Sebastian Raschka’s most recent book starts with some of the fundamental topics
    covered in these chapters, but goes deeper and shows how those concepts apply
    to more sophisticated and computationally intensive deep learing and reinforcement
    learning models using the well-known [PyTorch library](https://pytorch.org).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Sebastian Raschka的最新书籍从这些章节覆盖的基础主题开始，但深入探讨，并展示了这些概念如何应用于更复杂和计算密集的深度学习和强化学习模型，使用知名的[PyTorch库](https://pytorch.org)。
