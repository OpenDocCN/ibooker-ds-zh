- en: Chapter 11\. Running Many Workflows Conveniently in Terra
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章. 在Terra中方便地运行多个工作流
- en: In [Chapter 10](ch10.xhtml#running_single_workflows_at_scale_with), we gave
    you a tantalizing first taste of the power of the Cromwell plus Pipelines API
    combination. You learned how to dispatch individual workflows to PAPI, both directly
    through Cromwell and indirectly through the WDL Runner wrapper. Both approaches
    enabled you to rapidly marshal arbitrary amounts of cloud compute resources without
    needing to administer them directly, which is probably the most important lesson
    you can take from this book. However, as we’ve discussed, both approaches suffer
    from limitations that would prevent you from achieving the truly great scalability
    that the cloud has to offer.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](ch10.xhtml#running_single_workflows_at_scale_with)中，我们给您带来了Cromwell加上Pipelines
    API组合强大能力的令人期待的第一印象。您学会了如何将单个工作流分派到PAPI，无论是通过Cromwell直接操作还是通过WDL Runner包装器间接操作。这两种方法都使您能够快速调度任意数量的云计算资源，而无需直接管理它们，这可能是您从本书中获得的最重要的教训。然而，正如我们讨论过的那样，这两种方法都存在限制，这些限制可能会阻止您实现云提供的真正强大的可扩展性。
- en: In this chapter, we show you how to use a fully featured Cromwell server within
    *Terra*, a cloud-based platform operated by the Broad Institute. We begin by introducing
    you to the platform and walking you through the basics of running workflows in
    Terra. Along the way, you’ll have the opportunity to experiment with the call
    caching feature that allows the Cromwell server to resume failed or interrupted
    workflows from the point of failure. With that experience in hand, you’ll graduate
    to finally running a full-scale GATK Best Practices pipeline on a whole genome
    dataset.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将向您展示如何在*Terra*中使用全功能的Cromwell服务器，这是由Broad Institute运营的基于云的平台。我们将从介绍平台开始，并引导您了解在Terra中运行工作流的基础知识。在此过程中，您将有机会尝试调用缓存功能，该功能允许Cromwell服务器从故障点恢复失败或中断的工作流。有了这些经验，您将毕业于在整个基因组数据集上运行完整的GATK最佳实践流水线。
- en: Getting Started with Terra
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用Terra
- en: You are just a few short hops away from experiencing the delights of a fully
    loaded Cromwell server thanks to [Terra](https://terra.bio), a scalable platform
    for biomedical research operated by the Broad Institute in collaboration with
    Verily. Terra is designed to provide researchers with a user-friendly yet flexible
    environment for doing secure and scalable analysis in GCP. Under the hood, Terra
    includes a persistent Cromwell server configured to dispatch workflows to PAPI
    and equipped with a dedicated call caching database. On the surface, it provides
    a point-and-click interface for running and monitoring workflows as well as API
    access for those who prefer to interact with the system programmatically. Terra
    also provides rich functionality for accessing and managing data, performing interactive
    analysis through Jupyter Notebook, and collaborating securely through robust permissions
    controls. [Figure 11-1](#overview_of_the_terra_platformdot) summarizes Terra’s
    current primary capabilities.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你离体验充满乐趣的全功能Cromwell服务器仅有几步之遥，多亏了[Terra](https://terra.bio)，这是由Broad Institute与Verily合作运营的生物医学研究可扩展平台。Terra旨在为研究人员提供用户友好而灵活的环境，用于在GCP中进行安全和可扩展的分析。在幕后，Terra包括一个持久的Cromwell服务器，配置以将工作流分派到PAPI，并配备有专用的调用缓存数据库。在表面上，它提供了一个点-and-click界面，用于运行和监控工作流，以及为那些喜欢通过API与系统进行编程交互的用户。Terra还提供了丰富的功能，用于访问和管理数据，通过Jupyter
    Notebook进行交互式分析，并通过强大的权限控制安全地进行协作。[图11-1](#overview_of_the_terra_platformdot)总结了Terra当前的主要功能。
- en: '![Overview of the Terra platform.](Images/gitc_1101.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![Terra平台概览。](Images/gitc_1101.png)'
- en: Figure 11-1\. Overview of the Terra platform.
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-1. Terra平台概览。
- en: In this section, we focus on the workflow configuration, execution, and monitoring
    functionality through the web interface, but later in the chapter, we also dig
    into some interactive analysis in Jupyter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们关注通过Web界面进行的工作流配置、执行和监控功能，但在本章后面，我们还将深入探讨在Jupyter中进行的一些交互式分析。
- en: Note
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: As of this writing, the Terra platform is under active development, so you likely
    will encounter differences between the screenshots here and the live web interface,
    as well as new features and behaviors. We’ll provide updated instructions and
    guidance regarding any major changes in [the blog for this book](https://oreil.ly/genomics-blog).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们撰写本书时，Terra平台正在积极开发中，因此您可能会在此处的截图和实际Web界面中遇到差异，以及新的功能和行为。关于任何重大变更，我们将在[本书的博客](https://oreil.ly/genomics-blog)中提供更新的说明和指导。
- en: Creating an Account
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建账户
- en: You can register for a [Terra account for free](https://app.terra.bio). In the
    upper-left corner of your browser window, click the three-line symbol to expand
    the side menu and bring up the Sign in with Google button, as shown in [Figure 11-2](#expanded_side_menu_showing_sign_in_butt).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以免费注册[Terra 账户](https://app.terra.bio)。在浏览器窗口左上角，点击三条线符号以展开侧边菜单，并显示出使用 Google
    登录按钮，如[图 11-2](#expanded_side_menu_showing_sign_in_butt)所示。
- en: '![Expanded side menu showing sign-in button.](Images/gitc_1102.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![展开的侧边菜单显示登录按钮。](Images/gitc_1102.png)'
- en: Figure 11-2\. Expanded side menu showing sign-in button.
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-2\. 展开的侧边菜单显示登录按钮。
- en: Note
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Menu symbols and navigation patterns in Terra are often similar to those in
    the GCP console. Whenever you see the same symbols, you can safely assume they
    have the same purpose.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Terra 中的菜单符号和导航模式通常与 GCP 控制台相似。每当看到相同的符号时，您可以安全地假设它们具有相同的功能。
- en: Sign in with the same account that you have been using so far—the one you used
    to set up your GCP account, and submit the registration form shown in [Figure 11-3](#the_new_user_registration_formdot).
    The contact email can be different from the email you used to sign in; for example,
    if you are using a personal account to do the work but prefer to get email notifications
    sent to your work account. Email notifications you might receive from Terra mainly
    consist of notices about new feature releases and service status (such as planned
    maintenance or incident alerts). They are relatively infrequent, and you can opt
    out if you do not want to receive these notifications. The contact email you specify
    here is also used by the Terra helpdesk ticketing system, which will email you
    if you ask a question, report a bug, or suggest a feature.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用您迄今为止使用的同一帐户——您用来设置 Google Cloud 平台帐户的帐户，并提交所示的注册表单，参见[图 11-3](#the_new_user_registration_formdot)。联系电子邮件地址可以与您登录时使用的电子邮件地址不同；例如，如果您使用个人账户进行工作但希望将电子邮件通知发送到工作账户。来自
    Terra 的电子邮件通知主要包括有关新功能发布和服务状态（例如计划维护或事件警报）的通知。它们相对不频繁，如果您不希望收到这些通知，您可以选择退出。您在此处指定的联系电子邮件地址还将被
    Terra 帮助台票务系统使用，如果您提出问题、报告错误或建议功能，系统将通过电子邮件与您联系。
- en: '![The New User Registration form.](Images/gitc_1103.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![新用户注册表单。](Images/gitc_1103.png)'
- en: Figure 11-3\. The New User Registration form.
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-3\. 新用户注册表单。
- en: You’ll need to accept the Terra Terms of Service. We strongly suggest that you
    follow the recommendation to secure your Google-linked account with two-factor
    authentication. Keep in mind that Terra is designed primarily to enable analysis
    of human patient data and includes repositories that host data funded by US government
    agencies with access restrictions, so security is a serious matter on the platform.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要接受 Terra 服务条款。我们强烈建议您按照建议，使用两步验证来保护您的 Google 关联账户。请记住，Terra 的主要设计目的是支持人类患者数据分析，并包括承载由美国政府资助的数据的仓库，因此平台的安全性问题非常重要。
- en: Creating a Billing Project
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建计费项目
- en: After you have completed the registration process, you should find yourself
    on the Terra portal landing page. At the top of the page, you might see a banner
    advertising free credits, as shown in [Figure 11-4](#the_banner_that_you_might_seecomma_adve).
    As of this writing, you can get $300 worth of free credits to try out the platform
    (on top of the credits you might already be getting directly from GCP), as described
    in the [Terra user guide](https://oreil.ly/RQQun). Terra is built on top of GCP,
    and when you do work in Terra that incurs costs, GCP directly bills your account.
    The Broad Institute will not charge you any surcharges for the use of the platform.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 完成注册过程后，您应该会进入 Terra 门户的登陆页面。页面顶部可能会显示一个广告免费积分的横幅，如[图 11-4](#the_banner_that_you_might_seecomma_adve)所示。截至撰写本文时，您可以获得价值
    300 美元的免费积分来试用平台（此外，您可能已经直接从 GCP 获得了积分），详细信息请参阅[Terra 用户指南](https://oreil.ly/RQQun)。Terra
    是基于 GCP 构建的，当您在 Terra 上进行需要付费的工作时，GCP 将直接向您的账户计费。Broad Institute 不会为使用平台收取任何额外费用。
- en: '![The banner that you might see, advertising free credits.](Images/gitc_1104.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![您可能看到的广告免费积分横幅。](Images/gitc_1104.png)'
- en: Figure 11-4\. The banner that you might see, advertising free credits.
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-4\. 您可能看到的广告免费积分横幅。
- en: 'We recommend that you take advantage of the free credits opportunity, not only
    for the credits themselves, but also because the system will automatically set
    up a billing project that you can immediately use in Terra. This is the fastest
    way to get started using Terra; just click “Start trial,” accept the Terms of
    Service (don’t use the free credits to mine bitcoin!), and you’re off to the races.
    If you check the [Billing page](https://app.terra.bio/#billing), you should see
    a new billing project with a name following this pattern: `fccredits-*chemical
    element*-*color*-*number*`.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议您利用免费信用额度的机会，不仅仅是为了信用额度本身，而且因为系统将自动设置一个计费项目，您可以立即在 Terra 中使用。这是开始使用 Terra
    的最快方式；只需点击“开始试用”，接受服务条款（不要用免费信用挖比特币！），然后您就可以开始了。如果您查看[计费页面](https://app.terra.bio/#billing)，您应该会看到一个新的计费项目，其名称遵循这种模式：`fccredits-*化学元素*-*颜色*-*数字*`。
- en: If you do not see the banner or you don’t want to activate the free trial right
    away, you’ll need to go to the [Billing page](https://oreil.ly/WYZyl) (accessible
    from the side menu where you signed in) to set up a billing account. You can connect
    the billing account that you have been using so far by clicking the blue plus
    symbol and following the instructions that pop up. See the accompanying sidebar
    for a detailed walkthrough of the process for connecting an existing billing account
    to use in Terra.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有看到横幅或者不想立即激活免费试用，您需要访问[计费页面](https://oreil.ly/WYZyl)（可从您登录的侧边菜单访问），设置一个计费账户。您可以通过点击蓝色加号符号并按照弹出的说明进行操作，连接到迄今为止使用的计费账户。请查看附带的侧边栏，详细了解连接现有计费账户以在
    Terra 中使用的流程。
- en: After you have your billing project set up, all you need to go run some workflows
    is a workspace. In [Chapter 13](ch13.xhtml#assembling_your_own_workspace_in_terra),
    we show you how to create your own workspaces from scratch, but for now, you’re
    simply going to clone a workspace that we set up for you with all the essentials.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好计费项目之后，您只需一个工作空间即可运行一些工作流程。在[第 13 章](ch13.xhtml#assembling_your_own_workspace_in_terra)中，我们将向您展示如何从头开始创建自己的工作空间，但目前，您只需克隆我们为您设置的具备所有基本要素的工作空间即可。
- en: Cloning the Preconfigured Workspace
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 克隆预配置工作空间
- en: You can find the Genomics-in-the-Cloud-v1 workspace in the [Library Showcase](https://oreil.ly/RdqSW)
    (which is accessible from the expandable menu on the left) or go straight to [this
    link](https://oreil.ly/n7oOr). The landing page, or Dashboard, provides information
    about its purpose and contents. Take a minute to read the summary description
    if you’d like, and then we’ll get to work.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[图书馆展示](https://oreil.ly/RdqSW)中找到基因组云-v1工作空间（可从左侧可展开菜单访问），或直接访问[此链接](https://oreil.ly/n7oOr)。着陆页或仪表板会提供有关其目的和内容的信息。如果您愿意，可以花一分钟阅读摘要描述，然后我们就开始工作。
- en: This workspace is read-only, so the first thing you need to do is to create
    a clone that will belong to you and that you can therefore work with. To do so,
    in the upper-right corner of your browser, click the round symbol with three dots
    to expand the action menu. Select Clone, as shown in [Figure 11-8](#cloning_the_preconfigured_workspacedot),
    to bring up the workspace cloning form.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此工作空间是只读的，因此您需要做的第一件事是创建一个属于您的克隆副本，因此您可以进行操作。为此，在浏览器右上角点击带有三个点的圆形符号以展开操作菜单。选择克隆，如[图
    11-8](#cloning_the_preconfigured_workspacedot)所示，以打开工作空间克隆表单。
- en: '![Cloning the preconfigured workspace. A) List of available actions; B) cloning
    form.](Images/gitc_1108.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![克隆预配置工作空间。A) 可用操作列表；B) 克隆表单。](Images/gitc_1108.png)'
- en: Figure 11-8\. Cloning the preconfigured workspace. A) List of available actions;
    B) cloning form.
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-8\. 克隆预配置工作空间。A) 可用操作列表；B) 克隆表单。
- en: Select your billing project; that will determine the account GCP will bill when
    you do work that incurs costs. You can change the workspace name or leave it as
    is; workspace names must be unique within a billing project but do not need to
    be unique across all of Terra. Ignore the Authorization domain bit for now; that’s
    an optional whitelisting option that you don’t need at this time.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 选择您的计费项目；这将确定 Google Cloud Platform 在您进行产生费用的工作时要计费的账户。您可以更改工作空间名称或保留原样；工作空间名称必须在计费项目内是唯一的，但不需要在
    Terra 的所有空间中唯一。目前忽略授权域位；这是一个您当前不需要的可选白名单选项。
- en: When you click the Clone Workspace button, you’re automatically taken to your
    new workspace. Take a good look around; everything that the light touches belongs
    to you. There’s a lot there, huh? Actually, you know what, don’t spend too much
    time looking around. Let’s keep a tight focus on our goal, which is to get you
    running workflows through Terra’s Cromwell server.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当您单击克隆工作空间按钮时，系统会自动将您带到新的工作空间。好好看看周围吧；光及之处皆为您所有。有很多东西，对吧？实际上，你知道吗，不要花太多时间四处看。让我们紧紧地专注于我们的目标，那就是通过Terra的Cromwell服务器使您能够运行工作流。
- en: Running Workflows with the Cromwell Server in Terra
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Terra中使用Cromwell服务器运行工作流
- en: Alright, it’s showtime. Head on over to the Workflows section of the workspace,
    where you should see a list of available workflow configurations, as shown in
    [Figure 11-9](#list_of_available_workflow_configuratio).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，现在开始表演时间。前往工作空间的工作流部分，您会看到可用工作流配置列表，如图 11-9所示（#list_of_available_workflow_configuratio)。
- en: '![List of available workflow configurations.](Images/gitc_1109.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![可用工作流配置列表。](Images/gitc_1109.png)'
- en: Figure 11-9\. List of available workflow configurations.
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-9\. 可用工作流配置列表。
- en: These are two configurations for the same workflow, which you might recognize
    from the first part of their names, *scatter-hc.* That’s right, it’s your favorite
    parallelized *HaplotypeCaller* workflow. In case you’re wondering, the key difference
    between these two configurations is that one is designed to run on a single input
    sample, whereas the other can run on any arbitrary number of input samples. That
    sounds exciting, right? Right. But let’s focus on the simple case first.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是同一个工作流的两个配置，您可能会从它们的名称的前半部分认出它们，*scatter-hc.* 是的，这就是您最喜欢的并行化*HaplotypeCaller*工作流。如果您好奇，这两个配置之间的关键区别在于一个设计用于单个输入样本的运行，而另一个可以运行任意数量的输入样本。听起来很令人兴奋，对吧？没错。但首先让我们专注于简单的情况。
- en: Running a Workflow on a Single Sample
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在单个样本上运行工作流
- en: On the page that lists the workflow configurations, click the one called *scatter-hc.filepaths*
    to open the configuration page. [Figure 11-10](#viewing_the_workflow_information_summar)
    shows the summary information, including a one-line synopsis and short description.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在列出工作流配置的页面上，单击名为*scatter-hc.filepaths*的配置，以打开配置页面。图 11-10所示（#viewing_the_workflow_information_summar)显示了摘要信息，包括一行简要说明和短描述。
- en: '![Viewing the workflow information summary.](Images/gitc_1110.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![查看工作流信息摘要。](Images/gitc_1110.png)'
- en: Figure 11-10\. Viewing the workflow information summary.
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-10\. 查看工作流信息摘要。
- en: In addition, the summary links to the Source of the workflow. If you follow
    that link, it will take you to the Broad Institute’s [Methods Repository](https://oreil.ly/xBXrU),
    an internal repository of workflows. Terra can also import workflows from [Dockstore](https://dockstore.org),
    as you’ll see in [Chapter 13](ch13.xhtml#assembling_your_own_workspace_in_terra),
    but for this exercise, we chose to use the internal repository, which is a little
    easier to work with on first approach.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，摘要链接到工作流的源。如果您点击该链接，将跳转到Broad Institute的[方法库](https://oreil.ly/xBXrU)，这是一个工作流的内部存储库。Terra还可以从[Dockstore](https://dockstore.org)导入工作流，正如您将在[第13章](ch13.xhtml#assembling_your_own_workspace_in_terra)中看到的那样，但在本练习中，我们选择使用内部存储库，这在初次接触时更加方便。
- en: Back on the *scatter-hc.filepaths* configuration page, have a look at the SCRIPT
    tab, which displays the actual workflow code. Sure enough, it’s the same workflow
    that we’ve been using for a while.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 回到*scatter-hc.filepaths*配置页面，查看SCRIPT选项卡，显示实际的工作流代码。毫无疑问，这正是我们一直在使用的同一工作流。
- en: 'As shown in [Figure 11-11](#viewing_the_workflow_scriptdot), the code display
    uses *syntax highlighting*: it colors parts of the code based on the syntax of
    the WDL language. It’s not possible to edit the code in this window, but the aforementioned
    Methods Repository includes a code editor (also with syntax highlighting), which
    can be quite convenient for making small tweaks without too much hassle.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 11-11所示（#viewing_the_workflow_scriptdot），代码显示使用*语法高亮*：根据WDL语言的语法对代码进行着色。在此窗口中无法编辑代码，但上述方法库包含一个代码编辑器（也带有语法高亮），可以在不太麻烦的情况下方便地进行小调整。
- en: '![Viewing the workflow script.](Images/gitc_1111.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![查看工作流脚本。](Images/gitc_1111.png)'
- en: Figure 11-11\. Viewing the workflow script.
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-11\. 查看工作流脚本。
- en: So now you know for sure which workflow you’re going to be running, but where
    do you plug in the inputs? When you ran this workflow from the command line, you
    handed Cromwell a JSON file of inputs along with the WDL file. You can see the
    functional equivalent here on the Inputs tab, which is shown in part in [Figure 11-12](#viewing_the_workflow_inputsdot).
    For each input variable, you can see the Task name in the leftmost column and
    then the name of the Variable as it is defined in the workflow script as well
    as its Type. Finally, the rightmost column contains the Attribute, or value, that
    we are giving to each variable.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您确定要运行哪个工作流程了，但是输入应该放在哪里呢？当您从命令行运行此工作流程时，您会将一个JSON文件的输入与WDL文件一起交给Cromwell。您可以在此处的输入选项卡中看到功能上等效的部分，如[图11-12](#viewing_the_workflow_inputsdot)所示。对于每个输入变量，您可以在最左侧列中看到任务名称，然后是在工作流脚本中定义的变量名称及其类型。最后，最右侧列包含我们为每个变量提供的属性或值。
- en: '![Viewing the workflow inputs.](Images/gitc_1112.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![查看工作流输入。](Images/gitc_1112.png)'
- en: Figure 11-12\. Viewing the workflow inputs.
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-12\. 查看工作流输入。
- en: 'We’ve prefilled the configuration form for you, so you don’t need to edit anything,
    but please do take a moment to look at how the input values are specified. Especially
    for the File variables: we’ve provided the full paths to the locations of the
    files in GCS. This is truly an exact transcription of the contents of the JSON
    file of inputs. In fact, as you’ll learn in more detail in [Chapter 12](ch12.xhtml#interactive_analysis_in_jupyter_noteboo),
    all we had to do to set this up was to upload the JSON file to populate the contents
    of the form.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已为您预填写了配置表单，因此您无需编辑任何内容，但请花点时间查看如何指定输入值。特别是对于文件变量：我们已提供了文件在GCS中位置的完整路径。这实际上是输入JSON文件内容的真实转录。事实上，正如您将在[第12章](ch12.xhtml#interactive_analysis_in_jupyter_noteboo)中详细了解的那样，为了设置这一切，我们只需上传JSON文件即可填充表单内容。
- en: So are you ready to click that big blue Run Analysis button? Go for it; you’ve
    earned it. A small window will pop up asking for confirmation, as shown in [Figure 11-13](#the_workflow_launch_dialogdot).
    Press the blue Launch button and sit back while Terra processes your workflow
    submission.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，您准备好点击那个大蓝色的“运行分析”按钮了吗？去吧；您应得的。一个小窗口将弹出，询问是否确认，如[图11-13](#the_workflow_launch_dialogdot)所示。按下蓝色的“启动”按钮，然后坐下来，Terra会处理您的工作流程提交。
- en: '![The workflow launch dialog.](Images/gitc_1113.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![工作流启动对话框。](Images/gitc_1113.png)'
- en: Figure 11-13\. The workflow launch dialog.
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-13\. 工作流启动对话框。
- en: Under the hood, the system sends the built-in Cromwell server a packet of information
    containing the workflow code and inputs. As usual, Cromwell parses the workflow
    and starts dispatching individual jobs to PAPI for execution on the Google Compute
    Engine (GCE), as illustrated in [Figure 11-14](#overview_of_workflow_submission_in_terr).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，系统向内置的Cromwell服务器发送了一个信息包，其中包含工作流代码和输入。像往常一样，Cromwell解析工作流并开始将单个作业分派给PAPI，在Google
    Compute Engine（GCE）上执行，如[图11-14](#overview_of_workflow_submission_in_terr)所示。
- en: '![Overview of workflow submission in Terra.](Images/gitc_1114.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![Terra中工作流提交的概览。](Images/gitc_1114.png)'
- en: Figure 11-14\. Overview of workflow submission in Terra.
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-14\. Terra中工作流提交的概览。
- en: Meanwhile, Terra will take you to the Job History section of the workspace,
    where you can monitor execution and look up the status of any past submissions—after
    you’ve had a chance to run some, that is. Speaking of which, there will be more
    to look at here when the workflow you just submitted is further along, so let’s
    move on and plan to circle back to the Job History later in the chapter.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，Terra将带您进入工作空间的作业历史部分，您可以在那里监控执行并查看任何过去提交的状态——当然，前提是您有机会运行一些作业。说到这一点，当您刚刚提交的工作流程进展更进一步时，这里会有更多内容可供查看，因此让我们继续规划，稍后在本章节中再回顾作业历史。
- en: At this point, assuming everything went fine, you’ve essentially just replicated
    your earlier achievements of running the scattered *HaplotypeCaller* workflow,
    through PAPI, on a single sample. That’s nice, but wasn’t the point that we wanted
    to be able to run workflows on multiple samples at the same time? Why, yes; yes,
    it was. That’s where the second configuration comes in.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 到了这一步，假设一切顺利，您实际上只是通过PAPI在单个样本上重新运行了分散的*HaplotypeCaller*工作流程的先前成就。这很好，但我们的目的不是要能够同时在多个样本上运行工作流吗？是的，确实是。这就是第二个配置发挥作用的地方。
- en: Running a Workflow on Multiple Samples in a Data Table
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在数据表中运行多个样本的工作流程
- en: Let’s go take a look at that other configuration—the one called *scatter-hc.data-table*.
    As a reminder, you need to navigate to the Workflows pane and then click the configuration.
    You’ll see mostly the same thing as with the previous one (and the Source link
    is exactly the same), but if you look closely, there is one important difference.
    As shown in [Figure 11-15](#the_second_workflow_is_set_to_run_on_ro), this configuration
    is set up to “Run workflow(s) with inputs defined by data table,” whereas the
    *.filepaths* configuration was set to “Run workflow with inputs defined by file
    paths” and specified the *book_sample* table as the source of data, as shown in
    [Figure 11-10](#viewing_the_workflow_information_summar).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看另一个配置——名为*scatter-hc.data-table*的配置。作为提醒，您需要导航到工作流面板，然后点击该配置。您会看到与上一个配置大致相同的内容（并且源链接完全相同），但是如果您仔细观察，会发现一个重要的区别。如[图 11-15](#the_second_workflow_is_set_to_run_on_ro)所示，该配置被设置为“使用数据表定义的输入运行工作流程”，而*.filepaths*配置被设置为“使用文件路径定义的输入运行工作流程”，并指定*book_sample*表作为数据来源，如[图 11-10](#viewing_the_workflow_information_summar)所示。
- en: '![The second workflow is set to run on rows in a data table.](Images/gitc_1115.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![第二个工作流程设置为在数据表中的行上运行。](Images/gitc_1115.png)'
- en: Figure 11-15\. The second workflow is set to run on rows in a data table.
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-15\. 第二个工作流程设置为在数据表中的行上运行。
- en: 'Now take a closer look at how the inputs are defined on the Inputs tab. Do
    you see anything unfamiliar? For most of the variables, the straightforward values
    (like the Docker address and the file paths) have been replaced by what looks
    like more variables: either `workspace.*` or `this.*`, as shown in [Figure 11-16](#the_workflow_input_configuration_refere).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在仔细看看输入选项卡上如何定义的输入。您有看到任何不熟悉的内容吗？对于大多数变量，直接的值（如Docker地址和文件路径）被看起来更像是变量的东西替换了：要么是`workspace.*`，要么是`this.*`，如[图 11-16](#the_workflow_input_configuration_refere)所示。
- en: '![The workflow input configuration references data tables.](Images/gitc_1116.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![工作流输入配置引用数据表。](Images/gitc_1116.png)'
- en: Figure 11-16\. The workflow input configuration references data tables.
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-16\. 工作流输入配置引用数据表。
- en: And that’s exactly what those are, references to values that are defined somewhere
    else. Specifically, they point to values that are stored in metadata tables in
    the Data section of the workspace. Let’s head over there now and see if we can
    shed some light on how this all works.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是这些值的确切内容，它们是对某处定义的值的引用。具体而言，它们指向存储在工作空间数据部分元数据表中的值。让我们现在过去看看，看看是否能解释这一切是如何运作的。
- en: In the Data section, you’ll find a menu of data resources that should look something
    like [Figure 11-17](#viewing_the_menu_of_data_tables_on_the). Within that menu,
    you should see a table called *book_sample* and another one called *Workspace
    Data*. We’re going to start with the *Workspace Data* table, on the assumption
    that it’s the least complicated to understand.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据部分，您将找到一个数据资源菜单，应该看起来类似于[图 11-17](#viewing_the_menu_of_data_tables_on_the)。在该菜单中，您应该会看到一个名为*book_sample*和另一个名为*Workspace
    Data*的表。我们将从*Workspace Data*表开始，假设这是最容易理解的表。
- en: '![Viewing the menu of data tables on the DATA tab.](Images/gitc_1117.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![在DATA选项卡上查看数据表菜单。](Images/gitc_1117.png)'
- en: Figure 11-17\. Viewing the menu of data tables on the DATA tab.
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-17\. 在DATA选项卡上查看数据表菜单。
- en: Click Workspace Data to view the contents of that table, which are shown in
    [Figure 11-18](#the_workspace_data_tabledot). As you can see, this is a fairly
    simple list of key:value pairs; for example, the key *gatk_docker* is associated
    with the value `us.gcr.io/broad-gatk/gatk:4.1.3.0`. Meanwhile, behind the scenes,
    this *Workspace Data* table is called *workspace*. As a result, we can use the
    expression `workspace.gatk_docker` in the workflow inputs form, as shown in [Figure 11-16](#the_workflow_input_configuration_refere),
    to refer to the value `us.gcr.io/broad-gatk/gatk:4.1.3.0`, which is stored under
    the *gatk_docker* key in the *workspace* table.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 点击Workspace Data查看该表的内容，如[图 11-18](#the_workspace_data_tabledot)所示。正如您所见，这是一个相当简单的键值对列表；例如，键*gatk_docker*与值`us.gcr.io/broad-gatk/gatk:4.1.3.0`相关联。与此同时，在幕后，这个*Workspace
    Data*表被称为*workspace*。因此，我们可以在工作流输入表单中使用表达式`workspace.gatk_docker`，如[图 11-16](#the_workflow_input_configuration_refere)所示，以引用存储在*workspace*表的*gatk_docker*键下的值`us.gcr.io/broad-gatk/gatk:4.1.3.0`。
- en: '![The Workspace Data table. ](Images/gitc_1118.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![Workspace Data表。](Images/gitc_1118.png)'
- en: Figure 11-18\. The Workspace Data table.
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-18\. Workspace Data表。
- en: 'So the *workspace* keys are essentially serving as a kind of global variable
    that you can use in multiple configurations within the same workspace. This is
    very convenient if you want to update the version of the GATK Docker image in
    all of your configurations with minimum hassle: just update the key’s value in
    the *Workspace Data* table and you’re all set.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，*workspace*键本质上充当了你可以在同一工作区内多个配置中使用的全局变量。如果你想要轻松更新所有配置中GATK Docker镜像版本的话，这非常方便：只需更新*Workspace
    Data*表中键的值，就万事大吉了。
- en: The same benefit applies to the resource files that are typically used in multiple
    workflows across a project, such as the reference genome files or the interval
    lists. Considering how awkward it can be to wrangle those long *gs://* file paths,
    it’s a real blessing to be able to define them just once and then simply refer
    to them with short pointers everywhere else. The filenames shown in blue and underlined
    are full file paths to locations in GCS, even though the system shows only the
    filename.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的好处也适用于资源文件，这些文件通常在项目中的多个工作流中使用，比如参考基因组文件或区间列表。考虑到长长的*gs://*文件路径可能有多麻烦，只需定义一次然后在其他地方简单地用短指针引用它们，这真是一大福音。蓝色并带下划线显示的文件名是GCS中位置的完整文件路径，尽管系统只显示文件名。
- en: Note
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The keys defined in the *Workspace Data* table do not need to match the names
    of the variables from the WDL. We tend to standardize variable names and keys
    across our workflows in order to make it more obvious which ones go together,
    but it’s not a requirement of the system. If you wanted, you could set up a key
    called *my_docker* and provide it as *workspace.my_docker* to the *gatk_docker*
    variable in the workflow configuration.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*Workspace Data*表中定义的键不需要与WDL中的变量名称匹配。我们倾向于在工作流中统一变量名称和键，以便更容易理解它们之间的关系，但这并不是系统的要求。如果你愿意，你可以设置一个名为*my_docker*的键，并将其作为*workspace.my_docker*提供给工作流配置中的*gatk_docker*变量。'
- en: Now let’s have a look at the other table, *book_sample*. As shown in [Figure 11-19](#the_quotation_markbook_samplesquotation),
    this one is a more proper table, with multiple rows and columns. Each row is a
    different sample, identified by a unique (but for once, very readable) key in
    the *book_sample_id* column. Each sample has a file path under the *input_bam*
    column and another one under the *input_bam_index* column. If you peek at the
    paths, you might recognize these as the sample files of the family trio that we
    used in the joint calling exercise all the way back in [Chapter 6](ch06.xhtml#best_practices_for_germline_short_varia)
    (Germline short variant analysis), when the world was new and you were still running
    individual command lines in your VM.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看另一张表，*book_sample*。正如[图 11-19](#the_quotation_markbook_samplesquotation)所示，这是一张更为正式的表，具有多行和多列。每一行都是一个不同的样本，由*book_sample_id*列中独特的（但非常易读的）键标识。每个样本在*input_bam*列下有一个文件路径，在*input_bam_index*列下有另一个文件路径。如果你查看这些路径，你可能会认出它们是我们在[第 6
    章](ch06.xhtml#best_practices_for_germline_short_varia)中使用的家庭三体联合调用练习中使用的样本文件，那时候你还在VM中运行单个命令行。
- en: '![The “book_samples” table.](Images/gitc_1119.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![“book_samples”表。](Images/gitc_1119.png)'
- en: Figure 11-19\. The book_sample table.
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-19\. *book_sample*表。
- en: So how do we plug the contents of this table into the inputs form? Well, you
    just learned about the `workspace.*something*` syntax that we encountered in [Figure 11-16](#the_workflow_input_configuration_refere);
    now it’s time to extend that lesson to elucidate the `this.*something*` syntax.
    In a nutshell, it’s the same idea, except now the pointer is `this` instead of
    `workspace`. and it’s going to point to any row of data taken from the *book_sample*
    table and submitted to the workflow system for processing, instead of pointing
    to the *Workspace Data* table.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何将这个表的内容插入输入表单中呢？嗯，你刚学过`workspace.*something*`的语法，我们在[图 11-16](#the_workflow_input_configuration_refere)中遇到过；现在是时候扩展这个课程，以阐明`this.*something*`的语法了。简而言之，这是相同的概念，只是现在指针是`this`而不是`workspace`，它将指向从*book_sample*表中取出并提交给工作流系统进行处理的任何数据行，而不是指向*Workspace
    Data*表。
- en: 'Too abstract? Let’s use a concrete example. Imagine that you select one row
    from the *book_sample* table. That produces what is essentially a list of key:value
    pairs, just like the *Workspace Data* table:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 过于抽象了？让我们举个具体的例子来说明。想象一下，你从*book_sample*表中选择了一行。这实际上产生了一个键值对列表，就像*Workspace
    Data*表一样：
- en: '[PRE0]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can therefore refer to each value based on the column name, which has been
    reduced to a simple key by the process of isolating that one row. That is what
    the `this.*input_bam*` syntax does. It instructs the system: for every sample
    row that you run the workflow on, use this row’s `*input_bam*` value as an input
    for the `*input_bam*` variable, and so on for every variable where we use this
    syntax. (And again, the fact that the names match is not a requirement, though
    we do it intentionally for consistency.)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 您因此可以根据列名引用每个值，这些列名已通过隔离该行的过程简化为一个简单的键。这就是`this.*input_bam*`语法的作用。它指示系统：对于您运行工作流程的每个样本行，使用该行的`*input_bam*`值作为`*input_bam*`变量的输入，以及使用此语法的每个变量。
    （再次强调，名称匹配并不是必需的要求，尽管我们有意为之以保持一致性。）
- en: 'Alright, that was a long explanation, but we know this system trips up a lot
    of newcomers to Terra, so hopefully it’s been worth it. The feature itself certainly
    is, because it’s going to allow you to launch workflows on arbitrary numbers of
    samples at the click of a button. If that weren’t enough, the data table system
    has another benefit: when you have your workflow wired up to use the data table
    as input, you can start the process directly from the data table itself.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，解释有点长，但我们知道这个系统确实让 Terra 的新手们感到困惑，所以希望这篇文章是值得的。这个功能本身肯定是值得的，因为它可以让您只需点击一下按钮就可以在任意数量的样本上启动工作流程。如果这还不够，数据表系统还有另一个好处：当您的工作流程连接到数据表作为输入时，您可以直接从数据表本身启动流程。
- en: How would you like to try it out? Go ahead and use the checkboxes to select
    two of the samples, as shown in [Figure 11-20](#initiating_an_analysis_directly_on_a_su).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 您想尝试一下吗？请使用复选框选择两个样本，如[图 11-20](#initiating_an_analysis_directly_on_a_su)所示。
- en: '![Initiating an analysis directly on a subset of data.  ](Images/gitc_1120.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![在数据子集上直接启动分析。](Images/gitc_1120.png)'
- en: Figure 11-20\. Initiating an analysis directly on a subset of data.
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-20\. 直接在数据子集上启动分析。
- en: Having selected the samples, click the round symbol with three vertical dots
    located next to the count of selected rows. Click “Open with…” to open the menu
    of options and select Workflow as shown in [Figure 11-21](#specifying_a_workflow_to_run_on_the_sel).
    Options that are not suitable for your data selection are grayed out. When you
    click Workflow, you’re presented with a list of available workflow configurations.
    Be sure to pick the one that is set up to use the data table; the system does
    not automatically filter out workflows that are configured with direct file paths.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 选择样本后，单击位于所选行计数旁边的三个竖点的圆形符号。单击“打开方式…”以打开选项菜单，并选择工作流程，如[图 11-21](#specifying_a_workflow_to_run_on_the_sel)所示。对于不适合您的数据选择的选项将显示为灰色。选择工作流程后，您将看到一个可用工作流程配置的列表。务必选择设置为使用数据表的工作流程；系统不会自动过滤掉配置为直接文件路径的工作流程。
- en: '![Specifying a workflow to run on the selected data.](Images/gitc_1121.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![指定在所选数据上运行的工作流程。](Images/gitc_1121.png)'
- en: Figure 11-21\. Specifying a workflow to run on the selected data.
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-21\. 指定在所选数据上运行的工作流程。
- en: After you pick a workflow configuration, you are brought back in the workflows
    section. Looking at the configuration summary, you’ll see that it’s now set to
    run on the subset of data that you selected, as shown in [Figure 11-22](#configuration_updated_with_data_selecti).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择工作流程配置后，您将返回到工作流程部分。查看配置摘要时，您会发现它现在已设置为在您选择的数据子集上运行，如[图 11-22](#configuration_updated_with_data_selecti)所示。
- en: '![Configuration updated with data selection.](Images/gitc_1122.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![配置更新后的数据选择。](Images/gitc_1122.png)'
- en: Figure 11-22\. Configuration updated with data selection.
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-22\. 配置更新后的数据选择。
- en: When you submit this workflow execution request for the first time, the system
    saves a list of the samples you selected and stores the list as a row in a new
    data table called *sample_set.* After that, the system will add rows to the *sample_set*
    table every time you run a workflow on samples in this way. Note that you can
    also create sample sets yourself; you’ll see an example of that in [Chapter 13](ch13.xhtml#assembling_your_own_workspace_in_terra).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次提交此工作流程执行请求时，系统会保存您选择的样本列表，并将该列表存储为新数据表*sample_set*中的一行。之后，每次您以这种方式对样本运行工作流程时，系统都会向*sample_set*表中添加行。请注意，您也可以自行创建样本集；在[第 13
    章](ch13.xhtml#assembling_your_own_workspace_in_terra)中会看到一个示例。
- en: Note
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Selecting rows manually is something that we mostly do for testing purposes;
    it wouldn’t scale terribly well. For a more scalable approach, you can opt to
    run the workflow on all rows in a table, or you can create sets ahead of time.
    To access these options, simply click the Select Data link adjacent to the table
    selection menu. Speaking of which: yes, you can have multiple data tables in a
    workspace, although you cannot launch a workflow on multiple tables at the same
    time.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 手动选择行主要用于测试目的；这种方法不太可扩展。为了更具可扩展性，您可以选择在表中的所有行上运行工作流，或者您可以提前创建集合。要访问这些选项，只需点击表选择菜单旁边的选择数据链接。说到这个：是的，您可以在工作区中拥有多个数据表，尽管您不能同时在多个表上启动工作流。
- en: Finally, there’s nothing left to do but click the Run Analysis button and then
    confirm the launch. But this time, when you land in the Job History section, stick
    around so that we can take a look at how your first workflow submission fared.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，只需点击运行分析按钮，然后确认启动即可。但是这次，当您进入作业历史部分时，请留下来，这样我们就可以看看您的第一个工作流提交的情况如何。
- en: Monitoring Workflow Execution
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控工作流执行
- en: When you’re taken to the Job History page after launching a workflow, what you
    see is the summary page for the submission you just created. If you wandered off
    in the meantime and then came back to the Job History page on your own steam,
    what you’ll see is a list of submissions, as shown in [Figure 11-23](#list_of_submissions_in_the_job_historyd).
    If so, you’ll need to click one of them to open it in order to follow the instructions
    that follow.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 当您在启动工作流后被带到作业历史页面时，您看到的是您刚刚创建的提交的摘要页面。如果您在此期间离开然后自己回到作业历史页面，您将看到一个提交列表，如[图 11-23](#list_of_submissions_in_the_job_historyd)所示。如果是这样，您需要点击其中一个以打开它，以便按照接下来的说明进行操作。
- en: '![List of submissions in the Job History.](Images/gitc_1123.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![作业历史中的提交列表。](Images/gitc_1123.png)'
- en: Figure 11-23\. List of submissions in the Job History.
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-23\. 作业历史中的提交列表。
- en: The submission summary page, shown in [Figure 11-24](#the_workflow_submission_summary_pagedot),
    includes a link back to the workflow configuration, information about the data
    that the workflow was launched on, and a table listing individual workflow executions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 提交摘要页面，如[图 11-24](#the_workflow_submission_summary_pagedot)所示，包括返回工作流配置的链接，有关启动工作流的数据信息，以及列出单独工作流执行的表格。
- en: Each row in the table corresponds to an individual run of the workflow. If you
    used the data table approach to launch the workflow, the Data Entity column shows
    the identifier of the corresponding row in the data table as well as the name
    of the table. If you ran the workflow directly on file paths, as we did in the
    first exercise, that column is left blank. The *Workflow ID* is a unique tracking
    number assigned by the system and links to the location of the execution logs
    in GCS; if you click it, it will take you to the GCP console. Most of the time,
    you’ll want to ignore that link and use the View link instead, in the leftmost
    column, to view detailed status information about the workflow run.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 表中的每一行对应工作流的一个单独运行。如果您使用数据表方法启动工作流，则数据实体列显示对应数据表中行的标识符以及表的名称。如果您像在第一个练习中那样直接在文件路径上运行工作流，则该列为空白。*工作流
    ID*是系统分配的唯一跟踪号，链接到 GCS 中执行日志的位置；如果您点击它，将带您到 GCP 控制台。大多数情况下，您会忽略该链接，而是使用最左侧列中的查看链接，查看有关工作流运行的详细状态信息。
- en: '![The workflow submission summary page.](Images/gitc_1124.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![工作流提交摘要页面。](Images/gitc_1124.png)'
- en: Figure 11-24\. The workflow submission summary page.
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-24\. 工作流提交摘要页面。
- en: Go ahead and click the View link in one of the rows to open up the details for
    that workflow run. The workflow run details page packs in a lot of information,
    so let’s go through it one piece at a time.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 继续点击一行中的查看链接以打开该工作流运行的详细信息。工作流运行详细信息页面包含大量信息，让我们一次性逐个查看。
- en: Note
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: As of this writing, the workflow run details open on a new page titled Job Manager
    because it uses a service that is not yet fully integrated into the main Terra
    portal. You might need to sign in with your Google credentials to access the workflow
    run details page.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，工作流运行详细信息会在一个名为作业管理器的新页面上打开，因为它使用的服务尚未完全集成到主 Terra 门户。您可能需要使用您的 Google
    凭据登录以访问工作流运行详细信息页面。
- en: First, have a look at the overall status summary pane, shown in [Figure 11-25](#workflow_in_aright_parenthesis_running).
    If everything goes well, you’ll see your workflow change from Running to Succeeded
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，看一下总体状态摘要窗格，如[图 11-25](#workflow_in_aright_parenthesis_running)所示。如果一切顺利，您将看到您的工作流从运行状态变为成功状态。
- en: '![Workflow in A) Running state and, B) Succeeded state.](Images/gitc_1125.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![工作流在 A) 运行状态和 B) 成功状态下的情况。](Images/gitc_1125.png)'
- en: Figure 11-25\. Workflow in A) Running state and, B) Succeeded state.
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-25\. 工作流在 A) 运行状态和 B) 成功状态下的情况。
- en: In the unfortunate event that your workflow run failed, the page will display
    additional details, including any error messages and links to logs, as shown in
    [Figure 11-26](#the_workflow_in_failed_state_with_error).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的工作流运行失败，页面将显示额外的细节，包括任何错误消息和日志链接，如[图 11-26](#the_workflow_in_failed_state_with_error)所示。
- en: '![The workflow in Failed state with ERRORS summary and Failure Message.](Images/gitc_1126.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![工作流处于失败状态，显示错误摘要和失败消息。](Images/gitc_1126.png)'
- en: Figure 11-26\. A workflow in Failed state with ERRORS summary and Failure Message.
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-26\. 工作流处于失败状态，显示错误摘要和失败消息。
- en: When everything’s working, the panel below the summary pane, shown in [Figure 11-27](#list_of_tasks_and_related_resourcesdot),
    is your go-to for everything you need to monitor the step-by-step execution of
    your workflow. The list of tasks will be updated as the workflow progresses and
    will be populated with useful resources like links to each task’s logs, execution
    directory, inputs, and outputs. To be clear, tasks won’t be listed until the work
    on them actually starts, so don’t panic when you see only a subset of the tasks
    in your workflow if you check on its status while it’s still running.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 当一切正常时，摘要窗格下方的面板，如[图 11-27](#list_of_tasks_and_related_resourcesdot)所示，是您监视工作流逐步执行所需的一切资源。随着工作流的进展，任务列表将被更新，并且将填充有诸如每个任务的日志、执行目录、输入和输出的有用资源链接。需要明确的是，在任务实际开始工作之前，不会列出任务，因此当您在工作流正在运行时检查其状态时，看到的只是任务的一个子集时，请不要惊慌。
- en: '![List of tasks and related resources.](Images/gitc_1127.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![任务列表和相关资源。](Images/gitc_1127.png)'
- en: Figure 11-27\. List of tasks and related resources.
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-27\. 任务列表和相关资源。
- en: 'You might notice that in [Figure 11-27](#list_of_tasks_and_related_resourcesdot),
    the `HaplotypeCallerGVCF` task is represented a bit differently compared to the
    `MergeVCFs` task: its name is underlined and there is a symbol on the side that
    looks like a stack of paper. This is how scattered tasks are represented. As shown
    in [Figure 11-28](#viewing_the_status_of_shards_for_a_scat), you can hover over
    the stack symbol to see a status summary for all of the *shards* generated at
    that step; that is, the individual tasks resulting from the scatter.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能注意到在[图 11-27](#list_of_tasks_and_related_resourcesdot)中，`HaplotypeCallerGVCF`任务与`MergeVCFs`任务相比有所不同：其名称被下划线标记，并且侧面有一个看起来像一叠纸的符号。这就是散乱任务的表示方式。如[图 11-28](#viewing_the_status_of_shards_for_a_scat)所示，您可以将鼠标悬停在堆叠符号上，查看该步骤生成的所有*shards*的状态摘要；即散乱步骤生成的各个任务。
- en: '![Viewing the status of shards for a scattered task.](Images/gitc_1128.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![查看散乱任务的shard状态。](Images/gitc_1128.png)'
- en: Figure 11-28\. Viewing the status of shards for a scattered task.
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-28\. 查看散乱任务的shard状态。
- en: The panel shown in [Figure 11-27](#list_of_tasks_and_related_resourcesdot) has
    multiple tabs, so take a minute to explore those, as well. Our favorite tab in
    this panel is Timing Diagram, shown in [Figure 11-29](#a_timing_diagram_showing_the_breakdown),
    which shows you how much time each task took to run. This includes not just the
    time spent in the User Action stage—running the analysis command (for example,
    `HaplotypeCaller`), but also the time spent on getting the VM set up, pulling
    the container image, localizing files, and so on.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-27](#list_of_tasks_and_related_resourcesdot)中显示的面板有多个选项卡，请花点时间探索一下。我们在此面板中最喜欢的选项卡是时间图，如[图 11-29](#a_timing_diagram_showing_the_breakdown)所示，它展示了每个任务运行所花费的时间。这不仅包括在用户操作阶段的时间——运行分析命令（例如，`HaplotypeCaller`），还包括在VM设置、拉取容器映像、本地化文件等方面所花费的时间。'
- en: '![A timing diagram showing the breakdown of runtime per stage of execution
    for each task call.](Images/gitc_1129.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![时间图显示了每个任务调用阶段的运行时细分。](Images/gitc_1129.png)'
- en: Figure 11-29\. A timing diagram showing the breakdown of runtime per stage of
    execution for each task call.
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-29\. 时间图显示了每个任务调用阶段的运行时细分。
- en: If you recall the discussion about workflow efficiency in [Chapter 10](ch10.xhtml#running_single_workflows_at_scale_with),
    some amount of overhead is associated with each stage. The timing diagram is a
    great resource for examining this. It can help you identify any bottlenecks in
    your workflow that you need to address; for example, if your list of genomic intervals
    is not well balanced or if a particular command is taking far more time than it
    should.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得在[第 10 章](ch10.xhtml#running_single_workflows_at_scale_with)中关于工作流效率的讨论，每个阶段都会带来一定的开销。时序图是检查这些开销的好资源。它可以帮助您识别工作流中需要解决的任何瓶颈；例如，如果您的基因组区间列表不平衡或者某个命令花费的时间远远超过预期。
- en: Want to see it in action? Try hovering your mouse over the colored segments,
    and you’ll see tooltips appear that indicate the stage you’re looking at and the
    amount of time it took. For example, in [Figure 11-29](#a_timing_diagram_showing_the_breakdown),
    we were looking at the yellow block on the right side, which shows that `HaplotypeCaller`
    took just 21 seconds to run on the very short interval we gave it for testing
    purposes. In comparison, it took 101 seconds to pull the container image!
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 想看看它如何运作？试着将鼠标悬停在着色段上，您将看到工具提示出现，指示您正在查看的阶段及其所花费的时间。例如，在[图 11-29](#a_timing_diagram_showing_the_breakdown)中，我们看到右侧的黄色块，显示`HaplotypeCaller`仅用了21秒来运行我们用于测试的非常短的时间间隔。相比之下，拉取容器映像花了101秒！
- en: Finally, you might notice that the name of the task in the pop-up window includes
    *attempt 1*. This is because the workflow is configured to use preemptible instances,
    which we also discussed in the section on optimizations in [Chapter 10](ch10.xhtml#running_single_workflows_at_scale_with).
    If one of your tasks is preempted and restarted, each run attempt will be represented
    by a separate line in the diagram, as shown in [Figure 11-30](#a_timing_diagram_showing_preempted_call)
    (which comes from an unrelated workflow that we ran separately).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可能会注意到弹出窗口中任务的名称包括*尝试 1*。这是因为工作流配置为使用可抢占实例，我们在[第 10 章](ch10.xhtml#running_single_workflows_at_scale_with)中讨论过优化。如果其中一个任务被抢占并重新启动，则每次运行尝试将在图表中显示为单独的线，如[图 11-30](#a_timing_diagram_showing_preempted_call)所示（这来自我们分开运行的无关工作流）。
- en: '![A timing diagram showing preempted calls (green bars, at lines 2, 12, and
    13 from the top).](Images/gitc_1130.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![显示了被抢占调用的时间图（绿色条，位于从顶部第2、12和13行）。](Images/gitc_1130.png)'
- en: Figure 11-30\. A timing diagram showing preempted calls (green bars, at lines
    2, 12, and 13 from the top).
  id: totrans-129
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-30\. 显示了被抢占调用的时间图（绿色条，位于从顶部第2、12和13行）。
- en: The bars representing preempted jobs are displayed in a single solid color because
    the different stages of operation are not reported. As a result, you can usually
    see fairly clearly whether a pattern of serial preemptions exists; for example,
    in [Figure 11-30](#a_timing_diagram_showing_preempted_call) a job was started
    and then interrupted by preemption (line 12 from the top), restarted and interrupted
    again (line 13 from the top), and then restarted again and this time was successful.
    You can see from this example, in which even the shortest preempted job ran for
    almost four hours, that if you run into several preemptions in a row for a job
    that constitutes a bottleneck in your pipeline, the overall runtime can increase
    dramatically as a result. This highlights the importance of evaluating carefully
    whether the cost savings that you can reap from using preemptible instances is
    worth the risk of your pipelines taking much longer to complete. Our rule of thumb
    is that if our large-scale data-processing results are due next week, bring on
    the preemptibles. But if we’re frantically trying to finish a demo for a conference
    in two days, turn them off and suck up the extra cost.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表示被抢占作业的条形图显示为单一的实色，因为操作的不同阶段没有报告。因此，您通常可以清楚地看到是否存在一系列串行的抢占模式；例如，在[图 11-30](#a_timing_diagram_showing_preempted_call)中，一个作业开始然后被抢占（从顶部第12行），重新启动然后再次被抢占（从顶部第13行），然后再次成功启动。从这个例子中可以看出，即使是最短的被抢占作业也运行了近四个小时，如果您遇到连续多次作业抢占的情况，而这些作业构成管道中的瓶颈，总运行时间可能会显著增加。这突显了仔细评估使用可抢占实例可以获得的成本节约是否值得冒管道运行时间明显延长的风险的重要性。我们的经验法则是，如果我们的大规模数据处理结果将于下周交付，那就使用可抢占实例。但如果我们正在为两天后的会议展示拼命地完成演示，那就关闭它们并承担额外的成本。
- en: Locating Workflow Outputs in the Data Table
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在数据表中查找工作流输出
- en: As we noted earlier, the workflow details shown in [Figure 11-27](#list_of_tasks_and_related_resourcesdot)
    include pointers to the location of output files. That’s a pretty decent way to
    locate outputs for a particular workflow run, but that’s not going to scale well
    when you’re working on hundreds or thousands of samples. Not to mention hundreds
    *of* thousands of samples. (Yep, some people are at that point—isn’t it an exciting
    time to be alive?)
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前指出的，在[图 11-27](#list_of_tasks_and_related_resourcesdot)中显示的工作流详细信息包括指向输出文件位置的指针。这是定位特定工作流运行输出的相当不错的方式，但在处理数百甚至*数十万*个样本时，这种方式并不适用。（是的，有些人已经达到了这个程度——这不是一个令人兴奋的时代吗？）
- en: 'There is a much better way to do it if you used the data table, which you would
    need to do if you’re working at that scale. Here it is: with a tiny configuration
    trick, you can get the system to automatically add the workflow outputs to the
    data table. And, of course, we enabled that in the workflow configuration we made
    you run, so let’s go have a look at the data table, shown in [Figure 11-31](#the_data_table_showing_the_newly_genera),
    to see whether it worked.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在这种规模下工作，使用数据表会有一个更好的方法。下面是它：通过一个微小的配置技巧，你可以让系统自动将工作流输出添加到数据表中。当然，在我们要求你运行的工作流配置中启用了这个功能，所以让我们去看一下数据表，显示在[图 11-31](#the_data_table_showing_the_newly_genera)中，看看它是否起作用了。
- en: '![The data table showing the newly generated "output_gvcf" column.](Images/gitc_1131.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![显示新生成的"output_gvcf"列的数据表。](Images/gitc_1131.png)'
- en: Figure 11-31\. The data table showing the newly generated output_gvcf column.
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-31\. 显示新生成的output_gvcf列的数据表。
- en: And there it is! As you can see in [Figure 11-31](#the_data_table_showing_the_newly_genera),
    a new column has appeared in the *book_sample* table, named *output_gvcf*, and
    all the samples we ran the workflow on now have file paths corresponding to the
    GVCFs produced by the workflow runs.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 看！正如你在[图 11-31](#the_data_table_showing_the_newly_genera)中所见，*book_sample*表中出现了一个名为*output_gvcf*的新列，所有我们运行工作流的样本现在都有与工作流运行产生的GVCF文件对应的文件路径。
- en: So, where does the name of the new column come from? Let’s return to the `scatter-hc.data-table`
    workflow configuration and take a look at the Output tab, which we ignored earlier.
    As you can see in [Figure 11-32](#the_workflow_outputs_configuration_pane), we
    specified the output name and set it to be attached to the row data using the
    `this.` syntax, which we described earlier. You can pick an arbitrary name (for
    example, you could instead use `*this.my_gvcf*`), or you can click “Use defaults”
    to automatically use the name of the variable as it is specified in the workflow
    script, as we did here.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，新列的名称从何而来？让我们返回到`scatter-hc.data-table`工作流配置，看看我们之前忽略的输出选项卡。如你在[图 11-32](#the_workflow_outputs_configuration_pane)中所见，我们指定了输出名称，并设置将其附加到行数据，使用`this.`语法，我们之前已经描述过。你可以选择任意名称（例如，你可以改用`*this.my_gvcf*`），或者你可以点击“使用默认”以自动使用在工作流脚本中指定的变量名称，就像我们在这里所做的那样。
- en: '![The workflow outputs configuration panel.](Images/gitc_1132.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![工作流输出配置面板。](Images/gitc_1132.png)'
- en: Figure 11-32\. The workflow outputs configuration panel.
  id: totrans-139
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-32\. 工作流输出配置面板。
- en: Keep in mind that this option is available only if you’re using the data table
    to define the workflow inputs. In either case, however, the location where the
    files are written is the same. By default, the system stores all outputs produced
    by workflows in a bucket that is tightly associated with the workspace. The bucket
    is created automatically when you create a workspace, and it has the same ownership
    permissions as the workspace, so if you share the workspace with someone (same
    menu as for cloning), they will also be able to access the data in your workspace.
    One important restriction, however, is that you cannot modify the bucket’s permissions
    outside of Terra.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这个选项仅在你使用数据表定义工作流输入时才可用。无论哪种情况，文件写入位置都是相同的。系统默认将工作流产生的所有输出存储在一个与工作空间紧密关联的存储桶中。创建工作空间时会自动创建这个存储桶，它与工作空间具有相同的所有权权限，因此如果你与某人分享工作空间（与克隆相同的菜单），他们也能访问工作空间中的数据。然而，重要的限制是你无法在Terra之外修改存储桶的权限。
- en: Note
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you delete a workspace, its bucket will also be deleted, along with all its
    contents. In addition, when you clone a workspace, the data is not copied, and
    any paths in metadata tables will continue to point to the data’s original location.
    This is great because it allows you to avoid paying storage fees for multiple
    copies of the same data that you would otherwise generate. But if you thought
    you could save a copy of your data by cloning a workspace before deleting the
    original, well, you can’t.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果删除工作空间，其存储桶及其所有内容也会被删除。此外，当你克隆一个工作空间时，数据不会被复制，元数据表中的路径仍然指向数据的原始位置。这样做的好处是，你可以避免为相同数据的多个副本支付存储费用，否则你将会生成多个副本。但是，如果你认为通过克隆一个工作空间来保存数据的副本，那么，这是不可能的。
- en: Finally, you might have noticed on the Data page that there is a Files link
    in the lefthand menu, which is visible in [Figure 11-31](#the_data_table_showing_the_newly_genera)
    among others. If you go back to that page and click the Files link, it will open
    a filesystem-like interface that you can use to browse the contents of the bucket
    without having to leave Terra, as shown in [Figure 11-33](#the_file_browser_interface_showing_work).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可能已经注意到在数据页面中，在左侧菜单中有一个"Files"链接，在其他地方也可以看到[图11-31](#the_data_table_showing_the_newly_genera)等。如果你返回到那一页并点击"Files"链接，它将打开一个类似文件系统的界面，你可以在不离开Terra的情况下浏览存储桶的内容，正如[图11-33](#the_file_browser_interface_showing_work)所示。
- en: '![The file browser interface showing workflow outputs in the workspace bucket.](Images/gitc_1133.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![文件浏览器界面显示工作空间存储桶中的工作流输出。](Images/gitc_1133.png)'
- en: Figure 11-33\. The file browser interface showing workflow outputs in the workspace
    bucket.
  id: totrans-145
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-33\. 文件浏览器界面显示工作空间存储桶中的工作流输出。
- en: You can even add files to your bucket by dragging and dropping them from your
    desktop into the file browser. That being said, if you prefer, you can always
    access the bucket through the GCS console and  interact with its contents through
    `gsutil`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你甚至可以通过将它们从桌面拖放到文件浏览器中，向你的存储桶添加文件。话虽如此，如果你更喜欢，你总是可以通过GCS控制台访问存储桶，并通过`gsutil`与其内容交互。
- en: Running the Same Workflow Again to Demonstrate Call Caching
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 再次运行相同的工作流来展示调用缓存功能
- en: Did you think we were done? Not quite; we couldn’t possibly let you move on
    without experiencing the wonder that is Cromwell’s call caching feature. We’ve
    already gone over its purpose several times—make it so you can avoid running duplicate
    jobs, and resume a workflow from the last point of failure, interruption or modification—so
    now let’s see it in action. Go ahead and use the launching process you just learned
    to run the workflow again on one of the samples that you already ran on earlier.
    When you land on the Job History page, click through to the workflow monitoring
    details when the View link becomes available. It might take a couple of minutes,
    so feel free to go grab yourself a cup of tea, coffee, or other beverage of choice—just
    don’t spill it on your laptop when you return. And remember to refresh the page;
    the workflow status doesn’t refresh on its own.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你以为我们已经完成了吗？还没有，我们不可能让你继续前进，而不去体验Cromwell的调用缓存功能。我们已经多次讲解了它的用途——让你避免运行重复的作业，并从上次失败、中断或修改的位置恢复工作流程——现在让我们看看它的实际效果。继续使用刚学到的启动流程，在一个你已经运行过的样本上再次运行工作流。当你进入作业历史页面时，当"View"链接变为可用时，点击到工作流监控详细信息。这可能需要几分钟，所以随意去拿杯茶、咖啡或其他选择的饮料——只是回来时不要把它洒在你的笔记本上。记得刷新页面；工作流状态不会自动刷新。
- en: When you’re on the workflow details page, navigate to the Timing Diagram and
    hover over the widest bar for one of the lines. You should see something like
    [Figure 11-34](#a_timing_diagram_showing_callcachereadi), reporting on a stage
    named `CallCacheReading` that took about 10 seconds to run.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在工作流程详细页面时，导航到时序图并悬停在其中一条线的最宽条上。你会看到类似于[图11-34](#a_timing_diagram_showing_callcachereadi)的内容，报告了一个名为`CallCacheReading`的阶段大约运行了10秒钟。
- en: '![A timing diagram showing CallCacheReading stage runtime.](Images/gitc_1134.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![显示CallCacheReading阶段运行时间的时序图。](Images/gitc_1134.png)'
- en: Figure 11-34\. A timing diagram showing CallCacheReading stage run time.
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-34\. 显示CallCacheReading阶段运行时间的时序图。
- en: If you hover over the other bars, you’ll also see that you can’t find any of
    the stages related to pulling the container image or localizing inputs. This shows
    you that when call caching kicks in for a task, the system doesn’t even go to
    the trouble of setting up VMs. In fact, Cromwell doesn’t even dispatch anything
    about that task to PAPI.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将鼠标悬停在其他条上，你会发现没有与拉取容器镜像或本地化输入相关的任何阶段。这表明，当调用缓存对一个任务生效时，系统甚至不需要设置虚拟机。事实上，Cromwell
    甚至不会将有关该任务的任何内容发送到 PAPI。
- en: 'So what exactly does happen? Good question; let’s talk about how call caching
    works in practice. First, you should know that whenever the Cromwell server runs
    a task call successfully, it stores a detailed record of that call in its database.
    This includes the name of the task and all of its input values: files, parameters,
    container image version, everything—as well as a link to the output file. Then,
    the next time you send it a workflow to run, it will check each task against its
    database of past calls before sending it out for execution. If it finds any perfect
    matches, it will skip execution for that task and simply output a copy of the
    output file that it had linked to in the last successful execution. [Figure 11-35](#overview_of_cromwellapostrophes_call_ca)
    illustrates this process.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 那么实际上会发生什么呢？好问题；让我们谈谈调用缓存在实际中是如何工作的。首先，你应该知道，每当 Cromwell 服务器成功运行一个任务调用时，它会在其数据库中存储该调用的详细记录。这包括任务的名称和所有的输入值：文件、参数、容器镜像版本等等，以及一个指向输出文件的链接。然后，下次你发送一个工作流程来运行时，它会在发送任务执行之前检查每个任务是否与其过去调用的数据库中的记录完全匹配。如果找到任何完美匹配，它将跳过该任务的执行，并简单地输出上次成功执行时链接到的输出文件的副本。[图
    11-35](#overview_of_cromwellapostrophes_call_ca) 展示了这一过程。
- en: '![Overview of Cromwell’s call caching mechanism.](Images/gitc_1135.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![Cromwell 的调用缓存机制概览。](Images/gitc_1135.png)'
- en: Figure 11-35\. Overview of Cromwell’s call caching mechanism.
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-35\. Cromwell 的调用缓存机制概览。
- en: In this example, all task calls in the workflow matched the call cache; in other
    words, *call-cached* (yep, you can use it as a verb), so nothing actually was
    run except a few file copying operations done by the Cromwell server itself. If
    you were to modify the `MergeVCFs` call even slightly and run this again, the
    `HaplotypeCaller` calls would call-cache, but `MergeVCFs` would not, so Cromwell
    would send that call to PAPI for execution. You can try this out by changing the
    version of the container image used by `MergeVCFs` (try 4.1.4.1) and then have
    a look at the Timing Diagram.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，工作流中的所有任务调用都匹配了调用缓存；换句话说，*调用缓存*（是的，你可以把它当做动词用），因此除了 Cromwell 服务器本身进行的几次文件复制操作外，实际上没有运行任何内容。如果你稍微修改`MergeVCFs`调用，然后再次运行，`HaplotypeCaller`调用会调用缓存，但`MergeVCFs`不会，因此
    Cromwell 将发送该调用到 PAPI 执行。你可以尝试通过修改`MergeVCFs`使用的容器镜像版本（尝试 4.1.4.1）然后查看时序图。
- en: Note
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can disable call caching by clearing the checkbox in the workflow configuration,
    but why would you even want to do that? Call caching is fantastic. Call...ka-ching!
    (Because it saves you money.) #dadjokes.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过在工作流配置中取消选中复选框来禁用调用缓存，但是为什么你会想这么做呢？调用缓存太棒了。调用缓存...ka-ching！（因为它可以省钱。）#父亲笑话。
- en: Alright, time to take a break. How are you feeling? It’s normal to feel a little
    light-headed at this point; after all, you just got superpowers. Seriously, you
    are now capable of running real, sophisticated genomics workflows on as many samples
    as you can get your hands on. That’s no small feat. Yet the proof, as they say,
    is in the pudding, so grab a spoon and let’s go bite off something big.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，是时候休息一下了。你感觉怎么样？此刻感觉有点头晕是正常的；毕竟，你刚刚获得了超能力。说真的，你现在可以在尽可能多的样本上运行真正复杂的基因组学工作流程。这可不是小事。然而，证据就像人们所说的那样，得看结果，所以拿起勺子，让我们迎接一些大的挑战吧。
- en: Running a Real GATK Best Practices Pipeline at Full Scale
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在全规模下运行真正的 GATK 最佳实践管道
- en: 'Do you remember Mystery Workflow #2 from [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows),
    which turned out to be the Broad Institute’s whole genome analysis pipeline? It’s
    probably not the biggest genomics pipeline in the world (though it is plenty big),
    and it’s not the fastest pipeline in the world either (because it needs to be
    inexpensive). But it might just be the pipeline that has processed the largest
    number of human whole genome samples in the history of genomics (so far). If you’re
    looking to learn how to do something fairly standard that will come in handy at
    some point in the future, this pipeline would be a reasonable choice.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 你还记得[第9章](ch09.xhtml#deciphering_real_genomics_workflows)中的神秘工作流程＃2吗？它最终证明是Broad
    Institute的整个基因组分析流程？虽然它可能不是世界上最大的基因组学流水线（尽管它已经足够大了），它也不是世界上最快的流水线（因为它需要廉价）。但它可能只是在基因组学历史上处理了最多人类整个基因组样本的流水线（至今为止）。如果你想学习如何做一些相当标准的事情，在未来某个时候可能会有用，那么选择这个流水线是个合理的选择。
- en: In this last section of the chapter, we’re going to show you where to find it,
    test it, and run it on a full-scale human whole genome sample.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后一节，我们将向你展示在哪里找到它，测试它，并在全尺寸人类整个基因组样本上运行它。
- en: The good news is that it’s going to be pretty straightforward. We already mentioned
    previously that the GATK team makes its Best Practices workflows available in
    a [GitHub repository](https://oreil.ly/D0Ofp), but that’s not all; it also provides
    fully loaded Terra workspaces for all of them. These Best Practices workspaces
    contain data tables populated with appropriate example data samples (typically
    a small one and a full-scale one), and workflow configurations that are already
    wired up to run on the example data. All you need to do is clone the workspace.
    Then, you can follow the procedure that you learned in this chapter to run the
    workflows right out of the box. (We show you how to bring in data from other sources
    in [Chapter 13](ch13.xhtml#assembling_your_own_workspace_in_terra).)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，这将非常简单。我们之前已经提到过，GATK团队在[GitHub仓库](https://oreil.ly/D0Ofp)中提供了其最佳实践工作流程，但这还不是全部；它还为所有这些工作流程提供了完全加载的Terra工作空间。这些最佳实践工作空间包含了填充有适当示例数据样本（通常是小型和全尺寸的样本）的数据表，以及已经连接到示例数据运行的工作流配置。你所需做的就是克隆工作空间。然后，你可以按照本章学到的步骤直接运行工作流程。（我们会在[第13章](ch13.xhtml#assembling_your_own_workspace_in_terra)中展示如何从其他来源引入数据。）
- en: Finding and Cloning the GATK Best Practices Workspace for Germline Short Variant
    Discovery
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查找和克隆GATK生发性短变异发现最佳实践工作空间
- en: You already visited the [Terra Library showcase](https://oreil.ly/nUMy2) earlier
    in this chapter to find the tutorial workspace we created for the book. Let’s
    go back there, but this time you’re going to look for an actual Best Practices
    workspace published by the GATK team. As of this writing, the featured germline
    short variants workspace is called [Whole-Genome-Analysis-Pipeline](https://oreil.ly/x4Pzc),
    as shown in [Figure 11-36](#summary_information_for_the_whole_genom). This name
    might change in the future because the team has plans to adapt how they name and
    package these resources in light of the expanding scope covered by its tools.
    If you’re having trouble finding the right workspace, check the GATK website’s
    Best Practices section, which hosts a list of relevant resources that includes
    the Terra workspaces. Be sure to also check our book’s [blog](https://oreil.ly/genomics-blog),
    where we’ll provide updates over time.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 早些时候在本章中，你已经访问过[Terra图书馆展示](https://oreil.ly/nUMy2)，找到了我们为本书创建的教程工作空间。让我们回到那里，但这次你将寻找GATK团队发布的真正最佳实践工作空间。截至本文撰写时，特色的生发性短变异工作空间被称为[Whole-Genome-Analysis-Pipeline](https://oreil.ly/x4Pzc)，如[图11-36](#summary_information_for_the_whole_genom)所示。这个名称可能会随着团队计划根据工具的扩展范围调整如何命名和打包这些资源而发生变化。如果你在找到合适的工作空间时遇到问题，请查看GATK网站的最佳实践部分，其中包含了Terra工作空间的相关资源列表。还请务必查看我们书籍的[博客](https://oreil.ly/genomics-blog)，我们将随时间提供更新。
- en: '![Summary information for the Whole-Genome-Analysis-Pipeline workspace.](Images/gitc_1136.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![Whole-Genome-Analysis-Pipeline工作空间的摘要信息。](Images/gitc_1136.png)'
- en: Figure 11-36\. Summary information for the [Whole-Genome-Analysis-Pipeline workspace](https://oreil.ly/x4Pzc).
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-36\. [Whole-Genome-Analysis-Pipeline工作空间的摘要信息](https://oreil.ly/x4Pzc)。
- en: When you’ve found the workspace, clone it as described earlier in this chapter.
    You’ll notice that the Dashboard provides a lot of information about the workflow,
    the example data and how to use these resources effectively. It even includes
    a summary of how long it takes and how much it costs to run the workflow on the
    various samples in the example data table. Speaking of which, let’s go see what’s
    in there.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当找到工作空间后，按照本章前文的描述进行克隆。您会注意到仪表板提供了关于工作流程、示例数据以及如何有效使用这些资源的大量信息。它甚至包括运行工作流程在不同样本上所需的时间和成本摘要。说到这一点，让我们去看看里面有什么。
- en: Examining the Preloaded Data
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查预加载数据
- en: In your clone workspace, navigate to the Data section. Again, this might change,
    but as of this writing, this workspace contains two main data tables as well as
    the Workspace Data table. The latter lists the full-scale version of the genome
    reference files and other resources used in the whole genome pipeline. Note that
    these resources are all based on the hg38 build (more properly known as GRCh38)
    and would therefore not be compatible with the data in the tutorial workspace
    that we were using earlier.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在克隆的工作空间中，导航到数据部分。同样，这可能会改变，但截至本文写作时，该工作空间包含两个主要数据表以及工作空间数据表。后者列出了全基因组参考文件的全尺寸版本以及整个基因组流水线中使用的其他资源。请注意，这些资源都基于
    hg38 构建（更正式称为 GRCh38），因此与我们早期使用的教程工作空间中的数据不兼容。
- en: The two main data tables are called *participant* and *sample*, as shown in
    [Figure 11-37](#a_list_of_tables_and_detailed_view_of_t).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 主要数据表称为 *参与者* 和 *样本*，如 [图 11-37](#a_list_of_tables_and_detailed_view_of_t) 所示。
- en: '![A list of tables and detailed view of the sample table.](Images/gitc_1137.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![表格列表和示例表的详细视图。](Images/gitc_1137.png)'
- en: Figure 11-37\. A list of tables and detailed view of the sample table.
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-37\. 表格列表和示例表的详细视图。
- en: 'The *sample* table should look familiar to you because it’s the same kind of
    table as the *book_sample* table that you encountered earlier in this chapter,
    with a few additional columns. As you can see in [Figure 11-36](#summary_information_for_the_whole_genom),
    two samples are listed there: NA12878 and NAA12878_small. They both originate
    from the same study participant, dubbed NA12878\. The former is a full-size whole
    genome sequencing dataset, whereas the latter is a downsampled version of that
    dataset. For each sample, we have a list of unmapped BAM files (which will be
    the main input to the workflow) as well as other files that the documentation
    explains are outputs produced by the workflow, which has already been run in this
    workspace.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*样本* 表应该对您来说很熟悉，因为它与本章早期遇到的 *book_sample* 表是相同类型的表，只是有几列额外的内容。正如您在 [图 11-36](#summary_information_for_the_whole_genom)
    中看到的，那里列出了两个样本：NA12878 和 NAA12878_small。它们都来自同一个研究参与者，被称为 NA12878。前者是全尺寸的全基因组测序数据集，而后者是该数据集的降采样版本。对于每个样本，我们有一列未映射的
    BAM 文件（这将是工作流程的主要输入），以及其他文件，文档解释这些文件是工作流程已经在这个工作空间中运行时产生的输出。'
- en: The *participant* table, on the other hand, is probably new to you. It lists
    the study participants, though in this case, that’s just a single person. If you
    looked carefully at the sample table, you might have noticed that one of its columns
    is *participant*, which is an identifier that points to an entry in the participant
    table (*participant_id* in that table). The purpose of the participant table is
    to provide a higher level of organization for your data, which is useful when
    you have multiple study participants, and each of them can have multiple samples
    associated with them, either corresponding to different data types, different
    assays, or both. With this setup, you can use the data table system to do things
    like run a workflow on all the samples that belong to a subset of participants,
    for example.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*参与者* 表可能是新的对您来说。它列出了研究参与者，尽管在这种情况下，只有一个人。如果您仔细查看示例表，可能会注意到其中的一个列是 *参与者*，它是一个指向参与者表中条目（该表中的
    *参与者ID*）的标识符。参与者表的目的是为您的数据提供更高级别的组织，这在您有多个研究参与者并且每个参与者可以有多个相关样本（对应不同数据类型、不同测定方法或两者）时非常有用。有了这个设置，您可以使用数据表系统来做诸如在属于参与者子集的所有样本上运行工作流的事情，例如。
- en: 'As another example, the `Mutect2` somatic analysis pipeline (described in detail
    in [Chapter 7](ch07.xhtml#gatk_best_practices_for_somatic_variant)) expects to
    see a tumor sample and a matched normal sample from each patient, which are formally
    described as pairs of samples. If you check out the corresponding GATK Best Practices
    workspace ([this one](https://oreil.ly/a8ksp), at the time of writing), you’ll
    see it has four data tables organizing the data into participants, samples, pairs
    of samples, and sets of samples (for the normals that are used in the PoN, described
    in [Chapter 7](ch07.xhtml#gatk_best_practices_for_somatic_variant)). The data
    tables in that workspace conform to a *data model* defined by the TCGA cancer
    research program: The Cancer Genome Atlas.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，`Mutect2`体细胞分析管道（在[第七章](ch07.xhtml#gatk_best_practices_for_somatic_variant)中详细描述）期望看到每位患者的肿瘤样本和配对的正常样本，这些样本正式描述为样本对。如果您查看对应的GATK最佳实践工作区（[这个](https://oreil.ly/a8ksp)，截至撰写时），您会看到它有四个数据表将数据组织成参与者、样本、样本对和样本集合（用于在PoN中使用的正常样本，如[第七章](ch07.xhtml#gatk_best_practices_for_somatic_variant)中描述）。该工作区中的数据表符合由TCGA癌症研究计划定义的*数据模型*：癌症基因组图谱。
- en: More generally, you can use any number of tables to organize your data and describe
    the relationships between *data entities* like participants, samples, and others
    in a structured data model. In [Chapter 13](ch13.xhtml#assembling_your_own_workspace_in_terra),
    we discuss options for building your data model in Terra and using it effectively
    to save yourself time and effort.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地说，您可以使用任意数量的表格来组织您的数据，并描述*数据实体*之间的关系，如参与者、样本等在结构化数据模型中的组织。在[第十三章](ch13.xhtml#assembling_your_own_workspace_in_terra)中，我们讨论了在Terra中构建您的数据模型的选项，并有效地使用它来节省时间和精力。
- en: Selecting Data and Configuring the Full-Scale Workflow
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择数据并配置完整规模的工作流程
- en: As we’ve described previously, you can either head straight for the workflows
    page in the workspace or you can start the process from the Data page by selecting
    one or both samples in the *sample* table. (We recommend selecting both so you
    can experience the runtime difference of the plumbing test and the full-scale
    run for yourself.) If you choose to follow the same procedure as previously, click
    “Open with…” to choose the workflow option, and select the one workflow that is
    preconfigured in this workspace. Unless a lot has changed since the book came
    out, this should be the same, or practically the same, as the workflow that we
    examined in detail in [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows).
    However, you’ll notice that on the workflow page, you can view only the main WDL
    script, not any of the additional WDL files that contain the subworkflows and
    task libraries. This is a limitation of the current interface that will be addressed
    in future work.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所描述的，您可以直接进入工作区的工作流程页面，或者您可以从数据页面开始，通过选择*样本*表中的一个或两个样本来启动流程。（我们建议选择两者，这样您可以亲自体验管道测试和完整运行之间的运行时差异。）如果您选择按照之前的相同步骤操作，请点击“打开方式…”选择工作流选项，并选择预配置在此工作空间中的一个工作流程。除非自书籍出版以来有很多变化，否则这应该与我们在[第九章](ch09.xhtml#deciphering_real_genomics_workflows)中详细检查的工作流程相同或几乎相同。但是，您会注意到在工作流程页面上，您只能查看主要的WDL脚本，而不能查看包含子工作流和任务库的任何额外WDL文件。这是当前界面的一个限制，将在未来的工作中解决。
- en: We didn’t look at the inputs to this workflow in much detail when we dissected
    it in [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows), because at
    the time we were focused on understanding its internal plumbing. Now that we’re
    looking at them through the Terra interface, in the context of the workflow inputs
    configuration form, it’s pretty striking that it seems to have only four required
    inputs, which is fewer than the much simpler workflow we’ve been working with
    so far. However, this is mostly a distortion of reality; in fact, two of those
    four inputs represent a larger number of inputs that are bundled together using
    struct variables, which we encountered in [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows).
    These two structs represent the two most typical categories of inputs that you
    will frequently encounter in genomics workflows. One is a bundle of reference
    data, grouping the genome reference sequence, associated index files, and known
    variant resources for validation. The other groups the files that hold the actual
    data that you’re looking to process.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在[第9章](ch09.xhtml#deciphering_real_genomics_workflows)中解剖它时，我们并没有详细查看此工作流的输入，因为当时我们专注于理解其内部管道。现在通过Terra界面查看它们，在工作流输入配置表单的上下文中，我们发现它只有四个必填输入，比我们迄今为止处理的更简单的工作流少。然而，这在很大程度上是对现实的一种扭曲；事实上，这四个输入中的两个表示使用结构变量捆绑在一起的更多输入，我们在[第9章](ch09.xhtml#deciphering_real_genomics_workflows)中遇到过这种情况。这两个结构体代表你在基因组工作流中经常遇到的两种典型输入类别。一个是参考数据的捆绑，包括基因组参考序列、相关索引文件和用于验证的已知变异资源。另一个是包含你要处理的实际数据文件的文件组。
- en: Most of the optional inputs to this workflow are task-level runtime parameters
    and conditional checks, which are readily recognized by their type, Boolean. You
    might recall that in the first workflow we examined in [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows),
    we found a lot of conditional statements that defined settings like default runtime
    resource allocation. The optional inputs we see here are set up so that you can
    override those default settings when you configure the workflow; for example,
    if you have reason to believe that the defaults won’t be appropriate for your
    use case. Yet if you don’t know the first thing about what the runtime resource
    allocations should be, you can just leave those fields blank and trust that the
    presets will be good enough.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数此工作流的可选输入都是任务级运行时参数和条件检查，这些都是通过它们的布尔类型轻松识别的。你可能还记得，在我们在[第9章](ch09.xhtml#deciphering_real_genomics_workflows)中研究的第一个工作流中，我们找到了许多定义设置如默认运行时资源分配的条件语句。这里的可选输入设置是为了在配置工作流时可以覆盖这些默认设置；例如，如果你有理由认为默认设置对你的用例不合适。然而，如果你对运行时资源分配一无所知，你可以将这些字段留空，并相信预设值足够好。
- en: It’s also worth taking a quick peek at the Output tab, where you’ll be reminded
    that this workflow produces a ginormous number of outputs, which are mostly quality
    control-related metrics and reports. This is where we really appreciate being
    able to have the paths to the output files written to the data tables, which makes
    it a lot easier to find outputs than if you had to go rooting around in the Cromwell
    execution directories for each file. For the record, the outputs that you’re most
    likely to care about are the trio of `output_bam`, `output_cram`, and above all,
    `output_vcf`, which is the set of variant calls that you’ll want to use in downstream
    analysis.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得快速查看“输出”选项卡，在那里你会想起这个工作流生成了大量输出，其中大部分是与质量控制相关的指标和报告。这正是我们非常感激的地方，因为将输出文件的路径写入数据表格，使得查找输出比在每个文件的Cromwell执行目录中查找要容易得多。值得一提的是，你最关心的输出可能是`output_bam`、`output_cram`和最重要的`output_vcf`，后者是你希望在下游分析中使用的变异调用集。
- en: That being said, all of this should mostly be prefilled and ready to go, but
    on the Output tab, click “Use defaults” to set up the mapping of outputs to the
    sample table.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，所有这些内容应该大部分都是预填充并且准备就绪，但在“输出”选项卡上，点击“使用默认值”设置输出映射到样本表格。
- en: Launching the Full-Scale Workflow and Monitoring Execution
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动全面工作流和监控执行
- en: Enough talk, let’s run this thing! As previously, click Run Analysis and then
    Launch to submit the workflow for execution. You can follow the same steps as
    we described earlier to monitor the progress of your pipeline, but you should
    expect this to take quite a bit longer! As mentioned earlier, the Dashboard summary
    includes typical runtimes for the workflow running on both example datasets, so
    be sure to use that as a guide to gauge when to go check how it’s going. You can
    also browse the Job History of the original workspace (the one you cloned your
    copy from); it includes past executions, so you can look up the timing diagram
    there.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 言归正传，让我们运行这个东西！如前所述，点击“运行分析”，然后点击“启动”提交工作流程执行。您可以按照我们之前描述的相同步骤来监视管道的进展，但预计这将花费更长的时间！正如之前提到的，仪表板摘要包括工作流程在两个示例数据集上运行的典型运行时间，因此请确保将其用作衡量何时检查进度的指南。您还可以浏览原始工作区的作业历史记录（您从中克隆副本的那个），其中包括过去的执行，因此您可以在那里查看时序图。
- en: One new thing you might notice is that the List view of the workflow details
    page collapses subworkflows and displays their name in underlined font, as shown
    in [Figure 11-38](#the_list_view_of_the_task_calls_in_the). This is similar to
    the representation of scattered tasks but lacks the little stack icon on the side.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能注意到的一个新特点是工作流程详细信息页面的列表视图会折叠子工作流程，并以下划线字体显示它们的名称，如[图 11-38](#the_list_view_of_the_task_calls_in_the)所示。这类似于散列任务的表示，但缺少侧边的小堆栈图标。
- en: '![The List View of the task calls in the master workflow.](Images/gitc_1138.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![主工作流程中任务调用的列表视图。](Images/gitc_1138.png)'
- en: Figure 11-38\. The List View of the task calls in the master workflow.
  id: totrans-188
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 11-38\. 主工作流程中任务调用的列表视图。
- en: 'Have a look at the timing diagram provided at this level: you essentially get
    a high-level summary of the component segments of the workflow, as shown in [Figure 11-39](#the_timing_diagram_for_the_master_workf).
    If you hover over the various lines, you’ll see that the longest segment on the
    left corresponds to *UnmappedBamToAlignedBam*, the data processing subworkflow
    that takes in the raw unmapped data and outputs an analysis-ready BAM file. The
    next three lines consist of the main quality control subworkflow, *AggregatedBamQC*,
    and two metrics collection tasks that are not bundled into subworkflows. Next
    down is the `BamToGvcf` variant-calling subworkflow, which produces the final
    output of the per-ample pipeline, the GVCF file of variants. You’ll notice that
    those four segments all started at the same time, when the very first segment
    completed because they are independent of one another. This is parallelism in
    action! Finally, the last segment is the *BamToCram* workflow, which produces
    a CRAM file version of the processed sequencing data for archival purposes. The
    timing of that one might seem odd until you realize that it starts immediately
    after the *AggregatedBamQC* workflow finishes.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看此级别提供的时序图：您基本上会得到工作流程组成部分的高级摘要，如[图 11-39](#the_timing_diagram_for_the_master_workf)所示。如果您将鼠标悬停在各条线上，您将看到左侧最长的片段对应于*UnmappedBamToAlignedBam*，这是处理数据的子工作流程，接收原始未映射数据并输出准备好进行分析的BAM文件。接下来的三条线由主要的质量控制子工作流程*AggregatedBamQC*和两个未捆绑到子工作流程中的度量收集任务组成。下面是`BamToGvcf`变异调用子工作流程，它生成每个样本管道的最终输出，变异的GVCF文件。您会注意到这四个段落都在第一个段落完成时同时开始，因为它们彼此之间是独立的。这就是并行处理的实际应用！最后一个段落是*BamToCram*工作流程，它为归档目的生成已处理测序数据的CRAM文件版本。该段的时间安排可能看起来有些奇怪，直到您意识到它在*AggregatedBamQC*工作流程完成后立即开始。
- en: '![The timing diagram for the master workflow showing subworkflows (solid red
    bars) and individual tasks that are not bundled into subworkflows (multicolor
    bars).](Images/gitc_1139.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![主工作流程的时序图，显示子工作流程（实心红色条）和未捆绑到子工作流程中的单独任务（多色条）。](Images/gitc_1139.png)'
- en: Figure 11-39\. The timing diagram for the master workflow showing subworkflows
    (solid red bars) and individual tasks that are not bundled into subworkflows (multicolor
    bars).
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 11-39\. 主工作流程的时序图，显示子工作流程（实心红色条）和未捆绑到子工作流程中的单独任务（多色条）。
- en: Now go back to the List View and click through one of the subworkflows; for
    example, the `BamToGvcf` variant calling subworkflow. You’ll see it open up on
    its own page as if it were a standalone workflow, with its own list of tasks,
    timing diagram, and so on, as shown in [Figure 11-40](#the_workflow_details_page_for_the_bamto).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在返回到列表视图，点击其中一个子工作流，例如 `BamToGvcf` 变异调用子工作流。您将看到它会像独立工作流一样在自己的页面上打开，具有自己的任务列表、时间图等，如
    [图 11-40](#the_workflow_details_page_for_the_bamto) 所示。
- en: '![The workflow details page for the BamToGvcf subworkflow.](Images/gitc_1140.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![BamToGvcf 子工作流的工作流详情页面。](Images/gitc_1140.png)'
- en: Figure 11-40\. The workflow details page for the BamToGvcf subworkflow.
  id: totrans-194
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-40\. BamToGvcf 子工作流的工作流详情页面。
- en: There is theoretically no limit to how deeply you can nest WDL subworkflows,
    as long as you don’t create loops. In practice, though, we have not yet seen workflows
    with more than three levels of nesting (including task libraries). In any case,
    you can navigate back up to the parent workflow level by clicking the upward-pointing
    arrow in the upper-right corner.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，您可以无限嵌套 WDL 子工作流，只要不创建循环。但在实践中，我们尚未看到超过三级嵌套（包括任务库）的工作流。无论如何，您可以通过点击右上角的向上箭头导航回到父工作流水平。
- en: Finally, you can check that the outputs were produced as expected, both in the
    Job History view and in the *sample* data table, as we’ve described earlier in
    the chapter.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以检查输出是否按预期生成，无论是在作业历史视图中还是在*样本*数据表中，正如我们在本章前面描述的那样。
- en: Options for Downloading Output Data—or Not
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载输出数据的选项——或者不下载
- en: 'Whether you’re browsing the outputs of your workflow through the Job History
    page, or through either the data tables or the Files browser on the Data page,
    you can download any file by simply clicking its name or path. This brings up
    a small window that includes a preview of the file (if it’s in a readable text
    format), its size, and an estimate of the cost of the download, which is due to
    egress fees. In [Figure 11-41](#file_download_windows_showing_aright_pa), we have
    examples of such download windows for two kinds of files: the list of unmapped
    BAM files that served as input for the pipeline, which is a plain-text file and
    can therefore be previewed, and the GVCF that is the final data output of the
    pipeline, which is originally plain text, too, but here, was gzipped to require
    less storage space, and therefore cannot be previewed. That would also be the
    case for other compressed file formats like BAM and CRAM files, which also cannot
    be previewed.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是通过作业历史页面浏览工作流的输出，还是通过数据页面上的数据表或文件浏览器浏览，您都可以通过单击其名称或路径来下载任何文件。这将弹出一个小窗口，其中包括文件的预览（如果它是可读文本格式）、文件大小以及下载费用的估算，这是由于出站费用。在
    [图 11-41](#file_download_windows_showing_aright_pa) 中，我们展示了两种文件的下载窗口示例：作为流水线输入的未映射
    BAM 文件列表，这是一个纯文本文件，因此可以预览；以及作为流水线的最终数据输出的 GVCF，它原本也是纯文本，但这里经过 gzip 压缩以减少存储空间，因此无法预览。对于其他压缩文件格式如
    BAM 和 CRAM 文件，也同样无法预览。
- en: '![File download windows showing A) the list of unmapped BAM files, and B) the
    final GVCF output.](Images/gitc_1141.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![文件下载窗口显示 A) 未映射的 BAM 文件列表和 B) 最终的 GVCF 输出。](Images/gitc_1141.png)'
- en: Figure 11-41\. File download windows showing A) the list of unmapped BAM files,
    and B) the final GVCF output.
  id: totrans-200
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-41\. 文件下载窗口显示 A) 未映射的 BAM 文件列表和 B) 最终的 GVCF 输出。
- en: The download window offers three ways to download the file of interest. You
    can follow the link to the GCS console, where you can select multiple files and
    download them through your web browser. You can also simply click the blue Download
    button for that one file, which will also be downloaded by the web browser. Alternatively,
    you can copy the terminal download command, which includes the full path to the
    file’s location in GCS, to download the file with the command-line tool `gsutil`.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 下载窗口提供三种下载感兴趣文件的方式。您可以转到 GCS 控制台，选择多个文件并通过浏览器下载它们。您也可以直接点击蓝色的下载按钮下载该文件，浏览器也会自动下载它。或者，您可以复制终端下载命令，其中包括文件在
    GCS 中完整路径，使用命令行工具 `gsutil` 下载文件。
- en: The direct download option is fine for individual files that you want to look
    at quickly, especially if they’re small. For example, the 1.9 KB text file in
    [Figure 11-41](#file_download_windows_showing_aright_pa) is predicted to cost
    less than a penny to retrieve. If you need to retrieve multiple small to medium
    files like the 185 MB GVCF in [Figure 11-41](#file_download_windows_showing_aright_pa)
    (just two cents? sounds reasonable), you’ll usually be better off using either
    the GCP console or better yet, `gsutil`. But if you find yourself needing to retrieve
    large files (many gigabytes, many dollars), it might be worth pausing to rethink
    whether you really can’t do what you need to do without a local copy of the file.
    For example, were you planning to look at the BAM and VCF files in IGV to check
    some variant calls by eye? Remember, you can do that by connecting IGV to GCS.
    Or did you want to run another kind of analysis that you don’t have a workflow
    for, or that requires an interactive process? Ah, that’s fair…but maybe you could
    continue that work in the cloud rather than falling back to a local environment.
    Wouldn’t it be amazing if you could do *all* of your work in the cloud, from the
    raw data all the way to making the figures that are going to be in your paper?
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 直接下载选项适用于您想快速查看的单个文件，特别是如果它们很小的话。例如，[图 11-41](#file_download_windows_showing_aright_pa)中的1.9
    KB文本文件预计检索成本不到一分钱。如果您需要检索多个中小型文件，比如[图 11-41](#file_download_windows_showing_aright_pa)中的185
    MB GVCF文件（只需两分钱？听起来合理），通常最好使用GCP控制台或更好地使用`gsutil`。但是，如果您发现自己需要检索大文件（多个千兆字节，多个美元），也许值得停下来重新考虑，是否真的不能在没有本地文件副本的情况下完成所需操作。例如，您计划使用IGV查看BAM和VCF文件来检查某些变体调用吗？请记住，您可以通过将IGV连接到GCS来实现这一点。或者，您是否想要运行另一种需要工作流程的分析，或者需要交互过程？啊，这很公平……但也许您可以继续在云端完成这项工作，而不是回到本地环境。如果您能够从原始数据一直到制作论文中将出现的图形，都能在云端完成，那岂不是太神奇了？
- en: That is not a pipe dream. It’s already possible today—but you’re going to need
    something better than just the VM and something different from the workflow system.
    You will need an integrated environment for interactive analysis on the cloud,
    which Terra provides as well.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是一个空想。这已经是今天的现实——但是您需要的不仅仅是比虚拟机更好的东西，也不仅仅是不同于工作流系统的东西。您将需要一个集成环境，在云端进行交互式分析，而Terra也提供了这一点。
- en: Note
  id: totrans-204
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: The filename produced by the workflow uses a plain *.vcf* extension instead
    of *.g.vcf*, which is optional but recommended for signifying that a file is,
    in fact, a GVCF rather than a regular VCF file. This highlights the fact that
    you can rarely rely on filenames and extensions to know for sure what a file contains
    and how it was produced. Data management frameworks like the workspace data model
    can mitigate such problems by helping us keep track of the relationships between
    pieces of data.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程生成的文件名使用普通的*.vcf*扩展名，而不是*.g.vcf*，后者是可选的，但推荐用于标识文件是GVCF而不是常规VCF文件。这突显了一个事实，即您很少能够仅凭文件名和扩展名就确切知道文件包含的内容及其生成方式。工作空间数据模型等数据管理框架可以通过帮助我们跟踪数据片段之间的关系来缓解这类问题。
- en: Wrap-Up and Next Steps
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结与下一步
- en: For the past four chapters, including this one, we’ve been living and breathing
    for workflows. We started out small in [Chapter 8](ch08.xhtml#automating_analysis_execution_with_work),
    running canned WDL scripts on a single VM. Then, in [Chapter 9](ch09.xhtml#deciphering_real_genomics_workflows)
    we dissected real genomics workflows to learn what they did and how they were
    wired up. This led us to a better understanding of some of the requirements of
    such workflows, which are designed to take advantage of various cloud features
    including parallelism and burst capability.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的四章中，包括本章，我们一直在为工作流而奋斗。我们从[第8章](ch08.xhtml#automating_analysis_execution_with_work)开始小规模进行，运行在单个虚拟机上的WDL脚本。然后，在[第9章](ch09.xhtml#deciphering_real_genomics_workflows)中，我们解析了真实的基因组学工作流程，以了解它们的功能和如何配置。这使我们更好地理解了这些工作流的一些要求，这些工作流被设计用来利用各种云功能，包括并行性和突发能力。
- en: 'But that made us realize that we couldn’t continue running workflows on a single
    VM, even if we beefed up its resource allocations, so we moved to dispatching
    jobs to PAPI for execution in [Chapter 10](ch10.xhtml#running_single_workflows_at_scale_with).
    We experimented with two approaches for doing so: directly with Cromwell and through
    the WDL Runner wrapper, which showed us the power of PAPI but also showed us the
    limitations of launching a single workflow at a time.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这让我们意识到，即使加大资源配置，我们也不能继续在单个虚拟机上运行工作流程，因此我们转而将作业分派到 PAPI 以在[第十章](ch10.xhtml#running_single_workflows_at_scale_with)中执行。我们尝试了两种方法：直接使用
    Cromwell 和通过 WDL Runner 包装器进行，这展示了 PAPI 的强大之处，但也展示了一次只能启动单个工作流程的局限性。
- en: Finally, we moved to Terra in this chapter to use its built-in, full-featured
    Cromwell server. We were able to take advantage of some of the Cromwell server’s
    coolest features, like the vaunted call caching mechanism and the timing diagram,
    without worrying for a second about server maintenance. Along the way, we also
    encountered unexpected benefits of using Terra, mainly thanks to the integration
    of data management with workflow execution. Having learned to launch a workflow
    on rows in a data table, we’re now able to process arbitrary amounts of data without
    breaking a sweat. And we know how to get the outputs to be added to the table
    automatically, so we don’t need to go digging for them.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在本章中我们转向 Terra，以使用其内置的全功能 Cromwell 服务器。我们能够利用 Cromwell 服务器的一些最酷的功能，比如著名的调用缓存机制和时间图，而不需要为服务器维护担忧。在此过程中，我们还遇到了使用
    Terra 的意外好处，主要归功于数据管理与工作流执行的集成。通过学会在数据表中的行上启动工作流程，我们现在能够轻松处理任意数量的数据。而且我们知道如何让输出自动添加到表中，所以不需要费力去查找它们。
- en: While explaining all this, we might have implied that applying the GATK Best
    Practices to your own data should now “simply” be a matter of running the workflows
    as demonstrated. However, in the course of a real genomic study, you’ll typically
    need to perform a variety of peripheral tasks that aren’t so conveniently packaged
    into workflows. Whether for testing commands, evaluating the quality of results,
    or troubleshooting errors, you’ll need to be able to interact with the data in
    a more immediate way. That will be even more the case if your work responsibilities
    extend beyond what we defined very narrowly as genomics (i.e., variant discovery)
    to include developing and testing hypotheses to answer specific scientific or
    clinical questions.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释所有这些内容时，我们可能暗示应用 GATK 最佳实践到您自己的数据中现在应该只是运行我们演示的工作流程的问题。然而，在进行真正的基因组研究过程中，您通常需要执行各种不方便包装为工作流程的外围任务。无论是用于测试命令、评估结果质量还是解决错误，您都需要以更即时的方式与数据进行交互。如果您的工作职责超出了我们狭义定义的基因组学（即变异发现），包括开发和测试以回答特定科学或临床问题的假设，那情况将更是如此。
- en: In [Chapter 12](ch12.xhtml#interactive_analysis_in_jupyter_noteboo), we use
    a popular environment for interactive analysis that also happens to do wonders
    for reproducible science, called Jupyter. We’ll still be working within the Terra
    platform, which hosts a scalable system for serving Jupyter in the cloud.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第十二章](ch12.xhtml#interactive_analysis_in_jupyter_noteboo)中，我们使用了一个流行的交互式分析环境，它也对可重复科学有奇效，称为
    Jupyter。我们仍然在 Terra 平台内工作，该平台为在云中提供 Jupyter 提供了可扩展的系统。
