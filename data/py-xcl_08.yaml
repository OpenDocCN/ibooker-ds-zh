- en: Chapter 6\. Time Series Analysis with pandas
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第六章 pandas 时间序列分析
- en: 'A time series is a series of data points along a time-based axis that plays
    a central role in many different scenarios: while traders use historical stock
    prices to calculate risk measures, the weather forecast is based on time series
    generated by sensors measuring temperature, humidity, and air pressure. And the
    digital marketing department relies on time series generated by web pages, e.g.,
    the source and number of page views per hour, and will use them to draw conclusions
    with regard to their marketing campaigns.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列是沿着基于时间的轴的一系列数据点，在许多不同的场景中发挥着核心作用：交易员使用历史股票价格来计算风险度量，天气预报基于传感器生成的时间序列，这些传感器测量温度、湿度和气压。数字营销部门依赖于由网页生成的时间序列，例如每小时的页面浏览量的来源和数量，并将其用于从中得出关于其营销活动的结论。
- en: 'Time series analysis is one of the main driving forces why data scientists
    and analysts have started to look for a better alternative to Excel. The following
    points summarize some of the reasons behind this move:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分析是数据科学家和分析师开始寻找比Excel更好的替代方案的主要推动力之一。以下几点总结了这一举措背后的一些原因：
- en: Big datasets
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 大型数据集
- en: Time series can quickly grow beyond Excel’s limit of roughly one million rows
    per sheet. For example, if you work with intraday stock prices on a tick data
    level, you’re often dealing with hundreds of thousands of records—per stock and
    day!
  id: totrans-4
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 时间序列往往会快速超出Excel每个工作表大约一百万行的限制。例如，如果你在tick数据级别上处理股票的分钟价格，你通常会处理数十万条记录——每支股票每天！
- en: Date and time
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 日期和时间
- en: As we have seen in [Chapter 3](index_split_010.html#filepos178328), Excel has
    various limitations when it comes to handling date and time, the backbone of time
    series. Missing support for time zones and a number format that is limited to
    milliseconds are some of them. pandas supports time zones and uses NumPy’s `datetime64[ns]`
    data type, which offers a resolution in up to nanoseconds.
  id: totrans-6
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 正如我们在[第三章](index_split_010.html#filepos178328)中所看到的，Excel在处理日期和时间时存在各种限制，这是时间序列的基础。缺少对时区的支持以及仅限于毫秒的数字格式是其中一些限制。pandas支持时区，并使用NumPy的`datetime64[ns]`数据类型，该类型可提供高达纳秒的分辨率。
- en: Missing functionality
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失的功能
- en: Excel misses even basic tools to be able to work with time series data in a
    decent way. For example, if you want to turn a daily time series into a monthly
    time series, there is no easy way of doing this despite it being a very common
    task.
  id: totrans-8
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Excel甚至缺乏基本工具，无法以体面的方式处理时间序列数据。例如，如果你想将每日时间序列转换为每月时间序列，尽管这是一项非常常见的任务，但却没有简单的方法来实现这一点。
- en: 'DataFrames allow you to work with various time-based indices: `DatetimeIndex`
    is the most common one and represents an index with timestamps. Other index types,
    like `PeriodIndex`, are based on time intervals such as hours or months. In this
    chapter, however, we are only looking at `DatetimeIndex`, which I will introduce
    now in more detail.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrames允许你使用各种基于时间的索引：`DatetimeIndex`是最常见的一个，表示一个带有时间戳的索引。其他索引类型，比如`PeriodIndex`，基于时间间隔，比如小时或月份。然而，在本章中，我们只关注`DatetimeIndex`，我将在接下来更详细地介绍它。
- en: DatetimeIndex
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: DatetimeIndex
- en: In this section, we’ll learn how to construct a `DatetimeIndex`, how to filter
    such an index to a specific time range, and how to work with time zones.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何构建一个`DatetimeIndex`，如何将这样的索引筛选到特定的时间范围，并如何处理时区。
- en: Creating a DatetimeIndex
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个DatetimeIndex
- en: 'To construct a `DatetimeIndex`, pandas offers the `date_range` function. It
    accepts a start date, a frequency, and either the number of periods or the end
    date:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个`DatetimeIndex`，pandas提供了`date_range`函数。它接受一个开始日期、一个频率，以及要么周期数，要么结束日期：
- en: '`In``[``1``]:``# Let''s start by importing the packages we use in this chapter``#
    and by setting the plotting backend to Plotly``import``pandas``as``pd``import``numpy``as``np``pd``.``options``.``plotting``.``backend``=``"plotly"`'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``1``]:``# 让我们从导入本章中使用的包开始``# 并将绘图后端设置为Plotly``import``pandas``as``pd``import``numpy``as``np``pd``.``options``.``plotting``.``backend``=``"plotly"`'
- en: '`In``[``2``]:``# This creates a DatetimeIndex based on a start timestamp,``#
    number of periods and frequency ("D" = daily).``daily_index``=``pd``.``date_range``(``"2020-02-28"``,``periods``=``4``,``freq``=``"D"``)``daily_index`'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``2``]:``# 这将根据开始时间戳、周期数和频率（"D" = daily）创建一个DatetimeIndex。``daily_index``=``pd``.``date_range``(``"2020-02-28"``,``periods``=``4``,``freq``=``"D"``)``daily_index`'
- en: '`Out[2]: DatetimeIndex([''2020-02-28'', ''2020-02-29'', ''2020-03-01'', ''2020-03-02''],
             dtype=''datetime64[ns]'', freq=''D'')`'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[2]: DatetimeIndex([''2020-02-28'', ''2020-02-29'', ''2020-03-01'', ''2020-03-02''],
             dtype=''datetime64[ns]'', freq=''D'')`'
- en: '`In``[``3``]:``# This creates a DatetimeIndex based on start/end timestamp.``#
    The frequency is set to "weekly on Sundays" ("W-SUN").``weekly_index``=``pd``.``date_range``(``"2020-01-01"``,``"2020-01-31"``,``freq``=``"W-SUN"``)``weekly_index`'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``3``]:``# 根据起始/结束时间戳创建DatetimeIndex。频率设置为每周日一次 ("W-SUN")。``weekly_index``=``pd``.``date_range``(``"2020-01-01"``,``"2020-01-31"``,``freq``=``"W-SUN"``)``weekly_index`'
- en: '`Out[3]: DatetimeIndex([''2020-01-05'', ''2020-01-12'', ''2020-01-19'', ''2020-01-26''],
             dtype=''datetime64[ns]'', freq=''W-SUN'')`'
  id: totrans-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[3]: DatetimeIndex([''2020-01-05'', ''2020-01-12'', ''2020-01-19'', ''2020-01-26''],
             dtype=''datetime64[ns]'', freq=''W-SUN'')`'
- en: '`In``[``4``]:``# Construct a DataFrame based on the weekly_index. This could
    be``# the visitor count of a museum that only opens on Sundays.``pd``.``DataFrame``(``data``=``[``21``,``15``,``33``,``34``],``columns``=``[``"visitors"``],``index``=``weekly_index``)`'
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``4``]:``# 基于weekly_index构建DataFrame。这可以是只在星期日开放的博物馆的访客计数。``pd``.``DataFrame``(``data``=``[``21``,``15``,``33``,``34``],``columns``=``[``"visitors"``],``index``=``weekly_index``)`'
- en: '`Out[4]:             visitors         2020-01-05        21         2020-01-12       
    15         2020-01-19        33         2020-01-26        34`'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[4]:             visitors         2020-01-05        21         2020-01-12       
    15         2020-01-19        33         2020-01-26        34`'
- en: 'Let’s now return to the Microsoft stock time series from the last chapter.
    When you take a closer look at the data types of the columns, you will notice
    that the `Date` column has the type `object`, which means that pandas has interpreted
    the timestamps as strings:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们回到上一章的微软股票时间序列。当您仔细查看列的数据类型时，您会注意到`Date`列的类型是`object`，这意味着pandas将时间戳解释为字符串：
- en: '`In``[``5``]:``msft``=``pd``.``read_csv``(``"csv/MSFT.csv"``)`'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``5``]:``msft``=``pd``.``read_csv``(``"csv/MSFT.csv"``)`'
- en: '`In``[``6``]:``msft``.``info``()`'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``6``]:``msft``.``info``()`'
- en: '`<class ''pandas.core.frame.DataFrame''> RangeIndex: 8622 entries, 0 to 8621
    Data columns (total 7 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   Date       8622 non-null   object 1   Open       8622
    non-null   float64 2   High       8622 non-null   float64 3   Low        8622
    non-null   float64 4   Close      8622 non-null   float64 5   Adj Close  8622
    non-null   float64 6   Volume     8622 non-null   int64 dtypes: float64(5), int64(1),
    object(1) memory usage: 471.6+ KB`'
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`<class ''pandas.core.frame.DataFrame''> RangeIndex: 8622 entries, 0 to 8621
    Data columns (total 7 columns): #   Column     Non-Null Count  Dtype ---  ------    
    --------------  ----- 0   Date       8622 non-null   object 1   Open       8622
    non-null   float64 2   High       8622 non-null   float64 3   Low        8622
    non-null   float64 4   Close      8622 non-null   float64 5   Adj Close  8622
    non-null   float64 6   Volume     8622 non-null   int64 dtypes: float64(5), int64(1),
    object(1) memory usage: 471.6+ KB`'
- en: 'There are two ways to fix this and turn it into a `datetime` data type. The
    first one is to run the `to_datetime` function on that column. Make sure to assign
    the transformed column back to the original DataFrame if you want to change it
    at the source:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以修复这个问题并将其转换为`datetime`数据类型。第一种方法是在该列上运行`to_datetime`函数。如果您希望在源数据框中更改它，请确保将转换后的列重新赋值给原始DataFrame：
- en: '`In``[``7``]:``msft``.``loc``[:,``"Date"``]``=``pd``.``to_datetime``(``msft``[``"Date"``])`'
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``7``]:``msft``.``loc``[:,``"Date"``]``=``pd``.``to_datetime``(``msft``[``"Date"``])`'
- en: '`In``[``8``]:``msft``.``dtypes`'
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``8``]:``msft``.``dtypes`'
- en: '`Out[8]: Date         datetime64[ns]         Open                float64        
    High                float64         Low                 float64         Close              
    float64         Adj Close           float64         Volume                int64
            dtype: object`'
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[8]: Date         datetime64[ns]         Open                float64        
    High                float64         Low                 float64         Close              
    float64         Adj Close           float64         Volume                int64
            dtype: object`'
- en: 'The other possibility is to tell `read_csv` about the columns that contain
    timestamps by using the `parse_dates` argument. `parse_dates` expects a list of
    column names or indices. Also, you almost always want to turn timestamps into
    the index of the DataFrame since this will allow you to filter the data easily,
    as we will see in a moment. To spare yourself an extra `set_index` call, provide
    the column you would like to use as index via the `index_col` argument, again
    as column name or index:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可能性是告诉`read_csv`哪些列包含时间戳，使用`parse_dates`参数。`parse_dates`需要一个列名或索引的列表。此外，您几乎总是希望将时间戳转换为DataFrame的索引，因为这将使您能够轻松地过滤数据，稍后我们将看到。为了避免额外的`set_index`调用，请通过`index_col`参数提供您希望用作索引的列名或索引：
- en: '`In``[``9``]:``msft``=``pd``.``read_csv``(``"csv/MSFT.csv"``,``index_col``=``"Date"``,``parse_dates``=``[``"Date"``])`'
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``9``]:``msft``=``pd``.``read_csv``(``"csv/MSFT.csv"``,``index_col``=``"Date"``,``parse_dates``=``[``"Date"``])`'
- en: '`In``[``10``]:``msft``.``info``()`'
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``10``]:``msft``.``info``()`'
- en: '`<class ''pandas.core.frame.DataFrame''> DatetimeIndex: 8622 entries, 1986-03-13
    to 2020-05-27 Data columns (total 6 columns): #   Column     Non-Null Count  Dtype
    ---  ------     --------------  ----- 0   Open       8622 non-null   float64 1  
    High       8622 non-null   float64 2   Low        8622 non-null   float64 3  
    Close      8622 non-null   float64 4   Adj Close  8622 non-null   float64 5  
    Volume     8622 non-null   int64 dtypes: float64(5), int64(1) memory usage: 471.5
    KB`'
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`<class ''pandas.core.frame.DataFrame''> DatetimeIndex: 8622 entries, 1986-03-13
    to 2020-05-27 Data columns (total 6 columns): #   Column     Non-Null Count  Dtype
    ---  ------     --------------  ----- 0   Open       8622 non-null   float64 1  
    High       8622 non-null   float64 2   Low        8622 non-null   float64 3  
    Close      8622 non-null   float64 4   Adj Close  8622 non-null   float64 5  
    Volume     8622 non-null   int64 dtypes: float64(5), int64(1) memory usage: 471.5
    KB`'
- en: 'As `info` reveals, you are now dealing with a DataFrame that has a `DatetimeIndex`.
    If you would need to change another data type (let’s say you wanted `Volume` to
    be a `float` instead of an `int`), you again have two options: either provide
    `dtype={"Volume": float}` as argument to the `read_csv` function, or apply the
    `astype` method as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '正如`info`所显示的，你现在正在处理一个具有`DatetimeIndex`的DataFrame。如果你需要更改另一个数据类型（比如你想要`Volume`是`float`而不是`int`），你有两个选项：要么将`dtype={"Volume":
    float}`作为参数提供给`read_csv`函数，要么像下面这样应用`astype`方法：'
- en: '`In``[``11``]:``msft``.``loc``[:,``"Volume"``]``=``msft``[``"Volume"``]``.``astype``(``"float"``)``msft``[``"Volume"``]``.``dtype`'
  id: totrans-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``11``]:``msft``.``loc``[:,``"Volume"``]``=``msft``[``"Volume"``]``.``astype``(``"float"``)``msft``[``"Volume"``]``.``dtype`'
- en: '`Out[11]: dtype(''float64'')`'
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[11]: dtype(''float64'')`'
- en: 'With time series, it’s always a good idea to make sure the index is sorted
    properly before starting your analysis:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理时间序列时，在开始分析之前，确保索引已经正确排序是个好主意：
- en: '`In``[``12``]:``msft``=``msft``.``sort_index``()`'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``12``]:``msft``=``msft``.``sort_index``()`'
- en: 'And finally, if you need to access only parts of a `DatetimeIndex`, like the
    date part without the time, access the `date` attribute like this:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果你需要访问`DatetimeIndex`的部分，比如只需要日期部分而不需要时间，可以像这样访问`date`属性：
- en: '`In``[``13``]:``msft``.``index``.``date`'
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``13``]:``msft``.``index``.``date`'
- en: '`Out[13]: array([datetime.date(1986, 3, 13), datetime.date(1986, 3, 14),                
    datetime.date(1986, 3, 17), ..., datetime.date(2020, 5, 22),                 datetime.date(2020,
    5, 26), datetime.date(2020, 5, 27)],                dtype=object)`'
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[13]: array([datetime.date(1986, 3, 13), datetime.date(1986, 3, 14),                
    datetime.date(1986, 3, 17), ..., datetime.date(2020, 5, 22),                 datetime.date(2020,
    5, 26), datetime.date(2020, 5, 27)],                dtype=object)`'
- en: Instead of `date`, you can also use parts of a date like `year`, `month`, `day`,
    etc. To access the same functionality on a regular column with data type `datetime`,
    you will have to use the `dt` attribute, e.g., `df["column_name"].dt.date`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 替代`date`，你也可以使用日期的部分，比如`year`、`month`、`day`等。要访问具有数据类型`datetime`的常规列上的相同功能，你需要使用`dt`属性，例如`df["column_name"].dt.date`。
- en: With a sorted `DatetimeIndex`, let’s see how we can filter the DataFrame to
    certain time periods!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 有了排序的`DatetimeIndex`，让我们看看如何筛选DataFrame来选择特定的时间段！
- en: Filtering a DatetimeIndex
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 筛选`DatetimeIndex`
- en: 'If your DataFrame has a `DatetimeIndex`, there is an easy way to select rows
    from a specific time period by using `loc` with a string in the format `YYYY-MM-DD
    HH:MM:SS`. pandas will turn this string into a slice so it covers the whole period.
    For example, to select all rows from 2019, provide the year as a string, not a
    number:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的DataFrame具有`DatetimeIndex`，可以通过使用格式为`YYYY-MM-DD HH:MM:SS`的字符串在`loc`中选择特定时间段的行。pandas会将此字符串转换为切片，以涵盖整个时间段。例如，要选择2019年的所有行，请提供年份作为字符串，而不是数字：
- en: '`In``[``14``]:``msft``.``loc``[``"2019"``,``"Adj Close"``]`'
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``14``]:``msft``.``loc``[``"2019"``,``"Adj Close"``]`'
- en: '`Out[14]: Date          2019-01-02     99.099190          2019-01-03     95.453529
             2019-01-04     99.893005          2019-01-07    100.020401          2019-01-08   
    100.745613                           ...          2019-12-24    156.515396         
    2019-12-26    157.798309          2019-12-27    158.086731          2019-12-30   
    156.724243          2019-12-31    156.833633          Name: Adj Close, Length:
    252, dtype: float64`'
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[14]: Date          2019-01-02     99.099190          2019-01-03     95.453529
             2019-01-04     99.893005          2019-01-07    100.020401          2019-01-08   
    100.745613                           ...          2019-12-24    156.515396         
    2019-12-26    157.798309          2019-12-27    158.086731          2019-12-30   
    156.724243          2019-12-31    156.833633          Name: Adj Close, Length:
    252, dtype: float64`'
- en: 'Let’s take this a step further and plot the data between June 2019 and May
    2020 (see [Figure 6-1](#filepos798528)):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更进一步，绘制2019年6月至2020年5月之间的数据（见[图表 6-1](#filepos798528)）：
- en: '`In``[``15``]:``msft``.``loc``[``"2019-06"``:``"2020-05"``,``"Adj Close"``]``.``plot``()`'
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``15``]:``msft``.``loc``[``"2019-06"``:``"2020-05"``,``"Adj Close"``]``.``plot``()`'
- en: '![](images/00028.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00028.jpg)'
- en: Figure 6-1\. Adjusted close price for MSFT
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 6-1\. MSFT的调整收盘价
- en: Hover over the Plotly chart to read off the value as a tooltip and zoom in by
    drawing a rectangle with your mouse. Double-click the chart to get back to the
    default view.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 将鼠标悬停在Plotly图表上以读取提示信息，并通过鼠标绘制矩形来放大。双击图表以返回默认视图。
- en: We’ll use the adjusted close price in the next section to learn about time zone
    handling.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将使用调整后的收盘价来了解时区处理。
- en: Working with Time Zones
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 处理时区
- en: 'Microsoft is listed on the Nasdaq stock exchange. The Nasdaq is in New York
    and markets close at 4:00 p.m. To add this additional information to the DataFrame’s
    index, first add the closing hour to the date via `DateOffset`, then attach the
    correct time zone to the timestamps via `tz_localize`. Since the closing hour
    is only applicable to the close price, let’s create a new DataFrame with it:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 微软在纳斯达克证券交易所上市。纳斯达克位于纽约，市场在下午4点关闭。要将此附加信息添加到DataFrame的索引中，首先通过`DateOffset`将收盘小时添加到日期中，然后通过`tz_localize`将正确的时区附加到时间戳中。由于收盘时间仅适用于收盘价，让我们创建一个新的DataFrame：
- en: '`In``[``16``]:``# Add the time information to the date``msft_close``=``msft``.``loc``[:,``[``"Adj
    Close"``]]``.``copy``()``msft_close``.``index``=``msft_close``.``index``+``pd``.``DateOffset``(``hours``=``16``)``msft_close``.``head``(``2``)`'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``16``]:``# 将时间信息添加到日期中``msft_close``=``msft``.``loc``[:,``[``"Adj Close"``]]``.``copy``()``msft_close``.``index``=``msft_close``.``index``+``pd``.``DateOffset``(``hours``=``16``)``msft_close``.``head``(``2``)`'
- en: '`Out[16]:                      Adj Close          Date          1986-03-13
    16:00:00   0.062205          1986-03-14 16:00:00   0.064427`'
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[16]:                      Adj Close          Date          1986-03-13
    16:00:00   0.062205          1986-03-14 16:00:00   0.064427`'
- en: '`In``[``17``]:``# Make the timestamps time-zone-aware``msft_close``=``msft_close``.``tz_localize``(``"America/New_York"``)``msft_close``.``head``(``2``)`'
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``17``]:``# 将时间戳转换为时区感知时间``msft_close``=``msft_close``.``tz_localize``(``"America/New_York"``)``msft_close``.``head``(``2``)`'
- en: '`Out[17]:                            Adj Close          Date          1986-03-13
    16:00:00-05:00   0.062205          1986-03-14 16:00:00-05:00   0.064427`'
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[17]:                            Adj Close          Date          1986-03-13
    16:00:00-05:00   0.062205          1986-03-14 16:00:00-05:00   0.064427`'
- en: 'If you want to convert the timestamps to UTC time zone, use the DataFrame method
    `tz_convert`. UTC stands for Coordinated Universal Time and is the successor of
    Greenwich Mean Time (GMT). Note how the closing hours change in UTC depending
    on whether daylight saving time (DST) is in effect or not in New York:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想将时间戳转换为UTC时区，请使用DataFrame方法`tz_convert`。UTC代表协调世界时，是格林威治标准时间（GMT）的继任者。请注意，根据纽约是否实行夏令时（DST），UTC中的收盘时间会发生变化：
- en: '`In``[``18``]:``msft_close``=``msft_close``.``tz_convert``(``"UTC"``)``msft_close``.``loc``[``"2020-01-02"``,``"Adj
    Close"``]``# 21:00 without DST`'
  id: totrans-60
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``18``]:``msft_close``=``msft_close``.``tz_convert``(``"UTC"``)``msft_close``.``loc``[``"2020-01-02"``,``"Adj
    Close"``]``# 21:00 没有夏令时`'
- en: '`Out[18]: Date          2020-01-02 21:00:00+00:00    159.737595          Name:
    Adj Close, dtype: float64`'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[18]: Date          2020-01-02 21:00:00+00:00    159.737595          Name:
    Adj Close, dtype: float64`'
- en: '`In``[``19``]:``msft_close``.``loc``[``"2020-05-01"``,``"Adj Close"``]``# 20:00
    with DST`'
  id: totrans-62
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``19``]:``msft_close``.``loc``[``"2020-05-01"``,``"Adj Close"``]``# 20:00
    包含夏令时`'
- en: '`Out[19]: Date          2020-05-01 20:00:00+00:00    174.085175          Name:
    Adj Close, dtype: float64`'
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[19]: Date          2020-05-01 20:00:00+00:00    174.085175          Name:
    Adj Close, dtype: float64`'
- en: Preparing time series like this will allow you to compare close prices from
    stock exchanges across different time zones even if the time info is missing or
    stated in the local time zone.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 准备这样的时间序列将允许您即使时间信息缺失或以本地时区陈述，也能比较来自不同时区证券交易所的收盘价。
- en: Now that you know what a `DatetimeIndex` is, let’s try out a few common time
    series manipulations in the next section by calculating and comparing stock performance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了什么是`DatetimeIndex`，让我们在下一节中尝试一些常见的时间序列操作，例如计算和比较股票表现。
- en: Common Time Series Manipulations
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的时间序列操作
- en: In this section, I’ll show you how to perform common time series analysis tasks
    such as calculating stock returns, plotting the performance of various stocks,
    and visualizing the correlation of their returns in a heatmap. We’ll also see
    how to change the frequency of time series and how to calculate rolling statistics.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将向您展示如何执行常见的时间序列分析任务，例如计算股票回报率、绘制各种股票的表现，并在热图中可视化它们的回报相关性。我们还将看到如何更改时间序列的频率以及如何计算滚动统计数据。
- en: Shifting and Percentage Changes
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Shifting and Percentage Changes
- en: In finance, the log returns of stocks are often assumed to be normally distributed.
    By log returns, I mean the natural logarithm of the ratio of the current and previous
    price. To get a feeling for the distribution of the daily log returns, let’s plot
    a histogram. First, however, we need to calculate the log returns. In Excel, it’s
    typically done with a formula that involves cells from two rows, as shown in [Figure 6-2](#filepos810136).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域，股票的对数收益率通常被假设为正态分布。通过对数收益率，我指的是当前价格与上一个价格的比率的自然对数。为了对每日对数收益率的分布有所了解，让我们绘制一个直方图。但首先，我们需要计算对数收益率。在Excel中，通常使用涉及来自两行的单元格的公式，如[图 6-2](#filepos810136)所示。
- en: '![](images/00036.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00036.jpg)'
- en: Figure 6-2\. Calculating log returns in Excel
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6-2\. 在Excel中计算对数收益率
- en: LOGARITHMS IN EXCEL AND PYTHON
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Excel和Python中的对数
- en: Excel uses `LN` to denote the natural logarithm and `LOG` for the logarithm
    with base 10\. Python’s math module and NumPy, however, use `log` for the natural
    logarithm and `log10` for the logarithm with base 10.
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Excel使用`LN`表示自然对数，`LOG`表示以10为底的对数。然而，Python的math模块和NumPy使用`log`表示自然对数，`log10`表示以10为底的对数。
- en: 'With pandas, rather than having a formula accessing two different rows, you
    use the `shift` method to shift the values down by one row. This allows you to
    operate on a single row so your calculations can make use of vectorization. `shift`
    accepts a positive or negative integer that shifts the time series down or up
    by the respective number of rows. Let’s first see how `shift` works:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用pandas，而不是使用一个访问两个不同行的公式，你可以使用`shift`方法将值向下移动一行。这样可以让你在单个行上操作，因此你的计算可以利用矢量化。`shift`接受一个正数或负数，将时间序列向下或向上移动相应数量的行。让我们首先看看`shift`如何工作：
- en: '`In``[``20``]:``msft_close``.``head``()`'
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``20``]:``msft_close``.``head``()`'
- en: '`Out[20]:                            Adj Close          Date          1986-03-13
    21:00:00+00:00   0.062205          1986-03-14 21:00:00+00:00   0.064427         
    1986-03-17 21:00:00+00:00   0.065537          1986-03-18 21:00:00+00:00   0.063871
             1986-03-19 21:00:00+00:00   0.062760`'
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[20]:                            调整后收盘价          日期          1986-03-13
    21:00:00+00:00   0.062205          1986-03-14 21:00:00+00:00   0.064427         
    1986-03-17 21:00:00+00:00   0.065537          1986-03-18 21:00:00+00:00   0.063871
             1986-03-19 21:00:00+00:00   0.062760`'
- en: '`In``[``21``]:``msft_close``.``shift``(``1``)``.``head``()`'
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``21``]:``msft_close``.``shift``(``1``)``.``head``()`'
- en: '`Out[21]:                            Adj Close          Date          1986-03-13
    21:00:00+00:00        NaN          1986-03-14 21:00:00+00:00   0.062205         
    1986-03-17 21:00:00+00:00   0.064427          1986-03-18 21:00:00+00:00   0.065537
             1986-03-19 21:00:00+00:00   0.063871`'
  id: totrans-78
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[21]:                            调整后收盘价          日期          1986-03-13
    21:00:00+00:00        NaN          1986-03-14 21:00:00+00:00   0.062205         
    1986-03-17 21:00:00+00:00   0.064427          1986-03-18 21:00:00+00:00   0.065537
             1986-03-19 21:00:00+00:00   0.063871`'
- en: 'You are now able to write a single vector-based formula that is easy to read
    and understand. To get the natural logarithm, use NumPy’s `log` ufunc, which is
    applied to each element. Then we can plot a histogram (see [Figure 6-3](#filepos818582)):'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以编写一个简单的基于向量的公式，易于阅读和理解。要获取自然对数，请使用NumPy的`log` ufunc，它应用于每个元素。然后我们可以绘制直方图（见[图 6-3](#filepos818582)）：
- en: '`In``[``22``]:``returns``=``np``.``log``(``msft_close``/``msft_close``.``shift``(``1``))``returns``=``returns``.``rename``(``columns``=``{``"Adj
    Close"``:``"returns"``})``returns``.``head``()`'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``22``]:``returns``=``np``.``log``(``msft_close``/``msft_close``.``shift``(``1``))``returns``=``returns``.``rename``(``columns``=``{``"Adj
    Close"``:``"returns"``})``returns``.``head``()`'
- en: '`Out[22]:                             returns          Date          1986-03-13
    21:00:00+00:00       NaN          1986-03-14 21:00:00+00:00  0.035097         
    1986-03-17 21:00:00+00:00  0.017082          1986-03-18 21:00:00+00:00 -0.025749
             1986-03-19 21:00:00+00:00 -0.017547`'
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[22]:                             returns          日期          1986-03-13
    21:00:00+00:00       NaN          1986-03-14 21:00:00+00:00  0.035097         
    1986-03-17 21:00:00+00:00  0.017082          1986-03-18 21:00:00+00:00 -0.025749
             1986-03-19 21:00:00+00:00 -0.017547`'
- en: '`In``[``23``]:``# Plot a histogram with the daily log returns``returns``.``plot``.``hist``()`'
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``23``]:``# 用每日对数收益率绘制直方图``returns``.``plot``.``hist``()`'
- en: '![](images/00045.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00045.jpg)'
- en: Figure 6-3\. Histogram plot
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6-3\. 直方图绘制
- en: 'To get simple returns instead, use pandas’ built-in `pct_change` method. By
    default, it calculates the percentage change from the previous row, which is also
    the definition of simple returns:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得简单的收益率，使用pandas内置的`pct_change`方法。默认情况下，它计算与上一行的百分比变化，这也是简单收益率的定义：
- en: '`In``[``24``]:``simple_rets``=``msft_close``.``pct_change``()``simple_rets``=``simple_rets``.``rename``(``columns``=``{``"Adj
    Close"``:``"simple rets"``})``simple_rets``.``head``()`'
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``24``]:``simple_rets``=``msft_close``.``pct_change``()``simple_rets``=``simple_rets``.``rename``(``columns``=``{``"Adj
    Close"``:``"简单回报"``})``simple_rets``.``head``()`'
- en: '`Out[24]:                            simple rets          Date          1986-03-13
    21:00:00+00:00          NaN          1986-03-14 21:00:00+00:00     0.035721         
    1986-03-17 21:00:00+00:00     0.017229          1986-03-18 21:00:00+00:00    -0.025421
             1986-03-19 21:00:00+00:00    -0.017394`'
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[24]:                           简单回报          日期          1986-03-13 21:00:00+00:00         
    NaN          1986-03-14 21:00:00+00:00     0.035721          1986-03-17 21:00:00+00:00    
    0.017229          1986-03-18 21:00:00+00:00    -0.025421          1986-03-19 21:00:00+00:00   
    -0.017394`'
- en: So far, we have looked at just the Microsoft stock. In the next section, we’re
    going to load more time series so we can have a look at other DataFrame methods
    that require multiple time series.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只看过微软股票。在下一节中，我们将加载更多时间序列，以便查看需要多个时间序列的其他数据框方法。
- en: Rebasing and Correlation
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 重新基准化和相关性
- en: 'Things get slightly more interesting when we work with more than one time series.
    Let’s load a few additional adjusted close prices for Amazon (`AMZN`), Google
    (`GOOGL`), and Apple (`AAPL`), also downloaded from Yahoo! Finance:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处理多个时间序列时，情况会变得稍微有趣。让我们加载亚马逊（`AMZN`）、谷歌（`GOOGL`）和苹果（`AAPL`）的一些额外调整后的收盘价格，这些数据也是从
    Yahoo! Finance 下载的。
- en: '`In``[``25``]:``parts``=``[]``# List to collect individual DataFrames``for``ticker``in``[``"AAPL"``,``"AMZN"``,``"GOOGL"``,``"MSFT"``]:``#
    "usecols" allows us to only read in the Date and Adj Close``adj_close``=``pd``.``read_csv``(``f``"csv/{ticker}.csv"``,``index_col``=``"Date"``,``parse_dates``=``[``"Date"``],``usecols``=``[``"Date"``,``"Adj
    Close"``])``# Rename the column into the ticker symbol``adj_close``=``adj_close``.``rename``(``columns``=``{``"Adj
    Close"``:``ticker``})``# Append the stock''s DataFrame to the parts list``parts``.``append``(``adj_close``)`'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``25``]:``parts``=``[]``# 用于收集各个数据框的列表``for``ticker``in``[``"AAPL"``,``"AMZN"``,``"GOOGL"``,``"MSFT"``]:``#
    “usecols”参数允许我们只读取日期和调整后的收盘价``adj_close``=``pd``.``read_csv``(``f``"csv/{ticker}.csv"``,``index_col``=``"Date"``,``parse_dates``=``[``"Date"``],``usecols``=``[``"Date"``,``"Adj
    Close"``])``# 将列名改为股票代号``adj_close``=``adj_close``.``rename``(``columns``=``{``"Adj
    Close"``:``ticker``})``# 将该股票的数据框附加到 parts 列表``parts``.``append``(``adj_close``)`'
- en: '`In``[``26``]:``# Combine the 4 DataFrames into a single DataFrame``adj_close``=``pd``.``concat``(``parts``,``axis``=``1``)``adj_close`'
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``26``]:``# 将这 4 个数据框合并为一个数据框``adj_close``=``pd``.``concat``(``parts``,``axis``=``1``)``adj_close`'
- en: '`Out[26]:                   AAPL         AMZN        GOOGL        MSFT         
    Date          1980-12-12    0.405683          NaN          NaN         NaN         
    1980-12-15    0.384517          NaN          NaN         NaN          1980-12-16   
    0.356296          NaN          NaN         NaN          1980-12-17    0.365115         
    NaN          NaN         NaN          1980-12-18    0.375698          NaN         
    NaN         NaN          ...                ...          ...          ...        
    ...          2020-05-22  318.890015  2436.879883  1413.239990  183.509995         
    2020-05-26  316.730011  2421.860107  1421.369995  181.570007          2020-05-27 
    318.109985  2410.389893  1420.280029  181.809998          2020-05-28  318.250000 
    2401.100098  1418.239990         NaN          2020-05-29  317.940002  2442.370117 
    1433.520020         NaN           [9950 rows x 4 columns]`'
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[26]:                   AAPL         AMZN        GOOGL        MSFT         
    日期          1980-12-12    0.405683          NaN          NaN         NaN         
    1980-12-15    0.384517          NaN          NaN         NaN          1980-12-16   
    0.356296          NaN          NaN         NaN          1980-12-17    0.365115         
    NaN          NaN         NaN          1980-12-18    0.375698          NaN         
    NaN         NaN          ...                ...          ...          ...        
    ...          2020-05-22  318.890015  2436.879883  1413.239990  183.509995         
    2020-05-26  316.730011  2421.860107  1421.369995  181.570007          2020-05-27 
    318.109985  2410.389893  1420.280029  181.809998          2020-05-28  318.250000 
    2401.100098  1418.239990         NaN          2020-05-29  317.940002  2442.370117 
    1433.520020         NaN           [9950 行 x 4 列]`'
- en: 'Did you see the power of `concat`? pandas has automatically aligned the individual
    time series along the dates. This is why you get `NaN` values for those stocks
    that don’t go back as far as Apple. And since `MSFT` has `NaN` values at the most
    recent dates, you may have guessed that I downloaded MSFT.csv two days before
    the other ones. Aligning time series by date is a typical operation that is very
    cumbersome to do with Excel and therefore also very error-prone. Dropping all
    rows that contain missing values will make sure that all stocks have the same
    amount of data points:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到`concat`的威力了吗？pandas自动对齐了各个时间序列的日期。这就是为什么在那些不如Apple的股票中你会得到`NaN`值的原因。而且由于`MSFT`在最近日期有`NaN`值，你可能已经猜到我比其他股票提前两天下载了MSFT.csv文件。通过日期对齐时间序列是一种典型的操作，在Excel中非常繁琐且容易出错。删除所有包含缺失值的行将确保所有股票具有相同的数据点：
- en: '`In``[``27``]:``adj_close``=``adj_close``.``dropna``()``adj_close``.``info``()`'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``27``]:`adj_close`=``adj_close``.``dropna``()``adj_close``.``info``()`'
- en: '`<class ''pandas.core.frame.DataFrame''> DatetimeIndex: 3970 entries, 2004-08-19
    to 2020-05-27 Data columns (total 4 columns): #   Column  Non-Null Count  Dtype
    ---  ------  --------------  ----- 0   AAPL    3970 non-null   float64 1   AMZN   
    3970 non-null   float64 2   GOOGL   3970 non-null   float64 3   MSFT    3970 non-null  
    float64 dtypes: float64(4) memory usage: 155.1 KB`'
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`<class ''pandas.core.frame.DataFrame''> DatetimeIndex: 3970 entries, 2004-08-19
    to 2020-05-27 Data columns (total 4 columns): #   Column  Non-Null Count  Dtype
    ---  ------  --------------  ----- 0   AAPL    3970 non-null   float64 1   AMZN   
    3970 non-null   float64 2   GOOGL   3970 non-null   float64 3   MSFT    3970 non-null  
    float64 dtypes: float64(4) memory usage: 155.1 KB`'
- en: 'Let’s now rebase the prices so that all time series start at 100\. This allows
    us to compare their relative performance in a chart; see [Figure 6-4](#filepos838207).
    To rebase a time series, divide every value by its starting value and multiply
    by 100, the new base. If you did this in Excel, you would typically write a formula
    with a combination of absolute and relative cell references, then copy the formula
    for every row and every time series. In pandas, thanks to vectorization and broadcasting,
    you are dealing with a single formula:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将价格重新基准化，使所有时间序列从100开始。这样可以在图表中比较它们的相对表现；见[图 6-4](#filepos838207)。要重新基准化时间序列，将每个值除以其起始值并乘以100，这是新的基准。如果在Excel中进行此操作，通常会编写一个结合绝对和相对单元格引用的公式，然后将该公式复制到每行和每个时间序列。在pandas中，由于矢量化和广播技术，你只需处理一个公式：
- en: '`In``[``28``]:``# Use a sample from June 2019 - May 2020``adj_close_sample``=``adj_close``.``loc``[``"2019-06"``:``"2020-05"``,``:]``rebased_prices``=``adj_close_sample``/``adj_close_sample``.``iloc``[``0``,``:]``*``100``rebased_prices``.``head``(``2``)`'
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``28``]:`# 使用2019年6月至2020年5月的样本`adj_close_sample`=``adj_close``.``loc``[``"2019-06"``:``"2020-05"``,``:]``rebased_prices`=``adj_close_sample``/``adj_close_sample``.``iloc``[``0``,``:]``*``100``rebased_prices``.``head``(``2``)`'
- en: '`Out[28]:                   AAPL        AMZN      GOOGL        MSFT         
    Date          2019-06-03  100.000000  100.000000  100.00000  100.000000         
    2019-06-04  103.658406  102.178197  101.51626  102.770372`'
  id: totrans-99
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[28]:                   AAPL        AMZN      GOOGL        MSFT         
    Date          2019-06-03  100.000000  100.000000  100.00000  100.000000         
    2019-06-04  103.658406  102.178197  101.51626  102.770372`'
- en: '`In``[``29``]:``rebased_prices``.``plot``()`'
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``29``]:`rebased_prices``.``plot``()'
- en: '![](images/00053.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00053.jpg)'
- en: Figure 6-4\. Rebased time series
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6-4. 重新基准化的时间序列
- en: 'To see how independent the returns of the different stocks are, have a look
    at their correlations by using the `corr` method. Unfortunately, pandas doesn’t
    provide a built-in plot type to visualize the correlation matrix as a heatmap,
    so we need to use Plotly directly via its `plotly.express` interface (see [Figure 6-5](#filepos846256)):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看不同股票的回报独立性，可以使用`corr`方法查看它们的相关性。不幸的是，pandas没有提供内置的绘制热力图形式的相关矩阵的方法，因此我们需要直接通过其`plotly.express`接口使用Plotly（见[图 6-5](#filepos846256)）：
- en: '`In``[``30``]:``# Correlation of daily log returns``returns``=``np``.``log``(``adj_close``/``adj_close``.``shift``(``1``))``returns``.``corr``()`'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``30``]:`# 每日对数收益率的相关性`returns`=``np``.``log``(``adj_close``/``adj_close``.``shift``(``1``))``returns``.``corr``()'
- en: '`Out[30]:            AAPL      AMZN     GOOGL      MSFT          AAPL   1.000000 
    0.424910  0.503497  0.486065          AMZN   0.424910  1.000000  0.486690  0.485725
             GOOGL  0.503497  0.486690  1.000000  0.525645          MSFT   0.486065 
    0.485725  0.525645  1.000000`'
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[30]:            AAPL      AMZN     GOOGL      MSFT          AAPL   1.000000 
    0.424910  0.503497  0.486065          AMZN   0.424910  1.000000  0.486690  0.485725
             GOOGL  0.503497  0.486690  1.000000  0.525645          MSFT   0.486065 
    0.485725  0.525645  1.000000`'
- en: '`In``[``31``]:``import``plotly.express``as``px`'
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``31``]:`import`plotly.express`as`px'
- en: '`In``[``32``]:``fig``=``px``.``imshow``(``returns``.``corr``(),``x``=``adj_close``.``columns``,``y``=``adj_close``.``columns``,``color_continuous_scale``=``list``(``reversed``(``px``.``colors``.``sequential``.``RdBu``)),``zmin``=-``1``,``zmax``=``1``)``fig``.``show``()`'
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``32``]:``fig``=``px``.``imshow``(``returns``.``corr``(),``x``=``adj_close``.``columns``,``y``=``adj_close``.``columns``,``color_continuous_scale``=``list``(``reversed``(``px``.``colors``.``sequential``.``RdBu``)),``zmin``=-``1``,``zmax``=``1``)``fig``.``show``()`'
- en: If you want to understand how `imshow` works in detail, have a look at the [Plotly
    Express API docs](https://oreil.ly/O86li).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想详细了解`imshow`的工作原理，请查看[Plotly Express API文档](https://oreil.ly/O86li)。
- en: '![](images/00064.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00064.jpg)'
- en: Figure 6-5\. Correlation heatmap
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6-5\. 相关性热力图
- en: At this point, we have already learned quite a few things about time series,
    including how to combine and clean them and how to calculate returns and correlations.
    But what if you decide that daily returns are not a good base for your analysis
    and you want monthly returns? How you change the frequency of time series data
    is the topic of the next section.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学到了关于时间序列的许多知识，包括如何组合和清理它们，如何计算收益率和相关性。但是，如果你决定日收益率不适合你的分析基础，想要月度收益率呢？如何改变时间序列数据的频率将成为下一节的主题。
- en: Resampling
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 重新采样
- en: 'A regular task with time series is up- and downsampling. Upsampling means that
    the time series is converted into one with a higher frequency, and downsampling
    means that it is converted into one with a lower frequency. On financial factsheets,
    you often show monthly or quarterly performance, for example. To turn the daily
    time series into a monthly one, use the `resample` method that accepts a frequency
    string like `M` for end-of-calendar-month or `BM` for end-of-business-month. You
    can find a list of all frequency strings in the [pandas docs](https://oreil.ly/zStpt).
    Similar to how `groupby` works, you then chain a method that defines how you are
    resampling. I am using `last` to always take the last observation of that month:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列的常见任务包括上采样和下采样。上采样意味着将时间序列转换为频率更高的序列，而下采样则意味着将其转换为频率较低的序列。例如，在财务报表中，通常显示月度或季度表现。要将日度时间序列转换为月度时间序列，请使用`resample`方法，该方法接受频率字符串如`M`表示月末或`BM`表示工作日结束。你可以在[pandas文档](https://oreil.ly/zStpt)中找到所有频率字符串的列表。类似于`groupby`的工作方式，然后链接定义如何重新采样的方法。我使用`last`来始终获取该月的最后观测值：
- en: '`In``[``33``]:``end_of_month``=``adj_close``.``resample``(``"M"``)``.``last``()``end_of_month``.``head``()`'
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``33``]:``end_of_month``=``adj_close``.``resample``(``"M"``)``.``last``()``end_of_month``.``head``()`'
- en: '`Out[33]:                 AAPL       AMZN      GOOGL       MSFT          Date
             2004-08-31  2.132708  38.139999  51.236237  17.673630          2004-09-30 
    2.396127  40.860001  64.864868  17.900215          2004-10-31  3.240182  34.130001 
    95.415413  18.107374          2004-11-30  4.146072  39.680000  91.081078  19.344421
             2004-12-31  3.982207  44.290001  96.491493  19.279480`'
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[33]:                 AAPL       AMZN      GOOGL       MSFT          Date
             2004-08-31  2.132708  38.139999  51.236237  17.673630          2004-09-30 
    2.396127  40.860001  64.864868  17.900215          2004-10-31  3.240182  34.130001 
    95.415413  18.107374          2004-11-30  4.146072  39.680000  91.081078  19.344421
             2004-12-31  3.982207  44.290001  96.491493  19.279480`'
- en: Instead of `last`, you can choose any other method that works on `groupby`,
    like `sum` or `mean`. There is also `ohlc`, which conveniently returns the open,
    high, low, and close values over that period. This may serve as the source to
    create the typical candlestick charts that are often used with stock prices.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以选择除`last`外的任何在`groupby`上有效的方法，如`sum`或`mean`。还有`ohlc`，它方便地返回该期间的开盘价、最高价、最低价和收盘价。这可能用作创建股票价格常用的蜡烛图表的源。
- en: 'If that end-of-month time series would be all you have and you need to produce
    a weekly time series out of it, you have to upsample your time series. By using
    `asfreq`, you are telling pandas not to apply any transformation and hence you
    will see most of the values showing `NaN`. If you wanted to forward-fill the last
    known value instead, use the `ffill` method:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只有那些月末时间序列数据，并且需要生成周度时间序列，你需要对时间序列进行上采样。通过使用`asfreq`，你告诉pandas不要应用任何转换，因此你将看到大多数值显示为`NaN`。如果你想要向前填充最后已知值，使用`ffill`方法：
- en: '`In``[``34``]:``end_of_month``.``resample``(``"D"``)``.``asfreq``()``.``head``()``#
    No transformation`'
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``34``]:``end_of_month``.``resample``(``"D"``)``.``asfreq``()``.``head``()``#
    No transformation`'
- en: '`Out[34]:                 AAPL       AMZN      GOOGL      MSFT          Date
             2004-08-31  2.132708  38.139999  51.236237  17.67363          2004-09-01      
    NaN        NaN        NaN       NaN          2004-09-02       NaN        NaN       
    NaN       NaN          2004-09-03       NaN        NaN        NaN       NaN         
    2004-09-04       NaN        NaN        NaN       NaN`'
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[34]:                 AAPL       AMZN      GOOGL      MSFT          日期
             2004-08-31  2.132708  38.139999  51.236237  17.67363          2004-09-01      
    NaN        NaN        NaN       NaN          2004-09-02       NaN        NaN       
    NaN       NaN          2004-09-03       NaN        NaN        NaN       NaN         
    2004-09-04       NaN        NaN        NaN       NaN`'
- en: '`In``[``35``]:``end_of_month``.``resample``(``"W-FRI"``)``.``ffill``()``.``head``()``#
    Forward fill`'
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``35``]:``end_of_month``.``resample``(``"W-FRI"``)``.``ffill``()``.``head``()``#
    前向填充'
- en: '`Out[35]:                 AAPL       AMZN      GOOGL       MSFT          Date
             2004-09-03  2.132708  38.139999  51.236237  17.673630          2004-09-10 
    2.132708  38.139999  51.236237  17.673630          2004-09-17  2.132708  38.139999 
    51.236237  17.673630          2004-09-24  2.132708  38.139999  51.236237  17.673630
             2004-10-01  2.396127  40.860001  64.864868  17.900215`'
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`Out[35]:                 AAPL       AMZN      GOOGL       MSFT          日期
             2004-09-03  2.132708  38.139999  51.236237  17.673630          2004-09-10 
    2.132708  38.139999  51.236237  17.673630          2004-09-17  2.132708  38.139999 
    51.236237  17.673630          2004-09-24  2.132708  38.139999  51.236237  17.673630
             2004-10-01  2.396127  40.860001  64.864868  17.900215`'
- en: Downsampling data is one way of smoothing a time series. Calculating statistics
    over a rolling window is another way, as we will see next.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 降采样数据是平滑时间序列的一种方式。计算滚动窗口中的统计数据是另一种方式，我们将在下面看到。
- en: Rolling Windows
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动窗口
- en: 'When you calculate time series statistics, you often want a rolling statistic
    such as the moving average. The moving average looks at a subset of the time series
    (let’s say 25 days) and takes the mean from this subset before moving the window
    forward by one day. This will result in a new time series that is smoother and
    less prone to outliers. If you are into algorithmic trading, you may be looking
    at the intersection of the moving average with the stock price and take this (or
    some variation of it) as a trading signal. DataFrames have a `rolling` method,
    which accepts the number of observations as argument. You then chain it with the
    statistical method that you want to use—in the case of the moving average, it’s
    the `mean`. By looking at [Figure 6-6](#filepos859395), you are easily able to
    compare the original time series with the smoothed moving average:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算时间序列统计数据时，通常需要一个滚动统计量，如移动平均线。移动平均线查看时间序列的子集（比如25天），并在将窗口向前移动一天之前从该子集中取平均值。这将产生一个新的时间序列，更平滑且不易受到异常值的影响。如果你从事算法交易，可能会关注移动平均线与股票价格的交点，并将其（或其变体）作为交易信号。DataFrame具有`rolling`方法，接受观察次数作为参数。然后，将其与要使用的统计方法链接起来——对于移动平均线，就是`mean`。通过查看[图6-6](#filepos859395)，你可以轻松比较原始时间序列与平滑移动平均线：
- en: '`In``[``36``]:``# Plot the moving average for MSFT with data from 2019``msft19``=``msft``.``loc``[``"2019"``,``[``"Adj
    Close"``]]``.``copy``()``# Add the 25 day moving average as a new column to the
    DataFrame``msft19``.``loc``[:,``"25day average"``]``=``msft19``[``"Adj Close"``]``.``rolling``(``25``)``.``mean``()``msft19``.``plot``()`'
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`In``[``36``]:``# 使用2019年数据为MSFT绘制移动平均线``msft19``=``msft``.``loc``[``"2019"``,``[``"Adj
    Close"``]]``.``copy``()``# 将25天移动平均线作为新列添加到DataFrame``msft19``.``loc``[:,``"25day
    average"``]``=``msft19``[``"Adj Close"``]``.``rolling``(``25``)``.``mean``()``msft19``.``plot``()`'
- en: '![](images/00072.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00072.jpg)'
- en: Figure 6-6\. Moving average plot
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图6-6\. 移动平均线图
- en: Instead of `mean`, you can use many other statistical measures including `count`,
    `sum`, `median`, `min`, `max`, `std` (standard deviation), or `var` (variance).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用许多其他统计方法来替代`mean`，包括`count`、`sum`、`median`、`min`、`max`、`std`（标准差）或`var`（方差）。
- en: At this point, we have seen the most important functionality of pandas. It’s
    equally important, though, to understand where pandas has its limits, even though
    they may still be far away right now.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了pandas最重要的功能。同样重要的是要理解pandas的局限性，即使它们可能现在仍然很远。
- en: Limitations with pandas
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: pandas的局限性
- en: 'When your DataFrames start to get bigger, it’s a good idea to know the upper
    limit of what a DataFrame can hold. Unlike Excel, where you have a hard limit
    of roughly one million rows and 12,000 columns per sheet, pandas only has a soft
    limit: all data must fit into the available memory of your machine. If that’s
    not the case, there might be some easy fixes: only load those columns from your
    dataset that you need or delete intermediate results to free up some memory. If
    that doesn’t help, there are quite a few projects that will feel familiar to pandas
    users but work with big data. One of the projects, [Dask](https://dask.org), works
    on top of NumPy and pandas and allows you to work with big datasets by splitting
    it up into multiple pandas DataFrames and distributing the workload across multiple
    CPU cores or machines. Other big data projects that work with some sort of DataFrame
    are [Modin](https://oreil.ly/Wd8gi), [Koalas](https://oreil.ly/V13Be), [Vaex](https://vaex.io),
    [PySpark](https://oreil.ly/E7kmX), [cuDF](https://oreil.ly/zaeWz), [Ibis](https://oreil.ly/Gw4wn),
    and [PyArrow](https://oreil.ly/DQQGD). We will briefly touch on Modin in the next
    chapter but other than that, this is not something we are going to explore further
    in this book.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的 DataFrame 开始变得更大时，了解 DataFrame 能容纳的上限是个好主意。与 Excel 不同，Excel 的每个工作表都有大约一百万行和一万二千列的硬性限制，而
    pandas 只有软性限制：所有数据必须适合计算机可用的内存。如果情况不是这样，可能有一些简单的解决方案：只加载你需要的数据集中的那些列，或者删除中间结果以释放一些内存。如果这些方法都不起作用，有一些项目可能会让
    pandas 用户感到熟悉，但可以处理大数据。其中一个项目是[Dask](https://dask.org)，它在 NumPy 和 pandas 之上工作，允许你通过将数据拆分成多个
    pandas DataFrame，并将工作负载分配到多个 CPU 核心或机器上来处理大型数据集。其他与某种 DataFrame 类似的大数据项目包括[Modin](https://oreil.ly/Wd8gi)，[Koalas](https://oreil.ly/V13Be)，[Vaex](https://vaex.io)，[PySpark](https://oreil.ly/E7kmX)，[cuDF](https://oreil.ly/zaeWz)，[Ibis](https://oreil.ly/Gw4wn)和[PyArrow](https://oreil.ly/DQQGD)。我们将在下一章简要介绍
    Modin，但除此之外，在本书中我们不会进一步探索这个主题。
- en: Conclusion
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 结论
- en: Time series analysis is the area where I feel Excel has fallen behind the most,
    so after reading this chapter, you probably understand why pandas has such a big
    success in finance, an industry that heavily relies on time series. We’ve seen
    how easy it is to work with time zones, resample time series, or produce correlation
    matrices, functionality that either isn’t supported in Excel or requires cumbersome
    workarounds.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列分析是我认为 Excel 落后最多的领域，所以在阅读本章之后，你可能会明白为什么 pandas 在金融领域如此成功，金融行业严重依赖时间序列。我们已经看到了处理时区、重采样时间序列或生成相关矩阵是多么容易，而这些功能在
    Excel 中要么不支持，要么需要繁琐的解决方案。
- en: 'Knowing how to use pandas doesn’t mean you have to get rid of Excel, though,
    as the two worlds can play very nicely together: pandas DataFrames are a great
    way to transfer data from one world to the other, as we will see in the next part,
    which is about reading and writing Excel files in ways that bypass the Excel application
    entirely. This is very helpful as it means you can manipulate Excel files with
    Python on every operating system that Python supports, including Linux. To start
    this journey, the next chapter will show you how pandas can be used to automate
    tedious manual processes like the aggregation of Excel files into summary reports.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，了解如何使用 pandas 并不意味着你必须放弃 Excel，因为这两个世界可以非常好地配合：pandas DataFrame 是在两个世界之间传输数据的好方法，正如我们将在下一部分中看到的，该部分将介绍绕过
    Excel 应用程序完全读写 Excel 文件的方式。这非常有帮助，因为它意味着你可以在 Python 支持的所有操作系统上使用 Python 操作 Excel
    文件，包括 Linux。为了开始这段旅程，下一章将向你展示如何使用 pandas 来自动化繁琐的手动流程，比如将 Excel 文件聚合成摘要报告。
