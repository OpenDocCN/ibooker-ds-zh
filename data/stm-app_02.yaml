- en: Chapter 3\. Topology design
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第3章. 拓扑设计
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Decomposing a problem to fit Storm constructs
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将问题分解以适应Storm结构
- en: Working with unreliable data sources
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与不可靠的数据源一起工作
- en: Integrating with external services and data stores
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成外部服务和数据存储
- en: Understanding parallelism within a Storm topology
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Storm拓扑中的并行性
- en: Following best practices for topology design
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遵循拓扑设计的最佳实践
- en: 'In the previous chapter, we got our feet wet by building a simple topology
    that counts commits made to a GitHub project. We broke it down into Storm’s two
    primary components—spouts and bolts—but we didn’t concern ourselves with details
    as to why. This chapter expands on those basic Storm concepts by showing you how
    to think about modeling and designing solutions with Storm. You’ll learn strategies
    for problem analysis that can help you end up with a good design: a model for
    representing the workflow of the problem at hand.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们通过构建一个简单的拓扑来计算提交到GitHub项目的提交次数，从而开始了我们的实践。我们将它分解成了Storm的两个主要组件——spouts和bolts，但我们没有关注为什么这样做。本章通过向你展示如何使用Storm来思考和设计解决方案，扩展了这些基本的Storm概念。你将学习到帮助你设计出良好设计的策略：一个表示当前问题工作流程的模型。
- en: In addition, it’s important that you learn how scalability (or parallelization
    of units of work) is built into Storm because that affects the approach that you’ll
    take with topology design. We’ll also explore strategies for gaining the most
    out of your topology in terms of speed.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，了解可伸缩性（或工作单元的并行化）是如何内置到Storm中的也很重要，因为它会影响你在拓扑设计中所采取的方法。我们还将探讨提高拓扑速度的策略。
- en: After reading this chapter, not only will you be able to easily take apart a
    problem and see how it fits within Storm, but you’ll also be able to determine
    whether Storm is the right solution for tackling that problem. This chapter will
    give you a solid understanding of topology design so that you can envision solutions
    to big data problems.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章后，你不仅能够轻松地分解问题并看到它如何在Storm中适用，而且你还能确定Storm是否是解决该问题的正确解决方案。本章将为你提供对拓扑设计的坚实基础，以便你能够设想大数据问题的解决方案。
- en: Let’s get started by exploring how you can approach topology design and then
    get into breaking down a real-world scenario using the steps we’ve outlined.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从探索如何接近拓扑设计开始，然后根据我们概述的步骤分解一个现实场景。
- en: 3.1\. Approaching topology design
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 接近拓扑设计
- en: 'The approach to topology design can be broken down into the following five
    steps:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑设计的步骤可以分解为以下五个步骤：
- en: '***Defining the problem/forming a conceptual solution*—** This step serves
    to provide a clear understanding of the problem being tackled. It also serves
    as a place to document the requirements to be placed on any potential solution
    (including requirements with regard to speed, which is a common criterion in big
    data problems). This step involves modeling a solution (not an implementation)
    that addresses the core need(s) of the problem.'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***定义问题/形成概念性解决方案***—**这一步旨在对正在解决的问题有一个清晰的理解。它还作为一个地方来记录对任何潜在解决方案（包括与速度有关的要求，这是大数据问题中的常见标准）的要求。这一步涉及建模一个解决方案（不是实现），该解决方案解决了问题的核心需求。'
- en: '***Mapping the solution to Storm*—** In this step, you follow a set of tenets
    for breaking down the proposed solution in a manner that allows you to envision
    how it will map to Storm primitives (aka Storm concepts). At this stage, you’ll
    come up with a design for your topology. This design will be tuned and adjusted
    as needed in the following steps.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***将解决方案映射到Storm***—**在这一步中，你遵循一系列原则，将提出的解决方案分解成一种方式，以便你能够设想它如何映射到Storm原语（即Storm概念）。在这一阶段，你将为你自己的拓扑设计出一个方案。这个方案将在接下来的步骤中根据需要进行调整和优化。'
- en: '***Implementing the initial solution*—** Each of the components will be implemented
    at this point.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***实现初始解决方案***—**在这个阶段，每个组件都将被实现。'
- en: '***Scaling the topology*—** In this step, you’ll turn the knobs that Storm
    provides for you to run this topology at scale.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***扩展拓扑***—**在这一步中，你将调整Storm为你提供的旋钮，以便以规模运行此拓扑。'
- en: '***Tuning based on observations*—** Finally, you’ll adjust the topology based
    on observed behavior once it’s running. This step may involve additional tuning
    for achieving scale as well as design changes that may be warranted for efficiency.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***根据观察调整***—**最后，你将根据运行时的观察行为调整拓扑。这一步可能涉及为了实现规模而进行的额外调整，以及可能为了效率而需要的设计变更。'
- en: Let’s apply these steps to a real-world problem to show how you’d go about completing
    each of the steps. We’ll do this with a social heat map, which encapsulates several
    challenging topics related to topology design.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这些步骤应用到现实世界的问题中，以展示如何完成每个步骤。我们将使用社会热图来完成，它包含与拓扑设计相关的几个具有挑战性的主题。
- en: '3.2\. Problem definition: a social heat map'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 问题定义：社会热图
- en: 'Imagine this scenario: it’s Saturday night and you’re out drinking at a bar,
    enjoying the good life with your friends. You’re finishing your third drink and
    you’re starting to feel like you need a change of scene. Maybe switch it up and
    go to a different bar? So many choices—how do you even choose? Being a socialite,
    of course you’d want to end up in the bar that’s most popular. You don’t want
    to go somewhere that was voted best in your neighborhood glossy magazine. That
    was so last week. You want to be where the action is right now, not last week,
    not even last hour. You are the trendsetter. You have a responsibility to show
    your friends a good time.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下这个场景：现在是周六晚上，你和朋友们在酒吧里喝酒，享受美好的生活。你喝完了第三杯，开始觉得需要换换环境。也许去一个不同的酒吧？选择太多了——你甚至不知道怎么选择？作为一个社交达人，当然你希望最终能去最受欢迎的酒吧。你不想去你所在地区杂志上被评为最佳的地方。那已经是上周的事情了。你想要的是现在正在发生的事情，而不是上周，甚至不是上一个小时。你是潮流的引领者。你有责任让你的朋友们玩得开心。
- en: Okay, maybe that’s not you. But does that represent the average social network
    user? Now what can we do to help this person? If we can represent the answer this
    person is looking for in a graphical form factor, it’d be ideal—a map that identifies
    the neighborhoods with highest density of activity in bars as hot zones can convey
    everything quickly. A heat map can identify the general neighborhood in a big
    city like New York or San Francisco, and generally when a picking a popular bar,
    it’s better to have a few choices within close proximity to one another, just
    in case.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，也许那不是你。但这代表的是平均社会网络用户吗？现在我们能做些什么来帮助这个人呢？如果我们能以图形形式展示这个人正在寻找的答案，那就太理想了——一张能够快速传达酒吧活动密度最高的地区的热点地图。热图可以识别像纽约或旧金山这样的大城市中的普通地区，通常在挑选热门酒吧时，最好有几个彼此靠近的选择，以防万一。
- en: '|  |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Other case studies for heat maps**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**热图的其他案例研究**'
- en: 'What kind of problems benefit from visualization using a heat map? A good candidate
    would allow you to use the heat map’s intensity to model the relative importance
    of a set of data points as compared to others within an area (geographical or
    otherwise):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 哪些问题通过使用热图进行可视化会受益？一个好的候选者应该允许你使用热图的强度来模拟一组数据点相对于区域内（地理或其他）其他点的相对重要性：
- en: The spread of a wildfire in California, an approaching hurricane on the East
    Coast, or the outbreak of a disease can be modeled and represented as a heat map
    to warn residents.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加利福尼亚野火蔓延、东海岸即将来临的飓风或疾病的爆发可以通过热图进行模拟和表示，以警告居民。
- en: On an election day, you might want to know
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在选举日，你可能想知道
- en: Which political districts had the most voters turn out? You can depict this
    on a heat map by modeling the turnout numbers to reflect the intensity.
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪个政治选区有最多的选民投票？你可以通过模拟投票数来反映强度，在热图上描绘出来。
- en: You can depict which political party/candidate/issue received the most votes
    by modeling the party, candidate, or issue as a different color, with the intensity
    of the color reflecting the number of votes.
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以通过将政党、候选人或问题模拟为不同的颜色来描绘哪个政党/候选人/问题获得了最多的选票，颜色的强度反映了选票的数量。
- en: '|  |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: We’ve provided a general problem definition. Before moving any further, let’s
    form a conceptual solution.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提供了一个一般的问题定义。在继续前进之前，让我们形成一个概念性的解决方案。
- en: 3.2.1\. Formation of a conceptual solution
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1\. 概念性解决方案的形成
- en: Where should we begin? Multiple social networks incorporate the concept of check-ins.
    Let’s say we have access to a data fire hose that collects check-ins for bars
    from all of these networks. This fire hose will emit a bar’s address for every
    check-in. This gives us a starting point, but it’s also good to have an end goal
    in mind. Let’s say that our end goal is a geographical map with a heat map overlay
    identifying neighborhoods with the most popular bars. [Figure 3.1](#ch03fig01)
    illustrates our proposed solution where we’ll transform multiple check-ins from
    different venues to be shown in a heat map.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该从哪里开始？多个社交网络都包含了签到概念。假设我们能够访问一个收集所有这些网络酒吧签到的数据喷泉。这个喷泉将为每个签到发射一个酒吧的地址。这为我们提供了一个起点，但也要有一个目标在心中。假设我们的目标是带有热图覆盖的地理地图，以识别最受欢迎的酒吧所在的社区。[图3.1](#ch03fig01)展示了我们提出的解决方案，我们将从不同场所转换多个签到信息以在热图中显示。
- en: Figure 3.1\. Using check-ins to build a heat map of bars
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.1\. 使用签到信息构建酒吧热图
- en: '![](03fig01_alt.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig01_alt.jpg)'
- en: The solution that we need to model within Storm becomes the method of transforming
    (or aggregating) check-ins into a data set that can be depicted on a heat map.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在Storm中建模的解决方案，变成了将签到信息（或聚合）转换成可以绘制在热图上的数据集的方法。
- en: 3.3\. Precepts for mapping the solution to Storm
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 将解决方案映射到Storm的准则
- en: The best way to start is to contemplate the nature of data flowing through this
    system. When we better understand the peculiarities contained within the data
    stream, we can become more attuned to requirements that can be placed on this
    system realistically.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳的起点是思考通过这个系统流动的数据的本质。当我们更好地理解数据流中包含的奇特之处时，我们可以更适应这个系统可能面临的实际要求。
- en: 3.3.1\. Consider the requirements imposed by the data stream
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1\. 考虑数据流强加的要求
- en: We have a fire hose emitting addresses of bars for each check-in. But this stream
    of check-ins doesn’t reliably represent every single user who went to a bar. A
    check-in isn’t equivalent to a physical presence at a location. It’s better to
    think of it as a sampling of real life because not every single user checks in.
    But that leads us to question whether check-in data is even useful for solving
    this problem. For this example, we can safely assume that check-ins at bars are
    proportional to people at those locations.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个喷泉式地发射酒吧地址的检查流。但这个签到流并不能可靠地代表每个去过酒吧的用户。签到并不等同于在某个地点的物理存在。更好的想法是将其视为现实生活的样本，因为并非每个用户都会签到。但这让我们质疑签到数据是否真的有助于解决这个问题。在这个例子中，我们可以安全地假设酒吧的签到与那些地点的人数成比例。
- en: 'So we know the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们知道以下内容：
- en: Check-ins are a sampling of real-life scenarios, but they’re not complete.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 签到是现实场景的样本，但并不完整。
- en: They’re proportionately representative.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们是成比例的代表性。
- en: '|  |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Let’s make the assumption here that the data volume is large enough to compensate
    for data loss and that any data loss is intermittent and not sustained long enough
    to cause a noticeable disruption in service. These assumptions help us portray
    a case of working with an unreliable data source.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设数据量足够大，可以弥补数据丢失，并且任何数据丢失都是间歇性的，不足以造成服务中断的明显影响。这些假设帮助我们描绘了一个与不可靠数据源合作的情况。
- en: '|  |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'We have our first insight about our data stream: a proportionately representative
    but possibly incomplete stream of check-ins. What’s next? We know our users want
    to be notified about the latest trends in activity as soon as possible. In other
    words, we have a strict speed requirement: get the results to the user as quickly
    as possible because the value of data diminishes with time.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对我们数据流的第一个洞察：一个成比例的代表性但可能不完整的签到流。接下来是什么？我们知道我们的用户希望尽快收到关于活动最新趋势的通知。换句话说，我们有一个严格的速度要求：尽可能快地将结果呈现给用户，因为数据的价值会随时间而降低。
- en: What emerges from consideration of the data stream is that we don’t need to
    worry too much about data loss. We can come to this conclusion because we know
    that our incoming data set is incomplete, so accuracy down to some arbitrary,
    minute degree of precision isn’t necessary. But it’s proportionately representative
    and that’s good enough for determining popularity. Combine this with the requirement
    of speed and we know that as long as we get recent data quickly to our users,
    they’ll be happy. Even if data loss occurs, the past results will be replaced
    soon.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 从对数据流的考虑中可以看出，我们不必过于担心数据丢失。我们可以得出这个结论，因为我们知道我们的输入数据集是不完整的，所以不需要达到某些任意、微小的精度程度的准确性。但它是成比例的代表性，这对于确定流行度来说已经足够了。结合速度的要求，我们知道只要我们能快速将最近的数据提供给用户，他们就会满意。即使发生数据丢失，过去的结果也会很快被替换。
- en: This scenario maps directly to the idea of working with an unreliable data source
    in Storm. With an unreliable data source, you don’t have the ability to retry
    a failed operation; the data source may not have the ability to replay a data
    point. In our case, we’re sampling real life by way of check-ins and that mimics
    the availability of an incomplete data set.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这种场景直接映射到在Storm中处理不可靠数据源的概念。在不可靠的数据源中，你无法重试失败的操作；数据源可能没有重放数据点的能力。在我们的案例中，我们通过签到方式抽样现实生活，这模拟了不完整数据集的可用性。
- en: In contrast, there may be cases where you work with a reliable data source—one
    that has the ability to replay data points that fail. But perhaps accuracy is
    less important than speed and you may not want to take advantage of the replayability
    of a reliable data source. Then approximations can be just as acceptable, and
    you’re treating the reliable data source as if it was unreliable by choosing to
    ignore any reliability measures it provides.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，可能存在你与可靠数据源一起工作的情形——这种数据源有能力重放失败的数据点。但也许准确性不如速度重要，你可能不想利用可靠数据源的重放能力。那么近似值可能同样可以接受，而你通过选择忽略它提供的任何可靠性措施，将可靠数据源当作不可靠数据源来处理。
- en: '|  |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-52
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 备注
- en: We’ll cover reliable data sources along with fault tolerance in [chapter 4](kindle_split_012.html#ch04).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第4章](kindle_split_012.html#ch04)中介绍可靠数据源以及容错性。
- en: '|  |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Having defined the source of the data, the next step is to identify how the
    individual data points will flow through our proposed solution. We’ll explore
    this topic next.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了数据源之后，下一步是确定单个数据点如何通过我们提出的解决方案流动。我们将在下一节探讨这个话题。
- en: 3.3.2\. Represent data points as tuples
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2\. 将数据点表示为元组
- en: 'Our next step is to identify the individual data points that flow through this
    stream. It’s easy to accomplish this by considering the beginning and end. We
    begin with a series of data points composed of street addresses of bars with activity.
    We’ll also need to know the time the check-in occurred. So our input data point
    can be represented as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下一步是确定通过这个流流动的各个数据点。通过考虑开始和结束是很容易完成这个任务的。我们从一个由活跃酒吧的街道地址组成的一系列数据点开始。我们还需要知道签到发生的时间。因此，我们的输入数据点可以表示如下：
- en: '[PRE0]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: That’s the time and an address where the check-in happened. This would be our
    input tuple that’s emitted by the spout. As you’ll recall from [chapter 2](kindle_split_010.html#ch02),
    a *tuple* is a Storm primitive for representing a data point and a *spout* is
    a source of a stream of tuples.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是签到发生的时间和地址。这将是我们由spout发出的输入元组。如您从[第2章](kindle_split_010.html#ch02)中回忆的那样，*元组*是Storm表示数据点的原始数据结构，而*spout*是元组流的来源。
- en: 'We have the end goal of building a heat map with the latest activity at bars.
    So we need to end up with data points representing timely coordinates on a map.
    We can attach a time interval (say 9:00:00 PM to 9:00:15 PM, if we want 15-second
    increments) to a set of coordinates that occurred within that interval. Then at
    the point of display within the heat map, we can pick the latest available time
    interval. Coordinates on a map can be expressed by way of latitude and longitude
    (say, 40.7142° N, 74.0064° W for New York, NY). It’s standard form to represent
    40.7142° N, 74.0064° W as (40.7142, -74.0064). But there might be multiple coordinates
    representing multiple check-ins within a time window. So we need a list of coordinates
    for a time interval. Then our end data point starts to look like this:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是构建一个显示酒吧最新活动的热图。因此，我们需要最终得到表示地图上及时坐标的数据点。我们可以将一个时间间隔（例如，如果我们想要15秒的增量，可以说从晚上9:00:00到9:00:15）附加到该间隔内发生的一组坐标上。然后在热图显示的点，我们可以选择最新的可用时间间隔。地图上的坐标可以通过纬度和经度来表示（例如，纽约，纽约的纬度为40.7142°
    N，经度为74.0064° W）。将40.7142° N，74.0064° W表示为（40.7142，-74.0064）是标准形式。但是，可能会有多个坐标表示在时间窗口内的多个签到。因此，我们需要一个时间间隔的坐标列表。然后我们的最终数据点开始看起来像这样：
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: That’s an end data point containing a time interval and two corresponding check-ins
    at two different bars.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个包含时间间隔和两个不同酒吧对应签到的最终数据点。
- en: What if there’s two or more check-ins at the same bar within that time interval?
    Then that coordinate will be duplicated. How would we handle that? One option
    is to keep counts of occurrences within that time window for that coordinate.
    This involves determining sameness of coordinates based on some arbitrary but
    useful degree of precision. To avoid all that, let’s keep duplicates of any coordinate
    within a time interval with multiple check-ins. By adding multiples of the same
    coordinates to a heat map, we can let the map generator make use of multiple occurrences
    as a level of hotness (rather than using occurrence count for that purpose).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在那个时间间隔内同一酒吧有两次或更多签到怎么办？那么那个坐标将被重复。我们如何处理这种情况？一个选择是记录该坐标在该时间窗口内的出现次数。这涉及到根据一些任意但有用的精度确定坐标的相同性。为了避免所有这些，让我们在多个签到的时间间隔内保留任何坐标的副本。通过将相同坐标的多个倍数添加到热图中，我们可以让地图生成器利用多个出现次数作为热度级别（而不是使用出现次数来达到这个目的）。
- en: 'Our end data point will look like this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标数据点将看起来像这样：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that the first coordinate is duplicated. This is our end tuple that will
    be served up in the form of a heat map. Having a list of coordinates grouped by
    a time interval has these advantages:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，第一个坐标是重复的。这是我们最终元组，将以热图的形式提供。按时间间隔分组坐标列表有以下优点：
- en: Allows us to easily build a heat map by using the Google Maps API. We can do
    this by adding a heat map overlay on top of a regular Google Map.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许我们通过使用Google Maps API轻松构建热图。我们可以通过在常规Google地图上添加热图覆盖来实现这一点。
- en: Let us go back in time to any particular time interval and see the heat map
    for that point in time.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让我们回到过去，查看任何特定时间间隔的热图。
- en: Having the input data points and final data points is only part of the picture;
    we still need to identify how we get from point A to point B.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有输入数据点和最终数据点只是问题的一部分；我们仍然需要确定如何从A点到B点。
- en: 3.3.3\. Steps for determining the topology composition
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.3. 确定拓扑结构的步骤
- en: 'Our approach for designing a Storm topology can be broken down into three steps:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计Storm拓扑的方法可以分为三个步骤：
- en: Determine the input data points and how they can be represented as tuples.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定输入数据点以及它们如何表示为元组。
- en: Determine the final data points needed to solve the problem and how they can
    be represented as tuples.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定解决问题所需的最终数据点以及它们如何表示为元组。
- en: Bridge the gap between the input tuples and the final tuples by creating a series
    of operations that transform them.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过创建一系列操作来连接输入元组和最终元组，以填补它们之间的差距。
- en: 'We already know our input and desired output:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道我们的输入和期望的输出：
- en: 'Input tuples:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 输入元组：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'End tuples:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最终元组：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Somewhere along the way, we need to transform the addresses of bars into these
    end tuples. [Figure 3.2](#ch03fig02) shows how we can break down the problem into
    these series of operations.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个过程中，我们需要将酒吧地址转换为这些最终元组。[图3.2](#ch03fig02)展示了我们如何将这些操作分解成一系列。
- en: Figure 3.2\. Transforming input tuples to end tuples via a series of operations
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.2. 通过一系列操作将输入元组转换为最终元组
- en: '![](03fig02_alt.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig02_alt.jpg)'
- en: Let’s take these steps and see how they map onto Storm primitives (we’re using
    the terms *Storm primitives* and *Storm concepts* interchangeably).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些步骤是如何映射到Storm原语（我们使用*Storm原语*和*Storm概念*这两个术语互换）的。
- en: Operations as spouts and bolts
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 作为spout和bolt的操作
- en: 'We’ve created a series of operations to transform input tuples to end tuples.
    Let’s see how these four operations map to Storm primitives:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一系列操作，将输入元组转换为最终元组。让我们看看这四个操作是如何映射到Storm原语的：
- en: '**`Checkins`—** This will be the source of input tuples into the topology,
    so in terms of Storm concepts this will be our spout. In this case, because we’re
    using an unreliable data source, we’ll build a spout that has no capability of
    retrying failures. We’ll get into retrying failures in [chapter 4](kindle_split_012.html#ch04).'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`Checkins`—** 这将是输入元组进入拓扑的来源，因此在Storm的概念中，这将是我们的spout。在这种情况下，因为我们使用的是一个不可靠的数据源，我们将构建一个没有重试失败能力的spout。我们将在第4章中讨论重试失败。'
- en: '**`GeocodeLookup`—** This will take our input tuple and convert the street
    address to a geocoordinate by querying the Google Maps Geocoding API. This is
    the first bolt in the topology.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`GeocodeLookup`—** 这将接收我们的输入元组，并通过查询Google Maps Geocoding API将街道地址转换为地理坐标。这是拓扑中的第一个bolt。'
- en: '**`HeatMapBuilder`—** This is the second bolt in the topology, and it’ll keep
    a data structure in memory to map each incoming tuple to a time interval, thereby
    grouping check-ins by time interval. When each time interval is completely passed,
    it’ll emit the list of coordinates associated with that time interval.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`HeatMapBuilder`—** 这是拓扑中的第二个bolt，它将在内存中保持一个数据结构，将每个传入的元组映射到一个时间间隔，从而按时间间隔分组签到。当每个时间间隔完全过去后，它将发出与该时间间隔相关的坐标列表。'
- en: '**`Persistor`—** We’ll use this third and final bolt in our topology to save
    our end tuples to a database.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`Persistor`—** 我们将在我们的拓扑中使用这个第三个也是最后一个bolt来将我们的最终元组保存到数据库中。'
- en: '[Figure 3.3](#ch03fig03) provides an illustration of the design mapped to Storm
    concepts.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3.3](#ch03fig03) 提供了设计映射到Storm概念的说明。'
- en: Figure 3.3\. Heat map design mapped to Storm concepts
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.3\. 热图设计映射到Storm概念
- en: '![](03fig03_alt.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![03fig03_alt.jpg]'
- en: So far we’ve discussed the tuples, spout, and bolts. One thing in [figure 3.3](#ch03fig03)
    that we haven’t talked about is the stream grouping for each stream. We’ll get
    into each grouping in more detail when we cover the code for the topology in the
    next section.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了元组、spout和bolt。在[图3.3](#ch03fig03)中，有一件事我们没有讨论，那就是每个流的流分组。当我们下一节讨论拓扑的代码时，我们将更详细地介绍每个分组。
- en: 3.4\. Initial implementation of the design
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4\. 设计的初始实现
- en: With the design complete, we’re ready to tackle the implementation for each
    of the components. Much as we did in [chapter 2](kindle_split_010.html#ch02),
    we’ll start with the code for the spout and bolts, and finish with the code that
    wires it all together. Later we’ll adjust each of these implementations for efficiency
    or to address some of their shortcomings.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 设计完成后，我们准备着手实现每个组件的实现。就像我们在第2章中做的那样，我们将从spout和bolt的代码开始，并以将它们全部连接起来的代码结束。稍后，我们将调整这些实现以提高效率或解决它们的一些不足。
- en: '3.4.1\. Spout: read data from a source'
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.1\. Spout：从源读取数据
- en: In our design, the spout listens to a fire hose of social check-ins and emits
    a tuple for each individual check-in. [Figure 3.4](#ch03fig04) provides a reminder
    of where we are in our topology design.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的设计中，spout监听社交签到的大流量，并为每个单独的签到发出一个元组。[图3.4](#ch03fig04) 提供了我们在拓扑设计中的位置提醒。
- en: Figure 3.4\. The spout listens to the fire hose of social check-ins and emits
    a tuple for each check-in.
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.4\. spout监听社交签到的大流量，并为每个签到发出一个元组。
- en: '![](03fig04.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![03fig04.jpg]'
- en: For the purpose of this chapter, we’ll use a text file as our source of data
    for check-ins. To feed this data set into our Storm topology, we need to write
    a spout that reads from this file and emits a tuple for each line. The file, checkins.txt,
    will live next to the class for our spout and contain a list of check-ins in the
    expected format (see the following listing).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了本章的目的，我们将使用一个文本文件作为签到数据源。为了将这个数据集输入到我们的Storm拓扑中，我们需要编写一个从该文件读取并为每行发出一个元组的spout。文件checkins.txt将位于我们的spout类旁边，并包含按预期格式列出的签到列表（见以下列表）。
- en: Listing 3.1\. An excerpt from our simple data source, checkins.txt
  id: totrans-101
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.1\. 我们简单数据源checkins.txt的摘录
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The next listing shows the spout implementation that reads from this file of
    check-ins. Because our input tuple is a time and address, we’ll represent the
    time as a `Long` (millisecond-level Unix timestamp) and the address as a `String`,
    with the two separated by a comma in our text file.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表显示了读取此检查文件泄漏的泄漏实现。由于我们的输入元组是时间和地址，我们将时间表示为 `Long`（毫秒级 Unix 时间戳），将地址表示为
    `String`，在文本文件中以逗号分隔这两个。
- en: Listing 3.2\. `Checkins.java`
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.2\. `Checkins.java`
- en: '![](ch03ex02-0.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](ch03ex02-0.jpg)'
- en: '![](ch03ex02-1.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](ch03ex02-1.jpg)'
- en: Because we’re treating this as an unreliable data source, the spout remains
    simple; it doesn’t need to keep track of which tuples failed and which ones succeeded
    in order to provide fault tolerance. Not only does that simplify the spout implementation,
    it also removes quite a bit of bookkeeping that Storm needs to do internally and
    speeds things up. When fault tolerance isn’t necessary and we can define a service-level
    agreement (SLA) that allows us to discard data at will, an unreliable data source
    can be beneficial. It’s easier to maintain and provides fewer points of failure.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将此视为不可靠的数据源，因此泄漏保持简单；它不需要跟踪哪些元组失败以及哪些元组成功，以便提供容错性。这不仅简化了泄漏实现，还减少了 Storm
    需要内部进行的记录工作，从而加快了速度。当不需要容错性并且我们可以定义一个服务级别协议（SLA），允许我们随意丢弃数据时，不可靠的数据源可以是有益的。它更容易维护，并且提供了更少的故障点。
- en: '3.4.2\. Bolt: connect to an external service'
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.2\. 螺栓：连接到外部服务
- en: The first bolt in the topology will take the address data point from the tuple
    emitted by the `Checkins` spout and translate that address into a coordinate by
    querying the Google Maps Geocoding Service. [Figure 3.5](#ch03fig05) highlights
    the bolt we’re currently implementing.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑中的第一个螺栓将接收由 `Checkins` 泄露的元组中的地址数据点，并通过查询谷歌地图地理编码服务将该地址转换为坐标。[图 3.5](#ch03fig05)
    突出了我们目前正在实现的螺栓。
- en: Figure 3.5\. The geocode lookup bolt accepts a social check-in and retrieves
    the coordinates associated with that check-in.
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.5\. 地理编码查找螺栓接受社交检查并检索与该检查相关的坐标。
- en: '![](03fig05.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig05.jpg)'
- en: The code for this bolt can be seen in [listing 3.3](#ch03ex03). We’re using
    the Google Geocoder Java API from [https://code.google.com/p/geocoder-java/](https://code.google.com/p/geocoder-java/)
    to retrieve the coordinates.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这个螺栓的代码可以在[列表 3.3](#ch03ex03)中看到。我们使用来自[https://code.google.com/p/geocoder-java/](https://code.google.com/p/geocoder-java/)的谷歌地理编码
    Java API 来检索坐标。
- en: Listing 3.3\. `GeocodeLookup.java`
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.3\. `GeocodeLookup.java`
- en: '![](ch03ex03-0.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](ch03ex03-0.jpg)'
- en: '![](ch03ex03-1.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](ch03ex03-1.jpg)'
- en: We’ve intentionally kept our interaction with Google Geocoding API simple. In
    a real implementation we should be handling for error cases when addresses may
    not be valid. Additionally, the Google Geocoding API imposes a quota when used
    in this way that’s quite small and not practical for big data applications. For
    a big data application like this, you’d need to obtain an access level with a
    higher quota from Google if you wanted to use them as a provider for Geocoding.
    Other approaches to consider include locally caching geocoding results within
    your data center to avoid making unnecessary invocations to Google’s API.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有意使与谷歌地理编码 API 的交互保持简单。在实际实现中，我们应该处理地址可能无效的错误情况。此外，谷歌地理编码 API 在这种方式下使用时施加配额，这个配额相当小，对于大数据应用来说不实用。对于这样一个大数据应用，如果你想使用它们作为地理编码的提供者，你需要从谷歌获得一个具有更高配额的访问级别。其他可以考虑的方法包括在数据中心本地缓存地理编码结果，以避免对谷歌
    API 进行不必要的调用。
- en: We now have the time and geocoordinate of every check-in. We took our input
    tuple
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了每个检查的时间地理坐标。我们取我们的输入元组
- en: '[PRE6]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'and transformed it into this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 并将其转换成这样：
- en: '[PRE7]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This new tuple will then be sent to the bolt that maintains groups of check-ins
    by time interval, which we’ll look at now.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新的元组将被发送到通过时间间隔维护检查组群的螺栓，我们现在将探讨这一点。
- en: '3.4.3\. Bolt: collect data in-memory'
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.3\. 螺栓：内存中收集数据
- en: Next, we’ll build the data structure that represents the heat map. [Figure 3.6](#ch03fig06)
    illustrates our location in the design.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将构建表示热图的数据结构。[图 3.6](#ch03fig06) 展示了我们在设计中的位置。
- en: Figure 3.6\. The heat map builder bolt accepts a tuple with time and geocode
    and emits a tuple containing a time interval and a list of geocodes.
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.6\. 热图构建螺栓接受包含时间和地理编码的元组，并发出包含时间间隔和地理编码列表的元组。
- en: '![](03fig06.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig06.jpg)'
- en: What kind of data structure is suitable here? We have tuples coming into this
    bolt from the previous `GeocodeLookup` bolt in the form of `[time="9:00 PM", geocode=
    "40.72612,-74.001396"]`. We need to group these by time intervals—let’s say 15-second
    intervals because we want to display a new heat map every 15 seconds. Our end
    tuples need to be in the form of `[time-interval="9:00:00 PM to 9:00:15 PM", hotzones=
    List((40.719908,-73.987277),(40.72612,-74.001396),(40.719908,-73.987277))]`.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这里适合哪种数据结构？我们从这个 bolt 的前一个 `GeocodeLookup` bolt 接收元组，形式为 `[time="9:00 PM", geocode=
    "40.72612,-74.001396"]`。我们需要按时间间隔对这些进行分组——让我们假设是 15 秒的间隔，因为我们想每 15 秒显示一个新的热图。我们的最终元组需要以
    `[time-interval="9:00:00 PM to 9:00:15 PM", hotzones= List((40.719908,-73.987277),(40.72612,-74.001396),(40.719908,-73.987277))]`
    的形式存在。
- en: 'To group geocoordinates by time interval, let’s maintain a data structure in
    memory and collect incoming tuples into that data structure isolated by time interval.
    We can model this as a map:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要按时间间隔分组地理坐标，我们可以在内存中维护一个数据结构，并将传入的元组收集到该数据结构中，这些数据结构由时间间隔隔离。我们可以将其建模为一个映射：
- en: '[PRE8]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This map is keyed by the time that starts our interval. We can omit the end
    of the time interval because each interval is of the same length. The value will
    be the list of coordinates that fall into that time interval (including duplicates—duplicates
    or coordinates in closer proximity would indicate a hot zone or intensity on the
    heat map).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 此映射的键是我们间隔开始的时间。我们可以省略时间间隔的结束，因为每个间隔长度相同。值将是落入该时间间隔的坐标列表（包括重复项——重复项或更接近的坐标将表示热图上的热点区域或强度）。
- en: 'Let’s start building the heat map in three steps:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分三步开始构建热图：
- en: Collect incoming tuples into an in-memory map.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将传入的元组收集到内存映射中。
- en: Configure this bolt to receive a signal at a given frequency.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置此 bolt 接收给定频率的信号。
- en: Emit the aggregated heat map for elapsed time intervals to the `Persistor` bolt
    for saving to a database.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将经过的时间间隔的聚合热图发射到 `Persistor` bolt 以保存到数据库。
- en: Let’s look at each step individually, and then we can put everything together,
    starting with the next listing.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐个查看每个步骤，然后我们可以将所有内容组合起来，从下一个列表开始。
- en: 'Listing 3.4\. `HeatMapBuilder.java`: step 1, collecting incoming tuples into
    an in-memory map'
  id: totrans-135
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '列表 3.4\. `HeatMapBuilder.java`: 第 1 步，将传入的元组收集到内存映射中'
- en: '![](045fig01_alt.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![045fig01_alt.jpg](045fig01_alt.jpg)'
- en: The absolute time interval the incoming tuple falls into is selected by taking
    the check-in time and dividing it by the length of the interval—in this case,
    15 seconds. For example, if check-in time is 9:00:07.535 PM, then it should fall
    into the time interval 9:00:00.000–9:00:15.000 PM. What we’re extracting here
    is the beginning of that time interval, which is 9:00:00.000 PM.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 进入的元组所属的绝对时间间隔是通过将签到时间除以间隔长度来选择的——在本例中为 15 秒。例如，如果签到时间是下午 9:00:07.535，那么它应该落在下午
    9:00:00.000–9:00:15.000 的时间间隔内。我们在这里提取的是该时间间隔的开始，即下午 9:00:00.000。
- en: Now that we’re collecting all the tuples into a heat map, we need to periodically
    inspect it and emit the coordinates from completed time intervals so that they
    can be persisted into a data store by the next bolt.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正在收集所有元组到一个热图中，我们需要定期检查它，并从完成的时间间隔中发射坐标，以便它们可以通过下一个 bolt 持久化存储。
- en: Tick tuples
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 检查元组
- en: Sometimes you need to trigger an action periodically, such as aggregating a
    batch of data or flushing some writes to a database. Storm has a feature called
    *tick tuples* to handle this eventuality. Tick tuples can be configured to be
    received at a user-defined frequency and when configured, the `execute` method
    on the bolt will receive the tick tuple at the given frequency. You need to inspect
    the tuple to determine whether it’s one of these system-emitted tick tuples or
    whether it’s a normal tuple. Normal tuples within a topology will flow through
    the default stream, whereas tick tuples are flowing through a system tick stream,
    making them easily identifiable. The following listing shows the code for configuring
    and handling tick tuples in the `HeatMapBuilder` bolt.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 有时你需要定期触发一个动作，比如聚合一批数据或将一些写入操作刷新到数据库中。Storm 有一个名为 *tick tuples* 的功能来处理这种情况。Tick
    tuples 可以配置为以用户定义的频率接收，当配置后，bolt 上的 `execute` 方法将以给定频率接收 tick tuple。你需要检查元组以确定它是否是这些系统发出的
    tick tuples 之一，或者它是否是一个普通元组。拓扑中的普通元组将通过默认流流动，而 tick tuples 则通过系统 tick 流流动，这使得它们很容易被识别。以下列表显示了在
    `HeatMapBuilder` bolt 中配置和处理 tick tuples 的代码。
- en: 'Listing 3.5\. `HeatMapBuilder.java`: step 2, configuring to receive a signal
    at a given frequency'
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '列表 3.5\. `HeatMapBuilder.java`: 第 2 步，配置接收给定频率的信号'
- en: '![](046fig01_alt.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图片](046fig01_alt.jpg)'
- en: Looking at the code in [listing 3.5](#ch03ex05), you’ll notice that tick tuples
    are configured at the bolt level, as demonstrated by the `getComponentConfiguration`
    implementation. The tick tuple in question will only be sent to instances of this
    bolt.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 查看代码在[列表3.5](#ch03ex05)，你会注意到tick元组是在bolt级别配置的，如`getComponentConfiguration`实现所示。相关的tick元组将只发送到这个bolt的实例。
- en: '|  |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Emit frequencies of tick tuples**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**tick元组的发射频率**'
- en: We configured our tick tuples to be emitted at a frequency of every 60 seconds.
    This doesn’t mean they’ll be emitted exactly every 60 seconds; it’s done on a
    best-effort basis. Tick tuples that are sent to a bolt are queued behind the other
    tuples currently waiting to be consumed by the `execute()` method on that bolt.
    A bolt may not necessarily process the tick tuples at the frequency that they’re
    emitted if the bolt is lagging behind due to high latency in processing its regular
    stream of tuples.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们配置了tick元组以每60秒的频率发射。这并不意味着它们会精确地每60秒发射一次；这是尽力而为的方式。发送到bolt的tick元组将排队在等待被该bolt的`execute()`方法消费的其他元组后面。如果bolt因为处理常规元组流的延迟而落后，它可能不会以发射频率处理tick元组。
- en: '|  |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Now let’s use that tick tuple as a signal to select time periods that have passed
    for which we no longer expect any incoming coordinates, and emit them from this
    bolt so that the next bolt down the line can take them on (see the next listing).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用这个tick元组作为信号来选择已经过去的时间段，我们不再期望有新的坐标进入，并从这个bolt中发射它们，以便下一个bolt可以接收（参见下一列表）。
- en: 'Listing 3.6\. `HeatMapBuilder.java`: step 3, emitting the aggregated HeatMap
    for elapsed time intervals'
  id: totrans-149
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.6\. `HeatMapBuilder.java`：步骤3，发射经过时间间隔的聚合HeatMap
- en: '![](ch03ex06-0.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![图片](ch03ex06-0.jpg)'
- en: '![](ch03ex06-1.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图片](ch03ex06-1.jpg)'
- en: Steps 1, 2, and 3 provide a complete `HeatMapBuilder` implementation, showing
    how you can maintain state with an in-memory map and also how you can use Storm’s
    built-in tick tuple to emit a tuple at particular time intervals. With this implementation
    complete, let’s move on to persisting the results of the tuples emitted by `HeatMapBuilder`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤1、2和3提供了一个完整的`HeatMapBuilder`实现，展示了如何使用内存中的映射来维护状态，以及如何使用Storm的内置tick元组在特定时间间隔发射元组。随着这个实现的完成，让我们继续持久化由`HeatMapBuilder`发射的元组的结果。
- en: '|  |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Thread safety**'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**线程安全**'
- en: We’re collecting coordinates into an in-memory map, but we created it as an
    instance of a regular `HashMap`. Storm is highly scalable, and there are multiple
    tuples coming in that are added to this map, and we’re also periodically removing
    entries from that map. Is modifying an in-memory data structure like this thread-safe?
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在将坐标收集到一个内存映射中，但我们创建它作为一个常规`HashMap`的实例。Storm非常可扩展，有多个元组进入并添加到这个映射中，我们也会定期从这个映射中删除条目。像这样修改内存数据结构是否是线程安全的？
- en: Yes, it’s thread-safe because `execute()` is processing only one tuple at a
    time. Whether it’s our regular stream of tuples or a tick tuple, only one JVM
    thread of execution will be going through and processing code within an instance
    of this bolt. So within a given bolt instance, there will never be multiple threads
    running through it.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，它是线程安全的，因为`execute()`一次只处理一个元组。无论是我们的常规元组流还是tick元组，只有一个JVM执行线程会通过并处理这个bolt实例中的代码。所以在一个特定的bolt实例中，永远不会有多线程通过它。
- en: Does that mean you never need to worry about thread safety within the confines
    of your bolt? No, in certain cases you might.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这是否意味着你永远不会在bolt的范围内担心线程安全？不，在某些情况下你可能需要。
- en: One such case has to do with how values within a tuple are serialized on a different
    thread when being sent between bolts. For example, when you emit your in-memory
    data structure without copying it and it’s serialized on a different thread, if
    that data structure is changed during the serialization process, you’ll get a
    `Concurrent-ModificationException`. Theoretically, everything emitted to an `OutputCollector`
    should guard against such scenarios. One way to do this is make any emitted values
    immutable.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种情况与元组在发送到bolt之间在不同线程上序列化时的值有关。例如，当你不复制内存中的数据结构而直接发射它，并且它在不同线程上序列化时，如果在序列化过程中改变了该数据结构，你会得到一个`Concurrent-ModificationException`。理论上，所有发射到`OutputCollector`的东西都应该防范此类场景。一种方法是将发射的任何值都设置为不可变的。
- en: Another case is where you may create threads of your own with the bolt’s `execute()`
    method. For example, if instead of using tick tuples, you spawned a background
    thread that periodically emits heat maps, then you’ll need to concern yourself
    with thread safety, because you’ll have your own thread and Storm’s thread of
    execution both running through your bolt.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个案例是，您可能可以使用bolt的`execute()`方法创建自己的线程。例如，如果您不是使用tick tuples，而是启动了一个定期发出热图的背景线程，那么您需要关注线程安全性，因为您将有自己的线程和Storm的执行线程都通过您的bolt运行。
- en: '|  |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '3.4.4\. Bolt: persisting to a data store'
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.4. Bolt：持久化到数据存储
- en: We have the end tuples that represent a heat map. At this point, we’re ready
    to persist that data to some data store. Our JavaScript-based web application
    can read the heat map values from this data store and interact with the Google
    Maps API to build a geographical visualization from these calculated values. [Figure
    3.7](#ch03fig07) illustrates the final bolt in our design.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有表示热图的最终元组。在这个阶段，我们准备将数据持久化到某个数据存储中。我们的基于JavaScript的Web应用程序可以从这个数据存储中读取热图值，并与Google
    Maps API交互，从这些计算值中构建地理可视化。[图3.7](#ch03fig07)说明了我们设计中的最终bolt。
- en: Figure 3.7\. The `Persistor` bolt accepts a tuple with a time interval and a
    list of geocodes and persists that data to a data store.
  id: totrans-163
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.7. `Persistor` bolt接受一个包含时间间隔和地理编码列表的元组，并将这些数据持久化到数据存储中。
- en: '![](03fig07.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig07.jpg)'
- en: Because we’re storing and accessing heat maps based on time interval, it makes
    sense to use a key-value data model for storage. For this case study, we’ll use
    Redis, but any data store that supports the key-value model will suffice (such
    as Membase, Memcached, or Riak). We’ll store the heat maps keyed by time interval
    with the heat map itself as a JSON representation of the list of coordinates.
    We’ll use Jedis as a Java client for Redis and the Jackson JSON library for converting
    the heat map to JSON.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们根据时间间隔存储和访问热图，因此使用键值数据模型进行存储是有意义的。在本案例研究中，我们将使用Redis，但任何支持键值模型的数据存储都足够（例如Membase、Memcached或Riak）。我们将使用时间间隔作为键，将热图本身作为坐标列表的JSON表示来存储热图。我们将使用Jedis作为Redis的Java客户端，并使用Jackson
    JSON库将热图转换为JSON。
- en: '|  |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**NoSQL and other data stores with Storm**'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**NoSQL和其他与Storm一起使用的数据存储**'
- en: Examining the various NoSQL and data storage solutions available for working
    with large data sets is outside the scope of this book, but make sure you start
    off on the right foot when making your selections with regard to data storage
    solutions.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 检查可用于处理大数据集的各种NoSQL和数据存储解决方案超出了本书的范围，但请确保在选择数据存储解决方案时从正确的起点开始。
- en: It’s common for people to consider the various options available to them and
    ask themselves, “Which one of these NoSQL solutions should I pick?” This is the
    wrong approach. Instead, ask yourself questions about the functionality you’re
    implementing and the requirements they impose on any data storage solution.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 人们通常会考虑他们可用的各种选项，并问自己，“我应该选择这些NoSQL解决方案中的哪一个？”这是错误的方法。相反，你应该问自己关于你正在实施的功能以及它们对任何数据存储解决方案提出的要求的问题。
- en: 'You should be asking whether your use case requires a data store that supports
    the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该问自己，你的用例是否需要一个支持以下功能的数据存储：
- en: Random reads or random writes
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机读取或随机写入
- en: Sequential reads or sequential writes
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺序读取或顺序写入
- en: High read throughput or high write throughput
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高读取吞吐量或高写入吞吐量
- en: Whether the data changes or remains immutable once written
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据一旦写入是否改变或保持不变
- en: Storage model suitable for your data access patterns
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适合您数据访问模式的存储模型
- en: Column/column-family oriented
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列/列族导向
- en: Key-value
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 键值
- en: Document oriented
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档导向
- en: Schema/schemaless
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式/无模式
- en: Whether consistency or availability is most desirable
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否更希望一致性或可用性
- en: Once you’ve determined your mix of requirements, it’s easy to figure out which
    of the available NoSQL, NewSQL, or other solutions are suitable for you. There’s
    no right NoSQL solution for all problems. There’s also no perfect data store for
    use with Storm—it depends on the use case.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确定了你的需求组合，很容易找出哪些可用的NoSQL、NewSQL或其他解决方案适合你。没有一种NoSQL解决方案适合所有问题。也没有一种完美的数据存储适合与Storm一起使用——它取决于用例。
- en: '|  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: So let’s take a look at the code for writing to this NoSQL data store (see the
    following listing).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们看看写入这个NoSQL数据存储的代码（见以下列表）。
- en: Listing 3.7\. `Persistor.java`
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.7. `Persistor.java`
- en: '![](ch03ex07-0.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](ch03ex07-0.jpg)'
- en: '![](ch03ex07-1.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](ch03ex07-1.jpg)'
- en: Working with Redis is simple, and it serves as a good store for our use case.
    But for larger-scale applications and data sets, a different data store may be
    necessary. One thing to note is that because we’re working with an unreliable
    data stream, we’re simply logging any errors that may occur while saving to the
    database. Some errors may be able to be retried (say, a timeout), and when working
    with a reliable data stream, we’d consider how to retry them, as you’ll see in
    [chapter 4](kindle_split_012.html#ch04).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 与Redis一起工作很简单，它作为我们的用例的良好存储。但对于更大规模的应用和数据集，可能需要不同的数据存储。需要注意的是，因为我们正在处理一个不可靠的数据流，所以我们只是记录在保存到数据库时可能发生的任何错误。一些错误可能可以重试（例如，超时），而在与可靠数据流一起工作时，我们会考虑如何重试它们，正如你将在[第4章](kindle_split_012.html#ch04)中看到的。
- en: 3.4.5\. Defining stream groupings between the components
  id: totrans-188
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.5\. 定义组件之间的流分组
- en: 'In [chapter 2](kindle_split_010.html#ch02), you learned two ways of connecting
    components within a topology to one another—shuffle grouping and fields grouping.
    To recap:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](kindle_split_010.html#ch02)中，你学习了两种将拓扑内部组件连接到彼此的方法——洗牌分组和字段分组。为了回顾：
- en: You use shuffle grouping to distribute outgoing tuples from one component to
    the next in a manner that’s random but evenly spread out.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你使用洗牌分组以随机但均匀分布的方式将一个组件的输出元组分布到下一个组件。
- en: You use fields grouping when you want to ensure tuples with the same values
    for a selected set of fields always go to the same instance of the next bolt.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你想确保具有选定字段相同值的元组总是流向下一个螺栓的同一实例时，你使用字段分组。
- en: A shuffle grouping should suffice for the streams between `Checkins`/`GeocodeLookup`
    and `HeatMapBuilder`/`Persistor`.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`Checkins`/`GeocodeLookup`和`HeatMapBuilder`/`Persistor`之间的流，简单的洗牌分组应该足够。
- en: But we need to send the entire stream of outgoing tuples from the `GeocodeLookup`
    bolt to the `HeatMapBuilder` bolt. If different tuples from `GeocodeLookup` end
    up going to different instances of `HeatMapBuilder`, then we won’t be able to
    group them into time intervals because they’ll be spread out among different instances
    of `HeatMapBuilder`. This is where global grouping comes in. *Global grouping*
    will ensure that the entire stream of tuples will go to one specific instance
    of `HeatMapBuilder`. Specifically, the entire stream will go to the instance of
    `HeatMapBuilder` with the lowest task ID (an ID assigned internally by Storm).
    Now we have every tuple in one place and we can easily determine which time interval
    any tuple falls into and group them into their corresponding time intervals.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们需要将`GeocodeLookup`螺栓发出的整个元组流发送到`HeatMapBuilder`螺栓。如果来自`GeocodeLookup`的不同元组最终被发送到不同的`HeatMapBuilder`实例，那么我们就无法将它们分组到时间间隔中，因为它们将分布在不同的`HeatMapBuilder`实例中。这就是全局分组发挥作用的地方。*全局分组*将确保整个元组流都流向一个特定的`HeatMapBuilder`实例。具体来说，整个流将流向具有最低任务ID的`HeatMapBuilder`实例（由Storm内部分配的ID）。现在我们所有的元组都在一个地方，我们可以轻松地确定任何元组所属的时间间隔并将它们分组到相应的间隔中。
- en: '|  |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-195
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: Instead of using a global grouping you could have a single instance of the `HeatMapBuilder`
    bolt with a shuffle grouping. This will also guarantee that everything goes to
    the same `HeatMapBuilder` instance, as there is only one. But we favor being explicit
    in our code, and using a global grouping clearly conveys the desired behavior
    here. A global grouping is also slightly cheaper, as it doesn’t have to pick a
    random instance to emit to as in a shuffle grouping.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以选择不使用全局分组，而是一个`HeatMapBuilder`螺栓的单例实例与洗牌分组。这也会保证一切都会流向同一个`HeatMapBuilder`实例，因为只有一个。但我们更喜欢在代码中明确表达，使用全局分组清楚地传达了这里期望的行为。全局分组也稍微便宜一些，因为它不需要像洗牌分组那样选择一个随机实例来发射。
- en: '|  |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Let’s take a look at how we’d define these stream groupings in the code for
    building and running our topology.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们如何在代码中定义这些流分组，以构建和运行我们的拓扑。
- en: 3.4.6\. Building a topology for running in local cluster mode
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.6\. 在本地集群模式下运行拓扑结构
- en: 'We’re almost done. We just need to wire everything together and run the topology
    in local cluster mode, just like we did in [chapter 2](kindle_split_010.html#ch02).
    But in this chapter, we’re going to deviate from having all the code in a single
    `LocalTopologyRunner` class and split the code into two classes: one class for
    building the topology and another for running it. This is a common practice and
    while you might not see the benefits immediately in this chapter, hopefully in
    [chapters 4](kindle_split_012.html#ch04) and [5](kindle_split_013.html#ch05) you’ll
    see why we’ve decided to do this.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎完成了。我们只需要将所有东西连接起来，并在本地集群模式下运行拓扑，就像我们在第 2 章中做的那样。但在本章中，我们将偏离将所有代码放在单个 `LocalTopologyRunner`
    类中的做法，将代码分成两个类：一个用于构建拓扑，另一个用于运行它。这是一个常见的做法，虽然你在这章中可能看不到立即的好处，但希望在第 4 章和第 5 章中你会看到我们为什么这样做的原因。
- en: The following listing shows you the code for building the topology.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表展示了构建拓扑结构的代码。
- en: Listing 3.8\. `HeatmapTopologyBuilder.java`
  id: totrans-202
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.8. `HeatmapTopologyBuilder.java`
- en: '![](052fig01_alt.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图片](052fig01_alt.jpg)'
- en: With the code for building the topology defined, the next listing shows how
    to implement `LocalTopologyRunner`.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了构建拓扑的代码之后，下一个列表展示了如何实现 `LocalTopologyRunner`。
- en: Listing 3.9\. `LocalTopologyRunner.java`
  id: totrans-205
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.9. `LocalTopologyRunner.java`
- en: '![](052fig02_alt.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图片](052fig02_alt.jpg)'
- en: Now we have a working topology. We read check-in data from our spout, and in
    the end, we persist the coordinates grouped by time intervals into Redis and complete
    the heat map topology implementation. All we have left to do is read the data
    from Redis using a JavaScript application and use the heat map overlay feature
    of the Google Maps API to build the visualization.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个工作的拓扑。我们从我们的发射器读取提交数据，最后，我们将按时间间隔分组的坐标持久化到 Redis 中，并完成热图拓扑的实现。我们剩下要做的就是使用
    JavaScript 应用程序从 Redis 中读取数据，并使用 Google Maps API 的热图叠加功能来构建可视化。
- en: This simple implementation will run, but will it scale? Will it be fast enough?
    Let’s do some digging and find out.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的实现将会运行，但它会扩展吗？它足够快吗？让我们深入挖掘并找出答案。
- en: 3.5\. Scaling the topology
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5. 扩展拓扑结构
- en: Let’s review where we are so far. We have a working topology for our service
    that looks similar to the one shown in [figure 3.8](#ch03fig08).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下到目前为止的情况。我们有一个类似图 3.8 中所示的工作拓扑，用于我们的服务。
- en: Figure 3.8\. Heat map topology
  id: totrans-211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.8. 热图拓扑
- en: '![](03fig08.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig08.jpg)'
- en: There are problems with it. As it stands right now, this topology operates in
    a serial fashion, processing one check-in at a time. That isn’t web-scale—that’s
    Apple IIe scale. If we were to put this live, everything would back up and we
    would end up with unhappy customers, an unhappy ops team, and probably unhappy
    investors.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 它存在一些问题。就目前而言，这个拓扑以串行方式运行，一次处理一个提交。这不是 Web 规模——这是 Apple IIe 规模。如果我们将其投入实际使用，一切都会陷入停滞，我们最终会得到不满意的客户、不满意的运维团队，以及可能的不满意的投资者。
- en: '|  |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**What is web-scale?**'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么是 Web 规模？**'
- en: A system is web-scale when it can grow simply without downtime to cater to the
    demand brought about by the network effect that is the web. When each happy user
    tells 10 of their friends about your heat map, service and demand increase exponentially.
    This increase in demand is known as web-scale.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个系统可以简单地增长而不需要停机来满足由网络效应带来的需求时，它就是 Web 规模的。当每个满意的用户告诉他们的 10 个朋友关于你的热图时，服务和需求会呈指数增长。这种需求的增长被称为
    Web 规模。
- en: '|  |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: We need to process multiple check-ins at a time, so we’ll introduce parallelism
    into our topology. One property that makes Storm so alluring is how easy it is
    to parallelize workflows such as our heat map. Let’s take a look at the parts
    of the topology again and discuss how they can be parallelized. We’ll begin with
    check-ins.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要同时处理多个提交，因此我们将并行性引入到我们的拓扑中。使 Storm 如此吸引人的一个特性是并行化工作流程（如我们的热图）的简便性。让我们再次查看拓扑的各个部分，并讨论它们如何可以并行化。我们将从提交开始。
- en: 3.5.1\. Understanding parallelism in Storm
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.1. 理解 Storm 中的并行性
- en: Storm has additional primitives that serve as knobs for tuning how it can scale.
    If you don’t touch them, the topology can still work, but all components will
    run in a more or less linear fashion. This may be fine for topologies that only
    have a small stream of data flowing through them. For something like the heat
    map topology that’ll receive data from a large fire hose, we would want to address
    the bottlenecks in it. In this section, we’ll look at two of the primitives that
    deal with scaling. There are additional primitives for scaling that we’ll consider
    later in the next chapter.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 有一些额外的原语，它们可以作为调整其扩展方式的旋钮。如果你不触碰它们，拓扑仍然可以工作，但所有组件将以更或更少的线性方式运行。这可能适合只有少量数据流通过它们的拓扑。对于像热图拓扑这样的东西，它将从大口径的水管接收数据，我们希望解决其中的瓶颈。在本节中，我们将查看处理扩展的两个原语。我们将在下一章稍后考虑更多的扩展原语。
- en: Parallelism hints
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 并行度提示
- en: We know we’re going to need to process many check-ins rapidly, so we want to
    parallelize the spout that handles check-ins. [Figure 3.9](#ch03fig09) gives you
    an idea of what part of the topology we’re working on here.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道我们将会需要快速处理许多检查点，因此我们想要并行化处理检查点的发射器。[图 3.9](#ch03fig09) 给出了我们正在工作的拓扑部分的想法。
- en: Figure 3.9\. Focusing our parallelization changes on the `Checkins` spout
  id: totrans-223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.9\. 将我们的并行化更改集中在 `Checkins` 发射器上
- en: '![](03fig09.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig09.jpg)'
- en: Storm allows you to provide a parallelism hint when you define any spouts or
    bolts. In code, this would involve transforming
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: Storm 允许你在定义任何发射器或螺栓时提供并行度提示。在代码中，这涉及到将
- en: '[PRE9]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: to
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: to
- en: '[PRE10]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The additional parameter we provide to `setSpout` is the parallelism hint.
    That’s a bit of a mouthful: *parallelism hint*. So what is a parallelism hint?
    For right now, let’s say that the parallelism hint tells Storm how many check-in
    spouts to create. In our example, this results in four spout instances being created.
    There’s more to it than that, but we’ll get to that in a bit.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供给 `setSpout` 的附加参数是并行度提示。这听起来有点复杂：*并行度提示*。那么，什么是并行度提示呢？目前，我们可以这样说，并行度提示告诉
    Storm 应该创建多少个检查点发射器。在我们的例子中，这导致创建了四个发射器实例。这不仅仅是这样，但我们稍后会谈到。
- en: Now when we run our topology, we should be able to process check-ins four times
    as fast—except simply introducing more spouts and bolts into our topology isn’t
    enough. Parallelism in a topology is about both input and output. The `Checkins`
    spout can now process more check-ins at a time, but the `GeocodeLookup` bolt is
    still being handled serially. Simultaneously passing four check-ins to a single
    `GeocodeLookup` instance isn’t going to work out well. [Figure 3.10](#ch03fig10)
    illustrates the problem we’ve created.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们运行我们的拓扑时，我们应该能够以四倍的速度处理检查点——但是仅仅在我们的拓扑中引入更多的发射器和螺栓是不够的。拓扑中的并行性既涉及输入也涉及输出。`Checkins`
    发射器现在可以一次处理更多的检查点，但 `GeocodeLookup` 螺栓仍然以串行方式处理。同时将四个检查点传递给单个 `GeocodeLookup`
    实例是不会奏效的。[图 3.10](#ch03fig10) 展示了我们造成的问题。
- en: Figure 3.10\. Four `Checkins` instances emitting tuples to one `GeocodeLookup`
    instance results in the `GeocodeLookup` instance being a bottleneck.
  id: totrans-231
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.10\. 四个 `Checkins` 实例向一个 `GeocodeLookup` 实例发射元组，导致 `GeocodeLookup` 实例成为瓶颈。
- en: '![](03fig10_alt.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig10_alt.jpg)'
- en: Right now, what we have is akin to a circus clown car routine where many clowns
    all try to simultaneously pile into a car through the same door. This bottleneck
    needs to be resolved; let’s try parallelizing the geocode lookup bolt as well.
    We could just parallelize the geocode bolt in the same way we did check-ins. Going
    from this
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们面临的情况类似于马戏团的丑角汽车表演，许多丑角都试图同时通过同一个门挤进一辆车。这个瓶颈需要解决；让我们尝试并行化地理编码查找螺栓。我们可以像处理检查点一样并行化地理编码螺栓。从这一点
- en: '[PRE11]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: to this
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: to this
- en: '[PRE12]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'will certainly help. Now we have one `GeocodeLookup` instance for each `Checkins`
    instance. But `GeocodeLookup` is going to take a lot longer than receiving a check-in
    and handing it off to our bolt. So perhaps we can do something more like this:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 肯定会很有帮助。现在我们有一个 `GeocodeLookup` 实例对应于每个 `Checkins` 实例。但是 `GeocodeLookup` 将会比接收检查点并将其传递给我们的螺栓花费更长的时间。所以也许我们可以做点像这样的事情：
- en: '[PRE13]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now if `GeocodeLookup` takes two times as long as check-in handling, tuples
    should continue to flow through our system smoothly, resulting in [figure 3.11](#ch03fig11).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果 `GeocodeLookup` 比处理检查点花费两倍的时间，元组应该能够在我们系统中平稳地流动，从而产生 [图 3.11](#ch03fig11)。
- en: Figure 3.11\. Four `Checkins` instances emitting tuples to eight `GeocodeLookup`
    instances
  id: totrans-240
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.11\. 四个 `Checkins` 实例向八个 `GeocodeLookup` 实例发射元组
- en: '![](03fig11_alt.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig11_alt.jpg)'
- en: 'We’re making progress here, but there’s something else to think about: what
    happens as our service becomes more popular? We’re going to need to be able to
    continue to scale to keep pace with our ever expanding traffic without taking
    our application offline, or at least not taking it offline very often. Luckily
    Storm provides a way to do that. We loosely defined the parallelism hint earlier
    but said there was a little more to it. Well, here we are. That parallelism hint
    maps into two Storm concepts we haven’t covered yet: executors and tasks.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里取得了进展，但还有其他事情需要考虑：当我们的服务变得更受欢迎时会发生什么？我们需要能够继续扩展以跟上不断增长的流量，而不会使我们的应用程序离线，或者至少不会经常离线。幸运的是，Storm提供了一种方法来实现这一点。我们之前对并行性提示做了大致的定义，但说还有更多内容。好吧，现在我们就在这里。这个并行性提示映射到我们尚未覆盖的两个Storm概念：执行器和任务。
- en: Executors and tasks
  id: totrans-243
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 执行器和任务
- en: So what are executors and tasks? Truly understanding the answer to this question
    requires deeper knowledge of a Storm cluster and its various parts. Although we
    won’t learn any details about a Storm cluster until [chapter 5](kindle_split_013.html#ch05),
    we can provide you with a sneak peek into certain parts of a Storm cluster that’ll
    help you understand what executors and tasks are for the purpose of scaling our
    topology.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，执行器和任务是什么？真正理解这个问题的答案需要更深入地了解Storm集群及其各个部分。尽管我们直到[第5章](kindle_split_013.html#ch05)才会学习有关Storm集群的详细信息，但我们可以提前向你展示Storm集群的某些部分，这将帮助你理解执行器和任务在扩展拓扑中的作用。
- en: So far, we know that our spouts and bolts are each running as one or more instances.
    Each of these instances is running somewhere, right? There has to be some machine
    (physical or virtual) that’s actually executing our components. We’ll call this
    machine a worker node, and though a worker node isn’t the only type of node running
    on a Storm cluster, it is the node that executes the logic in our spouts and bolts.
    And because Storm runs on the JVM, each of these worker nodes is executing our
    spouts and bolts on a JVM. [Figure 3.12](#ch03fig12) shows what we have so far.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们知道我们的spouts和bolts每个都在作为一个或多个实例运行。这些实例都在某个地方运行，对吧？肯定有一些机器（物理或虚拟）实际上在执行我们的组件。我们将这个机器称为工作节点，尽管工作节点不是在Storm集群上运行的唯一类型的节点，但它是在spouts和bolts中执行逻辑的节点。由于Storm运行在JVM上，因此每个工作节点都在JVM上执行我们的spouts和bolts。[图3.12](#ch03fig12)显示了到目前为止的情况。
- en: Figure 3.12\. A worker node is a physical or virtual machine that’s running
    a JVM, which executes the logic in the spouts and bolts.
  id: totrans-246
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.12\. 工作节点是一个运行JVM的物理或虚拟机器，该JVM执行spouts和bolts中的逻辑。
- en: '![](03fig12_alt.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig12_alt.jpg)'
- en: 'There’s a little more to a worker node, but what’s important for now is that
    you understand that it runs the JVM that executes our spout and bolt instances.
    So we pose the question again: what are executors and tasks? Executors are a thread
    of execution on the JVM, and tasks are the instances of our spouts and bolts running
    within a thread of execution. [Figure 3.13](#ch03fig13) illustrates this relationship.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点还有一些其他内容，但对你来说现在重要的是要理解它运行了执行我们的spout和bolt实例的JVM。因此，我们再次提出问题：执行器和任务是什么？执行器是JVM上的一个执行线程，而任务是运行在执行线程中的我们的spouts和bolt的实例。[图3.13](#ch03fig13)说明了这种关系。
- en: Figure 3.13\. Executors (threads) and tasks (instances of spouts/bolts) run
    on a JVM.
  id: totrans-249
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.13\. 执行器（线程）和任务（spouts/bolts的实例）在JVM上运行。
- en: '![](03fig13_alt.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig13_alt.jpg)'
- en: It’s really that simple. An executor is a thread of execution within a JVM.
    A task is an instance of a spout or bolt running within that thread of execution.
    When discussing scalability in this chapter, we’re referring to changing the number
    of executors and tasks. Storm provides additional ways to scale by changing the
    number of worker nodes and JVMs, but we’re saving those for [chapters 6](kindle_split_014.html#ch06)
    and [7](kindle_split_015.html#ch07).
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 真的是这么简单。执行器是JVM中的一个执行线程。任务是运行在那个执行线程中的spout或bolt的实例。在讨论本章的可伸缩性时，我们指的是改变执行器和任务的数量。Storm通过改变工作节点和JVM的数量提供额外的扩展方式，但我们将在[第6章](kindle_split_014.html#ch06)和[第7章](kindle_split_015.html#ch07)中介绍这些内容。
- en: 'Let’s go back to our code and revisit what this means in terms of parallelism
    hints. Setting the parallelism hint to 8, as we did with `GeocodeLookup`, is telling
    Storm to create eight executors (threads) and run eight tasks (instances) of `GeocodeLookup`.
    This is seen with the following code:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们的代码，重新审视这代表什么，从并行性提示的角度来看。将并行性提示设置为8，就像我们在`GeocodeLookup`中做的那样，告诉Storm创建八个执行器（线程）并运行八个`GeocodeLookup`的任务（实例）。这可以通过以下代码看到：
- en: '[PRE14]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'By default, the parallelism hint is setting both the number of executors and
    tasks to the same value. We can override the number of tasks with the `setNumTasks()`
    method as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，并行性提示会将执行者和任务的数量设置为相同的值。我们可以使用`setNumTasks()`方法覆盖任务的数量，如下所示：
- en: '[PRE15]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Why provide the ability to set the number of tasks to something different than
    the number of executors? Before we answer this question, let’s take a step back
    and revisit how we got here. We were talking about how we’ll want to scale our
    heat map in the future without taking it offline. What’s the easiest way to do
    this? The answer: increase the parallelism. Fortunately, Storm provides a useful
    feature that allows us to increase the parallelism of a running topology by dynamically
    increasing the number of executors (threads). You’ll learn more on how this is
    done in [chapter 6](kindle_split_014.html#ch06).'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么提供将任务数量设置为与执行者数量不同的能力？在我们回答这个问题之前，让我们退一步，重新审视我们是如何到达这里的。我们正在讨论如何在将来不关闭热图的情况下对其进行扩展。最容易的方法是什么？答案是：增加并行性。幸运的是，Storm提供了一个有用的功能，允许我们通过动态增加执行者（线程）的数量来增加运行中的拓扑的并行性。你将在第6章中了解更多关于如何做到这一点的方法。[第6章](kindle_split_014.html#ch06)。
- en: What does this mean for our `GeocodeLookup` bolt with eight instances being
    run across eight threads? Well, each of those instances will spend most of its
    time waiting on network I/O. We suspect that this means `GeocodeLookup` is going
    to be a source of contention in the future and will need to be scaled up. We can
    allow for this possibility with
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这对我们运行在八个线程上的八个实例的`GeocodeLookup`螺栓意味着什么？嗯，每个实例将花费大部分时间等待网络I/O。我们怀疑这意味着`GeocodeLookup`将成为未来的争用源，并需要扩展。我们可以通过以下方式允许这种可能性：
- en: '[PRE16]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now we have 64 tasks (instances) of `GeocodeLookup` running across eight executors
    (threads). As we need to increase the parallelism of `GeocodeLookup`, we can keep
    increasing the number of executors up to a maximum of 64 without stopping our
    topology. We repeat: *without stopping the topology*. As we mentioned earlier,
    we’ll get into the details of how to do this in a later chapter, but the key point
    to understand here is that the number of executors (threads) can be dynamically
    changed in a running topology.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有64个`GeocodeLookup`的任务（实例）在八个执行者（线程）上运行。由于我们需要增加`GeocodeLookup`的并行性，我们可以继续增加执行者的数量，直到最大64个，而无需停止我们的拓扑。我们重复：*无需停止拓扑*。正如我们之前提到的，我们将在后面的章节中详细介绍如何做到这一点，但这里的关键点是执行者（线程）的数量可以在运行中的拓扑中动态更改。
- en: 'Storm breaks parallelism down into two distinct concepts of executors and tasks
    to deal with situations like we have with our `GeocodeLookup` bolt. To illustrate
    why, let’s go back to the definition of a fields grouping:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Storm将并行性分解为执行者和任务两个不同的概念，以处理像我们的`GeocodeLookup`螺栓这样的情况。为了说明原因，让我们回到字段分组的定义：
- en: A fields grouping is a type of stream grouping where tuples with the same value
    for a particular field name are always emitted to the same instance of a bolt.
  id: totrans-261
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 字段分组是一种流分组类型，其中具有特定字段名相同值的元组总是被发射到螺栓的相同实例。
- en: Within that definition lurks our answer. Fields groupings work by consistently
    hashing tuples across a set number of bolts. To keep keys with the same value
    going to the same bolt, the number of bolts can’t change. If it did, tuples would
    start going to different bolts. That would defeat the purpose of what we were
    trying to accomplish with a fields grouping.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在那个定义中隐藏着我们的答案。字段分组通过在固定数量的螺栓上持续散列元组来工作。为了保持具有相同值的键流向相同的螺栓，螺栓的数量不能改变。如果改变了，元组就会开始流向不同的螺栓。这就会违背我们通过字段分组试图实现的目的。
- en: It was easy to configure the executors and tasks on the `Checkins` spout and
    `GeocodeLookup` bolt in order to scale them at a later point in time. Sometimes,
    though, parts of our design won’t work well for scaling. Let’s look at that next.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Checkins`发射器和`GeocodeLookup`螺栓上配置执行者和任务很容易，以便在以后的时间点进行扩展。有时，我们的设计部分可能不适合扩展。让我们看看下一个问题。
- en: 3.5.2\. Adjusting the topology to address bottlenecks inherent within design
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.2. 调整拓扑以解决设计中的瓶颈
- en: '`HeatMapBuilder` is up next. Earlier we hit a bottleneck on `GeocodeLookup`
    when we increased the parallelism hint on the `Checkins` spout. But we were able
    to address this easily by increasing the parallelism on the `GeocodeLookup` bolt
    accordingly. We can’t do that here. It doesn’t make sense to increase the parallelism
    on `HeatMapBuilder` as it’s connected to the previous bolt using global grouping.
    Because global grouping dictates that every tuple goes to one specific instance
    of `HeatMapBuilder`, increasing parallelism on it doesn’t have any effect; only
    one instance will be actively working on the stream. There’s a bottleneck that’s
    inherent in the design of our topology.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '`HeatMapBuilder` 是下一个要讨论的。之前我们在增加 `Checkins` spout 的并行性提示时遇到了 `GeocodeLookup`
    的瓶颈。但通过相应地增加 `GeocodeLookup` bolt 的并行性，我们能够轻松解决这个问题。在这里我们无法这样做。由于 `HeatMapBuilder`
    是通过全局分组与前面的 bolt 连接的，因此增加其并行性没有意义。因为全局分组规定每个元组都发送到 `HeatMapBuilder` 的一个特定实例，增加其并行性没有任何效果；只有一个实例会积极处理流。我们拓扑设计中固有的瓶颈。'
- en: This is the downside of using global grouping. With global grouping, we’re trading
    our ability to scale and introducing an intentional bottleneck with being able
    to see the entire stream of tuples in one specific bolt instance.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用全局分组带来的缺点。使用全局分组，我们牺牲了扩展能力，引入了人为的瓶颈，以便在一个特定的 bolt 实例中看到整个元组流。
- en: So what can we do? Is there no way we can parallelize this step in our topology?
    If we can’t parallelize this bolt, it makes little sense to parallelize the bolts
    that follow. This is the choke point. It can’t be parallelized with the current
    design. When we come across a problem like this, the best approach is to take
    a step back and see what we can change about the topology design to achieve our
    goal.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们能做什么呢？我们是否无法在拓扑中并行化这一步骤？如果我们不能并行化这个 bolt，那么并行化后续 bolt 几乎没有意义。这是瓶颈点。它不能与当前设计并行化。当我们遇到这类问题时，最佳方法是退一步，看看我们能否通过改变拓扑设计来达到我们的目标。
- en: The reason why we can’t parallelize `HeatMapBuilder` is because all tuples need
    to go in to the same instance. All tuples have to go to the same instance because
    we need to ensure that every tuple that falls into any given time interval can
    be grouped together. So if we can ensure that every tuple that falls into given
    time interval goes into the same instance, we can have multiple instances of `HeatMapBuilder`.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能并行化 `HeatMapBuilder` 的原因是所有元组都需要进入同一个实例。所有元组都必须进入同一个实例，因为我们需要确保每个落入任何给定时间间隔的元组都能被分组在一起。所以如果我们能确保每个落入给定时间间隔的元组都进入同一个实例，我们就可以有多个
    `HeatMapBuilder` 实例。
- en: 'Right now, we use the `HeatMapBuilder` bolt to do two things:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们使用 `HeatMapBuilder` bolt 做两件事：
- en: Determine which time interval a given tuple falls into
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定给定元组所属的时间间隔
- en: Group tuples by time interval
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按时间间隔分组元组
- en: If we can move these two actions into separate bolts, we can get closer to our
    goal. Let’s look at the part of the `HeatMapBuilder` bolt that determines which
    time interval a tuple falls into in the next listing.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能将这两个操作移动到单独的 bolt 中，我们就能更接近我们的目标。让我们看看下一个列表中 `HeatMapBuilder` bolt 部分是如何确定元组所属的时间间隔的。
- en: Listing 3.10\. Determining time interval for a tuple in `HeatMapBuilder.java`
  id: totrans-273
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.10\. 在 `HeatMapBuilder.java` 中确定元组的时间间隔
- en: '[PRE17]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`HeatMapBuilder` receives a check-in time and a geocoordinate from `GeocodeLookup`.
    Let’s move this simple task of extracting the time interval out of tuple emitted
    by `GeocodeLookup` into another bolt. This bolt—let’s call it `TimeIntervalExtractor`—can
    emit a time interval and a coordinate that can be picked up by `HeatMapBuilder`
    instead, as shown in the following listing.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '`HeatMapBuilder` 从 `GeocodeLookup` 接收签到时间和地理坐标。让我们将这个从 `GeocodeLookup` 发射的元组中提取时间间隔的简单任务移动到另一个
    bolt 中。这个 bolt——让我们称它为 `TimeIntervalExtractor`——可以发射一个时间间隔和一个坐标，这些可以被 `HeatMapBuilder`
    捕获，如下列所示。'
- en: Listing 3.11\. `TimeIntervalExtractor.java`
  id: totrans-276
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.11\. `TimeIntervalExtractor.java`
- en: '![](060fig01_alt.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![060fig01_alt.jpg](060fig01_alt.jpg)'
- en: Introducing `TimeIntervalExtractor` requires a change in `HeatMapBuilder`. Instead
    of retrieving the time from the input tuple, we need to update that bolt’s `execute()`
    method to accept a time interval, as you can see in the next listing.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 引入 `TimeIntervalExtractor` 需要修改 `HeatMapBuilder`。我们不再从输入元组中检索时间，而是需要更新该 bolt
    的 `execute()` 方法以接受一个时间间隔，如下一个列表所示。
- en: Listing 3.12\. Updating `execute()` in `HeatMapBuilder.java` to use the precalculated
    time interval
  id: totrans-279
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.12\. 在 `HeatMapBuilder.java` 中更新 `execute()` 方法以使用预计算的时间间隔
- en: '[PRE18]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The components in our topology now include the following:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拓扑中的组件现在包括以下内容：
- en: '`Checkins` spout, which emits the time and address'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Checkins` spout，它输出时间和地址'
- en: '`GeocodeLookup` bolt, which emits the time and geocoordinate'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GeocodeLookup` bolt，它输出时间和地理坐标'
- en: '`TimeIntervalExtractor` bolt, which emits the time interval and geocoordinate'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TimeIntervalExtractor` bolt，它输出时间间隔和地理坐标'
- en: '`HeatMapBuilder` bolt, which emits the time interval as well as a list of grouped
    geocoordinates'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HeatMapBuilder` bolt，它输出时间间隔以及一组地理坐标'
- en: '`Persistor` bolt, which emits nothing because it’s the last bolt in our topology'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Persistor` bolt，它不输出任何内容，因为它是我们拓扑中的最后一个bolt'
- en: '[Figure 3.14](#ch03fig14) shows an updated topology design that reflects these
    changes.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3.14](#ch03fig14)显示了反映这些变更的更新拓扑设计。'
- en: Figure 3.14\. Updated topology with the `TimeIntervalExtractor` bolt
  id: totrans-288
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.14\. 包含`TimeIntervalExtractor` bolt的更新拓扑
- en: '![](03fig14.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig14.jpg)'
- en: Now when we wire `HeatMapBuilder` to `TimeIntervalExtractor` we don’t need to
    use global grouping.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将`HeatMapBuilder`连接到`TimeIntervalExtractor`时，不需要使用全局分组。
- en: We have the time interval precalculated, so now we need to ensure the same `HeatMapBuilder`
    bolt instance receives all values for the given time interval. It doesn’t matter
    whether different time intervals go to different instances. We can use *fields
    grouping* for this. Fields grouping lets us group values by a specified field
    and send all tuples that arrive with that given value to a specific bolt instance.
    What we’ve done is segment the tuples into time intervals and send each segment
    into different `HeatMapBuilder` instances, thereby allowing us to achieve parallelism
    by running the segments in parallel. [Figure 3.15](#ch03fig15) shows the updated
    stream groupings between our spout and bolts.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经预先计算了时间间隔，现在我们需要确保同一个`HeatMapBuilder` bolt实例接收给定时间间隔内的所有值。不同的时间间隔是否发送到不同的实例无关紧要。我们可以使用*字段分组*来实现这一点。字段分组允许我们根据指定的字段对值进行分组，并将所有带有该给定值的元组发送到特定的bolt实例。我们所做的是将元组分割成时间间隔，并将每个段发送到不同的`HeatMapBuilder`实例，从而通过并行运行段来实现并行化。[图3.15](#ch03fig15)显示了我们的spout和bolt之间的更新流分组。
- en: Figure 3.15\. Updated topology stream groupings
  id: totrans-292
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.15\. 更新拓扑流分组
- en: '![](03fig15_alt.jpg)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig15_alt.jpg)'
- en: Let’s take a look at the code we would need to add to `HeatmapTopologyBuilder`
    in order to incorporate our new `TimeIntervalExtractor` bolt along with changing
    to the appropriate stream groupings, as [listing 3.13](#ch03ex13) shows.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看需要添加到`HeatmapTopologyBuilder`中的代码，以便结合我们的新`TimeIntervalExtractor` bolt，并更改到适当的流分组，如[列表3.13](#ch03ex13)所示。
- en: Listing 3.13\. New bolt added to `HeatmapTopologyBuilder.java`
  id: totrans-295
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表3.13\. 新增到`HeatmapTopologyBuilder.java`的bolt
- en: '![](063fig01_alt.jpg)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![](063fig01_alt.jpg)'
- en: As the listing shows, we’ve completely removed the global grouping and we’re
    now using a series of shuffle groupings with a single fields grouping for the
    time intervals.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 如列表所示，我们已经完全移除了全局分组，现在我们使用一系列洗牌分组，其中包含一个针对时间间隔的单字段分组。
- en: '|  |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Global grouping**'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '**全局分组**'
- en: We scaled this bolt by replacing global grouping with fields grouping after
    some minor design changes. So does global grouping fit well with any real-world
    scenarios where we actually need scale? Don’t discount global grouping; it does
    serve a useful purpose when deployed at the right junction.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将全局分组替换为字段分组来扩展了这个bolt，在经过一些小的设计变更后。那么全局分组是否适合任何需要实际扩展的现实世界场景呢？不要小看全局分组；当它在正确的节点部署时，确实起到了有用的作用。
- en: In this case study, we used global grouping at the point of aggregation (grouping
    coordinates by time interval). When used at the point of aggregation, it doesn’t
    indeed scale because we’re forcing it to crunch a larger data set. But if we were
    to use global grouping postaggregation, it’d be dealing with a smaller stream
    of tuples and we wouldn’t have as great a need for scale as we would preaggregation.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例研究中，我们在聚合点使用了全局分组（按时间间隔分组坐标）。当在聚合点使用时，它确实不会扩展，因为我们迫使它处理更大的数据集。但如果我们使用聚合后的全局分组，它将处理较小的元组流，我们就不需要像聚合前那样大的扩展。
- en: 'If you need to see the entire stream of tuples, global grouping is highly useful.
    What you’d need to do first is aggregate them in some manner (shuffle grouping
    for randomly aggregating sets of tuples or fields grouping for aggregating selected
    sets of tuples) and then use global grouping on the aggregation to get the complete
    picture:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要查看整个元组流，全局分组非常有用。首先你需要以某种方式聚合它们（洗牌分组用于随机聚合元组集或字段分组用于聚合选定的元组集），然后对聚合使用全局分组以获得完整的图景：
- en: '[PRE19]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '`AggregationBolt` in this case can be scaled, and it’ll trim down the stream
    into a smaller set. Then `WorldViewBolt` can look at the complete stream by using
    global grouping on already aggregated tuples coming from `AggregationBolt`. We
    don’t have to scale `WorldViewBolt` because it’s looking at a smaller data set.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`AggregationBolt` 可以进行扩展，并将流裁剪成更小的集合。然后 `WorldViewBolt` 可以通过在来自 `AggregationBolt`
    的已聚合元组上使用全局分组来查看完整的流。我们不需要扩展 `WorldViewBolt`，因为它正在查看一个更小的数据集。
- en: '|  |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Parallelizing `TimeIntervalExtractor` is simple. To start, we can give it the
    same level of parallelism as the `Checkins` spout—there’s no waiting on an external
    service as with the `GeocodeLookup` bolt:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化 `TimeIntervalExtractor` 是简单的。首先，我们可以给它与 `Checkins` spout 相同的并行级别——与 `GeocodeLookup`
    bolt 不同，我们不需要等待外部服务：
- en: '[PRE20]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next up, we can clear our troublesome choke point in the topology:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以清除拓扑中的麻烦瓶颈：
- en: '[PRE21]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Finally we address the `Persistor`. This is similar to `GeocodeLookup` in the
    sense that we expect we’ll need to scale it later on. So we’ll need more tasks
    than executors for the reasons we covered under our `GeocodeLookup` discussion
    earlier:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们解决 `Persistor` 的问题。在某种程度上，这与 `GeocodeLookup` 类似，因为我们预计我们以后需要对其进行扩展。因此，我们需要比执行器更多的任务，原因与我们在之前的
    `GeocodeLookup` 讨论中提到的相同：
- en: '[PRE22]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[Figure 3.16](#ch03fig16) illustrates the parallelism changes that were just
    applied.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 3.16](#ch03fig16) 展示了刚刚应用的并行化变化。'
- en: Figure 3.16\. Parallelizing all the components in our topology
  id: totrans-313
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.16\. 并行化拓扑中的所有组件
- en: '![](03fig16.jpg)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig16.jpg)'
- en: It looks like we’re done with scaling this topology...or are we? We’ve configured
    every component (that is, every spout and bolt) for parallelism within the topology.
    Each bolt or spout may be configured for parallelism, but that doesn’t necessarily
    mean it will run at scale. Let’s see why.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来我们已经完成了这个拓扑的扩展...还是吗？我们已经为拓扑中的每个组件（即每个发射器和bolt）配置了并行性。每个bolt或spout都可以配置为并行，但这并不一定意味着它将以扩展的方式运行。让我们看看原因。
- en: 3.5.3\. Adjusting the topology to address bottlenecks inherent within a data
    stream
  id: totrans-316
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.3\. 调整拓扑结构以解决数据流中固有的瓶颈
- en: We’ve parallelized every component within the topology, and this is in line
    with the technical definition of how every grouping (shuffle grouping, fields
    grouping, and global grouping) we use affects the flow of tuples within our topology.
    Unfortunately, it’s still not effectively parallel.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经并行化了拓扑中的每个组件，这与我们使用的每个分组（洗牌分组、字段分组和全局分组）如何影响我们拓扑中元组的流动的技术定义是一致的。不幸的是，它仍然没有有效地实现并行。
- en: Although we were able to parallelize `HeatMapBuilder` with the changes from
    the previous section, what we forgot to consider is how the nature of our data
    stream affects parallelism. We’re grouping the tuples that flow through the stream
    into segments of 15 seconds, and that’s the source of our problem. For a given
    15-second window, all tuples that fall into that window will go through one instance
    of the `HeatMapBuilder` bolt. It’s true that with the design changes we made `HeatMapBuilder`
    became technically parallelizable, but it’s effectively not parallel yet. The
    shape of the data stream that flows through your topology can hide problems with
    scaling that may be hard to spot. It’s wise to always question the impact of how
    data flows through your topology.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们能够通过上一节中的更改并行化 `HeatMapBuilder`，但我们忘记考虑的是我们数据流的性质如何影响并行化。我们将流经流的元组分组为15秒的段，这是我们问题的根源。对于给定的15秒窗口，所有落入该窗口的元组都将通过
    `HeatMapBuilder` bolt 的一个实例。确实，通过我们做出的设计更改，`HeatMapBuilder` 在技术上可以并行化，但它实际上还没有实现并行。流经你的拓扑的数据流的形状可能会隐藏难以发现的扩展问题。始终质疑数据通过你的拓扑流动的影响是明智的。
- en: How can we parallelize this? We were right to group by time interval because
    that’s the basis for our heat map generation. What we need is an additional level
    of grouping under the time interval; we can refine our higher-level solution so
    that we’re delivering heat maps by time interval by city. When we add an additional
    level of grouping by city, we’ll have multiple data flows for a given time interval
    and they may flow through different instances of the `HeatmapBuilder`. In order
    to add this additional level of grouping, we first need to add city as a field
    in the output tuple of `GeocodeLookup`, as shown in the next listing.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何进行并行化？我们正确地按时间间隔分组，因为这是我们热图生成的依据。我们需要在时间间隔下增加一个额外的分组级别；我们可以细化我们的高级解决方案，以便通过时间间隔和城市来提供热图。当我们按城市增加一个额外的分组级别时，我们将有一个给定时间间隔的多个数据流，它们可能通过
    `HeatmapBuilder` 的不同实例流动。为了添加这个额外的分组级别，我们首先需要在 `GeocodeLookup` 的输出元组中添加城市作为一个字段，如下所示。
- en: Listing 3.14\. Adding city as a field in the output tuple of `GeocodeLookup.java`
  id: totrans-320
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.14\. 在 `GeocodeLookup.java` 的输出元组中添加城市作为一个字段
- en: '![](ch03ex14-0.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![图片](ch03ex14-0.jpg)'
- en: '![](ch03ex14-1.jpg)'
  id: totrans-322
  prefs: []
  type: TYPE_IMG
  zh: '![图片](ch03ex14-1.jpg)'
- en: '`GeocodeLookup` now includes city as a field in its output tuple. We’ll need
    to update `TimeIntervalExtractor` to read and emit this value, as shown in the
    following listing.'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '`GeocodeLookup` 现在将其输出元组中的城市作为一个字段。我们需要更新 `TimeIntervalExtractor` 以读取和发射此值，如下所示。'
- en: Listing 3.15\. Pass city field along in `TimeIntervalExtractor.java`
  id: totrans-324
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.15\. 在 `TimeIntervalExtractor.java` 中传递城市字段
- en: '[PRE23]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Finally, we need to update our `HeatmapTopologyBuilder` so the fields grouping
    between `TimeIntervalExtractor` and `HeatMapBuilder` is based on both the time-interval
    and city fields, as shown in the next listing.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要更新我们的 `HeatmapTopologyBuilder`，以便在 `TimeIntervalExtractor` 和 `HeatMapBuilder`
    之间的字段分组基于时间间隔和城市字段，如下所示。
- en: Listing 3.16\. Added second-level grouping to `HeatmapTopologyBuilder.java`
  id: totrans-327
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 3.16\. 在 `HeatmapTopologyBuilder.java` 中添加了二级分组
- en: '![](067fig01_alt.jpg)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![图片](067fig01_alt.jpg)'
- en: Now we have a topology that isn’t only technically parallelized but is also
    effectively running in parallel fashion. We’ve made a few changes here, so let’s
    take an updated look at our topology and the transformation of the tuples in [figure
    3.17](#ch03fig17).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个拓扑，它不仅在技术上并行化，而且实际上也在并行运行。我们在这里做了一些更改，所以让我们更新一下我们的拓扑和图 3.17 中元组的转换。
- en: Figure 3.17\. Adding city to the tuple being emitted by `GeocodeLookup` and
    having `TimeIntervalExtractor` pass the city along in its emitted tuple
  id: totrans-330
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 3.17\. 将城市添加到 `GeocodeLookup` 发射的元组中，并使 `TimeIntervalExtractor` 在其发射的元组中传递城市
- en: '![](03fig17_alt.jpg)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![图片](03fig17_alt.jpg)'
- en: We’ve covered the basics of parallelizing a Storm topology. The approach we
    followed here is based on making educated guesses driven by our understanding
    of how each topology component works. There’s more work that can be done on parallelizing
    this topology, including additional parallelism primitives and approaches to achieving
    optimal tuning based on observed metrics. We’ll visit them at appropriate points
    throughout the book. In this chapter, we built up the understanding of parallelism
    needed to properly design a Storm topology. The ability to scale a topology depends
    heavily on the makeup of a topology’s underlying component breakdown and design.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涵盖了并行化 Storm 拓扑的基本知识。我们在这里采取的方法是基于我们对每个拓扑组件如何工作的理解而做出的有根据的猜测。在并行化这个拓扑方面还有更多的工作可以做，包括额外的并行化原语和基于观察指标实现最佳调优的方法。我们将在本书的适当位置讨论它们。在本章中，我们构建了正确设计
    Storm 拓扑所需的并行性理解。拓扑的可扩展性在很大程度上取决于拓扑底层组件分解和设计。
- en: 3.6\. Topology design paradigms
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6\. 拓扑设计范式
- en: 'Let’s recap how we designed the heat map topology:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下我们是如何设计热图拓扑的：
- en: We examined our data stream, and determined that our input tuples are based
    on what we start with. Then we determined the resulting tuples we need to end
    up with in order to achieve our goal (the end tuples).
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们检查了我们的数据流，并确定我们的输入元组基于我们开始时的内容。然后我们确定了我们需要达到目标（最终元组）的结果元组。
- en: We created a series of operations (as bolts) that transform the input tuples
    into end tuples.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一系列操作（作为bolt），将输入元组转换为最终元组。
- en: We carefully examined each operation to understand its behavior and scaled it
    by making educated guesses based on our understanding of its behavior (by adjusting
    its executors/tasks).
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们仔细检查了每个操作，以了解其行为，并通过基于我们对行为理解的有根据的猜测进行扩展（调整其执行器/任务）。
- en: At points of contention where we could no longer scale, we rethought our design
    and refactored the topology into scalable components.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们不能再扩展的点，我们重新思考了我们的设计，并将拓扑重构为可扩展的组件。
- en: This is a good approach to topology design. It’s quite common for most people
    to fall into the trap of not having scalability in mind when creating their topologies.
    If we don’t do this early on and leave scalability concerns for later on, the
    amount of work you have to do to refactor or redesign your topology will increase
    by an order of magnitude.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的拓扑设计方法。在创建拓扑时，大多数人没有考虑到可扩展性，陷入了这个陷阱是很常见的。如果我们不早点做，而把可扩展性的问题留到以后，你为了重构或重新设计拓扑所需要做的工作量将增加一个数量级。
- en: Premature optimization is the root of all evil.
  id: totrans-340
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 过早优化是万恶之源。
- en: ''
  id: totrans-341
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Donald Knuth*'
  id: totrans-342
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*唐纳德·克努特*'
- en: 'As engineers we’re fond of using this quote from Donald Knuth whenever we talk
    about performance considerations early on. This is indeed true in most cases,
    but let’s look at the complete quote to give us more context to what Dr. Knuth
    was trying to say (rather than the sound bite we engineers normally use to make
    our point):'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 作为工程师，我们在早期讨论性能考虑因素时喜欢引用唐纳德·克努特的这句话。在大多数情况下，这确实是正确的，但让我们看看完整的引文，以给我们更多的背景，了解克努特博士试图说什么（而不是我们工程师通常用来表达观点的简短引语）：
- en: You should forget about small efficiencies, say about 97% of the time; premature
    optimization is the root of all evil.
  id: totrans-344
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你应该忘记关于小效率的事情，比如说97%的时间；过早优化是万恶之源。
- en: You’re not trying to achieve small efficiencies—you’re working with big data.
    Every efficiency enhancement you make counts. One minor performance block can
    be the difference in not achieving the performance SLA you need when working with
    large data sets. If you’re building a racecar, you need to keep performance in
    mind starting on day one. You can’t refactor your engine to improve it later if
    it wasn’t built for performance from the ground up. So steps 3 and 4 are critical
    pieces in designing a topology.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 你不是在尝试实现小效率——你是在处理大数据。你做的每一个效率提升都很重要。一个小的性能瓶颈可能会在大数据集上工作时，导致无法达到所需的性能服务等级协议。如果你在建造赛车，你需要从第一天开始就考虑性能。如果你没有从一开始就为性能而建造，你不能在以后重构引擎来提高它。所以步骤3和步骤4是设计拓扑的关键部分。
- en: The only caveat here is a lack of knowledge about the problem domain. If your
    knowledge about the problem domain is limited, that might work against you if
    you try to scale it too early. When we say *knowledge about the problem domain*,
    what we’re referring to is both the nature of the data that’s flowing through
    your system as well as the inherent choke points within your operations. It’s
    always okay to defer scaling concerns until you have a good understanding of it.
    Similar to building an expert system, when you have a true understanding of the
    problem domain, you might have to scrap your initial solution and start over.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 这里唯一的缺点是对问题域的了解不足。如果你的问题域知识有限，那么如果你试图过早地扩展它，可能会对你不利。当我们说“对问题域的了解”时，我们指的是系统中流动的数据的性质以及你操作中的固有瓶颈。在你对它有很好的理解之前，推迟可扩展性的问题总是可以的。类似于构建专家系统，当你真正理解了问题域时，你可能不得不放弃你的初始解决方案并重新开始。
- en: 3.6.1\. Design by breakdown into functional components
  id: totrans-347
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.6.1\. 通过分解为功能组件进行设计
- en: Let’s observe how we broke down the series of operations within our topology
    ([figure 3.18](#ch03fig18)).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们观察我们是如何分解拓扑中一系列操作的（[图3.18](#ch03fig18)）。
- en: Figure 3.18\. The heat map topology design as a series of functional components
  id: totrans-349
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.18\. 热图拓扑设计作为一系列功能组件
- en: '![](03fig18_alt.jpg)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig18_alt.jpg)'
- en: We decomposed the topology makeup into separate bolts by giving each bolt a
    specific responsibility. This is in line with the *principle of single responsibility*.
    We encapsulated a specific responsibility within each bolt and everything within
    each bolt is narrowly aligned with its responsibility and nothing else. In other
    words, each bolt represents a functional whole.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过给每个螺栓分配一个特定的责任，将拓扑结构分解成单独的螺栓。这与*单一责任原则*相一致。我们在每个螺栓中封装了特定的责任，每个螺栓中的所有内容都与它的责任紧密相关，与其他内容无关。换句话说，每个螺栓代表一个功能整体。
- en: There’s a lot of value in this approach to design. Giving each bolt a single
    responsibility makes it easy to work with a given bolt in isolation. It also makes
    it easy to scale a single bolt without interference from the rest of the topology
    because parallelism is tuned at the bolt level. Whether it’s scaling or troubleshooting
    a problem, when you can zoom in and focus your attention on a single component,
    the productivity gains to be had from that will allow you to reap the benefits
    of the effort spent on designing your components in this manner.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这种设计方法有很多价值。给每个bolt分配单一职责使其易于独立处理。它还使得在不干扰拓扑其余部分的情况下轻松扩展单个bolt，因为并行性是在bolt级别调整的。无论是扩展还是解决问题，当你能够聚焦于单个组件时，从这种专注中获得的效率提升将使你能够从以这种方式设计组件的努力中获得收益。
- en: 3.6.2\. Design by breakdown into components at points of repartition
  id: totrans-353
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.6.2\. 在重分区点按组件分解设计
- en: There’s a slightly different approach to breaking down a problem into its constituent
    parts. It provides a marked improvement in terms of performance over the approach
    of breaking down into functional components discussed earlier. With this pattern,
    instead of decomposing the problem into its simplest possible functional components,
    we think in terms of separation points (or join points) between the different
    components. In other words, we think of the points of connection between the different
    bolts. In Storm, the different stream groupings are markers between different
    bolts (as the groupings define how the outgoing tuples from one bolt are distributed
    to the next).
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 将问题分解为其组成部分的方法略有不同。与之前讨论的将问题分解为功能组件的方法相比，这种方法在性能方面提供了显著的改进。使用这种模式，我们不是将问题分解为其最简单的可能功能组件，而是从不同组件之间的分离点（或连接点）的角度思考。换句话说，我们考虑不同bolt之间的连接点。在Storm中，不同的流分组是不同bolt之间的标记（因为分组定义了来自一个bolt的输出元组如何分配到下一个bolt）。
- en: At these points, the stream of tuples flowing through the topology gets repartitioned.
    During a stream repartition, the way tuples are distributed changes. That is in
    fact the functionality of a stream grouping. [Figure 3.19](#ch03fig19) illustrates
    our design by points of repartition.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些点上，拓扑中流动的元组流会被重分区。在流重分区期间，元组的分配方式会改变。这实际上是流分组的函数。图3.19([Figure 3.19](#ch03fig19))通过重分区的点说明了我们的设计。
- en: Figure 3.19\. The HeatMap topology design as points of repartition
  id: totrans-356
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图3.19\. 以重分区点为依据的HeatMap拓扑设计
- en: '![](03fig19_alt.jpg)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![](03fig19_alt.jpg)'
- en: 'With this pattern of topology design, we strive to minimize the number of repartitions
    within a topology. Every time there’s a repartitioning, tuples will be sent from
    one bolt to another across the network. This is an expensive operation due to
    a number of reasons:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种拓扑设计模式，我们努力将拓扑内部的重分区数量最小化。每次进行重分区时，元组将从网络中的一个bolt发送到另一个bolt。由于多种原因，这是一个昂贵的操作：
- en: The topology operates within a distributed cluster. When tuples are emitted,
    they may travel across the cluster and this may incur network overhead.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拓扑在分布式集群中运行。当元组被发出时，它们可能穿越集群，这可能会产生网络开销。
- en: With every emit, a tuple will need to be serialized and deserialized at the
    receiving point.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次发出元组时，都需要在接收点进行序列化和反序列化。
- en: The higher the number of partitions, the higher the number of resources needed.
    Each bolt will require a number of executors and tasks and a queue in front for
    all the incoming tuples.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分区数量越多，所需的资源就越多。每个bolt都需要一定数量的executors和tasks，以及一个用于所有传入元组的队列。
- en: '|  |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-363
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: We’ll discuss the makeup of a Storm cluster and the internals that support a
    bolt in later chapters.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后面的章节中讨论Storm集群的组成以及支持bolt的内部机制。
- en: '|  |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'For our topology, what can we do to minimize the number of partitions? We’ll
    have to collapse a few bolts together. To do so, we must figure out what’s different
    about each functional component that makes it need its own bolt (and the resources
    that come with a bolt):'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的拓扑，我们如何最小化分区数量？我们将不得不合并几个bolt。要做到这一点，我们必须弄清楚每个功能组件有什么不同之处，使其需要自己的bolt（以及bolt带来的资源）：
- en: '`Checkins` (spout)—4 executors (reads a file)'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Checkins` (spout)—4 executors (读取文件)'
- en: '`GeocodeLookup`—8 executors, 64 tasks (hits an external service)'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GeocodeLookup`—8 executors, 64 tasks (调用外部服务)'
- en: '`TimeIntervalExtractor`—4 executors (internal computation; transforms data)'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TimeIntervalExtractor`—4 executors (内部计算；转换数据)'
- en: '`HeatMapBuilder`—4 executors (internal computation; aggregates tuples)'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HeatMapBuilder`—4个执行器（内部计算；聚合元组）'
- en: '`Persistor`—1 executor, 4 tasks (writes to a data store)'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Persistor`—1个执行器，4个任务（写入数据存储）'
- en: 'And now for the analysis:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进行分析：
- en: '`GeocodeLookup` and `Persistor` interact with an external entity and the time
    spent waiting on interactions with that external entity will dictate the way executors
    and tasks are allocated to these two bolts. It’s unlikely that we’ll be able to
    coerce the behavior of these bolts to fit within another. Maybe something else
    might be able to fit within the resources necessary for one of these two.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GeocodeLookup`和`Persistor`与外部实体交互，与该外部实体交互所花费的时间将决定执行器和任务如何分配给这两个bolt。我们不太可能能够迫使这些bolt的行为适应另一个。也许其他某些东西可能能够适应其中一个所需的资源。'
- en: '`HeatMapBuilder` does the aggregation of geocoordinates by time interval and
    city. It’s somewhat unique compared to others because it buffers data in memory
    and you can’t proceed to the next step until the time interval has elapsed. It’s
    peculiar enough that collapsing it with another will require careful consideration.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`HeatMapBuilder`按时间区间和城市对地理坐标进行聚合。与其他相比，它有些独特，因为它在内存中缓冲数据，并且只有在时间区间过去之后才能进行下一步。它足够奇特，以至于将其与其他合并需要仔细考虑。'
- en: '`Checkins` is a spout and normally you wouldn’t modify a spout to contain operations
    that involve computation. Also, because the spout is responsible for keeping track
    of the data that has been emitted, rarely would we perform any computation within
    one. But certain things related to adapting the initial tuples (such as parsing,
    extracting, and converting) do fit within the responsibilities of a spout.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Checkins`是一个spout，通常你不会修改一个spout以包含涉及计算的运算。此外，由于spout负责跟踪已发射的数据，我们很少在其中执行任何计算。但是，与适应初始元组相关的一些事情（如解析、提取和转换）确实适合spout的职责。'
- en: 'That leaves `TimeIntervalExtractor`. This is simple—all it does is transform
    a “time” entry into a “time interval.” We extracted it out of `HeatMapBuilder`
    because we needed to know the time interval prior to `HeatMapBuilder` so that
    we could group by the time interval. This allowed us to scale the `HeatMapBuilder`
    bolt. Work done by `TimeIntervalExtractor` can technically happen at any point
    before the `HeatMapBuilder`:'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这就留下了`TimeIntervalExtractor`。这很简单——它所做的只是将一个“时间”条目转换成一个“时间区间”。我们将其从`HeatMapBuilder`中提取出来，因为我们需要在`HeatMapBuilder`之前知道时间区间，以便我们可以按时间区间进行分组。这使我们能够扩展`HeatMapBuilder`bolt。`TimeIntervalExtractor`完成的工作在技术上可以在`HeatMapBuilder`之前的任何时刻发生：
- en: If we merge `TimeIntervalExtractor` with `GeocodeLookup`, it’ll need to fit
    within resources allocated to `GeocodeLookup`. Although they have different resource
    configurations, the simplicity of `TimeIntervalExtractor` will allow it to fit
    within resources allocated to `GeocodeLookup`. On a purely idealistic sense, they
    also fit—both operations are data transformations (going from time to time interval
    and address to geocoordinate). One of them is incredibly simple and the other
    requires the network overhead of using an external service.
  id: totrans-377
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们将`TimeIntervalExtractor`与`GeocodeLookup`合并，它需要适应分配给`GeocodeLookup`的资源。尽管它们有不同的资源配置，但`TimeIntervalExtractor`的简单性将允许它适应分配给`GeocodeLookup`的资源。从纯粹理想主义的角度来看，它们也适合——这两个操作都是数据转换（从时间到时间区间，从地址到地理坐标）。其中一个是极其简单的，而另一个则需要使用外部服务的网络开销。
- en: Can we merge `TimeIntervalExtractor` with the `Checkins` spout? They have the
    exact same resource configurations. Also, transforming a “time” to a “time interval”
    is one of the few types of operations from a bolt that can make sense within a
    spout. The answer is a resounding yes. This begs the question of whether `GeocodeLookup`
    can also be merged with the `Checkins` spout. Although `GeocodeLookup` is also
    a data transformer, it’s a much more heavyweight computation because it depends
    on an external service, meaning it doesn’t fit within the type of actions that
    should happen in a spout.
  id: totrans-378
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否将`TimeIntervalExtractor`与`Checkins` spout合并？它们具有完全相同的资源配置。此外，将“时间”转换为“时间区间”是bolt中可以合理地在spout中执行的操作类型之一。答案是响亮的肯定。这引出了一个问题，即`GeocodeLookup`是否也可以与`Checkins`
    spout合并。尽管`GeocodeLookup`也是一个数据转换器，但由于它依赖于外部服务，这是一个更重量级的计算，这意味着它不适合在spout中发生的动作。
- en: Should we merge `TimeIntervalExtractor` with `GeocodeLookup` or the `Checkins`
    spout? From an efficiency perspective, either will do, and that’s the right answer.
    We would merge it with the spout because we have a preference for keeping external
    service interactions untangled with much simpler tasks like `TimeIntervalExtractor`.
    We’ll let you make the needed changes in your topology to make this happen.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否应该将`TimeIntervalExtractor`与`GeocodeLookup`或`Checkins`源合并？从效率的角度来看，两者都可以，这是正确的答案。我们会将其与源合并，因为我们更喜欢将外部服务交互与像`TimeIntervalExtractor`这样的简单任务保持清晰。我们将让你在你的拓扑中进行必要的更改来实现这一点。
- en: You might wonder why in this example we chose not to merge `HeatMapBuilder`
    with `Persistor`. `HeatMapBuilder` emits the aggregated geocoordinates periodically
    (whenever it receives a tick tuple) and at the point of emitting, it can be modified
    to write the value to the data store instead (the responsibility of `Persistor`).
    Although this makes sense conceptually, it changes the observable behavior of
    the combined bolt. The combined `HeatMapBuilder`/`Persistor` behaves very differently
    on the two types of tuples it receives. The regular tuple from the stream will
    perform with low latency whereas the tick tuple for writing to the data store
    will have comparably higher latency. If we were to monitor and gather data about
    the performance of this combined bolt, it’d be difficult to isolate the observed
    metrics and make intelligent decisions on how to tune it further. This unbalanced
    nature of latency makes it very inelegant.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么在这个例子中我们选择不将`HeatMapBuilder`与`Persistor`合并。`HeatMapBuilder`定期（每当它收到一个tick元组时）发出聚合的地理坐标，在发出时，它可以修改为将值写入数据存储（`Persistor`的责任）。虽然从概念上讲这是合理的，但它改变了组合螺栓的可观察行为。组合的`HeatMapBuilder`/`Persistor`在接收到的两种类型的元组上表现非常不同。来自流的常规元组将以低延迟执行，而写入数据存储的tick元组将具有相对较高的延迟。如果我们要监控和收集关于这个组合螺栓性能的数据，将很难隔离观察到的指标并就如何进一步调整做出明智的决定。这种延迟不平衡的性质使得它非常不优雅。
- en: Designing a topology by considering the points of repartitioning of the stream
    and trying to minimize them will give you the most efficient use of resources
    with a topology makeup that has a higher likelihood of performing with low latency.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 通过考虑流的重分区点来设计拓扑，并尝试最小化它们，这将使你在具有较高性能可能性的拓扑结构中，以最低的延迟使用资源。
- en: 3.6.3\. Simplest functional components vs. lowest number of repartitions
  id: totrans-382
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.6.3\. 最简单的功能组件与最少数量的分区
- en: We’ve discussed two approaches to topology design. Which one is better? Having
    the lowest number of repartitions will provide the best performance as long as
    careful consideration is given to what kind of operations can be grouped into
    one bolt.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了两种拓扑设计的方法。哪一个更好？只要仔细考虑哪些操作可以组合成一个螺栓，拥有最少数量的分区将提供最佳性能。
- en: Usually it isn’t one or the other. As a Storm beginner, you should always start
    by designing the simplest functional components; doing so allows you to reason
    about different operations easily. Also, if you start with more complex components
    tasked with multiple responsibilities, it’s much harder to break down into simpler
    components if your design is wrong.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 通常不是非此即彼。作为一个Storm初学者，你应该始终从设计最简单的功能组件开始；这样做可以让你轻松地推理不同的操作。此外，如果你从具有多个职责的更复杂组件开始，如果设计错误，将很难将其分解成更简单的组件。
- en: You can always start with the simplest functional components and then advance
    toward combining different operations together to reduce the number of partitions.
    It’s much harder to go the other way around. As you gain more experience with
    working with Storm and develop intuition for topology design, you’ll be able start
    with the lowest number of repartitions from the beginning.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 你始终可以从最简单的功能组件开始，然后逐步将不同的操作组合在一起以减少分区数量。反过来操作要困难得多。随着你在与Storm合作方面获得更多经验并发展对拓扑设计的直觉，你将能够从最少数量的分区开始。
- en: 3.7\. Summary
  id: totrans-386
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.7\. 摘要
- en: In this chapter, you learned
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了
- en: How to take a problem and break it down into constructs that fit within a Storm
    topology
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将问题分解为适合Storm拓扑的构造
- en: How to take a topology that runs in a serial fashion and introduce parallelism
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将串行运行的拓扑转换为并行
- en: How to spot problems in your design and refine and refactor
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在设计中发现问题并进行精炼和重构
- en: The importance of paying attention to the effects of the data stream on the
    limitations it imposes on the topology
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关注数据流对拓扑结构限制的影响的重要性
- en: Two different approaches to topology design and the delicate balance between
    the two
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两种不同的拓扑设计方法以及两者之间的微妙平衡
- en: These design guidelines serve as best practices for building Storm topologies.
    Later on in the book, you’ll see why these design decisions aid greatly in tuning
    Storm for optimal performance.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设计指南是构建 Storm 顶点的最佳实践。在本书的后续部分，您将了解到为什么这些设计决策极大地有助于对 Storm 进行调优以实现最佳性能。
