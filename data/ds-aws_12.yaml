- en: Chapter 12\. Secure Data Science on AWS
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章 安全的AWS数据科学
- en: It is important to maintain least-privilege security at all layers, from network
    to application, and throughout the entire data science workflow, from data ingestion
    to model deployment. In this chapter, we reinforce that security is the top priority
    at AWS and often called “job zero” or “priority zero.” We discuss common security
    considerations and present best practices to build secure data science and machine
    learning projects on AWS. We will describe preventive controls that aim to stop
    events from occurring as well as detective controls to quickly detect potential
    events. We also identify responsive and corrective controls that help to remediate
    security violations.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有层面，从网络到应用程序，以及从数据摄入到模型部署的整个数据科学工作流程中，保持最小特权安全至关重要。在本章中，我们强调安全是AWS的首要任务，通常被称为“零工作”或“零优先级”。我们讨论常见的安全考虑，并提出在AWS上构建安全数据科学和机器学习项目的最佳实践。我们将描述旨在阻止事件发生的预防控制，以及快速检测潜在事件的检测控制。我们还确定响应和纠正控制，以帮助纠正安全违规行为。
- en: The most common security considerations for building secure data science projects
    in the cloud touch the areas of access management, compute and network isolation,
    and encryption. Let’s first discuss these more general security best practices
    and security-first principles. Then we will apply these practices and principles
    to secure our data science environment from notebooks to S3 buckets using both
    network-level security and application security. We also discuss governance and
    audibility best practices for compliance and regulatory purposes.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在云中构建安全数据科学项目的最常见安全考虑涉及访问管理、计算和网络隔离以及加密领域。让我们首先讨论这些更一般的安全最佳实践和安全优先原则。然后，我们将应用这些实践和原则，通过网络级安全和应用程序安全来保护从笔记本到S3存储桶的数据科学环境。我们还讨论了合规性和监管的治理和审计最佳实践。
- en: Shared Responsibility Model Between AWS and Customers
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS和客户之间的共享责任模型
- en: AWS implements the shared responsibility model, through which they provide a
    global secure infrastructure and foundational compute, storage, networking and
    database services, as well as a range of security services that we can use to
    secure anything we build and run on top of these services.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: AWS通过实施共享责任模型，提供全球安全基础设施和基础计算、存储、网络和数据库服务，以及一系列安全服务，我们可以利用这些服务来保护我们在其上构建和运行的任何内容。
- en: Security and compliance is a shared responsibility between AWS and the customer.
    AWS ensures the security “of” the cloud, while the customer is responsible for
    security “in” the cloud, as shown in [Figure 12-1](#security_is_a_shared_responsibility_bet).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 安全和合规性是AWS和客户之间的共同责任。AWS确保云的安全，“而”客户负责云中的安全，如[图 12-1](#security_is_a_shared_responsibility_bet)所示。
- en: '![](assets/dsaw_1201.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1201.png)'
- en: 'Figure 12-1\. Security is a shared responsibility between AWS and the customer.
    Source: [Amazon](https://oreil.ly/DgY3n).'
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-1\. 安全是AWS和客户之间的共同责任。来源：[Amazon](https://oreil.ly/DgY3n)。
- en: AWS protects the AWS cloud infrastructure that runs the AWS services. This includes
    all the components, from the host operating systems and virtualization layers
    down to the physical security of the facilities in which the AWS services run.
    The effectiveness of AWS security is regularly tested and verified by third-party
    auditors. We can access on-demand security and compliance reports and select online
    agreements via [AWS Artifact](https://oreil.ly/XFfgU).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: AWS保护运行AWS服务的AWS云基础设施。这包括从主机操作系统和虚拟化层到物理设施的物理安全的所有组件。AWS安全的有效性定期由第三方审计师测试和验证。我们可以通过[AWS
    Artifact](https://oreil.ly/XFfgU)访问按需的安全和合规性报告以及选择在线协议。
- en: In return, AWS customers are responsible to ensure the security in the cloud.
    The scope of the customer responsibilities is determined by the specific AWS service.
    In addition, customers can choose from a variety of security services and features
    to build secure and compliant applications in the AWS cloud.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 反过来，AWS的客户负责确保云中的安全。客户责任的范围由具体的AWS服务确定。此外，客户可以从各种安全服务和功能中选择，在AWS云中构建安全和合规的应用程序。
- en: Applying AWS Identity and Access Management
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用AWS身份和访问管理
- en: IAM is a service that helps us to manage access to AWS resources. IAM controls
    who has access (authentication) to the environment and what permissions authenticated
    users have (authorization). We can use IAM to define users, groups of users, and
    roles. IAM implements the concept of principals, actions, resources, and conditions.
    This defines which principals can perform which actions on which resources and
    under which conditions.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: IAM是一个帮助我们管理访问AWS资源的服务。IAM控制谁可以访问（认证）环境以及经认证用户具有什么权限（授权）。我们可以使用IAM定义用户、用户组和角色。IAM实施了主体、操作、资源和条件的概念。这定义了哪些主体可以在哪些资源上以及在哪些条件下执行哪些操作。
- en: We control access to specific resources by creating IAM policies and attaching
    them to IAM identities or AWS resources. Depending on different job roles or functions,
    we may want to grant different permissions to users. For example, some developers
    might just need to launch notebooks for ad hoc data exploration. Data scientists
    most likely require permissions to data stores, training jobs, and experiments.
    Data engineers and machine-learning engineers might need permissions to build
    repeatable data and model pipelines. DevOps teams require access to model deployments
    and performance monitors.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过创建IAM策略并将其附加到IAM身份或AWS资源，我们控制对特定资源的访问。根据不同的工作角色或功能，我们可能希望向用户授予不同的权限。例如，一些开发人员可能只需启动笔记本进行临时数据探索。数据科学家很可能需要对数据存储、训练作业和实验拥有权限。数据工程师和机器学习工程师可能需要权限来构建可重复使用的数据和模型流水线。DevOps团队需要访问模型部署和性能监视器。
- en: Amazon SageMaker leverages IAM for role-based access controls. We can also map
    any existing users/groups/roles from the AWS Directory Service, our enterprise
    user directory, or a web identity provider (called *federated users*).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker利用IAM进行基于角色的访问控制。我们还可以映射来自AWS目录服务、企业用户目录或Web身份提供者（称为*federated
    users*）的任何现有用户/组/角色。
- en: IAM Users
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IAM用户
- en: We can create individual IAM users for people accessing our AWS account. Each
    user will have unique security credentials. We can also assign IAM users to IAM
    groups with defined access permissions (i.e., for specific job functions), and
    the IAM users inherit those permissions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以为访问我们的AWS账户的个人创建单独的IAM用户。每个用户都将拥有唯一的安全凭证。我们还可以将IAM用户分配给具有定义访问权限的IAM组（即针对特定工作职能），并且IAM用户继承这些权限。
- en: IAM Policies
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IAM策略
- en: Access permissions are defined using IAM policies. It’s a standard security
    best practice to only grant least privilege by only granting the specific permissions
    required to perform a given task.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 访问权限通过IAM策略定义。仅授予执行给定任务所需的特定权限是一种标准的安全最佳实践。
- en: IAM User Roles
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IAM用户角色
- en: A more preferred way to delegate access permissions is via IAM roles. In contrast
    to an IAM user, which is uniquely associated with one person, a role can be assumed
    by anyone who needs it and provides us with only temporary security credentials
    for the duration of the role session. IAM service roles control which actions
    a service can perform on our behalf. IAM user roles are assumed by individual
    users.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 委托访问权限的更优方法是通过IAM角色。与仅与一个人相关联的IAM用户不同，角色可以由需要它的任何人扮演，并为角色会话的持续时间提供临时安全凭证。IAM服务角色控制服务代表我们执行哪些操作。IAM用户角色由个人用户扮演。
- en: The best practice is to create separate IAM user roles for individual job roles,
    such as the `DataScientistRole`, `MLEngineerRole`, `DataEngineeringRole`, `MLOpsEngineeringRole`,
    etc. This allows for fine-grained and distinct policies for the different roles
    in the model-development life cycle.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践是为不同的工作角色创建单独的IAM用户角色，例如`DataScientistRole`、`MLEngineerRole`、`DataEngineeringRole`、`MLOpsEngineeringRole`等。这样可以为模型开发生命周期中的不同角色提供精细化和明确的策略。
- en: IAM Service Roles
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IAM服务角色
- en: 'IAM service roles are assumed by AWS services. The best practice is to create
    separate service roles for distinct services and separate roles for distinct tasks
    per service. For Amazon SageMaker, we could separate service roles as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: IAM服务角色由AWS服务扮演。最佳做法是为不同的服务创建单独的服务角色，并为每个服务的不同任务创建单独的角色。对于Amazon SageMaker，我们可以按以下方式分离服务角色：
- en: '`SageMakerNotebookExecutionRole`'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`SageMakerNotebookExecutionRole`'
- en: The role assumed by a SageMaker notebook instance or SageMaker Studio Application,
    defining access permissions to SageMaker training or model hosting services
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker笔记本实例或SageMaker Studio应用程序所扮演的角色，定义了对SageMaker训练或模型托管服务的访问权限。
- en: '`SageMakerProcessingRole`'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`SageMakerProcessingRole`'
- en: The role assumed by SageMaker Processing Jobs, defining access to S3 buckets
    for data input/output
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker处理作业所假定的角色，定义了对数据输入/输出的S3存储桶的访问权限。
- en: '`SageMakerTrainingRole`'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`SageMakerTrainingRole`'
- en: The role assumed by SageMaker Training or Tuning Jobs, defining permissions
    during model training/tuning
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker训练或调整作业所假定的角色，在模型训练/调整期间定义权限。
- en: '`SageMakerModelRole`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`SageMakerModelRole`'
- en: The role assumed by the model hosting inference container on a SageMaker Endpoint,
    defining permissions during model inference
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker终端节点上模型托管推理容器所假定的角色，在模型推理期间定义权限。
- en: '[Figure 12-2](#sample_iam_user_and_service_roles_for_a) shows the data scientist
    IAM user role and the various SageMaker IAM service roles discussed.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-2](#sample_iam_user_and_service_roles_for_a)展示了数据科学家IAM用户角色和讨论的各种SageMaker
    IAM服务角色。'
- en: '![Sample IAM user and service roles for Amazon SageMaker.](assets/dsaw_1202.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![Amazon SageMaker的示例IAM用户和服务角色。](assets/dsaw_1202.png)'
- en: Figure 12-2\. Sample IAM user and service roles for Amazon SageMaker.
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图12-2\. Amazon SageMaker的示例IAM用户和服务角色。
- en: When defining user and service permissions via IAM policies, we should always
    assign the least privilege needed to perform the task at hand.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过IAM策略定义用户和服务权限时，我们应始终分配执行所需任务的最低权限。
- en: Specifying Condition Keys for IAM Roles
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为IAM角色指定条件键。
- en: 'We can use IAM condition keys to specify guardrails within our policies. When
    a principal calls a service API to create a resource, for example, the request
    information is compared to the conditions defined in the principal’s IAM policy.
    If the condition statement passes, the API call succeeds; if the condition statement
    fails, the request will be denied. Condition statements generally look like this:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用IAM条件键在策略中指定防护栏。例如，当主体调用服务API以创建资源时，请求信息将与主体IAM策略中定义的条件进行比较。如果条件语句通过，则API调用成功；如果条件语句失败，则请求将被拒绝。条件语句通常如下所示：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And here is a sample condition policy statement that denies uploads of any
    unencrypted objects to S3:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个示例条件策略语句，拒绝上传未加密对象到S3：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'SageMaker supports global condition keys and also adds a few service-specific
    condition keys. The global condition context keys start with an `aws:` prefix.
    SageMaker supports the following global condition keys:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker支持全局条件键，并添加了一些特定于服务的条件键。全局条件上下文键以`aws:`前缀开头。SageMaker支持以下全局条件键：
- en: '`aws:RequestTag/${TagKey}`'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`aws:RequestTag/${TagKey}`'
- en: Compares the tag key-value pair that was passed in the request with the tag
    pair specified in the policy
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 比较请求中传递的标签键值对与策略中指定的标签对。
- en: '`aws:ResourceTag/${TagKey}`'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`aws:ResourceTag/${TagKey}`'
- en: Compares the tag key-value pair that is specified in the policy with the key-value
    pair attached to the resource
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 比较策略中指定的标签键值对与资源附加的键值对。
- en: '`aws:SourceIp`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`aws:SourceIp`'
- en: Compares the requester’s IP address with the IP address specified in the policy
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 比较请求者的IP地址与策略中指定的IP地址。
- en: '`aws:SourceVpc`'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`aws:SourceVpc`'
- en: Checks whether the request comes from the Amazon Virtual Private Cloud (Amazon
    VPC) specified in the policy
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 检查请求是否来自策略中指定的Amazon Virtual Private Cloud（Amazon VPC）。
- en: '`aws:SourceVpce`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`aws:SourceVpce`'
- en: Compares the Amazon VPC endpoint identifier of the request with the endpoint
    ID specified in the policy
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 比较请求的Amazon VPC终端节点标识符与策略中指定的终端节点ID。
- en: '`aws:TagKeys`'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`aws:TagKeys`'
- en: Compares the tag keys in the request with the keys specified in the policy
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 比较请求中的标签键与策略中指定的键。
- en: 'SageMaker adds service-specific condition keys that start with a `sagemaker:`
    prefix as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker添加以`sagemaker:`前缀开头的特定于服务的条件键，如下所示：
- en: '`sagemaker:AcceleratorTypes`'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:AcceleratorTypes`'
- en: Uses a specific Amazon Elastic Inference accelerator when creating or updating
    notebook instances and when creating endpoint configurations
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建或更新笔记本实例以及创建端点配置时，使用特定的Amazon Elastic Inference加速器。
- en: '`sagemaker:DirectInternetAccess`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:DirectInternetAccess`'
- en: Controls direct internet access from notebook instances
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 控制笔记本实例的直接互联网访问。
- en: '`sagemaker:FileSystemAccessMode`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:FileSystemAccessMode`'
- en: Specifies the access mode of the directory associated with the input data channel
    (Amazon EFS or FSx)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 指定与输入数据通道（Amazon EFS或FSx）关联的目录的访问模式。
- en: '`sagemaker:FileSystemDirectoryPath`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:FileSystemDirectoryPath`'
- en: Specifies the filesystem directory path associated with the resource in the
    training and hyper-parameter tuning (HPT) request
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 指定与训练和超参数调整（HPT）请求中资源关联的文件系统目录路径。
- en: '`sagemaker:FileSystemId`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:FileSystemId`'
- en: Specifies the filesystem ID associated with the resource in the training and
    HPT request
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 指定与训练和 HPT 请求中资源关联的文件系统 ID。
- en: '`sagemaker:FileSystemType`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:FileSystemType`'
- en: Specifies the filesystem type associated with the resource in the training and
    HPT request
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 指定与训练和 HPT 请求中资源关联的文件系统类型。
- en: '`sagemaker:InstanceTypes`'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:InstanceTypes`'
- en: Specifies the list of all instance types for notebook instances, training jobs,
    HPT jobs, batch transform jobs, and endpoint configurations for hosting real-time
    inferencing
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 指定笔记本实例、训练作业、HPT 作业、批转换作业和端点配置的所有实例类型列表，用于托管实时推理。
- en: '`sagemaker:InterContainerTrafficEncryption`'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:InterContainerTrafficEncryption`'
- en: Controls inter-container traffic encryption for distributed training and HPT
    jobs
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式训练和 HPT 作业中控制容器间流量加密。
- en: '`sagemaker:MaxRuntimeInSeconds`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:MaxRuntimeInSeconds`'
- en: Controls costs by specifying the maximum length of time, in seconds, that the
    training, HPT, or compilation job can run
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通过指定训练、HPT 或编译作业可运行的最大时间长度（以秒为单位）来控制成本。
- en: '`sagemaker:ModelArn`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:ModelArn`'
- en: Specifies the Amazon Resource Name (ARN) of the model associated for batch transform
    jobs and endpoint configurations for hosting real-time inferencing
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 指定用于批转换作业和端点配置托管实时推理的模型关联的亚马逊资源名称（ARN）。
- en: '`Sagemaker:NetworkIsolation`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`Sagemaker:NetworkIsolation`'
- en: Enables network isolation when creating training, HPT, and inference jobs
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建训练、HPT 和推理作业时启用网络隔离。
- en: '`sagemaker:OutputKmsKey`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:OutputKmsKey`'
- en: Specifies the AWS KMS key to encrypt output data stored in Amazon S3
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 指定用于加密存储在亚马逊 S3 中的输出数据的 AWS KMS 密钥。
- en: '`sagemaker:RequestTag/${TagKey}`'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:RequestTag/${TagKey}`'
- en: Compares the tag key-value pair that was passed in the request with the tag
    pair that is specified in the policy
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 比较请求中传递的标签键值对与策略中指定的标签对。
- en: '`sagemaker:ResourceTag/${TagKey}`'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:ResourceTag/${TagKey}`'
- en: Compares the tag key-value pair that is specified in the policy with the key-value
    pair that is attached to the resource
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 比较策略中指定的标签键值对与附加到资源的键值对。
- en: '`sagemaker:RootAccess`'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:RootAccess`'
- en: Controls root access on the notebook instances
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本实例上控制根访问。
- en: '`sagemaker:VolumeKmsKey`'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:VolumeKmsKey`'
- en: Specifies an AWS KMS key to encrypt storage volumes when creating notebook instances,
    training jobs, HPT jobs, batch transform jobs, and endpoint configurations for
    hosting real-time inferencing
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建笔记本实例、训练作业、HPT 作业、批转换作业和端点配置托管实时推理时，指定用于加密存储卷的 AWS KMS 密钥。
- en: '`sagemaker:VPCSecurityGroupIds`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:VPCSecurityGroupIds`'
- en: '`L`ists all Amazon VPC security group IDs associated with the elastic network
    interface (ENI) that Amazon SageMaker creates in the Amazon VPC subnet'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 列出与亚马逊 SageMaker 在亚马逊 VPC 子网中创建的弹性网络接口（ENI）关联的所有亚马逊 VPC 安全组 ID。
- en: '`sagemaker:VPCSubnets`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`sagemaker:VPCSubnets`'
- en: Lists all Amazon VPC subnets where Amazon SageMaker creates ENIs to communicate
    with other resources like Amazon S3
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 列出亚马逊 SageMaker 创建 ENI 以与其他资源（如亚马逊 S3）通信的所有亚马逊 VPC 子网。
- en: Enable Multifactor Authentication
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用多因素认证
- en: SageMaker also supports multifactor authentication MFA. MFA adds extra security
    as it requires users to provide a second, unique authentication from an AWS-supported
    MFA mechanism. Supported MFA mechanisms include virtual MFA devices, U2F security
    keys, hardware MFA devices, or SMS text message–based MFAs.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 还支持多因素认证 MFA。MFA 提供额外的安全性，因为它要求用户从 AWS 支持的 MFA 机制中提供第二个唯一的认证。支持的 MFA
    机制包括虚拟 MFA 设备、U2F 安全密钥、硬件 MFA 设备或基于短信文本的 MFA。
- en: As a best practice, we should enable MFA for users with administrator access.
    We should also add MFA as a second step of authorization—in addition to IAM policies—to
    prevent destructive operations such as the termination and deletion of resources.
    This is useful when compliance and governance policies require models to be stored
    for a period of time before deletion.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最佳实践，我们应该为具有管理员访问权限的用户启用 MFA。我们还应将 MFA 添加为授权的第二步骤，以防止终止和删除资源等破坏性操作。在合规性和治理政策要求模型在删除之前存储一段时间时，这将非常有用。
- en: Least Privilege Access with IAM Roles and Policies
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 IAM 角色和策略实现最小权限访问控制
- en: IAM policies control access to AWS resources. We attach IAM policies to IAM
    identities or AWS resources to define permissions of the identity or resource.
    By default, an IAM user or role starts without any permissions. An administrator
    has to grant permissions to that IAM user or role. When the user is part of a
    group, the user inherits the group’s permissions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: IAM策略控制对AWS资源的访问。我们将IAM策略附加到IAM身份或AWS资源上，以定义身份或资源的权限。默认情况下，IAM用户或角色没有任何权限。管理员必须授予IAM用户或角色权限。当用户属于一个组时，用户会继承该组的权限。
- en: We can define a pool of IAM policies as needed and then assign policies to our
    IAM identities as applicable. [Figure 12-3](#relationship_between_iam_policies_and_i)
    shows a sample many-to-many relationship of IAM policies to IAM users/groups/roles.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 根据需要定义IAM策略池，然后将适用的策略分配给我们的IAM身份。[图 12-3](#relationship_between_iam_policies_and_i)展示了IAM策略与IAM用户/组/角色之间的典型多对多关系示例。
- en: '![Relationship between IAM policies and IAM users/roles](assets/dsaw_1203.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![IAM策略与IAM用户/角色之间的关系](assets/dsaw_1203.png)'
- en: Figure 12-3\. Relationship between IAM policies and IAM users/roles.
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-3\. IAM策略与IAM用户/角色之间的关系。
- en: There are different types of policies, including identity-based and resource-based
    policies. Identity-based policies are JSON policy documents we attach to an IAM
    user/group/role. The policy defines the permissions for the user/group/role.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同类型的策略，包括基于身份和基于资源的策略。基于身份的策略是我们附加到IAM用户/组/角色的JSON策略文档。该策略定义了用户/组/角色的权限。
- en: Resource-Based IAM Policies
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于资源的IAM策略
- en: Resource-based policies are JSON policy documents we attach to an AWS resource,
    such as S3 buckets. In the case of resource-based policies, the policy controls
    access to the resource, i.e., who is allowed to access the S3 bucket under what
    conditions.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 基于资源的策略是我们附加到AWS资源（例如S3存储桶）的JSON策略文档。在基于资源的策略中，策略控制对资源的访问，即谁有权以何种条件访问S3存储桶。
- en: Note that resource-based policies require a principal (who is allowed to perform
    actions on that resource and under what conditions). Principals can be AWS accounts,
    IAM users, IAM roles, federated users, or other AWS services.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，基于资源的策略需要一个主体（允许对资源执行操作及其条件）。主体可以是AWS账户、IAM用户、IAM角色、联合用户或其他AWS服务。
- en: 'Here is an example of a resource-based IAM policy. The following S3 bucket
    policy requires MFA to access the bucket. This is accomplished via the `aws:MultiFactorAuthAge`
    condition key:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个基于资源的IAM策略示例。以下S3存储桶策略要求通过MFA访问存储桶。这通过`aws:MultiFactorAuthAge`条件键实现：
- en: '[PRE2]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If Amazon S3 receives a bucket access request with MFA, `aws:MultiFactorAuthAge`
    carries a numeric value responding to the number of seconds since the temporary
    credential has been created. If the key is `null`, the credential wasn’t created
    via an MFA device, and the access request will be denied.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Amazon S3接收到带有MFA的存储桶访问请求，则`aws:MultiFactorAuthAge`携带一个数值，表示自创建临时凭证以来的秒数。如果该键为`null`，则表示凭证未通过MFA设备创建，访问请求将被拒绝。
- en: Identity-Based IAM Policies
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于身份的IAM策略
- en: 'Here is an example of an identity-based IAM policy that could be attached to
    a Data Scientist IAM role. The policy grants the role access to a specific S3
    bucket and SageMaker Studio environments:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个身份为数据科学家的IAM角色可以附加的基于身份的IAM策略示例。该策略授予角色对特定S3存储桶和SageMaker Studio环境的访问权限。
- en: '[PRE3]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Isolating Compute and Network Environments
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隔离计算和网络环境
- en: We can isolate our development, staging, and production environments by creating
    separate accounts and separate VPCs within each account. This gives us the compute
    and network isolation needed to deploy our Amazon SageMaker, S3, CloudWatch, Redshift,
    and other AWS resources in a least-privilege and internet-free manner. Without
    compute and network isolation, we are at risk of leaking data outside of our network
    and into the wrong hands. Additionally, we are at risk of outside attackers viewing
    data on our compute nodes or inspecting packets on our network.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过创建独立的账户和每个账户内的独立VPC来隔离开发、测试和生产环境。这样做可以为我们部署Amazon SageMaker、S3、CloudWatch、Redshift和其他AWS资源提供所需的计算和网络隔离，以最小权限且无互联网的方式进行。如果没有计算和网络隔离，我们可能会有数据泄露到网络外并落入错误的手中的风险。此外，我们还面临外部攻击者查看计算节点上的数据或检查网络数据包的风险。
- en: Virtual Private Cloud
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟私有云
- en: We can specify allowed network communications to/from our VPCs via route tables.
    Route tables contain rules (“routes”) that define where to send network traffic
    from our virtual private cloud’s (VPC) subnets or gateways.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过路由表指定允许与我们的 VPC 之间的网络通信。路由表包含定义从我们的虚拟私有云（VPC）子网或网关发送网络流量的规则（“路由”）。
- en: A VPC consists of one or more subnets. A VPC is a regional service and our VPC
    can span one or all of the Availability Zones (AZs) in the selected region by
    creating one or more subnets attached to an AZ. We can also add one or more subnets
    in each of the AZs. Subnets are defined as a range of IP addresses. For each subnet,
    we can further specify allowed communications to/from our Amazon EC2 instances,
    such as our SageMaker notebook instances, via Security Groups. VPCs can also be
    peered together to form secure connections within accounts and between accounts.
    Many popular SaaS products use VPC peering between the host and customer account.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: VPC 包括一个或多个子网。VPC 是一个区域性服务，我们的 VPC 可以跨所选区域中的一个或所有可用区（AZ）创建一个或多个与 AZ 关联的子网。我们还可以在每个
    AZ 中添加一个或多个子网。子网被定义为一系列 IP 地址范围。对于每个子网，我们可以进一步指定允许与我们的 Amazon EC2 实例（例如我们的 SageMaker
    笔记本实例）之间的通信，通过安全组。VPC 还可以进行对等连接，以在账户内和账户之间形成安全连接。许多热门的 SaaS 产品使用 VPC 对等连接来连接主机和客户账户。
- en: '[Figure 12-4](#relationship_between_a_vpc_and_related) shows the relationship
    between VPCs and related components, such as gateways, route tables, subnets,
    security groups, and instances.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-4](#relationship_between_a_vpc_and_related)展示了 VPC 与相关组件（如网关、路由表、子网、安全组和实例）之间的关系。'
- en: '![](assets/dsaw_1204.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1204.png)'
- en: Figure 12-4\. Relationship between a VPC and related components.
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-4\. VPC 与相关组件之间的关系。
- en: VPC Endpoints and PrivateLink
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VPC 终端节点和 PrivateLink
- en: VPC Endpoints allow us to connect to services powered by the AWS PrivateLink
    ecosystem, including most AWS services as well as third-party AWS Partner and
    Marketplace offerings. The owner of the service is the “service provider.” The
    consumer of the service is the “service consumer.”
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: VPC 终端节点允许我们连接由 AWS PrivateLink 生态系统支持的服务，包括大多数 AWS 服务以及第三方 AWS 合作伙伴和市场提供的服务。服务的所有者是“服务提供者”。服务的消费者是“服务消费者”。
- en: A VPC Endpoint is an ENI placed into a specific subnet accessible through a
    private IP address. We can control the network communications for that ENI via
    VPC security groups. To control access to the resources behind a VPC Endpoint,
    we specify VPC Endpoint policies.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: VPC 终端节点是放置在特定子网中的 ENI，通过私有 IP 地址访问。我们可以通过 VPC 安全组控制该 ENI 的网络通信。为了控制访问 VPC 终端节点后面的资源，我们指定
    VPC 终端节点策略。
- en: We can create VPC Endpoints to make a private connection between our VPC and
    AWS resources, such as Amazon S3, SageMaker, Redshift, Athena, and CloudWatch.
    Without a VPC Endpoint, we are accessing these services over the public internet
    securely, not with a private tunnel, as shown in [Figure 12-5](#without_vpc_endpointscomma_our_private).
    This is why we should use VPC Endpoints to access services that we use, as shown
    in [Figure 12-6](#with_vpc_endpointscomma_our_private_vpc).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建 VPC 终端节点，以建立我们的 VPC 与 AWS 资源（如 Amazon S3、SageMaker、Redshift、Athena 和
    CloudWatch）之间的私有连接。如果没有 VPC 终端节点，我们将通过公共互联网安全地访问这些服务，而不是通过私有隧道，如[图 12-5](#without_vpc_endpointscomma_our_private)所示。这就是为什么我们应该使用
    VPC 终端节点来访问我们使用的服务，如[图 12-6](#with_vpc_endpointscomma_our_private_vpc)所示。
- en: '![](assets/dsaw_1205.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1205.png)'
- en: Figure 12-5\. Without VPC Endpoints, our private VPC accesses AWS services through
    the public internet in a secure but public tunnel.
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-5\. 没有 VPC 终端节点，我们的私有 VPC 通过公共互联网访问 AWS 服务，以安全但公共的隧道。
- en: '![](assets/dsaw_1206.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1206.png)'
- en: Figure 12-6\. With VPC Endpoints, our private VPC communicates with AWS services
    through a secure and private tunnel.
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-6\. 使用 VPC 终端节点，我们的私有 VPC 通过安全且私有的隧道与 AWS 服务通信。
- en: Fortunately, most services, including Amazon S3, SageMaker, Redshift, Athena,
    and CloudWatch, support VPC Endpoints. But we should be cautious when integrating
    with third-party AWS Partner or Marketplace services that do not offer VPC Endpoints.
    The connections will be secure, but they will not be private unless using a VPC
    Endpoint.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，包括 Amazon S3、SageMaker、Redshift、Athena 和 CloudWatch 在内的大多数服务都支持 VPC 终端节点。但是，在集成不提供
    VPC 终端节点的第三方 AWS 合作伙伴或市场服务时，我们应该保持警惕。连接将是安全的，但除非使用 VPC 终端节点，否则不会是私有的。
- en: Limiting Athena APIs with a VPC Endpoint Policy
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 VPC 终端节点策略限制 Athena API
- en: 'We can create a VPC Endpoint Policy to only allow certain API calls for certain
    resources. For example, let’s lock down an Athena VPC Endpoint to only a specific
    workgroup and set of Athena APIs with a resource-based policy as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建VPC终端点策略，仅允许特定资源的特定API调用。例如，让我们通过以下基于资源的策略将Athena VPC终端点限制为仅特定的工作组和一组Athena
    API调用：
- en: '[PRE4]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Securing Amazon S3 Data Access
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全Amazon S3数据访问
- en: In today’s world, keeping data secure and safe is a top priority. By default,
    all Amazon S3 resources are private so only the resource owner, an AWS account
    that created it, can access the resource. The resource owner can optionally grant
    access permissions to others by writing an access policy.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今世界上，保护数据的安全和安全性是头等大事。默认情况下，所有Amazon S3资源都是私有的，因此只有资源所有者，即创建它的AWS账户，才能访问该资源。资源所有者可以选择通过编写访问策略向其他人授予访问权限。
- en: Amazon S3 integrates with AWS IAM for security and access management. We have
    learned that we can provide identity-based IAM policies, specifying what actions
    are allowed or denied on what AWS resource (i.e., the S3 bucket) by the IAM user/group/role
    the policy is attached to. We can also provide resource-based IAM policies, such
    as S3 bucket policies, which define the permissions by specific principals on
    the bucket. Without securing data access, we are at risk of sensitive data being
    exposed to the wrong audience.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3与AWS IAM集成，用于安全性和访问管理。我们已经了解到，我们可以通过IAM用户/组/角色附加的IAM基于身份的策略来指定允许或拒绝对AWS资源（即S3存储桶）执行的操作。我们还可以提供基于资源的IAM策略，例如S3存储桶策略，它们通过特定主体在存储桶上定义权限。如果不保护数据访问，敏感数据可能会暴露给错误的受众。
- en: Generally, we would use IAM identity-based policies if we need to define permissions
    for more than just S3, or if we have a number of S3 buckets, each with different
    permissions requirements. We might want to keep access control policies in the
    IAM environment.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，如果我们需要为不仅仅是S3定义权限，或者我们有多个S3存储桶，每个都有不同的权限要求，我们会使用IAM基于身份的策略。我们可能希望将访问控制策略保留在IAM环境中。
- en: We would use S3 bucket policies if we need a simple way to grant cross-account
    access to our S3 environment without using IAM roles, or if we reach the size
    limit for our IAM policy. We might want to keep access control policies in the
    S3 environment.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要一种简单的方式在我们的S3环境中授予跨账户访问权限而不使用IAM角色，或者如果我们达到了IAM策略的大小限制，我们将使用S3存储桶策略。我们可能希望将访问控制策略保留在S3环境中。
- en: Note that we can apply both IAM identity-based policies defining permissions
    for a bucket as well as an S3 bucket policy for the same bucket. The resulting
    authorization would be the least privilege from the union of all defined permissions.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们可以同时应用IAM基于身份的策略来定义对存储桶的权限，以及同一存储桶的S3存储桶策略。授权结果将是所有定义权限的联合的最小权限。
- en: When we create S3 buckets for our data science and machine learning projects,
    we should consider creating separate buckets to match our data classification
    and data access control needs. In heavily regulated industries that must comply
    with standards and controls, such as the Payment Card Industry, we should align
    our S3 buckets with separate accounts that also comply with the same standards
    and controls. In this case, our sensitive and raw datasets would only be accessible
    from the compliant accounts, while the nonsensitive, transformed, and masked datasets
    would be accessible from the data science account, for example.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们为数据科学和机器学习项目创建S3存储桶时，我们应考虑创建符合我们数据分类和数据访问控制需求的单独存储桶。在必须遵守诸如支付卡行业等标准和控制的高度管制行业中，我们应将我们的S3存储桶与也符合相同标准和控制的单独账户对齐。在这种情况下，我们的敏感和原始数据集只能从符合要求的账户访问，而非敏感的、转换的和掩码的数据集可以从数据科学账户访问，例如。
- en: As a best practice, we should also consider creating separate buckets for different
    teams, feature stores, model artifacts, and automation pipelines. In addition,
    we should enable S3 bucket-versioning to keep multiple versions of an object or
    recover from unintended user actions. With versioned S3 buckets, we can also enable
    S3 Object Lock, which will enforce “write-once-read-many” to ensure that an object
    does not change—and is not deleted—after it is written. This is required to satisfy
    compliance regulations in financial and healthcare industries.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最佳实践，我们还应考虑为不同的团队、特征存储、模型工件和自动化流水线创建单独的存储桶。此外，我们应启用 S3 存储桶版本控制，以保留对象的多个版本或从意外用户操作中恢复。通过版本化的
    S3 存储桶，我们还可以启用 S3 对象锁定，以确保对象在写入后不会更改或删除，从而满足金融和医疗行业的合规法规要求。
- en: In other scenarios, we need to be able to delete specific user data on request.
    For example, we might need to comply with the “right to be forgotten” rule, which
    is an important pillar in many data protection regulations, such as General Data
    Protection Regulation.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他场景中，我们需要能够根据请求删除特定的用户数据。例如，我们可能需要遵守“被遗忘权”规则，这是许多数据保护法规（如《通用数据保护条例》）中的重要支柱之一。
- en: Depending on which data store we use, there are various ways to implement this.
    For example, using Amazon Redshift Spectrum with the data stored in S3, we can
    copy the external table, which requires data deletion to a temporary Amazon Redshift
    table. We then delete the affected records and write the temporary table back
    to S3, overwriting the key name. In a final step, we delete the temporary Amazon
    Redshift table. If we need to scale and automate the data-deletion procedure,
    we could leverage Apache Spark to load the data from the data source into a temporary
    table, remove the data to be forgotten, and rewrite the data back to the original
    data store.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 根据所使用的数据存储，有多种实现此操作的方式。例如，使用存储在 S3 中的 Amazon Redshift Spectrum，我们可以复制外部表格，将需要删除的数据复制到临时的
    Amazon Redshift 表格中。然后删除受影响的记录，并将临时表格重新写入 S3，覆盖键名。最后，删除临时的 Amazon Redshift 表格。如果需要扩展和自动化数据删除过程，我们可以利用
    Apache Spark 将数据从数据源加载到临时表格中，删除待遗忘的数据，并将数据重新写入原始数据存储。
- en: In cases where models have been trained and deployed using the data to be forgotten,
    we need to trace the lineage forward from the data to find all models trained
    with that data. After removing the data—and depending on the details of the data-protection
    regulation, we may need to retrain and redeploy the model to truly “forget” the
    user and delete their data.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型已经使用待遗忘数据进行训练和部署的情况下，我们需要追踪数据的血统，以找到所有使用该数据进行训练的模型。在移除数据后，根据数据保护法规的具体细节，我们可能需要重新训练和部署模型，以真正地“遗忘”用户并删除他们的数据。
- en: Require a VPC Endpoint with an S3 Bucket Policy
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 需要具有 S3 存储桶策略的 VPC 端点
- en: 'Building on our discussion of IAM roles and VPC Endpoints, we can lock down
    access to specific S3 buckets by requiring a VPC Endpoint using an S3 Bucket Policy
    as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论 IAM 角色和 VPC 端点的基础上，我们可以通过使用 S3 存储桶策略要求 VPC 端点，来限制对特定 S3 存储桶的访问，如下所示：
- en: '[PRE5]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Limit S3 APIs for an S3 Bucket with a VPC Endpoint Policy
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 VPC 端点策略限制 S3 存储桶的 S3 APIs
- en: 'We can also attach a policy to a VPC Endpoint for S3 and only allow a subset
    of S3 APIs on a specific S3 bucket as follows:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以为 S3 的 VPC 端点附加策略，并且只允许在特定 S3 存储桶上执行 S3 APIs 的子集，如下所示：
- en: '[PRE6]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Restrict S3 Bucket Access to a Specific VPC with an S3 Bucket Policy
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 S3 存储桶策略限制特定 VPC 的 S3 存储桶访问
- en: 'Instead of completely locking down the S3 bucket, we could restrict access
    to a specified VPC as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是完全锁定 S3 存储桶，我们可以如下限制对指定 VPC 的访问：
- en: '[PRE7]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With this S3 bucket policy attached to the S3 bucket, all access requests from
    outside of the specified source VPC are denied.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 通过附加到 S3 存储桶的此 S3 存储桶策略，来自指定源 VPC 以外的所有访问请求都将被拒绝。
- en: 'We can verify that the access is denied as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以验证访问被拒绝的方式如下：
- en: '[PRE8]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will receive an error message similar to this:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将收到类似于以下错误消息：
- en: '[PRE9]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Limit S3 APIs with an S3 Bucket Policy
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 S3 存储桶策略限制 S3 APIs
- en: 'We can limit the S3 API operations for a specific bucket by specifying the
    following S3 Bucket Policy that denies the `ListBucket` API to the given bucket:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过指定以下 S3 存储桶策略，限制对特定存储桶的 `ListBucket` API 操作：
- en: '[PRE10]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can verify that the access is denied as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以验证访问被拒绝的方式如下：
- en: '[PRE11]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We will receive an error message similar to this:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将收到类似于以下错误消息：
- en: '[PRE12]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Restrict S3 Data Access Using IAM Role Policies
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 IAM 角色策略限制 S3 数据访问
- en: 'The following example shows how we can restrict access to our S3 buckets using
    an identity-based IAM policy:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的示例展示了如何使用基于身份的IAM策略限制对我们的S3存储桶的访问：
- en: '[PRE13]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can verify that the access is denied as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按如下方式验证访问是否被拒绝：
- en: '[PRE14]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We will receive an error message similar to this:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将收到类似于这样的错误消息：
- en: '[PRE15]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Restrict S3 Bucket Access to a Specific VPC with an IAM Role Policy
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用IAM角色策略限制S3存储桶访问特定VPC
- en: 'We could restrict access to the S3 bucket to a specified VPC as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按以下方式限制对S3存储桶的访问：
- en: '[PRE16]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: With this IAM policy attached to a role, all `ListBucket` requests initiated
    with this role must come from within the VPC or they will be denied.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 将此IAM策略附加到角色后，使用此角色发起的所有`ListBucket`请求必须来自于VPC，否则将被拒绝。
- en: 'We can verify that the access is denied as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按如下方式验证访问是否被拒绝：
- en: '[PRE17]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We will receive an error message similar to this:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将收到类似于这样的错误消息：
- en: '[PRE18]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Restrict S3 Data Access Using S3 Access Points
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用S3访问点限制S3数据访问
- en: Amazon S3 Access Points simplify access control for large, shared buckets such
    as data lakes. Traditionally, we accessed our S3 buckets through a unique bucket
    host name and defined access control with a combination of IAM policies and a
    single bucket policy. We can imagine that for shared datasets and a growing number
    of users, teams, and applications that needed access, this could quickly end up
    as a complex environment for us to maintain.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3访问点简化了对于像数据湖这样的大型共享存储桶的访问控制。传统上，我们通过唯一的存储桶主机名访问我们的S3存储桶，并通过IAM策略和单一存储桶策略定义访问控制。可以想象，对于需要访问的共享数据集以及越来越多的用户、团队和应用程序，这可能很快变得复杂，难以维护。
- en: Amazon S3 Access Points simplify managing data access by providing a customized
    path into a bucket, each with a unique hostname and IAM access policy that enforces
    the specific permissions and network controls for any request made through the
    access point. This is particularly useful for managing access to shared datasets.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3访问点通过提供自定义路径进入存储桶来简化数据访问管理，每个访问点具有唯一的主机名和IAM访问策略，用于强制执行通过访问点发出的请求的特定权限和网络控制。这对于管理对共享数据集的访问特别有用。
- en: We can also require that all access points be restricted to a VPC, providing
    an extra level of security by basically firewalling our data to within our private
    networks.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以要求所有访问点仅限于特定的VPC，通过在本质上将我们的数据防火墙化到我们的私有网络内提供额外的安全层级。
- en: Let’s assume we have our sample S3 bucket called `data-science-on-aws` with
    prefixes (subfolders) called `feature-store` and `data-warehouse`. Our data science
    team needs read/write access to the feature store data, and our business intelligence
    team needs read access to the data-warehouse data stored in that bucket.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有名为`data-science-on-aws`的样本S3存储桶，其中包含名为`feature-store`和`data-warehouse`的前缀（子文件夹）。我们的数据科学团队需要对特征存储数据具有读写访问权限，而我们的商业智能团队需要对存储在该存储桶中的数据仓库数据具有读取权限。
- en: '[Figure 12-7](#accessing_objects_in_amazon_sthree_with) shows how that scenario
    would look without the use of S3 Access Points.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-7](#accessing_objects_in_amazon_sthree_with)展示了在不使用S3访问点的情况下该场景的外观。'
- en: '![](assets/dsaw_1207.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1207.png)'
- en: Figure 12-7\. Accessing objects in Amazon S3 without S3 Access Points using
    a unique bucket host name.
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-7\. 使用唯一存储桶主机名访问Amazon S3中的对象，无需S3访问点。
- en: 'A single S3 bucket policy would have maybe looked like this:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 单个S3存储桶策略可能看起来像这样：
- en: '[PRE19]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now let’s see how we can simplify this with the use of S3 Access Points. The
    following sample command shows how to create Access Points called `ap1-ds` and
    `ap2-bi` via the AWS CLI command on our sample bucket called `data-science-on-aws`:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何通过使用S3访问点来简化这个过程。以下示例命令展示了如何通过AWS CLI命令在我们的样本存储桶`data-science-on-aws`上创建名为`ap1-ds`和`ap2-bi`的访问点：
- en: '[PRE20]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In an access point policy, we then grant the IAM group for our Data Scientist
    team (“ds”) in account 123456789012 permissions to `GET` and `PUT` objects with
    the prefix `feature-store/` through access point `ap1-ds`, and the IAM group for
    our Business Intelligence team (“bi”) permissions to `GET` objects with the prefix
    `data-warehouse/` through access point `ap2-bi`:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在访问点策略中，我们为我们的数据科学家团队（“ds”）（账户123456789012中）的IAM组授予通过访问点`ap1-ds`对前缀为`feature-store/`的对象执行`GET`和`PUT`操作的权限，并为我们的商业智能团队（“bi”）授予通过访问点`ap2-bi`对前缀为`data-warehouse/`的对象执行`GET`操作的权限：
- en: '[PRE21]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[Figure 12-8](#accessing_objects_in_amazon_sthree_usin) shows how we can manage
    access to our S3 objects with S3 Access Points.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-8](#accessing_objects_in_amazon_sthree_usin)展示了我们如何通过S3访问点管理对S3对象的访问。'
- en: '![](assets/dsaw_1208.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1208.png)'
- en: Figure 12-8\. Accessing objects in Amazon S3 using S3 Access Points.
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图12-8\. 使用S3访问点访问Amazon S3中的对象。
- en: 'An AWS CLI request to an object in that bucket through the S3 Access Point
    would then look like this (if we are in the us-east-1 region and have the access
    permissions):'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们位于us-east-1地区并具有访问权限，则通过S3访问点对该存储桶中的对象进行AWS CLI请求会是这样的：
- en: '[PRE22]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We can also access the objects in an Amazon S3 bucket with an access point using
    the AWS Management Console, AWS SDKs, or the S3 REST APIs. For an application
    or user to be able to access objects through an access point, both the access
    point and the underlying bucket must permit the request.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过AWS管理控制台、AWS SDK或S3 REST APIs访问Amazon S3存储桶中的对象。应用程序或用户要通过访问点访问对象，必须同时允许请求的访问点和底层存储桶。
- en: Encryption at Rest
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 静态加密
- en: Without encryption, data is readable by anybody who obtains access. All data
    should be encrypted as an extra layer of protection in case data ends up leaking
    into the malicious hands of an attacker—either internal or external to our organization.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有加密，数据可以被任何获取访问权的人阅读。所有数据都应加密，作为额外的保护层，以防数据泄漏到恶意攻击者（无论是内部还是外部组织）手中。
- en: SageMaker natively integrates with AWS Key Management Service (AWS KMS) to encrypt
    our data at rest using symmetric or asymmetric customer master keys (CMKs). CMKs,
    the primary AWS KMS resource, are a logical representation of a master key and
    include metadata such as the ID, description, creation date, and key state.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker本地集成了AWS Key Management Service（AWS KMS），使用对称或非对称客户主密钥（CMK）对我们的数据进行静态加密。CMK是AWS
    KMS的主要资源，是主密钥的逻辑表示，包括ID、描述、创建日期和密钥状态等元数据。
- en: 'There are three types of CMKs: customer-managed, AWS-managed, and AWS-owned.
    They differ based on who manages the key, who can access the key metadata, how
    often the keys are automatically rotated, and how the keys are scoped across accounts.
    The summary is shown in [Table 12-1](#different_types_of_customer_master_keys).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种类型的CMK：客户管理、AWS托管和AWS拥有。它们根据谁管理密钥、谁可以访问密钥元数据、密钥多久自动轮换以及密钥如何跨账户作用域而不同。总结如下，详见[表12-1](#different_types_of_customer_master_keys)。
- en: Table 12-1\. Different types of CMKs
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 表12-1\. 不同类型的CMK
- en: '| Type of CMK | Can view CMK metadata | Can manage CMK | Used only for our
    AWS account | Automatic rotation |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| CMK类型 | 可以查看CMK元数据 | 可以管理CMK | 仅用于我们的AWS账户 | 自动轮换 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Customer-managed CMK | Yes | Yes | Yes | Optional every 365 days (1 year)
    |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 客户管理的CMK | 是 | 是 | 是 | 每365天（1年）可选 |'
- en: '| AWS-managed CMK | Yes | No | Yes | Required every 1095 days (3 years) |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| AWS托管的CMK | 是 | 否 | 是 | 每1095天（3年）必需 |'
- en: '| AWS-owned CMK | No | No | No | Varies |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| AWS托管的CMK | 否 | 否 | 否 | 各异 |'
- en: We should enable default encryption for all storage volumes, including Amazon
    S3, Amazon EC2 instance disks, network-attached Amazon Elastic Block Store (Amazon
    EBS), and distributed Amazon EFS. Additionally, it is recommended that we use
    deny policies to prevent uploads of unencrypted data to these storage volumes.
    We should encrypt all data artifacts, including notebooks, transformed features,
    trained models, batch predictions, and endpoint predictions. Also, we shouldn’t
    forget to encrypt Docker images stored in Amazon ECR—as well as temporary “scratch”
    local storage and Amazon EBS volumes used during data processing and model training.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该为所有存储卷启用默认加密，包括Amazon S3、Amazon EC2实例磁盘、网络附加Amazon Elastic Block Store（Amazon
    EBS）和分布式Amazon EFS。此外，建议我们使用拒绝策略阻止向这些存储卷上传未加密数据。我们应该加密所有数据工件，包括笔记本、转换特征、训练模型、批量预测和端点预测。此外，我们不应忘记加密存储在Amazon
    ECR中的Docker镜像，以及在数据处理和模型训练期间使用的临时“scratch”本地存储和Amazon EBS卷。
- en: Create an AWS KMS Key
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建AWS KMS密钥
- en: 'We start by creating a key with the AWS KMS to encrypt the storage volumes
    used in our SageMaker examples:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过AWS KMS创建一个密钥，用于加密我们SageMaker示例中使用的存储卷：
- en: '[PRE23]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Encrypt the Amazon EBS Volumes During Training
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在培训期间加密Amazon EBS卷
- en: 'The following sample shows how to use an AWS KMS key with a SageMaker Training
    Job to encrypt the SageMaker instance’s Amazon EBS volume:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的示例展示了如何在SageMaker训练作业中使用AWS KMS密钥来加密SageMaker实例的Amazon EBS卷：
- en: '[PRE24]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Encrypt the Uploaded Model in S3 After Training
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 培训后在S3中加密上传的模型
- en: 'The following sample shows how to use encryption during a SageMaker Training
    Job using an AWS KMS key to encrypt the generated output assets, including our
    trained model in S3:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的示例展示了如何在SageMaker训练作业期间使用AWS KMS密钥对生成的输出资产（包括我们在S3中的训练模型）进行加密：
- en: '[PRE25]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Store Encryption Keys with AWS KMS
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 AWS KMS 存储加密密钥
- en: AWS KMS is a managed service that enables us to easily create and control the
    keys used for cryptographic operations. There are two ways to use AWS KMS with
    Amazon S3 to implement data-at-rest encryption. We can use server-side encryption
    to protect our data with a master key, or we can use an AWS KMS CMK with the Amazon
    S3 Encryption Client to protect our data on the client side.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: AWS KMS 是一个托管服务，可以轻松创建和控制用于加密操作的密钥。在 Amazon S3 中实施数据静态加密时，可以使用两种方法使用 AWS KMS。我们可以使用服务器端加密来使用主密钥保护我们的数据，或者我们可以使用
    AWS KMS CMK 与 Amazon S3 加密客户端来保护客户端端的数据。
- en: 'If we select server-side encryption, we can choose between the following options:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果选择服务器端加密，我们可以在以下选项之间选择：
- en: SSE-S3
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: SSE-S3
- en: Requires that Amazon S3 manage the data and master encryption keys
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 要求 Amazon S3 管理数据和主加密密钥
- en: SSE-C
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: SSE-C
- en: Requires that we manage the encryption key
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 要求我们管理加密密钥
- en: SSE-KMS
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: SSE-KMS
- en: Requires that AWS manage the data key but that we manage the CMK in AWS KMS
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 要求 AWS 管理数据密钥，但我们管理 AWS KMS 中的 CMK
- en: Enforce S3 Encryption for Uploaded S3 Objects
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强制上传到 Amazon S3 对象的 S3 加密
- en: 'To require server-side encryption of all objects in a particular Amazon S3
    bucket (enforcing data-at-rest encryption), we can use a bucket policy. For example,
    the following bucket policy denies upload object (`s3:PutObject`) permission to
    everyone if the request does not include the `x-amz-server-side-encryption` header
    requesting server-side encryption with SSE-KMS:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 要求特定 Amazon S3 存储桶中所有对象都执行服务器端加密（强制数据静态加密），我们可以使用存储桶策略。例如，以下存储桶策略如果请求不包括 `x-amz-server-side-encryption`
    头部来请求使用 SSE-KMS 进行服务器端加密，则拒绝给所有人上传对象 (`s3:PutObject`) 权限：
- en: '[PRE26]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In this case, S3 will encrypt every object before storing it and decrypt every
    object after retrieving it. This encrypt and decrypt process is done seamlessly
    behind the scenes. When we upload an object, we can specify the AWS KMS CMK using
    the header `x-amz-server-side-encryption-aws-kms-key-id`. If the header is not
    present in the request, Amazon S3 assumes the AWS-managed CMK.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，S3 将在存储每个对象之前进行加密，并在检索每个对象之后进行解密。这种加密和解密过程在幕后无缝完成。当我们上传对象时，可以使用头部 `x-amz-server-side-encryption-aws-kms-key-id`
    指定 AWS KMS CMK。如果请求中没有包含该头部，Amazon S3 将假定使用 AWS 托管的 CMK。
- en: Enforce Encryption at Rest for SageMaker Jobs
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强制 SageMaker Jobs 的数据静态加密
- en: 'The following IAM policy will not allow a SageMaker Job to be created without
    Amazon EBS volume encryption:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的 IAM 策略将不允许创建没有 Amazon EBS 卷加密的 SageMaker Job：
- en: '[PRE27]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Enforce Encryption at Rest for SageMaker Notebooks
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强制 SageMaker Notebooks 的数据静态加密
- en: 'The following IAM policy will not allow a SageMaker Notebook instance to be
    created without Amazon EBS volume encryption:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的 IAM 策略将不允许创建没有 Amazon EBS 卷加密的 SageMaker Notebook 实例：
- en: '[PRE28]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Enforce Encryption at Rest for SageMaker Studio
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强制 SageMaker Studio 的数据静态加密
- en: 'The following IAM policy will not allow a SageMaker Studio domain to be created
    without Amazon EFS volume encryption:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的 IAM 策略将不允许创建没有 Amazon EFS 卷加密的 SageMaker Studio 域：
- en: '[PRE29]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Encryption in Transit
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传输中的加密
- en: By default, all public AWS API calls are made over secure Transport Layer Security
    (TLS)–encrypted tunnels. This means that all network traffic is encrypted in transit,
    by default, between SageMaker and S3, for example. Without this encryption, data
    can be inspected by an attacker as it travels across the network in plain text.
    Remember that attacks can come from both inside and outside the organization.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，所有公共 AWS API 调用都通过安全的传输层安全性（TLS）加密隧道进行。这意味着例如 SageMaker 和 S3 之间的所有网络流量都默认情况下在传输过程中进行了加密。如果没有这种加密，数据可能在网络中以明文形式传输，可能会被攻击者查看。请记住，攻击可能来自组织内部和外部。
- en: For data in transit, SageMaker supports inter-container encryption for distributed
    training and HPT jobs. The information passed between training instances generally
    consists of model weights and other metadata versus training data itself, but
    enabling this setting can help meet regulatory requirements and add data protections.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 对于传输数据，SageMaker 支持分布式训练和 HPT 作业的容器间加密。通常传递给训练实例的信息包括模型权重和其他元数据，而不是训练数据本身，但启用此设置可以帮助满足监管要求并增加数据保护。
- en: Post-Quantum TLS Encryption in Transit with KMS
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 KMS 实现传输中的后量子 TLS 加密
- en: AWS KMS supports a quantum-resistant or “post-quantum” option for exchanging
    TLS encryption keys. While classic TLS cipher suite implementation is good enough
    to prevent brute force attacks on the key-exchange mechanism today, it will not
    be strong enough in the near future when large-scale quantum computers become
    accessible.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: AWS KMS支持量子抗性或“后量子”选项，用于交换TLS加密密钥。虽然经典TLS密码套件实现足以防止对今天的密钥交换机制进行暴力攻击，但在大规模量子计算机可用之后，它将不再足够强大。
- en: AWS KMS offers many key-exchange algorithm options for post-quantum TLS encryption,
    including [Kyber](https://oreil.ly/TPVel), [Bit Flipping Key Encapsulation](https://bikesuite.org),
    and [Supersingular Isogeny Key Encapsulation](https://sike.org). [Figure 12-9](#difference_between_classical_tls_onedot)
    shows the difference between Classical TLS 1.2 and Post-Quantum TLS 1.2.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: AWS KMS提供了许多后量子TLS加密的密钥交换算法选项，包括[Kyber](https://oreil.ly/TPVel)，[Bit Flipping
    Key Encapsulation](https://bikesuite.org)和[Supersingular Isogeny Key Encapsulation](https://sike.org)。[图 12-9](#difference_between_classical_tls_onedot)显示了经典TLS
    1.2和后量子TLS 1.2之间的差异。
- en: '![](assets/dsaw_1209.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1209.png)'
- en: Figure 12-9\. Classical and post-quantum TLS 1.2.
  id: totrans-244
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图12-9\. 经典与后量子TLS 1.2。
- en: These post-quantum key exchange mechanisms will affect performance as they require
    extra computational overhead. Therefore, we should always test the performance
    of these algorithms thoroughly before deploying to production.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 这些后量子密钥交换机制将影响性能，因为它们需要额外的计算开销。因此，在部署到生产环境之前，我们应该始终彻底测试这些算法的性能。
- en: Encrypt Traffic Between Training-Cluster Containers
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加密训练集群容器之间的流量
- en: For distributed model training jobs, we can optionally encrypt internal network
    traffic between containers of our distributed-training clusters. While inter-container
    encryption can increase the training time, we should enable this setting to prevent
    sensitive data leakage.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分布式模型训练作业，我们可以选择在分布式训练集群的容器之间加密内部网络流量。虽然容器间加密可能会增加训练时间，但我们应该启用此设置以防止敏感数据泄露。
- en: 'Here is an example of how to encrypt inter-container communication with the
    `encrypt_inter_container_traffic=True` flag:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用`encrypt_inter_container_traffic=True`标志加密容器间通信的示例：
- en: '[PRE30]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Enforce Inter-Container Encryption for SageMaker Jobs
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强制SageMaker作业间容器加密
- en: 'The following policy will not allow SageMaker Training Jobs to run unless inter-container
    traffic encryption is enabled:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 除非启用容器间流量加密，否则以下策略将不允许SageMaker训练作业运行：
- en: '[PRE31]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Securing SageMaker Notebook Instances
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护SageMaker笔记本实例
- en: By running our SageMaker notebook instances inside of our VPC, we create the
    network and compute isolation needed to prevent our sensitive notebooks from being
    accessed from outside the organization. Remember that notebooks, unlike typical
    software source files, often contain outputs such as visualizations and summary
    statistics that describe our datasets. These are just as sensitive as the data
    itself.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在VPC内运行我们的SageMaker笔记本实例，我们创建了所需的网络和计算隔离，以防止外部组织访问我们的敏感笔记本。请记住，笔记本与典型软件源文件不同，通常包含描述数据集的可视化和摘要统计等输出。这些输出与数据本身一样敏感。
- en: Note
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If we want to implement centralized, governed, and self-service access to SageMaker
    notebook instances for our data science teams, we could use the AWS Service Catalog
    to define the SageMaker notebook instance as a product and preconfigure all required
    security policies.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望为我们的数据科学团队实施集中、治理和自助访问SageMaker笔记本实例，我们可以使用AWS服务目录将SageMaker笔记本实例定义为产品，并预配置所有必需的安全策略。
- en: 'When we create a SageMaker notebook instance, we can connect it to our private
    VPC by specifying subnet IDs and security groups as follows:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 创建SageMaker笔记本实例时，可以通过指定子网ID和安全组将其连接到我们的私有VPC，如下所示：
- en: '[PRE32]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Deny Root Access Inside SageMaker Notebooks
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 禁止在SageMaker笔记本内部访问根目录
- en: 'Note that the example also specifies the SageMaker Execution IAM role and the
    KMS key to encrypt the attached volumes, disables direct internet access from
    the notebooks, and disables root access for users. If we want to restrict users
    from creating notebook instances with root access enabled, we could attach the
    following IAM policy to the SageMaker Execution role:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，示例还指定了SageMaker执行IAM角色和用于加密附加卷的KMS密钥，禁用笔记本的直接互联网访问，并禁用用户的根访问。如果我们希望限制用户创建启用了根访问权限的笔记本实例，我们可以将以下IAM策略附加到SageMaker执行角色。
- en: '[PRE33]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Disable Internet Access for SageMaker Notebooks
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 禁用SageMaker笔记本的互联网访问
- en: Another best practice is to disable internet access from/to our VPCs that have
    access to our data. We can provide any external project dependencies via a separate,
    shared service VPC. This VPC could, for example, host a PyPI mirror with our approved
    Python packages.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个最佳实践是禁止访问/从具有对我们数据访问权限的VPC的互联网。 我们可以通过单独的共享服务VPC提供任何外部项目依赖项。 例如，这个VPC可以托管一个带有我们批准的Python包的PyPI镜像。
- en: 'The following example IAM policy will not allow SageMaker notebook instances
    to be created with direct internet access enabled:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例IAM策略将不允许启用直接互联网访问的SageMaker笔记本实例创建：
- en: '[PRE34]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Securing SageMaker Studio
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护SageMaker Studio
- en: By locking down SageMaker Studio to our VPC, we are preventing outside attackers
    from accessing notebooks that contain sensitive data, such as visualizations and
    summary statistics that describe our datasets. SageMaker Studio also supports
    IAM and single-sign-on (SSO) authentication and authorization mechanisms. Using
    IAM and SSO, we can restrict Studio access to a limited number of individuals
    or groups using the least-privilege security principle. Without IAM and SSO authentication
    and authorization, malicious attackers could gain access to our notebooks and
    other Studio assets.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将SageMaker Studio锁定到我们的VPC，我们可以防止外部攻击者访问包含敏感数据的笔记本，例如描述数据集的可视化和摘要统计信息。 SageMaker
    Studio还支持IAM和单点登录（SSO）身份验证和授权机制。 使用IAM和SSO，我们可以根据最小权限安全原则限制Studio的访问权限，仅限少数个人或组。
    如果没有IAM和SSO身份验证和授权，恶意攻击者可能会访问我们的笔记本和其他Studio资产。
- en: Require a VPC for SageMaker Studio
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要求SageMaker Studio的VPC
- en: We can require SageMaker Studio access from our VPC by setting the parameter
    `AppNetworkAccessType` to `VpcOnly`. This deployment setting will create an ENI
    through which the resources in our VPC can communicate with the SageMaker Studio
    services using a VPC Endpoint. We can further control the communication by applying
    security groups to the ENI created by the VPC Endpoint.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将参数`AppNetworkAccessType`设置为`VpcOnly`，我们可以要求从我们的VPC访问SageMaker Studio。 这种部署设置将创建一个ENI，通过该ENI，我们的VPC中的资源可以使用VPC终端节点与SageMaker
    Studio服务通信。 我们可以通过向VPC终端节点创建的ENI应用安全组来进一步控制通信。
- en: 'The following example IAM policy will not allow a SageMaker Studio domain to
    be created outside of a private VPC:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例IAM策略将不允许在私有VPC之外创建SageMaker Studio域：
- en: '[PRE35]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: With `VpcOnly` mode, all SageMaker Studio traffic is routed through the specified
    VPC and subnets. The default setting is `PublicInternetOnly`, which sends all
    non-Amazon EFS traffic through the AWS-managed service VPC, which has internet
    access enabled.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`VpcOnly`模式，所有SageMaker Studio流量都通过指定的VPC和子网路由。 默认设置为`PublicInternetOnly`，将所有非Amazon
    EFS流量通过具有启用互联网访问的AWS托管服务VPC发送。
- en: We define the IAM role for SageMaker Studio during domain creation. We can specify
    a private VPC for network communication via `AppNetworkAccessType=VpcOnly` and
    provide the relevant subnet IDs and the VPC ID. We can also pass a KMS key to
    encrypt the Amazon EFS volume set up by SageMaker Studio.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在域创建期间为SageMaker Studio定义IAM角色。 我们可以通过`AppNetworkAccessType=VpcOnly`指定私有VPC进行网络通信，并提供相关的子网ID和VPC
    ID。 我们还可以传递一个KMS密钥来加密由SageMaker Studio设置的Amazon EFS卷。
- en: 'Here is an example of how to programmatically create the SageMaker Studio domain,
    a user profile, and the SageMaker Studio app with the mentioned settings:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何以编程方式创建SageMaker Studio域、用户配置文件和具有上述设置的SageMaker Studio应用程序的示例：
- en: '[PRE36]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: SageMaker Studio Authentication
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SageMaker Studio身份验证
- en: 'SageMaker Studio supports two modes to authenticate users: SSO and IAM. In
    SSO mode, we map federated identity pools to users. In IAM mode, SageMaker Studio
    is fully integrated with AWS IAM and follows our IAM users, roles, and policy
    configurations. We authenticate with SageMaker Studio running in a SageMaker service
    account and platform VPC with private tunnels to our private account and VPC,
    as shown in [Figure 12-10](#high_level_network_architecture_for_sag).'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Studio支持两种身份验证用户的模式：SSO和IAM。 在SSO模式下，我们将联合身份池映射到用户。 在IAM模式下，SageMaker
    Studio与AWS IAM完全集成，并遵循我们的IAM用户、角色和策略配置。 我们在运行在SageMaker服务账户和平台VPC中的SageMaker Studio中进行身份验证，该VPC通过私有隧道连接到我们的私有账户和VPC，如[图 12-10](#high_level_network_architecture_for_sag)所示。
- en: '![](assets/dsaw_1210.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1210.png)'
- en: Figure 12-10\. High-level network architecture for SageMaker Studio across the
    user VPC and SageMaker platform VPC.
  id: totrans-279
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-10\. SageMaker Studio跨用户VPC和SageMaker平台VPC的高级网络架构。
- en: Securing SageMaker Jobs and Models
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护SageMaker作业和模型
- en: We can also define permissions for SageMaker Jobs using service-level IAM roles
    to restrict permissions of IAM users/groups/roles, similar to the guardrails we
    discussed to restrict data access to our S3 buckets. We can restrict SageMaker
    Jobs to only have access to specific resources, such as S3 buckets or other data
    sources. Furthermore, we can require that SageMaker Jobs run in a private VPC
    to provide the compute and network isolation required to prevent external attackers
    from accessing data stored on the compute nodes or traveling across the network.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用服务级 IAM 角色为 SageMaker 作业定义权限，以限制 IAM 用户/组/角色的权限，类似于我们讨论过的防止数据访问到我们的 S3
    存储桶的防护栏。我们可以限制 SageMaker 作业只能访问特定资源，例如 S3 存储桶或其他数据源。此外，我们可以要求 SageMaker 作业在私有
    VPC 中运行，以提供所需的计算和网络隔离，以防止外部攻击者访问存储在计算节点上的数据或在网络上传输。
- en: Require a VPC for SageMaker Jobs
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要求为 SageMaker 作业配置一个 VPC
- en: 'In the context of SageMaker, we can specify IAM policies that require SageMaker
    to create resources without a VPC. Here is an example of such an IAM policy:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SageMaker 的上下文中，我们可以指定需要 SageMaker 在没有 VPC 的情况下创建资源的 IAM 策略。以下是这样一个 IAM 策略的示例：
- en: '[PRE37]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Here is an example of how to connect SageMaker Training Jobs to our private
    VPC by providing `subnets` and `security_group_ids` to our SageMaker Training
    Job:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这是如何通过为我们的 SageMaker 训练作业提供 `subnets` 和 `security_group_ids` 来将 SageMaker 训练作业连接到我们的私有
    VPC 的示例：
- en: '[PRE38]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: With this configuration, SageMaker will create the ENI to connect the training
    containers to our specified VPC.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种配置，SageMaker 将创建 ENI 来连接训练容器到我们指定的 VPC。
- en: 'We can enforce the specific VPC configuration via an IAM policy such as this:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过类似于这样的 IAM 策略强制执行特定的 VPC 配置：
- en: '[PRE39]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Before we can run our training job within a VPC, we need to make sure that
    the VPC has access to S3 through an S3 VPC endpoint (or NAT device) set up within
    our VPC. This includes configuring subnet route tables, security groups, and network
    access control lists (ACLs). If we don’t do this, we will see an error like this:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以在 VPC 中运行训练作业之前，我们需要确保 VPC 通过设置在我们的 VPC 内部的 S3 VPC 终端节点（或 NAT 设备）访问 S3。这包括配置子网路由表、安全组和网络访问控制列表（ACL）。如果我们没有这样做，我们将看到类似于这样的错误：
- en: '[PRE40]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: With the example IAM policy, we are explicitly denying model creation as well
    as the creation of SageMaker Autopilot Jobs, Training Jobs, Processing Jobs, or
    Hyper-Parameter Tuning Jobs unless deployed with the specified VPC subnet IDs
    and security groups.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个示例 IAM 策略，我们明确拒绝了模型创建以及创建 SageMaker 自动驾驶作业、训练作业、处理作业或超参数调整作业，除非使用指定的 VPC
    子网 ID 和安全组。
- en: 'Let’s run a Training Job without specifying the matching VPC parameters:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在不指定匹配 VPC 参数的情况下运行一个训练作业：
- en: '[PRE41]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We will see a client error like this:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到类似于以下的客户端错误：
- en: '[PRE42]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[Figure 12-11](#sagemaker_training_job_stopped_because) shows how the SageMaker
    Training Job started and stopped at 17:56 UTC.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-11](#sagemaker_training_job_stopped_because) 显示了 SageMaker 训练作业在 UTC
    时间 17:56 开始和停止的情况。'
- en: '![](assets/dsaw_1211.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图](assets/dsaw_1211.png)'
- en: Figure 12-11\. SageMaker Training Job stopped because it doesn’t comply with
    policies.
  id: totrans-299
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-11\. SageMaker 训练作业因不符合策略而停止。
- en: Require Network Isolation for SageMaker Jobs
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 需要为 SageMaker 作业进行网络隔离
- en: If we need to completely isolate our model training jobs, we can enable network
    isolation for the containers performing model training. In this case, the container
    is restricted from all outbound network communication (including API calls to
    Amazon S3) and can only communicate with the local Amazon EBS volume. All required
    input and output data for the training job will have to be stored on the container’s
    local Amazon EBS volumes, which should be encrypted.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要完全隔离我们的模型训练作业，我们可以为执行模型训练的容器启用网络隔离。在这种情况下，容器将被限制从所有出站网络通信（包括对 Amazon S3
    的 API 调用），并且只能与本地 Amazon EBS 卷通信。训练作业所需的所有输入和输出数据都必须存储在容器的本地 Amazon EBS 卷上，这些卷应该是加密的。
- en: Additionally, no AWS credentials are made available to the container runtime
    environment when network isolation is enabled. If we run a distributed training
    job, network communication is limited to the containers of the training cluster,
    which also can be encrypted.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当启用网络隔离时，容器运行时环境不会提供任何 AWS 凭证。如果我们运行分布式训练作业，则网络通信仅限于训练集群的容器，这也可以进行加密。
- en: Running SageMaker Jobs in network isolation mode is a strong protection against
    data-exfiltration risks. However, network isolation is not required to restrict
    traffic to specific AWS resources, such as S3 from within our VPC. For this, we
    use VPC subnet and security group configurations.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络隔离模式下运行 SageMaker 作业可以有效防止数据外泄风险。然而，并非必须在我们的 VPC 中限制对特定 AWS 资源（如 S3）的流量才需要网络隔离。为此，我们使用
    VPC 子网和安全组配置。
- en: 'The following example policy will deny SageMaker Job creation if network isolation
    is disabled:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 如果网络隔离被禁用，以下示例策略将拒绝 SageMaker 作业的创建：
- en: '[PRE43]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'If we try to access any resources outside of the container, we will see the
    following `NoCredentialsError`:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们试图访问容器外的任何资源，将会看到以下 `NoCredentialsError`：
- en: '[PRE44]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: While the training containers cannot access S3 directly because of the network
    isolation, the SageMaker runtime can still copy the data between S3 and the underlying
    SageMaker instance where the training job containers are running. The container
    still has access to the training data through the */opt/ml/input/* directory mounted
    by SageMaker after copying the S3 data to the training instance. Similarly, the
    trained model will be placed in */opt/ml/output/*, which SageMaker will copy to
    S3, as shown in [Figure 12-12](#network_isolation_does_not_prevent_sage).
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然由于网络隔离，训练容器无法直接访问 S3，但 SageMaker 运行时仍然可以将数据在 S3 和运行训练作业容器的底层 SageMaker 实例之间复制。在将
    S3 数据复制到训练实例后，容器仍可通过 SageMaker 挂载的 */opt/ml/input/* 目录访问训练数据。类似地，训练好的模型将被放置在 */opt/ml/output/*，SageMaker
    将其复制到 S3，如图 [12-12](#network_isolation_does_not_prevent_sage) 所示。
- en: '![](assets/dsaw_1212.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1212.png)'
- en: Figure 12-12\. Network isolation does not prevent SageMaker from mounting data
    from S3 into the training containers.
  id: totrans-310
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-12\. 网络隔离不会阻止 SageMaker 将数据从 S3 挂载到训练容器中。
- en: We can further limit the SageMaker runtime’s S3 access through additional IAM
    or S3 Bucket Policies. Additionally, network-isolation mode can be used in combination
    with a VPC, in which case the download/upload of data is routed via the VPC subnet.
    The model training containers would continue to be isolated, though, without access
    to resources in our VPC or the internet.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过额外的 IAM 或 S3 存储桶策略进一步限制 SageMaker 运行时对 S3 的访问。此外，网络隔离模式可以与 VPC 结合使用，此时数据的下载/上传将通过
    VPC 子网路由。模型训练容器将继续被隔离，无法访问我们的 VPC 或互联网上的资源。
- en: Securing AWS Lake Formation
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护 AWS Lake Formation
- en: AWS Lake Formation provides fine-grained access control to rows and columns
    of data for a given principal. With Lake Formation, we specify permissions on
    tables, rows, and columns versus S3 buckets, prefixes, and objects. With the Lake
    Formation “Data Permissions” UI, we can analyze all policies granted to users
    in a single view.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lake Formation 为特定主体的数据行和列提供细粒度访问控制。通过 Lake Formation，我们可以在表、行和列上指定权限，而不是在
    S3 存储桶、前缀和对象上指定。通过 Lake Formation 的“数据权限”用户界面，我们可以在单个视图中分析授予用户的所有策略。
- en: Lake Formation monitors and logs all data-access events in real time. We can
    subscribe to receive alerts when sensitive data is accessed. In addition to reviewing
    real-time dashboards and alerts, we can export data-access logs for offline auditing
    and reporting.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: Lake Formation 实时监控和记录所有数据访问事件。我们可以订阅以接收访问敏感数据时的警报。除了查看实时仪表板和警报外，我们还可以导出数据访问日志进行离线审计和报告。
- en: Securing Database Credentials with AWS Secrets Manager
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 AWS Secrets Manager 保护数据库凭据
- en: We should never use hard-coded, clear-text credentials in our scripts, applications,
    or notebooks. By exposing usernames, passwords, and API keys, we create security
    vulnerabilities, which lead to malicious attacks and data breaches. Instead, we
    should store and retrieve our credentials from AWS Secrets Manager.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们绝不能在脚本、应用程序或笔记本中使用硬编码的明文凭据。通过暴露用户名、密码和 API 密钥，我们会造成安全漏洞，从而导致恶意攻击和数据泄露。相反，我们应该从
    AWS Secrets Manager 存储和检索我们的凭据。
- en: Secrets Manager encrypts secrets using AWS KMS and leverages AWS IAM policies
    to control access to the stored credentials. In addition to manually rotating
    credentials, we can also rotate credentials on a schedule using Secrets Manager.
    Many AWS databases are integrated with Secrets Manager, including Amazon RDS,
    Aurora, and Redshift. For these databases, we specify the unique ARN when executing
    our query. AWS then retrieves and validates the credentials in the background
    without exposing any usernames, passwords, or API keys.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: Secrets Manager使用AWS KMS加密秘密并利用AWS IAM策略控制对存储凭据的访问。除了手动轮换凭据外，我们还可以使用Secrets
    Manager定期按计划轮换凭据。许多AWS数据库已与Secrets Manager集成，包括Amazon RDS、Aurora和Redshift。对于这些数据库，在执行查询时，我们指定唯一的ARN。然后AWS在后台检索和验证凭据，而不会暴露任何用户名、密码或API密钥。
- en: Governance
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 治理
- en: We discussed several mechanisms to implement and enforce configurations that
    help us to comply with our organizational security policies. The examples showed
    controls specific to IAM users, roles, and policies within one AWS account. If
    we want to implement security and governance across AWS accounts and regions,
    we can leverage AWS Organizations, AWS Config, and multiaccount environments.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了几种机制，以实施和执行符合我们组织安全政策的配置。示例显示了在一个AWS账户内特定于IAM用户、角色和策略的控制措施。如果我们希望在AWS账户和区域间实施安全和治理，我们可以利用AWS组织、AWS
    Config和多账户环境。
- en: With AWS Organizations we can define service control policies (SCPs), which
    give us centralized control over the maximum available permissions for all accounts
    in our organization. If we need to set up new, secure, multiaccount AWS environments,
    we can use AWS Control Tower.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AWS组织，我们可以定义服务控制策略（SCPs），这些策略为我们在组织中所有账户上的最大可用权限提供了集中控制。如果我们需要设置新的安全的多账户AWS环境，我们可以使用AWS控制塔。
- en: We can use AWS Config to evaluate AWS resource configurations across our accounts
    against best practices and our custom policies. AWS Config is an example of a
    detective control to alert us if configurations are out of compliance.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用AWS Config根据最佳实践和自定义策略评估我们账户中AWS资源的配置。AWS Config是一个检测控制的例子，用于在配置不符合规范时向我们发出警报。
- en: We can then apply the multiaccount setup to improve governance and security
    of our data science projects by, for example, separating the model deployment
    workflow across data science, staging, and production environments.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以应用多账户设置来改善我们数据科学项目的治理和安全性，例如，通过在数据科学、演示和生产环境之间分离模型部署工作流程。
- en: Secure Multiaccount AWS Environments with AWS Control Tower
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用AWS控制塔保护多账户AWS环境的安全
- en: AWS Control Tower enables us to set up and govern new, secure, multiaccount
    AWS environments in just a few clicks. Using AWS Control Tower, we can automate
    the setup of our AWS environment with best-practices blueprints for multiaccount
    structure, identity, access management, and account provisioning workflow. For
    example, we may want to disallow all public access to all S3 buckets, buckets
    that are not encrypted, or buckets that have versioning disabled.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: AWS控制塔使我们能够在几次点击内设置和管理新的安全的多账户AWS环境。使用AWS控制塔，我们可以通过多账户结构、身份访问管理和账户配置工作流的最佳实践蓝图自动设置我们的AWS环境。例如，我们可能希望禁止所有S3存储桶的公共访问、未加密的存储桶或者禁用版本控制的存储桶。
- en: Manage Accounts with AWS Organizations
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用AWS组织管理账户
- en: AWS Organizations is an account management service that allows us to consolidate
    multiple AWS accounts into one organization. We can then centrally manage all
    accounts mapped to this organization.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: AWS组织是一个账户管理服务，允许我们将多个AWS账户合并到一个组织中。然后，我们可以集中管理映射到该组织的所有账户。
- en: If we need to group specific AWS accounts, we can create organizational units
    (OUs), add the relevant accounts, and attach different policies to each OU. [Figure 12-13](#aws_organization_with_ouscomma_member_a)
    shows how we can group individual accounts into OUs and attach policies.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要分组特定的AWS账户，我们可以创建组织单位（OUs），添加相关账户，并为每个OU附加不同的策略。[图 12-13](#aws_organization_with_ouscomma_member_a)展示了如何将个别账户分组到OUs并附加策略。
- en: '![](assets/dsaw_1213.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_1213.png)'
- en: Figure 12-13\. AWS Organization with OUs, member accounts, and policies.
  id: totrans-329
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-13\. AWS组织与OUs、成员账户和策略。
- en: Enforce Account-Level Permissions with SCPs
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SCPs强制执行账户级权限
- en: AWS Organizations allow us to specify SCPs to define permissions for member
    accounts in the organization. We can leverage SCPs to implement and enforce the
    discussed security controls across AWS accounts.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 组织允许我们指定 SCP 以定义组织中成员账户的权限。我们可以利用 SCP 来跨 AWS 账户实施和执行讨论过的安全控制。
- en: We can leverage SCPs to restrict access to AWS services, resources, and individual
    API actions for users and roles in each mapped AWS member account. Note that these
    restrictions will even take precedence over administrators of member accounts.
    In other words, SCPs give us a centralized control over the maximum available
    permissions for all accounts in the organization.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用 SCP 限制在每个映射的 AWS 成员账户中的用户和角色对 AWS 服务、资源和个别 API 操作的访问。请注意，这些限制甚至会优先于成员账户的管理员。换句话说，SCP
    为我们提供了对组织中所有账户的最大可用权限的集中控制。
- en: We can leverage SCPs as a guardrail or to define limits on the actions that
    the member account’s administrator can grant to the individual account’s IAM user
    and roles. We still have to create IAM policies and attach the policies to IAM
    users/roles in the member accounts. The resulting permissions are the intersection
    between what is allowed by the SCP and the member account’s IAM policies.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用 SCP 作为一种防护栏或者定义成员账户管理员可以授予个别账户 IAM 用户和角色的操作限制。我们仍需在成员账户中创建 IAM 策略并附加这些策略到
    IAM 用户/角色上。最终的权限将取决于 SCP 允许的内容以及成员账户的 IAM 策略的交集。
- en: 'Building upon condition keys for IAM, the following example defines an SCP
    to enforce encryption with a specific KMS key for all SageMaker Training Jobs
    created in the mapped AWS member accounts:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 IAM 的条件键，以下示例定义了一个 SCP，强制在映射的 AWS 成员账户中使用特定的 KMS 密钥对所有 SageMaker 训练任务进行加密：
- en: '[PRE45]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Let’s start a SageMaker Training Job in one of the attached member accounts
    without specifying the given KMS key:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个已附加的成员账户中启动 SageMaker 训练任务，而不指定给定的 KMS 密钥：
- en: '[PRE46]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Here, we see the training job will fail with the expected `AccessDeniedException`:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到训练任务将因为预期的`AccessDeniedException`而失败：
- en: '[PRE47]'
  id: totrans-339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'To fix this, we will start the same Training Job with the specified KMS key,
    and the training job will start successfully:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 要解决此问题，我们将使用指定的 KMS 密钥启动相同的训练任务，训练任务将成功启动：
- en: '[PRE48]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Here, we see the SageMaker Training Job starts successfully using the KMS key
    provided:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 训练任务成功启动，并使用提供的 KMS 密钥：
- en: '[PRE49]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Implement Multiaccount Model Deployments
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实施多账户模型部署
- en: 'We can leverage AWS Control Tower, AWS Organizations, and AWS Config to set
    up and manage multiple AWS accounts. To improve governance and security for model
    deployments, we should create separate AWS accounts for our data scientists, as
    well as for staging and for production environments. A simple AWS Organizations
    structure that defines the corresponding OUs and mapped AWS accounts could look
    like this:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用 AWS 控制塔、AWS 组织和 AWS Config 来设置和管理多个 AWS 账户。为了模型部署的治理和安全性，我们应为数据科学家、以及分阶段和生产环境分别创建独立的
    AWS 账户。一个简单的 AWS 组织结构可以定义相应的 OU 和映射的 AWS 账户，如下所示：
- en: '[PRE50]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The data scientist should be able to freely build, train, and tune models in
    the data science account. Once a trained model qualifies for deployment, the data
    scientist approves the model, which deploys the model into the staging environment.
    The staging environment could be used by the DevOps team to run unit and integration
    tests before deploying the model into the production environment. In [Chapter 10](ch10.html#pipelines_and_mlops),
    we discussed how Amazon SageMaker Projects automate our model deployment pipelines
    across the data science, staging, and production environments. We can adapt the
    SageMaker Projects templates to any custom multiaccount setup.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家应能够在数据科学账户中自由构建、训练和调整模型。一旦训练后的模型符合部署条件，数据科学家批准模型，将其部署到分阶段环境。分阶段环境可供 DevOps
    团队在将模型部署到生产环境之前运行单元和集成测试。在 [第 10 章](ch10.html#pipelines_and_mlops) 中，我们讨论了如何使用
    Amazon SageMaker 项目自动化我们的模型部署流水线，涵盖数据科学、分阶段和生产环境。我们可以调整 SageMaker 项目模板以适应任何自定义的多账户设置。
- en: Auditability
  id: totrans-348
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可审计性
- en: Besides implementing security controls, we also need to audit our environment
    by logging activities, collecting events, and tracking user activities and API
    calls. Auditability is a major requirement for implementing compliance frameworks
    and processes. There are several AWS services and features available to implement
    auditability. We can tag resources and leverage CloudWatch Logs and CloudTrail
    to receive logs and track API calls.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 除了实施安全控制之外，我们还需要通过记录活动、收集事件以及追踪用户活动和 API 调用来审计我们的环境。审计能力是实施合规性框架和流程的主要要求。AWS
    提供了多种服务和功能来实现审计能力。我们可以对资源进行标记，并利用 CloudWatch Logs 和 CloudTrail 接收日志并跟踪 API 调用。
- en: Tag Resources
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标记资源
- en: 'We can add tags to any of our AWS resources. Resource tagging can be used as
    a mechanism for auditability. For example, we could enforce our SageMaker Studio
    applications to contain a specific team or project identifier via condition keys
    in our IAM policy as shown here:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以向任何 AWS 资源添加标签。资源标记可用作审计的一种机制。例如，我们可以通过 IAM 策略中的条件键来强制执行 SageMaker Studio
    应用程序包含特定团队或项目标识符，如下所示：
- en: '[PRE51]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: If we attach this IAM policy to the principal belonging to the “development”
    project, the IAM user or role cannot create applications tagged with another project.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将此 IAM 策略附加到属于“开发”项目的主体，IAM 用户或角色将无法创建带有其他项目标签的应用程序。
- en: Log Activities and Collect Events
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 记录活动并收集事件
- en: Amazon SageMaker automatically logs all API calls, events, data access, and
    interactions during our model development process. We can track and trace the
    interactions down to individual users and IP addresses.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的模型开发过程中，Amazon SageMaker 自动记录所有 API 调用、事件、数据访问和交互。我们可以追踪并跟踪到单个用户和 IP 地址的交互。
- en: We can leverage CloudWatch Logs to monitor, store, and access our SageMaker
    log files. Logs from SageMaker Studio notebooks, SageMaker Processing, or Model
    Training Jobs are also captured as CloudWatch events. We can keep track of metrics
    and create customized dashboards using CloudWatch Metrics. We can set up notifications
    or actions when a metric reaches a specified threshold. Note that SageMaker container
    logs and metrics are delivered to our CloudWatch environment, while the underlying
    infrastructure logs are retained by the SageMaker service platform.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用 CloudWatch Logs 监视、存储和访问我们的 SageMaker 日志文件。来自 SageMaker Studio 笔记本、SageMaker
    处理或模型训练作业的日志也会作为 CloudWatch 事件捕获。我们可以跟踪指标并使用 CloudWatch Metrics 创建定制仪表板。我们可以在指标达到指定阈值时设置通知或操作。需要注意的是，SageMaker
    容器日志和指标会传送到我们的 CloudWatch 环境，而底层基础设施日志由 SageMaker 服务平台保留。
- en: Track User Activity and API Calls
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 追踪用户活动和 API 调用
- en: We can track individual user activity and API calls with CloudTrail. CloudTrail
    will also show API calls that SageMaker instances make on our behalf, including
    the assumed IAM role. If we need to map the activities to each user, we need to
    create a separate IAM role for each user in each SageMaker service that assumes
    the role.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 CloudTrail 跟踪单个用户的活动和 API 调用。CloudTrail 还将显示 SageMaker 实例代表我们执行的 API
    调用，包括所假定的 IAM 角色。如果我们需要将活动映射到每个用户，我们需要在每个承担角色的 SageMaker 服务中为每个用户创建单独的 IAM 角色。
- en: All captured API call logs are delivered to an Amazon S3 bucket that we specify.
    The API logs include the user and account identities for each API call, the source
    IP addresses, and the timestamps of the API calls.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 所有捕获的 API 调用日志将传送到我们指定的 Amazon S3 存储桶。API 日志包括每个 API 调用的用户和账户标识、源 IP 地址以及 API
    调用的时间戳。
- en: Reduce Cost and Improve Performance
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 降低成本并提升性能
- en: We can reduce KMS cost by reducing the number of KMS API calls required by our
    application. In addition, we can reduce SageMaker cost by using IAM policies to
    limit the instance types available to our users.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用 IAM 策略限制用户可用的实例类型来减少 KMS API 调用次数从而降低 KMS 成本。此外，我们还可以通过使用 IAM 策略来减少
    SageMaker 成本。
- en: Limit Instance Types to Control Cost
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制实例类型以控制成本
- en: 'We may want to allow only CPU instances types for our long-lived, real-time
    model endpoints in production—saving the GPUs for our relatively short-lived,
    compute-intensive, batch training jobs. The following policy limits the instance
    types to CPU-based instances when creating a SageMaker Model Endpoint:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能希望在生产环境中，仅允许长期运行的实时模型端点使用 CPU 实例类型，将 GPU 留给相对短期的计算密集型批处理训练作业。以下策略限制在创建 SageMaker
    模型端点时使用基于 CPU 的实例类型：
- en: '[PRE52]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We can also limit the instance types used for SageMaker notebook instances
    and SageMaker Studio domains. Since notebook instances and SageMaker Studio are
    long-lived resources, we may want to limit the instance types to CPU-based instances
    since the GPU-based heavy lifting of SageMaker Training Jobs should happen on
    a SageMaker cluster and not in our notebook. The following policies will limit
    the instance types of long-lived SageMaker notebook instances and SageMaker Studio
    applications to help control cost and encourage better utilization of the more
    expensive GPU instances:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以限制用于SageMaker笔记本实例和SageMaker Studio域的实例类型。由于笔记本实例和SageMaker Studio是长期资源，我们可能希望限制实例类型为基于CPU的实例，因为SageMaker训练作业的GPU重型工作应该在SageMaker集群中进行，而不是在我们的笔记本上。以下策略将限制长期存在的SageMaker笔记本实例和SageMaker
    Studio应用程序的实例类型，以帮助控制成本并促进更好地利用更昂贵的GPU实例：
- en: '[PRE53]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Quarantine or Delete Untagged Resources
  id: totrans-367
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隔离或删除未标记的资源
- en: To control cost, we should tag every resource to properly track and monitor
    our spending. We can enforce tags using the “required-tags” rule with the AWS
    Config service. This rule checks if a resource has the required tags. If the resource
    does not have the required tag, it can be quarantined or deleted to save cost.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 为了控制成本，我们应该为每个资源添加标记，以便正确跟踪和监控我们的支出。我们可以使用AWS Config服务的“required-tags”规则强制执行标记。此规则检查资源是否具有所需的标记。如果资源没有所需的标记，可以将其隔离或删除以节省成本。
- en: Use S3 Bucket KMS Keys to Reduce Cost and Increase Performance
  id: totrans-369
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用S3存储桶KMS密钥以降低成本并提高性能
- en: 'We can reduce cost for encryption by using S3 Bucket Keys, which decreases
    the number of API calls to the AWS KMS service when new objects are uploaded.
    We can add an S3 Bucket Key to our bucket with the following code:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用S3存储桶密钥，我们可以降低加密成本，这减少了上传新对象时对AWS KMS服务的API调用次数。我们可以使用以下代码向我们的存储桶添加S3存储桶密钥：
- en: '[PRE54]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Summary
  id: totrans-372
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we started by discussing how AWS cloud security is “job zero”
    and “priority zero.” We introduced the relevant security concepts and AWS security
    services and features we can leverage—as well as the AWS shared-responsibility
    security model. We showed how to build secure data science and machine learning
    projects on AWS. We described how to implement preventive and detective controls
    that stop events from occurring—as well as responsive and corrective controls
    that helped to remediate security violations.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先讨论了AWS云安全如何是“零工作”和“零优先级”。我们介绍了相关的安全概念和可以利用的AWS安全服务和功能，以及AWS共享责任安全模型。我们展示了如何在AWS上构建安全的数据科学和机器学习项目。我们描述了如何实施预防和检测控制以阻止事件发生，以及响应和纠正控制，帮助补救安全违规行为。
- en: We described best practices in the area of compute and network isolation, authentication
    and authorization, encryption, and governance, as well as auditability and compliance.
    We learned how to protect our data by implementing access control with AWS IAM
    and restrict network access using VPCs. We highlighted some important concepts
    we should leverage to secure our data and showed specific examples of how to add
    different levels of security to our S3 data access and SageMaker Jobs. We showed
    how the use of S3 Access Points can help manage access to data in shared S3 buckets
    (aka our S3 data lake). We described data-at-rest encryption with AWS KMS and
    encryption-in-transit with traditional and post-quantum cryptography. Next, we
    discussed mechanisms to implement governance and auditability. Last, we finished
    the chapter by sharing tips on how to reduce cost and improve performance with
    the AWS security services.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在计算和网络隔离、身份验证和授权、加密、治理以及可审计性和合规性领域描述了最佳实践。我们学习了如何通过AWS IAM实施访问控制，并使用VPC限制网络访问。我们强调了一些重要的概念，我们应该利用这些概念来保护我们的数据，并展示了如何向我们的S3数据访问和SageMaker作业添加不同安全级别的具体示例。我们展示了S3访问点如何帮助管理对共享S3存储桶（也称为我们的S3数据湖）中数据的访问。我们描述了AWS
    KMS提供的数据静态加密和传统以及后量子密码学的数据传输加密。接下来，我们讨论了实施治理和可审计性的机制。最后，我们通过分享如何通过AWS安全服务来减少成本和提高性能的提示来结束本章。
