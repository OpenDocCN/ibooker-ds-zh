- en: 5 Collaborative filtering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 协同过滤
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Designing proper graph models for a collaborative filtering approach
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为协同过滤方法设计合适的图模型
- en: Importing existing (nongraph) datasets into the graph models designed
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将现有的（非图）数据集导入为图模型设计
- en: Implementing working collaborative filtering recommendation engines
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现工作协同过滤推荐引擎
- en: The content-based (also called content-filtering or cognitive) approach to recommendations
    described in chapter 4 creates profiles for users and items to characterize them.
    The profiles allow systems to match users with relevant items. The general principle
    of content-based methods is to identify the common characteristics of items that
    have received favorable feedback from a user (a positive rating, a purchase, a
    click) and then recommend to this user new items that share these characteristics.
    Content-based strategies require gathering information that might not be readily
    available, easy to collect, or directly relevant.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 第4章中描述的基于内容的（也称为内容过滤或认知）推荐方法为用户和项目创建档案以描述它们。这些档案允许系统将用户与相关项目匹配。基于内容方法的一般原则是识别用户对获得正面反馈（如好评、购买、点击）的项目共有的特征，然后向该用户推荐具有这些特征的新项目。基于内容策略需要收集可能不易获得、难以收集或与内容直接相关的信息。
- en: An alternative to content filtering relies only on past user behavior, such
    as previous transactions or item ratings, or the opinions of an existing user
    community to predict which items the users will most probably like or be interested
    in without requiring the creation of explicit profiles for both items and users
    based on item features. This approach is known as *collaborative filtering*, a
    term coined by the developers of Tapestry [Goldberg et al., 1992], the first recommender
    system. Collaborative filtering analyzes relationships between users and interdependencies
    among items to predict new user-item associations. Figure 5.1 represents a mental
    model for collaborative filtering recommenders considering input and output.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 内容过滤的替代方案仅依赖于过去用户的行为，例如之前的交易或项目评分，或现有用户社区的意见，以预测用户最可能喜欢或感兴趣的项目，而无需根据项目特征为项目和用户创建显式的档案。这种方法被称为*协同过滤*，是由Tapestry的开发者（Goldberg等人，1992年）提出的，是第一个推荐系统。协同过滤分析用户之间的关系和项目之间的相互依赖性，以预测新的用户-项目关联。图5.1表示了考虑输入和输出的协同过滤推荐者的心智模型。
- en: '![CH05_F01_Negro](../Images/CH05_F01_Negro.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F01_Negro](../Images/CH05_F01_Negro.png)'
- en: Figure 5.1 Collaborative filtering mental model
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 协同过滤心智模型
- en: A major appeal of collaborative filtering is that it is domain free and doesn’t
    require any detail about the items. It can be applied to a vast variety of use
    cases and scenarios, and it can address data aspects that are often elusive and
    difficult to profile by using content filtering.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤的一个主要吸引力是它不受领域限制，并且不需要任何关于项目的详细信息。它可以应用于广泛的用例和场景，并且可以使用内容过滤难以描述的数据方面来解决问题。
- en: Although it is generally more accurate than content-based techniques, collaborative
    filtering suffers from what is called the *cold-start problem* due to its inability
    to provide reasonable (in terms of accuracy) recommendations for new items and
    users or when limited interaction data is available. Nonetheless, mechanisms do
    exist that mitigate the effect of the cold-start problem by using different algorithms,
    such as the graph approach (discussed in section 5.5) or other sources of knowledge,
    such as social networks.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于协同过滤的方法通常比基于内容的技术更准确，但由于其无法为新项目或用户或当有限交互数据可用时提供合理的（从准确性角度）推荐，因此协同过滤受到所谓的*冷启动问题*的影响。尽管如此，确实存在一些机制，通过使用不同的算法（如第5.5节中讨论的图方法）或其他知识来源（如社交网络）来减轻冷启动问题的影响。
- en: 'Collaborative filtering techniques are generally classified into two main approaches
    or areas:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 协同过滤技术通常分为两种主要方法或领域：
- en: '*Memory-based*—Memory-based supposes that if a user likes the movie *Saving
    Private Ryan*, they may like similar movies, such as war movies, Spielberg movies,
    and Tom Hanks movies [Koren et al., 2009]. To predict a particular user’s rating
    for *Saving Private Ryan*, we would look for the movie’s nearest neighbors that
    this user rated. Alternatively, the algorithm can look for similar users based
    on the set of films they watched and suggest something that the current user hasn’t
    watched yet. In these methods, the User-Item dataset that is stored is used directly
    to predict ratings for items.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于记忆的*—基于记忆的方法假设如果用户喜欢电影《拯救大兵瑞恩》，他们可能喜欢类似的电影，例如战争电影、斯皮尔伯格的电影和汤姆·汉克斯的电影 [Koren
    等人，2009]。为了预测特定用户对《拯救大兵瑞恩》的评分，我们会寻找这位用户评价过的与这部电影最接近的邻居电影。或者，算法可以根据他们观看的电影集合寻找类似用户，并推荐当前用户尚未观看的内容。在这些方法中，存储的
    User-Item 数据集直接用于预测物品的评分。'
- en: These methods are also referred to as *neighborhood methods* because they center
    on computing the relationships among items or users. The *item-oriented* approach
    predicts a user’s preference for an item based on ratings of neighboring items
    by the same user. An item’s neighbors are other items that tend to get similar
    ratings when rated by the same user. By contrast, the *user-oriented* approach
    identifies like-minded users who can complement one another’s ratings. In other
    words, the recommendation process in this case consists of finding other users
    who are close to the current one (having rated items similarly or purchased the
    same things) and suggesting items those users have interacted with (rated, bought,
    or clicked).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法也被称为 *邻域方法*，因为它们集中在计算物品或用户之间的关系。*物品导向*的方法基于同一用户对邻近物品的评分来预测用户对物品的偏好。一个物品的邻居是那些在相同用户评分下倾向于获得相似评分的其他物品。相比之下，*用户导向*的方法识别出有共同观点的用户，他们可以互补彼此的评分。换句话说，在这种情况下，推荐过程包括寻找与当前用户相似的其他用户（对物品有相似的评分或购买了相同的东西），并推荐这些用户互动过的物品（评分、购买或点击）。
- en: '*Model-based*—These methods create models for users and items that describe
    their behavior via a set of factors or features and the weight these features
    have for each item and each user. In the movie example, the discovered factors
    might measure obvious dimensions such as genre (comedy, drama, action) or orientation
    to children; less well-defined dimensions such as depth of character development
    or quirkiness; or uninterpretable dimensions. For users, each factor expresses
    how much the user likes movies that score high on the corresponding factor. In
    these methods, the raw data (the User-Item dataset) is first processed offline,
    with the information on ratings or previous purchases used to create this predictive
    model. At run time, during the recommendation process, only the precomputed or
    learned model is required to make predictions. Latent factor models represent
    the most common approaches in this class. They try to explain the ratings by characterizing
    both items and users on, say, 20 to 100 factors inferred from the rating patterns.
    In a sense, such factors comprise a computerized alternative to the human-created
    features encountered in the content-based recommendation systems.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于模型的方法*—这些方法为用户和物品创建模型，通过一系列因素或特征以及这些特征对每个物品和每个用户的权重来描述他们的行为。在电影示例中，发现的因素可能衡量明显的维度，如类型（喜剧、剧情、动作）或对儿童的态度；不太明确的维度，如人物发展的深度或古怪性；或不可解释的维度。对于用户来说，每个因素都表达了用户对在相应因素上得分高的电影的喜爱程度。在这些方法中，原始数据（User-Item
    数据集）首先在离线状态下进行处理，使用评分或之前的购买信息来创建这个预测模型。在运行时，在推荐过程中，只需要预先计算或学习到的模型来做出预测。潜在因素模型是这类方法中最常见的途径。它们试图通过在从评分模式中推断出的20到100个因素上对物品和用户进行特征化来解释评分。从某种意义上说，这些因素构成了计算机化的替代品，替代了在基于内容的推荐系统中遇到的人类创建的特征。'
- en: Note Although recent investigations show state-of-the-art model-based approaches
    as being superior to neighborhood ones at the task of predicting ratings [Koren,
    2008, and Takács et al., 2007], an understanding is emerging that good prediction
    accuracy alone does not guarantee users an effective and satisfying experience
    [Herlocker et al., 2004].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：尽管最近的调查表明，在预测评分的任务中，基于模型的方法在性能上优于基于邻域的方法 [Koren，2008，以及 Takács 等人，2007]，但一个理解正在出现，即仅仅好的预测精度并不能保证用户获得有效和满意的体验
    [Herlocker 等人，2004]。
- en: As stated in the introduction to part 2, some of the main reasons why companies
    implement recommendation engines are to increase user satisfaction and loyalty,
    and to sell more diverse items. Moreover, recommending to a user a movie directed
    by their favorite director constitutes a novel recommendation if the user was
    not aware of that movie, but the user probably would have discovered that movie
    on their own [Ning et al., 2015].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如第2部分引言所述，公司实施推荐引擎的一些主要原因是为了提高用户满意度和忠诚度，以及销售更多样化的商品。此外，向用户推荐他们最喜欢的导演执导的电影，如果用户之前不知道这部电影，则构成一种新颖的推荐，但用户可能自己会发现这部电影[Ning
    等人，2015年]。
- en: 'This example shows another relevant factor that has been identified as playing
    an important role in users’ appreciation of the recommender system: serendipity
    [Herlocker et al., 2004, and Sarwar et al., 2001]. Serendipity extends the concept
    of novelty by helping users find interesting items that they might not have discovered
    otherwise. This aspect of recommendation increases user satisfaction and helps
    companies sell more diverse items.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此例展示了另一个被认定为在用户对推荐系统欣赏中扮演重要角色的相关因素：意外发现[Herlocker 等人，2004年，以及 Sarwar 等人，2001年]。意外发现通过帮助用户找到他们可能否则不会发现的有趣项目，扩展了新颖性的概念。这一方面的推荐增加了用户满意度，并帮助公司销售更多样化的商品。
- en: This example illustrates the way in which model-based approaches excel at characterizing
    the preferences of a user with latent factors. In a movie recommender system,
    such methods may determine that a given user is a fan of movies that are both
    funny and romantic without having to define the notions *funny* and *romantic*.
    This system, therefore, would be able to recommend to the user a romantic comedy
    that may not have been known to them. In terms of prediction accuracy, this approach
    delivers the best result possible, but it may be difficult for the system to recommend
    a movie that does not quite fit this high-level genre (such as a funny parody
    of a horror movie).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子说明了基于模型的方法在表征具有潜在因素的用户偏好方面的优势。在电影推荐系统中，这些方法可能确定某个用户是既搞笑又浪漫电影的粉丝，而无需定义“搞笑”和“浪漫”这些概念。因此，该系统将能够向用户推荐他们可能未曾知晓的浪漫喜剧。在预测准确度方面，这种方法可以提供最佳结果，但系统可能难以推荐一个与这种高级类型（如恐怖电影的搞笑模仿）不太吻合的电影。
- en: 'Neighborhood approaches, on the other hand, capture local associations in the
    data. Consequently, it is possible for a movie recommender system based on this
    type of approach to recommend a movie quite different from the user’s usual taste
    or to recommend a movie that is not well known (such as a repertoire film) if
    one of their closest (user) neighbors has given it a strong rating. This recommendation
    may not be a guaranteed success, as a romantic comedy might be, but it could help
    the user discover a new genre, or a new favorite actor or director. Neighborhood-based
    methods have numerous advantages, such as the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，基于邻域的方法捕捉数据中的局部关联。因此，基于这种类型的方法的电影推荐系统可能会推荐一部与用户通常口味截然不同的电影，或者如果他们的一个最近邻（用户）给出了强烈的评分，可能会推荐一部不太知名的电影（如保留剧目电影）。这种推荐可能不会像浪漫喜剧那样保证成功，但它可能帮助用户发现一个新类型，或者一个新喜爱的演员或导演。基于邻域的方法具有许多优点，如下所述：
- en: '*Simplicity*—Neighborhood-based methods are intuitive and relatively simple
    to implement. In their simplest form, only one parameter (the number of neighbors
    used in the prediction) requires tuning. Model-based approaches, on the other
    hand, generally use matrix factorization techniques that are implemented with
    optimization algorithms to find near-optimal solutions. These optimization techniques,
    such as stochastic gradient descent[¹](#pgfId-1009138) (SGD) and alternating least
    squares[²](#pgfId-1009163) (ALS), have a lot of hyperparameters that must be tuned
    carefully to avoid falling into a local minimum.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*简单性*——基于邻域的方法直观且相对容易实现。在其最简单形式中，只需要调整一个参数（用于预测中使用的邻居数量）。另一方面，基于模型的方法通常使用矩阵分解技术，这些技术通过优化算法实现以找到近似最优解。这些优化技术，如随机梯度下降[¹](#pgfId-1009138)（SGD）和交替最小二乘[²](#pgfId-1009163)（ALS），具有许多必须仔细调整的超参数，以避免陷入局部最小值。'
- en: '*Justifiability*—These methods provide concise and intuitive justification
    for the computed predictions. In item-based recommendations, the list of neighboring
    items, as well as the ratings given by the user to these items, can be presented
    to the user as justification for the recommendations. This explanation can help
    the user better understand the recommendation process and how the relevance is
    computed, increasing the user’s trust in the recommender system (and the platform
    providing it). It could also serve as a basis for an interactive system in which
    users select the neighbors to whom greater importance should be given in the recommendations
    [Bell et al., 2007].'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可解释性*——这些方法为计算出的预测提供了简洁直观的解释。在基于项目的推荐中，可以展示给用户邻近项目的列表以及用户对这些项目的评分，作为推荐的解释。这种解释可以帮助用户更好地理解推荐过程以及相关性是如何计算的，从而增加用户对推荐系统（及其提供平台）的信任。它还可以作为用户在选择在推荐中给予更大重要性的邻居时的交互式系统的基础
    [Bell et al., 2007]。'
- en: '*Efficiency*—One strong point of neighborhood-based systems is their time efficiency.
    By comparison with most model-based systems, they require fewer expensive training
    phases, which need to be carried out at frequent intervals in large commercial
    applications. These systems may require precomputing nearest neighbors in an offline
    step but are typically much cheaper than model training in a model-based approach.
    Furthermore, it is possible to identify a small portion of the model to be recomputed
    when new information is available. These features help provide near-instantaneous
    recommendations. Moreover, storing these nearest neighbors requires little memory,
    making such approaches scalable to applications with millions of users and items.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*效率*——基于邻域的系统的一个显著优点是它们的效率。与大多数基于模型的系统相比，它们需要的昂贵训练阶段更少，这些阶段在大规模商业应用中需要频繁进行。这些系统可能需要在离线步骤中预先计算最近邻，但通常比基于模型的方法的模型训练便宜得多。此外，当有新信息可用时，可以识别出需要重新计算的小部分模型。这些特性有助于提供几乎瞬时的推荐。此外，存储这些最近邻需要很少的内存，使得这种方法可以扩展到拥有数百万用户和项目的应用。'
- en: '*Stability*—Another useful property of recommender systems based on this approach
    is that they are little affected by the addition of users, items, and ratings,
    as is typically observed in large commercial applications. When item similarities
    have been computed, an item-based system can readily make recommendations to new
    users without being retrained. Moreover, when a few ratings have been entered
    for a new item, only the similarities between this item and the ones already in
    the system need to be computed.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*稳定性*——基于这种方法的推荐系统另一个有用的特性是，它们受到用户、项目和评分增加的影响很小，这在大型商业应用中通常观察到。当计算了项目相似度后，基于项目的系统可以轻松地向新用户推荐，而无需重新训练。此外，当为新项目输入少量评分时，只需计算此项目与系统中已有的项目之间的相似度。'
- en: '*Graph-based*—Another great advantage, related to the topic of this book, is
    that the origin dataset and the nearest neighbor model can be easily mapped in
    graph models. The resulting graph provides great advantages with regard to local
    navigation of data during model updating or forecasting, justifiability, and access
    efficiency. It also helps solve the cold-start problem, described in section 5.5.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于图的*——另一个与本书主题相关的重要优势是，原始数据集和最近邻模型可以轻松地映射到图模型中。由此产生的图在模型更新或预测期间的数据局部导航、可解释性和访问效率方面提供了巨大优势。它还有助于解决第5.5节中描述的冷启动问题。'
- en: For these reasons, this chapter focuses mainly on this class of collaborative
    filtering recommendation systems. But although neighborhood-based methods have
    gained popularity due to these advantages, they are known to suffer from the problem
    of limited coverage, which causes some items to never be recommended. Also, traditional
    methods in this category are known to be sensitive to sparseness of ratings and
    the cold-start problem when the system has only a few ratings or no ratings for
    new users and items. In section 5.5, I discuss techniques for mitigating or solving
    the cold-start problem. Finally, no single approach to recommendation engines
    can fit all cases, which is why hybrid approaches are generally used in production-ready
    recommendation engine systems. These methods are described in chapter 7.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些优势，本章主要关注这类协同过滤推荐系统。尽管基于邻居的方法因其优势而受到欢迎，但它们也普遍存在覆盖范围有限的问题，导致某些商品从未被推荐。此外，该类传统方法也普遍对评分稀疏性和系统只有少量评分或对新用户和商品没有评分时的冷启动问题敏感。在第5.5节中，我将讨论缓解或解决冷启动问题的技术。最后，没有单一的推荐引擎方法可以适用于所有情况，这就是为什么在可投入生产的推荐引擎系统中通常使用混合方法。这些方法在第7章中进行了描述。
- en: 5.1 Collaborative filtering recommendations
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 协同过滤推荐
- en: In this section, you are going to learn how to design graph models and the algorithms
    on top to implement a recommender system for an e-commerce site that uses a collaborative
    filtering approach to gently suggest to users items that could be of interest
    to them.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何设计图模型及其算法，以实现一个用于电子商务网站的推荐系统，该系统采用协同过滤方法，温和地向用户推荐可能对他们感兴趣的商品。
- en: The site might sell many types of items, such as books, computers, watches,
    and clothing. The details about each item are not curated; some items have only
    a title, one or more pictures, and a small and useless description. Suppliers
    don’t provide a lot of information, and due to the number of items and the number
    of suppliers, it’s not practical to have an internal team take care of this task
    at scale.[³](#pgfId-1009193) On the site, users can buy items only if they are
    registered and logged in. Thanks to cookies, it is possible to log the users in
    automatically as soon as they reach the site. Little information is tracked about
    each user—only what’s necessary for payments and shipping.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 该网站可能销售许多类型的商品，例如书籍、电脑、手表和服装。关于每个商品的详细信息未经精心整理；有些商品只有标题、一张或多张图片以及一小段无用的描述。供应商没有提供大量信息，由于商品数量和供应商数量众多，因此不可能有一个内部团队大规模地处理这项任务。[³](#pgfId-1009193)
    在网站上，用户只有在注册并登录后才能购买商品。多亏了cookies，用户一旦到达网站就可以自动登录。关于每个用户的信息跟踪很少——只有支付和运输所必需的信息。
- en: In this scenario, a content-based approach like the one described in chapter
    4 is not applicable. Often, no data that is useful for creating profiles about
    users or items is available. Nonetheless, users’ activity is tracked. Each user
    is logged in most of the time, and it is possible to collect and store a huge
    variety of interactions between users and items (purchases, clicks, searches,
    and ratings). Collaborative filtering approaches use this data to provide recommendations
    to users. The overall recommendation process, which takes advantage of graph models,
    can be summarized by the high-level schema in figure 5.2.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，类似于第4章中描述的内容方法不适用。通常，没有可用于创建用户或商品档案的有用数据。尽管如此，用户的活跃度是会被跟踪的。大多数时候用户都是登录状态，可以收集和存储用户与商品之间的大量互动（购买、点击、搜索和评分）。协同过滤方法使用这些数据向用户提供推荐。利用图模型的优势，整个推荐过程可以用图5.2中的高级架构进行总结。
- en: '![CH05_F02_Negro](../Images/CH05_F02_Negro.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F02_Negro](../Images/CH05_F02_Negro.png)'
- en: Figure 5.2 A graph-powered collaborative filtering recommender system
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2：由图驱动的协同过滤推荐系统
- en: 'This figure shows the main elements and tasks of the collaborative filtering
    recommendation engine, which uses graphs as the data representation for both the
    User-Item dataset and the nearest neighbor network. Suppose that user John buys
    two books from the e-commerce site: technical books about machine learning and
    graphs. As the first step, the User-Item matrix is converted to a bipartite graph.
    In this case, John, represented by a node, will be connected to two nodes representing
    the two books purchased. The resulting graph is used as input for the creation
    of the nearest neighbors network by computing similarities between users, items,
    or both, depending on the algorithm used for recommendations. Hence, John is similar
    to users who are interested in graphs and machine learning and who bought the
    same set of books. The two books are also similar to others that have been purchased
    by the same set of users, probably on the same topic. Then the top k-nearest neighbors
    for each element (users or items) are stored back in the original graph, which
    is enriched with these new relationships among users, items, or both. The similarity
    value is stored as a property of the relationship, assigning it a weight. The
    higher this weight value is, the more similar the users are by this relationship.
    Providing recommendations for users at this point is a matter of using their previous
    interactions and the nearest neighbors network. Such a task can be accomplished
    with a simple graph-matching query. Then the list of recommendations is provided
    to the user.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此图展示了协同过滤推荐引擎的主要元素和任务，该引擎使用图作为用户-项目数据集和最近邻网络的表示。假设用户约翰从电子商务网站购买了两种书籍：关于机器学习和图的科技书籍。作为第一步，用户-项目矩阵被转换为一个二分图。在这种情况下，代表约翰的节点将与代表购买的两本书的两个节点相连。生成的图被用作输入，通过计算用户、项目或两者的相似性来创建最近邻网络，具体取决于所使用的推荐算法。因此，约翰与对图和机器学习感兴趣且购买了相同书籍集的用户相似。这两本书也与被同一组用户购买的其它书籍相似，可能是在同一主题下。然后，将每个元素（用户或项目）的前k个最近邻存储回原始图，该图通过这些新的用户、项目或两者之间的关系得到丰富。相似度值作为关系的属性存储，并为其分配权重。这个权重值越高，通过这种关系用户之间的相似度就越高。此时为用户提供推荐是一个使用他们之前交互和最近邻网络的问题。这个任务可以通过简单的图匹配查询来完成。然后，将推荐列表提供给用户。
- en: Further interactions can be looped back into the system to update the model.
    This task can use the locality provided by the graph model; new interactions will
    affect only a small portion of the nearest neighbor network. If a user watches
    a new movie, it will be easy to find the affected movies (all the movies that
    share at least one user with the one affected by the change) and compute the new
    similarities for them. This approach also allows the recommender engine to adapt
    more easily to the evolution of tastes. Graph navigation based on relationship
    traversal facilitates those updates as well as the recommendation phase.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步的交互可以被循环回系统中以更新模型。这个任务可以利用图模型提供的局部性；新的交互只会影响最近邻网络的一小部分。如果一个用户观看了一部新电影，将很容易找到受影响的电影（所有至少与受影响的用户共享一个用户的电影），并计算它们的新的相似度。这种方法还允许推荐引擎更容易地适应口味的变化。基于关系遍历的图导航也有助于这些更新以及推荐阶段。
- en: Considering the high-level architecture, which also acts as a mental model,
    the following sections describe in detail how to create and navigate a bipartite
    graph, how to compute the nearest neighbor network, and how to provide recommendations.
    A concrete e-commerce dataset is used as the example in this scenario.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到高级架构，它也充当一个心理模型，以下章节将详细描述如何创建和导航一个二分图，如何计算最近邻网络，以及如何提供推荐。在这个场景中，使用一个具体的电子商务数据集作为示例。
- en: 5.2 Creating the bipartite graph for the User-Item dataset
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 创建用户-项目数据集的二分图
- en: In the content-based approach discussed in chapter 4, a lot of information is
    available for both items and users and is useful for creating profiles. We used
    a graph model to represent these profiles, connecting each item to its features
    and each user to features of interest. Even the nearest neighbor network was built
    with only this information. The collaborative filtering approach, on the other
    hand, relies on data related to different kinds of interactions between users
    and items. Such information is generally referred to as a *User-Item dataset*.
    An example of such a dataset was described in chapter 3; here, the discussion
    is extended and refined. Figure 5.3 highlights the creation of a bipartite graph
    from a User-Item dataset in the recommendation process.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4章讨论的内容导向方法中，物品和用户都有大量可用信息，这些信息对于创建个人资料非常有用。我们使用图模型来表示这些个人资料，将每个物品与其特征连接，并将每个用户与其感兴趣的特征连接。甚至最近的邻域网络也是仅用这些信息构建的。另一方面，协同过滤方法依赖于用户和物品之间不同类型交互的数据。这类信息通常被称为*用户-物品数据集*。第3章中描述了一个此类数据集的例子；在这里，讨论得到了扩展和细化。图5.3突出了在推荐过程中从用户-物品数据集中创建二分图的过程。
- en: '![CH05_F03_Negro](../Images/CH05_F03_Negro.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F03_Negro](../Images/CH05_F03_Negro.png)'
- en: Figure 5.3 Bipartite graph creation in the recommendation process
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3推荐过程中的二分图创建
- en: Table 5.1 shows an example dataset. The items are books that different users
    have bought.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1展示了示例数据集。物品是不同用户购买的书。
- en: Table 5.1 Example User-Item dataset for the e-commerce scenario
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1电子商务场景的示例用户-物品数据集
- en: '|  | Fluent Python | Machine Learning: A Probabilistic Perspective | Graph
    Analysis and Visualization | Bayesian Reasoning | Fraud Analytics | Deep Learning
    |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | Fluent Python | Machine Learning: A Probabilistic Perspective | Graph
    Analysis and Visualization | Bayesian Reasoning | Fraud Analytics | Deep Learning
    |'
- en: '| **User A** | 1 | 1 | 1 | 1 | 1 | 1 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| **用户A** | 1 | 1 | 1 | 1 | 1 | 1 |'
- en: '| **User B** | 0 | 1 | 0 | 0 | 0 | 1 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| **用户B** | 0 | 1 | 0 | 0 | 0 | 1 |'
- en: '| **User C** | 1 | 0 | 0 | 0 | 0 | 0 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| **用户C** | 1 | 0 | 0 | 0 | 0 | 0 |'
- en: '| **User D** | 0 | 1 | 0 | 1 | 0 | 1 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| **用户D** | 0 | 1 | 0 | 1 | 0 | 1 |'
- en: 'This table contains data on only one type of interaction: purchases. In different
    scenarios, including the e-commerce site, several types of interactions are available
    (views, clicks, ratings, and so on) and can be used in the recommendation process.
    *Multimodal* recommender systems [da Costa and Manzato, 2014] combine multiple
    interaction types to provide recommendations. One of the best approaches is to
    create an isolated recommender system for each interaction type and then combine
    the interactions in a hybrid recommender. Because the focus here is on data modeling
    and algorithms for collaborative filtering, we will focus on a single type, but
    the extension to more is straightforward and is discussed in section 7.2.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此表只包含关于一种类型交互的数据：购买。在不同的场景中，包括电子商务网站，有多种类型的交互可用（查看、点击、评分等），并且可以在推荐过程中使用。*多模态*推荐系统[da
    Costa and Manzato, 2014]结合多种交互类型来提供推荐。其中最好的方法之一是为每种交互类型创建一个独立的推荐系统，然后将这些交互在混合推荐系统中结合。因为这里的重点是协同过滤的数据建模和算法，我们将关注单一类型，但扩展到更多类型的讨论将在第7.2节中展开。
- en: 'The User-Item dataset (which in real life will be much bigger than the sample
    shown here) represents the input of the recommendation process in the collaborative
    filter. This initial data is easy to obtain. Here are a few examples:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 用户-物品数据集（在现实生活中将比这里展示的样本大得多）代表了协同过滤中推荐过程的输入。这些初始数据很容易获得。以下是一些例子：
- en: Online merchants keep records of which customers bought which products and sometimes
    of whether they liked those products.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线商家会记录哪些客户购买了哪些产品，有时还会记录他们是否喜欢这些产品。
- en: Supermarket chains usually keep purchase records for their regular customers
    by using reward cards.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超市连锁店通常通过使用奖励卡来记录其常客的购买记录。
- en: People’s preferences for things, such as for certain products sold by a retailer,
    can be represented as graphs in recommendation networks [Newman, 2010] and used
    in recommender systems. The fundamental and most common representation of a recommendation
    network is a bipartite graph or bigraph. We looked at these graphs in chapter
    3\. Figure 5.4 shows a simple, generic bipartite graph in which the nodes are
    type U or V.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 人们对于某些零售商销售的产品等事物的偏好可以用推荐网络中的图来表示[Newman, 2010]，并在推荐系统中使用。推荐网络的基本和最常见表示是二分图或双图。我们在第3章中讨论了这些图。图5.4展示了一个简单的、通用的二分图，其中节点是类型U或V。
- en: '![CH05_F04_Negro](../Images/CH05_F04_Negro.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F04_Negro](../Images/CH05_F04_Negro.png)'
- en: Figure 5.4 A generic bipartite graph
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 一个通用的二分图
- en: Let’s apply this simple concept to our scenario and to recommendation systems
    that use a collaborative filtering approach. In recommendation networks, one vertex
    type represents products (or items in general), and the other type represents
    users. Edges connect users to the items they interact with (buy or like, for example).
    It is also possible to represent strengths or weights on the edges to indicate
    how often a person has bought an item or how much they like it [Newman, 2010].
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个简单的概念应用到我们的场景中，以及使用协同过滤方法的推荐系统中。在推荐网络中，一种顶点类型代表产品（或一般的项目），另一种类型代表用户。边连接用户与他们互动的项目（例如购买或喜欢）。也可以在边上表示强度或权重，以指示一个人购买某个项目的频率或他们有多喜欢它
    [Newman, 2010]。
- en: Using this model, it is possible to convert the User-Item dataset in a bipartite
    graph. From our simple dataset for the e-commerce site in table 5.1, it is possible
    to create the graph in figure 5.5.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个模型，可以将二分图中的用户-项目数据集转换。从我们表 5.1 中的简单电子商务网站数据集，可以创建图 5.5 中的图。
- en: '![CH05_F05_Negro](../Images/CH05_F05_Negro.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F05_Negro](../Images/CH05_F05_Negro.png)'
- en: Figure 5.5 A bipartite graph representing table 5.1
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 表示表 5.1 的二分图
- en: Although a bipartite graph can represent an entire recommendation network, it
    is often convenient and useful to work with direct connections between vertices
    of only one type. From a bipartite graph, it is possible to infer connections
    between nodes of the same type, creating a one-mode projection. Two projections
    can be generated for each bipartite graph. The first projection connects the U
    nodes (users), and the second connects V nodes (books). Figure 5.6 shows the two
    projections computed from the bipartite graph in figure 5.5.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管二分图可以表示整个推荐网络，但通常处理仅一种类型顶点之间的直接连接既方便又有用。从一个二分图中，可以推断出相同类型节点之间的连接，创建一个单模式投影。对于每个二分图可以生成两个投影。第一个投影连接
    U 节点（用户），第二个连接 V 节点（书籍）。图 5.6 显示了从图 5.5 中的二分图计算出的两个投影。
- en: '![CH05_F06_Negro](../Images/CH05_F06_Negro.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F06_Negro](../Images/CH05_F06_Negro.png)'
- en: Figure 5.6 The two possible projections of the graph in figure 5.5
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 图 5.5 中的图的两个可能的投影
- en: The projections of the bipartite graph show the relationships among users who
    made the same purchases, even only one, and relationships between books that were
    purchased by the same users, even only one. This one-mode projection is often
    useful and widely employed, but its construction hides a lot of information from
    the original bipartite graph, so in a sense it is less powerful in terms of representation.
    In the case of items and users, it doesn’t show how many users purchased both
    of the two items. To solve this problem, it is possible to add a property to the
    relationships whose value captures this information, making such projection weighted.
    This projection is a co-occurrence network (described in chapter 3) whose source
    is the bipartite graph. In a User-Item matrix, two items are connected in the
    V-mode projection if they co-occur in at least one user’s preferences.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 二分图的投影显示了做出相同购买的用户之间的关系，即使只有一次，以及被相同用户购买的书籍之间的关系，即使只有一次。这种单模式投影通常很有用且被广泛采用，但它的构建隐藏了原始二分图中的大量信息，因此在表示方面在某种程度上较弱。在项目和用户的情况下，它没有显示有多少用户购买了这两件商品。为了解决这个问题，可以在关系上添加一个属性，其值捕获这些信息，使这种投影加权。这种投影是一个共现网络（在第
    3 章中描述），其来源是二分图。在用户-项目矩阵中，如果两个项目至少在一个用户的偏好中同时出现，它们在 V 模式投影中连接。
- en: The projections—weighted and unweighted—of a bipartite graph represent data
    in a way that allows us to perform some analysis more easily than with the original
    format. Therefore, projections are commonly used in recommendation systems [Grujic´,
    2008]. Often, graph clustering analysis (discussed in part 3) is performed on
    these networks to reveal groups of items that are generally purchased together
    or, in the other projection, to identify customer segments based on preferences
    for some specific set of items. Projections are also powerful visualization techniques
    that can reveal patterns that are difficult to discover or identify in the original
    format.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 双边图的加权和无权投影以一种方式表示数据，这使得我们比使用原始格式更容易进行某些分析。因此，投影在推荐系统中被广泛使用 [Grujic´, 2008]。通常，在这些网络上执行图聚类分析（在第3部分讨论），以揭示通常一起购买的项目组，或者在另一个投影中，根据对某些特定项目集合的偏好来识别客户细分。投影也是强大的可视化技术，可以揭示在原始格式中难以发现或识别的模式。
- en: To recap, the advantages of a graph model, and specifically a bipartite graph
    representation, of the User-Item dataset are
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，用户-项目数据集的图模型，特别是双边图表示，的优势是
- en: It represents the data in a compact and intuitive way. The User-Item dataset
    is sparse by nature; generally, it has a lot of users and a lot of items, and
    users interact with a small portion of the items available. A matrix representing
    such interactions would contain a huge number of zeros and few useful values.
    The graph contains only relationships that represent meaningful information.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它以紧凑直观的方式表示数据。用户-项目数据集在本质上稀疏；通常，它有大量的用户和大量的项目，而用户只与可用项目的一小部分进行交互。表示这种交互的矩阵将包含大量的零和很少的有用值。图只包含表示有意义信息的关联。
- en: Projections derived from the bipartite graph are information rich and allow
    different types of analyses, both graphical (after visualization) and via algorithms
    (an example is graph clustering). Analyses such as customer segmentation and item
    clustering can provide valuable support to the classical recommendation algorithms
    discussed in this section.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从双边图派生出的投影信息丰富，允许进行不同类型的分析，包括图形分析（在可视化后）和通过算法（例如图聚类）。如客户细分和项目聚类等分析可以为本节讨论的经典推荐算法提供有价值的支持。
- en: The representation can be extended by modeling multiple bipartite graphs that
    have the same set of vertices but use different edges. This extension helps us
    represent data used as input to a multimodal recommendation engine. These engines
    use multiple types of interactions to provide better recommendations.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过建模具有相同顶点集但使用不同边的多个双边图来扩展表示。这种扩展有助于我们表示作为多模态推荐引擎输入的数据。这些引擎使用多种类型的交互来提供更好的推荐。
- en: As discussed in section 5.3, when the nearest neighbor network is computed,
    it can be stored, sharing the user and item nodes of the bipartite graph. This
    approach simplifies the recommendation phase by providing access to a single data
    structure that contains both user preferences and the nearest neighbors network.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如第5.3节所述，当计算最近邻网络时，它可以存储，共享双边图的用户和项目节点。这种方法通过提供一个包含用户偏好和最近邻网络的单个数据结构来简化推荐阶段。
- en: Now that you understand the graph model describing the User-Item dataset, let’s
    get practical and create a real database. The following listing, which is similar
    to the one used for the content-based scenario, imports data from the Retail Rocket[⁴](#pgfId-1009218)
    dataset ([https://retailrocket.net](https://retailrocket.net)), converting the
    User-Item matrix to a bipartite graph.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了描述用户-项目数据集的图模型，让我们来实际操作，创建一个真实的数据库。以下列表，类似于用于基于内容场景的列表，从Retail Rocket[⁴](#pgfId-1009218)数据集([https://retailrocket.net](https://retailrocket.net))导入数据，将用户-项目矩阵转换为双边图。
- en: Listing 5.1 Code for importing User-Item dataset
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.1 导入用户-项目数据集的代码
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Creates the constraints to prevent duplicates. Each user and item must be
    unique
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建约束以防止重复。每个用户和项目必须是唯一的
- en: ❷ The query uses MERGE to create users or items when they don’t exist. The CREATE
    for the PURCHASES relationship stores one relationship for each purchase.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 查询使用MERGE在用户或项目不存在时创建它们。存储购买关系的CREATE存储每个购买的关联。
- en: ❸ The dataset has multiple event types (view, add to cart, and so on). We consider
    here only completed transactions or actual purchases.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 数据集包含多种事件类型（查看、添加到购物车等）。我们在这里只考虑完成的交易或实际购买。
- en: 'At the end of the import, which should take a few seconds, it is possible to
    run the following query and visualize a portion of the graph:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 导入完成后，这可能需要几秒钟，可以运行以下查询并可视化图形的一部分：
- en: '[PRE1]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The graph created from the bipartite model represents the entry point of the
    next phase, as described in the mental model of the process in figure 5.2\. Section
    5.3 describes how to compute and store the nearest neighbor network.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从二分模型创建的图代表下一阶段的入口点，如图5.2中的过程心理模型所述。第5.3节描述了如何计算和存储最近邻网络。
- en: Exercises
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: 'With the newly created database, run queries to do the following:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用新创建的数据库，运行查询以执行以下操作：
- en: Find the best sellers (the items with the highest number of purchases).
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找最佳卖家（购买次数最多的项目）。
- en: Find the best buyers (the users with the highest number of purchases).
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找最佳买家（购买次数最多的用户）。
- en: Find recurrent buys (items purchased more than one time by the same user).
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找重复购买（同一用户购买多次的项目）。
- en: 5.3 Computing the nearest neighbor network
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 计算最近邻网络
- en: The next task in the recommendation process is computing similarities between
    elements—users or items or both—and constructing the nearest neighbor network.
    Figure 5.7 highlights the creation of the nearest neighbor network as enrichment
    of the bipartite graph in the recommendation process.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐过程中的下一个任务是计算元素之间的相似性——用户或项目或两者——并构建最近邻网络。图5.7突出了在推荐过程中构建最近邻网络作为二分图的丰富化。
- en: '![CH05_F07_Negro](../Images/CH05_F07_Negro.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F07_Negro](../Images/CH05_F07_Negro.png)'
- en: Figure 5.7 Computing the nearest neighbor network in the recommendation process
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7在推荐过程中计算最近邻网络
- en: 'As described earlier, there are two possible approaches to memory-based recommendation
    for collaborative filtering:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，基于内存的协同过滤推荐有两种可能的方法：
- en: '*Item-based*—The similarities are computed between items based on the users
    who interact with them (rating, buying, clicking, and so on).'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于项目*——相似性是基于与项目交互的用户计算的。'
- en: '*User-based*—The similarities are computed between users based on the list
    of items they interact with.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于用户*——相似性是基于用户与之交互的项目列表计算的。'
- en: 'It is important to note that unlike in the content-based case, with the neighborhood
    methods, the information used for computing the similarities is related only to
    the interactions available in the User-Item dataset. Each item and each user can
    be identified only by an ID (or a node without any relevant properties different
    from the identifier). This approach has the advantage that the model can be created
    with no details available for items and users. Nonetheless, the procedure for
    the similarity computation is the same as that for the content-based approach:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的一点是，与基于内容的案例不同，在邻域方法中，用于计算相似性的信息仅与用户-项目数据集中可用的交互有关。每个项目和每个用户只能通过ID（或一个没有任何相关属性与标识符不同的节点）来识别。这种方法的优势在于，即使没有关于项目和用户的详细信息，也可以创建模型。尽管如此，相似性计算的程序与基于内容的相同：
- en: Identify/select a similarity function that allows you to compute distances between
    homogeneous elements in the graph (among users or items, for example).
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别/选择一个允许您计算图中同质元素之间距离的相似性函数（例如，用户或项目）。
- en: Represent each element in a way that’s suitable for the selected similarity
    function.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以适合所选相似性函数的方式表示每个元素。
- en: Compute similarities, and store them in the graph.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算相似性，并将它们存储在图中。
- en: The graph model, with its great flexibility, allows us to easily extract various
    representations for either users or items when the function is chosen. For the
    sake of simplicity and because it is the best suited to our example scenario,
    we’ll again use the cosine similarity.[⁵](#pgfId-1009235) The difference is in
    how to extract the vectors in the vector space model (VSM) required for the computation.
    Consider a simple bipartite graph that models a reduced version of a bigger User-Item
    dataset, as shown in figure 5.8.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图模型具有极大的灵活性，使我们能够轻松地提取用户或项目在各种函数选择下的各种表示。为了简单起见，并且因为它最适合我们的示例场景，我们再次使用余弦相似度。[⁵](#pgfId-1009235)
    不同之处在于如何在向量空间模型（VSM）中提取用于计算的向量。考虑一个简单的二分图，它表示一个更大的用户-项目数据集的简化版本，如图5.8所示。
- en: '![CH05_F08_Negro](../Images/CH05_F08_Negro.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F08_Negro](../Images/CH05_F08_Negro.png)'
- en: Figure 5.8 A bipartite graph representing a scaled-down User-Item dataset
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8表示缩小的用户-项目数据集的二分图
- en: Depending on the similarity we have to compute—among users or among items—it
    is possible to extract two vector representations from this graph. The vector
    creation process in this scenario is essentially the same as in the content-based
    approach. In that case, a vector is created for each item, considering the set
    of available features possibly describing it. In this case, for each item we consider
    the set of users who are interested in it, taking into account the items the users
    liked in the past. The following tables show how this task is accomplished. Depending
    on the similarity we have to compute—among users or among items—it is possible
    to extract two vector representations from this graph. The vector creation process
    in this scenario is essentially the same as in the content-based approach. In
    that case, a vector is created for each item, considering the set of available
    features possibly describing it. In this case, for each item we consider the set
    of users who are interested in it, taking into account the items the users liked
    in the past. Tables 5.2 and 5.3 show how this task is accomplished.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们需要计算的相似度（用户之间的或项目之间的），可以从这个图中提取出两种向量表示。在这种情况下，向量创建过程与基于内容的近似方法基本相同。在那个例子中，为每个项目创建一个向量，考虑可能描述它的特征集。在这个例子中，对于每个项目，我们考虑对它感兴趣的用户集，同时考虑用户过去喜欢的项目。以下表格显示了如何完成这项任务。根据我们需要计算的相似度（用户之间的或项目之间的），可以从这个图中提取出两种向量表示。在这种情况下，向量创建过程与基于内容的近似方法基本相同。在这个例子中，对于每个项目，我们考虑对它感兴趣的用户集，同时考虑用户过去喜欢的项目。表5.2和5.3显示了如何完成这项任务。
- en: Table 5.2 User vectors table from the graph in figure 5.8
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.2 图5.8中的用户向量表
- en: '|  | Fluent Python | Machine Learning: A Probabilistic Perspective | Graph
    Analysis and Visualization | Bayesian Reasoning | Fraud Analytics | Deep Learning
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|  | 流畅的Python | 概率视角下的机器学习 | 图分析及可视化 | 贝叶斯推理 | 欺诈分析 | 深度学习 |'
- en: '| **User A** | 1 | 1 | 1 | 1 | 1 | 1 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| **用户A** | 1 | 1 | 1 | 1 | 1 | 1 |'
- en: '| **User B** | 0 | 1 | 0 | 0 | 0 | 1 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| **用户B** | 0 | 1 | 0 | 0 | 0 | 1 |'
- en: '| **User C** | 1 | 0 | 0 | 0 | 0 | 0 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| **用户C** | 1 | 0 | 0 | 0 | 0 | 0 |'
- en: '| **User D** | 0 | 1 | 0 | 1 | 0 | 1 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| **用户D** | 0 | 1 | 0 | 1 | 0 | 1 |'
- en: 'In table 5.2, each row is a user, and each column represents an item (a book).
    The column order during vector creation must always be the same; otherwise, two
    vectors cannot be compared. In this example, the vectors are binary or Boolean:
    we are not considering the *value* of the relationships between users and items,
    only the fact that they exist. Such a value could model the rating the user assigned
    to a book, the number of times the user clicked a product, and so on, and it is
    represented as a property of the relationship in the graph model. Migrating to
    a nonbinary representation requires replacing the 1 with the actual value of the
    weight of the relationship between the user and the item.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在表5.2中，每一行代表一个用户，每一列代表一个项目（一本书）。在向量创建过程中，列的顺序必须始终相同；否则，两个向量无法比较。在这个例子中，向量是二进制或布尔型的：我们不是考虑用户和项目之间关系的*值*，只是它们存在的事实。这样的值可以模拟用户分配给书籍的评分、用户点击产品的次数等等，并在图模型中作为关系的属性表示。迁移到非二进制表示需要将1替换为用户和项目之间关系的实际权重值。
- en: In section 4.1, we saw that it is possible to mix binary values with real (integer,
    float, and double) values in the same vector construction. This approach is useful
    when we would like to create a vector for each item that represents more relationship
    types, as in the multimodal recommendation. This case is not considered here for
    the sake of simplicity.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在4.1节中，我们看到了在相同的向量构造中混合二进制值与实数（整数、浮点数和双精度浮点数）是可能的。当我们需要为每个项目创建一个表示更多关系类型的向量时，这种方法很有用，例如在多模态推荐中。为了简化，这里没有考虑这种情况。
- en: 'From table 5.2, we can extract the following compressed representation of the
    users in the VSM:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 从表5.2中，我们可以提取出VSM中用户的以下压缩表示：
- en: '*Vector(User A)* = [1, 1, 1, 1, 1, 1]'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量(用户A)* = [1, 1, 1, 1, 1, 1]'
- en: '*Vector(User B)* = [0, 1, 0, 0, 0, 1]'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量(用户B)* = [0, 1, 0, 0, 0, 1]'
- en: '*Vector(User C)* = [1, 0, 0, 0, 0, 0]'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量(用户C)* = [1, 0, 0, 0, 0, 0]'
- en: '*Vector(User D)* = [0, 1, 0, 1, 0, 1]'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量(用户D)* = [0, 1, 0, 1, 0, 1]'
- en: Table 5.3 shows the item vectors.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.3显示了项目向量。
- en: Table 5.3 Item vectors table
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.3 项目向量表
- en: '|  | User A | User B | User C | User D |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  | 用户A | 用户B | 用户C | 用户D |'
- en: '| Fluent Python | 1 | 0 | 1 | 0 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 流畅的Python | 1 | 0 | 1 | 0 |'
- en: '| Machine Learning: A Probabilistic Perspective | 1 | 1 | 0 | 1 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 概率视角下的机器学习 | 1 | 1 | 0 | 1 |'
- en: '| Graph Analysis and Visualization | 1 | 0 | 0 | 0 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 图分析与可视化 | 1 | 0 | 0 | 0 |'
- en: '| Bayesian Reasoning | 1 | 0 | 0 | 1 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 贝叶斯推理 | 1 | 0 | 0 | 1 |'
- en: '| Fraud Analytics | 1 | 0 | 0 | 0 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 欺诈分析 | 1 | 0 | 0 | 0 |'
- en: '| Deep Learning | 1 | 1 | 0 | 1 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 深度学习 | 1 | 1 | 0 | 1 |'
- en: 'This table takes the same approach to items. In this case, each row is an item,
    and each column represents a different user. The column order is important here,
    too. The resulting vector representation looks like this:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 此表采用与项目相同的方法。在这种情况下，每一行是一个项目，每一列代表不同的用户。在这里，列的顺序也很重要。结果向量表示看起来像这样：
- en: '*Vector(Fluent Python)* = [1, 0, 1, 0]'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量（流畅的Python）* = [1, 0, 1, 0]'
- en: '*Vector(Machine Learning)* = [1, 1, 0, 1]'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量（机器学习）* = [1, 1, 0, 1]'
- en: '*Vector(Graph Analysis)* = [1, 0, 0, 0]'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量（图分析）* = [1, 0, 0, 0]'
- en: '*Vector(Bayesian Reasoning)* = [1, 0, 0, 1]'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量（贝叶斯推理）* = [1, 0, 0, 1]'
- en: '*Vector(Fraud Analytics)* = [1, 0, 0, 0]'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量（欺诈分析）* = [1, 0, 0, 0]'
- en: '*Vector(Deep Learning)* = [1, 1, 0, 1]'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*向量（深度学习）* = [1, 1, 0, 1]'
- en: Those vectors, in both cases, can be extracted easily from the graph database
    by using a query. This example shows again that graphs not only are an appropriate
    data representation model for keeping complex data in a format that is easy to
    access and navigate, but also offer the flexibility to export data in a format
    that can suit different learning processes. A similar model can feed both a content-based
    approach and a neighborhood approach, and these approaches can even coexist in
    the same graph. And we are only beginning to uncover the power of graphs!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，都可以通过查询轻松地从图数据库中提取这些向量。这个例子再次表明，图不仅是一个适当的数据表示模型，可以以易于访问和导航的格式保持复杂数据，而且还提供了灵活性，可以以适合不同学习过程的数据格式导出数据。类似的模型可以同时为基于内容和邻域的方法提供数据，而且这些方法甚至可以在同一图中共存。而我们只是刚开始揭示图的力量！
- en: Before we examine the vector query itself, let’s take a quick look at some considerations
    that can help you obtain a significant boost in the way that data is extracted
    and processed. Representing vectors in a memory-efficient way and accessing their
    values efficiently are important machine learning tasks. The best approach to
    vector representation varies according to the nature of the vector and how it
    will be used. In the content-based scenario, vector creation for items relies
    on a small number of possible vector dimensions. The sparseness or denseness of
    a vector’s data is the most important consideration. Figure 5.9 shows examples
    of each type of vector.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们检查向量查询本身之前，让我们快速看一下一些可以帮助您在数据提取和处理方式上获得显著提升的考虑因素。以内存高效的方式表示向量和有效地访问它们的值是重要的机器学习任务。向量表示的最佳方法根据向量的性质及其使用方式而有所不同。在基于内容的场景中，项目向量的创建依赖于少量可能的向量维度。向量的稀疏性或密集性是最重要的考虑因素。图5.9显示了每种类型向量的示例。
- en: '![CH05_F09_Negro](../Images/CH05_F09_Negro.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F09_Negro](../Images/CH05_F09_Negro.png)'
- en: Figure 5.9 Example of dense and sparse vectors (with random values)
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9 密集和稀疏向量的示例（带有随机值）
- en: If you recall our discussion of vector creation for movies based on predefined
    features, the number of possible features was relatively limited. Considering
    all possible actors and directors together with all genres and so on, the number
    of features will be no more than 10,000 or 20,000\. The same is true of using
    text to create the vectors. In that case, the size of the vector is defined by
    the language vocabulary or the number of words in the language that are used.
    Although the number of nonzero values is small compared with the vector’s dimensionality,
    overall, the vector is small.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得我们关于基于预定义特征创建电影向量的讨论，可能的特征数量相对有限。考虑到所有可能的演员和导演以及所有类型等，特征的数量不会超过10,000或20,000。使用文本创建向量也是如此。在这种情况下，向量的尺寸由语言词汇量或语言中使用的单词数量定义。尽管与向量的维度性相比非零值的数量较小，但总体而言，向量是小的。
- en: 'A vector with relatively many nonzero values in relationship to its size is
    called *dense*. Such a vector can be represented by an implementation that stores
    values in an array of doubles or floats. Vector indices correspond directly to
    array indices. A dense vector’s advantage is speed: being array-backed, it’s quick
    to access and update any of its values.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 与其大小相比，具有相对较多非零值的向量被称为*密集向量*。这样的向量可以通过存储在双精度浮点数组中的实现来表示。向量索引直接对应于数组索引。密集向量的优势在于速度：由于是数组支持的，因此快速访问和更新其任何值。
- en: At the other end of the spectrum, a typical e-commerce site contains more than
    1 million items and (ideally for them) a number of users of the same order of
    magnitude. Each user, even one who has a compulsive e-shopping disorder (as I
    do for books) can buy only a small portion of the overall possible items. On the
    other side of the coin, each item—even a best seller—is purchased by a relatively
    small number of users, so the total number of nonzero values in the respective
    vectors will always be small. This type of vector, in which the total percentage
    of nonzero values is small, is called a *sparse vector*. Representing sparse vectors
    with an array is not only a waste of memory, but also makes any computation expensive.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在光谱的另一端，一个典型的电子商务网站包含超过100万件商品，并且（对他们来说理想的情况）有数量相同级别的用户。每个用户，即使是患有强迫性在线购物症候群的用户（像我一样对书籍），也只能购买整体可能商品的一小部分。另一方面，每个商品——即使是畅销书——也只被相对较少的用户购买，因此相应向量中的非零值总数始终很小。这种总非零值百分比小的向量被称为*稀疏向量*。使用数组表示稀疏向量不仅浪费内存，而且使任何计算都变得昂贵。
- en: It is possible to represent a sparse vector in different ways to optimize memory
    and simplify manipulation. In Java, some of the most common methods are available
    in Apache Mahout,[⁶](#pgfId-1009268) a distributed linear algebra framework used
    for creating scalable performant machine learning applications. For the similarity
    computation, I use a different representation for sparse vectors that still uses
    an array of floats or doubles as the basic data structure. The structure of my
    preferred implementation of a sparse vector is described in figure 5.10.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 可以用不同的方式表示稀疏向量以优化内存并简化操作。在Java中，Apache Mahout提供了一些最常见的方法，[⁶](#pgfId-1009268)是一个用于创建可扩展高性能机器学习应用的分布式线性代数框架。对于相似度计算，我使用了一种不同的稀疏向量表示方法，该方法仍然使用浮点数或双精度浮点数数组作为基本数据结构。我首选的稀疏向量实现结构在图5.10中描述。
- en: '![CH05_F10_Negro](../Images/CH05_F10_Negro.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F10_Negro](../Images/CH05_F10_Negro.png)'
- en: Figure 5.10 A sparse vector representation
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.10 稀疏向量表示
- en: Figure 5.10 shows how a sparse vector can be represented in a compact format.
    The first element contains the number of nonzero values in the original array.
    We will define it as N. The second part, which starts from position 1 (remember
    that the vector indexing starts at 0) and ends at position N, contains the indices
    of the nonzero values. The last part, which starts at N + 1 and continues to the
    end of the vector, contains the actual values.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.10展示了稀疏向量如何以紧凑的格式表示。第一个元素包含原始数组中非零值的数量。我们将它定义为N。第二部分，从位置1开始（记住向量的索引从0开始）到位置N结束，包含非零值的索引。最后一部分，从N+1开始，一直延续到向量的末尾，包含实际的值。
- en: Such a representation has the advantage that with a single small array, it is
    possible to represent a long and complex sparse vector. This array requires minimal
    memory and can be stored easily as a property of nodes. This advantage is a big
    one when you have to process a lot of data. My personal Java implementation is
    available in the code repository in the ch05/java directory.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这种表示方法的优势在于，使用单个小型数组，可以表示一个长而复杂的稀疏向量。这个数组需要的内存最小，并且可以轻松地作为节点的属性存储。当你需要处理大量数据时，这种优势是非常大的。我的个人Java实现可以在代码仓库的ch05/java目录中找到。
- en: To keep this chapter aligned with the rest, listing 5.2 contains the representation
    of a sparse vector in Python. In this programming language, a sparse vector can
    be represented as a dictionary in which the key is the position of the element
    in the vector, and the value is the effective element value. In this case, the
    number of nonzero elements is the size of the dictionary, making the representation
    simple enough. The relative code can be found in the code repository in the util/sparse_vector.py
    file.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使本章内容保持一致，列表5.2包含了Python中稀疏向量的表示。在这种编程语言中，稀疏向量可以表示为一个字典，其中键是向量中元素的索引，值是有效的元素值。在这种情况下，非零元素的数量是字典的大小，使得表示足够简单。相关的代码可以在代码仓库的util/sparse_vector.py文件中找到。
- en: Listing 5.2 Sparse vector implementation in Python
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.2 Python中的稀疏向量实现
- en: '[PRE2]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Function that creates a dict (sparse vector) from a vector
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从向量创建字典（稀疏向量）的函数
- en: ❷ Loops through the vector, taking the position and the value
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 遍历向量，获取位置和值
- en: ❸ Checks that the value is not null or 0
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 检查值是否不为空或0
- en: There is no real threshold you should consider for using a sparse rather than
    a dense vector. Generally, I prefer using sparse vectors because they optimize
    similarity computation. In most of the examples from now on in this book, we will
    use sparse vectors.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用稀疏向量而不是密集向量，没有真正的阈值需要考虑。通常，我更喜欢使用稀疏向量，因为它们优化了相似度计算。从现在起，本书中的大多数示例都将使用稀疏向量。
- en: Now we have all the elements required for extracting the user and item vectors
    and computing similarities between them. The queries for extracting the nonzero
    elements of each vector for users and items are shown in the next two listings.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了提取用户和项目向量以及计算它们之间相似度所需的所有元素。提取用户和项目每个向量非零元素的查询在接下来的两个列表中显示。
- en: Note In these queries, we are using the node ID as an index, but any integer
    or long value could work. We could use any numeric ID identifying the items, for
    example, such as itemId.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在这些查询中，我们使用节点ID作为索引，但任何整数或长值都可以工作。我们可以使用任何识别项目的数字ID，例如，如itemId。
- en: Listing 5.3 Query for extracting a sparse vector for a user
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.3 查询提取用户稀疏向量
- en: '[PRE3]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Listing 5.4 Query for extracting a sparse vector for an item
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.4 查询提取项目稀疏向量
- en: '[PRE4]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the MATCH clauses, the relationship PURCHASES is used to find all the items
    a user purchased or all the users who bought an item. The RETURN clause extracts
    the nonzero elements of the resulting vector. Because no value indicates the weight
    of the relationship, a binary approach is used, so by default, 1 is assigned to
    each value.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MATCH 子句中，使用 PURCHASES 关系找到用户购买的所有项目或购买项目的所有用户。RETURN 子句提取结果向量的非零元素。因为没有值表示关系的权重，所以使用二进制方法，默认情况下，每个值分配为
    1。
- en: EXERCISE
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: Change the preceding queries to use itemId and userId instead of the node ID.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 将前面的查询更改为使用 itemId 和 userId 而不是节点 ID。
- en: Hint Consider that the queries are stored as strings even though they are integers,
    and remember that we need a numeric value for the index.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：考虑到查询存储为字符串，尽管它们是整数，并且记住我们需要一个数值作为索引。
- en: 'The next step is computing and storing the similarities. For each user or item,
    we have to do the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是计算和存储相似度。对于每个用户或项目，我们必须执行以下操作：
- en: 'Compute the similarities with all the other elements (homogeneously: each user
    with other users and each item with other items).'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算与其他所有元素（均匀地：每个用户与其他用户以及每个项目与其他项目）的相似度。
- en: Order the similarities in a descending order.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按降序排列相似度。
- en: Keep only the top k, where the value of k is predefined. Alternatively, fix
    a threshold or minimum similarity value, and keep only the similarities above
    it.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅保留前 k 个，其中 k 的值是预定义的。或者，设置一个阈值或最小相似度值，并仅保留高于该值的相似度。
- en: Store the top k similar elements in the graph as new relationships between users
    or items.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将前 k 个相似元素存储在图中作为用户或项目之间的新关系。
- en: Figure 5.11 explodes the “Compute nearest neighbor” block of the recommendation
    process, summarizing the preceding sequence of steps.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 展示了推荐过程中的“计算最近邻”块，总结了前面的步骤序列。
- en: '![CH05_F11_Negro](../Images/CH05_F11_Negro.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F11_Negro](../Images/CH05_F11_Negro.png)'
- en: Figure 5.11 Detail on computing nearest neighbor
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 计算最近邻的细节
- en: The following listing shows the Python implementation for this task, using a
    sparse vector representation. The code is available in the ch05/recommendation/collaborative_
    filtering/recommender.py file.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了此任务的 Python 实现，使用稀疏向量表示。代码位于 ch05/recommendation/collaborative_filtering/recommender.py
    文件中。
- en: Listing 5.5 Similarity computation
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.5 相似度计算
- en: '[PRE5]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '❶ Setting some variables for user-based similarity: the labels of the nodes
    and the attribute with the element id. The variables for the items are in the
    code repository.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为基于用户的相似度设置一些变量：节点的标签和具有元素id的属性。项目的变量在代码库中。
- en: ❷ Query to extract the user purchases as a vector. The first element in each
    row returned is the itemId; the second is fixed to 1 because we are interested
    only in the purchase event, not in a rate or how many times the user bought the
    item. See listing 5.3.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 查询提取用户购买作为向量。每行返回的第一个元素是itemId；第二个固定为1，因为我们只对购买事件感兴趣，而不是比率或用户购买项目的次数。参见列表
    5.3。
- en: ❸ Entry-point function to compute and store the similarities for all users.
    Changing the variables, you’ll get the same result for the items.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算并存储所有用户相似度的入口点函数。更改变量，您将得到相同的项目结果。
- en: ❹ Loops over the dictionary with the sparse vectors for all the users, computes
    all the similarities, keeps only the k highest values for each node, and calls
    the function to store the k-NN
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 遍历所有用户的稀疏向量字典，计算所有相似性，为每个节点保留 k 个最高值，并调用存储 k-NN 的函数
- en: ❺ Function that creates a dictionary in which the key is the userId and the
    value is the user’s sparse vector
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 创建一个字典的函数，其中键是 userId，值是用户的稀疏向量
- en: ❻ Function that returns the list of elements’ (Users or Items) IDs by querying
    the database
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 通过查询数据库返回元素（用户或物品）ID 的列表的函数
- en: ❼ Function that returns for the specified user (or item) the related sparse
    vector by querying to the graph database
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 通过查询图数据库返回指定用户（或物品）的相关稀疏向量的函数
- en: ❽ Function that stores the k-NN in the database
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 将 k-NN 存储到数据库中的函数
- en: ❾ Query to delete all the similarities of the node
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 查询以删除节点的所有相似性
- en: ❿ Query to store in one shot all the similarities
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ❿ 一次性存储所有相似性的查询
- en: As is evident from the preceding code, the similarity computation requires N
    × N computations to be performed, where N is |U| or |V|. This operation may take
    a while when N is big.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码所示，相似度计算需要执行 N × N 次计算，其中 N 是 |U| 或 |V|。当 N 较大时，此操作可能需要一段时间。
- en: Figure 5.12 shows what the resulting graph model looks like when the relationships
    are stored in the graph. Because the graph is small, the k value is set to 2.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 显示了当关系存储在图中时，结果图模型的外观。因为图较小，所以 k 值设置为 2。
- en: '![CH05_F12_Negro](../Images/CH05_F12_Negro.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F12_Negro](../Images/CH05_F12_Negro.png)'
- en: Figure 5.12 Final graph model for the collaborative filtering
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 协同过滤的最终图模型
- en: 'The graph in figure 5.12 is not a bipartite graph anymore, because there now
    exist relationships among elements in the same partition. But we can have multiple
    subgraphs of the same graph by considering only a subset of nodes and relationships,
    so the graph can be split into three highly relevant subgraphs:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 中的图不再是二分图，因为现在存在同一分区中元素之间的关系。但我们可以通过仅考虑节点和关系的子集来拥有同一图的多个子图，因此可以将图分为三个高度相关的子图：
- en: The subgraph with both U and I (U represents all the users, and I represents
    all the items) as nodes and only the PURCHASES relationships is the bipartite
    graph we had before.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以 U 和 I（U 代表所有用户，I 代表所有物品）为节点，并且只有购买关系的子图是我们之前提到的二分图。
- en: The subgraph with U as nodes and SIMILARITY as the relationship is the nearest
    neighbor network for U (the k-NN for U).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以 U 为节点和相似性为关系的子图是 U 的最近邻网络（U 的 k-NN）。
- en: The subgraph with I as nodes and SIMILARITY as the relationship is the nearest
    neighbor network for I (the k-NN for I).
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以 I 为节点和相似性为关系的子图是 I 的最近邻网络（I 的 k-NN）。
- en: 'In section 5.4, these graphs are used as input for the last task, providing
    recommendations, but it is important to notice that these graphs already contain
    a lot of information. The process distills new knowledge from the bipartite graph
    and stores it back in a way that can serve various purposes in addition to recommendations:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在 5.4 节中，这些图被用作最后任务的输入，提供推荐，但重要的是要注意，这些图已经包含了很多信息。这个过程从二分图中提炼出新的知识，并以可以服务于除推荐之外多种目的的方式存储它。
- en: '*Clustering items*—By applying some graph clustering algorithms on the items’
    nearest neighbor network, it is possible to recognize (for example) groups of
    products that are generally bought together or movies that are watched by the
    same group of users.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*物品聚类*—通过在物品的最近邻网络上应用一些图聚类算法，可以识别（例如）通常一起购买的产品组或被同一组用户观看的电影。'
- en: '*Segmenting users*—The same clustering algorithms can be applied on the users’
    nearest neighbor network, and the result will be a group (*segment*) of users
    who generally buy the same products or see the same movies.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用户分割*—相同的聚类算法可以应用于用户的最近邻网络，结果将是一个用户组（*分割*），他们通常购买相同的产品或观看相同的电影。'
- en: '*Finding similar products*—The items’ nearest neighbor network itself is useful.
    If a user is looking at a specific product, by querying the graph it is possible
    to show a list of similar products based on the SIMILARITY relationship, and this
    operation will be fast.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*寻找相似产品*—物品的最近邻网络本身很有用。如果一个用户正在查看特定的产品，通过查询图，可以基于相似性关系显示一系列相似产品，并且这个操作将会很快。'
- en: The graph approach not only allows us to mix information by storing it in a
    flexible data structure, but also provides various opportunities for us to access
    data, reveal patterns, extract knowledge, and perform analysis in a homogeneous
    data environment.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图形方法不仅允许我们通过将信息存储在灵活的数据结构中来混合信息，而且还为我们提供了各种访问数据、揭示模式、提取知识和在统一数据环境中进行分析的机会。
- en: Modeling pro tip
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 建模技巧
- en: This section and the equivalent one in chapter 4 describe techniques for converting
    different types of data to graphs. Such techniques are generally referred to as
    *graph construction techniques*. In the content-based case, the data is defined
    by metadata and contents, such as actors, genres, and even the plots of movies,
    whereas in the collaborative filtering case, the data is the User-Item matrix.
    In both cases, a similarity function and a proper data conversion to a vector
    space model allow us to create a graph that imparts greater knowledge and has
    greater communication power than the original version of the data.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 本节和第4章中相应的部分描述了将不同类型的数据转换为图的技术。这些技术通常被称为*图构建技术*。在基于内容的情况下，数据由元数据和内容定义，例如演员、类型，甚至是电影的情节，而在协同过滤的情况下，数据是用户-物品矩阵。在这两种情况下，一个相似度函数和适当的数据转换为向量空间模型使我们能够创建一个比原始数据版本具有更多知识和更强沟通能力的图。
- en: In many areas of machine learning, graphs are used to model local relationships
    between data elements and to build global structures from local information [Silva
    and Zhao, 2016]. Building graphs is sometimes necessary for dealing with problems
    arising from applications in machine learning or data mining, and at other times,
    it's helpful for managing data. It's important to note that the transformation
    from the original data to a graph data representation can always be performed
    in a lossless manner. The opposite is not always true. For these reasons, the
    techniques and use cases described here represent concrete examples of how to
    perform these graph conversions; these examples may be of use not only in the
    scenarios described, but also in a lot of real use cases. Play with the data you
    have, and try to convert it to a graph.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习的许多领域，图被用来模拟数据元素之间的局部关系，并从局部信息构建全局结构 [Silva and Zhao, 2016]。构建图有时是处理机器学习或数据挖掘应用中产生的问题所必需的，而在其他时候，它有助于管理数据。重要的是要注意，从原始数据到图数据表示的转换始终可以以无损的方式进行。反之则不然。因此，这里描述的技术和用例代表了如何执行这些图转换的具体示例；这些示例不仅适用于所描述的场景，而且也适用于许多实际用例。玩转你拥有的数据，并尝试将其转换为图。
- en: So far, we’ve been using cosine similarity as a basic function for computing
    similarities. Other metrics have been proposed—such as adjusted cosine similarity,
    Spearman’s rank correlation coefficient, mean squared difference, and the Pearson
    coefficient—and are commonly used as alternatives to this function. Specifically,
    the Pearson coefficient outperforms other measures for user-based recommendations
    [Herlocker et al., 1999], whereas cosine similarity is the best for item-based
    recommendations.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直使用余弦相似度作为计算相似性的基本函数。已经提出了其他度量标准——例如调整后的余弦相似度、斯皮尔曼秩相关系数、均方差异和皮尔逊系数——并且通常作为该函数的替代方案。具体来说，皮尔逊系数在基于用户的推荐中优于其他度量
    [Herlocker et al., 1999]，而余弦相似度在基于物品的推荐中表现最佳。
- en: In this part of the book, the focus is on data modeling, so cosine similarity
    is the reference function. Later in the book, other solutions are described when
    their use is appropriate.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的这一部分，重点是数据建模，因此余弦相似度是参考函数。在本书的后面部分，当适用时，将描述其他解决方案。
- en: Exercises
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: 'Query the graph obtained by running the code that computes similarity to find
    the following:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 查询通过运行计算相似度的代码获得的图，以找到以下内容：
- en: Given an item, the list of similar items
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一个物品，相似物品列表
- en: Given a user, the list of similar users
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一个用户，相似用户列表
- en: The highest value of similarity (search the database to understand why)
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相似度的最高值（搜索数据库以了解原因）
- en: 5.4 Providing recommendations
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 提供推荐
- en: The final task of the recommendation process is to provide a list of suggestions
    to users whenever this list is necessary or valuable. Figure 5.13 highlights the
    recommendations provision of the recommendation process.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐过程的最终任务是，在必要时或有价值时，向用户提供建议列表。图5.13突出了推荐过程中的推荐提供。
- en: '![CH05_F13_Negro](../Images/CH05_F13_Negro.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F13_Negro](../Images/CH05_F13_Negro.png)'
- en: Figure 5.13 Last step in the recommendation process
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13 推荐过程的最后一步
- en: 'In our scenario, while the user is navigating the e-commerce site, in some
    boxes we would like to provide recommendations that are customized for that user.
    At a high level, the recommendation process produces the following types of output:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的场景中，当用户在电子商务网站上导航时，我们希望在某些框中提供针对该用户的定制化推荐。从高层次来看，推荐过程会产生以下类型的输出：
- en: '*Relevance scores*—Numerical predictions indicating the degree to which the
    current user likes or dislikes a certain item.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*相关性分数*——数值预测，表示当前用户对某个项目的喜好或厌恶程度。'
- en: '*Recommendations*—A list of N recommended items. Such a top-N list should not,
    of course, contain items that the current user has already bought unless the purchases
    can be recurring purchases.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*推荐*——一个包含N个推荐项目的列表。当然，这样的前N个列表不应包含当前用户已经购买的项目，除非这些购买是重复购买。'
- en: In the neighborhood approach to collaborative filtering, the first output—relevance
    scores—can be produced by looking at the user’s nearest neighbors (the user-based
    approach) network or the item’s nearest neighbors (the item-based approach) network.
    Let’s take a closer look at these two approaches.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在协同过滤的邻域方法中，第一个输出——相关性分数——可以通过查看用户的最近邻网络（基于用户的方法）或项目的最近邻网络（基于项目的方法）来产生。让我们更详细地看看这两种方法。
- en: The basic idea in the user-based approach is that given the current user as
    input, the bipartite graph representing the interaction database, and the nearest
    neighbors network, for every product p that the user has not seen or bought, a
    prediction is computed based on the ratings for p made by the peer users (the
    users in that user’s nearest neighbors network). Consider the diagram in figure
    5.14.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 基于用户的方法的基本思想是，给定当前用户作为输入，表示交互数据库的二元图和最近邻网络，对于用户尚未看到或购买的产品p，基于同行用户（该用户最近邻网络中的用户）对p的评分进行预测。考虑图5.14中的图。
- en: '![CH05_F14_Negro](../Images/CH05_F14_Negro.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F14_Negro](../Images/CH05_F14_Negro.png)'
- en: Figure 5.14 Collaborative filtering basic idea for user-based approach
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14 基于用户方法的协同过滤基本思想
- en: Alessandro bought the four products on the left. The idea of the user-based
    approach is to find similar users who also bought those products and then find
    other products they bought that Alessandro hasn’t bought yet. The underlying assumptions
    of such methods [Jannach, et al., 2010] are
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 亚历山德罗购买了左侧的四个产品。基于用户的方法的想法是找到也购买了这些产品的相似用户，然后找到他们购买但亚历山德罗尚未购买的其他产品。这类方法的潜在假设[Jannach,
    等人，2010]是
- en: If two users had similar tastes in the past, they will have similar tastes in
    the future.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果两个用户在过去有相似的味道，他们将来也会有相似的味道。
- en: Users’ preferences remain stable and consistent over time.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户的偏好随时间保持稳定和一致。
- en: Some methods mitigate such assumptions, but they are out of the scope of the
    scenario we are considering.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方法减轻了这些假设，但它们超出了我们考虑的场景的范围。
- en: Let’s convert the idea expressed in words and images to a formula that computers
    can understand. Two cases can occur. In one case, the interactions between users
    and items (clicks, purchases, and views) contain no weight. This case is called
    the *binary* or *Boolean* model. In the second case, there is a weight to the
    interactions (such as ratings). The formula for this case is
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将用文字和图像表达的想法转换为计算机可以理解的公式。可能有两种情况发生。在一种情况下，用户和项目之间的交互（点击、购买和查看）没有权重。这种情况称为*二元*或*布尔*模型。在第二种情况下，交互有权重（如评分）。这种情况的公式是
- en: '![CH05_F15_EQ01_Negro](../Images/CH05_F15_EQ01_Negro.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F15_EQ01_Negro](../Images/CH05_F15_EQ01_Negro.png)'
- en: This formula predicts the ratings that the user a would assign to the item p.
    KNN(a) represents the k-nearest neighbors of the user a, and r[b,p] represents
    the rating assigned by the user b to the product p. This rating can be 0 if user
    b doesn’t rate item p. Some variations of this formula exist, but they are out
    of the scope of this chapter.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式预测用户a会对项目p分配的评分。KNN(a)代表用户a的k个最近邻，r[b,p]代表用户b对产品p分配的评分。如果用户b没有对项目p进行评分，则该评分可以是0。这个公式的某些变体存在，但它们超出了本章的范围。
- en: 'The Boolean case is a little trickier, because in the literature, no single
    method is recognized as the best approach. The following formula [Sarwar et al.,
    2000] seems to me to be one of the most reasonable and is widely applied on e-commerce
    sites:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 布尔情况稍微复杂一些，因为在文献中，没有一种方法被公认为最佳方法。以下公式 [Sarwar et al., 2000] 在我看来是最合理的一个，并且在电子商务网站上得到了广泛应用：
- en: '![CH05_F15_EQ02_Negro](../Images/CH05_F15_EQ02_Negro.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F15_EQ02_Negro](../Images/CH05_F15_EQ02_Negro.png)'
- en: Here, r[b,p] will be 1 if the user b purchased the product p and 0 otherwise,
    so the sum will return how many of the nearest neighbors of a bought the product
    p. This value is normalized with the number of nearest neighbors for a (the value
    of |KNN(a)|).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，如果用户b购买了产品p，则r[b,p]将为1，否则为0，因此求和将返回有多少最近邻购买了产品p。这个值将用a的最近邻数量（|KNN(a)|的值）进行归一化。
- en: The following listing contains an example implementation in Python that uses
    the nearest neighbor network created previously. The code is available in the
    ch05/ recommendation/collaborative_filtering/recommender.py file.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表包含了一个使用之前创建的最近邻网络的Python示例实现。代码位于ch05/recommendation/collaborative_filtering/recommender.py文件中。
- en: Listing 5.6 Providing recommendations through a user-based approach
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.6 通过基于用户的方法提供推荐
- en: '[PRE6]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Query for scoring items based on similarity among users
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 基于用户之间相似性对项目评分的查询
- en: ❷ Function that provides the recommendations
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 提供推荐的函数
- en: ❸ Function that provides the list of not-yet-seen (in this case, not-yet-bought)
    items
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 提供尚未查看（在本例中为尚未购买）项目列表的函数
- en: ❹ Function that predicts the score of an item for a user by using a simple query.
    The query has been specified in the variable.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 通过使用简单查询预测用户对项目的评分的函数。查询已在变量中指定。
- en: Although user-based approaches have been applied successfully in different domains,
    some serious challenges remain when it comes to large e-commerce sites, where
    it is necessary to handle millions of users and millions of catalog items. In
    particular, due to the necessity of scanning a vast number of potential neighbors,
    it is practically impossible to compute predictions in real time, even using a
    graph approach. Large-scale e-commerce sites, therefore, often use different techniques.
    Item-based recommendations are among these techniques because they allow for the
    computation of recommendations in real time even for a large rating matrix [Sarwar
    et al., 2001].
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于用户的方法在不同领域已经成功应用，但当涉及到需要处理数百万用户和数百万目录项目的大型电子商务网站时，仍然存在一些严重的挑战。特别是，由于需要扫描大量潜在邻居，即使使用图方法，实际上也无法实时计算预测。因此，大型电子商务网站通常使用不同的技术。基于项目的推荐是这些技术之一，因为它们允许在大型评分矩阵中对推荐进行实时计算
    [Sarwar et al., 2001]。
- en: The main idea of item-based algorithms is to compute predictions by using the
    similarity between items, not users. Let’s examine a concrete example to make
    this idea clearer. Consider the graph database in figure 5.15, and suppose that
    we need to make a prediction of user Alessandro’s rating for Item 5.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 基于项目的算法的主要思想是通过使用项目之间的相似性来计算预测，而不是用户。让我们通过一个具体的例子来使这个想法更清晰。考虑图5.15中的图数据库，并假设我们需要预测用户Alessandro对项目5的评分。
- en: '![CH05_F15_Negro](../Images/CH05_F15_Negro.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F15_Negro](../Images/CH05_F15_Negro.png)'
- en: Figure 5.15 Collaborative filtering basic idea for item-based approach
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15 基于项目的协同过滤基本思想
- en: First, we compare the rating vectors of the other items and look for items that
    have ratings similar to Item 5 (that is, are similar to Item 5). In the example,
    we see that the ratings for Item 5 [3, 5, 4, 1, 0] are similar to the ratings
    for Item 1 [3, 4, 3, 1, 5] (two are the same, two are off by 1, and the 0 occurs
    because Alessandro did not rate Item 5), and there is a partial similarity with
    Item 4 [3, 3, 5, 2, 4] (one is the same, and three are off by 1). The idea of
    item-based recommendations is to look at Alessandro’s ratings for these similar
    items. He gave a 5 to Item 1 and a 4 to Item 4\. An item-based algorithm computes
    a weighted average of these other ratings and predicts a rating for Item 5 somewhere
    between 4 and 5.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们比较其他项目的评分向量，寻找与项目5评分相似的项（即与项目5相似）。在示例中，我们看到项目5的评分[3, 5, 4, 1, 0]与项目1的评分[3,
    4, 3, 1, 5]相似（两个相同，两个相差1，0是因为Alessandro没有对项目5进行评分），并且与项目4[3, 3, 5, 2, 4]有部分相似性（一个相同，三个相差1）。基于项目的推荐想法是查看Alessandro对这些相似项目的评分。他给项目1评了5分，给项目4评了4分。基于项目的算法计算这些其他评分的加权平均值，并预测项目5的评分在4到5之间。
- en: 'Again, to convert these words to a concrete formula to feed to a computer program,
    we need to consider both use cases: with an explicit rating and with a simple
    Boolean value that says whether the user interacted with the item (purchasing
    it, clicking it, and so on). In the case of Boolean values, the goal is not to
    predict a rating (as in 0-5, for example) but to predict the extent to which Item
    5 will be of interest to Alessandro in a range from 0 to 1 (0 = not of interest,
    1 = most likely of interest).'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，为了将这些词转换成具体的公式以供计算机程序使用，我们需要考虑两种用例：带有显式评分和带有简单布尔值，表示用户是否与项目互动（购买、点击等）。在布尔值的情况下，目标不是预测评分（例如0-5），而是预测项目5对Alessandro的兴趣程度，范围从0到1（0
    = 不感兴趣，1 = 最有可能感兴趣）。
- en: If the original User-Item dataset contains rating values, the formula to predict
    the rating for a not-yet-seen product in the dataset [Sarwar et al., 2001] is
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 如果原始用户-项目数据集包含评分值，预测数据集中尚未看到的产品的评分的公式是 [Sarwar et al., 2001]。
- en: '![CH05_F16_EQ03_Negro](../Images/CH05_F16_EQ03_Negro.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F16_EQ03_Negro](../Images/CH05_F16_EQ03_Negro.png)'
- en: This formula can be rewritten in different forms according to how you decide
    to navigate the data. In our case,
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式可以根据你决定如何导航数据来重写为不同的形式。在我们的情况下，
- en: q ∈ ratedItem(a) considers all the products rated by user a.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: q ∈ ratedItem(a) 考虑用户a评过的所有产品。
- en: 'For each q, it multiplies three values:'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个q，它乘以三个值：
- en: The similarity between q and the target product p.
  id: totrans-237
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: q与目标产品p之间的相似性。
- en: The rating assigned by the user to q.
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户对q的评分。
- en: '|KNN(q) ∩ {p}|, which is 1 if p is in the set of nearest neighbors of q and
    0 otherwise. It is possible to consider only the nearest neighbors of q and not
    all the similarities.'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '|KNN(q) ∩ {p}|，如果p是q的最近邻集合中的元素，则为1，否则为0。可以考虑只考虑q的最近邻，而不是所有相似性。'
- en: The denominator normalizes the value to not exceed the max value of the rating.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分母将值标准化，使其不超过评分的最大值。
- en: Consider the data in figure 5.15\. The similarities among all the three items
    are
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑图5.15中的数据。这三个项目之间的相似性是
- en: 'Item 1-Item 4: 0.943'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目1-项目4：0.943
- en: 'Item 1-Item 5: 0.759'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目1-项目5：0.759
- en: 'Item 4-Item 5: 0.811'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目4-项目5：0.811
- en: Because there are only three items, we consider all the similarities in the
    nearest neighbor; hence, for us |KNN(q) ∩ {p}| is always 1\. The user Alessandro
    rated Item 1 with 5 stars and Item 4 with 4 stars. The formula for predicting
    Alessandro’s interest/ stars for Item 5 is
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 因为只有三个项目，所以我们考虑了最近邻中的所有相似性；因此，对于我们来说 |KNN(q) ∩ {p}| 总是 1。用户Alessandro给项目1评了5星，给项目4评了4星。预测Alessandro对项目5的兴趣/评分的公式是
- en: '![CH05_F16_EQ04_Negro](../Images/CH05_F16_EQ04_Negro.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F16_EQ04_Negro](../Images/CH05_F16_EQ04_Negro.png)'
- en: 'As with the user-based approach, for the Boolean case there is no accepted
    standard approach for computing the scores, so I’ll present one of my favorites
    [Deshpande and Karypis, 2004]:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于用户的方法一样，对于布尔情况，没有接受的标准方法来计算分数，所以我将展示我最喜欢的其中一种 [Deshpande and Karypis, 2004]：
- en: '![CH05_F16_EQ05_Negro](../Images/CH05_F16_EQ05_Negro.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F16_EQ05_Negro](../Images/CH05_F16_EQ05_Negro.png)'
- en: In this case, we have no ratings, so the formula is simpler. Furthermore, it
    doesn’t return a prediction, but a generic score. Such a score can be normalized
    in different ways to facilitate comparisons.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们没有评分，所以公式更简单。此外，它不返回预测，而是一个通用的分数。这样的分数可以通过不同的方式归一化，以方便比较。
- en: The following listing presents an example implementation of the item-based version
    of the neighborhood approach. The code is available in the ch05/recommendation/
    collaborative_filtering/recommender.py file.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了基于物品的邻域方法的示例实现。代码位于ch05/recommendation/collaborative_filtering/recommender.py文件中。
- en: Listing 5.7 Providing recommendations by using a item-based approach
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.7 使用基于物品的方法提供推荐
- en: '[PRE7]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ The only required change from listing 5.6 is the score_query parameter. Here,
    the value is computed by considering the similarities among the previous user’s
    purchases and the target items.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从列表5.6中唯一需要更改的是score_query参数。在这里，该值是通过考虑先前用户购买与目标物品之间的相似性来计算的。
- en: Exercise
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 练习
- en: Run the code in the preceding listing (which is available in the book’s code
    repository), changing the users and observing how the list of recommendations
    changes. Then use a query to check the graph database and see whether the suggested
    items are in line with previous items bought by a user.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面列表中的代码（可在本书的代码仓库中找到），更改用户并观察推荐列表如何变化。然后使用查询检查图数据库，看看建议的物品是否与用户之前购买的物品一致。
- en: 5.5 Dealing with the cold-start problem
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.5 处理冷启动问题
- en: 'Before I close this chapter on collaborative filtering, it is important to
    discuss a problem that affects collaborative filtering recommender systems: data
    sparsity. In real-world e-commerce applications, User-Item matrices tend to be
    sparse, as customers typically have bought (or have provided ratings for) only
    a small fraction of the products in the catalog. The problem is even worse for
    new users or new items that have had no or few interactions. This problem is referred
    to as the cold-start problem, and it further illustrates the importance of addressing
    the issue of data sparsity.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在我结束关于协同过滤的这一章之前，讨论一个问题对于影响协同过滤推荐系统非常重要：数据稀疏性。在现实世界的电子商务应用中，用户-物品矩阵往往很稀疏，因为客户通常只购买了目录中很小一部分的产品（或为产品提供了评分）。对于没有或很少互动的新用户或新物品，这个问题更为严重。这个问题被称为冷启动问题，它进一步说明了解决数据稀疏性问题的重要性。
- en: In general, the challenge related to the cold-start problem is to compute good
    predictions when relatively little information is available. One straightforward
    option for dealing with this problem is to exploit additional information about
    the users, such as gender, age, education, interests, or any other available data
    that can help classify a user. Other approaches exist, such as creating hybrid
    recommender systems that merge multiple approaches in a single prediction mechanism
    (chapter 7).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，与冷启动问题相关的挑战是在相对较少的信息可用时计算良好的预测。处理这个问题的直接选择之一是利用关于用户的额外信息，例如性别、年龄、教育、兴趣或任何其他可以帮助分类用户的数据。其他方法也存在，例如创建混合推荐系统，将多种方法合并到单个预测机制中（第7章）。
- en: These approaches are no longer purely collaborative, and new questions arise
    as to how to acquire the additional information and combine the different classifiers.
    Nevertheless, to reach the critical mass of users needed in a collaborative approach,
    such techniques might be helpful in the ramp-up phase of a newly installed recommendation
    service.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法不再是纯粹的合作式，关于如何获取额外信息以及如何结合不同分类器的新问题也随之产生。尽管如此，为了达到合作方法所需的临界用户数量，这些技术在新的推荐服务启动阶段可能有所帮助。
- en: Among the various approaches proposed over the years, a graph-based approach
    [Huang et al., 2004] explores transitive associations (similarities) among consumers
    through past transactions and feedback. The main idea of this approach is to exploit
    the supposed transitivity of customer tastes when they share items. Users’ preferences
    are represented by the items and their interactions with the items.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中提出的各种方法中，基于图的方法 [Huang et al., 2004] 通过过去的交易和反馈探索消费者之间的传递性关联（相似性）。这种方法的主要思想是利用当消费者共享物品时客户口味假设的传递性。用户的偏好由物品及其与物品的互动来表示。
- en: The following example illustrates the idea of exploring transitive associations
    in recommender systems. Suppose that we have a simple User-Item dataset like the
    one in table 5.4.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例说明了在推荐系统中探索传递性关联的想法。假设我们有一个类似于表5.4中的简单用户-物品数据集。
- en: Table 5.4 A sample User-Item dataset
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.4 用户-物品数据集样本
- en: '|  | Item 1 | Item 2 | Item 3 | Item 4 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '|  | 物品1 | 物品2 | 物品3 | 物品4 |'
- en: '| **User 1** | 0 | 1 | 0 | 1 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| **用户1** | 0 | 1 | 0 | 1 |'
- en: '| **User 2** | 0 | 1 | 1 | 1 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| **用户2** | 0 | 1 | 1 | 1 |'
- en: '| **User 3** | 1 | 0 | 1 | 0 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| **用户3** | 1 | 0 | 1 | 0 |'
- en: At this point in the book, you should be able to easily represent this table
    as a bipartite graph. The result should look like figure 5.16.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 到这本书的这一部分，你应该能够轻松地将这个表格表示为二分图。结果应该看起来像图5.16。
- en: '![CH05_F16_Negro](../Images/CH05_F16_Negro.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F16_Negro](../Images/CH05_F16_Negro.png)'
- en: Figure 5.16 Graph representation of the User-Item dataset in table 5.4
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.16 表5.4中用户-项目数据集的图表示
- en: The proposed method uses this representation method to solve the data sparsity
    problem. Moreover, a weight can be assigned to each edge, such as the value of
    its corresponding rating.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的方法使用这种表示方法来解决数据稀疏性问题。此外，可以给每条边分配一个权重，例如其对应评分的值。
- en: Suppose that the recommender system needs to recommend items for User 1\. When
    we use a standard collaborative filtering approach, User 2 will be considered
    to be a peer of User 1 because both users bought Item 2 and Item 4\. Item 3 will
    be recommended to User 1 because that user’s nearest neighbor, User 2, also bought
    or liked it. No strong similarity can be found between User 1 and User 3.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 假设推荐系统需要为用户1推荐项目。当我们使用标准的协同过滤方法时，用户2将被视为用户1的同伴，因为这两个用户都购买了项目2和项目4。由于用户2也是用户1最近的邻居，并且也购买了或喜欢了项目3，因此项目3将被推荐给用户1。在用户1和用户3之间找不到强烈的相似性。
- en: In the transitive associations method, the recommendation approach can be easily
    implemented in a graph-based model by computing the associations between item
    nodes and user nodes. The recommendations are determined by determining paths
    between users and items. Standard collaborative filtering approaches, including
    both the user-based and item-based approaches, consider only paths with length
    equal to 3\. (As a reminder, the path length is computed by considering the edges
    in the path.)
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在传递关联方法中，推荐方法可以通过计算项目节点和用户节点之间的关联，在基于图的模型中轻松实现。推荐是由确定用户和项目之间的路径来确定的。标准的协同过滤方法，包括基于用户和基于项目的两种方法，只考虑长度等于3的路径。（作为提醒，路径长度是通过考虑路径中的边来计算的。）
- en: 'Consider our small example. In the bipartite graph in figure 5.16, the association
    between User 1 and Item 3 is determined by all paths of length 3 connecting User
    1 and Item 3\. It is easy to see from the diagram that two paths connect User
    1 and Item 3: User 1-Item 2-User 2-Item 3 and User 1-Item 4-User 2-Item 3\. Figure
    5.17 highlights all paths of length 3 in the graph from figure 5.16.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑我们的小例子。在图5.16中的二分图中，用户1和项目3之间的关联由所有长度为3的连接用户1和项目3的路径确定。从图中很容易看出，有两条路径连接用户1和项目3：用户1-项目2-用户2-项目3和用户1-项目4-用户2-项目3。图5.17突出了图5.16中所有长度为3的路径。
- en: '![CH05_F17_Negro](../Images/CH05_F17_Negro.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F17_Negro](../Images/CH05_F17_Negro.png)'
- en: Figure 5.17 Paths of length 3 between User 1 and Item 3
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.17 用户1和项目3之间的长度为3的路径
- en: This strong association leads to the recommendation of Item 3 to User 1\. The
    higher the number of unique paths connecting an item node to a user node, the
    stronger the association is between those two nodes.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这种强烈的关联导致将项目3推荐给用户1。连接项目节点和用户节点的唯一路径数量越多，这两个节点之间的关联就越强。
- en: Because the number of such paths of length 3 is small in sparse rating databases,
    the idea is to also consider longer paths—the so-called *indirect associations*—to
    compute recommendations. Extending the preceding approach to explore and incorporate
    transitive associations is straightforward in a graph-based model.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 由于稀疏评分数据库中此类长度为3的路径数量很少，因此想法是也要考虑更长的路径——所谓的*间接关联*——来计算推荐。在基于图的模型中，将先前的方法扩展以探索和包含传递关联是直截了当的。
- en: 'By considering paths whose length exceeds 3, the model can explore transitive
    associations. Two paths of length 5 connect User 1 and Item 1, for example: User
    1-Item 2-User 2-Item 3-User 3-Item 1 and User 1-item 4-User 2-Item 3-User 3-Item
    1\. Figure 5.18 highlights all paths of length 5 in the graph from figure 5.16.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 通过考虑长度超过3的路径，模型可以探索传递关联。例如，有两条长度为5的路径连接用户1和项目1：用户1-项目2-用户2-项目3-用户3-项目1和用户1-项目4-用户2-项目3-用户3-项目1。图5.18突出了图5.16中所有长度为5的路径。
- en: '![CH05_F18_Negro](../Images/CH05_F18_Negro.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F18_Negro](../Images/CH05_F18_Negro.png)'
- en: Figure 5.18 Paths of length 5 between User 1 and Item 1
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.18 用户1和项目1之间的长度为5的路径
- en: Thus, Item 1 could be recommended to User 1 when transitive associations are
    taken into consideration in the recommendation.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在考虑传递关联时，可以将项目1推荐给用户1。
- en: Even with this approach, it is necessary to define a scoring mechanism to order
    the recommendations list. In this case, recommendations are made based on the
    associations computed for pairs of user nodes and item nodes. Given a user node
    User t and an item node Item j, the association between them, score(User t, Item
    j), is defined as the sum of the weights of all distinctive paths connecting User
    t and Item j.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 即使采用这种方法，也需要定义一个评分机制来对推荐列表进行排序。在这种情况下，推荐是基于用户节点和项目节点对之间的关联进行的。给定一个用户节点 User
    t 和一个项目节点 Item j，它们之间的关联，即 score(User t, Item j)，定义为连接 User t 和 Item j 的所有独特路径的权重之和。
- en: In this formula, only paths whose length is less than or equal to the maximum
    defined length M will be considered. The limit M is a parameter that the designer
    of the recommender system can control. It is worth noting that M has to be an
    odd number because transitive associations are represented in a bipartite graph.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，只有长度小于或等于最大定义长度 M 的路径将被考虑。限制 M 是推荐系统设计者可以控制的参数。值得注意的是，M 必须是奇数，因为传递性关联在二分图中表示。
- en: '![CH05_F18_Negro_EQ06](../Images/CH05_F18_Negro_EQ06.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![CH05_F18_Negro_EQ06](../Images/CH05_F18_Negro_EQ06.png)'
- en: In this formula, pathsBetween(user,item,M) returns all the paths between *user*
    and *item* of length x where x ≤ M. The weight of the path is computed as α^x,
    where α is a constant between 0 and 1, ensuring that longer paths have lesser
    impact.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，`pathsBetween(user,item,M)` 返回所有长度为 x 且 x ≤ M 的从 *用户* 到 *项目* 的路径。路径的权重计算为
    α^x，其中 α 是介于 0 和 1 之间的常数，确保较长的路径具有较小的影响。
- en: The particular value for α can be determined by the system designer based on
    the characteristics of the underlying application domain. In applications in which
    transitive associations can be a strong predictor of consumer interests, α should
    take a value close to 1, whereas in applications where transitive associations
    tend to convey little information, α should take a value close to 0.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: α 的特定值可以根据底层应用领域的特性由系统设计者确定。在那些传递性关联可以作为消费者兴趣强预测的应用中，α 应取接近 1 的值，而在传递性关联很少传达信息的应用中，α
    应取接近 0 的值。
- en: 'Let’s illustrate this computation by using the example shown in figure 5.16\.
    When M is set to 3 (as in standard collaborative filtering), score(User 1, Item
    3) = 0.5³ + 0.5³ = 0.25, and score(User 1, Item 1) = 0\. When M is 5, score(User
    1, Item 3) = 0.5³ +0.5³ = 0.25, and score(User 1, Item 1) = 0.5⁵ + 0.5⁵ = 0.0625\.
    For consumer User 1, the preceding score computation is repeated for all items
    in the dataset. As in the previous cases, the items are sorted in decreasing order
    by this score. Then the first k items (excluding the items that User 1 purchased
    in the past) of this sorted list are recommended to User 1\. This approach requires
    our attention for different reasons:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过图 5.16 中的示例来说明这个计算。当 M 设置为 3（如标准协同过滤中所示）时，score(User 1, Item 3) = 0.5³
    + 0.5³ = 0.25，而 score(User 1, Item 1) = 0。当 M 为 5 时，score(User 1, Item 3) = 0.5³
    + 0.5³ = 0.25，而 score(User 1, Item 1) = 0.5⁵ + 0.5⁵ = 0.0625。对于消费者 User 1，上述分数计算会针对数据集中的所有项目重复进行。与之前的案例一样，项目会根据这个分数按降序排序。然后，将排序列表中的前
    k 个项目（排除 User 1 过去购买的项目）推荐给 User 1。这种方法需要我们注意以下几个原因：
- en: It generates high-quality recommendations even when a small amount of information
    is available.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使信息量很少，它也能生成高质量的推荐。
- en: It uses the same User-Item dataset used so far in this chapter.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用本章迄今为止使用的相同的用户-项目数据集。
- en: It is purely graph-based, and it uses the same bipartite graph model discussed
    in our examples.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它纯粹基于图，并使用我们在示例中讨论的相同二分图模型。
- en: Moreover, a comparison with the standard user-based and item-based algorithms
    shows that the quality of the recommendations can be significantly improved by
    the proposed technique based on indirect relationships, in particular when the
    ratings matrix is sparse. Also, for new users, the algorithm leads to measurable
    performance increases compared with standard collaborative filtering techniques.
    When the rating matrix reaches a certain density, however, the quality of recommendations
    can decrease compared with standard algorithms.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，与标准基于用户和基于项目的算法进行比较表明，基于间接关系的建议技术可以显著提高推荐质量，特别是在评分矩阵稀疏的情况下。对于新用户，该算法与标准协同过滤技术相比，性能有可测量的提升。然而，当评分矩阵达到一定密度时，与标准算法相比，推荐质量可能会下降。
- en: The approach described in this section uses path-based similarity to compute
    the recommendations. Other graph-based approaches use more sophisticated graph
    algorithms.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中描述的方法使用基于路径的相似性来计算推荐。其他基于图的方案使用更复杂的图算法。
- en: 5.6 Advantages of the graph approach
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.6 图方法的优势
- en: 'This chapter focuses on the creation of a collaborative filtering recommendation
    engine using graphs and graph models. In particular, it explores the neighborhood
    approach, which is well suited to a graph representation and graph-based navigation
    of the data. The main aspects and advantages of the graph-based approach to collaborative
    filtering recommendation engines implemented with neighborhood methods are as
    follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点介绍了使用图和图模型创建协同过滤推荐引擎。特别是，它探讨了适合于图表示和基于图的数据导航的邻域方法。使用邻域方法实现的基于图的合作过滤推荐引擎的主要方面和优势如下：
- en: The User-Item dataset can easily be represented as a bipartite graph, in which
    the weight of each user-item pair is represented as an optional property of the
    relationship.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户-物品数据集可以很容易地表示为一个二分图，其中每个用户-物品对的权重被表示为关系的可选属性。
- en: The bipartite graph representation of the User-Item dataset not only has the
    advantage of allowing us to store only relevant information—avoiding wasting memory
    by storing useless zeros, as in the matrix representation—but also of speeding
    access during model creation by focusing only on the potentially relevant neighbors.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户-物品数据集的二分图表示不仅具有只存储相关信息的优势——避免像矩阵表示那样存储无用的零，从而节省内存，而且还能在创建模型时通过仅关注可能相关的邻居来加速访问。
- en: It is possible to extract several vector representations for both items and
    users from the same graph model.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从同一个图模型中提取物品和用户的几个向量表示是可能的。
- en: The resulting model, consisting of similarities among users or items or both,
    can be naturally represented as new relationships that connect users and items.
    The resulting new graphs are the nearest neighbor (k-NN) networks.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果模型，由用户或物品或两者的相似性组成，可以自然地表示为连接用户和物品的新关系。结果的新图是最近邻（k-NN）网络。
- en: The algorithm, based on similarity computation, for creating the k-NN networks
    represents one of the most powerful and most widely adopted techniques for graph
    construction. The resulting networks not only are easy to navigate during the
    recommendation process, but also contain new knowledge distilled from the existing
    User-Item dataset that can be used for analyzing the data from other perspectives,
    such as item clustering, customer segmentation, and so on.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于相似性计算的算法，用于创建k-NN网络，代表了图构建中最强大和最广泛采用的技术之一。结果的网络不仅在推荐过程中易于导航，而且包含从现有的用户-物品数据集中提取的新知识，可用于从其他角度分析数据，例如物品聚类、客户细分等。
- en: A widely adopted technique for solving the data sparsity issue and the cold-start
    problem is based on graph representation, navigation, and processing. Graph navigation
    methods (like the pathfinding example described earlier) and graph algorithms
    (such as PageRank) are applied to fill some gaps and create a denser representation
    of the User-Item dataset.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种广泛采用的技术，用于解决数据稀疏问题和冷启动问题，基于图表示、导航和处理。图导航方法（如前面描述的路径查找示例）和图算法（如PageRank）被应用于填补一些空白，并创建一个更密集的用户-物品数据集表示。
- en: Even in this scenario, it is possible to mix multiple recommendation algorithms
    in a single graph and combine the power of multiple approaches to providing recommendations.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使在这种情况下，也可以在单个图中混合多个推荐算法，并结合多种方法的力量来提供推荐。
- en: Summary
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This chapter continued our discussion of data modeling and, specifically, recommendations
    by introducing one of the most common techniques for implementing recommendation
    engines: the collaborative filtering approach.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 本章继续我们关于数据建模的讨论，特别是通过介绍实现推荐引擎最常见的技术之一：协同过滤方法。
- en: In this chapter, you learned
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了
- en: How to model a User-Item dataset in the form of a bipartite graph and how to
    project it into the two related graphs
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将用户-物品数据集以二分图的形式建模，以及如何将其投影到两个相关图中
- en: How to compute similarities among users and items by using only the information
    related to the user-item interactions, instead of static information about the
    users and items
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何仅使用与用户-物品交互相关的信息来计算用户和物品之间的相似性，而不是使用关于用户和物品的静态信息
- en: How to store such similarities in a k-NN model
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 k-NN 模型中存储这样的相似性
- en: How to use such similarities to provide a recommendation list to the user via
    both a user-based and an item-based approach and considering binary and nonbinary
    values
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用这样的相似性通过基于用户和基于物品的方法以及考虑二元和非二元值来向用户提供一个推荐列表
- en: What the advantages of having a sparse vector are, when to use it, and how to
    implement it
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀疏向量的优势是什么，何时使用它，以及如何实现它
- en: How to use graph-based techniques to solve the data sparsity problem and in
    particular the cold-start problem
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用基于图的技术来解决数据稀疏性问题，特别是冷启动问题
- en: References
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Bell et al., 2007] Bell, Yehuda Koren, and Chris Volinsky. “Modeling Relationships
    at Multiple Scales to Improve Accuracy of Large Recommender Systems.” *Proceedings
    of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data
    Mining* (2007): 95-104.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '[Bell 等人，2007] Bell, Yehuda Koren, 和 Chris Volinsky. “在多个尺度上建模关系以提高大型推荐系统的准确性。”
    *第 13 届 ACM SIGKDD 国际知识发现和数据挖掘会议论文集* (2007): 95-104.'
- en: '[Börner, 2010] Börner, Katy. *Atlas of Science: Visualizing What We Know*.
    Cambridge, MA: MIT Press, 2010.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '[Börner，2010] Börner, Katy. *科学图谱：可视化我们所知*. 剑桥，MA: MIT Press, 2010.'
- en: '[da Costa and Manzato, 2014] da Costa, Arthur F., and Marcelo Garcia Manzato.
    “Multimodal Interactions in Recommender Systems: An Ensembling Approach.” *Proceedings
    of the Brazilian Conference on Intelligent Systems* (2014): 67-72.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '[da Costa 和 Manzato，2014] da Costa, Arthur F., 和 Marcelo Garcia Manzato. “推荐系统中的多模态交互：一种集成方法。”
    *巴西智能系统会议论文集* (2014): 67-72.'
- en: '[Deshpande and Karypis, 2004] Deshpande, Mukund, and George Karypis. “Item-Based
    Top-*N* Recommendation Algorithms.” *ACM Transactions on Information Systems*
    22:1 (2004): 143-177\. DOI: [http://dx.doi.org/10.1145/963770.963776](http://dx.doi.org/10.1145/963770.963776).'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '[Deshpande 和 Karypis，2004] Deshpande, Mukund, 和 George Karypis. “基于物品的 Top-*N*
    推荐算法。” *ACM 信息系统交易* 22:1 (2004): 143-177\. DOI: [http://dx.doi.org/10.1145/963770.963776](http://dx.doi.org/10.1145/963770.963776).'
- en: '[Diestel, 2008] Diestel, Reinhard. *Graph Theory (Graduate Texts in Mathematics)*.
    5th ed. Berlin: Springer, 2008.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '[Diestel，2008] Diestel, Reinhard. *图论（研究生数学教材）*. 第 5 版. 柏林: Springer, 2008.'
- en: '[Go et al., 2007] Go, Kwang-Il Goh, Michael E. Cusick, David Valle, Barton
    Childs, Marc Vidal, and Albert-László Barabási. “The Human Disease Network.” *PNAS*
    104:21 (2007): 8685-8690\. DOI: [https://doi.org/10.1073/pnas.0701361104](https://doi.org/10.1073/pnas.0701361104).'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '[Go 等人，2007] Go, Kwang-Il Goh, Michael E. Cusick, David Valle, Barton Childs,
    Marc Vidal, 和 Albert-László Barabási. “人类疾病网络。” *PNAS* 104:21 (2007): 8685-8690\.
    DOI: [https://doi.org/10.1073/pnas.0701361104](https://doi.org/10.1073/pnas.0701361104).'
- en: '[Goldberg et al., 1992] Goldberg, David, David Nichols, Brian M. Oki, and Douglas
    Terry. “Using Collaborative Filtering to Weave an Information Tapestry.” *Communications
    of the ACM* 35:12 (1992): 61-70\. DOI: [http://doi.acm.org/10.1145/138859.138867](http://doi.acm.org/10.1145/138859.138867).'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '[Goldberg 等人，1992] Goldberg, David, David Nichols, Brian M. Oki, 和 Douglas
    Terry. “使用协同过滤编织信息锦缎。” *ACM 通讯* 35:12 (1992): 61-70\. DOI: [http://doi.acm.org/10.1145/138859.138867](http://doi.acm.org/10.1145/138859.138867).'
- en: '[Grujic´, 2008] Grujic´, Jelena. “Movies Recommendation Networks as Bipartite
    Graphs.” *Proceedings of the 8th International Conference on Computational Science,
    Part II* (2008): 576-583.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '[Grujic´，2008] Grujic´, Jelena. “电影推荐网络作为二部图。” *第 8 届国际计算科学会议（第二部分）论文集* (2008):
    576-583.'
- en: '[Herlocker et al., 1999] Herlocker, Joseph A. Konstan, Al Borchers, and John
    Riedl. “An Algorithmic Framework for Performing Collaborative Filtering. *Proceedings
    of the 22nd Annual International ACM SIGIR Conference on Research and Development
    in Information Retrieval* (1999): 230-237\. DOI: [http://dx.doi.org/10.1145/312624.312682](http://dx.doi.org/10.1145/312624.312682).'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '[Herlocker 等人，1999] Herlocker, Joseph A., Konstan, Loren G., Borchers, Al,
    和 Riedl, John. “执行协同过滤的算法框架。” *第 22 届国际 ACM SIGIR 信息检索研究与发展年度会议论文集* (1999): 230-237\.
    DOI: [http://dx.doi.org/10.1145/312624.312682](http://dx.doi.org/10.1145/312624.312682).'
- en: '[Herlocker et al., 2004] Herlocker, Joseph A. Konstan, Loren G. Terveen, and
    John T. Riedl. “Evaluating Collaborative Filtering Recommender Systems.” *ACM
    Transactions on Information Systems* 22:1 (2004): 5-53\. DOI: [http://dx.doi.org/10.1145/963770.963772](http://dx.doi.org/10.1145/963770.963772).'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '[Herlocker 等人，2004] Herlocker, Joseph A., Konstan, Loren G., Terveen, Loren
    G., 和 Riedl, John T. “评估协同过滤推荐系统。” *ACM 信息系统交易* 22:1 (2004): 5-53\. DOI: [http://dx.doi.org/10.1145/963770.963772](http://dx.doi.org/10.1145/963770.963772).'
- en: '[Huang et al., 2004] Huang, Zan, Hsinchun Chen, and Daniel Zeng. “Applying
    Associative Retrieval Techniques to Alleviate the Sparsity Problem in Collaborative
    Filtering.” *ACM Transactions on Information Systems* 22:1 (2004): 116-142\. DOI:
    [http://dx.doi.org/10.1145/ 963770.963775](http://dx.doi.org/10.1145/963770.963775).'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '[黄等，2004] 黄，赞，辛钦·陈，和丹尼尔·曾。“将关联检索技术应用于缓解协同过滤中的稀疏性问题。”*ACM信息系统交易* 22:1（2004年）：116-142页。DOI:
    [http://dx.doi.org/10.1145/963770.963775](http://dx.doi.org/10.1145/963770.963775).'
- en: '[Jannach, et al., 2010] Jannach, Dietmar, Markus Zanker, Alexander Felfernig,
    and Gerhard Friedrich. *Recommender Systems: An Introduction*. Cambridge, UK:
    Cambridge University Press, 2010\. DOI: [http://dx.doi.org/10.1017/CBO9780511763113](http://dx.doi.org/10.1017/CBO9780511763113).'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '[詹纳奇等，2010] 詹纳奇，迪特马尔，马克斯·赞克尔，亚历山大·费尔费尼格，和格尔哈德·弗里德里希。《推荐系统：导论》。剑桥，英国：剑桥大学出版社，2010年。DOI:
    [http://dx.doi.org/10.1017/CBO9780511763113](http://dx.doi.org/10.1017/CBO9780511763113).'
- en: '[Koren, 2008] Koren, Yehuda. “Factorization Meets the Neighborhood: A Multifaceted
    Collaborative Filtering Model.” *Proceedings of the 14th ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining* (2008): 426-434\. DOI: [https://doi.org/10.1145/
    1401890.1401944](https://doi.org/10.1145/1401890.1401944).'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '[科伦，2008] 科伦，耶胡达。“因子分解与邻域相遇：一个多角度的协同过滤模型。”*第十四届ACM SIGKDD国际知识发现和数据挖掘会议论文集*（2008年）：426-434页。DOI:
    [https://doi.org/10.1145/1401890.1401944](https://doi.org/10.1145/1401890.1401944).'
- en: '[Koren et al., 2009] Koren, Yehuda, Robert Bell, and Chris Volinsky. “Matrix
    Factorization Techniques for Recommender Systems.” *Computer* 42:8 (2009): 30-37\.
    DOI: [http://dx.doi .org/10.1109/MC.2009.263](http://dx.doi.org/10.1109/MC.2009.263).'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '[科伦等，2009] 科伦，耶胡达，罗伯特·贝尔，和克里斯·沃尔辛斯基。“推荐系统中的矩阵分解技术。”*计算机* 42:8（2009年）：30-37页。DOI:
    [http://dx.doi.org/10.1109/MC.2009.263](http://dx.doi.org/10.1109/MC.2009.263).'
- en: '[Newman, 2010] Newman, Mark. *Networks: An Introduction*. Oxford, UK: Oxford
    University Press, 2010.'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '[纽曼，2010] 纽曼，马克。《网络：导论》。牛津，英国：牛津大学出版社，2010年。'
- en: '[Ning et al., 2015] Ning, Xia, Christian Desrosiers, and George Karypis. “A
    Comprehensive Survey of Neighborhood-Based Recommendation Methods.” In *Recommender
    Systems Handbook*, edited by Francesco Ricci, Lior Rockach, and Bracha Shapira,
    37-76\. New York: Springer, 2015\. 37-76\. 2015\. DOI: [https://doi.org/10.1007/978-1-4899-7637-6](https://doi.org/10.1007/978-1-4899-7637-6).'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '[宁等，2015] 宁，夏，克里斯蒂安·德罗西耶，和乔治·卡里皮斯。“基于邻域的推荐方法综述。”见《推荐系统手册》，由弗朗西斯科·里奇，利奥尔·罗卡奇，和布拉查·沙皮拉编辑，第37-76页。纽约：斯普林格，2015年。DOI:
    [https://doi.org/10.1007/978-1-4899-7637-6](https://doi.org/10.1007/978-1-4899-7637-6).'
- en: '[Sarwar et al., 2000] Sarwar, Badrul, George Karypis, Joseph Konstan, and John
    Riedl. “Analysis of Recommendation Algorithms for E-commerce.” *Proceedings of
    the 2nd ACM Conference on Electronic Commerce* (2000): 158-167\. DOI= [http://dx.doi.org/10.1145/352871.352887](http://dx.doi.org/10.1145/352871.352887).'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '[萨瓦尔等，2000] 萨瓦尔，巴杜鲁，乔治·卡里皮斯，约瑟夫·康斯坦，和约翰·里德尔。“电子商务推荐算法分析。”*第二届ACM电子商务会议论文集*（2000年）：158-167页。DOI=
    [http://dx.doi.org/10.1145/352871.352887](http://dx.doi.org/10.1145/352871.352887).'
- en: '[Sarwar et al., 2001] Sarwar, Badrul, George Karypis, Joseph Konstan, and John
    Riedl. “Item-Based Collaborative Filtering Recommendation Algorithms.” *Proceedings
    of the 10th International World Wide Web Conference* (2001) 285-295\. DOI: [https://doi.org/10.1145/
    371920.372071](https://doi.org/10.1145/371920.372071).'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '[萨瓦尔等，2001] 萨瓦尔，巴杜鲁，乔治·卡里皮斯，约瑟夫·康斯坦，和约翰·里德尔。“基于物品的协同过滤推荐算法。”*第十届国际万维网会议论文集*（2001年）285-295页。DOI:
    [https://doi.org/10.1145/371920.372071](https://doi.org/10.1145/371920.372071).'
- en: '[Silva and Zhao, 2016] Silva, Thiago C., and Liang Zhao. *Machine Learning
    in Complex Networks*. New York: Springer, 2016.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '[席尔瓦和赵，2016] 席尔瓦，蒂亚戈·C，和李昂·赵。《复杂网络中的机器学习》。纽约：斯普林格，2016年。'
- en: '[Takács et al., 2007] Takács, Gábor, István Pilászy, Bottyán Németh, and Domonkos
    Tikk. “Major Components of the Gravity Recommendation System.” *SIGKDD Explorations
    Newsletter* 9:2 (2007): 80-83\. DOI: [https://doi.org/10.1145/1345448.1345466](https://doi.org/10.1145/1345448.1345466).'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[塔卡奇等，2007] 塔卡奇，加博尔，伊斯特万·皮拉斯齐，博蒂安·内梅特，和多米诺斯·蒂克。“重力推荐系统的主要组件。”*SIGKDD探索通讯* 9:2（2007年）：80-83页。DOI:
    [https://doi.org/10.1145/1345448.1345466](https://doi.org/10.1145/1345448.1345466).'
- en: '* * *'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.)Stochastic gradient descent is an optimization technique common in machine
    learning. It tries to minimize the objective function (specifically, a differentiable
    objective function) via an iterative method. It is called *stochastic* because
    samples are selected randomly (or shuffled) instead of as a single group (as in
    standard gradient descent) or in the order in which they appear in the training
    set. In collaborative filtering, it is used during matrix factorization.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: ^（1.）随机梯度下降是机器学习中常见的优化技术。它试图通过迭代方法最小化目标函数（具体来说，是一个可微分的目标函数）。它被称为*随机*，因为样本是随机选择（或打乱顺序）的，而不是作为一个单一组（如标准梯度下降）或按照它们在训练集中出现的顺序。在协同过滤中，它用于矩阵分解。
- en: ^(2.)Alternating least squares is another optimization technique that has the
    advantage of being parallelized easily.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: ^（2.）交替最小二乘法是另一种易于并行化的优化技术。
- en: ^(3.)You may face these types of issues in real projects. The problem of content
    curation is common on e-commerce sites, and I’ve seen it in a lot of the projects
    I’ve followed.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: ^（3.）在实际项目中，你可能会遇到这些类型的问题。内容策划问题在电子商务网站上很常见，我在很多我跟踪的项目中都见过这种情况。
- en: ^(4.)The data is available through Kaggle at [http://mng.bz/8W8P](https://shortener.manning.com/8W8P).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: ^（4.）数据可通过Kaggle在[http://mng.bz/8W8P](https://shortener.manning.com/8W8P)获取。
- en: ^(5.)By this point, you should be familiar with the formula, which is always
    the same as in all the use cases described previously, so I won’t repeat it here.
    If you need a refresher, see section 4.2.3.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: ^（5.）到这一点，你应该已经熟悉了公式，它总是与之前描述的所有用例中的公式相同，所以这里不再重复。如果你需要复习，请参阅第4.2.3节。
- en: ^(6.)See, for example, [http://mng.bz/EVjJ](http://mng.bz/EVjJ) or [http://mng.bz/N8jD](https://shortener.manning.com/N8jD).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: ^（6.）例如，请参阅[http://mng.bz/EVjJ](http://mng.bz/EVjJ)或[http://mng.bz/N8jD](https://shortener.manning.com/N8jD)。
