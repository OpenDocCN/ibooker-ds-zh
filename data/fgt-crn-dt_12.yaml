- en: 9 Forecast accuracy and machine learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 预测准确性和机器学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的内容
- en: Calculating measurements of forecasting accuracy for churn
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算预测准确性的测量值以预测客户流失
- en: Backtesting a model in a historical simulation
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在历史模拟中回测模型
- en: Setting the regression parameter for the minimum metric contribution
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置最小指标贡献的回归参数
- en: Picking the best value of the regression parameter by testing (cross-validation)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过测试（交叉验证）选择回归参数的最佳值
- en: Forecasting churn risk with the XGBoost machine learning model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用XGBoost机器学习模型预测客户流失风险
- en: Setting the parameters of the XGBoost model with cross-validation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用交叉验证设置XGBoost模型的参数
- en: You know how to forecast the probability of customer churn, and you also know
    how to check the calibration of your forecasts. Another important measurement
    of a forecasting model is whether the customers predicted to be highly at risk
    are really more at risk than those predicted to be safe. This type of predictive
    performance is generally known as accuracy, although as you will see, there is
    more than one way to measure accuracy.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道如何预测客户流失的概率，也知道如何检查预测的校准。预测模型的一个重要测量指标是，那些预测为高度风险客户的客户，是否真的比那些预测为安全客户的客户风险更高。这种预测性能通常被称为准确性，尽管你会看到，测量准确性的方法不止一种。
- en: Back in chapter 1, I told you that forecasting churn with a predictive model
    was not the emphasis of this book because it isn’t helpful in many situations.
    The focus of this book is on having a good set of metrics that segment customers
    into healthy and unhealthy populations based on behavior. But there are a few
    reasons why it’s good to have accurate predictive churn forecasts, so this chapter
    will round out your skill set and ensure that you can forecast accurately when
    necessary.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，我告诉你，使用预测模型预测客户流失不是本书的重点，因为在许多情况下它并不有帮助。本书的重点是拥有一个好的指标集，根据行为将客户分为健康和不健康的人群。但有几个原因说明为什么拥有准确的预测流失率预测是有好处的，所以本章将完善你的技能集，并确保你在必要时能够准确预测。
- en: One time when it can be useful to forecast churn risk accurately is when an
    intervention is particularly expensive. An onsite training session with a product
    expert will be more expensive to deliver than an email, for example. If you’re
    selecting customers for onsite training with the intention of reducing churn risk,
    it makes sense to select only customers who have a high churn risk so that you
    enroll only customers with a suitable risk profile. Alternatively, you might not
    select the most at-risk customers because they may be beyond saving; it is often
    better to select customers with above-average but not maximum risk. (Also, you
    probably would screen the customers by particular metrics to make sure that they
    would benefit from this hypothetical training.)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，准确预测客户流失风险是有用的，尤其是在干预措施特别昂贵的情况下。例如，与产品专家进行现场培训的支出将比发送电子邮件更高。如果你选择客户进行现场培训以降低流失风险，那么只选择具有高流失风险的客户是有意义的，这样你只招收具有合适风险特征的客户。或者，你可能不会选择风险最高的客户，因为它们可能已经无法挽救；通常，选择风险高于平均水平但不是最高的客户会更好。（此外，你可能还会通过特定的指标筛选客户，以确保他们将从这种假设的培训中受益。）
- en: Another reason it is worth your time to forecast churn accurately is that doing
    so validates your entire data and analytic process; you can compare the accuracy
    of your predictions with known benchmarks, as I explain in this chapter. If you
    find that the performance of your process is below typical, that result suggests
    that you need to correct some aspect of your data or process. You may need to
    improve the way you clean your data by removing invalid examples, for example,
    or you might need to calculate better metrics. On the other hand, if you find
    that the performance of your analysis is in the high range of the benchmark, you
    can be confident that you have done a thorough analysis and there may not be much
    more to discover. You may even find that your accuracy is impossibly high, which
    might suggest the need for corrections and improvements in your data preparation,
    such as increasing the lookahead period you use to make your observations (chapter
    4).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得你花时间准确预测客户流失的原因是，这样做可以验证你的整个数据和数据分析过程；你可以将你的预测准确性与已知的基准进行比较，正如我在本章中解释的那样。如果你发现你的流程性能低于典型水平，那么这个结果表明你需要纠正你的数据或流程的某些方面。例如，你可能需要改进你的数据清洗方式，移除无效示例，或者你可能需要计算更好的指标。另一方面，如果你发现你的分析性能位于基准的高范围内，你可以有信心你已经进行了彻底的分析，可能没有太多可以发现的。你甚至可能发现你的准确性不可思议地高，这可能会表明你需要对你的数据准备进行纠正和改进，例如增加你用来进行观察的展望期（第4章）。
- en: 'This chapter is organized as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章组织如下：
- en: Section 9.1 explains ways to measure forecasting accuracy and teaches you some
    accuracy measurements that are particularly useful for churn.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9.1节解释了衡量预测准确性的方法，并教你一些对客户流失特别有用的准确性度量。
- en: Section 9.2 teaches you how to calculate accuracy measurements using a historical
    simulation.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9.2节教你如何使用历史模拟来计算准确性度量。
- en: Section 9.3 returns to the regression model from chapter 8 and explains how
    you can use an optional control parameter to control the number of weights that
    the regression uses.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9.3节回到第8章的回归模型，并解释了你可以如何使用可选的控制参数来控制回归使用的权重数量。
- en: Section 9.4 teaches you how to pick the best value of the regression control
    parameter based on the accuracy test results.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9.4节教你如何根据准确性测试结果选择回归控制参数的最佳值。
- en: Section 9.5 teaches you how to predict churn risk by using a machine learning
    model called XGBoost, which is usually more accurate than regression. You also
    learn about some of the pitfalls of the machine learning approach and see benchmark
    results from real case studies.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9.5节教你如何使用名为XGBoost的机器学习模型来预测客户流失风险，该模型通常比回归更准确。你还将了解机器学习方法的某些陷阱，并看到来自真实案例研究的基准结果。
- en: Section 9.6 covers some practical issues involved in forecasting with the machine
    learning model.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9.6节涵盖了使用机器学习模型进行预测时涉及的一些实际问题。
- en: The sections build on one another, so you should read them in order.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 各节相互关联，因此你应该按顺序阅读。
- en: 9.1 Measuring the accuracy of churn forecasts
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 测量客户流失预测的准确性
- en: To start, you learn what accuracy means in the context of churn forecasting
    and how to measure it. In fact, measuring the accuracy of churn forecasts is not
    straightforward.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你将学习在客户流失预测的背景下准确性意味着什么以及如何衡量它。实际上，衡量客户流失预测的准确性并不简单。
- en: 9.1.1 Why you don’t use the standard accuracy measurement for churn
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 为什么不使用标准的准确性度量来衡量客户流失
- en: When you’re talking about the accuracy of a forecast (such as churn probability
    predictions), the word accuracy has both a general and a specific meaning. First,
    the general definition.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当你谈论预测（如客户流失概率预测）的准确性时，"准确性"这个词既有一般意义也有特定意义。首先，一般定义。
- en: DEFINITION Accuracy (in the general sense) means the correctness or truthfulness
    of forecasts.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 定义（在一般意义上）准确性意味着预测的正确性或真实性。
- en: All methods of measuring the accuracy of churn forecasting involve comparing
    the predictions of risk with actual churn events, but there are many ways to measure
    accuracy. To make matters more confusing, one particular measurement of forecasting
    accuracy is called accuracy. This measurement is specific, but it is not a useful
    measurement for churn, as you’re about to see. I am going to start with that measurement,
    which I will call the standard accuracy measurement to prevent confusion with
    the more general meaning of accuracy. (When I say accuracy, I mean the word in
    the general sense.)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所有衡量流失预测准确率的方法都涉及将风险预测与实际流失事件进行比较，但衡量准确率的方法有很多。更令人困惑的是，有一种特定的预测准确率测量方法被称为准确率。这种测量是具体的，但它对于流失来说并不是一个有用的测量，正如你将要看到的。我将从这个测量方法开始，我将称之为标准准确率测量，以避免与准确率的更普遍含义混淆。（当我提到准确率时，我指的是这个词的普遍意义。）
- en: 'Figure 9.1 illustrates the standard accuracy measurement. In chapter 8, you
    learned how to assign a churn or retention forecast probability to each customer.
    The standard accuracy measurement further assumes that on the basis of those forecasts,
    you divide the customers into two groups: those who are expected to be retained
    and those who are expected to churn. I will return to the question of how you
    might divide customers into those two groups when I finish explaining the standard
    accuracy measurement.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1展示了标准准确率测量。在第8章中，你学习了如何为每个客户分配流失或保留预测概率。标准准确率测量进一步假设，基于这些预测，将客户分为两组：预期保留的客户和预期流失的客户。在我解释完标准准确率测量后，我将回到如何将客户分为这两组的问题。
- en: '![](../Images/9-01.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-01.png)'
- en: Figure 9.1 The standard accuracy measurement
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 标准准确率测量
- en: 'After customers are divided into expected retention and expected churn groups,
    the assigned categories are compared with what really happened. To define the
    standard accuracy measurement, you need to use the following terms:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在将客户分为预期保留和预期流失组后，分配的类别将与实际情况进行比较。为了定义标准准确率测量，你需要使用以下术语：
- en: A true-positive (TP) prediction is a predicted churn that churns.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阳性的预测（TP）是指预测到的流失确实发生了。
- en: A true-negative (TN) prediction is a predicted retention that stays.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真阴性的预测（TN）是指预测到的保留确实保持不变。
- en: A false-positive (FP) prediction is a predicted churn that stays instead of
    churning.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阳性的预测（FP）是指预测到的流失却未发生流失。
- en: A false-negative (FN) prediction is a predicted retention that churns.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假阴性的预测（FN）是指预测到的保留却发生了流失。
- en: Using these definitions, the standard accuracy measurement is defined as follows.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些定义，标准准确率测量被定义为以下内容。
- en: 'DEFINITION The standard accuracy is the percentage of forecasts that are either
    true positives or true negatives. In an equation, this would be Standard Accuracy
    = (#TP + #TN )/(#Total).'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** 标准准确率是指预测中为真阳性或真阴性的百分比。在方程中，这将是标准准确率 = (真阳性数量 + 真阴性数量) / 总数量。'
- en: 'Standard accuracy is meant to represent the percentage of predictions that
    were correct in a particular literal sense: the percentage of the category assignments
    that came true. That sounds reasonable, but in fact, standard accuracy is inappropriate
    for measuring the validity of churn forecasts. Standard accuracy has two problems
    when it comes to churn:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 标准准确率旨在表示在特定字面上的预测正确率：即类别分配中实现的比例。这听起来合理，但实际上，标准准确率不适用于衡量流失预测的有效性。在流失方面，标准准确率有两个问题：
- en: Churn is rare, so standard accuracy is dominated by nonchurns.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流失事件很少见，因此标准准确率主要由非流失事件主导。
- en: 'The basic assumption of the standard accuracy measurement is that you divide
    customers into two groups: expected churns and expected retentions. But that division
    isn’t a useful portrayal of customer segmentation use cases.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准准确率测量的基本假设是将客户分为两组：预期流失和预期保留。但这种划分并不是客户细分用例的有用描述。
- en: I will explain each of these problems in detail.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我将详细解释这些问题。
- en: Standard accuracy is dominated by nonchurns because churns are rare, so true
    positives cannot possibly have much impact on the numerator in the standard accuracy
    ratio. As a result, the measurement doesn’t always do a good job of showing whether
    forecasts are appropriate. To make this point, note that there is an easy way
    to get a high standard accuracy measurement, as illustrated in figure 9.2\. If
    you were to predict that no customers would churn (all customers in the nonchurn
    group), you would have true-negative predictions for the majority. If you have
    all the true negatives correctly assigned, the resulting accuracy is the retention
    rate, and you would have a high standard accuracy measurement without having predicted
    anything about churn.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 标准准确率通常受非流失客户的影响，因为流失客户很少见，所以真正的正面预测对标准准确率比率的分子部分不可能有太大影响。因此，这种测量方法并不总是能很好地展示预测是否恰当。为了说明这一点，请注意，有一种简单的方法可以获得很高的标准准确率测量值，如图9.2所示。如果你预测没有任何客户会流失（所有客户都属于非流失组），那么你将会有大量的真正负预测。如果你将所有真正负预测正确分配，那么得到的准确率就是保留率，你将获得一个很高的标准准确率测量值，而不需要预测任何关于流失的信息。
- en: '![](../Images/9-02.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图9.2 操纵流失的标准准确率测量](../Images/9-02.png)'
- en: Figure 9.2 Gaming the standard accuracy measurement for churn
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 操纵流失的标准准确率测量
- en: TAKEAWAY The standard accuracy measurement is inappropriate for churn because
    churn is rare, so the measurement can be gamed by predicting that no one will
    churn. More generally, accuracy on churned customers makes only a small contribution
    to the measurement.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点**：由于流失事件很少见，因此标准准确率测量方法不适用于流失预测，因为可以通过预测没有人会流失来操纵这种测量。更普遍地说，流失客户的准确率对测量贡献很小。'
- en: 'One possible remedy for this weakness in the standard accuracy measurement
    is to augment it with measurements based on not only true positives and true negatives
    but also false positives and false negatives. I don’t recommend this approach
    either, however, because there is another way in which standard accuracy measurement
    is inappropriate for churn use cases. Calculating standard accuracy relies on
    the assumption that you divided the customers into two groups: expected churns
    and expected retentions. Dividing predictions into two exclusive groups is standard
    for some forecasting use cases, but it is rarely done that way for customer churn.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于标准准确率测量中的这种弱点，一种可能的补救措施是增加基于不仅真正正面和真正负面，还包括假正面和假负面的测量。然而，我也不推荐这种方法，因为标准准确率测量对于流失用例的不适用性还有另一种方式。计算标准准确率依赖于你将客户分为两组：预期流失客户和预期保留客户的假设。将预测分为两个互斥的组对于某些预测用例是标准的，但在客户流失的情况下很少这样做。
- en: As mentioned at the start of the chapter, the most common use case for churn
    and retention forecasts is to select customers for relatively expensive interventions
    to reduce churn. In that case, the churn or retention probability is used like
    any other segmenting metric, in that the department organizing the intervention
    orders the customers by the metric and then uses its own criteria to pick the
    most appropriate customers. If the intervention has a specific budget, for example,
    the department might pick a fixed number of customers who are most at risk for
    churn or a fixed number of customers who are not most at risk. A common strategy
    is to select customers with above-average risk who still use the product a little
    because the most at-risk customers who do not use the product may not be savable.
    You (the data person) aren’t dividing the customers into expected churns and nonchurns
    as presumed by the standard accuracy measurement.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章开头所述，流失和保留预测最常见用例是选择客户进行相对昂贵的干预措施以减少流失。在这种情况下，流失或保留概率就像其他细分指标一样被使用，即组织干预措施的部门根据该指标对客户进行排序，然后使用自己的标准选择最合适的客户。例如，如果干预措施有特定的预算，那么部门可能会选择固定数量的最有可能流失或最不可能流失的客户。一种常见的策略是选择那些风险高于平均水平但仍使用产品的客户，因为这些最有可能流失且不使用产品的客户可能无法挽救。你（数据人员）并没有像标准准确率测量所假设的那样将客户分为预期流失客户和非流失客户。
- en: 'TAKEAWAY Churn forecasting use cases rely on using the ranking provided by
    the churn forecast as a segmenting metric but do not involve categorizing the
    customers into two groups: expected churns and nonchurns.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**要点**：流失预测用例依赖于使用流失预测提供的排名作为细分指标，但并不涉及将客户分为两组：预期流失客户和非流失客户。'
- en: Because real churn use cases depend on the model’s ability to rank customers
    by risk but not divide them into two groups per se, it makes more sense to turn
    to alternative (nonstandard) measurements of accuracy that better reflect the
    situation. As described in section 9.1.2, these measurements also remedy the problems
    in the standard accuracy measurement caused by the rarity of churn.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因为实际的客户流失用例依赖于模型按风险对客户进行排名的能力，而不是将他们分成两个群体本身，所以转向更准确地反映这种情况的替代（非标准）准确性测量方法更有意义。如第9.1.2节所述，这些测量方法也解决了标准准确性测量中由于客户流失的罕见性引起的问题。
- en: 9.1.2 Measuring churn forecast accuracy with the AUC
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 使用AUC测量客户流失率预测准确性
- en: The first accuracy measurement that you should use for churn is area under the
    curve (AUC), where the curve refers to an analytic technique known as the receiver
    operating curve. This naming is unfortunate, because AUC is a technical description
    of the way in which the metric is calculated but doesn’t convey clearly what it
    means. But everyone uses this name, so we have no choice but to stick with it;
    I won’t refer to the receiver operating curve anymore because it is not necessary
    for understanding or applying the metric. As you will see, my advice is not to
    even mention this measurement to your business colleagues. If you want more details,
    it is easy to find resources online.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于客户流失率，你应该首先使用的准确性测量方法是曲线下面积（AUC），这里的曲线指的是一种称为接收者操作曲线的分析技术。这种命名是不幸的，因为AUC是对指标计算方式的技术描述，但并没有清楚地传达其含义。但每个人都使用这个名字，所以我们别无选择，只能继续使用；我不会再提到接收者操作曲线，因为它对于理解或应用这个指标并不是必要的。正如你将看到的，我的建议是甚至不要向你的商业同事提及这个测量方法。如果你想要更多细节，很容易在网上找到资源。
- en: The meaning of AUC is simpler than the name, as summarized in figure 9.3\. As
    in the standard accuracy measurement, you start with a dataset in which you made
    a forecast for every customer and know which customers churned. Consider the following
    test. Take one customer who churned and one customer who didn’t churn. If your
    model is good, it should have forecast a higher churn risk for the customer who
    churned than for the one who didn’t. If the model did so, consider that comparison
    to be a success. Now consider the same test for every possible comparison. One
    by one, compare every churn with every nonchurn to see whether the model predicted
    higher churn risk for true churn. The overall proportion of successful predictions
    is the AUC.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: AUC的含义比其名称简单，如图9.3所示总结。与标准准确性测量一样，你从一个为每个客户都进行了预测并且知道哪些客户流失的数据集开始。考虑以下测试。取一个已经流失的客户和一个没有流失的客户。如果你的模型很好，它应该预测流失客户的流失风险比未流失客户要高。如果模型确实这样做了，那么认为这次比较是成功的。现在考虑每个可能的比较。一个接一个地，将每个客户流失与每个非客户流失进行比较，看看模型是否预测了真实的客户流失具有更高的流失风险。成功预测的整体比例就是AUC。
- en: '![](../Images/9-03.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图9.3](../Images/9-03.png)'
- en: Figure 9.3 Measuring accuracy with the AUC
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 使用AUC测量准确性
- en: DEFINITION AUC is the percentage of comparisons in which the model forecasts
    higher churn risk for a churn than for a nonchurn, considering pairwise comparisons
    of all churns and nonchurns.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 AUC是模型在所有客户流失和非客户流失的成对比较中，预测客户流失比非客户流失具有更高流失风险的比较百分比。
- en: AUC avoids the problem in standard accuracy, which is that prediction on churns
    doesn’t matter much because churns are such a small percentage of the population.
    In the AUC calculation, accurate prediction of churns is central because every
    comparison involves one churn, even if churns are only a small percentage of the
    data. At the same time, AUC is based on the ranking of risks and doesn’t require
    an artificial categorization of customers into two groups.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: AUC避免了标准准确性中的问题，即预测流失并不重要，因为流失在人口中只占很小的比例。在AUC的计算中，准确预测流失是核心，因为每个比较都涉及一个流失客户，即使流失客户只占数据的一小部分。同时，AUC基于风险的排名，不需要将客户人工分类为两个群体。
- en: If you think about the definition of AUC, that measurement could involve a lot
    of comparisons. The total number of pairwise comparisons is the product of the
    number of churned customers and the number of nonchurned customers. Fortunately,
    there is a more efficient way to do the calculation, involving that receiver operating
    curve, but I’m not going to teach you how to use it. Instead, you will use an
    open source package to do the calculation (listing 9.1). It’s true that AUC is
    more expensive to calculate than the standard accuracy metric, but the difference
    is not enough to cause concern.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你考虑 AUC 的定义，那个测量可能涉及很多比较。成对比较的总数是流失客户数和非流失客户数的乘积。幸运的是，有一种更有效的方法来进行计算，涉及到接收者操作曲线，但我不打算教你如何使用它。相反，你将使用一个开源包来进行计算（列出
    9.1）。确实，AUC 的计算成本比标准准确率指标要高，但差异并不足以引起担忧。
- en: If you run listing 9.1, you’ll see the short output in figure 9.4—a first demonstration.
    You will be using the AUC measurement throughout this chapter.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行列出 9.1，你将在图 9.4 中看到简短的输出——这是一个初步演示。你将在本章中使用 AUC 测量。
- en: '![](../Images/9-04.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-04.png)'
- en: Figure 9.4 Output of listing 9.1 for calculating the forecast model AUC
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 列出 9.1 计算预测模型 AUC 的输出
- en: 'To demonstrate the AUC, listing 9.1 reloads the logistic regression model that
    you saved in chapter 8; it also reloads the dataset used to train the model (the
    historical dataset with labeled churns and retentions, not the current customer
    dataset). The model’s `predict_proba` function is used to create forecasts, and
    these forecasts are passed to the function `roc_auc_score` from the sklearn.metrics
    package. You should run listing 9.1 on your own saved data and regression model
    with the following standard command and these arguments:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示 AUC，列出 9.1 重新加载了你在第 8 章中保存的逻辑回归模型；它还重新加载了用于训练模型的数据库（带有标记流失和保留的历史数据集，而不是当前客户数据集）。模型的
    `predict_proba` 函数用于创建预测，并将这些预测传递给来自 sklearn.metrics 包的 `roc_auc_score` 函数。你应该使用以下标准命令和这些参数在自己的保存数据和回归模型上运行列出
    9.1：
- en: '[PRE0]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Listing 9.1 Calculating the forecast model AUC
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 列出 9.1 计算预测模型 AUC
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ① sklean has a function to calculate the AUC.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ① sklean 函数可以用来计算 AUC。
- en: ② Reuses the prepare_data function from listing 8.2
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ② 重新使用列出 8.2 中的 prepare_data 函数
- en: ③ Reloads the regression model pickle
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 重新加载回归模型 pickle
- en: ④ Calls the reload_regression function
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 调用 reload_regression 函数
- en: ⑤ Calls the prepare_data function from listing 8.2
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 调用列出 8.2 中的 prepare_data 函数
- en: ⑥ predict_proba returns probability predictions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ predict_proba 返回概率预测。
- en: ⑦ Calls the function to calculate the AUC
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 调用计算 AUC 的函数
- en: You should find that the regression model has an AUC of around 0.7, which raises
    the question of whether 0.7 is good. AUC is a percentage, like accuracy, and 100%
    is the best possible. If you had 100% AUC, all the churns were ranked higher in
    risk than all the nonchurns. But you will never find a real churn-prediction system
    that has an AUC anywhere near that high.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会发现回归模型的 AUC 大约是 0.7，这引发了是否 0.7 是好的的问题。AUC 是一个百分比，就像准确率一样，100% 是最好的。如果你有
    100% 的 AUC，所有流失客户的风险排名都会高于所有非流失客户。但你永远不会找到一个 AUC 接近那个高度的真正流失预测系统。
- en: On the other hand, consider the worst you could possibly do. Zero percent sounds
    bad, but that result would mean that you had all the nonchurns ranked as a higher
    risk than the churns. If you think about it, that result would be fine, because
    then you could use your model as a perfect predictor of retention. Probably, though,
    something went wrong in your model setup to make it predict backward.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，考虑最坏的情况。零百分比听起来很糟糕，但这个结果意味着你将所有非流失客户排名高于流失客户。如果你这么想，这个结果倒是可以接受，因为那时你可以将你的模型作为完美的保留预测器。然而，很可能在你的模型设置中出了些问题，导致它做出了反向预测。
- en: 'In fact, the worst AUC would be 0.50, which would mean that your predictions
    were like coin flips: right half the time and wrong half the time. If a forecast
    model has an AUC of 0.5, it has the worst possible performance—the same as random
    guessing.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，最差的 AUC 是 0.50，这意味着你的预测就像抛硬币一样：一半时间正确，一半时间错误。如果一个预测模型的 AUC 是 0.5，那么它的性能最差——与随机猜测相同。
- en: TAKEAWAY AUC ranges from 0.5, which is equivalent to random guessing (no predictive
    power), to 1.0, which is perfect ranking of churns versus nonchurns.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要 AUC 范围从 0.5（相当于随机猜测，没有预测能力）到 1.0（完美地将流失客户与非流失客户进行排序）。
- en: Table 9.1 shows a list of benchmarks for what you can consider to be healthy
    and unhealthy AUC. Generally, churn forecasting AUC is healthy in the range from
    around 0.6 to 0.8\. If it’s less than 0.6 or greater than 0.8, something is probably
    wrong, and you need to check the data in your model. You may not think that high
    accuracy would be cause for concern, but it could be. I’ll say more about that
    subject in section 9.2.3.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1显示了您可以考虑的健康和不健康的AUC基准列表。一般来说，流失预测AUC在约0.6到0.8的范围内是健康的。如果它低于0.6或高于0.8，可能存在问题，您需要检查模型中的数据。您可能不会认为高精度会引发担忧，但它可能会。我将在第9.2.3节中更多关于这个主题。
- en: Table 9.1 Churn forecasting AUC benchmarks
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1 流失预测AUC基准
- en: '| AUC result | Diagnosis |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| AUC结果 | 诊断 |'
- en: '| < 0.45 | Something is wrong! The model is predicting backward. Check your
    data and the code calculating the AUC; is it using the wrong column of the predict_proba
    result? |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| < 0.45 | 存在问题！模型正在预测反向。检查您的数据以及计算AUC的代码；是否使用了预测概率结果的错误列？|'
- en: '| 0.45-0.55 | No different from random guessing (0.5). Check your data. |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 0.45-0.55 | 与随机猜测（0.5）没有区别。检查您的数据。|'
- en: '| 0.55-0.6 | Better than random guessing but not good. Check your data, collect
    better events, or make better metrics. |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 0.55-0.6 | 优于随机猜测，但并不理想。检查您的数据，收集更好的事件，或制定更好的指标。|'
- en: '| 0.6-0.7 | Healthy range for weakly predictable churn. |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 0.6-0.7 | 弱度可预测的流失的健康范围。|'
- en: '| 0.7-0.8 | Healthy range for highly predictable churn. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 0.7-0.8 | 高度可预测的流失的健康范围。|'
- en: '| 0.8-0.85 | Extremely predictable churn. This result is suspicious for a consumer
    product and usually is possible only for a business product with informative events
    and advanced metrics. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 0.8-0.85 | 极度可预测的流失。这个结果对于消费品来说可能是可疑的，通常只有具有信息性事件和高级指标的商业产品才可能实现。|'
- en: '| > 0.85 | Something probably is wrong. Normally, churn is not this predictable,
    even for business products. Check your data to make sure that you’re not using
    too short of a lead time to construct the dataset and that there are no lookahead
    events or customer data fields (described in section 9.2.3). |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| > 0.85 | 可能存在问题。通常，流失并不是这么可预测的，即使是对于商业产品。检查您的数据，确保您没有使用过短的领先时间来构建数据集，并且没有前瞻性事件或客户数据字段（在第9.2.3节中描述）。|'
- en: NOTE The AUC benchmarks in table 9.1 apply only to customer churn. For other
    problem domains, the expected range of forecasting AUC can be higher or lower.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意** 表9.1中的AUC基准仅适用于客户流失。对于其他问题域，预测AUC的预期范围可能更高或更低。'
- en: 'AUC is used throughout the rest of this chapter, but first, you should be aware
    of one other nonstandard accuracy measurement: the lift.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: AUC将在本章的其余部分中使用，但首先，你应该意识到另一种非标准的准确性度量：提升。
- en: 9.1.3 Measuring churn forecast accuracy with the lift
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3 使用提升测量流失预测准确性
- en: 'AUC is a useful metric, but it has one downside: it is abstract and hard to
    explain. I recommend a different metric for churn accuracy, primarily because
    it is easy for businesspeople to understand. In fact, this metric, known as the
    lift, originated in marketing. I’ll explain first the general use of lift in marketing
    and then its specific application to churn.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: AUC是一个有用的指标，但它有一个缺点：它是抽象的，难以解释。我建议使用另一个指标来衡量流失准确性，主要是因为它对商业人士来说很容易理解。事实上，这个指标，被称为提升，起源于市场营销。我将首先解释提升在市场营销中的通用用途，然后解释其在流失中的应用。
- en: DEFINITION Lift is the relative increase in responses due to some treatment
    relative to the baseline.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** 提升是由于某种处理相对于基线引起的响应的相对增加。'
- en: If 1% of people who visit a website sign up for the product, and a promotion
    increases the sign-up rate to 2%, the lift caused by the promotion is 2.0 (2%
    divided by 1%). According to that definition, a lift of 1.0 means no improvement.
    One thing to notice about lift is that it emphasizes improvement over the baseline,
    so it is suitable for measuring improvement in things that are rare to begin with.
    For measuring the accuracy of prediction models, you can use a more specific version
    of lift called the top decile lift.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如果访问网站的1%的人注册了产品，而促销活动将注册率提高到2%，那么促销活动引起的提升是2.0（2%除以1%）。根据这个定义，提升1.0表示没有改进。关于提升需要注意的一点是，它强调的是相对于基线的改进，因此它适合于测量原本就很少发生的事情的改进。对于测量预测模型的准确性，可以使用提升的一个更具体的版本，称为顶级十分位提升。
- en: DEFINITION The top decile lift of a predictive churn model is the ratio of the
    churn rate in the top decile of customers predicted to be most at risk to the
    overall churn rate.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** 预测流失模型的顶级十分位提升是指预测为最有可能流失的顶级十分位客户流失率与整体流失率之比。'
- en: Figure 9.5 illustrates this definition. The top decile lift is like a regular
    lift measurement, but the baseline is the overall churn rate, and the treatment
    is that you picked the 10% most at-risk customers according to the model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5说明了这个定义。顶部十分位提升类似于常规的升力测量，但基线是整体流失率，处理方式是根据模型选择了最危险的10%的客户。
- en: '![](../Images/9-05.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图9-05](../Images/9-05.png)'
- en: Figure 9.5 Measuring accuracy with the lift
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5 使用提升测量准确性
- en: IMPORTANT Because this definition is the most common definition of lift for
    churn forecasting, when I use the term lift, you should be aware from the context
    that I mean top decile lift.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 重要：因为这个定义是流失预测中最常见的提升定义，当我使用“提升”这个词时，你应该从上下文中意识到我指的是顶部十分位提升。
- en: Why is the overall churn rate the baseline? That’s how accurate you would be
    in predicting churn if you were randomly guessing. If you have a 5% churn rate,
    you will find churns 5% of the time if you pick customers at random. If you can
    do better than random guessing (lift greater than 1.0), your result improves.
    You might respond that you could do better than guessing randomly, and you probably
    could, especially if you use segments based on data-driven metrics like the ones
    you learn how to make in this book. But the point is that the overall churn rate
    is a reasonable baseline at all companies, regardless of whatever else you might
    be doing.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么整体流失率是基线？如果你随机猜测，这就是预测流失的准确性。如果你有5%的流失率，如果你随机选择客户，你将发现5%的时间会有流失。如果你能做得比随机猜测更好（提升大于1.0），你的结果会改善。你可能会回应说你可以做得比随机猜测更好，你很可能可以，特别是如果你使用基于数据驱动指标的分段，就像你在本书中学到的那些。但关键是，整体流失率是所有公司的一个合理的基线，无论你还在做些什么。
- en: TAKEAWAY Top decile lift is good for measuring accuracy because it emphasizes
    improvement from a low baseline level of prediction.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收：顶部十分位提升对于测量准确性是有益的，因为它强调了从低基线预测水平上的改进。
- en: Listing 9.2 shows how to calculate the lift with Python, assuming that you have
    a model saved (as in listing 9.1). Again, the output, as shown in figure 9.6,
    is a simple printout of the results and only a demonstration.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.2展示了如何使用Python计算提升，假设你已经保存了一个模型（如列表9.1所示）。同样，如图9.6所示，输出只是一个结果的简单打印，仅作为演示。
- en: '![](../Images/9-06.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图9-06](../Images/9-06.png)'
- en: Figure 9.6 Output of listing 9.2 (lift)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6 列表9.2的输出（提升）
- en: 'Listing 9.2 doesn’t use an open source package to calculate the lift. At the
    time of this writing, no open source package makes this calculation, so I have
    made an implementation for you in the function `calc_lift`. The steps to calculate
    the lift are as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.2没有使用开源包来计算升力。在撰写本文时，没有开源包能进行这种计算，因此我在函数`calc_lift`中为你实现了一个。计算升力的步骤如下：
- en: Validate the data to make sure you have a sufficient number of distinct forecasts.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证数据以确保你有足够数量的不同预测。
- en: Calculate the overall churn rate in the sample.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算样本中的整体流失率。
- en: Sort the predictions by the churn risk forecast.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照流失风险预测对预测进行排序。
- en: Locate the position of the top decile.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定位顶部十分位的位置。
- en: Calculate the number of churns in the top decile and the top decile churn rate.
    The result is the top decile churn rate divided by the overall churn rate.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算顶部十分位中的流失数量和顶部十分位流失率。结果是顶部十分位流失率除以整体流失率。
- en: The lift calculation I provide requires at least 10 unique values or levels
    for the forecasts. Not enough forecasts can be a problem with bad data or a misspecified
    model. The most common manifestation of bad data or a bad model is that all accounts
    get the same forecast, but other variants are possible. The criteria of 10 is
    a rule of thumb, not a hard rule. (In principle, the forecasts should allow you
    to select exactly 10% of the customers who are most at risk for the comparison.
    For example, it would be okay for the purpose of calculating lift to have just
    two distinct predictions coming from the model as long as exactly 10% of the population
    gets one prediction or the other. The 10-unique-values rule of thumb catches the
    most egregious model or data failures, and matching the condition precisely is
    not really necessary anyway.)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我提供的提升计算至少需要10个独特的值或水平来预测。如果预测不足，可能会因为数据质量差或模型指定不当而出现问题。数据质量差或模型错误最常见的表现是所有账户都得到相同的预测，但其他变体也是可能的。10个值的准则是一个经验法则，而不是一个硬性规则。（原则上，预测应该允许你选择最有可能进行比较的10%的客户。例如，在计算提升的目的上，只要精确的10%的人口得到一个预测或另一个，那么模型只提供两个不同的预测也是可以接受的。10个独特值的经验法则可以捕捉到最严重的模型或数据失败，而且精确匹配条件实际上并不必要。）
- en: Listing 9.2 Calculating the forecast model lift
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.2 计算预测模型提升
- en: '[PRE2]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ① Uses the prepare_data function from listing 8.2
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ① 使用列表8.2中的prepare_data函数
- en: ② Uses the reload_regression function from listing 9.1
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ② 使用列表9.1中的reload_regression函数
- en: ③ Parameters are series of true churn outcomes and predictions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 参数是真实流失结果和预测的序列。
- en: ④ Checks to make sure that the predictions are valid
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 确保预测是有效的
- en: ⑤ Calculates the overall churn rate
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 计算整体流失率
- en: ⑥ Sorts the predictions
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 对预测进行排序
- en: ⑦ Calculates the index of the 90th percentile
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 计算第90百分位的索引
- en: ⑧ Counts the churns in the top decile
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 计算最十分之一的流失
- en: ⑨ Calculates the top decile churn rate
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 计算最十分之一的流失率
- en: ⑩ Returns the ratio of the top decile churn to the overall churn
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 返回最十分之一流失与整体流失的比率
- en: ⑪ Loads the model, and generates predictions as in listing 8.1
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ⑪ 加载模型，并生成类似于列表8.1中的预测
- en: ⑫ Loads the data but doesn’t invert the outcome to retention
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ⑫ 加载数据，但不将结果反转为保留
- en: ⑬ Calls the lift calculation function
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ⑬ 调用提升计算函数
- en: 'You should run listing 9.2 with the following arguments to check the result
    yourself:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该使用以下参数运行列表9.2来自行检查结果：
- en: '[PRE3]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You should find that the regression model achieves a lift of around 4.0 on the
    simulated data. I’ve already mentioned that the minimum lift is 1.0, which indicates
    that your model is no better than random guessing because it can’t find more churns
    than the overall churn rate. A lift less than 1.0 is akin to an AUC less than
    0.5, which means that your model is predicting risk in reverse because the top
    decile has fewer churns than the overall sample.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会发现回归模型在模拟数据上实现了大约4.0的提升。我已经提到，最小提升是1.0，这表明你的模型并不比随机猜测好，因为它找不到比整体流失率更多的流失。提升小于1.0类似于AUC小于0.5，这意味着你的模型在预测风险时是反向的，因为最危险的十分之一比整体样本有更少的流失。
- en: 'You can also deduce the maximum possible lift if the top decile of customers
    most at risk contained only customers who churned. The lift would be 100% divided
    by the overall churn rate. So the maximum lift depends on the overall churn rate.
    Here are some examples:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果最危险的十分之一客户中只包含流失的客户，你也可以推断出可能的最大提升。提升将是100%除以整体流失率。因此，最大提升取决于整体流失率。以下是一些例子：
- en: If the churn rate is 20%, the maximum possible lift would occur if the top decile
    of forecasts were all churns. Then the lift would be 5 (100%/20% = 5).
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果流失率是20%，最大可能的提升将发生在预测的最十分之一都是流失的情况下。那么提升将是5（100%/20% = 5）。
- en: If the churn rate is 5%, the maximum lift would be if all those 5% churns were
    in the top decile forecast group. Then the top decile churn rate would be 50%,
    and the lift would be 10 (50%/5% = 10).
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果流失率是5%，最大提升将出现在所有5%的流失都在最十分之一预测组中。那么最十分之一的流失率将是50%，提升将是10（50%/5% = 10）。
- en: The pattern is that the higher the overall churn rate is, the lower the maximum
    possible lift. You are not going to get anywhere close to those maximums, but
    the relationship between churn rates and more typical lift values is the same.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 模式是，整体流失率越高，可能的最大提升越低。你不可能接近那些最大值，但流失率和更典型提升值之间的关系是相同的。
- en: TAKEAWAY The higher the overall churn rate, the lower the lift you should expect
    from a predictive model.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: TAKEAWAY 总体流失率越高，您应该期望的预测模型的提升效果越低。
- en: Table 9.2 lists benchmarks for what you can expect to find for lift in real
    churn prediction use cases. Unlike for the AUC, the reasonable range of lift values
    depends on the churn rate. If the churn rate is low, it’s easier to get a somewhat
    greater lift. If the churn rate is high (greater than 10%), the lift is likely
    to be lower. As explained in the preceding paragraph, the maximum lift is reduced
    when the churn rate is high. That property carries over to expecting lower lift
    scores generally because you’re not likely to find so many churns in the top decile.
    For low-churn products, a healthy lift is in the range from 2.0 to 5.0, whereas
    for high-churn products, the healthy range is around 1.5 to 3.0.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.2列出了在真实流失率预测用例中可以期望找到的提升度基准。与AUC不同，提升度值的合理范围取决于流失率。如果流失率低，则更容易获得相对较大的提升度。如果流失率高（大于10%），提升度可能较低。正如前一段所述，当流失率高时，最大提升度会降低。这一特性也适用于期望较低的提升度得分，因为您不太可能在顶部十分位找到如此多的流失率。对于低流失率产品，健康的提升度范围在2.0到5.0之间，而对于高流失率产品，健康的范围大约在1.5到3.0之间。
- en: Table 9.2 Churn forecasting lift benchmarks
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.2 流失率预测提升度基准
- en: '| Low churn (< 10%) lift result | High churn (> 10%) lift result | Diagnosis
    |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 低流失率（< 10%）提升度结果 | 高流失率（> 10%）提升度结果 | 诊断 |'
- en: '| < 0.8 | < 0.8 | Something is wrong! The model is predicting backward. Check
    your data and the code calculating the lift. Is it using the wrong column of the
    predict_proba result? |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| < 0.8 | < 0.8 | 存在问题！模型预测方向错误。检查您的数据以及计算提升度的代码。是否使用了预测概率结果的错误列？|'
- en: '| 0.8-1.5 | 0.8-1.2 | Random guessing (1.0), or not very different from random
    guessing. Check your data. |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 0.8-1.5 | 0.8-1.2 | 随机猜测（1.0），或者与随机猜测没有太大区别。检查您的数据。|'
- en: '| 1.5-2.0 | 1.2-1.5 | Better than random guessing but not good. Check your
    data, collect better events, or make new metrics. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 1.5-2.0 | 1.2-1.5 | 优于随机猜测，但并不理想。检查您的数据，收集更好的事件，或创建新的指标。|'
- en: '| 2.0-3.5 | 1.5-2.25 | Healthy range of weakly predictable churn. |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 2.0-3.5 | 1.5-2.25 | 弱可预测流失的健康范围。|'
- en: '| 3.5-5.0 | 2.25-3.0 | Healthy range of highly predictable churn. |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 3.5-5.0 | 2.25-3.0 | 高度可预测流失的健康范围。|'
- en: '| 5.0-6.0 | 3.0-3.5 | Extremely predictable churn. This result is suspicious
    for a consumer product and usually is possible only for a business product with
    good events and metrics. |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 5.0-6.0 | 3.0-3.5 | 极度可预测的流失。对于消费者产品来说，这个结果令人怀疑，通常只有具有良好事件和指标的商务产品才可能实现。|'
- en: '| > 6.0 | > 3.5 | Something probably is wrong. Normally, churn is not this
    predictable, even for business products. Check your data to make sure you’re that
    not using too short of a lead time to construct the dataset and that there are
    no lookahead events or customer data fields (described in section 9.2.3). |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| > 6.0 | > 3.5 | 可能存在问题。通常，即使是对于商务产品，流失率也不应该是如此可预测的。检查您的数据，确保您没有使用过短的领先时间来构建数据集，并且没有前瞻性事件或客户数据字段（在第9.2.3节中描述）。|'
- en: 'I like to use the lift when I explain accuracy to businesspeople because the
    term is intuitive and related to metrics that they already understand. But there
    is one problem with the lift: it can be unstable, particularly with small datasets.
    Small changes in the metrics or model you use to predict may create big changes
    in the result.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢在向商业人士解释准确度时使用提升度，因为这个术语直观且与他们已经理解的指标相关。但是，提升度有一个问题：它可能不稳定，尤其是在小数据集上。您用于预测的指标或模型中的微小变化可能会在结果中造成大的变化。
- en: WARNING The lift can be unstable, especially for small datasets. The result
    can vary significantly, comparing different time periods and forecasting models.
    To measure lift, you should have thousands of observations and hundreds of churns
    in the dataset (or more). The lower the churn rate, the more observations you
    need to make the lift measurement stable.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: WARNING 提升度可能不稳定，尤其是在小数据集上。结果可能在不同时间段和预测模型之间有显著差异。为了测量提升度，您应该有数千个观察值和数百个流失率在数据集中（或更多）。流失率越低，您需要的观察值越多，以便使提升度测量稳定。
- en: Suppose that you have only 500 customer observations and a 5% churn rate, so
    you have only 25 churns. In that case, the lift is based on how many of those
    25 are in the top 10% forecast at risk, with the baseline being an expected (average)
    2.5\. The addition or removal of a few churns from the top decile will make big
    swings in the lift. Generally, you should use the lift when you have thousands
    of observations or more. The AUC avoids this type of problem because it always
    uses every churn in the dataset and maximizes their use (by comparing every churn
    with every nonchurn).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你只有 500 个客户观察结果和 5% 的 churn 率，因此你只有 25 个 churn。在这种情况下，提升是基于这 25 个中有多少在风险预测的前
    10%，基线预期（平均）为 2.5。从顶部十分之一中增加或减少几个 churn 会对提升产生重大影响。通常，当你有数千个观察结果或更多时，你应该使用提升。AUC
    避免了这类问题，因为它始终使用数据集中的每个 churn，并最大化其使用（通过将每个 churn 与每个非 churn 进行比较）。
- en: TAKEAWAY Use the AUC to evaluate your model accuracy for your own understanding.
    Use the lift to explain the churn accuracy to businesspeople.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 吸取经验：使用 AUC 来评估你自己的模型准确性。使用提升来向商业人士解释 churn 准确性。
- en: 'Another nice property of the lift is that it makes the imprecise business of
    forecasting churn sound more impressive. Compare these two statements:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 提升的另一个优点是它使预测 churn 的不精确业务听起来更有说服力。比较以下两个陈述：
- en: This model is three times better than the baseline.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个模型比基线模型好三倍。
- en: This model ranks a customer who churns 70% of the time as more risky than a
    customer who doesn’t.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个模型将 churn 率为 70% 的客户评为比 churn 率为 0% 的客户风险更高。
- en: Even though both statements imply the same level of improvement above random
    guessing, three times is a more impressive statistic than 70%.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这两个陈述都暗示了比随机猜测更高的相同水平改进，但三倍是一个比 70% 更令人印象深刻的统计数据。
- en: '9.2 Historical accuracy simulation: Backtesting'
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 历史准确性模拟：回测
- en: 'Now you know the right way to measure accuracy of churn forecasts and what
    is typical in churn forecasting. But I ignored an important detail: the observations
    on which you should measure accuracy. As with many parts of the analysis, the
    situation is a little different for churn.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了衡量 churn 预测准确性的正确方法以及 churn 预测中的典型情况。但我忽略了一个重要细节：你应该在哪些观察结果上衡量准确性。与分析的许多部分一样，对于
    churn 来说，情况略有不同。
- en: 9.2.1 What and why of backtesting
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 回测的“什么”和“为什么”
- en: Earlier, I demonstrated the accuracy measurements you learned by calculating
    the accuracy of the forecast on the dataset with which you created the model.
    This demonstration is not the best practice, however; it’s like testing a student
    on questions that they have already seen in the sense that the same customer observations
    were used to fit the model. The best practice in forecasting is to test the accuracy
    of a model on observations that were not used to fit the model. This type of testing
    is known as out-of-sample testing because it tests observations that were not
    in the data sample given to the algorithm for determining the model.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我通过计算使用你创建模型的相同数据集上的预测准确性来演示你学到的准确性度量方法。然而，这种演示并不是最佳实践；从某种意义上说，就像测试一个学生已经见过的题目一样，因为相同的客户观察结果被用来拟合模型。预测的最佳实践是在未用于拟合模型的观察结果上测试模型的准确性。这种类型的测试被称为样本外测试，因为它测试了算法确定模型时未在数据样本中给出的观察结果。
- en: In general, accuracy is lower for new customer observations than for the ones
    used in the model fitting. How different in-sample and out-of-sample accuracy
    are depends on many factors. For regression on churn problems, the difference
    is usually slight; for the machine learning model shown in section 9.5, using
    in-sample observations for testing can create a large overestimate of accuracy.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，新客户观察结果的准确性低于用于模型拟合的观察结果。样本内和样本外准确性的差异取决于许多因素。对于 churn 问题上的回归，差异通常很小；对于第
    9.5 节中展示的机器学习模型，使用样本内观察结果进行测试可以导致对准确性的高估。
- en: TAKEAWAY Forecasting models should be tested on out-of-sample data that was
    not used to fit the model.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 吸取经验：预测模型应该在未用于拟合模型的样本外数据上测试。
- en: 'Do you need to wait to see how well the model predicts new churns on live customers
    to see how accurate it is? Waiting would work, and you should do that, but there’s
    an easier way: hold back some of the observations from the data when you fit the
    model and then test the accuracy on those held-back observations. Then you can
    see how accurate the model would be on new customers it hasn’t seen without waiting
    to get fresh new customers. After testing, you refit the model on all the data
    without holding anything back and use that final version to make the real new
    forecasts on active customers.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要等待看到模型在实时客户上的预测效果如何，以此来判断其准确性吗？等待是可行的，你也应该这样做，但有一个更简单的方法：在拟合模型时，保留一些观测值，然后在这些保留的观测值上测试准确性。这样你就可以看到模型在没有等待获取新客户的情况下，对新客户预测的准确性。测试完成后，你可以在不保留任何观测值的情况下，使用所有数据重新拟合模型，并使用这个最终版本对活跃客户进行真正的预测。
- en: The next question is which data to use and how much you should hold back for
    testing. The most realistic way to test the accuracy of a churn-forecasting model
    is to use a historical simulation. This procedure is called backtesting and is
    illustrated in figure 9.7.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个问题是要使用哪些数据以及你应该保留多少数据用于测试。测试客户流失预测模型准确性的最现实的方法是使用历史模拟。这个过程被称为回测，如图9.7所示。
- en: '![](../Images/9-07.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-07.png)'
- en: Figure 9.7 The backtesting process for measuring forecasting performance
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7 测量预测性能的回测过程
- en: DEFINITION Backtesting is the historical simulation of a forecasting model’s
    accuracy, as though it had been repeatedly fit and then used to forecast out of
    sample for consecutive periods in the past.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：回测是对预测模型准确性的历史模拟，就像它被反复拟合并用于在过去连续的时期内进行样本外预测一样。
- en: 'Here’s how backtesting works:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是回测的工作原理：
- en: Decide on a point in time in the past that is somewhere around one-half to one-third
    of the time in the period spanned by your dataset.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 决定一个过去的时间点，这个时间点大约是你数据集覆盖期间的一半到三分之一的时长。
- en: Use all the observations that correspond to points in time before that date
    to fit your model.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用所有对应于该日期之前时间点的观测值来拟合你的模型。
- en: Use the observations in the time from one to three months after the date you
    chose to test. This procedure tests what the accuracy of your model would have
    been if it were forecasting churn in the past but still forecasts on customer
    data that came in after the model was fit.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用从你选择的测试日期起一至三个月内的观测值。这个程序测试的是，如果模型在过去预测客户流失但仍然对模型拟合后进入的客户数据进行预测，其准确性会是多少。
- en: Assuming that you have more data, advance the target date to the end of your
    test period.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设你拥有更多数据，将目标日期提前到测试期的末尾。
- en: Repeat the process by refitting the model on all the data from the first fit,
    plus the observations you used to test on, and test the next one to three months.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在第一次拟合的所有数据上重新拟合模型，并加上用于测试的观测值，重复这个过程，并对下一个月到三个月进行测试。
- en: My advice for churn forecasting is a bit different from what is taught in most
    data science and statistics courses, which rarely mention backtesting. Students
    usually learn a random shuffling procedure to create out-of-sample tests that
    don’t pay attention to timing. The procedure of backtesting originated in financial
    forecasting on Wall Street. Backtesting was created due to the observation that
    markets are changing all the time, so predictive models perform differently on
    randomly shuffled accuracy tests than on live forecasting. Accuracy tests based
    on a realistic historical simulation do the best job of estimating how a model
    would have done if had been live at the time.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我对客户流失预测的建议与大多数数据科学和统计学课程中所教授的内容略有不同，这些课程很少提及回测。学生们通常学习一种随机洗牌的程序来创建样本外测试，但这些测试并不关注时间因素。回测的程序起源于华尔街的金融预测。回测的创建是由于观察到市场一直在变化，因此预测模型在随机洗牌的准确性测试上的表现与在实际预测上的表现不同。基于现实历史模拟的准确性测试最能准确地估计模型如果在当时是实时运行的话，其表现会如何。
- en: The reason why live-prediction accuracy can differ from a shuffled data test
    is that if economic conditions change, such as at the start of a recession, a
    live model fit before the recession probably won’t predict as well under the new
    recession conditions. For the model to do better, the new conditions have to be
    observed for some time; then the model could be refit. But with a shuffled data
    test, it is as though you fit a model that knows about the recession by observing
    the future before it happened. Such a model can appear to forecast well, but the
    real results will likely be worse than the test.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 实时预测准确度与洗牌数据测试不同的原因在于，如果经济条件发生变化，例如在经济衰退开始时，衰退前的实时模型拟合可能在新衰退条件下预测效果不佳。为了使模型表现更好，新的条件必须观察一段时间；然后可以对模型进行重新拟合。但在洗牌数据测试中，就好像你拟合了一个通过观察未来事件来了解衰退的模型。这样的模型可能看起来预测效果很好，但实际结果可能会比测试更差。
- en: The same reasoning applies to churn forecasting. If your market, product, or
    competition changes during the time spanned by your dataset, it might be hard
    to forecast churn accurately in the time after the change. If you shuffle the
    data, you can get a different result than you would have if you had been forecasting
    for your customers at that time. The most realistic simulation is to have your
    model run through the data and forecast out of sample in the order in which events
    happened. You may not know whether the conditions driving your customer churn
    behavior changed during your period of observation. But what you don’t know can
    hurt you, so backtesting is the best practice. Although the historical simulation
    I described sounds complicated, open source packages take care of all the details
    for you.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的推理适用于客户流失预测。如果你的市场、产品或竞争在数据集覆盖的时间段内发生变化，那么在变化之后准确预测客户流失可能会很困难。如果你对数据进行洗牌，你可能会得到与当时为你的客户进行预测时不同的结果。最现实的模拟是在事件发生顺序中让模型运行并通过数据外样本进行预测。你可能不知道在观察期间驱动你的客户流失行为条件是否发生变化。但你所不知道的可能会对你造成伤害，因此回测是最佳实践。尽管我描述的历史模拟听起来很复杂，但开源包会为你处理所有细节。
- en: 9.2.2 Backtesting code
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 回测代码
- en: Open source Python packages provide functions that run historical simulations
    like the one described in section 9.2.1\. You provide the package your data and
    the type of model you’re fitting and tell it how many tests you want to divide
    your data into.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 开源 Python 包提供运行历史模拟的函数，如第 9.2.1 节所述。你提供数据包你的数据和你要拟合的模型类型，并告诉它你想要将数据分成多少个测试。
- en: Figure 9.8 shows example output from a historical simulation, including the
    lift and the AUC for each out-of-sample test as well as the averages. For the
    simulated dataset, you will probably find that the AUC and lift in the backtest
    are similar to the AUC and lift from the in-sample data, but that will not necessarily
    be the case for a real product dataset.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8 展示了历史模拟的示例输出，包括每个外样本测试的升度和 AUC 以及平均值。对于模拟数据集，你可能会发现回测中的 AUC 和升度与样本内数据的
    AUC 和升度相似，但对于真实产品数据集来说，情况可能并非如此。
- en: '![](../Images/9-08.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-08.png)'
- en: Figure 9.8 Output of backtesting (listing 9.3)
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8 回测输出（列表 9.3）
- en: In figure 9.8, each testing period is known as a split, in reference to the
    fact that the data is split into a dataset for fitting the model and a holdout
    dataset for testing.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 9.8 中，每个测试周期被称为一个分割，这指的是数据被分割成用于拟合模型的数据库和用于测试的保留数据集。
- en: DEFINITION Split is a generic term for the division of a dataset into separate
    parts for model fitting and testing.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：分割是将数据集划分为单独的部分以进行模型拟合和测试的通用术语。
- en: 'Listing 9.3 contains the Python code that produced the output shown in figure
    9.8\. This listing contains many of the same elements as the regression fitting
    code in chapter 8 and the accuracy measurements discussed in section 9.1\. But
    there are three important new classes from the sklearn.model_selection package:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.3 包含了生成图 9.8 所示输出的 Python 代码。此列表包含了许多与第 8 章中回归拟合代码和第 9.1 节中讨论的准确度测量相同的元素。但来自
    sklearn.model_selection 包的三个重要新类：
- en: '`GridSearchCV`—A utility that performs a variety of tests on forecasting models.
    The name of the class derives from the fact that it specializes in searching for
    the best models through a process known as cross-validation (the `CV` in `GridSearchCV`).
    You’ll learn more about cross-validation in section 9.4; for now, you use the
    object to test a single model.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GridSearchCV`—一个执行各种预测模型测试的实用工具。类名来源于它通过交叉验证（`GridSearchCV` 中的 `CV`）的过程专门搜索最佳模型的事实。你将在第
    9.4 节中了解更多关于交叉验证的内容；现在，你使用该对象测试单个模型。'
- en: '`TimeSeriesSplit`—A helper object that tells `GridSearchCV` that the testing
    should be performed by historical simulation, rather than another type of test
    (typically, random shuffling). The name of the class is `TimeSeriesSplit`, but
    I recommend that you stick with the original Wall Street term that your business
    colleagues are most likely to understand: backtesting.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TimeSeriesSplit`—一个辅助对象，告诉 `GridSearchCV` 测试应通过历史模拟进行，而不是另一种类型的测试（通常是随机洗牌）。类名为
    `TimeSeriesSplit`，但我建议你坚持使用你商业同事最可能理解的原始华尔街术语：回测。'
- en: '`scorer`—An object that wraps a scoring function. When you use a nonstandard
    scoring function with `GridSearchCV,` you must wrap it in such an object. This
    task is easy: call the `make_scorer` function, provided by the package for this
    purpose. You pass your scoring function as a parameter when making the `scorer`
    object. In listing 9.3, this technique is used for the top decile lift calculation.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scorer`—一个包装评分函数的对象。当你使用 `GridSearchCV` 的非标准评分函数时，你必须将其包装在这样的对象中。这个任务很简单：调用为此目的提供的
    `make_scorer` 函数。你通过在创建 `scorer` 对象时传递评分函数作为参数。在列表 9.3 中，这种技术用于计算最高十分位的提升。'
- en: Other than `TimeSeriesSplit`, the parameters required to create `GridSearchCV`
    are the regression model object and a dictionary containing the two accuracy measurement
    functions. The lift measurement function is passed with the scorer object, and
    the AUC scoring function is passed as a string (naming it because this scorer
    object is a Python standard).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 `TimeSeriesSplit`，创建 `GridSearchCV` 所需的参数包括回归模型对象和一个包含两个准确度测量函数的字典。提升测量函数通过评分对象传递，AUC
    评分函数作为字符串传递（因为此评分对象是 Python 标准）。
- en: 'Other parameters that control the details of the test include the following:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 控制测试细节的其他参数包括以下内容：
- en: '`return_train_score`—Controls whether to also test for in-sample accuracy (also
    known as training accuracy)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`return_train_score`—控制是否也要测试样本内准确度（也称为训练准确度）'
- en: '`param_grid`—Tests parameters to find a better model (a subject you learn more
    about in section 9.4)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`param_grid`—测试参数以找到更好的模型（你将在第 9.4 节中了解更多关于此内容）'
- en: '`refit`—Tells the model to refit a final model on all the data (which you will
    do in section 9.4)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`refit`—告诉模型在所有数据上重新拟合一个最终模型（你将在第 9.4 节中这样做）'
- en: 'In other respects, listing 9.3 combines elements you have already seen: loading
    and preparing data, creating a regression model, and saving results. One thing
    to note is that the test is triggered by calling the `fit` function on `GridSearchCV`
    rather than on the regression object itself.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他方面，列表 9.3 结合了你已经看到的元素：加载数据和准备数据、创建回归模型和保存结果。需要注意的是，测试是通过在 `GridSearchCV`
    上调用 `fit` 函数而不是在回归对象本身上触发的。
- en: Listing 9.3 Backtesting with Python time-series cross-validation
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.3 使用 Python 时间序列交叉验证进行回测
- en: '[PRE4]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ① These classes run the tests.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ① 这些类运行测试。
- en: '② Defines a custom score function: the lift score'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ② 定义了一个自定义的评分函数：提升分数
- en: ③ Reuses listing 8.2 to reload data
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 重新使用列表 8.2 来重新加载数据
- en: ④ Reuses listing 9.2 to calculate the lift
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 重新使用列表 9.2 来计算提升
- en: ⑤ Loads the data, keeping the outcome as a churn flag
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 加载数据，将结果作为流失标志
- en: ⑥ Creates an object that controls the splits
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 创建一个控制拆分的对象
- en: ⑦ Creates a scorer object that wraps the lift function
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 创建一个包装提升函数的评分对象
- en: ⑧ Creates a dictionary that defines the scoring functions
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 创建一个字典，定义评分函数
- en: ⑨ Creates a new LogisticRegression object
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 创建一个新的 LogisticRegression 对象
- en: ⑩ Creates a GridSearchCV object
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 创建一个 GridSearchCV 对象
- en: ⑪ Runs the test
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: ⑪ 运行测试
- en: ⑫ Saves the results in a DataFrame
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ⑫ 将结果保存到 DataFrame 中
- en: 'You should run listing 9.3 on your own data from the social network simulation
    (chapter 8) and confirm that your result is similar to the one in figure 9.8\.
    With the Python wrapper program, the command to run is the following:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在社交网络模拟（第 8 章）的自己的数据上运行列表 9.3，并确认你的结果与图 9.8 中的结果相似。使用 Python 包装程序，运行命令如下：
- en: '[PRE5]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 9.2.3 Backtesting considerations and pitfalls
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 回测考虑事项和陷阱
- en: For the simulation, only two tests were used because the entire dataset spans
    only six months. If more tests were specified for a larger dataset, the additional
    results would appear as additional columns in the same file. But in backtesting
    for churn prediction, it is typical to test with a few splits. By contrast, the
    procedure you may have learned for randomly shuffled tests usually calls for 10
    random tests or more. You should pick the number of splits based on the length
    of time spanned by your data sample and how often you would be likely to refit
    the model.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 对于模拟，只使用了两个测试，因为整个数据集只覆盖了六个月。如果为更大的数据集指定了更多的测试，额外的结果将作为同一文件中的额外列出现。但在回测预测流失时，通常只使用几个分割点进行测试。相比之下，你可能已经学会的随机打乱测试的程序通常需要10个或更多的随机测试。你应该根据你的数据样本覆盖的时间长度以及你可能会重新拟合模型的频率来选择分割点的数量。
- en: Although you may optimistically think you would refit a new model every month,
    in reality, many companies “set it and forget it.” Even if you are very determined,
    you will probably refit your own model only a few times a year after you finish
    the initial development. (Refitting the simulation model every two months may
    be overly optimistic; I use this example for demonstration purposes.) Also, frequent
    model changes are confusing to businesspeople. In fact, some companies mandate
    an annual refitting of production models to prevent “moving the goal posts” when
    business metrics are tied to the model outputs. For example, if customer support
    representative compensation is linked to reducing churn probability, then the
    model must remain fixed for the fiscal year.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可能乐观地认为你每个月都会重新拟合一个新的模型，但现实中，许多公司“设置后即忘”。即使你非常坚定，在你完成初步开发后，你可能一年内只重新拟合自己的模型几次。（每两个月重新拟合一次模拟模型可能是过于乐观的；我使用这个例子是为了演示目的。）此外，频繁的模型更改会让商业人士感到困惑。事实上，一些公司要求每年重新拟合生产模型，以防止当业务指标与模型输出相关联时“移动目标”。例如，如果客户支持代表的薪酬与降低流失概率相关联，那么模型必须在整个财政年度保持固定。
- en: If you’re worried that using a few splits for the test is not as rigorous as
    using 10 tests, don’t worry. These measurements should be made with the spirit
    of agility and parsimony that I advocated in chapter 1\. Using a few tests will
    tell you whether you are predicting well or have work to do on your model; doing
    more tests wastes time. Also, if a high number of test splits implies an unrealistic
    rate of refitting your model when it is live, your test may overestimate the accuracy
    you would achieve in the real world, where you refit less often.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你担心使用几个分割点进行测试不如使用10个测试那样严格，请不要担心。这些测量应该以我在第一章中提倡的敏捷性和简约性精神来进行。使用几个测试就能告诉你是否预测得很好，或者是否需要在你的模型上做更多的工作；做更多的测试是浪费时间。此外，如果大量的测试分割意味着在模型运行时进行不切实际的模型重新拟合率，你的测试可能会高估你在现实世界中实现的准确性，而在现实世界中你重新拟合的频率较低。
- en: One other pitfall to be aware of in backtesting for accuracy is the possibility
    of adverse effects due to mistakes in how times are recorded in your database
    or data warehouse. This problem occurs mainly if events, subscriptions, or other
    customer data records were backdated when they were added to your database. In
    that case, you would calculate historical metrics and run your test with information
    that may not be available in real time for live forecasting on active customers.
    This type of error is known as a lookahead error or bias in forecasting.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在回测准确性时需要注意的一个其他陷阱是由于在数据库或数据仓库中记录时间时的错误而可能产生的负面影响。这个问题主要发生在事件、订阅或其他客户数据记录在数据库中添加时被回溯时。在这种情况下，你会计算历史指标，并使用可能不会在实时预测活跃客户时可用信息来运行测试。这种错误被称为预测中的前瞻性错误或偏差。
- en: DEFINITION A lookahead bias is an error that occurs when you estimate accuracy
    in a historical simulation using information that would not be available in real
    time for forecasting on active customers.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** 前瞻性偏差是在使用在实时预测活跃客户时不会可用信息的历史模拟来估计准确性时发生的一种错误。'
- en: WARNING Backdated records for events, subscriptions, or other customer data
    can lead to lookahead bias in your forecasts and cause the backtest to appear
    more accurate than what you would achieve in real-time forecasting.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告** 事件、订阅或其他客户数据的回溯记录可能导致你的预测中出现前瞻性偏差，并使回测看起来比你在实时预测中实现的准确性更高。'
- en: The fix for lookahead bias is to be aware of any backdating of records in your
    database and, if necessary, to correct it with custom lags in the event selection
    when you calculate metrics. If you know that all events are loaded into the data
    warehouse with a one-week delay and backdated to the time the event occurred,
    for example, you should include this delay when you calculate your metrics. The
    trick is that you won’t notice the one-week delay when you run your historical
    analysis, but you will when you try to forecast churn probabilities in real time
    and find that all your metrics are a week old.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 解决前瞻性偏差的方法是意识到你数据库中记录的任何回溯，并在必要时，在计算指标的事件选择时使用自定义滞后来纠正它。例如，如果你知道所有事件都是在一周后加载到数据仓库中，并且回溯到事件发生的时间，你应该在计算你的指标时包括这个延迟。技巧是，当你运行历史分析时，你不会注意到一周的延迟，但当你尝试实时预测客户流失概率时，你会发现自己所有的指标都过时了一周。
- en: 9.3 The regression control parameter
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 回归控制参数
- en: After measuring the accuracy of your forecasts, you’re probably wondering whether
    there is any way to be more accurate. Another problem I’ve mentioned is that a
    regression can result in many small weights on unimportant metrics. You have a
    way to adjust the regression that can help with both issues.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在测量你预测的准确性之后，你可能想知道是否有任何方法可以使预测更准确。我提到过的另一个问题是，回归可能导致许多小的权重出现在不重要的指标上。你有一种调整回归的方法，可以帮助解决这两个问题。
- en: 9.3.1 Controlling the strength and number of regression weights
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 控制回归权重的强度和数量
- en: In chapter 8, I mentioned that regression models can have too many small weights
    and that you can remove them. This technique is illustrated in figure 9.9, which
    shows the relative size of the regression weights from the social network simulation
    (figure 8.7 in chapter 8). Most of the weights are greater than 0.1, one weight
    is 0.00, and two weights are 0.01; those 0.01 weights are extraneous. Two small
    weights may not seem like a problem, but remember that real data can have a dozen
    or more smaller weights, which can make it harder for you and the businesspeople
    to understand the result.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在第8章中，我提到回归模型可能会有太多很小的权重，并且你可以移除它们。这种技术在第9.9图中有说明，该图显示了来自社交网络模拟（第8章中的第8.7图）的回归权重的相对大小。大多数权重都大于0.1，一个权重是0.00，两个权重是0.01；这些0.01的权重是多余的。两个小的权重可能看起来不是问题，但请记住，真实数据可能有十几个或更多的更小的权重，这可能会使你和企业人士更难理解结果。
- en: '![](../Images/9-09.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-09.png)'
- en: Figure 9.9 Regressions result in small weights that can be removed.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.9 回归产生的小权重可以被移除。
- en: It might seem that the simplest thing to do would be to set those very small
    weights to zero. But the decision about which weights to keep and which to remove
    may not be so clear-cut. Also, if some weights are removed, others should be readjusted.
    The regression algorithm has a more principled way to handle this situation with
    a parameter controlling the total weight available for the algorithm to distribute
    across all the metrics.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 可能看起来最简单的事情就是将这些非常小的权重设置为零。但关于哪些权重要保留，哪些要移除的决定可能并不那么明确。此外，如果移除了某些权重，其他权重也应该重新调整。回归算法有一种更原则性的方法来处理这种情况，即通过一个参数来控制算法可用于分配到所有指标的总权重。
- en: When the control parameter is set to a high value, the regression weights tend
    to be larger, and there will be fewer zeros. When the control parameter is set
    to a low value, the weights tend to be lower, and the lower the parameter is set,
    the more weights will be zero. The precise weights are optimized by the algorithm.
    Unfortunately, this controlling parameter has no good, generally accepted name.
    Because there is only one relevant parameter for the regression, I will call it
    the control parameter. Conveniently, the Python code refers to the parameter as
    (capital) `C`, so calling it the control parameter is clear.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 当控制参数设置为高值时，回归权重往往较大，零的个数较少。当控制参数设置为低值时，权重往往较低，参数设置得越低，零的权重越多。精确的权重由算法优化。不幸的是，这个控制参数没有好、普遍接受的名字。因为回归只有一个相关的参数，我将称之为控制参数。方便的是，Python代码将这个参数称为（大写）`C`，所以称之为控制参数是清晰的。
- en: DEFINITION The regression control parameter sets the size and number of weights
    that result from a regression. Higher `C` settings yield more and higher weights,
    and lower `C` settings yield fewer and lower weights.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 回归控制参数设置回归产生的权重的大小和数量。更高的`C`设置会产生更多和更大的权重，而更低的`C`设置会产生更少和更小的权重。
- en: The Python nomenclature `C` derives from something called a cost parameter in
    the regression algorithm. It’s called a cost because the algorithm includes a
    penalty cost for the size of the weights. But the documentation states that the
    cost is 1/`C`, so `C` is the inverse or reciprocal of the cost. It is confusing
    to have a parameter that you call the cost, but where the cost is higher for lower
    parameter values, so I stick with calling it a control parameter, or `C.`
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的命名 `C` 来自回归算法中称为成本参数的东西。它被称为成本，因为算法包括对权重大小的惩罚成本。但是文档中说明成本是 1/`C`，所以
    `C` 是成本的倒数或倒数。有一个参数被称为成本，但成本对于较低的参数值更高，这很令人困惑，所以我坚持称其为控制参数，或 `C`。
- en: 9.3.2 Regression with the control parameter
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 使用控制参数的回归
- en: Listing 9.4 shows a new version of the regression using the control parameter.
    This listing reuses all the helper functions from listing 8.2 (chapter 8), so
    there’s not much to it. The only difference is that listing 9.4 takes a value
    for `C` in the function call, passes it in when it creates the object, and then
    passes it as an extension to the output files. The output files are the same as
    those produced by listing 8.2.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.4 展示了使用控制参数的新版本的回归。此列表重用了列表 8.2（第 8 章）中的所有辅助函数，因此内容不多。唯一的区别是列表 9.4 在函数调用中取
    `C` 的值，在创建对象时传递它，并将其作为扩展传递给输出文件。输出文件与列表 8.2 生成的文件相同。
- en: 'You should run listing 9.4 on your simulated data. To see the effect of setting
    the `C` parameter, you can run three versions. These three versions have the `C`
    parameter set to 0.02, 0.01 and 0.005, respectively. Run these versions with the
    Python wrapper program, using the `version` argument as follows:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在您的模拟数据上运行列表 9.4。为了看到设置 `C` 参数的效果，您可以运行三个版本。这三个版本的 `C` 参数分别设置为 0.02、0.01
    和 0.005。使用 Python 包装程序运行这些版本，如下所示使用 `version` 参数：
- en: '[PRE6]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The results of running the two versions of listing 9.4 are compared in figure
    9.10, along with the result from the original regression (listing 8.2):'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 9.10 中比较了运行列表 9.4 的两个版本的结果，以及原始回归（列表 8.2）的结果：
- en: In the original listing, all but one weight is nonzero, and the highest-magnitude
    weight is 0.68.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在原始列表中，除了一个权重外，所有权重均不为零，最大权重的绝对值为 0.68。
- en: With the `C` parameter set to 0.02, four weights are zero, and the highest-magnitude
    weight is 0.61.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 `C` 参数设置为 0.02 时，四个权重为零，最大权重的绝对值为 0.61。
- en: With the `C` parameter set to 0.005, eight weights are zero, and the highest
    magnitude weight is 0.42.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 `C` 参数设置为 0.005 时，八个权重为零，最大权重的绝对值为 0.42。
- en: '![](../Images/9-10.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-10.png)'
- en: Figure 9.10 Comparison of regression weights resulting from different values
    of the control parameter, `C`
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.10 比较了不同控制参数 `C` 值导致的回归权重
- en: This overall pattern is what happens as the `C` parameter is reduced.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `C` 参数减少时，整体模式就是这样发生的。
- en: Listing 9.4 Regression using the control parameter `C`
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.4 使用控制参数 `C` 的回归
- en: '[PRE7]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ① This listing uses all the helper functions from listing 8.2.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ① 此列表使用了列表 8.2 中的所有辅助函数。
- en: ② There is an additional parameter, C, for the regression.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ② 回归还有一个额外的参数，C。
- en: ③ Passes the parameter when the regression is created
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 在创建回归时传递参数
- en: ④ Fits the regression, as in listing 8.2
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 按照列表 8.2 进行回归拟合
- en: ⑤ Adds the parameter to the result filename
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 将参数添加到结果文件名中
- en: ⑥ Calls the save functions
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 调用保存函数
- en: Note that the response of the algorithm to the `C` parameter setting is irregular.
    Changing the `C` parameter from 1 to 0.02 removes two additional metrics from
    the regression results, and a further reduction from point 0.02 to 0.005 removes
    three more. The way that the parameter is defined in the algorithm, you need to
    consider values of the control parameter that vary in a range below 1.0 (the default)
    and above zero, but the impact varies on a logarithmic scale as the parameter
    gets smaller.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，算法对 `C` 参数设置的响应是不规则的。将 `C` 参数从 1 减少到 0.02 会从回归结果中移除两个额外的指标，而从 0.02 减少到 0.005
    会再移除三个。根据算法中参数的定义，您需要考虑控制参数在 1.0（默认值）以下和零以上的变化范围，但影响随着参数的减小而以对数尺度变化。
- en: 'When I say that the impact varies on a logarithmic scale, I mean that changes
    in the parameter must be significantly different in the logarithm of the parameter
    to make a big difference in the algorithm. The impact of going from 1.0 to 0.9
    is not going to be much, and the impact of going from 1 to 0.1 is likely to be
    about the same as going from 0.1 to 0.01\. It is inefficient to test the range
    of parameters between 1 and 10 on a linear scale like [1, 0.9, 0.8, ..., 0.1]
    because the best value can be below 0.1, and you will probably not see that much
    change between values like 0.9 and 0.8\. Instead, you should test parameters decreasing
    by a divisive factor, such as dividing by 10: [1, 0.1, 0.01, 0.001]. How small
    you have to go to see the right impact depends on your data. If you want to do
    a more detailed search of the parameter space, divide by a smaller factor like
    2, as in [0.64, 0.32, 0.16, ...].'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说影响在对数尺度上变化时，我的意思是参数的变化必须在参数的对数中显著不同，才能在算法中产生重大影响。从 1.0 到 0.9 的变化不会太大，而从 1
    到 0.1 的变化可能大约与从 0.1 到 0.01 的变化相同。在像 [1, 0.9, 0.8, ..., 0.1] 这样的线性尺度上测试 1 和 10
    之间的参数范围是不高效的，因为最佳值可能低于 0.1，而且你可能在 0.9 和 0.8 这样的值之间看不到太大的变化。相反，你应该测试以除数因子递减的参数，例如除以
    10：[1, 0.1, 0.01, 0.001]。你需要减小到多小才能看到正确的影响取决于你的数据。如果你想更详细地搜索参数空间，可以除以更小的因子，如 2，例如
    [0.64, 0.32, 0.16, ...]。
- en: TAKEAWAY When you check smaller values of `C`, you must check values that are
    orders of a magnitude smaller than 1.0\. Usually, a `C` parameter around 1.0 assigns
    weights to all (or most) of the metrics that are even a little bit related to
    churn. To reduce the number of nonzero weights, try values of `C` like 0.1, 0.01,
    and 0.001.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收要点 当你检查 `C` 的较小值时，你必须检查比 1.0 小一个数量级的值。通常，一个大约为 1.0 的 `C` 参数会给所有（或大多数）与流失有一点关系的指标分配权重。为了减少非零权重的数量，尝试
    `C` 的值如 0.1、0.01 和 0.001。
- en: 9.4 Picking the regression parameter by testing (cross-validation)
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 通过测试（交叉验证）选择回归参数
- en: At this point, you should be wondering how low you should go with the control
    parameter. It makes sense to remove metrics with small weights, but at what point
    should you stop? This decision is best made by looking at the accuracy that results
    from each parameter setting.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能想知道控制参数应该降低到多低。删除权重小的指标是有意义的，但应该在什么点停止？这个决定最好通过查看每个参数设置产生的准确性来做出。
- en: 9.4.1 Cross-validation
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.1 交叉验证
- en: It should come as no surprise that you can remove metrics with small weights
    from a regression, and it won’t make much difference in the accuracy. (Because
    these weights are the small weights, they don’t make much difference.) A logical
    approach is to remove weights until you find that doing so harms accuracy. What
    can be more surprising is that removing some metrics improves accuracy.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从回归中删除权重小的指标，这对准确性影响不大，这应该不会让你感到惊讶。（因为这些权重是小的，所以它们没有太大影响。）更令人惊讶的是，删除一些指标可以提高准确性。
- en: You’re going to take different values of the `C` parameter and run a backtest
    with the parameter to see how accurate the resulting models are. At the same time,
    you can check how many metrics get zero and nonzero weights in the regression.
    Figure 9.11 illustrates this process. The general term for this type of procedure
    in machine learning and statistics is cross-validation.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 你将尝试不同的 `C` 参数值，并使用该参数进行回测，以查看生成的模型有多准确。同时，你可以检查回归中有多少指标获得了零和非零权重。图 9.11 展示了这一过程。在机器学习和统计学中，这类过程的通用术语是交叉验证。
- en: '![](../Images/9-11.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-11.png)'
- en: Figure 9.11 Cross-validation to select the regression parameter
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11 选择回归参数的交叉验证
- en: DEFINITION Cross-validation is the process of optimizing a forecasting model
    by comparing the accuracy and other characteristics of models created with different
    parameters.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 交叉验证是通过比较使用不同参数创建的模型的准确性和其他特征来优化预测模型的过程。
- en: Cross-validation is a common task in data science and machine learning, and
    what the `CV` means in the `GridSearchCV` object you were introduced to earlier.
    The `GridSearch` part of the name refers to the fact that a typical cross-validation
    works on a sequence or multiple sequences of parameters. If there were two parameters,
    each with its own sequence of values, the combinations of those two sequences
    would define a grid. In fact, there can be any number of parameters. For the regression
    model, you will do a cross-validation of one parameter. Later, you use higher-dimensional
    cross-validation for a machine learning model.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是数据科学和机器学习中的一个常见任务，而`CV`在您之前介绍的`GridSearchCV`对象中的含义。名称中的`GridSearch`部分指的是典型的交叉验证是在一系列或多个参数序列上进行的。如果有两个参数，每个参数都有其自己的值序列，那么这两个序列的组合将定义一个网格。实际上，可以有任意数量的参数。对于回归模型，您将进行一个参数的交叉验证。稍后，您将使用更高维度的交叉验证来进行机器学习模型。
- en: 9.4.2 Cross-validation code
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.2 交叉验证代码
- en: 'Figure 9.12 shows the main result of cross-validation, which plots the AUC,
    the lift, and the number of weights that you get when running the regression for
    a sequence of values from the `C` parameter. This result confirms that small-weight
    metrics can be removed, and accuracy will not suffer: the number of metrics can
    be reduced from 13 to 9 before any noticeable change in accuracy occurs. In the
    simulation, there was a slight gain in the lift, but no gain in the AUC when the
    less important metrics were removed.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.12显示了交叉验证的主要结果，它绘制了运行回归时从`C`参数的值序列中得到的AUC、提升和权重数量。这个结果证实了可以移除小权重指标，而准确度不会受到影响：在准确度发生任何明显变化之前，指标的数量可以从13减少到9。在模拟中，当移除不那么重要的指标时，提升略有增加，但AUC没有增加。
- en: '![](../Images/9-12.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![图9.12交叉验证结果图](../Images/9-12.png)'
- en: Figure 9.12 Cross-validation result plot
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.12 交叉验证结果图
- en: 'Listing 9.5 contains the code that produced figure 9.12\. The listing contains
    multiple function definitions, but note that much of the code is for plotting
    and analysis. The Python open source package takes care of the cross-validation
    in a few lines. The functions in listing 9.5 follow:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.5包含了生成图9.12的代码。列表中包含多个函数定义，但请注意，大部分代码是用于绘图和分析的。Python开源包只需几行代码就处理了交叉验证。列表9.5中的函数如下：
- en: '`crossvalidate_regression`—This main function performs cross-validation, and
    it is almost the same as that in listing 9.4\. The most important difference is
    that a sequence of `C` parameter values is passed instead of a single value. The
    other difference is that after the `fit` function on the `GridSearchCV` object
    returns, helper functions are called to perform additional analysis and to save
    the results.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`crossvalidate_regression`—这个主要函数执行交叉验证，几乎与列表9.4中的相同。最重要的区别是传递了一个`C`参数值的序列，而不是单个值。另一个区别是在`GridSearchCV`对象的`fit`函数返回后，调用辅助函数执行额外的分析和保存结果。'
- en: '`test_n_weights`—The `GridSearchCV` object tests each parameter for the accuracy
    of the model on the backtest, but it doesn’t test the number of weights returned
    by the regression. A separate loop is called to fit a regression at each `C` parameter
    in the sequence, and the number of nonzero weights is counted. This is done on
    the full dataset, so it is not a backtest but a measurement of the final model.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_n_weights`—`GridSearchCV`对象在回测中对每个参数进行模型准确性的测试，但它不会测试回归返回的权重数量。调用一个单独的循环来在每个`C`参数的序列中拟合回归，并计算非零权重的数量。这是在完整数据集上进行的，因此它不是一个回测，而是对最终模型的一个测量。'
- en: '`plot_regression_test`—This function creates the plot shown in figure 9.12
    by combining the results for AUC, lift, and the number of metrics with nonzero
    weights.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plot_regression_test`—这个函数通过结合AUC、提升和具有非零权重的指标数量，创建了图9.12所示的图表。'
- en: '`one_subplot`—This helper function creates and formats each subplot.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`one_subplot`—这个辅助函数创建并格式化每个子图。'
- en: Listing 9.5 also saves the results from figure 9.12 in a .csv file, shown in
    figure 9.13\. This result is the output from `GridsearchCV` (as in section 9.2),
    but instead of a single row, there is one row in the table per value of the `C`
    parameter that was tested. There is also an extra column with the result from
    testing the number of weights. The output from the cross-validation with multiple
    parameters shows that the columns labeled rank_test_lift and rank_test_AUC refer
    to the ranking of the models fit with the different parameter values on the accuracy
    metrics. (Some of these columns may have seemed extraneous when you first saw
    them in section 9.2.)
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.5还保存了图9.12的结果，如图9.13所示。这个结果是`GridsearchCV`（如第9.2节所述）的输出，但不是单行，而是每个测试的`C`参数值在表中占一行。还有一个额外的列，包含测试权重数量的结果。多个参数的交叉验证输出显示，标记为rank_test_lift和rank_test_AUC的列是指具有不同参数值的模型在准确度指标上的排名。（当你在第9.2节首次看到这些列时，其中一些可能看起来是多余的。）
- en: '![](../Images/9-13.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-13.png)'
- en: Figure 9.13 Cross-validation result table
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13 交叉验证结果表
- en: 'You should run listing 9.5 with the following command-line arguments to generate
    your own plot like figure 9.12 and a .csv file like figure 9.13:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 您应使用以下命令行参数运行列表9.5以生成自己的图表，如图9.12所示，并生成一个类似于图9.13的.csv文件：
- en: '[PRE8]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Listing 9.5 Regression `C` parameter cross-validation
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.5 回归`C`参数交叉验证
- en: '[PRE9]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ① The number of test splits is a parameter.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 测试拆分的数量是一个参数。
- en: ② The score function wraps the lift in a scorer object.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ② 分数函数将升力包装在评分对象中。
- en: ③ Instead of one C parameter, tests a list
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 不是测试一个C参数，而是测试一个列表
- en: ④ Creates the cross-validation object, and calls the fit method
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 创建交叉验证对象，并调用fit方法
- en: ⑤ Puts the result in a DataFrame
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 将结果放入DataFrame
- en: ⑥ Adds another column with the result of the weight test
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 添加另一个包含权重测试结果的列
- en: ⑦ Makes a plot with plot_ regression_ test
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用plot_ regression_ test绘制一个图表
- en: ⑧ Tests the number of weights for different C parameters
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 测试不同C参数的权重数量
- en: ⑨ Loops over the parameters
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 9.9 循环遍历参数
- en: ⑩ Creates a logistic regression with one value of C
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个C值创建逻辑回归
- en: ⑪ Fits the model
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合模型
- en: ⑫ Counts the number of nonzero weights
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ⑫ 计算非零权重的数量
- en: ⑬ Makes a plot from the result of the regression tests
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 从回归测试的结果中制作一个图表
- en: ⑭ String version of C parameter to use as the x-axis
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: C参数的字符串版本，用作x轴
- en: ⑮ Calls a helper function to plot the AUC
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ⑮ 调用辅助函数以绘制AUC
- en: ⑯ Adds a title above the first of three subplots
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在三个子图中的第一个上方添加标题
- en: ⑰ Calls a helper function to plot the lift
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 调用辅助函数以绘制升力
- en: ⑱ Calls a helper function to plot the number of nonzero weights
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: ⑱ 调用辅助函数以绘制非零权重的数量
- en: ⑲ Adds an x-label after the third subplot
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在第三个子图后添加一个x标签
- en: ⑳ Starts the subplot given by the parameter
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 开始由参数指定的子图
- en: ㉑ Plots the named variable against the string version of C
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 将命名变量与C参数的字符串版本进行绘图
- en: ㉒ Sets the y-limits based on the parameters
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 根据参数设置y轴限制
- en: ㉓ Sets the ticks based on the parameters
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 根据参数设置刻度
- en: 9.4.3 Regression cross-validation case studies
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.3 回归交叉验证案例研究
- en: Figure 9.14 shows examples of regression cross-validation from real company
    case studies. The number of nonzero weights is shown as a percentage rather than
    a count; otherwise, these results are read the same way as figure 9\. 12.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.14显示了来自真实公司案例研究的回归交叉验证示例。非零权重的数量以百分比而不是计数显示；否则，这些结果与图9.12的阅读方式相同。
- en: '![](../Images/9-14.png)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-14.png)'
- en: Figure 9.14 Cross-validation case study results
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.14 交叉验证案例研究结果
- en: 'Following are some interesting features of the case study results:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些案例研究结果的有趣特征：
- en: The forecasts have AUC in the range 0.6 to 0.8.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的AUC范围在0.6到0.8之间。
- en: The forecasts have lift in the range 2.0 to 3.5.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测的升力范围在2.0到3.5之间。
- en: For two of the three case studies, a noticeable improvement in AUC and lift
    occurs when many metrics get zero weight from the regression. (This result is
    a clear example of simplicity also benefiting accuracy.) In these cases, the optimal
    values of the `C` parameter are in the range of around 0.02 to 0.08\. The improvement
    over including all the features is a few percentage points of AUC.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于三个案例研究中的两个，当许多指标从回归中获得零权重时，AUC和升力有明显的改进。（这是一个简单性也有利于准确性的明显例子。）在这些情况下，`C`参数的最佳值在约0.02到0.08的范围内。与包含所有特征相比，AUC的改进是几个百分点。
- en: For the third simulation, the optimal AUC is achieved with all the metrics;
    removing any metrics results in significant loss of accuracy.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于第三次模拟，所有指标都达到了最优的AUC；删除任何指标都会导致准确性的显著下降。
- en: These results are typical, but you may see more diversity in real case studies
    than I can present here.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果是典型的，但你在实际案例研究中可能会看到比我这里呈现的更多样性。
- en: 9.5 Forecasting churn risk with machine learning
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.5 使用机器学习预测流失风险
- en: So far, you have learned about forecasting churn with a regression in which
    predictions are made by multiplying metrics by a set of weights. You can also
    predict churn with other kinds of forecasting models that are collectively known
    as machine learning. There is no official definition of what constitutes a machine
    learning model, but for the purpose of this book, I use the following.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经学习了使用回归进行预测，其中预测是通过将指标乘以一组权重来进行的。你也可以使用其他类型的预测模型来预测流失，这些模型统称为机器学习。没有官方的定义来界定什么是机器学习模型，但为了本书的目的，我使用以下定义。
- en: 'DEFINITION A machine learning model is any predictive algorithm that has the
    following two characteristics: (1) the algorithm learns to make the prediction
    by processing sample data (as compared with making predictions with rules set
    by a human programmer), and (2) the algorithm is not the regression algorithm.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：机器学习模型是指任何具有以下两个特征的预测算法：（1）算法通过处理样本数据来学习做出预测（与使用由人类程序员设置的规则进行预测相比），（2）算法不是回归算法。
- en: The second condition may seem strange because the regression algorithm certainly
    meets the first condition. The distinction is historical because the regression
    approach predates machine learning methods by decades.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个条件可能看起来很奇怪，因为回归算法显然满足第一个条件。这种区别是历史性的，因为回归方法比机器学习方法早了几十年。
- en: 9.5.1 The XGBoost learning model
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.1 XGBoost学习模型
- en: This book covers only one machine learning algorithm—XGBoost—but the same techniques
    for fitting the model and forecasting apply to most other algorithms you may consider.
    The XGBoost algorithm is based on the concept of a decision tree, illustrated
    in figure 9.15.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书只涵盖了一个机器学习算法——XGBoost，但拟合模型和预测的技术同样适用于你可能会考虑的多数其他算法。XGBoost算法基于决策树的概念，如图9.15所示。
- en: '![](../Images/9-15.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9-15.png)'
- en: Figure 9.15 Making predictions with a tree of rules
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.15 使用规则树进行预测
- en: DEFINITION A decision tree is an algorithm for predicting an outcome (such as
    a customer’s churning or not churning) that consists of a binary tree made up
    of rules or tests.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：决策树是一种预测结果（例如客户的流失或未流失）的算法，它由由规则或测试组成的二叉树组成。
- en: Each test in a decision tree takes a single metric and checks whether it is
    greater than or less than a predetermined cut point. The prediction for an observation
    (of a customer) is determined by starting at the root of the tree and performing
    the first test. The result of the test determines which of the two branches to
    follow from the node leading to one of the second-level tests. The result of all
    the tests determines a path through the tree, and each leaf of the tree has a
    designated prediction.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树中的每个测试都只取一个指标，并检查它是否大于或小于一个预定的切割点。对于观察结果（例如客户的观察结果）的预测是通过从树的根开始并执行第一个测试来确定的。测试的结果决定了从节点到二级测试的哪个分支进行。所有测试的结果确定了一条通过树的路，并且树的每个叶子节点都有一个指定的预测。
- en: Small decision trees seem to be simple, and they were once considered to be
    easy-to-interpret machine learning models. But in practice, large decision trees
    for datasets with many metrics become hard to interpret. Fortunately, no one has
    to read the rules in the tree to make a prediction.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 小决策树看起来很简单，它们曾经被认为是易于理解的机器学习模型。但在实践中，对于具有许多指标的数据库，大型决策树变得难以解释。幸运的是，没有人需要阅读树中的规则来做出预测。
- en: An algorithm is used to test metrics and decide on the cut points to optimize
    performance when making predictions using the sample data. If a backtest shows
    that the results are accurate, you can make predictions by using a decision tree
    without being too concerned about the substance of the rules. Methods to interpret
    a decision tree exist, but they are beyond the scope of this book. If you have
    more than a few metrics, understanding the influence of metrics on the likelihood
    of churn is best done through the grouping and regression methods shown in earlier
    chapters, so I won’t spend time on interpreting decision trees.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用样本数据进行预测时，使用算法测试指标并确定切点以优化性能。如果回测显示结果准确，你可以使用决策树进行预测，而不必过于关注规则的实质。存在解释决策树的方法，但它们超出了本书的范围。如果你有多个指标，最好通过前面章节中展示的分组和回归方法来理解指标对客户流失可能性影响，因此我不会在解释决策树上花费时间。
- en: Apart from being difficult to interpret, decision trees are no longer state
    of the art in terms of prediction accuracy. But decision trees are actually the
    building blocks for more accurate machine learning models. One example is a random
    forest, illustrated in figure 9.16.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 除了难以解释之外，决策树在预测准确性方面也不再是尖端技术。但决策树实际上是更准确机器学习模型的构建块。一个例子是随机森林，如图9.16所示。
- en: '![](../Images/9-16.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![图9.16 使用规则树森林进行预测](../Images/9-16.png)'
- en: Figure 9.16 Making predictions with a forest of rule trees
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.16 使用规则树森林进行预测
- en: DEFINITION A random forest is an algorithm for predicting an outcome such as
    a customer’s churning by randomly generating a large set of decision trees (a
    forest). All the trees try to predict the same outcome, but each does so according
    to a different set of learned rules. The final prediction is made by averaging
    the predictions of the forest.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** 随机森林是一种通过随机生成大量决策树（森林）来预测结果（如客户的流失）的算法。所有树都试图预测相同的输出，但每棵树都根据不同的学习规则进行预测。最终的预测是通过平均森林的预测得出的。'
- en: The random forest is an example of what is called an ensemble prediction algorithm
    because the final prediction is made from the combination of a group of other
    machine learning algorithms. Ensemble means a group evaluated as a whole rather
    than individually. A random forest is a simple type of ensemble in that each tree
    gets an equal vote in the outcome, and additional trees are added at random. Boosting
    is a name for machine learning algorithms that make some important improvements
    over ensembles such as random forest.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林是所谓的集成预测算法的一个例子，因为最终的预测是由一组其他机器学习算法的组合得出的。集成意味着作为一个整体而不是个别评估的一组。随机森林是一种简单的集成类型，因为每一棵树在结果中都有平等的投票权，并且随机添加额外的树。提升是一种机器学习算法的名称，它在集成（如随机森林）的基础上进行了一些重要的改进。
- en: DEFINITION Boosting is a machine learning ensemble in which the ensemble members
    are added so that they correct the errors of the existing ensemble.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** 提升是一种机器学习集成，其中集成成员被添加以纠正现有集成的错误。'
- en: Rather than randomly adding decision trees, as in a random forest, you create
    each new tree in a boosting ensemble to correct wrong answers made by the existing
    ensemble, rather than repredicting on the correct examples. Internal to the boosting
    algorithm, successive trees are generated to correct the observations that were
    not correctly classified by earlier trees. Also, the weight assigned to successive
    trees in the vote is made to best correct the mistakes, not an equal vote like
    in random forests. These improvements make boosted forests of decisions trees
    more accurate than a truly random forest of decision trees.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 与随机森林中随机添加决策树不同，在提升集成中，你创建每一棵新树是为了纠正现有集成中做出的错误答案，而不是在正确示例上重新预测。在提升算法内部，连续生成的树用于纠正先前树未能正确分类的观察结果。此外，在投票中分配给连续树的权重是为了最好地纠正错误，而不是像随机森林中那样进行平等的投票。这些改进使得决策树提升森林比真正的随机决策树森林更准确。
- en: XGBoost (short for extreme gradient boosting) is a machine learning model that
    (at the time of this writing) is the most popular and successful model for general-purpose
    prediction. XGBoost is popular because it delivers state-of-the-art performance,
    and the algorithm to fit the model is relatively fast (compared with other boosting
    algorithms, but not as fast as regression). Details about the XGBoost algorithm
    are beyond the scope of this book, but there are many excellent free resources
    online.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost（即极端梯度提升）是一种机器学习模型，在撰写本文时，它是用于通用预测的最受欢迎和最成功的模型。XGBoost之所以受欢迎，是因为它提供了最先进的性能，并且拟合模型的算法相对较快（与其他提升算法相比，但不如回归快）。关于XGBoost算法的详细信息超出了本书的范围，但网上有许多优秀的免费资源。
- en: 9.5.2 XGBoost cross-validation
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.2 XGBoost交叉验证
- en: 'Machine learning algorithms like XGBoost can make accurate predictions, but
    this accuracy comes with some additional complexity. One area of complexity is
    that the algorithms have multiple optional parameters that you must choose correctly
    to get the best results. The optional parameters for XGBoost include ones that
    control how the individual decision trees are generated, as well as parameters
    that control how the votes of different decision trees are combined. Here are
    a few of the most important parameters for XGBoost:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 像XGBoost这样的机器学习算法可以做出准确的预测，但这种准确性伴随着一些额外的复杂性。复杂性之一是算法具有多个可选参数，您必须正确选择这些参数才能获得最佳结果。XGBoost的可选参数包括控制单个决策树如何生成的参数，以及控制不同决策树的投票如何组合的参数。以下是XGBoost最重要的几个参数：
- en: '`max_depth`—The maximum depth of rules in each decision tree'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth`—每个决策树中规则的最高深度'
- en: '`n_estimator`—The number of decision trees to generate'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_estimator`—生成决策树的数量'
- en: '`learning_rate`—How heavily to emphasize the weight of votes from the best
    trees'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate`—强调最佳树投票权重的程度'
- en: '`min_child_weight`—The minimum weight of each tree in the vote, regardless
    of how well it did'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_child_weight`—投票中每个树的最低权重，无论其表现如何'
- en: Because there is no straightforward way to select the values for so many parameters,
    the values are set by out-of-sample cross-validation. You used this approach for
    the control parameter on the regression in section 9.4.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有直接选择这么多参数值的方法，因此这些值是通过样本外交叉验证来设置的。您在9.4节中的回归控制参数上使用了这种方法。
- en: TAKEAWAY State-of-the-art machine learning models have so many parameters that
    the only way to make sure you pick the best values is to cross-validate a large
    number of them. That is, you test a sequence of plausible values for each parameter
    and choose the ones that have the best values on a cross-validation test.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收要点：最先进的机器学习模型有如此多的参数，确保您选择最佳值的唯一方法是对大量参数进行交叉验证。也就是说，您测试每个参数的每个可能的值序列，并选择在交叉验证测试中具有最佳值的那些。
- en: '![](../Images/9-17.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-17.png)'
- en: Figure 9.17 XGBoost code output
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.17 XGBoost代码输出
- en: Figure 9.17 shows an example of such a cross-validation result.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.17显示了这样一个交叉验证结果的示例。
- en: 'Figure 9.17 was created by running listing 9.6 on the simulated social network
    dataset used in earlier chapters. It is similar to the cross-validation results
    you saw for picking the regression `C` parameter, but it has both more columns
    and more rows:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.17是通过在早期章节中使用的模拟社交网络数据集上运行列表9.6创建的。它与您看到的用于选择回归`C`参数的交叉验证结果类似，但它有更多的列和行：
- en: 'There are four columns of parameters because four parameters were part of the
    test: `max_depth`, `n_estimator`, `learning_rate`, and `minimum_child_weight`.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于有四个参数参与了测试：`max_depth`、`n_estimator`、`learning_rate`和`minimum_child_weight`，因此有四列参数。
- en: 'There are many more rows in the output table—256 parameter combinations, to
    be precise. The reason for 256 parameter combinations becomes clear when you inspect
    listing 9.6: the test is made over four parameters, and the sequence of values
    for each parameter has four entries. The total number of combinations is the product
    of the number of values for each parameter—in this case, 4 × 4 × 4 × 4 = 256.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出表中有很多行——精确地说，有256种参数组合。当您检查列表9.6时，256种参数组合的原因变得清晰：测试是在四个参数上进行的，每个参数的值序列有四个条目。组合的总数是每个参数值的数量的乘积——在这种情况下，4
    × 4 × 4 × 4 = 256。
- en: 'You should run listing 9.6 on your own simulated data, using the following
    usual Python wrapper program command with these arguments:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在您自己的模拟数据上运行列表9.6，使用以下常用的Python包装程序命令以及这些参数：
- en: '[PRE10]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Do not be surprised if the cross-validation for the XGBoost model takes a lot
    longer than it did for the regression. There are a lot more parameter combinations
    to test, and each time a model is fit, the process takes significantly longer.
    The precise time can vary (depending on your hardware), but for me, the XGBoost
    model takes about 40 times longer to fit in comparison with the regression model.
    As shown in figure 9.8, the regression takes only a few hundredths of a second
    to fit on average; figure 9.17 shows that the XGBoost fits take around 1 to 4
    seconds.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 如果XGBoost模型的交叉验证所需时间比回归模型长得多，请不要感到惊讶。有更多的参数组合需要测试，每次拟合模型时，过程都会显著变长。确切的时间可能因硬件而异，但与我相比，XGBoost模型拟合所需的时间大约是回归模型的40倍。如图9.8所示，回归模型平均只需要几百毫秒就能拟合；图9.17显示XGBoost模型的拟合大约需要1到4秒。
- en: NOTE XGBoost is in its own Python package, so if you have not used it before,
    you need to install it before running listing 9.6.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：XGBoost是一个独立的Python包，所以如果你之前没有使用过它，在运行列表9.6之前需要安装它。
- en: Listing 9.6 XGBoost cross-validation
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.6 XGBoost交叉验证
- en: '[PRE11]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ① Imports XGBoost, which is in a separate package
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: ① 导入XGBoost，它是一个独立的包。
- en: '② Most of this function is the same as listing 9.5: the regression cross-validation.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: ② 这部分功能与列表9.5中的内容基本相同：回归交叉验证。
- en: ③ Creates an XGBClassifier object for a binary outcome
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 创建一个用于二元结果的XGBClassifier对象。
- en: ④ Tests tree depths from 1 to 6
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 测试树深度从1到6。
- en: ⑤ Tests learning rates from 0.1 to 0.4
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 测试学习率从0.1到0.4。
- en: ⑥ Tests the number of estimators from 20 to 120
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 测试估计器的数量从20到120。
- en: ⑦ Tests minimum weights from 3 to 12
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: ⑦ 测试从3到12的最小权重。
- en: ⑧ Creates the GridSearchCV object with the XGBoost model object, and tests parameters
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: ⑧ 使用XGBoost模型对象创建GridSearchCV对象，并测试参数。
- en: ⑨ Refits the best model according to AUC after cross-validation
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: ⑨ 在交叉验证后根据AUC重新拟合最佳模型。
- en: ⑩ Passes as values, not a DataFrame, to avoid a known package issue at the time
    of this writing
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: ⑩ 将值作为非DataFrame传递，以避免在编写此内容时的已知包问题。
- en: ⑪ Transfers the results to a DataFrame
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: ⑪ 将结果转移到DataFrame中。
- en: ⑫ Sorts the result so the best AUC is first
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: ⑫ 对结果进行排序，以便最佳AUC值排在第一位。
- en: ⑬ Creates a pickle of the best result
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ⑬ 创建最佳结果的pickle文件。
- en: ⑭ The best result is in the best_estimator field of the GridSearchCV object.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: ⑭ 最佳结果位于GridSearchCV对象的best_estimator字段中。
- en: The code in listing 9.6 is similar to the one for cross-validating the regression
    (listing 9.5). The main steps are
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.6中的代码与用于回归交叉验证的列表9.5中的代码类似。主要步骤是
- en: Prepare the data.
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备数据。
- en: Create a model instance (in this case, an XGBoost model).
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个模型实例（在这个例子中，是一个XGBoost模型）。
- en: Define the accuracy measurement functions to use (lift and AUC).
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义要使用的准确度测量函数（提升和AUC）。
- en: Define the sequences of parameters to test.
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义要测试的参数序列。
- en: Pass the prepared parameters to the `GridSearchCV` object and call the `fit`
    function.
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将准备好的参数传递给GridSearchCV对象并调用fit函数。
- en: Save the results (with no additional analysis, as in the regression cross-validation).
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存结果（与回归交叉验证一样，没有进行额外的分析）。
- en: One important and slightly subtle difference between listing 9.6 and the regression
    cross-validation in listing 9.5 is that the dataset is created from the original
    unscaled metrics, and it doesn’t use scores or groups as you do for the regression.
    There is no reason to rescale metrics for XGBoost (or decision trees generally)
    because the cut points in the rules operate as well on the metrics, regardless
    of scale or skew. Also, grouping correlated metrics doesn’t provide any benefit;
    in fact, it can hurt the performance of this type of machine learning model. Grouping
    correlated metrics is beneficial for interpretation and averts the problems that
    correlated metrics can cause in regression.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.6与列表9.5中的回归交叉验证之间有一个重要且稍微微妙的不同之处在于，数据集是从原始未缩放的指标创建的，并且它不使用分数或组，就像你在回归中做的那样。对于XGBoost（或决策树通常）来说，没有理由重新缩放指标，因为规则中的切点在指标上同样有效，无论规模或偏斜如何。此外，分组相关指标不会提供任何好处；实际上，它可能会损害此类机器学习模型的性能。分组相关指标对解释有益，并避免了相关指标在回归中可能引起的问题。
- en: On the other hand, for XGBoost, a diversity of metrics is beneficial, and correlation
    does no harm. (If two metrics are correlated, either can make a suitable rule
    node in a tree.) For these reasons, the `prepare_data` function from chapter 8
    is called with an empty extension argument so that it loads the original dataset
    rather than the grouped scores (the default behavior).
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，对于XGBoost来说，多种指标是有益的，相关性无害。（如果两个指标相关，任何一个都可以作为树中的合适规则节点。）因此，从第八章的`prepare_data`函数使用空扩展参数调用，以便它加载原始数据集而不是分组得分（默认行为）。
- en: 9.5.3 Comparison of XGBoost accuracy to regression
  id: totrans-362
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.3 XGBoost准确性与回归比较
- en: Because XGBoost takes much longer to fit the larger number of parameters, you
    should expect that it provides some improvement in forecasting accuracy. This
    expectation is confirmed in figure 9.18, which compares the AUC and lift achieved
    by regression and the XGBoost models for the simulation, as well as three real
    company case study datasets for the companies introduced in chapter 1\. The AUC
    improvement ranges from 0.02 to 0.06, and XGBoost always produces more accurate
    forecasts than does regression. In terms of lift, the improvement is 0.1 to 0.5.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 由于XGBoost需要更长的时间来拟合更多的参数，你应该预期它在预测准确性方面会有所提高。这种预期在图9.18中得到证实，该图比较了回归和XGBoost模型在模拟以及第一章中介绍的公司三个真实案例研究数据集上的AUC和提升。AUC的提高范围从0.02到0.06，XGBoost总是比回归产生更准确的预测。在提升方面，提高范围是0.1到0.5。
- en: '![](../Images/9-18.png)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![图9-18](../Images/9-18.png)'
- en: Figure 9.18 Comparison of regression and XGBoost lift
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.18 回归和XGBoost提升比较
- en: Are those improvements significant? Remember that the full range of AUCs you’re
    likely to see in churn forecasting is around 0.6 to 0.8\. The maximum AUC, therefore,
    is 0.2 more than the minimum, and in relative terms, an improvement of 0.02 in
    AUC represents a 10% improvement in terms of overall possible range. By the same
    token, a 0.05 improvement in AUC represents 25% of the difference between worst
    and best in class, so these improvements are significant. Still, the forecasting
    is not perfect, even with machine learning, which why I advised in chapter 1 that
    predicting churn with machine learning is not likely to live up to some of the
    hype in the machine learning field.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 这些改进是否显著？记住，你可能在流失预测中看到的AUC范围大约在0.6到0.8之间。因此，最大AUC比最小AUC高出0.2，从相对意义上讲，AUC提高0.02表示整体可能范围提高了10%。同样，AUC提高0.05表示在同类中最差和最好之间的差异的25%，所以这些改进是显著的。尽管如此，即使使用机器学习，预测仍然不完美，这就是为什么我在第一章建议使用机器学习预测流失不太可能达到机器学习领域的一些炒作。
- en: TAKEAWAY Though machine learning algorithms can produce forecasts that are significantly
    more accurate than regression, churn will always be hard to predict due to factors
    such as subjectivity, imperfect information, rarity, and extraneous factors that
    influence the timing of churn.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结**：尽管机器学习算法可以产生比回归更准确的预测，但由于主观性、信息不完整、稀有性和影响流失时机的额外因素，流失总是难以预测。'
- en: 9.5.4 Comparison of advanced and basic metrics
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.4 高级指标与基本指标比较
- en: Another important question is how much improvement in accuracy can be attributed
    to the work you did to create advanced metrics back in chapter 7\. So far, you
    may have assumed that because the advanced metrics showed a relationship to churn
    in cohort analysis, they must have improved the model. But as you want to validate
    your data and modeling by showing that your model can predict out of sample, it
    makes sense to confirm that the work you did creating more metrics contributed
    something empirically.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的问题是，你可以将多少准确性的提高归因于你在第七章中创建高级指标所做的努力。到目前为止，你可能认为，由于高级指标在队列分析中显示出与流失的关系，它们必须提高了模型。但是，正如你想要通过展示你的模型可以预测样本外数据来验证你的数据和建模，确认你创建更多指标的工作在经验上有所贡献是有意义的。
- en: 'To make the comparison on the simulated social network datasets, you can run
    additional versions of the cross-validation testing command on the original dataset
    from chapter 4\. That is, you run the dataset without the advanced metrics from
    chapter 7—you use only the basic metrics from chapter 3\. To run the regression
    cross-validation on the basic metric dataset, use the following:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 要在模拟的社会网络数据集上进行比较，你可以在第四章的原始数据集上运行交叉验证测试命令的额外版本。也就是说，你运行的数据集不包括第七章的高级指标——你只使用第三章的基本指标。要在基本指标数据集上运行回归交叉验证，请使用以下命令：
- en: '[PRE12]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The result is a cross-validation table like one shown in figure 9.13\. You will
    probably find that the maximum accuracy of any model is somewhat less for data
    with basic metrics than for data with advanced metrics. As illustrated in the
    bar chart in figure 9.19, the maximum accuracy that I got on my regression simulation
    with basic metrics was 0.63; for the regression on the simulated data with advanced
    metrics, the maximum AUC was 0.75\. The time spent creating advanced metrics was
    well spent. In fact, the regression accuracy with advanced metrics is significantly
    better than when using XGBoost with basic metrics, and the additional improvements
    for the machine learning algorithm when it uses advanced metrics are relatively
    small.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个类似于图 9.13 所示的交叉验证表。您可能会发现，任何模型的最大精度对于基本指标数据比对于高级指标数据要低一些。如图 9.19 中的条形图所示，我使用基本指标进行的回归模拟的最大精度是
    0.63；对于带有高级指标的模拟数据回归，最大 AUC 是 0.75。创建高级指标所花费的时间是值得的。事实上，使用高级指标进行的回归精度显著优于使用带有基本指标的
    XGBoost，而当机器学习算法使用高级指标时，额外的改进相对较小。
- en: '![](../Images/9-19.png)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/9-19.png)'
- en: Figure 9.19 Comparison of AUC using basic and advanced metrics
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.19 使用基本和高级指标比较 AUC
- en: 'You can perform the same check on the XGBoost model by running the second version
    of the XGBoost cross-validation command with these arguments:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过运行带有这些参数的 XGBoost 交叉验证命令的第二版来对 XGBoost 模型执行相同的检查：
- en: '[PRE13]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this case, you will probably find that the XGBoost forecasts did a bit better
    with the advanced metrics. I got an AUC of 0.774 by using XGBoost with basic metrics
    compared with 0.797 for XGBoost with advanced metrics; the improvement attributable
    to advanced metrics is 0.023.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您可能会发现 XGBoost 预测在高级指标下表现略好。我使用带有基本指标的 XGBoost 得到了 0.774 的 AUC，而带有高级指标的
    XGBoost 得到了 0.797；归因于高级指标的改进是 0.023。
- en: 'Figure 9.18 also contains similar comparisons for forecasts made on three real
    company case studies introduced in chapter 1\. These comparisons show different
    relationships between accuracy with and without advanced metrics. These three
    cases illustrate the range of scenarios you may encounter in your own case studies:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.18 也包含了在第一章中介绍的三家真实公司案例研究中进行的预测的类似比较。这些比较显示了带有和未带有高级指标时的精度之间的不同关系。这三个案例说明了您在自己的案例研究中可能遇到的场景范围：
- en: In the first case study, the regression accuracy is significantly improved by
    the advanced metrics, but XGBoost doesn’t get any improvement, and XGBoost is
    best overall. This result shows that you can’t always expect advanced metrics
    to improve machine learning.
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个案例研究中，高级指标显著提高了回归精度，但 XGBoost 没有获得任何改进，XGBoost 整体表现最佳。这个结果表明，您不能总是期望高级指标会提高机器学习。
- en: 'In the second case study, both the regression and XGBoost are significantly
    improved by the addition of advanced metrics. The regression accuracy with advanced
    metrics is about the same as the XGBoost accuracy with basic metrics. The XGBoost
    accuracy with advanced metrics is the highest of all by a significant amount:
    around 0.1 more than regression with basic metrics.'
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个案例研究中，回归和 XGBoost 都因添加高级指标而显著改进。带有高级指标的回归精度与带有基本指标的 XGBoost 精度大致相同。带有高级指标的
    XGBoost 精度是所有中最高的，比带有基本指标的回归提高了约 0.1。
- en: 'In the third case study, the regression using advanced metrics has higher accuracy
    than XGBoost without advanced metrics. But the highest accuracy of all is achieved
    by XGBoost using advanced metrics: more than 0.1 improvement over basic metrics
    and regression. This case study is most similar to the social network simulation.'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三个案例研究中，使用高级指标进行的回归精度高于未使用高级指标的 XGBoost。但所有中最高的精度是通过使用高级指标的 XGBoost 实现的：比基本指标和回归提高了
    0.1。这个案例研究与社会网络模拟最相似。
- en: These cases demonstrate that if high accuracy on churn forecasts is a high priority
    for you, both machine learning and advanced metrics are important. In my experience,
    advanced metrics usually improve the accuracy of churn forecasts for both regression
    and machine learning models like XGBoost.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 这些案例表明，如果您将 churn 预测的高精度视为首要任务，那么机器学习和高级指标都非常重要。根据我的经验，高级指标通常可以提高回归和 XGBoost
    等机器学习模型的 churn 预测精度。
- en: 9.6 Segmenting customers with machine learning forecasts
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.6 使用机器学习预测细分客户
- en: 'Listing 9.6 found a set of parameters that produces a machine learning model
    with high accuracy. The program also saved the best model in a pickle file. If
    you want to use the model to forecast on your active customers, you need to reload
    the saved model and use it on an active customer list. The code is demonstrated
    in listing 9.7\. Listing 9.7 is practically the same as listing 9.5, which you
    used to make forecasts with the saved regression model. The listing does the following:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.6找到了一组参数，可以生成一个高精度的机器学习模型。程序还保存了最佳模型到一个pickle文件中。如果您想使用该模型对活跃客户进行预测，您需要重新加载保存的模型并在活跃客户列表上使用它。代码在列表9.7中演示。列表9.7实际上与列表9.5相同，您使用它来使用保存的回归模型进行预测。该列表执行以下操作：
- en: Reloads the saved model pickle
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新加载保存的模型pickle文件
- en: Loads the current customer dataset
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载当前客户数据集
- en: Calls the `predict_proba` function on the model, passing the data as a parameter
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型上调用`predict_proba`函数，并将数据作为参数传递
- en: Saves the results as a DataFrame of predictions and a histogram summarizing
    the result
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果保存为预测的DataFrame和总结结果的直方图
- en: As in the XGBoost classification in listing 9.6, the data is kept in its original
    form, unscaled and ungrouped. The preparation of the data for forecasting must
    match the way the data was prepared when the model was trained.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 与列表9.6中的XGBoost分类类似，数据保持其原始形式，未缩放且未分组。数据准备以进行预测必须与模型训练时的数据准备方式相匹配。
- en: Listing 9.7 XGBoost forecasting
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.7 XGBoost预测
- en: '[PRE14]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ① Reloads the XGBoost model saved in the pickle file
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: ① 重新加载pickle文件中保存的XGBoost模型
- en: ② Reloads the current customer metric data
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: ② 重新加载当前客户指标数据
- en: ③ Makes the predictions
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 进行预测
- en: ④ Makes a DataFrame from the predictions
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 从预测中创建DataFrame
- en: ⑤ This function from listing 8.5 makes a histogram.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 列表8.5中的此函数生成直方图。
- en: Listing 9.7 also creates a histogram of the XGBoost churn forecasts on current
    customers. It’s not shown because it is similar to the plot that you made for
    the churn probability forecasts with the regression model (made with the same
    function).
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.7还创建了XGBoost对当前客户流失预测的直方图。它没有显示，因为它与您使用相同函数为回归模型制作的流失概率预测图相似。
- en: NOTE You should check the calibration and distribution of XGBoost forecasts
    as you learned to do for the regression forecasts in chapter 8.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您应该检查XGBoost预测的校准和分布，就像您在第八章中学习如何对回归预测进行校准一样。
- en: For the social network simulation, the distribution and calibration of XGBoost
    forecasts turned out to be similar to the regression, but this result is a coincidence,
    not something you can always expect. You can’t expect XGBoost forecasts to be
    calibrated and distributed like the regression forecasts because the XGBoost forecast
    probabilities are not probabilities in the same sense as the regression forecast
    probabilities.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 对于社交网络模拟，XGBoost预测的分布和校准与回归相似，但这种结果是巧合，不是您可以始终期望的。您不能期望XGBoost预测像回归预测那样校准和分布，因为XGBoost预测概率不是与回归预测概率相同意义上的概率。
- en: Recall that calibration refers to the property that your forecasts are in accordance
    with the true probability of the events occurring. On the other hand, accuracy
    measured by the AUC and lift depends on the ordering or ranking of the forecasts,
    not the precise values. The regression model is designed so that the forecast
    probabilities are calibrated to the sample data, as well as being as accurate
    as the model allows. When the XGBoost model gives a forecast probability, it is
    the weighted voted of the ensemble decision trees. Those votes are optimized to
    rank the risk of churn—something at which XGBoost is successful, as shown by the
    accuracy results. But the vote of the ensemble decision trees is not designed
    to produce forecasts calibrated to actual churn rates.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，校准是指您的预测与事件发生的真实概率相一致的性质。另一方面，由AUC和提升度衡量的准确性取决于预测的排序或排名，而不是精确值。回归模型设计得使预测概率校准到样本数据，同时尽可能准确。当XGBoost模型给出预测概率时，它是集成决策树的加权投票。这些投票被优化以对流失风险进行排名——XGBoost在这方面是成功的，如准确性结果所示。但集成决策树的投票并不是为了产生校准到实际流失率的预测。
- en: TAKEAWAY XGBoost doesn’t necessarily give calibrated churn probability forecasts.
    The XGBoost model is optimized for accuracy as measured by the classification
    of churns, not matching observed churn rates.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 吸收点：XGBoost不一定提供校准的流失概率预测。XGBoost模型是针对以分类流失来衡量的准确性进行优化的，而不是匹配观察到的流失率。
- en: As a consequence of the forecasts from the XGBoost model’s not being reliably
    calibrated, the XGBoost forecasts are not suitable to use for estimating customer
    lifetime value, as was demonstrated in chapter 8.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 XGBoost 模型预测的不可靠校准，XGBoost 预测不适合用于估计客户终身价值，如第 8 章所示。
- en: 'WARNING Do not use XGBoost for predicting customer lifetime value or any other
    use case that depends on the churn probability forecasts matching real churn probabilities.
    The same applies to most machine learning models: read the literature for the
    model you’re using to confirm whether it produces forecasts that are calibrated
    in addition to being accurate.'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：不要使用 XGBoost 预测客户终身价值或任何其他依赖于 churn 概率预测与实际 churn 概率匹配的用例。这同样适用于大多数机器学习模型：阅读你所使用的模型的文献，以确认它是否产生除了准确之外还经过校准的预测。
- en: Summary
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Because of the rarity of churn, the accuracy of churn forecasts cannot be measured
    with the standard accuracy measurements.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于 churn 的罕见性，churn 预测的准确性不能使用标准准确性测量来衡量。
- en: The area under the curve (AUC) is the percentage of times that the model ranks
    a churn as having higher risk than a nonchurn, considering all pairs of churns
    and nonchurns.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曲线下面积（AUC）是模型将 churn 评为比非 churn 风险更高的百分比，考虑所有 churn 和非 churn 的配对。
- en: The lift is the ratio of the churn rate in the top decile of churn risk forecasts
    to the overall churn rate.
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升是 churn 风险预测中最高十分之一 churn 率与整体 churn 率的比率。
- en: The AUC and lift are good measurements for the accuracy of churn forecast.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AUC 和提升是衡量 churn 预测准确性的良好指标。
- en: Accuracy should be measured on samples that were not used to train the model.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应在未用于训练模型的样本上衡量准确性。
- en: For churn, accuracy should be measured in a backtesting (historical) simulation
    that reflects the fact that product and market conditions may change over time.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 churn，准确性应在反映产品和市场条件可能随时间变化的回测（历史）模拟中衡量。
- en: The regression model taught in this book includes a control parameter that sets
    the overall size of the weights and the number of nonzero weights.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书所教授的回归模型包括一个控制参数，该参数设置权重的整体大小和非零权重的数量。
- en: The best value to use for the regression control parameter can be found by testing
    the accuracy of versions of the model using different values of the regression
    parameter.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过测试使用不同回归参数值的模型版本，可以找到用于回归控制参数的最佳值。
- en: Setting a forecasting model parameter by testing is known as cross-validation.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过测试设置预测模型参数称为交叉验证。
- en: For regression, you choose the value of the control parameter that minimizes
    the number of nonzero weights and helps or doesn’t harm accuracy.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于回归，你选择控制参数的值，以最小化非零权重的数量并帮助或不会损害准确性。
- en: Usually, a significant fraction of the metrics can be assigned zero weights
    in a regression; the accuracy either improves or doesn’t get worse.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，在回归中，可以分配零权重给大部分指标；准确性要么提高，要么不会变差。
- en: A machine learning model is a forecasting model that is fit from the data (not
    programmed) and is not the regression model.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型是一个从数据（非编程）中拟合的预测模型，它不是回归模型。
- en: A decision tree is a simple machine learning model that forecasts by analyzing
    customers with a tree of metric comparison rules.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树是一种简单的机器学习模型，通过分析具有度量比较规则的树来预测客户。
- en: XGBoost is a state-of-the-art machine learning model that uses an ensemble of
    decision trees and weights their predictions together to maximize accuracy.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost 是一种最先进的机器学习模型，它使用决策树的集成并加权它们的预测以最大化准确性。
- en: XGBoost and other machine learning models have many parameters that must be
    set using cross-validation.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost 和其他机器学习模型有许多参数必须通过交叉验证来设置。
- en: The accuracy of XGBoost forecasts generally exceeds the accuracy of regression
    forecasts.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost 预测的准确性通常超过回归预测的准确性。
- en: Using advanced metrics in addition to basic metrics usually makes forecasts
    more accurate for both regression and machine learning models.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了基本指标外，使用高级指标通常会使回归和机器学习模型的预测更准确。
- en: XGBoost churn probability forecasts are not calibrated to actual churn rates,
    so XGBoost churn forecasts should not be used for customer lifetime value or other
    use cases that depend on matching the actual churn probabilities.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBoost 的 churn 概率预测未校准到实际 churn 率，因此 XGBoost 的 churn 预测不应用于客户终身价值或其他依赖于匹配实际
    churn 概率的用例。
