- en: 8 Reshaping and pivoting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 重塑和交叉
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Comparing wide and narrow data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较宽格式和窄格式数据
- en: Generating a pivot table from a `DataFrame`
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 `DataFrame` 生成交叉表
- en: Aggregating values by sum, average, count, and more
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过求和、平均值、计数等方式聚合值
- en: Stacking and unstacking `DataFrame` index levels
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆叠和取消堆叠 `DataFrame` 索引级别
- en: Melting a `DataFrame`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 `DataFrame` 熔化
- en: A data set can arrive in a format unsuited for the analysis that we’d like to
    perform on it. Sometimes, issues are confined to a specific column, row, or cell.
    A column may have the wrong data type, a row may have missing values, or a cell
    may have incorrect character casing. At other times, a data set may have larger
    structural problems that extend beyond the data. Perhaps the data set stores its
    values in a format that makes it easy to extract a single row but difficult to
    aggregate the data.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一个数据集可能以不适合我们对其进行分析的格式出现。有时，问题局限于特定的列、行或单元格。一列可能有错误的数据类型，一行可能有缺失值，或一个单元格可能有错误的字符大小写。在其他时候，数据集可能存在更大的结构问题，这些问题超出了数据本身。也许数据集存储其值的方式使得提取单行变得容易，但聚合数据变得困难。
- en: '*Reshaping* a data set means manipulating it into a different shape, one that
    tells a story that could not be gleaned from its original presentation. Reshaping
    offers a new view or perspective on the data. This skill is critical; one study
    estimates that 80% of data analysis consists of cleaning up data and contorting
    it into the proper shape. [¹](#pgfId-1090296)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*重塑* 数据集意味着将其操纵成不同的形状，这种形状可以讲述一个从其原始展示中无法获取的故事。重塑提供了对数据的新视角或观点。这项技能至关重要；一项研究估计，80%
    的数据分析都包括清理数据和将其扭曲成正确的形状。[¹](#pgfId-1090296)'
- en: In this chapter, we’ll explore new pandas techniques for molding data sets into
    the shapes we desire. First, we’ll look at how to summarize a larger data set
    in a concise pivot table. Then we’ll proceed in the opposite direction, learning
    how to split an aggregated data set. By the end, you’ll be a master of contorting
    data into whatever presentation best fits your analysis.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探索新的 pandas 技巧，以将数据集塑造成我们想要的形状。首先，我们将看看如何通过简洁的交叉表来总结更大的数据集。然后我们将朝相反的方向前进，学习如何拆分聚合数据集。到那时，你将成为一个能够将数据扭曲成最适合你分析展示的大师。
- en: 8.1 Wide vs. narrow data
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 宽格式与窄格式数据
- en: Before we dive into more methods, let’s talk briefly about data set structure.
    A data set can store its values in wide or narrow format. A *narrow* data set
    is also called a *long* or a *tall* data set. These names reflect the direction
    in which the data set expands as we add more values to it. A *wide* data set increases
    in width; it grows out. A narrow/long/tall data set increases in height; it grows
    down.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨更多方法之前，让我们简要地谈谈数据集结构。数据集可以以宽格式或窄格式存储其值。一个窄数据集也被称为长数据集或高数据集。这些名称反映了当我们向数据集中添加更多值时数据集扩展的方向。宽数据集在宽度上增加；它向外扩展。窄/长/高数据集在高度上增加；它向下扩展。
- en: 'Take a peek at the following table, which measures temperatures in two cities
    over two days:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下表格，它测量了两个城市在两天内的温度：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Consider the *variables*, the measurements that vary. One might think that
    the only variables in this data set are the weekdays and the temperatures. But
    an additional variable is hiding in the column names: the city. This data set
    stores the same variable—temperature—across two columns instead of one. The Miami
    and New York headers do not describe the data their columns store—that is, `100`
    is not a type of `Miami` in the same way that `Monday` is a type of `Weekday`.
    The data set has hidden the varying cities variable by storing it in the column
    headers. We can categorize this table as being a wide data set. A wide data set
    expands horizontally.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到 *变量*，即变化的测量值。有人可能会认为这个数据集中的唯一变量是星期几和温度。但还有一个额外的变量隐藏在列名中：城市。这个数据集在两列中存储了相同的变量——温度，而不是一列。迈阿密和纽约的标题并没有描述它们所存储的数据——也就是说，`100`
    并不是 `Miami` 的一种类型，就像 `Monday` 是 `Weekday` 的一种类型一样。数据集通过将变量存储在列标题中隐藏了变化的城市的变量。我们可以将这个表格归类为宽数据集。宽数据集在水平方向上扩展。
- en: 'Suppose that we introduced temperature measurements for two more cities. We
    would have to add two new columns for the same variable: the temperature. Notice
    the direction in which the data set expands. The data grows wider, not taller:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们为另外两个城市引入了温度测量值。我们不得不为相同的变量添加两个新列：温度。注意数据集扩展的方向。数据变宽了，而不是变高：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Is horizontal expansion a bad thing? Not necessarily. A wide data set is ideal
    for seeing the aggregate picture—the complete story. If what we care about is
    the temperatures on Monday and Tuesday, the data set is easy to read and understand.
    But the wide format has its share of disadvantages too. The data set becomes more
    difficult to work with as we add more columns. Suppose that we wrote code to calculate
    the average temperature across all days. Now the temperatures are stored across
    four columns. If we added another city column, we’d have to alter our calculation
    logic to include it. The design is less flexible.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 水平扩展是坏事吗？不一定。宽数据集非常适合查看汇总图——完整的故事。如果我们关心的是周一和周二的温度，数据集很容易阅读和理解。但宽格式也有其缺点。随着我们添加更多列，数据集变得难以处理。假设我们编写了计算所有天数平均温度的代码。现在温度存储在四个列中。如果我们添加另一个城市列，我们就必须修改我们的计算逻辑以包含它。设计变得不那么灵活。
- en: 'A narrow data set grows vertically. A narrow format makes it easier to manipulate
    existing data and to add new records. Each variable is isolated to a single column.
    Compare the first table in this section with the following table:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 窄数据集垂直增长。窄格式使得操作现有数据并添加新记录变得更容易。每个变量都被隔离到单个列中。比较本节中的第一个表格和以下表格：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To include temperatures for two more cities, we would add rows instead of columns.
    The data grows taller, not wider:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要包括两个更多城市的温度，我们应该添加行而不是列。数据会变得更长，而不是更宽：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Is it easier to locate the temperatures for cities on Monday? I would argue
    no because now the data is scattered across four rows. But it is easier to calculate
    the average temperature because we have isolated the temperature values to a single
    column. As we add more rows, the average calculation logic remains the same.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在周一定位城市的温度是否更容易？我会说不是，因为现在数据分散在四行中。但计算平均温度更容易，因为我们已经将温度值隔离到单个列中。随着我们添加更多行，平均计算逻辑保持不变。
- en: The optimal storage format for a data set depends on the insight we’re trying
    to glean from it. Pandas offers tools to transform `DataFrame`s from narrow formats
    to wide formats and vice versa. We’ll learn how to apply both transformations
    throughout the rest of the chapter.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的最佳存储格式取决于我们试图从中获得的洞察力。Pandas 提供了将 `DataFrame`s 从窄格式转换为宽格式以及相反的工具。我们将在本章的其余部分学习如何应用这两种转换。
- en: 8.2 Creating a pivot table from a DataFrame
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 从 DataFrame 创建透视表
- en: 'Our first data set, sales_by_employee.csv, is a list of business deals at a
    fictional company. Each row includes the sale’s Date, the salesman’s Name, the
    Customer, and the Revenue and Expenses from the deal:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一份数据集，sales_by_employee.csv，是一家虚构公司的业务交易列表。每一行包括销售的日期、销售人员的姓名、客户以及交易的收入和支出：
- en: '[PRE4]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'For utility’s sake, let’s convert the strings in the Date column to datetime
    objects with the `read_csv` function’s `parse_dates` parameter. After that change,
    this import looks good to go. We can assign the `DataFrame` to a `sales` variable:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，让我们使用 `read_csv` 函数的 `parse_dates` 参数将日期列中的字符串转换为 datetime 对象。在此更改之后，此导入看起来很好。我们可以将
    `DataFrame` 赋值给 `sales` 变量：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With our data set loaded, let’s explore how we can aggregate its data with a
    pivot table.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载数据集后，让我们探索如何使用透视表聚合其数据。
- en: 8.2.1 The pivot_table method
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 pivot_table 方法
- en: A *pivot table* aggregates a column’s values and groups the results by using
    other columns’ values. The word *aggregate* describes a summary computation that
    involves multiple values. Example aggregations include average, sum, median, and
    count. A pivot table in pandas is similar to the Pivot Table feature in Microsoft
    Excel.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*透视表* 通过聚合列的值并使用其他列的值对结果进行分组。*聚合* 一词描述了涉及多个值的汇总计算。示例聚合包括平均、总和、中位数和计数。Pandas
    中的透视表类似于 Microsoft Excel 中的透视表功能。'
- en: As always, an example proves to be most helpful, so let’s tackle our first challenge.
    Multiple salesmen closed deals on the same date. In addition, the same salesmen
    closed multiple deals on the same date. What if we want to sum the revenue by
    date and see how much each salesman contributed to the daily totals?
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，一个例子最有帮助，所以让我们解决我们的第一个挑战。多个销售人员在同一天完成了交易。此外，相同的销售人员在同一天完成了多个交易。如果我们想按日期汇总收入并查看每个销售人员对每日总量的贡献是多少？
- en: 'We follow four steps to create a pivot table:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们遵循四个步骤来创建透视表：
- en: Select the column(s) whose values we want to aggregate.
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择我们想要聚合的列（s）。
- en: Choose the aggregation operation to apply to the column(s).
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择要应用到列（s）上的聚合操作。
- en: Select the column(s) whose values will group the aggregated data into categories.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择将分组聚合数据为类别的列（s）。
- en: Determine whether to place the groups on the row axis, the column axis, or both
    axes.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定是否将组放在行轴、列轴或两个轴上。
- en: Let’s proceed one step at a time. First, we’ll need to invoke the `pivot_table`
    method on our existing `sales` `DataFrame`. The method’s `index` parameter accepts
    the column whose values will make up the pivot table’s index labels. Pandas will
    use the unique values from that column to group the results.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一步一步来。首先，我们需要在我们的现有`sales` `DataFrame`上调用`pivot_table`方法。该方法`index`参数接受将构成数据透视表索引标签的列。Pandas将使用该列的唯一值来分组结果。
- en: 'The next example uses the Date column’s values for the index labels of the
    pivot table. The Date column contains five unique dates. Pandas applies its default
    aggregation operation, an average, to all numeric columns in `sales` (Expenses
    and Revenue):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例使用日期列的值作为数据透视表的索引标签。日期列包含五个唯一的日期。Pandas对其`sales`中的所有数值列（支出和收入）应用其默认的聚合操作，即平均值：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The method returns a regular `DataFrame` object. It may be a bit underwhelming,
    but this DataFrame is a pivot table! The table shows average expenses and average
    revenue organized by the five unique dates in the Date column.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法返回一个常规的`DataFrame`对象。它可能有点令人失望，但这个DataFrame是一个数据透视表！该表显示了按日期列中的五个唯一日期组织的平均支出和平均收入。
- en: 'We declare the aggregation function with the `aggfunc` parameter; its default
    argument is `"mean"`. The following code produces the same result as the preceding
    code:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`aggfunc`参数声明聚合函数；其默认参数是`"mean"`。以下代码产生与前面代码相同的结果：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We’ll have to modify some method arguments to reach our original goal: a sum
    of each date’s revenue organized by salesman. First, let’s swap the `aggfunc`
    parameter’s argument to `"sum"` to add the values in Expenses and Revenue:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要修改一些方法参数以达到我们的原始目标：按销售人员组织每一天的收入总和。首先，让我们将`aggfunc`参数的参数更改为`"sum"`以在支出和收入中添加值：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'For now, we care only about summing the values in the Revenue column. The `values`
    parameter accepts the `DataFrame` column(s) that pandas will aggregate. To aggregate
    only one column’s values, we can pass the parameter a string with the column name:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们只关心对收入列中的值求和。`values`参数接受pandas将聚合的`DataFrame`列（s）。要仅聚合一个列的值，我们可以传递一个包含列名的字符串参数：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: To aggregate values across multiple columns, we can pass `values` a list of
    columns.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要跨多列聚合值，我们可以将`values`传递一个列的列表。
- en: 'We have a sum of revenue grouped by date. Our final step is communicating how
    much each salesman contributed to the daily total. One presentational view that
    seems to be optimal is placing each salesman’s name in a separate column. In other
    words, we’d like to use the Name column’s unique values as the column headers
    in the pivot table. Let’s add a `columns` parameter to the method invocation and
    pass it an argument of `"Name"`:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个按日期分组的收入总和。我们的最终步骤是传达每位销售人员对每日总收入的贡献。似乎最优的展示方式是将每位销售人员的名字放在单独的列中。换句话说，我们希望使用名称列的唯一值作为数据透视表的列标题。让我们在方法调用中添加一个`columns`参数，并传递参数`"Name"`：
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: That’s it! We have an aggregated sum of revenue organized by dates on the row
    axis and salesmen on the column axis. Notice the presence of `NaNs` in the data
    set. A `NaN` denotes that the salesman did not have a row in `sales` with a Revenue
    value for a given date. Dwight does not have any `sales` row with a Date value
    of 2020-01-02, for example. The pivot table needs the index label of 2020-01-02
    to exist for the four salesmen who have a revenue value for that date. Pandas
    plugs in the missing holes with `NaN`s. The presence of `NaN` values also forces
    the coercion of integers into floating-point numbers.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们已经按照日期和销售人员组织了收入的总和。注意数据集中存在`NaN`。`NaN`表示销售人员在某一天没有`sales`中的行，并且没有收入值。例如，Dwight没有2020-01-02日期的任何`sales`行。数据透视表需要存在2020-01-02的索引标签，以便为那天有收入值的四位销售人员。Pandas用`NaN`填充缺失的空白。`NaN`值的存在还迫使整数转换为浮点数。
- en: 'We can use the `fill_value` parameter to replace all pivot table `NaN`s with
    a fixed value. Let’s fill in the data gaps with zeroes:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`fill_value`参数将所有数据透视表中的`NaN`替换为固定值。让我们用零来填补数据空白：
- en: '[PRE11]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We may also want to see the revenue subtotals for each combination of date
    and salesman. We can pass an argument of `True` to the `margins` parameter to
    add totals for each row and column:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可能想查看每个日期和销售人员的收入小计。我们可以将`margins`参数的参数设置为`True`来为每一行和每一列添加总计：
- en: '[PRE12]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Notice that the inclusion of `"All"` in the row labels changes the visual representation
    of the dates, which now include the hour, minute, and second. Pandas needs to
    support both dates and string index labels. A string is the only data type that
    can represent either a date or a text value. Thus, the library converts the index
    from a `DatetimeIndex` for dates to a plain `Index` for strings. When converting
    a datetime object to its string representation, pandas includes the time; it also
    assumes the start of the day for a date without time.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，将`"All"`包含在行标签中会改变日期的可视表示，现在包括小时、分钟和秒。Pandas需要支持日期和字符串索引标签。字符串是唯一可以表示日期或文本值的数据类型。因此，库将索引从日期的`DatetimeIndex`转换为字符串的普通`Index`。当将日期对象转换为字符串表示时，Pandas包括时间；它还假设没有时间的日期从一天的开始。
- en: 'We can use the `margins_name` parameter to customize the subtotal labels. The
    next example changes the labels from `"All"` to `"Total"`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`margins_name`参数来自定义小计标签。以下示例将标签从`"All"`更改为`"Total"`：
- en: '[PRE13]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Ideally, Excel users will feel right at home with these options.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，Excel用户会感到非常熟悉这些选项。
- en: 8.2.2 Additional options for pivot tables
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 交叉表的附加选项
- en: 'A pivot table supports a variety of aggregation operations. Suppose that we’re
    interested in the number of business deals closed per day. We can pass `aggfunc`
    an argument of `"count"` to count the number of `sales` rows for each combination
    of date and employee:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉表支持各种聚合操作。假设我们感兴趣的是每天完成的企业交易数量。我们可以将`aggfunc`的参数设置为`"count"`来计算每个日期和员工组合的`sales`行数：
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once again, a `NaN` value indicates that the salesman did not make a sale on
    a given day. Creed did not close a single sale on 2020-01-03, for example, whereas
    Dwight closed three. Some additional options for the `aggfunc` parameter are listed
    in the following table:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，一个`NaN`值表示销售人员在某一天没有进行销售。例如，Creed在2020-01-03没有完成任何销售，而Dwight完成了三次。以下表格列出了`aggfunc`参数的一些其他选项：
- en: '| Argument | Description |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 参数 | 描述 |'
- en: '| `max` | The largest value in the grouping |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `max` | 分组中的最大值 |'
- en: '| `min` | The smallest value in the grouping |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| `min` | 分组中的最小值 |'
- en: '| `std` | The standard deviation of the values in the grouping |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| `std` | 分组中值的标准差 |'
- en: '| `median` | The median (midpoint) of the values in the grouping |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| `median` | 分组中值的中间值（中位数） |'
- en: '| `size` | The number of values in the grouping (equivalent to `count`) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| `size` | 分组中的值的数量（等同于`count`） |'
- en: 'We can also pass a list of aggregation functions to the `pivot_table` function’s
    `aggfunc` parameter. The pivot table will create a `MultiIndex` on the column
    axis and store the aggregations in its outermost level. The next example aggregates
    both the sum of revenue by date and the count of revenue by date:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以向`pivot_table`函数的`aggfunc`参数传递一个聚合函数的列表。交叉表将在列轴上创建一个`MultiIndex`，并将聚合存储在其最外层级别。以下示例聚合了按日期的收入的总和以及按日期的收入计数：
- en: '[PRE15]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can apply different aggregations to different columns by passing a dictionary
    to the `aggfunc` parameter. Use the dictionary’s keys to identify `DataFrame`
    columns and the values to set the aggregation. The next example extracts the minimum
    revenue and the maximum expense for each combination of date and salesman:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过向`aggfunc`参数传递一个字典来对不同列应用不同的聚合操作。使用字典的键来识别`DataFrame`列，并使用值来设置聚合操作。以下示例提取了每个日期和销售人员的组合的最小收入和最大支出：
- en: '[PRE16]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can also stack multiple groupings on a single axis by passing the `index`
    parameter a list of columns. The next example aggregates the sum of expenses by
    salesman and date on the row axis. Pandas return a `DataFrame` with a two-level
    `MultiIndex`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过将列的列表传递给`index`参数，在单个轴上堆叠多个分组。以下示例在行轴上聚合了按销售人员和日期的支出总和。Pandas返回一个具有两级`MultiIndex`的`DataFrame`：
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Switch the order of strings in the `index` list to rearrange the levels in
    the pivot table’s `MultiIndex`. The next example swaps the positions of Name and
    Date:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通过切换`index`列表中字符串的顺序来重新排列交叉表`MultiIndex`中的级别。以下示例交换了名称和日期的位置：
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The pivot table first organizes and sorts the Date values, and then organizes
    and sorts the Name values within each Date.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉表首先组织和排序日期值，然后在每个日期内组织和排序名称值。
- en: 8.3 Stacking and unstacking index levels
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 索引级别的堆叠和取消堆叠
- en: 'Here’s a reminder of what sales looks like currently:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是当前销售情况的提醒：
- en: '[PRE19]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Let’s pivot sales to organize revenue by employee name and date. We’ll place
    dates on the column axis and names on the row axis:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将销售数据按照员工姓名和日期来组织收入。我们将日期放在列轴上，姓名放在行轴上：
- en: '[PRE20]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Sometimes, we may want to move an index level from one axis to another. This
    change offers a different presentation of the data, and we can decide which view
    we like better.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们可能想要将一个索引级别从一个轴移动到另一个轴。这种变化提供了数据的不同展示方式，我们可以决定我们更喜欢哪种视图。
- en: 'The `stack` method moves an index level from the column axis to the row axis.
    The next example moves the Date index level from the column axis to the row axis.
    Pandas creates a `MultiIndex` to store the two row levels: Name and Date. Because
    only one column of values remains, pandas returns a `Series`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`stack` 方法将一个索引级别从列轴移动到行轴。接下来的示例将日期索引级别从列轴移动到行轴。Pandas 创建一个 `MultiIndex` 来存储两个行级别：姓名和日期。因为只剩下一列的值，pandas
    返回一个 `Series`：'
- en: '[PRE21]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Notice that the `DataFrame`’s `NaN`s are absent from the `Series`. Pandas kept
    cells with `NaN`s in the `by_name_and_date` pivot table to maintain the structural
    integrity of the rows and columns. The shape of this `MultiIndex Series` allows
    pandas to discard the `NaN` values.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到 `DataFrame` 中的 `NaN` 值在 `Series` 中不存在。Pandas 在 `by_name_and_date` 交叉表中保留了
    `NaN` 值的单元格，以保持行和列的结构完整性。这个 `MultiIndex Series` 的形状允许 pandas 丢弃 `NaN` 值。
- en: 'The complementary `unstack` method moves an index level from the row axis to
    the column axis. Consider the following pivot table, which groups revenue by customer
    and salesman. The row axis has a two-level `MultiIndex`, and the column axis has
    a regular index:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 相补的 `unstack` 方法将一个索引级别从行轴移动到列轴。考虑以下交叉表，它按客户和销售人员分组收入。行轴有一个两级的 `MultiIndex`，列轴有一个常规索引：
- en: '[PRE22]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `unstack` method moves the innermost level of the row index to the column
    index:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`unstack` 方法将行索引的最内层级别移动到列索引：'
- en: '[PRE23]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In the new `DataFrame`, the column axis now has a two-level `MultiIndex`, and
    the row axis has a regular one-level index.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在新的 `DataFrame` 中，列轴现在有一个两级的 `MultiIndex`，行轴有一个常规的一级索引。
- en: 8.4 Melting a data set
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.4 熔化数据集
- en: 'A pivot table aggregates the values in a data set. In this section, we’ll learn
    how to do the opposite: break an aggregated collection of data into an unaggregated
    one.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉表聚合数据集中的值。在本节中，我们将学习如何做相反的事情：将聚合的数据集合分解为非聚合的数据集合。
- en: 'Let’s apply our wide-versus-narrow framework to the sales `DataFrame`. Here’s
    an effective strategy to figure out whether a data set is in narrow format: navigate
    across one row of values, and ask each cell whether its value is a single measurement
    of the variable that the column header is describing. Here’s the first row of
    sales:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将宽格式与窄格式框架应用于销售 `DataFrame`。这里有一个有效的策略来确定数据集是否为窄格式：导航到一行值，询问每个单元格其值是否是列标题所描述变量的单个测量值。以下是销售的第一行：
- en: '[PRE24]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the previous example, `"2020-01-01"` is a Date, `"Oscar"` is a Name, `"Logistics
    XYZ"` is a Customer, `5250` is a Revenue amount, and `531` is an Expenses amount.
    The sales `DataFrame` is an example of a narrow data set. Each row value represents
    a single observation for a given variable. No variable repeats across multiple
    columns.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，`"2020-01-01"` 是日期，`"Oscar"` 是姓名，`"Logistics XYZ"` 是客户，`5250` 是收入金额，`531`
    是支出金额。销售 `DataFrame` 是一个窄数据集的例子。每一行的值代表一个给定变量的单个观察结果。没有变量在多列中重复。
- en: 'We often have to choose between flexibility and readability when manipulating
    data in a wide or narrow format. We could represent the last four columns (Name,
    Customer, Revenue, Expenses) as fields in a single Category column (following
    example), but there is no real benefit because the four variables are distinct
    and separate. It is harder to aggregate data when it is stored in a format like
    this one:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在宽格式或窄格式中操作数据时，我们经常需要在灵活性和可读性之间做出选择。我们可以将最后四列（姓名、客户、收入、支出）表示为单个类别列中的字段（以下示例），但并没有真正的益处，因为四个变量是独立且分开的。当数据以这种格式存储时，聚合数据会更困难：
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The next data set, video_game_sales.csv, is a listing of regional sales for
    more than 16,000 video games. Each row includes the game’s name as well as the
    number of units sold (in millions) in the North America (NA), Europe (EU), Japan
    (JP), and other (Other) regions:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个数据集，video_game_sales.csv，是超过 16,000 个视频游戏区域销售的列表。每一行包括游戏名称以及在美国（NA）、欧洲（EU）、日本（JP）和其他（其他）地区销售的单位数量（以百万计）：
- en: '[PRE26]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Once again, let’s traverse a sample row and ask each cell whether it holds
    the correct piece of information. Here’s the first row of video_game_sales:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，让我们遍历一个样本行，并询问每个单元格是否包含正确的信息。这是video_game_sales的第一行：
- en: '[PRE27]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The first cell is fine; `"Wii Sports"` is an example of a Name. The next four
    cells are problematic. 41.49 is not a type of NA or a measurement of NA. NA (North
    America) is not a variable whose values vary throughout its column. The NA column’s
    real piece of variable data is the sales numbers. NA represents the region for
    those sales numbers—a separate and distinct variable.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个单元格是好的；"Wii Sports"是名称的一个例子。接下来的四个单元格有问题。41.49不是NA的类型或NA的度量。NA（北美）不是一个其值在其列中变化的变量。NA列的实际变量数据是销售数字。NA代表这些销售数字的区域——一个单独且不同的变量。
- en: 'Thus, video_game_sales stores its data in wide format. Four columns (NA, EU,
    JP, and Other) store the same data point: the number of units sold. If we added
    more regional sales columns, the data set would grow horizontally. If we can group
    multiple column headers in a common category, it is a hint that the data set is
    storing its data in wide format.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，video_game_sales以宽格式存储其数据。四个列（NA、EU、JP和其他）存储相同的数据点：销售数量。如果我们添加更多的区域销售列，数据集将水平增长。如果我们可以在一个共同类别中分组多个列标题，那么这是一个提示，表明数据集正在以宽格式存储其数据。
- en: 'Suppose that we moved the values `"NA"`, `"EU"`, `"JP"`, and `"Other"` to a
    new Region column. Compare the preceding presentation with the following one:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们将值"NA"、"EU"、"JP"和"Other"移动到新的区域列中。将前面的表示与以下表示进行比较：
- en: '[PRE28]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In a way, we are unpivoting the video_game_sales `DataFrame`. We are converting
    an aggregate, summary view of the data to one in which each column stores one
    variable piece of information.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种意义上说，我们正在对video_game_sales `DataFrame`进行逆透视。我们正在将数据的汇总、概览视图转换为每个列存储一个变量信息的视图。
- en: 'Pandas melts a `DataFrame` with the `melt` method. (*Melting* is the process
    of converting a wide data set to a narrow one.) The method accepts two primary
    parameters:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas使用`melt`方法熔化`DataFrame`。（*熔化*是将宽数据集转换为窄数据集的过程。）该方法接受两个主要参数：
- en: The `id_vars` parameter sets the identifier column, the column for which the
    wide data set aggregates data. Name is the identifier column in video_game_sales.
    The data set aggregates sales per video game.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id_vars`参数设置标识符列，宽数据集聚合数据的列。Name是video_game_sales中的标识符列。数据集按视频游戏汇总销售。'
- en: The `value_vars` parameter accepts the column(s) whose values pandas will melt
    and store in a new column.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value_vars`参数接受pandas将熔化和存储在新列中的值所在的列（s）。'
- en: 'Let’s start simple, melting only the NA column’s values. In the next example,
    pandas loops through each NA column value and assigns it to a separate row in
    a new `DataFrame`. The library stores the former column name (NA) in a new variable
    column:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从简单开始，仅熔化NA列的值。在下一个示例中，pandas遍历每个NA列的值，并将其分配给新`DataFrame`中的单独一行。库将前一个列名（NA）存储在一个新的变量列中：
- en: '[PRE29]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, let’s melt all four of the regional sales columns. The next code sample
    passes the `value_vars` parameter a list of the four regional sales columns from
    video_game_sales:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们熔化所有四个区域销售列。下一个代码示例将`value_vars`参数传递给来自video_game_sales的四个区域销售列的列表：
- en: '[PRE30]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The `melt` method returns a `DataFrame` with 66,264 rows! By comparison, video_
    game_sales has 16,566 rows. The new data set is four times longer because it has
    four rows of data for each row in video_games_sales. The data set stores
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`melt`方法返回一个包含66,264行的`DataFrame`！相比之下，video_game_sales有16,566行。新的数据集是原来的四倍长，因为它为video_games_sales中的每一行有四行数据。数据集存储'
- en: 16,566 rows for each video game and its respective NA sales number
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个视频游戏及其相应的北美销售数量为16,566行
- en: 16,566 rows for each video game and its respective EU sales number
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个视频游戏及其相应的欧洲销售数量为16,566行
- en: 16,566 rows for each video game and its respective JP sales number
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个视频游戏及其相应的日本销售数量为16,566行
- en: 16,566 rows for each video game and its respective Other sales number
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个视频游戏及其相应的其他销售数量为16,566行
- en: The variable column holds the four regional column names from video_game_sales.
    The value column holds the values from those four regional sales columns. In the
    previous output, the data tells us that the videogame `"Woody` `Woodpecker` `in`
    `Crazy Castle` `5"` had a value of `0.00` in the Other column of video_game_sales.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 变量列包含来自video_game_sales的四个区域列名。值列包含来自这四个区域销售列的值。在上一个输出中，数据显示视频游戏"Woodpecker
    in Crazy Castle 5"在video_game_sales的其他列中的值为`0.00`。
- en: 'We can customize the melted `DataFrame`’s column names by passing arguments
    to the `var_name` and `value_name` parameters. The next example uses Region for
    the variable column and Sales for the value column:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过传递`var_name`和`value_name`参数的参数来自定义熔融`DataFrame`的列名。下一个示例使用“区域”作为变量列和“销售额”作为值列：
- en: '[PRE31]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Narrow data is easier to aggregate than wide data. Let’s say we want to find
    the sum of each video game’s sales across all regions. Given the melted data set,
    we can use the `pivot_table` method to accomplish this task with a few lines of
    code:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 窄数据比宽数据更容易聚合。假设我们想要找出所有地区每款视频游戏销售额的总和。给定熔融数据集，我们可以使用`pivot_table`方法通过几行代码来完成这个任务：
- en: '[PRE32]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The data set’s narrow shape simplified the process of pivoting it.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的窄形状简化了转置过程。
- en: 8.5 Exploding a list of values
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.5 爆炸值列表
- en: 'Sometimes, a data set stores multiple values in the same cell. We may want
    to break up the data cluster so that each row stores a single value. Consider
    recipes.csv, a collection of three recipes, each of which has a name and an ingredients
    list. The ingredients are stored in a single comma-separated string:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，数据集会在同一单元格中存储多个值。我们可能想要拆分数据簇，以便每行只存储一个值。考虑recipes.csv，这是一个包含三个菜谱的集合，每个菜谱都有一个名称和成分列表。成分存储在一个逗号分隔的字符串中：
- en: '[PRE33]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Do you recall the `str.split` method we introduced in chapter 6? This method
    uses a delimiter to split a string into substrings. We can split each Ingredients
    string by the presence of a comma. In the next example, pandas returns a `Series`
    of lists. Each list stores the ingredients for the row:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你还记得我们在第6章中介绍的`str.split`方法吗？此方法使用分隔符将字符串拆分为子字符串。我们可以通过逗号的存在来拆分每个“成分”字符串。在下一个示例中，pandas返回一个列表的`Series`。每个列表存储该行的成分：
- en: '[PRE34]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let’s overwrite the original Ingredients column with the new one:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用新的列覆盖原始的“成分”列：
- en: '[PRE35]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, how can we spread out each list’s values across multiple rows? The `explode`
    method creates a separate row for each list element in a `Series`. We invoke the
    method on a `DataFrame` and pass in the column with lists:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们如何将每个列表的值分散到多行中？`explode`方法为`Series`中的每个列表元素创建一个单独的行。我们在`DataFrame`上调用此方法，并传入包含列表的列：
- en: '[PRE36]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Beautiful! We’ve isolated each ingredient to a separate line. Note that the
    `explode` method requires a `Series` of lists to work properly.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 真棒！我们已经将每个成分隔离到单独的一行。请注意，`explode`方法需要一个列表的`Series`才能正常工作。
- en: 8.6 Coding challenge
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.6 编码挑战
- en: Here’s an opportunity to practice the reshaping, pivoting, and melting concepts
    introduced in this chapter.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个练习本章中介绍的重塑、转置和熔融概念的机会。
- en: 8.6.1 Problems
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.1 问题
- en: 'We have two data sets for you to play with. The used_cars.csv file is a listing
    of used cars for sale on the classifieds website Craigslist. Each row includes
    the car’s manufacturer, year of production, fuel type, transmission type, and
    price:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为你提供了两个数据集进行操作。used_cars.csv文件是Craigslist分类网站上出售的二手车的列表。每一行包括汽车的制造商、生产年份、燃料类型、传动类型和价格：
- en: '[PRE37]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The minimum_wage.csv data set is a collection of minimum wages across the United
    States. The data set has a State column and multiple year columns:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: minimum_wage.csv数据集是美国最低工资的集合。数据集有一个“州”列和多个年份列：
- en: '[PRE38]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Here are the challenges:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些挑战：
- en: Aggregate the sum of car prices in cars. Group the results by fuel type on the
    row axis.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对cars中的汽车价格总和进行汇总。按燃料类型在行轴上对结果进行分组。
- en: Aggregate the count of cars in cars. Group the results by manufacturer on the
    index axis and transmission type on the column axis. Show the subtotals for both
    the rows and columns.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对cars中的汽车数量进行汇总。按索引轴上的制造商和列轴上的传动类型对结果进行分组。显示行和列的子总计。
- en: Aggregate the average of car prices in cars. Group the results by year and fuel
    type on the index axis and transmission type on the column axis.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对cars中的汽车价格的平均值进行汇总。按年份和燃料类型在索引轴上，按传动类型在列轴上对结果进行分组。
- en: Given a `DataFrame` from the preceding challenge, move the transmission level
    from the column axis to the row axis.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定前一个挑战中的`DataFrame`，将传输级别从列轴移动到行轴。
- en: Convert the `min_wage` from wide format to narrow format. In other words, move
    the data from the eight year columns (2010–17) to a single column.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`min_wage`从宽格式转换为窄格式。换句话说，将数据从八个年份的列（2010-17）移动到单个列。
- en: 8.6.2 Solutions
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.6.2 解决方案
- en: 'Let’s tackle the problems one by one:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一解决这些问题：
- en: 'The `pivot_table` method is an optimal solution for adding the values in the
    Price column and organizing the totals by fuel type. We can use the method’s `index`
    parameter to set the pivot table’s index labels; we’ll pass an argument of `"Fuel"`.
    We’ll specify the aggregation operation as `"sum"` with the `aggfunc` parameter:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`pivot_table` 方法是添加价格列中的值并按燃料类型组织总计的最佳解决方案。我们可以使用方法的 `index` 参数设置数据透视表的索引标签；我们将传递一个
    `"Fuel"` 的参数。我们将指定聚合操作为 `"sum"`，使用 `aggfunc` 参数：'
- en: '[PRE39]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can also use the `pivot_table` method to count cars by manufacturer and
    transmission type. We’ll use the `columns` parameter to set the Transmission column’s
    values as the pivot table’s column labels. Remember to pass the `margins` parameter
    an argument of `True` to show subtotals for rows and columns:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以使用 `pivot_table` 方法按制造商和传动类型计数汽车。我们将使用 `columns` 参数设置传动列的值作为数据透视表的列标签。记得传递
    `margins` 参数一个 `True` 的参数以显示行和列的小计：
- en: '[PRE40]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'To organize average car prices by year and fuel type on the pivot table’s row
    axis, we can pass a list of strings to the `pivot_table` function’s `index` parameter:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要按年份和燃料类型在数据透视表的行轴上组织平均汽车价格，我们可以将一个字符串列表传递给 `pivot_table` 函数的 `index` 参数：
- en: '[PRE41]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Let’s assign the previous pivot table to a `report` variable for the next challenge:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们将之前的透视表分配给 `report` 变量以进行下一个挑战：
- en: '[PRE42]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The next exercise is to move the transmission type from the column index to
    the row index. The `stack` method does the trick here. The method returns a `MultiIndex`
    `Series`. The `Series` has three levels: Year, Fuel, and the newly added Transmission:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个练习是将传动类型从列索引移动到行索引。这里 `stack` 方法派上用场。该方法返回一个 `MultiIndex` `Series`。`Series`
    有三个级别：年份、燃料和新增的传动：
- en: '[PRE43]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Next, we’d like to convert the `min_wage` data set from wide format to narrow
    format. Eight columns store the same variable: the wages themselves. The solution
    is the `melt` method. We can declare the State column as the identifier column
    and the eight year columns as the variable columns:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们希望将 `min_wage` 数据集从宽格式转换为窄格式。八个列存储相同的变量：工资本身。解决方案是 `melt` 方法。我们可以将 State
    列声明为标识列，将八个年份列声明为变量列：
- en: '[PRE44]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Here’s a bonus tip: we can remove the `value_vars` parameter from the `melt`
    method invocation and still get the same `DataFrame`. By default, pandas melts
    data from all columns except the one we pass to the `id_vars` parameter:'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里有一个额外的技巧：我们可以在调用 `melt` 方法时移除 `value_vars` 参数，仍然得到相同的 `DataFrame`。默认情况下，pandas
    从除了我们传递给 `id_vars` 参数的列之外的所有列熔化数据：
- en: '[PRE45]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We can also customize the column names with the `var_name` and `value_name`
    parameters. The next example uses `"Year"` and `"Wage"` to better explain what
    each column represents:'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还可以使用 `var_name` 和 `value_name` 参数自定义列名。下一个示例使用 `"Year"` 和 `"Wage"` 来更好地解释每一列代表的内容：
- en: '[PRE46]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Congratulations on completing the coding challenge!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了编码挑战！
- en: Summary
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The `pivot_table` method aggregates a `DataFrame`’s data.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pivot_table` 方法聚合 `DataFrame` 的数据。'
- en: Pivot table aggregations include sum, count, and average.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据透视表的聚合包括求和、计数和平均值。
- en: We can customize the pivot table’s row labels and column labels.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以自定义数据透视表的行标签和列标签。
- en: We can use one or more columns’ values as the index labels of the pivot table.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用一个或多个列的值作为数据透视表的索引标签。
- en: The `stack` method moves an index level from the column index to the row index.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stack` 方法将一个索引级别从列索引移动到行索引。'
- en: The `unstack` method moves an index level from the row index to the column index.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unstack` 方法将一个索引级别从行索引移动到列索引。'
- en: The `melt` method “unpivots” an aggregated table by distributing its data across
    individual rows. The process converts a wide data set to a narrow one.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`melt` 方法通过将数据分布到各个单独的行来“取消透视”一个汇总表。这个过程将宽数据集转换为窄数据集。'
- en: The `explode` method creates a separate row entry for each element in a list;
    it requires a `Series` of lists.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`explode` 方法为列表中的每个元素创建一个单独的行条目；它需要一个列表的 `Series`。'
- en: '* * *'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ¹ See Hadley Wickham, “Tidy Data,” Journal of Statistical Software, [https://vita.had.co.nz/papers/tidy-data.pdf](https://vita.had.co.nz/papers/tidy-data.pdf).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 参见 Hadley Wickham 的文章“Tidy Data”，发表在《统计软件杂志》上，[https://vita.had.co.nz/papers/tidy-data.pdf](https://vita.had.co.nz/papers/tidy-data.pdf)。
