- en: 9 API gateway and circuit breakers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 API 网关和断路器
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Implementing edge services with Spring Cloud Gateway and Reactive Spring
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Cloud Gateway 和反应式 Spring 实现边缘服务
- en: Configuring circuit breakers with Spring Cloud Circuit Breaker and Resilience4J
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Cloud Circuit Breaker 和 Resilience4J 配置断路器
- en: Defining rate limiters with Spring Cloud Gateway and Redis
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Cloud Gateway 和 Redis 定义速率限制器
- en: Managing distributed sessions with Spring Session Data Redis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Spring Session Data Redis 管理分布式会话
- en: Routing application traffic with Kubernetes Ingress
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes Ingress 路由应用程序流量
- en: In the previous chapter, you learned several aspects of building resilient,
    scalable, and cost-effective applications using the reactive paradigm. In this
    chapter, the Spring reactive stack will be the foundation for implementing an
    API gateway for the Polar Bookshop system. An API gateway is a common pattern
    in distributed architectures, like microservices, used to decouple the internal
    APIs from the clients. When establishing such an entry point to your system, you
    can also use it to handle cross-cutting concerns, such as security, monitoring,
    and resilience.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您学习了使用反应式范式构建弹性、可扩展和成本效益高的应用程序的几个方面。在本章中，Spring 反应式堆栈将成为实现 Polar Bookshop
    系统的 API 网关的基础。API 网关是分布式架构（如微服务）中的一种常见模式，用于将内部 API 与客户端解耦。在建立系统入口点时，您还可以使用它来处理跨切面关注点，如安全、监控和弹性。
- en: This chapter will teach you how to use Spring Cloud Gateway to build an Edge
    Service application and implement an API gateway and some of those cross-cutting
    concerns. You’ll improve the resilience of the system by configuring circuit breakers
    with Spring Cloud Circuit Breaker, defining rate limiters with Spring Data Redis
    Reactive, and using retries and timeouts just like you learned in the previous
    chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将教会您如何使用 Spring Cloud Gateway 构建边缘服务应用程序并实现 API 网关以及一些跨切面关注点。您将通过配置 Spring
    Cloud Circuit Breaker 中的断路器、使用 Spring Data Redis Reactive 定义速率限制器以及使用重试和超时（正如您在上一章中学到的）来提高系统的弹性。
- en: Next, I’ll discuss how to design stateless applications. Some states will need
    to be saved for the applications to be useful—you have already used relational
    databases. This chapter will teach you how to store web session state using Spring
    Session Data Redis, a NoSQL in-memory data store.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将讨论如何设计无状态应用程序。一些状态需要保存，以便应用程序有用——您已经使用了关系型数据库。本章将教会您如何使用 Spring Session
    Data Redis，一个 NoSQL 内存数据存储，来存储 Web 会话状态。
- en: Finally, you’ll see how to manage external access to the applications running
    in a Kubernetes cluster by relying on the Kubernetes Ingress API.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您将了解如何通过依赖 Kubernetes Ingress API 来管理运行在 Kubernetes 集群中的应用程序的外部访问。
- en: Figure 9.1 shows what the Polar Bookshop system will look like after completing
    this chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 展示了完成本章后 Polar Bookshop 系统将呈现的样子。
- en: '![09-01](../Images/09-01.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![09-01](../Images/09-01.png)'
- en: Figure 9.1 The architecture of the Polar Bookshop system after adding Edge Service
    and Redis
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 添加边缘服务和 Redis 后的 Polar Bookshop 系统架构
- en: Note The source code for the examples in this chapter is available in the Chapter09/09-begin
    and Chapter09/09-end folders, containing the initial and final states of the project
    ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action)).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章示例的源代码可在 Chapter09/09-begin 和 Chapter09/09-end 文件夹中找到，包含项目的初始和最终状态 ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action))。
- en: 9.1 Edge servers and Spring Cloud Gateway
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 边缘服务器和 Spring Cloud Gateway
- en: Spring Cloud Gateway is a project built on top of Spring WebFlux and Project
    Reactor to provide an API gateway and a central place to handle cross-cutting
    concerns like security, resilience, and monitoring. It’s built for developers,
    and it’s a good fit in Spring architectures and heterogeneous environments.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway 是一个基于 Spring WebFlux 和 Project Reactor 的项目，旨在提供 API 网关以及处理跨切面关注点（如安全、弹性和监控）的中心位置。它是为开发者构建的，非常适合
    Spring 架构和异构环境。
- en: An API gateway provides an entry point to your system. In distributed systems
    like microservices, that’s a convenient way to decouple the clients from any changes
    to the internal services’ APIs. You’re free to change how your system is decomposed
    into services and their APIs, relying on the fact that the gateway can translate
    from a more stable, client-friendly, public API to the internal one.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: API网关为您的系统提供了一个入口点。在微服务这样的分布式系统中，这是一种方便的方法，可以将客户端与内部服务API的任何更改解耦。您可以自由地更改系统如何分解为服务和它们的API，依靠网关能够从更稳定、客户端友好的公共API转换为内部API。
- en: Suppose you’re in the process of moving from a monolith to microservices. In
    that case, an API gateway can be used as a *monolith strangler* and can wrap your
    legacy applications until they are migrated to the new architecture, keeping the
    process transparent to clients. In case of different client types (single-page
    applications, mobile applications, desktop applications, IoT devices), an API
    gateway gives you the option to provide a better-crafted API to each of them depending
    on their needs (also called the *backend-for-frontend* pattern). Sometimes a gateway
    can also implement the *API composition* pattern, letting you query and join data
    from different services before returning the result to a client (for example,
    using the new Spring for GraphQL project).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您正在从单体架构迁移到微服务架构的过程中。在这种情况下，API网关可以用作*单体杀手*，并可以包裹您的遗留应用程序，直到它们迁移到新的架构，使客户端对整个过程保持透明。对于不同类型的客户端（单页应用程序、移动应用程序、桌面应用程序、物联网设备），API网关为您提供了根据其需求提供更精心设计的API的选项（也称为*前端后端*模式）。有时网关还可以实现*API组合*模式，让您在将结果返回给客户端之前查询和合并来自不同服务的数据（例如，使用新的Spring
    for GraphQL项目）。
- en: Calls are forwarded to downstream services from the gateway according to specified
    routing rules, similar to a reverse proxy. This way the client doesn’t need to
    keep track of the different services involved in a transaction, simplifying the
    client’s logic and reducing the number of calls it has to make.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 根据指定的路由规则，调用从网关转发到下游服务，类似于反向代理。这样，客户端不需要跟踪参与事务的不同服务，简化了客户端的逻辑并减少了其必须进行的调用次数。
- en: 'Since the API gateway is the entry point to your system, it can also be an
    excellent place to handle cross-cutting concerns like security, monitoring, and
    resilience. *Edge servers* are applications at the edge of a system that implement
    aspects like API gateways and cross-cutting concerns. You can configure circuit
    breakers to prevent cascading failures when invoking the services downstream.
    You can define retries and timeouts for all the calls to internal services. You
    can control the ingress traffic and enforce quota policies to limit the use of
    your system depending on some criteria (such as the membership level of your users:
    basic, premium, pro). You can also implement authentication and authorization
    at the edge and pass tokens to downstream services (as you’ll see in chapters
    11 and 12).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 由于API网关是您系统的入口点，它也可以是一个处理跨领域关注点（如安全、监控和弹性）的绝佳位置。*边缘服务器*是位于系统边缘的应用程序，实现了诸如API网关和跨领域关注点等方面的功能。您可以为调用下游服务时配置断路器以防止级联故障。您可以定义对所有内部服务调用的重试和超时。您可以控制入站流量并实施配额策略，根据某些标准（例如用户的会员级别：基本、高级、专业）限制对系统的使用。您还可以在边缘实施身份验证和授权，并将令牌传递给下游服务（如第11章和第12章所示）。
- en: However, it’s important to remember that an edge server adds complexity to the
    system. It’s another component to build, deploy, and manage in production. It
    also adds a new network hop to the system, so the response time will increase.
    That’s usually an insignificant cost, but you should keep it in mind. Since the
    edge server is the entry point to the system, it’s at risk of becoming a single
    point of failure. As a basic mitigation strategy, you should deploy at least two
    replicas of an edge server following the same approach we discussed for configuration
    servers in chapter 4.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，重要的是要记住，边缘服务器会增加系统的复杂性。它是另一个需要在生产环境中构建、部署和管理组件。它还向系统添加了一个新的网络跳数，因此响应时间会增加。这通常是一个微不足道的成本，但您应该记住这一点。由于边缘服务器是系统的入口点，它有可能成为单点故障。作为基本缓解策略，您应该至少部署两个边缘服务器的副本，遵循我们在第4章中讨论的配置服务器的相同方法。
- en: Spring Cloud Gateway greatly simplifies building edge services, focusing on
    simplicity and productivity. Furthermore, since it’s based on a reactive stack,
    it can scale efficiently to handle the high workload naturally happening at the
    edge of a system.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway极大地简化了边缘服务的构建，专注于简洁和高效。此外，由于它基于响应式堆栈，它可以高效地扩展以处理系统边缘自然发生的高工作量。
- en: The following section will teach you how to set up an edge server with Spring
    Cloud Gateway. You’ll learn about routes, predicates, and filters, which are the
    building blocks of the gateway. And you’ll apply the retry and timeout patterns
    you learned in the previous chapter to the interactions between the gateway and
    the downstream services.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分将教你如何使用Spring Cloud Gateway设置边缘服务器。你将了解路由、断言和过滤器，它们是网关的构建块。你还将将上一章中学到的重试和超时模式应用到网关与下游服务之间的交互中。
- en: Note If you haven’t followed along with the examples implemented in the previous
    chapters, you can refer to the repository accompanying the book and use the project
    in Chapter09/09-begin as a starting point ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action)).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果你没有跟随前几章中实现的示例，你可以参考本书附带的仓库，并使用第09章/09-begin中的项目作为起点 ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action))。
- en: 9.1.1 Bootstrapping an edge server with Spring Cloud Gateway
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 使用Spring Cloud Gateway启动边缘服务器
- en: The Polar Bookshop system needs an edge server to route traffic to the internal
    APIs and address several cross-cutting concerns. You can initialize our new Edge
    Service project from Spring Initializr ([https://start.spring.io](https://start.spring.io)),
    store the result in a new edge-service Git repository, and push it to GitHub.
    The parameters for the initialization are shown in figure 9.2.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Polar Bookshop系统需要一个边缘服务器来路由流量到内部API并解决几个横切关注点。你可以从Spring Initializr ([https://start.spring.io](https://start.spring.io))初始化我们的新Edge
    Service项目，将结果存储在一个新的edge-service Git仓库中，并将其推送到GitHub。初始化的参数如图9.2所示。
- en: '![09-02](../Images/09-02.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![09-02](../Images/09-02.png)'
- en: Figure 9.2 The parameters for initializing the Edge Service project
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 初始化Edge Service项目的参数
- en: Tip In the begin folder for this chapter, you’ll find a curl command you can
    run in a Terminal window. It downloads a zip file containing all the code you
    need to get started, without going through the manual generation on the Spring
    Initializr website.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：在本章的开始文件夹中，你可以找到一个可以在终端窗口中运行的curl命令。它下载一个包含所有启动所需代码的zip文件，无需在Spring Initializr网站上手动生成。
- en: 'The dependencies section of the autogenerated build.gradle file looks like
    this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的build.gradle文件的依赖关系部分看起来像这样：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'These are the main dependencies:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是主要的依赖项：
- en: '*Spring Cloud Gateway* (org.springframework.cloud:spring-cloud-starter-gateway)—Provides
    utilities to route requests to APIs and cross-cutting concerns like resilience,
    security, and monitoring. It’s built on top of the Spring reactive stack.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Spring Cloud Gateway* (org.springframework.cloud:spring-cloud-starter-gateway)—提供将请求路由到API和横切关注点（如弹性、安全和监控）的实用工具。它建立在Spring响应式堆栈之上。'
- en: '*Spring Boot Test* (org.springframework.boot:spring-boot-starter-test)—Provides
    several libraries and utilities for testing applications, including Spring Test,
    JUnit, AssertJ, and Mockito. It’s automatically included in every Spring Boot
    project.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Spring Boot Test* (org.springframework.boot:spring-boot-starter-test)—提供用于测试应用程序的多个库和实用工具，包括Spring
    Test、JUnit、AssertJ和Mockito。它自动包含在每一个Spring Boot项目中。'
- en: At its core, Spring Cloud Gateway is a Spring Boot application. It provides
    all the convenient features we’ve been using in the previous chapters, such as
    auto-configuration, embedded servers, test utilities, externalized configuration,
    and so on. It’s also built on the Spring reactive stack, so you can use the tools
    and patterns you learned in the previous chapter regarding Spring WebFlux and
    Reactor. Let’s start by configuring the embedded Netty server.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，Spring Cloud Gateway是一个Spring Boot应用程序。它提供了我们在前几章中使用过的所有方便功能，例如自动配置、内嵌服务器、测试实用工具、外部化配置等。它也建立在Spring响应式堆栈之上，因此你可以使用你在前一章中关于Spring
    WebFlux和Reactor学到的工具和模式。让我们先配置内嵌的Netty服务器。
- en: First, rename the application.properties file generated by Spring Initializr
    (edge-service/src/main/resources) to application.yml. Then open the file and configure
    the Netty server as you learned in the previous chapter.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，将Spring Initializr生成的application.properties文件（edge-service/src/main/resources）重命名为application.yml。然后打开文件，并配置Netty服务器，就像你在上一章中学到的那样。
- en: Listing 9.1 Configuring Netty server and graceful shutdown
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.1配置Netty服务器和优雅关闭
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ The port where the server will accept connections
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 服务器将接受连接的端口
- en: ❷ How long to wait for a TCP connection to be established with the server
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 等待与服务器建立TCP连接的时间长度
- en: ❸ How long to wait before closing a TCP connection if no data is transferred
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 如果没有数据传输，则在关闭TCP连接之前等待的时间长度
- en: ❹ Enables graceful shutdown
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 启用优雅关闭
- en: ❺ Defines a 15 s grace period
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 定义了15秒的宽限期
- en: The application is set up, so you can move on and start exploring the features
    of Spring Cloud Gateway.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序已设置，因此您可以继续探索Spring Cloud Gateway的功能。
- en: 9.1.2 Defining routes and predicates
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 定义路由和谓词
- en: 'Spring Cloud Gateway provides three main building blocks:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway提供了三个主要构建块：
- en: '*Route*—This is identified by a unique ID, a collection of predicates for deciding
    whether to follow the route, a URI for forwarding the request if the predicates
    allow, and a collection of filters that are applied either before or after forwarding
    the request downstream.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*路由*—这由一个唯一的ID、一组用于决定是否遵循路由的谓词、一个允许转发请求的URI以及一组在转发请求到下游服务之前或之后应用的过滤器组成。'
- en: '*Predicate*—This matches anything from the HTTP request, including path, host,
    headers, query parameters, cookies, and body.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*谓词*—这匹配来自HTTP请求的任何内容，包括路径、主机、头部、查询参数、cookies和主体。'
- en: '*Filter*—This modifies an HTTP request or response before or after forwarding
    the request to the downstream service.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*过滤器*—在将请求转发到下游服务之前或之后修改HTTP请求或响应。'
- en: Suppose a client sends a request to Spring Cloud Gateway. If the request matches
    a route through its predicates, the Gateway HandlerMapping will send the request
    to the Gateway WebHandler, which in turn will run the request through a chain
    of filters.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 假设客户端向Spring Cloud Gateway发送请求。如果请求通过其谓词匹配到某个路由，则Gateway HandlerMapping会将请求发送到Gateway
    WebHandler，后者将运行请求通过一系列过滤器。
- en: There are two filter chains. One chain contains the filters to be run before
    the request is sent to the downstream service. The other chain is run after sending
    the request downstream and before forwarding the response. You’ll learn about
    the different types of filters in the next section. Figure 9.3 shows how the routing
    works in Spring Cloud Gateway.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个过滤器链。一个链包含在请求发送到下游服务之前运行的过滤器。另一个链在发送请求到下游并转发响应之前运行。您将在下一节中了解不同类型的过滤器。图9.3显示了Spring
    Cloud Gateway中的路由工作方式。
- en: '![09-03](../Images/09-03.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![09-03](../Images/09-03.png)'
- en: Figure 9.3 Requests are matched against predicates, filtered, and finally forwarded
    to the downstream service, which replies with a response that goes through another
    set of filters before being returned to the client.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3显示了请求如何与谓词匹配、过滤，并最终转发到下游服务，该服务在返回给客户端之前通过另一组过滤器发送响应。
- en: 'In the Polar Bookshop system, we have built two applications with APIs that
    are meant to be accessible from the outside world (public APIs): Catalog Service
    and Order Service. We can use Edge Service to hide them behind an API gateway.
    For starters, we need to define the routes.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在Polar Bookshop系统中，我们构建了两个具有API的应用程序，这些API旨在对外界世界（公共API）开放：目录服务和订单服务。我们可以使用边缘服务来隐藏它们背后的API网关。首先，我们需要定义路由。
- en: A minimal route must be configured with a unique ID, a URI where the request
    should be forwarded, and at least one predicate. Open the application.yml file
    for the Edge Service project, and configure two routes to Catalog Service and
    Order Service.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一个最小路由必须配置一个唯一的ID、一个请求应该转发到的URI以及至少一个谓词。打开Edge Service项目的application.yml文件，并配置两个路由到目录服务和订单服务。
- en: Listing 9.2 Configuring routes to downstream services
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.2配置下游服务的路由
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ A list of route definitions
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 路由定义列表
- en: ❷ The route ID
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 路由ID
- en: ❸ The predicate is a path to match
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 谓词是匹配的路径
- en: ❹ The URI value comes from an environment variable, or else from the default.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ URI值来自环境变量，否则来自默认值。
- en: Both the routes for Catalog Service and Order Service are matched based on a
    Path predicate. All the incoming requests with a path starting with /books will
    be forwarded to Catalog Service. If the path starts with /orders, then Order Service
    will receive the request. The URIs are computed using the value from an environment
    variable (CATALOG_SERVICE_URL and ORDER_SERVICE_URL). If they are not defined,
    the default value written after the first colon (:) symbol will be used. It’s
    an alternative approach compared to how we defined URLs in the previous chapter,
    based on custom properties; I wanted to show you both options.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Catalog Service和Order Service的路由都是基于Path谓词进行匹配的。所有以/path开始的请求都将转发到Catalog Service。如果路径以/path开始，则Order
    Service将接收请求。URI是通过环境变量的值（CATALOG_SERVICE_URL和ORDER_SERVICE_URL）计算的。如果它们未定义，则将使用第一个冒号（:）符号后面的默认值。这与我们在上一章中基于自定义属性定义URL的方法相比是一种替代方法；我想向您展示两种选项。
- en: 'The project comes with many different predicates built-in, which you can use
    in your route configuration to match against any aspect of an HTTP request, including
    Cookie, Header, Host, Method, Path, Query, and RemoteAddr. You can also combine
    them to form *AND* conditionals. In the previous example, we used the Path predicate.
    Refer to the official documentation for an extensive list of predicates available
    in Spring Cloud Gateway: [https://spring.io/projects/spring-cloud-gateway](https://spring.io/projects/spring-cloud-gateway).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目内置了许多不同的谓词，您可以在路由配置中使用它们来匹配HTTP请求的任何方面，包括Cookie、Header、Host、Method、Path、Query和RemoteAddr。您还可以将它们组合起来形成*AND*条件。在之前的示例中，我们使用了Path谓词。有关Spring
    Cloud Gateway中可用的谓词的详细列表，请参阅官方文档：[https://spring.io/projects/spring-cloud-gateway](https://spring.io/projects/spring-cloud-gateway)。
- en: Defining routes with the Java/Kotlin DSL
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Java/Kotlin DSL定义路由
- en: Spring Cloud Gateway is a very flexible project that lets you configure routes
    the way that best suits your needs. Here you have configured routes in a property
    file (application.yml or application.properties), but there’s also a DSL available
    for configuring routes programmatically in Java or Kotlin. Future versions of
    the project will also implement a feature to fetch the route configuration from
    a data source using Spring Data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway是一个非常灵活的项目，它允许您以最适合您需求的方式配置路由。在这里，您已经在属性文件（application.yml或application.properties）中配置了路由，但Java或Kotlin中也有可用于程序化配置路由的DSL。项目的未来版本也将实现从数据源获取路由配置的功能，使用Spring
    Data。
- en: How you use it is up to you. Putting routes in configuration properties gives
    you the chance to customize them easily depending on the environment and to update
    them at runtime without the need to rebuild and redeploy the application. For
    example, you would get those benefits when using Spring Cloud Config Server. On
    the other hand, the DSL for Java and Kotlin lets you define more complex routes.
    Configuration properties allow you to combine different predicates with an *AND*
    logical operator only. The DSL also enables you to use other logical operators
    like *OR* and *NOT*.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 您如何使用它取决于您。将路由放在配置属性中可以让你根据环境轻松自定义它们，并在运行时更新它们，而无需重新构建和重新部署应用程序。例如，当使用Spring
    Cloud Config Server时，您将获得这些好处。另一方面，Java和Kotlin的DSL允许您定义更复杂的路由。配置属性允许您仅使用*AND*逻辑运算符组合不同的谓词。DSL还允许您使用其他逻辑运算符，如*OR*和*NOT*。
- en: Let’s verify that it works as intended. We’ll use Docker to run the downstream
    services and PostgreSQL, whereas we’ll run Edge Service locally on the JVM to
    make it more efficient to work with, since we are actively implementing the application.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证它是否按预期工作。我们将使用Docker来运行下游服务和PostgreSQL，而我们将在本地的JVM上运行Edge Service以提高工作效率，因为我们正在积极实现应用程序。
- en: 'First, we need both Catalog Service and Order Service up and running. From
    each project’s root folder, run ./gradlew bootBuildImage to package them as container
    images. Then start them via Docker Compose. Open a Terminal window, navigate to
    the folder where your docker-compose.yml file is located (polar-deployment/docker),
    and run the following command:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要Catalog Service和Order Service都启动并运行。从每个项目的根目录中，运行./gradlew bootBuildImage将它们打包为容器镜像。然后通过Docker
    Compose启动它们。打开一个终端窗口，导航到您的docker-compose.yml文件所在的文件夹（polar-deployment/docker），并运行以下命令：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Since both applications depend on PostgreSQL, Docker Compose will also run the
    PostgreSQL container.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 由于两个应用程序都依赖于PostgreSQL，Docker Compose也将运行PostgreSQL容器。
- en: 'When the downstream services are all up and running, it’s time to start Edge
    Service. From a Terminal window, navigate to the project’s root folder (edge-service),
    and run the following command:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当下游服务全部启动并运行时，是时候启动 Edge Service 了。从终端窗口导航到项目的根文件夹（edge-service），并运行以下命令：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The Edge Service application will start accepting requests on port 9000\. For
    the final test, try executing operations on books and orders, but this time through
    the API gateway (that is, using port 9000 rather than the individual ports to
    which Catalog Service and Order Service are listening). They should return a 200
    OK response:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Edge Service 应用程序将在端口 9000 上开始接受请求。对于最终测试，尝试通过 API 网关（即使用端口 9000 而不是 Catalog
    Service 和 Order Service 监听的各个端口）执行书籍和订单操作。它们应该返回 200 OK 响应：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result is the same as if you called Catalog Service and Order Service directly,
    but you only need to know one hostname and port this time. When you are done testing
    the application, stop its execution with Ctrl-C. Then terminate all the containers
    with Docker Compose:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 结果与直接调用 Catalog Service 和 Order Service 相同，但这次你只需要知道一个主机名和端口号。完成应用程序测试后，使用 Ctrl-C
    停止其执行。然后使用 Docker Compose 终止所有容器：
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Under the hood, Edge Service uses Netty’s HTTP client to forward requests to
    downstream services. As extensively discussed in the previous chapter, whenever
    an application calls an external service, it’s essential to configure a timeout
    to make it resilient to interprocess communication failures. Spring Cloud Gateway
    provides dedicated properties to configure the HTTP client timeouts.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，Edge Service 使用 Netty 的 HTTP 客户端将请求转发到下游服务。正如前一章广泛讨论的那样，每当应用程序调用外部服务时，配置超时以使其能够抵御进程间通信失败是至关重要的。Spring
    Cloud Gateway 提供了专门的属性来配置 HTTP 客户端超时。
- en: Open the Edge Service application.yml file once again, and define values for
    the connection timeout (the time limit for a connection to be established with
    the downstream service) and for the response timeout (the time limit for receiving
    a response).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 再次打开 Edge Service application.yml 文件，并定义连接超时（与下游服务建立连接的时间限制）和响应超时（接收响应的时间限制）的值。
- en: Listing 9.3 Configuring timeouts for the gateway HTTP client
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.3 配置网关 HTTP 客户端超时
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Configuration properties for the HTTP client
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ HTTP 客户端配置属性
- en: ❷ Time limit for a connection to be established (in ms)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 建立连接的时间限制（以毫秒为单位）
- en: ❸ Time limit for a response to be received (Duration)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 接收响应的时间限制（持续时间）
- en: By default, the Netty HTTP client used by Spring Cloud Gateway is configured
    with an *elastic* connection pool to increase the number of concurrent connections
    dynamically as the workload increases. Depending on the number of requests your
    system receives simultaneously, you might want to switch to a *fixed* connection
    pool so you have more control over the number of connections. You can configure
    the Netty connection pool in Spring Cloud Gateway through the spring.cloud.gateway.httpclient.pool
    property group in the application.yml file.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Cloud Gateway 使用的 Netty HTTP 客户端配置为 *弹性* 连接池，以便随着工作负载的增加动态增加并发连接的数量。根据您的系统同时接收的请求数量，您可能希望切换到
    *固定* 连接池，以便您对连接数量有更多的控制。您可以通过 application.yml 文件中的 spring.cloud.gateway.httpclient.pool
    属性组在 Spring Cloud Gateway 中配置 Netty 连接池。
- en: Listing 9.4 Configuring the connection pool for the gateway HTTP client
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.4 配置网关 HTTP 客户端连接池
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Type of connection pool (elastic, fixed, or disabled)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 连接池类型（弹性、固定或禁用）
- en: ❷ Idle time after which the communication channel will be closed
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 通信通道关闭后的空闲时间
- en: ❸ Time after which the communication channel will be closed
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 通信通道关闭后的时间
- en: You can refer to the official Reactor Netty documentation for more details about
    how the connection pool works, what configurations are available, and tips on
    what values to use based on specific scenarios ([https://projectreactor.io/docs](https://projectreactor.io/docs)).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考官方 Reactor Netty 文档以获取有关连接池如何工作、可用的配置以及根据特定场景使用哪些值的更多详细信息（[https://projectreactor.io/docs](https://projectreactor.io/docs)）。
- en: In the next section, we’ll start implementing something more interesting than
    merely forwarding requests—we’ll look at the power of Spring Cloud Gateway filters.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将开始实现比仅仅转发请求更有趣的事情——我们将探讨 Spring Cloud Gateway 过滤器的强大功能。
- en: 9.1.3 Processing requests and responses through filters
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3 通过过滤器处理请求和响应
- en: Routes and predicates alone make the application act as a proxy, but it’s filters
    that make Spring Cloud Gateway really powerful.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 路由和断言本身使应用程序充当代理，但过滤器才是使Spring Cloud Gateway真正强大的原因。
- en: 'Filters can run before forwarding incoming requests to a downstream application
    (*pre-filters*). They can be used for:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤器可以在将传入请求转发到下游应用程序之前运行（*前过滤器*）。它们可以用于：
- en: Manipulating the request headers
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作请求头
- en: Applying rate limiting and circuit breaking
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用速率限制和断路器
- en: Defining retries and timeouts for the proxied request
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义代理请求的重试和超时
- en: Triggering an authentication flow with OAuth2 and OpenID Connect
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用OAuth2和OpenID Connect触发身份验证流程
- en: 'Other filters can apply to outgoing responses after they are received from
    the downstream application and before sending them back to the client (*post-filters*).
    They can be used for:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其他过滤器可以在从下游应用程序接收响应后，在将其发送回客户端之前应用于传出响应（*后过滤器*）。它们可以用于：
- en: Setting security headers
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置安全头
- en: Manipulating the response body to remove sensitive information
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作响应体以移除敏感信息
- en: Spring Cloud Gateway comes bundled with many filters that you can use to perform
    different actions, including adding headers to a request, configuring a circuit
    breaker, saving the web session, retrying the request on failure, or activating
    a rate limiter.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway附带了许多过滤器，你可以使用它们执行不同的操作，包括向请求添加头信息、配置断路器、保存Web会话、在失败时重试请求或激活速率限制器。
- en: In the previous chapter, you learned how to use the retry pattern to improve
    application resilience. You’ll now learn how to apply it as a default filter for
    all GET requests going through the routes defined in the gateway.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了如何使用重试模式来提高应用程序的弹性。现在，你将学习如何将其作为默认过滤器应用于通过网关定义的路由的所有GET请求。
- en: Using the Retry filter
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用重试过滤器
- en: You can define default filters in the application.yml file located under src/main/
    resources. One of the filters provided by Spring Cloud Gateway is the Retry filter.
    The configuration is similar to what we did in chapter 8.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在位于src/main/resources下的application.yml文件中定义默认过滤器。Spring Cloud Gateway提供的一个过滤器是重试过滤器。配置与第8章中我们所做的是类似的。
- en: Let’s define a maximum of three retry attempts for all GET requests whenever
    the error is in the 5xx range (SERVER_ERROR). We don’t want to retry requests
    when the error is in the 4xx range. For example, if the result is a 404 response,
    it doesn’t make sense to retry the request. We can also list the exceptions for
    which a retry should be attempted, such as IOException and TimeoutException.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个最大三次的重试尝试，对于所有GET请求，当错误在5xx范围（SERVER_ERROR）内时（例如，如果结果是404响应，重试请求就没有意义）。我们不希望在4xx范围内重试请求。例如，如果结果是404响应，重试请求就没有意义。我们还可以列出应尝试重试的异常，例如IOException和TimeoutException。
- en: By now, you know that you shouldn’t keep retrying requests one after the other.
    You should use a backoff strategy instead. By default, the delay is computed using
    the formula firstBackoff * (factor ^ n). If you set the basedOnPreviousValue parameter
    to true, the formula will be prevBackoff * factor.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你知道你不应该连续重试请求。你应该使用退避策略。默认情况下，延迟是通过公式firstBackoff * (factor ^ n)计算的。如果你将basedOnPreviousValue参数设置为true，公式将是prevBackoff
    * factor。
- en: Listing 9.5 Applying the retry filter to all routes
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.5将重试过滤器应用于所有路由
- en: '[PRE9]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ A list of default filters
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 默认过滤器列表
- en: ❷ The name of the filter
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 过滤器的名称
- en: ❸ Maximum of 3 retry attempts
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 最大3次重试尝试
- en: ❹ Retries only GET requests
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 仅重试GET请求
- en: ❺ Retries only when 5XX errors
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 仅在5XX错误时重试
- en: ❻ Retries only when the given exceptions are thrown
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 仅在抛出给定异常时重试
- en: ❼ Retries with a delay computed as “firstBackoff * (factor ^ n)”
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 使用“firstBackoff * (factor ^ n)”计算延迟的重试
- en: The retry pattern is useful when a downstream service is momentarily unavailable.
    But what if it stays down for more than a few instants? At that point we could
    stop forwarding requests to it until we’re sure that it’s back. Continuing to
    send requests won’t be beneficial for the caller or the callee. In that scenario,
    the circuit breaker pattern comes in handy. That’s the topic of the next section.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 当下游服务暂时不可用时，重试模式很有用。但如果它持续几秒钟以上呢？在那个时刻，我们可以停止转发请求，直到我们确信它已经恢复。继续发送请求对调用者或被调用者都没有好处。在这种情况下，断路器模式就派上用场了。这就是下一节的主题。
- en: 9.2 Fault tolerance with Spring Cloud Circuit Breaker and Resilience4J
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 使用Spring Cloud Circuit Breaker和Resilience4J实现容错
- en: As you know, resilience is a critical property of cloud native applications.
    One of the principles for achieving resilience is blocking a failure from cascading
    and affecting other components. Consider a distributed system where application
    X depends on application Y. If application Y fails, will application X fail, too?
    A circuit breaker can block a failure in one component from propagating to the
    others depending on it, protecting the rest of the system. That is accomplished
    by temporarily stopping communication with the faulty component until it recovers.
    This pattern comes from electrical systems, for which the circuit is physically
    opened to break the electrical connection and avoid destroying the entire house
    when a part of the system fails due to current overload.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '正如你所知，弹性是云原生应用的关键特性之一。实现弹性的原则之一是阻止失败级联并影响其他组件。考虑一个分布式系统，其中应用X依赖于应用Y。如果应用Y失败，应用X也会失败吗？电路断路器可以阻止一个组件的失败传播到依赖它的其他组件，保护系统的其余部分。这是通过暂时停止与故障组件的通信直到其恢复来实现的。这种模式来源于电气系统，其中电路被物理打开以断开电气连接，避免系统因部分因电流过载而失败时整个房屋被破坏。 '
- en: In the world of distributed systems, you can establish circuit breakers at the
    integration points between components. Think about Edge Service and Catalog Service.
    In a typical scenario, the circuit is *closed*, meaning that the two services
    can interact over the network. For each server error response returned by Catalog
    Service, the circuit breaker in Edge Service would register the failure. When
    the number of failures exceeds a certain threshold, the circuit breaker trips,
    and the circuit transitions to *open*.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在分布式系统的世界中，你可以在组件之间的集成点建立电路断路器。考虑Edge服务和目录服务。在典型场景中，电路是*关闭*的，这意味着两个服务可以通过网络进行交互。对于目录服务返回的每个服务器错误响应，Edge服务中的电路断路器将记录失败。当失败次数超过某个阈值时，电路断路器跳闸，电路过渡到*开启*状态。
- en: While the circuit is open, communications between Edge Service and Catalog Service
    are not allowed. Any request that should be forwarded to Catalog Service will
    fail right away. In this state, either an error is returned to the client, or
    fallback logic is executed. After an appropriate amount of time to permit the
    system to recover, the circuit breaker transitions to a *half-open* state, allowing
    the next call to Catalog Service to go through. That is an exploratory phase to
    check if there are still issues in contacting the downstream service. If the call
    succeeds, the circuit breaker is reset and transitions to *closed*. Otherwise
    it goes back to being *open*. Figure 9.4 shows how a circuit breaker changes state.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当电路处于开启状态时，Edge服务与目录服务之间的通信是不允许的。任何应该转发到目录服务的请求将立即失败。在此状态下，客户端会收到错误信息，或者执行回退逻辑。在允许系统恢复的适当时间后，电路断路器过渡到*半开启*状态，允许下一个调用目录服务的请求通过。这是一个探索阶段，以检查是否还有联系下游服务的问题。如果调用成功，电路断路器将被重置并过渡到*关闭*状态。否则，它将回到*开启*状态。图9.4展示了电路断路器如何改变状态。
- en: '![09-04](../Images/09-04.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![09-04](../Images/09-04.png)'
- en: 'Figure 9.4 A circuit breaker ensures fault tolerance when a downstream service
    exceeds the maximum number of failures allowed by blocking any communication between
    upstream and downstream services. The logic is based on three states: closed,
    open, and half-open.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 电路断路器确保在下游服务超过允许的最大失败次数时具有容错性，通过阻断上游和下游服务之间的任何通信来实现。其逻辑基于三种状态：关闭、开启和半开启。
- en: Unlike with retries, when the circuit breaker trips, no calls to the downstream
    service are allowed anymore. Like with retries, the circuit breaker’s behavior
    depends on a threshold and a timeout, and it lets you define a fallback method
    to call. The goal of resilience is to keep the system available to users, even
    in the face of failures. In the worst-case scenario, like when a circuit breaker
    trips, you should guarantee a graceful degradation. You can adopt different strategies
    for the fallback method. For example, you might decide to return a default value
    or the last available value from a cache, in case of a GET request.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 与重试不同，当电路断路器跳闸时，不再允许对下游服务的调用。与重试类似，电路断路器的行为取决于阈值和超时，并允许你定义一个回退方法进行调用。弹性的目标是即使在面对失败的情况下，也要保持系统对用户可用。在最坏的情况下，例如当电路断路器跳闸时，你应该保证优雅降级。你可以采用不同的策略来定义回退方法。例如，在GET请求的情况下，你可能会决定返回默认值或缓存中的最后一个可用值。
- en: The Spring Cloud Circuit Breaker project provides an abstraction for defining
    circuit breakers in a Spring application. You can choose between reactive and
    non-reactive implementations based on Resilience4J ([https://resilience4j.readme.io](https://resilience4j.readme.io)).
    Netflix Hystrix was the popular choice for microservices architectures, but it
    entered maintenance mode back in 2018\. After that, Resilience4J became the preferred
    choice because it provides the same features offered by Hystrix and more.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Circuit Breaker 项目为在 Spring 应用程序中定义断路器提供了一个抽象层。您可以根据 Resilience4J（[https://resilience4j.readme.io](https://resilience4j.readme.io)）选择响应式和非响应式实现。Netflix
    Hystrix 是微服务架构中流行的选择，但它在 2018 年进入了维护模式。之后，Resilience4J 成为了首选选择，因为它提供了与 Hystrix
    相同的功能，并且更多。
- en: Spring Cloud Gateway integrates natively with Spring Cloud Circuit Breaker,
    providing you with a CircuitBreaker gateway filter that you can use to protect
    the interactions with all downstream services. In the following sections, you’ll
    configure a circuit breaker for the routes to Catalog Service and Order Service
    from Edge Service.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway 与 Spring Cloud Circuit Breaker 原生集成，为您提供了一个 CircuitBreaker
    网关过滤器，您可以使用它来保护与所有下游服务的交互。在接下来的章节中，您将配置从 Edge Service 到 Catalog Service 和 Order
    Service 的路由断路器。
- en: 9.2.1 Introducing circuit breakers with Spring Cloud Circuit Breaker
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 使用 Spring Cloud Circuit Breaker 介绍断路器
- en: To use Spring Cloud Circuit Breaker in Spring Cloud Gateway, you need to add
    a dependency to the specific implementation you’d like to use. In this case, we’ll
    use the Resilience4J reactive version. Go ahead and add the new dependency in
    the build.gradle file for the Edge Service project (edge-service). Remember to
    refresh or reimport the Gradle dependencies after the new addition.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Spring Cloud Gateway 中使用 Spring Cloud Circuit Breaker，您需要添加您想要使用的特定实现的依赖项。在这种情况下，我们将使用
    Resilience4J 的响应式版本。请继续在 Edge Service 项目的 build.gradle 文件中添加新的依赖项（edge-service）。请记住，在添加新依赖项后，刷新或重新导入
    Gradle 依赖项。
- en: Listing 9.6 Adding dependency for Spring Cloud Circuit Breaker
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.6 添加 Spring Cloud Circuit Breaker 依赖项
- en: '[PRE10]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The CircuitBreaker filter in Spring Cloud Gateway relies on Spring Cloud Circuit
    Breaker to wrap a route. As with the Retry filter, you can choose to apply it
    to specific routes or define it as a default filter. Let’s go with the first option.
    You can also specify an optional fallback URI to handle the request when the circuit
    is in an open state. In this example (application.yml), both routes will be configured
    with a CircuitBreaker filter, but only catalog-route will have a fallbackUri value
    so that I can show you both scenarios.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway 中的 CircuitBreaker 过滤器依赖于 Spring Cloud Circuit Breaker 来包装路由。与
    Retry 过滤器类似，您可以选择将其应用于特定路由或将其定义为默认过滤器。让我们选择第一种选项。您还可以指定一个可选的回退 URI，以便在断路器处于开启状态时处理请求。在这个例子（application.yml）中，将配置两个路由使用
    CircuitBreaker 过滤器，但只有 catalog-route 将具有 fallbackUri 值，这样我就可以向您展示两种场景。
- en: Listing 9.7 Configuring circuit breakers for the gateway routes
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.7 配置网关路由的断路器
- en: '[PRE11]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Name of the filter
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 过滤器名称
- en: ❷ Name of the circuit breaker
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 断路器名称
- en: ❸ Forwards request to this URI when the circuit is open
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 当断路器开启时，将请求转发到此 URI
- en: ❹ No fallback defined for this circuit breaker.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 此断路器未定义回退
- en: The next step is configuring the circuit breaker.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是配置断路器。
- en: 9.2.2 Configuring a circuit breaker with Resilience4J
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 使用 Resilience4J 配置断路器
- en: After defining which routes you want to apply the CircuitBreaker filter to,
    you need to configure the circuit breakers themselves. As often in Spring Boot,
    you have two main choices. You can configure circuit breakers through the properties
    provided by Resilience4J or via a Customizer bean. Since we’re using the reactive
    version of Resilience4J, the specific configuration bean would be of type Customizer<ReactiveResilience4JCircuitBreakerFactory>.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了您想要应用 CircuitBreaker 过滤器的路由后，您需要配置断路器本身。在 Spring Boot 中，您通常有两个主要选择。您可以通过
    Resilience4J 提供的属性配置断路器，或者通过 Customizer bean。由于我们正在使用 Resilience4J 的响应式版本，具体的配置
    bean 类型将是 Customizer<ReactiveResilience4JCircuitBreakerFactory>。
- en: Either way, you can choose to define a specific configuration for each circuit
    breaker you used in your application.yml file (catalogCircuitBreaker and orderCircuitBreaker
    in our case) or declare some defaults that will be applied to all of them.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 无论哪种方式，您都可以选择在 application.yml 文件中为您的应用程序中使用的每个断路器定义特定的配置（在我们的例子中是 catalogCircuitBreaker
    和 orderCircuitBreaker）或声明一些默认值，这些值将应用于所有断路器。
- en: For the current example, we can define circuit breakers to consider a window
    of 20 calls (slidingWindowSize). Each new call will make the window move, dropping
    the oldest registered call. When at least 50% of the calls in the window have
    produced an error (failureRateThreshold), the circuit breaker will trip, and the
    circuit will enter the open state. After 15 seconds (waitDurationInOpenState),
    the circuit will be allowed to transition to a half-open state in which 5 calls
    are permitted (permittedNumberOfCallsInHalfOpenState). If at least 50% of them
    result in an error, the circuit will go back to the open state. Otherwise, the
    circuit breaker will trip to the closed state.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 对于当前示例，我们可以定义电路断路器，考虑20个调用窗口（slidingWindowSize）。每个新的调用将使窗口移动，丢弃最老的已注册调用。当窗口中的调用至少有50%产生错误（failureRateThreshold）时，电路断路器将触发，电路将进入开启状态。之后15秒（waitDurationInOpenState），电路将被允许过渡到半开启状态，此时允许5个调用（permittedNumberOfCallsInHalfOpenState）。如果其中至少有50%的结果是错误，电路将回到开启状态。否则，电路断路器将触发到关闭状态。
- en: On to the code. In the Edge Service project (edge-service), at the end of the
    application.yml file, define a default configuration for all Resilience4J circuit
    breakers.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是代码。在Edge Service项目（edge-service）中，在application.yml文件末尾，为所有Resilience4J电路断路器定义一个默认配置。
- en: Listing 9.8 Configuring circuit breaker and time limiter
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.8 配置电路断路器和时间限制器
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Default configuration bean for all circuit breakers
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 所有电路断路器的默认配置Bean
- en: ❷ The size of the sliding window used to record the outcome of calls when the
    circuit is closed
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 电路关闭时记录调用结果的滑动窗口大小
- en: ❸ Number of permitted calls when the circuit is half-open
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 电路半开启时的允许调用数
- en: ❹ When the failure rate is above the threshold, the circuit becomes open.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 当失败率高于阈值时，电路变为开启。
- en: ❺ Waiting time before moving from open to half-open (ms)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 从开启状态到半开启状态前的等待时间（毫秒）
- en: ❻ Default configuration bean for all time limiters
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 所有时间限制器的默认配置Bean
- en: ❼ Configures a timeout (seconds)
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 配置超时（秒）
- en: We configure both the circuit breaker and a time limiter, a required component
    when using the Resilience4J implementation of Spring Cloud Circuit Breaker. The
    timeout configured via Resilience4J will take precedence over the response timeout
    we defined in the previous section for the Netty HTTP client (spring.cloud.gateway.httpclient.response-timeout).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们配置了电路断路器和时间限制器，这是在使用Spring Cloud Circuit Breaker的Resilience4J实现时必需的组件。通过Resilience4J配置的超时将优先于我们在上一节中为Netty
    HTTP客户端定义的响应超时（spring.cloud.gateway.httpclient.response-timeout）。
- en: When a circuit breaker switches to the open state, we’ll want at least to degrade
    the service level gracefully and make the user experience as pleasant as possible.
    I’ll show you how to do that in the next section.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 当电路断路器切换到开启状态时，我们希望至少优雅地降低服务级别，并尽可能让用户体验愉快。我将在下一节中展示如何做到这一点。
- en: 9.2.3 Defining fallback REST APIs with Spring WebFlux
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 使用Spring WebFlux定义回退REST API
- en: When we added the CircuitBreaker filter to catalog-route, we defined a value
    for the fallbackUri property to forward the requests to the /catalog-fallback
    endpoint when the circuit is in an open state. Since the Retry filter is also
    applied to that route, the fallback endpoint will be invoked even when all retry
    attempts fail for a given request. It’s time to define that endpoint.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将CircuitBreaker过滤器添加到catalog-route时，我们为fallbackUri属性定义了一个值，当电路处于开启状态时，将请求转发到/catalog-fallback端点。由于重试过滤器也应用于该路由，即使对于给定请求的所有重试尝试都失败，回退端点也会被调用。是时候定义该端点了。
- en: As I mentioned in previous chapters, Spring supports defining REST endpoints
    either using @RestController classes or router functions. Let’s use the functional
    way of declaring the fallback endpoints.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在前面的章节中提到的，Spring支持使用@RestController类或路由函数来定义REST端点。让我们使用声明回退端点的函数式方法。
- en: In a new com.polarbookshop.edgeservice.web package in the Edge Service project,
    create a new WebEndpoints class. Functional endpoints in Spring WebFlux are defined
    as routes in a RouterFunction<ServerResponse> bean, using the fluent API provided
    by RouterFunctions. For each route, you need to define the endpoint URL, a method,
    and a handler.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在Edge Service项目的com.polarbookshop.edgeservice.web包中创建一个新的WebEndpoints类。在Spring
    WebFlux中，功能端点作为RouterFunction<ServerResponse> Bean中的路由定义，使用RouterFunctions提供的流畅API。对于每个路由，你需要定义端点URL、一个方法和一个处理器。
- en: Listing 9.9 Fallback endpoints for when the Catalog Service is down
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.9 当目录服务不可用时回退端点
- en: '[PRE13]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Functional REST endpoints are defined in a bean.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在一个 bean 中定义功能 REST 端点。
- en: ❷ Offers a fluent API to build routes
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 提供一个流畅的 API 来构建路由
- en: ❸ Fallback response used to handle the GET endpoint
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 用于处理 GET 端点的回退响应
- en: ❹ Fallback response used to handle the POST endpoint
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 用于处理 POST 端点的回退响应
- en: ❺ Builds the functional endpoints
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 构建功能端点
- en: For simplicity, the fallback for GET requests returns an empty string, whereas
    the fallback for POST requests returns an HTTP 503 error. In a real scenario,
    you might want to adopt different fallback strategies depending on the context,
    including throwing a custom exception to be handled from the client or returning
    the last value saved in the cache for the original request.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，GET 请求的回退返回一个空字符串，而 POST 请求的回退返回 HTTP 503 错误。在实际场景中，你可能希望根据上下文采用不同的回退策略，包括抛出自定义异常由客户端处理或返回原始请求保存的最后一个值。
- en: So far, we have used retries, timeouts, circuit breakers, and failovers (fallbacks).
    In the next section, I’ll expand on how we can work with all those resilience
    patterns together.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经使用了重试、超时、断路器和故障转移（回退）。在下一节中，我将扩展我们如何一起使用所有这些弹性模式。
- en: 9.2.4 Combining circuit breakers, retries, and time limiters
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.4 结合断路器、重试和时限器
- en: When you combine multiple resilience patterns, the sequence in which they are
    applied is fundamental. Spring Cloud Gateway takes care of applying the TimeLimiter
    first (or the timeout on the HTTP client), then the CircuitBreaker filter, and
    finally Retry. Figure 9.5 shows how these patterns work together to increase the
    application’s resilience.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当你结合多个弹性模式时，它们应用的顺序是基本的。Spring Cloud Gateway 负责首先应用 TimeLimiter（或 HTTP 客户端的超时），然后是
    CircuitBreaker 过滤器，最后是 Retry。图 9.5 展示了这些模式如何一起工作以增加应用程序的弹性。
- en: '![09-05](../Images/09-05.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![09-05](../Images/09-05.png)'
- en: Figure 9.5 When multiple resilience patterns are implemented, they are applied
    in a specific sequence.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 当实现多个弹性模式时，它们按照特定的顺序应用。
- en: You can verify the result of applying these patterns to Edge Service by using
    a tool like Apache Benchmark ([https://httpd.apache.org/docs/2.4/programs/ab.html](https://httpd.apache.org/docs/2.4/programs/ab.html)).
    If you’re using macOS or Linux, you might have this tool already installed. Otherwise,
    you can follow the instructions on the official website and install it.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 Apache Benchmark 等工具（[https://httpd.apache.org/docs/2.4/programs/ab.html](https://httpd.apache.org/docs/2.4/programs/ab.html)）来验证这些模式应用于边缘服务的结果。如果你使用的是
    macOS 或 Linux，你可能已经安装了此工具。否则，你可以按照官方网站上的说明进行安装。
- en: Make sure both Catalog Service and Order Service are not running so that you
    can test circuit breakers in a failure scenario. Then enable debug logging for
    Resilience4J so you can follow the state transitions of the circuit breaker. At
    the end of the application.yml file in your Edge Service project, add the following
    configuration.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 确保目录服务和订单服务都没有运行，这样你就可以在故障场景中测试断路器。然后启用 Resilience4J 的调试日志，以便你可以跟踪断路器的状态转换。在你的边缘服务项目中的应用.yml
    文件末尾，添加以下配置。
- en: Listing 9.10 Enabling debug logging for Resilience4J
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.10 启用 Resilience4J 的调试日志
- en: '[PRE14]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, build and run Edge Service (./gradlew bootRun). Since no downstream services
    are running (if they are, you should stop them), all the requests sent to them
    from Edge Service will result in errors. Let’s see what happens if we run 21 sequential
    POST requests (-n 21 -c 1 -m POST) to the /orders endpoint. Remember that POST
    requests have no retry configuration, and order-route has no fallback, so the
    result will only be affected by the timeout and circuit breaker:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，构建并运行边缘服务（./gradlew bootRun）。由于没有下游服务正在运行（如果有的话，你应该停止它们），从边缘服务发送到它们的所有请求都将导致错误。让我们看看如果我们向
    /orders 端点运行 21 个连续的 POST 请求（-n 21 -c 1 -m POST）会发生什么。记住，POST 请求没有重试配置，order-route
    没有回退，所以结果将仅受超时和断路器的影响：
- en: '[PRE15]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'From the ab output, you can see that all the requests returned an error:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 从 ab 输出中，你可以看到所有请求都返回了错误：
- en: '[PRE16]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The circuit breaker is configured to trip to the open state when at least 50%
    of the calls in a 20-sized time window fails. Since you have just started the
    application, the circuit will transition to the open state after 20 requests.
    In the application logs, you can analyze how the requests have been handled. All
    the requests failed, so the circuit breaker registers an ERROR event for each
    of them:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个20秒时间窗口内的至少50%的调用失败时，断路器被配置为跳转到开启状态。由于您刚刚启动了应用程序，电路将在20次请求后过渡到开启状态。在应用程序日志中，您可以分析请求是如何被处理的。所有请求都失败了，因此断路器为每个请求注册了一个ERROR事件：
- en: '[PRE17]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'At the 20th request, a FAILURE_RATE_EXCEEDED event is recorded because it exceeded
    the failure threshold. That will result in a STATE_TRANSITION event that will
    open the circuit:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在第20次请求时，记录了一个FAILURE_RATE_EXCEEDED事件，因为它超过了失败阈值。这将导致一个STATE_TRANSITION事件，打开电路：
- en: '[PRE18]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The 21st request will not even try contacting Order Service: the circuit is
    open, so it cannot go through. A NOT_PERMITTED event is registered to signal why
    the request failed:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 第21次请求甚至不会尝试联系订单服务：断路器处于开启状态，因此无法通过。注册了一个NOT_PERMITTED事件来表示请求失败的原因：
- en: '[PRE19]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Note Monitoring the status of circuit breakers in production is a critical
    task. In chapter 13, I’ll show you how to export that information as Prometheus
    metrics that you can visualize in a Grafana dashboard instead of checking the
    logs. In the meantime, for a more visual explanation, feel free to watch my “Spring
    Cloud Gateway: Resilience, Security, and Observability” session on circuit breakers
    at Spring I/O, 2022 ([http://mng.bz/z55A](http://mng.bz/z55A)).'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '注意：在生产环境中监控断路器的状态是一项关键任务。在第13章中，我将向您展示如何将此信息导出为Prometheus指标，您可以在Grafana仪表板上可视化这些指标，而不是检查日志。同时，为了更直观的解释，您可以自由观看我在2022年Spring
    I/O上关于断路器的“Spring Cloud Gateway: Resilience, Security, and Observability”会议（[http://mng.bz/z55A](http://mng.bz/z55A)）。'
- en: 'Now let’s see what happens when we call a GET endpoint for which both retries
    and fallback have been configured. Before proceeding, rerun the application so
    you can start with a clear circuit breaker state (./gradlew bootRun). Then run
    the following command:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看当我们调用已配置重试和回退的GET端点时会发生什么。在继续之前，重新运行应用程序，以便您可以从清晰的断路器状态开始（./gradlew bootRun）。然后运行以下命令：
- en: '[PRE20]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'If you check the application logs, you’ll see how the circuit breaker behaves
    precisely like before: 20 allowed requests (closed circuit), followed by a non-permitted
    request (open circuit). However, the result of the previous command shows 21 requests
    completed with no errors:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您检查应用程序日志，您将看到断路器的行为与之前完全一样：20个允许的请求（关闭电路），然后是一个不允许的请求（开启电路）。然而，上一个命令的结果显示有21个请求完成且没有错误：
- en: '[PRE21]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This time, all requests have been forwarded to the fallback endpoint, so the
    client didn’t experience any errors.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，所有请求都已转发到回退端点，因此客户端没有遇到任何错误。
- en: We configured the Retry filter to be triggered when an IOException or TimeoutException
    occurs. In this case, since the downstream service is not running, the exception
    thrown is of type ConnectException, so the request is conveniently not retried,
    which allowed me to show you the combined behavior of circuit breakers and fallbacks
    without retries.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们配置了重试过滤器，使其在发生IOException或TimeoutException时触发。在这种情况下，由于下游服务没有运行，抛出的异常是ConnectException类型，因此请求方便地没有被重试，这让我能够向您展示在无需重试的情况下断路器和回退的组合行为。
- en: So far we have looked at patterns that make the interactions between Edge Service
    and the downstream applications more resilient. What about the entry point of
    the system? The next section will introduce rate limiters, which will control
    the request flow coming into the system through the Edge Service application.
    Before proceeding, stop the application’s execution with Ctrl-C.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了使边缘服务和下游应用程序之间的交互更具弹性的模式。那么系统的入口点呢？下一节将介绍速率限制器，它将通过边缘服务应用程序控制进入系统的请求流。在继续之前，使用Ctrl-C停止应用程序的执行。
- en: 9.3 Request rate limiting with Spring Cloud Gateway and Redis
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 使用Spring Cloud Gateway和Redis进行请求速率限制
- en: Rate limiting is a pattern used to control the rate of traffic sent to or received
    from an application, helping to make your system more resilient and robust. In
    the context of HTTP interactions, you can apply this pattern to control outgoing
    or incoming network traffic using client-side and server-side rate limiters, respectively.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 速率限制是一种用于控制发送到或从应用程序接收的流量速率的模式，有助于使您的系统更具弹性和健壮性。在HTTP交互的上下文中，您可以使用这种模式分别通过客户端和服务器端速率限制器来控制出站或入站网络流量。
- en: '*Client-side rate limiters* are for constraining the number of requests sent
    to a downstream service in a given period. It’s a useful pattern to adopt when
    third-party organizations like cloud providers manage and offer the downstream
    service. You’ll want to avoid incurring extra costs for having sent more requests
    than are allowed by your subscription. In the case of pay-per-use services, this
    helps prevent unexpected expenses.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*客户端速率限制器* 用于限制在给定时间段内发送到下游服务的请求数量。当第三方组织，如云提供商管理和提供下游服务时，这是一个有用的模式。您希望避免因发送超出订阅允许的请求数量而产生额外费用。在按使用付费的服务中，这有助于防止意外费用。'
- en: If the downstream service belongs to your system, you might use a rate limiter
    to avoid causing DoS problems for yourself. In this case, though, a *bulkhead*
    pattern (or *concurrent request limiter*) would be a better fit, setting constraints
    on how many concurrent requests are allowed and queuing up the blocked ones. Even
    better is an adaptive bulkhead, for which the concurrency limits are dynamically
    updated by an algorithm to better adapt to the elasticity of cloud infrastructure.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如果下游服务属于您的系统，您可能使用速率限制器来避免给自己造成 DoS 问题。然而，在这种情况下，*bulkhead* 模式（或 *并发请求限制器*）将更适合，它会对允许的并发请求数量设置限制，并将阻塞的请求排队。更好的是自适应
    bulkhead，其并发限制会由算法动态更新，以更好地适应云基础设施的弹性。
- en: '*Server-side rate limiters* are for constraining the number of requests received
    by an upstream service (or client) in a given period. This pattern is handy when
    implemented in an API gateway to protect the whole system from overloading or
    from DoS attacks. When the number of users increases, the system should scale
    in a resilient way, ensuring an acceptable quality of service for all users. Sudden
    increases in user traffic are expected, and they are usually initially addressed
    by adding more resources to the infrastructure or more application instances.
    Over time, though, they can become a problem and even lead to service outages.
    Server-side rate limiters help with that.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '*服务器端速率限制器* 用于限制在给定时间段内接收到的上游服务（或客户端）的请求数量。当在 API 网关中实现时，这种模式便于保护整个系统免受过载或
    DoS 攻击。当用户数量增加时，系统应以弹性的方式扩展，确保所有用户都能获得可接受的服务质量。预计用户流量会突然增加，通常最初通过向基础设施或更多应用程序实例添加更多资源来应对。然而，随着时间的推移，它们可能成为问题，甚至导致服务中断。服务器端速率限制器有助于解决这个问题。'
- en: When a user has exceeded the number of allowed requests in a specific time window,
    all the extra requests are rejected with an HTTP 429 - Too Many Requests status.
    The limit is applied according to a given strategy. For example, you can limit
    requests per session, per IP address, per user, or per tenant. The overall goal
    is to keep the system available for all users in case of adversity. That is the
    definition of resilience. This pattern is also handy for offering services to
    users depending on their subscription tiers. For example, you might define different
    rate limits for basic, premium, and enterprise users.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户在特定时间窗口内超出允许的请求数量时，所有额外的请求都会以 HTTP 429 - Too Many Requests（请求过多）的状态被拒绝。限制是根据给定的策略应用的。例如，您可以按会话、按
    IP 地址、按用户或按租户限制请求。整体目标是在逆境中保持系统对所有用户的可用性。这就是弹性的定义。这种模式也便于根据用户的订阅级别提供服务。例如，您可能为基本用户、高级用户和企业用户定义不同的速率限制。
- en: Resilience4J supports the client-side rate limiter and bulkhead patterns for
    both reactive and non-reactive applications. Spring Cloud Gateway supports the
    server-side rate limiter pattern, and this section will show you how to use it
    for Edge Service by using Spring Cloud Gateway and Spring Data Redis Reactive.
    Let’s start with setting up a Redis container.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: Resilience4J 支持客户端速率限制器和 bulkhead 模式，适用于反应性和非反应性应用程序。Spring Cloud Gateway 支持服务器端速率限制器模式，本节将向您展示如何使用
    Spring Cloud Gateway 和 Spring Data Redis Reactive 通过边缘服务使用它。让我们从设置 Redis 容器开始。
- en: 9.3.1 Running Redis as a container
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 将 Redis 作为容器运行
- en: Imagine you want to limit access to your API so that each user can only perform
    10 requests per second. Implementing such a requirement would require a storage
    mechanism to track the number of requests each user performs every second. When
    the limit is reached, the following requests should be rejected. When the second
    is over, each user can perform 10 more requests within the next second. The data
    used by the rate-limiting algorithm is small and temporary, so you might think
    of saving it in memory inside the application itself.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想限制对 API 的访问，以便每个用户每秒只能执行 10 个请求。实现这样的要求需要一个存储机制来跟踪每个用户每秒执行的请求数量。当达到限制时，应拒绝后续请求。当秒数结束时，每个用户可以在下一个秒内再执行
    10 个请求。速率限制算法使用的数据量小且临时，因此你可能想将其保存在应用程序本身的内存中。
- en: However, that would make the application stateful and lead to errors, since
    each application instance would limit requests based on a partial data set. It
    would mean letting users perform 10 requests per second per instance rather than
    overall, because each instance would only keep track of its own incoming requests.
    The solution is to use a dedicated data service to store the rate-limiting state
    and make it available to all the application replicas. Enter Redis.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这样做会使应用程序具有状态性并导致错误，因为每个应用程序实例都会根据部分数据集来限制请求。这意味着让用户在每个实例上每秒执行 10 个请求，而不是整体上，因为每个实例只会跟踪自己的传入请求。解决方案是使用一个专门的数据服务来存储速率限制状态，并使其对所有应用程序副本可用。这就是
    Redis 的作用。
- en: Redis ([https://redis.com](https://redis.com)) is an in-memory store that is
    commonly used as a cache, message broker, or database. In Edge Service, we’ll
    use it as the data service backing the request rate limiter implementation provided
    by Spring Cloud Gateway. The Spring Data Redis Reactive project provides the integration
    between a Spring Boot application and Redis.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: Redis ([https://redis.com](https://redis.com)) 是一个内存存储，通常用作缓存、消息代理或数据库。在 Edge
    Service 中，我们将使用它作为 Spring Cloud Gateway 提供的请求速率限制实现背后的数据服务。Spring Data Redis Reactive
    项目提供了 Spring Boot 应用程序与 Redis 之间的集成。
- en: Let’s first define a Redis container. Open the docker-compose.yml file you created
    in your polar-deployment repository. (If you haven’t followed along with the examples,
    you can use Chapter09/09-begin/polar-deployment/docker/docker-compose.yml from
    the source code accompanying the book as a starting point.) Then add a new service
    definition using the Redis official image, and expose it through port 6379.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义一个 Redis 容器。打开你在 polar-deployment 仓库中创建的 docker-compose.yml 文件。（如果你没有跟随示例进行操作，你可以使用书中附带的源代码中的
    Chapter09/09-begin/polar-deployment/docker/docker-compose.yml 作为起点。）然后，使用 Redis
    官方镜像添加一个新的服务定义，并通过端口 6379 公开它。
- en: Listing 9.11 Defining a Redis container
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.11 定义 Redis 容器
- en: '[PRE22]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Uses Redis 7.0
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用 Redis 7.0
- en: ❷ Exposes Redis through port 6379
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 通过端口 6379 公开 Redis
- en: 'Next, open a Terminal window, navigate to the folder where your docker-compose.yml
    file is located, and run the following command to start a Redis container:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，打开一个终端窗口，导航到你的 docker-compose.yml 文件所在的文件夹，并运行以下命令以启动一个 Redis 容器：
- en: '[PRE23]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In the following section, you’ll configure the Redis integration with Edge Service.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将配置 Redis 与 Edge Service 的集成。
- en: 9.3.2 Integrating Spring with Redis
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 集成 Spring 与 Redis
- en: The Spring Data project has modules supporting several database options. In
    the previous chapters, we worked with Spring Data JDBC and Spring Data R2DBC to
    use relational databases. Now we’ll use Spring Data Redis, which provides support
    for this in-memory, non-relational data store. Both imperative and reactive applications
    are supported.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Data 项目有支持多个数据库选项的模块。在前几章中，我们使用了 Spring Data JDBC 和 Spring Data R2DBC
    来使用关系数据库。现在我们将使用 Spring Data Redis，它提供了对这个内存型非关系数据存储的支持。它支持命令式和响应式应用程序。
- en: First we need to add a new dependency on Spring Data Redis Reactive in the build.gradle
    file of the Edge Service project (edge-service). Remember to refresh or reimport
    the Gradle dependencies after the new addition.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要在 Edge Service 项目（edge-service）的 build.gradle 文件中添加一个新的依赖项 Spring Data
    Redis Reactive。记住，在添加新依赖项后，要刷新或重新导入 Gradle 依赖项。
- en: Listing 9.12 Adding dependency for Spring Data Redis Reactive
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.12 添加 Spring Data Redis Reactive 依赖项
- en: '[PRE24]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Then, in the application.yml file, configure the Redis integration through the
    properties provided by Spring Boot. Besides spring.redis.host and spring.redis.port
    for defining where to reach Redis, you can also specify connection and read timeouts
    using spring.redis.connect-timeout and spring.redis.timeout respectively.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 application.yml 文件中，通过 Spring Boot 提供的属性配置 Redis 集成。除了 spring.redis.host
    和 spring.redis.port 用于定义如何连接 Redis 之外，您还可以分别使用 spring.redis.connect-timeout 和
    spring.redis.timeout 指定连接和读取超时。
- en: Listing 9.13 Configuring the Redis integration
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.13 配置 Redis 集成
- en: '[PRE25]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: ❶ Time limit for a connection to be established
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 建立连接的时间限制
- en: ❷ Default Redis host
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 默认 Redis 主机
- en: ❸ Default Redis port
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 默认 Redis 端口
- en: ❹ Time limit for a response to be received
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 接收响应的时间限制
- en: In the next section, you’ll see how to use Redis to back the RequestRateLimiter
    gateway filter that provides server-side rate limiting support.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将了解如何使用 Redis 来支持 RequestRateLimiter 网关过滤器的服务器端速率限制。
- en: 9.3.3 Configuring a request rate limiter
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.3 配置请求速率限制器
- en: Depending on the requirements, you can configure the RequestRateLimiter filter
    for specific routes or as a default filter. In this case we’ll configure it as
    a default filter so that it’s applied to all routes, current and future.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 根据需求，您可以配置 RequestRateLimiter 过滤器针对特定路由或作为默认过滤器。在这种情况下，我们将将其配置为默认过滤器，以便应用于所有路由，包括当前和未来的路由。
- en: The implementation of RequestRateLimiter on Redis is based on the *token bucket
    algorithm*. Each user is assigned a bucket inside which tokens are dripped over
    time at a specific rate (the *replenish rate*). Each bucket has a maximum capacity
    (the *burst capacity*). When a user makes a request, a token is removed from its
    bucket. When there are no more tokens left, the request is not permitted, and
    the user will have to wait until more tokens are dripped into its bucket.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: RequestRateLimiter 在 Redis 上的实现基于 *令牌桶算法*。每个用户都会分配一个桶，其中以特定速率（*补充速率*）在一段时间内滴入令牌。每个桶都有一个最大容量（*突发容量*）。当用户发起请求时，会从其桶中移除一个令牌。当没有更多令牌时，请求将不被允许，用户将不得不等待直到更多令牌滴入其桶中。
- en: Note If you want to know more about the token bucket algorithm, I recommend
    reading Paul Tarjan’s “Scaling your API with Rate Limiters” article about how
    they use it to implement rate limiters at Stripe ([https://stripe.com/blog/rate-limiters](https://stripe.com/blog/rate-limiters)).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您想了解更多关于令牌桶算法的信息，我建议阅读 Paul Tarjan 的“使用速率限制器扩展您的 API”文章，该文章介绍了他们如何在 Stripe
    中使用它来实现速率限制器（[https://stripe.com/blog/rate-limiters](https://stripe.com/blog/rate-limiters)）。
- en: For this example, let’s configure the algorithm so that each request costs 1
    token (redis-rate-limiter.requestedTokens). Tokens are dripped in the bucket following
    the configured replenish rate (redis-rate-limiter.replenishRate), which we’ll
    set as 10 tokens per second. Sometimes there might be spikes, resulting in a larger
    number of requests than usual. You can allow temporary bursts by defining a larger
    capacity for the bucket (redis-rate-limiter.burstCapacity), such as 20. This means
    that when a spike occurs, up to 20 requests are allowed per second. Since the
    replenish rate is lower than the burst capacity, subsequent bursts are not allowed.
    If two spikes happen sequentially, only the first one will succeed, while the
    second will result in some requests being dropped with an HTTP 429 - Too Many
    Requests response. The resulting configuration in the application.yml file is
    shown in the following listing.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，让我们配置算法，使得每个请求消耗 1 个令牌（redis-rate-limiter.requestedTokens）。令牌会按照配置的补充速率（redis-rate-limiter.replenishRate）滴入桶中，我们将将其设置为每秒
    10 个令牌。有时可能会出现峰值，导致请求数量比平常多。您可以通过为桶定义更大的容量（redis-rate-limiter.burstCapacity）来允许暂时的突发，例如
    20。这意味着当出现峰值时，每秒最多允许 20 个请求。由于补充速率低于突发容量，后续的突发是不允许的。如果连续出现两个峰值，只有第一个会成功，而第二个将导致一些请求被丢弃，并返回
    HTTP 429 - 请求过多的响应。以下是在 application.yml 文件中的配置示例。
- en: Listing 9.14 Configuring a request rate limiter as a gateway filter
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.14 配置请求速率限制器作为网关过滤器
- en: '[PRE26]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ Number of tokens dripped in the bucket each second
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 每秒桶中滴入的令牌数量
- en: ❷ Allows request bursts of up to 20 requests
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 允许最多 20 个请求的突发
- en: ❸ How many tokens a request costs
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 请求消耗的令牌数量
- en: 'There’s no general rule to follow in coming up with good numbers for the request
    rate limiter. You should start with your application requirements and go with
    a trial and error approach: analyze your production traffic, tune the configuration,
    and do this all over again until you achieve a setup that keeps your system available
    while not affecting the user experience badly. Even after that, you should keep
    monitoring the status of your rate limiters, since things can change in the future.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在为请求速率限制器选择好的数字时没有一般规则可遵循。你应该从应用程序需求开始，采用试错法：分析你的生产流量，调整配置，然后重复此过程，直到你达到一个设置，既能保持系统可用，又不会严重影响用户体验。即使在那之后，你也应该继续监控速率限制器的状态，因为未来可能会有变化。
- en: Spring Cloud Gateway relies on Redis to keep track of the number of requests
    happening each second. By default, each user is assigned a bucket. However, we
    haven’t introduced an authentication mechanism yet, so we’ll use a single bucket
    for all requests until we address the security concerns in chapters 11 and 12.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway依赖于Redis来跟踪每秒发生的请求数量。默认情况下，每个用户都会分配一个桶。然而，我们还没有介绍认证机制，所以我们将使用单个桶处理所有请求，直到我们在第11章和第12章解决安全担忧。
- en: Note What happens if Redis becomes unavailable? Spring Cloud Gateway has been
    built with resilience in mind, so it will keep its service level, but the rate
    limiters would be disabled until Redis is up and running again.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果Redis变得不可用会发生什么？Spring Cloud Gateway已经考虑到容错性，所以它将保持其服务水平，但速率限制器将禁用，直到Redis再次运行起来。
- en: The RequestRateLimiter filter relies on a KeyResolver bean to determine which
    bucket to use for each request. By default, it uses the currently authenticated
    user in Spring Security. Until we add security to Edge Service, we’ll define a
    custom KeyResolver bean and make it return a constant value (for example, anonymous)
    so that all requests will be mapped to the same bucket.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 请求速率限制器过滤器依赖于KeyResolver bean来确定每个请求使用哪个桶。默认情况下，它使用Spring Security中当前认证的用户。在我们为Edge
    Service添加安全功能之前，我们将定义一个自定义的KeyResolver bean，并使其返回一个常量值（例如，匿名），这样所有请求都将映射到同一个桶。
- en: In your Edge Service project, create a RateLimiterConfig class in a new com.polarbookshop.edgeservice.config
    package, and declare a KeyResolver bean, implementing a strategy to return a constant
    key.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的Edge Service项目中，在新的com.polarbookshop.edgeservice.config包中创建一个RateLimiterConfig类，并声明一个KeyResolver
    bean，实现一个返回常量键的策略。
- en: Listing 9.15 Defining a strategy to resolve the bucket to use per request
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.15 定义一个策略以解决每个请求使用的桶
- en: '[PRE27]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ Rate limiting is applied to requests using a constant key.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用常量键对请求进行速率限制。
- en: Spring Cloud Gateway is configured to append headers with details about rate-limiting
    to each HTTP response, which we can use to verify its behavior. Rebuild and run
    Edge Service (./gradlew bootRun), and then try calling one of the endpoints.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway配置为将有关速率限制的详细信息附加到每个HTTP响应中，我们可以使用它来验证其行为。重新构建并运行Edge Service（./gradlew
    bootRun），然后尝试调用其中一个端点。
- en: '[PRE28]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The response body depends on whether Catalog Service is running or not, but
    that doesn’t matter in this example. The interesting aspect to notice is the HTTP
    headers of the response. They show the rate limiter’s configuration and the number
    of remaining requests allowed within the time window (1 second):'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 响应体取决于目录服务是否正在运行，但在本例中这不重要。需要注意的是响应的HTTP头。它们显示了速率限制器的配置以及时间窗口（1秒）内允许的剩余请求数量：
- en: '[PRE29]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: You might not want to expose this information to clients in cases where the
    information could help bad actors craft attacks against your system. Or you might
    need different header names. Either way, you can use the spring.cloud.gateway.redis-rate-limiter
    property group to configure that behavior. When you’re done testing the application,
    stop it with Ctrl-C.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，你可能不希望将此信息暴露给客户端，因为这可能会帮助恶意行为者针对你的系统进行攻击。或者你可能需要不同的头名称。无论如何，你可以使用spring.cloud.gateway.redis-rate-limiter属性组来配置这种行为。完成应用程序测试后，使用Ctrl-C停止它。
- en: Note When the rate limiter pattern is combined with other patterns like time
    limiters, circuit breakers, and retries, the rate limiter is applied first. If
    a user’s request exceeds the rate limit, it is rejected right away.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：当速率限制器模式与其他模式（如时间限制器、断路器和重试）结合使用时，速率限制器首先应用。如果用户的请求超过速率限制，它将立即被拒绝。
- en: 'Redis is an efficient data store ensuring fast data access, high availability,
    and resilience. In this section, we used it to provide storage for the rate limiters,
    and the next section will show you how to use it in another common scenario: session
    management.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Redis 是一个高效的数据存储，确保快速数据访问、高可用性和弹性。在本节中，我们使用它来提供速率限制器的存储，下一节将向你展示如何在另一个常见场景中使用它：会话管理。
- en: 9.4 Distributed session management with Redis
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 使用 Redis 进行分布式会话管理
- en: In the previous chapters, I often highlighted how cloud native applications
    should be stateless. We scale them in and out, and if they weren’t stateless,
    we would lose the state every time an instance is shut down. Some state needs
    to be saved, or the applications would probably be useless. For example, Catalog
    Service and Order Service are stateless, but they rely on a stateful service (the
    PostgreSQL database) to permanently store the data about books and orders. Even
    if the applications are shut down, the data will survive and be available to all
    the application instances.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我经常强调云原生应用应该是无状态的。我们对其进行扩展和缩减，如果它们不是无状态的，每次实例关闭时我们都会丢失状态。某些状态需要保存，否则应用程序可能毫无用处。例如，目录服务和订单服务是无状态的，但它们依赖于一个有状态的服务（PostgreSQL
    数据库）来永久存储关于书籍和订单的数据。即使应用程序关闭，数据也会存活并可供所有应用程序实例访问。
- en: Edge Service is not dealing with any business entities it needs to store, but
    it still needs a stateful service (Redis) to store the state related to the RequestRateLimiter
    filter. When Edge Service is replicated, it’s important to keep track of how many
    requests are left before exceeding the threshold. Using Redis, the rate limiter
    functionality is guaranteed consistently and safely.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘服务不处理任何需要存储的业务实体，但它仍然需要一个有状态的服务（Redis）来存储与请求速率限制器过滤器相关的状态。当边缘服务被复制时，跟踪在超过阈值之前剩余多少请求是很重要的。使用
    Redis，速率限制功能可以保证一致性和安全性。
- en: Furthermore, in chapter 11 you’ll expand Edge Service to add authentication
    and authorization. Since it’s the entry point to the Polar Bookshop system, it
    makes sense to authenticate the user there. Data about the authenticated session
    will have to be saved outside the application for the same reason as the rate
    limiter information is. If it wasn’t, the user might have to authenticate themselves
    every time a request hits a different Edge Service instance.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在第 11 章中，你将扩展边缘服务以添加身份验证和授权。由于它是 Polar 书店系统的入口点，因此在那里进行用户身份验证是有意义的。由于与速率限制器信息相同的原因，必须将已验证会话的数据保存在应用程序之外。如果不是这样，用户可能每次请求击中不同的边缘服务实例时都需要进行身份验证。
- en: The general idea is to keep the applications stateless and use data services
    for storing the state. As you learned in chapter 5, data services need to guarantee
    high availability, replication, and durability. In your local environment, you
    can ignore that aspect, but in production you’ll rely on the data services offered
    by cloud providers, both for PostgreSQL and Redis.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 通用思路是保持应用程序无状态，并使用数据服务来存储状态。正如你在第 5 章中学到的，数据服务需要保证高可用性、复制和持久性。在你的本地环境中，你可以忽略这一点，但在生产环境中，你将依赖于云提供商提供的数据服务，无论是
    PostgreSQL 还是 Redis。
- en: The following section will cover how you can work with Spring Session Data Redis
    to establish distributed session management.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分将介绍如何使用 Spring Session Data Redis 来建立分布式会话管理。
- en: 9.4.1 Handling sessions with Spring Session Data Redis
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.1 使用 Spring Session Data Redis 处理会话
- en: Spring provides session management features with the Spring Session project.
    By default, session data is stored in memory, but that’s not feasible in a cloud
    native application. You want to keep it in an external service so that the data
    survives the application shutdown. Another fundamental reason for using a distributed
    session store is that you usually have multiple instances of a given application.
    You’ll want them to access the same session data to provide a seamless experience
    to the user.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Spring 通过 Spring Session 项目提供会话管理功能。默认情况下，会话数据存储在内存中，但这在云原生应用程序中是不可行的。你希望将其保存在外部服务中，以便数据在应用程序关闭后仍然存在。使用分布式会话存储的另一个基本原因是，通常你有一个给定应用程序的多个实例。你希望它们能够访问相同的会话数据，以向用户提供无缝体验。
- en: Redis is a popular option for session management, and it’s supported by Spring
    Session Data Redis. Furthermore, you have already set it up for the rate limiters.
    You can add it to Edge Service with minimal configuration.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: Redis 是会话管理的一个流行选项，并且它由 Spring Session Data Redis 支持。此外，您已经为速率限制器设置了它。您可以通过最小配置将其添加到
    Edge Service 中。
- en: First you need to add a new dependency on Spring Session Data Redis to the build.gradle
    file for the Edge Service project. You can also add the Testcontainers library
    so you can use a lightweight Redis container when writing integration tests. Remember
    to refresh and reimport the Gradle dependencies after the new addition.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要在 Edge Service 项目的 build.gradle 文件中添加对 Spring Session Data Redis 的新依赖项。您还可以添加
    Testcontainers 库，以便在编写集成测试时使用轻量级的 Redis 容器。请记住，在添加新依赖项后刷新并重新导入 Gradle 依赖项。
- en: Listing 9.16 Adding dependency for Spring Session and Testcontainers
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.16 为 Spring Session 和 Testcontainers 添加依赖
- en: '[PRE30]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Next, you need to instruct Spring Boot to use Redis for session management (spring.session.store-type)
    and define a unique namespace to prefix all session data coming from Edge Service
    (spring.session.redis.namespace). You can also define a timeout for the session
    (spring.session.timeout). If you don’t specify a timeout, the default is 30 minutes.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您需要指导 Spring Boot 使用 Redis 进行会话管理（spring.session.store-type）并定义一个唯一的命名空间来前缀所有来自
    Edge Service 的会话数据（spring.session.redis.namespace）。您还可以定义会话的超时时间（spring.session.timeout）。如果您没有指定超时时间，默认为
    30 分钟。
- en: Configure Spring Session in the application.yml file as follows.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在 application.yml 文件中配置 Spring Session 如下。
- en: Listing 9.17 Configuring Spring Session to store data in Redis
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.17 配置 Spring Session 以在 Redis 中存储数据
- en: '[PRE31]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Managing web sessions in a gateway requires some additional care to ensure you
    save the right state at the right time. In this example, we want the session to
    be saved in Redis before forwarding a request downstream. How can we do that?
    If you were thinking about whether there’s a gateway filter for it, you would
    be right!
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在网关中管理 Web 会话需要额外的注意，以确保在正确的时间保存正确的状态。在这个例子中，我们希望在将请求转发到下游之前将会话保存到 Redis 中。我们该如何做呢？如果您在考虑是否有针对它的网关过滤器，那么您是对的！
- en: In the application.yml file for the Edge Service project, add SaveSession as
    a default filter to instruct Spring Cloud Gateway to always save the web session
    before forwarding requests downstream.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Edge Service 项目的 application.yml 文件中，将 SaveSession 添加为默认过滤器，以指示 Spring Cloud
    Gateway 在将请求转发到下游之前始终保存 Web 会话。
- en: Listing 9.18 Configuring the gateway to save the session data
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.18 配置网关以保存会话数据
- en: '[PRE32]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ Ensures the session data is saved before forwarding a request downstream
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 确保在转发请求到下游之前保存会话数据
- en: That’s a critical point when Spring Session is combined with Spring Security.
    Chapters 11 and 12 will cover more details about session management. For now,
    let’s set up an integration test to verify the Spring context in Edge Service
    loads correctly, including the integration with Redis.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Spring Session 与 Spring Security 结合使用时，这是一个关键点。第 11 章和第 12 章将详细介绍会话管理。现在，让我们设置一个集成测试来验证
    Edge Service 中的 Spring 上下文是否正确加载，包括与 Redis 的集成。
- en: The approach we’ll use is similar to the one we used to define PostgreSQL test
    containers in the previous chapter. Let’s extend the existing EdgeServiceApplicationTests
    class generated by Spring Initializr and configure a Redis test container. For
    this example, it’s enough to verify that the Spring context loads correctly when
    Redis is used for storing web session-related data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的方法与我们在上一章中定义 PostgreSQL 测试容器的类似。让我们扩展由 Spring Initializr 生成的现有 EdgeServiceApplicationTests
    类，并配置一个 Redis 测试容器。对于这个例子，验证当使用 Redis 存储与 Web 会话相关的数据时，Spring 上下文是否正确加载就足够了。
- en: Listing 9.19 Using a Redis container to test the Spring context loading
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.19 使用 Redis 容器测试 Spring 上下文加载
- en: '[PRE33]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ Loads a full Spring web application context and a web environment listening
    on a random port
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载一个完整的 Spring Web 应用程序上下文和一个监听随机端口的 Web 环境
- en: ❷ Activates automatic startup and cleanup of test containers
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 激活测试容器的自动启动和清理
- en: ❸ Defines a Redis container for testing
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义用于测试的 Redis 容器
- en: ❹ Overwrites the Redis configuration to point to the test Redis instance
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 覆盖 Redis 配置以指向测试 Redis 实例
- en: ❺ An empty test used to verify that the application context is loaded correctly
    and that a connection with Redis has been established successfully
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 一个空测试用于验证应用程序上下文是否正确加载，并且与 Redis 的连接已成功建立
- en: 'Finally, run the integration tests as follows:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，按照以下步骤运行集成测试：
- en: '[PRE34]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Should you want to disable the session management through Redis in some of your
    tests, you can do so by setting the spring.session.store-type property to none
    in a specific test class using the @TestPropertySource annotation, or in a property
    file if you want to make it apply to all test classes.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在某些测试中禁用通过 Redis 的会话管理，您可以通过在特定的测试类中使用 @TestPropertySource 注解或在属性文件中设置 spring.session.store-type
    属性为 none 来实现，如果您想使其适用于所有测试类。
- en: Polar Labs
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: Polar Labs
- en: Feel free to apply what you learned in the previous chapters and prepare the
    Edge Service application for deployment.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 随意应用您在前几章中学到的知识，并为部署边缘服务做好准备。
- en: Add Spring Cloud Config Client to Edge Service to make it fetch configuration
    data from Config Service.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 Spring Cloud Config Client 添加到边缘服务中，使其能够从配置服务中获取配置数据。
- en: Configure the Cloud Native Buildpacks integration, containerize the application,
    and define the commit stage of the deployment pipeline, as you learned in chapters
    3 and 6.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置 Cloud Native Buildpacks 集成，容器化应用程序，并定义部署管道的提交阶段，正如您在第 3 章和第 6 章中学到的。
- en: Write the Deployment and Service manifests for deploying Edge Service to a Kubernetes
    cluster.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写部署和服务清单，以将边缘服务部署到 Kubernetes 集群。
- en: Configure Tilt to automate the Edge Service deployment to your local Kubernetes
    cluster initialized with minikube.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置 Tilt 以自动化将边缘服务部署到使用 minikube 初始化的本地 Kubernetes 集群。
- en: You can refer to the Chapter09/09-end folder in the code repository accompanying
    the book to check the final result ([https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action)).
    You can also deploy the backing services from the manifests available in the Chapter09/09-end/polar-deployment/kubernetes/platform/development
    folder with kubectl apply -f services.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考书中附带的代码仓库中的 Chapter09/09-end 文件夹以检查最终结果（[https://github.com/ThomasVitale/cloud-native-spring-in-action](https://github.com/ThomasVitale/cloud-native-spring-in-action)）。您还可以使用
    kubectl apply -f services 从 Chapter09/09-end/polar-deployment/kubernetes/platform/development
    文件夹中可用的清单部署支持服务。
- en: 9.5 Managing external access with Kubernetes Ingress
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.5 使用 Kubernetes Ingress 管理外部访问
- en: Spring Cloud Gateway helps you define an edge service where you can implement
    several patterns and cross-cutting concerns at the ingress point of a system.
    In the previous sections, you saw how to use it as an API gateway, implement resilience
    patterns like rate limiting and circuit breakers, and define distributed sessions.
    In chapters 11 and 12, we’ll also add authentication and authorization features
    to Edge Service.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway 帮助您定义一个边缘服务，您可以在系统的入口点实现多个模式和横切关注点。在前面的章节中，您看到了如何将其用作 API
    网关，实现诸如速率限制和断路器等弹性模式，并定义分布式会话。在第 11 章和第 12 章中，我们还将向边缘服务添加身份验证和授权功能。
- en: Edge Service represents the entry point to the Polar Bookshop system. However,
    when it’s deployed in a Kubernetes cluster, it’s only accessible from within the
    cluster itself. In chapter 7, we used the *port-forward* feature to expose a Kubernetes
    Service defined in a minikube cluster to your local computer. That’s a useful
    strategy during development, but it’s not suitable for production.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘服务代表 Polar 书店系统的入口点。然而，当它在 Kubernetes 集群中部署时，它只能从集群内部访问。在第 7 章中，我们使用了 *端口转发*
    功能，将 minikube 集群中定义的 Kubernetes 服务暴露到您的本地计算机。这在开发期间是一个有用的策略，但并不适合生产环境。
- en: This section will cover how you can manage external access to applications running
    in a Kubernetes cluster using the Ingress API.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何使用 Ingress API 管理运行在 Kubernetes 集群中的应用程序的外部访问。
- en: Note This section assumes you have gone through the tasks listed in the previous
    “Polar Labs” sidebar and prepared Edge Service for deployment on Kubernetes.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本节假设您已经完成了上一节“Polar Labs”侧边栏中列出的任务，并已为 Kubernetes 部署边缘服务做好准备。
- en: 9.5.1 Understanding Ingress API and Ingress Controller
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.1 理解 Ingress API 和 Ingress Controller
- en: When it comes to exposing applications inside a Kubernetes cluster, we can use
    a Service object of type ClusterIP. That’s what we’ve done so far to make it possible
    for Pods to interact with each other within the cluster. For example, that’s how
    Catalog Service Pods can communicate with the PostgreSQL Pod.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到在 Kubernetes 集群内部暴露应用程序时，我们可以使用类型为 ClusterIP 的 Service 对象。这正是我们迄今为止所做的一切，以便使
    Pods 能够在集群内部相互交互。例如，这就是 Catalog Service Pods 如何与 PostgreSQL Pod 进行通信的方式。
- en: A Service object can also be of type LoadBalancer, which relies on an external
    load balancer provisioned by a cloud provider to expose an application to the
    internet. We could define a LoadBalancer Service for Edge Service instead of the
    ClusterIP one. When running the system in a public cloud, the vendor would provision
    a load balancer, assign a public IP address, and all the traffic coming from that
    load balancer would be directed to the Edge Service Pods. It’s a flexible approach
    that lets you expose a service directly to the internet, and it works with different
    types of traffic.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 服务对象也可以是负载均衡器类型，它依赖于云服务提供商提供的负载均衡器来将应用程序暴露给互联网。我们可以为边缘服务定义一个负载均衡器服务，而不是集群IP服务。当在公共云中运行系统时，供应商会提供负载均衡器，分配一个公共IP地址，所有来自该负载均衡器的流量都会被导向边缘服务Pod。这是一种灵活的方法，可以直接将服务暴露给互联网，并且适用于不同类型的流量。
- en: The LoadBalancer Service approach involves assigning a different IP address
    to each service we decide to expose to the internet. Since services are directly
    exposed, we don’t have the chance to apply any further network configuration,
    such as TLS termination. We could configure HTTPS in Edge Service, route all traffic
    directed to the cluster through the gateway (even platform services that don’t
    belong to Polar Bookshop), and apply further network configuration there. The
    Spring ecosystem provides everything we need to address those concerns, and it’s
    probably what we would do in many scenarios. However, since we want to run our
    system on Kubernetes, we can manage those infrastructural concerns at the platform
    level and keep our applications simpler and more maintainable. That’s where the
    Ingress API comes in handy.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 负载均衡器服务方法涉及为决定暴露给互联网的每个服务分配不同的IP地址。由于服务是直接暴露的，我们没有机会应用任何进一步的网络配置，例如TLS终止。我们可以在边缘服务中配置HTTPS，将所有指向集群的流量通过网关路由（即使是属于极书书店平台的服务），并在那里应用进一步的网络配置。Spring生态系统提供了我们解决这些问题的所有所需工具，这可能是我们在许多场景中会做的事情。然而，由于我们想在Kubernetes上运行我们的系统，我们可以在平台级别管理这些基础设施问题，并保持我们的应用程序更简单、更易于维护。这就是Ingress
    API派上用场的地方。
- en: An *Ingress* is an object that “manages external access to the services in a
    cluster, typically HTTP. Ingress may provide load balancing, SSL termination and
    name-based virtual hosting” ([https://kubernetes.io/docs](https://kubernetes.io/docs)).
    An Ingress object acts as an entry point into a Kubernetes cluster and is capable
    of routing traffic from a single external IP address to multiple services running
    inside the cluster. We can use an Ingress object to perform load balancing, accept
    external traffic directed to a specific URL, and manage the TLS termination to
    expose the application services via HTTPS.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '*Ingress*是一个“管理集群中服务的对外访问，通常是HTTP”的对象。Ingress可能提供负载均衡、SSL终止和基于名称的虚拟主机（[https://kubernetes.io/docs](https://kubernetes.io/docs)）。Ingress对象充当Kubernetes集群的入口点，能够将来自单个外部IP地址的流量路由到集群内部运行的多项服务。我们可以使用Ingress对象进行负载均衡，接受指向特定URL的外部流量，并管理TLS终止，通过HTTPS暴露应用程序服务。'
- en: Ingress objects don’t accomplish anything by themselves. We use an Ingress object
    to declare the *desired state* in terms of routing and TLS termination. The actual
    component that enforces those rules and routes traffic from outside the cluster
    to the applications inside is the *ingress controller*. Since multiple implementations
    are available, there’s no default ingress controller included in the core Kubernetes
    distribution—it’s up to you to install one. Ingress controllers are applications
    that are usually built using reverse proxies like NGINX, HAProxy, or Envoy. Some
    examples are Ambassador Emissary, Contour, and Ingress NGINX.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress对象本身并不能完成任何事情。我们使用Ingress对象来声明关于路由和TLS终止的*期望状态*。实际执行这些规则并将流量从集群外部路由到集群内部应用程序的组件是*ingress控制器*。由于有多种实现方式，核心Kubernetes发行版中不包含默认的ingress控制器——安装一个取决于你。Ingress控制器是通常使用反向代理如NGINX、HAProxy或Envoy构建的应用程序。一些例子包括Ambassador
    Emissary、Contour和Ingress NGINX。
- en: In production, the cloud platform or dedicated tools would be used to configure
    an ingress controller. In our local environment, we’ll need some additional configuration
    to make the routing work. For the Polar Bookshop example, we’ll use Ingress NGINX
    ([https://github.com/kubernetes/ingress-nginx](https://github.com/kubernetes/ingress-nginx))
    in both environments.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，云平台或专用工具将被用来配置 Ingress 控制器。在我们的本地环境中，我们需要进行一些额外的配置才能使路由工作。对于 Polar Bookshop
    的例子，我们将在两种环境中都使用 Ingress NGINX ([https://github.com/kubernetes/ingress-nginx](https://github.com/kubernetes/ingress-nginx))。
- en: Note There are two popular ingress controllers based on NGINX. The Ingress NGINX
    project ([https://github.com/kubernetes/ingress-nginx](https://github.com/kubernetes/ingress-nginx))
    is developed, supported, and maintained in the Kubernetes project itself. It’s
    open source, and it’s what we’ll use in this book. The NGINX Controller ([www.nginx.com/products/nginx-controller](http://www.nginx.com/products/nginx-controller))
    is a product developed and maintained by the F5 NGINX company, and it comes with
    free and commercial options.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：基于 NGINX 的有两个流行的 Ingress 控制器。Ingress NGINX 项目（[https://github.com/kubernetes/ingress-nginx](https://github.com/kubernetes/ingress-nginx)）是在
    Kubernetes 项目内部开发和维护的。它是开源的，也是本书中我们将使用的内容。NGINX 控制器（[www.nginx.com/products/nginx-controller](http://www.nginx.com/products/nginx-controller)）是由
    F5 NGINX 公司开发和维护的产品，它提供了免费和商业选项。
- en: Let’s see how we can use Ingress NGINX on our local Kubernetes cluster. An ingress
    controller is a workload just like any other application running on Kubernetes,
    and it can be deployed in different ways. The simplest option would be using kubectl
    to apply its deployment manifests to the cluster. Since we use minikube to manage
    a local Kubernetes cluster, we can rely on a built-in add-on to enable the Ingress
    functionality based on Ingress NGINX.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在我们的本地 Kubernetes 集群上使用 Ingress NGINX。Ingress 控制器就像在 Kubernetes 上运行的其他任何应用程序一样是一个工作负载，并且可以以不同的方式部署。最简单的方法是使用
    kubectl 将其部署清单应用到集群中。由于我们使用 minikube 来管理本地 Kubernetes 集群，我们可以依赖一个内置的附加组件来启用基于
    Ingress NGINX 的 Ingress 功能。
- en: 'First, let’s start the polar local cluster we introduced in chapter 7\. Since
    we configured minikube to run on Docker, make sure your Docker Engine is up and
    running:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们启动在第 7 章中介绍的 polar 本地集群。由于我们配置了 minikube 在 Docker 上运行，请确保你的 Docker 引擎正在运行：
- en: '[PRE35]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next we can enable the ingress add-on, which will make sure that Ingress NGINX
    is deployed to our local cluster:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以启用 ingress 附加组件，这将确保 Ingress NGINX 被部署到我们的本地集群中：
- en: '[PRE36]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'In the end, you can get information about the different components deployed
    with Ingress NGINX as follows:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以这样获取使用 Ingress NGINX 部署的不同组件的信息：
- en: '[PRE37]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The preceding command contains an argument we haven’t encountered yet: -n ingress-nginx.
    It means that we want to fetch all objects created in the ingress-nginx *namespace*.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令包含了一个我们尚未遇到的参数：-n ingress-nginx。这意味着我们想要获取在 ingress-nginx *命名空间*中创建的所有对象。
- en: A *namespace* is “an abstraction used by Kubernetes to support isolation of
    groups of resources within a single cluster. Namespaces are used to organize objects
    in a cluster and provide a way to divide cluster resources” ([https://kubernetes.io/docs/reference/glossary](https://kubernetes.io/docs/reference/glossary)).
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '*命名空间*是“Kubernetes 用于在单个集群内支持资源组隔离的一种抽象。命名空间用于在集群中组织对象，并提供了一种划分集群资源的方法” ([https://kubernetes.io/docs/reference/glossary](https://kubernetes.io/docs/reference/glossary))。'
- en: We use namespaces to keep our clusters organized and define network policies
    to keep certain resources isolated for security reasons. So far, we’ve been working
    with the default namespace, and we’ll keep doing that for all our Polar Bookshop
    applications. However, when it comes to platform services such as Ingress NGINX,
    we’ll rely on dedicated namespaces to keep those resources isolated.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用命名空间来保持我们的集群井然有序，并定义网络策略以出于安全原因隔离某些资源。到目前为止，我们一直在使用默认命名空间，并且我们将继续在所有 Polar
    Bookshop 应用程序中使用它。然而，当涉及到 Ingress NGINX 这样的平台服务时，我们将依赖专用命名空间来隔离这些资源。
- en: Now that Ingress NGINX is installed, let’s go ahead and deploy the backing services
    used by our Polar Bookshop applications. Check the source code repository accompanying
    this book (Chapter09/09-end) and copy the content of the polar-deployment/kubernetes/platform/development
    folder into the same path in your polar-deployment repository, overwriting any
    existing file we used in previous chapters. The folder contains basic Kubernetes
    manifests to run PostgreSQL and Redis.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 现在Ingress NGINX已经安装好了，让我们继续部署Polar Bookshop应用所使用的后端服务。检查本书附带源代码仓库（第09章/09-end）并复制polar-deployment/kubernetes/platform/development文件夹的内容到你的polar-deployment仓库中相同的路径，覆盖掉我们在前几章中使用的任何现有文件。该文件夹包含运行PostgreSQL和Redis的基本Kubernetes清单。
- en: 'Open a Terminal window, navigate to the kubernetes/platform/development folder
    located in your polar-deployment repository, and run the following command to
    deploy PostgreSQL and Redis in your local cluster:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 打开一个终端窗口，导航到你的polar-deployment仓库中的kubernetes/platform/development文件夹，并运行以下命令在你的本地集群中部署PostgreSQL和Redis：
- en: '[PRE38]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'You can verify the results with the following command:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令来验证结果：
- en: '[PRE39]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Tip For your convenience, I prepared a script that performs all the previous
    operations with a single command. You can run it to create a local Kubernetes
    cluster with minikube, enable the Ingress NGINX add-on, and deploy the backing
    services used by Polar Bookshop. You’ll find the create-cluster.sh and destroy-cluster.sh
    files in the kubernetes/platform/development folder that you have just copied
    over to your polar-deployment repository. On macOS and Linux, you might need to
    make the scripts executable via the chmod +x create-cluster.sh command.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：为了方便起见，我准备了一个脚本，它可以执行所有之前的操作。你可以运行它来创建一个本地Kubernetes集群，启用Ingress NGINX插件，并部署Polar
    Bookshop使用的后端服务。你将在你刚刚复制到polar-deployment仓库中的kubernetes/platform/development文件夹中找到create-cluster.sh和destroy-cluster.sh文件。在macOS和Linux上，你可能需要通过chmod
    +x create-cluster.sh命令使脚本可执行。
- en: 'Let’s conclude this section by packaging Edge Service as a container image
    and loading the artifact to the local Kubernetes cluster. Open a Terminal window,
    navigate to the Edge Service root folder (edge-service), and run the following
    commands:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将Edge Service打包成容器镜像并将其加载到本地Kubernetes集群中来结束本节。打开一个终端窗口，导航到Edge Service根目录（edge-service），并运行以下命令：
- en: '[PRE40]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: In the next section, you’ll define an Ingress object and configure it to manage
    external access to the Polar Bookshop system running in a Kubernetes cluster.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将定义一个Ingress对象，并配置它来管理运行在Kubernetes集群中的Polar Bookshop系统的外部访问。
- en: 9.5.2 Working with Ingress objects
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.2 与Ingress对象一起工作
- en: Edge Service takes care of application routing, but it should not be concerned
    with the underlying infrastructure and network configuration. Using an Ingress
    resource, we can decouple the two responsibilities. Developers would maintain
    Edge Service, while the platform team would manage the ingress controller and
    the network configuration (perhaps relying on a service mesh like Linkerd or Istio).
    Figure 9.6 shows the deployment architecture of Polar Bookshop after introducing
    an Ingress.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: Edge Service负责应用路由，但它不应该关心底层的基础设施和网络配置。使用Ingress资源，我们可以解耦这两个责任。开发者将维护Edge Service，而平台团队将管理ingress控制器和网络配置（可能依赖于像Linkerd或Istio这样的服务网格）。图9.6显示了引入Ingress后的Polar
    Bookshop部署架构。
- en: '![09-06](../Images/09-06.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![09-06](../Images/09-06.png)'
- en: Figure 9.6 The deployment architecture of the Polar Bookshop system after introducing
    an Ingress to manage external access to the cluster
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6 引入Ingress管理集群外部访问后的Polar Bookshop系统部署架构
- en: 'Let’s define an Ingress to route all HTTP traffic coming from outside the cluster
    to Edge Service. It’s common to define Ingress routes and configurations based
    on the DNS name used to send the HTTP request. Since we are working locally, and
    assuming we don’t have a DNS name, we can call the external IP address provisioned
    for the Ingress to be accessible from outside the cluster. On Linux, you can use
    the IP address assigned to the minikube cluster. You can retrieve that value by
    running the following command:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个Ingress，将所有来自集群外部的HTTP流量路由到Edge Service。根据发送HTTP请求使用的DNS名称定义Ingress路由和配置是很常见的。由于我们是在本地工作，并且假设我们没有DNS名称，我们可以调用为Ingress分配的、可以从集群外部访问的外部IP地址。在Linux上，你可以使用分配给minikube集群的IP地址。你可以通过运行以下命令来检索该值：
- en: '[PRE41]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: On macOS and Windows, the ingress add-on doesn’t yet support using the minikube
    cluster’s IP address when running on Docker. Instead, we need to use the minikube
    tunnel --profile polar command to expose the cluster to the local environment,
    and then use the 127.0.0.1 IP address to call the cluster. This is similar to
    the kubectl port-forward command, but it applies to the whole cluster instead
    of a specific service.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在macOS和Windows上，当在Docker上运行时，路由器附加组件尚不支持使用minikube集群的IP地址。相反，我们需要使用minikube
    tunnel --profile polar命令将集群暴露到本地环境中，然后使用127.0.0.1 IP地址调用集群。这与kubectl port-forward命令类似，但它适用于整个集群而不是特定服务。
- en: After identifying the IP address to use, let’s define the Ingress object for
    Polar Bookshop. In the Edge Service project, create a new ingress.yml file in
    the k8s folder.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定要使用的IP地址后，让我们为Polar书店定义Ingress对象。在Edge Service项目中，在k8s文件夹中创建一个新的ingress.yml文件。
- en: Listing 9.20 Exposing Edge Service outside the cluster via an Ingress
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.20 通过Ingress将Edge服务暴露在集群外部
- en: '[PRE42]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: ❶ The API version for Ingress objects
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Ingress对象的API版本
- en: ❷ The type of object to create
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 要创建的对象类型
- en: ❸ The name of the Ingress
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ Ingress的名称
- en: ❹ Configures the ingress controller responsible for managing this object
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 配置负责管理此对象的路由器
- en: ❺ Ingress rules for HTTP traffic
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ HTTP流量的Ingress规则
- en: ❻ A default rule for all requests
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 为所有请求设置默认规则
- en: ❼ The name of the Service object where traffic should be forwarded
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 应将流量转发到该服务对象名称
- en: ❽ The port number for the Service where traffic should be forwarded
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 应将流量转发到该服务的端口号
- en: 'At this point we are ready to deploy Edge Service and the Ingress to the local
    Kubernetes cluster. Open a Terminal window, navigate to the Edge Service root
    folder (edge-service), and run the following command:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经准备好将Edge服务和Ingress部署到本地Kubernetes集群。打开一个终端窗口，导航到Edge Service根目录（edge-service），并运行以下命令：
- en: '[PRE43]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Let’s verify that the Ingress object has been created correctly with the following
    command:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下命令验证Ingress对象是否已正确创建：
- en: '[PRE44]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'It’s time to test that Edge Service is correctly available through the Ingress.
    If you’re on Linux, you don’t need any further preparation steps. If you’re on
    macOS or Windows, open a new Terminal window and run the following command to
    expose your minikube cluster to your localhost. The command will continue running
    for the tunnel to be accessible, so make sure you keep the Terminal window open.
    The first time you run this command, you might be asked to input your machine’s
    password to authorize the tunneling to the cluster:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候测试Edge服务是否可以通过Ingress正确访问了。如果您在Linux上，您不需要进行任何进一步的准备步骤。如果您在macOS或Windows上，请打开一个新的终端窗口并运行以下命令以将您的minikube集群暴露到本地主机。该命令将保持运行，以便隧道可访问，因此请确保您保持终端窗口开启。您第一次运行此命令时，可能会被要求输入您的机器密码以授权隧道到集群：
- en: '[PRE45]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Finally, open a new Terminal window and run the following command to test the
    application (on Linux, use the minikube’s IP address instead of 127.0.0.1):'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，打开一个新的终端窗口并运行以下命令以测试应用程序（在Linux上，请使用minikube的IP地址而不是127.0.0.1）：
- en: '[PRE46]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Since Catalog Service is not running, Edge Service will execute the fallback
    behavior we configured earlier and return a 200 OK response with an empty body.
    That’s what we expected, and it proves that the Ingress configuration works.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 由于目录服务没有运行，Edge Service将执行我们之前配置的回退行为，并返回一个带有空体的200 OK响应。这正是我们预期的，这也证明了Ingress配置是有效的。
- en: 'When you are done trying out the deployment, you can stop and delete the local
    Kubernetes cluster with the following commands:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 当您完成部署的尝试后，可以使用以下命令停止并删除本地Kubernetes集群：
- en: '[PRE47]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Tip For your convenience, you can also use the destroy-cluster.sh script (available
    in the kubernetes/platform/development folder of your polar-deployment repository)
    that you copied earlier from the book’s source code. On macOS and Linux, you might
    need to make the script executable via the chmod +x destroy-cluster.sh command.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士：为了方便起见，您还可以使用之前从书籍源代码中复制的destroy-cluster.sh脚本（位于您的polar-deployment存储库的kubernetes/platform/development文件夹中）。在macOS和Linux上，您可能需要通过chmod
    +x destroy-cluster.sh命令使脚本可执行。
- en: Good job! We’re now ready to make Edge Service even better by adding authentication
    and authorization. Before configuring security, though, we still need to complete
    the Polar Bookshop business logic for dispatching orders. In the next chapter,
    you’ll do that while learning event-driven architectures, Spring Cloud Function,
    and Spring Cloud Stream with RabbitMQ.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！我们现在已经准备好通过添加身份验证和授权来使边缘服务变得更好。然而，在配置安全设置之前，我们仍然需要完成极地书店的业务逻辑，以便分派订单。在下一章中，你将在学习事件驱动架构、Spring
    Cloud Function和Spring Cloud Stream与RabbitMQ的同时完成这项工作。
- en: Summary
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: An API gateway provides several benefits in a distributed architecture, including
    decoupling the internal services from the external API and offering a central,
    convenient place for handling cross-cutting concerns like security, monitoring,
    and resilience.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在分布式架构中，API网关提供了几个好处，包括解耦内部服务与外部API，并提供一个集中、方便的地方来处理诸如安全、监控和弹性等横切关注点。
- en: Spring Cloud Gateway is based on the Spring reactive stack. It provides an API
    gateway implementation, and it integrates with the other Spring projects to add
    cross-cutting concerns to the application, including Spring Security, Spring Cloud
    Circuit Breaker, and Spring Session.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spring Cloud Gateway基于Spring响应式堆栈。它提供了一个API网关实现，并与其他Spring项目集成，为应用程序添加横切关注点，包括Spring
    Security、Spring Cloud Circuit Breaker和Spring Session。
- en: Routes are the core of Spring Cloud Gateway. They are identified by a unique
    ID, a collection of predicates determining whether to follow the route, a URI
    for forwarding the request if the predicates allow, and a collection of filters
    that are applied before or after forwarding the request downstream.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路由是Spring Cloud Gateway的核心。它们通过一个唯一的ID、一组确定是否遵循路由的谓词、一个用于如果谓词允许则转发请求的URI以及一组在转发请求之前或之后应用的过滤器来识别。
- en: The Retry filter is for configuring retry attempts for specific routes.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重试过滤器用于配置特定路由的重试尝试。
- en: The RequestRateLimiter filter, integrated with Spring Data Redis Reactive, limits
    the number of requests that can be accepted within a specific time window.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求速率限制过滤器与Spring Data Redis Reactive集成，限制了在特定时间窗口内可以接受请求的数量。
- en: The CircuitBreaker filter, based on Spring Cloud Circuit Breaker and Resilience4J,
    defines circuit breakers, time limiters, and fallbacks to specific routes.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于Spring Cloud Circuit Breaker和Resilience4J的断路器过滤器定义了断路器、时间限制器和针对特定路由的回退。
- en: Cloud native applications should be stateless. Data services should be used
    for storing the state. For example, PostgreSQL is used for persistence storage
    and Redis for cache and session data.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云原生应用应该是无状态的。数据服务应用于存储状态。例如，PostgreSQL用于持久化存储，Redis用于缓存和会话数据。
- en: A Kubernetes Ingress resource allows you to manage external access to applications
    running inside the Kubernetes cluster.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes Ingress资源允许你管理运行在Kubernetes集群内部的应用程序的外部访问。
- en: The routing rules are enforced by an ingress controller, which is an application
    that also runs in the cluster.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路由规则由一个入口控制器强制执行，这是一个也在集群中运行的应用程序。
