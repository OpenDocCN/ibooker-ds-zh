- en: 7 Understanding Java performance
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 理解Java性能
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Why performance matters
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能为什么重要
- en: The G1 garbage collector
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: G1垃圾收集器
- en: Just-in-time (JIT) compilation
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即时编译（JIT）
- en: JFR—the JDK Flight Recorder
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JFR——JDK飞行记录器
- en: Poor performance kills applications—it’s bad for your customers and your application’s
    reputation. Unless you have a totally captive market, your customers will vote
    with their feet—they’ll already be out the door, heading to a competitor. To stop
    poor performance from harming your project, you need to understand performance
    analysis and how to make it work for you.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 糟糕的性能会杀死应用程序——这对你的客户和应用程序的声誉都是有害的。除非你有一个完全受控的市场，否则你的客户会用他们的脚投票——他们已经出门，走向竞争对手。为了阻止糟糕的性能损害你的项目，你需要了解性能分析和如何让它为你工作。
- en: 'Performance analysis and tuning is a huge subject, and too many treatments
    focus on the wrong things. So, we’re going to start by telling you the big secret
    of performance tuning. Here it is—the single biggest secret of performance tuning:
    *You have to measure. You can’t tune properly without measuring.*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 性能分析和调整是一个巨大的主题，太多的处理方法都集中在错误的事情上。因此，我们将从告诉你性能调整的巨大秘密开始。这里就是——性能调整的最大秘密：*你必须进行测量。不测量，你无法正确调整。*
- en: 'And here’s why: the human brain is pretty much always wrong when it comes to
    guessing what the slow parts of systems are. Everyone’s is. Yours, mine, James
    Gosling’s—we’re all subject to our subconscious biases and tend to see patterns
    that may not be there. In fact, the answer to the question, “Which part of my
    Java code needs optimizing?” is quite often, “None of it.”'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 原因如下：当涉及到猜测系统中的慢速部分时，人脑几乎总是错误的。每个人的都是。你的，我的，詹姆斯·高斯林的——我们都受到我们无意识的偏见的影响，并倾向于看到可能并不存在的模式。事实上，对于“我的Java代码中哪部分需要优化？”这个问题，答案通常是“都不是。”
- en: Consider a typical (if rather conservative) ecommerce web application, providing
    services to a pool of registered customers. It has an SQL database, web servers
    fronting Java services, and a fairly standard network configuration connecting
    all of it. Very often, the non-Java parts of the system (database, filesystem,
    network) are the real bottleneck, but without measurement, the Java developer
    would never know that. Instead of finding and fixing the real problem, the developer
    may waste time on micro-optimization of code aspects that aren’t really contributing
    to the issue.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个典型的（如果相当保守的）电子商务网络应用程序，为注册客户提供服务。它有一个SQL数据库，Java服务的前端是Web服务器，以及连接所有这些的相当标准的网络配置。非常常见的是，系统的非Java部分（数据库、文件系统、网络）是真正的瓶颈，但没有测量，Java开发者永远不会知道这一点。开发者可能不会找到并修复真正的问题，而是浪费时间在微优化那些实际上并没有真正贡献到问题的代码方面。
- en: 'The kinds of fundamental questions that you want to be able to answer are these:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你希望能够回答的基本问题类型是这些：
- en: If you have a sales drive and suddenly have 10 times as many customers, will
    the system have enough memory to cope?
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有一个销售驱动，突然有10倍多的客户，系统是否有足够的内存来应对？
- en: What is the average response time your customers see from your application?
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的客户从你的应用程序中看到的平均响应时间是多少？
- en: How does that compare to your competitors?
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这与你的竞争对手相比如何？
- en: Notice that all of these example questions are about aspects of your system
    that are directly relevant to your customers—the users of your system. There is
    nothing here about topics such as
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，所有这些示例问题都是关于你的系统与你的客户——系统用户直接相关方面的。这里没有关于诸如
- en: Are lambdas and streams faster than `for` loops?
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda和流比`for`循环更快吗？
- en: Are regular methods (virtual methods) faster than interface methods?
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正常方法（虚方法）比接口方法更快吗？
- en: What’s the fastest implementation of `hashcode()`?
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hashcode()`函数的最快实现是什么？'
- en: The inexperienced performance engineer will often make the mistake of assuming
    that user-visible performance is strongly dependent upon, or closely correlated
    with, the microperformance aspects that the second set of questions addresses.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 经验不足的性能工程师经常会犯的错误是假设用户可见的性能强烈依赖于，或者与第二组问题解决的微观性能方面密切相关。
- en: This assumption—essentially a reductionist viewpoint—is actually not true in
    practice. Instead, the complexity of modern software systems causes overall performance
    to be an *emergent* property of the system and all of its layers. Specific microeffects
    are almost impossible to isolate, and microbenchmarking is of very limited utility
    to most application programmers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个假设——本质上是一种还原论观点——在实践中实际上并不成立。相反，现代软件系统的复杂性导致整体性能成为系统及其所有层的**涌现**属性。特定的微观效应几乎无法隔离，并且对于大多数应用程序程序员来说，微观基准测试的效用非常有限。
- en: Instead, to do performance tuning, you have to get out of the realm of guessing
    about what’s making the system slow—and *slow* means “impacting the experience
    of customers.” You have to start knowing, and the only way to know for sure is
    to measure.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，为了进行性能调优，你必须跳出猜测系统缓慢原因的领域——这里的“缓慢”意味着“影响客户的体验”。你必须开始了解，而唯一确定了解的方法就是测量。
- en: 'You also need to understand what else performance tuning *isn’t*. It isn’t
    the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要了解性能调优**不是**什么。它不是以下内容：
- en: A collection of tips and tricks
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一系列技巧和窍门
- en: Secret sauce
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 秘密配方
- en: Fairy dust that you sprinkle on at the end of a project
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在项目结束时撒上的“魔法粉”
- en: Be especially careful of the “tips and tricks” approaches. The truth is that
    the JVM is a very sophisticated and highly tuned environment, and without proper
    context, most of these tips are useless (and may actually be harmful). They also
    go out of date very quickly as the JVM gets smarter and smarter at optimizing
    code.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 特别注意“技巧和窍门”的方法。事实是，JVM是一个非常复杂且高度优化的环境，如果没有适当的环境，大多数这些技巧都是无用的（甚至可能是有害的）。随着JVM在优化代码方面变得越来越聪明，它们也很快就会过时。
- en: Performance analysis is really a type of experimental science. You can think
    of your code as a type of science experiment that has inputs and produces “outputs”—performance
    metrics that indicate how efficiently the system is performing the work asked
    of it. The job of the performance engineer is to study these outputs and look
    for patterns. This makes performance tuning a branch of applied statistics, rather
    than a collection of old wives’ tales and applied folklore.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 性能分析实际上是一种实验科学。你可以把你的代码看作是一种科学实验，它有输入并产生“输出”——性能指标，这些指标表明系统执行所要求工作的效率。性能工程师的职责是研究这些输出并寻找模式。这使得性能调优成为应用统计学的一个分支，而不是一系列老妇人的传说和应用的民间传说。
- en: 'This chapter is here to help you get started. It’s an introduction to the practice
    of Java performance tuning. But this is a big subject, and we have space to give
    you only a primer on some essential theory and some signposts. We’ll try to answer
    the following most fundamental questions:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在帮助你入门。这是Java性能调优实践的一个介绍。但这是一个很大的主题，我们只能给你一些基本理论和一些路标。我们将尝试回答以下最基本的问题：
- en: Why does performance matter?
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能为什么很重要？
- en: Why is performance analysis hard?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么性能分析很难？
- en: What aspects of the JVM make it potentially complex to tune?
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JVM 的哪些方面使其调优变得可能复杂？
- en: How should performance tuning be thought about and approached?
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该如何思考和处理性能调优？
- en: What are the most common underlying causes of slowness?
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最常见的导致系统缓慢的根本原因是什么？
- en: 'We’ll also give you an introduction to the following two subsystems in the
    JVM that are the most important when it comes to performance-related matters:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将向你介绍JVM中以下两个子系统，当涉及到性能相关问题时，它们是最重要的：
- en: The garbage collection subsystem
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垃圾回收子系统
- en: The JIT compiler
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JIT 编译器
- en: This should be enough to get you started and help you apply this (admittedly
    somewhat theory-heavy) knowledge to the real problems you face in your code. Let’s
    get going by taking a quick look at some fundamental vocabulary that will enable
    you to express and frame your performance problems and goals.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该足以让你开始，并帮助你将这种（不可否认地有些理论性）知识应用到你在代码中面临的实际问题中。让我们快速浏览一些基本词汇，这将使你能够表达和界定你的性能问题和目标。
- en: '7.1 Performance terminology: Some basic definitions'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 性能术语：一些基本定义
- en: 'To get the most out of our discussions in this chapter, we need to formalize
    some notions of performance that you may be aware of. We’ll begin by defining
    some of the following important terms in the performance engineer’s lexicon:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用本章的讨论，我们需要将一些你可能已经了解的性能概念进行形式化。我们将从定义性能工程师词汇表中的以下一些重要术语开始：
- en: Latency
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟
- en: Throughput
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吞吐量
- en: Utilization
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用率
- en: Efficiency
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 效率
- en: Capacity
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容量
- en: Scalability
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可伸缩性
- en: Degradation
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 退化
- en: A number of these terms are discussed by Doug Lea in the context of multithreaded
    code, but we’re considering a much wider context here. When we speak of performance,
    we could mean anything from a single multithreaded process all the way up to an
    entire cluster of services hosted in the cloud.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Doug Lea在多线程代码的背景下讨论了这些术语中的许多，但我们在这里考虑的是一个更广泛的背景。当我们谈论性能时，我们可能意味着从单个多线程进程到托管在云中的整个服务集群的任何事情。
- en: 7.1.1 Latency
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.1 延迟
- en: '*Latency* is the end-to-end time taken to process a single work unit at a given
    workload. Quite often, latency is quoted just for “normal” workloads, but an often-useful
    performance measure is the graph showing latency as a function of increasing workload.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*延迟*是在给定工作负载下处理单个工作单元所需的总时间。通常，延迟只是针对“正常”工作负载进行报价，但一个经常有用的性能指标是显示延迟作为增加工作负载函数的图表。'
- en: The graph in figure 7.1 shows a sudden, nonlinear degradation of a performance
    metric (e.g., latency) as the workload increases. This is usually called a performance
    elbow (or “hockey stick”).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1显示了随着工作负载的增加，性能指标（例如，延迟）的突然、非线性下降。这通常被称为性能拐点（或“曲棍球棒”）。
- en: '![](../Images/CH07_F01_Evans2.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH07_F01_Evans2.png)'
- en: Figure 7.1 A performance elbow
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 性能拐点
- en: 7.1.2 Throughput
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.2 吞吐量
- en: '*Throughput* is the number of units of work that a system can perform in some
    time period with given resources. One commonly quoted number is transactions per
    second on some reference platform (e.g., a specific brand of server with specified
    hardware, OS, and software stack).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '*吞吐量*是指系统在给定资源下在某个时间段内可以执行的工作单元数量。一个常见的引用数字是在某些参考平台（例如，具有指定硬件、操作系统和软件堆栈的特定品牌服务器）上的每秒事务数。'
- en: 7.1.3 Utilization
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.3 利用率
- en: '*Utilization* represents the percentage of available resources that are being
    used to handle work units, instead of housekeeping tasks (or just being idle).
    People will commonly quote a server as being, for example, 10% utilized. This
    refers to the percentage of CPU processing work units during normal processing
    time. Note that the difference can be very large between the utilization levels
    of different resources, such as CPU and memory.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*利用率*表示可用于处理工作单元的资源百分比，而不是用于维护任务（或只是闲置）。人们通常会引用服务器的利用率，例如10%。这指的是在正常处理时间内CPU处理工作单元的百分比。请注意，不同资源（如CPU和内存）的利用率水平之间的差异可能非常大。'
- en: 7.1.4 Efficiency
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.4 效率
- en: The *efficiency* of a system is equal to the throughput divided by the resources
    used. A system that requires more resources to produce the same throughput is
    less efficient.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的*效率*等于吞吐量除以使用的资源。需要更多资源来产生相同吞吐量的系统效率较低。
- en: For example, consider comparing two clustering solutions. If solution A requires
    twice as many servers as solution B for the same throughput, it’s half as efficient.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑比较两种聚类解决方案。如果方案A需要比方案B多两倍的服务器才能达到相同的吞吐量，那么它的效率只有一半。
- en: Remember that resources can also be considered in cost terms—if solution A costs
    twice as much (or requires twice as many staff to run the production environment)
    as solution B, then it’s only half as efficient.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，资源也可以从成本的角度来考虑——如果方案A的成本是方案B的两倍（或运行生产环境需要两倍的员工），那么它的效率只有一半。
- en: 7.1.5 Capacity
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.5 容量
- en: '*Capacity* is the number of work units (such as transactions) that can be in
    flight through the system at any time. That is, it’s the amount of simultaneous
    processing available at a specified latency or throughput.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*容量*是指在任何时候可以通过系统传输的工作单元（如事务）的数量。也就是说，这是在指定延迟或吞吐量下可用的并发处理量。'
- en: 7.1.6 Scalability
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.6 可伸缩性
- en: As resources are added to a system, the throughput (or latency) will change.
    This change in throughput or latency is the *scalability* of the system.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当向系统添加资源时，吞吐量（或延迟）将发生变化。这种吞吐量或延迟的变化是系统的*可伸缩性*。
- en: If solution A doubles its throughput when the available servers in a pool are
    doubled, it’s scaling in a perfectly linear fashion. Perfect linear scaling is
    very, very difficult to achieve under most circumstances—remember Amdahl’s law.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果方案A在服务器池中可用的服务器数量加倍时，其吞吐量也加倍，那么它以完美的线性方式扩展。在大多数情况下，完美线性扩展是非常、非常困难的——记住Amdahl定律。
- en: You should also note that the scalability of a system depends on a number of
    factors, and it isn’t constant. A system can scale close to linearly up until
    some point and then begin to degrade badly. That’s a different kind of performance
    elbow.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你还应该注意，一个系统的可扩展性取决于许多因素，并且它不是恒定的。一个系统可以接近线性地扩展到某个点，然后开始严重退化。这是一种不同的性能拐点。
- en: 7.1.7 Degradation
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.7 退化
- en: If you add more work units, or clients for network systems, without adding more
    resources, you’ll typically see a change in the observed latency or throughput.
    This change is the *degradation* of the system under additional load.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你添加更多的工作单元，或者网络系统的客户端，而没有添加更多资源，你通常会看到观察到的延迟或吞吐量的变化。这种变化是在额外负载下系统退化的表现。
- en: The degradation will, under normal circumstances, be negative. That is, adding
    work units to a system will cause a negative effect on performance (such as causing
    the latency of processing to increase). But some circumstances exist under which
    degradation could be positive. For example, if the additional load causes some
    part of the system to cross a threshold and switch to a high-performance mode,
    this can cause the system to work more efficiently and reduce processing times,
    even though there is actually more work to be done. The JVM is a very dynamic
    runtime system, and several parts of it could contribute to this sort of effect.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常情况下，退化将是负面的。也就是说，向系统中添加工作单元将导致性能下降（例如，导致处理延迟增加）。但在某些情况下，退化可能是正面的。例如，如果额外的负载导致系统的一部分超过阈值并切换到高性能模式，这可能会使系统工作得更有效率，并减少处理时间，尽管实际上还有更多的工作要做。JVM是一个非常动态的运行时系统，其几个部分可能会对这种效果做出贡献。
- en: The preceding terms are the most frequently used indicators of performance.
    Others are occasionally important, but these are the basic system statistics that
    will normally be used to guide performance tuning. In the next section, we’ll
    lay out an approach that is grounded in close attention to these numbers and that
    is as quantitative as possible.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 前述术语是性能最常用的指标。其他指标偶尔也很重要，但这些是通常用于指导性能调整的基本系统统计指标。在下一节中，我们将阐述一种基于对这些数字的密切关注的做法，并尽可能地量化。
- en: 7.2 A pragmatic approach to performance analysis
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 一种实用的性能分析方法
- en: Many developers, when they approach the task of performance analysis, don’t
    start with a clear picture of what they want to achieve by doing the analysis.
    A vague sense that the code “ought to run faster” is often all that developers
    or managers have when the work begins.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发者在接近性能分析任务时，并没有一个清晰的关于通过分析想要实现什么目标的认识。当工作开始时，开发者或管理者通常只有一种模糊的感觉，即代码“应该运行得更快”。
- en: 'But this is completely backward. To do really effective performance tuning,
    you should have think about some key areas before beginning any kind of technical
    work. You should know the following things:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 但这是完全相反的。为了真正有效地进行性能调整，你应该在开始任何技术工作之前考虑一些关键领域。你应该知道以下事情：
- en: What observable aspects of your code you’re measuring
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你正在测量你代码的哪些可观察方面
- en: How to measure those observables
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何衡量那些可观察量
- en: What the goals are for the observables
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可观察量的目标是什么
- en: How you’ll recognize when you’re done with performance tuning
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将如何知道性能调整已经完成
- en: What the maximum acceptable cost is (in terms of developer time invested and
    additional complexity in the code) for the performance tuning
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能调整的最大可接受成本（以开发者投入的时间和代码的额外复杂性来衡量）
- en: What not to sacrifice as you optimize
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化时不应牺牲什么
- en: Most important, as we’ll say many times in this chapter, you *have* to measure.
    Without measurement of at least one observable, you aren’t doing performance analysis.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，正如我们将在本章中多次说到的，你必须进行测量。如果没有至少一个可观察量的测量，你就不在进行性能分析。
- en: It’s also very common when you start measuring your code to discover that time
    isn’t being spent where you think it is. A missing database index or contended
    filesystem locks can be the root of a lot of performance problems. When thinking
    about optimizing your code, you should always remember that it’s possible that
    the code isn’t the issue. To quantify where the problem is, the first thing you
    need to know is what you’re measuring.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始测量你的代码时，发现时间并没有花在你认为的地方，这也是非常常见的。缺少数据库索引或争用的文件系统锁可能是许多性能问题的根源。在考虑优化你的代码时，你应该始终记住，代码可能不是问题所在。为了量化问题的位置，你需要知道的第一件事是你正在测量什么。
- en: 7.2.1 Know what you’re measuring
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.1 了解你在测量什么
- en: In performance tuning, you always have to be measuring something. If you aren’t
    measuring an observable, you’re not doing performance tuning. Sitting and staring
    at your code, hoping that a faster way to solve the problem will strike you, isn’t
    performance analysis.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在性能调整中，你总是需要测量某些东西。如果你没有测量可观察的量，你就没有进行性能调整。坐着盯着你的代码，希望更快解决问题的方法会突然出现在你脑海中，这不是性能分析。
- en: Tip To be a good performance engineer, you should understand terms such as *mean,
    median, mode, variance, percentile, standard deviation, sample size,* and *normal
    distribution*. If you aren’t familiar with these concepts, you should start with
    a quick web search and do further reading if needed. Chapter 5 of Leonard Apeltsin’s
    *Data Science Bookcamp* (Manning, 2021\. [http://mng.bz/e7Oq](http://mng.bz/e7Oq))
    is a good place to start.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：要成为一名优秀的性能工程师，你应该了解诸如 *平均数、中位数、众数、方差、百分位数、标准差、样本大小* 和 *正态分布* 等术语。如果你不熟悉这些概念，你应该从快速网络搜索开始，并在需要时进行进一步阅读。Leonard
    Apeltsin 的 *数据科学 Bootcamp*（Manning，2021）的第 5 章是一个很好的起点。[http://mng.bz/e7Oq](http://mng.bz/e7Oq)。
- en: 'When undertaking performance analysis, it’s important to know exactly which
    of the observables we described in the last section are important to you. You
    should always tie your measurements, objectives, and conclusions to one or more
    of the basic observables we introduced. Some typical observables that are good
    targets for performance tuning follow:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行性能分析时，了解我们上节中描述的哪些可观察量对你来说很重要。你应该始终将你的测量、目标和结论与我们所介绍的一个或多个基本可观察量联系起来。以下是一些典型的可观察量，它们是性能调整的良好目标：
- en: Average time taken for the `handleRequest()` method to run (after warmup)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`handleRequest()` 方法运行的平均时间（在预热之后）'
- en: The 90th percentile of the system’s end-to-end latency with 10 concurrent clients
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 10 个并发客户端的情况下，系统端到端延迟的 90 分位数
- en: The degradation of the response time as you increase from 1 to 1,000 concurrent
    users
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当从 1 个增加到 1,000 个并发用户时，响应时间的下降
- en: All of these represent quantities that the engineer might want to measure and
    potentially tune. To obtain accurate and useful numbers, a basic knowledge of
    statistics is essential.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都代表了工程师可能想要测量和可能调整的量。为了获得准确和有用的数字，基本统计学知识是必不可少的。
- en: Knowing what you’re measuring and having confidence that your numbers are accurate
    is the first step. But vague or open-ended objectives don’t often produce good
    results, and performance tuning is no exception. Instead, your performance goals
    should be what are sometimes referred to as SMART objectives (for *specific, measurable,
    agreed, relevant,* and *time-boxed*).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 知道你在测量什么，并对你所得到的数字的准确性有信心是第一步。但模糊或不明确的目标往往不会产生好的结果，性能调整也不例外。相反，你的性能目标应该是所谓的
    SMART 目标（即 *具体、可衡量、达成共识、相关* 和 *时间限制*）。
- en: 7.2.2 Know how to take measurements
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.2 了解如何进行测量
- en: 'We have really only the following two ways to determine precisely how long
    a method or other piece of Java code takes to run:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实际上只有以下两种方法来确定一个方法或其他 Java 代码运行的确切时间：
- en: Measure it directly, by inserting measurement code into the source class.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接测量，通过在源类中插入测量代码来实现。
- en: Transform the class that is to be measured at class loading time.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在类加载时转换要测量的类。
- en: These two approaches are referred to as *manual* and *automatic* instrumentation,
    respectively. All commonly used performance measuring techniques will rely on
    one (or both) of these techniques.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法分别被称为 *手动* 和 *自动* 仪器化。所有常用的性能测量技术都将依赖于其中一种（或两种）技术。
- en: Note There is also the JVM Tool Interface (JVMTI), which can be used to create
    very sophisticated performance tools, but it has drawbacks, notably that it requires
    the use of native code, which impacts both the complexity and safety of tools
    written using it.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：还有 JVM 工具接口（JVMTI），它可以用来创建非常复杂的性能工具，但它也有一些缺点，尤其是它需要使用原生代码，这会影响使用它编写的工具的复杂性和安全性。
- en: Direct measurement
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 直接测量
- en: 'Direct measurement is the easiest technique to understand, but it’s also intrusive.
    In its simplest form, it looks like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 直接测量是最容易理解的技术，但它也是侵入性的。在其最简单的形式中，它看起来像这样：
- en: '[PRE0]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This will produce an output line that should give a millisecond-accurate view
    of how long `methodToBeMeasured()` took to run. The inconvenient part is that
    code like this has to be added throughout the codebase, and as the number of measurements
    grows, it becomes difficult to avoid being swamped with data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一条输出行，应该可以给出`methodToBeMeasured()`运行所需时间的毫秒级准确视图。不方便的是，像这样的代码必须添加到代码库的各个部分，随着测量数量的增加，避免被数据淹没变得越来越困难。
- en: 'There are other problems too—for example, what happens if `methodToBeMeasured()`
    takes under a millisecond to run? As we’ll see later in this chapter, there are
    also cold-start effects to worry about: JIT compilation means that later runs
    of the method may well be quicker than earlier runs.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 还存在其他问题——例如，如果`methodToBeMeasured()`的运行时间少于毫秒，会发生什么？正如我们将在本章后面看到的那样，还有冷启动效应需要担心：JIT编译意味着方法的后续运行可能比早期运行更快。
- en: 'There are also more subtle problems: the call to `currentTimeMillis()` requires
    a call to a native method and a system call to read the system clock. This is
    not only time-consuming but can also flush code from the execution pipelines,
    leading to additional performance degradation that would not occur if the measurement
    code was not there.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 还存在一些更微妙的问题：调用`currentTimeMillis()`需要调用本地方法和对系统时钟的系统调用。这不仅耗时，还可能从执行管道中清除代码，导致额外的性能下降，而这种下降在没有测量代码的情况下是不会发生的。
- en: Automatic instrumentation via class loading
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 通过类加载进行自动插装
- en: In chapters 1 and 4, we discussed how classes are assembled into an executing
    program. One of the key steps that is often overlooked is the transformation of
    bytecode as it’s loaded. This is incredibly powerful, and it lies at the heart
    of many modern techniques in the Java platform.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1章和第4章中，我们讨论了类是如何组装成执行程序的。其中经常被忽视的关键步骤之一是字节码在加载时的转换。这非常强大，并且它是Java平台许多现代技术的核心。
- en: One example of it is the automatic instrumentation of methods. In this approach,
    `methodToBeMeasured()` is loaded by a special class loader that adds in bytecode
    at the start and end of the method to record the times at which the method was
    entered and exited. These timings are typically written to a shared data structure,
    which is accessed by other threads. These threads act on the data, typically either
    writing output to log files or contacting a network-based server that processes
    the raw data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个例子是方法的自动插装。在这种方法中，`methodToBeMeasured()`由一个特殊的类加载器加载，该类加载器在方法的开头和结尾添加字节码，以记录方法进入和退出的时间。这些时间通常写入共享数据结构，由其他线程访问。这些线程对数据进行操作，通常是将输出写入日志文件或联系基于网络的服务器，该服务器处理原始数据。
- en: This technique lies at the heart of many professional-grade Java performance-monitoring
    tools (such as New Relic), but actively maintained open source tools that fill
    the same niche have been scarce. This situation may now be changing with the rise
    of the OpenTelemetry OSS libraries and standards and their Java auto-instrumentation
    subproject.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术是许多专业级Java性能监控工具（如New Relic）的核心，但填补相同空白且积极维护的开源工具却很少。随着OpenTelemetry OSS库和标准的兴起以及它们的Java自动插装子项目，这种状况可能正在改变。
- en: Note As we’ll discuss later, Java methods start off interpreted, then switch
    to compiled mode. For true performance numbers, you have to discard the timings
    generated when in interpreted mode, because they can badly skew the results. Later
    we’ll discuss in more detail how you can know when a method has switched to compiled
    mode.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：正如我们稍后将要讨论的，Java方法最初是解释执行的，然后切换到编译模式。为了获得真正的性能数字，您必须丢弃在解释模式下生成的计时数据，因为这些数据可能会严重扭曲结果。稍后我们将更详细地讨论您如何知道方法何时切换到编译模式。
- en: Using one or both of these techniques will allow you to produce numbers for
    how quickly a given method executes. The next question is, what do you want the
    numbers to look like when you’ve finished tuning?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这两种技术之一，您可以为给定方法的执行速度生成数字。接下来的问题是，在调整完成后，您希望这些数字看起来是什么样子？
- en: 7.2.3 Know what your performance goals are
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.3 了解您的性能目标
- en: 'Nothing focuses the mind like a clear target, so just as important as knowing
    what to measure is knowing and communicating the end goal of tuning. In most cases,
    this should be a simple and precisely stated goal, such as the following:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 没有什么比一个明确的目标更能集中注意力，因此了解要测量什么和了解并传达调整的最终目标同样重要。在大多数情况下，这应该是一个简单且精确陈述的目标，例如以下内容：
- en: Reduce the 90th percentile end-to-end latency by 20% at 10 concurrent users
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在10个并发用户的情况下，将90%分位数的端到端延迟降低20%
- en: Reduce the mean latency of `handleRequest()` by 40%
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`handleRequest()`的平均延迟降低40%
- en: In more complex cases, the goal may be to reach several related performance
    targets at once. You should be aware that the more separate observables that you
    measure and try to tune, the more complex the performance exercise can become.
    Optimizing for one performance goal can negatively impact on another.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在更复杂的情况下，目标可能是同时达到几个相关的性能目标。你应该意识到，你测量的和尝试调整的独立可观察量越多，性能练习可能变得越复杂。优化一个性能目标可能会对另一个目标产生负面影响。
- en: Sometimes it’s necessary to do some initial analysis, such as determining what
    the important methods are, before setting goals, such as making them run faster.
    This is fine, but after the initial exploration, it’s almost always better to
    stop and state your goals before trying to achieve them. Too often developers
    will plow on with the analysis without stopping to elucidate their goals.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，在设定目标之前，比如让它们运行得更快，进行一些初步分析是必要的，比如确定哪些是重要的方法。这是可以的，但在初步探索之后，几乎总是最好在尝试实现它们之前停下来并明确你的目标。开发者经常会在不停止阐明他们的目标的情况下继续分析。
- en: 7.2.4 Know when to stop
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.4 知道何时停止
- en: In theory, knowing when it’s time to stop optimizing is easy—you’re done when
    you’ve achieved your goals. In practice, however, it’s easy to get sucked into
    performance tuning. If things go well, the temptation to keep pushing and do even
    better can be very strong. Alternatively, if you’re struggling to reach your goal,
    it’s hard to keep from trying out different strategies in an attempt to hit the
    target.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，知道何时停止优化很容易——当你达到你的目标时，你就完成了。然而，在实践中，很容易陷入性能调优的陷阱。如果一切顺利，继续努力做得更好的诱惑可能非常强烈。或者，如果你在努力达到目标时遇到困难，很难不尝试不同的策略来达到目标。
- en: Knowing when to stop involves having an awareness of your goals but also a sense
    of what they’re worth. Getting 90% of the way to a performance goal can often
    be enough, and the engineer’s time may well be spent better elsewhere.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 知道何时停止需要意识到你的目标，同时也需要有一种感觉，知道它们的价值。达到性能目标的90%通常已经足够，工程师的时间可能更好地花在其他地方。
- en: Another important consideration is how much effort is being spent on rarely
    used code paths. Optimizing code that accounts for 1% or less of the program’s
    runtime is almost always a waste of time, yet a surprising number of developers
    will engage in this behavior.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的考虑因素是花费在很少使用的代码路径上的工作量。几乎总是浪费时间来优化只占程序运行时间1%或更少的代码，但令人惊讶的是，许多开发者会参与这种行为。
- en: 'Here’s a set of very simple guidelines for knowing what to optimize. You may
    need to adapt these for your particular circumstances, but they work well for
    a wide range of situations:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一套非常简单的指导原则，用于了解什么需要优化。你可能需要根据你的具体情况调整这些原则，但它们在许多情况下都适用：
- en: Optimize what matters, not what is easy to optimize.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化重要的，而不是容易优化的。
- en: Hit the most important (usually the most often called) methods first.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先击中最重要的（通常是调用最频繁的）方法。
- en: Take low-hanging fruit as you come across it, but be aware of how often the
    code that it represents is called.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遇到低垂的果实就摘取，但要注意代表这些代码的调用频率。
- en: At the end, do another round of measurement. If you haven’t hit your performance
    goals, take stock. Look and see how close you are to hitting those goals, and
    whether the gains you’ve made have had the desired impact on overall performance.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，再进行一轮测量。如果你没有达到性能目标，就要进行盘点。看看你离达到这些目标有多近，以及你所取得的进步是否对整体性能产生了预期的积极影响。
- en: 7.2.5 Know the cost of achieving higher performance
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.5 了解实现更高性能的成本
- en: 'All performance tweaks have a price tag attached, such as the following:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 所有性能调整都有一个价格标签，如下所示：
- en: There’s the time taken to do the analysis and develop an improvement (and it’s
    worth remembering that the cost of developer time is almost always the greatest
    expense on any software project).
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这包括进行分析和开发改进所需的时间（而且值得记住，开发者时间的成本几乎总是任何软件项目中最高的开销）。
- en: There’s the additional technical complexity that the fix will probably have
    introduced. (There are performance improvements that also simplify the code, but
    they’re not the majority of cases.)
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修复可能引入的额外技术复杂性。（也有性能改进可以简化代码，但它们并不是大多数情况。）
- en: Additional threads may have been introduced to perform auxiliary tasks to allow
    the main processing threads to go faster, and these threads may have unforeseen
    effects on the overall system at higher loads.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能引入了额外的线程来执行辅助任务，以便允许主处理线程更快地运行，这些线程在更高负载下可能对整个系统产生不可预见的影响。
- en: Whatever the price tag, pay attention to it, and try to identify it before you
    finish a round of optimization.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 无论代价如何，都要注意它，并在完成一轮优化之前尝试确定它。
- en: It often helps to have some idea of what the maximum acceptable cost for higher
    performance is. This can be set as a time constraint on the developers doing the
    tuning, or as numbers of additional classes or lines of code. For example, a developer
    could decide that no more than a week should be spent optimizing, or that the
    optimized classes should not grow by more than 100% (double their original size).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 有时了解提高性能所能接受的最大成本是有帮助的。这可以设定为调整开发人员的时间限制，或者作为额外类或代码行的数量。例如，开发人员可以决定优化不应超过一周的时间，或者优化的类不应增长超过100%（加倍其原始大小）。
- en: 7.2.6 Know the dangers of premature optimization
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.6 了解过早优化的危险
- en: 'One of the most famous quotes on optimization is from Donald Knuth (“Structured
    Programming with go to Statements,” *Computing Surveys*, 6, no. 4 [December 1974].):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 关于优化的最著名引语之一来自Donald Knuth（《使用goto语句的结构化编程》，《计算机评论》，6，第4期 [1974年12月]）：
- en: Programmers waste enormous amounts of time thinking about, or worrying about,
    the speed of noncritical parts of their programs, and these attempts at efficiency
    actually have a strong negative impact ... premature optimization is the root
    of all evil.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 程序员在思考或担心程序非关键部分的运行速度上浪费了大量的时间，而这些试图提高效率的努力实际上有强烈的负面影响...过早优化是万恶之源。
- en: 'This statement has been widely debated in the community, and in many cases,
    only the second part is remembered. This is unfortunate for several reasons:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这句话在社区中引起了广泛的讨论，在许多情况下，只有第二部分被记住。这有几个不幸的原因：
- en: In the first part of the quote, Knuth is reminding us implicitly of the need
    to measure, without which we can’t determine the critical parts of programs.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在引文的第一部分，Knuth在隐晦地提醒我们需要测量，没有测量我们就无法确定程序的临界部分。
- en: We need to remember yet again that it might not be the code that’s causing the
    latency—it could be something else in the environment.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还需要再次记住，延迟可能不是由代码引起的——可能是环境中的其他东西。
- en: In the full quote, it’s easy to see that Knuth is talking about optimization
    that forms a conscious, concerted effort.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在完整的引文中，很容易看出Knuth在谈论形成有意识、一致努力的优化。
- en: The shorter form of the quote leads to the quote being used as a fairly pat
    excuse for poor design or execution choices.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简短的引文导致这句话被用作相当陈词滥调的借口，用于糟糕的设计或执行选择。
- en: 'Some optimizations, in particular, the following, are really a part of good
    style:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一些优化，特别是以下这些，实际上是良好风格的一部分：
- en: Don’t allocate an object you don’t need to.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要分配你不需要的对象。
- en: Remove a debug log message if you’ll never need it.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你永远不会需要它，就删除调试日志消息。
- en: 'In the following snippet, we’ve added a check to see if the logging object
    will do anything with a debug log message. This kind of check is called a *loggability
    guard*. If the logging subsystem isn’t set up for debug logs, this code will never
    construct the log message, saving the cost of the call to `currentTimeMillis()`
    and the construction of the `StringBuilder` object used for the log message:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码片段中，我们添加了一个检查，看看日志对象是否会处理调试日志消息。这种检查被称为*可记录性保护*。如果日志子系统没有为调试日志设置，则此代码永远不会构造日志消息，从而节省了调用`currentTimeMillis()`和用于日志消息的`StringBuilder`对象构造的成本：
- en: '[PRE1]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: But if the debug log message is truly useless, we can save a couple of processor
    cycles (the cost of the loggability guard) by removing the code altogether. This
    cost is trivial and will get lost in the noise of the rest of the performance
    profile, but if it genuinely isn’t needed, take it out.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果调试日志消息确实毫无用处，我们可以通过完全删除代码来节省几个处理器周期（可记录性保护的成本）。这种成本微不足道，将在性能配置文件的其他部分的噪声中丢失，但如果它确实不是必需的，就将其删除。
- en: One aspect of performance tuning is to write good, well-performing code in the
    first place. Gaining a better awareness of the platform and how it behaves under
    the hood (e.g., understanding the implicit object allocations that come from the
    concatenation of two strings) and thinking about aspects of performance as you
    go lead to better code.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 性能调优的一个方面是首先编写好、性能良好的代码。更好地了解平台及其底层行为（例如，理解来自两个字符串连接的隐式对象分配）以及在编写代码时考虑性能方面，都会导致更好的代码。
- en: We now have some basic vocabulary we can use to frame our performance problems
    and goals and an outline approach for how to tackle problems. But we still haven’t
    explained why this is a software engineer’s problem and where this need came from.
    To understand this, we need to delve briefly into the world of hardware.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一些基本的词汇可以用来构建我们的性能问题和目标，以及如何解决问题的概述方法。但我们还没有解释为什么这是软件工程师的问题，以及这种需求是从何而来的。为了理解这一点，我们需要简要地深入到硬件的世界。
- en: 7.3 What went wrong? Why do we have to care?
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 发生了什么问题？为什么我们必须关心？
- en: For a few halcyon years up until the mid-2000s, it seemed as though performance
    was not really a concern. Clock speeds were going up and up, and it seemed that
    all software engineers had to do was to wait a few months, and the improved CPU
    speeds would give an uptick to even badly written code.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在2000年中期之前的几年里，性能似乎并不是一个真正的问题。时钟速度在不断提高，似乎所有软件工程师需要做的只是等待几个月，改进的CPU速度就会给即使是写得不好的代码带来提升。
- en: How, then, did things go so wrong? Why are clock speeds not improving that much
    anymore? More worryingly, why does a computer with a 3 GHz chip not seem much
    faster than one with a 2 GHz chip? Where has this trend for software engineers
    across the industry to be concerned about performance come from?
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，事情为什么会变得如此糟糕？为什么时钟速度不再有太大的提升？更令人担忧的是，为什么一个3 GHz芯片的计算机似乎并不比一个2 GHz芯片的计算机快多少？这种软件工程师行业普遍关注性能的趋势是从何而来的？
- en: In this section, we’ll talk about the forces driving this trend, and why even
    the purest of software developers needs to care a bit about hardware. We’ll set
    the stage for the topics in the rest of the chapter and give you the concepts
    you’ll need to really understand JIT compilation and some of our in-depth examples.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论推动这一趋势的力量，以及为什么即使是纯粹的软件开发者也需要稍微关注一下硬件。我们将为本章剩余部分的主题设定舞台，并为您提供真正理解即时编译（JIT
    compilation）以及一些深入示例所需的概念。
- en: You may have heard the term “Moore’s law” bandied about. Many developers are
    aware that it has something to do with the rate at which computers get faster
    but are vague on the details. Let’s get under way by explaining exactly what it
    means and what the consequences are of it possibly coming to an end in the near
    future.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过“摩尔定律”这个词被广泛讨论。许多开发者都知道它与计算机速度提高的速率有关，但对细节并不清楚。让我们开始解释它确切的意思以及它可能在不久的将来结束的后果。
- en: 7.3.1 Moore’s law
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.1 摩尔定律
- en: 'Moore’s law is named for Gordon Moore, one of the founders of Intel. Here is
    one of the most common formulations of his law: *The maximum number of transistors
    on a chip that is economic to produce roughly doubles every two years.*'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 摩尔定律是以英特尔创始人之一戈登·摩尔的名字命名的。以下是他的定律最常见的一种表述：*在经济上可生产的芯片上，晶体管的最大数量大约每两年翻一番。*
- en: The law, which is really an observation about trends in computer processors
    (CPUs), is based on a paper he wrote in 1965, in which he originally forecast
    for 10 years—that is, up until 1975\. That it has lasted so well is truly remarkable.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这条定律，实际上是对计算机处理器（CPU）趋势的观察，基于他在1965年撰写的一篇论文，他最初预测了10年——即直到1975年。它持续得如此之好，确实令人印象深刻。
- en: In figure 7.2 we’ve plotted a number of real CPUs from various families (primarily
    Intel x86 family) all the way from 1980 through to the latest (2021) Apple Silicon
    (graph data is from Wikipedia, lightly edited for clarity). The graph shows the
    transistor counts of the chips against their release dates.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在图7.2中，我们绘制了来自各个系列（主要是英特尔x86系列）的多个真实CPU，从1980年到最新的（2021年）苹果硅（图中的数据来自维基百科，略有编辑以增强清晰度）。该图显示了芯片的晶体管数量与其发布日期的关系。
- en: '![](../Images/CH07_F02_Evans2.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F02_Evans2.png)'
- en: Figure 7.2 Log-linear plot of transistor count over time
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 随时间变化的晶体管数量对数线性图
- en: This is a log-linear graph, so each increment on the *y*-axis is 10 times the
    previous one. As you can see, the line is essentially straight and takes about
    six or seven years to cross each vertical level. This demonstrates Moore’s law,
    because taking six or seven years to increase tenfold is the same as roughly doubling
    every two years.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个对数线性图，因此 *y* 轴上的每个增量是前一个的 10 倍。正如您所看到的，线条基本上是直的，大约需要六到七年才能跨越每个垂直级别。这证明了摩尔定律，因为用六到七年的时间增加十倍相当于大约每两年翻一番。
- en: Keep in mind that the *y*-axis on the graph is a log scale—this means that a
    mainstream Intel chip produced in 2005 had around 100 million transistors. This
    is *100 times* as many as a chip produced in 1990.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，图中的 *y* 轴是对数刻度——这意味着 2005 年生产的主流英特尔芯片大约有 1 亿个晶体管。这是 1990 年生产的芯片的 *100 倍*。
- en: 'It’s important to notice that Moore’s law specifically talks about transistor
    counts. This is the basic point that must be understood to grasp why Moore’s law
    alone isn’t enough for the software engineer to continue to obtain a free lunch
    from the hardware engineers (see Herb Sutter, “The Free Lunch Is Over: A Fundamental
    Turn Toward Concurrency in Software,” *Dr. Dobb’s Journal* 30 (2005): 202–210).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '重要的是要注意摩尔定律专门讨论的是晶体管数量。这是理解为什么摩尔定律本身不足以让软件工程师继续从硬件工程师那里获得免费午餐的基本点（参见 Herb Sutter，“The
    Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software，” *Dr. Dobb’s
    Journal* 30 (2005): 202–210）。'
- en: Moore’s law has been a good guide to the past, but it is formulated in terms
    of transistor counts, which is not really a good guide to the performance that
    developers should expect from their code. Reality, as we’ll see, is more complicated.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 摩尔定律一直是过去的良好指南，但它是以晶体管数量来表述的，这并不是开发者应该从他们的代码中期望的性能的良好指南。正如我们将看到的，现实更加复杂。
- en: Note Transistor counts aren’t the same thing as clock speed, and even the still-common
    idea that a higher clock speed means better performance is a gross oversimplification.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 注意晶体管数量并不等同于时钟速度，而且一个更高的时钟速度意味着更好的性能这种仍然普遍存在的想法也是一个过于简化的说法。
- en: 'The truth is that real-world performance depends on a number of factors, all
    of which are important. If we had to pick just one, however, it would be this:
    how fast can data relevant to the next instructions be located? This is such an
    important concept to performance that we should take an in-depth look at it.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 事实是，现实世界的性能取决于许多因素，所有这些因素都很重要。如果我们必须只选择一个，那么它将是：与后续指令相关的数据能够多快地定位？这是一个对性能至关重要的概念，我们应该深入探讨它。
- en: 7.3.2 Understanding the memory latency hierarchy
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.2 理解内存延迟层次结构
- en: Computer processors require data to work on. If the data to process isn’t available,
    then it doesn’t matter how fast the CPU cycles—it just has to wait, performing
    no-operation (NOP) and basically stalling until the data is available.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机处理器需要数据来工作。如果要处理的数据不可用，那么 CPU 循环的速度有多快都没有关系——它只能等待，执行无操作 (NOP) 并基本上停滞，直到数据可用。
- en: 'This means that two of the most fundamental questions when addressing latency
    are, “Where is the nearest copy of the data that the CPU core needs to work on?”
    and “How long will it take to get to where the core can use it?” The main possibilities
    follow (in the so-called *Von-Neumann architecture*, which is the most commonly
    used form):'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在处理延迟时，最基本的问题有两个，“CPU 核心需要工作的数据最近副本在哪里？”以及“到达核心可以使用数据的地方需要多长时间？”以下是一些主要可能性（在所谓的
    *冯·诺依曼架构* 中，这是最常用的形式）：
- en: '*Registers*—A memory location that’s on the CPU and ready for immediate use.
    This is the part of memory that instructions operate on directly.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*寄存器*—位于 CPU 上并准备立即使用的内存位置。这是指令直接操作的内存部分。'
- en: '*Main memory*—Usually DRAM. The access time for this is around 50 ns (but see
    later on for details about how processor caches are used to avoid this latency).'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*主存储器*—通常是 DRAM。访问时间大约为 50 纳秒（但请参阅后面的细节，了解处理器缓存如何用于避免这种延迟）。'
- en: '*Solid-state drive (SSD)*—It takes 0.1 ms or less to access these disks, but
    they’re still typically more expensive compared to traditional hard disks.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*固态硬盘 (SSD)*—访问这些磁盘需要 0.1 毫秒或更少的时间，但它们通常比传统硬盘更贵。'
- en: '*Hard disk*—It takes around 5 ms to access the disk and load the required data
    into main memory.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*硬盘*—访问磁盘并将所需数据加载到主存储器大约需要 5 毫秒。'
- en: Moore’s law has described an exponential increase in transistor count, and this
    has benefited memory as well—memory access speed has also increased exponentially.
    But the exponents for these two have not been the same. Memory speed has improved
    more slowly than CPUs have added transistors, which means there’s a risk that
    the processing cores will fall idle due to not having the relevant data on hand
    to process.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 摩尔定律描述了晶体管数量的指数增长，这也使内存受益——内存访问速度也呈指数增长。但这两个指数并不相同。内存速度的提高速度比CPU增加晶体管的速度慢，这意味着处理核心可能会因为缺乏处理所需的相关数据而闲置。
- en: To solve this problem, caches—small amounts of faster memory (SRAM, rather than
    DRAM)—have been introduced between the registers and main memory. This faster
    memory costs a lot more than DRAM, both in terms of money and transistor budget,
    which is why computers don’t simply use SRAM for their entire memory.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，在寄存器和主存储器之间引入了缓存——这是一种更快的内存（SRAM，而不是DRAM）的小量。这种内存比DRAM在金钱和晶体管预算上都贵得多，这也是为什么计算机不会简单地使用SRAM作为它们整个内存的原因。
- en: Caches are referred to as L1 and L2 (some machines also have L3), with the numbers
    indicating how physically close to the core the cache is (closer caches will be
    faster). We’ll talk more about caches in section 7.6 (on JIT compilation) and
    show an example of how important the L1 cache effects are to running code. Figure
    7.3 shows just how much faster L1 and L2 cache are than main memory.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存被称为L1和L2（一些机器也有L3），数字表示缓存在物理上离核心有多近（更近的缓存会更快）。我们将在第7.6节（关于即时编译）中更多地讨论缓存，并展示一个关于L1缓存对运行代码的重要性示例。图7.3显示了L1和L2缓存比主存储器快多少。
- en: '![](../Images/CH07_F03_Evans2.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F03_Evans2.png)'
- en: Figure 7.3 Relative access times (in clock cycles) for registers, processor
    caches, and main memory
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3寄存器、处理器缓存和主存储器的相对访问时间（以时钟周期计）
- en: As well as adding caches, another technique that was used extensively in the
    1990s and early 2000s was to add increasingly complex processor features to try
    to work around the latency of memory. Sophisticated hardware techniques, such
    as instruction-level parallelism (ILP) and chip multithreading (CMT), were used
    to try to keep the CPU operating on data, even in the face of the widening gap
    between CPU capability and memory latency.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 除了添加缓存之外，20世纪90年代和21世纪初广泛使用的一种技术是添加越来越复杂的处理器特性，试图克服内存的延迟。复杂的硬件技术，如指令级并行性（ILP）和芯片多线程（CMT），被用来试图保持CPU在数据上运行，即使在CPU能力和内存延迟之间的差距不断扩大的情况下。
- en: 'These techniques came to consume a large percentage of the transistor budget
    of the CPU, and the impact they had on real performance was subject to diminishing
    returns. This trend led to the viewpoint that the future of CPU design lay in
    chips with multiple (or many) cores. Modern processors are essentially all multicore—in
    fact, this is one of the second-order consequences of Moore’s law: core counts
    have gone up as a way to utilize available transistors.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术最终消耗了CPU晶体管预算的大部分，它们对实际性能的影响是递减的。这种趋势导致了这样一个观点：CPU设计的未来在于具有多个（或许多）核心的芯片。现代处理器基本上都是多核的——事实上，这是摩尔定律的二级后果之一：核心数量增加是为了利用可用的晶体管。
- en: 'The future of performance is intimately tied to concurrency—one of the main
    ways that a system can be made more performant overall is by utilizing more cores.
    That way, even if one core is waiting for data, the other cores may still be able
    to progress (but remember the impact of Amdahl’s law, which we introduced in chapter
    5). This connection is so important that we’re going to say it again:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 性能的未来与并发性紧密相连——一个系统可以使其整体性能更优的主要方法之一是利用更多的核心。这样，即使一个核心在等待数据，其他核心仍然可能继续进步（但请记住第5章中介绍的Amdahl定律的影响）。这种联系非常重要，所以我们再次强调：
- en: Essentially all modern CPUs are multicore.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际上，几乎所有现代CPU都是多核的。
- en: Performance and concurrency are tied together as concerns.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能和并发性是紧密相连的。
- en: 'We’ve only scratched the surface of the world of computer architecture as it
    relates to software and Java programming. The interested reader who wants to know
    more should consult a specialist text, such as *Computer Architecture: A Quantitative*
    Approach, 6th edition, by Hennessy et al. (Morgan Kaufmann, December 2017).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是触及了与软件和Java编程相关的计算机体系结构世界的表面。对了解更多信息感兴趣的读者应查阅专业文本，例如Hennessy等人所著的《计算机体系结构：定量方法》第6版（Morgan
    Kaufmann，2017年12月）。
- en: These hardware concerns aren’t specific to Java programmers, but the managed
    nature of the JVM brings in some additional complexities. Let’s move on to take
    a look at these in the next section.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这些硬件问题并不特定于Java程序员，但JVM的托管特性引入了一些额外的复杂性。让我们继续前进，在下一节中查看这些内容。
- en: 7.4 Why is Java performance tuning hard?
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 为什么Java性能调优如此困难？
- en: Tuning for performance on the JVM (or, indeed, any other managed runtime) is
    inherently more difficult than for code that runs unmanaged. In a managed system,
    the entire point is to allow the runtime to take some control of the environment,
    so that the developer doesn’t have to cope with every detail. This makes programmers
    much more productive overall, but it does mean that some control has to be given
    up.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在JVM（或实际上任何其他托管运行时）上进行的性能调优，本质上比未托管的代码要困难得多。在托管系统中，整个目的就是让运行时对环境进行一些控制，这样开发者就不必处理每个细节。这使得程序员在整体上更加高效，但也意味着必须放弃一些控制权。
- en: This shift in emphasis makes the system as a whole harder to reason about because
    the managed runtime is an opaque box to the developer. The alternative is to give
    up all the advantages that a managed runtime brings, forcing programmers of, say,
    C/C++, to do almost everything for themselves. In this case, the OS supplies only
    minimal services, such as rudimentary thread scheduling, which is almost always
    a much higher overall time commitment than the additional effort required to performance
    tune.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这种重点的转移使得整个系统更难以推理，因为对开发者来说，托管运行时是一个不透明的盒子。另一种选择是放弃托管运行时带来的所有优势，迫使C/C++等语言的程序员几乎一切都要自己来做。在这种情况下，操作系统只提供最基本的服务，例如基本的线程调度，这通常比额外的性能调优所需的努力要高得多。
- en: 'Some of the most important aspects of the Java platform that contribute to
    making tuning hard follow:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Java平台中一些最重要的方面，这些方面使得调优变得困难，包括：
- en: Thread scheduling
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程调度
- en: Garbage collection (GC)
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垃圾收集（GC）
- en: Just-in-time (JIT) compilation
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即时编译（JIT）
- en: These aspects can interact in subtle ways. For example, the compilation subsystem
    uses timers to decide which methods to compile. The set of methods that are candidates
    for compilation can be affected by concerns such as scheduling and GC. The methods
    that are compiled could be different from run to run.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方面可以以微妙的方式相互作用。例如，编译子系统使用计时器来决定编译哪些方法。候选方法集可能会受到诸如调度和GC等关注点的影响。编译的方法可能会在每次运行中有所不同。
- en: As you’ve seen throughout this section, accurate measurement is key to the decision-making
    processes of performance analysis. An understanding of the details (and limitations)
    of how time is handled in the Java platform is, therefore, very useful if you
    want to get serious about performance tuning.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本节中看到的，准确测量是性能分析决策过程的关键。因此，如果你想要认真进行性能调优，了解Java平台中时间处理的细节（以及局限性）非常有用。
- en: 7.4.1 The role of time in performance tuning
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.1 时间在性能调优中的作用
- en: Performance tuning requires you to understand how to interpret the measurements
    recorded during code execution, which means you also need to understand the limitations
    inherent in any measurement of time on the platform.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 性能调优需要你理解如何解释代码执行期间记录的测量结果，这意味着你还需要理解平台任何时间测量固有的局限性。
- en: Precision
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 精度
- en: Quantities of time are usually quoted to the nearest unit on some scale. This
    is referred to as the *precision* of the measurement. For example, times are often
    measured to millisecond precision. A timing is precise if repeated measurements
    give a narrow spread around the same value.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 时间量通常以某个尺度上的最近单位来报价。这被称为测量的*精度*。例如，时间通常测量到毫秒精度。如果重复测量给出围绕相同值的狭窄分布，则计时是精确的。
- en: Precision is a measure of the amount of random noise contained in a given measurement.
    We’ll assume that the measurements made of a particular piece of code are normally
    distributed. In that case, a common way of quoting the precision is to quote the
    width of the 95% confidence interval.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 精度是给定测量中包含的随机噪声量的度量。我们将假设对特定代码片段的测量是正态分布的。在这种情况下，报价精度的常见方式是报价95%置信区间的宽度。
- en: Accuracy
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性
- en: The *accuracy* of a measurement (in our case, of time) is the ability to obtain
    a value close to the true value. In reality, you won’t normally know the true
    value, so the accuracy may be harder to determine than the precision.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 测量的*准确性*（在我们的案例中，是时间）是获得接近真实值的能力。实际上，您通常不会知道真实值，因此准确性可能比精度更难确定。
- en: Accuracy measures the systematic error in a measurement. It’s possible to have
    accurate measurements that aren’t very precise (so the basic reading is sound,
    but random environmental noise exists). It’s also possible to have precise results
    that aren’t accurate.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性衡量测量中的系统误差。可能存在准确但不太精确的测量（因此基本读数是正确的，但存在随机环境噪声）。也可能存在精确但并不准确的结果。
- en: Understanding measurements
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 理解测量
- en: An interval quoted at nanosecond precision as 5945 ns that came from a timer
    accurate to 1 *μ*s is really somewhere between 3945–7945 ns (with 95% probability).
    Beware of performance numbers that seem overly precise; always check the precision
    and accuracy of the measurements.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 一个以纳秒精度表示的5945 ns间隔，来自精度为1 *μ*s的计时器，实际上可能在3945–7945 ns之间（95%的概率）。警惕那些看似过于精确的性能数字；始终检查测量的精度和准确性。
- en: Granularity
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 粒度
- en: The true *granularity* of the system is that of the frequency of the fastest
    timer—likely the interrupt timer, in the 10 ns range. This is sometimes called
    the *distinguishability*, the shortest interval between which two events can be
    definitely said to have occurred “close together but at different times.”
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的真正*粒度*是最快计时器的频率——可能是中断计时器，在10 ns范围内。这有时被称为*可区分性*，即两个事件之间可以肯定地说它们“接近但不同时”的最短间隔。
- en: As we progress through layers of OS, JVM, and library code, the resolution of
    these extremely short times becomes basically impossible. Under most circumstances,
    these very short times aren’t available to the application developer.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们通过操作系统、JVM和库代码的各个层次前进，这些极其短时间的分辨率基本上变得不可能。在大多数情况下，这些非常短的时间对于应用程序开发者来说是不可用的。
- en: Network-distributed timing
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 网络分布式计时
- en: Most of our discussion of performance tuning centers on systems where all the
    processing takes places on a single host. But you should be aware that a number
    of special problems can arise when doing performance tuning of systems spread
    over a network. Synchronization and timing over networks is far from easy, and
    not only over the internet—even Ethernet networks will show these issues.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关于性能调整的大部分讨论集中在所有处理都在单个主机上进行的系统。但您应该意识到，在跨网络的系统进行性能调整时，可能会出现一些特殊问题。网络同步和计时远非易事，不仅限于互联网——甚至以太网网络也会出现这些问题。
- en: A full discussion of network-distributed timing is outside the scope of this
    book, but you should be aware that in general, it’s difficult to obtain accurate
    timings for workflows that extend over several boxes. In addition, even standard
    protocols such as NTP can be too inaccurate for high-precision work.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 对网络分布式计时的全面讨论超出了本书的范围，但您应该知道，通常情况下，对于跨越多个盒子的工作流程，很难获得准确的计时。此外，即使是标准协议如NTP也可能对于高精度工作来说不够准确。
- en: 'Let’s recap the most important points about Java’s timing systems:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下关于Java计时系统的最重要几点：
- en: Most systems have several different clocks inside them.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数系统内部都有几个不同的时钟。
- en: Millisecond timings are safe and reliable.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 毫秒级的计时是安全可靠的。
- en: Higher-precision time needs careful handling to avoid drift.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高精度时间需要谨慎处理，以避免漂移。
- en: You need to be aware of the precision and accuracy of timing measurements.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要意识到计时测量的精度和准确性。
- en: Before we move on to discuss garbage collection, let’s look at an example we
    referred to earlier—the effects of memory caches on code performance.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续讨论垃圾回收之前，让我们看看我们之前提到的一个例子——内存缓存对代码性能的影响。
- en: 7.4.2 Understanding cache misses
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4.2 理解缓存未命中
- en: For many high-throughput pieces of code, one of the main factors reducing performance
    is the number of L1 cache misses that are involved in executing application code.
    Listing 7.1 runs over a 2 MiB array and prints the time taken to execute one of
    two loops. The first loop increments 1 in every 16 entries of an `int[]`. Almost
    always 64 bytes are in an L1 cache line (and a Java `int` is 4 bytes wide), so
    this means touching each cache line once.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多高吞吐量的代码片段，降低性能的主要因素之一是执行应用程序代码时涉及的L1缓存未命中次数。列表7.1遍历一个2MiB数组，并打印执行两个循环之一所需的时间。第一个循环在`int[]`的每个16个条目中增加1。几乎总是有64字节在一个L1缓存行中（Java的`int`是4字节宽），这意味着只接触每个缓存行一次。
- en: Note that before you can get accurate results, we need to warm up the code,
    so that the JVM will compile the methods you’re interested in. We’ll talk about
    JIT warmup in more detail later in the chapter.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在您能够获得准确结果之前，我们需要预热代码，这样JVM就会编译您感兴趣的方法。我们将在本章后面更详细地讨论JIT预热。
- en: Listing 7.1 Understanding cache misses
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.1 理解缓存未命中
- en: '[PRE2]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Touches every item
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 涉及每个项目
- en: ❷ Touches each cache line
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 涉及每个缓存行
- en: ❸ Warms up the code
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 预热代码
- en: 'The second function, `touchEveryItem()`, increments every byte in the array,
    so it does 16 times as much work as `touchEveryLine()`. But here are some sample
    results from a typical laptop:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个函数`touchEveryItem()`增加数组中的每个字节，所以它比`touchEveryLine()`多做16倍的工作。但是，这里有一些来自典型笔记本电脑的样本结果：
- en: '[PRE3]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The results of this code show that `touchEveryItem()` doesn’t take 16 times
    as long to run as `touchEveryLine()`. It’s the memory transfer time—loading from
    main memory to CPU cache—that dominates the overall performance profile. `touchEveryLine()`
    and `touchEveryItem()` have the same number of cache line reads, and the data
    transfer time vastly outweighs the cycles spent on actually modifying the data.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的结果表明`touchEveryItem()`的运行时间并不比`touchEveryLine()`长16倍。是内存传输时间——从主内存到CPU缓存的加载——主导了整体性能轮廓。`touchEveryLine()`和`touchEveryItem()`有相同数量的缓存行读取，数据传输时间远远超过了实际修改数据所花费的周期。
- en: 'Note This demonstrates a key point: we need to develop at least a working understanding
    (or mental model) of how the CPU actually spends its time.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这证明了关键点：我们需要至少有一个工作理解（或心理模型）来了解CPU实际上是如何花费它的时间的。
- en: Our next topic is a discussion of the garbage collection subsystem of the platform.
    This is one of the most important pieces of the performance picture, and it has
    tunable parts that can be very important tools for the developer doing performance
    analysis.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来要讨论的是平台垃圾回收子系统的讨论。这是性能图中最重要的部分之一，它有可调整的部分，对于进行性能分析的开发者来说可能是非常重要的工具。
- en: 7.5 Garbage collection
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.5 垃圾回收
- en: Automatic memory management is one of the most important parts of the Java platform.
    Before managed platforms such as Java and .NET, developers could expect to spend
    a noticeable percentage of their careers hunting down bugs caused by imperfect
    memory handling.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 自动内存管理是Java平台最重要的部分之一。在Java和.NET等托管平台之前，开发者可以预期在他们的职业生涯中花费相当一部分时间来追踪由不完善的内存处理引起的错误。
- en: In recent years, however, automatic allocation techniques have become so advanced
    and reliable that they have become part of the furniture—a large number of Java
    developers are unaware of how the memory management capabilities of the platform
    work, what options are available to the developer, and how to optimize within
    the constraints of the framework.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，近年来，自动分配技术已经变得如此先进和可靠，以至于它们已经成为基础设施的一部分——大量的Java开发者对平台内存管理功能的工作原理、开发者可用的选项以及如何在框架约束内进行优化一无所知。
- en: This is a sign of how successful Java’s approach has been. Most developers don’t
    know about the details of the memory and GC systems because they usually just
    don’t *need* to know. The JVM can do a pretty good job of handling memory for
    most applications without the need for any special tuning.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这标志着Java方法取得了多么大的成功。大多数开发者不知道内存和GC系统的细节，因为他们通常根本不需要知道。JVM可以很好地处理大多数应用程序的内存，无需任何特殊调整。
- en: So, what can do when you’re in a situation where you do need to do some tuning?
    Well, first you’ll need to understand what the JVM actually does to manage memory
    for you. So, in this section we’ll cover basic theory, including
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当你处于需要调整的情况时，你能做什么呢？首先，你需要了解JVM实际上是如何为您管理内存的。因此，在本节中，我们将介绍基本理论，包括
- en: How memory is handled for a running Java process
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行Java进程时的内存处理方式
- en: Basics of mark-and-sweep collection
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记-清除收集的基础
- en: The Garbage First (G1) collector, which has been Java’s default collector since
    Java 9
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自 Java 9 以来，垃圾收集器（Garbage First，G1）一直是 Java 的默认收集器
- en: Let’s start with the basics.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从基础知识开始。
- en: 7.5.1 Basics
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.1 基础知识
- en: The standard Java process has both a stack and a heap. The *stack* is where
    local variables are stored. Local variables that hold primitives directly store
    the primitive value in the stack.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的 Java 进程既有栈也有堆。*栈* 是存储局部变量的地方。直接存储原始值的局部变量将原始值存储在栈中。
- en: Note Primitives hold bit patterns that will be interpreted according to their
    type, so the two bytes `00000000 01100001` will be interpreted as `a` if the type
    is `char` or 97 if the type is `short`.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：原始值持有将被根据其类型解释的位模式，因此这两个字节 `00000000 01100001` 如果类型是 `char`，将被解释为 `a`；如果类型是
    `short`，将被解释为 97。
- en: On the other hand, local variables of reference type will point at a location
    in Java’s *heap*, which is where the objects will actually be created. Figure
    7.4 shows where storage for variables of various types is located.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，引用类型的局部变量将指向 Java 的 *堆* 中的一个位置，这是对象实际创建的地方。图 7.4 展示了各种类型变量存储的位置。
- en: '![](../Images/CH07_F04_Evans2.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F04_Evans2.png)'
- en: Figure 7.4 Variables in the stack and heap
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 栈和堆中的变量
- en: Note that the primitive fields of an object are still allocated at addresses
    within the heap. As a Java program runs, new objects are created in the heap,
    and the relationships between the objects changes (as fields are updated). Eventually,
    the heap will run out of space for new objects to be created. However, many of
    the objects that have been created will no longer be needed (e.g., temporary objects
    that were created in one method and not passed to any other method, or returned
    to the caller).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对象的原始字段仍然在堆内的地址分配。随着 Java 程序的运行，会在堆中创建新的对象，对象之间的关系会发生变化（因为字段被更新）。最终，堆将没有足够的空间来创建新的对象。然而，许多已经创建的对象将不再需要（例如，在一个方法中创建但未传递给任何其他方法或返回给调用者的临时对象）。
- en: Space in the heap can therefore be reclaimed, and the program can continue to
    run. The mechanism by which the platform recovers and reuses heap memory that
    is no longer in use by application code is called *garbage collection*.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，堆中的空间可以被回收，程序可以继续运行。平台通过恢复和重用不再由应用程序代码使用的堆内存的机制被称为 *垃圾收集*。
- en: 7.5.2 Mark and sweep
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.2 标记和清除
- en: A great example of a simple garbage collection algorithm is *mark and sweep*,
    and, in fact, it was the first to be developed (in LISP 1.5, released in 1965).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的垃圾收集算法的绝佳例子是 *标记和清除*，实际上，它是第一个被开发的（在 1965 年发布的 LISP 1.5 中）。
- en: Note Other automatic memory management techniques exist, such as the reference-counting
    approach used by languages like Perl, which are arguably simpler (at least superficially),
    but they aren’t really garbage collection (as per Guy L. Steele “Multiprocessing
    Compactifying Garbage Collection,” *Communications of the ACM* 18, no. 9 [September
    1975]).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：其他自动内存管理技术存在，例如 Perl 等语言使用的引用计数方法，它们可能更简单（至少表面上），但它们实际上并不是垃圾收集（如 Guy L. Steele
    在“Multiprocessing Compactifying Garbage Collection”*ACM 通讯* 18, no. 9 [1975 年
    9 月] 中所述）。
- en: In its simplest form, the mark-and-sweep algorithm pauses all running program
    threads and starts from the set of objects that are known to be “live”—objects
    that have a reference in any stack frame (whether that reference is the content
    of a local variable, method parameter, temporary variable, or some rarer possibility)
    of any user thread. It then walks through the tree of references from the live
    objects, marking as live any object found en route. When this has completed, everything
    left is garbage and can be collected (swept). Note that the swept memory is returned
    to the JVM, not necessarily to the OS.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 标记-清除算法在其最简单形式下，会暂停所有正在运行的程序线程，并从已知为“活动”的对象集合开始——这些对象在任何用户线程的任何栈帧（无论该引用是局部变量、方法参数、临时变量还是一些更罕见的情况）中都有一个引用。然后，它遍历从活动对象开始的引用树，标记沿途找到的任何对象为活动状态。当这一过程完成后，剩下的所有东西都是垃圾，可以被收集（清除）。请注意，清除的内存返回给
    JVM，而不是返回给操作系统。
- en: What about the nondeterministic pause?
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 那非确定性暂停怎么办？
- en: One of the criticisms often leveled at Java (and other environments such as
    .NET) is that the mark-and-sweep form of garbage collection inevitably leads to
    Stop-the-World (usually referred to as STW). These are states in which all user
    threads must be stopped briefly, and this causes pauses that go on for some nondeterministic
    amount of time.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 对Java（以及.NET等其他环境）的批评之一是，标记-清除形式的垃圾回收不可避免地会导致“停止世界”（通常称为STW）。在这些状态下，所有用户线程必须短暂停止，这会导致持续一段时间的不确定暂停。
- en: This issue is frequently overstated. For server software, very few applications
    have to care about the pause times displayed by the garbage collectors of modern
    versions of Java. For example, in Java 11 and upward, the default garbage collector
    is a concurrent collector that does most of its work alongside application threads
    and minimizes pause time.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题通常被夸大了。对于服务器软件来说，很少有应用程序需要关心现代Java版本垃圾收集器显示的暂停时间。例如，在Java 11及以上版本中，默认的垃圾收集器是一个并发收集器，它的大部分工作与应用程序线程并行进行，并最小化暂停时间。
- en: Note Developers sometimes dream up elaborate schemes to avoid a pause, or a
    full collection of memory. In almost all cases, these should be avoided because
    they usually do more harm than good.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：开发者有时会想出复杂的方案来避免暂停，或者完全收集内存。在几乎所有情况下，都应该避免这些方案，因为它们通常弊大于利。
- en: The Java platform provides a number of enhancements to the basic mark-and-sweep
    approach. One of the simplest is the addition of *generational GC*. In this approach,
    the heap isn’t a uniform area of memory—a number of different areas of heap memory
    participate in the life cycle of a Java object.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Java平台为基本的标记-清除（mark-and-sweep）方法提供了一系列增强。其中最简单的一种是添加了*代际垃圾回收（generational GC）*。在这种方法中，堆（heap）不是一个统一的内存区域——堆内存的多个不同区域参与Java对象的整个生命周期。
- en: Depending on how long an object lives, it can be moved from area to area during
    collections. References to it can point to several different areas of memory during
    the lifespan of the object (as illustrated in figure 7.5).
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 根据对象的寿命长短，它们在收集过程中可以从一个区域移动到另一个区域。在对象的整个生命周期中，对其的引用可以指向几个不同的内存区域（如图7.5所示）。
- en: '![](../Images/CH07_F05_Evans2.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH07_F05_Evans2.png)'
- en: Figure 7.5 Areas of memory
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5 内存区域
- en: The reason for this arrangement (and the movement of objects) is that analysis
    of running systems shows that objects tend to either have brief lives or be very
    long-lived. The different areas of heap memory are designed to allow the platform
    to exploit this property, by segregating the long-lived objects from the rest.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这种安排（以及对象的移动）的原因是，对运行系统的分析表明，对象要么寿命短暂，要么非常长寿。堆内存的不同区域被设计成允许平台利用这一特性，通过将长寿对象与其他对象分开。
- en: Please note that figure 7.5 is a simple schematic of a heap designed to illustrate
    the concept of generational areas. The reality of a real Java heap is a little
    more complicated and depends upon the collector in use, as we’ll explain later
    in this chapter.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，图7.5是一个简单的堆示意图，旨在说明代际区域的概念。真实Java堆的现实情况要复杂一些，这取决于所使用的收集器，我们将在本章后面解释。
- en: 7.5.3 Areas of memory
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.3 内存区域
- en: 'The JVM has the following different areas of memory that are used to store
    objects during their natural life cycle:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: JVM在对象自然生命周期期间使用以下不同的内存区域来存储对象：
- en: '*Eden*—Eden is the area of the heap where all objects are initially allocated,
    and for many objects, this will be the only part of memory in which they ever
    reside.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*伊甸园（Eden）*—伊甸园是堆中所有对象最初分配的区域，对于许多对象来说，这将是它们唯一驻留的内存部分。'
- en: '*Survivor*—These spaces are where objects that survive a garbage collection
    cycle (hence the name) are moved. Initially they are moved from Eden, but they
    may also move between survivor spaces during subsequent GCs.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*幸存者*—这些空间是那些在垃圾回收周期中幸存下来的对象（因此得名）被移动的地方。最初，它们是从伊甸园（Eden）移动过来的，但在随后的垃圾回收（GC）过程中，它们也可能在幸存者空间之间移动。'
- en: '*Tenured*—The tenured space (aka old generation) is where surviving objects
    deemed to be “old enough” are moved to (escaping from the survivor spaces). Tenured
    memory isn’t collected during young collections.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*持久代（Tenured）*—持久代（也称为老年代）是那些被认为“足够老”的幸存对象被移动到的区域（逃离幸存者空间）。在年轻代收集期间不会收集持久代内存。'
- en: As noted, these areas of memory also participate in collections in different
    ways. For example, the survivor spaces are really there as a catch-all mechanism,
    so that short-lived objects created immediately before a collection are handled
    properly.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 正如所提到的，这些内存区域也以不同的方式参与收集。例如，幸存者空间实际上是一个通用的捕获机制，以便在收集之前立即创建的短生命期对象能够得到适当的处理。
- en: 'If the survivor spaces were not present, then very recently created (but short-lived)
    objects would be marked as “live” by the GC and would be promoted into Tenured.
    They would then immediately die but continue to take up space in Tenured until
    the next time it was collected. This next collection would also happen sooner
    than necessary due to the improper promotion of what are actually short-lived
    objects. From a theoretical standpoint, the generational hypothesis also leads
    us to the idea that there are two types of collections: young and full.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有幸存者空间，那么非常新创建的（但短生命期的）对象会被GC标记为“活着的”，并提升到Tenured。然后它们会立即死亡，但会继续占用Tenured空间，直到下一次它被收集。下一次收集也会因为实际上短生命期对象的错误提升而比必要的更早发生。从理论角度来看，代假设也引导我们想到有两种类型的收集：年轻和完整。
- en: 7.5.4 Young collections
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.4 年轻集合
- en: 'A *young collection* attempts to clear the “young” spaces (Eden and survivor).
    The process is relatively simple, as described next:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 *年轻集合* 尝试清除“年轻”空间（伊甸园和幸存者）。这个过程相对简单，如下所述：
- en: All live young objects found during the marking phase are moved.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在标记阶段发现的全部活着的对象都会被移动。
- en: Objects that are sufficiently old (those that have survived enough previous
    GC runs) go into Tenured.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 足够老的（那些在足够的GC运行中存活下来的）对象会进入Tenured。
- en: All other young, live objects go into an empty survivor space.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有其他年轻、活着的对象都会进入一个空的幸存者空间。
- en: At the end, Eden and any recently vacated survivor spaces are ready to be overwritten
    and reused, because they contain nothing but garbage.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，伊甸园和任何最近被清空的幸存者空间都准备好被覆盖和重用，因为它们除了垃圾什么都没有。
- en: A young collection is triggered when Eden is full. Note that the marking phase
    must traverse the entire live object graph. If a young object has a reference
    to a Tenured object, the references held by the Tenured object must still be scanned
    and marked. Otherwise, the situation could arise where a Tenured object holds
    a reference to an object in Eden, but nothing else does. If the mark phase doesn’t
    fully traverse, this Eden object would never been seen and would not be correctly
    handled. In practice, some performance hacks (e.g. *card tables*) are used to
    reduce the potentially high cost of a full marking traversal.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 当伊甸园满时，会触发一个年轻集合。请注意，标记阶段必须遍历整个活着的对象图。如果一个年轻对象引用了一个Tenured对象，那么Tenured对象持有的引用也必须被扫描和标记。否则，可能会出现Tenured对象持有对伊甸园中对象的引用，但没有其他任何东西持有该引用。如果标记阶段没有完全遍历，这个伊甸园对象将永远不会被看到，并且不会被正确处理。在实践中，一些性能优化（例如
    *卡片表*）被用来减少全标记遍历可能的高成本。
- en: 7.5.5 Full collections
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.5 完整集合
- en: When a young collection can’t promote an object to Tenured (due to lack of space),
    a full collection is triggered. Depending on the collector used, this may involve
    moving around objects within the old generation. This is done to ensure that the
    old generation has enough space to allocate a large object if necessary. This
    is called *compacting*.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个年轻集合无法将对象提升为Tenured（由于空间不足）时，会触发一个完整集合。根据所使用的收集器，这可能会涉及在旧代内部移动对象。这样做是为了确保旧代有足够的空间在必要时分配一个大对象。这被称为
    *压缩*。
- en: 7.5.6 Safepoints
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.6 安全点
- en: Garbage collection can’t take place without at least a short pause of all application
    threads. However, threads can’t be stopped at any arbitrary time for GC, because
    application code can modify the contents of the heap. Instead, certain special
    times occur where the JVM can be sure that the heap is in a consistent state and
    GC can take place—these are called *safepoints*.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾收集不能在没有至少短暂暂停所有应用程序线程的情况下进行。然而，线程不能在任何任意时间停止以进行GC，因为应用程序代码可以修改堆的内容。相反，在特定的时间点，JVM可以确保堆处于一致状态，GC可以发生——这些被称为
    *安全点*。
- en: One of the simplest examples of a safepoint is “in between bytecode instructions.”
    The JVM interpreter executes one bytecode at a time, and then loops to take the
    next bytecode from the stream. Just before looping, that interpreter thread must
    be finished with any modifications to the heap (e.g., from a `putfield`), so if
    the thread stops there, it is “safe.” Once all of the application threads reach
    a safepoint, then garbage collection can take place.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: safepoint的一个简单例子是“字节码指令之间”。JVM解释器一次执行一个字节码，然后循环从流中获取下一个字节码。在循环之前，那个解释器线程必须完成对堆的任何修改（例如，来自`putfield`的修改），所以如果线程在那里停止，它就是“安全的”。一旦所有应用程序线程达到safepoint，垃圾收集就可以进行。
- en: 'This is a simple example of a safepoint, but there are others. A more complete
    discussion of safepoints, and how they impact certain JIT compiler techniques,
    can be found here: [http://mng.bz/Oo8a](http://mng.bz/Oo8a). Let’s move on from
    the theoretical discussion and meet some of the garbage collection algorithms
    in the JVM.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的safepoint示例，但还有其他示例。关于safepoint的更完整讨论，以及它们如何影响某些JIT编译器技术，可以在这里找到：[http://mng.bz/Oo8a](http://mng.bz/Oo8a)。让我们从理论讨论转向实际，了解JVM中的垃圾收集算法。
- en: '7.5.7 G1: Java’s default collector'
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '7.5.7 G1: Java的默认收集器'
- en: G1 is a relatively new collector for the Java platform. It became production-quality
    at Java 8u40 and was made the default collector with Java 9 (in 2017). It was
    originally intended as a *low-pause* collector but in practice has evolved into
    a general-purpose collector (hence its default status).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: G1是Java平台的一个相对较新的收集器。它在Java 8u40时达到生产质量，并在Java 9（2017年）中被设置为默认收集器。它最初被设计为一个*低暂停*收集器，但在实践中已经发展成为一个通用收集器（因此成为默认状态）。
- en: It is not only a generational garbage collector, but it is also *regionalized*,
    which means that the G1 Java heap divides the heap into equal-sized regions (such
    as 1, 2, or 4 MB each). Generations still exist, but they are now no longer necessarily
    contiguous in memory. The new arrangement of equal-sized regions in the heap is
    illustrated in figure 7.6.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 它不仅是一个代垃圾收集器，而且它是区域化的，这意味着G1 Java堆将堆分成大小相等的区域（例如，每个1、2或4MB）。代仍然存在，但现在它们在内存中不再一定是连续的。堆中大小相等的区域的新排列如图7.6所示。
- en: '![](../Images/CH07_F06_Evans2.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F06_Evans2.png)'
- en: Figure 7.6 How G1 divides up the heap
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 G1如何划分堆
- en: Regionalization has been introduced to support the idea of predictability of
    GC pauses. Older collectors (such as Parallel) suffered from the problem that
    once a GC cycle had begun, it needed to run to completion, regardless of how long
    that took (i.e., they were *all-or-nothing*).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持GC暂停的可预测性，引入了区域化。较老的收集器（如并行收集器）存在一个问题，一旦GC周期开始，它就需要运行到完成，不管这需要多长时间（即，它们是“全有或全无”的）。
- en: G1 provides a collection strategy that should not result in longer pause times
    for larger heaps. It was designed to avoid all-or-nothing behavior, and a key
    concept for this is the *pause goal*. This is how long the program can pause for
    GC before resuming execution. G1 will do everything it can to hit your pause goals,
    within reason. During a pause, surviving objects are evacuated to another region
    (like Eden objects being moved to survivor spaces), and the region is placed back
    on the *free list* of empty regions.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: G1提供了一种收集策略，它不会导致较大堆的暂停时间更长。它被设计用来避免全有或全无的行为，而关键概念之一是*暂停目标*。这是程序在恢复执行之前可以暂停GC的时间长度。G1会尽其所能，在合理范围内达到您的暂停目标。在暂停期间，幸存对象会被迁移到另一个区域（例如，将Eden对象移动到幸存空间），然后该区域被放置回空区域的*自由列表*。
- en: Young collections in G1 are fully STW and will run to completion. This avoids
    race conditions between collection and allocation threads (which could occur if
    young collections ran concurrently with application threads).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: G1中的年轻收集是完全STW（Stop-The-World）的，并且会运行到完成。这避免了收集线程和分配线程之间的竞争条件（如果年轻收集与应用程序线程并发运行，可能会发生这种情况）。
- en: Note The generational hypothesis is that only a small fraction of objects encountered
    during a young collection are still alive. So, the time taken for a young collection
    should be very small, and much less than the pause goal.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：代假设是，在年轻收集期间遇到的仅有一小部分对象仍然存活。因此，年轻收集所需的时间应该非常小，远小于暂停目标。
- en: The collection of old objects has a different character from young collections—first,
    because once objects have reached the old generation, they tend to live for a
    considerable length of time. Second, the space provided for the old generation
    tends to be much larger than the young generation.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 旧对象的集合与年轻集合具有不同的特性——首先，因为一旦对象达到旧代，它们往往能存活相当长的时间。其次，为旧代提供的空间往往比年轻代大得多。
- en: G1 keeps track of the objects that are moved to the old generation, and when
    enough old space has been filled (controlled by the `InitiatingHeapOccupancyPercent`
    or IHOP, which defaults to 45%), an old collection is started. This is a *concurrent*
    collection, because it runs (as far as possible) concurrently with the application
    threads.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: G1会跟踪移动到旧代的对象，当足够的老空间被填满（由`InitiatingHeapOccupancyPercent`或IHOP控制，默认为45%）时，就会启动旧代收集。这是一个*并发*收集，因为它尽可能地与应用程序线程并发运行。
- en: The first piece of this old collection is a concurrent marking phase. This is
    based on an algorithm that was first described by Dijkstra and Lamport in 1978
    (see [https://dl.acm.org/doi/10.1145/359642.359655](https://dl.acm.org/doi/10.1145/359642.359655)).
    Once this completes, then a young collection is immediately triggered. This is
    followed by a *mixed collection*, which collects old regions based on how much
    garbage they have in them (which can be deduced from the statistics gathered during
    the concurrent mark). Surviving objects from the old regions are evacuated into
    fresh old regions (and compacted).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 这个旧代收集的第一部分是一个并发标记阶段。这是基于1978年由迪杰斯特拉和兰波特首次描述的算法（见[https://dl.acm.org/doi/10.1145/359642.359655](https://dl.acm.org/doi/10.1145/359642.359655)）。一旦完成，就会立即触发年轻代收集。随后是一个*混合收集*，它根据区域中垃圾的数量（可以从并发标记期间收集的统计数据中推断出来）来收集旧区域。旧区域中幸存的对象会被疏散到新的旧区域（并进行压缩）。
- en: The nature of the G1 collection strategy also allows the platform to collect
    statistics on how long (on average) a single region takes to collect. This is
    how pause goals are implemented—G1 will collect only as many regions as it has
    time for (although there may be overruns if the last region takes longer to collect
    than expected).
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: G1收集策略的性质还允许平台收集有关单个区域收集所需时间（平均）的统计数据。这就是暂停目标是如何实现的——G1将只收集它有时间收集的区域（尽管如果最后一个区域收集时间比预期长，可能会出现超时）。
- en: It is possible that the collection of the entire old generation cannot be completed
    in a single GC cycle. In this case, G1 just collects a set of regions and then
    completes the collection, releasing the CPU cores that were being used for GC.
    Provided that, over a sustained period, the creation of long-lived objects does
    not outstrip the ability of the GC to reclaim them, all should be well.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 有可能整个旧代的收集无法在一个GC周期内完成。在这种情况下，G1只收集一组区域，然后完成收集，释放用于GC的CPU核心。只要在一段持续的时间内，长生命对象的创建不会超过GC回收它们的能力，一切应该都会顺利。
- en: In the case that allocation outstrips reclamation for a sustained amount of
    time, then, as a last-ditch effort, the GC will perform a STW full collection
    and fully clean and compact the old generation. In practice, this behavior is
    not seen unless the application is badly struggling.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在分配超过回收持续一段时间的情况下，作为最后的努力，GC将执行STW完整收集，并完全清理和压缩旧代。在实践中，除非应用程序处于严重困境，否则这种行为是不会看到的。
- en: 'One other point is worth mentioning: it is possible to allocate objects that
    are larger than a single region. In practice, this means a large array (often
    of bytes or other primitives).'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 另有一点值得提及：可以分配比单个区域更大的对象。在实践中，这意味着一个大数组（通常是字节或其他原始数据类型）。
- en: Note It would be possible to artificially construct a class that had so many
    fields that a single object instance was larger than 1 MB, but this would never
    be done in a practical, real system.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：理论上可以人为构造一个具有如此多字段，以至于单个对象实例大于1 MB的类，但在实际、真实的系统中，这种情况永远不会发生。
- en: Such objects require a special type of region—a *humongous region*. These require
    special treatment by the GC because the space allocated for large arrays must
    be contiguous in memory. If sufficient free regions are adjacent to each other,
    they can be converted to a single humongous region and the array can be allocated.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的对象需要一个特殊类型的区域——一个*巨型区域*。这些区域需要GC的特殊处理，因为为大数组分配的空间在内存中必须是连续的。如果足够的空闲区域相邻，它们可以被转换成一个单一的巨型区域，数组就可以被分配。
- en: If there isn’t anywhere in memory where the array can be allocated (even after
    a young collection), then memory is said to be *fragmented*. The GC must perform
    a fully STW and compacting collection to try to free up sufficient space for the
    allocation.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 如果内存中没有地方可以分配数组（甚至在年轻代收集之后），那么内存就被说成是*碎片化*的。GC必须执行完全STW和压缩收集，以尝试为分配腾出足够的空间。
- en: G1 is established as a very effective collector across a wide variety of workloads
    and application types. However, for some workloads (e.g., those that need pure
    throughput or are still running on Java 8), then another collector, such as Parallel,
    may be of use.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: G1被确立为在广泛的负载和应用类型中非常有效的收集器。然而，对于某些工作负载（例如，需要纯吞吐量或仍在运行Java 8的工作负载），另一个收集器，如并行收集器，可能是有用的。
- en: 7.5.8 The Parallel collector
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.8 并行收集器
- en: 'The Parallel collector was the default until Java 8, and it can still be used
    as an alternative choice to G1 today. The name Parallel needs a bit of explanation,
    because *concurrent* and *parallel* are both used to describe properties of GC
    algorithms. They sound as though they should mean the same thing, but in fact
    they have two totally different meanings, as described here:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 并行收集器在Java 8之前是默认的，并且今天仍然可以用作G1的替代选择。Parallel这个名字需要一点解释，因为*并发*和*并行*都用来描述GC算法的特性。它们听起来好像应该意味着相同的事情，但实际上它们有两个完全不同的含义，如以下所述：
- en: '*Concurrent*—GC threads can run at the same time as application threads.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*并发*——GC线程可以与应用程序线程同时运行。'
- en: '*Parallel*—The GC algorithm is multithreaded and can use multiple cores.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*并行*——GC算法是多线程的，可以使用多个核心。'
- en: The terms are in no way equivalent. Instead, it’s better to think of them as
    the opposites to two other GC terms—*concurrent* is the opposite of STW, and *parallel*
    is the opposite of *single-threaded*.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这些术语在没有任何方式上是等效的。相反，最好将它们视为两个其他GC术语的对立面——*并发*是STW的对立面，*并行*是*单线程*的对立面。
- en: In some collectors (including Parallel), the heap is not regionalized. Instead,
    the generations are contiguous areas of memory, which have headroom to grow and
    shrink as needed. In this heap configuration there are two survivor spaces. They
    are sometimes referred to as *From* and *To*, and one of the survivor spaces is
    always empty unless a collection is under way.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些收集器（包括并行收集器）中，堆不是区域化的。相反，代是连续的内存区域，可以根据需要增长和缩小。在这种堆配置中，有两个幸存空间。它们有时被称为*From*和*To*，除非正在进行收集，否则其中一个幸存空间总是空的。
- en: Note Very old versions of Java also had a space called *PermGen* (or Permanent
    Generation). This is where memory was allocated for the JVM’s internal structures,
    such as the definitions of classes and methods. PermGen was removed in Java 8,
    so if you find any resources that refer to it, then they are old and likely to
    be outdated.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：Java的非常早期版本中有一个名为*PermGen*（或永久生成）的空间。这是为JVM的内部结构分配内存的地方，例如类和方法定义。PermGen在Java
    8中被移除，所以如果你发现任何提及它的资源，那么它们很可能是旧的并且可能已经过时。
- en: 'Parallel is a very efficient collector—the most efficient one available in
    mainstream Java—but it comes with a drawback: it has no real pause goal capability
    and old collections (that are STW) must run to completion, regardless of how long
    it takes.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 并行收集器是一个非常高效的收集器——在主流Java中效率最高的一个——但它也有一个缺点：它没有真正的暂停目标能力，并且旧收集（STW）必须运行完成，不管需要多长时间。
- en: Some developers sometimes ask questions about the complexity (aka “big-O”) behavior
    of GC algorithms. However, this is not really a useful question to ask. GC algorithms
    are very general, and they are required to behave acceptably across an entire
    range of possible workloads. Focusing only on their asymptotic behavior is not
    all that useful, and it is definitely not a suitable proxy for their general-case
    performance.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 一些开发者有时会询问关于GC算法的复杂度（即“大O”）行为的问题。然而，这实际上并不是一个有用的问题。GC算法非常通用，并且它们需要在整个可能的负载范围内表现出可接受的行为。仅仅关注它们的渐近行为并不是非常有用，而且绝对不是它们一般情况性能的合适代理。
- en: Garbage collection is always about trade-offs, and the trade-offs that G1 makes
    are very good for most workloads (so much so that many developers can just ignore
    them). However, the trade-offs always exist, whether or not the developer is aware
    of them. Some applications cannot ignore the trade-offs and must choose to care
    about the details of the GC subsystem, either by changing collection algorithm
    or by tuning using GC parameters.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾回收总是关于权衡，G1 做出的权衡对大多数工作负载来说非常好（好到许多开发者可以完全忽略它们）。然而，权衡总是存在的，无论开发者是否意识到它们。有些应用程序不能忽略权衡，必须选择关注
    GC 子系统的细节，无论是通过更改收集算法还是通过调整 GC 参数来微调。
- en: 7.5.9 GC configuration parameters
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5.9 GC 配置参数
- en: The JVM ships with a huge number of useful parameters (at least a hundred) that
    can be used to customize many aspects of the runtime behavior of the JVM. In this
    section, we’ll discuss some of the basic switches that pertain to garbage collection.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 随带了大量有用的参数（至少有一百个），可以用来定制 JVM 运行行为的许多方面。在本节中，我们将讨论一些与垃圾收集相关的基本开关。
- en: If a switch starts with `-X:`, it’s nonstandard and may not be portable across
    JVM implementations (such as HotSpot or Eclipse OpenJ9). If it starts with `-XX:`,
    it’s an extended switch and isn’t recommended for casual use. Many performance-relevant
    switches are extended switches.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个开关以 `-X:` 开头，它是不标准的，可能无法跨 JVM 实现移植（例如 HotSpot 或 Eclipse OpenJ9）。如果它以 `-XX:`
    开头，它是一个扩展开关，不建议用于日常使用。许多与性能相关的开关都是扩展开关。
- en: Some switches are Boolean in effect and take a + or - in front of them to turn
    it on or off. Other switches take a parameter, such as `-XX:CompileThreshold=20000`
    (which would set the number of times a method needs to be called before being
    considered for JIT compilation to 20000). Table 7.1 lists the basic GC switches
    and displays the default value (if any) of the switch.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 一些开关在效果上是布尔值，并在前面带有 + 或 - 来打开或关闭。其他开关需要参数，例如 `-XX:CompileThreshold=20000`（这将设置方法需要被调用多少次才被认为是
    JIT 编译的次数为 20000）。表 7.1 列出了基本的 GC 开关，并显示了开关的默认值（如果有）。
- en: Table 7.1 Basic garbage collection switches
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7.1 基本垃圾收集开关
- en: '| Switch | Effect |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 开关 | 影响 |'
- en: '| --- | --- |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| -Xms<size in MB>m | Initial size of the heap (default 1/64 physical memory)
    |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| -Xms<size in MB>m | 堆的初始大小（默认为物理内存的 1/64） |'
- en: '| -Xmx<size in MB>m | Maximum size of the heap (default 1/4 physical memory)
    |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| -Xmx<size in MB>m | 堆的最大大小（默认为物理内存的 1/4） |'
- en: '| -Xmn<size in MB>m | Size of the young generation in the heap |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| -Xmn<size in MB>m | 堆中年轻代的大小 |'
- en: '| -XX: `-DisableExplicitGC` | Prevents calls to `System.gc()` from having any
    effect |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| -XX: `-DisableExplicitGC` | 防止对 `System.gc()` 的调用产生任何效果 |'
- en: One unfortunately common technique is to set the size of `-Xms` to the same
    as `-Xmx`. This then means that the process will run with exactly that heap size
    and will not resize during execution. Superficially, this makes sense, and it
    gives the illusion of control to the developer. However, in practice, this approach
    is an antipattern. Modern GCs have good dynamic sizing algorithms, and artificially
    constraining them almost always does more harm than good.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 一个不幸但常见的技巧是将 `-Xms` 的大小设置为与 `-Xmx` 相同。这意味着进程将以确切的堆大小运行，并且在执行期间不会调整大小。表面上，这似乎是有道理的，并且给开发者一种控制的错觉。然而，在实践中，这种方法是一种反模式。现代
    GC 具有良好的动态大小算法，人工限制它们几乎总是弊大于利。
- en: Note In 2022, best practice for most workloads, in the absence of any other
    evidence, is to set `Xmx` and not to set `Xms` at all.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在 2022 年，对于大多数工作负载，如果没有其他证据，最佳实践是设置 `Xmx` 而不设置 `Xms`。
- en: It’s also worth noting the behavior of the JVM in a container. For Java 11 and
    17, “physical memory” means the container limit, so the heap max size must fit
    within any container limit and with space for the non-Java heap memory and any
    other processes other than the JVM. Early versions of Java 8 do not necessarily
    respect container limits, so the advice is always to upgrade to Java 11 if you
    are running your application in containers. For the G1 collector, two other settings
    may be useful during tuning exercises—they’re shown in table 7.2.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 还值得注意的是 JVM 在容器中的行为。对于 Java 11 和 17，“物理内存”意味着容器限制，因此堆的最大大小必须适合任何容器限制，并留有非 Java
    堆内存和 JVM 以外的任何其他进程的空间。Java 8 的早期版本不一定尊重容器限制，因此建议始终升级到 Java 11，如果您在容器中运行应用程序。对于
    G1 收集器，在调整练习期间可能还有两个其他设置可能有用——它们在表 7.2 中显示。
- en: Table 7.2 Flags for the G1 collector
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7.2 G1 收集器的标志
- en: '| Switch | Effect |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 开关 | 影响 |'
- en: '| --- | --- |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| -XX:MaxGCPauseMillis=50 | Indicates to G1 that it should try to pause for
    no more than 50 ms during one collection |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| -XX:MaxGCPauseMillis=50 | 告诉G1在一次收集期间尝试暂停不超过50毫秒 |'
- en: '| -XX:GCPauseIntervalMillis=200 | Indicates to G1 that it should try to run
    for at least 200 ms between collections |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| -XX:GCPauseIntervalMillis=200 | 告诉G1在收集之间至少运行200毫秒 |'
- en: The switches can be combined, such as to set a maximum pause goal of 50 ms with
    pauses occurring no closer together than 200 ms. Of course, there’s a limit on
    how hard the GC system can be pushed. There has to be enough pause time to take
    out the trash. A pause goal of 1 ms per 100 years is certainly not going to be
    attainable or honored.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这些开关可以组合使用，例如，将最大暂停目标设置为50毫秒，暂停间隔不小于200毫秒。当然，GC系统可以施加的压力是有限的。必须有一定的暂停时间来清理垃圾。每100年暂停1毫秒的目标显然是无法实现或被尊重的。
- en: In the next section, we’ll take a look at JIT compilation. For many programs,
    this is a major contributing factor to producing performant code. We’ll look at
    some of the basics of JIT compilation, and at the end of the section, we’ll explain
    how to switch on logging of JIT compilation to enable you to tell which of your
    methods are being compiled.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨JIT编译。对于许多程序来说，这是产生高性能代码的主要贡献因素之一。我们将探讨JIT编译的一些基本知识，并在本节结束时解释如何开启JIT编译的日志记录，以便您知道哪些方法正在被编译。
- en: 7.6 JIT compilation with HotSpot
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.6 HotSpot的JIT编译
- en: As we discussed in chapter 1, the Java platform is perhaps best thought of as
    “dynamically compiled.” Some application and framework classes undergo further
    compilation at runtime to transform them into machine code that can be directly
    executed.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第一章中讨论的，Java平台最好被看作是“动态编译”的。一些应用程序和框架类在运行时进行进一步编译，以将它们转换为可以直接执行的机器代码。
- en: This process is called *just-in-time (JIT) compilation*, or just JITing, and
    it usually occurs on one method at a time. Understanding this process is often
    key to identifying the important parts of any sizable codebase.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程被称为*即时（JIT）编译*，或简称JITing，它通常一次只针对一个方法。理解这个过程通常是识别任何大型代码库重要部分的关键。
- en: 'Let’s look at some good basic facts about JIT compilation:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看关于JIT编译的一些基本事实：
- en: Virtually all modern JVMs will have a JIT compiler of some sort.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几乎所有现代JVM都将拥有某种类型的JIT编译器。
- en: Purely interpreted JVMs are very slow by comparison.
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与纯解释型JVM相比，速度非常慢。
- en: Compiled methods run much, much faster than interpreted code.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译方法比解释代码运行得快得多。
- en: It makes sense to compile the most heavily used methods first.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先编译最频繁使用的方法是有意义的。
- en: When doing JIT compilation, it’s always important to take the low-hanging fruit
    first.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在进行即时编译（JIT）时，首先抓住低垂的果实总是很重要的。
- en: This last point means that we should look at the compiled code first, because
    under normal circumstances, any method that is still in an interpreted state hasn’t
    been run as often as one that has been compiled. (Occasionally a method will fail
    compilation, but this is quite rare.)
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 这最后一点意味着我们应该首先查看编译后的代码，因为在正常情况下，任何仍然处于解释状态的方法都没有像编译过的那些方法运行得频繁。（偶尔一个方法会失败编译，但这非常罕见。）
- en: Methods start off being interpreted from their bytecode representation, with
    the JVM keeping track of how many times a method has been called (and some other
    statistics). When a threshold value is reached, if the method is eligible, a JVM
    thread will compile the bytecode to machine code in the background. If compilation
    succeeds, all further calls to the method will use the compiled form, unless something
    happens to invalidate it or otherwise cause deoptimization.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 方法最初是从它们的字节码表示形式进行解释的，JVM会跟踪一个方法被调用的次数（以及一些其他统计数据）。当达到阈值值时，如果方法符合条件，JVM线程将在后台将字节码编译成机器代码。如果编译成功，所有后续对该方法的调用都将使用编译后的形式，除非发生某些情况使其无效或导致去优化。
- en: Depending on the exact nature of the code in a method, a compiled method can
    be vastly faster than the same method in interpreted mode. The figure of “up to
    100 times faster” is sometimes given, but this is an extremely rough rule of thumb.
    The nature of JIT compilation changes the executed code so much that any kind
    of single number is misleading. Understanding which methods are important in a
    program, and which important methods are being compiled, is quite often a major
    technique in improving performance.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 根据方法中代码的确切性质，编译后的方法可能比解释模式下的相同方法快得多。有时会给出“最多快100倍”的数字，但这只是一个非常粗略的经验法则。即时编译的本质会极大地改变执行代码，任何单一数字都是误导性的。理解程序中哪些方法是重要的，以及哪些重要的方法正在被编译，通常是提高性能的主要技术之一。
- en: 7.6.1 Why have dynamic compilation?
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.6.1 为什么要有动态编译？
- en: A question that is sometimes asked is, why does the Java platform bother with
    dynamic compilation? Why isn’t all compilation done up front (like C++)? The first
    answer is usually that having platform-independent artifacts (.jar and .class
    files) as the basic unit of deployment is much less of a headache than trying
    to deal with a different compiled binary for each platform being targeted.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 有时会被问到的问题之一是，为什么Java平台要费心进行动态编译？为什么不像C++那样在编译前完成所有编译？第一个答案通常是，拥有平台无关的工件（.jar和.class文件）作为部署的基本单元，比尝试处理每个目标平台的不同编译二进制文件要少很多麻烦。
- en: An alternative, and more ambitious, answer is that languages that use dynamic
    compilation have more information available to their compiler. Specifically, ahead-of-time
    (AOT) compiled languages don’t have access to any runtime information, such as
    the availability of certain instructions or other hardware details, or any statistics
    on how the code is running. This opens the intriguing possibility that a dynamically
    compiled language like Java could actually run faster than AOT-compiled languages.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个替代方案，并且更加雄心勃勃的答案是，使用动态编译的语言（如Java）有更多的信息可供编译器使用。具体来说，AOT编译的语言无法访问任何运行时信息，例如某些指令的可用性或其他硬件细节，或代码运行的任何统计数据。这开启了一个引人入胜的可能性，即动态编译的语言（如Java）实际上可能比AOT编译的语言运行得更快。
- en: Note Direct, AOT compilation of Java bytecode to machine code (aka “static Java”)
    is a live area of research in the Java community but, unfortunately, is outside
    the scope of this book.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：直接、AOT（Ahead-of-Time）编译Java字节码到机器代码（也称为“静态Java”）是Java社区中的一个活跃研究领域，但不幸的是，它超出了本书的范围。
- en: For the rest of this discussion of the mechanics of JITing, we’ll be speaking
    specifically about the JVM called HotSpot. A lot of the general discussion will
    apply to other VMs, but the specifics could vary a lot.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节关于JIT机制的其他讨论中，我们将具体讨论名为HotSpot的JVM。许多一般性讨论将适用于其他虚拟机（VM），但具体细节可能会有很大差异。
- en: We’ll start by introducing the different JIT compilers that ship with HotSpot
    and then explain two of the most powerful optimizations available from HotSpot—*inlining*
    and *monomorphic dispatch*. We’ll conclude this section by showing how to turn
    on logging of method compilation, so that you can see exactly which methods are
    being compiled. Let’s get started by introducing HotSpot.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍随HotSpot一起提供的不同即时（JIT）编译器，然后解释HotSpot提供的两种最强大的优化——*内联*和*单态分发*。我们将通过展示如何开启方法编译的日志记录来结束本节，这样您就可以看到哪些方法正在被编译。让我们从介绍HotSpot开始。
- en: 7.6.2 Introduction to HotSpot
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.6.2 热点（HotSpot）简介
- en: 'HotSpot is the JVM that Oracle acquired when it bought Sun Microsystems (it
    already owned a JVM called JRockit, which was originally developed by BEA Systems).
    HotSpot is the JVM that forms the basis of OpenJDK. It’s capable of running in
    two separate modes: client and server.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: HotSpot是Oracle在收购Sun Microsystems时获得的JVM（它已经拥有一个名为JRockit的JVM，最初由BEA Systems开发）。HotSpot是构成OpenJDK基础的JVM。它能够在两种不同的模式下运行：客户端和服务器端。
- en: In the old days, the mode could be chosen by specifying the `-client` or `-server`
    switch to the JVM on startup. Each of these modes has different applications that
    they can be preferred for.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，可以通过在启动JVM时指定`-client`或`-server`开关来选择模式。每种模式都有不同的应用场景，可以根据需要选择。
- en: C1 (aka client compiler)
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: C1（也称为客户端编译器）
- en: The C1 compiler was originally intended for use in GUI applications. This is
    an area where consistency of operation is prized, so C1 (sometimes called the
    *client compiler*) tends to make more conservative decisions when compiling. It
    can’t pause unexpectedly while it backs out an optimization decision that turned
    out to be incorrect or based on a faulty assumption. It has a fairly low compilation
    threshold—a method must be executed 1500 times before being eligible for compilation—so
    it has a relative short warmup period.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: C1编译器最初是为了在GUI应用程序中使用而设计的。这是一个重视操作一致性的领域，因此C1（有时称为*客户端编译器*）在编译时倾向于做出更保守的决定。它不能在撤销一个证明是错误的或基于错误假设的优化决策时意外地暂停。它的编译阈值相当低——一个方法必须执行1500次才能有资格进行编译——因此它的预热期相对较短。
- en: C2 (aka server compiler)
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: C2（又称服务器编译器）
- en: By contrast, the *server compiler* (C2) makes aggressive assumptions when compiling.
    To ensure that the code that’s run is always correct, C2 adds a quick runtime
    check (usually called a *guard condition*) that the assumption it made is valid.
    If not, it backs out the aggressive compilation and often tries something else.
    This aggressive approach can yield far better performance than the rather risk-averse
    client compiler.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，*服务器编译器*（C2）在编译时做出大胆的假设。为了确保运行的代码始终正确，C2添加了一个快速的运行时检查（通常称为*保护条件*），以验证它所做的假设是否有效。如果不是，它会撤销大胆的编译，并经常尝试其他方法。这种大胆的方法可以带来比相对风险规避的客户端编译器更好的性能。
- en: C2 has a much higher inlining threshold than C1\. By default, a method is not
    eligible for C2 compilation until it hits 10,000 invocations, which implies a
    much longer warmup time.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: C2的内联阈值比C1高得多。默认情况下，一个方法必须达到10,000次调用才有资格进行C2编译，这意味着更长的预热时间。
- en: Real-time Java
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 实时Java
- en: Historically, a form of Java was developed called real-time Java, and some developers
    wonder why code that has a need for high performance doesn’t simply use this platform
    (which is a separate JVM, not a HotSpot option). The answer is that a real-time
    system is not, despite common myth, necessarily the fastest system.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，开发了一种称为实时Java的Java形式，一些开发者想知道为什么需要高性能的代码不简单地使用这个平台（这是一个独立的JVM，而不是HotSpot选项）。答案是，尽管有普遍的误解，实时系统并不一定是最快的系统。
- en: Real-time programming is really about the guarantees that can be made. In statistical
    terms, a real-time system seeks to reduce the variance of the time taken to perform
    certain operations and is prepared to sacrifice a certain amount of mean latency
    to do so. Overall performance may be slightly sacrificed to attain more consistent
    running. Teams in search of higher performance are usually in search of lower
    mean latency, even at the cost of higher variance, so the aggressive optimizations
    of the server compiler are especially suitable.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 实时编程实际上关于可以做出的保证。从统计学的角度来看，实时系统寻求减少执行某些操作所需时间的方差，并准备为此牺牲一定量的平均延迟。为了达到更一致的运行，整体性能可能会略有牺牲。寻求更高性能的团队通常在寻求更低的平均延迟，即使这意味着更高的方差，因此服务器编译器的大胆优化特别适合。
- en: In modern JVMs, the client and server compilers are both used—the client compiler
    is used early on, and the advanced server-class optimizations are used after the
    application has warmed up. This dual use is known as *tiered compilation*. Our
    next topic is one that is extensively used by all of the JIT compilers.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代JVM中，客户端和服务器编译器都得到使用——客户端编译器在早期使用，而高级服务器类优化在应用程序预热后使用。这种双重使用被称为*分层编译*。我们接下来要讨论的是所有JIT编译器广泛使用的一个主题。
- en: 7.6.3 Inlining methods
  id: totrans-358
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.6.3 内联方法
- en: Inlining is one of the most powerful techniques that HotSpot has at its disposal.
    It works by eliminating the call to the inlined method and instead places the
    code of the called method inside the caller.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 内联是HotSpot拥有的最强大的技术之一。它通过消除对内联方法的调用，并将被调用方法的代码放置在调用者内部来实现。
- en: One of the advantages of the platform is that the compiler can make the decision
    to inline based on decent runtime statistics about how often the method is called
    and other factors (e.g., will it make the caller method too large and potentially
    affect code caches). HotSpot’s compiler can make much smarter decisions about
    inlining than ahead-of-time compilers.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 平台的一个优点是编译器可以根据关于方法调用频率和其他因素的合理运行时统计数据来决定是否内联（例如，这会使调用方法变得过大并可能影响代码缓存）。HotSpot的编译器在决定内联方面比即时编译器能做出更明智的决定。
- en: What about accessor methods?
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 访问器方法怎么办？
- en: Some developers incorrectly assume that an accessor method (a public getter
    accessing a private member variable) can’t be inlined by HotSpot. Their reasoning
    is that because the variable is private, the method call can’t be optimized away,
    because access to it is prohibited outside the class. This is incorrect.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 一些开发者错误地认为，访问器方法（一个公共获取器访问私有成员变量）不能被HotSpot内联。他们的理由是，因为变量是私有的，方法调用不能被优化掉，因为对它的访问在类外是被禁止的。这是不正确的。
- en: HotSpot can and will ignore access control when compiling methods to machine
    code and will replace an accessor method with a direct access to the private field.
    This doesn’t compromise Java’s security model, because all of the access control
    was checked when the class was loaded or linked.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: HotSpot可以在编译方法到机器代码时忽略访问控制，并将访问器方法替换为直接访问私有字段。这并不损害Java的安全模型，因为所有的访问控制都是在类加载或链接时检查过的。
- en: Inlining of methods is entirely automatic, and under almost all circumstances,
    the default parameter values are fine. Switches are available to control what
    size of methods will be inlined and how often a method needs to be called before
    becoming a candidate.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 方法的内联是完全自动的，在几乎所有情况下，默认参数值都是合适的。有开关可以控制将内联的方法大小以及一个方法需要被调用多少次才能成为候选者。
- en: These switches are mostly useful for the curious programmer to get a better
    understanding of how the inlining part of the internals works. They aren’t often
    useful for production code and should be considered something of a last resort
    as a performance technique, because they may well have other unpredictable effects
    on the performance of the runtime system.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 这些开关主要用于好奇的程序员更好地理解内部工作的内联部分。它们通常对生产代码没有太大用处，应被视为一种最后的性能技术手段，因为它们可能会对运行时系统的性能产生其他不可预测的影响。
- en: 7.6.4 Dynamic compilation and monomorphic calls
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.6.4 动态编译和单态调用
- en: 'One example of this type of aggressive optimization is that of the *monomorphic
    call*. This is an optimization that’s based on the observation that, in most circumstances,
    a method call on an object, like this:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型激进优化的一个例子是*单态调用*。这是一种基于观察的优化，即，在大多数情况下，对对象的方法调用，例如：
- en: '[PRE4]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: will only ever be called by one type of object. Another way of saying this is
    that the call site `obj.callMyMethod()` will almost never encounter both a class
    and its subclass. In this case, the Java method lookup can be replaced with a
    direct call to the compiled code corresponding to `callMyMethod()`.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 将只被一种类型的对象调用。另一种说法是，调用点`obj.callMyMethod()`几乎永远不会同时遇到一个类及其子类。在这种情况下，Java方法查找可以被替换为直接调用对应于`callMyMethod()`的编译代码。
- en: Note Monomorphic dispatch provides an example of the JVM runtime profiling,
    allowing the platform to perform optimizations that an AOT language like C++ simply
    can’t.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：单态分派提供了JVM运行时分析的一个例子，允许平台执行C++这样的AOT语言无法进行的优化。
- en: There’s no technical reason why the `getInstance()` method can’t return an object
    of type `MyActualClassNotInterface` under some circumstances and an object of
    some subclass under others. To guard against the possibility that this happens,
    `getInstance()` will not be put forward for monomorphic optimization unless the
    exact same type has been seen at the call site every single time, until the compilation
    threshold is reached. A runtime test to check the type of `obj` is also inserted
    into the compiled code for future calls. If this expectation is ever violated,
    the runtime backs out the optimization without the program ever noticing or ever
    doing anything incorrect.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 没有技术原因说明为什么在某些情况下`getInstance()`方法不能返回`MyActualClassNotInterface`类型的对象，而在其他情况下返回某个子类的对象。为了防止这种情况发生，除非在每次调用位置都看到完全相同的类型，直到达到编译阈值，否则`getInstance()`方法不会用于单态优化。编译代码中还会插入一个运行时测试来检查`obj`的类型，以便于未来的调用。如果这个预期被违反，运行时会撤销优化，而程序不会注意到或做任何错误的事情。
- en: This is a fairly aggressive optimization that is only ever performed by the
    server compiler. The client compiler does not do this.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当激进的优化，仅由服务器编译器执行。客户端编译器不会这样做。
- en: 7.6.5 Reading the compilation logs
  id: totrans-373
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.6.5 阅读编译日志
- en: Let’s take a look at an example to illustrate how you can use the log messages
    output by the JIT compiler. The Hipparcos star catalog lists details about stars
    that can be observed from Earth. Our example application processes the catalog
    to generate star maps of the stars that can be seen on a given night, in a given
    location.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来看看如何使用JIT编译器输出的日志消息。Hipparcos星表列出了从地球可以观察到的恒星详情。我们的示例应用程序处理该目录以生成特定地点特定夜晚可见的恒星星图。
- en: 'Let’s look at some example output that shows which methods are being compiled
    when we run our star map application. The key JVM flag we’re using is `-XX:+Print-Compilation`.
    This is one of the extended switches we briefly discussed earlier. Adding this
    switch to the command line used to start the JVM tells the JIT compilation threads
    to add messages to the standard log. These messages indicate when methods have
    passed the compilation threshold and been turned into machine code as follows:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些示例输出，这些输出显示了在运行我们的星图应用程序时正在编译哪些方法。我们使用的关键JVM标志是`-XX:+Print-Compilation`。这是我们之前简要讨论过的一个扩展开关。将此开关添加到启动JVM时使用的命令行中，告诉JIT编译线程向标准日志添加消息。这些消息指示方法何时通过编译阈值并转换为机器代码，如下所示：
- en: '[PRE5]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This is pretty typical output from `PrintCompilation`. These lines indicate
    which methods have been deemed sufficiently “hot” to be compiled. As you might
    expect, the first methods to be compiled will likely be platform methods (such
    as `String ::hashCode()`). Over time, application methods (such as the `org.camelot.hipparcos
    .Star::parseStar()` method, which is used in the example to parse a record from
    the astronomical catalog) will also be compiled.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从`PrintCompilation`输出的典型输出。这些行指示哪些方法被认为足够“热”而被编译。正如你所期望的，首先被编译的方法很可能是平台方法（例如`String
    ::hashCode()`）。随着时间的推移，应用程序方法（例如示例中用于解析天文目录记录的`org.camelot.hipparcos .Star::parseStar()`方法）也将被编译。
- en: 'The output lines have a number, which indicates in which order the methods
    are compiled on this run. Note that this order may change slightly between runs
    due to the dynamic nature of the platform. Some of the other fields follow:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 输出行带有编号，这表示在这次运行中方法被编译的顺序。请注意，由于平台的动态特性，这个顺序可能在不同的运行之间略有变化。其他一些字段如下：
- en: '`s`—Indicates the method is synchronized'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s`—表示该方法被同步'
- en: '`!`—Indicates the method has exception handlers'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`!`—表示该方法有异常处理器'
- en: '`%`—On-stack replacement (OSR)'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`%`—栈上替换（OSR）'
- en: OSR means that the method was compiled and replaced the interpreted version
    in running code. Note that OSR methods have their own numbering scheme, starting
    at 1.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: OSR表示该方法已被编译并替换了运行代码中的解释版本。请注意，OSR方法有自己的编号方案，从1开始。
- en: Beware of the zombie
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 小心僵尸
- en: When looking at sample output logs on code that is run using the server compiler
    (C2), you’ll occasionally see lines like “made not entrant” and “made zombie.”
    These lines mean that a particular method, which had been compiled, has now been
    invalidated, usually because of a class loading operation.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 当查看使用服务器编译器（C2）运行的代码的示例输出日志时，你偶尔会看到“made not entrant”和“made zombie”这样的行。这些行意味着一个特定的方法，它已经被编译，但现在已被无效化，通常是因为类加载操作。
- en: 7.6.6 Deoptimization
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.6.6 反优化
- en: HotSpot is capable of deoptimizing code that’s based on an assumption that turned
    out not to be true. In many cases, it then reconsiders and tries an alternative
    optimization. Thus, the same method may be deoptimized and recompiled several
    times.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: HotSpot能够反优化基于一个最终证明是错误的假设的代码。在许多情况下，它将重新考虑并尝试另一种优化。因此，同一个方法可能被反优化和重新编译多次。
- en: Over time, you’ll see that the number of compiled methods stabilizes. Code reaches
    a steady, compiled state and largely remains there. The exact details of which
    methods get compiled can depend on the exact JVM version and OS platform in use.
    It’s a mistake to assume that all platforms will produce the same set of compiled
    methods and that the compiled code for a given method will be roughly the same
    size across platforms. As with so much else in the performance space, this should
    be measured, and the results may surprise. Even a fairly innocent-looking Java
    method has proved to have a factor-of-five difference between Mac and Linux in
    terms of the machine code generated by JIT compilation.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，您会发现编译方法的数量会趋于稳定。代码达到一个稳定的编译状态，并大部分保持在那里。具体哪些方法会被编译可能取决于所使用的 JVM 版本和操作系统平台。认为所有平台都会产生相同的一组编译方法，并且给定方法的编译代码在各个平台上的大小大致相同是错误的。正如性能空间中的许多其他事情一样，这应该被衡量，结果可能会令人惊讶。即使是看起来相当无害的
    Java 方法，JIT 编译生成的机器代码在 Mac 和 Linux 之间也证明了有五倍的性能差异。
- en: Measurement is always necessary. Fortunately, modern JVMs ship some great tools
    to facilitate deep-dive performance analysis. Let’s take a look at them.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 测量始终是必要的。幸运的是，现代 JVM 预装了一些优秀的工具，以促进深入的性能分析。让我们来看看它们。
- en: 7.7 JDK Flight Recorder
  id: totrans-389
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.7 JDK 飞行记录器
- en: Historically, the Flight Recorder and Mission Control tools (usually referred
    to as JFR and JMC) were obtained by Oracle as part of the acquisition of BEA Systems
    back in 2008\. The two components work together—JFR is a low-overhead, event-based
    profiling engine with a high-performance backend for writing events in a binary
    format, whereas JMC is a GUI tool for examining a data file created by JFR from
    the telemetry of a single JVM.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，飞行记录器和任务控制工具（通常称为 JFR 和 JMC）是在 2008 年 Oracle 收购 BEA Systems 时获得的。这两个组件协同工作——JFR
    是一个低开销、基于事件的分析引擎，具有高性能的后端用于以二进制格式写入事件，而 JMC 是一个用于检查由 JFR 从单个 JVM 的遥测数据创建的数据文件的
    GUI 工具。
- en: The tools were originally part of the tooling offering for BEA’s JRockit JVM
    and were moved to the commercial version of Oracle JDK as part of the process
    of merging JRockit with HotSpot. After the release of JDK 9, Oracle changed the
    release model of Java and announced that JFR and JMC would become open source
    tools. JFR was contributed to OpenJDK and was delivered in JDK 11 as JEP 328\.
    JMC was spun out into a standalone open-source project and exists today as a separate
    download.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具最初是 BEA 的 JRockit JVM 工具集的一部分，在将 JRockit 与 HotSpot 合并的过程中被转移到 Oracle JDK
    的商业版本中。JDK 9 发布后，Oracle 改变了 Java 的发布模式，并宣布 JFR 和 JMC 将成为开源工具。JFR 被贡献给了 OpenJDK，并在
    JDK 11 中作为 JEP 328 提供。JMC 被分离出来成为一个独立的开源项目，现在作为一个单独的下载存在。
- en: 'Note Java 14 introduced a new feature to JFR: the ability for JFR to produce
    a continuous stream of events. This change provides a callback API to enable events
    to be handled immediately, rather than by parsing a file after the fact.'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，Java 14 为 JFR 引入了一个新特性：JFR 能够产生一个连续的事件流。这一变化提供了一个回调 API，以便能够立即处理事件，而不是在事后解析文件。
- en: One issue, however, is that because JFR and JMC only recently became open source
    tools, many Java developers are not aware of their considerable capabilities.
    Let’s take this opportunity to introduce JMC and JFR from the beginning.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一个问题是因为 JFR 和 JMC 最近才成为开源工具，许多 Java 开发者并不了解它们的强大功能。让我们借此机会从开始介绍 JMC 和 JFR。
- en: 7.7.1 Flight Recorder
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.7.1 飞行记录器
- en: JFR first became available as open source as part of OpenJDK 11, so to make
    use of it, you need to be running that version (or a more recent one). The technology
    was also back-ported to OpenJDK 8 and is available for versions 8u262 and upward.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: JFR 首次作为 OpenJDK 11 的一部分以开源形式提供，因此要使用它，您需要运行该版本（或更高版本）。该技术也被回滚到 OpenJDK 8，并适用于
    8u262 及更高版本。
- en: 'There are various ways to create a JFR recording, but we’re going to look at
    two in particular: the use of command-line arguments when starting up a JVM and
    the use of `jcmd`.'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 JFR 记录有多种方法，但我们将重点探讨两种：在启动 JVM 时使用命令行参数以及使用 `jcmd`。
- en: 'First, let’s see what command-line switches we need to start JFR up at process
    start time. The key switch follows:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看在进程启动时需要哪些命令行开关来启动 JFR。关键开关如下：
- en: '[PRE6]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This can either be done as a one-off dump file or a continuous ring buffer,
    and a large number of individual command-line options control what data is being
    captured.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以是作为一次性转储文件或连续环形缓冲区，并且大量的单个命令行选项控制着正在捕获哪些数据。
- en: In addition, JFR can capture more than a hundred different possible metrics.
    Most of these are very low-impact, but some do incur some overhead. Managing the
    configuration of all of these metrics individually would be a huge task.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，JFR可以捕获一百多种不同的可能指标。其中大多数影响非常小，但有些确实会产生一些开销。单独管理所有这些指标的配置将是一项巨大的任务。
- en: 'Instead, to simplify the process, JFR uses profiling configuration files. These
    are simple XML files that contain configurations for each metric and whether or
    not it should be captured. The standard JDK download contains two basic files:
    default.jfc and profile.jfc.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，为了简化过程，JFR使用配置文件。这些是简单的XML文件，包含每个指标的配置以及是否应该捕获。标准的JDK下载包含两个基本文件：default.jfc和profile.jfc。
- en: The default level of recording is designed to be extremely low overhead and
    to be useable by basically every production Java process. The profile.jfc configuration
    contains more detailed information, but this, of course, comes at a higher runtime
    cost.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的记录级别旨在具有极低的开销，并且基本上可以由每个生产Java进程使用。profile.jfc配置包含更详细的信息，但当然，这会带来更高的运行时成本。
- en: Note As well as the two supplied files, it is possible to create a custom configuration
    file that contains just the data points that are wanted. The JMC tool has a template
    manager that enables easy creation of these files.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：除了提供的两个文件，还可以创建一个自定义配置文件，其中只包含所需的数据点。JMC工具有一个模板管理器，可以轻松创建这些文件。
- en: 'As well as the settings file, other options that can be passed include the
    filename in which to store the recorded data and how much data to keep (in terms
    of the age of the data points). For example, an overall JFR command line might
    look like this (given on a single line):'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 除了设置文件，还可以传递其他选项，包括存储记录数据的文件名以及要保留的数据量（以数据点的年龄来衡量）。例如，一个整体的JFR命令行可能看起来像这样（给出在一行中）：
- en: '[PRE7]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note When JFR was a part of the commercial build, it was unlocked with the `-XX:+UnlockCommercialFeatures`
    switch. However, Oracle JDK 11+ emits a warning when the `-XX:+UnlockCommercialFeatures`
    option is used. This is because all the commercial features have been open sourced,
    and because the flag was never part of OpenJDK, it does not make sense to continue
    to use it. In OpenJDK builds, using the commercial features flag results in an
    error.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：当JFR是商业构建的一部分时，可以通过`-XX:+UnlockCommercialFeatures`开关来解锁。然而，Oracle JDK 11+在使用`-XX:+UnlockCommercialFeatures`选项时会发出警告。这是因为所有商业功能都已开源，并且由于该标志从未是OpenJDK的一部分，继续使用它没有意义。在OpenJDK构建中，使用商业功能标志会导致错误。
- en: 'One of the great features of JFR is that it does not need to be configured
    at the process start. Instead, it can be controlled from the command line using
    the `jcmd` command, as shown here:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: JFR的一个伟大特性是它不需要在进程启动时进行配置。相反，它可以通过`jcmd`命令从命令行进行控制，如下所示：
- en: '[PRE8]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: JFR also provides a JMX API for controlling JFR recordings as well. However,
    no matter how JFR is activated, the end result is the same—a single file per profiling
    run per JVM. The file contains a lot of binary data and is not human-readable,
    so we need some sort of tool to extract and visualize the data.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: JFR还提供了一个JMX API来控制JFR记录。然而，无论JFR如何激活，最终结果都是相同的——每个JVM的每个分析运行只有一个文件。该文件包含大量二进制数据，不便于人类阅读，因此我们需要某种工具来提取和可视化这些数据。
- en: 7.7.2 Mission Control
  id: totrans-410
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.7.2 任务控制台
- en: JDK Mission Control (JMC) is a graphical tool used to display the data contained
    in JFR output files. It is started up from the `jmc` command. This program used
    to be bundled with the Oracle JDK download but is now available separately from
    [https://jdk.java.net/jmc/](https://jdk.java.net/jmc/).
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: JDK任务控制台（JMC）是一个图形工具，用于显示JFR输出文件中的数据。它可以通过`jmc`命令启动。这个程序曾经包含在Oracle JDK下载中，但现在可以从[https://jdk.java.net/jmc/](https://jdk.java.net/jmc/)单独获取。
- en: The startup screen for Mission Control can be seen in figure 7.7\. After loading
    the file, JMC performs some automated analysis on it to identify any obvious problems
    present in the recorded run.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 任务控制台的启动屏幕如图7.7所示。在加载文件后，JMC会对其进行一些自动分析，以识别记录运行中存在的任何明显问题。
- en: '![](../Images/CH07_F07_Evans2.png)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F07_Evans2.png)'
- en: Figure 7.7 JMC startup screen
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 JMC启动屏幕
- en: Note To profile, Flight Recorder must, of course, be enabled on the target application.
    As well as using a previously created file, it is also possible to dynamically
    attach it after the application has already started. For the latter option, JMC
    provides a tab on the left of the top-left panel labeled JVM Browser for attaching
    it dynamically to local applications.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：要进行分析，当然必须在目标应用程序上启用 Flight Recorder。除了使用之前创建的文件外，还可以在应用程序启动后动态地附加它。对于后者，JMC
    在左上角面板的左侧提供了一个标签为 JVM 浏览器的选项卡，用于动态地将它附加到本地应用程序。
- en: One of the first screens encountered in JMC is the overview telemetry screen
    that shows a high-level dashboard of the overall health of the JVM. This can be
    seen in figure 7.8
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 在 JMC 中遇到的第一个屏幕之一是概述遥测屏幕，它显示了 JVM 整体健康状况的高级仪表板。这可以在图 7.8 中看到。
- en: '![](../Images/CH07_F08_Evans2.png)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F08_Evans2.png)'
- en: Figure 7.8 JMC dashboard
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8 JMC 仪表板
- en: The major subsystems of the JVM all have dedicated screens to enable deep-dive
    analysis. For example, garbage collection has an overview screen to show the GC
    events over the lifetime of the JFR file. The “Longest Pause” display at the bottom
    allows the user to see where any anomalously long GC events have occurred over
    the timeline, as shown in figure 7.9
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 的主要子系统都拥有专门的屏幕，以便进行深入分析。例如，垃圾回收有一个概述屏幕，用于显示 JFR 文件生命周期内的 GC 事件。底部的“最长暂停”显示允许用户查看在时间线中任何异常长的
    GC 事件发生的位置，如图 7.9 所示。
- en: '![](../Images/CH07_F09_Evans2.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F09_Evans2.png)'
- en: Figure 7.9 JMC garbage collection
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9 JMC 垃圾回收
- en: In the detailed profile configuration, it is also possible to see the individual
    events where new allocation buffers (TLABs) are handed out to application threads.
    We can see a much more accurate view of allocation within the process. The view
    looks like that shown in figure 7.10\. This view allows developers to easily see
    which threads are allocating the most memory—in this example, it’s a thread that
    is consuming data from Apache Kafka topics.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在详细配置配置中，还可以看到将新的分配缓冲区（TLABs）分配给应用程序线程的单独事件。我们可以看到进程内分配的更精确视图。这个视图看起来就像图 7.10
    中所示的那样。这个视图允许开发者轻松地看到哪些线程分配了最多的内存——在这个例子中，是一个正在消费 Apache Kafka 主题数据的线程。
- en: '![](../Images/CH07_F10_Evans2.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F10_Evans2.png)'
- en: Figure 7.10 JMC TLAB allocation
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10 JMC TLAB 分配
- en: The other major subsystem of the JVM is the JIT compiler, and JMC allows us
    to dig into the details of how the compiler is working, as we can see in figure
    7.11.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: JVM 的另一个主要子系统是 JIT 编译器，JMC 允许我们深入了解编译器的工作细节，如图 7.11 所示。
- en: '![](../Images/CH07_F11_Evans2.png)'
  id: totrans-426
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F11_Evans2.png)'
- en: Figure 7.11 JMC JIT compilation
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 JMC JIT 编译
- en: A key resource is the available memory in the JIT compiler’s code cache. This
    is the area of memory where the compiled version of methods are stored. The usage
    of the code cache can be visualized in JMC— an example is shown in figure 7.12.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键资源是 JIT 编译器的代码缓存中可用的内存。这是存储方法编译版本的区域。JMC 可以可视化代码缓存的使用情况——一个示例在图 7.12 中显示。
- en: '![](../Images/CH07_F12_Evans2.png)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F12_Evans2.png)'
- en: Figure 7.12 JMC JIT code cache
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 JMC JIT 代码缓存
- en: For processes that have a lot of compiled methods, this area of memory can be
    exhausted, causing the process to not reach peak performance.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 对于拥有大量编译方法的过程，这个内存区域可能会耗尽，导致进程无法达到峰值性能。
- en: JMC also includes a method-level profiler, which works in a very similar way
    to the one found in VisualVM or commercial tools such as JProfiler or YourKit.
    Figure 7.13 shows a typical result.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: JMC 还包括一个方法级分析器，其工作方式与 VisualVM 或 JProfiler 或 YourKit 等商业工具中的分析器非常相似。图 7.13
    显示了一个典型的结果。
- en: '![](../Images/CH07_F13_Evans2.png)'
  id: totrans-433
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F13_Evans2.png)'
- en: Figure 7.13 JMC method profiling
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13 JMC 方法分析
- en: One of the more advanced screens within JMC is the VM Operations view, which
    shows some of the internal operations the JVM performs and how long they take.
    This is not a view that we would expect to need for every analysis, but it would
    be potentially useful for detecting certain types of less-common problem. We can
    see a typical usage in figure 7.14.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: JMC 中更高级的屏幕之一是 VM 操作视图，它显示了 JVM 执行的一些内部操作及其持续时间。这不是我们预期在每次分析中都需要查看的视图，但它对于检测某些不太常见的问题可能非常有用。我们可以在图
    7.14 中看到一个典型的用法。
- en: '![](../Images/CH07_F14_Evans2.png)'
  id: totrans-436
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH07_F14_Evans2.png)'
- en: Figure 7.14 JMC JVM operations
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 JMC JVM 操作
- en: JMC can be used to diagnose a single JVM, and this is a great capability to
    have. However, this use case does not scale to examining an entire cluster (or
    full application). In addition, modern systems frequently need a monitoring, or
    *observability*, solution as well as the deep-dive capability.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: JMC可以用来诊断单个JVM，这是一个非常棒的功能。然而，这种用例并不能扩展到检查整个集群（或完整的应用程序）。此外，现代系统通常还需要监控或*可观察性*解决方案以及深入探究的能力。
- en: The classic JFR model of a recording file (and one-file JVM) does not make this
    easy. It is not a good fit for the stream of telemetry data delivered over the
    network to a SaaS provider or internal tool. Some vendors (e.g., New Relic and
    DataDog) do provide a JFR capability, but the use of these techniques is still
    somewhat niche.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的JFR记录文件模型（以及单文件JVM）并不便于此。它并不适合通过网络传输到SaaS提供商或内部工具的遥测数据流。一些供应商（例如New Relic和DataDog）确实提供了JFR功能，但使用这些技术的范围仍然相对狭窄。
- en: Fortunately, the JFR Streaming API that was introduced with Java 14 provides
    an excellent building block for the observability use case as well as a deep dive.
    The community as a whole has tended not to adopt the non-LTS releases of Java,
    however. This means that it is likely that only with the arrival of Java 17 (which
    is LTS) will we see widespread adoption of a Java version that supports the streaming
    form of JFR.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Java 14中引入的JFR流式API为可观察性用例以及深入探究提供了一个出色的构建块。然而，整个社区倾向于不采用Java的非LTS版本。这意味着，可能只有随着Java
    17（LTS版本）的到来，我们才会看到支持JFR流式形式的Java版本得到广泛采用。
- en: Performance tuning isn’t about staring at your code and praying for enlightenment
    or applying canned quick fixes. Instead, it’s about meticulous measurement, attention
    to detail, and patience. It’s about persistent reduction of sources of error in
    your tests, so that the true sources of performance problems emerge.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 性能调优不是关于盯着你的代码祈祷获得启迪或应用现成的快速修复。相反，它关乎细致的测量、关注细节和耐心。它关乎在测试中持续减少错误来源，以便真正导致性能问题的根源显现出来。
- en: In this chapter, we’ve been able to give only a brief introduction to a rich
    and varied topic. There is so much more to explore, and the interested reader
    should consult a dedicated text, such as *Optimizing Java* by Ben Evans, James
    Gough, and Chris Newland (O’Reilly Media, May 2018).
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们只能对丰富多样的主题进行简要介绍。还有更多内容值得探索，感兴趣的读者可以参考Ben Evans、James Gough和Chris Newland合著的《优化Java》（O’Reilly
    Media，2018年5月）等专门文本。
- en: Summary
  id: totrans-443
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The JVM is an incredibly powerful and sophisticated runtime environment.
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JVM是一个极其强大且复杂的运行时环境。
- en: The JVM’s nature can make it sometimes challenging to optimize the code within.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JVM的本质有时会使得优化其内部的代码变得具有挑战性。
- en: You have to measure to get an accurate idea of where the problems really are.
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您必须进行测量才能准确了解问题真正所在的位置。
- en: Pay particular attention to the garbage collection subsystem and the JIT compiler.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特别注意垃圾回收子系统和即时编译器。
- en: Monitoring and other tools can really help.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控和其他工具确实能提供帮助。
- en: Learn to read the logs and other indicators of the platform—tools aren’t always
    available.
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习阅读日志和其他平台指标——工具并不总是可用。
