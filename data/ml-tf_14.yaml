- en: 11 A peek into autoencoders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 概览自动编码器
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Getting to know neural networks
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解神经网络
- en: Designing autoencoders
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计自动编码器
- en: Representing images by using an autoencoder
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自动编码器表示图像
- en: Have you ever heard a person humming a melody and identified the song? That
    might be easy for you, but I’m comically tone-deaf when it comes to music. Humming
    is an approximation of a song. An even better approximation could be singing.
    Include some instrumentals, and sometimes, a cover of a song sounds indistinguishable
    from the original.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经听到有人哼唱一段旋律并识别出这首歌？这可能对你来说很容易，但我在音乐方面幽默地没有音感。哼唱是对歌曲的一种近似。更好的近似可能是唱歌。加入一些乐器，有时，翻唱的歌曲听起来与原版几乎无法区分。
- en: Instead of songs, in this chapter you’ll approximate functions. *Functions*
    are a general notion of relations between inputs and outputs. In machine learning,
    you typically want to find the function that relates inputs to outputs. Finding
    the best possible function fit is difficult, but approximating the function is
    much easier.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将不是处理歌曲，而是近似函数。*函数*是输入和输出之间关系的一般概念。在机器学习中，你通常想要找到将输入与输出关联起来的函数。找到最佳可能的函数拟合是困难的，但近似函数则容易得多。
- en: Conveniently, artificial neural networks (ANNs) are a model in machine learning
    that can approximate any function. As you’ve learned, your model is a function
    that gives the output you’re looking for, given the inputs you have. In machine-learning
    terms, given training data, you want to build a neural network model that best
    approximates the implicit function that might have generated the data—one that
    might not give you the exact answer but that’s good enough to be useful.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络（ANNs）是机器学习中的一个模型，可以近似任何函数。正如你所学的，你的模型是一个函数，它根据你拥有的输入给出你想要的输出。在机器学习的术语中，给定训练数据，你想要构建一个神经网络模型，它能最好地近似可能生成数据的隐含函数——这个函数可能不会给出确切的答案，但足够好以至于有用。
- en: So far, you’ve generated models by explicitly designing a function, whether
    it be linear; polynomial; or something more complicated, like softmax regression
    or hidden Markov models (HMMs). Neural networks enable a little bit of leeway
    when it comes to picking out the right function and, consequently, the right model.
    In theory, a neural network can model general-purpose types of transformation,
    in which you don’t need to know much at all about the function being modeled.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你通过明确设计一个函数来生成模型，无论是线性的；多项式的；还是更复杂的，如softmax回归或隐藏马尔可夫模型（HMMs）。神经网络在选择正确的函数和相应的模型时提供了一定的灵活性。理论上，神经网络可以模拟通用类型的转换，在这种情况下，你不需要了解太多关于被模拟的函数。
- en: After section 11.1 introduces neural networks, you’ll learn how to use autoencoders,
    which encode data into smaller, faster representations (section 11.2).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在11.1节介绍了神经网络之后，你将学习如何使用自动编码器，它们可以将数据编码成更小、更快的表示（11.2节）。
- en: 11.1 Neural networks
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 神经网络
- en: If you’ve heard about neural networks, you’ve probably seen diagrams of nodes
    and edges connected in a complicated mesh. That visualization is inspired mostly
    by biology—specifically, neurons in the brain. It’s also a convenient way to visualize
    functions, such as f (x) = w × x + b, as shown in figure 11.1.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你听说过神经网络，你可能见过节点和边缘以复杂网格连接的图表。这种可视化主要受到生物学的启发——特别是大脑中的神经元。它也是可视化函数（如f(x) =
    w × x + b）的一个方便方法，如图11.1所示。
- en: '![CH11_F01_Mattmann2](../Images/CH11_F01_Mattmann2.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F01_Mattmann2](../Images/CH11_F01_Mattmann2.png)'
- en: Figure 11.1 A graphical representation of the linear equation f (x) = w × x
    + b. The nodes are represented as circles, and edges are represented as arrows.
    The values on the edges are often called weights, and they act as a multiplication
    on the input. When two arrows lead to the same node, they act as a summation of
    the inputs.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 线性方程f(x) = w × x + b的图形表示。节点用圆圈表示，边用箭头表示。边上的值通常称为权重，它们对输入进行乘法操作。当两个箭头指向同一个节点时，它们作为输入的总和。
- en: As a reminder, a *linear model* is set of linear functions, such as *f* (*x*)
    = *w* × *x* + *b*, where (*w*, *b*) is the vector of parameters. The learning
    algorithm drifts around the values of *w* and *b* until it finds a combination
    that best matches the data. After the algorithm successfully converges, it’ll
    find the best possible linear function to describe the data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，**线性模型**是一组线性函数，例如 *f* (*x*) = *w* × *x* + *b*，其中 (*w*, *b*) 是参数向量。学习算法会在
    *w* 和 *b* 的值周围漂移，直到找到最佳匹配数据的组合。算法成功收敛后，它会找到最佳可能的线性函数来描述数据。
- en: Linear is a good place to start, but the real world isn’t always that pretty.
    Thus, we dive into the type of machine learning responsible for TensorFlow’s inception.
    This chapter is your introduction to a type of model called an *ANN*, which can
    approximate arbitrary functions (not only linear ones).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 线性是一个好的起点，但现实世界并不总是那么完美。因此，我们深入探讨了 TensorFlow 的起源。本章是介绍一种称为**人工神经网络**（ANN）的模型，它可以近似任意函数（不仅仅是线性函数）。
- en: Exercise 11.1
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 11.1
- en: Is f (x) = |x| a linear function?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: f (x) = |x| 是线性函数吗？
- en: '**Answer**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案**'
- en: No. It’s two linear functions stitched together at zero, not a single straight
    line.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 不，它是两个在零点缝合在一起的线性函数，而不是一条直线。
- en: To incorporate the concept of nonlinearity, it’s effective to apply a nonlinear
    function, called the *activation function*, to each neuron’s output. Three of
    the most commonly used activation functions are *sigmoid* (sig), *hyperbolic tangent*
    (tan), and a type of *ramp* function called a *Rectifying Linear Unit* (ReLU),
    all plotted in figure 11.2.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要引入非线性概念，对每个神经元的输出应用一个非线性函数，称为**激活函数**，是有效的。最常用的三个激活函数是 *sigmoid*（sig）、*双曲正切*（tan）和一种称为**ReLU**（Rectifying
    Linear Unit）的**斜坡**函数，如图 11.2 所示。
- en: '![CH11_F02_Mattmann2](../Images/CH11_F02_Mattmann2.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F02_Mattmann2](../Images/CH11_F02_Mattmann2.png)'
- en: Figure 11.2 Use nonlinear functions such as sig, tan, and ReLU to introduce
    nonlinearity to your models.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 使用非线性函数，如 sig、tan 和 ReLU，向你的模型引入非线性。
- en: You don’t have to worry too much about which activation function is better under
    what circumstances. The answer is still an active research topic. Feel free to
    experiment with the three functions shown in figure 11.2\. Usually, the best one
    is chosen by using cross-validation to determine which one gives the best model,
    given the dataset you’re working with. Remember your confusion matrix in chapter
    5? You test which model gives the fewest false positives or false negatives, or
    whatever other criterion best suits your needs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你不必过于担心在什么情况下哪种激活函数更好。答案仍然是一个活跃的研究课题。请随意尝试图 11.2 中显示的三个函数。通常，最佳选择是通过交叉验证来确定哪个函数在给定的数据集上给出最佳模型。你还记得第
    5 章中的混淆矩阵吗？你测试哪个模型给出的假阳性或假阴性最少，或者最适合你需求的任何其他标准。
- en: The sigmoid function isn’t new to you. As you may recall, the logistic regression
    classifier in chapters 5 and 6 applied this sigmoid function to the linear function
    *w* × *x* + *b*. The neural network model in figure 11.3 represents the function
    *f* (*x*) = sig(*w* × *x* + *b*). The function is a one-input, one-output network,
    where *w* and *b* are the parameters of this model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: sigmoid 函数对你来说并不陌生。你可能记得，第 5 章和第 6 章中的逻辑回归分类器将这个 sigmoid 函数应用于线性函数 *w* × *x*
    + *b*。图 11.3 中的神经网络模型表示函数 *f* (*x*) = sig(*w* × *x* + *b*)。该函数是一个单输入、单输出的网络，其中
    *w* 和 *b* 是该模型的参数。
- en: '![CH11_F03_Mattmann2](../Images/CH11_F03_Mattmann2.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F03_Mattmann2](../Images/CH11_F03_Mattmann2.png)'
- en: Figure 11.3 A nonlinear function, such as sigmoid, is applied to the output
    of a node.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 将非线性函数，如 sigmoid，应用于节点的输出。
- en: If you have two inputs (*x*1 and *x*2), you can modify your neural network to
    look like the one in figure 11.4\. Given training data and a cost function, the
    parameters to be learned are *w*1, *w*2, and b. When you’re trying to model data,
    having multiple inputs to a function is common. Image classification takes the
    entire image (pixel by pixel) as the input, for example.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有两个输入 (*x*1 和 *x*2)，你可以修改你的神经网络，使其看起来像图 11.4 中的那样。给定训练数据和损失函数，要学习的参数是 *w*1、*w*2
    和 b。当你试图建模数据时，函数有多个输入是很常见的。例如，图像分类将整个图像（像素逐像素）作为输入。
- en: '![CH11_F04_Mattmann2](../Images/CH11_F04_Mattmann2.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F04_Mattmann2](../Images/CH11_F04_Mattmann2.png)'
- en: Figure 11.4 A two-input network will have three parameters (w 1, w 2, and b).
    Multiple lines leading to the same node indicate summation.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 一个双输入网络将有三个参数（w 1、w 2 和 b）。指向同一节点的多条线表示求和。
- en: Naturally, you can generalize to an arbitrary number of inputs (*x*1, *x*2,
    ..., *xn*). The corresponding neural network represents the function *f*`(`*x*1,
    ..., *xn*`)` = sig`(`*wn* × *xn* + ... + *w*1 × *x*1 + *b*`)`, as shown in figure
    11.5.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，你可以推广到任意数量的输入（*x*1, *x*2, ..., *xn*）。相应的神经网络表示函数 *f*`(`*x*1, ..., *xn*`)`
    = sig`(`*wn* × *xn* + ... + *w*1 × *x*1 + *b*`)`，如图11.5所示。
- en: '![CH11_F05_Mattmann2](../Images/CH11_F05_Mattmann2.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F05_Mattmann2](../Images/CH11_F05_Mattmann2.png)'
- en: Figure 11.5 The input dimension can be arbitrarily long. Each pixel in a grayscale
    image can have a corresponding input x1, for example. This neural network uses
    all inputs to generate a single output number, which you might use for regression
    or classification. The notation w^T means that you’re transposing w, which is
    an n × 1 vector, into a 1 × n vector. That way, you can properly multiply it with
    x (which has the dimensions n × 1). Such a matrix multiplication is also called
    a dot product, and it yields a scalar (1D) value.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 输入维度可以是任意长的。例如，灰度图像中的每个像素都可以有一个相应的输入x1。这个神经网络使用所有输入生成一个单一的输出数字，你可能用它来进行回归或分类。符号w^T表示你正在将w（一个n
    × 1的向量）转置成一个1 × n的向量。这样，你可以正确地与x（具有n × 1的维度）相乘。这种矩阵乘法也称为点积，它产生一个标量（一维）值。
- en: So far, you’ve dealt with only an input layer and an output layer. Nothing’s
    stopping you from arbitrarily adding neurons in between. Neurons that are used
    as neither input nor output are called *hidden neurons*. These neurons are hidden
    from the input and output interfaces of the neural network, so no one can influence
    their values directly. A *hidden layer* is any collection of hidden neurons that
    don’t connect, as shown in figure 11.6\. Adding more hidden layers greatly improves
    the expressive power of the network.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你只处理了输入层和输出层。没有任何阻止你在中间任意添加神经元。既不作为输入也不作为输出的神经元称为*隐藏神经元*。这些神经元被隐藏在神经网络的输入和输出接口后面，因此没有人可以直接影响它们的值。*隐藏层*是任何未连接的隐藏神经元集合，如图11.6所示。添加更多的隐藏层可以大大提高网络的表达能力。
- en: '![CH11_F06_Mattmann2](../Images/CH11_F06_Mattmann2.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F06_Mattmann2](../Images/CH11_F06_Mattmann2.png)'
- en: Figure 11.6 Nodes that don’t interface to both the input and the output are
    called hidden neurons. A hidden layer is a collection of hidden units that aren’t
    connected.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6 不与输入和输出都接口的节点称为隐藏神经元。隐藏层是一组未连接的隐藏单元。
- en: As long as the activation function is something nonlinear, a neural network
    with at least one hidden layer can approximate arbitrary functions. In linear
    models, no matter what parameters are learned, the function remains linear. The
    nonlinear neural network model with a hidden layer, on the other hand, is flexible
    enough to approximately represent any function. What a time to be alive!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 只要激活函数是非线性的，至少有一个隐藏层的神经网络可以逼近任意函数。在线性模型中，无论学习到什么参数，函数都保持线性。另一方面，具有隐藏层的非线性神经网络模型足够灵活，可以近似表示任何函数。这是一个多么美好的时代！
- en: 'TensorFlow comes with many helper functions that help you obtain the parameters
    of a neural network in an efficient way. You’ll see how to invoke those tools
    in this chapter when you start using your first neural network architecture: an
    autoencoder.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow附带许多辅助函数，可以帮助你以高效的方式获得神经网络的参数。当你开始使用你的第一个神经网络架构：自动编码器时，你将在本章中看到如何调用这些工具。
- en: 11.2 Autoencoders
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 自动编码器
- en: An *autoencoder* is a type of neural network that tries to learn parameters
    that make the output as close to the input as possible. An obvious way to do so
    is to return the input directly, as shown in figure 11.7.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*自动编码器*是一种神经网络，它试图学习使输出尽可能接近输入的参数。一个明显的方法是直接返回输入，如图11.7所示。'
- en: '![CH11_F07_Mattmann2](../Images/CH11_F07_Mattmann2.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F07_Mattmann2](../Images/CH11_F07_Mattmann2.png)'
- en: Figure 11.7 If you want to create a network in which the input equals the output,
    you can connect the corresponding nodes and set each parameter’s weight to 1.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.7 如果你想创建一个输入等于输出的网络，你可以连接相应的节点并将每个参数的权重设置为1。
- en: But an autoencoder is more interesting than that. It contains a small hidden
    layer! If that hidden layer has a smaller dimension than the input, the hidden
    layer is a compression of your data, called *encoding*.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 但自动编码器比这更有趣。它包含一个小的隐藏层！如果这个隐藏层的维度比输入小，那么隐藏层就是你的数据压缩，称为*编码*。
- en: Encoding data in the real world
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中编码数据
- en: A couple of audio formats are out there, but the most popular may be MP3 because
    of its relatively small file size. You may have already guessed that such efficient
    storage comes with a trade-off. The algorithm to generate an MP3 file takes original
    uncompressed audio and shrinks it to a much smaller file that sounds approximately
    the same to your ears. But it’s lossy, meaning that you won’t be able to completely
    recover the original uncompressed audio from the encoded version.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种音频格式，但最流行的可能是MP3，因为它相对较小的文件大小。你可能已经猜到，这种高效的存储方式是有代价的。生成MP3文件的算法将原始未压缩音频缩小到一个听起来与你耳朵相似但文件大小小得多的文件。但是它是有损的，这意味着你将无法从编码版本完全恢复原始未压缩音频。
- en: Similarly, in this chapter, we want to reduce the dimensionality of the data
    to make it more workable but not necessarily create a perfect reproduction.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在本章中，我们希望降低数据的维度，使其更易于处理，但并不一定需要创建一个完美的复制。
- en: The process of reconstructing the input from the hidden layer is called *decoding*.
    Figure 11.8 shows an exaggerated example of an autoencoder.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从隐藏层重建输入的过程称为*解码*。图11.8展示了自动编码器的夸张示例。
- en: '![CH11_F08_Mattmann2](../Images/CH11_F08_Mattmann2.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F08_Mattmann2](../Images/CH11_F08_Mattmann2.png)'
- en: Figure 11.8 Here, you introduce a restriction to a network that tries to reconstruct
    its input. Data will pass through a narrow channel, as illustrated by the hidden
    layer. In this example, there’s only one node in the hidden layer. This network
    is trying to encode (and decode) an n-dimensional input signal into one dimension,
    which will likely be difficult in practice.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8 在这里，你为尝试重建其输入的网络引入了一个限制。数据将通过一个狭窄的通道，如图中的隐藏层所示。在这个例子中，隐藏层只有一个节点。这个网络试图将一个n维输入信号编码（和解码）为一维，这在实践中可能很困难。
- en: Encoding is a great way to reduce the dimensions of the input. If you can represent
    a 256 × 256 image in 100 hidden nodes, for example, you’ve reduced each data item
    by a factor of thousands.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 编码是减少输入维度的绝佳方式。例如，如果你能将256 × 256的图像表示为100个隐藏节点，那么你已将每个数据项减少了数千倍。
- en: Exercise 11.2
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.2
- en: Let x denote the input vector (x1, x2, ..., xn), and let y denote the output
    vector (y1, y2, ..., yn). Last, let w and w’ denote the encoder and decoder weights,
    respectively. What’s a possible cost function to train this neural network?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让x表示输入向量（x1, x2, ..., xn），让y表示输出向量（y1, y2, ..., yn）。最后，让w和w’分别表示编码器和解码器的权重。训练这个神经网络的可能成本函数是什么？
- en: '**Answer**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案**'
- en: See the loss function in listing 11.3.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅列表11.3中的损失函数。
- en: It makes sense to use an object-oriented programming style to implement an autoencoder.
    That way, you can reuse the class in other applications without worrying about
    tightly coupled code. Creating your code as outlined in listing 11.1 helps you
    build deeper architectures, such as a *stacked autoencoder*, which has been known
    to perform better empirically.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用面向对象编程风格实现自动编码器是有意义的。这样，你可以在其他应用中重用这个类，而不用担心紧密耦合的代码。按照列表11.1中的概述创建你的代码可以帮助你构建更深的架构，例如*堆叠自动编码器*，这在经验上已被证明表现更好。
- en: TIP Generally, with neural networks, adding more hidden layers seems to improve
    performance if you have enough data to not overfit the model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：通常，在神经网络中，如果你有足够的数据来避免模型过拟合，增加更多的隐藏层似乎可以提高性能。
- en: Listing 11.1 Python class schema
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.1 Python类架构
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Initializes variables
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 初始化变量
- en: ❷ Trains on a dataset
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在数据集上训练
- en: ❸ Tests on some new data
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 对一些新数据的测试
- en: Open a new Python source file, and call it autoencoder.py. This file will define
    the `autoencoder` class that you’ll use from a separate piece of code.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 打开一个新的Python源文件，并将其命名为autoencoder.py。这个文件将定义你将在单独的代码中使用的`autoencoder`类。
- en: The constructor will set up all the TensorFlow variables, placeholders, optimizers,
    and operators. Anything that doesn’t immediately need a session can go in the
    constructor. Because you’re dealing with two sets of weights and biases (one for
    the encoding step and the other for the decoding step), you can use TensorFlow’s
    `tf.name` scopes to disambiguate a variable’s name.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数将设置所有TensorFlow变量、占位符、优化器和算子。任何不需要立即会话的东西都可以放在构造函数中。因为你正在处理两组权重和偏差（一组用于编码步骤，另一组用于解码步骤），你可以使用TensorFlow的`tf.name`作用域来区分变量的名称。
- en: Listing 11.2 shows an example of defining a variable within a named scope. Now
    you can seamlessly save and restore this variable without worrying about name
    collisions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.2展示了在命名范围内定义变量的一个示例。现在你可以无缝地保存和恢复这个变量，而不用担心名称冲突。
- en: Listing 11.2 Using name scopes
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.2 使用名称范围
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Moving on, implement the constructor, as shown in listing 11.3.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，实现构造函数，如列表11.3所示。
- en: Listing 11.3 The `autoencoder` class
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.3 `autoencoder`类
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Number of learning cycles
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 学习周期数
- en: ❷ Hyperparameter of the optimizer
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 优化器的超参数
- en: ❸ Defines the input layer dataset
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义输入层数据集
- en: ❹ Defines the weights and biases under a name scope so you can tell them apart
    from the decoder’s weights and biases
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在名称范围内定义权重和偏差，以便你能将它们与解码器的权重和偏差区分开来
- en: ❺ The decoder’s weights and biases are defined under this name scope.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 解码器的权重和偏差定义在这个名称范围内。
- en: ❻ These will be method variables.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 这些将是方法变量。
- en: ❼ Defines the reconstruction cost
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 定义重建成本
- en: ❽ Chooses the optimizer
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 选择优化器
- en: ❾ Sets up a saver to save model parameters as they’re being learned
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ❾ 设置保存器以在学习过程中保存模型参数
- en: Now, in listing 11.4, you’ll define a class method called `train` that will
    receive a dataset and learn parameters to minimize its loss.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在列表11.4中，你将定义一个名为`train`的类方法，它将接收一个数据集并学习参数以最小化其损失。
- en: Listing 11.4 Training the autoencoder
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.4 训练自动编码器
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Starts a TensorFlow session and initializes all variables
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 启动TensorFlow会话并初始化所有变量
- en: ❷ Iterates through the number of cycles defined in the constructor
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 遍历构造函数中定义的周期数
- en: ❸ One sample at a time, trains the neural network on a data item
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 一次训练一个样本，在数据项上训练神经网络
- en: ❹ Prints the reconstruction error once every 10 cycles
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 每10个周期打印一次重建误差
- en: ❺ Saves the learned parameters to file
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将已学习的参数保存到文件
- en: Now you have enough code to design an algorithm that learns an autoencoder from
    arbitrary data. Before you start using this class, create one more method. As
    shown in listing 11.5, the `test` method lets you evaluate the autoencoder on
    new data.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有足够的代码来设计一个从任意数据中学习自动编码器的算法。在你开始使用这个类之前，创建一个额外的方法。如列表11.5所示，`test`方法让你可以在新数据上评估自动编码器。
- en: Listing 11.5 Testing the model on data
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.5 在数据上测试模型
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Loads the learned parameters
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载已学习的参数
- en: ❷ Reconstructs the input
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 重建输入
- en: Finally, create a new Python source file called main.py, and use your `autoencoder`
    class, as shown in listing 11.6.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，创建一个新的Python源文件名为main.py，并使用你的`autoencoder`类，如列表11.6所示。
- en: Listing 11.6 Using your `autoencoder` class
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.6 使用你的`autoencoder`类
- en: '[PRE5]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Running the `train` function will output debug info about how the loss decreases
    over the epochs. The `test` function shows info about the encoding and decoding
    process:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`train`函数将输出关于损失如何在各个时期减少的调试信息。`test`函数显示编码和解码过程的信息：
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Notice that you’re able to compress a 4D vector into 1D and then decode it back
    into a 4D vector with some loss in data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你可以将一个4D向量压缩成1D，然后通过一些数据损失将其解码回4D向量。
- en: 11.3 Batch training
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 批量训练
- en: Training a network one sample at a time is the safest bet if you’re not pressed
    for time. But if your network training is taking longer than desired, one solution
    is to train it with multiple data inputs at a time, called *batch training*.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有时间压力，一次训练一个样本是训练网络最安全的方法。但如果你的网络训练时间过长，一个解决方案是同时使用多个数据输入进行训练，称为*批量训练*。
- en: Typically, as the batch size increases, the algorithm speeds up but has a lower
    likelihood of converging successfully. The comparison between batch size and successful
    convergence is a double-edged sword. Go wield it in listing 11.7\. You’ll use
    that helper function later.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，随着批量大小的增加，算法速度会加快，但成功收敛的可能性会降低。批量大小的比较是一把双刃剑。在列表11.7中运用它。你稍后会使用那个辅助函数。
- en: Listing 11.7 Batch helper function
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.7 批量辅助函数
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: To use batch learning, you’ll need to modify the `train` method from listing
    11.4\. The batch version, shown in listing 11.8, inserts an additional inner loop
    for each batch of data. Typically, the number of batch iterations should be enough
    so that all data is covered in the same epoch.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用批量学习，你需要修改列表11.4中的`train`方法。批量版本，如列表11.8所示，为每个数据批次插入一个额外的内部循环。通常，批次数应该足够，以便在同一个时期内覆盖所有数据。
- en: Listing 11.8 Batch learning
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.8 批量学习
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Loops through various batch selections
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 遍历各种批次选择
- en: ❷ Runs the optimizer on a randomly selected batch
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在随机选择的批次上运行优化器
- en: 11.4 Working with images
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.4 处理图像
- en: Most neural networks, like your autoencoder, accept only 1D input. Pixels of
    an image, on the other hand, are indexed by both rows and columns. Moreover, if
    a pixel is in color, it has a value for its red, green, and blue concentrations,
    as shown in figure 11.9.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数神经网络，如您的自动编码器，只接受 1D 输入。另一方面，图像的像素由行和列索引。此外，如果一个像素是彩色的，它具有红色、绿色和蓝色浓度的值，如图
    11.9 所示。
- en: '![CH11_F09_Mattmann2](../Images/CH11_F09_Mattmann2.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F09_Mattmann2](../Images/CH11_F09_Mattmann2.png)'
- en: Figure 11.9 A colored image is composed of pixels, and each pixel contains values
    for red, green, and blue.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.9 一幅彩色图像由像素组成，每个像素包含红色、绿色和蓝色的值。
- en: 'A convenient way to manage the higher dimensions of an image involves two steps:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 管理图像高维度的便捷方法涉及两个步骤：
- en: Convert the image to grayscale. Merge the values of red, green, and blue into
    the *pixel intensity*, which is a weighted average of the color values.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为灰度。将红色、绿色和蓝色的值合并到 *像素强度* 中，它是颜色值的加权平均值。
- en: Rearrange the image into row-major order. *Row-major order* stores an array
    as a longer, single-dimension set; you put all the dimensions of an array on the
    end of the first dimension, which allows you to index the image by one number
    instead of two. If an image is 3 × 3 pixels, you rearrange it into the structure
    shown in figure 11.10.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像重新排列成行主序。*行主序*将数组存储为更长的单维集合；您将数组的所有维度放在第一个维度的末尾，这使得您可以用一个数字而不是两个数字来索引图像。如果一个图像是
    3 × 3 像素，您将其重新排列成图 11.10 所示的结构。
- en: '![CH11_F10_Mattmann2](../Images/CH11_F10_Mattmann2.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F10_Mattmann2](../Images/CH11_F10_Mattmann2.png)'
- en: Figure 11.10 An image can be represented in row-major order. That way, you can
    represent a 2D structure as a 1D structure.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.10 图像可以用行主序表示。这样，您可以将二维结构表示为一维结构。
- en: You can use images in TensorFlow in many ways. If you have pictures lying around
    on your hard drive, you can load them by using SciPy, which comes with TensorFlow.
    Listing 11.9 shows you how to load an image in grayscale, resize it, and represent
    it in row-major order.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用多种方式在 TensorFlow 中使用图像。如果您在硬盘上有一堆图片，您可以使用 TensorFlow 中的 SciPy 加载它们。列表 11.9
    展示了如何以灰度模式加载图像，调整大小，并以行主序表示它。
- en: Listing 11.9 Loading images
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.9 加载图像
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Loads an image as grayscale
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 以灰度模式加载图像
- en: ❷ Resizes it to something smaller
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将其调整到更小的尺寸
- en: ❸ Converts it to a 1D structure
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将其转换为 1D 结构
- en: Image processing is a lively field of research, so datasets are readily available
    for you to use, instead of using your own limited images. A dataset called CIFAR-10,
    for example, contains 60,000 labeled images, each 32 × 32.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图像处理是一个充满活力的研究领域，因此数据集很容易获得，您可以使用这些数据集而不是使用自己有限的图像。例如，名为 CIFAR-10 的数据集包含 60,000
    个标记的图像，每个图像大小为 32 × 32。
- en: Exercise 11.3
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 11.3
- en: Can you name other online image datasets? Search online for more.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 您能列出其他在线图像数据集吗？在网上搜索更多。
- en: '**Answer**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案**'
- en: Perhaps the most-used dataset in the deep-learning community is ImageNet ([www
    .image-net.org](http://www.image-net.org)). You can also find a great list at
    [http://deeplearning.net/datasets](http://deeplearning.net/datasets).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习社区中最常用的数据集可能是 ImageNet ([www.image-net.org](http://www.image-net.org))。您也可以在
    [http://deeplearning.net/datasets](http://deeplearning.net/datasets) 找到一份很好的列表。
- en: Download the Python dataset from [www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html).
    Place the extracted cifar-10-batches-py folder in your working directory. Listing
    11.10 is from the CIFAR-10 web page; add the code to a new file called main_ imgs.py.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html)
    下载 Python 数据集。将提取的 cifar-10-batches-py 文件夹放置在您的当前工作目录中。列表 11.10 来自 CIFAR-10 网页；将代码添加到名为
    main_imgs.py 的新文件中。
- en: Listing 11.10 Reading from the extracted CIFAR-10 dataset
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.10 从提取的 CIFAR-10 数据集中读取
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Reads the CIFAR-10 file, returning the loaded dictionary
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 读取 CIFAR-10 文件，返回加载的字典
- en: You can read each of the dataset files by using the `unpickle` function created
    in listing 11.10\. The CIFAR-10 dataset contains six files, each prefixed with
    `data_batch_` and followed by a number. Each file contains information about the
    image data and corresponding label. Listing 11.11 shows how to loop through all
    the files and append the datasets to memory.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用列表 11.10 中创建的 `unpickle` 函数读取数据集中的每个文件。CIFAR-10 数据集包含六个文件，每个文件以 `data_batch_`
    开头，后跟一个数字。每个文件包含关于图像数据和相应标签的信息。列表 11.11 展示了如何遍历所有文件并将数据集附加到内存中。
- en: Listing 11.11 Reading all CIFAR-10 files to memory
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.11 将所有 CIFAR-10 文件读取到内存中
- en: '[PRE11]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Loops through the six files
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 遍历六个文件
- en: ❷ Loads the file to obtain a Python dictionary
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 加载文件以获取 Python 字典
- en: ❸ The rows of a data sample represent each sample, so you stack it vertically.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 数据样本的行代表每个样本，所以你垂直堆叠它。
- en: ❹ Labels are 1D, so you stack them horizontally.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 标签是一维的，所以你水平堆叠它们。
- en: Each image is represented as a series of red pixels, followed by green pixels
    and then blue pixels. Listing 11.12 creates a helper function to convert the image
    to grayscale by averaging the red, green, and blue values.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 每个图像都表示为一系列红色像素，接着是绿色像素，然后是蓝色像素。列表 11.12 创建了一个辅助函数，通过平均红色、绿色和蓝色值将图像转换为灰度。
- en: Note You can achieve more-realistic grayscale in other ways, but this approach
    of averaging the three values gets the job done. Human perception is more sensitive
    to green light, so in some other versions of grayscaling, green values might have
    a higher weight in the averaging.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：你可以用其他方法实现更逼真的灰度，但这种方法通过平均三个值来完成工作。人类对绿光的感知更敏感，所以在某些其他版本的灰度中，绿色值可能在平均中具有更高的权重。
- en: Listing 11.12 Converting CIFAR-10 image to grayscale
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.12 将 CIFAR-10 图像转换为灰度
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Finally, collect all images of a certain class, such as `horse`. You’ll run
    your autoencoder on all pictures of horses, as shown in listing 11.13.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，收集某一类别的所有图像，例如“马”。你将在所有马的图片上运行你的自动编码器，如列表 11.13 所示。
- en: Listing 11.13 Setting up the autoencoder
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.13 设置自动编码器
- en: '[PRE13]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Selects horse (label 7) from the set of indices to use to index into the data
    array x
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从用于索引数据数组 x 的索引集中选择马（标签 7）
- en: ❷ A matrix of size (5000, 3072), 5,000 images and 32 × 32*3 channels (R,G,B),
    or 3,072 values
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 大小为 (5000, 3072) 的矩阵，5,000 张图像和 32 × 32*3 个通道（R,G,B），或 3,072 个值
- en: 'Now you can encode images similar to your training dataset into 100 numbers.
    This autoencoder model is one of the simplest, so clearly, the encoding will be
    lossy. Beware: running this code may take up to 10 minutes. The output will trace
    loss values of every 10 epochs:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以将类似于你的训练数据集的图像编码为 100 个数字。这个自动编码器模型是最简单的之一，所以很明显，编码将是损失性的。小心：运行此代码可能需要长达
    10 分钟。输出将跟踪每 10 个周期的损失值：
- en: '[PRE14]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: See the book’s website ([http://mng.bz/nzpa](http://mng.bz/nzpa)) or GitHub
    repo ([http://mng.bz/ v9m7](http://mng.bz/v9m7)) for a full example of the output.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅本书的网站 ([http://mng.bz/nzpa](http://mng.bz/nzpa)) 或 GitHub 仓库 ([http://mng.bz/v9m7](http://mng.bz/v9m7))
    以获取输出示例的完整示例。
- en: 11.5 Application of autoencoders
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.5 自动编码器的应用
- en: 'This chapter introduced the most straightforward type of autoencoder, but other
    variants have been studied, each with their benefits and applications. Let’s take
    a look at a few:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了最直接的自动编码器类型，但其他变体也已被研究，每种都有其优点和应用。让我们看看几个例子：
- en: A *stacked autoencoder* starts the same way that a normal autoencoder does.
    It learns the encoding for an input into a smaller hidden layer by minimizing
    the reconstruction error. Then the hidden layer is treated as the input to a new
    autoencoder that tries to encode the first layer of hidden neurons to an even
    smaller layer (the second layer of hidden neurons). This process continues as
    desired. Often, the learned encoding weights are used as initial values for solving
    regression or classification problems in a deep neural network architecture.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *堆叠自动编码器* 以与普通自动编码器相同的方式开始。它通过最小化重建误差来学习输入到较小隐藏层的编码。然后，将隐藏层作为新自动编码器的输入，该自动编码器试图将第一层隐藏神经元编码到一个更小的层（第二层隐藏神经元）。这个过程可以按需继续。通常，学习的编码权重被用作解决深度神经网络架构中的回归或分类问题的初始值。
- en: A *denoising autoencoder* receives a noised-up input instead of the original
    input and tries to “denoise” it. The cost function is no longer used to minimize
    the reconstruction error. Now you’re trying to minimize the error between the
    denoised image and the original image. The intuition is that our human minds can
    still comprehend a photograph even with scratches or markings on it. If a machine
    can also see through the noised input to recover the original data, maybe it has
    a better understanding of the data. Denoising models have been shown to better
    capture salient features of an image.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 *去噪自动编码器* 接收的是经过噪声处理的输入而不是原始输入，并试图“去噪”它。成本函数不再用于最小化重建误差。现在你正在尝试最小化去噪图像与原始图像之间的误差。直觉是，即使照片上有划痕或标记，我们的人类大脑仍然可以理解照片。如果一台机器也能透过噪声输入来恢复原始数据，那么它可能对数据的理解更好。去噪模型已被证明能更好地捕捉图像的显著特征。
- en: A *variational autoencoder* can generate new natural images, given the hidden
    variables directly. Let’s say you encode a picture of a man as a 100D vector and
    then a picture of a woman as another 100D vector. You can take the average of
    the two vectors, run it through the decoder, and produce a reasonable image that
    represents a person who’s between a man and a woman. This generative power of
    the variational autoencoder is derived from a type of probabilistic model called
    a *Bayesian network*. It’s also some of the technology used in modern deep fakes
    and generative adversarial networks.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种 *变分自动编码器* 可以直接根据隐藏变量生成新的自然图像。比如说，你将一张男人的照片编码为一个100维向量，然后将一张女人的照片编码为另一个100维向量。你可以取这两个向量的平均值，通过解码器处理，并生成一个合理的图像，代表一个介于男人和女人之间的形象。这种变分自动编码器的生成能力来源于一种称为
    *贝叶斯网络* 的概率模型。它也是现代深度伪造和生成对抗网络中使用的某些技术之一。
- en: Summary
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A neural network is useful when a linear model is ineffective for describing
    the dataset.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当线性模型无法有效描述数据集时，神经网络是有用的。
- en: Autoencoders are unsupervised learning algorithms that try to reproduce their
    inputs and in doing so reveal interesting structure about the data.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动编码器是一种无监督学习算法，试图重现其输入，并在这样做的同时揭示数据中的有趣结构。
- en: Images can easily be fed as input to a neural network by flattening and grayscaling.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过展平和灰度化，图像可以轻松地作为输入馈送到神经网络中。
