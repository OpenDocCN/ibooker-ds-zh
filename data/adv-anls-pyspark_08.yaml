- en: Chapter 8\. Estimating Financial Risk
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬å…«ç« ã€‚ä¼°è®¡é‡‘èé£é™©
- en: 'Is there a way to approximate how much you can expect to lose when investing
    in financial markets? This is the quantity that the financial statistic *value
    at risk* (VaR) seeks to measure. VaR is a simple measure of investment risk that
    tries to provide a reasonable estimate of the maximum probable loss in value of
    an investment portfolio over a particular time period. A VaR statistic depends
    on three parameters: a portfolio, a time period, and a probability. For example,
    a VaR value of $1 million with a 5% probability and two weeks indicates the belief
    that the portfolio stands only a 5% chance of losing more than $1 million over
    two weeks.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æŠ•èµ„é‡‘èå¸‚åœºæ—¶ï¼Œæ˜¯å¦æœ‰ä¸€ç§æ–¹æ³•å¯ä»¥è¿‘ä¼¼é¢„æœŸæŸå¤±çš„é‡ï¼Ÿè¿™å°±æ˜¯é‡‘èç»Ÿè®¡é‡*é£é™©ä»·å€¼*ï¼ˆVaRï¼‰è¯•å›¾è¡¡é‡çš„å†…å®¹ã€‚VaRæ˜¯ä¸€ç§ç®€å•çš„æŠ•èµ„é£é™©åº¦é‡ï¼Œè¯•å›¾æä¾›æŠ•èµ„ç»„åˆåœ¨ç‰¹å®šæ—¶é—´æ®µå†…å¯èƒ½çš„æœ€å¤§æŸå¤±çš„åˆç†ä¼°è®¡ã€‚VaRç»Ÿè®¡é‡ä¾èµ–äºä¸‰ä¸ªå‚æ•°ï¼šä¸€ä¸ªæŠ•èµ„ç»„åˆï¼Œä¸€ä¸ªæ—¶é—´æ®µå’Œä¸€ä¸ªæ¦‚ç‡ã€‚ä¾‹å¦‚ï¼ŒVaRå€¼ä¸º$1
    millionï¼Œæ¦‚ç‡ä¸º5%ï¼Œæ—¶é—´ä¸ºä¸¤å‘¨ï¼Œåˆ™è¡¨æ˜æŠ•èµ„ç»„åˆåªæœ‰5%çš„æ¦‚ç‡åœ¨ä¸¤å‘¨å†…æŸå¤±è¶…è¿‡$1 millionã€‚
- en: Since its development soon after the stock market crash of 1987, VaR has seen
    widespread use across financial services organizations. The statistic plays a
    vital role in the management of these institutions by helping to determine the
    risk characteristics of their strategies.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ª1987å¹´è‚¡å¸‚å´©ç›˜åä¸ä¹…ï¼ŒVaRåœ¨é‡‘èæœåŠ¡ç»„ç»‡ä¸­å¹¿æ³›ä½¿ç”¨ã€‚è¯¥ç»Ÿè®¡é‡é€šè¿‡å¸®åŠ©ç¡®å®šç­–ç•¥çš„é£é™©ç‰¹å¾ï¼Œåœ¨è¿™äº›æœºæ„çš„ç®¡ç†ä¸­å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚
- en: Many of the most sophisticated approaches to estimating this statistic rely
    on computationally intensive simulations of markets under random conditions. The
    technique behind these approaches, called the Monte Carlo simulation, involves
    posing thousands or millions of random market scenarios and observing how they
    tend to affect a portfolio. These scenarios are referred to as *trials*. PySpark
    is an ideal tool for Monte Carlo simulations. PySpark can leverage thousands of
    cores to run random trials and aggregate their results. As a general-purpose data
    transformation engine, it is also adept at performing the pre- and postprocessing
    steps that surround the simulations. It can transform raw financial data into
    the model parameters needed to carry out the simulations, as well as support ad
    hoc analysis of the results. Its simple programming model can drastically reduce
    development time compared to more traditional approaches that use HPC environments.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: è®¸å¤šä¼°è®¡è¿™ä¸€ç»Ÿè®¡é‡çš„æœ€å¤æ‚æ–¹æ³•ä¾èµ–äºåœ¨éšæœºæ¡ä»¶ä¸‹å¸‚åœºçš„è®¡ç®—å¯†é›†å‹æ¨¡æ‹Ÿã€‚è¿™äº›æ–¹æ³•èƒŒåçš„æŠ€æœ¯è¢«ç§°ä¸ºè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œæ¶‰åŠæå‡ºæ•°åƒç”šè‡³æ•°ç™¾ä¸‡ä¸ªéšæœºå¸‚åœºåœºæ™¯ï¼Œå¹¶è§‚å¯Ÿå®ƒä»¬å¦‚ä½•å½±å“æŠ•èµ„ç»„åˆã€‚è¿™äº›åœºæ™¯è¢«ç§°ä¸º*è¯•éªŒ*ã€‚PySparkæ˜¯è¿›è¡Œè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿçš„ç†æƒ³å·¥å…·ã€‚PySparkå¯ä»¥åˆ©ç”¨æ•°åƒä¸ªæ ¸å¿ƒè¿è¡Œéšæœºè¯•éªŒå¹¶æ±‡æ€»å®ƒä»¬çš„ç»“æœã€‚ä½œä¸ºé€šç”¨æ•°æ®è½¬æ¢å¼•æ“ï¼Œå®ƒè¿˜æ“…é•¿æ‰§è¡Œå›´ç»•æ¨¡æ‹Ÿçš„é¢„å¤„ç†å’Œåå¤„ç†æ­¥éª¤ã€‚å®ƒå¯ä»¥å°†åŸå§‹é‡‘èæ•°æ®è½¬æ¢ä¸ºæ‰§è¡Œæ¨¡æ‹Ÿæ‰€éœ€çš„æ¨¡å‹å‚æ•°ï¼Œå¹¶æ”¯æŒå¯¹ç»“æœçš„ä¸´æ—¶åˆ†æã€‚ä¸ä½¿ç”¨HPCç¯å¢ƒçš„æ›´ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå…¶ç®€å•çš„ç¼–ç¨‹æ¨¡å‹å¯ä»¥å¤§å¤§å‡å°‘å¼€å‘æ—¶é—´ã€‚
- en: Weâ€™ll also discuss how to compute a related statistic called *conditional value
    at risk* (CVaR), sometimes known as *expected shortfall*, which the Basel Committee
    on Banking Supervision proposed as a better risk measure than VaR a few years
    back. A CVaR statistic has the same three parameters as a VaR statistic but considers
    the expected average loss instead of providing a probable loss value. A CVaR of
    $5 million with a 5% *q-value* and two weeks indicates the belief that the average
    loss in the worst 5% of outcomes is $5 million.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜å°†è®¨è®ºå¦‚ä½•è®¡ç®—ä¸€ä¸ªç›¸å…³çš„ç»Ÿè®¡é‡ç§°ä¸º*æ¡ä»¶é£é™©ä»·å€¼*ï¼ˆCVaRï¼‰ï¼Œæœ‰æ—¶ä¹Ÿç§°ä¸º*é¢„æœŸæŸå¤±*ï¼Œè¿™æ˜¯å‡ å¹´å‰å·´å¡å°”é“¶è¡Œç›‘ç£å§”å‘˜ä¼šæå‡ºçš„æ¯”VaRæ›´å¥½çš„é£é™©åº¦é‡ã€‚CVaRç»Ÿè®¡é‡ä¸VaRç»Ÿè®¡é‡å…·æœ‰ç›¸åŒçš„ä¸‰ä¸ªå‚æ•°ï¼Œä½†è€ƒè™‘çš„æ˜¯é¢„æœŸå¹³å‡æŸå¤±ï¼Œè€Œä¸æ˜¯æä¾›å¯èƒ½æŸå¤±çš„å€¼ã€‚ä¾‹å¦‚ï¼ŒCVaRä¸º$5
    millionï¼Œæ¦‚ç‡ä¸º5%ï¼Œæ—¶é—´ä¸ºä¸¤å‘¨ï¼Œåˆ™è¡¨æ˜æœ€å·®çš„5%ç»“æœä¸­å¹³å‡æŸå¤±ä¸º$5 millionã€‚
- en: In the process of modeling VaR, weâ€™ll introduce a few different concepts, approaches,
    and packages. Weâ€™ll start by going over basic financial terminology that will
    be used throughout the chapter and then learn about the methods used to calculate
    VaR, including the Monte Carlo simulation technique. After that, we will download
    and prepare our dataset using PySpark and pandas. Weâ€™ll be using stock market
    data from late 2000s and early 2010s, including market indicators such as treasury
    bond prices along with stock values of various companies. Once done with preprocessing,
    we will create a linear regression model to calculate change in value for stocks
    over a time period. Weâ€™ll also come up with a way to generate sample market indicator
    values for use in trials when performing a Monte Carlo simulation. Finally, weâ€™ll
    perform the simulation using PySpark and go over our results.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å»ºæ¨¡VaRçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ä¸€äº›ä¸åŒçš„æ¦‚å¿µã€æ–¹æ³•å’Œå·¥å…·åŒ…ã€‚æˆ‘ä»¬å°†ä»ä»‹ç»è´¯ç©¿æ•´ç« ä½¿ç”¨çš„åŸºæœ¬é‡‘èæœ¯è¯­å¼€å§‹ï¼Œç„¶åå­¦ä¹ è®¡ç®—VaRçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬è’™ç‰¹å¡æ´›æ¨¡æ‹ŸæŠ€æœ¯ã€‚ä¹‹åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨PySparkå’Œpandasä¸‹è½½å’Œå‡†å¤‡æˆ‘ä»¬çš„æ•°æ®é›†ã€‚æˆ‘ä»¬å°†ä½¿ç”¨2000å¹´ä»£æœ«å’Œ2010å¹´ä»£åˆçš„è‚¡å¸‚æ•°æ®ï¼ŒåŒ…æ‹¬å›½å€ºä»·æ ¼å’Œå„ç§å…¬å¸çš„è‚¡ç¥¨ä»·å€¼ç­‰å¸‚åœºæŒ‡æ ‡ã€‚åœ¨é¢„å¤„ç†å®Œæˆåï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ï¼Œä»¥è®¡ç®—è‚¡ç¥¨åœ¨ä¸€æ®µæ—¶é—´å†…çš„ä»·å€¼å˜åŒ–ã€‚æˆ‘ä»¬è¿˜å°†æƒ³å‡ºä¸€ç§æ–¹æ³•ï¼Œåœ¨æ‰§è¡Œè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿæ—¶ç”Ÿæˆæ ·æœ¬å¸‚åœºæŒ‡æ ‡å€¼ã€‚æœ€åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨PySparkæ‰§è¡Œæ¨¡æ‹Ÿï¼Œå¹¶æ£€æŸ¥æˆ‘ä»¬çš„ç»“æœã€‚
- en: Letâ€™s start by defining basic financial terms that we will use.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¼€å§‹å®šä¹‰æˆ‘ä»¬å°†ä½¿ç”¨çš„åŸºæœ¬é‡‘èæœ¯è¯­ã€‚
- en: Terminology
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æœ¯è¯­
- en: 'This chapter makes use of a set of terms specific to the finance domain:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« ä½¿ç”¨äº†é‡‘èé¢†åŸŸç‰¹å®šæœ¯è¯­çš„é›†åˆï¼š
- en: Instrument
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å·¥å…·
- en: A tradable asset, such as a bond, loan, option, or stock investment. At any
    particular time, an instrument is considered to have a *value*, which is the price
    for which it could be sold.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å¯äº¤æ˜“èµ„äº§ï¼Œä¾‹å¦‚å€ºåˆ¸ã€è´·æ¬¾ã€æœŸæƒæˆ–è‚¡ç¥¨æŠ•èµ„ã€‚ä»»ä½•ç‰¹å®šæ—¶é—´ï¼Œå·¥å…·éƒ½è¢«è®¤ä¸ºå…·æœ‰*ä»·å€¼*ï¼Œå³å…¶å¯å”®å‡ºä»·æ ¼ã€‚
- en: Portfolio
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ•èµ„ç»„åˆ
- en: A collection of instruments owned by a financial institution.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: é‡‘èæœºæ„æ‹¥æœ‰çš„ä¸€ç³»åˆ—å·¥å…·ã€‚
- en: Return
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ”¶ç›Š
- en: The change in an instrument or portfolioâ€™s value over a time period.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ®µæ—¶é—´å†…å·¥å…·æˆ–æŠ•èµ„ç»„åˆä»·å€¼çš„å˜åŒ–ã€‚
- en: Loss
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: æŸå¤±
- en: A negative return.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: è´Ÿå›æŠ¥ã€‚
- en: Index
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æŒ‡æ•°
- en: An imaginary portfolio of instruments. For example, the NASDAQ Composite Index
    includes about 3,000 stocks and similar instruments for major US and international
    companies.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§è™šæ„çš„å·¥å…·ç»„åˆã€‚ä¾‹å¦‚ï¼Œçº³æ–¯è¾¾å…‹ç»¼åˆæŒ‡æ•°åŒ…æ‹¬çº¦3000åªä¸»è¦ç¾å›½å’Œå›½é™…å…¬å¸çš„è‚¡ç¥¨åŠç±»ä¼¼å·¥å…·ã€‚
- en: Market factor
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å¸‚åœºå› ç´ 
- en: A value that can be used as an indicator of macro aspects of the financial climate
    at a particular timeâ€”for example, the value of an index, the gross domestic product
    of the United States, or the exchange rate between the dollar and the euro. We
    will often refer to market factors as just *factors*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨ä½œç‰¹å®šæ—¶é—´é‡‘èç¯å¢ƒå®è§‚æ–¹é¢æŒ‡æ ‡çš„å€¼â€”â€”ä¾‹å¦‚ï¼Œä¸€ä¸ªæŒ‡æ•°çš„ä»·å€¼ï¼Œç¾å›½çš„å›½å†…ç”Ÿäº§æ€»å€¼ï¼Œæˆ–ç¾å…ƒä¸æ¬§å…ƒä¹‹é—´çš„æ±‡ç‡ã€‚æˆ‘ä»¬é€šå¸¸å°†å¸‚åœºå› ç´ ç®€ç§°ä¸º*å› ç´ *ã€‚
- en: Methods for Calculating VaR
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®¡ç®—VaRçš„æ–¹æ³•
- en: So far, our definition of VaR has been fairly open ended. Estimating this statistic
    requires proposing a model for how a portfolio functions and choosing the probability
    distribution its returns are likely to take. Institutions employ a variety of
    approaches for calculating VaR, all of which tend to fall under a few general
    methods.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å¯¹é£é™©ä»·å€¼ï¼ˆVaRï¼‰çš„å®šä¹‰ä¸€ç›´æ¯”è¾ƒå¼€æ”¾ã€‚ä¼°è®¡è¿™ä¸€ç»Ÿè®¡é‡éœ€è¦æå‡ºä¸€ä¸ªå…³äºæŠ•èµ„ç»„åˆè¿ä½œæ–¹å¼çš„æ¨¡å‹ï¼Œå¹¶é€‰æ‹©å…¶æ”¶ç›Šå¯èƒ½æœä»çš„æ¦‚ç‡åˆ†å¸ƒã€‚æœºæ„é‡‡ç”¨å„ç§æ–¹æ³•æ¥è®¡ç®—VaRï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å¯ä»¥å½’çº³ä¸ºå‡ ç§ä¸€èˆ¬æ–¹æ³•ä¹‹ä¸‹ã€‚
- en: Variance-Covariance
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ–¹å·®-åæ–¹å·®
- en: '*Variance-covariance* is by far the simplest and least computationally intensive
    method. Its model assumes that the return of each instrument is normally distributed,
    which allows deriving an estimate analytically.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ–¹å·®-åæ–¹å·®*æ–¹æ³•æ˜¯æœ€ç®€å•ä¸”è®¡ç®—å¼ºåº¦æœ€ä½çš„æ–¹æ³•ã€‚å…¶æ¨¡å‹å‡è®¾æ¯ç§å·¥å…·çš„æ”¶ç›Šæœä»æ­£æ€åˆ†å¸ƒï¼Œè¿™ä½¿å¾—å¯ä»¥é€šè¿‡è§£ææ¨å¯¼å‡ºä¸€ä¸ªä¼°è®¡å€¼ã€‚'
- en: Historical Simulation
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å†å²æ¨¡æ‹Ÿ
- en: '*Historical simulation* extrapolates risk from historical data by using its
    distribution directly instead of relying on summary statistics. For example, to
    determine a 95% VaR for a portfolio, we might look at that portfolioâ€™s performance
    for the last 100 days and estimate the statistic as its value on the fifth-worst
    day. A drawback of this method is that historical data can be limited and fails
    to include what-ifs. For example, what if the history we have for the instruments
    in our portfolio lacks market collapses, and we want to model what happens to
    our portfolio in these situations? Techniques exist for making historical simulation
    robust to these issues, such as introducing â€œshocksâ€ into the data, but we wonâ€™t
    cover them here.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*å†å²æ¨¡æ‹Ÿ*é€šè¿‡ç›´æ¥ä½¿ç”¨å…¶åˆ†å¸ƒè€Œä¸ä¾èµ–äºæ‘˜è¦ç»Ÿè®¡æ•°æ®ï¼Œä»å†å²æ•°æ®ä¸­æ¨æ–­é£é™©ã€‚ä¾‹å¦‚ï¼Œä¸ºäº†ç¡®å®šä¸€ä¸ªæŠ•èµ„ç»„åˆçš„95% VaRï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæŸ¥çœ‹è¯¥æŠ•èµ„ç»„åˆè¿‡å»100å¤©çš„è¡¨ç°ï¼Œå¹¶å°†è¯¥ç»Ÿè®¡æ•°æ®ä¼°è®¡ä¸ºç¬¬äº”å·®çš„ä¸€å¤©çš„å€¼ã€‚è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯ï¼Œå†å²æ•°æ®å¯èƒ½æœ‰é™ï¼Œå¹¶ä¸”æœªåŒ…å«å‡è®¾æƒ…å†µã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æŠ•èµ„ç»„åˆä¸­çš„å·¥å…·çš„å†å²ç¼ºä¹å¸‚åœºå´©ç›˜ï¼Œæˆ‘ä»¬æƒ³è¦æ¨¡æ‹Ÿåœ¨è¿™äº›æƒ…å†µä¸‹æˆ‘ä»¬çš„æŠ•èµ„ç»„åˆä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿå­˜åœ¨æŠ€æœ¯å¯ä»¥ä½¿å†å²æ¨¡æ‹Ÿèƒ½å¤Ÿåº”å¯¹è¿™äº›é—®é¢˜ï¼Œä¾‹å¦‚å‘æ•°æ®å¼•å…¥â€œå†²å‡»â€ï¼Œä½†æˆ‘ä»¬åœ¨è¿™é‡Œä¸ä¼šè¯¦ç»†ä»‹ç»è¿™äº›æŠ€æœ¯ã€‚'
- en: Monte Carlo Simulation
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ
- en: '*Monte Carlo simulation*, which the rest of this chapter will focus on, tries
    to weaken the assumptions in the previous methods by simulating the portfolio
    under random conditions. When we canâ€™t derive a closed form for a probability
    distribution analytically, we can often estimate its probability density function
    by repeatedly sampling simpler random variables that it depends on and seeing
    how it plays out in aggregate. In its most general form, this method:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿ*ï¼Œæœ¬ç« çš„å…¶ä½™éƒ¨åˆ†å°†é‡ç‚¹ä»‹ç»ï¼Œè¯•å›¾é€šè¿‡åœ¨éšæœºæ¡ä»¶ä¸‹æ¨¡æ‹ŸæŠ•èµ„ç»„åˆæ¥å‡å¼±å‰è¿°æ–¹æ³•ä¸­çš„å‡è®¾ã€‚å½“æˆ‘ä»¬æ— æ³•ä»è§£æä¸Šå¯¼å‡ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„é—­åˆå½¢å¼æ—¶ï¼Œæˆ‘ä»¬é€šå¸¸å¯ä»¥é€šè¿‡é‡å¤æŠ½æ ·å®ƒæ‰€ä¾èµ–çš„æ›´ç®€å•çš„éšæœºå˜é‡æ¥ä¼°è®¡å…¶æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œå¹¶è§‚å¯Ÿå…¶åœ¨æ€»ä½“ä¸Šçš„è¡¨ç°ã€‚åœ¨å…¶æœ€ä¸€èˆ¬çš„å½¢å¼ä¸­ï¼Œè¯¥æ–¹æ³•ï¼š'
- en: Defines a relationship between market conditions and each instrumentâ€™s returns.
    This relationship takes the form of a model fitted to historical data.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç¡®å®šå¸‚åœºæ¡ä»¶ä¸æ¯ç§å·¥å…·æ”¶ç›Šä¹‹é—´çš„å…³ç³»ã€‚è¯¥å…³ç³»é‡‡ç”¨æ ¹æ®å†å²æ•°æ®æ‹Ÿåˆçš„æ¨¡å‹å½¢å¼ã€‚
- en: Defines distributions for the market conditions that are straightforward to
    sample from. These distributions are fitted to historical data.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºå¸‚åœºæ¡ä»¶å®šä¹‰åˆ†å¸ƒï¼Œå¯ä»¥æ–¹ä¾¿åœ°ä»ä¸­è¿›è¡ŒæŠ½æ ·ã€‚è¿™äº›åˆ†å¸ƒæ˜¯æ ¹æ®å†å²æ•°æ®æ‹Ÿåˆçš„ã€‚
- en: Poses trials consisting of random market conditions.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æå‡ºç”±éšæœºå¸‚åœºæ¡ä»¶ç»„æˆçš„è¯•éªŒã€‚
- en: Calculates the total portfolio loss for each trial and uses these losses to
    define an empirical distribution over losses. This means that if we run 100 trials
    and want to estimate the 5% VaR, we would choose it as the loss from the trial
    with the fifth-greatest loss. To calculate the 5% CVaR, we would find the average
    loss over the five worst trials.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ¯æ¬¡è¯•éªŒçš„æ€»æŠ•èµ„ç»„åˆæŸå¤±ï¼Œå¹¶ä½¿ç”¨è¿™äº›æŸå¤±æ¥å®šä¹‰æŸå¤±çš„ç»éªŒåˆ†å¸ƒã€‚è¿™æ„å‘³ç€å¦‚æœæˆ‘ä»¬è¿›è¡Œ100æ¬¡è¯•éªŒï¼Œå¹¶å¸Œæœ›ä¼°è®¡5%çš„VaRï¼Œåˆ™ä¼šé€‰æ‹©ç¬¬äº”å¤§æŸå¤±çš„è¯•éªŒã€‚è¦è®¡ç®—5%çš„CVaRï¼Œåˆ™ä¼šæ‰¾åˆ°äº”ä¸ªæœ€å·®è¯•éªŒçš„å¹³å‡æŸå¤±ã€‚
- en: Of course, the Monte Carlo method isnâ€™t perfect either. It relies on models
    for generating trial conditions and for inferring instrument performance, and
    these models must make simplifying assumptions. If these assumptions donâ€™t correspond
    to reality, then neither will the final probability distribution that comes out.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å½“ç„¶ï¼Œè’™ç‰¹å¡æ´›æ–¹æ³•ä¹Ÿå¹¶éå®Œç¾æ— ç¼ºã€‚å®ƒä¾èµ–äºç”¨äºç”Ÿæˆè¯•éªŒæ¡ä»¶å’Œæ¨æ–­ä»ªå™¨æ€§èƒ½çš„æ¨¡å‹ï¼Œè€Œè¿™äº›æ¨¡å‹å¿…é¡»åšå‡ºç®€åŒ–çš„å‡è®¾ã€‚å¦‚æœè¿™äº›å‡è®¾ä¸ç°å®ä¸ç¬¦ï¼Œé‚£ä¹ˆæœ€ç»ˆå¾—å‡ºçš„æ¦‚ç‡åˆ†å¸ƒä¹Ÿå°†ä¸ç¬¦åˆå®é™…æƒ…å†µã€‚
- en: Our Model
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„æ¨¡å‹
- en: 'A Monte Carlo risk model typically phrases each instrumentâ€™s return in terms
    of a set of market factors. Common market factors might be the value of indexes
    like the S&P 500, the US GDP, or currency exchange rates. We then need a model
    that predicts the return of each instrument based on these market conditions.
    In our simulation, weâ€™ll use a simple linear model. By our previous definition
    of return, a *factor return* is a change in the value of a market factor over
    a particular time. For example, if the value of the S&P 500 moves from 2,000 to
    2,100 over a time interval, its return would be 100\. Weâ€™ll derive a set of features
    from simple transformations of the factor returns. That is, the market factor
    vector *m[t]* for a trial *t* is transformed by some function Ï• to produce a feature
    vector of possible different length *f[t]*:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è’™ç‰¹å¡æ´›é£é™©æ¨¡å‹é€šå¸¸å°†æ¯ä¸ªå·¥å…·çš„å›æŠ¥è¡¨è¿°ä¸ºä¸€ç»„å¸‚åœºå› ç´ ã€‚å¸¸è§çš„å¸‚åœºå› ç´ å¯èƒ½æ˜¯è¯¸å¦‚æ ‡å‡†æ™®å°”500æŒ‡æ•°ã€ç¾å›½GDPæˆ–è´§å¸æ±‡ç‡ç­‰çš„æŒ‡æ•°å€¼ã€‚ç„¶åï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ¨¡å‹ï¼Œæ ¹æ®è¿™äº›å¸‚åœºæ¡ä»¶é¢„æµ‹æ¯ä¸ªå·¥å…·çš„å›æŠ¥ã€‚åœ¨æˆ‘ä»¬çš„æ¨¡æ‹Ÿä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä¸€ä¸ªç®€å•çš„çº¿æ€§æ¨¡å‹ã€‚æŒ‰ç…§æˆ‘ä»¬ä¹‹å‰å¯¹å›æŠ¥çš„å®šä¹‰ï¼Œ*å› å­å›æŠ¥*æ˜¯å¸‚åœºå› ç´ åœ¨ç‰¹å®šæ—¶é—´å†…çš„ä»·å€¼å˜åŒ–ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ ‡å‡†æ™®å°”500æŒ‡æ•°çš„å€¼ä»2000å˜åˆ°2100ï¼Œåœ¨ä¸€ä¸ªæ—¶é—´é—´éš”å†…ï¼Œå…¶å›æŠ¥å°†æ˜¯100ã€‚æˆ‘ä»¬å°†ä»å› å­å›æŠ¥çš„ç®€å•è½¬æ¢ä¸­æ´¾ç”Ÿä¸€ç»„ç‰¹å¾ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äºè¯•éªŒ*t*ï¼Œå¸‚åœºå› ç´ å‘é‡*m[t]*é€šè¿‡æŸäº›å‡½æ•°Ï•è½¬æ¢ä¸ºå¯èƒ½å…·æœ‰ä¸åŒé•¿åº¦*f[t]*çš„ç‰¹å¾å‘é‡ï¼š
- en: '*f[t] = Ï•(m[t])*'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f[t] = Ï•(m[t])*'
- en: 'For each instrument, weâ€™ll train a model that assigns a weight to each feature.
    To calculate *r[it]*, the return of instrument *i* in trial *t*, we use *c[i]*,
    the intercept term for the instrument; *w[ij]*, the regression weight for feature
    *j* on instrument *i*; and *f[tj]*, the randomly generated value of feature *j*
    in trial *t*:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªå·¥å…·ï¼Œæˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œä¸ºæ¯ä¸ªç‰¹å¾åˆ†é…ä¸€ä¸ªæƒé‡ã€‚ä¸ºäº†è®¡ç®—è¯•éªŒ*t*ä¸­å·¥å…·*i*çš„å›æŠ¥*r[it]*ï¼Œæˆ‘ä»¬ä½¿ç”¨*c[i]*ï¼Œå·¥å…·*i*çš„æˆªè·é¡¹ï¼›*w[ij]*ï¼Œå·¥å…·*i*åœ¨ç‰¹å¾*j*ä¸Šçš„å›å½’æƒé‡ï¼›ä»¥åŠ*f[tj]*ï¼Œè¯•éªŒ*t*ä¸­ç‰¹å¾*j*çš„éšæœºç”Ÿæˆå€¼ï¼š
- en: <math alttext="r Subscript i t Baseline equals c Subscript i Baseline plus sigma-summation
    Underscript j equals 1 Overscript StartAbsoluteValue w Subscript i Baseline EndAbsoluteValue
    Endscripts w Subscript i j Baseline asterisk f Subscript t j" display="block"><mrow><msub><mi>r</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub> <mo>=</mo> <msub><mi>c</mi> <mi>i</mi></msub>
    <mo>+</mo> <munderover><mo>âˆ‘</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow>
    <mrow><mrow><mo>|</mo></mrow><msub><mi>w</mi> <mi>i</mi></msub> <mrow><mo>|</mo></mrow></mrow></munderover>
    <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub> <mo>*</mo> <msub><mi>f</mi>
    <mrow><mi>t</mi><mi>j</mi></mrow></msub></mrow></math>
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="r Subscript i t Baseline equals c Subscript i Baseline plus sigma-summation
    Underscript j equals 1 Overscript StartAbsoluteValue w Subscript i Baseline EndAbsoluteValue
    Endscripts w Subscript i j Baseline asterisk f Subscript t j" display="block"><mrow><msub><mi>r</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub> <mo>=</mo> <msub><mi>c</mi> <mi>i</mi></msub>
    <mo>+</mo> <munderover><mo>âˆ‘</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow>
    <mrow><mrow><mo>|</mo></mrow><msub><mi>w</mi> <mi>i</mi></msub> <mrow><mo>|</mo></mrow></mrow></munderover>
    <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub> <mo>*</mo> <msub><mi>f</mi>
    <mrow><mi>t</mi><mi>j</mi></mrow></msub></mrow></math>
- en: This means that the return of each instrument is calculated as the sum of the
    returns of the market factor features multiplied by their weights for that instrument.
    We can fit the linear model for each instrument using historical data (also known
    as doing linear regression). If the horizon of the VaR calculation is two weeks,
    the regression treats every (overlapping) two-week interval in history as a labeled
    point.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€æ¯ä¸ªå·¥å…·çš„å›æŠ¥è¢«è®¡ç®—ä¸ºå¸‚åœºå› ç´ ç‰¹å¾çš„å›æŠ¥ä¹˜ä»¥å®ƒä»¬åœ¨è¯¥å·¥å…·ä¸Šçš„æƒé‡çš„æ€»å’Œã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å†å²æ•°æ®ï¼ˆä¹Ÿç§°ä¸ºè¿›è¡Œçº¿æ€§å›å½’ï¼‰ä¸ºæ¯ä¸ªå·¥å…·æ‹Ÿåˆçº¿æ€§æ¨¡å‹ã€‚å¦‚æœVaRè®¡ç®—çš„è§†é‡æ˜¯ä¸¤å‘¨ï¼Œåˆ™å›å½’å°†å†å²ä¸Šçš„æ¯ä¸ªï¼ˆé‡å çš„ï¼‰ä¸¤å‘¨é—´éš”è§†ä¸ºä¸€ä¸ªæ ‡è®°ç‚¹ã€‚
- en: 'Itâ€™s also worth mentioning that we could have chosen a more complicated model.
    For example, the model need not be linear: it could be a regression tree or explicitly
    incorporate domain-specific knowledge.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å€¼å¾—ä¸€æçš„æ˜¯ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€‰æ‹©æ›´å¤æ‚çš„æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œæ¨¡å‹ä¸ä¸€å®šæ˜¯çº¿æ€§çš„ï¼šå®ƒå¯ä»¥æ˜¯å›å½’æ ‘æˆ–æ˜ç¡®åœ°ç»“åˆé¢†åŸŸç‰¹å®šçŸ¥è¯†ã€‚
- en: 'Now that we have our model for calculating instrument losses from market factors,
    we need a process for simulating the behavior of market factors. A simple assumption
    is that each market factor return follows a normal distribution. To capture the
    fact that market factors are often correlatedâ€”when the NASDAQ is down, the Dow
    is likely to be suffering as wellâ€”we can use a multivariate normal distribution
    with a nondiagonal covariance matrix:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰äº†è®¡ç®—å¸‚åœºå› ç´ é€ æˆçš„å·¥å…·æŸå¤±çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ¨¡æ‹Ÿå¸‚åœºå› ç´ è¡Œä¸ºçš„è¿‡ç¨‹ã€‚ä¸€ä¸ªç®€å•çš„å‡è®¾æ˜¯æ¯ä¸ªå¸‚åœºå› ç´ å›æŠ¥éƒ½éµå¾ªæ­£æ€åˆ†å¸ƒã€‚ä¸ºäº†æ•æ‰å¸‚åœºå› ç´ é€šå¸¸ç›¸å…³çš„äº‹å®â€”â€”å½“çº³æ–¯è¾¾å…‹ä¸‹è·Œæ—¶ï¼Œé“ç¼æ–¯ä¹Ÿå¯èƒ½åœ¨é­å—æŸå¤±â€”â€”æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å…·æœ‰éå¯¹è§’åæ–¹å·®çŸ©é˜µçš„å¤šå…ƒæ­£æ€åˆ†å¸ƒï¼š
- en: <math alttext="m Subscript t Baseline tilde script upper N left-parenthesis
    mu comma normal upper Sigma right-parenthesis" display="block"><mrow><msub><mi>m</mi>
    <mi>t</mi></msub> <mo>âˆ¼</mo> <mi>ğ’©</mi> <mrow><mo>(</mo> <mi>Î¼</mi> <mo>,</mo>
    <mi>Î£</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="m Subscript t Baseline tilde script upper N left-parenthesis
    mu comma normal upper Sigma right-parenthesis" display="block"><mrow><msub><mi>m</mi>
    <mi>t</mi></msub> <mo>âˆ¼</mo> <mi>ğ’©</mi> <mrow><mo>(</mo> <mi>Î¼</mi> <mo>,</mo>
    <mi>Î£</mi> <mo>)</mo></mrow></mrow></math>
- en: where Î¼ is a vector of the empirical means of the returns of the factors and
    Î£ is the empirical covariance matrix of the returns of the factors.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ï¼ŒÎ¼æ˜¯å› ç´ å›æŠ¥çš„ç»éªŒå‡å€¼å‘é‡ï¼ŒÎ£æ˜¯å› ç´ å›æŠ¥çš„ç»éªŒåæ–¹å·®çŸ©é˜µã€‚
- en: As before, we could have chosen a more complicated method of simulating the
    market or assumed a different type of distribution for each market factor, perhaps
    using distributions with fatter tails.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å’Œä»¥å‰ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©æ›´å¤æ‚çš„æ¨¡æ‹Ÿå¸‚åœºçš„æ–¹æ³•ï¼Œæˆ–è€…å‡è®¾æ¯ä¸ªå¸‚åœºå› ç´ çš„ä¸åŒç±»å‹åˆ†å¸ƒï¼Œä¹Ÿè®¸ä½¿ç”¨å°¾éƒ¨æ›´åšçš„åˆ†å¸ƒã€‚
- en: Getting the Data
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è·å–æ•°æ®
- en: 'Download the historical stock price dataset and place it in a *data/stocks/*
    directory:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½å†å²è‚¡ä»·æ•°æ®é›†å¹¶å°†å…¶æ”¾ç½®åœ¨*data/stocks/*ç›®å½•ä¸­ï¼š
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It can be difficult to find large volumes of nicely formatted historical price
    data. The dataset used in this chapter was downloaded from Yahoo!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰¾åˆ°å¤§é‡æ ¼å¼è‰¯å¥½çš„å†å²ä»·æ ¼æ•°æ®å¯èƒ½å¾ˆå›°éš¾ã€‚æœ¬ç« ä½¿ç”¨çš„æ•°æ®é›†æ˜¯ä»Yahoo!ä¸‹è½½çš„ã€‚
- en: 'We also need historical data for risk factors. For our factors, weâ€™ll use the
    values of:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜éœ€è¦é£é™©å› ç´ çš„å†å²æ•°æ®ã€‚å¯¹äºæˆ‘ä»¬çš„å› ç´ ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ä»¥ä¸‹å€¼ï¼š
- en: 'iShares 20 Plus Year Treasury Bond ETF (NASDAQ: TLT)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: iShares 20 Plus Year Treasury Bond ETF (çº³æ–¯è¾¾å…‹ï¼šTLT)
- en: 'iShares US Credit Bond ETF (NYSEArca: CRED)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'iShares ç¾å›½ä¿¡ç”¨å€ºåˆ¸ETFï¼ˆNYSEArca: CREDï¼‰'
- en: 'SPDR Gold Trust (NYSEArca: GLD)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'é»„é‡‘ETFä¿¡æ‰˜åŸºé‡‘ï¼ˆNYSEArca: GLDï¼‰'
- en: 'Download and place the factors data:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½å¹¶æ”¾ç½®å› å­æ•°æ®ï¼š
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Letâ€™s have a look at one of our factors:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬çœ‹çœ‹å…¶ä¸­ä¸€ä¸ªå› å­ï¼š
- en: '[PRE2]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: With our dataset downloaded, we will now prepare it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸‹è½½äº†æˆ‘ä»¬çš„æ•°æ®é›†åï¼Œæˆ‘ä»¬ç°åœ¨å°†å¯¹å…¶è¿›è¡Œå‡†å¤‡ã€‚
- en: Preparing the Data
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‡†å¤‡æ•°æ®
- en: 'The first few rows of the Yahoo!-formatted data for GOOGL look like this:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: é›…è™æ ¼å¼åŒ–æ•°æ®ä¸­ GOOGL çš„å‰å‡ è¡Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Letâ€™s fire up the PySpark shell:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å¯åŠ¨ PySpark shellï¼š
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Read in the instruments dataset as a DataFrame:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸º DataFrame è¯»å–å·¥å…·æ•°æ®é›†ï¼š
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The DataFrame is missing the instrument symbol. Letâ€™s add that using the input
    filenames corresponding to each row:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame ç¼ºå°‘å·¥å…·ç¬¦å·ã€‚ è®©æˆ‘ä»¬ä½¿ç”¨å¯¹åº”æ¯ä¸€è¡Œçš„è¾“å…¥æ–‡ä»¶åæ·»åŠ å®ƒï¼š
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We will read in and process the factors dataset in a similar manner:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä»¥ç±»ä¼¼çš„æ–¹å¼è¯»å–å¹¶å¤„ç†å› å­æ•°æ®é›†ï¼š
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We filter out instruments with less than five years of history:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿‡æ»¤æ‰å†å²ä¸è¶³äº”å¹´çš„å·¥å…·ï¼š
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Different types of instruments may trade on different days, or the data may
    have missing values for other reasons, so it is important to make sure that our
    different histories align. First, we need to trim all of our time series to the
    same period in time. To do that, weâ€™ll first convert the `Date` columnâ€™s type
    from string to date:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åŒç±»å‹çš„å·¥å…·å¯èƒ½åœ¨ä¸åŒçš„æ—¥æœŸäº¤æ˜“ï¼Œæˆ–è€…æ•°æ®å¯èƒ½ç”±äºå…¶ä»–åŸå› ç¼ºå°‘å€¼ï¼Œå› æ­¤ç¡®ä¿æˆ‘ä»¬ä¸åŒå†å²è®°å½•å¯¹é½éå¸¸é‡è¦ã€‚ é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰æ—¶é—´åºåˆ—ä¿®å‰ªåˆ°åŒä¸€æ—¶é—´æ®µå†…ã€‚
    ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆå°†`Date`åˆ—çš„ç±»å‹ä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¥æœŸï¼š
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Letâ€™s trim the time periods of instruments to align:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä¿®å‰ªå·¥å…·çš„æ—¶é—´æ®µä»¥å¯¹é½ï¼š
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will convert the `Date` columnâ€™s type and trim the time period in our factors
    DataFrame too:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†è½¬æ¢`Date`åˆ—çš„ç±»å‹ï¼Œå¹¶åœ¨å› å­DataFrameä¸­ä¹Ÿä¿®å‰ªæ—¶é—´æ®µï¼š
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The histories of a few thousand instruments and three factors are small enough
    to read and process locally. This remains the case even for larger simulations
    with hundreds of thousands of instruments and thousands of factors. Even though
    we have used PySpark for preprocessing our data so far, the need arises for a
    distributed system such as PySpark when weâ€™re actually running the simulations,
    which can require massive amounts of computation on each instrument. We can convert
    our PySpark DataFrame into a pandas DataFrame and still continue working with
    it easily by performing in-memory operations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ åƒä¸ªå·¥å…·å’Œä¸‰ä¸ªå› å­çš„å†å²æ•°æ®è¶³å¤Ÿå°ï¼Œå¯ä»¥åœ¨æœ¬åœ°è¯»å–å’Œå¤„ç†ã€‚ å³ä½¿åœ¨å…·æœ‰æ•°åä¸‡ä¸ªå·¥å…·å’Œæ•°åƒä¸ªå› å­çš„æ›´å¤§æ¨¡æ‹Ÿä¸­ï¼Œæƒ…å†µä¹Ÿæ˜¯å¦‚æ­¤ã€‚ å°½ç®¡åˆ°ç›®å‰ä¸ºæ­¢æˆ‘ä»¬ä½¿ç”¨ PySpark
    å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œä½†åœ¨å®é™…è¿è¡Œæ¨¡æ‹Ÿæ—¶ï¼Œä¾‹å¦‚å¯ä»¥éœ€è¦å¤§é‡è®¡ç®—çš„åˆ†å¸ƒå¼ç³»ç»Ÿï¼ˆå¦‚ PySparkï¼‰ã€‚ æˆ‘ä»¬å¯ä»¥å°† PySpark DataFrame è½¬æ¢ä¸º pandas
    DataFrameï¼Œå¹¶ç»§ç»­é€šè¿‡æ‰§è¡Œå†…å­˜æ“ä½œè½»æ¾åœ°å¤„ç†å®ƒã€‚
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We will use these pandas DataFrames in the next section as we try to fit a linear
    regression model to predict instrument returns based on factor returns.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€èŠ‚ä¸­ä½¿ç”¨è¿™äº› pandas DataFrameï¼Œå°è¯•å°†çº¿æ€§å›å½’æ¨¡å‹æ‹Ÿåˆåˆ°åŸºäºå› å­å›æŠ¥çš„å·¥å…·å›æŠ¥ä¸Šã€‚
- en: Determining the Factor Weights
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¡®å®šå› å­æƒé‡
- en: 'Recall that VaR deals with losses *over a particular time horizon*. We are
    not concerned with the absolute prices of instruments, but with how those prices
    move over a given length of time. In our calculation, we will set that length
    to two weeks. The following function makes use of the pandas `rolling` method
    to transform a time series of prices into an overlapping sequence of price movements
    over two-week intervals. Note that we use 10 instead of 14 to define the window
    because financial data does not include weekends:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å›é¡¾VaRå¤„ç†*ç‰¹å®šæ—¶é—´æ®µå†…*çš„æŸå¤±ã€‚ æˆ‘ä»¬å…³å¿ƒçš„ä¸æ˜¯å·¥å…·çš„ç»å¯¹ä»·æ ¼ï¼Œè€Œæ˜¯è¿™äº›ä»·æ ¼åœ¨ç»™å®šæ—¶é—´é•¿åº¦å†…çš„å˜åŠ¨æƒ…å†µã€‚ åœ¨æˆ‘ä»¬çš„è®¡ç®—ä¸­ï¼Œæˆ‘ä»¬å°†è¯¥é•¿åº¦è®¾å®šä¸ºä¸¤å‘¨ã€‚
    ä»¥ä¸‹åŠŸèƒ½åˆ©ç”¨ pandas çš„`rolling`æ–¹æ³•ï¼Œå°†ä»·æ ¼æ—¶é—´åºåˆ—è½¬æ¢ä¸ºé‡å çš„ä¸¤å‘¨ä»·æ ¼å˜åŠ¨åºåˆ—ã€‚ è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨10è€Œä¸æ˜¯14æ¥å®šä¹‰çª—å£ï¼Œå› ä¸ºé‡‘èæ•°æ®ä¸åŒ…æ‹¬å‘¨æœ«ï¼š
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: With these return histories in hand, we can turn to our goal of training predictive
    models for the instrument returns. For each instrument, we want a model that predicts
    its two-week return based on the returns of the factors over the same time period.
    For simplicity, we will use a linear regression model.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰‹å¤´æœ‰äº†è¿™äº›å›æŠ¥å†å²æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç€æ‰‹è®­ç»ƒç”¨äºå·¥å…·å›æŠ¥é¢„æµ‹çš„é¢„æµ‹æ¨¡å‹ã€‚ å¯¹äºæ¯ä¸ªå·¥å…·ï¼Œæˆ‘ä»¬å¸Œæœ›æœ‰ä¸€ä¸ªæ¨¡å‹ï¼Œæ ¹æ®ç›¸åŒæ—¶é—´æ®µå†…å› å­çš„å›æŠ¥æ¥é¢„æµ‹å…¶ä¸¤å‘¨å›æŠ¥ã€‚
    ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹ã€‚
- en: 'To model the fact that instrument returns may be nonlinear functions of the
    factor returns, we can include some additional features in our model that we derive
    from nonlinear transformations of the factor returns. As an example, we will add
    one additional feature for each factor return: square. Our model is still a linear
    model in the sense that the response variable is a linear function of the features.
    Some of the features just happen to be determined by nonlinear functions of the
    factor returns. Keep in mind that this particular feature transformation is meant
    to demonstrate some of the options availableâ€”it shouldnâ€™t be perceived as a state-of-the-art
    practice in predictive financial modeling.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å»ºæ¨¡å·¥å…·å›æŠ¥å¯èƒ½æ˜¯å› å­å›æŠ¥çš„éçº¿æ€§å‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æ¨¡å‹ä¸­åŒ…å«ä¸€äº›é¢å¤–çš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾æ˜¯ä»å› å­å›æŠ¥çš„éçº¿æ€§å˜æ¢ä¸­å¯¼å‡ºçš„ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å°†ä¸ºæ¯ä¸ªå› å­å›æŠ¥æ·»åŠ ä¸€ä¸ªé¢å¤–çš„ç‰¹å¾ï¼šå¹³æ–¹ã€‚ä»ç‰¹å¾çš„è§’åº¦æ¥çœ‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä»ç„¶æ˜¯çº¿æ€§æ¨¡å‹ã€‚æŸäº›ç‰¹å¾åªæ˜¯ç¢°å·§ç”±å› å­å›æŠ¥çš„éçº¿æ€§å‡½æ•°ç¡®å®šã€‚è¯·è®°ä½ï¼Œè¿™ç§ç‰¹å®šçš„ç‰¹å¾å˜æ¢æ—¨åœ¨å±•ç¤ºå¯ç”¨é€‰é¡¹ä¸­çš„ä¸€äº›å†…å®¹ï¼Œä¸åº”è¢«è§†ä¸ºé¢„æµ‹é‡‘èå»ºæ¨¡ä¸­çš„æœ€å…ˆè¿›å®è·µã€‚
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_estimating_financial_risk_CO1-1)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_estimating_financial_risk_CO1-1)'
- en: Convert factors dataframe from long to wide format so that all factors for a
    period are in one row
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å› å­æ•°æ®æ¡†ä»é•¿æ ¼å¼è½¬æ¢ä¸ºå®½æ ¼å¼ï¼Œä»¥ä¾¿æ¯ä¸ªå‘¨æœŸçš„æ‰€æœ‰å› å­éƒ½åœ¨ä¸€è¡Œä¸­
- en: '[![2](assets/2.png)](#co_estimating_financial_risk_CO1-2)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_estimating_financial_risk_CO1-2)'
- en: Flatten multi-index dataframe and fix column names
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: å±•å¹³å¤šçº§ç´¢å¼•æ•°æ®æ¡†å¹¶ä¿®å¤åˆ—å
- en: 'Even though we will be carrying out many regressionsâ€”one for each instrumentâ€”the
    number of features and data points in each regression is small, meaning that we
    donâ€™t need to make use of PySparkâ€™s distributed linear modeling capabilities.
    Instead, weâ€™ll use the ordinary least squares regression offered by the scikit-learn
    package:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å³ä½¿æˆ‘ä»¬å°†æ‰§è¡Œè®¸å¤šå›å½’åˆ†æâ€”â€”æ¯ä¸ªå·¥å…·ä¸€ä¸ªâ€”â€”æ¯ä¸ªå›å½’ä¸­çš„ç‰¹å¾æ•°å’Œæ•°æ®ç‚¹æ•°éƒ½å¾ˆå°ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬ä¸éœ€è¦åˆ©ç”¨PySparkçš„åˆ†å¸ƒå¼çº¿æ€§å»ºæ¨¡èƒ½åŠ›ã€‚ç›¸åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨scikit-learnåŒ…æä¾›çš„æ™®é€šæœ€å°äºŒä¹˜å›å½’ï¼š
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We now have a dataframe where each row is the set of model parameters (coefficients,
    weights, covariants, regressors, or whatever you wish to call them) for an instrument.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æœ‰ä¸€ä¸ªæ•°æ®æ¡†ï¼Œå…¶ä¸­æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªå·¥å…·çš„æ¨¡å‹å‚æ•°ï¼ˆç³»æ•°ã€æƒé‡ã€åå˜é‡ã€å›å½’å™¨æˆ–è€…ä½ æƒ³ç§°å‘¼å®ƒä»¬çš„ä»»ä½•ä¸œè¥¿ï¼‰ã€‚
- en: At this point in any real-world pipeline it would be useful to understand how
    well these models fit the data. Because the data points are drawn from time series,
    and especially because the time intervals are overlapping, it is very likely that
    the samples are autocorrelated. This means that common measures like *R*Â² are
    likely to overestimate how well the models fit the data. The [Breusch-Godfrey
    test](https://oreil.ly/9cwg6) is a standard test for assessing these effects.
    One quick way to evaluate a model is to separate a time series into two sets,
    leaving out enough data points in the middle so that the last points in the earlier
    set are not autocorrelated with the first points in the later set. Then train
    the model on one set and look at its error on the other.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä»»ä½•å®é™…çš„æµç¨‹ä¸­ï¼Œç†è§£è¿™äº›æ¨¡å‹å¦‚ä½•ä¸æ•°æ®æ‹Ÿåˆæ˜¯å¾ˆæœ‰ç”¨çš„ã€‚ç”±äºæ•°æ®ç‚¹æ¥è‡ªæ—¶é—´åºåˆ—ï¼Œç‰¹åˆ«æ˜¯å› ä¸ºæ—¶é—´é—´éš”é‡å ï¼Œå¾ˆå¯èƒ½æ ·æœ¬æ˜¯è‡ªç›¸å…³çš„ã€‚è¿™æ„å‘³ç€å¸¸è§çš„æµ‹é‡å¦‚*R*Â²å¾ˆå¯èƒ½ä¼šé«˜ä¼°æ¨¡å‹æ‹Ÿåˆæ•°æ®çš„æ•ˆæœã€‚[å¸ƒé²èˆ-æˆˆå¾·å¼—é›·æ£€éªŒ](https://oreil.ly/9cwg6)æ˜¯è¯„ä¼°è¿™äº›æ•ˆåº”çš„æ ‡å‡†æ£€éªŒæ–¹æ³•ã€‚è¯„ä¼°æ¨¡å‹çš„ä¸€ä¸ªå¿«é€Ÿæ–¹æ³•æ˜¯å°†æ—¶é—´åºåˆ—åˆ†ä¸ºä¸¤ç»„ï¼Œä¸­é—´ç•™å‡ºè¶³å¤Ÿçš„æ•°æ®ç‚¹ï¼Œä½¿å¾—å‰ä¸€ç»„çš„æœ€åç‚¹ä¸åä¸€ç»„çš„ç¬¬ä¸€ç‚¹ä¸è‡ªç›¸å…³ã€‚ç„¶ååœ¨ä¸€ç»„ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œå¹¶æŸ¥çœ‹å…¶åœ¨å¦ä¸€ç»„ä¸Šçš„è¯¯å·®ã€‚
- en: With our models that map factor returns to instrument returns in hand, we now
    need a procedure for simulating market conditions by generating random factor
    returns. Thatâ€™s what weâ€™ll do next.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬æ‰‹å¤´æœ‰å°†å› å­å›æŠ¥æ˜ å°„åˆ°å·¥å…·å›æŠ¥çš„æ¨¡å‹ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªè¿‡ç¨‹æ¥é€šè¿‡ç”Ÿæˆéšæœºå› å­å›æŠ¥æ¥æ¨¡æ‹Ÿå¸‚åœºæ¡ä»¶ã€‚è¿™å°±æ˜¯æˆ‘ä»¬æ¥ä¸‹æ¥è¦åšçš„ã€‚
- en: Sampling
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é‡‡æ ·
- en: To come up with a way for generating random factor returns, we need to decide
    on a probability distribution over factor return vectors and sample from it. What
    distribution does the data actually take? It can often be useful to start answering
    this kind of question visually.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æƒ³å‡ºä¸€ä¸ªç”Ÿæˆéšæœºå› å­å›æŠ¥çš„æ–¹æ³•ï¼Œæˆ‘ä»¬éœ€è¦å†³å®šä¸€ä¸ªå› å­å›æŠ¥å‘é‡ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒï¼Œå¹¶ä»ä¸­è¿›è¡Œé‡‡æ ·ã€‚æ•°æ®å®é™…ä¸Šå–ä»€ä¹ˆåˆ†å¸ƒï¼Ÿé€šå¸¸å¯ä»¥ä»è§†è§‰ä¸Šå¼€å§‹å›ç­”è¿™ç±»é—®é¢˜æ˜¯æœ‰ç”¨çš„ã€‚
- en: A nice way to visualize a probability distribution over continuous data is a
    density plot that plots the distributionâ€™s domain versus its probability density
    function. Because we donâ€™t know the distribution that governs the data, we donâ€™t
    have an equation that can give us its density at an arbitrary point, but we can
    approximate it through a technique called *kernel density estimation* (KDE). In
    a loose way, kernel density estimation is a way of smoothing out a histogram.
    It centers a probability distribution (usually a normal distribution) at each
    data point. So a set of two-week-return samples would result in multiple normal
    distributions, each with a different mean. To estimate the probability density
    at a given point, it evaluates the PDFs of all the normal distributions at that
    point and takes their average. The smoothness of a kernel density plot depends
    on its *bandwidth*, the standard deviation of each of the normal distributions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ç§å¾ˆå¥½çš„æ–¹æ³•æ¥å¯è§†åŒ–è¿ç»­æ•°æ®ä¸Šçš„æ¦‚ç‡åˆ†å¸ƒæ˜¯å¯†åº¦å›¾ï¼Œå®ƒå°†åˆ†å¸ƒçš„å®šä¹‰åŸŸä¸å…¶æ¦‚ç‡å¯†åº¦å‡½æ•°è¿›è¡Œç»˜åˆ¶ã€‚å› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“æ§åˆ¶æ•°æ®çš„åˆ†å¸ƒï¼Œæ‰€ä»¥æˆ‘ä»¬æ²¡æœ‰èƒ½å¤Ÿåœ¨ä»»æ„ç‚¹ç»™å‡ºå…¶å¯†åº¦çš„æ–¹ç¨‹ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ç§ç§°ä¸º*æ ¸å¯†åº¦ä¼°è®¡*ï¼ˆKDEï¼‰çš„æŠ€æœ¯æ¥è¿‘ä¼¼å®ƒã€‚ä»¥ä¸€ç§å®½æ¾çš„æ–¹å¼ï¼Œæ ¸å¯†åº¦ä¼°è®¡æ˜¯å¹³æ»‘ç›´æ–¹å›¾çš„ä¸€ç§æ–¹æ³•ã€‚å®ƒåœ¨æ¯ä¸ªæ•°æ®ç‚¹å¤„éƒ½ä¼šå±…ä¸­ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼ˆé€šå¸¸æ˜¯æ­£æ€åˆ†å¸ƒï¼‰ã€‚å› æ­¤ï¼Œä¸€ä¸ªä¸¤å‘¨å›æŠ¥æ ·æœ¬é›†å°†äº§ç”Ÿå¤šä¸ªæ­£æ€åˆ†å¸ƒï¼Œæ¯ä¸ªéƒ½æœ‰ä¸åŒçš„å‡å€¼ã€‚ä¸ºäº†ä¼°è®¡ç»™å®šç‚¹å¤„çš„æ¦‚ç‡å¯†åº¦ï¼Œå®ƒè¯„ä¼°æ‰€æœ‰æ­£æ€åˆ†å¸ƒåœ¨è¯¥ç‚¹çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œå¹¶å–å®ƒä»¬çš„å¹³å‡å€¼ã€‚æ ¸å¯†åº¦å›¾çš„å¹³æ»‘ç¨‹åº¦å–å†³äºå…¶*å¸¦å®½*ï¼Œå³æ¯ä¸ªæ­£æ€åˆ†å¸ƒçš„æ ‡å‡†å·®ã€‚
- en: 'Weâ€™ll use one of pandas DataFrameâ€™s built-in methods to calculate and draw
    a KDE plot. The following snippet creates a density plot for one of our factors:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨ pandas DataFrame çš„å†…ç½®æ–¹æ³•ä¹‹ä¸€æ¥è®¡ç®—å¹¶ç»˜åˆ¶ KDE å›¾ã€‚ä»¥ä¸‹ä»£ç ç‰‡æ®µåˆ›å»ºäº†ä¸€ä¸ªå› å­çš„å¯†åº¦å›¾ï¼š
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[FigureÂ 8-1](#figure8-1) shows the distribution (probability density function)
    of two-week returns for the 20+ Year Treasury Bond ETF in our history.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 8-1](#figure8-1) æ˜¾ç¤ºäº†æˆ‘ä»¬å†å²ä¸­ä¸¤å‘¨æœŸå›½åº“å€ºåˆ¸ ETF çš„å›æŠ¥åˆ†å¸ƒï¼ˆæ¦‚ç‡å¯†åº¦å‡½æ•°ï¼‰ã€‚'
- en: '![Two-week 20+ Year Treasury Bond ETF distribution](assets/aaps_0801.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![ä¸¤å‘¨ 20+ å¹´æœŸå›½åº“å€ºåˆ¸ ETF åˆ†å¸ƒ](assets/aaps_0801.png)'
- en: Figure 8-1\. Two-week 20+ Year Treasury Bond ETF distribution
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 8-1\. ä¸¤å‘¨ 20+ å¹´æœŸå›½åº“å€ºåˆ¸ ETF å›æŠ¥åˆ†å¸ƒ
- en: '[FigureÂ 8-2](#figure8-2) shows the same for two-week returns of US Credit Bonds.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 8-2](#figure8-2) å±•ç¤ºäº†ç¾å›½ä¿¡ç”¨å€ºçš„ä¸¤å‘¨å›æŠ¥æƒ…å†µã€‚'
- en: '![aaps 0802](assets/aaps_0802.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![aaps 0802](assets/aaps_0802.png)'
- en: Figure 8-2\. Two-week US Credit Bond ETF returns distribution
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 8-2\. ç¾å›½ä¿¡ç”¨å€º ETF ä¸¤å‘¨å›æŠ¥åˆ†å¸ƒ
- en: We will fit a normal distribution to the returns of each factor. Looking for
    a more exotic distribution, perhaps with fatter tails, that more closely fits
    the data is often worthwhile. However, for the sake of simplicity, weâ€™ll avoid
    tuning our simulation in this way.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†å¯¹æ¯ä¸ªå› å­çš„å›æŠ¥æ‹Ÿåˆä¸€ä¸ªæ­£æ€åˆ†å¸ƒã€‚å¯»æ‰¾æ›´æ¥è¿‘æ•°æ®çš„ã€å¯èƒ½å…·æœ‰æ›´èƒ–å°¾å·´çš„æ›´å¥‡ç‰¹åˆ†å¸ƒé€šå¸¸æ˜¯å€¼å¾—çš„ã€‚ç„¶è€Œï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å°†é¿å…ä»¥è¿™ç§æ–¹å¼è°ƒæ•´æˆ‘ä»¬çš„æ¨¡æ‹Ÿã€‚
- en: 'The simplest way to sample factorsâ€™ returns would be to fit a normal distribution
    to each of the factors and sample from these distributions independently. However,
    this ignores the fact that market factors are often correlated. If the Treasury
    Bond ETF is down, the Credit Bond ETF is likely to be down as well. Failing to
    take these correlations into account can give us a much rosier picture of our
    risk profile than its reality. Are the returns of our factors correlated? The
    Pearsonâ€™s correlation implementation in pandas can help us find out:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹å› å­çš„å›æŠ¥è¿›è¡ŒæŠ½æ ·çš„æœ€ç®€å•æ–¹æ³•æ˜¯å¯¹æ¯ä¸ªå› å­æ‹Ÿåˆä¸€ä¸ªæ­£æ€åˆ†å¸ƒï¼Œå¹¶ä»è¿™äº›åˆ†å¸ƒä¸­ç‹¬ç«‹æŠ½æ ·ã€‚ç„¶è€Œï¼Œè¿™å¿½è§†äº†å¸‚åœºå› å­é€šå¸¸å­˜åœ¨ç›¸å…³æ€§çš„äº‹å®ã€‚å¦‚æœå›½åº“å€ºåˆ¸ ETF
    ä¸‹è·Œï¼Œä¿¡ç”¨å€ºåˆ¸ ETF ä¹Ÿå¯èƒ½ä¸‹è·Œã€‚æœªèƒ½è€ƒè™‘è¿™äº›ç›¸å…³æ€§å¯èƒ½ä½¿æˆ‘ä»¬å¯¹é£é™©é…ç½®çš„å®é™…æƒ…å†µæŒæœ‰è¿‡äºä¹è§‚çš„çœ‹æ³•ã€‚æˆ‘ä»¬çš„å› å­å›æŠ¥æ˜¯å¦ç›¸å…³ï¼Ÿpandas ä¸­çš„ Pearson
    ç›¸å…³æ€§å®ç°å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ‰¾å‡ºç­”æ¡ˆï¼š
- en: '[PRE17]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Because we have nonzero elements off the diagonals, it doesnâ€™t look like it.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬çš„éå¯¹è§’å…ƒç´ æ˜¯éé›¶çš„ï¼Œæ‰€ä»¥å®ƒçœ‹èµ·æ¥å¹¶ä¸åƒå®ƒã€‚
- en: The Multivariate Normal Distribution
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤šå…ƒæ­£æ€åˆ†å¸ƒ
- en: The multivariate normal distribution can help here by taking the correlation
    information between the factors into account. Each sample from a multivariate
    normal is a vector. Given values for all of the dimensions but one, the distribution
    of values along that dimension is normal. But, in their joint distribution, the
    variables are not independent.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šå…ƒæ­£æ€åˆ†å¸ƒåœ¨è¿™é‡Œæœ‰åŠ©äºè€ƒè™‘å› å­ä¹‹é—´çš„ç›¸å…³ä¿¡æ¯ã€‚æ¥è‡ªå¤šå…ƒæ­£æ€åˆ†å¸ƒçš„æ¯ä¸ªæ ·æœ¬éƒ½æ˜¯ä¸€ä¸ªå‘é‡ã€‚å¯¹äºæ‰€æœ‰ç»´åº¦ä¸­é™¤ä¸€ç»´ä¹‹å¤–çš„ç»™å®šå€¼ï¼Œè¯¥ç»´åº¦ä¸Šçš„å€¼åˆ†å¸ƒæ˜¯æ­£æ€çš„ã€‚ä½†æ˜¯ï¼Œåœ¨å®ƒä»¬çš„è”åˆåˆ†å¸ƒä¸­ï¼Œå˜é‡å¹¶ä¸æ˜¯ç‹¬ç«‹çš„ã€‚
- en: The multivariate normal is parameterized with a mean along each dimension and
    a matrix describing the covariances between each pair of dimensions. With *N*
    dimensions, the covariance matrix is *N* by *N* because we want to capture the
    covariances between each pair of dimensions. When the covariance matrix is diagonal,
    the multivariate normal reduces to sampling along each dimension independently,
    but placing nonzero values in the off-diagonals helps capture the relationships
    between variables.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šå…ƒæ­£æ€åˆ†å¸ƒæ˜¯ç”¨æ¯ä¸ªç»´åº¦çš„å‡å€¼å’Œæè¿°æ¯å¯¹ç»´åº¦ä¹‹é—´çš„åæ–¹å·®çš„çŸ©é˜µæ¥å‚æ•°åŒ–çš„ã€‚å¯¹äº*N*ä¸ªç»´åº¦ï¼Œåæ–¹å·®çŸ©é˜µæ˜¯*N*ä¹˜*N*çš„ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³è¦æ•è·æ¯å¯¹ç»´åº¦ä¹‹é—´çš„åæ–¹å·®ã€‚å½“åæ–¹å·®çŸ©é˜µæ˜¯å¯¹è§’çº¿æ—¶ï¼Œå¤šå…ƒæ­£æ€åˆ†å¸ƒå°†å‡å°‘åˆ°æ²¿ç€æ¯ä¸ªç»´åº¦ç‹¬ç«‹é‡‡æ ·ï¼Œä½†åœ¨å¯¹è§’çº¿ä¸Šæ”¾ç½®éé›¶å€¼æœ‰åŠ©äºæ•è·å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚
- en: The VaR literature often describes a step in which the factor weights are transformed
    (decorrelated) so that sampling can proceed. This is normally accomplished with
    a Cholesky decomposition or eigendecomposition. NumPy packageâ€™s `Mâ uâ lâ tâ iâ vâ aâ râ iâ aâ tâ eâ€‹Nâ oâ râ mâ aâ lâ Distribution`
    takes care of this step for us under the covers using an eigendecomposition.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: VaRæ–‡çŒ®é€šå¸¸æè¿°äº†ä¸€ç§åœ¨å› å­æƒé‡è¢«è½¬æ¢ï¼ˆå»ç›¸å…³ï¼‰çš„æ­¥éª¤ï¼Œä»¥ä¾¿å¯ä»¥è¿›è¡Œé‡‡æ ·ã€‚è¿™é€šå¸¸é€šè¿‡Choleskyåˆ†è§£æˆ–ç‰¹å¾åˆ†è§£æ¥å®Œæˆã€‚NumPyè½¯ä»¶åŒ…çš„`MultivariateNormalDistribution`åœ¨åº•å±‚ä½¿ç”¨ç‰¹å¾åˆ†è§£ä¸ºæˆ‘ä»¬å¤„ç†äº†è¿™ä¸€æ­¥ã€‚
- en: 'To fit a multivariate normal distribution to our data, first we need to find
    its sample means and covariances:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å°†å¤šå…ƒæ­£æ€åˆ†å¸ƒæ‹Ÿåˆåˆ°æˆ‘ä»¬çš„æ•°æ®ä¸­ï¼Œé¦–å…ˆæˆ‘ä»¬éœ€è¦æ‰¾åˆ°å…¶æ ·æœ¬å‡å€¼å’Œåæ–¹å·®ï¼š
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then we can simply create a distribution parameterized with them and sample
    a set of market conditions from it:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥ç®€å•åœ°åˆ›å»ºä¸€ä¸ªä»¥å®ƒä»¬ä¸ºå‚æ•°çš„åˆ†å¸ƒï¼Œå¹¶ä»ä¸­é‡‡æ ·ä¸€ç»„å¸‚åœºæ¡ä»¶ï¼š
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: With the per-instrument models and a procedure for sampling factor returns,
    we now have the pieces we need to run the actual trials. Letâ€™s start working on
    our simulation and run the trials.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº†æ¯ä¸ªä»ªå™¨æ¨¡å‹å’Œé‡‡æ ·å› å­æ”¶ç›Šçš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬ç°åœ¨æœ‰äº†è¿è¡Œå®é™…è¯•éªŒæ‰€éœ€çš„éƒ¨ä»¶ã€‚è®©æˆ‘ä»¬å¼€å§‹ç€æ‰‹è¿›è¡Œæˆ‘ä»¬çš„æ¨¡æ‹Ÿå¹¶è¿è¡Œè¯•éªŒã€‚
- en: Running the Trials
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¿è¡Œè¯•éªŒ
- en: Because running the trials is computationally intensive, weâ€™ll turn to PySpark
    to help us parallelize them. In each trial, we want to sample a set of risk factors,
    use them to predict the return of each instrument, and sum all those returns to
    find the full trial loss. To achieve a representative distribution, we want to
    run thousands or millions of these trials.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºè¿è¡Œè¯•éªŒæ˜¯è®¡ç®—å¯†é›†å‹çš„ï¼Œæˆ‘ä»¬å°†æ±‚åŠ©äºPySparkæ¥å¸®åŠ©æˆ‘ä»¬å¹¶è¡ŒåŒ–å®ƒä»¬ã€‚åœ¨æ¯ä¸ªè¯•éªŒä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›é‡‡æ ·ä¸€ç»„é£é™©å› ç´ ï¼Œç”¨å®ƒä»¬æ¥é¢„æµ‹æ¯ä¸ªä»ªå™¨çš„æ”¶ç›Šï¼Œå¹¶å°†æ‰€æœ‰è¿™äº›æ”¶ç›Šç›¸åŠ ä»¥æ‰¾åˆ°å®Œæ•´çš„è¯•éªŒæŸå¤±ã€‚ä¸ºäº†è·å¾—ä»£è¡¨æ€§çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬å¸Œæœ›è¿è¡Œæ•°åƒæˆ–æ•°ç™¾ä¸‡æ¬¡è¿™æ ·çš„è¯•éªŒã€‚
- en: We have a few choices for how to parallelize the simulation. We can parallelize
    along trials, instruments, or both. To parallelize along both, we would create
    a dataset of instruments and a dataset of trial parameters and then use the `crossJoin`
    transformation to generate a dataset of all the pairs. This is the most general
    approach, but it has a couple of disadvantages. First, it requires explicitly
    creating a DataFrame of trial parameters, which we can avoid by using some tricks
    with random seeds. Second, it requires a shuffle operation.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ‰å‡ ç§é€‰æ‹©æ¥å¹¶è¡ŒåŒ–æ¨¡æ‹Ÿã€‚æˆ‘ä»¬å¯ä»¥æ²¿è¯•éªŒã€ä»ªå™¨æˆ–ä¸¤è€…ä¸€èµ·å¹¶è¡ŒåŒ–ã€‚è¦æ²¿ä¸¤è€…ä¸€èµ·å¹¶è¡ŒåŒ–ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªä»ªå™¨æ•°æ®é›†å’Œä¸€ä¸ªè¯•éªŒå‚æ•°æ•°æ®é›†ï¼Œç„¶åä½¿ç”¨`crossJoin`è½¬æ¢æ¥ç”Ÿæˆæ‰€æœ‰é…å¯¹çš„æ•°æ®é›†ã€‚è¿™æ˜¯æœ€ä¸€èˆ¬çš„æ–¹æ³•ï¼Œä½†å®ƒæœ‰ä¸€äº›ç¼ºç‚¹ã€‚é¦–å…ˆï¼Œå®ƒéœ€è¦æ˜ç¡®åˆ›å»ºä¸€ä¸ªè¯•éªŒå‚æ•°çš„DataFrameï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€äº›éšæœºç§å­çš„æŠ€å·§æ¥é¿å…è¿™ç§æƒ…å†µã€‚å…¶æ¬¡ï¼Œå®ƒéœ€è¦ä¸€ä¸ªæ´—ç‰Œæ“ä½œã€‚
- en: 'Partitioning along instruments would look something like this:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¿ä»ªå™¨åˆ†åŒºçš„æƒ…å†µå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: With this approach, the data is partitioned across a DataFrame of instruments,
    and for each instrument a `flatMap` transformation computes and yields the loss
    against every trial. Using the same random seed across all tasks means that we
    will generate the same sequence of trials. `reduceByKey` sums together all the
    losses corresponding to the same trials. A disadvantage of this approach is that
    it still requires shuffling *O*(|instruments| * |trials|) data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨è¿™ç§æ–¹æ³•ï¼Œæ•°æ®è¢«åˆ†åŒºåˆ°ä¸€ä¸ªä»ªå™¨DataFrameä¸­ï¼Œå¹¶ä¸”å¯¹äºæ¯ä¸ªä»ªå™¨ï¼Œ`flatMap`è½¬æ¢è®¡ç®—å¹¶äº§ç”Ÿäº†é’ˆå¯¹æ¯ä¸ªè¯•éªŒçš„æŸå¤±ã€‚åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­ä½¿ç”¨ç›¸åŒçš„éšæœºç§å­æ„å‘³ç€æˆ‘ä»¬å°†ç”Ÿæˆç›¸åŒçš„è¯•éªŒåºåˆ—ã€‚`reduceByKey`å°†æ‰€æœ‰ä¸ç›¸åŒè¯•éªŒå¯¹åº”çš„æŸå¤±ç›¸åŠ åœ¨ä¸€èµ·ã€‚è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯å®ƒä»ç„¶éœ€è¦å¯¹*O*(|instruments|
    * |trials|)æ•°æ®è¿›è¡Œæ´—ç‰Œã€‚
- en: Our model data for our few thousand instruments is small enough to fit in memory
    on every executor, and some back-of-the-envelope calculations reveal that this
    is probably still the case even with a million or so instruments and hundreds
    of factors. A million instruments times 500 factors times the 8 bytes needed for
    the double that stores each factor weight equals roughly 4 GB, small enough to
    fit in each executor on most modern-day cluster machines. This means that a good
    option is to distribute the instrument data in a broadcast variable. The advantage
    of each executor having a full copy of the instrument data is that total loss
    for each trial can be computed on a single machine. No aggregation is necessary.
    We also broadcast some other data required for trial return calculation.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°‘é‡å·¥å…·çš„æ¨¡å‹æ•°æ®è¶³å¤Ÿå°ï¼Œå¯ä»¥åœ¨æ¯ä¸ªæ‰§è¡Œå™¨çš„å†…å­˜ä¸­å®¹çº³ï¼Œå¹¶ä¸”ä¸€äº›ç²—ç•¥çš„è®¡ç®—æ˜¾ç¤ºï¼Œå³ä½¿æ˜¯æ•°ç™¾ä¸‡å·¥å…·å’Œæ•°ç™¾ä¸ªå› ç´ ï¼Œè¿™å¯èƒ½ä»ç„¶é€‚ç”¨ã€‚ç™¾ä¸‡å·¥å…·ä¹˜ä»¥500å› ç´ ä¹˜ä»¥å­˜å‚¨æ¯ä¸ªå› ç´ æƒé‡æ‰€éœ€çš„8å­—èŠ‚ï¼Œå¤§çº¦ç›¸å½“äº4
    GBï¼Œè¶³å¤Ÿå°ï¼Œå¯ä»¥åœ¨å¤§å¤šæ•°ç°ä»£é›†ç¾¤æœºå™¨çš„æ¯ä¸ªæ‰§è¡Œå™¨ä¸Šå®¹çº³ã€‚è¿™æ„å‘³ç€ä¸€ä¸ªå¥½çš„é€‰æ‹©æ˜¯åœ¨å¹¿æ’­å˜é‡ä¸­åˆ†å‘å·¥å…·æ•°æ®ã€‚æ¯ä¸ªæ‰§è¡Œå™¨æ‹¥æœ‰å·¥å…·æ•°æ®çš„å®Œæ•´å‰¯æœ¬çš„ä¼˜åŠ¿åœ¨äºå¯ä»¥åœ¨å•å°æœºå™¨ä¸Šè®¡ç®—æ¯ä¸ªè¯•éªŒçš„æ€»æŸå¤±ã€‚ä¸éœ€è¦èšåˆã€‚æˆ‘ä»¬è¿˜å¹¿æ’­äº†ä¸€äº›å…¶ä»–ç”¨äºè®¡ç®—è¯•éªŒå›æŠ¥æ‰€éœ€çš„æ•°æ®ã€‚
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'With the partition-by-trials approach (which we will use), we start out with
    a DataFrame of seeds. We want a different seed in each partition so that each
    partition generates different trials:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æŒ‰è¯•éªŒåˆ†åŒºçš„æ–¹æ³•ï¼ˆæˆ‘ä»¬å°†ä½¿ç”¨å®ƒï¼‰ï¼Œæˆ‘ä»¬ä»ç§å­çš„DataFrameå¼€å§‹ã€‚æˆ‘ä»¬å¸Œæœ›æ¯ä¸ªåˆ†åŒºä¸­æœ‰ä¸€ä¸ªä¸åŒçš„ç§å­ï¼Œä»¥ä¾¿æ¯ä¸ªåˆ†åŒºç”Ÿæˆä¸åŒçš„è¯•éªŒï¼š
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Random number generation is a time-consuming and CPU-intensive process. While
    we donâ€™t employ this trick here, it can often be useful to generate a set of random
    numbers in advance and use it across multiple jobs. The same random numbers should
    *not* be used within a single job, because this would violate the Monte Carlo
    assumption that the random values are independently distributed.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: éšæœºæ•°ç”Ÿæˆæ˜¯ä¸€ä¸ªè€—æ—¶ä¸”CPUå¯†é›†å‹çš„è¿‡ç¨‹ã€‚è™½ç„¶æˆ‘ä»¬åœ¨è¿™é‡Œæ²¡æœ‰ä½¿ç”¨è¿™ä¸ªæŠ€å·§ï¼Œä½†é€šå¸¸å¯ä»¥é¢„å…ˆç”Ÿæˆä¸€ç»„éšæœºæ•°ï¼Œå¹¶åœ¨å¤šä¸ªä½œä¸šä¸­ä½¿ç”¨å®ƒã€‚ä¸åº”åœ¨å•ä¸ªä½œä¸šå†…ä½¿ç”¨ç›¸åŒçš„éšæœºæ•°ï¼Œå› ä¸ºè¿™å°†è¿åè’™ç‰¹å¡æ´›å‡è®¾ï¼Œå³éšæœºå€¼æ˜¯ç‹¬ç«‹åˆ†å¸ƒçš„ã€‚
- en: 'For each seed, we want to generate a set of trial parameters and observe the
    effects of these parameters on all the instruments. We will write a function that
    calculates the full return of instruments for multiple trials. We start by simply
    applying the linear model that we trained earlier for each instrument. Then we
    average over the returns of all the instruments. This assumes that weâ€™re holding
    an equal value of each instrument in the portfolio. A weighted average would be
    used if we held different amounts of each stock. Lastly, we need to generate a
    bunch of trials in each task. Because choosing random numbers is a big part of
    the process, it is important to use a strong random number generator. Pythonâ€™s
    in-built `random` library includes a Mersenne Twister implementation that is good
    for this. We use it to sample from a multivariate normal distribution as described
    previously:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ªç§å­ï¼Œæˆ‘ä»¬å¸Œæœ›ç”Ÿæˆä¸€ç»„è¯•éªŒå‚æ•°ï¼Œå¹¶è§‚å¯Ÿè¿™äº›å‚æ•°å¯¹æ‰€æœ‰ä»ªå™¨çš„å½±å“ã€‚æˆ‘ä»¬å°†ç¼–å†™ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—å¤šä¸ªè¯•éªŒçš„æ‰€æœ‰ä»ªå™¨çš„å…¨é¢å›æŠ¥ã€‚æˆ‘ä»¬é¦–å…ˆç®€å•åœ°åº”ç”¨æˆ‘ä»¬ä¹‹å‰ä¸ºæ¯ä¸ªä»ªå™¨è®­ç»ƒçš„çº¿æ€§æ¨¡å‹ã€‚ç„¶åæˆ‘ä»¬å¯¹æ‰€æœ‰ä»ªå™¨çš„å›æŠ¥å–å¹³å‡å€¼ã€‚è¿™å‡è®¾æˆ‘ä»¬åœ¨æŠ•èµ„ç»„åˆä¸­æŒæœ‰æ¯ç§ä»ªå™¨ç›¸ç­‰çš„ä»·å€¼ã€‚å¦‚æœæˆ‘ä»¬æŒæœ‰ä¸åŒæ•°é‡çš„æ¯åªè‚¡ç¥¨ï¼Œåˆ™å°†ä½¿ç”¨åŠ æƒå¹³å‡ã€‚æœ€åï¼Œåœ¨æ¯ä¸ªä»»åŠ¡ä¸­æˆ‘ä»¬éœ€è¦ç”Ÿæˆä¸€å †è¯•éªŒã€‚å› ä¸ºé€‰æ‹©éšæœºæ•°æ˜¯è¯¥è¿‡ç¨‹çš„ä¸€ä¸ªé‡è¦éƒ¨åˆ†ï¼Œæ‰€ä»¥ä½¿ç”¨å¼ºéšæœºæ•°ç”Ÿæˆå™¨éå¸¸é‡è¦ã€‚Pythonå†…ç½®çš„`random`åº“åŒ…æ‹¬ä¸€ä¸ªæ¢…æ£®æ—‹è½¬å®ç°ï¼Œéå¸¸é€‚åˆè¿™ä¸ªä»»åŠ¡ã€‚æˆ‘ä»¬ç”¨å®ƒæ¥ä»å…ˆå‰æè¿°çš„å¤šå˜é‡æ­£æ€åˆ†å¸ƒä¸­æŠ½æ ·ï¼š
- en: '[PRE23]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'With our scaffolding complete, we can use it to compute a DataFrame where each
    element is the total return from a single trial:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€æˆ‘ä»¬çš„æ”¯æ¶å®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒæ¥è®¡ç®—ä¸€ä¸ªDataFrameï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ æ˜¯å•ä¸ªè¯•éªŒçš„æ€»å›æŠ¥ï¼š
- en: '[PRE24]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[![1](assets/1.png)](#co_estimating_financial_risk_CO2-1)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_estimating_financial_risk_CO2-1)'
- en: Split array of trial returns into individual DataFrame rows
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: å°†è¯•éªŒå›æŠ¥çš„åˆ†å‰²æ•°ç»„æ‹†åˆ†ä¸ºå•ç‹¬çš„DataFrameè¡Œ
- en: 'If you recall, the whole reason weâ€™ve been messing around with all these numbers
    is to calculate VaR. `trials` now forms an empirical distribution over portfolio
    returns. To calculate 5% VaR, we need to find a return that we expect to underperform
    5% of the time, and a return that we expect to outperform 5% of the time. With
    our empirical distribution, this is as simple as finding the value that 5% of
    trials are worse than and 95% of trials are better than. We can accomplish this
    by pulling the worst 5% of trials into the driver. Our VaR is the return of the
    best trial in this subset:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ è¿˜è®°å¾—ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨å¤„ç†æ‰€æœ‰è¿™äº›æ•°å­—çš„æ•´ä¸ªåŸå› æ˜¯ä¸ºäº†è®¡ç®— VaRã€‚ç°åœ¨ï¼Œ`trials` å½¢æˆäº†æŠ•èµ„ç»„åˆæ”¶ç›Šçš„ç»éªŒåˆ†å¸ƒã€‚ä¸ºäº†è®¡ç®— 5% VaRï¼Œæˆ‘ä»¬éœ€è¦æ‰¾åˆ°é¢„è®¡ä¼šä½äº
    5% æ—¶é—´çš„æ”¶ç›Šå’Œé¢„è®¡ä¼šè¶…è¿‡ 5% æ—¶é—´çš„æ”¶ç›Šã€‚é€šè¿‡æˆ‘ä»¬çš„ç»éªŒåˆ†å¸ƒï¼Œè¿™å°±åƒæ‰¾åˆ°æ¯”ç‡ä¸­æœ€å·®çš„ 5% å’Œæ¯”ç‡ä¸­æœ€å¥½çš„ 95% ä¸€æ ·ç®€å•ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æŠŠæœ€å·®çš„ 5%
    çš„è¯•éªŒæ‹‰åˆ°é©¾é©¶ä¸­æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬çš„ VaR æ˜¯è¿™ä¸ªå­é›†ä¸­æœ€ä½³è¯•éªŒçš„æ”¶ç›Šï¼š
- en: '[PRE25]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can find the CVaR with a nearly identical approach. Instead of taking the
    best trial return from the worst 5% of trials, we take the average return from
    that set of trials:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥ç”¨å‡ ä¹ç›¸åŒçš„æ–¹æ³•æ‰¾åˆ° CVaRã€‚ä¸åŒäºä»æœ€å·®çš„ 5% è¯•éªŒä¸­å–æœ€ä½³è¯•éªŒæ”¶ç›Šï¼Œæˆ‘ä»¬ä»è¿™äº›è¯•éªŒçš„é›†åˆä¸­å–å¹³å‡æ”¶ç›Šï¼š
- en: '[PRE26]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Visualizing the Distribution of Returns
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¯è§†åŒ–æ”¶ç›Šåˆ†å¸ƒ
- en: 'In addition to calculating VaR at a particular confidence level, it can be
    useful to look at a fuller picture of the distribution of returns. Are they normally
    distributed? Do they spike at the extremities? As we did for the individual factors,
    we can plot an estimate of the probability density function for the joint probability
    distribution using kernel density estimation (see [FigureÂ 8-3](#figure9-3)):'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†åœ¨ç‰¹å®šç½®ä¿¡æ°´å¹³è®¡ç®— VaR å¤–ï¼ŒæŸ¥çœ‹æ”¶ç›Šåˆ†å¸ƒçš„æ›´å®Œæ•´å›¾åƒä¹Ÿå¾ˆæœ‰ç”¨ã€‚å®ƒä»¬æ˜¯å¦æ­£æ€åˆ†å¸ƒï¼Ÿå®ƒä»¬åœ¨æç«¯æ—¶æ˜¯å¦ä¼šçªç„¶ä¸Šå‡ï¼Ÿå°±åƒæˆ‘ä»¬ä¸ºä¸ªåˆ«å› ç´ æ‰€åšçš„é‚£æ ·ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ ¸å¯†åº¦ä¼°è®¡ç»˜åˆ¶è”åˆæ¦‚ç‡åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°çš„ä¼°è®¡ï¼ˆè§
    [å›¾ 8-3](#figure9-3)ï¼‰ã€‚
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![aaps 0803](assets/aaps_0803.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![aaps 0803](assets/aaps_0803.png)'
- en: Figure 8-3\. Two-week returns distribution
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 8-3\. ä¸¤å‘¨æ”¶ç›Šåˆ†å¸ƒ
- en: Where to Go from Here
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥çš„æ­¥éª¤
- en: The model laid out in this exercise is a very rough first cut of what would
    be used in an actual financial institution. In building an accurate VaR model,
    we glossed over a few very important steps. Curating the set of market factors
    can make or break a model, and it is not uncommon for financial institutions to
    incorporate hundreds of factors in their simulations. Picking these factors requires
    both running numerous experiments on historical data and a heavy dose of creativity.
    Choosing the predictive model that maps market factors to instrument returns is
    also important. Although we used a simple linear model, many calculations use
    nonlinear functions or simulate the path over time with Brownian motion.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­æå‡ºçš„æ¨¡å‹æ˜¯åœ¨å®é™…é‡‘èæœºæ„ä¸­ä½¿ç”¨çš„ç¬¬ä¸€æ¬¡ç²—ç•¥å°è¯•ã€‚åœ¨æ„å»ºå‡†ç¡®çš„ VaR æ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬å¿½ç•¥äº†ä¸€äº›éå¸¸é‡è¦çš„æ­¥éª¤ã€‚ç­›é€‰å¸‚åœºå› ç´ çš„é›†åˆå¯èƒ½æ˜¯æ¨¡å‹çš„æˆè´¥å…³é”®ï¼Œé‡‘èæœºæ„åœ¨å…¶æ¨¡æ‹Ÿä¸­é€šå¸¸ä¼šèåˆæ•°ç™¾ç§å› ç´ ã€‚é€‰æ‹©è¿™äº›å› ç´ æ—¢éœ€è¦åœ¨å†å²æ•°æ®ä¸Šè¿è¡Œå¤šæ¬¡å®éªŒï¼Œåˆéœ€è¦å¤§é‡çš„åˆ›é€ åŠ›ã€‚é€‰æ‹©å°†å¸‚åœºå› ç´ æ˜ å°„åˆ°å·¥å…·æ”¶ç›Šçš„é¢„æµ‹æ¨¡å‹ä¹Ÿå¾ˆé‡è¦ã€‚è™½ç„¶æˆ‘ä»¬ä½¿ç”¨äº†ç®€å•çš„çº¿æ€§æ¨¡å‹ï¼Œä½†è®¸å¤šè®¡ç®—ä½¿ç”¨éçº¿æ€§å‡½æ•°æˆ–æ¨¡æ‹Ÿæ—¶é—´è·¯å¾„ä½¿ç”¨å¸ƒæœ—è¿åŠ¨ã€‚
- en: Lastly, it is worth putting care into the distribution used to simulate the
    factor returns. Kolmogorov-Smirnov tests and chi-squared tests are useful for
    testing an empirical distributionâ€™s normality. Q-Q plots are useful for comparing
    distributions visually. Usually, financial risk is better mirrored by a distribution
    with fatter tails than the normal distribution that we used. Mixtures of normal
    distributions are one good way to achieve these fatter tails. [â€œFinancial Economics,
    Fat-tailed Distributionsâ€](https://oreil.ly/XSxhB), an article by Markus Haas
    and Christian Pigorsch, provides a nice reference on some of the other fat-tailed
    distributions out there.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å€¼å¾—å…³æ³¨ç”¨äºæ¨¡æ‹Ÿå› å­æ”¶ç›Šçš„åˆ†å¸ƒã€‚ç§‘å°”è«å“¥æ´›å¤«-æ–¯ç±³å°”è¯ºå¤«æ£€éªŒå’Œå¡æ–¹æ£€éªŒå¯¹äºæµ‹è¯•ç»éªŒåˆ†å¸ƒçš„æ­£æ€æ€§éå¸¸æœ‰ç”¨ã€‚Q-Q å›¾ç”¨äºç›´è§‚æ¯”è¾ƒåˆ†å¸ƒã€‚é€šå¸¸ï¼Œé‡‘èé£é™©æ›´å¥½åœ°é€šè¿‡å…·æœ‰æ¯”æˆ‘ä»¬ä½¿ç”¨çš„æ­£æ€åˆ†å¸ƒæ›´èƒ–å°¾éƒ¨çš„åˆ†å¸ƒæ¥åæ˜ ã€‚æ­£æ€åˆ†å¸ƒçš„æ··åˆæ˜¯å®ç°è¿™äº›èƒ–å°¾éƒ¨çš„ä¸€ç§å¥½æ–¹æ³•ã€‚Markus
    Haas å’Œ Christian Pigorsch çš„æ–‡ç« [ã€Šé‡‘èç»æµå­¦ï¼Œèƒ–å°¾åˆ†å¸ƒã€‹](https://oreil.ly/XSxhB)æä¾›äº†ä¸€äº›å…¶ä»–èƒ–å°¾åˆ†å¸ƒçš„è‰¯å¥½å‚è€ƒã€‚
- en: Banks use PySpark and large-scale data processing frameworks for calculating
    VaR with historical methods as well. [â€œEvaluation of Value-at-Risk Models Using
    Historical Dataâ€](https://oreil.ly/0JoXu), by Darryll Hendricks, provides a good
    overview and performance comparison of historical VaR methods.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: é“¶è¡Œä½¿ç”¨ PySpark å’Œå¤§è§„æ¨¡æ•°æ®å¤„ç†æ¡†æ¶è®¡ç®—å†å²æ–¹æ³•çš„ VaRã€‚[â€œä½¿ç”¨å†å²æ•°æ®è¯„ä¼°é£é™©ä»·å€¼æ¨¡å‹â€](https://oreil.ly/0JoXu)ï¼Œç”±
    Darryll Hendricks ç¼–å†™ï¼Œæä¾›äº†å¯¹å†å² VaR æ–¹æ³•çš„æ¦‚è¿°å’Œæ€§èƒ½æ¯”è¾ƒã€‚
- en: Monte Carlo risk simulations can be used for more than calculating a single
    statistic. The results can be used to proactively reduce the risk of a portfolio
    by shaping investment decisions. For example, if in the trials with the poorest
    returns, a particular set of instruments tends to come up losing money repeatedly,
    we might consider dropping those instruments from the portfolio or adding instruments
    that tend to move in the opposite direction from them.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: è’™ç‰¹å¡æ´›é£é™©æ¨¡æ‹Ÿä¸ä»…å¯ä»¥ç”¨äºè®¡ç®—å•ä¸€ç»Ÿè®¡é‡ã€‚å…¶ç»“æœå¯ä»¥ç”¨äºé€šè¿‡å¡‘é€ æŠ•èµ„å†³ç­–æ¥ç§¯æé™ä½æŠ•èµ„ç»„åˆçš„é£é™©ã€‚ä¾‹å¦‚ï¼Œåœ¨é‚£äº›å›æŠ¥æœ€å·®çš„è¯•éªŒä¸­ï¼Œç‰¹å®šçš„ä¸€ç»„å·¥å…·å¯èƒ½ä¼šåå¤äºæŸï¼Œæˆ‘ä»¬å¯èƒ½è€ƒè™‘ä»æŠ•èµ„ç»„åˆä¸­å‰”é™¤è¿™äº›å·¥å…·ï¼Œæˆ–è€…æ·»åŠ é‚£äº›å€¾å‘äºä¸å®ƒä»¬ç›¸åæ–¹å‘ç§»åŠ¨çš„å·¥å…·ã€‚
