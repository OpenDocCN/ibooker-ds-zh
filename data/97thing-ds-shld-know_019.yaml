- en: Chapter 17\. First, Do No Harm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第17章。首先，不要伤害
- en: Eric Schmidt
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 艾瑞克·施密特
- en: '![](Images/Eric_Schmidt.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/Eric_Schmidt.png)'
- en: Global Director, Data & Analytics, Coca-Cola
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 可口可乐全球数据与分析总监
- en: It is October 2019, and I am presenting at a data science conference at the
    Historic Academy of Medicine in Atlanta, Georgia. Unceremoniously tucked away
    in a corner of the men’s room is a bust of Hippocrates, the father of professional
    ethics, and a plaque with the Hippocratic oath. The basic gist of the Hippocratic
    oath is *primum non nocere*, or “first, do no harm.” That is a pretty good generalization
    and represents an ethical framework that has stood for millennia. As a new profession,
    data science is just beginning to define our ethical framework.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是2019年10月，我正在亚特兰大历史医学学院参加一个数据科学会议。在男性洗手间的一个角落里，不起眼地摆放着希波克拉底的半身像，这位职业伦理学之父的半身像旁边还有一个写着希波克拉底誓言的牌匾。希波克拉底誓言的基本精神是*primum
    non nocere*，即“首先，不要伤害”。这是一个非常好的概括，代表了一个数千年来一直存在的伦理框架。作为一个新兴的专业领域，数据科学正处于定义我们伦理框架的初期阶段。
- en: 'As I stared at Hippocrates’s bust, I wanted to ask him: who defines ethics?
    Leaders of technology companies have been at the center of the public stage in
    this discussion, but I wonder if they are leveraging the wealth of established
    philosophy on ethics. Rather than inventing new frameworks, what could Larry Page,
    Sergey Brin, Mark Zuckerberg, Steve Jobs, Larry Ellison, Bill Gates, Jeff Bezos,
    or Jack Ma learn about data privacy or other modern ethical dilemmas from Socrates,
    Confucius, Hobbes, Locke, Kant, and Nietzsche? For example, Hobbes and Locke might
    argue over social contract theory to sway Zuckerberg toward more or less absolute
    government regulation. If we leave data science ethics to the technocrats and
    allow corporations to follow their nature, would they drive society to ruthlessness,
    as Hobbes might argue? Certainly, we can find evidence of this ruthlessness in
    corporate behavior.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当我凝视着希波克拉底的半身像时，我想问他：谁来定义伦理？科技公司的领导者一直在这个讨论的中心，但我想知道他们是否在利用已有的伦理哲学来解决这个问题。与其发明新的框架，拉里·佩奇、谢尔盖·布林、马克·扎克伯格、史蒂夫·乔布斯、拉里·埃里森、比尔·盖茨、杰夫·贝索斯或者马云能从苏格拉底、孔子、霍布斯、洛克、康德和尼采那里学到关于数据隐私或其他现代伦理困境的什么呢？例如，霍布斯和洛克可能会因社会契约理论的差异而试图说服扎克伯格朝着更或者更少绝对政府管制的方向发展。如果我们将数据科学的伦理问题留给技术官员，并允许公司按照它们的天性行事，他们会像霍布斯所说的那样驱使社会走向无情吗？当然，我们可以在企业行为中找到这种无情的证据。
- en: 'In most professions, practitioners define ethics. “Attorney-client privilege,”
    “protect and serve,” “seek the truth,” “do not reveal your source,” “serve the
    people”: these are all mottos that encapsulate a profession’s ethical code. While
    these codes might have some basis in the historical philosophy of ethics, professions
    develop their ethics with feedback from society, updating as standards evolve.
    The resulting ethical code is only as good as the practitioners’ interpretation
    of society. Further, ethical codes are effective only if professionals enforce
    them, and history has shown that doesn’t always happen. If we let data science
    practitioners define ethics for the field, would the members live up to and self-enforce
    those codes?'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数职业中，从业者定义了伦理。比如“律师与客户的保密权”，“保护与服务”，“寻求真相”，“不泄露你的消息来源”，“为人民服务”：这些口号都概括了一个职业的伦理准则。虽然这些准则可能在历史伦理哲学的基础上有些依据，但职业是在从社会中得到反馈的过程中发展出他们的伦理，随着标准的演变而更新。最终的伦理准则只有在从业者对其进行解释时才有效。此外，只有专业人士对其进行实施，历史表明这并不总是发生的。如果我们让数据科学从业者为该领域定义伦理，他们能够达到并自我实施这些准则吗？
- en: Maybe an ethical code is not even needed for the data science field. After all,
    how can math be unethical? 2 + 2 = 4, does it not? The equation does not care
    what inputs it is given; it objectively adds two numbers without bias. However,
    machine learning is more complex, and one argument is that data scientists may
    inadvertently create biased models if they use incomplete or nonrepresentative
    training data. In my opinion, that is an efficacy issue, not an ethics issue.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 或许数据科学领域甚至不需要伦理准则。毕竟，数学怎么可能不道德？2 + 2 = 4，不是吗？这个等式不在乎它得到了什么样的输入；它客观地将两个数相加而没有偏见。然而，机器学习更加复杂，一个论点是，如果数据科学家使用不完整或者不具代表性的训练数据，他们可能会无意中创建有偏见的模型。在我看来，这是一个效能问题，而不是伦理问题。
- en: If machine learning or artificial intelligence is not innately good or evil,
    then we should consider the application of data science. For example, we might
    consider using data science to identify a precancerous person for the purpose
    of marketing life insurance or recommending a medical checkup. Which use case
    is ethical? Are both cases acceptable as long as we save the patient’s life? If
    ethics is really about the application, then practitioners can simply adopt the
    ethics where it is being applied. The field may not need its own framework.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果机器学习或人工智能本质上既不是善也不是恶，那么我们应该考虑数据科学的应用。例如，我们可以考虑使用数据科学来识别患有癌前病变的人，以便推销人寿保险或推荐医疗检查。哪种用例是符合伦理的？只要我们能拯救患者的生命，这两种情况都可以接受吗？如果伦理真的关乎应用，那么从业者们可以简单地在应用的地方采纳伦理。这个领域可能不需要自己的框架。
- en: Perhaps the ethical question is who should have access to data science methods.
    In the 1990s, the technology race was all about computing power. The US government
    restricted exports of high-performance computers under the Export Administration
    Act of 1979 for national security reasons. Apple Computer used this situation
    to great effect when it released the Power Mac G4, “the first desktop supercomputer,”
    in 1999\. The premise, which may have been more marketing than reality, was that
    G4 exports should be restricted to prevent rogue nations from using the computer
    to develop nuclear or other advanced weapons. Building on that premise, should
    advanced data science methodologies be restricted to prevent rogue actors, organizations,
    or nations from doing harm? That would seem to be counter to the open source culture
    of data science, but as Locke might argue, voluntary sacrifice of some freedoms
    may be needed to ensure other more important freedoms. Ethics is hard and probably
    comes at some cost.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 或许伦理问题在于谁应该有权访问数据科学方法。在20世纪90年代，技术竞赛主要集中在计算能力上。美国政府出于国家安全原因限制了高性能计算机的出口，根据1979年出口管理法案。苹果计算机在1999年发布了Power
    Mac G4，“第一台桌面超级计算机”，充分利用了这种情况。这个前提，可能更多是营销而非现实，是G4的出口应受限制，以防止流氓国家使用计算机开发核武器或其他先进武器。基于这个前提，应该限制先进的数据科学方法，以防止流氓行为者、组织或国家造成伤害吗？这似乎与数据科学的开源文化背道而驰，但正如洛克可能会主张的那样，为了确保其他更重要的自由，可能需要自愿放弃一些自由。伦理很难，而且可能会有一些成本。
- en: 'A final thought: my question to Hippocrates’s bust still stands. Who should
    define ethics for data science—corporate leaders, the field of application, practitioners,
    or maybe an open source ethics AI? Given the complexity of today’s world, getting
    ethics right is a big challenge. A good place to start might be a simple golden
    rule like the one Hippocrates laid out for the medical profession a few thousand
    years ago: first, do no harm.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个想法：我对希波克拉底雕像的问题仍然存在。谁应该为数据科学定义伦理——企业领导、应用领域、从业者，还是可能是一个开源伦理人工智能？考虑到当今世界的复杂性，正确理解伦理是一个巨大的挑战。一个好的起点可能是像希波克拉底几千年前为医学界确立的简单黄金法则：首先，不要伤害他人。
