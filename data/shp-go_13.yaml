- en: 10 Advanced deployment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 高级部署
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Creating a Kubernetes cluster
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建 Kubernetes 集群
- en: Deploying an API in Kubernetes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中部署 API
- en: Deploying a database using Helm
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Helm 部署数据库
- en: Configuring your API to use the database
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置你的 API 以使用数据库
- en: '“If you look at these charts, you can see that our new service has actually
    helped drive more traffic to our services. Our mobile application team was able
    to whip together a quick application using some of the same techniques adopted
    for the translation service. This application has had wide adoption and is trending
    in all app stores. However, since the translation service is still running as
    an on-demand service, we find that it is more expensive than running dedicated
    servers, so we are left with two options: use a dedicated container orchestrator
    like Kubernetes or build dedicated virtual machines to run the service.”'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: “如果你看看这些图表，你会发现我们的新服务实际上帮助我们的服务吸引了更多的流量。我们的移动应用团队能够快速地使用为翻译服务采用的一些相同技术制作了一个应用程序。这个应用程序得到了广泛的应用，并且在所有应用商店中都有趋势。然而，由于翻译服务仍然作为一个按需服务运行，我们发现它比运行专用服务器更昂贵，所以我们只剩下两个选择：使用像
    Kubernetes 这样的专用容器编排器，或者构建专用虚拟机来运行服务。”
- en: Everyone looks at the graphs the DevOps lead is showing. There are some nods
    of an agreement, but the CTO finally speaks up.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 所有人都在看 DevOps 领导展示的图表。有一些表示同意的点头，但最终 CTO 发言了。
- en: “I thought the whole point was to move away from dedicated services and toward
    a ‘serverless’ approach. Won’t this reduce our delivery to market? Are there alternatives?”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: “我认为整个点是要从专用服务转向‘无服务器’方法。这不会减少我们的市场交付吗？有没有替代方案？”
- en: The DevOps lead advances the slide and says, “We have a longer-term goal of
    moving toward a container orchestration framework like Kubernetes. This is because
    we may not get 100% utilization out of a dedicated virtual machine to handle more
    applications on the same level or resources. We are working with various teams
    to start implementing container creation for their products so that we can host
    all of them on a Kubernetes, or K8S, cluster. However, none of us have worked
    with Kubernetes before, so there could be a bit of a learning curve. The alternative
    is to create custom images and deploy them to virtual machines. We call this the
    *classic deployment* process. It is error-prone right now because we have little
    process around it. However, we’ve learned from this process that having as much
    as possible in the repository helps with productivity overall, so we will adopt
    ‘infrastructure as code’ on some of our older services to help us maintain our
    infrastructure more clearly. Unfortunately, we don’t have anyone with experience
    in this area and are swamped, so we may rely a bit on the development team to
    get things started. Would that be okay?”
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps 领导推进了幻灯片并说：“我们有一个更长期的目标，即向 Kubernetes 这样的容器编排框架迈进。这是因为我们可能无法从处理相同级别或资源的更多应用程序的专用虚拟机中获得
    100% 的利用率。我们正在与各个团队合作，开始为他们的产品实施容器创建，这样我们就可以在 Kubernetes 或 K8S 集群上托管所有这些。然而，我们中没有人之前使用过
    Kubernetes，所以可能会有一个学习曲线。另一种选择是创建自定义镜像并将它们部署到虚拟机上。我们称之为*经典部署*过程。目前它容易出错，因为我们在这方面几乎没有流程。然而，我们从这一过程中学到了尽可能多的东西可以帮助提高整体生产力，所以我们将对我们的一些较旧服务采用‘基础设施即代码’，以帮助我们更清晰地维护基础设施。不幸的是，我们没有人有这方面的经验，而且我们很忙，所以我们可能需要依赖开发团队来开始这项工作。这样可以吗？”
- en: You smile and nod. The fact that these initiatives and ideologies are now starting
    to spread to other teams shows tremendous improvement overall by the company.
    Working on a more robust deployment process for the entire company can seem a
    little daunting, but it will be well worth the value.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你微笑点头。这些倡议和理念现在开始传播到其他团队，这表明公司整体上有了巨大的改进。为整个公司工作一个更健壮的部署流程可能看起来有点令人畏惧，但它将非常值得。
- en: “In an attempt to not seem too trendy, I think it’s worthwhile to do a research
    spike on both. Do you think you can get me some estimates of the level of work
    for the Kubernetes cluster first? If we can move the entire company in that direction,
    I think it will make sense for us financially, but we need to make sure it won’t
    monopolize developer time. We can then experiment with the infrastructure as code
    at a later date.”
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: “为了不显得太时髦，我认为对这两者都进行一次研究是很值得的。你认为你能给我一些关于 Kubernetes 集群的工程量估计吗？如果我们能将整个公司引向那个方向，我认为从财务上对我们来说是有意义的，但我们需要确保它不会垄断开发者的时间。我们可以在稍后日期尝试基础设施即代码。”
- en: 10.1 Not quite IaaS
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 并非完全的 IaaS
- en: We have come to a crossroads in our deployment progression. Remember that we
    are treating various abstractions with our deployments and using them as a service.
    In previous infrastructure chapters, we explored using a function as a service
    (FaaS), wherein a small, lightweight, on-demand application runs only when requested.
    We then moved to a platform as a service (PaaS), wherein we simply hand over our
    binary, and a server is magically created around it. Our last deployment used
    containers as a service (CaaS), wherein a container is built and run, giving us
    exposure to an underlying virtualized environment for more system-level integrations.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在部署进展中来到了一个十字路口。记住，我们在部署中处理各种抽象，并将它们用作服务。在之前的基础设施章节中，我们探讨了使用函数即服务（FaaS），其中一个小型、轻量级的按需应用程序仅在请求时运行。然后我们转向平台即服务（PaaS），我们只需提交我们的二进制文件，就会神奇地创建一个服务器。我们最后的部署使用了容器即服务（CaaS），其中容器被构建和运行，使我们能够接触到底层虚拟化环境，以便进行更多系统级别的集成。
- en: At this point, if you find that we need fewer abstractions and even more control,
    we can go one of two different ways. One is to go on a full Infrastructure as
    a Service (IaaS) route by building and running our physical infrastructure using
    virtual machines and load balancers to direct traffic to our application. The
    other way is to set up, run, and manage a container orchestration tool such as
    Kubernetes. In this chapter, we choose the latter because it is trendy due to
    its varied development toolset and developer-friendly interfaces. Appendix D briefly
    outlines the alternative for those who may want to take the true IaaS route. Instead,
    we are going to be in the middle of the IaaS and CaaS stacks shown in figure 10.1.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，如果你发现我们需要更少的抽象和更多的控制，我们可以选择两条不同的路径之一。一条是走完全的基础设施即服务（IaaS）路线，通过构建和运行我们的物理基础设施，使用虚拟机和负载均衡器将流量导向我们的应用程序。另一种方式是设置、运行和管理一个容器编排工具，如
    Kubernetes。在本章中，我们选择后者，因为它因其多样化的开发工具集和开发者友好的接口而流行。附录 D 简要概述了那些可能想要走真正的 IaaS 路线的替代方案。相反，我们将处于图
    10.1 所示的 IaaS 和 CaaS 栈的中间。
- en: '![](../../OEBPS/Images/CH10_F01_Holmes4.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F01_Holmes4.png)'
- en: Figure 10.1 We are now using our container as our shippable product.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 我们现在使用我们的容器作为我们的可运输产品。
- en: Kubernetes is not quite IaaS. It lives somewhere between the CaaS and IaaS realms.
    This is because Kubernetes handles much of the underlying infrastructure through
    abstractions. Features like node scaling and load balancing are all created and
    maintained by the Kubernetes cluster. As the developer, you are only concerned
    with defining the types of resources you want and submitting them to the cluster
    to then run. This building of resources in an abstract way is the core of IaaS.
    Tools like Terraform are used to maintain and build actual infrastructure, just
    like Kubernetes.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 并非完全等同于基础设施即服务（IaaS）。它存在于容器即服务（CaaS）和 IaaS 领域之间。这是因为 Kubernetes 通过抽象处理了大部分底层基础设施。例如，节点扩展和负载均衡等功能都是由
    Kubernetes 集群创建和维护的。作为开发者，你只需关注定义你想要的资源类型，并将它们提交给集群以运行。这种以抽象方式构建资源是 IaaS 的核心。像
    Terraform 这样的工具用于维护和构建实际的基础设施，就像 Kubernetes 一样。
- en: Instead of servers and load balancers, Kubernetes works with deployments and
    services. These abstractions allow Kubernetes to shift workloads across different
    server instances based on the load on the server. Kubernetes reduces a lot of
    the maintenance and management around your applications because it handles tasks
    such as load balancing, service restarts, and so on. Because of this, Kubernetes
    has become a very popular option for many teams that have scaled from on-demand
    to dedicated services for optimal uptime.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 与部署和服务一起工作，而不是服务器和负载均衡器。这些抽象允许 Kubernetes 根据服务器的负载在不同服务器实例之间移动工作负载。Kubernetes
    减少了围绕你的应用程序的大量维护和管理工作，因为它处理诸如负载均衡、服务重启等任务。正因为如此，Kubernetes 已经成为许多从按需服务扩展到专用服务以实现最佳正常运行时间的团队的非常受欢迎的选择。
- en: 10.2 Your first cluster
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 你的第一个集群
- en: We need to first create a cluster (see the following listing). Instead of installing
    Kubernetes locally, we will rely on GCP to create one for us. To do this, we will
    use the GCP tool.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要创建一个集群（见以下列表）。我们不会在本地安装 Kubernetes，而是将依靠 GCP 为我们创建一个。为此，我们将使用 GCP 工具。
- en: Listing 10.1 Creating a cluster
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.1 创建集群
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Creates the cluster in a given zone
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在指定区域创建集群
- en: ❷ Enables registry access for your containers
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为你的容器启用注册访问
- en: ❸ Installs the authentication plugin
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 安装身份验证插件
- en: ❹ Retrieves credentials for your cluster to be used in kubectl
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 检索用于 kubectl 的集群凭据
- en: NOTE If you don’t want to go through the hassle of setting up a cluster in the
    cloud, there are plenty of local tools, such as Minikube and KinD.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您不想在云中设置集群而感到麻烦，有许多本地工具可供选择，例如 Minikube 和 KinD。
- en: And you should have access to your nodes. That’s it. Google makes it very simple
    for you. If you wish to use another cloud provider, there may be additional steps.
    Now you are ready to deploy.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该能够访问您的节点。就是这样。Google 使这变得非常简单。如果您希望使用其他云提供商，可能会有额外的步骤。现在您已经准备好部署。
- en: For a full list of regions and zones that are closer to where you live, visit
    [http://mng.bz/91Ro](http://mng.bz/91Ro).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看更靠近您居住地区的所有地区和区域列表，请访问 [http://mng.bz/91Ro](http://mng.bz/91Ro)。
- en: 10.3 Building blocks
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 构建块
- en: 'You can find countless books, talks, and blog posts about Kubernetes and all
    of its building blocks, so I will not go into it here. We need to worry about
    two things: deployments and services. *Deployments* run a container or group of
    containers (*pods*) that scale (replica sets), which is exactly what GCP’s Cloud
    Run did for us in chapter 7\. A *service* creates an endpoint that directs calls
    to our deployment. This essentially acts as a load balancer that can distribute
    calls equally among multiple server instances.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以找到无数关于 Kubernetes 及其所有构建块的书、演讲和博客文章，所以在这里我不会深入讨论。我们需要关注两件事：部署和服务。*部署* 运行容器或容器组（Pod），这些容器可以扩展（副本集），这正是第
    7 章中 GCP 的 Cloud Run 为我们做的事情。*服务* 创建一个端点，将调用定向到我们的部署。这本质上充当了一个负载均衡器，可以在多个服务器实例之间平均分配调用。
- en: Let me explain each of these two core elements in more detail. A deployment
    can be thought of as a wrapper around two lower entity definitions for Kubernetes.
    Pods are groups of containers (a play on the Docker Whale; a group of whales is
    a pod). If you want more than one copy of your pod to run, wrap it in a *replica
    set*, which runs multiple instances of your pod. Finally, a deployment wraps the
    scaling in health checks and definitions to call the pod.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我更详细地解释这两个核心元素。部署可以被视为 Kubernetes 两个较低实体定义的包装器。Pod 是容器组（Docker Whale 的游戏；一组鲸鱼是一个
    Pod）。如果您想运行多个 Pod 实例，可以将它包装在一个 *副本集* 中，该副本集运行多个 Pod 实例。最后，部署将扩展、健康检查和调用 Pod 的定义包装起来。
- en: A service acts like a router to your application. It can be as simple as a forwarding
    port to your underlying application, similar to a DNS lookup that a browser does
    when loading a website or as complicated as a load balancer with specific rules
    for how to route calls for A/B testing or feature testing.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 服务充当您应用程序的路由器。它可以像将端口转发到底层应用程序一样简单，类似于浏览器在加载网站时进行的 DNS 查询，或者像具有特定路由规则的负载均衡器一样复杂，用于
    A/B 测试或功能测试。
- en: Both of these definitions lack a lot of detail, which should suffice for what
    we are trying to accomplish. However, I encourage you to look at Marko Luksa’s
    *Kubernetes in Action* (Manning, 2017) for more details.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个定义缺少很多细节，但对于我们试图实现的目标来说已经足够了。然而，我鼓励您查看 Marko Luksa 的 *Kubernetes in Action*（Manning，2017）以获取更多详细信息。
- en: Let’s start by creating our deployment. First, we need to create a new directory
    called `k8s` in your root directory and a directory beneath it for the service
    called `hello-api`. Here, we will create a new file called `deployment.yml`. In
    it, we need to write our deployment definition. The key is to have one instance
    of our container running. Luckily, we have a container image uploaded that we
    can use. The code in the following listing shows the deployment definition, which
    will be `/k8s/hello-api/deployment.yml`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建我们的部署开始。首先，我们需要在您的根目录中创建一个名为 `k8s` 的新目录，并在其下创建一个名为 `hello-api` 的服务目录。在这里，我们将创建一个名为
    `deployment.yml` 的新文件。在文件中，我们需要编写我们的部署定义。关键是让我们的容器运行一个实例。幸运的是，我们已经上传了一个容器镜像，我们可以使用它。以下列表中的代码显示了部署定义，它将是
    `/k8s/hello-api/deployment.yml`。
- en: Listing 10.2 `deployment.yml`
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.2 `deployment.yml`
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ The type of Kubernetes object we are creating
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们正在创建的 Kubernetes 对象类型
- en: ❷ The name of the deployment
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 部署的名称
- en: ❸ The number of pods to run
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 要运行的 Pod 数量
- en: ❹ This port matches what the container is listening on.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 此端口与容器监听的端口相匹配。
- en: ❺ How to reach this application
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 如何访问此应用程序
- en: Now we apply our deployment using `kubectl`. If it is not installed, you can
    do so by following the instructions on [https://kubernetes.io/docs/tasks/tools/](https://kubernetes.io/docs/tasks/tools/).
    Once installed, you simply need to run `kubectl` `apply` `-f` `k8s`, and all files
    in that directory will be applied. If we type `kubectl` `get` `pods`, we should
    now see our running API pod.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用`kubectl`应用我们的部署。如果它尚未安装，你可以按照[https://kubernetes.io/docs/tasks/tools/](https://kubernetes.io/docs/tasks/tools/)上的说明进行安装。安装后，你只需运行`kubectl`
    `apply` `-f` `k8s`，该目录下的所有文件都将被应用。如果我们输入`kubectl` `get` `pods`，我们现在应该能看到我们的运行API
    pod。
- en: Now let’s set up the service in `/k8s/hello-api/service.yml`. Our service is
    very simple, as it just needs to open a port to point to our deployment, as shown
    in the following listing.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将在`/k8s/hello-api/service.yml`中设置服务。我们的服务非常简单，因为它只需要打开一个端口指向我们的部署，如下面的列表所示。
- en: Listing 10.3 `service.yml`
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.3 `service.yml`
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ The Service type will route incoming requests to deployments.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 服务类型将路由传入请求到部署。
- en: ❷ The Load Balancer will utilize underlying cloud infrastructure to route messages
    to your deployment.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 负载均衡器将利用底层云基础设施将消息路由到你的部署。
- en: ❸ Maps to the port the deployment depends on
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 映射到部署依赖的端口
- en: Now we can call `apply` and see our service show up. We can test it by calling
    the endpoint provided at `kubectl` `describe` `service` `hello-api`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以调用`apply`来查看我们的服务是否出现。我们可以通过调用`kubectl` `describe` `service` `hello-api`提供的端点来测试它。
- en: 10.4 Scaling and health status
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 扩展和健康状态
- en: 'A service critical to any system should have some sort of redundancy. In software,
    you want your customers to avoid any downtime and be able to meet the demands
    that people are asking on your system. This is known as *scaling*: the system
    can grow to meet the demands put upon it by distributing the requests among several
    running services. In doing so, you reduce the chances of a system running out
    of memory or having long responses. There are two types of scaling: vertical and
    horizontal. *Vertical scaling* allows you to add more power to a machine to handle
    the increased load. *Horizontal scaling* allows you to create additional instances
    of servers to handle the load. In this section, we will focus on scaling horizontally
    for our deployments.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 任何系统中的关键服务都应该有一定的冗余。在软件中，你希望你的客户避免任何停机时间，并能够满足人们对你的系统提出的需求。这被称为*扩展*：系统可以通过在多个运行服务之间分配请求来增长以满足其需求。这样做可以减少系统耗尽内存或产生长时间响应的机会。有两种类型的扩展：垂直扩展和水平扩展。*垂直扩展*允许你向机器添加更多功率来处理增加的负载。*水平扩展*允许你创建额外的服务器实例来处理负载。在本节中，我们将关注对我们部署的水平扩展。
- en: We haven’t had to worry too much about scaling up to this point because the
    system we are deploying the application on has handled all of our scaling. If
    you were to make 1 million requests against our FaaS, PaaS, or CaaS services we
    put up, you would see that they have multiple running instances to handle the
    load. Meanwhile, our Kubernetes deployment would not be able to scale at this
    point because we haven’t given it the proper settings to do so. We will only focus
    on manual scaling and health checks here, but books like *Kubernetes in Action*
    can show you other methods.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们不必过多担心扩展问题，因为我们部署应用程序的系统已经处理了所有的扩展。如果你对我们的FaaS、PaaS或CaaS服务发起100万次请求，你会看到它们有多个运行实例来处理负载。同时，我们的Kubernetes部署在这个阶段无法扩展，因为我们还没有给它适当的设置来这样做。我们在这里将只关注手动扩展和健康检查，但像《Kubernetes
    in Action》这样的书籍可以展示其他方法。
- en: Again, we do not want outage time, so we need to allow Kubernetes to know when
    a deployment is ready so that it can shut down the old deployment. This is known
    as a *rolling deployment*. To do this, we tap into the health check endpoints
    we added in chapter 4\. Here, we will add liveness (Is the service running?) and
    readiness (Is it ready to receive requests?) checks. Both will let Kubernetes
    know that our pod is ready. To do this, we need to modify our deployment file
    by adding the code in the following listing.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们不希望出现中断时间，因此我们需要允许Kubernetes知道何时部署就绪，以便它可以关闭旧的部署。这被称为*滚动部署*。为此，我们将利用在第4章中添加的健康检查端点。在这里，我们将添加存活性（服务是否正在运行？）和就绪性（是否准备好接收请求？）检查。这两个检查都将让Kubernetes知道我们的pod已就绪。为此，我们需要通过添加以下列表中的代码来修改我们的部署文件。
- en: Listing 10.4 `deployment.yml`
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.4 `deployment.yml`
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ This call will check every 3 seconds to see if it is returning a 200 response.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这个调用将每3秒检查一次是否返回200响应。
- en: The liveness probe will check to see if the container is up and running, while
    the readiness probe will start directing traffic to the pod. In this instance,
    we will use the health endpoint. Here, we determine if the system is ready by
    checking if the HTTP server responds. If not, the pod will be shut down and a
    new one will start in its place.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 活性探测将检查容器是否已启动并运行，而就绪探测将开始将流量导向Pod。在这种情况下，我们将使用健康端点。在这里，我们通过检查HTTP服务器是否响应来确定系统是否就绪。如果没有响应，Pod将被关闭，并启动一个新的Pod来替代它。
- en: In this instance, our liveness probe and readiness probe are the same. This,
    however, is not always the case. Let’s say, for example, that you had two processes
    running in your pod, an API and a cache. Caches can sometimes be *warmed* or preloaded
    with data. In this case, the liveness probe would be healthy, but the pod would
    only be ready to accept messages after the cache was warmed. Think of it as starting
    your car versus putting it into gear. If either of the checks takes longer than
    expected, the pod will be deleted and a new one created to start the process over.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们的活性探测和就绪探测是相同的。然而，这并不总是如此。比如说，如果你的Pod中运行了两个进程，一个API和一个缓存。缓存有时可以被*预热*或预加载数据。在这种情况下，活性探测将是健康的，但Pod只有在缓存预热后才能准备好接受消息。想象一下，这是启动你的车与将其挂入档位之间的区别。如果任何一个检查耗时超过预期，Pod将被删除，并创建一个新的Pod来重新启动进程。
- en: With the liveness and readiness probes in place, we can now scale the service
    by adding replicas. To do this, we just need to edit one line, as shown in the
    following listing.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置了活性和就绪探测之后，我们现在可以通过添加副本来扩展服务。为此，我们只需编辑一行，如下所示。
- en: Listing 10.5 `deployment.yml`
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.5 `deployment.yml`
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Increases the number of instances to 3
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将实例数量增加到3
- en: This will create three separate pods for this service. Commit these changes.
    We will be able to see how all this works after we create automatic deployments.
    But at the moment, Kubernetes gives us the control to add and remove advanced
    deployment practices with a few lines of code. In the past, this configuration
    would have been difficult to maintain and monitor because you would have been
    dealing with physical machines, load balancers, and monitoring tools. Instead,
    Kubernetes provides all of this for you so that you can get started on deploying.
    Because it is all code, it becomes much easier for us to update our deployments.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为该服务创建三个独立的Pod。提交这些更改。我们将在创建自动部署后看到这一切是如何工作的。但到目前为止，Kubernetes通过几行代码就给了我们添加和删除高级部署实践的控制权。在过去，这种配置难以维护和监控，因为你需要处理物理机器、负载均衡器和监控工具。相反，Kubernetes为你提供了所有这些，以便你可以开始部署。因为一切都是代码，所以我们更新部署变得更加容易。
- en: 10.5 Automatically deploying
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 自动部署
- en: In the past, we deployed our code when we merged to main. This gave our customers
    the bleeding edge of our development each time we merged our pull requests. However,
    in chapter 8, we introduced the concept of tags, which allow us to mark a deployment
    as stable. With this stability, we can easily track what code has been deployed
    and what fixes and features we can target for future releases. Once this cadence
    is established, we can easily estimate the time it takes to deliver new releases
    to our customers.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，我们在合并到主分支时部署我们的代码。这使我们的客户每次合并拉取请求时都能获得我们开发的最新成果。然而，在第8章中，我们介绍了标签的概念，它允许我们标记一个部署为稳定。有了这种稳定性，我们可以轻松跟踪已经部署的代码以及我们可以针对未来版本的目标修复和功能。一旦这种节奏建立起来，我们就可以轻松估计向客户交付新版本所需的时间。
- en: All of this is to say is that tagging your products and codebases is extremely
    important. It also meshes well with our containerized releases because containers
    also use release tags. Our deployment code has a reference to a `latest` tag,
    which loosely translates to “I don’t care what version it is; I want the newest.”
    We feel like we have moved past this point (maybe this would be a good setup for
    a development environment!) and now want to tag, so we should create a container
    build process that pushes a new tagged version of our container when our code
    is tagged. We will use the same tagging strategy we discussed in chapter 8, but
    this will also be based on what your team decides. Let’s modify our code to do
    that, as in the following listing.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都是为了说明标记你的产品和代码库非常重要。这也很好地与我们的容器化发布相结合，因为容器也使用发布标签。我们的部署代码有一个指向 `latest`
    标签的引用，这可以松散地翻译为“我不在乎是什么版本；我想要最新的。”我们感觉我们已经超过了这一点（这可能是一个开发环境的好设置！）现在我们想要标记，因此我们应该创建一个容器构建过程，当我们的代码被标记时，它会推送一个新的标记版本。我们将使用在第
    8 章中讨论的相同的标记策略，但这也将基于你团队的决定。让我们修改我们的代码来实现这一点，如下所示。
- en: Listing 10.6 `pipeline`
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.6 `pipeline`
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s try it out:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试看：
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should see a new container tagged and pushed to GCP. Now that we can tag
    our containers, we need to have a process of updating our deployment. There are
    two rules of thought with managing these types of deployments: automated or retroactive.
    In the automated world, you create a process that runs `apply` whenever a file
    is changed in the K8s directory. This means that you change the code, and the
    pipeline keeps track of the cluster credentials and state. This is a great place
    to get to, but until those processes are clearly defined and working efficiently,
    many will update their repo with the applied changes retroactively. This is typically
    done by putting a PR up with the changes and waiting for approval. Once it’s approved,
    you apply the code and then merge.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该会看到一个新容器被标记并推送到 GCP。现在我们能够标记我们的容器，我们需要有一个更新部署的过程。在管理这类部署时，有两种思考规则：自动化或事后。在自动化世界中，你创建一个过程，每当
    K8s 目录中的文件发生变化时，就会运行 `apply`。这意味着你更改了代码，而管道会跟踪集群凭据和状态。这是一个很好的地方，但直到那些过程被明确定义并且高效运行，许多人会事后将已应用的变化更新到仓库中。这通常是通过提交一个包含更改的
    PR 并等待批准来完成的。一旦批准，你应用代码然后合并。
- en: We now have a CD process in place using Kubernetes. We aren’t running our production-level
    system. To do that, we need our database and configuration.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经在 Kubernetes 上建立了一个 CD 流程。我们并没有运行我们的生产级系统。为了做到这一点，我们需要数据库和配置。
- en: 10.6 Deploying Redis using Helm
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.6 使用 Helm 部署 Redis
- en: Many platforms like Kubernetes that use infrastructure as code allow additional
    tools and abstractions to extend it or be built on top of it. In this case, Kubernetes
    works well with a tool called Helm. Helm is like a package manager but for your
    Kubernetes cluster. It will use a similar deployment mechanism known as a Helm
    Chart to deploy applications. Helm charts are used mostly for out-of-the-box functionality
    in production but can be tweaked to suit your needs.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 许多像 Kubernetes 这样的平台，使用基础设施即代码，允许额外的工具和抽象来扩展它或在其之上构建。在这种情况下，Kubernetes 与一个名为
    Helm 的工具配合得很好。Helm 就像是一个包管理器，但用于你的 Kubernetes 集群。它将使用一个称为 Helm 图表的类似部署机制来部署应用程序。Helm
    图表主要用于生产中的开箱即用功能，但可以根据你的需求进行调整。
- en: In this instance, we will use Helm to deploy Redis for our cluster, but first
    we need to install Helm. To do so, follow the instructions at [https://helm.sh/docs/intro/install/](https://helm.sh/docs/intro/install/).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用 Helm 为我们的集群部署 Redis，但首先我们需要安装 Helm。为此，请遵循[https://helm.sh/docs/intro/install/](https://helm.sh/docs/intro/install/)中的说明。
- en: I’m hoping that you have been wondering where our Makefile was for this section.
    We need it now to help us manage our deployments. First, we will create the Helm
    deployment and then the steps to deploy our app. Helm allows us to configure our
    deployments by passing specific settings as we apply the chart. These settings
    are often things like scaling or security values. In our case, we want our Redis
    database to be secure by using a password. To do that, we edit our Makefile so
    that we can have a deployment command with some configurations (see the following
    listing).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你在想我们这个部分的 Makefile 在哪里。我们现在需要它来帮助我们管理部署。首先，我们将创建 Helm 部署，然后是部署我们的应用程序的步骤。Helm
    允许我们在应用图表时通过传递特定的设置来配置我们的部署。这些设置通常是像扩展或安全值这样的东西。在我们的例子中，我们希望我们的 Redis 数据库通过使用密码来保证安全。为此，我们编辑我们的
    Makefile，以便我们可以有一个带有一些配置的部署命令（见以下列表）。
- en: Listing 10.7 Makefile
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.7 Makefile
- en: '[PRE7]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Uses a specialized Kubernetes deployment of Redis
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用专门的 Kubernetes Redis 部署
- en: ❷ Generates a random password to use
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 生成一个随机密码使用
- en: Run `make install-k8s-redis`, and we should be able to watch the new pods come
    online. The database is now running, so we can configure our system to run against
    it. For that, we need to create a configuration map.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `make install-k8s-redis`，我们应该能够看到新的 pod 上线。数据库现在正在运行，因此我们可以配置我们的系统以针对它运行。为此，我们需要创建一个配置映射。
- en: 10.7 Updating deployment configuration
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.7 更新部署配置
- en: In chapter 8, we went through the work of making our application change its
    functionality through configuration. Now we can use this same mechanism using
    Kubernetes. Since Kubernetes clusters do not consist of a single machine, we can’t
    simply set environmental variables on each system, nor can we add a configuration
    file to the individual server.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 8 章中，我们讨论了通过配置使我们的应用程序改变其功能的工作。现在我们可以使用 Kubernetes 的相同机制。由于 Kubernetes 集群不是由单个机器组成的，我们无法简单地在每个系统上设置环境变量，也无法将配置文件添加到单个服务器上。
- en: Instead, Kubernetes treats this as a resource, just like a deployment or service.
    We can create and reference a *configuration map*, which defines a set of similarly
    used configuration values that decouple our environmental variables from the consuming
    container. This means we will have a configuration map for our service to consume.
    Since we are now in production, we should also consider updating our Redis server
    by using a special configuration type called a *secret*. First, let’s make our
    map.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，Kubernetes 将其视为一种资源，就像部署或服务一样。我们可以创建和引用一个 *配置映射*，它定义了一组类似使用的配置值，将我们的环境变量与消费容器解耦。这意味着我们将有一个配置映射供我们的服务消费。由于我们现在处于生产状态，我们还应该考虑通过使用称为
    *密钥* 的特殊配置类型来更新我们的 Redis 服务器。首先，让我们制作我们的映射。
- en: Configuration maps are just like any other Kubernetes resource in that we can
    create them using a file. Let’s create a new `config.yml` file under the `k8s/hello-api`
    directory. In it, we will add the code in the following listing.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 配置映射就像 Kubernetes 中的任何其他资源一样，我们可以通过文件来创建它们。让我们在 `k8s/hello-api` 目录下创建一个新的 `config.yml`
    文件。在其中，我们将添加以下列表中的代码。
- en: Listing 10.8 `config.yml`
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.8 `config.yml`
- en: '[PRE8]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Sets ENV vars in the config map
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在配置映射中设置环境变量
- en: Apply it by typing `kubectl` `apply` `-f` `k8s/hello-api/config.yml`, and you
    should see a notification that a new resource was created.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 通过输入 `kubectl apply -f k8s/hello-api/config.yml` 来应用它，你应该会看到一个通知，表明已创建了一个新资源。
- en: Before we attach the configuration to our service, we should also create a secret
    for our Redis server. Secrets are a little different than configuration maps in
    that you don’t want to store them as files on our system because of a security
    risk, nor do you want to make them easily visible within our cluster.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将配置附加到我们的服务之前，我们还应该为我们的 Redis 服务器创建一个密钥。与配置映射不同，你不希望因为安全风险而将它们作为文件存储在我们的系统上，也不希望使它们在我们的集群中容易可见。
- en: NOTE While Kubernetes has a special field called a secret, it does not mean
    this is encrypted or secure, only that it is obfuscated from the end user. A robust
    production system should consider a secret manager like Vault.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：虽然 Kubernetes 有一个称为“密钥”的特殊字段，但这并不意味着它是加密或安全的，只是意味着它对最终用户是隐藏的。一个健壮的生产系统应该考虑使用
    Vault 这样的密钥管理器。
- en: Secrets are mostly used for things like usernames and passwords. They don’t
    need to be like your email or bank login that you need to remember. Instead, as
    we saw earlier, we can provide a random string to be the password, and Kubernetes
    will manage it for us. When we created our Redis deployment, a password was provided.
    We don’t need it; we can just reference it in the same way as a configuration
    map. To put these values in our deployment, we need to set some environmental
    variables. Let’s open that and add the code in the following listing.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 机密通常用于像用户名和密码这样的东西。它们不需要像您需要记住的电子邮件或银行登录信息一样。相反，正如我们之前看到的，我们可以提供一个随机字符串作为密码，Kubernetes将为我们管理它。当我们创建我们的Redis部署时，提供了一个密码。我们不需要它；我们可以像配置映射一样引用它。为了将这些值放入我们的部署中，我们需要设置一些环境变量。让我们打开它，并在下面的列表中添加代码。
- en: Listing 10.9 `deployment.yml`
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.9 `deployment.yml`
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Sets DB URL from the configuration map
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从配置映射设置DB URL
- en: ❷ Sets Password from the Helm secret
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从Helm机密设置密码
- en: 'These values should match the values we had in our application configuration
    when we run this locally. The configuration values get loaded into the containers
    as they start. To see this work now, we can simply reapply our deployment using
    `kubectl apply` `-f` `k8s`. Once it is running, we can verify the results by querying
    against the database by trying a query in a different language:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值应该与我们本地运行应用程序配置时拥有的值匹配。配置值在容器启动时被加载。为了现在看到这个工作，我们可以简单地使用`kubectl apply` `-f`
    `k8s`重新应用我们的部署。一旦它运行起来，我们可以通过尝试用不同的语言进行查询来查询数据库以验证结果：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Hopefully, you see the proper translation!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您看到的是正确的翻译！
- en: It’s now Friday, two weeks since you started this whole project, and less than
    a day from the Kubernetes kickoff meeting. You sit down and draft a quick email
    to the team telling them your status and drafting your findings in a design document
    to help the team move forward. Smiling, you reflect on how far your company has
    come. You’ve helped create a culture of experimentation while maintaining standards
    and easing development. Everyone seems pleased, but you know it will not be perfect.
    Things will need to change, new applications will need to be developed, and hopefully
    you will be able to help.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是星期五，距离您开始这个整个项目已经两周，距离Kubernetes启动会议不到一天。您坐下来，给团队发了一封快速电子邮件，告诉他们您的状态，并在设计文档中草拟了您的发现，以帮助团队前进。微笑着，您反思了公司走了多远。您在保持标准的同时帮助创造了一种实验文化，并简化了开发过程。每个人都看起来很满意，但您知道这不会完美。事情需要改变，需要开发新的应用程序，并且希望您能够提供帮助。
- en: Summary
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Kubernetes clusters abstract deployments across multiple servers managed by
    your team.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes集群抽象化了由您的团队管理的多个服务器上的部署。
- en: Deployments create groups of containers called pods that can scale depending
    on demand or required availability.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署创建了一组称为pods的容器组，可以根据需求或所需的可用性进行扩展。
- en: Services route calls to deployments.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务将调用路由到部署。
- en: Secrets and configuration files can be used to populate environmental variables
    for application configuration.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机密和配置文件可以用来填充应用程序配置的环境变量。
