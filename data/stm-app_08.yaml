- en: Chapter 9\. Trident
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第9章\. Trident
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Trident and why it’s useful
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident及其为何有用
- en: Trident operations and streams as a series of batched tuples
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Trident操作和流作为一系列批处理元组
- en: Kafka, its design, and how it aligns with Trident
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka，其设计以及如何与Trident相匹配
- en: Implementing a Trident topology
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现Trident拓扑
- en: Using Storm’s distributed remote procedure call (DRPC) functionality
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Storm的分布式远程过程调用（DRPC）功能
- en: Mapping native Storm components to Trident operations via the Storm UI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Storm UI将原生Storm组件映射到Trident操作
- en: Scaling a Trident topology
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展Trident拓扑
- en: 'We’ve come a long way in *Storm Applied*. Way back in [chapter 2](kindle_split_010.html#ch02)
    we introduced Storm’s primitive abstractions: bolts, spouts, tuples, and streams.
    Over the course of the first six chapters, we dug into those primitives, covering
    higher-level topics such as guaranteed message processing, stream groupings, parallelism,
    and so much more. [Chapter 7](kindle_split_015.html#ch07) provided a cookbook
    approach to identifying various types of resource contention, whereas [chapter
    8](kindle_split_016.html#ch08) took you to a level of abstraction below Storm’s
    primitive abstractions. Understanding all of these concepts is essential to mastering
    Storm.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在《Storm应用》中我们已经走得很远了。早在[第2章](kindle_split_010.html#ch02)中，我们就介绍了Storm的基本抽象：bolt、spout、元组和流。在前六章中，我们深入探讨了这些基本抽象，涵盖了高级主题，如保证消息处理、流分组、并行性以及更多。[第7章](kindle_split_015.html#ch07)提供了一种烹饪法来识别各种类型的资源竞争，而[第8章](kindle_split_016.html#ch08)则带你进入Storm基本抽象之下的抽象层次。理解所有这些概念对于掌握Storm至关重要。
- en: 'In this chapter we’ll introduce Trident, the high-level abstraction that sits
    on top of Storm’s primitives, and discuss how it allows you to express a topology
    in terms of the “what” instead of the “how.” We’ll explain Trident within the
    context of a final use case: an internet radio application. But rather than start
    with the use case as we have in previous chapters, we’ll start by explaining Trident.
    Because Trident is a higher-level abstraction, we feel understanding that abstraction
    before designing a solution for the use case makes sense, as that understanding
    may influence the design for our internet radio topology.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍Trident，这是位于Storm基本抽象之上的高级抽象，并讨论它如何允许你用“是什么”而不是“怎么做”来表述拓扑。我们将在一个最终用例的背景下解释Trident：一个互联网广播应用程序。但与我们在前几章中一样，我们从解释Trident开始。因为Trident是一个高级抽象，我们在设计用例解决方案之前理解这个抽象是有意义的，因为这种理解可能会影响我们互联网广播拓扑的设计。
- en: This chapter will start with an explanation of Trident and its core operations.
    We’ll then talk about how Trident handles streams as a series of batches, which
    is different than native Storm topologies, and why Kafka is a perfect match for
    Trident topologies. At that point we’ll break out a design for our internet radio
    application followed by its associated implementation, which will include Storm’s
    DRPC functionality. Once we have the implementation, we’ll discuss scaling a Trident
    topology. After all, Trident is simply an abstraction that still results in a
    topology that must be tweaked and tuned for maximum performance.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将从解释Trident及其核心操作开始。然后，我们将讨论Trident如何处理流作为一系列批次，这与原生的Storm拓扑不同，以及为什么Kafka是Trident拓扑的完美匹配。到那时，我们将为我们的互联网广播应用程序制定一个设计，然后是相关的实现，其中包括Storm的DRPC功能。一旦我们有了实现，我们将讨论扩展Trident拓扑。毕竟，Trident只是一个抽象，但最终结果仍然是一个必须调整和优化以实现最佳性能的拓扑。
- en: Without further ado, we’ll introduce you to Trident, the abstraction that sits
    on top of Storm’s primitives.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 不再拖延，我们将向您介绍Trident，这是位于Storm基本抽象之上的抽象。
- en: 9.1\. What is Trident?
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1\. 什么是Trident？
- en: Trident is an abstraction on top of Storm primitives. It allows you to express
    a topology in terms of the “what” (declarative) as opposed to the “how” (imperative).
    To achieve this, Trident provides operations such as joins, aggregations, groupings,
    functions, and filters, along with providing primitives for doing stateful, incremental
    processing on top of any database or persistence store. If you’re familiar with
    high-level batch-processing tools like Pig or Cascading, the concepts of Trident
    will be familiar to you.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Trident是建立在Storm基本抽象之上的抽象。它允许你用“是什么”（声明式）而不是“怎么做”（命令式）来表述拓扑。为了实现这一点，Trident提供了诸如连接、聚合、分组、函数和过滤器等操作，并提供在任意数据库或持久化存储上执行有状态、增量处理的原语。如果你熟悉像Pig或Cascading这样的高级批处理工具，Trident的概念对你来说将是熟悉的。
- en: What does it mean to express computations using Storm in terms of *what* you
    want to accomplish rather than *how*? We’ll answer this question by taking a look
    at how we built the GitHub commit count topology in [chapter 2](kindle_split_010.html#ch02)
    and comparing it to a Trident version of this same topology. As you may remember
    from [chapter 2](kindle_split_010.html#ch02), the goal of the GitHub commit count
    topology was to read in a stream of commit messages, where each message contained
    an email, and keep track of the count of commits for each email.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Storm表达计算，用你想要完成的“是什么”而不是“如何”来表示，这意味着什么？我们将通过查看我们在第二章 [kindle_split_010.html#ch02]
    中构建的GitHub提交计数拓扑以及将其与这个拓扑的Trident版本进行比较来回答这个问题。你可能还记得，第二章 [kindle_split_010.html#ch02]
    中GitHub提交计数拓扑的目标是从包含电子邮件的提交消息流中读取，并跟踪每个电子邮件的提交计数。
- en: '[Chapter 2](kindle_split_010.html#ch02) described the GitHub commit count topology
    in terms of how to count commit messages per email. It was a mechanical, imperative
    process. The following listing shows the code for building this topology.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第二章](kindle_split_010.html#ch02) 以如何按电子邮件计数提交消息的术语描述了GitHub提交计数拓扑。这是一个机械的、命令式的过程。下面的列表显示了构建此拓扑的代码。'
- en: Listing 9.1\. Building a GitHub commit count Storm topology
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.1\. 构建GitHub提交计数Storm拓扑
- en: '![](209fig01_alt.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](209fig01_alt.jpg)'
- en: Looking at how this topology is built, you can see that we ![](1.jpg) assign
    a spout to the topology to listen for commit messages, ![](2.jpg) define our first
    bolt to extract emails from each commit message, ![](3.jpg) tell Storm how tuples
    are sent between our spout and first bolt, ![](4.jpg) define our second bolt that
    keeps a running count of the number of emails, and end with ![](5.jpg), where
    we tell Storm how tuples are sent between our two bolts.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看这个拓扑的构建方式，你可以看到我们 ![](1.jpg) 将一个spout分配给拓扑以监听提交消息，![](2.jpg) 定义我们的第一个bolt从每个提交消息中提取电子邮件，![](3.jpg)
    告诉Storm元组如何在我们的spout和第一个bolt之间发送，![](4.jpg) 定义我们的第二个bolt，它保持电子邮件数量的运行计数，并以 ![](5.jpg)
    结尾，在那里我们告诉Storm元组如何在我们的两个bolt之间发送。
- en: Again, this is a mechanical process, one that’s specific to “how” we’re solving
    the commit count problem. The code in the listing is easy to follow because the
    topology itself isn’t complicated. But that may not be the case when looking at
    more complicated Storm topologies; understanding what’s being done at a higher
    level can become difficult.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这同样是一个机械的过程，一个特定于“我们如何”解决提交计数问题的过程。列表中的代码易于理解，因为拓扑本身并不复杂。但是，当查看更复杂的Storm拓扑时，可能就不是这样了；在更高层次上理解正在执行的操作可能会变得困难。
- en: This is where Trident helps. With its various concepts of “join,” “group,” “aggregate,”
    and so forth, we express computations at a higher level than bolts or spouts,
    making it easier to understand what’s being done. Let’s show what we mean by taking
    a look at a Trident version of the GitHub commit count topology. Notice how the
    code is expressed more in terms of the “what” we’re doing rather than “how” it’s
    being done in the following listing.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Trident如何帮助的地方。通过其“连接”、“分组”、“聚合”等概念，我们在比bolt或spout更高的层次上表达计算，这使得理解正在执行的操作变得更容易。让我们通过查看GitHub提交计数拓扑的Trident版本来展示我们的意思。注意在下面的列表中，代码更多地以我们正在做的“是什么”而不是“如何”执行来表达。
- en: Listing 9.2\. Building a GitHub commit count Trident topology
  id: totrans-22
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.2\. 构建GitHub提交计数Trident拓扑
- en: '![](209fig02_alt.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](209fig02_alt.jpg)'
- en: Once you understand Trident’s concepts, it’s much easier to understand our computation
    than if we expressed it in terms of spouts and bolts. Even without a great deal
    of understanding of Trident, we can see that we ![](1.jpg) create a stream coming
    from a spout, and for each entry in the stream ![](2.jpg), we split the field
    `commit` into a number of `email` field entries, group like emails together ![](3.jpg),
    and persist a count of the emails ![](4.jpg).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你理解了Trident的概念，理解我们的计算就比如果我们用spouts和bolts来表示它要容易得多。即使没有对Trident有太多的理解，我们也可以看到我们
    ![](1.jpg) 创建一个从spout来的流，对于流中的每个条目 ![](2.jpg)，我们将`commit`字段分割成多个`email`字段条目，将类似的电子邮件分组
    ![](3.jpg)，并持久化电子邮件的数量 ![](4.jpg)。
- en: If we were to come across the code in this listing, we’d have a much easier
    time understanding what was going on compared to the equivalent code using the
    Storm primitives we have so far. We’re expressing our computation at much closer
    to a pure “what” level with far less “how” mixed in.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们遇到这个列表中的代码，与迄今为止使用的Storm原语等价的代码相比，我们会更容易理解正在发生的事情。我们以更接近纯“是什么”的水平表达我们的计算，其中混合了更少的“如何”。
- en: The code in this listing touches on a few of Trident’s abstractions that help
    you write code that expresses the “what” instead of the “how.” Let’s take a look
    at the full range of the operations Trident provides.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 列表中的代码涉及了Trident的一些抽象，这些抽象可以帮助你编写表达“是什么”而不是“如何做”的代码。让我们看看Trident提供的操作的全范围。
- en: 9.1.1\. The different types of Trident operations
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.1.1. 不同类型的Trident操作
- en: We have a vague idea of what it means to use Trident to express our code in
    terms of the “what” instead of the “how.” In the code in the previous section,
    we had a Trident spout emit a stream to be transformed by a series of Trident
    operations. The combination of these operations adds up to form a Trident topology.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对使用Trident以“是什么”而不是“如何做”的方式来表达我们的代码有一个模糊的概念。在前一节的代码中，我们有一个Trident spout发出一个流，该流将被一系列Trident操作转换。这些操作的组合构成了一个Trident拓扑。
- en: This sounds similar to a Storm topology built on top of Storm’s primitives (spouts
    and bolts), except that we’ve replaced a Storm spout with a Trident spout and
    Storm bolts with Trident operations. This intuition isn’t true. It’s important
    to understand that Trident operations don’t directly map to Storm primitives.
    In a native Storm topology, you write your code within a bolt that performs your
    operation(s). You’re given a unit of execution that’s a bolt and you’re afforded
    the freedom to do whatever you see fit within that. But with Trident, you don’t
    have that flexibility. You’re provided with a series of stock operations and need
    to figure out how to map your problem onto one or more of these stock operations,
    most likely chaining them together.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来与建立在Storm原始操作（spouts和bolts）之上的Storm拓扑相似，但不同的是，我们用Trident spout替换了Storm spout，用Trident操作替换了Storm
    bolts。这种直觉是不正确的。重要的是要理解Trident操作并不直接映射到Storm原始操作。在原生的Storm拓扑中，你在一个执行你的操作（s）的bolt中编写你的代码。你得到的是一个bolt的执行单元，你可以在其中自由地做任何你想做的事。但与Trident不同，你没有这种灵活性。你提供了一系列标准操作，并需要找出如何将你的问题映射到这些标准操作之一或多个，很可能是将它们链接在一起。
- en: 'Many different Trident operations are available that you can use to implement
    your functionality. From a high level, they can be listed as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的不同Trident操作很多，你可以使用它们来实现你的功能。从高层次来看，它们可以列出如下：
- en: '***Functions*—** Operate on an incoming tuple and emit one or more corresponding
    tuples.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***函数*—** 对进入的元组进行操作并发出一个或多个相应的元组。'
- en: '***Filters*—** Decide to keep or filter out an incoming tuple from the stream.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***过滤器*—** 决定保留或过滤掉从流中进入的元组。'
- en: '***Splits*—** Splitting a stream will result in multiple streams with the same
    data and fields.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***分割*—** 分割流将导致多个具有相同数据和字段的流。'
- en: '***Merges*—** Streams can be merged only if they have the same fields (same
    field names and same number of fields).'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***合并*—** 只有当流具有相同的字段（相同的字段名称和相同数量的字段）时，才能合并流。'
- en: '***Joins*—** Joining is for different streams with mostly different fields,
    except for one or more common field(s) to join on (similar to a SQL join).'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***连接*—** 连接用于具有大部分不同字段的不同流，除了一个或多个用于连接的公共字段（类似于SQL连接）。'
- en: '***Grouping*—** Group by specific field(s) within a partition (more on partitions
    later).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***分组*—** 在分区内部按特定字段（s）进行分组（关于分区的更多内容稍后讨论）。'
- en: '***Aggregation*—** Perform calculations for aggregating sets of tuples.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***聚合*—** 对元组集进行计算。'
- en: '***State updater*—** Persist tuples or calculated values to a datastore.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***状态更新器*—** 将元组或计算值持久化到数据存储。'
- en: '***State querying*—** Query a datastore.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***状态查询*—** 查询数据存储。'
- en: '***Repartitioning*—** Repartition the stream by hashing on specific field(s)
    (similar to a fields grouping) or in a random manner (similar to a shuffle grouping).
    Repartitioning by hashing on some specific field(s) is different from grouping
    in that repartitioning happens across all partitions whereas grouping happens
    within a single partition.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***重新分区*—** 通过对特定字段（类似于字段分组）进行哈希或以随机方式（类似于洗牌分组）重新分区流。通过某些特定字段进行重新分区与分组不同，因为重新分区发生在所有分区上，而分组发生在单个分区内。'
- en: Representing your problem as a series of these operations allows you to think
    and reason at a much higher level than what the native Storm primitives allow.
    It also makes the Trident API for wiring in these different operations together
    feel much like a domain-specific language (DSL). For example, let’s say you have
    a step where you need to save your calculated results to a datastore. At that
    step, you’d wire in a *state updater* operation. Whether that state updater operation
    is writing to Cassandra, Elasticsearch, or Redis is completely irrelevant. In
    fact, you can have a state updater operation that writes to Redis and share that
    among different Trident topologies.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将你的问题表示为一系列这些操作，可以使你比本地Storm原语允许的更高层次地思考和推理。这也使得将这些不同操作连接在一起的Trident API感觉更像是一种领域特定语言（DSL）。例如，假设你有一个需要将计算结果保存到数据存储的步骤。在那个步骤中，你会连接一个*状态更新器*操作。无论该状态更新器操作是写入Cassandra、Elasticsearch还是Redis，这都完全无关紧要。实际上，你可以有一个写入Redis的状态更新器操作，并在不同的Trident拓扑之间共享它。
- en: 'Hopefully you’re starting to gain an understanding of the types of abstractions
    Trident provides. Don’t worry about how these various operations are implemented
    right now. We’ll cover that soon when we dig into the design and implementation
    of our internet radio topology. But before we get into designing that topology,
    we need to cover one more topic: how Trident handles streams. This is fundamentally
    different from how a native Storm topology handles streams and will influence
    the design of our internet radio topology.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你已经开始理解Trident提供的抽象类型。现在不必担心这些各种操作是如何实现的。当我们深入研究我们的互联网广播拓扑的设计和实现时，我们很快就会介绍这一点。但在我们开始设计该拓扑之前，我们需要覆盖一个额外的主题：Trident如何处理流。这与本地Storm拓扑处理流的方式根本不同，并将影响我们互联网广播拓扑的设计。
- en: 9.1.2\. Trident streams as a series of batches
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.1.2. Trident流作为一系列批次
- en: One fundamental difference between a Trident topology and a native Storm topology
    is that within a Trident topology, streams are handled as batches of tuples, whereas
    in a native Storm topology, streams are handled as a series of individual tuples.
    This means that each Trident operation processes a batch of tuples whereas each
    native Storm bolt executes on a single tuple. [Figure 9.1](#ch09fig01) provides
    an illustration of this.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Trident拓扑与本地Storm拓扑之间的一个基本区别是，在Trident拓扑中，流被处理为元组批次，而在本地Storm拓扑中，流被处理为一系列单个元组。这意味着每个Trident操作处理一个元组批次，而每个本地Storm
    bolt在单个元组上执行。[图9.1](#ch09fig01)提供了这个概念的说明。
- en: Figure 9.1\. Trident topologies operate on streams of batches of tuples whereas
    native Storm topologies operate on streams of individual tuples.
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.1。Trident拓扑在元组批次流上操作，而本地Storm拓扑在单个元组流上操作。
- en: '![](09fig01.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig01.jpg)'
- en: Because Trident handles streams as batches of tuples, it falls under the category
    of micro-batching tools discussed in [chapter 1](kindle_split_009.html#ch01).
    As you’ll recall from that chapter, micro-batching is a hybrid between batch processing
    and stream processing.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 因为Trident将流视为元组批次，所以它属于[第1章](kindle_split_009.html#ch01)中讨论的微批处理工具类别。正如你从那一章中回忆起来的，微批处理是批处理和流处理之间的混合体。
- en: This fundamental difference in how Trident treats streams as a series of batches
    is why there are operations and not bolts in Trident. We think in terms of the
    stream and the series of operations we can apply to that stream. The operations
    discussed in [section 9.1.1](#ch09lev2sec1) will modify either the tuples that
    flow within the stream or the stream itself. In order to understand Trident, you
    must understand both streams and operations within Trident.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种在Trident中将流视为一系列批次的根本区别，是为什么在Trident中存在操作而不是bolt的原因。我们以流及其可以应用于该流的操作系列来思考。在[第9.1.1节](#ch09lev2sec1)中讨论的操作将修改流中流动的元组或流本身。为了理解Trident，你必须理解Trident中的流和操作。
- en: Next we’ll discuss a message queue implementation that’s well suited for use
    with Trident. It matches Trident’s needs so closely that it’s bundled with Storm
    to be used with Trident topologies.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论一个非常适合与Trident一起使用的消息队列实现。它与Trident的需求如此接近，以至于它被捆绑在Storm中，以便与Trident拓扑一起使用。
- en: 9.2\. Kafka and its role with Trident
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2. Kafka及其在Trident中的作用
- en: Storm maintains a unique relationship with Apache Kafka when it comes to message
    queues that serve as a source of input. That’s not to say that other message queue
    technologies can’t be used. We’ve been careful throughout the book to point out
    how Storm can be used with a number of different technologies, such as RabbitMQ
    and Kestrel. What sets Kafka apart from other message broker implementations?
    It boils down to the core architectural decisions made during the creation of
    Kafka. To help you understand what makes Kafka such a good fit with Trident, we’re
    going to briefly discuss Kafka’s design and then talk about what characteristics
    of this design align well with Trident.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到作为输入源的消息队列时，Storm 与 Apache Kafka 保持着独特的关系。这并不意味着不能使用其他消息队列技术。我们在整本书中都非常小心地指出
    Storm 如何与多种不同的技术一起使用，例如 RabbitMQ 和 Kestrel。是什么让 Kafka 与其他消息代理实现不同？这归结于 Kafka 创建过程中的核心架构决策。为了帮助您理解为什么
    Kafka 与 Trident 非常匹配，我们将简要讨论 Kafka 的设计，然后讨论该设计的哪些特性与 Trident 非常吻合。
- en: 9.2.1\. Breaking down Kafka’s design
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.2.1\. 拆解 Kafka 的设计
- en: This section will briefly dive into Kafka’s design, but only as far as is necessary
    for you to understand why it’s relevant to Storm and Trident.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将简要探讨 Kafka 的设计，但仅限于您理解为什么它与 Storm 和 Trident 相关。
- en: '|  |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: We use some standard Kafka terminology throughout this chapter. Two of the terms
    more commonly used are 1) *topic*, which is a feed of messages for a particular
    category and 2) *broker*, which is a server/node that’s usually one of many running
    in a Kafka cluster.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用了一些标准的 Kafka 术语。其中两个更常用的术语是 1) *主题*，它是一个特定类别的消息源，2) *代理*，它是一个服务器/节点，通常在
    Kafka 集群中运行的一个多个节点之一。
- en: '|  |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'The Kafka website describes itself in two ways, both of which serve as clues
    to why the design fits well with Trident:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 网站以两种方式描述自己，这两种方式都作为为什么设计适合 Trident 的线索：
- en: It’s a publish-subscribe message broker, rethought as a *distributed commit
    log*.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是一个发布-订阅消息代理，重新构想为一个 *分布式提交日志*。
- en: It’s a distributed, partitioned, replicated commit log service that provides
    the functionality of a messaging system, but with a unique design.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是一个分布式、分区、复制的提交日志服务，提供消息系统的功能，但具有独特的设计。
- en: Let’s talk about each of these, because understanding these basic design decisions
    will help you see how Kafka aligns with Trident.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一讨论这些内容，因为理解这些基本的设计决策将帮助您了解 Kafka 如何与 Trident 对齐。
- en: Partitioning for distributing a Kafka topic
  id: totrans-62
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 分区以分发 Kafka 主题
- en: When a message producer writes to a Kafka topic, it writes a given message to
    a particular partition of that topic. A *partition* is an ordered, immutable sequence
    of messages that’s continually being appended to. A topic can have multiple partitions,
    and these partitions can be distributed across multiple Kafka brokers. A message
    consumer will read from each partition in order to see the entire topic. [Figure
    9.2](#ch09fig02) illustrates a single topic distributed across multiple partitions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当消息生产者向 Kafka 主题写入消息时，它会将该主题的特定分区中的给定消息写入。一个 *分区* 是一个有序的、不可变的消息序列，它不断地被追加。一个主题可以有多个分区，这些分区可以分布在多个
    Kafka 代理上。消息消费者将读取每个分区，以查看整个主题。[图 9.2](#ch09fig02) 展示了一个主题如何分布到多个分区。
- en: Figure 9.2\. Distribution of a Kafka topic as group of partitions on many Kafka
    brokers
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.2\. Kafka 主题的分布，作为多个 Kafka 代理上的分区组
- en: '![](09fig02_alt.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig02_alt.jpg)'
- en: By partitioning a topic, Kafka gains the ability to scale a single topic beyond
    a single broker (node) for both reads and writes. Each of the partitions can additionally
    be replicated to provide resiliency. This means that if you have `n` replicas
    for a partition, you can lose up to `n – 1` replicas without suffering any data
    loss.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对主题进行分区，Kafka 获得了将单个主题扩展到单个代理（节点）之外的能力，无论是读取还是写入。每个分区还可以进行复制以提供容错性。这意味着如果您为分区有
    `n` 个副本，您可以在不遭受任何数据丢失的情况下丢失多达 `n – 1` 个副本。
- en: Having multiple partitions and being able to scale those partitions are important
    concepts to grasp when it comes to Trident. As you’ll see later in this chapter,
    this maps well with how a Trident topology reads data from a stream. But before
    we get ahead of ourselves, we should elaborate a bit more on how Kafka stores
    messages.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Trident 中，理解多个分区以及能够扩展这些分区是非常重要的概念。正如您将在本章后面看到的那样，这与 Trident 读取流数据的拓扑方式非常吻合。但在我们继续前进之前，我们应该更详细地阐述
    Kafka 如何存储消息。
- en: Modeling storage as a commit log
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 将存储建模为提交日志
- en: The storage model Kafka uses for messages within a topic yields many advantages—in
    both terms of performance and functional characteristics. We know from the previous
    section that a partition is an ordered, immutable sequence of messages on the
    filesystem. This represents a commit log. Each message within the partition is
    assigned a sequential identifier, called an *offset*, which marks where in the
    commit log each message is stored.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 用于主题内消息的存储模型在性能和功能特性方面都提供了许多优势。我们从上一节中了解到，分区是文件系统上有序、不可变的消息序列。这代表了一个提交日志。分区内的每条消息都被分配了一个顺序标识符，称为*偏移量*，它标记了每条消息在提交日志中的存储位置。
- en: Kafka also maintains an ordering of messages within a partition, so strong ordering
    is guaranteed when a single consumer is reading from the partition. A message
    consumer reading from a particular partition will then maintain its own reference
    to its current position, known as that consumer’s offset into the commit log.
    [Figure 9.3](#ch09fig03) illustrates offsets for multiple partitions.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 还维护分区内的消息顺序，因此当单个消费者从分区读取时，可以保证强顺序。从特定分区读取消息的消息消费者将维护其当前位置的引用，这被称为该消费者在提交日志中的偏移量。[图9.3](#ch09fig03)说明了多个分区的偏移量。
- en: Figure 9.3\. A partition contains an immutable, ordered sequence of messages,
    where the consumers reading these messages maintain offsets for their read positions.
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.3。一个分区包含一个不可变、有序的消息序列，其中读取这些消息的消费者维护其读取位置的偏移量。
- en: '![](09fig03_alt.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图9.3](09fig03_alt.jpg)'
- en: Kafka doesn’t discard messages after a consumer advances its offset; they’re
    kept in the log for a configured time period (such as 24 hours or 7 days). Once
    that time interval elapses, Kafka will compact the log and purge any older entries.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 在消费者推进偏移量后不会丢弃消息；它们会被保留在日志中一段时间（例如24小时或7天）。一旦这个时间间隔过去，Kafka 将压缩日志并清除任何较旧的条目。
- en: You should now have a general idea of how Kafka’s design works. A topic serves
    as a feed of messages for a particular category. This topic can then be broken
    into multiple partitions, which are immutable, ordered sequences of messages.
    These partitions can each be distributed across different brokers in the Kafka
    cluster. We’ll now elaborate on some of the advantages of this design in terms
    of both functionality and performance.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在应该对 Kafka 的设计工作原理有一个大致的了解。主题充当特定类别的消息源。然后，这个主题可以被分解成多个分区，这些分区是不可变、有序的消息序列。这些分区可以分布在
    Kafka 集群的不同代理上。我们现在将详细阐述一些关于功能和性能方面的设计优势。
- en: The functional and performance advantages of Kafka’s design
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Kafka 设计的功能和性能优势
- en: 'The functional advantages of this design include the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 此设计的功能优势包括以下内容：
- en: Because messages aren’t discarded immediately and the consumer decides when
    or when not to advance its offset into the commit log, it’s easy to replay any
    messages from Kafka.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于消息不会立即被丢弃，并且消费者决定何时或何时不推进其提交日志中的偏移量，因此很容易从 Kafka 重新播放任何消息。
- en: Similarly, if your consumers fall behind for a long time and it no longer makes
    sense to consume those queued messages due to some consume-by-deadline requirements,
    it makes it easy to advance the offset by a large number into a new read position
    to skip all the expired messages.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似地，如果您的消费者长时间落后，并且由于某些消费截止日期的要求，不再有消费这些排队消息的意义，那么通过将偏移量向前推进一大步到新的读取位置来跳过所有过期的消息就变得容易了。
- en: If your consumer acts on messages in batches and needs to complete the batch
    all at once or not at all, this can be accomplished by advancing the offset for
    a batch of sequential messages from a partition in one go.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的消费者以批量的方式处理消息，并且需要一次性完成整个批次或者根本不完成，这可以通过一次性推进一个分区中一系列消息的偏移量来实现。
- en: If you have different applications that need to subscribe to the same messages
    from a topic, consumers can easily read these different applications from that
    topic’s same set of partitions. This is facilitated because a message isn’t discarded
    after one consumer is done with it but rather the consumer controls its own offset
    into the commit log.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您有不同需要订阅同一主题中相同消息的应用程序，消费者可以轻松地从该主题的相同分区集中读取这些不同的应用程序。这是因为消息在第一个消费者处理完毕后并不会被丢弃，而是消费者控制其自己的提交日志中的偏移量。
- en: On the other hand, if you want to ensure that only a single consumer consumes
    each message, you can do so by pinning a single consumer instance to a particular
    partition of a topic.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，如果你想确保只有单个消费者消费每条消息，你可以通过将单个消费者实例固定到特定主题的特定分区来实现。
- en: 'The performance advantages include the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 性能优势包括以下方面：
- en: Whether your message bus ends up being bottlenecked by the message producer
    or the message consumer, that bottleneck can be easily addressed by increasing
    the number of partitions.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无论你的消息总线最终是由消息生产者还是消息消费者造成的瓶颈，这个瓶颈都可以通过增加分区数量来轻松解决。
- en: 'The sequential and immutable nature of the commit log along with the sequential
    nature of the consumer’s offset advancement pattern (in most cases) buys us many
    performance advancements:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提交日志的顺序和不可变特性，以及消费者偏移量推进模式的顺序特性（在大多数情况下），为我们带来了许多性能提升：
- en: Disk access is often expensive but in most cases this is due to the random access
    nature that’s common among most applications. Because Kafka is designed from the
    ground up to make use of sequential access to data in the filesystem, modern operating
    systems will make efficient use of that by way of read-ahead caches and write-behind
    caching to give you large strides in performance improvements.
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 磁盘访问通常成本较高，但在大多数情况下，这是由于大多数应用程序中普遍存在的随机访问特性。由于Kafka从头开始设计就是为了利用文件系统中数据的顺序访问，现代操作系统将通过预读缓存和写后缓存来高效地利用这一点，从而在性能提升上取得大幅进步。
- en: Kafka makes excellent use of the OS disk cache. This allows Kafka to sidestep
    maintaining expensive caches in-process and not subject itself to garbage collection
    pressure.
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka充分利用了操作系统的磁盘缓存。这使得Kafka能够避免在进程内维护昂贵的缓存，并免受垃圾收集压力的影响。
- en: We have a decent picture of Kafka’s general design along with the advantages,
    both functional and performance-related, that this design provides. It’s time
    to identify how Kafka aligns with Trident, making it such a great choice for Trident
    that it now comes bundled with Storm.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对Kafka的一般设计和它提供的优势，包括功能性和性能相关的优势，已经有了相当的了解。现在是时候确定Kafka如何与Trident兼容，使其成为Trident如此优秀的选择，以至于它现在与Storm捆绑在一起。
- en: 9.2.2\. Kafka’s alignment with Trident
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.2.2. Kafka与Trident的兼容性
- en: 'You’re probably able to imagine how wonderfully Storm would benefit from both
    the functional and performance advantages of Kafka. Kafka provides a performance
    advantage that’s an order of magnitude over its competition. For that reason alone,
    Kafka is the message bus of choice for native Storm. But when used with Trident,
    it’s clear why it’s such a good choice as the messaging implementation:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能能够想象到Storm如何从Kafka的功能性和性能优势中受益。Kafka提供的性能优势比其竞争对手高出一个数量级。仅凭这一点，Kafka就成为了原生Storm的首选消息总线。但是，当与Trident一起使用时，它作为消息实现的优秀选择的原因就很明显了：
- en: Because Trident performs micro-batching within a stream, it relies on being
    able to manage a batch of tuples atomically. By allowing Trident to advance its
    consumer offset, Kafka supports this functionality.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于Trident在流中执行微批处理，它依赖于能够原子性地管理一个元组批次。通过允许Trident推进其消费者偏移量，Kafka支持这一功能。
- en: Messages aren’t discarded, so by rewinding the offset, you can replay messages
    from any point in time (up to Kafka’s log expiry time interval). This allows Kafka
    to behave as a reliable data source on which you can build a reliable spout, both
    for Trident and native Storm.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消息不会被丢弃，因此通过回滚偏移量，你可以从任何时间点（直到Kafka的日志过期时间间隔）重新播放消息。这使得Kafka能够作为一个可靠的数据源，你可以在此基础上构建一个可靠的spout，无论是对于Trident还是原生Storm。
- en: As we’ll see later, Trident can use Kafka partitions to serve as a primary means
    of parallelism within a Trident topology.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如我们稍后将要看到的，Trident可以使用Kafka分区作为Trident拓扑内部并行化的主要手段。
- en: A Storm spout implemented for Kafka can maintain its consumer offsets for the
    different partitions in Zookeeper, so when your Storm or Trident topology is restarted
    or redeployed, you can continue processing from the place where you left off.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为Kafka实现的Storm spout可以在Zookeeper中维护不同分区的消费者偏移量，因此当你的Storm或Trident拓扑重启或重新部署时，你可以从上次停止的地方继续处理。
- en: 'Let’s pause for a moment and see what we’ve covered so far. By now, you should
    understand the following:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂停一下，看看我们已经涵盖了哪些内容。到目前为止，你应该理解以下内容：
- en: Trident provides an abstraction on top of Storm’s primitives, allowing you to
    write code that expresses “what” is being done rather than “how” to do it.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident在Storm的原始操作之上提供了一个抽象层，允许你编写表达“做什么”而不是“如何做”的代码。
- en: Trident streams are handled as a series of batches of tuples rather than individual
    tuples, one at a time.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident 流被处理为一组元组的批次，而不是单个元组，一次一个。
- en: Trident has operations, instead of bolts, that you apply to streams. These operations
    include functions, filters, splits, merges, joins, grouping, aggregation, state
    updater, state querying, and repartitioning.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident 有操作，而不是螺栓，可以应用于流。这些操作包括函数、过滤器、拆分、合并、连接、分组、聚合、状态更新器、状态查询和重新分区。
- en: Kafka is the ideal queuing implementation for Trident topologies.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka 是适用于 Trident 顶点的理想队列实现。
- en: We’re finally ready to dive into our use case and apply all of these Trident
    principles to our design and implementation. As we go through the use case, try
    to keep in mind Trident’s operations and how it handles streams, because this
    will help steer our design.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于准备好深入我们的用例，并将所有这些 Trident 原则应用于我们的设计和实现。当我们通过用例时，请尝试记住 Trident 的操作以及它是如何处理流的，因为这将有助于指导我们的设计。
- en: '9.3\. Problem definition: Internet radio'
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3\. 问题定义：互联网广播
- en: Let’s say we want to start an internet radio company. We want to be conscientious
    about paying fair royalties to artists for their music that gets streamed through
    our internet radio platform. To do this, we decide to keep track of play counts
    for individual songs by artist. These counts can later be queried for use within
    reporting and for assigning royalties. In addition to paying royalties, we’re
    fairly ambitious and want to be able to query/report on the types of music our
    users prefer in order to provide them with the best possible experience when using
    our application.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要创办一家互联网广播公司。我们希望对艺术家通过我们的互联网广播平台流过的音乐支付公平的版税。为此，我们决定跟踪艺术家个人歌曲的播放次数。这些计数可以稍后用于报告和分配版税。除了支付版税外，我们还有相当雄心勃勃，希望能够查询/报告用户偏好的音乐类型，以便在用户使用我们的应用程序时提供最佳体验。
- en: Our users will be listening to our internet radio on various devices and on
    the web. These applications will collect “play logs” and send that information
    to us to be streamed into our topology from our Trident spout.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的用户将在各种设备和网页上收听我们的互联网广播。这些应用程序将收集“播放日志”并将这些信息发送给我们，以便从我们的 Trident spout 流入我们的拓扑。
- en: With this problem definition in hand, let’s take a look at the starting and
    ending data points, much like we’ve done in previous chapters.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 拿着这个问题定义，让我们来看看起始和结束的数据点，就像我们在前面的章节中所做的那样。
- en: 9.3.1\. Defining the data points
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.3.1\. 定义数据点
- en: For our scenario, each play log will be streamed into our topology as JSON containing
    the artist, the title of the song, and a list of tags relevant to the song. The
    next listing provides an example of a single play log.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的场景，每个播放日志将作为包含艺术家、歌曲标题和与歌曲相关的标签列表的 JSON 流入我们的拓扑。下面的列表提供了一个单个播放日志的示例。
- en: Listing 9.3\. Sample play log entry for the stream of play logs
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.3\. 样本播放日志流条目
- en: '[PRE0]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The play log JSON gives us a starting point for our data. We want to persist
    three different types of counts: counts by artist, by title, and by tag. Trident
    provides a `TridentState` class that we’ll use for this. We’ll get more into `TridentState`
    later—what’s important now is that you understand the data we start with and where
    we want to end up.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 播放日志 JSON 给我们提供了数据的起点。我们希望持久化三种不同类型的计数：按艺术家、标题和标签的计数。Trident 提供了一个 `TridentState`
    类，我们将用它来完成这个任务。我们将在稍后更深入地了解 `TridentState`——现在重要的是你要理解我们开始的数据以及我们想要达到的目标。
- en: With the data defined, the next step is to define the series of steps we need
    to go from a feed of play logs to the counts stored in `TridentState` instances.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 数据定义后，下一步是定义一系列步骤，我们需要从播放日志的流到存储在 `TridentState` 实例中的计数。
- en: 9.3.2\. Breaking down the problem into a series of steps
  id: totrans-110
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.3.2\. 将问题分解为一系列步骤
- en: We’ve established that we’ll start with a play log and end with counts for artist,
    title, and tag. In forming a conceptual solution, we need to identify all the
    steps between our start and end.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经确定我们将从一个播放日志开始，以艺术家、标题和标签的计数结束。在形成一个概念解决方案时，我们需要确定我们开始和结束之间的所有步骤。
- en: 'Remember earlier when we said to keep in mind the various Trident operations
    when discussing the design for our use case? This is where we’ll look at those
    operations and see which make sense in our scenario. We end up with the following:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们之前在讨论用例设计时提到要记住各种 Trident 操作吗？这就是我们将查看这些操作并确定哪些在我们的场景中合理的地方。我们最终得到以下结果：
- en: A spout that emits a Trident stream. Remember that a Trident stream consists
    of batches of tuples as opposed to individual tuples.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个发出Trident流的喷口。记住，Trident流由元组批次组成，而不是单个元组。
- en: A function that deserializes (splits) incoming play logs into tuple batches
    for artist, title, and tag.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个将传入的播放日志反序列化（分割）成艺术家、标题和标签元组批次的函数。
- en: Separate functions to count each of the artists, titles, and tags respectively.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分别为艺术家、标题和标签分别计数的功能。
- en: Trident state to persist the counts by artist, title, and tag, respectively.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Trident状态通过艺术家、标题和标签分别持久化计数。
- en: These steps are illustrated in [figure 9.4](#ch09fig04), which illustrates our
    design goal. Next we need to implement the code for the Trident operations that
    we’ll apply to the stream of tuple batches containing play logs.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤在[图9.4](#ch09fig04)中得到了说明，该图说明了我们的设计目标。接下来，我们需要实现将应用于包含播放日志的元组批次流的Trident操作的代码。
- en: Figure 9.4\. Trident topology for internet radio application
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.4\. 互联网广播应用的Trident拓扑
- en: '![](09fig04_alt.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig04_alt.jpg)'
- en: 9.4\. Implementing the internet radio design as a Trident topology
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4\. 将互联网广播设计实现为Trident拓扑
- en: At this point, we’re ready to implement a Trident topology that meets our design
    goal established in [figure 9.4](#ch09fig04). You’ll notice as we start to go
    through the implementation that much of the code for our topology is handled within
    the topology builder class (`TopologyBuilder`). Although we do implement some
    functions for the operations used, the `TopologyBuilder` is where you’ll see the
    code expressed in terms of the “what” rather than the “how.”
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经准备好实现一个符合我们在[图9.4](#ch09fig04)中建立的设计目标的Trident拓扑。当你开始通过实现进行时，你会注意到我们拓扑的大部分代码都在拓扑构建器类（`TopologyBuilder`）中处理。虽然我们确实实现了一些用于操作的函数，但你将在`TopologyBuilder`中看到以“what”而不是“how”的形式表达代码。
- en: Let’s start with the spout for our topology. Fortunately for us, Storm comes
    with a built-in spout implementation that we can use, saving ourselves some time.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从我们的拓扑的喷口开始。幸运的是，对于我们的需求，Storm自带了一个内置的喷口实现，我们可以使用它来节省一些时间。
- en: 9.4.1\. Implementing the spout with a Trident Kafka spout
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.4.1\. 使用Trident Kafka喷口实现喷口
- en: We’ll use the Trident Kafka spout that comes with the official Storm distribution.
    [Figure 9.5](#ch09fig05) shows where this Trident Kafka spout will be used in
    the topology.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用官方Storm发行版中包含的Trident Kafka喷口。[图9.5](#ch09fig05)显示了在拓扑中此Trident Kafka喷口将如何使用。
- en: Figure 9.5\. The Trident Kafka spout will be used for handling incoming play
    logs.
  id: totrans-125
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.5\. Trident Kafka喷口将用于处理传入的播放日志。
- en: '![](09fig05_alt.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig05_alt.jpg)'
- en: Although the implementation details of this spout are outside the scope of this
    chapter, we’ll show you the code for wiring up this spout in the `TopologyBuilder`
    class in the next listing.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个喷口的实现细节超出了本章的范围，但我们将展示如何在下一个列表中`TopologyBuilder`类中连接这个喷口的代码。
- en: Listing 9.4\. Wiring up a `TransactionalTridentKafkaSpout` in the `TopologyBuilder`
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.4\. 在`TopologyBuilder`中连接`TransactionalTridentKafkaSpout`
- en: '![](219fig01_alt.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](219fig01_alt.jpg)'
- en: We now have a spout implementation that will emit batches of play logs. The
    next step is to implement our first operation that will take the JSON for each
    tuple in the batch and transform that JSON into separate tuple batches for artist,
    title, and tags.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个将发出播放日志批次的喷口实现。下一步是实现我们的第一个操作，该操作将批次的每个元组的JSON转换为艺术家、标题和标签的单独元组批次。
- en: 9.4.2\. Deserializing the play log and creating separate streams for each of
    the fields
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.4.2\. 反序列化播放日志并为每个字段创建单独的流
- en: 'The next step to implement in the design is to take the batches of incoming
    `play-log` tuples and emit batches of tuples for each of the fields we’re interested
    in counting: artist, title, and tag. [Figure 9.6](#ch09fig06) illustrates the
    batches of input tuples, our operation, and batches of output tuples, with each
    batch being emitted on a separate stream.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计中要实施的下一步是获取进入的`play-log`元组批次，并为我们要计数的每个字段（艺术家、标题和标签）发出元组批次。[图9.6](#ch09fig06)说明了输入元组批次、我们的操作和输出元组批次，每个批次都在单独的流上发出。
- en: Figure 9.6\. Operation for deserializing JSON into Trident tuples for each of
    the artist, title, and tags fields
  id: totrans-133
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.6\. 将JSON反序列化为Trident元组批次的操作，针对艺术家、标题和标签字段
- en: '![](09fig06_alt.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig06_alt.jpg)'
- en: 'Looking at the figure, you can see we need to do two things: 1) convert the
    JSON into separate tuples for the artist, title, and tags fields, and 2) create
    a separate stream for each of those fields. For the first task, we’re going to
    take a look at the `each` operation.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 观察图示，你可以看到我们需要做两件事：1) 将JSON转换为艺术家、标题和标签字段的单个元组，2) 为这些字段中的每个字段创建一个单独的流。对于第一个任务，我们将查看`each`操作。
- en: Trident provides an `each` operation that can be applied to each tuple, one
    at a time. The `each` operation can be used with a function or a filter. In our
    scenario, an `each` function seems like the appropriate choice, because we’re
    transforming the JSON into Trident tuples for artist, title, and tag. If we needed
    to filter out any data for some reason, then a filter would be a more appropriate
    choice.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Trident提供了一个可以应用于每个元组的`each`操作。`each`操作可以与函数或过滤器一起使用。在我们的场景中，一个`each`函数似乎是一个合适的选择，因为我们正在将JSON转换为艺术家、标题和标签的Trident元组。如果我们需要出于某种原因过滤掉任何数据，那么过滤器将是一个更合适的选择。
- en: Implementing an each function
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 实现每个函数
- en: A function takes in a set of input fields and emits zero or more tuples. If
    it doesn’t emit anything, the original tuple is filtered out. When using an `each`
    function, the fields of the output tuple are appended to the input tuple. The
    following listing provides the code for implementing an `each` function for our
    topology.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 函数接收一组输入字段并发出零个或多个元组。如果它不发出任何内容，则原始元组被过滤掉。当使用`each`函数时，输出元组的字段被附加到输入元组上。以下列表提供了为我们拓扑实现`each`函数的代码。
- en: Listing 9.5\. `TopologyBuilder.java` with an `each` function for deserializing
    the play logs
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.5\. `TopologyBuilder.java`中的`each`函数用于反序列化播放日志
- en: '![](221fig01_alt.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图片](221fig01_alt.jpg)'
- en: The new stream will contain the fields `play-log`, `artist`, `title`, and `tags`.
    The `each` function `LogDeserializer` is built by providing an implementation
    for the `Base-Function` abstract class, and will deserialize the input tuple with
    a JSON string into the required output. Implementing a `BaseFunction` is similar
    to implementing a `Base-BasicBolt` in native Storm. The following listing shows
    the implementation.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 新的流将包含`play-log`、`artist`、`title`和`tags`字段。`each`函数`LogDeserializer`通过为`Base-Function`抽象类提供一个实现来构建，并将输入元组中的JSON字符串反序列化到所需的输出。实现`BaseFunction`类似于在原生Storm中实现`Base-BasicBolt`。以下列表显示了实现。
- en: Listing 9.6\. `LogDeserializer.java`
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.6\. `LogDeserializer.java`
- en: '![](ch09ex06-0.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图片](ch09ex06-0.jpg)'
- en: '![](ch09ex06-1.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图片](ch09ex06-1.jpg)'
- en: '|  |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Projections**'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**投影**'
- en: When you define an `each` function as `stream.each(inputFields, function, output-Fields)`,
    only a subset of fields (represented by `inputFields`) from the original stream
    is sent into the function (the rest become inaccessible within the function).
    This is called *projection*. Projections make it extremely easy to avoid issues
    that people commonly encounter with having sent unnecessary fields into a function.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当你定义一个`each`函数为`stream.each(inputFields, function, output-Fields)`时，只有原始流中的一部分字段（由`inputFields`表示）被发送到函数中（其余的函数内部无法访问）。这被称为*投影*。投影使得避免人们通常遇到的问题变得极其容易，即向函数发送了不必要的字段。
- en: 'You can also use the `project(..)` method on the stream to remove any unnecessary
    fields that are hanging around after an operation. In our case we have the `play-log`
    field as part of the stream after the `LogDeserializer` operation and we don’t
    need the original JSON anymore. It’s better to get rid of it; keeping unnecessary
    data in memory will affect efficiency (particularly in Trident because we’re treating
    a stream as a series of batches and that involves keeping more data in memory
    within a JVM than a regular Storm topology):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在流上使用`project(..)`方法来移除操作后挂留的任何不必要的字段。在我们的例子中，我们在`LogDeserializer`操作后流中有一个`play-log`字段，我们不再需要原始的JSON。最好将其删除；保留不必要的内存数据会影响效率（尤其是在Trident中，因为我们把流当作一系列批次来处理，这涉及到在JVM中比常规Storm拓扑保留更多的数据）：
- en: '[PRE1]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|  |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'As we mentioned earlier, we must do two things: 1) convert the JSON into separate
    tuples, which we’ve now done, and 2) create a separate stream for each of those
    fields. Let’s take a look at that second task next.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，我们必须做两件事：1) 将JSON转换为单独的元组，我们现在已经做到了，2) 为这些字段中的每个字段创建一个单独的流。让我们看看第二个任务。
- en: Splitting a stream and grouping the fields
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 分割流和分组字段
- en: 'If we were to end our implementation right now, we’d have a single stream containing
    batches of tuples with four values. This is because of the following in `LogDeserializer`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在结束实现，我们将有一个包含四个值元组批次的单个流。这是因为`LogDeserializer`中的以下原因：
- en: '[PRE2]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[Figure 9.7](#ch09fig07) illustrates where we currently are versus where we
    want to be.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9.7](#ch09fig07) 展示了我们现在所在的位置与我们的目标位置。'
- en: Figure 9.7\. We want to move from a stream with tuples containing multiple values
    to multiple streams with tuples containing single values.
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.7\. 我们希望从包含多个值的元组的流移动到包含单个值的多个流。
- en: '![](09fig07_alt.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](09fig07_alt.jpg)'
- en: Fortunately for us, splitting a stream is easy. We hold multiple references
    for the stream from the split origination point and then continue to apply different
    Trident operations to those references, as shown in the next listing.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，拆分流很容易。我们从拆分起源点持有多个流引用，然后继续对这些引用应用不同的Trident操作，如下一列表所示。
- en: Listing 9.7\. Splitting the stream originating from `LogDeserializer` into three
    separate streams
  id: totrans-159
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.7\. 将来自`LogDeserializer`的流拆分为三个独立的流
- en: '![](223fig01_alt.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图片](223fig01_alt.jpg)'
- en: We have code for creating separate streams, but there isn’t anything to those
    streams. They’re just references to the originating `playStream`. We need to associate
    each of those streams with the fields we’re interested in splitting on. This is
    where grouping the tuples by field name comes into play.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有创建单独流的代码，但那些流中没有什么内容。它们只是对起源`playStream`的引用。我们需要将每个流与我们要拆分的字段相关联。这正是按字段名称对元组进行分组发挥作用的地方。
- en: Grouping tuples by field name
  id: totrans-162
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 按字段名称对元组进行分组
- en: Trident provides a `groupBy` operation we can use for grouping together tuples
    with the same field name. A `groupBy` operation first repartitions the stream
    so that tuples with the same selected field values fall within the same partition.
    Within each partition, it then groups the tuples together whose group fields are
    equal. The code for performing these `groupBy` operations is in the next listing.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Trident提供了一个`groupBy`操作，我们可以用它来对具有相同字段名的元组进行分组。`groupBy`操作首先重新分区流，使得具有相同选定字段值的元组落在同一个分区中。在每个分区内部，它然后将具有相等组字段的元组分组在一起。执行这些`groupBy`操作的代码在下一列表中。
- en: Listing 9.8\. Grouping by artist, title, and tag in the three split streams
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.8\. 在三个拆分流中对艺术家、标题和标签进行分组
- en: '![](224fig01_alt.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图片](224fig01_alt.jpg)'
- en: '`ListSplitter` is an `each` function implemented in a similar manner to `LogDeserializer`.
    The difference is that `ListSplitter` splits the `tags` list into individual `tag`
    tuples.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`ListSplitter`是一个以类似`LogDeserializer`的方式实现的`each`函数。不同之处在于`ListSplitter`将`tags`列表拆分为单个`tag`元组。'
- en: Now that we’ve split the streams and performed a grouping on each of the `artist`,
    `title`, and `tag` fields, we’re ready to calculate the counts for each of these
    fields.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拆分了流并对每个`artist`、`title`和`tag`字段进行了分组，我们准备计算这些字段的计数。
- en: 9.4.3\. Calculating and persisting the counts for artist, title, and tag
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.4.3\. 计算并持久化艺术家、标题和标签的计数
- en: The next step is to aggregate the `artist`, `title`, and `tag` tuples in order
    to calculate the counts for each. [Figure 9.8](#ch09fig08) provides a reminder
    of where we are in the topology design.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是对`artist`、`title`和`tag`元组进行聚合，以便计算每个的计数。[图9.8](#ch09fig08) 提醒我们在拓扑设计中的位置。
- en: Figure 9.8\. Counting each of the `artist`, `title`, and `tag` values and persisting
    those values to a store
  id: totrans-170
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.8\. 对每个`artist`、`title`和`tag`值进行计数并将这些值持久化到存储中
- en: '![](09fig08_alt.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图片](09fig08_alt.jpg)'
- en: 'According to [figure 9.8](#ch09fig08), there are basically two steps here:
    1) aggregate the tuples by value for each stream to perform the counts, and 2)
    persist the counts. Let’s start by looking at three different ways to aggregate
    tuples and identify the one that’s best for our scenario.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[图9.8](#ch09fig08)，这里基本上有两个步骤：1) 对每个流按值聚合元组以执行计数，2) 持久化计数。让我们先看看三种不同的聚合元组的方法，并确定最适合我们场景的方法。
- en: Choosing an aggregator implementation for performing the counts
  id: totrans-173
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 为执行计数选择聚合器实现
- en: 'There are three ways to aggregate tuples, each with its own interface for defining
    how it should be implemented:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种方法可以聚合元组，每种方法都有自己的接口来定义如何实现：
- en: '![](225fig01_alt.jpg)'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![图片](225fig01_alt.jpg)'
- en: A `CombinerAggregator` calls the `init` ![](1.jpg) method for each tuple, and
    then uses the `combine` ![](2.jpg) method to combine each tuple’s `init` value
    and returns a result. If there are no tuples to aggregate, it returns the `zero`
    ![](3.jpg) value.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个 `CombinerAggregator` 对每个元组调用 `init` ![](1.jpg) 方法，然后使用 `combine` ![](2.jpg)
    方法将每个元组的 `init` 值合并并返回一个结果。如果没有元组要聚合，它返回 `zero` ![](3.jpg) 值。
- en: '![](225fig02_alt.jpg)'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![](225fig02_alt.jpg)'
- en: A `ReducerAggregator` calls the `init` method ![](1.jpg) just once for the aggregation,
    and then calls `reduce` ![](2.jpg) with each tuple and current value.
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个 `ReducerAggregator` 只对聚合调用一次 `init` 方法，然后对每个元组和当前值调用 `reduce` ![](2.jpg)。
- en: '[PRE3]'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_PRE
  zh: '[PRE3]'
- en: An `Aggregator` is a more low-level abstraction interface for implementing more
    complex aggregations. Please refer to the Storm documentation for more information.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`Aggregator` 是一个更底层的抽象接口，用于实现更复杂的聚合。请参阅 Storm 文档以获取更多信息。'
- en: The majority of the time, you’ll use `CombinerAggregator` or `ReducerAggregator`.
    If the initial value for the entire aggregation isn’t dependent on any single
    tuple, then you’ll have to use `ReducerAggregator`. Otherwise, we suggest `CombinerAggregator`
    because it’s more performant.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，你会使用 `CombinerAggregator` 或 `ReducerAggregator`。如果整个聚合的初始值不依赖于任何单个元组，那么你就必须使用
    `ReducerAggregator`。否则，我们建议使用 `CombinerAggregator`，因为它性能更好。
- en: '|  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Benefits of CombinerAggregator over ReducerAggregator**'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**CombinerAggregator 相对于 ReducerAggregator 的优势**'
- en: When you’re running an aggregate operation with a `ReducerAggregator`- or an
    `Aggregator`-based implementation, a repartitioning of the stream takes place
    so that all partitions are collapsed into one and the aggregation takes place
    on that one partition. But if you use a `CombinerAggregator`-based implementation
    (as we do with `Count`), Trident will perform partial aggregations on the current
    partitions and then repartition the stream into one stream and complete aggregation
    by further aggregating the partially aggregated tuples. This is far more efficient
    because fewer tuples have to cross the wire during the repartition. `CombinerAggregator`
    should always be preferred because of this reason; the only time you’ll have to
    resort to `ReducerAggregator` is when you need to seed an aggregation with an
    initial value independent of the tuples.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用基于 `ReducerAggregator` 或 `Aggregator` 的实现运行聚合操作时，流会发生重新分区，以便所有分区都合并成一个，并在该分区上进行聚合。但如果你使用基于
    `CombinerAggregator` 的实现（就像我们使用 `Count` 一样），Trident 将在当前分区上执行部分聚合，然后重新分区流为一个流，并通过进一步聚合部分聚合的元组来完成聚合。这要高效得多，因为
    fewer tuples have to cross the wire during the repartition. `CombinerAggregator`
    应该始终优先考虑，因为这个原因；你唯一需要求助于 `ReducerAggregator` 的时候是当你需要用一个与元组无关的初始值来初始化聚合。
- en: '|  |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: For our scenario, let’s use a built-in aggregator called `Count` that implements
    `Combiner-Aggregator`. This is a simple implementation that will allow us to count
    artists, titles, and tags within our groupings. The next listing shows the implementation
    for `Count`.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的场景，让我们使用一个名为 `Count` 的内置聚合器，它实现了 `Combiner-Aggregator`。这是一个简单的实现，它将允许我们在分组内计数艺术家、标题和标签。下一个列表显示了
    `Count` 的实现。
- en: Listing 9.9\. Built-in `Count.java` that implements `CombinerAggregator.java`
  id: totrans-187
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.9\. 实现 `CombinerAggregator.java` 的内置 `Count.java`
- en: '![](226fig01_alt.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](226fig01_alt.jpg)'
- en: We know that we’ll be using the `Count` class to perform the actual counts,
    but we still need to wire up `Count` instances somewhere in our `TopologyBuilder`.
    Let’s look at various ways to do this next.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道我们将使用 `Count` 类来执行实际的计数，但我们仍然需要在我们的 `TopologyBuilder` 中将 `Count` 实例连接起来。让我们看看如何做到这一点。
- en: Choosing an aggregate operation to work with our aggregator implementation
  id: totrans-190
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 选择一个聚合操作与我们的聚合器实现一起使用
- en: 'Trident provides three ways to use an aggregator with a stream:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Trident 提供了三种方法来使用聚合器与流：
- en: '**`partitionAggregate`—** This operation takes on the single responsibility
    of aggregating tuples and works only within a single partition. This operation
    results in a `Stream` containing the aggregate result tuple(s). The code for setting
    up `partition-Aggregate` is as follows:'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`partitionAggregate`—** 这个操作承担了聚合元组的单一责任，并且仅在单个分区内工作。这个操作的结果是一个包含聚合结果元组的
    `Stream`。设置 `partition-Aggregate` 的代码如下：'
- en: '[PRE4]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**`aggregate`—** This operation takes on the single responsibility of aggregating
    tuples and works across all partitions within a single batch of tuples. The operation
    results in a `Stream` containing the aggregate result tuple(s). The code for setting
    up `aggregate` is as follows:'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`aggregate`—** 这个操作承担着聚合元组的单一职责，并在单个元组批次的所有分区中工作。操作的结果是一个包含聚合结果元组的`Stream`。设置`aggregate`的代码如下：'
- en: '[PRE5]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**`persistentAggregate`—** This operation applies across multiple batches and
    takes on the dual responsibility of aggregating the tuples and persisting the
    results. It will persist the aggregated results to a datastore managed by a `<state-factory>`.
    A state factory is Trident’s abstraction for working with a datastore. Because
    it works with state, `persistentAggregate` can work across batches. It does this
    by aggregating the current batch from the stream and then aggregating that value
    with the current value in the datastore. This operation results in a `TridentState`
    that can be queried against. The code for setting up `persistentAggregate` is
    as follows:'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`persistentAggregate`—** 这个操作跨越多个批次，承担着聚合元组和持久化结果的职责。它将聚合结果持久化到由`<state-factory>`管理的数据存储中。状态工厂是Trident用于与数据存储一起工作的抽象。因为它与状态一起工作，所以`persistentAggregate`可以在批次之间工作。它是通过从流中聚合当前批次，然后将该值与数据存储中的当前值聚合来实现的。这个操作产生了一个可以查询的`TridentState`。设置`persistentAggregate`的代码如下：'
- en: '[PRE6]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this list, the `Count` aggregator could be replaced with any `CombinerAggregator`,
    `ReducerAggregator`, or `Aggregator` implementation.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个列表中，`Count`聚合器可以被替换为任何`CombinerAggregator`、`ReducerAggregator`或`Aggregator`实现。
- en: Which of these aggregation operations best suits our needs? Let’s start with
    `partition-Aggregate`. We know that `partitionAggregate` works within a single
    partition, so we must figure out if we need to aggregate within a single partition.
    We’ve already applied a `groupBy` operation to group tuples by a field (artist,
    title, and tag) and then count the number of tuples within that group across the
    entire batch. This means we’re going across partitions, making `partitionAggregate`
    not the choice for us.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 哪种聚合操作最适合我们的需求？让我们从`partition-Aggregate`开始。我们知道`partitionAggregate`在单个分区内部工作，因此我们必须弄清楚我们是否需要在单个分区内部进行聚合。我们已经对一个字段（艺术家、标题和标签）的元组应用了`groupBy`操作来分组，然后在整个批次中计算该组内的元组数量。这意味着我们正在跨分区操作，这使得`partitionAggregate`不是我们的选择。
- en: Next up is `aggregate`. The `aggregate` operation works across all partitions
    within a batch of tuples, which is what we need. But if we decide to use `aggregate`,
    we’ll need to apply another operation to persist the aggregated results. So `aggregate`
    can work if we decide to take on additional work and build more that allows us
    to aggregate across batches and persist the results.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是`aggregate`操作。`aggregate`操作在元组批次的所有分区中工作，这正是我们所需要的。但如果我们决定使用`aggregate`，我们还需要应用另一个操作来持久化聚合结果。因此，如果我们决定承担更多的工作并构建更多内容，允许我们在批次之间聚合并持久化结果，`aggregate`就可以工作。
- en: We have a feeling there’s a better choice for our scenario, which brings us
    to `persistent-Aggregate`. The name alone gives us the feeling that it might be
    the operation we need. We need to both aggregate counts and then persist those
    aggregated results. Because `persistentAggregate` works with state and thus works
    across batches, it feels like the perfect choice for our scenario. In addition,
    `persistentAggregate` leaves us with a `TridentState` object that can be queried
    against, making it easy for us to build the various reports we discussed earlier
    in the problem definition.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感觉对于我们的场景，可能有一个更好的选择，这让我们想到了`persistent-Aggregate`。仅从名称上，我们就有一种感觉，这可能正是我们需要进行的操作。我们需要对计数进行聚合，并将这些聚合结果持久化。因为`persistentAggregate`与状态一起工作，因此可以在批次之间工作，这使得它非常适合我们的场景。此外，`persistentAggregate`为我们留下了一个可以查询的`TridentState`对象，这使得我们很容易构建之前在问题定义中讨论的各种报告。
- en: 'We’ve settled on `persistentAggregate` for our solution, but there’s one last
    piece we need to define before we’re done. Let’s look at the code for `persistent-Aggregate`
    again:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经决定使用`persistentAggregate`作为我们的解决方案，但在完成之前，我们还需要定义最后一个部分。让我们再次看看`persistent-Aggregate`的代码：
- en: '[PRE7]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We still need a `<state-factory>`, which we’ll discuss next.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然需要一个`<state-factory>`，我们将在下一节讨论。
- en: Working with state
  id: totrans-205
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 处理状态
- en: We need an implementation of `StateFactory` when dealing with state in Trident.
    This `StateFactory` serves as an abstraction that knows both how to query and
    update a datastore. For our scenario, we’re going to choose `MemoryMapState.Factory`,
    which is bundled with Trident. `MemoryMapState.Factory` works with an in-memory
    `Map` and will serve our needs fine for now. The code for wiring up this factory
    can be seen in the following listing.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Trident 中处理状态时，我们需要一个 `StateFactory` 的实现。这个 `StateFactory` 作为一种抽象，知道如何查询和更新数据存储。在我们的场景中，我们将选择与
    Trident 一起捆绑的 `MemoryMapState.Factory`。`MemoryMapState.Factory` 与内存中的 `Map` 一起工作，目前它完全可以满足我们的需求。连接这个工厂的代码可以在下面的列表中看到。
- en: Listing 9.10\. Using a `persistentAggregate` operation to update/persist counts
    in `TopologyBuilder.java`
  id: totrans-207
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.10\. 使用 `persistentAggregate` 操作在 `TopologyBuilder.java` 中更新/持久化计数
- en: '![](ch09ex10-0.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![ch09ex10-0.jpg](ch09ex10-0.jpg)'
- en: '![](ch09ex10-1.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![ch09ex10-1.jpg](ch09ex10-1.jpg)'
- en: 'That brings the basic implementation of our Trident topology to a close. We’re
    now at a place where we have in-memory counts for all of the fields we’re interested
    in: `artist`, `title`, and `tag`. We’re done now; ready to move on, right? Well,
    not quite. We’d hate to leave you hanging with these in-memory counts that you
    have no way of accessing. Let’s look at a way to implement access to these counts.
    It will come in the form of Storm’s DRPC functionality.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了我们 Trident 拓扑的基本实现。我们现在已经拥有了所有感兴趣字段的内存计数：`artist`、`title` 和 `tag`。现在我们已经完成了；准备好继续前进，对吧？嗯，还不完全是。我们不想让你带着这些无法访问的内存计数离开。让我们看看如何实现对这些计数的访问。这将以
    Storm 的 DRPC 功能的形式出现。
- en: 9.5\. Accessing the persisted counts through DRPC
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5\. 通过 DRPC 访问持久化的计数
- en: Now that we have `TridentState` objects with counts by artist, title, and tag,
    we can query these state objects to build the reports we need. We want our reporting
    application to be external to Storm, so this reporting application needs to be
    able to query this topology to get the data it needs. We’ll make use of distributed
    remote procedure calls (DRPC) for this purpose.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了按艺术家、标题和标签计数的 `TridentState` 对象，我们可以查询这些状态对象来构建我们需要的报告。我们希望我们的报告应用程序在
    Storm 之外，因此这个报告应用程序需要能够查询这个拓扑以获取它所需的数据。我们将利用分布式远程过程调用（DRPC）来实现这个目的。
- en: In Storm DRPC, the client will invoke a DRPC request with a Storm DRPC server,
    which will coordinate the request by sending it to the corresponding Storm topology
    and wait for the response from that topology. Once it receives the response, it
    will communicate that back to the calling client. This in effect acts as a distributed
    query by querying for multiple artists or tags in parallel and summing up the
    results.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Storm DRPC 中，客户端将使用 Storm DRPC 服务器调用一个 DRPC 请求，该服务器将通过将请求发送到相应的 Storm 拓扑并等待该拓扑的响应来协调请求。一旦它收到响应，它将把这个响应传达给调用客户端。这实际上通过并行查询多个艺术家或标签并汇总结果来充当一个分布式查询。
- en: 'This section covers the three parts of Storm DRPC required to implement our
    solution for querying the counts:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖了实现我们的查询计数解决方案所需的 Storm DRPC 的三个部分：
- en: Creating a DRPC stream
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个 DRPC 流
- en: Applying a DRPC state query to the stream
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 DRPC 状态查询应用于流
- en: Using the DRPC client to make DRPC calls via Storm
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 DRPC 客户端通过 Storm 进行 DRPC 调用
- en: We’ll start our explanation with the DRPC stream.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从 DRPC 流开始我们的解释。
- en: 9.5.1\. Creating a DRPC stream
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.5.1\. 创建一个 DRPC 流
- en: When the Storm DRPC server receives a request, it needs to route it to our topology.
    For our topology to be able handle this incoming request, it needs a DRPC stream.
    The Storm DRPC server will route any incoming requests to this stream. The DRPC
    stream is given a name that’s intended to be the name of this distributed query
    we want to execute. The DRPC server will identify which topology (and which stream
    within that topology) to route incoming requests based on this name. The next
    listing shows how to create a DRPC stream.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Storm DRPC 服务器接收到一个请求时，它需要将其路由到我们的拓扑。为了我们的拓扑能够处理这个传入的请求，它需要一个 DRPC 流。Storm
    DRPC 服务器将把任何传入的请求路由到这个流。DRPC 流被赋予一个名称，这个名称是我们想要执行的这个分布式查询的名称。DRPC 服务器将根据这个名称确定要路由到哪个拓扑（以及该拓扑中的哪个流）。下面的列表显示了如何创建一个
    DRPC 流。
- en: Listing 9.11\. Creating a DRPC stream
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.11\. 创建一个 DRPC 流
- en: '[PRE8]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The DRPC server accepts arguments for a DRPC function as text and forwards it
    along with the request to this DRPC stream. We need to parse the textual arguments
    into a form that we can make use of within the DRPC stream. The following listing
    defines the contract for the arguments for our `count-request-by-tag` DRPC stream
    to be a comma-delimited list of tags we want to query by.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: DRPC 服务器接受以文本形式传递给 DRPC 函数的参数，并将这些参数与请求一起转发到该 DRPC 流。我们需要将这些文本参数解析成我们可以在 DRPC
    流中使用的格式。以下列表定义了我们的 `count-request-by-tag` DRPC 流的参数合同，即我们想要查询的标签的逗号分隔列表。
- en: Listing 9.12\. Defining the contract for the arguments for the DRPC stream
  id: totrans-224
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.12\. 定义 DRPC 流参数的合同
- en: '[PRE9]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[Listing 9.12](#ch09ex12) references an each function called `SplitOnDelimiter`,
    so let’s take a look at that class’s implementation, as shown in the following
    listing.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 9.12](#ch09ex12) 引用了名为 `SplitOnDelimiter` 的每个函数，因此让我们看看该类的实现，如下列表所示。'
- en: Listing 9.13\. `SplitOnDelimiter.java`
  id: totrans-227
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.13\. `SplitOnDelimiter.java`
- en: '![](230fig01_alt.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![230fig01_alt.jpg](230fig01_alt.jpg)'
- en: This gives us a basic DRPC stream to work with. The next step is to apply a
    state query to this stream.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了一个基本的 DRPC 流来工作。下一步是将状态查询应用于此流。
- en: 9.5.2\. Applying a DRPC state query to a stream
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.5.2\. 将 DRPC 状态查询应用于流
- en: The state query we want to execute in response to this DRPC request is to count
    the number of play logs by given tag arguments. Let’s refresh our memory of how
    we calculated `TridentState` for the tags before we continue, as shown in the
    next listing.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要执行的针对此 DRPC 请求的状态查询是按给定标签参数计算播放日志的数量。在我们继续之前，让我们刷新一下如何计算标签的 `TridentState`
    的记忆，如下列表所示。
- en: Listing 9.14\. Creating the `counts-by-tag` stream resulting in `TridentState`
  id: totrans-232
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.14\. 创建导致 `TridentState` 的 `counts-by-tag` 流
- en: '[PRE10]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We stored the counts by a given tag in an in-memory map with the tag as the
    key and count as the value. Now all we need to do is look up the counts for the
    tags we received as arguments for the DRPC query. This is achieved through the
    `stateQuery` operation on the DRPC stream. An explanation of the `stateQuery`
    operation can be seen in [figure 9.9](#ch09fig09).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用标签作为键和计数作为值，将按给定标签的计数存储在内存映射中。现在我们只需要查找作为 DRPC 查询参数接收到的标签的计数。这是通过 DRPC 流上的
    `stateQuery` 操作实现的。`stateQuery` 操作的解释可以在 [图 9.9](#ch09fig09) 中看到。
- en: Figure 9.9\. Breaking down the `stateQuery` operation
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.9\. 分析 `stateQuery` 操作
- en: '![](09fig09_alt.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![09fig09_alt.jpg](09fig09_alt.jpg)'
- en: As the figure illustrates, the `QueryFunction` we choose needs to know how to
    access the data through the `TridentState` object. Fortunately for us, Storm comes
    with a built-in `MapGet` query function that can work with our `MemoryMapState`
    implementation.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，我们选择的 `QueryFunction` 需要知道如何通过 `TridentState` 对象访问数据。幸运的是，Storm 内置了一个 `MapGet`
    查询函数，它可以与我们的 `MemoryMapState` 实现一起工作。
- en: But implementing this state query isn’t as simple as adding the `stateQuery`
    operation to the end of our DRPC stream. The reason for that is in our original
    play stream, we repartitioned the stream using a `groupBy` operation on the `tag`
    field. In order to send `count-request-by-tag` requests from the DRPC stream into
    the same partition that contains the needed tag in the `TridentState`, we need
    to apply a `groupBy` operation on the DRPC stream as well, on the same tag field.
    The next listing provides the code for this.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 但实现这个状态查询并不像在我们的 DRPC 流末尾添加 `stateQuery` 操作那么简单。原因是我们在原始播放流中，使用 `tag` 字段上的 `groupBy`
    操作重新分区了流。为了将 `count-request-by-tag` 请求从 DRPC 流发送到包含所需标签的 `TridentState` 的同一分区，我们还需要在
    DRPC 流上应用一个 `groupBy` 操作，在相同的标签字段上。下一个列表提供了相应的代码。
- en: Listing 9.15\. Looking up `counts-by-tag` by querying a source of state
  id: totrans-239
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.15\. 通过查询状态源查找 `counts-by-tag`
- en: '![](232fig01_alt.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![232fig01_alt.jpg](232fig01_alt.jpg)'
- en: Now we have the results of the count for each tag that we wanted. We can stop
    here in the DRPC stream and be done. Optionally, we can append an additional `each`
    operation to filter out null counts (that is, tags that haven’t yet been encountered
    on the play stream), but we’ll leave the nulls as something to be handled by the
    DRPC caller.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经得到了我们想要的每个标签的计数结果。我们可以在 DRPC 流中停止这里并完成。可选地，我们可以附加一个额外的 `each` 操作来过滤掉空计数（即尚未在播放流中遇到的标签），但我们将空值留给
    DRPC 调用者处理。
- en: 'This brings us to our final step: being able to communicate with Storm via
    a DRPC client.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这将我们带到最后一步：能够通过 DRPC 客户端与 Storm 进行通信。
- en: 9.5.3\. Making DRPC calls with a DRPC client
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.5.3\. 使用 DRPC 客户端调用 DRPC 调用
- en: Making a DRPC request to this topology can be done by including Storm as a dependency
    in your client application and using the DRPC client built into Storm. Once you’ve
    done this, you can use something similar to the code in the next listing for making
    the actual DRPC request.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 向此拓扑发送DRPC请求可以通过在您的客户端应用程序中包含Storm作为依赖项，并使用Storm内置的DRPC客户端来完成。一旦这样做，您就可以使用类似于下一列表中的代码来发送实际的DRPC请求。
- en: Listing 9.16\. Performing a DRPC request
  id: totrans-245
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.16\. 执行DRPC请求
- en: '![](232fig02_alt.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](232fig02_alt.jpg)'
- en: DRPC requests are made over the Thrift protocol, so you’ll need to handle the
    Thrift-related errors (usually connectivity-related) as well as `DRPCExecutionException`
    errors (usually feature-related). And that’s it. We haven’t left you hanging.
    You now have a topology that maintains state with the counts for various fields
    of `artist`, `title`, and `tag`, and you’re able to query that state. We’ve built
    a fully functional topology using Trident and Storm DRPC.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: DRPC请求是通过Thrift协议进行的，因此您需要处理与Thrift相关的错误（通常是连接相关）以及`DRPCExecutionException`错误（通常是功能相关）。就是这样。我们没有让您失望。现在您有一个拓扑，它可以维护`artist`、`title`和`tag`等不同字段的计数状态，并且您能够查询该状态。我们已经使用Trident和Storm
    DRPC构建了一个完全功能化的拓扑。
- en: Or is that it? If you’ve learned anything from earlier chapters, it’s that once
    you’ve deployed your topology, your job as a developer hasn’t ended. The same
    holds true here. [Section 9.6](#ch09lev1sec6) discusses how Trident operations
    map to Storm primitives using the Storm UI to identify the spouts and bolts that
    are created under the covers. [Section 9.7](#ch09lev1sec7) will then touch upon
    scaling a Trident topology.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 或者就这样了吗？如果您从前面的章节中学到了什么，那就是一旦您部署了拓扑，作为开发者的工作还没有结束。这里也是同样的情况。[第9.6节](#ch09lev1sec6)讨论了如何使用Storm
    UI来识别在幕后创建的spout和bolt，以将Trident操作映射到Storm原语。[第9.7节](#ch09lev1sec7)将接着讨论扩展Trident拓扑。
- en: 9.6\. Mapping Trident operations to Storm primitives
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.6\. 将Trident操作映射到Storm原语
- en: Recall that in the beginning of the chapter we discussed how Trident topologies
    are built on top of the Storm primitives that we’ve become comfortable with over
    the course of this book. With our use case complete, let’s take a look at how
    Storm turns our Trident topology into bolts and spouts. We’ll start by looking
    at how our topology, sans our DRPC spout, is mapped down to Storm primitives.
    Why not just look at everything at once? We feel it will be easier to understand
    what exactly is going on by addressing the core Trident streams first and then
    tacking on the DRPC stream.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，在本章的开头我们讨论了如何基于我们在本书中逐渐熟悉的Storm原语构建Trident拓扑。随着我们的用例完成，让我们看看Storm是如何将我们的Trident拓扑转换为bolt和spout的。我们将首先查看没有我们的DRPC
    spout，我们的拓扑是如何映射到Storm原语的。为什么不一次性查看所有内容呢？我们觉得首先处理核心的Trident流，然后再添加DRPC流，这样更容易理解到底发生了什么。
- en: Without our DRPC spout, our `TopologyBuilder` code can be seen in the following
    listing.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 没有我们的DRPC spout，我们的`TopologyBuilder`代码可以在以下列表中看到。
- en: Listing 9.17\. `TopologyBuilder.java` without the DRPC stream
  id: totrans-252
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.17\. 没有DRPC流的`TopologyBuilder.java`
- en: '[PRE11]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When our Trident topology is being turned into a Storm topology, Storm takes
    our Trident operations and packages them into bolts in a way that’s efficient.
    Some operations will be grouped together into the same bolts whereas others will
    be separate. The Storm UI provides a view into how that mapping is being done
    ([figure 9.10](#ch09fig10)).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的Trident拓扑被转换为Storm拓扑时，Storm会以高效的方式将我们的Trident操作打包到bolt中。一些操作将被组合到同一个bolt中，而其他操作将是独立的。Storm
    UI提供了一个视图，展示了这种映射是如何进行的（[图9.10](#ch09fig10)）。
- en: Figure 9.10\. Our Trident topology broken down into spouts and bolts in the
    Storm UI
  id: totrans-255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.10\. 在Storm UI中分解为spout和bolt的我们的Trident拓扑
- en: '![](09fig10.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig10.jpg)'
- en: As you can see, we have one spout and six bolts. Two of the bolts have the name
    “spout” in them and four others are labeled b-0 to b-3\. We can see some components
    there but we have no idea how they’re related to our Trident operations.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们有一个spout和六个bolt。其中两个bolt的名称中包含“spout”，另外四个分别标记为b-0到b-3。我们可以在那里看到一些组件，但我们不知道它们如何与我们的Trident操作相关联。
- en: Rather than try to figure out the mystery behind the names, we’ll show you a
    way to make it easier to identify the components. Trident has a name operation
    that assigns a name we specify to an operation. If we name each collection of
    operations in our topology, our code ends up like that in the next listing.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是试图解开名称背后的神秘，我们将向您展示一种使识别组件更容易的方法。Trident有一个命名操作，它将我们指定的名称分配给一个操作。如果我们给拓扑中的每个操作集合命名，我们的代码最终会像下面列表中的那样。
- en: Listing 9.18\. `TopologyBuilder.java` with named operations
  id: totrans-259
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.18\. `TopologyBuilder.java`带有命名操作
- en: '[PRE12]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: If we take a look at our Storm UI, what’s going on becomes much more apparent
    ([figure 9.11](#ch09fig11)).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看我们的Storm UI，发生的事情就变得更加明显了([图9.11](#ch09fig11))。
- en: Figure 9.11\. Our Trident topology displayed on the Storm UI after naming each
    of the operations
  id: totrans-262
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.11\. 在Storm UI上命名每个操作后显示的我们的Trident拓扑
- en: '![](09fig11.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig11.jpg)'
- en: We can see that our `b-3` bolt was log deserialization and sanitation. And our
    `b-0`, `b-1`, and `b-2` bolt our title, tag, and artist counting, respectively.
    Given the amount of clarity that using names provides, we recommend you always
    name your partitions.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，我们的`b-3`螺栓是日志反序列化和净化。而我们的`b-0`、`b-1`和`b-2`螺栓分别对应标题、标签和艺术家计数。考虑到使用名称提供的清晰度，我们建议您始终为分区命名。
- en: What’s up with the name of the log deserialization bolt? `LogDeserializer-Sanitizer-ArtistCounts-LogDeserializerSanitizer-TitleCounts-Log-Deserializer-Sanitizer-TagCounts`—what
    a mouthful! But it does provide us with a great deal of information. The name
    indicates that we’re getting our data from the log deserializer and sanitizer
    and feeding into artist counts, title counts, and tag counts. It’s not the most
    elegant of discovery mechanisms but it beats just b-0 and so on.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 日志反序列化螺栓的名称是怎么回事？`LogDeserializer-Sanitizer-ArtistCounts-LogDeserializerSanitizer-TitleCounts-Log-Deserializer-Sanitizer-TagCounts`——多么冗长！但它确实为我们提供了大量信息。名称表明我们从日志反序列化和净化器获取数据，并将其输入到艺术家计数、标题计数和标签计数中。这不是最优雅的发现机制，但比仅仅b-0要好。
- en: With this additional clarity, take a look at [figure 9.12](#ch09fig12), which
    illustrates how our Trident operations are mapped down into bolts. Now let’s add
    back the DRPC stream with relevant names as well. The code for this appears in
    the next listing.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得这种额外的清晰度后，看看[图9.12](#ch09fig12)，它说明了我们的Trident操作是如何映射到螺栓中的。现在让我们添加回带有相关名称的DRPC流。这个代码在下一个列表中。
- en: Figure 9.12\. How our Trident operations are mapped down into bolts
  id: totrans-267
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.12\. 我们Trident操作如何映射到螺栓中
- en: '![](09fig12.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig12.jpg)'
- en: Listing 9.19\. The DRPC stream with named operations
  id: totrans-269
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表9.19\. 带有命名操作的DRPC流
- en: '[PRE13]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Adding the DRPC stream with named operations results in the Storm UI seen in
    [figure 9.13](#ch09fig13).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 添加带有命名操作的DRPC流导致出现[图9.13](#ch09fig13)中看到的Storm UI。
- en: Figure 9.13\. The Storm UI with named operations for both the Trident topology
    and DRPC stream
  id: totrans-272
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.13\. 包含Trident拓扑和DRPC流的命名操作的Storm UI
- en: '![](09fig13_alt.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig13_alt.jpg)'
- en: What has changed? Well...
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 发生了什么变化？嗯...
- en: Our log sanitizer bolt is now b-2 rather than b-3\. This is very important.
    You can’t rely on the autogenerated bolt names remaining the same when you make
    changes to the number of bolts in the topology.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们日志净化器螺栓现在是b-2而不是b-3。这非常重要。当您更改拓扑中螺栓的数量时，不能依赖自动生成的螺栓名称保持不变。
- en: The number of named bolts has increased from 4 to 5 and the names of those bolts
    have changed.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 命名螺栓的数量从4个增加到5个，并且这些螺栓的名称也发生了变化。
- en: We have some unnamed bolts. What’s going on with the bolt name changes? The
    addition of our DRPC spout has changed the mapping onto Storm primitives and names
    have changed accordingly. [Figure 9.14](#ch09fig14) shows the final mapping of
    Trident/DRPC operations into bolts.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一些未命名的螺栓。螺栓名称变更发生了什么情况？我们添加了DRPC喷嘴后，映射到Storm原语和名称相应地发生了变化。[图9.14](#ch09fig14)显示了Trident/DRPC操作最终映射到螺栓的过程。
- en: Figure 9.14\. How the Trident and DRPC streams and operations are being mapped
    down into bolts
  id: totrans-278
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.14\. Trident和DRPC流以及操作如何映射到螺栓中
- en: '![](09fig14_alt.jpg)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![](09fig14_alt.jpg)'
- en: Note how “Tag Counts” and “Query for Request” are mapped to the same bolt and
    the name has been adjusted accordingly. Okay, but what about those unnamed bolts?
    The reason why we saw some components named as spouts in the bolts section of
    the UI is because Storm runs Trident spouts wrapped in a bolt. Remember that Trident
    spouts aren’t the same as native Storm spouts. Additionally, Trident topologies
    have other coordinators that allow us to treat an incoming stream as a series
    of batches. Storm introduced them when we added the DRPC spout to our topology
    and changed how it was mapped to Storm.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 注意“标签计数”和“请求查询”是如何映射到同一个螺栓，并且名称已经相应调整。好吧，那么那些未命名的螺栓怎么办？我们之所以在 UI 的螺栓部分看到一些组件被命名为喷嘴，是因为
    Storm 运行在螺栓中的 Trident 喷嘴。记住，Trident 喷嘴与本地 Storm 喷嘴不同。此外，Trident 拓扑还有其他协调器，允许我们将传入的流视为一系列批次。当我们将
    DRPC 喷嘴添加到拓扑中并更改其映射方式时，Storm 引入了它们。
- en: 'Identifying how Storm maps Trident operations to native Storm components is
    easy with a few extra lines of code. Adding names is the key and will save you
    headaches. Now that you have an idea of how to map native Storm components to
    Trident operations via names and the Storm UI, let’s turn our attention to the
    final topic of this chapter: scaling a Trident topology.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 通过几行额外的代码，很容易识别 Storm 如何将 Trident 操作映射到本地 Storm 组件。添加名称是关键，这将节省你很多麻烦。现在你已经了解了如何通过名称和
    Storm UI 将本地 Storm 组件映射到 Trident 操作，让我们将注意力转向本章的最后一个主题：扩展 Trident 拓扑。
- en: 9.7\. Scaling a Trident topology
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.7\. 扩展 Trident 拓扑
- en: Let’s talk units of parallelism. When working with bolts and spouts, we trade
    in executors and tasks. They form our primary means of parallelism between components.
    When working with Trident, we still work with them but only tangentially as Trident
    operations are mapped down to those primitives. When working with Trident, our
    primary method to achieve parallelism is the partition.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈并行单位。当处理螺栓和喷嘴时，我们交换执行者和任务。它们构成了组件之间并行的主要手段。当使用 Trident 时，我们仍然与它们一起工作，但只是作为
    Trident 操作映射到这些原语。当使用 Trident 时，我们实现并行的主要方法是分区。
- en: 9.7.1\. Partitions for parallelism
  id: totrans-284
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.7.1\. 用于并行的分区
- en: With Trident, we take a stream of data and work with it across one or more worker
    processes by partitioning the stream and applying our operations in parallel across
    each of the partitions. If we had five partitions within our topology and three
    worker processes, our work would be distributed in a fashion similar to what’s
    shown in [figure 9.15](#ch09fig15).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Trident，我们通过分区流并在每个分区上并行应用我们的操作，在一个或多个工作进程中处理数据流。如果我们拓扑中有五个分区和三个工作进程，我们的工作将以类似
    [图 9.15](#ch09fig15) 中所示的方式分布。
- en: Figure 9.15\. Partitions are distributed across storm worker process (JVMs)
    and operated on in parallel
  id: totrans-286
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.15\. 分区分布在 storm 工作进程（JVM）上，并并行操作
- en: '![](09fig15.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![图片](09fig15.jpg)'
- en: Unlike Storm, where we imagine our parallelism as spreading executors across
    a series of worker processes, here we’re imagining our parallelism as a series
    of partitions being spread across a series of worker processes. The way we scale
    our Trident topology is by adjusting the number of partitions.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Storm 不同，在 Storm 中我们想象并行性是跨一系列工作进程分散执行者，而在这里我们想象并行性是一系列分区被分散到一系列工作进程中。我们通过调整分区数量来扩展
    Trident 拓扑。
- en: 9.7.2\. Partitions in Trident streams
  id: totrans-289
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9.7.2\. Trident 流中的分区
- en: Partitions start at the Trident spout. A Trident spout (a much different beast
    from a Storm spout) will emit a stream, which then has a set of Trident operations
    applied to it. This stream is partitioned to provide parallelism for the topology.
    Trident will break down this partitioned stream into a series of small batches
    containing thousands of tuples to perhaps millions of tuples, depending on your
    incoming throughput. [Figure 9.16](#ch09fig16) shows the zoomed-in view of what
    a Trident stream looks like between two Trident operations or between the Trident
    spout and the first Trident operation.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 分区从 Trident 喷嘴开始。Trident 喷嘴（与 Storm 喷嘴大不相同）会发出一个流，然后对这个流应用一系列 Trident 操作。这个流被分区以提供拓扑的并行性。Trident
    将这个分区流分解成一系列小批量，包含数千个元组到数百万个元组，具体取决于你的输入吞吐量。[图 9.16](#ch09fig16) 展示了两个 Trident
    操作之间或 Trident 喷嘴和第一个 Trident 操作之间的 Trident 流的放大视图。
- en: Figure 9.16\. Partitioned stream with a series of batches in between two operations
  id: totrans-291
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.16\. 两个操作之间带有一系列批次的分区流
- en: '![](09fig16_alt.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![图片](09fig16_alt.jpg)'
- en: If parallelism starts at the spout, and we adjust the number of partitions to
    control parallelism, how do we adjust the number of partitions at the spout? We
    adjust the number of partitions for the Kafka topic we’re subscribed to. If we
    had one partition for our Kafka topic, then we’d start with one partition in our
    topology. If we increased our Kafka topic to having three partitions, the number
    of partitions in our Trident topology would change accordingly ([figure 9.17](#ch09fig17)).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 如果并行度从 spout 开始，并且我们调整分区数来控制并行度，我们如何调整 spout 上的分区数？我们调整我们订阅的 Kafka 主题的分区数。如果我们有一个
    Kafka 主题的分区，那么我们的拓扑将从一个分区开始。如果我们把 Kafka 主题增加到有三个分区，那么我们的 Trident 拓扑中的分区数将相应改变（[图
    9.17](#ch09fig17)）。
- en: Figure 9.17\. Kafka topic partitions and how they relate to the partitions within
    a Trident stream
  id: totrans-294
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.17\. Kafka 主题分区及其与 Trident 流中分区的关系
- en: '![](09fig17_alt.jpg)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![图片](09fig17_alt.jpg)'
- en: From here, our stream with three partitions can be partitioned further by various
    operations. Let’s step back from talking about having three partitions from the
    spout and go back to having just one; it will make everything else easier to reason
    about when learning more about parallelism within our Trident topology.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们的三个分区的流可以通过各种操作进一步分区。让我们从谈论从 spout 有三个分区的话题退一步，回到只有一个分区；在学习我们 Trident
    拓扑中的并行度时，这将使其他一切更容易推理。
- en: Within a Trident topology, natural points of partition will exist. Points where
    partitioning has to change are based on the operations being applied. At these
    points, you can adjust the parallelism of each of the resulting partitions. The
    `groupBy` operations that we use in our topology result in repartitioning. Each
    of our `groupBy` operations resulted in a repartitioning that we could supply
    a parallelism hint to, as shown in the following listing.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Trident 拓扑中，将存在自然的分区点。需要改变分区的地方基于正在应用的运算。在这些点上，您可以调整每个结果分区的并行度。我们在拓扑中使用的 `groupBy`
    操作会导致重新分区。我们每个 `groupBy` 操作都导致了一种重新分区，我们可以向其提供并行度提示，如下面的列表所示。
- en: Listing 9.20\. Specifying parallelism at the points of repartition
  id: totrans-298
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 9.20\. 在重新分区点指定并行度
- en: '[PRE14]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here we’ve given each of our final three bolts a parallelism of four. That means
    they each operate with four partitions. We were able to specify a level of parallelism
    for those because there’s natural repartitioning happening between them and bolts
    that came before them due to `groupBy` and `persistentAggregate` operations. We
    didn’t specify any parallelism hint to our first two bolts because they don’t
    have any inherent repartitioning going on between them and the spouts that came
    before them. Therefore, they operate at the same number of partitions as the spouts.
    [Figure 9.18](#ch09fig18) shows what this configuration looks like in the Storm
    UI.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们给我们的最后三个 bolt 分别分配了四个并行度。这意味着它们各自使用四个分区。我们能够为它们指定并行度，因为它们之间以及它们之前的 bolts
    之间由于 `groupBy` 和 `persistentAggregate` 操作发生了自然的重新分区。我们没有为前两个 bolts 指定任何并行度提示，因为它们之间以及它们之前的
    spouts 之间没有进行任何内在的重新分区。因此，它们以与 spouts 相同的分区数运行。[图 9.18](#ch09fig18) 展示了这种配置在 Storm
    UI 中的样子。
- en: Figure 9.18\. Result of applying a parallelism hint of four to the `groupBy`
    operations in our Trident topology
  id: totrans-301
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 9.18\. 将四个并行度提示应用于我们的 Trident 拓扑中的 `groupBy` 操作的结果
- en: '![](09fig18_alt.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图片](09fig18_alt.jpg)'
- en: '|  |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Forcing a repartition**'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '**强制重新分区**'
- en: In addition to natural changes in partitions that happen as a result of `groupBy`
    operations, we have the ability to force Trident to repartition operations. Such
    operations will cause tuples to be transferred across the network as the partitions
    are changed. This will have a negative impact on performance. You should avoid
    repartitioning solely for the sake of changing parallelism unless you can verify
    that your parallelism hints post repartitioning have caused an overall throughput
    increase.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 除了由于 `groupBy` 操作导致的分区自然变化之外，我们还有能力强制 Trident 进行重新分区操作。此类操作将在分区改变时导致元组在网络中传输。这将对性能产生负面影响。除非您能验证重新分区后的并行度提示确实导致了整体吞吐量的增加，否则您应该避免仅为了改变并行度而进行重新分区。
- en: '|  |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: This brings us to the close of Trident. You’ve learned quite a bit in this chapter,
    all of which was built on a foundation that was laid in the first eight chapters
    of this book. Hopefully this foundation is only the beginning of your adventure
    with Storm, and our goal is for you to continue to refine and tune these skills
    as you use Storm for any problem you may encounter.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们来到了Trident的结尾。在本章中，你学到了很多，所有这些都建立在这本书前八章所奠定的基础之上。希望这个基础只是你Storm冒险的开始，我们的目标是让你在使用Storm解决任何问题时，继续对这些技能进行优化和调整。
- en: 9.8\. Summary
  id: totrans-308
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.8. 摘要
- en: In this chapter, you learned that
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解到
- en: Trident allows you to focus on the “what” of solving a problem rather than the
    “how.”
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident允许你专注于解决问题的“是什么”，而不是“如何”。
- en: Trident makes use of operations that operate on batches of tuples, which are
    different from native Storm bolts that operate on individual tuples.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident利用操作在元组批次上运行，这与在单个元组上运行的Storm bolts原生操作不同。
- en: Kafka is a distributed message queue implementation that aligns perfectly with
    how Trident operates on batches of tuples across partitions.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kafka是一个分布式消息队列实现，它与Trident在分区上对元组批次进行操作的运行方式完美匹配。
- en: Trident operations don’t map one-to-one to spouts and bolts, so it’s important
    to always name your operations.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Trident操作并不直接映射到spouts和bolts，因此始终命名你的操作是很重要的。
- en: Storm DRPC is a useful way to execute a distributed query against persistent
    state calculated by a Storm topology.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm DRPC是执行针对由Storm拓扑计算出的持久状态的分布式查询的有用方式。
- en: Scaling a Trident topology is much different than scaling a native Storm topology
    and is done across partitions as opposed to setting exact instances of spouts
    and bolts.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展Trident拓扑与扩展原生Storm拓扑大不相同，并且是在分区上进行的，而不是设置spouts和bolts的确切实例。
