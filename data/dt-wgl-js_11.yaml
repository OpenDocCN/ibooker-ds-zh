- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Live data
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 实时数据
- en: '**This chapter covers**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**本章涵盖**'
- en: Working with a real-time data feed
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与实时数据流一起工作
- en: Receiving data through HTTP POST and sockets
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过HTTP POST和套接字接收数据
- en: Decoupling modules in your server with an event-based architecture
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于事件的架构解耦服务器模块
- en: Triggering SMS alerts and generating automated reports
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 触发短信警报并生成自动报告
- en: Sending new data to a live chart through socket.io
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过socket.io将新数据发送到实时图表
- en: 'In this chapter we bring together multiple aspects of data wrangling that we’ve
    already learned and combine them into a real-time data pipeline. We’re going to
    build something that’s almost a real production system. It’s a data pipeline that
    will do all the usual things: acquire and store data (chapter 3), clean and transform
    the data (chapter 6), and, in addition, perform on-the-fly data analysis (chapter
    9).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将汇集我们已经学习到的数据整理的多个方面，并将它们组合成一个实时数据管道。我们将构建几乎是一个真实生产系统的东西。这是一个将执行所有常规事情的数据管道：获取和存储数据（第3章），清理和转换数据（第6章），此外，还会进行即时数据分析（第9章）。
- en: Output from the system will take several forms. The most exciting will be a
    browser-based visualization, based on our work from chapter 10, but with live
    data feeding in and updating as we watch. It will automatically generate a daily
    report (using techniques from chapter 11) that’s emailed to interested parties.
    It will also issue SMS text message alerts about unusual data points arriving
    in the system.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的输出将采取几种形式。最令人兴奋的是基于浏览器的可视化，基于第10章的工作，但会有实时数据在观看时流入和更新。它将自动生成一份日报（使用第11章的技术），并将其发送给感兴趣的各方。它还将就系统收到的异常数据点发出短信警报。
- en: To be sure, the system we’ll build now will be something of a toy project, but
    besides that, it will demonstrate many of the features you’d want to see in a
    real system of this nature, and on a small scale, it could work in a real production
    environment.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们现在要构建的系统将是一个玩具项目，但除此之外，它将展示许多你希望在真实系统中看到的特性，并且在小规模上，它可以在真实的生产环境中工作。
- en: This will be one of the most complex chapters yet, but please stick with it!
    I can promise you that getting to the live visualization will be worth it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是迄今为止最复杂的章节之一，但请坚持下去！我可以向你保证，达到实时可视化将是值得的。
- en: 12.1 We need an early warning system
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 我们需要一个预警系统
- en: For many cities, monitoring the air quality is important, and in certain countries,
    it’s even regulated by the government. Air pollution can be a real problem, regardless
    of how it’s caused. In Melbourne, Australia, in 2016, an incident occurred that
    the media were calling thunderstorm asthma.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多城市来说，监测空气质量很重要，在有些国家，它甚至受到政府的监管。无论是由什么原因造成的，空气污染都可能成为一个真正的问题。在2016年的澳大利亚墨尔本，发生了一起媒体称之为雷暴哮喘的事件。
- en: A major storm hit the city, and the combination of wind and moisture caused
    pollen to break up and disperse into particles that were too small to be filtered
    out by the nose. People with asthma and allergies were at high risk. In the following
    hours, emergency services were overwhelmed with the large volume of calls. Thousands
    of people became ill. In the week that followed, nine people died. Some kind of
    early warning system might have helped prepare the public and the emergency services
    for the impending crisis, so let’s try building something like that.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一场大风暴袭击了这座城市，风和湿度的结合导致花粉破裂并分散成鼻子无法过滤的微小颗粒。患有哮喘和过敏症的人处于高风险。在接下来的几个小时里，紧急服务部门被大量电话淹没。成千上万的人生病了。在随后的那一周里，有九人死亡。某种预警系统可能有助于帮助公众和紧急服务部门为即将到来的危机做好准备，所以让我们尝试构建类似的东西。
- en: In this chapter, we’ll build an air quality monitoring system. It will be somewhat
    simplified but would at least be a good starting point for a full production system.
    We’re building an early warning system, and it must raise the alarm as soon as
    poor air quality is detected.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将构建一个空气质量监控系统。它将相对简化，但至少是一个完整生产系统的良好起点。我们正在构建一个预警系统，它必须在检测到空气质量不佳时立即发出警报。
- en: 'What are we aiming for here? Our live data pipeline will accept a continuous
    data feed from a hypothetical air quality sensor. Our system will have three main
    features:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里的目标是什么？我们的实时数据管道将从假设的空气质量传感器接受连续的数据流。我们的系统将具有三个主要功能：
- en: To allow air quality to be continuously monitored through a live chart
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许通过实时图表持续监测空气质量
- en: To automatically generate a daily report and email it to interested parties
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了自动生成每日报告并将其发送给感兴趣的相关方
- en: To continuously check the level of air quality and to raise an SMS text message
    alert when poor air quality is detected
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了持续检查空气质量水平，并在检测到空气质量不佳时发送短信警报
- en: This chapter is all about dealing with live and dynamic data, and we’ll try
    to do this in a real context. We’ll see more software architecture in this chapter
    than we’ve yet seen in the book because the work we’re doing is getting more complex
    and we need more powerful ways to organize our code. We’ll work toward building
    our application on an event-based architecture. To emulate how I’d really do the
    development, we’ll start simple and then restructure our code partway through
    to incorporate an event hub that will decouple the components of our app and help
    us to manage the rising level of complexity.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本章全部关于处理实时和动态数据，我们将尝试在一个真实的环境中完成这项工作。在本章中，我们将看到比书中之前看到的更多软件架构，因为我们所做的工作变得更加复杂，我们需要更强大的方式来组织我们的代码。我们将致力于在基于事件架构上构建我们的应用程序。为了模拟我真正如何进行开发，我们将从简单开始，然后在代码的部分重构中引入一个事件中心，这将解耦我们的应用程序组件，并帮助我们管理不断上升的复杂性水平。
- en: 12.2 Getting the code and data
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 获取代码和数据
- en: 'The code and data for this chapter are available in the Data Wrangling with
    JavaScript Chapter 12-repository in GitHub: [https://github.com/data-wrangling-with-javascript/chapter-12](https://github.com/data-wrangling-with-javascript/chapter-12)[.](http://.)
    Data for this chapter was acquired from the Queensland Government open data website
    at [https://data.qld.gov.au/](https://data.qld.gov.au/)[.](http://.)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码和数据可在GitHub上的Data Wrangling with JavaScript第12章仓库中找到：[https://github.com/data-wrangling-with-javascript/chapter-12](https://github.com/data-wrangling-with-javascript/chapter-12)[.](http://.)
    本章的数据是从昆士兰州政府开放数据网站[https://data.qld.gov.au/](https://data.qld.gov.au/)获取的[.](http://.)
- en: Each subdirectory in the code repo is a complete working example, and each corresponds
    to code listings throughout this chapter.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 代码仓库中的每个子目录都是一个完整的示例，并且每个子目录都对应本章中的代码列表。
- en: Before attempting to run the code in each subdirectory, please be sure to install
    the npm and Bower dependencies as necessary.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试运行每个子目录中的代码之前，请确保根据需要安装npm和Bower依赖项。
- en: Refer to “Getting the code and data” in chapter 2 for help on getting the code
    and data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考第2章中的“获取代码和数据”部分以获取获取代码和数据的帮助。
- en: 12.3 Dealing with live data
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 处理实时数据
- en: Creating a live data pipeline isn’t much different from anything else we’ve
    seen so far in the book, except now we’ll have a continuous stream of data pushed
    to us by a communication channel. [Figure 12.1](#figure12.1) gives the simplified
    overall picture. We’ll have an air pollution sensor (our data collection device)
    that submits the current metric of air quality to our Node.js server on an hourly
    basis, although we’ll speed this up dramatically for development and testing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 创建实时数据管道与我们之前在书中看到的任何其他事情并没有太大区别，只是现在我们将通过通信渠道接收连续的数据流。[图12.1](#figure12.1)给出了简化的整体图。我们将有一个空气污染传感器（我们的数据收集设备），它将每小时将当前的空气质量指标提交到我们的Node.js服务器，尽管为了开发和测试，我们会大幅加快这一过程。
- en: '![c12_01.eps](Images/c12_01.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![c12_01.eps](Images/c12_01.png)'
- en: '[Figure 12.1](#figureanchor12.1) An air pollution sensor pushes data to our
    Node.js server.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.1](#figureanchor12.1) 空气污染传感器将数据推送到我们的Node.js服务器。'
- en: For a more in-depth understanding of how the data feed fits into our pipeline,
    see [figure 12.2](#figure12.2). Incoming data arrives in our system on the left
    of the diagram at the data collection point. The data then feeds through the processing
    pipeline. You should recognize the various pipeline stages here and already have
    an idea what they do. Output is then delivered to our user through alerts, visualizations,
    and a daily report.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解数据流如何融入我们的管道，请参阅[图12.2](#figure12.2)。数据在图中的左侧数据收集点进入我们的系统。然后数据通过处理管道。你应该能识别出这里的各个管道阶段，并且已经对它们的作用有了概念。输出随后通过警报、可视化和每日报告交付给用户。
- en: '![c12_02.eps](Images/c12_02.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![c12_02.eps](Images/c12_02.png)'
- en: '[Figure 12.2](#figureanchor12.2) We’ll now have a continuous stream of data
    flowing into our data pipeline.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.2](#figureanchor12.2) 现在，我们将有一个连续的数据流进入我们的数据处理管道。'
- en: 12.4 Building a system for monitoring air quality
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 构建空气质量监控系统
- en: Before we dive into building our air quality monitoring system, let’s look at
    the data we have. The CSV data file *brisbanecbd-aq-2014.csv* is available under
    the *data* subdirectory of the Chapter-12 GitHub repository. As usual, we should
    take a good look at our data before we start coding. You can see an extract from
    the data file in [figure 12.3](#figure12.3).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入构建空气质量监测系统之前，让我们看看我们拥有的数据。CSV数据文件*brisbanecbd-aq-2014.csv*可在第12章GitHub仓库的*data*子目录下找到。像往常一样，在我们开始编码之前，我们应该仔细查看我们的数据。你可以在[图12.3](#figure12.3)中看到数据文件的摘录。
- en: This data was downloaded from the Queensland Government open data website.^([1](#c12-footnote-1)) 
    Thanks to the Queensland Government for supporting open data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这份数据是从昆士兰州政府开放数据网站下载的.^([1](#c12-footnote-1)) 感谢昆士兰州政府支持开放数据。
- en: The data file contains an hourly reading of atmospheric conditions. The metric
    of interest is the PM10 column. This is the count of particles in the air that
    are less than 10 micrometers in diameter. Pollen and dust are two examples of
    such particles. To understand how small this is, you need to know that a human
    hair is around 100 micrometers wide, so 10 of these particles can be placed on
    the width of a human hair. That’s tiny.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据文件包含大气条件的每小时读数。我们感兴趣的指标是PM10列。这是直径小于10微米的空气中颗粒物的计数。花粉和灰尘是这类颗粒物的例子。为了理解这有多小，你需要知道人类头发的宽度大约是100微米，所以10个这样的颗粒物可以放在一根人类头发的宽度上。这非常小。
- en: Particulate matter this small can be drawn into the lungs, whereas bigger particles
    are often trapped in the nose, mouth, and throat. The PM10 value specifies mass
    per volume, in this case micrograms per cubic meter (µg/m³).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这样小的颗粒物可以被吸入肺部，而较大的颗粒物通常被鼻子、嘴巴和喉咙捕获。PM10值指定的是质量与体积的比率，在这种情况下是每立方米微克（µg/m³）。
- en: '![c12_03.eps](Images/c12_03.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![c12_03.eps](Images/c12_03.png)'
- en: '[Figure 12.3](#figureanchor12.3) The data for this chapter. We’re interested
    in the PM10 column for monitoring air quality.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.3](#figureanchor12.3) 本章的数据。我们关注的是PM10列，用于监测空气质量。'
- en: Notice the larger values for PM10 that are highlighted in [figure 12.3](#figure12.3).
    At these times, we’ve got potentially problematic levels of atmospheric particulate
    matter. On the chart in [figure 12.4](#figure12.4), we can easily see this spike
    between 12 p.m. and 3 p.m.—this is when air quality is worse than normal. [Figure
    12.4](#figure12.4) also shows the chart that we’ll make in this chapter.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 注意[图12.3](#figure12.3)中突出显示的PM10的较大值。在这些时候，我们的大气颗粒物水平可能存在问题。在[图12.4](#figure12.4)的图表中，我们可以很容易地看到中午12点到下午3点之间的峰值——这是空气质量比正常更差的时候。[图12.4](#figure12.4)还显示了本章我们将制作的图表。
- en: For the purposes of our air quality monitoring system, we’ll regard any PM10
    value over 80 as a poor quality of air and worthy of raising an alarm. I’ve taken
    this number from the table of air quality categories from the Environmental Protection
    Authority (EPA) Victoria.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了我们空气质量监测系统的目的，我们将任何超过80的PM10值视为空气质量差，并值得发出警报。我从维多利亚环境保护局（EPA Victoria）的空气质量类别表中选取了这个数字。
- en: What will our system look like? You can see a schematic of the complete system
    in [figure 12.5](#figure12.5). I’m showing you this system diagram now as a heads-up
    on where we’re heading. I don’t expect you to understand all the parts of this
    system right at the moment, but you can think of this as a map of what we’re creating,
    and please refer back to it from time to time during this chapter to orient yourself.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的系统将是什么样子？你可以在[图12.5](#figure12.5)中看到整个系统的示意图。我现在向你展示这个系统图，是为了让你提前了解我们的方向。我不期望你立刻就能理解这个系统的所有部分，但你可以把它看作是我们正在创建的地图，请在本章中不时地参考它来定位自己。
- en: '![c12_04.eps](Images/c12_04.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![c12_04.eps](Images/c12_04.png)'
- en: '[Figure 12.4](#figureanchor12.4) Charting the PM10 value, we can see the big
    spike between 12 and 3 p.m.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.4](#figureanchor12.4) 绘制PM10值，我们可以看到中午12点和下午3点之间的大峰值。'
- en: I told you this would be the most complicated project in the book! Still, this
    system will be simple compared to most real production systems. But it will have
    all the parts shown in the schematic even though we’ll only be examining parts
    of this whole. At the end of the chapter, I’ll present the code for the completed
    system for you to study in your own time.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经告诉你，这将是书中最复杂的项目！然而，与大多数实际生产系统相比，这个系统将会很简单。尽管我们只将检查这个整体的部分，但它将包含图中显示的所有部件。在章节结束时，我将向您展示完成系统的代码，以便您在空闲时间自行研究。
- en: Our system starts with data produced by an air pollution sensor (shown on the
    left of [figure 12.5](#figure12.5)). The sensor detects the air quality and feeds
    data to the data collection point at hourly intervals. The first thing we must
    do is store the data in our database. The worst thing we can do is lose data,
    so it’s important to first make sure the data is safe. The data collection point
    then raises the incoming-data event. This is where our event-based architecture
    comes into play. It allows us to create a separation of concerns and decouple
    our data collection from our downstream data operations. To the right of [figure
    12.5](#figure12.5), we see the outputs of our system, the SMS alert, the daily
    report, and the live visualization.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的系统从由空气污染传感器产生的数据开始（如图12.5左边的所示）。该传感器检测空气质量，并以每小时一次的间隔将数据馈送到数据收集点。我们必须做的第一件事是将数据存储到我们的数据库中。最糟糕的事情就是丢失数据，因此首先确保数据安全是非常重要的。然后数据收集点会触发传入数据事件。这就是我们的基于事件架构发挥作用的地方。它允许我们创建关注点的分离，并将我们的数据收集与下游数据操作解耦。在图12.5的右边，我们看到系统的输出，包括短信警报、日报和实时可视化。
- en: '![c12_05.eps](Images/c12_05.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![c12_05.eps](Images/c12_05.png)'
- en: '[Figure 12.5](#figureanchor12.5) Schematic of our air quality monitoring system'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.5](#figureanchor12.5) 我们空气质量监测系统的示意图'
- en: 12.5 Set up for development
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.5 开发设置
- en: To build this system, we must create a kind of artificial scaffold in which
    to run it. You probably don’t have an actual particulate matter sensor on hand—although
    you can actually buy these at a reasonable price if you’re particularly motivated
    by this example project.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建这个系统，我们必须创建一个运行它的某种人工支架。你可能没有实际的颗粒物传感器在手——尽管如果你对这个示例项目特别感兴趣，你实际上可以以合理的价格购买这些传感器。
- en: Instead, we’ll use JavaScript to create a sort of mock sensor to simulate the
    real sensor. The code we’ll write might be pretty close to what the real thing
    would look like. For example, if we could attach a Raspberry PI to the real sensor
    and install Node.js, we could then run code that might be similar to the mock
    sensor we’re going to build in a moment.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们将使用JavaScript创建一种模拟传感器来模拟真实传感器。我们将编写的代码可能非常接近真实产品的样子。例如，如果我们能将Raspberry
    PI连接到真实传感器并安装Node.js，我们就可以运行可能与我们要构建的模拟传感器相似的代码。
- en: We don’t have a real sensor, so we’ll need precanned data for the mock sensor
    to “generate” and feed to our monitoring system. We already have realistic data,
    as seen in [figure 12.3](#figure12.3), although this data is hourly. If we’re
    to use it in a realistic fashion, then our workflow would be slow because we’d
    have to wait an hour for each new data point to come in.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有真实的传感器，因此我们需要为模拟传感器提供预录制的数据来“生成”并馈送到我们的监控系统。我们已经有了真实的数据，如[图12.3](#figure12.3)所示，尽管这些数据是按小时记录的。如果我们想以现实的方式使用它，那么我们的工作流程将会很慢，因为我们必须等待一个小时才能得到每个新的数据点。
- en: To be productive, we need to speed this up. Instead of having our data come
    in at hourly intervals, we’ll make it come in every second. This is like speeding
    up time and watching our system run in fast forward. Other than this time manipulation,
    our system will run in a realistic fashion.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高效率，我们需要加快这个流程。我们不会让数据以每小时一次的间隔传入，而是每秒传入一次。这就像加快时间并观看系统以快进的方式运行。除了这种时间操作外，我们的系统将以现实的方式运行。
- en: Each code listing for this chapter has its own subdirectory under the Chapter-12
    GitHub repository. Under each listing’s directory, you’ll find a client and a
    server directory. You can get an idea of what this looks like in [figure 12.6](#figure12.6).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本章每个代码列表都在Chapter-12 GitHub仓库下的一个子目录中。在每个列表的目录下，您将找到一个客户端和一个服务器目录。您可以在[图12.6](#figure12.6)中了解其结构。
- en: '![c12_06.eps](Images/c12_06.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![c12_06.eps](Images/c12_06.png)'
- en: '[Figure 12.6](#figureanchor12.6) The project structure for code listings in
    chapter 12'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.6](#figureanchor12.6) 第12章代码列表的项目结构'
- en: 'For each code listing, the mock sensor, our data collection device, lives in
    the client subdirectory, and our evolving air monitoring system lives in the server
    subdirectory. To follow along with the code listings, you’ll need to open two
    command-line windows. In the first command line, you should run the server as
    follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个代码列表，模拟传感器，我们的数据收集设备，位于客户端子目录中，我们不断发展的空气质量监控系统位于服务器子目录中。要跟随代码列表，您需要打开两个命令行窗口。在第一个命令行中，您应该按照以下方式运行服务器：
- en: '[PRE0]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the second command line, you should run the client (mock sensor) as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个命令行中，您应该按照以下方式运行客户端（模拟传感器）：
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The client and server are now both running, and the client is feeding data to
    the server. When moving onto the next code listing, change the listing number
    depending on where you are. Make sure you install the npm and Bower dependencies
    before trying to run each code listing.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端和服务器现在都在运行，客户端正在向服务器提供数据。在查看下一个代码列表时，根据你的位置更改列表编号。在尝试运行每个代码列表之前，请确保安装了 npm
    和 Bower 依赖项。
- en: 12.6 Live-streaming data
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.6 实时流数据
- en: 'The first problem we must solve is how to connect our sensor to our monitoring
    system. In the coming sections, we’ll cover two network-based mechanisms: HTTP
    POST and sockets. Both protocols build on the TCP network protocol and are directly
    supported by Node.js. Which protocol you choose depends on the frequency at which
    you expect data to be submitted.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须解决的首要问题是如何将我们的传感器连接到我们的监控系统。在接下来的章节中，我们将介绍两种基于网络的机制：HTTP POST 和套接字。这两种协议都建立在
    TCP 网络协议之上，并且直接由 Node.js 支持。你选择哪种协议取决于你期望数据提交的频率。
- en: 12.6.1 HTTP POST for infrequent data submission
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.6.1 频繁数据提交的 HTTP POST
- en: Let’s start by looking at data submission via HTTP POST. We can use this when
    data submission is infrequent or ad hoc. It’s also simplest and so is a good place
    to start. [Figure 12.7](#figure12.7) shows how our air pollution sensor is going
    to send single packets of data to our Node.js server. In this case, our data collection
    point, the entry point for data arriving at our server, will be an HTTP POST request
    handler. From there, the data is fed into our live data pipeline.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看通过 HTTP POST 提交数据。当数据提交不频繁或临时时，我们可以使用这个方法。它也是最简单的，因此是一个很好的起点。[图 12.7](#figure12.7)
    展示了我们的空气污染传感器将如何向我们的 Node.js 服务器发送单个数据包。在这种情况下，我们的数据收集点，即数据到达我们服务器的人口，将是一个 HTTP
    POST 请求处理器。从那里，数据被输入到我们的实时数据管道中。
- en: '![c12_07.eps](Images/c12_07.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![c12_07.eps](Images/c12_07.png)'
- en: '[Figure 12.7](#figureanchor12.7) HTTP POST is used to send single packets of
    data to our server.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.7](#figureanchor12.7) 使用 HTTP POST 向我们的服务器发送单个数据包。'
- en: Our code at this point will be incredibly simple. Starting off, we want to get
    the data feed moving from the mock sensor into our Node.js server. You can run
    this code, but you must start it in the right order—first the server and then
    the client (mock sensor). Our Node.js server receives data and then prints it
    to the console (as shown in [figure 12.8](#figure12.8)). We’re starting simple,
    and that’s all it does at this point. We do this to check that our data is coming
    across to our server correctly.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的代码将非常简单。首先，我们希望从模拟传感器开始将数据流移动到我们的 Node.js 服务器。你可以运行这段代码，但你必须按正确的顺序启动它——首先是服务器，然后是客户端（模拟传感器）。我们的
    Node.js 服务器接收数据并将其打印到控制台（如图 12.8 所示）。我们开始得很简单，目前就做这么多。我们这样做是为了检查我们的数据是否正确地到达了我们的服务器。
- en: '![c12_08.png](Images/c12_08.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![c12_08.png](Images/c12_08.png)'
- en: '[Figure 12.8](#figureanchor12.8) Output displayed as our Node.js server receives
    data using HTTP POST.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.8](#figureanchor12.8) 使用 HTTP POST 接收数据时显示的输出。'
- en: Node.js directly supports HTTP POST, but in this case, we’ll use *request-promise*,
    a higher-level library, to make this a bit easier and also to wrap our HTTP request
    in promises.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Node.js 直接支持 HTTP POST，但在这个例子中，我们将使用 *request-promise*，一个高级库，使这个过程变得更容易，并且将我们的
    HTTP 请求包装在承诺中。
- en: 'If you installed dependencies already, then you have request-promise installed
    in your project; otherwise, you can install it in a fresh Node.js project like
    this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经安装了依赖项，那么你的项目中已经安装了 request-promise；否则，你可以在新的 Node.js 项目中这样安装它：
- en: '[PRE2]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The following listing shows the code for our first mock air pollution sensor.
    It reads our example CSV data file. Once per second it takes the next row of data
    and submits it to the server using HTTP POST.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了我们的第一个模拟空气污染传感器的代码。它读取我们的示例 CSV 数据文件。每秒它读取下一行数据，并使用 HTTP POST 将其提交到服务器。
- en: Listing 12.1a Air pollution sensor that submits data to the server via HTTP
    POST (listing-12.1/client/index.js)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.1a 通过 HTTP POST 向服务器提交数据的空气污染传感器（列表-12.1/client/index.js）
- en: '[PRE3]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: On the server side, we use the *express* library to accept incoming data using
    HTTP POST. As we did with request-promise, we use the express library to make
    our lives a little easier. Node.js already has everything we need to build an
    HTTP server, but it’s common practice to use a higher-level library like express
    to simplify and streamline our code.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务器端，我们使用 *express* 库通过 HTTP POST 接收传入的数据。就像我们使用 request-promise 一样，我们使用 express
    库让我们的生活变得简单一些。Node.js 已经拥有我们构建 HTTP 服务器所需的一切，但使用像 express 这样的高级库来简化并精简我们的代码是一种常见的做法。
- en: 'Again, if you installed dependencies, then you already have the express library
    installed; otherwise, you install it and the body-parser middleware as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，如果你已经安装了依赖项，那么你已经有express库了；否则，你可以按照以下方式安装它和body-parser中间件：
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We’re using the body-parser middleware to parse the HTTP request body from JSON
    when it’s received. This way we don’t have to do the parsing ourselves. It will
    happen automatically.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用body-parser中间件在接收到HTTP请求体时从JSON中解析它。这样我们就不必自己进行解析。它将自动完成。
- en: '[Listing 12.1b](#listing12.1b) shows the code for a simple Node.js server that
    accepts data using the URL data-collection-point. We print incoming data to the
    console to check that it’s coming through correctly.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表12.1b](#listing12.1b) 展示了一个简单的Node.js服务器代码，该服务器使用URL数据收集点接收数据。我们将传入数据打印到控制台以检查其是否正确通过。'
- en: Listing 12.1b Node.js server that can accept data via HTTP POST (listing-12.1/server/index.js)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.1b 可以通过HTTP POST接收数据的Node.js服务器（列表-12.1/server/index.js）
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We now have a mechanism that allows us to accept an infrequent or ad hoc data
    feed. This would be good enough if we were only receiving incoming data on an
    hourly basis—as we would be if this were a real-life system. But given that we’re
    sending our data through every second, and because it’s an excuse to do more network
    coding, let’s look at using sockets to accept a high-frequency real-time data
    feed into our server.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个机制，允许我们接受不频繁或临时的数据馈送。如果我们只按小时接收传入数据——就像在现实生活中的系统中那样，这已经足够好了。但鉴于我们每秒都在发送数据，而且这也是进行更多网络编码的借口，让我们看看如何使用套接字来接受高频实时数据馈送到我们的服务器。
- en: 12.6.2 Sockets for high-frequency data submission
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.6.2 用于高频数据提交的套接字
- en: We’ll now convert our code over to using a socket connection, which is a better
    alternative when we have a high frequency of data submission. We’re going to create
    a long-lived communication channel between the sensor and the server. The communication
    channel is also bidirectional, but that’s not something we’ll use in this example,
    although you could later use it for sending commands and status back to your sensor
    if that’s what your system design needed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将把我们的代码转换为使用套接字连接，这在数据提交频率较高时是一个更好的选择。我们将创建传感器和服务器之间的长连接通信通道。通信通道也是双向的，但在这个例子中我们不会使用它，尽管你可以稍后使用它来向你的传感器发送命令和状态，如果这是你的系统设计所需的话。
- en: '![c12_09.eps](Images/c12_09.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![c12_09.eps](Images/c12_09.png)'
- en: '[Figure 12.9](#figureanchor12.9) A long-lived socket connection is used to
    receive continuous and high-frequency streaming data into our server.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.9](#figureanchor12.9) 使用长连接套接字接收连续且高频的流数据到我们的服务器。'
- en: '[Figure 12.9](#figure12.9) shows how we’ll integrate the socket connection
    into our system. This looks similar to what we did with HTTP POST, although it
    shows that we’ll have a stream of data coming through and arriving at the socket
    handler, which replaces the HTTP post handler and is our new data collection point.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.9](#figure12.9) 展示了我们将如何将套接字连接集成到我们的系统中。这看起来与我们在HTTP POST中所做的工作类似，尽管它显示我们将有一个数据流通过并到达套接字处理器，这取代了HTTP
    POST处理器，并成为我们的新数据收集点。'
- en: In the following listing, we adapt our mock sensor from [listing 12.1a](#listing12.1a)
    so that it writes the outgoing data to the socket connection. Besides the connection
    setup and the call to `socket.write`, this listing is similar to [listing 12.1a](#listing12.1a).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下列表中，我们将从[列表12.1a](#listing12.1a)中的模拟传感器进行适配，使其将输出数据写入套接字连接。除了连接设置和对`socket.write`的调用外，此列表与[列表12.1a](#listing12.1a)类似。
- en: Listing 12.2a Air pollution sensor that submits data to the server via a socket
    connection (listing-12.2/client/index.js)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.2a 通过套接字连接提交数据到服务器的空气污染传感器（列表-12.2/client/index.js）
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In [listing 12.2b](#listing12.2b), we have a new Node.js server that listens
    on a network port and accepts incoming socket connections. When our mock sensor
    (the client) connects, we set a handler for the socket’s `data` event. This is
    how we intercept incoming data; we’re also starting to see that event-based architecture
    that I mentioned earlier. In this example, as before, we print the data to the
    console to check that it has come through correctly.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在[列表12.2b](#listing12.2b)中，我们有一个新的Node.js服务器，它监听网络端口并接受传入的套接字连接。当我们的模拟传感器（客户端）连接时，我们为套接字的`data`事件设置处理器。这就是我们拦截传入数据的方式；我们也开始看到我之前提到的基于事件的架构。在这个例子中，就像之前一样，我们将数据打印到控制台以检查其是否正确通过。
- en: Listing 12.2b Acquiring real-time data through a socket connection (listing-12.2/server/index.js)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.2b 通过套接字连接获取实时数据（listing-12.2/server/index.js）
- en: '[PRE7]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note how we’re sending the data over the wire in the JSON data format. We did
    this in the HTTP example as well, but in that case request-promise (on the client)
    and express (on the server) did the heavy lifting for us. In this case, we’re
    manually serializing the data to JSON (on the client) before pushing it onto the
    network and then manually deserializing when it comes out at the other end (on
    the server).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们是如何以 JSON 数据格式通过网络发送数据的。我们在 HTTP 示例中也这样做过，但在那种情况下，request-promise（在客户端）和
    express（在服务器端）为我们做了大量的工作。在这种情况下，我们在将数据推送到网络之前（在客户端）手动将数据序列化为 JSON，然后在另一端出来时（在服务器端）手动反序列化。
- en: 12.7 Refactor for configuration
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.7 配置重构
- en: To this point, our server code has been simple, but in a moment the complexity
    will start to rise sharply. Let’s take a moment and do a refactor that will cleanly
    separate our configuration from our code. We won’t go too far with this; it’s
    a simple restructure and will help us keep the app tidy as it grows.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的服务器代码很简单，但很快复杂性将开始急剧上升。让我们花点时间进行一次重构，这将干净地分离我们的配置和代码。我们不会走得太远；这只是一个简单的重构，将帮助我们保持应用程序的整洁，随着其增长。
- en: The only configuration we have at the moment is the socket server setup details
    from [listing 12.2b](#listing12.2b). We’re going to move these to a separate configuration
    file, as shown in [figure 12.10](#figure12.10). This will be a central place to
    consolidate the configuration of the app and where we’ll need to go to later change
    its configuration.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们唯一的配置是从 [列表 12.2b](#listing12.2b) 中的套接字服务器设置细节。我们将把这些移动到一个单独的配置文件中，如图 12.10
    所示。这将是一个集中配置应用程序的地方，我们稍后需要去更改其配置。
- en: '![c12_10.png](Images/c12_10.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![c12_10.png](Images/c12_10.png)'
- en: '[Figure 12.10](#figureanchor12.10) The new configuration file in our Node.js
    project'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.10](#figureanchor12.10) 我们 Node.js 项目的新的配置文件'
- en: '[Listing 12.3a](#listing12.3a) shows our simple starting configuration for
    the project. You might well ask, “Why bother?” We’ll, it’s because we have a bunch
    of configuration details yet to come. The database, SMS alerts, and report generation
    all require their own configuration, and it’s nice to gather them in this one
    place.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 12.3a](#listing12.3a) 展示了我们为项目设置的一个简单起始配置。你可能会问，“为什么要费这个劲？”嗯，这是因为我们还有一大堆配置细节尚未到来。数据库、短信警报和报告生成都需要它们自己的配置，把所有这些集中在一个地方是很方便的。'
- en: Listing 12.3a Adding a simple configuration file to the Node.js project (listing-12.3/server/config.js)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.3a 向 Node.js 项目添加简单的配置文件（listing-12.3/server/config.js）
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[Listing 12.3b](#listing12.3b) shows how we load and use the configuration
    file. Nothing is complex here; our configuration is a regular Node.js code module
    with exported variables. This is a simple and convenient way to get started adding
    configuration to your app. It costs us little time to get this in place, and it’s
    useful in the long run.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 12.3b](#listing12.3b) 展示了我们如何加载和使用配置文件。这里没有复杂的地方；我们的配置是一个普通的 Node.js 代码模块，具有导出的变量。这是一种简单方便的方法来开始向你的应用程序添加配置。我们花费很少的时间来设置这个，而且从长远来看很有用。'
- en: Listing 12.3b The Node.js server is modified to load and use the configuration
    file (listing-12.3/server/index.js)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.3b 修改 Node.js 服务器以加载和使用配置文件（listing-12.3/server/index.js）
- en: '[PRE9]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You may wonder why I chose to use a Node.js code module as a configuration
    file. Well, my first thought was for simplicity. Normally, in production, I’ve
    used a JSON file for this kind of thing, and that’s just as easy to drop into
    this example. Believe it or not, you can require a JSON file in Node.js the same
    way that you require a JavaScript file. For example, you could have also done
    this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道我为什么选择使用 Node.js 代码模块作为配置文件。嗯，我的第一个想法是为了简单。通常，在生产环境中，我使用 JSON 文件来做这类事情，这在这个例子中也同样简单。信不信由你，你可以在
    Node.js 中以与要求 JavaScript 文件相同的方式要求 JSON 文件。例如，你也可以这样做：
- en: '[PRE10]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'It’s cool that you can do that: it’s a simple and effective way to load data
    and configuration into your Node.js app. But it also occurred to me that using
    JavaScript as your configuration file means you can include comments! This is
    a great way to document and explain configuration files and isn’t something you
    can ordinarily do with JSON files. (How many times do you wish you could have
    added comments to JSON files?!)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以这样做真是太酷了：这是一个简单而有效的方法将数据和配置加载到你的 Node.js 应用程序中。但这也让我想到，使用 JavaScript 作为配置文件意味着你可以包含注释！这是一种很好的方式来记录和解释配置文件，而且这是你通常无法用
    JSON 文件做到的。（你有多少次希望能在 JSON 文件中添加注释？！）
- en: You have more scalable and secure ways to store configuration, but simplicity
    serves our needs here, and this is something we’ll touch on again in chapter 14.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 你有更多可扩展和更安全的存储配置的方法，但简单性满足了我们的需求，我们将在第 14 章再次涉及这一点。
- en: 12.8 Data capture
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.8 数据捕获
- en: Now we’re more than ready to do something with our data, and the first thing
    we should do is to make sure that it’s safe and secure. We should immediately
    capture it to our database so that we’re at no risk of losing it.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已准备好对我们的数据进行一些操作，我们首先应该确保它是安全和安全的。我们应该立即将其捕获到我们的数据库中，这样我们就不会丢失它。
- en: '[Figure 12.11](#figure12.11) shows what our system looks like at this point.
    We have data incoming from the sensor, the data arrives at the data collection
    point, and then it’s stored in our database for safe-keeping.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.11](#figure12.11)展示了此时我们的系统看起来是什么样子。我们有来自传感器的数据进入，数据到达数据收集点，然后存储在我们的数据库中以备安全使用。'
- en: This time, after we run our code, we use a database viewer such as Robomongo
    to check that our data has arrived safely in our database (see [figure 12.12](#figure12.12)).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，在我们运行代码之后，我们使用数据库查看器，如 Robomongo，来检查我们的数据是否安全地到达了我们的数据库（见[图 12.12](#figure12.12)）。
- en: '![c12_11.eps](Images/c12_11.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![c12_11.eps](Images/c12_11.png)'
- en: '[Figure 12.11](#figureanchor12.11) Immediately store received data into our
    database before taking any further action.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.11](#figureanchor12.11)在采取任何进一步行动之前立即将接收到的数据存储到我们的数据库中。'
- en: '![c12_12.eps](Images/c12_12.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![c12_12.eps](Images/c12_12.png)'
- en: '[Figure 12.12](#figureanchor12.12) Using Robomongo to check that our incoming
    data has been captured to the database'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.12](#figureanchor12.12)使用 Robomongo 检查我们的数据是否已捕获到数据库中'
- en: To connect to the database, we need to get our database connection details from
    somewhere. In the following listing, we’ve added these to our configuration file.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要连接到数据库，我们需要从某处获取数据库连接详细信息。在以下列表中，我们已经将这些信息添加到我们的配置文件中。
- en: Listing 12.4a Adding the database connection details to the configuration file
    (listing-12.4/server/config.js)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.4a 将数据库连接详细信息添加到配置文件（列表-12.4/server/config.js）
- en: '[PRE11]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note that we’re using the default port 27017 when connecting to MongoDB in [listing
    12.4a](#listing12.4a). This assumes that you have a default installation of MongoDB
    on your development PC. If you want to try running this code, you’ll need to install
    MongoDB; otherwise, you could boot up the Vagrant VM that’s in the vm-with-empty-db
    subdirectory of the Chapter-8 Github repository. Booting that VM will give you
    an empty MongoDB database on port 6000 to use for code listings in this chapter.
    Make sure you modify the code to refer to the correct port number. For example,
    in [listing 12.4a](#listing12.4a) you’d change the connection string from `mongodb://localhost:27017`
    to `mongodb://localhost:6000`. For help on Vagrant, please see appendix C.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当我们连接到 MongoDB 时，使用的是默认端口 27017，如[列表 12.4a](#listing12.4a)所示。这假设你在你的开发电脑上安装了
    MongoDB 的默认版本。如果你想尝试运行此代码，你需要安装 MongoDB；否则，你可以启动位于 Chapter-8 Github 仓库 vm-with-empty-db
    子目录中的 Vagrant VM。启动该 VM 将为你提供一个端口为 6000 的空 MongoDB 数据库，用于本章中的代码示例。确保你修改代码以引用正确的端口号。例如，在[列表
    12.4a](#listing12.4a)中，你需要将连接字符串从`mongodb://localhost:27017`更改为`mongodb://localhost:6000`。有关
    Vagrant 的帮助，请参阅附录 C。
- en: The following listing shows the code that connects to MongoDB and stores the
    data that arrives at our data collection point immediately after it’s received.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表展示了连接到 MongoDB 并将接收到的数据存储在数据收集点的代码。
- en: Listing 12.4b Storing incoming data into the MongoDB database (listing-12.4/server/index.js)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.4b 将传入数据存储到 MongoDB 数据库（列表-12.4/server/index.js）
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The fact that we’re storing this data in the database immediately after receiving
    it is a design decision. I believe that this data is important and that we shouldn’t
    risk doing any initial processing on it before we’ve safely stored it. We’ll touch
    on this idea again soon.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在接收到数据后立即将其存储在数据库中是一个设计决策。我相信这些数据很重要，我们不应该在将其安全存储之前对它进行任何初始处理。我们很快将再次讨论这个想法。
- en: 12.9 An event-based architecture
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.9 基于事件的架构
- en: Let’s now look at how we can better evolve our application over time. I wanted
    an opportunity to show how we can deploy a design pattern to structure our app
    and help manage its complexity.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在看看我们如何更好地随着时间的推移改进我们的应用程序。我想有机会展示我们如何部署设计模式来结构化我们的应用程序并帮助管理其复杂性。
- en: You might argue that I’m overengineering this simple toy application, but what
    I want to show you is how separation of concerns and decoupling of components
    can give us the foundation for a solid, reliable, and extensible application.
    This should become obvious as we ramp up complexity culminating in the complete
    system at the end of the chapter.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为我过度设计了这个简单的玩具应用，但我想向你展示的是，关注点的分离和组件解耦如何为我们构建一个坚实、可靠和可扩展的应用程序奠定基础。随着我们逐步增加复杂性，并在章节末尾达到完整的系统，这一点应该会变得明显。
- en: '[Figure 12.13](#figure12.13) shows how we’ll use an event hub to decouple our
    data collection from any downstream data processing operation; for example, *update*
    *visualization*, which is responsible for forwarding incoming data to a live chart
    in the web browser.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.13](#figure12.13) 展示了我们将如何使用事件中心来解耦我们的数据收集与任何下游数据处理操作；例如，*更新* *可视化*，它负责将传入数据转发到网页浏览器中的实时图表。'
- en: '![c12_13.eps](Images/c12_13.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![c12_13.eps](Images/c12_13.png)'
- en: '[Figure 12.13](#figureanchor12.13) An event-handling architecture allows us
    to decouple our code modules.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.13](#figureanchor12.13) 事件处理架构允许我们解耦我们的代码模块。'
- en: 'The event hub is like a conduit for our events: the incoming-data event is
    raised by the data collection point, and the update visualization event handler
    responds to it. With this kind of infrastructure in place, we can now easily slot
    in new downstream data operations to extend the system.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 事件中心就像是我们事件的导管：数据收集点引发传入数据事件，更新可视化事件处理器对其做出响应。有了这种基础设施，我们现在可以轻松地添加新的下游数据操作来扩展系统。
- en: '[Figure 12.14](#figure12.14), for example, shows how we’ll plug in an SMS alert
    module so that our system can raise the alarm when it has detected poor-quality
    air.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.14](#figure12.14)，例如，展示了我们将如何接入一个短信警报模块，以便我们的系统在检测到空气质量不佳时发出警报。'
- en: '![c12_14.eps](Images/c12_14.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![c12_14.eps](Images/c12_14.png)'
- en: '[Figure 12.14](#figureanchor12.14) We can now expand our system, adding new
    downstream operations without refactoring or restructuring the data collection
    point.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.14](#figureanchor12.14) 我们现在可以扩展我们的系统，添加新的下游操作，而无需重构或重新结构化数据收集点。'
- en: Using an event-based architecture like this gives us a framework on which to
    hang new code modules. We’ve added a natural extension point where we can plug
    in new event sources and event handlers. This means we’ve designed our application
    to be upgraded. We’re now better able to modify and extend our app without turning
    it into a big mess of spaghetti code—at least that’s the aim. I won’t claim that
    it’s easy to keep an evolving application under control, but design patterns like
    this can help.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种基于事件的架构，我们可以在其上挂起新的代码模块。我们增加了一个自然的扩展点，可以在此处接入新的事件源和事件处理器。这意味着我们已经设计了一个可升级的应用程序。我们现在能够更好地修改和扩展我们的应用程序，而不会将其变成一团糟的意大利面代码——至少这是我们的目标。我不会声称保持一个不断发展的应用程序处于控制之下很容易，但像这样的设计模式可以有所帮助。
- en: The important thing for us in this project is that we can add new code modules
    such as *update visualization* and *SMS alert* without having to modify our data
    collection point. Why is this important here and now? Well, I wanted to make the
    point that the safety of our data is critical, and we must ensure that it’s safe
    and sound before anything else happens. Any time we make code changes to the data
    collection point, we run the risk of breaking this code. It’s imperative that
    we minimize the changes that we make to this code in the future, and the event-based
    architecture means we can add new code modules without having to change the code
    at the data collection point.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中对我们来说重要的是，我们可以添加新的代码模块，如*更新可视化*和*SMS警报*，而无需修改我们的数据收集点。为什么现在这里很重要？嗯，我想指出，我们数据的安全性至关重要，我们必须在发生任何其他事情之前确保它是安全可靠的。每次我们对数据收集点进行代码更改时，我们都有破坏这段代码的风险。我们迫切需要最小化我们对这段代码未来所做的更改，基于事件架构意味着我们可以在不更改数据收集点代码的情况下添加新的代码模块。
- en: As well as helping structure our app and make it more extensible, the event-based
    architecture also makes it easy to partition our system so that, if necessary
    for scaling up, we can distribute the application across multiple servers or virtual
    machines with the events being transmitted across the wire. This kind of architecture
    can help enable horizontal scaling that we’ll discuss further in chapter 14.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 除了帮助结构化我们的应用程序并使其更具可扩展性外，基于事件的架构还使得将我们的系统分区变得容易，这样，如果需要扩展，我们可以将应用程序分布到多个服务器或虚拟机上，事件通过电线传输。这种架构可以帮助实现我们在第14章中将进一步讨论的水平扩展。
- en: Code restructure for event handling
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件处理代码重构
- en: Let’s restructure our code so that it’s based around the notion of an event
    hub that coordinates the raising and handling of events. We’ll use the Node.js
    `EventEmitter` class because it’s designed for this sort of thing.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重构我们的代码，使其基于事件中心的概念，该中心协调事件的提升和处理。我们将使用Node.js的`EventEmitter`类，因为它是为这类事情设计的。
- en: 'In [listing 12.5a](#listing12.5a) you can see the code for our new event hub.
    This is super simple: the entire module instantiates an `EventEmitter` and exports
    it for use in other modules. No one said this needed to be complex, although you
    can surely build a more sophisticated event hub than this!'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在[列表12.5a](#listing12.5a)中，你可以看到我们新的事件中心的代码。这非常简单：整个模块实例化一个`EventEmitter`并将其导出以供其他模块使用。没有人说这需要复杂，尽管你可以构建一个比这更复杂的更高级的事件中心！
- en: Listing 12.5a Creating an event hub for the server (listing-12.5/server/event-hub.js)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.5a 创建服务器的事件中心（列表-12.5/server/event-hub.js）
- en: '[PRE13]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now that we have our event hub, we can wire it up to the existing code. The
    first thing we have to do is raise the incoming-data event when data is received
    by the server. We do this by calling the `emit` function on the event hub.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了事件中心，我们可以将其连接到现有代码。我们首先要做的是在服务器接收到数据时触发传入数据事件。我们通过在事件中心上调用`emit`函数来完成此操作。
- en: As you can see from the code extract in the following listing, the event is
    raised immediately after the data has been successfully stored in the database.
    For safety, we store the data first and everything else happens later.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从以下列表中的代码摘录中可以看到，事件在数据成功存储在数据库后立即被触发。为了安全起见，我们首先存储数据，然后发生其他所有事情。
- en: Listing 12.5b Raising the incoming-data event (extract from listing-12.5/server/data-collection-point.js)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.5b 触发传入数据事件（列表-12.5/server/data-collection-point.js）
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: With the incoming-data event in place and being raised whenever we have data
    arriving at the server, we’re in a position to start building downstream data
    processing modules.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在传入数据事件就绪并在我们有数据到达服务器时被触发后，我们可以开始构建下游数据处理模块。
- en: 12.10.1 Triggering SMS alerts
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.10.1 触发SMS警报
- en: The next thing we care about is knowing in real time when the quality of the
    air is deteriorating. We can now add an event handler to monitor incoming PM10
    values and raise an alarm when poor air quality is detected.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来关心的是实时了解空气质量何时恶化。现在我们可以添加一个事件处理程序来监控传入的PM10值，并在检测到空气质量差时发出警报。
- en: 'To handle the event, we first import the event hub into our code. Then we call
    the `on` function to register an event handler function for a named event such
    as the incoming-data event we added a moment ago. This is shown in the following
    listing: checking the incoming data for PM10 values greater than or equal to the
    max safe level, which is set to 80 in the configuration file. When such values
    are detected, we sound the alarm and send an SMS text message to our users.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理事件，我们首先将事件中心导入到我们的代码中。然后我们调用 `on` 函数来为名为事件（例如我们刚才添加的 incoming-data 事件）的事件注册一个事件处理函数。这如下所示：检查
    PM10 值是否大于或等于配置文件中设置为 80 的最大安全水平。当检测到这样的值时，我们会发出警报并向我们的用户发送短信文本消息。
- en: Listing 12.5c Handle event and trigger alert when PM10 exceeds safe value (listing-12.5/server/trigger-sms-alert.js)
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.5c 处理事件并在 PM10 超过安全值时触发警报（listing-12.5/server/trigger-sms-alert.js）
- en: '[PRE15]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The code in [listing 12.5c](#listing12.5c) is an example of adding a downstream
    data operation that does data analysis and sequences an appropriate response.
    This code is simple, but we could imagine doing something more complex here, such
    as checking whether the rolling average (see chapter 9) is on an upward trend
    or whether the incoming value is more than two standard deviations above the normal
    average (again, see chapter 9). If you’d prototyped data analysis code using exploratory
    coding (such as we did in chapter 5 or 9), you can probably imagine slotting that
    code into the system at this point.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 12.5c](#listing12.5c) 中的代码是添加下游数据操作的一个示例，该操作执行数据分析并安排适当的响应。此代码很简单，但我们可以想象在这里做更复杂的事情，比如检查滚动平均值（见第9章）是否呈上升趋势，或者传入的值是否比正常平均值高出两个标准差（再次见第9章）。如果您已经使用探索性编码（例如我们在第5章或第9章中做的那样）原型化了数据分析代码，您可能可以想象在这个时候将那段代码集成到系统中。'
- en: Now if you run this code ([listing 12.5](#listing12.5a)) and wait for a bit,
    you’ll see an “SMS alert” triggered. You only have to wait a few moments for this
    to happen (when those large PM10 values between 12 p.m. and 3 p.m. come through).
    The code that would send the SMS message is commented out for the moment, though,
    so all you’ll see is console logging that shows you what would have happened.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果您运行此代码 ([列表 12.5](#listing12.5a)) 并稍等片刻，您将看到触发了“短信警报”。您只需等待片刻即可发生此事件（当中午12点到下午3点之间的大
    PM10 值通过时）。不过，此时发送短信消息的代码已被注释掉，所以您只会看到显示将要发生什么的控制台日志。
- en: To get the SMS code working, you’ll need to uncomment the code in the file listing-12.5/server/sms-alert-system.js.
    You’ll need to sign up for Twilio (or similar service) and add your configuration
    details to the config file. Also make sure you add your own mobile number so that
    the SMS message will be sent to you. Do all this, run the code again, and you’ll
    receive the alert on your phone.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 要使短信代码生效，您需要在文件 listing-12.5/server/sms-alert-system.js 中取消注释代码。您需要注册 Twilio（或类似服务）并添加您的配置详细信息到配置文件中。同时确保您添加了自己的手机号码，这样短信消息就会发送到您的手机上。完成所有这些操作后，再次运行代码，您将在手机上收到警报。
- en: 12.10.2 Automatically generating a daily report
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.10.2 自动生成日报
- en: Let’s look at another example of raising and handling events. For the next feature,
    we’ll add automatically generated daily reports. The report won’t be anything
    fancy; we’ll render a chart of PM10 to a PDF file and then have that emailed to
    our users. But you can imagine going much further with this, say, rendering other
    statistics or attaching a spreadsheet with a summary of recent data.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看另一个触发和处理事件的例子。对于下一个特性，我们将添加自动生成的日报。报告不会很复杂；我们将 PM10 的图表渲染到 PDF 文件中，然后将其通过电子邮件发送给我们的用户。但你可以想象这可以做得更深入，比如渲染其他统计数据或附加一个包含最近数据摘要的电子表格。
- en: Because we want to generate our reports daily, we now need a way to generate
    time-based events. For this, we’ll add a scheduler to our system, and we’ll program
    it to raise a *generate-daily-report* event once per day. A separate daily report
    generator module will handle the event and do the work. You can see how this fits
    together in [figure 12.15](#figure12.15).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们希望每天生成报告，我们现在需要一种生成基于时间的事件的方法。为此，我们将在系统中添加一个调度器，并编程它每天触发一次 *generate-daily-report*
    事件。一个独立的日报生成模块将处理事件并完成工作。您可以在 [图12.15](#figure12.15) 中看到它是如何结合在一起的。
- en: '![c12_15.eps](Images/c12_15.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![c12_15.eps](Images/c12_15.png)'
- en: '[Figure 12.15](#figureanchor12.15) Our scheduler feeds an event into the system
    once per day to generate a daily report.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.15](#figureanchor12.15) 我们的调度器每天向系统中输入一个事件以生成日报。'
- en: To implement the scheduler, we’ll need a timer to know when to raise the event.
    We could build this from scratch using the JavaScript functions `setTimeout` or
    `setInterval.` Although these functions are useful, they’re also low-level, and
    I’d like us to use something more expressive and more convenient.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现调度器，我们需要一个计时器来知道何时触发事件。我们可以从头开始使用 JavaScript 函数 `setTimeout` 或 `setInterval`
    来构建它。虽然这些函数很有用，但它们也是低级的，我希望我们使用更易于表达和更方便的方法。
- en: Raising the generate daily report event
  id: totrans-165
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 触发生成每日报告事件
- en: To schedule our time-based events, we’ll rely on the cron library from npm to
    be our timer. With this library we can express scheduled jobs using the well-known
    UNIX cron format. As with any such library, you have many alternatives available
    on npm; this is the one that I use, but it’s always good to shop around to make
    sure you’re working with a library that best suits your own needs.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安排我们的基于时间的事件，我们将依赖 npm 中的 cron 库作为我们的计时器。使用这个库，我们可以使用众所周知的 UNIX cron 格式表达计划作业。与任何此类库一样，在
    npm 上有许多可用的替代方案；这是我使用的库，但总是好的，要四处看看，以确保你正在使用最适合你自身需求的库。
- en: In [listing 12.6a](#listing12.6a) we create an instance of `CronJob` with a
    schedule retrieved from our config file and then start the job. This invokes `generateReport`
    once per day, and this is where we raise the generate-daily-report event.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [列表 12.6a](#listing12.6a) 中，我们创建了一个 `CronJob` 实例，其计划是从我们的配置文件中检索的，然后启动作业。这每天调用一次
    `generateReport`，这就是我们触发生成每日报告事件的地方。
- en: Listing 12.6a Using the cron library to emit the time-based generate-daily-report
    event (listing-12.6/server/scheduler.js)
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.6a 使用 cron 库触发基于时间的生成每日报告事件（listing-12.6/server/scheduler.js）
- en: '[PRE16]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The cron format we’ll use for our daily cron job is specified in the configuration
    file and looks like this:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用于每日定时任务的 cron 格式在配置文件中指定，看起来如下所示：
- en: '[PRE17]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This looks cryptic, but we can read it from right to left as Monday to Friday
    (days 1–5), every month (the asterisk), every day of the month (the next asterisk),
    6 a.m. at the zero minute, and the zero second. This specifies the time at which
    to invoke the job. To put it more succinctly: we generate our report each weekday
    at 6 a.m.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来很神秘，但我们可以从右到左阅读，即星期一到星期五（1-5 天），每月（星号），每月的每一天（下一个星号），零分钟的 6 点，以及零秒。这指定了调用作业的时间。更简洁地说：我们每周工作日早上
    6 点生成报告。
- en: 'The problem with this schedule is that it takes far too long to test. We can’t
    wait a whole day to test the next iteration of our report generation code! As
    we did with the incoming-data stream, we need to speed things up, so we’ll comment
    out the daily schedule (we’ll need it again to put this app into production) and
    replace it with one that runs more frequently:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这个计划的问题在于测试它需要花费太长时间。我们无法等待整整一天来测试报告生成代码的下一个迭代！正如我们处理传入数据流一样，我们需要加快速度，所以我们将注释掉每日计划（我们将在将此应用程序投入生产时再次需要它）并替换为运行更频繁的计划：
- en: '[PRE18]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This specifies a schedule that runs every minute (you can read it right to left
    as every day, every month, every day of month, every hour, every minute, and at
    the zero second of that minute).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这指定了一个每分钟运行一次的计划（你可以从右到左阅读为每天，每月，每月的每一天，每小时，每分钟，以及该分钟的零秒）。
- en: We’ll generate a new report every minute. This is a fast pace to be sure, but
    it means we have frequent opportunities to test and debug our code.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将每分钟生成一个新的报告。这确实是一个快速的节奏，但这也意味着我们有频繁的机会来测试和调试我们的代码。
- en: Handling the generate report event
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 处理生成报告事件
- en: Now we’re ready to handle the *generate-daily-report* event and generate and
    email the report. The following listing shows how the event is handled and then
    calls down to a helper function to do the work.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备处理 *generate-daily-report* 事件并生成并发送报告。以下列表显示了如何处理事件，然后调用辅助函数来完成工作。
- en: Listing 12.6b Handling the generate-daily-report event and generating the report
    (listing-12.6/server/trigger-daily-report.js)
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.6b 处理生成每日报告事件并生成报告（listing-12.6/server/trigger-daily-report.js）
- en: '[PRE19]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Generating the report
  id: totrans-181
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生成报告
- en: Generating the report is similar to what we learned in chapter 11; in fact,
    [listing 12.6c](#listing12.6c) was derived from [listing 11.7](c11.xhtml#listing11.7a)
    in chapter 11.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 生成报告与我们在第 11 章中学到的类似；实际上，[列表 12.6c](#listing12.6c) 是从第 11 章中的 [列表 11.7](c11.xhtml#listing11.7a)
    衍生出来的。
- en: Before generating the report, we query the database and retrieve the data that’s
    to be included in it. We then use the `generateReport` toolkit function, which,
    the way we did in chapter 11, starts an embedded web server with a template report
    and captures the report to a PDF file using Nightmare. Ultimately, we call our
    helper function `sendEmail` to email the report to our users.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成报告之前，我们查询数据库并检索要包含在其中的数据。然后我们使用`generateReport`工具包函数，就像我们在第11章中做的那样，启动一个带有模板报告的嵌入式Web服务器，并使用Nightmare捕获报告到PDF文件。最终，我们调用我们的辅助函数`sendEmail`将报告通过电子邮件发送给用户。
- en: Listing 12.6c Generating the daily report and emailing it to interested parties
    (listing-12.6/server/generate-daily-report.js)
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.6c 生成日报并将其发送给感兴趣方（列表-12.6/server/generate-daily-report.js）
- en: '[PRE20]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: To run the code for [listing 12.6](#listing12.6a), you’ll need to have an SMTP
    email server that you can use to send the emails. Typically, I’d use Mailgun for
    this (which has a free/trial version), but you have plenty of other alternatives,
    such as Gmail. You need access to a standard SMTP account and then can put your
    SMTP username and password and report-related details in the config file. You
    can now run [listing 12.6](#listing12.6a) and have it email you a daily report
    once every minute (please don’t leave it running for too long—you’ll get a lot
    of emails!).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行[列表12.6](#listing12.6a)的代码，你需要有一个SMTP邮件服务器，你可以用它来发送邮件。通常，我会使用Mailgun（它有一个免费/试用版本）来做这件事，但你有很多其他的选择，比如Gmail。你需要访问一个标准的SMTP账户，然后可以在配置文件中输入你的SMTP用户名和密码以及与报告相关的详细信息。现在你可以运行[列表12.6](#listing12.6a)，并且每分钟它会通过电子邮件发送一份日报给你（请不要让它运行得太久——你会收到很多邮件！）
- en: You might now be interested to peruse the code in listing-12.6/server/send-email.js
    to understand how the email is sent using the `Nodemailer` library (the preeminent
    Node.js email sending library).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可能对查看列表-12.6/server/send-email.js中的代码感兴趣，以了解如何使用`Nodemailer`库（最优秀的Node.js邮件发送库）发送邮件。
- en: Live data processing
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时数据处理
- en: We’ll get to the live visualization in a moment and finish up this chapter,
    but before that, I want to have a quick word about adding more data processing
    steps to your live pipeline.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在稍后讨论实时可视化，并完成本章，但在那之前，我想快速谈谈如何将更多的数据处理步骤添加到你的实时管道中。
- en: '![c12_16.eps](Images/c12_16.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![c12_16.eps](Images/c12_16.png)'
- en: '[Figure 12.16](#figureanchor12.16) Data transformation during acquisition (if
    it goes wrong, you lose your data)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.16](#figureanchor12.16) 数据采集过程中的数据转换（如果出错，你会丢失数据）'
- en: Say that you need to add more code to do data cleanup, transformation, or maybe
    data analysis. Where’s the best place to put this?
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你需要添加更多代码来进行数据清理、转换，或者可能是数据分析。最好的放置位置在哪里？
- en: We could put code like this directly in our data collection point before we
    store the data, as shown in [figure 12.16](#figure12.16). Obviously, I don’t recommend
    this because it puts us at risk of data loss should anything go wrong with the
    data transformation (and I’ve been around long enough to know that something always
    goes wrong).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在存储数据之前，像图12.16所示的那样，直接在我们的数据收集点放置这样的代码。显然，我不推荐这样做，因为它会使我们在数据转换出错时面临数据丢失的风险（而且我经验丰富，知道总会有事情出错）。
- en: To properly mitigate this risk using what I believe is the safest way to structure
    this code, we can make our downstream data operations always happen on the other
    side of the event hub. We store the data quickly and safely before triggering
    any downstream work. As shown in [figure 12.17](#figure12.17), subsequent operations
    independently decide how they want to retrieve the data they need, and they have
    their own responsibility to safely store any data that has been modified.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用我认为最安全的代码结构方式来适当缓解这种风险，我们可以让我们的下游数据操作始终在事件中心的其他一侧发生。我们在触发任何下游工作之前快速且安全地存储数据。如图12.17所示，后续操作独立决定如何检索它们所需的数据，并且它们有责任安全地存储任何已修改的数据。
- en: '![c12_17.eps](Images/c12_17.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![c12_17.eps](Images/c12_17.png)'
- en: '[Figure 12.17](#figureanchor12.17) Data transformation is downstream from storage
    (a safer way to manage your data acquisition).'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[图12.17](#figureanchor12.17) 数据转换位于存储之后（管理数据采集的一种更安全的方式）。'
- en: The data required by the downstream data operation might be passed through the
    event itself (as we’ve done with the incoming-data event), or the operation can
    be made completely independent and must query the database itself to find its
    own data.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 下游数据操作所需的数据可能通过事件本身传递（就像我们处理incoming-data事件那样），或者操作可以完全独立，必须查询数据库本身以找到自己的数据。
- en: If you now have modified data that needs to be stored, you could overwrite the
    original data. I wouldn’t recommend this approach, however, because if any latent
    bugs should manifest, you might find that your source data has been overwritten
    with corrupted data. A better solution is to have the transformed data stored
    to a different database collection; at least this provides you with a buffer against
    data-destroying bugs.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在有需要存储的修改后的数据，你可以覆盖原始数据。然而，我不建议这种方法，因为如果任何潜在的错误出现，你可能会发现你的源数据已被损坏的数据覆盖。更好的解决方案是将转换后的数据存储到不同的数据库集合中；至少这为你提供了对数据破坏性错误的缓冲。
- en: Live visualization
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时可视化
- en: 'We’re finally here at the most exciting part of the chapter, the part that
    you have been waiting for: let’s get live data feeding into a dynamically updating
    chart.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于来到了本章最激动人心的部分，你一直期待的部分：让我们让实时数据流入动态更新的图表。
- en: '[Figure 12.18](#figure12.18) shows what our live data chart looks like. When
    this is running, you can sit back and watch new data points being fed into the
    chart each second (based on our accelerated notion of time).'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.18](#figure12.18) 展示了我们的实时数据图表的外观。当它运行时，你可以坐下来观看每秒（基于我们加速的时间观念）被输入到图表中的新数据点。'
- en: '![c12_18.png](Images/c12_18.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![c12_18.png](Images/c12_18.png)'
- en: '[Figure 12.18](#figureanchor12.18) The chart we''ll be producing from the live
    data stream'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.18](#figureanchor12.18) 我们将从实时数据流生成的图表'
- en: 'To make our live updating visualization, we must do two things:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要制作我们的实时更新可视化，我们必须做两件事：
- en: Put the initial data into the chart.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将初始数据放入图表中。
- en: Feed new data points into the chart as they arrive.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当新数据点到达时，将它们输入到图表中。
- en: The first one should be familiar to us by now, because we’ve already seen how
    to create charts in chapters 10 and 11\. Now we’ll add the second step into the
    mix and create a dynamic chart that automatically updates as new data becomes
    available.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个现在应该对我们来说很熟悉，因为我们已经在第 10 章和第 11 章中看到了如何创建图表。现在我们将添加第二个步骤，并创建一个动态图表，当有新数据可用时，它会自动更新。
- en: We already have part of the infrastructure we need to make this happen. Let’s
    add a new code module, update visualization, to handle the incoming-data event
    and forward new data points to the browser. See how this fits together in [figure
    12.19](#figure12.19).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有了实现这一目标所需的部分基础设施。让我们添加一个新的代码模块，更新可视化，来处理传入的数据事件并将新数据点转发到浏览器。看看它在[图 12.19](#figure12.19)中的组合方式。
- en: '![c12_19.eps](Images/c12_19.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![c12_19.eps](Images/c12_19.png)'
- en: '[Figure 12.19](#figureanchor12.19) Data flowing through to a live visualization'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12.19](#figureanchor12.19) 数据流向实时可视化'
- en: I would be remiss if I wrote this chapter and didn’t mention socket.io. It’s
    an extremely popular library for real-time events, messaging, and data streaming
    in JavaScript.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我写这一章而不提一下 socket.io，那我就疏忽了。这是一个在 JavaScript 中用于实时事件、消息和数据流的热门库。
- en: Socket.io allows us to open a bidirectional communication channel between our
    server and our web app. We can’t use regular sockets to communicate with a sandboxed
    web app, but socket.io uses web sockets, a technology that’s built on top of regular
    HTTP and gives us the data streaming conduit that we need to send a stream of
    data to the browser. Socket.io also has a fallback mode, so if web sockets aren’t
    available, it will gracefully degrade to sending our data using regular HTTP post.
    This means our code will work on older browsers.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Socket.io 允许我们在服务器和我们的 Web 应用程序之间打开一个双向通信通道。我们不能使用常规套接字与沙盒 Web 应用程序通信，但 socket.io
    使用 Web 套接字，这是一种建立在常规 HTTP 之上的技术，为我们提供了所需的数据流通道，以便将数据流发送到浏览器。Socket.io 还有一个回退模式，如果
    Web 套接字不可用，它将优雅地降级为使用常规 HTTP POST 发送我们的数据。这意味着我们的代码将在旧浏览器上工作。
- en: '[Listing 12.7a](#listing12.7a) shows the code for the web server that hosts
    our new live visualization. This does three main tasks:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 12.7a](#listing12.7a) 展示了托管我们新实时可视化的 Web 服务器的代码。这主要有三个任务：'
- en: Serves the assets for the web app itself
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为 Web 应用程序本身提供资产
- en: Provides the initial data for the chart
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为图表提供初始数据
- en: Registers Socket.io connections with our new code module update-visualization
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用我们新的代码模块更新可视化功能注册 Socket.io 连接
- en: You can see about halfway through the code listing where the web server starts
    accepting incoming Socket.io connections and registers each with our new *update-visualization*
    module.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在代码列表的中间部分看到，Web 服务器开始接受传入的 Socket.io 连接，并将每个连接注册到我们新的 *update-visualization*
    模块。
- en: Listing 12.7a Web server for a web app with a live chart for PM10 (listing-12.7/server/web-server.js)
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.7a 带有实时 PM10 图表的 Web 服务器（listing-12.7/server/web-server.js）
- en: '[PRE21]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[Listing 12.7b](#listing12.7b) shows the code for our new update-visualization
    module, which tracks all open connections, because there could be multiple instances
    of our web app connected at any one time. Notice where it handles the incoming-data
    event; here we call `socket.emit` to forward each packet of data to the web app.
    This is how new data points are sent to the web app to be added to the chart.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 12.7b](#listing12.7b) 展示了我们新的更新可视化模块的代码，该模块跟踪所有打开的连接，因为任何时刻可能有多个我们的 Web
    应用程序实例连接。注意它如何处理 incoming-data 事件；在这里，我们调用 `socket.emit` 将每个数据包转发到 Web 应用程序。这就是如何将新的数据点发送到
    Web 应用程序以添加到图表中的方式。'
- en: Listing 12.7b Forwarding incoming data to the web app (listing-12.7/server/update-visualization.js)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.7b 将传入数据转发到 Web 应用程序（listing-12.7/server/update-visualization.js）
- en: '[PRE22]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We also need to look at what is happening in the code for the web app. You can
    see in [listing 12.7c](#listing12.7c) that it’s mostly the same as what you’d
    expect to see in a C3 chart (for a refresher, see chapter 10). This time, in addition,
    we’re creating a socket.io instance and receiving incoming-data events from our
    web server. It’s then a simple job to add the incoming-data point to our existing
    array of data and load the revised data using the C3 `load` function. C3 conveniently
    provides an animation for the new data, which gives the chart a nice flowing effect.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要查看 Web 应用程序代码中发生的情况。您可以在[列表 12.7c](#listing12.7c)中看到，它基本上与您在 C3 图表中预期看到的内容相同（为了复习，请参阅第
    10 章）。这次，除了这个之外，我们还在创建一个 socket.io 实例，并从我们的 Web 服务器接收 incoming-data 事件。然后，将传入的数据点添加到我们现有的数据数组中，并使用
    C3 的 `load` 函数加载修订后的数据。C3 便利地提供了一个新数据的动画，这使得图表具有流畅的视觉效果。
- en: Listing 12.7c Adding new data to the chart as it arrives (listing-12.7/server/public/app.js)
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.7c 在数据到达时向图表中添加新数据（listing-12.7/server/public/app.js）
- en: '[PRE23]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: One last thing to take note of is how we make Socket.io available to our web
    app. You can see in [listing 12.7d](#listing12.7d) that we’re including the socket.io
    client’s JavaScript file into the HTML file for our web app. Where did this file
    come from?
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 最后要注意的一点是我们如何使 Socket.io 可用于我们的 Web 应用程序。您可以在[列表 12.7d](#listing12.7d) 中看到，我们将
    socket.io 客户端的 JavaScript 文件包含到我们的 Web 应用程序的 HTML 文件中。这个文件是从哪里来的？
- en: Well, this file is automatically made available and served over HTTP by the
    Socket.io library that we included in our server application. It’s kind of neat
    that it’s made available like magic, and we don’t have to install this file using
    Bower or otherwise manually install it.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这个文件是由我们包含在服务器应用程序中的 Socket.io 库自动提供并通过 HTTP 服务的。它以一种类似魔法的方式提供，我们不需要使用 Bower
    或其他方式手动安装此文件。
- en: Listing 12.7d Socket.io is automatically available to the client by the server
    (listing-12.7/server/public/index.html)
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.7d 服务器自动使 Socket.io 可用于客户端（listing-12.7/server/public/index.html）
- en: '[PRE24]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'When you run the code for [listing 12.7](#listing12.7a), keep in mind one caveat:
    each time you run it fresh (the mock sensor and the server), please reset your
    incoming MongoDB collection each time (you can remove all documents from a collection
    using Robomongo). Otherwise, your live chart will come out wonky due to the chronological
    nature of the data and the fact that we’re replaying our fake data. This is an
    artifact of the way we’ve set up our development framework with a mock sensor
    and fake data. This won’t be an issue in production. This is a pain during development,
    so for continued development, you might want to have an automatic way to reset
    your database to starting conditions.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行[列表 12.7](#listing12.7a)的代码时，请记住一个注意事项：每次您全新运行它（模拟传感器和服务器）时，请每次重置您的传入 MongoDB
    集合（您可以使用 Robomongo 从集合中删除所有文档）。否则，由于数据的时序性和我们正在回放我们的假数据，您的实时图表可能会出现异常。这是我们使用模拟传感器和假数据设置我们的开发框架的方式的一个副作用。在生产环境中这不会是问题。这在开发过程中是个麻烦，因此，为了继续开发，您可能希望有一种自动重置数据库到起始条件的方法。
- en: Well, there you have it. We’ve built a complete system for processing a continuous
    feed of live data. Using this system, we can monitor air quality, and hopefully
    we can be better prepared for emergencies and can respond in real time. You can
    find the full code under the *complete* subdirectory of the GitHub repo for chapter
    12\. It brings together all the parts we’ve discussed in this chapter and combines
    them into a cohesive functioning system.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，这就是我们完成的。我们已经构建了一个用于处理连续实时数据流的完整系统。使用这个系统，我们可以监控空气质量，并且希望我们能够更好地为紧急情况做好准备，并能够实时响应。你可以在GitHub仓库第12章的*complete*子目录下找到完整的代码。它汇集了我们本章讨论的所有部分，并将它们组合成一个连贯的、功能齐全的系统。
- en: The work we’ve done in this chapter has been a major step toward a full production
    system, but we’re not quite there yet. We still have many issues to address so
    that we can rely on this system, but we’ll come back and discuss those in chapter
    14\. Let’s take a break from the serious stuff, and in chapter 13 we’ll upgrade
    our visualization skills with D3.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们所做的工作是朝着完整生产系统迈出的重要一步，但我们还没有完全达到那里。我们仍有许多问题需要解决，以便我们可以依赖这个系统，但我们将回到第14章来讨论这些问题。现在让我们暂时放下严肃的内容，在第13章中，我们将使用D3提升我们的可视化技能。
- en: Summary
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: You learned how to manage a live data pipeline.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你学习了如何管理实时数据管道。
- en: You worked through examples of sending and receiving data through HTTP post
    and sockets.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你通过示例学习了如何通过HTTP POST和套接字发送和接收数据。
- en: We refactored our code to extract a simple configuration file.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们重构了代码，提取了一个简单的配置文件。
- en: We brought in an event-based architecture to our app using Node.js’ EventEmitter
    to add a simple event hub for our server.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用Node.js的EventEmitter引入了基于事件的架构，为我们的服务器添加了一个简单的事件中心。
- en: We used the `cron` library to create time-based scheduled jobs.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用了`cron`库来创建基于时间的计划任务。
- en: We explored using Socket.io for sending data to a live updating C3 chart.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们探讨了使用Socket.io向实时更新的C3图表发送数据的方法。
