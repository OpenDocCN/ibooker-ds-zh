- en: 1 Designing modern machine learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 设计现代机器学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Evolving from classical AI to cutting-edge approaches
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从经典人工智能发展到尖端方法
- en: Applying design patterns to deep learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将设计模式应用于深度学习
- en: Introducing the procedural reuse design pattern for modeling neural networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍用于建模神经网络的程序重用设计模式
- en: The latest revolution in deep learning is at the macro level rather than the
    micro level, with the introduction of an approach that I coined while working
    at Google Cloud AI as *model amalgamation*. In this approach, models are broken
    into composable units that share and adapt components to achieve different objectives
    with the same initial data. The components are interconnected in a variety of
    connectivity patterns, in which each component *learns* communication interfaces
    between the models through design, without the necessity of a backend application.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的最新革命是在宏观层面而不是微观层面，通过在谷歌云人工智能工作期间我提出的**模型融合**方法。在这种方法中，模型被分解成可组合的单元，这些单元共享和适应组件以使用相同初始数据实现不同的目标。组件以各种连接模式相互连接，其中每个组件通过设计*学习*模型之间的通信接口，而不需要后端应用程序。
- en: In addition, model amalgamation can be used to train Internet of Things (IoT)
    devices for data enrichment, turning IoT sensors from static to dynamically learning
    devices—a technique called *model fusion*. Amalgamation is providing the means
    for putting AI into production at a scale and operational complexity not conceivable
    in 2017, when the push into production first started to emerge.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，模型融合可用于训练物联网（IoT）设备进行数据丰富，将物联网传感器从静态转变为动态学习设备——一种称为**模型融合**的技术。融合正在提供将人工智能投入生产并在规模和操作复杂性方面实现2017年难以想象的方法，当时将人工智能投入生产的推动力刚开始出现。
- en: Think, for example, of the operational complexity of visual real estate data
    on a variety of aspects of the rental market, such as pricing, property condition,
    and amenities. Using the model amalgamation approach, you could create a vision
    analysis pipeline that connects individual models’ components, each working on
    one of those aspects. In the end, you’d have a system in place to automatically
    *learn* to determine the condition, amenities, and general market appeal with
    the corresponding appropriate rental pricing.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一下在租赁市场的各个方面（如定价、物业状况和设施）上视觉房地产数据的操作复杂性。使用模型融合方法，您可以创建一个连接单个模型组件的视觉分析管道，每个组件处理这些方面的一个。最终，您将拥有一个系统，可以自动*学习*确定条件、设施和一般市场吸引力以及相应的适当租金定价。
- en: The model amalgamation approach encourages engineers to view models as design
    patterns or templates that can be adapted to create individual components. So
    if you hope to use this approach, you’ll need to understand the designs of the
    key models and systems that other engineers have developed to solve problems similar
    to the ones you will encounter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 模型融合方法鼓励工程师将模型视为可以适应以创建单个组件的设计模式或模板。因此，如果你希望使用这种方法，你需要了解其他工程师为解决与你将遇到的类似问题而开发的键模型和系统的设计。
- en: The goal of this book is to aid you in that deep understanding by introducing
    you to the design patterns of seminal deep learning models, as well as the design
    or system architecture that puts those components together to develop, train,
    deploy, and serve larger deep learning systems. Even if you never work with huge
    enterprise amalgamations, becoming fluent in the underlying designs of these models
    and architectures will improve the engineering of any deep learning system you
    create.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的目标是通过向您介绍开创性深度学习模型的设计模式以及将这些组件组合在一起以开发、训练、部署和服务的更大深度学习系统的设计或系统架构，帮助您深入理解。即使您从未与大型企业融合合作，熟练掌握这些模型和架构的底层设计也将提高您创建的任何深度学习系统的工程水平。
- en: 1.1 A focus on adaptability
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 适应性重点
- en: Because this book is aimed at less-experienced deep learning engineers and data
    scientists, part 1 starts with the designs of the basic deep neural networks (DNNs),
    convolutional neural networks (CNNs), and residual neural networks (ResNets).
    Part 1 also looks at the architecture of simple training pipelines. Whole books
    are written about just these networks and architectures, so here you’ll get more
    of a reminder of how they work, with an emphasis on design patterns and principles.
    The point here is to lay out the design of basic deep learning components that
    all of the models you’ll see in part 2 will fit into.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书针对的是不太经验的深度学习工程师和数据科学家，第1部分从基本深度神经网络（DNNs）、卷积神经网络（CNNs）和残差神经网络（ResNets）的设计开始。第1部分还探讨了简单训练管道的架构。关于这些网络和架构的整本书都是写的，所以在这里你将更多地回顾它们是如何工作的，重点是设计模式和原则。这里的目的是概述基本深度学习组件的设计，这些组件将适合第2部分中你将看到的所有模型。
- en: That said, if you are well versed in the fundamentals, you can go directly to
    part 2, which looks at the seminal models in the development of deep learning.
    My approach is to provide enough information about each model design so that you
    can play around with them and come up with solutions to the AI challenges you
    may encounter. The models are introduced more or less chronologically, so part
    2 also serves as a kind of history of deep learning, with an emphasis on the evolution
    from one model to the next.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，如果你对基础知识了如指掌，你可以直接跳到第2部分，这部分将探讨深度学习发展中的关键模型。我的方法是提供每个模型设计的足够信息，以便你可以对它们进行实验，并提出解决你可能会遇到的AI挑战的方案。这些模型大致按照时间顺序介绍，因此第2部分也充当了深度学习历史的一部分，重点在于从一种模型到另一种模型的演变。
- en: Now, if enterprise production is moving toward automatic learning for model
    development, you may wonder about the value of examining these manually designed,
    formerly state-of-the-art (SOTA) models. Many of these models, however, continue
    to be used as stock models, particularly for transfer learning. Some of the others
    never made it into production at all, but were responsible for discoveries that
    continue to be used today.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果企业生产正在向模型开发自动学习转变，你可能会质疑检查这些手动设计、以前的前沿（SOTA）模型的价值。然而，许多这些模型继续作为标准模型使用，尤其是在迁移学习方面。其他一些模型从未进入生产，但它们负责的发现至今仍在使用。
- en: Model development for production continues to be a combination of automatic
    and hand-designed learning—which is often crucial for proprietary needs or advantages.
    But designing by hand does not mean starting from scratch; typically, you would
    start with a stock model and make tweaks and adjustments. To do this effectively,
    you need to know *how* the model works and *why* it works that way, the concepts
    that underlie its design, and the pros and cons of alternative building blocks
    you will learn from other SOTA models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发用于生产仍然是一系列自动和手工设计的学习的组合——这对于专有需求或优势往往至关重要。但手工设计并不意味着从头开始；通常，你会从一个标准模型开始，进行微调和调整。为了有效地做到这一点，你需要知道模型是如何工作的以及为什么它会以这种方式工作，其设计背后的概念，以及你将从其他SOTA模型中学到的替代构建块的优缺点。
- en: The final part of the book takes a deep dive into the design patterns for training
    and deployment for production. While not all readers will be deploying the kinds
    of enterprise systems that are my focus, I feel this information is relevant to
    all. Becoming familiar with many types—and sizes—of systems addressing a variety
    of problems can help you when you need to think outside the box to solve a problem.
    The more you know about the underlying concepts and designs, the more able and
    adaptable you become.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 书的最后一部分深入探讨了用于生产的训练和部署的设计模式。虽然并非所有读者都会部署我关注的那些企业级系统，但我认为这些信息对所有读者都相关。熟悉许多类型和规模的系统，这些系统针对各种问题，可以帮助你在需要跳出思维定势解决问题时有所帮助。你对底层概念和设计的了解越多，你变得越有能力且适应性越强。
- en: This adaptability is probably the most valuable takeaway from this book. Production
    involves a vast number of moving parts, and an endless flow of “monkey wrenches”
    being tossed into the mix. If engineers or data scientists simply rote-memorize
    sets of reproducible steps in a framework, how will they handle the diversity
    of tasks they’ll encounter and resolve the monkey wrenches thrown at them? Employers
    look for more than just skill and experience; they want to know how technically
    adaptive you are.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这种适应性可能是这本书最有价值的收获。生产涉及大量的移动部件，并且不断有“猴子 wrench”被扔进混合物中。如果工程师或数据科学家只是机械地记住框架中可重复的步骤集合，他们将如何处理他们遇到的多样化任务，以及解决扔向他们的“猴子
    wrench”呢？雇主寻找的不仅仅是技能和经验；他们想知道你的技术适应性如何。
- en: 'Imagine yourself in an interview: you score high on skill and work experience
    and nail the stock machine learning (ML) coding challenge. Then the interviewers
    throw you a monkey wrench, an unexpected or unusual problem. They do this to observe
    how you think through a challenge, which concepts you apply and the reasoning
    behind them, how you evaluate the pros and cons of the various solutions, and
    your ability to debug. That’s adaptability. And that’s what I hope deep learning
    developers and data scientists will get from this book.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下自己在面试中：你在技能和工作经验上得分很高，并且在股票机器学习（ML）编码挑战中表现出色。然后面试官给你一个意外或不同寻常的问题，一个“猴子 wrench”。他们这样做是为了观察你如何思考挑战，你应用了哪些概念以及背后的推理，你如何评估各种解决方案的优缺点，以及你的调试能力。这就是适应性。这正是我希望深度学习开发者和数据科学家从这本书中获得的东西。
- en: 1.1.1 Computer vision leading the way
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 计算机视觉引领潮流
- en: I teach all of these concepts primarily in the context of computer vision, because
    design patterns evolved first in computer vision. But they are applicable to natural-language
    processing (NLP), structured data, signal processing, and other fields. If we
    roll the clock back to prior to 2012, ML in all fields was mostly using classical
    statistics-based methods.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我主要在计算机视觉的背景下教授所有这些概念，因为设计模式最初是在计算机视觉中演化的。但它们也适用于自然语言处理（NLP）、结构化数据、信号处理和其他领域。如果我们把时钟拨回到2012年之前，所有领域的机器学习（ML）主要使用基于经典统计的方法。
- en: Various academic researchers, such as Fei-Fei Liu at Stanford University and
    Geoffrey Hinton of the University of Toronto, began to pioneer applying neural
    networks to computer vision. Liu, along with her students, compiled a computer
    vision dataset, now known as ImageNet, to advance the research into computer vision.
    ImageNet, along with the PASCAL dataset, became the basis for the annual ImageNet
    Large Scale Vision Recognition Challenge (ILSVRC) competition in 2010\. Early
    entries used traditional image recognition/signal processing methods.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如斯坦福大学的Fei-Fei Liu和加拿大多伦多大学的Geoffrey Hinton等学术研究人员开始率先将神经网络应用于计算机视觉。Liu及其学生编制了一个计算机视觉数据集，现在被称为ImageNet，以推进计算机视觉的研究。ImageNet，连同PASCAL数据集，成为2010年年度ImageNet大规模视觉识别挑战（ILSVRC）竞赛的基础。早期参赛者使用了传统的图像识别/信号处理方法。
- en: Then, in 2012, Alex Krizhevsky, also of the University of Toronto, entered a
    deep learning model, AlexNet, using convolution layers. This model won the ILSVRC
    contest and by a sizable margin. The AlexNet model, jointly designed with Hinton
    and Ilya Sutskever, kicked off deep learning. In their corresponding paper, “ImageNet
    Classification with Deep Convolutional Neural Networks” ([http://mng.bz/1ApV](http://mng.bz/1ApV)),
    they showed how neural networks can be designed.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在2012年，多伦多大学的Alex Krizhevsky提交了一个使用卷积层的深度学习模型，AlexNet。这个模型赢得了ILSVRC竞赛，并且领先优势明显。与Hinton和Ilya
    Sutskever共同设计的AlexNet模型开启了深度学习。在他们相应的论文《使用深度卷积神经网络的ImageNet分类》（[http://mng.bz/1ApV](http://mng.bz/1ApV)）中，他们展示了如何设计神经网络。
- en: In 2013, Matthew Zeiler and Rob Fergus of New York University won the competition
    by fine-tuning AlexNet into what they called ZFNet. This pattern of building on
    each other’s success continued. The Visual Geometry Group at Oxford expanded on
    the AlexNet design principles and won the 2014 contest. In 2015, Kaiming He and
    others at Microsoft Research further expanded on the AlexNet/VGG design principles
    and introduced new design patterns, winning the competition. Their model, ResNet,
    and their “Deep Residual Learning for Image Recognition” paper ([https://arxiv.org/abs/
    1512.03385](https://arxiv.org/abs/1512.03385)), set off a surge in discovering
    and exploring the design space of CNNs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在2013年，纽约大学的Matthew Zeiler和Rob Fergus通过微调AlexNet成为他们所说的ZFNet赢得了比赛。这种基于彼此成功的模式持续发展。牛津大学的视觉几何组在此基础上扩展了AlexNet的设计原则，并在2014年的比赛中获胜。2015年，微软研究院的Kaiming
    He等人进一步扩展了AlexNet/VGG的设计原则，并引入了新的设计模式，赢得了比赛。他们的模型ResNet以及他们的“用于图像识别的深度残差学习”论文([https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385))，引发了探索CNN设计空间的热潮。
- en: '1.1.2 Beyond computer vision: NLP, NLU, structured data'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 超越计算机视觉：自然语言处理（NLP）、自然语言理解（NLU）、结构化数据
- en: In these early years of developing design principles and design patterns using
    deep learning for computer vision, developments in natural-language understanding
    (NLU) and structured data models lagged behind and continued to focus on classical
    approaches. They used classical ML frameworks, like the Natural Language Toolkit
    (NLTK) for text input, and classical algorithms based on decision trees, like
    random forest, for structured data input.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些早期使用深度学习为计算机视觉开发设计原则和设计模式的年份里，自然语言理解（NLU）和结构化数据模型的发展落后，并继续专注于经典方法。他们使用了经典的机器学习框架，如自然语言工具包（NLTK）用于文本输入，以及基于决策树的经典算法，如随机森林，用于结构化数据输入。
- en: In the NLU field, progress was made with the introduction of RNNs and long-short-term-memory
    (LSTM) and gated recurrent unit (GRU) layers. That progress took a leap in 2017
    with the introduction of the Transformer design pattern for natural language,
    and the corresponding paper “Attention Is All You Need” by Ashish Vaswani et.
    al ([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)). Google
    Brain, a deep learning research organization within Google AI, adopted early a
    comparable attention mechanism in ResNet. Likewise, advancements in design patterns
    for structured data evolved with the introduction of the wide-and-deep model pattern,
    outlined in “Wide & Deep Learning for Recommender Systems” ([https://arxiv.org/abs/1606.07792](https://arxiv.org/abs/1606.07792))
    by Heng-Tze Cheng et. al, at the technology-agnostic research group Google Research,
    in 2016.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言理解（NLU）领域，随着循环神经网络（RNNs）、长短期记忆（LSTM）和门控循环单元（GRU）层的引入，取得了进展。2017年，随着自然语言中的Transformer设计模式的引入以及Ashish
    Vaswani等人撰写的相应论文“Attention Is All You Need”([https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))，这一进展实现了飞跃。谷歌大脑，作为谷歌AI内部的一个深度学习研究组织，在ResNet中早期采用了类似的注意力机制。同样，随着结构化数据设计模式的引入，例如2016年由Google
    Research的技术无关研究小组Heng-Tze Cheng等人概述的“Wide & Deep Learning for Recommender Systems”([https://arxiv.org/abs/1606.07792](https://arxiv.org/abs/1606.07792))，设计模式的发展也随之演进。
- en: While I focus on computer vision to teach both the evolution and current state
    of the art in design patterns, I refer to corresponding progress in NLU and structured
    data where appropriate. Many of the concepts in this book are applicable across
    fields and data types. For instance, chapters 2 through 4 cover universal fundamentals,
    and all but one chapter in part 3 cover concepts that are agnostic of the model
    and data type.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当我专注于计算机视觉，以教授设计模式的发展和当前状态时，我会适当提及自然语言理解（NLU）和结构化数据方面的相应进展。本书中的许多概念适用于多个领域和数据类型。例如，第2章到第4章涵盖了通用基础，而第3部分除了第一章外，所有章节都涵盖了与模型和数据类型无关的概念。
- en: In chapters where it makes sense, mostly in part 2, I introduce an example from
    beyond computer vision. For example, in chapter 5, I compare the development of
    residual blocks with identity links to attention in transformers for NLU. In chapter
    6, we’ll explore how wide CNNs are relevant to developments in wide-and-deep and
    TabNet models for structured data. Chapter 9 explains how autoencoders are comparable
    to embeddings in NLU, and chapter 11 discusses how the steps for transfer learning
    are comparable to both NLU and structured data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在有意义的章节中，主要在第二部分，我引入了来自计算机视觉之外的例子。例如，在第5章，我比较了具有身份链接的残差块在NLU中与注意力在Transformer中的发展。在第6章，我们将探讨宽CNN如何与结构化数据的宽度和深度模型以及TabNet的发展相关。第9章解释了自编码器在NLU中与嵌入的比较，第11章讨论了迁移学习步骤如何与NLU和结构化数据相媲美。
- en: By generalizing from the examples I share from computer vision, NLP, and structural
    data, you should be able to adapt the concepts, methods, and techniques to problems
    in your domain.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从计算机视觉、自然语言处理和结构化数据中分享的例子进行泛化，你应该能够将概念、方法和技术应用到你的领域中的问题。
- en: 1.2 The evolution in machine learning approaches
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 机器学习方法的演变
- en: To understand the modern approach, we first have to understand where we are
    with AI and ML, and how we got here. This section presents several top-level approaches
    and design patterns for working in today’s production environment, including intelligent
    automation, machine design, model fusion, and model amalgamation.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解现代方法，我们首先必须了解我们在人工智能和机器学习方面的现状，以及我们是如何到达这个阶段的。本节介绍了在当今生产环境中工作的几个顶级方法和设计模式，包括智能自动化、机器设计、模型融合和模型合并。
- en: 1.2.1 Classical AI vs. narrow AI
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 经典人工智能与窄人工智能
- en: Let’s briefly cover the difference between classical AI and today’s modern narrow
    AI. In *classical AI* (also known as *semantic AI* ), models were designed as
    rule-based systems. These systems were used to solve problems that could not be
    solved by a mathematical equation. Instead, the system was set up to mimic a subject
    matter or domain expert. Figure 1.1 offers a visual of this approach.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要地介绍一下经典人工智能和当今现代窄人工智能之间的区别。在*经典人工智能*（也称为*语义人工智能*）中，模型被设计为基于规则的系统。这些系统被用来解决无法用数学方程式解决的问题。相反，系统被设置成模仿一个主题或领域专家。图1.1展示了这种方法的一个视觉表示。
- en: '![](Images/CH01_F01_Ferlitsch.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH01_F01_Ferlitsch.png)'
- en: Figure 1.1 In a classical AI approach, the domain expert designs rules to mimic
    their knowledge.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 在经典人工智能方法中，领域专家设计规则来模仿他们的知识。
- en: Classical AI worked well in input spaces that were low-dimensionality (as in,
    had a low number of distinct inputs); had an input space that could be broken
    into discrete segments, such as categories or bins; and maintained a strong linear
    relationship between the discrete space and the output. The domain expert designed
    a set of rules, based on inputs and state transformations, that mimicked their
    expertise. A programmer then converted these rules into a rule-based system, typically
    of the form “If *A* and *B* are true, then *C* is true.”
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 经典人工智能在低维输入空间（例如，具有少量不同输入）中表现良好；输入空间可以被分成离散的段，如类别或箱；并且离散空间与输出之间保持强烈的线性关系。领域专家设计了一套基于输入和状态转换的规则，以模仿他们的专业知识。然后程序员将这些规则转换成一个基于规则的系统，通常是“如果*A*和*B*为真，则*C*为真”的形式。
- en: Systems like this were well suited for problems like predicting the quality
    and appropriateness of a wine, which required only a small set of rules. For example,
    for the wine selector, the inputs might have been whether the meal was lunch or
    dinner, the entree, the occasion, and whether dessert would be included. But classical
    AI failed to scale to larger problems; accuracy would drop dramatically, and rules
    required continuous refinement to try to stave off the drop. Inconsistencies among
    domain experts designing the rules was another problem contributing to inaccuracies.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这种系统非常适合像预测葡萄酒的质量和适宜性这样的问题，这只需要一小套规则。例如，对于葡萄酒选择器，输入可能包括餐点是午餐还是晚餐、主菜、场合以及是否包含甜点。但经典人工智能无法扩展到更大的问题；准确性会大幅下降，规则需要不断细化以试图避免下降。设计规则的领域专家之间的不一致性是导致不准确性的另一个问题。
- en: In *narrow AI* (also known as *statistical AI* ), a model gets trained on a
    large amount of data, alleviating the need for domain experts. Instead, the model
    uses principles of statistics to learn patterns in the distribution of the input
    data, also referred to as a *sampling distribution*. These patterns can then be
    applied with high accuracy to samples not seen in training. When trained with
    a sampling distribution made up of large amounts of data that is representative
    of the larger population, or *population distribution*, we can model problems
    without the constraints that come with classical AI. In other words, narrow AI
    can work very well with substantially higher dimensionality in the input space
    (meaning a large number of distinct inputs), and with inputs that can be a mix
    of discrete and continuous.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在*窄人工智能*（也称为*统计人工智能*）中，模型在大量数据上得到训练，减轻了对领域专家的需求。相反，模型使用统计原理来学习输入数据分布中的模式，也称为*抽样分布*。这些模式可以以高精度应用于训练中未见的样本。当使用由大量代表更大人群或*总体分布*的数据组成的抽样分布进行训练时，我们可以建模没有经典人工智能带来的约束的问题。换句话说，窄人工智能可以在输入空间具有显著更高维度（意味着大量不同的输入）以及可以混合离散和连续输入的情况下工作得非常好。
- en: Let’s contrast rule-based with narrow AI by applying both to predicting the
    sale price of a house. A rule-based system could generally consider only a small
    number of inputs; for instance, lot size, square footage, number of bedrooms,
    number of bathrooms, and property tax. A system like this could predict a median
    price for comparable homes, but not for any one home, because of nonlinearity
    in the relationships of the property to the price.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将两者都应用于预测房屋售价来对比基于规则的窄人工智能。基于规则的系统通常只能考虑少量输入；例如，地块大小、平方英尺、卧室数量、浴室数量和财产税。这样的系统可以预测类似房屋的中位价格，但不能预测任何单个房屋的价格，因为财产与价格之间的关系是非线性的。
- en: Let’s take a step back and discuss the difference between a linear and nonlinear
    relationship. In a *linear relationship*, the value of one variable predicts the
    value of another. For example, say we have the function *y* = *f*(*x*), which
    we define as 2 × *x*. The value of *y* can be predicted with 100% confidence for
    any value *x*. In a *nonlinear relationship*, the value of *y* can be predicted
    only with a probability distribution on any value *x*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步，讨论线性关系和非线性关系之间的区别。在*线性关系*中，一个变量的值可以预测另一个变量的值。例如，假设我们有一个函数*y* = *f*(*x*)，我们将其定义为2
    × *x*。对于任何值*x*，我们可以以100%的置信度预测*y*的值。在*非线性关系*中，只能通过任何值*x*的概率分布来预测*y*的值。
- en: Using our housing example, we could try to say *y* = *f*(*x*) as the *selling
    price* = *sqft* × *price_per_sq_ft*. The reality is that a lot of other variables
    affect *price_per_sq_ft*, and there is some uncertainty in how those affect the
    price. In other words, the square footage of the house has a nonlinear relationship
    to the selling price, which, by itself, could predict only a probability distribution
    of the selling price.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们的住房示例，我们可以说*y* = *f*(*x*)作为*售价* = *sqft* × *每平方英尺价格*。现实情况是，许多其他变量会影响*每平方英尺价格*，并且这些变量如何影响价格存在一些不确定性。换句话说，房屋的平方英尺与售价之间存在非线性关系，它本身只能预测售价的概率分布。
- en: In narrow AI, we substantially increase the number of inputs to learn the nonlinearity,
    such as adding the year the house was built, when permits for upgrades were granted,
    the type of architecture, materials used for roofing and siding, school district
    information, employment opportunities, average income, the neighborhood, as well
    as crime, and vicinity to parks, public transportation, and highways. These additional
    variables help the model learn the probability distribution with high confidence.
    Inputs whose value is from a fixed set, such as building architecture, are *discrete*,
    while inputs that are from an unbounded range, like average income, are *continuous*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在窄人工智能中，我们显著增加了输入的数量以学习非线性，例如添加房屋建造年份、升级许可发放时间、建筑类型、屋顶和侧面的材料、学区信息、就业机会、平均收入、社区以及犯罪率、公园、公共交通和高速公路的邻近程度。这些额外的变量有助于模型以高置信度学习概率分布。值来自固定集合的输入，如建筑架构，是*离散的*，而来自无界范围的输入，如平均收入，是*连续的*。
- en: Narrow AI models work well with inputs that have a high level of nonlinearity
    to the outputs (predictions), by learning the boundaries to segment the inputs—again,
    if those segments have a strongly linear relationship to the output. These types
    of models are based on statistics, requiring large amounts of data, and are called
    *narrow AI* because they are good at solving narrow problems consisting of a limited
    range of tasks within one field. Narrow models are not so good at generalizing
    to problems of a wide scope. Figure 1.2 illustrates the narrow AI approach.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 窄AI模型通过学习分割输入的边界来处理具有高非线性输出（预测）的输入，如果这些分割与输出有强烈的线性关系。这些类型的模型基于统计学，需要大量数据，因此被称为*窄AI*，因为它们擅长解决一个领域内有限范围的任务的狭窄问题。窄模型在泛化到广泛范围的问题上并不擅长。图1.2说明了窄AI的方法。
- en: '![](Images/CH01_F02_Ferlitsch.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH01_F02_Ferlitsch.png)'
- en: Figure 1.2 In narrow AI, the model learns to be the domain expert by training
    on a large dataset that is representative of the larger population.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 在窄AI中，模型通过在大数据集上训练，这些数据集代表了更广泛的群体，来学习成为领域专家。
- en: Another way to see the difference between classical AI and narrow AI is by looking
    at the error-rate reduction in both kinds of models, as deep learning is continuously
    pushing to the Bayes theoretical error limit. Bayes described this theoretical
    error limit as a progression, as shown in figure 1.3.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种区分经典AI和窄AI的方法是观察这两种模型在误差率降低方面的差异，因为深度学习不断推动向贝叶斯理论误差极限迈进。贝叶斯将这个理论误差极限描述为一种进步，如图1.3所示。
- en: '![](Images/CH01_F03_Ferlitsch.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH01_F03_Ferlitsch.png)'
- en: Figure 1.3 ML has progressed toward the Bayes theoretical error limit.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 机器学习向贝叶斯理论误差极限迈进。
- en: 'First, what would be the error rate of an average non-expert solving a task?
    Then, what would be the error rate of an expert solving the task (this is analogous
    to semantic AI)? What would be the error rate with a roomful of experts solving
    the task? And finally, the theoretical limit: what would be the error rate of
    an infinite number of experts solving the task?'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，一个普通非专家解决任务的误差率会是什么？然后，一个专家解决任务的误差率会是什么（这类似于语义AI）？一群专家解决任务的误差率会是什么？最后，理论极限：无限多个专家解决任务的误差率会是什么？
- en: Deep learning in vast numbers of computer vision and NLP tasks has achieved
    the error rate of a roomful of experts, vastly outperforming both conventional
    software applications and expert systems. In 2020, researchers and enterprise
    ML engineers began pursuing production systems that are in the realm of the Bayes
    theoretical error limit.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在大量计算机视觉和NLP任务中，深度学习已经达到了一群专家的误差率，远远超过了传统的软件应用和专家系统。到2020年，研究人员和企业机器学习工程师开始追求处于贝叶斯理论误差极限范围内的生产系统。
- en: 1.2.2 Next steps in computer learning
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 计算机学习的下一步
- en: Now that we understand how we got here, where, exactly, are we? As computer
    learning has changed, we first moved from artificial intelligence to intelligent
    automation. And then we’ve moved into machine design, model fusion, and model
    amalgamation. Let’s define these modern advances.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了我们是如何到达这里的，我们确切地在哪里？随着计算机学习的改变，我们首先从人工智能转向智能自动化。然后我们进入了机器设计、模型融合和模型合并。让我们定义这些现代进步。
- en: Intelligent automation
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 智能自动化
- en: As we’ve just seen, early artificial intelligence meant classical AI, which
    was mostly rule-based and required domain experts. This allowed us to essentially
    write software programs to start automating tasks that were typically done manually.
    Then, in narrow AI, we applied statistics to learning, eliminating the need for
    a domain expert.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们刚才看到的，早期的人工智能意味着经典AI，这主要是基于规则的，需要领域专家。这使我们能够基本上编写软件程序来开始自动化通常手工完成的任务。然后，在窄AI中，我们将统计学应用于学习，消除了对领域专家的需求。
- en: The next major advance was *intelligent automation* (*IA*). In this approach,
    the models learn a (near) optimal way to automate the process, exceeding the performance
    and accuracy when compared to the manual or computer-automated counterpart.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个主要进步是*智能自动化*（*IA*）。在这种方法中，模型学习自动化过程的（近）最优方式，其性能和准确性超过了手动或计算机自动化的对应物。
- en: Typically, the IA system works as a pipeline process. Cumulative information,
    transformations, and state transitions are the inputs to a model at various points
    in the pipeline. The output, or prediction, of each model is used to perform the
    next information transformation and/or decide the next state transition. Typically,
    each model is trained and deployed independently, usually as a microservice, with
    a backend application driving the whole pipeline process.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，IA系统作为一个管道流程工作。累积信息、转换和状态转换是管道中各个点的模型输入。每个模型的输出或预测被用来执行下一个信息转换和/或决定下一个状态转换。通常，每个模型都是独立训练和部署的，通常作为一个微服务，后端应用程序驱动整个管道流程。
- en: An example of IA is automating the extraction of patient information from patient
    medical records from diverse sources and formats, including sources the model
    was never trained on. I worked on architecting such systems in the healthcare
    field in 2018\. Today, numerous turnkey providers make these kinds of systems
    available; Google Cloud Healthcare API ([https://cloud.google.com/healthcare](https://cloud.google.com/healthcare))
    is one.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: IA的一个例子是从来自不同来源和格式的患者医疗记录中自动提取患者信息，包括模型从未训练过的来源。我在2018年从事了医疗保健领域这类系统的架构设计工作。如今，许多现成的提供商使这些系统可用；Google
    Cloud Healthcare API ([https://cloud.google.com/healthcare](https://cloud.google.com/healthcare))就是其中之一。
- en: In 2019, AI was moving into full production in a vast number of enterprise-size
    companies. Throughout the year, I would be in a growing number of meetings with
    Google’s largest clients. We now talk about AI in business terms. These technology
    concepts have evolved into business concepts.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 到2019年，AI正在大量企业规模的公司中进入全面生产。在整个一年中，我会与谷歌最大的客户进行越来越多的会议。我们现在用商业术语来谈论AI。这些技术概念已经演变成了商业概念。
- en: In these meetings, we have moved away from saying *AI* and replaced it with
    *IA* to demystify the process. We have the client describe each step (manual and
    computer assisted) in the process that they want to apply AI to. Let’s say that
    one step costs $100,000\. In the past, our tendency would be to jump to that step
    and apply AI—the “big reward.” But let’s say another step costs just a penny,
    but occurs a million times a day—that’s $10,000 a day, or $3.65 million a year.
    And let’s say we could replace this low-hanging fruit with a model that learns
    the optimal way to automate this step and that operationally costs $40,000 a year.
    No one leaves $3.61 million dollars on the table.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些会议中，我们不再使用*AI*，而是用*IA*来揭示这个过程。我们让客户描述他们想要应用AI的过程中的每个步骤（手动和计算机辅助）。假设一个步骤的成本是100,000美元。过去，我们的倾向是直接跳到那个步骤并应用AI——“大回报”。但假设另一个步骤的成本只是几分钱，但每天发生一百万次——那就是每天10,000美元，或每年3,650,000美元。假设我们可以用每年运营成本为40,000美元的模型来替代这个低垂的果实。没有人会留下3,610,000美元。
- en: That’s intelligent automation. Instead of programmers coding a predesigned algorithm
    to automate, the programmers guide the model to intelligently learn the optimal
    algorithm. Figure 1.4 maps out how we would apply IA to a single step in a claim-processing
    pipeline.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是智能自动化。程序员不再编写预设计的算法来自动化，而是引导模型智能地学习最优算法。图1.4展示了我们将如何将智能自动化应用于索赔处理流程的单一步骤。
- en: '![](Images/CH01_F04_Ferlitsch.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH01_F04_Ferlitsch.png)'
- en: Figure 1.4 Intelligent automation applied to claims processing
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 智能自动化应用于索赔处理
- en: Let’s do a high-level review of what is happening in this pipeline. At step
    1, documents relating to a claim are scanned and ingested into the IA pipeline.
    At step 2, the prior practice of a document operator subsequently viewing each
    scanned document and tagging it is replaced with a natural-language classification
    model that has been trained for this claims-processing task.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对这个管道中发生的事情进行一个高级回顾。在第1步，与索赔相关的文件被扫描并摄入到IA管道中。在第2步，以前文档操作员随后查看每个扫描的文档并标记的做法被一个为这个索赔处理任务训练的自然语言分类模型所取代。
- en: This replacement has several advantages. First, the cost of manual labor is
    eliminated. In addition to the speed improvement of a computer versus a human,
    the process can be distributed so that a mass number of documents can be processed
    in parallel.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种替代有几个优点。首先，消除了人工成本。除了计算机比人类速度快之外，这个过程可以分布，以便可以并行处理大量文档。
- en: Second, the error rate on correctly tagging the document’s classes is substantially
    reduced from the human error rate. Let’s consider why. Each human operator may
    have different levels of training and experience and wide variance in accuracy.
    Additionally, human fatigue contributes to the error rate. But let’s say we had
    one thousand trained human operators viewing the same document(s) and we use a
    majority voting method on how to tag the document. We would expect the error rate
    to be substantially reduced, approaching near zero.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，正确标记文档类别的错误率与人类错误率相比大幅降低。让我们考虑一下原因。每个操作员可能具有不同的训练水平和经验，以及广泛的准确性差异。此外，人类疲劳也会导致错误率上升。但假设我们有一千名经过培训的人类操作员查看相同的文档，并且我们使用多数投票法来决定如何标记文档。我们预计错误率将大幅降低，接近于零。
- en: 'That’s what the model does: it has been trained on vast numbers of documents
    that have been tagged by vast numbers of trained human operators. In that way,
    once trained, the model’s performance is equal to that of a collective of trained
    human operators.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 模型就是这样做的：它已经在大量由大量经过培训的人类操作员标记的文档上进行了训练。通过这种方式，一旦训练完成，模型的性能就等同于一群经过培训的人类操作员的集体性能。
- en: At step 3 in the manual version, an expert human operator would inspect the
    tagging to further reduce errors. This step is not eliminated in the IA process—but
    with the substantial reduction in errors from step 2, the workload on the human
    operator is significantly further reduced.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在手动版本的步骤3中，专家人工操作员会检查标记以进一步减少错误。这一步骤在IA流程中并未被消除——但由于步骤2中错误的大幅减少，人工操作员的工作量显著减少。
- en: The IA processes downstream continue to reduce/eliminate human operator costs
    and further reduce error rates. Once we get to the final step, a trained subject-matter
    expert (SME) makes the final review for authorization (or nonauthorization) of
    payment. Now that the information that the SME reviews is of higher accuracy,
    the human subjective decision is more reliable, further reducing costs of making
    the wrong subjective decision.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: IA流程下游继续降低/消除人工操作员成本，并进一步降低错误率。一旦到达最后一步，经过培训的主题专家（SME）将对支付授权（或非授权）进行最终审查。现在，由于SME审查的信息准确性更高，人类主观决策更加可靠，进一步降低了错误主观决策的成本。
- en: We in the industry have stopped using the term *machine learning* and replaced
    it with *machine design*, to make the analogy to computer-aided design (CAD).
    We applied CAD to problems that were too complex to engineer even a suboptimal
    solution. These systems had building components, mathematical knowledge, and expert
    system rules, and the SMEs guided the CAD systems to find a good suboptimal solution.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在行业中已经停止使用*机器学习*这个术语，并用*机器设计*来代替它，以便与计算机辅助设计（CAD）进行类比。我们将CAD应用于那些即使设计一个次优解也太复杂的工程问题。这些系统具有建筑组件、数学知识和专家系统规则，而SMEs则指导CAD系统找到良好的次优解。
- en: In machine design, the system instead learns the building components, the mathematical
    knowledge, and the rules, and the ML engineer guides the machine design to find
    the optimal solution. By moving to machine design, we free up the high-value people
    assets to work on the next level of challenging problems, accelerating their technical
    progression and bringing a higher return on investment (ROI) per staffer for the
    business.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器设计中，系统学习的是建筑组件、数学知识和规则，而机器学习工程师则指导机器设计以找到最优解。通过转向机器设计，我们释放了高价值的人力资源去解决下一阶段的挑战性问题，加速他们的技术进步，并为业务带来更高的投资回报率（ROI）。
- en: Machine design
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 机器设计
- en: Before deep learning, SMEs designed software programs to search for good solutions
    in parts of the software and hardware that had high complexity. Typically, these
    programs were a combination of search optimization and rule-based techniques.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习之前，SMEs设计软件程序来搜索软件和硬件中具有高复杂性的部分中的良好解决方案。通常，这些程序是搜索优化和基于规则技术的组合。
- en: In the next advancement, *machine design*, the models learn a (near) optimal
    way to design and integrate the software and hardware components. These systems
    exceed in performance, accuracy, and complexity, even when compared to models
    designed by an SME with the assistance of a CAD program. The human designer uses
    their real-world expertise to guide the model’s search space for solutions.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个发展阶段，*机器设计*，模型学习了一种（近似）最优的方式来设计和集成软件和硬件组件。这些系统在性能、准确性和复杂性方面都超越了由具有CAD程序辅助的小型企业专家（SME）设计的模型。人类设计师利用他们的现实世界专业知识来引导模型搜索解决方案的空间。
- en: Consider a hospital with two X-ray departments; one department has an expensive
    X-ray machine, and the other a low-cost one. An examining physician chooses which
    department to send a patient to for confirmation of a pneumonia diagnosis *depending
    on the likelihood of the patient having pneumonia*. If the likelihood is low,
    or unlikely, for pneumonia, the doctor sends the patient to the low-cost X-ray
    machine, following hospital policy and the desire to lower costs for the insurance
    provider. If the determination is high, or likely, the patient merits the high-cost
    X-ray. This is an example of machine design informing the hyperparameter and architecture
    search space and guiding the pipeline in a system for automatic learning of medical
    images from different distributions (medical devices, in this case, X-ray machines).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个有两个X射线部门的医院；一个部门有一台昂贵的X射线机，另一个部门有一台低成本X射线机。一位检查医生根据患者患有肺炎的可能性选择将患者送往哪个部门进行肺炎诊断确认。如果肺炎的可能性低，或者不太可能，医生会根据医院政策和降低保险提供商成本的愿望，将患者送往低成本X射线机。如果确定的可能性高，或者很可能，患者应得到昂贵的X射线。这是一个机器设计影响超参数和架构搜索空间，并指导从不同分布（在这种情况下是X射线机）自动学习医学图像的系统管道的例子。
- en: Keep in mind that if the accumulative X-rays and diagnostic determinations from
    the two X-ray devices are used to train a model, we have bias in the data. Instead
    of learning from the data, the model may inadvertently learn the unique characteristics
    of the two medical devices—a bias of the *view perspective**.* The classic example
    of a view-perspective problem in a model is the case of determining dogs versus
    wolves, in which the model inadvertently learned snow for wolves, since all the
    training pictures of the wolves were taken during winter.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，如果使用两个X射线设备产生的累积X射线和诊断确定数据来训练一个模型，我们会有数据偏差。模型不是从数据中学习，而是可能无意中学习了两个医疗设备的独特特征——*视角偏差*。模型中视角偏差的经典例子是确定狗与狼的情况，模型无意中学习了狼的雪，因为所有狼的训练图片都是在冬天拍摄的。
- en: In machine design, in addition to training a model, the system learns the optimal
    training pipeline for an adversarial model, known as the *surrogate*. If you want
    to delve into this more, “An Adversarial Approach for the Robust Classification
    of Pneumonia from Chest Radiographs” ([https://arxiv.org/pdf/2001.04051.pdf](https://arxiv.org/pdf/2001.04051.pdf))
    is a foundational machine-design paper related to this very problem.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器设计中，除了训练模型外，系统还学习了对抗性模型（称为*代理*）的最佳训练管道。如果您想深入了解，请参阅“一种用于从胸部X光片中稳健分类肺炎的对抗性方法”（[https://arxiv.org/pdf/2001.04051.pdf](https://arxiv.org/pdf/2001.04051.pdf)），这是一篇关于这个问题的基础机器设计论文。
- en: Model fusion
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 模型融合
- en: '*Model* *fusion* is the next advancement in developing more-accurate, lower-cost
    systems for predictive maintenance and fault detection, such as those used in
    IoT sensor systems. Traditionally, very expensive equipment and infrastructure,
    such as factory machines, airplanes, and regional power infrastructures, have
    had built-in IoT sensors. This continuous sensory data would be fed to rule-based
    algorithms designed by an expert.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型融合*是开发更精确、成本更低的预测维护和故障检测系统（例如在物联网传感器系统中使用的系统）的下一项进步。传统上，非常昂贵的设备和基础设施，如工厂机器、飞机和地区电力基础设施，都内置了物联网传感器。这些连续的感官数据将被输送到由专家设计的基于规则的算法中。'
- en: The problem with these traditional systems has been that they are subject to
    high environmental variance that affects their reliability. For example, in the
    electrical power industry, transmission lines have sensors at each tower that
    monitor for anomalies in the line impedance between the towers. The impedance
    can fluctuate as a result of stress on the line connection due to wind, changes
    in temperature affecting conductivity, and secondary factors such as moisture
    buildup.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些传统系统的问题在于它们容易受到高环境变化的影响，这影响了它们的可靠性。例如，在电力行业中，输电线路在每个塔上都有传感器，用于监控塔之间的线路阻抗异常。由于风对线路连接的压力、温度变化影响导电性以及次要因素（如水分积累）的影响，阻抗可能会波动。
- en: Model fusion improves the reliability of IoT systems by using a machine-learned
    model with higher operational cost to generate label data to convert the expert-designed
    system. Continuing with our example, the power industry today uses drones and
    deep learning models trained in computer vision to periodically inspect power-transmission
    lines. This process is highly accurate and more operationally expensive. Therefore,
    it is used to generate label data for the impedance sensor data created by the
    lower-cost sensor system. The labeled data generated at high operational cost
    is then used to train another model, which impedance sensors (the low-cost system)
    then use to achieve comparable reliability.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 模型融合通过使用具有更高操作成本的机器学习模型生成标签数据来转换专家设计的系统，从而提高了物联网系统的可靠性。继续我们的例子，电力行业今天使用无人机和计算机视觉训练的深度学习模型定期检查输电线路。这个过程非常准确，但操作成本更高。因此，它被用来为低成本传感器系统创建的阻抗传感器数据生成标签数据。在较高操作成本下生成的标签数据随后被用来训练另一个模型，该模型使用阻抗传感器（低成本系统）来实现可比的可靠性。
- en: Model amalgamation
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 模型融合
- en: Before deep learning, applications were constructed as either a monolithic application
    running on a backend server or a core backbone on a server that used distributed
    microservices. In *model amalgamation*, the model(s) essentially become the entire
    application, which directly shares model components and outputs and learns a communication
    interface between the models. All this happens without the need for a bulky backend
    application or microservices.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习之前，应用程序要么是运行在后端服务器上的单体应用程序，要么是服务器上的核心骨干，该服务器使用分布式微服务。在*模型融合*中，模型（们）本质上成为整个应用程序，直接共享模型组件和输出，并在模型之间学习通信接口。所有这些都不需要庞大的后端应用程序或微服务。
- en: Imagine a model pipeline for the real estate industry that uses vision analysis
    on photographs of houses and apartment buildings to determine rental pricing.
    Models within a set are chained together, with each model trained on a particular
    feature; together, they automatically determine rental condition, rental amenities,
    and market appeal, and come up with the corresponding pricing.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下房地产行业的模型管道，它使用房屋和公寓大楼的照片进行视觉分析，以确定租金定价。一组模型中的模型是串联在一起的，每个模型都针对特定的特征进行训练；一起，它们自动确定租赁条件、租赁设施和市场吸引力，并得出相应的定价。
- en: Let’s compare this to more traditional IA, where each step in the process pipeline
    is a separate deployed model instance, taking as input either the original image,
    or a transformation and state, all of which is controlled by a backend rule-based
    application designed by expert(s). In contrast, in an amalgamation, the model
    instances communicate directly with each other. Each model has learned the optimal
    method for performing its specialized task (e.g., determine condition); learned
    the optimal communication path and representation between the models (models for
    home, room, and amenities); and learned the optimal method for determining state
    changes (condition of the property).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下更传统的IA，其中流程管道中的每一步都是一个单独部署的模型实例，输入可以是原始图像、转换和状态，所有这些都由专家设计的基于规则的后端应用程序控制。相比之下，在融合中，模型实例直接相互通信。每个模型都学会了执行其专业任务的最佳方法（例如，确定条件）；学会了模型之间的最佳通信路径和表示（房屋、房间和设施模型）；以及学会了确定状态变化（财产条件）的最佳方法。
- en: In 2021, I anticipate that at the enterprise level, production will move to
    model amalgamation. We are still trying to figure out how to make that work. Prior
    to amalgamation, a plurality of models would be deployed performing different
    tasks, and developers would construct a backend application that made representational
    state transfer (REST) or microservice calls. We still coded the logic of the application,
    and the interface and data communication between the application and the models.
    Figure 1.5 is an example of a model amalgamation I designed in late 2019 for sports
    broadcasting.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在2021年，我预计在企业层面，生产将转向模型融合。我们仍在努力弄清楚如何使其运作。在融合之前，多个模型会被部署执行不同的任务，开发者会构建一个后端应用程序，该程序执行表示状态转移（REST）或微服务调用。我们仍然编写了应用程序的逻辑，以及应用程序和模型之间的接口和数据通信。图1.5是我在2019年底为体育广播设计的模型融合的一个示例。
- en: '![](Images/CH01_F05_Ferlitsch.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH01_F05_Ferlitsch.png)'
- en: Figure 1.5 Model amalgamation applied to sports broadcasting
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 应用到体育广播的模型融合
- en: Let’s walk through this process. First, the amalgamation ingests live video;
    that is, the amalgamation is continuously processing the video in real time. The
    video is parsed in real time as a time-sequence set of frames. Each frame is an
    image of the game, such as a baseball player ready to bat. Each frame is first
    processed by a shared set of convolutional layers (shared convolutional layers)
    that generates a common internal encoding across downstream tasks. In other words,
    instead of each downstream task (model) starting with the same input image and
    processing it into an internal encoding, the input image is encoded once and the
    encoding is reused downstream. This speeds up the model’s response and shrinks
    its size in memory.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步了解这个过程。首先，合并处理实时视频；也就是说，合并处理正在实时连续处理视频。视频被实时解析为一系列时间序列的帧。每一帧都是比赛的图像，例如一个准备击球的棒球运动员。每一帧首先由一组共享的卷积层（共享卷积层）进行处理，生成跨下游任务的通用内部编码。换句话说，每个下游任务（模型）不是从相同的输入图像开始并处理成内部编码，而是输入图像只编码一次，编码在下游重复使用。这加快了模型的响应速度，并缩小了其在内存中的大小。
- en: Next, the generated common encoding goes through an object-detection model,
    which has been trained on the common encoding as input instead of the input image,
    reducing the size and increasing the speed of the object detection. Let’s say
    the object detection is trained to recognize objects including people, player
    equipment, stadium, and field. For each object it recognizes in the frame, it
    will output an object-level embedding, which is a lower-dimensional representation
    (for example, reduced-size encoding) along with the spatial coordinates within
    the upstream input frame.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，生成的通用编码通过一个对象检测模型，该模型已经针对通用编码进行训练，而不是输入图像，从而减少了检测对象的大小并提高了速度。比如说，对象检测被训练以识别包括人物、球员装备、体育场和场地在内的对象。对于它在画面中识别的每个对象，它将输出一个对象级别的嵌入，这是一个低维度的表示（例如，缩小尺寸的编码）以及在上游输入帧内的空间坐标。
- en: These object-level embeddings now become inputs to another set of downstream
    tasks. Next, you see that embeddings classified as people are passed to a facial-recognition
    model that has been trained on the embeddings versus the original image. The model
    may be trained, for example, to recognize players, officials, referees, coaches,
    and security, and correspondingly tags the embedding. The player-specific object
    embeddings are then passed on to a pose-estimation model that finds human key
    points and classifies the identified person’s pose in the frame, such as player
    *A* is in a batting position.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这些对象级别的嵌入现在成为另一组下游任务的输入。接下来，你会看到被分类为人物的嵌入被传递到一个已经针对嵌入与原始图像进行训练的面部识别模型。例如，该模型可能被训练以识别球员、官员、裁判、教练和安全人员，并相应地标记嵌入。然后，特定于球员的对象嵌入被传递到一个姿态估计模型，该模型找到人体关键点并分类识别的人物的姿态，例如球员
    *A* 处于击球位置。
- en: Next, the object-level embeddings (players, gears, stadium, and so forth) combine
    with the player-specific pose into an information-enriched dense embedding. And
    all this rich information is passed to another model to predict the player’s action,
    such as player *A* is at the mound, ready to bat. This predictive action is then
    passed to another model that converts the action into closed-captioned text that
    is overlaid on the live broadcast.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，对象级别的嵌入（球员、齿轮、体育场等）与特定于球员的姿态结合成一个信息丰富的密集嵌入。所有这些丰富的信息都传递给另一个模型来预测球员的动作，例如球员
    *A* 正在准备击球。这个预测动作随后传递给另一个模型，将动作转换为叠加在直播上的字幕文本。
- en: Let’s assume the sports event is being broadcasted across the world and watched
    by viewers in a wide variety of languages. The output from the image-captioning
    model (for example, English) is passed to another model that performs language
    translation specific to each market. In each market, the translated text is converted
    to speech for real-time commentary.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 假设体育赛事正在全球范围内播出，被各种语言的观众观看。图像字幕模型的输出（例如，英语）被传递给另一个模型，该模型执行针对每个市场的特定语言翻译。在每个市场中，翻译的文本被转换为语音进行实时解说。
- en: As you can see, models have evolved from single-task predictions and standalone
    deployments, to models that perform multiple tasks, share model components, and
    are integrated to form a solution, such as in the healthcare document-handling
    and the sports broadcasting examples. Another way of describing these integrated
    model solutions is as a *serving pipeline*. A pipeline is made of connected components;
    the output of one component is the input to another, and each component is configurable,
    replaceable, and has version control and history. Using pipelines in today’s production
    ML extends across the entire end-to-end pipeline.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，模型已经从单一任务的预测和独立部署，发展到执行多项任务、共享模型组件并集成形成解决方案的模型，例如在医疗文档处理和体育广播的例子中。另一种描述这些集成模型解决方案的方式是作为*serving
    pipeline*（服务管道）。管道由连接的组件组成；一个组件的输出是另一个组件的输入，每个组件都是可配置的、可替换的，并且具有版本控制和历史记录。在今天的生产机器学习中，使用管道的范围涵盖了整个端到端流程。
- en: 1.3 The benefits of design patterns
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 设计模式的益处
- en: Prior to 2017, the majority of renditions of neural network models in all fields
    were coded in a batch scripting style. As AI researchers and experienced software
    engineers became increasingly involved in research and design, we started to see
    a shift in the coding of models that reflected software engineering principles
    for reuse and design patterns.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在2017年之前，所有领域的神经网络模型的实现大多数都是用批处理脚本风格编写的。随着人工智能研究人员和经验丰富的软件工程师越来越多地参与研究和设计，我们开始看到模型编码的转变，这反映了软件工程原则的重用和设计模式。
- en: A *design pattern* implies that a best practice exists for constructing and
    coding a model that can be reapplied across a wide range of cases, such as image
    classification, object detection and tracking, facial recognition, image segmentation,
    super-resolution, and style transfer for image data; document classification,
    sentiment analysis, entity extraction, and summarization for text data; and classification,
    regression, and forecasting for unstructured data.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '*设计模式*意味着存在一种最佳实践，用于构建和编码一个可以在广泛情况下重用的模型，例如图像分类、目标检测和跟踪、人脸识别、图像分割、超分辨率和图像数据的风格迁移；文本数据的文档分类、情感分析、实体提取和摘要；以及非结构化数据的分类、回归和预测。'
- en: The development of design patterns for deep learning is what led to model amalgamation,
    model fusion, and machine design—in which model components can be reused and adapted.
    These design patterns for model components allowed researchers and other deep
    learning practitioners to incrementally develop both model components and best
    practices for applications, across all models and data types. This knowledge sharing
    accelerated the development of design patterns and the reuse of model components
    that makes it possible to deploy deep learning into widespread production applications.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习设计模式的发展导致了模型融合、模型融合和机器设计——其中模型组件可以被重用和适应。这些模型组件的设计模式允许研究人员和其他深度学习实践者逐步开发模型组件和应用的最佳实践，适用于所有模型和数据类型。这种知识共享加速了设计模式的发展，并促进了模型组件的重用，使得深度学习能够广泛应用于生产应用。
- en: Many of the historical SOTA models I cover in this book revealed knowledge and
    concepts that have been incorporated into today’s modern production. Even though
    many of these models eventually stop being used, an understanding of the knowledge,
    concepts, and building-block components behind them is essential to understanding
    and practicing deep learning at today’s large scale.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这本书中介绍的历史上最先进的模型中，许多都揭示了被纳入今天现代生产中的知识和概念。尽管许多这些模型最终停止使用，但理解其背后的知识、概念和构建块组件对于理解和实践今天的深度学习至关重要。
- en: One of the earliest design patterns for neural network models was *procedural
    reuse*, which was simultaneously adopted across computer vision, NLU, and structured
    data. As with a software application, we design a procedural reuse model as components
    that reflect the data flow and decompose components into reusable functions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络模型最早的设计模式之一是*过程重用*，它同时被应用于计算机视觉、NLU和结构化数据。与软件应用一样，我们设计过程重用模型作为反映数据流和将组件分解为可重用函数的组件。
- en: There were—and still are—many benefits to using a procedural reuse design pattern.
    First, it simplifies the task of representing models in architectural diagrams.
    Prior to the use of a formal design pattern, each team of researchers invented
    its own way of representing its model architecture in the papers it published.
    A design pattern also defines how a model structure and flow are represented.
    Having a consistent and refined method simplified the representation of architectural
    diagrams. Second, the model architectures are more understandable by other researchers
    and ML engineers. Furthermore, working from a standard pattern exposes the inner
    workings of the design, which, in turn, makes the models easier to modify and
    easier to troubleshoot and debug.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 使用过程重用设计模式有许多好处——并且现在仍然如此。首先，它简化了在架构图中表示模型的任务。在正式设计模式的使用之前，每个研究团队都在其发表的论文中发明了自己的方法来表示其模型架构。设计模式还定义了如何表示模型结构和流程。拥有一致和精细的方法简化了架构图的表示。其次，模型架构对其他研究人员和机器学习工程师来说更容易理解。此外，从标准模式开始工作揭示了设计的内部运作，这反过来使得模型更容易修改，也更容易进行故障排除和调试。
- en: In 2016, research papers began presenting component flow—typically referred
    to as the *stem*, (representational) *learner*, and (transformational) *task*.
    Prior to 2016, research papers presented their models as a monolithic architecture.
    These monolithic architectures made it challenging for researchers to prove that
    a new concept improved any individual part of a model. Because these components
    contain repeated flow patterns, eventually the concept of configurable components
    emerged. These repeated flow patterns were subsequently reused and refined by
    other researchers in the design of their model architectures. While the application
    of model components lagged behind in NLU and structured data, by 2017 we started
    to see their appearance in research papers. Today, regardless of the model type
    and field, you see the model design comprising the same comparable three primary
    model components.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在2016年，研究论文开始提出组件流——通常被称为*茎*，（表征性）*学习器*和（转换性）*任务*。在2016年之前，研究论文将它们的模型作为单一架构提出。这些单一架构使得研究人员难以证明新概念改善了模型中的任何一部分。因为这些组件包含重复的流程模式，最终出现了可配置组件的概念。这些重复的流程模式随后被其他研究人员在他们的模型架构设计中重用和改进。尽管在NLU和结构化数据中模型组件的应用落后，但到2017年，我们开始看到它们在研究论文中的出现。今天，无论模型类型和领域如何，你都会看到模型设计由相同的三种主要模型组件组成。
- en: An earlier version of a design pattern that decomposed a model into components
    was SqueezeNet ([https://arxiv.org/pdf/1602.07360.pdf](https://arxiv.org/pdf/1602.07360.pdf)),
    which used configurable components based on metaparameters. The introduction of
    metaparameters, which describe how to configure model components, helped formalize
    how to represent, design, and implement configurable components. Designing models
    based on configurable components provided the means for researchers to measure
    performance improvements on a per-component basis, while trying various component
    configurations. This design approach is standard practice when developing application
    software; among its many of the benefits is that it promotes code reuse.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型分解为组件的早期设计模式是SqueezeNet ([https://arxiv.org/pdf/1602.07360.pdf](https://arxiv.org/pdf/1602.07360.pdf))，它使用了基于元参数的可配置组件。元参数的引入，描述了如何配置模型组件，有助于正式化如何表示、设计和实现可配置组件。基于可配置组件设计模型为研究人员提供了在尝试各种组件配置的同时，按组件衡量性能改进的手段。这种设计方法在开发应用软件时是标准做法；其众多好处之一是它促进了代码重用。
- en: Procedural patterns for reuse were the first, and remain the most fundamental,
    reusable designs, so they are the focus of this book. Later, what we call factory
    and abstract factory patterns would be introduced to do machine design. A *factory
    design pattern* uses SOTA building blocks as a factory and an objective to search
    for the best design that matches the requirements. An *abstract factory pattern*
    abstracts down another level and searches for the best factory, which is then
    used to search for the best model.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 用于重用的过程模式是第一个，也是最基本的可重用设计，因此它们是本书的重点。后来，我们所说的工厂模式和抽象工厂模式被引入来进行机器设计。*工厂设计模式*使用SOTA（最先进的技术）构建块作为工厂，并寻找与需求匹配的最佳设计。*抽象工厂模式*进一步抽象，寻找最佳的工厂，然后使用该工厂来寻找最佳模型。
- en: But in this book, you will learn the cornerstone designs, starting with the
    architectures of the basic DNNs and CNNs in part 1, moving to the seminal models
    coded for procedural reuse in part 2, and finishing up with a tour of the modern
    production pipeline in part 3.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 但在这本书中，你将学习基石设计，从第一部分的基本DNN和CNN架构开始，过渡到第二部分为程序重用编码的原始模型，最后在第三部分完成对现代生产管道的巡礼。
- en: Summary
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning evolved from classical AI to narrow AI, which led to using AI
    to solve problems with high-dimensionality inputs.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习从经典AI发展到窄AI，这导致了使用AI来解决具有高维输入的问题。
- en: Deep learning has evolved from experimenting with models to a reusable and reconfigurable
    pipeline approach for data, training, deployment, and serving.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习已经从实验模型发展到数据、训练、部署和服务的可重用和可配置管道方法。
- en: At the leading edge at the enterprise scale, ML practitioners are using model
    amalgamation, model fusion, and machine design.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在企业规模的尖端，机器学习从业者正在使用模型融合、模型融合和机器设计。
- en: The procedural reuse design pattern is the building block and segue into today’s
    leading edge at the enterprise scale.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 程序重用设计模式是构建块，也是通往今天企业规模尖端领先地位的过渡。
