- en: Chapter 1\. Introducing Kubernetes
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章\. 介绍 Kubernetes
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Understanding how software development and deployment has changed over recent
    years
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解近年来软件开发和部署的变化
- en: Isolating applications and reducing environment differences using containers
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用容器隔离应用程序并减少环境差异
- en: Understanding how containers and Docker are used by Kubernetes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 如何使用容器和 Docker
- en: Making developers’ and sysadmins’ jobs easier with Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 使开发者和系统管理员的工作变得更简单
- en: Years ago, most software applications were big monoliths, running either as
    a single process or as a small number of processes spread across a handful of
    servers. These legacy systems are still widespread today. They have slow release
    cycles and are updated relatively infrequently. At the end of every release cycle,
    developers package up the whole system and hand it over to the ops team, who then
    deploys and monitors it. In case of hardware failures, the ops team manually migrates
    it to the remaining healthy servers.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 几年前，大多数软件应用程序都是大型单体，要么作为一个单独的进程运行，要么作为少量分散在几台服务器上的进程运行。这些遗留系统今天仍然很普遍。它们的发布周期缓慢，更新相对较少。在每个发布周期的末尾，开发者将整个系统打包，并将其交给运维团队，然后运维团队部署并监控它。在硬件故障的情况下，运维团队手动将其迁移到剩余的健康服务器。
- en: Today, these big monolithic legacy applications are slowly being broken down
    into smaller, independently running components called microservices. Because microservices
    are decoupled from each other, they can be developed, deployed, updated, and scaled
    individually. This enables you to change components quickly and as often as necessary
    to keep up with today’s rapidly changing business requirements.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，这些大型单体遗留应用程序正在逐渐被分解成更小、独立运行的组件，称为微服务。由于微服务彼此解耦，它们可以单独开发、部署、更新和扩展。这使得您能够快速且频繁地更改组件，以跟上今天快速变化的业务需求。
- en: But with bigger numbers of deployable components and increasingly larger datacenters,
    it becomes increasingly difficult to configure, manage, and keep the whole system
    running smoothly. It’s much harder to figure out where to put each of those components
    to achieve high resource utilization and thereby keep the hardware costs down.
    Doing all this manually is hard work. We need automation, which includes automatic
    scheduling of those components to our servers, automatic configuration, supervision,
    and failure-handling. This is where Kubernetes comes in.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，随着可部署组件数量的增加和数据中心规模的不断扩大，配置、管理和保持整个系统平稳运行变得越来越困难。确定每个组件放置的位置以实现高资源利用率并因此降低硬件成本变得更加困难。手动完成所有这些工作是一项艰巨的任务。我们需要自动化，这包括自动将这些组件调度到我们的服务器上、自动配置、监督和故障处理。这正是
    Kubernetes 发挥作用的地方。
- en: Kubernetes enables developers to deploy their applications themselves and as
    often as they want, without requiring any assistance from the operations (ops)
    team. But Kubernetes doesn’t benefit only developers. It also helps the ops team
    by automatically monitoring and rescheduling those apps in the event of a hardware
    failure. The focus for system administrators (sysadmins) shifts from supervising
    individual apps to mostly supervising and managing Kubernetes and the rest of
    the infrastructure, while Kubernetes itself takes care of the apps.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 允许开发者自行部署他们的应用程序，并且可以随时进行部署，无需从运维（ops）团队获得任何帮助。但 Kubernetes 的好处不仅限于开发者。它还通过在硬件故障的情况下自动监控和重新调度这些应用程序来帮助运维团队。系统管理员（sysadmins）的焦点从监督单个应用程序转移到主要监督和管理
    Kubernetes 以及其他基础设施，而 Kubernetes 本身则负责应用程序。
- en: '|  |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Kubernetes is Greek for pilot or helmsman (the person holding the ship’s steering
    wheel). People pronounce Kubernetes in a few different ways. Many pronounce it
    as Koo-ber-nay-tace, while others pronounce it more like Koo-ber-netties. No matter
    which form you use, people will understand what you mean.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 在希腊语中意为飞行员或舵手（握有船舵的人）。人们对 Kubernetes 的发音有几种不同的方式。许多人将其发音为 Koo-ber-nay-tace，而其他人则更接近于
    Koo-ber-netties。无论您使用哪种形式，人们都会理解您的意思。
- en: '|  |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Kubernetes abstracts away the hardware infrastructure and exposes your whole
    datacenter as a single enormous computational resource. It allows you to deploy
    and run your software components without having to know about the actual servers
    underneath. When deploying a multi-component application through Kubernetes, it
    selects a server for each component, deploys it, and enables it to easily find
    and communicate with all the other components of your application.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes抽象化了硬件基础设施，并将您的整个数据中心暴露为一个单一的巨大计算资源。它允许您部署和运行软件组件，而无需了解实际的服务器。当通过Kubernetes部署多组件应用程序时，它会为每个组件选择一个服务器，部署它，并使其能够轻松地找到并与其他应用程序的所有其他组件进行通信。
- en: This makes Kubernetes great for most on-premises datacenters, but where it starts
    to shine is when it’s used in the largest datacenters, such as the ones built
    and operated by cloud providers. Kubernetes allows them to offer developers a
    simple platform for deploying and running any type of application, while not requiring
    the cloud provider’s own sysadmins to know anything about the tens of thousands
    of apps running on their hardware.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得Kubernetes非常适合大多数本地数据中心，但它在被用于最大的数据中心时开始发光，例如由云服务提供商建设和运营的那些数据中心。Kubernetes允许他们为开发者提供一个简单的平台，用于部署和运行任何类型的应用程序，同时不需要云服务提供商的自己的系统管理员了解在其硬件上运行的数万个应用程序的任何信息。
- en: With more and more big companies accepting the Kubernetes model as the best
    way to run apps, it’s becoming the standard way of running distributed apps both
    in the cloud, as well as on local on-premises infrastructure.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 随着越来越多的大型公司接受Kubernetes模型作为运行应用程序的最佳方式，它正在成为在云中以及本地本地基础设施上运行分布式应用程序的标准方式。
- en: 1.1\. Understanding the need for a system like Kubernetes
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 1.1. 理解需要像Kubernetes这样的系统
- en: Before you start getting to know Kubernetes in detail, let’s take a quick look
    at how the development and deployment of applications has changed in recent years.
    This change is both a consequence of splitting big monolithic apps into smaller
    microservices and of the changes in the infrastructure that runs those apps. Understanding
    these changes will help you better see the benefits of using Kubernetes and container
    technologies such as Docker.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在您开始详细了解Kubernetes之前，让我们快速看一下近年来应用程序的开发和部署是如何发生变化的。这种变化既是将大型单体应用程序拆分为更小的微服务的结果，也是运行这些应用程序的基础设施变化的结果。理解这些变化将帮助您更好地看到使用Kubernetes和Docker等容器技术的好处。
- en: 1.1.1\. Moving from monolithic apps to microservices
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 1.1.1. 从单体应用程序迁移到微服务
- en: Monolithic applications consist of components that are all tightly coupled together
    and have to be developed, deployed, and managed as one entity, because they all
    run as a single OS process. Changes to one part of the application require a redeployment
    of the whole application, and over time the lack of hard boundaries between the
    parts results in the increase of complexity and consequential deterioration of
    the quality of the whole system because of the unconstrained growth of inter-dependencies
    between these parts.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 单体应用程序由所有紧密耦合在一起的组件组成，必须作为一个整体进行开发、部署和管理，因为它们都作为一个单独的操作系统进程运行。应用程序某一部分的更改需要整个应用程序的重部署，随着时间的推移，部分之间缺乏明确的边界导致复杂性增加，由于这些部分之间相互依赖的无约束增长，整个系统的质量因此恶化。
- en: Running a monolithic application usually requires a small number of powerful
    servers that can provide enough resources for running the application. To deal
    with increasing loads on the system, you then either have to vertically scale
    the servers (also known as scaling up) by adding more CPUs, memory, and other
    server components, or scale the whole system horizontally, by setting up additional
    servers and running multiple copies (or replicas) of an application (scaling out).
    While scaling up usually doesn’t require any changes to the app, it gets expensive
    relatively quickly and in practice always has an upper limit. Scaling out, on
    the other hand, is relatively cheap hardware-wise, but may require big changes
    in the application code and isn’t always possible—certain parts of an application
    are extremely hard or next to impossible to scale horizontally (relational databases,
    for example). If any part of a monolithic application isn’t scalable, the whole
    application becomes unscalable, unless you can split up the monolith somehow.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 运行单体应用程序通常需要少量强大的服务器，这些服务器能够提供足够的资源来运行应用程序。为了应对系统负载的增加，你随后可以选择通过增加CPU、内存和其他服务器组件来垂直扩展服务器（也称为向上扩展），或者通过设置额外的服务器并运行应用程序的多个副本（或副本）来水平扩展整个系统（向外扩展）。虽然向上扩展通常不需要对应用程序进行任何更改，但它相对较快地变得昂贵，并且在实践中总是有一个上限。另一方面，向外扩展在硬件方面相对便宜，但可能需要在应用程序代码中进行重大更改，并且并不总是可行——应用程序的某些部分在水平扩展方面极其困难或几乎不可能（例如关系数据库）。如果单体应用程序的任何部分不可扩展，整个应用程序就变得不可扩展，除非你能以某种方式将其拆分。
- en: Splitting apps into microservices
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用程序拆分为微服务
- en: These and other problems have forced us to start splitting complex monolithic
    applications into smaller independently deployable components called microservices.
    Each microservice runs as an independent process (see [figure 1.1](#filepos130087))
    and communicates with other microservices through simple, well-defined interfaces
    (APIs).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些以及其他问题迫使我们必须开始将复杂的单体应用程序拆分成更小的、可以独立部署的组件，这些组件被称为微服务。每个微服务作为一个独立的过程运行（参见[图1.1](#filepos130087)），并通过简单、定义良好的接口（API）与其他微服务进行通信。
- en: Figure 1.1\. Components inside a monolithic application vs. standalone microservices
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1\. 单体应用程序内部的组件与独立微服务
- en: '![](images/00190.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00190.jpg)'
- en: Microservices communicate through synchronous protocols such as HTTP, over which
    they usually expose RESTful (REpresentational State Transfer) APIs, or through
    asynchronous protocols such as AMQP (Advanced Message Queueing Protocol). These
    protocols are simple, well understood by most developers, and not tied to any
    specific programming language. Each microservice can be written in the language
    that’s most appropriate for implementing that specific microservice.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务通过同步协议（如HTTP）进行通信，通常通过RESTful（表示状态传输）API公开，或者通过异步协议（如AMQP，高级消息队列协议）进行通信。这些协议简单、大多数开发者都理解，并且与任何特定的编程语言无关。每个微服务都可以使用最适合实现该特定微服务的语言编写。
- en: Because each microservice is a standalone process with a relatively static external
    API, it’s possible to develop and deploy each microservice separately. A change
    to one of them doesn’t require changes or redeployment of any other service, provided
    that the API doesn’t change or changes only in a backward-compatible way.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个微服务都是一个具有相对静态外部API的独立进程，因此可以单独开发和部署每个微服务。只要API没有更改或仅以向后兼容的方式进行更改，对其中任何一个的更改就不需要更改或重新部署任何其他服务。
- en: Scaling microservices
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务的扩展
- en: Scaling microservices, unlike monolithic systems, where you need to scale the
    system as a whole, is done on a per-service basis, which means you have the option
    of scaling only those services that require more resources, while leaving others
    at their original scale. [Figure 1.2](#filepos132052) shows an example. Certain
    components are replicated and run as multiple processes deployed on different
    servers, while others run as a single application process. When a monolithic application
    can’t be scaled out because one of its parts is unscalable, splitting the app
    into microservices allows you to horizontally scale the parts that allow scaling
    out, and scale the parts that don’t, vertically instead of horizontally.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与需要整体扩展系统的单体系统不同，微服务的扩展是基于每个服务的，这意味着你可以选择只扩展那些需要更多资源的特定服务，而将其他服务保持在原始规模。[图 1.2](#filepos132052)
    展示了一个示例。某些组件被复制并在不同的服务器上作为多个进程部署，而其他组件则作为一个单一的应用程序进程运行。当一个单体应用程序无法扩展，因为其某个部分不可扩展时，将应用程序拆分为微服务允许你水平扩展允许扩展的部分，而对于不扩展的部分则垂直扩展。
- en: Figure 1.2\. Each microservice can be scaled individually.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2\. 每个微服务都可以单独扩展。
- en: '![](images/00012.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00012.jpg)'
- en: Deploying microservices
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务的部署
- en: As always, microservices also have drawbacks. When your system consists of only
    a small number of deployable components, managing those components is easy. It’s
    trivial to decide where to deploy each component, because there aren’t that many
    choices. When the number of those components increases, deployment-related decisions
    become increasingly difficult because not only does the number of deployment combinations
    increase, but the number of inter-dependencies between the components increases
    by an even greater factor.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，微服务也有其缺点。当你的系统只包含少量可部署的组件时，管理这些组件是容易的。决定每个组件部署位置是微不足道的，因为没有那么多选择。当这些组件的数量增加时，与部署相关的决策变得越来越困难，因为不仅部署组合的数量增加了，而且组件之间的相互依赖关系也以更大的比例增加。
- en: Microservices perform their work together as a team, so they need to find and
    talk to each other. When deploying them, someone or something needs to configure
    all of them properly to enable them to work together as a single system. With
    increasing numbers of microservices, this becomes tedious and error-prone, especially
    when you consider what the ops/sysadmin teams need to do when a server fails.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务作为一个团队一起执行工作，因此它们需要找到彼此并进行通信。在部署它们时，需要有人或某种机制来正确配置所有这些服务，以便它们能够作为一个单一系统协同工作。随着微服务数量的增加，这变得既繁琐又容易出错，尤其是当考虑到当服务器失败时运维/系统管理员团队需要做什么时。
- en: Microservices also bring other problems, such as making it hard to debug and
    trace execution calls, because they span multiple processes and machines. Luckily,
    these problems are now being addressed with distributed tracing systems such as
    Zipkin.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务还带来其他问题，例如使调试和跟踪执行调用变得困难，因为它们跨越多个进程和机器。幸运的是，这些问题现在正在通过分布式跟踪系统如 Zipkin 得到解决。
- en: Understanding the divergence of environment requirements
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 理解环境需求差异
- en: As I’ve already mentioned, components in a microservices architecture aren’t
    only deployed independently, but are also developed that way. Because of their
    independence and the fact that it’s common to have separate teams developing each
    component, nothing impedes each team from using different libraries and replacing
    them whenever the need arises. The divergence of dependencies between application
    components, like the one shown in [figure 1.3](#filepos134352), where applications
    require different versions of the same libraries, is inevitable.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前提到的，微服务架构中的组件不仅独立部署，而且也是这样开发的。由于它们的独立性和通常有单独的团队开发每个组件的事实，没有任何东西阻碍每个团队使用不同的库，并在需要时替换它们。应用程序组件之间的依赖关系差异，如[图
    1.3](#filepos134352) 所示，其中应用程序需要同一库的不同版本，是不可避免的。
- en: Figure 1.3\. Multiple applications running on the same host may have conflicting
    dependencies.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3\. 在同一主机上运行的多应用程序可能会有冲突的依赖关系。
- en: '![](images/00032.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00032.jpg)'
- en: Deploying dynamically linked applications that require different versions of
    shared libraries, and/or require other environment specifics, can quickly become
    a nightmare for the ops team who deploys and manages them on production servers.
    The bigger the number of components you need to deploy on the same host, the harder
    it will be to manage all their dependencies to satisfy all their requirements.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 部署需要不同版本的共享库，以及/或其他环境特定要求的动态链接应用程序，对于在生产服务器上部署和管理它们的运维团队来说，很快就会变成一场噩梦。你需要部署在同一主机上的组件数量越多，管理它们的所有依赖关系以满足所有要求就越困难。
- en: 1.1.2\. Providing a consistent environment to applications
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 1.1.2\. 为应用程序提供一致的环境
- en: Regardless of how many individual components you’re developing and deploying,
    one of the biggest problems that developers and operations teams always have to
    deal with is the differences in the environments they run their apps in. Not only
    is there a huge difference between development and production environments, differences
    even exist between individual production machines. Another unavoidable fact is
    that the environment of a single production machine will change over time.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你正在开发和部署多少个单独的组件，开发和运维团队始终必须处理的一个最大的问题是他们在其中运行应用程序的环境差异。不仅开发和生产环境之间存在巨大差异，个别生产机器之间也存在差异。另一个不可避免的事实是，单个生产机器的环境会随着时间的推移而变化。
- en: These differences range from hardware to the operating system to the libraries
    that are available on each machine. Production environments are managed by the
    operations team, while developers often take care of their development laptops
    on their own. The difference is how much these two groups of people know about
    system administration, and this understandably leads to relatively big differences
    between those two systems, not to mention that system administrators give much
    more emphasis on keeping the system up to date with the latest security patches,
    while a lot of developers don’t care about that as much.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些差异从硬件到操作系统，再到每台机器上可用的库都有所不同。生产环境由运维团队管理，而开发者通常自己负责他们的开发笔记本电脑。差异在于这两组人对系统管理的了解程度，这可以理解地导致这两个系统之间存在相当大的差异，更不用说系统管理员更注重保持系统与最新的安全补丁保持更新，而许多开发者并不那么关心这一点。
- en: Also, production systems can run applications from multiple developers or development
    teams, which isn’t necessarily true for developers’ computers. A production system
    must provide the proper environment to all applications it hosts, even though
    they may require different, even conflicting, versions of libraries.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，生产系统可以运行来自多个开发者或开发团队的应用程序，这对于开发者的计算机来说并不一定是真的。生产系统必须为它所托管的所有应用程序提供适当的环境，即使它们可能需要不同版本，甚至是冲突的库版本。
- en: To reduce the number of problems that only show up in production, it would be
    ideal if applications could run in the exact same environment during development
    and in production so they have the exact same operating system, libraries, system
    configuration, networking environment, and everything else. You also don’t want
    this environment to change too much over time, if at all. Also, if possible, you
    want the ability to add applications to the same server without affecting any
    of the existing applications on that server.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少仅在生产环境中出现的问题数量，如果应用程序在开发和生产过程中能够在完全相同的环境中运行，那么它们将拥有完全相同的操作系统、库、系统配置、网络环境以及所有其他内容，这将是非常理想的。此外，你也不希望这个环境随着时间的推移发生太大的变化，如果可能的话。另外，如果可能的话，你希望有将应用程序添加到同一服务器上的能力，而不会影响该服务器上现有的任何应用程序。
- en: '1.1.3\. Moving to continuous delivery: DevOps and NoOps'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 1.1.3\. 转向持续交付：DevOps 和 NoOps
- en: In the last few years, we’ve also seen a shift in the whole application development
    process and how applications are taken care of in production. In the past, the
    development team’s job was to create the application and hand it off to the operations
    team, who then deployed it, tended to it, and kept it running. But now, organizations
    are realizing it’s better to have the same team that develops the application
    also take part in deploying it and taking care of it over its whole lifetime.
    This means the developer, QA, and operations teams now need to collaborate throughout
    the whole process. This practice is called DevOps.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年里，我们也看到了整个应用程序开发过程以及应用程序在生产中的维护方式的转变。在过去，开发团队的工作是创建应用程序并将其移交给运维团队，然后运维团队负责部署、维护并确保其正常运行。但现在，组织意识到最好让开发应用程序的同一团队也参与部署和维护其整个生命周期。这意味着开发人员、QA和运维团队现在需要在整个过程中进行协作。这种做法被称为DevOps。
- en: Understanding the benefits
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 理解好处
- en: Having the developers more involved in running the application in production
    leads to them having a better understanding of both the users’ needs and issues
    and the problems faced by the ops team while maintaining the app. Application
    developers are now also much more inclined to give users the app earlier and then
    use their feedback to steer further development of the app.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让开发人员更多地参与到应用程序的生产运行中，使他们更好地理解用户的需要和问题，以及运维团队在维护应用程序时面临的问题。现在，应用程序开发人员也更倾向于尽早向用户提供应用程序，并利用他们的反馈来引导应用程序的进一步开发。
- en: To release newer versions of applications more often, you need to streamline
    the deployment process. Ideally, you want developers to deploy the applications
    themselves without having to wait for the ops people. But deploying an application
    often requires an understanding of the underlying infrastructure and the organization
    of the hardware in the datacenter. Developers don’t always know those details
    and, most of the time, don’t even want to know about them.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更频繁地发布应用程序的新版本，你需要简化部署流程。理想情况下，你希望开发人员自己部署应用程序，而无需等待运维人员。但部署应用程序通常需要了解底层基础设施和数据中心的硬件组织结构。开发人员并不总是知道这些细节，而且大多数时候，他们甚至不想了解这些。
- en: Letting developers and sysadmins do what they do best
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让开发人员和系统管理员发挥他们最擅长的
- en: Even though developers and system administrators both work toward achieving
    the same goal of running a successful software application as a service to its
    customers, they have different individual goals and motivating factors. Developers
    love creating new features and improving the user experience. They don’t normally
    want to be the ones making sure that the underlying operating system is up to
    date with all the security patches and things like that. They prefer to leave
    that up to the system administrators.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管开发人员和系统管理员都致力于实现同一个目标，即成功运行软件应用程序作为服务提供给客户，但他们有不同的个人目标和激励因素。开发人员喜欢创建新功能和改进用户体验。他们通常不希望成为确保底层操作系统保持最新状态、所有安全补丁等的人。他们更愿意将这项工作留给系统管理员。
- en: The ops team is in charge of the production deployments and the hardware infrastructure
    they run on. They care about system security, utilization, and other aspects that
    aren’t a high priority for developers. The ops people don’t want to deal with
    the implicit interdependencies of all the application components and don’t want
    to think about how changes to either the underlying operating system or the infrastructure
    can affect the operation of the application as a whole, but they must.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 运维团队负责生产部署以及它们运行的硬件基础设施。他们关心系统安全、利用率和其他对开发人员来说不是高优先级的问题。运维人员不希望处理所有应用程序组件的隐含依赖关系，也不希望考虑底层操作系统或基础设施的更改如何影响应用程序的整体运行，但他们必须这样做。
- en: Ideally, you want the developers to deploy applications themselves without knowing
    anything about the hardware infrastructure and without dealing with the ops team.
    This is referred to as NoOps. Obviously, you still need someone to take care of
    the hardware infrastructure, but ideally, without having to deal with peculiarities
    of each application running on it.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你希望开发人员自己部署应用程序，而不需要了解任何关于硬件基础设施的信息，也不需要与运维团队打交道。这被称为NoOps。显然，你仍然需要有人来维护硬件基础设施，但理想情况下，无需处理运行在其上的每个应用程序的特定问题。
- en: As you’ll see, Kubernetes enables us to achieve all of this. By abstracting
    away the actual hardware and exposing it as a single platform for deploying and
    running apps, it allows developers to configure and deploy their applications
    without any help from the sysadmins and allows the sysadmins to focus on keeping
    the underlying infrastructure up and running, while not having to know anything
    about the actual applications running on top of it.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您将看到的，Kubernetes使我们能够实现所有这些功能。通过抽象化实际硬件并将其作为部署和运行应用程序的单个平台暴露出来，它允许开发者配置和部署他们的应用程序，而无需任何系统管理员的帮助，并允许系统管理员专注于保持底层基础设施的正常运行，而无需了解其上运行的实际应用程序。
- en: 1.2\. Introducing container technologies
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 1.2\. 介绍容器技术
- en: In [section 1.1](index_split_018.html#filepos127270) I presented a non-comprehensive
    list of problems facing today’s development and ops teams. While you have many
    ways of dealing with them, this book will focus on how they’re solved with Kubernetes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1.1节](index_split_018.html#filepos127270)中，我列举了当今开发和运维团队面临的一些问题。虽然您有多种方法来处理这些问题，但本书将专注于它们如何通过Kubernetes得到解决。
- en: Kubernetes uses Linux container technologies to provide isolation of running
    applications, so before we dig into Kubernetes itself, you need to become familiar
    with the basics of containers to understand what Kubernetes does itself, and what
    it offloads to container technologies like Docker or rkt (pronounced “rock-it”).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用Linux容器技术来提供运行应用程序的隔离，因此在我们深入研究Kubernetes本身之前，您需要熟悉容器的基本知识，以了解Kubernetes本身做什么，以及它将哪些任务卸载给容器技术，如Docker或rkt（发音为“rock-it”）。
- en: 1.2.1\. Understanding what containers are
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 1.2.1\. 理解容器是什么
- en: In [section 1.1.1](index_split_018.html#filepos127877) we saw how different
    software components running on the same machine will require different, possibly
    conflicting, versions of dependent libraries or have other different environment
    requirements in general.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1.1.1节](index_split_018.html#filepos127877)中，我们看到了在同一台机器上运行的不同的软件组件将需要不同、可能冲突的依赖库版本，或者通常具有其他不同的环境要求。
- en: When an application is composed of only smaller numbers of large components,
    it’s completely acceptable to give a dedicated Virtual Machine (VM) to each component
    and isolate their environments by providing each of them with their own operating
    system instance. But when these components start getting smaller and their numbers
    start to grow, you can’t give each of them their own VM if you don’t want to waste
    hardware resources and keep your hardware costs down. But it’s not only about
    wasting hardware resources. Because each VM usually needs to be configured and
    managed individually, rising numbers of VMs also lead to wasting human resources,
    because they increase the system administrators’ workload considerably.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个应用程序仅由少量大型组件组成时，为每个组件分配一个专用的虚拟机（VM）并为他们各自提供操作系统实例来隔离其环境是完全可接受的。但当这些组件开始变小且数量开始增加时，如果您不想浪费硬件资源并保持硬件成本较低，您就不能为每个组件分配自己的虚拟机。但这不仅仅是关于浪费硬件资源。因为每个虚拟机通常都需要单独配置和管理，虚拟机数量的增加也会导致人力资源的浪费，因为它们大大增加了系统管理员的负担。
- en: Isolating components with Linux container technologies
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Linux容器技术隔离组件
- en: Instead of using virtual machines to isolate the environments of each microservice
    (or software processes in general), developers are turning to Linux container
    technologies. They allow you to run multiple services on the same host machine,
    while not only exposing a different environment to each of them, but also isolating
    them from each other, similarly to VMs, but with much less overhead.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与使用虚拟机来隔离每个微服务（或一般软件流程）的环境相比，开发者正在转向Linux容器技术。它们允许您在同一台主机机器上运行多个服务，不仅为每个服务提供不同的环境，而且将它们彼此隔离，类似于虚拟机，但开销要小得多。
- en: A process running in a container runs inside the host’s operating system, like
    all the other processes (unlike VMs, where processes run in separate operating
    systems). But the process in the container is still isolated from other processes.
    To the process itself, it looks like it’s the only one running on the machine
    and in its operating system.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器中运行的过程是在宿主操作系统中运行的，就像所有其他进程一样（与虚拟机不同，虚拟机中的进程在单独的操作系统中运行）。但容器中的进程仍然与其他进程隔离。对于进程本身来说，它看起来就像它是这台机器和其操作系统中唯一运行的进程。
- en: Comparing virtual machines to containers
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 比较虚拟机与容器
- en: Compared to VMs, containers are much more lightweight, which allows you to run
    higher numbers of software components on the same hardware, mainly because each
    VM needs to run its own set of system processes, which requires additional compute
    resources in addition to those consumed by the component’s own process. A container,
    on the other hand, is nothing more than a single isolated process running in the
    host OS, consuming only the resources that the app consumes and without the overhead
    of any additional processes.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 与虚拟机相比，容器要轻量得多，这使得你可以在相同的硬件上运行更多的软件组件，主要是因为每个虚拟机都需要运行自己的系统进程集，这需要额外的计算资源，除了组件自身进程消耗的资源之外。另一方面，容器不过是在宿主操作系统上运行的单个隔离进程，仅消耗应用程序消耗的资源，而不需要任何额外进程的开销。
- en: Because of the overhead of VMs, you often end up grouping multiple applications
    into each VM because you don’t have enough resources to dedicate a whole VM to
    each app. When using containers, you can (and should) have one container for each
    application, as shown in [figure 1.4](#filepos145005). The end-result is that
    you can fit many more applications on the same bare-metal machine.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于虚拟机的开销，你通常会将多个应用程序组合到每个虚拟机中，因为你没有足够的资源为每个应用程序分配整个虚拟机。当使用容器时，你可以（并且应该）为每个应用程序使用一个容器，如图[图
    1.4](#filepos145005)所示。最终结果是，你可以在同一裸机机器上容纳更多的应用程序。
- en: Figure 1.4\. Using VMs to isolate groups of applications vs. isolating individual
    apps with containers
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4\. 使用虚拟机隔离应用程序组与使用容器隔离单个应用程序
- en: '![](images/00052.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00052.jpg)'
- en: When you run three VMs on a host, you have three completely separate operating
    systems running on and sharing the same bare-metal hardware. Underneath those
    VMs is the host’s OS and a hypervisor, which divides the physical hardware resources
    into smaller sets of virtual resources that can be used by the operating system
    inside each VM. Applications running inside those VMs perform system calls to
    the guest OS’ kernel in the VM, and the kernel then performs x86 instructions
    on the host’s physical CPU through the hypervisor.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在主机上运行三个虚拟机时，有三个完全独立的操作系统在相同的裸机硬件上运行和共享。在这些虚拟机下面是宿主操作系统和一个虚拟机管理程序，它将物理硬件资源划分为更小的虚拟资源集，这些资源可以被每个虚拟机内部的操作系统使用。在那些虚拟机内部运行的应用程序会对虚拟机中的客户操作系统内核执行系统调用，然后内核通过虚拟机管理程序在宿主物理
    CPU 上执行 x86 指令。
- en: '|  |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Note
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Two types of hypervisors exist. Type 1 hypervisors don’t use a host OS, while
    Type 2 do.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 存在两种类型的虚拟机管理程序。类型 1 虚拟机管理程序不使用宿主操作系统，而类型 2 则使用。
- en: '|  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Containers, on the other hand, all perform system calls on the exact same kernel
    running in the host OS. This single kernel is the only one performing x86 instructions
    on the host’s CPU. The CPU doesn’t need to do any kind of virtualization the way
    it does with VMs (see [figure 1.5](#filepos146541)).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，容器都在宿主操作系统运行的相同内核上执行系统调用。这个单一的内核是唯一在宿主 CPU 上执行 x86 指令的内核。CPU 不需要像虚拟机那样进行任何类型的虚拟化（见[图
    1.5](#filepos146541)）。
- en: Figure 1.5\. The difference between how apps in VMs use the CPU vs. how they
    use them in containers
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5\. 虚拟机中的应用程序使用 CPU 的方式与容器中应用程序使用 CPU 的方式的区别
- en: '![](images/00107.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00107.jpg)'
- en: The main benefit of virtual machines is the full isolation they provide, because
    each VM runs its own Linux kernel, while containers all call out to the same kernel,
    which can clearly pose a security risk. If you have a limited amount of hardware
    resources, VMs may only be an option when you have a small number of processes
    that you want to isolate. To run greater numbers of isolated processes on the
    same machine, containers are a much better choice because of their low overhead.
    Remember, each VM runs its own set of system services, while containers don’t,
    because they all run in the same OS. That also means that to run a container,
    nothing needs to be booted up, as is the case in VMs. A process run in a container
    starts up immediately.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机的主要优势是它们提供的完全隔离，因为每个虚拟机都运行自己的 Linux 内核，而容器都调用相同的内核，这显然可能构成安全风险。如果你硬件资源有限，当需要隔离少量进程时，虚拟机可能是一个选择。要在一个机器上运行更多数量的隔离进程，容器由于它们的低开销，是一个更好的选择。记住，每个虚拟机都运行自己的系统服务集，而容器则不需要，因为它们都在同一个操作系统上运行。这也意味着运行容器时，不需要像虚拟机那样启动任何东西。在容器中运行的进程会立即启动。
- en: Introducing the mechanisms that make container isolation possible
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 介绍使容器隔离成为可能机制
- en: By this point, you’re probably wondering how exactly containers can isolate
    processes if they’re running on the same operating system. Two mechanisms make
    this possible. The first one, Linux Namespaces, makes sure each process sees its
    own personal view of the system (files, processes, network interfaces, hostname,
    and so on). The second one is Linux Control Groups (cgroups), which limit the
    amount of resources the process can consume (CPU, memory, network bandwidth, and
    so on).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能想知道容器如何在同一操作系统中运行时如何精确地隔离进程。两种机制使得这一点成为可能。第一种是Linux命名空间（Linux Namespaces），确保每个进程看到自己的系统视图（文件、进程、网络接口、主机名等）。第二种是Linux控制组（cgroups），它限制了进程可以消耗的资源量（CPU、内存、网络带宽等）。
- en: Isolating processes with Linux Namespaces
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Linux命名空间隔离进程
- en: By default, each Linux system initially has one single namespace. All system
    resources, such as filesystems, process IDs, user IDs, network interfaces, and
    others, belong to the single namespace. But you can create additional namespaces
    and organize resources across them. When running a process, you run it inside
    one of those namespaces. The process will only see resources that are inside the
    same namespace. Well, multiple kinds of namespaces exist, so a process doesn’t
    belong to one namespace, but to one namespace of each kind.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，每个Linux系统最初只有一个命名空间。所有系统资源，如文件系统、进程ID、用户ID、网络接口等，都属于单个命名空间。但你可以创建额外的命名空间并在它们之间组织资源。当运行一个进程时，你将在其中一个命名空间内运行它。进程将只能看到同一命名空间内的资源。嗯，存在多种命名空间，所以一个进程不属于一个命名空间，而是属于每种类型的命名空间。
- en: 'The following kinds of namespaces exist:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 存在以下类型的命名空间：
- en: Mount (mnt)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挂载（mnt）
- en: Process ID (pid)
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程ID（pid）
- en: Network (net)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络（net）
- en: Inter-process communication (ipc)
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程间通信（ipc）
- en: UTS
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: UTS
- en: User ID (user)
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户ID（user）
- en: Each namespace kind is used to isolate a certain group of resources. For example,
    the UTS namespace determines what hostname and domain name the process running
    inside that namespace sees. By assigning two different UTS namespaces to a pair
    of processes, you can make them see different local hostnames. In other words,
    to the two processes, it will appear as though they are running on two different
    machines (at least as far as the hostname is concerned).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 每种类型的命名空间用于隔离一组特定的资源。例如，UTS命名空间决定了运行在该命名空间内的进程可以看到的主机名和域名。通过将两个不同的UTS命名空间分配给一对进程，你可以使它们看到不同的本地主机名。换句话说，对于这两个进程来说，它们似乎在不同的机器上运行（至少在主机名方面是这样）。
- en: Likewise, what Network namespace a process belongs to determines which network
    interfaces the application running inside the process sees. Each network interface
    belongs to exactly one namespace, but can be moved from one namespace to another.
    Each container uses its own Network namespace, and therefore each container sees
    its own set of network interfaces.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，进程所属的网络命名空间决定了运行在该进程内的应用程序可以看到哪些网络接口。每个网络接口属于恰好一个命名空间，但可以从一个命名空间移动到另一个命名空间。每个容器使用自己的网络命名空间，因此每个容器都看到自己的网络接口集。
- en: This should give you a basic idea of how namespaces are used to isolate applications
    running in containers from each other.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该能给你一个基本的概念，了解命名空间是如何用来隔离容器中运行的应用程序的。
- en: Limiting resources available to a process
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 限制进程可用的资源
- en: The other half of container isolation deals with limiting the amount of system
    resources a container can consume. This is achieved with cgroups, a Linux kernel
    feature that limits the resource usage of a process (or a group of processes).
    A process can’t use more than the configured amount of CPU, memory, network bandwidth,
    and so on. This way, processes cannot hog resources reserved for other processes,
    which is similar to when each process runs on a separate machine.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 容器隔离的另一部分是限制容器可以消耗的系统资源量。这是通过cgroups实现的，它是Linux内核的一个功能，可以限制进程（或一组进程）的资源使用。进程不能使用超过配置的CPU、内存、网络带宽等资源量。这样，进程就不能占用为其他进程保留的资源，这类似于每个进程都在单独的机器上运行。
- en: 1.2.2\. Introducing the Docker container platform
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 1.2.2. 介绍Docker容器平台
- en: While container technologies have been around for a long time, they’ve become
    more widely known with the rise of the Docker container platform. Docker was the
    first container system that made containers easily portable across different machines.
    It simplified the process of packaging up not only the application but also all
    its libraries and other dependencies, even the whole OS file system, into a simple,
    portable package that can be used to provision the application to any other machine
    running Docker.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管容器技术已经存在很长时间了，但随着Docker容器平台的兴起，它们变得更加广为人知。Docker是第一个使容器能够在不同机器之间轻松便携的容器系统。它简化了打包应用程序的过程，不仅包括应用程序，还包括所有库和其他依赖项，甚至包括整个操作系统文件系统，使其成为一个简单、便携的包，可用于将应用程序部署到任何运行Docker的其他机器上。
- en: When you run an application packaged with Docker, it sees the exact filesystem
    contents that you’ve bundled with it. It sees the same files whether it’s running
    on your development machine or a production machine, even if it the production
    server is running a completely different Linux OS. The application won’t see anything
    from the server it’s running on, so it doesn’t matter if the server has a completely
    different set of installed libraries compared to your development machine.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行一个用Docker打包的应用程序时，它会看到你与之捆绑的确切文件系统内容。无论它是在你的开发机器上运行还是在生产机器上运行，它都会看到相同的文件，即使生产服务器运行的是完全不同的Linux操作系统。应用程序不会看到它运行的服务器上的任何内容，因此如果服务器安装的库与你的开发机器完全不同，这并不重要。
- en: For example, if you’ve packaged up your application with the files of the whole
    Red Hat Enterprise Linux (RHEL) operating system, the application will believe
    it’s running inside RHEL, both when you run it on your development computer that
    runs Fedora and when you run it on a server running Debian or some other Linux
    distribution. Only the kernel may be different.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你已经将应用程序与整个Red Hat Enterprise Linux (RHEL)操作系统的文件打包在一起，那么当你在运行Fedora的开发计算机上运行它，或者在运行Debian或其他Linux发行版的服务器上运行它时，应用程序都会相信它是在RHEL内部运行的。唯一可能不同的是内核。
- en: This is similar to creating a VM image by installing an operating system into
    a VM, installing the app inside it, and then distributing the whole VM image around
    and running it. Docker achieves the same effect, but instead of using VMs to achieve
    app isolation, it uses Linux container technologies mentioned in the previous
    section to provide (almost) the same level of isolation that VMs do. Instead of
    using big monolithic VM images, it uses container images, which are usually smaller.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于通过在虚拟机中安装操作系统来创建VM镜像，然后在其中安装应用程序，并将整个VM镜像分发并运行。Docker实现了相同的效果，但它不是使用VM来实现应用程序隔离，而是使用上一节中提到的Linux容器技术来提供（几乎）与VM相同的隔离级别。它不是使用庞大的单体VM镜像，而是使用容器镜像，这些镜像通常更小。
- en: A big difference between Docker-based container images and VM images is that
    container images are composed of layers, which can be shared and reused across
    multiple images. This means only certain layers of an image need to be downloaded
    if the other layers were already downloaded previously when running a different
    container image that also contains the same layers.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Docker容器镜像与VM镜像之间的一大区别是，容器镜像由层组成，这些层可以在多个镜像之间共享和重用。这意味着如果之前在运行包含相同层的不同容器镜像时已经下载了其他层，则只需要下载该镜像的某些层。
- en: Understanding Docker concepts
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 理解Docker概念
- en: Docker is a platform for packaging, distributing, and running applications.
    As we’ve already stated, it allows you to package your application together with
    its whole environment. This can be either a few libraries that the app requires
    or even all the files that are usually available on the filesystem of an installed
    operating system. Docker makes it possible to transfer this package to a central
    repository from which it can then be transferred to any computer running Docker
    and executed there (for the most part, but not always, as we’ll soon explain).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Docker是一个用于打包、分发和运行应用程序的平台。正如我们之前所述，它允许你将应用程序及其整个环境打包在一起。这可以是应用程序所需的几个库，甚至是通常在已安装操作系统的文件系统上可用的所有文件。Docker使得将此包传输到中央存储库成为可能，然后可以从该存储库将其传输到任何运行Docker的计算机上，并在那里执行（大多数情况下是这样，但并非总是如此，我们很快会解释）。
- en: 'Three main concepts in Docker comprise this scenario:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Docker中的三个主要概念构成了这个场景：
- en: Images—A Docker-based container image is something you package your application
    and its environment into. It contains the filesystem that will be available to
    the application and other metadata, such as the path to the executable that should
    be executed when the image is run.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镜像——基于 Docker 的容器镜像是将您的应用程序及其环境打包进的东西。它包含将可供应用程序和其他元数据使用的文件系统，例如，当运行镜像时应执行的可执行文件路径。
- en: Registries—A Docker Registry is a repository that stores your Docker images
    and facilitates easy sharing of those images between different people and computers.
    When you build your image, you can either run it on the computer you’ve built
    it on, or you can push (upload) the image to a registry and then pull (download)
    it on another computer and run it there. Certain registries are public, allowing
    anyone to pull images from it, while others are private, only accessible to certain
    people or machines.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注册表——Docker 注册表是一个存储您的 Docker 镜像并便于不同人之间和计算机之间共享这些镜像的仓库。当您构建镜像时，您可以在构建它的计算机上运行它，或者将镜像推送到注册表，然后在另一台计算机上拉取（下载）它并运行。某些注册表是公开的，允许任何人从中拉取镜像，而另一些则是私有的，只有某些人或机器可以访问。
- en: Containers—A Docker-based container is a regular Linux container created from
    a Docker-based container image. A running container is a process running on the
    host running Docker, but it’s completely isolated from both the host and all other
    processes running on it. The process is also resource-constrained, meaning it
    can only access and use the amount of resources (CPU, RAM, and so on) that are
    allocated to it.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器——基于 Docker 的容器是从基于 Docker 的容器镜像创建的常规 Linux 容器。运行中的容器是在运行 Docker 的主机上运行的进程，但它与主机以及所有其他在其上运行的进程完全隔离。该进程也受到资源限制，这意味着它只能访问和使用分配给它的资源（CPU、RAM
    等）。
- en: Building, distributing, and running a Docker image
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 构建、分发和运行 Docker 镜像
- en: '[Figure 1.6](#filepos156318) shows all three concepts and how they relate to
    each other. The developer first builds an image and then pushes it to a registry.
    The image is thus available to anyone who can access the registry. They can then
    pull the image to any other machine running Docker and run the image. Docker creates
    an isolated container based on the image and runs the binary executable specified
    as part of the image.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1.6](#filepos156318) 展示了这三个概念以及它们之间的关系。开发者首先构建一个镜像，然后将其推送到注册表。因此，任何可以访问注册表的人都可以使用该镜像。然后，他们可以将镜像拉取到任何运行
    Docker 的其他机器上并运行它。Docker 基于该镜像创建一个隔离的容器，并运行作为镜像一部分指定的二进制可执行文件。'
- en: Figure 1.6\. Docker images, registries, and containers
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6\. Docker 镜像、注册表和容器
- en: '![](images/00127.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00127.jpg)'
- en: Comparing virtual machines and Docker containers
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 比较虚拟机和 Docker 容器
- en: I’ve explained how Linux containers are generally like virtual machines, but
    much more lightweight. Now let’s look at how Docker containers specifically compare
    to virtual machines (and how Docker images compare to VM images). [Figure 1.7](#filepos157036)
    again shows the same six applications running both in VMs and as Docker containers.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经解释了 Linux 容器通常与虚拟机相似，但更轻量。现在让我们看看 Docker 容器具体是如何与虚拟机（以及 Docker 镜像与 VM 镜像）相比的。[图
    1.7](#filepos157036) 再次显示了相同的六个应用程序在虚拟机和 Docker 容器中同时运行。
- en: Figure 1.7\. Running six apps on three VMs vs. running them in Docker containers
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7\. 在三个虚拟机上运行六个应用程序与在 Docker 容器中运行它们的比较
- en: '![](images/00145.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00145.jpg)'
- en: You’ll notice that apps A and B have access to the same binaries and libraries
    both when running in a VM and when running as two separate containers. In the
    VM, this is obvious, because both apps see the same filesystem (that of the VM).
    But we said that each container has its own isolated filesystem. How can both
    app A and app B share the same files?
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到，当在虚拟机中运行以及作为两个独立的容器运行时，应用程序 A 和 B 都可以访问相同的二进制文件和库。在虚拟机中，这是显而易见的，因为两个应用程序都看到相同的文件系统（虚拟机的文件系统）。但我们说过每个容器都有自己的隔离文件系统。应用程序
    A 和应用程序 B 如何共享相同的文件？
- en: Understanding image layers
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 理解镜像层
- en: I’ve already said that Docker images are composed of layers. Different images
    can contain the exact same layers because every Docker image is built on top of
    another image and two different images can both use the same parent image as their
    base. This speeds up the distribution of images across the network, because layers
    that have already been transferred as part of the first image don’t need to be
    transferred again when transferring the other image.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经说过，Docker镜像由层组成。不同的镜像可以包含完全相同的层，因为每个Docker镜像都是建立在另一个镜像之上的，并且两个不同的镜像都可以使用相同的父镜像作为其基础。这加快了图像在网络上的分发，因为作为第一个图像的一部分已经传输的层在传输其他图像时不需要再次传输。
- en: But layers don’t only make distribution more efficient, they also help reduce
    the storage footprint of images. Each layer is only stored once. Two containers
    created from two images based on the same base layers can therefore read the same
    files, but if one of them writes over those files, the other one doesn’t see those
    changes. Therefore, even if they share files, they’re still isolated from each
    other. This works because container image layers are read-only. When a container
    is run, a new writable layer is created on top of the layers in the image. When
    the process in the container writes to a file located in one of the underlying
    layers, a copy of the whole file is created in the top-most layer and the process
    writes to the copy.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 但层不仅使分发更高效，还有助于减少镜像的存储占用。每个层只存储一次。因此，从基于相同基础层的两个镜像创建的两个容器可以读取相同的文件，但如果其中一个覆盖了这些文件，另一个则看不到这些更改。因此，即使它们共享文件，它们之间仍然是隔离的。这是因为容器镜像层是只读的。当容器运行时，在镜像的层之上创建一个新的可写层。当容器中的进程向位于底层之一的文件写入时，在顶层创建整个文件的副本，并且进程向副本写入。
- en: Understanding the portability limitations of container images
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 理解容器镜像的可移植性限制
- en: In theory, a container image can be run on any Linux machine running Docker,
    but one small caveat exists—one related to the fact that all containers running
    on a host use the host’s Linux kernel. If a containerized application requires
    a specific kernel version, it may not work on every machine. If a machine runs
    a different version of the Linux kernel or doesn’t have the same kernel modules
    available, the app can’t run on it.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，容器镜像可以在运行Docker的任何Linux机器上运行，但存在一个小小的限制——与所有容器都在主机上使用主机的Linux内核这一事实相关。如果一个容器化应用程序需要特定的内核版本，它可能不会在每台机器上运行。如果机器运行的是不同的Linux内核版本或没有相同的内核模块可用，该应用程序就不能在该机器上运行。
- en: While containers are much more lightweight compared to VMs, they impose certain
    constraints on the apps running inside them. VMs have no such constraints, because
    each VM runs its own kernel.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 与虚拟机相比，容器要轻量得多，但它们对容器内运行的应用程序施加了某些限制。虚拟机没有这样的限制，因为每个虚拟机都运行自己的内核。
- en: And it’s not only about the kernel. It should also be clear that a containerized
    app built for a specific hardware architecture can only run on other machines
    that have the same architecture. You can’t containerize an application built for
    the x86 architecture and expect it to run on an ARM-based machine because it also
    runs Docker. You still need a VM for that.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅关乎内核。还应该明确，为特定硬件架构构建的容器化应用程序只能在具有相同架构的其他机器上运行。你不能将针对x86架构构建的应用程序容器化并期望它在基于ARM的机器上运行，因为这也运行Docker。你仍然需要虚拟机来做到这一点。
- en: 1.2.3\. Introducing rkt—an alternative to Docker
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 1.2.3\. 介绍rkt——Docker的替代品
- en: Docker was the first container platform that made containers mainstream. I hope
    I’ve made it clear that Docker itself doesn’t provide process isolation. The actual
    isolation of containers is done at the Linux kernel level using kernel features
    such as Linux Namespaces and cgroups. Docker only makes it easy to use those features.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Docker是第一个使容器主流化的容器平台。我希望我已经清楚地说明，Docker本身并不提供进程隔离。容器的实际隔离是在Linux内核级别通过使用如Linux
    Namespaces和cgroups等内核功能来实现的。Docker只是使这些功能更容易使用。
- en: After the success of Docker, the Open Container Initiative (OCI) was born to
    create open industry standards around container formats and runtime. Docker is
    part of that initiative, as is rkt (pronounced “rock-it”), which is another Linux
    container engine.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在Docker成功之后，开放容器倡议（OCI）诞生，旨在围绕容器格式和运行时创建开放行业标准。Docker是这一倡议的一部分，rkt（发音为“rock-it”）也是，它是另一个Linux容器引擎。
- en: Like Docker, rkt is a platform for running containers. It puts a strong emphasis
    on security, composability, and conforming to open standards. It uses the OCI
    container image format and can even run regular Docker container images.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Docker 类似，rkt 是一个运行容器的平台。它非常重视安全性、可组合性和符合开放标准。它使用 OCI 容器镜像格式，甚至可以运行常规的 Docker
    容器镜像。
- en: This book focuses on using Docker as the container runtime for Kubernetes, because
    it was initially the only one supported by Kubernetes. Recently, Kubernetes has
    also started supporting rkt, as well as others, as the container runtime.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 本书侧重于使用 Docker 作为 Kubernetes 的容器运行时，因为它是 Kubernetes 初始支持的唯一一种。最近，Kubernetes
    也开始支持 rkt，以及其他容器运行时。
- en: The reason I mention rkt at this point is so you don’t make the mistake of thinking
    Kubernetes is a container orchestration system made specifically for Docker-based
    containers. In fact, over the course of this book, you’ll realize that the essence
    of Kubernetes isn’t orchestrating containers. It’s much more. Containers happen
    to be the best way to run apps on different cluster nodes. With that in mind,
    let’s finally dive into the core of what this book is all about—Kubernetes.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里提到 rkt 的原因是为了防止你犯这样一个错误：认为 Kubernetes 是一个专门为基于 Docker 的容器设计的容器编排系统。实际上，在本书的整个过程中，你会发现
    Kubernetes 的本质并不是编排容器。它要复杂得多。容器恰好是运行在不同集群节点上的最佳方式。考虑到这一点，让我们最终深入探讨本书的核心内容——Kubernetes。
- en: 1.3\. Introducing Kubernetes
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 1.3\. 介绍 Kubernetes
- en: We’ve already shown that as the number of deployable application components
    in your system grows, it becomes harder to manage them all. Google was probably
    the first company that realized it needed a much better way of deploying and managing
    their software components and their infrastructure to scale globally. It’s one
    of only a few companies in the world that runs hundreds of thousands of servers
    and has had to deal with managing deployments on such a massive scale. This has
    forced them to develop solutions for making the development and deployment of
    thousands of software components manageable and cost-efficient.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经展示了随着你的系统中可部署的应用程序组件数量的增加，管理它们变得越来越困难。谷歌可能是第一家意识到它需要一种更好的方式来部署和管理其软件组件及其基础设施以实现全球扩展的公司。它是世界上为数不多的运行数十万台服务器并不得不处理如此大规模部署管理的公司之一。这迫使他们开发解决方案，以使成千上万的软件组件的开发和部署变得可管理且成本效益高。
- en: 1.3.1\. Understanding its origins
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 1.3.1\. 了解其起源
- en: Through the years, Google developed an internal system called Borg (and later
    a new system called Omega), that helped both application developers and system
    administrators manage those thousands of applications and services. In addition
    to simplifying the development and management, it also helped them achieve a much
    higher utilization of their infrastructure, which is important when your organization
    is that large. When you run hundreds of thousands of machines, even tiny improvements
    in utilization mean savings in the millions of dollars, so the incentives for
    developing such a system are clear.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 经过多年的发展，谷歌开发了一个内部系统，称为 Borg（后来又开发了一个新的系统，称为 Omega），该系统帮助应用程序开发者和系统管理员管理那些成千上万的应用程序和服务。除了简化开发和管理工作外，它还帮助他们实现了基础设施的高效利用，这对于组织规模很大时尤为重要。当你运行数十万台机器时，即使是利用率的微小提升也能带来数百万美元的节省，因此开发这样一个系统的激励措施是显而易见的。
- en: After having kept Borg and Omega secret for a whole decade, in 2014 Google introduced
    Kubernetes, an open-source system based on the experience gained through Borg,
    Omega, and other internal Google systems.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在将 Borg 和 Omega 保密整整十年之后，2014 年谷歌推出了 Kubernetes，这是一个基于 Borg、Omega 和其他内部谷歌系统经验积累的开源系统。
- en: 1.3.2\. Looking at Kubernetes from the top of a mountain
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 1.3.2\. 从山顶俯瞰 Kubernetes
- en: Kubernetes is a software system that allows you to easily deploy and manage
    containerized applications on top of it. It relies on the features of Linux containers
    to run heterogeneous applications without having to know any internal details
    of these applications and without having to manually deploy these applications
    on each host. Because these apps run in containers, they don’t affect other apps
    running on the same server, which is critical when you run applications for completely
    different organizations on the same hardware. This is of paramount importance
    for cloud providers, because they strive for the best possible utilization of
    their hardware while still having to maintain complete isolation of hosted applications.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个软件系统，它允许你轻松地在它之上部署和管理容器化应用。它依赖于 Linux 容器的特性，以运行异构应用，而无需了解这些应用的任何内部细节，也无需在每个主机上手动部署这些应用。因为这些应用在容器中运行，所以它们不会影响同一服务器上运行的其他应用，这在运行针对完全不同组织的应用时至关重要。这对云服务提供商来说至关重要，因为他们力求最大限度地利用其硬件，同时仍需保持托管应用之间的完全隔离。
- en: Kubernetes enables you to run your software applications on thousands of computer
    nodes as if all those nodes were a single, enormous computer. It abstracts away
    the underlying infrastructure and, by doing so, simplifies development, deployment,
    and management for both development and the operations teams.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 允许你在数千个计算机节点上运行你的软件应用，就像所有这些节点都是一个单一、巨大的计算机一样。它抽象出底层基础设施，通过这样做，简化了开发和运维团队的开发、部署和管理。
- en: Deploying applications through Kubernetes is always the same, whether your cluster
    contains only a couple of nodes or thousands of them. The size of the cluster
    makes no difference at all. Additional cluster nodes simply represent an additional
    amount of resources available to deployed apps.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你的集群只包含几个节点还是数千个节点，通过 Kubernetes 部署应用总是相同的。集群的大小根本无关紧要。额外的集群节点仅仅代表了可供部署应用使用的额外资源量。
- en: Understanding the core of what Kubernetes does
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 的核心功能
- en: '[Figure 1.8](#filepos165918) shows the simplest possible view of a Kubernetes
    system. The system is composed of a master node and any number of worker nodes.
    When the developer submits a list of apps to the master, Kubernetes deploys them
    to the cluster of worker nodes. What node a component lands on doesn’t (and shouldn’t)
    matter—neither to the developer nor to the system administrator.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.8](#filepos165918) 展示了 Kubernetes 系统最简单的视图。该系统由一个主节点和任意数量的工作节点组成。当开发者向主节点提交应用列表时，Kubernetes
    将它们部署到工作节点集群中。组件最终落在哪个节点上（并且不应该）并不重要——无论是对于开发者还是系统管理员来说。'
- en: Figure 1.8\. Kubernetes exposes the whole datacenter as a single deployment
    platform.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8\. Kubernetes 将整个数据中心暴露为单个部署平台。
- en: '![](images/01fig08_alt.jpeg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](images/01fig08_alt.jpeg)'
- en: The developer can specify that certain apps must run together and Kubernetes
    will deploy them on the same worker node. Others will be spread around the cluster,
    but they can talk to each other in the same way, regardless of where they’re deployed.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者可以指定某些应用必须一起运行，Kubernetes 将它们部署在同一个工作节点上。其他应用将被分散在集群中，但它们可以以相同的方式相互通信，无论它们部署在哪里。
- en: Helping developers focus on the core app features
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 帮助开发者专注于核心应用功能
- en: Kubernetes can be thought of as an operating system for the cluster. It relieves
    application developers from having to implement certain infrastructure-related
    services into their apps; instead they rely on Kubernetes to provide these services.
    This includes things such as service discovery, scaling, load-balancing, self-healing,
    and even leader election. Application developers can therefore focus on implementing
    the actual features of the applications and not waste time figuring out how to
    integrate them with the infrastructure.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将 Kubernetes 视为集群的操作系统。它使应用开发者从将某些基础设施相关服务实现到他们的应用中解脱出来；相反，他们依赖 Kubernetes
    提供这些服务。这包括服务发现、扩展、负载均衡、自我修复甚至领导者选举。因此，应用开发者可以专注于实现应用的真正功能，而无需浪费时间考虑如何将它们与基础设施集成。
- en: Helping ops teams achieve better resource utilization
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 帮助运维团队实现更好的资源利用率
- en: Kubernetes will run your containerized app somewhere in the cluster, provide
    information to its components on how to find each other, and keep all of them
    running. Because your application doesn’t care which node it’s running on, Kubernetes
    can relocate the app at any time, and by mixing and matching apps, achieve far
    better resource utilization than is possible with manual scheduling.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes将在集群的某个位置运行您的容器化应用，向其组件提供信息以了解如何找到彼此，并保持所有组件的运行。因为您的应用不关心它运行在哪个节点上，所以Kubernetes可以在任何时候重新定位应用，并通过混合匹配应用，实现比手动调度更好的资源利用率。
- en: 1.3.3\. Understanding the architecture of a Kubernetes cluster
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 1.3.3.理解Kubernetes集群的架构
- en: 'We’ve seen a bird’s-eye view of Kubernetes’ architecture. Now let’s take a
    closer look at what a Kubernetes cluster is composed of. At the hardware level,
    a Kubernetes cluster is composed of many nodes, which can be split into two types:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了Kubernetes架构的全貌。现在让我们更详细地看看Kubernetes集群是由什么组成的。在硬件层面，Kubernetes集群由许多节点组成，这些节点可以分为两种类型：
- en: The master node, which hosts the Kubernetes Control Plane that controls and
    manages the whole Kubernetes system
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主节点，它托管Kubernetes控制平面，该平面控制和管理工作整个Kubernetes系统
- en: Worker nodes that run the actual applications you deploy
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行您部署的实际应用的Worker节点
- en: '[Figure 1.9](#filepos168553) shows the components running on these two sets
    of nodes. I’ll explain them next.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1.9](#filepos168553)显示了在这些两组节点上运行的组件。我将在下面解释它们。'
- en: Figure 1.9\. The components that make up a Kubernetes cluster
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9。组成Kubernetes集群的组件
- en: '![](images/00181.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00181.jpg)'
- en: The Control Plane
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面
- en: The Control Plane is what controls the cluster and makes it function. It consists
    of multiple components that can run on a single master node or be split across
    multiple nodes and replicated to ensure high availability. These components are
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面是控制集群并使其运行的部分。它由多个组件组成，这些组件可以运行在单个主节点上，也可以跨多个节点分割并复制以确保高可用性。这些组件包括
- en: The Kubernetes API Server, which you and the other Control Plane components
    communicate with
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes API服务器，您和其他控制平面组件与之通信
- en: The Scheduler, which schedules your apps (assigns a worker node to each deployable
    component of your application)
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度器，它调度您的应用（为您的应用的每个可部署组件分配一个Worker节点）
- en: The Controller Manager, which performs cluster-level functions, such as replicating
    components, keeping track of worker nodes, handling node failures, and so on
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器管理器，它执行集群级别的功能，例如复制组件、跟踪Worker节点、处理节点故障等
- en: etcd, a reliable distributed data store that persistently stores the cluster
    configuration.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: etcd，一个可靠的分布式数据存储，用于持久化存储集群配置。
- en: The components of the Control Plane hold and control the state of the cluster,
    but they don’t run your applications. This is done by the (worker) nodes.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 控制平面的组件持有并控制集群的状态，但它们不运行您的应用。这项工作由（Worker）节点来完成。
- en: The nodes
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 节点
- en: 'The worker nodes are the machines that run your containerized applications.
    The task of running, monitoring, and providing services to your applications is
    done by the following components:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Worker节点是运行您的容器化应用的机器。运行、监控和为您的应用提供服务的工作由以下组件完成：
- en: Docker, rkt, or another container runtime, which runs your containers
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker、rkt或另一个容器运行时，它运行您的容器
- en: The Kubelet, which talks to the API server and manages containers on its node
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubelet，它与API服务器通信并管理其节点上的容器
- en: The Kubernetes Service Proxy (kube-proxy), which load-balances network traffic
    between application components
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes服务代理（kube-proxy），它在应用组件之间进行网络流量负载均衡
- en: We’ll explain all these components in detail in [chapter 11](index_split_087.html#filepos1036287).
    I’m not a fan of explaining how things work before first explaining what something
    does and teaching people to use it. It’s like learning to drive a car. You don’t
    want to know what’s under the hood. You first want to learn how to drive it from
    point A to point B. Only after you learn how to do that do you become interested
    in how a car makes that possible. After all, knowing what’s under the hood may
    someday help you get the car moving again after it breaks down and leaves you
    stranded at the side of the road.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第11章](index_split_087.html#filepos1036287)中详细解释所有这些组件。我不喜欢在解释事物的工作原理之前先解释事物的作用，并教人们如何使用它。这就像学习开车一样。您不想知道引擎盖下是什么。您首先想学习如何从A点到B点驾驶。只有在你学会了如何做到这一点之后，你才会对汽车是如何做到这一点感兴趣。毕竟，了解引擎盖下的事情可能会在汽车抛锚并让您被困在路边时帮助您再次启动汽车。
- en: 1.3.4\. Running an application in Kubernetes
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 1.3.4. 在Kubernetes中运行应用程序
- en: To run an application in Kubernetes, you first need to package it up into one
    or more container images, push those images to an image registry, and then post
    a description of your app to the Kubernetes API server.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Kubernetes中运行应用程序，您首先需要将其打包成一个或多个容器镜像，将这些镜像推送到镜像仓库，然后将您的应用程序描述发布到Kubernetes
    API服务器。
- en: The description includes information such as the container image or images that
    contain your application components, how those components are related to each
    other, and which ones need to be run co-located (together on the same node) and
    which don’t. For each component, you can also specify how many copies (or replicas)
    you want to run. Additionally, the description also includes which of those components
    provide a service to either internal or external clients and should be exposed
    through a single IP address and made discoverable to the other components.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 描述包括有关容器镜像或包含您的应用程序组件的镜像的信息，以及这些组件之间是如何相互关联的，以及哪些组件需要运行在同一个节点上（协同运行）以及哪些不需要。对于每个组件，您还可以指定您想要运行多少个副本（或副本）。此外，描述还包括哪些组件为内部或外部客户端提供服务，并且应该通过单个IP地址公开，并使其他组件能够发现。
- en: Understanding how the description results in a running container
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 理解描述如何导致运行中的容器
- en: When the API server processes your app’s description, the Scheduler schedules
    the specified groups of containers onto the available worker nodes based on computational
    resources required by each group and the unallocated resources on each node at
    that moment. The Kubelet on those nodes then instructs the Container Runtime (Docker,
    for example) to pull the required container images and run the containers.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当API服务器处理您的应用程序描述时，调度器根据每个组所需的计算资源以及每个节点在该时刻未分配的资源，将指定的容器组调度到可用的工作节点上。然后，这些节点上的Kubelet指示容器运行时（例如Docker）拉取所需的容器镜像并运行容器。
- en: Examine [figure 1.10](#filepos173857) to gain a better understanding of how
    applications are deployed in Kubernetes. The app descriptor lists four containers,
    grouped into three sets (these sets are called pods; we’ll explain what they are
    in [chapter 3](index_split_028.html#filepos271328)). The first two pods each contain
    only a single container, whereas the last one contains two. That means both containers
    need to run co-located and shouldn’t be isolated from each other. Next to each
    pod, you also see a number representing the number of replicas of each pod that
    need to run in parallel. After submitting the descriptor to Kubernetes, it will
    schedule the specified number of replicas of each pod to the available worker
    nodes. The Kubelets on the nodes will then tell Docker to pull the container images
    from the image registry and run the containers.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 查看图1.10，以更好地理解应用程序如何在Kubernetes中部署。应用程序描述列出了四个容器，分为三个集合（这些集合被称为pod；我们将在第3章中解释它们是什么）。前两个pod每个只包含一个容器，而最后一个包含两个。这意味着两个容器都需要协同运行，并且不应该相互隔离。在每个pod旁边，您还可以看到一个表示每个pod需要并行运行的副本数量的数字。在将描述提交给Kubernetes后，它将指定每个pod的副本数量调度到可用的工作节点上。节点上的Kubelets然后将告诉Docker从镜像仓库拉取容器镜像并运行容器。
- en: Figure 1.10\. A basic overview of the Kubernetes architecture and an application
    running on top of it
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.10。Kubernetes架构的基本概述以及在其上运行的应用程序
- en: '![](images/00001.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图片](images/00001.jpg)'
- en: Keeping the containers running
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 保持容器运行
- en: Once the application is running, Kubernetes continuously makes sure that the
    deployed state of the application always matches the description you provided.
    For example, if you specify that you always want five instances of a web server
    running, Kubernetes will always keep exactly five instances running. If one of
    those instances stops working properly, like when its process crashes or when
    it stops responding, Kubernetes will restart it automatically.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦应用程序开始运行，Kubernetes将不断确保应用程序的部署状态始终与您提供的描述相匹配。例如，如果您指定您始终想要运行五个Web服务器的实例，Kubernetes将始终保持恰好五个实例运行。如果这些实例中的一个停止正常工作，比如其进程崩溃或停止响应，Kubernetes将自动重启它。
- en: Similarly, if a whole worker node dies or becomes inaccessible, Kubernetes will
    select new nodes for all the containers that were running on the node and run
    them on the newly selected nodes.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，如果整个工作节点死亡或变得不可访问，Kubernetes将为在节点上运行的所有容器选择新的节点，并在新选择的节点上运行它们。
- en: Scaling the number of copies
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展副本数量
- en: While the application is running, you can decide you want to increase or decrease
    the number of copies, and Kubernetes will spin up additional ones or stop the
    excess ones, respectively. You can even leave the job of deciding the optimal
    number of copies to Kubernetes. It can automatically keep adjusting the number,
    based on real-time metrics, such as CPU load, memory consumption, queries per
    second, or any other metric your app exposes.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用程序运行时，您可以决定您想要增加或减少副本数量，Kubernetes 将启动额外的副本或停止多余的副本。您甚至可以将决定最佳副本数量的任务留给 Kubernetes。它可以根据实时指标自动调整数量，例如
    CPU 负载、内存消耗、每秒查询数或任何其他应用程序公开的指标。
- en: Hitting a moving target
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 打击移动目标
- en: We’ve said that Kubernetes may need to move your containers around the cluster.
    This can occur when the node they were running on has failed or because they were
    evicted from a node to make room for other containers. If the container is providing
    a service to external clients or other containers running in the cluster, how
    can they use the container properly if it’s constantly moving around the cluster?
    And how can clients connect to containers providing a service when those containers
    are replicated and spread across the whole cluster?
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经说过 Kubernetes 可能需要将您的容器在集群中移动。这可能会发生在它们运行的节点失败或因为需要为其他容器腾出空间而被从节点驱逐时。如果容器正在为外部客户端或集群中运行的容器提供服务，当容器不断在集群中移动时，它们如何正确使用容器？当这些容器被复制并分散在整个集群中时，客户端如何连接到提供服务的容器？
- en: To allow clients to easily find containers that provide a specific service,
    you can tell Kubernetes which containers provide the same service and Kubernetes
    will expose all of them at a single static IP address and expose that address
    to all applications running in the cluster. This is done through environment variables,
    but clients can also look up the service IP through good old DNS. The kube-proxy
    will make sure connections to the service are load balanced across all the containers
    that provide the service. The IP address of the service stays constant, so clients
    can always connect to its containers, even when they’re moved around the cluster.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让客户端能够轻松找到提供特定服务的容器，您可以告诉 Kubernetes 哪些容器提供相同的服务，Kubernetes 将将它们全部暴露在单个静态
    IP 地址上，并将该地址暴露给集群中运行的所有应用程序。这是通过环境变量完成的，但客户端也可以通过古老的 DNS 查找服务 IP。kube-proxy 将确保连接到服务的连接在提供服务的所有容器之间进行负载均衡。服务的
    IP 地址保持不变，因此客户端可以始终连接到其容器，即使它们在集群中移动。
- en: 1.3.5\. Understanding the benefits of using Kubernetes
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 1.3.5. 理解使用 Kubernetes 的好处
- en: If you have Kubernetes deployed on all your servers, the ops team doesn’t need
    to deal with deploying your apps anymore. Because a containerized application
    already contains all it needs to run, the system administrators don’t need to
    install anything to deploy and run the app. On any node where Kubernetes is deployed,
    Kubernetes can run the app immediately without any help from the sysadmins.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在所有服务器上部署了 Kubernetes，运维团队就不再需要处理应用程序的部署了。因为容器化应用程序已经包含了运行所需的所有内容，系统管理员不需要安装任何东西来部署和运行应用程序。在任何已部署
    Kubernetes 的节点上，Kubernetes 可以立即运行应用程序，无需系统管理员的帮助。
- en: Simplifying application deployment
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 简化应用程序部署
- en: Because Kubernetes exposes all its worker nodes as a single deployment platform,
    application developers can start deploying applications on their own and don’t
    need to know anything about the servers that make up the cluster.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 Kubernetes 将所有工作节点暴露为一个单一的部署平台，应用程序开发者可以自行开始部署应用程序，而无需了解构成集群的服务器。
- en: In essence, all the nodes are now a single bunch of computational resources
    that are waiting for applications to consume them. A developer doesn’t usually
    care what kind of server the application is running on, as long as the server
    can provide the application with adequate system resources.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 从本质上讲，所有节点现在都是一组等待应用程序消耗的计算资源。开发者通常不关心应用程序运行在哪种服务器上，只要服务器能够为应用程序提供足够的系统资源即可。
- en: Certain cases do exist where the developer does care what kind of hardware the
    application should run on. If the nodes are heterogeneous, you’ll find cases when
    you want certain apps to run on nodes with certain capabilities and run other
    apps on others. For example, one of your apps may require being run on a system
    with SSDs instead of HDDs, while other apps run fine on HDDs. In such cases, you
    obviously want to ensure that particular app is always scheduled to a node with
    an SSD.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 确实存在某些情况下，开发者关心应用程序应该运行在哪种硬件上。如果节点是异构的，你会发现有些情况下你希望某些应用程序运行在具有特定功能的节点上，而其他应用程序则运行在其他节点上。例如，你的某个应用程序可能需要在具有
    SSD 的系统上运行，而其他应用程序在 HDD 上运行也运行良好。在这种情况下，显然你希望确保该特定应用程序始终被调度到具有 SSD 的节点上。
- en: Without using Kubernetes, the sysadmin would select one specific node that has
    an SSD and deploy the app there. But when using Kubernetes, instead of selecting
    a specific node where your app should be run, it’s more appropriate to tell Kubernetes
    to only choose among nodes with an SSD. You’ll learn how to do that in [chapter
    3](index_split_028.html#filepos271328).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在不使用 Kubernetes 的情况下，系统管理员会选择一个具有 SSD 的特定节点并将应用程序部署在那里。但是，当使用 Kubernetes 时，而不是选择应用程序应该运行的特定节点，更合适的是告诉
    Kubernetes 只在具有 SSD 的节点中选择。你将在第 3 章（index_split_028.html#filepos271328）中学习如何做到这一点。
- en: Achieving better utilization of hardware
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 实现更好的硬件利用率
- en: By setting up Kubernetes on your servers and using it to run your apps instead
    of running them manually, you’ve decoupled your app from the infrastructure. When
    you tell Kubernetes to run your application, you’re letting it choose the most
    appropriate node to run your application on based on the description of the application’s
    resource requirements and the available resources on each node.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在你的服务器上设置 Kubernetes 并使用它来运行你的应用程序而不是手动运行它们，你已经将应用程序与基础设施解耦。当你告诉 Kubernetes
    运行你的应用程序时，你是在让它根据应用程序的资源需求描述和每个节点上的可用资源选择最合适的节点来运行你的应用程序。
- en: By using containers and not tying the app down to a specific node in your cluster,
    you’re allowing the app to freely move around the cluster at any time, so the
    different app components running on the cluster can be mixed and matched to be
    packed tightly onto the cluster nodes. This ensures the node’s hardware resources
    are utilized as best as possible.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用容器而不是将应用程序绑定到集群中的特定节点，你允许应用程序在任何时间自由地在集群中移动，因此集群上运行的不同应用程序组件可以混合匹配，紧密打包到集群节点上。这确保了节点的硬件资源得到尽可能好的利用。
- en: The ability to move applications around the cluster at any time allows Kubernetes
    to utilize the infrastructure much better than what you can achieve manually.
    Humans aren’t good at finding optimal combinations, especially when the number
    of all possible options is huge, such as when you have many application components
    and many server nodes they can be deployed on. Computers can obviously perform
    this work much better and faster than humans.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 能够在任何时间在集群中移动应用程序的能力，使得 Kubernetes 能够比手动实现更好地利用基础设施。人类在寻找最佳组合方面并不擅长，尤其是当所有可能选项的数量巨大时，例如当你有许多应用程序组件和许多可以部署的服务器节点时。计算机显然可以比人类更好地、更快地完成这项工作。
- en: Health checking and self-healing
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 健康检查和自我修复
- en: Having a system that allows moving an application across the cluster at any
    time is also valuable in the event of server failures. As your cluster size increases,
    you’ll deal with failing computer components ever more frequently.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个系统，可以在任何时间将应用程序移动到集群中，在服务器故障的情况下也很有价值。随着你的集群规模增加，你将更频繁地处理失败的计算机组件。
- en: Kubernetes monitors your app components and the nodes they run on and automatically
    reschedules them to other nodes in the event of a node failure. This frees the
    ops team from having to migrate app components manually and allows the team to
    immediately focus on fixing the node itself and returning it to the pool of available
    hardware resources instead of focusing on relocating the app.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 监控你的应用程序组件以及它们运行的节点，并在节点故障的情况下自动将它们重新调度到其他节点。这使运维团队从手动迁移应用程序组件的负担中解脱出来，并允许团队立即专注于修复节点本身并将其返回到可用硬件资源池，而不是专注于重新定位应用程序。
- en: If your infrastructure has enough spare resources to allow normal system operation
    even without the failed node, the ops team doesn’t even need to react to the failure
    immediately, such as at 3 a.m. They can sleep tight and deal with the failed node
    during regular work hours.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的基础设施有足够的备用资源，即使在没有失败节点的正常系统操作中，运维团队也不必立即对故障做出反应，例如凌晨3点，他们可以安心入睡，在正常工作时间处理失败的节点。
- en: Automatic scaling
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 自动扩展
- en: Using Kubernetes to manage your deployed applications also means the ops team
    doesn’t need to constantly monitor the load of individual applications to react
    to sudden load spikes. As previously mentioned, Kubernetes can be told to monitor
    the resources used by each application and to keep adjusting the number of running
    instances of each application.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 来管理您的已部署应用程序还意味着运维团队不需要不断监控单个应用程序的负载以应对突发的负载峰值。如前所述，Kubernetes
    可以被告知监控每个应用程序使用的资源，并持续调整每个应用程序运行的实例数量。
- en: If Kubernetes is running on cloud infrastructure, where adding additional nodes
    is as easy as requesting them through the cloud provider’s API, Kubernetes can
    even automatically scale the whole cluster size up or down based on the needs
    of the deployed applications.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Kubernetes 运行在云基础设施上，添加额外的节点就像通过云提供商的 API 请求它们一样简单，那么 Kubernetes 甚至可以根据部署的应用程序的需求自动调整整个集群的大小，进行扩展或缩减。
- en: Simplifying application development
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 简化应用程序开发
- en: The features described in the previous section mostly benefit the operations
    team. But what about the developers? Does Kubernetes bring anything to their table?
    It definitely does.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个章节中描述的功能主要对运维团队有益。但开发者呢？Kubernetes 为他们带来了什么？当然，它确实带来了。
- en: If you turn back to the fact that apps run in the same environment both during
    development and in production, this has a big effect on when bugs are discovered.
    We all agree the sooner you discover a bug, the easier it is to fix it, and fixing
    it requires less work. It’s the developers who do the fixing, so this means less
    work for them.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您回顾一下应用程序在开发和生产环境中都在同一环境中运行的事实，这将对何时发现错误产生重大影响。我们都同意，您发现错误越早，修复它就越容易，修复它需要的劳动也越少。修复错误的是开发者，这意味着他们需要做的工作更少。
- en: Then there’s the fact that developers don’t need to implement features that
    they would usually implement. This includes discovery of services and/or peers
    in a clustered application. Kubernetes does this instead of the app. Usually,
    the app only needs to look up certain environment variables or perform a DNS lookup.
    If that’s not enough, the application can query the Kubernetes API server directly
    to get that and/or other information. Querying the Kubernetes API server like
    that can even save developers from having to implement complicated mechanisms
    such as leader election.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然后还有这样一个事实，开发者不需要实现他们通常需要实现的功能。这包括在集群应用程序中发现服务和/或对等节点。Kubernetes 会代替应用程序来做这件事。通常，应用程序只需要查找某些环境变量或执行
    DNS 查询。如果这还不够，应用程序可以直接查询 Kubernetes API 服务器以获取这些和/或其他信息。以这种方式查询 Kubernetes API
    服务器甚至可以节省开发者实现复杂的机制，如领导者选举。
- en: As a final example of what Kubernetes brings to the table, you also need to
    consider the increase in confidence developers will feel knowing that when a new
    version of their app is going to be rolled out, Kubernetes can automatically detect
    if the new version is bad and stop its rollout immediately. This increase in confidence
    usually accelerates the continuous delivery of apps, which benefits the whole
    organization.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 Kubernetes 带来的最终例证，您还需要考虑开发者将感受到的信心增加，知道当他们的应用程序的新版本即将推出时，Kubernetes 可以自动检测新版本是否不良，并立即停止其发布。这种信心增加通常加速了应用程序的持续交付，这对整个组织都有益。
- en: 1.4\. Summary
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 1.4. 摘要
- en: In this introductory chapter, you’ve seen how applications have changed in recent
    years and how they can now be harder to deploy and manage. We’ve introduced Kubernetes
    and shown how it, together with Docker and other container platforms, helps deploy
    and manage applications and the infrastructure they run on. You’ve learned that
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的介绍中，您已经看到了应用程序在近年来是如何变化的，以及它们现在为什么更难部署和管理。我们介绍了 Kubernetes，并展示了它是如何与 Docker
    和其他容器平台一起帮助部署和管理应用程序及其运行的基础设施的。您已经了解到
- en: Monolithic apps are easier to deploy, but harder to maintain over time and sometimes
    impossible to scale.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单体应用程序部署起来更容易，但随着时间的推移维护起来更困难，有时甚至无法进行扩展。
- en: Microservices-based application architectures allow easier development of each
    component, but are harder to deploy and configure to work as a single system.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于微服务的应用程序架构使得每个组件的开发更加容易，但部署和配置为一个单一系统则更为困难。
- en: Linux containers provide much the same benefits as virtual machines, but are
    far more lightweight and allow for much better hardware utilization.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux 容器提供了与虚拟机几乎相同的优势，但它们更加轻量级，并允许更有效地利用硬件。
- en: Docker improved on existing Linux container technologies by allowing easier
    and faster provisioning of containerized apps together with their OS environments.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 通过允许更轻松、更快速地提供容器化应用程序及其操作系统环境，改进了现有的 Linux 容器技术。
- en: Kubernetes exposes the whole datacenter as a single computational resource for
    running applications.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 将整个数据中心暴露为单个计算资源，用于运行应用程序。
- en: Developers can deploy apps through Kubernetes without assistance from sysadmins.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发者可以在不依赖系统管理员的情况下通过 Kubernetes 部署应用程序。
- en: Sysadmins can sleep better by having Kubernetes deal with failed nodes automatically.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统管理员可以通过让 Kubernetes 自动处理失败的节点来睡得更香。
- en: In the next chapter, you’ll get your hands dirty by building an app and running
    it in Docker and then in Kubernetes.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将通过构建一个应用程序并在 Docker 和 Kubernetes 中运行它来亲自动手。
