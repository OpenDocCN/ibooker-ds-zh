- en: Chapter 1\. Introducing Storm
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一章. 介绍Storm
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: What Storm is
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是Storm
- en: The definition of big data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据的定义
- en: Big data tools
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据工具
- en: How Storm fits into the big data picture
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm在大数据图景中的位置
- en: Reasons for using Storm
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Storm的原因
- en: Apache Storm is a distributed, real-time computational framework that makes
    processing unbounded streams of data easy. Storm can be integrated with your existing
    queuing and persistence technologies, consuming streams of data and processing/transforming
    these streams in many ways.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Storm是一个分布式、实时计算框架，它使得处理无界数据流变得容易。Storm可以与你的现有队列和持久化技术集成，消费数据流并在许多方式上对这些流进行处理/转换。
- en: Still following us? Some of you are probably feeling smart because you know
    what that means. Others are searching for the proper animated GIF to express your
    level of frustration. There’s a lot in that description, so if you don’t grasp
    what all of it means right now, don’t worry. We’ve devoted the remainder of this
    chapter to clarifying exactly what we mean.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 仍在关注我们吗？你们中的一些人可能觉得自己很聪明，因为你们知道这意味着什么。其他人可能在寻找合适的动态GIF来表达你的挫败感。这个描述中有很多内容，所以如果你现在还没有完全理解它的所有含义，请不要担心。我们已经在本章的剩余部分致力于阐明我们确切的意思。
- en: To appreciate what Storm is and when it should be used, you need to understand
    where Storm falls within the big data landscape. What technologies can it be used
    with? What technologies can it replace? Being able to answer questions like these
    requires some context.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解Storm是什么以及何时应该使用它，你需要了解Storm在大数据领域中的位置。它可以与哪些技术一起使用？它可以替代哪些技术？能够回答这些问题需要一些背景知识。
- en: 1.1\. What is big data?
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1\. 什么是大数据？
- en: To talk about big data and where Storm fits within the big data landscape, we
    need to have a shared understanding of what “big data” means. There are a lot
    of definitions of big data floating around. Each has its own unique take. Here’s
    ours.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要谈论大数据以及Storm在大数据领域中的位置，我们需要对“大数据”的含义有一个共同的理解。关于大数据有很多定义。每个定义都有其独特的见解。这是我们的定义。
- en: 1.1.1\. The four Vs of big data
  id: totrans-12
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.1.1\. 大数据的四个V
- en: 'Big data is best understood by considering four different properties: volume,
    velocity, variety, and veracity.^([[1](#ch01fn01)])'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过考虑大数据的四个不同属性来理解大数据：数据量、速度、多样性和真实性.^([[1](#ch01fn01)])
- en: ¹ [http://en.wikipedia.org/wiki/Big_data](http://en.wikipedia.org/wiki/Big_data)
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹ [http://en.wikipedia.org/wiki/Big_data](http://en.wikipedia.org/wiki/Big_data)
- en: Volume
  id: totrans-15
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据量
- en: 'Volume is the most obvious property of big data—and the first that comes to
    most people’s minds when they hear the term. Data is constantly being generated
    every day from a multitude of sources: data generated by people via social media,
    data generated by software itself (website tracking, application logs, and so
    on), and user-generated data, such as Wikipedia, only scratch the surface of sources
    of data.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 数据量是大数据最明显的属性——也是当人们听到这个术语时首先想到的。每天从各种来源不断生成数据：由社交媒体中的人生成数据、软件自身生成数据（网站跟踪、应用程序日志等），以及用户生成数据，如维基百科，只是数据来源的一小部分。
- en: When people think volume, companies such as Google, Facebook, and Twitter come
    to mind. Sure, all deal with enormous amounts of data, and we’re certain you can
    name others, but what about companies that don’t have that volume of data? There
    are many other companies that, by definition of volume alone, don’t have big data,
    yet these companies use Storm. Why? This is where the second V, velocity, comes
    into play.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当人们想到数据量时，谷歌、Facebook和Twitter等公司会浮现在脑海中。当然，所有这些公司都处理着大量的数据，我们确信你们可以列出其他公司，但那些没有这种数据量的公司呢？有很多其他公司，仅从数据量的定义来看，并不拥有大数据，但这些公司却在使用Storm。为什么？这就是第二个V，速度，发挥作用的地方。
- en: Velocity
  id: totrans-18
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 速度
- en: Velocity deals with the pace at which data flows into a system, both in terms
    of the amount of data and the fact that it’s a continuous flow of data. The amount
    of data (maybe just a series of links on your website that a visitor is clicking
    on) might be relatively small, but the rate at which it’s flowing into your system
    could be rather high. Velocity matters. It doesn’t matter how much data you have
    if you aren’t processing it fast enough to provide value. It could be a couple
    terabytes; it could be 5 million URLs making up a much smaller volume of data.
    All that matters is whether you can extract meaning from this data before it goes
    stale.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 速度处理数据流入系统的速度，无论是数据量还是它是连续的数据流。数据量（可能只是网站上的几个链接，访客正在点击）可能相对较小，但流入你系统的速度可能相当高。速度很重要。如果你处理数据不够快，无法提供价值，那么你有多少数据都无关紧要。它可能只有几个太字节；它可能是由500万个URL组成的较小数据量。所有重要的是你能否在数据过时之前从中提取意义。
- en: 'So far we have volume and velocity, which deal with the amount of data and
    the pace at which it flows into a system. In many cases, data will also come from
    multiple sources, which leads us to the next V: variety.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经有了量和速度，它们处理数据量和流入系统的速度。在许多情况下，数据也会来自多个来源，这让我们来到了下一个V：多样性。
- en: Variety
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 多样性
- en: 'For variety, let’s step back and look at extracting meaning from data. Often,
    that can involve taking data from several sources and putting them together into
    something that tells a story. When you start, though, you might have some data
    in Google Analytics, maybe some in an append-only log, and perhaps some more in
    a relational database. You need to bring all of these together and shape them
    into something you can work with to drill down and extract meaningful answers
    from questions such as the following:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增加多样性，让我们退一步，看看如何从数据中提取意义。通常，这可能涉及从几个来源获取数据并将它们组合成可以讲述故事的东西。然而，当你开始时，你可能有一些数据在谷歌分析中，也许有一些在只读日志中，也许还有一些在关系型数据库中。你需要将这些数据全部整合起来，并塑造出你可以用来深入挖掘并从以下问题中提取有意义的答案的东西：
- en: 'Q: *Who are my best customers?*'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Q: *我的最佳客户是谁？*'
- en: 'A: *Coyotes in New Mexico.*'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'A: *新墨西哥州的野狗。*'
- en: 'Q: *What do they usually purchase?*'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Q: *他们通常购买什么？*'
- en: 'A: *Some paint but mostly large heavy items.*'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'A: *有些是油漆，但大多是大型重物。*'
- en: 'Q: *Can I look at each of these customers individually and find items others
    have liked and market those items to them?*'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Q: *我能否单独查看每位客户并找到其他人喜欢的产品，然后将这些产品推广给他们？*'
- en: 'A: *That depends on how quickly you can turn your variety of data into something
    you can use and operate on.*'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'A: *这取决于你多快能将你的各种数据转化为你可以使用和操作的东西。*'
- en: 'As if we didn’t have enough to worry about with large volumes of data entering
    our system at a quick pace from a variety of sources, we also have to worry about
    how accurate that data entering our system is. The final V deals with this: veracity.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们没有足够的担忧一样，大量数据以快速的速度从各种来源进入我们的系统，我们还得担心进入我们系统中的数据准确性。最后的V处理这个问题：真实性。
- en: Veracity
  id: totrans-30
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 真实性
- en: Veracity involves the accuracy of incoming and outgoing data. Sometimes, we
    need our data to be extremely accurate. Other times, a “close enough” estimate
    is all we need. Many algorithms that allow for high fidelity estimates while maintaining
    low computational demands (like hyperloglog) are often used with big data. For
    example, determining the exact mean page view time for a hugely successful website
    is probably not required; a close-enough estimate will do. These trade-offs between
    accuracy and resources are common features of big data systems.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 真实性涉及进入和出去数据的准确性。有时，我们需要我们的数据非常准确。其他时候，“足够接近”的估计就足够了。许多允许进行高保真估计同时保持低计算需求的算法（如超对数）通常用于大数据。例如，确定一个极其成功的网站的精确平均页面浏览时间可能不是必需的；一个足够接近的估计就足够了。这些准确性和资源之间的权衡是大数据系统的常见特征。
- en: With the properties of volume, velocity, variety, and veracity defined, we’ve
    established some general boundaries around what big data is. Our next step is
    to explore the various types of tools available for processing data within these
    boundaries.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了量、速度、多样性和真实性这些属性后，我们为大数据建立了一些一般性的边界。我们的下一步是探索在这些边界内可用于处理数据的各种工具。
- en: 1.1.2\. Big data tools
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.1.2\. 大数据工具
- en: 'Many tools exist that address the various characteristics of big data (volume,
    velocity, variety, and veracity). Within a given big data ecosystem, different
    tools can be used in isolation or together for different purposes:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多工具来解决大数据的各种特性（体积、速度、多样性和真实性）。在给定的大数据生态系统中，不同的工具可以单独使用或组合使用，用于不同的目的：
- en: '***Data processing*—** These tools are used to perform some form of calculation
    and extract intelligence out of a data set.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***数据处理*—** 这些工具用于执行某种形式的计算并从数据集中提取智能。'
- en: '***Data transfer*—** These tools are used to gather and ingest data into the
    data processing systems (or transfer data in between different components of the
    system). They come in many forms but most common is a message bus (or a queue).
    Examples include Kafka, Flume, Scribe, and Scoop.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***数据传输*—** 这些工具用于收集和摄取数据到数据处理系统（或在不同系统组件之间传输数据）。它们有多种形式，但最常见的是消息总线（或队列）。示例包括
    Kafka、Flume、Scribe 和 Scoop。'
- en: '***Data storage*—** These tools are used to store the data sets during various
    stages of processing. They may include distributed filesystems such as Hadoop
    Distributed File System (HDFS) or GlusterFS as well as NoSQL data stores such
    as Cassandra.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***数据存储*—** 这些工具用于在处理的不同阶段存储数据集。它们可能包括分布式文件系统，如 Hadoop 分布式文件系统 (HDFS) 或 GlusterFS，以及
    NoSQL 数据存储，如 Cassandra。'
- en: 'We’re going to focus on data processing tools because Storm is a data-processing
    tool. To understand Storm, you need to understand a variety of data-processing
    tools. They fall into two primary classes: batch processing and stream processing.
    More recently, a hybrid between the two has emerged: micro-batch processing within
    a stream.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重点关注数据处理工具，因为 Storm 是一个数据处理工具。要理解 Storm，你需要了解各种数据处理工具。它们主要分为两大类：批处理和流处理。最近，两者之间出现了一种混合形式：流处理中的微批处理。
- en: Batch processing
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 批处理
- en: 'Consider for a moment a single datum: a unique click on a website. Now imagine
    hundreds of thousands of other clicks that are happening over the same time period.
    All of those clicks together form a batch—a collection of data points to be processed
    together. [Figure 1.1](#ch01fig01) provides an overview of how data flows into
    a batch-oriented tool.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 暂时考虑一个单一的数据点：对网站的一次唯一点击。现在想象在相同的时间段内发生的数十万次其他点击。所有这些点击一起形成一个批次——要一起处理的数据点集合。[图
    1.1](#ch01fig01) 提供了数据流入面向批次的工具的概述。
- en: Figure 1.1\. A batch processor and how data flows into it
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.1\. 批处理器和数据如何流入其中
- en: '![](01fig01_alt.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](01fig01_alt.jpg)'
- en: Processing a website’s log files to extract information about the behavior of
    visitors is an excellent example of a batch-processing problem. We have a fixed
    pool of data that we will process to get a result. What’s important to note here
    is that the tool acts on a batch of data. That batch could be a small segment
    of data, or it could be the entire data set. When working on a batch of data,
    you have the ability to derive a big picture overview of that entire batch instead
    of a single data point. The earlier example of learning about visitor behavior
    can’t be done on a single data point basis; you need to have some context based
    on the other data points (that is, other URLs visited). In other words, batch
    processing allows you to join, merge, or aggregate different data points together.
    This is why batch processing is quite often used for machine learning algorithms.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 处理网站的日志文件以提取有关访客行为的例子是一个优秀的批处理问题。我们有一个固定的数据池，我们将对其进行处理以获得结果。这里需要注意的重要一点是，工具作用于数据批次。这个批次可能是一个小的数据段，也可能整个数据集。在处理数据批次时，你能够从整个批次中得出一个整体概述，而不是单个数据点。之前关于了解访客行为的例子不能基于单个数据点进行；你需要基于其他数据点（即，其他访问的
    URL）的上下文。换句话说，批处理允许你连接、合并或聚合不同的数据点。这就是为什么批处理经常用于机器学习算法。
- en: Another characteristic of a batch process is that its results are usually not
    available until the entire batch has completed processing. The results for earlier
    data points don’t become available until the entire process is done. The larger
    your batch, the more merging, aggregating, and joining you can do, but this comes
    at a cost. The larger your batch, the longer you have to wait to get useful information
    from it. If immediacy of answers is important, stream processing might be a better
    solution.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 批量处理的另一个特点是，其结果通常只有在整个批次完成处理之后才能获得。早期数据点的结果只有在整个过程完成后才会变得可用。你的批次越大，你能够进行的合并、聚合和连接就越多，但这也带来了成本。批次越大，你需要等待的时间就越长，才能从其中获取有用的信息。如果答案的即时性很重要，流处理可能是一个更好的解决方案。
- en: Stream processing
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 流处理
- en: A stream processor acts on an unbounded stream of data instead of a batch of
    data points. [Figure 1.2](#ch01fig02) illustrates how data flows into a stream-processing
    system.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理器对无界的数据流进行操作，而不是对数据点的批次进行操作。[图1.2](#ch01fig02)说明了数据如何流入流处理系统。
- en: Figure 1.2\. A stream processor and how data flows into it
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.2\. 流处理器及其数据流入方式
- en: '![](01fig02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](01fig02.jpg)'
- en: A stream processor is continually ingesting new data (a “stream”). The need
    for stream processing usually follows a need for immediacy in the availability
    of results. This isn’t always the case and is definitely not a mandate for stream
    processing. That’s why we have an unbounded stream of data being fed into the
    stream processor. This stream of data is usually directed from its origin by way
    of a message bus into the stream processor so that results can be obtained while
    the data is still hot, so to speak. Unlike a batch process, there’s no well-defined
    beginning or end to the data points flowing through this stream; it’s continuous.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 流处理器持续地摄取新的数据（称为“流”）。对流处理的需求通常源于对结果即时性的需求。但这并不总是如此，也绝对不是流处理的强制要求。这就是为什么我们有未界定的数据流不断输入到流处理器中。这些数据通常通过消息总线从其源头导向流处理器，以便在数据仍然“热”的时候就能获得结果。与批量处理不同，流中流动的数据点没有明确的开始或结束；它是连续的。
- en: These systems achieve that immediacy by working on a single data point at a
    time. Numerous data points are flowing through the stream, and when you work on
    one data point at a time and you’re doing it in parallel, it’s quite easy to achieve
    sub-second-level latency in between the data being created and the results being
    available. Think of doing sentiment analysis on a stream of tweets. To achieve
    that, you don’t need to join or relate any incoming tweet with other tweets occurring
    at the same time, so you can work on a single tweet at a time. Sure, you may need
    some contextual data by way of a training set that’s created using historical
    tweets. But because this training set doesn’t need to be made up of current tweets
    as they’re happening, expensive aggregations with current data can be avoided
    and you can continue operating on a single tweet at a time. So in a stream-processing
    application, unlike a batch system, you’ll have results available per data point
    as each completes processing.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统通过一次处理一个数据点来实现即时性。大量数据点正在流过流，当你一次处理一个数据点并且并行进行时，在数据创建和结果可用之间实现亚秒级延迟是非常容易的。想想对推文流进行情感分析。为了实现这一点，你不需要将任何传入的推文与其他同时发生的推文关联起来，因此你可以一次处理一个推文。当然，你可能需要一些通过使用历史推文创建的训练集来获取的上下文数据。但由于这个训练集不需要由当前发生的推文组成，可以避免昂贵的当前数据聚合，你可以在一次处理一个推文的同时继续操作。因此，在流处理应用程序中，与批量系统不同，你将在每个数据点完成处理时获得结果。
- en: But stream processing isn’t limited to working on one data point at a time.
    One of the most well-known examples of this is Twitter’s “trending topics.” Trending
    topics are calculated over a sliding window of time by considering the tweets
    within each window of time. Trends can be observed by comparing the top subjects
    of tweets from the current window to the previous windows. Obviously, this adds
    a level of latency over working on a single data point at a time due to working
    over a batch of tweets within a time frame (because each tweet can’t be considered
    as completed processing until the time window it falls into elapses). Similarly,
    other forms of buffering, joins, merges, or aggregations may add latency during
    stream processing. There’s always a trade-off between the introduced latency and
    the achievable accuracy in this kind of aggregation. A larger time window (or
    more data in a join, merge, or aggregate operation) may determine the accuracy
    of the results in certain algorithms—at the cost of latency. Usually in streaming
    systems, we stay within processing latencies of milliseconds, seconds, or a matter
    of minutes at most. Use cases that go beyond that are more suitable for batch
    processing.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 但流处理不仅限于一次处理一个数据点。最著名的例子之一是Twitter的“趋势话题”。趋势话题是通过考虑每个时间窗口内的推文来在滑动时间窗口内计算的。通过比较当前窗口的推文主题与之前的窗口，可以观察到趋势。显然，由于在时间框架内处理推文批次，这会在一次处理一个数据点的基础上增加延迟（因为每个推文不能被视为完成处理，直到它所属的时间窗口结束）。同样，其他形式的缓冲、连接、合并或聚合可能在流处理期间增加延迟。在这种聚合中，引入的延迟和可达到的精度之间总是存在权衡。更大的时间窗口（或在连接、合并或聚合操作中的更多数据）可能在某些算法中确定结果的准确性——以延迟为代价。通常在流系统中，我们保持在毫秒、秒或最多几分钟的处理延迟内。超出这个范围的用例更适合批处理。
- en: We just considered two use cases for tweets with streaming systems. The amount
    of data in the form of tweets flowing through Twitter’s system is immense, and
    Twitter needs to be able to tell users what everyone in their area is talking
    about right now. Think about that for a moment. Not only does Twitter have the
    requirement of operating at high volume, but it also needs to operate with high
    velocity (that is, low latency). Twitter has a massive, never-ending stream of
    tweets coming in and it must be able to extract, in real time, what people are
    talking about. That’s a serious feat of engineering. In fact, [chapter 3](kindle_split_011.html#ch03)
    is built around a use case that’s similar to this idea of trending topics.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚考虑了使用流系统对推文的两个用例。以推文形式通过Twitter系统流动的数据量是巨大的，Twitter需要能够告诉用户他们所在地区现在都在谈论什么。想想看。Twitter不仅需要以高容量运行，还需要以高速度（即低延迟）运行。Twitter有一个巨大的、永无止境的推文流进入，它必须能够实时提取人们正在谈论的内容。这是一项艰巨的工程壮举。事实上，[第3章](kindle_split_011.html#ch03)就是围绕一个类似这种趋势话题想法的用例构建的。
- en: Micro-batch processing within a stream
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 流中的微批处理
- en: Tools have emerged in the last couple of years built just for use with examples
    like trending topics. These micro-batching tools are similar to stream-processing
    tools in that they both work with an unbounded stream of data. But unlike a stream
    processor that allows you access to every data point within it, a micro-batch
    processor groups the incoming data into batches in some fashion and gives you
    a batch at a time. This approach makes micro-batching frameworks unsuitable for
    working on single-data-point-at-a-time kinds of problems. You’re also giving up
    the associated super-low latency in processing one data point at a time. But they
    make working with batches of data within a stream a bit easier.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，出现了一些专为与趋势话题等示例一起使用而构建的工具。这些微批处理工具与流处理工具类似，因为它们都处理无界的数据流。但与允许你访问其中每个数据点的流处理器不同，微批处理处理器以一种方式将传入的数据分组到批次中，并一次给你一个批次。这种方法使得微批处理框架不适合一次处理一个数据点的问题。你也在放弃处理单个数据点时相关的超低延迟。但它们使得在流中处理数据批次变得容易一些。
- en: 1.2\. How Storm fits into the big data picture
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2\. Storm如何融入大数据场景
- en: 'So where does Storm fit within all of this? Going back to our original definition,
    we said this:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Storm在这个所有内容中处于什么位置呢？回到我们最初的定义，我们说：
- en: Storm is a distributed, real-time computational framework that makes processing
    unbounded streams of data easy.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Storm是一个分布式、实时计算框架，使得处理无界数据流变得容易。
- en: Storm is a stream-processing tool, plain and simple. It’ll run indefinitely,
    listening to a stream of data and doing “something” any time it receives data
    from the stream. Storm is also a distributed system; it allows machines to be
    easily added in order to process as much data in real-time as we can. In addition,
    Storm comes with a framework called Trident that lets you perform micro-batching
    within a stream.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Storm是一个流处理工具，简单明了。它将无限期运行，监听数据流，并在从流中接收到数据时“做些什么”。Storm也是一个分布式系统；它允许我们轻松地添加机器，以便实时处理尽可能多的数据。此外，Storm还附带一个名为Trident的框架，允许您在流中进行微批处理。
- en: '|  |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**What is real-time?**'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**什么是实时？**'
- en: When we use the term *real-time* throughout this book, what exactly do we mean?
    Well, technically speaking, *near real-time* is more accurate. In software systems,
    real-time constraints are defined to set operational deadlines for how long it
    takes a system to respond to a particular event. Normally, this latency is along
    the order of milliseconds (or at least sub-second level), with no perceivable
    delay to the end user. Within the context of Storm, both real-time (sub-second
    level) and near real-time (a matter of seconds or few minutes depending on the
    use case) latencies are possible.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在整本书中使用“实时”这个术语时，我们究竟指的是什么？好吧，从技术角度来说，“近实时”更为准确。在软件系统中，实时约束被定义为设置系统响应特定事件的操作截止时间。通常，这种延迟在毫秒级别（或者至少是亚秒级），对最终用户来说没有可感知的延迟。在Storm的上下文中，实时（亚秒级）和近实时（取决于用例，几秒或几分钟）的延迟都是可能的。
- en: '|  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: And what about the second sentence in our initial definition?
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们最初定义中的第二句话是什么意思呢？
- en: Storm can be integrated with your existing queuing and persistence technologies,
    consuming streams of data and processing/transforming these streams in many ways.
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 暴风雨可以与您现有的队列和持久化技术集成，消费数据流并以多种方式处理/转换这些流。
- en: As we’ll show you throughout the book, Storm is extremely flexible in that the
    source of a stream can be anything—usually this means a queuing system, but Storm
    doesn’t put limits on where your stream comes from (we’ll use Kafka and RabbitMQ
    for several of our use cases). The same thing goes for the result of a stream
    transformation produced by Storm. We’ve seen many cases where the result is persisted
    to a database somewhere for later access. But the result may also be pushed onto
    a separate queue for another system (maybe even another Storm topology) to process.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在整本书中向您展示的那样，Storm在灵活性方面极为出色，流源可以是任何东西——通常这意味着一个队列系统，但Storm并不限制您的流来自哪里（在我们的几个用例中，我们将使用Kafka和RabbitMQ）。对于Storm产生的流转换结果也是如此。我们已经看到许多案例，其中结果被持久化到某个数据库中以便稍后访问。但结果也可能被推送到另一个队列，供另一个系统（甚至可能是另一个Storm拓扑）处理。
- en: The point is that you can plug Storm into your existing architecture, and this
    book will provide use cases illustrating how you can do so. [Figure 1.3](#ch01fig03)
    shows a hypothetical scenario for analyzing a stream of tweets.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 重点是您可以将Storm插入到现有的架构中，这本书将提供用例来说明您如何做到这一点。[图1.3](#ch01fig03)展示了分析推文流的一个假设场景。
- en: Figure 1.3\. Example of how Storm may be used within a system
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.3\. Storm在系统内使用的示例
- en: '![](01fig03_alt.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图片01fig03_alt](01fig03_alt.jpg)'
- en: 'This high-level hypothetical solution is exactly that: hypothetical. We wanted
    to show you where Storm could fall within a system and how the coexistence of
    batch-and stream-processing tools is possible.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个高级假设解决方案正是如此：假设的。我们想展示Storm可以在系统中的哪个位置，以及批处理和流处理工具共存的可能性。
- en: What about the different technologies that can be used with Storm? [Figure 1.4](#ch01fig04)
    sheds some light on this question. The figure shows a small sampling of some of
    the technologies that can be used in this architecture. It illustrates how flexible
    Storm is in terms of the technologies it can work with as well as where it can
    be plugged into a system.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 那么与Storm一起使用的不同技术呢？[图1.4](#ch01fig04)对此问题提供了一些启示。该图显示了在这个架构中可以使用的某些技术的少量样本。它说明了Storm在可以与之工作的技术以及可以插入系统中的位置方面的灵活性。
- en: Figure 1.4\. How Storm can be used with other technologies
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.4\. Storm与其他技术一起使用的方法
- en: '![](01fig04_alt.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图片01fig04_alt](01fig04_alt.jpg)'
- en: 'For our queuing system, we could choose from a number of technologies, including
    Kafka, Kestrel, and RabbitMQ. The same thing goes for our database choice: Redis,
    Cassandra, Riak, and MySQL only scratch the surface in terms of options. And look
    at that—we’ve even managed to include a Hadoop cluster in our solution for performing
    the required batch computation for our “Top Daily Topics” report.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的队列系统，我们可以从包括 Kafka、Kestrel 和 RabbitMQ 在内的一系列技术中进行选择。数据库的选择也是如此：Redis、Cassandra、Riak
    和 MySQL 只是在众多选项中触及了表面。而且看，我们甚至在我们的解决方案中包含了一个 Hadoop 集群，用于执行我们“每日热门话题”报告所需的批量计算。
- en: Hopefully you’re starting to gain a clearer understanding of where Storm fits
    and what it can be used with. A wide range of technologies, including Hadoop,
    can work with Storm within a system. Wait, did we just tell you Storm can work
    with Hadoop?
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你开始更清楚地了解 Storm 的位置以及它可以与什么一起使用。包括 Hadoop 在内的一系列技术都可以在系统中与 Storm 一起工作。等等，我们刚刚告诉你
    Storm 可以与 Hadoop 一起工作吗？
- en: 1.2.1\. Storm vs. the usual suspects
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1.2.1\. 暴风雨与常规嫌疑人
- en: In many conversations between engineers, Storm and Hadoop often come up in the
    same sentence. Instead of starting with the tools, we’ll begin with the kind of
    problems you’ll likely encounter and show you the tools that fit best by considering
    each tool’s characteristics. Most likely you’ll end up picking more than one,
    because no single tool is appropriate for all problems. In fact, tools might even
    be used in conjunction given the right circumstances.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多工程师之间的对话中，Storm 和 Hadoop 经常被放在同一句话中。我们不会从工具开始，而是从你可能会遇到的问题类型开始，通过考虑每个工具的特点来展示最适合的工具。很可能会选择多个工具，因为没有单个工具适合所有问题。实际上，在适当的条件下，工具甚至可以结合使用。
- en: The following descriptions of the various big data tools and the comparison
    with Storm are intended to draw attention to some of the ways in which they’re
    uniquely different from Storm. But don’t use this information alone to pick one
    tool over another.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下对各种大数据工具的描述以及与 Storm 的比较旨在引起人们对它们与 Storm 独特不同的注意。但不要仅凭此信息就选择一个工具而放弃另一个。
- en: Apache Hadoop
  id: totrans-78
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Apache Hadoop
- en: Hadoop used to be synonymous with batch-processing systems. But with the release
    of Hadoop v2, it’s more than a batch-processing system—it’s a platform for big
    data applications. Its batch-processing component is called Hadoop MapReduce.
    It also comes with a job scheduler and cluster resource manager called YARN. The
    other main component is the Hadoop distributed filesystem, HDFS. Many other big
    data tools are being built that take advantage of YARN for managing the cluster
    and HDFS as a data storage back end. In the remainder of this book, whenever we
    refer to Hadoop we’re talking about its MapReduce component, and we’ll refer to
    YARN and HDFS explicitly.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 以前是批量处理系统的同义词。但随着 Hadoop v2 的发布，它不仅仅是一个批量处理系统——它是一个大数据应用的平台。其批量处理组件被称为
    Hadoop MapReduce。它还附带了一个作业调度器和集群资源管理器，称为 YARN。另一个主要组件是 Hadoop 分布式文件系统，HDFS。许多其他大数据工具正在构建中，它们利用
    YARN 来管理集群，并将 HDFS 作为数据存储后端。在本书的剩余部分，当我们提到 Hadoop 时，我们指的是其 MapReduce 组件，我们将明确提及
    YARN 和 HDFS。
- en: '[Figure 1.5](#ch01fig05) shows how data is fed into Hadoop for batch processing.
    The data store is the distributed filesystem, HDFS. Once the batches of data related
    to the problem at hand are identified, the MapReduce process runs over each batch.
    When a Map-Reduce process runs, it moves the code over to the nodes where the
    data resides. This is usually a characteristic needed for batch jobs. Batch jobs
    are known to work on very large data sets (from terabytes to petabytes isn’t unheard
    of), and in those cases, it’s easier to move the code over to the data nodes within
    the distributed filesystem and execute the code on those nodes, and thus achieve
    substantial scale in efficiency thanks to that data locality.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 1.5](#ch01fig05) 展示了数据如何被输入到 Hadoop 进行批量处理。数据存储是分布式文件系统，HDFS。一旦确定了与当前问题相关的数据批次，MapReduce
    过程就会在每个批次上运行。当 Map-Reduce 过程运行时，它将代码移动到数据所在的节点。这通常是批量作业的一个特性。批量作业已知可以处理非常大的数据集（从千兆到拍字节并不罕见），在这些情况下，将代码移动到分布式文件系统中的数据节点并在这些节点上执行代码更容易，从而通过数据本地性实现了显著的效率提升。'
- en: Figure 1.5\. Hadoop and how data flows into it
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.5\. Hadoop 及数据流入方式
- en: '![](01fig05_alt.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片 1.5](01fig05_alt.jpg)'
- en: Storm
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Storm
- en: Storm, as a general framework for doing real-time computation, allows you to
    run incremental functions over data in a fashion that Hadoop can’t. [Figure 1.6](#ch01fig06)
    shows how data is fed into Storm.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Storm作为一个实时计算的一般框架，允许你以Hadoop无法实现的方式在数据上运行增量函数。[图1.6](#ch01fig06)展示了数据是如何进入Storm的。
- en: Figure 1.6\. Storm and how data flows into it
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.6\. Storm及其数据流
- en: '![](01fig06.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](01fig06.jpg)'
- en: Storm falls into the stream-processing tool category that we discussed earlier.
    It maintains all the characteristics of that category, including low latency and
    fast processing. In fact, it doesn’t get any speedier than this.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Storm属于我们之前讨论的流处理工具类别。它保持了该类别的所有特征，包括低延迟和快速处理。事实上，它的速度不会比这更快。
- en: Whereas Hadoop moves the code to the data, Storm moves the data to the code.
    This behavior makes more sense in a stream-processing system, because the data
    set isn’t known beforehand, unlike in a batch job. Also, the data set is continuously
    flowing through the code.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 与Hadoop将代码移动到数据不同，Storm将数据移动到代码。这种行为在流处理系统中更有意义，因为数据集在事先是未知的，这与批量作业不同。此外，数据集是连续通过代码流动的。
- en: Additionally, Storm provides invaluable, guaranteed message processing with
    a well-defined framework of what to do when failures occur. Storm comes with its
    own cluster resource management system, but there has been unofficial work by
    Yahoo to get Storm running on Hadoop v2’s YARN resource manager so that resources
    can be shared with a Hadoop cluster.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Storm提供了一个定义良好的框架，用于在发生故障时进行有价值的、保证的消息处理。Storm自带其自己的集群资源管理系统，但雅虎已经进行了非官方的工作，使Storm能够在Hadoop
    v2的YARN资源管理器上运行，以便资源可以与Hadoop集群共享。
- en: Apache Spark
  id: totrans-90
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Apache Spark
- en: Spark falls into the same line of batch-processing tools as Hadoop MapReduce.
    It also runs on Hadoop’s YARN resource manager. What’s interesting about Spark
    is that it allows caching of intermediate (or final) results in memory (with overflow
    to disk as needed). This ability can be highly useful for processes that run repeatedly
    over the same data sets and can make use of the previous calculations in an algorithmically
    meaningful manner.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Spark属于与Hadoop MapReduce相同的批量处理工具系列。它也运行在Hadoop的YARN资源管理器上。Spark有趣的地方在于它允许在内存中缓存中间（或最终）结果（如有需要，溢出到磁盘）。这种能力对于在相同数据集上重复运行的过程非常有用，并且可以以算法上有意义的方式利用之前的计算。
- en: Spark Streaming
  id: totrans-92
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Spark Streaming
- en: Spark Streaming works an unbounded stream of data like Storm does. But it’s
    different from Storm in the sense that Spark Streaming doesn’t belong in the stream-processing
    category of tools we discussed earlier; instead, it falls into the micro-batch-processing
    tools category. Spark Streaming is built on top of Spark, and it needs to represent
    the incoming flow of data within a stream as a batch in order to operate. In this
    sense, it’s comparable to Storm’s Trident framework rather than Storm itself.
    So Spark Streaming won’t be able to support the low latencies supported by the
    one-at-a-time semantics of Storm, but it should be comparable to Trident in terms
    of performance.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Spark Streaming与Storm一样处理无界的数据流。但它在某种程度上与Storm不同，因为Spark Streaming不属于我们之前讨论的流处理工具类别；相反，它属于微批处理工具类别。Spark
    Streaming建立在Spark之上，并且需要将流中的数据流入表示为批次才能运行。在这方面，它与Storm的Trident框架相当，而不是Storm本身。因此，Spark
    Streaming无法支持Storm的单次处理语义支持的低延迟，但在性能方面应该与Trident相当。
- en: Spark’s caching mechanism is also available with Spark Streaming. If you need
    caching, you’ll have to maintain your own in-memory caches within your Storm components
    (which isn’t hard at all and is quite common), but Storm doesn’t provide any built-in
    support for doing so.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的缓存机制在Spark Streaming中也是可用的。如果你需要缓存，你将不得不在你的Storm组件内部维护自己的内存缓存（这并不困难，而且相当常见），但Storm并没有提供任何内置的支持来做这件事。
- en: Apache Samza
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Apache Samza
- en: Samza is a young stream-processing system from the team at LinkedIn that can
    be directly compared with Storm. Yet you’ll notice some differences. Whereas Storm
    and Spark/Spark Streaming can run under their own resource managers as well as
    under YARN, Samza is built to run on the YARN system specifically.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Samza是来自LinkedIn团队的一个年轻的流处理系统，它可以直接与Storm进行比较。然而，你会注意到一些差异。虽然Storm和Spark/Spark
    Streaming可以在自己的资源管理器下运行，也可以在YARN下运行，但Samza是专门为在YARN系统上运行而构建的。
- en: Samza has a parallelism model that’s simple and easy to reason about; Storm
    has a parallelism model that lets you fine-tune the parallelism at a much more
    granular level. In Samza, each step in the workflow of your job is an independent
    entity, and you connect each of those entities using Kafka. In Storm, all the
    steps are connected by an internal system (usually Netty or ZeroMQ), resulting
    in much lower latency. Samza has the advantage of having a Kafka queue in between
    that can act as a checkpoint as well as allow multiple independent consumers access
    to that queue.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Samza有一个简单且易于推理的并行模型；Storm有一个并行模型，让您可以在更细粒度的水平上微调并行性。在Samza中，您工作流程中的每个步骤都是一个独立的实体，您使用Kafka连接这些实体。在Storm中，所有步骤都通过一个内部系统（通常是Netty或ZeroMQ）连接起来，从而实现更低的延迟。Samza的优势在于它有一个Kafka队列，可以作为检查点，并允许多个独立的消费者访问该队列。
- en: As we alluded to earlier, it’s not just about making trade-offs between these
    various tools and choosing one. Most likely, you can use a batch-processing tool
    along with a stream-processing tool. In fact, using a batch-oriented system with
    a stream-oriented one is the subject of *Big Data* (Manning, 2015) by Nathan Marz,
    the original author of Storm.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所提到的，这不仅仅是在这些各种工具之间进行权衡并选择一个。很可能是您可以使用批处理工具和流处理工具结合使用。实际上，使用以批处理为导向的系统与以流为导向的系统相结合是Nathan
    Marz所著的*大数据*（Manning, 2015）一书中讨论的主题，而Nathan Marz是Storm的原始作者。
- en: 1.3\. Why you’d want to use Storm
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3. 您为什么想使用Storm
- en: 'Now that we’ve explained where Storm fits in the big data landscape, let’s
    discuss why you’d want to use Storm. As we’ll demonstrate throughout this book,
    Storm has fundamental properties that make it an attractive option:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经解释了Storm在大数据领域中的位置，接下来让我们讨论一下为什么您会想要使用Storm。正如我们将在整本书中展示的那样，Storm具有一些基本特性，使其成为一个吸引人的选择：
- en: It can be applied to a wide variety of use cases.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以应用于广泛的用例。
- en: It works well with a multitude of technologies.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它与多种技术配合良好。
- en: It’s scalable. Storm makes it easy to break down work over a series of threads,
    over a series of JVMs, or over a series of machines—all this without having to
    change your code to scale in that fashion (you only change some configuration).
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是可扩展的。Storm使您能够轻松地将工作分解为一系列线程、一系列JVM或一系列机器——所有这些都不需要更改您的代码以进行这种扩展（您只需更改一些配置）。
- en: It guarantees that it will process every piece of input you give it at least
    once.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它保证它会至少处理您给出的每一块输入一次。
- en: It’s very robust—you might even call it fault-tolerant. There are four major
    components within Storm, and at various times, we’ve had to kill off any of the
    four while continuing to process data.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它非常健壮——您甚至可以说它是容错的。在Storm内部有四个主要组件，在各个时期，我们不得不关闭其中的任何一个，同时继续处理数据。
- en: It’s programming-language agnostic. If you can run it on the JVM, you can run
    it easily on Storm. Even if you can’t run it on the JVM, if you can call it from
    a *nix command line, you can probably use it with Storm (although in this book,
    we’ll confine ourselves to the JVM and specifically to Java).
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它对编程语言没有限制。如果您可以在JVM上运行它，您就可以轻松地在Storm上运行它。即使您不能在JVM上运行它，如果您可以从*nix命令行调用它，您可能可以使用它与Storm一起使用（尽管在这本书中，我们将限制自己在JVM上，特别是Java上）。
- en: We think you’ll agree that sounds impressive. Storm has become our go-to toolkit
    not just for scaling, but also for fault tolerance and guaranteed message processing.
    We have a variety of Storm topologies (a chunk of Storm code that performs a given
    task) that could easily run as a Python script on a single machine. But if that
    script crashes, it doesn’t compare to Storm in terms of recoverability; Storm
    will restart and pick up work from our point of crash. No 3 a.m. pager-duty alerts,
    no 9 a.m. explanations to the VP of engineering why something died. One of the
    great things about Storm is you come for the fault tolerance and stay for the
    easy scaling.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为您会同意这听起来很令人印象深刻。Storm已经成为我们首选的工具包，不仅用于扩展，还用于容错和保证消息处理。我们有许多Storm拓扑（执行特定任务的Storm代码块），这些拓扑可以轻松地作为Python脚本在单台机器上运行。但如果该脚本崩溃，它在可恢复性方面并不比Storm强；Storm将重新启动并从我们的崩溃点继续工作。没有凌晨3点的紧急通知，没有早上9点的向工程副总裁解释为什么某件事失败的解释。关于Storm的伟大之处之一是，您是为了容错而来，但留在了易于扩展的环境中。
- en: Armed with this knowledge, you can now move on to the core concepts in Storm.
    A good grasp of these concepts will serve as the foundation for everything else
    we discuss in this book.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 带着这些知识，您现在可以继续学习Storm的核心概念。对这些概念的良好理解将为我们在这本书中讨论的所有其他内容奠定基础。
- en: 1.4\. Summary
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4. 摘要
- en: In this chapter, you learned that
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解到
- en: Storm is a stream-processing tool that runs indefinitely, listening to a stream
    of data and performing some type of processing on that stream of data. Storm can
    be integrated with many existing technologies, making it a viable solution for
    many stream-processing needs.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm 是一个无限运行的流处理工具，它监听数据流并对这些数据流进行某种类型的处理。Storm 可以与许多现有技术集成，使其成为许多流处理需求的可行解决方案。
- en: 'Big data is best defined by thinking of it in terms of its four main properties:
    volume (amount of data), velocity (speed of data flowing into a system), variety
    (different types of data), and veracity (accuracy of the data).'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最好通过考虑其四个主要属性来定义大数据：数据量（数据量）、速度（数据流入系统的速度）、种类（不同类型的数据）和真实性（数据的准确性）。
- en: 'There are three main types of tools for processing big data: batch processing,
    stream processing, and micro-batch processing within a stream.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理大数据主要有三种工具类型：批处理、流处理和流内的微批处理。
- en: Some of the benefits of Storm include its scalability, its ability to process
    each message at least once, its robustness, and its ability to be developed with
    any programming language.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storm的一些优点包括其可扩展性、至少处理每条消息一次的能力、其健壮性以及能够用任何编程语言进行开发的能力。
