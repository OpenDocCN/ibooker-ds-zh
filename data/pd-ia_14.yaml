- en: 12 Imports and exports
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 导入和导出
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Importing JSON data
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入JSON数据
- en: Flattening a nested collection of records
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展平嵌套的记录集合
- en: Downloading a CSV from an online website
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从在线网站下载CSV文件
- en: Reading from and writing to Excel workbooks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从Excel工作簿中读取和写入
- en: 'Data sets come in a variety of file formats: comma-separated values (CSV),
    tab-separated values (TSV), Excel workbooks (XLSX), and more. Some data formats
    do not store data in tabular format; instead, they nest collections of related
    data inside a key-value store. Consider the following two examples. Figure 12.1
    stores data in a table, and figure 12.2 stores the same data in a Python dictionary.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集以各种文件格式存在：逗号分隔值（CSV）、制表符分隔值（TSV）、Excel工作簿（XLSX）等。一些数据格式不存储在表格格式中；相反，它们在键值存储中嵌套相关数据的集合。考虑以下两个例子。图12.1以表格形式存储数据，而图12.2以Python字典的形式存储相同的数据。
- en: '![](../Images/CH12_F01_Paskhaver.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F01_Paskhaver.png)'
- en: Figure 12.1 A table of Oscar winners
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1奥斯卡获奖者表格
- en: 'Python’s dictionary is an example of a key-value data structure:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Python的字典是一个键值数据结构的例子：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Figure 12.2 A Python dictionary (key-value store) with the same data
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2具有相同数据的Python字典（键值存储）
- en: 'Pandas ships with utility functions to manipulate key-value data into tabular
    data and vice versa. When we have the data in a `DataFrame`, we can apply all
    our favorite techniques to it. But contorting the data into the right shape often
    proves to be the most challenging part of an analysis. In this chapter, we’ll
    learn how to resolve common problems in data imports. We’ll also explore the other
    side of the equation: exporting `DataFrame`s to various file types and data structures.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas附带用于将键值数据转换为表格数据及其相反操作的实用函数。当我们有`DataFrame`中的数据时，我们可以应用所有我们喜欢的技巧。但将数据扭曲成正确的形状通常证明是分析中最具挑战性的部分。在本章中，我们将学习如何解决数据导入中的常见问题。我们还将探索等式的另一面：将`DataFrame`导出为各种文件类型和数据结构。
- en: 12.1 Reading from and writing to JSON files
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 从JSON文件中读取和写入
- en: Let’s kick things off by talking about JSON, perhaps the most popular key-value
    storage format available today. *JavaScript Object Notation* (JSON) is a format
    for storing and transferring text data. Although the JavaScript programming language
    inspires its syntax, JSON itself is language-independent. Most languages today,
    including Python, can generate and parse JSON.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从谈论JSON开始，可能是今天最受欢迎的键值存储格式。*JavaScript对象表示法*（JSON）是一种用于存储和传输文本数据的格式。尽管JavaScript编程语言启发了其语法，但JSON本身是语言无关的。今天的大多数语言，包括Python，都可以生成和解析JSON。
- en: 'A JSON response consists of key-value pairs, in which a key serves as a unique
    identifier for a value. The colon symbol ( `:` ) connects a key to a value:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个JSON响应由键值对组成，其中键作为值的唯一标识符。冒号符号（`:`）将键与值连接起来：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Keys must be strings. Values can be of any data type, including strings, numbers,
    and Booleans. JSON is similar to Python’s dictionary object.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 键必须是字符串。值可以是任何数据类型，包括字符串、数字和布尔值。JSON类似于Python的字典对象。
- en: 'JSON is a popular response format for many modern application programming interfaces
    (APIs), such as website servers. A raw JSON response from an API looks like a
    plain string. Here’s what a response might look like:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: JSON是许多现代应用程序编程接口（API）的流行响应格式，例如网站服务器。API的原始JSON响应看起来像是一个普通的字符串。以下是一个响应可能的样子：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Software programs called *linters* format JSON responses by placing each key-value
    pair on a separate line. One popular example is JSONLint ([https://jsonlint.com](https://jsonlint.com/)).
    Running the previous JSON through JSONLint produces the following output:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 被称为*linters*的软件程序通过将每个键值对放在单独的一行上格式化JSON响应。一个流行的例子是JSONLint ([https://jsonlint.com](https://jsonlint.com/))。将之前的JSON通过JSONLint运行会产生以下输出：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: There is no technical difference between the two preceding code samples, but
    the latter is more readable.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个先前的代码样本之间没有技术差异，但后者更易读。
- en: 'The JSON response holds three key-value pairs:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: JSON响应包含三个键值对：
- en: The `"name"` key has a string value of `"Harry Potter"`.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"name"`键的字符串值为`"Harry Potter"`。'
- en: The `"age"` key has an integer value of 17.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"age"`键的整数值为17。'
- en: The `"wizard"` key has a Boolean value of `true`. In JSON, Booleans are spelled
    in lowercase. The concept is identical to a Python Boolean.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`"wizard"`键的布尔值为`true`。在JSON中，布尔值以小写形式书写。这个概念与Python布尔值相同。'
- en: 'A key can also point to an *array*, an ordered collection of elements equivalent
    to a Python list. The `"friends"` key in the next JSON example maps to an array
    of two strings:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 键也可以指向一个*数组*，这是一个有序的元素集合，相当于Python列表。以下JSON示例中的`"friends"`键映射到一个包含两个字符串的数组：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'JSON can store additional key-value pairs within nested objects, such as `"address"`
    in the following example. In Pythonic terms, we can think of `"address"` as a
    dictionary nested within another dictionary:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: JSON可以在嵌套对象中存储额外的键值对，例如以下示例中的`"address"`。用Python的说法，我们可以将`"address"`视为嵌套在另一个字典中的字典：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Nested stores of key-value pairs help simplify the data by grouping related
    fields.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌套的键值对存储有助于通过分组相关字段来简化数据。
- en: 12.1.1 Loading a JSON file Into a DataFrame
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.1 将JSON文件加载到DataFrame中
- en: 'Let’s create a new Jupyter Notebook and import the pandas library. Make sure
    to create the Notebook in the same directory as this chapter’s data files:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个新的Jupyter Notebook并导入pandas库。确保在包含本章数据文件的同一目录中创建Notebook：
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'JSON can be stored in a plain-text file with a .json extension. This chapter’s
    prizes.json file is a saved JSON response from the Nobel Prize API. The API stores
    Nobel Prize laureates dating back to 1901\. You can view the raw JSON response
    in your web browser by navigating to [http://api.nobelprize.org/v1/prize.json](http://api.nobelprize.org/v1/prize.json).
    Here’s a preview of the JSON shape:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: JSON可以存储在一个以.json扩展名的纯文本文件中。本章的prizes.json文件是从诺贝尔奖API保存的JSON响应。API存储了从1901年以来的诺贝尔奖获得者。您可以通过在网页浏览器中导航到[http://api.nobelprize.org/v1/prize.json](http://api.nobelprize.org/v1/prize.json)来查看原始JSON响应。以下是JSON形状的预览：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The JSON consists of a top-level `prizes` key that maps to an array of dictionaries,
    one for each combination of year and category (`"chemistry"`, `"physics"`, `"literature"`,
    and so on). The "`year"` and "`category"` keys are present for all winners, whereas
    the `"laureates"` and `"overallMotivation"` keys are present for only some. Here’s
    a sample dictionary with an `"overallMotivation"` key:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: JSON包含一个顶层`prizes`键，它映射到一个字典数组，每个字典对应于年份和类别的组合（例如`"chemistry"`、`"physics"`、`"literature"`等）。对于所有获奖者，`"year"`和`"category"`键都存在，而`"laureates"`和`"overallMotivation"`键只存在于某些获奖者中。以下是一个包含`"overallMotivation"`键的示例字典：
- en: '[PRE8]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `"laureates"` key connects to an array of dictionaries, each with its own
    `"id"`, `"firstname"`, `"surname",` `"motivation"`, and `"share"` keys. The `"laureates"`
    key stores an array to accommodate years in which multiple people were awarded
    a Nobel Prize in the same category. The `"laureates"` key uses a list even if
    a year had only one winner. Here is an example:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`"laureates"`键连接到一个字典数组，每个字典都有自己的`"id"`、`"firstname"`、`"surname"`、`"motivation"`和`"share"`键。`"laureates"`键存储一个数组，以容纳在相同类别中获得诺贝尔奖的多个年份。即使某一年只有一个获奖者，`"laureates"`键也会使用列表。以下是一个示例：'
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Import functions in pandas have a consistent naming scheme; each one consists
    of a `read` prefix followed by a file type. We’ve used the `read_csv` function
    many times throughout the book, for example. To import a JSON file, we’ll use
    the complementary `read_json` function. Its first argument is the file path. The
    next example passes the nobel.json file. Pandas returns a one-column `DataFrame`
    with a prizes column:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: pandas中的导入函数有一个一致的命名方案；每个函数都由一个`read`前缀后跟文件类型组成。例如，我们已经在整本书中多次使用了`read_csv`函数。要导入JSON文件，我们将使用互补的`read_json`函数。它的第一个参数是文件路径。以下示例传递了nobel.json文件。Pandas返回一个包含奖项列的单列`DataFrame`：
- en: '[PRE10]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We’ve successfully imported the file into pandas, but unfortunately, not in
    a format that’s ideal for analysis. Pandas set the JSON’s top-level `prizes` key
    as the column name and created a Python dictionary for each key-value pair it
    parsed from the JSON. Here’s a sample row value:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功地将文件导入到pandas中，但不幸的是，它不是分析的理想格式。Pandas将JSON的顶层`prizes`键设置为列名，并为从JSON中解析的每个键值对创建了一个Python字典。以下是一个示例行值：
- en: '[PRE11]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The next example passes the row value into Python’s built-in `type` function.
    We indeed have a `Series` of dictionaries:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例将行值传递给Python的内置`type`函数。我们确实有一个字典的`Series`：
- en: '[PRE12]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Our goal is to convert the data to tabular format. To do so, we’ll need to
    extract the JSON’s top-level key-value pairs (year, category) to separate `DataFrame`
    columns. We’ll also need to iterate over each dictionary in the `"laureates"`
    list and extract its nested information. Our goal is a separate row for each Nobel
    laureate, connected to their year and category. The `DataFrame` we’re aiming for
    looks like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是将数据转换为表格格式。为此，我们需要提取 JSON 的顶级键值对（年份，类别）到单独的 `DataFrame` 列。我们还需要遍历 `"laureates"`
    列表中的每个字典并提取其嵌套信息。我们的目标是每个诺贝尔奖获得者一行，与他们所在的年份和类别相关联。我们追求的 `DataFrame` 看起来像这样：
- en: '[PRE13]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The process of moving nested records of data into a single, one-dimensional
    list is called *flattening* or *normalizing*. The pandas library includes a built-in
    `json_normalize` function to take care of the heavy lifting. Let’s try it on a
    small example: a sample dictionary from the `nobel` `DataFrame`. We’ll use the
    `loc` accessor to access the first row’s dictionary and assign it to a `chemistry_2019`
    variable:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 将嵌套数据记录移动到单个一维列表的过程称为 *展平* 或 *归一化*。pandas 库包含一个内置的 `json_normalize` 函数来处理繁重的工作。让我们在一个小例子上尝试它：来自
    `nobel` `DataFrame` 的一个样本字典。我们将使用 `loc` 访问器来访问第一行的字典并将其分配给一个 `chemistry_2019`
    变量：
- en: '[PRE14]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Let’s pass the `chemistry_2019` dictionary to the `json_normalize` function’s
    `data` parameter. The good news is that pandas extracts the three top-level dictionary
    keys `("year"`, `"category"`, and `"laureates"`) to separate columns in a new
    `DataFrame`. Unfortunately, the library still keeps the nested dictionaries from
    the `"laureates"` list. Ultimately, we’d like to store the data in separate columns.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将 `chemistry_2019` 字典传递给 `json_normalize` 函数的 `data` 参数。好消息是 pandas 提取了三个顶级字典键
    `("year"`, `"category"`, 和 `"laureates"`) 并将它们作为新 `DataFrame` 中的单独列。不幸的是，库仍然保留了
    `"laureates"` 列表中的嵌套字典。最终，我们希望将数据存储在单独的列中。
- en: '[PRE15]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can use the `json_normalize` function’s `record_path` parameter to normalize
    the nested `"laureates"` records. We pass the parameter a string denoting which
    key in the dictionary holds the nested records. Let’s pass it `"laureates"`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `json_normalize` 函数的 `record_path` 参数来归一化嵌套的 `"laureates"` 记录。我们将传递一个表示字典中哪个键持有嵌套记录的字符串。让我们传递
    `"laureates"`：
- en: '[PRE16]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'One step forward, one step back. Pandas expanded the nested `"laureates"` dictionaries
    into new columns, but now we’ve lost the original year and category columns. To
    preserve these top-level key-value pairs, we can pass a list with their names
    to a parameter called `meta`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 前进一步，退一步。Pandas 将嵌套的 `"laureates"` 字典扩展到新的列中，但现在我们失去了原始的年份和类别列。为了保留这些顶级键值对，我们可以将它们的名称列表传递给一个名为
    `meta` 的参数：
- en: '[PRE17]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'That’s exactly the `DataFrame` we want. Our normalization strategy has worked
    successfully on a single dictionary from the prizes column. Luckily, the `json_normalize`
    function is smart enough to accept a `Series` of dictionaries and repeat the extraction
    logic for each entry. Let’s see what happens when we pass it the `prizes` `Series`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们想要的 `DataFrame`。我们的归一化策略已经成功应用于奖项列中的单个字典。幸运的是，`json_normalize` 函数足够智能，可以接受字典的
    `Series` 并为每个条目重复提取逻辑。让我们看看当我们传递 `prizes` `Series` 时会发生什么：
- en: '[PRE18]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Unfortunately, Pandas raises a `KeyError` exception. Some dictionaries in the
    prizes `Series` do not have a `"laureates"` key. The `json_normalize` function
    is unable to extract nested laureates information from a nonexistent list. One
    way we can solve this problem is to identify the dictionaries that lack a `"laureates"`
    key and manually assign them the key. In those situations, we can provide the
    `"laureates"` key a value of an empty list.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Pandas 抛出了一个 `KeyError` 异常。奖项 `Series` 中的一些字典没有 `"laureates"` 键。`json_normalize`
    函数无法从一个不存在的列表中提取嵌套的获奖者信息。我们可以通过识别缺少 `"laureates"` 键的字典并手动分配它们键值来解决这个问题。在这些情况下，我们可以为
    `"laureates"` 键提供一个空列表的值。
- en: 'Let’s take a second to review the `setdefault` method on a Python dictionary.
    Consider this dictionary:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们花点时间回顾一下 Python 字典中的 `setdefault` 方法。考虑以下字典：
- en: '[PRE19]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The `setdefault` method assigns a key-value pair to a dictionary, but only if
    the dictionary does not have the key. If the key exists, the method returns its
    existing value. The method’s first argument is the key, and its second argument
    is the value.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`setdefault` 方法将键值对分配给字典，但只有当字典中没有该键时。如果键已存在，该方法返回其现有值。该方法的第一参数是键，第二参数是值。'
- en: 'The following example attempts to add the key `"France"` to the `cheese_consumption`
    dictionary with a value of `100`. The key exists, so nothing changes. Python keeps
    the original value of `57.9`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例尝试将键 `"France"` 添加到 `cheese_consumption` 字典中，其值为 `100`。键存在，因此没有变化。Python
    保留了原始值 `57.9`：
- en: '[PRE20]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'By comparison, the next example invokes `setdefault` with an argument of `"Italy"`.
    The key `"Italy"` does not exist in the dictionary, so Python adds it and assigns
    it a value of `48`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相比，下一个示例使用 `"Italy"` 参数调用 `setdefault`。字典中不存在 `"Italy"` 键，因此 Python 添加它并将其赋值为
    `48`：
- en: '[PRE21]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let’s apply this technique to each nested dictionary within prizes. If a dictionary
    does not have a `laureates` key, we’ll use the `setdefault` method to add the
    key with a value of an empty list. As a reminder, we can use the `apply` method
    to iterate individually over each `Series` element. This method, introduced in
    chapter 3, accepts a function as an argument and passes each `Series` row to the
    function in sequence. The next example defines an `add_laureates_key` function
    to update a single dictionary and then passes the function to the `apply` method
    as an argument:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将此技术应用于奖项中的每个嵌套字典。如果一个字典没有 `laureates` 键，我们将使用 `setdefault` 方法添加键，其值为空列表。提醒一下，我们可以使用
    `apply` 方法逐个遍历每个 `Series` 元素。该方法在第 3 章中引入，接受一个函数作为参数，并将每个 `Series` 行按顺序传递给该函数。下一个示例定义了一个
    `add_laureates_key` 函数来更新单个字典，然后将该函数作为参数传递给 `apply` 方法：
- en: '[PRE22]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The `setdefault` method mutates the dictionaries within prizes, so there is
    no need to overwrite the original `Series`.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`setdefault` 方法会修改奖项中的字典，因此不需要覆盖原始 `Series`。'
- en: 'Now that all nested dictionaries have a `laureates` key, we can reinvoke the
    `json_normalize` function. Once again, we’ll pass a list to the `meta` parameter
    with the two top-level dictionary keys we’d like to keep. We’ll also use `record_path`
    to specify the top-level attribute with a nested list of records:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在所有嵌套字典都有一个 `laureates` 键，我们可以重新调用 `json_normalize` 函数。再次，我们将包含我们希望保留的两个顶级字典键的列表传递给
    `meta` 参数。我们还将使用 `record_path` 来指定具有嵌套记录列表的顶级属性：
- en: '[PRE23]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Success! We’ve normalized the JSON data, converted it to tabular format, and
    stored it in a two-dimensional `DataFrame`.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 成功！我们已经将 JSON 数据标准化，转换为表格格式，并将其存储在一个二维的 `DataFrame` 中。
- en: 12.1.2 Exporting a DataFrame to a JSON file
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.2 将 DataFrame 导出为 JSON 文件
- en: 'Now let’s attempt the process in reverse: converting a `DataFrame` to a JSON
    representation and writing it to a JSON file. The `to_json` method creates a JSON
    string from a pandas data structure; its `orient` parameter customizes the format
    in which pandas returns the data. The next example uses an argument of `"records"`
    to return a JSON array of key-value objects. Pandas stores the column names as
    dictionary keys that point to the row’s respective values. Here’s an example with
    the first two rows of `winners`, the `DataFrame` we created in section 12.1.1:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试逆向过程：将 `DataFrame` 转换为 JSON 表示形式并将其写入 JSON 文件。`to_json` 方法从 pandas 数据结构创建
    JSON 字符串；其 `orient` 参数自定义 pandas 返回数据时的格式。下一个示例使用 `"records"` 参数来返回一个键值对象的 JSON
    数组。Pandas 将列名存储为字典键，这些键指向行的相应值。以下是一个示例，展示了 `winners` 的前两行，这是我们在 12.1.1 节中创建的 `DataFrame`：
- en: '[PRE24]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'By comparison, we can pass an argument of `"split"` to return a dictionary
    with separate `columns`, `index`, and `data` keys. This option prevents the duplication
    of column names for each row entry:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 与之相比，我们可以传递一个 `"split"` 参数来返回一个包含单独的 `columns`、`index` 和 `data` 键的字典。此选项防止了每行条目中列名的重复：
- en: '[PRE25]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Additional arguments available for the `orient` parameter include `"index"`,
    `"columns"`, `"values"`, and `"table"`.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`orient` 参数的其他可用参数包括 `"index"`、`"columns"`、`"values"` 和 `"table"`。'
- en: 'When the JSON format fits your expectations, pass the JSON file name as the
    first argument to the `to_json` method. Pandas will write the string to a JSON
    file in the same directory as the Jupyter Notebook:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当 JSON 格式符合你的预期时，将 JSON 文件名作为 `to_json` 方法的第一个参数传递。Pandas 将字符串写入与 Jupyter Notebook
    相同目录的 JSON 文件中：
- en: '[PRE26]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: WARNING Be mindful when executing the same cell twice. If a `winners.json` file
    exists in the directory, pandas will overwrite it when we execute the previous
    cell. The library will not warn us that it is replacing the file. For this reason,
    I strongly recommend giving output files a different name from input files.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：执行相同的单元格两次时要小心。如果在目录中存在 `winners.json` 文件，pandas 将在执行上一个单元格时覆盖它。库不会警告我们正在替换文件。因此，我强烈建议为输出文件和输入文件使用不同的名称。
- en: 12.2 Reading from and writing to CSV files
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 从CSV文件读取和写入
- en: Our next data set is a collection of baby names in New York City. Each row includes
    the name, birth year, gender, ethnicity, count, and popularity rank. The CSV file
    is hosted on New York City’s government website and is available at [http://mng.bz/MgzQ](http://mng.bz/MgzQ).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下一个数据集是纽约市婴儿名字的集合。每一行包括名字、出生年份、性别、种族、计数和流行排名。CSV文件托管在纽约市政府网站上，可在[http://mng.bz/MgzQ](http://mng.bz/MgzQ)找到。
- en: 'We can access the website in our web browser and download the CSV file to our
    computer for local storage. As an alternative, we can pass the URL as the first
    argument to the `read_csv` function. Pandas will automatically fetch the data
    set and import it into a `DataFrame`. Hardcoded URLs are helpful when we have
    real-time data that changes frequently because they save us the manual work of
    downloading the data set each time we rerun our analysis:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在我们的网络浏览器中访问该网站，并将CSV文件下载到我们的计算机上进行本地存储。作为替代方案，我们可以将URL作为`read_csv`函数的第一个参数传递。Pandas将自动获取数据集并将其导入到`DataFrame`中。硬编码的URL在处理实时数据且数据频繁变化时非常有用，因为它们可以节省我们每次重新运行分析时手动下载数据集的工作：
- en: '[PRE27]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Note that pandas will raise an HTTPError exception if the link is invalid.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果链接无效，pandas将引发HTTPError异常。
- en: 'Let’s try writing the baby_names `DataFrame` to a plain CSV file with the `to_csv`
    method`.` Without an argument, the method outputs the CSV string directly in our
    Jupyter Notebook. Following CSV conventions, pandas separates rows with line breaks
    and row values with commas. As a reminder, a `\n` character marks a line break
    in Python. Here’s a small preview of the method’s output for the first ten rows
    of baby_names:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用`to_csv`方法将baby_names `DataFrame`写入一个普通的CSV文件。如果没有提供参数，该方法将直接在Jupyter
    Notebook中输出CSV字符串。遵循CSV约定，pandas使用换行符分隔行，使用逗号分隔行值。作为提醒，Python中`\n`字符标记行断。以下是方法输出前十个行的预览：
- en: '[PRE28]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: By default, pandas includes the `DataFrame` index in the CSV string. Notice
    the comma at the beginning of the string and the numeric values (0, 1, 2, and
    so on) after each `\n` symbol. Figure 12.3 highlights the commas in the output
    from the `to_csv` method.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，pandas将`DataFrame`索引包含在CSV字符串中。注意字符串开头的逗号和每个`\n`符号后面的数值（0、1、2等等）。图12.3突出了`to_csv`方法输出中的逗号。
- en: '![](../Images/CH12_F03_Paskhaver.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F03_Paskhaver.png)'
- en: Figure 12.3 The CSV output with arrows highlighting the index labels
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 CSV输出，箭头突出显示索引标签
- en: 'We can exclude the index by passing the `index` parameter an argument of `False`:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将`index`参数的参数设置为`False`来排除索引：
- en: '[PRE29]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To write the string to a CSV file, we can pass the desired filename as the
    first argument to the `to_csv` method. Make sure to include the .csv extension
    in the string. If we do not provide a specific path, pandas will write the file
    to the same directory as the Jupyter Notebook:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 要将字符串写入CSV文件，我们可以将所需的文件名作为第一个参数传递给`to_csv`方法。确保在字符串中包含.csv扩展名。如果我们不提供特定路径，pandas将把文件写入与Jupyter
    Notebook相同的目录：
- en: '[PRE30]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The method produces no output below the Notebook cell. If we flip back to the
    Jupyter Notebook navigation interface, however, we see that pandas has created
    the CSV file. Figure 12.4 shows the saved NYC_Baby_Names.csv file.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法在笔记本单元下方不产生输出。然而，如果我们切换回Jupyter Notebook导航界面，我们会看到pandas已创建了CSV文件。图12.4显示了保存的NYC_Baby_Names.csv文件。
- en: '![](../Images/CH12_F04_Paskhaver.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F04_Paskhaver.png)'
- en: Figure 12.4 The NYC_Baby_Names.csv file saved to the same directory as the Jupyter
    Notebook
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 NYC_Baby_Names.csv文件已保存到与Jupyter Notebook相同的目录中
- en: 'By default, pandas writes all `DataFrame` columns to the CSV file. We can choose
    which columns to export by passing a list of names to the `columns` parameter.
    The next example creates a CSV with only the Gender, Child’s First Name, and Count
    columns:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，pandas将所有`DataFrame`列写入CSV文件。我们可以通过传递一个列名列表到`columns`参数来选择要导出的列。下一个示例创建了一个只包含性别、孩子的名字和计数列的CSV文件：
- en: '[PRE31]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Please note that if a NYC_Baby_Names.csv file exists in the directory, pandas
    will overwrite the existing file.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果目录中存在NYC_Baby_Names.csv文件，pandas将覆盖现有文件。
- en: 12.3 Reading from and writing to Excel workbooks
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 从Excel工作簿读取和写入
- en: Excel is the most popular spreadsheet application in use today. Pandas makes
    it easy to read from and write to Excel workbooks and even specific worksheets.
    But first, we’ll need to do a little housekeeping to integrate the two pieces
    of software.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Excel是目前使用最广泛的电子表格应用程序。Pandas使得从Excel工作簿和特定工作表中读取和写入变得容易。但首先，我们需要做一些整理工作以集成这两款软件。
- en: 12.3.1 Installing the xlrd and openpyxl libraries in an Anaconda environment
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.1 在Anaconda环境中安装xlrd和openpyxl库
- en: Pandas needs the `xlrd` and `openpyxl` libraries to interact with Excel. These
    packages are the glue that connects Python to Excel.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas需要`xlrd`和`openpyxl`库来与Excel交互。这些包是连接Python和Excel的粘合剂。
- en: Here’s a refresher on installing a package in an Anaconda environment. For a
    more in-depth overview, see appendix A. If you’ve already installed these libraries
    in your Anaconda environment, feel free to skip to section 12.3.2.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是关于在Anaconda环境中安装包的复习。要获取更深入的概述，请参阅附录A。如果您已经在您的Anaconda环境中安装了这些库，请自由跳转到第12.3.2节。
- en: Launch the Terminal (macOS) or Anaconda Prompt (Windows) application.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动终端（macOS）或Anaconda Prompt（Windows）应用程序。
- en: 'Use the `conda` `info` `--envs` command to see your available Anaconda environments:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`conda info --envs`命令查看您的可用Anaconda环境：
- en: '[PRE32]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Activate the Anaconda environment in which you’d like to install the libraries.
    Appendix A shows how to create a `pandas_in_action` environment for this book.
    If you chose a different environment name, replace `pandas_in_action` with it
    in the following command:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活您想要安装库的Anaconda环境。附录A展示了如何为本书创建一个`pandas_in_action`环境。如果您选择了不同的环境名称，请在以下命令中将`pandas_in_action`替换为它：
- en: '[PRE33]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Install the `xlrd` and `openpyxl` libraries with the `conda install` command:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`conda install`命令安装`xlrd`和`openpyxl`库：
- en: '[PRE34]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: When Anaconda lists the required package dependencies, enter `"Y"` and press
    Enter to start the installation.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当Anaconda列出所需的包依赖关系时，输入`"Y"`并按Enter键开始安装。
- en: When the installation completes, execute `jupyter notebook` to start the Jupyter
    server again, and navigate back to the Jupyter Notebook for the chapter.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后，执行`jupyter notebook`以再次启动Jupyter服务器，并导航回该章节的Jupyter Notebook。
- en: Don’t forget to execute the cell with the `import` `pandas` `as pd` command
    at the top.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不要忘记执行顶部的`import pandas as pd`命令的单元格。
- en: 12.3.2 Importing Excel workbooks
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.2 导入Excel工作簿
- en: The `read_excel` function at the top level of pandas imports an Excel workbook
    into a `DataFrame`. Its first parameter, `io`, accepts a string with the workbook’s
    path. Make sure to include the .xlsx extension in the filename. By default, pandas
    will import only the first worksheet in the workbook.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: pandas顶层中的`read_excel`函数将Excel工作簿导入到`DataFrame`中。其第一个参数`io`接受一个包含工作簿路径的字符串。确保在文件名中包含.xlsx扩展名。默认情况下，pandas将只导入工作簿中的第一个工作表。
- en: 'The Single Worksheet.xlsx Excel workbook is a good place to start because it
    contains a single Data worksheet:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 单个工作表的Excel工作簿Single Worksheet.xlsx是一个很好的起点，因为它包含一个单独的数据工作表：
- en: '[PRE35]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The `read_excel` function supports many of the same parameters as `read_csv``,`
    including `index_col` to set the index columns, `usecols` to select the columns,
    and `squeeze` to coerce a one-column `DataFrame` into a `Series` object. The next
    example sets the City column as the index and keeps only three of the data set’s
    four columns. Note that if we pass a column to the `index_col` parameter, we must
    also include the column in the `usecols` list:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_excel`函数支持与`read_csv`相同的许多参数，包括`index_col`来设置索引列，`usecols`来选择列，以及`squeeze`将一列`DataFrame`强制转换为`Series`对象。下一个示例将City列设置为索引并仅保留数据集的四列中的三列。请注意，如果我们传递一个列到`index_col`参数，我们必须也在`usecols`列表中包含该列：'
- en: '[PRE36]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The complexity increases slightly when a workbook contains multiple worksheets.
    The Multiple Worksheets.xlsx workbook holds three worksheets: Data 1, Data 2,
    and Data 3\. By default, pandas imports only the first worksheet in the workbook:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 当工作簿包含多个工作表时，复杂性略有增加。Multiple Worksheets.xlsx工作簿包含三个工作表：Data 1、Data 2和Data 3。默认情况下，pandas只导入工作簿中的第一个工作表：
- en: '[PRE37]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'During import, pandas assigns each worksheet an index position starting at
    0\. We can import a specific worksheet by passing the worksheet’s index position
    or its name to the `sheet_name` parameter. The parameter’s default argument is
    `0` (the first worksheet). Therefore, the following two statements return the
    same `DataFrame`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入过程中，pandas将每个工作表分配一个从0开始的索引位置。我们可以通过传递工作表的索引位置或其名称到`sheet_name`参数来导入特定的工作表。该参数的默认参数是`0`（第一个工作表）。因此，以下两个语句返回相同的`DataFrame`：
- en: '[PRE38]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'To import all worksheets, we can pass an argument of `None` to the `sheet_name`
    parameter. Pandas will store each worksheet in a separate `DataFrame`. The `read_excel`
    function returns a dictionary with the worksheets’ names as keys and the respective
    `DataFrame`s as values:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 要导入所有工作表，我们可以将`None`作为参数传递给`sheet_name`。Pandas将每个工作表存储在一个单独的`DataFrame`中。`read_excel`函数返回一个字典，其键是工作表名称，相应的值是`DataFrame`s：
- en: '[PRE39]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'To access a `DataFrame`/worksheet, we access a key in the dictionary. Here,
    we access the `DataFrame` for the Data 2 worksheet:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问`DataFrame`/工作表，我们通过字典中的一个键来访问。在这里，我们访问Data 2工作表的`DataFrame`：
- en: '[PRE40]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'To specify a subset of worksheets to import, we can pass the `sheet_name` parameter
    a list of index positions or worksheet names. Pandas still returns a dictionary.
    The dictionary’s keys will match the strings in the `sheet_name` list. The next
    example imports only the Data 1 and Data 3 worksheets:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 要指定要导入的工作表子集，我们可以将`sheet_name`参数传递为一个索引位置或工作表名称的列表。Pandas仍然返回一个字典。该字典的键将与`sheet_name`列表中的字符串相匹配。下一个示例仅导入Data
    1和Data 3工作表：
- en: '[PRE41]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The next example targets index positions 1 and 2 or, equivalently, the second
    and third worksheets:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个示例针对索引位置1和2，或者等价地，第二和第三个工作表：
- en: '[PRE42]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: After we’ve imported the `DataFrame`, we’re free to invoke whatever methods
    we like on it. The original source of the data has no impact on our available
    operations.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们导入`DataFrame`之后，我们可以自由地对其调用任何我们喜欢的操作。原始数据源对我们的可用操作没有影响。
- en: 12.3.3 Exporting Excel workbooks
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.3 导出Excel工作簿
- en: 'Let’s return to the baby_names `DataFrame` that we downloaded from the city
    of New York. Here’s a reminder of what it looks like:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们从纽约市下载的`baby_names` `DataFrame`。这是它的一个提醒：
- en: '[PRE43]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Let’s say we want to split the data set into two `DataFrame`s, one for each
    gender. Then we’d like to write each `DataFrame` to a separate worksheet in a
    new Excel workbook. We can begin by filtering the baby_names `DataFrame`, using
    the values in the Gender column. Chapter 5 introduced the following syntax:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要将数据集分成两个`DataFrame`，一个用于每个性别。然后我们希望将每个`DataFrame`写入一个新的Excel工作簿中的单独工作表中。我们可以从通过使用性别列中的值过滤`baby_names`
    `DataFrame`开始。第5章介绍了以下语法：
- en: '[PRE44]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Writing to an Excel workbook requires a few more steps than writing to a CSV.
    First up, we need to create an `ExcelWriter` object. This object serves as the
    foundation of the workbook. We’ll attach individual worksheets to it in a moment.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据写入Excel工作簿比写入CSV需要更多步骤。首先，我们需要创建一个`ExcelWriter`对象。该对象作为工作簿的基础。我们将在稍后将其附加到单独的工作表上。
- en: 'The `ExcelWriter` constructor is available as a top-level attribute of the
    pandas library. Its first parameter, `path`, accepts the new workbook’s filename
    as a string. If we do not provide a path to a directory, pandas will create the
    Excel file in the same directory as the Jupyter Notebook. Make sure to save the
    `ExcelWriter` object to a variable. The following example uses `excel_file`:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`ExcelWriter`构造函数作为pandas库的一个顶级属性可用。它的第一个参数`path`接受新的工作簿文件名作为字符串。如果我们不提供一个目录的路径，pandas将在Jupyter
    Notebook相同的目录中创建Excel文件。确保将`ExcelWriter`对象保存到变量中。以下示例使用`excel_file`：'
- en: '[PRE45]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Next, we need to connect our girls and boys `DataFrame`s to individual worksheets
    in the workbook. Let’s start with the former.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要将我们的女孩和男孩`DataFrame`s连接到工作簿中的单独工作表。让我们从前者开始。
- en: 'A `DataFrame` includes a `to_excel` method for writing to an Excel workbook.
    The method’s first parameter, `excel_writer`, accepts an `ExcelWriter` object,
    like the one we created in the preceding example. The method’s `sheet_name` parameter
    accepts the worksheet name as a string. Finally, we can pass the `index` parameter
    a value of `False` to exclude the `DataFrame` index:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataFrame`包含一个用于写入Excel工作簿的`to_excel`方法。该方法的第一参数`excel_writer`接受一个`ExcelWriter`对象，就像前面示例中创建的那样。该方法的`sheet_name`参数接受工作表名称作为字符串。最后，我们可以通过将`index`参数的值设置为`False`来排除`DataFrame`索引：'
- en: '[PRE46]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Note that we have not created the Excel workbook yet. Rather, we’ve wired up
    the `ExcelWriter` object to include the girls `DataFrame` when we do create the
    workbook.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们还没有创建Excel工作簿。相反，我们在创建工作簿时将`ExcelWriter`对象连接到包括女孩`DataFrame`。
- en: 'Next, let’s connect our boys `DataFrame` to the Excel workbook. We’ll invoke
    the `to_excel` method on boys, passing the `excel_writer` parameter the same `ExcelWriter`
    object. Now pandas knows that it should write both data sets to the same workbook.
    Let’s also alter the string argument to the `sheet_name` parameter. To export
    only a subset of columns, let’s pass a custom list to the `columns` parameter.
    The next example instructs pandas to include only the Child’s First Name, Count,
    and Rank columns when writing the boys `DataFrame` to the “Boys” worksheet in
    the workbook:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们将我们的boys `DataFrame`连接到Excel工作簿。我们将在boys上调用`to_excel`方法，将`excel_writer`参数传递给相同的`ExcelWriter`对象。现在pandas知道它应该将两个数据集写入同一个工作簿。让我们也修改`sheet_name`参数的字符串参数。为了只导出子集的列，我们将传递一个自定义列表到`columns`参数。下一个例子指示pandas在将boys
    `DataFrame`写入工作簿中的“Boys”工作表时只包含Child’s First Name，Count和Rank列：
- en: '[PRE47]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Now that we’ve configured the Excel workbook’s plumbing, we’re clear to write
    it to disk. Invoke the `save` method on the `excel_file` `ExcelWriter` object
    to complete the process:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经配置了Excel工作簿的管道，我们可以将其写入磁盘。在`excel_file` `ExcelWriter`对象上调用`save`方法来完成这个过程：
- en: '[PRE48]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Check out the Jupyter Notebook interface to see the result. Figure 12.5 shows
    the new Baby_Names.xlsx file in the same folder.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 查看Jupyter Notebook界面以查看结果。图12.5显示了同一文件夹中的新Baby_Names.xlsx文件。
- en: '![](../Images/CH12_F05_Paskhaver.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F05_Paskhaver.png)'
- en: Figure 12.5 The XLSX Excel file saved to the same directory as the Jupyter Notebook
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 将XLSX Excel文件保存到与Jupyter Notebook相同的目录中
- en: And there you have it. Now you know how to export JSON, CSV, and XLSX files
    from pandas. The library offers additional functions for exporting its data structures
    to other file formats.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何从pandas导出JSON、CSV和XLSX文件。该库提供了将数据结构导出到其他文件格式的附加功能。
- en: 12.4 Coding challenge
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 编程挑战
- en: 'Let’s practice the concepts introduced in this chapter. The tv_shows.json file
    is an aggregate collection of TV show episodes pulled from the Episodate.com API
    (see [https://www.episodate.com/api](https://www.episodate.com/api)). The JSON
    includes data for three TV shows: *The X-Files,* *Lost*, and *Buffy the Vampire
    Slayer*.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们练习本章介绍的概念。tv_shows.json文件是从Episodate.com API（见[https://www.episodate.com/api](https://www.episodate.com/api)）拉取的电视剧集的聚合集合。JSON包含了三部电视剧的数据：*《X档案》，*《迷失》，和*《吸血鬼猎人巴菲》*。
- en: '[PRE49]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The JSON consists of a top-level `"shows"` key that connects to a list of three
    dictionaries, one for each of the three shows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: JSON包含一个顶层的`"shows"`键，它连接到一个包含三个字典的列表，每个字典对应三个节目中的一个：
- en: '[PRE50]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Each nested show dictionary includes `"show"`, `"runtime"`, `"network"`, and
    `"episodes"` keys. Here’s a truncated preview of the first row’s dictionary:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 每个嵌套的电视剧字典包括`"show"`，`"runtime"`，`"network"`，和`"episodes"`键。以下是第一行字典的截断预览：
- en: '[PRE51]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The `"episodes"` key maps to a list of dictionaries. Each dictionary holds data
    for one show episode. In the previous example, we see the data for the first two
    episodes of season 1 of *The X-Files*.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`"episodes"`键映射到一个字典列表。每个字典包含一个电视剧集的数据。在之前的例子中，我们看到的是《X档案》第一季前两集的数据。'
- en: 12.4.1 Problems
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.1 问题
- en: Your challenges are
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你的挑战是
- en: Normalize the nested episode data for each dictionary in the shows column. The
    goal is a `DataFrame` with a separate row for each episode. Each row should include
    the episode’s relevant metadata (`season`, `episode`, `name`, and `air_date`)
    as well as the show’s top-level information (`show`, `runtime`, and `network`).
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个字典中的嵌套剧集数据规范化，目标是创建一个`DataFrame`，其中每行代表一个剧集。每行应包括剧集的相关元数据（`season`，`episode`，`name`，和`air_date`）以及电视剧的顶级信息（`show`，`runtime`，和`network`）。
- en: Filter the normalized data set into three separate `DataFrame`s, one for each
    of the shows `("The X-Files"`, `"Lost"`, and `"Buffy the Vampire Slayer"`).
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将规范化数据集过滤成三个单独的`DataFrame`，每个对应一个节目`("The X-Files"`，`"Lost"`，和`"Buffy the Vampire
    Slayer"`)。
- en: Write the three `DataFrame`s to an episodes.xlsx Excel workbook, and save each
    TV show’s episode data to a separate worksheet. (The worksheet names are up to
    you.)
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将三个`DataFrame`写入一个episodes.xlsx Excel工作簿，并将每个电视剧的剧集数据保存到单独的工作表中。（工作表名称由你决定。）
- en: 12.4.2 Solutions
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.2 解决方案
- en: 'Let’s tackle the problems:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解决这些问题：
- en: 'We can use the `json_normalize` function to extract each TV show’s nested batch
    of episodes. The episodes are available under the `"episodes"` key, which we can
    pass to the method’s `record_path` parameter. To preserve the top-level show data,
    we can pass the `meta` parameter a list of the top-level keys to keep:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用 `json_normalize` 函数提取每个电视节目的嵌套剧集批次。剧集位于 `"episodes"` 键下，我们可以将其传递给方法的
    `record_path` 参数。为了保留顶级节目数据，我们可以将 `meta` 参数传递一个包含要保留的顶级键的列表：
- en: '[PRE52]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Our next challenge is to split the data set into three `DataFrame`s, one for
    each TV show. We can filter the rows in tv_shows based on the values in the show
    column:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们接下来的挑战是将数据集拆分为三个 `DataFrame`，每个 `DataFrame` 对应一个电视节目。我们可以根据 show 列中的值在 tv_shows
    中过滤行：
- en: '[PRE53]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Finally, let’s write the three `DataFrame`s to an Excel workbook. We’ll begin
    by instantiating an `ExcelWriter` object and saving it to a variable. We can pass
    in the workbook name as the first argument. I’ve chosen to call it episodes.xlsx:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们将三个 `DataFrame` 写入 Excel 工作簿。我们首先实例化一个 `ExcelWriter` 对象并将其保存到一个变量中。我们可以将工作簿名称作为第一个参数传入。我选择将其命名为
    episodes.xlsx：
- en: '[PRE54]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Next, we must invoke the `to_excel` method on the three `DataFrame`s to connect
    them to individual worksheets in the workbook. We’ll pass the same `episodes`
    `ExcelWriter` object to the `excel_writer` parameter in each invocation. We’ll
    make sure to provide a unique name for each worksheet via the `sheet_name` parameter.
    Finally, we’ll pass the `index` parameter a value of `False` to exclude the `DataFrame`
    index:'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，我们必须在三个 `DataFrame` 上调用 `to_excel` 方法，将它们连接到工作簿中的单独工作表。我们将相同的 `episodes`
    `ExcelWriter` 对象传递给每个调用中的 `excel_writer` 参数。我们确保通过 `sheet_name` 参数为每个工作表提供唯一的名称。最后，我们将
    `index` 参数的值设置为 `False` 以排除 `DataFrame` 的索引：
- en: '[PRE55]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'With the worksheets wired up, we can invoke the `save` method on the `episodes`
    `ExcelWriter` object to create the episodes.xlsx workbook:'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在工作表连接好之后，我们可以在 `episodes` `ExcelWriter` 对象上调用 `save` 方法来创建 episodes.xlsx 工作簿：
- en: '[PRE56]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Congratulations on completing the coding challenge!
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你完成了编码挑战！
- en: Summary
  id: totrans-182
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The `read_json` function parses a JSON file into a `DataFrame`.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`read_json` 函数将 JSON 文件解析为 `DataFrame`。'
- en: The `json_normalize` function converts nested JSON data to a tabular `DataFrame`.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`json_normalize` 函数将嵌套 JSON 数据转换为表格 `DataFrame`。'
- en: We can pass URLs to import functions such as `read_csv`, `read_json`, and `read_excel`.
    Pandas will download the data set from the provided link.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以将 URL 传递给导入函数，如 `read_csv`、`read_json` 和 `read_excel`。Pandas 将从提供的链接下载数据集。
- en: The `read_excel` function imports an Excel workbook. The method’s `sheet_name`
    parameter sets the worksheets to import. When we import multiple worksheets, pandas
    stores the resulting `DataFrame`s in a dictionary.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`read_excel` 函数导入 Excel 工作簿。方法中的 `sheet_name` 参数设置要导入的工作表。当我们导入多个工作表时，pandas
    将结果 `DataFrame` 存储在字典中。'
- en: To write one or more `DataFrame`s to an Excel workbook, instantiate an `ExcelWriter`
    object, attach the `DataFrame`s to it via the `to_excel` method, and then invoke
    the `save` method on the `ExcelWriter` object.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要将一个或多个 `DataFrame` 写入 Excel 工作簿，需要实例化一个 `ExcelWriter` 对象，通过 `to_excel` 方法将其
    `DataFrame` 附加到该对象上，然后在该 `ExcelWriter` 对象上调用 `save` 方法。
