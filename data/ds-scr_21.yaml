- en: Chapter 20\. Clustering
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第20章 聚类
- en: Where we such clusters had
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 当我们有这样的聚类时
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As made us nobly wild, not mad
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 使我们变得高尚而不是疯狂
- en: ''
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Robert Herrick
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 罗伯特·赫里克
- en: Most of the algorithms in this book are what’s known as *supervised learning*
    algorithms, in that they start with a set of labeled data and use that as the
    basis for making predictions about new, unlabeled data. Clustering, however, is
    an example of *unsupervised learning*, in which we work with completely unlabeled
    data (or in which our data has labels but we ignore them).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的大多数算法都属于*监督学习*算法，即它们从一组带标签的数据开始，并将其用作对新的未标记数据进行预测的基础。然而，聚类是*无监督学习*的一个例子，我们在其中使用完全未标记的数据（或者我们的数据具有标签但我们忽略它们）。
- en: The Idea
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 思路
- en: Whenever you look at some source of data, it’s likely that the data will somehow
    form *clusters*. A dataset showing where millionaires live probably has clusters
    in places like Beverly Hills and Manhattan. A dataset showing how many hours people
    work each week probably has a cluster around 40 (and if it’s taken from a state
    with laws mandating special benefits for people who work at least 20 hours a week,
    it probably has another cluster right around 19). A dataset of demographics of
    registered voters likely forms a variety of clusters (e.g., “soccer moms,” “bored
    retirees,” “unemployed millennials”) that pollsters and political consultants
    consider relevant.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每当您查看某些数据源时，很可能数据会以某种方式形成*聚类*。显示百万富翁住在哪里的数据集可能在比佛利山庄和曼哈顿等地形成聚类。显示人们每周工作多少小时的数据集可能在周围形成一个大约为40的聚类（如果它来自于一项法律规定每周至少工作20小时的州，那么它可能还有另一个大约在19左右的聚类）。登记选民的人口统计数据集可能形成各种各样的聚类（例如，“足球妈妈”，“无聊的退休者”，“失业的千禧一代”），这些聚类被民意调查员和政治顾问认为是相关的。
- en: Unlike some of the problems we’ve looked at, there is generally no “correct”
    clustering. An alternative clustering scheme might group some of the “unemployed
    millennials” with “grad students,” and others with “parents’ basement dwellers.”
    Neither scheme is necessarily more correct—instead, each is likely more optimal
    with respect to its own “how good are the clusters?” metric.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们已经研究过的一些问题不同，通常没有“正确”的聚类。另一种聚类方案可能会将一些“失业的千禧一代”与“研究生”分组，而将其他一些与“父母的地下室居民”分组。这两种方案都不一定更正确——而是每一种都可能更优，关于自身的“聚类有多好？”度量标准而言。
- en: Furthermore, the clusters won’t label themselves. You’ll have to do that by
    looking at the data underlying each one.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些簇不会自行标记。您需要通过查看每个簇下面的数据来完成。
- en: The Model
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: For us, each `input` will be a vector in *d*-dimensional space, which, as usual,
    we will represent as a list of numbers. Our goal will be to identify clusters
    of similar inputs and (sometimes) to find a representative value for each cluster.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说，每个`input`将是*d*维空间中的一个向量，通常我们将其表示为数字列表。我们的目标将是识别相似输入的簇，并（有时）为每个簇找到一个代表值。
- en: For example, each input could be a numeric vector that represents the title
    of a blog post, in which case the goal might be to find clusters of similar posts,
    perhaps in order to understand what our users are blogging about. Or imagine that
    we have a picture containing thousands of `(red, green, blue)` colors and that
    we need to screen-print a 10-color version of it. Clustering can help us choose
    10 colors that will minimize the total “color error.”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，每个输入可以是表示博客文章标题的数值向量，此时目标可能是找到相似帖子的簇，也许是为了理解我们的用户正在博客的内容。或者想象一下，我们有一张包含数千个`(红色，绿色，蓝色)`颜色的图片，并且我们需要丝网印刷它的10种颜色版本。聚类可以帮助我们选择最小化总“颜色误差”的10种颜色。
- en: One of the simplest clustering methods is *k*-means, in which the number of
    clusters *k* is chosen in advance, after which the goal is to partition the inputs
    into sets <math><mrow><msub><mi>S</mi> <mn>1</mn></msub> <mo>,</mo> <mo>...</mo>
    <mo>,</mo> <msub><mi>S</mi> <mi>k</mi></msub></mrow></math> in a way that minimizes
    the total sum of squared distances from each point to the mean of its assigned
    cluster.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的聚类方法之一是*k*-means，在其中聚类数*k*是预先选择的，然后目标是以最小化每个点到其分配的簇的平均值的距离的总平方和的方式将输入分区到集合<math><mrow><msub><mi>S</mi>
    <mn>1</mn></msub> <mo>,</mo> <mo>...</mo> <mo>,</mo> <msub><mi>S</mi> <mi>k</mi></msub></mrow></math>。
- en: 'There are a lot of ways to assign *n* points to *k* clusters, which means that
    finding an optimal clustering is a very hard problem. We’ll settle for an iterative
    algorithm that usually finds a good clustering:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多方法可以将*n*个点分配到*k*个簇中，这意味着找到最佳聚类是一个非常困难的问题。我们将采用一个通常能找到良好聚类的迭代算法：
- en: Start with a set of *k*-means, which are points in *d*-dimensional space.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以一组*k*-means开始，这些点位于*d*维空间中。
- en: Assign each point to the mean to which it is closest.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个点分配给最接近它的均值。
- en: If no point’s assignment has changed, stop and keep the clusters.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有点的分配发生变化，请停止并保留这些簇。
- en: If some point’s assignment has changed, recompute the means and return to step
    2.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果某些点的分配发生了变化，请重新计算均值并返回到步骤2。
- en: Using the `vector_mean` function from [Chapter 4](ch04.html#linear_algebra),
    it’s pretty simple to create a class that does this.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用来自[第四章](ch04.html#linear_algebra)的`vector_mean`函数，创建一个执行此操作的类非常简单。
- en: 'To start with, we’ll create a helper function that measures how many coordinates
    two vectors differ in. We’ll use this to track our training progress:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建一个辅助函数，用于衡量两个向量在多少坐标上不同。我们将使用这个函数来跟踪我们的训练进度：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We also need a function that, given some vectors and their assignments to clusters,
    computes the means of the clusters. It may be the case that some cluster has no
    points assigned to it. We can’t take the mean of an empty collection, so in that
    case we’ll just randomly pick one of the points to serve as the “mean” of that
    cluster:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一个函数，它根据一些向量及其对簇的分配计算簇的均值。有可能某个簇没有分配到任何点。我们不能对空集合取平均值，因此在这种情况下，我们将随机选择一个点作为该簇的“均值”：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And now we’re ready to code up our clusterer. As usual, we’ll use `tqdm` to
    track our progress, but here we don’t know how many iterations it will take, so
    we then use `itertools.count`, which creates an infinite iterable, and we’ll `return`
    out of it when we’re done:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以编写我们的聚类器代码了。像往常一样，我们将使用`tqdm`来跟踪我们的进度，但在这里，我们不知道需要多少次迭代，因此我们使用`itertools.count`，它创建一个无限迭代器，当完成时我们会从中`return`出来：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s take a look at how this works.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这是如何工作的。
- en: 'Example: Meetups'
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 例子：见面会
- en: To celebrate DataSciencester’s growth, your VP of User Rewards wants to organize
    several in-person meetups for your hometown users, complete with beer, pizza,
    and DataSciencester t-shirts. You know the locations of all your local users ([Figure 20-1](#user_locations)),
    and she’d like you to choose meetup locations that make it convenient for everyone
    to attend.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了庆祝DataSciencester的增长，您的用户奖励副总裁希望为您的本地用户组织几次面对面见面会，提供啤酒、披萨和DataSciencester
    T恤。您知道所有本地用户的位置（见[图20-1](#user_locations)），她希望您选择方便每个人参加的见面地点。
- en: '![User locations.](assets/dsf2_2001.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![用户位置。](assets/dsf2_2001.png)'
- en: Figure 20-1\. The locations of your hometown users
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图20-1. 您的本地用户位置
- en: Depending on how you look at it, you probably see two or three clusters. (It’s
    easy to do visually because the data is only two-dimensional. With more dimensions,
    it would be a lot harder to eyeball.)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的视角不同，你可能看到两个或三个簇。（从视觉上很容易，因为数据只有二维。如果是更多维度，只凭眼睛判断会更难。）
- en: 'Imagine first that she has enough budget for three meetups. You go to your
    computer and try this:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，她预算足够举办三次见面会。你去电脑上尝试这个：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You find three clusters centered at [–44, 5], [–16, –10], and [18, 20], and
    you look for meetup venues near those locations ([Figure 20-2](#user_locations_3_means)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你会找到三个以[-44, 5]，[-16, -10]和[18, 20]为中心的簇，并且寻找靠近这些位置的见面场所（见[图20-2](#user_locations_3_means)）。
- en: '![User locations with 3 means.](assets/dsf2_2002.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![带有3个均值的用户位置。](assets/dsf2_2002.png)'
- en: Figure 20-2\. User locations grouped into three clusters
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图20-2. 用户位置分为三个簇
- en: You show your results to the VP, who informs you that now she only has enough
    budgeted for *two* meetups.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您将结果展示给副总裁，她通知您现在只有预算足够举办*两次*见面会。
- en: '“No problem,” you say:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: “没问题”，你说：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As shown in [Figure 20-3](#user_locations_2_means), one meetup should still
    be near [18, 20], but now the other should be near [–26, –5].
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图20-3](#user_locations_2_means)所示，一个见面会仍应接近[18, 20]，但另一个现在应该接近[-26, -5]。
- en: '![User locations with 2 means.](assets/dsf2_2003.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![带有2个均值的用户位置。](assets/dsf2_2003.png)'
- en: Figure 20-3\. User locations grouped into two clusters
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图20-3. 用户位置分为两个簇
- en: Choosing k
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择*k*
- en: 'In the previous example, the choice of *k* was driven by factors outside of
    our control. In general, this won’t be the case. There are various ways to choose
    a *k*. One that’s reasonably easy to understand involves plotting the sum of squared
    errors (between each point and the mean of its cluster) as a function of *k* and
    looking at where the graph “bends”:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个示例中，*k*的选择受到我们控制之外的因素的驱动。一般情况下，这不会发生。有各种选择*k*的方法。其中一个相对容易理解的方法涉及绘制作为*k*的平方误差和（每个点与其簇的平均值之间的平方误差）的函数，并查看图表“弯曲”的位置：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'which we can apply to our previous example:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以应用到我们之前的例子中：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Looking at [Figure 20-4](#choosing_a_k), this method agrees with our original
    eyeballing that three is the “right” number of clusters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[图 20-4](#choosing_a_k)，这种方法与我们最初的直觉观察相符，认为三是“正确”的聚类数目。
- en: '![Choosing a k.](assets/dsf2_2004.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![选择一个*k*。](assets/dsf2_2004.png)'
- en: Figure 20-4\. Choosing a *k*
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-4\. 选择一个*k*
- en: 'Example: Clustering Colors'
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例：聚类颜色
- en: The VP of Swag has designed attractive DataSciencester stickers that he’d like
    you to hand out at meetups. Unfortunately, your sticker printer can print at most
    five colors per sticker. And since the VP of Art is on sabbatical, the VP of Swag
    asks if there’s some way you can take his design and modify it so that it contains
    only five colors.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Swag的副总裁设计了引人注目的DataSciencester贴纸，他希望你在聚会上分发。不幸的是，你的贴纸打印机每张最多只能打印五种颜色。由于艺术副总裁正在休假，Swag的副总裁问你是否有办法修改他的设计，使其只包含五种颜色。
- en: Computer images can be represented as two-dimensional arrays of pixels, where
    each pixel is itself a three-dimensional vector `(red, green, blue)` indicating
    its color.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机图像可以表示为像素的二维数组，其中每个像素本身是一个三维向量`(red, green, blue)`，表示其颜色。
- en: 'Creating a five-color version of the image, then, entails:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 创建图片的五种颜色版本，因此，涉及：
- en: Choosing five colors.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择五种颜色。
- en: Assigning one of those colors to each pixel.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个像素分配其中的一种颜色。
- en: It turns out this is a great task for *k*-means clustering, which can partition
    the pixels into five clusters in red-green-blue space. If we then recolor the
    pixels in each cluster to the mean color, we’re done.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 原来这是*k*-means聚类的一个很好的任务，它可以将像素在红-绿-蓝色彩空间中分成五个聚类。然后，如果我们将每个聚类中的像素重新着色为平均颜色，我们就完成了。
- en: 'To start with, we’ll need a way to load an image into Python. We can do this
    with matplotlib, if we first install the pillow library:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一种方法将图像加载到Python中。我们可以通过matplotlib来实现这一点，前提是我们首先安装pillow库：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then we can just use `matplotlib.image.imread`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们只需使用`matplotlib.image.imread`：
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Behind the scenes `img` is a NumPy array, but for our purposes, we can treat
    it as a list of lists of lists.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，`img`是一个NumPy数组，但是对于我们的目的，我们可以将其视为列表的列表的列表。
- en: '`img[i][j]` is the pixel in the *i*th row and *j*th column, and each pixel
    is a list `[red, green, blue]` of numbers between 0 and 1 indicating the [color
    of that pixel](http://en.wikipedia.org/wiki/RGB_color_model):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`img[i][j]`是第*i*行第*j*列的像素，每个像素是一个列表`[red, green, blue]`，数字介于0和1之间，表示[该像素的颜色](http://en.wikipedia.org/wiki/RGB_color_model)：'
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In particular, we can get a flattened list of all the pixels as:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们可以获得所有像素的扁平化列表，如下所示：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'and then feed them to our clusterer:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将它们提供给我们的聚类器：
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Once it finishes, we just construct a new image with the same format:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们只需构造一个新的具有相同格式的图像：
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'and display it, using `plt.imshow`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 并显示它，使用`plt.imshow`：
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: It is difficult to show color results in a black-and-white book, but [Figure 20-5](#mt_both)
    shows grayscale versions of a full-color picture and the output of using this
    process to reduce it to five colors.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在黑白书籍中展示彩色结果很困难，但[图 20-5](#mt_both)显示了将全彩色图片转换为灰度版本以及使用此过程减少至五种颜色的输出。
- en: '![Original picture and its 5-means decoloring.](assets/dsf2_2005.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![原始图片及其5-means去色化结果。](assets/dsf2_2005.png)'
- en: Figure 20-5\. Original picture and its 5-means decoloring
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-5\. 原始图片及其5-means去色化结果
- en: Bottom-Up Hierarchical Clustering
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自底向上的分层聚类
- en: 'An alternative approach to clustering is to “grow” clusters from the bottom
    up. We can do this in the following way:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类的另一种方法是从底部向上“增长”聚类。我们可以这样做：
- en: Make each input its own cluster of one.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使每个输入成为自己的一个簇。
- en: As long as there are multiple clusters remaining, find the two closest clusters
    and merge them.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只要还有多个剩余的聚类，就找到最接近的两个聚类并将它们合并。
- en: At the end, we’ll have one giant cluster containing all the inputs. If we keep
    track of the merge order, we can re-create any number of clusters by unmerging.
    For example, if we want three clusters, we can just undo the last two merges.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将拥有一个包含所有输入的巨大聚类。如果我们跟踪合并顺序，我们可以通过取消合并来重新创建任意数量的聚类。例如，如果我们想要三个聚类，我们可以撤销最后两个合并。
- en: 'We’ll use a really simple representation of clusters. Our values will live
    in *leaf* clusters, which we will represent as `NamedTuple`s:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用聚类的一个非常简单的表示。我们的值将存储在*leaf*簇中，并将其表示为`NamedTuple`：
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We’ll use these to grow *merged* clusters, which we will also represent as
    `NamedTuple`s:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这些来增长*merged*聚类，我们也将其表示为`NamedTuple`：
- en: '[PRE15]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This is another case where Python’s type annotations have let us down. You’d
    like to type hint `Merged.children` as `Tuple[Cluster, Cluster]` but `mypy` doesn’t
    allow recursive types like that.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一种情况，Python的类型注解让我们感到失望。你想用`Tuple[Cluster, Cluster]`作为`Merged.children`的类型提示，但`mypy`不允许这样的递归类型。
- en: 'We’ll talk about merge order in a bit, but first let’s create a helper function
    that recursively returns all the values contained in a (possibly merged) cluster:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会讨论合并顺序，但首先让我们创建一个递归返回所有值的帮助函数，这些值包含在（可能已合并的）簇中：
- en: '[PRE16]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In order to merge the closest clusters, we need some notion of the distance
    between clusters. We’ll use the *minimum* distance between elements of the two
    clusters, which merges the two clusters that are closest to touching (but will
    sometimes produce large chain-like clusters that aren’t very tight). If we wanted
    tight spherical clusters, we might use the *maximum* distance instead, as it merges
    the two clusters that fit in the smallest ball. Both are common choices, as is
    the *average* distance:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了合并最接近的簇，我们需要一些关于簇之间距离的概念。我们将使用两个簇中元素之间的*最小*距离，这将合并最接近接触的两个簇（但有时会产生不太紧密的链式簇）。如果我们想要紧凑的球状簇，我们可能会改用*最大*距离，因为它会合并适合最小球中的两个簇。这两种选择都很常见，同样常见的是*平均*距离：
- en: '[PRE17]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We’ll use the merge order slot to track the order in which we did the merging.
    Smaller numbers will represent *later* merges. This means when we want to unmerge
    clusters, we do so from lowest merge order to highest. Since `Leaf` clusters were
    never merged, we’ll assign them infinity, the highest possible value. And since
    they don’t have an `.order` property, we’ll create a helper function:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用合并顺序插槽来跟踪我们执行合并的顺序。较小的数字将表示*较晚*的合并。这意味着当我们想要拆分簇时，我们会从最低的合并顺序到最高的顺序进行。由于`Leaf`簇从未合并过，我们将给它们分配无穷大，即最大可能的值。由于它们没有`.order`属性，因此我们将创建一个辅助函数：
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Similarly, since `Leaf` clusters don’t have children, we’ll create and add
    a helper function for that:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，由于`Leaf`簇没有子节点，因此我们将为此创建并添加一个辅助函数：
- en: '[PRE19]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now we’re ready to create the clustering algorithm:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备创建聚类算法：
- en: '[PRE20]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Its use is very simple:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 它的使用非常简单：
- en: '[PRE21]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This produces a clustering that looks as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个如下所示的聚类：
- en: '[PRE22]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The numbers at the top indicate “merge order.” Since we had 20 inputs, it took
    19 merges to get to this one cluster. The first merge created cluster 18 by combining
    the leaves [19, 28] and [21, 27]. And the last merge created cluster 0.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 顶部的数字表示“合并顺序”。因为我们有20个输入，所以需要19次合并才能得到这一个簇。第一次合并通过组合叶子[19, 28]和[21, 27]创建了簇18。最后一次合并创建了簇0。
- en: If you wanted only two clusters, you’d split at the first fork (“0”), creating
    one cluster with six points and a second with the rest. For three clusters, you’d
    continue to the second fork (“1”), which indicates to split that first cluster
    into the cluster with ([19, 28], [21, 27], [20, 23], [26, 13]) and the cluster
    with ([11, 15], [13, 13]). And so on.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只想要两个簇，你可以在第一个分叉点“0”处分割，创建一个包含六个点的簇和另一个包含剩余点的簇。对于三个簇，你将继续到第二个分叉点“1”，它指示要将第一个簇拆分为包含([19,
    28], [21, 27], [20, 23], [26, 13])的簇和包含([11, 15], [13, 13])的簇。依此类推。
- en: 'Generally, though, we don’t want to be squinting at nasty text representations
    like this. Instead, let’s write a function that generates any number of clusters
    by performing the appropriate number of unmerges:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们通常不想看到像这样的难看文本表示。相反，让我们编写一个函数，通过执行适当数量的拆分来生成任意数量的簇：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'So, for example, if we want to generate three clusters, we can just do:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想生成三个簇，我们只需执行以下操作：
- en: '[PRE24]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'which we can easily plot:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 可以轻松绘制的部分：
- en: '[PRE25]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This gives very different results than *k*-means did, as shown in [Figure 20-6](#hierarchical_clustering_image).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这与*k*-means产生了非常不同的结果，如[图20-6](#hierarchical_clustering_image)所示。
- en: '![Three Bottom-Up Clusters Using Min Distance.](assets/dsf2_2006.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![使用最小距离生成的三个自下而上的簇。](assets/dsf2_2006.png)'
- en: Figure 20-6\. Three bottom-up clusters using min distance
  id: totrans-112
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图20-6\. 使用最小距离生成的三个自下而上的簇
- en: As mentioned previously, this is because using `min` in `cluster_distance` tends
    to give chain-like clusters. If we instead use `max` (which gives tight clusters),
    it looks the same as the 3-means result ([Figure 20-7](#hierarchical_clustering_image_max)).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这是因为在`cluster_distance`中使用`min`倾向于生成链式簇。如果我们改用`max`（生成紧密簇），它将与3-means结果相同（见[图20-7](#hierarchical_clustering_image_max)）。
- en: Note
  id: totrans-114
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The previous `bottom_up_clustering` implementation is relatively simple, but
    also shockingly inefficient. In particular, it recomputes the distance between
    each pair of inputs at every step. A more efficient implementation might instead
    precompute the distances between each pair of inputs and then perform a lookup
    inside `cluster_distance`. A *really* efficient implementation would likely also
    remember the `cluster_distance`s from the previous step.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的`bottom_up_clustering`实现相对简单，但效率惊人地低下。特别是，它在每一步重新计算每对输入之间的距离。更高效的实现可能会预先计算每对输入之间的距离，然后在`cluster_distance`内执行查找。*真正*高效的实现可能还会记住前一步骤的`cluster_distance`。
- en: '![Three Bottom-Up Clusters Using Max Distance.](assets/dsf2_2007.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![使用最大距离的三个自底向上聚类。](assets/dsf2_2007.png)'
- en: Figure 20-7\. Three bottom-up clusters using max distance
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 20-7\. 使用最大距离的三个自底向上聚类
- en: For Further Exploration
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步探索
- en: scikit-learn has an entire module, [`sklearn.cluster`](http://scikit-learn.org/stable/modules/clustering.html),
    that contains several clustering algorithms including `KMeans` and the `Ward`
    hierarchical clustering algorithm (which uses a different criterion for merging
    clusters than ours did).
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn有一个完整的模块，[`sklearn.cluster`](http://scikit-learn.org/stable/modules/clustering.html)，其中包含几种聚类算法，包括`KMeans`和`Ward`层次聚类算法（其合并集群的标准与我们的不同）。
- en: '[SciPy](http://www.scipy.org/) has two clustering models: `scipy.cluster.vq`,
    which does *k*-means, and `scipy.cluster.hierarchy`, which has a variety of hierarchical
    clustering algorithms.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SciPy](http://www.scipy.org/) 提供了两种聚类模型：`scipy.cluster.vq`，实现*k*-均值；以及`scipy.cluster.hierarchy`，提供多种层次聚类算法。'
