- en: Chapter 11\. Map algebra with NumPy and SciPy
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第11章\. 使用NumPy和SciPy进行局部、焦点和区域地图代数计算
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Manipulating data with NumPy
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用NumPy操作数据
- en: Using NumPy and SciPy for local, focal, and zonal map algebra calculations
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用NumPy和SciPy进行局部、焦点和区域地图代数计算
- en: Using GDAL for global map algebra calculations
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GDAL进行全局地图代数计算
- en: Resampling data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重采样数据
- en: You’ve seen how to read and write raster data, but you still don’t know how
    to manipulate pixel values to do any analysis. Aerial photos make nice basemaps,
    but many types of raster datasets are used for scientific data analysis. For example,
    you’ll see several examples of landcover classification in the next chapter. If
    you wanted to create your own landcover model, you might collect satellite imagery,
    elevation data, and climate data such as average precipitation or temperature,
    all of which are generally raster datasets. If you wanted to use vector data in
    the model, such as soil types, you’d convert it to raster first so that you could
    use it with your raster datasets. You could then use techniques from this chapter
    to derive slope and aspect from your elevation data and to combine all of your
    datasets to create a landcover model.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了如何读取和写入栅格数据，但你仍然不知道如何操作像素值来进行任何分析。航空照片是很好的基础地图，但许多类型的栅格数据集都用于科学数据分析。例如，你将在下一章看到几个土地覆盖分类的例子。如果你想创建自己的土地覆盖模型，你可能需要收集卫星图像、高程数据和气候数据，如平均降水量或温度，这些都是通常的栅格数据集。如果你想将矢量数据（如土壤类型）用于模型，你需要首先将其转换为栅格，这样你就可以与你的栅格数据集一起使用。然后，你可以使用本章介绍的技术从你的高程数据中推导出坡度和方位，并将所有数据集组合起来创建土地覆盖模型。
- en: You’ll learn several techniques for manipulating raster data in this chapter.
    For example, you’ll learn how to apply calculations on a pixel-by-pixel basis
    to two or more rasters. You’ll also see how to use a small set of neighboring
    pixels to come up with new values. This is what happens when you smooth or sharpen
    a digital photo. Other calculations use all pixels in a raster, or divide them
    up based on some common value. Each of these has different uses, and you’ll see
    examples of all of them.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习几种操作栅格数据的技术。例如，你将学习如何对两个或多个栅格进行逐像素的计算。你还将看到如何使用一组相邻像素来得出新的值。这就是当你平滑或锐化数字照片时发生的事情。其他计算使用栅格中的所有像素，或者根据某些共同值将它们划分。这些都有不同的用途，你将看到所有这些的例子。
- en: If you plan on working with large raster datasets with Python, you need to be
    familiar with the SciPy project, which is a collection of Python modules designed
    for scientific computing. The NumPy, SciPy, and matplotlib modules are part of
    this. NumPy was designed to handle large arrays of data, which is perfect for
    raster data because a band is essentially a two-dimensional array of pixel values.
    SciPy contains routines for several kinds of scientific analysis, and it uses
    NumPy to hold the data. We’ll look at both of these modules, along with a couple
    of others, in the next two chapters. Matplotlib is a plotting module that’s also
    part of the SciPy project, and we’ll look at it in the last chapter.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划使用Python处理大型栅格数据集，你需要熟悉SciPy项目，这是一个为科学计算设计的Python模块集合。NumPy、SciPy和matplotlib模块都是这个项目的一部分。NumPy被设计来处理大量数据数组，这对于栅格数据来说非常完美，因为波段本质上是一个像素值的二维数组。SciPy包含几种科学分析例程，并使用NumPy来存储数据。我们将在下一章中查看这两个模块，以及几个其他模块。Matplotlib是一个绘图模块，也是SciPy项目的一部分，我们将在最后一章中查看它。
- en: 11.1\. Introduction to NumPy
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1\. NumPy简介
- en: Entire books have been written about NumPy, but we’ll take a brief look at how
    to create arrays and access specific values. When you use the GDAL `ReadAsArray`
    function, the data are put into a NumPy array for you. Once there, you can manipulate
    your data in many different ways. The bulk of this chapter discusses map algebra,
    which involves calculations on one or more arrays, and many of the examples won’t
    make much sense if you don’t understand the basics of working with NumPy arrays.
    For more in-depth information, please look at another book or refer to the excellent
    documentation online at [http://www.numpy.org](http://www.numpy.org).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 关于NumPy已经写了许多本书，但我们将简要地看看如何创建数组并访问特定值。当你使用GDAL的`ReadAsArray`函数时，数据会自动放入一个NumPy数组中。一旦在那里，你可以以许多不同的方式操作你的数据。本章的大部分内容讨论了地图代数，它涉及一个或多个数组上的计算，如果你不理解使用NumPy数组的基本知识，那么许多例子将不会很有意义。对于更深入的信息，请参阅另一本书或参考在线的优秀文档[http://www.numpy.org](http://www.numpy.org)。
- en: Accessing individual cell values in NumPy arrays is much the same as accessing
    values in a Python list, except that they have an index for each dimension of
    the array. For example, if you have a two-dimensional array, you need to provide
    both the row and the column offsets to specify a particular cell. Let’s look at
    this and other basics from inside a Python interactive session.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在NumPy数组中访问单个单元格值与在Python列表中访问值非常相似，除了它们为数组的每个维度都有一个索引。例如，如果你有一个二维数组，你需要提供行和列偏移量来指定特定的单元格。让我们从Python交互会话内部查看这个和其他基本概念。
- en: '|  |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Tip
  id: totrans-13
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小贴士
- en: By convention, the `numpy` module is renamed to `np` when importing it into
    a Python script. You don’t have to follow suit, but you’ll find that many examples,
    including those on the NumPy website, do this.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 按照惯例，当将`numpy`模块导入Python脚本时，将其重命名为`np`。你不必遵循这一做法，但你将发现许多示例，包括NumPy网站上的示例，都是这样做的。
- en: '|  |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: First create an example array using the `arange` function, which returns an
    array containing a sequence of numbers. Because this array only has one dimension,
    you can access elements with a single index. You can also get a slice, or section,
    of an array by providing starting and ending indices separated by a colon.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先使用`arange`函数创建一个示例数组，该函数返回包含一系列数字的数组。因为这个数组只有一个维度，所以你可以使用单个索引来访问元素。你也可以通过提供用冒号分隔的起始和结束索引来获取数组的某个部分，或称为切片。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'As long as the total number of elements in an array doesn’t change, you can
    reshape it to different dimensions. For example, the array you created contains
    12 elements, so it can be reshaped into a two-dimensional array with three rows
    and four columns because that also contains 12 elements. It couldn’t be reshaped
    into an array with four rows and four columns, however, because that would require
    16 elements. A two-dimensional array requires a row and a column index, in that
    order, to access its elements:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 只要数组的元素总数不变，你就可以将其重塑为不同的维度。例如，你创建的数组包含12个元素，因此它可以被重塑为具有三行四列的二维数组，因为这也包含12个元素。然而，它不能被重塑为四行四列的数组，因为这需要16个元素。二维数组需要按照顺序提供行和列索引来访问其元素：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|  |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Tip
  id: totrans-21
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小贴士
- en: When specifying the shape of an array in a function, be sure to pass the dimensions
    in a tuple instead of as individual values.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数中指定数组形状时，请确保以元组的形式传递维度，而不是作为单独的值。
- en: '|  |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'If you only provide one index, `n`, it returns the entire *n*^(th) row. You
    can get an entire column by using a colon as the row index, which is the same
    as `0:n`, where `n` is the number of rows. You could retrieve the entire second
    row or third column like this:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只提供一个索引`n`，它返回整个*n*^(th)行。你可以通过使用冒号作为行索引来获取整个列，这与`0:n`相同，其中`n`是行数。你可以这样检索整个第二行或第三列：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You can access a two-dimensional slice by providing starting and ending indices
    for both dimensions. Again, not providing a starting index on the left of the
    colon is the same as using 0, and if you don’t provide an ending index, then you
    get the rest of the values in that dimension. You can also use negative numbers
    to leave rows or columns off the end.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过提供两个维度的起始和结束索引来访问二维切片。同样，在冒号的左侧不提供起始索引与使用0相同，如果你不提供结束索引，则在该维度上获取剩余的所有值。你也可以使用负数来省略末尾的行或列。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Working with NumPy arrays is more than accessing cell values, though. You need
    to use multiple arrays together to implement many types of analyses. If two or
    more arrays have the same dimensions, you can perform mathematical and logical
    operations on them. These work on a cell-by-cell basis, so, for example, if you
    add two arrays, the [n, m] cell in the first array is added to the [n, m] cell
    in the second array. The same rule applies to operations such as multiplication;
    if you want mathematical matrix algebra behavior instead, use the `numpy.linalg`
    submodule.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管与NumPy数组一起工作不仅仅是访问单元格值。你需要使用多个数组一起实现许多类型的分析。如果两个或更多数组具有相同的维度，你可以在它们上执行数学和逻辑运算。这些操作是基于单元格进行的，所以例如，如果你添加两个数组，第一个数组中的[n,
    m]单元格将添加到第二个数组中的[n, m]单元格。相同的规则适用于乘法等操作；如果你想要数学矩阵代数行为，请使用`numpy.linalg`子模块。
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Many different functions exist for working with arrays, including one that
    works much like an if-else statement. For example, you could create an array with
    certain values based on the comparison of two existing arrays like this:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多用于处理数组的函数，包括一个与if-else语句非常相似的函数。例如，你可以根据两个现有数组的比较创建具有特定值的数组，如下所示：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The first parameter to the `where` function is the condition to check, the
    second parameter is the value to use if the condition is true, and the third is
    the value to use otherwise. These values can also be arrays, as long as they’re
    the same size as the condition array. For example, you could get the larger of
    the two values at each location like this:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`where`函数的第一个参数是要检查的条件，第二个参数是在条件为真时使用的值，第三个是在条件不为真时使用的值。这些值也可以是数组，只要它们与条件数组的大小相同。例如，你可以这样获取每个位置的两个值中的较大值：'
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now that you’ve seen these examples, let’s look at another way to extract data
    from arrays. You aren’t limited to one value or slices of contiguous data, because
    you can also use a list of indices. As an example, create an array of 12 random
    integers between 0 and 20 and then extract the ninth, first, and fourth values,
    in that order:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了这些例子，让我们看看另一种从数组中提取数据的方法。你不仅限于一个值或连续数据的切片，因为你还可以使用一个索引列表。例如，创建一个包含0到20之间12个随机整数的数组，然后按顺序提取第九、第一和第四个值：
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If the array is multidimensional, you need to provide a list of lists, with
    an inner list for each dimension. If you want to extract three values from a two-dimensional
    array, you would provide a list containing two other lists. The first of these
    would contain the three row offsets, and the second would contain the three column
    offsets. You’ll use this technique to easily sample pixel values at a list of
    locations in the next chapter. Try converting the random number array into two-dimensions
    and look at how it works:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数组是多维的，你需要提供一个列表的列表，每个维度都有一个内部列表。如果你想从一个二维数组中提取三个值，你需要提供一个包含两个其他列表的列表。这些列表中的第一个将包含三个行偏移量，第二个将包含三个列偏移量。你将在下一章中用这个技术轻松地从一系列位置采样像素值。尝试将随机数数组转换为二维，看看它是如何工作的：
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can also use an array of Boolean values that’s the same size as your data
    array, and the returned array will contain only the values that correspond to
    `True`. Here’s an example of this, using the same array `a`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用一个与你的数据数组大小相同的布尔值数组，返回的数组将只包含对应于`True`的值。以下是一个使用相同数组`a`的例子：
- en: '[PRE9]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Why is this useful? Say you wanted to get the mean pixel value, but only for
    pixels that had a value greater than five. Using `where` to select the values
    of interest wouldn’t work, because you’d still have to set the nonmatching ones
    to some value, which would mess up your mean calculation. Using Boolean indexing
    solves your problem.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这有什么用呢？比如说，你想要获取大于五的像素的平均值，但使用`where`来选择感兴趣的值是不行的，因为你仍然需要将不匹配的值设置为某个值，这会破坏你的平均值计算。使用布尔索引可以解决这个问题。
- en: '[PRE10]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Sometimes you need to create a new array from scratch. If the cells need to
    be initialized to a certain value, you can use the `zeros` or `ones` functions.
    These return floating-point arrays by default, but you can specify the data type
    if needed. If you need a different number, you can create an array of ones and
    multiply that by the number you need:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候你需要从头开始创建一个新的数组。如果单元格需要初始化为某个特定值，你可以使用`zeros`或`ones`函数。这些函数默认返回浮点数数组，但如果你需要，可以指定数据类型。如果你需要不同的数字，你可以创建一个全为1的数组，并将其乘以所需的数字：
- en: '[PRE11]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You might have noticed that `np.int` was provided as a second parameter to the
    `ones` examples. Arrays are created as floating-point by default, but you can
    specify a different data type if you need. This example didn’t specify if it should
    be a 32-bit or 64-bit integer, and the result is system-dependent. To ensure that
    you get a 64-bit integer, use `np.int64`. A list of the available NumPy data types
    can be found at [http://docs.scipy.org/doc/numpy/user/basics.types.html](http://docs.scipy.org/doc/numpy/user/basics.types.html).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，在`ones`示例中，`np.int`被作为第二个参数提供。数组默认创建为浮点数，但如果你需要，可以指定不同的数据类型。这个例子没有指定它应该是32位还是64位整数，结果是系统相关的。为了确保你得到64位整数，请使用`np.int64`。可以在[http://docs.scipy.org/doc/numpy/user/basics.types.html](http://docs.scipy.org/doc/numpy/user/basics.types.html)找到可用的NumPy数据类型列表。
- en: '|  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Tip
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小贴士
- en: NumPy data types and GDAL data types aren’t the same thing, and you can’t use
    them interchangeably.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy数据类型和GDAL数据类型不是同一回事，你不能互换使用它们。
- en: '|  |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'If you need an empty array that doesn’t have to be initialized to a certain
    value, you can use the `empty` function. This is faster than initializing an array,
    but be sure to fill all cells with real data eventually, because ones that you
    don’t fill will contain garbage, like that shown here:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要一个不需要初始化为特定值的空数组，可以使用`empty`函数。这比初始化数组更快，但请确保最终填充所有单元格以包含真实数据，因为未填充的单元格将包含垃圾数据，就像这里所示：
- en: '[PRE12]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You’ll see examples of several more NumPy functions and techniques for working
    with arrays as you read through this chapter.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本章内容的过程中，您将看到更多NumPy函数和用于处理数组的技术的示例。
- en: 11.2\. Map algebra
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2\. 地图代数
- en: Map algebra is way of manipulating raster datasets using algebraic operations
    that you’re already familiar with, such as addition and subtraction. In this case,
    however, two or more rasters are used instead of numbers. You can use these techniques
    to process raster data in many different ways, from simple to complex. You could
    touch up a dataset to make it look better on a map, or you could create entirely
    new datasets derived from one or more others.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 地图代数是一种使用您已经熟悉的代数运算来操作栅格数据集的方法，例如加法和减法。然而，在这种情况下，使用的是两个或多个栅格而不是数字。您可以使用这些技术以多种不同的方式处理栅格数据，从简单到复杂。您可以对数据集进行润色，使其在地图上看起来更好，或者您可以从一个或多个其他数据集中创建全新的数据集。
- en: Four main types of map algebra exist, all useful for different types of analyses.
    Several of the array examples in the previous section showed local analysis, where
    each operation works on individual pixels. This is what happens when you add two
    arrays together. Focal analyses use a few surrounding pixels, zonal operations
    work on pixels with the same value, and global analyses work on the entire array.
    We’ll look at examples of all of these.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 存在四种主要的地图代数类型，所有这些类型都适用于不同类型的分析。上一节中的几个数组示例展示了局部分析，其中每个操作都针对单个像素进行。这就是您将两个数组相加时发生的情况。焦点分析使用一些周围的像素，区域操作针对具有相同值的像素，而全局分析针对整个数组。我们将查看所有这些示例。
- en: 'Before diving into the details, though, let’s write a function that will save
    typing later, as shown in [listing 11.1](#ch11ex01). It will create an output
    GeoTIFF with the same dimensions, geotransform, and projection as an existing
    dataset. The function will require five parameters: the existing dataset, the
    filename for the new dataset, a NumPy array containing data to write to the new
    image, an output data type, and an optional `NoData` value.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入细节之前，让我们编写一个函数，以便稍后可以节省输入，如[列表11.1](#ch11ex01)所示。该函数将创建一个与现有数据集具有相同维度、地理变换和投影的输出GeoTIFF。该函数需要五个参数：现有数据集、新数据集的文件名、包含要写入新图像的数据的NumPy数组、输出数据类型以及可选的`NoData`值。
- en: Listing 11.1\. Function to save a new raster
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.1\. 保存新栅格的函数
- en: '[PRE13]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This code has nothing new. All it does is create a new raster using information
    from the existing dataset and the provided data type, write the data into this
    new raster, and compute statistics. It then returns the new dataset. All of this
    code would need to be in the rest of the chapter listings, but this function will
    reduce it to one line. For the sake of convenience, it’s already in the ospybook
    module.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码没有新内容。它所做的只是使用现有数据集和提供的数据类型信息创建一个新的栅格，将数据写入这个新的栅格，并计算统计数据。然后返回新的数据集。所有这些代码都需要在章节的其余部分列表中，但这个函数将简化为一行。为了方便起见，它已经包含在ospybook模块中。
- en: 11.2.1\. Local analyses
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.2.1\. 局部分析
- en: Local map algebraic operations are probably the simplest to both understand
    and perform. They work on two or more arrays that are the same size, and an algebraic
    equation is applied to each set of pixel locations. [Figure 11.1](#ch11fig01)
    shows an example of a local calculation that adds two 2D arrays together. This
    is a simple example, but the operations can be much more involved if required.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 本地地图代数操作可能是最容易理解和执行的。它们作用于大小相同的两个或多个数组，并将代数方程应用于每一组像素位置。[图11.1](#ch11fig01)展示了将两个二维数组相加的局部计算示例。这是一个简单的示例，但如果需要，操作可以更加复杂。
- en: Figure 11.1\. Local map algebra calculations work on a pixel-by-pixel basis,
    so the equation applies to pixels that fall in the same spatial location.
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.1\. 本地地图代数计算是基于像素逐个进行的，因此该方程适用于落在相同空间位置的像素。
- en: '![](11fig01_alt.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图11.1](11fig01_alt.jpg)'
- en: Adding two rasters together may not seem useful at first, but it can be. For
    example, I remember helping with a project many years ago that used this technique
    to rank land for conservation efforts. A few input rasters were created that ranked
    locations by individual variables, such as distance to riparian areas. Areas within
    a certain distance to water had the highest rank, and other distance intervals
    had different ranks. Another input raster ranked areas on biodiversity, and another
    on distance to existing developments. There were six or seven of these datasets,
    all with a small number of rank categories. They were added together to find the
    locations with the highest overall rank, and therefore the most important for
    conservation efforts. This simple model was then turned into an interactive online
    tool that allowed people to change their rankings of the different variables.
    If a user selected a different ranking structure for a variable, a new raster
    to reflect those priorities was created and the appropriate rasters were added
    together to get a new overall importance map. This gave planners a simple tool
    for exploring different scenarios without knowing anything about GIS. I’m sure
    much more sophisticated models exist online today, but this was in the days before
    online mapping was common.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将两个栅格相加可能一开始看起来没有用，但实际上是有用的。例如，我记得多年前帮助过一个项目，该项目使用这种技术对土地进行保护工作排名。创建了几个输入栅格，根据单个变量（如到河岸地区的距离）对位置进行排名。距离水较近的区域排名最高，其他距离区间有不同的排名。另一个输入栅格根据生物多样性对区域进行排名，另一个根据到现有发展的距离进行排名。有六个或七个这样的数据集，所有这些数据集都有少量排名类别。它们被加在一起以找到整体排名最高的位置，因此对于保护工作来说是最重要的。然后，这个简单的模型被转换成了一个交互式在线工具，允许人们更改不同变量的排名。如果用户为某个变量选择了不同的排名结构，就会创建一个新的栅格来反映这些优先级，并将适当的栅格相加以获得新的整体重要性地图。这为规划者提供了一个简单的工具，用于探索不同的场景，而无需了解任何关于GIS的知识。我确信现在网上存在许多更复杂的模型，但这是在线地图变得普遍之前的那些日子。
- en: Local analysis can be used for plenty of other things as well. Another common
    task using multispectral imagery is to compute various indices for tasks such
    as distinguishing between burned and unburned land or measuring nitrogen contained
    in vegetation. Let’s look at an index used to measure “greenness,” the normalized
    difference vegetation index (NDVI). The NDVI is a simple index that uses red and
    near-infrared wavelengths to produce a number that ranges from -1 to 1\. Growing
    plants use red wavelengths for photosynthesis, but reflect near-infrared radiation,
    so a high ratio of these two measurements can indicate photosynthetic activity
    and healthy vegetation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 本地分析也可以用于许多其他事情。使用多光谱影像的另一个常见任务是计算各种指数，例如区分已烧毁和未烧毁的土地或测量植被中的含氮量。让我们看看用于测量“绿色度”的指数，即归一化植被指数（NDVI）。NDVI是一个简单的指数，它使用红色和近红外波长来产生一个范围从-1到1的数字。生长的植物使用红色波长进行光合作用，但反射近红外辐射，因此这两个测量值的高比率可以指示光合作用活动和健康的植被。
- en: '|  |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Note to Print Book Readers: Color Graphics'
  id: totrans-66
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意：打印书籍读者：彩色图形
- en: Many graphics in this book are best viewed in color. The eBook versions display
    the color graphics, so they should be referred to as you read. To get your free
    eBook in PDF, ePub, and Kindle formats, go to [https://www.manning.com/books/geoprocessing-with-python](https://www.manning.com/books/geoprocessing-with-python)
    to register your print book.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的许多图形最好以彩色查看。电子书版本显示彩色图形，因此在阅读时应参考。要获取免费电子书（PDF、ePub和Kindle格式），请访问[https://www.manning.com/books/geoprocessing-with-python](https://www.manning.com/books/geoprocessing-with-python)注册您的印刷版书籍。
- en: '|  |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Remember the near-infrared color composite from [chapter 9](kindle_split_017.html#ch09)
    that clearly showed that stadium turf was artificial? Let’s revisit that briefly
    in [figure 11.2](#ch11fig02). Here you can see the natural color, red band, near-infrared
    band, near-infrared composite, and NDVI images. The red, near-infrared, and NDVI
    images are of single bands, where brighter areas have higher values. Notice that
    the vegetation is dark in the red band image but bright in the near-infrared one.
    Vegetation is absorbing red light and reflecting near-infrared, and these pixel
    values measure the amount being reflected back to the sensor, the same way our
    eyes see what’s reflected back. The color infrared composite is a visual image
    only. Our eyes can see that vegetation appears red (unless you’re reading a black-and-white
    copy of this book, in which case it’s gray and doesn’t look much different from
    the natural color image), but that’s not useful if you want to use the data in
    an analysis. This is where the NDVI comes in. The practice fields in the NDVI
    image are bright, meaning they have high values and represent growing vegetation.
    The stadium field is dark, making it easy to determine that it’s artificial.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 记得第9章中提到的近红外彩色合成图像，它清楚地显示了体育场草坪是人工的吗？让我们简要回顾一下[图11.2](#ch11fig02)。在这里，您可以看到自然色彩、红色波段、近红外波段、近红外合成和NDVI图像。红色、近红外和NDVI图像是单波段，其中较亮的区域具有更高的值。请注意，植被在红色波段图像中是暗的，但在近红外波段中是亮的。植被吸收红光并反射近红外光，这些像素值测量反射回传感器的量，就像我们的眼睛看到反射回来的东西一样。彩色红外合成仅是一种视觉图像。我们的眼睛可以看到植被看起来是红色的（除非你在阅读这本书的黑白副本，在这种情况下它是灰色，看起来与自然色彩图像没有太大区别），但这在您想要在分析中使用数据时并不有用。这就是NDVI发挥作用的地方。NDVI图像中的练习场是明亮的，这意味着它们具有高值，代表生长的植被。体育场场地是暗的，这使得很容易确定它是人工的。
- en: Figure 11.2\. Different examples of looking at the same image in different ways.
    Image A is the natural color image composed of the red, green, and blue wavelengths,
    and B and C are single bands, where bright areas have higher pixel values. Image
    D is a visual representation that allows people to see what’s vegetation and what
    isn’t, but doesn’t help with data analysis. Image E, however, is a single NDVI
    band in which higher values represent growing vegetation. Not all differences
    are readily apparent in black and white, but a color version of this figure is
    available online.
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.2. 以不同方式查看同一图像的不同示例。图像A是由红色、绿色和蓝色波长组成的自然色彩图像，而B和C是单波段，其中明亮区域具有更高的像素值。图像D是一种视觉表示，让人们可以看到什么是植被，什么不是，但并不帮助数据分析。然而，图像E是一个单一的NDVI波段，其中较高的值表示生长的植被。并非所有差异在黑白中都一目了然，但该图的彩色版本可在网上找到。
- en: '![](11fig02_alt.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![11fig02_alt.jpg](11fig02_alt.jpg)'
- en: 'In the following example, you’ll calculate the NDVI that’s shown in [figure
    11.2](#ch11fig02)E. The formula is simple:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，您将计算[图11.2](#ch11fig02)E中显示的NDVI。公式很简单：
- en: '![](244equ01.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![244equ01.jpg](244equ01.jpg)'
- en: You can use NumPy to apply this equation to two arrays, where one holds the
    red values and the other the near-infrared. You already know how to read data
    into NumPy arrays, because you did it in [chapter 9](kindle_split_017.html#ch09).
    One potential problem exists, however. It’s possible for both the red and near-infrared
    pixels to have 0 values, in which case the denominator is also 0, and we all know
    that you can’t divide by 0\. This situation probably doesn’t exist in the example
    data we’re using, but if you’re using a satellite image you may have a large number
    of 0 values around the edges, and this becomes important.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用NumPy将此方程应用于两个数组，其中一个包含红色值，另一个包含近红外值。您已经知道如何将数据读入NumPy数组，因为您在[第9章](kindle_split_017.html#ch09)中已经这样做过了。然而，存在一个潜在问题。红色和近红外像素都可能有0值，在这种情况下，分母也是0，我们都知道不能除以0。在我们使用的示例数据中，这种情况可能不存在，但如果你使用卫星图像，你可能会在边缘附近有大量的0值，这变得很重要。
- en: 'You have several ways of dealing with this problem, and you might get different
    advice depending on who you talk to. The first is to proceed as if there were
    no problem, although I don’t suggest this approach. By default, NumPy will warn
    you that it ran into errors, but the rest of the calculations will be fine (you
    can change this behavior, however, so if your settings are different, then things
    might crash). However, the output will have invalid numbers for the pixels that
    couldn’t be calculated, so you’ll have to deal with that somehow. If both the
    numerator and denominator of the equation are equal to 0, then the output is the
    `np.nan` value, which stands for *not a number*. If only the denominator is 0,
    then the output is set to the `np.inf` value, which stands for *infinity*. If
    you leave these values in your dataset, not only will it affect your statistics
    calculations, but different software will treat the values differently. For these
    reasons, you’ll probably want to set the invalid pixels to `NoData` so that things
    are standardized. You could do that by checking for pixels equal to either of
    these values and replacing them with another number, like this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你有几种处理这个问题的方法，而且根据你与谁交谈，你可能会得到不同的建议。第一种方法是像没有问题一样继续进行，尽管我不建议这种方法。默认情况下，NumPy会警告你遇到了错误，但其余的计算将正常进行（然而，你可以更改这种行为，所以如果你的设置不同，那么事情可能会崩溃）。然而，对于无法计算像素，输出将包含无效的数字，所以你必须以某种方式处理这个问题。如果方程的分子和分母都等于0，则输出是`np.nan`值，表示*不是一个数字*。如果只有分母是0，则输出设置为`np.inf`值，表示*无穷大*。如果你在数据集中留下这些值，不仅会影响你的统计计算，而且不同的软件将按不同的方式处理这些值。出于这些原因，你可能希望将无效像素设置为`NoData`，以便标准化。你可以通过检查像素是否等于这两个值之一，并用另一个数字替换它们来实现这一点，如下所示：
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Then you would also set the `NoData` value for your output band to whatever
    number you used, in this case -99\. I like to use -99 because I know it isn’t
    a valid number for my use cases and it’s easy for me to remember, but software
    packages tend to use much larger numbers.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你也会将输出波段中的`NoData`值设置为你在该情况下使用的任何数字，例如-99。我喜欢使用-99，因为它不是我在用例中有效的数字，而且对我来说很容易记住，但软件包往往使用更大的数字。
- en: 'You might think you could deal with the problem by doing the calculation on
    only the pixels that don’t have 0 as a denominator, like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为你可以通过只对没有0作为分母的像素进行计算来解决这个问题，如下所示：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This will run faster than the first example, but you’ll still get division errors
    and risk a crash. At least you don’t have to check for `nan` or `inf`, because
    everywhere with a division by 0 will be assigned -99 during the calculation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这将比第一个例子运行得更快，但你仍然会遇到除法错误并可能崩溃。至少你不必检查`nan`或`inf`，因为所有进行除以0的地方在计算过程中都会被分配为-99。
- en: '|  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Tip
  id: totrans-82
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小贴士
- en: Change NumPy’s behavior when it encounters floating-point errors with the `numpy.seterr`
    function.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`numpy.seterr`函数更改NumPy遇到浮点错误时的行为。
- en: '|  |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: A better solution to the division by 0 problem is to use masked arrays, which
    allow you to completely ignore certain pixels during the calculation. This will
    get rid of the division errors, and also makes it explicit what pixels you’re
    ignoring. The idea is that you mask out the pixels that you want to ignore, do
    your calculations, and then fill in the missing pixels with your `NoData` value.
    Check out the following listing for an example of this in action.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 解决除以0问题的更好方法是使用掩码数组，这允许你在计算过程中完全忽略某些像素。这将消除除法错误，并明确指出你正在忽略哪些像素。想法是屏蔽掉你想要忽略的像素，进行计算，然后用你的`NoData`值填充缺失的像素。查看以下列表以获取此操作的示例。
- en: Listing 11.2\. Compute NDVI for a NAIP image
  id: totrans-86
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.2\. 计算NAIP图像的NDVI
- en: '![](246fig01_alt.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![246fig01_alt.jpg](246fig01_alt.jpg)'
- en: This example uses the same input image as that shown in [figure 11.2](#ch11fig02).
    This dataset is from the National Agriculture Imagery Program (NAIP), part of
    the United States Department of Agriculture. These aerial images are acquired
    periodically, with different states processed in different years. Although the
    visible red, green, and blue bands are always collected so that the images are
    natural color, sometimes a fourth, near-infrared band is also collected. That’s
    the case with the image used here. The first band is red light, and the fourth
    is near-infrared, which is why you read these two bands in at the beginning. Because
    the output is floating-point, you want to ensure that floating point math is used,
    so you convert the red band from byte to floating-point as you read it into the
    NumPy array.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例使用与[图11.2](#ch11fig02)中所示相同的输入图像。此数据集来自美国农业部国家农业影像计划（NAIP）。这些航空图像定期获取，不同州在不同年份进行处理。尽管始终收集可见的红、绿和蓝波段，以便图像为自然色，但有时也会收集第四个近红外波段。这里使用的图像就是这样。第一个波段是红光，第四个是近红外，这就是为什么你一开始就读取这两个波段。因为输出是浮点数，所以你想要确保使用浮点数进行数学运算，所以在将其读入NumPy数组时，将红波段从字节转换为浮点数。
- en: 'Once you have the data in memory, you mask out the red array in all locations
    where the sum of the two arrays is 0\. Although you could also mask the near-infrared
    data, you don’t need to because if one array has a masked value, then no computations
    happen on that pixel, so it doesn’t matter what value the other input arrays have.
    If you’d rather create a separate mask because you want to apply it to multiple
    arrays, you could do something like this instead:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据存储在内存中，你就在两个数组之和为0的所有位置屏蔽掉红数组。虽然你也可以屏蔽近红外数据，但不需要，因为如果一个数组有屏蔽值，那么该像素上就不会进行任何计算，所以其他输入数组有什么值都无关紧要。如果你更愿意创建一个单独的屏蔽，因为你想要将其应用于多个数组，你可以这样做：
- en: '[PRE16]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Once you mask out the bad pixels, you apply the NDVI equation to the two arrays
    to create a third one with valid NDVI values in most pixels, but with bad pixels
    masked out and containing no value. You want your output image to have `NoData`
    in those locations, so you fill those pixels in with -99 and then make sure to
    set -99 as the band’s `NoData` value later. All that’s left to do is save your
    new NDVI array to a new dataset with the same projection and geotransform as the
    original NAIP image.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦屏蔽掉坏像素，你将NDVI方程应用于两个数组，以创建一个包含大多数像素有效NDVI值的第三个数组，但屏蔽掉坏像素且不包含任何值。你希望你的输出图像在这些位置有`NoData`，所以用-99填充这些像素，然后确保稍后设置-99为波段的`NoData`值。剩下要做的就是将新的NDVI数组保存到与原始NAIP图像相同投影和地理变换的新数据集中。
- en: 11.2.2\. Focal analyses
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.2.2. 聚焦分析
- en: Focal analyses use the pixels that surround the target pixel in order to calculate
    a value. For a given cell in the output, the value is calculated based on the
    corresponding cell and its neighbors in the input dataset. This is also called
    a *moving window* analysis because you can think of it as “window” of cells centered
    on each pixel in turn. Once the value for the target pixel is calculated, the
    window moves to the next pixel. [Figure 11.3](#ch11fig03) shows how a 3 x 3 window
    would “move” across an image. The output values of the dark pixels are calculated
    using the nine surrounding lightly-shaded input pixels. These types of operations
    are common for smoothing data and removing random noise. In fact, you’ve probably
    used similar filters to touch up your own digital photos. Focal analyses can also
    be used for anything else that requires input from surrounding pixels, such as
    computing slope and aspect for an elevation dataset.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 聚焦分析使用围绕目标像素的像素来计算一个值。对于输出中的给定单元格，该值是基于输入数据集中相应单元格及其邻居的单元格计算的。这也被称为*移动窗口*分析，因为你可以将其视为“窗口”的单元格，依次以每个像素为中心。一旦计算了目标像素的值，窗口就移动到下一个像素。[图11.3](#ch11fig03)显示了3
    x 3窗口如何“移动”穿过图像。暗像素的输出值是使用九个周围浅色阴影输入像素计算的。这些类型的操作常用于平滑数据和去除随机噪声。实际上，你可能已经使用过类似的过滤器来修饰你自己的数码照片。聚焦分析还可以用于需要周围像素输入的任何其他事情，例如计算高程数据集的坡度和方位。
- en: Figure 11.3\. In a 3 x 3 moving window analysis, the output value for each dark
    pixel is calculated using the nine surrounding lightly-shaded input pixels.
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.3. 在3 x 3移动窗口分析中，每个暗像素的输出值是通过使用九个周围浅色阴影输入像素计算得出的。
- en: '![](11fig03.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图11.3](11fig03.jpg)'
- en: '[Figure 11.4](#ch11fig04) shows an example of a smoothing filter that computes
    the mean of a 3 x 3 moving window. The value of each output pixel is the average
    value of the nine surrounding pixels in the input. The exception to this is if
    the target pixel is on the edge, so that there aren’t a full nine surrounding
    pixels. In this particular example, the average of the available pixels is used,
    but you have many ways of dealing with the edge problem. In the figure, the shaded
    regions in the input (left) raster show the cells that are used to compute the
    output value for the corresponding shaded cells in the raster on the right.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11.4](#ch11fig04)显示了一个计算3 x 3移动窗口平均值的平滑滤波器示例。每个输出像素的值是输入中九个周围像素的平均值。例外情况是如果目标像素在边缘，那么就没有完整的九个周围像素。在这个特定例子中，使用可用像素的平均值，但你有很多处理边缘问题的方法。在图中，输入（左）光栅中的阴影区域显示了用于计算右侧光栅中相应阴影单元格输出值的单元格。'
- en: Figure 11.4\. A 3 x 3 moving window that calculates the average value of the
    nine surrounding pixels (or less if the target pixel is on the edge). The shaded
    areas correspond to the window of input pixels that produce one output pixel value.
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.4\. 一个3 x 3的移动窗口，计算九个周围像素（或更少，如果目标像素在边缘）的平均值。阴影区域对应于产生一个输出像素值的输入像素窗口。
- en: '![](11fig04.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图片](11fig04.jpg)'
- en: 'If the input data array from [figure 11.4](#ch11fig04) is called `indata` and
    the result is called `outdata`, then the upper shaded output pixel in the figure
    is computed like this:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果从[图11.4](#ch11fig04)的输入数据数组称为`indata`，结果称为`outdata`，那么图中上方的阴影输出像素的计算方式如下：
- en: '[PRE17]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This is the average of the nine surrounding pixels. Thankfully, you have a
    shorter way to write the same thing:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这是九个周围像素的平均值。幸运的是，你有更短的方式来写同样的事情：
- en: '[PRE18]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Using this information, you might be tempted to loop through the rows and columns
    of a raster to implement a moving window like this one, especially if you have
    background in a language such as C. To simplify and eliminate special cases where
    you don’t have nine input pixels, you might throw out the outer rows and columns,
    and then your code would be similar to this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些信息，你可能想遍历光栅的行和列来实现这样一个移动窗口，尤其是如果你有C语言等语言的背景。为了简化并消除没有九个输入像素的特殊情况，你可能扔掉外部的行和列，然后你的代码将类似于以下内容：
- en: '![](248fig01_alt.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图片](248fig01_alt.jpg)'
- en: This example would run, but it would be excruciatingly slow, and unless your
    raster was small, you’d wait a long time for the output. It’s a bad idea to implement
    looping like this on a NumPy array if you don’t absolutely have to. You’re much
    better off using array slices, and then your processing speed will be closer to
    the speed you could get with C. To do this, you need to create nine slices, each
    one corresponding to one of the nine input pixels, as shown in [figures 11.5](#ch11fig05)
    and [11.6](#ch11fig06). The first figure shows a small raster with six rows and
    columns, and the lightly shaded cells correspond to the slice specified with the
    text below each example. The dark outline defines the 3 x 3 window around the
    cell at index [2, 2].
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子会运行，但会非常慢，除非你的光栅很小，否则你会等待很长时间才能得到输出。如果你绝对不需要这样做，在NumPy数组上实现这样的循环是个坏主意。你最好使用数组切片，这样你的处理速度将接近你用C语言可以得到的速度。为此，你需要创建九个切片，每个切片对应于九个输入像素中的一个，如[图11.5](#ch11fig05)和[11.6](#ch11fig06)所示。第一个图显示了一个有六行六列的小光栅，浅阴影单元格对应于每个示例下方文本指定的切片。深轮廓定义了围绕索引[2,
    2]单元格的3 x 3窗口。
- en: Figure 11.5\. The slices that are used in a 3 x 3 moving window. Each example
    shows the same input data, but the lightly shaded cells are the slices defined
    by the text below the example. The dark outline defines the window around pixel
    [2, 2]. The darker shaded cells are all at index [1, 1] inside the corresponding
    slice.
  id: totrans-106
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.5\. 用于3 x 3移动窗口的切片。每个示例显示相同输入数据，但浅阴影单元格是示例下方文本定义的切片。深轮廓定义了围绕像素[2, 2]的3 x
    3窗口。较深的阴影单元格都在相应切片中的索引[1, 1]内。
- en: '![](11fig05_alt.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图片](11fig05_alt.jpg)'
- en: Figure 11.6\. The individual slices created in [figure 11.5](#ch11fig05), along
    with their sum and average. The shaded cells at index [1, 1] in each slice are
    the same cells as those in the outlined window in [figure 11.5](#ch11fig05), so
    averaging the slices is equivalent to averaging the cells in the window.
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.6\. 在[图11.5](#ch11fig05)中创建的各个切片，以及它们的总和和平均值。每个切片中的索引[1, 1]的阴影单元格与[图11.5](#ch11fig05)中轮廓窗口中的单元格相同，因此平均切片等同于平均窗口中的单元格。
- en: '![](11fig06_alt.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](11fig06_alt.jpg)'
- en: '[Figure 11.6](#ch11fig06) shows these same slices with the cell at index [1,
    1] highlighted. Compare the values of these highlighted pixels to the values of
    the pixels inside the dark outline in [figure 11.5](#ch11fig05). They’re the same,
    so if you take the average of the slices, the value at index [1, 1] will be the
    average of the nine pixels outlined in [figure 11.5](#ch11fig05). In fact, the
    output contains the average of all complete 3 x 3 windows in the original dataset.
    Again, this leaves the edge rows and columns out of the resulting data, for the
    sake of simplicity. You’d need to cut off more rows and columns from the edges
    for larger moving windows. For example, a 5 x 5 window would cut off two on each
    side instead of one.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[图11.6](#ch11fig06) 展示了这些相同的切片，其中索引为 [1, 1] 的细胞被突出显示。将这些突出像素的值与 [图11.5](#ch11fig05)
    中暗轮廓内像素的值进行比较。它们的值是相同的，因此如果你取切片的平均值，索引 [1, 1] 的值将是 [图11.5](#ch11fig05) 中轮廓的九个像素的平均值。实际上，输出包含原始数据集中所有完整的
    3 x 3 窗口的平均值。再次强调，为了简化，结果数据中排除了边缘行和列。对于更大的移动窗口，你需要从边缘裁剪更多的行和列。例如，一个 5 x 5 的窗口会在每边裁剪掉两个像素而不是一个。'
- en: 'You could create all nine slices, add them together, and then divide by 9,
    like this:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以创建所有九个切片，将它们相加，然后除以 9，就像这样：
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'That looks like a pain, but again, I have an easier way to do it. If the slices
    are all stacked into a three-dimensional array, then you can use the `mean` function,
    which would definitely be simpler. The `dstack` function will stack the slices
    on top of each other, which is what you need. But you still need to get all of
    the slices so you can pass them to `dstack`. You could type everything out again,
    but that isn’t any easier than before. Instead, you could use a loop to get each
    slice and add it to a list. To do this, you need to loop through three rows and
    three columns. Assuming that you use loop indices 0-2, the current index can be
    used as the row or column to start the slice. You know that when a slice starts
    at row 0, then it needs to end at 2 less than the number of rows. If you add 1
    to the starting index, then you need to add 1 to the ending index as well. Therefore,
    you can find the ending index by adding the starting index to the number rows
    minus 2:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来很麻烦，但同样，我有一个更简单的方法来做这件事。如果切片都被堆叠成一个三维数组，那么你可以使用 `mean` 函数，这肯定会更简单。`dstack`
    函数会将切片堆叠在一起，这正是你所需要的。但你还必须获取所有的切片，以便将它们传递给 `dstack`。你可以再次输入所有内容，但这并不比之前更容易。相反，你可以使用循环来获取每个切片并将其添加到一个列表中。为此，你需要遍历三行和三列。假设你使用的是索引
    0-2，当前索引可以用作切片的起始行或列。你知道当切片从行 0 开始时，它需要结束在行数减去 2 的位置。如果你将起始索引加 1，那么你也需要将结束索引加
    1。因此，你可以通过将起始索引加上行数减去 2 来找到结束索引：
- en: '[PRE20]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Not only does this require less typing, but it scales much easier to larger
    windows, as you’ll see in a bit. But now that you have a list of slices, you can
    stack them in the third dimension with the `dstack` function, which returns a
    three-dimensional array that can be used to compute means:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅这需要更少的输入，而且它更容易扩展到更大的窗口，就像你很快就会看到的那样。但现在你有了切片的列表，你可以使用 `dstack` 函数在第三维上堆叠它们，这将返回一个三维数组，可以用来计算平均值：
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: By default, the `mean` function returns the mean of all pixels in the array,
    but you want the mean calculated for each set of pixels in a single spatial location,
    like a local analysis. To do this, tell the function which axis you’d like the
    mean calculated on. The third dimension is axis 2, so if you specify that, you’ll
    get an array with the same numbers of rows and columns as the stacked array, with
    the value of each cell being the mean of the nine slices in that location. The
    slices have two less rows and columns than the original data set, however, so
    you create a zero-filled array the same size as the original data, and then insert
    the array containing the means into the middle of it, cutting off a row and column
    on each side.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`mean` 函数返回数组中所有像素的平均值，但你想计算单个空间位置中像素集的平均值，就像局部分析一样。为此，告诉函数你希望计算平均值的哪个轴。第三维是轴
    2，所以如果你指定这个轴，你将得到一个与堆叠数组具有相同行和列数的数组，每个单元格的值是该位置九个切片的平均值。然而，切片比原始数据集少两行和两列，因此你创建一个与原始数据大小相同的零填充数组，然后将包含平均值数组的数组插入其中，每边裁剪掉一行和一列。
- en: This method of getting the nine slices can be easily generalized into a function
    that will return slices of any size you want (well, as long as the dimensions
    are odd numbers—even numbers don’t work well because there’s no middle cell).
    This function, which is in the ospybook module, is shown in the next listing.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这种获取九个切片的方法可以很容易地推广成一个函数，该函数可以返回你想要的任何大小的切片（嗯，只要维度是奇数——偶数效果不好，因为没有中间单元格）。这个函数位于ospybook模块中，将在下一个列表中展示。
- en: Listing 11.3\. Function to get slices of any size from an array
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.3. 从数组中获取任何大小的切片的函数
- en: '![](251fig01_alt.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图片](251fig01_alt.jpg)'
- en: Now you can use everything you’ve learned so far to run an average smoothing
    filter on an elevation dataset. [Figure 11.7](#ch11fig07) shows a DEM of the area
    surrounding Mt. Everest. For some reason, a seamline runs right through the middle,
    and the northern half looks better than the southern half. I thought that perhaps
    smoothing the dataset would make the seamline less obvious. Whether it did or
    not is open to debate, but the smoothed image does look different from the original.
    This is especially obvious in the northern part of the image, where the contours
    are less distinct in the smoothed version. The following listing shows the code
    to apply the filter.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以使用到目前为止所学的一切来对一个高程数据集运行平均平滑滤波器。[图11.7](#ch11fig07)显示了珠穆朗玛峰周围地区的DEM。由于某种原因，一条接缝线正好穿过中间，北部看起来比南部好。我想也许平滑数据集会使接缝线不那么明显。不管是否真的做到了，这是否值得讨论，但平滑后的图像确实与原始图像不同。这在图像的北部尤其明显，在平滑版本中，等高线不那么明显。下面的列表显示了应用该滤波器的代码。
- en: Figure 11.7\. A digital elevation model of the area surrounding Mt. Everest,
    along with a version that has been smoothed using a 3 x 3 moving average filter
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.7. 珠穆朗玛峰周围地区的数字高程模型，以及使用3 x 3移动平均滤波器平滑后的版本
- en: '![](11fig07_alt.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图片](11fig07_alt.jpg)'
- en: Listing 11.4\. Smooth an elevation dataset
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.4. 平滑高程数据集
- en: '![](252fig01_alt.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图片](252fig01_alt.jpg)'
- en: Although it took a while to work up to it, the filtering code turned out to
    be simple. You use your `make_slices` function to create the nine slices, stack
    them into a three-dimensional array, and then use the `mean` function to calculate
    the average across the third dimension. Because the slices are smaller than the
    original data, you put the result into the middle of an array of the correct size
    that has already been initialized to the `NoData` value. This ensures that the
    ignored edges are set to `NoData`, as long as you remember to pass that value
    to the `make_raster` function.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然达到这个目标花了一些时间，但过滤代码最终变得很简单。你使用`make_slices`函数创建九个切片，将它们堆叠成一个三维数组，然后使用`mean`函数计算第三维的平均值。因为切片比原始数据小，所以你将结果放入一个已经初始化为`NoData`值的正确大小的数组中间。只要记得将这个值传递给`make_raster`函数，就可以确保忽略的边缘被设置为`NoData`。
- en: Nothing is stopping you from applying much more complicated functions to the
    cells that make up the moving window. In fact, this is exactly what you’d want
    to do for many analyses. One example is computing slope from an elevation model.
    Several algorithms calculate slope, and one of them is shown in [figure 11.8](#ch11fig08).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何东西阻止你将更复杂的函数应用到组成移动窗口的单元格上。实际上，这正是许多分析所希望做的。一个例子是从高程模型计算斜率。有几个算法可以计算斜率，其中一个在[图11.8](#ch11fig08)中展示。
- en: Figure 11.8\. The algorithm for computing the slope of cell e from elevation
    values in the surrounding cells
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.8. 从周围单元格的高程值计算单元格e的斜率的算法
- en: '![](11fig08.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图片](11fig08.jpg)'
- en: The next listing shows code for calculating the slope of the Mt. Everest DEM
    using these equations. Note that for this algorithm to work properly, the elevation
    units must be the same as the horizontal ones. For example, if your dataset uses
    a UTM projection, then the coordinates are expressed in meters, so the elevation
    values must also be meters.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表显示了使用这些方程计算珠穆朗玛峰DEM斜率的代码。请注意，为了使此算法正常工作，高程单位必须与水平单位相同。例如，如果你的数据集使用UTM投影，那么坐标以米为单位表示，因此高程值也必须是米。
- en: Listing 11.5\. Compute slope from DEM
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.5. 从DEM计算斜率
- en: '![](ch11ex05-0.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图片](ch11ex05-0.jpg)'
- en: '![](ch11ex05-1.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](ch11ex05-1.jpg)'
- en: This is more complicated than the smoothing example, but it’s still not too
    bad. Most of it is made up of calculating the slope. You do need to know the order
    that the slices are stored in the `slices` list to use the correct one in each
    part of the equation, however. The `make_slices` function returns them in the
    same order as if you were reading left to right and down, or in other words, in
    alphabetical order if you refer to [figure 11.8](#ch11fig08). Unlike the smoothing
    example, in this case you don’t stack the slices into a three-dimensional array
    because you need to reference them individually in the slope equations. Again,
    you make sure that the edges are set to the `NoData` value. The output looks like
    that shown in [figure 11.9](#ch11fig09).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这比平滑示例要复杂一些，但还不算太糟糕。大部分工作都是计算斜率。不过，你需要知道切片在`slices`列表中的存储顺序，以便在方程的每一部分使用正确的切片。`make_slices`函数会按照从左到右和从上到下的顺序返回它们，换句话说，如果参考[图11.8](#ch11fig08)，则是按字母顺序。与平滑示例不同，在这种情况下，你不需要将切片堆叠成三维数组，因为需要在斜率方程中单独引用它们。再次强调，确保边缘设置为`NoData`值。输出看起来就像[图11.9](#ch11fig09)中所示的那样。
- en: Figure 11.9\. The original Mt. Everest DEM and a slope raster derived from it
  id: totrans-135
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.9\. 原始珠穆朗玛峰DEM及其派生的坡度栅格
- en: '![](11fig09_alt.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](11fig09_alt.jpg)'
- en: Using SciPy for focal analysis
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用SciPy进行焦点分析
- en: SciPy is a versatile Python module designed for scientific data analysis, and
    it uses NumPy arrays to store large amounts of data. It has submodules for interpolation,
    Fourier transforms, linear algebra, statistics, signal processing, and image processing,
    among others. The multidimensional image processing submodule contains filtering
    functions that can be used to perform the same operations you did with NumPy.
    It’s probably easier to use SciPy than NumPy, but hopefully now you understand
    enough about working with NumPy arrays that you can figure out how to solve other
    problems that you might run into.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: SciPy是一个多功能的Python模块，旨在用于科学数据分析，它使用NumPy数组来存储大量数据。它包含子模块，如插值、傅里叶变换、线性代数、统计学、信号处理和图像处理等。多维图像处理子模块包含可以执行与使用NumPy相同的操作的过滤函数。使用SciPy可能比使用NumPy更容易，但希望你现在对使用NumPy数组的工作已经足够了解，可以找出如何解决你可能遇到的其他问题。
- en: One advantage to using SciPy is that it will handle the edge problems for you
    by filling in extra cells around the edges so that the calculations can be performed
    on all cells. It has several different ways of populating these extra pixels,
    and you can decide which one you want to use. The default is the “reflect” mode,
    which repeats the values near the edge, but in the opposite order. You can also
    use the nearest value, a constant value of your own choosing, or a few other value-repeating
    methods.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SciPy的一个优点是它会通过填充边缘周围的额外单元格来为你处理边缘问题，这样就可以在所有单元格上执行计算。它有几种不同的方法来填充这些额外像素，你可以决定使用哪一种。默认模式是“反射”模式，它会以相反的顺序重复边缘附近的值。你也可以使用最近的值、你选择的常数值或一些其他值重复方法。
- en: One of the built-in filters in SciPy is a uniform filter, which is a smoothing
    filter that works the same as the smoothing filter from [listing 11.4](#ch11ex04).
    This next listing shows how you use it.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: SciPy中内置的一个过滤器是均匀滤波器，它是一个与[列表11.4](#ch11ex04)中的平滑滤波器工作方式相同的平滑滤波器。接下来的列表显示了如何使用它。
- en: Listing 11.6\. Smoothing filter using SciPy
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.6\. 使用SciPy的平滑滤波器
- en: '![](255fig01_alt.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](255fig01_alt.jpg)'
- en: As you can see, running the actual filter only requires one line of code, and
    the rest of it is dealing with reading and writing the data. The only required
    argument to `uniform_filter` is the NumPy array containing the data to smooth,
    but you have several optional parameters. You use two of them here. The `size`
    parameter specifies the size of the moving window to use, and you don’t really
    need to use it here because the default value is 3 anyway. You also use the `mode`
    parameter to change the method of dealing with the edges so that the closest pixel
    values are used to fill in the edges.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，运行实际滤波器只需要一行代码，其余的都是处理读取和写入数据。`uniform_filter`函数的唯一必需参数是包含要平滑数据的NumPy数组，但你还有几个可选参数。你在这里使用了其中两个。`size`参数指定了要使用的移动窗口的大小，实际上你在这里并不需要使用它，因为默认值已经是3。你还使用`mode`参数来更改处理边缘的方法，以便使用最近的像素值来填充边缘。
- en: Other built-in filters exist, including minimum, maximum, and median values.
    But what about more complicated situations such as the slope calculation? All
    you need to do is create a function that performs the calculation that you want
    and then pass that to a generic filter function, as shown in the following listing.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 存在其他的内置过滤器，包括最小值、最大值和中值。但对于更复杂的情况，比如斜率计算，该怎么办呢？你所需要做的就是创建一个执行你想要计算的功能的函数，然后将它传递给一个通用过滤器函数，如下面的列表所示。
- en: Listing 11.7\. Calculate slope using SciPy
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.7\. 使用 SciPy 计算斜率
- en: '![](ch11ex07-0.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![ch11ex07-0.jpg](ch11ex07-0.jpg)'
- en: '![](ch11ex07-1.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![ch11ex07-1.jpg](ch11ex07-1.jpg)'
- en: The first thing you do is write a custom filter function called `slope` that
    contains the exact same math as before, so it should look familiar. The first
    argument to your filter function must be a one-dimensional array of data that
    will be used for the calculation. Conveniently, the cell values will be in the
    same order that you used earlier with your `make_slices` function. The first value
    is the upper-left pixel, the second is the upper-middle pixel, and so on, until
    ending with the lower-right pixel. If you need it to, your function can also take
    additional parameters, but this isn’t a requirement for custom filters. In this
    case, you need to know the pixel dimensions for the slope calculation, so your
    function also requires pixel width and height.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先需要编写一个名为 `slope` 的自定义过滤器函数，它包含与之前完全相同的数学公式，因此应该看起来很熟悉。你的过滤器函数的第一个参数必须是一个一维数据数组，该数组将用于计算。方便的是，单元格值将与你在之前的
    `make_slices` 函数中使用的顺序相同。第一个值是左上像素，第二个是上中像素，以此类推，直到结束于右下像素。如果你的函数需要，它也可以接受额外的参数，但这不是自定义过滤器的必需要求。在这种情况下，你需要知道斜率计算所需的像素尺寸，因此你的函数还需要像素宽度和高度。
- en: Once you have your custom filter function, you provide it as a parameter when
    calling the SciPy `generic_filter` function. The first argument to `generic_filter`
    is the NumPy array containing data to filter and the second is the filter function
    to use. These are the only required parameters, but once again, you can use optional
    ones. In this case, you specify a 3 x 3 moving window, but it’s possible to use
    different sizes, or even use a Boolean array to indicate exactly which cell values
    to pass to your filter. You can read more about this in the SciPy documentation.
    Once again, you change the default method of dealing with the array edges, and
    finally, you provide a tuple containing the extra arguments that your function
    requires. The `generic_filter` function passes the appropriate pixel values to
    your function to calculate each output cell value.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了自定义的过滤器函数，你可以在调用 SciPy 的 `generic_filter` 函数时将其作为参数提供。`generic_filter`
    的第一个参数是包含要过滤数据的 NumPy 数组，第二个是使用的过滤器函数。这些是唯一必需的参数，但同样，你也可以使用可选参数。在这种情况下，你指定了一个
    3 x 3 的移动窗口，但也可以使用不同的大小，甚至可以使用布尔数组来精确指示要传递给过滤器的哪些单元格值。你可以在 SciPy 文档中了解更多相关信息。再次强调，你改变了处理数组边界的默认方法，最后，你提供了一个包含你的函数所需的额外参数的元组。`generic_filter`
    函数将适当的像素值传递给你的函数以计算每个输出单元格的值。
- en: Breaking up focal analyses
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 分解焦点分析
- en: What if you want to do a moving window analysis but don’t have enough RAM to
    hold everything in memory? You can break the image up into chunks, but instead
    of processing discrete sets of data, have them overlap each other. [Figure 11.10](#ch11fig10)
    shows an example of reading in multiple rows at a time using a step parameter
    of 5\. More than five rows get read in each time, though, because of the overlap.
    The dark outlines show the rows that are processed, and the shaded areas are the
    cells that get valid data in that iteration. Because this is a 3 x 3 window, it
    has one empty row and column on each side. The idea is to tack one row on the
    top and one on the bottom of each chunk so that every row ends up with valid data.
    The first time through, one extra row is added at the bottom so six rows get processed
    instead of five. The second time through, two extra rows are processed. To get
    an extra row at the top, the starting offset is moved to an earlier row. For example,
    with a step value of 5, the second iteration would normally start reading at row
    5, but instead it starts at row 4 in this example. The third time through is similar,
    except that the available rows are limited so only four are read in. You can see
    that all of the rows except the top and bottom end up with valid data.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想进行移动窗口分析，但没有足够的RAM来在内存中存储所有内容，怎么办？您可以拆分图像为块，但不是处理离散的数据集，而是让它们相互重叠。[图11.10](#ch11fig10)展示了使用步长参数为5一次读取多行的一个示例。然而，由于重叠，每次读取的行数超过五行。深色轮廓显示了被处理的行，而阴影区域是那一迭代中获得有效数据的单元格。因为这是一个3
    x 3的窗口，所以每边都有一个空行和列。想法是在每个块的顶部和底部各添加一行，以便每行最终都有有效数据。第一次通过时，底部添加了一行额外的数据，因此处理了六行而不是五行。第二次通过时，处理了两行额外的数据。为了在顶部获得额外的一行，起始偏移量被移动到一个更早的行。例如，对于步长值为5，第二次迭代通常从第5行开始读取，但在这个例子中，它从第4行开始。第三次通过类似，但可用的行数有限，因此只读取了四行。您可以看到，除了顶部和底部之外的所有行最终都获得了有效数据。
- en: Figure 11.10\. Breaking up an image into overlapping chunks. The thick outlines
    show the cells read from disk, and the shaded cells are the ones that get valid
    data and are written to the output.
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.10\. 将图像拆分为重叠的块。粗轮廓显示了从磁盘读取的单元格，而阴影单元格是获得有效数据并写入输出的单元格。
- en: '![](11fig10_alt.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](11fig10_alt.jpg)'
- en: Although the Everest dataset is small, pretend for a moment that it’s too large
    to process all at once, but you have enough RAM to process approximately 100 rows
    at a time. The following listing shows how you could do this.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Everest数据集很小，但请暂时假设它太大，无法一次性处理，但您有足够的RAM来一次处理大约100行。以下列表显示了您如何做到这一点。
- en: Listing 11.8\. Focal analysis broken into chunks
  id: totrans-155
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.8\. 分块进行焦点分析
- en: '![](ch11ex08-0.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](ch11ex08-0.jpg)'
- en: '![](ch11ex08-1.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](ch11ex08-1.jpg)'
- en: Much of this resembles code you’ve written before. Remember that you’re going
    to read in two extra rows if possible, so you need to take those extra rows into
    account when checking if enough rows exist to read an entire chunk. You also make
    sure you don’t try to use -1 as a row offset in the first iteration. Once you
    determine how many rows to grab, you read them in and process them as before.
    For all but the first chunk, though, you make sure not to write the first row
    of the processed data to the output. If you had, it would’ve overwritten the good
    data written during the previous iteration. Because you’re ignoring this first
    row, you also have to increase the row offset you use for writing.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这大部分与您之前编写的代码相似。请记住，如果可能的话，您将读取两行额外的数据，因此在检查是否有足够的行来读取整个块时，需要考虑这些额外的行。您还确保在第一次迭代中不要尝试使用-1作为行偏移。一旦确定要抓取的行数，您就按之前的方式读取并处理它们。但是，对于除了第一个块之外的所有块，您确保不要将处理后的数据的第一行写入输出。如果您这样做了，它将覆盖之前迭代中写入的好数据。因为您正在忽略这一行，所以您还必须增加用于写入的行偏移量。
- en: 11.2.3\. Zonal analyses
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.2.3\. 区域分析
- en: Zonal analyses work on cells that share a certain value, or belong to the same
    zone. The zones are usually defined by one raster and the analysis performed using
    values from a second one. For example, if you have a raster showing land ownership
    categories such as federal, state, and private, and a second raster showing landcover,
    you could use the ownership categories as zones to determine the acreage of each
    landcover type within each ownership category, as shown in [figure 11.11](#ch11fig11).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 区域分析作用于具有特定值或属于同一区域的单元格。区域通常由一个栅格定义，分析使用来自第二个栅格的值进行。例如，如果你有一个显示土地所有权类别（如联邦、州和私人）的栅格，以及一个显示土地覆盖的第二个栅格，你可以使用所有权类别作为区域来确定每个土地覆盖类型在每个所有权类别中的面积，如图11.11所示。
- en: Figure 11.11\. An example of a zonal analysis using ownership and landcover
    type. The number of pixels for each landcover are counted per ownership zone.
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.11. 使用所有权和土地覆盖类型进行区域分析的示例。每个土地覆盖类型的像素数按所有权区域计数。
- en: '![](11fig11.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图11.11](11fig11.jpg)'
- en: 'First let’s look at how you could do this with NumPy and then a more flexible
    method using SciPy. What you want here is basically a two-dimensional histogram.
    A regular histogram gives you the number of items in each bin, but in this case,
    you want to treat zones as one set of bins and landcover as another set of bins,
    and then get the count for each combination of zone and landcover bin. There are
    several ways you can define your bins, including letting NumPy do it for you,
    but here you’ll see how to do it yourself. A set of bins is defined by an array
    of bin edges. The first number in the array is the lower bound for the first bin,
    the second number is the upper, non-inclusive bound for the first bin and also
    the lower, inclusive bound for the second bin, and so on. The last number in the
    array is the upper bound of the last bin. One easy way to get the bins for this
    particular use case is to get the unique values in the dataset. The NumPy `unique`
    function returns these values in sorted order. Because the lower bound is inclusive,
    this list of numbers would create the lower bound for bins corresponding to the
    dataset values. All that’s left is to add a larger number to the end to form the
    upper bound for the last bin. The following function creates this array of bin
    edges for you:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看如何使用NumPy来完成这项工作，然后是一个更灵活的方法，使用SciPy。你在这里想要的基本上是一个二维直方图。常规直方图给你每个区间的项目数，但在这个例子中，你想要将区域视为一组区间，将土地覆盖视为另一组区间，然后获取每个区域和土地覆盖区间组合的计数。你可以定义区间的几种方法，包括让NumPy为你做，但在这里，你会看到如何自己完成。一组区间由一个包含区间边界的数组定义。数组中的第一个数字是第一个区间的下限，第二个数字是第一个区间的上限（非包含），也是第二个区间的下限（包含），依此类推。数组中的最后一个数字是最后一个区间的上限。获取此特定用例的区间的简单方法是从数据集中获取唯一值。NumPy的`unique`函数按排序顺序返回这些值。因为下限是包含的，所以这个数字列表将创建与数据集值对应的区间的下限。剩下要做的就是向末尾添加一个更大的数字来形成最后一个区间的上限。以下函数为你创建这个区间边界的数组：
- en: '[PRE22]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now that you know how to define bins, let’s see how to use them with the NumPy
    `histogram2d` function to get the counts. The two required parameters for this
    function are the two arrays containing values to bin, and one of the optional
    arguments lets you specify the bins you want to use. If the values from the upper-left
    dataset shown in [figure 11.11](#ch11fig11) are in an array called `zones`, and
    the values from the upper-right dataset are in an array called `landcover`, then
    you can get the two-way histogram like this:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何定义区间，让我们看看如何使用NumPy的`histogram2d`函数来获取计数。此函数的两个必需参数是包含要分箱的值的两个数组，其中一个可选参数允许你指定你想要使用的区间。如果[图11.11](#ch11fig11)中显示的右上角数据集的值在一个名为`zones`的数组中，而右上角数据集的值在一个名为`landcover`的数组中，那么你可以这样得到一个双向直方图：
- en: '[PRE23]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Notice a couple of things here. First, the `histogram2d` function wants the
    data arrays to be one-dimensional, and the `flatten` function takes care of that
    detail. The `histogram2d` function returns three values: a two-dimensional histogram
    and two sets of bins, one for each input array. The histogram rows correspond
    to the bins from the first array passed in, and the columns correspond to the
    second. In this case, the two bin outputs will be exactly what you pass in, but
    if you don’t explicitly define your bins, then these two return values would tell
    you what bins were used for the calculation.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这里的一些事项。首先，`histogram2d` 函数需要数据数组为一维的，而 `flatten` 函数负责处理这个细节。`histogram2d`
    函数返回三个值：一个二维直方图和两组bins，每组对应一个输入数组。直方图的行对应于传入的第一个数组的bins，列对应于第二个。在这种情况下，这两个bins输出将正好是你传入的值，但如果你没有明确定义你的bins，那么这两个返回值将告诉你用于计算的bins是什么。
- en: If you have SciPy, you can accomplish this same thing with a more general SciPy
    function called `stats.binned_statistic_2d`. The following listing shows you how
    to use this to count up the number of pixels with each landcover class in each
    ecoregion zone shown in [figure 11.12](#ch11fig12).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你安装了SciPy，你可以使用一个更通用的SciPy函数`stats.binned_statistic_2d`来完成相同的事情。下面的列表展示了如何使用这个函数来计算每个ecoregion区域中每个landcover类像素的数量，如[图11.12](#ch11fig12)所示。
- en: Figure 11.12\. SWReGAP landcover classification with ecoregion boundaries drawn
    on top
  id: totrans-169
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.12. 在SWReGAP土地覆盖分类上绘制ecoregion边界
- en: '![](11fig12.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图11.12](11fig12.jpg)'
- en: Listing 11.9\. Zonal analysis with SciPy
  id: totrans-171
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.9. 使用SciPy进行区域分析
- en: '![](ch11ex09-0.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图11.12](ch11ex09-0.jpg)'
- en: '![](ch11ex09-1.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图11.12](ch11ex09-1.jpg)'
- en: The first thing you do is read in the ecoregion and landcover datasets as flattened,
    one-dimensional arrays (because this function, like `histogram2d`, requires single-dimension
    arrays), and also calculate the required bins for each dataset. Then you create
    your histogram using the `binned_statistic_2d` function. The first two parameters
    are the same as the `histogram2d` function, namely, the two datasets that will
    be binned. Unlike `histogram2d`, this function can not only count occurrences
    but also calculate statistics, so it also requires a third array containing the
    values to calculate statistics on. Because you count the number of pixels, it
    doesn’t matter if you use landcover or ecoregions in this case, but you use landcover.
    The next parameter to the function specifies which statistic you want to calculate,
    which is “count” in this case (other options are mean, median, sum, or a custom
    function that you provide). But you could do something like calculate the mean
    elevation in each combination of ecoregion and landcover by passing an elevation
    dataset as the third parameter and “mean” as the fourth. Anyway, you provide the
    bin boundaries as the last argument, the way you did before. This returns the
    same outputs as the histogram function, along with one extra one that indicates
    which bin the data value fell into.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先需要将ecoregion和landcover数据集作为展平的一维数组读入（因为这个函数，就像`histogram2d`，需要单维数组），并且计算每个数据集所需的bins。然后，你使用`binned_statistic_2d`函数创建你的直方图。前两个参数与`histogram2d`函数相同，即将要分组的两个数据集。与`histogram2d`不同，这个函数不仅可以计数出现次数，还可以计算统计数据，因此它还需要一个包含要计算统计数据的值的第三个数组。由于你计算像素的数量，在这种情况下，使用landcover或ecoregions无关紧要，但这里使用landcover。函数的下一个参数指定你想要计算哪个统计数据，在这种情况下是“count”（其他选项是平均值、中位数、总和或你提供的自定义函数）。但你可以通过传递一个包含高程数据集的第三个参数和“mean”作为第四个参数来计算每个ecoregion和landcover组合的平均高程。无论如何，你提供bin边界作为最后一个参数，就像你之前做的那样。这会返回与直方图函数相同的输出，以及一个额外的输出，指示数据值落在哪个bins中。
- en: This time you also get ambitious and add several bin labels to your histogram.
    Because the different landcovers are the columns, you use those bins as the column
    labels. Remember that the last item in the bins array is the upper bound and isn’t
    needed to label your bins. You insert all but the last number in the landcover
    bins array as the first row of the histogram. The `insert` function wants the
    data being inserting into, the index to insert at, the data to insert, and the
    axis, where 0 means a row. You use the same idea to insert the ecoregion bins
    as row labels, except that you have to add a placeholder for the first row, which
    is now landcover labels. You insert 0 at the beginning and then use axis 1 to
    insert a column at the beginning of your histogram.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这次你野心勃勃，还给你的直方图添加了几个箱标签。因为不同的土地覆盖是列，所以你使用这些箱作为列标签。记住，箱数组中的最后一个项目是上限，不需要用来标记你的箱。你将土地覆盖箱数组中除了最后一个数字之外的所有数字插入到直方图的第一行。`insert`
    函数需要插入的数据，插入的位置索引，要插入的数据，以及轴，其中 0 表示一行。你使用相同的方法将生态区箱插入为行标签，除了你必须在现在为土地覆盖标签的第一行添加一个占位符。你在开始处插入
    0，然后使用轴 1 在你的直方图开始处插入一列。
- en: If you wanted to know the area instead of pixel count, you could multiply the
    histogram array by the area of a pixel before adding the label row and column.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要知道面积而不是像素计数，你可以在添加标签行和列之前将直方图数组乘以像素的面积。
- en: Once your table is complete, you write it out to a text file. The `fmt` parameter
    to `savetxt` specifies how you want the numbers formatted in the output. Without
    this, you’d probably get scientific notation; nothing is wrong with that, but
    here you specify integers instead. The `%` is the first character of a format
    string, the `1` means you want it to print out at least one digit, the `.0` means
    no numbers after the decimal point, and `f` means that it will be getting a floating-point
    number to work with. For more information on format strings, please see the NumPy
    documentation for `savetxt` at [http://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html](http://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的表格完成，你就将其写入一个文本文件。`savetxt` 函数的 `fmt` 参数指定了你在输出中希望数字的格式。如果没有这个参数，你可能会得到科学记数法；这并没有什么问题，但在这里你指定了整数。`%`
    是格式字符串的第一个字符，`1` 表示你希望至少打印出一个数字，`.0` 表示小数点后没有数字，而 `f` 表示它将处理一个浮点数。有关格式字符串的更多信息，请参阅
    NumPy 文档中关于 `savetxt` 的部分，网址为 [http://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html](http://docs.scipy.org/doc/numpy/reference/generated/numpy.savetxt.html)。
- en: Your output should look something like [figure 11.13](#ch11fig13).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 你的输出应该类似于 [图 11.13](#ch11fig13)。
- en: Figure 11.13\. The first few columns of the histogram output. The first column
    specifies the ecoregion (255 is `NoData` cells), and the top row specifies the
    landcover category. All other values are cell counts.
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.13. 直方图输出的前几列。第一列指定了生态区（255 是 `NoData` 单元），而最上面一行指定了土地覆盖类别。所有其他值都是单元格计数。
- en: '![](11fig13_alt.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![11图13替代](11fig13_alt.jpg)'
- en: 'What if you wanted to know the most common landcover type in each ecoregion
    but didn’t care about counts? In this case, you could use the one-dimensional
    `binned_statistic` function instead, because you only need to bin one ecoregion.
    Unfortunately, mode isn’t one of the supported statistics types, but you can provide
    your own statistical function. All you need to do is write a simple function that
    returns the mode and then pass it to `binned_statistic`, like this:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道每个生态区中最常见的土地覆盖类型，但不关心计数，你可以使用一维的 `binned_statistic` 函数，因为你只需要对一个生态区进行分箱。不幸的是，模式不是支持的统计类型之一，但你可以提供自己的统计函数。你只需要编写一个简单的函数，该函数返回模式，然后将它传递给
    `binned_statistic`，如下所示：
- en: '[PRE24]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: You can use this technique to calculate whatever information you want, as long
    as it can be computed from a one-dimensional array.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用这种技术来计算你想要的信息，只要它能从一维数组中计算出来。
- en: 11.2.4\. Global analyses
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.2.4. 全球分析
- en: Global functions work on the entire image, such as proximity analysis or cost
    distance. A *proximity analysis* determines the Euclidean distance of each cell
    to the nearest cell that’s marked as a source, while *cost distance* determines
    the least cost of traveling between each cell and the nearest source, as determined
    by a cost surface. For example, if you’re walking between two points in the mountains,
    the easiest, and therefore least costly path, may not be the shortest. In this
    case, the cost surface might be derived from elevation and slope rasters, and
    cells on a mountain pass would have a lower cost than cells on steep ridges.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 全局函数在整个图像上工作，例如邻近分析或成本距离。*邻近分析*确定每个单元格到最近标记为源单元格的欧几里得距离，而*成本距离*确定每个单元格与最近源单元格之间旅行的最低成本，该成本由成本表面确定。例如，如果你在山脉之间行走，最简单、因此成本最低的路径可能不是最短的。在这种情况下，成本表面可能来自高程和坡度栅格，而山口上的单元格的成本会比陡峭的山脊上的单元格低。
- en: GDAL has global analysis functions built in, and you’re about to see how to
    use several of them to determine the distance to the nearest road for areas in
    the Frank Church—River of No Return Wilderness in Idaho ([figure 11.14](#ch11fig14)).
    You’ll start off with a state-wide roads shapefile and a shapefile showing wilderness
    boundaries. Several polygons make up this wilderness area, so you’ll select them
    out, get the extent of the selected polygons, and use that rectangle to select
    the roads you’re interested in. Then you can use GDAL to create a raster that
    has ones where there are roads and zeros everywhere else. This will be used as
    a source layer in order to determine distances from roads to every other pixel.
    The following listing shows how to accomplish all of this. The listing is long,
    but that’s because the data haven’t been preprocessed.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: GDAL 内置了全局分析函数，你将看到如何使用其中几个函数来确定爱达荷州弗兰克·奇奇-无回报河荒野区域内区域到最近道路的距离（[图 11.14](#ch11fig14)）。你将从州级道路形状文件和一个显示荒野边界形状文件开始。这个荒野区域由几个多边形组成，所以你需要选择它们，获取所选多边形的范围，并使用该矩形选择你感兴趣的路线。然后你可以使用
    GDAL 创建一个栅格，其中包含有道路的地方为 1，其他地方为 0。这将被用作源图层，以确定从道路到每个其他像素的距离。下面的列表显示了如何完成所有这些。列表很长，但这是因为数据尚未预处理。
- en: 'Figure 11.14\. Data used for calculating average distance to roads within a
    wilderness area. A: The dark shaded area is the wilderness area of interest, and
    the lines are roads (the roads dataset has artifacts, but those will be treated
    as real data in the example). B: Roads are no longer smooth lines when rasterized.
    C: Results of the proximity analysis, where bright areas are further from roads.
    D: The proximity dataset with non-wilderness removed.'
  id: totrans-187
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '图 11.14\. 用于计算荒野区域内平均道路距离的数据。A: 深色阴影区域是感兴趣的荒野区域，线条是道路（道路数据集有瑕疵，但在示例中将被视为真实数据）。B:
    道路在栅格化后不再是平滑的线条。C: 邻近分析的结果，其中明亮区域离道路更远。D: 移除了非荒野区域的邻近数据集。'
- en: '![](11fig14_alt.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](11fig14_alt.jpg)'
- en: Listing 11.10\. Proximity analysis
  id: totrans-189
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.10\. 邻近分析
- en: '![](ch11ex10-0.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![](ch11ex10-0.jpg)'
- en: '![](ch11ex10-1.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](ch11ex10-1.jpg)'
- en: 'Because you’re using statewide datasets, the first thing you do is find the
    extent of the wilderness area that you’re interested in. To do this, you open
    the wilderness shapefile and set an attribute filter that selects out all records
    where the `WILD_NM` attribute value was equal to `''Frank Church – RONR''`. Because
    the layer’s `GetExtent` function returns the extent of the entire layer, even
    when a filter has been applied, you have to come up with a different method to
    get bounding coordinates. The solution is to make a list of the extents for each
    of the selected polygons and then find the minimum and maximum coordinates from
    that. Creating the list of polygon extents is easy enough:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你使用的是州级数据集，所以你首先要做的是找到你感兴趣的荒野区域的范围。为此，你打开荒野形状文件，并设置一个属性过滤器，选择所有 `WILD_NM`
    属性值等于 `'Frank Church – RONR'` 的记录。由于层的 `GetExtent` 函数即使在应用了过滤器的情况下也返回整个层的范围，你必须想出一个不同的方法来获取边界坐标。解决方案是制作一个列表，列出所选每个多边形的范围，然后从该列表中找到最小和最大的坐标。创建多边形范围列表是足够简单的：
- en: '[PRE25]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Each tuple in this list contains the minimum and maximum x value, and the minimum
    and maximum y, in that order. Now if you zip these tuples together, you end up
    with four lists, one each for minimum and maximum x and y. From there, it’s a
    simple matter of extracting the most extreme values in each list:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表中的每个元组包含最小和最大的 x 值，以及最小和最大的 y 值，顺序如下。现在如果你将这些元组组合在一起，你最终会得到四个列表，每个列表分别对应最小和最大的
    x 和 y。从那里，提取每个列表中的最极端值就变得简单了：
- en: '[PRE26]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now that you have the bounding coordinates for the wilderness extent, you set
    a spatial filter on the roads layer to select only the roads that fall in that
    rectangle:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经得到了荒野范围的边界坐标，你可以在道路层上设置一个空间过滤器，以选择仅在该矩形内的道路：
- en: '[PRE27]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: After getting your roads of interest, you turn them into a raster band that
    you use for your proximity analysis. The raster band must already exist, and then
    the vector features are burned into it. You figure out how many rows and columns
    will fit in the extent, given the cell size you chose early in the script. Smaller
    cell sizes result in more-precise distances, but they also greatly increase processing
    time. Ten meters is a reasonable size for this example.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在获取到感兴趣的路线后，你将它们转换成栅格波段，用于你的邻近度分析。栅格波段必须已经存在，然后将矢量要素烧录到其中。你根据在脚本早期选择的单元格大小来确定行和列的数量。较小的单元格大小会导致更精确的距离，但也会大大增加处理时间。对于这个例子，十米是一个合理的大小。
- en: '[PRE28]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now you have all of the information necessary to create a new raster dataset,
    which you do. It needs a geotransform so that the roads can be burned into the
    correct locations, so you construct one from your bounding coordinates and numbers
    of rows and columns. You also copy the spatial reference from the roads layer.
    Remember that a layer’s `GetSpatialRef` function returns a spatial reference object,
    but a raster dataset’s `SetProjection` function requires a WKT string, which is
    why you have to get the layer’s spatial reference as a string:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你有了创建新栅格数据集所需的所有信息，于是你创建了它。它需要一个地理变换，以便将道路烧录到正确的位置，因此你从边界坐标和行数和列数中构建一个地理变换。你还从道路层复制了空间参考。记住，层的
    `GetSpatialRef` 函数返回一个空间参考对象，但栅格数据集的 `SetProjection` 函数需要一个 WKT 字符串，这就是为什么你必须将层的空间参考作为字符串获取：
- en: '[PRE29]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now you can finally burn the roads into a raster band using the following function:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以使用以下函数最终将道路烧录成栅格波段：
- en: '[PRE30]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '`dataset` is the raster dataset containing the band(s) to burn into.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset` 是包含要烧录到其中的波段（s）的栅格数据集。'
- en: '`bands` is the list of bands to burn the data into, where the first one has
    index 1.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bands` 是要烧录数据的波段列表，其中第一个的索引为 1。'
- en: '`layer` is the OGR layer whose features will be burned into the raster bands.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer` 是将要素烧录到栅格波段中的 OGR 层。'
- en: '`transformer` is a GDAL transformer object to convert map coordinates into
    pixel offsets. If not provided, then the function will create its own using the
    geotransform.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformer` 是一个 GDAL 转换器对象，用于将地图坐标转换为像素偏移。如果没有提供，则函数将使用地理变换创建自己的转换器。'
- en: '`transformArg` is the callback data for the transformer.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transformArg` 是转换器的回调数据。'
- en: '`burn_values` is the list of values to burn into the raster wherever there
    are features. If this parameter is provided, it must be the same length as bands.
    The default for a byte array is 255.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`burn_values` 是要烧录到栅格中的值的列表。如果提供了此参数，它必须与波段长度相同。对于字节数组，默认值为 255。'
- en: '`options` is a list of key=value strings. See appendix E for a list of possibilities.
    (Appendixes C through E are available online on the Manning Publications website
    at [https://www.manning.com/books/geoprocessing-with-python](https://www.manning.com/books/geoprocessing-with-python).)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`options` 是一个 key=value 字符串的列表。有关可能的列表，请参阅附录 E。（附录 C 至 E 可在 Manning Publications
    网站上在线获取，网址为 [https://www.manning.com/books/geoprocessing-with-python](https://www.manning.com/books/geoprocessing-with-python)。）'
- en: '`callback` is a callback function for reporting burn progress.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` 是用于报告烧录进度的回调函数。'
- en: '`callback_data` is data to be passed to the callback function.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_data` 是传递给回调函数的数据。'
- en: 'You use this function to burn the value of 1 everywhere there was a road:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 你使用此函数将 1 的值烧录到所有曾经有道路的地方：
- en: '[PRE31]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: If you load this raster into a GIS, it won’t look like much until you start
    to zoom in. This is because the pixel size is so small that you’ll need to zoom
    in to see many of them. When you do zoom in, you’ll see that the roads are blocky,
    as in [figure 11.15](#ch11fig15). This is a result of them now being represented
    as pixels instead of smooth vector lines.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您将此栅格加载到 GIS 中，直到您开始放大，它看起来不会太多。这是因为像素大小非常小，您需要放大才能看到其中许多。当您放大时，您会看到道路是块状的，就像[图
    11.15](#ch11fig15) 中的那样。这是它们现在被表示为像素而不是平滑矢量线的结果。
- en: Figure 11.15\. Rasterized roads
  id: totrans-216
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.15\. 栅格化的道路
- en: '![](11fig15.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](11fig15.jpg)'
- en: 'Once you have a raster representation of the roads, you’re almost ready to
    compute proximity to them using the `ComputeProximity` function:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了道路的栅格表示，您就几乎准备好使用 `ComputeProximity` 函数来计算它们的邻近度：
- en: '[PRE32]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`srcBand` is the raster band containing the features to compute proximity to.
    By default, any non-zero pixels are considered features.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`srcBand` 是包含要计算其邻近度的特征的栅格带。默认情况下，任何非零像素都被视为特征。'
- en: '`proximityBand` is the raster band to store the proximity measurements into.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`proximityBand` 是存储邻近度测量的栅格带。'
- en: '`options` is a list of key=value strings. See appendix E for a list of possibilities.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`options` 是一个包含 key=value 字符串的列表。有关可能的列表，请参阅附录 E。'
- en: '`callback` is a callback function for reporting progress.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback` 是用于报告进度的回调函数。'
- en: '`callback_data` is data to be passed to the callback function.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`callback_data` 是要传递给回调函数的数据。'
- en: 'Like the `RasterizeLayer` function, the `ComputeProximity` function requires
    that the output raster band already exist. You create a new dataset and copy the
    spatial reference information and geotransform from your roads raster, and then
    calculate proximity using map distances instead of the default pixel distances:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `RasterizeLayer` 函数类似，`ComputeProximity` 函数要求输出栅格带已经存在。您创建一个新的数据集，并从您的道路栅格中复制空间参考信息和地理变换，然后使用地图距离而不是默认的像素距离来计算邻近度：
- en: '[PRE33]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Although you now have a proximity raster, you only want statistics for the areas
    within the wilderness area. You could use a zonal analysis to calculate that information,
    or you could get rid of the non-wilderness data altogether. Either case requires
    rasterizing the wilderness polygons, though, so you do that in a similar manner
    as the roads, except you use the MEM driver to store the dataset in memory instead
    of writing it to disk. Then you read both the wilderness and proximity data into
    NumPy arrays and change all proximity values to -99 if the wilderness value is
    0, which signifies that the pixel doesn’t fall in a wilderness polygon.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管您现在有一个邻近度栅格，但您只想获取荒野区域内的统计数据。您可以使用区域分析来计算这些信息，或者您可以完全删除非荒野数据。但无论如何，都需要栅格化荒野多边形，所以您以类似道路的方式执行此操作，只是您使用
    MEM 驱动程序将数据集存储在内存中而不是写入磁盘。然后您将荒野和邻近度数据都读入 NumPy 数组，并将所有邻近度值更改为 -99，如果荒野值为 0，这表示像素不在荒野多边形内。
- en: '[PRE34]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Once you save the data back to disk, you’re able to correctly calculate statistics,
    and you also have a nice proximity dataset for use later. [Figure 11.16](#ch11fig16)
    shows part of this dataset, zoomed in far enough to get an idea of how it works.
    The brighter the pixel, the longer the distance from a road.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将数据保存回磁盘，您就可以正确地计算统计数据，并且您还有一个很好的邻近度数据集供以后使用。[图 11.16](#ch11fig16) 显示了该数据集的一部分，放大到足够远以了解其工作原理。像素越亮，距离道路的距离就越长。
- en: Figure 11.16\. A small section of the proximity dataset with roads drawn on
    top. Brighter areas indicate longer distances from roads.
  id: totrans-230
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.16\. 带有道路绘制的邻近度数据集的小部分。亮度较高的区域表示距离道路较远。
- en: '![](11fig16.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](11fig16.jpg)'
- en: 11.3\. Resampling data
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3\. 重采样数据
- en: 'Back in [chapter 9](kindle_split_017.html#ch09) you learned how to resample
    your data to different cell sizes by changing the size of the arrays used to hold
    the data. Other ways to resample give you more control over the outcome, however.
    One simple approach is to use slices to keep pixel values at a specific interval
    and throw out everything in between. To do this, provide a step value when specifying
    your slice. A step value of 2 tells NumPy to keep every second value, 3 means
    keep every third value, and so on. This example shows you how to keep every other
    cell, reducing the rows and columns by half:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第9章](kindle_split_017.html#ch09)中，你学习了如何通过改变存储数据的数组大小来对数据进行重采样。然而，其他重采样方法可以让你对结果有更多的控制。一种简单的方法是使用切片来保持特定间隔的像素值，并丢弃其间的所有值。为此，在指定切片时提供一个步长值。步长值为2表示NumPy保留每个第二个值，3表示保留每个第三个值，依此类推。以下示例展示了如何保留每隔一个单元格，从而将行和列减半：
- en: '[PRE35]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'For this example, `data[0:4:2, 0:6:2]` provides the same results as `data[::2,
    ::2]`. Not providing starting and stopping indices around the first colon means
    that you want to start at the beginning and go to the end. The third number, after
    the second colon, is the step index. If you want to start at the second row and
    column instead of the first, you can do this:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个示例，`data[0:4:2, 0:6:2]`提供的结果与`data[::2, ::2]`相同。不提供第一个冒号周围的起始和停止索引意味着你想要从开始到结束。第二个冒号之后的数字是步长索引。如果你想从第二行和第二列而不是第一行和第一列开始，你可以这样做：
- en: '[PRE36]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This should look familiar, because the results are similar to the automatic
    resampling that happens when you read data from a file into a differently sized
    array.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该看起来很熟悉，因为结果与从文件中读取数据到不同大小的数组时自动重采样的结果相似。
- en: 'You can also increase the size of the array, which is how you’d decrease pixel
    sizes. To do this, use the NumPy `repeat` function, which wants an array of data,
    the number of times to repeat each value, and the axis to use. If you don’t provide
    an axis, then the array is flattened to one dimension. An axis of 0 repeats the
    rows, and a value of 1 repeats columns, like this:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以增加数组的大小，这是减小像素大小的常用方法。为此，使用NumPy的`repeat`函数，该函数需要一个数据数组、重复每个值的次数以及要使用的轴。如果你不提供轴，则数组会被展平为一维。轴为0表示重复行，值为1表示重复列，如下所示：
- en: '[PRE37]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Notice how each column is repeated twice? To end up with each value repeated
    four times (so the rows and columns are both doubled), call `repeat` once on rows
    and once on columns:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到每一列都是重复两次吗？为了使每个值重复四次（这样行和列都加倍），请在行和列上各调用一次`repeat`函数：
- en: '[PRE38]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: But let’s look at something more interesting. You can also use multiple slices
    to apply custom algorithms instead of using a single pixel value. For example,
    if you want to resample to pixels that are four times the original size (twice
    the length and twice the width), you could take the average of those four pixel
    values and use that as the new value. [Figure 11.17](#ch11fig17) shows an example
    of this.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 但让我们看看一些更有趣的东西。你还可以使用多个切片来应用自定义算法，而不是使用单个像素值。例如，如果你想将重采样到原始大小的四倍像素（长度和宽度都是两倍），你可以取这四个像素值的平均值，并将其用作新值。[图11.17](#ch11fig17)展示了这个示例。
- en: Figure 11.17\. Increasing cell size and using the average value of the input
    pixels as the output value
  id: totrans-243
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.17\. 增加单元格大小，并使用输入像素的平均值作为输出值
- en: '![](11fig17.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图11.17](11fig17.jpg)'
- en: In the case of [figure 11.17](#ch11fig17), you need four numbers to calculate
    the output value. To accomplish the same thing with slices, you’d need four slices,
    with each one corresponding to one of the four input values. Unlike the slices
    you used for moving windows, however, these would each be much smaller than the
    original array. Instead, they’d be the same size as the output array, and each
    one would contain one value per output cell, as shown in [figure 11.18](#ch11fig18).
    The figure shows the original data, but the cells that would make up each slice
    are highlighted. One slice would contain the upper-left pixel from every set of
    four pixels used to calculate the output. Another slice would contain each upper-right
    pixel, and so on. Each of the slices in this example has three rows and three
    columns, which is the same size as the output. If you take the average of these
    slices on a pixel-by-pixel basis, you end up with the values shown in [figure
    11.17](#ch11fig17). For example, the upper-left corner would have a value of (3
    + 5 + 4 + 5) / 4 = 17 / 4 = 4.25.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图11.17](#ch11fig17)的情况下，你需要四个数字来计算输出值。要使用切片完成相同的事情，你需要四个切片，每个切片对应于四个输入值中的一个。然而，与用于移动窗口的切片不同，这些切片将比原始数组小得多。相反，它们将与输出数组具有相同的大小，并且每个切片将包含每个输出单元格的一个值，如图11.18所示。该图显示了原始数据，但构成每个切片的单元格被突出显示。一个切片将包含用于计算输出的每组四个像素中的左上像素。另一个切片将包含每个右上像素，依此类推。在这个例子中，每个切片都有三行三列，这与输出的大小相同。如果你按像素逐个对这些切片取平均值，你最终会得到[图11.17](#ch11fig17)中显示的值。例如，左上角将有一个值为(3
    + 5 + 4 + 5) / 4 = 17 / 4 = 4.25。
- en: Figure 11.18\. Slices used to resample using an average of the input values.
    The shaded cells are the ones used to create each smaller slice. The smaller arrays
    are averaged together to get the final result.
  id: totrans-246
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.18。用于通过输入值的平均值进行重采样的切片。阴影单元格是用于创建每个较小切片的单元格。较小的数组被平均在一起以得到最终结果。
- en: '![](11fig18_alt.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图片](11fig18_alt.jpg)'
- en: Let’s look at how to implement this with code. Once again, your life will be
    easier if you write a function to create the required slices. The following listing
    shows one that returns the slices in a list, given the original data and the window
    size (2 x 2 in the example from [figure 11.18](#ch11fig18)).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看如何用代码来实现这一点。再次强调，如果你编写一个函数来创建所需的切片，你的生活将会更加轻松。下面的列表显示了这样一个函数，它根据原始数据和窗口大小（例如，来自[图11.18](#ch11fig18)的示例中的2
    x 2）返回切片。
- en: Listing 11.11\. Function to make stepped slices
  id: totrans-249
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表11.11。创建阶梯式切片的函数
- en: '[PRE39]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The first thing this function does is calculate the last row and column that
    will be used. This is necessary because the original data might not be divisible
    by the size of the window you want. For example, in [figure 11.19](#ch11fig19)
    the input array has five rows and five columns. The figure shows two of the slices
    needed to take an average of four pixels, but the second one is smaller than the
    first. If you try to use these two slices together, you’ll get an error because
    they’re different sizes. The function in [listing 11.11](#ch11ex11) handles this
    by cutting off the fifth row and column, so that the slices are created from four
    rows and columns instead. To do this, the total number of rows or columns is divided
    by the number of rows or columns in a window. For the example in [figure 11.19](#ch11fig19),
    this would be 5 / 2 = 2 for both, so the data can fit two full windows in each
    direction. Multiply that by the window size to get the total number of rows or
    columns to use, which is four in the example. This number is used to put an upper
    bound on the slices.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数首先计算将使用的最后一行和列。这是必要的，因为原始数据可能不能被你想要的窗口大小整除。例如，在[图11.19](#ch11fig19)中，输入数组有五行五列。该图显示了用于取四个像素平均的两个所需切片，但第二个比第一个小。如果你尝试一起使用这两个切片，你会得到一个错误，因为它们的大小不同。[列表11.11](#ch11ex11)中的函数通过截断第五行和列来处理这个问题，这样切片就是从四行四列创建的。为此，总行数或列数被除以窗口中的行数或列数。对于[图11.19](#ch11fig19)中的例子，这将是两个方向上的2，所以数据可以每个方向放入两个完整的窗口。将这个数乘以窗口大小，得到要使用的总行数或列数，在例子中是4。这个数字用于对切片设置上限。
- en: Figure 11.19\. When the dimensions of the array to be resampled are not divisible
    by the dimensions of the window (2 x 2 in this case), the slices are different
    sizes. This must be accounted for so that the slices have the same size.
  id: totrans-252
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.19。当要重采样的数组的维度不能被窗口的维度（在本例中为2 x 2）整除时，切片的大小不同。这必须被考虑到，以确保切片具有相同的大小。
- en: '![](11fig19_alt.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![图片](11fig19_alt.jpg)'
- en: Once the numbers of rows and columns are known, the function creates one slice
    for each input location, using the window size as the step parameter so only one
    input pixel per window is extracted. The slices are all returned as a list, and
    once you have that you can apply any algorithm you want, as long as you can code
    it up. To get an average, you could stack the slices and then use the NumPy `mean`
    function, as you did for moving windows.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦知道了行数和列数，该函数就会为每个输入位置创建一个切片，使用窗口大小作为步长参数，因此每个窗口只提取一个输入像素。所有切片都作为列表返回，一旦你有了这些，你就可以应用任何你想要的算法，只要你能编写出来。要得到平均值，你可以堆叠切片，然后使用NumPy的`mean`函数，就像你为移动窗口所做的那样。
- en: '|  |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Tip
  id: totrans-256
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 小贴士
- en: Don’t forget to change the geotransform to reflect the new cell size when resampling
    your data.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记在重采样数据时更改geotransform以反映新的单元格大小。
- en: '|  |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Techniques like this are great if your output cell size is a multiple of the
    original, but they don’t work in other cases. Let’s look at a way to extract specific
    pixels that can’t be specified with a step parameter. To do this, you need to
    know the original pixel size, the new pixel size, and the numbers of rows and
    columns in the original image. Get a scaling factor for width by dividing the
    new pixel width by the original width, and do the same for pixel height. For example,
    if your original image has a pixel width of 10 but your target width is 25, then
    the scaling factor is 2.5\. The new pixels are 2.5 old pixels wide.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的输出单元格大小是原始大小的倍数，这种技术很棒，但在其他情况下它们不起作用。让我们看看一种提取特定像素的方法，这些像素不能用步长参数指定。为此，你需要知道原始像素大小、新像素大小以及原始图像中的行数和列数。通过将新像素宽度除以原始宽度来获取宽度缩放因子，并对像素高度做同样的处理。例如，如果你的原始图像的像素宽度为10，但你的目标宽度为25，那么缩放因子是2.5。新像素的宽度是2.5个旧像素。
- en: Divide the scaling factor in half to determine that the center of a new pixel
    is 1.25 old pixels from the edge. This center point is what you want because you
    use the center of new pixels to determine which nearby old pixels to use when
    resampling. To get the center x values for the new pixels in terms of the original
    cell offsets, create an array that starts at the center (1.25) and increments
    by the scaling factor (2.5). You need to make sure this array goes up to, but
    not past, the total number of columns in the original array. Do the same for rows,
    so that you have two arrays containing x and y offsets. [Figure 11.20](#ch11fig20)
    shows an example of a few pixels. The alternating shaded areas are the original
    pixels (of size 10) and the thick outlines denote the pixels with size 25\. The
    dots are the center points of the large pixels, and the text shows the coordinates
    for these points in terms of the smaller pixels.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 将缩放因子除以二，以确定新像素的中心距离边缘有1.25个旧像素。这个中心点是你想要的，因为你在重采样时使用新像素的中心来确定使用哪些附近的旧像素。为了以原始单元格偏移量的形式获取新像素的中心x值，创建一个从中心（1.25）开始并按缩放因子（2.5）递增的数组。你需要确保这个数组达到，但不超出原始数组中的总列数。对行做同样的处理，这样你就有了包含x和y偏移量的两个数组。[图11.20](#ch11fig20)显示了几个像素的示例。交替阴影区域是原始像素（大小为10），粗轮廓表示大小为25的像素。点是大像素的中心点，文本显示了这些点的坐标，以较小像素为基准。
- en: Figure 11.20\. Resampling to a larger pixel size that’s not a multiple of the
    original size. The alternating shaded areas are the original pixels and the thick
    outlines show the new ones. The dots are the center points for the new pixels.
  id: totrans-261
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图11.20。将像素大小重采样到不是原始大小倍数的大像素大小。交替阴影区域是原始像素，粗轮廓显示新的像素。点是新像素的中心点。
- en: '![](11fig20.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![图片](11fig20.jpg)'
- en: Once you have the lists of x and y offsets, you can use the NumPy `meshgrid`
    function to get two new arrays that contain all possible coordinates obtained
    from these values. For example, if your row offsets are (3, 5) and column offsets
    are (2, 4), then the possible combinations are [(3, 2), (3, 4), (5, 2), (5, 4)],
    and `meshgrid` would return two four-element arrays, one for the row offsets and
    one for the columns.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了x和y偏移量的列表，你可以使用NumPy的`meshgrid`函数来获取两个包含所有可能坐标的新数组，这些坐标是从这些值获得的。例如，如果你的行偏移量是(3,
    5)，列偏移量是(2, 4)，那么可能的组合是[(3, 2), (3, 4), (5, 2), (5, 4)]，而`meshgrid`将返回两个四元素数组，一个用于行偏移量，一个用于列。
- en: The following listing shows a function that computes the scaling factors, makes
    the offset arrays, and then creates and returns the coordinate arrays.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了一个函数，该函数计算缩放因子，创建偏移量数组，然后创建并返回坐标数组。
- en: Listing 11.12\. Function to get new pixel offsets in terms of old pixels
  id: totrans-265
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.12\. 获取旧像素的新偏移量的函数
- en: '[PRE40]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Once you have coordinates, you can take advantage of the fact that offset lists
    can be used to extract values from NumPy arrays to get the values of the original
    pixels that fall directly under the center of the new pixels. This is nearest-neighbor
    resampling, which uses the value of the closest pixel in the original array and
    doesn’t do any other processing. To do this, you’d extract the values at the calculated
    indices and be done with it, like this:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦有了坐标，你可以利用偏移量列表可以用来从 NumPy 数组中提取值的事实，以获取位于新像素中心直接下方的原始像素的值。这是最近邻重采样，它使用原始数组中最接近像素的值，并且不进行任何其他处理。为此，你会提取计算出的索引处的值，然后完成它，如下所示：
- en: '[PRE41]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The only trick is that you need to convert the indices to integers or NumPy
    will complain when you attempt to use them to index an array.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的技巧是，你需要将索引转换为整数，否则当尝试使用它们来索引数组时，NumPy 会抱怨。
- en: Nearest-neighbor is simple, fast, and one of the few appropriate resampling
    methods for categorical data, but it’s not the greatest choice for continuous
    data. For these types of data, you usually want to use several surrounding pixels
    to calculate your new value. You could use an average as you did earlier, or one
    of several other common resampling methods. Two examples of these are *bilinear
    interpolation*, which takes a weighted average of the four closest pixels, and
    *cubic convolution*, which fits a smooth curve through the 16 nearest pixels and
    uses that to calculate a new value. You’re going to write a function that uses
    the output from your `get_indices` function to perform bilinear interpolation.
    The hatched areas in [figure 11.21](#ch11fig21) show which four original pixels
    are used for each center point.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 最近邻法简单、快速，并且是适用于分类数据的一少数几种合适的重采样方法之一，但它并不是连续数据的最佳选择。对于这些类型的数据，你通常希望使用几个周围的像素来计算你的新值。你可以使用之前所做的那样进行平均，或者使用几种其他常见的重采样方法之一。这些方法的两个例子是
    *双线性插值*，它对四个最近的像素进行加权平均，以及 *立方卷积*，它通过 16 个最近的像素拟合一条平滑曲线，并使用该曲线来计算新值。你将编写一个函数，使用你的
    `get_indices` 函数的输出执行双线性插值。图 11.21 中的阴影区域显示了每个中心点使用的四个原始像素。
- en: Figure 11.21\. The hatched areas show the four original pixels closest to the
    new pixel center point. These are the ones used to calculate a value for the new
    pixel.
  id: totrans-271
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 11.21\. 阴影区域显示了最接近新像素中心点的四个原始像素。这些是用于计算新像素值的像素。
- en: '![](11fig21.jpg)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图片](11fig21.jpg)'
- en: To get the values of these four pixels, the first thing you need to do is subtract
    0.5 from the calculated indices so that they correspond to the center, instead
    of the edge, of the input pixels. Then you need to determine the integers on either
    side of these coordinates, which gives you the offsets to use. For example, if
    the row coordinate is 4.25, then you’d use rows 4 and 5\. If you do that for column
    offsets as well, you have two rows and two columns and can use those to get the
    four input pixels surrounding the target pixel.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取这四个像素的值，首先需要从计算出的索引中减去 0.5，以便它们对应于输入像素的中心，而不是边缘。然后你需要确定这些坐标两侧的整数，这给出了要使用的偏移量。例如，如果行坐标是
    4.25，那么你会使用第 4 行和第 5 行。如果你也对列偏移量做同样的事情，你就有了两行和两列，可以使用这些来获取围绕目标像素的四个输入像素。
- en: Once you have an input pixel value, multiply it by the distance in both directions
    from that pixel to the target pixel. This is the part that weights the closer
    pixels heavier than further pixels. Then add the four weighted values together
    to get the final output value. If you’d like a more detailed explanation of the
    algorithm, you can find many sources online.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦有了输入像素值，乘以该像素到目标像素的两个方向上的距离。这是使较近像素比较远像素更重的部分。然后将四个加权值相加以获得最终的输出值。如果你想要更详细的算法解释，你可以在网上找到许多资源。
- en: The following listing shows a function that performs bilinear interpolation,
    given the original data and the center offsets for the new pixels.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了一个执行双线性插值的函数，给定原始数据和新的像素中心偏移量。
- en: Listing 11.13\. Function for bilinear interpolation
  id: totrans-276
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.13\. 双线性插值函数
- en: '![](273fig01_alt.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![图片](273fig01_alt.jpg)'
- en: Now to use bilinear interpolation to resample a raster, you can use your `get_indices`
    function to get offsets, which you then pass to the `bilinear` function. Don’t
    forget to edit the geotransform when saving the output, as shown in the following
    listing.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 现在要使用双线性插值来重采样栅格，你可以使用你的 `get_indices` 函数来获取偏移量，然后将这些偏移量传递给 `bilinear` 函数。保存输出时，别忘了编辑地理变换，如下所示。
- en: Listing 11.14\. Bilinear interpolation
  id: totrans-279
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 11.14. 双线性插值
- en: '![](274fig01_alt.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图片](274fig01_alt.jpg)'
- en: If you’d like to try other types of interpolation, `scipy.ndimage` contains
    several interpolation methods. See [http://docs.scipy.org/doc/scipy-0.16.1/reference/ndimage.html#module-scipy.ndimage.interpolation](http://docs.scipy.org/doc/scipy-0.16.1/reference/ndimage.html#module-scipy.ndimage.interpolation)
    for more information.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要尝试其他类型的插值，`scipy.ndimage` 包含了多种插值方法。更多信息请参阅 [http://docs.scipy.org/doc/scipy-0.16.1/reference/ndimage.html#module-scipy.ndimage.interpolation](http://docs.scipy.org/doc/scipy-0.16.1/reference/ndimage.html#module-scipy.ndimage.interpolation)。
- en: '|  |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Resampling with GDAL command-line utilities**'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 GDAL 命令行工具进行重采样**'
- en: 'This might be a good time to mention the GDAL command-line utilities. There
    are currently about 30 of them, and new ones get added occasionally. These aren’t
    Python tools; you need to run them from a command prompt or terminal window. Let’s
    see how to use gdalwarp to resample an image. This utility is designed for transforming
    rasters between spatial reference systems, but you can also use it to resample
    without changing the spatial reference. The command line looks like this:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是一个提及 GDAL 命令行工具的好时机。目前大约有 30 个这样的工具，偶尔还会添加新的。这些不是 Python 工具；你需要从命令提示符或终端窗口运行它们。让我们看看如何使用
    gdalwarp 来重采样图像。这个实用程序旨在在空间参考系统之间转换栅格，但你也可以用它来进行重采样而不改变空间参考。命令行看起来像这样：
- en: '[PRE42]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The `–tr` option is for target resolution, in this case indicating that both
    cell width and height should be 0.02\. As you’ve probably guessed, `-r` stands
    for resampling method, and this specifies bilinear. Other options include but
    aren’t limited to nearest-neighbor, average, cubic convolution, and mode. The
    input file is everest.tif, and the new file will be called everest_resampled.tif.
    Many more options are available, and they’re all documented at [http://www.gdal.org/gdalwarp.html](http://www.gdal.org/gdalwarp.html).
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '`–tr` 选项用于目标分辨率，在这种情况下表示单元格宽度和高度都应该是 0.02。正如你可能猜到的，`-r` 代表重采样方法，这里指定为双线性。其他选项包括但不限于最近邻、平均、立方卷积和模式。输入文件是
    everest.tif，新文件将命名为 everest_resampled.tif。还有更多选项可用，它们都在 [http://www.gdal.org/gdalwarp.html](http://www.gdal.org/gdalwarp.html)
    上有文档说明。'
- en: If you have GDAL version 2.x, you can also use the same options with the gdal_translate
    utility, which is designed to convert data between different formats. (I wish
    I knew how many times I’ve pointed people to this tool over the years!)
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是 GDAL 2.x 版本，你也可以使用 gdal_translate 工具的相同选项，该工具旨在在不同格式之间转换数据。（我希望我知道我这些年有多少次向人们推荐这个工具！）
- en: 'Although these aren’t Python tools, you can call them from Python using the
    subprocess module, which sends commands out to the operating system:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些不是 Python 工具，但你可以使用 subprocess 模块从 Python 中调用它们，该模块将命令发送到操作系统：
- en: '[PRE43]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The `result` variable will hold 0 if the process completed successfully, and
    1 if not. It’s preferred that you break your command up into a list of arguments
    like the example so that Python can handle special cases such as spaces in filenames,
    but you can also pass a string instead, like this:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 如果过程成功完成，`result` 变量将保持 0，如果不成功则为 1。建议你将命令拆分成一个参数列表，如示例所示，这样 Python 可以处理特殊案例，例如文件名中的空格，但你也可以传递一个字符串，如下所示：
- en: '[PRE44]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '|  |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 11.4\. Summary
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4. 概述
- en: If you need to work with large arrays of data in Python, the NumPy module is
    your answer.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你需要在 Python 中处理大量数据数组，NumPy 模块是你的答案。
- en: Use the SciPy module to perform many different scientific data analyses on NumPy
    arrays.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SciPy 模块在 NumPy 数组上执行许多不同的科学数据分析。
- en: Local map algebra computations work on a pixel-by-pixel basis, such as calculating
    NDVI for a pixel.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地地图代数计算基于像素进行，例如计算像素的 NDVI。
- en: Focal map algebra computations involve a moving window that uses surrounding
    pixels to calculate the output value, such as calculating slope.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 焦点地图代数计算涉及一个移动窗口，该窗口使用周围的像素来计算输出值，例如计算坡度。
- en: Zonal calculations work on pixels that are all in the same zone, such as calculating
    the histogram of landcover types based on land ownership.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区域计算针对同一区域内的像素，例如根据土地所有权计算土地覆盖类型的直方图。
- en: Global calculations, such as proximity analysis, involve the entire raster dataset.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全球计算，例如邻近度分析，涉及整个栅格数据集。
