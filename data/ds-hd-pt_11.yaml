- en: Chapter 9\. Simulation and Bootstrapping
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬9ç«  æ¨¡æ‹Ÿå’Œè‡ªä¸¾æ³•
- en: The application of different techniques in the data scientistâ€™s toolkit depends
    critically on the nature of the data youâ€™re working with. *Observational* data
    arises in the normal, day-to-day, business-as-usual set of interactions at any
    company. In contrast, *experimental* data arises under well-designed experimental
    conditions, such as when you set up an A/B test. This type of data is most commonly
    used to infer causality or estimate the incrementality of a lever ([ChapterÂ 15](ch15.html#ch15_incrementality)).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®ç§‘å­¦å®¶å·¥å…·åŒ…ä¸­ä¸åŒæŠ€æœ¯çš„åº”ç”¨å–å†³äºæ‚¨æ­£åœ¨å¤„ç†çš„æ•°æ®çš„æ€§è´¨ã€‚*è§‚å¯Ÿ*æ•°æ®æºè‡ªäºä»»ä½•å…¬å¸åœ¨æ—¥å¸¸ä¸šåŠ¡ä¸­çš„æ­£å¸¸äº’åŠ¨ï¼Œè€Œ*å®éªŒ*æ•°æ®åˆ™æ˜¯åœ¨è®¾è®¡è‰¯å¥½çš„å®éªŒæ¡ä»¶ä¸‹äº§ç”Ÿçš„ï¼Œä¾‹å¦‚è¿›è¡ŒA/Bæµ‹è¯•ã€‚åè€…é€šå¸¸ç”¨äºæ¨æ–­å› æœå…³ç³»æˆ–ä¼°è®¡æ æ†çš„å¢é‡æ€§ï¼ˆ[ç¬¬15ç« ](ch15.html#ch15_incrementality)ï¼‰ã€‚
- en: A third type, *simulated* or *synthetic* data, is less well-known and occurs
    when a person re-creates the *data generating process* (DGP). This can be done
    either by making strong assumptions about it or by training a generative model
    on a dataset. In this chapter, I will only deal with the former type, but Iâ€™ll
    recommend references at the end of this chapter if youâ€™re interested in the latter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸‰ç§ç±»å‹ï¼Œå³*æ¨¡æ‹Ÿ*æˆ–*åˆæˆ*æ•°æ®ï¼Œåœ¨é‡æ–°åˆ›å»º*æ•°æ®ç”Ÿæˆè¿‡ç¨‹*ï¼ˆDGPï¼‰æ—¶è¾ƒä¸ºå°‘è§ã€‚è¿™å¯ä»¥é€šè¿‡å¯¹å…¶è¿›è¡Œå¼ºå‡è®¾æˆ–åœ¨æ•°æ®é›†ä¸Šè®­ç»ƒç”Ÿæˆæ¨¡å‹æ¥å®ç°ã€‚æœ¬ç« ä»…è®¨è®ºå‰ä¸€ç§ç±»å‹ï¼Œä½†å¦‚æœæ‚¨å¯¹åä¸€ç§ç±»å‹æ„Ÿå…´è¶£ï¼Œæˆ‘ä¼šåœ¨æœ¬ç« æœ«å°¾æ¨èç›¸å…³èµ„æ–™ã€‚
- en: 'Simulation is a great tool for data scientists for different reasons:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºæ•°æ®ç§‘å­¦å®¶è€Œè¨€ï¼Œæ¨¡æ‹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„å·¥å…·ï¼Œå…¶åŸå› æœ‰ä»¥ä¸‹å‡ ç‚¹ï¼š
- en: Understanding an algorithm
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è§£ç®—æ³•
- en: No algorithm works universally well across datasets. Simulation allows you to
    single out different aspects of a DGP and understand the sensitivity of the algorithm
    to changes. This is commonly done with Monte Carlo (MC) simulations.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰ä¸€ç§ç®—æ³•èƒ½å¤Ÿåœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ã€‚æ¨¡æ‹Ÿå…è®¸æ‚¨å•ç‹¬åˆ†æDGPçš„ä¸åŒæ–¹é¢ï¼Œå¹¶äº†è§£ç®—æ³•å¯¹å˜åŒ–çš„æ•æ„Ÿæ€§ã€‚è’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ¨¡æ‹Ÿé€šå¸¸ç”¨äºè¿™ç§åˆ†æã€‚
- en: Bootstrapping
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªä¸¾æ³•
- en: Many times you need to estimate the precision of an estimate without making
    distributional assumptions that simplify the calculations. Bootstrapping is a
    sort of simulation that can help you out in such cases.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å¾ˆå¤šæ—¶å€™ï¼Œæ‚¨éœ€è¦åœ¨ä¸åšå‡ºåˆ†å¸ƒå‡è®¾çš„æƒ…å†µä¸‹ä¼°è®¡ä¼°è®¡å€¼çš„ç²¾ç¡®åº¦ã€‚è‡ªä¸¾æ³•æ˜¯ä¸€ç§å¯ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹å¸®åŠ©æ‚¨çš„æ¨¡æ‹Ÿæ–¹æ³•ã€‚
- en: Levers optimization
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ æ†ä¼˜åŒ–
- en: There are some cases when you need to simulate a system to understand and optimize
    the impact of certain levers. This chapter doesnâ€™t discuss this topic, but does
    provide some references at the end.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº›æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦æ¨¡æ‹Ÿä¸€ä¸ªç³»ç»Ÿä»¥äº†è§£å’Œä¼˜åŒ–æŸäº›æ æ†çš„å½±å“ã€‚æœ¬ç« ä¸æ¶‰åŠæ­¤ä¸»é¢˜ï¼Œä½†åœ¨ç« æœ«æä¾›äº†ä¸€äº›å‚è€ƒèµ„æ–™ã€‚
- en: Before delving into these topics, letâ€™s start with the basics of simulation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ·±å…¥è®¨è®ºè¿™äº›ä¸»é¢˜ä¹‹å‰ï¼Œè®©æˆ‘ä»¬ä»æ¨¡æ‹Ÿçš„åŸºç¡€çŸ¥è¯†å¼€å§‹ã€‚
- en: Basics of Simulation
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿçš„åŸºç¡€çŸ¥è¯†
- en: 'A *data generating process* (DGP) states clearly the relationships among inputs,
    noise, inputs, and outputs in a simulated dataset. Take this DGP as an example:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ•°æ®ç”Ÿæˆè¿‡ç¨‹*ï¼ˆDGPï¼‰æ¸…æ¥šåœ°è¯´æ˜äº†åœ¨æ¨¡æ‹Ÿæ•°æ®é›†ä¸­è¾“å…¥ã€å™ªå£°ã€è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„å…³ç³»ã€‚ä»¥è¿™ä¸ªDGPä¸ºä¾‹ï¼š'
- en: <math alttext="StartLayout 1st Row 1st Column y 2nd Column equals 3rd Column
    alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon 2nd Row 1st Column x 1
    comma x 2 2nd Column tilde 3rd Column upper N left-parenthesis bold 0 bold comma
    bold upper Sigma bold right-parenthesis 3rd Row 1st Column epsilon 2nd Column
    tilde 3rd Column upper N left-parenthesis 0 comma sigma squared right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub></mrow></mtd> <mtd><mo>âˆ¼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn mathvariant="bold">0</mn>
    <mo>,</mo> <mi>Î£</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>Ïµ</mi></mtd>
    <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn>0</mn>
    <mo>,</mo> <msup><mi>Ïƒ</mi> <mn>2</mn></msup> <mo>)</mo></mrow></mtd></mtr></mtable></math>
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column y 2nd Column equals 3rd Column
    alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon 2nd Row 1st Column x 1
    comma x 2 2nd Column tilde 3rd Column upper N left-parenthesis bold 0 bold comma
    bold upper Sigma bold right-parenthesis 3rd Row 1st Column epsilon 2nd Column
    tilde 3rd Column upper N left-parenthesis 0 comma sigma squared right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mi>y</mi></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub></mrow></mtd> <mtd><mo>âˆ¼</mo></mtd>
    <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn mathvariant="bold">0</mn>
    <mo>,</mo> <mi>Î£</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>Ïµ</mi></mtd>
    <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn>0</mn>
    <mo>,</mo> <msup><mi>Ïƒ</mi> <mn>2</mn></msup> <mo>)</mo></mrow></mtd></mtr></mtable></math>
- en: This says that the dataset is comprised of one outcome (*y*) and two features
    ( <math alttext="x 1 comma x 2"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo>
    <msub><mi>x</mi> <mn>2</mn></msub></mrow></math> ). The outcome is a linear function
    of the features and noise. All of the information needed to simulate the dataset
    is included, so the DGP is fully specified.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†ç”±ä¸€ä¸ªç»“æœï¼ˆ*y*ï¼‰å’Œä¸¤ä¸ªç‰¹å¾ï¼ˆ<math alttext="x 1 comma x 2"><mrow><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub></mrow></math>ï¼‰ç»„æˆã€‚ç»“æœæ˜¯ç‰¹å¾å’Œå™ªå£°çš„çº¿æ€§å‡½æ•°ã€‚åŒ…æ‹¬åœ¨å†…çš„æ‰€æœ‰æ¨¡æ‹Ÿæ•°æ®é›†æ‰€éœ€ä¿¡æ¯å‡å·²åŒ…å«ï¼Œå› æ­¤DGPå·²å®Œå…¨ç¡®å®šã€‚
- en: 'To create the data, follow these steps:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»º   åˆ›å»ºæ•°æ®çš„æ­¥éª¤å¦‚ä¸‹ï¼š
- en: '*Set up some parameters*. Choose the values for <math alttext="alpha 0 comma
    alpha 1 comma alpha 2"><mrow><msub><mi>Î±</mi> <mn>0</mn></msub> <mo>,</mo> <msub><mi>Î±</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>Î±</mi> <mn>2</mn></msub></mrow></math>
    , the <math alttext="2 times 2"><mrow><mn>2</mn> <mo>Ã—</mo> <mn>2</mn></mrow></math>
    covariance matrix <math alttext="bold upper Sigma"><mi>Î£</mi></math> , and the
    residual or pure noise variance <math alttext="sigma squared"><msup><mi>Ïƒ</mi>
    <mn>2</mn></msup></math> .'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è®¾ç½®ä¸€äº›å‚æ•°*ã€‚é€‰æ‹©<math alttext="alpha 0 comma alpha 1 comma alpha 2"><mrow><msub><mi>Î±</mi>
    <mn>0</mn></msub> <mo>,</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>Î±</mi>
    <mn>2</mn></msub></mrow></</mrow></math> çš„å€¼ï¼Œ<math alttext="2 times 2"><mrow><mn>2</mn>
    <mo>Ã—</mo> <mn>2</mn></mrow></math> åæ–¹å·®çŸ©é˜µ <math alttext="bold upper Sigma"><mi>Î£</mi></math>
    ï¼Œä»¥åŠæ®‹å·®æˆ–çº¯å™ªå£°æ–¹å·® <math alttext="sigma squared"><msup><mi>Ïƒ</mi> <mn>2</mn></msup></math>ã€‚'
- en: '*Draw from the distributions*. Here, I decided that the features follow a mean-zero
    multivariate normal distribution, and that the residuals are to be independently
    drawn from a mean-zero normal distribution.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä»åˆ†å¸ƒä¸­æŠ½æ ·*ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å†³å®šç‰¹å¾éµå¾ªå‡å€¼ä¸ºé›¶çš„å¤šå…ƒæ­£æ€åˆ†å¸ƒï¼Œæ®‹å·®åˆ™ç‹¬ç«‹åœ°ä»å‡å€¼ä¸ºé›¶çš„æ­£æ€åˆ†å¸ƒä¸­æŠ½æ ·ã€‚'
- en: '*Compute the outcome*. Once all of the inputs are drawn, you can compute the
    outcome *y*.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è®¡ç®—ç»“æœ*ã€‚ä¸€æ—¦æ‰€æœ‰è¾“å…¥éƒ½è¢«æŠ½å–ï¼Œä½ å¯ä»¥è®¡ç®—ç»“æœ *y*ã€‚'
- en: The second step is at the heart of simulation, so letâ€™s discuss this first.
    Computers canâ€™t simulate truly random numbers. But there are ways to generate
    *pseudorandom* draws from distributions that have some desirable properties expected
    when thereâ€™s pure uncertainty. In Python the [random](https://oreil.ly/rDWrf)
    module includes several pseudorandom number generators that can be easily used.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒæ­¥æ˜¯æ¨¡æ‹Ÿçš„æ ¸å¿ƒï¼Œæ‰€ä»¥æˆ‘ä»¬å…ˆæ¥è®¨è®ºè¿™ä¸ªã€‚è®¡ç®—æœºæ— æ³•æ¨¡æ‹ŸçœŸæ­£çš„éšæœºæ•°ã€‚ä½†æ˜¯æœ‰åŠæ³•ä»å…·æœ‰çº¯éšæœºæ€§è´¨çš„åˆ†å¸ƒä¸­ç”Ÿæˆ*ä¼ªéšæœº*æŠ½æ ·ã€‚åœ¨Pythonä¸­ï¼Œ[random](https://oreil.ly/rDWrf)æ¨¡å—åŒ…å«å¤šä¸ªå¯ä»¥è½»æ¾ä½¿ç”¨çš„ä¼ªéšæœºæ•°ç”Ÿæˆå™¨ã€‚
- en: Nonetheless, letâ€™s take a step back and try to understand how these pseudorandom
    number generators work. I will now describe the *inverse transform sampling* method.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å¦‚æ­¤ï¼Œè®©æˆ‘ä»¬é€€ä¸€æ­¥ï¼Œè¯•ç€ç†è§£è¿™äº›ä¼ªéšæœºæ•°ç”Ÿæˆå™¨çš„å·¥ä½œåŸç†ã€‚ç°åœ¨æˆ‘å°†æè¿°*é€†å˜æ¢æŠ½æ ·*æ–¹æ³•ã€‚
- en: 'Suppose you are able to draw a uniform random number <math alttext="u tilde
    upper U left-parenthesis 0 comma 1 right-parenthesis"><mrow><mi>u</mi> <mo>âˆ¼</mo>
    <mi>U</mi> <mo>(</mo> <mn>0</mn> <mo>,</mo> <mn>1</mn> <mo>)</mo></mrow></math>
    , and you want to draw from a distribution with a known cumulative distribution
    function (CDF), <math alttext="upper F left-parenthesis x right-parenthesis equals
    Prob left-parenthesis upper X less-than-or-equal-to x right-parenthesis"><mrow><mi>F</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mtext>Prob</mtext> <mo>(</mo> <mi>X</mi>
    <mo>â‰¤</mo> <mi>x</mi> <mo>)</mo></mrow></math> . Importantly, you can also compute
    the inverse of the CDF. The steps are ([FigureÂ 9-1](#ch9_inversesampling)):'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾ä½ èƒ½å¤ŸæŠ½å–ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒçš„éšæœºæ•° <math alttext="u tilde upper U left-parenthesis 0 comma 1
    right-parenthesis"><mrow><mi>u</mi> <mo>âˆ¼</mo> <mi>U</mi> <mo>(</mo> <mn>0</mn>
    <mo>,</mo> <mn>1</mn> <mo>)</mo></mrow></math> ï¼Œå¹¶ä¸”ä½ æƒ³è¦ä»å·²çŸ¥ç´¯ç§¯åˆ†å¸ƒå‡½æ•°ï¼ˆCDFï¼‰ä¸º <math alttext="upper
    F left-parenthesis x right-parenthesis equals Prob left-parenthesis upper X less-than-or-equal-to
    x right-parenthesis"><mrow><mi>F</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo>
    <mtext>Prob</mtext> <mo>(</mo> <mi>X</mi> <mo>â‰¤</mo> <mi>x</mi> <mo>)</mo></mrow></math>
    çš„åˆ†å¸ƒä¸­æŠ½æ ·ã€‚é‡è¦çš„æ˜¯ï¼Œä½ è¿˜å¯ä»¥è®¡ç®—CDFçš„é€†å‡½æ•°ã€‚æ­¥éª¤å¦‚ä¸‹ï¼ˆ[å›¾ 9-1](#ch9_inversesampling)ï¼‰ï¼š
- en: Generate *K* independent draws <math alttext="u Subscript k Baseline tilde upper
    U left-parenthesis 0 comma 1 right-parenthesis"><mrow><msub><mi>u</mi> <mi>k</mi></msub>
    <mo>âˆ¼</mo> <mi>U</mi> <mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <mn>1</mn> <mo>)</mo></mrow></mrow></math>
    .
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆ *K* ä¸ªç‹¬ç«‹æŠ½æ · <math alttext="u Subscript k Baseline tilde upper U left-parenthesis
    0 comma 1 right-parenthesis"><mrow><msub><mi>u</mi> <mi>k</mi></msub> <mo>âˆ¼</mo>
    <mi>U</mi> <mrow><mo>(</mo> <mn>0</mn> <mo>,</mo> <mn>1</mn> <mo>)</mo></mrow></mrow></math>
    ã€‚
- en: 'For each <math alttext="u Subscript k"><msub><mi>u</mi> <mi>k</mi></msub></math>
    find <math alttext="x Subscript k Baseline equals upper F Superscript negative
    1 Baseline left-parenthesis u Subscript k Baseline right-parenthesis"><mrow><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>=</mo> <msup><mi>F</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mrow><mo>(</mo> <msub><mi>u</mi> <mi>k</mi></msub> <mo>)</mo></mrow></mrow></math>
    : the latter are independent draws from the desired distribution.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ª <math alttext="u Subscript k"><msub><mi>u</mi> <mi>k</mi></msub></math>
    æ‰¾åˆ° <math alttext="x Subscript k Baseline equals upper F Superscript negative 1
    Baseline left-parenthesis u Subscript k Baseline right-parenthesis"><mrow><msub><mi>x</mi>
    <mi>k</mi></msub> <mo>=</mo> <msup><mi>F</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <mrow><mo>(</mo> <msub><mi>u</mi> <mi>k</mi></msub> <mo>)</mo></mrow></mrow></math>
    ï¼šåè€…æ˜¯ä»æ‰€éœ€åˆ†å¸ƒä¸­ç‹¬ç«‹æŠ½å–çš„ç»“æœã€‚
- en: '![inverse sampling](assets/dshp_0901.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![é€†è½¬æ¢æŠ½æ ·](assets/dshp_0901.png)'
- en: Figure 9-1\. Inverse transform sampling
  id: totrans-25
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 9-1\. é€†å˜æ¢æŠ½æ ·
- en: 'The following code snippet shows how to calculate the inverse CDF for a logistic
    random variable. Each [uniform random number](https://oreil.ly/yPHM6) is passed
    as an argument, and then all you need to do is compute the inverse of the CDF,
    given some location and scale parameters:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä»£ç ç‰‡æ®µå±•ç¤ºäº†å¦‚ä½•è®¡ç®— logistic éšæœºå˜é‡çš„é€†CDFã€‚æ¯ä¸ª[å‡åŒ€éšæœºæ•°](https://oreil.ly/yPHM6)è¢«ä½œä¸ºå‚æ•°ä¼ å…¥ï¼Œç„¶åä½ åªéœ€è®¡ç®—CDFçš„é€†ï¼Œç»™å®šä¸€äº›ä½ç½®å’Œå°ºåº¦å‚æ•°ï¼š
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[FigureÂ 9-2](#ch9_qq_logistic) shows a Q-Q plot comparing Numpyâ€™s logistic
    random number [generator](https://oreil.ly/nnt5k) and my own implementation using
    the inverse transform sampling just described, for three different sample sizes.
    Q-Q plots are great to visually inspect whether two distributions are similar.
    This is done by comparing corresponding quantiles for the distributions on the
    horizontal and vertical axes: equal distributions must have the same quantiles
    creating a plot that lies on the 45-degree diagonal (dashed), so you are looking
    for any departures from this ideal scenario. You can see that as the sample size
    increases, Numpyâ€™s logistic random number generator and my own implementation
    get closer.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 9-2](#ch9_qq_logistic) å±•ç¤ºäº†ä¸€ä¸ª Q-Q å›¾ï¼Œæ¯”è¾ƒäº† Numpy çš„ logistic éšæœºæ•° [ç”Ÿæˆå™¨](https://oreil.ly/nnt5k)
    å’Œæˆ‘è‡ªå·±ä½¿ç”¨åˆšåˆšæè¿°çš„åè½¬å˜æ¢æŠ½æ ·å®ç°çš„ç”Ÿæˆå™¨ï¼Œé’ˆå¯¹ä¸‰ç§ä¸åŒçš„æ ·æœ¬å¤§å°ã€‚Q-Q å›¾éå¸¸é€‚åˆç›´è§‚åœ°æ£€æŸ¥ä¸¤ä¸ªåˆ†å¸ƒæ˜¯å¦ç›¸ä¼¼ã€‚é€šè¿‡æ¯”è¾ƒæ°´å¹³å’Œå‚ç›´è½´ä¸Šçš„å¯¹åº”åˆ†ä½æ•°æ¥å®Œæˆæ­¤æ“ä½œï¼šç›¸ç­‰çš„åˆ†å¸ƒå¿…é¡»å…·æœ‰ç›¸åŒçš„åˆ†ä½æ•°ï¼Œä»è€Œåˆ›å»ºä¸€ä¸ªä½äº
    45 åº¦å¯¹è§’çº¿ï¼ˆè™šçº¿ï¼‰ä¸Šçš„å›¾å½¢ï¼Œå› æ­¤æ‚¨è¦æŸ¥æ‰¾ä»»ä½•åç¦»è¿™ç§ç†æƒ³æƒ…å†µçš„æƒ…å†µã€‚æ‚¨å¯ä»¥çœ‹åˆ°éšç€æ ·æœ¬å¤§å°çš„å¢åŠ ï¼ŒNumpy çš„ logistic éšæœºæ•°ç”Ÿæˆå™¨å’Œæˆ‘çš„å®ç°é€æ¸æ¥è¿‘ã€‚'
- en: '![QQ plot](assets/dshp_0902.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![QQ plot](assets/dshp_0902.png)'
- en: Figure 9-2\. Numpyâ€™s and my own logistic random variable generator for different
    sample sizes
  id: totrans-30
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 9-2\. Numpy å’Œæˆ‘è‡ªå·±çš„ logistic éšæœºå˜é‡ç”Ÿæˆå™¨ï¼Œé€‚ç”¨äºä¸åŒçš„æ ·æœ¬å¤§å°
- en: One last important piece of information has to do with the *seed* of random
    number generators. Pseudorandom numbers are generated through a dynamic process
    like <math alttext="x Subscript t Baseline equals f left-parenthesis x Subscript
    t minus 1 Baseline comma midline-horizontal-ellipsis comma x Subscript t minus
    k Baseline comma x 0 right-parenthesis"><mrow><msub><mi>x</mi> <mi>t</mi></msub>
    <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>,</mo> <mo>â‹¯</mo> <mo>,</mo> <msub><mi>x</mi> <mrow><mi>t</mi><mo>-</mo><mi>k</mi></mrow></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>0</mn></msub> <mo>)</mo></mrow></mrow></math>
    . The seed is the initial value of the sequence, so given the process (and its
    parameters), you can always replicate the complete sequence. In practice, seeds
    are used for the purpose of *replication*. In the code to this chapter, youâ€™ll
    see that I always set a seed to ensure that the results donâ€™t change when I run
    the code again.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€ä¸ªé‡è¦çš„ä¿¡æ¯ä¸éšæœºæ•°ç”Ÿæˆå™¨çš„ *ç§å­* æœ‰å…³ã€‚ä¼ªéšæœºæ•°æ˜¯é€šè¿‡åŠ¨æ€è¿‡ç¨‹ç”Ÿæˆçš„ï¼Œä¾‹å¦‚ <math alttext="x Subscript t Baseline
    equals f left-parenthesis x Subscript t minus 1 Baseline comma midline-horizontal-ellipsis
    comma x Subscript t minus k Baseline comma x 0 right-parenthesis"><mrow><msub><mi>x</mi>
    <mi>t</mi></msub> <mo>=</mo> <mi>f</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>,</mo> <mo>â‹¯</mo> <mo>,</mo> <msub><mi>x</mi> <mrow><mi>t</mi><mo>-</mo><mi>k</mi></mrow></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>0</mn></msub> <mo>)</mo></mrow></mrow></math>
    ã€‚ç§å­æ˜¯åºåˆ—çš„åˆå§‹å€¼ï¼Œå› æ­¤åœ¨ç»™å®šè¿‡ç¨‹ï¼ˆåŠå…¶å‚æ•°ï¼‰çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥å¤åˆ¶å®Œæ•´çš„åºåˆ—ã€‚åœ¨å®è·µä¸­ï¼Œç§å­ç”¨äº *å¤åˆ¶* çš„ç›®çš„ã€‚åœ¨æœ¬ç« çš„ä»£ç ä¸­ï¼Œæ‚¨ä¼šçœ‹åˆ°æˆ‘æ€»æ˜¯è®¾ç½®ä¸€ä¸ªç§å­æ¥ç¡®ä¿å†æ¬¡è¿è¡Œä»£ç æ—¶ç»“æœä¸ä¼šæ”¹å˜ã€‚
- en: Simulating a Linear Model and Linear Regression
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿçº¿æ€§æ¨¡å‹å’Œçº¿æ€§å›å½’
- en: 'The simplest simulation that is still useful in machine learning (ML) is that
    of a linear model. I will now simulate the following model:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰ä¸­ä»ç„¶æœ‰ç”¨çš„æœ€ç®€å•çš„æ¨¡æ‹Ÿæ˜¯çº¿æ€§æ¨¡å‹çš„æ¨¡æ‹Ÿã€‚ç°åœ¨æˆ‘å°†æ¨¡æ‹Ÿä»¥ä¸‹æ¨¡å‹ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column y 2nd Column equals 3rd Column
    2 plus 3.5 x 1 minus 5 x 2 plus epsilon 2nd Row 1st Column x 1 comma x 2 2nd Column
    tilde 3rd Column upper N left-parenthesis bold 0 bold comma bold diag bold left-parenthesis
    bold 3 bold comma bold 10 bold right-parenthesis bold right-parenthesis 3rd Row
    1st Column epsilon 2nd Column tilde 3rd Column upper N left-parenthesis 0 comma
    1 right-parenthesis EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mi>y</mi></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mn>2</mn>
    <mo>+</mo> <mn>3</mn> <mo>.</mo> <mn>5</mn> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>-</mo> <mn>5</mn> <msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo>
    <msub><mi>x</mi> <mn>2</mn></msub></mrow></mtd> <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mi>N</mi>
    <mo>(</mo> <mn mathvariant="bold">0</mn> <mo>,</mo> <mrow><mtext mathvariant="bold">diag</mtext>
    <mo>(</mo> <mn mathvariant="bold">3</mn> <mo>,</mo> <mn mathvariant="bold">10</mn>
    <mo>)</mo></mrow> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>Ïµ</mi></mtd>
    <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn>0</mn>
    <mo>,</mo> <mn>1</mn> <mo>)</mo></mrow></mtd></mtr></mtable></math>
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column y 2nd Column equals 3rd Column
    2 plus 3.5 x 1 minus 5 x 2 plus epsilon 2nd Row 1st Column x 1 comma x 2 2nd Column
    tilde 3rd Column upper N left-parenthesis bold 0 bold comma bold diag bold left-parenthesis
    bold 3 bold comma bold 10 bold right-parenthesis bold right-parenthesis 3rd Row
    1st Column epsilon 2nd Column tilde 3rd Column upper N left-parenthesis 0 comma
    1 right-parenthesis EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mi>y</mi></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mn>2</mn>
    <mo>+</mo> <mn>3</mn> <mo>.</mo> <mn>5</mn> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>-</mo> <mn>5</mn> <msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo>
    <msub><mi>x</mi> <mn>2</mn></msub></mrow></mtd> <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mi>N</mi>
    <mo>(</mo> <mn mathvariant="bold">0</mn> <mo>,</mo> <mrow><mtext mathvariant="bold">diag</mtext>
    <mo>(</mo> <mn mathvariant="bold">3</mn> <mo>,</mo> <mn mathvariant="bold">10</mn>
    <mo>)</mo></mrow> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>Ïµ</mi></mtd>
    <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mi>N</mi> <mo>(</mo> <mn>0</mn>
    <mo>,</mo> <mn>1</mn> <mo>)</mo></mrow></mtd></mtr></mtable></math>
- en: Note that the features are independent draws from a normal distribution (covariance
    matrix is diagonal, and bold denotes vectors or matrices), and that residuals
    follow a standard normal distribution.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œç‰¹å¾æ˜¯ç‹¬ç«‹äºæ­£æ€åˆ†å¸ƒçš„æŠ½æ ·ï¼ˆåæ–¹å·®çŸ©é˜µæ˜¯å¯¹è§’çš„ï¼Œç²—ä½“è¡¨ç¤ºå‘é‡æˆ–çŸ©é˜µï¼‰ï¼Œæ®‹å·®éµå¾ªæ ‡å‡†æ­£æ€åˆ†å¸ƒã€‚
- en: 'You are now ready to run the MC simulation. A typical simulation is comprised
    of the following steps:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨ç°åœ¨å¯ä»¥å‡†å¤‡è¿è¡Œ MC æ¨¡æ‹Ÿã€‚å…¸å‹çš„æ¨¡æ‹ŸåŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š
- en: '*Fix parameters, seeds, and sample size (N)*. This ensures that one single
    MC experiment can be performed.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç¡®å®šå‚æ•°ã€ç§å­å’Œæ ·æœ¬å¤§å° (N)*ã€‚è¿™ç¡®ä¿å¯ä»¥æ‰§è¡Œå•ä¸ª MC å®éªŒã€‚'
- en: '*Define what you wish to accomplish*. Typically, you want to test the performance
    of an ML algorithm against the true DGP, for instance, by computing the bias.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*å®šä¹‰æ‚¨å¸Œæœ›å®ç°çš„ç›®æ ‡*ã€‚é€šå¸¸ï¼Œæ‚¨å¸Œæœ›æµ‹è¯• ML ç®—æ³•ç›¸å¯¹äºçœŸå® DGP çš„æ€§èƒ½ï¼Œä¾‹å¦‚é€šè¿‡è®¡ç®—åå·®ã€‚'
- en: '*Fix a number of simulations ( <math alttext="upper M"><mi>M</mi></math> ),
    estimate, and save the parameters*. For each experiment, simulate and train the
    model, and compute the metric defined in the previous step. For the case of bias,
    it would be something like:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç¡®å®šæ¨¡æ‹Ÿçš„æ•°é‡ ( <math alttext="upper M"><mi>M</mi></math> )ï¼Œä¼°è®¡å¹¶ä¿å­˜å‚æ•°*ã€‚å¯¹äºæ¯ä¸ªå®éªŒï¼Œæ¨¡æ‹Ÿå¹¶è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è®¡ç®—åœ¨ä¸Šä¸€æ­¥éª¤ä¸­å®šä¹‰çš„åº¦é‡ã€‚å¯¹äºåå·®çš„æƒ…å†µï¼Œå¯èƒ½æ˜¯è¿™æ ·çš„ï¼š'
- en: <math alttext="Bias left-parenthesis theta comma ModifyingAbove theta With caret
    right-parenthesis equals upper E left-parenthesis ModifyingAbove theta With caret
    right-parenthesis minus theta" display="block"><mrow><mtext>Bias</mtext> <mrow><mo>(</mo>
    <mi>Î¸</mi> <mo>,</mo> <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <mi>E</mi> <mrow><mo>(</mo> <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover>
    <mo>)</mo></mrow> <mo>-</mo> <mi>Î¸</mi></mrow></math>
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <math alttext="Bias left-parenthesis theta comma ModifyingAbove theta With caret
    right-parenthesis equals upper E left-parenthesis ModifyingAbove theta With caret
    right-parenthesis minus theta" display="block"><mrow><mtext>Bias</mtext> <mrow><mo>(</mo>
    <mi>Î¸</mi> <mo>,</mo> <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <mi>E</mi> <mrow><mo>(</mo> <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover>
    <mo>)</mo></mrow> <mo>-</mo> <mi>Î¸</mi></mrow></math>
- en: Where <math alttext="theta"><mi>Î¸</mi></math> is the *true* parameter of interest
    (set up in step 1), <math alttext="ModifyingAbove theta With caret"><mover accent="true"><mi>Î¸</mi>
    <mo>^</mo></mover></math> is an estimate coming from an ML model, and the expectation
    is usually replaced with the sample mean across the *M* simulations.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: å…¶ä¸­<math alttext="theta"><mi>Î¸</mi></math>æ˜¯æ„Ÿå…´è¶£çš„*çœŸå®*å‚æ•°ï¼ˆåœ¨ç¬¬ä¸€æ­¥ä¸­è®¾ç½®ï¼‰ï¼Œ<math alttext="ModifyingAbove
    theta With caret"><mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover></math>æ˜¯æ¥è‡ªMLæ¨¡å‹çš„ä¼°è®¡ï¼ŒæœŸæœ›é€šå¸¸ç”¨*M*æ¬¡æ¨¡æ‹Ÿä¸­çš„æ ·æœ¬å‡å€¼æ›¿ä»£ã€‚
- en: '[FigureÂ 9-3](#ch9_mc_ols) shows the results from an MC simulation with three
    hundred experiments for the linear model defined and parameterized earlier. The
    estimated parameters for each experiment are saved, and the plot shows the sample
    mean and 95% confidence intervals, as well as the true parameters. The 95% confidence
    intervals are calculated directly from the results of the simulation by finding
    the 2.5% and 97.5% quantiles across the *M* experiments.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾9-3](#ch9_mc_ols)å±•ç¤ºäº†åœ¨æ—©æœŸå®šä¹‰å’Œå‚æ•°åŒ–çš„çº¿æ€§æ¨¡å‹çš„ä¸‰ç™¾æ¬¡MCæ¨¡æ‹Ÿå®éªŒç»“æœã€‚æ¯æ¬¡å®éªŒçš„ä¼°è®¡å‚æ•°éƒ½è¢«ä¿å­˜ï¼Œå›¾ä¸­æ˜¾ç¤ºäº†æ ·æœ¬å‡å€¼å’Œ95%ç½®ä¿¡åŒºé—´ï¼Œä»¥åŠçœŸå®å‚æ•°ã€‚ç½®ä¿¡åŒºé—´ç›´æ¥ä»æ¨¡æ‹Ÿç»“æœè®¡ç®—å¾—å‡ºï¼Œé€šè¿‡æ‰¾åˆ°*M*æ¬¡å®éªŒä¸­çš„2.5%å’Œ97.5%åˆ†ä½æ•°ã€‚'
- en: This is the *plain vanilla* simulation where all of the assumptions of ordinary
    least squares (OLS) are satisfied, so itâ€™s no surprise that linear regression
    does a great job at estimating the true parameters.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯*æ™®é€šçš„é¦™è‰*æ¨¡æ‹Ÿï¼Œå…¶ä¸­æ‰€æœ‰æ™®é€šæœ€å°äºŒä¹˜æ³•ï¼ˆOLSï¼‰çš„å‡è®¾éƒ½å¾—åˆ°æ»¡è¶³ï¼Œå› æ­¤çº¿æ€§å›å½’åœ¨ä¼°è®¡çœŸå®å‚æ•°æ—¶è¡¨ç°å‡ºè‰²å¹¶ä¸è¶³ä¸ºå¥‡ã€‚
- en: '![mc ols](assets/dshp_0903.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![mc ols](assets/dshp_0903.png)'
- en: Figure 9-3\. Results from an MC experiment with linear regression
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾9-3\. çº¿æ€§å›å½’çš„MCå®éªŒç»“æœ
- en: Now that Iâ€™ve used an MC simulation to verify that OLS estimates are unbiased,
    Iâ€™ll try something more interesting. What happens when the signal-to-noise ratio
    changes?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘å·²ç»ä½¿ç”¨MCæ¨¡æ‹ŸéªŒè¯äº†OLSä¼°è®¡æ˜¯æ— åçš„ï¼Œæˆ‘å°†å°è¯•æ›´æœ‰è¶£çš„äº‹æƒ…ã€‚å½“ä¿¡å·ä¸å™ªå£°æ¯”å‘ç”Ÿå˜åŒ–æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ
- en: Intuitively, the *signal-to-noise ratio* (SNR) measures the amount of information
    provided by the model (signal) relative to that from the unexplained part of the
    model (noise). In general, the more informative features you include, the *higher*
    the SNR for your prediction model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´è§‰ä¸Šï¼Œ*ä¿¡å·ä¸å™ªå£°æ¯”*ï¼ˆSNRï¼‰è¡¡é‡æ¨¡å‹æä¾›çš„ä¿¡æ¯é‡ï¼ˆä¿¡å·ï¼‰ä¸æ¨¡å‹æœªè§£é‡Šéƒ¨åˆ†çš„ä¿¡æ¯é‡ï¼ˆå™ªå£°ï¼‰ä¹‹æ¯”ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œä½ åŒ…å«çš„ä¿¡æ¯ç‰¹å¾è¶Šå¤šï¼Œé¢„æµ‹æ¨¡å‹çš„SNRå°±*è¶Šé«˜*ã€‚
- en: Using the first simulation as a baseline, itâ€™s straightforward to change the
    SNR by changing the residual variance *Ïƒ*Â² *and holding the variance of the features*
    fixed. [FigureÂ 9-4](#ch9_mc_ols_snr) plots the results from a new MC simulation
    with the same parameters as before, except for the residual variance, which is
    now one thousand times larger.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç¬¬ä¸€æ¬¡æ¨¡æ‹Ÿä½œä¸ºåŸºå‡†ï¼Œé€šè¿‡æ”¹å˜æ®‹å·®æ–¹å·®*Ïƒ*Â²å¹¶ä¿æŒç‰¹å¾çš„æ–¹å·®ä¸å˜ï¼Œå¯ä»¥è½»æ¾åœ°æ”¹å˜SNRã€‚[å›¾9-4](#ch9_mc_ols_snr)å±•ç¤ºäº†ä»æ–°çš„MCæ¨¡æ‹Ÿç»“æœä¸­ç»˜åˆ¶çš„ç»“æœï¼Œä¸ä¹‹å‰ç›¸åŒçš„å‚æ•°ï¼Œå”¯ä¸€ä¸åŒçš„æ˜¯æ®‹å·®æ–¹å·®å¢å¤§äº†ä¸€åƒå€ã€‚
- en: '![mc ols signal](assets/dshp_0904.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![mc ols ä¿¡å·](assets/dshp_0904.png)'
- en: Figure 9-4\. Linear regression and decreasing the SNR
  id: totrans-50
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾9-4\. çº¿æ€§å›å½’ä¸SNRé™ä½
- en: You can visually validate that OLS remains unbiased in the sense that the average
    of the estimates is *very close* to the true parameters. But because of the lower
    SNR, estimates are now less precise (larger confidence intervals). This is a typical
    symptom when your SNR is not high enough.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥ç›´è§‚åœ°éªŒè¯OLSä¿æŒæ— åæ€§ï¼Œå³ä¼°è®¡çš„å¹³å‡å€¼éå¸¸æ¥è¿‘çœŸå®å‚æ•°ã€‚ä½†ç”±äºSNRè¾ƒä½ï¼Œä¼°è®¡ç°åœ¨ä¸é‚£ä¹ˆç²¾ç¡®ï¼ˆç½®ä¿¡åŒºé—´è¾ƒå¤§ï¼‰ã€‚å½“ä½ çš„SNRä¸å¤Ÿé«˜æ—¶ï¼Œè¿™æ˜¯ä¸€ç§å…¸å‹çš„ç—‡çŠ¶ã€‚
- en: What Are Partial Dependence Plots?
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯åä¾èµ–å›¾ï¼Ÿ
- en: 'Notwithstanding its subpar predictive performance, linear regression is still
    great from an *interpretability* standpoint. To see this, take the simple linear
    model used before:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å…¶é¢„æµ‹æ€§èƒ½ä¸ä½³ï¼Œä½†ä»*å¯è§£é‡Šæ€§*çš„è§’åº¦æ¥çœ‹ï¼Œçº¿æ€§å›å½’ä»ç„¶å¾ˆå‡ºè‰²ã€‚ä¸ºäº†çœ‹æ¸…æ¥šè¿™ä¸€ç‚¹ï¼Œçœ‹çœ‹ä¹‹å‰ä½¿ç”¨çš„ç®€å•çº¿æ€§æ¨¡å‹ï¼š
- en: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>Ïµ</mi></mrow></math>
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>+</mo> <mi>Ïµ</mi></mrow></math>
- en: 'Since the residual is mean-zero by assumption, calculating the conditional
    expectation and partial derivatives, you get:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºæ®‹å·®æ ¹æ®å‡è®¾å¹³å‡ä¸ºé›¶ï¼Œè®¡ç®—æ¡ä»¶æœŸæœ›å’Œåå¯¼æ•°ï¼Œå¾—åˆ°ï¼š
- en: <math alttext="StartFraction partial-differential upper E left-parenthesis y
    vertical-bar bold upper X bold right-parenthesis Over partial-differential x Subscript
    k Baseline EndFraction equals alpha Subscript k" display="block"><mrow><mfrac><mrow><mi>âˆ‚</mi><mi>E</mi><mo>(</mo><mi>y</mi><mo>|</mo><mi>ğ—</mi><mo>)</mo></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>Î±</mi>
    <mi>k</mi></msub></mrow></math>
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartFraction partial-differential upper E left-parenthesis y
    vertical-bar bold upper X bold right-parenthesis Over partial-differential x Subscript
    k Baseline EndFraction equals alpha Subscript k" display="block"><mrow><mfrac><mrow><mi>âˆ‚</mi><mi>E</mi><mo>(</mo><mi>y</mi><mo>|</mo><mi>ğ—</mi><mo>)</mo></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mi>k</mi></msub></mrow></mfrac> <mo>=</mo> <msub><mi>Î±</mi>
    <mi>k</mi></msub></mrow></math>
- en: 'This shows that each parameter can be interpreted as the *marginal effect*
    of the corresponding feature on the expected outcome (conditioning on everything
    else). Put differently: in the linear world, a one-unit change in a feature is
    associated with a change in <math alttext="alpha Subscript k"><msub><mi>Î±</mi>
    <mi>k</mi></msub></math> units in the outcome. This makes OLS potentially great
    from a storytelling perspective.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™è¡¨æ˜æ¯ä¸ªå‚æ•°å¯ä»¥è§£é‡Šä¸ºå¯¹æœŸæœ›ç»“æœçš„ç›¸åº”ç‰¹å¾çš„*è¾¹é™…æ•ˆåº”*ï¼ˆåœ¨å…¶ä»–æ¡ä»¶ä¸‹ï¼‰ã€‚æ¢å¥è¯è¯´ï¼Œåœ¨çº¿æ€§ä¸–ç•Œä¸­ï¼Œç‰¹å¾çš„å•ä½å˜åŒ–ä¸ç»“æœä¸­ <math alttext="alpha
    Subscript k"><msub><mi>Î±</mi> <mi>k</mi></msub></math> å•ä½çš„å˜åŒ–ç›¸å…³è”ã€‚è¿™ä½¿OLSåœ¨å™äº‹è§†è§’ä¸Šå…·æœ‰æ½œåŠ›ã€‚
- en: '*Partial dependence plots* (PDPs) are the counterpart for nonlinear models,
    such as random forest or gradient boosting regression:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*å±€éƒ¨ä¾èµ–å›¾*ï¼ˆPDPsï¼‰æ˜¯éçº¿æ€§æ¨¡å‹ï¼ˆä¾‹å¦‚éšæœºæ£®æ—æˆ–æ¢¯åº¦æå‡å›å½’ï¼‰çš„å¯¹åº”ç‰©ï¼š'
- en: <math alttext="y equals f left-parenthesis x 1 comma x 2 right-parenthesis"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <mi>f</mi> <mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals f left-parenthesis x 1 comma x 2 right-parenthesis"
    display="block"><mrow><mi>y</mi> <mo>=</mo> <mi>f</mi> <mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></math>
- en: where *f* represents the possibly nonlinear function that you want to learn.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œ*f*ä»£è¡¨æ‚¨æƒ³å­¦ä¹ çš„å¯èƒ½æ˜¯éçº¿æ€§å‡½æ•°ã€‚
- en: You can easily calculate PDPs for feature *j* by following these steps:^([1](ch09.html#id559))
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡ä»¥ä¸‹æ­¥éª¤å¯ä»¥è½»æ¾è®¡ç®—ç‰¹å¾ *j* çš„PDPï¼š^([1](ch09.html#id559))
- en: '*Train the model*. Train the model using the training sample, and save the
    model object.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è®­ç»ƒæ¨¡å‹*ã€‚ä½¿ç”¨è®­ç»ƒæ ·æœ¬è®­ç»ƒæ¨¡å‹ï¼Œå¹¶ä¿å­˜æ¨¡å‹å¯¹è±¡ã€‚'
- en: '*Calculate the means of the features*. Calculate the means of the *K* features
    <math alttext="bold x overbar equals left-parenthesis x overbar Subscript 1 Baseline
    comma midline-horizontal-ellipsis comma x overbar Subscript upper K Baseline right-parenthesis"><mrow><mover><mi>ğ±</mi>
    <mo>Â¯</mo></mover> <mo>=</mo> <mrow><mo>(</mo> <msub><mover><mi>x</mi> <mo>Â¯</mo></mover>
    <mn>1</mn></msub> <mo>,</mo> <mo>â‹¯</mo> <mo>,</mo> <msub><mover><mi>x</mi> <mo>Â¯</mo></mover>
    <mi>K</mi></msub> <mo>)</mo></mrow></mrow></math> . Because of random sampling,
    it shouldnâ€™t matter if you use the test or training sample.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è®¡ç®—ç‰¹å¾çš„å‡å€¼*ã€‚è®¡ç®—*K*ä¸ªç‰¹å¾ <math alttext="bold x overbar equals left-parenthesis x
    overbar Subscript 1 Baseline comma midline-horizontal-ellipsis comma x overbar
    Subscript upper K Baseline right-parenthesis"><mrow><mover><mi>ğ±</mi> <mo>Â¯</mo></mover>
    <mo>=</mo> <mrow><mo>(</mo> <msub><mover><mi>x</mi> <mo>Â¯</mo></mover> <mn>1</mn></msub>
    <mo>,</mo> <mo>â‹¯</mo> <mo>,</mo> <msub><mover><mi>x</mi> <mo>Â¯</mo></mover> <mi>K</mi></msub>
    <mo>)</mo></mrow></mrow></math> ã€‚ç”±äºéšæœºæŠ½æ ·ï¼Œä½¿ç”¨æµ‹è¯•æ ·æœ¬æˆ–è®­ç»ƒæ ·æœ¬åº”è¯¥æ²¡æœ‰åŒºåˆ«ã€‚'
- en: '*Create a linear grid for the j-th feature <math alttext="x Subscript j"><msub><mi>x</mi>
    <mi>j</mi></msub></math>* . Fix a grid size *G* and create the grid as <math alttext="grid
    left-parenthesis x Subscript j Baseline right-parenthesis equals left-parenthesis
    x Subscript 0 j Baseline comma x Subscript 1 j Baseline comma midline-horizontal-ellipsis
    comma x Subscript upper G j Baseline right-parenthesis"><mrow><mtext>grid</mtext>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>j</mi></msub> <mo>)</mo></mrow> <mo>=</mo>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mrow><mn>0</mn><mi>j</mi></mrow></msub> <mo>,</mo>
    <msub><mi>x</mi> <mrow><mn>1</mn><mi>j</mi></mrow></msub> <mo>,</mo> <mo>â‹¯</mo>
    <mo>,</mo> <msub><mi>x</mi> <mrow><mi>G</mi><mi>j</mi></mrow></msub> <mo>)</mo></mrow></mrow></math>
    , where indices 0 and G are used to denote the minimum and maximum values of the
    feature in your sample.^([2](ch09.html#id560))'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä¸ºç¬¬jä¸ªç‰¹å¾åˆ›å»ºçº¿æ€§ç½‘æ ¼ <math alttext="x Subscript j"><msub><mi>x</mi> <mi>j</mi></msub></math>*
    ã€‚å›ºå®šç½‘æ ¼å¤§å° *G* å¹¶åˆ›å»ºç½‘æ ¼ä¸º <math alttext="grid left-parenthesis x Subscript j Baseline
    right-parenthesis equals left-parenthesis x Subscript 0 j Baseline comma x Subscript
    1 j Baseline comma midline-horizontal-ellipsis comma x Subscript upper G j Baseline
    right-parenthesis"><mrow><mtext>grid</mtext> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>j</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mrow><mn>0</mn><mi>j</mi></mrow></msub> <mo>,</mo> <msub><mi>x</mi> <mrow><mn>1</mn><mi>j</mi></mrow></msub>
    <mo>,</mo> <mo>â‹¯</mo> <mo>,</mo> <msub><mi>x</mi> <mrow><mi>G</mi><mi>j</mi></mrow></msub>
    <mo>)</mo></mrow></mrow></math> ï¼Œå…¶ä¸­ç´¢å¼•0å’ŒGç”¨äºè¡¨ç¤ºæ ·æœ¬ä¸­ç‰¹å¾çš„æœ€å°å€¼å’Œæœ€å¤§å€¼ã€‚^([2](ch09.html#id560))'
- en: '*Compute a means-grid matrix*. Matrix <math alttext="bold upper X overbar Subscript
    bold j"><msub><mover><mi>ğ—</mi> <mo>Â¯</mo></mover> <mi>ğ£</mi></msub></math> has
    the linear grid for <math alttext="x Subscript j"><msub><mi>x</mi> <mi>j</mi></msub></math>
    in the corresponding column, and means for all other features elsewhere:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è®¡ç®—å‡å€¼-ç½‘æ ¼çŸ©é˜µ*ã€‚çŸ©é˜µ <math alttext="bold upper X overbar Subscript bold j"><msub><mover><mi>ğ—</mi>
    <mo>Â¯</mo></mover> <mi>ğ£</mi></msub></math> åœ¨ç›¸åº”åˆ—ä¸­å…·æœ‰<math alttext="x Subscript
    j"><msub><mi>x</mi> <mi>j</mi></msub></math>çš„çº¿æ€§ç½‘æ ¼ï¼Œå…¶ä»–ç‰¹å¾çš„å‡å€¼ä½äºå…¶ä»–åœ°æ–¹ï¼š'
- en: <math alttext="bold upper X overbar Subscript bold j Baseline equals Start 4
    By 6 Matrix 1st Row 1st Column x overbar Subscript 1 2nd Column x overbar Subscript
    2 3rd Column midline-horizontal-ellipsis 4th Column x Subscript 0 j 5th Column
    midline-horizontal-ellipsis 6th Column x overbar Subscript upper K 2nd Row 1st
    Column x overbar Subscript 1 2nd Column x overbar Subscript 2 3rd Column midline-horizontal-ellipsis
    4th Column x Subscript 1 j 5th Column midline-horizontal-ellipsis 6th Column x
    overbar Subscript upper K 3rd Row 1st Column vertical-ellipsis 2nd Column vertical-ellipsis
    3rd Column down-right-diagonal-ellipsis 4th Column vertical-ellipsis 5th Column
    vertical-ellipsis 4th Row 1st Column x overbar Subscript 1 2nd Column x overbar
    Subscript 2 3rd Column midline-horizontal-ellipsis 4th Column x Subscript upper
    G j 5th Column midline-horizontal-ellipsis 6th Column x overbar Subscript upper
    K EndMatrix Subscript upper G times upper K" display="block"><mrow><msub><mover><mi>ğ—</mi>
    <mo>Â¯</mo></mover> <mi>ğ£</mi></msub> <mo>=</mo> <msub><mfenced close=")" open="("><mtable><mtr><mtd><msub><mover><mi>x</mi>
    <mo>Â¯</mo></mover> <mn>1</mn></msub></mtd> <mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover>
    <mn>2</mn></msub></mtd> <mtd><mo>â‹¯</mo></mtd><mtd><msub><mi>x</mi> <mrow><mn>0</mn><mi>j</mi></mrow></msub></mtd>
    <mtd><mo>â‹¯</mo></mtd><mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover> <mi>K</mi></msub></mtd></mtr>
    <mtr><mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover> <mn>1</mn></msub></mtd> <mtd><msub><mover><mi>x</mi>
    <mo>Â¯</mo></mover> <mn>2</mn></msub></mtd> <mtd><mo>â‹¯</mo></mtd><mtd><msub><mi>x</mi>
    <mrow><mn>1</mn><mi>j</mi></mrow></msub></mtd> <mtd><mo>â‹¯</mo></mtd><mtd><msub><mover><mi>x</mi>
    <mo>Â¯</mo></mover> <mi>K</mi></msub></mtd></mtr> <mtr><mtd><mo>â‹®</mo></mtd><mtd><mo>â‹®</mo></mtd><mtd><mo>â‹±</mo></mtd><mtd><mo>â‹®</mo></mtd><mtd><mo>â‹®</mo></mtd></mtr><mtr><mtd><msub><mover><mi>x</mi>
    <mo>Â¯</mo></mover> <mn>1</mn></msub></mtd> <mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover>
    <mn>2</mn></msub></mtd> <mtd><mo>â‹¯</mo></mtd><mtd><msub><mi>x</mi> <mrow><mi>G</mi><mi>j</mi></mrow></msub></mtd>
    <mtd><mo>â‹¯</mo></mtd><mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover> <mi>K</mi></msub></mtd></mtr></mtable></mfenced>
    <mrow><mi>G</mi><mo>Ã—</mo><mi>K</mi></mrow></msub></mrow></math>
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <math alttext="bold upper X overbar Subscript bold j Baseline equals Start 4
    By 6 Matrix 1st Row 1st Column x overbar Subscript 1 2nd Column x overbar Subscript
    2 3rd Column midline-horizontal-ellipsis 4th Column x Subscript 0 j 5th Column
    midline-horizontal-ellipsis 6th Column x overbar Subscript upper K 2nd Row 1st
    Column x overbar Subscript 1 2nd Column x overbar Subscript 2 3rd Column midline-horizontal-ellipsis
    4th Column x Subscript 1 j 5th Column midline-horizontal-ellipsis 6th Column x
    overbar Subscript upper K 3rd Row 1st Column vertical-ellipsis 2nd Column vertical-ellipsis
    3rd Column down-right-diagonal-ellipsis 4th Column vertical-ellipsis 5th Column
    vertical-ellipsis 4th Row 1st Column x overbar Subscript 1 2nd Column x overbar
    Subscript 2 3rd Column midline-horizontal-ellipsis 4th Column x Subscript upper
    G j 5th Column midline-horizontal-ellipsis 6th Column x overbar Subscript upper
    K EndMatrix Subscript upper G times upper K" display="block"><mrow><msub><mover><mi>ğ—</mi>
    <mo>Â¯</mo></mover> <mi>ğ£</mi></msub> <mo>=</mo> <msub><mfenced close=")" open="("><mtable><mtr><mtd><msub><mover><mi>x</mi>
    <mo>Â¯</mo></mover> <mn>1</mn></msub></mtd> <mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover>
    <mn>2</mn></msub></mtd> <mtd><mo>â‹¯</mo></mtd><mtd><msub><mi>x</mi> <mrow><mn>0</mn><mi>j</mi></mrow></msub></mtd>
    <mtd><mo>â‹¯</mo></mtd><mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover> <mi>K</mi></msub></mtd></mtr>
    <mtr><mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover> <mn>1</mn></msub></mtd> <mtd><msub><mover><mi>x</mi>
    <mo>Â¯</mo></mover> <mn>2</mn></msub></mtd> <mtd><mo>â‹¯</mo></mtd><mtd><msub><mi>x</mi>
    <mrow><mn>1</mn><mi>j</mi></mrow></msub></mtd> <mtd><mo>â‹¯</mo></mtd><mtd><msub><mover><mi>x</mi>
    <mo>Â¯</mo></mover> <mi>K</mi></msub></mtd></mtr> <mtr><mtd><mo>â‹®</mo></mtd><mtd><mo>â‹®</mo></mtd><mtd><mo>â‹±</mo></mtd><mtd><mo>â‹®</mo></mtd><mtd><mo>â‹®</mo></mtd></mtr><mtr><mtd><msub><mover><mi>x</mi>
    <mo>Â¯</mo></mover> <mn>1</mn></msub></mtd> <mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover>
    <mn>2</mn></msub></mtd> <mtd><mo>â‹¯</mo></mtd><mtd><msub><mi>x</mi> <mrow><mi>G</mi><mi>j</mi></mrow></msub></mtd>
    <mtd><mo>â‹¯</mo></mtd><mtd><msub><mover><mi>x</mi> <mo>Â¯</mo></mover> <mi>K</mi></msub></mtd></mtr></mtable></mfenced>
    <mrow><mi>G</mi><mo>Ã—</mo><mi>K</mi></mrow></msub></mrow></math>
- en: '*Make a prediction*. Using your trained model, make a prediction using the
    means-grid matrix. This gives you the PDP for feature *j*:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è¿›è¡Œé¢„æµ‹*ã€‚ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä½¿ç”¨å‡å€¼-ç½‘æ ¼çŸ©é˜µè¿›è¡Œé¢„æµ‹ã€‚è¿™ç»™å‡ºäº†ç‰¹å¾ *j* çš„PDPï¼š'
- en: <math alttext="PDP left-parenthesis x Subscript j Baseline right-parenthesis
    equals ModifyingAbove f With caret left-parenthesis bold upper X Subscript bold
    j Baseline overbar right-parenthesis" display="block"><mrow><mtext>PDP</mtext>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>j</mi></msub> <mo>)</mo></mrow> <mo>=</mo>
    <mover accent="true"><mi>f</mi> <mo>^</mo></mover> <mrow><mo>(</mo> <mover><msub><mi>ğ—</mi>
    <mi>ğ£</mi></msub> <mo>Â¯</mo></mover> <mo>)</mo></mrow></mrow></math>
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <math alttext="PDP left-parenthesis x Subscript j Baseline right-parenthesis
    equals ModifyingAbove f With caret left-parenthesis bold upper X Subscript bold
    j Baseline overbar right-parenthesis" display="block"><mrow><mtext>PDP</mtext>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>j</mi></msub> <mo>)</mo></mrow> <mo>=</mo>
    <mover accent="true"><mi>f</mi> <mo>^</mo></mover> <mrow><mo>(</mo> <mover><msub><mi>ğ—</mi>
    <mi>ğ£</mi></msub> <mo>Â¯</mo></mover> <mo>)</mo></mrow></mrow></math>
- en: 'Note that the *partial* derivative and the *partial* dependence plots answer
    a very similar question: what is the predicted change in the outcome when only
    one feature is allowed to vary? With nonlinear functions, you need to fix everything
    else at some value (standard practice is the sample mean, but you can choose otherwise).
    The partial derivative focuses on *changes*, while the PDP plots the entire predicted
    outcome given a feature that is allowed to vary.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ï¼Œ*åå¯¼æ•°*å’Œ*åä¾èµ–å›¾*å›ç­”äº†ä¸€ä¸ªéå¸¸ç±»ä¼¼çš„é—®é¢˜ï¼šå½“åªå…è®¸ä¸€ä¸ªç‰¹å¾å˜åŒ–æ—¶ï¼Œé¢„æµ‹ç»“æœçš„å˜åŒ–æ˜¯å¤šå°‘ï¼Ÿå¯¹äºéçº¿æ€§å‡½æ•°ï¼Œä½ éœ€è¦å°†å…¶ä»–æ‰€æœ‰å€¼å›ºå®šåœ¨æŸä¸ªå€¼ä¸Šï¼ˆæ ‡å‡†åšæ³•æ˜¯æ ·æœ¬å‡å€¼ï¼Œä½†ä½ ä¹Ÿå¯ä»¥é€‰æ‹©å…¶ä»–å€¼ï¼‰ã€‚åå¯¼æ•°å…³æ³¨*å˜åŒ–*ï¼Œè€Œåä¾èµ–å›¾åˆ™æ˜¾ç¤ºäº†åœ¨å…è®¸ä¸€ä¸ªç‰¹å¾å˜åŒ–æ—¶çš„æ•´ä½“é¢„æµ‹ç»“æœã€‚
- en: 'The pseudocode Iâ€™ve shown you works well for continuous features. With categorical
    features, you need to be careful with the â€œgridâ€: instead of creating a linear
    grid, you just create an array of possible values, such as *{0,1}* for a dummy
    variable. Everything else is the same, but a bar plot makes more sense here, as
    explained in [ChapterÂ 8](ch08.html#ch08_datavis).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç»™ä½ å±•ç¤ºçš„ä¼ªä»£ç å¯¹äºè¿ç»­ç‰¹å¾æ•ˆæœå¾ˆå¥½ã€‚å¯¹äºåˆ†ç±»ç‰¹å¾ï¼Œä½ éœ€è¦åœ¨â€œç½‘æ ¼â€ä¸Šå°å¿ƒå¤„ç†ï¼šä¸æ˜¯åˆ›å»ºçº¿æ€§ç½‘æ ¼ï¼Œè€Œæ˜¯åˆ›å»ºå¯èƒ½å€¼çš„æ•°ç»„ï¼Œä¾‹å¦‚*{0,1}*ä½œä¸ºè™šæ‹Ÿå˜é‡ã€‚å…¶ä½™éƒ¨åˆ†ä¿æŒä¸å˜ï¼Œä½†åœ¨è¿™é‡Œä½¿ç”¨æ¡å½¢å›¾æ›´åˆç†ï¼Œæ­£å¦‚[ç¬¬8ç« ](ch08.html#ch08_datavis)ä¸­æ‰€è§£é‡Šçš„é‚£æ ·ã€‚
- en: 'Iâ€™ll now use the first model I simulated to compare the results from a linear
    regression and scikit-learnâ€™s [gradient boosting regression](https://oreil.ly/UNDoi)
    (GBR) and [random forest regression](https://oreil.ly/fFCoh) (RFR). This is a
    useful benchmark to set: nonlinear algorithms are expected to be more powerful
    at identifying nonlinearities, but are they also good when the true underlying
    model is linear?'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘å°†ä½¿ç”¨æˆ‘æ¨¡æ‹Ÿçš„ç¬¬ä¸€ä¸ªæ¨¡å‹æ¥æ¯”è¾ƒçº¿æ€§å›å½’å’Œ scikit-learn çš„[æ¢¯åº¦æå‡å›å½’](https://oreil.ly/UNDoi)ï¼ˆGBRï¼‰ä»¥åŠ[éšæœºæ£®æ—å›å½’](https://oreil.ly/fFCoh)ï¼ˆRFRï¼‰çš„ç»“æœã€‚è¿™æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŸºå‡†ï¼šéçº¿æ€§ç®—æ³•é¢„è®¡åœ¨è¯†åˆ«éçº¿æ€§æ–¹é¢æ›´å¼ºå¤§ï¼Œä½†å½“çœŸå®çš„åŸºç¡€æ¨¡å‹æ˜¯çº¿æ€§æ—¶ï¼Œå®ƒä»¬æ˜¯å¦åŒæ ·æœ‰æ•ˆå‘¢ï¼Ÿ
- en: '[FigureÂ 9-5](#ch9_pdp_depth1) plots the true slopes along with the estimated
    PDPs for GBR and RFR, using the *maximum depth = 1* parameter that governs the
    maximum height of each tree in both algorithms. This is not an unreasonable choice
    here since the model is linear in the parameters and features; a single tree wouldnâ€™t
    be able to learn the DGP, but this restriction is less important for ensembles.
    All other metaparameters are fixed at scikit-learnâ€™s default values.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾9-5](#ch9_pdp_depth1)ç»˜åˆ¶äº†çœŸå®æ–œç‡ä»¥åŠä½¿ç”¨*æœ€å¤§æ·±åº¦ = 1*å‚æ•°ä¼°è®¡çš„GBRå’ŒRFRçš„PDPï¼Œè¯¥å‚æ•°æ§åˆ¶äº†ä¸¤ç§ç®—æ³•ä¸­æ¯æ£µæ ‘çš„æœ€å¤§é«˜åº¦ã€‚è¿™é‡Œé€‰æ‹©è¿™ä¸ªå‚æ•°å¹¶ä¸ä¸åˆç†ï¼Œå› ä¸ºæ¨¡å‹åœ¨å‚æ•°å’Œç‰¹å¾ä¸Šæ˜¯çº¿æ€§çš„ï¼›å•æ£µæ ‘æ— æ³•å­¦ä¹ DGPï¼Œä½†å¯¹äºé›†æˆæ¥è¯´ï¼Œè¿™ä¸ªé™åˆ¶å°±ä¸é‚£ä¹ˆé‡è¦äº†ã€‚æ‰€æœ‰å…¶ä»–å…ƒå‚æ•°éƒ½ä¿æŒåœ¨scikit-learnçš„é»˜è®¤å€¼ã€‚'
- en: Itâ€™s interesting to see that out-of-the-box GBR makes a great job at recovering
    the true parameter for both features. RFR does a decent job with <math alttext="x
    2"><msub><mi>x</mi> <mn>2</mn></msub></math> but not with <math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math> .
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰è¶£çš„æ˜¯ï¼Œç›´æ¥ä½¿ç”¨GBRèƒ½å¤Ÿå¾ˆå¥½åœ°æ¢å¤ä¸¤ä¸ªç‰¹å¾çš„çœŸå®å‚æ•°ã€‚RFRå¯¹<math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>è¡¨ç°å¾—è¿˜å¯ä»¥ï¼Œä½†å¯¹<math
    alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>è¡¨ç°ä¸ä½³ã€‚
- en: '![pdp 1](assets/dshp_0905.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![pdp 1](assets/dshp_0905.png)'
- en: Figure 9-5\. PDPs for GBR and RFR regression (max. depth = 1)
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾9-5\. GBR å’Œ RFR å›å½’çš„PDPï¼ˆæœ€å¤§æ·±åº¦ = 1ï¼‰
- en: '[FigureÂ 9-6](#ch9_pdp_depth7) shows the results when *maximum depth = 7* and
    everything else is set at the default values as before. GBR performs well again,
    and with the additional allowed nonlinearity, RFR is also able to estimate the
    true parameters. Interestingly, with <math alttext="maximum depth greater-than-or-equal-to
    3"><mrow><mtext>maximum</mtext> <mtext>depth</mtext> <mo>â‰¥</mo> <mn>3</mn></mrow></math>
    , the right shape of the PDP for <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    starts to be recovered (results in the [repo](https://oreil.ly/dshp-repo) for
    this chapter). Whatâ€™s going on here?'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾9-6](#ch9_pdp_depth7)å±•ç¤ºäº†å½“*æœ€å¤§æ·±åº¦ = 7*æ—¶çš„ç»“æœï¼Œå…¶ä½™éƒ¨åˆ†ä¸ä¹‹å‰è®¾ç½®çš„é»˜è®¤å€¼ç›¸åŒã€‚GBRå†æ¬¡è¡¨ç°å‡ºè‰²ï¼Œè€Œä¸”åœ¨å…è®¸æ›´å¤šéçº¿æ€§çš„æƒ…å†µä¸‹ï¼ŒRFRä¹Ÿèƒ½å¤Ÿä¼°è®¡å‡ºçœŸå®çš„å‚æ•°ã€‚æœ‰è¶£çš„æ˜¯ï¼Œå½“<math
    alttext="maximum depth greater-than-or-equal-to 3"><mrow><mtext>æœ€å¤§æ·±åº¦</mtext> <mo>â‰¥</mo>
    <mn>3</mn></mrow></math>æ—¶ï¼Œå¼€å§‹æ¢å¤<math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>çš„æ­£ç¡®PDPå½¢çŠ¶ï¼ˆè¯¦ç»†ç»“æœè¯·è§æœ¬ç« çš„[repo](https://oreil.ly/dshp-repo)ï¼‰ã€‚è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ'
- en: '![pdp 7](assets/dshp_0906.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![pdp 7](assets/dshp_0906.png)'
- en: Figure 9-6\. PDPs for GB and RF regression (max. depth = 7)
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾9-6\. GBR å’Œ RF å›å½’çš„PDPï¼ˆæœ€å¤§æ·±åº¦ = 7ï¼‰
- en: 'This simulation has two parameters that simultaneously give more weight to
    the second feature <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    : it was drawn from a normal distribution with higher variance ( <math alttext="sigma
    22 equals 10 greater-than 3 equals sigma 11"><mrow><msub><mi>Ïƒ</mi> <mn>22</mn></msub>
    <mo>=</mo> <mn>10</mn> <mo>></mo> <mn>3</mn> <mo>=</mo> <msub><mi>Ïƒ</mi> <mn>11</mn></msub></mrow></math>
    ), and the corresponding parameter is also larger in absolute value. This means
    that one standard deviation change in <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    has a larger impact on *y* than a corresponding change in <math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math> . The result is that RFR tends to select the second feature
    more often in the first and only split of each tree.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªæ¨¡æ‹Ÿæœ‰ä¸¤ä¸ªå‚æ•°ï¼ŒåŒæ—¶ç»™äºˆç¬¬äºŒä¸ªç‰¹å¾ <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math>
    æ›´å¤šçš„æƒé‡ï¼šå®ƒæ˜¯ä»ä¸€ä¸ªå…·æœ‰æ›´é«˜æ–¹å·®çš„æ­£æ€åˆ†å¸ƒä¸­æŠ½å–çš„ï¼ˆ <math alttext="sigma 22 equals 10 greater-than 3 equals
    sigma 11"><mrow><msub><mi>Ïƒ</mi> <mn>22</mn></msub> <mo>=</mo> <mn>10</mn> <mo>></mo>
    <mn>3</mn> <mo>=</mo> <msub><mi>Ïƒ</mi> <mn>11</mn></msub></mrow></math> ï¼‰ï¼Œç›¸åº”çš„å‚æ•°åœ¨ç»å¯¹å€¼ä¸Šä¹Ÿæ›´å¤§ã€‚è¿™æ„å‘³ç€
    <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> çš„ä¸€ä¸ªæ ‡å‡†å·®å˜åŒ–å¯¹ *y* çš„å½±å“å¤§äºå¯¹
    <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> çš„ç›¸åº”å˜åŒ–ã€‚ç»“æœæ˜¯ï¼Œéšæœºæ£®æ—å›å½’å¾€å¾€åœ¨æ¯æ£µæ ‘çš„ç¬¬ä¸€ä¸ªå’Œå”¯ä¸€çš„åˆ†å‰²ç‚¹ä¸Šæ›´é¢‘ç¹åœ°é€‰æ‹©ç¬¬äºŒä¸ªç‰¹å¾ã€‚
- en: '[FigureÂ 9-7](#ch9_pdp_vcv_depth1) shows the results when I switch the variances
    of the simulated features and everything else remains the same. You can see that
    RFR now does a better job at estimating the true effect of the first feature and
    a relatively bad one (but not terrible as before) for the second feature. Since
    the parameters were not changedâ€”only the variance from the distributions that
    were drawnâ€” <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> still
    gets sufficient weight at the first splits of each tree in the ensemble, so the
    algorithm is able to pick up part of the true effect.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 9-7](#ch9_pdp_vcv_depth1) å±•ç¤ºäº†åœ¨æˆ‘åˆ‡æ¢æ¨¡æ‹Ÿç‰¹å¾çš„æ–¹å·®è€Œå…¶ä»–ä¸€åˆ‡ä¿æŒä¸å˜æ—¶çš„ç»“æœã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œç°åœ¨éšæœºæ£®æ—å›å½’èƒ½æ›´å¥½åœ°ä¼°è®¡ç¬¬ä¸€ä¸ªç‰¹å¾çš„çœŸå®æ•ˆæœï¼Œå¹¶ä¸”å¯¹ç¬¬äºŒä¸ªç‰¹å¾æœ‰ä¸€ä¸ªç›¸å¯¹è¾ƒå·®çš„ä¼°è®¡ï¼ˆä½†ä¸åƒä¹‹å‰é‚£æ ·ç³Ÿç³•ï¼‰ã€‚ç”±äºå‚æ•°æ²¡æœ‰æ”¹å˜ï¼Œåªæ˜¯ä»æŠ½å–çš„åˆ†å¸ƒä¸­æ”¹å˜äº†æ–¹å·®ï¼Œæ‰€ä»¥
    <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> ä»ç„¶åœ¨é›†æˆæ ‘çš„ç¬¬ä¸€ä¸ªåˆ†è£‚ç‚¹å¤„è·å¾—è¶³å¤Ÿçš„æƒé‡ï¼Œå› æ­¤ç®—æ³•èƒ½å¤Ÿæ•æ‰åˆ°éƒ¨åˆ†çœŸå®æ•ˆæœã€‚'
- en: '![pdp 1 switched](assets/dshp_0907.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![pdp 1 switched](assets/dshp_0907.png)'
- en: Figure 9-7\. PDPs when variances of features are switched (max. depth = 1)
  id: totrans-82
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 9-7\. å˜é‡ç‰¹å¾å€¼åˆ‡æ¢æ—¶çš„åå¯¼æ•°å›¾ï¼ˆæœ€å¤§æ·±åº¦ä¸º 1ï¼‰
- en: You may wonder if thereâ€™s another metaparameter that can be optimized to reduce
    the bias in this RFR estimation. As mentioned, the problem appears to be that
    <math alttext="x 2"><msub><mi>x</mi> <mn>2</mn></msub></math> is given more weight,
    so it ends up being selected for the first split in the tree (and any further
    splits if the maximum depth is increased). One way to proceed is by changing the
    default parameter `max_features` that sets the number of *randomly* chosen features
    that are allowed to compete in each split. The default value is the total number
    of features (two in this example), so <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math>
    always loses. But if you change it to one feature, thanks to the randomness of
    the selection, you force the ensemble to give it a free pass sometimes. [FigureÂ 9-8](#ch9_pdp_depth1_maxfeat)
    shows the results of making this change.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹Ÿè®¸ä½ ä¼šæƒ³çŸ¥é“æ˜¯å¦æœ‰å…¶ä»–å…ƒå‚æ•°å¯ä»¥ä¼˜åŒ–ï¼Œä»¥å‡å°‘è¿™ä¸ªéšæœºæ£®æ—å›å½’ä¼°è®¡ä¸­çš„åå·®ã€‚æ­£å¦‚å‰é¢æåˆ°çš„ï¼Œé—®é¢˜ä¼¼ä¹åœ¨äº <math alttext="x 2"><msub><mi>x</mi>
    <mn>2</mn></msub></math> è¢«èµ‹äºˆæ›´å¤§çš„æƒé‡ï¼Œå› æ­¤å®ƒæœ€ç»ˆè¢«é€‰ä¸ºæ ‘çš„ç¬¬ä¸€ä¸ªåˆ†å‰²ç‚¹ï¼ˆå¦‚æœå¢åŠ æœ€å¤§æ·±åº¦ï¼Œåˆ™è¿˜ä¼šè¢«é€‰ä¸ºä»»ä½•è¿›ä¸€æ­¥åˆ†å‰²çš„ç‚¹ï¼‰ã€‚ä¸€ç§è§£å†³æ–¹æ³•æ˜¯æ”¹å˜é»˜è®¤å‚æ•°
    `max_features`ï¼Œå®ƒè®¾ç½®æ¯æ¬¡åˆ†å‰²å…è®¸ç«äº‰çš„*éšæœº*é€‰æ‹©ç‰¹å¾çš„æ•°é‡ã€‚é»˜è®¤å€¼æ˜¯æ€»ç‰¹å¾æ•°ï¼ˆæœ¬ä¾‹ä¸­ä¸ºä¸¤ä¸ªï¼‰ï¼Œå› æ­¤ <math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math> æ€»æ˜¯å¤±è´¥ã€‚ä½†æ˜¯ï¼Œå¦‚æœå°†å…¶æ›´æ”¹ä¸ºä¸€ä¸ªç‰¹å¾ï¼Œç”±äºé€‰æ‹©çš„éšæœºæ€§ï¼Œæœ‰æ—¶ä¼šå¼ºåˆ¶é›†æˆç³»ç»Ÿæ”¾å®ƒä¸€é©¬ã€‚[å›¾Â 9-8](#ch9_pdp_depth1_maxfeat)
    å±•ç¤ºäº†è¿™ç§æ”¹å˜çš„ç»“æœã€‚
- en: '![pdp max_features](assets/dshp_0908.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![pdp max_features](assets/dshp_0908.png)'
- en: Figure 9-8\. Random forest PDPs (max. depth = 1 and max. features = 1)
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 9-8\. éšæœºæ£®æ—åå¯¼æ•°å›¾ï¼ˆæœ€å¤§æ·±åº¦ä¸º 1ï¼Œæœ€å¤§ç‰¹å¾æ•°ä¸º 1ï¼‰
- en: Omitted Variable Bias
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é—æ¼å˜é‡åå·®
- en: In linear regression, [*omitted variable bias*](https://oreil.ly/IqzUA) takes
    place when the data scientist fails to include one feature that *must have been
    included* and is correlated to any other included feature, creating biased parameter
    estimates and thus, suboptimal predictive performance.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çº¿æ€§å›å½’ä¸­ï¼Œ[*é—æ¼å˜é‡åå·®*](https://oreil.ly/IqzUA) å‘ç”Ÿåœ¨æ•°æ®ç§‘å­¦å®¶æœªåŒ…æ‹¬*å¿…é¡»åŒ…æ‹¬*å¹¶ä¸ä»»ä½•å…¶ä»–åŒ…æ‹¬çš„ç‰¹å¾ç›¸å…³çš„ä¸€ä¸ªç‰¹å¾æ—¶ï¼Œè¿™ä¼šå¯¼è‡´åè¯¯çš„å‚æ•°ä¼°è®¡ï¼Œä»è€Œå¯¼è‡´æ¬¡ä¼˜çš„é¢„æµ‹æ€§èƒ½ã€‚
- en: 'To explain how the bias works, letâ€™s go back to the simple two-feature linear
    model presented at the beginning of the chapter, but assume now that the data
    scientist includes only the first feature and estimates:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è§£é‡Šåå·®å¦‚ä½•å·¥ä½œï¼Œè®©æˆ‘ä»¬å›åˆ°æœ¬ç« å¼€å¤´ä»‹ç»çš„ç®€å•äºŒç‰¹å¾çº¿æ€§æ¨¡å‹ï¼Œä½†ç°åœ¨å‡è®¾æ•°æ®ç§‘å­¦å®¶ä»…åŒ…æ‹¬ç¬¬ä¸€ä¸ªç‰¹å¾å¹¶ä¼°è®¡ï¼š
- en: <math alttext="y equals beta 0 plus beta 1 x 1 plus eta" display="block"><mrow><mi>y</mi>
    <mo>=</mo> <msub><mi>Î²</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mi>Î·</mi></mrow></math>
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals beta 0 plus beta 1 x 1 plus eta" display="block"><mrow><mi>y</mi>
    <mo>=</mo> <msub><mi>Î²</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <mi>Î·</mi></mrow></math>
- en: 'The true unobserved coefficient for the included variable is <math alttext="alpha
    1"><msub><mi>Î±</mi> <mn>1</mn></msub></math> , so comparing it to the coefficient
    from the misspecified model ( <math alttext="beta 1"><msub><mi>Î²</mi> <mn>1</mn></msub></math>
    ), you can show that:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: åŒ…å«å˜é‡çš„çœŸå®æœªè§‚å¯Ÿç³»æ•°æ˜¯ <math alttext="alpha 1"><msub><mi>Î±</mi> <mn>1</mn></msub></math>
    ï¼Œå› æ­¤å°†å…¶ä¸è¯¯æŒ‡å®šæ¨¡å‹çš„ç³»æ•°ï¼ˆ <math alttext="beta 1"><msub><mi>Î²</mi> <mn>1</mn></msub></math>
    ï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œå¯ä»¥æ˜¾ç¤ºï¼š
- en: <math alttext="beta 1 equals alpha 1 plus ModifyingBelow alpha 2 StartFraction
    upper C o v left-parenthesis x 1 comma x 2 right-parenthesis Over upper V a r
    left-parenthesis x 1 right-parenthesis EndFraction With bottom-brace Underscript
    Bias Endscripts" display="block"><mrow><msub><mi>Î²</mi> <mn>1</mn></msub> <mo>=</mo>
    <msub><mi>Î±</mi> <mn>1</mn></msub> <mo>+</mo> <munder><munder accentunder="true"><mrow><msub><mi>Î±</mi>
    <mn>2</mn></msub> <mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo><msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>)</mo></mrow></mfrac></mrow> <mo>ï¸¸</mo></munder> <mtext>Bias</mtext></munder></mrow></math>
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="beta 1 equals alpha 1 plus ModifyingBelow alpha 2 StartFraction
    upper C o v left-parenthesis x 1 comma x 2 right-parenthesis Over upper V a r
    left-parenthesis x 1 right-parenthesis EndFraction With bottom-brace Underscript
    Bias Endscripts" display="block"><mrow><msub><mi>Î²</mi> <mn>1</mn></msub> <mo>=</mo>
    <msub><mi>Î±</mi> <mn>1</mn></msub> <mo>+</mo> <munder><munder accentunder="true"><mrow><msub><mi>Î±</mi>
    <mn>2</mn></msub> <mfrac><mrow><mi>C</mi><mi>o</mi><mi>v</mi><mo>(</mo><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo><msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow>
    <mrow><mi>V</mi><mi>a</mi><mi>r</mi><mo>(</mo><msub><mi>x</mi> <mn>1</mn></msub>
    <mo>)</mo></mrow></mfrac></mrow> <mo>ï¸¸</mo></munder> <mtext>Bias</mtext></munder></mrow></math>
- en: It follows that thereâ€™s bias when the two features are uncorrelated. Moreover,
    the sign of the bias depends on the sign of <math alttext="alpha 2 times upper
    C o v left-parenthesis x 1 comma x 2 right-parenthesis"><mrow><msub><mi>Î±</mi>
    <mn>2</mn></msub> <mo>Ã—</mo> <mi>C</mi> <mi>o</mi> <mi>v</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow></mrow></math> .
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœæ˜¯å½“ä¸¤ä¸ªç‰¹å¾æ— å…³è”æ—¶å­˜åœ¨åå·®ã€‚æ­¤å¤–ï¼Œåå·®çš„ç¬¦å·å–å†³äº <math alttext="alpha 2 times upper C o v left-parenthesis
    x 1 comma x 2 right-parenthesis"><mrow><msub><mi>Î±</mi> <mn>2</mn></msub> <mo>Ã—</mo>
    <mi>C</mi> <mi>o</mi> <mi>v</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math>
    ã€‚
- en: 'Letâ€™s start by simulating the same DGP as before, but excluding *x*[2]. Iâ€™ll
    do this for a grid of correlation coefficients, since these are bounded to the
    [âˆ’1,1] interval and are thus easier to work with. Recall that the true parameter
    is *Î±*[2] = âˆ’5, so the sign of the bias will be negative the sign of the correlation:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»æ¨¡æ‹Ÿä¸ä¹‹å‰ç›¸åŒçš„ DGP å¼€å§‹ï¼Œä½†æ’é™¤ *x*[2]ã€‚æˆ‘å°†å¯¹ç›¸å…³ç³»æ•°çš„ç½‘æ ¼è¿›è¡Œæ¨¡æ‹Ÿï¼Œå› ä¸ºè¿™äº›ç³»æ•°é™åˆ¶åœ¨ [âˆ’1,1] åŒºé—´å†…ï¼Œå› æ­¤æ›´å®¹æ˜“å¤„ç†ã€‚è¯·è®°ä½ï¼ŒçœŸå®å‚æ•°æ˜¯
    *Î±*[2] = âˆ’5ï¼Œå› æ­¤åå·®çš„ç¬¦å·å°†æ˜¯ç›¸å…³ç³»æ•°çš„è´Ÿå·ï¼š
- en: <math alttext="Sgn left-parenthesis upper B i a s right-parenthesis equals minus
    Sgn left-parenthesis upper C o v left-parenthesis x 1 comma x 2 right-parenthesis
    right-parenthesis" display="block"><mrow><mtext>Sgn</mtext> <mrow><mo>(</mo> <mi>B</mi>
    <mi>i</mi> <mi>a</mi> <mi>s</mi> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <mtext>Sgn</mtext>
    <mo>(</mo> <mi>C</mi> <mi>o</mi> <mi>v</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow>
    <mo>)</mo></mrow></math>
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="Sgn left-parenthesis upper B i a s right-parenthesis equals minus
    Sgn left-parenthesis upper C o v left-parenthesis x 1 comma x 2 right-parenthesis
    right-parenthesis" display="block"><mrow><mtext>Sgn</mtext> <mrow><mo>(</mo> <mi>B</mi>
    <mi>i</mi> <mi>a</mi> <mi>s</mi> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <mtext>Sgn</mtext>
    <mo>(</mo> <mi>C</mi> <mi>o</mi> <mi>v</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>)</mo></mrow>
    <mo>)</mo></mrow></math>
- en: 'To simulate <math alttext="x 1 comma x 2 tilde upper N left-parenthesis bold
    0 bold comma bold upper Sigma bold left-parenthesis rho bold right-parenthesis
    bold right-parenthesis"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>âˆ¼</mo> <mi>N</mi> <mrow><mo>(</mo> <mn mathvariant="bold">0</mn>
    <mo>,</mo> <mi>Î£</mi> <mrow><mo>(</mo> <mi>Ï</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
    , you can simplify the parameterization by having unit variances so that:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ¨¡æ‹Ÿ <math alttext="x 1 comma x 2 tilde upper N left-parenthesis bold 0 bold
    comma bold upper Sigma bold left-parenthesis rho bold right-parenthesis bold right-parenthesis"><mrow><msub><mi>x</mi>
    <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi> <mn>2</mn></msub> <mo>âˆ¼</mo> <mi>N</mi>
    <mrow><mo>(</mo> <mn mathvariant="bold">0</mn> <mo>,</mo> <mi>Î£</mi> <mrow><mo>(</mo>
    <mi>Ï</mi> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math> ï¼Œæ‚¨å¯ä»¥é€šè¿‡å…·æœ‰å•ä½æ–¹å·®æ¥ç®€åŒ–å‚æ•°åŒ–ï¼Œä»¥ä¾¿ï¼š
- en: <math alttext="normal upper Sigma left-parenthesis rho right-parenthesis equals
    Start 2 By 2 Matrix 1st Row 1st Column 1 2nd Column rho 2nd Row 1st Column rho
    2nd Column 1 EndMatrix" display="block"><mrow><mi>Î£</mi> <mrow><mo>(</mo> <mi>Ï</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mi>Ï</mi></mtd></mtr> <mtr><mtd><mi>Ï</mi></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="normal upper Sigma left-parenthesis rho right-parenthesis equals
    Start 2 By 2 Matrix 1st Row 1st Column 1 2nd Column rho 2nd Row 1st Column rho
    2nd Column 1 EndMatrix" display="block"><mrow><mi>Î£</mi> <mrow><mo>(</mo> <mi>Ï</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mfenced close=")" open="("><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mi>Ï</mi></mtd></mtr> <mtr><mtd><mi>Ï</mi></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'The steps to run the simulation are as follows:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡Œæ¨¡æ‹Ÿçš„æ­¥éª¤å¦‚ä¸‹ï¼š
- en: Fix a correlation parameter <math alttext="rho"><mi>Ï</mi></math> from the grid.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»ç½‘æ ¼ä¸­ç¡®å®šä¸€ä¸ªç›¸å…³å‚æ•° <math alttext="rho"><mi>Ï</mi></math> ã€‚
- en: Simulate the DGP given this correlation parameter.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»™å®šæ­¤ç›¸å…³å‚æ•°æ¨¡æ‹Ÿ DGPã€‚
- en: For each MC experiment, estimate the parameters excluding the second feature.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹äºæ¯ä¸ª MC å®éªŒï¼Œä¼°è®¡æ’é™¤ç¬¬äºŒä¸ªç‰¹å¾çš„å‚æ•°ã€‚
- en: Compute the bias across all MC experiments.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¡ç®—æ‰€æœ‰ MC å®éªŒä¸­çš„åå·®ã€‚
- en: Repeat for all other elements of the grid.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å¯¹ç½‘æ ¼ä¸­çš„æ‰€æœ‰å…¶ä»–å…ƒç´ é‡å¤ã€‚
- en: '[FigureÂ 9-9](#ch9_ovb_corrgrid) shows the results from an MC simulation with
    different correlation parameters. Four results are noteworthy:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 9-9](#ch9_ovb_corrgrid) æ˜¾ç¤ºäº†å…·æœ‰ä¸åŒç›¸å…³å‚æ•°çš„ MC æ¨¡æ‹Ÿçš„ç»“æœã€‚æœ‰å››ä¸ªç»“æœå€¼å¾—æ³¨æ„ï¼š'
- en: Bias is null when features are uncorrelated.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å½“ç‰¹å¾æ— å…³è”æ—¶ï¼Œåå·®ä¸ºé›¶ã€‚
- en: The sign of the bias is negative the sign of the correlation parameter.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åå·®çš„ç¬¦å·ä¸ºç›¸å…³å‚æ•°çš„è´Ÿå·ã€‚
- en: With unit correlation coefficient, bias equals the parameter of the excluded
    feature.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åœ¨å•ä½ç›¸å…³ç³»æ•°ä¸‹ï¼Œåå·®ç­‰äºè¢«æ’é™¤ç‰¹å¾çš„å‚æ•°ã€‚
- en: Thereâ€™s no bias for the intercept (by definition, uncorrelated with the omitted
    variable).
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆªè·æ²¡æœ‰åå·®ï¼ˆæ ¹æ®å®šä¹‰ï¼Œä¸è¢«æ’é™¤å˜é‡æ— å…³ï¼‰ã€‚
- en: '![bias corr grid](assets/dshp_0909.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![bias corr grid](assets/dshp_0909.png)'
- en: Figure 9-9\. Bias as a function of the correlation parameter
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 9-9\. åå·®ä½œä¸ºç›¸å…³å‚æ•°çš„å‡½æ•°
- en: 'Letâ€™s summarize this last finding: *if youâ€™re going to use linear regression,
    think really hard about the features you need to include!* Thatâ€™s why including
    some controls is always recommended even if you have only weak hypotheses about
    the underlying causal mechanism (for instance, including geographical dummies
    can help you mitigate the extent of omitted variable bias with features that vary
    at that level).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬æ€»ç»“è¿™ä¸€æœ€åçš„å‘ç°ï¼š*å¦‚æœä½ è¦ä½¿ç”¨çº¿æ€§å›å½’ï¼ŒåŠ¡å¿…è®¤çœŸè€ƒè™‘ä½ éœ€è¦åŒ…å«çš„ç‰¹å¾ï¼* è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå³ä½¿å¯¹äºåº•å±‚å› æœæœºåˆ¶åªæœ‰å¼±å‡è®¾çš„æƒ…å†µä¸‹ï¼ˆä¾‹å¦‚ï¼ŒåŒ…å«åœ°ç†è™šæ‹Ÿå˜é‡å¯èƒ½æœ‰åŠ©äºå‡è½»çœç•¥å˜é‡åå·®çš„ç¨‹åº¦ï¼‰ï¼Œä¹Ÿå»ºè®®å§‹ç»ˆåŒ…å«ä¸€äº›æ§åˆ¶å˜é‡ã€‚
- en: This said, these days almost no one uses OLS except in introductory courses
    or textbooks or when estimating causal effects ([ChapterÂ 15](ch15.html#ch15_incrementality)).
    A natural question is whether the more predictive algorithms also suffer from
    this problem.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ ·è¯´ï¼Œç°åœ¨å‡ ä¹æ²¡æœ‰äººä½¿ç”¨OLSï¼Œé™¤äº†å…¥é—¨è¯¾ç¨‹æˆ–æ•™ç§‘ä¹¦ï¼Œæˆ–è€…åœ¨ä¼°è®¡å› æœæ•ˆåº”æ—¶ï¼ˆ[ç¬¬15ç« ](ch15.html#ch15_incrementality)ï¼‰ã€‚ä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜æ˜¯æ›´å…·é¢„æµ‹æ€§èƒ½çš„ç®—æ³•æ˜¯å¦ä¹Ÿä¼šé­å—è¿™ä¸ªé—®é¢˜ã€‚
- en: 'To answer this, letâ€™s run an MC experiment and compute the bias from OLS and
    GBR. But I first need to find a way to estimate parameters with GBR that are comparable
    to those in the linear DGP. Inspecting a PDP ([FigureÂ 9-5](#ch9_pdp_depth1)) suggests
    a simple way to do it:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œè®©æˆ‘ä»¬è¿›è¡Œä¸€ä¸ªMCå®éªŒå¹¶è®¡ç®—OLSå’ŒGBRçš„åå·®ã€‚ä½†æˆ‘é¦–å…ˆéœ€è¦æ‰¾åˆ°ä¸€ç§æ–¹æ³•æ¥ä¼°è®¡ä¸çº¿æ€§DGPä¸­å¯æ¯”çš„GBRå‚æ•°ã€‚æ£€æŸ¥PDPï¼ˆ[å›¾Â 9-5](#ch9_pdp_depth1)ï¼‰å»ºè®®äº†ä¸€ä¸ªç®€å•çš„æ–¹æ³•ï¼š
- en: Construct the partial dependence plot for <math alttext="x 1"><msub><mi>x</mi>
    <mn>1</mn></msub></math> .
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æ„å»º <math alttext="x 1"><msub><mi>x</mi> <mn>1</mn></msub></math> çš„åä¾èµ–å›¾ã€‚
- en: Run a linear regression <math alttext="p d p equals gamma 0 plus gamma 1 Grid
    left-parenthesis x 1 right-parenthesis plus zeta"><mrow><mi>p</mi> <mi>d</mi>
    <mi>p</mi> <mo>=</mo> <msub><mi>Î³</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î³</mi>
    <mn>1</mn></msub> <mtext>Grid</mtext> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub>
    <mo>)</mo></mrow> <mo>+</mo> <mi>Î¶</mi></mrow></math> .
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è¿è¡Œçº¿æ€§å›å½’ <math alttext="p d p equals gamma 0 plus gamma 1 Grid left-parenthesis
    x 1 right-parenthesis plus zeta"><mrow><mi>p</mi> <mi>d</mi> <mi>p</mi> <mo>=</mo>
    <msub><mi>Î³</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î³</mi> <mn>1</mn></msub>
    <mtext>Grid</mtext> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow>
    <mo>+</mo> <mi>Î¶</mi></mrow></math> ã€‚
- en: Use the estimated slope parameter <math alttext="gamma 1"><msub><mi>Î³</mi> <mn>1</mn></msub></math>
    to compute the bias.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¼°è®¡çš„æ–œç‡å‚æ•° <math alttext="gamma 1"><msub><mi>Î³</mi> <mn>1</mn></msub></math>
    è®¡ç®—åå·®ã€‚
- en: '[FigureÂ 9-10](#ch9_ovb_gbr) plots simulated bias for the case of independent
    (left plot) and correlated (right plot) features for OLS and GBR *without metaparameter
    optimization*. As expected, with independent features, bias is indistinguishable
    from zero (see the confidence intervals). With positively correlated features,
    bias is negative and statistically different from zero, and this is true for *both*
    OLS and GBR. The results are discouraging and humbling: you cannot fix a data
    problem with an algorithm.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 9-10](#ch9_ovb_gbr) ç»˜åˆ¶äº†OLSå’ŒGBRåœ¨ç‹¬ç«‹ï¼ˆå·¦å›¾ï¼‰å’Œç›¸å…³ï¼ˆå³å›¾ï¼‰ç‰¹å¾æƒ…å†µä¸‹çš„æ¨¡æ‹Ÿåå·®ï¼Œ*æœªç»è¶…å‚æ•°ä¼˜åŒ–*ã€‚å¦‚é¢„æœŸçš„é‚£æ ·ï¼Œå¯¹äºç‹¬ç«‹ç‰¹å¾ï¼Œåå·®ä¸é›¶æ— å¼‚ï¼ˆå‚è§ç½®ä¿¡åŒºé—´ï¼‰ã€‚å¯¹äºæ­£ç›¸å…³ç‰¹å¾ï¼Œåå·®ä¸ºè´Ÿä¸”åœ¨ç»Ÿè®¡ä¸Šä¸é›¶æ˜¾è‘—ä¸åŒï¼Œè¿™å¯¹äº*OLSå’ŒGBRéƒ½æ˜¯å¦‚æ­¤*ã€‚ç»“æœä»¤äººæ²®ä¸§å’Œä»¤äººè­¦é†’ï¼šä½ ä¸èƒ½ç”¨ç®—æ³•ä¿®å¤æ•°æ®é—®é¢˜ã€‚'
- en: '![ovb gbr](assets/dshp_0910.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![ovb gbr](assets/dshp_0910.png)'
- en: Figure 9-10\. OLS and GBR bias for independent and correlated features
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 9-10\. OLS å’Œ GBR å¯¹ç‹¬ç«‹å’Œç›¸å…³ç‰¹å¾çš„åå·®
- en: Tip
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: æç¤º
- en: As a general rule, donâ€™t expect your algorithm to fix a problem with your data.
    There are *robust* algorithms, but none is bulletproof.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€èˆ¬è§„åˆ™ï¼Œä¸è¦æœŸæœ›ä½ çš„ç®—æ³•èƒ½è§£å†³æ•°æ®é—®é¢˜ã€‚è™½ç„¶æœ‰*å¥å£®*ç®—æ³•ï¼Œä½†æ²¡æœ‰ä¸€ä¸ªæ˜¯ä¸‡æ— ä¸€å¤±çš„ã€‚
- en: Simulating Classification Problems
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿåˆ†ç±»é—®é¢˜
- en: 'As you may recall, in classification problems the outcome variable is categorical
    rather than continuous. These problems arise frequently in data science (DS),
    with typical use cases that include predicting customer churn (two categories:
    a user churned or didnâ€™t churn), problems where a customer needs to accept or
    reject an offer, such as cross- and up-selling or any other marketing campaign,
    predicting fraud, and many others.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æ‚¨å¯èƒ½è®°å¾—çš„é‚£æ ·ï¼Œåœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œç»“æœå˜é‡æ˜¯åˆ†ç±»çš„è€Œä¸æ˜¯è¿ç»­çš„ã€‚è¿™äº›é—®é¢˜åœ¨æ•°æ®ç§‘å­¦ï¼ˆDSï¼‰ä¸­ç»å¸¸å‡ºç°ï¼Œå…¸å‹ç”¨ä¾‹åŒ…æ‹¬é¢„æµ‹å®¢æˆ·æµå¤±ï¼ˆä¸¤ç±»åˆ«ï¼šç”¨æˆ·æµå¤±æˆ–æœªæµå¤±ï¼‰ï¼Œéœ€è¦å®¢æˆ·æ¥å—æˆ–æ‹’ç»æä¾›çš„æƒ…å†µï¼Œå¦‚è·¨é”€å”®å’Œæå‡é”€å”®æˆ–ä»»ä½•å…¶ä»–è¥é”€æ´»åŠ¨ï¼Œé¢„æµ‹æ¬ºè¯ˆç­‰ã€‚
- en: Latent Variable Models
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ½œå˜é‡æ¨¡å‹
- en: 'One standard way to simulate binomial classification models is by using latent
    variables.^([3](ch09.html#id569)) A variable is *latent* if it canâ€™t be directly
    observed but affects an observable outcome. This definition will become more clear
    after inspecting the following DGP:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡æ‹ŸäºŒé¡¹åˆ†ç±»æ¨¡å‹çš„ä¸€ç§æ ‡å‡†æ–¹æ³•æ˜¯ä½¿ç”¨æ½œå˜é‡ã€‚^([3](ch09.html#id569)) å˜é‡å¦‚æœä¸èƒ½ç›´æ¥è§‚å¯Ÿä½†å½±å“å¯è§‚å¯Ÿç»“æœï¼Œåˆ™ç§°ä¸º*æ½œå˜é‡*ã€‚æŸ¥çœ‹ä»¥ä¸‹ç”Ÿæˆæ•°æ®è¿‡ç¨‹åï¼Œè¿™ä¸ªå®šä¹‰å°†å˜å¾—æ›´åŠ æ¸…æ™°ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column z 2nd Column equals 3rd Column
    alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon 2nd Row 1st Column y 2nd
    Column equals 3rd Column StartLayout Enlarged left-brace 1st Row 1st Column 0
    2nd Column if 3rd Column z less-than 0 2nd Row 1st Column 1 2nd Column if 3rd
    Column z greater-than-or-equal-to 0 EndLayout 3rd Row 1st Column epsilon 2nd Column
    tilde 3rd Column Logistic left-parenthesis mu comma s right-parenthesis 4th Row
    1st Column x 1 comma x 2 2nd Column tilde 3rd Column upper N left-parenthesis
    bold 0 bold comma bold upper Sigma bold right-parenthesis EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mi>z</mi></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î±</mi>
    <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>Î±</mi>
    <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mi>y</mi></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfenced
    close="" open="{" separators=""><mtable><mtr><mtd columnalign="left"><mn>0</mn></mtd>
    <mtd columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><mi>z</mi> <mo><</mo>
    <mn>0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mn>1</mn></mtd> <mtd
    columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><mi>z</mi> <mo>â‰¥</mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mtd></mtr>
    <mtr><mtd columnalign="right"><mi>Ïµ</mi></mtd> <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mtext>Logistic</mtext>
    <mo>(</mo> <mi>Î¼</mi> <mo>,</mo> <mi>s</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>2</mn></msub></mrow></mtd> <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mi>N</mi>
    <mo>(</mo> <mn mathvariant="bold">0</mn> <mo>,</mo> <mi>Î£</mi> <mo>)</mo></mrow></mtd></mtr></mtable></math>
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column z 2nd Column equals 3rd Column
    alpha 0 plus alpha 1 x 1 plus alpha 2 x 2 plus epsilon 2nd Row 1st Column y 2nd
    Column equals 3rd Column StartLayout Enlarged left-brace 1st Row 1st Column 0
    2nd Column if 3rd Column z less-than 0 2nd Row 1st Column 1 2nd Column if 3rd
    Column z greater-than-or-equal-to 0 EndLayout 3rd Row 1st Column epsilon 2nd Column
    tilde 3rd Column Logistic left-parenthesis mu comma s right-parenthesis 4th Row
    1st Column x 1 comma x 2 2nd Column tilde 3rd Column upper N left-parenthesis
    bold 0 bold comma bold upper Sigma bold right-parenthesis EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mi>z</mi></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><msub><mi>Î±</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>Î±</mi>
    <mn>1</mn></msub> <msub><mi>x</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi>Î±</mi>
    <mn>2</mn></msub> <msub><mi>x</mi> <mn>2</mn></msub> <mo>+</mo> <mi>Ïµ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mi>y</mi></mtd> <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mfenced
    close="" open="{" separators=""><mtable><mtr><mtd columnalign="left"><mn>0</mn></mtd>
    <mtd columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><mi>z</mi> <mo><</mo>
    <mn>0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mn>1</mn></mtd> <mtd
    columnalign="left"><mtext>if</mtext></mtd> <mtd><mrow><mi>z</mi> <mo>â‰¥</mo> <mn>0</mn></mrow></mtd></mtr></mtable></mfenced></mtd></mtr>
    <mtr><mtd columnalign="right"><mi>Ïµ</mi></mtd> <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mtext>Logistic</mtext>
    <mo>(</mo> <mi>Î¼</mi> <mo>,</mo> <mi>s</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>2</mn></msub></mrow></mtd> <mtd><mo>âˆ¼</mo></mtd> <mtd columnalign="left"><mrow><mi>N</mi>
    <mo>(</mo> <mn mathvariant="bold">0</mn> <mo>,</mo> <mi>Î£</mi> <mo>)</mo></mrow></mtd></mtr></mtable></math>
- en: The latent variable is <math alttext="z"><mi>z</mi></math> , and it follows
    a simple linear model with logistic disturbances. You only observe the binomial
    variable <math alttext="y"><mi>y</mi></math> that depends on the sign of the latent
    variable.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: æ½œå˜é‡ä¸º <math alttext="z"><mi>z</mi></math> ï¼Œå®ƒéµå¾ªå…·æœ‰é€»è¾‘æ‰°åŠ¨çš„ç®€å•çº¿æ€§æ¨¡å‹ã€‚æ‚¨åªè§‚å¯Ÿåˆ°ä¾èµ–äºæ½œå˜é‡ç¬¦å·çš„äºŒé¡¹å˜é‡
    <math alttext="y"><mi>y</mi></math>ã€‚
- en: The choice of the distribution for the disturbances can help you simulate models
    with more or less *balanced* outcomes. Symmetric distributions like the Gaussian
    or logistic generate balanced outcomes, but you can choose an asymmetric distribution
    if you want to focus the simulation on the â€œunbalancednessâ€ of the data (you can
    also hand-pick different thresholds without changing the distribution and achieve
    the same result).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰°åŠ¨åˆ†å¸ƒçš„é€‰æ‹©å¯ä»¥å¸®åŠ©æ‚¨æ¨¡æ‹Ÿå…·æœ‰æ›´å¤šæˆ–æ›´å°‘*å¹³è¡¡*ç»“æœçš„æ¨¡å‹ã€‚åƒé«˜æ–¯æˆ–é€»è¾‘åˆ†å¸ƒè¿™æ ·çš„å¯¹ç§°åˆ†å¸ƒä¼šç”Ÿæˆå¹³è¡¡çš„ç»“æœï¼Œä½†å¦‚æœæ‚¨æƒ³å°†æ¨¡æ‹Ÿé›†ä¸­åœ¨æ•°æ®çš„â€œä¸å¹³è¡¡æ€§â€ä¸Šï¼Œå¯ä»¥é€‰æ‹©éå¯¹ç§°åˆ†å¸ƒï¼ˆæ‚¨è¿˜å¯ä»¥æ‰‹åŠ¨é€‰æ‹©ä¸åŒçš„é˜ˆå€¼è€Œä¸æ”¹å˜åˆ†å¸ƒï¼Œä»è€Œè¾¾åˆ°ç›¸åŒçš„ç»“æœï¼‰ã€‚
- en: 'One important difference with linear regression models is that usually the
    parameters in the DGP for the latent variable are not *identifiable*, meaning
    that they canâ€™t be directly estimated; only *normalized* versions of the parameters
    can be estimated. To see this, notice that:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸çº¿æ€§å›å½’æ¨¡å‹çš„ä¸€ä¸ªé‡è¦åŒºåˆ«æ˜¯ï¼Œæ½œå˜é‡DGPä¸­çš„å‚æ•°é€šå¸¸æ˜¯ä¸å¯*è¯†åˆ«*çš„ï¼Œè¿™æ„å‘³ç€å®ƒä»¬ä¸èƒ½ç›´æ¥ä¼°è®¡ï¼›åªèƒ½ä¼°è®¡å‚æ•°çš„*å½’ä¸€åŒ–*ç‰ˆæœ¬ã€‚è¯·æ³¨æ„ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column Prob left-parenthesis y equals
    1 right-parenthesis 2nd Column equals 3rd Column Prob left-parenthesis bold x
    prime alpha plus epsilon greater-than-or-equal-to 0 right-parenthesis 2nd Row
    1st Column Blank 2nd Column equals 3rd Column Prob left-parenthesis negative epsilon
    less-than-or-equal-to bold x prime alpha bold right-parenthesis 3rd Row 1st Column
    Blank 2nd Column equals 3rd Column Prob left-parenthesis minus StartFraction epsilon
    Over sigma Subscript epsilon Baseline EndFraction less-than-or-equal-to StartFraction
    bold x prime alpha Over sigma Subscript epsilon Baseline EndFraction right-parenthesis
    4th Row 1st Column Blank 2nd Column equals 3rd Column upper F left-parenthesis
    bold x prime alpha bold slash sigma Subscript epsilon Baseline bold right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mtext>Prob</mtext>
    <mo>(</mo> <mi>y</mi> <mo>=</mo> <mn>1</mn> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mtext>Prob</mtext> <mo>(</mo> <mrow><msup><mrow><mi>ğ±</mi></mrow>
    <mo>'</mo></msup> <mi>Î±</mi></mrow> <mo>+</mo> <mi>Ïµ</mi> <mo>â‰¥</mo> <mn>0</mn>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mtext>Prob</mtext>
    <mo>(</mo> <mo>-</mo> <mi>Ïµ</mi> <mo>â‰¤</mo> <msup><mrow><mi>ğ±</mi></mrow> <mo>'</mo></msup>
    <mi>Î±</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mtext>Prob</mtext>
    <mo>(</mo> <mo>-</mo> <mfrac><mi>Ïµ</mi> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub></mfrac>
    <mo>â‰¤</mo> <mfrac><mrow><msup><mrow><mi>ğ±</mi></mrow> <mo>'</mo></msup> <mi>Î±</mi></mrow>
    <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub></mfrac> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>F</mi> <mo>(</mo> <msup><mrow><mi>ğ±</mi></mrow>
    <mo>'</mo></msup> <mi>Î±</mi> <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub> <mo>)</mo></mrow></mtd></mtr></mtable></math>
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column Prob left-parenthesis y equals
    1 right-parenthesis 2nd Column equals 3rd Column Prob left-parenthesis bold x
    prime alpha plus epsilon greater-than-or-equal-to 0 right-parenthesis 2nd Row
    1st Column Blank 2nd Column equals 3rd Column Prob left-parenthesis negative epsilon
    less-than-or-equal-to bold x prime alpha bold right-parenthesis 3rd Row 1st Column
    Blank 2nd Column equals 3rd Column Prob left-parenthesis minus StartFraction epsilon
    Over sigma Subscript epsilon Baseline EndFraction less-than-or-equal-to StartFraction
    bold x prime alpha Over sigma Subscript epsilon Baseline EndFraction right-parenthesis
    4th Row 1st Column Blank 2nd Column equals 3rd Column upper F left-parenthesis
    bold x prime alpha bold slash sigma Subscript epsilon Baseline bold right-parenthesis
    EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mtext>Prob</mtext>
    <mo>(</mo> <mi>y</mi> <mo>=</mo> <mn>1</mn> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mtext>Prob</mtext> <mo>(</mo> <mrow><msup><mrow><mi>ğ±</mi></mrow>
    <mo>'</mo></msup> <mi>Î±</mi></mrow> <mo>+</mo> <mi>Ïµ</mi> <mo>â‰¥</mo> <mn>0</mn>
    <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mtext>Prob</mtext>
    <mo>(</mo> <mo>-</mo> <mi>Ïµ</mi> <mo>â‰¤</mo> <msup><mrow><mi>ğ±</mi></mrow> <mo>'</mo></msup>
    <mi>Î±</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mtext>Prob</mtext>
    <mo>(</mo> <mo>-</mo> <mfrac><mi>Ïµ</mi> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub></mfrac>
    <mo>â‰¤</mo> <mfrac><mrow><msup><mrow><mi>ğ±</mi></mrow> <mo>'</mo></msup> <mi>Î±</mi></mrow>
    <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub></mfrac> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>F</mi> <mo>(</mo> <msup><mrow><mi>ğ±</mi></mrow>
    <mo>'</mo></msup> <mi>Î±</mi> <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub> <mo>)</mo></mrow></mtd></mtr></mtable></math>
- en: where *F* is the CDF for the logistic distribution, and Iâ€™ve used the fact that
    the logistic PDF is symmetric. The last equation shows that true parameters are
    indistinguishable from normalized parameters <math alttext="alpha bold slash sigma
    Subscript epsilon"><mrow><mi>Î±</mi> <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub></mrow></math>
    . In the simulation, I will report both sets of parameters to highlight this fact.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­*F*æ˜¯é€»è¾‘åˆ†å¸ƒçš„CDFï¼Œæˆ‘ä½¿ç”¨äº†é€»è¾‘PDFæ˜¯å¯¹ç§°çš„äº‹å®ã€‚æœ€åä¸€ä¸ªæ–¹ç¨‹æ˜¾ç¤ºçœŸå®å‚æ•°ä¸å½’ä¸€åŒ–å‚æ•° <math alttext="alpha bold
    slash sigma Subscript epsilon"><mrow><mi>Î±</mi> <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub></mrow></math>
    ä¸å¯åŒºåˆ†ã€‚åœ¨æ¨¡æ‹Ÿä¸­ï¼Œæˆ‘å°†æŠ¥å‘Šè¿™ä¸¤ç»„å‚æ•°ï¼Œä»¥çªæ˜¾è¿™ä¸€ç‚¹ã€‚
- en: '*Marginal effects* in classification models measure the impact of an infinitesimal
    change in one feature on *the probability* of interest. In linear regression this
    was just the coefficient corresponding to each feature, but since CDFs are nonlinear
    in the parameters, the calculation is not as straightforward for classification
    models. Since the derivative of the CDF is the PDF, after applying the chain rule
    for differentiation, you get:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»æ¨¡å‹ä¸­çš„*è¾¹é™…æ•ˆåº”*è¡¡é‡äº†ä¸€ä¸ªç‰¹å¾å¾®å°å˜åŒ–å¯¹*æ„Ÿå…´è¶£çš„æ¦‚ç‡*çš„å½±å“ã€‚åœ¨çº¿æ€§å›å½’ä¸­ï¼Œè¿™åªæ˜¯å¯¹åº”äºæ¯ä¸ªç‰¹å¾çš„ç³»æ•°ï¼Œä½†ç”±äºCDFåœ¨å‚æ•°ä¸Šæ˜¯éçº¿æ€§çš„ï¼Œå¯¹åˆ†ç±»æ¨¡å‹æ¥è¯´è®¡ç®—å¹¶ä¸é‚£ä¹ˆç®€å•ã€‚ç”±äºCDFçš„å¯¼æ•°æ˜¯PDFï¼Œåœ¨åº”ç”¨é“¾å¼æ³•åˆ™è¿›è¡Œå¾®åˆ†åï¼Œä½ ä¼šå¾—åˆ°ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column StartFraction partial-differential
    Prob left-parenthesis y equals 1 right-parenthesis Over partial-differential x
    Subscript k Baseline EndFraction 2nd Column equals 3rd Column f left-parenthesis
    bold x prime alpha bold right-parenthesis alpha Subscript bold k 2nd Row 1st Column
    Blank 2nd Column equals 3rd Column StartFraction e Superscript bold x prime alpha
    Baseline Over left-parenthesis 1 plus e Superscript bold x prime alpha Baseline
    right-parenthesis squared EndFraction alpha Subscript k EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mfrac><mrow><mi>âˆ‚</mi><mtext>Prob</mtext><mo>(</mo><mi>y</mi><mo>=</mo><mn>1</mn><mo>)</mo></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mi>k</mi></msub></mrow></mfrac></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>f</mi> <mrow><mo>(</mo> <msup><mrow><mi>ğ±</mi></mrow>
    <mo>'</mo></msup> <mi>Î±</mi> <mo>)</mo></mrow> <msub><mi>Î±</mi> <mi>ğ¤</mi></msub></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mfrac><msup><mi>e</mi>
    <mrow><msup><mrow><mi>ğ±</mi></mrow> <mo>'</mo></msup> <mi>Î±</mi></mrow></msup>
    <msup><mrow><mo>(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><msup><mrow><mi>ğ±</mi></mrow>
    <mo>'</mo></msup> <mi>Î±</mi></mrow></msup> <mo>)</mo></mrow> <mn>2</mn></msup></mfrac>
    <msub><mi>Î±</mi> <mi>k</mi></msub></mrow></mtd></mtr></mtable></math>
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column StartFraction partial-differential
    Prob left-parenthesis y equals 1 right-parenthesis Over partial-differential x
    Subscript k Baseline EndFraction 2nd Column equals 3rd Column f left-parenthesis
    bold x prime alpha bold right-parenthesis alpha Subscript bold k 2nd Row 1st Column
    Blank 2nd Column equals 3rd Column StartFraction e Superscript bold x prime alpha
    Baseline Over left-parenthesis 1 plus e Superscript bold x prime alpha Baseline
    right-parenthesis squared EndFraction alpha Subscript k EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mfrac><mrow><mi>âˆ‚</mi><mtext>Prob</mtext><mo>(</mo><mi>y</mi><mo>=</mo><mn>1</mn><mo>)</mo></mrow>
    <mrow><mi>âˆ‚</mi><msub><mi>x</mi> <mi>k</mi></msub></mrow></mfrac></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mi>f</mi> <mrow><mo>(</mo> <msup><mrow><mi>ğ±</mi></mrow>
    <mo>'</mo></msup> <mi>Î±</mi> <mo>)</mo></mrow> <msub><mi>Î±</mi> <mi>ğ¤</mi></msub></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd columnalign="left"><mrow><mfrac><msup><mi>e</mi>
    <mrow><msup><mrow><mi>ğ±</mi></mrow> <mo>'</mo></msup> <mi>Î±</mi></mrow></msup>
    <msup><mrow><mo>(</mo><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><msup><mrow><mi>ğ±</mi></mrow>
    <mo>'</mo></msup> <mi>Î±</mi></mrow></msup> <mo>)</mo></mrow> <mn>2</mn></msup></mfrac>
    <msub><mi>Î±</mi> <mi>k</mi></msub></mrow></mtd></mtr></mtable></math>
- en: 'Note how nonlinearity kicks in: in order to calculate the marginal effect of
    one feature, you need to evaluate <math alttext="f left-parenthesis bold x prime
    alpha bold right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <msup><mrow><mi>ğ±</mi></mrow>
    <mo>''</mo></msup> <mi>Î±</mi> <mo>)</mo></mrow></math> . As with PDPs, the standard
    practice is to use the sample means of the features to compute the inner product
    with the estimated parameters. The sign of the marginal effect depends only on
    the sign of the true parameters, which is always a desirable property.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„éçº¿æ€§çš„è¡¨ç°ï¼šä¸ºäº†è®¡ç®—ä¸€ä¸ªç‰¹å¾çš„è¾¹é™…æ•ˆåº”ï¼Œæ‚¨éœ€è¦è¯„ä¼° <math alttext="f left-parenthesis bold x prime
    alpha bold right-parenthesis"><mrow><mi>f</mi> <mo>(</mo> <msup><mrow><mi>ğ±</mi></mrow>
    <mo>'</mo></msup> <mi>Î±</mi> <mo>)</mo></mrow></math> ã€‚ä¸PDPsä¸€æ ·ï¼Œæ ‡å‡†åšæ³•æ˜¯ä½¿ç”¨ç‰¹å¾çš„æ ·æœ¬å‡å€¼æ¥è®¡ç®—ä¸ä¼°è®¡å‚æ•°çš„å†…ç§¯ã€‚è¾¹é™…æ•ˆåº”çš„ç¬¦å·ä»…å–å†³äºçœŸå®å‚æ•°çš„ç¬¦å·ï¼Œè¿™æ€»æ˜¯ä¸€ä¸ªç†æƒ³çš„ç‰¹æ€§ã€‚
- en: Comparing Different Algorithms
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¯”è¾ƒä¸åŒç®—æ³•
- en: 'I will now run an MC simulation to compare the results from three different
    models:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘å°†è¿è¡Œè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œä»¥æ¯”è¾ƒä¸‰ç§ä¸åŒæ¨¡å‹çš„ç»“æœï¼š
- en: Linear probability model
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§æ¦‚ç‡æ¨¡å‹
- en: Run OLS on the observed binary outcome and features. I do *not* correct for
    heteroskedasticity using weighted least squares, which is the standard practice
    when you want to report confidence intervals (but it doesnâ€™t affect the bias).^([4](ch09.html#id573))
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: è¿è¡ŒOLSå›å½’ï¼Œè§‚å¯ŸäºŒå…ƒç»“æœå’Œç‰¹å¾ã€‚æˆ‘ä¸ä½¿ç”¨åŠ æƒæœ€å°äºŒä¹˜æ³•æ¥æ ¡æ­£å¼‚æ–¹å·®ï¼Œè¿™æ˜¯æŠ¥å‘Šç½®ä¿¡åŒºé—´çš„æ ‡å‡†åšæ³•ï¼ˆä½†å®ƒä¸ä¼šå½±å“åå·®ï¼‰ã€‚^([4](ch09.html#id573))
- en: Logistic model
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: é€»è¾‘æ¨¡å‹
- en: Standard [logistic regression](https://oreil.ly/rfsei). I present both the estimated
    parameters and the marginal effects obtained from the last equation.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡å‡†[é€»è¾‘å›å½’](https://oreil.ly/rfsei)ã€‚æˆ‘å±•ç¤ºäº†ä»æœ€åä¸€ä¸ªæ–¹ç¨‹å¾—åˆ°çš„ä¼°è®¡å‚æ•°å’Œè¾¹é™…æ•ˆåº”ã€‚
- en: Gradient boosting classifier
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢¯åº¦æå‡åˆ†ç±»å™¨
- en: From the [scikit-learn library](https://oreil.ly/H3JkU). To make it comparable,
    I compute the slope of the PDP.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥è‡ª[scikit-learnåº“](https://oreil.ly/H3JkU)ã€‚ä¸ºäº†å¯æ¯”æ€§ï¼Œæˆ‘è®¡ç®—äº†PDPçš„æ–œç‡ã€‚
- en: 'The parameters for the simulation are as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿçš„å‚æ•°å¦‚ä¸‹ï¼š
- en: <math mode="display"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mo>(</mo>
    <msub><mi>Î±</mi> <mn>0</mn></msub> <mo>,</mo> <msub><mi>Î±</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mo>(</mo> <mn>2</mn> <mo>,</mo> <mrow><mn>3.5</mn></mrow>
    <mo>,</mo> <mrow><mn>-5</mn></mrow> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msub><mi>Ïƒ</mi>
    <mn>11</mn></msub> <mo>=</mo> <msub><mi>Ïƒ</mi> <mn>22</mn></msub> <mo>=</mo> <mi>s</mi></mrow></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mn>1</mn></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><msub><mi>Ïƒ</mi> <mn>12</mn></msub> <mo>=</mo> <msub><mi>Ïƒ</mi>
    <mn>21</mn></msub> <mo>=</mo> <mi>Î¼</mi></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd
    columnalign="left"><mn>0</mn></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msubsup><mi>Ïƒ</mi>
    <mi>Ïµ</mi> <mn>2</mn></msubsup> <mo>=</mo> <mrow><mo>(</mo> <msup><mi>s</mi> <mn>2</mn></msup>
    <msup><mi>Ï€</mi> <mn>2</mn></msup> <mo>)</mo></mrow> <mo>/</mo> <mn>3</mn></mrow></mtd>
    <mtd><mo>â‰ˆ</mo></mtd> <mtd columnalign="left"><mrow><mn>3.28</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mo>(</mo> <msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub> <mo>,</mo> <msub><mi>Î±</mi> <mn>1</mn></msub>
    <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub> <mo>,</mo> <msub><mi>Î±</mi> <mn>2</mn></msub>
    <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub> <mo>)</mo></mrow></mtd> <mtd><mo>â‰ˆ</mo></mtd>
    <mtd columnalign="left"><mrow><mo>(</mo> <mn>1.1</mn> <mo>,</mo> <mn>1.9</mn>
    <mo>,</mo> <mn>-2.8</mn> <mo>)</mo></mrow></mtd></mtr></mtable></math>
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: <math mode="display"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mo>(</mo>
    <msub><mi>Î±</mi> <mn>0</mn></msub> <mo>,</mo> <msub><mi>Î±</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>Î±</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo></mtd>
    <mtd columnalign="left"><mrow><mo>(</mo> <mn>2</mn> <mo>,</mo> <mrow><mn>3.5</mn></mrow>
    <mo>,</mo> <mrow><mn>-5</mn></mrow> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msub><mi>Ïƒ</mi>
    <mn>11</mn></msub> <mo>=</mo> <msub><mi>Ïƒ</mi> <mn>22</mn></msub> <mo>=</mo> <mi>s</mi></mrow></mtd>
    <mtd><mo>=</mo></mtd> <mtd columnalign="left"><mn>1</mn></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><msub><mi>Ïƒ</mi> <mn>12</mn></msub> <mo>=</mo> <msub><mi>Ïƒ</mi>
    <mn>21</mn></msub> <mo>=</mo> <mi>Î¼</mi></mrow></mtd> <mtd><mo>=</mo></mtd> <mtd
    columnalign="left"><mn>0</mn></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msubsup><mi>Ïƒ</mi>
    <mi>Ïµ</mi> <mn>2</mn></msubsup> <mo>=</mo> <mrow><mo>(</mo> <msup><mi>s</mi> <mn>2</mn></msup>
    <msup><mi>Ï€</mi> <mn>2</mn></msup> <mo>)</mo></mrow> <mo>/</mo> <mn>3</mn></mrow></mtd>
    <mtd><mo>â‰ˆ</mo></mtd> <mtd columnalign="left"><mrow><mn>3.28</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mo>(</mo> <msub><mi>Î±</mi> <mn>0</mn></msub>
    <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub> <mo>,</mo> <msub><mi>Î±</mi> <mn>1</mn></msub>
    <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub> <mo>,</mo> <msub><mi>Î±</mi> <mn>2</mn></msub>
    <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>Ïµ</mi></msub> <mo>)</mo></mrow></mtd> <mtd><mo>â‰ˆ</mo></mtd>
    <mtd columnalign="left"><mrow><mo>(</mo> <mn>1.1</mn> <mo>,</mo> <mn>1.9</mn>
    <mo>,</mo> <mn>-2.8</mn> <mo>)</mo></mrow></mtd></mtr></mtable></math>
- en: The last line shows the true normalized parameters that will serve as a benchmark.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€è¡Œæ˜¾ç¤ºäº†ä½œä¸ºåŸºå‡†çš„çœŸå®å½’ä¸€åŒ–å‚æ•°ã€‚
- en: 'Results can be found in [FigureÂ 9-11](#ch9_class_comp). The two main lessons
    from this simulation are:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœå¯ä»¥åœ¨[FigureÂ 9-11](#ch9_class_comp)ä¸­æ‰¾åˆ°ã€‚è¿™æ¬¡æ¨¡æ‹Ÿçš„ä¸¤ä¸ªä¸»è¦æ•™è®­æ˜¯ï¼š
- en: True parameters are not identified.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: çœŸå®å‚æ•°æ— æ³•è¯†åˆ«ã€‚
- en: 'Compared to the true parameters in the DGP, estimated parameters from the logistic
    regression are off since they are not identifiable. Nonetheless, estimates are
    very close to *normalized parameters* as expected: compare the estimates (1.0,
    1.8, âˆ’2.6) with the true normalized parameters earlier.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸DGPä¸­çš„çœŸå®å‚æ•°ç›¸æ¯”ï¼Œé€»è¾‘å›å½’çš„ä¼°è®¡å‚æ•°åç¦»ï¼Œå› ä¸ºå®ƒä»¬ä¸å¯è¯†åˆ«ã€‚å°½ç®¡å¦‚æ­¤ï¼Œä¼°è®¡å€¼éå¸¸æ¥è¿‘*å½’ä¸€åŒ–å‚æ•°*ï¼Œæ­£å¦‚é¢„æœŸçš„é‚£æ ·ï¼šä¸ä¹‹å‰çš„çœŸå®å½’ä¸€åŒ–å‚æ•°ä¼°è®¡å€¼ï¼ˆ1.0,
    1.8, âˆ’2.6ï¼‰è¿›è¡Œæ¯”è¾ƒã€‚
- en: The three methods estimate the right marginal effects.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸‰ç§æ–¹æ³•ä¼°è®¡äº†æ­£ç¡®çš„è¾¹é™…æ•ˆåº”ã€‚
- en: Theoretical marginal effects from the logistic regression (PDF times the coefficient),
    coefficients from a linear probability model, and PDP slopes from GBR are in agreement.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: é€»è¾‘å›å½’çš„ç†è®ºè¾¹é™…æ•ˆåº”ï¼ˆPDFä¹˜ä»¥ç³»æ•°ï¼‰ã€çº¿æ€§æ¦‚ç‡æ¨¡å‹çš„ç³»æ•°ä»¥åŠGBRä¸­çš„PDPæ–œç‡è¾¾æˆä¸€è‡´ã€‚
- en: '![classification comparison](assets/dshp_0911.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![åˆ†ç±»æ¯”è¾ƒ](assets/dshp_0911.png)'
- en: 'Figure 9-11\. Classification simulation: comparison of estimates'
  id: totrans-151
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾9-11ã€‚åˆ†ç±»æ¨¡æ‹Ÿï¼šä¼°è®¡çš„æ¯”è¾ƒ
- en: Bootstrapping
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è‡ªåŠ©æ³•
- en: Monte Carlo simulation is all about generating datasets by specifying the DGPs.
    In contrast, *bootstrapping* generates samples *from the current dataset* and
    is mostly used to quantify the variance of an estimate. Examples of estimates
    that are relevant in data science are PDPs (and marginal effects), precision and
    recall, and the like. Since these depend on the sample at your disposal, there
    will always be some sampling variation that you may want to quantify.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è’™ç‰¹å¡ç½—æ¨¡æ‹Ÿä¸»è¦æ˜¯é€šè¿‡æŒ‡å®šDGPæ¥ç”Ÿæˆæ•°æ®é›†ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œ*è‡ªåŠ©æ³•*æ˜¯ä»å½“å‰æ•°æ®é›†ä¸­ç”Ÿæˆæ ·æœ¬ï¼Œä¸»è¦ç”¨äºé‡åŒ–ä¼°è®¡çš„æ–¹å·®ã€‚åœ¨æ•°æ®ç§‘å­¦ä¸­ï¼Œä¾èµ–äºæ‰‹å¤´çš„æ ·æœ¬ï¼Œæ¯”å¦‚PDPï¼ˆåå¯¼æ•°å›¾ï¼‰å’Œè¾¹é™…æ•ˆåº”ã€ç²¾åº¦å’Œå¬å›ç‡ç­‰çš„ä¼°è®¡ï¼Œæ€»ä¼šå­˜åœ¨ä¸€å®šçš„æŠ½æ ·å˜å¼‚æ€§ï¼Œä½ å¯èƒ½å¸Œæœ›é‡åŒ–å®ƒã€‚
- en: 'To describe how bootstrapping works, assume that the number of observations
    in your sample is <math alttext="upper N"><mi>N</mi></math> . Your estimate is
    a function of your sample data, so:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æè¿°è‡ªåŠ©æ³•çš„å·¥ä½œåŸç†ï¼Œå‡è®¾ä½ çš„æ ·æœ¬ä¸­è§‚æµ‹å€¼çš„æ•°é‡ä¸º <math alttext="upper N"><mi>N</mi></math> ã€‚ä½ çš„ä¼°è®¡æ˜¯åŸºäºæ ·æœ¬æ•°æ®çš„å‡½æ•°ï¼Œå› æ­¤ï¼š
- en: <math alttext="ModifyingAbove theta With caret equals ModifyingAbove theta With
    caret left-parenthesis StartSet y Subscript i Baseline comma bold x Subscript
    bold i Baseline EndSet Subscript i equals 1 Superscript upper N Baseline right-parenthesis"
    display="block"><mrow><mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mo>=</mo>
    <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mrow><mo>(</mo> <msubsup><mrow><mo>{</mo><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>,</mo><msub><mi>ğ±</mi> <mi>ğ¢</mi></msub> <mo>}</mo></mrow>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>N</mi></msubsup> <mo>)</mo></mrow></mrow></math>
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="ModifyingAbove theta With caret equals ModifyingAbove theta With
    caret left-parenthesis StartSet y Subscript i Baseline comma bold x Subscript
    bold i Baseline EndSet Subscript i equals 1 Superscript upper N Baseline right-parenthesis"
    display="block"><mrow><mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mo>=</mo>
    <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mrow><mo>(</mo> <msubsup><mrow><mo>{</mo><msub><mi>y</mi>
    <mi>i</mi></msub> <mo>,</mo><msub><mi>ğ±</mi> <mi>ğ¢</mi></msub> <mo>}</mo></mrow>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>N</mi></msubsup> <mo>)</mo></mrow></mrow></math>
- en: 'A pseudocode for bootstrapping is:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ©æ³•çš„ä¼ªä»£ç å¦‚ä¸‹ï¼š
- en: Set the number of bootstrap samples ( <math alttext="upper B"><mi>B</mi></math>
    ).
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è®¾ç½®è‡ªåŠ©æ³•æ ·æœ¬çš„æ•°é‡ï¼ˆ <math alttext="upper B"><mi>B</mi></math> ï¼‰ã€‚
- en: 'For each sample <math alttext="b equals 1 comma ellipsis comma upper B"><mrow><mi>b</mi>
    <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>...</mo> <mo>,</mo> <mi>B</mi></mrow></math>
    :'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'å¯¹äºæ¯ä¸ªæ ·æœ¬ <math alttext="b equals 1 comma ellipsis comma upper B"><mrow><mi>b</mi>
    <mo>=</mo> <mn>1</mn> <mo>,</mo> <mo>...</mo> <mo>,</mo> <mi>B</mi></mrow></math>
    :'
- en: Randomly select, *with replacement*, <math alttext="upper N"><mi>N</mi></math>
    rows from your dataset.
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: éšæœºé€‰æ‹©ï¼Œ*å¸¦æ”¾å›åœ°*ï¼Œä»ä½ çš„æ•°æ®é›†ä¸­é€‰æ‹© <math alttext="upper N"><mi>N</mi></math> è¡Œã€‚
- en: 'Calculate and save your estimate, given this bootstrap sample:'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç»™å®šè¿™ä¸ªè‡ªåŠ©æ³•æ ·æœ¬ï¼Œè®¡ç®—å¹¶ä¿å­˜ä½ çš„ä¼°è®¡ï¼š
- en: <math alttext="ModifyingAbove theta With caret Superscript b Baseline equals
    ModifyingAbove theta With caret left-parenthesis StartSet y Subscript i Superscript
    b Baseline comma bold x Subscript bold i Superscript bold b Baseline EndSet Subscript
    bold i bold equals bold 1 Superscript bold upper N Baseline bold right-parenthesis"><mrow><msup><mover
    accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mi>b</mi></msup> <mo>=</mo> <mover
    accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mrow><mo>(</mo> <msubsup><mrow><mo>{</mo><msubsup><mi>y</mi>
    <mi>i</mi> <mi>b</mi></msubsup> <mo>,</mo><msubsup><mi>ğ±</mi> <mi>ğ¢</mi> <mi>ğ›</mi></msubsup>
    <mo>}</mo></mrow> <mrow><mi>ğ¢</mi><mo>=</mo><mn mathvariant="bold">1</mn></mrow>
    <mi>ğ</mi></msubsup> <mo>)</mo></mrow></mrow></math>
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: <math alttext="ModifyingAbove theta With caret Superscript b Baseline equals
    ModifyingAbove theta With caret left-parenthesis StartSet y Subscript i Superscript
    b Baseline comma bold x Subscript bold i Superscript bold b Baseline EndSet Subscript
    bold i bold equals bold 1 Superscript bold upper N Baseline bold right-parenthesis"><mrow><msup><mover
    accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mi>b</mi></msup> <mo>=</mo> <mover
    accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mrow><mo>(</mo> <msubsup><mrow><mo>{</mo><msubsup><mi>y</mi>
    <mi>i</mi> <mi>b</mi></msubsup> <mo>,</mo><msubsup><mi>ğ±</mi> <mi>ğ¢</mi> <mi>ğ›</mi></msubsup>
    <mo>}</mo></mrow> <mrow><mi>ğ¢</mi><mo>=</mo><mn mathvariant="bold">1</mn></mrow>
    <mi>ğ</mi></msubsup> <mo>)</mo></mrow></mrow></math>
- en: 'Calculate the variance or confidence interval using the *B* estimates. For
    instance, you can calculate the standard deviation like this:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ *B* ä¸ªä¼°è®¡å€¼è®¡ç®—æ–¹å·®æˆ–ç½®ä¿¡åŒºé—´ã€‚ä¾‹å¦‚ï¼Œä½ å¯ä»¥è¿™æ ·è®¡ç®—æ ‡å‡†å·®ï¼š
- en: <math alttext="upper S upper D left-parenthesis ModifyingAbove theta With caret
    right-parenthesis equals StartRoot StartFraction sigma-summation Underscript b
    equals 1 Overscript upper B Endscripts left-parenthesis ModifyingAbove theta With
    caret Superscript b Baseline minus upper A upper V upper G left-parenthesis ModifyingAbove
    theta With caret Superscript b Baseline right-parenthesis right-parenthesis squared
    Over upper B minus 1 EndFraction EndRoot" display="block"><mrow><mi>S</mi> <mi>D</mi>
    <mrow><mo>(</mo> <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <msqrt><mfrac><mrow><msubsup><mo>âˆ‘</mo> <mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>B</mi></msubsup> <msup><mrow><mo>(</mo><msup><mover accent="true"><mi>Î¸</mi>
    <mo>^</mo></mover> <mi>b</mi></msup> <mo>-</mo><mi>A</mi><mi>V</mi><mi>G</mi><mrow><mo>(</mo><msup><mover
    accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mi>b</mi></msup> <mo>)</mo></mrow><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>B</mi><mo>-</mo><mn>1</mn></mrow></mfrac></msqrt></mrow></math>
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: <math alttext="upper S upper D left-parenthesis ModifyingAbove theta With caret
    right-parenthesis equals StartRoot StartFraction sigma-summation Underscript b
    equals 1 Overscript upper B Endscripts left-parenthesis ModifyingAbove theta With
    caret Superscript b Baseline minus upper A upper V upper G left-parenthesis ModifyingAbove
    theta With caret Superscript b Baseline right-parenthesis right-parenthesis squared
    Over upper B minus 1 EndFraction EndRoot" display="block"><mrow><mi>S</mi> <mi>D</mi>
    <mrow><mo>(</mo> <mover accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mo>)</mo></mrow>
    <mo>=</mo> <msqrt><mfrac><mrow><msubsup><mo>âˆ‘</mo> <mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>B</mi></msubsup> <msup><mrow><mo>(</mo><msup><mover accent="true"><mi>Î¸</mi>
    <mo>^</mo></mover> <mi>b</mi></msup> <mo>-</mo><mi>A</mi><mi>V</mi><mi>G</mi><mrow><mo>(</mo><msup><mover
    accent="true"><mi>Î¸</mi> <mo>^</mo></mover> <mi>b</mi></msup> <mo>)</mo></mrow><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><mi>B</mi><mo>-</mo><mn>1</mn></mrow></mfrac></msqrt></mrow></math>
- en: A typical use case is when you decide to plot the true positive rate (TPR) after
    dividing your sample in equally spaced buckets, such as deciles (see [ChapterÂ 6](ch06.html#ch06_lift)).
    In classification models itâ€™s natural to expect that the score is informative
    of the actual occurrence of the event, implying that the TPR should be a nondecreasing
    function of the score (higher scores, higher incidence).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: å…¸å‹ç”¨ä¾‹æ˜¯å½“æ‚¨å†³å®šç»˜åˆ¶çœŸæ­£çš„æ­£ä¾‹ç‡ï¼ˆTPRï¼‰ï¼Œå°†æ ·æœ¬åˆ†æˆç­‰è·çš„æ¡¶ï¼Œä¾‹å¦‚ååˆ†ä½æ•°ï¼ˆå‚è§[ç¬¬ 6 ç« ](ch06.html#ch06_lift)ï¼‰ã€‚åœ¨åˆ†ç±»æ¨¡å‹ä¸­ï¼Œé¢„æœŸå¾—åˆ†èƒ½å¤Ÿæœ‰æ•ˆåœ°é¢„æµ‹äº‹ä»¶çš„å®é™…å‘ç”Ÿï¼Œè¿™æ„å‘³ç€
    TPR åº”è¯¥æ˜¯å¾—åˆ†çš„éé€’å‡å‡½æ•°ï¼ˆå¾—åˆ†è¶Šé«˜ï¼Œå‘ç”Ÿç‡è¶Šé«˜ï¼‰ã€‚
- en: To give a concrete example, suppose you trained a churn model predicting whether
    a customer will stop purchasing in the next month or not. You make a prediction
    for two customers and get the scores *Å*[1] = 0.8 and *Å*[2] = 0.5\. Ideally,
    these would represent actual probabilities, but in most cases, scores and probabilities
    donâ€™t map one-to-one, so this requires some calibration. But even if the scores
    canâ€™t be interpreted as probabilities, it would be great if theyâ€™re at least *directionally
    correct*, in the sense that the first customer is more likely to churn.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¾ä¸ªå…·ä½“ä¾‹å­ï¼Œå‡è®¾ä½ è®­ç»ƒäº†ä¸€ä¸ªé¢„æµ‹å®¢æˆ·æ˜¯å¦åœ¨ä¸‹ä¸ªæœˆåœæ­¢è´­ä¹°çš„æµå¤±æ¨¡å‹ã€‚ä½ ä¸ºä¸¤ä½å®¢æˆ·é¢„æµ‹å¾—åˆ† *Å*[1] = 0.8 å’Œ *Å*[2] = 0.5\.
    ç†æƒ³æƒ…å†µä¸‹ï¼Œè¿™äº›åº”è¯¥ä»£è¡¨å®é™…æ¦‚ç‡ï¼Œä½†åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå¾—åˆ†å’Œæ¦‚ç‡å¹¶ä¸æ˜¯ä¸€ä¸€å¯¹åº”çš„ï¼Œå› æ­¤éœ€è¦è¿›è¡Œä¸€äº›æ ¡å‡†ã€‚ä½†å³ä½¿å¾—åˆ†ä¸èƒ½è¢«è§£é‡Šä¸ºæ¦‚ç‡ï¼Œå¦‚æœå®ƒä»¬è‡³å°‘åœ¨æ–¹å‘ä¸Šæ˜¯æ­£ç¡®çš„ï¼Œä¹Ÿæ˜¯éå¸¸å¥½çš„ï¼Œæ„å‘³ç€ç¬¬ä¸€ä¸ªå®¢æˆ·æ›´æœ‰å¯èƒ½æµå¤±ã€‚
- en: 'Plotting TPRs by buckets allows you to see if your model is informative in
    this sense. But thereâ€™s a catch! Because of sampling variation, monotonicity really
    depends on the desired granularity. To see this principle in action, [FigureÂ 9-12](#ch9_boot_tpr)
    shows TPR for quintiles, deciles, and 20-tiles (ventiles), along with bootstrapped
    95% confidence intervals. You can see that monotonicity holds when I use quintiles
    and deciles. What happens when you decide to increase the granularity to 20 equally
    spaced buckets? If you hadnâ€™t plotted the confidence intervals, you wouldâ€™ve concluded
    that thereâ€™s something off with your model (see buckets 11, 15, and 19). But itâ€™s
    all about sampling variation: once you take this into account, you can safely
    conclude that these buckets are not statistically different from their neighbors.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æ¡¶ç»˜åˆ¶ TPR å…è®¸æ‚¨æŸ¥çœ‹æ‚¨çš„æ¨¡å‹æ˜¯å¦åœ¨è¿™ä¸ªæ„ä¹‰ä¸Šæ˜¯ä¿¡æ¯ä¸°å¯Œçš„ã€‚ä½†æ˜¯æœ‰ä¸ªé™·é˜±ï¼ç”±äºæŠ½æ ·å˜å¼‚æ€§ï¼Œå•è°ƒæ€§å®é™…ä¸Šå–å†³äºæ‰€éœ€çš„ç²’åº¦ã€‚ä¸ºäº†çœ‹åˆ°è¿™ä¸ªåŸç†çš„å®é™…æ•ˆæœï¼Œ[å›¾
    9-12](#ch9_boot_tpr) å±•ç¤ºäº†äº”åˆ†ä½æ•°ã€ååˆ†ä½æ•°å’Œ 20 ç­‰è·æ¡¶ï¼ˆ20-åˆ†ä½æ•°ï¼‰ï¼Œä»¥åŠè‡ªä¸¾æ³• 95% ç½®ä¿¡åŒºé—´ã€‚æ‚¨å¯ä»¥çœ‹åˆ°ï¼Œå½“æˆ‘ä½¿ç”¨äº”åˆ†ä½æ•°å’Œååˆ†ä½æ•°æ—¶ï¼Œå•è°ƒæ€§æˆç«‹ã€‚å½“æ‚¨å†³å®šå°†ç²’åº¦å¢åŠ åˆ°
    20 ä¸ªç­‰è·æ¡¶æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿå¦‚æœæ‚¨æ²¡æœ‰ç»˜åˆ¶ç½®ä¿¡åŒºé—´ï¼Œæ‚¨å¯èƒ½ä¼šå¾—å‡ºç»“è®ºï¼Œæ‚¨çš„æ¨¡å‹æœ‰é—®é¢˜ï¼ˆè¯·å‚è§æ¡¶ 11ã€15 å’Œ 19ï¼‰ã€‚ä½†è¿™éƒ½æ˜¯ç”±äºæŠ½æ ·å˜å¼‚æ€§é€ æˆçš„ï¼šä¸€æ—¦è€ƒè™‘åˆ°è¿™ä¸€ç‚¹ï¼Œæ‚¨å¯ä»¥å®‰å…¨åœ°å¾—å‡ºç»“è®ºï¼Œè¿™äº›æ¡¶ä¸å…¶é‚»å±…ä¹‹é—´æ²¡æœ‰ç»Ÿè®¡å­¦ä¸Šçš„å·®å¼‚ã€‚
- en: '![bootstrapping tprs](assets/dshp_0912.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![bootstrapping tprs](assets/dshp_0912.png)'
- en: Figure 9-12\. Bootstrapping TPRs from a classification model
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 9-12\. ä»åˆ†ç±»æ¨¡å‹ä¸­å¼•å¯¼ TPR çš„è‡ªä¸¾
- en: 'If you have a statistics background, you may think that bootstrapping is unnecessarily
    complicated in this example, since you just need to calculate the parametric variance
    of the TPR per bucket, which follows a binomial distribution (so for deciles,
    the variance can be calculated as <math alttext="upper N slash 10 times upper
    T upper P upper R Subscript d times left-parenthesis 1 minus upper T upper P upper
    R Subscript d Baseline right-parenthesis"><mrow><mi>N</mi> <mo>/</mo> <mn>10</mn>
    <mo>Ã—</mo> <mi>T</mi> <mi>P</mi> <msub><mi>R</mi> <mi>d</mi></msub> <mo>Ã—</mo>
    <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>T</mi> <mi>P</mi> <msub><mi>R</mi>
    <mi>d</mi></msub> <mo>)</mo></mrow></mrow></math> ). With this you can calculate
    parametric confidence intervals. Youâ€™re right; bootstrapping is most useful when:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æœ‰ç»Ÿè®¡èƒŒæ™¯ï¼Œæ‚¨å¯èƒ½ä¼šè®¤ä¸ºåœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå¼•å¯¼æ³•æ˜¯ä¸å¿…è¦å¤æ‚çš„ï¼Œå› ä¸ºæ‚¨åªéœ€è®¡ç®—æ¯ä¸ªæ¡¶ä¸­ TPR çš„å‚æ•°æ–¹å·®ï¼Œè¿™éµå¾ªäºŒé¡¹åˆ†å¸ƒï¼ˆå› æ­¤å¯¹äºååˆ†ä½æ•°ï¼Œæ–¹å·®å¯ä»¥è®¡ç®—ä¸º
    <math alttext="upper N slash 10 times upper T upper P upper R Subscript d times
    left-parenthesis 1 minus upper T upper P upper R Subscript d Baseline right-parenthesis"><mrow><mi>N</mi>
    <mo>/</mo> <mn>10</mn> <mo>Ã—</mo> <mi>T</mi> <mi>P</mi> <msub><mi>R</mi> <mi>d</mi></msub>
    <mo>Ã—</mo> <mrow><mo>(</mo> <mn>1</mn> <mo>-</mo> <mi>T</mi> <mi>P</mi> <msub><mi>R</mi>
    <mi>d</mi></msub> <mo>)</mo></mrow></mrow></math> ). é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ‚¨å¯ä»¥è®¡ç®—å‚æ•°ç½®ä¿¡åŒºé—´ã€‚æ‚¨æ˜¯å¯¹çš„ï¼›å¼•å¯¼æ³•åœ¨ä»¥ä¸‹æƒ…å†µä¸‹æœ€æœ‰ç”¨ï¼š
- en: You want to calculate the variance without making distributional assumptions
    (that is, nonparametric estimation).
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨å¸Œæœ›åœ¨ä¸åšåˆ†å¸ƒå‡è®¾ï¼ˆå³éå‚æ•°ä¼°è®¡ï¼‰çš„æƒ…å†µä¸‹è®¡ç®—æ–¹å·®ã€‚
- en: Computing the variance analytically is hard or computationally expensive.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: åˆ†æè®¡ç®—æ–¹å·®æ˜¯å›°éš¾æˆ–è®¡ç®—æˆæœ¬é«˜æ˜‚çš„ã€‚
- en: Key Takeaways
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸»è¦æ”¶è·
- en: 'These are the key takeaways from this chapter:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›æ˜¯æœ¬ç« çš„è¦ç‚¹ï¼š
- en: No algorithm works universally well across datasets.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰ä¸€ç§ç®—æ³•èƒ½åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šæ™®éè¡¨ç°è‰¯å¥½ã€‚
- en: Since real-world data is not perfect, you may want to check if the algorithm
    performs correctly in a simulated example.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºçœŸå®ä¸–ç•Œçš„æ•°æ®å¹¶éå®Œç¾ï¼Œä½ å¯èƒ½å¸Œæœ›æ£€æŸ¥ç®—æ³•åœ¨æ¨¡æ‹Ÿç¤ºä¾‹ä¸­æ˜¯å¦èƒ½æ­£ç¡®æ‰§è¡Œã€‚
- en: Algorithms wonâ€™t fix data issues.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ç®—æ³•æ— æ³•è§£å†³æ•°æ®é—®é¢˜ã€‚
- en: Knowing the limitations of each training algorithm is critical. Moreover, if
    you have issues with your data, donâ€™t expect the algorithm to fix them.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ¥é“æ¯ä¸ªè®­ç»ƒç®—æ³•çš„å±€é™æ€§æ˜¯è‡³å…³é‡è¦çš„ã€‚æ­¤å¤–ï¼Œå¦‚æœä½ çš„æ•°æ®å­˜åœ¨é—®é¢˜ï¼Œä¸è¦æœŸæœ›ç®—æ³•èƒ½å¤Ÿè§£å†³å®ƒä»¬ã€‚
- en: Simulation as a tool for understanding algorithm limitations.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿä½œä¸ºç†è§£ç®—æ³•å±€é™æ€§çš„å·¥å…·ã€‚
- en: In this chapter, Iâ€™ve presented several examples where simulation provides insights
    into the pros and cons of different algorithms. Other examples can be found in
    the [repo](https://oreil.ly/dshp-repo) for this chapter (outliers and missing
    values).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘å±•ç¤ºäº†å‡ ä¸ªä¾‹å­ï¼Œå±•ç¤ºäº†æ¨¡æ‹Ÿå¦‚ä½•æä¾›å¯¹ä¸åŒç®—æ³•ä¼˜ç¼ºç‚¹çš„æ´å¯Ÿã€‚å…¶ä»–ä¾‹å­å¯ä»¥åœ¨æœ¬ç« çš„[å­˜å‚¨åº“](https://oreil.ly/dshp-repo)ä¸­æ‰¾åˆ°ï¼ˆå¼‚å¸¸å€¼å’Œç¼ºå¤±å€¼ï¼‰ã€‚
- en: Partial dependence plots are great tools for opening the black box of many ML
    algorithms.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: å±€éƒ¨ä¾èµ–å›¾æ˜¯æ­ç¤ºè®¸å¤šæœºå™¨å­¦ä¹ ç®—æ³•é»‘ç›’çš„é‡è¦å·¥å…·ã€‚
- en: To showcase the power of simulation, I computed PDPs and compared them to the
    parameters of linear regression and classification.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: å±•ç¤ºæ¨¡æ‹Ÿçš„å¼ºå¤§ä¹‹å¤„ï¼Œæˆ‘è®¡ç®—äº†PDPï¼Œå¹¶å°†å…¶ä¸çº¿æ€§å›å½’å’Œåˆ†ç±»çš„å‚æ•°è¿›è¡Œäº†æ¯”è¾ƒã€‚
- en: Bootstrapping can help you quantify the precision of your estimates.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ©æ³•å¯ä»¥å¸®åŠ©ä½ é‡åŒ–ä¼°è®¡çš„ç²¾åº¦ã€‚
- en: Bootstrapping is similar to Monte Carlo simulation in the sense that you draw
    repeated samplesâ€”not from simulated DGPs but from your datasetâ€”and infer some
    statistical properties with this information.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªåŠ©æ³•ç±»ä¼¼äºè’™ç‰¹å¡æ´›æ¨¡æ‹Ÿï¼Œå› ä¸ºä½ ä¸æ˜¯ä»æ¨¡æ‹Ÿçš„æ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­æŠ½å–é‡å¤æ ·æœ¬ï¼Œè€Œæ˜¯ä»ä½ çš„æ•°æ®é›†ä¸­æŠ½å–ï¼Œå¹¶ä½¿ç”¨è¿™äº›ä¿¡æ¯æ¨æ–­ä¸€äº›ç»Ÿè®¡å±æ€§ã€‚
- en: Further Reading
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥é˜…è¯»
- en: 'The field of simulation is vast, and this chapter barely scratched the most
    basic principles. Simulation is an essential tool in Bayesian statistics and generative
    ML models. For the former, you can check Andrew Gelman et al., *Bayesian Data
    Analysis*, 3rd ed. (Chapman and Hall/CRC Press). A great reference for the latter
    is Kevin Murphyâ€™s *Machine Learning: A Probabilistic Perspective* (MIT Press).
    He also has two updated versions that I havenâ€™t reviewed but should be great.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: æ¨¡æ‹Ÿé¢†åŸŸå¹¿æ³›ï¼Œæœ¬ç« ä»…æµ…å°å…¶åŸºæœ¬åŸç†ã€‚æ¨¡æ‹Ÿåœ¨è´å¶æ–¯ç»Ÿè®¡å’Œç”Ÿæˆå¼æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­æ˜¯ä¸€ä¸ªé‡è¦å·¥å…·ã€‚å…³äºå‰è€…ï¼Œä½ å¯ä»¥æŸ¥é˜…Andrew Gelmanç­‰äººçš„ã€Šè´å¶æ–¯æ•°æ®åˆ†æã€‹ç¬¬3ç‰ˆï¼ˆChapman
    and Hall/CRC Pressï¼‰ã€‚å…³äºåè€…çš„ä¸€ä¸ªå¾ˆå¥½çš„å‚è€ƒä¹¦ç±æ˜¯Kevin Murphyçš„ã€Šæœºå™¨å­¦ä¹ ï¼šæ¦‚ç‡é€è§†ã€‹ï¼ˆMIT Pressï¼‰ã€‚ä»–è¿˜æœ‰ä¸¤ä¸ªæ›´æ–°ç‰ˆæœ¬ï¼Œæˆ‘è¿˜æ²¡æœ‰å®¡æŸ¥ï¼Œä½†åº”è¯¥ä¹Ÿå¾ˆæ£’ã€‚
- en: '*Monte Carlo Statistical Methods* by Christian Robert and George Casella (Springer)
    is a now classic reference on the vast and complex field of Monte Carlo simulations
    and how to draw from distributions. Note that this book is for the technically
    inclined.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Christian Robertå’ŒGeorge Casellaçš„ã€Šè’™ç‰¹å¡æ´›ç»Ÿè®¡æ–¹æ³•ã€‹ï¼ˆSpringerï¼‰æ˜¯è’™ç‰¹å¡æ´›æ¨¡æ‹Ÿå¹¿é˜”ä¸”å¤æ‚é¢†åŸŸçš„ç»å…¸å‚è€ƒä¹¦ã€‚è¯·æ³¨æ„ï¼Œè¿™æœ¬ä¹¦é€‚åˆæŠ€æœ¯å€¾å‘çš„è¯»è€…ã€‚
- en: 'You can find more information on bootstrapping in *The Elements of Statistical
    Learning: Data Mining, Inference, and Prediction*, 2nd ed., by Trevor Hastie et
    al. (Springer, and available [online](https://oreil.ly/QvSUb) on the authorâ€™s
    web page). You can also find information on some of the methods used for linear
    and logistic regression.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥åœ¨Trevor Hastieç­‰äººçš„ã€Šç»Ÿè®¡å­¦ä¹ è¦ç´ ï¼šæ•°æ®æŒ–æ˜ã€æ¨æ–­ä¸é¢„æµ‹ã€‹ç¬¬2ç‰ˆä¸­æ‰¾åˆ°æ›´å¤šå…³äºè‡ªåŠ©æ³•çš„ä¿¡æ¯ï¼ˆSpringerå‡ºç‰ˆï¼Œå¹¶ä¸”ä½œè€…ç½‘é¡µä¸Š[åœ¨çº¿æä¾›](https://oreil.ly/QvSUb)ï¼‰ã€‚ä½ ä¹Ÿå¯ä»¥æ‰¾åˆ°å…³äºçº¿æ€§å’Œé€»è¾‘å›å½’ä½¿ç”¨çš„ä¸€äº›æ–¹æ³•çš„ä¿¡æ¯ã€‚
- en: '*Practical Synthetic Data Generation* by Khaled El Emam et al. (Oâ€™Reilly) provides
    some useful information on simulating synthetic data. As I mentioned at the beginning
    of the chapter, you can simulate data by making assumptions about the data generating
    processes behind a dataset, or you can train a model on real-world data that can
    be used to generate synthetic datasets. This book provides some practical guidance
    on how to do it.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Khaled El Emamç­‰äººçš„ã€Šå®ç”¨åˆæˆæ•°æ®ç”Ÿæˆã€‹ï¼ˆOâ€™Reillyï¼‰æä¾›äº†æœ‰å…³æ¨¡æ‹Ÿåˆæˆæ•°æ®çš„ä¸€äº›æœ‰ç”¨ä¿¡æ¯ã€‚æ­£å¦‚æˆ‘åœ¨æœ¬ç« å¼€å¤´æåˆ°çš„ï¼Œä½ å¯ä»¥é€šè¿‡å¯¹æ•°æ®ç”Ÿæˆè¿‡ç¨‹åšå‡ºå‡è®¾æ¥æ¨¡æ‹Ÿæ•°æ®ï¼Œæˆ–è€…ä½ å¯ä»¥è®­ç»ƒä¸€ä¸ªæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ç”¨äºç”Ÿæˆåˆæˆæ•°æ®é›†ã€‚è¿™æœ¬ä¹¦æä¾›äº†ä¸€äº›å…³äºå¦‚ä½•å®ç°è¿™ä¸€ç‚¹çš„å®ç”¨æŒ‡å¯¼ã€‚
- en: The omitted variable bias and the lack of identification in logistic regression
    are pretty standard results that can be found in any econometrics textbook. See
    for instance William Greeneâ€™s *Econometric Analysis*, 8th ed. (Pearson).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨é€»è¾‘å›å½’ä¸­ï¼Œè¢«é—æ¼çš„å˜é‡åå·®å’Œç¼ºä¹é‰´å®šæ€§æ˜¯éå¸¸æ ‡å‡†çš„ç»“æœï¼Œå¯ä»¥åœ¨ä»»ä½•è®¡é‡ç»æµå­¦æ•™æä¸­æ‰¾åˆ°ã€‚ä¾‹å¦‚ï¼Œå‚è§William Greeneçš„ã€Šè®¡é‡ç»æµåˆ†æã€‹ç¬¬8ç‰ˆï¼ˆPearsonå‡ºç‰ˆï¼‰ã€‚
- en: 'In *Analytical Skills for AI and Data Science*, I discuss the use of simulation
    for levers optimization. Scott Pageâ€™s *The Model Thinker: What You Need to Know
    to Make Data Work for You* (Basic Books) is a good reference if you want to explore
    this subject. See also *Stochastic Simulation* by Brian Ripley (Wiley).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ã€ŠAIä¸æ•°æ®ç§‘å­¦çš„åˆ†ææŠ€èƒ½ã€‹ä¸­ï¼Œæˆ‘è®¨è®ºäº†åˆ©ç”¨æ¨¡æ‹Ÿè¿›è¡Œæ æ†ä¼˜åŒ–ã€‚å¦‚æœä½ æƒ³æ·±å…¥æ¢è®¨è¿™ä¸ªä¸»é¢˜ï¼Œæ–¯ç§‘ç‰¹Â·ä½©å¥‡çš„ã€Šæ¨¡å‹æ€ç»´è€…ï¼šè®©æ•°æ®ä¸ºä½ å·¥ä½œçš„å¿…å¤‡çŸ¥è¯†ã€‹ï¼ˆåŸºç¡€å›¾ä¹¦ï¼‰æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å‚è€ƒã€‚åŒæ—¶ï¼Œè¿˜å¯ä»¥å‚è€ƒå¸ƒèµ–æ©Â·é‡Œæ™®åˆ©çš„ã€Šéšæœºæ¨¡æ‹Ÿã€‹ï¼ˆWileyï¼‰ã€‚
- en: ^([1](ch09.html#id559-marker)) While I find this method intuitive, itâ€™s not
    the standard way to compute PDPs. In [ChapterÂ 13](ch13.html#ch13_storytellingML),
    Iâ€™ll discuss this in depth.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch09.html#id559-marker)) å°½ç®¡æˆ‘å‘ç°è¿™ç§æ–¹æ³•ç›´è§‚ï¼Œä½†è¿™å¹¶éè®¡ç®—PDPçš„æ ‡å‡†æ–¹å¼ã€‚åœ¨[ç¬¬13ç« ](ch13.html#ch13_storytellingML)ä¸­ï¼Œæˆ‘å°†æ·±å…¥è®¨è®ºè¿™ä¸ªé—®é¢˜ã€‚
- en: ^([2](ch09.html#id560-marker)) Alternatively, you can trim the outliers and
    set the extremes at some chosen quantiles. The code in the [repo](https://oreil.ly/dshp-repo)
    allows for this setting, which is very helpful in applications.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch09.html#id560-marker)) æˆ–è€…ï¼Œä½ å¯ä»¥ä¿®å‰ªå¼‚å¸¸å€¼ï¼Œå¹¶å°†æç«¯å€¼è®¾å®šä¸ºæŸäº›é€‰æ‹©çš„åˆ†ä½æ•°ã€‚ä»£ç åº“ä¸­çš„ä»£ç å…è®¸è¿›è¡Œè¿™ç§è®¾ç½®ï¼Œè¿™åœ¨åº”ç”¨ä¸­éå¸¸æœ‰å¸®åŠ©ã€‚
- en: ^([3](ch09.html#id569-marker)) To simulate a multinomial logistic model, you
    need to use a [different technique](https://oreil.ly/K5d8i) that takes into account
    some properties of logistic multinomial models.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch09.html#id569-marker)) è¦æ¨¡æ‹Ÿå¤šé¡¹é€»è¾‘å›å½’æ¨¡å‹ï¼Œéœ€è¦ä½¿ç”¨[ä¸åŒçš„æŠ€æœ¯](https://oreil.ly/K5d8i)ï¼Œè€ƒè™‘åˆ°é€»è¾‘å¤šé¡¹æ¨¡å‹çš„ä¸€äº›ç‰¹æ€§ã€‚
- en: ^([4](ch09.html#id573-marker)) A critical assumption in OLS is that the disturbances
    have the same variance (*homoskedastic*). In contrast, *heteroskedastic* disturbances
    have different variance parameters, and OLS is no longer *optimal* in a very precise
    sense. Weighted least squares are an alternative to OLS when the form of the heteroskedasticity
    can be estimated.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch09.html#id573-marker)) OLSä¸­çš„ä¸€ä¸ªå…³é”®å‡è®¾æ˜¯æ‰°åŠ¨å…·æœ‰ç›¸åŒçš„æ–¹å·®ï¼ˆ*åŒæ–¹å·®*ï¼‰ã€‚ç›¸åï¼Œ*å¼‚æ–¹å·®*æ‰°åŠ¨å…·æœ‰ä¸åŒçš„æ–¹å·®å‚æ•°ï¼ŒOLSåœ¨éå¸¸ç²¾ç¡®çš„æ„ä¹‰ä¸Šä¸å†æ˜¯*æœ€ä¼˜*çš„ã€‚åŠ æƒæœ€å°äºŒä¹˜æ˜¯ä¸€ç§æ›¿ä»£OLSçš„æ–¹æ³•ï¼Œå½“å¼‚æ–¹å·®æ€§è´¨å¯ä»¥ä¼°è®¡æ—¶ã€‚
