- en: Chapter 8\. Estimating Financial Risk
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 金融风险估算
- en: 'Is there a way to approximate how much you can expect to lose when investing
    in financial markets? This is the quantity that the financial statistic *value
    at risk* (VaR) seeks to measure. VaR is a simple measure of investment risk that
    tries to provide a reasonable estimate of the maximum probable loss in value of
    an investment portfolio over a particular time period. A VaR statistic depends
    on three parameters: a portfolio, a time period, and a probability. For example,
    a VaR value of $1 million with a 5% probability and two weeks indicates the belief
    that the portfolio stands only a 5% chance of losing more than $1 million over
    two weeks.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在投资金融市场时，您能期望损失多少？这正是金融统计量*风险价值*（VaR）试图衡量的数量。VaR是一种简单的投资风险度量，试图提供关于投资组合在特定时间段内最大潜在损失的合理估计。VaR统计量取决于三个参数：一个投资组合、一个时间段和一个概率。例如，具有5%概率和两周的$1百万VaR值表示相信，在两周内，投资组合仅有5%的概率损失超过$1百万。
- en: Since its development soon after the stock market crash of 1987, VaR has seen
    widespread use across financial services organizations. The statistic plays a
    vital role in the management of these institutions by helping to determine the
    risk characteristics of their strategies.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 自1987年股市崩盘后不久的发展以来，VaR已被广泛应用于金融服务组织中。该统计量通过帮助确定其战略的风险特征，在这些机构的管理中发挥着关键作用。
- en: Many of the most sophisticated approaches to estimating this statistic rely
    on computationally intensive simulations of markets under random conditions. The
    technique behind these approaches, called the Monte Carlo simulation, involves
    posing thousands or millions of random market scenarios and observing how they
    tend to affect a portfolio. These scenarios are referred to as *trials*. PySpark
    is an ideal tool for Monte Carlo simulations. PySpark can leverage thousands of
    cores to run random trials and aggregate their results. As a general-purpose data
    transformation engine, it is also adept at performing the pre- and postprocessing
    steps that surround the simulations. It can transform raw financial data into
    the model parameters needed to carry out the simulations, as well as support ad
    hoc analysis of the results. Its simple programming model can drastically reduce
    development time compared to more traditional approaches that use HPC environments.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 许多估算此统计量的最复杂方法依赖于在随机条件下进行计算密集型市场模拟。这些方法背后的技术称为蒙特卡洛模拟，涉及提出数千甚至数百万个随机市场场景，并观察它们如何倾向于影响投资组合。这些场景被称为*试验*。PySpark是进行蒙特卡洛模拟的理想工具。PySpark能够利用数千个核心来运行随机试验并汇总它们的结果。作为通用的数据转换引擎，它还擅长执行围绕模拟的预处理和后处理步骤。它可以将原始金融数据转换为执行模拟所需的模型参数，并支持对结果进行临时分析。与使用HPC环境的传统方法相比，其简单的编程模型可以大大缩短开发时间。
- en: We’ll also discuss how to compute a related statistic called *conditional value
    at risk* (CVaR), sometimes known as *expected shortfall*, which the Basel Committee
    on Banking Supervision proposed as a better risk measure than VaR a few years
    back. A CVaR statistic has the same three parameters as a VaR statistic but considers
    the expected average loss instead of providing a probable loss value. A CVaR of
    $5 million with a 5% *q-value* and two weeks indicates the belief that the average
    loss in the worst 5% of outcomes is $5 million.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论如何计算称为*条件风险价值*（CVaR）的相关统计量，有时也称为*预期缺口*，几年前，巴塞尔银行监管委员会提议将其作为比VaR更好的风险度量。CVaR统计量与VaR统计量具有相同的三个参数，但考虑的是预期平均损失，而不是提供潜在损失值。具有5%*q值*和两周的$5百万CVaR表示相信，在最差的5%结果中平均损失为$5百万。
- en: In the process of modeling VaR, we’ll introduce a few different concepts, approaches,
    and packages. We’ll start by going over basic financial terminology that will
    be used throughout the chapter and then learn about the methods used to calculate
    VaR, including the Monte Carlo simulation technique. After that, we will download
    and prepare our dataset using PySpark and pandas. We’ll be using stock market
    data from late 2000s and early 2010s, including market indicators such as treasury
    bond prices along with stock values of various companies. Once done with preprocessing,
    we will create a linear regression model to calculate change in value for stocks
    over a time period. We’ll also come up with a way to generate sample market indicator
    values for use in trials when performing a Monte Carlo simulation. Finally, we’ll
    perform the simulation using PySpark and go over our results.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在建模VaR的过程中，我们将介绍一些不同的概念、方法和软件包。我们将从介绍整章中将使用的基本金融术语开始，然后学习计算VaR的方法，包括蒙特卡洛模拟技术。之后，我们将使用PySpark和pandas下载和准备我们的数据集。我们将使用2000年代末和2010年代初的股市数据，包括国库债券价格以及各种公司的股票价值等市场指标。在预处理完成后，我们将创建一个线性回归模型来计算股票在一段时间内的价值变化。我们还将想出一种方法，在执行蒙特卡洛模拟时生成样本市场指标值。最后，我们将使用PySpark执行模拟并检查我们的结果。
- en: Let’s start by defining basic financial terms that we will use.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义我们将使用的基本金融术语开始。
- en: Terminology
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语
- en: 'This chapter makes use of a set of terms specific to the finance domain:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章使用了一组特定于金融领域的术语：
- en: Instrument
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 仪器
- en: A tradable asset, such as a bond, loan, option, or stock investment. At any
    particular time, an instrument is considered to have a *value*, which is the price
    for which it could be sold.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 可交易资产，例如债券、贷款、期权或股票投资。在任何特定时间，仪器被认为有一个*价值*，这是它可能被出售的价格。
- en: Portfolio
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 投资组合
- en: A collection of instruments owned by a financial institution.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 金融机构拥有的一系列工具。
- en: Return
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 回报
- en: The change in an instrument or portfolio’s value over a time period.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 仪器或投资组合在一段时间内价值的变化。
- en: Loss
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 损失
- en: A negative return.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 负回报。
- en: Index
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 指数
- en: An imaginary portfolio of instruments. For example, the NASDAQ Composite Index
    includes about 3,000 stocks and similar instruments for major US and international
    companies.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一种虚拟的仪器投资组合。例如，纳斯达克综合指数包含约3000只美国和国际主要公司的股票和类似的仪器。
- en: Market factor
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 市场因子
- en: A value that can be used as an indicator of macro aspects of the financial climate
    at a particular time—for example, the value of an index, the gross domestic product
    of the United States, or the exchange rate between the dollar and the euro. We
    will often refer to market factors as just *factors*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 可用作特定时间金融环境宏观方面指标的价值，例如一个指数的值，美国的国内生产总值，或美元与欧元之间的汇率。我们通常将市场因子简称为*factors*。
- en: Methods for Calculating VaR
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算VaR的方法
- en: So far, our definition of VaR has been fairly open ended. Estimating this statistic
    requires proposing a model for how a portfolio functions and choosing the probability
    distribution its returns are likely to take. Institutions employ a variety of
    approaches for calculating VaR, all of which tend to fall under a few general
    methods.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们对VaR的定义相对开放。估算这一统计量需要提出一个关于如何计算投资组合的模型，并选择其回报可能遵循的概率分布。机构使用多种方法来计算VaR，这些方法大多归结为几种一般方法之下。
- en: Variance-Covariance
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方差-协方差
- en: '*Variance-covariance* is by far the simplest and least computationally intensive
    method. Its model assumes that the return of each instrument is normally distributed,
    which allows deriving an estimate analytically.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*方差-协方差*是迄今为止最简单且计算量最小的方法。其模型假设每个仪器的回报是正态分布的，这允许通过分析推导出一个估计。'
- en: Historical Simulation
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 历史模拟
- en: '*Historical simulation* extrapolates risk from historical data by using its
    distribution directly instead of relying on summary statistics. For example, to
    determine a 95% VaR for a portfolio, we might look at that portfolio’s performance
    for the last 100 days and estimate the statistic as its value on the fifth-worst
    day. A drawback of this method is that historical data can be limited and fails
    to include what-ifs. For example, what if the history we have for the instruments
    in our portfolio lacks market collapses, and we want to model what happens to
    our portfolio in these situations? Techniques exist for making historical simulation
    robust to these issues, such as introducing “shocks” into the data, but we won’t
    cover them here.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*历史模拟*通过直接使用其分布而不依赖于摘要统计数据来从历史数据中推断风险。例如，为了确定投资组合的95% VaR，我们可以查看过去100天内该投资组合的表现，并将其统计量估计为第五差的那天的值。该方法的缺点是历史数据可能有限，并且未能包括假设情况。例如，如果我们的投资组合中的工具历史记录缺少市场崩盘，我们想要模拟在这些情况下我们的投资组合的表现会发生什么？存在使历史模拟在这些问题上更为健壮的技术，例如向数据中引入“冲击”，但我们在这里不会涉及这些技术。'
- en: Monte Carlo Simulation
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 蒙特卡罗模拟
- en: '*Monte Carlo simulation*, which the rest of this chapter will focus on, tries
    to weaken the assumptions in the previous methods by simulating the portfolio
    under random conditions. When we can’t derive a closed form for a probability
    distribution analytically, we can often estimate its probability density function
    by repeatedly sampling simpler random variables that it depends on and seeing
    how it plays out in aggregate. In its most general form, this method:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*蒙特卡罗模拟*，本章剩余部分将重点讨论，试图通过模拟投资组合在随机条件下的表现，减弱前一种方法中的假设。当我们无法从解析上导出一个概率分布的闭合形式时，我们通常可以通过重复抽样它依赖的更简单的随机变量来估计其概率密度函数，并观察其在总体中的表现。在其最一般的形式下，这种方法：'
- en: Defines a relationship between market conditions and each instrument’s returns.
    This relationship takes the form of a model fitted to historical data.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义了市场条件与每个工具收益之间的关系。这种关系采用了根据历史数据拟合的模型形式。
- en: Defines distributions for the market conditions that are straightforward to
    sample from. These distributions are fitted to historical data.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义了市场条件的分布，可以轻松进行抽样。这些分布是根据历史数据拟合的。
- en: Poses trials consisting of random market conditions.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提出由随机市场条件组成的试验。
- en: Calculates the total portfolio loss for each trial and uses these losses to
    define an empirical distribution over losses. This means that if we run 100 trials
    and want to estimate the 5% VaR, we would choose it as the loss from the trial
    with the fifth-greatest loss. To calculate the 5% CVaR, we would find the average
    loss over the five worst trials.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算每次试验的总投资组合损失，并使用这些损失定义损失的经验分布。这意味着如果我们进行100次试验并希望估计5%的VaR，我们将选择第五大损失的试验的损失。要计算5%的CVaR，我们将找出最差五次试验的平均损失。
- en: Of course, the Monte Carlo method isn’t perfect either. It relies on models
    for generating trial conditions and for inferring instrument performance, and
    these models must make simplifying assumptions. If these assumptions don’t correspond
    to reality, then neither will the final probability distribution that comes out.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，蒙特卡罗方法也并非完美无缺。它依赖于用于生成试验条件和推断仪器性能的模型，并且这些模型必须进行简化假设。如果这些假设与现实不符，那么最终的概率分布也将不准确。
- en: Our Model
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的模型
- en: 'A Monte Carlo risk model typically phrases each instrument’s return in terms
    of a set of market factors. Common market factors might be the value of indexes
    like the S&P 500, the US GDP, or currency exchange rates. We then need a model
    that predicts the return of each instrument based on these market conditions.
    In our simulation, we’ll use a simple linear model. By our previous definition
    of return, a *factor return* is a change in the value of a market factor over
    a particular time. For example, if the value of the S&P 500 moves from 2,000 to
    2,100 over a time interval, its return would be 100\. We’ll derive a set of features
    from simple transformations of the factor returns. That is, the market factor
    vector *m[t]* for a trial *t* is transformed by some function ϕ to produce a feature
    vector of possible different length *f[t]*:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙特卡洛风险模型通常将每个工具的回报用一组市场因素表达。常见的市场因素可能是诸如标准普尔500指数、美国GDP或货币汇率等的指数值。然后，我们需要一个模型，根据这些市场条件预测每个工具的回报。在我们的模拟中，我们将使用一个简单的线性模型。根据我们之前对回报的定义，*因子回报*是一个特定时间内市场因素值的变化。例如，如果标准普尔500指数从2000上升到2100，其回报将是100。我们将从因子回报的简单转换中派生一组特征。也就是说，试验*t*中的市场因素向量*m[t]*通过某个函数ϕ转换，产生可能不同长度的特征向量*f[t]*：
- en: '*f[t] = ϕ(m[t])*'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f[t] = ϕ(m[t])*'
- en: 'For each instrument, we’ll train a model that assigns a weight to each feature.
    To calculate *r[it]*, the return of instrument *i* in trial *t*, we use *c[i]*,
    the intercept term for the instrument; *w[ij]*, the regression weight for feature
    *j* on instrument *i*; and *f[tj]*, the randomly generated value of feature *j*
    in trial *t*:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个工具，我们将训练一个模型，为每个特征分配一个权重。要计算*r[it]*，即试验*t*中工具*i*的回报，我们使用*c[i]*，工具的截距项；*w[ij]*，工具*i*上特征*j*的回归权重；以及*f[tj]*，试验*t*中特征*j*的随机生成值：
- en: <math alttext="r Subscript i t Baseline equals c Subscript i Baseline plus sigma-summation
    Underscript j equals 1 Overscript StartAbsoluteValue w Subscript i Baseline EndAbsoluteValue
    Endscripts w Subscript i j Baseline asterisk f Subscript t j" display="block"><mrow><msub><mi>r</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub> <mo>=</mo> <msub><mi>c</mi> <mi>i</mi></msub>
    <mo>+</mo> <munderover><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow>
    <mrow><mrow><mo>|</mo></mrow><msub><mi>w</mi> <mi>i</mi></msub> <mrow><mo>|</mo></mrow></mrow></munderover>
    <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub> <mo>*</mo> <msub><mi>f</mi>
    <mrow><mi>t</mi><mi>j</mi></mrow></msub></mrow></math>
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="r Subscript i t Baseline equals c Subscript i Baseline plus sigma-summation
    Underscript j equals 1 Overscript StartAbsoluteValue w Subscript i Baseline EndAbsoluteValue
    Endscripts w Subscript i j Baseline asterisk f Subscript t j" display="block"><mrow><msub><mi>r</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub> <mo>=</mo> <msub><mi>c</mi> <mi>i</mi></msub>
    <mo>+</mo> <munderover><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow>
    <mrow><mrow><mo>|</mo></mrow><msub><mi>w</mi> <mi>i</mi></msub> <mrow><mo>|</mo></mrow></mrow></munderover>
    <msub><mi>w</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub> <mo>*</mo> <msub><mi>f</mi>
    <mrow><mi>t</mi><mi>j</mi></mrow></msub></mrow></math>
- en: This means that the return of each instrument is calculated as the sum of the
    returns of the market factor features multiplied by their weights for that instrument.
    We can fit the linear model for each instrument using historical data (also known
    as doing linear regression). If the horizon of the VaR calculation is two weeks,
    the regression treats every (overlapping) two-week interval in history as a labeled
    point.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着每个工具的回报被计算为市场因素特征的回报之和，乘以它们在该工具上的权重。我们可以使用历史数据为每个工具拟合线性模型（也称为进行线性回归）。如果VaR计算的视野是两周，那么回归将历史上每个（重叠的）两周区间视为一个标记点。
- en: 'It’s also worth mentioning that we could have chosen a more complicated model.
    For example, the model need not be linear: it could be a regression tree or explicitly
    incorporate domain-specific knowledge.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，我们本可以选择更复杂的模型。例如，模型不必是线性的：它可以是回归树，或者明确地结合领域特定的知识。
- en: 'Now that we have our model for calculating instrument losses from market factors,
    we need a process for simulating the behavior of market factors. A simple assumption
    is that each market factor return follows a normal distribution. To capture the
    fact that market factors are often correlated—when the NASDAQ is down, the Dow
    is likely to be suffering as well—we can use a multivariate normal distribution
    with a nondiagonal covariance matrix:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了计算市场因素导致的工具损失的模型，我们需要一个过程来模拟市场因素的行为。一个简单的假设是，每个市场因素的回报都遵循正态分布。为了捕捉市场因素通常相关的事实——当纳斯达克下跌时，道琼斯也可能在受苦——我们可以使用带有非对角协方差矩阵的多元正态分布：
- en: <math alttext="m Subscript t Baseline tilde script upper N left-parenthesis
    mu comma normal upper Sigma right-parenthesis" display="block"><mrow><msub><mi>m</mi>
    <mi>t</mi></msub> <mo>∼</mo> <mi>𝒩</mi> <mrow><mo>(</mo> <mi>μ</mi> <mo>,</mo>
    <mi>Σ</mi> <mo>)</mo></mrow></mrow></math>
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="m Subscript t Baseline tilde script upper N left-parenthesis
    mu comma normal upper Sigma right-parenthesis" display="block"><mrow><msub><mi>m</mi>
    <mi>t</mi></msub> <mo>∼</mo> <mi>𝒩</mi> <mrow><mo>(</mo> <mi>μ</mi> <mo>,</mo>
    <mi>Σ</mi> <mo>)</mo></mrow></mrow></math>
- en: where μ is a vector of the empirical means of the returns of the factors and
    Σ is the empirical covariance matrix of the returns of the factors.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 其中μ是因素回报的经验均值向量，Σ是因素回报的经验协方差矩阵。
- en: As before, we could have chosen a more complicated method of simulating the
    market or assumed a different type of distribution for each market factor, perhaps
    using distributions with fatter tails.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，我们本可以选择更复杂的模拟市场的方法，或者假设每个市场因素的分布类型不同，也许使用具有更厚尾部的分布。
- en: Getting the Data
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据
- en: 'Download the historical stock price dataset and place it in a *data/stocks/*
    directory:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下载历史股价数据集，并将其放置在*data/stocks/*目录中：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It can be difficult to find large volumes of nicely formatted historical price
    data. The dataset used in this chapter was downloaded from Yahoo!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 很难找到大量格式良好的历史价格数据。本章中使用的数据集是从Yahoo!下载的。
- en: 'We also need historical data for risk factors. For our factors, we’ll use the
    values of:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要风险因素的历史数据。对于我们的因素，我们将使用以下值：
- en: 'iShares 20 Plus Year Treasury Bond ETF (NASDAQ: TLT)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'iShares 20 Plus Year Treasury Bond ETF (NASDAQ: TLT)'
- en: 'iShares US Credit Bond ETF (NYSEArca: CRED)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'iShares美国信用债券ETF（NYSEArca: CRED）'
- en: 'SPDR Gold Trust (NYSEArca: GLD)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'SPDR黄金信托基金（NYSEArca: GLD）'
- en: 'Download and place the factors data:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并放置因子数据：
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s have a look at one of our factors:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的一个因子：
- en: '[PRE2]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: With our dataset downloaded, we will now prepare it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完我们的数据集后，现在我们将对其进行准备。
- en: Preparing the Data
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据
- en: 'The first few rows of the Yahoo!-formatted data for GOOGL look like this:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 雅虎格式的GOOGL数据的前几行如下所示：
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let’s fire up the PySpark shell:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启动PySpark shell：
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Read in the instruments dataset as a DataFrame:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将仪器数据集作为DataFrame读取：
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The DataFrame is missing the instrument symbol. Let’s add that using the input
    filenames corresponding to each row:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame缺少仪器符号。让我们使用对应每行的输入文件名添加它：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We will read in and process the factors dataset in a similar manner:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以类似的方式读取并处理因子数据集：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We filter out instruments with less than five years of history:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们过滤掉历史少于五年的仪器：
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Different types of instruments may trade on different days, or the data may
    have missing values for other reasons, so it is important to make sure that our
    different histories align. First, we need to trim all of our time series to the
    same period in time. To do that, we’ll first convert the `Date` column’s type
    from string to date:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的仪器可能在不同的日子交易，或者数据可能由于其他原因存在缺失值，因此确保我们的不同历史记录对齐非常重要。首先，我们需要将所有时间序列剪裁到同一时间段。为此，我们将首先将`Date`列的类型从字符串转换为日期：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let’s trim the time periods of instruments to align:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将仪器的时间期限调整对齐：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will convert the `Date` column’s type and trim the time period in our factors
    DataFrame too:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将在因子DataFrame中转换`Date`列的类型并调整时间段：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The histories of a few thousand instruments and three factors are small enough
    to read and process locally. This remains the case even for larger simulations
    with hundreds of thousands of instruments and thousands of factors. Even though
    we have used PySpark for preprocessing our data so far, the need arises for a
    distributed system such as PySpark when we’re actually running the simulations,
    which can require massive amounts of computation on each instrument. We can convert
    our PySpark DataFrame into a pandas DataFrame and still continue working with
    it easily by performing in-memory operations.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 几千种仪器和三个因子的历史数据足够小，可以在本地读取和处理。即使是包含数十万个仪器和数千个因子的更大型模拟，情况也是如此。尽管我们迄今为止使用PySpark对数据进行预处理，但当我们实际运行模拟时，如PySpark这样的分布式系统的需求变得迫切，因为每个仪器可能需要大量计算。我们可以将PySpark的DataFrame转换为pandas的DataFrame，仍然可以通过内存操作轻松地继续使用它。
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We will use these pandas DataFrames in the next section as we try to fit a linear
    regression model to predict instrument returns based on factor returns.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中使用这些pandas数据框架，试图拟合一个线性回归模型，以预测基于因子回报的仪器回报。
- en: Determining the Factor Weights
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定因子权重
- en: 'Recall that VaR deals with losses *over a particular time horizon*. We are
    not concerned with the absolute prices of instruments, but with how those prices
    move over a given length of time. In our calculation, we will set that length
    to two weeks. The following function makes use of the pandas `rolling` method
    to transform a time series of prices into an overlapping sequence of price movements
    over two-week intervals. Note that we use 10 instead of 14 to define the window
    because financial data does not include weekends:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 记住VaR处理的是*特定时间范围内*的损失。我们关注的不是仪器的绝对价格，而是这些价格在给定时间段内的波动。在我们的计算中，我们将将这个长度设置为两周。以下函数利用pandas的`rolling`方法将价格时间序列转换为重叠的两周价格变动序列。请注意，我们使用10而不是14来定义窗口，因为金融数据不包括周末：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: With these return histories in hand, we can turn to our goal of training predictive
    models for the instrument returns. For each instrument, we want a model that predicts
    its two-week return based on the returns of the factors over the same time period.
    For simplicity, we will use a linear regression model.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些回报历史数据，我们可以开始实现对仪器回报进行预测模型的目标。对于每个仪器，我们希望建立一个模型，根据相同时间段内因子的回报来预测其两周回报。为简单起见，我们将使用线性回归模型。
- en: 'To model the fact that instrument returns may be nonlinear functions of the
    factor returns, we can include some additional features in our model that we derive
    from nonlinear transformations of the factor returns. As an example, we will add
    one additional feature for each factor return: square. Our model is still a linear
    model in the sense that the response variable is a linear function of the features.
    Some of the features just happen to be determined by nonlinear functions of the
    factor returns. Keep in mind that this particular feature transformation is meant
    to demonstrate some of the options available—it shouldn’t be perceived as a state-of-the-art
    practice in predictive financial modeling.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟仪器收益可能是因子收益的非线性函数的事实，我们可以在我们的模型中包含一些额外的特征，这些特征是从因子收益的非线性转换中导出的。例如，我们将为每个因子收益添加一个额外的特征：平方。我们的模型仍然是一个线性模型，因为响应变量是特征的线性函数。一些特征恰好是由因子收益的非线性函数确定的。请记住，这种特定的特征转换旨在演示一些可用的选项，不应被视为预测金融建模中的最新实践。
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_estimating_financial_risk_CO1-1)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_estimating_financial_risk_CO1-1)'
- en: Convert factors dataframe from long to wide format so that all factors for a
    period are in one row
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 将因子数据框从长格式转换为宽格式，以便每个周期的所有因子都在一行中
- en: '[![2](assets/2.png)](#co_estimating_financial_risk_CO1-2)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_estimating_financial_risk_CO1-2)'
- en: Flatten multi-index dataframe and fix column names
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 展平多级索引数据框并修复列名
- en: 'Even though we will be carrying out many regressions—one for each instrument—the
    number of features and data points in each regression is small, meaning that we
    don’t need to make use of PySpark’s distributed linear modeling capabilities.
    Instead, we’ll use the ordinary least squares regression offered by the scikit-learn
    package:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们将进行许多回归分析——每个仪器一个——但每个回归中的特征数和数据点都很少，这意味着我们不需要使用 PySpark 的分布式线性建模能力。相反，我们将使用
    scikit-learn 包提供的普通最小二乘回归：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We now have a dataframe where each row is the set of model parameters (coefficients,
    weights, covariants, regressors, or whatever you wish to call them) for an instrument.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个数据框，其中每一行都是一个仪器的模型参数集（系数、权重、协变量、回归变量，或者你希望称呼它们的任何东西）。
- en: At this point in any real-world pipeline it would be useful to understand how
    well these models fit the data. Because the data points are drawn from time series,
    and especially because the time intervals are overlapping, it is very likely that
    the samples are autocorrelated. This means that common measures like *R*² are
    likely to overestimate how well the models fit the data. The [Breusch-Godfrey
    test](https://oreil.ly/9cwg6) is a standard test for assessing these effects.
    One quick way to evaluate a model is to separate a time series into two sets,
    leaving out enough data points in the middle so that the last points in the earlier
    set are not autocorrelated with the first points in the later set. Then train
    the model on one set and look at its error on the other.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何真实的管道中的这一点上，了解这些模型对数据的拟合程度是很有用的。因为数据点来自时间序列，特别是时间间隔重叠，样本很可能是自相关的。这意味着常见的测量如
    *R*² 很可能会高估模型对数据的拟合程度。[Breusch-Godfrey test](https://oreil.ly/9cwg6) 是评估这些效应的标准测试。评估模型的一种快速方法是将时间序列分成两组，留出足够的中间数据点，以使较早集合中的最后点与较晚集合中的第一点不自相关。然后在一组上训练模型，并查看其在另一组上的误差。
- en: With our models that map factor returns to instrument returns in hand, we now
    need a procedure for simulating market conditions by generating random factor
    returns. That’s what we’ll do next.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们手头有了将因子收益映射到仪器收益的模型，接下来我们需要一个过程来通过生成随机因子收益来模拟市场条件。这就是我们接下来要做的。
- en: Sampling
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 抽样
- en: To come up with a way for generating random factor returns, we need to decide
    on a probability distribution over factor return vectors and sample from it. What
    distribution does the data actually take? It can often be useful to start answering
    this kind of question visually.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了想出一种生成随机因子收益的方法，我们需要决定因子收益向量上的概率分布，并从中抽样。数据实际上采用什么分布？从视觉上回答这类问题通常是有用的。
- en: A nice way to visualize a probability distribution over continuous data is a
    density plot that plots the distribution’s domain versus its probability density
    function. Because we don’t know the distribution that governs the data, we don’t
    have an equation that can give us its density at an arbitrary point, but we can
    approximate it through a technique called *kernel density estimation* (KDE). In
    a loose way, kernel density estimation is a way of smoothing out a histogram.
    It centers a probability distribution (usually a normal distribution) at each
    data point. So a set of two-week-return samples would result in multiple normal
    distributions, each with a different mean. To estimate the probability density
    at a given point, it evaluates the PDFs of all the normal distributions at that
    point and takes their average. The smoothness of a kernel density plot depends
    on its *bandwidth*, the standard deviation of each of the normal distributions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化连续数据上的概率分布的一种好方法是密度图，它绘制了分布的定义域与其概率密度函数。因为我们不知道支配数据的分布，所以我们没有一个可以在任意点给出其密度的方程，但我们可以通过一种称为*核密度估计*（KDE）的技术来近似它。在松散的方式中，核密度估计是一种平滑直方图的方法。它在每个数据点处将概率分布（通常是正态分布）居中。因此，一组两周回报样本将导致多个正态分布，每个分布具有不同的均值。为了在给定点估计概率密度，它评估该点处所有正态分布的概率密度函数并取它们的平均值。核密度图的平滑程度取决于其*带宽*，即每个正态分布的标准差。
- en: 'We’ll use one of pandas DataFrame’s built-in methods to calculate and draw
    a KDE plot. The following snippet creates a density plot for one of our factors:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 pandas DataFrame 的内置方法之一来计算并绘制 KDE 图。以下代码片段创建了一个因子的密度图：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[Figure 8-1](#figure8-1) shows the distribution (probability density function)
    of two-week returns for the 20+ Year Treasury Bond ETF in our history.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-1](#figure8-1)展示了我们历史上两周20+年期国库券ETF回报的分布（概率密度函数）。'
- en: '![Two-week 20+ Year Treasury Bond ETF distribution](assets/aaps_0801.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![两周20+年期国库券ETF分布](assets/aaps_0801.png)'
- en: Figure 8-1\. Two-week 20+ Year Treasury Bond ETF distribution
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-1\. 两周20+年期国库券ETF分布
- en: '[Figure 8-2](#figure8-2) shows the same for two-week returns of US Credit Bonds.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-2](#figure8-2)展示了美国信用债券两周收益的相同情况。'
- en: '![aaps 0802](assets/aaps_0802.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![aaps 0802](assets/aaps_0802.png)'
- en: Figure 8-2\. Two-week US Credit Bond ETF returns distribution
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-2\. 美国信用债券ETF两周回报分布
- en: We will fit a normal distribution to the returns of each factor. Looking for
    a more exotic distribution, perhaps with fatter tails, that more closely fits
    the data is often worthwhile. However, for the sake of simplicity, we’ll avoid
    tuning our simulation in this way.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为每个因子的回报拟合正态分布。寻找一个更接近数据的更奇特分布，也许是具有更胖尾巴的分布，通常是值得的。然而，出于简化起见，我们将避免通过这种方式调整我们的模拟。
- en: 'The simplest way to sample factors’ returns would be to fit a normal distribution
    to each of the factors and sample from these distributions independently. However,
    this ignores the fact that market factors are often correlated. If the Treasury
    Bond ETF is down, the Credit Bond ETF is likely to be down as well. Failing to
    take these correlations into account can give us a much rosier picture of our
    risk profile than its reality. Are the returns of our factors correlated? The
    Pearson’s correlation implementation in pandas can help us find out:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样因子回报的最简单方法是将正态分布拟合到每个因子，并从这些分布中独立抽样。然而，这忽略了市场因素通常相关的事实。如果国库券ETF下跌，信用债券ETF也可能下跌。不考虑这些相关性可能会使我们对我们的风险配置有一个比实际情况更乐观的看法。我们的因子回报是否相关？pandas
    中的 Pearson 相关实现可以帮助我们找出：
- en: '[PRE17]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Because we have nonzero elements off the diagonals, it doesn’t look like it.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们对角线之外有非零元素，看起来不像是这样。
- en: The Multivariate Normal Distribution
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多元正态分布
- en: The multivariate normal distribution can help here by taking the correlation
    information between the factors into account. Each sample from a multivariate
    normal is a vector. Given values for all of the dimensions but one, the distribution
    of values along that dimension is normal. But, in their joint distribution, the
    variables are not independent.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 多元正态分布可以通过考虑因素之间的相关信息来帮助。来自多元正态分布的每个样本都是一个向量。给定所有维度但一个维度的值，沿该维度的值的分布是正态的。但是，在它们的联合分布中，变量不是独立的。
- en: The multivariate normal is parameterized with a mean along each dimension and
    a matrix describing the covariances between each pair of dimensions. With *N*
    dimensions, the covariance matrix is *N* by *N* because we want to capture the
    covariances between each pair of dimensions. When the covariance matrix is diagonal,
    the multivariate normal reduces to sampling along each dimension independently,
    but placing nonzero values in the off-diagonals helps capture the relationships
    between variables.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 多元正态分布是用每个维度的均值和描述每对维度之间协方差的矩阵参数化的。对于 *N* 维度，协方差矩阵是 *N* 行 *N* 列，因为我们希望捕捉每对维度之间的协方差关系。当协方差矩阵是对角线时，多元正态分布减少到独立沿每个维度抽样，但在非对角线上放置非零值有助于捕捉变量之间的关系。
- en: The VaR literature often describes a step in which the factor weights are transformed
    (decorrelated) so that sampling can proceed. This is normally accomplished with
    a Cholesky decomposition or eigendecomposition. NumPy package’s `M⁠u⁠l⁠t⁠i⁠v⁠a⁠r⁠i⁠a⁠t⁠e​N⁠o⁠r⁠m⁠a⁠l⁠Distribution`
    takes care of this step for us under the covers using an eigendecomposition.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: VaR文献经常描述了一个步骤，其中因子权重被转换（去相关化），以便进行抽样。通常使用Cholesky分解或特征分解来实现这一点。NumPy包的`MultivariateNormalDistribution`在幕后使用特征分解为我们处理这一步。
- en: 'To fit a multivariate normal distribution to our data, first we need to find
    its sample means and covariances:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要将多元正态分布拟合到我们的数据中，首先我们需要找到其样本均值和协方差：
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then we can simply create a distribution parameterized with them and sample
    a set of market conditions from it:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以简单地创建一个由它们参数化的分布，并从中抽样一组市场条件：
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: With the per-instrument models and a procedure for sampling factor returns,
    we now have the pieces we need to run the actual trials. Let’s start working on
    our simulation and run the trials.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 通过每个仪器模型和抽样因子回报的过程，我们现在具备运行实际试验所需的条件。让我们开始模拟并运行试验。
- en: Running the Trials
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行试验
- en: Because running the trials is computationally intensive, we’ll turn to PySpark
    to help us parallelize them. In each trial, we want to sample a set of risk factors,
    use them to predict the return of each instrument, and sum all those returns to
    find the full trial loss. To achieve a representative distribution, we want to
    run thousands or millions of these trials.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于运行试验的计算密集型，我们将求助于PySpark来帮助我们并行化它们。在每次试验中，我们希望抽样一组风险因素，用它们来预测每个仪器的回报，并总结所有这些回报以找到完整的试验损失。为了获得代表性分布，我们希望运行数千或数百万次这样的试验。
- en: We have a few choices for how to parallelize the simulation. We can parallelize
    along trials, instruments, or both. To parallelize along both, we would create
    a dataset of instruments and a dataset of trial parameters and then use the `crossJoin`
    transformation to generate a dataset of all the pairs. This is the most general
    approach, but it has a couple of disadvantages. First, it requires explicitly
    creating a DataFrame of trial parameters, which we can avoid by using some tricks
    with random seeds. Second, it requires a shuffle operation.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有几种选择来并行化模拟。我们可以沿着试验、仪器或两者并行化。要沿两者并行化，我们将创建一个仪器数据集和一个试验参数数据集，然后使用`crossJoin`转换来生成所有配对的数据集。这是最一般的方法，但它有几个缺点。首先，它需要显式创建一个试验参数的DataFrame，我们可以通过使用一些随机种子的技巧来避免这一点。其次，它需要进行洗牌操作。
- en: 'Partitioning along instruments would look something like this:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 按仪器进行分区可能看起来像这样：
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: With this approach, the data is partitioned across a DataFrame of instruments,
    and for each instrument a `flatMap` transformation computes and yields the loss
    against every trial. Using the same random seed across all tasks means that we
    will generate the same sequence of trials. `reduceByKey` sums together all the
    losses corresponding to the same trials. A disadvantage of this approach is that
    it still requires shuffling *O*(|instruments| * |trials|) data.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法，数据被分区到仪器的DataFrame中，对于每个仪器，`flatMap`转换计算并产生相应的每个试验的损失。在所有任务中使用相同的随机种子意味着我们将生成相同的试验序列。`reduceByKey`将所有对应相同试验的损失总和在一起。这种方法的一个缺点是仍然需要对
    *O*(|instruments| * |trials|) 的数据进行洗牌。
- en: Our model data for our few thousand instruments is small enough to fit in memory
    on every executor, and some back-of-the-envelope calculations reveal that this
    is probably still the case even with a million or so instruments and hundreds
    of factors. A million instruments times 500 factors times the 8 bytes needed for
    the double that stores each factor weight equals roughly 4 GB, small enough to
    fit in each executor on most modern-day cluster machines. This means that a good
    option is to distribute the instrument data in a broadcast variable. The advantage
    of each executor having a full copy of the instrument data is that total loss
    for each trial can be computed on a single machine. No aggregation is necessary.
    We also broadcast some other data required for trial return calculation.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数千种工具的模型数据足够小，可以放入每个执行器的内存中，一些粗略的计算显示，即使是数百万种工具和数百个因子，情况可能仍然如此。一百万个工具乘以500个因子乘以每个因子权重所需的8字节，大约等于4
    GB，足够小，可以放入大多数现代集群机器上的每个执行器中。这意味着一个好的选项是将工具数据分布为广播变量。每个执行器都拥有工具数据的完整副本的优势在于，每次试验的总损失可以在单台机器上计算。不需要聚合。我们还广播了一些其他用于计算试验回报所需的数据。
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'With the partition-by-trials approach (which we will use), we start out with
    a DataFrame of seeds. We want a different seed in each partition so that each
    partition generates different trials:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 使用分区试验方法（我们将使用此方法），我们从种子数据框开始。我们希望每个分区中都有不同的种子，以便每个分区生成不同的试验：
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Random number generation is a time-consuming and CPU-intensive process. While
    we don’t employ this trick here, it can often be useful to generate a set of random
    numbers in advance and use it across multiple jobs. The same random numbers should
    *not* be used within a single job, because this would violate the Monte Carlo
    assumption that the random values are independently distributed.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 随机数生成是一个耗时且需要大量CPU资源的过程。虽然我们这里没有采用这个技巧，但通常预先生成一组随机数并在多个作业中使用是非常有用的。不应在单个作业内使用相同的随机数，因为这会违反蒙特卡洛假设，即随机值是独立分布的。
- en: 'For each seed, we want to generate a set of trial parameters and observe the
    effects of these parameters on all the instruments. We will write a function that
    calculates the full return of instruments for multiple trials. We start by simply
    applying the linear model that we trained earlier for each instrument. Then we
    average over the returns of all the instruments. This assumes that we’re holding
    an equal value of each instrument in the portfolio. A weighted average would be
    used if we held different amounts of each stock. Lastly, we need to generate a
    bunch of trials in each task. Because choosing random numbers is a big part of
    the process, it is important to use a strong random number generator. Python’s
    in-built `random` library includes a Mersenne Twister implementation that is good
    for this. We use it to sample from a multivariate normal distribution as described
    previously:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个种子，我们希望生成一组试验参数，并观察这些参数对所有工具的影响。我们将编写一个函数，用于计算多次试验中工具的全面回报。我们首先简单地应用我们之前为每个工具训练过的线性模型。然后我们对所有工具的回报进行平均。这假设我们在投资组合中持有每种工具的等值。如果我们持有每支股票的数量不同，则会使用加权平均。最后，在每个任务中需要生成一堆试验。由于选择随机数是过程的重要部分，使用强大的随机数生成器非常重要。Python内置的`random`库包括一个梅森旋转器实现，非常适合这个目的。我们用它来从之前描述的多变量正态分布中进行抽样：
- en: '[PRE23]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'With our scaffolding complete, we can use it to compute a DataFrame where each
    element is the total return from a single trial:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们的脚手架完成，我们可以使用它来计算一个数据框，其中每个元素都是单次试验的总回报：
- en: '[PRE24]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[![1](assets/1.png)](#co_estimating_financial_risk_CO2-1)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_estimating_financial_risk_CO2-1)'
- en: Split array of trial returns into individual DataFrame rows
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 将试验回报的分割数组拆分为单独的数据框行
- en: 'If you recall, the whole reason we’ve been messing around with all these numbers
    is to calculate VaR. `trials` now forms an empirical distribution over portfolio
    returns. To calculate 5% VaR, we need to find a return that we expect to underperform
    5% of the time, and a return that we expect to outperform 5% of the time. With
    our empirical distribution, this is as simple as finding the value that 5% of
    trials are worse than and 95% of trials are better than. We can accomplish this
    by pulling the worst 5% of trials into the driver. Our VaR is the return of the
    best trial in this subset:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还记得，我们一直在处理所有这些数字的原因是为了计算VaR。`trials` 现在形成了一个投资组合回报的经验分布。要计算5%的VaR，我们需要找到一个我们预计在5%的时间内表现不佳的回报，以及一个我们预计在95%的时间内表现优异的回报。通过我们的经验分布，这简单地意味着找到那些比5%的trials更差的值，以及比95%的trials更好的值。我们可以通过将最差的5%的trials拉到驾驶员中来实现这一点。我们的VaR是这个子集中最佳试验的回报：
- en: '[PRE25]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can find the CVaR with a nearly identical approach. Instead of taking the
    best trial return from the worst 5% of trials, we take the average return from
    that set of trials:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用几乎相同的方法找到CVaR。与从最差的5%的试验中获取最佳试验回报不同，我们从该组试验中获取回报的平均值：
- en: '[PRE26]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Visualizing the Distribution of Returns
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化回报分布
- en: 'In addition to calculating VaR at a particular confidence level, it can be
    useful to look at a fuller picture of the distribution of returns. Are they normally
    distributed? Do they spike at the extremities? As we did for the individual factors,
    we can plot an estimate of the probability density function for the joint probability
    distribution using kernel density estimation (see [Figure 8-3](#figure9-3)):'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在特定置信水平下计算VaR外，查看回报分布的更全面画面也很有用。它们是否呈正态分布？它们是否在极端处出现尖峰？正如我们为个体因素所做的那样，我们可以使用核密度估计来绘制联合概率分布的概率密度函数的估计（见[图8-3](#figure9-3)）：
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![aaps 0803](assets/aaps_0803.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![aaps 0803](assets/aaps_0803.png)'
- en: Figure 8-3\. Two-week returns distribution
  id: totrans-144
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3\. 两周回报分布
- en: Where to Go from Here
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 接下来该如何进行
- en: The model laid out in this exercise is a very rough first cut of what would
    be used in an actual financial institution. In building an accurate VaR model,
    we glossed over a few very important steps. Curating the set of market factors
    can make or break a model, and it is not uncommon for financial institutions to
    incorporate hundreds of factors in their simulations. Picking these factors requires
    both running numerous experiments on historical data and a heavy dose of creativity.
    Choosing the predictive model that maps market factors to instrument returns is
    also important. Although we used a simple linear model, many calculations use
    nonlinear functions or simulate the path over time with Brownian motion.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习中提出的模型是实际金融机构中使用的第一个粗糙版本。在建立准确的VaR模型时，我们忽略了一些非常重要的步骤。筛选市场因素集合可以使模型成功或失败，金融机构在其模拟中通常会纳入数百个因素。选择这些因素需要在历史数据上运行大量实验和大量创意。选择将市场因素映射到工具回报的预测模型也很重要。虽然我们使用了简单的线性模型，但许多计算使用非线性函数或通过布朗运动模拟随时间的路径。
- en: Lastly, it is worth putting care into the distribution used to simulate the
    factor returns. Kolmogorov-Smirnov tests and chi-squared tests are useful for
    testing an empirical distribution’s normality. Q-Q plots are useful for comparing
    distributions visually. Usually, financial risk is better mirrored by a distribution
    with fatter tails than the normal distribution that we used. Mixtures of normal
    distributions are one good way to achieve these fatter tails. [“Financial Economics,
    Fat-tailed Distributions”](https://oreil.ly/XSxhB), an article by Markus Haas
    and Christian Pigorsch, provides a nice reference on some of the other fat-tailed
    distributions out there.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，值得注意的是，用于模拟因子回报的分布需要仔细考虑。Kolmogorov-Smirnov检验和卡方检验对于测试经验分布的正态性非常有用。Q-Q图对于直观比较分布也很有用。通常，金融风险更好地通过具有比我们使用的正态分布更大尾部的分布来反映。混合正态分布是实现这些更大尾部的一种好方法。马克斯·哈斯和克里斯蒂安·皮戈尔施的文章“《金融经济学，厚尾分布》”（[https://oreil.ly/XSxhB](https://oreil.ly/XSxhB)）提供了关于其他厚尾分布的良好参考。
- en: Banks use PySpark and large-scale data processing frameworks for calculating
    VaR with historical methods as well. [“Evaluation of Value-at-Risk Models Using
    Historical Data”](https://oreil.ly/0JoXu), by Darryll Hendricks, provides a good
    overview and performance comparison of historical VaR methods.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 银行使用PySpark和大规模数据处理框架来计算历史方法下的VaR。["使用历史数据评估风险价值模型"](https://oreil.ly/0JoXu)，作者Darryll
    Hendricks，提供了对历史VaR方法的概述和性能比较。
- en: Monte Carlo risk simulations can be used for more than calculating a single
    statistic. The results can be used to proactively reduce the risk of a portfolio
    by shaping investment decisions. For example, if in the trials with the poorest
    returns, a particular set of instruments tends to come up losing money repeatedly,
    we might consider dropping those instruments from the portfolio or adding instruments
    that tend to move in the opposite direction from them.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙特卡罗风险模拟不仅可以用于计算单一统计数据。其结果可以通过塑造投资决策来主动减少投资组合的风险。例如，如果在表现最差的试验中，某一类工具反复出现亏损，我们可以考虑将这些工具从投资组合中剔除，或者增加那些与其运动方向相反的工具。
