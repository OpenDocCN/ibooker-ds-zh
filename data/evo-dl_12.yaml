- en: 9 Generative deep learning and evolution
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 生成深度学习和进化
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Overviewing generative adversarial networks
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概述生成对抗网络
- en: Understanding problems in generative adversarial network optimization
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解生成对抗网络优化中的问题
- en: Fixing generative adversarial network problems by applying Wasserstein loss
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过应用Wasserstein损失修复生成对抗网络问题
- en: Creating a generative adversarial network encoder for evolutionary optimization
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为进化优化创建生成对抗网络编码器
- en: Evolving a deep convolutional generative adversarial network with genetic algorithms
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用遗传算法进化深度卷积生成对抗网络
- en: In the last chapter, we were introduced to autoencoders (AEs) and learned how
    features could be extracted. We learned how to apply evolution to the network
    architecture optimization of an AE, and then we covered the variational AE that
    introduced the concept of generative deep learning, or representative learning.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了自编码器（AEs）并学习了如何提取特征。我们学习了如何将进化应用于AE的网络架构优化，然后我们介绍了变分自编码器，它引入了生成深度学习或表示学习的概念。
- en: In this chapter, we continue exploring representation learning, this time by
    looking at generative adversarial networks (GANs). GANs are a fascinating topic
    worthy of several books, but for our purposes, we only need to explore the basics.
    So in this chapter, we look at the fundamentals of the GAN and how it may be optimized
    with evolution.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们继续探索表示学习，这次通过研究生成对抗网络（GANs）。GANs是一个值得几本书来探讨的有趣话题，但就我们的目的而言，我们只需要探索其基础。因此，在本章中，我们研究GAN的基础以及它如何通过进化进行优化。
- en: GANs are notoriously difficult to train, so being able to optimize this process
    with evolution will be beneficial. We start by introducing the basic, or what
    is often referred to as the “vanilla,” GAN in the next section.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: GANs的训练非常困难，因此能够通过进化优化这个过程将是有益的。我们将在下一节介绍基本的GAN，通常被称为“原味”GAN。
- en: 9.1 Generative adversarial networks
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 生成对抗网络
- en: The GAN is the artist of DL, and while it can create beautiful representations,
    it also has nefarious uses. While we don’t explore those extremes in this section,
    we do look at how the basic GAN works. Before we jump into the code though, we’ll
    quickly introduce or review how a GAN works.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: GAN是深度学习中的艺术家，虽然它可以创造出美丽的表示，但它也有恶意用途。虽然我们在这个部分不探讨这些极端情况，但我们确实探讨了基本GAN的工作原理。然而，在我们跳入代码之前，我们将快速介绍或复习GAN是如何工作的。
- en: 9.1.1 Introducing GANs
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 介绍GANs
- en: We often romanticize the explanation of GANs using the analogy of the art forger
    and art discriminator, detective, or critic. Art forgery being a lucrative business,
    the art forger tries to generate fakes that can fool the art critic or detective.
    Likewise, the detective uses their knowledge base to determine the validity of
    the generated art and prevent fakes from being sold.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常用艺术伪造者和艺术判别器、侦探或评论家的类比来浪漫化GANs的解释。艺术伪造是一个有利可图的行业，艺术伪造者试图生成可以欺骗艺术评论家或侦探的伪造品。同样，侦探使用他们的知识库来确定生成艺术的真伪，防止伪造品被出售。
- en: Figure 9.1 is a classic representation of this adversarial battle between the
    art generator and the art discriminator or detective. The discriminator learns
    by evaluating real art and generated fakes from the forger. The generator or forger
    is blind to the real art and only learns from feedback from the detective or discriminator.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1是艺术生成器与艺术判别器或侦探之间的对抗战的经典表示。判别器通过评估真实艺术和伪造者生成的伪造艺术来学习。生成器或伪造者对真实艺术一无所知，只从侦探或判别器的反馈中学习。
- en: '![](../Images/CH09_F01_Lanham.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F01_Lanham.png)'
- en: Figure 9.1 Classic explanation of a GAN
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 GAN的经典解释
- en: Figure 9.2 depicts the process from figure 9.1 as a DL system. The generator
    (G) receives as input a randomized latent space with a little noise added. This
    represents the random thoughts an art forger takes as input (I) from figure 9.1\.
    From these random thoughts, generated images are sent to the discriminator (D)
    to verify the art’s validity—whether it is real or fake.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2将图9.1的过程描绘为一个深度学习系统。生成器（G）接收一个随机化的潜在空间作为输入，并添加了一些噪声。这代表了艺术伪造者从图9.1中作为输入（I）的随机想法。从这些随机想法中，生成的图像被发送到判别器（D）以验证艺术的真伪——是真是假。
- en: '![](../Images/CH09_F02_Lanham.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F02_Lanham.png)'
- en: Figure 9.2 A generative adversarial network
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 生成对抗网络
- en: Likewise, D takes as input samples of real images and the fake generated images
    from G. D learns to detect real versus fakes by getting feedback on its predictions—negative
    feedback if D predicts a real as fake and positive feedback for successfully detecting
    real images.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，D 将真实图像样本和 G 生成的假图像作为输入。D 通过对其预测的反馈来学习检测真实与假货——如果 D 将真实预测为假，则得到消极反馈；如果它成功检测到真实图像，则得到积极反馈。
- en: Conversely, G learns from feedback from D. Again, this feedback is positive
    if the generator can fool D and negative if it fails. D, in turn, receives negative
    feedback if it authenticates a fake as real and positive if it detects a fake
    as fake.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，G 从 D 的反馈中学习。同样，如果生成器能够欺骗 D，则这种反馈是积极的；如果它失败了，则反馈是消极的。反过来，如果 D 认证了一个假货为真，它就会收到消极反馈；如果它检测到一个假货为假，它就会收到积极反馈。
- en: On the surface, the simple elegance of the adversarial training process is overshadowed
    by the difficulty of its training. GANs work best when G and D learn at the same
    rate. If either learns more quickly or slowly, then the system breaks down and
    neither benefit from this symbiotic relationship.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上看，对抗训练过程的简单优雅被其训练的难度所掩盖。GANs 在 G 和 D 以相同速度学习时效果最佳。如果其中任何一个学习得更快或更慢，那么系统就会崩溃，双方都无法从这种共生关系中受益。
- en: GAN training and optimization, as discussed in this chapter, makes an excellent
    candidate to apply evolutionary optimization against. However, before we get to
    there, it is helpful to review the technical implementation of how a GAN works
    and how it is built in the next section.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章所讨论的，GAN的训练和优化是应用进化优化策略的一个很好的候选者。然而，在我们到达那里之前，回顾GAN如何工作以及如何在下一节中构建的技术实现是有帮助的。
- en: 9.1.2 Building a convolutional generative adversarial network in Keras
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 在 Keras 中构建卷积生成对抗网络
- en: In this section, we look at the basic, “vanilla” GAN that uses convolution and
    which we typically refer to as a dual convolution GAN of DCGAN. The addition of
    the DC simply signifies the GAN is more specialized with the addition of convolution.
    A lot of what we cover here is a review of previous chapters on convolution and
    autoencoders. As such, we don’t cover those details here but simply investigate
    how to build and train a GAN.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们查看使用卷积的基本的、“经典”GAN，我们通常将其称为DCGAN的双卷积GAN。DC的添加仅仅意味着GAN通过添加卷积变得更加专业化。我们在这里涵盖的很多内容是对之前章节中关于卷积和自编码器的回顾。因此，我们在这里不涵盖那些细节，而是简单地研究如何构建和训练GAN。
- en: Open the EDL_9_1_GAN.ipynb notebook in Google Colab. Refer to the appendix if
    you need assistance. Run all the cells in the notebook by selecting Runtime >
    Run All form the menu.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 打开Google Colab中的EDL_9_1_GAN.ipynb笔记本。如果需要帮助，请参考附录。通过选择菜单中的“运行”>“运行所有”来运行笔记本中的所有单元格。
- en: 'We use the MNIST Handwritten Digits and Fashion-MNIST datasets in this chapter.
    However, to reduce training times, we extract a single class of images from the
    dataset with the `extract` function, as shown in listing 9.1\. The `extract` function
    takes as input the batch of images and labels and the class number to extract.
    The first line extracts the indexes that match the labels equal to the class number.
    Then, the list of indexes is used to isolate the subset of images from the original
    dataset that match the class. The result is a dataset with just one class of images:
    `train_images`. We can see from the call to the `extract` function, using a class
    of `5` represents the digit 5 in the dataset, as shown in the plot output.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用MNIST手写数字和Fashion-MNIST数据集。然而，为了减少训练时间，我们使用`extract`函数从数据集中提取单个类别的图像，如列表9.1所示。`extract`函数接受图像批次和标签以及要提取的类别号作为输入。第一行提取与类别号相等的标签匹配的索引。然后，使用索引列表从原始数据集中隔离出匹配类别的图像子集。结果是只包含一个类别图像的数据集：`train_images`。我们可以从对`extract`函数的调用中看到，使用类别号`5`代表数据集中的数字5，如图表输出所示。
- en: 'Listing 9.1 EDL_9_1_GAN.ipynb: The `extract` function'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.1 EDL_9_1_GAN.ipynb：`extract`函数
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Extracts indexes of images matching class
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 提取匹配类别的图像索引
- en: ❷ Extracts images matching indexes
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 提取匹配索引的图像
- en: ❸ Prints out the shape/size of a new image dataset
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 打印出新图像数据集的形状/大小
- en: Next, we look at setting some base hyperparameters and optimizers for the generator
    and discriminator. The first parameter is a hyperparameter that defines the size
    of the latent space or random thoughts that are input into the generator. Next,
    we create a different optimizer for G and D to attempt to balance the training,
    as shown in listing 9.2\. After that, we calculate a convolutional constant we
    will use to build the networks as well as extract the number of channels and image
    shape. This notebook was developed to support various other sample datasets, including
    CIFAR.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们查看为生成器和判别器设置一些基本超参数和优化器。第一个参数是一个超参数，它定义了输入到生成器的潜在空间或随机想法的大小。接下来，我们为 G
    和 D 创建不同的优化器，以尝试平衡训练，如列表 9.2 所示。之后，我们计算一个卷积常数，我们将使用它来构建网络以及提取通道数和图像形状。这个笔记本是为了支持各种其他样本数据集而开发的，包括
    CIFAR。
- en: 'Listing 9.2 EDL_9_1_GAN.ipynb: Optimizers and hyperparameters'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.2 EDL_9_1_GAN.ipynb：优化器和超参数
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Defines the latent space input size
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义潜在空间输入大小
- en: ❷ Creates optimizers for G and D
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为 G 和 D 创建优化器
- en: ❸ Calculates the convolution space constant
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算卷积空间常数
- en: ❹ Extracts image channels and size
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 提取图像通道和大小
- en: As shown in listing 9.3, a GAN is built by breaking up the discriminator and
    generator into separate models and combining them, not unlike building an AE.
    The generator architecture resembles a decoder in an AE, where the `build_generator`
    function creates a convolutional network to generate images from a random and
    noisy latent space.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如列表 9.3 所示，GAN 是通过将判别器和生成器分解为单独的模型并组合它们来构建的，这与构建自动编码器（AE）的方式类似。生成器架构类似于 AE 中的解码器，其中
    `build_generator` 函数创建一个卷积网络，从随机和嘈杂的潜在空间生成图像。
- en: 'Listing 9.3 EDL_9_1_GAN.ipynb: Building the generator'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.3 EDL_9_1_GAN.ipynb：构建生成器
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ The first layer inputs latent space.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 第一层输入潜在空间。
- en: ❷ Reshapes output for convolution
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 重新塑形输出以适应卷积
- en: ❸ Uses UpSampling to increase resolution
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用上采样来增加分辨率
- en: ❹ Flattens the channels to match the image output
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将通道展平以匹配图像输出
- en: ❺ Adds random noise as input to the model
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将随机噪声作为输入添加到模型中
- en: Figure 9.3 shows the model summary after running the `build_generator` function.
    Notice that this is only the summary of the internal model and that we add another
    model wrapper around the base generator to add the noise inputs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 显示了运行 `build_generator` 函数后的模型摘要。请注意，这仅是内部模型的摘要，我们还在基础生成器周围添加了另一个模型包装器以添加噪声输入。
- en: '![](../Images/CH09_F03_Lanham.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F03_Lanham.png)'
- en: Figure 9.3 Summary of the output of the generator model
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 生成器模型输出的摘要
- en: The discriminator is constructed in a similar fashion, but this time, we add
    a validation input, as shown in listing 9.4\. The model starts with a convolutional
    layer taking the image as input, using a stride of size `2` to reduce or pool
    the image for the next layer. Increasing the strides here works similarly at reducing
    image size as pooling. The output from the discriminator is a single value that
    classifies the input image as fake or real.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器以类似的方式构建，但这次我们在列表 9.4 中添加了一个验证输入。模型从以图像作为输入的卷积层开始，使用大小为 `2` 的步长来减少或池化图像以供下一层使用。在这里增加步长与池化一样，可以减少图像大小。判别器的输出是一个单一值，它将输入图像分类为伪造或真实。
- en: 'Listing 9.4 EDL_9_1_GAN.ipynb: Building the discriminator'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.4 EDL_9_1_GAN.ipynb：构建判别器
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ The first layer of convolution takes the image as input.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 第一层卷积以图像作为输入。
- en: ❷ The convolution layers use strides=2 to reduce the pool image.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 卷积层使用步长=2来减少池化图像。
- en: ❸ The final output is a single value.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 最终输出是一个单一值。
- en: ❹ Adds validity (real or fake) as input to the model
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将有效性（真实或伪造）作为输入添加到模型中
- en: ❺ Returns the combined model
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 返回组合模型
- en: Since we train the discriminator separately from the generator, we also compile
    the created model with `d_optimizer`, a loss of binary cross entropy, and accuracy
    for metrics, as shown in the following listing.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们分别从生成器中训练判别器，因此我们还使用 `d_optimizer` 编译创建的模型，损失为二元交叉熵，并使用准确度作为指标，如下列所示。
- en: 'Listing 9.5 EDL_9_1_GAN.ipynb: Compiling the discriminator'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.5 EDL_9_1_GAN.ipynb：编译判别器
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Compiles the model with the optimizer
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用优化器编译模型
- en: 'Now, we can construct the combined GAN model with the D and G models we built
    earlier. Inside the cell, we create an input representing the latent space input
    for the generator, as shown in listing 9.6\. Then, we create an output from G,
    called `img`, for the generated image. After that, we turn off training for the
    discriminator model that will be used in the combined GAN. We don’t train the
    discriminator within the combined GAN. Rather, the generator is trained separately,
    within the combined GAN, using a separate optimizer: the `g_optimizer`. The validity
    of an image output from the discriminator, `d`, is used to train the generator
    in the combined model.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用我们之前构建的 D 和 G 模型来构建联合 GAN 模型。在单元格内部，我们创建一个表示生成器潜在空间输入的输入，如列表 9.6 所示。然后，我们创建一个来自
    G 的输出，称为 `img`，用于生成的图像。之后，我们关闭将在联合 GAN 中使用的判别器模型的训练。我们不在联合 GAN 中训练判别器。相反，生成器在联合
    GAN 中使用单独的优化器 `g_optimizer` 分别进行训练。判别器输出的图像的有效性用于在联合模型中训练生成器。
- en: 'Listing 9.6 EDL_9_1_GAN.ipynb: Compiling the discriminator'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.6 EDL_9_1_GAN.ipynb：编译判别器
- en: '[PRE5]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Generates an image from latent space
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从潜在空间生成图像
- en: ❷ Turns off discriminator training in the GAN
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在 GAN 中关闭判别器训练
- en: ❸ Introduces adversarial ground truths
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 引入对抗性真实值
- en: ❹ Builds a combined model
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 构建联合模型
- en: ❺ Compiles with loss and optimizer
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 编译带有损失和优化器的模型
- en: 'Since we have separate training flows, we can’t simply use the Keras `model.fit`
    function. Instead, we must train the discriminator and generator separately. The
    code, shown in listing 9.7, starts by creating the adversarial ground truths for
    real and fake image sets, making a tensor of `1`s for valid images and `0`s for
    fake images. Training is done within two loops: the outer, controlled by the number
    of epochs, and the inner, the calculated number of batches. Inside the loop, we
    sample a random set of real images, `imgs`, and then generate a fake set of images,
    `gen_images`, using random noise. Then, we train and calculate the loss of the
    real and fake images on the discriminator. Notice for each set of training how
    we pass the respective ground truths. A final combined discriminator loss is calculated
    by taking the average of the real and fake loss. Finally, we train the combined
    GAN or just the generator by passing in the valid ground truth against the generated
    fake images.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有独立的训练流程，我们不能简单地使用 Keras 的 `model.fit` 函数。相反，我们必须分别训练判别器和生成器。代码，如列表 9.7
    所示，首先创建真实和伪造图像集的对抗性真实值，为有效图像创建一个 `1`s 的张量，为伪造图像创建一个 `0`s 的张量。训练在两个循环中进行：外循环由 epoch
    数量控制，内循环由批次的计算数量控制。在循环内部，我们随机采样一组真实图像 `imgs`，然后使用随机噪声生成一组伪造图像 `gen_images`。然后，我们在判别器上训练并计算真实和伪造图像的损失。注意，对于每一组训练，我们如何传递相应的真实值。通过取真实和伪造损失的均值来计算最终的联合判别器损失。最后，我们通过传递有效真实值与生成的伪造图像来训练联合
    GAN 或仅生成器。
- en: 'Listing 9.7 EDL_9_1_GAN.ipynb: Training the GAN'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.7 EDL_9_1_GAN.ipynb：训练 GAN
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Generates adversarial ground truths
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 生成对抗性真实值
- en: ❷ A sample random batch of real images
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 一个样本随机批次的真实图像
- en: ❸ Creates noise and generates fake images
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建噪声并生成伪造图像
- en: ❹ Trains the discriminator and calculates loss on real and fake images
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 训练判别器并在真实和伪造图像上计算损失
- en: ❺ Trains the generator using a valid ground truth
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 使用有效真实值训练生成器
- en: 'Figure 9.4 shows the results of training the GAN on 10 epochs over one class
    of data: the digit 5\. You can just start to see the generator creating images
    that resemble a hand-drawn 5\. Combined with the generated images, we also see
    results of the loss training for the discriminator broken out by real and fake
    as well as the generator. Without getting deep into the mathematics, the goal
    of training a “vanilla” GAN is to maximize the loss of the fake images and minimize
    the loss of the real images. In essence, D needs to become better at identifying
    real images but also needs to get worse at identifying the fakes. Reciprocal to
    this, the generator must minimize the loss of creating fake images. In the figure,
    it appears to be the opposite, but this is because it is still in the early stages
    of training.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4显示了在单个数据类别（数字5）上训练GAN 10个周期的结果。你可以开始看到生成器创建的图像类似于手绘的5。结合生成的图像，我们还看到了判别器的损失训练结果，按真实和伪造分开以及生成器。不深入数学，训练“vanilla”GAN的目标是最大化伪造图像的损失并最小化真实图像的损失。本质上，D需要变得更好于识别真实图像，但也需要变得更差于识别伪造图像。相反，生成器必须最小化创建伪造图像的损失。在图中，这似乎是相反的，但这是因为它仍然处于训练的早期阶段。
- en: '![](../Images/CH09_F04_Lanham.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F04_Lanham.png)'
- en: Figure 9.4 Training a GAN for 10 epochs
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 训练GAN 10个周期
- en: Go ahead and increase the number of `EPOCHS` for training the GAN, and then
    run the notebook again via Runtime > Run All from the menu. You will see how the
    various real and fake losses maximize and minimize, respectively.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 前进并增加训练GAN的`EPOCHS`数量，然后通过菜单中的Runtime > Run All再次运行笔记本。你会看到各种真实和伪造损失如何分别最大化或最小化。
- en: 9.1.3 Learning exercises
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3 学习练习
- en: 'Use the following exercises to help improve your understanding of the basic
    GAN:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习来帮助提高你对基本GAN的理解：
- en: Increase or decrease the `BATCH_SIZE` and then rerun the notebook. What effect
    does changing this hyperparameter have on GAN training?
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增加或减少`BATCH_SIZE`，然后重新运行笔记本。改变这个超参数对GAN训练有什么影响？
- en: Increase or decrease the learning rate for the `g_optimizer` and `d_optimizer`
    in listing 9.2\. What effect does changing either optimizer have on GAN training?
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在9.2列表中增加或减少`g_optimizer`和`d_optimizer`的学习率。改变任一优化器对GAN训练有什么影响？
- en: Don’t use the `extract` function to limit the dataset to one class in listing
    9.1\. How does that affect training the GAN?
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在9.1列表中不要使用`extract`函数将数据集限制为单个类别。这会如何影响GAN的训练？
- en: Now, we have a working GAN that can learn to generate realistic and accurate
    digits of a given class. While the concept is simple, hopefully you can also appreciate,
    at this point, the subtle complexity and nuances of the code we just quickly covered.
    We explore those technical nuances and attempt to understand the difficulty of
    training a GAN in the next section.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个可以学习生成给定类别真实且准确的数字的正在工作的GAN。虽然概念很简单，但希望你现在也能欣赏到我们刚刚快速覆盖的代码的微妙复杂性和细微差别。我们将在下一节中探讨这些技术细微差别，并尝试理解训练GAN的难度。
- en: 9.2 The challenges of training a GAN
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 训练GAN的挑战
- en: A GAN can best be described as a balancing act between the discriminator and
    generator, where if either model surpasses the other, then the whole system fails.
    Since the discriminator is trained separately, it may still produce valid models,
    but this is rarely useful in broader applications.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: GAN最好被描述为判别器和生成器之间的平衡行为，如果任一模型超过另一个，整个系统就会失败。由于判别器是单独训练的，它仍然可能产生有效的模型，但在更广泛的应用中这很少是有用的。
- en: Discriminator repurposing
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器再利用
- en: While the goal of building and training a GAN is being able to generate realistic
    fakes, another benefit is a robust discriminator that can distinguish between
    real images and fakes. Discriminators essentially become classifiers that can
    identify the difference between real or fake images for a given dataset, allowing
    the model to be reused as a simple classifier of the entire dataset. For example,
    if you trained a GAN on faces, the resulting discriminator could be used to classify
    any image as being a face or not a face.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然构建和训练GAN的目标是能够生成逼真的伪造品，但另一个好处是拥有一个健壮的判别器，可以区分真实图像和伪造图像。判别器本质上成为分类器，可以识别给定数据集中真实或伪造图像之间的差异，使得模型可以作为整个数据集的简单分类器被重用。例如，如果你在面部上训练了一个GAN，那么生成的判别器可以用来判断任何图像是否为面部或非面部。
- en: Building and training a GAN that can perform this balancing act and produce
    excellent results is notoriously difficult. In this section, we explore some obvious
    and not so obvious points of failure when training GANs. Then, of course, as we
    progress through the chapter, we look at various strategies to resolve these problems
    manually and with evolution. Before we do that, however, let’s review why GAN
    optimization is a problem.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 构建和训练一个能够进行这种平衡操作并产生优秀结果的 GAN 是出了名的困难。在本节中，我们探讨了在训练 GAN 时可能出现的明显和不那么明显的失败点。当然，随着我们进入本章，我们将探讨各种手动和通过进化的策略来解决这些问题。然而，在我们这样做之前，让我们回顾一下为什么
    GAN 优化是一个问题。
- en: 9.2.1 The GAN optimization problem
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 GAN 优化问题
- en: 'Often, the main problem of GAN training is getting the generator and discriminator
    to converge at a solution effectively and in tandem. Fortunately, when these problems
    manifest themselves, they often become obvious in the form of various artifacts.
    The following is a summary of some of the most common and identifiable problems
    you may face training a GAN:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，GAN 训练的主要问题是在一个有效且同步的解决方案中让生成器和判别器收敛。幸运的是，当这些问题出现时，它们通常以各种现象的形式变得明显。以下是在训练
    GAN 时可能遇到的一些最常见和可识别的问题的总结：
- en: '*Vanishing gradients*—If the discriminator becomes strong at identifying fakes,
    this often reduces the amount of loss fed back to the generator. In turn, that
    reduced loss diminishes the training gradients applied to the generator and results
    in vanishing gradients.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*梯度消失*—如果判别器在识别伪造内容方面变得强大，这通常会减少反馈给生成器的损失量。反过来，这种减少的损失会降低应用于生成器的训练梯度，导致梯度消失。'
- en: '*Mode collapse or overfitting*—A generator can get stuck continually generating
    the same output with little variation. This happens because the model becomes
    too specialized and essentially overfits the generated output.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模式坍塌或过拟合*—生成器可能会陷入不断生成几乎相同输出的状态，变化很小。这是因为模型变得过于专业化，实际上过度拟合了生成的输出。'
- en: '*Failure to converge*—If the generator improves too quickly during training,
    the discriminator becomes overwhelmed and confused. This causes the discriminator
    to break down and, essentially, make random 50/50 guesses between observed real
    or fake images.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无法收敛*—如果在训练过程中生成器改进得太快，判别器会感到不知所措和困惑。这导致判别器崩溃，本质上是在观察到的真实或伪造图像之间随机做出 50/50
    的猜测。'
- en: Observing each of these problems and being able to identify when they occur
    is useful for understanding and training GANs. In the next few subsections, we
    look at modifying the original notebook to replicate and observe these artifacts.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 观察这些问题并能够识别它们何时发生，对于理解和训练生成对抗网络（GAN）是有用的。在接下来的几个小节中，我们将探讨修改原始笔记本以复制和观察这些现象。
- en: 9.2.2 Observing vanishing gradients
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 观察梯度消失
- en: To replicate vanishing gradients in the generator, we often just need to adjust
    the optimizer used for the discriminator. Network architecture may also play into
    the vanishing gradient problem, but we showcase a couple elements we already put
    in place to address that. Open your browser, and let’s jump into the next notebook.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在生成器中复制梯度消失现象，我们通常只需要调整用于判别器的优化器。网络架构也可能对梯度消失问题产生影响，但我们将展示我们已经采取的一些措施来解决这个问题。打开您的浏览器，让我们跳转到下一个笔记本。
- en: Open the EDL_9_2_GAN_Optimization.ipynb notebook in Colab. Hold off on running
    the entire notebook until we review some sections of the code. Scroll down a couple
    cells to where the optimizer setup is, and then look for the comment `vanishing`
    `gradients`, as shown in the following listing. Uncomment the following line that
    sets the discriminator optimizer, `disc_optimizer`. Comment out the original discriminator
    optimizer, and then uncomment the optimizer labelled `vanishing gradients`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Colab 中打开 EDL_9_2_GAN_Optimization.ipynb 笔记本。在我们回顾一些代码部分之前，不要运行整个笔记本。向下滚动几个单元格，找到优化器设置的地方，然后寻找注释
    `vanishing gradients`，如下所示。取消以下设置判别器优化器的行注释，即取消注释 `disc_optimizer`。注释掉原始的判别器优化器，然后取消注释标记为
    `vanishing gradients` 的优化器。
- en: 'Listing 9.8 EDL_9_2_GAN_Optimization.ipynb: Setting the optimizer'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '列表 9.8 EDL_9_2_GAN_Optimization.ipynb: 设置优化器'
- en: '[PRE7]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Comments out the original optimizer
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 取消原始优化器的注释
- en: ❷ Uncomments the Adam optimizer
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 取消 Adam 优化器的注释
- en: The result of swapping out the optimizer for the discriminator is, effectively,
    making it better or very good at identifying fakes and real images. Consequently,
    we should see loss for the generator minimize as training progresses, with no
    appreciable improvement in output.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 将优化器替换为判别器的结果，实际上是使其在识别伪造和真实图像方面变得更好或非常好。因此，我们应该看到随着训练的进行，生成器的损失最小化，而输出没有明显的改进。
- en: After you make the change, run all the cells in the notebook by selecting Runtime
    > Run All from the menu. Scroll down to the training output; you should see similar
    output to that shown in figure 9.5\. The results show the classic indication that
    the generator is in trouble because of vanishing gradients. The two strong indicators
    a GAN may be undergoing this problem are generator loss and discriminator loss
    on the fakes. As we can see in the figure, the discriminator fake loss remains
    fixed within a small range for the entire training session. For the generator,
    this results in smaller observed changes in loss over time, producing vanishing
    gradients.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在你做出更改后，通过选择菜单中的“运行”>“运行所有”来运行笔记本中的所有单元格。向下滚动到训练输出；你应该看到与图 9.5 中显示的类似输出。结果显示了经典的指示，表明生成器由于梯度消失而陷入困境。GAN可能遇到此问题的两个强烈指标是伪造生成器的损失和判别器的损失。如图所示，判别器的伪造损失在整个训练过程中保持在很小的范围内。对于生成器来说，这导致损失随时间的变化观察到的变化较小，产生梯度消失。
- en: '![](../Images/CH09_F05_Lanham.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F05_Lanham.png)'
- en: Figure 9.5 GAN training output showing vanishing gradients
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 GAN 训练输出显示梯度消失
- en: Normally, when we observe vanishing gradients in a DL model, we review the model
    architecture and look for areas that may result in VG. If you refer to where the
    generator model is built, you may notice we are using `ReLU` activation functions.
    We can change this by swapping out the comments on the code, as shown in the follow-ing
    listing.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当我们在一个深度学习模型中观察到梯度消失时，我们会审查模型架构并寻找可能导致 VG 的区域。如果你参考生成器模型构建的地方，你可能注意到我们正在使用
    `ReLU` 激活函数。我们可以通过取消注释代码来实现这一点，如下面的列表所示。
- en: 'Listing 9.9 EDL_9_2_GAN_Optimization.ipynb: Trying `LeakyReLU`'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.9 EDL_9_2_GAN_Optimization.ipynb：尝试使用 `LeakyReLU`
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Comments out the original activation function
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 注释掉原始激活函数
- en: ❷ Uncomments the LeakyReLU activation function
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 取消注释 LeakyReLU 激活函数
- en: Run all the cells in the notebook Runtime > Run All from the menu. Unfortunately,
    we observe very little improvement. This is because swapping the activation function
    of the generator has little effect, since the problem is the discriminator. If
    you want to observe how this GAN should work, go ahead and swap the code back
    by commenting and uncommenting and then rerunning the notebook.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 运行笔记本中的所有单元格。不幸的是，我们观察到非常小的改进。这是因为交换生成器的激活函数几乎没有效果，因为问题是判别器。如果你想观察这个GAN应该如何工作，请继续通过注释和取消注释代码，然后重新运行笔记本。
- en: The typical way to address vanishing gradients in a GAN is to either adjust
    the optimizer or resolve the manner of loss calculation. We attempt to understand
    and improve the loss calculation later in this chapter, but before that, let’s
    jump back to observing other forms of GAN failure in the next section.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 解决GAN中梯度消失的典型方法是对优化器进行调整或解决损失计算的方式。我们试图在本章的后面部分理解和改进损失计算，但在那之前，让我们跳到下一节观察其他形式的GAN失败。
- en: 9.2.3 Observing mode collapse in GANs
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 观察GAN中的模式崩溃
- en: Mode collapse occurs when a GAN struggles to produce variation in its output.
    This happens when the generator finds only a single or small set of outputs that
    can fool the critic. Then, as the critic improves, the generator becomes stuck
    producing a small range of variation in output.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个GAN在输出中难以产生变化时，就会发生模式崩溃。这种情况发生在生成器只找到可以欺骗评论家的一个或一小组输出时。然后，随着评论家的改进，生成器就会陷入只产生输出的小范围变化的困境。
- en: Open the EDL_9_2_GAN_Optimization.ipynb notebook in Colab. Make sure to load
    a fresh copy from the repository if you made any modifications in the last section.
    Scroll down again to the optimizer set up section, and then uncomment the code
    below the comment `mode collapse`, as shown in the following listing.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Colab 中打开 EDL_9_2_GAN_Optimization.ipynb 笔记本。如果你在上一个部分中进行了任何修改，请确保从存储库中加载一个全新的副本。再次向下滚动到优化器设置部分，然后取消注释注释
    `mode collapse` 下的代码，如下面的列表所示。
- en: 'Listing 9.10 EDL_9_2_GAN_Optimization.ipynb: Setting the optimizer again'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.10 EDL_9_2_GAN_Optimization.ipynb：再次设置优化器
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Comments out the original optimizer
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 注释掉原始优化器
- en: ❷ Uncomments the Adam optimizer
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 取消Adam优化器的注释
- en: After you make the changes, run all the cells in the notebook via Runtime >
    Run All from the menu. Figure 9.6 shows the output of training the GAN over 25
    epochs. Your results may vary slightly, but you should observe mode collapse of
    the output images, as shown in the figure.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在您做出更改后，通过菜单中的“运行”>“运行所有单元格”来运行笔记本中的所有单元格。图9.6显示了在25个时期上训练GAN的输出。您的结果可能会有所不同，但您应该观察到输出图像的模式崩溃，如图所示。
- en: '![](../Images/CH09_F06_Lanham.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图9.6](../Images/CH09_F06_Lanham.png)'
- en: Figure 9.6 Observing mode collapse on a GAN
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6 观察GAN上的模式崩溃
- en: The simple fix to overcome mode collapse is, of course, to find the right optimizer.
    There are other approaches that also can help minimize this problem, including
    adjusting the loss function and unrolling the GAN.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 克服模式崩溃的简单修复当然是找到正确的优化器。还有其他方法也可以帮助最小化这个问题，包括调整损失函数和展开GAN。
- en: Unrolling GANs
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 展开GAN
- en: The idea behind unrolling GANs is to train the generator on current and future
    states of the discriminator. This allows the generator to look ahead and account
    for future incarnations of the discriminator in a form of time travel. While the
    concept is not complex, the code to implement this management of current and future
    states is.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 展开GAN背后的想法是将生成器在判别器的当前和未来状态上训练。这允许生成器向前看，并以时间旅行的形式考虑到判别器的未来形态。虽然这个概念并不复杂，但实现这种当前和未来状态管理的代码却是。
- en: 'We cover swapping the GAN loss function later, and unrolling the GAN is too
    complex for our simple needs. Instead, we choose a very simple method to alleviate
    mode collapse: using noise.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后面介绍交换GAN损失函数，而展开GAN对于我们的简单需求来说过于复杂。相反，我们选择一个非常简单的方法来缓解模式崩溃：使用噪声。
- en: Scroll down to the training function; notice the addition of a new `ADD_NOISE`
    Boolean form constant, as shown in the following listing. You can use the Colab
    form to switch this variable between `True` and `False`. Switch it to `True`,
    and then run all the cells in the notebook via Runtime > Run All.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动到训练函数；注意添加了一个新的`ADD_NOISE`布尔形式常量，如下面的列表所示。您可以使用Colab表单在`True`和`False`之间切换此变量。将其切换为`True`，然后通过菜单中的“运行”>“运行所有单元格”来运行笔记本中的所有单元格。
- en: 'Listing 9.11 EDL_9_2_GAN_Optimization.ipynb: Adding noise to adversarial ground
    truths'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.11 EDL_9_2_GAN_Optimization.ipynb：向对抗性地面真实值添加噪声
- en: '[PRE10]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ The fake ground truth is now between 0 and 0.2.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 假设的地面真实值现在介于0和0.2之间。
- en: ❷ The valid ground truth is now between 0.8 and 1.0.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 有效的地面真实值现在介于0.8和1.0之间。
- en: ❸ Keeps the same valid ground truth for the generator
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 保持生成器的有效地面真实值不变
- en: Figure 9.7 shows the result of training the GAN over 25 epochs with the addition
    of noise. While the results are still not exceptional due to the discrepancy in
    optimizers, we can see an improvement in output variation.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7显示了在添加噪声的情况下，经过25个时期训练GAN的结果。由于优化器的差异，结果仍然不算出色，但我们可以看到输出变异性有所改善。
- en: '![](../Images/CH09_F07_Lanham.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图9.6](../Images/CH09_F07_Lanham.png)'
- en: Figure 9.7 An example output showing increased variation in model outpu
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7 显示模型输出增加变异性的一例输出
- en: As you can see from the changes in the last notebook, we were able to correct
    the mode collapse problem by simply adding noise to the adversarial ground truths.
    In the next section, we address one more problem area of GANs.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从最后一个笔记本中的变化中可以看到，我们通过简单地向对抗性地面真实值添加噪声来纠正了模式崩溃问题。在下一节中，我们将解决GAN的另一个问题领域。
- en: 9.2.4 Observing convergence failures in GANs
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.4 观察GAN中的收敛失败
- en: Convergence is an underlying problem in GANs and can be a consequence of mode
    collapse, vanishing gradients, or badly balanced optimization. Thus, we can replicate
    convergence failures relatively easily. However, in this observation, we want
    to look at an example in which just the generator or discriminator fails to converge.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 收敛是GAN的一个基本问题，可能是模式崩溃、梯度消失或优化不平衡的后果。因此，我们可以相对容易地复制收敛失败。然而，在这个观察中，我们想要看看一个例子，其中只是生成器或判别器未能收敛。
- en: Open the EDL_9_2_GAN_Optimization.ipynb notebook in Colab. Be sure to start
    with a new copy from the repository if you modified it. Scroll down to the optimizers
    set up cell and uncomment/comment the appropriate lines marked `convergence`,
    as shown in the following listing.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在Colab中打开EDL_9_2_GAN_Optimization.ipynb笔记本。如果您对其进行了修改，请确保从存储库中开始一个新的副本。滚动到设置优化器的单元格，并取消注释/注释标记为`convergence`的适当行，如下面的列表所示。
- en: 'Listing 9.12 EDL_9_2_GAN_Optimization.ipynb: Setting the optimizer'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.12 EDL_9_2_GAN_Optimization.ipynb：设置优化器
- en: '[PRE11]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Comments out the original generator optimizer
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 注释掉原始生成器优化器
- en: ❷ Uncomments the optimizer
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 取消优化器的注释
- en: Run all the cells in the notebook via Runtime > Run All from the menu. Figure
    9.8 shows the convergence failure of the GAN generator. While the discriminator
    looks to be converging well, we can see the increasing loss of the generator has
    resulted in an inability to converge.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 通过菜单中的“运行”>“运行所有单元格”来运行笔记本中的所有单元格。图9.8显示了GAN生成器的收敛失败。虽然判别器看起来收敛得很好，但我们可以看到生成器损失的不断增加导致无法收敛。
- en: '![](../Images/CH09_F08_Lanham.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F08_Lanham.png)'
- en: Figure 9.8 GAN failure to converge on the generator
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.8 GAN生成器未能收敛
- en: As in our previous examples, there is a relatively simple fix to correct convergence
    problems. One solution is to break the tight loop between the generator and discriminator
    training. We can do this by allowing the D and G training to cycle independently
    of one another.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前的例子一样，有一个相对简单的解决方案来纠正收敛问题。一个解决方案是打破生成器和判别器训练之间的紧密循环。我们可以通过允许D和G训练相互独立地循环来实现这一点。
- en: To support this independent iteration scheme, we have added more code and additional
    inputs to control it, as shown in listing 9.13\. The code in the listing only
    shows the essential parts of the training loop, during which we add two inner
    loops—one to train the discriminator and the other the generator. How often these
    respective loops run can be controlled from Colab using the variables `CRITIC_ITS`,
    to control discriminator iterations, and `GEN_ITS`, to control generator iterations.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持这种独立的迭代方案，我们添加了更多的代码和额外的输入来控制它，如列表9.13所示。列表中的代码只显示了训练循环的基本部分，在这个过程中，我们添加了两个内部循环——一个用于训练判别器，另一个用于训练生成器。这些循环的运行频率可以通过Colab中的变量`CRITIC_ITS`来控制，以控制判别器迭代次数，以及`GEN_ITS`来控制生成器迭代次数。
- en: 'Listing 9.13 EDL_9_2_GAN_Optimization.ipynb: Breaking the training loop'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.13 EDL_9_2_GAN_Optimization.ipynb：打破训练循环
- en: '[PRE12]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ The variable to control the number of iterations on the discriminator/generator
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 控制判别器/生成器迭代次数的变量
- en: ❷ The loop for the discriminator
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 判别器的循环
- en: ❸ The loop for the generator
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 生成器的循环
- en: Set the `CRITIC_ITS` value to `5` and the `GEN_ITS` to `10`, and then rerun
    all the notebook cells. via Runtime > Run All. Figure 9.9 shows the results of
    breaking the tight dependency between generator and discriminator as well as the
    GAN converging.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 将`CRITIC_ITS`值设置为`5`，将`GEN_ITS`设置为`10`，然后通过“运行”>“运行所有单元格”重新运行所有笔记本单元格。图9.9显示了打破生成器和判别器之间紧密依赖关系以及GAN收敛的结果。
- en: '![](../Images/CH09_F09_Lanham.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F09_Lanham.png)'
- en: Figure 9.9 The GAN converges after breaking tight coupling
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.9 打破紧密耦合后GAN收敛
- en: 9.2.5 Learning exercises
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.5 学习练习
- en: 'Use the following exercises to improve your understanding of GAN training:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习来提高你对GAN训练的理解：
- en: How can you reduce the possibility of mode collapse while training the generator
    in a GAN?
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在GAN中训练生成器时，如何减少模式崩溃的可能性？
- en: What is the primary cause of convergence failure in generators?
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成器收敛失败的主要原因是什么？
- en: How can you reduce the vanishing gradient problem in GANs (generators)?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你如何减少GAN（生成器）中的梯度消失问题？
- en: Getting the right number of iterations between the generator and discriminator
    becomes a matter of rerunning the model with different values. This, of course,
    can be done manually or, you guessed it, with some form of evolutionary optimization.
    While this GAN is working better, we can add another improvement by updating the
    loss function we use in the next section.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成器和判别器之间获得正确的迭代次数成为了一个通过使用不同值重新运行模型的问题。当然，这可以手动完成，或者，正如你所猜想的，通过某种形式的进化优化来完成。当这个GAN运行得更好时，我们可以在下一节中通过更新我们使用的损失函数来添加另一个改进。
- en: 9.3 Fixing GAN problems with Wasserstein loss
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 使用Wasserstein损失修复GAN问题
- en: In the next notebook, we look at improving the GAN performance and fixing problems
    by reducing or eliminating convergence failures, vanishing gradients, and mode
    collapse. We do this by introducing an alternate method of measuring loss or distance,
    called *Wasserstein loss*, within a GAN. Before jumping into the notebook, let’s
    review what Wasserstein loss is in the next section.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个笔记本中，我们将通过减少或消除收敛失败、梯度消失和模式崩溃来提高GAN性能并解决问题。我们通过在GAN中引入一种称为*Wasserstein损失*的替代损失或距离度量方法来实现这一点。在跳入笔记本之前，让我们在下一节中回顾一下Wasserstein损失是什么。
- en: 9.3.1 Understanding Wasserstein loss
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 理解Wasserstein损失
- en: One of the key problems we face when training GANs is resolving and balancing
    the loss between the generator and discriminator. In a standard GAN, the discriminator
    measures loss in terms of probability, or the probability an image is fake or
    real. Mathematically measuring the difference in probabilities, a measure of uncertainty,
    becomes less accurate over consecutive iterations of training.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们训练GAN时，面临的一个关键问题是如何解决和平衡生成器和判别器之间的损失。在标准的GAN中，判别器通过概率来衡量损失，即图像是伪造的还是真实的概率。在数学上，测量概率差异，即不确定性的度量，在连续的训练迭代中会变得不准确。
- en: 'In 2017, Martin Arjovsky et al. proposed a revised method of loss in their
    paper titled “Wasserstein GAN”: swapping out the discriminator for a critic. In
    their method, the critic, instead of measuring probabilities, predicts a value
    representing how real or fake an image is. Thus, a generated image could be measured
    on a scale of real to fake.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年，Martin Arjovsky等人在其题为“Wasserstein GAN”的论文中提出了一种改进的损失方法：用评论家替换判别器。在他们提出的方法中，评论家不是测量概率，而是预测一个表示图像真实或伪造程度的值。因此，生成的图像可以在真实到伪造的尺度上进行测量。
- en: Fundamentally, when we train a GAN, our goal is to narrow or optimize the distance
    between what is real and fake. When we measure this distance in terms of probabilities,
    we are fixed to using a measure of uncertainty. By introducing a scaled distance
    for loss, we introduce an alternate measure of distance optimization.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，当我们训练GAN时，我们的目标是缩小或优化真实与伪造之间的距离。当我们用概率来衡量这个距离时，我们就固定使用不确定性的度量。通过引入损失的缩放距离，我们引入了距离优化的另一种度量。
- en: Figure 9.10 shows a comparison between measuring variational, or probabilistic,
    distance and Wasserstein distance. Wasserstein distance is nicknamed *earthmover
    distance*, as it better describes how the two distributions are measured. Where
    Kullback-Lieber and Jensen Shannon distance measure the horizontal distance, earthmover
    distance accounts for vertical differences as well.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.10显示了测量变分距离或概率距离与Wasserstein距离之间的比较。Wasserstein距离被称为*地球迁移距离*，因为它更好地描述了如何测量两个分布。Kullback-Lieber和Jensen
    Shannon距离衡量的是水平距离，而地球迁移距离则考虑了垂直差异。
- en: '![](../Images/CH09_F10_Lanham.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F10_Lanham.png)'
- en: Figure 9.10 The difference between variational distance and Wasserstein distance
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.10 变分距离与Wasserstein距离的差异
- en: The benefit of using earthmover distance is that the loss or measure of distance
    between a real or fake image is better quantified and results in a more robust
    and less sensitive model. Using Wasserstein distance also eliminates or reduces
    the possibility of the GAN encountering mode collapse, failure to converge, and
    vanishing gradients, as we see in the next section, when we implement Wasserstein
    loss in a GAN.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 使用地球迁移距离的好处是，它更好地量化了真实或伪造图像之间的损失或距离，从而产生一个更稳健且更不敏感的模型。使用Wasserstein距离还可以消除或减少GAN遇到模式崩溃、无法收敛和梯度消失的可能性，正如我们在下一节中实现Wasserstein损失在GAN中看到的那样。
- en: 9.3.2 Improving the DCGAN with Wasserstein loss
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 使用Wasserstein损失改进DCGAN
- en: Now, we can jump in and review how to implement Wasserstein, or earthmover,
    loss within a GAN. This notebook is the same as the DCGAN we just built with the
    extension of Wasserstein loss.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以跳进去回顾如何在GAN中实现Wasserstein，或地球迁移，损失。这个笔记本与我们在DCGAN中构建的相同，只是扩展了Wasserstein损失。
- en: Open the EDL_9_3_WGAN.ipynb notebook in Colab. Go ahead and run all the cells
    in the notebook via Runtime > Run All from the menu.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在Colab中打开EDL_9_3_WGAN.ipynb笔记本。然后，通过菜单中的“运行”>“运行所有单元格”来运行笔记本中的所有单元格。
- en: Scroll down to where the optimizers are instantiated. The first thing you may
    notice is that we switch the name of the `discriminator` model to `critic`, as
    shown in the following listing. This is because the `critic` predicts the measure
    of realness or fakeness rather than the probability of it being real or fake.
    Also, notice how we are now using the same optimizer for the `generator` and `critic`.
    We can also do this because the scale of real versus fake normalizes the differences
    between the measures.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动到实例化优化器的位置。你可能会首先注意到我们将`discriminator`模型的名称更改为`critic`，如下所示。这是因为`critic`预测的是真实度或伪造度的度量，而不是它真实或伪造的概率。此外，请注意我们现在正在为`generator`和`critic`使用相同的优化器。我们也可以这样做，因为真实与伪造的比例将标准化度量之间的差异。
- en: 'Listing 9.14 EDL_9_3_WGAN.ipynb: Optimizer set up'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.14 EDL_9_3_WGAN.ipynb：优化器设置
- en: '[PRE13]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ The generator optimizer
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 生成器优化器
- en: ❷ The discriminator swapped to the critic
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 判别器替换为评论家
- en: Move down to the next cell, shown in listing 9.15; we can see the calculation
    of Wasserstein loss in a function called `wasserstein_loss`. From the single line
    of code, you can see how the average of the true or real inputs is multiplied
    across the predictions. The output of this is the earthmover distance between
    both distributions.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 移动到下一个单元格，如列表9.15所示；我们可以看到一个名为`wasserstein_loss`的函数中的Wasserstein损失的计算。从单行代码中，你可以看到真实或实际输入的平均值是如何乘以预测的。这个输出的结果是两个分布之间的地球搬运距离。
- en: 'Listing 9.15 EDL_9_3_WGAN.ipynb: The Wasserstein loss function'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.15 EDL_9_3_WGAN.ipynb：Wasserstein损失函数
- en: '[PRE14]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Computes the average across real and predicted
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算真实和预测的平均值。
- en: We can then see how the `wasserstein_loss` function is used by looking at the
    `critic` construction code, shown in the following listing. Notice again how we
    updated the name of the `discriminator` to `critic` and employed the `wasserstein_loss`
    function when compiling the model.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过查看以下列表中的`critic`构建代码来看到`wasserstein_loss`函数的使用。再次注意，我们如何更新了`discriminator`的名称为`critic`，并在编译模型时使用了`wasserstein_loss`函数。
- en: 'Listing 9.16 EDL_9_3_WGAN.ipynb: Building the critic'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.16 EDL_9_3_WGAN.ipynb：构建评论者。
- en: '[PRE15]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Use Wasserstein loss.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用Wasserstein损失。
- en: ❷ Uses the selected optimizer
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用选定的优化器。
- en: The last major change we need to look at is updating the critic training code.
    Calculating loss with the `critic` is the same as the `discriminator`—nothing
    changes aside from the naming. Implementing Wasserstein loss introduces a possibility
    of exploding gradients; to overcome this, we add a clipping step, shown in listing
    9.17\. For every training iteration of the `critic`, we now make sure to clip
    each of the model weights to within the `clip_value` hyperparameter. This clipping
    of weights eliminates any possibility of exploding gradients and reduces the convergence
    model space.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要考虑的最后的主要变化是更新评论者训练代码。使用`critic`计算损失与`discriminator`相同——除了命名之外没有变化。实现Wasserstein损失引入了梯度爆炸的可能性；为了克服这一点，我们添加了一个剪辑步骤，如列表9.17所示。对于`critic`的每个训练迭代，我们现在确保将每个模型权重剪辑到`clip_value`超参数内。这种权重的剪辑消除了梯度爆炸的可能性，并减少了收敛模型空间。
- en: 'Listing 9.17 EDL_9_3_WGAN.ipynb: Training the critic'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.17 EDL_9_3_WGAN.ipynb：训练评论者。
- en: '[PRE16]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ The average of real and fake loss
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 真实和伪造损失的平均值。
- en: ❷ Loops through the critic layers
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 遍历评论层。
- en: ❸ The clip layer weights with range
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用范围剪辑层权重。
- en: '![](../Images/CH09_F11_Lanham.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F11_Lanham.png)'
- en: Figure 9.11 Training a Wasserstein GAN on extracted digits
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11在提取的数字上训练Wasserstein GAN。
- en: Figure 9.11 shows the results of training this GAN over 80 epochs on a single
    extracted class of the MNIST Handwritten Digits dataset. If you want to see how
    this dataset performs on the Fashion-MNIST dataset, rerun the entire notebook
    with the code change in listing 9.18\. You can also remove the call to the extract
    function to see how well the model works across all classes in the datasets.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11显示了在MNIST手写数字数据集的一个单独提取类别上训练这个GAN在80个epoch的结果。如果你想看到这个数据集在Fashion-MNIST数据集上的表现，请重新运行整个笔记本，并在列表9.18中更改代码。你也可以移除对extract函数的调用，以查看模型在数据集的所有类别上的表现。
- en: 'Listing 9.18 EDL_9_3_WGAN.ipynb: Switching to the Fashion-MNIST dataset'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.18 EDL_9_3_WGAN.ipynb：切换到Fashion-MNIST数据集
- en: '[PRE17]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Comments out the line
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 注释掉该行。
- en: ❷ Uncomments the line
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 取消注释该行。
- en: Introducing Wasserstein loss to the DCGAN, making it a WGAN or WDCGAN, alleviates
    several shortcomings of the standard GAN. Reducing these additional complications
    makes it easier for us to build an evolutionary optimizer to find our best possible
    GAN. Before we do that, we need to wrap our WDCGAN up, so it can become an encoded
    model usable in evolutionary optimization in the next section.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 将Wasserstein损失引入DCGAN，使其成为WGAN或WDCGAN，可以缓解标准GAN的几个缺点。减少这些额外的复杂性使得我们更容易构建一个进化优化器来找到我们可能的最佳GAN。在我们这样做之前，我们需要将我们的WDCGAN包装起来，以便它可以在下一节中用作进化优化中的编码模型。
- en: 9.4 Encoding the Wasserstein DCGAN for evolution
  id: totrans-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.4 编码Wasserstein DCGAN以进行进化。
- en: We have already undergone the process of encoding the hyperparameters or architecture
    of various models in previous chapters. For our next notebook, we look to do the
    same thing but limit the encoding to just hyperparameters. This allows for a more
    concise optimization space for the evolutionary optimizer to explore.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在之前的章节中经历了将各种模型的超参数或架构编码的过程。对于我们的下一个笔记本，我们打算做同样的事情，但仅限于超参数的编码。这允许进化优化器探索一个更简洁的优化空间。
- en: Evolutionary optimizing complex models
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 进化优化复杂模型。
- en: As the models we attempt to optimize become more complex, we are faced with
    iterating through more intense training operations. We can no longer rely on a
    model just being trained for 3 epochs to give us reasonable results; instead,
    some models may require training for hundreds of epochs. GAN optimization is one
    of those problem sets that can be expensive to train. Because of this, if you
    want to see interesting or good results, expect to train some of these optimizations
    for hours or even days.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们尝试优化的模型变得更加复杂，我们面临着进行更多强度训练操作的迭代。我们不能再依赖于模型只训练3个epoch就能给出合理的结果；相反，一些模型可能需要训练数百个epoch。GAN优化是那些训练成本可能很高的问题集之一。正因为如此，如果你想看到有趣或好的结果，预期一些优化可能需要数小时甚至数天的时间来训练。
- en: The next notebook is an extension and consolidation of the GAN code we have
    been developing in this chapter into a single class. This class is instantiated
    by passing an `individual` `gene` sequence to populate the various model hyperparameters.
    The `gene` sequence is a simple array of floats we have seen many times before
    when employing genetic algorithms.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个笔记本是对本章中我们一直在开发的GAN代码的扩展和整合，将其合并为一个单独的类。这个类通过传递一个`individual` `gene`序列来实例化，以填充各种模型超参数。`gene`序列是我们之前在应用遗传算法时多次见过的简单浮点数数组。
- en: Open the EDL_9_4_WDCGAN_encoder.ipynb notebook in Colab. Go ahead and run all
    the cells by selecting Runtime > Run All from the menu.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在Colab中打开EDL_9_4_WDCGAN_encoder.ipynb笔记本。然后从菜单中选择运行 > 运行所有来运行所有单元格。
- en: 'In this notebook, a single class encapsulates the entire model and variation
    of each class is controlled by an input `gene` sequence: an array of floats, where
    each element in the array has a corresponding controlled hyperparameter defined
    by the index to the sequence. The code to define these indexes and min/max limits
    of the hyperparameter values is shown in the following listing.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个笔记本中，一个单独的类封装了整个模型以及每个类的变体，每个类的变体由一个输入`gene`序列控制：一个浮点数数组，其中数组中的每个元素都有一个由序列索引定义的对应控制的超参数。定义这些索引和超参数值的最小/最大限制的代码如下所示。
- en: 'Listing 9.19 EDL_9_4_WDCGAN_encoder.ipynb: `gene` encoding parameters'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '列表9.19 EDL_9_4_WDCGAN_encoder.ipynb: `gene`编码参数'
- en: '[PRE18]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Base number of filters used in convolution
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 卷积中使用的基滤波器数量
- en: ❷ Alpha parameter used in LeakyReLU
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ LeakyReLU中使用的Alpha参数
- en: ❸ Number of critic iterations per generator
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 每个生成器迭代的批评次数
- en: ❹ The clipping range to clip critic weights
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 裁剪批评权重的范围
- en: ❺ The optimizer learning rate
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 优化器的学习率
- en: We can next look at the `__init__` function of the `DCGAN` class to see how
    the `gene` sequence `i` defines each of the hyperparameters used in the model,
    as shown in listing 9.20\. First, we make sure the `image_shape` is divisible
    by four and can fit within the model’s convolutional architecture. Next, each
    of the hyperparameter values is generated by mapping the float to the corresponding
    space. The code also initiates the weights around the value zero to better align
    the weights with the clipping function. Finally, the code creates a single optimizer
    and then constructs the various models.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来可以查看`DCGAN`类的`__init__`函数，以了解`gene`序列`i`如何定义模型中使用的每个超参数，如列表9.20所示。首先，我们确保`image_shape`能被4整除并且可以适应模型的卷积架构。接下来，每个超参数值通过将浮点数映射到相应的空间来生成。代码还初始化权重在零值周围，以便更好地将权重与裁剪函数对齐。最后，代码创建一个单独的优化器，然后构建各种模型。
- en: 'Listing 9.20 EDL_9_4_DCGAN_encoder.ipynb: Initializing the model'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '列表9.20 EDL_9_4_DCGAN_encoder.ipynb: 初始化模型'
- en: '[PRE19]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Confirms the image size is divisible by 4
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 确认图像大小能被4整除
- en: ❷ Converts float to a hyperparameter
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将浮点数转换为超参数
- en: ❸ Initializes the starting weights
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 初始化起始权重
- en: ❹ Creates a single optimizer
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 创建一个单独的优化器
- en: ❺ Builds the models
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 构建模型
- en: Much of the remaining code we have seen before, but we should highlight an updated
    section in the training function, shown in listing 9.21\. Comparing loss between
    models in GANs is complicated by variations in loss functions and model performance.
    To compare losses between one GAN and another, we normalize the loss. We do this
    by tracking the min and max losses for the `critic` and `generator`, and then
    we output this value on a linear space between `0` and `1`, using the `reverse_space`
    function.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经看到了大部分代码，但我们应该突出显示训练函数中的一个更新部分，如列表9.21所示。在GANs中比较模型之间的损失比较复杂，因为损失函数和模型性能存在差异。为了比较一个GAN和另一个GAN之间的损失，我们标准化损失。我们通过跟踪`critic`和`generator`的最小和最大损失来实现这一点，然后使用`reverse_space`函数在`0`和`1`之间的线性空间上输出这个值。
- en: 'Listing 9.21 EDL_9_4_DCGAN_encoder.ipynb: Normalizing the output loss'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.21 EDL_9_4_DCGAN_encoder.ipynb：归一化输出损失
- en: '[PRE20]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ Tracks the minimum loss
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 跟踪最小损失
- en: ❷ Tracks the maximum loss
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 跟踪最大损失
- en: ❸ Normalizes the values to 0–1
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将值归一化到 0–1 范围内
- en: By encapsulating everything into a class, including the training function, we
    can quickly instantiate a GAN with a known `gene` sequence to test the results.
    To do this, as shown in listing 9.22, we use the `reverse_space` function to convert
    known hyperparameter values to the appropriate float values embedded in the sequence,
    called an `individual`. This `individual` is then passed into the `DCGAN` construction
    to create the model. After that, the class’s `train` function is called, using
    the `verbose=1` option to display the training results.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将包括训练函数在内的所有内容封装到一个类中，我们可以快速实例化一个具有已知 `gene` 序列的 GAN 来测试结果。为此，如列表 9.22 所示，我们使用
    `reverse_space` 函数将已知的超参数值转换为序列中嵌入的适当浮点值，称为 `individual`。然后，将这个 `individual` 传递到
    `DCGAN` 构造函数中创建模型。之后，调用类的 `train` 函数，使用 `verbose=1` 选项显示训练结果。
- en: 'Listing 9.22 EDL_9_4_DCGAN_encoder.ipynb: Testing the encoding and GAN training'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.22 EDL_9_4_DCGAN_encoder.ipynb：测试编码和 GAN 训练
- en: '[PRE21]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Creates a random individual
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个随机个体
- en: ❷ Converts values to 0–1 space
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将值转换为 0–1 空间
- en: ❸ Creates the model with the individual
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用个体创建模型
- en: ❹ Trains the model, and shows the results
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 训练模型并显示结果
- en: '![](../Images/CH09_F12_Lanham.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F12_Lanham.png)'
- en: Figure 9.12 The output of training DCGAN over 10 epochs
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12 训练 DCGAN 10 个周期的输出
- en: Figure 9.12 shows the results of training the model over 10 epochs on an extracted
    class from the MNIST Handwritten Digits dataset. By normalizing the loss, we can
    clearly see what the model is working to optimize. If you compare these results
    to figure 9.11, you can clearly see how easy it is to identify the target of optimization
    within a known range. This is a critical piece to optimizing the model when using
    genetic algorithms, as discussed later in this chapter.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12 展示了在 MNIST 手写数字数据集的一个提取类别上训练模型 10 个周期的结果。通过归一化损失，我们可以清楚地看到模型正在努力优化的内容。如果你将这些结果与图
    9.11 进行比较，你可以清楚地看到在已知范围内识别优化目标是多么容易。这是在使用遗传算法优化模型时一个关键的部分，正如本章后面所讨论的。
- en: Go ahead and try other hyperparameter values to see how these affect model training.
    You may want to try using completely random `gene` sequences to see what the model
    generates as well.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试其他超参数值，看看这些如何影响模型训练。你可能想尝试使用完全随机的 `gene` 序列来查看模型生成的结果。
- en: 9.4.1 Learning exercises
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.4.1 学习练习
- en: 'Use the following exercise to improve your understanding of the WGAN:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习来提高你对 WGAN 的理解：
- en: Increase or decrease the `gene` encoding hyperparameters in listing 9.19 and
    then rerun the notebook.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整列表 9.19 中的 `gene` 编码超参数，然后重新运行笔记本。
- en: Don’t use the `extract` function to limit the dataset to a single class and
    then rerun the notebook with all the data.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不要使用 `extract` 函数将数据集限制为单个类别，然后使用所有数据重新运行笔记本。
- en: Use a different dataset, like Fashion-MNIST and then rerun the notebook.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用不同的数据集，例如 Fashion-MNIST，然后重新运行笔记本。
- en: Now that we have an encapsulated class that represents the GAN and the ability
    to pass a representative `gene` sequence to initialize the model, we can move
    on to optimization. In the next section, we add the genetic algorithm code to
    optimize this DCGAN model.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经封装了一个代表 GAN 的类，并且能够传递一个代表性的 `gene` 序列来初始化模型，我们可以继续进行优化。在下一节中，我们将遗传算法代码添加到优化这个
    DCGAN 模型中。
- en: 9.5 Optimizing the DCGAN with genetic algorithms
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.5 使用遗传算法优化 DCGAN
- en: Now that we have the genetic encoder built for replicating a DCGAN, we can pull
    everything together. At this point, optimizing the encapsulated DCGAN class is
    a matter of simply adding DEAP and defining the GA parameters we require for evolution.
    Again, adding evolutionary search provides us the ability to self-optimize GAN
    networks—which is exactly what we do in the next notebook.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为复制 DCGAN 构建了遗传编码器，我们可以将所有内容整合在一起。在这个阶段，优化封装的 DCGAN 类只是简单地添加 DEAP 并定义我们需要的进化
    GA 参数。再次强调，添加进化搜索为我们提供了自我优化 GAN 网络的能力——这正是我们在下一个笔记本中所做的。
- en: Open the EDL_9_5_EVO_DCGAN.ipynb notebook in Colab. Run the entire notebook
    by selecting Runtime > Run All from the menu.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Colab 中打开 EDL_9_5_EVO_DCGAN.ipynb 笔记本。通过选择菜单中的“运行”>“运行所有”来运行整个笔记本。
- en: As you may notice, this notebook installs DEAP and adds the required tools and
    operators for performing GA evolution. Code cells that are not relevant are hidden,
    but if you want to review their contents, just click the Show Code link or double-click
    on the cell. We have seen most of this code before, and as always, we just refer
    to the relevant code sections here.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如你可能注意到的，这个笔记本安装了DEAP，并添加了执行GA进化的所需工具和算子。不相关的代码单元格被隐藏了，但如果你想查看它们的内 容，只需点击“显示代码”链接或双击单元格。我们之前已经看到过大部分的代码，而且像往常一样，我们只是在这里引用相关的代码部分。
- en: We first look at the `evaluate` function, shown in listing 9.23, where we evaluate
    the `fitness` of the model. At the start of the function, we convert the `individual`
    to a string for use as an index in the `trained` dictionary. Notice how we are
    rounding the values to a single decimal point. Thus, a starting value of `[.2345868]`
    becomes `[.2]`, which simplifies or discretizes the number of entries in the dictionary.
    This is done to simplify the training from an infinite exploration space to a
    finite one. To be precise, by rounding off the values to a single digit and knowing
    the `gene` sequence length is `5`, we can determine that there are 10 × 10 × 10
    × 10 × 10 = 100,000 possible models to test. The real benefit of doing this is
    that it allows greater `populations` to be evolved, without having to reevaluate
    similar `individuals`. As shown in this section, evaluating each model takes a
    significant amount of time.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先来看`evaluate`函数，如列表9.23所示，其中我们评估模型的`fitness`。在函数的开始部分，我们将`individual`转换为字符串，以便在`trained`字典中用作索引。注意我们是如何将数值四舍五入到小数点后一位的。因此，起始值`[.2345868]`变成了`[.2]`，这简化或离散化了字典中的条目数量。这样做是为了将训练从无限探索空间简化为有限空间。更准确地说，通过将数值四舍五入到一位数字，并且知道`gene`序列长度为`5`，我们可以确定有10
    × 10 × 10 × 10 × 10 = 100,000个可能的模型需要测试。这样做的好处是它允许进化更大的`populations`，而无需重新评估相似的`individuals`。正如本节所示，评估每个模型需要相当多的时间。
- en: 'Listing 9.23 EDL_9_5_EVO_DCGAN_encoder.ipynb: The `evaluate` function'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.23 EDL_9_5_EVO_DCGAN_encoder.ipynb：`evaluate`函数
- en: '[PRE22]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ The dictionary to hold the evaluation history
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 保存评估历史的字典
- en: ❷ Rounds off the values
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 四舍五入数值
- en: ❸ The trained dictionary of history
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 训练历史的字典
- en: ❹ Calculates the optimized loss
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 计算优化损失
- en: ❺ The average of calculated losses
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 计算损失的平均值
- en: ❻ The trained dictionary of history
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 训练历史的字典
- en: 'Optimizing a DCGAN is not a simple matter of comparing accuracy. We need to
    account for three output values or losses from the model: the real, fake, and
    generated losses. Each of these losses need to be optimized—in this case, minimized—in
    different ways. If you refer to listing 9.23, you can see how each loss is extracted
    and, in the case of the real and generated losses, which are inverted to produce
    a partial `fitness`. The total `fitness` is calculated as an average of the three
    derived loss or `fitness` values.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 优化DCGAN不是简单比较准确性的问题。我们需要考虑模型输出的三个值或损失：真实、伪造和生成损失。这些损失中的每一个都需要以不同的方式进行优化——在这种情况下，最小化。如果你参考列表9.23，你可以看到每个损失是如何提取的，在真实和生成损失的情况下，它们被反转以产生部分`fitness`。总`fitness`是三个派生损失或`fitness`值的平均值。
- en: The output in the notebook shows the partial results of evolving an optimal
    solution for the DCGAN. We leave it up to you to run this example further and
    explore the best potential GAN you can produce.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本中的输出显示了进化DCGAN最优解的部分结果。我们留给你自己运行这个示例并探索你能产生的最佳潜在GAN。
- en: The last notebook can take a significant amount of time to evolve, but it is
    automated and will eventually produce good results. As AutoML solutions go, GANs,
    or other complex models, are not typically high on the list of those requiring
    automated optimization. Over time and as the field of AI/ML evolves, methods like
    the one we introduced here will likely become more mainstream.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个笔记本可能需要相当长的时间来进化，但它自动化了，最终会得到好的结果。在AutoML解决方案中，GAN或其他复杂模型通常不是需要自动化优化的列表上的高优先级。随着时间的推移和AI/ML领域的发展，我们这里介绍的方法可能会变得更加主流。
- en: 9.5.1 Learning exercises
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.5.1 学习练习
- en: 'Use the following exercises to continue exploring this version of an Evo DCGAN:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习继续探索这个Evo DCGAN版本：
- en: Take the time to evolve a GAN model. Then, use this model to continue training
    on a dataset to see how well you can generate new output.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 抽出时间进化一个GAN模型。然后，使用这个模型在数据集上继续训练，看看你能够生成多好的新输出。
- en: Take an evolved model developed on one dataset and reuse it to train a GAN on
    a new dataset. This works best on datasets with similar sizes, like the Fashion-MNIST
    and MNIST Handwritten Digits datasets.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将在一个数据集上开发的进化模型重新用于在新的数据集上训练 GAN。这在数据集大小相似的情况下效果最佳，例如 Fashion-MNIST 和 MNIST
    手写数字数据集。
- en: Adapt this notebook to use evolutionary strategies and/or differential evolution.
    Evaluate how well this may or may not improve the evolution of the GAN training
    hyperparameters.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这个笔记本调整为使用进化策略和/或微分进化。评估这种方法可能或可能不会改善 GAN 训练超参数的进化。
- en: Summary
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Generative adversarial networks are a form of generative modeling that employs
    dual networks—one for data discrimination and the other for data generation:'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗网络是一种生成模型，它使用双网络——一个用于数据判别，另一个用于数据生成：
- en: GANs work by feeding real samples to the discriminator while, at the same time,
    allowing the generator to generate fake samples.
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs 通过向判别器提供真实样本，同时允许生成器生成假样本来工作。
- en: The generator learns to generate better output by getting feedback from the
    discriminator, which is also learning to better classify data as real or fake.
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器通过从判别器获得反馈来学习生成更好的输出，而判别器也在学习更好地将数据分类为真实或假。
- en: Building a GAN can be done simply with Python and Keras.
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 和 Keras 可以简单地构建 GAN。
- en: 'GANs are notoriously difficult to train effectively:'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs 以其难以有效训练而闻名：
- en: The core problem in training GANs is attaining a balance between how quickly
    the discriminator and generator learn.
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练 GAN 的核心问题是在判别器和生成器学习速度之间取得平衡。
- en: Both networks need to learn at the same rate to balance their adversarial relationship.
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个网络需要以相同的速率学习，以平衡它们之间的对抗关系。
- en: When GANs fall out of balance, many common problems can occur, such as the inability
    to converge, mode collapse, and vanishing gradients.
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 GANs 失去平衡时，可能会出现许多常见问题，例如无法收敛、模式坍塌和梯度消失。
- en: Solving this problem of training can be tackled by using evolutionary algorithms.
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用进化算法来解决这个训练问题。
- en: Wasserstein loss, or earthmover distance, is a measure of loss that can help
    a GAN resolve or minimize common training problems.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 水晶距离（Wasserstein loss）或地球迁移距离是一种衡量损失的措施，可以帮助 GAN 解决或最小化常见的训练问题。
- en: Balancing the training hyperparameters of a GAN can be assisted by encapsulating
    a GAN (DCGAN) into a class that accepts a genetic encoded `genome` representation
    for evolutionary optimization.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将 GAN（DCGAN）封装到一个接受遗传编码的 `genome` 表示形式的类中，可以帮助平衡 GAN 的训练超参数。
- en: Genetic algorithms can be used to balance the training of a discriminator and
    generator within a GAN.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用遗传算法来平衡 GAN 中判别器和生成器的训练。
