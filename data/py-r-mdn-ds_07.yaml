- en: Chapter 4\. Data Format Context
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章。数据格式背景
- en: Boyan Angelov
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Boyan Angelov
- en: In this chapter we’ll review tools in Python and R for importing and processing
    data in a variety of formats. We’ll cover a selection of packages, compare and
    contrast them, and highlight the properties that make them effective. At the end
    of this tour, you’ll be able to select packages with confidence. Each section
    illustrates the tool’s capabilities with a specific mini-case study, based on
    tasks that a data scientist encounters daily. If you’re transitioning your work
    from one language to another, or simply want to find out how to get started quickly
    using complete, well-maintained and context-specific packages this chapter will
    guide you.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将审查Python和R中用于导入和处理多种格式数据的工具。我们将涵盖一系列包，进行比较和对比，并突出它们的有效性。在这次旅程结束时，您将能够自信地选择包。每个部分通过一个特定的小案例研究展示工具的能力，这些案例基于数据科学家每天遇到的任务。如果您正在将工作从一种语言转换到另一种，或者只是想快速了解如何使用完整、维护良好和特定背景的包，本章将为您指引。
- en: Before we dive in, remember that the open-source ecosystem is constantly changing.
    New developments, such as [transformer models](https://www.tensorflow.org/tutorials/text/transformer)
    and [xAI](https://robotics.sciencemag.org/content/4/37/eaay7120), seem to emerge
    every other week. These often aim at lowering the learning curve and increasing
    developer productivity. This explosion of diversity also applies to related packages,
    resulting in a nearly constant flow of new and (hopefully) better tools. If you
    have a very specific problem, there’s probably a package already available for
    you, so you don’t have to reinvent the wheel. Tool selection can be overwhelming,
    but at the same time this variety of options can improve the quality and speed
    of your data science work.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入讨论之前，请记住开源生态系统是不断变化的。新的发展，例如[转换器模型](https://www.tensorflow.org/tutorials/text/transformer)和[xAI](https://robotics.sciencemag.org/content/4/37/eaay7120)，似乎每隔一周就会出现。这些通常旨在降低学习曲线并增加开发者的生产力。这种多样性的爆炸也适用于相关的包，导致几乎不断涌现新的（希望是）更好的工具。如果您有非常具体的问题，可能已经有适合您的包，因此您不必重新发明轮子。工具选择可能会令人不知所措，但同时这种多样性的选择可以提高数据科学工作的质量和速度。
- en: The package selection in this chapter can appear limited in view, hence it is
    essential to clarify our selection criteria. So what qualities should we look
    for in a good tool?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的包选择在视野上可能显得有限，因此澄清我们的选择标准是至关重要的。那么，一个好的工具应该具备哪些特质？
- en: 'It should be **open source**: there is a large number of valuable commercial
    tools available, but we firmly believe that open source tools have a great advantage.
    They tend to be easier to extend and understand what their inner workings are,
    and are more popular.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该**开源**：有大量有价值的商业工具可用，但我们坚信开源工具具有巨大的优势。它们往往更容易扩展和理解其内部工作原理，并且更受欢迎。
- en: 'It should be **feature-complete**: the package should include a comprehensive
    set of functions that help the user do their fundamental work without resorting
    to other tools.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该**功能完备**：该包应包括一套全面的函数，帮助用户在不依赖其他工具的情况下完成他们的基础工作。
- en: 'It should be **well-maintained**: one of the drawbacks of using Open Source
    Software (OSS) is that sometimes packages have a short lifecycle, and their maintenance
    is abandoned (so called “abandonware”). We want to use packages which are actively
    worked on, so we can feel confident they are up-to-date.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该**维护良好**：使用开源软件（OSS）的一个缺点是，有时包的生命周期很短，它们的维护被放弃（所谓的“废弃软件”）。我们希望使用那些正在积极开发的包，这样我们就可以确信它们是最新的。
- en: Let’s begin with a definition. What is a “data format”? There are [several answers](https://en.wikipedia.org/wiki/Data_format)
    available. Possible candidates are *data type*, *recording format* and *file format*.
    *Data type* is related to data stored in databases or types in programming languages
    (for example integer, float or string). The *recording format* is how data is
    stored in a physical medium, such as CD or DVD. And finally, what we’re after,
    the *file format*, i.e. how information is *prepared for a computing purpose*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个定义开始。什么是“数据格式”？[有几种答案](https://en.wikipedia.org/wiki/Data_format)可供选择。可能的候选者包括*数据类型*、*录音格式*和*文件格式*。*数据类型*与存储在数据库中的数据或编程语言中的类型有关（例如整数、浮点数或字符串）。*录音格式*是数据如何存储在物理介质上，例如CD或DVD。最后，我们关注的是*文件格式*，即信息如何为计算目的*准备*。
- en: 'With that definition in hand, one might still wonder why should we dedicate
    an entire chapter to focus just on file formats? You have probably been exposed
    to them in another context, such as saving a PowerPoint slide deck with a `.ppt`
    or `.pptx` extension (and wondering which one is better). The problem here goes
    much further beyond basic tool compatibility. The way information is stored influences
    the complete downstream data science process. For example, if our end goal is
    to perform advanced analytics and the information is stored in a text format,
    we have to pay attention to factors such as character encoding (a notorious problem,
    especially for Python^([1](ch04.xhtml#idm45127452048648))). For such data to be
    effectively processed, it also needs to go through several steps^([2](ch04.xhtml#idm45127452046808)),
    such as [tokenization](https://en.wikipedia.org/wiki/Tokenization) and [stop word](https://en.wikipedia.org/wiki/Stop_word)
    removal. Those same steps are not applicable to image data, even though we may
    have the same end goal in mind, e.g. classification. In that case other processing
    techniques are more suitable, such as resizing and scaling. These differences
    in data processing pipelines are shown on [???](#pipelines_diff). To summarize:
    the data format is the most significant factor influencing what you can, and cannot
    do with it.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个定义，人们可能会想，为什么我们要专门用一整章节来讨论文件格式呢？也许你在其他情境下已经接触过它们，比如用`.ppt`或`.pptx`扩展名保存
    PowerPoint 幻灯片（并且想知道哪个更好）。然而，问题远不止于基本工具的兼容性。信息存储的方式会影响整个下游数据科学流程。例如，如果我们的最终目标是进行高级分析，而信息以文本格式存储，我们必须关注诸如字符编码等因素（这是一个臭名昭著的问题，尤其是对于
    Python^([1](ch04.xhtml#idm45127452048648))）。为了有效处理这些数据，还需要经历几个步骤^([2](ch04.xhtml#idm45127452046808))，比如[tokenization](https://en.wikipedia.org/wiki/Tokenization)和[stop
    word](https://en.wikipedia.org/wiki/Stop_word)移除。然而，这些步骤对于图像数据则不适用，即使我们的最终目标可能是相同的，比如分类。在这种情况下，更适合的是其他处理技术，比如调整大小和缩放。这些数据处理管道的差异展示在[pipelines_diff](#pipelines_diff)上。总结一下：数据格式是影响你能够做什么、不能做什么的最重要因素。
- en: Note
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We now use the word “pipeline” for the first time in this context, so let’s
    use the opportunity to define it. You have probably heard the expression that
    “data is the new oil”. This expression goes beyond a simple marketing strategy
    and represents a useful way to think about data. There are surprisingly many parallels
    between how oil and data are processed. You can imagine that the initial data
    that the business collects is the rawest form - probably of limited use initially.
    It then undergoes a sequence of steps, called data processing, before it’s used
    in some application (i.e. for training an ML model or feeding a dashboard). In
    oil processing this would be called refinement and enrichment - making the data
    usable for a business purpose. Pipelines transport the different oil types (raw,
    refined) through the system to its final state. The same term can be used in data
    science and engineering to describe the infrastructure and technology required
    to process and deliver data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在这个上下文中首次使用“管道”这个词，让我们利用这个机会来定义它。你可能听说过“数据是新的石油”的表达。这个表达不仅仅是一种简单的营销策略，而是一种有用的思考数据的方式。在数据和石油处理之间存在惊人的许多类似之处。你可以想象，企业收集的初始数据是最原始的形式，最初可能有限的用途。然后，在它被用于某些应用程序之前，它经历了一系列称为数据处理的步骤（例如用于训练
    ML 模型或供给仪表盘）。在石油处理中，这被称为精炼和丰富化 - 使数据对业务目的可用。管道将不同类型的石油（原油、精炼油）通过系统传输到最终状态。在数据科学和工程中，同样的术语可以用来描述处理和交付数据所需的基础设施和技术。
- en: difference between common data format pipelines. The green color indicates the
    shared steps between the workflows. image::img/pipelines_diff.jpg[""]
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 常见数据格式管道之间的差异。绿色表示工作流程之间的共享步骤。image::img/pipelines_diff.jpg[""]
- en: Infrastructure and performance also need to be taken into consideration when
    working with a specific data format. For example, with image data, you’ll need
    more storage availability. For time-series data you might need to use a particular
    database, such as [Influx DB](https://www.influxdata.com/products/influxdb-overview/).
    And finally, in terms of performance, image classification is often solved using
    deep learning methods based on Convolutional Neural Networks (CNNs) which may
    require a Graphics Processing Unit (GPU). Without it, model training can be very
    slow and become a bottleneck both for your development work and a potential production
    deployment.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理特定数据格式时，还需要考虑基础设施和性能。例如，对于图像数据，您需要更多的存储空间。对于时间序列数据，您可能需要使用特定的数据库，例如[Influx
    DB](https://www.influxdata.com/products/influxdb-overview/)。最后，在性能方面，图像分类通常使用基于卷积神经网络（CNN）的深度学习方法来解决，这可能需要图形处理单元（GPU）。如果没有，模型训练可能会非常缓慢，并成为开发工作和潜在生产部署的瓶颈。
- en: Now that we covered the reasons to carefully consider which packages to use,
    we’ll have a look at the possible data formats. This overview is presented in
    [Table 4-1](#data-format-zoo-table) (note that those tools are mainly designed
    for small to medium size datasets). Admittedly, we are just scratching the surface
    on what’s out there, and there are a few notable omissions (such as audio and
    video). Here, we’ll focusing on the most widely used formats.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了仔细考虑使用哪些包的原因，让我们来看看可能的数据格式。这个概述在[表 4-1](#data-format-zoo-table)中展示（请注意，这些工具主要设计用于小到中等规模的数据集）。诚然，我们只是浅尝辄止，还有一些显著的遗漏（比如音频和视频）。在这里，我们将专注于最常用的格式。
- en: Table 4-1\. An overview of data formats and popular Python and R packages used
    to process data stored in them.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-1\. 数据格式及用于处理其中存储数据的流行 Python 和 R 包概览。
- en: '| Data type | Python package | R package |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 数据类型 | Python 包 | R 包 |'
- en: '| --- | --- | --- |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Tabular | `pandas` | `readr`, `rio` |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 表格 | `pandas` | `readr`，`rio` |'
- en: '| Image | `open-cv`, `scikit-image`, `PIL` | `magickr`, `imager`, `EBImage`
    |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 图像 | `open-cv`，`scikit-image`，`PIL` | `magickr`，`imager`，`EBImage` |'
- en: '| Text | `nltk`, `spaCy` | `tidytext`, `stringr` |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | `nltk`，`spaCy` | `tidytext`，`stringr` |'
- en: '| Time series | `prophet`, `sktime` | `prophet`, `ts`, `zoo` |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 时间序列 | `prophet`，`sktime` | `prophet`，`ts`，`zoo` |'
- en: '| Spatial | `gdal`, `geopandas`, `pysal` | `rgdal`, `sp`, `sf`, `raster` |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 空间 | `gdal`，`geopandas`，`pysal` | `rgdal`，`sp`，`sf`，`raster` |'
- en: This table is by no means exhaustive, and we are certain new tools will appear
    soon, but those are the workhorses fulfilling our selection criteria. Let’s get
    them to work in the following sections, and see which ones are the best for the
    job!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这张表远非详尽无遗，我们确信新工具将很快出现，但这些工具是实现我们选择标准的工作马，让我们在接下来的章节中看看它们的表现，看看哪些是最适合这项工作的！
- en: External versus base packages
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 外部与基础包
- en: In [Chapter 2](ch02.xhtml#ch03) and [Chapter 3](ch03.xhtml#ch04), we introduced
    packages very early in the learning process. In Python we used `pandas` right
    at the outset and we also transitioned to the `tidyverse` in R relatively quickly.
    This allowed us to be productive much faster than if we went down the rabbit holes
    of archaic language features that you’re unlikely to need as a beginner^([3](ch04.xhtml#idm45127452007560)).
    A programming language’s utility is defined by the availability and quality of
    it’s third-party packages, as opposed to the core features of the language itself.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](ch02.xhtml#ch03)和[第三章](ch03.xhtml#ch04)中，我们在学习过程的早期就介绍了包。在 Python 中，我们在一开始就使用了`pandas`，而在
    R 中，我们也相对迅速地过渡到了`tidyverse`。这使我们比如果深入探讨那些初学者不太可能需要的过时语言特性，更快地提高了生产力^([3](ch04.xhtml#idm45127452007560))。一个编程语言的实用性取决于其第三方包的可用性和质量，而不是语言本身的核心特性。
- en: Note
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: This is not to say that the aren’t a lot of things that you can accomplish with
    just base R (as you’ll see in some of the upcoming examples), but taking advantage
    of the open-source ecosystem is a fundamental skill to increase your productivity
    and avoid reinventing the wheel.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着仅仅使用基础 R 就可以完成很多事情（正如您将在即将看到的一些示例中所见），但利用开源生态系统是提高您生产力的基本技能，避免重复造轮子。
- en: Go back and learn the basics
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回头学习基础知识
- en: There is a danger in overusing third-party packages, and you have to be aware
    of when the right time to go back to the basics is. Otherwise you might fall victim
    to a false sense of security, and become reliant on the training wheels provided
    by tools such as `pandas`. This might lead to difficulties when dealing with more
    specific real-world challenges.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 过度使用第三方包存在风险，你必须知道何时是回归基础的正确时机。否则，你可能会陷入虚假的安全感，并依赖于像`pandas`这样的工具提供的支持。这可能导致在处理更具体的现实世界挑战时遇到困难。
- en: 'Let’s now see this package vs. base language concept plays out in practice
    by going into detail with a topic we’re already familiar with: tabular data^([4](ch04.xhtml#idm45127452002248)).
    There are at least two ways to do this in Python. First, using `pandas`:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过详细讨论一个我们已经熟悉的主题，来看看这个包与基础语言概念在实践中是如何发挥作用的：表格数据^([4](ch04.xhtml#idm45127452002248))。在Python中至少有两种方法可以做到这一点。首先是使用`pandas`：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Second, with the built-in `csv` module:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 其次是使用内置的`csv`模块：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](Images/1.png)](#co_data_format_context_CO1-1)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_data_format_context_CO1-1)'
- en: Note how you need to specify the [file mode](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files),
    in this case `"r"` (standing for “read”). This is to make sure the file is not
    overwritten by accident, hinting at a more general-purpose oriented language.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意你需要指定[file mode](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files)，在本例中是`"r"`（表示“读取”）。这是为了确保文件不会意外被覆盖，这暗示了一种更面向通用目的的语言。
- en: '[![2](Images/2.png)](#co_data_format_context_CO1-2)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_data_format_context_CO1-2)'
- en: Using a loop to read a file might seem strange to a beginner, but it’s making
    the process explicit.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于初学者来说，使用循环读取文件可能看起来很奇怪，但这使过程更加明确。
- en: This example tells us that `pd.read_csv()` in `pandas` provides a more concise,
    convenient and intuitive way to import data. It is also less explicit than vanilla
    Python and not essential. `pd.read_csv()` is, in essence, a *convenience wrapper*
    of existing functionality — good for us!
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子告诉我们，`pandas`中的`pd.read_csv()`提供了一种更简洁、方便和直观的导入数据方式。它比纯粹的Python少了明确，也不是必需的。`pd.read_csv()`本质上是现有功能的*便利封装*
    —— 对我们很有帮助！
- en: Here we see that packages serve two functions. First, as we have come to expect,
    they provide *new* functionality. Second, they are also convenience wrappers for
    existing standard functions, which make our lives easier.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到包有两个功能。首先，正如我们所期望的那样，它们提供*新*的功能。其次，它们还是现有标准功能的便利封装，使我们的生活更轻松。
- en: This is brilliantly demonstrated in R’s `rio` package^([5](ch04.xhtml#idm45127451851368)).
    `rio` stands for “R input/output” and it does just was it says^([6](ch04.xhtml#idm45127451849368)).
    Here, the single function `import()` uses the file’s filename extension to select
    the best function in a collection of packages for importing. This works on Excel,
    SPSS, stata, SAS or many other formats commonly seen.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这在R的`rio`包中得到了很好的展示^([5](ch04.xhtml#idm45127451851368))。`rio`代表“R input/output”，它确实如其名称所示^([6](ch04.xhtml#idm45127451849368))。在这里，单个函数`import()`使用文件的文件名扩展名来选择在一系列包中导入的最佳函数。这适用于Excel、SPSS、stata、SAS或许多其他常见格式。
- en: Another R tidyverse package, `vroom` allows for fast import of tabular data,
    and can read an entire directory of files in one command, with the use of `map()`
    functions or `for loops`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个R tidyverse包`vroom`允许快速导入表格数据，并可以在一个命令中读取整个目录的文件，使用`map()`函数或`for loops`。
- en: Finally, the `data.table` package, which is often neglected at the expense of
    promoting the tidyverse, provides the exceptional `fread()` which can import very
    large files at a fraction of what base R or `readr` offer.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，经常被忽视以推广tidyverse为代价的`data.table`包提供了出色的`fread()`，它可以以远低于基础R或`readr`提供的速度导入非常大的文件。
- en: The usefulness of learning how to use a third-party packages becomes more apparent
    when we try to perform more complex tasks, as we’ll see next when processing other
    data formats.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 学习如何使用第三方包的实用性在我们尝试执行更复杂的任务时变得更加明显，正如我们下面在处理其他数据格式时将会看到。
- en: Now that we can appreciate the advantages of packages, we’ll demonstrate some
    of their capabilities. For this we’ll work on several different real-world use
    cases, listed in [Table 4-2](#case-study-table). We won’t focus on minute implementation
    details, but instead cover the elements that expose their benefits (and shortcomings)
    for the tasks at hand. Since the focus in this chapter is on data formats, and
    [Chapter 5](ch05.xhtml#ch06) is all about workflows, all these case studies are
    about data processing (as illustrated previously in [???](#pipelines_diff)).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们可以欣赏包的优势，我们将展示它们的一些功能。为此，我们将处理几个不同的真实用例，列在 [表 4-2](#case-study-table) 中。我们不会专注于细节实现，而是覆盖那些暴露它们在任务中优点（和缺点）的元素。由于本章重点是数据格式，而
    [第五章](ch05.xhtml#ch06) 则全面介绍工作流程，所有这些案例研究都涉及数据处理（如前面在 [???](#pipelines_diff) 中所示）。 '
- en: Note
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For pedagogic purposes we have omitted parts of the code. If you’d like to follow
    along, executable code is available in the [book repository](https://github.com/moderndatadesign/PyR4MDS).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了教学目的，我们省略了部分代码。如果您想跟着做，请查看 [书籍存储库](https://github.com/moderndatadesign/PyR4MDS)
    中的可执行代码。
- en: Table 4-2\. An overview of the different use-cases
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4-2\. 不同用例的概述
- en: '| Data format | Use case |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 数据格式 | 使用案例 |'
- en: '| --- | --- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| image | [Swimming pool and car Detection](https://www.kaggle.com/kbhartiya83/swimming-pool-and-car-detection)
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 图像 | [游泳池和汽车检测](https://www.kaggle.com/kbhartiya83/swimming-pool-and-car-detection)
    |'
- en: '| text | [Amazon Music reviews processing](http://jmcauley.ucsd.edu/data/amazon/)
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 文本 | [Amazon 音乐评论处理](http://jmcauley.ucsd.edu/data/amazon/) |'
- en: '| time series | [Daily Australian Temperatures](https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv)
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 时间序列 | [澳大利亚日温度](https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv)
    |'
- en: '| spatial | [*Loxodonta africana* species distribution data](https://www.gbif.org/)
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 空间 | [*Loxodonta africana* 物种分布数据](https://www.gbif.org/) |'
- en: Further information on how to download and process these data is available in
    the official [repository](https://github.com/moderndatadesign/PyR4MDS) for the
    book.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于如何下载和处理这些数据的信息可以在官方 [存储库](https://github.com/moderndatadesign/PyR4MDS) 中找到。
- en: Image data
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像数据
- en: Images pose a unique set of challenges for data scientists. We’ll demonstrate
    the optimal methodology by covering the challenge of aerial image processing -
    a domain of growing importance in agriculture, biodiversity conservation, urban
    planning and climate change research. Our mini use-case uses data from Kaggle,
    collected to help the detection of swimming pools and cars. For more information
    on the dataset, you can use the URL in [Table 4-2](#case-study-table).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据科学家来说，图像提出了一系列独特的挑战。我们将通过处理航空图像处理的挑战来演示最佳方法，这是农业、生物多样性保护、城市规划和气候变化研究日益重要的领域。我们的迷你用例使用了来自
    Kaggle 的数据，旨在帮助检测游泳池和汽车。有关数据集的更多信息，请使用 [表 4-2](#case-study-table) 中的网址。
- en: OpenCV and scikit-image
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenCV 和 scikit-image
- en: As we mentioned at the beginning of the chapter, downstream purpose influences
    data processing heavily. Since aerial data is often used to train machine learning
    algorithms, our focus will be on preparatory tasks.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章开头提到的，下游目的极大地影响数据处理。由于航空数据经常用于训练机器学习算法，我们的重点将放在准备性任务上。
- en: The [OpenCV](https://opencv.org/) package is one of the most common ways to
    work with image data in Python. It contains all the necessary tools for image
    loading, manipulation and storage. The “CV” in the name stands for Computer Vision
    - the field of machine learning that focuses on image data. Another handy tool
    that we’ll use is `scikit-image`. As its naming suggests, it’s very much related
    to [scikit-learn](https://scikit-learn.org/stable/)^([7](ch04.xhtml#idm45127451817912)).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[OpenCV](https://opencv.org/) 包是在 Python 中处理图像数据的最常见方法之一。它包含了加载、操作和存储图像所需的所有工具。名称中的
    “CV” 代表计算机视觉 - 这是专注于图像数据的机器学习领域。我们还将使用的另一个便捷工具是 `scikit-image`。正如其名称所示，它与 [scikit-learn](https://scikit-learn.org/stable/)^([7](ch04.xhtml#idm45127451817912))
    密切相关。'
- en: 'Here are the steps of our task (refer to [Table 4-2](#case-study-table)):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们任务的步骤（参见 [表 4-2](#case-study-table)）：
- en: Resize the image to a specific size
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整图像大小到特定尺寸
- en: Convert the image to black and white
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为黑白
- en: Augment the data by rotating the image
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过旋转图像增强数据
- en: For an ML algorithm to learn successfully from data, the input has to be cleaned
    (data munging), standardized (i.e., scaling) and filtered (feature engineering)^([8](ch04.xhtml#idm45127451810536)).
    You can imagine gathering a dataset of images (for example, by scraping^([9](ch04.xhtml#idm45127451809800))
    data from Google Images). They will differ in some way or another - such as size
    and/or color. Steps 1 and 2 in our task list help us deal with that. Step 3 is
    handy for ML applications. The performance (i.e., classification accuracy, or
    Area Under the Curve(AUC)) of ML algorithms depends mostly on the amount of training
    data, which is often in little supply. To get around this, without resorting to
    obtaining more data^([10](ch04.xhtml#idm45127451808600)), data scientists have
    discovered that playing around with the data already available, such as rotating
    and cropping, can introduce new data points. Those can then be used to train the
    model again and improve performance. This process is formally known as data augmentation^([11](ch04.xhtml#idm45127451807656)).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要使ML算法成功地从数据中学习，必须对输入进行清洗（数据整理），标准化（即缩放）和过滤（特征工程）^([8](ch04.xhtml#idm45127451810536))。你可以想象收集一组图像数据集（例如从Google图像中爬取^([9](ch04.xhtml#idm45127451809800))数据）。它们可能在大小和/或颜色等方面有所不同。我们任务列表中的步骤1和2帮助我们处理这些差异。第3步对ML应用非常有用。ML算法的性能（例如分类准确度或曲线下面积（AUC））主要取决于训练数据的数量，通常供应量有限。为了解决这个问题，而不是获取更多数据^([10](ch04.xhtml#idm45127451808600))，数据科学家发现，对已有数据进行操作，如旋转和裁剪，可以引入新的数据点。然后可以再次用这些数据点来训练模型并提高性能。这个过程正式称为数据增强^([11](ch04.xhtml#idm45127451807656))。
- en: Enough talk - let’s start by importing the data! Remember, if you want to follow
    along, check the complete code at the book’s [repository](https://github.com/moderndatadesign/PyR4MDS).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 足够的讨论 - 让我们从导入数据开始吧！如果你想跟着做，请检查本书的[代码仓库](https://github.com/moderndatadesign/PyR4MDS)。
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](Images/1.png)](#co_data_format_context_CO2-1)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_data_format_context_CO2-1)'
- en: Using `cv2` might seem confusing since the package is named `OpenCV.` `cv2`
    is used as a short-hand name. The same naming pattern is used for `scikit-image`,
    where the import statement is shortened to `skimage`.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`cv2`可能看起来令人困惑，因为包名为`OpenCV`。`cv2`被用作缩写名称。与`scikit-image`相同的命名模式，在导入语句中缩短为`skimage`。
- en: '![](Images/prds_0401.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0401.png)'
- en: Figure 4-1\. Raw image plot in Python with `matplotlib`.
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-1\. Python中使用`matplotlib`绘制的原始图像。
- en: 'So in what object type did `cv2` store the data? We can check with `type`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 那么`cv2`将数据存储在哪种对象类型中？我们可以用`type`来检查：
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here we can observe an important feature that already provides advantages to
    using Python for CV tasks as opposed to R. The image is directly stored as a `numpy`
    multidimensional array (`nd` stands for n-dimensions), making it accessible to
    a variety of other tools available in the wider Python ecosystem. Because this
    is built on the `pyData` stack, it’s well-supported. Is this true for R? Let’s
    have a look at the `magick` package:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以观察到一个重要的特性，它已经为使用Python进行CV任务相对于R提供了优势。图像直接存储为`numpy`多维数组（`nd`代表n维），使其可以访问Python生态系统中的各种其他工具。因为这是建立在`pyData`堆栈上的，所以得到了良好的支持。这对于R也适用吗？让我们看看`magick`包：
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `magick-image` class is only accessible to functions from the `magick` package,
    or other closely related tools, but not the powerful base R methods (such as the
    ones shown in [Chapter 2](ch02.xhtml#ch03), with the notable exception of `plot()`).
    Those different approaches in how various open source packages support each other
    is illustrated in [Figure 4-2](#package_design), and is a common thread throughout
    the examples in this chapter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`magick-image`类仅限于来自`magick`包或其他密切相关工具的函数使用，而不是强大的基础R方法（例如第2章中展示的方法，特别是`plot()`除外）。各种开源包之间如何支持彼此的不同方法在本章的示例中有所体现，如图4-2所示，是一个共同的主题。'
- en: Note
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There is at least one exception to this rule - the `EBImage` package, a part
    of [Bioconductor](https://bioconductor.org/). By using it you can get access to
    the image in its raw array form, and then use other tools on top of that. The
    drawback here is that it’s a part of a domain-specific package, and it might not
    be easy to see how it works in a standard CV pipeline.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 至少有一个例外情况符合这一规则 - `EBImage`包，它是[Bioconductor](https://bioconductor.org/)的一部分。通过使用它，您可以以原始数组形式访问图像，然后在此基础上使用其他工具。这里的缺点是它是一个特定领域的包的一部分，可能不容易在标准CV流水线中看到它是如何工作的。
- en: '![](Images/prds_0402.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0402.png)'
- en: Figure 4-2\. The two types of package design hierarchies as they are used during
    a data lifecycle (bottom to top). The left pattern shows a suboptimal structure,
    where users are forced to adopt and use purpose-specific tools at the first level
    which limits their flexibility and productivity. The pattern on the right shows
    a better structure, where there are standard tools for the initial phases of the
    data lineage, enabling a variety of tools downstream.
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-2\. 两种包设计层次结构，在数据生命周期中使用（从底部到顶部）。左侧模式显示了一个次优结构，用户被迫在第一级别使用特定目的的工具，这限制了他们的灵活性和生产力。右侧模式显示了一个更好的结构，在数据传递的初始阶段有标准工具，从而在下游能够使用多种工具。
- en: Note that in the previous step (where we loaded the raw image in Python), we
    also used one of the most popular plotting tool - `matplotlib` (data visualization
    is covered in [Chapter 5](ch05.xhtml#ch06)), so we again took advantage of this
    better design pattern.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在前一步骤中（加载Python中的原始图像时），我们还使用了最流行的绘图工具之一 - `matplotlib`（数据可视化在[第5章](ch05.xhtml#ch06)中有所涉及），因此我们再次利用了这种更好的设计模式。
- en: 'Now that we know that the image data is stored as a `numpy` `ndarray`, we can
    use `numpy`’s methods. What’s the size of the image? For this we can try the `.shape`
    method of `ndarray`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道图像数据存储为`numpy`的`ndarray`，我们可以使用`numpy`的方法。图像的尺寸是多少？我们可以尝试`ndarray`的`.shape`方法来获取：
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'It worked indeed! The first two output values correspond to the image `height`
    and `width` respectively, and the third one to the number of channels in the image
    - three in this case ((r)ed, (g)reen and (b)lue). Now let’s continue and deliver
    on the first standardization step - image resizing. Here we’ll use `cv2` for the
    first time:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 确实有效！前两个输出值分别对应于图像的`height`和`width`，第三个则是图像中的通道数 - 在这种情况下是三个 ((r)ed, (g)reen
    和 (b)lue)。现在让我们继续并完成第一步标准化 - 图像调整大小。在这里我们将第一次使用`cv2`：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you gain experience working with such fundamental tools in both languages,
    you’ll be able to test your ideas quickly, even without knowing whether those
    methods exist. If the tools you use are designed well (as in the better design
    in [Figure 4-2](#package_design)), often they will work as expected!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在两种语言中都有使用这些基础工具的经验，你将能够快速测试你的想法，即使不知道这些方法是否存在。如果你使用的工具设计良好（如[图4-2](#package_design)中的更好设计），通常它们会按预期工作！
- en: 'Perfect, it worked like a charm! The next step is to convert the image to black
    and white. For this, we’ll also use `cv2`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 完美，它的运行效果如同魔术一般！接下来的步骤是将图像转换为黑白。为此，我们同样会使用`cv2`：
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The colors are greenish and not grey. This default option chooses a color scheme
    that makes the contrast more easily discernible for a human eye than black and
    white. When you look at the shape of the `numpy` `ndarray` you can see that the
    channel number has disappeared - there is just one now. Now let’s complete our
    task and do a simple data augmentation step and flip the image horizontally. Here
    we’re again taking advantage that the data is stored as a `numpy` array. We’ll
    use a function directly from `numpy`, without relying on the other CV libraries
    (`OpenCV` or `scikit-image`):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色呈绿色调，而非灰色。默认选项选择了一种颜色方案，使得对人眼的对比更容易辨别，比黑白色更加明显。当你观察`numpy`的`ndarray`形状时，你会发现通道数已经消失了
    - 现在只剩下一个。现在让我们完成我们的任务，并进行简单的数据增强步骤，将图像水平翻转。在这里，我们再次利用数据存储为`numpy`数组的优势。我们将直接使用`numpy`中的一个函数，而不依赖于其他CV库（如`OpenCV`或`scikit-image`）：
- en: '[PRE8]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The results are shown on [Figure 4-3](#flipped_image).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在[图4-3](#flipped_image)中。
- en: '![](Images/prds_0403.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0403.png)'
- en: Figure 4-3\. Plot of an image flipped by using `numpy` functions.
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-3\. 使用`numpy`函数翻转图像的绘图。
- en: 'We can use `scikit-image` for further image manipulation tasks such as rotation,
    and even this different package will work as expected on our data format:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`scikit-image`进行更多的图像操作任务，比如旋转，即使使用这种不同的包也能按预期在我们的数据格式上工作：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The data standardization and augmentation steps we went through illustrate
    how the less complex package design ([Figure 4-2](#package_design)) makes us more
    productive. We can drive the point home by showing a negative example for the
    third step, this time in R. For that, we’ll have to rely on the `adimpro` package:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经历的数据标准化和增强步骤说明了较简单的包设计（[图4-2](#package_design)）如何提高我们的生产力。我们可以通过展示第三步的负面例子来进一步强调这一点，这次是在R语言中。为此，我们将依赖于`adimpro`包：
- en: '[PRE10]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Whenever we load yet another package, we are decreasing the quality, readability,
    and reusability of our code. This issue is primarily due to possible unknown bugs,
    a steeper learning curve, or a potential lack of consistent and thorough documentation
    for that third-party package. A quick check on the status of `adimpro` on [CRAN](https://cran.r-project.org/web/packages/adimpro/index.html)
    reveals that the last time it was updated was in November 2019^([12](ch04.xhtml#idm45127451457144)).
    This is why using tools such as `OpenCV`, which work on image data by taking advantage
    of the `PyData` stack^([13](ch04.xhtml#idm45127451455800)), such as `numpy` is
    preferred.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们加载另一个包时，都会降低我们代码的质量、可读性和可重用性。这个问题主要是由于可能存在未知的bug、更陡的学习曲线或第三方包缺乏一致和详尽的文档。通过快速检查[CRAN上的`adimpro`](https://cran.r-project.org/web/packages/adimpro/index.html)，可以发现它最后一次更新是在2019年11月^([12](ch04.xhtml#idm45127451457144))。这就是为什么更倾向于使用像`OpenCV`这样的工具，它利用`PyData`堆栈^([13](ch04.xhtml#idm45127451455800))处理图像数据，如`numpy`。
- en: A less complex, modular, and abstract enough package design goes a long way
    to make data scientists productive and happy in using their tools. They are then
    free to focus on actual work and not dealing with complex documentation or a multitude
    of abandonware packages. These considerations make Python the clear winner in
    importing and processing image data, but is this the case for the other formats?
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一个较少复杂、模块化且足够抽象的包设计可以大大提高数据科学家在使用工具时的生产力和满意度。他们可以自由专注于实际工作，而不是处理复杂的文档或大量弃用的包。这些考虑使得Python在导入和处理图像数据方面成为明显的优选，但对其他格式是否也是如此呢？
- en: Text data
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本数据
- en: The analysis of text data is often used interchangeably with the term Natural
    Language Processing (NLP). This, in turn, is a subfield of ML. Hence it’s not
    surprising to see that Python-based tools also dominate it. The inherently compute-intensive
    nature of working with text data is one good reason to why that’s the case. Another
    one is that dealing with larger datasets can be a more significant challenge in
    R^([14](ch04.xhtml#idm45127451424392)) then in Python (this topic is covered further
    in [Chapter 5](ch05.xhtml#ch06)). And it is a Big Data problem. The amount of
    text data has proliferated in recent years with the rise of services on the internet
    and social media giants such as Twitter and Facebook. Such organizations have
    also invested heavily in the technology and related open-source, due to the fact
    that a large chunk of data available to them is in text format.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 文本数据分析通常与自然语言处理（NLP）术语交替使用。这又是ML的一个子领域。因此，Python工具的主导地位并不奇怪。处理文本数据本质上需要大量计算资源，这也是为什么Python工具主导的一个很好的原因。另一个原因是，在R中处理更大的数据集可能比在Python中更具挑战性^([14](ch04.xhtml#idm45127451424392))（关于此主题的更多内容，请参阅[第5章](ch05.xhtml#ch06)）。这是一个大数据问题。随着互联网服务和Twitter、Facebook等社交媒体巨头的兴起，文本数据量近年来激增。这些组织也大力投资于相关技术和开源，因为他们可获取的大部分数据都是文本格式。
- en: 'Similarly to the image data case, we’ll start by designing a standard NLP task.
    It should contain the most fundamental elements of an NLP pipeline. For a dataset,
    we selected texts from the Amazon Product Reviews Dataset ([Table 4-2](#case-study-table)),
    and we have to prepare it for an advanced analytics use case, such as text classification,
    sentiment analysis, or topic modeling. The steps needed for completion are the
    following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 与图像数据类似，我们将设计一个标准的NLP任务。它应包含NLP流水线的最基本元素。作为数据集，我们选择了来自亚马逊产品评论数据集的文本（见[表4-2](#case-study-table)），并需准备用于文本分类、情感分析或主题建模等高级分析用例。完成所需的步骤如下：
- en: Tokenize the data
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对数据进行分词
- en: Remove stop-words
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 去除停用词
- en: Tag the Parts of Speech (PoS)
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标记词性（PoS）
- en: We’ll also go through more advanced methods (such as word embeddings) in `spaCy`
    to demonstrate what the Python packages are capable of, and at the same time,
    provide a few R examples for comparison.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将通过`spaCy`介绍更高级的方法（如词嵌入），以展示Python包的功能，并同时提供几个R示例以进行比较。
- en: NLTK and spaCy
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NLTK和spaCy
- en: So what are the most common tools in Python? The most popular one is often referred
    to as the swiss-army knife of NLP - the Natural Language Toolkit (NLTK)^([15](ch04.xhtml#idm45127451414392)).
    It contains a good selection of tools covering the whole pipeline. It also has
    excellent documentation and a relatively low learning curve for its API.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 Python 中最常用的工具是什么？最流行的工具之一通常被称为 NLP 的瑞士军刀 - 自然语言工具包（NLTK）^([15](ch04.xhtml#idm45127451414392))。它包含了涵盖整个流程的丰富工具集。它还具有出色的文档和相对较低的
    API 学习曲线。
- en: NLTK Book
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: NLTK 书籍
- en: The NLTK authors have also written one of the most accessible books on working
    with text data - the NLTK Book, currently in version 3\. It’s available to read
    online for free [on the official website](https://www.nltk.org/book/). It can
    serve as an excellent reference manual, so if you want to dive deeper into some
    of the topics we cover in this section, go ahead and have a look!
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK 的作者们还写了一本关于文本数据处理最易于理解的书籍 - NLTK 书籍，当前版本为3\. 它可以免费在线阅读，网址在[官方网站](https://www.nltk.org/book/)。这可以作为一个很好的参考手册，如果你想深入了解我们在本节中涵盖的一些主题，请随时查阅！
- en: 'As a data scientist, one of the first steps in a project is to look at the
    raw data. Here’s one example review, along with its data type:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名数据科学家，在项目中的第一步之一是查看原始数据。这里是一个示例评论及其数据类型：
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This here is important - the data is stored in a fundamental data type in Python
    - `str` (string). Similar to the image data being stored as a multidimensional
    `numpy` array, many other tools can have access to it. For example, suppose we
    were to use a tool that efficiently searches and replaces parts of a string, such
    as [flashtext](https://github.com/vi3k6i5/flashtext). In that case, we’d be able
    to use it here without formatting issues, and the need to coerce^([16](ch04.xhtml#idm45127451365400))
    the data type.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这里很重要 - 数据存储在 Python 中的一个基本数据类型中 - `str`（字符串）。类似于将图像数据存储为多维`numpy`数组，许多其他工具也可以访问它。例如，假设我们要使用一种能够高效搜索和替换字符串部分的工具，比如[flashtext](https://github.com/vi3k6i5/flashtext)。在这种情况下，我们可以在这里使用它而不会出现格式问题，也无需强制转换^([16](ch04.xhtml#idm45127451365400))数据类型。
- en: 'Now we can take the first step in our mini case study - *tokenization*. It
    will split the reviews into components, such as words or sentences:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在我们的迷你案例研究中迈出第一步 - *分词*。它将评论分割成词或句子等组件：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Easy enough! For illustration purposes, would it be that hard to attempt this
    relatively simple task in R, with some functions from `tidytext`?
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 足够简单！为了举例说明，在 R 中使用一些来自`tidytext`的函数尝试这个相对简单的任务会有多困难？
- en: '[PRE15]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This is one of the most well-documented methods to use. One issue with this
    is that it relies heavily on the “tidy data” concept, and also on the pipeline
    chaining concept from `dplyr` (we covered both in [Chapter 2](ch02.xhtml#ch03)).
    These concepts are specific to R, and to use `tidytext` successfully, you would
    have to learn them first, instead of directly jumping to processing your data.
    The second issue is the output of this procedure - a new `data.frame` containing
    the data in a processed column. While this might be what we need in the end, this
    skips a few intermediate steps and is several layers of abstraction higher than
    what we did with `nltk`. Lowering this abstraction and working in a more modular
    fashion (such as processing a single text field first) adheres to software development
    best practices, such as DRY (“Do not repeat yourself”) and separation of concerns.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用的最详细记录方法之一。其中一个问题是它过于依赖“整洁数据”概念，以及`dplyr`中的管道连接概念（我们在[第2章](ch02.xhtml#ch03)中涵盖了这两个概念）。这些概念特定于
    R 语言，如果要成功使用`tidytext`，首先必须学习它们，而不能直接开始处理数据。第二个问题是此过程的输出 - 包含处理列中数据的新`data.frame`。虽然这可能是最终所需的内容，但它跳过了一些中间步骤，比我们使用`nltk`时的抽象层级要高几层。降低这种抽象并以更模块化的方式工作（例如首先处理单个文本字段）符合软件开发的最佳实践，如
    DRY（“不要重复自己”）和关注点分离。
- en: The second step of our small NLP data processing pipeline is removing stop words^([17](ch04.xhtml#idm45127451276088)).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们小型 NLP 数据处理流水线的第二步是移除停用词^([17](ch04.xhtml#idm45127451276088))。
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This code suffers from the same issues, along with a new confusing function
    - `anti_join`. Let’s compare to the simple list comprehension (more information
    on this in [Chapter 3](ch03.xhtml#ch04)) step in `nltk`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码存在与之前相同的问题，还有一个新的令人困惑的函数 - `anti_join`。让我们来比较一下简单的列表推导（更多信息见[第3章](ch03.xhtml#ch04)中的`nltk`步骤）：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`english_stop_words` is just a `list,` and then the only thing we do is loop
    through every word in another `list` (`words`) and remove it *if* it’s present
    in both. This is easier to understand. There’s no relying on advanced concepts
    or functions that are not directly related. This code is also at the right level
    of abstraction. Small code chunks can be used more flexibly as parts of a larger
    text processing pipeline function. A similar “meta” processing function in R can
    become bloated - slow to execute and hard to read.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`english_stop_words`只是一个`list`，然后我们只需循环遍历另一个`list`（`words`）中的每个单词，并删除*如果*它同时存在于两者中。这更易于理解。没有依赖于与直接相关的高级概念或函数。这段代码也处于正确的抽象级别。小代码块可以更灵活地作为更大文本处理管道函数的一部分使用。在R中，类似的“元”处理函数可能会变得臃肿
    - 执行缓慢且难以阅读。'
- en: While `nltk` allows for such fundamental tasks, we’ll now have a look at a more
    advanced package - `spaCy`. We’ll use this for the third and final step in our
    case study - Part of Speech (PoS) tagging^([18](ch04.xhtml#idm45127451178120)).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`nltk`可以执行这些基本任务，但现在我们将看一看更高级的包 - `spaCy`。在我们的案例研究的第三和最后一步中，我们将使用它进行词性标注（Part
    of Speech，PoS）^([18](ch04.xhtml#idm45127451178120))。
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[![1](Images/1.png)](#co_data_format_context_CO3-1)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_data_format_context_CO3-1)'
- en: Here we are loading all the advanced functionality we need through one function.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通过一个函数加载所有我们需要的高级功能。
- en: '[![2](Images/2.png)](#co_data_format_context_CO3-2)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_data_format_context_CO3-2)'
- en: 'We take one example review and feed it to a `spaCy` model, resulting in the
    `spacy.tokens.doc.Doc` type, not a `str`. This object can then be used for all
    kinds of other operations:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们取一条示例评论并将其提供给`spaCy`模型，结果是`spacy.tokens.doc.Doc`类型，而不是`str`。然后可以对该对象进行各种其他操作：
- en: '[PRE20]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The data is already tokenized on loading. Not only that - all the PoS tags are
    marked already!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 数据在加载时已经进行了标记。不仅如此 - 所有的词性标注也已经完成了！
- en: 'The data processing steps that we covered are relatively basic. How about some
    newer and more advanced NLP methods? We can take word embeddings for example.
    This is one of the more advanced text vectorization^([19](ch04.xhtml#idm45127451081640))
    methods, where each vector represents the meaning of a word based on its context.
    For that, we can already use the same `nlp` object from the `spaCy` code:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所涉及的数据处理步骤相对基础。那么，再来看看一些更新、更高级的自然语言处理方法呢？例如，我们可以考虑词嵌入。这是更高级的文本向量化方法之一，其中每个向量表示一个词在其上下文中的含义^([19](ch04.xhtml#idm45127451081640))。为此，我们可以直接使用来自`spaCy`代码的同一个`nlp`对象：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: It’s a welcome surprise to see that those abilities are already built-in into
    one of the most popular Python NLP packages. On this level of NLP methods, we
    can see that there’s almost no alternative available in R (or even other languages
    for that matter). Many analogous solutions in R rely on wrapper code around a
    Python backend (which can defeat the purpose of using the R language)^([20](ch04.xhtml#idm45127451027384)).
    This pattern is often seen in the book, especially in [Chapter 5](ch05.xhtml#ch06).
    The same is also true for some other advanced methods such as transformer models^([21](ch04.xhtml#idm45127451025304)).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 看到这些功能已经内置在其中一款最受欢迎的Python自然语言处理包中真是个惊喜。在这个自然语言处理方法的水平上，我们几乎看不到R（或其他语言）的任何替代方案。许多在R中类似的解决方案依赖于围绕Python后端的包装代码（这可能违背使用R语言的初衷）^([20](ch04.xhtml#idm45127451027384))。这种模式在书中经常见到，特别是在[第5章](ch05.xhtml#ch06)。对于一些其他高级方法，如变换器模型，也是如此^([21](ch04.xhtml#idm45127451025304))。
- en: For round two Python is again the winner. The capabilities of `nltk`, `spaCy`
    and other associated packages make it an excellent choice for NLP work!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二轮来说，Python 再次胜出。`nltk`、`spaCy`以及其他相关包的能力使其成为进行自然语言处理工作的优秀选择！
- en: Time series data
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间序列数据
- en: The time-series format is used to store any data with an associated temporal
    dimension. It could be as simple as shampoo sales from a local grocery store,
    with a timestamp, or millions of data points from a sensor network measuring humidity
    in an agricultural field.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列格式用于存储具有时间维度的任何数据。它可以是简单的本地杂货店洗发水销售数据，带有时间戳，也可以是从农业领域湿度传感器网络中测量的数百万数据点。
- en: Note
  id: totrans-142
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There are some exceptions to the domination of R for the analysis of time-series
    data. The recent developments in deep learning methods, in particular, Long Short
    Term Memory networks (LSTM) have proved to be very successful for time series
    prediction. As is the case for other deep learning methods (more on this in [Chapter 5](ch05.xhtml#ch06)),
    this is an area better supported by Python tools.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: R在时间序列数据分析中的统治地位也有一些例外情况。特别是，最近深度学习方法的发展，尤其是长短期记忆网络（LSTM），已被证明在时间序列预测方面非常成功。就像其他深度学习方法一样（详见[第五章](ch05.xhtml#ch06)），这是一个更好地由Python工具支持的领域。
- en: Base R
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Base R
- en: There are quite a few different packages that an R user can use to analyze time-series
    data, including `xts`, and `zoo`, but we’ll be focusing on base R functions as
    a start. After this, we’ll have a look at one more modern package to illustrate
    more advanced functionality - [Facebook’s Prophet](https://facebook.github.io/prophet/).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: R用户可以使用相当多的不同包来分析时间序列数据，包括`xts`和`zoo`，但我们将以base R函数为起点。在此之后，我们将看一看一个更现代的包，以说明更高级的功能
    - [Facebook的Prophet](https://facebook.github.io/prophet/)。
- en: 'Weather data is both widely available and relatively easy to interpret, so
    for our case study, we’ll analyze the daily minimum temperature in Australia ([Table 4-2](#case-study-table)).
    To do a time series analysis, we need to go through the following steps:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 天气数据既易获取又相对容易解释，因此在我们的案例研究中，我们将分析澳大利亚的每日最低温度（详见[表4-2](#case-study-table)）。要进行时间序列分析，我们需要执行以下步骤：
- en: Load the data into an appropriate format
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据加载到适当的格式中
- en: Plot the data
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制数据
- en: Remove noise and seasonal effects and extract trend
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 去除噪声和季节性影响并提取趋势
- en: Then we would be able to proceed with more advanced analysis. Imagine we have
    loaded the data from a `.csv` file into a `data.frame` object in R. Nothing out
    of the ordinary here. Still, differently from most Python packages, R requires
    data coercion into a specific object type. In this case, we need to transform
    the `data.frame` into a `ts` (which stands for time series).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们就能进行更高级的分析了。假设我们已经将数据从`.csv`文件加载到R中的`data.frame`对象中。这里没有什么特别之处。然而，与大多数Python包不同，R需要将数据强制转换为特定的对象类型。在这种情况下，我们需要将`data.frame`转换为`ts`（代表时间序列）。
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: So why would we prefer that to `pandas`? Well, even after you manage to convert
    the raw data into a time series `pd.DataFrame`, you’ll encounter a new concept
    - `DataFrame` indexing (see [Figure 4-4](#ts_index)). To be efficient in data
    munging, you’ll need to understand how this works first!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么我们要选择它而不是`pandas`呢？嗯，即使你成功地将原始数据转换为时间序列`pd.DataFrame`，你还会遇到一个新概念 - `DataFrame`索引（见[图4-4](#ts_index)）。要高效地进行数据操作，你需要先了解这是如何工作的！
- en: '![](Images/prds_0404.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0404.png)'
- en: Figure 4-4\. The time series index in `pandas`.
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-4\. `pandas`中的时间序列索引。
- en: 'This indexing concept can be confusing, so let’s now look at what the alternative
    is in R and whether that’s better. With the `df_ts` time series object, there
    are already a few useful things we can do. It’s also a good starting point when
    you are working with more advanced time series packages in R, since the coercion
    of a `ts` object into `xts` or `zoo`, should throw no errors (this once again
    is an example of the good object design we covered in [Figure 4-2](#package_design)).
    The first thing you can try to do is `plot` the object, which often yields good
    results in R:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个索引概念可能会让人感到困惑，所以现在让我们看看R中的替代方法以及是否更好。使用`df_ts`时间序列对象，我们已经可以做一些有用的事情。当你在R中使用更高级的时间序列包时，这也是一个很好的起点，因为将`ts`对象转换为`xts`或`zoo`应该不会出错（这再次是我们在[图4-2](#package_design)中讨论的良好对象设计的一个例子）。你可以尝试做的第一件事是对对象进行`plot`，这在R中通常会产生良好的结果：
- en: '[PRE24]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Note
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Calling the `plot` function does not simply use a standard function that can
    plot all kinds of different objects in R (this is what you would expect). It calls
    a particular method that is associated with the data object (more on the difference
    between functions and methods is available in [Chapter 2](ch02.xhtml#ch03)). A
    lot of complexity is hidden behind this simple function call!
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`plot`函数并不仅仅是使用一个标准函数，可以在R中绘制各种不同的对象（这是你所期望的）。它调用与数据对象关联的特定方法（关于函数和方法之间的区别的更多信息，请参阅[第二章](ch02.xhtml#ch03)）。这个简单函数调用背后隐藏了很多复杂性！
- en: '![](Images/prds_0405.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0405.png)'
- en: Figure 4-5\. Plot of a time-series (`ts`) object in base R.
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-5\. 在base R中绘制时间序列（`ts`）对象。
- en: 'The results from `plot(df_ts)` on [Figure 4-5](#ts_plot) are already useful.
    The dates on the x-axis are recognized, and a `line` plot is chosen instead of
    the default `points` Plot. The most prevalent issue in analyzing time-series data
    (and most ML data for that matter) is dealing with noise. The difference between
    this data format and others is that there are a few different noise sources, and
    different patterns can be cleaned. This is achieved by a technique called decomposition,
    for which we have the built-in and well-named function `decompose`:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图 4-5](#ts_plot) 上的 `plot(df_ts)` 结果已经很有用。x 轴上的日期被识别，并选择了 `line` 绘图，而不是默认的
    `points` 绘图。分析时间序列数据（以及大多数机器学习数据）中最普遍的问题是处理噪声。与其他数据格式的不同之处在于存在几种不同的噪声来源，可以清除不同的模式。这是通过一种称为分解的技术实现的，我们有内置且命名良好的函数
    `decompose` 来完成这一点：
- en: '[PRE25]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The results can be seen on [Figure 4-6](#ts_decompose).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可以在 [图 4-6](#ts_decompose) 上看到。
- en: '![](Images/prds_0406.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0406.png)'
- en: Figure 4-6\. Plot of decomposed time-series in base R.
  id: totrans-165
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-6\. 在基本 R 中绘制的分解时间序列图。
- en: We can see what the random noise is and also what is a seasonal and overall
    pattern. We achieved all this with just one function call in base R! In Python,
    we would need to use the `statsmodels` package to achieve the same.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看出随机噪声和季节性以及总体模式是什么。我们只需在基本 R 中进行一次函数调用就实现了所有这些！在 Python 中，我们需要使用 `statsmodels`
    包来达到同样的效果。
- en: prophet
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: prophet
- en: 'For analyzing time-series data, we also have another exciting package example.
    It’s simultaneously developed for both R and Python (similar to the `lime` explainable
    ML tool) - [Facebook Prophet](https://facebook.github.io/prophet/). This example
    can help us compare the differences in API design. `prophet` is a package whose
    main strength lies in the flexibility for a domain user to adjust to their particular
    need, ease of use of the API, and focus on production readiness. These factors
    make it a good choice for prototyping time series work and using it in a data
    product. Let’s have a look; our data is stored as a `pandas` `DataFrame` in `df`:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分析时间序列数据，我们还有另一个令人兴奋的包例子。它同时为 R 和 Python 开发（类似于 `lime` 可解释的 ML 工具） - [Facebook
    Prophet](https://facebook.github.io/prophet/)。这个例子可以帮助我们比较 API 设计上的差异。`prophet`
    是一个主要优势在于领域用户能够根据其特定需求进行调整，API 使用便捷且专注于生产就绪的包。这些因素使其成为原型化时间序列工作和在数据产品中使用的不错选择。让我们来看看；我们的数据存储为
    `pandas` 的 `DataFrame` 在 `df` 中：
- en: '[PRE26]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[![1](Images/1.png)](#co_data_format_context_CO4-1)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_data_format_context_CO4-1)'
- en: Here we see the same `fit` API pattern again, borrowed from `scikit-learn`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们再次看到相同的 `fit` API 模式，借鉴自 `scikit-learn`。
- en: '[![2](Images/2.png)](#co_data_format_context_CO4-2)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_data_format_context_CO4-2)'
- en: This step creates a new empty `Data.Frame` that stores our predictions later.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步创建了一个新的空的 `Data.Frame`，以便稍后存储我们的预测结果。
- en: '[PRE27]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Both are simple enough and contain the same amount of steps - this is an excellent
    example of a consistent API design (more on this in [Chapter 5](ch05.xhtml#ch06)).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 两者都足够简单，并包含相同数量的步骤 - 这是一致的 API 设计的一个很好的例子（在 [第 5 章](ch05.xhtml#ch06) 中详细讨论）。
- en: Note
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: It’s an interesting and helpful idea to offer a consistent user experience across
    languages, but we do not predict it’ll be widely implemented. Few organizations
    possess the resources to do such work, which can be limiting since compromises
    have to be made in software design choices.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 提供跨语言一致的用户体验是一个有趣且有帮助的想法，但我们预计它不会被广泛实现。很少有组织拥有进行这种工作的资源，这可能限制选择软件设计的折衷。
- en: At this point, you can appreciate that knowing both languages would give you
    a significant advantage in daily work. If you were exposed only to the Python
    package ecosystem, you would probably try to find similar tools for analyzing
    time-series and missing out on the incredible opportunities that base R and related
    R packages provide.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您可以感受到同时掌握两种语言将为您的日常工作带来重大优势。如果您只接触过 Python 包生态系统，您可能会尝试寻找类似的工具来分析时间序列，从而错失基本
    R 和相关 R 包提供的令人难以置信的机会。
- en: Spatial data
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 空间数据
- en: The analysis of spatial data is one of the most promising areas in modern machine
    learning and has a rich history. New tools have been developed in recent years,
    but R has had the upper hand for a long time, despite some recent Python advances.
    As in the previous sections, we’ll look at a practical example to see the packages
    in action.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 空间数据分析是现代机器学习中最有前景的领域之一，并且具有丰富的历史。近年来已开发出新工具，但长期以来 R 一直占据优势，尽管 Python 近年来也有了一些进展。与之前的部分一样，我们将通过一个实际例子来看看这些包是如何运作的。
- en: Note
  id: totrans-181
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: There are several formats of spatial data available. In this subsection, we
    are focusing on the analysis of *raster* data. For other formats there are some
    interesting tools available in Python, such as [GeoPandas](https://geopandas.org/),
    but this is out of scope for this chapter.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 空间数据有几种格式可用。在本小节中，我们专注于对*raster*数据的分析。对于其他格式，在Python中有一些有趣的工具可用，比如[GeoPandas](https://geopandas.org/)，但这超出了本章的范围。
- en: 'Our task is to process occurrence^([22](ch04.xhtml#idm45127450735128)) and
    environmental data for *Loxodonta africana* (African elephant) make it suitable
    for spatial predictions. Such data processing is typical in Species Distribution
    Modeling (SDM), where the predictions are used to construct habitat suitability
    maps used for conservation. This case study is more advanced than the previous
    ones, and a lot of the steps hide some complexity where the packages are doing
    the heavy lifting. The steps are as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务是处理*Loxodonta africana*（非洲象）的出现数据^([22](ch04.xhtml#idm45127450735128))和环境数据，使其适用于空间预测。这种数据处理在物种分布建模（SDM）中很典型，其中预测用于构建用于保护的栖息地适宜性地图。这个案例研究比之前的更复杂，并且许多步骤中隐藏了一些复杂性，包装程序正在进行大量的操作。步骤如下：
- en: Obtain environmental raster data
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取环境栅格数据
- en: Cut the raster to fit the area of interest
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 裁剪栅格以适应感兴趣的区域
- en: Deal with spatial autocorrelation with sampling methods
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用抽样方法处理空间自相关
- en: raster
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 栅格
- en: To solve this problem as a first step, we need to process raster data^([23](ch04.xhtml#idm45127450728616)).
    This is, in a way, very similar to standard image data, but still different in
    processing steps. For this R has the excellent `raster` package available (the
    alternative is Python’s `gdal` and R’s `rgdal`, which in our opinion, are trickier
    to use).
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题的第一步，我们需要处理栅格数据^([23](ch04.xhtml#idm45127450728616))。从某种意义上说，这与标准图像数据非常相似，但在处理步骤上仍然有所不同。对此，R语言有出色的`raster`包可用（另一种选择是Python的`gdal`和R的`rgdal`，但在我们看来更难使用）。
- en: '[PRE28]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '`raster` allows us to download most of the common useful spatial environmental
    datasets, including the bioclimactic data^([24](ch04.xhtml#idm45127450683720)).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`raster`允许我们下载大多数常见的有用的空间环境数据集，包括生物气候数据^([24](ch04.xhtml#idm45127450683720))。'
- en: '[PRE29]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Here we use the handy `extent` function to crop (cut) the raster data - we are
    only interested in a subsection of all those environmental layers surrounding
    the occurrence data. Here we use the longitude and latitude coordinates to draw
    this rectangle. As a next step, to have a classification problem, we are randomly
    sampling data points from the raster data (those are called “pseudo absences).
    You could imagine that those are the `0`’s in our classification task, and the
    occurrences (observations) are the `1`’s - the target variable. We then convert
    the pseudo-absences to `spatial points`, and finally extract the climate data
    for them as well. In the `SpatialPoints` function, you can also see how we specify
    the geographic projection system, one of the fundamental concepts when analyzing
    spatial data.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们使用便捷的`extent`函数来裁剪（切割）栅格数据 - 我们只对围绕出现数据的所有环境层的一个子集感兴趣。在这里，我们使用经度和纬度坐标来绘制这个矩形。作为下一步，为了形成一个分类问题，我们从栅格数据中随机抽样数据点（这些被称为“伪缺失”）。你可以想象这些是我们分类任务中的`0`，而出现（观测）则是`1`
    - 目标变量。然后我们将伪缺失转换为`空间点`，最后也提取它们的气候数据。在`SpatialPoints`函数中，你还可以看到我们如何指定地理投影系统，这是分析空间数据时的基本概念之一。
- en: 'One of the most common issues when working in ML is correlations within the
    data. The fundamental assumption for a correct dataset is that the individual
    observations in the data are *independent* of each other to get accurate statistical
    results. This issue is always present in spatial data due to its very nature.
    This issue is called *spatial autocorrelation*. There are several packages available
    for sampling from the data to mitigate this risk to deal with this. One such package
    is `ENMeval`:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行ML工作时，最常见的问题之一是数据内的相关性。正确数据集的基本假设是数据中的个体观察结果彼此*独立*，以获得准确的统计结果。由于其本质的原因，空间数据始终存在这个问题。这个问题被称为*空间自相关*。有几个可用于从数据中抽样以减轻这一风险的包。其中一个这样的包是`ENMeval`：
- en: '[PRE30]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The `get.checkerboard1` function samples the data in an evenly distributed manner,
    similar to taking equal points from each square from a black and white chessboard.
    We can then take this resampled data and successfully train an ML model without
    worrying about spatial autocorrelation. As a final step, we can take those predictions
    and create the habitat suitability map, shown on ([???](#sdm_map)).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`get.checkerboard1`函数以均匀分布的方式对数据进行采样，类似于从黑白棋盘的每个方块中取等量的点。然后，我们可以使用这些重新采样的数据成功训练
    ML 模型，而不必担心空间自相关。最后一步，我们可以取得这些预测并创建生境适宜性地图，显示在（[???](#sdm_map)）。'
- en: '[PRE31]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Plot of a `raster` object prediction in R, resulting in a habitat suitability
    map. image::img/sdm_map.png[""]
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 R 中绘制`raster`对象预测，生成生境适宜性地图。image::img/sdm_map.png[""]
- en: When you’re working with spatial raster data, the better package design is provided
    by R. The fundamental tools such as `raster` provide a consistent foundation for
    more advanced application specific ones such as `ENMeval` and `dismo`, without
    the need to worry about complex transformation or error-prone type coercion.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 当您处理空间栅格数据时，R 提供了更好的包设计。像`raster`这样的基础工具为更高级的特定应用程序（如`ENMeval`和`dismo`）提供了一致的基础，而无需担心复杂的转换或易出错的类型强制转换。
- en: Final thoughts
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最终思考
- en: In this chapter we went through the different common data formats, and what
    are the best packages to process them so they are ready for advanced tasks. In
    each case study, we demonstrated a good package design and how that can make a
    data scientist more productive. We have seen that for more ML-focused tasks, such
    as CV and NLP, Python is providing the better user experience and lower learning
    curve. In contrast, for more time series prediction and spatial analysis, R has
    the upper hand. Those selection choices are shown on [Figure 4-7](#decision_tree).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们详细介绍了不同的常见数据格式，以及处理它们准备进行高级任务的最佳包。在每个案例研究中，我们展示了一个良好的包设计如何使数据科学家更加高效。我们已经看到，对于更多以
    ML 为重点的任务，如 CV 和 NLP，Python 提供了更好的用户体验和更低的学习曲线。相比之下，对于时间序列预测和空间分析，R 则占据了上风。这些选择在[图 4-7](#decision_tree)中显示。
- en: '![](Images/prds_0407.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/prds_0407.png)'
- en: Figure 4-7\. Decision tree for package selection.
  id: totrans-202
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-7\. 包选择的决策树。
- en: What the best tools have in common is the better package design ([Figure 4-2](#package_design)).
    You should always use the optimal tool for the job and pay attention to the complexity,
    documentation, and performance of the tools you use!
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳工具的共同之处在于更好的包设计（[图 4-2](#package_design)）。您应该始终使用最适合工作的工具，并注意您使用的工具的复杂性、文档和性能！
- en: '^([1](ch04.xhtml#idm45127452048648-marker)) For a more thorough explanation
    on this have a look here: [*https://realpython.com/python-encodings-guide/*](https://realpython.com/python-encodings-guide/).'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch04.xhtml#idm45127452048648-marker)) 欲了解更详细的解释，请查看此处：[*https://realpython.com/python-encodings-guide/*](https://realpython.com/python-encodings-guide/)。
- en: ^([2](ch04.xhtml#idm45127452046808-marker)) This is commonly referred to as
    “data lineage”.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch04.xhtml#idm45127452046808-marker)) 这通常被称为“数据血统”。
- en: ^([3](ch04.xhtml#idm45127452007560-marker)) Who else didn’t learn what `if __name__
    == "__main__"` does in Python?
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch04.xhtml#idm45127452007560-marker)) 还有谁没有学会在 Python 中`if __name__ ==
    "__main__"`是做什么的？
- en: ^([4](ch04.xhtml#idm45127452002248-marker)) One table from the data, stored
    in a single file.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch04.xhtml#idm45127452002248-marker)) 数据中的一个表，存储在一个文件中。
- en: ^([5](ch04.xhtml#idm45127451851368-marker)) Not to forget `tidyr`, which was
    discussed in [Chapter 2](ch02.xhtml#ch03)
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch04.xhtml#idm45127451851368-marker)) 别忘了`tidyr`，它在[第二章](ch02.xhtml#ch03)中已经讨论过了。
- en: ^([6](ch04.xhtml#idm45127451849368-marker)) We did mention that statisticians
    are very literal, right?
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch04.xhtml#idm45127451849368-marker)) 我们确实提到统计学家非常字面吧？
- en: ^([7](ch04.xhtml#idm45127451817912-marker)) This consistency is a common thread
    in the chapters in [Part III](part03.xhtml#p03) and is addressed additionally
    in [Chapter 5](ch05.xhtml#ch06).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch04.xhtml#idm45127451817912-marker)) 这种一致性是第三部分的各章节中的共同主题，并在[第五章](ch05.xhtml#ch06)中另外讨论。
- en: ^([8](ch04.xhtml#idm45127451810536-marker)) Remember - garbage in, garbage out.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch04.xhtml#idm45127451810536-marker)) 记住 - 输入垃圾，输出垃圾。
- en: ^([9](ch04.xhtml#idm45127451809800-marker)) Using code to go through the content
    of a web page, download and store it in a machine-readable format.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch04.xhtml#idm45127451809800-marker)) 使用代码浏览网页内容，下载并以机器可读格式存储。
- en: ^([10](ch04.xhtml#idm45127451808600-marker)) Which can be expensive, or even
    impossible in some cases.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch04.xhtml#idm45127451808600-marker)) 这在某些情况下可能是昂贵的，甚至是不可能的。
- en: ^([11](ch04.xhtml#idm45127451807656-marker)) If you want to learn more on data
    augmentation of images have a look at [this](https://www.tensorflow.org/tutorials/images/data_augmentation)
    tutorial.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch04.xhtml#idm45127451807656-marker)) 如果你想了解更多关于图像数据增强的信息，请查看[此教程](https://www.tensorflow.org/tutorials/images/data_augmentation)。
- en: ^([12](ch04.xhtml#idm45127451457144-marker)) At the time of writing.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch04.xhtml#idm45127451457144-marker)) 在撰写时。
- en: ^([13](ch04.xhtml#idm45127451455800-marker)) Not to be confused with the conference
    of the same name, the PyData stack refers to `NumPy`, `SciPy`, `Pandas`, `IPython`
    and `matplotlib`.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch04.xhtml#idm45127451455800-marker)) 不要与同名会议混淆，PyData堆栈指的是`NumPy`、`SciPy`、`Pandas`、`IPython`和`matplotlib`。
- en: ^([14](ch04.xhtml#idm45127451424392-marker)) The R community has also rallied
    to the call and improved the tooling in recent times, but it still arguably lags
    behind its Python counterparts.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch04.xhtml#idm45127451424392-marker)) R社区也响应了这一号召，并在最近改进了工具链，但与其Python对应部分相比仍有一定差距。
- en: ^([15](ch04.xhtml#idm45127451414392-marker)) To learn more about NLTK have a
    look at the official book available [here](https://www.nltk.org/book/).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch04.xhtml#idm45127451414392-marker)) 欲了解更多关于NLTK的信息，请查阅官方书籍，链接在[这里](https://www.nltk.org/book/)。
- en: ^([16](ch04.xhtml#idm45127451365400-marker)) Data type coercion is the conversion
    of one data type to another.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch04.xhtml#idm45127451365400-marker)) 数据类型强制转换是将一个数据类型转换为另一个的过程。
- en: ^([17](ch04.xhtml#idm45127451276088-marker)) This is a common step in NLP. Some
    examples of stop words are “the”, “a” and “this”. These need to be removed since
    they rarely offer useful information for ML algorithms.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch04.xhtml#idm45127451276088-marker)) 这是自然语言处理中的常见步骤。一些停用词的例子包括“the”、“a”和“this”。这些词需要移除，因为它们很少提供有用的信息给机器学习算法。
- en: ^([18](ch04.xhtml#idm45127451178120-marker)) The process of labeling words in
    with the PoS they belong to.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch04.xhtml#idm45127451178120-marker)) 将词语标记为它们所属的词性的过程。
- en: ^([19](ch04.xhtml#idm45127451081640-marker)) Converting text into numbers for
    ingestion by a ML algorithm.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch04.xhtml#idm45127451081640-marker)) 将文本转换为数字，以便机器学习算法处理。
- en: ^([20](ch04.xhtml#idm45127451027384-marker)) Such as trying to create custom
    embeddings. Check the RStudio blog [here](https://blogs.rstudio.com/ai/posts/2017-12-22-word-embeddings-with-keras/)
    for more information.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch04.xhtml#idm45127451027384-marker)) 例如尝试创建自定义嵌入。更多信息请查阅RStudio博客，链接在[这里](https://blogs.rstudio.com/ai/posts/2017-12-22-word-embeddings-with-keras/)。
- en: ^([21](ch04.xhtml#idm45127451025304-marker)) You can read more about that [here](https://blogs.rstudio.com/ai/posts/2020-07-30-state-of-the-art-nlp-models-from-r/).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch04.xhtml#idm45127451025304-marker)) 您可以在[这里](https://blogs.rstudio.com/ai/posts/2020-07-30-state-of-the-art-nlp-models-from-r/)阅读更多相关信息。
- en: ^([22](ch04.xhtml#idm45127450735128-marker)) Location-tagged observations of
    the animal in the wild.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch04.xhtml#idm45127450735128-marker)) 在野外记录的动物位置标记观测。
- en: ^([23](ch04.xhtml#idm45127450728616-marker)) Data representing cells, where
    the cell value represents some information.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch04.xhtml#idm45127450728616-marker)) 表示单元格的数据，其中单元格值代表某些信息。
- en: ^([24](ch04.xhtml#idm45127450683720-marker)) Environmental features that have
    been determined by ecologists to be highly predictive of species distributions,
    i.e. humidity and temperature.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch04.xhtml#idm45127450683720-marker)) 生态学家确定的高度预测物种分布的环境特征，例如湿度和温度。
