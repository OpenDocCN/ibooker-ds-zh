- en: 4 Automated generation of end-to-end ML solutions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 自动生成端到端ML解决方案
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节涵盖了
- en: A brief introduction to AutoKeras
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoKeras简介
- en: Automated classification and regression
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动分类和回归
- en: Addressing multi-input and multi-output problems with AutoML
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用AutoML解决多输入和多输出问题
- en: This chapter begins by teaching you how to create an end-to-end deep learning
    solution without selecting or tuning any deep learning algorithms. This can be
    done with as few as five lines of code, which is much simpler than the process
    introduced in chapter 3 for implementing a deep learning pipeline. Then you’ll
    learn how to perform classification and regression on image, text, and tabular
    data, as we did in the previous chapters, but with AutoML. We’ll also explore
    several more complex scenarios, including tasks with multiple types of inputs,
    such as both images and text, and tasks with multiple targets, such as a joint
    prediction of regression responses and classification labels.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节首先教您如何创建一个端到端的深度学习解决方案，而无需选择或调整任何深度学习算法。这可以通过尽可能少的五行代码实现，这比第3章中介绍实现深度学习管道的过程要简单得多。然后，您将学习如何使用AutoML在图像、文本和表格数据上执行分类和回归，正如我们在前面的章节中所做的那样。我们还将探索几个更复杂的场景，包括具有多种类型输入的任务，例如图像和文本，以及具有多个目标的任务，例如回归响应和分类标签的联合预测。
- en: '4.1 Preparing the AutoML toolkit: AutoKeras'
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 准备AutoML工具包：AutoKeras
- en: Before starting to work on the real problems, let’s first explore our primary
    tool for AutoML, AutoKeras. AutoKeras is a Python library focused on the automated
    generation of deep learning solutions. To install AutoKeras, you can simply run
    pip install autokeras at your command line or !pip install autokeras in a Jupyter
    notebook. A more detailed discussion of the package installation is given in appendix
    A.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始解决实际问题之前，让我们首先探索我们的主要AutoML工具——AutoKeras。AutoKeras是一个专注于自动生成深度学习解决方案的Python库。要安装AutoKeras，您可以在命令行中简单地运行pip
    install autokeras，或者在Jupyter笔记本中运行!pip install autokeras。关于包安装的更详细讨论见附录A。
- en: AutoKeras is built on the TensorFlow backend ([https://tensorflow.org](https://tensorflow.org)),
    the TensorFlow Keras API ([https://keras.io](https://keras.io)), and the KerasTuner
    library ([https://keras.io/ keras_tuner/](https://keras.io/keras_tuner/)). These
    four components illustrate a complete spectrum of deep learning software. From
    the user’s perspective, as illustrated in figure 4.1, TensorFlow is the most configurable
    but is also the most complicated; AutoKeras, at the other end of the spectrum,
    is the simplest. The components on the right were developed based on those on
    the left, and they offer more advanced and encapsulated automation but less customizability.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: AutoKeras建立在TensorFlow后端([https://tensorflow.org](https://tensorflow.org))、TensorFlow
    Keras API([https://keras.io](https://keras.io))和KerasTuner库([https://keras.io/keras_tuner/](https://keras.io/keras_tuner/))之上。这四个组件展示了深度学习软件的完整范围。从用户的角度来看，如图4.1所示，TensorFlow是最可配置的，但也是最复杂的；AutoKeras位于光谱的另一端，是最简单的。右侧的组件是基于左侧的组件开发的，它们提供了更高级和封装的自动化，但可定制性较低。
- en: '![04-01](../Images/04-01.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![04-01](../Images/04-01.png)'
- en: Figure 4.1 The Keras ecosystem
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 Keras生态系统
- en: Note “More configurable” here means more arguments for users to specify in the
    APIs, which allows greater flexibility to customize the ML pipeline and the AutoML
    algorithm (mainly the search space). Users with more ML expertise can achieve
    more personalized solutions to meet their requirements using lower-level libraries
    such as TensorFlow and the Keras API. These allow users to customize their deep
    learning models layer by layer. On the other hand, users with less knowledge of
    ML who want to save themselves some effort in modeling and tuning and don’t mind
    sacrificing some flexibility may want to use the higher-level libraries, such
    as KerasTuner and AutoKeras.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，“更多可配置性”在这里意味着用户可以在API中指定更多参数，这为自定义ML管道和AutoML算法（主要是搜索空间）提供了更大的灵活性。具有更多ML专业知识的用户可以使用像TensorFlow和Keras
    API这样的底层库来实现更个性化的解决方案，以满足他们的需求。这些库允许用户逐层自定义他们的深度学习模型。另一方面，那些对ML了解较少，希望在建模和调整上节省一些精力，并且不介意牺牲一些灵活性的用户，可能希望使用像KerasTuner和AutoKeras这样的高级库。
- en: In this book, we’ll focus on using AutoKeras to address deep learning problems,
    with a brief look at KerasTuner in chapter 7\. Compared with AutoKeras, KerasTuner
    can be applied to a wider array of ML problems (beyond the scope of deep learning)
    and is more flexible in terms of search space design and search algorithm selection.
    Correspondingly, it requires more knowledge about the ML pipelines to be tuned
    and about AutoML algorithms. If you’re interested in exploring conventional deep
    learning and the lower-level functionality of TensorFlow and Keras, François Chollet’s
    book *Deep Learning with Python*, 2nd edition (Manning, 2021), provides a more
    detailed introduction.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将重点关注使用AutoKeras解决深度学习问题，并在第7章简要介绍KerasTuner。与AutoKeras相比，KerasTuner可以应用于更广泛的机器学习问题（超出深度学习的范围），并且在搜索空间设计和搜索算法选择方面更加灵活。相应地，它需要更多关于要调整的机器学习流水线和AutoML算法的知识。如果您对探索传统深度学习和TensorFlow和Keras的底层功能感兴趣，François
    Chollet的书籍《Python深度学习》（第2版，Manning，2021年）提供了更详细的介绍。
- en: 'AutoKeras is positioned as the highest-level library of all the libraries in
    the Keras ecosystem. It offers the highest level of automation. As illustrated
    in figure 4.2, it provides the following three levels of APIs—namely, a set of
    task APIs, an input/output (IO) API, and a functional API—to cover different scenarios
    when applying AutoML in real-world applications:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: AutoKeras定位为Keras生态系统中最顶层的库。它提供了最高级别的自动化。如图4.2所示，它提供了以下三个级别的API——即一组任务API、输入/输出（IO）API和功能API——以覆盖在现实世界应用中应用AutoML的不同场景：
- en: 'The task APIs help you generate an end-to-end deep learning solution for a
    target ML task, such as image classification. These are the most straightforward
    AutoKeras APIs because they enable you to achieve the desired ML solution with
    only one step: feeding in the data. Six different task APIs support six different
    tasks in the latest release of AutoKeras, including classification and regression
    for image, text, and structured data.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务API帮助您为针对目标机器学习任务生成端到端的深度学习解决方案，例如图像分类。这些是AutoKeras中最直接的API，因为它们允许您通过仅一步操作（输入数据）来实现所需的机器学习解决方案。在AutoKeras的最新版本中，六个不同的任务API支持六个不同的任务，包括图像、文本和结构化数据的分类和回归。
- en: Real-world problems can have multiple inputs or outputs. For example, we can
    use both visual and acoustic information to detect actions in a video. We may
    also want to predict multiple outputs, such as using the consumption records of
    customers to predict their shopping interests and income levels. To address these
    tasks, we can use AutoKeras’s IO API. You’ll see two examples in section 4.4.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现实世界的问题可能有多个输入或输出。例如，我们可以使用视觉和声学信息来检测视频中的动作。我们可能还希望预测多个输出，例如使用客户的消费记录来预测他们的购物兴趣和收入水平。为了解决这些任务，我们可以使用AutoKeras的IO
    API。您将在第4.4节中看到两个示例。
- en: The functional API is mainly for advanced users who want to tailor the search
    space to their needs. It resembles the TensorFlow Keras functional API, which
    we used in chapter 3 to create deep neural networks, and allows us to build a
    deep learning pipeline by wiring some AutoKeras building blocks. A building block
    often represents a specific deep learning model composed of multiple Keras layers
    such as a CNN, meaning that we don’t have to specify these models layer by layer.
    The search space of the hyperparameters for each block is also designed and set
    up for us so that we can focus on the hyperparameters that concern us without
    worrying about the rest.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 功能API主要面向希望根据自身需求定制搜索空间的进阶用户。它类似于我们在第3章中使用的TensorFlow Keras功能API，允许我们通过连接一些AutoKeras构建块来构建深度学习流水线。一个构建块通常代表由多个Keras层（如CNN）组成的特定深度学习模型，这意味着我们不需要逐层指定这些模型。每个块的超参数搜索空间也是为我们设计和设置的，这样我们就可以专注于我们关心的超参数，而无需担心其他方面。
- en: '![04-02](../Images/04-02.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![04-02](../Images/04-02.png)'
- en: Figure 4.2 Different levels of AutoKeras APIs
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2 AutoKeras API的不同级别
- en: This chapter will focus on the task APIs and the IO API. Both of these allow
    you to generate end-to-end solutions without customizing the search space. The
    functional API will be discussed in the next chapter.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点关注任务API和IO API。这两个API都允许您在不自定义搜索空间的情况下生成端到端解决方案。功能API将在下一章讨论。
- en: 4.2 Automated image classification
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 自动化图像分类
- en: 'Ideally, given an ML problem and the corresponding data, we expect an AutoML
    algorithm to be able to provide a satisfactory ML solution with minimal human
    effort or configuration. In this section, we use the image classification problem
    with the MNIST dataset as an example to introduce how to achieve this goal with
    only the following two steps:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，给定一个机器学习问题和相应的数据，我们期望AutoML算法能够在最小的人力或配置下提供令人满意的机器学习解决方案。在本节中，我们以MNIST数据集的图像分类问题为例，介绍如何仅通过以下两个步骤实现这一目标：
- en: Select the AutoKeras task API that is suited to the problem at hand.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择适合当前问题的AutoKeras任务API。
- en: Feed the data to the selected API.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据输入到所选API中。
- en: You’ll be able to create the image classifier without creating any deep learning
    models or touching the AutoML algorithm. We will discuss more examples related
    to different tasks and data types in the next section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你将能够创建图像分类器，而无需创建任何深度学习模型或接触AutoML算法。在下一节中，我们将讨论更多与不同任务和数据类型相关联的示例。
- en: 4.2.1 Attacking the problem with five lines of code
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.1 使用五行代码解决问题
- en: 'Remember that we addressed the image classification problem in the previous
    chapter by building up a CNN with TensorFlow and its Keras API. The following
    five steps were in the deep learning workflow:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们在上一章中通过构建TensorFlow及其Keras API的CNN来解决图像分类问题。以下五个步骤是深度学习工作流程的一部分：
- en: Load the training and test datasets with TensorFlow.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用TensorFlow加载数据集和测试数据集。
- en: Preprocess the images via normalization.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过归一化预处理图像。
- en: Build a neural network.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建神经网络。
- en: Compile and train the neural network.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译和训练神经网络。
- en: Evaluate the pipeline on the test data.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据上评估流水线。
- en: Implementing this process requires the selection of each component in the deep
    learning algorithm. You need to define the hyperparameters for the whole pipeline
    and construct the network layer by layer. Even with this process, it’s not always
    easy to obtain the desired result, because there’s no guarantee that you will
    set all the hyperparameters suitably on your first attempt. Tuning the hyperparameters
    on a separate validation set requires extra effort during the implementation phase
    and is a trial-and-error process. With the help of AutoML, you can settle all
    the matters in one go. Let’s automatically generate a deep learning model for
    classifying MNIST digits using AutoKeras. The whole problem can be addressed with
    as few as five lines of code, as you can see in the following listing.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 实现此过程需要选择深度学习算法中的每个组件。您需要定义整个流水线的超参数，并逐层构建网络。即使有这个过程，也不总是容易获得期望的结果，因为没有保证您会在第一次尝试时设置所有超参数都合适。在实现阶段，在单独的验证集上调整超参数需要额外的努力，并且是一个试错过程。借助AutoML，您可以一次解决所有问题。让我们使用AutoKeras自动生成一个用于分类MNIST数字的深度学习模型。整个问题可以用尽可能少的五行代码来解决，如下所示。
- en: Listing 4.1 Multiclass image classification with AutoKeras task API
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.1 使用AutoKeras任务API的多类图像分类
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Loads the data
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载数据
- en: ❷ Initializes an AutoKeras ImageClassifier
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 初始化AutoKeras ImageClassifier
- en: ❸ Feeds the ImageClassifier with training data
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将训练数据输入到ImageClassifier中
- en: 'After loading the datasets, the only thing you need to do to get the final
    solution is to initialize the API and feed the training data into the initialized
    ImageClassifier object. Fitting is an iterative process using the following three
    steps:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载数据集之后，您要获取最终解决方案的唯一事情就是初始化API并将训练数据输入到初始化的ImageClassifier对象中。拟合是一个迭代过程，使用以下三个步骤：
- en: Select a deep learning pipeline (composed of the preprocessing methods, a CNN
    model, and the training algorithm implemented with Keras) from the search space
    based on the AutoML search algorithm. For each ML task, AutoKeras integrates a
    tailored search space and a task-specific search algorithm in the corresponding
    task API. You don’t need to specify them when using the API. In this example,
    because we’re tackling an image classification problem, the ImageClassifier in
    AutoKeras will automatically populate the search space with a set of deep learning
    pipelines composed of different data preprocessing methods for images and CNNs.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据AutoML搜索算法从搜索空间中选择一个深度学习流水线（由预处理方法、CNN模型和用Keras实现的训练算法组成）。对于每个机器学习任务，AutoKeras在其相应的任务API中集成了一个定制的搜索空间和特定于任务的搜索算法。在使用API时，您无需指定它们。在本例中，因为我们正在处理图像分类问题，所以AutoKeras中的ImageClassifier将自动用一系列由不同的图像预处理方法和CNN组成的深度学习流水线填充搜索空间。
- en: Train the selected pipeline and evaluate it to get its classification accuracy.
    By default, 20% of the training data will be split off as the validation set.
    The validation loss or accuracy will be used to compare the performance of all
    the selected pipelines.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练选定的管道并评估它以获取其分类准确率。默认情况下，20% 的训练数据将被分割为验证集。验证损失或准确率将用于比较所有选定管道的性能。
- en: Update the AutoML search algorithm. Some AutoML algorithms can learn from the
    performance of the previously explored pipelines to make their later explorations
    more efficient. This step may not be required because some AutoML algorithms,
    such as grid search, do not need to be updated.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 AutoML 搜索算法。一些 AutoML 算法可以从先前探索的管道的性能中学习，以使它们的后续探索更加高效。这一步可能不是必需的，因为一些 AutoML
    算法，如网格搜索，不需要更新。
- en: This iterative process imitates manual tuning but removes the human element,
    letting the AutoML algorithm do the selection. The number of tuning iterations
    is decided by the number of trials you want to conduct—that is, how many pipelines
    you want the AutoML algorithm to explore in the search space. When initializing
    the ImageClassifier, you can set this in the max_trials argument. After all the
    trials are completed, the best pipeline found so far will be trained again using
    the full training dataset to achieve the final solution (see figure 4.3).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这个迭代过程模仿了手动调整，但去除了人为因素，让 AutoML 算法来完成选择。调整迭代的次数由你想要进行的试验次数决定——即你想要 AutoML 算法在搜索空间中探索多少个管道。在初始化
    ImageClassifier 时，你可以在 max_trials 参数中设置这个值。所有试验完成后，迄今为止找到的最佳管道将再次使用完整的训练数据集进行训练，以实现最终解决方案（见图
    4.3）。
- en: '![04-03](../Images/04-03.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![04-03](../Images/04-03.png)'
- en: Figure 4.3 The AutoML process of the AutoKeras task API
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 AutoKeras 任务 API 的 AutoML 流程
- en: Calling the fit() method of ImageClassifier is the same as calling the fit()
    method of a Keras model. All the arguments for fitting a single Keras model can
    be seamlessly adopted here to control the training process of each selected pipeline,
    such as the number of epochs. All the trials and the model weights of the best
    pipeline will be saved to disk, so they are preserved for evaluation and later
    use.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 ImageClassifier 的 fit() 方法与调用 Keras 模型的 fit() 方法相同。所有用于拟合单个 Keras 模型的参数都可以无缝地应用于此处，以控制每个选定管道的训练过程，例如训练轮数。所有试验和最佳管道的模型权重都将保存到磁盘上，以便于后续评估和使用。
- en: 'The evaluation of the final solution is also similar to evaluating a Keras
    model. After the fitting is done, we can test the best pipeline by calling the
    evaluate() method. It will first preprocess the test images using the preprocessing
    methods contained in the best pipeline and then feed the processed data into the
    model. As shown in the next code sample, the evaluation accuracy of the best pipeline
    in this example is 98.74%, which is not bad considering that we conducted only
    two trials (explored two pipelines):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 最终解决方案的评估也与评估 Keras 模型类似。拟合完成后，我们可以通过调用 evaluate() 方法来测试最佳管道。它将首先使用最佳管道中包含的预处理方法对测试图像进行预处理，然后将处理后的数据输入到模型中。如以下代码示例所示，本例中最佳管道的评估准确率为
    98.74%，考虑到我们只进行了两次试验（探索了两个管道），这个结果还不错：
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can also get the predicted labels of the test images by calling the predict()
    function like so:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过调用 predict() 函数来获取测试图像的预测标签，如下所示：
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The best found pipeline can be exported as a Keras model. The best model achieved
    in this example can be exported and printed out as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 找到的最佳管道可以导出为 Keras 模型。本例中实现的最佳模型可以如下导出并打印出来：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The model stacks a normalization layer, two convolutional layers, and a pooling
    layer after the input layer. The *dropout* layer is used to randomly set partial
    input tensor elements to zero during each training iteration (batch of data),
    effectively dropping them out of consideration. It is applied only during the
    training process to help overcome the overfitting issue of the network.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在输入层之后堆叠了一个归一化层、两个卷积层和一个池化层。*dropout* 层用于在每个训练迭代（数据批次）期间随机将部分输入张量元素设置为 0，从而有效地将它们排除在考虑之外。它仅在训练过程中应用，以帮助克服网络的过拟合问题。
- en: Why a dropout layer can mitigate overfitting
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么 dropout 层可以减轻过拟合
- en: 'A dropout layer can mitigate overfitting when training a neural network for
    three reasons:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: dropout 层可以在以下三个原因下减轻训练神经网络时的过拟合：
- en: It reduces the complexity of the correlations between the neurons. The dropout
    layer masks some neurons during the training; only the unmasked neurons are interacted
    with and updated during each forward pass and backpropagation iteration.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它减少了神经元之间相关性的复杂性。在训练过程中，dropout 层会屏蔽一些神经元；只有未屏蔽的神经元在每次前向传递和反向传播迭代中才会被交互和更新。
- en: It averages the effects of subnetworks. To some extent, dropout can be regarded
    as an ensemble strategy to average the predictions of multiple subnetworks randomly
    selected from the whole network during the training process.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它平均了子网络的效果。在某种程度上，dropout 可以被视为一种集成策略，在训练过程中平均从整个网络随机选择的多个子网络的预测。
- en: It introduces extra randomness into the training process, which can help the
    network layers adapt to different input conditions. This will improve its generalizability
    to unseen cases during testing.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它在训练过程中引入了额外的随机性，这有助于网络层适应不同的输入条件。这将提高其在测试期间对未见案例的泛化能力。
- en: To learn the details of the dropout layer, see François Chollet’s book *Deep
    Learning with Python*, 2nd edition (Manning, 2021).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解 dropout 层的详细信息，请参阅 François Chollet 的书籍《使用 Python 进行深度学习》，第 2 版（Manning，2021
    年）。
- en: The exported Keras model can be saved to disk and loaded for further use by
    providing the saved path. As mentioned previously, the exported model does not
    contain the reshaping layer at the beginning to preprocess the input images. We
    need to first expand the input images into 3-D images before making predictions
    with the loaded model, as shown in the following listing.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 导出的 Keras 模型可以通过提供保存的路径保存到磁盘，并用于进一步的使用。如前所述，导出的模型不包含预处理输入图像的开头重塑层。在使用加载的模型进行预测之前，我们需要首先将输入图像扩展为
    3-D 图像，如下面的列表所示。
- en: Listing 4.2 Saving and loading the best model
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.2 保存和加载最佳模型
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Saves the model in the model_autokeras folder
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在 model_autokeras 文件夹中保存模型
- en: ❷ Loads the model
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 加载模型
- en: ❸ Predicts with the loaded model
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用加载的模型进行预测
- en: As this example shows, compared to the conventional deep learning solution we
    created with the TensorFlow Keras API, using AutoML with the AutoKeras task APIs
    allows us to address ML tasks with much less effort spent on data preparation,
    algorithm configuration, and knowledge acquisition. To conclude this example and
    further showcase the flexibility of AutoML, let’s take a look at some additional
    use cases.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 正如这个示例所示，与使用 TensorFlow Keras API 创建的传统深度学习解决方案相比，使用 AutoML 和 AutoKeras 任务 API
    可以让我们在数据准备、算法配置和知识获取上花费更少的精力来处理机器学习任务。为了总结这个示例并进一步展示 AutoML 的灵活性，让我们看看一些额外的用例。
- en: 4.2.2 Dealing with different data formats
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.2 处理不同的数据格式
- en: 'In practice, we may have data in different formats. AutoML should be able to
    accommodate and process the different formats automatically without extra manual
    preprocessing. Some examples follow:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，我们可能拥有不同格式的数据。AutoML 应该能够自动适应并处理不同的格式，而无需额外的手动预处理。以下是一些示例：
- en: Images may or may not have an explicitly specified channel dimension. We expect
    the AutoML API can directly handle both situations, whereas (as we saw in the
    previous chapter) to feed the MNIST images to a Keras model, we need to manually
    add an extra channel dimension for each image to convert their shapes when the
    channel dimension is not presented.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像可能或可能没有明确指定的通道维度。我们期望 AutoML API 可以直接处理这两种情况，而（正如我们在上一章中看到的）为了将 MNIST 图像输入到
    Keras 模型中，我们需要手动为每个图像添加一个额外的通道维度，以在通道维度不存在时转换它们的形状。
- en: Labels of images could be strings, integers, or even be prepared into a one-hot-encoded
    format (vectors of 0s and 1s).
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像的标签可以是字符串、整数，甚至可以准备成 one-hot 编码格式（0 和 1 的向量）。
- en: The data structure of images and labels may vary, depending on the packages
    used for loading and preparing the datasets. They might be formatted as NumPy
    arrays (np.ndarray), pandas DataFrames (pd.DataFrame), or TensorFlow Datasets
    (tf.data.Dataset).
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像和标签的数据结构可能因用于加载数据集的包而异。它们可能格式化为 NumPy 数组 (np.ndarray)、pandas DataFrame (pd.DataFrame)
    或 TensorFlow Datasets (tf.data.Dataset)。
- en: To reduce the burden of data preparation, AutoML libraries often provide the
    flexibility to handle different data formats. For example, all the cases that
    were just described can be handled by the ImageClassifier. Testing that is left
    to the reader as an exercise.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻数据准备的压力，AutoML 库通常提供处理不同数据格式的灵活性。例如，所有刚刚描述的案例都可以由 ImageClassifier 处理。测试留给读者作为练习。
- en: 4.2.3 Configuring the tuning process
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2.3 配置调优过程
- en: As well as the data format, you may want to configure the search process by
    specifying how much data you want to use as the validation set, the evaluation
    metric you want to collect for the explored pipelines, how you want to compare
    the pipelines (such as by comparing the accuracy or loss on the validation set),
    and so on.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据格式，您可能还想通过指定您希望用作验证集的数据量、您希望收集用于探索管道的评估指标、您希望如何比较管道（例如，通过比较验证集上的准确率或损失）等方式来配置搜索过程。
- en: Listing 4.3 provides an example. The loss function for training a pipeline is
    defined as categorical cross-entropy loss. The selected evaluation metric is accuracy.
    The search objective is set to validation accuracy, so the best pipeline will
    be the one with the highest classification accuracy on the validation set. Finally,
    we set aside 15% of the training data to use as the validation set for the tuning
    process.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.3提供了一个示例。训练管道的损失函数定义为类别交叉熵损失。选定的评估指标是准确率。搜索目标设置为验证准确率，因此最佳管道将是验证集上分类准确率最高的管道。最后，我们预留出15%的训练数据用于调整过程的验证集。
- en: Listing 4.3 Customizing the configuration for the tuning process
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.3 定制调整过程的配置
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Uses categorical cross-entropy loss for classification
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用类别交叉熵损失进行分类
- en: ❷ Uses accuracy as the evaluation metric
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用准确率作为评估指标
- en: ❸ Sets validation accuracy as the tuning objective
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将验证准确率设置为调整目标
- en: ❹ Splits out 15% of the data for validation
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将15%的数据分出用于验证
- en: We may want to use a custom evaluation metric rather than the default one to
    compare the performance of the pipelines. For example, we can create our own metric
    function and wrap it up as an evaluation objective in the AutoML process. As we’re
    tuning deep learning models constructed with TensorFlow Keras, the creation of
    the objective metric should follow the creation of a Keras metric function, which
    takes the ground-truth responses (labels in the classification problem) and the
    model predictions for a batch of data points as inputs and outputs the metric
    value, as shown next.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能希望使用自定义评估指标而不是默认指标来比较管道的性能。例如，我们可以创建自己的指标函数，并将其作为AutoML过程中的评估目标封装。由于我们正在调整使用TensorFlow
    Keras构建的深度学习模型，因此目标指标的创建应遵循Keras指标函数的创建，该函数接受真实响应（分类问题中的标签）和一批数据点的模型预测作为输入，并输出指标值，如下所示。
- en: Listing 4.4 Creating a customized Keras metric function
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.4 创建定制的Keras评估指标函数
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Compares the model predictions with the ground-truth labels
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将模型预测与真实标签进行比较
- en: ❷ Computes the prediction accuracy in this batch of data
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算此批次数据中的预测准确率
- en: Note Multiple metrics may be added to an ImageClassifier, which will all be
    computed during the evaluation. However, only one objective is set for an ImageClassifier—the
    metric used to select the best model. It is true for the rest of the task APIs
    as well.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，可以为ImageClassifier添加多个指标，这些指标将在评估期间全部计算。然而，对于ImageClassifier，仅设置一个目标——用于选择最佳模型的指标。对于其他任务API也是如此。
- en: To set the customized metric as the metric and objective in the AutoML process,
    we should first pass the function as one of the metrics so that it will be calculated
    during the evaluation process for each selected pipeline. Then we can wrap it
    up as a search objective, which is used by the search algorithm to compare the
    performance of the pipelines. Wrapping the objective requires the Objective class
    in the KerasTuner library (see listing 4.5). Two arguments should be provided
    to instantiate an objective. The first one specifies the name of the metric to
    be used as the search objective (val_my_metric in this example). Because we want
    to use the validation accuracy of the pipelines as the objective, we should add
    a val_ prefix to the function (or metric) name. The second argument (direction)
    indicates whether larger values for the metric (direction='max') or smaller values
    (direction='min') are better. In this example, we want to find a pipeline to maximize
    the customized accuracy, so we set the direction to 'max'.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要在AutoML过程中将自定义的指标作为指标和目标，我们首先应该将函数作为其中一个指标传递，这样它就会在评估过程中为每个选定的管道计算。然后我们可以将其封装为一个搜索目标，该目标由搜索算法用于比较管道的性能。封装目标需要KerasTuner库中的Objective类（见列表4.5）。实例化一个目标需要提供两个参数。第一个参数指定用作搜索目标的指标名称（本例中的val_my_metric）。因为我们想将管道的验证准确率作为目标，所以我们应该在函数（或指标）名称中添加一个val_前缀。第二个参数（方向）指示指标的大值（direction='max'）或小值（direction='min'）更好。在本例中，我们想找到一个最大化自定义准确率的管道，因此我们将方向设置为'max'。
- en: Listing 4.5 Passing the customized metric to the AutoML process
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.5 将自定义指标传递给AutoML过程
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Wraps the customized metric function in a KerasTuner Objective and passes
    it to AutoKeras
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将自定义指标函数封装在KerasTuner Objective中，并将其传递给AutoKeras
- en: ❷ Includes the customized metric as one of the metrics
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将自定义指标作为其中一个指标包含在内
- en: It’s worth pointing out that the task APIs do not directly provide arguments
    for selecting the search algorithm and configuring the search space, because their
    goal is to simplify the whole ML workflow and reduce your burden as much as possible.
    Let’s look at a few more examples of using the AutoKeras task APIs. You’ll learn
    a more general AutoML solution to deal with tasks with multiple inputs and outputs
    in the last section of this chapter.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 值得指出的是，任务API没有直接提供用于选择搜索算法和配置搜索空间的参数，因为它们的目的是简化整个机器学习（ML）工作流程，尽可能减轻你的负担。让我们看看使用AutoKeras任务API的更多示例。在本章的最后部分，你将学习一个更通用的AutoML解决方案，用于处理具有多个输入和输出的任务。
- en: 4.3 End-to-end AutoML solutions for four supervised learning problems
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 四个监督学习问题的端到端AutoML解决方案
- en: 'In this section, we’ll use AutoML to generate end-to-end solutions for four
    more supervised ML problems with the help of different AutoKeras task APIs. The
    problems we will solve follow:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用AutoML，借助不同的AutoKeras任务API，为四个更多的监督机器学习（ML）问题生成端到端解决方案。我们将解决的问题如下：
- en: Text classification with the 20 newsgroups dataset
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用20个新闻组数据集进行文本分类
- en: Structured data classification with the Titanic dataset
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用泰坦尼克号数据集进行结构化数据分类
- en: Structured data regression with the California housing dataset
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用加利福尼亚住房数据集进行结构化数据回归
- en: Multilabel image classification with a synthetic dataset
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用合成数据集进行多标签图像分类
- en: We’ve already solved the first three problems with traditional ML methods in
    the previous chapters; here, we reapproach them with AutoML to get you familiar
    with the use of AutoKeras’s task APIs.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在上一章中用传统的机器学习（ML）方法解决了前三个问题；在这里，我们用AutoML重新处理这些问题，以便让你熟悉AutoKeras的任务API的使用。
- en: Before going into the problem, let’s quickly recap the differences between the
    traditional ML methods and the AutoML methods. Traditional ML methods create one
    model for a problem. Therefore, you have to specify the details of the model.
    AutoML methods search for different types of models so that you don’t specify
    all the details but leave some part of the model for the search. This difference
    results in the API of AutoML being different from traditional methods. The AutoML
    APIs are more concise because they leave the detailed configurations to the search.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在进入问题之前，让我们快速回顾一下传统机器学习（ML）方法和AutoML方法之间的区别。传统的机器学习（ML）方法为每个问题创建一个模型。因此，你必须指定模型的详细信息。AutoML方法搜索不同类型的模型，这样你就不必指定所有细节，但将模型的一部分留给搜索。这种差异导致AutoML的API与传统方法不同。AutoML
    API更简洁，因为它们将详细配置留给搜索。
- en: The final problem is a more sophisticated image classification scenario, in
    which each image is related to multiple labels (such as an image containing both
    a cat and a dog). You may not know how to address it with conventional ML, but
    with the help of AutoML and the AutoKeras task API, you need to change only one
    argument in ImageClassifier, and everything will be done in one go.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个问题是一个更复杂的图像分类场景，其中每个图像都与多个标签相关（例如，包含猫和狗的图像）。您可能不知道如何使用传统的机器学习来解决它，但借助AutoML和AutoKeras任务API的帮助，您只需要在ImageClassifier中更改一个参数，所有事情都会一次性完成。
- en: 4.3.1 Text classification with the 20 newsgroups dataset
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1 使用20个新闻组数据集进行文本分类
- en: The first example is a text classification problem using the 20 newsgroups dataset,
    fetched with the scikit-learn library. The goal is to classify each document into
    one of the 20 newsgroups, based on its topic. If you’re not familiar with the
    basic ML process of text classification, we recommend you check out appendix B.
    We provide more details there related to the preprocessing of text data and two
    probabilistic classification models. Here we use AutoML to address the problem
    with the TextClassifier task API in AutoKeras.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个例子是使用scikit-learn库获取的20个新闻组数据集进行文本分类的问题。目标是根据文档的主题将其分类到20个新闻组之一。如果您不熟悉文本分类的基本机器学习过程，我们建议您查看附录B。我们在那里提供了有关文本数据预处理和两种概率分类模型的更多详细信息。这里我们使用AutoML来处理AutoKeras中的TextClassifier任务API的问题。
- en: We first download the data with the built-in data loader fetch_20newsgroups
    in scikit-learn. It has already been split into training and test sets for ease
    of use. As shown in the following listing, we load only two of the 20 newsgroup
    categories (rec.autos and rec.motorcycles), to make running the search process
    faster.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先使用scikit-learn内置的数据加载器fetch_20newsgroups下载数据。它已经被分为训练集和测试集，以便于使用。如下所示，我们只加载了20个新闻组类别中的两个（rec.autos和rec.motorcycles），以使搜索过程更快。
- en: Listing 4.6 Loading the 20 newsgroups dataset
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.6 加载20个新闻组数据集
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Loads the training and test datasets
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载训练和测试数据集
- en: ❷ Formats the datasets into NumPy arrays
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将数据集格式化为NumPy数组
- en: 'Let’s explore the training and test datasets. Each document has been formatted
    as a string of terms as shown here:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索训练和测试数据集。每个文档都已格式化为如这里所示的术语字符串：
- en: '[PRE9]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: After loading the data, we can directly input these raw documents into the API
    without any further preprocessing, such as transforming the documents into numerical
    vectors. In listing 4.7, we set the number of pipelines to be searched and compared
    as three. We do not specify the number of epochs to train each of them. The TextClassifier
    API will, by default, train each pipeline for, at most, 1,000 epochs and stop
    training whenever the validation loss does not improve in 10 consecutive epochs
    to minimize the training time and avoid overfitting.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载数据后，我们可以直接将这些原始文档输入API，而无需任何进一步的前处理，例如将文档转换为数值向量。在列表4.7中，我们设置了要搜索和比较的管道数量为三个。我们没有指定每个管道的训练轮数。TextClassifier
    API将默认为每个管道训练，最多1,000轮，并在验证损失在连续10轮中没有改善时停止训练，以最小化训练时间并避免过拟合。
- en: Listing 4.7 Classifying text with AutoKeras task API
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.7 使用AutoKeras任务API进行文本分类
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Initializes an AutoKeras TextClassifier
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 初始化AutoKeras TextClassifier
- en: ❷ Feeds the TextClassifier with training data
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将训练数据输入TextClassifier
- en: 'The best pipeline found in the three trials achieves 96.1% accuracy on the
    final test set, as shown here:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在三次试验中找到的最佳管道在最终的测试集上实现了96.1%的准确率，如下所示：
- en: '[PRE11]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can get the predicted labels of the documents by feeding them into the predict()
    function and export the best model by calling the export_model() method. Because
    the procedure is the same as in the previous example, it’s not repeated here.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将文档输入predict()函数来获取预测标签，并通过调用export_model()方法导出最佳模型。由于这个过程与前面的例子相同，这里不再重复。
- en: 4.3.2 Structured data classification with the Titanic dataset
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.2 使用泰坦尼克号数据集进行结构化数据分类
- en: In this example, we’ll use the Titanic dataset to automatically generate an
    ML solution for a structured data classification task. This dataset contains both
    categorical features, or string types, and numerical features. Some features also
    have missing values, so they require extra preprocessing before they are input
    into a neural network. More details of the dataset and the classical way of preprocessing
    it are introduced in appendix B. When using AutoML to address the classification
    problem, as we do here, you don’t need to worry about these manual preprocessing
    steps.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们将使用泰坦尼克号数据集来自动生成一个针对结构化数据分类任务的机器学习解决方案。该数据集包含分类特征，或字符串类型，以及数值特征。一些特征也存在缺失值，因此在它们输入神经网络之前需要额外的预处理。数据集的更多细节以及预处理它的经典方法在附录
    B 中介绍。当使用 AutoML 解决分类问题时，正如我们在这里所做的那样，您无需担心这些手动预处理步骤。
- en: Structured data is often formatted and saved as tables in CSV files. You can
    also feed in these raw CSV files as inputs without loading them into NumPy arrays
    or pandas DataFrames.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化数据通常以表格格式保存并存储在 CSV 文件中。您也可以将这些原始 CSV 文件作为输入提供，而无需将它们加载到 NumPy 数组或 pandas
    DataFrame 中。
- en: We use a real structured dataset, the Titanic dataset. The features of the dataset
    are the profiles of the passengers of the Titanic. The prediction target is whether
    the passenger survived the accident.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个真实的结构化数据集，即泰坦尼克号数据集。数据集的特征是泰坦尼克号乘客的档案。预测目标是乘客是否在事故中幸存。
- en: We can download the dataset using the code shown in listing 4.8\. We have two
    files to download—the training data and the testing data. We use the get_file(...)
    function from tf.keras.utils, which downloads the CSV files from the URLs. The
    first argument is the filename to use for saving the file locally. The second
    argument is the URL to download the file. The function returns the path to the
    location that the file is saved locally.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用图 4.8 所示的代码下载数据集。我们有两个文件需要下载——训练数据和测试数据。我们使用 tf.keras.utils 中的 get_file(...)
    函数，该函数从 URL 下载 CSV 文件。第一个参数是用于保存文件的本地文件名。第二个参数是下载文件的 URL。该函数返回文件在本地保存的位置的路径。
- en: Listing 4.8 Downloading the Titanic dataset
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.8 下载泰坦尼克号数据集
- en: '[PRE12]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The first five lines in the training CSV file are shown in figure 4.4\. The
    first line gives the names of the target response (survived) and the nine features.
    The next four lines denote four passengers and their corresponding features. The
    missing values are marked as “unknown,” such as the deck feature of the first
    passenger. A total of 627 passengers are in the training set. The testing CSV
    file is in the same format and contains data on 264 passengers.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 CSV 文件的前五行如图 4.4 所示。第一行给出了目标响应（survived）和九个特征的名称。接下来的四行表示四位乘客及其相应的特征。缺失值被标记为“unknown”，例如第一位乘客的甲板特征。训练集中共有
    627 名乘客。测试 CSV 文件具有相同的格式，包含 264 名乘客的数据。
- en: '![04-04](../Images/04-04.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![04-04](../Images/04-04.png)'
- en: Figure 4.4 The first five lines of the Titanic training CSV file
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 泰坦尼克号训练 CSV 文件的前五行
- en: To solve structured data classification problems, we can use the StructuredDataClassifier
    API in AutoKeras. We fit an initialized StructuredDataClassifier object with the
    path of the training CSV file. It will load and preprocess the data automatically.
    The name of the target label column (survived) should be provided as an argument,
    as shown in the next listing.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决结构化数据分类问题，我们可以使用 AutoKeras 中的 StructuredDataClassifier API。我们使用训练 CSV 文件的路径来拟合一个初始化的
    StructuredDataClassifier 对象。它将自动加载数据并进行预处理。目标标签列（survived）的名称应作为参数提供，如以下列表所示。
- en: Listing 4.9 Structured data classification with AutoKeras task API
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.9 使用 AutoKeras 任务 API 进行结构化数据分类
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Path to the training CSV file
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 训练 CSV 文件的路径
- en: ❷ Name of the target label column
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 目标标签列的名称
- en: The StructuredDataClassifier will load the names of each feature from the header
    of the training CSV file and infer the types of the features (categorical or numerical)
    automatically. You can also explicitly specify them when initializing the StructuredDataClassifier,
    as shown in the following listing.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: StructuredDataClassifier 将从训练 CSV 文件的标题中加载每个特征的名称，并自动推断特征类型（分类或数值）。您也可以在初始化
    StructuredDataClassifier 时显式指定它们，如以下列表所示。
- en: Listing 4.10 Providing feature information to the AutoKeras API
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.10 向 AutoKeras API 提供特征信息
- en: '[PRE14]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Specifies the feature names
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 指定特征名称
- en: ❷ Specifies the data types of the two features
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 指定两个特征的数据类型
- en: To make predictions using the best discovered pipeline, we can feed the path
    of the testing CSV file to the predict() method. All the feature columns adopted
    from the training file should be provided in the testing file. Similarly, we can
    evaluate the best pipeline using the evaluate() method by providing the path of
    the testing CSV file, as shown next.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用最佳发现的管道进行预测，我们可以将测试CSV文件的路径传递给predict()方法。测试文件中应提供从训练文件中采用的所有特征列。同样，我们可以通过提供测试CSV文件的路径来使用evaluate()方法评估最佳管道，如以下所示。
- en: Listing 4.11 Testing the structured data classifier
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.11 使用AutoKeras测试结构化数据分类器
- en: '[PRE15]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Gets predictions for the testing data from the CSV file
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从CSV文件获取测试数据的预测
- en: ❷ Evaluates the classifier
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 评估分类器
- en: We’ve now solved three classification tasks on different types of data with
    the help of AutoKeras’s task APIs. Next, we’ll explore a regression problem.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经使用AutoKeras的任务API解决了三种不同类型数据的分类任务。接下来，我们将探讨一个回归问题。
- en: 4.3.3 Structured data regression with the California housing dataset
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.3 使用加利福尼亚住房数据集进行结构化数据回归
- en: In this example, we will use AutoML to address a structured data regression
    problem. The only difference compared with a structured data classification problem
    lies in selecting the task API in AutoKeras. We first fetch the dataset from scikit-learn
    and split off 20% of the data to use as the test set, as shown in the next listing.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用AutoML来解决结构化数据回归问题。与结构化数据分类问题相比，唯一的区别在于在AutoKeras中选择任务API。我们首先从scikit-learn获取数据集，并将20%的数据分割出来作为测试集，如下一列表所示。
- en: Listing 4.12 Loading and splitting the California housing dataset
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.12 加载和分割加利福尼亚住房数据集
- en: '[PRE16]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Fetches the dataset
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取数据集
- en: ❷ Packs the features into a pandas DataFrame
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将特征打包到pandas DataFrame中
- en: ❸ Splits off 20% of the data for testing
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 分割20%的数据用于测试
- en: Then we use AutoKeras’s StructuredDataRegressor API to perform the regression
    task, as shown in listing 4.13\. We use a larger batch size here (1024) to increase
    the training speed of each pipeline. The final testing MSE of the best pipeline
    discovered in the 10 trials is 0.31\. Compared to the result we got in chapter
    3 using traditional ML methods, which was 0.34, the result from AutoML is significantly
    better.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用AutoKeras的StructuredDataRegressor API来执行回归任务，如列表4.13所示。在这里我们使用更大的批量大小（1024）以提高每个管道的训练速度。在10次试验中发现的最佳管道的最终测试MSE为0.31。与第3章中使用传统机器学习方法得到的结果0.34相比，AutoML的结果显著更好。
- en: Note This code example may take a long time to run.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：此代码示例可能需要很长时间才能运行。
- en: Listing 4.13 Structured data regression with AutoKeras task API
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.13 使用AutoKeras任务API进行结构化数据回归
- en: '[PRE17]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Fits the API with training data
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用训练数据拟合API
- en: ❷ Tests the final regressor
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 测试最终的回归器
- en: Besides the StructuredDataRegressor, AutoKeras also provides ImageRegressor
    and TextRegressor APIs for image and text data regression tasks, respectively.
    They are used in the same way, which allows you to draw inferences about other
    cases from this example.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 除了StructuredDataRegressor之外，AutoKeras还提供了ImageRegressor和TextRegressor API，分别用于图像和文本数据的回归任务。它们的使用方式相同，这允许您从这个例子中推断其他情况。
- en: 4.3.4 Multilabel image classification
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.4 多标签图像分类
- en: Our last example is a *multilabel classification* *problem*. We have already
    explored some examples of multiclass classification, such as classifying handwritten
    digits in the MNIST dataset and assigning newsgroups to the related topic. In
    those cases, each instance can belong to only one of the classes, which means
    all the classes are mutually exclusive. But in real-world situations, a sample
    may have multiple labels. For example, an image of a scene may contain both a
    mountain and a river, and a news document may cover both political and economic
    topics. In multilabel classification, a sample can be associated with multiple
    labels, as indicated via a set of Boolean variables (whether or not the instance
    belongs to a label). The goal is to assign the sample to all its possible labels.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最后一个例子是一个*多标签分类*问题。我们已经探讨了多类分类的一些例子，例如在MNIST数据集中对手写数字进行分类以及将新闻组分配到相关主题。在这些情况下，每个实例只能属于一个类别，这意味着所有类别都是互斥的。但在现实世界中，一个样本可能具有多个标签。例如，一个场景的图像可能包含山脉和河流，而一篇新闻文档可能涉及政治和经济主题。在多标签分类中，一个样本可以与多个标签相关联，这通过一组布尔变量（实例是否属于标签）来指示。目标是分配样本到所有可能的标签。
- en: This may not seem like a trivial extension of multiclass classification. But
    with the help of AutoML, and specifically the task APIs in AutoKeras, you don’t
    have to learn, select, and implement a tailored pipeline by yourself. You need
    to change only one argument to settle the matter in one go. We’ll use the image
    classification API (ImageClassifier) as an example and construct a synthetic multilabel
    image classification dataset with the scikit-learn library. In the next listing,
    we create 100 samples with 64 features. There are three classes in total. Each
    sample should belong to at least one class and at most three classes. The average
    number of labels per sample is set to be two (n_labels=2).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来不是多类分类的简单扩展。但借助AutoML的帮助，特别是AutoKeras中的任务API，您不必自己学习、选择和实现定制的管道。您只需更改一个参数，就可以一次性解决问题。我们将使用图像分类API（ImageClassifier）作为示例，并使用scikit-learn库构建一个合成多标签图像分类数据集。在下一条列表中，我们创建了100个样本，每个样本有64个特征。总共有三个类别。每个样本应属于至少一个类别，最多三个类别。每个样本的平均标签数设置为两个（n_labels=2）。
- en: Listing 4.14 Creating a synthetic multilabel image classification dataset
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.14 使用AutoKeras创建合成多标签图像分类数据集
- en: '[PRE18]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Creates the synthetic dataset
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建合成数据集
- en: ❷ Formats the features into 100 8×8 synthetic images
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将特征格式化为100个8×8的合成图像
- en: ❸ Splits off 20% of the data as a test set
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将20%的数据分割为测试集
- en: Next, we use the ImageClassifier as before—but this time we set the argument
    multi_label to True, as shown in listing 4.15\. Similar methods can be used to
    retrieve the prediction results and test accuracy.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用ImageClassifier，但这次我们将参数multi_label设置为True，如列表4.15所示。类似的方法可以用来检索预测结果和测试准确率。
- en: Listing 4.15 Multilabel classification with AutoKeras task API
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.15 使用AutoKeras任务API进行多标签分类
- en: '[PRE19]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Fits the AutoML algorithm
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 调整AutoML算法
- en: ❷ Tests the final model
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 测试最终模型
- en: ❸ Gets the predicted labels
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 获取预测标签
- en: As shown in the previous code, the prediction for each instance is a vector,
    whose length is the same as the number of classes. The values in the vector can
    only be 1s or 0s representing whether or not the instance belongs to the corresponding
    class. It is similar to the one-hot encoding vectors but with multiple 1s in the
    vector. Therefore, it is named *multi-hot encoding*.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码所示，每个实例的预测是一个向量，其长度与类别的数量相同。向量中的值只能是1或0，表示实例是否属于相应的类别。它与one-hot编码向量类似，但向量中有多个1。因此，它被称为*多-hot编码*。
- en: You can also use StructuredDataClassifier and TextClassifier with the multi_
    label argument.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用带有multi_label参数的StructuredDataClassifier和TextClassifier。
- en: For regression problems, if the target response of an instance is a vector rather
    than a single value, you don’t have to explicitly change any argument; the APIs
    will automatically infer whether we have single or multiple regression responses
    from the data.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归问题，如果实例的目标响应是一个向量而不是单个值，您不必显式更改任何参数；API将自动推断数据中是否存在单个或多个回归响应。
- en: 'You’ve now seen how to use AutoKeras’s task APIs to address classification
    and regression problems with different data types. They’re quite friendly for
    users with limited ML knowledge and convenient for deriving end-to-end deep learning
    solutions. But this method has the following two limitations:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已经看到了如何使用AutoKeras的任务API来处理不同数据类型的分类和回归问题。它们对ML知识有限的用户非常友好，并且便于推导端到端的深度学习解决方案。但这种方法有以下两个局限性：
- en: You’re not able to change the search space and the search algorithm with the
    provided arguments. You trade a certain amount of flexibility, customizability,
    and extensibility for convenience.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您无法使用提供的参数更改搜索空间和搜索算法。您以一定的灵活性、可定制性和可扩展性为代价换取便利性。
- en: The running time can be very slow when the dataset size or the number of trials
    is large.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当数据集大小或试验次数很大时，运行时间可能会非常慢。
- en: Mitigating these problems and accommodating more complicated scenarios requires
    greater knowledge of the ML models and AutoML algorithms you want to use. You’ll
    learn about designing your own search space in the next two chapters, and the
    topics of customizing search algorithms and accelerating the AutoML process will
    be discussed in the third part of the book. But before we get to that, let’s first
    work on two scenarios that are a little more complex than the previous examples.
    They don’t require you to have knowledge of the models you want to use, but they
    do require a bit more customization of the search space. The aim of the next section
    is to introduce a more general solution that accommodates different data types
    and supervised learning tasks without switching across different APIs in AutoKeras.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解这些问题并适应更复杂的情况需要您对想要使用的机器学习模型和AutoML算法有更深入的了解。您将在下一章学习如何设计自己的搜索空间，而定制搜索算法和加速AutoML过程的话题将在本书的第三部分讨论。但在我们到达那里之前，让我们先处理两个比之前的例子稍微复杂一点的情况。它们不需要您了解想要使用的模型，但确实需要更多对搜索空间的定制。下一节的目标是介绍一个更通用的解决方案，它可以适应不同的数据类型和监督学习任务，而无需在AutoKeras的不同API之间切换。
- en: 4.4 Addressing tasks with multiple inputs or outputs
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 处理具有多个输入或输出的任务
- en: An ML task could involve multiple inputs collected from different resources,
    which we call different data *modalities*. For example, images could be associated
    with tags and other text descriptions, and videos could contain both visual and
    acoustic information (as well as metadata) that is useful for classification.
    Multiple inputs augment information resources. They could benefit and compensate
    with each other to help train a better ML model. This approach is called *multi-input
    learning* or *multimodal learning*. Similarly, we might want to have multiple
    outputs corresponding to different tasks (regression or classification) that we
    address simultaneously. This is called *multi-output learning* or *multitask learning*.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一个机器学习任务可能涉及从不同资源收集的多个输入，我们称之为不同的数据*模态*。例如，图像可以与标签和其他文本描述相关联，视频可以包含对分类有用的视觉和声学信息（以及元数据）。多个输入可以增强信息资源。它们可以相互受益和补偿，以帮助训练更好的机器学习模型。这种方法被称为*多输入学习*或*多模态学习*。同样，我们可能希望有多个输出对应于我们同时解决的不同任务（回归或分类）。这被称为*多输出学习*或*多任务学习*。
- en: 'This section looks at how we can use the AutoKeras IO API to handle tasks with
    multiple inputs or outputs. Unlike the task APIs, where we have multiple variants
    targeting different specific data types and tasks, the IO API provides a fairly
    general solution—there’s only one API class, named AutoModel—but requires extra
    configuration to specify the types of inputs and outputs. In fact, all the classes
    of the task APIs inherit from the AutoModel class, so you can use the IO API to
    address all the previous tasks. Here we’ll explore examples focusing on three
    scenarios: multiclass classification, multi-input learning, and multi-output learning.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将探讨我们如何使用AutoKeras IO API来处理具有多个输入或输出的任务。与针对不同特定数据类型和任务的多个变体的任务API不同，IO API提供了一个相当通用的解决方案——只有一个API类，名为AutoModel——但需要额外的配置来指定输入和输出的类型。实际上，所有任务API的类都继承自AutoModel类，因此您可以使用IO
    API来解决所有之前的任务。在这里，我们将探索关注三个场景的示例：多类分类、多输入学习和多输出学习。
- en: 4.4.1 Automated image classification with the AutoKeras IO API
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.1 使用AutoKeras IO API进行自动图像分类
- en: We’ll begin by using the IO API to address a simple image classification task
    with the MNIST dataset. The goal is to introduce the basic configuration of the
    IO API so that we can examine more advanced scenarios.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先使用IO API来处理使用MNIST数据集的简单图像分类任务。目标是介绍IO API的基本配置，以便我们可以检查更高级的场景。
- en: We load the data as usual with TensorFlow and construct an AutoModel object
    to address the problem (see listing 4.16). The main difference between using the
    IO API (AutoModel) and the image classification task API (ImageClassifier) is
    in the initialization. When using the task APIs, because each API is tailored
    to a specific problem (classification or regression) and data type (image, text,
    or structured data), we don’t need to specify anything except the number of trials
    (pipelines) to explore in the search space. However, the IO API can generalize
    to all types of data and tasks, so we need to provide information about the data
    types and task types during initialization, so it can select the appropriate loss
    function, metrics, search space, and search objective. In this example, our inputs
    are images and the task is a classification task. Thus, when initializing the
    AutoModel, we feed its inputs argument with ak.ImageInput(), an AutoKeras placeholder
    for image data, and we set its outputs argument to ak.ClassificationHead(), indicating
    the task is a classification task. We also specify the loss function and evaluation
    metrics for the training of each pipeline. If this were a multilabel classification
    task, we would set the multi_label argument to True.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们像往常一样使用TensorFlow加载数据，并构建一个AutoModel对象来解决问题（参见列表4.16）。使用IO API（AutoModel）与图像分类任务API（ImageClassifier）之间的主要区别在于初始化。当使用任务API时，因为每个API都是针对特定问题（分类或回归）和数据类型（图像、文本或结构化数据）定制的，所以我们除了指定搜索空间中要探索的试验（管道）数量之外，不需要指定任何内容。然而，IO
    API可以泛化到所有类型的数据和任务，因此我们需要在初始化时提供有关数据类型和任务类型的信息，以便它可以选择适当的损失函数、指标、搜索空间和搜索目标。在本例中，我们的输入是图像，任务是分类任务。因此，当初始化AutoModel时，我们向其inputs参数提供ak.ImageInput()，这是AutoKeras用于图像数据的占位符，并将它的outputs参数设置为ak.ClassificationHead()，表示任务是分类任务。我们还指定了每个管道的训练损失函数和评估指标。如果这是一个多标签分类任务，我们将multi_label参数设置为True。
- en: Note This code example may take a long time to run.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：此代码示例可能需要很长时间才能运行。
- en: Listing 4.16 MNIST image classification with AutoKeras IO API
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.16 使用AutoKeras IO API进行MNIST图像分类
- en: '[PRE20]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ Specifies the input data type
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 指定输入数据类型
- en: ❷ Specifies the task type and training configurations
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 指定任务类型和训练配置
- en: ❸ Selects the search objective
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 选择搜索目标
- en: ❹ Selects the search algorithm
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 选择搜索算法
- en: ❺ Fits the model with the prepared data
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 使用准备好的数据拟合模型
- en: 'To control the search process, we can set the search objective used to compare
    the performance of different pipelines (validation loss, in this example). As
    with the task APIs, you can create custom evaluation metrics and objectives to
    compare the performance of the pipelines and select the best candidate (we do
    not elaborate it again here). The IO API also provides an extra argument named
    tuner that you can set during initialization. A *tuner* defines a search algorithm
    to explore and select different pipelines in the search space. For example, the
    ''random'' tuner used in this example selects pipelines in the search space randomly:
    it constructs a pipeline at each trial by randomly selecting a value for each
    of the hyperparameters. The tuner also controls the training and evaluation process
    for each constructed pipeline so that the search process can proceed smoothly.
    AutoKeras provides tuners corresponding to several of the most popular search
    algorithms in the current AutoML field. You’ll learn more about tuners in chapter
    7.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 为了控制搜索过程，我们可以设置用于比较不同管道性能的搜索目标（在本例中为验证损失）。与任务API一样，你可以创建自定义评估指标和目标来比较管道的性能并选择最佳候选者（此处不再赘述）。IO
    API还提供了一个名为tuner的额外参数，你可以在初始化时设置。*tuner*定义了一个搜索算法，用于探索和选择搜索空间中的不同管道。例如，本例中使用的'random'
    tuner随机选择搜索空间中的管道：它通过为每个超参数随机选择一个值来构建每个试验的管道。tuner还控制每个构建的管道的训练和评估过程，以便搜索过程可以顺利地进行。AutoKeras提供了与当前AutoML领域中几种最流行的搜索算法相对应的tuner。你将在第7章中了解更多关于tuner的信息。
- en: We can use the other methods of the IO API the same way as the task APIs, as
    illustrated in the following listing. You should be able to use them as long as
    you know how to use one of the task APIs.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用与任务API相同的方式使用IO API的其他方法，如下面的列表所示。只要你知道如何使用其中一个任务API，就应该能够使用它们。
- en: Listing 4.17 Exporting, testing, and evaluating using the IO API
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.17 使用IO API进行导出、测试和评估
- en: '[PRE21]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Exports the best model found by AutoKeras
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 导出AutoKeras找到的最佳模型
- en: ❷ Makes predictions on the test data
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在测试数据上做出预测
- en: ❸ Evaluates the model’s performance
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 评估模型的性能
- en: This example showed how to use the IO API for a multiclass image classification
    task, but it’s easy to draw inferences about other use cases from it. For example,
    if the data type is structured data or text data, you can change ak.ImageInput()
    to ak.StructuredDataInput() or ak.TextInput(). If the task is a regression task,
    you can change ak.ClassificationHead() to ak.RegressionHead(), and the loss and
    metrics can also be changed accordingly. Next, we’ll look at a more complicated
    case.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例展示了如何使用IO API进行多类图像分类任务，但很容易从中推断出其他用例。例如，如果数据类型是结构化数据或文本数据，可以将ak.ImageInput()更改为ak.StructuredDataInput()或ak.TextInput()。如果任务是回归任务，可以将ak.ClassificationHead()更改为ak.RegressionHead()，并且损失和度量也可以相应地更改。接下来，我们将探讨一个更复杂的情况。
- en: 4.4.2 Automated multi-input learning
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.2 自动多输入学习
- en: A typical pipeline structure to handle multiple inputs in conventional ML is
    shown in figure 4.5\. The pipeline first applies data-specific operations to each
    input source, such as normalization and convolutional layers for images, numerical
    embedding for text, and so on. Then it merges all the processed data to generate
    the classification or regression outputs. This structure can also be adopted for
    all the pipelines in the search space to conduct AutoML, and we can leverage the
    IO API of AutoKeras to specify the inputs and the output head.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统机器学习中处理多个输入的典型流程结构如图4.5所示。流程首先对每个输入源应用数据特定的操作，例如对图像进行归一化和卷积层，对文本进行数值嵌入等。然后它将所有处理后的数据合并以生成分类或回归输出。这种结构也可以用于搜索空间中的所有流程以进行AutoML，我们可以利用AutoKeras的IO
    API来指定输入和输出头。
- en: '![04-05](../Images/04-05.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![04-05](../Images/04-05.png)'
- en: Figure 4.5 Multi-input learning pipeline structure
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 多输入学习流程结构
- en: In listing 4.18, we create a synthetic multi-input classification dataset with
    both images and structured data. The images are of three dimensions, with shape
    (32, 32, 3). Each 3-D image is associated with a row vector in the structured
    data representing its attributes (a synthetic description of the image). The target
    labels have five classes, and we split out 20% of the data as a validation set.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表4.18中，我们创建了一个包含图像和结构化数据的合成多输入分类数据集。图像是三维的，形状为（32, 32, 3）。每个三维图像都与结构化数据中的一行向量相关联，该向量表示其属性（图像的合成描述）。目标标签有五个类别，我们将20%的数据作为验证集分割出来。
- en: Listing 4.18 Creating a synthetic multi-input classification dataset
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.18 创建合成多输入分类数据集
- en: '[PRE22]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Generates the image data
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 生成图像数据
- en: ❷ Generates the structured data
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 生成结构化数据
- en: ❸ Generates the classification labels of five classes
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 生成五个类别的分类标签
- en: It is quite intuitive to configure the IO API to accommodate multiple inputs—we
    need to input a list of placeholders only during the initialization of an AutoModel
    object, as shown in listing 4.19\. The placeholders can have the same type, such
    as two structured data placeholders, or different types. Their number aligns with
    the number of inputs (modalities). During the fitting and evaluation phase, we
    need to feed the data in the same order as the corresponding placeholders.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 配置IO API以适应多个输入相当直观——我们只需要在初始化AutoModel对象时输入一个占位符列表，如列表4.19所示。这些占位符可以具有相同的类型，例如两个结构化数据占位符，或者不同的类型。它们的数量与输入（模态）的数量相匹配。在拟合和评估阶段，我们需要按照相应的占位符顺序提供数据。
- en: Listing 4.19 Performing multi-input classification with AutoKeras IO API
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.19 使用AutoKeras IO API执行多输入分类
- en: '[PRE23]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Defines multiple inputs
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义多个输入
- en: ❷ Feeds multiple inputs to the AutoModel
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将多个输入馈送到AutoModel
- en: ❸ Evaluates the best found pipeline with the test set
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用测试集评估找到的最佳流程
- en: The training process and search algorithms are configured the same way as in
    the previous example.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程和搜索算法的配置与上一个示例相同。
- en: 4.4.3 Automated multi-output learning
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.3 自动多输出学习
- en: We can also use the IO API to deal with multiple outputs. This situation usually
    happens when we want to jointly address multiple tasks, such as predicting a person’s
    age and gender. A common pipeline structure for multi-output learning (or multitask
    learning) is shown in figure 4.6\. We use different heads here to represent different
    output targets, but the heads could also have the same type. For example, if we
    treat multilabel classification with *N* labels as a combination of *N* binary
    classification tasks, we can form a multi-output learning problem with *N* ClassificationHeads.
    The data input could also contain multiple inputs, as discussed in the previous
    example.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 IO API 来处理多个输出。这种情况通常发生在我们想要联合处理多个任务时，例如预测一个人的年龄和性别。多输出学习（或多任务学习）的常见管道结构如图
    4.6 所示。我们在这里使用不同的头来表示不同的输出目标，但头也可以具有相同的类型。例如，如果我们把具有 *N* 个标签的多标签分类视为 *N* 个二进制分类任务的组合，我们可以形成一个具有
    *N* 个 ClassificationHeads 的多输出学习问题。数据输入也可以包含多个输入，如前一个示例中讨论的那样。
- en: '![04-06](../Images/04-06.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![04-06](../Images/04-06.png)'
- en: Figure 4.6 Multi-output learning pipeline structure
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 多输出学习管道结构
- en: In listing 4.20, we generate a synthetic dataset with multiple inputs and multiple
    outputs to serve as a general example of multitask learning with multiple inputs.
    The inputs include both images and structured data, and the outputs cover classification
    and regression responses. When initializing the AutoModel, we input a list of
    input placeholders corresponding to the data types we’re providing and a list
    of heads corresponding to the different output targets. The full implementation
    is shown here.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 4.20 中，我们生成一个包含多个输入和多个输出的合成数据集，作为具有多个输入的多任务学习的通用示例。输入包括图像和结构化数据，输出涵盖分类和回归响应。当初始化
    AutoModel 时，我们输入一个与提供的数据类型相对应的输入占位符列表，以及一个与不同输出目标相对应的头列表。完整的实现如下所示。
- en: Listing 4.20 Multi-output learning with AutoKeras IO API
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.20 使用 AutoKeras IO API 的多输出学习
- en: '[PRE24]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ❶ Generates two input sources
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 生成两个输入源
- en: ❷ Generates two target responses
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 生成两个目标响应
- en: ❸ Specifies multiple output targets
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 指定多个输出目标
- en: Let’s display the best model to see what it looks like, as shown next.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们显示最佳模型，看看它的样子，如下所示。
- en: Listing 4.21 Displaying the best model
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.21 显示最佳模型
- en: '[PRE25]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: In figure 4.7, we can see that the model has a crossing structure connecting
    the two input sources and generating the two output targets from top to bottom.
    The image input is processed by a CNN branch, and an MLP branch processes the
    structured data input. We use the categorical encoding layer to transform the
    categorical features in the structured data into numerical vectors to feed into
    the MLP. For each instance, the output representations from the two branches are
    two vectors of length 800 and 32, respectively. They are concatenated to generate
    both classification and regression predictions.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 4.7 中，我们可以看到模型具有连接两个输入源并从上到下生成两个输出目标的交叉结构。图像输入由 CNN 分支处理，MLP 分支处理结构化数据输入。我们使用分类编码层将结构化数据中的分类特征转换为数值向量，以供
    MLP 使用。对于每个实例，两个分支的输出表示分别是长度为 800 和 32 的两个向量。它们被连接起来生成分类和回归预测。
- en: '![04-07](../Images/04-07.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![04-07](../Images/04-07.png)'
- en: Figure 4.7 The best searched multitask model
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 最佳搜索的多任务模型
- en: As these three examples show, unlike the task APIs (which trade off convenience
    for customizability), the IO API provides the flexibility to define the inputs
    and the outputs of the pipelines in the search space. It also enables the selection
    of search algorithms. However, at this point we don’t know much about the search
    space or how to customize it. We will explore the topic of search space design
    in the next two chapters.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如这三个示例所示，与任务 API（以定制性换取便利性）不同，IO API 提供了在搜索空间中定义管道输入和输出的灵活性。它还允许选择搜索算法。然而，到目前为止，我们对搜索空间或如何定制它知之甚少。我们将在下一章探讨搜索空间设计的话题。
- en: So far we have learned how to use AutoKeras to solve problems with AutoML techniques.
    However, AutoKeras does have some limitations. First, it is hard to automatically
    select models by their inferencing time and model size, which may be important
    for the final deployment of the machine learning model. Second, another limitation
    of AutoKeras, which is also the limitation of AutoML, is that it cannot take into
    account any knowledge of the dataset content. For example, it cannot understand
    the meaning of each column in the Titanic dataset. Therefore, it may not be able
    to design a better model than the human experts who have a deeper understanding
    of the problem. Third, AutoKeras is more about providing concise and easy-to-learn
    APIs to the users and producing a model with good performance, rather than producing
    the best model that beats all the state-of-the-art solutions.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了如何使用 AutoKeras 通过 AutoML 技术解决问题。然而，AutoKeras 确实存在一些局限性。首先，自动根据推理时间和模型大小选择模型比较困难，这对于机器学习模型的最终部署可能很重要。其次，AutoKeras
    的另一个局限性，也是 AutoML 的局限性，是它无法考虑任何关于数据集内容的知识。例如，它无法理解 Titanic 数据集中每一列的含义。因此，它可能无法设计出比那些对问题有更深入理解的专家更好的模型。第三，AutoKeras
    更多的是为用户提供简洁且易于学习的 API，并生成性能良好的模型，而不是生成击败所有最先进解决方案的最佳模型。
- en: Summary
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: AutoML allows you to create end-to-end ML solutions for different ML tasks by
    feeding in the dataset directly. You can achieve this in Python with the help
    of AutoKeras’s task APIs.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML 允许您通过直接输入数据集来创建针对不同机器学习任务的端到端 ML 解决方案。您可以使用 AutoKeras 的任务 API 在 Python
    中实现这一点。
- en: To apply AutoML to different tasks with AutoKeras, you need to clarify the data
    type and learning paradigm of the task at hand, such as multiclass or multilabel
    classification, so you can select the corresponding task API and settings.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要将 AutoML 应用于 AutoKeras 的不同任务，您需要明确当前任务的数据类型和学习范式，例如多类或多标签分类，以便您可以选择相应的任务 API
    和设置。
- en: With AutoKeras’s IO API, you can address tasks with multiple inputs and data
    types. You can also define different heads to generate multiple outputs for multitask
    learning.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AutoKeras 的 IO API，您可以处理具有多个输入和数据类型的任务。您还可以定义不同的头部，以生成多任务学习中的多个输出。
- en: The search space is usually tailored to different tasks. AutoKeras provides
    a default search space for each task to save you effort on search space design.
    To customize the search space for personalized use cases, you need to use the
    functional API, which will be introduced in the next chapter.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索空间通常针对不同的任务进行定制。AutoKeras 为每个任务提供默认的搜索空间，以节省您在搜索空间设计上的精力。为了针对个性化用例自定义搜索空间，您需要使用将在下一章中介绍的函数式
    API。
