- en: 11 Config Management architecture
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 配置管理架构
- en: Michael Madison
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔·麦迪逊
- en: This chapter covers
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Why configuration at scale is a challenge
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么大规模配置是一个挑战
- en: An overview of Anthos Config Management
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos Config Management概述
- en: Examples and case studies of ACM implementations showing the utility and versatility
    of the solution.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACM实施的示例和案例研究，展示了该解决方案的实用性和多功能性。
- en: In the world of application development, we always desire more speed and more
    capability as well as more applications that fulfill more tasks, automate more
    minutiae, run faster, and operate in locations closer to where they are actually
    used. The proliferation of smartphones, tablets, and IoT devices, as well as the
    continued advancement of computers into every part of our daily lives, drives
    the need for more compute power. Environmental factors, the availability of high-speed
    internet and other utilities, and government regulations are changing the way
    companies deploy resources. Depending on the circumstances, this could result
    in a concentration of compute resources in a few data centers, a move to mostly
    cloud-based compute, fragmenting to lots of “mini” data centers, or a combination
    of these solutions.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序开发的世界里，我们总是希望有更多的速度、更多的能力以及更多的应用程序来满足更多任务，自动化更多细节，运行得更快，并在更接近实际使用地点的地方运行。智能手机、平板电脑和物联网设备的普及，以及计算机在我们日常生活中的不断进步，推动了更多计算能力的需求。环境因素、高速互联网和其他公用事业的可获得性以及政府法规正在改变公司部署资源的方式。根据具体情况，这可能导致计算资源集中在几个数据中心，转向主要基于云的计算，碎片化为许多“微型”数据中心，或者这些解决方案的组合。
- en: Organizations rarely decide to reduce the total resources they manage. Although
    short-term reductions, consolidations, or even eliminations of applications might
    occur, most companies will be managing more tomorrow than today. This has been
    the path that application development has followed for the past 40 years or longer.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 组织很少决定减少他们管理的总资源。尽管可能会出现短期内的减少、整合甚至消除应用程序的情况，但大多数公司明天管理的资源将比今天更多。过去40年或更长时间以来，应用程序开发一直遵循这条道路。
- en: But the expanding use of Kubernetes has brought this problem into focus for
    many organizations as they come to grips with moving and managing thousands of
    VMs and applications in the Kubernetes landscape. Although many legacy tools would
    still work, using them in the same way would negate most of the advantages available
    with Kubernetes. On top of that, legacy toolsets are often disconnected from one
    another, forcing managers to make firewall changes in one tool, granting VM access
    in another, and setting up routing through a third. These challenges fall largely
    on the shoulders of IT operations teams who are charged with implementing and
    maintaining all of this infrastructure.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，随着Kubernetes的广泛应用，许多组织在处理将成千上万的虚拟机和应用程序迁移到Kubernetes环境中时，这个问题变得突出。尽管许多传统工具仍然可以使用，但以同样的方式使用它们将消除Kubernetes提供的许多优势。更不用说，传统工具集通常彼此脱节，迫使管理者在一个工具中更改防火墙设置，在另一个工具中授予虚拟机访问权限，在第三个工具中设置路由。这些挑战主要落在负责实施和维护所有这些基础设施的IT运维团队肩上。
- en: As more companies move to Kubernetes for their daily operations, the need for
    security professionals and managers to be confident in their ability to configure,
    administer, and audit Kubernetes clusters has become critical for business success.
    IT security groups are responsible for developing and implementing security controls
    around and within the IT infrastructure, including software, hardware, and physical
    limitations, policies, procedures, and guidance. Many companies adopt a tiered
    permissions model, allowing super users a greater subset of abilities without
    becoming full administrators. Because much of the work in Kubernetes is driven
    by a common definition language, expressed in JSON or YAML, the security framework
    should also be familiar to IT security teams who regularly work with Kubernetes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着越来越多的公司转向Kubernetes进行日常运营，安全专业人士和管理人员对其配置、管理和审计Kubernetes集群的能力充满信心，这对商业成功变得至关重要。IT安全团队负责在IT基础设施的各个方面开发和实施安全控制，包括软件、硬件和物理限制、政策、程序和指导。许多公司采用分层权限模型，允许超级用户拥有更大的能力子集，而不成为完整管理员。由于Kubernetes中的许多工作都是由一个通用的定义语言驱动的，这种语言以JSON或YAML的形式表达，因此安全框架也应该为那些经常与Kubernetes一起工作的IT安全团队所熟悉。
- en: To help organizations address this need, Google has created Anthos Config Management
    (ACM) to simplify the development, deployment, and maintenance of Kubernetes policies,
    resources, and configuration. In the next section, you’ll examine the full scope
    of challenges that ACM helps solve and the opportunities ACM provides to drive
    efficiencies within an organization.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助组织满足这一需求，谷歌创建了Anthos Config Management (ACM)，以简化Kubernetes策略、资源和配置的开发、部署和维护。在下一节中，你将了解ACM帮助解决的全面挑战以及ACM为提高组织效率提供的机遇。
- en: 11.1 What are we trying to solve?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 我们试图解决什么问题？
- en: Over time, businesses have moved processes to digital formats. Even without
    the internet as an engagement platform, companies have shifted their internal
    operations to rely on digital applications and communications. When that’s added
    to the massive drive to engage digital customers, companies’ need for compute
    power becomes greater than ever before, and it shows no signs of slowing. One
    of the newest aspects of computing, edge computing, is expected to be an over
    $155 billion market alone by 2030, according to Grandview Research ([http://mng.bz/oJnr](http://mng.bz/oJnr)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，企业已经将流程转移到数字格式。即使没有互联网作为参与平台，公司也已经将内部运营转移到依赖数字应用程序和通信。当这加上与数字客户的巨大互动需求相结合时，公司对计算能力的需要比以往任何时候都更大，而且没有放缓的迹象。根据Grandview
    Research的预测，到2030年，边缘计算这一最新计算领域预计将成为一个超过1550亿美元的市场([http://mng.bz/oJnr](http://mng.bz/oJnr))。
- en: Additionally, many businesses see greater efficiency by having these systems
    communicate with each other to automate their processes. The proliferation of,
    for example, ticket-based self-service software such as ServiceNow, personnel
    management solutions like Workday, and combined authentication and authorization
    services such as Okta encourage companies to expand their capabilities on-site
    and in the cloud. As companies pivot to depend more heavily on their staff’s development
    capabilities for mission-critical solutions, the complexity involved in the deployment
    of these applications increases with each new vendor they bring into their ecosystem.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，许多企业通过让这些系统相互通信来自动化他们的流程，从而提高了效率。例如，基于票务的自助服务软件如ServiceNow、人员管理解决方案如Workday以及结合认证和授权服务如Okta的普及，鼓励公司扩大其现场和云端的业务能力。随着公司转向更多地依赖员工的发展能力来应对关键任务解决方案，随着他们将其生态系统中的每个新供应商引入，这些应用的部署复杂性也在增加。
- en: The needs of any company diverge from their closest competitor as they design
    their unique value to customers, but most businesses have a digital presence both
    on-prem and in the cloud. Although some companies have used multiple data centers
    or colocation facilities to provide their redundant and reliable infrastructure,
    many have turned to cloud providers. But cloud providers’ best practices and user
    experiences can vary widely. Each cloud brought online by an operations team greatly
    increases their technical burden and operational overhead, as shown in figure
    11.1\. Even in the case of data centers designed to be identical, security controls
    and physical separation still impose barriers to their operation and maintainability.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 任何公司在设计其独特的客户价值时，其需求都会与最接近的竞争对手有所不同，但大多数企业都在本地和云端都有数字存在。尽管一些公司已经使用多个数据中心或互惠设施来提供其冗余和可靠的基础设施，但许多公司已经转向云服务提供商。但云服务提供商的最佳实践和用户体验可能差异很大。运营团队上线每个云都极大地增加了他们的技术负担和运营开销，如图11.1所示。即使在设计为相同的数据中心的情况下，安全控制和物理分离仍然对其运营和维护构成障碍。
- en: '![11-01](../../OEBPS/Images/11-01.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![11-01](../../OEBPS/Images/11-01.png)'
- en: Figure 11.1 Bringing multiple infrastructure platforms online adds considerable
    operations overhead.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 启用多个基础设施平台增加了相当大的运营开销。
- en: 'The size of a company’s digital footprint also adds complexity to the configuration
    and operation of their systems. Multiple working locations, more data centers,
    and a corresponding increase of the number of people involved in the management
    of these systems all add their own challenges. As an organization grows, introducing
    and using systemic security and configuration controls becomes vital. ACM addresses
    these challenges using the following central capabilities:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 公司的数字足迹大小也增加了其系统和操作的配置和运营复杂性。多个工作地点、更多的数据中心以及参与这些系统管理的人数相应增加，都带来了各自的挑战。随着组织的发展，引入和使用系统安全性和配置控制变得至关重要。ACM通过以下核心能力来解决这些挑战：
- en: Managing complexity
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理复杂性
- en: Workload observability and inspection
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作负载可观察性和检查
- en: Remediating and preventing problems when they do occur
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在问题发生时进行修复和预防
- en: Next, you’ll examine how ACM manages complexity in modern infrastructure.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将了解ACM如何管理现代基础设施的复杂性。
- en: 11.1.1 Managing complexity
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.1 管理复杂性
- en: You can configure compute infrastructure in innumerable ways, but most solutions
    do follow some general patterns. These solutions can generally be grouped by whether
    the system scales horizontally or vertically. For a company adopting or using
    a Kubernetes-based infrastructure, a similar decision must be made about the overall
    design of all the Kubernetes clusters at a company. A company using multiple,
    smaller clusters for different purposes (e.g., one or more per team) is implementing
    a horizontal scaling solution. A company using a smaller number of larger clusters
    (e.g., one each for Dev, Test, and Prod) is building vertical scalability into
    their Kubernetes infrastructure. Neither approach is better than the other, but
    a company should determine what fits best with their approach to deployments and
    software design.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以以无数种方式配置计算基础设施，但大多数解决方案都遵循一些通用模式。这些解决方案通常可以根据系统是横向扩展还是纵向扩展来分组。对于采用或使用基于Kubernetes的基础设施的公司，公司必须就所有Kubernetes集群的整体设计做出类似的决定。使用多个、较小集群（例如，每个团队一个或多个）用于不同目的的公司（例如）正在实施横向扩展解决方案。使用较少数量的大型集群（例如，每个用于开发、测试和生产）的公司正在将其Kubernetes基础设施构建到纵向可扩展性中。这两种方法没有一种是优于另一种的，但公司应确定哪种最适合其部署和软件设计方法。
- en: Geographic limitations, edge-processing needs, and telecommunications operations
    also impose restrictions on how clusters are delineated. Government regulations
    in certain countries prevent the egress of data from those regions, requiring
    the databases and application layers to be located inside the country. Even without
    government regulation, the operations of certain types of businesses, such as
    restaurants, retail stores, or even banks, might prefer a local processing system
    running a subset of applications that would benefit from, or require, a shorter
    communications loop.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 地理限制、边缘处理需求以及电信运营也对集群的划分方式施加了限制。某些国家的政府法规禁止数据从这些地区流出，要求数据库和应用层位于国内。即使没有政府监管，某些类型的业务（如餐馆、零售店，甚至银行）可能也更倾向于使用本地处理系统，运行能够从更短的通信循环中受益或需要的应用程序子集。
- en: In addition, large businesses require more staff to efficiently organize and
    operate the IT infrastructure. To mitigate single points of failure among IT personnel,
    developing simple processes that can be scaled out to multiple people is critical
    to long-term success.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，大型企业需要更多的人员来有效地组织和运营IT基础设施。为了减轻IT人员中的单点故障，开发可以扩展到多人的简单流程对于长期成功至关重要。
- en: 11.1.2 Transparency and inspection
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.2 透明度和检查
- en: Visibility and inspection of workloads and overall health of a Kubernetes cluster
    is outside the purview of this chapter (it is primarily covered in chapter 5).
    However, the plaintext representation of policies and configurations for all clusters
    afforded by Anthos Config Management can do a great deal on the frontend to ensure
    that appropriate policies are adhered to.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes集群的工作负载可见性和整体健康状况超出了本章的讨论范围（它主要在第5章中介绍）。然而，Anthos Config Management提供的所有集群的策略和配置的明文表示可以在前端做很多事情，以确保遵循适当的策略。
- en: The goal of Anthos Config Management is to maintain a cluster in a state specified
    by a policy directory stored in a Git repository. This policy directory exists
    separate from the clusters being managed and is stored in a text-based format.
    Thus, the policy directory itself can be used as a source of information about
    the configuration of the cluster. By using the features of the Git repo itself,
    the IT operations team can determine when a cluster is out of compliance and can
    easily track changes to a cluster’s configuration.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Anthos Config Management的目标是保持集群处于由存储在Git仓库中的策略目录指定的状态。这个策略目录存在于被管理集群之外，并以文本格式存储。因此，策略目录本身可以用作有关集群配置的信息来源。通过使用Git仓库本身的特性，IT运维团队能够确定集群何时不符合规范，并且可以轻松跟踪集群配置的变化。
- en: ACM provides a command-line utility, via the nomos command, to interrogate clusters
    directly and determine their current state. Operations teams can use nomos to
    diagnose the rollout of a change and determine whether an error or lag occurs
    that would be causing problems. Much of the information that is provided via nomos
    is visible in the Anthos UI[¹](#pgfId-1113011) within the Google Cloud console,
    showing what configuration version each cluster is currently running, as well
    as the overall state of the ACM installation. Also, the Kubernetes operator for
    the system logs events and information in the same manner as other containers
    and, thus, can be viewed in Cloud Logging and used in Cloud Monitoring alerts
    and metrics.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ACM通过nomos命令提供命令行工具，可以直接查询集群并确定其当前状态。运维团队可以使用nomos诊断更改的部署情况，并确定是否发生错误或延迟，这可能导致问题。nomos提供的大部分信息在Google
    Cloud控制台中的Anthos UI[¹](#pgfId-1113011)中可见，显示每个集群当前正在运行哪个配置版本，以及ACM安装的整体状态。此外，系统日志的Kubernetes操作员以与其他容器相同的方式记录事件和信息，因此可以在Cloud
    Logging中查看，并在Cloud Monitoring警报和指标中使用。
- en: 11.1.3 Remediating and preventing problems
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.3 补救和预防问题
- en: One of the major responsibilities of an IT operations team is to maintain system
    reliability and uptime. Knowing that a change has caused a disruption and being
    able to quickly isolate the problem and rapidly apply a remediation are critical
    tools in the team’s arsenal. On all three of these points, ACM brings unique features
    that enable the team to respond to situations as they occur.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: IT运维团队的主要职责之一是维护系统可靠性和正常运行时间。知道更改导致了中断，并且能够快速隔离问题并迅速应用补救措施，是团队武器库中的关键工具。在这三个要点上，ACM都带来了独特的功能，使团队能够应对发生的情况。
- en: Because ACM is driven from a Git repository, you can easily add guardrails and
    policy enforcement through existing pull request mechanisms or tie activity on
    one or many branches into a monitoring suite and bring additional alerting to
    bear after a change to the policies. Using the repo as the source of truth, the
    team can investigate what changes were applied at what times to narrow down any
    problematic configurations. Existing Git tooling can then be used to revert or
    fix the configuration. Due to ACM’s design, these changes normally take effect
    within a minute or two of the change being pushed to the policy repo.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因为ACM是由Git仓库驱动的，你可以通过现有的拉取请求机制轻松添加护栏和政策执行，或者将一个或多个分支上的活动与监控套件绑定，并在政策变更后带来额外的警报。使用仓库作为事实来源，团队可以调查在什么时间应用了哪些更改，以缩小任何问题配置的范围。然后可以使用现有的Git工具来回滚或修复配置。由于ACM的设计，这些更改通常在将更改推送到策略仓库后一分钟或两分钟内生效。
- en: In addition to fixing problems that have already been deployed, you can use
    existing CI/CD tooling and processes to verify configurations before they are
    allowed to take effect. Other tooling around Git, such as pull and merge requests,
    branching, and more, can also serve to allow multiple users to develop new policies,
    while permitting the organization the ability to approve those changes prior to
    deployment.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了修复已部署的问题外，你还可以使用现有的CI/CD工具和流程在配置生效之前验证配置。围绕Git的其他工具，如拉取和合并请求、分支等，也可以用来允许多个用户开发新的策略，同时允许组织在部署之前批准这些更改。
- en: ACM includes the ability to apply a configuration to a subset of clusters. Although
    we use this in our examples to deploy different versions of an application to
    clusters by region, the same functionality can be used to deploy changes in a
    controlled fashion, or to apply different roles per cluster. For example, a retail
    chain running a cluster in each store can deploy a new version of an application
    to a specific set of test stores before rolling it out to the entire chain. A
    company using different clusters for Dev, Test, and Prod environments can grant
    users different permissions based on the cluster while still taking advantage
    of a single policy repository.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ACM包括将配置应用于集群子集的能力。虽然我们在示例中使用它通过地区部署应用程序的不同版本到集群，但相同的功能也可以用来以受控的方式部署更改，或者为每个集群应用不同的角色。例如，每个商店运行一个集群的零售连锁店可以在将其推广到整个连锁店之前，将应用程序的新版本部署到特定的测试商店。使用不同集群进行开发、测试和生产环境的公司可以根据集群授予用户不同的权限，同时仍然可以利用单个策略仓库。
- en: 11.1.4 Bringing it together
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.4 整合一切
- en: All three of these problems are well handled with Anthos Config Management.
    By providing tools familiar to IT professionals and with a design that thrives
    in a highly distributed ecosystem, ACM can help teams manage large systems easily.
    In the next section, we will give a brief overview of how ACM works and the components
    that can be included with an installation.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个问题都可以通过 Anthos Config Management 得到很好的处理。通过提供IT专业人士熟悉的工具，以及在一个高度分布式的生态系统中茁壮成长的设计，ACM
    可以帮助团队轻松地管理大型系统。在下一节中，我们将简要概述ACM的工作原理以及可以包含在安装中的组件。
- en: 11.2 Overview of ACM
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 ACM概述
- en: Now that we have a good idea of the problems we are trying to solve with Anthos
    Config Management, let’s take a deeper look at the technical implementation of
    ACM. ACM works by way of a Kubernetes operator[²](#pgfId-1113032) deployed onto
    each cluster to be managed. A configuration file containing the canonical name
    of the cluster, a Git configuration, and a set of feature flags are also applied
    to the cluster. The operator uses the Git configuration to connect to a Git repository
    hosted in any accessible Git service containing the full configuration information
    for the cluster. The feature flags are switches to activate Config Sync, Policy
    Controller, or Hierarchy Controller, which will be covered later in this chapter.
    ACM uses the name of the cluster, along with the policy configurations in the
    Git repo, to add ephemeral tags to the cluster. These tags can then be used within
    the policy repo to modify which resources are deployed to each cluster.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对使用 Anthos Config Management 尝试解决的问题有了很好的了解，让我们更深入地看看ACM的技术实现。ACM通过在每个要管理的集群上部署一个Kubernetes操作员[²](#pgfId-1113032)来实现。一个包含集群规范名称、Git配置和一组功能标志的配置文件也被应用到集群上。操作员使用Git配置连接到任何可访问的Git服务中托管的Git仓库，该仓库包含集群的完整配置信息。功能标志是开关，用于激活配置同步、策略控制器或层次结构控制器，这些将在本章后面介绍。ACM使用集群名称以及Git仓库中的策略配置，为集群添加临时标签。然后，这些标签可以在策略仓库中使用，以修改部署到每个集群的资源。
- en: 'ACM works on a minimum-footprint mentality: it does not try to take over the
    entire Kubernetes cluster. Rather, the operator knows what objects are defined
    in the policy configuration and works to manage only those specific objects. This
    allows multiple deployment mechanisms to work in parallel on a single Kubernetes
    cluster without stepping on each other. However, using multiple tools does add
    the additional burden of needing to know which tools have deployed each object.
    ACM includes a specific annotation on objects it manages,[³](#pgfId-1113043) but
    that may not look the same for all tools. As we will see later, ACM repos can
    be configured in an unstructured mode that allows an organization to continue
    using existing tools that support outputting to YAML or JSON while still using
    ACM to perform the actual deployment and management processes.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ACM 的工作基于最小化占用心态：它不会试图接管整个Kubernetes集群。相反，操作员知道策略配置中定义了哪些对象，并致力于仅管理那些特定对象。这允许多个部署机制在单个Kubernetes集群上并行工作，而不会相互干扰。然而，使用多个工具确实增加了额外的负担，需要知道哪些工具部署了每个对象。ACM在其管理的对象上包含一个特定的注解[³](#pgfId-1113043)，但可能不是所有工具看起来都一样。正如我们稍后将会看到的，ACM仓库可以配置为非结构化模式，允许组织继续使用支持输出到YAML或JSON的现有工具，同时仍然使用ACM执行实际的部署和管理过程。
- en: The operator syncs every few minutes, and this frequency can be adjusted in
    the configuration, depending on the needs of the organization. ACM can use both
    public and private repos, with appropriate credentials, as the policy repository.
    In addition, the Git configuration can be pointed at a directory below the top
    level of the repository. This can be useful if the Git repository uses a templating
    engine or even application code where a subdirectory can be used to store the
    policies.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 操作员每隔几分钟同步一次，这个频率可以在配置中调整，取决于组织的需要。ACM可以使用公共和私有仓库，并使用适当的凭据作为策略仓库。此外，Git配置可以指向仓库顶层以下的目录。如果Git仓库使用模板引擎或甚至应用程序代码，其中可以使用子目录来存储策略，这可能很有用。
- en: 'You can deploy Anthos Config Management in three primary ways, depending on
    the type of Kubernetes cluster you are using: a Google Kubernetes Engine (GKE)
    cluster deployed on GCP, a GKE on VMware cluster, or another flavor of Kubernetes.
    For GKE on GCP, enabling ACM is a simple matter of selecting a checkbox on the
    cluster configuration page. For GKE on VMware, ACM is enabled by default and cannot
    be disabled. Only clusters that do not fit into either category require manual
    configuration to install the operator: retrieve the most recent version of the
    operator’s custom resource definition file, provided by Google, and apply it to
    the cluster.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以根据所使用的 Kubernetes 集群类型以三种主要方式部署 Anthos Config Management：在 GCP 上部署的 Google
    Kubernetes Engine (GKE) 集群、VMware 上的 GKE 集群，或 Kubernetes 的其他版本。对于 GCP 上的 GKE，启用
    ACM 只需在集群配置页面上勾选一个复选框。对于 VMware 上的 GKE，ACM 默认启用且无法禁用。只有不符合上述任一类别的集群需要手动配置来安装操作符：获取由
    Google 提供的操作符自定义资源定义文件的最新版本，并将其应用到集群中。
- en: 'At this point, all flavors of Kubernetes have the operator installed and running,
    but ACM still needs to be enabled and told where to pull policies from. This is
    done by creating an operator configuration object and applying it to the cluster,
    along with whatever Git credentials are required. Multiple methods of Git authentication
    are supported, including public repos with no authentication, SSH key pairs, personal
    access tokens, and Google service accounts. Some of these methods require specific
    information to be loaded into a Kubernetes Secret for the operator to load it
    properly. The configuration object allows specifying proxies for the Git repository,
    if needed. In addition to the Git connection information, the configuration object
    can contain settings to enable or disable the individual components named earlier,
    as well as name the cluster for use within ACM policy rules. Note that the ConfigManagement
    object created on the cluster and the configuration YAML used by gcloud to initially
    install ACM are similar but are not the same. As ACM’s capabilities expand, more
    options will be added to this configuration object, but the current structure
    of the initial deployment YAML follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，所有版本的 Kubernetes 都已安装并运行操作符，但 ACM 仍需启用并指定从哪里拉取策略。这通过创建一个操作符配置对象并将其应用到集群中完成，同时附带所需的
    Git 凭据。支持多种 Git 认证方法，包括无需认证的公共仓库、SSH 密钥对、个人访问令牌和 Google 服务帐户。其中一些方法需要将特定信息加载到
    Kubernetes Secret 中，以便操作符正确加载。配置对象允许指定 Git 仓库的代理，如果需要的话。除了 Git 连接信息外，配置对象还可以包含设置以启用或禁用之前提到的单个组件，以及为
    ACM 策略规则中的集群命名。请注意，在集群上创建的 ConfigManagement 对象和 gcloud 用于最初安装 ACM 所使用的配置 YAML
    相似，但并不相同。随着 ACM 功能的扩展，将向此配置对象添加更多选项，但初始部署 YAML 的当前结构如下：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The operator on the individual clusters is the mechanism ACM uses to update
    the objects on each cluster. Although ACM uses a central Git repository, because
    the individual clusters reach out to fetch the configuration, this greatly simplifies
    connectivity between the cluster and the repository. The repository does not push
    out the configs, so we do not need to introduce additional complexity or security
    ingress holes, nor does the central repository need to know about every individual
    cluster beforehand.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 单个集群上的操作符是 ACM 用于更新每个集群上对象的机制。尽管 ACM 使用中央 Git 仓库，但由于单个集群会主动拉取配置，这大大简化了集群与仓库之间的连接性。仓库不会推送配置，因此我们不需要引入额外的复杂性或安全入口漏洞，中央仓库也不需要事先了解每个单个集群。
- en: 11.2.1 ACM policy structure
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.1 ACM 策略结构
- en: The ACM policy directory must be in one of two supported formats, either hierarchy
    or unstructured, with hierarchy as the default. This setting is also reflected
    in the operator configuration object referenced earlier, in the spec.sourceFormat
    key. In both cases, the policy directory defines Kubernetes objects, which are
    then examined and applied by the ACM operator on each of the clusters connected
    to the Git repository. ACM itself uses some of these objects internally to determine
    which resources to apply to the current cluster.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ACM 策略目录必须采用两种支持的格式之一，要么是层次结构，要么是无结构，其中层次结构是默认格式。此设置也反映在前面提到的操作符配置对象中，在 spec.sourceFormat
    键中。在两种情况下，策略目录定义 Kubernetes 对象，然后 ACM 操作符将检查并应用这些对象到连接到 Git 仓库的每个集群。ACM 本身使用其中一些对象内部来确定要应用到当前集群的资源。
- en: In addition to the overall format of the repository, you can use multiple repositories
    to configure clusters. When using the enableMultiRepo functionality, a single
    repository is used as the root repository (and may be hierarchy or unstructured),
    whereas all other repositories are used to configure objects in a single namespace.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 除了存储库的整体格式外，您还可以使用多个存储库来配置集群。当使用 enableMultiRepo 功能时，单个存储库用作根存储库（可能是层次结构或非结构化），而所有其他存储库都用于在单个命名空间中配置对象。
- en: Hierarchy
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 层次结构
- en: In a hierarchy repository, top-level directories in the policy directory separate
    configuration files based on purpose and scope—system, clusterregistry, cluster,
    and namespaces—as shown in table 11.1.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在层次结构存储库中，策略目录中的顶级目录根据目的和范围（系统、集群注册、集群和命名空间）来区分配置文件，如表 11.1 所示。
- en: Table 11.1 Top-level directories in a hierarchy repository
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11.1 层次结构存储库中的顶级目录
- en: '| Directory | Purpose |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 目录 | 目的 |'
- en: '| System | Configs related to the policy repository itself, such as the version
    of the deployed configuration. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 系统 | 与策略存储库本身相关的配置，例如已部署配置的版本。 |'
- en: '| Clusterregistry | Stores Cluster and ClusterSelector objects, which are used
    together to select subsets of clusters to restrict where a specific object is
    applied to. Cluster definitions attach specific tags to a cluster by name; ClusterSelectors
    can then use these tags to select a set of clusters meeting a certain set of requirements.
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 集群注册 | 存储集群和 ClusterSelector 对象，这些对象一起用于选择集群的子集，以限制特定对象的应用位置。集群定义通过名称给集群附加特定的标签；ClusterSelectors
    可以使用这些标签来选择满足一定要求的集群集合。 |'
- en: '| Cluster | Contains objects that are defined for the entire cluster, except
    for namespaces. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 集群 | 包含为整个集群定义的对象，但不包括命名空间。 |'
- en: '| Namespaces | Contains objects that are assigned to one or more specific namespaces,
    as well the Namespace and NamespaceSelector definitions. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 命名空间 | 包含分配给一个或多个特定命名空间的对象，以及命名空间和 NamespaceSelector 定义。 |'
- en: ACM in hierarchy mode uses a concept of “abstract” namespaces, a grouping of
    one or more actual namespaces, which should share a set of Kubernetes objects.
    For instance, you might define a Role or ConfigMap in each namespace that a team
    uses. When ACM analyzes the repository, any object defined in an abstract namespace
    is automatically copied into every namespace beneath it. These abstract namespaces
    can also be nested within each other to have multiple layers of abstraction. For
    example, you may place all application development teams under an app-dev abstract
    namespace, and then each team in a separate abstract namespace within app-dev.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在层次结构模式下，ACM 使用“抽象”命名空间的概念，即一个或多个实际命名空间的组合，这些命名空间应共享一组 Kubernetes 对象。例如，您可能在每个团队使用的命名空间中定义一个
    Role 或 ConfigMap。当 ACM 分析存储库时，任何在抽象命名空间中定义的对象都会自动复制到其下所有的命名空间中。这些抽象命名空间也可以相互嵌套，以形成多个抽象层。例如，您可以将所有应用程序开发团队放置在
    app-dev 抽象命名空间下，然后在 app-dev 内部为每个团队创建一个单独的抽象命名空间。
- en: Although ACM will copy an object in an abstract namespace to all child namespaces,
    you can use a NamespaceSelector to restrict what namespaces the object is applied
    to. Using the app-dev example, we want to deploy a ConfigMap to multiple namespaces
    across multiple teams, but only to the namespaces that contain finance-related
    applications. By applying a label to those namespaces, we can then define a NamespaceSelector
    to select only those namespaces, and then link the ConfigMap config object to
    the NamespaceSelector. Although these selectors do have their purpose in a hierarchy
    repo, their primary use is in an unstructured repo. Further, in a hierarchy repo,
    a specific namespace must be a child of the folder containing the object, as well
    as matching the selector. A full example in an unstructured repo with the configuration
    objects defined can be found in the Evermore Industries example at the end of
    the chapter.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ACM会将抽象命名空间中的对象复制到所有子命名空间中，但您可以使用 NamespaceSelector 来限制对象应用到的命名空间。以 app-dev
    为例，我们希望将 ConfigMap 部署到多个团队跨多个命名空间中，但仅限于包含与财务相关应用程序的命名空间。通过给这些命名空间应用标签，我们就可以定义一个
    NamespaceSelector 来选择这些命名空间，然后将 ConfigMap 配置对象链接到 NamespaceSelector。尽管这些选择器在层次结构存储库中确实有其用途，但它们的主要用途是在非结构化存储库中。此外，在层次结构存储库中，特定的命名空间必须是包含对象的文件夹的子文件夹，并且必须匹配选择器。一个包含配置对象定义的非结构化存储库的完整示例可以在本章末尾的
    Evermore Industries 示例中找到。
- en: 'Once you have a specific namespace name to be created, you also should decide
    on which abstract namespace to inherit from. This may mean that certain objects
    must be defined at a higher level than you would normally do, simply to have them
    inherited by the individual namespaces. Once you have the name and the abstract
    namespaces, you create a folder with that name at the bottom of that set of namespace
    directories. Inside the newly created directory, you must also create the Kubernetes
    Namespace object with the same name. All the objects defined in the abstract namespaces
    are also created inside the leaf namespace. Let’s look at an example with the
    following folder structure:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了要创建的特定命名空间名称，你也应该决定从哪个抽象命名空间继承。这可能意味着某些对象必须定义在比通常更高的级别，只是为了让它们被各个命名空间继承。一旦有了名称和抽象命名空间，你就在命名空间目录集的底部创建一个具有该名称的文件夹。在新建的目录内，你还必须创建具有相同名称的
    Kubernetes 命名空间对象。在抽象命名空间中定义的所有对象也会在叶子命名空间内创建。让我们通过以下文件夹结构来举一个例子：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For the production abstract namespace, we are defining a role and binding for
    developers in the developer-rbac.yaml and a Kubernetes service account for the
    applications in the app-service-account.yaml. Because the weather-app-prod, front-office-prod,
    and marketing namespaces are under the production abstract namespace, the role,
    role binding, and Kubernetes service account will be created in all three namespaces.
    Due to how ACM analyzes the policy repository, actual namespaces cannot have subdirectories
    in their folder, and every leaf directory must be an actual namespace with the
    corresponding namespace declaration in the directory. Failing to adhere to this
    restriction will cause a configuration error when ACM is deployed.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生产抽象命名空间，我们在 developer-rbac.yaml 中为开发者定义了一个角色和绑定，在 app-service-account.yaml
    中为应用程序定义了一个 Kubernetes 服务账户。由于 weather-app-prod、front-office-prod 和 marketing
    命名空间位于生产抽象命名空间下，因此角色、角色绑定和 Kubernetes 服务账户将在所有三个命名空间中创建。由于 ACM 分析策略存储库的方式，实际命名空间在其文件夹中不能有子目录，并且每个叶子目录都必须是一个实际命名空间，并在目录中有相应的命名空间声明。如果未能遵守此限制，当
    ACM 部署时将导致配置错误。
- en: In addition to abstract namespaces, objects can use NamespaceSelectors (which
    are declared in a manner similar to ClusterSelectors, covered later in this chapter),
    to affect only a subset of namespaces within the object’s scope. In the previous
    example, the app-service-account can use a selector to deploy only to the weather-app-prod
    and front-office-prod namespaces, and not the marketing namespace. However, NamespaceSelectors
    in hierarchy repositories operate only on namespaces in the current folder tree.
    For example, even if the namespace selector included weather-app-staging in its
    criteria, the app-service-account defined under the production abstract namespace
    would never be applied to the staging namespace because the weather-app-staging
    directory is not a child of the directory that contains the app-service-account.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 除了抽象命名空间外，对象还可以使用 NamespaceSelectors（其声明方式类似于稍后在本章中介绍的 ClusterSelectors），以影响对象作用域内的子集命名空间。在之前的例子中，app-service-account
    可以使用选择器仅部署到 weather-app-prod 和 front-office-prod 命名空间，而不是 marketing 命名空间。然而，在层次存储库中，NamespaceSelectors
    仅在当前文件夹树中的命名空间上操作。例如，即使命名空间选择器在其标准中包括了 weather-app-staging，位于生产抽象命名空间下的 app-service-account
    定义永远不会应用于 staging 命名空间，因为 weather-app-staging 目录不是包含 app-service-account 的目录的子目录。
- en: Pros and cons
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 优缺点
- en: A hierarchy repository simplifies the deployment of objects to a subset of namespaces,
    because an object can be deployed only to the namespaces at or below the level
    of the configuration file in the repository. With the use of NamespaceSelectors,
    an organization can further restrict what namespaces an object can be deployed
    to. This can be especially useful if there are multiple ways to group namespaces.
    For example, a development team might group namespaces, but they may also need
    to be grouped by function (e.g., frontend, middleware) or business unit. Using
    a hierarchy repo, you must choose one “primary” grouping strategy; if an object
    needs to be deployed to multiple namespaces that are not grouped together, the
    object would be placed at a higher level in the repo and restricted using a NamespaceSelector.
    This organization makes it very simple to start determining which namespaces an
    object deploys to, because it can be only those defined at or below the object’s
    definition file. Cluster-level resources and resources that are primarily used
    to deliver ACM also have dedicated folders where they must be located, making
    it easier to find a given object.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 分层仓库简化了将对象部署到命名空间子集的过程，因为对象只能部署到仓库中配置文件所在级别或以下的命名空间。使用NamespaceSelectors，组织可以进一步限制对象可以部署到的命名空间。如果有多种分组命名空间的方法，这可能特别有用。例如，一个开发团队可能会按命名空间分组，但他们可能还需要按功能（例如，前端、中间件）或业务单元分组。使用分层仓库，您必须选择一个“主要”的分组策略；如果对象需要部署到多个未分组的命名空间，则该对象将被放置在仓库的更高层级，并使用NamespaceSelector进行限制。这种组织方式使得确定对象部署到的命名空间变得非常简单，因为它们只能是定义文件中定义的或以下级别的那些。集群级别的资源和主要用于交付ACM的资源也有专门的文件夹，它们必须位于这些文件夹中，这使得找到特定对象变得更加容易。
- en: However, this rigid structure can cause difficulties when implementing ACM at
    your organization. Many organizations already have at least a basic familiarity
    with Kubernetes and use existing toolsets and processes to deploy Kubernetes resources
    and applications. Because cross-namespace objects must be configured in different
    folders in a hierarchy repository, this can complicate the integration of ACM
    into an existing CI/CD pipeline. An organization should weigh the benefits of
    the automatic duplication of objects afforded by a hierarchy repository with the
    restrictions it imposes.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种严格的结构在您组织实施ACM时可能会造成困难。许多组织已经至少对Kubernetes有基本的了解，并使用现有的工具集和流程来部署Kubernetes资源和应用程序。由于跨命名空间的对象必须在分层仓库的不同文件夹中进行配置，这可能会使ACM集成到现有的CI/CD管道中变得复杂。组织应权衡分层仓库提供的对象自动复制的好处与它施加的限制。
- en: Unstructured
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 非结构化
- en: Unlike a hierarchy repo, an unstructured repo has no special directory structure.
    Teams are free to use whatever style of organization they wish, such as grouping
    files and objects by application or team. Using an unstructured repo, however,
    prevents ACM from using the concept of an abstract namespace to automatically
    create a single object in multiple namespaces. To compensate for this restriction,
    an object must declare either a namespace, or a NamespaceSelector. Though NamespaceSelectors
    behave in the same manner as in a hierarchy repository, without the restriction
    of only operating on namespaces in the same folder tree, greater care must be
    taken to make sure only the desired namespace(s) actually matches the selector.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 与分层仓库不同，非结构化仓库没有特殊的目录结构。团队可以自由选择他们想要的任何组织风格，例如按应用程序或团队分组文件和对象。然而，使用非结构化仓库会阻止ACM使用抽象命名空间的概念来在多个命名空间中自动创建单个对象。为了弥补这一限制，对象必须声明一个命名空间或一个NamespaceSelector。尽管NamespaceSelectors在分层仓库中的行为与在非分层仓库中相同，但它们不受仅在同一文件夹树中操作命名空间的限制，因此必须更加小心，以确保实际匹配的命名空间（或命名空间）确实是所需的。
- en: Pros and cons
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 优缺点
- en: When an organization is already using a templating engine to deploy objects
    to Kubernetes, an unstructured repo becomes even more favorable. Because most
    templating engines, including Helm, include the ability to export the completed
    Kubernetes objects to a local directory, you can use the output from those commands
    and simply place the generated configurations directly into the ACM policy directory.
    An unstructured ACM repo does not care about the exact placement of configurations
    under the policy directory, so this can provide a less-stressful upgrade path
    when implementing ACM.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个组织已经使用模板引擎将对象部署到Kubernetes时，非结构化存储库变得更加有利。因为大多数模板引擎，包括Helm，都包括将完成的Kubernetes对象导出到本地目录的能力，你可以使用这些命令的输出，并将生成的配置直接放置到ACM策略目录中。非结构化ACM存储库不关心配置在策略目录下的确切位置，因此在实施ACM时，这可以提供一条压力较小的升级路径。
- en: However, unstructured repositories have a couple of wrinkles when it comes to
    namespace assignment. Configurations in an unstructured repository cannot infer
    the namespace they should be assigned to, so users must explicitly assign all
    objects. This can result in the deployment of an object to an unintended namespace
    if the selector is defined or used improperly. In addition, finding a resource
    becomes more complicated because no implicit relationship exists between the location
    of the configuration file and the deployment namespace.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在命名空间分配方面，非结构化存储库存在一些问题。非结构化存储库中的配置无法推断它们应该分配到的命名空间，因此用户必须显式地分配所有对象。如果选择器定义或使用不当，这可能导致对象被部署到意外的命名空间。此外，由于配置文件的位置与部署命名空间之间没有隐含关系，查找资源变得更加复杂。
- en: Multiple Repository mode
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 多存储库模式
- en: Configuring ACM to pull from multiple repositories allows organizations to permit
    individual teams to manage their own namespaces while still taking advantage of
    many of the benefits of ACM. When the cluster configuration object is set to enable
    multiple repository mode ([http://mng.bz/zmB6](http://mng.bz/zmB6)), using the
    enableMultiRepo flag, the spec.git set of fields is not supported. Instead, you
    create a separate RootSync object to hold the configuration details for the root
    repository.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 将ACM配置为从多个存储库中提取，允许组织允许各个团队管理自己的命名空间，同时仍然可以利用ACM的许多好处。当集群配置对象设置为启用多个存储库模式（[http://mng.bz/zmB6](http://mng.bz/zmB6)），使用enableMultiRepo标志时，spec.git字段集不支持。相反，你创建一个单独的RootSync对象来保存根存储库的配置细节。
- en: With enableMultiRepo set, an organization can define the repository to be used
    for each individual namespace. As with the RootSync object, these individual RepoSync
    objects contain the configuration for fetching from a Git repository as well as
    the directory in that repository for the top of the policy tree. Even when using
    multiple repository mode, the root repository can still define objects to be managed
    in any namespace. In the case of a conflict between the root repository and the
    individual namespace repositories, the root repository’s version is the one used.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当enableMultiRepo被设置时，组织可以定义每个单独命名空间要使用的存储库。与RootSync对象一样，这些单独的RepoSync对象包含从Git存储库提取配置以及该存储库中策略树顶部的目录的配置。即使在多存储库模式下使用，根存储库也可以定义在任何命名空间中管理的对象。在根存储库与单个命名空间存储库之间发生冲突的情况下，使用的是根存储库的版本。
- en: The root repository of a multiple repository setup functions identically to
    a configuration that is not in multiple repository mode; only the configuration
    of how to fetch the repository changes. Therefore, multiple repository mode is
    an ideal solution to allow operations and security teams to impose policies, RBAC
    rules, and Istio rules, configure namespaces, and so on while enabling application
    teams to manage and deploy their own applications into individual namespaces.
    The team managing the root repository also needs to add the appropriate policies
    to define which objects the individual repositories can modify. This is done by
    defining a custom Role or ClusterRole, or using one of the built-in roles, and
    then using a RoleBinding to attach the namespace’s worker service account to that
    role. This allows the operations team to offload much of the work of configuring
    a given application to the teams and defining custom permissions per team if needed,
    rather than requiring the central team to validate or perform the work themselves.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '多仓库设置的根仓库的功能与不在多仓库模式中的配置相同；只是获取仓库的配置方式发生了变化。因此，多仓库模式是一个理想的解决方案，允许操作和安全团队实施策略、RBAC规则、Istio规则，配置命名空间等，同时使应用团队能够管理和部署自己的应用程序到各自的命名空间中。管理根仓库的团队还需要添加适当的策略来定义各个仓库可以修改的对象。这是通过定义自定义角色或
    ClusterRole，或使用内置角色之一，然后使用 RoleBinding 将命名空间的worker服务帐户附加到该角色来完成的。这允许操作团队将配置特定应用程序的大部分工作转移到团队，并在需要时为每个团队定义自定义权限，而不是要求中央团队验证或自行执行工作。 '
- en: 11.2.2 ACM-specific objects
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.2 ACM特定的对象
- en: Although ACM can manage any valid Kubernetes object, custom objects can adjust
    how the system operates and applies new configurations.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然ACM可以管理任何有效的Kubernetes对象，但自定义对象可以调整系统的操作方式并应用新的配置。
- en: ConfigManagement
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigManagement
- en: ACM uses this object to determine how and where to fetch the policy configurations
    to be used for the cluster. Deploying a ConfigManagement object to the cluster
    activates ACM for that cluster. This object also defines the name of the cluster,
    as used inside ACM, and determines which plug-ins (Config Sync, Policy Controller,
    and Hierarchy Controller) are active for the cluster.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ACM使用此对象来确定如何以及在哪里获取用于集群的策略配置。将 ConfigManagement 对象部署到集群中激活了该集群的ACM。此对象还定义了ACM内部使用的集群名称，并确定哪些插件（配置同步、策略控制器和层次控制器）对集群是激活的。
- en: RootSync/RepoSync
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: RootSync/RepoSync
- en: When the cluster is running in multiple repository mode, the configuration for
    fetching policies, including Git URLs and Secrets, are not stored in the ConfigManagement
    object but rather in either the RootSync object (for the core repository) or in
    RepoSync objects in each namespace.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当集群以多个仓库模式运行时，用于获取策略的配置，包括 Git URL 和 Secrets，不会存储在 ConfigManagement 对象中，而是在
    RootSync 对象（对于核心仓库）或每个命名空间中的 RepoSync 对象中。
- en: Cluster
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Cluster
- en: A cluster config is created in the ACM policy repo and allows users to attach
    labels to a specific cluster by cluster name. These labels are then used in ClusterSelectors
    to select specific types of clusters. In a hierarchy repo, the Cluster definitions
    must be in the clusterregistry directory.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在ACM策略仓库中创建集群配置，允许用户通过集群名称将标签附加到特定集群。然后，这些标签在 ClusterSelectors 中被用来选择特定类型的集群。在层次仓库中，集群定义必须在
    clusterregistry 目录中。
- en: ClusterSelector
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ClusterSelector
- en: This object uses the common Kubernetes labelSelectors pattern[⁴](#pgfId-1113200)
    to select a subset of clusters. The ClusterSelector can then be used by an object,
    such as a Deployment, ConfigMap, or Secret, to deploy only that object in clusters
    matching the selector. In a hierarchy repo, these must be in the clusterregistry
    directory.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此对象使用常见的Kubernetes labelSelectors模式[⁴](#pgfId-1113200)来选择集群的子集。ClusterSelector然后可以被对象（如Deployment、ConfigMap或Secret）使用，以仅在匹配选择器的集群中部署该对象。在层次仓库中，这些必须在
    clusterregistry 目录中。
- en: NamespaceSelector
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: NamespaceSelector
- en: Similar to the ClusterSelector, this selector also uses labelSelectors, but
    it is used to select namespaces instead. It is primarily used in unstructured
    repos or in a hierarchy repo as an additional method to limit to which namespaces
    an object is deployed.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与 ClusterSelector 类似，此选择器也使用 labelSelectors，但它用于选择命名空间。它主要用于非结构化仓库或作为在层次仓库中限制对象部署到哪些命名空间的附加方法。
- en: HierarchyConfiguration
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: HierarchyConfiguration
- en: These objects are declared in individual namespaces and point to their parent.
    This sets up the hierarchical namespace relationship that the Hierarchy Controller
    uses. Note that using the Hierarchy Controller is not the same as a hierarchy
    repository; the Hierarchy Controller will be explored further later in the chapter.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这些对象在单独的命名空间中声明，并指向其父对象。这设置了 Hierarchy Controller 所使用的层次命名空间关系。请注意，使用 Hierarchy
    Controller 与使用层次存储库不同；Hierarchy Controller 将在本章的后续部分进一步探讨。
- en: 11.2.3 Additional components
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.3 其他组件
- en: Although not strictly part of ACM itself, Config Connector, Policy Controller,
    and Hierarchy Controller greatly enhance the functionality of ACM and your Kubernetes
    environments. This section gives only a short introduction to each component,
    but all three are demonstrated in the examples at the end of the chapter. Google
    is also integrating additional components as development on Anthos continues.
    Please refer to the online documentation at [http://mng.bz/Q8rw](http://mng.bz/Q8rw)
    for the most up-to-date information on available add-ons.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Config Connector、Policy Controller 和 Hierarchy Controller 并非 ACM 本身的一部分，但它们极大地增强了
    ACM 和您的 Kubernetes 环境的功能。本节仅对每个组件进行了简要介绍，但所有三个组件都在本章末尾的示例中进行了演示。随着 Anthos 的发展，Google
    也在集成额外的组件。请参阅[http://mng.bz/Q8rw](http://mng.bz/Q8rw)上的在线文档，获取有关可用附加组件的最新信息。
- en: Config Connector
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Config Connector
- en: Config Connector ([https://cloud.google.com/config-connector/docs](https://cloud.google.com/config-connector/docs))
    is an add-on to Kubernetes that allows you to configure GCP resources, such as
    SQL instances, storage buckets, and Compute Engine VMs, using Kubernetes objects.
    A full example of the structure of one of these objects is provided in the Evermore
    Industries case study in this chapter. With proper permissioning, this add-on
    allows a developer proficient with Kubernetes to create several types of GCP resources,
    including SQL databases, networks, BigQuery datasets and tables, Compute Instances,
    Pub/Sub topics and subscriptions, and storage buckets. In addition, these configurations
    can reference each other, simplifying configuration and allowing for a single
    source of truth.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Config Connector ([https://cloud.google.com/config-connector/docs](https://cloud.google.com/config-connector/docs))
    是 Kubernetes 的一个附加组件，允许您使用 Kubernetes 对象配置 GCP 资源，例如 SQL 实例、存储桶和 Compute Engine
    虚拟机。本章中提供了其中一个此类对象结构的完整示例。在适当的权限下，此附加组件允许熟悉 Kubernetes 的开发者创建多种类型的 GCP 资源，包括 SQL
    数据库、网络、BigQuery 数据集和表、Compute 实例、Pub/Sub 主题和订阅以及存储桶。此外，这些配置可以相互引用，简化配置并允许单一事实来源。
- en: Users can also use Kubernetes Secrets to store sensitive information, such as
    passwords, and then use that information in Config Connector resources. Each of
    the Config Connector objects also includes a status section, describing the current
    state of the resource as it is created or updated in GCP.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 用户还可以使用 Kubernetes Secrets 来存储敏感信息，例如密码，然后使用这些信息在 Config Connector 资源中。每个 Config
    Connector 对象还包括一个状态部分，描述了资源在 GCP 中创建或更新时的当前状态。
- en: Policy Controller
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Policy Controller
- en: Although the Kubernetes role-based access control system can finely control
    what a specific user is permitted to do at the namespace and object-type level,
    it does not enforce arbitrary policies, or policies on specific objects. For example,
    we may want all Pods deployed in a specific namespace to declare CPU limits for
    the containers, or require that all namespaces include a custom label that indicates
    the cost center that should be billed for the resource usage. We may also want
    to protect a specific deployment and prevent modifications to that specific resource,
    while still allowing other resources in the same namespace to be modified. This
    is where Policy Controller comes into play.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Kubernetes 的基于角色的访问控制系统能够在命名空间和对象类型级别精细控制特定用户可以执行的操作，但它不强制执行任意策略或特定对象上的策略。例如，我们可能希望所有在特定命名空间中部署的
    Pod 都为容器声明 CPU 限制，或者要求所有命名空间都包含一个自定义标签，以指示应向其收费的资源使用成本中心。我们可能还希望保护特定的部署并防止对该特定资源的修改，同时允许同一命名空间中的其他资源被修改。这正是
    Policy Controller 发挥作用的地方。
- en: Built from the open source OPA Gatekeeper project ([http://mng.bz/ydpG](http://mng.bz/ydpG)),
    Policy Controller ([http://mng.bz/X5mG](http://mng.bz/X5mG)) is an admission controller
    that checks and verifies any creation of, or update to, an object against the
    policies that have been declared and loaded to the cluster. Each policy consists
    of a constraint template, which is written using Rego to perform the test needed,
    and a constraint, which provides the arguments to the template for the specific
    policy. A set of existing templates, known as a template library, is provided
    by default when Policy Controller is enabled, though users can create customized
    constraint templates as well. Users can then create constraints that use these
    policy templates to enforce specific restrictions on the cluster.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 由开源OPA Gatekeeper项目([http://mng.bz/ydpG](http://mng.bz/ydpG))构建的策略控制器([http://mng.bz/X5mG](http://mng.bz/X5mG))是一个准入控制器，它检查并验证任何对象的创建或更新是否符合已声明并加载到集群中的策略。每个策略由一个约束模板组成，该模板使用Rego编写以执行所需的测试，以及一个约束，它为特定策略提供模板的参数。当启用策略控制器时，默认提供一组现有的模板，称为模板库，但用户也可以创建定制的约束模板。然后，用户可以创建使用这些策略模板来对集群实施特定限制的约束。
- en: Because we are utilizing ACM, we can pair the policy constraints with ClusterSelectors
    to restrict which clusters a particular policy applies to, locking some down while
    allowing a more relaxed set of rules on others.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在使用ACM，我们可以将策略约束与ClusterSelectors配对，以限制特定策略应用于哪些集群，锁定一些集群的同时，在另一些集群上允许更宽松的规则集。
- en: Hierarchy Controller
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 层级控制器
- en: Hierarchy Controller ([http://mng.bz/Mlr7](http://mng.bz/Mlr7)) is the newest
    add-on to fall under the ACM umbrella and is still in open beta at the time of
    writing. This controller substantially changes how namespaces work within Kubernetes
    by allowing for inheritance between namespaces and is driven from the Kubernetes
    Working Group for Multitenancy ([https://github.com/kubernetes-sigs/multi-tenancy](https://github.com/kubernetes-sigs/multi-tenancy)).
    Though similar to how abstract namespaces work in a hierarchy ACM repo, this component
    takes it a step further by allowing objects to be actively replicated from a parent
    namespace to a child. This is especially useful when using an ACM repo that does
    omit Secrets as part of the repo (due to the security considerations involved).
    By configuring the Hierarchy Controller to replicate a Secret from a parent to
    a child or children, a single Secret can be replicated to multiple namespaces,
    simplifying the amount of rework or manual intervention required.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 层级控制器([http://mng.bz/Mlr7](http://mng.bz/Mlr7))是最新加入ACM体系下的附加组件，并在撰写本文时仍处于公开测试阶段。该控制器通过允许命名空间之间的继承，实质性地改变了Kubernetes中命名空间的工作方式，并由Kubernetes多租户工作组([https://github.com/kubernetes-sigs/multi-tenancy](https://github.com/kubernetes-sigs/multi-tenancy))推动。尽管与ACM仓库中抽象命名空间在层级结构中的工作方式相似，但该组件通过允许对象从父命名空间主动复制到子命名空间，进一步扩展了这一功能。这在使用ACM仓库且仓库中不包含机密信息（由于涉及的安全考虑）时特别有用。通过配置层级控制器从父命名空间复制机密到子或多个子命名空间，可以简化重工作量或手动干预的需求。
- en: One other useful feature of Hierarchy Controller is the synergy between the
    controller and Cloud Logging. When the enablePodTreeLabels flag is set on the
    ACM config file, Hierarchy Controller sets flags on all pods, including those
    in child namespaces. This also indicates how far down the hierarchy tree the pod
    is located. Figure 11.2 contains an example.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 层级控制器的一个其他有用功能是控制器与云日志之间的协同作用。当在ACM配置文件上设置enablePodTreeLabels标志时，层级控制器会在所有Pod上设置标志，包括子命名空间中的Pod。这也指示了Pod在层级树中的位置有多深。图11.2包含了一个示例。
- en: '![11-02](../../OEBPS/Images/11-02.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![11-02](../../OEBPS/Images/11-02.png)'
- en: Figure 11.2 Namespaces and Pods with hierarchy-related labels when enablePodTreeLabels
    is enabled
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 当启用enablePodTreeLabels时，具有与层级相关的标签的命名空间和Pod
- en: As you can see in this example, we have the eom-prod and eom-staging namespaces
    as children of the end-of-month namespace. The end-of-month namespace is a child
    of accounting, which is a child of the corporate namespace. As you can see in
    figure 11.2, the hierarchy labels applied to the reporter-backend Pods correspond
    to the namespace hierarchy. In Kubernetes, you can query by the presence of a
    label, as well as by the value. So, if we wanted to see all Pods under the accounting
    and child namespaces, we can run kubectl --all-namespaces get pods -l accounting.tree
    .hnc.x-k8s.io/depth, and it would fetch both instances of the reporter backend.
    These labels also appear in Cloud Logging and can be used to fetch Pods in multiple
    namespaces there.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在本例中可以看到，我们有 eom-prod 和 eom-staging 命名空间作为月末命名空间的孩子。月末命名空间是会计命名空间的孩子，而会计命名空间又是公司命名空间的孩子。如图
    11.2 所示，应用后端 Pods 上的层级标签对应着命名空间层级。在 Kubernetes 中，您可以按标签的存在性以及标签值进行查询。因此，如果我们想查看会计及其子命名空间下的所有
    Pods，我们可以运行 `kubectl --all-namespaces get pods -l accounting.tree .hnc.x-k8s.io/depth`，这将检索到报告后端的两个实例。这些标签也出现在云日志中，可以用来在多个命名空间中检索
    Pods。
- en: 11.3 Examples and case studies
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 示例和案例研究
- en: ACM is built on top of Kubernetes objects, operating within the cluster life
    cycle to efficiently manage the state of the cluster. So far, we have seen the
    components of ACM; in the next section, let’s examine three case studies in detail.
    Each of these fictional companies is either using Kubernetes currently and wants
    to optimize their deployment or is moving to Kubernetes for the first time; each
    will use ACM to perform slightly different functions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ACM 是建立在 Kubernetes 对象之上的，在集群生命周期内运行以高效管理集群的状态。到目前为止，我们已经看到了 ACM 的组件；在下一节中，我们将详细检查三个案例研究。这些虚构的公司中，每个要么目前正在使用
    Kubernetes 并希望优化其部署，要么是第一次迁移到 Kubernetes；每个都将使用 ACM 来执行略微不同的功能。
- en: Our first company, Evermore Industries, has decided to use a single, large cluster
    with many nodes. All their application teams will run their Dev, QA, and production
    environments in parallel namespaces. Evermore wants to take advantage of GCP resources
    whenever possible, but their application developers do not have a lot of experience
    with infrastructure as code (IaC) tools. The core infrastructure team does have
    experience in IaC but lacks sufficient members to provision everything the application
    teams desire. Management has decided to allow the application teams to manage
    portions of their own cloud infrastructure but still wants to impose certain guidelines
    and policy rails to prevent out-of-control expenditures. Finally, due to the multitude
    of applications in the company and the variable permission levels involved, a
    service mesh is needed to isolate and control traffic.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一家公司 Evermore Industries 已经决定使用一个由许多节点组成的大型集群。他们所有的应用团队将在并行命名空间中运行他们的开发、测试和质量保证环境。Evermore
    希望尽可能利用 GCP 资源，但他们的应用开发者对基础设施即代码（IaC）工具的经验不多。核心基础设施团队在 IaC 方面有经验，但缺乏足够的成员来提供应用团队所需的所有资源。管理层已经决定允许应用团队管理他们自己的云基础设施的一部分，但仍希望施加某些指南和政策轨道以防止无序支出。最后，由于公司中应用程序的多样性和涉及的权限级别不同，需要一个服务网格来隔离和控制流量。
- en: Village Linen, LLC, was founded approximately two decades ago and previously
    ran all their infrastructure locally in two data centers near their headquarters.
    Partially due to a change in ownership at one of their data centers, but also
    due to bad results on past high-traffic shopping days, the company has decided
    to use the cloud to enable rapid scalability, while keeping several core functions
    in their one remaining data center. However, corporate leadership wishes to retain
    the ability to run their entire application stack solely from the local data center
    and has mandated that the two environments be as close to identical as possible
    and that failover should be as simple and quick as possible. Village Linen also
    wants to allow developers the freedom to manage their own namespaces, without
    accidentally affecting other applications and without creating a lot of overhead
    to approve each change.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 村庄亚麻公司，LLC 大约二十年前成立，之前在其总部附近的两个数据中心本地运行所有基础设施。部分原因是其中一个数据中心的所有权发生变化，但也由于过去高流量购物日的糟糕结果，该公司决定使用云来实现快速可扩展性，同时保持其剩余的一个数据中心中的几个核心功能。然而，公司领导希望保留仅从本地数据中心运行整个应用程序堆栈的能力，并要求两个环境尽可能相似，并且故障转移应尽可能简单和快速。村庄亚麻还希望允许开发者自由管理自己的命名空间，而不会意外影响其他应用程序，也不会因批准每个变更而产生大量开销。
- en: Our final company, Ambiguous Rock Feasting, runs several hundred restaurants
    across the United States and Canada and has started expanding into Europe and
    Asia. Currently, their onsite applications (including inventory control, payroll,
    FOH systems, scheduling, and accounting) are updated via a monthly patch process
    that pushes the changes to the individual stores. This requires specialized networking
    and can be temperamental at times. The company wishes to pivot to a solution that
    does not require their central IT network to maintain persistent connections to
    the individual stores. They have also had problems in the past modifying their
    deployment processes and technology when adding a new application to the suite,
    as well as when trying to deploy targeted versions of the software to different
    regions.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后一家公司，模糊岩石盛宴，在美国和加拿大拥有数百家餐厅，并开始向欧洲和亚洲扩张。目前，他们的现场应用程序（包括库存控制、工资、前厅系统、调度和会计）通过每月补丁流程更新，将更改推送到各个门店。这需要专门的网络，有时可能会出现不稳定。该公司希望转向一种不需要他们的中央
    IT 网络持续连接到各个门店的解决方案。他们过去在添加新应用程序到套件以及尝试将软件的目标版本部署到不同地区时，也遇到过修改他们的部署流程和技术的问题。
- en: 11.3.1 Evermore Industries
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.1 永恒工业
- en: For Evermore Industries, the simplicity of only having one large cluster to
    manage was key. However, managing the large number of namespaces, users, permissions,
    and GCP resources was proving too much for their IT operations. Thus, they turned
    to ACM, Policy Controller, and Config Connector to take some of the heavy load.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于永恒工业来说，只需管理一个大集群的简单性是关键。然而，管理大量的命名空间、用户、权限和 GCP 资源对他们的 IT 运维来说证明是过于繁重。因此，他们转向
    ACM、策略控制器和配置连接器来分担一些繁重的工作。
- en: During a short proof of concept at the beginning of their migration, the IT
    operations team realized that an unstructured repo would allow them to more easily
    attach specific policies to individual namespaces (such as applying consistent
    rules to production namespaces) while also allowing the use of team-based rules
    without requiring a large amount of duplication. The unstructured repository also
    permitted the IT security team to easily restrict which users had permission to
    modify specific folders in the repo. Thus, a developer on Team Griffins could
    not accidentally delete something from Team Unicorns, and no application team
    members were allowed to modify the global policies. This reduced, but did not
    eliminate, the amount of configuration review needed for each change.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在迁移初期进行的一次简短的概念验证中，IT 运维团队意识到，一个非结构化的仓库可以让他们更容易地将特定策略附加到单个命名空间（例如，对生产命名空间应用一致的规则）的同时，也允许使用基于团队的规则，而无需大量重复。非结构化仓库还允许
    IT 安全团队轻松限制哪些用户有权修改仓库中的特定文件夹。因此，格里芬团队的开发者不可能意外删除独角兽团队的东西，并且不允许任何应用程序团队成员修改全局策略。这减少了每个变更所需的配置审查量，但并未消除。
- en: Although Evermore has been using Kubernetes for a few years, their CI/CD process[⁵](#pgfId-1113280)
    uses a templating engine (Helm) to deploy directly to the cluster. This setup
    has caused a few problems in the past, and management has decided to move away
    from users having direct access to make changes to the prod namespace directly,
    including the CI/CD service accounts. Because an unstructured repo does not mandate
    any particular organization for the config elements in the directory, Evermore
    has decided to continue to use their templating engine but write the configs directly
    to the ACM repo and create pull requests when a new version is to be deployed.
    Because these actions can quickly be validated by the operations team administrators,
    they can be quickly deployed to the active repo.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Evermore已经使用Kubernetes几年了，但他们的CI/CD流程[⁵](#pgfId-1113280)使用模板引擎（Helm）直接部署到集群。这种设置在过去造成了一些问题，管理层已决定不再允许用户直接访问prod命名空间进行更改，包括CI/CD服务账户。由于非结构化存储库不强制要求目录中的配置元素属于任何特定组织，Evermore已决定继续使用他们的模板引擎，但将配置直接写入ACM存储库，并在需要部署新版本时创建拉取请求。因为这些操作可以迅速由运营团队管理员验证，所以它们可以迅速部署到活动存储库。
- en: 'In addition, several application teams have expressed interest in using GCP
    resources to offload some of the workloads for their applications. Primarily,
    these teams are interested in Cloud SQL, Pub/Sub, and storage buckets. Because
    the application teams have almost no one with experience using IaC tools, or with
    GCP in general, Evermore will be using Config Connector to allow the teams to
    remain in the Kubernetes space for all deployment needs, as well as removing the
    need to configure and train users to access both Kubernetes and GCP itself. Let’s
    take a look at the repo outline, shown here:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，几个应用团队表示有兴趣使用GCP资源来卸载他们应用程序的一些工作负载。主要，这些团队对Cloud SQL、Pub/Sub和存储桶感兴趣。由于应用团队几乎没有人有使用IaC工具或GCP的经验，Evermore将使用Config
    Connector允许团队在所有部署需求中保持Kubernetes空间，同时消除配置和培训用户访问Kubernetes和GCP本身的必要性。让我们看一下存储库概要，如下所示：
- en: '[PRE2]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We will not go into detail on every object and file created in this repo, but
    this outline gives us a place to start with the structure Evermore has chosen.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细介绍在这个存储库中创建的每个对象和文件，但这个概要为我们提供了一个起点，以了解Evermore所选择的架构。
- en: 'In an unstructured repo, the policy directory is not permitted to be at the
    top level of the Git repository, so the company has chosen to place it in a policies
    directory one level down. Within that directory, objects can be placed at any
    level, so the IT operations team has placed a set of common namespace selectors
    in the namespace_selectors directory. One of these is the production selector,
    as shown next:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在非结构化存储库中，策略目录不允许位于Git存储库的顶层，因此公司选择将其放置在一级以下的策略目录中。在该目录内，对象可以放置在任何级别，因此IT运营团队在namespace_selectors目录中放置了一套常见的命名空间选择器。其中之一是生产选择器，如下所示：
- en: '[PRE3]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To simplify the work for the application teams, IT operations also defined
    a selector that would normally only reference one namespace as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化应用团队的工作，IT 运营团队也定义了一个选择器，该选择器通常只引用一个命名空间，如下所示：
- en: '[PRE4]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To prevent massive changes in the event a new project is created, all Config
    Connector objects defined by the teams use the namespace selector method to choose
    the appropriate namespace to deploy their objects to. For example:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止在创建新项目时发生大规模变更，所有由团队定义的 Config Connector 对象都使用命名空间选择器方法来选择适当的命名空间以部署其对象。例如：
- en: '[PRE5]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the global directory are policies defined by the IT operations team that
    apply across the cluster for both RBAC and Policy Controller. In the RBAC directory,
    the namespace-scoped roles for Dev/QA and production are defined separately. The
    roles use NamespaceSelectors to apply to multiple namespaces with one configuration.
    NamespaceSelectors are used via an annotation, and all namespace-scoped objects
    in an unstructured repo must declare either a namespace directly (via metadata.namespace)
    or use a NamespaceSelector. Here is the basic production role most developers
    will receive:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在全局目录中，IT运营团队定义了适用于整个集群的RBAC和策略控制器策略。在RBAC目录中，Dev/QA和生产环境的命名空间范围角色分别定义。这些角色使用NamespaceSelectors通过一个配置应用到多个命名空间。NamespaceSelectors通过注解使用，非结构化存储库中的所有命名空间范围对象必须直接声明一个命名空间（通过metadata.namespace）或使用NamespaceSelector。以下是大多数开发者将收到的基本生产角色：
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The policy_controller directory is where Evermore has decided to put all their
    Policy Controller constraints. In addition to constraints requiring the definition
    of container limits and restrictions on the Istio[⁶](#pgfId-1113370) Service Mesh,
    the IT operations team has also added the following constraint to force teams
    to define the environment and team for a given namespace:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: policy_controller目录是Evermore决定放置所有他们的Policy Controller约束的地方。除了需要定义容器限制和对Istio[⁶](#pgfId-1113370)服务网格的限制之外，IT运维团队还添加了以下约束，以强制团队为给定的命名空间定义环境和团队：
- en: '[PRE7]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In addition to requiring the labels to be set on namespaces, this constraint
    also limits what the valid values are. The Policy Controller infrastructure allows
    for the creation of custom constraint templates, but Evermore has been able to
    implement all their desired policies with those from the provided library.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 除了要求在命名空间上设置标签之外，此约束还限制了有效值的范围。Policy Controller基础设施允许创建自定义约束模板，但Evermore已经能够使用提供的库实现所有他们希望实施的政策。
- en: The namespaces directory in the global folder holds configurations that are
    managed by IT operations and are either not used by any application team or are
    used by most or all teams. For example, this includes the Istio namespace and
    the Config Connector project namespace. In addition, subfolders underneath this
    folder contain Secrets, ConfigMaps, and Deployments that would be used across
    the system. The IT operations staff has placed some of the general Istio configs
    as well as configs that should be replicated to multiple namespaces (including
    a contact information ConfigMap that can be mounted via environment variables
    in each application) in this structure.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 全局文件夹中的命名空间目录包含由IT运维管理的配置，这些配置要么未被任何应用团队使用，要么被大多数或所有团队使用。例如，这包括Istio命名空间和Config
    Connector项目命名空间。此外，此文件夹下的子文件夹包含将在整个系统中使用的Secrets、ConfigMaps和Deployments。IT运维人员已将一些通用的Istio配置以及应复制到多个命名空间（包括可以通过每个应用程序的环境变量挂载的联系人信息ConfigMap）的配置放置在此结构中。
- en: For each team’s folder, the rbac and namespaces directories are handled by the
    individual application teams, though the changes must still be approved by a member
    of IT operations via a pull request. The namespace directory holds the namespace
    declarations for each application and environment, whereas the rbac directory
    holds the RoleBindings and ClusterRoleBindings for each user.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个团队的文件夹，rbac和命名空间目录由各个应用程序团队处理，尽管更改仍必须通过IT运维人员成员的pull request进行批准。命名空间目录包含每个应用程序和环境的命名空间声明，而rbac目录包含每个用户的RoleBindings和ClusterRoleBindings。
- en: Inside each of the application folders (reconciler, storefront, etl, etc.),
    three folders exist for each environment. These folders are tied into the CI/CD
    processes that already exist for each application. The CI/CD pipelines were already
    configured to generate the Kubernetes objects to be loaded onto a cluster, so
    the teams changed the destination to output to a set of files in the appropriate
    environment’s directory. This CI/CD process also triggers an automatic pull request
    with the change, which can then be quickly approved and processed by a member
    of the IT operations staff.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个应用程序文件夹（reconciler、storefront、etl等）内部，每个环境都存在三个文件夹。这些文件夹与每个应用程序已存在的CI/CD流程相连接。CI/CD管道已经配置为生成要加载到集群上的Kubernetes对象，因此团队将目标更改为输出到适当环境目录中的一组文件。此CI/CD流程还会触发一个自动的pull
    request，然后可以快速由IT运维人员成员批准和处理。
- en: Evermore chose this configuration for their repo because it best suits their
    needs at the present time. However, they are using an unstructured repo, so changing
    the directory structure is a low-cost option, if needed. Other companies might
    choose to concentrate all RBAC-related objects into a single directory, or to
    eliminate the concept of a “team” altogether and organize everything based on
    the individual applications. The unstructured repo allows the freedom to organize
    your policies in a manner that makes the most sense for your organization, instead
    of being restricted to a namespace-centered structure.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Evermore选择这种配置用于他们的仓库，因为它最适合他们当前的需求。然而，他们正在使用一个无结构的仓库，因此如果需要，更改目录结构是一个低成本的选择。其他公司可能会选择将所有RBAC相关的对象集中到一个目录中，或者完全消除“团队”的概念，并根据单个应用程序组织一切。无结构仓库允许您以对组织最有意义的方式组织策略，而不是被限制在以命名空间为中心的结构中。
- en: 11.3.2 Village Linen, LLC
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.2 Village Linen, LLC
- en: Village Linen has decided to go forward with a hierarchy repo, but they are
    going to use Hierarchy Controller to help with automatic replication of some of
    their Secrets and ConfigMaps. They are running GKE on GCP, as well as a GKE on
    VMware in their existing data center and want both to operate almost identically
    inside the cluster.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: Village Linen 决定采用分层仓库，但他们将使用 Hierarchy Controller 来帮助自动复制他们的一些 Secrets 和 ConfigMaps。他们正在
    GCP 上运行 GKE，同时在现有的数据中心中运行 VMware 上的 GKE，希望两者在集群内部几乎可以完全相同地运行。
- en: 'Disaster recovery is an important problem for corporate management, but management
    understands that data replication can sometimes be a problem when handling failover.
    Therefore, the architects have developed a system that allows for users to use
    both the cloud and the on-prem application layer but uses a single database cluster
    in the cloud. The database is replicated locally (the configuration of the replication
    is not included or covered here), and a configuration change directs the applications
    to use the standby database located in the data center. The repo generally looks
    as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 灾难恢复是企业管理的重大问题，但管理层明白在处理故障转移时数据复制有时可能成为问题。因此，架构师们开发了一个系统，允许用户同时使用云和本地应用程序层，但在云中使用单个数据库集群。数据库在本地进行复制（此处不包括或覆盖复制配置），配置更改将应用程序指向数据中心中位于的数据中心的备用数据库。仓库通常如下所示：
- en: '[PRE8]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Starting from the bottom, we have a definition for the repo that contains the
    current version of the policies. In the clusterregistry directory, we have cluster
    definitions for the cluster in the local data center, as well as the cluster in
    GCP. We also have selectors defined for each of these clusters so that we can
    restrict resources in the namespaces directory. The cloud cluster declaration
    and selector, for example, are as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 从底层开始，我们有一个包含当前版本策略的仓库定义。在 clusterregistry 目录中，我们定义了本地数据中心中的集群以及 GCP 中的集群。我们还为这些集群中的每一个定义了选择器，以便我们可以在
    namespaces 目录中限制资源。例如，云集群声明和选择器如下：
- en: '[PRE9]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the cluster directory, we have configurations that apply to the cluster
    as a whole. These include ClusterRoles and ClusterRoleBindings and Policy Controller
    constraints. By default, Hierarchy Controller only propagates RBAC Roles and RoleBindings
    from parent to child namespaces. However, Village Linen wants to use Hierarchy
    Controller to synchronize Secrets and config maps from the central namespace to
    the application and project namespaces. This way, Secrets can be applied directly
    to the central namespace and replicated automatically without needing to be checked
    into a Git repository. The modified HNCConfiguration follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在 cluster 目录中，我们有适用于整个集群的配置。这些包括 ClusterRoles 和 ClusterRoleBindings 以及 Policy
    Controller 约束。默认情况下，Hierarchy Controller 只从父命名空间传播 RBAC 角色和角色绑定到子命名空间。然而，Village
    Linen 想要使用 Hierarchy Controller 从 central 命名空间同步 Secrets 和 config maps 到应用程序和项目命名空间。这样，Secrets
    可以直接应用于 central 命名空间，并自动复制，无需将其检查到 Git 仓库中。修改后的 HNCConfiguration 如下：
- en: '[PRE10]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Moving up to the namespaces directory, we have a top-level file to define a
    set of RBAC roles to be created in each namespace. Village Linen can then bind
    these roles at either the applications abstract namespace (which would apply the
    bindings to the website and inventory namespaces), or to the explicitly defined
    namespaces to control who has access to these roles.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 向上移动到 namespaces 目录，我们有一个顶层文件来定义在每个命名空间中要创建的一组 RBAC 角色。Village Linen 可以将这些角色绑定到应用程序抽象命名空间（这将将这些绑定应用于网站和库存命名空间），或者绑定到显式定义的命名空间，以控制谁可以访问这些角色。
- en: 'The directory here defines a total of four namespaces: central, website, inventory,
    and village-linen-ac15e6. The last namespace matches the project ID used to deploy
    resources for use with these clusters (also the location where the cloud GKE cluster
    is deployed). The two application namespaces share a service account definition,
    though this will create two separate service accounts, one in each namespace.
    In the central namespace, we declare a ConfigMap, which tells the applications
    which database to use, either the Cloud SQL or the on-prem cluster.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此目录定义了总共四个命名空间：central、website、inventory 和 village-linen-ac15e6。最后一个命名空间与用于部署这些集群资源的项目
    ID 匹配（也是云 GKE 集群部署的位置）。两个应用程序命名空间共享一个服务账户定义，尽管这将创建两个独立的服务账户，一个在每个命名空间中。在 central
    命名空间中，我们声明了一个 ConfigMap，它告诉应用程序使用哪个数据库，无论是 Cloud SQL 还是本地集群。
- en: 'In each of the “child” namespaces (website, inventory, and village-linen-ac15e6),
    the repository has a HierarchyConfiguration object that enables the Hierarchy
    Controller to propagate objects from parent to child:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个“子”命名空间（网站、库存和 village-linen-ac15e6）中，仓库都有一个 HierarchyConfiguration 对象，它使
    Hierarchy Controller 能够从父级传播对象到子级：
- en: '[PRE11]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In this case, all the “child” namespaces inherit from a common parent, but it
    is possible to “stack” these namespaces into a chain. For example, we could introduce
    another namespace—applications—which inherits from central and modify inventory
    and website to inherit from applications instead. Performing this type of stacked
    hierarchy allows for a finer control of what is replicated, as well as adds additional
    tagging to the logs, if enabled.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，所有“子”命名空间都继承自一个共同的父级，但可以将这些命名空间“堆叠”成链。例如，我们可以引入另一个命名空间——applications，它继承自中央，并将库存和网站修改为从
    applications 继承。执行此类堆叠层次结构可以更精细地控制要复制的对象，如果启用，还可以为日志添加额外的标记。
- en: When enabling Hierarchy Controller for a given cluster, an additional option
    can be selected, which includes the tree labels on Pods. These labels indicate
    the hierarchy relationship for the Pod and can be used both with command-line
    tools and in Cloud Logging, to filter for logs that descend from a given namespace.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当为特定集群启用 Hierarchy Controller 时，可以选择一个附加选项，该选项包括 Pods 上的树标签。这些标签表示 Pod 的层次关系，可以与命令行工具和
    Cloud Logging 一起使用，以过滤来自给定命名空间的日志。
- en: 'Because Village Linen is using a hierarchy repo, explicitly defining the metadata
    .namespace field is not required for objects in the namespaces directory. However,
    the namespace itself is required to be explicitly defined; Village Linen has chosen
    to place these definitions in the namespace.yaml files, though that is not required.
    The objects defined in the website and inventory namespaces are used to enable
    the multiple repository functionality covered next. However, the Cloud SQL cluster
    is defined in the final folder of the namespaces directory. The cloud_sql.yaml
    defines the SQL database, instance, and user as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 Village Linen 使用分层仓库，所以对于 namespaces 目录中的对象，不需要显式定义 .namespace 字段。然而，需要显式定义命名空间本身；Village
    Linen 选择将这些定义放在 namespace.yaml 文件中，尽管这不是必需的。在网站和库存命名空间中定义的对象用于启用下一节中提到的多仓库功能。但是，Cloud
    SQL 集群是在 namespaces 目录的最后一个文件夹中定义的。cloud_sql.yaml 文件如下定义了 SQL 数据库、实例和用户：
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, Config Connector allows references both to other Config Connector
    objects (the instanceRef declarations in the previous code snippet) and Secrets.
    Config Connector can also pull information from ConfigMaps. For security reasons,
    the db-creds Secret is not stored in the ACM repo. However, because the Hierarchy
    Controller is configured to replicate Secrets and ConfigMaps, we can manually
    create or update the Secret in the central namespace, and the Hierarchy Controller
    will handle the replication to the application and project namespaces. When Config
    Connector reconciles the next time, the new password will be used for the user.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，Config Connector 允许引用其他 Config Connector 对象（前一个代码片段中的 instanceRef 声明）和
    Secrets。Config Connector 还可以从 ConfigMaps 中提取信息。出于安全原因，db-creds Secret 没有存储在 ACM
    仓库中。然而，由于 Hierarchy Controller 被配置为复制 Secrets 和 ConfigMaps，我们可以手动在中央命名空间中创建或更新
    Secret，Hierarchy Controller 将处理复制到应用程序和项目命名空间。当 Config Connector 下次进行协调时，将使用新密码为用户。
- en: All the Config Connector configurations include an annotation with a cluster
    selector. This references the cluster selector defined in the clusterregistry
    directory for the cloud installation of GKE. Because Config Connector works to
    create GCP resources from Kubernetes objects, it is active only on GKE in GCP
    clusters. The company did not enable Config Connector in the local cluster, so
    trying to deploy these resources would fail. Even if Config Connector were enabled
    on the local cluster, deploying the resources there should not have any effect
    and would probably cause more troubleshooting problems, so we only deploy them
    to the cloud cluster.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 所有 Config Connector 配置都包含一个带有集群选择器的注解。这引用了在 GKE 云安装中 clusterregistry 目录中定义的集群选择器。由于
    Config Connector 旨在从 Kubernetes 对象创建 GCP 资源，因此它仅在 GCP 集群的 GKE 上处于活动状态。公司没有在本地集群中启用
    Config Connector，因此尝试部署这些资源将会失败。即使 Config Connector 在本地集群中启用，部署这些资源在那里也不会有任何影响，可能会引起更多的故障排除问题，所以我们只将它们部署到云集群。
- en: With this configuration, if Village Linen needs to switch from the cloud database
    back to a local database, a simple change to the database_location_config should
    be made. After deploying and pushing the updated configuration, the individual
    applications would need to be restarted.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此配置，如果Village Linen需要从云数据库切换回本地数据库，只需对database_location_config进行简单更改。部署并推送更新后的配置后，单个应用程序需要重新启动。
- en: 'In the directory structure outlined earlier, each application namespace contains
    a repo-sync file. These objects are used to implement multiple repository mode:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面概述的目录结构中，每个应用程序命名空间都包含一个repo-sync文件。这些对象用于实现多个仓库模式：
- en: '[PRE13]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: By using multiple repository mode, Village Linen can create separate repositories
    for each namespace, allowing application teams a simpler experience when modifying
    Kubernetes objects (including the Deployment, Services, and persistent volumes)
    for their application. This arrangement also restricts the teams from accidentally
    deploying something outside of their namespace. The operations team is still able
    to add items to each namespace using the core repository, and these exist in parallel
    with the namespace-specific objects. In the event of a conflict, the core repository’s
    version is the one used, preventing the application teams from overriding policies,
    service accounts, Secrets, and so on that the operations team has already defined.
    In addition, because the operations team has restricted which objects the namespace’s
    worker can modify using RBAC, the individual repositories are sandboxed to control
    only a limited set of objects and cannot grant themselves permissions unless the
    operations team allows it.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用多个仓库模式，Village Linen可以为每个命名空间创建单独的仓库，使得应用程序团队在修改Kubernetes对象（包括部署、服务和持久卷）时拥有更简单的体验。这种安排也限制了团队意外部署其命名空间之外的内容。操作团队仍然可以使用核心仓库向每个命名空间添加项目，这些项目与特定命名空间的对象并行存在。在发生冲突的情况下，核心仓库的版本将被使用，防止应用程序团队覆盖操作团队已经定义的策略、服务帐户、机密等。此外，由于操作团队已通过RBAC限制了命名空间工作员可以修改的对象，因此单个仓库被沙盒化，仅控制一组有限的对象，并且除非操作团队允许，否则不能授予自身权限。
- en: For Village Linen, ACM provides a convenient location for all core configurations
    to be centrally located and updated, while freeing the application teams to control
    their own namespaces. It also provides a convenient audit trail when configurations
    change. When either the local data center cluster or the cloud cluster fails for
    any reason, a new cluster can be spun up and connected to the ACM repo, rapidly
    and automatically deploying the full operational stack.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Village Linen，ACM提供了一个方便的位置，以便所有核心配置可以集中管理和更新，同时释放应用程序团队控制他们自己的命名空间。它还在配置更改时提供了一个方便的审计跟踪。当本地数据中心集群或云集群因任何原因失败时，可以快速自动启动一个新的集群并将其连接到ACM仓库，部署完整的操作栈。
- en: 11.3.3 Ambiguous Rock Feasting
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.3 Ambiguous Rock Feasting
- en: For Ambiguous Rock Feasting (A.R. Feasting), managing their expanding set of
    restaurants and the technology deployed within has become increasingly difficult
    over the past few years. The company now feels that the implementation time for
    the technology pieces along with the additional operational overhead each new
    location places on their IT operations team have become unsustainable. Therefore,
    they are moving to a more flexible model that will scale better.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Ambiguous Rock Feasting（A.R. Feasting），在过去几年中，管理他们不断扩大的餐厅群和部署的技术变得越来越困难。公司现在认为，技术组件的实施时间以及每个新位置给他们的IT运营团队带来的额外运营负担已经变得不可持续。因此，他们正在转向一个更具灵活性的模型，该模型可以更好地扩展。
- en: The restaurants already ran Kubernetes clusters on their local servers, but
    updating the deployed applications or troubleshooting problems caused a significant
    time loss for each location. Therefore, A.R. Feasting has pivoted to using ACM
    to manage the individual clusters. In general, the repository layout matches that
    of Village Linen, except A.R. Feasting is not using Hierarchy Controller.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这些餐厅已经在本地服务器上运行了Kubernetes集群，但更新部署的应用程序或解决问题导致每个位置都损失了大量的时间。因此，A.R. Feasting已经转向使用ACM来管理单个集群。一般来说，仓库布局与Village
    Linen的布局相匹配，但A.R. Feasting没有使用层次控制器。
- en: 'When deploying the ACM operators, each location’s cluster was given a dedicated
    name, such as arf-043-01a. The IT operations team then labeled these clusters
    using Cluster definitions in the policy repo like so:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当部署ACM操作员时，每个位置的集群都被分配了一个专有的名称，例如arf-043-01a。然后IT运维团队使用策略仓库中的集群定义对这些集群进行标记，如下所示：
- en: '[PRE14]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Or like this one for arf-101-01a:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 或者像这个arf-101-01a的例子：
- en: '[PRE15]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The IT operations team then define selectors based on these labels, some of
    which are included here:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: IT运维团队随后根据这些标签定义选择器，其中一些如下所示：
- en: '[PRE16]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'These selectors are then used to control deployments of new versions of applications,
    or to deploy only certain applications in certain regions. For example, only restaurants
    in the United States have drive-throughs. Therefore, the drive-through management
    application needs to be deployed only to the country-us clusters. The company
    has also decided to have certain selected stores be test beds of new software,
    as indicated by the is-rollout-tester flag on their cluster. An example deployment
    for an application is included here. However, some portions of the template have
    been removed because they are identical between the two examples:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这些选择器随后用于控制应用程序新版本的部署，或者在某些地区仅部署某些应用程序。例如，只有美国的餐厅有快车道。因此，快车道管理应用程序只需要部署到country-us集群。公司还决定让某些选定的商店成为新软件的测试床，这可以通过它们集群上的is-rollout-tester标志来表示。这里包含了一个应用程序部署的示例。然而，模板的一些部分已被删除，因为它们在两个示例中是相同的：
- en: '[PRE17]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The differences between these two deployments are the cluster selector used
    and the version of the engine image. Looking back at the cluster selectors defined,
    rollout-testers and non-testers do not overlap. If we had not defined a non-testers
    group and left the annotation off the second deployment earlier, we would have
    had a collision for the rollout-testers because both deployments would have been
    valid.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种部署之间的区别在于所使用的集群选择器和引擎镜像的版本。回顾一下定义的集群选择器，rollout-testers和non-testers没有重叠。如果我们没有定义non-testers组，并且在第二个部署中提前移除了注释，那么rollout-testers就会发生冲突，因为两个部署都是有效的。
- en: Because ACM logs the changes it makes using the same logging standards as Kubernetes,
    and with A.R. Feasting restaurants forwarding their logs to Cloud Logging, the
    IT operations team can set up monitoring using Cloud Monitoring to determine the
    status of specific applications and versions on the various clusters. Using this
    dashboard, they can quickly diagnose where potential problems might be (such as
    a power outage at a store) and work more efficiently.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 由于ACM使用与Kubernetes相同的日志标准记录其更改，并且A.R. Feasting餐厅将它们的日志转发到云日志，IT运维团队可以使用云监控设置监控，以确定各个集群上特定应用程序和版本的状态。使用此仪表板，他们可以快速诊断潜在问题可能发生的地方（例如商店的停电），并更有效地工作。
- en: 11.4 Conclusions
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.4 结论
- en: Organizations face increasing complexity managing their IT environments. Using
    Anthos Config Management with Kubernetes clusters, whether on-prem, in Google
    Cloud, or in another cloud provider, provides administrators with a familiar,
    declarative method to control the foundations of their clusters. This chapter
    has provided a broad overview of the service, some of the reasons to adopt a strategy
    incorporating ACM, and a couple of examples to illustrate the power of Anthos
    Config Management.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 组织在管理其IT环境时面临着日益增加的复杂性。使用Anthos Config Management与Kubernetes集群（无论是在本地、Google
    Cloud还是其他云服务提供商），为管理员提供了一个熟悉且声明式的控制其集群基础的方法。本章提供了该服务的广泛概述，一些采用ACM策略的原因，以及几个示例来说明Anthos
    Config Management的强大功能。
- en: 'However, we have not fully explored the capabilities and possibilities of Anthos
    Config Management: doing so would take a book all its own. Ultimately, ACM is
    intended to make your business more efficient and to reduce the complexity of
    managing your clusters. This chapter should have provided you with ideas on how
    to use ACM in your own organization, as well as some examples of how to drive
    adoption.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们还没有完全探索Anthos Config Management的能力和可能性：这样做可能需要一本完全属于自己的书。最终，ACM旨在使您的业务更高效，并减少管理集群的复杂性。本章应该为您提供了如何在您的组织中使用ACM的想法，以及一些如何推动采用的示例。
- en: 'For more information and examples on various topics touched on in this chapter,
    see the corresponding section of this book:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 关于本章涉及的各种主题的更多信息示例，请参阅本书相应的章节：
- en: 'Policy Controller: chapter 13'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 策略控制器：第13章
- en: 'Cloud Logging: chapter 5'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云日志：第5章
- en: Summary
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: As the number of clusters an organization manages increases, enforcing best
    practices or providing core functionality becomes exponentially more difficult.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着组织管理的集群数量增加，强制执行最佳实践或提供核心功能变得越来越困难。
- en: Modern development practices and the security landscape encourage organizations
    to adopt technologies that can rapidly adapt and deploy changes.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代开发实践和安全格局鼓励组织采用能够快速适应和部署更改的技术。
- en: Anthos Config Management is a core component of the Anthos platform, intended
    to provide the security and transparency that infrastructure, security, and operations
    teams desire, while also giving development teams the ability to deploy their
    applications with minimal additional hurdles.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos Config Management 是 Anthos 平台的核心组件，旨在提供基础设施、安全和运营团队所期望的安全性和透明度，同时给予开发团队以最小的额外障碍部署其应用程序的能力。
- en: 'ACM can be deployed in the following two modes, both offering distinct advantages:'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACM 可以部署在以下两种模式中，两者都提供了独特的优势：
- en: Hierarchical mode allows for easy deployment of a single resource across multiple
    namespaces and requires a logical collection of namespaces to be effective.
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分层模式允许轻松地将单个资源部署到多个命名空间，并需要一个逻辑的命名空间集合才能有效。
- en: Unstructured mode allows for developers and administrators to more easily pick
    and choose which namespaces to deploy components to, with the drawback of needing
    to be explicit about which namespace(s) to use. This mode is also compatible with
    many templating frameworks that may not function properly in hierarchical mode.
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无结构模式允许开发人员和管理员更容易地选择将组件部署到哪些命名空间，但缺点是需要明确指定使用哪些命名空间。此模式也与许多可能在分层模式中无法正常工作的模板框架兼容。
- en: ACM includes custom resources allowing for greater control over which namespaces
    and which clusters to apply configuration elements to.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACM 包含自定义资源，允许对应用配置元素到哪些命名空间和哪些集群有更大的控制。
- en: 'ACM also brings in the following additional components based on open source
    tools:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACM 还基于开源工具引入了以下附加组件：
- en: Config Connector provides infrastructure-as-data capability to a Kubernetes
    cluster, allowing for the provisioning of Google Cloud resources by declaring
    a Kubernetes resource.
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Config Connector 为 Kubernetes 集群提供基础设施作为数据的能力，允许通过声明 Kubernetes 资源来配置 Google
    Cloud 资源。
- en: Policy Controller gives administrators a convenient tool to create and enforce
    policies across their clusters.
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Policy Controller 为管理员提供了一个方便的工具，可以在其集群中创建和执行策略。
- en: Hierarchy Controller is the result of an initiative to provide an alternative
    method of replicating resources between namespaces in a cluster. Because storing
    Secrets in a Git repo is an antipattern, Hierarchy Controller definitions allow
    an organization to define a Secret or configuration once and have it replicated
    to the descendant namespaces automatically.
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hierarchy Controller 是一个旨在提供在集群中命名空间之间复制资源替代方法的倡议的结果。由于在 Git 仓库中存储 Secrets 是一种反模式，Hierarchy
    Controller 定义允许组织定义一个 Secret 或配置一次，并自动将其复制到子命名空间。
- en: 'The following three case studies explored different reasons for using and implementing
    ACM:'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下三个案例研究探讨了使用和实施 ACM 的不同原因：
- en: Evermore Industries wants to reduce the number of users directly working in
    their production environment and allow development teams to provision certain
    Google Cloud resources directly. They are currently using, and will continue to
    use, a templating engine for generating their Kubernetes configurations.
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Evermore Industries 希望减少直接在生产环境中工作的用户数量，并允许开发团队直接配置某些 Google Cloud 资源。他们目前正在使用，并将继续使用模板引擎来生成他们的
    Kubernetes 配置。
- en: Village Linen, LLC, is using ACM both on- and off-prem, as well as Hierarchy
    Controller to manage the replication of ConfigMaps and Secrets within both sets
    of clusters.
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Village Linen, LLC 正在使用 ACM 在本地和远程环境中，以及 Hierarchy Controller 来管理 ConfigMaps
    和 Secrets 在这两组集群中的复制。
- en: Ambiguous Rock Feasting is well versed in Kubernetes but is making specific
    use of the ClusterSelector feature of ACM to more precisely control where their
    applications are deployed.
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ambiguous Rock Feasting 在 Kubernetes 方面经验丰富，但正在特定地使用 ACM 的 ClusterSelector 功能来更精确地控制其应用程序的部署位置。
- en: '* * *'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.)The Anthos UI is covered primarily in chapter 1.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ^ (1.)Anthos UI 主要在第 1 章中介绍。
- en: ^(2.)For more information on the Kubernetes operator pattern, see [http://mng.bz/nJog](http://mng.bz/nJog).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ^ (2.)有关 Kubernetes 操作符模式的更多信息，请参阅 [http://mng.bz/nJog](http://mng.bz/nJog)。
- en: '^(3.)The annotation is configmanagement.gke.io/managed: enabled.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '(3.)注解为configmanagement.gke.io/managed: enabled。'
- en: ^(4.)This is the same pattern Deployments and Jobs use and is detailed at [http://mng.bz/41Ga](http://mng.bz/41Ga).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: (4.)这是部署和作业使用的相同模式，详细信息请参阅[http://mng.bz/41Ga](http://mng.bz/41Ga)。
- en: ^(5.)For more information on CI/CD and Anthos, see chapter 12.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: (5.)有关CI/CD和Anthos的更多信息，请参阅第12章。
- en: ^(6.)Istio is explored in detail in chapter 4.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: (6.)第4章详细探讨了Istio。
