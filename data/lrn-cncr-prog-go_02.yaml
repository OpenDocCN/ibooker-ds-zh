- en: 1 Stepping into concurrent programming
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 进入并发编程
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Introducing concurrent programming
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍并发编程
- en: Improving performance with concurrent execution
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用并发执行提高性能
- en: Scaling our programs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展我们的程序
- en: Meet Jane Sutton. Jane has been working at HSS International Accountancy as
    a software developer for three months. In her latest project, she has been looking
    at a problem in the payroll system. The payroll software module runs at the end
    of the month after the close of business, and it computes all the salary payments
    for the HSS clients’ employees. Jane’s manager has arranged a meeting with the
    product owner, the infrastructure team, and a sales representative to try to get
    to the bottom of the problem. Unexpectedly, Sarika Kumar, CTO, has joined the
    meeting room via video call.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 认识Jane Sutton。Jane已经在HSS国际会计师事务所担任软件开发者工作了三个月。在她的最新项目中，她一直在研究薪资系统中的一个问题。薪资软件模块在业务结束后运行于月底，并为HSS客户的员工计算所有薪资支付。Jane的经理安排了与产品负责人、基础设施团队和一位销售代表的会议，试图找到问题的根源。出乎意料的是，CTO
    Sarika Kumar通过视频会议加入了会议室。
- en: 'Thomas Bock, the product owner, starts: “I don’t understand. The payroll module
    has been working fine for as long as I can remember. Suddenly, last month, the
    payment calculations weren’t completed on time, and we got loads of complaints
    from our clients. It made us look really unprofessional to Block Entertainment,
    our new and biggest client yet, with them threatening to go to our competitor.”'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 产品负责人Thomas Bock开始说：“我不明白。我记得薪资模块一直运行得很好。突然，上个月，支付计算没有按时完成，我们收到了大量来自客户的投诉。这让我们在Block
    Entertainment面前显得非常不专业，他们是我们的新客户，也是迄今为止最大的客户，他们威胁要转向我们的竞争对手。”
- en: 'Jane’s manager, Francesco Varese, chimes in: “The problem is that the calculations
    are too slow and take too long. They are slow because of their complex nature,
    considering many factors such as employee absences, joining dates, overtime, and
    a thousand other factors. Parts of the software were written more than a decade
    ago in C++. There are no developers left in the firm who understand how this code
    works.”'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Jane的经理Francesco Varese插话道：“问题在于计算太慢，耗时过长。由于它们的复杂性质，需要考虑许多因素，如员工缺勤、入职日期、加班和成千上万的其它因素。软件的部分部分是在十多年前用C++编写的。公司里没有开发者能理解这段代码是如何工作的。”
- en: “We’re about to sign up our biggest client ever, a company with over 30,000
    employees. They’ve heard about our payroll problem, and they want to see it resolved
    before they proceed with the contract. It’s really important that we fix this
    as soon as possible,” replies Rob Gornall from the Sales and Acquisitions department.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: “我们即将签约我们最大的客户，一家拥有超过30,000名员工的公司。他们已经听说我们的薪资问题，并希望在签订合同之前看到问题得到解决。我们尽快解决这个问题非常重要，”来自销售和收购部门的Rob
    Gornall回应道。
- en: “We’ve tried adding more processor cores and memory to the server that runs
    the module, but this made absolutely no difference. When we execute the payroll
    calculation using test data, it’s taking the same amount of time, no matter how
    many resources we allocate. It’s taking more than 20 hours to calculate all the
    clients’ payrolls, which is too long for our clients,” continues Frida Norberg
    from Infrastructure.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: “我们尝试在运行模块的服务器上添加更多处理器核心和内存，但这完全没有效果。当我们使用测试数据执行薪资计算时，无论我们分配多少资源，所需时间都是相同的。计算所有客户的薪资需要超过20小时，这对我们的客户来说太长了，”来自基础设施的Frida
    Norberg继续说道。
- en: It’s Jane’s turn to finally speak. As the firm’s newest employee, she hesitates
    a little but manages to say, “If the code is not written in a manner that takes
    advantage of the additional cores, it won’t matter if you allocate multiple processors.
    The code needs to use concurrent programming for it to run faster when you add
    more processing resources.”
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 轮到Jane终于发言了。作为公司的新员工，她有些犹豫，但设法说道：“如果代码没有以利用额外核心的方式编写，那么分配多个处理器也没有用。代码需要使用并发编程，这样在添加更多处理资源时才能运行得更快。”
- en: Everyone seems to have acknowledged that Jane is the most knowledgeable about
    the subject. There is a short pause. Jane feels as if everyone wants her to come
    up with some sort of answer, so she continues. “Right. Okay. I’ve been experimenting
    with a simple program written in Go. It divides the payroll into smaller employee
    groups and then calls the payroll module with each group as input. I’ve programmed
    it so that it calls the module concurrently using multiple goroutines. I’m also
    using a Go channel to load-balance the workload. At the end, I have another goroutine
    that collects the results via another channel.”
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 似乎每个人都承认简是这个主题最博学的人。短暂的停顿之后，简感觉好像每个人都希望她给出某种答案，于是她继续说：“对，好吧。我一直在用 Go 编写的简单程序进行实验。它将工资单分成更小的员工组，然后对每个组调用工资模块。我已经编程使其使用多个
    goroutine 并发调用模块。我还使用 Go 通道来负载均衡工作负载。最后，我还有一个 goroutine 通过另一个通道收集结果。”
- en: Jane looks around quickly and sees blank looks on everyone’s faces, so she adds,
    “In simulations, it’s at least five times faster on the same multicore hardware.
    There are still a few tests to run to make sure there are no race conditions,
    but I’m pretty sure that I can make it run even faster, especially if I get some
    help from accounting to migrate some of the old C++ logic into clean Go concurrent
    code.”
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 简迅速环顾四周，看到每个人的脸上都露出茫然的神情，于是她补充说：“在模拟中，它在相同的多核硬件上至少快了五倍。还有一些测试要运行以确保没有竞争条件，但我相当确信我可以让它运行得更快，特别是如果我能从会计那里得到一些帮助，将一些旧的
    C++ 逻辑迁移到干净的 Go 并发代码中。”
- en: Jane’s manager has a big smile on his face now. Everyone else in the meeting
    seems surprised and speechless. The CTO finally speaks up and says, “Jane, what
    do you need to get this done by the end of the month?”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 简的经理现在脸上带着大大的笑容。会议上的其他人似乎都感到惊讶和无言。CTO 最后开口说：“简，你需要在月底前完成这项工作，你需要什么？”
- en: Concurrent programming is a skill that is increasingly sought after by tech
    companies. It is a technique used in virtually every field of development, from
    web development to game programming, backend business logic, mobile applications,
    crypto, and many others. Businesses want to utilize hardware resources to their
    full capacity, as this saves them time and money. To accomplish this, they understand
    that they have to hire the right talent—developers who can write scalable concurrent
    applications.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 并发编程是一种越来越受到科技公司青睐的技能。它是一种在几乎每个开发领域都使用的技巧，从网页开发到游戏编程，再到后端业务逻辑、移动应用、加密技术以及许多其他领域。企业希望充分利用硬件资源，因为这可以节省他们的时间和金钱。为了实现这一点，他们明白他们必须雇佣合适的人才——能够编写可扩展并发应用程序的开发者。
- en: 1.1 About concurrency
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 关于并发
- en: In this book, we will focus on principles and patterns of concurrent programming.
    How can we program instructions that happen at the same time? How can we manage
    concurrent executions so they don’t step over each other? What techniques should
    we use to have executions collaborate toward solving a common problem? When and
    why should we use one form of communication over another? We will answer all these
    questions and more by making use of the Go programming language. Go gives us a
    full set of tools to illustrate these concepts.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将关注并发编程的原则和模式。我们如何编写同时发生的指令？我们如何管理并发执行，以确保它们不会相互干扰？我们应该使用什么技术使执行协作解决共同问题？何时以及为什么应该使用一种通信形式而不是另一种？我们将通过使用
    Go 编程语言来回答所有这些问题以及更多。Go 为我们提供了一套完整的工具来展示这些概念。
- en: 'If you have little or no experience in concurrency but have some experience
    in Go or a similar C-style language, this book is ideal. This book starts with
    a gentle introduction to concurrency concepts in the operating system and describes
    how Go uses them to model concurrency. We’ll then move on to explain race conditions
    and why they occur in some concurrent programs. Later, we’ll discuss the two main
    ways we can implement communication between our executions: memory sharing and
    message passing. In the final chapters of this book, we’ll discuss concurrency
    patterns, deadlocks, and some advanced topics such as spinning locks.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在并发编程方面经验很少或没有经验，但有一些使用 Go 或类似 C 风格语言的经验，这本书非常适合你。本书从操作系统中并发概念的温和介绍开始，描述了
    Go 如何使用它们来模拟并发。然后，我们将继续解释竞争条件以及为什么它们在某些并发程序中发生。稍后，我们将讨论我们可以实现执行之间通信的两种主要方式：内存共享和消息传递。在本书的最后几章中，我们将讨论并发模式、死锁以及一些高级主题，如自旋锁。
- en: Apart from helping us to get hired or promoted as developers, knowing concurrent
    programming gives us a wider set of skills that we can employ in new scenarios.
    For example, we can model complex business interactions that happen at the same
    time. We can also use concurrent programming to improve our software’s responsiveness
    by picking up tasks swiftly. Unlike sequential programming, concurrent programming
    can make use of multiple CPU cores, which allows us to increase the work done
    by our programs by speeding up their execution. Even with a single CPU core, concurrency
    offers benefits because it enables time-sharing and lets us perform tasks while
    we’re waiting for I/O operations to complete. Let’s now look at some of these
    scenarios in more detail.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 除了帮助我们作为开发者获得雇佣或晋升外，了解并发编程还给我们提供了一组更广泛的技能，我们可以在新的场景中使用这些技能。例如，我们可以模拟同时发生的复杂商业交互。我们还可以通过迅速处理任务来使用并发编程提高我们软件的响应性。与顺序编程不同，并发编程可以利用多个CPU核心，这使我们能够通过加快执行速度来增加程序完成的工作量。即使只有一个CPU核心，并发也提供了好处，因为它实现了时间共享，并允许我们在等待I/O操作完成时执行任务。现在让我们更详细地看看这些场景中的一些。
- en: 1.2 Interacting with a concurrent world
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 与并发世界交互
- en: We live and work in a concurrent world. The software that we write models complex
    business processes that interact concurrently. Even the simplest of businesses
    typically have many of these concurrent interactions. For example, consider multiple
    people ordering online at the same time or a consolidation process grouping packages
    together while coordinating with ongoing shipments, as shown in figure 1.1.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生活和工作在一个并发世界中。我们编写的软件模拟了并发交互的复杂商业流程。即使是简单的业务通常也有许多这些并发交互。例如，考虑多个人同时在线订购，或者如图1.1所示，整合过程将包裹分组在一起，同时协调正在进行的运输。
- en: '![](../../OEBPS/Images/CH01_F01_Cutajar.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F01_Cutajar.png)'
- en: Figure 1.1 A consolidation shipping process showing complex concurrent interactions
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 显示复杂并发交互的整合运输流程
- en: In our everyday life, we deal with concurrency all the time. Every time we drive
    a car, we interact with multiple concurrent actors, such as other cars, cyclists,
    and pedestrians. At work, we may put a task on hold while we’re waiting for an
    email reply and pick up the next task. When cooking, we plan our steps so we maximize
    our productivity and shorten the cooking time. Our brain is perfectly comfortable
    managing concurrent behavior. In fact, it does this all the time without us even
    noticing.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的日常生活中，我们时刻都在处理并发。每次我们开车，我们都会与多个并发参与者互动，例如其他车辆、骑自行车的人和行人。在工作时，我们可能会在等待电子邮件回复时暂停一项任务，然后继续下一项任务。在烹饪时，我们规划我们的步骤，以便最大化我们的生产力并缩短烹饪时间。我们的大脑非常适应管理并发行为。事实上，它一直在这样做，而我们甚至没有注意到。
- en: Concurrent programming is about writing code so that multiple tasks and processes
    can execute and interact at the same time. If two customers place an order simultaneously
    and only one stock item remains, what happens? If the price of a flight ticket
    goes up every time a client buys a ticket, what happens when multiple tickets
    are booked at the same exact instant? If we have a sudden increase in load due
    to extra demand, how will our software scale when we increase the processing and
    memory resources? These are all scenarios that developers deal with when they
    are designing and programming concurrent software.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 并发编程是编写代码，以便多个任务和进程可以同时执行和交互。如果两个客户同时下单，而只有一件库存商品，会发生什么？如果每次客户购买机票时机票价格都会上涨，那么当多个机票在同一确切时刻预订时会发生什么？如果我们由于额外需求而突然增加负载，当我们增加处理和内存资源时，我们的软件将如何扩展？这些都是开发者在设计和编程并发软件时需要处理的场景。
- en: 1.3 Increasing throughput
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 提高吞吐量
- en: For the modern developer, it is increasingly important to understand how to
    program concurrently. This is because the hardware landscape has changed over
    the years to benefit this type of programming.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于现代开发者来说，了解如何进行并发编程变得越来越重要。这是因为随着硬件景观的变化，这种编程类型得到了益处。
- en: Prior to multicore technology, processor performance increased proportionally
    to clock frequency and transistor count, roughly doubling every two years. Processor
    engineers started hitting physical limits due to overheating and power consumption,
    which coincided with the explosion of more mobile hardware, such as notebooks
    and smartphones. To reduce excessive battery consumption and CPU overheating while
    increasing processing power, engineers introduced multicore processors.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在多核技术出现之前，处理器性能与时钟频率和晶体管数量成比例增加，大约每两年翻一番。由于过热和功耗，处理器工程师开始遇到物理极限，这与移动硬件的爆炸性增长相吻合，例如笔记本电脑和智能手机。为了减少过度的电池消耗和CPU过热，同时增加处理能力，工程师引入了多核处理器。
- en: In addition, the rise of cloud computing services has given developers easy
    access to large, cheap processing resources where they can run their code. This
    extra computational power can only be harnessed effectively if our code is written
    in a manner that takes full advantage of the extra processing units.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，云计算服务的兴起使得开发者可以轻松访问大量廉价的处理资源，他们可以在这些资源上运行他们的代码。只有当我们的代码以充分利用额外处理单元的方式编写时，这种额外的计算能力才能被有效地利用。
- en: DEFINITION *Horizontal scaling* is when we improve system performance by distributing
    the load over multiple processing resources, such as processors and server machines
    (see figure 1.2). *Vertical scaling* is when we improve the existing resources,
    such as by getting a faster processor.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义** 横向扩展是指通过在多个处理资源（如处理器和服务器机器）上分配负载来提高系统性能（见图1.2）。**纵向扩展**是指通过获取更快的处理器来提高现有资源。'
- en: '![](../../OEBPS/Images/CH01_F02_Cutajar.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F02_Cutajar.png)'
- en: Figure 1.2 Improving performance by adding more processors
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 通过添加更多处理器来提高性能
- en: Having multiple processing resources means we can scale horizontally. We can
    use the extra processors to execute tasks in parallel and finish them more quickly.
    This is only possible if we write code in a way that takes full advantage of the
    extra processing resources.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有多个处理资源意味着我们可以进行横向扩展。我们可以使用额外的处理器并行执行任务，从而更快地完成任务。只有当我们以充分利用额外处理资源的方式编写代码时，这才能成为可能。
- en: What about a system that has only one processor? Is there any advantage to writing
    concurrent code if our system does not have multiple processors? It turns out
    that writing concurrent programs has a benefit even in this scenario.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如果一个系统只有一个处理器，如果我们的系统没有多个处理器，编写并发代码有什么优势吗？结果是，即使在这样的情况下，编写并发程序也有好处。
- en: Most programs spend only a small proportion of their time executing computations
    on the processor. Think, for example, about a word processor that waits for input
    from the keyboard, or a text-file search utility that spends most of its running
    time waiting for portions of the text files to load from disk. We can have our
    program perform different tasks while it’s waiting for I/O. For example, the word
    processor could perform a spell check on the document while the user is thinking
    about what to type next. We can have the file search utility look for a match
    with the file that we already loaded in memory while we are reading the next file
    into another portion of memory.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数程序只花费很少的时间在处理器上执行计算。例如，考虑一个等待键盘输入的文字处理器，或者一个文本文件搜索实用程序，它在运行时的大部分时间都在等待文本文件的部分从磁盘加载。我们可以在程序等待I/O时执行不同的任务。例如，当用户在思考下一个要输入的内容时，文字处理器可以对文档进行拼写检查。我们可以在将下一个文件读入内存的另一部分时，让文件搜索实用程序查找与我们已加载到内存中的文件匹配的内容。
- en: As another example, think of cooking or baking a favorite dish. We can make
    more effective use of our time if, while the dish is in the oven or on the stove,
    we perform some other actions instead of just waiting around (see figure 1.3).
    In this way, we are making more effective use of our time, and we are more productive.
    This is analogous to our program executing other instructions on the CPU while
    it waits for a network message, user input, or a file to be written. This means
    our program can get more work done in the same amount of time.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，想想烹饪或烘焙一道喜欢的菜肴。如果在菜肴在烤箱或炉子上时，我们做一些其他的事情而不是只是等待（见图1.3），我们就可以更有效地利用我们的时间。这样，我们就能更有效地利用我们的时间，提高我们的生产力。这与我们的程序在等待网络消息、用户输入或文件写入时在CPU上执行其他指令类似。这意味着我们的程序可以在相同的时间内完成更多的工作。
- en: '![](../../OEBPS/Images/CH01_F03_Cutajar.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F03_Cutajar.png)'
- en: Figure 1.3 Even with one processor, we can improve performance if we utilize
    idle times.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 即使只有一个处理器，如果我们利用空闲时间，也可以提高性能。
- en: 1.4 Improving responsiveness
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 提高响应性
- en: Concurrent programming makes our software more responsive because we don’t need
    to wait for one task to finish before responding to a user’s input. Even if we
    have one processor, we can always pause the execution of a set of instructions,
    respond to the user’s input, and then continue with the execution while we’re
    waiting for the next user’s input.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 并发编程使我们的软件更具响应性，因为我们不需要等待一个任务完成后再响应用户的输入。即使我们只有一个处理器，我们也可以暂停一组指令的执行，响应用户的输入，然后在等待下一个用户输入时继续执行。
- en: If we again think of a word processor, multiple tasks might be running in the
    background while we are typing. There is a task that listens to keyboard events
    and displays each character on the screen. We might also have a task that checks
    our spelling and grammar in the background. Another task might be running to give
    us stats on our document (word count, page count, etc.). Periodically, we may
    have another task that autosaves our document. All these tasks running together
    give the impression that they are somehow running simultaneously, but what’s happening
    is that these tasks are being fast-switched by the operating system on CPUs. Figure
    1.4 illustrates a simplified timeline showing these three tasks executing on a
    single processor. This interleaving system is implemented by using a combination
    of hardware interrupts and operating system traps.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次考虑文字处理器，在我们输入时，可能会有多个任务在后台运行。有一个任务监听键盘事件并在屏幕上显示每个字符。我们可能还有一个任务在后台检查我们的拼写和语法。另一个任务可能正在运行，为我们提供文档的统计数据（单词计数、页数等）。定期，我们可能还有一个任务自动保存我们的文档。所有这些任务一起运行，给人一种它们似乎同时运行的印象，但实际上，这些任务是由操作系统在CPU上快速切换的。图1.4展示了这三个任务在一个处理器上执行的简化时间线。这种交错系统是通过结合使用硬件中断和操作系统陷阱来实现的。
- en: '![](../../OEBPS/Images/CH01_F04_Cutajar.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH01_F04_Cutajar.png)'
- en: Figure 1.4 Simplified task interleaving in a word processor
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 文字处理器中的简化任务交错
- en: We’ll go into more detail on operating systems and concurrency in the next chapter.
    For now, it’s important to realize that if we didn’t have this interleaving system,
    we would have to perform each task one after the other. We would have to type
    a sentence, then click the spell check button, wait for it to complete, and then
    click another button and wait for the document stats to appear.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章中更详细地介绍操作系统和并发。现在，重要的是要意识到，如果没有这种交错系统，我们就必须一个接一个地执行每个任务。我们必须输入一个句子，然后点击拼写检查按钮，等待它完成，然后点击另一个按钮并等待文档统计信息出现。
- en: 1.5 Programming concurrency in Go
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 Go语言中的并发编程
- en: Go is a very good language to use when learning about concurrent programming
    because its creators designed it with high-performance concurrency in mind. Their
    aim was to produce a language that was efficient at runtime, readable, and easy
    to use.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Go语言是学习并发编程的一个非常好的语言，因为它的创造者设计它时考虑了高性能的并发。他们的目标是创建一个在运行时效率高、可读性强且易于使用的语言。
- en: 1.5.1 Goroutines at a glance
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.1 一瞥goroutines
- en: Go uses a lightweight construct, called a *goroutine**,* to model the basic
    unit of concurrent execution. As we shall see in the next chapter, goroutines
    give us a system of user-level threads running on a set of kernel-level threads
    and managed by Go’s runtime.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Go使用一种轻量级结构，称为*goroutine*，来模拟并发执行的基本单元。正如我们将在下一章中看到的，goroutines为我们提供了一个用户级线程系统，这些线程在一组内核级线程上运行，并由Go的运行时管理。
- en: Given the lightweight nature of goroutines, the premise of the language is that
    we should focus mainly on writing correct concurrent programs, letting Go’s runtime
    and hardware mechanics deal with parallelism. The principle is that if you need
    something to be done concurrently, create a goroutine to do it. If you need many
    things done concurrently, create as many goroutines as you need, without worrying
    about resource allocation. Then, depending on the hardware and environment that
    your program is running on, your solution will scale.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于goroutines的轻量级特性，该语言的前提是我们应该主要关注编写正确的并发程序，让Go的运行时和硬件机制处理并行性。原则是，如果你需要并发执行某事，创建一个goroutine来完成它。如果你需要并发执行许多事情，创建你需要的那么多goroutine，无需担心资源分配。然后，根据你的程序运行的硬件和环境，你的解决方案将进行扩展。
- en: In addition to goroutines, Go provides us with many abstractions that allow
    us to coordinate the concurrent executions on a common task. One of these abstractions
    is known as a *channel*. Channels allow two or more goroutines to pass messages
    to each other. This enables the exchange of information and synchronization of
    the multiple executions in an easy and intuitive manner.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 除了goroutines之外，Go还为我们提供了许多抽象，使我们能够协调在共同任务上的并发执行。其中一种抽象称为*通道*。通道允许两个或更多goroutines相互传递消息。这使得信息交换和多个执行的同步变得简单直观。
- en: 1.5.2 Modeling concurrency with CSP and primitives
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.2 使用CSP和原语建模并发
- en: In 1978, C.A.R. Hoare first described *communicating sequential processes* (CSP)
    as a formal language for expressing concurrent interactions. Many languages, such
    as Occam and Erlang, have been influenced by CSP. Go tries to implement many of
    CSP’s ideas, such as the use of synchronized channels.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 1978年，C.A.R. Hoare首次将*通信顺序进程*（CSP）描述为一种用于表达并发交互的正式语言。许多语言，如Occam和Erlang，都受到了CSP的影响。Go试图实现CSP的许多想法，例如使用同步通道。
- en: This concurrency model of having isolated goroutines communicating and synchronizing
    using channels (see figure 1.5) reduces the risk of race conditions—types of programming
    errors that occur in bad concurrent programming and that are typically very hard
    to debug and lead to data corruption and unexpected behavior. This type of modeling
    concurrency is more akin to how concurrency happens in our everyday lives, such
    as when we have isolated executions (people, processes, or machines) working concurrently,
    communicating with each other by sending messages back and forth.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这种具有隔离goroutines通过通道进行通信和同步的并发模型（见图1.5）降低了竞态条件的风险——这类编程错误发生在不良的并发编程中，通常很难调试，并可能导致数据损坏和意外行为。这种类型的并发建模更类似于我们在日常生活中遇到的情况，例如当我们有隔离的执行（人、进程或机器）并发工作时，通过相互发送消息进行通信。
- en: '![](../../OEBPS/Images/CH01_F05_Cutajar.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH01_F05_Cutajar.png)'
- en: Figure 1.5 A concurrent Go application using CSP
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 使用CSP的并发Go应用程序
- en: Depending on the problem, the classic concurrency primitives used with memory
    sharing (such as mutexes and condition variables, found in many other languages)
    will sometimes do a better job and result in better performance than using CSP-style
    programming. Luckily for us, Go provides us with these tools in addition to the
    CSP-style tools. When CSP is not the appropriate model to use, we can fall back
    on the other classic primitives.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 根据问题，与内存共享一起使用的经典并发原语（如许多其他语言中找到的互斥锁和条件变量）有时会做得更好，并产生更好的性能，比使用CSP风格的编程更好。幸运的是，Go为我们提供了这些工具，除了CSP风格的工具之外。当CSP不是合适的模型时，我们可以退回到其他经典原语。
- en: In this book, we will purposely start with memory sharing and synchronization
    using classic primitives. The idea is that by the time we get to discussing CSP-style
    concurrent programming, you will have a solid foundation in the traditional locking
    and synchronization primitives.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将故意从使用经典原语进行内存共享和同步开始。目的是当我们讨论CSP风格的并发编程时，你将拥有坚实的传统锁定和同步原语的基础。
- en: 1.5.3 Building our own concurrency tools
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.3 构建自己的并发工具
- en: In this book, you will learn how to use various tools to build concurrent applications.
    This includes concurrency constructs such as mutex, condition variables, channels,
    semaphores, and so on.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，你将学习如何使用各种工具来构建并发应用程序。这包括诸如互斥锁、条件变量、通道、信号量等并发构造。
- en: Knowing how to use these concurrency tools is good, but what about understanding
    their inner workings? Here, we’ll go one step further and take the approach of
    building them together from scratch, even if they are available in Go’s libraries.
    We will pick common concurrency tools and see how they can be implemented using
    other concurrency primitives as building blocks. For example, Go doesn’t come
    with a bundled semaphore implementation, so apart from understanding how and when
    to use semaphores, we’ll go about implementing one ourselves. We’ll also do this
    for some of the tools that are available in Go, such as waitgroups and channels.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 知道如何使用这些并发工具是好的，但了解它们的内部工作原理呢？在这里，我们将更进一步，从零开始构建它们，即使它们在Go的库中可用。我们将选择常见的并发工具，看看它们如何使用其他并发原语作为构建块来实现。例如，Go没有内置的信号量实现，因此除了理解何时以及如何使用信号量之外，我们还将自己实现一个。我们还将为Go中可用的某些工具做同样的事情，例如等待组和通道。
- en: This idea is analogous to having the knowledge to implement well-known algorithms.
    We might not need to know how to implement a sorting algorithm to use a sorting
    function; however, learning how the algorithm works exposes us to different scenarios
    and new ways of thinking, making us better programmers. We can then apply those
    scenarios to different problems. In addition, knowing how a concurrency tool is
    built allows us to make better-informed decisions about when and how to use it.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法类似于拥有实现知名算法的知识。我们可能不需要知道如何实现排序算法就能使用排序函数；然而，了解算法的工作原理使我们接触到不同的场景和新思维方式，使我们成为更好的程序员。然后我们可以将这些场景应用到不同的问题中。此外，了解并发工具是如何构建的，使我们能够更明智地决定何时以及如何使用它。
- en: 1.6 Scaling performance
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.6 性能扩展
- en: '*Performance* *scalability* is the measure of how well a program speeds up
    in proportion to the increase in the number of resources available to the program.
    To understand this, let’s try to make use of a simple analogy.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*性能* *可扩展性*是衡量程序在可用资源数量增加时速度提升的指标。为了理解这一点，让我们尝试使用一个简单的类比。'
- en: Imagine a world where we are property developers. Our current project is to
    build a small multi-story residential house. We give the architectural plan to
    a builder, and they set off to finish the small house. The work is all completed
    in a period of eight months.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们是一个房地产开发商。我们当前的项目是建造一栋小型多层住宅。我们给建筑工人一份建筑图纸，他们就开始建造小房子。所有工作都在八个月的时间内完成。
- en: As soon as that project is finished, we get another request for the same build
    but in another location. To speed things up, we hire two builders instead of one.
    This time around, the builders complete the house in just four months.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 那个项目一完成，我们就收到了另一个相同建造请求，但地点不同。为了加快进度，我们雇佣了两个建筑工人而不是一个。这次，建筑工人只用了四个月就完成了房子的建造。
- en: The next time we are asked to build the same house, we hire even more help,
    so that the house is finished quicker. This time we pay four builders, and it
    takes them two and a half months to complete. The house has cost us a bit more
    to build than the previous one. Paying four builders for two and a half months
    costs more than paying two builders for four months (assuming they all charge
    the same rate).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下次我们被要求建造同样的房子时，我们雇佣了更多的帮手，以便更快地完成房子。这次我们雇佣了四个建筑工人，他们花了两个半月的时间才完成。建造这所房子的成本比之前的那所房子要高一些。雇佣四个建筑工人两个半月的花费比雇佣两个建筑工人四个月的花费要多（假设他们的收费率相同）。
- en: We repeat the experiment twice more, once with 8 builders and then with 16\.
    With both 8 and 16 builders, the house takes two months to complete. It seems
    that no matter how many hands we put on the job, the build cannot be completed
    in less than two months. In geek speak, we say that we have hit our *scalability
    limit**.* Why does this happen? Why can’t we continue to double our resources
    (people, money, or processors) and always reduce the time spent by half?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次进行了两次实验，一次是雇佣8个建筑工人，另一次是雇佣16个。无论是8个还是16个建筑工人，房子都需要两个月才能完成。似乎无论我们投入多少人力，都无法在两个月内完成建造。用技术术语来说，我们达到了**可扩展性极限**。为什么会这样？为什么我们不能继续加倍我们的资源（人力、资金或处理器）并总是将所需时间减半？
- en: 1.6.1 Amdahl’s law
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6.1 Amdahl定律
- en: In 1967, Gene Amdahl, a computer scientist, presented a formula at a conference
    that measured speedup with regard to a problem’s parallel-to-sequential ratio.
    This became known as Amdahl’s law.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在1967年，计算机科学家Gene Amdahl在一次会议上提出了一个公式，用来衡量问题并行到顺序比的速度提升。这被称为Amdahl定律。
- en: Definition *Amdahl’s law* states that the overall performance improvement gained
    by optimizing a single part of a system is limited by the fraction of time that
    the improved part is actually used.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 *Amdahl定律* 表示，通过优化系统的一个部分所获得的总体性能提升受到该改进部分实际使用时间的比例限制。
- en: In our house build scenario, the scalability is limited by various factors.
    For starters, our approach to solving the problem might be limiting us. For example,
    one cannot construct the second floor before constructing the first. In addition,
    several parts of the build can only be done sequentially. For example, if a single
    road leads to the building site, only one transport can use the road at any point
    in time. In other words, some parts of the building process are sequential (one
    after the other), and other parts can be done in parallel (at the same time).
    These factors influence and limit the scalability of our task.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的房屋建造场景中，可扩展性受多种因素限制。首先，我们解决问题的方法可能限制了我们的能力。例如，在建造第一层之前不能建造第二层。此外，建造的几个部分只能顺序完成。例如，如果只有一条道路通往建筑工地，任何时候只能有一辆运输工具使用这条道路。换句话说，建筑过程中的某些部分是顺序的（一个接一个），而其他部分可以并行完成（同时进行）。这些因素影响并限制了我们的任务的可扩展性。
- en: Amdahl’s law tells us that the non-parallel parts of an execution act as a bottleneck
    and limit the advantage of parallelizing the execution. Figure 1.6 shows this
    relationship between the theoretical speedup obtained as we increase the number
    of processors.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 阿姆达尔定律告诉我们，执行的不可并行部分充当瓶颈，并限制了并行执行的优势。图1.6显示了随着处理器数量的增加而获得的理论速度提升之间的关系。
- en: '![](../../OEBPS/Images/CH01_F06_Cutajar.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH01_F06_Cutajar.png)'
- en: Figure 1.6 The speedup against the number of processors according to Amdahl’s
    law
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 根据阿姆达尔定律，速度提升与处理器数量的关系
- en: If we apply this chart to our construction problem, when we use a single builder
    and they spend 5% of their time on the parts that can only be done sequentially,
    the scalability follows the topmost line in our chart (95% parallel). This sequential
    portion is the part that can only be done by one person, such as trucking in the
    building materials through a narrow road.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这张图应用于我们的构建问题，当我们使用单个构建者并且他们花费5%的时间在只能顺序完成的部件上时，可扩展性遵循图表中最上面的线条（95%并行）。这部分顺序操作是只能由一个人完成的，例如通过狭窄的道路运输建筑材料。
- en: As you can see from the chart, even with 512 people working on the construction,
    we would only finish the job about 19 times faster than if we had just 1 person.
    After this point, the situation does not improve much. We’ll need more than 4,096
    builders to finish the project just 20 times faster. We hit a hard limit around
    this number. Contracting more workers does not help at all, and we would be wasting
    our money.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从图表中可以看到，即使有512人在建造工作中，我们也只能比只有1个人时快大约19倍完成工作。在此之后，情况并没有多大改善。我们需要超过4,096名建造者才能使项目快20倍完成。我们在这个数字附近遇到了硬限制。雇佣更多的工人根本不会有所帮助，我们只是在浪费金钱。
- en: The situation is even worse if a lower percentage of work is parallelizable.
    With 90%, we would hit this scalability limit around the 512-workers mark. With
    75%, we get there at 128 workers, and with 50% at just 16 workers. Notice that
    it’s not just this limit that goes down—the speedup is also greatly reduced. When
    the work is 90%, 75%, and 50% parallelizable, we get maximum speedups of 10, 4,
    and 2, respectively.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可并行化的工作比例更低，情况会更糟。以90%的比例，我们会在512个工作者的标记处达到这个可扩展性限制。以75%的比例，我们会在128个工作者处达到，以50%的比例在仅16个工作者处达到。请注意，不仅仅是这个限制在下降——速度提升也大大减少。当工作量为90%、75%和50%可并行化时，我们分别获得最大速度提升为10、4和2。
- en: Amdahl’s law paints a pretty bleak picture of concurrent programming and parallel
    computing. Even with concurrent code that has a tiny fraction of serial processing,
    the scalability is greatly reduced. Thankfully, this is not the full picture.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 阿姆达尔定律为并发编程和并行计算描绘了一幅相当黯淡的图景。即使并发代码只有极小比例的串行处理，可扩展性也会大大降低。幸运的是，这并不是全部的图景。
- en: 1.6.2 Gustafson’s law
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6.2 古斯塔夫森定律
- en: In 1988, two computer scientists, John L. Gustafson and Edwin H. Barsis, reevaluated
    Amdahl’s law and published an article addressing some of its shortcomings (“Reevaluating
    Amdah’s Law,” [https://dl.acm.org/doi/pdf/10.1145/42411.42415](https://dl.acm.org/doi/pdf/10.1145/42411.42415)).
    The article gives an alternative perspective on the limits of parallelism. Their
    main argument is that, in practice, the size of the problem changes when we have
    access to more resources.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在1988年，两位计算机科学家约翰·L·古斯塔夫森和爱德华·H·巴里斯重新评估了阿姆达尔定律，并发表了一篇文章，讨论了其一些不足之处（“重新评估阿姆达尔定律”，[https://dl.acm.org/doi/pdf/10.1145/42411.42415](https://dl.acm.org/doi/pdf/10.1145/42411.42415)）。这篇文章给出了关于并行限制的另一种观点。他们的主要论点是，在实践中，当我们能够访问更多资源时，问题的大小会发生变化。
- en: To continue with our house-building analogy, if we did have thousands of builders
    available at our disposal, it would be wasteful to put them all into building
    a small house when we have future projects in the pipeline. Instead, we would
    try to put the optimal number of builders on our house construction and allocate
    the rest of the workers to other projects.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们的房屋建造类比，如果我们确实有数千名建筑工人可供使用，当我们有未来的项目在管道中时，将他们全部用于建造一个小房子将是浪费的。相反，我们会尝试将最佳数量的建筑工人用于我们的房屋建设，并将剩余的工人分配到其他项目中。
- en: Suppose we were developing software and we had a large number of computing resources.
    If we noticed that utilizing half the resources resulted in the same software
    performance, we could allocate the extra resources to do other things, such as
    increasing the accuracy or quality of that software in other areas.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在开发软件时拥有大量的计算资源。如果我们注意到利用一半的资源就能达到相同的软件性能，我们可以将额外的资源分配去做其他事情，例如在其他区域提高该软件的准确性或质量。
- en: The second argument against Amdahl’s law is that when you increase the problem’s
    size, the non-parallel part of the problem typically does not grow in proportion
    with the problem size. In fact, Gustafson argues that for many problems, this
    remains constant. Thus, when you take these two points into account, the speedup
    can scale linearly with the available parallel resources. This relationship is
    shown in figure 1.7.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 反对阿姆达尔定律的第二个论点是，当你增加问题的大小，问题的非并行部分通常不会与问题大小成比例增长。事实上，古斯塔夫森认为，对于许多问题，这一点保持不变。因此，当你考虑这两个点时，加速可以与可用的并行资源成线性比例。这种关系在图1.7中显示。
- en: '![](../../OEBPS/Images/CH01_F07_Cutajar.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH01_F07_Cutajar.png)'
- en: Figure 1.7 The speedup against the number of processors according to Gustafson’s
    law
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 根据古斯塔夫森定律的加速与处理器数量的关系
- en: Gustafson’s law tells us that as long as we find ways to keep our extra resources
    busy, the speedup should continue to increase and not be limited by the serial
    part of the problem. However, this is only true if the serial part stays constant
    as we increase the problem size, which, according to Gustafson, is the case in
    many types of programs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 古斯塔夫森定律告诉我们，只要我们找到方法让我们的额外资源保持忙碌，加速应该会继续增加，而不会受到问题串行部分的限制。然而，这只在串行部分在我们增加问题大小时保持不变的情况下才成立，根据古斯塔夫森的说法，这在许多类型的程序中是成立的。
- en: To fully understand both Amdahl’s and Gustafson’s laws, let’s take a computer
    game as an example. Let’s say a particular computer game with rich graphics was
    written to make use of multiple computing processors. As time goes by and computers
    become more powerful, with more parallel processing cores, we can run that same
    game with a higher frame rate, giving us a smoother experience. Eventually, we
    get to a point where we’re adding more processors, but the frame rate is not increasing
    further. This happens when we hit the speedup limit. No matter how many processors
    we add, the game won’t run with higher frame rates. This is what Amdahl’s law
    is telling us—that there is a speedup limit for a particular problem of fixed
    size if it has a non-parallel portion.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面理解阿姆达尔定律和古斯塔夫森定律，让我们以一个电脑游戏为例。假设一个具有丰富图形的电脑游戏被编写来利用多个计算处理器。随着时间的推移，计算机变得越来越强大，拥有更多的并行处理核心，我们可以以更高的帧率运行相同的游戏，从而获得更平滑的体验。最终，我们会达到一个点，即我们添加更多的处理器，但帧率不再进一步增加。这发生在我们达到加速极限时。无论我们添加多少处理器，游戏都不会以更高的帧率运行。这就是阿姆达尔定律告诉我们的——如果一个问题有固定的大小并且有一个非并行部分，那么它有一个加速极限。
- en: However, as technology improves and processors get more cores, the game designers
    will put those extra processing units to good use. Although the frame rate might
    not increase, the game can now contain more graphic detail and higher resolution
    due to the extra processing power. This is Gustafson’s law in action. When we
    increase the resources, there is an expectation of an increase in the system’s
    capabilities, and the developers will make good use of the extra processing power.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，随着技术的进步和处理器核心数量的增加，游戏设计师将充分利用这些额外的处理单元。尽管帧率可能不会增加，但由于额外的处理能力，游戏现在可以包含更多的图形细节和更高的分辨率。这就是古斯塔夫森定律在起作用。当我们增加资源时，我们期望系统能力有所增加，开发者将充分利用额外的处理能力。
- en: Summary
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Concurrent programming allows us to build more responsive software.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发编程使我们能够构建更响应的软件。
- en: Concurrent programs can also provide increased speedup when running on multiple
    processors.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发程序在多个处理器上运行时也可以提供更高的加速。
- en: We can increase throughput even when we have only one processor if our concurrent
    programming makes effective use of the I/O wait times.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使只有一个处理器，只要我们的并发编程能够有效地利用 I/O 等待时间，我们仍然可以增加吞吐量。
- en: Go provides us with goroutines, which are lightweight constructs for modeling
    concurrent executions.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go 为我们提供了 goroutines，这是一种用于建模并发执行的轻量级结构。
- en: Go provides us with abstractions, such as channels, that enable concurrent executions
    to communicate and synchronize.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go 提供了诸如通道等抽象，这些抽象使得并发执行能够进行通信和同步。
- en: Go allows us the choice of building our concurrent application either using
    the communicating sequential processes (CSP)-style model or using the classical
    primitives.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go 允许我们选择使用通信顺序进程（CSP）风格的模型，或者使用经典原语来构建我们的并发应用程序。
- en: Using a CSP-style model, we reduce the chance of certain types of concurrent
    errors; however, for certain problems, using the classical primitives will give
    us better results.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 CSP 风格的模型，我们减少了某些类型并发错误的可能性；然而，对于某些问题，使用经典原语将给我们带来更好的结果。
- en: Amdahl’s law tells us that the performance scalability of a fixed-size problem
    is limited by the non-parallel parts of an execution.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阿姆达尔定律告诉我们，固定大小问题的性能可扩展性受到执行非并行部分的限制。
- en: Gustafson’s law tells us that if we keep on finding ways to keep our extra resources
    busy, the speedup should continue to increase and not be limited by the serial
    part of the problem.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 古斯塔夫森定律告诉我们，如果我们不断找到让我们的额外资源保持忙碌的方法，加速应该会继续增加，而不会受到问题串行部分的限制。
