- en: 2 Building a serverless image recognition system, part 1
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 构建无服务器图像识别系统，第一部分
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节涵盖
- en: Building a simple AI as a Service system
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建简单的AI as a Service系统
- en: Setting up the cloud environment
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置云环境
- en: Setting up a local development environment
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置本地开发环境
- en: Implementing a simple asynchronous service
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现简单的异步服务
- en: Deploying to the cloud
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署到云端
- en: In this chapter and in chapter 3 we will focus on building our first AI-enabled
    serverless system. By the end, you will have configured and deployed to the cloud
    a small system that is capable of reading and recognizing images from a web page
    and displaying the results for review. This may sound like an awful lot of work
    for a single chapter and indeed, before the advent of Serverless and off-the-shelf
    AI, the progress that we will make in this chapter would have taken a small team
    of engineers many person-months to complete. As Isaac Newton stated, we stand
    on the shoulders of giants! In this chapter we will stand on the shoulders of
    countless software engineers and AI experts to rapidly assemble our “hello world”
    system.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章和第3章中，我们将专注于构建我们的第一个具有AI功能的无服务器系统。到结束时，你将配置并部署到云端一个能够从网页读取和识别图像并显示结果以供审查的小型系统。这听起来可能是一个章节中要做的大量工作，确实如此，在无服务器和现成AI出现之前，我们将在本章取得的成绩需要一个小团队工程师数月的工作量来完成。正如艾萨克·牛顿所说，我们站在巨人的肩膀上！在本章中，我们将站在无数软件工程师和AI专家的肩膀上，快速组装我们的“hello
    world”系统。
- en: If you are new to AWS and serverless technology, there is an awful lot to take
    in over the course of these two chapters. Our aim is go slowly and to provide
    a lot of detail in order to bring everyone up to speed. We will take a “paint
    by numbers” approach, so if you follow the code and deployment instructions carefully,
    you should be just fine.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你刚开始接触AWS和无服务器技术，在这两个章节中，你将需要吸收大量的信息。我们的目标是慢慢来，并提供很多细节，以便让每个人都能跟上进度。我们将采取“按数字绘画”的方法，所以如果你仔细遵循代码和部署说明，你应该会做得很好。
- en: As you progress through these pages, no doubt several questions will pop into
    your head, such as “How do I debug this?” or “How should I unit test this?” Rest
    assured that we will provide more detail in subsequent chapters; for now, grab
    some coffee and buckle up!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你翻阅这些页面，无疑会有几个问题出现在你的脑海中，比如“我该如何调试这个？”或者“我应该如何进行单元测试？”请放心，我们将在后续章节中提供更多细节；现在，请拿一些咖啡，系好安全带！
- en: 2.1 Our first system
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 我们的第一个系统
- en: Our first serverless AI system will use Amazon Rekognition to analyze the images
    on a web page. From an analysis of these images, the system will generate a word
    cloud and provide a list of tags for each image. We will develop the system as
    a number of discrete, decoupled services. A screenshot of the finished user interface
    is shown in figure 2.1.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个无服务器AI系统将使用Amazon Rekognition来分析网页上的图像。通过对这些图像的分析，系统将生成一个词云并为每个图像提供标签列表。我们将开发这个系统作为一个由多个离散、解耦的服务组成的系统。完成的用户界面截图显示在图2.1中。
- en: '![](../Images/CH02_F01_Elger.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F01_Elger.png)'
- en: Figure 2.1 Finished UI
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 完成的UI
- en: In this case, we pointed our system to a web page that contains images of cats.
    The image recognition AI has correctly identified the cats and allowed us to construct
    a word cloud and a histogram of the detected label frequency from this analysis.
    The system then shows us each image that was analyzed, along with the results
    of the analysis and a confidence level for each tag.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将系统指向包含猫的图片的网页。图像识别AI正确识别了猫，并允许我们从这个分析中构建一个词云和检测标签频率的直方图。然后系统向我们展示了每个被分析的图像，以及分析结果和每个标签的置信度。
- en: 2.2 Architecture
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 架构
- en: Before we dive into implementation, let’s take a look at the architecture for
    this simple system to see how it maps to the canonical architecture that we developed
    in chapter 1, and how the services collaborate to delver this functionality. Figure
    2.2 depicts the overall structure of the system.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入实施之前，让我们看看这个简单系统的架构，看看它如何映射到我们在第1章中开发的规范架构，以及服务如何协作以提供此功能。图2.2描述了系统的整体结构。
- en: '![](../Images/CH02_F02_Elger.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F02_Elger.png)'
- en: Figure 2.2 System architecture. The system is composed of custom services built
    using AWS Lambda and API Gateway. SQS is used for message communication. The managed
    services used here are S3 and Rekognition.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 系统架构。系统由使用AWS Lambda和API Gateway构建的自定义服务组成。SQS用于消息通信。这里使用的管理服务是S3和Rekognition。
- en: 'The system architecture shows the layers of the system:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 系统架构显示了系统的层级：
- en: Starting with the front end, served from S3 (Simple Storage Service), APIs are
    invoked through the API Gateway.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从前端开始，由S3（简单存储服务）提供，通过API网关调用API。
- en: The asynchronous Lambda functions are triggered by SQS (Simple Queue Service)
    messages.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步Lambda函数由SQS（简单队列服务）消息触发。
- en: The synchronous Lambda functions are triggered by events coming from the API
    Gateway.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步Lambda函数由来自API网关的事件触发。
- en: AWS Rekognition is a fully managed AI image analysis service.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Rekognition是一个完全管理的AI图像分析服务。
- en: 2.2.1 Web application
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.1 网络应用程序
- en: The front end of the system is a single-page application comprising HTML, CSS,
    and some simple JavaScript to render the UI, as highlighted in figure 2.3\. You
    will see this figure repeated throughout the chapter as we walk through the building
    blocks of our system.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的前端是一个单页应用程序，由HTML、CSS和一些简单的JavaScript组成，用于渲染UI，如图2.3所示。您将在本章中多次看到此图，因为我们将介绍我们系统的基础构建块。
- en: '![](../Images/CH02_F03_Elger.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH02_F03_Elger.png)'
- en: Figure 2.3 Web application
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 网络应用程序
- en: The front end is deployed into an S3 bucket. Also in this tier, we are using
    API Gateway to provide a route into the synchronous services that provide data
    for the front end to render.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 前端部署到一个S3存储桶中。在这个层级中，我们使用API网关提供进入同步服务的路由，这些同步服务为前端提供渲染数据。
- en: 2.2.2 Synchronous services
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.2 同步服务
- en: There are three synchronous services implemented as Lambda functions, as shown
    in figure 2.4.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个同步服务作为Lambda函数实现，如图2.4所示。
- en: '![](../Images/CH02_F04_Elger.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH02_F04_Elger.png)'
- en: Figure 2.4 Synchronous services
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 同步服务
- en: 'These services are available as RESTful endpoints accessed through the API
    gateway:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些服务作为通过API网关访问的RESTful端点提供：
- en: '`POST /url/analyze`--This endpoint takes a URL in the body and submits it to
    an SQS queue for analysis.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`POST /url/analyze`--此端点接收一个包含URL的请求体，并将其提交到SQS队列以进行分析。'
- en: '`GET /url/list`--Used by the front end to fetch the list of URLs that have
    been processed by the system.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GET /url/list`--由前端使用，以获取系统已处理的URL列表。'
- en: '`GET /image/list`--Returns the set of images and analysis results that have
    been processed for a given URL.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GET /image/list`--返回给定URL已处理的图像和分析结果集。'
- en: 'To trigger the analysis, the user of our system inputs a URL into the input
    field at the top of the UI and clicks the Analysis button. This will make a POST
    request to `/url/analyze`, which will result in a JSON message post to an SQS
    queue of the form:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要触发分析，我们的系统用户在UI顶部的输入字段中输入一个URL，然后点击分析按钮。这将向`/url/analyze`发送一个POST请求，这将导致一个JSON消息被发送到一个形式为SQS队列的消息：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 2.2.3 Asynchronous services
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.3 异步服务
- en: The asynchronous services form the main processing engine of the system. There
    are two main services, highlighted in figure 2.5.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 异步服务构成了系统的主处理引擎。有两个主要服务，如图2.5所示。
- en: '![](../Images/CH02_F05_Elger.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH02_F05_Elger.png)'
- en: Figure 2.5 Asynchronous services
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 异步服务
- en: The crawler service extracts images from an HTML page. The analysis service
    provides an interface to AWS Rekognition, submitting images for analysis and collating
    the results.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 爬虫服务从HTML页面中提取图像。分析服务提供了一个AWS Rekognition的接口，提交图像进行分析并汇总结果。
- en: 'On receipt of a “download” message, the crawler service will fetch the HTML
    from the provided URL. The crawler will then parse this HTML and extract the source
    attributes for each of the inline image tags in the page. The crawler will then
    download each image and store it in an S3 bucket. Once all of the images have
    been downloaded, the crawler will post an analyze message to the analysis SQS
    queue of the form:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在收到“下载”消息后，爬虫服务将从提供的URL中获取HTML。爬虫将解析此HTML，并提取页面中每个内联图像标签的源属性。然后，爬虫将下载每个图像并将其存储在S3存储桶中。一旦所有图像都下载完毕，爬虫将向分析SQS队列发送一个分析消息：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This message will be picked up by the analysis service, which will call out
    to the image recognition AI for each downloaded image, collect the results, and
    write them into the bucket for later display by the front end.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 此消息将被分析服务获取，该服务将为每个下载的图像调用图像识别AI，收集结果，并将它们写入存储桶以供前端稍后显示。
- en: 2.2.4 Communication services
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.4 通信服务
- en: Internally, the system uses the Simple Queue Service (SQS) as a message pipeline,
    as shown in figure 2.6.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 内部，系统使用简单队列服务（SQS）作为消息管道，如图2.6所示。
- en: '![](../Images/CH02_F06_Elger.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH02_F06_Elger.png)'
- en: Figure 2.6 Communication and data services
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 通信和数据服务
- en: As we will see throughout this book, this messaging approach is a powerful pattern
    that allows us to add services to and remove them from our system with little
    or no perturbation to the system as a whole. It also forces us to keep our services
    decoupled and provides a clean model to individually scale services.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在整本书中看到的那样，这种消息传递方法是一种强大的模式，它允许我们在几乎不影响整个系统的情况下向系统中添加服务或从系统中移除服务。它还迫使我们保持服务解耦，并为单独扩展服务提供了一个清晰的模型。
- en: For this system, we are using SQS as our primary communication mechanism, but
    we use the term *communication services* to encompass any infrastructural technology
    that can be used to facilitate communication between consumers and services. Typically
    this will require some form of service discovery and one or more communication
    protocols. Figure 2.7 depicts an isolated view of the communication services for
    our system.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个系统，我们使用 SQS 作为我们的主要通信机制，但我们使用术语 *通信服务* 来涵盖任何可以用来促进消费者和服务之间通信的基础设施技术。通常这需要某种形式的服务发现和一个或多个通信协议。图
    2.7 描述了我们系统通信服务的隔离视图。
- en: '![](../Images/CH02_F07_Elger.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.7 Elger](../Images/CH02_F07_Elger.png)'
- en: Figure 2.7 Communication services
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 通信服务
- en: The communication services shown are Route 53 DNS (Domain Name System) for service
    discovery and HTTP and SQS as the communication protocols. Typically we will use
    the JSON data format to encode messages between parties. This is independent of
    the underlying communication protocol.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所示的通信服务包括用于服务发现的 Route 53 DNS（域名系统）以及 HTTP 和 SQS 作为通信协议。通常，我们将使用 JSON 数据格式来编码双方之间的消息。这与底层通信协议无关。
- en: Messaging technology
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递技术
- en: 'Messaging systems, queuing, and related technology are a large topic and we
    won’t cover them in detail in this book. However you should be aware of the concepts
    if you aren’t already. In brief, messaging systems typically support either of
    two models--point to point or publish/subscribe:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 消息传递系统、队列和相关技术是一个大主题，我们不会在本书中详细讨论。然而，如果你还没有意识到这些概念，你应该了解它们。简而言之，消息传递系统通常支持两种模型之一--点对点或发布/订阅：
- en: Point to point--Under this model, a message that is placed into a queue is delivered
    to one consumer and one consumer only.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点对点--在这个模型下，放入队列的消息仅被发送给一个消费者，仅此一个消费者。
- en: Publish/subscribe--Under this model, all consumers that have registered an interest
    in a message type receive the message.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布/订阅--在这个模型下，所有已注册对某种消息类型感兴趣的所有消费者都将接收到该消息。
- en: 'Queue systems also differ in how consumers are informed of a new message. Broadly,
    this can happen in one of three ways:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 队列系统在通知消费者新消息的方式上也存在差异。总的来说，这可以通过以下三种方式之一发生：
- en: Push--The queue system will push the message to the consumer(s).
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推送--队列系统将消息推送到消费者（们）。
- en: Poll--The consumers will poll the queue for messages.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮询--消费者将轮询队列以获取消息。
- en: Long poll--the consumes will poll for an extended period of time.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长轮询--消费者将进行一段较长时间的轮询。
- en: In this chapter, SQS will push messages to our consuming Lambda function.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，SQS 将将消息推送到我们的消费 Lambda 函数。
- en: For a primer on this subject we recommend *Enterprise Integration Patterns*
    by Gregor Hohpe and Bobby Woolf (Addison-Wesley Professional, 2003).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个主题的入门，我们推荐 Gregor Hohpe 和 Bobby Woolf 的《企业集成模式》（Addison-Wesley Professional，2003年）。
- en: 2.2.5 AI services
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.5 人工智能服务
- en: This system uses only a single AI service, Amazon Rekognition. This AI service
    provides a number of different image recognition modes including object and scene
    detection, facial recognition, facial analysis, celebrity recognition, and text
    detection in images. For this first system, we are using the default object and
    scene detection API.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这个系统只使用一个人工智能服务，即 Amazon Rekognition。这个人工智能服务提供多种不同的图像识别模式，包括对象和场景检测、面部识别、面部分析、名人识别以及图像中的文本检测。对于这个第一个系统，我们使用默认的对象和场景检测
    API。
- en: 2.2.6 Data services
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.6 数据服务
- en: In the Data Services tier, we are using only the Simple Storage Service (S3).
    This is sufficient for our needs in this initial platform; we will explore other
    data services in subsequent chapters.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据服务层，我们只使用简单存储服务（S3）。这对于我们在这个初始平台的需求来说是足够的；我们将在后续章节中探索其他数据服务。
- en: 2.2.7 Development support and operational support
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.7 开发支持和运营支持
- en: We are using the serverless framework as our main development-support system.
    All logging data is collected using CloudWatch. We will discuss each of these
    in more detail in the following sections.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用无服务器框架作为我们的主要开发支持系统。所有日志数据都使用CloudWatch收集。我们将在接下来的章节中更详细地讨论这些内容。
- en: 2.3 Getting ready
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 准备工作
- en: Now that we have seen the end goal, let’s dive in and put the system together.
    You will need an active AWS account. If you don’t already have an AWS account,
    you will need to create one. If you are new to AWS, then please refer to appendix
    A, which has instructions to get you set up.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了最终目标，让我们深入其中，将系统组合起来。您需要一个活跃的AWS账户。如果您还没有AWS账户，您需要创建一个。如果您是AWS的新手，请参阅附录A，其中包含了帮助您设置的说明。
- en: For those of you familiar with AWS, we suggest that you create a separate sub-account
    to keep the examples in this book clear of any other systems you may be running.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于熟悉AWS的各位，我们建议您创建一个独立的子账户，以保持本书中的示例不受您可能正在运行的任何其他系统的影响。
- en: Appendix A also contains instructions for creating API keys and configuring
    command-line and API access, so we suggest that even experienced AWS developers
    review this material to ensure a correct development environment.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 附录A还包含了创建API密钥和配置命令行及API访问的说明，因此我们建议即使是经验丰富的AWS开发者也应该回顾这些材料，以确保正确的开发环境。
- en: Tip All example code has been tested in the `eu-west-1` region; we suggest that
    you also use this region for deployment of code.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士：所有示例代码已在`eu-west-1`区域进行了测试；我们建议您在代码部署时也使用此区域。
- en: Warning Using AWS costs money! Please ensure that any cloud infrastructure is
    destroyed once you are finished with it. We have provided scripts to help with
    resource removal at the end of each chapter.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：使用AWS需要付费！请确保您完成使用后，任何云基础设施都被销毁。我们已在每章末尾提供了帮助资源移除的脚本。
- en: 2.3.1 DNS domain and SSL/TLS certificate
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.1 DNS域名和SSL/TLS证书
- en: The example in this chapter and others throughout the book require that a DNS
    domain and associated certificate be in place. These can be set up easily on AWS,
    and full instructions on how to do this are provided in appendix D. Before attempting
    to run the examples, please ensure that you have set up your AWS environment as
    per the instructions provided in appendix D.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的示例以及本书其他部分的示例都需要一个DNS域名及其相关证书。这些可以在AWS上轻松设置，如何在附录D中提供了完整的说明。在尝试运行示例之前，请确保您已根据附录D中提供的说明设置了您的AWS环境。
- en: Node.js
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Node.js
- en: We use Node.js as our main development platform in this book. If you haven’t
    installed it already, you need to.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本书中使用Node.js作为主要开发平台。如果您还没有安装它，您需要安装。
- en: Why Node.js?
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么选择Node.js？
- en: We selected Node.js as our development platform for this book because of the
    ubiquity of JavaScript, which is available in every major web browser as well
    as server-side with the Node.js platform. Additionally, JavaScript is available
    as an implementation language for all of the major FaaS offerings, all of which
    makes it the natural choice.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择Node.js作为本书的开发平台，因为JavaScript的普遍性，它不仅可在每个主要网络浏览器中使用，还可以在Node.js平台上作为服务器端使用。此外，JavaScript还是所有主要FaaS（无服务器功能即服务）提供的实现语言，所有这些都使其成为自然的选择。
- en: Don’t worry if you haven’t used Node.js before. If you know even a small amount
    of JavaScript, you’ll be just fine. We can highly recommend the tutorial series
    at Node School if you want to brush up on Node (and even JavaScript). Head over
    to [https://nodeschool.io/](https://nodeschool.io/) to get started.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您之前没有使用过Node.js，请不要担心。如果您甚至只了解一点JavaScript，您也会做得很好。如果您想复习Node（甚至JavaScript），我们强烈推荐Node
    School的教程系列。前往[https://nodeschool.io/](https://nodeschool.io/)开始学习。
- en: At the time of writing, the current LTS (long term supported) versions of Node.js
    are 10.x and 12.x. Binary installers are available from [https://nodejs.org/](https://nodejs.org/).
    Download and install the appropriate binary for your development machine.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，当前的长期支持（LTS）版本的Node.js是10.x和12.x。可以从[https://nodejs.org/](https://nodejs.org/)下载二进制安装程序，为您的开发机器安装适当的二进制文件。
- en: Note The latest supported version of Node.js on AWS where we will be building
    this system is 12.x. For consistency, it’s best to choose the latest 12.x LTS
    release in your local development environment.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们将构建此系统的AWS上支持的最新Node.js版本是12.x。为了保持一致性，最好在您的本地开发环境中选择最新的12.x LTS版本。
- en: 'Once the installer has run, check that all is well by opening a console window
    and checking the Node.js and NPM versions using these commands:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 安装程序运行后，请打开控制台窗口并使用以下命令检查一切是否正常：
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: NPM
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: NPM
- en: 'NPM is the package management system for Node.js. For each of our example systems,
    we will use NPM to manage dependent software units called *node modules*. If you
    are unfamiliar with NPM, we can recommend the NPM tutorial at Node School: [https://nodeschool.io/#workshopper-list](https://nodeschool.io/#workshopper-list).'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: NPM 是 Node.js 的包管理系统。对于我们的每个示例系统，我们将使用 NPM 来管理称为 *node 模块* 的依赖软件单元。如果您不熟悉 NPM，我们可以在
    Node School 的 NPM 教程中推荐您：[https://nodeschool.io/#workshopper-list](https://nodeschool.io/#workshopper-list)。
- en: The Serverless Framework
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Serverless Framework
- en: Next, we will need to install the Serverless Framework. This provides a layer
    of abstraction and configuration above the base AWS API, and helps us to more
    easily create and consume cloud services. We will make extensive use of the Serverless
    Framework throughout this book, so it should become familiar. We install Serverless
    using NPM. Open a console window and run
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要安装 Serverless Framework。这个框架在基础 AWS API 之上提供了一层抽象和配置，帮助我们更轻松地创建和消费云服务。在这本书中，我们将广泛使用
    Serverless Framework，因此它应该变得熟悉。我们使用 NPM 安装 Serverless。打开控制台窗口并运行
- en: '[PRE3]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: NPM global installs
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: NPM 全局安装
- en: Running `npm` `install` with the `-g` flag tells NPM to install a module globally.
    This makes the module available on the path so that it can be executed as a system
    command.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `-g` 标志运行 `npm install` 告诉 NPM 全局安装一个模块。这使得模块可在路径上可用，因此可以作为系统命令执行。
- en: Check that Serverless installed successfully by running
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令来检查 Serverless 是否成功安装
- en: '[PRE4]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The Serverless Framework
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Serverless Framework
- en: There are several frameworks available to help support serverless development.
    The leading framework at the time of writing is the Serverless Framework, which
    is implemented in Node.js. Under the hood, the framework uses the Node.js AWS
    API to accomplish its work, and for AWS it leans heavily on CloudFormation. In
    this chapter we will just use the framework without going into detail about how
    it works. For now the key point to understand is that the framework allows us
    to define infrastructure and Lambda functions as code, which means that we can
    manage our operational resources in a similar manner to how we manage the rest
    of the source code for our system.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个框架可用于帮助支持无服务器开发。在撰写本文时，领先的框架是 Serverless Framework，它由 Node.js 实现。在底层，该框架使用
    Node.js AWS API 来完成其工作，并且对于 AWS，它大量依赖于 CloudFormation。在本章中，我们将仅使用该框架，而不会详细介绍其工作原理。目前，我们需要理解的关键点是，该框架允许我们将基础设施和
    Lambda 函数定义为代码，这意味着我们可以以类似管理系统其他源代码的方式管理我们的操作资源。
- en: Note If you’re curious to know more about Serverless, we have provided an in-depth
    look at how the framework operates in appendix E.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 如果您想了解更多关于 Serverless 的信息，我们已在附录 E 中提供了框架操作的深入了解。
- en: Tip Chapter 6 covers some advanced serverless topics and provides a production
    grade template for your projects.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 提示 第 6 章涵盖了某些高级无服务器主题，并为您的项目提供了生产级别的模板。
- en: 2.3.2 Setup checklist
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.2 设置清单
- en: 'Before we proceed with the code. Please review this checklist to ensure that
    everything is in place:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续编写代码之前，请查看此清单以确保一切就绪：
- en: Appendix A
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 附录 A
- en: AWS account created
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS 账户已创建
- en: AWS command line installed
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS 命令行已安装
- en: AWS access keys created
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS 访问密钥已创建
- en: Development shell configured with access keys and verified
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发外壳配置了访问密钥并已验证
- en: Appendix D
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 附录 D
- en: Route 53 domain registered
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Route 53 域已注册
- en: SSL/TLS Certificate created
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: SSL/TLS 证书已创建
- en: This chapter
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章
- en: Node.js installed
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Node.js 已安装
- en: Serverless Framework installed
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Serverless Framework 已安装
- en: If all of the this is in place, we are good to go!
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所有这些都已经就绪，我们就可以开始了！
- en: Warning Please ensure that all of the items in this checklist are completed;
    otherwise you may encounter issues when trying to run the example code. In particular,
    please ensure that *both* the environment variables `AWS_REGION` and `AWS_DEFAULT_REGION`
    are set and point to the same AWS region, as described in appendix A.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 警告 请确保完成此清单中的所有项目；否则，在尝试运行示例代码时可能会遇到问题。特别是，请确保已设置环境变量 `AWS_REGION` 和 `AWS_DEFAULT_REGION`，并且它们指向附录
    A 中描述的同一 AWS 区域。
- en: 2.3.3 Get the code
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.3 获取代码
- en: 'Now that we have a basic setup done, we can proceed to grab the code for the
    system. The source code for this chapter is available in this repository: [https://github.com/fourTheorem/ai-as-a-service](https://github.com/fourTheorem/ai-as-a-service)
    in the `chapter2-3` subdirectory. To get started, go ahead and clone this repository:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了基本设置，我们可以继续获取系统的代码。本章的源代码存储在本仓库的`chapter2-3`子目录中：[https://github.com/fourTheorem/ai-as-a-service](https://github.com/fourTheorem/ai-as-a-service)。要开始，请先克隆此仓库：
- en: '[PRE5]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The code maps to the architecture as you might expect. There is a top-level
    directory for each defined service, as shown in the following listing.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 代码映射到您可能预期的架构。每个定义的服务都有一个顶级目录，如下所示。
- en: Listing 2.1 Repository structure
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.1 仓库结构
- en: '[PRE6]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 2.3.4 Setting up cloud resources
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.4 设置云资源
- en: In addition to our services folders, we also have a top-level directory called
    *resources*. Our system relies on a number of cloud resources, and before we can
    deploy any of the service elements, we need these resources to be in place. For
    the case of our simple system, we will need an SQS queue for asynchronous communication
    and an S3 bucket to hold downloaded images. We will deploy these using a dedicated
    Serverless Framework configuration file. Let’s take a look at how this is done.
    `cd` into the `chapter2-3/resources` resources directory and take a look at the
    `serverless.yml` file, shown in the next listing.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们的服务文件夹外，我们还有一个名为*resources*的顶级目录。我们的系统依赖于许多云资源，在我们能够部署任何服务元素之前，我们需要这些资源已经就绪。对于我们的简单系统，我们需要一个SQS队列用于异步通信和一个S3存储桶来存储下载的图像。我们将使用专门的Serverless
    Framework配置文件来部署这些资源。让我们看看这是如何完成的。进入`chapter2-3/resources`资源目录，查看下一个列表中的`serverless.yml`文件。
- en: Listing 2.2 Serverless configuration for resources
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.2 资源的服务器无配置
- en: '[PRE7]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Service name
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 服务名称
- en: ❷ Custom definitions
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 自定义定义
- en: ❸ Provider-specific
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 特定提供者
- en: ❹ Bucket definition
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 存储桶定义
- en: ❺ Bucket policy
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 存储桶策略
- en: ❻ Queue definitions
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 队列定义
- en: 'Tip Serverless uses the *YAML* file format for its configuration. YAML stands
    for *YAML Ain’t Markup Language*; you can find more information on YAML at this
    site: [http://yaml.org/](http://yaml.org/).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：Serverless使用*YAML*文件格式进行配置。YAML代表*YAML Ain’t Markup Language*；您可以在本网站上找到有关YAML的更多信息：[http://yaml.org/](http://yaml.org/)。
- en: Don’t worry if this looks overwhelming at first. We will be using the Serverless
    Framework throughout this book, so these configuration files will become very
    familiar. Let’s take a look at the overall structure of this file.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一开始看起来令人不知所措，请不要担心。我们将在这本书中一直使用Serverless Framework，因此这些配置文件将变得非常熟悉。让我们看看这个文件的总体结构。
- en: 'Tip Full documentation for the Serverless Framework and its configuration can
    be found at the project’s main site: [https://serverless.com/framework/docs/](https://serverless.com/framework/docs/).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：Serverless Framework及其配置的完整文档可以在项目的主要网站上找到：[https://serverless.com/framework/docs/](https://serverless.com/framework/docs/)。
- en: The Serverless configuration is broken down into several top-level sections.
    The key ones to understand are
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器无配置被分解为几个顶级部分。其中关键的部分是
- en: '`custom`--Defines attributes to be used elsewhere in the configuration.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom`--定义在配置中其他地方使用的属性。'
- en: '`provider`--Defines provider-specific configuration to the framework. In this
    example we are using AWS as the provider; however, the framework supports multiple
    cloud platforms'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`provider`--定义框架中特定提供者的配置。在本例中，我们使用AWS作为提供者；然而，该框架支持多个云平台'
- en: '`functions`--Defines function endpoints that the service implements. In this
    example we don’t have any functions to define, so this section is not present
    in this example.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`functions`--定义服务实现的功能端点。在本例中，我们没有要定义的功能，因此本例中不存在此部分。'
- en: '`resources`--Defines supporting resources on the cloud platform. In this example
    we are defining two SQS queues and an S3 bucket. When we deploy this configuration,
    the Serverless Framework will create the queues and bucket for us.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resources`--定义云平台上的支持资源。在本例中，我们定义了两个SQS队列和一个S3存储桶。当我们部署此配置时，Serverless Framework将为我们创建队列和存储桶。'
- en: Note There are many other tools that can be used to deploy cloud resources,
    such as AWS CloudFormation or Hashicorp’s Terraform, both of which are great tools
    for managing infrastructure as code. We would recommend investigating these if
    you have an infrastructure-intensive project. For this book we will be using the
    Serverless Framework almost exclusively. We also note that the Serverless Framework
    uses CloudFormation on AWS under the hood; we cover this in more detail in appendix
    E.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：还有许多其他工具可以用来部署云资源，例如AWS CloudFormation或Hashicorp的Terraform，这两者都是管理基础设施代码的出色工具。如果你有一个基础设施密集型项目，我们建议调查这些工具。对于这本书，我们将几乎完全使用无服务器框架。我们还注意到，无服务器框架在AWS底层使用CloudFormation；我们将在附录E中更详细地介绍这一点。
- en: 'Before we can go ahead and deploy our resources, we need to decide on a bucket
    name. The AWS bucket name space is global, so you should pick a name that is available
    and add an additional environment variable, `CHAPTER2_BUCKET`, to your shell in
    the same way that we set up the AWS environment variables:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续部署资源之前，我们需要确定一个存储桶名称。AWS存储桶名称空间是全球性的，因此你应该选择一个可用的名称，并在你的shell中添加一个额外的环境变量`CHAPTER2_BUCKET`，就像我们设置AWS环境变量一样：
- en: '[PRE8]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Replace `<YOUR BUCKET NAME>` with a unique name of your choosing. Now we are
    all set, so let’s go ahead and deploy our resources. From a command shell in the
    `chapter2-3/resources` directory, run
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 将`<YOUR BUCKET NAME>`替换为你选择的唯一名称。现在我们已经准备好了，让我们继续部署资源。在`chapter2-3/resources`目录的命令行中运行
- en: '[PRE9]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Serverless will go ahead and deploy our resources, and you should see output
    similar to the following listing.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器将自动部署我们的资源，你应该会看到类似以下列表的输出。
- en: Listing 2.3 Serverless deploy output
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.3 无服务器部署输出
- en: '[PRE10]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Serverless has created an S3 bucket and an SQS queues for us. Now that we have
    our supporting infrastructure, we can move on to the actual implementation!
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 无服务器已经为我们创建了一个S3存储桶和一个SQS队列。现在我们已经有了支持的基础设施，我们可以继续进行实际实现了！
- en: 2.4 Implementing the asynchronous services
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 实现异步服务
- en: With our basic setup done, we can proceed to write our first services. In this
    section we will put together the crawler and analysis asynchronous services and
    test them in isolation.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成基本设置后，我们可以继续编写我们的第一个服务。在本节中，我们将组合爬虫和分析异步服务，并在隔离状态下测试它们。
- en: 2.4.1 Crawler service
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.1 爬虫服务
- en: First up, let’s take a look at the `crawler-service` code. Figure 2.8 illustrates
    the process flow inside this service.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看`crawler-service`的代码。图2.8展示了该服务内部的流程。
- en: '![](../Images/CH02_F08_Elger.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F08_Elger.png)'
- en: Figure 2.8 Crawler service
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 爬虫服务
- en: The `crawler-service` is invoked when a message is placed on the `crawler` queue.
    The message contains a target URL for the service to crawl. Once invoked, the
    crawler fetches the HTML page at the specified URL, and parses out the image tags.
    Then, for each image in turn, it downloads the image into an S3 folder. Finally,
    once all of the images have been downloaded, it posts an `analyze` message to
    the `analysis` queue, including the domain name of the analyzed URL for further
    processing.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当消息被放置在`crawler`队列中时，会调用`crawler-service`。消息包含服务要爬取的目标URL。一旦被调用，爬虫会抓取指定URL的HTML页面，并解析出图像标签。然后，对于每个图像依次，它会将图像下载到S3文件夹中。最后，一旦所有图像都下载完毕，它会向`analysis`队列发送一个`analyze`消息，包括分析URL的域名以进行进一步处理。
- en: 'The code for the crawler service is located at `chapter2-3/crawler-service`.
    `cd` into this directory and you should see the files listed here:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 爬虫服务的代码位于`chapter2-3/crawler-service`。进入这个目录，你应该会看到以下列出的文件：
- en: '[PRE11]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: To get an understanding of the resources used by this service and the overall
    structure, we should first look at the file `serverless.yml`, which contains the
    configuration shown in the next listing.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解此服务使用的资源及其整体结构，我们首先应该查看文件`serverless.yml`，其中包含下一列表中显示的配置。
- en: Listing 2.4 `serverless.yml` for the crawler service
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.4 爬虫服务的`serverless.yml`
- en: '[PRE12]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ S3 bucket name
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ S3存储桶名称
- en: ❷ SQS queue name
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ SQS队列名称
- en: ❸ Account ID from local environment
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 本地环境中的账户ID
- en: ❹ S3 permissions
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ S3权限
- en: ❺ Allow receipt from crawler queue
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 允许从爬虫队列接收
- en: ❻ Allow posts to the analysis queue
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 允许向分析队列发送
- en: ❼ Define the handler function entry point
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 定义处理函数的入口点
- en: ❽ Function triggered by crawler queue
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 由爬虫队列触发的函数
- en: The effect of this configuration is to define and deploy our crawler service
    function to AWS, and allow it to be triggered by the crawler SQS queue that we
    deployed through the resource’s configuration. The key sections are
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置的效果是定义并部署我们的爬虫服务函数到AWS，并允许它通过资源配置中部署的爬虫SQS队列触发。关键部分如下
- en: '`custom`--Define attributes to be used elsewhere in the configuration.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`custom`--定义在配置中其他地方使用的属性。'
- en: '`provider`--The provider section in this configuration sets up the AWS permissions
    to allow the service to access the SQS queues, and also to give it permission
    to write to our S3 bucket.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`provider`--在此配置中的提供者部分设置AWS权限，允许服务访问SQS队列，并授予它写入我们S3存储桶的权限。'
- en: '`functions`--This section defines the service Lambda. The handler setting references
    the implementation, which we will look at shortly. The events entry connects the
    function to our previously deployed SQS crawler queue. Finally, the environment
    block defines the environment variables that will be available to our function.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`functions`--此部分定义了服务Lambda。处理器设置引用了实现，我们将在稍后查看。事件条目将函数连接到我们之前部署的SQS爬虫队列。最后，环境块定义了将可用于我们的函数的环境变量。'
- en: Note The permissions defined in the `iamRoleStatements` block maps directly
    to the AWS Identity and Access Management (IAM) model. Full documentation on this
    can be found on AWS at [https://aws.amazon.com/iam](https://aws.amazon.com/iam).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：`iamRoleStatements`块中定义的权限直接映射到AWS身份和访问管理（IAM）模型。关于这方面的完整文档可以在AWS上找到，网址为[https://aws.amazon.com/iam](https://aws.amazon.com/iam)。
- en: Unlike the previous `serverless.yml` file for our resources, this file does
    not define any resources. That is because we chose to define our resources outside
    of the scope of this service. In general, a good rule of thumb to adopt is that
    global or shared resources should be deployed in a common resource stack; resources
    that are used by a single service should be deployed with that specific service.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们资源之前的`serverless.yml`文件不同，此文件没有定义任何资源。这是因为我们选择在服务范围之外定义我们的资源。一般来说，一个很好的经验法则是，全局或共享资源应该部署在公共资源堆栈中；用于单个服务的资源应该与该特定服务一起部署。
- en: Tip Resource sections in Serverless YAML files define resources that will be
    created on deployment. Other services depending on this resource must be deployed
    after the resource has been created. We find that it is best to put global resources
    in a separate configuration.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在无服务器YAML文件中的“资源”部分定义了在部署时将创建的资源。依赖于此资源的其他服务必须在资源创建后部署。我们发现将全局资源放在单独的配置中是最好的做法。
- en: Let’s now take a look at the main implementation file for the crawler, which
    is in `handler.js`. At the top of the file we include a number of modules, as
    shown in the following listing.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在看看爬虫的主要实现文件`handler.js`。在文件顶部，我们包含了一些模块，如下所示。
- en: Listing 2.5 Crawler handler.js required modules
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.5 爬虫handler.js所需模块
- en: '[PRE13]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ request is a node module that implements a fully featured HTTP client.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ request是一个实现功能齐全的HTTP客户端的node模块。
- en: ❷ url is a core node module that understands how to parse URLs.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ url是一个核心node模块，它理解如何解析URL。
- en: ❸ Include the AWS SDK node module. In this case, we instantiate an S3 and an
    SQS object in order to interface with our S3 bucket and queue respectively.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 包含AWS SDK节点模块。在这种情况下，我们实例化了S3和SQS对象，以便分别与我们的S3存储桶和队列进行接口。
- en: ❹ ./images refers to our own module in the file images.js.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ ./images 指的是文件images.js中的我们自己的模块。
- en: 'The main entry point to this service is `crawlImages`. This function takes
    three parameters: `event`, `context`, and `cb`. The code for this is shown next.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 进入此服务的主要入口点是`crawlImages`。此函数接受三个参数：`event`、`context`和`cb`。下面的代码展示了这一部分。
- en: Listing 2.6 Crawler service entry point
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.6 爬虫服务入口点
- en: '[PRE14]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Loop over messages
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 遍历消息
- en: ❷ Crawl the URL for images.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 爬取图像的URL。
- en: ❸ Send message to SQS to trigger analysis
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 向SQS发送消息以触发分析
- en: 'The function takes three parameters as follows:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 函数接受以下三个参数：
- en: '`event`--Supplies information about the current event that is being processed.
    In this case, the event object holds an array of records taken from the SQS queue.'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`event`--提供有关正在处理的当前事件的详细信息。在这种情况下，事件对象包含从SQS队列中取出的记录数组。'
- en: '`context`--Used by AWS to supply contextual information for the call, such
    as the amount of available memory, execution time, and the client call context.'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`context`--由AWS用于提供调用上下文信息，例如可用内存量、执行时间和客户端调用上下文。'
- en: '`cb`--Callback function. This should be called by the handler with a result
    once processing is complete.'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`cb`--回调函数。处理完成后，应由处理程序调用此函数并传递结果。'
- en: Callbacks and asynchronous I/O
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 回调和异步 I/O
- en: Callback functions are a staple of JavaScript, allowing code to execute asynchronously
    and return a result through execution of a passed-in callback parameter. Callbacks
    are a natural syntactic fit for asynchronous I/O (as opposed to synchronous I/O),
    which is one of the reasons for the success of the Node.js platform. If you need
    to brush up on JavaScript functions and callbacks, we can recommend the Node School
    “Javascripting” tutorial which can be found at [https://nodeschool.io/](https://nodeschool.io/).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 回调函数是 JavaScript 的一个基本组成部分，允许代码异步执行并通过执行传入的回调参数返回结果。回调对于异步 I/O（与同步 I/O 相比）是一个自然的语法匹配，这也是
    Node.js 平台成功的原因之一。如果你需要复习 JavaScript 函数和回调，我们可以推荐 Node School 的“Javascripting”教程，该教程可在
    [https://nodeschool.io/](https://nodeschool.io/) 找到。
- en: Finally, for the crawler service, let’s take a brief look at the file `package.json`
    shown in the next listing. This file provides a set of Node module dependencies.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于捕获服务，让我们简要看看下一个列表中所示的 `package.json` 文件。此文件提供了一组 Node 模块依赖项。
- en: Listing 2.7 Crawler service `package.json`
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 2.7 捕获服务 `package.json`
- en: '[PRE15]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Sets the module version number
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置模块版本号
- en: ❷ Sets the aws-sdk module version
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 设置 aws-sdk 模块版本
- en: package.json
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: package.json
- en: Though the format of the `package.json` file is relatively straightforward,
    there are a few nuances, such as semantic version support and scripts. It would
    be beyond the scope of this book to describe the full details here. In-depth coverage
    of this topic is provided by NPM at [https://docs.npmjs.com/files/package.json](https://docs.npmjs.com/files/package.json).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `package.json` 文件的格式相对简单，但也有一些细微差别，例如语义版本支持脚本。在这里描述全部细节超出了本书的范围。关于这个主题的深入覆盖可以在
    NPM 的 [https://docs.npmjs.com/files/package.json](https://docs.npmjs.com/files/package.json)
    找到。
- en: This entry point function is pretty simple. It just calls the `crawl` function
    to download images from the URL provided in the event object, and once the crawl
    is complete, it queues a message to SQS indicating that the downloaded images
    are ready for analysis.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这个入口函数相当简单。它只是调用 `crawl` 函数从事件对象中提供的 URL 下载图像，一旦捕获完成，它将一条消息排队到 SQS，表明下载的图像已准备好进行分析。
- en: The main `crawl` function is shown in the following listing.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 主 `crawl` 函数在下面的列表中展示。
- en: Listing 2.8 `crawl` function
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 2.8 `crawl` 函数
- en: '[PRE16]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ The domain part is extracted from the requested URL.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从请求的 URL 中提取域名部分。
- en: ❷ The request module is used to fetch the HTML for the given URL.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用请求模块获取给定 URL 的 HTML。
- en: ❸ The parsed HTML content is handed off to the parseImageUrls function, which
    returns a list of images for download.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 解析的 HTML 内容被传递给 `parseImageUrls` 函数，该函数返回一个用于下载的图像列表。
- en: ❹ The list of images is passed into the fetchImages function, which downloads
    each image to the nominated bucket.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将图像列表传递给 `fetchImages` 函数，该函数将每个图像下载到指定的存储桶。
- en: ❺ Finally, the function writes a status file to the bucket for downstream services
    to consume before resolving the promise.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 最后，该函数将状态文件写入存储桶，以便下游服务在解析承诺之前消费。
- en: Promises and fat arrow
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Promises 和箭头函数
- en: 'If you are a little out of practice with JavaScript, you might be wondering
    what the construct `.then(result` => `{...` means. The fat arrow operator is a
    replacement for the `function` keyword (with a slight twist). For pragmatic purposes
    you can think of the following as equivalent:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你稍微有些 JavaScript 实践不足，你可能想知道构造 `.then(result => `{...` 的含义。箭头函数操作符是 `function`
    关键字的替代（略有变化）。出于实用目的，你可以将以下内容视为等价：
- en: '[PRE17]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `.then` construct defines a handler function to be called on resolution
    of a promise. Promises provide an alternative mechanism to callbacks for asynchronous
    I/O. Many folks prefer to use promises as opposed to callbacks, as it helps to
    keep code cleaner and avoid what is colloquially known as “Callback Hell.” If
    you are unfamiliar with promises, full details can be found at [https://www.promisejs.org/](https://www.promisejs.org/).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`.then` 构造定义了一个在承诺解析时被调用的处理函数。承诺为异步 I/O 提供了替代回调的机制。许多人更喜欢使用承诺而不是回调，因为它有助于使代码更干净，并避免俗称的“回调地狱”。如果你不熟悉承诺，可以在
    [https://www.promisejs.org/](https://www.promisejs.org/) 找到全部细节。'
- en: The `queueAnalysis` function, shown in the next listing, uses the AWS SQS interface
    to post a message to the analysis queue, which will later be picked up by the
    analysis service.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个列表中显示的`queueAnalysis`函数使用AWS SQS接口向分析队列发送消息，该消息稍后将被分析服务获取。
- en: Listing 2.9 `queueAnalysis` function
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.9 `queueAnalysis`函数
- en: '[PRE18]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Build the SQS endpoint URL.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建SQS端点URL。
- en: ❷ Construct the message body.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 构建消息正文。
- en: ❸ Post the message to SQS.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将消息发布到SQS。
- en: Now that we understand the code for the crawler, let’s deploy the service. First
    we will need to install the supporting node modules. To do this, `cd` into the
    `crawler-service` directory and run
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经理解了爬虫的代码，让我们部署这个服务。首先我们需要安装支持节点模块。为此，`cd`到`crawler-service`目录并运行
- en: '[PRE19]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can now deploy our service by running the Serverless Framework’s `deploy`
    command:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以通过运行Serverless Framework的`deploy`命令来部署我们的服务：
- en: '[PRE20]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Once this command has completed, we can check that all is well by inspecting
    the AWS Lambda console, which should look similar to figure 2.9.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦此命令完成，我们可以通过检查AWS Lambda控制台来确认一切正常，它应该类似于图2.9。
- en: '![](../Images/CH02_F09_Elger.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F09_Elger.png)'
- en: Figure 2.9 Crawler service Lambda
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 爬虫服务Lambda
- en: Before we move on to the analysis function, let’s test out the crawler by sending
    a message to SQS. Open the AWS console, go to the SQS service page, and select
    the `Chap2CrawlerQueue` in the appropriate region. Then select Send Message from
    the Queue Action drop-down.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续分析函数之前，让我们通过向SQS发送消息来测试爬虫。打开AWS控制台，转到SQS服务页面，并在相应区域中选择`Chap2CrawlerQueue`。然后从队列操作下拉菜单中选择发送消息。
- en: '![](../Images/CH02_F10_Elger.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F10_Elger.png)'
- en: Figure 2.10 Send SQS message
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10 发送SQS消息
- en: 'Paste the JSON shown here into the message window and click Send Message:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 将此处显示的JSON粘贴到消息窗口中，然后点击发送消息：
- en: '[PRE21]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*Note* We have created a simple static website using S3 for testing purposes
    that has some example images at the URL in the test message, but you can use a
    different URL if you prefer--for example, the results of a Google image search.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意* 我们为了测试目的创建了一个简单的静态网站，使用S3，并在测试消息中的URL上放置了一些示例图片，但如果你更喜欢，可以使用不同的URL--例如，谷歌图片搜索的结果。'
- en: The message will be appended to the SQS queue and picked up by the crawler service.
    We can take a look at the crawler logs to confirm that this indeed happened. Open
    up the AWS console and then open up CloudWatch. Click on the Logs menu item on
    the left side and then select the crawler service, listed as `crawler-service
    -dev-crawlimages`, to inspect the logs. You should see output similar to that
    shown in figure 2.11.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 消息将被附加到SQS队列，并由爬虫服务获取。我们可以查看爬虫日志以确认这一点。打开AWS控制台，然后打开CloudWatch。点击左侧的日志菜单项，然后选择爬虫服务，列出的为`crawler-service
    -dev-crawlimages`，以检查日志。你应该会看到类似于图2.11的输出。
- en: '![](../Images/CH02_F11_Elger.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F11_Elger.png)'
- en: Figure 2.11 CloudWatch logs for crawler
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11 爬虫的CloudWatch日志
- en: Finally let’s check that our images were downloaded correctly. Open up the AWS
    console and go to the S3 service. Select your bucket. You should see a folder
    named `ai-as-a-service.s3-website-eu-west-1.amazonaws.com`. Click into this to
    view the downloaded images, as shown in figure 2.12.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 最后让我们检查我们的图片是否正确下载。打开AWS控制台，转到S3服务。选择您的存储桶。您应该看到一个名为`ai-as-a-service.s3-website-eu-west-1.amazonaws.com`的文件夹。点击进入以查看下载的图片，如图2.12所示。
- en: '![](../Images/CH02_F12_Elger.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F12_Elger.png)'
- en: Figure 2.12 Downloaded images
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12 下载的图片
- en: In the next chapter we will turn our attention to the analysis service and complete
    the deployment of the asynchronous services, before deploying the rest of the
    system. For now take a well-earned break and congratulate yourself on your hard
    work so far!
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将把注意力转向分析服务，并完成异步服务的部署，然后再部署系统的其余部分。现在，好好休息一下，并祝贺自己到目前为止的辛勤工作！
- en: Summary
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: AWS provides a growing range of cloud native services that we can leverage.
    In this chapter we used S3, Route53, Lambda, and SQS.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS提供了一系列不断增长的云原生服务，我们可以利用。在本章中，我们使用了S3、Route53、Lambda和SQS。
- en: AWS provides a web-based console that we can use to set up an account and configure
    API access keys
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS提供了一个基于Web的控制台，我们可以使用它来设置账户并配置API访问密钥
- en: The Serverless Framework is used to deploy cloud infrastructure, including an
    S3 bucket, SQS queue, and Route53 DNS records. A `serverless.yml` file allows
    us to define and deploy our infrastructure in a predictable and logical way.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器框架用于部署云基础设施，包括S3存储桶、SQS队列和Route53 DNS记录。一个`serverless.yml`文件允许我们以可预测和逻辑的方式定义和部署我们的基础设施。
- en: An SQS queue connects to a crawler Lambda function.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个SQS队列连接到一个爬虫Lambda函数。
- en: The crawler service is a Lambda function that downloads images and places them
    in an S3 bucket.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爬虫服务是一个Lambda函数，它下载图片并将它们放置在S3存储桶中。
- en: '*Warning* Chapter 3 continues to build on this system, and we provide instructions
    on how to remove the deployed resources at the end of chapter 3\. If you are not
    planning on working on chapter 3 for some time, please ensure that you fully remove
    all cloud resources deployed in this chapter in order to avoid additional charges!'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '*警告* 第3章将继续构建这个系统，并在第3章末尾提供如何删除已部署资源的说明。如果你在一段时间内不打算处理第3章，请确保你完全删除本章中部署的所有云资源，以避免额外费用！'
