- en: 1 Introduction to distributed machine learning systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 分布式机器学习系统简介
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Handling the growing scale in large-scale machine learning applications
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理大规模机器学习应用中的规模增长
- en: Establishing patterns to build scalable and reliable distributed systems
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立可扩展和可靠的分布式系统模式
- en: Using patterns in distributed systems and building reusable patterns
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分布式系统中的模式和构建可重用模式
- en: Machine learning systems are becoming more important nowadays. Recommendation
    systems learn to generate recommendations of potential interest with the right
    context according to user feedback and interactions, anomalous event detection
    systems help monitor assets to prevent downtime due to extreme conditions, and
    fraud detection systems protect financial institutions from security attacks and
    malicious fraud behaviors.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习系统在当今变得越来越重要。推荐系统根据用户反馈和交互学习生成具有正确上下文的潜在感兴趣推荐，异常事件检测系统帮助监控资产以防止因极端条件而导致的停机，欺诈检测系统保护金融机构免受安全攻击和恶意欺诈行为。
- en: There is increasing demand for building large-scale distributed machine learning
    systems. If a data analyst, data scientist, or software engineer has basic knowledge
    of and hands-on experience in building machine learning models in Python and wants
    to take things a step further by learning how to build something more robust,
    scalable, and reliable, this book is the right one to read. Although experience
    in production environments or distributed systems is not a requirement, I expect
    readers in this position to have at least some exposure to machine learning applications
    running in production and should have written Python and Bash scripts for at least
    one year.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 对构建大规模分布式机器学习系统的需求日益增长。如果一个数据分析师、数据科学家或软件工程师在Python中构建机器学习模型方面有基本知识和实践经验，并希望通过学习如何构建更稳健、可扩展和可靠的系统来更进一步，那么这本书就是正确的选择。尽管在生产环境或分布式系统方面的经验不是必需的，但我期望处于这种位置的读者至少对在生产环境中运行的机器学习应用有所了解，并且应该至少编写过一年的Python和Bash脚本。
- en: Being able to handle large-scale problems and take what’s developed on your
    laptop to large distributed clusters is exciting. This book introduces best practices
    in various patterns that help you speed up the development and deployment of machine
    learning models, use automations from different tools, and benefit from hardware
    acceleration. After reading this book, you will be able to choose and apply the
    correct patterns for building and deploying distributed machine learning systems;
    use common tooling such as TensorFlow ([https://www.tensorflow.org](https://www.tensorflow.org/)),
    Kubernetes ([https://kubernetes.io](https://kubernetes.io/)), Kubeflow ([https://www.kubeflow.org](https://www.kubeflow.org/)),
    and Argo Workflows appropriately within a machine learning workflow; and gain
    practical experience in managing and automating machine learning tasks in Kubernetes.
    A comprehensive, hands-on project in chapter 9 provides an opportunity to build
    a real-life distributed machine learning system that uses many of the patterns
    we learn in the second part of the book. In addition, supplemental exercises at
    the end of some sections in the following chapters recap what we’ve learned.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 能够处理大规模问题，并将你在笔记本电脑上开发的内容扩展到大型分布式集群中是非常令人兴奋的。本书介绍了各种模式中的最佳实践，这些模式可以帮助你加快机器学习模型的开发和部署，使用来自不同工具的自动化，并从硬件加速中受益。阅读本书后，你将能够选择并应用正确的模式来构建和部署分布式机器学习系统；在机器学习工作流中适当使用常见的工具，如TensorFlow
    ([https://www.tensorflow.org](https://www.tensorflow.org/))、Kubernetes ([https://kubernetes.io](https://kubernetes.io/))、Kubeflow
    ([https://www.kubeflow.org](https://www.kubeflow.org/))和Argo Workflows；并在Kubernetes中管理自动化机器学习任务获得实践经验。第9章的一个全面、实践的项目提供了一个机会，可以构建一个使用我们在本书第二部分学到的许多模式的真实生活分布式机器学习系统。此外，在以下章节的一些部分末尾的补充练习回顾了我们学到的内容。
- en: 1.1 Large-scale machine learning
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 大规模机器学习
- en: The scale of machine learning applications has become unprecedentedly large.
    Users are demanding faster responses to meet real-life requirements, and machine
    learning pipelines and model architectures are getting more complex. In this section,
    we’ll talk about the growing scale in more detail and what we can do to address
    the challenges.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习应用的范围已经变得前所未有的大。用户要求更快地响应以满足现实生活的需求，机器学习管道和模型架构也在变得更加复杂。在本节中，我们将更详细地讨论规模的增长以及我们可以采取哪些措施来应对挑战。
- en: 1.1.1 The growing scale
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 规模的增长
- en: As the demand for machine learning grows, the complexity involved in building
    machine learning systems is increasing as well. Machine learning researchers and
    data analysts are no longer satisfied with building simple machine learning models
    on their laptops on gigabytes of Microsoft Excel sheets. Due to the growing demand
    and complexity, machine learning systems have to be built with the ability to
    handle the growing scale, including the increasing volume of historical data;
    frequent batches of incoming data; complex machine learning architectures; heavy
    model serving traffic; and complicated end-to-end machine learning pipelines.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习需求的增长，构建机器学习系统的复杂性也在增加。机器学习研究人员和数据分析师不再满足于在笔记本电脑上构建简单的机器学习模型，这些模型基于几GB的Microsoft
    Excel表格。由于需求的增长和复杂性，机器学习系统必须具备处理不断增长规模的能力，包括历史数据的增加量；频繁的 incoming 数据批次；复杂的机器学习架构；大量的模型服务流量；以及复杂的端到端机器学习管道。
- en: Let’s consider two scenarios. First, imagine that you have a small machine learning
    model that has been trained on a small dataset (less than 1 GB). This approach
    might work well for your analysis at hand because you have a laptop with sufficient
    computational resources. But you realize that the dataset grows by 1 GB every
    hour, so the original model is no longer useful and predictive in real life. Suppose
    that you want to build a time-series model that predicts whether a component of
    a train will fail in the next hour to prevent failures and downtime. In this case,
    we have to build a machine learning model that uses the knowledge gained from
    the original data and the most recent data that arrives every hour to generate
    more accurate predictions. Unfortunately, your laptop has a fixed amount of computational
    resources and is no longer sufficient for building a new model that uses the entire
    dataset.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑两个场景。首先，想象一下你有一个小型机器学习模型，它是在一个小型数据集（小于1 GB）上训练的。这种方法可能适合你当前的分析，因为你有一台具有足够计算资源的笔记本电脑。但你意识到数据集每小时增长1
    GB，所以原始模型在现实生活中不再有用和可预测。假设你想构建一个时间序列模型，预测火车组件在下一个小时内是否会失败，以防止故障和停机。在这种情况下，我们必须构建一个机器学习模型，该模型使用从原始数据和每小时到达的最新数据中获得的知识来生成更准确的预测。不幸的是，你的笔记本电脑计算资源固定，不再足以构建一个使用整个数据集的新模型。
- en: Second, suppose that you have successfully trained a model and developed a simple
    web application that uses the trained model to make predictions based on the user’s
    input. The web application may have worked well in the beginning, generating accurate
    predictions, and the user was quite happy with the results. This user’s friends
    heard about the good experience and decided to try it as well, so they sat in
    the same room and opened the website. Ironically, they started seeing longer delays
    when they tried to see the prediction results. The reason for the delays is that
    the single server used to run the web application can’t handle the increasing
    number of user requests as the application gets more popular. This scenario is
    a common challenge that many machine learning applications will encounter as they
    grow from beta products to popular applications. These applications need to be
    built on scalable machine learning system patterns to handle the growing scale
    of throughput.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，假设你已经成功训练了一个模型并开发了一个简单的Web应用程序，该应用程序使用训练好的模型根据用户的输入进行预测。在开始时，这个Web应用程序可能运行良好，生成准确的预测，用户对结果非常满意。这个用户的朋友们听说了这段美好的体验，决定也试试看，于是他们坐在同一个房间里打开了网站。讽刺的是，当他们试图查看预测结果时，开始看到更长的延迟。延迟的原因是，运行Web应用程序的单个服务器无法处理随着应用程序越来越受欢迎而增加的用户请求。这种情况是许多机器学习应用在从测试产品发展到流行应用过程中会遇到的一个常见挑战。这些应用需要建立在可扩展的机器学习系统模式之上，以处理不断增长的吞吐量规模。
- en: 1.1.2 What can we do?
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 我们能做什么？
- en: When the dataset is too large to fit in a single machine, as in the first scenario
    in section 1.1.1, how can we store the large dataset? Perhaps we can store different
    parts of the dataset on different machines and then train the machine learning
    model by sequentially looping through the various parts of the dataset on different
    machines.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据集太大而无法适应单个机器时，就像1.1.1节中的第一个场景一样，我们如何存储这个大数据集？也许我们可以将数据集的不同部分存储在不同的机器上，然后通过在不同机器上按顺序循环遍历数据集的不同部分来训练机器学习模型。
- en: If we have a 30 GB dataset like the one in figure 1.1, we can divide it into
    three partitions of 10 GB data, with each partition sitting on a separate machine
    that has enough disk storage. Then, we can consume the partitions one by one without
    having to train the machine learning model by using the entire dataset at the
    same time.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个如图1.1所示的30 GB数据集，我们可以将其分为三个10 GB数据的分区，每个分区位于具有足够磁盘存储的独立机器上。然后，我们可以逐个消费分区，而无需同时使用整个数据集来训练机器学习模型。
- en: '![01-01](../../OEBPS/Images/01-01.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![01-01](../../OEBPS/Images/01-01.png)'
- en: Figure 1.1 An example of dividing a large dataset into three partitions on three
    separate machines that have sufficient disk storage
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 在三个具有足够磁盘存储的独立机器上将大型数据集分为三个分区的示例
- en: Then, we might ask what will happen if looping through different parts of the
    dataset is quite time-consuming. Assume that the dataset at hand has been divided
    into three partitions. As illustrated in figure 1.2, first, we initialize the
    machine learning model on the first machine, and then we train it, using all the
    data in the first data partition. Next, we transfer the trained model to the second
    machine, which continues training by using the second data partition. If each
    partition is large and time-consuming, we’ll spend a significant amount of time
    waiting.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可能会问，如果遍历数据集的不同部分非常耗时，会发生什么。假设手头的数据集已经被分为三个分区。如图1.2所示，首先，我们在第一台机器上初始化机器学习模型，然后使用第一个数据分区中的所有数据进行训练。接下来，我们将训练好的模型转移到第二台机器上，该机器继续使用第二个数据分区进行训练。如果每个分区都很大且耗时，我们将花费大量时间等待。
- en: '![01-02](../../OEBPS/Images/01-02.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![01-02](../../OEBPS/Images/01-02.png)'
- en: Figure 1.2 An example of training the model sequentially on each data partition
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 在每个数据分区上依次训练模型的示例
- en: In this case, we can think about adding workers. Each worker is responsible
    for consuming each of the data partitions, and all workers train the same model
    in parallel without waiting for others. This approach is definitely good for speeding
    up the model training process. But what if some workers finish consuming the data
    partitions that they are responsible for and want to update the model at the same
    time? Which of the worker’s results (gradients) should we use to update the model
    first? Then, we must consider the conflicts and tradeoffs between performance
    and model quality. In figure 1.2, if the data partition that the first worker
    uses has better quality due to a more rigorous data collection process than the
    one that the second worker uses, using the first worker’s results first would
    produce a more accurate model. On the other hand, if the second worker has a smaller
    partition, it could finish training faster, so we could start using that worker’s
    computational resources to train a new data partition. When more workers are added,
    such as the three workers shown in figure 1.2, the conflicts in completion time
    for data consumption by different workers become even more obvious.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以考虑添加工作节点。每个工作节点负责消费每个数据分区，所有工作节点并行训练相同的模型，而不需要等待他人。这种方法无疑有助于加快模型训练过程。但是，如果一些工作节点完成消费它们负责的数据分区并希望同时更新模型，我们应该首先使用哪个工作节点的结果（梯度）来更新模型？然后，我们必须考虑性能和模型质量之间的冲突和权衡。如图1.2所示，如果第一个工作节点使用的数据分区由于数据收集过程比第二个工作节点使用的数据分区更为严格而质量更好，那么首先使用第一个工作节点的结果将产生更准确的模型。另一方面，如果第二个工作节点有更小的分区，它可能训练得更快，因此我们可以开始使用该工作节点的计算资源来训练新的数据分区。当添加更多工作节点，如图1.2中所示的三个工作节点时，不同工作节点在数据消费完成时间上的冲突变得更加明显。
- en: Similarly, if the application that uses the trained machine learning model to
    make predictions observes much heavier traffic, can we simply add servers, with
    each new server handling a certain percentage of the traffic? Unfortunately, the
    answer is not that simple. This naive solution would need to take other things
    into consideration, such as deciding the best load balancer strategy and processing
    duplicate requests in different servers.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，如果使用训练好的机器学习模型进行预测的应用观察到流量非常重，我们是否可以简单地添加服务器，每个新服务器处理一定比例的流量？遗憾的是，答案并不那么简单。这种简单的解决方案需要考虑其他因素，例如决定最佳的负载均衡策略以及在不同的服务器上处理重复请求。
- en: We will learn more about handling these types of problems in the second part
    of the book. For now, the main takeaway is that we have established patterns and
    best practices to deal with certain situations, and we will use those patterns
    to make the most of our limited computational resources.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的第二部分学习更多关于处理这些类型问题的知识。目前，主要的收获是我们已经建立了模式和最佳实践来处理某些情况，我们将使用这些模式来最大限度地利用我们有限的计算资源。
- en: 1.2 Distributed systems
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 分布式系统
- en: A single machine or laptop can’t satisfy the requirements for training a large
    machine learning model with a large amount of data. We need to write programs
    that can run on multiple machines and be accessed by people all over the world.
    In this section, we’ll talk about what a distributed system is and discuss one
    concrete example pattern that’s often used in distributed systems.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 单台机器或笔记本电脑无法满足训练大量数据的大型机器学习模型的性能要求。我们需要编写可以在多台机器上运行并被世界各地的人访问的程序。在本节中，我们将讨论分布式系统是什么，并讨论一个在分布式系统中经常使用的具体示例模式。
- en: 1.2.1 What is a distributed system?
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 什么是分布式系统？
- en: Computer programs have evolved from being able to run on only one machine to
    working with multiple machines. The increasing demand for computing power and
    the pursuit of higher efficiency, reliability, and scalability have boosted the
    advancement of large-scale data centers that consist of hundreds or thousands
    of computers communicating via the shared network, which have resulted in the
    development of distributed systems. A *distributed system* is one in which components
    are located on different networked computers and can communicate with one another
    to coordinate workloads and work together via message passing.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机程序已经从只能在单台机器上运行发展到与多台机器协同工作。对计算能力的日益增长的需求和对更高效率、可靠性和可扩展性的追求推动了由数百或数千台计算机组成的大型数据中心的发展，这些计算机通过共享网络进行通信，这导致了分布式系统的开发。*分布式系统*是指组件位于不同的联网计算机上，并且可以通过消息传递相互通信以协调工作负载并协同工作。
- en: Figure 1.3 illustrates a small distributed system consisting of two machines
    communicating with each other via message passing. One machine contains two CPUs,
    and the other machine contains three CPUs. Obviously, a machine contains computational
    resources other than the CPUs; we use only CPUs here for illustration purposes.
    In real-world distributed systems, the number of machines can be extremely large--tens
    of thousands, depending on the use case. Machines with more computational resources
    can handle larger workloads and share the results with other machines.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3展示了由两台机器组成的小型分布式系统，这两台机器通过消息传递相互通信。一台机器包含两个CPU，另一台机器包含三个CPU。显然，一台机器除了CPU之外还包含其他计算资源；我们在这里仅使用CPU进行说明。在现实世界的分布式系统中，机器的数量可以非常大——根据用例，可能有数万台。具有更多计算资源的机器可以处理更大的工作负载，并将结果与其他机器共享。
- en: '![01-03](../../OEBPS/Images/01-03.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![01-03](../../OEBPS/Images/01-03.png)'
- en: Figure 1.3 An example of a small distributed system consisting of two machines
    with different amounts of computational resources communicating with each other
    via message passing
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 一个由两台机器组成的小型分布式系统示例，这两台机器具有不同数量的计算资源，通过消息传递相互通信
- en: 1.2.2 The complexity and patterns
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 复杂性和模式
- en: These distributed systems can run on multiple machines and be accessed by users
    all over the world. They are often complex and need to be designed carefully to
    be more reliable and scalable. Bad architectural considerations can lead to problems,
    often on a large scale, and result in unnecessary costs.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些分布式系统可以在多台机器上运行，并且可以被全球各地的用户访问。它们通常很复杂，需要精心设计以确保更高的可靠性和可扩展性。不良的架构考虑可能导致问题，通常规模很大，并导致不必要的成本。
- en: Lots of good patterns and reusable components are available for distributed
    systems. The *work-queue pattern* in a batch processing system, for example, makes
    sure that each piece of work is independent of the others and can be processed
    without any interventions within a certain amount of time. In addition, workers
    can be scaled up and down to ensure that the workload can be handled properly.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统有很多好的模式和可重用的组件。例如，在批处理系统中的*工作队列模式*确保每项工作都是独立的，并且可以在一定时间内无需任何干预进行处理。此外，工作者可以扩展和缩减，以确保工作负载能够得到妥善处理。
- en: Figure 1.4 depicts seven work items, each of which might be an image that needs
    to be modified to grayscale by the system in the processing queue. Each of the
    three existing workers takes two to three work items from the processing queue,
    ensuring that no worker is idle to avoid waste of computational resources and
    maximizing the performance by processing multiple images at the same time. This
    performance is possible because each work item is independent of the others.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 描述了七个工作项，每个工作项可能是一个需要由系统在处理队列中修改为灰度的图像。每个现有的三个工作者从处理队列中取出两个到三个工作项，确保没有工作者空闲，以避免计算资源的浪费，并通过同时处理多个图像来最大化性能。这种性能之所以可能，是因为每个工作项都是独立的。
- en: '![01-04](../../OEBPS/Images/01-04.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![01-04](../../OEBPS/Images/01-04.png)'
- en: Figure 1.4 An example of a batch processing system using the work-queue pattern
    to modify images to grayscale
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 使用工作队列模式修改图像为灰度的批处理系统示例
- en: 1.3 Distributed machine learning systems
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 分布式机器学习系统
- en: Distributed systems are useful not only for general computing tasks but also
    for machine learning applications. Imagine that we could use multiple machines
    with large amounts of computational resources in a distributed system to consume
    parts of the large dataset, store different partitions of a large machine learning
    model, and so on. Distributed systems can greatly speed up machine learning applications
    with scalability and reliability in mind. In this section, we’ll introduce distributed
    machine learning systems, present a few patterns that are often used in those
    systems, and talk about some real-life scenarios.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式系统不仅对通用计算任务有用，对机器学习应用也同样有用。想象一下，我们可以在分布式系统中使用多台具有大量计算资源的机器来消费大型数据集的部分，存储大型机器学习模型的不同分区，等等。考虑到可扩展性和可靠性，分布式系统可以大大加快机器学习应用的速度。在本节中，我们将介绍分布式机器学习系统，展示那些系统中常用的一些模式，并讨论一些实际场景。
- en: 1.3.1 What is a distributed machine learning system?
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 什么是分布式机器学习系统？
- en: A *distributed machine learning system* is a distributed system consisting of
    a pipeline of steps and components that are responsible for different steps in
    machine learning applications, such as data ingestion, model training, and model
    serving. It uses patterns and best practices similar to those of a distributed
    system, as well as patterns designed specifically to benefit machine learning
    applications. Through careful design, a distributed machine learning system is
    more scalable and reliable for handling large-scale problems, such as large datasets,
    large models, heavy model serving traffic, and complicated model selection or
    architecture optimization.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 *分布式机器学习系统* 是一个由负责机器学习应用中不同步骤的步骤和组件组成的分布式系统，例如数据摄取、模型训练和模型服务。它使用与分布式系统类似的模式和最佳实践，以及专门为机器学习应用设计的模式。通过精心设计，分布式机器学习系统在处理大规模问题时更具可扩展性和可靠性，例如大型数据集、大型模型、重模型服务流量以及复杂的模型选择或架构优化。
- en: 1.3.2 Are there similar patterns?
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 是否有类似的模式？
- en: To handle the increasing demand for and scale of machine learning systems that
    will be deployed in real-life applications, we need to design the components in
    a distributed machine learning pipeline carefully. Design is often nontrivial,
    but using good patterns and best practices allows us to speed the development
    and deployment of machine learning models, use automations from different tools,
    and benefit from hardware accelerations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理将在实际应用中部署的机器学习系统的日益增长的需求和规模，我们需要仔细设计分布式机器学习管道中的组件。设计通常是复杂的，但使用良好的模式和最佳实践可以让我们加快机器学习模型的开发和部署，利用不同工具的自动化，并从硬件加速中受益。
- en: There are similar patterns in distributed machine learning systems. As an example,
    multiple workers can be used to train the machine learning model asynchronously,
    with each worker being responsible for consuming certain partitions of the dataset.
    This approach, which is similar to the work-queue pattern used in distributed
    systems, can speed up the model training process significantly. Figure 1.5 illustrates
    how we can apply this pattern to distributed machine learning systems by replacing
    the work items with data partitions. Each worker takes some data partitions from
    the original data stored in a database and then uses them to train a centralized
    machine learning model.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式机器学习系统中也存在类似的模式。例如，可以使用多个工作节点异步训练机器学习模型，每个工作节点负责消费数据集的特定分区。这种方法类似于在分布式系统中使用的任务队列模式，可以显著加快模型训练过程。图1.5说明了我们如何通过用数据分区替换工作项来将此模式应用于分布式机器学习系统。每个工作节点从存储在数据库中的原始数据中获取一些数据分区，然后使用它们来训练一个集中的机器学习模型。
- en: '![01-05](../../OEBPS/Images/01-05.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![01-05](../../OEBPS/Images/01-05.png)'
- en: Figure 1.5 An example of applying the work-queue pattern in distributed machine
    learning systems
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 分布式机器学习系统中应用任务队列模式的示例
- en: Another example pattern commonly used in machine learning systems instead of
    general distributed systems is the *parameter server pattern* for distributed
    model training. As shown in figure 1.6, the parameter servers are responsible
    for storing and updating a particular part of the trained model. Each worker node
    is responsible for taking a particular part of the dataset that will be used to
    update a certain part of the model parameters. This pattern is useful when the
    model is too large to fit in a single server and dedicated parameter servers for
    storing model partitions without allocating unnecessary computational resources.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习系统中，除了通用分布式系统外，常用的另一种示例模式是用于分布式模型训练的**参数服务器模式**。如图1.6所示，参数服务器负责存储和更新训练模型的特定部分。每个工作节点负责获取数据集的特定部分，这些部分将用于更新模型参数的特定部分。当模型太大而无法适应单个服务器时，这种模式非常有用，此时可以专门使用参数服务器来存储模型分区，而不必分配不必要的计算资源。
- en: '![01-06](../../OEBPS/Images/01-06.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![01-06](../../OEBPS/Images/01-06.png)'
- en: Figure 1.6 An example of applying the parameter server pattern in a distributed
    machine learning system
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 分布式机器学习系统中应用参数服务器模式的示例
- en: Part 2 of this book illustrates patterns like these. For now, keep in mind that
    some patterns in distributed machine learning systems also appear in general-purpose
    distributed systems, as well as patterns specially designed to handle machine
    learning workloads at large scale.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 本书第二部分将介绍这些模式。目前，请记住，分布式机器学习系统中的某些模式也出现在通用分布式系统中，以及专门设计来处理大规模机器学习工作负载的模式。
- en: 1.3.3 When should we use a distributed machine learning system?
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.3 我们应该在何时使用分布式机器学习系统？
- en: 'If the dataset is too large to fit on our local laptops, as illustrated in
    figures 1.1 and 1.2, we can use patterns such as data partitioning or introduce
    additional workers to speed up model training. We should start thinking about
    designing a distributed machine learning system when any of the following scenarios
    occurs:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据集太大而无法适应我们的本地笔记本电脑，如图1.1和1.2所示，我们可以使用数据分区或引入额外的工人来加速模型训练。当以下任何一种情况发生时，我们应该开始考虑设计分布式机器学习系统：
- en: The model is large, consisting of millions of parameters that a single machine
    cannot store and that must be partitioned on different machines.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型很大，由数百万个参数组成，单个机器无法存储，必须在不同的机器上进行分区。
- en: The machine learning application needs to handle increasing amounts of heavy
    traffic that a single server can no longer manage.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习应用需要处理越来越多的重流量，而单个服务器已无法管理。
- en: The task at hand involves many parts of the model’s life cycle, such as data
    ingestion, model serving, data/model versioning, and performance monitoring.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前任务涉及模型生命周期的许多部分，例如数据摄入、模型服务、数据/模型版本控制和性能监控。
- en: We want to use many computing resources for acceleration, such as dozens of
    servers that have many GPUs each.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望使用大量计算资源进行加速，例如每台服务器都配备了许多GPU的数十台服务器。
- en: If any of these scenarios occur, it’s usually a sign that a well-designed distributed
    machine learning system will be needed in the near future.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果发生任何这些情况，通常是一个迹象，表明在不久的将来将需要一个设计良好的分布式机器学习系统。
- en: 1.3.4 When should we not use a distributed machine learning system?
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.4 我们在什么情况下不应该使用分布式机器学习系统？
- en: 'Although a distributed machine learning system is helpful in many situations,
    it is usually harder to design and requires experience to operate efficiently.
    Additional overhead and tradeoffs are involved in developing and maintaining such
    a complicated system. If you encounter any of the following cases, stick with
    a simple approach that already works well:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管分布式机器学习系统在许多情况下都有帮助，但它通常更难设计，并且需要经验才能高效地操作。开发和维护这样一个复杂的系统涉及额外的开销和权衡。如果你遇到以下任何情况，请坚持使用已经工作得很好的简单方法：
- en: The dataset is small, such as a CSV file smaller than 10 GBs.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集很小，例如小于10 GB的CSV文件。
- en: The model is simple and doesn’t require heavy computation, such as linear regression.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型简单，不需要复杂的计算，例如线性回归。
- en: Computing resources are limited but sufficient for the tasks at hand.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算资源有限，但对于手头的任务来说是足够的。
- en: 1.4 What we will learn in this book
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 本书我们将学习的内容
- en: 'In this book, we’ll learn to choose and apply the correct patterns for building
    and deploying distributed machine learning systems to gain practical experience
    in managing and automating machine learning tasks. We’ll use several popular frameworks
    and cutting-edge technologies to build components of a distributed machine learning
    workflow, including the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将学习选择和应用正确的模式来构建和部署分布式机器学习系统，以获得管理和自动化机器学习任务的实际经验。我们将使用几个流行的框架和尖端技术来构建分布式机器学习工作流程的组件，包括以下内容：
- en: TensorFlow ([https://www.tensorflow.org](https://www.tensorflow.org/))
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow ([https://www.tensorflow.org](https://www.tensorflow.org/))
- en: Kubernetes ([https://kubernetes.io](https://kubernetes.io/))
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes ([https://kubernetes.io](https://kubernetes.io/))
- en: Kubeflow ([https://www.kubeflow.org](https://www.kubeflow.org/))
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubeflow ([https://www.kubeflow.org](https://www.kubeflow.org/))
- en: Docker ([https://www.docker.com](https://www.docker.com/))
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker ([https://www.docker.com](https://www.docker.com/))
- en: Argo Workflows ([https://argoproj.github.io/workflows/](https://argoproj.github.io/workflows/))
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Argo Workflows ([https://argoproj.github.io/workflows/](https://argoproj.github.io/workflows/))
- en: A comprehensive hands-on project in the last part of the book consists of an
    end-to-end distributed machine learning pipeline system. Figure 1.7 is the architecture
    diagram of the system that we will be building. We will gain hands-on experience
    implementing many of the patterns covered in the following chapters. Handling
    large-scale problems and taking what we’ve developed on our personal laptops to
    large distributed clusters should be exciting.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 本书最后一部分的一个综合实战项目包括一个端到端的分布式机器学习管道系统。图1.7是我们将要构建的系统架构图。我们将通过以下章节中涵盖的许多模式获得实践经验。处理大规模问题和将我们在个人笔记本电脑上开发的内容扩展到大型分布式集群应该是令人兴奋的。
- en: '![01-07](../../OEBPS/Images/01-07.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![01-07](../../OEBPS/Images/01-07.png)'
- en: Figure 1.7 An architecture diagram of the end-to-end machine learning system
    that we will be building in the last part of the book
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 本书最后一部分我们将构建的端到端机器学习系统架构图
- en: We’ll be using TensorFlow with Python to build machine learning and deep learning
    models for various tasks, such as building useful features based on a real-life
    dataset, training predictive models, and making real-time predictions. We’ll also
    use Kubeflow to run distributed machine learning tasks in a Kubernetes cluster.
    Furthermore, we will use Argo Workflows to build a machine learning pipeline that
    consists of many important components of a distributed machine learning system.
    The basics of these technologies are introduced in chapter 2, and we’ll gain hands-on
    experience with them in part 2\. Table 1.1 shows the key technologies that will
    be covered in this book and example uses.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用TensorFlow和Python构建用于各种任务的机器学习和深度学习模型，例如基于真实数据集构建有用的特征、训练预测模型和进行实时预测。我们还将使用Kubeflow在Kubernetes集群中运行分布式机器学习任务。此外，我们将使用Argo
    Workflows构建一个由分布式机器学习系统许多重要组件组成的机器学习管道。这些技术的基础知识在第2章中介绍，我们将在第2部分中获得实践经验。表1.1显示了本书将涵盖的关键技术和示例用途。
- en: Table 1.1 The technologies covered in this book and their uses
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.1 本书涵盖的技术及其用途
- en: '| Technology | Use |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 技术 | 用途 |'
- en: '| TensorFlow | Building machine learning and deep learning models |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| TensorFlow | 构建机器学习和深度学习模型 |'
- en: '| Kubernetes | Managing distributed environments and resources |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| Kubernetes | 管理分布式环境和资源 |'
- en: '| Kubeflow | Submitting and managing distributed training jobs easily on Kubernetes
    clusters |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| Kubeflow | 在 Kubernetes 集群上轻松提交和管理分布式训练作业 |'
- en: '| Argo Workflows | Defining, orchestrating, and managing workflows |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| Argo Workflows | 定义、编排和管理工作流 |'
- en: '| Docker | Building and managing images to be used for starting containerized
    environments |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| Docker | 构建和管理用于启动容器化环境的镜像 |'
- en: Before we dive into details in chapter 2, I recommend that readers have basic
    knowledge of and hands-on experience in building machine learning models in Python.
    Although experience in production environments or distributed systems is not a
    requirement, I expect readers in this position to have at least some exposure
    to machine learning applications running in production and to have written Python
    and Bash scripts for at least one year. In addition, understanding the basics
    of Docker and being able to manage images/containers by using the Docker command-line
    interface is required. Familiarity with basic YAML syntax is helpful but not required;
    the syntax is intuitive and should be easy to pick up along the way. If most of
    these topics are new to you, I suggest that you learn more about them from other
    resources before reading further.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入到第2章的细节之前，我建议读者具备在 Python 中构建机器学习模型的基本知识和实践经验。尽管在生产环境或分布式系统中的经验不是必需的，但我期望处于这种位置的读者至少对在生产环境中运行的机器学习应用有所了解，并且至少已经编写了
    Python 和 Bash 脚本一年以上。此外，了解 Docker 的基础知识并能够使用 Docker 命令行界面管理镜像/容器是必需的。熟悉基本的 YAML
    语法有帮助但不是必需的；语法直观，应该可以在学习过程中轻松掌握。如果这些主题大部分对你来说都是新的，我建议你在继续阅读之前从其他资源中了解更多相关信息。
- en: Summary
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Machine learning systems deployed in real-life applications usually need to
    handle the growing scale of larger datasets and heavier model serving traffic.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实际应用中部署的机器学习系统通常需要处理更大数据集和更重的模型服务流量不断增长的问题。
- en: It’s nontrivial to design large-scale distributed machine learning systems.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计大规模分布式机器学习系统并非易事。
- en: A distributed machine learning system is usually a pipeline of many components,
    such as data ingestion, model training, serving, and monitoring.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式机器学习系统通常是一个由许多组件组成的管道，例如数据摄取、模型训练、服务和监控。
- en: Using good patterns to design the components of a machine learning system can
    speed up the development and deployment of machine learning models, enable the
    use of automations from different tools, and benefit from hardware acceleration.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用良好的模式来设计机器学习系统的组件可以加快机器学习模型的开发和部署，使不同工具的自动化功能得以使用，并从硬件加速中受益。
