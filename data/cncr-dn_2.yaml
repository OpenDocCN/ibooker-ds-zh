- en: Part 3
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分
- en: Modern patterns of concurrent programming applied
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 应用现代并发编程模式
- en: '**This third and final part of the book allows you to put into practice all
    the functional concurrent programming techniques you’ve learned thus far. These
    chapters will become your go-to reference for questions and answers about concurrency.**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**本书的第三部分和最后一部分允许你将迄今为止所学的所有函数式并发编程技术付诸实践。这些章节将成为你关于并发问题的问答的必备参考。**'
- en: Chapter 13 covers recipes to solve both common and complex problems you may
    encounter in concurrent applications using the functional paradigm. Chapter 14
    walks you through the full implementation of a scalable and highly performant
    stock market server application, which includes iOS and WPF versions for the client
    side.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 第13章涵盖了使用函数式范式解决你在并发应用程序中可能遇到的常见和复杂问题的食谱。第14章将带你详细了解一个可扩展且高性能的股票市场服务器应用程序的完整实现，该应用程序包括客户端的iOS和WPF版本。
- en: Functional paradigm principles learned in the book will be applied in the design
    and architecture decisions, as well as to code development, to achieve a highly
    performant and scalable solution. You’ll see in this section the positive side
    effects that come from applying functional principles to reduce bugs and increase
    maintainability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中学到的函数式范式原则将应用于设计和架构决策，以及代码开发中，以实现高性能和可扩展的解决方案。你将在本节中看到，将函数式原则应用于减少错误并提高可维护性所带来的积极影响。
- en: '13'
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Recipes and design patterns for successful concurrent programming
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 成功并发编程的食谱和设计模式
- en: '**This chapter covers**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**本章涵盖**'
- en: Twelve code recipes that answer common problems in parallel programming
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 十二个解决并行编程常见问题的代码食谱
- en: The 12 recipes presented in this chapter have broad applications. You can use
    the core ideas as a reference when you’re facing a similar problem and require
    a quick answer. The material demonstrates how the functional concurrent abstractions
    covered throughout this book make it possible to solve complex problems by developing
    sophisticated and rich functions with relatively few lines of code. I’ve kept
    the implementations of the recipes as simple as possible, so you’ll need to deal
    from time to time with cancellations and exception handling.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中提出的12个食谱具有广泛的应用。当你面临类似问题并需要快速答案时，可以将核心思想作为参考。这些材料展示了本书中涵盖的函数式并发抽象如何通过开发复杂且丰富的函数以及相对较少的代码行数来解决复杂问题。我将食谱的实现尽可能简化，因此你有时需要处理取消和异常处理。
- en: This chapter shows you how to put together everything you’ve learned so far
    to combine concurrent programming models using the functional programming abstraction
    as a glue to write efficient and performant programs. By the end of this chapter,
    you’ll have at your disposal a set of useful and reusable tools for solving common
    concurrent coding problems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将向你展示如何将迄今为止所学的一切结合起来，使用函数式编程抽象作为粘合剂来编写高效且性能良好的程序。到本章结束时，你将拥有一套用于解决常见并发编程问题的有用且可重用的工具。
- en: Each recipe is built in either C# or F#; for the majority of the code implementation,
    you can find both versions in the downloadable code online. Also, keep in mind
    that F# and C# are .NET programming languages with interoperability support to
    interact with each other. You can easily use a C# program in F# and vice versa.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 每个食谱都是用C#或F#编写的；对于大多数代码实现，你可以在在线可下载的代码中找到两种版本。此外，请记住，F#和C#是具有互操作支持以相互交互的.NET编程语言。你可以轻松地在F#中使用C#程序，反之亦然。
- en: 13.1 Recycling objects to reduce memory consumption
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.1 回收对象以减少内存消耗
- en: In this section you’ll implement a reusable asynchronous object pool. This should
    be used in cases where the recycling of objects benefits the reduction of memory
    consumption. Minimizing the number of GC generations allows your program to enjoy
    better performance speed. [Figure 13.1](#figure13.1), repeated from chapter 12,
    shows how to apply concurrent Producer/Consumer patterns, from Listing 12.9, to
    compress and encrypt a large file in parallel.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将实现一个可重用的异步对象池。在回收对象有助于减少内存消耗的情况下应使用此对象池。最小化GC代数数量可以使你的程序享受更好的性能速度。[图13.1](#figure13.1)，重复自第12章，展示了如何将第12章中的并发生产者/消费者模式（从列表12.9）应用于并行压缩和加密大文件。
- en: '![c13-01.png](Images/c13-01.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![c13-01.png](Images/c13-01.png)'
- en: '[Figure 13.1](#figureanchor13.1) The `Transform` blocks process the messages
    in parallel. The result is sent to the next block when the operation completes.
    The Aggregate agent’s purpose is to maintain the integrity of order of the messages,
    similar to the `AsOrdered` PLINQ extension method.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13.1](#figureanchor13.1) `Transform`块并行处理消息。当操作完成时，结果被发送到下一个块。Aggregate代理的目的是维护消息的顺序完整性，类似于`AsOrdered`
    PLINQ扩展方法。'
- en: The function `CompressAndEncrypt`, from listing 12.9, partitions a large file
    in a set of byte-array chunks, which has the negative effect of producing a large
    volume of GC generations due to high memory consumption. Each memory chunk is
    created, processed, and collected by the GC when the memory pressure reaches the
    trigger point for demanding for more resources.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 来自列表12.9的函数`CompressAndEncrypt`将大文件分割成一系列字节数组块，由于高内存消耗，这会产生大量的GC代数。当内存压力达到需要更多资源的触发点时，每个内存块都会被创建、处理和收集。
- en: This high volume operation of creating and destroying byte array causes many
    GC generations, which negatively impact the overall performance of the application.
    In fact, the program allocates a considerable number of memory buffers (byte arrays)
    for its full execution in a multithreaded fashion, meaning that multiple threads
    can simultaneously allocate the same amount of memory. Consider that each buffer
    is 4,096 bytes of memory, and 25 threads are running simultaneously; in this case,
    about 102,400 bytes are being simultaneously allocated in the heap. Additionally,
    when each thread completes its execution, many buffers are out of scope, pressuring
    the GC to start a generation. This is bad for performance, because the application
    is under heavy memory management.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种创建和销毁字节数组的高容量操作会导致许多GC代数，这会负面影响应用程序的整体性能。事实上，程序在多线程方式下为其整个执行分配了相当数量的内存缓冲区（字节数组），这意味着多个线程可以同时分配相同数量的内存。考虑到每个缓冲区是4,096字节的内存，并且有25个线程同时运行；在这种情况下，大约有102,400字节同时在堆中分配。此外，当每个线程完成其执行时，许多缓冲区超出作用域，迫使GC启动一个代数。这对性能不利，因为应用程序正承受着沉重的内存管理压力。
- en: '13.1.1 Solution: *asynchronously recycling a pool of objects*'
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.1 解决方案：*异步回收对象池*
- en: '*To optimize the performance of a concurrent application with intense memory
    consumption, recycle the objects that otherwise are subject to be garbage collected
    by the system. In the parallel compress and encrypt stream example, you want to
    reuse the same byte buffers (byte arrays) generated instead of creating new ones.
    This is possible using `ObjectPool`, a class designed to provide a cached pool
    of objects that recycles the items that aren’t being used. This reuse of objects
    avoids expensive acquisition and release of resources, minimizing the potential
    memory allocation. Specifically, in the highly concurrent example, you need a
    thread-safe and non-blocking (task-based) concurrent object pool ([figure 13.2](#figure13.2)).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*为了优化具有强烈内存消耗的并发应用程序的性能，回收那些否则会被系统垃圾回收的对象。在并行压缩和加密流示例中，你希望重用生成的相同的字节缓冲区（字节数组），而不是创建新的。这可以通过使用`ObjectPool`类来实现，该类旨在提供一个缓存的对象池，用于回收未使用的项目。这种对象的重用避免了昂贵的资源获取和释放，最小化了潜在的内存分配。具体来说，在高度并发的示例中，你需要一个线程安全和非阻塞（基于任务的）并发对象池([图13.2](#figure13.2))。*'
- en: '![c13-02.png](Images/c13-02.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![c13-02.png](Images/c13-02.png)'
- en: '[Figure 13.2](#figureanchor13.2) An object pool can asynchronously handle multiple
    concurrent requests for reusable objects from multiple consumers. The consumer
    then sends the object back to the object pool when it’s done with the work. Internally,
    object pool generates a queue of objects using a given factory delegate. These
    objects are then recycled to reduce memory consumption and the cost of new instantiation.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13.2](#figureanchor13.2) 对象池可以异步处理来自多个消费者的多个并发请求，以重用对象。消费者完成工作后，将对象送回对象池。内部，对象池使用给定的工厂代理生成一个对象队列。然后，这些对象被回收以减少内存消耗和新的实例化成本。'
- en: In [Listing 13.1](#listing13.1) the implementation of `ObjectPoolAsync` is based
    on a TDF that uses the `BufferBlock` as a building block. The `ObjectPoolAsync`
    pre-initializes a set of objects for an application to use and reuse when needed.
    Furthermore, TDF is intrinsically thread safe while providing an asynchronous,
    non-blocking semantic.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在[列表13.1](#listing13.1)中，`ObjectPoolAsync`的实现基于一个使用`BufferBlock`作为构建块的TDF。`ObjectPoolAsync`预先初始化一组对象，以便应用程序在需要时使用和重用。此外，TDF本质上是线程安全的，同时提供异步、非阻塞的语义。
- en: '[Listing 13.1](#listinganchor13.1) Asynchronous object pool implementation
    using TDF'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表13.1](#listinganchor13.1) 使用TDF的异步对象池实现'
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`ObjectPoolAsync` accepts as arguments an initial number of objects to create
    and a factory delegate constructor. `ObjectPoolAsync` exposes two functions to
    orchestrate the object’s recycle:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`ObjectPoolAsync`接受创建对象的初始数量和一个工厂委托构造函数作为参数。`ObjectPoolAsync`公开两个函数来协调对象的回收：'
- en: '`PutAsync`—An item can be `Put` into the pool asynchronously.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PutAsync`—可以将一个项目异步地`Put`入池中。'
- en: '`GetAsync`—An item can be taken from the pool asynchronously.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GetAsync`—可以异步地从池中取出一个项目。'
- en: In the downloadable source code, you can find the full solution of the `CompressAndEncrypt`
    program updated to use `ObjectPoolAsync`. [Figure 13.3](#figure13.3) is a graphical
    comparison of the GC generations for different file sizes between the original
    version of the program and the new one that exploits `ObjectPoolAsync`.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在可下载的源代码中，您可以找到更新为使用`ObjectPoolAsync`的`CompressAndEncrypt`程序的完整解决方案。[图13.3](#figure13.3)是程序原始版本和新版本之间不同文件大小GC代数的图形比较。
- en: '![c13-03.png](Images/c13-03.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![c13-03.png](Images/c13-03.png)'
- en: '[Figure 13.3](#figureanchor13.3) Comparison of chapter 12’s `CompressAndEncrypt`
    program, which processes different large files (1 GB, 2 GB, and 3 GB), implemented
    with and without `AsyncObjectPool`. The implementation using the object pool has
    a low number of GC generations compared to the original one. Minimizing GC generation
    results in better performance.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13.3](#figureanchor13.3) 比较第12章的`CompressAndEncrypt`程序，该程序使用和未使用`AsyncObjectPool`实现了对不同大文件（1
    GB、2 GB和3 GB）的处理。与原始版本相比，使用对象池的实现具有更少的GC代数。最小化GC代数可以带来更好的性能。'
- en: The results displayed in the chart demonstrate how the `CompressAndEncrypt`
    program implemented using `ObjectPoolAsync` dramatically reduces the GC generations,
    speeding up overall application performance. In an eight-core machine, the new
    version of `CompressAndEncrypt` is about 8% faster.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图表中显示的结果展示了使用`ObjectPoolAsync`实现的`CompressAndEncrypt`程序如何显著减少GC代数，从而加快整体应用程序的性能。在八核机器上，`CompressAndEncrypt`的新版本大约快8%。
- en: 13.2 Custom parallel Fork/Join operator
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.2 自定义并行Fork/Join操作符
- en: In this section you implement a reusable extension method to parallelize Fork/Join
    operations. Let’s say you detected a piece of code in your program that would
    benefit from being executed in parallel using a Divide and Conquer pattern to
    speed up performance. You decide to refactor the code to use a concurrent Fork/Join
    pattern ([figure 13.4](#figure13.4)). And the more you check the program, the
    more similar patterns arise.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将实现一个可重用的扩展方法来并行化Fork/Join操作。假设您在程序中检测到一段代码，如果使用分治模式并行执行将有助于提高性能。您决定重构代码以使用并发Fork/Join模式（[图13.4](#figure13.4)）。并且您检查程序越多，出现的类似模式就越多。
- en: '![c13-04.png](Images/c13-04.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![c13-04.png](Images/c13-04.png)'
- en: '[Figure 13.4](#figureanchor13.4) The Fork/Join pattern splits a task into subtasks
    that can be executed independently in parallel. When the operations complete,
    the subtasks are joined again. It isn’t a coincidence that this pattern is often
    used to achieve data parallelism. In fact, there are clearly similarities.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13.4](#figureanchor13.4) Fork/Join模式将任务分割成可以并行独立执行的子任务。当操作完成时，子任务再次合并。这种模式常用于实现数据并行化并不偶然。事实上，存在明显的相似之处。'
- en: 'Unfortunately, in .NET, there’s no built-in support for parallel Fork/Join
    extension methods to be reused on demand. But you can create this and more to
    have a reusable and flexible operator that does the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，在.NET中，没有内置的并行Fork/Join扩展方法支持按需重用。但你可以创建这样的方法以及更多，以拥有一个可重用且灵活的操作符，它执行以下操作：
- en: Splits the data
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分割数据
- en: Applies the Fork/Join pattern in parallel
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行应用Fork/Join模式
- en: Optionally allows you to configure the degree of parallelism
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选地允许您配置并行度
- en: Merges the results using a reducer function
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用归约函数合并结果
- en: The .NET operator `Task.WhenAll` and the F# `Async.Parallel` can compose a set
    of given tasks in parallel; but these operators don’t provide an aggregate (or
    reduce) functionality to join the results. Moreover, they lack configurability
    when you want to control the degree of parallelism. To get your desired operator,
    you need a tailored solution.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: .NET 操作符 `Task.WhenAll` 和 F# 的 `Async.Parallel` 可以并行组合一组给定的任务；但这两个操作符不提供聚合（或归约）功能来连接结果。此外，当想要控制并行度时，它们缺乏可配置性。为了得到你想要的操作符，你需要一个定制的解决方案。
- en: '13.2.1 Solution: composing a pipeline of steps forming the Fork/Join pattern'
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.2.1 解决方案：组成形成 Fork/Join 模式的步骤管道
- en: With TDF, you can compose different building blocks together as a pipeline.
    You can use the pipeline to define the steps of a Fork/Join pattern ([figure 13.5](#figure13.5)),
    where the Fork step runs a set of tasks in parallel, then the following step joins
    the results, and the final step applies a reducer block for the ultimate output.
    For the later step of the workflow that aggregates the results, you need an object
    that maintains the state of the previous steps. In this case, you use the agent-based
    block built in chapter 12 using TDF.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TDF，你可以将不同的构建块组合在一起作为一个管道。你可以使用管道来定义 Fork/Join 模式的步骤（[图 13.5](#figure13.5)），其中
    Fork 步骤并行运行一系列任务，然后接下来的步骤合并结果，最后一步应用归约块以产生最终输出。对于工作流程的后续步骤，该步骤聚合结果，你需要一个对象来维护之前步骤的状态。在这种情况下，你使用第
    12 章中基于 TDF 构建的基于代理的块。
- en: The Fork/Join pattern is implemented as an extension method over a generic `IEnumerable`
    to be accessed conveniently in a fluent style from the code, as shown in [Listing
    13.2](#listing13.2) (the code to note is in bold).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Fork/Join 模式作为对泛型 `IEnumerable` 的扩展方法实现，以便从代码中以流畅的方式方便地访问，如 [列表 13.2](#listing13.2)
    所示（请注意，代码部分为粗体）。
- en: '![c13-05.png](Images/c13-05.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![c13-05.png](Images/c13-05.png)'
- en: '[Figure 13.5](#figureanchor13.5) Fork/Join pattern implemented using TDF, where
    each step of the computation is defined using a different dataflow block'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 13.5](#figureanchor13.5) 使用 TDF 实现的 Fork/Join 模式，其中每个计算步骤都使用不同的数据流块定义'
- en: '[Listing 13.2](#listinganchor13.2) Parallel `ForkJoin` using TDF'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 13.2](#listinganchor13.2) 使用 TDF 的并行 `ForkJoin`'
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `ForkJoin` extension method accepts as an argument the `IEnumerable` source
    to process a mapping function, to transform its items, as well as an aggregate
    (reducer) function to merge all the results coming from the mapping computation.
    The argument `initialState` is the seed required by the aggregate function for
    the initial state value. But if the result type `T2` can be combined (because
    the monoidal laws are satisfied), you could modify the method to use a reducer
    function with zero initial state, as explained in Listing 5.10\.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`ForkJoin` 扩展方法接受一个参数作为要处理的 `IEnumerable` 源，用于映射函数，以转换其项，以及一个聚合（归约）函数，用于合并来自映射计算的所有的结果。参数
    `initialState` 是聚合函数所需的初始状态值。但如果结果类型 `T2` 可以组合（因为满足单调律），你可以修改该方法以使用具有零初始状态的归约函数，如列表
    5.10 所解释的。'
- en: The underlying dataflow blocks are linked to form a pipeline. Interestingly,
    `mapperBlock` is converted into an `Observable` using the `AsObservable` extension
    method, which is then subscribed to send messages to the `reducerAgent` when an
    output is materialized. The values `partitionLevel` and `boundCapacity` are used
    respectively to set the degree of parallelism and the bound capacity.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 基础数据流块被链接起来形成一个管道。有趣的是，`mapperBlock` 使用 `AsObservable` 扩展方法被转换为一个 `Observable`，然后订阅它以在输出具体化时向
    `reducerAgent` 发送消息。值 `partitionLevel` 和 `boundCapacity` 分别用于设置并行度的大小和边界容量。
- en: 'Here is a simple example of how to exploit the `ForkJoin` operator:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个如何利用 `ForkJoin` 操作符的简单示例：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The previous code sums the squares of all number from 1 to 100,000 using the
    Fork/Join pattern.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码使用 Fork/Join 模式计算了从 1 到 100,000 所有数字的平方和。
- en: '13.3 Parallelizing tasks with dependencies: designing code to optimize performance'
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.3 并行化具有依赖关系的任务：设计代码以优化性能
- en: Let’s imagine you need to write a tool that can execute a series of asynchronous
    tasks—each with a different set of dependencies that influence the order of the
    operations. You can address this with sequential and imperative execution; but
    if you want to maximize performance, sequential operations won’t do. Instead,
    you must build the tasks to run in parallel. Many concurrent problems can be considered
    a static collection of atomic operations with dependencies between their inputs
    and outputs. On completion of the operation, the output is used as input to other
    dependent operations. To optimize performance, these tasks need to be scheduled
    based on the dependency, and the algorithm must be optimized to run the dependent
    tasks in serial as necessary and in parallel as much as possible.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们假设你需要编写一个工具，该工具可以执行一系列异步任务——每个任务都有不同的依赖关系，这些依赖关系会影响操作的顺序。你可以使用顺序和命令式执行来解决这个问题；但如果你想最大化性能，顺序操作是不够的。相反，你必须构建可以并行运行的任务。许多并发问题可以被视为具有依赖关系的静态原子操作集合，这些依赖关系存在于它们的输入和输出之间。操作完成后，输出被用作其他依赖操作的输入。为了优化性能，这些任务需要根据依赖关系进行调度，并且算法必须优化以在必要时串行运行依赖任务，尽可能并行运行。
- en: You want a reusable component that runs a series of tasks in parallel, ensuring
    that all the dependencies that could influence the order of the operations are
    respected. How do you create a programming model that exposes the underlying parallelism
    of a collection of operations that are executed efficiently, either in parallel
    or serially depending on the dependencies with other operations?
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个可重用的组件，该组件可以并行运行一系列任务，确保所有可能影响操作顺序的依赖关系都得到尊重。你如何创建一个编程模型，该模型可以暴露执行效率高的一系列操作的底层并行性，这些操作要么并行执行，要么根据与其他操作的依赖关系以串行方式执行？
- en: '13.3.1 Solution: implementing a dependencies graph of tasks'
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.3.1 解决方案：实现任务依赖图
- en: The solution is called a directed acyclic graph (DAG), which aims to form a
    graph by breaking down operations into a series of atomic tasks with defined dependencies.
    The acyclic nature of the graph is important because it removes the possibility
    of deadlocks between tasks, provided the tasks are truly atomic. When specifying
    the graph, it’s important to understand all dependencies between tasks, especially
    hidden dependencies that may result in deadlocks or race conditions. [Figure 13.6](#figure13.6)
    is a typical example of a data structure in the shape of a graph, which can be
    used to represent scheduling constraints between the operations of the graph.
    A graph is an extremely powerful data structure in computer science that gives
    rise to strong algorithms.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案被称为有向无环图（DAG），其目的是通过将操作分解为一系列具有定义依赖关系的原子任务来形成一个图。图的无环性质很重要，因为它消除了任务之间发生死锁的可能性，前提是任务是真正原子的。在指定图时，理解任务之间的所有依赖关系很重要，特别是可能导致死锁或竞争条件的隐藏依赖关系。[图
    13.6](#figure13.6) 是一个典型的以图形形状的数据结构示例，可以用来表示图中操作之间的调度约束。图是计算机科学中一个非常强大的数据结构，它产生了强大的算法。
- en: '![c13-06.png](Images/c13-06.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![c13-06.png](Images/c13-06.png)'
- en: '[Figure 13.6](#figureanchor13.6) A graph is a collection of vertices connected
    by edges. In this representation of a DAG, node 1 has dependencies on nodes 4
    and 5, node 2 depends on node 5, node 3 has dependencies on nodes 5 and 6, and
    so on.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 13.6](#figureanchor13.6) 图是由边连接的顶点集合。在这个有向无环图的表示中，节点 1 依赖于节点 4 和 5，节点 2
    依赖于节点 5，节点 3 依赖于节点 5 和 6，依此类推。'
- en: You can apply the DAG structure as a strategy to run tasks in parallel while
    respecting the order of the dependencies for increasing performance. You can define
    this graph structure using the F# `MailboxProcessor`, which keeps an internal
    state for the tasks registered to be performed in the shape of edge dependencies.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将 DAG 结构作为策略应用于并行运行任务，同时尊重依赖关系的顺序以提高性能。你可以使用 F# 的 `MailboxProcessor` 定义此图结构，它为注册执行的任务保持内部状态，这些任务以边依赖的形式存在。
- en: The following example uses the F# `MailboxProcessor` as a perfect candidate
    to implement a DAG to run in parallel operations with dependencies. First, let’s
    define the discriminated union used to manage the tasks and run their dependencies.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例使用 F# 的 `MailboxProcessor` 作为实现并行操作依赖的有向无环图的完美候选。首先，让我们定义用于管理任务和运行其依赖关系的区分联合。
- en: Listing 13.3 Message type and data structure to coordinate task execution
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.3 协调任务执行的消息类型和数据结构
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `TaskMessage` type represents the message cases sent to the underlying agent
    of the `ParallelTasksDAG`, implemented in [Listing 13.4](#listing13.4). These
    messages are used for task coordination and dependency synchronization. The `TaskInfo`
    type contains and tracks the details of the registered tasks during the execution
    of the DAG, including the dependency edges. The execution context ([http://mng.bz/2F9o](http://mng.bz/2F9o))
    is captured to access information during the delayed execution, such as the current
    user, any state associated with the logical thread of execution, code-access security
    information, and so forth. The start and end for the execution time are published
    when the event fires.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`TaskMessage` 类型表示发送到 `ParallelTasksDAG` 的底层代理的消息案例，该代理在 [列表 13.4](#listing13.4)
    中实现。这些消息用于任务协调和依赖同步。`TaskInfo` 类型包含并跟踪 DAG 执行期间注册的任务的详细信息，包括依赖边。执行上下文 ([http://mng.bz/2F9o](http://mng.bz/2F9o))
    被捕获以在延迟执行期间访问信息，例如当前用户、与执行逻辑线程相关联的任何状态、代码访问安全信息等。当事件触发时，会发布执行时间的开始和结束。'
- en: '[Listing 13.4](#listinganchor13.4) DAG F# agent to parallelize the execution
    of operations'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 13.4](#listinganchor13.4) DAG F# 代理以并行化操作执行'
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The purpose of the function `AddTask` is to register a task including arbitrary
    dependency edges. This function accepts a unique ID, a function task that must
    be executed, and a set of edges that represent the IDs of other registered tasks,
    all of which must be completed before the current task can be executed. If the
    array is empty, it means there are no dependencies. The `MailboxProcessor` named
    `dagAgent` keeps the registered tasks in a current state `tasks`, which is a map
    (`tasks : Dictionary<int, TaskInfo>`) between the ID of each task and its details.
    The agent also keeps the state of the edge dependencies for each task ID (`edges
    : Dictionary<int, int list>`). The `Dictionary` collections are mutable because
    the state changes during the execution of the `ParallelTasksDAG`, and because
    they inherited thread safety from being inside an agent. When the agent receives
    the notification to start the execution, part of the process involves verifying
    that all the edge dependencies are registered and that there are no cycles within
    the graph. This verification step is available in the full implementation of the
    `ParallelTasksDAG` in the downloadable source code. The following code is an example
    in C# that references and consumes the F# library to run the `ParallelTasksDAG`.
    The tasks registered mirror the dependencies from [figure 13.6](#figure13.6):'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '函数 `AddTask` 的目的是注册一个任务，包括任意依赖边。此函数接受一个唯一 ID、必须执行的功能任务以及表示其他已注册任务 ID 的边集，所有这些都必须在当前任务执行之前完成。如果数组为空，则表示没有依赖。名为
    `dagAgent` 的 `MailboxProcessor` 保持注册任务在当前状态 `tasks` 中，这是一个 ID 与其详细信息之间的映射（`tasks
    : Dictionary<int, TaskInfo>`）。代理还保持每个任务 ID 的边依赖状态（`edges : Dictionary<int, int
    list>`）。`Dictionary` 集合是可变的，因为 `ParallelTasksDAG` 的执行过程中状态会发生变化，并且因为它们继承自代理内部的线程安全性。当代理收到启动执行的通知时，该过程的一部分涉及验证所有边依赖都已注册并且图中没有循环。此验证步骤可在可下载源代码中
    `ParallelTasksDAG` 的完整实现中找到。以下代码是 C# 示例，它引用并消耗 F# 库以运行 `ParallelTasksDAG`。注册的任务反映了
    [图 13.6](#figure13.6) 中的依赖关系：'
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The helper function’s `action` purpose is to print when a task starts, indicating
    the current thread `Id` as a reference to prove the multithreaded functionality.
    The event `OnTaskCompleted` is registered to notify when each task completes printing
    in the console the task ID and the current thread `Id`. Here’s the output when
    the method `Execute­Tasks` is called:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 辅助函数的 `action` 目的是在任务开始时打印，指示当前线程 `Id` 作为多线程功能的参考。将事件 `OnTaskCompleted` 注册为在控制台打印每个任务完成打印时通知，包括任务
    ID 和当前线程 `Id`。以下是调用 `Execute­Tasks` 方法时的输出：
- en: '[PRE6]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, the tasks run in parallel with a different thread of execution
    (different thread ID), and the dependency order is preserved.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，任务在不同的执行线程（不同的线程 ID）中并行运行，并且依赖顺序得到保留。
- en: '13.4 Gate for coordinating concurrent I/O operations sharing resources: one
    write, multiple reads'
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.4 用于协调共享资源（一个写入，多个读取）的并发 I/O 操作的网关
- en: Imagine you’re implementing a server application where there are many concurrent
    client requests coming in. These concurrent requests came into the server application
    because of the need to access shared data. Occasionally, a request that needs
    to modify the shared data would come in, requiring the data to be synchronized.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，您正在实现一个服务器应用程序，其中有很多并发客户端请求进入。这些并发请求进入服务器应用程序是因为需要访问共享数据。偶尔，需要修改共享数据的请求会进入，需要同步数据。
- en: When a new client request arrives, the thread pool dispatches a thread to handle
    the request and to start the processing. Imagine if at this point the request
    wants to update data in the server in a thread-safe manner. You must face the
    problem of how to coordinate the read and write operations so that they access
    the resources concurrently without blocking. In this case, blocking means to coordinate
    the access of a shared resource. In doing so, the write operation locks the other
    operations to take ownership of the resource until its operation is complete.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当新的客户端请求到达时，线程池调度一个线程来处理请求并开始处理。想象一下，如果此时请求想要以线程安全的方式更新服务器中的数据。您必须面对如何协调读写操作的问题，以便它们可以并发访问资源而不阻塞。在这种情况下，阻塞意味着协调对共享资源的访问。这样做时，写操作锁定其他操作，以获取资源的所有权，直到其操作完成。
- en: A possible solution is to use primitive lock, such as `ReaderWriterLockSlim
    (`[http://mng.bz/FY0J](http://mng.bz/FY0J)), which also manages access to a resource,
    allowing multiple threads.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能的解决方案是使用原始锁，例如`ReaderWriterLockSlim `[http://mng.bz/FY0J](http://mng.bz/FY0J)]，它也管理对资源的访问，允许多个线程。
- en: But in this book you learned that you should avoid using primitive locks when
    possible. Locks prevent the code from running in parallel, and in many cases,
    overwhelm the thread pool by forcing it to create a new thread for each request.
    The other threads are blocked from acquiring access to the same resources. Another
    downside is that locks could be held for an extremely long time, causing the threads
    that have been awakened from the thread pool to process the read requests, to
    be immediately put to sleep waiting for the writer thread to complete its task.
    Additionally, this design doesn’t scale.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 但在这本书中，您了解到您应该尽可能避免使用原始锁。锁阻止代码并行运行，并且在许多情况下，通过为每个请求强制创建新线程而压倒线程池。其他线程被阻止获取对相同资源的访问。另一个缺点是锁可能被持有很长时间，导致从线程池唤醒的线程处理读取请求后，立即被置于睡眠状态，等待写线程完成任务。此外，这种设计不具可扩展性。
- en: Finally, the read and write operations should be handled differently to allow
    multiple reads to happen simultaneously, because these operations don’t change
    the data. This should be balanced by ensuring write operations are only processed
    one at a time, while blocking the reads from retrieving stale data.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，读写操作应分别处理，以便同时发生多个读取操作，因为这些操作不会改变数据。这应该通过确保写操作一次只处理一个，同时阻止读取操作检索过时数据来平衡。
- en: You need a custom coordinator that can synchronize the read and write operations
    asynchronously without blocking. This coordinator should execute the writes one
    at a time in sequential order without blocking any threads and leave the reads
    to run in parallel.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要一个自定义协调器，该协调器可以异步同步读写操作，而不阻塞。这个协调器应该一次执行一个写操作，按顺序进行，而不阻塞任何线程，并让读取操作并行运行。
- en: '13.4.1 Solution: applying multiple read/write operations to shared thread-safe
    resources'
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.4.1 解决方案：对共享线程安全资源应用多次读写操作
- en: '`ReaderWriterAgent` offers reader-writer asynchronous semantics without blocking
    any threads and maintains a FIFO order of operations. It reduces resource consumption
    and improves the performance of the application. In fact, `ReaderWriterAgent`
    can perform an extraordinary amount of work using only a few threads. Regardless
    of the number of operations being made against the `ReaderWriterAgent`, only a
    few resources are required.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`ReaderWriterAgent`提供了无阻塞的读写异步语义，并保持操作的FIFO顺序。它减少了资源消耗，并提高了应用程序的性能。实际上，`ReaderWriterAgent`可以使用很少的线程完成大量的工作。无论对`ReaderWriterAgent`进行的操作数量有多少，只需要很少的资源。'
- en: In the examples that follow, you want to send multiple read and write operations
    to a shared database. These operations are processed giving higher priority to
    reader threads than writers, as shown in [figure 13.7](#figure13.7). The same
    concepts can be applied to any other resources, such as a filesystem.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的示例中，您希望向共享数据库发送多个读取和写入操作。这些操作在处理时给予读取线程比写入线程更高的优先级，如图 13.7 所示。同样的概念可以应用于任何其他资源，例如文件系统。
- en: '![c13-07.png](Images/c13-07.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![c13-07.png](Images/c13-07.png)'
- en: '[Figure 13.7](#figureanchor13.7) `ReaderWriterAgent` acts as a gate agent to
    asynchronously synchronize the access to share resources. In the top image, only
    one write operation at a time is executed, while the read operations are queued
    up to wait asynchronously for the write operation to complete before proceeding.
    In the bottom image, multiple read operations are processed asynchronously in
    parallel according to the degree of parallelism configured.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 13.7](#figureanchor13.7) `ReaderWriterAgent` 作为门控代理异步同步对共享资源的访问。在上图中，一次只执行一个写入操作，而读取操作则排队异步等待写入操作完成后再进行。在下图中，根据配置的并行度，并行处理多个读取操作。'
- en: '[Listing 13.5](#listing13.5) is the implementation of `ReaderWriterAgent` using
    the F# `MailboxProcessor`. The reason for choosing the F# `MailboxProcessor` is
    for simplicity in defining state machines, which are convenient to implement a
    reader-writer asynchronous coordinator. First, you need to define the message
    types to represent the operations by which the `ReaderWriterAgent` coordinates
    and synchronizes the read and write operations.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 13.5](#listing13.5) 是使用 F# `MailboxProcessor` 实现 `ReaderWriterAgent` 的代码。选择
    F# `MailboxProcessor` 的原因是定义状态机简单，这便于实现读取-写入异步协调器。首先，您需要定义消息类型来表示 `ReaderWriterAgent`
    协调和同步读取和写入操作的操作。'
- en: '[Listing 13.5](#listinganchor13.5) Message types used by the `ReaderWriterAgent`
    coordinator'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 13.5](#listinganchor13.5) `ReaderWriterAgent` 协调器使用的消息类型'
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `ReaderWriterMsg` message type denotes the command to either read or write
    to the database or to notify that the operation is completed. `ReaderWriterGateState`
    is a DU used to queue up the read/write operations to the `ReaderWriterAgent`.
    Ultimately, the `ReadWriteMessages` DU identifies the cases for the read/write
    operations queued in the internal `ReaderWriterAgent`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`ReaderWriterMsg` 消息类型表示对数据库进行读取或写入的命令，或者通知操作已完成。`ReaderWriterGateState` 是一个
    DU，用于将读取/写入操作排队到 `ReaderWriterAgent`。最终，`ReadWriteMessages` DU 识别内部 `ReaderWriterAgent`
    中排队的读取/写入操作的情况。'
- en: This listing shows the implementation of the `ReaderWriterAgent` type.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 此列表显示了 `ReaderWriterAgent` 类型的实现。
- en: Listing 13.6 `ReaderWriterAgent` coordinates asynchronous operations
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.6 `ReaderWriterAgent` 协调异步操作
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The implementation of the underlying F# `MailboxProcessor`, in the `ReaderWriter­Agent`
    type, is a multi-state machine that coordinates exclusive writes and reads access
    to shared resources. The `ReaderWriterAgent` creates sub-agents that access the
    resources based on the `ReadWriteMsg` message type received. When the agent coordinator
    receives a `Read` command, its current state is checked using pattern matching
    to apply exclusive access logic:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `ReaderWriterAgent` 类型中，底层 F# `MailboxProcessor` 的实现是一个多状态机，它协调对共享资源的独占写入和读取访问。`ReaderWriterAgent`
    根据接收到的 `ReadWriteMsg` 消息类型创建子代理来访问资源。当代理协调器收到 `Read` 命令时，使用模式匹配检查其当前状态以应用独占访问逻辑：
- en: If the state is `Idle`, the `Read` command is sent to the agent children to
    be processed. If there are no active writes, then the state of the main agent
    is changed to `SendRead.`
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果状态是 `Idle`，则将 `Read` 命令发送到代理子代进行处理。如果没有活跃的写入操作，则主代理的状态变为 `SendRead`。
- en: If the state is `SendRead`, the `Read` operation is sent to the agent’s children
    to be performed only if there are no active writes.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果状态是 `SendRead`，则将 `Read` 操作发送到代理的子代执行，前提是没有活跃的写入操作。
- en: In all other cases, the `Read` operation is placed in the local `Read` queue
    for later processing.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有其他情况下，`Read` 操作被放置在本地 `Read` 队列中，稍后进行处理。
- en: 'In the case of a `Write` command sent to the agent coordinator, the message
    is pattern matched and processed according to its current state:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当向代理协调器发送 `Write` 命令时，消息会被模式匹配并根据其当前状态进行处理：
- en: If the state is `Idle`, the `Write` command is sent to the sub-agent inboxes
    to be processed. The state of the main agent is then changed to `SendWrite.`
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果状态是 `Idle`，则将 `Write` 命令发送到子代理的收件箱以进行处理。然后，主代理的状态变为 `SendWrite`。
- en: In all other cases, the `Write` operation is placed in the local `Write` queue
    for later processing.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有其他情况下，`Write` 操作被放置在本地 `Write` 队列中，稍后进行处理。
- en: '[Figure 13.8](#figure13.8) shows the `ReaderWriterAgent` multi-state machine.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13.8](#figure13.8) 展示了 `ReaderWriterAgent` 多状态机。'
- en: '![c13-08.png](Images/c13-08.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![c13-08.png](Images/c13-08.png)'
- en: '[Figure 13.8](#figureanchor13.8) The `ReaderWriterAgent` works as a state machine,
    where each state aims to asynchronously synchronize the access to share resources
    (in this case, a database).'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[图13.8](#figureanchor13.8) `ReaderWriterAgent` 作为一个状态机工作，其中每个状态旨在异步同步对共享资源（在这种情况下，是数据库）的访问。'
- en: 'The following code snippet is a simple example that uses `ReaderWriterAgent`.
    For simplicity, instead of concurrently accessing a database, you’re accessing
    a local mutable dictionary in a thread-safe and non-blocking manner:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段是使用 `ReaderWriterAgent` 的简单示例。为了简单起见，你并不是并发访问数据库，而是在线程安全和非阻塞的方式下访问本地可变字典：
- en: '[PRE9]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The code example creates the `agentSql` object, whose purpose it is to emulate
    a database accessing the local resource `myDB`. The instance agent of the `ReaderWriterAgent`
    type coordinates the parallel operations reads and writes, which accesses concurrently
    and in a thread-safe manner the `myDB` dictionary without blocking. In a real-world
    scenario, the mutable collection `myDB` represents a database, a file, or any
    sort of shared resource.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 代码示例创建了 `agentSql` 对象，其目的是模拟访问本地资源 `myDB` 的数据库。`ReaderWriterAgent` 类的实例代理协调并行操作读取和写入，以并发和线程安全的方式访问
    `myDB` 字典，而不阻塞。在现实世界场景中，可变集合 `myDB` 代表数据库、文件或任何类型的共享资源。
- en: 13.5 Thread-safe random number generator
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.5 线程安全随机数生成器
- en: Often, when dealing with multithreaded code, you need to generate random numbers
    for an operation in the program. For example, suppose you’re writing a web server
    application that needs to randomly send back an audio clip when a user sends a
    request. For performance reasons, the set of audio clips is loaded in the memory
    of the server, which is concurrently receiving a large number of requests. For
    each request, an audio clip must be randomly selected and sent back to the user
    to be played.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 经常在处理多线程代码时，你需要为程序中的某个操作生成随机数。例如，假设你正在编写一个需要当用户发送请求时随机发送音频片段的Web服务器应用程序。出于性能考虑，音频片段集被加载到服务器的内存中，该服务器正在同时接收大量请求。对于每个请求，必须随机选择一个音频片段并发送给用户播放。
- en: In most cases, the `System.Random` class is a fast-enough solution for producing
    random number values. But an effective application of a `Random` instance that
    is accessed in parallel becomes a challenging problem to solve in a high-performance
    style. When an instance of the `Random` class is used by multiple threads, its
    internal state can be compromised, and it will potentially always return zero.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，`System.Random` 类是生成随机数值的足够快的解决方案。但是，一个有效的 `Random` 实例在并行访问中的应用成为一个在高性能风格中解决的有挑战性的问题。当
    `Random` 类的实例被多个线程使用时，其内部状态可能会受损，并且它可能会始终返回零。
- en: '13.5.1 Solution: using the ThreadLocal object'
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.5.1 解决方案：使用 ThreadLocal 对象
- en: '`ThreadLocal``<T>` ensures that each thread receives its own instance of a
    `Random` class, guaranteeing completely thread-safe access even in a multithreaded
    program. The following listing shows the implementation of the thread-safe random
    number generator using the `ThreadLocal<T>` class, which provides a strongly typed
    and locally scoped type to create object instances that are kept separate for
    each thread.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`ThreadLocal<T>` 确保每个线程都接收其自己的 `Random` 类实例，即使在多线程程序中也能保证完全线程安全的访问。以下列表展示了使用
    `ThreadLocal<T>` 类实现线程安全随机数生成器的实现，该类提供了一个强类型和局部作用域的类型，用于创建每个线程保持独立的对象实例。'
- en: Listing 13.7 Thread-safe random number generator
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.7 线程安全随机数生成器
- en: '[PRE10]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`ThreadSafeRandom` represents a thread-safe pseudo random number generator.
    This class is a subclass of `Random` and overrides the methods `Next`, `NextDouble`,
    and ``NextBytes. The `MakeRandomSeed` method provides a unique value for each
    instance of the underlying `Random` class, which does not depend on the system
    clock.``'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '`ThreadSafeRandom` 表示一个线程安全的伪随机数生成器。这个类是 `Random` 类的子类，并重写了 `Next`、`NextDouble`
    和 `NextBytes` 方法。`MakeRandomSeed` 方法为底层 `Random` 类的每个实例提供一个唯一的值，这个值不依赖于系统时钟。'
- en: '[PRE11]*  *[PRE12]*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE11]*  *[PRE12]*'
