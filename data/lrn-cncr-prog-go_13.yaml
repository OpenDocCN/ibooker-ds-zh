- en: 10 Concurrency patterns
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 并发模式
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Decomposing programs by task
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过任务分解程序
- en: Decomposing programs by data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过数据分解程序
- en: Recognizing common concurrency patterns
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别常见并发模式
- en: When we have a job to do and many helping hands, we need to decide how to divide
    the work so that it’s completed efficiently. A significant task in developing
    a concurrent solution is identifying mostly independent computations—tasks that
    do not affect each other if they are executed at the same time. This process of
    breaking down our programming into separate concurrent tasks is known as *decomposition**.*
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有工作要做，并且有许多帮手时，我们需要决定如何划分工作，以便高效地完成。开发并发解决方案的一个重大任务是识别主要独立的计算——如果它们同时执行，不会相互影响的任务。将我们的编程分解为单独的并发任务的过程被称为*分解*。
- en: In this chapter, we shall see techniques and ideas for performing this decomposition.
    Later, we’ll discuss common implementation patterns used in various concurrent
    scenarios.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看到执行这种分解的技术和想法。稍后，我们将讨论在各种并发场景中使用的常见实现模式。
- en: 10.1 Decomposing programs
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 分解程序
- en: How can we convert a program or an algorithm so that it can run more efficiently
    using concurrent programming? *Decomposition* is the process of subdividing a
    program into many tasks and recognizing which of these tasks can be executed concurrently.
    Let’s pick a real-life example to see how decomposition works.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将程序或算法转换为可以使用并发编程运行得更高效的版本？*分解*是将程序细分为许多任务并识别其中哪些任务可以并发执行的过程。让我们通过一个现实生活中的例子来看看分解是如何工作的。
- en: 'Imagine we are in a car, driving along with a group of friends. Suddenly, we
    hear weird noises coming from the front of the car. We stop to check and find
    that we have a flat tire. Not wanting to be late, we decide to replace the wheel
    with the spare instead of waiting for a tow truck. Here are the steps we need
    to perform:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 想象我们正坐在一辆车里，和一群朋友一起开车。突然，我们听到车前传来奇怪的噪音。我们停车检查，发现我们有一个轮胎没气了。不想迟到，我们决定用备用轮胎更换轮胎，而不是等待拖车。以下是我们需要执行的步骤：
- en: Apply the handbrake.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用手刹。
- en: Unload the spare wheel.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卸下备用轮胎。
- en: Loosen the wheel nuts.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 松开轮胎螺母。
- en: Jack the car off the ground.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将车顶起。
- en: Remove the flat tire.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 移除漏气的轮胎。
- en: Place the spare tire.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 放置备用轮胎。
- en: Tighten the nuts.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拧紧螺母。
- en: Lower the car.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 降低车辆。
- en: Stow the bad tire.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存放坏轮胎。
- en: Since we are not alone, we can assign some steps to other people so that we
    can complete the job more quickly. For example, we can have someone unload the
    spare tire while someone else is loosening the wheel nuts. To decide which steps
    can be done in parallel with others, we can perform a dependency analysis on the
    job by drawing a task dependency graph as shown in figure 10.1.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不是孤身一人，我们可以将一些步骤分配给其他人，这样我们就可以更快地完成工作。例如，我们可以让一个人卸下备用轮胎，同时另一个人松开轮胎螺母。为了决定哪些步骤可以与其他步骤并行执行，我们可以通过绘制如图10.1所示的任务依赖图来对工作进行依赖分析。
- en: '![](../../OEBPS/Images/CH10_F01_Cutajar.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH10_F01_Cutajar.png)'
- en: Figure 10.1 Task dependency graph for changing a flat tire
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 更换漏气轮胎的任务依赖图
- en: By looking at the task dependency graph, we can make informed decisions about
    how best to allocate the tasks so we complete the job more efficiently. In this
    example, we could assign one person to unload the spare tire from the trunk while
    someone else is loosening the wheel nuts. We could also have another person stowing
    the bad tire after we remove it while another is placing the spare tire.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看任务依赖图，我们可以做出明智的决定，关于如何最佳地分配任务，以便我们更有效地完成工作。在这个例子中，我们可以指派一个人从后备箱卸下备用轮胎，同时另一个人松开轮胎螺母。我们还可以在移除坏轮胎后让另一个人存放它，同时另一个人放置备用轮胎。
- en: 'Building a task dependency graph is a good start. However, how do we come up
    with the list of steps that are needed? What if we can come up with a different
    list of steps that could be performed more efficiently when executed in parallel?
    To help us break down our programming task and think about the various concurrent
    tasks, we can consider our programs from two different sides: task and data decomposition.
    We’ll use these two decomposition techniques together and try to apply common
    concurrency patterns to our problem.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 构建任务依赖图是一个好的开始。然而，我们如何得出所需的步骤列表？如果我们能想出一个不同的步骤列表，这些步骤在并行执行时可能更有效，会怎样？为了帮助我们分解编程任务并考虑各种并发任务，我们可以从两个不同的角度考虑我们的程序：任务和数据分解。我们将结合使用这两种分解技术，并尝试将常见的并发模式应用于我们的问题。
- en: 10.1.1 Task decomposition
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 任务分解
- en: '*Task decomposition* occurs when we think about the various actions in our
    program that can be performed in parallel. In task decomposition, we ask the question,
    “What are the different parallel actions we can perform to accomplish the job
    more quickly?” As an analogy, think about two pilots dividing up the work of landing
    an airplane and performing various tasks in parallel (see figure 10.2). In our
    analogy, the pilots have access to the same input data through the aircraft’s
    instruments, but each is performing different tasks to get the aircraft on the
    ground safely and efficiently.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*任务分解*发生在我们考虑程序中可以并行执行的各种动作时。在任务分解中，我们提出问题，“我们可以执行哪些不同的并行动作来更快地完成任务？”作为一个类比，想想两个飞行员分配降落飞机和并行执行各种任务的工作（见图10.2）。在我们的类比中，飞行员可以通过飞机的仪表访问相同的数据，但每个飞行员都在执行不同的任务，以确保飞机安全有效地降落。'
- en: '![](../../OEBPS/Images/CH10_F02_Cutajar.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F02_Cutajar.png)'
- en: Figure 10.2 Pilots performing separate tasks while landing a plane
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 飞行员在降落飞机时执行不同的任务
- en: In the previous chapter, we saw various ways we could distribute different tasks
    to different executions, such as when we built a program to find the longest words
    in a group of web documents. In task decomposition, we need to break down the
    problem into several tasks, such as
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看到了我们可以将不同的任务分配给不同的执行方式，例如当我们编写一个程序来查找一组网络文档中最长的单词时。在任务分解中，我们需要将问题分解成几个任务，例如
- en: Downloading the web pages
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载网页
- en: Extracting the words
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取单词
- en: Finding the longest words
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找最长单词
- en: After obtaining this breakdown of tasks, we can start by outlining the dependencies
    of each. In our program to find the longest words, each task has a dependency
    on the previous one. For example, we cannot extract the words before we download
    the web pages.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得任务分解后，我们可以先概述每个任务的依赖关系。在我们的查找最长单词的程序中，每个任务都依赖于前一个任务。例如，在下载网页之前，我们不能提取单词。
- en: 10.1.2 Data decomposition
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.2 数据分解
- en: We can also break down our program by thinking about how data flows through
    it. We can, for example, divide the input data and feed it to multiple parallel
    executions (see figure 10.3). This is known as *data decomposition*, where we
    ask the question, “How can we organize the data in our program so that we can
    execute more work in parallel?”
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以通过考虑数据在程序中的流动来分解我们的程序。例如，我们可以将输入数据分割并分配给多个并行执行（见图10.3）。这被称为*数据分解*，其中我们提出问题，“我们如何组织程序中的数据，以便我们可以并行执行更多的工作？”
- en: '![](../../OEBPS/Images/CH10_F03_Cutajar.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F03_Cutajar.png)'
- en: Figure 10.3 Data can be divided between multiple executions.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 数据可以在多个执行之间分割。
- en: Definition Data decomposition can be done at various points in our process.
    *Input data decomposition* occurs when we divide the program’s input data and
    process it through multiple concurrent executions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 数据分解可以在我们过程的各个点进行。*输入数据分解*发生在我们将程序输入数据分割并通过多个并发执行处理时。
- en: In input data decomposition, we divide the program input and feed it to our
    various executions. For example, in chapter 3, we wrote a concurrent program that
    downloaded various web documents and counted the letter frequencies. We opted
    for an input data decomposition design where each input URL was given to a separate
    goroutine. The goroutine downloaded the document from the input URL and counted
    the letters on a shared data structure.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在输入数据分解中，我们将程序输入数据分割并分配给我们的各种执行。例如，在第3章中，我们编写了一个并发程序，下载了各种网络文档并计算了字母频率。我们选择了输入数据分解设计，其中每个输入URL都分配给一个单独的goroutine。该goroutine从输入URL下载文档，并在共享数据结构上计算字母。
- en: Definition In *output data decomposition*, we use the program’s output data
    to distribute the work amongst our executions.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 在*输出数据分解*中，我们使用程序的输出数据来在执行之间分配工作。
- en: In contrast, our matrix multiplication in chapter 6 was based on output data
    decomposition. In that example, we had separate goroutines, each responsible for
    working out the results for one output matrix row (see figure 10.4). For a 3 ×
    3 matrix, we had goroutine 0 work out the result for row 0, goroutine 1 work out
    the result for row 1, and so on, for the entire matrix.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，我们在第6章中的矩阵乘法是基于输出数据分解的。在那个例子中，我们有单独的goroutine，每个goroutine负责计算一个输出矩阵行的结果（见图10.4）。对于一个3×3的矩阵，goroutine
    0计算第0行的结果，goroutine 1计算第1行的结果，依此类推，直到整个矩阵。
- en: '![](../../OEBPS/Images/CH10_F04_Cutajar.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F04_Cutajar.png)'
- en: Figure 10.4 Output data decomposition using one output row for each execution
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 使用每执行一行输出数据的输出数据分解
- en: Note Task and data decomposition are principles that should be applied together
    when designing a concurrent program. Most concurrent applications apply a mixture
    of task and data decomposition to achieve an efficient solution.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：任务和数据分解是设计并发程序时应一起应用的原则。大多数并发应用程序都采用任务和数据分解的混合方法来实现高效的解决方案。
- en: 10.1.3 Thinking about granularity
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.3 考虑粒度
- en: How big should our subtasks or data chunks be when we distribute parts of a
    problem to various concurrent executions? This is what we call *task granularity*.
    At one end of the granularity spectrum, we have *fine-grained* tasks, in which
    the problem is broken down into a large number of small tasks. At the other end,
    when a problem is split into a few large tasks, we say we have *coarse-grained*
    tasks.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将问题的一部分分配给各种并发执行时，我们的子任务或数据块应该有多大？这就是我们所说的*任务粒度*。在粒度谱的一端，我们有*细粒度*任务，其中问题被分解成大量的小任务。在另一端，当问题被分解成几个大型任务时，我们说我们有*粗粒度*任务。
- en: To understand task granularity, we can think of a team of developers working
    together to deliver an online web shop. We can break down the project delivery
    into smaller tasks and distribute them amongst the developers. If we make our
    tasks too coarse, the tasks are few and large. With so few tasks, we might not
    have enough tasks for everyone. Even if we do have tasks for every developer,
    if they are too coarse, we might have some developers busy working on their large
    tasks, with others idling after finishing their smaller tasks quickly. This happens
    because the amount of work in each task will vary.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解任务粒度，我们可以想象一个开发者团队共同努力交付一个在线网店。我们可以将项目交付分解成更小的任务，并分配给开发者。如果我们使任务过于粗略，任务就很少且很大。如此少的任务，我们可能没有足够的任务分配给每个人。即使我们有每个开发者的任务，如果它们过于粗略，我们可能会有些开发者忙于处理他们的大型任务，而其他人则在快速完成他们的较小任务后闲置。这是因为每个任务中的工作量会有所不同。
- en: If, on the other hand, we break down our project into tasks that are too fine-grained,
    we will be able to distribute the work to more developers (if they’re available).
    In addition, it’s less likely that we’ll have an imbalance where some developers
    will be idle without work while others are busy working on a large task. However,
    in breaking down the tasks too finely, we create a situation where developers
    waste a lot of time in meetings talking about who’s doing what and when. A lot
    of effort will be spent coordinating and synchronizing the various tasks, and
    the overall efficiency will drop.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果另一方面，我们将项目分解成过于细粒度的任务，我们就能将工作分配给更多的开发者（如果他们可用）。此外，我们不太可能遇到不平衡的情况，即一些开发者空闲没有工作，而其他人正忙于处理大型任务。然而，在将任务分解得太细的情况下，我们创造了一个开发者浪费大量时间在会议上讨论谁做什么以及何时做的局面。大量的努力将花费在协调和同步各种任务上，整体效率将下降。
- en: Somewhere between these two extremes lies an optimal point that will give us
    the maximum speedup—a task granularity that will enable us to deliver the project
    in the shortest time. The location of this sweet spot (see figure 10.5) will depend
    on many factors, such as how many developers we have and how many meetings they
    will have to attend (time spent on communication). The biggest factor will be
    the nature of our project, which will dictate how much we can parallelize the
    tasks since parts of the project will have dependencies on other tasks.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个极端之间，存在一个最佳点，将给我们带来最大的加速——一个能够使我们以最短时间交付项目的任务粒度。这个甜蜜点的位置（见图10.5）将取决于许多因素，例如我们有多少开发者以及他们需要参加多少次会议（在沟通上花费的时间）。最大的因素将是我们的项目性质，这将决定我们可以并行化多少任务，因为项目的某些部分将依赖于其他任务。
- en: '![](../../OEBPS/Images/CH10_F05_Cutajar.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F05_Cutajar.png)'
- en: Figure 10.5 Task granularity when we build an online shop
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 构建在线商店时的任务粒度
- en: The same principles apply to choosing the right type of task granularity for
    our algorithms and programs. Task granularity has big effects on the parallel
    execution performance of our software. Determining the best granularity depends
    on many factors but is dictated mainly by the problem you’re trying to solve.
    Splitting a problem into many small tasks (fine grained) means that when our program
    is executing, it will have more parallelism (if extra processors are present)
    and a bigger speedup. However, increased synchronization and communication due
    to our tasks being too fine grained will constrain scalability. As we increase
    the parallelism, we will have a negligible or even a negative effect on speedup.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的任务粒度类型的原则同样适用于我们的算法和程序。任务粒度对我们的软件并行执行性能有重大影响。确定最佳粒度取决于许多因素，但主要取决于你试图解决的问题。将问题分解成许多小任务（细粒度）意味着当我们的程序执行时，它将具有更多的并行性（如果存在额外的处理器）和更大的加速效果。然而，由于我们的任务过于细粒度而导致的增加的同步和通信将限制可扩展性。随着我们增加并行性，我们可能会对加速效果产生可忽略或甚至负面的影响。
- en: If we choose coarse granularity, we’ll reduce the need for a lot of communication
    and synchronization between executions. However, having a few large tasks may
    result in a smaller speedup, and can lead to load imbalances between our executions.
    Just as in our online shop example, we need to find the right balance that works
    for our scenario. This can be done by modeling, experimentation, and testing.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择粗粒度，我们将减少执行之间的许多通信和同步需求。然而，拥有少量的大型任务可能会导致较小的加速效果，并可能导致我们的执行之间出现负载不平衡。正如我们在在线商店的例子中一样，我们需要找到适合我们场景的正确平衡。这可以通过建模、实验和测试来实现。
- en: TIP Concurrent solutions that require very little communication and synchronization
    (due to the nature of the problem being solved) generally allow us to have finer-grained
    solutions and achieve bigger speedups.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：需要非常少的通信和同步（由于解决问题的性质）的并发解决方案通常允许我们拥有更细粒度的解决方案并实现更大的加速效果。
- en: 10.2 Concurrency implementation patterns
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 并发实现模式
- en: Once we have decomposed our problem using a mixture of task and data decomposition,
    we can apply common concurrent patterns for our implementation. Each of these
    patterns is suitable for specific scenarios, although we can sometimes combine
    more than one pattern in a single solution.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们使用任务和数据分解的组合将问题分解，我们就可以为我们的实现应用常见的并发模式。这些模式中的每一个都适用于特定的场景，尽管我们有时可以在单个解决方案中结合多个模式。
- en: 10.2.1 Loop-level parallelism
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 循环级并行性
- en: When we have a collection of data that we need to perform a task on, we can
    use concurrency to perform multiple tasks on different parts of the collection
    at the same time. A serial program might have a loop to perform the task on each
    item of the collection, one after the other. The loop-level parallelism pattern
    transforms each iteration task into a concurrent task so it can be performed in
    parallel.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要对一组数据进行任务操作时，我们可以使用并发来同时在不同部分上执行多个任务。一个串行程序可能有一个循环来依次对集合中的每个项目执行任务。循环级并行模式将每个迭代任务转换为一个并发任务，以便可以并行执行。
- en: Suppose we have to come up with a program to compute the hash code for a list
    of files in a specific directory. In sequential programming, we would come up
    with a file hashing function (shown in the following listing). Then we’d have
    our program collect a list of files from the directory and iterate over them.
    On each iteration, we would call our hash function and print the results.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要编写一个程序来计算特定目录中文件列表的哈希码。在顺序编程中，我们会编写一个文件哈希函数（如下所示）。然后我们的程序会从目录中收集文件列表并遍历它们。在每次迭代中，我们会调用我们的哈希函数并打印结果。
- en: Listing 10.1 SHA256 file hashing function (error handling omitted for brevity)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.1 SHA256 文件哈希函数（为简洁起见省略了错误处理）
- en: '[PRE0]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Opens file
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 打开文件
- en: ❷ Calculates the hash code using the crypto sha256 library
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用crypto sha256库计算哈希码
- en: ❸ Returns the hash result
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 返回哈希结果
- en: Instead of processing each file in the directory one after the other sequentially,
    we could use loop-level parallelism and feed each file to a separate goroutine.
    Listing 10.2 reads all the files from a specified directory and then iterates
    over every file in a loop. For each iteration, it starts a new goroutine to compute
    the hash code for the file in that iteration. This listing uses a waitgroup to
    pause the `main()` goroutine until all the tasks are complete.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以不按顺序逐个处理目录中的每个文件，而是使用循环级别的并行性，并将每个文件馈送到一个单独的goroutine。列表10.2从指定的目录读取所有文件，然后在一个循环中遍历每个文件。对于每个迭代，它启动一个新的goroutine来计算该迭代中文件的哈希码。这个列表使用waitgroup来暂停`main()`
    goroutine，直到所有任务完成。
- en: Listing 10.2 Using loop-level parallelism to compute file hash codes
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.2 使用循环级别并行性计算文件哈希码
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Gets a list of files from the specified directory
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从指定的目录获取文件列表
- en: ❷ Starts a goroutine to compute the hash code for the file in the iteration
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 启动一个goroutine来计算迭代中文件的哈希码
- en: ❸ Computes and outputs the hash code for the file using the previously developed
    function
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用先前开发的函数计算并输出文件的哈希码
- en: ❹ Waits for all the tasks, which are computing the hashes, to be complete
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 等待所有任务完成，这些任务正在计算哈希码
- en: 'Running the previous listing on a specific directory results in a list of hash
    codes for the files in the directory:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在特定目录上运行前面的列表会产生目录中文件的哈希码列表：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In this example, we can easily use the loop-level parallelism pattern because
    there is no dependence between the tasks. The result of computing the hash code
    for one file does not affect the hash code computation for the next file. If we
    had enough processors, we could execute each iteration on a separate processor.
    But what if the computation of an iteration depends on a step being computed in
    a previous iteration?
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们可以轻松地使用循环级别的并行模式，因为任务之间没有依赖关系。计算一个文件的哈希码的结果不会影响下一个文件的哈希码计算。如果我们有足够的处理器，我们可以在每个迭代上执行一个单独的处理器。但如果我们迭代中的计算依赖于前一个迭代中计算的一个步骤呢？
- en: Definition *Loop-carried dependence* is when a step in one iteration depends
    on another step in a different iteration in the same loop.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 定义*循环携带依赖*是指同一循环中一个迭代中的一个步骤依赖于另一个迭代中的不同步骤。
- en: Let’s extend our program to compute a single hash code for an entire directory
    to illustrate an example of loop-carried dependence. Computing a hash code for
    the contents of the entire directory will tell us if any file is added, removed,
    or modified. To keep things simple, we’re only going to consider the files in
    one directory and assume that there are no subdirectories. To achieve this, we
    can iterate over every file and compute its hash code. In the same iteration,
    we can combine each hash result into a single hash value. At the end, we’ll have
    a single hash value representing the entire directory.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们扩展我们的程序来计算整个目录的单个哈希码，以说明循环携带依赖的例子。计算整个目录内容的哈希码将告诉我们是否有任何文件被添加、删除或修改。为了简化问题，我们只考虑一个目录中的文件，并假设没有子目录。为了实现这一点，我们可以遍历每个文件并计算其哈希码。在相同的迭代中，我们可以将每个哈希结果组合成一个单一的哈希值。最后，我们将有一个代表整个目录的单个哈希值。
- en: In listing 10.3, we do this with a sequential `main()` function. The sequential
    program shows that each iteration has a dependency on the previous iteration.
    Step `i` in the loop requires step `i-1` to be complete. The order in which we
    add the hash codes to our `sha256` function matters. If we change this order,
    we’ll produce different results.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表10.3中，我们使用一个顺序的`main()`函数来做这件事。顺序程序显示每个迭代都依赖于前一个迭代。循环中的步骤`i`需要步骤`i-1`完成。我们将哈希码添加到我们的`sha256`函数中的顺序很重要。如果我们改变这个顺序，我们将产生不同的结果。
- en: Listing 10.3 Computing the hash code of an entire directory (imports omitted)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.3 计算整个目录的哈希码（省略了导入）
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Gets a list of files from the specified directory
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从指定的目录获取文件列表
- en: ❷ Creates a new, empty hash container for the directory
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为目录创建一个新的、空的哈希容器
- en: ❸ Computes the hash code for each file in the directory
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算目录中每个文件的哈希码
- en: ❹ Concatenates the computed hash code to the directory one
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将计算出的哈希码连接到目录中
- en: ❺ Outputs the final hash code
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 输出最终的哈希码
- en: In the preceding listing, we have a loop-carried dependence; we must add the
    previous iteration hash code to the global directory hash before we add the current
    one. This creates a problem for our concurrent program. We cannot just use the
    same trick as we did before because now we have to wait for the previous iteration
    to finish before starting the next one. Instead, we can take advantage of the
    fact that parts of the instructions inside each iteration are independent and
    execute those concurrently. We can then use synchronization techniques to compute
    the carried dependence steps in the correct order.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的列表中，我们有一个循环依赖；在我们添加当前迭代之前，我们必须将前一个迭代的哈希码添加到全局目录哈希中。这给我们的并发程序带来了问题。我们不能像之前那样使用同样的技巧，因为现在我们必须在开始下一个迭代之前等待前一个迭代完成。相反，我们可以利用每个迭代内部指令的部分是独立的事实，并并发执行这些指令。然后我们可以使用同步技术来按正确的顺序计算携带依赖步骤。
- en: In our directory hashing application, we can compute the file hash code in parallel
    because it is independent. In each iteration, we need to wait for the previous
    iteration to finish and only then add the file hash code to the global directory
    hash. Figure 10.6 shows how this can be done. The lengthy part of each iteration—reading
    the file and computing the file hash code—is completely independent of any other
    iteration in the same loop. This means that we can execute this part in a goroutine
    without waiting.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的目录哈希应用中，由于它是独立的，我们可以并行计算文件哈希码。在每次迭代中，我们需要等待前一个迭代完成，然后才能将文件哈希码添加到全局目录哈希中。图10.6展示了如何实现这一点。每次迭代的冗长部分——读取文件和计算文件哈希码——与同一循环中的任何其他迭代完全独立。这意味着我们可以在一个goroutine中执行这部分，而不需要等待。
- en: '![](../../OEBPS/Images/CH10_F06_Cutajar.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH10_F06_Cutajar.png)'
- en: Figure 10.6 The file hash computation in each iteration can be done in parallel.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 每个迭代中的文件哈希计算可以并行进行。
- en: Once the goroutine finishes computing the file hash, it must wait for the previous
    iteration to finish. In our implementation, we use channels to implement this
    wait. Each goroutine waits to receive a signal from the previous iteration. Once
    it has computed the partial directory hash code, it then signals that it is complete
    by sending a channel message to the next iteration. This is shown in the following
    listing.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦goroutine完成文件哈希的计算，它必须等待前一个迭代完成。在我们的实现中，我们使用通道来实现这个等待。每个goroutine等待从前一个迭代接收信号。一旦它计算了部分目录哈希码，它就通过向下一个迭代发送通道消息来发送完成信号。这在上面的列表中有所展示。
- en: Listing 10.4 Loop-carried dependency in directory hashing (imports omitted)
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.4 目录哈希中的循环依赖（省略导入）
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Creates the next channel used by the goroutine to signal that it’s ready
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建goroutine用于发送就绪信号的下一个通道
- en: ❷ Computes the hash code on the file
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在文件上计算哈希码
- en: ❸ If the goroutine is not in the first iteration, waits until the previous iteration
    sends a signal
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 如果goroutine不在第一个迭代中，则等待直到前一个迭代发送信号
- en: ❹ Computes the directory partial hash
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 计算目录部分哈希
- en: ❺ Signals to the next iteration that it’s done
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 向下一个迭代发送完成信号
- en: ❻ Assigns the next channel to be previous; the next goroutine will wait on a
    signal from the current iteration
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 将下一个通道分配为前一个；下一个goroutine将等待当前迭代的信号
- en: ❼ Waits for the last iteration to be complete before outputting the result
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 在输出结果之前等待最后一个迭代完成
- en: Note Go’s `os.ReadDir()` function returns entries in the directory order. This
    is a key requirement for our listing to work properly. If the order was undefined,
    the hash result might be different each time we ran the program without the directory
    changing.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 注意Go的`os.ReadDir()`函数按目录顺序返回条目。这是我们列表正确工作的关键要求。如果顺序未定义，每次运行程序（目录未更改）时，哈希结果可能不同。
- en: 'The `main()` goroutine waits for the final iteration to be complete by expecting
    a ready message on the `next` channel. It then prints out the result of the directory
    hash code. In the previous listing, the ready message is just a `0` sent on the
    channel. Here is the output from listing 10.4:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`main()` goroutine通过在`next`通道上等待就绪消息来等待最终迭代完成。然后它打印出目录哈希码的结果。在上面的列表中，就绪消息只是发送到通道上的一个`0`。以下是列表10.4的输出：'
- en: '[PRE5]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 10.2.2 The fork/join pattern
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 分支/合并模式
- en: The fork/join pattern is useful in situations where we need to create a number
    of executions to perform tasks in parallel, and then we collect and merge the
    results from these executions. In this pattern, the program spawns one execution
    per task and then waits until all of these tasks are complete before proceeding.
    Let’s use the fork/join pattern in a program to search for source files that have
    deeply nested code blocks.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: fork/join模式在需要创建多个执行以并行执行任务，然后收集和合并这些执行结果的情况下很有用。在这个模式中，程序为每个任务启动一个执行，然后等待所有这些任务完成后再继续。让我们在一个程序中使用fork/join模式来搜索具有深层嵌套代码块的源文件。
- en: 'Deeply nested code is hard to read. The following code has a nested depth level
    of 3 because it opens three nested blocks of code before closing them:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 深层嵌套的代码难以阅读。以下代码的嵌套深度为3，因为它在关闭之前打开了三个嵌套的代码块：
- en: '[PRE6]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We want to write a program that recursively scans through a directory and finds
    the source file that has the deepest nested block. Listing 10.5 shows a function
    that, when given a filename, reads the file and returns the nested code depth
    for that source file. It does this by increasing a counter every time it finds
    an open curly bracket and reducing it when it finds a closed one. The function
    keeps track of the highest value found and returns it with the filename.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望编写一个程序，递归地扫描目录并找到具有最深嵌套块的源文件。列表10.5显示了一个函数，当给定一个文件名时，它会读取该文件并返回该源文件的嵌套代码深度。它是通过每次找到开括号时增加计数器，找到闭括号时减少计数器来实现的。该函数跟踪找到的最高值，并将其与文件名一起返回。
- en: Listing 10.5 Finding the deepest nested code block (imports and error handling
    omitted)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.5 查找最深嵌套的代码块（省略了导入和错误处理）
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Reads the full file into a memory buffer
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将整个文件读入内存缓冲区
- en: ❷ Iterates over every single character in the file
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 遍历文件中的每一个字符
- en: ❸ When the character is an opening curly bracket, increments level by 1
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 当字符是一个开括号时，将层级加1
- en: ❹ Records the maximum value of level variable
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 记录层级变量的最大值
- en: ❺ When the curly brackets are closed, decrements level by 1
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 当花括号关闭时，将层级减1
- en: ❻ Returns the result with the filename
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 返回包含文件名的结果
- en: We now need logic to run this function on all the source files found recursively
    in a directory. In a sequential program, we would simply call this function on
    all the files, one after the other, and keep track of the code depth with the
    maximum value. Figure 10.7 shows how we can employ the fork/join pattern to solve
    this problem concurrently. In the fork part, the `main()` goroutine spawns a number
    of goroutines that execute the `deepestNestedBlock()` function, and it then outputs
    the result on a common channel.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要逻辑来递归地在目录中找到的所有源文件上运行这个函数。在一个顺序程序中，我们会简单地依次调用这个函数处理所有文件，并跟踪代码深度的最大值。图10.7展示了我们如何使用fork/join模式来并发地解决这个问题。在fork部分，`main()`
    goroutine生成了一个执行`deepestNestedBlock()`函数的goroutine集合，然后它将结果输出到一个公共通道上。
- en: '![](../../OEBPS/Images/CH10_F07_Cutajar.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F07_Cutajar.png)'
- en: Figure 10.7 Using the fork/join pattern to scan source files
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 使用fork/join模式扫描源文件
- en: The join part of the pattern is when we consume the common output channel and
    wait for all the goroutines to be complete. In this example, we implement this
    part with a separate join goroutine that collects the results and keeps track
    of the deepest nested block. When it’s complete, this goroutine sends the result
    to the `main()` goroutine to output on the console.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 模式的join部分是我们消费公共输出通道并等待所有goroutine完成的时候。在这个例子中，我们通过一个单独的join goroutine来实现这一部分，它收集结果并跟踪最深嵌套块。当它完成时，这个goroutine将结果发送到`main()`
    goroutine以在控制台上输出。
- en: In our implementation, the `main()` goroutine waits on a waitgroup until all
    the forked goroutines are complete. When the waitgroup is done (meaning the forked
    goroutines are finished), it closes the common output channel. When the join goroutine
    notices that the common channel has been closed, it sends the result, containing
    the filename with the deepest nested block, on another channel to `main()`. The
    `main()` goroutine simply waits for this result and prints it on the console.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的实现中，`main()` goroutine等待一个waitgroup直到所有forked goroutines完成。当waitgroup完成（意味着forked
    goroutines已经完成），它关闭公共输出通道。当join goroutine注意到公共通道已被关闭时，它将包含最深嵌套块文件名的结果发送到另一个通道给`main()`。`main()`
    goroutine简单地等待这个结果并在控制台上打印它。
- en: Listing 10.6 implements the fork section of this pattern. It verifies that the
    given path is not a directory, adds one to the waitgroup, and starts a goroutine
    executing the `deepestNestedBlock()` function on the filename. In this listing,
    we don’t handle directories, as we call this function from `filepath.Walk()` later
    in our `main()` function. The return value of `deepestNestedBlock()` is sent on
    the common result channel. Once the function completes, it calls `Done()` on the
    waitgroup.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.6实现了此模式中的fork部分。它验证给定的路径不是目录，将1添加到waitgroup，并启动一个goroutine在文件名上执行`deepestNestedBlock()`函数。在此列表中，我们不处理目录，因为我们稍后在`main()`函数中从`filepath.Walk()`调用此函数。`deepestNestedBlock()`的返回值发送到公共结果通道。一旦函数完成，它就在waitgroup上调用`Done()`。
- en: Listing 10.6 Forking in the fork/join pattern
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.6 实现了fork/join模式中的fork部分
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Verifies that the path is a file and that it’s a Go source file by checking
    its extension
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 通过检查扩展名验证路径是一个文件，并且它是一个Go源文件
- en: ❷ Adds 1 to the waitgroup
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将1添加到waitgroup
- en: ❸ Spawns a new goroutine
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 启动一个新的goroutine
- en: ❹ Calls the function and writes the return value on the common results channel
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 调用函数并将返回值写入公共结果通道
- en: ❺ Marks the work done on the waitgroup
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 标记waitgroup上的工作完成
- en: For the joining part of the fork/join pattern, we need a goroutine that collects
    the results from the common output channel, shown in listing 10.7\. The `joinResults()`
    goroutine consumes from this common channel and records the maximum value of the
    deepest nested block from the received results. Once the common channel closes,
    it writes the result to the main channel, `finalResult`.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对于fork/join模式中的join部分，我们需要一个goroutine来收集来自公共输出通道的结果，如列表10.7所示。`joinResults()`
    goroutine从该公共通道消费并记录接收到的结果中最深嵌套块的最大值。一旦公共通道关闭，它将结果写入主通道，`finalResult`。
- en: Listing 10.7 Joining results onto a final result channel
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.7 将结果合并到最终结果通道
- en: '[PRE9]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Creates a channel that will contain the final result
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个将包含最终结果的通道
- en: ❷ Receives results from the channel until it’s closed
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 接收通道中的结果，直到它关闭
- en: ❸ Records the value of the deepest nested block
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 记录最深嵌套块的值
- en: ❹ After the channel is closed, writes result on the the output channel
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在通道关闭后，将结果写入输出通道
- en: In listing 10.8, our `main()` function wires everything together. We start by
    creating the common channel and the waitgroup. Then we walk recursively through
    all the files in the directory specified in the arguments, and we fork a goroutine
    for each source file encountered. In the end, we join everything by starting the
    goroutine to collect the results, and we wait on the waitgroup for the forked
    goroutines to be complete, closing the common channel and then finally reading
    the result from the `finalResult` channel.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表10.8中，我们的`main()`函数将所有东西连接起来。我们首先创建公共通道和waitgroup。然后我们递归地遍历参数中指定的目录中的所有文件，并为遇到的每个源文件创建一个goroutine。最后，我们通过启动收集结果的goroutine来连接一切，我们等待forked
    goroutines完成，关闭公共通道，然后最终从`finalResult`通道读取结果。
- en: Listing 10.8 `main()` function forking and then outputting the result
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.8 `main()`函数创建goroutine并输出结果
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Reads root directory from arguments
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从参数中读取根目录
- en: ❷ Creates common channel used by all forked goroutines
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建所有forked goroutines使用的公共通道
- en: ❸ Walks the root directory, and for every file, calls the fork function, creating
    goroutines
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 遍历根目录，并对每个文件调用fork函数，创建goroutines
- en: ❹ Calls the join function and gets the channel that will contain the final result
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 调用join函数并获取包含最终结果的通道
- en: ❺ Waits for all the forked goroutines to complete their work
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 等待所有forked goroutines完成其工作
- en: ❻ Closes the common channel, signaling the join goroutine that the work is complete
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 关闭公共通道，向join goroutine发出工作完成的信号
- en: ❼ Receives the final result and outputs it on the console
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 接收最终结果并在控制台输出
- en: Note Unlike the previous directory hashing scenario, this example does not rely
    on the order of the partial results to compute the complete result. Not having
    this requirement allows us to easily adopt the fork/join pattern, where we can
    aggregate the results in the join part.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：与之前的目录哈希场景不同，此示例不依赖于部分结果的顺序来计算完整结果。没有这个要求使我们能够轻松采用fork/join模式，其中我们可以在join部分聚合结果。
- en: 'When we put all the listings together, we can use it to scan our top source
    directory to find out which file has the deepest code block. Here’s the output:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将所有列表放在一起时，我们可以用它来扫描指定的顶级源目录，以找出哪个文件具有最深的代码块。以下是输出：
- en: '[PRE11]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 10.2.3 Using worker pools
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.3 使用工作池
- en: In some cases, we don’t know how much work we are going to get. It can be difficult
    to decompose our algorithms and make them work concurrently if the workload will
    vary depending on the demand. For example, we might have an HTTP server that handles
    a varying number of requests per second depending on how many users are accessing
    a website.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，我们不知道我们将得到多少工作量。如果工作量将根据需求而变化，那么分解我们的算法并使它们并发工作可能会很困难。例如，我们可能有一个HTTP服务器，它每秒处理的请求数量会根据访问网站的用户的数量而变化。
- en: In real life, the solution is to have a number of workers and a queue of work.
    Imagine a bank branch with several tellers serving a single queue of customers.
    In concurrent programming, the worker pool pattern copies this real-life queue
    and workers model in programming.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实生活中，解决方案是拥有一定数量的工作者和一个工作队列。想象一下，一个银行分行有几位出纳员为单个客户队列提供服务。在并发编程中，工作池模式复制了这种现实生活中的队列和工作者模型。
- en: Different names for the same pattern
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 同一模式的多种名称
- en: The worker pool pattern and slight variations of it are known under many different
    names, such as the thread pool pattern, replicated workers, master/worker, or
    worker-crew model.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 工作池模式及其轻微的变化以许多不同的名称为人所知，例如线程池模式、复制工作者、主/工作模式或工作者-团队模型。
- en: In the worker pool pattern, we have a fixed number of goroutines created and
    ready to accept work. In this pattern, the goroutines are either idle, waiting
    for a task, or they’re busy executing one. The work gets passed to the worker
    pool through a common work queue. When all the workers are busy, the work queue
    increases in size. If the work queue fills to its full capacity, we can stop accepting
    more work. In some worker pool implementations, the worker pool can also be increased
    in size by increasing the number of goroutines, up to a limit, to handle the extra
    load.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作池模式中，我们创建并准备好接受工作的goroutine数量是固定的。在这个模式中，goroutine要么是空闲的，等待任务，要么正忙于执行一个任务。工作通过公共工作队列传递给工作池。当所有工作者都忙碌时，工作队列的大小会增加。如果工作队列填满其全部容量，我们可以停止接受更多的工作。在某些工作池实现中，通过增加goroutine的数量，工作池的大小也可以增加到一定限制，以处理额外的负载。
- en: To see this concurrency pattern in action, let’s implement a very simple HTTP
    web server that serves static files as web resources. The worker pool pattern
    in our HTTP server can be seen in figure 10.8\. In our design, several goroutines
    take part in the worker pool, waiting for work to arrive in the work queue. We
    implement the work queue with a Go channel. When all the worker goroutines are
    reading from the same channel, this has the effect of load-balancing the items
    on the channel to all the workers.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要看到这种并发模式的实际应用，让我们实现一个非常简单的HTTP网络服务器，它将静态文件作为网络资源提供服务。我们HTTP服务器中的工作池模式可以在图10.8中看到。在我们的设计中，几个goroutine参与工作池，等待工作队列中的工作到来。我们使用Go通道实现工作队列。当所有工作goroutine都从同一个通道中读取时，这会对通道上的项目进行负载均衡，使所有工作都分配给所有工作者。
- en: '![](../../OEBPS/Images/CH10_F08_Cutajar.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH10_F08_Cutajar.png)'
- en: Figure 10.8 Using a worker pool in an HTTP server
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8 在HTTP服务器中使用工作池
- en: In our HTTP web server, we have our `main()` goroutine accepting socket connections
    from clients. Once a connection is open, the `main()` goroutine passes it to any
    idle worker by putting the connection on the channel. The idle worker handles
    the HTTP requests and replies with the appropriate response. Once the response
    is sent, the worker goroutine goes back to wait for the next connection by waiting
    on the channel.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的HTTP网络服务器中，我们的`main()` goroutine从客户端接受套接字连接。一旦连接打开，`main()` goroutine通过将连接放入通道将它们传递给任何空闲的工作者。空闲工作者处理HTTP请求，并以适当的响应回复。一旦响应发送，工作者goroutine就会回到通道上等待下一个连接。
- en: Listing 10.9 shows the minimal HTTP protocol handling. In the listing, we read
    the request from the connection (using regex), load the requested file from the
    resources directory, and return the contents of the file as a response with the
    appropriate headers. If the file does not exist or the request is invalid, the
    function responds with a suitable HTTP error. This is the logic that every goroutine
    in the worker pool will execute upon receiving a connection from the `main()`
    goroutine on the channel.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.9显示了最简单的HTTP协议处理。在列表中，我们从连接中读取请求（使用正则表达式），从资源目录中加载请求的文件，并以适当的头信息将文件内容作为响应返回。如果文件不存在或请求无效，函数会以适当的HTTP错误响应。这是工作池中的每个goroutine在从`main()`
    goroutine在通道中接收到连接时将执行的逻辑。
- en: Listing 10.9 A simple HTTP response handler
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.9 简单的HTTP响应处理器
- en: '[PRE12]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Creates buffer to store HTTP request
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建缓冲区以存储HTTP请求
- en: ❷ Reads from the connection into the buffer
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从连接读取到缓冲区
- en: ❸ If the request is a valid one, reads the request file from the resources directory
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 如果请求是有效的，则从资源目录读取请求文件
- en: ❹ If the file exists, responds to the client with the HTTP header and file contents
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 如果文件存在，则向客户端响应HTTP头和文件内容
- en: ❺ If the file does not exist, responds with an error
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 如果文件不存在，则响应错误
- en: ❻ If the HTTP request is not valid, responds with an error
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 如果HTTP请求无效，则响应错误
- en: ❼ Closes the connection after handling the request
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 在处理请求后关闭连接
- en: The following listing initializes all the goroutines in the worker pool. The
    function simply starts `n` goroutines, each reading from the input channel containing
    the client connections. When a new connection is received on the channel, the
    `handleHttpRequest()` function is called to handle the client’s request.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表初始化工作池中的所有goroutine。该函数简单地启动 `n` 个goroutine，每个goroutine从包含客户端连接的输入通道中读取。当通道接收到新的连接时，调用
    `handleHttpRequest()` 函数来处理客户端的请求。
- en: Listing 10.10 Starting up the worker pool
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.10 启动工作池
- en: '[PRE13]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Starts n goroutines
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 启动 n 个goroutine
- en: ❷ Consumes connections from the work queue channel until the channel is closed
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从工作队列通道消耗连接，直到通道关闭
- en: ❸ Handles the HTTP request from the received connection
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 处理接收到的连接上的HTTP请求
- en: Next, we need the `main()` goroutine to listen for new connections on a port
    and pass on any newly established connection on the work queue channel. In listing
    10.11, the `main()` function creates the work queue channel, starts up the worker
    pool, and then binds a TCP listen connection on port 8080\. In an infinite loop,
    when a new connection is established, the `Accept()` function unblocks and returns
    the connection. This connection is then passed on the channel to be used by one
    of the goroutines in the worker pool.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要 `main()` goroutine 在一个端口上监听新的连接，并将任何新建立的连接传递到工作队列通道。在列表10.11中，`main()`
    函数创建工作队列通道，启动工作池，然后在端口8080上绑定TCP监听连接。在一个无限循环中，当建立新的连接时，`Accept()` 函数解除阻塞并返回连接。然后，这个连接通过通道传递给工作池中的某个goroutine使用。
- en: Listing 10.11 `main()` function passing work to the worker pool (error handling
    omitted)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.11 `main()` 函数将工作传递给工作池（省略错误处理）
- en: '[PRE14]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Creates a work queue channel
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建工作队列通道
- en: ❷ Starts the worker pool with three goroutines
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用三个goroutine启动工作池
- en: ❸ Binds the TCP listening connection to port 8080
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将TCP监听连接绑定到端口8080
- en: ❹ Blocks until there is a new connection from a client
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 阻塞直到有来自客户端的新连接
- en: ❺ Passes the connection on the work queue channel
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将连接通过工作队列通道传递
- en: 'We can test the previous listings either by pointing a browser to http://localhost:8080/
    index.html or by using the following `curl` command:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过将浏览器指向 http://localhost:8080/index.html 或使用以下 `curl` 命令来测试前面的列表：
- en: '[PRE15]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note The worker pool pattern is especially useful when creating new threads
    of execution is expensive. Instead of creating threads on the fly when we have
    new work, this pattern creates the worker pool before processing begins, and the
    workers are reused. This way, less time is wasted when we need new work to be
    done. In Go, creating goroutines is a very fast process, so this pattern doesn’t
    bring much benefit in terms of performance.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：工作池模式在创建新的执行线程成本高昂时特别有用。在我们有新工作要做时，不是即时创建线程，而是在处理开始之前创建工作池，并且重用工作者。这样，当我们需要新工作来完成时，可以节省更多的时间。在Go中，创建goroutine是一个非常快速的过程，因此这种模式在性能方面不会带来很多好处。
- en: Even though worker pools do not offer much performance benefit in Go, they can
    still be used to limit the amount of concurrency so that programs and servers
    don’t run out of resources. In our HTTP server, we can opt to stop handling client
    connections when the entire worker pool is busy, as shown in figure 10.9\. We
    can use the channel in a non-blocking manner so that the `main()` goroutine returns
    a “server busy” error to the client.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在工作池中Go不提供很多性能优势，但它们仍然可以用来限制并发量，以便程序和服务器不会耗尽资源。在我们的HTTP服务器中，我们可以选择在整个工作池忙碌时停止处理客户端连接，如图10.9所示。我们可以以非阻塞方式使用通道，以便
    `main()` goroutine 向客户端返回“服务器忙碌”错误。
- en: '![](../../OEBPS/Images/CH10_F09_Cutajar.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F09_Cutajar.png)'
- en: Figure 10.9 Server detects that it’s too busy and returns an error message
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 服务器检测到太忙并返回错误消息
- en: Listing 10.12 implements this non-blocking behavior on the work queue channel.
    In this listing, we use a `select` statement that triggers the default case when
    there are no free worker pool goroutines. The logic in the default case returns
    a “busy” error message to the client.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.12在工作队列通道上实现了这种非阻塞行为。在这个列表中，我们使用了一个`select`语句，当没有空闲的工作池goroutines时，触发默认情况。默认情况中的逻辑向客户端返回“忙碌”错误信息。
- en: Listing 10.12 Using `select`’s default case to limit the load on the server
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.12 使用`select`的默认情况来限制服务器的负载
- en: '[PRE16]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ When no goroutines are consuming from the work queue, the default case triggers.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 当没有goroutines从工作队列中消费时，触发默认情况。
- en: ❷ Returns “busy” message to client
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 向客户端返回“忙碌”信息
- en: ❸ Closes client connection
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 关闭客户端连接
- en: 'We can trigger this “busy” error message when we open many simultaneous connections.
    Our worker pool is very small, with only three goroutines, so it’s quite easy
    to get the entire pool busy. Using the following command, we can see that the
    server returns this error message. In this command, the `xargs` with `-P100` option
    executes `curl` requests in parallel, with 100 processes:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们打开许多同时连接时，我们可以触发这个“忙碌”的错误信息。我们的工作池非常小，只有三个goroutines，所以很容易让整个池子变得忙碌。使用以下命令，我们可以看到服务器返回这个错误信息。在这个命令中，带有`-P100`选项的`xargs`并行执行`curl`请求，有100个进程：
- en: '[PRE17]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 10.2.4 Pipelining
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.4 管道化
- en: 'What if the only way to decompose our problem is to have a set of tasks where
    each task completely depends on the previous one being complete? For example,
    consider a scenario in which we are running a cupcake factory. Baking cupcakes
    in our factory involves the following steps:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果分解我们问题的唯一方式是拥有一系列任务，其中每个任务完全依赖于前一个任务完成，那会怎样？例如，考虑这样一个场景：我们正在运营一个纸杯蛋糕工厂。在我们工厂中制作纸杯蛋糕涉及以下步骤：
- en: Prepare the baking tray.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备烘焙托盘。
- en: Pour the cupcake mixture.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 倒入纸杯蛋糕混合物。
- en: Bake the mixture in the oven.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在烤箱中烘烤混合物。
- en: Add toppings.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加配料。
- en: Pack the cupcakes in a box for delivery.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将纸杯蛋糕装箱以供配送。
- en: If we wanted to speed things up, simply hiring staff and asking them to pick
    up any task that needs doing would not be a very effective strategy in terms of
    efficiency, because each step, apart from the first one, depends on the previous
    one. When we have this heavy task dependency, applying a pipeline pattern will
    allow us to do more work in the same amount of time.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要加快速度，仅仅雇佣员工并让他们去完成任何需要做的任务，从效率的角度来看，这并不是一个非常有效的策略，因为除了第一个步骤之外，每个步骤都依赖于前一个步骤。当我们有这种沉重的任务依赖时，应用管道模式将允许我们在相同的时间内完成更多的工作。
- en: The pipeline pattern is used in many manufacturing industries. One common example
    is a modern car assembly line. The frame of a car moves along the line, and at
    each stage, a different robot performs a different action (such as attaching a
    part) on the car being built.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 管道模式在许多制造业中都有应用。一个常见的例子是现代汽车装配线。汽车的底盘沿着生产线移动，在每一个阶段，不同的机器人会对正在建造的汽车执行不同的动作（例如安装零件）。
- en: We can use the same principle in our example. We can have people working in
    parallel on different cupcakes batches. Each person is working on a different
    one of the previously outlined steps, and the output of one step feeds into the
    input of the next (see figure 10.10). In this way, we can utilize the full workforce
    and increase the number of cupcakes we can produce in a given time.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在我们的例子中使用同样的原则。我们可以让人们在不同的纸杯蛋糕批次上并行工作。每个人都在执行之前概述的不同步骤，一个步骤的输出被输入到下一个步骤（见图10.10）。这样，我们可以充分利用劳动力，并在给定的时间内增加可以生产的纸杯蛋糕数量。
- en: '![](../../OEBPS/Images/CH10_F10_Cutajar.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F10_Cutajar.png)'
- en: Figure 10.10 The cupcake factory using a pipeline pattern
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 使用管道模式的纸杯蛋糕工厂
- en: There are technical problems where we can only decompose tasks in this manner.
    For example, consider a sound processing application in which multiple filters,
    such as noise reduction, high cut, bandpass, etc., need to be applied to a sound
    stream on top of each other. There are similar examples that apply to video and
    image processing. In the previous chapter, we built an application using a pipeline
    pattern that downloaded documents from web pages, extracted words, and then counted
    word frequencies.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些技术问题中，我们只能以这种方式分解任务。例如，考虑一个声音处理应用程序，其中需要将多个过滤器（如降噪、高切、带通等）叠加应用于声音流。还有类似的例子适用于视频和图像处理。在前一章中，我们使用管道模式构建了一个应用程序，该应用程序从网页下载文档，提取单词，然后计算单词频率。
- en: Let’s stay with our cupcake example and try to implement a program that simulates
    this. We can then use this program to examine the various properties of a typical
    pipeline. In the following listing, the steps that we outlined in figure 10.10
    are in separate functions. In each function, we are simulating work by sleeping
    for 2 seconds, except for the `Bake()` function, where we sleep for 5 seconds.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用我们的纸杯蛋糕示例，并尝试实现一个模拟此过程的程序。然后我们可以使用这个程序来检查典型管道的各种属性。在以下列表中，我们在图 10.10
    中概述的步骤在单独的函数中。在每个函数中，我们通过暂停 2 秒来模拟工作，除了 `Bake()` 函数，在那里我们暂停 5 秒。
- en: Listing 10.13 Steps for making cupcakes
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.13 制作纸杯蛋糕的步骤
- en: '[PRE18]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Every step, except the bake step, sleeps for 2 seconds to simulate work.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 除了烘焙步骤外，每个步骤都暂停 2 秒来模拟工作。
- en: ❷ Each function returns a description of what was done.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 每个函数返回所执行操作的描述。
- en: ❸ The oven step sleeps for 5 seconds instead of 2.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 烘焙步骤暂停 5 秒而不是 2 秒。
- en: To compare the speedup of parallel vs. sequential execution, let’s first execute
    all the steps, one after the other, by using the sequential program outlined in
    the following listing. Here we are simulating one person producing 10 boxes of
    cupcakes by performing one step after the other.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较并行执行与顺序执行的速度提升，让我们首先使用以下列表中概述的顺序程序依次执行所有步骤。在这里，我们通过依次执行一个步骤来模拟一个人生产 10 盒纸杯蛋糕。
- en: Listing 10.14 `main()` function producing 10 boxes of cupcakes sequentially
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.14 `main()` 函数顺序生产 10 盒纸杯蛋糕
- en: '[PRE19]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Executes 10 times
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 执行 10 次
- en: ❷ Performs one step after the other sequentially
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 依次顺序执行一个步骤
- en: 'When performing one step after the other, sequentially, finishing a box of
    cupcakes takes us about 13 seconds. In our program, finishing 10 boxes takes around
    130 seconds, as shown in the output when we execute the previous two listings
    together:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当依次顺序执行一个步骤时，完成一盒纸杯蛋糕大约需要 13 秒。在我们的程序中，完成 10 盒纸杯蛋糕大约需要 130 秒，如执行前两个列表的输出所示：
- en: '[PRE20]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let’s now convert our program to run with multiple executions in a pipeline
    fashion. The steps in a simple pipeline all follow the same pattern: accept input
    from an input channel of type X, process X, and produce the result Y on an output
    channel of type Y. Figure 10.11 shows how we can build a reusable component that
    creates a goroutine reading from an input channel consuming type X, calls a function
    that maps X to Y, and outputs Y on an output channel.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将我们的程序转换为以管道方式运行的多重执行。简单管道中的步骤都遵循相同的模式：从类型为 X 的输入通道接收输入，处理 X，并在类型为 Y 的输出通道上产生结果
    Y。图 10.11 显示了我们可以构建一个可重用组件，该组件创建一个从输入通道读取类型 X 的 goroutine，调用将 X 映射到 Y 的函数，并在输出通道上输出
    Y。
- en: '![](../../OEBPS/Images/CH10_F11_Cutajar.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F11_Cutajar.png)'
- en: Figure 10.11 Pipeline step accepts X, calls a function to map to Y, and outputs
    Y
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11 管道步骤接受 X，调用函数将其映射到 Y，并输出 Y
- en: In listing 10.15, we implement this. In the signature, we accept both input
    and output channels and a mapping function `f`. The `AddOnPipe()` function creates
    an output channel and starts up a goroutine that calls the mapping function in
    an infinite loop. In the implementation, we use the usual quit channel pattern
    where we stop if the quit channel (the parameter named `q` in the listing) is
    closed. We make use of Go’s generics so that the types from the channels and the
    mapping function match.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 10.15 中，我们实现了这一点。在签名中，我们接受输入和输出通道以及一个映射函数 `f`。`AddOnPipe()` 函数创建一个输出通道并启动一个无限循环调用映射函数的
    goroutine。在实现中，我们使用通常的退出通道模式，如果退出通道（列表中命名为 `q` 的参数）被关闭，则停止。我们利用 Go 的泛型，以确保通道和映射函数的类型匹配。
- en: Listing 10.15 A reusable pipeline node
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.15 可重用管道节点
- en: '[PRE21]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Creates an output channel of type Y
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建类型为 Y 的输出通道
- en: ❷ Starts the goroutine
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 启动 goroutine
- en: ❸ Calls select in an infinite loop
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在无限循环中调用 select
- en: ❹ When the quit channel is closed, exits the loop and terminates the goroutine
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 当退出通道关闭时，退出循环并终止 goroutine
- en: ❺ Receives a message on the input channel if one is available
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 如果有可用的消息，则在输入通道上接收消息
- en: ❻ Calls the function f and outputs the function’s return value on the output
    channel
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 调用函数 f 并在输出通道上输出函数的返回值
- en: We can now add all the steps of our cupcake factory on a common pipeline, using
    the function in listing 10.15\. In the following listing, we have a `main()` function
    that wraps each step using the `AddOnPipe()` function. It then starts a goroutine
    that feeds 10 messages into the `PrepareTray()` step. This has the effect of running
    our pipeline 10 times.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用列表10.15中的函数，将我们曲奇工厂的所有步骤添加到一个公共管道中。在下面的列表中，我们有一个`main()`函数，它使用`AddOnPipe()`函数包装每个步骤。然后它启动一个goroutine，向`PrepareTray()`步骤中输入10条消息。这相当于运行我们的管道10次。
- en: Listing 10.16 Wiring and starting our cupcake pipeline
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.16 连接和启动我们的曲奇管道
- en: '[PRE22]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Creates the first input channel to be used to connect to the first step
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建第一个输入通道，用于连接到第一个步骤
- en: ❷ Creates the quit channel
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建退出通道
- en: ❸ Wires each step on the pipeline, feeding the output of each step to the input
    of the next one
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将管道上的每个步骤连接起来，将每个步骤的输出馈送到下一个步骤的输入
- en: ❹ Creates a goroutine that sends 10 integers onto the pipeline to produce 10
    cupcake boxes
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 创建一个goroutine，向管道发送10个整数以生产10个曲奇盒子
- en: ❺ Reads 10 cupcake boxes as output from the last pipeline step
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 从上一个管道步骤读取10个曲奇盒子作为输出
- en: 'At the end of our `main()` function, we wait for 10 messages to arrive and
    print out the message on the console. Here’s the output when we run the previous
    listing:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在`main()`函数的末尾，我们等待10条消息到达并在控制台上打印出消息。以下是运行上一个列表时的输出：
- en: '[PRE23]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Using the pipelining version of our algorithm resulted in a faster execution
    of around 58 seconds instead of 130\. Can we improve it even further by speeding
    up the time it takes to complete some of the steps? Let’s experiment with the
    timings, and along the way, we’ll discover some properties of the pipeline pattern.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们算法的管道版本导致执行速度加快，大约为58秒而不是130秒。我们能否通过加快完成某些步骤所需的时间来进一步提高它？让我们对时间进行实验，在这个过程中，我们将发现管道模式的一些属性。
- en: 10.2.5 Pipelining properties
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.5 管道属性
- en: 'What would happen if we sped up all our manual steps (excluding the baking
    time)? In our program, we can reduce the constant `everyThingElseTime` (from listing
    10.1) to a smaller value. In this way, all the steps, excluding the baking time,
    will run faster. Here’s the output when we set `everyThingElseTime = 1`:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们加快所有手动步骤（不包括烘焙时间）的速度会发生什么？在我们的程序中，我们可以将常数`everyThingElseTime`（从列表10.1）减小到一个更小的值。这样，除了烘焙时间之外的所有步骤都会运行得更快。以下是设置`everyThingElseTime
    = 1`时的输出：
- en: '[PRE24]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: What is going on here? We have doubled the speed of almost every step, but the
    total time to produce 10 boxes has stayed almost the same. To understand what
    is going on, have a look at figure 10.12.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生了什么？我们几乎加倍了几乎每个步骤的速度，但生产10个盒子的总时间几乎保持不变。要了解发生了什么，请看图10.12。
- en: '![](../../OEBPS/Images/CH10_F12_Cutajar.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH10_F12_Cutajar.png)'
- en: Figure 10.12 Increasing the speed of non-baking parts does not increase the
    throughput significantly.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12增加非烘焙部分的速度并不会显著提高吞吐量。
- en: Note In a pipeline, the *throughput* *rate* is dictated by the slowest step.
    The *latency* of the system is the sum of the time it takes to perform every step
    along the way.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在管道中，*吞吐量* *速率* 由最慢的步骤决定。系统的*延迟*是执行每一步所需时间的总和。
- en: If our pipeline were real, four people would be working twice as fast but making
    hardly any difference in terms of throughput. This is because the bottleneck in
    our pipeline is the baking time. Our slowest step is limited by the fact that
    we have a slow oven, and it is slowing everything down. To increase the number
    of cupcakes created per unit of time, we should focus on speeding up our slowest
    step.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的管道是真实的，四个人会工作得快两倍，但在吞吐量方面几乎没有任何区别。这是因为我们的管道中的瓶颈是烘焙时间。我们最慢的步骤受限于我们有一个慢烤箱，它使一切变慢。为了提高单位时间内生产的曲奇数量，我们应该专注于加快我们最慢的步骤。
- en: TIP To increase the throughput of a system, it’s always best to focus on the
    bottleneck of that system. This is the part that is having the greatest effect
    on slowing down our performance.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：为了提高系统的吞吐量，始终最好关注该系统的瓶颈。这是对降低我们性能影响最大的部分。
- en: Speeding up most of the steps has made a difference in how much time it takes
    to produce a single box of cupcakes from start to finish. In the first run, it
    took us 13 seconds to produce one box. When we set `everyThingElseTime = 1`, this
    went down to 9 seconds. We can think of this as the system latency. For some applications
    (such as backend batch processing), it’s more important to have high throughput,
    while for other applications (such as real-time systems), it’s better to improve
    latency.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 加快大多数步骤已经对从开始到结束生产一盒纸杯蛋糕所需的时间产生了影响。在第一次运行中，我们用了13秒来生产一盒。当我们设置`everyThingElseTime
    = 1`时，这个时间下降到了9秒。我们可以将这视为系统延迟。对于某些应用程序（如后端批量处理），高吞吐量更重要，而对于其他应用程序（如实时系统），提高延迟更好。
- en: TIP To reduce the latency of a pipeline system, we need to improve the speed
    of most steps in the pipeline.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：为了减少管道系统的延迟，我们需要提高管道中大多数步骤的速度。
- en: 'Let’s experiment further with our pipeline by improving the baking step and
    making it faster. In real life, we could get a more powerful oven or perhaps have
    multiple ovens that can work in parallel. In our program, we can simply set the
    variable `ovenTime = 2` instead of `5` and set `everyThingElseTime` back to `2`.
    When we run the program again, we get the following output:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进一步通过改进烘焙步骤并使其更快来实验我们的管道。在现实生活中，我们可以得到一个更强大的烤箱，或者可能有多个可以并行工作的烤箱。在我们的程序中，我们可以简单地设置变量`ovenTime
    = 2`而不是`5`，并将`everyThingElseTime`恢复到`2`。当我们再次运行程序时，我们得到以下输出：
- en: '[PRE25]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We have greatly improved the time it takes to produce 10 boxes of cupcakes.
    The reason for this speedup is clear in figure 10.13\. We can see that we’re now
    more efficient with time. Every goroutine is constantly busy without any idle
    time. This means we have improved throughput—the number of cupcakes produced per
    unit of time.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们大大提高了生产10盒纸杯蛋糕所需的时间。这种加速的原因在图10.13中很清楚。我们可以看到，我们现在在时间上更有效率。每个goroutine都在不断忙碌，没有任何空闲时间。这意味着我们提高了吞吐量——单位时间内生产的纸杯蛋糕数量。
- en: '![](../../OEBPS/Images/CH10_F13_Cutajar.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH10_F13_Cutajar.png)'
- en: Figure 10.13 Speeding up our slowest step has bigger effects on throughput.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13 加快最慢的步骤对吞吐量的影响更大。
- en: It’s worth noting that although we have increased throughput, the time it takes
    to produce a box of cupcakes (the system latency) has not been greatly affected.
    It now takes 10 seconds to produce a box from start to finish instead of 13 seconds.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，尽管我们已经提高了吞吐量，但生产一盒纸杯蛋糕（系统延迟）的时间并没有受到很大影响。现在从开始到结束生产一盒纸杯蛋糕需要10秒，而不是13秒。
- en: 10.3 Exercises
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 练习
- en: NOTE Visit [http://github.com/cutajarj/ConcurrentProgrammingWithGo](http://github.com/cutajarj/ConcurrentProgrammingWithGo)
    to see all the code solutions.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：访问[http://github.com/cutajarj/ConcurrentProgrammingWithGo](http://github.com/cutajarj/ConcurrentProgrammingWithGo)以查看所有代码解决方案。
- en: Implement the same directory hashing that we did in listing 10.4, but instead
    of using channels to synchronize between iterations, try using waitgroups.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现与列表10.4中相同的目录哈希，但不是使用通道在迭代之间同步，而是尝试使用waitgroups。
- en: Change listing 10.2 so that the work queue channel between the `main()` goroutine
    and the worker pool has a buffer of 10 messages. Doing so will give you a capacity
    buffer so that when all the goroutines are busy, some of the requests are queued
    before they can be picked up.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改列表10.2，使得`main()` goroutine和工作者池之间的工作队列通道具有10条消息的缓冲区。这样做将为您提供容量缓冲区，以便当所有goroutine都忙碌时，一些请求在它们被选中之前可以排队。
- en: The following listing downloads 30 web pages and counts the total number of
    lines on all the documents sequentially. Convert this program to use concurrent
    programming, using a concurrency pattern explained in this chapter.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下列表下载30个网页，并按顺序计算所有文档的总行数。将此程序转换为使用本章中解释的并发编程模式。
- en: Listing 10.17 Line count for web pages
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.17 网页行数
- en: '[PRE26]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Summary
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Decomposition is the process of breaking a program into different parts and
    figuring out which parts can be executed concurrently.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分解是将程序分解为不同的部分，并找出哪些部分可以并发执行。
- en: Building dependency graphs helps us understand which tasks can be performed
    in parallel with others.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建依赖图有助于我们了解哪些任务可以与其他任务并行执行。
- en: Task decomposition is about breaking down a problem into the different actions
    needed to complete the entire job.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务分解是将问题分解为完成整个工作所需的不同动作。
- en: Data decomposition is partitioning data in a way so that tasks on the data can
    be performed concurrently.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分解是将数据划分成一种方式，使得对数据的任务可以并行执行。
- en: Choosing fine granularity when breaking down programs means more parallelism
    at the cost of limiting scalability due to time spent on synchronization and communication.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在将程序分解时选择细粒度意味着在同步和通信上花费时间以限制可扩展性的同时，可以获得更多的并行性。
- en: Choosing coarse granularity means less parallelism, but it reduces the amount
    of synchronization and communication required.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择粗粒度意味着并行性较少，但它减少了所需的同步和通信量。
- en: Loop-level parallelism can be used to perform a list of tasks concurrently if
    there is no dependency on the tasks.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果任务之间没有依赖关系，可以使用循环级别的并行性来并发执行一系列任务。
- en: In loop-level parallelism, splitting the problem into parallel and synchronized
    parts allows for a dependency on a previous task iteration.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在循环级别的并行性中，将问题分解为并行和同步部分，允许依赖于前一个任务迭代。
- en: Fork/join is a concurrency pattern that can be used when we have a problem with
    an initial parallel part and a final step that merges the various results.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fork/join 是一种并发模式，当问题有一个初始的并行部分和一个最终步骤来合并各种结果时可以使用。
- en: A worker pool is useful when the concurrency needs to scale on demand.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当并发需求需要按需扩展时，工作池是有用的。
- en: Pre-creating executions in a worker pool is faster than creating them on the
    fly for most languages.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在工作池中预先创建执行比动态创建对大多数语言来说都要快。
- en: In Go, the performance of pre-creating a worker pool versus creating goroutines
    on the fly is minimal due to the lightweight nature of goroutines.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Go 语言中，由于 goroutines 的轻量级特性，预先创建工作池与动态创建 goroutines 的性能差异极小。
- en: Worker pools can be used to limit concurrency so as not to overload servers
    when there is an unexpected increase in demand.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当需求意外增加时，可以使用工作池来限制并发性，以免服务器过载。
- en: Pipelines are useful to increase throughput when each task depends on the previous
    one to be complete.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当每个任务都依赖于前一个任务完成时，管道对于提高吞吐量是有用的。
- en: Increasing the speed of the slowest node in a pipeline results in an increase
    in the throughput performance of the entire pipeline.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加管道中最慢节点的速度会导致整个管道的吞吐量性能提高。
- en: Increasing the speed of any node in a pipeline results in a reduction in the
    pipeline’s latency.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加管道中任何节点的速度会导致管道延迟的减少。
