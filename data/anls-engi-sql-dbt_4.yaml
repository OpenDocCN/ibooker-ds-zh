- en: Chapter 4\. Data Transformation with dbt
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章。使用dbt进行数据转换
- en: The primary purpose of dbt is to help you *transform* the data of your data
    platforms in an easy and integrated way by simply writing SQL statements. When
    we place dbt in an ELT workflow, it matches the activities during the transformation
    stage, providing you with additional components—such as version control, documentation,
    tests, or automated deployment—that simplify the overall work of a data specialist.
    Does this remind you of the actual activities of an analytics engineer? Well,
    that’s because dbt is one of the modern tools that defines what analytics engineers
    do, giving them the instruments integrated with the platform, which reduces the
    need to set up additional services to answer specific problems and decreases the
    overall system complexity.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: dbt的主要目的是通过简单地编写SQL语句，帮助您在数据平台上*轻松*和*集成*地*转换*数据。将dbt置于ELT工作流中时，它与转换阶段的活动相匹配，为您提供额外的组件——如版本控制、文档、测试或自动部署——以简化数据专家的整体工作。这是否让您想起了分析工程师的实际活动？那是因为dbt是定义分析工程师工作的现代工具之一，为他们提供与平台集成的工具，减少了设置额外服务来解决特定问题并降低了整体系统复杂性的需求。
- en: dbt supports the tasks described for an analytics engineer, empowering them
    to run the code in their data platform collaboratively for a single source of
    truth for metrics and business definitions. It promotes central and modular analytics
    code, leveraging DRY code with Jinja templating language, macros, or packages.
    In parallel, dbt also provides the security that we typically find in software
    engineering best practices, such as *collaborate* on data models, *version* them,
    and *test* and *document* your queries before safely *deploying* them to production,
    with *monitoring* and *visibility*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: dbt支持为分析工程师描述的任务，赋予他们在其数据平台上协作运行代码的能力，为指标和业务定义提供单一真实来源。它促进了中心化和模块化的分析代码，利用Jinja模板语言、宏或包来实现DRY代码。同时，dbt还提供了我们通常在软件工程最佳实践中找到的安全性，例如*协作*在数据模型上，*版本*它们，并在*部署*到生产之前*测试*和*文档*您的查询，配合*监控*和*可见性*。
- en: We’ve provided a thorough introduction to dbt. However, within this chapter,
    we will delve even deeper into the specifics of dbt and clarify its importance
    in the world of data analytics. We will discuss the dbt design philosophy, the
    principles behind this transformation tool, and the data lifecycle with dbt at
    its core, presenting how dbt transforms raw data into structured models for easy
    consumption. We will explore the dbt project structure by outlining its various
    features, such as building models, documentation, and tests, as well as detailing
    other dbt artifacts, such as YAML files. By the end of this chapter, you will
    have a comprehensive understanding of dbt and its capabilities, which will enable
    you to implement it effectively in your data analytics workflow.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经为您提供了dbt的全面介绍。然而，在本章中，我们将更深入地探讨dbt的具体内容，澄清其在数据分析世界中的重要性。我们将讨论dbt的设计理念，这种转换工具背后的原则，以及以dbt为核心的数据生命周期，展示dbt如何将原始数据转换为易于消费的结构化模型。我们将通过概述其各种功能，如构建模型、文档和测试，以及详细说明其他dbt工件，如YAML文件，来探索dbt项目结构。通过本章的学习，您将全面了解dbt及其能力，从而能够在您的数据分析工作流中有效实施它。
- en: dbt Design Philosophy
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: dbt设计理念
- en: As data engineering and analytics workflows become increasingly complex, tools
    that streamline the process while maintaining data quality and reliability are
    essential. dbt has emerged as a concentrated solution with a well-defined design
    philosophy that underpins its approach to data modeling and analytics engineering.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 随着数据工程和分析工作流程变得日益复杂，重视数据质量和可靠性的流程简化工具至关重要。dbt作为一个集中的解决方案，通过其对数据建模和分析工程的方法基础的设计理念，显现出其重要性。
- en: 'In summary, dbt design philosophy relies on the following points:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 简言之，dbt的设计理念依赖于以下几点：
- en: Code-centric approach
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 以代码为中心的方法
- en: At the core of dbt’s design philosophy is a code-centric approach to data modeling
    and transformation. Instead of relying on GUI-based interfaces or manual SQL scripts,
    dbt encourages users to define data transformations using code. This shift to
    code-driven development promotes collaboration, version control, and automation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: dbt设计理念的核心是基于代码的数据建模和转换方法。dbt鼓励用户使用代码定义数据转换，而不是依赖于基于GUI的界面或手动SQL脚本。这种转向代码驱动的开发促进了协作、版本控制和自动化。
- en: Modularity for reusability
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 可重用性的模块化
- en: dbt promotes modularity, allowing data practitioners to create reusable code
    components. Models, macros, and tests can be organized into packages, which facilitates
    code maintenance and scalability. This modular approach aligns with best practices
    and enhances code reusability.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: dbt推广模块化，允许数据从业者创建可重用的代码组件。模型、宏和测试可以组织成包，从而促进代码维护和可扩展性。这种模块化方法符合最佳实践，并增强了代码的可重用性。
- en: Transformations as SQL `SELECT` statements
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 转换为SQL `SELECT`语句
- en: dbt models are defined as SQL `SELECT` statements, making them accessible to
    analysts and engineers with SQL skills. This design choice simplifies development
    and ensures that data modeling closely follows SQL best practices.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: dbt模型被定义为SQL `SELECT`语句，使得具备SQL技能的分析师和工程师可以轻松访问。这种设计选择简化了开发，并确保数据建模紧密遵循SQL最佳实践。
- en: Declarative language
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 声明性语言
- en: dbt uses a declarative language for defining data transformations. Analysts
    specify the desired outcome, and dbt handles the underlying implementation. This
    abstraction reduces the complexity of writing complex SQL code and enhances readability.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: dbt使用声明性语言定义数据转换。分析师指定所需的结果，dbt处理底层实现。这种抽象减少了编写复杂SQL代码的复杂性，并增强了可读性。
- en: Incremental builds
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 增量构建
- en: Efficiency is a key focus of dbt’s design. It supports incremental builds, which
    allows data engineers to update only the affected pieces of the data pipeline
    rather than reprocessing the entire dataset. This accelerates development and
    reduces processing time.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 效率是dbt设计的重点。它支持增量构建，这使得数据工程师可以仅更新受影响的数据管道部分，而不是重新处理整个数据集。这加速了开发并减少了处理时间。
- en: Documentation as code
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 文档即代码
- en: dbt advocates for documenting data models and transformations as code. Descriptions,
    explanations, and metadata are stored alongside the project code, making it easier
    for team members to understand and collaborate effectively.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: dbt倡导将数据模型和转换视为代码进行文档化。描述、解释和元数据存储在项目代码旁边，使团队成员更容易理解并有效协作。
- en: Data quality, testing, and validation
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量、测试和验证
- en: dbt places a significant emphasis on data testing. It provides a testing framework
    that enables analysts to define data quality checks and validation rules. This
    includes data reliability and quality throughout the pipeline, thus ensuring that
    data meets predefined criteria and adheres to business rules.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: dbt非常重视数据测试。它提供了一个测试框架，使分析师能够定义数据质量检查和验证规则。这包括数据可靠性和质量在整个管道中的保证，从而确保数据符合预定义的标准并遵循业务规则。
- en: Version control integration
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 版本控制集成
- en: Seamless integration with version control systems like Git is a fundamental
    aspect of dbt. This feature enables collaborative development, change tracking,
    and the ability to roll back changes, ensuring that data pipelines remain under
    version control.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 与像Git这样的版本控制系统的无缝集成是dbt的一个基本特性。这个功能支持协同开发、变更追踪和回滚功能，确保数据管道始终处于版本控制之下。
- en: Native integration with data platforms
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据平台的本地集成
- en: dbt is designed to work seamlessly with popular data platforms such as Snowflake,
    BigQuery, and Redshift. It leverages the native capabilities of these platforms
    for scalability and performance.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: dbt被设计成与Snowflake、BigQuery和Redshift等流行数据平台无缝集成。它利用这些平台的本地功能进行扩展和性能优化。
- en: Open source and extensible
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 开源且可扩展
- en: dbt is an open source tool with a thriving community. Users can extend its functionality
    by creating custom macros and packages. This extensibility allows organizations
    to tailor dbt to their specific data needs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: dbt是一个开源工具，拥有一个充满活力的社区。用户可以通过创建自定义宏和包来扩展其功能。这种可扩展性允许组织根据其特定的数据需求定制dbt。
- en: Separation of transformation and loading
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 转换与加载的分离
- en: dbt separates the transformation and loading steps in the data pipeline. Data
    is transformed within dbt and then loaded into the data platform.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: dbt将数据管道中的转换和加载步骤分开。数据在dbt内部进行转换，然后加载到数据平台。
- en: In essence, dbt’s design philosophy is rooted in creating a collaborative, code-centric,
    and modular environment for data engineers, analysts, and data scientists to efficiently
    transform data, ensure data quality, and generate valuable insights. dbt empowers
    organizations to harness the full potential of their data by simplifying the complexities
    of data modeling and analytics engineering.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 实质上，dbt 的设计理念根植于为数据工程师、分析师和数据科学家创建一个协作、代码中心化和模块化的环境，以便有效地转换数据、确保数据质量并生成有价值的洞察。dbt
    通过简化数据建模和分析工程的复杂性，赋予组织充分利用数据的潜力。
- en: dbt Data Flow
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: dbt 数据流
- en: '[Figure 4-1](#typical_data_flow_with_dbt) shows the big picture of a data flow.
    It identifies where dbt and its features fit in the overall data landscape.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-1](#typical_data_flow_with_dbt) 显示了数据流的大局观。它指出了 dbt 及其功能在整体数据景观中的位置。'
- en: '![dbt Flow](assets/aesd_0401.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Flow](assets/aesd_0401.png)'
- en: Figure 4-1\. Typical data flow with dbt that helps you transform your data from
    BigQuery, Snowflake, Databricks, and Redshift, among others (see the [dbt documentation
    for supported data platforms](https://oreil.ly/9b8dG))
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 使用 dbt 的典型数据流，帮助您从 BigQuery、Snowflake、Databricks 和 Redshift 等数据平台转换您的数据（请参阅
    [dbt 文档支持的数据平台](https://oreil.ly/9b8dG)）
- en: 'As mentioned, the primary purpose of dbt is to help you *transform* the data
    of your data platforms, and for that, dbt offers two tools for achieving that
    goal:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 正如提到的，dbt 的主要目的是帮助您 *转换* 数据平台的数据，并为此，dbt 提供了两个工具来实现这一目标：
- en: dbt Cloud
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: dbt 云
- en: dbt Core, an open source CLI tool, maintained by dbt Labs, that you can set
    up on your managed environments or run locally
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: dbt Core 是由 dbt Labs 维护的开源 CLI 工具，您可以在托管环境中设置或在本地运行
- en: Let’s look at an example to see how dbt works in real life and what it can do.
    Imagine that we are working on a pipeline that periodically extracts data from
    a data platform such as BigQuery. Then, it transforms the data by combining tables
    ([Figure 4-2](#typical_data_flow_with_dbt_2)).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个例子，了解 dbt 在实际生活中的工作原理及其作用。假设我们正在处理一个周期性从数据平台（如 BigQuery）提取数据的管道。然后，通过组合表格对数据进行转换（见[图
    4-2](#typical_data_flow_with_dbt_2)）。
- en: We’ll combine the first two tables into one, applying several transformation
    techniques, such as data cleaning or consolidation. This phase takes place in
    dbt, so we’ll need to create a dbt project to accomplish this merge. We will get
    there, but let’s first get familiar with dbt Cloud and how to set up our working
    environment.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将前两个表合并为一个，应用多种转换技术，如数据清洗或合并。这一阶段在 dbt 中进行，因此我们需要创建一个 dbt 项目来完成此合并。我们会逐步学习
    dbt Cloud 及如何设置我们的工作环境。
- en: Note
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For this book, we will use dbt Cloud to write our code since it is the fastest
    and most reliable way to start with dbt, from development to writing tests, scheduling,
    deployments, and investigating data models. Also, dbt Cloud runs on top of dbt
    Core, so while we work on dbt Cloud, we will become familiar with the same commands
    used in dbt Core’s CLI tool.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中，我们将使用 dbt Cloud 编写我们的代码，因为这是从开发到编写测试、调度、部署和调查数据模型的最快最可靠的方式。此外，dbt Cloud
    在 dbt Core 的 CLI 工具之上运行，因此在使用 dbt Cloud 时，我们将熟悉与 dbt Core 相同的命令。
- en: '![dbt Flow 2](assets/aesd_0402.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Flow 2](assets/aesd_0402.png)'
- en: Figure 4-2\. Data pipeline use case with dbt
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 使用 dbt 的数据管道用例
- en: dbt Cloud
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: dbt 云
- en: '*dbt Cloud* is a cloud-based version of dbt that offers a wide range of features
    and services to write and productize your analytics code. dbt Cloud allows you
    to schedule your dbt jobs, monitor their progress, and view logs and metrics in
    real time. dbt Cloud also provides advanced collaboration features, including
    version control, testing, and documentation. Moreover, dbt Cloud integrates with
    various cloud data warehouses, such as Snowflake, BigQuery, and Redshift, which
    allows you to easily transform your data.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*dbt Cloud* 是 dbt 的云版本，提供广泛的功能和服务来编写和产品化您的分析代码。dbt Cloud 允许您调度 dbt 作业，监视其进展，并实时查看日志和指标。dbt
    Cloud 还提供高级协作功能，包括版本控制、测试和文档编制。此外，dbt Cloud 还与各种云数据仓库集成，如 Snowflake、BigQuery 和
    Redshift，可以轻松地转换您的数据。'
- en: You can use dbt Core with the majority of the stated features, but it will require
    configuration and setup on your infrastructure, similar to running your own server
    or an Amazon Elastic Compute Cloud (EC2) instance for tools like Airflow. This
    means you’ll need to maintain and manage it autonomously, similar to managing
    a virtual machine (VM) on EC2.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 dbt Core 的大多数功能，但它需要在您的基础设施上进行配置和设置，类似于在自己的服务器或类似 Airflow 的工具上运行 Amazon
    弹性计算云（EC2）实例。这意味着您需要自主维护和管理它，类似于在 EC2 上管理虚拟机（VM）。
- en: In contrast, dbt Cloud operates like a managed service, similar to Amazon Managed
    Workflows for Apache Airflow (MWAA). It offers convenience and ease of use, as
    many operational aspects are handled for you, allowing you to focus more on your
    analytics tasks and less on infrastructure management.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，dbt Cloud 的运作方式类似于托管服务，类似于 Amazon 管理的 Apache Airflow 工作流服务（MWAA）。它提供了便利和易用性，因为许多操作方面都已为您处理，使您能够更专注于分析任务，而不是基础设施管理。
- en: Setting Up dbt Cloud with BigQuery and GitHub
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 BigQuery 和 GitHub 设置 dbt Cloud 的第一步
- en: There is nothing better than learning a specific technology by practicing it,
    so let’s set up the environment we will use to apply our knowledge. To start,
    let’s first register for a [dbt account](https://oreil.ly/OGGji).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 没有比通过实践学习特定技术更好的方法，所以让我们设置我们将用来应用知识的环境。首先，让我们注册一个[dbt 账户](https://oreil.ly/OGGji)。
- en: After registering, we will land on the Complete Project Setup page ([Figure 4-3](#dbt_landing_page_complete_setup)).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 注册后，我们将进入完整的项目设置页面（[图 4-3](#dbt_landing_page_complete_setup)）。
- en: '![dbt Registration2](assets/aesd_0403.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 注册 2](assets/aesd_0403.png)'
- en: Figure 4-3\. dbt landing page to complete the project setup
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-3\. dbt 项目设置的起始页
- en: This page has multiple sections to properly configure our dbt project, including
    connections to our desired data platform and to our code repository. We will use
    BigQuery as the data platform and GitHub to store our code.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此页面包含多个部分，用于正确配置我们的 dbt 项目，包括连接到我们期望的数据平台和代码库。我们将使用 BigQuery 作为数据平台，并使用 GitHub
    存储我们的代码。
- en: The first step in BigQuery is to set up a new project. In [GCP](https://oreil.ly/EQBXK),
    search for Create a Project in the search bar and click it ([Figure 4-4](#bigquery_project_setup_1)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在 BigQuery 中设置新项目的第一步是在[GCP](https://oreil.ly/EQBXK)中搜索“创建项目”并点击搜索栏中的该选项（[图
    4-4](#bigquery_project_setup_1)）。
- en: '![BigQuery project setup 1](assets/aesd_0404.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![BigQuery 项目设置 1](assets/aesd_0404.png)'
- en: Figure 4-4\. BigQuery project setup, step 1
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-4\. BigQuery 项目设置，第 1 步
- en: A screen similar to [Figure 4-5](#bigquery_project_setup_2) is presented, where
    you can set up the project. We’ve named it *dbt-analytics-engineer*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 展示了类似于[图 4-5](#bigquery_project_setup_2)的屏幕，您可以在此设置项目。我们将其命名为*dbt-analytics-engineer*。
- en: '![BigQuery project setup 2](assets/aesd_0405.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![BigQuery 项目设置 2](assets/aesd_0405.png)'
- en: Figure 4-5\. BigQuery project setup, step 2
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5\. BigQuery 项目设置，第 2 步
- en: After configuration, go into your BigQuery IDE—you can use the search bar again.
    It should look similar to [Figure 4-6](#bigquery_ide).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 配置完成后，进入您的 BigQuery IDE —— 您可以再次使用搜索栏。它应该看起来类似于[图 4-6](#bigquery_ide)。
- en: '![BigQuery IDE](assets/aesd_0406.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![BigQuery IDE](assets/aesd_0406.png)'
- en: Figure 4-6\. BigQuery IDE
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-6\. BigQuery IDE
- en: Finally, test the dbt public dataset to ensure that BigQuery is working correctly.
    For that, copy the code in [Example 4-1](#example_4-1) into BigQuery and then
    click Run.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，测试 dbt 的公共数据集，以确保 BigQuery 正常工作。为此，请将代码复制到[示例 4-1](#example_4-1)中，并点击“运行”。
- en: Example 4-1\. dbt public datasets in BigQuery
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-1\. BigQuery 中的 dbt 公共数据集
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you see the page in [Figure 4-7](#bigquery_dataset_output), then you did
    it!
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您看到[图 4-7](#bigquery_dataset_output)的页面，那么您做得很好！
- en: Note
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Since we’ve executed three queries simultaneously, we won’t see the output results.
    For that, click View Results to inspect the query output individually.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们同时执行了三个查询，我们看不到输出结果。为此，请单击“查看结果”以逐个检查查询输出。
- en: '![BigQuery dataset output](assets/aesd_0407.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![BigQuery 数据集输出](assets/aesd_0407.png)'
- en: Figure 4-7\. BigQuery dataset output
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-7\. BigQuery 数据集输出
- en: Now let’s connect dbt with BigQuery and execute these queries inside the dbt
    IDE. To let dbt connect to your data platform, you’ll need to generate a *keyfile*,
    similar to using a database username and password in most other data platforms.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将 dbt 与 BigQuery 连接，并在 dbt IDE 中执行这些查询。为了让 dbt 连接到您的数据平台，您需要生成一个*密钥文件*，类似于在大多数其他数据平台中使用数据库用户名和密码。
- en: 'Go to the [BigQuery console](https://oreil.ly/EQBXK). Before proceeding with
    the next steps, make sure you select the new project in the header. If you do
    not see your account or project, click your profile picture to the right and verify
    that you are using the correct email account:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 前往[BigQuery控制台](https://oreil.ly/EQBXK)。在继续下一步之前，请确保您在页眉中选择了新项目。如果您看不到您的帐户或项目，请点击右侧的个人资料图片，并验证您是否在使用正确的电子邮件帐户：
- en: Go to IAM & Admin and select Service Accounts.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往IAM & Admin并选择服务帐户。
- en: Click Create Service Account.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击创建服务帐户。
- en: In the name field, type **`dbt-user`** and then click Create and Continue.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在名称字段中输入**`dbt-user`**，然后点击创建和继续。
- en: On “Grant this service account access to project” select BigQuery Admin in the
    role field. Click Continue.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“授予此服务帐户对项目的访问权限”中，在角色字段中选择BigQuery管理员。然后点击继续。
- en: Leave fields blank in the “Grant users access to this service account” section
    and click Done.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“授予用户访问此服务帐户”部分留空字段，然后点击完成。
- en: The screen should look like [Figure 4-8](#bigquery_service_account_screen).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 屏幕应该看起来像[图 4-8](#bigquery_service_account_screen)。
- en: '![BigQuery Service accounts](assets/aesd_0408.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![BigQuery 服务帐户](assets/aesd_0408.png)'
- en: Figure 4-8\. BigQuery Service Accounts screen
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-8\. BigQuery 服务帐户屏幕
- en: 'Moving on, proceed with the remaining steps:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来继续进行剩余的步骤：
- en: Click the service account that you just created.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击刚刚创建的服务帐户。
- en: Select Keys.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择Keys。
- en: Click Add Key; then select “Create new key.”
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击添加密钥；然后选择“创建新密钥”。
- en: Select JSON as the key type; then click Create.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择JSON作为密钥类型，然后点击创建。
- en: You should be prompted to download the JSON file. Save it locally to an easy-to-remember
    spot with a clear filename—for example, *dbt-analytics-engineer-keys.json*.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应提示您下载JSON文件。将其保存在一个易于记忆的位置，并使用清晰的文件名，例如*dbt-analytics-engineer-keys.json*。
- en: 'Now let’s get back into the dbt Cloud for the final setup:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们返回到dbt Cloud进行最后的设置：
- en: On the project setup screen, give a more verbose name to your project. In our
    case, we chose *dbt-analytics-engineer*.
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在项目设置屏幕上，为您的项目指定一个更详细的名称。在我们的案例中，我们选择了*dbt-analytics-engineer*。
- en: On the “Choose a warehouse” screen, click the BigQuery icon and Next.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“选择仓库”屏幕上，点击BigQuery图标然后点击下一步。
- en: Upload the JSON file generated previously. To do this, click the “Upload a Service
    Account JSON file” button, visible in [Figure 4-9](#dbt_bigquery_upload_json).
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传先前生成的JSON文件。为此，请点击“上传服务帐户JSON文件”按钮，见[图 4-9](#dbt_bigquery_upload_json)。
- en: 'Last but not least, after you upload the file, apply the remaining step:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，在上传文件之后，应用剩余的步骤：
- en: Go to the bottom and click “test.” If you see “Your test completed successfully,”
    as [Figure 4-10](#dbt_bigquery_connection_test) shows, you’re good to go! Now
    click Next. On the other hand, if the test fails, there’s a good chance you’ve
    encountered an issue with your BigQuery credentials. Try to regenerate them again.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到底部并点击“测试”。如果看到“您的测试成功完成”，就像[图 4-10](#dbt_bigquery_connection_test)所示，那么您就可以继续进行了！现在点击下一步。另一方面，如果测试失败，很有可能是您的BigQuery凭据出现了问题。尝试重新生成它们。
- en: '![dbt Upload BigQuery Service accounts](assets/aesd_0409.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![dbt上传BigQuery服务帐户](assets/aesd_0409.png)'
- en: Figure 4-9\. dbt Cloud, submit BigQuery Service Account screen
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-9\. dbt Cloud，提交BigQuery服务帐户屏幕
- en: '![dbt-BigQuery Connection test](assets/aesd_0410.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![dbt-BigQuery连接测试](assets/aesd_0410.png)'
- en: Figure 4-10\. dbt and BigQuery connection test
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-10\. dbt和BigQuery连接测试
- en: 'The final step is setting up GitHub, but first, let’s understand what we are
    discussing here. GitHub is a popular version control platform that hosts Git repositories
    that allow you to track changes in your code and collaborate with others effectively.
    To correctly use Git, sticking to these principles and best practices is essential:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是设置GitHub，但首先，让我们先了解我们在这里讨论的内容。GitHub 是一个流行的版本控制平台，托管Git仓库，允许您跟踪代码的更改并有效地与他人协作。正确使用Git，遵循这些原则和最佳实践是至关重要的：
- en: Commit often, commit early
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 经常提交，早点提交
- en: Make frequent commits, even for small changes. This helps in tracking your progress
    and simplifies debugging. Each commit should represent a logical change or feature.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 经常进行提交，即使是小的更改也要如此。这有助于跟踪您的进度并简化调试。每个提交应代表一个逻辑变更或功能。
- en: Use meaningful commit messages
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 使用有意义的提交消息
- en: Write concise and descriptive commit messages. A good commit message should
    explain what was changed and why it was changed.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 写简洁而描述性的提交消息。一个好的提交消息应该解释了什么被改变以及为什么被改变。
- en: Follow a branching strategy
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循分支策略
- en: Use branches for different features, bug fixes, or development tasks.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用不同的分支来处理不同的功能、错误修复或开发任务。
- en: Pull before push
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 先拉取再推送
- en: Always pull the latest changes from the remote repository (e.g., `git pull`)
    before pushing your changes. This reduces conflicts and ensures that your changes
    are based on the latest code.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在推送您的更改之前，始终从远程存储库拉取最新更改（例如，`git pull`）。这样可以减少冲突，并确保您的更改基于最新的代码。
- en: Review code before committing
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在提交之前审查代码
- en: If your team practices code reviews, make sure to review and test your changes
    before committing. It helps maintain code quality.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的团队进行代码审查，请确保在提交之前审查和测试您的更改。这有助于维护代码质量。
- en: Use .gitignore
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 使用.gitignore
- en: Create a *.gitignore* file to specify files and directories that should be excluded
    from version control (e.g., build artifacts, temporary files).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个*.gitignore*文件，指定应从版本控制中排除的文件和目录（例如构建产物、临时文件）。
- en: Use atomic commits
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 使用原子提交
- en: Keep commits focused on a single, specific change. Avoid mixing unrelated changes
    in the same commit.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 保持提交集中于单一特定更改。避免在同一提交中混合不相关的更改。
- en: Rebase instead of merge
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用rebase而非merge
- en: Use `git rebase` to integrate changes from a feature branch into the main branch
    instead of traditional merging. This results in a cleaner commit history.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`git rebase`来将功能分支的更改集成到主分支中，而不是传统的合并。这将产生更清晰的提交历史。
- en: Keep commit history clean
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 保持提交历史干净
- en: Avoid committing “work in progress” or debugging statements. Use tools like
    `git stash` to temporarily save unfinished work.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 避免提交“正在进行中”的或调试语句。使用`git stash`等工具暂时保存未完成的工作。
- en: Use tags
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 使用标签
- en: Create tags, such as version tags, to mark important points in your project’s
    history, like releases or major milestones.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 创建标签，例如版本标签，以标记项目历史中的重要节点，如发布或主要里程碑。
- en: Collaborate and communicate
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 协作和沟通
- en: Communicate with your team about Git workflows and conventions. Establish guidelines
    for handling issues, pull requests, and conflict resolution.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 与团队沟通关于Git工作流程和约定。建立处理问题、提交请求和冲突解决的指南。
- en: Know how to undo changes
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 知道如何撤销更改
- en: Learn how to revert commits (`git revert`), reset branches (`git reset`), and
    recover lost work (`git reflog`) when needed.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 学习如何撤销提交（`git revert`）、重置分支（`git reset`）以及在需要时恢复丢失的工作（`git reflog`）。
- en: Document
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 文档
- en: Document your project’s Git workflow and conventions in a *README* or contributing
    guidelines to effectively onboard new team members.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在*README*或贡献指南中记录项目的Git工作流程和约定，以有效引导新团队成员。
- en: Use backup and remote repositories
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用备份和远程存储库
- en: Regularly back up your Git repositories and use remote repositories like GitHub
    for collaboration and redundancy.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 定期备份您的Git存储库，并使用GitHub等远程存储库进行协作和冗余备份。
- en: Continue learning
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 持续学习
- en: Git is a great tool with many features. Keep learning and exploring advanced
    Git concepts like cherry-picking, interactive rebasing, and custom hooks to improve
    your workflow.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Git是一个功能强大的工具，具有许多特性。继续学习和探索高级Git概念，如挑选、交互式重置和自定义挂钩，以改进您的工作流程。
- en: To better understand in practice some of the common Git terms and commands,
    let’s have a look at [Table 4-1](#git_terms_commands_example).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地实践一些常见的Git术语和命令，请参考[表4-1](#git_terms_commands_example)。
- en: Table 4-1\. Git terms and commands
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 表4-1\. Git术语和命令
- en: '| Term/command | Definition | Git command (if applicable) |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 术语/命令 | 定义 | Git命令（如果适用） |'
- en: '| --- | --- | --- |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Repository (repo) | This is similar to a project folder and contains all
    the files, history, and branches of your project. | - |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 存储库（repo） | 这类似于项目文件夹，包含项目的所有文件、历史记录和分支。 | - |'
- en: '| Branch | A branch is a separate line of development. It allows you to work
    on new features or fixes without affecting the main codebase. | `git branch *<branch_name>*`
    |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 分支 | 分支是开发的一个独立线路。它允许您在不影响主代码库的情况下工作新功能或修复。 | `git branch *<branch_name>*`
    |'
- en: '| Pull request (PR) | A pull request is a proposed change that you want to
    merge into the main branch. It’s a way to collaborate and review code changes
    with your team. | - |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 提交请求（PR） | 提交请求是您希望合并到主分支的建议更改。这是与团队协作和审查代码更改的一种方式。 | - |'
- en: '| Stash | `git stash` is a command that temporarily saves changes you have
    made in your working directory but do not want to commit yet. | `git stash save
    *"Your stash message here"*` |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 暂存 | `git stash` 是一个命令，暂时保存您在工作目录中进行的更改，但尚未提交。 | `git stash save *"在此添加您的暂存消息"*`
    |'
- en: '| Commit | A commit is a snapshot of your code at a specific point in time.
    It represents a set of changes you’ve made to your files. | `git commit -m *"Commit
    message here"*` |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 提交 | 提交是您代码在特定时间点的快照。它表示您对文件所做更改的集合。 | `git commit -m *"Commit message here"*`
    |'
- en: '| Add | `git add` is used to stage changes for the next commit. When you modify
    your files, Git doesn’t automatically include them in the next commit. You need
    to explicitly tell Git which changes to include. | To stage all changes, the git
    command is `git add .`, but you also specify a file or directory: `git add *<path/to/directory/>*`
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 添加 | `git add` 用于将更改暂存到下一次提交。当您修改文件时，Git 不会自动包含它们在下一次提交中。您需要明确告诉 Git 要包含哪些更改。
    | 要暂存所有更改，git 命令是 `git add .`，但您也可以指定文件或目录：`git add *<path/to/directory/>*` |'
- en: '| Fork | Forking a repository means creating your copy of someone else’s project
    on GitHub. You can make changes to your forked repository without affecting the
    original. | - |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 分叉 | 分叉存储库意味着在 GitHub 上创建别人项目的副本。您可以对分叉存储库进行更改，而不影响原始存储库。 | - |'
- en: '| Clone | Cloning a repository means making a local copy of a remote repository.
    You can work on your code locally and push changes to the remote repository. |
    `git clone *<repository_url>*` |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 克隆 | 克隆存储库意味着在本地创建远程存储库的副本。您可以在本地修改代码，并将更改推送到远程存储库。 | `git clone *<repository_url>*`
    |'
- en: '| Push | `git push` uploads your local changes to a remote repository. | `git
    push *<origin branch_name>*` |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 推送 | `git push` 将您的本地更改上传到远程存储库。 | `git push *<origin branch_name>*` |'
- en: '| Pull | `git pull` updates your local repository with changes from a remote
    repository. | `git pull` |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 拉取 | `git pull` 将远程存储库的更改更新到您的本地存储库。 | `git pull` |'
- en: '| Status | `git status` shows the current state of your working directory and
    staging area. | `git status` |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 状态 | `git status` 显示您工作目录和暂存区的当前状态。 | `git status` |'
- en: '| Log | `git log` displays a chronological list of commits in the repository
    and commits messages, authors, and commit IDs. | `git log` |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 记录 | `git log` 显示存储库中提交的时间顺序列表以及提交消息、作者和提交 ID。 | `git log` |'
- en: '| Diff | The `gitdiff` command shows the differences between two sets of code.
    | `git diff` |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 差异 | `gitdiff` 命令显示两组代码之间的差异。 | `git diff` |'
- en: '| Merge | The `git merge` command combines changes from one branch with another.
    | `git checkout *<target_branch>*` or `git merge *<source_branch>*` |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 合并 | `git merge` 命令将一个分支的更改与另一个分支合并。 | `git checkout *<target_branch>*` 或
    `git merge *<source_branch>*` |'
- en: '| Rebase | Rebase allows you to move or combine a sequence of commits to a
    new base commit. | `git rebase base_branch` |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 变基 | 变基允许您将一系列提交移动或合并到一个新的基础提交上。 | `git rebase base_branch` |'
- en: '| Checkout | The `checkout` command is used for switching between branches
    or commits. | `git checkout *<branch_name>*` |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 检出 | `checkout` 命令用于在不同分支或提交之间切换。 | `git checkout *<branch_name>*` |'
- en: These Git commands and terms provide the foundation for version control in your
    projects. Nevertheless, Git commands often have many additional arguments and
    options, allowing for fine-tuned control over your version control tasks. While
    we’ve covered some essential commands here, it’s essential to note that Git’s
    versatility extends far beyond what we’ve outlined.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 Git 命令和术语为项目中的版本控制奠定了基础。尽管如此，Git 命令通常具有许多额外的参数和选项，允许对版本控制任务进行精细调整。虽然我们在这里介绍了一些基本命令，但需要注意的是，Git
    的灵活性远远超出了我们所概述的范围。
- en: For a more comprehensive list of Git commands and the diverse array of arguments
    they can accept, we recommend referring to the official [Git documentation](https://oreil.ly/kmUcc).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取更全面的 Git 命令列表及其多样的参数，请参阅官方的 [Git 文档](https://oreil.ly/kmUcc)。
- en: 'Now that you understand what Git and GitHub are and their role within the project,
    let’s establish a connection to GitHub. For that, you need to do the following:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您了解了 Git 和 GitHub 在项目中的角色及其作用，让我们建立到 GitHub 的连接。为此，您需要执行以下操作：
- en: Register for a GitHub account if you don’t already have one.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您还没有 GitHub 账户，请注册一个。
- en: Click New to create a new repository, which is where you will version your analytics
    code. On the “Create a new repository screen,” give your repository a name; then
    click “Create repository.”
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“新建”以创建一个新存储库，这是您将版本化您的分析代码的地方。在“创建新存储库”屏幕上，为您的存储库命名；然后单击“创建存储库”。
- en: With the repository created, let’s get back to dbt. In the Setup a Repository
    section, select GitHub and then connect the GitHub account.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建存储库后，让我们回到 dbt。在“设置存储库”部分，选择 GitHub，然后连接 GitHub 账户。
- en: Click Configure GitHub Integration to open a new window where you can select
    the location to install the dbt Cloud. Then choose the repository you want to
    install.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“配置 GitHub 集成”以打开一个新窗口，您可以选择安装 dbt Cloud 的位置。然后选择要安装的仓库。
- en: Now click “Start developing in the IDE.” [Figure 4-11](#dbt_ide) is what you
    should expect to see.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在点击“在 IDE 中开始开发”。[图 4-11](#dbt_ide)就是您应该看到的样子。
- en: '![dbt IDE](assets/aesd_0411.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![dbt IDE](assets/aesd_0411.png)'
- en: Figure 4-11\. dbt IDE
  id: totrans-156
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-11\. dbt IDE
- en: We will give an overview of the dbt Cloud Integrated Development Environment
    (IDE) in [“Using the dbt Cloud IDE”](#dbt_cloud_ide_chapter) and cover it in more
    detail in [“Structure of a dbt Project”](#structure_of_dbt_chapter).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[“使用 dbt Cloud IDE”](#dbt_cloud_ide_chapter)中概述 dbt Cloud 集成开发环境（IDE），并在[“dbt
    项目结构”](#structure_of_dbt_chapter)中详细介绍。
- en: Click “Initialize dbt project” on the top left. Now, you should be able to see
    the screen as it looks in [Figure 4-12](#dbt_ide_after_initialize).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 点击左上角的“初始化 dbt 项目”。现在，您应该能够看到屏幕的样子，就像[图 4-12](#dbt_ide_after_initialize)中显示的一样。
- en: '![dbt IDE After initialize project](assets/aesd_0412.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![初始化项目后的 dbt IDE](assets/aesd_0412.png)'
- en: Figure 4-12\. dbt after project initialization
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-12\. 项目初始化后的 dbt
- en: We will detail each folder and file in [“Structure of a dbt Project”](#structure_of_dbt_chapter).
    For now, let’s see if the queries work. Run them again by copying the [Example 4-2](#dbt_dataset_output_code)
    code and click Preview.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[“dbt 项目结构”](#structure_of_dbt_chapter)中详细描述每个文件夹和文件。现在，让我们看看查询是否有效。通过复制[示例 4-2](#dbt_dataset_output_code)的代码并点击预览来再次运行它们。
- en: Example 4-2\. dbt public datasets in BigQuery, dbt test
  id: totrans-162
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-2\. BigQuery 中的 dbt 公共数据集，dbt 测试
- en: '[PRE1]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If the output looks similar to [Figure 4-13](#dbt_dataset_output), that means
    your connection works. You can then submit queries to your data platform, which
    in our case is BigQuery.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果输出看起来类似于[图 4-13](#dbt_dataset_output)，那意味着您的连接正常。然后，您可以向您的数据平台提交查询，这在我们的情况下是
    BigQuery。
- en: Note
  id: totrans-165
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The steps provided here are part of the documentation for the BigQuery adapter
    in dbt. As technologies evolve and improve, these steps and configurations may
    also change. To ensure that you have the most up-to-date information, refer to
    the latest [dbt documentation for BigQuery](https://oreil.ly/og-M8). This resource
    will provide you with the most current guidance and instructions for working with
    dbt and BigQuery.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提供的步骤是 dbt 中 BigQuery 适配器文档的一部分。随着技术的发展和改进，这些步骤和配置也可能发生变化。为确保您拥有最新的信息，请参阅最新的[dbt
    BigQuery 文档](https://oreil.ly/og-M8)。这个资源将为您提供与 dbt 和 BigQuery 一起工作的最新指导和说明。
- en: '![dbt Output Bigquery Public dataset](assets/aesd_0413.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![BigQuery 公共数据集的 dbt 输出](assets/aesd_0413.png)'
- en: Figure 4-13\. dbt output of BigQuery public dataset
  id: totrans-168
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-13\. BigQuery 公共数据集的 dbt 输出
- en: Finally, let’s test whether your GitHub integration is working as expected by
    carrying out your first “Commit and push.” Click the button with the same description,
    visible in [Figure 4-14](#dbt_git_commit), at the left. A popup screen, the image
    to the right in [Figure 4-14](#dbt_git_commit), will appear where you can write
    your commit message. Click Commit Changes.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们测试您的 GitHub 集成是否按预期工作，通过进行您的第一次“提交和推送”。点击左侧具有相同描述的按钮，在[图 4-14](#dbt_git_commit)中可见。一个弹出屏幕，如[图 4-14](#dbt_git_commit)右侧的图像，将弹出，您可以在其中编写您的提交消息。点击“提交更改”。
- en: '![dbt Git Commit](assets/aesd_0414.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Git Commit](assets/aesd_0414.png)'
- en: Figure 4-14\. Commit and push to GitHub
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-14\. 提交和推送到 GitHub
- en: Since we didn’t create a Git branch, it will version our code inside the main
    branch. Go into the GitHub repository you made during this setup and see if your
    dbt project exists. [Figure 4-15](#dbt_git_repos) should be similar to what you
    see on your GitHub repository.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有创建 Git 分支，它将在主分支中版本化我们的代码。进入您在此设置期间创建的 GitHub 仓库，并查看您的 dbt 项目是否存在。[图 4-15](#dbt_git_repos)应该与您在
    GitHub 仓库上看到的类似。
- en: '![dbt Git Repos](assets/aesd_0415.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Git Repos](assets/aesd_0415.png)'
- en: Figure 4-15\. dbt GitHub repository, first commit check
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-15\. dbt GitHub 仓库，第一个提交检查
- en: Using the dbt Cloud UI
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 dbt Cloud UI
- en: When you sign in to dbt Cloud, the initial page displays a welcome message and
    a summary of your job’s execution history. As [Figure 4-16](#dbt_landing_page)
    shows, the page is empty at first but once we create and run our first jobs, we
    will start seeing information. In [“Jobs and Deployment”](#structure_of_dbt_chapter_jobs_deploy),
    we detail a job’s execution in more detail.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当您登录到dbt Cloud时，初始页面将显示欢迎消息和您作业执行历史的摘要。正如 [图4-16](#dbt_landing_page) 所示，初始页面是空的，但一旦我们创建并运行第一个作业，我们将开始看到信息。在
    [“作业和部署”](#structure_of_dbt_chapter_jobs_deploy) 中，我们将详细介绍作业的执行。
- en: '![dbt Landing page](assets/aesd_0416.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 登陆页面](assets/aesd_0416.png)'
- en: Figure 4-16\. dbt landing page
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-16\. dbt 登陆页面
- en: On the top bar, you will see several options. Starting from the left, you can
    access the Develop page, where you will develop all your analytics code and create
    your models, tests, and documentation. It is the core of dbt development, and
    we will give you more insights into this section in [“Using the dbt Cloud IDE”](#dbt_cloud_ide_chapter),
    and deep dive into each component in [“Structure of a dbt Project”](#structure_of_dbt_chapter).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部菜单栏，您会看到几个选项。从左边开始，您可以进入开发页面，在这里您将开发所有分析代码并创建模型、测试和文档。这是dbt开发的核心，我们将在 [“使用dbt
    Cloud IDE”](#dbt_cloud_ide_chapter) 中为您提供更多见解，并深入研究每个组件在 [“dbt项目结构”](#structure_of_dbt_chapter)
    中。
- en: Right next to the Develop option is the Deploy menu, as shown in [Figure 4-17](#dbt_deploy_menu).
    From this menu, you can configure jobs and monitor their execution via Run History,
    configure the development environments, and verify the source freshness of your
    snapshots via Data Sources.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 紧挨着开发选项的右侧是Deploy菜单，如 [图4-17](#dbt_deploy_menu) 所示。从这个菜单中，您可以配置作业并通过运行历史监视其执行情况，配置开发环境，并验证快照的源数据新鲜度。
- en: '![dbt Deploy menu](assets/aesd_0417.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Deploy 菜单](assets/aesd_0417.png)'
- en: Figure 4-17\. dbt Deploy menu
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-17\. dbt Deploy 菜单
- en: The Deploy menu’s first option is Run History, which opens the page shown in
    [Figure 4-18](#dbt_deploy_run_history). Here you can see your job’s run history.
    In the context of dbt, *jobs* are automated tasks or processes that you configure
    to perform specific actions, such as running models, tests, or generating documentation.
    These jobs are an integral part of orchestrating dbt, which involves managing
    and automating various data transformation and analytics tasks.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Deploy 菜单的第一个选项是运行历史，打开的页面显示在 [图4-18](#dbt_deploy_run_history) 中。在这里，您可以查看作业的运行历史。在dbt的上下文中，*作业*
    是您配置的自动化任务或流程，用于执行特定操作，如运行模型、测试或生成文档。这些作业是协调dbt的重要组成部分，涉及管理和自动化各种数据转换和分析任务。
- en: '![dbt Deploy Run History](assets/aesd_0418.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Deploy 运行历史](assets/aesd_0418.png)'
- en: Figure 4-18\. dbt Run History page
  id: totrans-185
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-18\. dbt 运行历史页面
- en: Suppose you have jobs configured that had executions already in this section.
    In that case, you can inspect each job’s invocation and status. A wealth of information
    is available in the job’s run history, including its status, duration, the environment
    in which the job executed, and other useful details. You can access information
    about the steps the job went through, including respective logs for each step.
    Additionally, you can find artifacts generated by the job, such as models, tests,
    or documentation.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您已经配置了在此部分中已执行的作业。在那种情况下，您可以检查每个作业的调用和状态。作业的运行历史提供了丰富的信息，包括其状态、持续时间、作业执行的环境以及其他有用的详细信息。您可以访问作业经历的步骤信息，包括每个步骤的日志。此外，您还可以找到作业生成的文档、模型或测试等生成物。
- en: The Deploy menu’s next option is Jobs. This opens a page for configuring all
    your automation, including CI/CD pipelines, run tests, and other exciting behaviors,
    without running dbt commands manually from the command line.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Deploy 菜单的下一个选项是作业。这将打开一个页面，用于配置所有自动化内容，包括CI/CD管道、运行测试和其他有趣的行为，而无需手动从命令行运行dbt命令。
- en: '[Figure 4-19](#dbt_jobs) shows the empty Jobs landing page. We have a whole
    section dedicated to Jobs in [“Jobs and Deployment”](#structure_of_dbt_chapter_jobs_deploy).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4-19](#dbt_jobs) 显示了空的作业登陆页面。我们在 [“作业和部署”](#structure_of_dbt_chapter_jobs_deploy)
    中有一个完整的作业部分。'
- en: '![dbt Jobs](assets/aesd_0419.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Jobs](assets/aesd_0419.png)'
- en: Figure 4-19\. dbt Jobs page
  id: totrans-190
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-19\. dbt 作业页面
- en: 'The third Deploy menu option is Environments. Inside dbt, we have two main
    types of environment: development and deployment. Out of the box, dbt configures
    the development environment for you, which is visible right after you set up your
    dbt project. [Figure 4-20](#dbt_deploy_environments) shows you the Environments
    landing page, which should be similar to yours if you followed the steps in [“Setting
    Up dbt Cloud with BigQuery and GitHub”](#setting_up_dbt_cloud).'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个部署菜单选项是环境。在 dbt 内部，我们有两种主要类型的环境：开发和部署。开箱即用，dbt 为您配置开发环境，这在您设置完 dbt 项目后就可以看到。[图 4-20](#dbt_deploy_environments)
    展示了环境的着陆页面，如果您按照[“使用 BigQuery 和 GitHub 设置 dbt Cloud”](#setting_up_dbt_cloud)中的步骤进行操作，您的页面应该与此类似。
- en: '![dbt Environments](assets/aesd_0420.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 环境](assets/aesd_0420.png)'
- en: Figure 4-20\. dbt Environments page
  id: totrans-193
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-20\. dbt 环境页面
- en: Finally, we have the Data Sources option. This page, shown in [Figure 4-21](#dbt_data_sources),
    is populated automatically by dbt Cloud once you configure a job to snapshot source-data
    freshness. Here you will see the state of the most recent snapshots, allowing
    you to analyze if your source data freshness is meeting the service-level agreements
    (SLAs) you’ve defined with your organization. We will give you a better idea of
    data freshness in [“Source freshness”](#source_freshness_subchap) and how to test
    it in [“Testing sources”](#testing_sources_freshness_subchap).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有数据源选项。这一页显示在 [图 4-21](#dbt_data_sources)，由 dbt Cloud 自动填充，一旦您配置了一个作业来快照源数据的新鲜度。在这里，您将看到最新快照的状态，可以分析您的源数据新鲜度是否符合您与组织定义的服务水平协议（SLAs）。我们将在[“源新鲜度”](#source_freshness_subchap)中为您提供有关数据新鲜度的更好理解，以及在[“测试数据源新鲜度”](#testing_sources_freshness_subchap)中如何进行测试。
- en: '![dbt Data Sources](assets/aesd_0421.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 数据源](assets/aesd_0421.png)'
- en: Figure 4-21\. dbt Data Sources page
  id: totrans-196
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-21\. dbt 数据源页面
- en: 'Next is the Documentation option, and as long as you and your team create routines
    to ensure that your dbt project is correctly documented, this step will have a
    particular level of significance. Proper documentation can answer questions like
    these:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是文档选项，只要您和您的团队创建了确保您的 dbt 项目正确文档化的常规，这一步将具有特定的重要性。适当的文档可以回答以下问题：
- en: What does this data mean?
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些数据意味着什么？
- en: Where does this data come from?
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些数据来自哪里？
- en: How are these metrics calculated?
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些指标是如何计算的？
- en: '[Figure 4-22](#dbt_documentation) shows the Documentation page for your project.
    We will explain how to leverage and write documentation inside your dbt project
    while writing your code in [“Documentation”](#structure_of_dbt_chapter_documentation).'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-22](#dbt_documentation) 展示了您项目的文档页面。我们将解释如何在编写代码的同时利用和编写您的 dbt 项目内的文档在[“文档”](#structure_of_dbt_chapter_documentation)章节。'
- en: '![dbt Data Sources](assets/aesd_0422.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 数据源](assets/aesd_0422.png)'
- en: Figure 4-22\. dbt Documentation page
  id: totrans-203
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-22\. dbt 文档页面
- en: The top-right menu allows you to select your dbt project ([Figure 4-23](#dbt_select_Account)).
    This short menu makes it simple to move around between dbt projects.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 右上角菜单允许您选择您的 dbt 项目（[图 4-23](#dbt_select_Account)）。这个简短的菜单使得在 dbt 项目之间移动变得简单。
- en: '![dbt Select Account menu](assets/aesd_0423.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 选择账户菜单](assets/aesd_0423.png)'
- en: Figure 4-23\. dbt Select Account menu
  id: totrans-206
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-23\. dbt 选择账户菜单
- en: The dbt Help menu ([Figure 4-24](#dbt_help_menu)) can be found by clicking the
    question mark symbol. Here you can speak directly with the dbt team through chat,
    provide feedback, and access dbt documentation. Finally, via the Help menu, you
    can join the Slack dbt community or GitHub dbt discussions.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: dbt 帮助菜单（[图 4-24](#dbt_help_menu)）可以通过点击问号符号找到。在这里，您可以直接与 dbt 团队通过聊天联系，提供反馈，并访问
    dbt 文档。最后，通过帮助菜单，您可以加入 Slack dbt 社区或 GitHub dbt 讨论。
- en: '![dbt Help menu](assets/aesd_0424.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 帮助菜单](assets/aesd_0424.png)'
- en: Figure 4-24\. dbt Help menu
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-24\. dbt 帮助菜单
- en: The Settings menu, [Figure 4-25](#dbt_settings_menu), is where you can configure
    everything related to your account, profile, or even notifications.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 设置菜单，[图 4-25](#dbt_settings_menu)，是您可以配置与您的帐户、配置文件甚至通知相关的一切内容的地方。
- en: '![dbt Settings menu](assets/aesd_0425.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 设置菜单](assets/aesd_0425.png)'
- en: Figure 4-25\. dbt Settings menu
  id: totrans-212
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-25\. dbt 设置菜单
- en: Once you click one of the three options, you will land on the Settings page,
    similar to [Figure 4-26](#dbt_settings_account). On the first page, Account Settings,
    you can edit and create new dbt projects, manage users and their access control
    level (if you are an owner), and manage the billing.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您点击三个选项中的任何一个，您将进入设置页面，类似于[图 4-26](#dbt_settings_account)。在第一个页面上，帐户设置中，您可以编辑和创建新的dbt项目，管理用户及其访问控制级别（如果您是所有者），以及管理计费。
- en: '![dbt Account Settings](assets/aesd_0426.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![dbt帐户设置](assets/aesd_0426.png)'
- en: Figure 4-26\. dbt Account Settings page
  id: totrans-215
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-26\. dbt帐户设置页面
- en: The second menu option, Profile Settings, accesses the Your Profile page ([Figure 4-27](#dbt_settings_profile)).
    On this page, you can review all your personal information and manage linked accounts,
    such as GitHub or GitLab, Slack, and single sign-on (SSO) tools. You can also
    review and edit the credentials you defined for your data platform and the API
    access key.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个菜单选项，配置文件设置，访问了您的个人资料页面（[图 4-27](#dbt_settings_profile)）。在这个页面上，您可以查看所有个人信息，并管理关联帐户，如GitHub或GitLab、Slack和单点登录（SSO）工具。您还可以查看和编辑为数据平台和API访问密钥定义的凭据。
- en: '![dbt Profile Settings](assets/aesd_0427.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![dbt配置文件设置](assets/aesd_0427.png)'
- en: Figure 4-27\. dbt Your Profile page
  id: totrans-218
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-27\. dbt个人资料页面
- en: Finally, the Notification Settings option accesses the Notifications center
    ([Figure 4-28](#dbt_settings_notification)), where you can configure alerts to
    be received in a chosen Slack channel or email when a job run succeeds, fails,
    or is canceled.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通知设置选项访问了通知中心（[图 4-28](#dbt_settings_notification)），在这里您可以配置在作业运行成功、失败或取消时在选择的Slack频道或电子邮件中接收到的警报。
- en: '![dbt Notification Settings](assets/aesd_0428.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![dbt通知设置](assets/aesd_0428.png)'
- en: Figure 4-28\. dbt Notifications center
  id: totrans-221
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-28\. dbt通知中心
- en: Using the dbt Cloud IDE
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用dbt Cloud IDE
- en: One of the essential parts of the dbt Cloud is the IDE, where all your analytics
    code can be written, along with tests and documentation. [Figure 4-29](#dbt_ide_with_legends)
    shows the main sections of the dbt IDE.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: dbt Cloud的重要部分之一是IDE，您可以在其中编写所有分析代码，包括测试和文档。[图 4-29](#dbt_ide_with_legends)显示了dbt
    IDE的主要部分。
- en: '![dbt IDE Legends](assets/aesd_0429.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![dbt IDE图例](assets/aesd_0429.png)'
- en: Figure 4-29\. dbt IDE—annotated
  id: totrans-225
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-29\. dbt IDE—注释
- en: 'Next, you can find a detailed explanation of what each section represents and
    its relevance inside the integrated development environment:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您可以找到每个部分代表的详细解释及其在集成开发环境中的重要性：
- en: Git controls and documentation
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Git控制和文档
- en: This menu is where you interact with Git. Here you can see what changed since
    your previous commit and what’s new. All Git commands in the IDE are here, and
    you can decide whether to commit and push or revert your code. Also, in the top
    right of this window, you can see the documentation icon. Once documentation is
    generated, you can click this shortcut to access your project documentation.
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个菜单是您与Git交互的地方。在这里，您可以查看自上次提交以来的更改以及新增内容。IDE中的所有Git命令都在这里，您可以决定是否提交和推送或还原您的代码。此外，在窗口右上角，您可以看到文档图标。一旦生成文档，您可以单击此快捷方式访问项目文档。
- en: File Explorer
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文件资源管理器
- en: The File Explorer gives you the main overview of your dbt project. Here you
    can check how your dbt project is built—generally in the form of *.sql*, *.yml*,
    and other compatible file types.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 文件资源管理器为您提供了dbt项目的主要概述。在这里，您可以检查您的dbt项目是如何构建的——通常是*.sql*、*.yml*和其他兼容的文件类型。
- en: Text editor
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本编辑器
- en: This section of the IDE is where your analytics code is written and becomes
    mature. Here you can also edit and create other relevant files for your project,
    such as the YAML files. If you select those files from File Explorer, they will
    pop up here. Multiple files can be opened simultaneously.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这部分IDE是您编写和成熟分析代码的地方。在这里，您还可以编辑和创建项目的其他相关文件，如YAML文件。如果您从文件资源管理器中选择这些文件，它们将在这里弹出。可以同时打开多个文件。
- en: Information window and code Preview, Compile, and Build
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 信息窗口和代码预览、编译和构建
- en: This menu will show your results once you click the Preview or Compile buttons.
    Preview will compile and run your query against your data platform and display
    the results in the Results tab at the bottom of your screen. On the other hand,
    Compile will convert any Jinja into pure SQL. This will be displayed in the information
    window in the Compiled Code tab at the bottom of your screen. Preview or Compile
    buttons apply to statements and SQL files.
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦单击“预览”或“编译”按钮，此菜单将显示您的结果。预览将编译并运行您的查询以及您的数据平台，并在屏幕底部的“结果”选项卡中显示结果。另一方面，“编译”将把任何
    Jinja 转换成纯 SQL。这将显示在屏幕底部的“编译代码”选项卡中的信息窗口中。预览或编译按钮适用于语句和 SQL 文件。
- en: Build is a special button that pops up only in specific files. Depending on
    what type of build you choose, the run results will include information about
    all models, tests, seeds, and snapshots that were selected to build, combined
    into one file.
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: “构建”是仅在特定文件中弹出的特殊按钮。根据您选择的构建类型，运行结果将包括有关所有模型、测试、种子和快照的信息，这些信息被合并到一个文件中。
- en: The information window is also helpful for troubleshooting errors during development
    or using the Lineage tab to check the data lineage of the model currently open
    in the text editor and its ancestors and dependencies.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 信息窗口在开发过程中排查错误或使用“谱系”选项卡来检查当前在文本编辑器中打开的模型及其祖先和依赖项的数据谱系也很有帮助。
- en: Command line
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 命令行
- en: The command line is where you can execute specific dbt commands such as `dbt
    run` or `dbt test`. During or after the execution of the command, it also displays
    a pop-up screen to show the results as they are processed—for that, click the
    arrow at the beginning of the command line. Logs can also be viewed here. [Figure 4-30](#dbt_ide_cli)
    shows the command line expanded; the command to be executed is at the top, and
    the log of the execution follows.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 命令行是您可以执行特定 dbt 命令（如 `dbt run` 或 `dbt test`）的地方。在命令执行期间或之后，它还会显示一个弹出屏幕，以显示正在处理的结果—为此，请单击命令行开头的箭头。日志也可以在这里查看。[图 4-30](#dbt_ide_cli)
    显示了扩展的命令行；要执行的命令位于顶部，并跟随执行的日志。
- en: '![ch02_IDE_command_line.PNG](assets/aesd_0430.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![ch02_IDE_command_line.PNG](assets/aesd_0430.png)'
- en: Figure 4-30\. dbt command line expanded
  id: totrans-240
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-30\. dbt 命令行扩展
- en: Structure of a dbt Project
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: dbt 项目的结构
- en: A dbt *project* is a directory composed of folders and files, programming patterns,
    and naming conventions. All your analytics code, tests, documentation, and parametrizations
    that will tell dbt how to operate will be in those files and folders. It will
    use those naming conventions and programming patterns. The way you organize your
    folders and file directory is your dbt project structure.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 dbt *项目* 是一个由文件夹和文件、编程模式和命名约定组成的目录。所有分析代码、测试、文档和参数化都将放置在这些文件和文件夹中。它将使用这些命名约定和编程模式。您如何组织文件夹和文件目录就是您的
    dbt 项目结构。
- en: Building a proper dbt project takes effort. To be well implemented, it needs
    to bring together the company domains and departments, leveraging their particular
    expertise to map the goals and needs of the whole company. As such, defining a
    set of conventions and patterns that are clear, comprehensive, and consistent
    is relevant. Accomplishing that will ensure that the project remains accessible
    and maintainable as your company scales, while using dbt to empower and benefit
    as many people as possible.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 建立一个合适的 dbt 项目需要付出努力。为了良好实施，它需要汇集公司的领域和部门，利用他们的专业知识来映射整个公司的目标和需求。因此，定义一套明确、全面和一致的惯例和模式是相关的。实现这一点将确保项目在公司扩展时保持可访问和可维护，同时利用
    dbt 来赋能和惠及尽可能多的人。
- en: How you organize your dbt project can vary and might be subject to changes defined
    by you or company guidelines. That’s not a problem. What’s important is that you
    explicitly declare those changes in a rigorous and accessible way for all contributors
    and, above all, stay consistent with it. For the sake of this book, we will keep
    the basic structure of the dbt project that you encounter once you initialize
    ([Example 4-3](#dbt_initial_folder_structure)).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 您如何组织您的 dbt 项目可能会有所不同，并可能受到您或公司指南定义的变化的影响。这并不是问题。重要的是，您要明确声明这些变化，并以一种严格和易于访问的方式为所有贡献者保持一致。出于本书的目的，我们将保持您初始化时遇到的
    dbt 项目的基本结构（[示例 4-3](#dbt_initial_folder_structure)）。
- en: Example 4-3\. Initial structure of a dbt project
  id: totrans-245
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-3\. dbt 项目的初始结构
- en: '[PRE2]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Each folder and file will be explained in the subsequent sections in this chapter
    and [Chapter 5](ch05.html#chapter_id_05). Some will have more emphasis and will
    be used more regularly than others. Yet, it is essential to have a broader idea
    of their purpose:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 每个文件夹和文件将在本章节和[第5章](ch05.html#chapter_id_05)中的后续部分详细解释。有些比其他更加重要和经常使用。然而，理解它们的目的是非常重要的：
- en: analyses folder
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 分析文件夹
- en: Detailed in [“Analyses”](#structure_of_dbt_chapter_analyses), this folder is
    commonly used to store queries for auditing purposes. For example, you may want
    to find discrepancies during logic migration from another system into dbt and
    still leverage the capabilities of dbt, such as the use of Jinja and version control,
    without including it in your built models inside your data platform.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“分析”](#structure_of_dbt_chapter_analyses)中详细介绍，这个文件夹通常用于存储审计目的的查询。例如，您可能希望在从其他系统迁移逻辑到dbt时查找不一致之处，并利用dbt的能力（如使用Jinja和版本控制），而无需将其包含在内置模型中。
- en: dbt_packages folder
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: dbt_packages文件夹
- en: Is where you will install your dbt packages. We will cover the concept of packages
    in [“dbt Packages”](ch05.html#dbt_packages). Still, the idea is that packages
    are standalone dbt projects that tackle specific problems and can be reused and
    shared across organizations. This promotes a DRY-er code since you aren’t implementing
    the same logic over and over.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在此处安装dbt包。我们将在[“dbt包”](ch05.html#dbt_packages)中详细介绍包的概念。总体来说，包是独立的dbt项目，解决特定问题，并可以在组织间共享和重用。这促进了更干净的代码，因为您不需要一遍又一遍地实现相同的逻辑。
- en: logs folder
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 日志文件夹
- en: Is where all your project logs will be written by default, unless you configure
    them differently in your *dbt_project.yml*.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，所有项目日志将写入此处，除非您在*dbt_project.yml*中进行了不同配置。
- en: macros folder
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 宏文件夹
- en: Is where your DRY-ing up transformations code will be stored. Macros, analogous
    to functions in other programming languages, are pieces of Jinja code that can
    be reused multiple times. We will devote an entire section in [“Using SQL Macros”](ch05.html#dbt_macros)
    to detailing them.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在此处存储DRY转换代码。宏，类似于其他编程语言中的函数，是可以多次重用的Jinja代码片段。我们将在[“使用SQL宏”](ch05.html#dbt_macros)中专门讨论它们。
- en: models folder
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 模型文件夹
- en: Is one of the mandatory folders in dbt. Generally speaking, a *model* is a SQL
    file that contains a `SELECT` statement with a modular piece of logic that will
    take your raw data and build it into the final transformed data. In dbt, the model’s
    name indicates the name of a future table or view, or neither if configured as
    an ephemeral model. This subject will be detailed in [“Models”](#structure_of_dbt_chapter_models).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: dbt中的强制文件夹之一。一般来说，*模型*是一个包含`SELECT`语句的SQL文件，其中包含将原始数据转换为最终转换数据的模块化逻辑。在dbt中，模型的名称表示将来的表或视图的名称，或者如果配置为临时模型，则表示不包含。此主题将在[“模型”](#structure_of_dbt_chapter_models)中详细说明。
- en: seeds folder
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 种子文件夹
- en: Is where our lookup tables will be stored. We will discuss this in [“Seeds”](#structure_of_dbt_chapter_seeds).
    The general idea is that seeds are CSV files that change infrequently, and are
    used for modeling data that doesn’t exist in any source system. Some helpful use
    cases could be mapping zip codes to states or a list of test emails we need to
    exclude from the analysis.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[“种子”](#structure_of_dbt_chapter_seeds)中讨论，这里是我们存储查找表的地方。总体思路是，种子是CSV文件，变化不频繁，用于建模源系统中不存在的数据。一些有用的用例可能是将邮政编码映射到州或需要从分析中排除的测试电子邮件列表。
- en: snapshots folder
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 快照文件夹
- en: Contains all snapshot models for your project, which must be separated from
    the models folder. The dbt snapshot feature records change to a mutable table
    over time. It applies the type 2 slowly changing dimension (SCDs), which identifies
    how a row in a table changes during the time. This is covered in detail in [“Snapshots”](ch05.html#models_materializations_chapter_snapshots).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 包含项目的所有快照模型，必须与模型文件夹分开。dbt快照功能记录了可变表格随时间的变化。它应用了类型2慢变化维度（SCD），用于标识表中行在时间内的变化。这在[“快照”](ch05.html#models_materializations_chapter_snapshots)中有详细介绍。
- en: target folder
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 目标文件夹
- en: Contains the compiled SQL files that will be written when you run the `dbt run`,
    `dbt compile`, or `dbt test` commands. You can optionally configure in *dbt_project.yml*
    to be written into another folder.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 包含编译后的SQL文件，当您运行`dbt run`、`dbt compile`或`dbt test`命令时将被写入。您可以选择在*dbt_project.yml*中配置写入到另一个文件夹。
- en: tests folder
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 测试文件夹
- en: Serves the purpose of testing multiple specific tables simultaneously. This
    will not be the solo folder where your tests will be written. A good number will
    still be under your model’s folder inside the YAML files, or through macros. Yet,
    the tests folder is more suited for singular tests, which report the results of
    how several specific models interact or relate to one another. We will cover this
    topic in depth in [“Tests”](#structure_of_dbt_chapter_tests).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 用于同时测试多个特定表的目的。这不会是您编写测试的唯一文件夹。大部分还是会在您模型文件夹内的 YAML 文件中，或通过宏。然而，测试文件夹更适合单独的测试，报告多个特定模型之间如何互动或相关的结果。我们将在
    [“测试”](#structure_of_dbt_chapter_tests) 章节深入讨论此主题。
- en: dbt_project.yml
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: dbt_project.yml
- en: Is the core of every dbt project. This is how dbt knows a directory is a dbt
    project, and it contains important information that tells dbt how to operate on
    your project. We will cover this file throughout the course of this book. It’s
    also covered in [“dbt_project.yml”](#dbt_project_yml).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 是每个 dbt 项目的核心。这是 dbt 知道一个目录是一个 dbt 项目的方式，并且它包含重要信息，告诉 dbt 如何在您的项目上操作。我们将在本书的整个过程中介绍这个文件。它也在
    [“dbt_project.yml”](#dbt_project_yml) 中有所涵盖。
- en: '*.gitignore* and README.md'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '*.gitignore* 和 README.md'
- en: Are files typically used for your Git projects. While *gitignore* specifies
    intentional files that Git should ignore during your commit and push, the *README*
    file is an essential guide that gives other developers a detailed description
    of your Git project.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这些文件通常用于您的 Git 项目。*gitignore* 指定了在提交和推送期间 Git 应该忽略的有意的文件，而 *README* 文件是一个重要的指南，为其他开发人员详细描述了您的
    Git 项目。
- en: We’ll cover these folders in more detail in this chapter and [Chapter 5](ch05.html#chapter_id_05)
    while going deeper into the dbt project and features.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章和 [第五章](ch05.html#chapter_id_05) 中更详细地介绍这些文件夹，深入探讨 dbt 项目和其特性。
- en: Jaffle Shop Database
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Jaffle 商店数据库
- en: In this book, we will give a set of practical examples of how to work with the
    components and features of dbt. In most cases, we will need to develop SQL queries
    to give you the best idea of what we want to show. So, it is essential to have
    a database that we can work with. That database is the Jaffle Shop.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将提供一组实际示例，展示如何使用 dbt 的组件和功能。在大多数情况下，我们将需要开发 SQL 查询，以便更好地向您展示我们想要展示的内容。因此，有一个我们可以操作的数据库是非常重要的。这个数据库就是
    Jaffle 商店。
- en: The *Jaffle Shop database* is a simple database composed of two tables, for
    customers and orders. To give more context, we will have a side database, from
    Stripe, with the payments connected with the orders. All three tables will be
    our raw data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '*Jaffle 商店数据库* 是一个由两个表组成的简单数据库，用于存储客户和订单。为了提供更多背景信息，我们将有一个来自 Stripe 的附加数据库，其中包含与订单相关联的支付。这三个表将是我们的原始数据。'
- en: The reason we use this database is that it is already publicly available, in
    BigQuery, by dbt Labs. It is one of the main databases used for their documentation
    and courses, so we hope it will simplify the overall learning curve of the dbt
    platform at this stage of the book.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个数据库的原因是它已经在 dbt Labs 的 BigQuery 中公开可用。它是他们文档和课程中主要使用的数据库之一，因此我们希望它能简化本书阶段
    dbt 平台的整体学习曲线。
- en: '[Figure 4-31](#js_er_diagram) shows you the ERD representing our raw data with
    customers, orders, and payments.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4-31](#js_er_diagram) 展示了我们的原始数据 ERD，显示了客户、订单和支付。'
- en: '![JS ER Diagram](assets/aesd_0431.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![JS ER Diagram](assets/aesd_0431.png)'
- en: 'Figure 4-31\. A Jaffle Shop raw data ERD, which we read as follows: single
    customer (1) can have multiple orders (N), and a single order (1) can have multiple
    processing payments (N)'
  id: totrans-277
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-31\. Jaffle 商店原始数据 ERD，我们如下阅读：单个客户（1）可以有多个订单（N），单个订单（1）可以有多个处理支付（N）
- en: YAML Files
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: YAML 文件
- en: '*YAML* is a human-readable data-serialization language commonly used for configuration
    files and in applications where data is being stored or transmitted. In dbt, YAML
    is used to define properties and some configurations of the components of your
    dbt project: models, snapshots, seeds, tests, sources, or even the actual dbt
    project, *dbt_project.yml*.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '*YAML* 是一种人类可读的数据序列化语言，通常用于配置文件和应用程序中存储或传输数据的地方。在 dbt 中，YAML 用于定义你的 dbt 项目的组件的属性和一些配置：模型、快照、种子、测试、源，甚至实际的
    dbt 项目，*dbt_project.yml*。'
- en: 'Apart from the top-level YAML files, such as *dbt_project.yml* and *packages.yml*,
    that need to be specifically named and in specific locations, the way you organize
    the other YAML files inside your dbt project is up to you. Remember that, as with
    other aspects of structuring your dbt project, the most important guidelines are
    to keep consistent, be clear on your intentions, and document how and why it is
    organized that way. It is important to balance centralization and file size to
    make specific configurations as easy to find as possible. Following are a set
    of recommendations on how to organize, structure, and name your YAML files:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 除了顶级的 YAML 文件，例如 *dbt_project.yml* 和 *packages.yml*，需要明确命名并放置在特定位置外，您组织 dbt
    项目中的其他 YAML 文件的方式由您决定。请记住，与组织 dbt 项目的其他方面一样，最重要的指导原则是保持一致性，明确您的意图，并记录组织的方式及其原因。重要的是要在集中性和文件大小之间取得平衡，以便尽可能地方便查找特定配置。以下是关于如何组织、结构化和命名您的
    YAML 文件的一套建议：
- en: As mentioned, balancing the configuration’s centralization and file size is
    particularly relevant. Having all configurations within a single file might make
    it challenging to find a specific one as your project scales (though you technically
    can use one file). Change management with Git will also be complicated because
    of the repetitive nature of the file.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如前所述，平衡配置的集中性和文件大小尤为重要。将所有配置放在单个文件中可能会使得随着项目规模的扩展变得更难找到特定的配置（尽管在技术上可以使用一个文件）。由于文件的重复性质，使用
    Git 进行变更管理也会变得复杂。
- en: As per the previous point, if we follow a config per folder approach, it is
    better to maintain all your configurations in the long run. In other words, in
    each model’s folder directory, it is recommended to have a YAML file that will
    facilitate the configurations of all the models in that directory. Extend this
    rule by separating the model’s configuration file, having a specific file for
    your sources configurations inside the same directory ([Example 4-4](#dbt_yml_files_directory_structure)).
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如前所述，如果我们采用每个文件夹的配置方法，在长期运行中，最好保持所有配置。换句话说，在每个模型的文件夹目录中，建议有一个 YAML 文件，以便简化该目录中所有模型的配置。通过在同一目录内部分离模型配置文件，扩展此规则，有一个特定文件用于您在同一目录内部的源配置（见
    [示例 4-4](#dbt_yml_files_directory_structure)）。
- en: In this structure, we’ve used the staging models to represent what’s being discussed,
    since it covers most cases, such as sources, YAML files. Here you can see the
    config per folder system, where source and model configurations are divided. It
    also introduces the Markdown files for documentation, which we will discuss in
    more detail in [“Documentation”](#structure_of_dbt_chapter_documentation). Finally,
    the underscore at the beginning puts all these files at the top of their respective
    directory so they are easier to find.
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这种结构中，我们使用了分期模型来代表所讨论的内容，因为它涵盖了大多数情况，比如源、YAML 文件。在这里，您可以看到每个文件夹系统的配置，其中源和模型配置被分开。它还介绍了文档的
    Markdown 文件，我们将在 [“文档”](#structure_of_dbt_chapter_documentation) 中更详细地讨论。最后，文件名开头的下划线将所有这些文件放置在各自目录的顶部，以便更容易找到。
- en: Example 4-4\. dbt YAML files in the model directory
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-4\. 模型目录中的 dbt YAML 文件
- en: '[PRE3]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: When using documentation blocks, also follow the same approach by creating one
    Markdown file (`.md`) per models directory. In [“Documentation”](#structure_of_dbt_chapter_documentation),
    we will get to know this type of file better.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当使用文档块时，也要按照相同的方法创建每个模型目录的一个 Markdown 文件（`.md`）。在 [“文档”](#structure_of_dbt_chapter_documentation)
    中，我们将更详细地了解这种类型的文件。
- en: It is recommended that you set up default configurations of your dbt project
    in your *dbt_project.yml* file at the directory level and use the cascading scope
    priority to define variations of these configurations. This can help you streamline
    your dbt project management and ensure that your configurations are consistent
    and easily maintainable. For example, leveraging [Example 4-4](#dbt_yml_files_directory_structure),
    imagine that all our staging models would be configured to be materialized as
    a view by default. That would be in your *dbt_project.yml*. But if you have a
    specific use case where you need to change the materialization configuration for
    your `jaffle_shop` staging models, you can do so by modifying the *_jaffle_shop_models.yml*
    file. This way, you can customize the materialization configuration for this specific
    set of models while keeping the rest of your project configurations unchanged.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 建议您在目录级别的*dbt_project.yml*文件中设置默认配置，使用级联的范围优先级来定义这些配置的变化。这可以帮助您简化dbt项目管理，确保您的配置一致且易于维护。例如，利用[示例 4-4](#dbt_yml_files_directory_structure)，想象一下我们所有的暂存模型默认配置为视图。这将在您的*dbt_project.yml*文件中进行配置。但是，如果您有特定的用例需要更改`jaffle_shop`暂存模型的物化配置，您可以通过修改*_jaffle_shop_models.yml*文件来实现。这样，您可以为这组特定模型定制物化配置，同时保持项目其余配置不变。
- en: The ability to override the default configurations for specific models is made
    possible by the cascading scope priority used in the dbt project build. While
    all staging models would be materialized as views because this is the default
    configuration, the staging `jaffle_shop` models would be materialized as tables
    because we overrode the default by updating the specific *_jaffle_shop_models.yml*
    YAML file.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 使用在dbt项目构建中使用的级联范围优先级，可以覆盖特定模型的默认配置。虽然所有暂存模型默认情况下都会作为视图物化，但暂存`jaffle_shop`模型将作为表物化，因为我们通过更新特定的*_jaffle_shop_models.yml*
    YAML文件来覆盖了默认设置。
- en: dbt_project.yml
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: dbt_project.yml
- en: One of the most critical files in dbt is *dbt_project.yml*. This file must be
    in the root of the project and it is the main configuration file for your project,
    containing pertinent information for dbt to properly operate.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在dbt中最关键的文件之一是*dbt_project.yml*。此文件必须位于项目的根目录，并且它是您的项目的主要配置文件，包含dbt正常运行所需的相关信息。
- en: The *dbt_project.yml* file also has some relevancy while writing your DRY-er
    analytics code. Generally speaking, your project default configurations will be
    stored here, and all objects will inherit from it unless overridden at the model
    level.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '*dbt_project.yml*文件在编写更加DRY的分析代码时也具有一定的相关性。一般来说，您的项目默认配置将存储在此处，并且所有对象都将从中继承，除非在模型级别进行覆盖。'
- en: 'Here are some of the most important fields that you will encounter in this
    file:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是您将在此文件中遇到的一些最重要的字段之一：
- en: name
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: name
- en: (Mandatory.) The name of the dbt project. We recommend changing this configuration
    to your project name. Also, remember to change it in the model’s section and the
    *dbt_project.yml* file. In our case, we name it *dbt_analytics_engineer_book*.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: (必须)。dbt项目的名称。我们建议将此配置更改为您的项目名称。还要记得在模型部分和*dbt_project.yml*文件中做出相应更改。在我们的案例中，我们将其命名为*dbt_analytics_engineer_book*。
- en: version
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: version
- en: (Mandatory.) Core version of your project. Different from *dbt version*.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: (必须)。项目的核心版本。与*dbt version*不同。
- en: config-version
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: config-version
- en: (Mandatory.) Version 2 is the currently available version.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: (必须)。版本2是目前可用的版本。
- en: profile
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: profile
- en: (Mandatory.) Profile within dbt is used to connect to your data platform.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: (必须)。在dbt中，配置文件用于连接到您的数据平台。
- en: '[folder]-paths'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '[folder]-paths'
- en: (Optional.) Where [folder] is the list of folders in the dbt project. It can
    be a model, seed, test, analysis, macro, snapshot, log, etc. For example, the
    *model-paths* will state the directory of your models and sources. The *macro-paths*
    is where your macros code lives, and so on.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: (可选)。其中[folder]是dbt项目中的文件夹列表。它可以是模型、种子、测试、分析、宏、快照、日志等。例如，*model-paths*将说明您的模型和源文件的目录。*macro-paths*是您的宏代码所在位置，依此类推。
- en: target-path
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: target-path
- en: (Optional.) This path will store the compiled SQL file.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: (可选)。此路径将存储编译后的SQL文件。
- en: clean-targets
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: clean-targets
- en: (Optional.) List of directories containing artifacts to be removed by the `dbt
    clean` command.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: (可选)。包含通过`dbt clean`命令要删除的工件的目录列表。
- en: models
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: models
- en: (Optional.) Default configuration of the models. In [Example 4-5](#dbt_project_yml_model),
    we want all models inside the staging folder to be materialized as views.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: （可选。）模型的默认配置。在 [Example 4-5](#dbt_project_yml_model) 中，我们希望将 staging 文件夹中的所有模型物化为视图。
- en: Example 4-5\. dbt_project.yml, model configuration
  id: totrans-309
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 4-5\. dbt_project.yml，模型配置
- en: '[PRE4]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: packages.yml
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: packages.yml
- en: '*Packages* are standalone dbt projects that tackle specific problems and can
    be reused and shared across organizations. They are projects with models and macros;
    by adding them to your project, those models and macros will become part of it.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '*Packages* 是独立的 dbt 项目，解决特定问题并可以在组织之间重用和共享。它们是包含模型和宏的项目；通过将它们添加到你的项目中，这些模型和宏将成为其一部分。'
- en: 'To access those packages, you first need to define them in the *packages.yml*
    file. The detailed steps are as follows:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问这些包，你首先需要在 *packages.yml* 文件中定义它们。详细步骤如下：
- en: You must ensure that the *packages.yml* file is in your dbt project. If not,
    please create it at the same level as your *dbt_project.yml* file.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你必须确保 *packages.yml* 文件位于你的 dbt 项目中。如果没有，请在与 *dbt_project.yml* 文件相同的级别创建它。
- en: Inside the dbt *packages.yml* file, define the packages you want to have available
    for use inside your dbt project. You can install packages from sources like the
    [dbt Hub](https://hub.getdbt.com); Git repositories, such as GitHub or GitLab;
    or even packages you have stored locally. [Example 4-6](#dbt_packages_yml) shows
    you the syntax required for each of these scenarios.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *packages.yml* 文件中定义你希望在 dbt 项目中可用的包。你可以从 [dbt Hub](https://hub.getdbt.com)、GitHub
    或 GitLab 等源安装包，甚至是本地存储的包。[Example 4-6](#dbt_packages_yml) 展示了每种情况所需的语法。
- en: Run `dbt deps` to install the defined packages. Unless you configure differently,
    by default those packages get installed in the *dbt_packages* directory.
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `dbt deps` 命令来安装定义的包。除非你进行了不同的配置，否则默认情况下这些包会安装在 *dbt_packages* 目录中。
- en: Example 4-6\. Syntax to install packages from the dbt hub, Git, or locally
  id: totrans-317
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 4-6\. 从 dbt hub、Git 或本地安装包的语法
- en: '[PRE5]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: profiles.yml
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: profiles.yml
- en: If you decide to use the dbt CLI and run your dbt project locally, you will
    need to set up a *profiles.yml*, which is not needed if you use dbt Cloud. This
    file contains the database connection that dbt will use to connect to the data
    platform. Because of its sensitive content, this file lives outside the project
    to avoid credentials being versioned into your code repository. You can safely
    use code versioning if your credentials are stored under environment variables.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你决定使用 dbt CLI 并在本地运行 dbt 项目，则需要设置 *profiles.yml*，但如果使用 dbt Cloud 则不需要。此文件包含了
    dbt 将用于连接数据平台的数据库连接信息。由于其敏感内容，此文件保存在项目之外，以避免将凭据版本化到代码库中。如果你的凭据存储在环境变量下，你可以安全地使用代码版本控制。
- en: Once you invoke dbt from your local environment, dbt parses your *dbt_project.yml*
    file and gets the profile name, which dbt needs to connect to your data platform.
    You can have multiple profiles as needed, yet it is common to have one profile
    per dbt project or per data platform. even using dbt Cloud for this book, and
    the profiles configuration not being necessary. We’re showing a sample of the
    *profiles.yml* if you are curious or prefer to use dbt CLI with BigQuery.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在本地环境中调用 dbt 时，dbt 会解析你的 *dbt_project.yml* 文件并获取配置文件名，这是 dbt 连接到你的数据平台所需的。根据需要，你可以拥有多个配置文件，但通常每个
    dbt 项目或数据平台都有一个配置文件。即使在本书中使用 dbt Cloud，并且不需要配置文件。我们展示了一个 *profiles.yml* 的示例，如果你好奇或者更喜欢使用
    dbt CLI 连接 BigQuery。
- en: The typical YAML schema file for *profiles.yml* is shown in [Example 4-7](#dbt_profiles_yml).
    We are using dbt Cloud for this book, meaning the profiles configuration is not
    necessary. However, we’re showing a sample of *profiles.yml* if you are curious
    or prefer to use the dbt CLI with BigQuery.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '*profiles.yml* 的典型 YAML 模式文件如 [Example 4-7](#dbt_profiles_yml) 所示。我们在本书中使用
    dbt Cloud，这意味着不需要配置文件。然而，我们展示了一个 *profiles.yml* 的示例，如果你好奇或者更喜欢使用 dbt CLI 连接 BigQuery。'
- en: Example 4-7\. profiles.yml
  id: totrans-323
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 4-7\. profiles.yml
- en: '[PRE6]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The most common structure of *profiles.yaml* has the following components:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '*profiles.yaml* 的最常见结构包含以下组件：'
- en: profile_name
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: profile_name
- en: The profile’s name must be equal to the name found in your *dbt_project.yml*.
    In our case, we’ve named it `dbt_analytics_engineer_book`.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件的名称必须与 *dbt_project.yml* 中找到的名称相同。在我们的情况下，我们将其命名为 `dbt_analytics_engineer_book`。
- en: target
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: target
- en: This is how you have different configurations for different environments. For
    instance, you would want separate datasets/databases to work on when developing
    locally. But when deploying to production, it is best to have all tables in a
    single dataset/database. By default, the target is set up to be `dev`.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在不同环境中拥有不同配置的方法。例如，当在本地开发时，您可能希望使用单独的数据集/数据库进行工作。但是在部署到生产环境时，最好将所有表放在单个数据集/数据库中。默认情况下，目标设置为`dev`。
- en: type
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 类型
- en: 'The type of data platform you want to connect: BigQuery, Snowflake, Redshift,
    among others.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 您希望连接的数据平台类型：BigQuery、Snowflake、Redshift 等。
- en: database-specific connection details
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 特定于数据库的连接细节
- en: '[Example 4-7](#dbt_profiles_yml) includes attributes like `method`, `project`,
    `dataset`, and `keyfile` that are required to set up a connection to BigQuery,
    using this approach.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 4-7](#dbt_profiles_yml) 包括属性，如`method`、`project`、`dataset` 和 `keyfile`，这些属性在使用这种方法连接到
    BigQuery 时是必需的。'
- en: threads
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 线程
- en: 'Number of threads the dbt project will run on. It creates a DAG of links between
    models. The number of threads represents the maximum number of paths through the
    graph that dbt may work in parallel. For example, if you specify `threads: 1`,
    dbt will start building only one resource (models, tests, etc.) and finish it
    before moving on to the next. On the other hand, if you have `threads: 4`, dbt
    will work on up to four models at once without violating dependencies.'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 'dbt 项目将运行的线程数。它创建了模型之间的链接DAG。线程数代表 dbt 可以并行处理的图中路径的最大数量。例如，如果指定 `threads: 1`，dbt
    将仅开始构建一个资源（模型、测试等），并在继续下一个之前完成它。另一方面，如果设置为 `threads: 4`，dbt 将同时处理多达四个模型，而不会违反依赖关系。'
- en: Note
  id: totrans-336
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The overall idea of the *profiles.yml* file is presented here. We will not go
    further than this nor give a detailed setup guide on configuring your dbt local
    project with BigQuery. Most of the tasks were already described, such as keyfile
    generation in [“Setting Up dbt Cloud with BigQuery and GitHub”](#setting_up_dbt_cloud),
    but there might be some nuances. If you want to learn more, dbt provides a [comprehensive
    guide](https://oreil.ly/BeMDc).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '*profiles.yml* 文件的整体概念在这里介绍。我们不会进一步介绍，也不会提供有关如何配置您的 dbt 本地项目与 BigQuery 的详细设置指南。大部分任务已经描述过，比如在[“使用
    BigQuery 和 GitHub 设置 dbt 云”](#setting_up_dbt_cloud) 中生成 keyfile，但可能还有一些细微差别。如果您想了解更多信息，dbt
    提供了[全面的指南](https://oreil.ly/BeMDc)。'
- en: Models
  id: totrans-338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: '*Models* are where you, as a data specialist, will spend most of your time
    inside the dbt ecosystem. They are typically written as `select` statements, saved
    as *.sql*, and are one of the most important pieces in dbt that will help you
    transform your data inside your data platform.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型* 是您作为数据专家将在 dbt 生态系统内花费大部分时间的地方。它们通常以 `select` 语句的形式编写，保存为 *.sql* 文件，并且是帮助您在数据平台内转换数据的
    dbt 中最重要的组成部分之一。'
- en: To properly build your models and create a clear and consistent project structure,
    you need to be comfortable with the data modeling concept and techniques. This
    is core knowledge if your goal is to become an analytics engineer or, generically
    speaking, someone who wants to work with data.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 要正确构建您的模型并创建清晰一致的项目结构，您需要熟悉数据建模的概念和技术。如果您的目标是成为分析工程师或者说是希望与数据一起工作的人，这是核心知识。
- en: As we saw in [Chapter 2](ch02.html#chapter_id_02), *data modeling* is the process
    that, by analyzing and defining the data requirements, creates data models that
    support the business processes in your organization. It shapes your source data,
    the data your company collects and produces, into transformed data, answering
    the data needs of your company domains and departments and generating added value.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第 2 章](ch02.html#chapter_id_02)中所看到的，*数据建模* 是通过分析和定义数据需求来创建支持组织业务流程的数据模型的过程。它塑造了您的源数据，即公司收集和生成的数据，将其转换为变换后的数据，以满足公司领域和部门的数据需求，并产生附加值。
- en: In line with data modeling, and also as introduced in [Chapter 2](ch02.html#chapter_id_02),
    modularity is another concept that is vital to properly structuring your dbt project
    and organizing your models while keeping your code DRY-er. Conceptually speaking,
    *modularity* is the process of decomposing a problem into a set of modules that
    can be separated and recombined, which reduces the overall complexity of the system,
    often with the benefit of flexibility and variety of use. In analytics, this is
    no different. While building a data product, we don’t write the code all at once.
    Instead, we make it piece by piece until we reach the final data artifacts.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循数据建模的原则，正如在[第2章](ch02.html#chapter_id_02)中介绍的，模块化是另一个对正确构建您的dbt项目和组织模型至关重要的概念。从概念上讲，*模块化*
    是将问题分解为一组可以分离和重组的模块的过程，这降低了系统的整体复杂性，并常常带来灵活性和多样性的好处。在分析学中，情况也是如此。在构建数据产品时，我们不会一次性编写所有代码，而是逐步完成直到最终数据产品。
- en: 'Since we will try to have modularity present from the beginning, our initial
    models will also be built with modularity in mind and in accordance with what
    we’ve discussed in [Chapter 2](ch02.html#chapter_id_02). Following a typical dbt
    data transformation flow, there will be three layers in our model’s directory:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将从一开始就采用模块化方法，我们的初始模型也将考虑到模块化，并根据我们在[第2章](ch02.html#chapter_id_02)中讨论过的内容进行构建。遵循典型的dbt数据转换流程，我们模型目录中将有三层：
- en: Staging layer
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '**Staging layer**'
- en: Our initial modular building blocks are within the staging layer of our dbt
    project. In this layer, we establish an interface with our source systems, similar
    to how an API interacts with external data sources. Here, data is reordered, cleaned
    up, and prepared for downstream processing. This includes tasks like data standardization
    and minor transformations that set the stage for more advanced data processing
    further downstream.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的初始模块化构建块位于我们的dbt项目的中间层（staging layer）内。在这一层，我们与源系统建立接口，类似于API与外部数据源的交互方式。在这里，数据被重新排序、清理并准备进行下游处理。这包括数据标准化和轻微转换的任务，为进一步的高级数据处理奠定基础。
- en: Intermediate layer
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '**Intermediate layer**'
- en: This layer consists of models between the staging layer and the marts layer.
    These models are built on top of our staging models and are used to conduct extensive
    data transformations, as well as data consolidation from multiple sources, which
    creates varied intermediate tables that will serve distinct purposes.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 此层包含介于中间层和数据仓库层之间的模型。这些模型是在我们的中间层模型基础上构建的，用于进行广泛的数据转换以及来自多个来源的数据整合，从而创建多样化的中间表，这些表将服务于不同的目的。
- en: Marts layer
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '**Marts layer**'
- en: Depending on your data modeling technique, marts bring together all modular
    pieces to give a broader vision of the entities your company cares about. If,
    for example, we choose a dimensional modeling technique, the marts layer contains
    your fact and dimension tables. In this context, *facts* are occurrences that
    keep happening over time, such as orders, page clicks, or inventory changes, with
    their respective measures. *Dimensions* are attributes, such as customers, products,
    and geography, that can describe those facts. *Marts* can be described as subsets
    of data inside your data platform that are oriented to specific domains or departments,
    such as finance, marketing, logistics, customer service, etc. It can also be a
    good practice to have a mart called “core,” for example, that isn’t oriented to
    a specific domain but is instead the core business facts and dimensions.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的数据建模技术，数据仓库中的中间层（staging layer）将所有模块化的部分汇集在一起，以更广泛地展示公司关心的实体。例如，如果我们选择维度建模技术，数据仓库中的中间层包含事实表和维度表。在这个上下文中，*事实*
    是随时间持续发生的事件，如订单、页面点击或库存变化，其相应的度量。*维度* 是描述这些事实的属性，如客户、产品和地理位置。*数据仓库（marts）* 可以被描述为数据平台内部特定领域或部门的子集，如财务、市场营销、物流、客户服务等。也可以养成一个名为“核心”的仓库，它不针对特定领域，而是核心业务事实和维度的集合。
- en: With the introductions made, let’s now build our first models, initially only
    on our staging layer. Create a new folder inside your models folder, named *staging*,
    and the respective folders per source, *jaffle_shop* and *stripe*, inside the
    *staging* folder. Then create the necessary SQL files, one for *stg_stripe_order_payments.sql*
    ([Example 4-8](#stg_stripe_order_payments_code)), another for *stg_jaffle_shop_customers.sql*
    ([Example 4-9](#stg_jaffle_shop_customers_code)), and finally one for *stg_jaffle_shop_orders.sql*
    ([Example 4-10](#stg_jaffle_shop_orders_code)). In the end, delete the example
    folder inside your models. It is unnecessary, so it would create unneeded visual
    noise while coding. The folder structure should be similar to [Example 4-11](#dbt_yml_files_directory_staging_structure).
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: With the introductions made, let’s now build our first models, initially only
    on our staging layer. Create a new folder inside your models folder, named *staging*,
    and the respective folders per source, *jaffle_shop* and *stripe*, inside the
    *staging* folder. Then create the necessary SQL files, one for *stg_stripe_order_payments.sql*
    ([示例 4-8](#stg_stripe_order_payments_code)), another for *stg_jaffle_shop_customers.sql*
    ([示例 4-9](#stg_jaffle_shop_customers_code)), and finally one for *stg_jaffle_shop_orders.sql*
    ([示例 4-10](#stg_jaffle_shop_orders_code)). In the end, delete the example folder
    inside your models. It is unnecessary, so it would create unneeded visual noise
    while coding. The folder structure should be similar to [示例 4-11](#dbt_yml_files_directory_staging_structure).
- en: Example 4-8\. stg_stripe_order_payments.sql
  id: totrans-351
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-8\. stg_stripe_order_payments.sql
- en: '[PRE7]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Example 4-9\. stg_jaffle_shop_customers.sql
  id: totrans-353
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-9\. stg_jaffle_shop_customers.sql
- en: '[PRE8]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Example 4-10\. stg_jaffle_shop_orders.sql
  id: totrans-355
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-10\. stg_jaffle_shop_orders.sql
- en: '[PRE9]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Example 4-11\. Staging models’ folder structure
  id: totrans-357
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-11\. Staging models’ 文件夹结构
- en: '[PRE10]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now let’s execute and validate what we did. Typically, typing `dbt run` in your
    command line is enough, but at BigQuery, you may need to type **`dbt run --full-refresh`**.
    After, look at your logs by using the arrow to the left of your command line.
    The logs should look similar to [Figure 4-32](#dbt_system_logs).
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: Now let’s execute and validate what we did. Typically, typing `dbt run` in your
    command line is enough, but at BigQuery, you may need to type **`dbt run --full-refresh`**.
    After, look at your logs by using the arrow to the left of your command line.
    The logs should look similar to [图 4-32](#dbt_system_logs).
- en: '![dbt System logs](assets/aesd_0432.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 系统日志](assets/aesd_0432.png)'
- en: Figure 4-32\. dbt system logs
  id: totrans-361
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-32\. dbt 系统日志
- en: Tip
  id: totrans-362
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Tip
- en: Your logs should also give you a good idea of the issue if something goes wrong.
    In [Figure 4-32](#dbt_system_logs), we present a logs summary, but you can also
    check the detailed logs for more verbosity.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: Your logs should also give you a good idea of the issue if something goes wrong.
    In [图 4-32](#dbt_system_logs), we present a logs summary, but you can also check
    the detailed logs for more verbosity.
- en: Expecting that you have received the “Completed successfully” message, let’s
    now take a look at BigQuery, where you should see all three models materialized,
    as [Figure 4-33](#dbt_models_bigquery) shows.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: Expecting that you have received the “Completed successfully” message, let’s
    now take a look at BigQuery, where you should see all three models materialized,
    as [图 4-33](#dbt_models_bigquery) shows.
- en: '![dbt Models BigQuery](assets/aesd_0433.png)'
  id: totrans-365
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Models BigQuery](assets/aesd_0433.png)'
- en: Figure 4-33\. dbt BigQuery models
  id: totrans-366
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-33\. dbt BigQuery 模型
- en: By default, dbt materializes your models inside your data platform as views.
    Still, you can easily configure this in the configuration block at the top of
    the model file ([Example 4-12](#dbt_materialization_config_model_file)).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: By default, dbt materializes your models inside your data platform as views.
    Still, you can easily configure this in the configuration block at the top of
    the model file ([示例 4-12](#dbt_materialization_config_model_file)).
- en: Example 4-12\. Materialization config inside the model file
  id: totrans-368
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-12\. 模型文件中的材化配置
- en: '[PRE11]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now that we have created our first models, let’s move to the next steps. Rearrange
    the code using the YAML files, and follow the best practices recommended in [“YAML
    Files”](#structure_of_dbt_chapter_yaml). Let’s take the code block from there
    and configure our materializations inside our YAML files ([Example 4-12](#dbt_materialization_config_model_file)).
    The first file we will change is *dbt_project.yml*. This should be the core YAML
    file for default configurations. As such, let’s change the model’s configuration
    inside with the code presented in [Example 4-13](#dbt_project_yml_staging_model_configs)
    and then execute **`dbt run`** again.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: Now that we have created our first models, let’s move to the next steps. Rearrange
    the code using the YAML files, and follow the best practices recommended in [“YAML
    Files”](#structure_of_dbt_chapter_yaml). Let’s take the code block from there
    and configure our materializations inside our YAML files ([示例 4-12](#dbt_materialization_config_model_file)).
    The first file we will change is *dbt_project.yml*. This should be the core YAML
    file for default configurations. As such, let’s change the model’s configuration
    inside with the code presented in [示例 4-13](#dbt_project_yml_staging_model_configs)
    and then execute **`dbt run`** again.
- en: Example 4-13\. Materialize models as views and as tables
  id: totrans-371
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-13\. 将模型材化为视图和表
- en: '[PRE12]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-373
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Note
- en: The + prefix is a dbt syntax enhancement, introduced with dbt v0.17.0, designed
    to clarify resource paths and configurations within *dbt_project.yml* files.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 前缀 + 是 dbt 语法增强功能，引入于 dbt v0.17.0，旨在澄清 *dbt_project.yml* 文件中的资源路径和配置。
- en: Since [Example 4-13](#dbt_project_yml_staging_model_configs) forced all staging
    Stripe models to be materialized as a table, BigQuery should look like [Figure 4-34](#dbt_models_bigquery_materialized_table).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 自 [Example 4-13](#dbt_project_yml_staging_model_configs) 强制所有暂存 Stripe 模型作为表格材料化后，BigQuery
    应该看起来像 [Figure 4-34](#dbt_models_bigquery_materialized_table)。
- en: '![dbt Models BigQuery materialized table](assets/aesd_0434.png)'
  id: totrans-376
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Models BigQuery 材料化表格](assets/aesd_0434.png)'
- en: Figure 4-34\. dbt BigQuery models with materialized table
  id: totrans-377
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-34\. dbt BigQuery 模型与材料化表格
- en: '[Example 4-13](#dbt_project_yml_staging_model_configs) shows how to configure,
    per folder, the specific desired materializations inside *dbt_project.yml*. Your
    staging models will be kept by default as views, so overriding this configuration
    can be done at the model’s folder level, leveraging the cascading scope priority
    on the project build. First, let’s change our *dbt_project.yml* to set all staging
    models to be materialized as views, as [Example 4-14](#dbt_project_yml_staging_model_configs_2)
    shows.'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '[Example 4-13](#dbt_project_yml_staging_model_configs) 显示了如何在 *dbt_project.yml*
    中配置每个文件夹内特定的期望材料化方式。您的暂存模型默认将保留为视图，因此可以在模型文件夹级别覆盖此配置，利用项目构建中的级联作用域优先级。首先，让我们修改我们的
    *dbt_project.yml*，将所有暂存模型设置为视图，如 [Example 4-14](#dbt_project_yml_staging_model_configs_2)
    所示。'
- en: Example 4-14\. Staging models to be materialized as views
  id: totrans-379
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 4-14\. 将暂存模型材料化为视图
- en: '[PRE13]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now let’s create the separate YAML file for `stg_jaffle_shop_customers`, stating
    that it needs to be materialized as a table. For that, create the respective YAML
    file, with the name *_jaffle_shop_models.yml*, inside the *staging/jaffle_shop*
    directory and copy the code in [Example 4-15](#stg_jaffle_shop_customers_yml).
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们为 `stg_jaffle_shop_customers` 创建单独的 YAML 文件，声明其需要被材料化为表格。为此，在 *staging/jaffle_shop*
    目录内创建名为 *_jaffle_shop_models.yml* 的 YAML 文件，并复制 [Example 4-15](#stg_jaffle_shop_customers_yml)
    中的代码。
- en: Example 4-15\. Defining that the model will be materialized as a table
  id: totrans-382
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 4-15\. 定义模型将被材料化为表格
- en: '[PRE14]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: After you rerun dbt, take a look at BigQuery. It should be similar to [Figure 4-35](#dbt_models_bigquery_materialized_table_v2).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在重新运行 dbt 后，查看 BigQuery。它应该类似于 [Figure 4-35](#dbt_models_bigquery_materialized_table_v2)。
- en: '![dbt Models BigQuery materialized table v2](assets/aesd_0435.png)'
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Models BigQuery 材料化表格 v2](assets/aesd_0435.png)'
- en: Figure 4-35\. dbt BigQuery customers model materialized into a table
  id: totrans-386
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-35\. dbt BigQuery 客户模型材料化为表格
- en: This is a simple example of using the YAML files, playing with table materializations,
    and seeing what the cascading scope priority means in practice. There is still
    a lot to do and see, and some of what we’re discussing will have even more applicability
    as we move onward. For now, we would just ask you to change your model inside
    *_jaffle_shop_models.yml* to be materialized as a view. This will be your default
    configuration.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用 YAML 文件的简单示例，玩弄表格材料化，并看到级联作用域优先级在实践中的意义。还有很多要做和看到的内容，我们讨论的一些内容随着我们的前进将会有更多的适用性。目前，我们只需请您更改
    *_jaffle_shop_models.yml* 中的模型，将其材料化为视图。这将是您的默认配置。
- en: Hopefully, at this stage, you’ve developed your first models and understand
    roughly the overall purpose of the YAML files and the cascading scope priority.
    The following steps will be to create our intermediate and mart models while learning
    about `ref()` functions. This will be our first use of Jinja, which we will cover
    in more detail in [“Dynamic SQL with Jinja”](ch05.html#dynamic_sql_with_jinja).
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 希望在这个阶段，您已经开发了您的第一个模型，并大致了解了 YAML 文件的总体目的和级联作用域优先级。接下来的步骤将是创建我们的中间和 Mart 模型，同时学习
    `ref()` 函数。这将是我们首次使用 Jinja，我们将在 [“使用 Jinja 进行动态 SQL”](ch05.html#dynamic_sql_with_jinja)
    中详细讨论它。
- en: 'First things first: our use case. With our models inside our staging area,
    we need to know what we want to do with them. As we mentioned at the start of
    this section, you need to define the data requirements that support the business
    processes in your organization. As a business user, multiple streams can be taken
    from our data. One of them, which will be our use case, is to analyze our orders
    per customer, presenting the total amount paid per successful order and the total
    amount per successful order type (cash and credit).'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要明确我们的用例。在我们的模型位于我们的暂存区内时，我们需要知道我们想要做什么。正如我们在本节开头提到的，您需要定义支持组织业务流程的数据需求。作为业务用户，我们的数据可以从多个流中获取。其中之一，将成为我们的用例，是分析我们的每个客户订单，显示每个成功订单的总付款金额以及每个成功订单类型（现金和信用卡）的总金额。
- en: Since we have some transformations here that require a granularity change from
    payment type level to order grain, it justifies isolating this complex operation
    before we reach the marts layer. This is where the intermediate layer lands. In
    your models folder, create a new folder named *intermediate*. Inside, create a
    new SQL file named *int_payment_type_amount_per_order.sql* and copy the code in
    [Example 4-16](#int_payment_type_amount_per_order).
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在此处有一些转换，需要从付款类型级别改变到订单粒度，这正好解释了为什么在我们到达数据集市层之前需要隔离这个复杂操作。这就是中间层的落地点。在您的模型文件夹中，创建一个名为*intermediate*的新文件夹。在里面，创建一个名为*int_payment_type_amount_per_order.sql*的新SQL文件，并复制[Example 4-16](#int_payment_type_amount_per_order)中的代码。
- en: Example 4-16\. int_payment_type_amount_per_order.sql
  id: totrans-391
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-16\. int_payment_type_amount_per_order.sql
- en: '[PRE15]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As you can see while creating the `order_payments` CTE, we gather the data
    from `stg_stripe_order_payments` by using the `ref()` function. This function
    references the upstream tables and views that were building your data platform.
    We’ll use this function as a standard while we implement our analytics code due
    to the benefits, such as:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在创建`order_payments` CTE时可以看到，我们使用`ref()`函数从`stg_stripe_order_payments`中收集数据。此函数引用了构建您数据平台的上游表和视图。由于其带来的好处，如在我们实施分析代码时，我们将使用此函数作为标准：
- en: It allows you to build dependencies among models in a flexible way that can
    be shared in a common codebase since it compiles the name of the database object
    during the `dbt run`, gathering it from the environment configuration when you
    create the project. This means that in your environment, the code will be compiled
    considering your environment configurations, available in your particular development
    environment, but different from that of your teammate who is using a different
    development environment but shares the same codebase.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它允许您以灵活的方式构建模型之间的依赖关系，这些依赖关系可以在共同的代码库中共享，因为它在`dbt run`期间编译数据库对象的名称，并从环境配置中收集该名称，当您创建项目时。这意味着在您的环境中，代码将根据您的环境配置编译，这些配置在您特定的开发环境中可用，但与您的队友的开发环境不同，但共享同一代码库。
- en: You can build lineage graphs in which you can visualize a specific model’s data
    flow and dependencies. We will discuss this later in this chapter, and it’s also
    covered in [“Documentation”](#structure_of_dbt_chapter_documentation).
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以构建血统图，以可视化特定模型的数据流和依赖关系。我们将在本章后面讨论此问题，它还涵盖在[“文档”](#structure_of_dbt_chapter_documentation)中。
- en: Finally, while acknowledging that the preceding code may seem like an antipattern,
    because of the sense of repetitiveness of `CASE WHEN` conditions, it’s essential
    to clarify that the entire dataset includes all orders, regardless of their payment
    status. However, for this example, we chose to conduct financial analysis only
    on payments associated with orders that have reached the “success” status.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，虽然承认前面的代码可能看起来像是一种反模式，因为`CASE WHEN`条件的重复感，但需要澄清整个数据集包括所有订单，无论其付款状态如何。然而，对于本例子，我们选择仅对已达到“成功”状态的订单关联的支付进行财务分析。
- en: With the intermediate table built, let’s move to the final layer. Considering
    the use case described, we need to analyze the orders from the customer’s perspective.
    This means we must create a customer dimension that connects with our fact table.
    Since the current use case can fulfill multiple departments, we will not create
    a specific department folder but one named *core*. So, to start, let’s create,
    in our models folder, the *marts/core* directory. Then copy [Example 4-17](#dim_customers)
    into a new file named *dim_customers.sql* and [Example 4-18](#fct_orders) into
    a new file named *fct_orders.sql*.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 中间表创建完成后，让我们进入最终层。考虑到所描述的用例，我们需要从客户角度分析订单。这意味着我们必须创建一个与事实表连接的客户维度。由于当前用例可以满足多个部门，我们不会创建一个特定的部门文件夹，而是一个名为
    *core* 的文件夹。因此，首先在我们的模型文件夹中创建 *marts/core* 目录。然后将 [示例 4-17](#dim_customers) 复制到名为
    *dim_customers.sql* 的新文件中，将 [示例 4-18](#fct_orders) 复制到名为 *fct_orders.sql* 的新文件中。
- en: Example 4-17\. dim_customers.sql
  id: totrans-398
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-17\. dim_customers.sql
- en: '[PRE16]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Example 4-18\. fct_orders.sql
  id: totrans-400
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-18\. fct_orders.sql
- en: '[PRE17]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: With all files created, let’s just set our default configurations inside *dbt_project.yml*,
    as shown in [Example 4-19](#dbt_project_yml_new_default_configs), and then execute
    `dbt run`, or potentially `dbt run --full-refresh` on BigQuery.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 所有文件创建完成后，让我们在 *dbt_project.yml* 中设置默认配置，如 [示例 4-19](#dbt_project_yml_new_default_configs)
    所示，然后在 BigQuery 上执行 `dbt run`，或者可能是 `dbt run --full-refresh`。
- en: Example 4-19\. Model configuration, per layer, inside dbt_project.yml
  id: totrans-403
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-19\. 在 dbt_project.yml 中，每层的模型配置
- en: '[PRE18]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Tip
  id: totrans-405
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Tip
- en: If you are receiving an error message similar to “Compilation Error in rpc request…​depends
    on a node named *int_payment_type_amount_per_order* which was not found,” this
    means that you have a model, dependent on the one that you are trying to preview,
    that is not yet inside your data platform—in our case `int_payment_type_amount_per_order`.
    To solve this, go to that particular model and execute the `dbt run --select *MODEL_NAME*`
    command, replacing `*MODEL_NAME*` with the respective model name.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您收到类似于“rpc 请求中的编译错误...依赖于一个名为 *int_payment_type_amount_per_order* 的节点，但该节点尚未在您的数据平台中——在我们的情况下是
    `int_payment_type_amount_per_order`。要解决此问题，请转到该特定模型并执行 `dbt run --select *MODEL_NAME*`
    命令，将 `*MODEL_NAME*` 替换为相应的模型名称。
- en: If everything ran successfully, your data platform should be fully updated with
    all dbt models. Just look at BigQuery, which should be similar to [Figure 4-36](#dbt_models_bigquery_final_structure).
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，您的数据平台应已完全更新所有 dbt 模型。只需查看 BigQuery，其应类似于 [图 4-36](#dbt_models_bigquery_final_structure)。
- en: '![dbt Models with all BigQuery](assets/aesd_0436.png)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
  zh: '![dbt Models with all BigQuery](assets/aesd_0436.png)'
- en: Figure 4-36\. dbt BigQuery with all models
  id: totrans-409
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-36\. 带有所有模型的 dbt BigQuery
- en: Finally, open *fct_orders.sql* and look at the Lineage option inside the information
    window ([Figure 4-37](#fct_orders_lineage)). This is one of the great features
    we will cover in [“Documentation”](#structure_of_dbt_chapter_documentation), giving
    us a good idea of the data flow that feeds a specific model and its upstream and
    downstream dependencies.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，打开 *fct_orders.sql* 并查看信息窗口中的 Lineage 选项（参见 [图 4-37](#fct_orders_lineage)）。这是我们将在
    [“文档”](#structure_of_dbt_chapter_documentation) 中介绍的众多功能之一，它为我们提供了关于数据流向特定模型及其上游和下游依赖关系的良好概念。
- en: '![dbt fct orders](assets/aesd_0437.png)'
  id: totrans-411
  prefs: []
  type: TYPE_IMG
  zh: '![dbt fct orders](assets/aesd_0437.png)'
- en: Figure 4-37\. dbt fct_orders data lineage
  id: totrans-412
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-37\. dbt fct_orders 数据血统
- en: Sources
  id: totrans-413
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 源
- en: In dbt, *sources* are the raw data available in your data platform, captured
    using a generic extract-and-load (EL) tool. It is essential to distinguish dbt
    sources from traditional data sources. A traditional data source can be either
    internal or external. *Internal data sources* provide the transactional data that
    supports the daily business operations inside your organization. Customer, sales,
    and product data are examples of potential content from an internal data source.
    On the other hand, *external data sources* provide data that originated outside
    your organization, such as data collected from your business partners, the internet,
    and market research, among others. Often this is data related to competitors,
    economics, customer demographics, etc.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 在 dbt 中，*sources* 是您数据平台上可用的原始数据，使用通用的抽取和加载（EL）工具捕获。区分 dbt 源与传统数据源至关重要。传统数据源可以是内部或外部的。*内部数据源*
    提供支持组织日常业务操作的交易数据。客户、销售和产品数据是内部数据源潜在内容的示例。另一方面，*外部数据源* 提供源自组织外部的数据，例如从商业伙伴、互联网和市场研究等处收集的数据。这通常是与竞争对手、经济学、客户人口统计等相关的数据。
- en: dbt sources rely on internal and external data upon business demand but differ
    in definition. As mentioned, dbt sources are the raw data inside your data platform.
    This raw data is typically brought by the data engineering teams, using an EL
    tool, into your data platform and will be the foundation that allows your analytical
    platform to operate.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: dbt sources 依赖于业务需求中的内部和外部数据，但其定义有所不同。正如前文所述，dbt sources 是您数据平台内的原始数据。这些原始数据通常由数据工程团队通过
    EL 工具带入您的数据平台，并且将是支持您的分析平台运行的基础。
- en: In our models, from [“Models”](#structure_of_dbt_chapter_models), we’ve referred
    to our sources by using hardcoded strings such as `dbt-tutorial.stripe.payment`
    or `dbt-t​u​t​o​r​i​a​l​.​j​a​f​f​l​e​_​s​h​o​p​.​customers`. Even if this works,
    consider that if your raw data changes, such as its location or the table name
    to follow specific naming conventions, making the changes across multiple files
    can be difficult and time-consuming. This is where dbt sources come in. They allow
    you to document those source tables inside a YAML file, where you can reference
    your source database, the schema, and tables.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的模型中，从[“模型”](#structure_of_dbt_chapter_models)中，我们通过使用硬编码字符串如`dbt-tutorial.stripe.payment`或`dbt-t​u​t​o​r​i​a​l​.​j​a​f​f​l​e​_​s​h​o​p​.​customers`引用我们的源。即使这样也能工作，但请考虑，如果您的原始数据发生变化，如位置或表名按照特定命名约定进行更改，则在多个文件中进行更改将会很困难且耗时。这就是
    dbt sources 的用武之地。它们允许您在一个 YAML 文件中记录这些源表格，您可以在其中引用源数据库、模式和表格。
- en: Let’s put this into practice. By following the recommended best practices in
    [“YAML Files”](#structure_of_dbt_chapter_yaml), let’s now create a new YAML file
    in the *models/staging/jaffle_shop* directory, named *_jaffle_shop_sources.yml*,
    and copy the code from [Example 4-20](#stg_jaffle_shop_sources). Then create another
    YAML file, now in the *models/staging/stripe* directory, named *_stripe_sources.yml*,
    copying the code in [Example 4-21](#stg_stripe_sources).
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把这些付诸实践。通过遵循[“YAML 文件”](#structure_of_dbt_chapter_yaml)中推荐的最佳实践，现在让我们在 *models/staging/jaffle_shop*
    目录下创建一个名为 *_jaffle_shop_sources.yml* 的新 YAML 文件，并复制[示例 4-20](#stg_jaffle_shop_sources)中的代码。然后，在
    *models/staging/stripe* 目录中创建另一个 YAML 文件，命名为 *_stripe_sources.yml*，并复制[示例 4-21](#stg_stripe_sources)中的代码。
- en: Example 4-20\. _jaffle_shop_sources.yml—sources parametrization file for all
    tables under the Jaffle Shop schema
  id: totrans-418
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-20\. _jaffle_shop_sources.yml—Jaffle Shop 模式下所有表格的源参数化文件
- en: '[PRE19]'
  id: totrans-419
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Example 4-21\. _stripe_sources.yml—sources parametrization file for all tables
    under the stripe schema
  id: totrans-420
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-21\. _stripe_sources.yml—stripe 模式下所有表格的源参数化文件
- en: '[PRE20]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: With our YAML files configured, we need to make a final change inside our models.
    Instead of having our sources hardcoded, we will use a new function named `source()`.
    This works like the `ref()` function that we introduced in [“Referencing data
    models”](ch02.html#ref_data-models), but instead of `{{ ref("stg_stripe_order_payments")
    }}`, to configure a source we now pass something like `{{ source("stripe", "payment")
    }}`, which, in this particular case, will reference the YAML file that we’ve created
    in [Example 4-21](#stg_stripe_sources).
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 配置好我们的 YAML 文件后，我们需要在模型中进行最后一次更改。不再使用硬编码的数据源，而是使用一个名为`source()`的新函数。这类似于我们在[“引用数据模型”](ch02.html#ref_data-models)中介绍的`ref()`函数，但现在配置源时我们传递类似于`{{
    source("stripe", "payment") }}`的内容，这在特定情况下将引用我们在[示例 4-21](#stg_stripe_sources)中创建的
    YAML 文件。
- en: Let’s now get our hands dirty. Take all the SQL staging model code you created
    earlier, and replace it with the respective code in [Example 4-22](#stg_models_with_sources).
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们动手吧。拿出你之前创建的所有 SQL 分期模型代码，并用[示例 4-22](#stg_models_with_sources)中相应的代码替换它。
- en: Example 4-22\. Payments, orders, and customers staging models with the `source()`
    function
  id: totrans-424
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-22\. 使用`source()`函数的付款、订单和客户分期模型
- en: '[PRE21]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: After you switch your models with our `source()` function, you can check how
    your code executes in your data platform by running `dbt compile` or clicking
    the Compile button in your IDE. In the backend, dbt will look to the referenced
    YAML file and replace the `source()` function with the direct table reference,
    as shown in [Figure 4-38](#dbt_source_function_compiled_code).
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 切换到使用我们的`source()`函数后，您可以通过运行`dbt compile`或单击 IDE 中的编译按钮来检查您的代码在数据平台中的执行情况。在后台，dbt
    将查找引用的 YAML 文件，并将`source()`函数替换为直接的表格引用，如[图 4-38](#dbt_source_function_compiled_code)所示。
- en: '![dbt Staging with source function and compiled code](assets/aesd_0438.png)'
  id: totrans-427
  prefs: []
  type: TYPE_IMG
  zh: '![带有 source 函数和编译代码的 dbt 分期](assets/aesd_0438.png)'
- en: Figure 4-38\. dbt customers staging model with `source()` function and respective
    code compiled. The compiled code is what will run inside your data platform.
  id: totrans-428
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-38\. dbt 客户分期模型与`source()`函数及相应编译的代码。编译后的代码将在您的数据平台内运行。
- en: Another benefit of using the `source()` function is that now you can see the
    sources in the lineage graph. Just take a look, for example, at the *fct_orders.sql*
    lineage. The same lineage shown in [Figure 4-37](#fct_orders_lineage) should now
    look like [Figure 4-39](#fct_orders_lineage_with_sources).
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`source()`函数的另一个好处是现在您可以在血统图中看到来源。例如，只需看一下*fct_orders.sql*的血统。现在，与[图 4-37](#fct_orders_lineage)中显示的相同的血统应该看起来像[图 4-39](#fct_orders_lineage_with_sources)。
- en: '![dbt Fact orders lineage with sources](assets/aesd_0439.png)'
  id: totrans-430
  prefs: []
  type: TYPE_IMG
  zh: '![dbt `fct_orders` 数据源血统与来源](assets/aesd_0439.png)'
- en: Figure 4-39\. dbt `fct_orders` data lineage with sources
  id: totrans-431
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-39\. dbt `fct_orders` 数据源血统与来源
- en: Source freshness
  id: totrans-432
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据源新鲜度
- en: The freshness of your data is an essential aspect of data quality. If the data
    isn’t up-to-date, it is obsolete, which could cause significant issues in your
    company’s decision-making process since it could lead to inaccurate insights.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的新鲜度是数据质量的一个重要方面。如果数据不是最新的，它就是过时的，这可能会导致公司决策过程中的重大问题，因为这可能导致不准确的洞察。
- en: dbt allows you to mitigate this situation with the source freshness test. For
    that, we need to have an audit field that states the loaded timestamp of a specific
    data artifact in your data platform. With it, dbt will be able to test how old
    the data is and trigger a warning or an error, depending on the specified conditions.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: dbt允许您通过数据源新鲜度测试来缓解这种情况。为此，我们需要一个审计字段，该字段声明了您的数据平台中特定数据工件的加载时间戳。有了它，dbt将能够测试数据的年龄，并根据指定的条件触发警告或错误。
- en: To achieve this, let’s get back to our source YAML files. For this particular
    example, we will use the orders data in our data platform, so by inference, we
    will replace the code in *_jaffle_shop_sources.yml* with the code in [Example 4-23](#stg_jaffle_shop_sources_freshness).
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，让我们回到我们的源YAML文件。对于这个特定的例子，我们将使用我们数据平台中的订单数据，因此，通过推理，我们将用[示例 4-23](#stg_jaffle_shop_sources_freshness)中的代码替换*_jaffle_shop_sources.yml*中的代码。
- en: Example 4-23\. _jaffle_shop_sources.yml—sources parametrization file for all
    tables under Jaffle Shop schema, with source freshness test
  id: totrans-436
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-23\. _jaffle_shop_sources.yml—Jaffle Shop模式下所有表的源参数化文件，包含源新鲜度测试
- en: '[PRE22]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As you can see, we’ve used the `_etl_loaded_at` field in our data platform.
    We didn’t have to bring it to our transformation process since it had no added
    value for forward models. This isn’t an issue because we are testing our upstream
    data, which in our case is our raw data. In the YAML file, we’ve created two additional
    properties: `loaded_at_field`, which represents the field to be monitored under
    the source freshness test, and `freshness`, with the actual rules to monitor the
    source freshness. Inside the `freshness` property, we’ve configured it to raise
    a warning if the data is 12 hours outdated with the `warn_after` property and
    raise an actual error if the data wasn’t refreshed in the past 24 hours with the
    `error_after` property.'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们在我们的数据平台中使用了`_etl_loaded_at`字段。我们不需要将其带入我们的转换过程中，因为它对于前向模型没有附加值。这并不是问题，因为我们正在测试我们的上游数据，而在我们的情况下是原始数据。在YAML文件中，我们创建了两个额外的属性：`loaded_at_field`，它代表在源新鲜度测试下要监视的字段，以及`freshness`，其中包含监视源新鲜度的实际规则。在`freshness`属性内部，我们配置它在数据过时12小时后使用`warn_after`属性发出警告，并且在过去24小时内未刷新数据时使用`error_after`属性发出实际错误。
- en: Finally, let’s see what happens if we execute the command **`dbt source freshness`**.
    In our case, we got a warning, as you can see in [Figure 4-40](#dbt_source_freshness_logs).
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看如果执行命令**`dbt source freshness`**会发生什么。在我们的情况下，我们收到了一个警告，正如您可以在[图 4-40](#dbt_source_freshness_logs)中看到的那样。
- en: '![dbt Source freshness test](assets/aesd_0440.png)'
  id: totrans-440
  prefs: []
  type: TYPE_IMG
  zh: '![dbt 数据源新鲜度测试](assets/aesd_0440.png)'
- en: Figure 4-40\. dbt orders raw data and source freshness test logs
  id: totrans-441
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-40\. dbt 订单原始数据和数据源新鲜度测试日志
- en: If you check the log details, you can see the query executed in your data platform
    and troubleshoot. This particular warning was expected. The `_etl_loaded_at` was
    built to take 16 hours from the current time, so anything lower than that will
    raise a warning. If you want to keep playing around, change your `warn_after`
    to something higher, like 17 hours. All your tests should pass.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您检查日志详细信息，可以看到在您的数据平台中执行的查询并进行故障排除。这个特定的警告是预期的。`_etl_loaded_at`预计将从当前时间开始花费16小时，所以任何低于这个时间的值都会引发警告。如果您想继续测试，请将您的`warn_after`更改为更高的值，如17小时。所有测试都应该通过。
- en: Hopefully, the source freshness concept is now clear. We will get back to it
    later in the book and show you how to automate and snapshot the source freshness
    tests. In the meantime, it is essential to understand its purpose in the overall
    test landscape, how to configure it, and how important this test could be to mitigate
    data quality issues.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 希望现在源数据新鲜度的概念已经清晰了。我们将在本书的后面回到这个概念，并向您展示如何自动化和快照源数据新鲜度测试。与此同时，了解其在整体测试环境中的目的、如何配置以及这种测试在减少数据质量问题中的重要性非常关键。
- en: Tests
  id: totrans-444
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试
- en: As an analytics engineer, you must ensure that data is accurate and reliable
    to build trust in the analytics you deliver and provide objective insights for
    your organization. Everyone agrees with this, yet even if you follow all the engineering
    state-of-the-art best practices, there will always be exceptions—even more so
    when you have to deal with the volatility that is working with data, its variations,
    type, structure, etc.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 作为分析工程师，您必须确保数据准确可靠，以建立对您提供的分析的信任，并为您的组织提供客观的见解。每个人都同意这一点，但即使您遵循所有工程最佳实践，当您必须处理工作中的数据波动、类型、结构等时，总会有例外情况。
- en: There are many ways to capture those exceptions. Nonetheless, when you work
    with significant amounts of data, you need to think of a scalable approach to
    analyzing large datasets and quickly identifying those exceptions. This is where
    dbt comes in.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以捕获这些异常。然而，当您处理大量数据时，您需要考虑一种可扩展的方法来分析大型数据集并快速识别这些异常。这就是dbt发挥作用的地方。
- en: dbt allows you to rapidly and easily scale tests across your data workflow so
    that you can identify when things break before anyone else does. In a development
    environment, you can use tests to ensure that your analytics code produces the
    desired output. In a deployment/production environment, you can automate tests
    and set up an alert to tell you when a specific test fails so you can quickly
    react to it and fix it before it generates a more extreme consequence.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: dbt允许您快速且轻松地扩展数据工作流中的测试，以便您可以在其他人之前识别出问题。在开发环境中，您可以使用测试来确保您的分析代码产生所需的输出。在部署/生产环境中，您可以自动化测试并设置警报，以便在特定测试失败时通知您，以便您可以迅速做出反应并修复问题，以免产生更严重的后果。
- en: As a data practitioner, it’s important to understand that tests in dbt can be
    summarized as assertions about your data. When you run tests on top of your data
    models, you assert that those data models produce the expected output, which is
    a crucial step in ensuring data quality and reliability. These tests are a form
    of verification similar to confirming that your data follows specific patterns
    and meets predefined criteria.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据从业者，重要的是要理解dbt中的测试可以总结为关于数据的断言。当您在数据模型之上运行测试时，您断言这些数据模型产生了预期的输出，这是确保数据质量和可靠性的关键步骤。这些测试是一种验证形式，类似于确认您的数据遵循特定模式并符合预定义标准。
- en: However, it’s essential to note that dbt tests are just one type of testing
    within the broader landscape of data testing. In software testing, tests are often
    differentiated between verification and validation. dbt tests primarily focus
    on verification by confirming that data adheres to established patterns and structures.
    They are not designed for testing the finer details of logic within your data
    transformations, comparable to what unit tests do in software development.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，在数据测试的更广泛环境中，dbt测试只是测试的一种类型。在软件测试中，测试通常区分为验证和验证两种类型。dbt测试主要侧重于验证，通过确认数据是否符合已建立的模式和结构来进行验证。它们并不设计用于测试数据转换中逻辑的细节，这类似于软件开发中单元测试的作用。
- en: Furthermore, dbt tests can assist with the integration of data components to
    some extent, particularly when multiple components are run together. Nevertheless,
    it’s crucial to recognize that dbt tests have their limitations and may not cover
    all testing use cases. For comprehensive testing in data projects, you may need
    to employ other testing methods and tools tailored to specific validation and
    verification needs.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，dbt测试可以在某种程度上协助数据组件的集成，特别是当多个组件一起运行时。尽管如此，需要认识到dbt测试有其局限性，可能无法涵盖所有测试用例。在数据项目的全面测试中，您可能需要使用其他针对特定验证和验证需求定制的测试方法和工具。
- en: 'With this in mind, let’s focus on which tests can be employed with dbt. There
    are two main classifications of tests in dbt: singular and generic. Let’s get
    to know a bit more about both types, their purpose, and how we can leverage them.'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个理解，让我们专注于可以在dbt中使用哪些测试。在dbt中，测试分为两类：单一测试和通用测试。让我们更多地了解一下这两种类型，它们的目的以及我们如何利用它们。
- en: Generic tests
  id: totrans-452
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通用测试
- en: 'The simplest yet highly scalable tests in dbt are *generic tests*. With these
    tests, you usually don’t need to write any new logic, yet custom generic tests
    are also an option. Nevertheless, you typically write a couple of YAML lines of
    code and then test a particular model or column, depending on the test. dbt comes
    with four built-in generic tests:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: dbt中最简单但高度可扩展的测试是*通用测试*。通过这些测试，通常无需编写任何新逻辑，但也可以选择自定义通用测试。尽管如此，您通常只需编写几行YAML代码，然后根据测试来测试特定模型或列。dbt提供了四种内置的通用测试：
- en: '`unique` test'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: '`unique` 测试'
- en: Verifies that every value in a specific column is unique
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 验证特定列中的每个值是否唯一
- en: '`not_null` test'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '`not_null` 测试'
- en: Verifies that every value in a specific column is not null
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 验证特定列中的每个值是否不为null
- en: '`accepted_values` test'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '`accepted_values` 测试'
- en: Ensures that every value in a specific column exists in a given predefined list
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 确保特定列中的每个值存在于给定的预定义列表中
- en: '`relationships` test'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '`relationships` 测试'
- en: Ensures that every value in a specific column exists in a column in another
    model, and so we grant referential integrity
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 确保特定列中的每个值存在于另一个模型中的列中，因此我们保证了参照完整性
- en: Now that we have some context about the generic tests, let’s try them. We can
    choose the model we want, but to simplify, let’s pick one to which we can apply
    all the tests. For that, we’ve chosen the *stg_jaffle_shop_orders.sql* model.
    Here we will be able to test `unique` and `not_null` in fields like `customer_id`
    and `order_id`. We can use `accepted_values` to check whether all orders `status`
    are in a predefined list. Finally, we will use the `relationships` test to check
    whether all values from the `customer_id` are in the *stg_jaffle_shop_customers.sql*
    model. Let’s start by replacing our *_jaffle_shop_models.yml* with the code in
    [Example 4-24](#jaffle_shop_models_with_generic_tests).
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对通用测试有了一些背景了解，让我们尝试一下。我们可以选择想要的模型，但为了简化，让我们选择一个模型，可以对其应用所有测试。为此，我们选择了*stg_jaffle_shop_orders.sql*模型。在这里，我们将能够测试`customer_id`和`order_id`等字段的`unique`和`not_null`。我们可以使用`accepted_values`检查所有订单的`status`是否在预定义列表中。最后，我们将使用`relationships`测试检查`customer_id`的所有值是否在*stg_jaffle_shop_customers.sql*模型中。让我们从用[示例 4-24](#jaffle_shop_models_with_generic_tests)中的代码替换我们的*_jaffle_shop_models.yml*开始。
- en: Example 4-24\. _jaffle_shop_models.yml parametrizations with generic tests
  id: totrans-463
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-24\. 带有通用测试的_jaffle_shop_models.yml参数化
- en: '[PRE23]'
  id: totrans-464
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now, in your command line, type **`dbt test`** and take a look at the logs.
    If the test failed in the `accepted_values`, you did everything right. It was
    supposed to fail. Let’s debug to understand the potential root cause of the failure.
    Open the logs and expand the test that failed. Then click Details. You’ll see
    the query executed to test the data, as [Figure 4-41](#generic_test_logs_failure)
    shows.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在命令行中键入**`dbt test`**并查看日志。如果`accepted_values`测试失败，那么您做得很好。它应该失败的。让我们进行调试，了解失败的潜在根本原因。打开日志并展开失败的测试。然后点击详细信息。您将看到执行测试数据的查询，正如[Figure 4-41](#generic_test_logs_failure)所示。
- en: '![Generic value test failure](assets/aesd_0441.png)'
  id: totrans-466
  prefs: []
  type: TYPE_IMG
  zh: '![通用值测试失败](assets/aesd_0441.png)'
- en: Figure 4-41\. Generic test, dbt logs with `accepted_values` failed test
  id: totrans-467
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-41\. 通用测试，使用`accepted_values`失败的dbt日志
- en: Let’s copy this query to your text editor—keep only the inner query and then
    execute it. You should have a similar output as in [Figure 4-42](#generic_test_debug).
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将此查询复制到您的文本编辑器中——仅保留内部查询然后执行它。您应该会得到与[Figure 4-42](#generic_test_debug)中类似的输出。
- en: '![Test debug](assets/aesd_0442.png)'
  id: totrans-469
  prefs: []
  type: TYPE_IMG
  zh: '![测试调试](assets/aesd_0442.png)'
- en: Figure 4-42\. Generic test debug
  id: totrans-470
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-42\. 通用测试调试
- en: And voilá. We found the issue. The additional status `return_pending` is missing
    from our test list. Let’s add it and rerun our **`dbt test`** command. All the
    tests should pass now, as shown in [Figure 4-43](#generic_test_execution_success).
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 天啊。我们发现了问题。附加状态`return_pending`在我们的测试列表中缺失。让我们添加它并重新运行我们的**`dbt test`**命令。现在所有测试都应该通过，如[图 4-43](#generic_test_execution_success)所示。
- en: '![Tests success](assets/aesd_0443.png)'
  id: totrans-472
  prefs: []
  type: TYPE_IMG
  zh: '![测试成功](assets/aesd_0443.png)'
- en: Figure 4-43\. Generic test with all tests being successfully executed
  id: totrans-473
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-43\. 所有测试成功执行的通用测试
- en: Note
  id: totrans-474
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In addition to the generic tests within dbt Core, a lot more are in the dbt
    ecosystem. These tests are found in dbt packages because they are an extension
    of the generic tests built inside dbt. [“dbt Packages”](ch05.html#dbt_packages)
    will detail the concept of packages and how to install them, but for extended
    testing capabilities, packages such as [*dbt_utils*](https://oreil.ly/MwqgC) from
    the dbt team, or [*dbt_expectations*](https://oreil.ly/bmrqJ) from the Python
    library Great Expectations, are clear examples of the excellent usage of packages
    and a must-have in any dbt project. Finally, custom generic tests are another
    dbt feature that enables you to define your own data validation rules and checks,
    tailored to your specific project requirements.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 除了dbt Core中的通用测试之外，dbt生态系统中还有更多测试。这些测试位于dbt包中，因为它们是内置于dbt中的通用测试的扩展。[“dbt Packages”](ch05.html#dbt_packages)将详细介绍包的概念及其安装方法，但是对于扩展测试功能，如来自dbt团队的*dbt_utils*（https://oreil.ly/MwqgC）或来自Python库Great
    Expectations的*dbt_expectations*（https://oreil.ly/bmrqJ）等包，都是出色的使用示例，并且是任何dbt项目中必不可少的。最后，自定义通用测试是dbt的另一个功能，它允许您定义适合特定项目需求的数据验证规则和检查。
- en: Singular tests
  id: totrans-476
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单数测试
- en: Unlike the generic tests, *singular tests* are defined in *.sql* files under
    the *tests* directory. Typically, these tests are helpful when you want to test
    a specific attribute inside a particular model, but the traditional tests built
    inside dbt don’t fit your needs.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 与通用测试不同，*单数测试*定义在*tests*目录下的*.sql*文件中。通常，在您想要测试特定模型内特定属性时很有帮助，但内置于dbt中的传统测试不符合您的需求。
- en: Looking into our data model, a good test is to check that no order has a negative
    total amount. We could perform this test in one of the three layers—staging, intermediate,
    or marts. We’ve chosen the intermediate layer since we did some transformations
    that could influence the data. To start, create a file named *assert_total_payment_amount_is_positive.sql*
    in the *tests* directory and copy the code in [Example 4-25](#test_assert_total_payment_amount_is_positive).
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看我们的数据模型时，一个很好的测试是检查没有订单的总金额为负数。我们可以在三个层次之一——分段、中间或市场中执行此测试。我们选择了中间层，因为我们做了一些可能影响数据的转换。首先，在*tests*目录中创建名为*assert_total_payment_amount_is_positive.sql*的文件，并复制[Example 4-25](#test_assert_total_payment_amount_is_positive)中的代码。
- en: Example 4-25\. assert_total_payment_amount_is_positive.sql singular test to
    check if the `total_amount` attribute inside int_payment_type_amount_per_order
    has only non-negative values
  id: totrans-479
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例4-25\. assert_total_payment_amount_is_positive.sql，用于检查`int_payment_type_amount_per_order`内的`total_amount`属性是否仅具有非负值的单数测试
- en: '[PRE24]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now you can execute one of the following commands to run your test, which should
    pass:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以执行以下命令之一来运行您的测试，这些测试应该通过：
- en: '`dbt test`'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt test`'
- en: Executes all your tests
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 执行您的所有测试
- en: '`dbt test --select test_type:singular`'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt test --select test_type:singular`'
- en: Executes only singular tests
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 仅执行单数测试
- en: '`dbt test --select int_payment_type_amount_per_order`'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt test --select int_payment_type_amount_per_order`'
- en: Executes all tests for the `int_payment_type_amount_per_order` model
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 执行`int_payment_type_amount_per_order`模型的所有测试
- en: '`dbt test --select assert_total_payment_amount_is_positive`'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt test --select assert_total_payment_amount_is_positive`'
- en: Executes only the specific test we created
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 执行我们创建的特定测试
- en: These commands offer the ability to selectively run tests according to your
    requirements. Whether you need to run all tests, tests of a specific type, tests
    for a particular model, or even a single specific test, dbt allows you to leverage
    various selection syntax options within your commands. This variety of choices
    ensures that you can precisely target the tests, along with other dbt resources,
    that you wish to execute. In [“dbt Commands and Selection Syntax”](#sub_chapt_dbt_command_and_ss),
    we’ll provide a comprehensive overview of the available dbt commands and investigate
    how to efficiently use selection syntax to specify resources.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令提供了根据您的需求选择运行测试的能力。无论您需要运行所有测试、特定类型的测试、特定模型的测试，甚至是单独的特定测试，dbt都允许您在命令中利用各种选择语法选项。这种多样的选择确保您可以精确地定位您希望执行的测试，以及其他dbt资源。
- en: Testing sources
  id: totrans-491
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在[“dbt命令和选择语法”](#sub_chapt_dbt_command_and_ss)中，我们将提供对可用dbt命令的全面概述，并探讨如何有效地使用选择语法来指定资源。
- en: To test your models in your dbt project, you can also extend those tests to
    your sources. You already did this with the source freshness test in [“Source
    freshness”](#source_freshness_subchap). Still, you can also potentiate generic
    and singular tests for that purpose. Using the test capabilities in your sources
    will give us confidence that the raw data is built to fit our expectations.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的dbt项目中测试您的模型，您还可以将这些测试扩展到您的数据源。您已经在[“数据源新鲜度”](#source_freshness_subchap)中使用数据源新鲜度测试做过了这一点。此外，您还可以为此目的加强通用和单一测试。在您的数据源中使用测试功能将使我们确信原始数据构建得符合我们的期望。
- en: In the same way that you configure tests in your models, you can also do so
    for your sources. Either in YAML files for generic tests, or *.sql* files for
    singular tests, the norm remains the same. Let’s take a look at one example for
    each type of test.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 与您在模型中配置测试的方式相同，您也可以为您的数据源进行配置。无论是通用测试的YAML文件，还是单一测试的*.sql*文件，规范始终如一。让我们分别看一下每种测试类型的一个示例。
- en: Starting with generic tests, you will need to edit the specific YAML file of
    the sources. Let’s keep the same `unique`, `not_null`, and `accepted_values` tests
    as we have for the customers and orders staging tables, but now you will test
    their sources. So, to make this happen, replace the *_jaffle_shop_sources.yml*
    code with the code from [Example 4-26](#_jaffle_shop_sources_with_tests).
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 从通用测试开始，您需要编辑数据源的特定YAML文件。让我们保留与顾客和订单分期表相同的`unique`、`not_null`和`accepted_values`测试，但现在您将测试它们的数据源。因此，为了实现这一目标，请将*_jaffle_shop_sources.yml*中的代码替换为[示例 4-26](#_jaffle_shop_sources_with_tests)中的代码。
- en: Example 4-26\. _jaffle_shop_sources.yml—parametrizations with generic tests
  id: totrans-495
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 执行`dbt test`或`dbt test --select source:stripe`，因为我们在这种情况下查看了Stripe数据源。一切也应该通过。
- en: '[PRE25]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Once you have your new code in the YAML file, you can run `dbt test` or, to
    be more exact, execute the command that will test only the source for which we’ve
    created these tests, `dbt test --select source:jaffle_shop`. All your tests should
    pass.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您在YAML文件中有了新的代码，您可以运行`dbt test`或更确切地执行命令，仅测试我们创建了这些测试的数据源，`dbt test --select
    source:jaffle_shop`。您的所有测试应该通过。
- en: Finally, you can also implement singular tests as you did before. Let’s replicate
    the singular test we performed earlier in [Example 4-25](#test_assert_total_payment_amount_is_positive).
    Create a new file named *assert_source_total_payment_amount_is_positive.sql* in
    your *tests* directory and copy the code from [Example 4-27](#assert_source_total_payment_amount_is_positive).
    This test checks whether the sum of the `amount` attribute, per order, inside
    the payment source table has only nonnegative values.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您也可以像之前一样实施单一测试。让我们复制我们之前在[示例 4-25](#test_assert_total_payment_amount_is_positive)中执行的单一测试。在您的*tests*目录中创建一个名为*assert_source_total_payment_amount_is_positive.sql*的新文件，并从[示例 4-27](#assert_source_total_payment_amount_is_positive)复制代码。该测试检查付款来源表中订单的`amount`属性的总和是否仅为非负值。
- en: Example 4-27\. assert_source_total_payment_amount_is_positive.sql singular test
  id: totrans-499
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 测试数据源
- en: '[PRE26]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Execute `dbt test` or `dbt test --select source:stripe`, since we look into
    the Stripe source in this case. Everything should pass as well.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 4-27\. assert_source_total_payment_amount_is_positive.sql 单一测试
- en: Analyses
  id: totrans-502
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '*analyses*文件夹可以存储您的特定查询、审计查询、培训查询或重构查询，例如，在影响模型之前检查代码外观的用途。'
- en: The *analyses* folder can store your ad hoc queries, audit queries, training
    queries, or refactoring queries, used, for example, to check how your code will
    look before affecting your models.
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 4-26\. _jaffle_shop_sources.yml—使用通用测试的参数化
- en: Analyses are templated SQL files that you can’t execute during `dbt run`, but
    since you can use Jinja on your analyses, you can still use `dbt compile` to see
    how your code will look while preserving your code under version control. Considering
    its purpose, let’s look into one use case where we can leverage the *analyses*
    folder.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 分析是模板化的 SQL 文件，您不能在 `dbt run` 中执行，但由于您可以在分析中使用 Jinja，因此您仍然可以使用 `dbt compile`
    来查看您的代码的外观，同时保留您的代码在版本控制下。考虑到其目的，让我们看看可以利用 *analyses* 文件夹的一个用例。
- en: Imagine that you don’t want to build a whole new model but still want to keep
    a piece of information for future needs by leveraging the code versioning. With
    analyses, you can do just that. For our use case, let’s analyze the top 10 most
    valuable customers in terms of the total amount paid, considering only orders
    “completed” status. To see this, inside the *analyses* directory, create a new
    file named *most_valuable_customers.sql* and copy the code from [Example 4-28](#most_valuable_customers).
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你不想建立一个全新的模型，但仍然想通过利用代码版本管理来保留未来需求的一部分信息。通过分析，你可以做到这一点。对于我们的用例，让我们分析总支付金额最高的前
    10 名客户，仅考虑订单“完成”状态。要查看此信息，在 *analyses* 目录中，创建一个名为 *most_valuable_customers.sql*
    的新文件，并复制来自 [示例 4-28](#most_valuable_customers) 的代码。
- en: Example 4-28\. most_valuable_customers.sql analyses, which output the top 10
    most valuable customers based on completed orders
  id: totrans-506
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-28\. most_valuable_customers.sql 分析，基于已完成订单输出前 10 名最有价值的客户
- en: '[PRE27]'
  id: totrans-507
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Now execute the code and check the results. It will give you the top 10 most
    valuable customers if everything goes well, as [Figure 4-44](#valuable_customers)
    shows.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 现在执行代码并检查结果。如果一切顺利，它将给出最有价值的前 10 名客户，就像 [图 4-44](#valuable_customers) 所示的那样。
- en: '![Valuable customers](assets/aesd_0444.png)'
  id: totrans-509
  prefs: []
  type: TYPE_IMG
  zh: '![有价值客户](assets/aesd_0444.png)'
- en: Figure 4-44\. Top 10 most valuable customers, based on the total global amount
    paid with completed orders
  id: totrans-510
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-44\. 基于已完成订单支付的全球总金额最有价值的前 10 名客户
- en: Seeds
  id: totrans-511
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 种子
- en: '*Seeds* are CSV files within your dbt platform with a small amount of nonvolatile
    data to be materialized as a table inside your data platform. By simply typing
    `dbt seed` in your command line, seeds can be used in your models in the standard
    way, like all the other models, using the `ref()` function.'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: '*Seeds* 是您的 dbt 平台中的 CSV 文件，其中包含少量非易失性数据，可作为表在您的数据平台中实现。只需在命令行中输入 `dbt seed`，种子就可以像所有其他模型一样在您的模型中使用
    `ref()` 函数。'
- en: We can find multiple applications for seeds, from mapping country codes (for
    example, PT to Portugal or US to United States), zip codes to states, dummy email
    addresses to be excluded from our analyses, or even other complex analyses, like
    price range classification. What’s important is to remember that seeds shouldn’t
    have large or frequently changing data. If that is the case, rethink your data
    capture approach—for example, using an SFTP (SSH File Transfer Protocol) or an
    API.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以找到种子的多个应用场景，从映射国家代码（例如，PT 表示葡萄牙或 US 表示美国）、邮政编码到州、需要排除在我们分析之外的虚拟电子邮件地址，甚至其他复杂的分析，比如价格范围分类。重要的是记住，种子不应该有大量或频繁变动的数据。如果情况是这样的话，重新考虑你的数据捕捉方法，例如使用
    SFTP（SSH 文件传输协议）或 API。
- en: To better understand how to use seeds, let’s follow the next use case. Taking
    into account what we did in [“Analyses”](#structure_of_dbt_chapter_analyses),
    we want to not only see the top 10 most valuable customers, based on paid orders
    completed, but also classify all customers with orders as *regular*, *bronze*,
    *silver*, or *gold*, considering the `total_amount` paid. As a start, let’s create
    our seed. For that, create a new file named *customer_range_per_paid_amount.csv*
    in your seeds folder and copy the [Example 4-29](#customer_range_per_paid_amount)
    data.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解如何使用种子，请按照下一个用例继续操作。考虑到我们在 [“分析”](#structure_of_dbt_chapter_analyses)
    中所做的工作，我们不仅希望看到根据已支付的订单确定的最有价值的前 10 名客户，还要根据支付的 `total_amount` 将所有客户分类为 *regular*、*bronze*、*silver*
    或 *gold*。作为一个开始，让我们创建我们的种子。为此，在您的 seeds 文件夹中创建一个名为 *customer_range_per_paid_amount.csv*
    的新文件，并复制 [示例 4-29](#customer_range_per_paid_amount) 的数据。
- en: Example 4-29\. seed_customer_range_per_paid_amount.csv with ranges mapping
  id: totrans-515
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-29\. seed_customer_range_per_paid_amount.csv，其中包含映射范围的数据
- en: '[PRE28]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: After you complete this, execute **`dbt seed`**. It will materialize your CSV
    file into a table in your data platform. Finally, in the *analyses* directory,
    let’s make a new file named *customer_range_based_on_total_paid_amount.sql* and
    copy the code from [Example 4-30](#customer_range_based_on_total_paid_amount).
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，请执行**`dbt seed`**。它将把你的 CSV 文件转换成数据平台中的表格。最后，在*分析*目录下，让我们创建一个名为*customer_range_based_on_total_paid_amount.sql*的新文件，并从[示例 4-30](#customer_range_based_on_total_paid_amount)复制代码。
- en: Example 4-30\. customer_range_based_on_total_paid_amount.sql shows you, based
    on the completed orders and the total amount paid, the customer classification
    range
  id: totrans-518
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-30\. customer_range_based_on_total_paid_amount.sql 根据已完成订单和支付总额，显示了客户分类范围。
- en: '[PRE29]'
  id: totrans-519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Let’s now execute our code and see the results. It will give each customer the
    total amount paid and its corresponding range ([Figure 4-45](#customers_range)).
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们执行我们的代码并查看结果。它将为每位客户提供总支付金额及其对应的范围（[图 4-45](#customers_range)）。
- en: '![Customers range](assets/aesd_0445.png)'
  id: totrans-521
  prefs: []
  type: TYPE_IMG
  zh: '![客户范围](assets/aesd_0445.png)'
- en: Figure 4-45\. Customers’ range, based on the total global amount paid with completed
    orders
  id: totrans-522
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-45\. 基于完成订单和支付总额的客户范围。
- en: Documentation
  id: totrans-523
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文档
- en: Documentation is critical in the global software engineering landscape, yet
    it seems like a taboo. Some teams do it, others don’t, or it is incomplete. It
    can become too bureaucratic or complex, or be seen as an overhead to the developer’s
    to-do list, and thus avoided at all costs. You might hear a giant list of reasons
    to justify not creating documentation or postponing it to a less demanding time.
    No one says documentation is nonessential. It’s just that “we won’t do it,” “not
    now,” or “we don’t have time.”
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 在全球软件工程领域，文档至关重要，但似乎又像个禁忌。一些团队做了，而其他团队则没有，或者做得不完整。文档可能会变得过于官僚主义或复杂，或者被视为开发者待办事项中的负担，因此不惜一切代价避免。你可能听到一长串理由来证明不创建文档或将其推迟到较不紧迫的时间。没有人会说文档是不重要的。只是“我们不会做”，“现在不做”，或者“我们没有时间”。
- en: 'Here are several reasons to justify creating and using documentation:'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是几个理由，来证明创建和使用文档的必要性：
- en: Facilitates the onboarding, handover, and hiring processes. With proper documentation,
    any new team member will have the safeguard that they are not being “thrown to
    the wolves.” The new colleague will have the onboarding process and technical
    documentation in writing, which reduces their learning curve on the current team
    processes, concepts, standards, and technological developments. The same applies
    to employee turnover and the knowledge-sharing transition.
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进了入职、移交和招聘流程。有了适当的文档，任何新的团队成员都可以确保他们不是“被抛向狼群”。新同事将拥有书面的入职流程和技术文档，从而减少其对当前团队流程、概念、标准和技术发展的学习曲线。员工流失和知识分享过渡也适用同样的原则。
- en: It will empower a single source of the truth. From business definitions, processes,
    and how-to articles, to letting users answer self-service questions, having documentation
    will save your team time and energy trying to reach that information.
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将赋予真理的单一来源。从业务定义、流程和操作文章，到让用户自助回答问题，有文档将节省团队寻找信息的时间和精力。
- en: Sharing knowledge through documentation will mitigate duplicate or redundant
    work. If the documentation was done already, it could be reused without the need
    to start from scratch.
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过文档分享知识，可以减少重复或冗余工作。如果文档已经完成，可以重新使用，而无需从头开始。
- en: It promotes a sense of shared responsibility, ensuring that critical knowledge
    is not confined to a single individual. This shared ownership is crucial in preventing
    disruptions when key team members are unavailable.
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它促进了共同责任感，确保关键知识不局限于单个个体。在关键团队成员不可用时，这种共享所有权对防止中断至关重要。
- en: It is essential when you want to establish quality, process control, and meet
    compliance regulations. Having documentation will enable your team to work toward
    cohesion and alignment across the company.
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你希望建立质量、过程控制并遵守合规法规时，文档至关重要。有文档将使你的团队能够在公司各部门之间实现协调和一致性。
- en: One reason that justifies the lack of motivation to create documentation is
    that it is a parallel stream from the actual development flow, like using one
    tool for development and another for the documentation. With dbt, this is different.
    You build your project documentation while developing your analytics code, tests,
    and connecting to sources, among other tasks. Everything is inside dbt, not in
    a separate interface.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 一个理由证明缺乏创建文档的动机是，它与实际开发流程并行，就像使用一个工具进行开发，另一个工具进行文档编写一样。但是，使用dbt不同。您在开发分析代码、测试和连接到源等任务时，同时构建项目文档。一切都在dbt内部进行，而不是在一个单独的界面中。
- en: The way dbt handles documentation enables you to create it while building your
    code. Typically, a good part of the documentation is already dynamically generated,
    such as the lineage graphs we’ve introduced before, requiring only that you configure
    your `ref()` and `source()` functions appropriately. The other part is partially
    automated, needing you to give your manual inputs of what a particular model or
    column represents. Yet, once again, everything is done inside dbt, directly in
    the YAML or Markdown files.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: dbt处理文档的方式使您能够在构建代码的同时创建文档。通常情况下，文档的很大一部分已经是动态生成的，例如我们之前介绍过的血统图，只需要您适当配置`ref()`和`source()`函数即可。另一部分是部分自动化的，需要您手动输入特定模型或列代表的内容。然而，再次强调，所有操作都是在dbt内部进行的，直接在YAML或Markdown文件中进行。
- en: Let’s get started with our documentation. The use case we want to achieve is
    to document our models and respective columns of `fct_orders` and `dim_customers`.
    We will use the models’ YAML files, and for richer documentation, we will use
    doc blocks inside the Markdown files. Since we still need to create a YAML file
    for the core models inside the *marts* directory, let’s do so with the name *_core_models.yml*.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始我们的文档工作。我们想要实现的用例是记录我们的模型及其对应的`fct_orders`和`dim_customers`列。我们将使用模型的YAML文件，并为了更丰富的文档，我们将在Markdown文件中使用文档块。由于我们仍然需要在*marts*目录中为核心模型创建一个YAML文件，让我们使用名称为*_core_models.yml*。
- en: Copy [Example 4-31](#_core_models). Then, create a Markdown file in the same
    directory folder named *_code_docs.md*, copying [Example 4-32](#_core_doc).
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 复制[示例 4-31](#_core_models)。然后，在同一目录文件夹中创建一个名为*_code_docs.md*的 Markdown 文件，复制[示例
    4-32](#_core_doc)。
- en: Example 4-31\. _core_models.yml—YAML file with `description` parameter
  id: totrans-535
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-31\. _core_models.yml—带有`description`参数的YAML文件
- en: '[PRE30]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Example 4-32\. _core_doc.md—markdown file with a doc block
  id: totrans-537
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-32\. _core_doc.md—带有文档块的Markdown文件
- en: '[PRE31]'
  id: totrans-538
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Before generating the documentation, let’s try to understand what we did. By
    analyzing the YAML file *_core_models.yml*, you can see we’ve added a new property:
    `description`. This basic property allows you to complement the documentation
    with your manual inputs. These manual inputs can be text, as we used in most cases,
    but can also reference doc blocks inside Markdown files, as done in `fct_orders`,
    column `is_order_completed`. We first created the doc block inside the Markdown
    file `_code_docs.md` and named it `is_order_completed_docblock`. This name is
    the one that we’ve used to reference the doc block inside the description field:
    `"{{ doc(''is_order_completed_docblock'') }}"`.'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成文档之前，让我们尝试理解我们做了什么。通过分析YAML文件*_core_models.yml*，您可以看到我们添加了一个新属性：`description`。这个基本属性允许您用手动输入来补充文档。这些手动输入可以是文本，就像我们在大多数情况下使用的那样，也可以是引用Markdown文件中的文档块，就像我们在`fct_orders`列`is_order_completed`中所做的那样。我们首先在Markdown文件*_code_docs.md*中创建了文档块，并命名为`is_order_completed_docblock`。这个名称是我们用来引用描述字段中文档块的名称：`"{{
    doc('is_order_completed_docblock') }}"`。
- en: Let’s generate our documentation by typing **`dbt docs generate`** in your command
    line. After it finishes successfully, you can navigate through the documentation
    page.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过在命令行中键入**`dbt docs generate`**来生成我们的文档。当它成功完成后，您可以浏览文档页面。
- en: Reaching the documentation page is simple. After you execute `dbt docs generate`
    successfully, inside the IDE, at the top left of the screen, you can click the
    Documentation site book icon right next to the Git branch information ([Figure 4-46](#view_documentation)).
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看文档页面很简单。在您成功执行`dbt docs generate`之后，在IDE中，在屏幕左上角，在Git分支信息的旁边，您可以点击文档站点书本图标，即
    [图 4-46](#view_documentation)。
- en: '![View documentation](assets/aesd_0446.png)'
  id: totrans-542
  prefs: []
  type: TYPE_IMG
  zh: '![查看文档](assets/aesd_0446.png)'
- en: Figure 4-46\. View documentation
  id: totrans-543
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-46\. 查看文档
- en: Once you enter the documentation page, you will see the overview page, similar
    to [Figure 4-47](#documentation_landing_page). For now, you have the default information
    provided by dbt, but this page is also fully customizable.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦进入文档页面，您将看到类似[Figure 4-47](#documentation_landing_page)的概述页面。目前，您将看到dbt提供的默认信息，但此页面也是完全可定制的。
- en: '![Documentation landing page](assets/aesd_0447.png)'
  id: totrans-545
  prefs: []
  type: TYPE_IMG
  zh: '![文档着陆页](assets/aesd_0447.png)'
- en: Figure 4-47\. Documentation landing page
  id: totrans-546
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-47\. 文档着陆页
- en: Looking on the overview page, you can see your project structure to the left
    ([Figure 4-48](#documentation_folder_structure)) with tests, seeds, and models,
    among others, that you can navigate freely.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 查看概述页面，您可以看到左侧的项目结构（[Figure 4-48](#documentation_folder_structure)），其中包括测试、种子和模型等，您可以自由导航。
- en: '![Project folder structure in documentation](assets/aesd_0448.png)'
  id: totrans-548
  prefs: []
  type: TYPE_IMG
  zh: '![文档中的项目文件结构](assets/aesd_0448.png)'
- en: Figure 4-48\. dbt project structure inside the documentation
  id: totrans-549
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-48\. dbt项目结构在文档中的展示
- en: Now choose one of our developed models and look at its respective documentation.
    We’ve selected the `fct_orders` model. Once we click its file, the screen will
    show you several layers of information on the model, as shown in [Figure 4-49](#documentation_fct_orders_01).
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 现在选择我们开发的一个模型并查看其相应的文档。我们选择了`fct_orders`模型。一旦我们点击其文件，屏幕将显示有关模型的多层信息，如[Figure 4-49](#documentation_fct_orders_01)所示。
- en: '![fct_orders documentation page](assets/aesd_0449.png)'
  id: totrans-551
  prefs: []
  type: TYPE_IMG
  zh: '![fct_orders文档页面](assets/aesd_0449.png)'
- en: Figure 4-49\. `fct_orders` documentation page
  id: totrans-552
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-49\. `fct_orders`文档页面
- en: At the top, the Details section gives you information about table metadata,
    such as the table type (also known as *materialization*). The language used, the
    number of rows, and the approximate table size are other available details.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部，详细信息部分提供了关于表元数据的信息，例如表类型（也称为*物化*）。可用的其他详细信息包括使用的语言、行数以及表的大致大小。
- en: Right after, we have the Description of the model. As you may recall, it was
    the one we configured in the *_core_models.yml* file for the `fct_orders` table.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 紧接着，我们有模型的描述。您可能记得，这是我们在*_core_models.yml*文件中为`fct_orders`表配置的模型。
- en: Finally, we have the Columns information related to `fct_orders`. This documentation
    is partially automated (for example, the column type), but also receives manual
    inputs (such as the column descriptions). We gave those inputs already filling
    the description properties and provided comprehensive information using doc blocks
    for the `is_order_completed` attribute. To see the written doc block on the documentation
    page, click in the `is_order_completed` field, which should expand and present
    the desired information ([Figure 4-50](#documentation_fct_orders_01_doc_block)).
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有与`fct_orders`相关的列信息。该文档部分自动化（例如列类型），但也接受手动输入（例如列描述）。我们已经提供了这些输入，并使用文档块为`is_order_completed`属性提供了全面信息。要查看文档页上的文档块，请点击`is_order_completed`字段，该字段应扩展并呈现所需信息（[Figure 4-50](#documentation_fct_orders_01_doc_block)）。
- en: '![fct_orders doc block](assets/aesd_0450.png)'
  id: totrans-556
  prefs: []
  type: TYPE_IMG
  zh: '![fct_orders文档块](assets/aesd_0450.png)'
- en: Figure 4-50\. `is_order_completed` column showing the configured doc block
  id: totrans-557
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-50\. `is_order_completed`列显示配置的文档块
- en: After the Columns information, we have the downstream and upstream dependencies
    of the model, with the Referenced By and Depends On sections, respectively. These
    dependencies are also shown in [Figure 4-51](#documentation_fct_orders_02_dependencies).
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 在列信息之后，我们有模型的下游和上游依赖关系，包括引用和依赖部分。这些依赖关系也显示在[Figure 4-51](#documentation_fct_orders_02_dependencies)中。
- en: '![fct_orders dependencies](assets/aesd_0451.png)'
  id: totrans-559
  prefs: []
  type: TYPE_IMG
  zh: '![fct_orders依赖关系](assets/aesd_0451.png)'
- en: Figure 4-51\. `fct_orders` dependencies in the documentation
  id: totrans-560
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-51\. `fct_orders` 在文档中的依赖关系
- en: At the bottom of the `fct_orders` documentation page is the Code that generated
    the specific model. You can visualize the source code in a raw format, with Jinja,
    or the compiled code. [Figure 4-52](#documentation_fct_orders_03_source_code)
    shows its raw form.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 在`fct_orders`文档页面底部是生成特定模型的代码。您可以以原始格式、Jinja或编译代码来可视化源代码。[Figure 4-52](#documentation_fct_orders_03_source_code)展示了其原始形式。
- en: '![fct orders source code](assets/aesd_0452.png)'
  id: totrans-562
  prefs: []
  type: TYPE_IMG
  zh: '![fct orders源代码](assets/aesd_0452.png)'
- en: Figure 4-52\. `fct_orders` source code
  id: totrans-563
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 4-52\. `fct_orders` 源代码
- en: Finally, if you look at the bottom right of your documentation page, you’ll
    see a blue button. Clicking this button accesses the lineage graph for the respective
    model you are visualizing. We have selected the `fct_orders` lineage graph, where
    you can see the upstream dependencies, such as the source tables or the intermediate
    tables, as well as the downstream dependencies, like the analysis files shown
    in [Figure 4-53](#fct_orders_lineage_graph). The lineage graph is powerful since
    it provides a holistic view of how data moves from the moment you consume it until
    you transform and serve it.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您查看文档页面右下角，会看到一个蓝色按钮。点击该按钮将访问您正在可视化的相应模型的血统图。我们已选择了`fct_orders`血统图，您可以在其中看到上游依赖项，如源表或中间表，以及下游依赖项，如[图 4-53](#fct_orders_lineage_graph)中显示的分析文件。血统图非常强大，因为它提供了数据从您消耗它的那一刻起直到转换和提供的整体视图。
- en: Another interesting aspect of dbt documentation worth mentioning is the ability
    to persist column- and table-level descriptions directly to the database by using
    the `persist_docs` configuration. This feature is valuable for all users of your
    data warehouse, including those who may not have access to dbt Cloud. It ensures
    that essential metadata and descriptions are readily available to data consumers,
    facilitating better understanding and utilization of your data assets.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: dbt 文档的另一个有趣的方面是通过使用`persist_docs`配置直接将列级和表级描述持久化到数据库的能力。此功能对于您数据仓库的所有用户都非常有价值，包括那些可能无法访问dbt
    Cloud的用户。它确保关键的元数据和描述对数据消费者是随时可用的，有助于更好地理解和利用您的数据资产。
- en: '![fct orders lineage graph](assets/aesd_0453.png)'
  id: totrans-566
  prefs: []
  type: TYPE_IMG
  zh: '![fct orders lineage graph](assets/aesd_0453.png)'
- en: Figure 4-53\. `fct_orders` lineage graph
  id: totrans-567
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-53\. `fct_orders`血统图
- en: dbt Commands and Selection Syntax
  id: totrans-568
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: dbt 命令和选择语法
- en: We’ve already introduced several dbt commands, such as `dbt run` and `dbt test`,
    and how we interact with the CLI to execute them. In this section, we’ll explore
    the essential dbt commands and selection syntax that allow you to execute, manage,
    and control various aspects of your dbt project. Whether running transformations,
    executing tests, or generating documentation, these commands are your toolkit
    for effective project management.
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了几个dbt命令，例如`dbt run`和`dbt test`，以及我们如何与CLI交互来执行它们。在本节中，我们将探讨使您能够执行、管理和控制dbt项目各个方面的基本dbt命令和选择语法。无论是运行转换、执行测试还是生成文档，这些命令都是您有效项目管理的工具包。
- en: Let’s start at the beginning. At its core, dbt is a command-line tool designed
    to streamline your data transformation workflows. It provides a set of commands
    that enable you to interact with your dbt project efficiently. Let’s explore each
    of these commands in more detail.
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从头开始。在其核心，dbt是一个旨在简化数据转换工作流程的命令行工具。它提供了一组命令，使您能够高效地与dbt项目交互。让我们更详细地探讨每一个这些命令。
- en: dbt run
  id: totrans-571
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: dbt run
- en: The `dbt run` command is your go-to tool for executing data transformations
    defined in your dbt models. It works with your project’s configuration files,
    such as *dbt_project.yml*, to understand which models to run and in what order.
    This command will identify the models that must be executed based on their dependencies
    and run them in the appropriate order.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt run`命令是执行您dbt模型中定义的数据转换的首选工具。它与项目的配置文件（如*dbt_project.yml*）一起工作，了解需要运行哪些模型以及以何种顺序运行它们。该命令将根据其依赖关系识别必须执行的模型，并以适当的顺序运行它们。'
- en: dbt test
  id: totrans-573
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: dbt test
- en: Ensuring the quality and reliability of your data is essential. The `dbt test`
    command lets you define and execute tests on your data models, verifying that
    they meet your business rules and expectations.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 确保数据的质量和可靠性至关重要。`dbt test`命令允许您定义和执行对数据模型的测试，验证它们是否符合您的业务规则和期望。
- en: dbt docs
  id: totrans-575
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: dbt docs
- en: Adequate documentation is essential for collaborative data projects. `dbt docs`
    automates the documentation generation for your dbt project, including model descriptions,
    column descriptions, and relationships between models. To generate the documentation,
    you need to execute `dbt docs generate`.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 充分的文档对于协作数据项目至关重要。`dbt docs`自动化生成您dbt项目的文档，包括模型描述、列描述和模型之间的关系。要生成文档，您需要执行`dbt
    docs generate`。
- en: dbt build
  id: totrans-577
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: dbt build
- en: Before running your dbt project, compiling it is often necessary. The `dbt build`
    command performs this task, creating the required artifacts for execution. This
    step is essential for optimizing the execution process and ensuring everything
    is in its proper place. Once your project compiles successfully, you can proceed
    with other commands like `dbt run` with more confidence.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行 dbt 项目之前，通常需要编译它。`dbt build` 命令执行此任务，为执行创建所需的工件。此步骤对于优化执行过程并确保一切就位至关重要。一旦项目成功编译，您可以更有信心地进行像
    `dbt run` 这样的其他命令。
- en: Other commands
  id: totrans-579
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他命令
- en: 'Although the preceding commands may be the most used, you should be aware of
    other dbt commands, such as these:'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管上述命令可能是最常用的，您还应该了解其他 dbt 命令，例如以下命令：
- en: '`dbt seed`'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt seed`'
- en: Loads raw data or reference data into your project
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 将原始数据或参考数据加载到您的项目中
- en: '`dbt clean`'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt clean`'
- en: Deletes artifacts generated by `dbt build`
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 删除由 `dbt build` 生成的工件
- en: '`dbt snapshot`'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt snapshot`'
- en: Takes a snapshot of your data for versioning
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 对您的数据进行版本控制快照
- en: '`dbt archive`'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt archive`'
- en: Archives tables or models to cold storage
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 存档表或模型至冷存储
- en: '`dbt deps`'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt deps`'
- en: Installs project dependencies defined in *packages.yml*
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 安装在 *packages.yml* 中定义的项目依赖项
- en: '`dbt run-operation`'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt run-operation`'
- en: Runs a custom operation defined in your project
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: 运行在项目中定义的自定义操作
- en: '`dbt source snapshot-freshness`'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt source snapshot-freshness`'
- en: Checks the freshness of your source data
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 检查您的源数据的新鲜度
- en: '`dbt ls`'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt ls`'
- en: Lists resources defined in a dbt project
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 列出在 dbt 项目中定义的资源
- en: '`dbt retry`'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt retry`'
- en: Re-runs the last run dbt command from the point of failure
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 从失败点重新运行最后一次运行的 dbt 命令
- en: '`dbt debug`'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt debug`'
- en: Runs dbt in debug mode, providing detailed debugging information
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 以调试模式运行 dbt，提供详细的调试信息
- en: '`dbt parse`'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt parse`'
- en: Parses dbt models without running them, which is helpful for syntax checking
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 解析 dbt 模型而不运行它们，这对于语法检查非常有用
- en: '`dbt clone`'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt clone`'
- en: Clones selected models from the specified state
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: 克隆从指定状态选择的模型
- en: '`dbt init`'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt init`'
- en: Creates a new dbt project in the current directory
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前目录中创建一个新的 dbt 项目
- en: Selection syntax
  id: totrans-607
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择语法
- en: As your dbt projects grow, you’ll need to target specific models, tests, or
    other resources for execution, testing, or documentation generation instead of
    running them all every time. This is where selection syntax comes into play.
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您的 dbt 项目的增长，您将需要针对特定模型、测试或其他资源进行执行、测试或文档生成，而不是每次运行所有资源。这就是选择语法发挥作用的地方。
- en: Selection syntax allows you to precisely specify which resources to include
    or exclude when running dbt commands. Selection syntax includes various elements
    and techniques, such as the following.
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 选择语法允许您在运行 dbt 命令时精确指定要包括或排除的资源。选择语法包括各种元素和技术，例如以下内容。
- en: Wildcard *
  id: totrans-610
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通配符 *
- en: The asterisk (*) represents any character or sequence of characters. Let’s have
    a look at [Example 4-33](#dbt_selection_syntax_all).
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: '星号 (*) 表示任何字符或字符序列。让我们看看 [示例 4-33](#dbt_selection_syntax_all)。 '
- en: Example 4-33\. Selection syntax with * wildcard
  id: totrans-612
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-33\. 使用 * 通配符的选择语法
- en: '[PRE32]'
  id: totrans-613
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Here, we’re using the * wildcard along with the `--select` flag to target all
    resources or models within the *core* directory. This command will execute all
    models, tests, or other resources located within that directory.
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: 在此，我们将 * 通配符与 `--select` 标志一起使用，以定位 *core* 目录中的所有资源或模型。此命令将执行该目录中的所有模型、测试或其他资源。
- en: Tags
  id: totrans-615
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 标签
- en: '*Tags* are labels you can assign to models, macros, or other resources in your
    dbt project—in particular, inside the YAML files. You can use selection syntax
    to target resources with specific tags. For instance, [Example 4-34](#dbt_selection_syntax_tag)
    shows how to select resources based on the `marketing` tag.'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: '*标签* 是您可以分配给 dbt 项目中模型、宏或其他资源的标签，特别是在 YAML 文件中。您可以使用选择语法来定位具有特定标签的资源。例如，[示例 4-34](#dbt_selection_syntax_tag)
    展示了如何基于 `marketing` 标签选择资源。'
- en: Example 4-34\. Selection syntax with a tag
  id: totrans-617
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-34\. 使用标签的选择语法
- en: '[PRE33]'
  id: totrans-618
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Model name
  id: totrans-619
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型名称
- en: You can precisely select a single model by using its name in the selection syntax,
    as shown in [Example 4-35](#dbt_selection_syntax_model).
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过选择语法中的模型名称精确选择单个模型，如 [示例 4-35](#dbt_selection_syntax_model) 所示。
- en: Example 4-35\. Selection syntax with a model
  id: totrans-621
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-35\. 使用模型的选择语法
- en: '[PRE34]'
  id: totrans-622
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Dependencies
  id: totrans-623
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 依赖关系
- en: Use the + and - symbols to select models that depend on or are depended upon
    by others. For example, `fct_orders+` selects models that depend on `fct_orders`,
    while `+fct_orders` selects models that `fct_orders` depends on ([Example 4-36](#dbt_selection_syntax_model_dependencies)).
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 使用+和-符号来选择依赖于或被其他模型依赖的模型。例如，`fct_orders+`选择依赖于`fct_orders`的模型，而`+fct_orders`选择`fct_orders`依赖的模型（[示例 4-36](#dbt_selection_syntax_model_dependencies)）。
- en: Example 4-36\. Selection syntax with dependencies
  id: totrans-625
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-36\. 使用依赖关系的选择语法
- en: '[PRE35]'
  id: totrans-626
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Packages
  id: totrans-627
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 包
- en: If you organize your dbt project into packages, you can use package syntax to
    select all resources within a specific package, as shown in [Example 4-37](#dbt_selection_syntax_package).
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 如果将您的dbt项目组织为包，您可以使用包语法来选择特定包中的所有资源，如[示例 4-37](#dbt_selection_syntax_package)所示。
- en: Example 4-37\. Selection syntax with a package
  id: totrans-629
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-37\. 使用包的选择语法
- en: '[PRE36]'
  id: totrans-630
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Multiple selections
  id: totrans-631
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多重选择
- en: You can combine elements of selection syntax to create complex selections, as
    shown in [Example 4-38](#dbt_selection_syntax_me).
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以组合选择语法的元素来创建复杂的选择，如[示例 4-38](#dbt_selection_syntax_me)所示。
- en: Example 4-38\. Selection syntax with multiple elements
  id: totrans-633
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 4-38\. 使用多个元素的选择语法
- en: '[PRE37]'
  id: totrans-634
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In this example, we combined elements such as tagging and model selection. It
    will run the dbt model named `fct_orders` only if it has the tag `marketing`.
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们结合了标记和模型选择等元素。它将仅在dbt模型名称为`fct_orders`且具有标签`marketing`时运行。
- en: Selection syntax allows you to control which dbt resources run based on various
    criteria, including model names, tags, and dependencies. You can use selection
    syntax with the `--select` flag to tailor your dbt operations to specific subsets
    of your project.
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 选择语法允许您基于各种标准（包括模型名称、标签和依赖关系）控制运行哪些dbt资源。您可以使用`--select`标志以选择语法定制您的dbt操作，以适应项目的特定子集。
- en: Additionally, dbt offers several other selection-related flags and options,
    such as `--selector`, `--exclude`, `--defer`, and more, which provide even more
    fine-grained control over how you interact with your dbt project. These options
    make it easier to manage and execute dbt models and resources in a way that aligns
    with your project’s requirements and workflows.
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，dbt还提供了几个其他与选择相关的标志和选项，如`--selector`、`--exclude`、`--defer`等，这些选项提供了更精细的控制，以便您与dbt项目的交互方式与项目的需求和工作流程保持一致。
- en: Jobs and Deployment
  id: totrans-638
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作业和部署
- en: Until now, we’ve been covering how to develop using dbt. We’ve learned about
    models and how to implement tests and write documentation, among other relevant
    components that dbt provides. We accomplished and tested all of this by utilizing
    our development environment and manually executing our dbt commands.
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在讨论如何使用dbt进行开发。我们学习了关于模型的知识，并且如何实施测试和编写文档，以及dbt提供的其他相关组件。通过利用我们的开发环境并手动执行dbt命令，我们完成并测试了所有这些工作。
- en: Using a development environment shouldn’t be minimized. It allows you to continue
    building your dbt project without affecting the deployment/production environment
    until you are ready. But now we have reached the stage where we need to productionize
    and automate our code. For that, we need to deploy our analytics code into a production
    branch, typically named the main branch, and into a dedicated production schema,
    such as `dbt_analytics_engineering.core` in BigQuery, or the equivalent production
    target in your data platform.
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: 使用开发环境不应该被忽视。它允许您在准备好之前继续构建dbt项目，而不会影响部署/生产环境。但现在我们已经达到了需要将我们的代码投入生产并自动化的阶段。为此，我们需要将我们的分析代码部署到生产分支，通常命名为主分支，并且部署到专用的生产模式中，例如BigQuery中的`dbt_analytics_engineering.core`，或者您数据平台中等效的生产目标。
- en: Finally, we need to configure and schedule a job to automate what we want to
    roll into production. Configuring a job is an essential part of the CI/CD process.
    It allows you to automate the execution of your commands in a cadence that fits
    your business needs.
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要配置并安排一个作业来自动化我们希望投入生产的内容。配置作业是CI/CD过程的重要部分。它允许您根据业务需求的节奏自动执行命令。
- en: To begin, let’s commit and sync everything we did until now into our development
    branch and then merge with the main branch. Click the “Commit and sync” button
    ([Figure 4-54](#deploy_commit_push)). Don’t forget to write a comprehensive message.
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将目前为止的所有工作提交并同步到我们的开发分支，然后与主分支合并。点击“提交和同步”按钮（[图 4-54](#deploy_commit_push)）。不要忘记写一条全面的消息。
- en: '![deploy commit push](assets/aesd_0454.png)'
  id: totrans-643
  prefs: []
  type: TYPE_IMG
  zh: '![deploy commit push](assets/aesd_0454.png)'
- en: Figure 4-54\. “Commit and sync” button
  id: totrans-644
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-54\. “提交并同步”按钮
- en: You may need to make a pull request. As explained briefly in [“Setting Up dbt
    Cloud with BigQuery and GitHub”](#setting_up_dbt_cloud), pull requests (PRs) play
    an essential role in collaborative development. They serve as a fundamental mechanism
    for communicating your proposed changes to your team. However, it’s crucial to
    understand that PRs are not just about notifying your colleagues of your work;
    they are a critical step in the review and integration process.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要发起一个拉取请求。如 [“在 BigQuery 和 GitHub 中设置 dbt Cloud”](#setting_up_dbt_cloud)
    中简要说明的那样，拉取请求（PR）在协作开发中发挥着重要作用。它们作为将您提议的更改传达给团队的基本机制。然而，理解 PR 并不仅仅是通知同事您的工作进展；它们是审查和集成过程中的关键步骤。
- en: When you create a PR, you are essentially inviting your team to review your
    code, provide feedback, and collectively decide whether these changes align with
    the project’s goals and quality standards.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: 当您创建 PR 时，实质上是邀请您的团队审查您的代码、提供反馈，并共同决定这些更改是否与项目的目标和质量标准一致。
- en: Getting back to our code, after your PR, merge it with your main branch in GitHub.
    Your final screen in GitHub should be similar to [Figure 4-55](#deploy_github_after_merge).
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的代码，在 PR 后，将其与 GitHub 上的主分支合并。您在 GitHub 上的最终屏幕应与图 4-55\. 类似。
- en: '![deploy GitHub after merge](assets/aesd_0455.png)'
  id: totrans-648
  prefs: []
  type: TYPE_IMG
  zh: '![合并后部署 GitHub](assets/aesd_0455.png)'
- en: Figure 4-55\. Pull request screen after merging with the main branch
  id: totrans-649
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-55\. 主分支合并后的拉取请求屏幕
- en: 'At this stage, your main branch should equal your development branch. Now it
    is time to deploy it into your data platform. Before creating a job, you need
    to set up your deployment environment:'
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，您的主分支应该与您的开发分支相同。现在是将其部署到数据平台的时候了。在创建作业之前，您需要设置您的部署环境：
- en: From the Deploy menu, click the Environments option and then click the Create
    Environment button. A screen will pop up where you can configure your deployment
    environment.
  id: totrans-651
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从部署菜单中，点击“环境”选项，然后点击“创建环境”按钮。会弹出一个屏幕，您可以在其中配置您的部署环境。
- en: Keep the latest dbt Version, and don’t check the option to run on a custom branch
    since we’ve merged our code into the main branch.
  id: totrans-652
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保留最新的 dbt 版本，并且不勾选在自定义分支上运行的选项，因为我们已将代码合并到了主分支。
- en: Name the environment “Deployment.”
  id: totrans-653
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将环境命名为“部署”。
- en: In the Deployment Credentials section, write the dataset that will link your
    deployment/production environment. We’ve named it `dbt_analytics_engineer_prod`,
    but you can use the name that best suits your needs.
  id: totrans-654
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“部署凭证”部分，编写将连接您的部署/生产环境的数据集。我们将其命名为 `dbt_analytics_engineer_prod`，但您可以根据需要选择最合适的名称。
- en: If everything goes well, you should have a deployment environment set up with
    configurations similar to those in [Figure 4-56](#deploy_environemnt).
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切顺利，您应该已经设置了一个与图 4-56\. 类似的部署环境配置。
- en: '![deployment environment settings](assets/aesd_0456.png)'
  id: totrans-656
  prefs: []
  type: TYPE_IMG
  zh: '![部署环境设置](assets/aesd_0456.png)'
- en: Figure 4-56\. Deployment environment settings
  id: totrans-657
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-56\. 部署环境设置
- en: 'Now it is time to configure your job. Inside the dbt Cloud UI, click the Jobs
    option in your Deploy menu and then click the Create New Job button. Creating
    a job can range from simple concepts to more complex ones. Let’s set up a job
    that will cover the main ideas that we’ve discussed:'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是配置作业的时候了。在 dbt Cloud UI 中，点击部署菜单中的“作业”选项，然后点击“创建新作业”按钮。创建作业可以涵盖从简单概念到更复杂的概念。让我们设置一个涵盖我们讨论过的主要思想的作业：
- en: Name the job ([Figure 4-57](#deploy_job_name)).
  id: totrans-659
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给作业命名（参见图 4-57\.）。
- en: '![job-name](assets/aesd_0457.png)'
  id: totrans-660
  prefs: []
  type: TYPE_IMG
  zh: '![作业名称](assets/aesd_0457.png)'
- en: Figure 4-57\. Defining the job name
  id: totrans-661
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-57\. 定义作业名称
- en: 'In the Environment section, we will point to the Deployment environment. Configure
    the dbt version to inherit from the version defined in the Deployment environment.
    Then leave the Target Name set as default. This is helpful if you would like to
    define conditions based on your work environment (for example: if in the deployment
    environment, do this; if in development, do that). Finally, we covered the Threads
    in [“profiles.yml”](#subchapt_profiles_yaml). Let’s keep it set to the default
    configuration. We didn’t create any Environment Variables, so this section will
    be left empty. [Figure 4-58](#deploy_job_environment) presents the overall Environment
    section configuration.'
  id: totrans-662
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在环境部分，我们将指向部署环境。将dbt版本配置为继承在部署环境中定义的版本。然后将目标名称设置为默认。如果您希望根据工作环境定义条件（例如：如果在部署环境中，则执行此操作；如果在开发环境中，则执行那个操作），这将非常有帮助。最后，我们在[“profiles.yml”](#subchapt_profiles_yaml)中覆盖了Threads。让我们将其保持为默认配置。我们没有创建任何环境变量，因此该部分将保持为空。[图 4-58](#deploy_job_environment)展示了整体环境部分的配置。
- en: '![job environment](assets/aesd_0458.png)'
  id: totrans-663
  prefs: []
  type: TYPE_IMG
  zh: '![作业环境](assets/aesd_0458.png)'
- en: Figure 4-58\. Defining the job environment
  id: totrans-664
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-58\. 定义作业环境
- en: '[Figure 4-59](#deploy_job_settings) shows the global configurations of the
    Execution Settings. We’ve set Run Timeout to 0, so dbt will never kill the job
    if it runs for more than a certain amount of time. Then we’ve also chosen “do
    not defer to another run.” Finally, we’ve selected the “Generate docs on run”
    and “Run source freshness” boxes. This configuration will reduce the number of
    commands you need to write in the Commands section. For this use case, we kept
    the default `dbt build` only.'
  id: totrans-665
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[图 4-59](#deploy_job_settings)显示了执行设置的全局配置。我们将运行超时设置为0，因此如果作业运行时间超过一定时间，dbt将不会终止作业。然后我们还选择了“不推迟到另一个运行”。最后，我们选中了“在运行时生成文档”和“运行源新鲜度”框。这个配置将减少您在Commands部分需要编写的命令数量。对于这个用例，我们仅保留了默认的`dbt
    build`。'
- en: '![job settings](assets/aesd_0459.png)'
  id: totrans-666
  prefs: []
  type: TYPE_IMG
  zh: '![作业设置](assets/aesd_0459.png)'
- en: Figure 4-59\. Defining job settings
  id: totrans-667
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-59\. 定义作业设置
- en: 'The last configuration setting is Triggers, in which you configure how to launch
    the job. There are three options to trigger a job:'
  id: totrans-668
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后的配置设置是**Triggers**，在这里您可以配置如何启动作业。有三种选项可以触发作业：
- en: A configured schedule inside dbt
  id: totrans-669
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在dbt中配置的计划
- en: Through Webhooks
  id: totrans-670
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Webhooks
- en: Through an API call
  id: totrans-671
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过API调用
- en: For this use case, we’ve chosen the Schedule option and set the schedule to
    run on an hourly basis, as shown in [Figure 4-60](#deploy_job_trigger).
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个用例，我们选择了**Schedule**选项，并将计划设置为每小时运行一次，如[图 4-60](#deploy_job_trigger)所示。
- en: '![job trigger](assets/aesd_0460.png)'
  id: totrans-673
  prefs: []
  type: TYPE_IMG
  zh: '![作业触发器](assets/aesd_0460.png)'
- en: Figure 4-60\. Defining the job trigger
  id: totrans-674
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-60\. 定义作业触发器
- en: It’s time to execute and see what happens. Save your job; then select Run Now
    or wait for the job to be automatically triggered after it hits the configured
    schedule.
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是执行并查看结果的时候了。保存您的作业；然后选择立即运行或者等待作业按照配置的计划自动触发。
- en: While the job runs, or after it finishes, you can always inspect the status
    and what was executed. From the Deploy menu, select the Run History option. You
    will see your job executions. Select one and take a look at the Run Overview.
    [Figure 4-61](#deploy_job_run_overview) is what you should expect to see.
  id: totrans-676
  prefs: []
  type: TYPE_NORMAL
  zh: 在作业运行时或运行结束后，您可以随时检查状态和执行内容。从部署菜单中，选择运行历史选项。您将看到作业的执行情况。选择其中一个并查看运行概览。[图 4-61](#deploy_job_run_overview)是您应该看到的内容。
- en: '![job run overview](assets/aesd_0461.png)'
  id: totrans-677
  prefs: []
  type: TYPE_IMG
  zh: '![作业运行概览](assets/aesd_0461.png)'
- en: Figure 4-61\. The job’s Run Overview screen
  id: totrans-678
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-61\. 作业运行概览屏幕
- en: Once inside the Run Overview, you have relevant information about the specific
    job execution, which could be helpful with potential troubleshooting issues. At
    the top is a summary of the job execution status, the person or system who triggered
    the job, the Git commit indexed to this job execution, the generated documentation,
    sources, and the environment where this job ran.
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦进入运行概览，您将获得有关特定作业执行的相关信息，这对于潜在的故障排除问题可能会有帮助。顶部显示作业执行状态的摘要，触发作业的人或系统，与此作业执行相关的Git提交，生成的文档，源和作业运行的环境。
- en: Right after the job summary, you can find the execution details, such as the
    time it took to execute the job and when it started and finished. Finally, one
    of the essential pieces of information that the Run Overview gives you is the
    Run Steps, which detail all the commands executed during the job execution and
    allow you to inspect each isolated step and its logs, as shown in [Figure 4-62](#deploy_job_run_steps_details).
    Exploring each step’s logs will enable you to understand what ran in each and
    look up issues during its execution.
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 在作业摘要之后，您可以找到执行细节，如执行作业所需的时间以及开始和结束的时间。最后，运行概述提供给您的其中一个关键信息是运行步骤，它详细列出了作业执行期间执行的所有命令，并允许您检查每个独立步骤及其日志，如
    [图 4-62](#deploy_job_run_steps_details) 所示。查看每个步骤的日志将帮助您了解每个步骤中运行的内容，并在执行过程中查找问题。
- en: '![job run step details](assets/aesd_0462.png)'
  id: totrans-681
  prefs: []
  type: TYPE_IMG
  zh: '![作业运行步骤详细信息](assets/aesd_0462.png)'
- en: Figure 4-62\. The job’s Run Steps details
  id: totrans-682
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-62\. 作业的运行步骤详细信息
- en: By using dbt jobs, you can easily automate your transformations and deploy your
    projects to production in an efficient and scalable way. Whether you are a data
    analyst, data engineer, or analytics engineer, dbt can help you address the complexity
    of your data transformations and ensure that your data models are always accurate
    and up-to-date.
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用 dbt 作业，您可以轻松自动化您的转换并以高效和可扩展的方式将项目部署到生产环境中。无论您是数据分析师、数据工程师还是分析工程师，dbt 都可以帮助您解决数据转换的复杂性，并确保您的数据模型始终准确和更新。
- en: Summary
  id: totrans-684
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter demonstrates that analytics engineering is an ever-evolving field
    that is always influenced by innovations. dbt is not just one aspect of this story;
    it is a crucial tool in the field.
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 本章表明，分析工程是一个不断受创新影响的不断发展的领域。dbt 不仅仅是这个故事的一个方面；它是该领域中的一个关键工具。
- en: The primary objective of analytics engineering is to convert raw data into valuable
    insights, and this tool plays a crucial role in simplifying the complexities of
    data transformation and promoting cooperation among a wide range of stakeholders.
    dbt ensures that data transformation is not just a technical change but also places
    great emphasis on openness, inclusivity, and knowledge sharing.
  id: totrans-686
  prefs: []
  type: TYPE_NORMAL
  zh: 分析工程的主要目标是将原始数据转化为有价值的见解，而此工具在简化数据转换的复杂性和促进各种利益相关者之间的合作中发挥着至关重要的作用。dbt 确保数据转换不仅是技术变革，还非常重视开放性、包容性和知识共享。
- en: dbt is renowned for its capacity to streamline complicated processes by effortlessly
    integrating with large data warehouses. It also promotes a collaborative approach
    to data transformation by ensuring optimal traceability and accuracy. Furthermore,
    it highlights the significance of thoroughly testing data processes to guarantee
    dependability. Its user-friendly interface reinforces the notion that analytics
    engineering is an inclusive field, welcoming contributions from individuals of
    all competency levels.
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: dbt 以其无缝集成大型数据仓库的能力而闻名。它还通过确保最佳可追溯性和准确性，促进数据转换的协作方法。此外，它强调彻底测试数据流程的重要性，以保证可靠性。其用户友好的界面强化了分析工程是一个包容性领域的观念，欢迎各种能力水平的个人贡献。
- en: To conclude, we strongly encourage analytics engineers who want to stay at the
    forefront of the industry to take a deep dive into this transformational tool.
    As dbt is increasingly important and unequivocally beneficial, being proficient
    in this tool can not only improve your skill set but also facilitate smoother
    and more cooperative data transformations in the future.
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，我们强烈建议希望保持行业前沿的分析工程师深入了解这个变革性工具。由于 dbt 的重要性日益增加且显而易见的好处，精通这个工具不仅可以提升您的技能，还可以促进未来更顺畅和更协作的数据转换。
