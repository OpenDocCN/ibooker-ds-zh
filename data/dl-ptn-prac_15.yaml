- en: 12 Data distributions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 数据分布
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Applying statistical principles of distributions in machine learning
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在机器学习中应用分布的统计原理
- en: Understanding the differences between curated and uncurated datasets
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解精选数据集和非精选数据集之间的差异
- en: Using population, sampling, and subpopulation distributions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用总体、抽样和子总体分布
- en: Applying distribution concepts when training a model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练模型时应用分布概念
- en: 'As a data scientist and educator, I get a lot of questions from software engineers
    on how to improve the accuracy of a model. The five basic answers I give out to
    increase the accuracy of a model are as follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家和教育工作者，我经常收到软件工程师关于如何提高模型准确性的问题。我给出的五个基本答案，以提高模型的准确性如下：
- en: Increase training time.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加训练时间。
- en: Increase the depth (or width) of the model.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加模型的深度（或宽度）。
- en: Add regularization.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加正则化。
- en: Expand the dataset with data augmentation.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过数据增强扩展数据集。
- en: Increase hyperparameter tuning.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加超参数调整。
- en: 'These are the five most likely places to address, and often working on one
    or another will improve model accuracy. But it’s important to understand that
    the limitations to accuracy ultimately lie in *the dataset used to train the model*.
    That’s what we are going to look at here: the nuances of datasets, and how and
    why they affect accuracy. And by *nuances*, I mean the distribution patterns of
    the data.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是最有可能需要解决的问题，并且通常解决其中之一或多个将提高模型准确性。但重要的是要理解，准确性的限制最终在于*用于训练模型的数据库集*。这正是我们要探讨的：数据集的细微差别，以及它们如何以及为什么会影响准确性。而“细微差别”指的是数据的分布模式。
- en: 'In this chapter, we do a deep dive into the three types of data distributions:
    population, sampling, and subpopulation. In particular, we will look at how these
    distributions affect the ability of the model to accurately generalize to data
    in the real world. The model’s accuracy, you’ll see, often differs from the predictions
    generated by the training or evaluation dataset, a difference referred to as serving
    skew and data drift.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨三种类型的数据分布：总体、抽样和子总体。特别是，我们将研究这些分布如何影响模型在现实世界中对数据的准确泛化能力。你会发现，模型的准确性通常与训练或评估数据集生成的预测不同，这种差异被称为服务偏差和数据漂移。
- en: In the second half of the chapter, we walk through a hands-on example of applying
    different data distributions to the same model during training, and see the differing
    outcomes, during inference, on real-world serving skew and data drift.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后半部分，我们将通过一个实际案例来展示如何在训练过程中将不同的数据分布应用于同一模型，并观察在推理阶段，对真实世界服务偏差和数据漂移的不同影响结果。
- en: To understand distributions and how they affect outcomes and accuracy, we need
    to go back to basic statistics, which you likely studied in high school or college.
    The term *model* was not created by AI, or by machine learning, or by any other
    newer development in computer technology. The term originates from statistics.
    As a software engineer, you’re used to coding an algorithm that generally has
    a many-to-one relationship between the input and output. We typically refer to
    this as the inputs having a *linear relationship* to the output—or in other words,
    the output is *deterministic*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解分布及其对结果和准确性的影响，我们需要回到基础统计学，这可能是你在高中或大学学过的。术语*模型*不是由人工智能、机器学习或任何其他计算机技术的新发展创造的。这个术语起源于统计学。作为一个软件工程师，你习惯于编写一个算法，该算法通常具有输入和输出之间的多对一关系。我们通常将这种关系称为输入与输出之间的*线性关系*——换句话说，输出是*确定的*。
- en: In statistics, the output is not deterministic, but a probability distribution.
    Let’s consider a coin toss. You cannot write an algorithm that will output the
    correct result of heads or tails on any single coin toss, because it is not deterministic.
    But you can *model* the probability distribution over a single, ten, or thousands
    of coin tosses.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计学中，输出不是确定的，而是一个概率分布。让我们考虑一下抛硬币的情况。你无法编写一个算法来输出任何单次抛硬币的正确结果（正面或反面），因为它不是确定的。但你可以*建模*单次、十次或上千次抛硬币的概率分布。
- en: 12.1 Distribution types
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 分布类型
- en: The field of statistics deals with algorithms that are not deterministic, but
    whose outcome is a probability distribution. As in our coin toss example, if I
    toss a coin two times, the outcome is not deterministic. Instead, there is a 50%
    probability that one toss is heads and one is tails, and a 25% probability for
    both tosses being heads and both tosses being tails, respectively. These algorithms
    are called *models*, and they model a behavior that makes an output (or outcome)
    of a prediction over a probability distribution. That sure sounds like statistics,
    right?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学领域处理的是非确定性算法，但其结果是概率分布。就像我们的抛硬币例子一样，如果我抛两次硬币，结果不是确定的。相反，一次抛出正面和一次抛出反面的概率是50%，两次都是正面的概率是25%，两次都是反面的概率也是25%。这些算法被称为*模型*，它们模拟一个行为，使得预测在概率分布上的输出（或结果）。
- en: 'In this section, we examine three of the distributions most often used in ML
    modeling: population, sampling, and subpopulation distributions. Our goal here
    is to see how each distribution affects the training of a deep learning model,
    especially its accuracy.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们考察了在机器学习建模中最常用的三种分布：总体分布、抽样分布和子总体分布。我们的目标是了解每种分布如何影响深度学习模型的训练，特别是它的准确性。
- en: The advent of deep learning using neural networks to develop models is from
    the field of artificial intelligence. In recent years, the two separate fields
    of statistical modeling and deep learning have fused together, and we now categorize
    both under machine learning. But whether you are doing what I refer to as classical
    machine learning (statistics) or deep learning with neural networks, the limitation
    in what you can model or learn comes down to the dataset.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用神经网络开发模型的深度学习出现于人工智能领域。近年来，统计建模和深度学习这两个独立的领域已经融合在一起，我们现在将它们都归类为机器学习。但无论你是在做我所说的经典机器学习（统计学）还是基于神经网络的深度学习，你能够建模或学习到的限制都归结于数据集。
- en: To look at these three distributions, we will use the MNIST dataset ([https://keras.io/datasets/](https://keras.io/datasets/)).
    This dataset is small enough that we can use it to demonstrate each of these concepts,
    as well as leave you with code samples that you can reproduce and use, to see
    with your own eyes why (and how) the data is the limitation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看这三个分布，我们将使用MNIST数据集([https://keras.io/datasets/](https://keras.io/datasets/))。这个数据集足够小，我们可以用它来演示这些概念，同时给你留下代码示例，你可以复制并使用这些代码，亲眼看到为什么（以及如何）数据是限制。
- en: 12.1.1 Population distribution
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.1 总体分布
- en: When you make a model and it turns out to not generalize as you expected “in
    the wild” (in production), one of the reasons is usually that you did not understand
    the population distribution of what you are modeling.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当你构建一个模型，结果发现它没有像你预期的那样在“野外”（在生产环境中）泛化，通常原因之一是你没有理解你所建模的总体分布。
- en: Let’s say you were building a model to predict the shoe size of an adult male
    in the United States based on physical characteristics (height, hair color, and
    so forth). The population distribution of this model would be *all* adult males
    in the United States. Let me emphasize *all*. When we say a *population distribution*,
    it has every single example in the population—the whole population. With a population
    distribution, we would know the complete distribution of shoe sizes and the corresponding
    features (height, hair color, and so forth).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在构建一个模型，根据身体特征（身高、发色等）预测美国成年男性的鞋码。这个模型的总体分布将是*所有*美国成年男性。让我强调*所有*。当我们说一个*总体分布*时，它包含人口中的每一个例子——整个人口。有了总体分布，我们就知道鞋码的完整分布以及相应的特征（身高、发色等）。
- en: 'The problem, of course, is that you won’t have data for all adult males in
    the United States. Instead, you will have a subset of data: we take batches of
    the data at random (which we call a *random sample*) to determine a distribution
    within the batch that you hope comes close to matching the distribution of the
    overall population.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，问题是，你不会拥有美国所有成年男性的数据。相反，你将拥有数据的一个子集：我们随机抽取数据的一批（我们称之为*随机样本*）来确定批次内的分布，你希望这个分布尽可能接近整体人口的分布。
- en: Figure 12.1 depicts random sampling within a population distribution. The outer
    circle, labeled *Population*, represents all examples in the population, such
    as in our example for shoe size of all adult males in the United States. The inner
    circle, labeled *Random Sample*, represents a randomly chosen subset of examples,
    such as a random chosen number of adult males in the United States. For the population
    distribution, we know things like the exact size (number of adult males), the
    mean (average shoe size), and standard deviation (percentage of different sizes).
    These are referred to in statistics as the *parameters* of the population, which
    is a deterministic distribution. Assuming we don’t have the population distribution,
    we want to use the random sample to estimate the parameters—which is called the
    *statistic*. The larger and more random the sample, the more likely our estimate
    will be closer to the parameters.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1展示了在总体分布内的随机抽样。外圈，标记为*总体*，代表总体中的所有例子，例如在我们关于美国所有成年男性鞋码的例子中。内圈，标记为*随机样本*，代表随机选择的一组例子，例如在美国随机选择的一定数量的成年男性。对于总体分布，我们知道诸如确切的大小（成年男性的数量）、平均值（平均鞋码）和标准差（不同尺寸的百分比）等信息。这些在统计学上被称为总体的*参数*，这是一个确定性分布。假设我们没有总体分布，我们希望使用随机样本来估计参数——这被称为*统计量*。样本越大、越随机，我们的估计就越有可能接近参数。
- en: '![](Images/CH12_F01_Ferlitsch.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH12_F01_Ferlitsch.png)'
- en: Figure 12.1 Population distribution and random sampling within the population
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1展示了总体分布及其内部的随机抽样
- en: 12.1.2 Sampling distribution
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.2 抽样分布
- en: The goal with a sampling distribution is to have enough random samples of the
    population so that, collectively, the distributions within these samples can be
    used to predict the distribution within the population as a whole, and thus we
    can generalize a model to a population. The keyword here is *predict*, meaning
    we are determining a probabilistic distribution from the samples versus a deterministic
    distribution from the population.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用抽样分布的目标是拥有足够多的来自总体的随机样本，这样，这些样本内部的分布可以共同用来预测整个总体的分布，从而我们可以将模型推广到总体。这里的关键词是*预测*，意味着我们从样本中确定一个概率分布，而不是从总体中确定一个确定性分布。
- en: Let’s take our shoe size example. If we had just one example, we probably could
    not adequately model the parameters of the distribution. But if we had a thousand
    examples, perhaps we could substantially increase our ability to model the parameters.
    But wait, what if those thousand were not really random—say they were collected
    from purchases at a professional athletic shoe store. Those examples would likely
    be biased to certain characteristics (features) of the nonrandom examples. So
    the examples in the sampling distribution need to be randomly selected.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以我们的鞋码例子为例。如果我们只有一个例子，我们可能无法充分地模拟分布的参数。但如果我们有一千个例子，我们可能能够显著提高模拟参数的能力。但是等等，如果那一千个例子并不是真正随机的——比如说它们是从专业运动鞋店的购买中收集的。这些例子可能会倾向于某些非随机例子的特征（特性）。因此，抽样分布中的例子需要是随机选择的。
- en: Figure 12.2 depicts a sampling distribution of a population. A *sampling distribution*
    consists of a collection of examples that have been randomly selected and are
    generally the same size. For example, we might have hired different survey companies
    to collect our shoe size data, with each using its own selection criteria. Each
    company collects the data on a hundred random examples, based on its selection
    criteria.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2描述了一个总体抽样分布。一个*抽样分布*由随机选择的一组例子组成，通常大小相同。例如，我们可能雇佣了不同的调查公司来收集我们的鞋码数据，每个公司使用自己的选择标准。每个公司根据其选择标准收集了一百个随机样本的数据。
- en: '![](Images/CH12_F02_Ferlitsch.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH12_F02_Ferlitsch.png)'
- en: Figure 12.2 Sampling distribution that predicts the parameters of a population
    distribution
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2：预测总体分布参数的抽样分布
- en: We can presume that each of these separate random samples is a weak predictor
    of the parameters of the population. Instead, we treat them as an ensemble. For
    example, if we take the average of each random sample mean, given enough random
    samples of enough size, we can more strongly predict the mean of the population.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以假设这些单独的随机样本是总体参数的弱预测器。相反，我们将它们视为一个整体。例如，如果我们取每个随机样本均值的平均值，给定足够数量和足够大小的随机样本，我们可以更准确地预测总体的均值。
- en: In general, the dataset you use to train a model is a sampling distribution,
    and the larger the sample size and the more random the examples, the more likely
    your model will generalize to the parameters of the population.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您用于训练模型的数据库是一个抽样分布，样本量越大，例子越随机，您的模型就越有可能推广到群体的参数。
- en: 12.1.3 Subpopulation distribution
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.3 子群体分布
- en: You need to understand that regardless of how large and comprehensive your dataset
    is, it is likely a sampling distribution of a subpopulation and not the population.
    A *subpopulation* is a subset of a population that is defined by a set of characteristics
    and that would not have the same probability distribution as the population. As
    in our earlier adult male shoe example, let’s assume our samples are all from
    a chain of stores that specialize in selling sports shoes to professional athletes.
    With sufficient samples, we can develop a sampling distribution that is representative
    and therefore predictive of the subpopulation of professional athletes, but it
    is unlikely to be representative of the entire population.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要理解，无论您的数据集有多大、多么全面，它很可能是一个子群体的抽样分布，而不是整个群体。子群体是群体的一部分，由一组特征定义，并且与群体的概率分布不同。例如，在我们的早期成年男性鞋类例子中，假设我们的样本都来自一家专门为职业运动员销售运动鞋的连锁店。有了足够的样本，我们可以开发出一个具有代表性的抽样分布，因此可以预测职业运动员的子群体，但它不太可能代表整个群体。
- en: This is not the same as a bias, as long as our intent is to model that subpopulation
    and not the population at large. A *bias* occurs when we draw from batches of
    random samples but, no matter how many we draw from, the corresponding sampling
    distribution will not be representative of the population we are modeling—because
    we drew the random samples from a subpopulation. Figure 12.3 shows a subpopulation
    distribution.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这与偏差不同，只要我们的意图是模拟该子群体而不是整个群体。当从随机样本批次中抽取时，会出现偏差，无论我们抽取多少，相应的抽样分布都不会代表我们正在模拟的群体——因为我们是从子群体中抽取的随机样本。图12.3展示了子群体分布。
- en: '![](Images/CH12_F03_Ferlitsch.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH12_F03_Ferlitsch.png)'
- en: Figure 12.3 Subpopulation distribution
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 子群体分布
- en: 12.2 Out of distribution
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 分布外
- en: Let’s assume you’ve trained a model and deployed it on a dataset, but it does
    not generalize to what it really sees in production as well as your evaluation
    data. This model is possibly seeing a different distribution of examples than
    what the model was trained on. We refer to this as being *out of distribution,
    also referred to as serving skew*. In other words, your model was trained on a
    subpopulation distribution that is different from what the deployed model sees.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您已经训练了一个模型并将其部署在数据集上，但它并没有像您的评估数据那样在生产中推广。这个模型可能看到了与训练时不同的例子分布。我们称这种情况为“分布外”，也称为“服务偏差”。换句话说，您的模型是在一个与部署模型看到的不同的子群体分布上训练的。
- en: In this section, we will use the MNIST dataset to demonstrate how to detect
    out-of-distribution populations when the model is deployed. Then we’ll explore
    approaches to improve the model to generalize to an out-of-distribution population.
    We first discussed the MNIST dataset in chapter 2\. We will start with a brief
    refresher on the dataset.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用MNIST数据集来演示在模型部署时如何检测分布外的群体。然后我们将探讨改进模型以推广到分布外群体的方法。我们已在第2章中首次讨论了MNIST数据集。我们将从对该数据集的简要回顾开始。
- en: 12.2.1 The MNIST curated dataset
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.1 MNIST精选数据集
- en: MNIST is a dataset of 70,000 images of handwritten digits that is proportionally
    balanced across each digit. It’s super easy to train a model to get near 100%
    accuracy on the dataset (hence it’s the “hello, world” example of machine learning).
    But almost all “in the wild” applications of the trained model will fail—because
    the distribution of images in MNIST is a subpopulation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST是一个包含70,000个手写数字图像的数据集，每个数字的比例平衡。训练一个模型以在数据集上达到接近100%的准确率非常容易（因此它是机器学习的“hello,
    world”示例）。但几乎所有的“实际应用”中的训练模型都会失败——因为MNIST中的图像分布是一个子群体。
- en: MNIST is a *curated* dataset. The data curator selected samples for inclusion
    whose characteristics meet a certain definition. In other words, a curated dataset
    is sufficiently representative of a subpopulation that it can model the parameters
    of that subpopulation, but otherwise may not be representative of the entire population
    (for example, all digits).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST是一个*精选*的数据集。数据管理员选择了符合一定定义的特征的样本进行包含。换句话说，精选数据集足以代表一个亚群体，可以对该亚群体的参数进行建模，但否则可能不代表整个群体（例如，所有数字）。
- en: In the case of MNIST, each sample is a 28-×-28-pixel image, with the drawing
    of the digit centered in the middle. The digit is white, and the background is
    gray, and a padding of at least 4 pixels is around the digit. Figure 12.4 shows
    the layout of a MNIST image. This instance of the digit 7 is just an arbitrary
    random selection from the dataset, which is used for example purposes only.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在MNIST的情况下，每个样本是一个28-×-28像素的图像，数字的绘制位于中间。数字是白色的，背景是灰色的，数字周围至少有4像素的填充。图12.4显示了MNIST图像的布局。这个数字7的实例只是从数据集中随机选择的任意随机选择，仅用于示例目的。
- en: '![](Images/CH12_F04_Ferlitsch.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH12_F04_Ferlitsch.png)'
- en: Figure 12.4 The layout of a MNIST image
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 MNIST图像的布局
- en: 12.2.2 Setting up the environment
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.2 设置环境
- en: 'Let’s first do what I call *housekeeping*. The following is a code snippet
    we will use throughout our examples. It includes importing the TF.Keras API for
    designing and training models, various Python libraries we will use, and, finally,
    the loading of the MNIST dataset that is prebuilt into the TF.Keras API:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们做一下我所说的*家务管理*。以下是我们将在所有示例中使用的代码片段。它包括导入TF.Keras API以设计和训练模型，我们将使用的各种Python库，以及最后，加载预建在TF.Keras
    API中的MNIST数据集：
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Gets the built-in dataset for MNIST
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取MNIST的内置数据集
- en: 'The dataset from Keras is in a generic format, so we need to do some initial
    data preparation to use it for training either a DNN or a CNN. This preparation
    includes the following:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Keras的数据集是通用格式，因此我们需要进行一些初始数据准备，以便用于训练DNN或CNN。这些准备包括以下内容：
- en: The pixel data (`x_train` and `x_test`) contains the original INT8 values (0
    to 255). We will normalize the pixel data to be from 0 to 1 as a FLOAT32.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 像素数据（`x_train`和`x_test`）包含原始INT8值（0到255）。我们将像素数据归一化到0到1的FLOAT32。
- en: The image data matrices are of shape *Height* × *Width* (*H* × *W*). Keras expects
    tensors in the shape of *Height* × *Width* × *Channel*. These are grayscale images,
    so we will reshape the train and test data to (*H* × *W* × 1).
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像数据矩阵的形状为*高度* × *宽度* (*H* × *W*)。Keras期望张量的形状为*高度* × *宽度* × *通道*。这些是灰度图像，因此我们将训练和测试数据调整为(*H*
    × *W* × 1)。
- en: We are also going to set aside a copy of the test and training data before it’s
    been prepared (which we discuss in section 12.2.3).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备（我们将在12.2.3节中讨论）之前，我们将留出一份数据集的测试和训练数据的副本。
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Sets aside a copy of the original training and test data
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 留出原始训练和测试数据的副本
- en: ❷ Normalizes the pixel data and casts to 32-bit float
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将像素数据归一化并转换为32位浮点数
- en: ❸ Reshapes into H × W × 1 for TF.Keras model API
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 调整形状以符合TF.Keras模型API
- en: 12.2.3 The challenge (“in the wild”)
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.3 挑战（在野外）
- en: In addition to randomly choosing test data (known as the *holdout set*) from
    this curated dataset, we will also create two more test datasets as examples of
    what the trained model may see in the wild. These two additional datasets, known
    as the *inverted set* and the *sifted set*, will contain examples that are not
    represented by the training data. In other words, the original MNIST dataset is
    one subpopulation of the population of digits, and our two new datasets are different
    subpopulations of digits. The inverted and sifted sets have a different distribution
    than the MNIST dataset, and so we refer to them as being *out of distribution*
    relative to the MNIST dataset.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 除了从这个精选数据集中随机选择测试数据（称为*保留集*）之外，我们还将创建另外两个测试数据集，作为展示训练模型在野外可能看到的示例。这两个额外的数据集，称为*反转集*和*筛选集*，将包含训练数据未表示的示例。换句话说，原始MNIST数据集是数字群体中的一个亚群体，而我们这两个新的数据集是数字的不同亚群体。反转集和筛选集的分布与MNIST数据集不同，因此我们称它们相对于MNIST数据集为*分布外*。
- en: We will use these two additional test datasets to demonstrate how the model
    will fail, and to find ways we might modify the training and dataset to overcome
    this, and the limitations. What constitutes each set?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这两个额外的测试数据集来展示模型将如何失败，并找到我们可能修改训练和数据集以克服这些局限性的方法。每个集合由什么构成？
- en: '*Inverted set*—The pixel data is inverted such that the images are now gray
    digits on a white background.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*倒置集*——像素数据被倒置，使得图像现在是在白色背景上的灰色数字。'
- en: '*Shifted set*—The images are shifted 4 pixels to the right, and thus are not
    centered anymore. Since there is at least a padding of 4 pixels, none of the digits
    will be clipped.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*平移集*——图像向右平移了4个像素，因此不再居中。由于至少有4个像素的填充，没有任何数字会被裁剪。'
- en: Figure 12.5 is an example of a single test image from the original test data,
    the inverted test data, and the shifted test data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5是从原始测试数据、倒置测试数据和平移测试数据中选取的单个测试图像的示例。
- en: '![](Images/CH12_F05_Ferlitsch.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH12_F05_Ferlitsch.png)'
- en: Figure 12.5 The original and in the wild out-of-distribution examples
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 原始和野外分布外的示例
- en: 'In this code, we make our two additional test datasets from the copy of the
    original test dataset:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，我们从原始测试数据集的副本中创建了两个额外的测试数据集：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ The “in the wild” inverted data
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ “野外”倒置数据
- en: ❷ The “in the wild” shifted data
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ “野外”平移数据
- en: 12.2.4 Training as a DNN
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.4 作为DNN进行训练
- en: We will start by training a model based on the as-is MNIST subpopulation, compare
    the accuracy to the holdout set that is from the same subpopulation, and finally
    test and compare them against the out-of-distribution data.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先基于现有的MNIST子集训练一个模型，将准确率与来自同一子集的保留集进行比较，最后测试并比较它们与野外分布数据。
- en: 'MNIST is so easy we can build a classifier with 97%+ accuracy with a DNN. The
    next code example is a function for constructing simple DNNs, consisting of the
    following:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST非常简单，我们可以用DNN构建一个97%+准确率的分类器。下一个代码示例是一个构建简单DNN的函数，包括以下内容：
- en: The parameter `nodes` is a list specifying the number of nodes per layer.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数`nodes`是一个列表，指定每层的节点数。
- en: The input to the DNN are images in the shape 28 × 28 × 1
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DNN的输入是形状为28 × 28 × 1的图像
- en: The input is flattened into a 1D vector of length 784.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入被展平成一个长度为784的1D向量。
- en: There is an optional dropout (for regularization) after each layer.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个层后都有一个可选的dropout（用于正则化）。
- en: The last dense layer of 10 nodes with a softmax activation function is the classifier.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一个有10个节点的密集层，带有softmax激活函数，是分类器。
- en: '![](Images/CH12_F06_Ferlitsch.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH12_F06_Ferlitsch.png)'
- en: Figure 12.6 The configurable DNN architecture for the MNIST model
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 MNIST模型的可配置DNN架构
- en: Figure 12.6 illustrates the configurable DNN architecture for this example.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6展示了本例中可配置的DNN架构。
- en: '[PRE3]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Function for constructing simple DNNs
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建简单DNN的函数
- en: ❷ Compiles the DNN for a multiclass classifier
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 编译多类分类器的DNN
- en: For our first test, we will train the dataset on a single layer (excluding the
    output layer) of 512 nodes. Figure 12.7 depicts the corresponding architecture.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第一次测试中，我们将数据集在一个包含512个节点的单层（不包括输出层）上进行训练。图12.7展示了相应的架构。
- en: '![](Images/CH12_F07_Ferlitsch.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH12_F07_Ferlitsch.png)'
- en: Figure 12.7 The single-layer, 512-node DNN for our first MNIST model to train
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 我们第一个MNIST模型的单层、512节点DNN
- en: 'Here is the code for building, training, and evaluating the model for our first
    test:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是构建、训练和评估我们第一次测试模型的代码：
- en: '[PRE4]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Trains the model on MNIST
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在MNIST上训练模型
- en: ❷ Evaluates the trained model
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 评估训练好的模型
- en: 'The output from the `summary()` method will look like this:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`summary()`方法的输出将如下所示：'
- en: '[PRE5]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The number of trainable parameters is a measurement of the complexity of our
    model, which is 408,000 parameters. We train it for a total of 10 epochs (we feed
    the entire training data through the model 10 times). The following is the output
    from the training. The training accuracy quickly reaches 99%+, and our accuracy
    on the test (holdout) data is nearly 98%.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 可训练参数的数量是我们模型复杂度的衡量标准，共有408,000个参数。我们总共训练了10个epoch（我们将整个训练数据通过模型输入10次）。以下是从训练中得到的输出。训练准确率迅速达到99%+，我们在测试（保留）数据上的准确率接近98%。
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'So far, it looks good. Let’s now try the model on the inverted and shifted
    test datasets:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，看起来不错。现在让我们尝试在倒置和平移的测试数据集上使用模型：
- en: '[PRE7]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Evaluates the model on the out-of-distribution inverted dataset
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在野外分布的倒置数据集上评估模型
- en: ❷ Evaluates the model on the out-of-distribution shifted dataset
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在野外分布的平移数据集上评估模型
- en: 'The following is the output. Our accuracy on the inverted dataset is only 2%,
    and on the shifted dataset, it does better but only 41%:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从测试中得到的输出。我们在倒置数据集上的准确率仅为2%，在平移数据集上表现较好，但只有41%：
- en: '[PRE8]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: What happened? For the inverted dataset, it looks like our model learned the
    gray background and the whiteness of the digit as part of the digit recognition.
    Thus, when we inverted the data, the model totally failed to classify it.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 发生了什么？对于反转数据集，看起来我们的模型将灰色背景和数字的纯度作为数字识别的一部分来学习。因此，当我们反转数据时，模型完全无法对其进行分类。
- en: For the shifted dataset, a dense layer does not preserve spatial relationships
    between the pixels. Each pixel is a unique feature. Thus, even the shift of a
    few pixels was enough to dramatically drop the accuracy.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于移动数据集，密集层没有保留像素之间的空间关系。每个像素都是独特的特征。因此，即使像素的微小移动也足以大幅降低准确率。
- en: So to improve the accuracy, we might try to increase the number of nodes in
    the input layer—the more nodes, the better learning. Let’s repeat the same test
    with 1024 nodes. Figure 12.8 depicts the corresponding architecture.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了提高准确率，我们可能尝试增加输入层的节点数量——节点越多，学习效果越好。让我们用1024个节点重复相同的测试。图12.8展示了相应的架构。
- en: '![](Images/CH12_F08_Ferlitsch.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH12_F08_Ferlitsch.png)'
- en: Figure 12.8 The wider, single-layer, 1024-node DNN for our second MNIST model
    to train
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 为我们的第二个MNIST模型训练的更宽的单层1024节点深度神经网络
- en: 'Here is the code for building, training, and evaluating the model for our second
    test:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是构建、训练和评估第二个测试模型的代码：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ The number of nodes is doubled (widened).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 节点数量加倍（变宽）。
- en: 'The output from `model.summary()` is as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.summary()`的输出如下：'
- en: '[PRE10]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You can see that by doubling the number of nodes on the input layer, we double
    the computational complexity (the number of trainable parameters). Let’s see if
    this improves the accuracy on our alternate test data.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，通过将输入层的节点数量加倍，我们也将计算复杂度（可训练参数的数量）加倍。让我们看看这能否提高我们替代测试数据的准确率。
- en: 'Nope, we see a marginal increase on the inverted dataset to about 5%, but it’s
    so low that’s probably just noise, and the accuracy on the shifted dataset is
    about the same at 40%. So increasing the number of nodes in the input layer (widening)
    did not aid in either filtering out (not learning) the background and whiteness
    of the digits or learning the spatial relationships:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 没有，我们在反转数据集上看到了微小的提升，大约5%，但这太低了，可能只是噪声，而在移动数据集上的准确率大约相同，为40%。所以增加输入层的节点数量（变宽）并没有帮助过滤掉（未学习）数字的背景和纯度，也没有学习空间关系：
- en: '[PRE11]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Another approach we might try is to increase the number of layers (deepening).
    This time, let’s make the DNN with two 512-node layers. Figure 12.9 depicts our
    model architecture.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种我们可能尝试的方法是增加层数（变深）。这次，让我们使用两个512节点的层。图12.9展示了我们的模型架构。
- en: '![](Images/CH12_F09_Ferlitsch.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH12_F09_Ferlitsch.png)'
- en: Figure 12.9 The deeper two-layer DNN (512 + 512 nodes) for our third MNIST model
    to train
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 为我们的第三个MNIST模型训练的更深的两层深度神经网络（512 + 512个节点）
- en: 'Here is the code for building, training, and evaluating the model for our third
    test:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是构建、训练和评估第三个测试模型的代码：
- en: '[PRE12]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Increases the number of layers (deepen)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 增加层数（变深）
- en: 'The ending output from `model.summary()`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.summary()`的输出结果：'
- en: '[PRE13]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let’s see if this improves the accuracy on our alternate test data:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这能否提高我们替代测试数据的准确率：
- en: '[PRE14]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We see another slight increase in the shifted dataset to 10%. But did it really
    improve? We have 10 classes (digits). If we made random guesses, we would be right
    10% of the time. This is still purely a random outcome—nothing learned here. Looks
    like adding layers did not aid in learning the spatial relationships either.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在移动数据集上看到了另一个轻微的提升，达到10%。但这真的有所改善吗？我们有10个类别（数字）。如果我们随机猜测，我们会有10%的时间猜对。这仍然是一个纯粹随机的结果——这里没有学习到任何东西。看起来增加层并没有帮助学习空间关系。
- en: Another approach would be to add some regularization to prevent overfitting
    the model to the training data and be more generalized. We will use the same two-layer
    DNN of 512 nodes per layer, and add a 50% dropout after the first layer and 25%
    dropout after the second layer. It used to be a common practice to use a higher
    dropout at the first layer, which is learning coarse features, and to use a smaller
    dropout at subsequent layers, which are learning finer features. Figure 12.10
    shows the model architecture.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法可能是添加一些正则化，以防止模型过度拟合训练数据并使其更具泛化能力。我们将使用每层512节点的相同两层深度神经网络，并在第一层后添加50%的dropout，在第二层后添加25%的dropout。过去，在第一层使用更高的dropout（学习粗糙特征）和在后续层使用较小的dropout（学习更精细的特征）是一种常见的做法。图12.10显示了模型架构。
- en: '![](Images/CH12_F10_Ferlitsch.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH12_F10_Ferlitsch.png)'
- en: Figure 12.10 The DNN with dropout added to improve generalizing
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.10 添加dropout以改善泛化的DNN
- en: 'Here is the code for building, training, and evaluating the model for our fourth
    test:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是构建、训练和评估我们第四次测试模型的代码：
- en: '[PRE15]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Adds dropout for regularization
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 添加dropout进行正则化
- en: 'Let’s see if this improves the accuracy on our alternate test data:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这能否提高我们备用测试数据上的准确率：
- en: '[PRE16]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Nope, no improvement. Thus, widening a layer, deepening layers, and regularization
    did not help in training the model to recognize the digits in the out-of-distribution
    test datasets. Perhaps the issue is that a DNN is just not the right type of model
    architecture to generalize to an out-of-distribution model. Next, we will try
    a CNN and see what happens.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 没有改进。因此，加宽层、加深层和正则化并没有帮助模型在分布外的测试数据集中识别数字。也许问题在于DNN根本不是泛化到分布外模型的正确模型架构。接下来，我们将尝试CNN并看看会发生什么。
- en: 12.2.5 Training as a CNN
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.5 作为CNN的训练
- en: OK, now let’s test the accuracy of the three datasets in a convolutional neural
    network. With convolutional layers, we should at least learn the spatial relationships.
    Perhaps the convolutional layers will filter out the background as well as the
    whiteness of the digits.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在让我们在一个卷积神经网络中测试三个数据集的准确率。有了卷积层，我们至少应该学会空间关系。也许卷积层会过滤掉背景以及数字的白色。
- en: 'The following code constructs our CNNs as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码按照以下方式构建我们的CNN：
- en: The parameter `filters` is a list specifying the number of filters per convolution.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数`filters`是一个列表，指定每个卷积的过滤器数量。
- en: The inputs to the CNN are images in the shape 28 × 28 × 1.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN的输入是形状为28 × 28 × 1的图像。
- en: A max pooling reduces the feature map sizes by 75% after each convolution.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次卷积后，最大池化将特征图大小减少75%。
- en: A dropout (regularization) of 25% occurs after each convolution/max pooling
    layer.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个卷积/最大池化层之后发生25%的dropout（正则化）。
- en: The last dense layer of 10 nodes with a softmax activation function is the classifier.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一个具有10个节点和softmax激活函数的密集层是分类器。
- en: '[PRE17]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Function for constructing simple CNNs
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建简单CNN的函数
- en: ❷ Compiles the CNN for a multiclass classifier
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 编译CNN以进行多类分类器
- en: Let’s start with a CNN with a single convolutional layer of 16 filters. Figure
    12.11 illustrates the model architecture.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从具有单个16个过滤器的卷积层的CNN开始。图12.11说明了模型架构。
- en: '![](Images/CH12_F11_Ferlitsch.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH12_F11_Ferlitsch.png)'
- en: Figure 12.11 The single-layer CNN for our MNIST training
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.11 用于MNIST训练的单层CNN
- en: 'Here is the code for building, training, and evaluating the model for our first
    test with a CNN:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们使用CNN进行第一次测试的构建、训练和评估模型的代码：
- en: '[PRE18]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Constructs the CNN with 16 filters
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建具有16个过滤器的CNN
- en: 'The output from `model.summary()`is as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.summary()`的输出如下：'
- en: '[PRE19]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here is the result from our training of the CNN:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们CNN训练的结果：
- en: '[PRE20]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: You can see we can get comparable accuracy (98%) on the test data with a CNN
    with a lot fewer trainable parameters (27,000 versus more than 400,000).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，我们可以使用具有许多更少的可训练参数的CNN（27,000个参数与超过400,000个参数相比）在测试数据上获得相当准确的准确率（98%）。
- en: 'Let’s see if this improves the accuracy on our alternate test data:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这能否提高我们备用测试数据上的准确率：
- en: '[PRE21]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Yes, it made a measurable difference. We went from a previous high of 10% accuracy
    on the inverted dataset to 50% accuracy. Thus, it does seem the convolutional
    layers help filter out (not learn) the background or whiteness of the digits.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这确实产生了可测量的差异。我们从之前倒置数据集上的10%准确率提高到50%准确率。因此，卷积层似乎有助于过滤（而不是学习）数字的背景或白色。
- en: But it’s still far too low in accuracy. For the shifted dataset, we increased
    to 57%. That’s still below our target, but we can also see that now the convolutional
    layers are learning the spatial relationships. So, what did we learn here? Well,
    if you have the wrong model architecture, it does not matter how deeper or wider
    you make the model, or how much regularization you add; the model will not generalize
    to out-of-distribution test data. We also learned that a CNN not only better generalizes,
    but is also a lot more efficient in parameters, and in our first test, we did
    it with only a stem and no learner component.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 但准确率仍然太低。对于偏移数据集，我们将其提高到57%。这仍然低于我们的目标，但我们也可以看到，现在卷积层正在学习空间关系。那么，我们在这里学到了什么呢？嗯，如果你有一个错误的模型架构，无论你如何加深或加宽模型，或者添加多少正则化，模型都不会泛化到分布外的测试数据。我们还了解到，CNN不仅泛化得更好，而且在参数方面也更为高效，在我们的第一次测试中，我们只使用了茎而没有学习组件。
- en: 'If one convolutional layer improved things, let’s see how much better we can
    do with two convolutional layers. We will use two layers: the first with 16 filters
    and the second with 32 filters. It’s a common practice to double the number of
    filters as you get successively deeper into a CNN. Figure 12.12 depicts our model
    architecture.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个卷积层能改善事情，那么让我们看看使用两个卷积层我们能做得更好。我们将使用两层：第一层有16个过滤器，第二层有32个过滤器。随着CNN逐渐加深，加倍过滤器数量是一种常见的做法。图12.12展示了我们的模型架构。
- en: '![](Images/CH12_F12_Ferlitsch.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH12_F12_Ferlitsch.png)'
- en: Figure 12.12 The deeper two-layer CNN for our MNIST training
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.12 深度两层CNN用于MNIST训练
- en: 'Here is the code for building, training, and evaluating the model for our second
    test with a CNN:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是构建、训练和评估我们第二次测试中CNN模型的代码：
- en: '[PRE22]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Constructs a two-layer CNN
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建一个两层CNN
- en: 'Here is the result from our training of the CNN:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的CNN训练结果：
- en: '[PRE23]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Again, we get comparable accuracy, with slight improvement to ~99% on the test
    data. Let’s see whether adding convolutional layers will improve the accuracy
    on our alternate test data:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们在测试数据上获得了相当准确的精度，略有提升，达到约99%。让我们看看添加卷积层是否能够提高我们在替代测试数据上的精度：
- en: '[PRE24]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We do see some incremental improvement. Our inverted dataset went up to 63%.
    So it’s learning to better filter out the background and whiteness of the digits,
    but it’s still not there. Our shifted dataset test jumped to 76%. So you can see
    how convolutional layers are learning the spatial relationships in the digits
    versus the position in the image (compared to a DNN).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实看到了一些渐进的改进。我们的反转数据集上升到63%。因此，它正在学习更好地过滤掉数字的背景和白色，但仍然没有达到目标。我们的平移数据集测试跃升至76%。所以你可以看到卷积层是如何学习数字的空间关系与图像中的位置（与DNN相比）。
- en: 12.2.6 Image augmentation
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.6 图像增强
- en: Finally, let’s use image augmentation to try to improve on generalizing to the
    out-of-distribution alternate test data. Recall that *image augmentation* is a
    process of generating new samples from existing samples by making small modifications.
    These modifications would not change what the image would be classified as, and
    the image would be still recognized by the human eye as being of that class.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们使用图像增强来尝试改进对分布外替代测试数据的泛化。回想一下，*图像增强*是一个通过在现有样本上进行小修改来生成新样本的过程。这些修改不会改变图像的分类，而且图像仍然会被人类眼睛识别为那个类别。
- en: Figure 12.13 depicts an example of image augmentation, in which an image of
    a cat was randomly rotated and then cropped and resized back to the original shape.
    The picture is still recognizable by the human eye as a cat.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.13展示了图像增强的一个示例，其中一张猫的图片被随机旋转，然后裁剪并调整大小回到原始形状。这张图片仍然可以被人类眼睛识别为猫。
- en: '![](Images/CH12_F13_Ferlitsch.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH12_F13_Ferlitsch.png)'
- en: Figure 12.13 Image augmentation pipeline to generate examples with randomly
    selected translations
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.13 使用随机选择的平移生成的图像增强示例管道
- en: In addition to adding more samples to the training set, certain types of augmentation
    can aid in generalizing the model to accurately classify images outside the test
    (holdout) dataset that it would’ve otherwise failed on.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 除了向训练集中添加更多样本外，某些类型的增强可以帮助模型泛化，以便准确分类测试（保留）数据集之外的图像，否则模型可能会在这些图像上失败。
- en: As we saw on our CNN, we still had insufficient accuracy on shifted images;
    thus our model has not fully learned the spatial relationships of the digits separate
    from the location and background in the image. We could add more filters and convolutional
    layers in an attempt to increase the accuracy on shifted images. This would make
    the model more computationally complex and longer to train, and have a larger
    memory print and longer latency when deployed to do predictions (inference).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在CNN中看到的，我们在平移图像上仍然缺乏足够的精度；因此，我们的模型还没有完全学会将数字的空间关系从图像中的位置和背景中分离出来。我们可以添加更多过滤器并增加卷积层，以尝试提高平移图像上的精度。这将使模型更复杂，训练时间更长，并且在部署进行预测（推理）时会有更大的内存占用和更长的延迟。
- en: Alternately, we are going to improve the model by using image augmentation to
    randomly shift the image left or right up to 20%. Since our images are 28 pixels
    wide, 20% would mean that the image gets shifted a maximum of 6 pixels in either
    direction. We have a minimum of a 4-pixel boundary, so there will be little to
    no clipping of the digits.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们将通过使用图像增强来随机左右移动图像最多20%来改进模型。由于我们的图像宽度为28像素，20%意味着图像在任一方向上最多移动6像素。我们有一个最小4像素的边界，因此数字的裁剪将很少或没有。
- en: 'We will use the `ImageDataGenerator` class in TF.Keras to do the image augmentation.
    In the following code example, we do the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用TF.Keras中的`ImageDataGenerator`类来进行图像增强。在下面的代码示例中，我们执行以下操作：
- en: Create the same CNN model as before.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建与之前相同的CNN模型。
- en: Instantiate an `ImageDataGenerator` generator object whose parameter `width_
    shift_range=0.2` will augment the dataset during training by randomly shifting
    images +/– 20%.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实例化一个`ImageDataGenerator`生成器对象，其参数`width_shift_range=0.2`将在训练期间通过随机左右移动图像+/-
    20%来增强数据集。
- en: Invoke the `fit_generator()` method to train the model using our image augmentation
    generator with our existing training data.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用`fit_generator()`方法，使用我们的图像增强生成器和现有的训练数据来训练模型。
- en: 'Specify the number of `steps_per_epoch` in the generator as the number of training
    samples divided by the batch size; otherwise, the generator would loop indefinitely
    on the first epoch:'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生成器中指定`steps_per_epoch`的数值为训练样本数除以批大小；否则，生成器将在第一个epoch上无限循环：
- en: '[PRE25]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: ❶ Instantiates generator for randomly shifting images +/– 20%
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 实例化随机左右移动图像 +/- 20%的生成器
- en: ❷ Trains the model using the image augmentation
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用图像增强训练模型
- en: 'The following is the result from our training of the CNN:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们对CNN训练的结果：
- en: '[PRE26]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Let’s see if this improves the accuracy on the out-of-distribution test data:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这能否提高分布外测试数据的准确率：
- en: '[PRE27]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Wow, our accuracy on the shifted data is now nearly 98%. So we were able to
    train the model to learn the spatial relationships of digits when they shifted
    in the image without increasing the complexity of the model. But we did not see
    any improvement yet on the inverted data.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，现在我们在移动数据上的准确率接近98%。所以我们能够训练模型学习数字在图像中移动时的空间关系，而不会增加模型的复杂性。但在倒置数据上我们还没有看到任何改进。
- en: Let’s now tackle training the model to filter out the background and whiteness
    of the digits to improve the model’s ability to generalize to the out-of-distribution
    inverted test data. In the following code, we take 10% of the training data (`x_train_
    copy[0:6000]`) and invert it as we did with the test data. Why 10% instead of
    the whole training data? When we want to train a model to filter out something,
    we generally can do it with as little as 10% of the distribution of the entire
    training data.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来训练模型，以过滤掉数字的背景和白色，以提高模型泛化到分布外倒置测试数据的能力。在下面的代码中，我们像测试数据那样取了10%的训练数据(`x_train_copy[0:6000]`)并对其进行倒置。为什么是10%而不是全部训练数据？当我们想要训练一个模型来过滤掉某些东西时，我们通常可以用整个训练数据分布的10%来完成。
- en: 'Next we combine the original training data with the additional inverted training
    data by appending the two training sets together—both `x_train` (the data) and
    `y_train` (the labels—for a total of 66,000 images (versus 60,000) in our training
    set:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将原始训练数据与额外的倒置训练数据合并，将两个训练集连接在一起——包括`x_train`（数据）和`y_train`（标签——在我们的训练集中总共66,000张图像（与60,000张相比）：
- en: '[PRE28]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: ❶ Selects 10% of the (copy of) training data and inverts it
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从（副本）训练数据中选择10%并对其进行倒置
- en: ❷ Selects the same 10% of the corresponding labels
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 选择相同的10%的对应标签
- en: ❸ Combines the two training datasets into a single training set
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将两个训练数据集合并成一个训练集
- en: ❹ Trains the model with the combined training dataset
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用合并的训练数据集训练模型
- en: 'Here is the result from our training of the CNN:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们对CNN训练的结果：
- en: '[PRE29]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Let’s see if this improves the accuracy on our alternate test data:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这能否提高我们备用测试数据的准确率：
- en: '[PRE30]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Wow, our test accuracy on the inverted images is nearly 96%.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，我们在倒置图像上的测试准确率接近96%。
- en: 12.2.7 Final test
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.7 最终测试
- en: As a final test, I randomly selected “in the wild” images of a handwritten single
    digit from a Google image search. These included images that were colored, drawn
    with a felt-tip pen, painted with a paintbrush, and drawn in crayon by a young
    child. After I did my testing, I got only 40% accuracy with the CNN we just trained
    in this chapter.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的测试，我从谷歌图片搜索中随机选择了一些手写单个数字的“野外”图像。这些图像包括用彩色绘制的、用圆珠笔绘制的、用画笔绘制的以及由小孩子用蜡笔绘制的图像。在我完成测试后，我使用本章训练的CNN只得到了40%的准确率。
- en: Why only 40%, and how would we diagnose the cause? The question should be what
    subpopulation distribution did the model learn? Did the model learn to generalize
    the contours of the digits independent of the contrast to the background, or did
    it simply learn that digits are either white or black? What would happen if we
    tested with a black digit on a gray background (instead of white)?
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么只有40%，我们该如何诊断原因？问题应该是模型学习了哪个子群体分布？模型是否学会了独立于背景对比的数字轮廓的泛化，还是它只是学会了数字要么是白色要么是黑色？如果我们用黑色数字在灰色背景上（而不是白色）进行测试会发生什么？
- en: The training and test data from MNIST are digits drawn with a pen or pencil,
    so the lines are thin. Some of my “in the wild” images were thicker, made by a
    felt-tip pen, paintbrush, or crayon. Did the model learn to generalize the thickness
    of the lines? What about texture? The crayon- and paint-drawn digits had uneven
    texture; were these differences in texture learned as edges in the convolutional
    layers?
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST的训练和测试数据是用笔或铅笔绘制的数字，所以线条很细。我的一些“野外”图像线条较粗，是用圆珠笔、画笔或蜡笔绘制的。模型是否学会了泛化线条的粗细？关于纹理呢？用蜡笔和颜料绘制的数字有粗糙的纹理；这些纹理差异是否作为边缘在卷积层中被学习？
- en: As a final example, say you developed a model for use in a factory to detect
    defects in parts. The camera is in a fixed position with its perspective over
    a gray conveyor belt that has ridges running down it. All works well until one
    day the owner replaces the conveyor belt with a smooth yellow belt to add some
    color to the factory, and now the defect detection model fails. What happened?
    Well, because the gray conveyor belt was in all the training images, it would’ve
    become part of the learned features in the latent space, before entering the task
    learner (the classifier). This is similar to the classic case of dogs versus wolves,
    in which all the wolf pictures were taken in the winter. In this classic case,
    when the trained model was given a picture of a dog with snow in the background
    (out of distribution), the model predicted *wolf*. The model simply learned in
    that case that *snow* means *wolf*.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的例子，假设你开发了一个用于在工厂中检测零件缺陷的模型。相机位于一个固定的位置，其视角覆盖着一个有凹槽的灰色输送带。一切正常，直到有一天，所有者用一条光滑的黄色输送带来替换它，以给工厂增添一些色彩，现在缺陷检测模型失败了。发生了什么？好吧，因为灰色输送带在所有训练图像中，它就会成为潜在空间中学习特征的一部分，在进入任务学习器（分类器）之前。这类似于经典的狗与狼的案例，其中所有的狼照片都是在冬天拍摄的。在这个经典案例中，当训练模型被给了一张背景有雪的狗的照片（分布外）时，模型预测的是*狼*。在这种情况下，模型只是学会了*雪*意味着*狼*。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A sampling distribution models the parameters of a population distribution.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本分布模型了一个群体分布的参数。
- en: A subpopulation distribution models a bias, which is a subportion, of the population
    distribution.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子群体分布模型了一个偏差，这是群体分布的一个子部分。
- en: If you trained on a subpopulation distribution, and your model does not generalize
    in production on the examples it sees, the production data is likely out of distribution
    from the subpopulation you trained. This is also referred to as serving skew.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你在一个子群体分布上进行训练，并且你的模型在生产中对它看到的例子没有泛化，那么生产数据很可能超出了你训练的子群体分布。这也被称为服务偏差。
- en: Adding deeper or wider layers and/or more regularization generally will not
    help generalizing to an out-of-distribution population.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加更深或更宽的层以及/或更多的正则化通常不会帮助泛化到分布外的群体。
- en: Generating training samples from image augmentation can aid in generalizing
    to an out-of-distribution population in some cases.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从图像增强中生成训练样本有时可以帮助泛化到分布外的群体。
- en: When image augmentation is insufficient to generalize, you will need to add
    training examples from the out-of-distribution subpopulation.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当图像增强不足以泛化时，你需要添加来自分布外子群体的训练示例。
