- en: 9 Data analysis using GPU computing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 使用 GPU 计算进行数据分析
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Using GPU architectures to improve many data analysis algorithms
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GPU 架构改进许多数据分析算法
- en: Using Numba to convert Python code to efficient GPU low-level code
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Numba 将 Python 代码转换为高效的 GPU 低级代码
- en: Writing highly parallel GPU code to work on matrices
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写高度并行的 GPU 代码以处理矩阵
- en: Using GPU-native data analysis libraries from Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用来自 Python 的 GPU 原生数据分析库
- en: 'Graphics processing units (GPUs) were originally designed to make graphics
    applications more efficient: drawing and animation software, computer-aided design,
    and, of course, games!'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图形处理单元（GPUs）最初是为了使图形应用程序更高效而设计的：绘图和动画软件、计算机辅助设计和当然，游戏！
- en: At some point, it became clear that GPUs could not only do graphics processing
    but could also be used to do all kinds of computing, hence the appearance of general-purpose
    computing on graphics processing units (GPGPUs). GPUs are attractive because they
    have substantially more computing power than CPUs. They have been successfully
    used for many applications, such as scientific computing and artificial intelligence.
    They have massive applications in data science and in making computing more efficient
    in general.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时候，变得很明显，GPU 不仅能够进行图形处理，还可以用于各种计算，因此出现了通用计算在图形处理单元（GPGPUs）上的应用。GPU 吸引人的地方在于它们比
    CPU 具有更多的计算能力。它们已经在许多应用中取得了成功，例如科学计算和人工智能。它们在数据科学和使计算更有效方面有巨大的应用。
- en: GPGPUs use the architecture and programming paradigms imposed by the hardware
    of the GPUs and are built with two key considerations in mind. First, they need
    to do a lot of computation because graphics are very data-intensive. Second, they
    need to process many similar data points simultaneously, as every pixel in a graphics
    multiprocessor is computed at the same time. These requirements have a big effect
    on GPU design. For example, GPUs have many, many processing units, typically in
    the thousands, that are doing mostly similar tasks at the same time. In contrast,
    a typical CPU has a handful of processing units, each one doing different things
    at the same point in time. Processing speed in GPUs comes from the sheer number
    of processing units. In fact, each individual core is not very fast, at least
    compared to a CPU core. GPUs are thus massively parallel.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: GPGPUs 使用 GPU 硬件强加的架构和编程范式，并考虑了两个关键因素。首先，它们需要做大量的计算，因为图形非常数据密集。其次，它们需要同时处理许多相似的数据点，因为图形多处理器中的每个像素都是在同一时间计算的。这些需求对
    GPU 设计有很大影响。例如，GPU 有许多、许多处理单元，通常有数千个，它们同时在执行大多数相似的任务。相比之下，典型的 CPU 只有几个处理单元，每个处理单元在相同的时间点执行不同的事情。GPU
    的处理速度来自处理单元的数量。实际上，每个单独的核心并不非常快，至少与 CPU 核心相比。因此，GPU 是高度并行的。
- en: These crucial hardware differences mean that coding for GPUs is very different
    from coding for CPUs. It is not just a matter of recompiling existing code. Coding
    for GPUs, at least when we take care of it explicitly, implies a massive paradigm
    shift in how we think as programmers.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这些关键的硬件差异意味着为 GPU 编码与为 CPU 编码非常不同。这不仅仅是一个重新编译现有代码的问题。为 GPU 编码，至少当我们明确关注它时，意味着我们在程序员思维模式上发生了巨大的范式转变。
- en: 'GPU computing can be advantageous for data analysis, but many people give up
    learning to code for GPUs due to the different mindset it requires. So this chapter
    focuses on the most important step in coding for high-performance GPU computing:
    the transition to that new way of thinking. Unlike the other chapters in this
    book, I will treat this as more of an introduction to an approach and a way of
    thinking. As such, I’ll simplify the material to some degree and skip details.
    We will not discuss some important topics like thread synchronization, and we
    will assume trivially parallelizable problems so we can focus on understanding
    the programming paradigm instead. Many problems in data science are actually trivial
    to parallelize, so the material here is quite applicable to our field.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 计算在数据分析中可能具有优势，但许多人因为需要不同的思维方式而放弃学习为 GPU 编码。因此，本章重点介绍高性能 GPU 编码中最重要的一步：转向那种新的思维方式。与本书中的其他章节不同，我将将其视为一种方法和思维方式介绍的更多。因此，我将在一定程度上简化材料并跳过细节。我们不会讨论一些重要的话题，如线程同步，并且我们将假设可以轻易并行化的问题，这样我们就可以专注于理解编程范式。数据科学中的许多问题实际上很容易并行化，因此这里的内容对我们的领域非常适用。
- en: 'Tip You can get more in-depth information on GPU computing from other sources.
    I recommend NVIDIA’s CUDA C++ Programming Guide ([http://mng.bz/61Bp](http://mng.bz/61Bp)).
    While geared for C and C++, the first four chapters will provide you with a mostly
    language-agnostic perspective on GPU architectures and programming concepts. Part
    3 of *Parallel and High Performance Computing* by Bob Robey and Yuliana Zamora
    (Manning, 2021) is dedicated to GPUs; you can read chapter 9, “GPU Architectures
    and Concepts,” for free by following this link: [http://mng.bz/oJ6y](http://mng.bz/oJ6y).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士：您可以从其他来源获取更多关于 GPU 计算的深入信息。我推荐 NVIDIA 的 CUDA C++ 编程指南 ([http://mng.bz/61Bp](http://mng.bz/61Bp))。虽然它针对
    C 和 C++，但前四章将为您提供对 GPU 架构和编程概念的多数语言无关的视角。Bob Robey 和 Yuliana Zamora 的《并行与高性能计算》（Manning，2021）的第三部分专门介绍
    GPU；您可以通过以下链接免费阅读第 9 章，“GPU 架构和概念”：[http://mng.bz/oJ6y](http://mng.bz/oJ6y)。
- en: We will start by looking at GPU architectures and their implications on algorithm
    and software development. I’ll assume no prior knowledge and show you how GPUs
    work.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从查看 GPU 架构及其对算法和软件开发的影响开始。我将假设您没有先前的知识，并展示 GPU 的工作原理。
- en: Because Python code cannot be run on GPUs directly, we will use Numba, which
    is a translator of Python to machine code that works with both GPUs and CPUs.
    Numba takes your Python code and compiles it at run time to a lower-level representation
    that is compatible with either your CPU or GPU. You can find an introduction to
    Numba in appendix B. Our examples will deploy Python code on the GPU explicitly.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Python 代码不能直接在 GPU 上运行，我们将使用 Numba，它是一种将 Python 转换为机器代码的翻译器，它适用于 GPU 和 CPU。Numba
    在运行时将您的 Python 代码编译为与您的 CPU 或 GPU 兼容的更低级表示。您可以在附录 B 中找到 Numba 的介绍。我们的示例将明确在 GPU
    上部署 Python 代码。
- en: After we are done with the hard part, which is fundamental to start understanding
    the programming model of GPUs, we will then make use of high-level data analysis
    libraries. While you can program GPUs directly, you can also use GPUs through
    libraries, which take care of most implementation details for you. Here, you will
    be using GPUs implicitly as external libraries will deploy computation on GPUs.
    For example, we will replace NumPy with CuPy. As we will see, even though libraries
    remove most of the burden of running code on GPUs, it is not simply a matter of
    replacing the library. Let’s start by understanding GPU architectures from the
    perspective of the necessary changes in coding paradigms and performance.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成困难的部分，即理解 GPU 编程模型的基础之后，我们将利用高级数据分析库。虽然您可以直接编程 GPU，但您也可以通过库使用 GPU，这些库为您处理了大多数实现细节。在这里，您将隐式地使用
    GPU，因为外部库将在 GPU 上部署计算。例如，我们将用 CuPy 替换 NumPy。正如我们将看到的，尽管库消除了在 GPU 上运行代码的大部分负担，但这并不仅仅是替换库的问题。让我们从理解编码范式和性能所需的必要变化的角度开始理解
    GPU 架构。
- en: Note This chapter requires access to a GPU—namely, a recent NVIDIA GPU (i.e.,
    Pascal architecture or newer). Thus, this chapter is vendor-dependent. While I
    would prefer to do vendor-agnostic content, the reality is that GPU computing
    happens mostly on top of NVIDIA GPUs using the CUDA architecture. This is especially
    important in the Python world with libraries like CuPy or cuDF. If you want to
    research vendor-agnostic ways to do GPGPU computing, check out OpenCL ([https://www.khronos.org/opencl/](https://www.khronos.org/opencl/))
    or Vulkan ([https://www.vulkan.org/](https://www.vulkan.org/)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章需要访问 GPU——即最新的 NVIDIA GPU（即 Pascal 架构或更新的架构）。因此，本章依赖于供应商。虽然我更愿意进行供应商无关的内容，但现实是
    GPU 计算主要在 NVIDIA GPU 上使用 CUDA 架构进行。这在 Python 世界中尤为重要，例如 CuPy 或 cuDF 这样的库。如果您想研究供应商无关的
    GPGPU 计算方法，请查看 OpenCL ([https://www.khronos.org/opencl/](https://www.khronos.org/opencl/))
    或 Vulkan ([https://www.vulkan.org/](https://www.vulkan.org/))).
- en: You will have to make sure that your installation has all the required NVIDIA
    drivers to do GPGPU computing. You will need to install the CUDA toolkit, along
    with CuPy, to run software on this chapter. This can be done in conda with `conda
    install -c rapidsai -c nvidia -c numba -c conda-forge cupy cudatoolkit`. There
    is a Docker image for GPU processing called `tiagoantao/python-performance-gpu`.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须确保您的安装具有进行 GPGPU 计算所需的全部 NVIDIA 驱动程序。您需要安装 CUDA 工具包以及 CuPy，以便在本章中运行软件。这可以通过
    conda 完成，命令为 `conda install -c rapidsai -c nvidia -c numba -c conda-forge cupy
    cudatoolkit`。有一个名为 `tiagoantao/python-performance-gpu` 的用于 GPU 处理的 Docker 镜像。
- en: 9.1 Making sense of GPU computing power
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 理解 GPU 计算能力
- en: GPUs can, for some classes of algorithms, perform orders of magnitude better
    than CPUs. In this section, we will look at GPU architectures with the objective
    of understanding when and why GPUs can be more efficient for data analysis problems.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些类别的算法，GPU可以比CPU表现得更好几个数量级。在本节中，我们将探讨GPU架构，目的是了解何时以及为什么GPU在数据分析问题中可以更有效率。
- en: 9.1.1 Understanding the advantages of GPUs
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 理解GPU的优势
- en: To understand why GPUs are so efficient, we will present a simplified conceptual
    model of CPU and GPU execution using a practical example. The objective of this
    simple example is to give you insight into why GPUs perform so well for many,
    but only certain classes of, parallel problems.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解为什么GPU如此高效，我们将通过一个实际例子来展示一个简化的CPU和GPU执行的概念模型。这个简单例子的目的是让你了解为什么GPU在许多，但只有某些类别的并行问题中表现如此出色。
- en: 'Consider the simple problem of getting an array of 100 elements and returning
    a doubled version of it:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这样一个简单的问题：获取一个包含100个元素的数组，并返回其加倍版本：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you have a naive single-threaded and single-core CPU, the low-level implementation,
    such as a pseudocode assembler, for the previous code could be:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个简单的单线程单核CPU，那么前面代码的低级实现，例如伪代码汇编器，可能是这样的：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ① Gets the first element of the array A and puts it into a register called TMPVAR
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ① 将数组A的第一个元素取出并放入一个名为TMPVAR的寄存器中
- en: ② Doubles the value in the register
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将寄存器中的值加倍
- en: ③ Puts the value of the register in the first position of array B
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 将寄存器的值放入数组B的第一个位置
- en: This pseudocode gets the first element of the array `A` into a register, doubles
    its value, and puts it on the first element of array `B`. This is repeated for
    all 100 elements of our array.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个伪代码将数组`A`的第一个元素放入寄存器中，将其值加倍，并将其放在数组`B`的第一个元素上。这会重复进行，直到我们的数组中的所有100个元素。
- en: 'Now, remember from chapter 6 that retrieving values from main memory is an
    *extremely* expensive operation. Assume here that our naive CPU has no cache.
    Our read and write operations, `TMPVAR = A[0]` and `B[0] = TMPVAR`, take 90 units
    of time each, and our doubling operation, `TMPVAR = 2 * TMPVAR`, takes 2 units
    of time. We have 100 reads, 100 writes, and 100 doublings: 100*90 + 100*90 + 100*2\.
    This adds up to 18,200 units of time. Remember, too, that our naive CPU is sequential,
    so one operation can only start after the previous operation is complete.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，记得从第6章中提到的，从主存中检索值是一个*极其*昂贵的操作。这里假设我们的简单CPU没有缓存。我们的读取和写入操作`TMPVAR = A[0]`和`B[0]
    = TMPVAR`每个都需要90个时间单位，我们的加倍操作`TMPVAR = 2 * TMPVAR`需要2个时间单位。我们有100次读取，100次写入和100次加倍：100*90
    + 100*90 + 100*2。这总共是18,200个时间单位。记住，我们的简单CPU是顺序的，所以一个操作只能在之前的操作完成后才能开始。
- en: 'Now imagine a completely different execution model where you have 100 threads
    running in parallel, and *each* thread does a single memory read, followed by
    a single doubling and, finally, a single write. Let’s assume that the cost of
    reading and writing is the same: 90 time units. But the cost of doubling is substantially
    more expensive; we have a lot of computing units, so they are slower by the unit—say,
    40 time units.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一个完全不同的执行模型，其中你有100个线程并行运行，并且*每个*线程执行一次内存读取，然后是一次加倍操作，最后是一次写入。假设读取和写入的成本相同：90个时间单位。但是加倍的成本要高得多；我们有大量的计算单元，所以它们按单位来说较慢——比如说，40个时间单位。
- en: So *all* threads emit a memory read request at the same time. One hundred time
    units later, *all* threads receive their data and then take 40 time units to perform
    the computation. Remember, all threads are operating in parallel at the same time
    and are independent of each other. Finally, they write to memory in parallel at
    100 time units of cost. The total cost is 100 + 40 + 100 = 240 time units.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，*所有*线程同时发出内存读取请求。100个时间单位后，*所有*线程收到数据，然后花费40个时间单位进行计算。记住，所有线程都是同时并行操作的，并且彼此独立。最后，它们以100个时间单位的成本并行写入内存。总成本是100
    + 40 + 100 = 240个时间单位。
- en: 'So, our “CPU” takes 18,200 time units whereas our “GPU” takes 240 time units:
    making the “GPU” roughly 75 times faster. However, if you only wanted to make
    the operation on a *single* value, then the “CPU” would take 202 time cycles,
    whereas the “GPU” would take 240 time cycles.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的“CPU”需要18,200个时间单位，而我们的“GPU”只需要240个时间单位：这使得“GPU”大约快75倍。然而，如果你只想对一个*单个*值进行操作，那么“CPU”将需要202个时间周期，而“GPU”将需要240个时间周期。
- en: This example should provide you with some insight into the advantages and disadvantages
    of GPU computing. In essence, GPUs are great for dealing with memory latency and
    doing similar operations on lots of data, but they are not efficient at dealing
    with single operations. To use a metaphor, we can compare a CPU with a Ferrari
    and a GPU with a bus. If you only need to transport 5 people, the Ferrari will
    beat the bus. But if you need to transport 500 people, it’s not even a fair competition.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子应该能让你对GPU计算的优势和劣势有所了解。本质上，GPU非常适合处理内存延迟以及在大量数据上执行类似操作，但它们在处理单个操作方面效率不高。用比喻来说，我们可以将CPU比作法拉利，将GPU比作公交车。如果你只需要运送5个人，法拉利会打败公交车。但如果你需要运送500人，这甚至不是一场公平的竞争。
- en: 'One of the biggest obstacles that many developers face when learning or using
    GPUs is overcoming their intuitive feeling that most code should be sequential.
    While it’s true that a lot of code is sequential, many, if not most, of the *expensive*
    parts of the computation are very parallel. The quintessential example is pixels
    on a screen. There are 2 million pixels on an HD screen with a resolution of 1920
    × 1080\. Each pixel is processed independently, and thus we could, at least in
    theory, process all those pixels in parallel. Or consider N-dimensional arrays,
    which are exactly the type of data structures used in data science: each element
    of the array can be computed separately and thus all elements can potentially
    be computed in parallel. So GPUs are very applicable to many problems of interest.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发者在学习或使用GPU时面临的最大障碍之一是克服他们直观的感觉，即大多数代码应该是顺序的。虽然确实有很多代码是顺序的，但许多（如果不是大多数）计算中的*昂贵*部分是非常并行的。一个典型的例子是屏幕上的像素。一个分辨率为1920
    × 1080的HD屏幕上有200万个像素。每个像素都是独立处理的，因此，至少在理论上，我们可以并行处理所有这些像素。或者考虑N维数组，这正是数据科学中使用的数据结构类型：数组的每个元素都可以单独计算，因此所有元素都可以潜在地并行计算。所以GPU非常适合许多有趣的问题。
- en: To get a clearer understanding of why GPUs are appropriate for highly parallel
    problems, we need to look more closely at the architecture of these machines.
    We will do just that in the next section.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更清楚地了解为什么GPU适合高度并行的问题，我们需要更仔细地研究这些机器的架构。我们将在下一节中这样做。
- en: 9.1.2 The relationship between CPUs and GPUs
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2 CPU和GPU之间的关系
- en: The computation model of a GPU is very different from a CPU. To program a GPU
    efficiently—actually, to program a GPU at all—we need to understand the underlying
    architecture and how it is different from what we are used to.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: GPU的计算模型与CPU非常不同。为了有效地编程GPU——实际上，为了编程GPU——我们需要了解其底层架构以及它与我们所习惯的不同之处。
- en: 'The GPU is, for all intents and purposes, a co-processor. The CPU is the main
    processor, and code for it controls the top level of the computation. The nomenclature
    surrounding GPU computing makes this relationship quite clear: the *host* refers
    to the CPU, and the *device* is the GPU. The code in the host drives the overall
    computing process.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从所有意义上讲，GPU都是一个协处理器。CPU是主处理器，为其编写的代码控制计算的最高层。围绕GPU计算术语的命名清楚地说明了这种关系：*主机*指的是CPU，而*设备*是GPU。主机中的代码驱动整体计算过程。
- en: Most important from a performance perspective, for the overwhelming majority
    of CPU and GPU architectures, the CPU and GPU have different memory banks that
    are separated from each other. We thus have *host memory* (i.e., the memory available
    in the host) and *device memory* (i.e., the memory available in the GPU).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从性能角度来看，对于绝大多数CPU和GPU架构，CPU和GPU有不同的内存银行，它们彼此分离。因此，我们有*主机内存*（即主机可用的内存）和*设备内存*（即GPU可用的内存）。
- en: '![](../Images/CH09_F01_Antao.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F01_Antao.png)'
- en: Figure 9.1 The CPU and GPU have separate memory spaces. We need to transfer
    our data to the memory associated with the GPU for computation and then get our
    results back into the CPU-associated memory, which can cost a substantial amount
    of time.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 CPU和GPU有独立的内存空间。我们需要将我们的数据传输到与GPU相关的内存中进行计算，然后将结果传输回与CPU相关的内存，这可能会花费大量时间。
- en: The cost of transferring data to and from the GPU memory can have a massive
    effect on performance, especially if the amount of computation that we do on the
    GPU is limited. Figure 9.1 depicts this relationship.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据传输到GPU内存以及从GPU内存中传输数据的成本可以对性能产生巨大影响，尤其是如果我们GPU上的计算量有限时。图9.1描绘了这种关系。
- en: GPU vendors and software portability
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: GPU供应商和软件可移植性
- en: 'Before we discuss the internal architecture of GPUs, I want to make a point
    about GPU vendors and software portability. There are two main vendors of GPUs
    for general-purpose computing: NVIDIA and AMD. In theory, there are vendor-agnostic
    interfaces that allow us to program in a non–vendor-dependent way. If you are
    interested in being vendor agnostic, you can check out software solutions for
    that, such as OpenCL or the Vulkan compute API.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论GPU的内部架构之前，我想就GPU供应商和软件可移植性提出一个观点。对于通用计算，有两个主要的GPU供应商：NVIDIA和AMD。从理论上讲，存在无供应商特定的接口，允许我们以非供应商依赖的方式编程。如果您对无供应商特定感兴趣，您可以查看相关的软件解决方案，例如OpenCL或Vulkan计算API。
- en: The practical reality is that NVIDIA almost completely dominates the general-purpose
    computing market. That can be seen at a lower-level programming for GPUs with
    the dominance of NVIDIA’s Compute Unified Device Architecture (CUDA), as well
    as at the Python level, where many data analysis libraries supporting GPUs are
    CUDA based such as CuPy, CuDF, cuML, and BlazingSQL.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 实际情况是，NVIDIA几乎完全主导了通用计算市场。这可以从GPU的底层编程中看出，NVIDIA的Compute Unified Device Architecture
    (CUDA)占主导地位，以及在Python级别，许多支持GPU的数据分析库都是基于CUDA的，例如CuPy、CuDF、cuML和BlazingSQL。
- en: In this chapter we will be solely NVIDIA/CUDA based in terms of APIs. However,
    from a conceptual perspective, the information is transferable to the AMD space
    as well as vendor-agnostic libraries.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将仅基于NVIDIA/CUDA的API。然而，从概念上讲，这些信息也可以转移到AMD空间以及无供应商特定的库中。
- en: 'The problem with vendor dependence extends into the nomenclature: vendor-agnostic
    terminology can be different from NVIDIA terminology. I will try to present vendor-agnostic
    terms in as much as possible, but I will give NVIDIA equivalents when those have
    become common terms.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 供应商依赖的问题延伸到了术语学：无供应商特定的术语可能与NVIDIA的术语不同。我将尽可能多地展示无供应商特定的术语，但当我遇到已经成为通用术语的NVIDIA等效术语时，我会给出相应的NVIDIA术语。
- en: The trouble with naming is further complicated because, adding to vendor-specific
    terminology, there are some words that are based on the graphics origins of GPUs.
    For example, a CUDA core is also a streaming processor—not to be confused with
    streaming multiprocessor—and a shader.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 命名的问题进一步复杂化，因为除了供应商特定的术语外，还有一些基于GPU图形起源的词汇。例如，CUDA核心也是一个流处理器——不要与流式多处理器混淆——以及着色器。
- en: 9.1.3 The internal architecture of GPUs
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3 GPU的内部架构
- en: GPUs have several streaming multiprocessors (SMs). The number can vary from
    1 to 30 or even more. Each SM is composed of many streaming processors (SPs),
    which are sometimes called CUDA cores. Each SM has many SPs. See figure 9.2 for
    a simplified overview of the main GPU components.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: GPU有几个流式多处理器（SMs）。数量可以从1到30甚至更多。每个SM由许多流处理器（SPs）组成，有时也称为CUDA核心。每个SM有许多SPs。参见图9.2以了解主要GPU组件的简化概述。
- en: For example, a NVIDIA RTX 2070 is based on the NVIDIA Turing 106 GPU, which
    has 36 SMs, each with 64 CUDA Cores for a total of 2304 CUDA cores; this GPU is
    like having the ability to run 2,304 threads simultaneously. As I said previously,
    we are opting here for simplification, as the architecture is substantially more
    complicated. Of particular importance for data science are the new tensor cores
    that can be used for AI computation; we will not cover these in this chapter,
    but you might want to research them for more advanced usage.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，NVIDIA RTX 2070基于NVIDIA Turing 106 GPU，该GPU有36个SM（Streaming Multiprocessors，流式多处理器），每个SM有64个CUDA核心，总共2304个CUDA核心；这个GPU就像能够同时运行2,304个线程。正如我之前所说的，我们在这里选择简化，因为架构实际上要复杂得多。对于数据科学来说，特别重要的是可以用于AI计算的新的张量核心；我们不会在本章中涵盖这些内容，但您可能想要研究它们以用于更高级的使用。
- en: 'Memory organization is also important: each SM has a certain amount of L1 cache
    (check chapter 6 for cache concepts) that can be shared across all SPs in the
    same SM. We will not be making direct use of the L1 cache, which can be used to
    share states across threads running on the same SM. There is also L2 cache, which
    is shared by all SMs, and, finally, the GPU main memory. For example the TU 106
    GPU has 64 KB of L1 cache per SM and 4 MB of L2 cache, and the RTX 2070 comes
    with 8 GB of main memory.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 内存组织也很重要：每个SM都有一定量的L1缓存（检查第6章以了解缓存概念），这些缓存可以由同一SM中的所有SP（Streaming Processors，流处理器）共享。我们不会直接使用L1缓存，它可以用于在同一个SM上运行的线程之间共享状态。还有L2缓存，它由所有SM共享，最后是GPU主内存。例如，TU
    106 GPU每个SM有64 KB的L1缓存和4 MB的L2缓存，RTX 2070配备了8 GB的主内存。
- en: '![](../Images/CH09_F02_Antao.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F02_Antao.png)'
- en: 'Figure 9.2 A simplified overview of the main GPU components: streaming multiprocessors
    that contain streaming processors (CUDA cores) and local cache. The GPU includes
    all the streaming multiprocessors along with some extra cache and the GPU main
    memory.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 主要 GPU 组件的简化概述：包含流处理器的流多处理器（CUDA 核心）和本地缓存。GPU 包括所有流多处理器以及一些额外的缓存和 GPU
    主内存。
- en: How will this affect our coding and performance design? You need to be explicitly
    aware of the architecture to run code on it, as we will see next.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这将如何影响我们的编码和性能设计？你需要明确了解架构才能在上面运行代码，正如我们接下来将要看到的。
- en: 9.1.4 Software architecture considerations
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.4 软件架构考虑因素
- en: 'Let’s now see how the hardware architecture affects GPU code design. We will
    have a look at the steps necessary to run our previous simple example: multiplying
    a matrix by 2\. Later in the chapter, we will actually code this, but for now
    let’s revisit the high-level steps.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看硬件架构如何影响 GPU 代码设计。我们将查看运行我们之前的简单示例（将矩阵乘以 2）所需的步骤。在本章的后面，我们将实际编写这段代码，但现在让我们回顾一下高级步骤。
- en: We have our matrix in the memory near the CPU, so the first thing we need to
    do is to transfer it to the GPU memory. This operation can be quite expensive,
    especially if we don’t have much computation to do on the GPU.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 CPU 附近的内存中有我们的矩阵，所以我们需要做的第一件事是将它传输到 GPU 内存。这个操作可能相当昂贵，尤其是如果我们没有在 GPU 上做很多计算的话。
- en: Imagine a 1024 × 64 matrix (i.e., 65,536 elements). In a GPU, each element will
    be computed as a separate thread. So, we will have 65,536 threads. Each thread
    will run the *same code*. Threads need to be divided into thread blocks; all threads
    in a thread block are placed in the same SM and can share memory and synchronization
    primitives. In our case, nothing is needed to share across different threads as
    the algorithm is trivial, but we still need to divide our code in thread blocks.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个 1024 × 64 的矩阵（即 65,536 个元素）。在 GPU 中，每个元素将作为一个单独的线程来计算。因此，我们将有 65,536 个线程。每个线程将运行
    *相同的代码*。线程需要被分成线程块；一个线程块中的所有线程都放置在同一个 SM 中，并且可以共享内存和同步原语。在我们的例子中，由于算法非常简单，不需要在不同线程之间共享任何内容，但我们仍然需要将我们的代码分成线程块。
- en: If we assume, for example, the value of 32 threads per block, we will need 2048
    blocks. Each block can be executed on different SMs.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们假设每个块有 32 个线程，那么我们需要 2048 个块。每个块可以在不同的 SM 上执行。
- en: 'So how do we call the code? Remember that the CPU drives everything, so the
    CPU will call an entry point on the GPU that will drive all the computations.
    The name for that entry point is the *kernel function*. We now have a very basic
    idea of the fundamentals of coding a GPU: the existence of an entry point—*kernel
    function*—and the running of the same code over many threads.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何调用代码？记住 CPU 驱动一切，所以 CPU 将调用 GPU 上的一个入口点来驱动所有计算。这个入口点的名称是 *内核函数*。我们现在对编写
    GPU 代码的基本原理有一个非常基本的了解：存在一个入口点——*内核函数*——以及相同的代码在许多线程上运行。
- en: We will deploy low-level code to the GPU. Because there is no Cython equivalent
    to convert Python to OpenCL C (or CUDA C), we will use Numba. If you have never
    used Numba, see appendix B, which is an introduction to the technology.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将部署低级代码到 GPU 上。因为 Cython 没有等效功能将 Python 转换为 OpenCL C（或 CUDA C），所以我们将使用 Numba。如果你从未使用过
    Numba，请参阅附录 B，其中介绍了这项技术。
- en: 9.2 Using Numba to generate GPU code
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 使用 Numba 生成 GPU 代码
- en: 'After some basic preparation, we are finally going to write our first GPU program
    using Numba. To understand the basic problems with GPU coding, we will start with
    the simplest of examples: doubling the value of an array. After that, we will
    implement a Mandelbrot generator, which you can then compare with a CPU version
    in appendix B. Again, if you’ve never used Numba, consider looking first at that
    appendix where Numba is introduced on the CPU.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些基本准备之后，我们最终将使用 Numba 编写我们的第一个 GPU 程序。为了理解 GPU 编码的基本问题，我们将从最简单的例子开始：将数组值加倍。之后，我们将实现一个
    Mandelbrot 生成器，你可以在附录 B 中将其与 CPU 版本进行比较。再次提醒，如果你从未使用过 Numba，可以考虑先查看那个附录，其中介绍了在
    CPU 上使用 Numba。
- en: 9.2.1 Installation of GPU software for Python
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 Python GPU 软件安装
- en: Before we can start running our GPU code, we need to be sure that all the drivers
    and required software for the GPU are installed. Installing the software is not
    always trivial. It is not possible here to provide general instructions for different
    operating systems and architectures, but a few guidelines can be given.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始运行GPU代码之前，我们需要确保所有GPU的驱动程序和所需的软件都已安装。安装软件并不总是简单的事情。在这里，不可能为不同的操作系统和架构提供一般性的说明，但可以给出一些指导方针。
- en: You will probably need kernel drivers installed with the potential need to reboot
    your machine. You will need the CUDA toolkit, which comes in different flavors;
    if you are using Anaconda, doing `conda install cudatoolkit` is probably the easiest
    approach.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要安装内核驱动程序，可能需要重新启动你的机器。你需要CUDA工具包，它有不同的版本；如果你使用Anaconda，执行`conda install
    cudatoolkit`可能是最简单的方法。
- en: 'Numba has the ability to test the existing infrastructure and report on existing
    hardware and libraries. To check, run this in the following shell:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Numba有测试现有基础设施和报告现有硬件和库的能力。要检查，请在以下shell中运行：
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You will have a very detailed view of your system. To determine whether the
    GPU is available, you need to see whether the hardware is detected and the libraries
    are available. For the hardware, search for something like this:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你将非常详细地了解你的系统。为了确定GPU是否可用，你需要查看硬件是否被检测到并且库是否可用。对于硬件，搜索类似以下内容：
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This code will allow you to check whether the device is detected and supported.
    Some older GPUs might not be supported. You also need to make sure that all libraries
    are found. Another part of the report will include something like this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将允许你检查设备是否被检测并支持。一些较旧的GPU可能不受支持。你还需要确保所有库都被找到。报告的另一部分将包括类似以下内容：
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This code will allow you to discover all problematic libraries. Let’s now write
    some GPU code.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将允许你发现所有有问题的库。现在让我们写一些GPU代码。
- en: 9.2.2 The basics of GPU programming with Numba
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 使用Numba的GPU编程基础
- en: 'Before we start with our code, let’s get into the right mindset by looking
    at what we do *not* want to do. Remember, we are trying simply to double an array,
    so the following would be a potential solution with a CPU mindset:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始编写代码之前，让我们通过查看我们不希望做的事情来调整我们的心态。记住，我们只是尝试简单地加倍一个数组，所以以下是一个具有CPU思维的潜在解决方案：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ① for is a sequential operation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ① for 是一个顺序操作。
- en: 'This code is a sequential loop over the array. But our GPU code will use one
    thread per element, so our code should only handle a *single* element. Later,
    we will take care of telling the GPU to apply our code to all elements of the
    array. Here is the first version:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码是对数组的顺序循环。但我们的GPU代码将使用每个元素一个线程，所以我们的代码应该只处理一个*单个*元素。稍后，我们将确保GPU将我们的代码应用于数组的所有元素。以下是第一个版本：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ① Compiles the function to CUDA
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ① 编译函数到CUDA
- en: ② cuda.grid accesses the current position to be processed in the array.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ② cuda.grid 访问数组中要处理的当前位置。
- en: There is no output to show here because this all happens on the GPU.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有输出可以显示，因为所有这些都在GPU上发生。
- en: Yes, a function call handles a single element only! This approach is very different
    from what we are used to—outside vectorized approaches.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，一个函数调用只处理单个元素！这种方法与我们习惯的非常不同——在非矢量化方法之外。
- en: We annotate our function with the `cuda.jit` decorator so that Numba generates
    a CUDA version of our code. We then use the “magic” function `cuda.grid` to get
    the single and only position we will be changing; we will see later what is going
    on there. Finally, we change a single entry in the array based on position.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`cuda.jit`装饰器来注释我们的函数，这样Numba就会生成我们代码的CUDA版本。然后我们使用“魔法”函数`cuda.grid`来获取我们将要更改的单个唯一位置；我们稍后会看到那里发生了什么。最后，我们根据位置更改数组中的单个条目。
- en: Our function cannot return values as it going to be implemented as a GPU kernel
    function, so we need to pass parameters to accommodate return values. If we try
    to execute the code
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的功能不能返回值，因为它将被实现为一个GPU内核函数，所以我们需要传递参数以适应返回值。如果我们尝试执行代码
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'we will get an error:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到一个错误：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This error is because we must also tell Numba how to distribute the computation.
    As alluded to in the section on architecture, we have to divide the computation
    into thread blocks, and each block, into grids. This will work:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这个错误是因为我们必须还告诉Numba如何分配计算。正如在架构部分所暗示的，我们必须将计算分成线程块，每个块分成网格。这将有效：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ① The call to the function uses a syntax that is not very idiomatic.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ① 函数调用的语法不是非常符合习惯。
- en: ② We want to check that the function was applied to all elements of the array.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ② 我们想检查函数是否已应用于数组的所有元素。
- en: Notice that the syntax to call the function is not very idiomatic. At the end,
    we are checking that all elements are 2 using `assert`. We are trying to be careful
    because if we supply the wrong number of blocks, not all arrays may be computed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，调用函数的语法并不十分地道。最后，我们使用 `assert` 来检查所有元素是否为 2。我们试图小心行事，因为如果我们提供的方块数量不正确，可能不是所有的数组都会被计算。
- en: We are issuing 20 threads per block, and as we have 1,000 elements, we will
    need 50 blocks. Generally, 32 threads are common. Give the memory hierarchy in
    GPUs, threads in the same block can share some states very fast. Here we will
    not be concerned with those types of algorithms, as they are for a more advanced
    stage. Thus, we can be quite flexible with our code distribution over the GPU.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在每个方块中发出 20 个线程，因为我们有 1,000 个元素，我们需要 50 个方块。通常，32 个线程是常见的。考虑到 GPU 的内存层次结构，同一方块中的线程可以非常快速地共享一些状态。在这里，我们不会关注这些类型的算法，因为它们属于更高级的阶段。因此，我们可以相当灵活地在
    GPU 上分配我们的代码。
- en: 'That being said, sometimes it is not possible to have a `blocks * threads`
    that is equal to the number of elements in our array (e.g., in an array whose
    size is a prime number). In that case, we have to specify a `blocks * threads`
    that is slightly bigger than our array. Here is an example:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，有时不可能使 `blocks * threads` 等于我们数组中的元素数量（例如，在大小为素数的数组中）。在这种情况下，我们必须指定一个比我们的数组稍大的
    `blocks * threads`。以下是一个例子：
- en: '[PRE10]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In this case, we will have a total of 1,008 threads (16*63). If you are lucky,
    this code will work. It is also quite possible that it crashes!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将有总共 1,008 个线程（16*63）。如果你很幸运，这段代码会工作。也有可能它会崩溃！
- en: You are calling the code for positions 0 to 1007, and the last eight positions,
    1000 to 1007, were not allocated. Now, here you have to stop with the Python mindset
    and remember that your code was converted into a lower-level language. This conversion
    means that all the standard Python bounds checking will not be available and that
    you can get, as a “prize,” a memory allocation error or, worse, a silent bug.
    We will see an example later of this type of bug.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你正在调用位置 0 到 1007 的代码，最后八个位置，即 1000 到 1007，尚未分配。现在，你必须停止使用 Python 的思维方式，并记住你的代码已被转换为低级语言。这种转换意味着所有标准的
    Python 边界检查将不可用，而且你可能会得到“奖品”，即内存分配错误，或者更糟糕的是，一个静默的错误。我们稍后会看到一个这种错误的例子。
- en: 'Correcting this problem is quite easy:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题相当简单：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We check whether the position is bigger than the array size and, if so, return.
    Now we can call the code confidently:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们检查位置是否大于数组大小，如果是，则返回。现在我们可以自信地调用代码：
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Finally, at this stage, we properly called code on the GPU!
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在这个阶段，我们正确地在 GPU 上调用了代码！
- en: 'Now, let’s get back to the “magic” of `cuda.grid` to get the position to be
    computed. We will understand what is going on with that call by explicitly coding
    it ourselves. Having to code it ourselves is sometime necessary (e.g., with arrays
    that have more than three dimensions):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回到 `cuda.grid` 的“魔法”，以获取要计算的位置。我们将通过自己编写代码来理解这个调用发生了什么。有时必须自己编写代码（例如，对于具有超过三个维度的数组）：
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The thread call has access to which block and thread it is running. It also
    has access to the block dimension. `cuda.blockIdx` gives you the block index where
    the current thread is running. `cuda.blockDim` provides the block dimension, and
    `cuda.threadIdx` gives you the thread inside the group. With this information,
    you can make sure each thread addresses a different position in the array.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 线程调用可以访问它正在运行的方块和线程。它还可以访问方块维度。`cuda.blockIdx` 给出当前线程正在运行的方块索引。`cuda.blockDim`
    提供方块维度，而 `cuda.threadIdx` 给出组内的线程。有了这些信息，你可以确保每个线程都指向数组中的不同位置。
- en: 'Location information for a thread can be one-, two-, and three-dimensional:
    You might have noticed the `.x` parameter on all the CUDA calls; `.y` and `.z`
    parameters can be used if you have two- and three-dimensional arrays.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 线程的位置信息可以是一维、二维和三维：你可能已经注意到了所有 CUDA 调用中的 `.x` 参数；如果你有二维和三维数组，可以使用 `.y` 和 `.z`
    参数。
- en: 'Let’s now look at the same function but for a two-dimensional array:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看同一个函数，但针对二维数组：
- en: '[PRE14]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We now use `cuda.grid(2)` to get two indices. Notice that we returned to the
    unsafe code because we can now be quite sure that we will trigger an error. Let’s
    run this code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用 `cuda.grid(2)` 来获取两个索引。注意，我们回到了不安全的代码，因为我们现在可以相当肯定我们会触发一个错误。让我们运行这段代码：
- en: '[PRE15]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This will print `True`, as all elements of the matrix are now 2\. Notice that
    we have block and thread definitions that are two-dimensional like our data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印`True`，因为矩阵的所有元素现在都是2。注意，我们定义的块和线程是二维的，就像我们的数据一样。
- en: If you run this code and are lucky enough that it doesn’t crash, it will most
    surely return erroneous results. This outcome occurs because we are not testing
    matrix boundaries, and when you go over in one row, you will land on the next
    row of the matrix, which was not possible with a one-dimensional array. So, there
    will probably be positions where the value is 4, not 2, as the code will be executed
    there twice.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行这段代码并且足够幸运以至于它没有崩溃，它几乎肯定会返回错误的结果。这种结果发生是因为我们没有测试矩阵边界，当您超出一行时，您将落在矩阵的下一行上，这在单维数组中是不可能的。因此，可能存在值为4而不是2的位置，因为代码将在那里执行两次。
- en: 'Correcting this is quite simple, as we have previously seen. The following
    is our final version where we also are explicit with the matrix indexes:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 正确处理这个问题相当简单，正如我们之前看到的。以下是我们最终的版本，我们在其中也明确指出了矩阵索引：
- en: '[PRE16]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now that we have covered the basics, let’s re-create our Mandelbrot example
    using a GPU.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了基础知识，让我们使用GPU重新创建我们的Mandelbrot示例。
- en: 9.2.3 Revisiting the Mandelbrot example using GPUs
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 重新审视使用GPU的Mandelbrot示例
- en: We have gone over almost all the Numba concepts, so let’s create a Mandelbrot
    renderer using a GPU. To put those concepts together and build the renderer, we
    will take a circuitous route, following what may seem like the logical approach,
    but ending up at a few dead ends that do not work. The goal here is to illustrate
    and explain exactly *why* these steps do not work, in the hopes that this understanding
    will save you from the pitfalls of just following your intuition.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经几乎涵盖了所有的Numba概念，所以让我们创建一个使用GPU的Mandelbrot渲染器。为了将这些概念结合起来构建渲染器，我们将采取一条迂回的路线，遵循看似合理的步骤，但最终会遇到几个不工作的死胡同。这里的目的是说明并解释为什么这些步骤不工作，希望这种理解能帮助您避免仅仅跟随直觉的陷阱。
- en: 'Let’s start by implementing the Mandelbrot function to compute the value for
    a single point:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先实现Mandelbrot函数来计算单个点的值：
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note the `device=True` addition to the `cuda.jit` decorator. We are telling
    Numba that this function needs to be invoked from *inside* the device. Device
    functions, unlike kernel functions, can return values.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`device=True`添加到`cuda.jit`装饰器中。我们正在告诉Numba这个函数需要在设备内部调用。与内核函数不同，设备函数可以返回值。
- en: 'Next, we will implement a first version that may seem sensible but does not
    work:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将实现一个看似合理但实际上不工作的第一个版本：
- en: '[PRE18]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'While this function compiles, if you try to call it, you will get the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当这个函数编译时，如果您尝试调用它，您将得到以下结果：
- en: '[PRE19]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The problem here is that Numba cannot handle tuples as input parameters (at
    least at the present time). But this points to a larger problem that we need to
    remember: *some Python functionality is not supported by Numba*. So, be sure to
    check Numba’s documentation ([http://numba.pydata.org/](http://numba.pydata.org/))
    to determine what functions are supported. It makes no sense for us to discuss
    here which specific features are unsupported, because Numba is changing all the
    time. It may very well be supporting new features between the time I am writing
    and the time you are reading this section.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的问题在于Numba无法处理元组作为输入参数（至少在目前这个时间点是这样）。但这指向了一个更大的问题，我们需要记住：*一些Python功能不被Numba支持*。因此，请务必检查Numba的文档([http://numba.pydata.org/](http://numba.pydata.org/))以确定哪些函数被支持。在这里讨论哪些具体功能不被支持是没有意义的，因为Numba一直在变化。完全有可能在我写这段话和您阅读这段话之间，Numba已经支持了新的功能。
- en: 'So, to make this solution work, we have to create a version without tuples
    as input parameters:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了使这个解决方案工作，我们必须创建一个不带元组作为输入参数的版本：
- en: '[PRE20]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'There is a minor detail worth noticing in the last line: remember that with
    NumPy arrays the `y` coordinate goes first, so we write `img_array[y, x]`.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一行有一个值得注意的细节：记住，对于NumPy数组，`y`坐标在前，所以我们应该写`img_array[y, x]`。
- en: 'Let’s now make our call:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们进行调用：
- en: '[PRE21]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The most important point that I’d like you to notice here is the specification
    of the number of blocks: given that we have 16 threads per block on each dimension,
    we need to have `size / 16` blocks. As the number might not be an integer, we
    must round up to make sure all points are covered.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望您在这里注意的最重要的一点是块数的指定：鉴于我们在每个维度上每个块有16个线程，我们需要有`size / 16`个块。由于这个数字可能不是整数，我们必须向上取整以确保所有点都被覆盖。
- en: 'We can time this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计时这个操作：
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This compares with 539 ms for the best CPU version demonstrated in appendix
    B. Although, to be honest, this is not a fair comparison, as it pits a poor CPU
    against a good GPU. Furthermore, there are plenty of other factors, like algorithm
    type and CPU-to-GPU memory transfer, that have a massive effect on speed. Nonetheless,
    it should be clear that GPUs can deliver increased performance compared to CPUs
    for some algorithms.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这与附录B中展示的最佳CPU版本的539 ms相比。然而，说实话，这并不是一个公平的比较，因为它将一个较差的CPU与一个优秀的GPU进行了比较。此外，还有许多其他因素，如算法类型和CPU到GPU的内存传输，对速度有巨大影响。尽管如此，应该很清楚，对于某些算法，GPU可以提供比CPU更高的性能。
- en: Now that we have our first Mandelbrot generator based on GPUs with a substantial
    increase in performance, let’s create another Mandelbrot generator. This time,
    we’ll create it using NumPy vectorization, because it can be quite useful in accelerating
    data analysis, as we have seen before.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了基于GPU的Mandelbrot生成器，性能有了显著提升，让我们再创建另一个Mandelbrot生成器。这次，我们将使用NumPy向量化来实现，因为它在加速数据分析方面非常有用，正如我们之前所看到的。
- en: 9.2.4 A NumPy version of the Mandelbrot code
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.4 Mandelbrot代码的NumPy版本
- en: 'Our final version is a NumPy universal function running on the GPU. We’ve gone
    over all the essential pieces, so it should be quite easy to put this together.
    Here is the computation point along with the vectorized version:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终的版本是一个在GPU上运行的NumPy通用函数。我们已经讨论了所有必要的部分，所以应该很容易将这些部分组合起来。以下是计算点及其向量化版本：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ① We will be using a simpler version of the point calculation with the interaction
    limit hardcoded.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ① 我们将使用一个更简单的点计算版本，其中交互限制是硬编码的。
- en: The only small novelty of this code is the use of `target="cuda"` in the `vectorize`
    call on the last line.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的唯一小创新是在最后一行的`vectorize`调用中使用`target="cuda"`。
- en: 'Remember from the previous section that we need to prepare an array with positions
    for which we want computation:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 记住上一节中我们提到，我们需要准备一个数组，其中包含我们想要进行计算的位位置：
- en: '[PRE24]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We can now time the execution of this version:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以计时这个版本的执行：
- en: '[PRE25]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The numbers are worse than the previous GPU version, but still better than
    the CPU version. The pattern here is different from the CPU version: in the CPU
    version, the fastest code was with an universal function.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数字比之前的GPU版本更差，但仍然比CPU版本好。这里的模式与CPU版本不同：在CPU版本中，最快的代码是使用通用函数。
- en: NumPy functionality is limited with CUDA due to the computation model. Wouldn’t
    it be nice if there was a native GPU implementation of NumPy? Enter CuPy. . .
    .
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 由于计算模型，NumPy的功能在CUDA中受到限制。如果有一个原生的NumPy GPU实现不是很好吗？这就是CuPy的出现……
- en: '9.3 Performance analysis of GPU code: The case of a CuPy application'
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 GPU代码的性能分析：CuPy应用的案例
- en: 'In this section, we will implement a solution using a native GPU version of
    NumPy: CuPy.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用NumPy的原生GPU版本：CuPy来实现一个解决方案。
- en: Note Many CPU-based data analysis libraries have GPU counterparts. So, you can
    use GPUs with little to no knowledge of how the GPU code works. As such, we will
    start by listing existing versions of GPU-based libraries for data analysis.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：许多基于CPU的数据分析库都有GPU对应版本。因此，你可以使用GPU，即使对GPU代码的工作原理知之甚少。因此，我们将首先列出现有的基于GPU的数据分析库版本。
- en: After we create our CuPy solution, we will use our code to discuss techniques
    to profile GPU code. Our CuPy example will serve as an excuse to introduce tools
    to analyze the performance of GPU solutions. But before we discuss code or profiling,
    let’s get an overview of existing GPU-based libraries for data science.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们创建我们的CuPy解决方案后，我们将使用我们的代码来讨论分析GPU代码的技术。我们的CuPy示例将作为介绍分析GPU解决方案性能的工具的借口。但在讨论代码或分析之前，让我们先概述现有的基于GPU的数据科学库。
- en: 9.3.1 GPU-based data analysis libraries
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 基于GPU的数据分析库
- en: If you have access to GPUs, you don’t have to code from scratch. There are a
    few GPU-based libraries that provide similar functionality—many times with very
    close interfaces—to existing known data libraries for CPUs. In many instances,
    you don’t need to know anything about GPU programming. Table 9.1 provides a list
    of currently existing libraries along with their CPU counterparts.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你可以访问GPU，你不必从头开始编写代码。有几个基于GPU的库提供了类似的功能——许多情况下与现有的CPU数据库接口非常接近。在许多情况下，你不需要了解任何关于GPU编程的知识。表9.1提供了一个当前存在的库列表及其CPU对应版本。
- en: Table 9.1 GPU-based libraries with CPU counterparts
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1 基于GPU的库及其CPU对应版本
- en: '| GPU | CPU | Purpose |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| GPU | CPU | 目的 |'
- en: '| cuBLAS | BLAS | Basic linear algebra |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| cuBLAS | BLAS | 基本线性代数 |'
- en: '| CuPy | NumPy | N-dimensional array processing |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| CuPy | NumPy | N 维数组处理 |'
- en: '| CuDF | pandas | Columnar data analysis |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| CuDF | pandas | 列数据分析 |'
- en: '| CuGraph |  | Graph algorithms for data frames |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| CuGraph |  | 数据帧的图算法 |'
- en: '| CuML | scikit-learn | Machine learning |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| CuML | scikit-learn | 机器学习 |'
- en: '| BlazingSQL |  | SQL interfaces on top of columnar data |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| BlazingSQL |  | 基于列数据的 SQL 接口 |'
- en: Other libraries are able to accelerate existing analysis code. For example,
    cuDNN can increase the performance of machine learning libraries like PyTorch
    or TensorFlow.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 其他库能够加速现有的分析代码。例如，cuDNN 可以提高 PyTorch 或 TensorFlow 等机器学习库的性能。
- en: You can consider these libraries for your data analysis projects based on GPUs.
    For example, we will develop a project based on CuPy.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以根据 GPU 数据分析项目考虑使用这些库。例如，我们将基于 CuPy 开发一个项目。
- en: '9.3.2 Using CuPy: A GPU-based version of NumPy'
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 使用 CuPy：NumPy 的 GPU 版本
- en: We will develop a project using a high-level data science library, CuPy. CuPy
    is a GPU-based version of NumPy. Many high-level GPU libraries have similar interfaces
    with their CPU counterparts so not much new information needs to be introduced
    at that level. But, other than allowing us to see a real example of GPU-based
    data science code, we can use the code generated in this example to introduce
    profiling tools for GPU code. Our project will be, you guessed it, a Mandelbrot
    generator on top of CuPy arrays.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用高级数据科学库 CuPy 开发一个项目。CuPy 是 NumPy 的 GPU 版本。许多高级 GPU 库与它们的 CPU 对应库具有相似的接口，因此在那个层面上不需要介绍太多新信息。但是，除了能够展示基于
    GPU 的数据科学代码的真实示例外，我们还可以使用这个示例中生成的代码来介绍 GPU 代码的剖析工具。我们的项目将是，不出所料，基于 CuPy 数组的曼德布罗特生成器。
- en: 9.3.3 A basic interaction with CuPy
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.3 与 CuPy 的基本交互
- en: 'Before we implement our Mandelbrot generator, let’s do some basic work with
    CuPy, which will allow us to discuss of the underlying mechanics going on with
    CuPy. We are simply going to create a matrix of 5000 × 5000 and double it:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们实现曼德布罗特生成器之前，让我们做一些基本的 CuPy 工作，这将使我们能够讨论 CuPy 中的底层机制。我们将简单地创建一个 5000 × 5000
    的矩阵并将其加倍：
- en: '[PRE26]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: While having similar interfaces, CuPy and NumPy are different libraries and
    expose different object types. It is not uncommon that you end up importing both
    for many analyses.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 CuPy 和 NumPy 具有相似的接口，但它们是不同的库，并暴露了不同的对象类型。你可能会在许多分析中同时导入它们，这并不罕见。
- en: The type of `my_matrix` will be `cupy._core.core.ndarray`, whereas the type
    of `np_matrix` will be `numpy.ndarray`. The data for `my_matrix` resides on the
    GPU memory, so when you want do operations on it, there will be no memory transfer
    from the CPU to the GPU side. For example, the multiplication `2 * my_matrix`
    occurs completely in the GPU. A memory transfer from the GPU side will happen
    when you explicitly do `my_matrix.get()`, which will create an independent NumPy
    representation of the original matrix.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`my_matrix` 的类型将是 `cupy._core.core.ndarray`，而 `np_matrix` 的类型将是 `numpy.ndarray`。`my_matrix`
    的数据位于 GPU 内存中，因此当你想要对其执行操作时，不会有从 CPU 到 GPU 的内存传输。例如，乘法 `2 * my_matrix` 完全在 GPU
    上执行。当你显式地执行 `my_matrix.get()` 时，将会发生从 GPU 端的内存传输，这将创建原始矩阵的独立 NumPy 表示。'
- en: Basic profiling of GPU code should not be done with the typical Python tools
    like the `timeit` module or the `%timeit` magic of IPython. The GPU code executes
    independently from the CPU code, and a CPU perspective of execution time will
    not be representative of the GPU cost.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上对 GPU 代码进行性能分析时，不应使用典型的 Python 工具，如 `timeit` 模块或 IPython 的 `%timeit` 魔法。GPU
    代码独立于 CPU 代码执行，CPU 视角下的执行时间并不能代表 GPU 成本。
- en: 'CuPy provides a simple mechanism to profile code. Let’s run `2 * my_matrix`
    200 times and see its cost:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: CuPy 提供了一种简单的机制来剖析代码。让我们运行 `2 * my_matrix` 200 次，看看它的成本：
- en: '[PRE27]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The output on my machine is:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的机器上的输出是：
- en: '[PRE28]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: So, on average, each execution takes 60 µs of CPU time and 785 µs of GPU time.
    I ran this code on a Tesla T4 GPU, which was hosted on an Intel Xeon at 2.50 GHz.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，平均每次执行需要 60 µs 的 CPU 时间和 785 µs 的 GPU 时间。我在一个配备 2.50 GHz 英特尔 Xeon 处理器的 Tesla
    T4 GPU 上运行了此代码。
- en: Now let’s move on and finally implement our Mandelbrot generator using CuPy.
    Our larger objective here is not to show the interface because it is supposed
    to be similar, by design, with NumPy. We are also not going to talk about CuPy
    limitations compared to NumPy because these change over time, and when you read
    this text, they may have already changed.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续前进，并最终使用 CuPy 实现 Mandelbrot 生成器。我们在这里的更大目标是展示接口，因为按照设计，它应该与 NumPy 类似。我们也不会讨论
    CuPy 相比 NumPy 的局限性，因为这些会随着时间的推移而变化，当你阅读这篇文章时，它们可能已经发生了变化。
- en: Our objective with our next *two* Mandelbrot implementations is to explore how
    to extract the most performance out of the GPU. We will write processing functions
    that work on the GPU with CuPy. Our first will show the interaction of CuPy with
    Numba.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下一个两个Mandelbrot实现的目标是探索如何从GPU中提取最大性能。我们将编写使用CuPy在GPU上工作的处理函数。我们的第一个将展示CuPy与Numba的交互。
- en: 9.3.4 Writing a Mandelbrot generator using Numba
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.4 使用Numba编写Mandelbrot生成器
- en: 'CuPy interacts seamlessly with Numba: you can write a Numba-decorated function
    and use it with CuPy.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: CuPy与Numba无缝交互：你可以编写一个Numba装饰的函数，并使用CuPy。
- en: Tip CuPy has its own converter of Python code to GPU code that is somewhat competitive
    with Numba. At the current stage, its support for Python features is quite limited
    compared to Numba. I recommend trying Numba first, although, with time, maybe
    the native CuPy converter will become more feature-complete.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：CuPy有一个将Python代码转换为GPU代码的转换器，它与Numba有一定的竞争力。在当前阶段，与Numba相比，它对Python特性的支持相当有限。我建议首先尝试Numba，尽管随着时间的推移，也许CuPy的本地转换器会变得更加功能完善。
- en: 'The following is our implementation of a Mandelbrot generator written in Numba
    that works with CuPy:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们使用Numba编写的Mandelbrot生成器的实现，它与CuPy一起工作：
- en: '[PRE29]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Nothing in this code is really new to you from a conceptual point of view when
    compared to what we discussed in the Numba for GPU section. The same is true for
    calling the code:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在Numba GPU部分讨论的内容相比，从概念上讲，这段代码中没有什么真正新的东西。调用代码也是如此：
- en: '[PRE30]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The only thing left to do is to save our image:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的唯一事情就是保存我们的图像：
- en: '[PRE31]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Here we need to convert our CuPy array into a NumPy version to be able to use
    the Pillow library to create an image representation. This means that data will
    be transferred from GPU to CPU memory.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们需要将我们的CuPy数组转换为NumPy版本，以便能够使用Pillow库创建图像表示。这意味着数据将从GPU传输到CPU内存。
- en: 'Let’s do some basic performance analysis:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一些基本的性能分析：
- en: '[PRE32]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The performance reported here is:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这里报告的性能是：
- en: '[PRE33]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: It seems that `repeat` prefers to report 70,600 µs instead of the more visually
    pleasant 70 ms. Now that we have the first version of our Mandelbrot generator
    on top of CuPy, let’s do a second version that embeds the CUDA C code into our
    Python code.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来`repeat`更倾向于报告70,600 µs而不是更直观的70 ms。现在我们已经有了基于CuPy的Mandelbrot生成器的第一个版本，让我们来做第二个版本，将CUDA
    C代码嵌入到我们的Python代码中。
- en: 9.3.5 Writing a Mandelbrot generator using CUDA C
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.5 使用CUDA C编写Mandelbrot生成器
- en: We will create a vectorized function to generate a Mandelbrot set. Our vectorized
    function will receive a matrix with all the positions and compute, for each one,
    the Mandelbrot value. We will be implementing our function using CUDA C.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个向量化函数来生成Mandelbrot集。我们的向量化函数将接收一个包含所有位置的矩阵，并计算每个位置的Mandelbrot值。我们将使用CUDA
    C实现我们的函数。
- en: 'As with the NumPy version, we start by preparing the position array. We will
    actually do that in NumPy and then transfer it to CuPy:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 与NumPy版本一样，我们首先准备位置数组。我们实际上会在NumPy中做这件事，然后将其传输到CuPy：
- en: '[PRE34]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The code for input preparation is exactly as before. In the last line, we convert
    the NumPy array to a CuPy version on the GPU, which requires a memory transfer.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 输入准备代码与之前完全相同。在最后一行，我们将NumPy数组转换为GPU上的CuPy版本，这需要内存传输。
- en: 'We must now prepare our `threads_per_block` and `blocks_per_grid` variables.
    To keep our C code as simple as possible, we will work in one, rather than two,
    dimensions:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在必须准备`threads_per_block`和`blocks_per_grid`变量。为了使我们的C代码尽可能简单，我们将在一个维度上工作，而不是两个维度：
- en: '[PRE35]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We scale our one-dimensional blocks and threads per block as necessary. Here
    is our implementation:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据需要调整一维块和每个块中的线程数。以下是我们的实现：
- en: '[PRE36]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The point of this book is not to teach you C, so we are not going to delve into
    the details of this listing, but the code is designed with simplicity in mind
    and should be easy to understand. As before, we are not focusing on how we decide
    on the position to compute but, rather, on `blockDim.x * blockIdx.x threadIdx.x`.
    The C code is actually looking at the matrix as a one-dimensional array and that
    works.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的目的是不教你C语言，所以我们不会深入探讨这个列表的细节，但代码的设计是以简洁为原则的，应该容易理解。就像以前一样，我们不是关注我们如何决定计算的位置，而是关注`blockDim.x
    * blockIdx.x threadIdx.x`。实际上，C代码是将矩阵视为一维数组，这样是可行的。
- en: 'Finally, let’s use the previous function to compute the Mandelbrot set from
    the position array:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们使用前面的函数从位置数组计算Mandelbrot集：
- en: '[PRE37]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Note the syntax to call the function while specifying the number of blocks
    and threads per block: it’s different from the Numba approach. We finalize by
    transferring the CuPy array to a NumPy version to print it.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 注意调用函数时的语法，同时指定每个块和每个块中的线程数：这与 Numba 方法不同。我们通过将 CuPy 数组传输到 NumPy 版本来打印它来结束。
- en: 'Let’s do some basic performance analysis:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一些基本的性能分析：
- en: '[PRE38]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'On my machine, I get:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的机器上，我得到：
- en: '[PRE39]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This result of 3.1 ms is 20 times faster than the Numba version. If your Numba
    code is still not fast enough, there is one final step that you can take: an embedded
    CUDA C implementation.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 3.1 毫秒的结果比 Numba 版本快 20 倍。如果你的 Numba 代码仍然不够快，你可以采取一个最后的步骤：嵌入 CUDA C 实现。
- en: Now that we have some code that makes use of the GPU, let’s find out about some
    GPU performance analysis tools.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经有一些利用 GPU 的代码，让我们了解一下一些 GPU 性能分析工具。
- en: 9.3.6 Profiling tools for GPU code
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.6 GPU 代码的性能分析工具
- en: 'Here we will use some basic functions of NVIDIA profiling tools to analyze
    the performance of our Mandelbrot implementations. The profiling tools are general:
    they don’t depend on CuPy and not even on Python—you can use them with any GPU
    code. To demonstrate this, we will be profiling the NumPy version of our Mandelbrot
    code using a vectorized GPU implementation.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用 NVIDIA 性能分析工具的一些基本功能来分析我们 Mandelbrot 实现的性能。这些分析工具是通用的：它们不依赖于 CuPy，甚至不依赖于
    Python——你可以用任何 GPU 代码使用它们。为了演示这一点，我们将使用向量化 GPU 实现来分析我们 Mandelbrot 代码的 NumPy 版本。
- en: We will use NVIDIA’s Nsight Systems to do our performance analysis. We will
    assume offline usage, and we will capture performance analysis and separately
    analyze it using Nsight’s GUI. This is the most flexible approach, as it assumes
    that the GPU machine is separate from the analysis machine—for example, when the
    GPU machine is on the cloud and you look at the performance data on your local
    machine.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 NVIDIA 的 Nsight Systems 来进行性能分析。我们将假设离线使用，并使用 Nsight 的 GUI 分别捕获性能分析并进行分析。这是最灵活的方法，因为它假设
    GPU 机器与分析机器是分开的——例如，当 GPU 机器在云端，而你查看性能数据在本地机器上时。
- en: 'After installing Nsight Systems, we can very easily profile the code by doing
    the following:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Nsight Systems 后，我们可以通过以下步骤轻松地进行代码分析：
- en: '[PRE40]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'To profile the NumPy version with a vectorized GPU implementation, we can do:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用向量化 GPU 实现来分析 NumPy 版本，我们可以这样做：
- en: '[PRE41]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We now have three profile traces: `numba.qdrep`, `c.qdrep`, and `numpy.qdrep`.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有三个性能分析跟踪：`numba.qdrep`、`c.qdrep` 和 `numpy.qdrep`。
- en: Remember that we have a `timeit` mean of 222 ms for the NumPy version and a
    GPU cost from `cupyx.time.repeat` of 70 ms for the Numba version and 3 ms for
    the CUDA C version.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，我们 NumPy 版本的平均 `timeit` 是 222 毫秒，而 Numba 版本的 GPU 成本是 `cupyx.time.repeat`
    的 70 毫秒，CUDA C 版本是 3 毫秒。
- en: 'We can collect some basic profile statistics from each. Let’s start with the
    NumPy version:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从每个版本收集一些基本的性能统计信息。让我们从 NumPy 版本开始：
- en: '[PRE42]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'This code will produce a lot of output. Let’s concentrate on the main GPU calls:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将产生大量的输出。让我们关注主要的 GPU 调用：
- en: '[PRE43]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Notice that our implementation spends a lot of time copying data in and out
    of the GPU: these are the `cuMemcpyDtoH` and `cuMemcpyHtoD` calls, which take
    more than 99% of the time.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们的实现花费了大量时间在 GPU 内部复制数据：这些是 `cuMemcpyDtoH` 和 `cuMemcpyHtoD` 调用，它们占用了超过 99%
    的时间。
- en: 'We can also inspect the cost of just the computation (i.e., kernel) part. The
    following is the NumPy abridged version:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以检查仅计算（即内核）部分的成本。以下是一个简化的 NumPy 版本：
- en: '[PRE44]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The time cost is 365860777 ns, or 365 ms.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 时间成本是 365860777 纳秒，或 365 毫秒。
- en: 'The time cost for the CuPy version using Numba is:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Numba 的 CuPy 版本的时间成本为：
- en: '[PRE45]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The result is 180 ms.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是 180 毫秒。
- en: 'Finally, the time cost for CUDA C is:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，CUDA C 的时间成本为：
- en: '[PRE46]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The result is 5.8 ms.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是 5.8 毫秒。
- en: The NumPy version is twice as slow as Numba. The C version is 32 times faster
    than the Numba version for kernel execution.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 版本比 Numba 慢两倍。对于内核执行，C 版本比 Numba 版本快 32 倍。
- en: 'Nsight Systems has a great GUI, invoked using `nsys-ui`, that allows you to
    explore traces and follow execution in real time. While it’s difficult to catch
    such dynamism in a screenshot, figure 9.3 shows a zoomed-in portion of the trace
    for the C version of our Mandelbrot generator. The application can be followed
    by CPU and GPU events, but here we concentrate on the GPU ones. You can see two
    blocks of relevance. First, in the one on the left, a host-to-device transfer
    is copying the NumPy matrix for positions into a CuPy version on the GPU: `cp_pos_array
    = cp.array(pos_array)`. The second block is actually doing the Mandelbrot computation.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Nsight Systems有一个出色的GUI，通过`nsys-ui`调用，允许您实时探索跟踪并跟踪执行。虽然很难在屏幕截图中捕捉到这种动态，但图9.3显示了我们的Mandelbrot生成器C版本的跟踪的放大部分。应用程序可以通过CPU和GPU事件进行跟踪，但在这里我们专注于GPU事件。您可以看到两个相关的块。首先，在左侧的块中，主机到设备的传输正在将NumPy矩阵的位置复制到GPU上的CuPy版本：`cp_pos_array
    = cp.array(pos_array)`。第二个块实际上正在执行Mandelbrot计算。
- en: '![](../Images/CH09_F03_Antao.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F03_Antao.png)'
- en: 'Figure 9.3 The GUI for Nsight Systems. Top left window: an outline of all processes
    allowing GPU and CPU usage. Main window: a temporal view of executions. Bottom
    left: temporal statistics of several GPU operations. Bottom right: details about
    one of the blocks from the main window.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 Nsight Systems的GUI。左上角窗口：所有进程的概览，显示GPU和CPU的使用情况。主窗口：执行的时间视图。左下角：几个GPU操作的时间统计。右下角：主窗口中一个块的详细信息。
- en: 'To sum up the two most crucial takeaways from this section:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 总结本节最重要的两个要点：
- en: As with CPUs, if you have performance problems, it is better to quantify the
    problem with proper profiling than to guess.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就像CPU一样，如果您遇到性能问题，最好是使用适当的分析来量化问题，而不是猜测。
- en: If GPU libraries exist that mimic the CPU APIs that you already know, the most
    efficient path is probably to use those libraries instead of writing your own
    code from scratch to implement the same functionality.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果存在模仿您已知的CPU API的GPU库，那么最有效的方法可能是使用这些库，而不是从头开始编写代码来实现相同的功能。
- en: Summary
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: While CPUs provide a handful of computation units that are very fast and can
    work on different problems, GPUs typically provide thousands of computation units
    that are slow and expected to do similar workloads.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然 CPU 提供了一些非常快且可以处理不同问题的计算单元，但 GPU 通常提供成千上万的计算单元，这些单元速度较慢，预期执行相似的工作负载。
- en: GPUs provide computational power that is highly suited for efficient data processing,
    as many data science problems rely on data structures like matrices that lend
    themselves to parallelization via the use of the same algorithm over many data
    points.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU提供了非常适合高效数据处理的计算能力，因为许多数据科学问题依赖于矩阵等数据结构，这些数据结构可以通过在多个数据点上使用相同的算法进行并行化。
- en: There are several GPU manufacturers, but in reality, the standard for GPU computing
    is based on NVIDIA hardware.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然有多个GPU制造商，但事实上，GPU计算的标准是基于NVIDIA硬件的。
- en: When writing code for GPUs, we need to be aware that the compute model of GPUs
    is very different from CPUs and requires a different mindset from traditional
    sequential CPU computing.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当为GPU编写代码时，我们需要意识到GPU的计算模型与CPU非常不同，并且需要与传统顺序CPU计算不同的思维方式。
- en: Standard Python code cannot be directly run on top of a GPU; we need to consider
    alternatives to be able to explore GPU power.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准Python代码不能直接在GPU上运行；我们需要考虑替代方案来探索GPU的强大功能。
- en: There are already many Python libraries that allow the use of GPUs without needing
    to know how to program them directly.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已经有许多Python库允许使用GPU，而无需直接了解如何编程它们。
- en: Many Python libraries are almost drop-in replacements for existing CPU versions.
    For example, CuPy exposes a similar interface to NumPy while working on GPUs,
    and cuDF has a similar interface to pandas.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多Python库几乎是现有CPU版本的直接替代品。例如，CuPy在GPU上工作时提供了一个与NumPy相似的接口，而cuDF则有一个与pandas相似的接口。
- en: 'Numba can generate code for GPUs, but there is little value in just annotating
    existing Python code with Numba: code needs to be redesigned to explore the extreme
    parallelism that is possible with many algorithms working on large arrays.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Numba可以为GPU生成代码，但仅仅用Numba注释现有的Python代码价值不大：代码需要重新设计，以探索许多算法在大型数组上工作时的极端并行性。
- en: Numba code, even for GPUs, can interact seamlessly with NumPy, allowing it to
    offload highly parallel algorithms while still integrating with the traditional
    Python data analysis stack.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Numba代码，即使是针对GPU的，也可以与NumPy无缝交互，允许它卸载高度并行的算法，同时仍然与传统的Python数据分析堆栈集成。
