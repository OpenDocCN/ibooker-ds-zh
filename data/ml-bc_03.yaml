- en: 3 Machine learning for classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3 机器学习用于分类
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Performing exploratory data analysis for identifying important features
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行探索性数据分析以识别重要特征
- en: Encoding categorical variables to use them in machine learning models
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将分类变量编码以在机器学习模型中使用
- en: Using logistic regression for classification
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用逻辑回归进行分类
- en: In this chapter, we are going to use machine learning to predict churn.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用机器学习来预测客户流失。
- en: '*Churn* is when customers stop using the services of a company. Thus, churn
    prediction is about identifying customers who are likely to cancel their contracts
    soon. If the company can do that, it can offer discounts on these services in
    an effort to keep the users.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*客户流失*是指客户停止使用公司的服务。因此，客户流失预测就是识别那些可能很快取消合同的客户。如果公司能够做到这一点，它就可以通过提供折扣来努力留住用户。'
- en: 'Naturally, we can use machine learning for that: we can use past data about
    customers who churned and, based on that, create a model for identifying present
    customers who are about to leave. This is a binary classification problem. The
    target variable that we want to predict is categorical and has only two possible
    outcomes: churn or not churn.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 自然地，我们可以使用机器学习来做到这一点：我们可以使用关于流失客户的过去数据，并根据这些数据创建一个模型来识别即将离开的当前客户。这是一个二元分类问题。我们想要预测的目标变量是分类变量，并且只有两种可能的结果：流失或未流失。
- en: 'In chapter 1, we learned that many supervised machine learning models exist,
    and we specifically mentioned ones that can be used for binary classification,
    including logistic regression, decision trees, and neural networks. In this chapter,
    we start with the simplest one: logistic regression. Even though it’s indeed the
    simplest, it’s still powerful and has many advantages over other models: it’s
    fast and easy to understand, and its results are easy to interpret. It’s a workhorse
    of machine learning and the most widely used model in the industry.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，我们了解到存在许多监督机器学习模型，我们特别提到了可以用于二元分类的模型，包括逻辑回归、决策树和神经网络。在本章中，我们从最简单的一个开始：逻辑回归。尽管它确实是最简单的，但它仍然非常强大，并且与其他模型相比具有许多优势：它速度快，易于理解，其结果易于解释。它是机器学习中的工作马，也是工业界最广泛使用的模型。
- en: 3.1 Churn prediction project
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.1 客户流失预测项目
- en: The project we prepared for this chapter is churn prediction for a telecom company.
    We will use logistic regression and Scikit-learn for that.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为本章准备的项目是电信公司的客户流失预测。我们将使用逻辑回归和Scikit-learn来完成这个项目。
- en: 'Imagine that we are working at a telecom company that offers phone and internet
    services, and we have a problem: some of our customers are churning. They no longer
    are using our services and are going to a different provider. We would like to
    prevent that from happening, so we develop a system for identifying these customers
    and offer them an incentive to stay. We want to target them with promotional messages
    and give them a discount. We also would like to understand why the model thinks
    our customers churn, and for that, we need to be able to interpret the model’s
    predictions.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们正在一家提供电话和互联网服务的电信公司工作，我们遇到了一个问题：一些客户开始流失。他们不再使用我们的服务，转而去了其他供应商。我们希望阻止这种情况发生，因此我们开发了一个系统来识别这些客户，并给予他们留存的激励。我们希望通过促销信息来吸引他们，并给予他们折扣。我们还希望了解模型为什么认为我们的客户会流失，为此，我们需要能够解释模型的预测结果。
- en: 'We have collected a dataset where we’ve recorded some information about our
    customers: what type of services they used, how much they paid, and how long they
    stayed with us. We also know who canceled their contracts and stopped using our
    services (churned). We will use this information as the target variable in the
    machine learning model and predict it using all other available information.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收集了一个数据集，其中记录了一些关于我们客户的信息：他们使用了什么类型的服务，他们支付了多少钱，以及他们与我们在一起的时间有多长。我们还知道谁取消了他们的合同并停止使用我们的服务（流失）。我们将使用这些信息作为机器学习模型的目标变量，并使用所有其他可用信息来预测它。
- en: 'The plan for the project follows:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 项目的计划如下：
- en: 'First, we download the dataset and do some initial preparation: rename columns
    and change values inside columns to be consistent throughout the entire dataset.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们下载数据集并进行一些初步准备：重命名列并更改列内的值，以确保整个数据集的一致性。
- en: Then we split the data into train, validation, and test so we can validate our
    models.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们将数据分为训练集、验证集和测试集，以便我们可以验证我们的模型。
- en: As part of the initial data analysis, we look at feature importance to identify
    which features are important in our data.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为初步数据分析的一部分，我们查看特征重要性以确定哪些特征在我们的数据中很重要。
- en: We transform categorical variables into numeric variables so we can use them
    in the model.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将分类变量转换为数值变量，以便在模型中使用它们。
- en: Finally, we train a logistic regression model.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们训练一个逻辑回归模型。
- en: In the previous chapter, we implemented everything ourselves, using Python and
    NumPy. In this project, however, we will start using Scikit-learn, a Python library
    for machine learning. Namely, we will use it for
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们完全是自己实现的，使用了 Python 和 NumPy。然而，在这个项目中，我们将开始使用 Scikit-learn，这是一个用于机器学习的
    Python 库。具体来说，我们将用它来
- en: Splitting the dataset into train and test
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集分为训练集和测试集
- en: Encoding categorical variables
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对分类变量进行编码
- en: Training logistic regression
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练逻辑回归
- en: 3.1.1 Telco churn dataset
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1.1 Telco churn 数据集
- en: As in the previous chapter, we will use Kaggle datasets for data. This time
    we will use data from [https://www.kaggle.com/blastchar/telco-customer-churn](https://www.kaggle.com/blastchar/telco-customer-churn).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章所述，我们将使用 Kaggle 数据集进行数据。这次我们将使用来自 [https://www.kaggle.com/blastchar/telco-customer-churn](https://www.kaggle.com/blastchar/telco-customer-churn)
    的数据。
- en: 'According to the description, this dataset has the following information:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 根据描述，这个数据集包含以下信息：
- en: 'Services of the customers: phone; multiple lines; internet; tech support and
    extra services such as online security, backup, device protection, and TV streaming'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户服务：电话；多线；互联网；技术支持和额外服务，如在线安全、备份、设备保护和电视流媒体
- en: 'Account information: how long they have been clients, type of contract, type
    of payment method'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 账户信息：他们作为客户的时间长度、合同类型、支付方式类型
- en: 'Charges: how much the client was charged in the past month and in total'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 费用：客户在过去一个月和总计中被收取的费用
- en: 'Demographic information: gender, age, and whether they have dependents or a
    partner'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人口统计信息：性别、年龄以及他们是否有子女或伴侣
- en: 'Churn: yes/no, whether the customer left the company within the past month'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 演退：是/否，客户在过去一个月内是否离开了公司
- en: 'First, we download the dataset. To keep things organized, we first create a
    folder, chapter-03-churn-prediction. Then we go to that directory and use Kaggle
    CLI for downloading the data:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们下载数据集。为了保持整洁，我们首先创建一个文件夹，chapter-03-churn-prediction。然后我们进入那个目录，并使用 Kaggle
    CLI 下载数据：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After downloading it, we unzip the archive to get the CSV file from there:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 下载后，我们解压缩存档以从那里获取 CSV 文件：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We are ready to start now.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以开始了。
- en: 3.1.2 Initial data preparation
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1.2 初始数据准备
- en: 'The first step is creating a new notebook in Jupyter. If it’s not running,
    start it:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是创建一个新的 Jupyter 笔记本。如果它没有运行，请启动它：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We name the notebook chapter-03-churn-project (or any other name that we like).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将笔记本章节命名为 chapter-03-churn-project（或我们喜欢的任何其他名称）。
- en: 'As previously, we begin with adding the usual imports:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们首先添加常用的导入：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'And now we can read the dataset:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以读取数据集：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We use the `read_csv` function to read the data and then write the results
    to a dataframe named `df`. To see how many rows it contains, let’s use the `len`
    function:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `read_csv` 函数读取数据，然后将结果写入名为 `df` 的数据框。为了查看它包含多少行，让我们使用 `len` 函数：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It prints 7043, so there are 7,043 rows in this dataset. The dataset is not
    large but should be enough to train a decent model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 它打印出 7043，所以这个数据集有 7,043 行。数据集不大，但应该足以训练一个不错的模型。
- en: Next, let’s look at the first couple of rows using `df.head``()` (figure 3.1).
    By default, it shows the first five rows of the dataframe.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们使用 `df.head()` 查看前几行（图3.1）。默认情况下，它显示数据框的前五行。
- en: '![](../Images/03_01.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_01.png)'
- en: Figure 3.1 The output of the `df.head()` command showing the first five rows
    of the telco churn dataset
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 `df.head()` 命令的输出，显示了 telco churn 数据集的前五行
- en: 'This dataframe has quite a few columns, so they all don’t fit on the screen.
    Instead, we can transpose the dataframe using the `T` function, switching columns
    and rows so the columns (customerID, gender, and so on) become rows. This way
    we can see a lot more data (figure 3.2):'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据框有相当多的列，所以它们都不适合在屏幕上显示。相反，我们可以使用 `T` 函数转置数据框，交换列和行，使得列（如 customerID、性别等）变成行。这样我们就可以看到更多的数据（图3.2）：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/03_02.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_02.png)'
- en: 'Figure 3.2 The output of the `df.head().T` command showing the first three
    rows of the telco churn dataset. The original rows are shown as columns: this
    way, it’s possible to see more data without having to use the slider.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2 `df.head().T` 命令的输出，显示了电信客户流失数据集的前三行。原始行以列的形式显示：这样，可以查看更多数据，而无需使用滑块。
- en: 'We see that the dataset has a few columns:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到数据集有几个列：
- en: 'CustomerID: the ID of the customer'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'CustomerID: 客户ID'
- en: 'Gender: male/female'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gender: 男性/女性'
- en: 'SeniorCitizen: whether the customer is a senior citizen (0/1)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'SeniorCitizen: 客户是否为老年人（0/1）'
- en: 'Partner: whether they live with a partner (yes/no)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Partner: 是否与伴侣同住（是/否）'
- en: 'Dependents: whether they have dependents (yes/no)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dependents: 是否有受抚养人（是/否）'
- en: 'Tenure: number of months since the start of the contract'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tenure: 自合同开始以来的月份数'
- en: 'PhoneService: whether they have phone service (yes/no)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'PhoneService: 是否有电话服务（是/否）'
- en: 'MultipleLines: whether they have multiple phone lines (yes/no/no phone service)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'MultipleLines: 是否有多个电话线路（是/否/无电话服务）'
- en: 'InternetService: the type of internet service (no/fiber/optic)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'InternetService: 互联网服务类型（无/光纤/光纤）'
- en: 'OnlineSecurity: if online security is enabled (yes/no/no internet)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OnlineSecurity: 如果启用了在线安全（是/否/无互联网）'
- en: 'OnlineBackup: if online backup service is enabled (yes/no/no internet)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OnlineBackup: 如果启用了在线备份服务（是/否/无互联网）'
- en: 'DeviceProtection: if the device protection service is enabled (yes/no/no internet)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'DeviceProtection: 如果启用了设备保护服务（是/否/无互联网）'
- en: 'TechSupport: if the customer has tech support (yes/no/no internet)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'TechSupport: 客户是否有技术支持（是/否/无互联网）'
- en: 'StreamingTV: if the TV streaming service is enabled (yes/no/no internet)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'StreamingTV: 如果启用了电视流媒体服务（是/否/无互联网）'
- en: 'StreamingMovies: if the movie streaming service is enabled (yes/no/no internet)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'StreamingMovies: 如果启用了电影流媒体服务（是/否/无互联网）'
- en: 'Contract: the type of contract (monthly/yearly/two years)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Contract: 合同类型（每月/年度/两年）'
- en: 'PaperlessBilling: if the billing is paperless (yes/no)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'PaperlessBilling: 如果账单是无纸化的（是/否）'
- en: 'PaymentMethod: payment method (electronic check, mailed check, bank transfer,
    credit card)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'PaymentMethod: 付款方式（电子支票、邮寄支票、银行转账、信用卡）'
- en: 'MonthlyCharges: the amount charged monthly (numeric)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'MonthlyCharges: 每月收费金额（数值）'
- en: 'TotalCharges: the total amount charged (numeric)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'TotalCharges: 总计收费金额（数值）'
- en: 'Churn: if the client has canceled the contract (yes/no)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Churn: 如果客户已取消合同（是/否）'
- en: 'The most interesting one for us is Churn. As the target variable for our model,
    this is what we want to learn to predict. It takes two values: yes if the customer
    churned and no if the customer didn’t.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说最有趣的是Churn。作为我们模型的目标变量，这是我们想要学习预测的内容。它有两个值：如果客户流失则为“是”，如果客户未流失则为“否”。
- en: 'When reading a CSV file, Pandas tries to automatically determine the proper
    type of each column. However, sometimes it’s difficult to do it correctly, and
    the inferred types aren’t what we expect them to be. This is why it’s important
    to check whether the actual types are correct. Let’s have a look at them by using
    `df.dtypes`:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '当读取CSV文件时，Pandas会尝试自动确定每列的正确类型。然而，有时很难正确完成这项任务，推断出的类型并不是我们期望的。这就是为什么检查实际类型是否正确很重要的原因。让我们通过使用`df.dtypes`来查看它们： '
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We see (figure 3.3) that most of the types are inferred correctly. Recall that
    object means a string value, which is what we expect for most of the columns.
    However, we may notice two things. First, SeniorCitizen is detected as int64,
    so it has a type of integer, not object. The reason for this is that instead of
    the values yes and no, as we have in other columns, there are 1 and 0 values,
    so Pandas interprets this as a column with integers. It’s not really a problem
    for us, so we don’t need to do any additional preprocessing for this column.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到（图3.3）大多数类型都被正确推断。回想一下，对象表示字符串值，这是我们期望大多数列的内容。然而，我们可能注意到两件事。首先，SeniorCitizen被检测为int64，因此它具有整型类型，而不是对象。原因是，与其他列中的yes和no值不同，这里有的是1和0值，因此Pandas将其解释为整型列。这对我们来说并不是真正的问题，因此我们不需要为此列进行任何额外的预处理。
- en: '![](../Images/03_03.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_03.png)'
- en: Figure 3.3 Automatically inferred types for all the columns of the dataframe.
    Object means a string. TotalCharges is incorrectly identified as “object,” but
    it should be “float.”
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 自动推断的数据框所有列的类型。对象表示字符串。TotalCharges被错误地识别为“对象”，但它应该是“浮点数”。
- en: 'The other thing to note is the type for TotalCharges. We would expect this
    column to be numeric: it contains the total amount of money the client was charged,
    so it should be a number, not a string. Yet Pandas infers the type as “object.”
    The reason is that in some cases this column contains a space (“ ”) to represent
    a missing value. When coming across nonnumeric characters, Pandas has no other
    option but to declare the column “object.”'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 另一点需要注意的是 TotalCharges 的类型。我们预计此列应该是数值类型：它包含客户被收取的总金额，因此应该是数字，而不是字符串。然而，Pandas
    推断其类型为“对象”。原因是，在某些情况下，此列包含一个空格（“ ”）来表示缺失值。当遇到非数值字符时，Pandas 没有其他选择，只能将该列声明为“对象”。
- en: 'Important Watch out for cases when you expect a column to be numeric, but Pandas
    says it’s not: most likely the column contains special encoding for missing values
    that require additional preprocessing.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示：注意当你期望一个列是数值类型，但 Pandas 表示它不是的情况：最可能的原因是该列包含用于缺失值的特殊编码，这需要额外的预处理。
- en: 'We can force this column to be numeric by converting it to numbers using a
    special function in Pandas: `to_numeric`. By default, this function raises an
    exception when it sees nonnumeric data (such as spaces), but we can make it skip
    these cases by specifying the `errors=''coerce''` option. This way Pandas will
    replace all nonnumeric values with a `NaN` (not a number):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用 Pandas 中的特殊函数 `to_numeric` 将此列强制转换为数值类型：通过将列转换为数字。默认情况下，此函数在遇到非数值数据（如空格）时会引发异常，但我们可以通过指定
    `errors='coerce'` 选项来使其跳过这些情况。这样 Pandas 将所有非数值值替换为 `NaN`（不是一个数字）：
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To confirm that data indeed contains nonnumeric characters, we can now use
    the `isnull()` function of `total_charges` to refer to all the rows where Pandas
    couldn’t parse the original string:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认数据确实包含非数值字符，我们现在可以使用 `total_charges` 的 `isnull()` 函数来引用 Pandas 无法解析原始字符串的所有行：
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We see that indeed there are spaces in the TotalCharges column (figure 3.4).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 TotalCharges 列中确实存在空格（图 3.4）。
- en: '![](../Images/03_04.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_04.png)'
- en: Figure 3.4 We can spot nonnumeric data in a column by parsing the content as
    numeric and see at which rows the parsing fails.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 我们可以通过将内容解析为数值来检测列中的非数值数据，并查看解析失败的行。
- en: 'Now it’s up to us to decide what to do with these missing values. Although
    we could do many things with them, we are going to do the same thing we did in
    the previous chapter—set the missing values to zero:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在取决于我们决定如何处理这些缺失值。尽管我们可以对它们做很多事情，但我们将做与上一章相同的事情——将缺失值设置为零：
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In addition, we notice that the column names don’t follow the same naming convention.
    Some of them start with a lower letter, whereas others start with a capital letter,
    and there are also spaces in the values.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们注意到列名不遵循相同的命名约定。其中一些以小写字母开头，而其他一些以大写字母开头，值中也有空格。
- en: 'Let’s make it uniform by lowercasing everything and replacing spaces with underscores.
    This way we remove all the inconsistencies in the data. We use the exact same
    code we used in the previous chapter:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将所有内容转换为小写并替换空格为下划线来使其统一。这样我们就消除了数据中的所有不一致性。我们使用与上一章完全相同的代码：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, let’s look at our target variable: `churn`. Currently, it’s categorical,
    with two values, “yes” and “no” (figure 3.5A). For binary classification, all
    models typically expect a number: 0 for “no” and 1 for “yes.” Let’s convert it
    to numbers:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看我们的目标变量：`churn`。目前，它是分类的，有两个值，“是”和“否”（图 3.5A）。对于二元分类，所有模型通常都期望一个数字：0
    代表“否”，1 代表“是”。让我们将其转换为数字：
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: When we use `df.churn` `==` `'yes'`, we create a Pandas series of type boolean.
    A position in the series is equal to `True` if it’s “yes” in the original series
    and `False` otherwise. Because the only other value it can take is “no,” this
    converts “yes” to `True` and “no” to `False` (figure 3.5B). When we perform casting
    by using the `astype(int)` function, we convert `True` to 1 and `False` to 0 (figure.
    3.5C). This is exactly the same idea that we used in the previous chapter when
    we implemented category encoding.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用 `df.churn` `==` `'yes'` 时，我们创建了一个布尔类型的 Pandas 系列对象。如果原始系列中的位置是“是”，则该系列的位置等于
    `True`，否则为 `False`。因为该系列只能取“否”这个值，所以“是”转换为 `True`，“否”转换为 `False`（图 3.5B）。当我们使用
    `astype(int)` 函数进行类型转换时，将 `True` 转换为 1，将 `False` 转换为 0（图 3.5C）。这正是我们在上一章实现类别编码时使用的相同思路。
- en: '![](../Images/03_05a.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_05a.png)'
- en: '(A) The original Churn column: it’s a Pandas series that contains only “yes”
    and “no” values.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: （A）原始的 Churn 列：它是一个只包含“是”和“否”值的 Pandas 系列对象。
- en: '![](../Images/03_05b.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_05b.png)'
- en: '(B) The result of the == operator: it’s a Boolean series with `True` when the
    elements of the original series are “yes” and `False` otherwise.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: （B）比较运算符的结果：它是一个布尔序列，当原始序列的元素是“yes”时为 `True`，否则为 `False`。
- en: '![](../Images/03_05c.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图3.5](../Images/03_05c.png)'
- en: '(C) The result of converting the Boolean series to integer: `True` is converted
    to 1 and `False` is converted to 0.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: （C）将布尔序列转换为整数的结果：`True` 转换为1，`False` 转换为0。
- en: Figure 3.5 The expression `(df.churn` `==` `'yes').astype(int)` broken down
    by individual steps
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 表达式 `(df.churn == 'yes').astype(int)` 的逐个步骤分解
- en: We’ve done a bit of preprocessing already, so let’s put aside some data for
    testing. In the previous chapter, we implemented the code for doing it ourselves.
    This is great for understanding how it works, but typically we don’t write such
    things from scratch every time we need them. Instead, we use existing implementations
    from libraries. In this chapter we use Scikit-learn, and it has a module called
    `model_selection` that can handle data splitting. Let’s use it.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经做了一些预处理，所以让我们留出一部分数据用于测试。在上一章中，我们实现了自己进行这一操作的代码。这对于理解其工作原理是很好的，但通常我们不需要每次都从头开始编写这些代码。相反，我们使用库中的现有实现。在本章中，我们使用Scikit-learn，它有一个名为
    `model_selection` 的模块可以处理数据分割。让我们使用它。
- en: 'The function we need to import from `model_selection` is called `train_test_split`:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要从 `model_selection` 中导入的函数叫做 `train_test_split`：
- en: '[PRE13]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'After importing, it’s ready to be used:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 导入后，就可以使用了：
- en: '[PRE14]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The function `train_test_split` takes a dataframe `df` and creates two new
    dataframes: `df_train_full` and `df_test`. It does this by shuffling the original
    dataset and then splitting it in such a way that the test set contains 20% of
    the data and the train set contains the remaining 80% (figure 3.6). Internally,
    it’s implemented similarly to what we did ourselves in the previous chapter.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_test_split` 函数接受一个数据框 `df` 并创建两个新的数据框：`df_train_full` 和 `df_test`。它是通过打乱原始数据集然后以这种方式分割数据来实现的，即测试集包含20%的数据，训练集包含剩余的80%（图3.6）。在内部，它的实现与我们上一章自己实现的方式相似。'
- en: '![](../Images/03_06.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图3.6](../Images/03_06.png)'
- en: Figure 3.6 When using `train_test_split`, the original dataset is shuffled and
    then split such that 80% of the data goes to the train set and the remaining 20%
    goes to the test set.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 当使用 `train_test_split` 时，原始数据集被打乱，然后分割，使得80%的数据进入训练集，剩余的20%进入测试集。
- en: 'This function contains a few parameters:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数包含几个参数：
- en: 'The first parameter that we pass is the dataframe that we want to split: `df`.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们传递的第一个参数是我们想要分割的数据框：`df`。
- en: The second parameter is `test_size`, which specifies the size of the dataset
    we want to set aside for testing—20% for our case.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个参数是 `test_size`，它指定了我们想要留出的测试数据集的大小——在我们的例子中是20%。
- en: The third parameter we pass is `random_state`. It’s needed for ensuring that
    every time we run this code, the dataframe is split in the exact same way.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们传递的第三个参数是 `random_state`。它对于确保每次我们运行此代码时，数据框的分割方式完全相同是必要的。
- en: Shuffling of data is done using a random-number generator; it’s important to
    fix the random seed to ensure that every time we shuffle the data, the final arrangement
    of rows will be the same.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的打乱是通过随机数生成器完成的；固定随机种子对于确保每次我们打乱数据时，行的最终排列都是相同的非常重要。
- en: 'We do see a side effect from shuffling: if we look at the dataframes after
    splitting by using the `head()` method, for example, we notice that the indices
    appear to be randomly ordered (figure 3.7).'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实看到了打乱带来的副作用：如果我们使用 `head()` 方法查看分割后的数据框，例如，我们会注意到索引似乎是无序的（图3.7）。
- en: '![](../Images/03_07.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图3.7](../Images/03_07.png)'
- en: 'Figure 3.7 The side effect of `train_test_split`: the indices (the first column)
    are shuffled in the new dataframes, so instead of consecutive numbers like 0,
    1, 2, ..., they look random.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.7 `train_test_split` 的副作用：新数据框中的索引（第一列）被随机打乱，因此不再是连续的数字，如0、1、2、...，而是看起来是随机的。
- en: 'In the previous chapter, we split the data into three parts: train, validation,
    and test. However, the `train_test_split` function splits the data into only two
    parts: train and test. In spite of that, we can still split the original dataset
    into three parts; we just take one part and split it again (figure 3.8).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们将数据分为三个部分：训练集、验证集和测试集。然而，`train_test_split` 函数只将数据分为两个部分：训练集和测试集。尽管如此，我们仍然可以将原始数据集分为三个部分；我们只需取出一部分并再次分割（图3.8）。
- en: '![](../Images/03_08.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图3.8](../Images/03_08.png)'
- en: Figure 3.8 Because `train_test_split` splits a dataset into only two parts,
    we perform the split two times because we need three parts. First, we split the
    entire dataset into full train and test, and then we split full train into train
    and validation.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 由于`train_test_split`将数据集仅分为两部分，我们需要三部分，因此我们进行了两次分割。首先，我们将整个数据集分为完整的训练集和测试集，然后我们将完整的训练集分为训练集和验证集。
- en: 'Let’s take the `df_train_full` dataframe and split it one more time into train
    and validation:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次将`df_train_full`数据框分割成训练集和验证集：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Sets the random seed when doing the split to make sure that every time we
    run the code, the result is the same
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在分割时设置随机种子，以确保每次运行代码时结果都是相同的
- en: ❷ Takes the column with the target variable, churn, and saves it outside the
    dataframe
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将包含目标变量churn的列保存到数据框外部
- en: ❸ Deletes the churn columns from both dataframes to make sure we don’t accidentally
    use the churn variable as a feature during training
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 从两个数据框中删除churn列，以确保我们不会在训练过程中意外使用churn变量作为特征
- en: Now the dataframes are prepared, and we are ready to use the training dataset
    for performing initial exploratory data analysis.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据框已经准备好了，我们可以使用训练数据集进行初步的探索性数据分析。
- en: 3.1.3 Exploratory data analysis
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1.3 探索性数据分析
- en: Looking at the data before training a model is important. The more we know about
    the data and the problems inside, the better the model we can build afterward.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型之前查看数据非常重要。我们了解的数据和问题越多，之后构建的模型就越好。
- en: 'We should always check for any missing values in the dataset because many machine
    learning models cannot easily deal with missing data. We have already found a
    problem with the TotalCharges column and replaced the missing values with zeros.
    Now let’s see if we need to perform any additional null handling:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该始终检查数据集中是否存在任何缺失值，因为许多机器学习模型难以处理缺失数据。我们已经发现了TotalCharges列的问题，并用零替换了缺失值。现在让我们看看是否需要执行任何额外的空值处理：
- en: '[PRE16]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: It prints all zeros (figure 3.9), so we have no missing values in the dataset
    and don’t need to do anything extra.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 它打印所有零（图3.9），因此数据集中没有缺失值，不需要做任何额外的事情。
- en: '![](../Images/03_09.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_09.png)'
- en: 'Figure 3.9 We don’t have to handle missing values in the dataset: all the values
    in all the columns are present.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 我们不需要处理数据集中的缺失值：所有列中的所有值都是存在的。
- en: 'Another thing we should do is check the distribution of values in the target
    variable. Let’s take a look at it using the `value_counts()` method:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该做的一件事是检查目标变量中值的分布。让我们使用`value_counts()`方法来看看：
- en: '[PRE17]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: It prints
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 它打印
- en: '[PRE18]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The first column is the value of the target variable, and the second is the
    count. As we see, the majority of the customers didn’t churn.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 第一列是目标变量的值，第二列是计数。正如我们所见，大多数客户没有流失。
- en: We know the absolute numbers, but let’s also check the proportion of churned
    users among all customers. For that, we need to divide the number of customers
    who churned by the total number of customers. We know that 1,521 of 5,634 churned,
    so the proportion is
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道绝对数字，但让我们也检查所有客户中流失用户的比例。为此，我们需要将流失客户数除以客户总数。我们知道5,634中有1,521人流失，所以比例是
- en: 1521 / 5634 = 0.27
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 1521 / 5634 = 0.27
- en: This gives us the proportion of churned users, or the probability that a customer
    will churn. As we see in the training dataset, approximately 27% of the customers
    stopped using our services, and the rest remained as customers.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了流失用户的比例，或者客户流失的概率。正如我们在训练数据集中看到的那样，大约27%的客户停止使用我们的服务，其余的继续作为客户。
- en: 'The proportion of churned users, or the probability of churning, has a special
    name: churn rate.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 流失用户的比例，或流失的概率，有一个特殊的名称：流失率。
- en: 'There’s another way to calculate the churn rate: the `mean()` method. It’s
    more convenient to use than manually calculating the rate:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 计算流失率的另一种方法是`mean()`方法。它比手动计算率更方便：
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Using this method, we also get 0.27 (figure 3.10).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，我们也得到了0.27（图3.10）。
- en: '![](../Images/03_10.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_10.png)'
- en: Figure 3.10 Calculating the global churn rate in the training dataset
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 计算训练数据集中的全局流失率
- en: The reason it produces the same result is the way we calculate the mean value.
    If you don’t remember, the formula for that is
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 它产生相同结果的原因是我们计算平均值的方式。如果您不记得，该公式的计算方法是
- en: '![](../Images/03_10-Equation_3-1.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_10-Equation_3-1.png)'
- en: where *n* is the number of items in the dataset.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *n* 是数据集中的项目数。
- en: Because *y[i]* can take only zeros and ones, when we sum all of them, we get
    the number of ones, or the number of people who churned. Then we divide it by
    the total number of customers, which is exactly the same as the formula we used
    for calculating the churn rate previously.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 *y[i]* 只能取零和一，当我们把它们全部加起来时，我们得到的是一的数量，或者说是转出的人数。然后我们将其除以总客户数，这与我们之前计算转出率的公式完全相同。
- en: 'Our churn dataset is an example of a so-called *imbalanced* dataset. There
    were three times as many people who didn’t churn in our dataset as those who did
    churn, and we say that the nonchurn class dominates the churn class. We can clearly
    see that: the churn rate in our data is 0.27, which is a strong indicator of class
    imbalance. The opposite of *imbalanced* is the *balanced* case, when positive
    and negative classes are equally distributed among all observations.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的转出数据集是一个所谓的*不平衡*数据集的例子。在我们的数据集中，没有转出的人数是转出人数的三倍，我们说非转出类别主导了转出类别。我们可以清楚地看到：我们的数据中的转出率是0.27，这是类别不平衡的强烈指标。与*不平衡*相反的是*平衡*的情况，即正负类别在所有观测值中均匀分布。
- en: Exercise 3.1
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 练习3.1
- en: The mean of a Boolean array is
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 布尔数组的平均值是
- en: 'a) The percentage of `False` elements in the array: the number of `False` elements
    divided by the length of the array'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: a) 数组中`False`元素的比例：`False`元素的数量除以数组的长度
- en: 'b) The percentage of `True` elements in the array: the number of `True` elements
    divided by the length of the array'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: b) 数组中`True`元素的比例：`True`元素的数量除以数组的长度
- en: c) The length of an array
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: c) 数组的长度
- en: Both the categorical and numerical variables in our dataset are important, but
    they are also different and need different treatment. For that, we want to look
    at them separately.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据集中的分类变量和数值变量都很重要，但它们也不同，需要不同的处理。为此，我们希望单独查看它们。
- en: 'We will create two lists:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建两个列表：
- en: '`categorical`, which will contain the names of categorical variables'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`分类`，它将包含分类变量的名称'
- en: '`numerical`, which, likewise, will have the names of numerical variables'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`数值`，同样，它将包含数值变量的名称'
- en: 'Let’s create them:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建它们：
- en: '[PRE20]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'First, we can see how many unique values each variable has. We already know
    we should have just a few for each column, but let’s verify it:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以看到每个变量有多少个唯一值。我们已经知道每个列应该只有几个，但让我们验证一下：
- en: '[PRE21]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Indeed, we see that most of the columns have two or three values and one (paymentmethod)
    has four (figure 3.11). This is good. We don’t need to spend extra time preparing
    and cleaning the data; everything is already good to go.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们看到大多数列都有两到三个值，而一个（paymentmethod）有四个（图3.11）。这是好的。我们不需要额外的时间来准备和清理数据；一切都已经准备好了。
- en: '![](../Images/03_11.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_11.png)'
- en: Figure 3.11 The number of distinct values for each categorical variable. We
    see that all the variables have very few unique values.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11 每个分类变量的不同值数量。我们看到所有变量都有非常少的唯一值。
- en: 'Now we come to another important part of exploratory data analysis: understanding
    which features may be important for our model.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来到了探索性数据分析的另一个重要部分：了解哪些特征可能对我们的模型很重要。
- en: 3.1.4 Feature importance
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1.4 特征重要性
- en: Knowing how other variables affect the target variable, churn, is the key to
    understanding the data and building a good model. This process is called *feature
    importance analysi*s, and it’s often done as a part of exploratory data analysis
    to figure out which variables will be useful for the model. It also gives us additional
    insights about the dataset and helps answer questions like “What makes customers
    churn?” and “What are the characteristics of people who churn?”
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 了解其他变量如何影响目标变量，即转出，是理解数据和构建好模型的关键。这个过程被称为*特征重要性分析*，它通常作为探索性数据分析的一部分来进行，以确定哪些变量对模型有用。它还为我们提供了关于数据集的额外见解，并帮助回答像“是什么导致客户转出？”和“转出的人有什么特征？”等问题。
- en: 'We have two different kinds of features: categorical and numerical. Each kind
    has different ways of measuring feature importance, so we will look at each separately.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两种不同类型的特征：分类和数值。每种类型都有不同的测量特征重要性的方法，因此我们将分别查看每种。
- en: Churn rate
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 转出率
- en: Let’s start by looking at categorical variables. The first thing we can do is
    look at the churn rate for each variable. We know that a categorical variable
    has a set of values it can take, and each value defines a group inside the dataset.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从查看分类变量开始。我们可以做的第一件事是查看每个变量的转出率。我们知道分类变量可以取一组值，每个值在数据集中定义一个组。
- en: 'We can look at all the distinct values of a variable. Then, for each variable,
    there’s a group of customers: all the customers who have this value. For each
    such group, we can compute the churn rate, which is the group churn rate. When
    we have it, we can compare it with the global churn rate—the churn rate calculated
    for all the observations at once.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以查看一个变量的所有不同值。然后，对于每个变量，都有一个客户群体：所有具有该值的客户。对于这样的每个群体，我们可以计算客户流失率，即群体客户流失率。当我们得到这个值时，我们可以将其与全局客户流失率进行比较——即一次性计算所有观察值的客户流失率。
- en: If the difference between the rates is small, the value is not important when
    predicting churn because this group of customers is not really different from
    the rest of the customers. On the other hand, if the difference is not small,
    something inside that group sets it apart from the rest. A machine learning algorithm
    should be able to pick this up and use it when making predictions.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两者之间的差异很小，那么在预测客户流失时，这个值并不重要，因为这个客户群体与其他客户并没有真正的区别。另一方面，如果差异很大，那么这个群体内部存在某些因素使其与其他客户群体区分开来。机器学习算法应该能够捕捉到这一点并在预测时使用它。
- en: 'Let’s check first for the `gender` variable. This `gender` variable can take
    two values, female and male. There are two groups of customers: ones that have
    `gender` `==` `''female''` and ones that have `gender` `==` `''male''` (figure
    3.12). To compute the churn rate for all female customers, we first select only
    rows that correspond to `gender` `==` `''female''` and then compute the churn
    rate for them:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先检查`gender`变量。这个`gender`变量可以取两个值，女性和男性。有两个客户群体：`gender` `==` `'female'` 的客户群体和
    `gender` `==` `'male'` 的客户群体（图3.12）。为了计算所有女性客户的客户流失率，我们首先只选择对应 `gender` `==` `'female'`
    的行，然后计算他们的客户流失率：
- en: '[PRE22]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](../Images/03_12.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图3.12](../Images/03_12.png)'
- en: 'Figure 3.12 The dataframe is split by the values of the `gender` variable into
    two groups: a group with `gender` `==` `"female"` and a group with `gender` `==`
    `"male"`.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 根据性别变量的值将数据框分为两组：一组是`gender` `==` `"female"` 的组，另一组是`gender` `==` `"male"`
    的组。
- en: 'We then do the same for all male customers:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们对所有男性客户做同样的处理：
- en: '[PRE23]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: When we execute this code and check the results, we see that the churn rate
    of female customers is 27.7% and that of male customers is 26.3%, whereas the
    global churn rate is 27% (figure 3.13). The difference between the group rates
    for both females and males is quite small, which indicates that knowing the gender
    of the customer doesn’t help us identify whether they will churn.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们执行此代码并检查结果时，我们看到女性客户的客户流失率是27.7%，男性客户的客户流失率是26.3%，而全局客户流失率是27%（图3.13）。女性和男性群体流失率之间的差异相当小，这表明了解客户的性别并不能帮助我们确定他们是否会流失。
- en: '![](../Images/03_13.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图3.13](../Images/03_13.png)'
- en: Figure 3.13 The global churn rate compared with churn rates among males and
    females. The numbers are quite close, which means that `gender` is not a useful
    variable when predicting churn.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13 全球客户流失率与男性和女性客户流失率的比较。这些数字非常接近，这意味着在预测客户流失时，`性别`不是一个有用的变量。
- en: 'Now let’s take a look at another variable: `partner`. It takes values of yes
    and no, so there are two groups of customers: the ones for which `partner` `==`
    `''yes''` and the ones for which `partner` `==` `''no''`.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看另一个变量：`partner`。它取值为“是”和“否”，因此有两组客户：`partner` `==` `'yes'` 的客户和 `partner`
    `==` `'no'` 的客户。
- en: 'We can check the group churn rates using the same code as we used previously.
    All we need to change is the filter conditions:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用之前使用的相同代码来检查分组客户流失率。我们只需要更改过滤条件：
- en: '[PRE24]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'As we see, the rates for those who have a partner are quite different from
    rates for those who don’t: 20% and 33%, respectively. It means that clients with
    no partner are more likely to churn than the ones with a partner (figure 3.14).'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，有伴侣的人的流失率与没有伴侣的人的流失率相当不同：分别是20%和33%。这意味着没有伴侣的客户比有伴侣的客户更有可能流失（图3.14）。
- en: '![](../Images/03_14.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图3.14](../Images/03_14.png)'
- en: Figure 3.14 The churn rate for people with a partner is significantly less than
    the rate for the ones without a partner—20.5% versus 33%—which indicates that
    the `partner` variable is useful for predicting churn.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 有伴侣的人的客户流失率显著低于没有伴侣的人的客户流失率——分别是20.5%和33%——这表明`partner`变量对预测客户流失是有用的。
- en: Risk ratio
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 风险比
- en: 'In addition to looking at the difference between the group rate and the global
    rate, it’s interesting to look at the ratio between them. In statistics, the ratio
    between probabilities in different groups is called the *risk ratio*, where *risk*
    refers to the risk of having the effect. In our case, the effect is churn, so
    it’s the risk of churning:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 除了观察组别比率与全球比率之间的差异之外，观察它们之间的比率也很有趣。在统计学中，不同组别概率之间的比率称为*风险比*，其中*风险*指的是出现效果的风险。在我们的案例中，效果是客户流失，因此是客户流失的风险：
- en: risk = group rate / global rate
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 风险 = 组别比率 / 全球比率
- en: 'For `gender` `==` `female`, for example, the risk of churning is 1.02:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于`性别`等于`女性`的情况，客户流失的风险是1.02：
- en: risk = 27.7% / 27% = 1.02
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 风险 = 27.7% / 27% = 1.02
- en: Risk is a number between zero and infinity. It has a nice interpretation that
    tells you how likely the elements of the group are to have the effect (churn)
    compared with the entire population.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 风险是一个介于零和无穷大之间的数值。它有一个很好的解释，告诉你组别元素出现效果（客户流失）的可能性与整个群体相比如何。
- en: 'If the difference between the group rate and the global rate is small, the
    risk is close to 1: this group has the same level of risk as the rest of the population.
    Customers in the group are as likely to churn as anyone else. In other words,
    a group with a risk close to 1 is not risky at all (figure 3.15, group A).'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如果组别比率与全球比率之间的差异很小，风险值接近1：这个组别的风险水平与整个人群相同。该组别的客户流失的可能性与其他人一样。换句话说，风险值接近1的组别根本不具风险（图3.15，组A）。
- en: 'If the risk is lower than 1, the group has lower risks: the churn rate in this
    group is smaller than the global churn. For example, the value 0.5 means that
    the clients in this group are two times less likely to churn than clients in general
    (figure 3.15, group B).'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果风险值低于1，那么这个组别的风险较低：这个组别的客户流失率低于全球流失率。例如，值0.5意味着这个组别的客户流失的可能性是普通客户的一半（图3.15，组B）。
- en: 'On the other hand, if the value is higher than 1, the group is risky: there’s
    more churn in the group than in the population. So a risk of 2 means that customers
    from the group are two times more likely to churn (figure 3.15, group C).'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果这个值高于1，那么这个组别是有风险的：组别中的客户流失率高于整个人群。因此，风险值为2意味着该组别的客户流失的可能性是整个人群的两倍（图3.15，组C）。
- en: '![](../Images/03_15.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_15.png)'
- en: Figure 3.15 Churn rate of different groups compared with the global churn rate.
    In group (A), the rates are approximately the same, so the risk of churn is around
    1\. In group (B), the group churn rate is smaller than the global rate, so the
    risk is around 0.5\. Finally, in group (C), the group churn rate is higher than
    the global rate, so the risk is close to 2.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 不同组别的客户流失率与全球客户流失率比较。在组别(A)中，比率大致相同，因此客户流失的风险约为1。在组别(B)中，组别客户流失率低于全球比率，因此风险约为0.5。最后，在组别(C)中，组别客户流失率高于全球比率，因此风险接近2。
- en: 'The term *risk* originally comes from controlled trials, in which one group
    of patients is given a treatment (a medicine) and the other group isn’t (only
    a placebo). Then we compare how effective the medicine is by calculating the rate
    of negative outcomes in each group and then calculating the ratio between the
    rates:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 术语*风险*最初来自对照试验，其中一组患者接受治疗（药物），而另一组则不接受（仅给予安慰剂）。然后我们通过计算每个组别负面结果的发生率，然后计算比率来比较药物的有效性：
- en: risk = negative outcome rate in group 1 / negative outcome rate in group 2
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 风险 = 组别1的负面结果发生率 / 组别2的负面结果发生率
- en: If medicine turns out to be effective, it’s said to reduce the risk of having
    the negative outcome, and the value of the risk is less than 1.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如果药物证明是有效的，它被认为可以降低出现负面结果的几率，且风险值小于1。
- en: Let’s calculate the risks for `gender` and `partner`. For the `gender` variable,
    the risks for both males and females is around 1 because the rates in both groups
    aren’t significantly different from the global rate. Not surprisingly, it’s different
    for the `partner` variable; having no partner is more risky (table 3.1).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算`性别`和`伴侣`的风险。对于`性别`变量，男性和女性的风险值都大约为1，因为两组的比率与全球比率没有显著差异。不出所料，对于`伴侣`变量则不同；没有伴侣的风险更高（表3.1）。
- en: 'Table 3.1 Churn rates and risks for the `gender` and `partner` variables. The
    churn rates for females and males are not significantly different from the global
    churn rates, so the risks for them to churn are low: both have risks values around
    1\. On the other hand, the churn rate for people with no partner is significantly
    higher than average, making them risky, with the risk value of 1.22\. People with
    partners tend to churn less, so for them, the risk is only 0.75.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.1 `性别`和`伴侣`变量的流失率和风险。女性和男性的流失率与全局流失率没有显著差异，因此他们流失的风险较低：两者的风险值都在1左右。另一方面，没有伴侣的人的流失率显著高于平均水平，使他们变得有风险，风险值为1.22。有伴侣的人流失较少，因此他们的风险仅为0.75。
- en: '| Variable | Value | Churn rate | Risk |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 变量 | 值 | 流失率 | 风险 |'
- en: '| gender | Female | 27.7% | 1.02 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 性别 | 女性 | 27.7% | 1.02 |'
- en: '|  | Male | 26.3% | 0.97 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '|  | 男性 | 26.3% | 0.97 |'
- en: '| partner | Yes | 20.5% | 0.75 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 伴侣 | 是 | 20.5% | 0.75 |'
- en: '|  | No | 33% | 1.22 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '|  | 无 | 33% | 1.22 |'
- en: We did this from only two variables. Let’s now do this for all the categorical
    variables. To do that, we need a piece of code that checks all the values a variable
    has and computes churn rate for each of these values.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只从两个变量中做了这个。现在让我们对所有分类变量做同样的事情。为了做到这一点，我们需要一段代码来检查变量具有的所有值，并为这些值中的每个计算流失率。
- en: 'If we used SQL, that would be straightforward to do. For gender, we’d need
    to do something like this:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用SQL，这将非常简单。对于性别，我们需要做类似这样的事情：
- en: '[PRE25]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This is a rough translation to Pandas:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对Pandas的一个粗略翻译：
- en: '[PRE26]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ Computes the AVG(churn)
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算AVG(churn)
- en: ❷ Calculates the difference between group churn rate and global rate
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算组流失率与全局流失率之间的差异
- en: ❸ Calculates the risk of churning
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算客户流失风险
- en: 'In ❶ we calculate the `AVG(churn``)` part. For that, we use the `agg` function
    to indicate that we need to aggregate data into one value per group: the mean
    value. In ❷ we create another column, diff, where we will keep the difference
    between the group mean and the global mean. Likewise, in ❸ we create the column
    risk, where we calculate the fraction between the group mean and the global mean.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在❶中，我们计算了`AVG(churn)`部分。为此，我们使用`agg`函数来表示我们需要将数据聚合到每个组的一个值中：平均值。在❷中，我们创建了一个名为diff的新列，我们将在这里保存组平均值与全局平均值之间的差异。同样，在❸中，我们创建了一个名为risk的列，我们在这里计算组平均值与全局平均值之间的比例。
- en: We can see the results in figure 3.16.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在图3.16中看到结果。
- en: '![](../Images/03_16.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_16.png)'
- en: Figure 3.16 The churn rate for the `gender` variable. We see that for both values,
    the difference between the group churn rate and the global churn rate is not very
    large.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16 `性别`变量的客户流失率。我们看到，对于两个值，组客户流失率与全局客户流失率之间的差异并不大。
- en: 'Let’s now do that for all categorical variables. We can iterate through them
    and apply the same code for each:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对所有分类变量做同样的事情。我们可以遍历它们，并对每个变量应用相同的代码：
- en: '[PRE27]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ Loops over all categorical variables
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 遍历所有分类变量
- en: ❷ Performs groupby for each categorical variable
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 对每个分类变量执行分组操作
- en: ❸ Displays the resulting dataframe
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 显示结果数据框
- en: Two things are different in this code. First, instead of manually specifying
    the column name, we iterate over all categorical variables.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码中有两点不同。首先，我们不是手动指定列名，而是遍历所有分类变量。
- en: 'The second difference is more subtle: we need to call the `display` function
    to render a dataframe inside the loop. The way we typically display a dataframe
    is to leave it as the last line in a Jupyter Notebook cell and then execute the
    cell. If we do it that way, the dataframe is displayed as the cell output. This
    is exactly how we managed to see the content of the dataframe at the beginning
    of the chapter (figure 3.1). However, we cannot do this inside a loop. To still
    be able to see the content of the dataframe, we call the `display` function explicitly.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个不同之处更为微妙：我们需要调用`display`函数来在循环中渲染数据框。我们通常显示数据框的方式是将它作为Jupyter Notebook单元格中的最后一行，然后执行该单元格。如果我们这样做，数据框将作为单元格的输出显示。这正是我们在本章开头（图3.1）看到数据框内容的方式。然而，我们无法在循环中这样做。为了仍然能够看到数据框的内容，我们显式地调用`display`函数。
- en: From the results (figure 3.17) we learn that
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果（图3.17）中我们了解到
- en: For gender, there is not much difference between females and males. Both means
    are approximately the same, and for both groups the risks are close to 1.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于性别，男性和女性之间没有太大差异。两组的平均值大致相同，两组的风险值都接近1。
- en: 'Senior citizens tend to churn more than nonseniors: the risk of churning is
    1.53 for seniors and 0.89 for nonseniors.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 老年人比非老年人更容易流失：老年人的流失风险为1.53，非老年人的流失风险为0.89。
- en: People with a partner churn less than people with no partner. The risks are
    0.75 and 1.22, respectively.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有伴侣的人比没有伴侣的人流失率低。风险分别是0.75和1.22。
- en: 'People who use phone service are not at risk of churning: the risk is close
    to 1, and there’s almost no difference with the global churn rate. People who
    don’t use phone service are even less likely to churn: the risk is below 1, and
    the difference with the global churn rate is negative.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用电话服务的人不会面临流失风险：风险接近1，与全球流失率几乎没有差异。不使用电话服务的人流失的可能性更低：风险低于1，与全球流失率的差异为负。
- en: '![](../Images/03_17a.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_17a.png)'
- en: '(A) Churn ratio and risk: `gender`'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: (A) 流失比率和风险：`gender`
- en: '![](../Images/03_17b.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_17b.png)'
- en: '(B) Churn ratio and risk: `seniorcitizen`'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: (B) 流失比率和风险：`seniorcitizen`
- en: '![](../Images/03_17c.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_17c.png)'
- en: '(C) Churn ratio and risk: `partner`'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: (C) 流失比率和风险：`partner`
- en: '![](../Images/03_17d.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_17d.png)'
- en: '(D) Churn ratio and risk: `phoneservice`'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: (D) 流失比率和风险：`phoneservice`
- en: 'Figure 3.17 Churn rate difference and risk for four categorical variables:
    `gender`, `seniorcitizen`, `partner`, and `phoneservice`'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.17 四个分类变量的流失率差异和风险：`gender`、`seniorcitizen`、`partner`和`phoneservice`
- en: 'Some of the variables have quite significant differences (figure 3.18):'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 一些变量有相当显著的区别（图3.18）：
- en: Clients with no tech support tend to churn more than those who do.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有技术支持的客户比有技术支持的客户更容易流失。
- en: People with monthly contracts cancel the contract a lot more often than others,
    and people with two-year contacts churn very rarely.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每月签订合同的客户取消合同的情况比其他人多，而两年合同的客户很少流失。
- en: '![](../Images/03_18a.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_18a.png)'
- en: '(A) Churn ratio and risk: `techsupport`'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: (A) 流失比率和风险：`techsupport`
- en: '![](../Images/03_18b.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_18b.png)'
- en: '(B) Churn ratio and risk: `contract`'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: (B) 流失比率和风险：`contract`
- en: Figure 3.18 Difference between the group churn rate and the global churn rate
    for `techsupport` and `contract`. People with no tech support and month-to-month
    contracts tend to churn a lot more than clients from other groups, whereas people
    with tech support and two-year contracts are very low-risk clients.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.18 `techsupport`和`contract`组流失率与全球流失率之间的差异。没有技术支持和按月签订合同的客户比其他组的客户流失得多，而有技术支持和两年合同的客户是风险很低的客户。
- en: 'This way, just by looking at the differences and the risks, we can identify
    the most discriminative features: the features that are helpful for detecting
    churn. Thus, we expect that these features will be useful for our future models.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，仅通过观察差异和风险，我们就可以识别出最具判别性的特征：有助于检测流失的特征。因此，我们预计这些特征将对我们未来的模型有用。
- en: Mutual information
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 互信息
- en: The kinds of differences we just explored are useful for our analysis and important
    for understanding the data, but it’s hard to use them to say what the most important
    feature is and whether tech support is more useful than the type of contract.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才探讨的差异对我们的分析有用，对于理解数据也很重要，但很难用它们来说明最重要的特征是什么，以及技术支持是否比合同类型更有用。
- en: 'Luckily, the metrics of importance can help us: we can measure the degree of
    dependency between a categorical variable and the target variable. If two variables
    are dependent, knowing the value of one variable gives us some information about
    another. On the other hand, if a variable is completely independent of the target
    variable, it’s not useful and can be safely removed from the dataset.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，重要性指标可以帮助我们：我们可以测量一个分类变量与目标变量之间的依赖程度。如果两个变量是相关的，知道一个变量的值会给我们关于另一个变量的某些信息。另一方面，如果一个变量与目标变量完全独立，那么它就没有用，可以从数据集中安全地移除。
- en: In our case, knowing that the customer has a month-to-month contract may indicate
    that this customer is more likely to churn than not.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，知道客户有按月签订的合同可能表明这位客户更有可能流失。
- en: Important Customers with month-to-month contracts tend to churn a lot more than
    customers with other kinds of contracts. This is exactly the kind of relationship
    we want to find in our data. Without such relationships in data, machine learning
    models will not work—they will not be able to make predictions. The higher the
    degree of dependency, the more useful a feature is.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他类型的合同相比，每月签订合同的客户流失率往往要高得多。这正是我们想要在数据中找到的那种关系。如果没有这样的关系在数据中，机器学习模型将无法工作——它们将无法做出预测。依赖度越高，特征就越有用。
- en: For categorical variables, one such metric is mutual information, which tells
    how much information we learn about one variable if we learn the value of the
    other variable. It’s a concept from information theory, and in machine learning,
    we often use it to measure the mutual dependency between two variables.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类变量，这样的度量之一是互信息，它告诉我们如果我们知道另一个变量的值，我们将了解多少关于一个变量的信息。这是一个来自信息理论的概念，在机器学习中，我们经常用它来衡量两个变量之间的相互依赖性。
- en: 'Higher values of mutual information mean a higher degree of dependence: if
    the mutual information between a categorical variable and the target is high,
    this categorical variable will be quite useful for predicting the target. On the
    other hand, if the mutual information is low, the categorical variable and the
    target are independent, and thus the variable will not be useful for predicting
    the target.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 互信息值越高，表示依赖度越高：如果一个分类变量与目标之间的互信息高，那么这个分类变量将非常有助于预测目标。另一方面，如果互信息低，分类变量与目标独立，因此该变量将不会对预测目标有用。
- en: 'Mutual information is already implemented in Scikit-learn in the `mutual_info_
    score` function from the `metrics` package, so we can just use it:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 互信息已经在Scikit-learn的`metrics`包中的`mutual_info_score`函数中实现，因此我们可以直接使用它：
- en: '[PRE28]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: ❶ Creates a stand-alone function for calculating mutual information
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个用于计算互信息的独立函数
- en: ❷ Uses the mutual _info_score function from Scikit-learn
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用Scikit-learn中的`mutual_info_score`函数
- en: ❸ Applies the function from ❶ to each categorical column of the dataset
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将❶中的函数应用于数据集的每一列分类变量
- en: ❹ Sorts the values of the result
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 对结果值进行排序
- en: 'In ❸, we use the `apply` method to apply the `calculate_mi` function we defined
    in ❶ to each column of the `df_train_full` dataframe. Because we include an additional
    step of selecting only categorical variables, it’s applied only to them. The function
    we define in ❶ takes only one parameter: `series`. This is a column from the dataframe
    on which we invoked the `apply()` method. In ❷, we compute the mutual information
    score between the series and the target variable `churn`. The output is a single
    number, so the output of the `apply()` method is a Pandas series. Finally, we
    sort the elements of the series by the mutual information score and convert the
    series to a dataframe. This way, the result is rendered nicely in Jupyter.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在❸中，我们使用`apply`方法将我们在❶中定义的`calculate_mi`函数应用于`df_train_full`数据框的每一列。因为我们包括了一个额外的步骤，即仅选择分类变量，所以它只应用于它们。我们在❶中定义的函数只接受一个参数：`series`。这是一个来自数据框的列，我们在其上调用了`apply()`方法。在❷中，我们计算序列与目标变量`churn`之间的互信息得分。输出是一个单一数字，因此`apply()`方法的输出是一个Pandas序列。最后，我们根据互信息得分对序列的元素进行排序，并将序列转换为数据框。这样，结果在Jupyter中显示得很好。
- en: As we see, `contract`, `onlinesecurity`, and `techsupport` are among the most
    important features (figure 3.19). Indeed, we’ve already noted that `contract`
    and `techsupport` are quite informative. It’s also not surprising that `gender`
    is among the least important features, so we shouldn’t expect it to be useful
    for the model.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，`contract`、`onlinesecurity`和`techsupport`是最重要的特征之一（图3.19）。事实上，我们之前已经指出`contract`和`techsupport`非常有信息量。`gender`是重要性最低的特征之一，因此我们不应该期望它对模型有用。
- en: '![](../Images/03_19a.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_19a.png)'
- en: (A) The most useful features according to the mutual information score.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: (A) 根据互信息得分，最有用的特征。
- en: '![](../Images/03_19b.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_19b.png)'
- en: (B) The least useful features according to the mutual information score.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: (B) 根据互信息得分，最无用的特征。
- en: Figure 3.19 Mutual information between categorical variables and the target
    variable. Higher values are better. According to it, `contract` is the most useful
    variable, whereas `gender` is the least useful.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.19 分类变量与目标变量之间的互信息。值越高越好。根据它，`contract`是最有用的变量，而`gender`是最无用的。
- en: Correlation coefficient
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 相关系数
- en: Mutual information is a way to quantify the degree of dependency between two
    categorical variables, but it doesn’t work when one of the features is numerical,
    so we cannot apply it to the three numerical variables that we have.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 互信息是一种量化两个分类变量之间依赖程度的度量方法，但当其中一个特征是数值时，它不起作用，因此我们不能将其应用于我们拥有的三个数值变量。
- en: We can, however, measure the dependency between a binary target variable and
    a numerical variable. We can pretend that the binary variable is numerical (containing
    only the numbers zero and one) and then use the classical methods from statistics
    to check for any dependency between these variables.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以测量二进制目标变量和数值变量之间的依赖性。我们可以假设二进制变量是数值的（只包含数字零和一），然后使用统计学中的经典方法来检查这些变量之间是否存在任何依赖性。
- en: 'One such method is the *correlation* coefficient (sometimes referred as *Pearson’s
    correlation coefficient*). It is a value from –1 to 1:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一种方法是*相关系数*（有时称为*皮尔逊相关系数*）。它是一个从-1到1的值：
- en: Positive correlation means that when one variable goes up, the other variable
    tends to go up as well. In the case of a binary target, when the values of the
    variable are high, we see ones more often than zeros. But when the values of the
    variable are low, zeros become more frequent than ones.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正相关意味着当一个变量上升时，另一个变量也倾向于上升。在二进制目标的情况下，当变量的值较高时，我们更经常看到一，而不是零。但当变量的值较低时，零的出现频率高于一。
- en: 'Zero correlation means no relationship between two variables: they are completely
    independent.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零相关意味着两个变量之间没有关系：它们是完全独立的。
- en: Negative correlation occurs when one variable goes up and the other goes down.
    In the binary case, if the values are high, we see more zeros than ones in the
    target variable. When the values are low, we see more ones.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负相关发生在当一个变量上升而另一个变量下降时。在二进制情况下，如果值较高，目标变量中零的个数多于一的个数。当值较低时，一的个数多于零的个数。
- en: 'It’s very easy to calculate the correlation coefficient in Pandas:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在Pandas中计算相关系数非常容易：
- en: '[PRE29]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We see the results in figure 3.20:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在图3.20中看到了结果：
- en: 'The correlation between `tenure` and churn is –0.35: it has a negative sign,
    so the longer customers stay, the less often they tend to churn. For customers
    staying with the company for two months or less, the churn rate is 60%; for customers
    with tenure between 3 and 12 months, the churn rate is 40%; and for customers
    staying longer than a year, the churn rate is 17%. So the higher the value of
    tenure, the smaller the churn rate (figure 3.21A).'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tenure`与流失率之间的相关系数为-0.35：它有一个负号，这意味着客户待的时间越长，他们流失的频率就越低。对于服务期在两个月或更短的客户，流失率为60%；对于服务期在3到12个月之间的客户，流失率为40%；而对于服务期超过一年的客户，流失率为17%。因此，服务期的值越高，流失率就越小（图3.21A）。'
- en: '`monthlycharges` has a positive coefficient of 0.19, which means that customers
    who pay more tend to leave more often. Only 8% of those who pay less than $20
    monthly churned; customers paying between $21 and $50 churn more frequently with
    a churn rate of 18%; and 32% of people paying more than $50 churned (figure 3.21B).'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`monthlycharges`的正相关系数为0.19，这意味着支付更多的客户倾向于更频繁地离开。只有8%的每月支付少于20美元的客户流失；支付介于21美元和50美元之间的客户流失频率更高，流失率为18%；而支付超过50美元的人中有32%流失（图3.21B）。'
- en: '`totalcharges` has a negative correlation, which makes sense: the longer people
    stay with the company, the more they have paid in total, so it’s less likely that
    they will leave. In this case, we expect a pattern similar to `tenure`. For small
    values, the churn rate is high; for larger values, it’s lower.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`totalcharges`存在负相关，这是有道理的：人们在公司待的时间越长，支付的总金额就越多，因此他们离职的可能性就越小。在这种情况下，我们预计会出现与`tenure`相似的图案。对于较小的值，流失率较高；对于较大的值，流失率较低。'
- en: '![](../Images/03_20.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_20.png)'
- en: 'Figure 3.20 Correlation between numerical variables and churn. `tenure` has
    a high negative correlation: as tenure grows, churn rate goes down. `monthlycharges`
    has positive correlation: the more customers pay, the more likely they are to
    churn.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.20 数值变量与流失率的相关性。`tenure`有高度的负相关：随着服务期的增长，流失率下降。`monthlycharges`有正相关：客户支付越多，他们流失的可能性就越大。
- en: 'After doing initial exploratory data analysis, identifying important features,
    and getting some insights into the problem, we are ready to do the next step:
    feature engineering and model training.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行初步的探索性数据分析、识别重要特征并对问题有所了解之后，我们准备进行下一步：特征工程和模型训练。
- en: '![](../Images/03_21a.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_21a.png)'
- en: '(A) Churn rate for different values of `tenure`. The correlation coefficient
    is negative, so the trend is downward: for higher values of `tenure`, the churn
    rate is smaller.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: (A) 不同`tenure`值下的客户流失率。相关系数为负，因此趋势是下降的：对于更高的`tenure`值，客户流失率较小。
- en: '![](../Images/03_21b.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_21b.png)'
- en: '(B) Churn rate for different values of `monthlycharges`. The correlation coefficient
    is positive, so the trend is upward: for higher values of `monthlycharges`, the
    churn rate is higher.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: (B) 不同`monthlycharges`值下的客户流失率。相关系数为正，因此趋势是上升的：对于更高的`monthlycharges`值，客户流失率更高。
- en: Figure 3.21 Churn rate for `tenure` (negative correlation of –0.35) and `monthlycharges`
    (positive correlation of 0.19)
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.21 `tenure`（-0.35的负相关性）和`monthlycharges`（0.19的正相关性）的客户流失率
- en: 3.2 Feature engineering
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.2 特征工程
- en: We had an initial look at the data and identified what could be useful for the
    model. After doing that, we have a clear understanding how other variables affect
    churn—our target.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们初步查看数据并确定了可能对模型有用的信息。在这样做之后，我们清楚地理解了其他变量如何影响客户流失——我们的目标。
- en: 'Before we proceed to training, however, we need to perform the feature engineering
    step: transforming all categorical variables to numeric features. We’ll do that
    in the next section, and after that, we’ll be ready to train the logistic regression
    model.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续进行训练之前，然而，我们需要执行特征工程步骤：将所有分类变量转换为数值特征。我们将在下一节中这样做，之后我们就可以准备训练逻辑回归模型了。
- en: 3.2.1 One-hot encoding for categorical variables
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2.1 分类变量的独热编码
- en: As we already know from the first chapter, we cannot just take a categorical
    variable and put it into a machine learning model. The models can deal only with
    numbers in matrices. So, we need to convert our categorical data into a matrix
    form, or encode.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第一章中已经知道的，我们不能直接将分类变量放入机器学习模型中。模型只能处理矩阵中的数字。因此，我们需要将我们的分类数据转换为矩阵形式，或者进行编码。
- en: One such encoding technique is *one-hot encoding*. We already saw this encoding
    technique in the previous chapter, when creating features for the make of a car
    and other categorical variables. There, we mentioned it only briefly and used
    it in a very simple way. In this chapter, we will spend more time understanding
    and using it.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一种编码技术是*独热编码*。我们已经在上一章中看到了这种编码技术，当时我们在创建汽车品牌和其他分类变量的特征时使用了它。在那里，我们只是简要地提到了它，并且以非常简单的方式使用了它。在本章中，我们将花更多的时间来理解和使用它。
- en: If a variable `contract` has possible values (monthly, yearly, and two-year),
    we can represent a customer with the yearly contract as (0, 1, 0). In this case,
    the yearly value is active, or *hot*, so it gets 1, whereas the remaining values
    are not active, or *cold*, so they are 0.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个变量`contract`有（月度、年度和两年期）可能的值，我们可以用一个客户拥有年度合同来表示为（0, 1, 0）。在这种情况下，年度值是激活的，或*热*，因此得到1，而其他值不是激活的，或*冷*，因此它们是0。
- en: To understand this better, let’s consider a case with two categorical variables
    and see how we create a matrix from them. These variables are
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这一点，让我们考虑一个有两个分类变量的案例，并看看我们如何从它们中创建一个矩阵。这些变量是
- en: '`gender`, with values female and male'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gender`，其值为female和male'
- en: '`contract`, with values monthly, yearly, and two-year'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contract`，其值为月度、年度和两年期'
- en: 'Because the `gender` variable has only two possible values, we create two columns
    in the resulting matrix. The `contract` variable has three columns, and in total,
    our new matrix will have five columns:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`gender`变量只有两个可能的值，我们在结果矩阵中创建两个列。`contract`变量有三个列，因此我们的新矩阵将总共包含五个列：
- en: gender=female
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gender=female`'
- en: gender=male
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gender=male`'
- en: contract=monthly
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contract=monthly`'
- en: contract=yearly
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contract=yearly`'
- en: contract=two-year
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contract=two-year`'
- en: 'Let’s consider two customers (figure 3.22):'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑两个客户（图3.22）：
- en: A female customer with a yearly contract
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有年度合同的女性客户
- en: A male customer with a monthly contract
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有月度合同的男性客户
- en: For the first customer, the `gender` variable is encoded by putting 1 in the
    gender =female column and 0 in the gender=male column. Likewise, contract=yearly
    gets 1, whereas the remaining contract columns, contract=monthly and contract=two-year,
    get 0.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一位客户，`gender`变量通过在`gender=female`列中放置1，在`gender=male`列中放置0来进行编码。同样，`contract=yearly`得到1，而其他合同列（`contract=monthly`和`contract=two-year`）得到0。
- en: As for the second customer, gender=male and contract=monthly get ones, and the
    rest of the columns get zeros (figure 3.22).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二位客户，`gender=male`和`contract=monthly`得到1，其余列得到0（图3.22）。
- en: '![](../Images/03_22.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_22.png)'
- en: Figure 3.22 The original dataset with categorical variables is on the left and
    the one-hot encoded representation on the right. For the first customer, gender=male
    and contract=monthly are the hot columns, so they get 1\. For the second customer,
    the hot columns are gender=female and contract=yearly.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.22 原始数据集带有分类变量在左侧，独热编码表示在右侧。对于第一个客户，性别=male和合同=monthly是热列，因此它们得到1。对于第二个客户，热列是性别=female和合同=yearly。
- en: The way we implemented it previously was simple but quite limited. We first
    looked at the top five values of the variable and then looped over each value
    and manually created a column in the dataframe. When the number of features grows,
    however, this process becomes tedious.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前实现的方式简单但相当有限。我们首先查看变量的前五个值，然后对每个值进行循环并手动在数据框中创建一个列。然而，当特征数量增加时，这个过程变得繁琐。
- en: 'Luckily, we don’t need to implement this by hand: we can use Scikit-learn.
    We can perform one-hot encoding in multiple ways in Scikit-learn, but we will
    use `DictVectorizer`.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，我们不需要手动实现这个功能：我们可以使用Scikit-learn。在Scikit-learn中，我们可以以多种方式执行独热编码，但我们将使用`DictVectorizer`。
- en: As the name suggests, `DictVectorizer` takes in a dictionary and *vectorizes*
    it—that is, it creates vectors from it. Then the vectors are put together as rows
    of one matrix. This matrix is used as input to a machine learning algorithm (figure
    3.23).
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，`DictVectorizer`接受一个字典并将其*矢量化*——也就是说，它从中创建向量。然后这些向量被组合成一个矩阵的行。这个矩阵被用作机器学习算法的输入（图3.23）。
- en: '![](../Images/03_23.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_23.png)'
- en: Figure 3.23 The process of creating a model. First, we convert a dataframe to
    a list of dictionaries, then we vectorize the list to a matrix, and finally, we
    use the matrix to train a model.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.23 创建模型的过程。首先，我们将数据框转换为字典列表，然后我们将列表矢量化为矩阵，最后我们使用矩阵来训练模型。
- en: 'To use this method, we need to convert our dataframe to a list of dictionaries,
    which is simple to do in Pandas using the `to_dict` method with the `orient="records"`
    parameter:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用这种方法，我们需要将我们的数据框转换为字典列表，这在Pandas中使用`to_dict`方法并带有`orient="records"`参数是非常简单的：
- en: '[PRE30]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: If we take a look at the first element of this new list, we see
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看这个新列表的第一个元素，我们会看到
- en: '[PRE31]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Each column from the dataframe is the key in this dictionary, with values coming
    from the actual dataframe row values.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框中的每一列是这个字典的键，值来自实际的数据框行值。
- en: 'Now we can use `DictVectorizer`. We create it and then fit it to the list of
    dictionaries we created previously:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用`DictVectorizer`。我们创建它，然后将其拟合到我们之前创建的字典列表：
- en: '[PRE32]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In this code we create a `DictVectorizer` instance, which we call `dv`, and
    “train” it by invoking the `fit` method. The `fit` method looks at the content
    of these dictionaries and figures out the possible values for each variable and
    how to map them to the columns in the output matrix. If a feature is categorical,
    it applies the one-hot encoding scheme, but if a feature is numerical, it’s left
    intact.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们创建了一个名为`dv`的`DictVectorizer`实例，并通过调用`fit`方法来“训练”它。`fit`方法查看这些字典的内容，并确定每个变量的可能值以及如何将它们映射到输出矩阵的列中。如果一个特征是分类的，它将应用独热编码方案，但如果一个特征是数值的，它将保持不变。
- en: 'The `DictVectorizer` class can take in a set of parameters. We specify one
    of them: `sparse=False`. This parameter means that the created matrix will not
    be sparse and instead will create a simple NumPy array. If you don’t know about
    sparse matrices, don’t worry: we don’t need them in this chapter.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '`DictVectorizer`类可以接受一组参数。我们指定其中一个：`sparse=False`。此参数意味着创建的矩阵将不是稀疏的，而是创建一个简单的NumPy数组。如果你不了解稀疏矩阵，不要担心：我们在这个章节中不需要它们。'
- en: 'After we fit the vectorizer, we can use it for converting the dictionaries
    to a matrix by using the `transform` method:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们拟合矢量化器之后，我们可以使用它通过`transform`方法将字典转换为矩阵：
- en: '[PRE33]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This operation creates a matrix with 45 columns. Let’s have a look at the first
    row, which corresponds to the customer we looked at previously:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作创建了一个有45列的矩阵。让我们看看第一行，它对应于我们之前查看的客户：
- en: '[PRE34]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'When we put this code into a Jupyter Notebook cell and execute it, we get the
    following output:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将这段代码放入Jupyter Notebook单元格中并执行时，我们得到以下输出：
- en: '[PRE35]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'As we see, most of the elements are ones and zeros—they’re one-hot encoded
    categorical variables. Not all of them are ones and zeros, however. We see that
    three of them are other numbers. These are our numeric variables: `monthlycharges`,
    `tenure`, and `totalcharges`.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，大多数元素都是1和0——它们是独热编码的分类变量。然而，并非所有都是1和0。我们看到其中三个是其他数字。这些是我们的数值变量：`monthlycharges`、`tenure`和`totalcharges`。
- en: 'We can learn the names of all these columns by using the `get_feature_names`
    method:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用 `get_feature_names` 方法来学习所有这些列的名称：
- en: '[PRE36]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: It prints
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 它打印
- en: '[PRE37]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As we see, for each categorical feature it creates multiple columns for each
    of its distinct values. For `contract`, we have `contract=month-to-month`, `contract=one_year`,
    and `contract=two_year`, and for `dependents`, we have `dependents=no` and `dependents
    =yes`. Features such as `tenure` and `totalcharges` keep the original names because
    they are numerical; therefore, `DictVectorizer` doesn’t change them.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，对于每个分类特征，它为每个不同的值创建多个列。对于 `contract`，我们有 `contract=month-to-month`、`contract=one_year`
    和 `contract=two_year`，对于 `dependents`，我们有 `dependents=no` 和 `dependents =yes`。像
    `tenure` 和 `totalcharges` 这样的特征保持原始名称，因为它们是数值型的；因此，`DictVectorizer` 不对它们进行更改。
- en: 'Now our features are encoded as a matrix, so we can move to the next step:
    using a model to predict churn.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的特征已编码为矩阵，因此我们可以进行下一步：使用模型来预测流失。
- en: Exercise 3.2
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 练习3.2
- en: How would `DictVectorizer` encode the following list of dictionaries?
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '`DictVectorizer` 将如何编码以下字典列表？'
- en: '[PRE38]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'a)   Columns: `[''total_charges'',` `''paperless_billing=yes'',` `''paperless_
    billing=no'']`'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: a)   列：`['total_charges',` `'paperless_billing=yes',` `'paperless_ billing=no']`
- en: 'Values: `[10,` `1,` `0],` `[30,` `0,` `1],` `[20,` `0,` `1]`'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 值：`[10,` `1,` `0],` `[30,` `0,` `1],` `[20,` `0,` `1]`
- en: 'b)   Columns: `[''total_charges=10'',` `''total_charges=20'',` `''total_charges=
    30'',` `''paperless_billing=yes'',` `''paperless_billing=no'']`'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: b)   列：`['total_charges=10',` `'total_charges=20',` `'total_charges= 30',` `'paperless_billing=yes',`
    `'paperless_billing=no']`
- en: 'Values: `[1,` `0,` `0,` `1,` `0],` `[0,` `0,` `1,` `0,` `1],` `[0,` `1,` `0,`
    `0,` `1]`'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 值：`[1,` `0,` `0,` `1,` `0],` `[0,` `0,` `1,` `0,` `1],` `[0,` `1,` `0,` `0,`
    `1]`
- en: 3.3 Machine learning for classification
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.3 分类机器学习
- en: We have learned how to use Scikit-learn to perform one-hot encoding for categorical
    variables, and now we can transform them into a set of numerical features and
    put everything together into a matrix.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学习了如何使用Scikit-learn对分类变量进行独热编码，现在我们可以将它们转换为一组数值特征，并将所有内容组合成一个矩阵。
- en: When we have a matrix, we are ready to do the model training part. In this section
    we learn how to train the logistic regression model and interpret its results.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有一个矩阵时，我们就准备好进行模型训练部分了。在本节中，我们学习如何训练逻辑回归模型并解释其结果。
- en: 3.3.1 Logistic regression
  id: totrans-360
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.1 逻辑回归
- en: In this chapter, we use logistic regression as a classification model, and now
    we train it to distinguish churned and not-churned users.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用逻辑回归作为分类模型，现在我们训练它来区分已流失和未流失的用户。
- en: Logistic regression has a lot in common with linear regression, the model we
    learned in the previous chapter. If you remember, the linear regression model
    is a regression model that can predict a number. It has the form
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归与我们在上一章学习的线性回归有很多相似之处。如果你还记得，线性回归模型是一种可以预测数值的回归模型。它具有以下形式
- en: '![](../Images/03_23-Equation_3-2.png)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_23-Equation_3-2.png)'
- en: where
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '*x[i]* is the feature vector corresponding to the *i* th observation.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x[i]* 是对应于第 *i* 个观察的特征向量。'
- en: '*w*[0] is the bias term.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[0] 是偏置项。'
- en: '*w* is a vector with the weights of the model.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w* 是包含模型权重的向量。'
- en: We apply this model and get *g*(*x[i]*)—the prediction of what we think the
    value for *x[i]* should be. Linear regression is trained to predict the target
    variable *y[i]*—the actual value of the observation *i*. In the previous chapter,
    this was the price of a car.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用这个模型并得到 *g*(*x[i]*)——我们认为 *x[i]* 应该有的值的预测。线性回归被训练来预测目标变量 *y[i]*——观察 *i*
    的实际值。在上一章中，这是汽车的价格。
- en: Linear regression is a linear model. It’s called *linear* because it combines
    the weights of the model with the feature vector *linearly*, using the dot product.
    Linear models are simple to implement, train, and use. Because of their simplicity,
    they are also fast.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是一个线性模型。它被称为*线性*是因为它将模型的权重与特征向量*线性组合*，使用点积。线性模型易于实现、训练和使用。由于它们的简单性，它们也很快。
- en: 'Logistic regression is also a linear model, but unlike linear regression, it’s
    a classification model, not regression, even though the name might suggest that.
    It’s a binary classification model, so the target variable *y[i]* is binary; the
    only values it can have are zero and one. Observations with *y[i]* *=* 1 are typically
    called *positive examples*: examples in which the effect we want to predict is
    present. Likewise, examples with *y[i]* *=* 0 are called *negative examples*:
    the effect we want to predict is absent. For our project, *y[i]* *=* 1 means that
    the customer churned, and *y[i]* *=* 0 means the opposite: the customer stayed
    with us.'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归也是一个线性模型，但与线性回归不同，它是一个分类模型，而不是回归模型，尽管名称可能暗示了这一点。它是一个二元分类模型，因此目标变量 *y[i]*
    是二元的；它只能取零和一这两个值。*y[i]* 等于 1 的观测通常被称为 *正例*：即我们想要预测的效果存在的例子。同样，*y[i]* 等于 0 的例子被称为
    *负例*：即我们想要预测的效果不存在。在我们的项目中，*y[i]* 等于 1 表示客户流失，而 *y[i]* 等于 0 则表示相反：客户留在了我们这里。
- en: The output of logistic regression is probability—the probability that the observation
    *x[i]* is positive, or, in other words, the probability that *y[i]* *=* 1\. For
    our case, it’s the probability that the customer *i* will churn.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归的输出是概率——即观察值 *x[i]* 为正的概率，或者说，*y[i]* 等于 1 的概率。在我们的案例中，这是客户 *i* 将会流失的概率。
- en: To be able to treat the output as a probability, we need to make sure that the
    predictions of the model always stay between zero and one. We use a special mathematical
    function for this purpose called *sigmoid*, and the full formula for the logistic
    regression model is
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够将输出作为概率处理，我们需要确保模型的预测值始终在零和一之间。为此，我们使用一个特殊的数学函数，称为 *sigmoid*，逻辑回归模型的完整公式如下：
- en: '![](../Images/03_23-Equation_3-3.png)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_23-Equation_3-3.png)'
- en: 'If we compare it with the linear regression formula, the only difference is
    this sigmoid function: in case of linear regression, we have only *w*[0] *+ x[i]^T**w*.
    This is why both of these models are linear; they are both based on the dot product
    operation.'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将其与线性回归公式进行比较，唯一的区别就是这个sigmoid函数：在线性回归的情况下，我们只有 *w*[0] *+ x[i]^T**w*。这就是为什么这两个模型都是线性的；它们都是基于点积操作。
- en: 'The sigmoid function maps any value to a number between zero and one (figure
    3.24). It’s defined this way:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: sigmoid函数将任何值映射到0到1之间的一个数（图3.24）。它被定义为以下方式：
- en: '![](../Images/03_23-Equation_3-4.png)'
  id: totrans-376
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_23-Equation_3-4.png)'
- en: '![](../Images/03_24.png)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_24.png)'
- en: Figure 3.24 The sigmoid function outputs values that are always between 0 and
    1\. When the input is 0, the result of sigmoid is 0.5; for negative values, the
    results are below 0.5 and start approaching 0 for input values less than –6\.
    When the input is positive, the result of sigmoid is above 0.5 and approaches
    1 for input values starting from 6.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.24 sigmoid函数输出的值总是在0到1之间。当输入为0时，sigmoid的结果是0.5；对于负值，结果小于0.5，并且当输入值小于-6时开始接近0。当输入为正值时，sigmoid的结果大于0.5，并且当输入值从6开始时接近1。
- en: We know from chapter 2 that if the feature vector *x[i]* is *n*-dimensional,
    the dot product *x[i]^T**w* can be unwrapped as a sum, and we can write *g*(*x[i]*)
    as
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从第二章知道，如果特征向量 *x[i]* 是 *n*-维的，点积 *x[i]^T**w* 可以展开为一个和，我们可以将 *g*(*x[i]*) 写作：
- en: '![](../Images/03_24-Equation_3-5.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_24-Equation_3-5.png)'
- en: Or, using sum notation, as
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，使用求和符号表示，如下：
- en: '![](../Images/03_24-Equation_3-6.png)'
  id: totrans-382
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_24-Equation_3-6.png)'
- en: Previously, we translated the formulas to Python for illustration. Let’s do
    the same here.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们将公式翻译成Python进行说明。现在我们在这里做同样的操作。
- en: 'The linear regression model has the following formula:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型具有以下公式：
- en: '![](../Images/03_24-Equation_3-7.png)'
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_24-Equation_3-7.png)'
- en: 'If you remember from the previous chapter, this formula translates to the following
    Python code:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得上一章的内容，这个公式可以翻译成以下Python代码：
- en: '[PRE39]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The translation of the logistic regression formula to Python is almost identical
    to the linear regression case, except that at the end, we apply the sigmoid function:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 将逻辑回归公式翻译成Python与线性回归的情况几乎相同，只是在最后我们应用sigmoid函数：
- en: '[PRE40]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Of course, we also need to define the sigmoid function:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们还需要定义sigmoid函数：
- en: '[PRE41]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: We use *score* to mean the intermediate result before applying the sigmoid function.
    The score can take any real value. The *probability* is the result of applying
    the sigmoid function to the score; this is the final output, and it can take only
    the values between zero and one.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`score`来表示应用Sigmoid函数之前的中间结果。分数可以取任何实数值。*probability*是应用Sigmoid函数到分数的结果；这是最终输出，它只能取零和一之间的值。
- en: 'The parameters of the logistic regression model are the same as for linear
    regression:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型的参数与线性回归相同：
- en: '*w*[0] is the bias term.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[0] 是偏置项。'
- en: '*w =* (*w*[1], *w*[2], ..., *w[n]*) is the weights vector.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w =* (*w*[1], *w*[2], ..., *w[n]*) 是权重向量。'
- en: To learn the weights, we need to train the model, which we will do now using
    Scikit-learn.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 为了学习权重，我们需要训练模型，我们将使用Scikit-learn来完成这项工作。
- en: Exercise 3.3
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 练习3.3
- en: Why do we need sigmoid for logistic regression?
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么逻辑回归需要使用Sigmoid函数？
- en: a) Sigmoid converts the output to values between –6 and 6, which is easier to
    deal with.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: a) Sigmoid将输出转换为-6和6之间的值，这更容易处理。
- en: b) Sigmoid makes sure the output is between zero and one, which can be interpreted
    as probability.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: b) Sigmoid确保输出值在零和一之间，这可以解释为概率。
- en: 3.3.2 Training logistic regression
  id: totrans-401
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.2 训练逻辑回归
- en: 'To get started, we first import the model:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，我们首先导入模型：
- en: '[PRE42]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Then we train it by calling the `fit` method:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们通过调用`fit`方法来训练它：
- en: '[PRE43]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The class `LogisticRegression` from Scikit-learn encapsulates the training
    logic behind this model. It’s configurable, and we can change quite a few parameters.
    In fact, we already specify two of them: `solver` and `random_state`. Both are
    needed for reproducibility:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn中的`LogisticRegression`类封装了此模型背后的训练逻辑。它是可配置的，我们可以更改相当多的参数。实际上，我们已经指定了其中两个：`solver`和`random_state`。两者都是可复现性的必要条件：
- en: '`random_state.` The seed number for the random-number generator. It shuffles
    the data when training the model; to make sure the shuffle is the same every time,
    we fix the seed.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`random_state.` 随机数生成器的种子数字。在训练模型时，它会对数据进行打乱；为了确保每次打乱都是相同的，我们固定了种子。'
- en: '`solver`. The underlying optimization library. In the current version (at the
    moment of writing, v0.20.3), the default value for this parameter is `liblinear`,
    but according to the documentation ([https://scikit-learn.org/stable/modules/
    generated/sklearn.linear_model.LogisticRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)),
    it will change to a different one in version v0.22\. To make sure our results
    are reproducible in the later versions, we also set this parameter.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`solver`。底层优化库。在当前版本（撰写本文时，v0.20.3），此参数的默认值为`liblinear`，但根据文档（[https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)），它将在v0.22版本中变为不同的值。为了确保我们可以在后续版本中复现结果，我们也设置了此参数。'
- en: Other useful parameters for the model include `C`, which controls the regularization
    level. We talk about it in the next chapter when we cover parameter tuning. Specifying
    `C` is optional; by default, it gets the value 1.0.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 模型中其他有用的参数包括`C`，它控制正则化级别。我们将在下一章讨论参数调整时讨论它。指定`C`是可选的；默认情况下，它的值为1.0。
- en: The training takes a few seconds, and when it’s done, the model is ready to
    make predictions. Let’s see how well the model performs. We can apply it to our
    validation data to obtain the probability of churn for each customer in the validation
    dataset.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 训练需要几秒钟，完成后，模型就准备好进行预测了。让我们看看模型的性能如何。我们可以将其应用于我们的验证数据，以获得验证数据集中每个客户的流失概率。
- en: 'To do that, we need to apply the one-hot encoding scheme to all the categorical
    variables. First, we convert the dataframe to a list of dictionaries and then
    feed it to the `DictVectorizer` we fit previously:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们需要将独热编码方案应用于所有分类变量。首先，我们将数据框转换为字典列表，然后将其输入到我们之前拟合的`DictVectorizer`中：
- en: '[PRE44]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: ❶ We perform one-hot encoding in exactly the same way as during training.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们以与训练期间完全相同的方式进行独热编码。
- en: ❷ Instead of fit and then transform, we use transform, which we fit previously.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们使用`transform`而不是`fit`和`transform`，这是我们在之前拟合的。
- en: 'As a result, we get `X_val`, a matrix with features from the validation dataset.
    Now we are ready to put this matrix to the model. To get the probabilities, we
    use the `predict_ proba` method of the model:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，我们得到`X_val`，这是一个包含验证数据集特征的矩阵。现在我们准备好将这个矩阵放入模型中。为了得到概率，我们使用模型的`predict_proba`方法：
- en: '[PRE45]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The result of `predict_proba` is a two-dimensional NumPy array, or a two-column
    matrix. The first column of the array contains the probability that the target
    is negative (no churn), and the second column contains the probability that the
    target is positive (churn) (figure 3.25).
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_proba`的结果是一个二维NumPy数组，或一个两列矩阵。数组的第一个列包含目标为负（无流失）的概率，第二个列包含目标为正（流失）的概率（图3.25）。'
- en: '![](../Images/03_25.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_25.png)'
- en: 'Figure 3.25 The predictions of the model: a two-column matrix. The first column
    contains the probability that the target is zero (the client won’t churn). The
    second column contains the opposite probability (the target is one, and the client
    will churn).'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.25 模型的预测：一个两列矩阵。第一列包含目标为零（客户不会流失）的概率。第二列包含相反的概率（目标是1，客户会流失）。
- en: These columns convey the same information. We know the probability of churn—it’s
    *p*—and the probability of not churning is always 1 – *p*, so we don’t need both
    columns.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 这些列传达相同的信息。我们知道流失的概率——它是*p*，而不流失的概率总是1 – *p*，所以我们不需要两个列。
- en: 'Thus, it’s enough to take only the second column of the prediction. To select
    only one column from a two-dimensional array in NumPy, we can use the slicing
    operation `[:,` `1]`:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，只需要取预测的第二个列。要在NumPy中从二维数组中选择一列，我们可以使用切片操作`[:, 1]`：
- en: '[PRE46]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: This syntax might be confusing, so let’s break it down. Two positions are inside
    the brackets, the first one for rows and the second one for columns.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 这种语法可能让人困惑，所以让我们来分解一下。括号中有两个位置，第一个用于行，第二个用于列。
- en: 'When we use `[:,` `1]`, NumPy interprets it this way:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用`[:, 1]`时，NumPy是这样解释的：
- en: '`:` means select all the rows.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`:`表示选择所有行。'
- en: '`1` means select only the column at index 1, and because the indexing starts
    at 0, it’s the second column.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1`表示只选择索引为1的列，因为索引从0开始，所以它是第二列。'
- en: As a result, we get a one-dimensional NumPy array that contains the values from
    the second column only.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得到一个只包含第二列值的二维NumPy数组。
- en: This output (probabilities) is often called *soft* predictions. These tell us
    the probability of churning as a number between zero and one. It’s up to us to
    decide how to interpret this number and how to use it.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出（概率）通常被称为**软**预测。这些告诉我们流失的概率，是一个介于零和一之间的数字。如何解释这个数字以及如何使用它取决于我们。
- en: 'Remember how we wanted to use this model: we wanted to retain customers by
    identifying those who are about to cancel their contract with the company and
    send them promotional messages, offering discounts and other benefits. We do this
    in the hope that after receiving the benefit, they will stay with the company.
    On the other hand, we don’t want to give promotions to all our customers, because
    it will hurt us financially: we will make less profit, if any.'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们想要如何使用这个模型：我们想要通过识别那些即将取消与公司合同的人，并向他们发送促销信息，提供折扣和其他优惠来保留客户。我们这样做是希望他们在收到优惠后能继续与我们合作。另一方面，我们不希望向所有客户发送促销，因为这会损害我们的财务状况：我们的利润会减少，如果有的话。
- en: To make the actual decision about whether to send a promotional letter to our
    customers, using the probability alone is not enough. We need *hard* predictions—binary
    values of `True` (churn, so send the mail) or `False` (not churn, so don’t send
    the mail).
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 要做出是否向客户发送促销信件的实际决定，仅使用概率是不够的。我们需要**硬**预测——`True`（流失，因此发送邮件）或`False`（不流失，因此不发送邮件）的二进制值。
- en: 'To get the binary predictions, we take the probabilities and cut them above
    a certain threshold. If the probability for a customer is higher than this threshold,
    we predict churn, otherwise, not churn. If we select 0.5 to be this threshold,
    making the binary predictions is easy. We just use the “`>=`” operator:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 要得到二进制预测，我们取概率并在某个阈值之上进行切割。如果一个客户的概率高于这个阈值，我们预测流失，否则不流失。如果我们选择0.5作为这个阈值，进行二进制预测就很简单。我们只需使用“`>=`”运算符：
- en: '[PRE47]'
  id: totrans-432
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The comparison operators in NumPy are applied element-wise, and the result
    is a new array that contains only Boolean values: `True` and `False`. Under the
    hood, it performs the comparison for each element of the `y_pred` array. If the
    element is greater than 0.5 or equal to 0.5, the corresponding element in the
    output array is `True`, and otherwise, it’s `False` (figure 3.26).'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy中的比较运算符是逐元素应用的，结果是一个只包含布尔值的新数组：`True`和`False`。在底层，它会对`y_pred`数组的每个元素进行比较。如果元素大于0.5或等于0.5，输出数组中对应的元素就是`True`，否则是`False`（图3.26）。
- en: '![](../Images/03_26.png)'
  id: totrans-434
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_26.png)'
- en: Figure 3.26 The `>=` operator is applied element-wise in NumPy. For every element,
    it performs the comparison, and the result is another array with `True` or `False`
    values, depending on the result of the comparison.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.26 NumPy中的`>=`操作符是逐元素应用的。对于每个元素，它执行比较操作，结果是一个包含`True`或`False`值的数组，这取决于比较的结果。
- en: 'Let’s write the results to the `churn` array:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将结果写入`churn`数组：
- en: '[PRE48]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'When we have these hard predictions made by our model, we would like to understand
    how good they are, so we are ready to move to the next step: evaluating the quality
    of these predictions. In the next chapter, we will spend a lot more time learning
    about different evaluation techniques for binary classification, but for now,
    let’s do a simple check to make sure our model learned something useful.'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有模型做出的这些硬预测时，我们希望了解它们有多好，因此我们准备进入下一步：评估这些预测的质量。在下一章中，我们将花费更多的时间学习关于二元分类的不同评估技术，但现在，让我们进行一个简单的检查，以确保我们的模型学到了有用的东西。
- en: The simplest thing to check is to take each prediction and compare it with the
    actual value. If we predict churn and the actual value is churn, or we predict
    non-churn and the actual value is non-churn, our model made the correct prediction.
    If the predictions don’t match, they aren’t good. If we calculate the number of
    times our predictions match the actual value, we can use it for measuring the
    quality of our model.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的事情是取每个预测值并与实际值进行比较。如果我们预测客户会流失，而实际值也是流失，或者我们预测客户不会流失，而实际值也是不会流失，那么我们的模型做出了正确的预测。如果预测值与实际值不匹配，那么它们就不好。如果我们计算预测值与实际值匹配的次数，我们可以用它来衡量我们模型的质量。
- en: 'This quality measure is called *accuracy*. It’s very easy to calculate accuracy
    with NumPy:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 这个质量指标被称为*准确率*。使用NumPy计算准确率非常简单：
- en: '[PRE49]'
  id: totrans-441
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Even though it’s easy to calculate, it might be difficult to understand what
    this expression does when you see it for the first time. Let’s try to break it
    down into individual steps.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然计算起来很容易，但当你第一次看到这个表达式时，可能很难理解它做了什么。让我们尝试将其分解成单独的步骤。
- en: 'First, we apply the `==` operator to compare two NumPy arrays: `y_val` and
    `churn`. If you remember, the first array, `y_val`, contains only numbers: zeros
    and ones. This is our target variable: one if the customer churned and zero otherwise.
    The second array contains Boolean predictions: `True` and `False` values. In this
    case `True` means we predict the customer will churn, and `False` means the customer
    will not churn (figure 3.27).'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们应用`==`操作符来比较两个NumPy数组：`y_val`和`churn`。如果你还记得，第一个数组`y_val`只包含数字：零和一。这是我们目标变量：如果客户流失则为1，否则为0。第二个数组包含布尔预测值：`True`和`False`。在这种情况下，`True`表示我们预测客户会流失，而`False`表示客户不会流失（图3.27）。
- en: '![](../Images/03_27.png)'
  id: totrans-444
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_27.png)'
- en: Figure 3.27 Applying the `==` operator to compare the target data with our predictions
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.27 将`==`操作符应用于比较目标数据与我们的预测
- en: Even though these two arrays have different types inside (integer and Boolean),
    it’s still possible to compare them. The Boolean array is cast to integer such
    that `True` values are turned to “1” and `False` values are turned to “0.” Then
    it’s possible for NumPy to perform the actual comparison (figure 3.28).
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这两个数组内部有不同的数据类型（整数和布尔值），但仍然可以比较它们。布尔数组会被转换为整数类型，这样`True`值会被转换为“1”，而`False`值会被转换为“0”。然后NumPy就可以执行实际的比较操作（图3.28）。
- en: '![](../Images/03_28.png)'
  id: totrans-447
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_28.png)'
- en: Figure 3.28 To compare the prediction with the target data, the array with predictions
    is cast to integer.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.28 为了比较预测值与目标数据，包含预测值的数组被转换为整数。
- en: Like the `>=` operator, the `==` operator is applied element-wise. In this case,
    however, we have two arrays to compare, and here, we compare each element of one
    array with the respective element of the other array. The result is again a Boolean
    array with `True` or `False` values, depending on the outcome of the comparison
    (figure 3.29).
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 与`>=`操作符类似，`==`操作符也是逐元素应用的。然而，在这种情况下，我们有两组数组需要比较，我们比较一个数组中的每个元素与另一个数组中相应的元素。结果是另一个包含`True`或`False`值的布尔数组，这取决于比较的结果（图3.29）。
- en: '![](../Images/03_29.png)'
  id: totrans-450
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_29.png)'
- en: Figure 3.29 The `==` operator from NumPy is applied element-wise for two NumPy
    arrays.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.29 NumPy中的`==`操作符应用于两个NumPy数组，是逐元素应用的。
- en: In our case, if the true value in `y_pred` matches our prediction in churn,
    the label is `True`, and if it doesn’t, the label is `False`. In other words,
    we have `True` if our prediction is correct and `False` if it’s not.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，如果`y_pred`中的真实值与我们的 churn 预测匹配，则标签是`True`，如果不匹配，则标签是`False`。换句话说，如果我们的预测是正确的，则为`True`，如果不正确，则为`False`。
- en: 'Finally, we take the results of comparison—the Boolean array—and compute its
    mean using the `mean()` method. This method, however, is applied to numbers, not
    Boolean values, so before calculating the mean, the values are cast to integers:
    `True` values to “1” and `False` values to “0” (figure 3.30).'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们取比较的结果——布尔数组——并使用`mean()`方法计算其平均值。然而，这个方法应用于数字，而不是布尔值，因此在计算平均值之前，值被转换为整数：`True`值转换为“1”，`False`值转换为“0”（图3.30）。
- en: '![](../Images/03_30.png)'
  id: totrans-454
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_30.png)'
- en: Figure 3.30 When computing the mean of a Boolean array, NumPy first casts it
    to integers and then computes the mean.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.30 当计算布尔数组的平均值时，NumPy首先将其转换为整数，然后计算平均值。
- en: Finally, as we already know, if we compute the mean of an array that contains
    only ones and zeros, the result is the fraction of ones in that array, which we
    already used for calculating the churn rate. Because “1” (`True`) in this case
    is a correct prediction and “0” (`False`) is an incorrect prediction, the resulting
    number tells us the percentage of correct predictions.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，正如我们已经知道的，如果我们计算只包含一和零的数组的平均值，结果是数组中一的比例，我们已经在计算流失率时使用了这个比例。因为在这种情况下，“1”（`True`）是一个正确的预测，“0”（`False`）是一个错误的预测，所以得到的结果告诉我们正确预测的百分比。
- en: After executing this line of code, we see 0.8 in output. This means that the
    model predictions matched the actual value 80% of the time, or the model makes
    correct predictions in 80% of cases. This is what we call the accuracy of the
    model.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 执行这一行代码后，我们在输出中看到0.8。这意味着模型预测与实际值匹配了80%的时间，或者说模型在80%的情况下做出了正确的预测。这就是我们所说的模型的准确率。
- en: Now we know how to train a model and evaluate its accuracy, but it’s still useful
    to understand how it makes the predictions. In the next section, we try to look
    inside the models and see how we can interpret the coefficients it learned.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何训练模型并评估其准确率，但了解它是如何做出预测的仍然很有用。在下一节中，我们试图查看模型内部，看看我们如何解释它所学习的系数。
- en: 3.3.3 Model interpretation
  id: totrans-459
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.3 模型解释
- en: 'We know that the logistic regression model has two parameters that it learns
    from data:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道逻辑回归模型有两个参数，它从数据中学习这些参数：
- en: '*w*[0] is the bias term.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[0]是偏差项。'
- en: '*w = (w*[1], *w*[2], ..., *w[n]**)* is the weights vector.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w = (w*[1], *w*[2], ..., *w[n]**)*是权重向量。'
- en: We can get the bias term from `model.intercept_[0]`. When we train our model
    on all features, the bias term is –0.12.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从`model.intercept_[0]`中获取偏差项。当我们使用所有特征训练模型时，偏差项是-0.12。
- en: The rest of the weights are stored in `model.coef_[0]`. If we look inside, it’s
    just an array of numbers, which is hard to understand on its own.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的权重存储在`model.coef_[0]`中。如果我们查看内部，它只是一个数字数组，单独来看很难理解。
- en: 'To see which feature is associated with each weight, let’s use the `get_feature_
    names` method of the `DictVectorizer`. We can zip the feature names together with
    the coefficients before looking at them:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解每个权重与哪个特征相关联，让我们使用`DictVectorizer`的`get_feature_names`方法。在查看它们之前，我们可以将特征名称与系数一起压缩：
- en: '[PRE50]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: This prints
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 这会打印
- en: '[PRE51]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'To understand how the model works, let’s consider what happens when we apply
    this model. To build the intuition, let’s train a simpler and smaller model that
    uses only three variables: `contract`, `tenure`, and `totalcharges`.'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解模型的工作原理，让我们考虑当我们应用这个模型时会发生什么。为了建立直觉，让我们训练一个更简单、更小的模型，它只使用三个变量：`contract`、`tenure`和`totalcharges`。
- en: The variables `tenure` and `totalcharges` are numeric so we don’t need to do
    any additional preprocessing; we can take them as is. On the other hand, `contract`
    is a categorical variable, so to be able to use it, we need to apply one-hot encoding.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`tenure`和`totalcharges`是数值型，所以我们不需要进行任何额外的预处理；我们可以直接使用它们。另一方面，`contract`是一个分类变量，因此为了能够使用它，我们需要应用独热编码。
- en: 'Let’s redo the same steps we did for training, this time using a smaller set
    of features:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新执行训练时相同的步骤，这次使用一组更小的特征集：
- en: '[PRE52]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: So as not to confuse it with the previous model, we add `small` to all the names.
    This way, it’s clear that we use a smaller model, and it saves us from accidentally
    overwriting the results we already have. Additionally, we will use it to compare
    the quality of the small model with the full one.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 为了不与之前的模型混淆，我们在所有名称中添加了`small`。这样，我们可以清楚地知道我们使用的是较小的模型，并且可以避免意外覆盖我们已有的结果。此外，我们还将用它来比较小模型与完整模型的质量。
- en: 'Let’s see which features the small model will use. For that, as previously,
    we use the `get_feature_names` method from `DictVectorizer`:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看小模型将使用哪些特征。为此，正如之前一样，我们使用`DictVectorizer`的`get_feature_names`方法：
- en: '[PRE53]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'It outputs the feature names:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 它输出了特征名称：
- en: '[PRE54]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: There are five features. As expected, we have `tenure` and `totalcharges`, and
    because they are numeric, their names are not changed.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 有五个特征。正如预期的那样，我们有`tenure`和`totalcharges`，因为它们是数值型的，所以它们的名称没有改变。
- en: 'As for the `contract` variable, it’s categorical, so `DictVectorizer` applies
    the one-hot encoding scheme to convert it to numbers. `contract` has three distinct
    values: month-to-month, one year, and two years. Thus, one-hot encoding scheme
    creates three new features: `contract=month-to-month`, `contract=one_year`, and
    `contract= two_years`.'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`contract`变量，它是分类的，所以`DictVectorizer`应用了one-hot编码方案将其转换为数字。`contract`有三个不同的值：按月、一年和两年。因此，one-hot编码方案创建了三个新的特征：`contract=month-to-month`、`contract=one_year`和`contract=
    two_years`。
- en: 'Let’s train the small model on this set of features:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这一组特征上训练小模型：
- en: '[PRE55]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The model is ready after a few seconds, and we can look inside the weights
    it learned. Let’s first check the bias term:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 模型几秒钟后准备就绪，我们可以查看它学到的权重。让我们首先检查偏差项：
- en: '[PRE56]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'It outputs –0.638\. Then we can check the other weights, using the same code
    as previously:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 它输出-0.638。然后我们可以检查其他权重，使用与之前相同的代码：
- en: '[PRE57]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'This line of code shows the weight for each feature:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 这行代码显示了每个特征的权重：
- en: '[PRE58]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Let’s put all these weights together in one table and call them *w*[1], *w*[2],
    *w*[3], *w*[4], and *w*[5] (table 3.2).
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把所有这些权重放在一起，并称它们为*w*[1]、*w*[2]、*w*[3]、*w*[4]和*w*[5]（表3.2）。
- en: Table 3.2 The weights of a logistic regression model
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 表3.2 逻辑回归模型的权重
- en: '| Bias | `contract` | `tenure` | `charges` |'
  id: totrans-490
  prefs: []
  type: TYPE_TB
  zh: '| 偏差 | `contract` | `tenure` | `charges` |'
- en: '| month | year | 2-year |'
  id: totrans-491
  prefs: []
  type: TYPE_TB
  zh: '| month | year | 2-year |'
- en: '| *w*[0] | *w*[1] | *w*[2] | *w*[3] | *w*[4] | *w*[5] |'
  id: totrans-492
  prefs: []
  type: TYPE_TB
  zh: '| *w*[0] | *w*[1] | *w*[2] | *w*[3] | *w*[4] | *w*[5] |'
- en: '| —0.639 | 0.91 | —0.144 | —1.404 | —0.097 | 0.0 |'
  id: totrans-493
  prefs: []
  type: TYPE_TB
  zh: '| —0.639 | 0.91 | —0.144 | —1.404 | —0.097 | 0.0 |'
- en: Now let’s take a look at these weights and try to understand what they mean
    and how we can interpret them.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看这些权重，并尝试理解它们的含义以及我们如何解释它们。
- en: 'First, let’s think about the bias term and what it means. Recall that in the
    case of linear regression, it’s the baseline prediction: the prediction we would
    make without knowing anything else about the observation. In the car price prediction
    project, it would be the price of a car on average. This is not the final prediction;
    later, this baseline is corrected with other weights.'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们思考一下偏差项及其含义。回想一下，在线性回归的情况下，它是基线预测：在没有了解其他关于观察结果的情况下所做的预测。在汽车价格预测项目中，它将是汽车的平均价格。这不是最终的预测；稍后，这个基线将与其他权重一起进行校正。
- en: 'In the case of logistic regression, it’s similar: it’s the baseline prediction—or
    the score we would make on average. Likewise, we later correct this score with
    the other weights. However, for logistic regression, interpretation is a bit trickier
    because we also need to apply the sigmoid function before we get the final output.
    Let’s consider an example to help us understand that.'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 在逻辑回归的情况下，情况类似：它是基线预测——或者平均会得到的分数。同样，我们稍后会用其他权重来校正这个分数。然而，对于逻辑回归，解释要复杂一些，因为我们在得到最终输出之前还需要应用sigmoid函数。让我们考虑一个例子来帮助我们理解这一点。
- en: In our case, the bias term has the value of –0.639\. This value is negative.
    If we look at the sigmoid function, we can see that for negative values, the output
    is lower than 0.5 (figure 3.31). For –0.639, the resulting probability of churning
    is 34%. This means that on average, a customer is more likely to stay with us
    than churn.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，偏差项的值为-0.639。这个值是负的。如果我们看sigmoid函数，我们可以看到对于负值，输出低于0.5（图3.31）。对于-0.639，
    churn的概率为34%。这意味着平均而言，客户更有可能继续与我们合作而不是流失。
- en: '![](../Images/03_31.png)'
  id: totrans-498
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/03_31.png)'
- en: Figure 3.31 The bias term –0.639 on the sigmoid curve. The resulting probability
    is less than 0.5, so the average customer is more likely to not churn.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.31 sigmoid曲线上偏差项-0.639。结果概率小于0.5，因此平均客户更有可能不会流失。
- en: The reason why the sign before the bias term is negative is the class imbalance.
    There are a lot fewer churned users in the training data than non-churned ones,
    meaning the probability of churn on average is low, so this value for the bias
    term makes sense.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 偏置项前的符号为负的原因是类别不平衡。训练数据中流失用户比未流失用户少得多，这意味着平均流失概率较低，因此这个偏置项的值是有意义的。
- en: 'The next three weights are the weights for the contract variable. Because we
    use one-hot encoding, we have three `contract` features and three weights, one
    for each feature:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的三个权重是合同变量的权重。因为我们使用one-hot编码，所以我们有三个`contract`特征和三个权重，每个特征一个：
- en: '[PRE59]'
  id: totrans-502
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'To build our intuition on how one-hot encoded weights can be understood and
    interpreted, let’s think of a client with a month-to-month contract. The `contract`
    variable has the following one-hot encoding representation: the first position
    corresponds to the month-to-month value and is hot, so it’s set to “1.” The remaining
    positions correspond to one_year and two_years, so they are cold and set to “0”
    (figure 3.32).'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立我们对如何理解和解释one-hot编码权重的直觉，让我们考虑一个签订按月合同的客户。`contract`变量有以下one-hot编码表示：第一个位置对应按月值，是热的，因此设置为“1”。其余位置对应one_year和two_years，因此它们是冷的，设置为“0”（图3.32）。
- en: '![](../Images/03_32.png)'
  id: totrans-504
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_32.png)'
- en: Figure 3.32 The one-hot encoding representation for a customer with a month-to-month
    contract
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.32 按月合同客户的one-hot编码表示
- en: We also know the weights *w*[1], *w*[2], and *w*[3] that correspond to `contract=month-to-month`,
    `contract=one_year`, and `contract=two_years` (figure 3.33).
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还知道与`contract=month-to-month`，`contract=one_year`和`contract=two_years`对应的权重*w*[1]，*w*[2]和*w*[3]（图3.33）。
- en: '![](../Images/03_33.png)'
  id: totrans-507
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_33.png)'
- en: Figure 3.33 The weights of the contract=month-to-month, contract=one_year, and
    contract=two_years features
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.33 contract=month-to-month，contract=one_year和contract=two_years特征的权重
- en: To make a prediction, we perform the dot product between the feature vector
    and the weights, which is multiplication of the values in each position and then
    summation. The result of the multiplication is 0.91, which turns out to be the
    same as the weight of the `contract=month-to-month` feature (figure 3.34).
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行预测，我们执行特征向量与权重的点积，即每个位置的值的乘积然后求和。乘积的结果是0.91，结果与图3.34中`contract=month-to-month`特征的权重相同。
- en: '![](../Images/03_34.png)'
  id: totrans-510
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_34.png)'
- en: Figure 3.34 The dot product between the one-hot encoding representation of the
    contract variable and the corresponding weights. The result is 0.91, which is
    the weight of the hot feature.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.34 合同变量的one-hot编码表示与相应权重的点积。结果是0.91，这是热特征的权重。
- en: 'Let’s consider another example: a client with a two-year contract. In this
    case, the `contract=two_year` feature is hot and has a value of “1,” and the rest
    are cold. When we multiply the vector with the one-hot encoding representation
    of the variable by the weight vector, we get –1.404 (figure 3.35).'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑另一个例子：一个签订两年合同的客户。在这种情况下，`contract=two_year`特征是热的，值为“1”，其余的是冷的。当我们用变量的one-hot编码表示与权重向量相乘时，我们得到-1.404（图3.35）。
- en: '![](../Images/03_35.png)'
  id: totrans-513
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_35.png)'
- en: Figure 3.35 For a customer with a two-year contract, the result of the dot product
    is –1.404.
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.35 对于签订两年合同的客户，点积的结果是-1.404。
- en: 'As we see, during the prediction, only the weight of the hot feature is taken
    into account, and the rest of the weights are not considered in calculating the
    score. This makes sense: the cold features have values of zero, and when we multiply
    by zero, we get zero again (figure 3.36).'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，在预测过程中，只考虑了热特征的权重，其余权重在计算分数时并未考虑。这是有道理的：冷特征的值为零，当我们乘以零时，结果仍然是零（图3.36）。
- en: '![](../Images/03_36a.png) ![](../Images/03_36b.png) ![](../Images/03_36c.png)'
  id: totrans-516
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_36a.png) ![图片](../Images/03_36b.png) ![图片](../Images/03_36c.png)'
- en: Figure 3.36 When we multiply the one-hot encoding representation of a variable
    by the weight vector from the model, the result is the weight corresponding to
    the hot feature.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.36 当我们将变量的one-hot编码表示与模型中的权重向量相乘时，结果是热特征的权重。
- en: The interpretation of the signs of the weights for one-hot encoded features
    follows the same intuition as the bias term. If a weight is positive, the respective
    feature is an indicator of churn, and vice versa. If it’s negative, it’s more
    likely to belong to a non-churning customer.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 对于独热编码特征的权重符号的解释遵循与偏置项相同的直觉。如果一个权重是正的，那么相应的特征是流失的指标，反之亦然。如果它是负的，那么它更有可能属于非流失客户。
- en: Let’s look again at the weights of the `contract` variable. The first weight
    for `contract=month-to-month` is positive, so customers with this type of contract
    are more likely to churn than not. The other two features, `contract=one_year`
    and `contract=two_years`, have negative signs, so such clients are more likely
    to remain loyal to the company (figure 3.37).
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次看看`contract`变量的权重。对于`contract=month-to-month`的第一个权重是正的，因此拥有这种合同类型的客户更有可能流失而不是不流失。其他两个特征`contract=one_year`和`contract=two_years`具有负号，因此这类客户更有可能对公司保持忠诚（图3.37）。
- en: '![](../Images/03_37.png)'
  id: totrans-520
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_37.png)'
- en: Figure 3.37 The sign of the weight matters. If it’s positive, it’s a good indicator
    of churn; if it’s negative, it indicates a loyal customer.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.37 权重的符号很重要。如果是正的，它是一个良好的流失指标；如果是负的，它表示一个忠诚的客户。
- en: The magnitude of the weights also matters. For `two_year`, the weight is –1.404,
    which is greater in magnitude than –0.144—the weight for `one_year`. So, a two-year
    contract is a stronger indicator of not churning than a one-year one. It confirms
    the feature importance analysis we did previously. The risk ratios (the risk of
    churning) for this set of features are 1.55 for monthly, 0.44 for one-year, and
    0.10 for two-year (figure 3.38).
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 权重的幅度也很重要。对于`two_year`，权重是-1.404，其幅度大于`one_year`的权重-0.144。因此，两年合同不是流失的更强指标，比一年合同更强。这证实了我们之前做的特征重要性分析。这个特征集的风险比（流失风险）为每月1.55，一年为0.44，两年为0.10（图3.38）。
- en: '![](../Images/03_38.png)'
  id: totrans-523
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_38.png)'
- en: Figure 3.38 The weights for the contract features and their translation to probabilities.
    For `contract=two_year`, the weight is –1.404, which translates to very low probability
    of churn. For `contract=one_year`, the weight is –0.144, so the probability is
    moderate. And for `contract=month-to-month`, the weight is 0.910, and the probability
    is quite high.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.38 合同特征的权重及其转换为概率。对于`contract=two_year`，权重是-1.404，这表示非常低的流失概率。对于`contract=one_year`，权重是-0.144，因此概率适中。而对于`contract=month-to-month`，权重是0.910，概率相当高。
- en: 'Now let’s have a look at the numerical features. We have two of them: `tenure`
    and `totalcharges`. The weight of the `tenure` feature is –0.097, which has a
    negative sign. This means the same thing: the feature is an indicator of no churn.
    We already know from the feature importance analysis that the longer clients stay
    with us, the less likely they are to churn. The correlation between `tenure` and
    churn is –0.35, which is also a negative number. The weight of this feature confirms
    it: for every month that the client spends with us, the total score gets lower
    by 0.097.'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看数值特征。我们有两个：`tenure`和`totalcharges`。`tenure`特征的权重是-0.097，带有负号。这意味着相同的事情：这个特征是流失的指标。我们已经从特征重要性分析中知道，客户与我们合作的时间越长，他们流失的可能性就越小。`tenure`与流失之间的相关性是-0.35，这也是一个负数。这个特征的权重证实了这一点：对于客户与我们合作的每一个月，总分数会降低0.097。
- en: The other numerical feature, `totalchanges`, has weight of zero. Because it’s
    zero, no matter what the value of this feature is, the model will never consider
    it, so this feature is not really important for making the predictions.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个数值特征`totalchanges`的权重为零。因为它为零，无论这个特征的值是多少，模型都不会考虑它，所以这个特征对于做出预测并不是真正重要的。
- en: To understand it better, let’s consider a couple of examples. For the first
    example, let’s imagine we have a user with a month-to-month contract, who spent
    a year with us and paid $1,000 (figure 3.39).
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解它，让我们考虑几个例子。对于第一个例子，让我们想象我们有一个拥有月度合同的用户，与我们合作了一年，支付了1000美元（图3.39）。
- en: '![](../Images/03_39.png)'
  id: totrans-528
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_39.png)'
- en: Figure 3.39 The score the model calculates for a customer with a month-to-month
    contract and 12 months of tenure
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.39 模型为拥有月度合同和12个月服务期的客户计算的分数
- en: 'This is the prediction we make for this customer:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们对这位客户的预测：
- en: We start with the baseline score. It’s the bias term with the value of –0.639.
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们从基线分数开始。它是具有-0.639值的偏置项。
- en: Because it’s a month-to-month contract, we add 0.91 to this value and get 0.271\.
    Now the score becomes positive, so it may mean that the client is going to churn.
    We know that a monthly contract is a strong indicator of churning.
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为这是一个按月签订的合同，我们给这个值加上0.91，得到0.271。现在分数变成了正数，这可能意味着客户将要流失。我们知道月度合同是流失的一个强烈指标。
- en: Next, we consider the `tenure` variable. For each month that the customer stayed
    with us, we subtract 0.097 from the score so far. Thus, we get 0.271 – 12 · 0.097
    = –0.893\. Now the score is negative again, so the likelihood of churn decreases.
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们考虑`tenure`变量。对于客户在我们这里停留的每个月，我们从目前的分数中减去0.097。因此，我们得到0.271 – 12 · 0.097
    = –0.893。现在分数再次变为负数，所以流失的可能性降低。
- en: Now we add the amount of money the customer paid us (`totalcharges`) multiplied
    by the weight of this feature, but because it’s zero, we don’t do anything. The
    result stays –0.893.
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在我们加上客户支付给我们的金额（`totalcharges`）乘以这个特征的权重，但因为它是零，所以我们不做任何事情。结果仍然是–0.893。
- en: The final score is a negative number, so we believe that the customer is not
    very likely to churn soon.
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终分数是一个负数，所以我们认为这位客户不太可能很快流失。
- en: To see the actual probability of churn, we compute the sigmoid of the score,
    and it’s approximately 0.29\. We can treat this as the probability that this customer
    will churn.
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了看到实际的流失概率，我们计算分数的sigmoid值，大约是0.29。我们可以将这个值视为这位客户将要流失的概率。
- en: If we have another client with a yearly contract who stayed 24 months with us
    and spent $2,000, the score is –2.823 (figure 3.40).
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们还有另一位客户，他签订了年度合同，与我们合作了24个月，花费了2,000美元，那么分数是–2.823（图3.40）。
- en: '![](../Images/03_40.png)'
  id: totrans-538
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_40.png)'
- en: Figure 3.40 The score that the model calculates for a customer with a yearly
    contract and 24 months of tenure
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.40 模型为签订了年度合同且服务了24个月的客户计算的分数
- en: After taking sigmoid, the score of –2.823 becomes 0.056, so the probability
    of churn for this customer is even lower (figure 3.41).
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 在取sigmoid之后，–2.823的分数变为0.056，所以这位客户的流失概率更低（图3.41）。
- en: '![](../Images/03_41.png)'
  id: totrans-541
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/03_41.png)'
- en: 'Figure 3.41 The scores of –2.823 and –0.893 translated to probability: 0.05
    and 0.29, respectively'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.41 –2.823和–0.893的分数分别转换为概率：0.05和0.29
- en: 3.3.4 Using the model
  id: totrans-543
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3.4 使用模型
- en: Now we know a lot better how logistic regression, and we can also interpret
    what our model learned and understand how it makes the predictions.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对逻辑回归有了更好的了解，我们还可以解释我们的模型学到了什么，并理解它是如何进行预测的。
- en: Additionally, we applied the model to the validation set, computed the probabilities
    of churning for every customer there, and concluded that the model is 80% accurate.
    In the next chapter we will evaluate whether this number is satisfactory, but
    for now, let’s try to use the model we trained. Now we can apply the model to
    customers for scoring them. It’s quite easy.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还应用了模型到验证集上，计算了每个客户的流失概率，并得出结论，该模型的准确率是80%。在下一章中，我们将评估这个数字是否令人满意，但现在，让我们尝试使用我们训练的模型。现在我们可以将模型应用于客户进行评分。这相当简单。
- en: 'First, we take a customer we want to score and put all the variable values
    in a dictionary:'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们取一个我们想要评分的客户，并将所有变量值放入一个字典中：
- en: '[PRE60]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Note When we prepare items for prediction, they should undergo the same preprocessing
    steps we did for training the model. If we don’t do it in exactly the same way,
    the model might not get things it expects to see, and, in this case, the predictions
    could get really off. This is why in the previous example, in the `customer` dictionary,
    the field names and string values are lowercased and spaces are replaced with
    underscores.
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：当我们为预测准备项目时，它们应该经过与我们为训练模型所进行的相同的预处理步骤。如果我们不按完全相同的方式进行，模型可能无法获得它期望看到的东西，在这种情况下，预测可能会非常不准确。这就是为什么在前面的例子中，在`customer`字典中，字段名称和字符串值都转换为小写，空格被下划线替换。
- en: Now we can use our model to see whether this customer is going to churn. Let’s
    do it.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用我们的模型来查看这位客户是否会流失。让我们试试。
- en: 'First, we convert this dictionary to a matrix by using the `DictVectorizer`:'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们使用`DictVectorizer`将这个字典转换为矩阵：
- en: '[PRE61]'
  id: totrans-551
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The input to the vectorizer is a list with one item: we want to score only
    one customer. The output is a matrix with features, and this matrix contains only
    one row—the features for this one customer:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 向量化器的输入是一个包含一个项目的列表：我们只想为一位客户评分。输出是一个包含特征的矩阵，而这个矩阵只包含一行——这位客户的特征：
- en: '[PRE62]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: We see a bunch of one-hot encoding features (ones and zeros) as well as some
    numeric ones (`monthlycharges`, `tenure`, and `totalcharges`).
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到一组独热编码特征（一和零）以及一些数值特征（`monthlycharges`、`tenure`和`totalcharges`）。
- en: 'Now we take this matrix and put it into the trained model:'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将这个矩阵放入训练好的模型中：
- en: '[PRE63]'
  id: totrans-556
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output is a matrix with predictions. For each customer, it outputs two
    numbers, which are the probability of staying with the company and the probability
    of churn. Because there’s only one customer, we get a tiny NumPy array with one
    row and two columns:'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一个包含预测的矩阵。对于每个客户，它输出两个数字，即客户继续与公司合作和客户流失的概率。因为只有一个客户，所以我们得到一个只有一行两列的小NumPy数组：
- en: '[PRE64]'
  id: totrans-558
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'All we need from the matrix is the number at the first row and second column:
    the probability of churning for this customer. To select this number from the
    array, we use the brackets operator:'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要矩阵中的第一个行和第二个列的数字：这位客户流失的概率。要从数组中选择这个数字，我们使用方括号操作符：
- en: '[PRE65]'
  id: totrans-560
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: We used this operator to select the second column from the array. However, this
    time there’s only one row, so we can explicitly ask NumPy to return the value
    from that row. Because indexes start from 0 in NumPy, `[0,` `1]` means first row,
    second column.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用这个操作符从数组中选择第二列。然而，这次只有一个行，所以我们可以明确要求NumPy返回该行的值。因为NumPy中的索引从0开始，`[0, 1]`表示第一行，第二列。
- en: When we execute this line, we see that the output is 0.073, so that the probability
    that this customer will churn is only 7%. It’s less than 50%, so we will not send
    this customer a promotional mail.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们执行这一行时，我们看到输出是0.073，这意味着这位客户流失的概率仅为7%。这低于50%，所以我们将不会给这位客户发送促销邮件。
- en: 'We can try to score another client:'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以尝试评分另一位客户：
- en: '[PRE66]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Let’s make a prediction:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行一次预测：
- en: '[PRE67]'
  id: totrans-566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: The output of the model is 83% likelihood of churn, so we should send this client
    a promotional mail in the hope of retaining them.
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的输出是83%的流失可能性，因此我们应该给这位客户发送促销邮件，希望留住他们。
- en: So far, we’ve built intuition on how logistic regression works, how to train
    it with Scikit-learn, and how to apply it to new data. We haven’t covered the
    evaluation of the results yet; this is what we will do in the next chapter.
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经对逻辑回归的工作原理、如何使用Scikit-learn进行训练以及如何将其应用于新数据有了直觉。我们还没有涵盖结果的评估；这是我们将在下一章中要做的。
- en: 3.4 Next steps
  id: totrans-569
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3.4 下一步
- en: 3.4.1 Exercises
  id: totrans-570
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.1 练习
- en: 'You can try a couple of things to learn the topic better:'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试一些事情来更好地学习这个主题：
- en: In the previous chapter, we implemented many things ourselves, including linear
    regression and dataset splitting. In this chapter we learned how to use Scikit-learn
    for that. Try to redo the project from the previous chapter using Scikit-learn.
    To use linear regression, you need `LinearRegression` from the `sklearn.linear_model`
    package. To use regularized regression, you need to import `Ridge` from the same
    package `sklearn.linear_model`.
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在上一章中，我们亲自实现了许多事情，包括线性回归和数据集拆分。在这一章中，我们学习了如何使用Scikit-learn来做这些。尝试使用Scikit-learn重新做上一章的项目。要使用线性回归，你需要从`sklearn.linear_model`包中导入`LinearRegression`。要使用正则化回归，你需要从同一个包`sklearn.linear_model`中导入`Ridge`。
- en: We looked at feature importance metrics to get some insights into the dataset
    but did not really use this information for other purposes. One way to use this
    information could be removing features that aren’t useful from the dataset to
    make the model simpler, faster, and potentially better. Try to exclude the two
    least useful features (`gender` and `phoneservices`) from the training data matrix,
    and see what happens to validation accuracy. What if we remove the most useful
    feature (`contract`)?
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们查看特征重要性指标，以获取对数据集的一些洞察，但并没有真正使用这些信息进行其他目的。使用这些信息的一种方法可能是从数据集中移除无用的特征，使模型更简单、更快，并可能更好。尝试从训练数据矩阵中排除两个最无用的特征（`gender`和`phoneservices`），看看验证准确率会发生什么变化。如果我们移除最有用的特征（`contract`）会怎样呢？
- en: 3.4.2 Other projects
  id: totrans-574
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4.2 其他项目
- en: 'We can use classification in numerous ways to solve real-life problems, and
    now, after learning the materials of this chapter, you should have enough knowledge
    to apply logistic regression to solve similar problems. In particular, we suggest
    these:'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用多种方式使用分类来解决现实生活中的问题，现在，在学完本章内容后，你应该有足够的知识来应用逻辑回归来解决类似的问题。特别是，我们建议以下方法：
- en: Classification models are often used for marketing purposes, and one of the
    problems it solves is *lead scoring*. A *lead* is a potential customer who may
    convert (become an actual customer) or not. In this case, the conversion is the
    target we want to predict. You can take a dataset from [https://www.kaggle.com/ashydv/
    leads-dataset](https://www.kaggle.com/ashydv/leads-dataset) and build a model
    for that. You may notice that the lead-scoring problem is similar to churn prediction,
    but in one case, we want to get a new client to sign a contract with us, and in
    another case, we want a client not to cancel the contract.
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类模型常用于营销目的，它解决的问题之一是*潜在客户评分*。一个*潜在客户*可能转化（成为实际客户）也可能不转化。在这种情况下，转化是我们想要预测的目标。你可以从[https://www.kaggle.com/ashydv/
    leads-dataset](https://www.kaggle.com/ashydv/leads-dataset)获取一个数据集并为其构建模型。你可能注意到，潜在客户评分问题与客户流失预测问题类似，但在一种情况下，我们希望新客户与我们签订合同，而在另一种情况下，我们希望客户不要取消合同。
- en: 'Another popular application of classification is default prediction, which
    is estimating the risk of a customer’s not paying back a loan. In this case, the
    variable we want to predict is default, and it also has two outcomes: whether
    the customer managed to pay back the loan in time (good customer) or not (default).
    You can find many datasets online for training a model, such as [https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)
    (or the same one available via Kaggle: [https://www.kaggle.com/pratjain/credit-card-default](https://www.kaggle.com/pratjain/credit-card-default)).'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类的一个流行应用是预测违约，即估计客户不偿还贷款的风险。在这种情况下，我们想要预测的变量是违约，它也有两种结果：客户是否成功按时偿还了贷款（良好客户）或者没有（违约）。你可以在网上找到许多用于训练模型的数据库，例如[https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients)（或者通过Kaggle可用的相同数据：[https://www.kaggle.com/pratjain/credit-card-default](https://www.kaggle.com/pratjain/credit-card-default)）。
- en: Summary
  id: totrans-578
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The *risk* of a categorical feature tells us if a group that has the feature
    will have the condition we model. For churn, values lower than 1.0 indicate low
    risk of churning, whereas values higher than 1.0 indicate high risk of churning.
    It tells us which features are important for predicting the target variable and
    helps us better understand the problem we’re solving.
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类特征的*风险*告诉我们具有该特征的群体是否会具有我们模型中的条件。对于客户流失，值低于1.0表示低流失风险，而值高于1.0表示高流失风险。它告诉我们哪些特征对于预测目标变量很重要，并帮助我们更好地理解我们正在解决的问题。
- en: 'Mutual information measures the degree of (in)dependence between a categorical
    variable and the target. It’s a good way of determining important features: the
    higher the mutual information is, the more important the feature.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互信息衡量一个分类变量与目标之间的（不）独立性程度。这是一种确定重要特征的好方法：互信息越高，特征就越重要。
- en: Correlation measures the dependence between two numerical variables, and it
    can be used for determining if a numerical feature is useful for predicting the
    target variable.
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关系数衡量两个数值变量之间的依赖程度，它可以用来确定一个数值特征是否对预测目标变量有用。
- en: One-hot encoding gives us a way to represent categorical variables as numbers.
    Without it, it wouldn’t be possible to easily use these variables in a model.
    Machine learning models typically expect all input variables to be numeric, so
    having an encoding scheme is crucial if we want to use categorical features in
    modeling.
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独热编码为我们提供了一种将分类变量表示为数字的方法。没有它，我们就不可能轻松地在模型中使用这些变量。机器学习模型通常期望所有输入变量都是数值型的，因此如果我们想在建模中使用分类特征，编码方案是至关重要的。
- en: We can implement one-hot encoding by using `DictVectorizer` from Scikit-learn.
    It automatically detects categorical variables and applies the one-hot encoding
    scheme to them while leaving numerical variables intact. It’s very convenient
    to use and doesn’t require a lot of coding on our side.
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以通过使用Scikit-learn的`DictVectorizer`来实现独热编码。它自动检测分类变量并对它们应用独热编码方案，同时保留数值变量不变。使用起来非常方便，并且不需要我们进行大量的编码。
- en: 'Logistic regression is a linear model, just like linear regression. The difference
    is that logistic regression has an extra step at the end: it applies the sigmoid
    function to convert the scores to probabilities (a number between zero and one).
    That allows us to use it for classification. The output is the probability of
    belonging to a positive class (churn, in our case).'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归是一个线性模型，就像线性回归一样。不同之处在于逻辑回归在最后有一个额外的步骤：它应用sigmoid函数将分数转换为概率（介于零和一之间的数字）。这使得我们可以将其用于分类。输出是属于正类（在我们的案例中是流失）的概率。
- en: 'When the data is prepared, training logistic regression is very simple: we
    use the `LogisticRegression` class from Scikit-learn and invoke the `fit` function.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据准备完成后，训练逻辑回归非常简单：我们使用Scikit-learn中的`LogisticRegression`类并调用`fit`函数。
- en: 'The model outputs probabilities, not hard predictions. To binarize the output,
    we cut the predictions at a certain threshold. If the probability is greater than
    or equal to 0.5, we predict `True` (churn), and `False` (no churn) otherwise.
    This allows us to use the model for solving our problem: predicting customers
    who churn.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型输出的是概率，而不是硬预测。为了二值化输出，我们在某个阈值处截断预测。如果概率大于或等于0.5，我们预测`True`（流失），否则预测`False`（未流失）。这使得我们可以使用该模型来解决我们的问题：预测流失的客户。
- en: The weights of the logistic regression model are easy to interpret and explain,
    especially when it comes to the categorical variables encoded using the one-hot
    encoding scheme. It helps us understand the behavior of the model better and explain
    to others what it’s doing and how it’s working.
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归模型的权重易于解释和说明，尤其是在使用单热编码方案对分类变量进行编码时。这有助于我们更好地理解模型的行为，并向他人解释它在做什么以及它是如何工作的。
- en: In the next chapter we will continue with this project on churn prediction.
    We will look at ways of evaluating binary classifiers and then use this information
    for tuning the model’s performance.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将继续进行关于客户流失预测的项目。我们将探讨评估二元分类器的方法，然后利用这些信息来调整模型的表现。
- en: Answers to exercises
  id: totrans-589
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习答案
- en: Exercise 3.1 B) The percentage of `True` elements
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习3.1 B) 真实元素的百分比
- en: Exercise 3.2 A) It will keep a numeric variable as is and encode only the categorical
    variable.
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习3.2 A) 它将保持数值变量不变，并仅对分类变量进行编码。
- en: Exercise 3.3 B) Sigmoid converts the output to a value between zero and one.
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习3.3 B) sigmoid函数将输出转换为介于零和一之间的值。
