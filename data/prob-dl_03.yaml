- en: 2 Neural network architectures
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 神经网络架构
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Needing different network types for different data types
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要根据不同的数据类型使用不同的网络类型
- en: Using fully connected neural networks for tabular-like data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用完全连接神经网络处理类似表格的数据
- en: Using 2D convolutional neural networks for image-like data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用二维卷积神经网络处理类似图像的数据
- en: Using 1D convolutional neural networks for ordered data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用一维卷积神经网络处理有序数据
- en: '![](../Images/2-unnumb.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-unnumb.png)'
- en: 'The vast majority of DL models are based on one or a combination of three types
    of layers: fully connected, convolutional, and recurrent. The success of a DL
    model depends in great part on choosing the right architecture for the problem
    at hand.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数深度学习模型都是基于一种或多种类型的层：完全连接、卷积和循环。深度学习模型的成功在很大程度上取决于为特定问题选择正确的架构。
- en: If you want to analyze data that has no structure, like tabular data in Excel
    sheets, then you should consider fully connected networks. If the data has a special
    local structure like images, then convolutional neural networks (NNs) are your
    friends. Finally, if the data is sequential like text, then the easiest option
    is to use 1D convolutional networks. This chapter gives you an overview of the
    different architectures used in DL and provides hints as to when to use which
    architectural type.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要分析没有结构的数据，例如Excel表格中的表格数据，那么你应该考虑使用完全连接网络。如果数据具有特殊的局部结构，如图像，那么卷积神经网络（NNs）是你的朋友。最后，如果数据是序列性的，如文本，那么最简单的选择是使用一维卷积网络。本章为你概述了在深度学习中使用的不同架构，并提供了一些关于何时使用哪种架构类型的提示。
- en: 2.1 Fully connected neural networks (fcNNs)
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 完全连接神经网络（fcNNs）
- en: Before diving into the details of the different DL architectures, let’s look
    at figure 2.1\. Recall the architecture of a typical traditional artificial NN
    that we discussed in chapter 1\. The visualized NN has three hidden layers, each
    holding nine neurons. Each neuron within a layer connects with each neuron in
    the next layer. This is why this architecture is called a densely connected NN
    or a fully connected neural network (fcNN).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨不同深度学习架构的细节之前，让我们看看图2.1。回想一下我们在第1章中讨论的典型传统人工神经网络的架构。可视化的神经网络有三个隐藏层，每个层包含九个神经元。层内的每个神经元都与下一层的每个神经元相连。这就是为什么这种架构被称为密集连接神经网络或完全连接神经网络（fcNN）。
- en: '![](../Images/2-1.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-1.png)'
- en: Figure 2.1 An example of a fully connected neural network (fcNN) model with
    three hidden layers
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.1 一个具有三个隐藏层的完全连接神经网络（fcNN）模型示例](../Images/2-1.png)'
- en: 2.1.1 The biology that inspired the design of artificial NNs
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.1 激发人工神经网络设计的生物学
- en: The design of NNs is inspired by the way the brain works. You shouldn’t overstretch
    this point; it’s just a loose inspiration. The brain is a network of neurons.
    The human brain has about 100 billion neurons, and each neuron, on average, connects
    with 10,000 other neurons. Let’s take a look at the brain’s basic unit--the neuron
    (see figure 2.2).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的设计灵感来源于大脑的工作方式。你不应该过分强调这一点；这只是一个大致的灵感。大脑是一个由神经元组成的网络。人脑大约有1000亿个神经元，平均每个神经元连接大约10000个其他神经元。让我们看看大脑的基本单元——神经元（见图2.2）。
- en: '![](../Images/2-2.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-2.png)'
- en: Figure 2.2 A single biological brain cell. The neuron receives the signal from
    other neurons via its dendrites (shown on the left). If the accumulated signal
    exceeds a certain value, an impulse is sent via the axon to the axon terminals
    (on the right), which, in turn, couple to other neurons.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.2 单个生物脑细胞。神经元通过其树突（左侧所示）接收来自其他神经元的信号。如果累积的信号超过一定值，就会通过轴突发送冲动到轴突末端（右侧），这些末端反过来与其他神经元耦合。](../Images/2-2.png)'
- en: 'Figure 2.2 shows a very simplified sketch of a neuron. It receives signals
    from other neurons via its dendrites. Some inputs have an activating impact, and
    some inputs have an inhibiting impact. The received signal accumulates and is
    processed within the cell body of the neuron. If the signal is strong enough,
    the neuron fires. That means it produces a signal that’s transported to the axon
    terminals. Each axon terminal connects to another neuron. Some connections can
    be stronger than others, which makes it easier to transduce the signal to the
    next neuron. Experiences and learning can change the strength of these connections.
    Computer scientists have derived a mathematical abstraction from the biological
    brain cell: the artificial neuron shown in figure 2.3.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 展示了一个非常简化的神经元草图。它通过其树突接收来自其他神经元的信号。一些输入具有激活作用，而一些输入具有抑制作用。接收到的信号在神经元的细胞体中积累并处理。如果信号足够强，神经元就会放电。这意味着它产生一个信号，该信号被传输到轴突末端。每个轴突末端都连接到另一个神经元。一些连接可能比其他连接更强，这使得将信号转换到下一个神经元更容易。经验和学习可以改变这些连接的强度。计算机科学家从生物大脑细胞中推导出一个数学抽象：图2.3中所示的人工神经元。
- en: '![](../Images/2-3.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-3.png)'
- en: Figure 2.3 The mathematical abstraction of a brain cell (an artificial neuron).
    The value *z* is computed as the weighted sum of the input values p, *x*[1] to
    xp, and a bias term *b* that shifts up or down the resulting weighted sum of the
    inputs. The value *y* is computed from *z* by applying an activation function.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 大脑细胞（人工神经元）的数学抽象。值 *z* 是通过输入值 p，*x*[1] 到 xp 的加权和以及一个偏置项 *b*（该偏置项的输入为1）来计算的，该偏置项将输入的加权总和向上或向下移动。值
    *y* 通过应用激活函数从 *z* 计算得出。
- en: 'An artificial neuron receives some numeric input values, *x**[i]* , which are
    multiplied with some corresponding numeric weights, wi. To accumulate the inputs,
    determine the weighted sum of the inputs plus a bias term *b* (that gets 1 as
    input) as *z = x*[1] *∙ w*[1] *+x*[1] *∙ w*[1] *+* ⋯ *+* *x**[p]* ⋅ *w**[p]* *+*
    1 ⋅ *b* . Note that this formula is the same as that used in linear regression.
    You can then further transform the resulting *z* value by a non-linear activation
    function, the so-called sigmoid function, which transfers *z* to a number between
    0 and 1 (see figure 2.4). This function is given by:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经元接收一些数值输入值，*x**[i]*，这些值与一些相应的数值权重 wi 相乘。为了累积输入，确定输入的加权总和加上一个偏置项 *b*（该偏置项的输入为1）作为
    *z = x*[1] *∙ w*[1] *+x*[1] *∙ w*[1] *+* ⋯ *+* *x**[p]* ⋅ *w**[p]* *+* 1 ⋅ *b*。请注意，这个公式与线性回归中使用的公式相同。然后你可以通过一个非线性激活函数，即所谓的S型函数，进一步转换得到的
    *z* 值，该函数将 *z* 转换为一个介于0和1之间的数（见图2.4）。该函数由以下公式给出：
- en: '![](../Images/equation_2-2.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![公式](../Images/equation_2-2.png)'
- en: As you can see in figure 2.4, large positive values of *z* result in values
    close to 1, and negative values with large absolute values result in values close
    to 0\. In this sense, the resulting value *y* can be interpreted as the probability
    that the neuron fires. Or, in the context of classification, as a probability
    for a certain class. If you want to build a binary classifier (with 0 and 1 as
    possible classes), which takes several numeric features, *x**[i]* , and generates
    the probability for class 1, then you can use a single neuron. If you have a background
    in statistics, this might look familiar, and indeed, a network with a single neuron
    is known in statistics also as logistic regression. But no need to worry if you’ve
    never heard of logistic regression.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如图2.4所示，*z* 的较大正值导致接近1的值，而具有较大绝对值的负值导致接近0的值。在这种情况下，结果值 *y* 可以解释为神经元放电的概率。或者，在分类的背景下，为某一类别的概率。如果你想要构建一个二元分类器（具有0和1作为可能的类别），它接受几个数值特征
    *x**[i]*，并生成类别1的概率，那么你可以使用单个神经元。如果你有统计学背景，这可能会让你感到熟悉，实际上，在统计学中，具有单个神经元的网络也被称为逻辑回归。但如果你从未听说过逻辑回归，无需担心。
- en: '![](../Images/2-4.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-4.png)'
- en: Figure 2.4 The sigmoid function f translating (squeezing) an arbitrary number
    *z* to a number between 0 and 1.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 S型函数 f 将任意数 *z* 转换为介于0和1之间的数。
- en: 2.1.2 Getting started with implementing an NN
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.2 开始实现神经网络
- en: To get started working with DL, you need to know the basic data structures,
    the tensors, and the software packages manipulating those entities.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用深度学习，你需要了解基本的数据结构，张量，以及操作这些实体的软件包。
- en: 'Tensors: The basic entities in DL'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 张量：深度学习中的基本实体
- en: Looking at figure 2.3, the mathematical abstraction of a neuron, you might ask
    the question, “What goes in and what comes out?” Assuming that p = 3 in figure
    2.3, then you see three numbers (x1, x2, and x3) entering the neuron and a single
    number leaving the neuron. These three numbers can be treated as an array with
    one index. More complex neural networks can take a grayscale image, say of size
    64 × 32 as input, which can be also expressed as an array. But this time the array
    has two indices. The first index, i, ranges from 0 to 63 and the second, j, from
    0 to 31.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 观察图2.3中神经元的数学抽象，你可能会问，“输入什么，输出什么？”假设图2.3中的p=3，那么你会看到三个数字（x1、x2和x3）进入神经元，一个数字离开神经元。这三个数字可以被视为一个只有一个索引的数组。更复杂的神经网络可以接受一个灰度图像作为输入，例如大小为64×32的图像，这也可以表示为一个数组。但这次数组有两个索引。第一个索引i的范围是从0到63，第二个索引j的范围是从0到31。
- en: Going further, say you have a color image with the colors red, green, and blue.
    For such an image, each pixel has *x*,y coordinates and three additional values.
    The image can be stored in an array with three indices (i, j, c). Taking it to
    the extreme, say you input a whole stack of 128 color images into the network.
    These could be stored in an array of (b, *x*, *y* , c) with *b* ranging from 0
    to 127\. Also, you can view the three weights in figure 2.3 as an array with one
    index, going from 0 to 2.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步来说，假设你有一个包含红色、绿色和蓝色三种颜色的彩色图像。对于这样的图像，每个像素都有*x*,y坐标和三个额外的值。图像可以存储在一个有三个索引（i,
    j, c）的数组中。将其推向极端，假设你将一整堆128个彩色图像输入到网络中。这些可以存储在一个(b, *x*, *y* , c)的数组中，其中*b*的范围是从0到127。此外，你还可以将图2.3中的三个权重视为一个只有一个索引的数组，从0到2。
- en: 'As it turns out, all quantities in DL can be put into arrays. In the context
    of DL, these arrays are called tensors, and from an abstract standpoint, all that
    happens in DL is the manipulation of tensors. The number of indices tensors have
    is the so-called dimension, order, or sometimes rank (so don’t get confuse*D*).
    Tensors of order 0, like the output of the neuron in figure 2.3, have no indices.
    Tensors with low orders also have special names:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，深度学习中的所有量都可以放入数组中。在深度学习的背景下，这些数组被称为张量，从抽象的角度来看，深度学习中所发生的一切都是对张量的操作。张量拥有的索引数被称为维度、阶数，有时也称为秩（所以不要混淆D）。阶数为0的张量，如图2.3中神经元的输出，没有索引。低阶张量也有特殊的名称：
- en: Tensors of order 0 are called scalars.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阶数为0的张量被称为标量。
- en: Tensors of order 1 are called vectors.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一阶张量被称为向量。
- en: Tensors of order 2 are called matrices.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二阶张量被称为矩阵。
- en: The shape of a tensor defines how many values each index can have. For example,
    if you have a gray-valued image of 64 × 32 pixels, the shape of the tensor is
    (64, 32). That’s all you need to know about tensors when you use DL. But be aware
    when you google tensors, you might find frightening stuff, like the mathematical
    definition by its transformation properties. Don’t worry. In the context of DL,
    a tensor is only a data container with a special structure like, for example,
    a vector or a matrix. If you feel insecure with vectors and matrices, it’s worth
    taking a look at chapter 2 of François Chollet’s book, Deep Learning with Python,
    2nd ed., (Manning, 2017), at [http://mng.bz/EdPo](http://mng.bz/EdPo) for an in-depth
    explanation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 张量的形状定义了每个索引可以有多少个值。例如，如果你有一个64×32像素的灰度图像，张量的形状是（64，32）。这就是你在使用深度学习时需要了解的所有关于张量的知识。但请注意，当你谷歌搜索张量时，你可能会找到一些令人恐惧的东西，比如通过其变换属性给出的数学定义。别担心。在深度学习的背景下，张量只是一个具有特殊结构的数据容器，例如，例如向量或矩阵。如果你对向量和矩阵感到不安全，那么查看François
    Chollet的《Python深度学习》第2版（Manning，2017）的第2章是值得的，可以在[http://mng.bz/EdPo](http://mng.bz/EdPo)找到深入的解释。
- en: Software tools
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工具
- en: DL has gained enormous popularity with the availability of software frameworks
    built to manipulate tensors. In this book, we mainly use Keras([https://keras.io/](https://keras.io/))
    and TensorFlow([https://www.tensorflow.org/](https://www.tensorflow.org/)). Currently,
    these two frameworks are most often used by DL practitioners. TensorFlow is an
    open source framework developed by Google that comes with strong support for DL.
    Keras is a user-friendly, high-level neural networks API written in Python and
    capable of running on top of TensorFlow, allowing for fast prototyping.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 随着用于操作张量的软件框架的可用性，深度学习获得了巨大的普及。在这本书中，我们主要使用Keras([https://keras.io/](https://keras.io/))和TensorFlow([https://www.tensorflow.org/](https://www.tensorflow.org/))。目前，这两个框架是最常被深度学习从业者使用的。TensorFlow是由Google开发的开源框架，它为深度学习提供了强大的支持。Keras是一个用户友好的、高级神经网络API，用Python编写，可以在TensorFlow之上运行，允许快速原型设计。
- en: To work through the exercises in this book, we recommend that you use the Google
    Colab environment ([https://colab.research.google.com](https://colab.research.google.com))
    as a cloud solution that runs in your browser. The most important frameworks,
    packages, and tools for DL are already installed, and you can immediately start
    coding. If you want to install a DL framework on your own computer, we recommend
    you follow the description given in chapter 3 of Chollet’s book at [http://mng.bz/NKPN](http://mng.bz/NKPN)
    .
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这本书中的练习，我们建议您使用Google Colab环境（[https://colab.research.google.com](https://colab.research.google.com)）作为在浏览器中运行的云解决方案。深度学习最重要的框架、包和工具已经安装，您可以立即开始编码。如果您想在您的计算机上安装深度学习框架，我们建议您遵循Chollet在其书籍第3章中给出的描述，请参阅
    [http://mng.bz/NKPN](http://mng.bz/NKPN) .
- en: 'To dig deeper into TensorFlow, Martin Görner’s tutorial is a good starting
    point: [https://www.youtube.com/watch?v=vq2nnJ4g6N0](https://www.youtube.com/watch?v=vq2nnJ4g6N0)
    .'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要深入了解TensorFlow，Martin Görner的教程是一个很好的起点：[https://www.youtube.com/watch?v=vq2nnJ4g6N0](https://www.youtube.com/watch?v=vq2nnJ4g6N0)
    .
- en: To learn more about Keras, we recommend the website [https://keras.io/](https://keras.io/)
    .
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要了解更多关于Keras的信息，我们推荐访问网站 [https://keras.io/](https://keras.io/) .
- en: 'We use Jupyter notebooks ([https://jupyter.org/](https://jupyter.org/)) to
    provide you with some hands-on exercises and code examples. Jupyter notebooks
    offer the ability to mix Python, TensorFlow, and Keras code with text and Markdown.
    The notebooks are organized in cells containing either text or code. This lets
    you play around with the code by changing only the code in one cell. In many exercises,
    we provide large parts of the code, and you can experiment in individual cells
    with your own code. Feel free to also change the code at any location; you can’t
    break anything. While DL often involves huge data sets and needs enormous computing
    power, we distilled simple examples so that you can interactively work with the
    notebooks. We use the following icon to indicate the positions in the book where
    you should open a Jupyter notebook and work through the related code:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Jupyter笔记本（[https://jupyter.org/](https://jupyter.org/)）为您提供一些动手练习和代码示例。Jupyter笔记本允许将Python、TensorFlow和Keras代码与文本和Markdown混合。笔记本组织在包含文本或代码的单元格中。这使您可以通过仅更改一个单元格中的代码来玩转代码。在许多练习中，我们提供了大量代码，您可以在单独的单元格中使用自己的代码进行实验。您也可以随意更改代码的任何位置；您不会破坏任何东西。虽然深度学习通常涉及大量数据集并需要巨大的计算能力，但我们提炼了简单的示例，以便您可以交互式地使用笔记本。我们使用以下图标来指示书中您应该打开Jupyter笔记本并执行相关代码的位置：
- en: '![](../Images/computer-icon.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![计算机图标](../Images/computer-icon.png)'
- en: 'You can open these notebooks directly in Google Colab, where you can edit and
    run these in your browser. Colab is great, but you need to be online to use it.
    Another option (good for working offline) is to use the provided Docker container.
    For details on how to install Docker, see [https://tensorchiefs.github.io/dl_book/](https://tensorchiefs.github.io/dl_book/)
    . Within the Jupyter notebooks, we use the following icon to indicate where you
    should return to this book:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接在Google Colab中打开这些笔记本，在那里您可以在浏览器中编辑和运行它们。Colab很棒，但您需要在线才能使用它。另一个选项（适合离线工作）是使用提供的Docker容器。有关如何安装Docker的详细信息，请参阅
    [https://tensorchiefs.github.io/dl_book/](https://tensorchiefs.github.io/dl_book/)
    . 在Jupyter笔记本中，我们使用以下图标来指示您应该返回这本书的位置：
- en: '![book-icon](../Images/book-icon.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![书籍图标](../Images/book-icon.png)'
- en: Setting up a first NN model to identify fake banknotes
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 设置第一个神经网络模型以识别假钞
- en: Let’s get started and do a first DL experiment. In this experiment, you use
    a single artificial neuron to discriminate real from fake banknotes.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始，进行第一个深度学习实验。在这个实验中，你使用一个单一的人工神经元来区分真钞和假钞。
- en: '| ![](../Images/computer-icon.png) | Hands-on time Open [http://mng.bz/lGd6](http://mng.bz/lGd6)
    , where you’ll find a data set describing 1,372 banknotes by two features and
    a class label *y* . |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| ![计算机图标](../Images/computer-icon.png) | 动手时间 打开 [http://mng.bz/lGd6](http://mng.bz/lGd6)
    ，您将找到一个数据集，该数据集通过两个特征和一个类别标签 *y* 描述了1,372张钞票。 |'
- en: The two image features are based on wavelet analysis, a frequently used method
    in traditional image analysis. It’s common to store the input values and the target
    values in two separate tensors. The input data set contains 1,372 instances described
    by two features that you can organize in one 2D tensor. The first dimension usually
    describes the samples. This axis is referred to as axis 0\. For the example, you
    have a 2D tensor with a shape (1372, 2). The target values are the true class
    labels that can be stored in a second 1D tensor with a shape (1372).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 两个图像特征基于小波分析，这是传统图像分析中常用的一种方法。通常将输入值和目标值存储在两个不同的张量中。输入数据集包含1,372个实例，由两个特征描述，你可以将这些特征组织在一个2D张量中。第一个维度通常描述样本。这个轴被称为轴0。对于这个例子，你有一个形状为（1372，2）的2D张量。目标值是真实的类别标签，可以存储在一个形状为（1372）的第二个1D张量中。
- en: DL models typically run on graphic cards, also called graphic processing units
    (GPUs). These GPUs have limited memory. You therefore can’t process an entire
    data set at once. The data is split into smaller batches containing only a subset
    of the entire data set. These batches are called mini-batches, and a typical number
    of instances contained in a mini-batch is either 32, 64, or 128\. In our banknote
    example, we use mini-batches with a size shape of 128.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型通常在图形卡上运行，也称为图形处理单元（GPU）。这些GPU具有有限的内存。因此，你不能一次性处理整个数据集。数据被分成更小的批次，这些批次只包含整个数据集的一个子集。这些批次被称为小批量，一个典型的小批量包含的实例数量是32、64或128。在我们的纸币示例中，我们使用形状为128的小批量。
- en: Because the banknotes are described by only two features, you can easily see
    the positions of real and fake banknotes in the 2D feature space (see figure 2.5).
    Also, the boundary between the two classes isn’t separated by a straight line.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于纸币仅由两个特征描述，你可以在2D特征空间中轻松地看到真实和假纸币的位置（见图2.5）。此外，两个类别的边界不是由一条直线分开的。
- en: '![](../Images/2-5.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-5.png)'
- en: Figure 2.5 The (training) data points for the real and fake banknotes
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2.5**：真实和假纸币的（训练）数据点'
- en: Let’s use a single neuron with a sigmoid activation function (also known as
    logistic regression) as a classification model (see figure 2.6). We’ll separate
    the fake banknotes from the real banknotes for the data shown in figure 2.5.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用一个具有sigmoid激活函数（也称为逻辑回归）的单个神经元作为分类模型（见图2.6）。我们将分离图2.5所示数据中的假纸币和真纸币。
- en: Before we define the Keras code, let’s think of the tensor structure needed.
    What goes into the network? If you use a single training data point, it’s a vector
    with two entries (the next section discusses how the bias is handle*D*). If you
    take a batch of size 128 of those vectors, you have a tensor of order 2 (a matrix)
    with the shape (128, 2). Usually one doesn’t specify the batch size when defining
    the network. In that case, you use `None` as the batch size. As in figure 2.6,
    the input is processed by a single neuron with sigmoid activation.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们定义Keras代码之前，让我们先考虑所需的张量结构。网络中包含什么？如果你使用单个训练数据点，它是一个有两个条目（下一节将讨论如何处理偏置*D*）的向量。如果你取128个这样的向量的批次，你将得到一个2阶（矩阵）的张量，形状为（128，2）。通常在定义网络时不会指定批次大小。在这种情况下，你使用`None`作为批次大小。如图2.6所示，输入由一个具有sigmoid激活的单个神经元处理。
- en: '![](../Images/2-6.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-6.png)'
- en: Figure 2.6 An fcNN with one single neuron. The two nodes in the input layer
    correspond to the two features describing each banknote. The output layer has
    one node that corresponds to the probability of class 1 (a fake banknote).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**图2.6**：一个具有单个神经元的全连接神经网络。输入层中的两个节点对应于描述每个纸币的两个特征。输出层有一个节点，对应于类别1（假纸币）的概率。'
- en: NOTE Here we only briefly discuss the main building blocks needed for our DL
    experiment. To learn about Keras, refer to the Keras website at [https:// keras.io/,](https://keras.io/)
    and the book, Deep Learning With Python, written by the creator of Keras, François
    Chollet.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**：在这里，我们仅简要讨论我们深度学习实验所需的主要构建块。要了解Keras，请参考Keras网站[https://keras.io/](https://keras.io/)以及由Keras的创造者François
    Chollet所著的《Python深度学习》一书。'
- en: In listing 2.1, we use the sequential mode to define the NN model. In the sequential
    model definition, the layers are added one after the other. The output of one
    layer is the input to the next layer and so on; therefore, you usually don’t need
    to specify the shape of the inputs to a layer. The first layer is an exception,
    and here you need to specify the shape of the input.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表2.1中，我们使用顺序模式定义NN模型。在顺序模型定义中，层是依次添加的。一个层的输出是下一个层的输入，依此类推；因此，通常不需要指定层的输入形状。第一层是一个例外，这里你需要指定输入的形状。
- en: Under the hood, Keras translates the model into tensor operations. In our simple
    model in listing 2.1, the dense layer, `Dense(1)` , takes the input tensor `X`
    with the dimension (`batch_size` , 2), multiplies it with a 2 × 2 matrix **W**
    , and adds a bias term b. This gives a vector of length `batch_size.` If this
    sounds strange to you, take a look at chapter 2 of Chollet’s book, Deep Learning
    with Python, at [http://mng.bz/EdPo](http://mng.bz/EdPo) to learn more about matrix
    multiplication.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，Keras将模型转换为张量操作。在我们的简单模型列表2.1中，`Dense(1)`密集层接收维度为（`batch_size`，2）的输入张量`X`，与2×2矩阵**W**相乘，并加上一个偏置项b。这给出一个长度为`batch_size`的向量。如果你觉得这很奇怪，可以查看Chollet的《Python深度学习》一书的第2章，了解更多关于矩阵乘法的信息。[http://mng.bz/EdPo](http://mng.bz/EdPo)
- en: After defining the model, it’s compiled, and the used loss and an optimization
    function need to be specified. Here we use the loss function `crossentropy` ,
    which is commonly used for classification and which quantifies how well the correct
    class is predicted. You’ll learn more about loss functions in chapter 4\. Last
    but not least, we optimize the weights of the model by an iterative training process,
    which is called stochastic gradient descent (SGD), discussed in chapter 3\. The
    goal of the fitting process is to adapt the model weights so that the loss is
    minimized. The model weights are updated after each mini-batch, here containing
    128 instances. One iteration over the complete training set is called an epoch;
    here we train for 400 epochs.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义模型之后，需要编译模型，并指定使用的损失函数和优化函数。这里我们使用损失函数`crossentropy`，它常用于分类，并量化正确类别的预测效果。你将在第4章中了解更多关于损失函数的内容。最后但同样重要的是，我们通过迭代训练过程优化模型的权重，这被称为随机梯度下降（SGD），在第3章中有详细讨论。拟合过程的目标是调整模型权重，以使损失最小化。在每个小批量之后更新模型权重，这里包含128个实例。对整个训练集的一次遍历称为一个epoch；这里我们训练了400个epochs。
- en: Listing 2.1 Definition of an NN with only one neuron after the input
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.1 定义一个输入后只有一个神经元的NN
- en: '[PRE0]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Sequential starts the definition of the network.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Sequential开始定义网络。
- en: ❷ Adds a new layer to the network with a single neuron; hence, 1 in Dense(1)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在网络中添加了一个具有单个神经元的新的层；因此，在`Dense(1)`中是1
- en: ❸ The input is a tensor of size (Batch Size, 2). Using None, we don’t need to
    specify the batch size now.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 输入是一个大小为（批大小，2）的张量。使用None，我们现在不需要指定批大小。
- en: ❹ Chooses the activation function sigmoid as in figure 2.4
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 选择如图2.4所示的激活函数sigmoid
- en: ❺ Compiles the model, which ends the definition of the model
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 编译模型，这标志着模型定义的结束
- en: ❻ Defines and uses the stochastic gradient descent optimizer
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 定义并使用随机梯度下降优化器
- en: ❼ Trains the model using the data stored in *x* and *y* for 400 epochs
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 使用存储在*x*和*y*中的数据训练模型400个epochs
- en: ❽ Fixes the batch size to 128 examples
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 将批大小固定为128个示例
- en: '| ![](../Images/computer-icon.png) | Hands-on time When running the code in
    the [http://mng.bz/lGd6](http://mng.bz/lGd6) notebook, you’ll observe a decreasing
    loss and an increasing accuracy. This indicates that the training works fine.
    |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| ![](../Images/computer-icon.png) | 实践时间 当在[http://mng.bz/lGd6](http://mng.bz/lGd6)笔记本中运行代码时，你会观察到损失逐渐减少，准确率逐渐提高。这表明训练工作正常。
    |'
- en: Let’s take the trained network, use it for a prediction, and look at the output.
    In figure 2.7, you see a systematic evaluation of the probability that a banknote
    is fake, given the features *x*[1] and x2.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用训练好的网络进行预测，并查看输出。在图2.7中，你可以看到基于特征*x*[1]和x2的系统评估一张纸币是假币的概率。
- en: The shading of the background in figure 2.7 indicates the predicted probability
    for an instance with the corresponding values of the two features. The white color
    indicates positions in the feature space where the probability for both classes
    is 0.5\. Points on the one side are classified to one class and points on the
    other side, to the other class. This boundary is called the decision boundary.
    As you can see, it’s a line. This isn’t a coincidence but a general property of
    a single artificial neuron with a sigmoid as an activation function. In a 2D features
    space, the decision boundary is a straight line. It isn’t curved and has no wiggles.
    If you have three features, the boundary is a plane (no wiggles), and it stays
    as an object with no wiggles for a feature space with more than three dimensions,
    which is called hyperplane.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7中背景的阴影表示具有相应两个特征值的实例的预测概率。白色表示特征空间中两个类别的概率都是0.5的位置。一侧的点被分类为一类，另一侧的点被分类为另一类。这个边界被称为决策边界。如你所见，它是一条线。这不是巧合，而是具有sigmoid激活函数的单个人工神经元的一般特性。在二维特征空间中，决策边界是一条直线。它不是曲线，也没有波动。如果你有三个特征，边界是一个平面（没有波动），并且对于超过三个维度的特征空间，它保持没有波动的对象，这被称为超平面。
- en: '![](../Images/2-7.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-7.png)'
- en: Figure 2.7 An NN with only one neuron after the input layer produces a linear
    decision boundary. The shading of the background in the 2D feature space shows
    the probability for a fake banknote. The right side overlays the training data,
    showing that the linear decision curve doesn’t fit nicely in the boundary between
    the real and fake banknotes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 输入层之后只有一个神经元的神经网络产生一个线性决策边界。二维特征空间中背景的阴影表示假钞的概率。右侧叠加了训练数据，显示线性决策曲线在真钞和假钞之间的边界上并不完美地拟合。
- en: But in the banknote example, the true boundary between the two classes is curved.
    Therefore, a single neuron isn’t appropriate to model the probability for a fake
    banknote based on its two features. To get a more flexible model, we introduce
    an additional layer between the input and output layers (see figure 2.8). This
    layer is called the hidden layer because its values aren’t directly observed but
    are constructed from the values in the input layer.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 但在纸币示例中，两个类别之间的真实边界是曲线的。因此，单个神经元不适合根据其两个特征来模拟假钞的概率。为了获得更灵活的模型，我们在输入层和输出层之间引入了一个额外的层（见图2.8）。这个层被称为隐藏层，因为它的值不是直接观察到的，而是由输入层的值构建的。
- en: 'In this example, the hidden layer holds eight neurons; each gets as input a
    weighted sum of the same input features but with different weights. The weighted
    sum is then transformed by the activation function. You can think about these
    neurons in the hidden layer as a new representation of the input. Originally,
    it was represented by two values (features), now it’s represented by eight values
    (features): the output of the eight neurons. This is sometimes called feature
    expansion. You can use different numbers of neurons in the hidden layer, which
    is part of the design of the NN.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，隐藏层包含八个神经元；每个神经元都接收相同输入特征的加权总和，但权重不同。加权总和随后通过激活函数进行转换。你可以将这些隐藏层中的神经元视为输入的新表示。最初，它由两个值（特征）表示，现在则由八个值（特征）表示：八个神经元的输出。这有时被称为特征扩展。你可以在隐藏层中使用不同数量的神经元，这是神经网络设计的一部分。
- en: 'The output layer gives the probability for the instance to be a real or fake
    banknote. You have seen that one neuron is sufficient in a binary classification
    problem because knowing the probability p of one class fixes the probability of
    the other class to 1 - p. You can also use two neurons in the output layer: one
    neuron modeling the probability for the first class and the other neuron modeling
    the probability for the second class. This output layer design generalizes to
    classification tasks with more than two classes. In this case, the output layer
    has as many neurons as you have classes in the classification problem. Each neuron
    stands for a class, and you want to interpret the output of the neuron as the
    probability for the class. This can be done using the `softmax` function. The
    `softmax` function takes the weighted sum zi and transforms it into a probability
    pi by setting'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 输出层给出了实例是真实或假钞的概率。你已经看到，在二元分类问题中，一个神经元就足够了，因为知道一个类的概率p就固定了另一个类的概率为1 - p。你还可以在输出层使用两个神经元：一个神经元模拟第一个类的概率，另一个神经元模拟第二个类的概率。这种输出层设计可以推广到具有两个以上类别的分类任务。在这种情况下，输出层的神经元数量与分类问题中的类别数量相同。每个神经元代表一个类别，你希望将神经元的输出解释为该类的概率。这可以通过`softmax`函数来完成。`softmax`函数将加权求和zi转换为概率pi，通过设置
- en: '![](../Images/equation_2-3.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/equation_2-3.png)'
- en: This ensures that the values are between 0 and 1 and, further, add up to 1\.
    You can therefore interpret pi as the probability for the class i. The “soft”
    in softmax indicates that, rather than giving a hard call to one of the possible
    classes, the network can assign smaller probabilities to the other classes.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这确保了值在0和1之间，并且进一步地，它们的总和为1。因此，你可以将π解释为类别i的概率。softmax中的“软”表示，网络不是对可能的类别之一做出硬性判断，而是可以给其他类别分配较小的概率。
- en: '![](../Images/2-8.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-8.png)'
- en: Figure 2.8 An fcNN with one hidden layer consisting of eight nodes. The input
    layer has two nodes corresponding to two features in the banknote data set, and
    the output layer has two nodes corresponding to two classes (real and fake banknotes).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 由八个节点组成的一个隐藏层的fcNN。输入层有两个节点，对应于钞票数据集中的两个特征，输出层有两个节点，对应于两个类别（真实和假钞）。
- en: The *y* vector of the training data also has to be changed to be compatible
    with the two outputs. It was *y* = 1 if the example belonged to the class `fake`
    and *y* = 0 for the class `real` . Now you want the label to describe the two
    possible outputs. A real banknote should have the output values p0 = 1 and p1
    = 0, and a fake banknote, the values p0 = 0 and p1 = 1\. This can be achieved
    by a one-hot encoding of *y*. You start with a vector with as many zeros as you
    have classes (here two). Then you set one entry to 1\. For *y* = 0, you set the
    0 th entry to 1 so that you have the vector (1, 0), and for *y* = 1, you have
    the vector (0, 1). For the architecture of the fcNN, see figure 2.8, and for the
    corresponding Keras code, see listing 2.2.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据的*y*向量也需要改变，以便与两个输出兼容。如果示例属于类别`fake`，则*y* = 1，对于类别`real`，*y* = 0。现在你希望标签描述两个可能的输出。一张真实的钞票应该有输出值p0
    = 1和p1 = 0，而一张假钞，其值p0 = 0和p1 = 1。这可以通过*y*的一热编码来实现。你从一个与类别数量一样多的零向量开始（这里有两个）。然后设置一个条目为1。对于*y*
    = 0，你将第0个条目设置为1，这样你就有了向量(1, 0)，而对于*y* = 1，你有了向量(0, 1)。关于fcNN的架构，请参阅图2.8，以及相应的Keras代码，请参阅列表2.2。
- en: Listing 2.2 Definition of the network with one hidden layer
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.2 定义具有一个隐藏层的网络
- en: '[PRE1]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Definition of the hidden layer with eight neurons
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 具有八个神经元的隐藏层定义
- en: ❷ The output layer with two output neurons
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 具有两个输出神经元的输出层
- en: As you can see in figure 2.9, the network now yields a curved decision surface,
    and it’s better able to separate the two classes in the training data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如图2.9所示，网络现在产生一个弯曲的决策表面，并且它更好地能够将训练数据中的两个类别分开。
- en: '![](../Images/2-9.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-9.png)'
- en: Figure 2.9 An fcNN produces a curved decision boundary. The shading of the background
    in the 2D feature space shows the probability for a fake banknote predicted by
    an fcNN with one hidden layer that contains eight neurons and uses the features
    *x*[1] and *x*[2] as input. The right side overlays the training data, showing
    that the curved decision boundary better fits the boundary between the real and
    fake banknotes.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 全连接神经网络产生一个弯曲的决策边界。二维特征空间中背景的阴影显示了由包含八个神经元并使用特征 *x*[1] 和 *x*[2] 作为输入的全连接神经网络预测的假钞的概率。右侧叠加了训练数据，显示了弯曲的决策边界更好地符合真钞和假钞之间的边界。
- en: '| ![](../Images/computer-icon.png) | Hands-on time Become a member of the DL
    club by just adding more hidden layers in the banknote notebook at [http://mng.bz/lGd6](http://mng.bz/lGd6).
    It’s much easier than machine learning (see figure 2.10) |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| ![](../Images/computer-icon.png) | 实践时间：只需在[http://mng.bz/lGd6](http://mng.bz/lGd6)的钞票笔记本中添加更多隐藏层，即可成为深度学习俱乐部的一员。这比机器学习要简单得多（见图2.10）|'
- en: '![](../Images/2-10.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2-10.png)'
- en: Figure 2.10 A DL expert at work. Inspired by [http://mng.bz/VgJP](http://mng.bz/VgJP).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10 工作中的深度学习专家。灵感来源于[http://mng.bz/VgJP](http://mng.bz/VgJP)。
- en: 'But what’s going on when adding an additional layer? In principle, the same
    thing as we discussed for the first hidden layer. You can see the neuron values
    in the added hidden layer as a new feature representation of the input. But there’s
    one difference: the features in deeper layers aren’t directly constructed from
    the input but from the previous layer. For example, in the second hidden layer,
    the features are constructed from the features in the first hidden layer (see
    figure 2.12). This hierarchical construction of the features is often efficient
    because it allows you to learn from the first layer basic features that can be
    used as components in several more complex features of the next layer.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，在添加一个额外的层时发生了什么？原则上，与我们对第一个隐藏层讨论的相同。您可以将添加的隐藏层中的神经元值视为输入的新特征表示。但有一个区别：深层中的特征不是直接从输入构建的，而是从前一层构建的。例如，在第二个隐藏层中，特征是从第一个隐藏层的特征构建的（见图2.12）。这种特征的层次化构建通常很有效，因为它允许您从第一层学习基本特征，这些特征可以用作下一层几个更复杂特征的组成部分。
- en: By stacking many layers together, you allow the NN to construct hierarchical
    and complex features that get more and more abstract and task-specific when going
    from layer to layer. As the number of neurons per layer (and also the number of
    hidden layers) is part of the design, you need to decide if this number, for example,
    is based on the complexity of your problem and your experience, or if it’s what’s
    reported by other successful deep learners.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 通过堆叠许多层，您允许神经网络构建层次化和复杂的特征，这些特征在从一层到另一层的过程中变得越来越抽象和特定于任务。由于每层的神经元数量（以及隐藏层的数量）是设计的一部分，您需要决定这个数量是基于您问题的复杂性和您的经验，还是它是由其他成功的深度学习者报告的。
- en: The good news in DL is that you don’t need to predefine weights that determine
    how to construct the features in one layer from the features in the previous layer.
    The NN learns this during the training. You also don’t need to train each layer
    separately, but you usually train the NN as a whole, which is called end-to-end
    training. This has the advantage that changes in one layer automatically trigger
    adaptations in all other layers. In chapter 3, you’ll learn how this training
    process works.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，好消息是您不需要预先定义确定如何从前一层的特征构建当前层特征的权重。神经网络在训练过程中学习这一点。您也不需要单独训练每一层，但通常您会整体训练神经网络，这被称为端到端训练。这有一个优点，即某一层的改变会自动触发所有其他层的适应。在第3章中，您将了解这个训练过程是如何工作的。
- en: 2.1.3 Using a fully connected NN (fcNN) to classify images
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.3 使用全连接神经网络（fcNN）进行图像分类
- en: 'Let’s now use your new skills to build a larger network and see how it performs
    on the task of classifying handwritten digits. Different scientific disciplines
    have different model systems that benchmark their methods: molecular biologists
    use a worm called C. Elegance; people performing social network analysis use the
    Zachary Karate Club, and finally, people working with DL use the famous MNIST
    digit data set. This benchmark data set consists of 70,000 handwritten digits
    and is available from [http://mng .bz/xW8W](http://mng.bz/xW8W) . The images all
    have 28 × 28 pixels and are grayscaled with values between 0 and 255\. Figure
    2.11 displays the first four images of the data set.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用你新学的技能来构建一个更大的网络，并看看它在对手写数字进行分类的任务上的表现。不同的科学学科有不同的模型系统，用于衡量它们的方法：分子生物学家使用一种名为C.
    Elegance的线虫；进行社会网络分析的人使用Zachary Karate Club，最后，与深度学习相关的工作者使用著名的MNIST数字数据集。这个基准数据集包含70,000个手写数字，可以从[http://mng.bz/xW8W](http://mng.bz/xW8W)
    获取。所有图像都具有28 × 28像素，并且是灰度图像，像素值介于0到255之间。图2.11显示了数据集的前四幅图像。
- en: '![](../Images/2-11.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2-11.png)'
- en: Figure 2.11 The first four digits of the MNIST data set--the standard data set
    used for benchmarking an NN for image classification.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11 MNIST数据集的前四个数字--用于基准测试神经网络进行图像分类的标准数据集。
- en: 'This data set is well known in the machine learning community. If you develop
    a novel algorithm for image classification, you usually also report its performance
    on the MNIST data set. The MNIST images are grayscale images, and the gray value
    of each pixel is defined by an integer in the range from 0 to 255\. For a fair
    comparison, there’s a standard split of the data: 60,000 of the images are used
    for training the network and 10,000 are used for testing. In Keras, you can download
    the whole data set with a single line (see listing 2.3). You can also download
    the companion MNIST notebook for this section (on which you can work later) at
    [http://mng.bz/AAJz](http://mng.bz/AAJz) .'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集在机器学习社区中广为人知。如果你开发了一种新的图像分类算法，你通常也会报告它在MNIST数据集上的性能。MNIST图像是灰度图像，每个像素的灰度值由0到255范围内的整数定义。为了进行公平的比较，数据有一个标准的分割：60,000个图像用于训练网络，10,000个用于测试。在Keras中，你可以用一行代码下载整个数据集（见列表2.3）。你还可以下载本节的相关MNIST笔记本（你可以在以后工作），网址为[http://mng.bz/AAJz](http://mng.bz/AAJz)
    。
- en: Simple neural networks can’t deal with 2D images but need a 1D input vector.
    Hence, instead of feeding the 28 × 28 images directly, you first flatten the image
    into a vector of size 28 · 28 = 784\. The output should indicate whether the input
    image is one of the digits 0-9\. More precisely, you want to model the probability
    that the network thinks that a given input image is a certain digit. For this,
    the output layer has ten neurons (one for each digit). You again use the activation
    function `softmax` to ensure that the computed outputs can be interpreted as probabilities
    (numbers between 0 and 1), adding up to 1\. For this example, we also include
    hidden layers. Figure 2.12 shows a simplified version of the network and the definition
    of the corresponding model in Keras is shown in listing 2.4.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的神经网络无法处理2D图像，但需要一个1D输入向量。因此，你首先将28 × 28的图像展平成一个大小为28 · 28 = 784的向量。输出应该指示输入图像是否是0到9中的数字之一。更精确地说，你希望模型表示网络认为给定输入图像是某个特定数字的概率。为此，输出层有十个神经元（每个数字一个）。你再次使用激活函数`softmax`来确保计算出的输出可以被解释为概率（介于0到1之间的数字），总和为1。在这个例子中，我们还包括了隐藏层。图2.12显示了网络的简化版本以及Keras中相应模型的定义，如列表2.4所示。
- en: '![](../Images/2-12.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2-12.png)'
- en: Figure 2.12 An fcNN with two hidden layers. In the MNIST example, the input
    layer has 784 values for the 28 × 28 pixels and the output layer has 10 nodes
    for the 10 classes.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12 一个具有两个隐藏层的全连接神经网络。在MNIST示例中，输入层有784个值对应于28 × 28像素，输出层有10个节点对应于10个类别。
- en: Listing 2.3 Loading the MNIST data
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.3 加载MNIST数据
- en: '[PRE2]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Loads the MNIST training (60,000 images) and test set
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载MNIST训练集（60,000个图像）和测试集
- en: ❷ Uses 50,000 images for training, dividing by 255 so that the pixel values
    are in the range 0 to 1
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用50,000个图像进行训练，除以255，使像素值在0到1的范围内
- en: ❸ Stores the labels given as integers from 0 to 9 as one-hot encoded vectors
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将作为整数从0到9给出的标签存储为one-hot编码向量
- en: ❹ We do the same with the validation set.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 我们对验证集也做同样的处理。
- en: Note We don’t use the test set for this listing.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们在这个列表中不使用测试集。
- en: Also, where we store the labels for the `y_train` for the network, we transform
    those to categorical data of length 10 to match the output. A 1 is translated
    as (0,1,0,0,0,0,0,0,0,0). This is called one-hot encoding. In the next listing,
    you can see a small fcNN using the one-hot encoded labels `Y_train.`
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在我们存储网络 `y_train` 标签的地方，我们将这些转换为长度为 10 的分类数据，以匹配输出。1 被转换为 (0,1,0,0,0,0,0,0,0,0)。这被称为
    one-hot 编码。在下一个列表中，你可以看到一个小 fcNN 使用 one-hot 编码的标签 `Y_train.`。
- en: Listing 2.4 Definition of an fcNN for the MNIST data
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 2.4 MNIST 数据的 fcNN 定义
- en: '[PRE3]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ The first hidden layer with 100 neurons, connected to the input size 28 ×
    28 pixels
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 第一个隐藏层有 100 个神经元，连接到输入大小 28 × 28 像素
- en: ❷ A second dense layer with 50 neurons
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 第二个密集层有 50 个神经元
- en: ❸ The third layer connecting to the 10 output neurons
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 第三层连接到 10 个输出神经元
- en: ❹ Uses a different optimizer than the SGD, which is faster (see chapter 3)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用比 SGD 更快的不同优化器（见第 3 章）
- en: ❺ Tracks the accuracy (fraction of correctly classified training and validation
    examples) during the training
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 跟踪训练过程中的准确率（正确分类的训练和验证示例的分数）
- en: '| ![](../Images/computer-icon.png) | Hands-on timeNow open the MNIST notebook
    [http://mng.bz/AAJz](http://mng.bz/AAJz) , run it, and try to understand the code.
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| ![图片](../Images/computer-icon.png) | 实践时间现在打开 MNIST 笔记本 [http://mng.bz/AAJz](http://mng.bz/AAJz)
    ，运行它，并尝试理解代码。'
- en: When looking at the course of the loss curves over the number of iterations
    (figure 2.13), you can observe that the model fits the data. The performance of
    the trained fcNN on the validation set is around 97%, which isn’t bad, but the
    state of the art is about 99%.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 当查看损失曲线随迭代次数的变化过程（见图 2.13）时，你可以观察到模型拟合了数据。训练好的 fcNN 在验证集上的性能大约为 97%，这并不坏，但最先进的技术大约为
    99%。
- en: '![](../Images/2-13.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-13.png)'
- en: Figure 2.13 The increase of the accuracy training (top) and the decrease of
    the loss (bottom) during the different training steps
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13 在不同的训练步骤中，准确率训练（顶部）和损失（底部）的增加
- en: 'Play the DL game and stack more layers. Another trick that’s often used is
    to replace the sigmoid activation function in the hidden layers with something
    easier: ReLU. ReLU stands for Rectified Linear Unit and is quite a mouthful for
    what it really does. It simply clamps values smaller than zero to zero and leaves
    values larger than zero as they are (see figure 2.14). It is essential to use
    non-linear activation functions in hidden layers, because when using a linear
    activation function, you can replace a stack of layers by only one layer. (This
    is because going through a linear layer corresponds to a matrix multiplication,
    and you can replace a series of matrix multiplications by one matrix multiplication.)
    To change the activation in Keras, simply exchange `sigmoid` with `relu` . If
    you like, you can change the activation function in the notebook [http://mng.bz/AAJz](http://mng.bz/AAJz)
    .'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 玩深度学习游戏并堆叠更多层。常用的另一个技巧是将隐藏层中的 sigmoid 激活函数替换为更简单的：ReLU。ReLU 代表修正线性单元，对于它所做的事情来说，这个名字相当长。它只是将小于零的值固定为零，而将大于零的值保持不变（见图
    2.14）。在隐藏层中使用非线性激活函数是至关重要的，因为当使用线性激活函数时，你可以用一个层来替换层堆叠。这是因为通过一个线性层相当于矩阵乘法，你可以用一个矩阵乘法来替换一系列矩阵乘法。要在
    Keras 中更改激活函数，只需将 `sigmoid` 替换为 `relu`。如果你愿意，你可以在笔记本 [http://mng.bz/AAJz](http://mng.bz/AAJz)
    中更改激活函数。
- en: '![](../Images/2-14.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-14.png)'
- en: Figure 2.14 A comparison between the ReLU and the sigmoid activation functions
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14 ReLU 和 sigmoid 激活函数的比较
- en: Let’s do a small experiment and investigate what happens if you shuffle the
    pixel values before you feed those into the network. Figure 2.15 shows the same
    digits as in figure 2.11, but this time randomly shuffled.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一个小的实验，研究在你将这些像素值输入网络之前对像素值进行洗牌会发生什么。图 2.15 显示了与图 2.11 相同的数字，但这次是随机洗牌的。
- en: '![](../Images/2-15.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-15.png)'
- en: Figure 2.15 The same digits (5, 0, 4, 1) as in figure 2.11 after shuffling the
    pixels
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.15 在图 2.11 中相同的数字（5, 0, 4, 1）在像素洗牌后的样子
- en: For each image, the pixels have been shuffled the same way. You’d have a hard
    time telling the right digit even after seeing thousands of training examples.
    Can a network still learn to recognize the digits?
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每张图像，像素都按照相同的方式进行洗牌。即使看过成千上万的训练示例，你也很难说出正确的数字。网络还能学会识别这些数字吗？
- en: '| ![](../Images/computer-icon.png) | Hands-on time Try it out and play with
    the code in the MNIST notebook [http://mng.bz/2XN0.](http://mng.bz/2XN0) What
    do you observe? |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| ![计算机图标](../Images/computer-icon.png) | 实践时间 尝试在MNIST笔记本中运行代码并与之互动 [http://mng.bz/2XN0](http://mng.bz/2XN0)。你观察到了什么？
    |'
- en: NOTE Only follow the notebook until you reach the section “CNN as a classification
    model for MNIST data.” We’ll look at CNNs later and then revisit the notebook.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：只跟随笔记本直到你达到“CNN作为MNIST数据的分类模型”这一部分。我们稍后会研究CNN，然后再回到笔记本。
- en: You’ll probably reach the same accuracy (within statistical fluctuations) as
    with the original images. This might come as a surprise at first. But looking
    at the network architecture of an fcNN, the order of the input doesn’t matter
    whatsoever. Because the network has no concept of nearby pixels, there’s nothing
    like a neighborhood. People, therefore, also call fcNN permutation invariant NN
    because its performance doesn’t depend on whether the data is permuted (shuffle*D*).
    However, real image data isn’t permutation invariant, and nearby pixels tend to
    have similar values. If you shuffle images, people will have a problem recognizing
    those. Moreover, two images showing the same digit don’t need to show the same
    pixel values. You can move (translate) the image a bit, and it still shows the
    same object.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会达到与原始图像相同的准确度（在统计波动范围内）。一开始这可能会让人感到惊讶。但看看全连接神经网络的网络架构，输入的顺序根本不重要。因为网络没有邻近像素的概念，所以没有类似邻域的东西。因此，人们也把全连接神经网络称为排列不变神经网络，因为其性能不依赖于数据是否被排列（打乱*D*）。然而，真实的图像数据并不是排列不变的，邻近像素往往具有相似值。如果你打乱图像，人们将难以识别它们。此外，显示相同数字的两个图像不需要显示相同的像素值。你可以稍微移动（平移）图像，它仍然显示相同的对象。
- en: The fact that humans are great in visual tasks but have problems with shuffled
    images indicates that the evolution has found ways to take advantage of the special
    properties of image data. While fcNNs are good for spreadsheet-like data where
    the order of the columns doesn’t matter, there are better architectures when the
    order or the spatial alignment does matter, like convolutional NNs. In principle,
    fcNN can be used for images, but you need many layers and huge training data sets
    that allow the network to learn that nearby pixels tend to have the same values
    and that images are translation invariant.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 人类在视觉任务上表现出色，但在处理打乱顺序的图像时却存在问题，这表明进化已经找到了利用图像数据特殊属性的方法。虽然全连接神经网络（fcNNs）在处理类似电子表格的数据时表现良好，其中列的顺序并不重要，但当顺序或空间对齐很重要时，如卷积神经网络（convolutional
    NNs），有更好的架构。原则上，全连接神经网络可以用于图像处理，但你需要很多层和巨大的训练数据集，以便网络学习到邻近像素倾向于具有相同值，以及图像是平移不变的。
- en: 2.2 Convolutional NNs for image-like data
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 用于图像数据卷积神经网络
- en: Fully connected NNs with even a single hidden layer can represent any function,
    but quickly get too big and contain so many parameters that you usually don’t
    have enough data to fit them. Much of the progress in DL has been around creating
    different architectures that more efficiently exploit the structure of the data.
    For image data, one such architecture is convolutional NNs.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 即使只有一个隐藏层的全连接神经网络也能表示任何函数，但很快就会变得太大，包含太多的参数，通常没有足够的数据来拟合它们。深度学习（DL）的许多进展都围绕着创建不同的架构，这些架构更有效地利用数据的结构。对于图像数据，这种架构之一就是卷积神经网络。
- en: For the example of an fcNN with only one hidden layer (see figure 2.8), we discussed
    that you can view the number of neurons in the hidden layer as the number of new
    features that are constructed from the input. This implies that you need a large
    number of neurons in the hidden layer if you want to tackle a complex problem.
    But the more neurons you have in the hidden layer, the more parameters you need
    to learn, and the more training data you need. Stacking layers lets the model
    learn task-specific features in a hierarchical manner. This approach needs fewer
    parameters than an fcNN to construct complex features and, therefore, is less
    data hungry.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 对于只有一个隐藏层的全连接神经网络示例（见图2.8），我们讨论了可以将隐藏层中的神经元数量视为从输入构建的新特征数量。这意味着如果你想解决复杂问题，你需要隐藏层中有大量的神经元。但隐藏层中的神经元越多，你需要学习的参数就越多，你需要更多的训练数据。堆叠层让模型以层次化的方式学习特定任务的特征。这种方法比全连接神经网络构建复杂特征所需的参数更少，因此对数据的需求也更低。
- en: You learned in the last section that you get more out of an fcNN if you add
    more hidden layers. Going deep is a great trick to enhance the performance of
    NNs, giving DL its name. You also learned that an fcNN ignores the neighboring
    structure of pixels in an image. This suggests that there might be a better NN
    architecture to analyze image data. And indeed, the success of DL in the field
    of computer vision was not possible without some additional architectural tricks
    that exploit the knowledge about the local structure of image data.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 你在上一个章节中学到，如果你为全连接神经网络（fcNN）添加更多的隐藏层，你就能得到更多。深入挖掘是增强神经网络性能的一个很好的技巧，这也是深度学习之所以得名的原因。你还了解到，全连接神经网络忽略了图像中像素的邻近结构。这表明可能存在一个更好的神经网络架构来分析图像数据。实际上，深度学习在计算机视觉领域的成功也离不开一些额外的架构技巧，这些技巧利用了关于图像数据局部结构的知识。
- en: 'The most important ingredient to tailor an NN for locally correlated data such
    as image data is the so-called convolutional layers. In this section, we explain
    how a convolutional layer works. NNs that consist mainly of convolutional layers
    are called convolutional neural networks (CNNs) and have an extremely broad range
    of applications including:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为图像数据等局部相关数据定制神经网络的最重要组成部分是所谓的卷积层。在本节中，我们将解释卷积层是如何工作的。主要由卷积层组成的神经网络被称为卷积神经网络（CNN），并且具有极其广泛的应用范围，包括：
- en: Image classification, such as discriminating a truck from a road sign
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像分类，例如区分卡车和路标
- en: Video data prediction, such as generating future radar images for weather forecasting
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频数据预测，例如生成天气预报的未来雷达图像
- en: Quality control in production lines based on image or video data
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于图像或视频数据的生产线质量监控
- en: Classification and detection of different tumors in histopathological slices
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在组织病理切片中对不同肿瘤的分类和检测
- en: Segmentation of different objects in an image
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像中不同对象的分割
- en: 2.2.1 Main ideas in a CNN architecture
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.1 CNN架构中的主要思想
- en: Let’s focus on image data and discuss a specialized NN architecture that takes
    into account the highly local structure within an image (see figure 2.16). In
    2012, Alex Krizhevsky used this architecture in the internationally renowned ImageNet
    competition, which brought with it a breakthrough for DL into the field of computer
    vision.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们专注于图像数据，并讨论一种专门的网络架构，该架构考虑了图像内部的高度局部结构（见图2.16）。在2012年，Alex Krizhevsky在国际知名的ImageNet竞赛中使用了这种架构，这为深度学习进入计算机视觉领域带来了突破。
- en: '![](../Images/2-16.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-16.png)'
- en: Figure 2.16 An image can be broken into local patterns such as edges, textures,
    and so on.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.16：图像可以被分解成局部模式，如边缘、纹理等。
- en: 'We’ll now dive into the architecture of CNNs and discuss how they got their
    name. Let’s look at the main idea of a CNN: instead of connecting all neurons
    between two successive layers, only a small patch of neighboring pixels connects
    to a neuron in the next layer (see figure 2.17). With this simple trick, the network
    architecture has the local structure of images built in. This trick also reduces
    the number of weights in the NN. If you only consider small patches of, for example,
    3 × 3 pixels as a local pattern (see figure 2.18) that’s connected to a neuron
    in the next layer, then you have only 3 ⋅ 3+1=10 weights to learn for the weighted
    sum *z* = *x*[1] ⋅ *w*[1] - *x*[2] ∙ *w*[2] + ⋯ + *x*[9] ∙ *w*[9] + *b* , which
    is the input to the next neuron.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将深入探讨卷积神经网络（CNN）的架构，并讨论它们是如何获得这个名字的。让我们看看CNN的主要思想：不是连接两个连续层之间的所有神经元，而只是相邻像素的小块区域连接到下一层的神经元（见图2.17）。通过这个简单的技巧，网络架构内置了图像的局部结构。这个技巧也减少了神经网络中的权重数量。如果你只考虑例如3
    × 3像素的小块区域作为连接到下一层神经元的局部模式（见图2.18），那么你只需要学习10个权重，即加权求和*z* = *x*[1] ⋅ *w*[1] -
    *x*[2] ∙ *w*[2] + ⋯ + *x*[9] ∙ *w*[9] + *b*，这是下一神经元的输入。
- en: '![](../Images/2-17.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-17.png)'
- en: Figure 2.17 Connectivity between the input image and a neuron in the first hidden
    layer for an fcNN (on the left) or for a CNN (on the right). This representation
    ignores the bias term.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.17：全连接神经网络（fcNN）（左侧）或卷积神经网络（CNN）（右侧）的输入图像与第一隐藏层神经元之间的连接。这种表示忽略了偏差项。
- en: If you have experience with classical image analysis, then you know that this
    idea isn’t new at all. What you’re doing here is called convolution.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有过经典图像分析的经验，那么你知道这个想法根本不新鲜。你在这里做的是所谓的卷积。
- en: '![](../Images/2-18.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-18.png)'
- en: Figure 2.18 Convolution of a 6 × 6 grayscale image with a 3 × 3 kernel and a
    stride of 1 without padding yields as output a 4 × 4 feature map. The kernel is
    applied at all 16 possible positions to determine the 16 values of the activation
    map. Two possible kernel positions are marked in the input with thick solid and
    dashed borders. The respective positions of the resulting pixels in the activation
    map are also marked with thick solid and dashed borders. The CNN computes the
    resulting values by multiplying the pixel values with the overlaid kernel values
    and adding all terms (bias is assumed to be 0).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.18展示了将一个6×6的灰度图像与一个3×3的核进行卷积，步长为1且不进行填充时，得到的输出是一个4×4的特征图。核在所有16个可能的位置上应用，以确定激活图的16个值。输入中用粗实线和虚线标记了两个可能的核位置。激活图中相应像素的位置也用粗实线和虚线标记。CNN通过将像素值与叠加的核值相乘并添加所有项（假设偏差为0）来计算结果值。
- en: Have a look at figure 2.18, where you see a small image with 6 × 6 pixels and
    a 3 × 3 kernel[1](#pgfId-1022849) with predefined weights. You can slide the kernel
    over the image by taking steps of 1 pixel (called `stride=1`). At each position,
    you compute the element-wise multiplication of the image pixel and the overlaid
    kernel weights. You then add these values to get the weighted sum *z = x*[1] ∙
    *w*[1] *+x*[2] ∙ *w*[2] *+* ⋯ *+x**[k]* ∙ *w**[k]* *+ b* , where k is the number
    of pixels connected to each neuron and *b* is a bias term. The computed value
    *z* is a single element of the output matrix. After shifting the kernel to the
    next position over the image, you can compute the next output value *z* and so
    on. We call the resulting output an activation map or feature map.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下图2.18，其中你可以看到一个6×6像素的小图像和一个3×3的核[1](#pgfId-1022849)，核具有预定义的权重。你可以通过每次移动1个像素（称为`stride=1`）来在图像上滑动核。在每个位置，你计算图像像素和叠加核权重的逐元素乘积。然后，将这些值相加得到加权总和
    *z = x*[1] ∙ *w*[1] *+x*[2] ∙ *w*[2] *+* ⋯ *+x**[k]* ∙ *w**[k]* *+ b* ，其中k是连接到每个神经元的像素数量，*b*
    是偏差项。计算出的值 *z* 是输出矩阵的单个元素。将核移到图像上的下一个位置后，你可以计算下一个输出值 *z*，依此类推。我们将这种结果输出称为激活图或特征图。
- en: In the example in figure 2.18, we start with a 6 × 6 image, convolve it with
    a 3 × 3 kernel, and receive a 4 × 4 activation map. Sliding a kernel over an image
    and requiring that the whole kernel is at each position completely within the
    image yields an activation map with reduced dimensions. For example, if you have
    a 3 × 3 kernel on all sides, one pixel is knocked off in the resulting activation
    map; in case of a 5 × 5 kernel, 2 pixels would be knocked off. If you want to
    have the same dimension after applying the convolution, you can use a zero padding
    of the input image (called `padding='same'` , the argument of the convolution
    layer in listing 2.5; if you don’t want zero padding, the argument would be `padding='valid'`).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在图2.18的例子中，我们从一个6×6的图像开始，将其与一个3×3的核进行卷积，得到一个4×4的激活图。在图像上滑动核并要求整个核在每个位置完全位于图像内，可以得到一个尺寸减小的激活图。例如，如果你在所有边都有一个3×3的核，结果激活图中会去掉一个像素；如果是5×5的核，则会去掉两个像素。如果你希望在应用卷积后保持相同的尺寸，你可以使用输入图像的零填充（称为`padding='same'`，列表2.5中卷积层的参数；如果你不想使用零填充，参数将是`padding='valid'`）。
- en: In CNNs, the kernel weights are learned (see chapter 3). Because you use the
    same kernel at each position, you have shared weights, and in our example, you
    only need to learn 3 ∙ 3 = 9 weights to compute a whole activation map. Usually
    a bias term is also included in case there are 10 weights to learn. To interactively
    apply different kernels to a real image, see [http://setosa.io/ev/image-kernels/](http://setosa.io/ev/image-kernels/)
    .
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在CNN中，核权重是通过学习得到的（参见第3章）。因为你在每个位置使用相同的核，所以有共享权重，在我们的例子中，你只需要学习3×3=9个权重来计算整个激活图。通常，如果需要学习10个权重，也会包括一个偏差项。要交互式地将不同的核应用于真实图像，请参阅[http://setosa.io/ev/image-kernels/](http://setosa.io/ev/image-kernels/)。
- en: What can the values in an activation map tell you? If you apply a kernel to
    all possible positions within the image, you get only a high signal where the
    underlying image shows the pattern of the kernel. Assembling the outputs to an
    image yields a map that shows at which positions in the image the kernel pattern
    appears. This is the reason why the resulting image is often called a feature
    map or an activation map.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 激活图中的值能告诉你什么？如果你将核应用于图像中所有可能的位置，你只会得到高信号，在这些位置下，底层图像显示了核的模式。将输出组装成图像，可以得到一个映射，显示了核模式出现在图像中的哪些位置。这就是为什么结果图像通常被称为特征图或激活图的原因。
- en: Each neuron in the same activation map has the same number of input connections,
    and the connecting weights are also the same. (you’ll soon see that real applications
    use more than one kernel.) Each neuron is connected to a different patch of the
    input (previous layer), meaning that each neuron within the same feature map looks
    for the same pattern but at different positions of the input. Figure 2.19 demonstrates
    this concept for an abstract image that consists of rectangular areas where a
    kernel with a vertical edge pattern is applied. We use this technique in image
    manipulation, for example, to enhance the edges of an image or to blur it. Visit
    [http://setosa.io/ ev/image-kernels/](http://setosa.io/ev/image-kernels/) to get
    a feel for the effect of different kernels on more complex images.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 同一激活图中的每个神经元具有相同数量的输入连接，连接的权重也相同。（你很快就会看到实际应用中使用不止一个核。）每个神经元连接到输入（前一层）的不同区域，这意味着同一特征图内的每个神经元都在寻找相同的模式，但位置不同。图2.19展示了这一概念，该图像由矩形区域组成，在这些区域上应用了具有垂直边缘模式的核。我们使用这种技术在图像处理中使用，例如，增强图像的边缘或使其模糊。访问[http://setosa.io/ev/image-kernels/](http://setosa.io/ev/image-kernels/)以了解不同核对更复杂图像的影响。
- en: In figure 2.19, you see the vertical-edge kernel (going from bright to dark)
    in three positions of the image. At an image position with a vertical edge that
    goes from bright to dark, you get a high value (shown as dark gray pixels in the
    activation map). At an image position with a vertical edge that goes from dark
    to bright, you get a low value (shown as light gray pixels in the activation map).
    At positions where there’s no vertical edge in the image, the resulting values
    are neither high nor low (shown as mid-gray pixels in the activation map). In
    case of the displayed filter where the weights add up to one, the values in the
    activation maps are zero if the input is an image patch with a constant gray value.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在图2.19中，你可以看到垂直边缘核（从亮到暗）在图像中的三个位置。在图像位置中，垂直边缘从亮到暗，你会得到一个高值（在激活图中显示为深灰色像素）。在图像位置中，垂直边缘从暗到亮，你会得到一个低值（在激活图中显示为浅灰色像素）。在图像中没有垂直边缘的位置，结果值既不高也不低（在激活图中显示为中灰色像素）。在显示的滤波器中，如果权重总和为1，则如果输入是具有恒定灰度值的图像块，激活图中的值将为零。
- en: 2.2.2 A minimal CNN for edge lovers
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.2 最小CNN，适合边缘爱好者
- en: Let’s imagine an art lover who gets excited if an image contains vertical edges.
    Your task is to predict for a set of striped images if the art lover will like
    those. Some of the images in the set have horizontal edges and some vertical edges.
    To identify the images with vertical stripes, a vertical-edge detection model
    would be great. For this purpose, you might want to do something similar to that
    depicted in figure 2.19 and perform a convolution of a predefined vertical-edge
    filter, using the maximal value in the resulting feature map as a score that indicates
    if the art lover will like the image.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象一个对包含垂直边缘的图像感到兴奋的艺术爱好者。你的任务是预测一组条纹图像，看艺术爱好者是否会喜欢这些图像。该集合中的一些图像有水平边缘，而另一些有垂直边缘。为了识别具有垂直条纹的图像，一个垂直边缘检测模型将非常出色。为此目的，你可能想要做类似于图2.19中描述的事情，并使用预定义的垂直边缘滤波器进行卷积，使用结果特征图中的最大值作为分数，表示艺术爱好者是否会喜欢该图像。
- en: '![](../Images/2-19.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-19.png)'
- en: Figure 2.19 Convolution of a 3 × 3 kernel with a weight pattern that resembles
    a vertical edge (upper left panel) with an image consisting of squared areas (lower
    left and right panel) results in a feature map that highlights the positions of
    vertical edges in the input image (upper right panel). In the left panel, the
    numbers indicate the weighted values for the kernel (upper left) and the pixel
    values for the image (lower left).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.19展示了将一个3×3核与类似垂直边缘的权重模式（左上面板）与由平方区域组成的图像（左下和右面板）进行卷积的结果，这会产生一个特征图，突出显示输入图像中垂直边缘的位置（右上面板）。在左面板中，数字表示核的加权值（左上）和图像的像素值（左下）。
- en: Using a predefined kernel for convolution is often done in traditional image
    analysis when the feature of interest is known and can be described as a local
    pattern. In such a situation, it’d be rather silly not to use this traditional
    image analysis approach. But let’s pretend you don’t know that the art lover likes
    vertical edges, and you only have a list of images that they like and dislike.
    You want to learn the values for the weights within the kernel that you can use
    for convolution. Figure 2.20 shows the corresponding network architecture, where
    the size of the kernel is 5 × 5\. The resulting hidden layer is a feature map.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的图像分析中，当感兴趣的特性已知并且可以描述为局部模式时，通常使用预定义的核进行卷积。在这种情况下，不使用这种传统的图像分析方法就显得有些愚蠢。但让我们假设你不知道艺术爱好者喜欢垂直边缘，而你只有他们喜欢和不喜欢的一组图像列表。你想要学习核中可用于卷积的权重值。图2.20显示了相应的网络架构，其中核的大小为5
    × 5。结果隐藏层是一个特征图。
- en: '![](../Images/2-20.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![2-20.png]'
- en: Figure 2.20 A CNN with only one hidden layer consisting of one feature map.
    As a pooled value, you take a maximum of all values within the feature map. You
    add a dense layer to determine the probability for two possible class labels in
    the output.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.20 仅由一个特征图组成，包含一个隐藏层的CNN。作为一个池化值，你取特征图内所有值的最大值。你添加一个密集层来确定输出中两个可能的类别标签的概率。
- en: 'To check if this feature map indicates that the image contains the kernel pattern,
    you take the maximum value of the feature map. From this value, you want to predict
    the probability that the art lover likes the image. You already saw how to do
    that: you add a single, fully connected layer with two output nodes and use softmax
    activation to ensure that the two output values can be taken as probabilities
    for the two classes (art lover likes the image; art lover doesn’t like the image).
    This adds up to 1\. This small CNN network (the feature map in the first hidden
    layer) results from the convolution of the image with a kernel. The classification
    is done in the fully connected part shown on the right side in figure 2.20\. This
    architecture is probably one of the smallest possible CNNs one can think of. To
    model image data with TensorFlow and Keras, you need to create 4D tensors with
    the form:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查这个特征图是否表明图像包含核模式，你取特征图的最大值。从这个值，你想要预测艺术爱好者喜欢图像的概率。你已经看到了如何做到这一点：你添加一个单层的全连接层，具有两个输出节点，并使用softmax激活来确保两个输出值可以作为两个类别的概率（艺术爱好者喜欢图像；艺术爱好者不喜欢图像）。这加起来为1。这个小CNN网络（第一隐藏层中的特征图）是通过图像与核的卷积得到的。分类是在图2.20右侧显示的全连接部分完成的。这种架构可能是人们能想到的最小的CNN之一。要使用TensorFlow和Keras建模图像数据，你需要创建形式为4D的张量：
- en: '[PRE4]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The batch dimension corresponds to the number of images in one batch. The next
    two elements define the height and width of the image in units of pixels. The
    last dimension defines the number of channels. (A typical RGB color image has
    3 channels. This means that a batch of 128 color images, each having 256 rows
    and columns, could be stored in a tensor of shape (128, 256, 256, 3.)
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 批量维度对应于一个批次中的图像数量。接下来的两个元素定义了图像的高度和宽度，单位为像素。最后一个维度定义了通道数。（一个典型的RGB彩色图像有3个通道。这意味着一个包含128个彩色图像的批次，每个图像有256行和256列，可以存储在一个形状为（128,
    256, 256, 3）的张量中。）
- en: You can set up, train, and evaluate the CNN model with a few lines of Keras
    code (see listing 2.5). The only thing you need is a data set of images with horizontal
    or vertical stripes and a corresponding class label. This can be easily simulated.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用几行Keras代码设置、训练和评估CNN模型（见列表2.5）。你需要的是包含水平或垂直条纹的图像数据集及其相应的类别标签。这可以很容易地模拟。
- en: '| ![](../Images/computer-icon.png) | Hands-on time Open the edge lovers’ notebook
    at [http://mng.bz/1zEj](http://mng.bz/1zEj) and follow the instructions there
    to simulate the image data and fit the model. Check out which kernel weights are
    learned and if these form a vertical edge. If you can’t reproduce the result,
    don’t worry; just do the training again until you get the result. Investigate
    the impact of the activation function and the pooling method. |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| ![计算机图标](../Images/computer-icon.png) | 实践时间 打开边缘爱好者笔记本，访问[http://mng.bz/1zEj](http://mng.bz/1zEj)，并遵循那里的说明来模拟图像数据和拟合模型。检查哪些核权重被学习，以及这些是否形成垂直边缘。如果你无法重现结果，不要担心；只需重新进行训练，直到你得到结果。研究激活函数和池化方法的影响。|'
- en: '[PRE5]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Uses a convolutional layer with one kernel of the size 5 × 5 with the same
    padding
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用一个大小为5 × 5的核，具有相同填充的卷积层
- en: ❷ Adds a linear activation function (passes all values through)
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加线性激活函数（传递所有值）
- en: ❸ The MaxPooling layer extracts the maximal value of the feature map.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ MaxPooling层提取特征图的最大值。
- en: ❹ Flattens the output of the previous layer to make it a vector
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将前一层输出展平成一个向量
- en: ❺ A dense layer with two neurons predicts the probabilities of two labels.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 一个包含两个神经元的密集层预测两个标签的概率。
- en: ❻ Adds a softmax activation function to compute the probability for the two
    classes
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 添加softmax激活函数来计算两个类别的概率
- en: NOTE In the listing, using a convolutional layer with `padding='same'` means
    that the output feature map has the same size as the input image.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在列表中，使用`padding='same'`的卷积层意味着输出特征图的大小与输入图像相同。
- en: In your experiments with the edge lovers’ notebook at [http://mng.bz/1zEj](http://mng.bz/1zEj)
    , you’ve probably seen that a vertical edge kernel isn’t always learned; sometimes
    a horizontal edge kernel is learned instead. This is perfectly fine because the
    data set consists of images with either horizontal or vertical edges, and the
    task is only to discriminate between horizontal and vertical edges. Finding no
    horizontal edges indicates that the image contains only vertical edges.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在你使用边缘爱好者笔记本进行实验的[http://mng.bz/1zEj](http://mng.bz/1zEj)时，你可能已经注意到，垂直边缘核并不总是被学习到；有时会学习到水平边缘核。这是完全可以接受的，因为数据集由具有水平或垂直边缘的图像组成，任务只是区分水平和垂直边缘。没有找到水平边缘表明图像只包含垂直边缘。
- en: In this edge lovers’ example, it probably makes no difference if you use a predefined
    kernel or learn the weights of the kernel. But in a more realistic application,
    the best discriminating pattern is sometimes hard to predefine, and learning the
    optimal kernel weights is a great advantage of CNNs. In chapter 3, you’ll learn
    how the weights of a model are trained.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个边缘爱好者例子中，使用预定义的核或学习核的权重可能没有太大区别。但在更现实的应用中，最佳区分模式有时很难预先定义，而学习最优核权重是CNN的一个巨大优势。在第3章中，你将学习如何训练模型权重。
- en: 2.2.3 Biological inspiration for a CNN architecture
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.3 CNN架构的生物灵感
- en: The edge lovers’ example was only a toy, and you might think that there’s certainly
    no edge-loving neuron in a real brain. The opposite is true! The so-called visual
    cortex in the brains of humans and animals, indeed, have such edge-loving neurons.
    Two biologists, Hubel and Wiesel, received the Nobel prize in Physiology or Medicine
    for discovering this in 1981\. The way they found this is quite interesting. And,
    as is often in research, there is a great deal of luck involved.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘爱好者这个例子只是一个玩具，你可能会认为在真实的大脑中肯定没有喜欢边缘的神经元。相反，确实如此！人类和动物大脑中的所谓视觉皮层确实有喜欢边缘的神经元。两位生物学家Hubel和Wiesel因在1981年发现这一点而获得了诺贝尔生理学或医学奖。他们发现这一点的过程非常有趣。而且，正如研究中的常见情况一样，其中涉及了很多运气。
- en: In the late 1950s, Hubel and Wiesel wanted to investigate the correlation of
    the neuronal activity due to stimuli in the visual cortex of a cat. For this purpose,
    they anesthetized a cat and projected some images on a screen in front of it.
    They picked a single neuron to measure the electrical signal (see figure 2.21).
    The experiment, however, seemed not to work because they couldn’t observe the
    neuron firing while presenting different images to the cat. They changed the slides
    in the projector to those of an increasingly higher frequency. Finally, they shook
    the projector because a slide got stuck and then the neuron started to fire. In
    this manner, they discovered that neurons in different positions in the visual
    cortex are activated if edges with different orientations slide over the retina
    of the cat’s eye.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪50年代末，Hubel和Wiesel想要研究猫视觉皮层中由于刺激引起的神经元活动的相关性。为此，他们对猫进行了麻醉，并在它面前屏幕上投影了一些图像。他们选择了一个神经元来测量电信号（见图2.21）。然而，实验似乎没有成功，因为他们无法在向猫展示不同图像时观察到神经元放电。他们更换了投影仪中的幻灯片，换成了频率越来越高的幻灯片。最后，由于幻灯片卡住了，他们摇晃了投影仪，神经元开始放电。通过这种方式，他们发现视觉皮层不同位置的神经元在边缘以不同方向滑过猫眼视网膜时会被激活。
- en: '![](../Images/2-21.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2-21.png)'
- en: Figure 2.21 Setup of the experiment of Hubel and Wiesel in which they discovered
    neurons in the visual cortex that responded when they showed moving edges to a
    cat.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.21展示了Hubel和Wiesel的实验设置，他们发现了在猫的视觉皮层中，当向猫展示移动边缘时，会响应的神经元。
- en: Brain research continued to develop, and now it’s widely known that in the area
    of the brain where Hubel and Wiesel did their experiments (called the V1 region),
    all neurons respond to rather simple forms of stimuli on different areas of the
    retina. This isn’t only true for cats but also for other animals and humans. It’s
    also known that neurons in other regions of the brain (called V2, V4, and IT)
    respond to increasingly complex visual stimuli like, for example, a whole face
    (see figure 2.22). Research shows that a neuron’s signal is transmitted from region
    to region. Also, only parts of the neurons in one region of the brain connect
    to the neurons in the next region. Via the connections of the neurons, the activation
    of different neurons is combined in a hierarchical way that allows the neurons
    to respond on increasingly larger regions in the retina and to more and more complex
    visual stimuli.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 脑科学研究持续发展，现在众所周知，在Hubel和Wiesel进行实验的大脑区域（称为V1区域），所有神经元对不同视网膜区域上的相对简单的刺激形式都有反应。这不仅适用于猫，也适用于其他动物和人类。还知道，大脑其他区域的神经元（称为V2、V4和IT）对越来越复杂的视觉刺激有反应，例如整个面部（见图2.22）。研究表明，神经元的信号是从一个区域传到另一个区域的。此外，只有大脑一个区域的神经元的一部分连接到下一个区域的神经元。通过神经元的连接，不同神经元的激活以层次化的方式结合，这使得神经元能够在视网膜上对越来越大的区域和越来越复杂的视觉刺激做出反应。
- en: '![](../Images/2-22.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-22.png)'
- en: Figure 2.22 Organization of the visual cortex in a brain. Neurons in different
    regions respond to an increasingly larger receptive field and more and more complex
    stimuli.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.22 大脑视觉皮层的组织。不同区域的神经元对越来越大的感受野和越来越复杂的刺激有反应。
- en: NOTE You’ll see soon that the architecture of deeper CNNs are loosely inspired
    by this hierarchical detection of complex structures from simple structures. However,
    the analogy shouldn’t be overstressed; the brain isn’t wired up to form a CNN.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：你很快就会看到，更深层次的CNN架构在某种程度上受到了从简单结构到复杂结构的层次检测的启发。然而，这种类比不应过分强调；大脑并不是为了形成CNN而连接起来的。
- en: 2.2.4 Building and understanding a CNN
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.4 构建和理解CNN
- en: 'More realistic image classification tasks can’t be tackled by such a simple
    CNN architecture such as that depicted in figure 2.20, which only learns to detect
    one local image pattern like an edge. Even simple image classification tasks like
    discriminating between the 10 digits in the MNIST data set require learning lots
    of more complex image features. You can probably already guess how to do that:
    going deep is the main secret. But before going deep, you need to go broad and
    add more kernels to the first layer.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 更现实的图像分类任务无法通过如图2.20所示的简单CNN架构来处理，该架构仅学习检测像边缘这样的单个局部图像模式。即使是简单的图像分类任务，如区分MNIST数据集中的10个数字，也需要学习大量的更复杂的图像特征。你可能已经能猜到如何做到这一点：深入挖掘是主要秘诀。但在深入挖掘之前，你需要拓宽视野，并在第一层添加更多核。
- en: '![](../Images/2-23.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-23.png)'
- en: Figure 2.23 Convolution of the input image with six different kernels results
    in six activation maps. If the input image has only one channel (a), then each
    kernel has also only one channel. If the input image has three channels (b), then
    each filter has also three channels.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.23 输入图像与六个不同核的卷积产生了六个激活图。如果输入图像只有一个通道（a），那么每个核也只有一个通道。如果输入图像有三个通道（b），那么每个滤波器也有三个通道。
- en: Each kernel can learn another set of weights, and so for each kernel, you get
    another activation map in the hidden layer (see figure 2.23). If the input has
    not only 1 but d channels, then the kernel also needs to have d channels to compute
    an activation map. For color images, d = 3 for (red, green, blue), and a valid
    kernel can be one that is active for a vertical edge in the green channel and
    for horizontal edges in the blue and red channels. The kernel matrix again defines
    the weights for the weighted sum, which determines the input to the neuron in
    the respective position of the activation map.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 每个核可以学习另一组权重，因此对于每个核，你都会在隐藏层中得到另一个激活图（见图2.23）。如果输入不仅有1个通道，而是有d个通道，那么核也需要有d个通道来计算激活图。对于彩色图像，d
    = 3，对应于（红、绿、蓝），一个有效的核可以是绿色通道中垂直边缘活跃，而在蓝色和红色通道中水平边缘活跃的核。核矩阵再次定义了加权求和的权重，这决定了激活图中相应位置的神经元输入。
- en: Now let’s talk about analogies between fcNNs and CNNs. An fcNN learns a new
    set of weights for each neuron (the learning process is discussed in chapter 3)
    that combines the input of the former layer to a new value that can be seen as
    a feature of the image (see, for example, figure 2.8). In an fcNN, you can go
    deep by adding layers where all neurons of one layer are connected to all neurons
    in the next layer. In this sense, the number of kernel sets or activation maps
    in a CNN correspond to the number of neurons in one layer of an fcNN. If you want
    to go deep in a CNN, you need to add more convolutional layers. This means that
    you learn kernels that are again applied to the stack of activation maps of the
    previous layers.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来谈谈全连接神经网络（fcNN）和卷积神经网络（CNN）之间的类比。全连接神经网络为每个神经元学习一组新的权重（学习过程在第3章中讨论），这些权重将前一层输入结合到一个新的值，这个值可以看作是图像的特征（例如，参见图2.8）。在全连接神经网络中，你可以通过添加层来加深网络，其中一层中的所有神经元都连接到下一层中的所有神经元。从这个意义上说，CNN中的核集或激活图的数量对应于全连接神经网络一层中的神经元数量。如果你想在CNN中加深网络，你需要添加更多的卷积层。这意味着你学习的核再次应用于前一层激活图的堆叠。
- en: Figure 2.25 illustrates this principle. In that figure, you see a CNN with 3
    convolutional layers. The convolution over a stack of activation maps isn’t different
    than the convolution with an input of several channels. In figure 2.23, only 6
    activation maps are generated from a 3-channel input image. However, learning
    only 6 kernels isn’t common. A typical number to learn is 32 kernels in the first
    layer or even more kernels. (Often the number of kernels doubles when moving from
    layer to layer.) To reduce the number of weights in a CNN, it’s also common to
    downsample the activation maps before doing the next round of convolution. This
    is often done by replacing a 2 × 2 patch of neurons in an activation map with
    the maximal activation. We call this step max pooling.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.25说明了这个原理。在该图中，你可以看到一个具有3个卷积层的CNN。在激活图堆叠上的卷积与具有多个通道输入的卷积没有区别。在图2.23中，仅从3通道输入图像中生成了6个激活图。然而，只学习6个核并不常见。典型的情况是在第一层学习32个核，甚至更多的核。（通常，从一层到下一层核的数量会加倍。）为了减少CNN中的权重数量，在下一轮卷积之前对激活图进行下采样也是常见的做法。这通常是通过用一个2×2的神经元块替换激活图中的最大激活来完成的。我们称这一步为最大池化。
- en: When adding more layers to a CNN, the area that a neuron sees in the original
    image gets larger. We call this a receptive field, and it’s composed of all the
    pixels in the original image to which the neuron is connected, through all intermediate
    layers. Depending on the image size and the kernel size (often after around four
    to ten layers), all neurons connect to the whole input image. Still, the complexity
    of image patterns that activate the neurons in different layers of the CNN gets
    higher with each layer.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 当向CNN添加更多层时，神经元在原始图像中看到的区域会变大。我们称之为感受野，它由所有与神经元通过所有中间层连接的原始图像中的像素组成。根据图像大小和核大小（通常在四到十个层之后），所有神经元都连接到整个输入图像。尽管如此，激活CNN不同层中神经元的图像模式复杂性随着每一层的增加而提高。
- en: When checking which images or image parts can activate a neuron in the different
    layers of a CNN, layers close to the input respond to simple image patterns (like
    edges) and layers close to the output combine these simple patterns into more
    complex patterns (see figure 2.24).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当检查哪些图像或图像部分可以在CNN的不同层中激活一个神经元时，靠近输入的层对简单的图像模式（如边缘）做出反应，而靠近输出的层将这些简单模式组合成更复杂的模式（参见图2.24）。
- en: '![](../Images/2-24.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2-24.png)'
- en: 'Figure 2.24 Image patterns that activate neurons in different convolutional
    layers of a CNN show a hierarchy of increasing complexity: simple patterns (like
    edges) combine into local objects (like eyes or ears) that further combine into
    higher-level concepts (such as a cat). Figure used with permission from François
    Chollet’s book, Deep Learning with Python (Manning, 2017).'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.24展示了CNN不同卷积层中激活神经元图像模式的层次结构：简单的模式（如边缘）组合成局部对象（如眼睛或耳朵），这些对象进一步组合成更高级的概念（如猫）。该图使用得到了François
    Chollet的《Python深度学习》（Manning, 2017）一书的许可。
- en: 'The number of convolutional layers and the numbers of kernels within each layer
    are tuning parameters in a CNN. When the complexity of the problem increases,
    you usually need more convolutional layers and more kernels per layer. In the
    last convolutional layer of the CNN, we have a new representation of the input.
    Flattening all neurons of this layer into a vector results in a new feature representation
    of the image with as many features as there were neurons in the last convolutional
    layer (see figure 2.25). We end up with the same situation as before: the input
    is described by a vector of image features. But this time, the features are results
    from trained kernels. Now you can add a couple of densely connected layers to
    construct the prediction.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层的数量以及每层的核数量是 CNN 中的调整参数。当问题的复杂性增加时，通常需要更多的卷积层和每层的更多核。在 CNN 的最后一个卷积层中，我们得到了输入的新表示。将此层的所有神经元展平成一个向量，结果得到一个具有与最后一个卷积层中神经元数量一样多的图像特征的新特征表示（见图
    2.25）。我们最终又回到了之前的情况：输入由一个图像特征向量描述。但这次，特征是训练核的结果。现在你可以添加几个密集连接层来构建预测。
- en: '![](../Images/2-25.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图 2-25](../Images/2-25.png)'
- en: Figure 2.25 A CNN with three convolutional layers followed by three fully connected
    layers. The number of feature maps in each convolutional layer indicate the number
    of kernel sets learned. The number of elements in each layer of the fully connected
    part indicate the number of weighted sets learned.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.25 一个具有三个卷积层和三个全连接层的 CNN。每个卷积层中的特征图数量表示学习到的核集数量。全连接部分每层的元素数量表示学习到的加权集数量。
- en: Let’s try a CNN on the MNIST data. In listing 2.6, you see the definition of
    a CNN with convolutional layers followed by fully connected layers.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 MNIST 数据上尝试一个 CNN。在列表 2.6 中，你可以看到具有卷积层和全连接层的 CNN 的定义。
- en: '| ![](../Images/computer-icon.png) | Hands-on time Open the MNIST notebook
    again [http://mng.bz/AAJz](http://mng.bz/AAJz) and fit a CNN with two convolutional
    layers to the MNIST data (see the second part of the notebook). Then compare the
    performance to what you achieved with an fcNN. Play with the code and perform
    a permutation experiment to check that the order of the pixels within the images
    matter for the performance of the CNN. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| ![计算机图标](../Images/computer-icon.png) | 实践时间 再次打开 MNIST 笔记本 [http://mng.bz/AAJz](http://mng.bz/AAJz)，将具有两个卷积层的
    CNN 拟合到 MNIST 数据上（参见笔记本的第二部分）。然后比较与使用 fcNN 所达到的性能。玩转代码并执行一个排列实验以检查图像中像素的顺序对 CNN
    性能的影响。 |'
- en: '[PRE6]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Uses a convolutional layer with eight kernels of the size 3 × 3
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用一个大小为 3 × 3 的八个核的卷积层
- en: ❷ Applies the relu activation function to the feature maps
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将 relu 激活函数应用于特征图
- en: ❸ This max pooling layer has a pooling size of 2 × 2 and a stride of 2.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 此最大池化层具有 2 × 2 的池化大小和 2 的步长。
- en: ❹ Uses a convolutional layer with 16 kernels of the size 3 × 3
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用一个大小为 3 × 3 的 16 个核的卷积层
- en: ❺ This max pooling layer transforms the 14 × 14 × 16 input tensor into a 7 ×
    7 × 16 output tensor.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 此最大池化层将 14 × 14 × 16 的输入张量转换为 7 × 7 × 16 的输出张量。
- en: ❻ Flattens the output of the previous layer resulting in a vector of length
    784 (7 × 7 × 16)
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 将前一层输出展平，得到长度为 784（7 × 7 × 16）的向量
- en: ❼ Outputs nb_classes (here 10)
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 输出 nb_classes（此处为 10）
- en: ❽ Uses softmax to transform the 10 outputs to 10 prediction probabilities
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 使用 softmax 将 10 个输出转换为 10 个预测概率
- en: The first convolutional layer with eight kernels with the same padding results
    in an output feature map that has the same size as the input image. In the MNIST
    case, the input image has a size 28 × 28 × 1 pixels. The resulting eight feature
    maps each have a size of 28 × 28\. After the first pooling, the input has a shape
    of 28 × 28 × 8, and the output has a shape of 14 × 14 × 8.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个卷积层使用八个具有相同填充的核，结果输出特征图的大小与输入图像相同。在 MNIST 情况下，输入图像的大小为 28 × 28 × 1 像素。结果八个特征图每个的大小为
    28 × 28。经过第一次池化后，输入的形状为 28 × 28 × 8，输出形状为 14 × 14 × 8。
- en: 'From your experiments with the MNIST notebook at [http://mng.bz/AAJz](http://mng.bz/AAJz)
    , you’ve learned that with this image classification task, it’s easy to achieve
    a higher performance with a CNN (around 99%) than with an fcNN (around 96%). The
    permutation experiment shows that the arrangement of the pixels within the image
    does matter: the CNN performs much better when trained on the original image data
    (99%) than when trained on a shuffled version of the image data (95%). This supports
    the idea that the secret of the high performance of a CNN in image-related tasks
    lies in the architecture that takes the local order of an image into account.
    Before moving on, let us look back and emphasize some advantages of CNNs when
    working with image data:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 从您在 [http://mng.bz/AAJz](http://mng.bz/AAJz) 的 MNIST 笔记本中的实验中，您已经了解到，对于这个图像分类任务，使用
    CNN（大约 99%）比使用 fcNN（大约 96%）更容易实现更高的性能。排列实验表明，图像中像素的排列确实很重要：当在原始图像数据上训练时（99%），CNN
    的表现比在图像数据的随机版本上训练时（95%）要好得多。这支持了这样一个观点，即 CNN 在图像相关任务中表现优异的秘密在于其架构考虑了图像的局部顺序。在继续之前，让我们回顾一下并强调
    CNN 在处理图像数据时的某些优势：
- en: Local connectivity makes use of the local information of image data.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 局部连通性利用了图像数据的局部信息。
- en: You need less weight parameters in a CNN than in an fcNN.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 CNN 中，您需要的权重参数比在 fcNN 中少。
- en: A CNN is to a large extent invariant to translations within the images.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN 在很大程度上对图像内的平移是不变的。
- en: The convolutional part of a CNN allows the network to learn hierarchically task-specific
    abstract image features.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN 的卷积部分允许网络以层次结构学习特定任务的抽象图像特征。
- en: The next special case of data that’s successfully analyzed with DL is data that
    shows an ordering. Let’s look at that next.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个成功使用深度学习分析的特殊数据类型是显示排序的数据。让我们看看下一个。
- en: 2.3 One-dimensional CNNs for ordered data
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 有序数据的一维 CNN
- en: 'Ordered data can be text (understood as sequences of words or characters),
    time series (like the daily maximum temperature in Zürich), sound, or any other
    data that’s ordered. Applications of these algorithms include the following:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 有序数据可以是文本（理解为单词或字符的序列），时间序列（如苏黎世的每日最高温度），声音或任何其他有序数据。这些算法的应用包括以下内容：
- en: Document and time series classification, such as identifying the topic of an
    article or the author of a book
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档和时间序列分类，例如识别文章的主题或书籍的作者
- en: Sequence comparisons, such as estimating how closely related two documents or
    two stock tickers are
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列比较，例如估计两个文档或两个股票交易者的相似程度
- en: Sequence-to-sequence learning, such as decoding an English sentence into French
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列到序列学习，例如将英语句子解码成法语
- en: Sentiment analysis, such as classifying the sentiment of tweets or movie reviews
    as positive or negative
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感分析，例如将推文或电影评论的情感分类为正面或负面
- en: Time series forecasting, such as predicting the future weather at a certain
    location given recent weather data
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列预测，例如根据最近的天气数据预测某个地点的未来天气
- en: 2.3.1 Format of time-ordered data
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.1 时间排序数据的格式
- en: 'To model sequential data with TensorFlow and Keras, you need to provide that
    data as 3D tensors:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 TensorFlow 和 Keras 模型有序数据，您需要将数据作为 3D 张量提供：
- en: '[PRE7]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `batch` dimension specifies the number of sequences that are processed in
    one batch. Using many sequences in a batch is only for performance reasons. The
    sequences in a batch are processed independently. This is the same situation as
    with the previous CNNs, where the images in a batch are also processed independently.
    When calculating the loss function, the results of those different sequences in
    a batch are averaged.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`batch` 维度指定了在一次批量中处理的序列数量。在一个批量中使用许多序列只是为了性能原因。批量中的序列是独立处理的。这与之前的 CNN 情况相同，其中批量中的图像也是独立处理的。在计算损失函数时，这些不同序列的结果会被平均。'
- en: 'Let’s look at an example. You want to predict the daily maximum temperature
    for tomorrow. You have 12 years of historical data, and you want to take the last
    10 days into account to predict tomorrow’s temperature. You choose a batch size
    of 128\. In that case, the input tensor has the following shape: (128, 10, 1).
    Let’s refine the model. Maybe there’s information in the daily maximum temperature
    of five nearby cities that can help with your prediction. You also take those
    temperatures into account, which results in an input tensor of shape (128, 10,
    6).'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个例子。你想预测明天的日最高气温。你有12年的历史数据，并且想考虑最后10天的数据来预测明天的气温。你选择了一个批大小为128。在这种情况下，输入张量的形状如下：(128,
    10, 1)。让我们细化模型。也许五个附近城市的日最高气温中包含的信息可以帮助你的预测。你也考虑了这些温度，这导致输入张量的形状为(128, 10, 6)。
- en: Another application area of ordered data is text analysis. Let’s say you want
    to analyze text with characters as input. The `timestep` dimension specifies the
    position of a character within a sequence. The `input_feature` dimension holds
    for each sequence and timestep the actual values.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 有序数据的另一个应用领域是文本分析。假设你想分析以字符为输入的文本。`timestep` 维度指定了字符在序列中的位置。`input_feature`
    维度则保存了每个序列和时间步的实际值。
- en: 'Let’s take another example. Suppose you want to analyze text data in lowercase
    at the character level. The third sequence in the batch starts with “hello.” You
    could encode “hello” by using the position of the letters in the alphabet as (8,
    5, 11, 11, 14). Coding characters like this implies an ordering that’s artificial.
    Therefore, in DL, categorical data is treated using one-hot encoding. See [http://mng.bz/7Xrv](http://mng.bz/7Xrv)
    for a more detailed description of one-hot encoding. The first two elements of
    this sequence in the 3D input tensor would then be:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 再来看另一个例子。假设你想在字符级别分析小写的文本数据。批次的第三个序列以“hello.”开头。你可以通过使用字母在字母表中的位置来编码“hello”，即(8,
    5, 11, 11, 14)。以这种方式编码字符意味着存在一种人为的顺序。因此，在深度学习中，分类数据使用独热编码来处理。有关独热编码的更详细描述，请参阅[http://mng.bz/7Xrv](http://mng.bz/7Xrv)。在这个3D输入张量中，这个序列的前两个元素将是：
- en: '[PRE8]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: One-hot encoding is useful if you need to model text at the character level
    when you have a limited number of characters. If you model text at the word level
    and do one-hot encoding, you need vectors with as many dimensions as you have
    words. These vectors would get quite large and sparse, and hence, it’s better
    to find a denser representation. This is a step we call embedding, which yields
    a new representation of the word as a vector of numbers. In chapter 6 of Chollet’s
    book at [http://mng.bz/qMGr](http://mng.bz/qMGr) , you can find more details of
    transforming text to vectors and some demo code for Keras.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有有限数量的字符需要以字符级别对文本进行建模时，独热编码是有用的。如果你在词级别建模文本并执行独热编码，你需要与单词数量一样多的维度的向量。这些向量会变得相当大且稀疏，因此，找到一种更密集的表示更好。这是我们称之为嵌入的步骤，它产生了一个新的表示，将单词作为数字向量。在Chollet的书中第6章[http://mng.bz/qMGr](http://mng.bz/qMGr)中，你可以找到将文本转换为向量的更多细节和一些Keras的示例代码。
- en: 2.3.2 What’s special about ordered data?
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.2 有序数据有什么特别之处？
- en: 'For text and other ordered data, the sequences often have some particular properties.
    The first property is that there is often no notion of a natural starting point
    in time. Becoming a bit philosophical, if you forget about the Big Bang for now
    and consider normal time spans, there’s no marked starting point. This has as
    a consequence that all physical laws must be invariant in time. If you play table
    tennis, the trajectory of the ball is the same as in the 15th century. The second
    particularity is that time-ordered data often includes long-range dependencies.
    Consider the following string (taken from Wikipedia’s article on Kant, [https://en.wikipedia.org/wiki/Immanuel_Kant](https://en.wikipedia.org/wiki/Immanuel_Kant)):'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本和其他有序数据，序列通常具有一些特定的属性。第一个属性是通常没有时间上的自然起点概念。稍微哲学一点，如果你现在不考虑大爆炸，而考虑正常的时间跨度，就没有明显的起点。这导致所有物理定律都必须在时间上保持不变。如果你打乒乓球，球的轨迹和15世纪时是一样的。第二个特殊性是时间序列数据通常包括长距离依赖关系。考虑以下字符串（取自维基百科关于康德的条目[https://en.wikipedia.org/wiki/Immanuel_Kant](https://en.wikipedia.org/wiki/Immanuel_Kant)）：
- en: Kant was born on April 22, 1724 into a Prussian German family of Lutheran Protestant
    faith in Königsberg, East Prussia. . . . [thousands of words left out]. A common
    myth is that Kant never traveled more than 16 kilometers (9.9 mi) from Königsberg
    his whole life. . . . [thousands of words left out]. Kant’s health, long poor,
    worsened and he died at ___________.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 康德于1724年4月22日出生于东普鲁士的柯尼斯堡的一个路德派新教普鲁士家庭。......[省略数千字]。一个常见的说法是，康德一生从未超过16公里（9.9英里）离开过柯尼斯堡。......[省略数千字]。康德的健康状况一直不佳，病情恶化，他在__________去世。
- en: 'What’s the probability of the next word being one of these: a) lightsaber,
    b) London, or c) Königsberg? This shows that there are quite long-range dependencies
    in sequential data. Also, lengthy range dependencies can be found in other ordered
    data. For example, if you consider the daily maximum temperature at an arbitrary
    place on earth, it’s quite likely that 365 data points later, a similar temperature
    occurs (at least more likely than 182 days later). The last special property of
    ordered data occurs especially in time series, where there’s a notion of past,
    present, and future. In this case, the future doesn’t have an impact on the past.
    This feature is true for a time series like the temperatures in a weather forecast
    but not for tasks in sentiment analysis.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个词是以下哪一个的概率：a)光剑，b)伦敦，或c)柯尼斯堡？这表明在序列数据中存在相当长的依赖关系。此外，在有序数据中也可以找到长距离依赖。例如，如果你考虑地球上任意地点的每日最高气温，那么在365个数据点之后，出现相似气温的可能性相当大（至少比182天后更有可能）。有序数据的最后一个特殊属性特别出现在时间序列中，其中存在过去、现在和未来的概念。在这种情况下，未来不会影响过去。这个特性对于天气预报中的温度时间序列来说是正确的，但不是对于情感分析任务。
- en: An optimal network should incorporate these hard facts in its design so that
    it doesn’t need to learn them. In the case of causal networks, the architecture
    ensures that only information from the past has an influence on the present. Similarly,
    in the case of CNN for images, the architecture with shared weights ensures that
    the model is invariant to small spatial shifts.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 一个最优的网络应该在设计中融入这些硬事实，这样它就不需要学习它们。在因果网络的情况下，架构确保只有过去的信息对现在有影响。同样，在图像卷积网络的情况下，具有共享权重的架构确保模型对小的空间位移是不变的。
- en: 2.3.3 Architectures for time-ordered data
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.3 时间序列数据的架构
- en: 'We often analyze time-ordered data using so-called recurrent neural networks(RNNs)
    like long short-term memory networks(LSTMs). These networks are conceptually a
    bit more complicated than CNNs. Furthermore, RNNs are a bit harder to train. In
    many applications, RNNs can be replaced by CNNs, or as the finding of a recent
    research paper states it (Bai et al., [https://arxiv.org/abs/1803.01271](https://arxiv.org/abs/1803.01271)):'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常使用所谓的循环神经网络（RNNs）如长短期记忆网络（LSTMs）来分析时间序列数据。这些网络在概念上比CNNs复杂一些。此外，RNNs的训练也稍微困难一些。在许多应用中，RNNs可以被CNNs替代，或者如最近的研究论文所指出（Bai等人，[https://arxiv.org/abs/1803.01271](https://arxiv.org/abs/1803.01271)）：
- en: We conclude that the common association between sequence modeling and recurrent
    networks should be reconsidered, and convolutional networks should be regarded
    as a natural starting point for sequence modeling tasks.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得出结论，序列建模与循环网络之间的常见关联应该被重新考虑，卷积网络应该被视为序列建模任务的起点。
- en: Because you don’t need RNNs for the rest of the book, refer to chapter 6 of
    Chollet’s book at [http://mng.bz/mBea,](http://mng.bz/mBea) and proceed with CNNs
    for sequence modeling.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你不需要在本书的其余部分使用RNNs，请参考Chollet的书籍第6章，[http://mng.bz/mBea](http://mng.bz/mBea)，并继续使用CNNs进行序列建模。
- en: Using CNNs for time-ordered data
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CNNs处理时间序列数据
- en: An alternative way to handle time-ordered data is to use one-dimensional (1*D*)
    CNNs. In these 1D networks, time is treated just like a spatial dimension. You
    can use these 1D convolutional networks for various sequence-specific tasks like
    sentiment analysis. Here we demonstrate their use for predicting a time series.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 处理时间序列数据的另一种方法是使用一维（1*D*）卷积神经网络。在这些一维网络中，时间被当作一个空间维度来处理。你可以使用这些一维卷积网络来完成各种特定于序列的任务，如情感分析。在这里，我们展示了它们在预测时间序列中的应用。
- en: For time series data, the future mustn’t have any influence on the present or
    the past. And further, there should also be no marked starting time. You can apply
    the learned convolutional kernels to sequences of arbitrary size. These, therefore,
    can be slid over a sequence and don’t treat any time point in a special fashion.
    Allowing only past and current time points to influence the prediction of a current
    or future outcome is called causal. You can easily apply the causal requirement
    by letting only values from the previous or current time influence the prediction
    of the current value. This leads to so-called causal convolutions. Figure 2.26
    shows a simple example of a convolution of the input values 10, 20, 30 with a
    1D convolution kernel of size 2 having the weight values of 1 and 2.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 对于时间序列数据，未来不应对现在或过去有任何影响。更进一步，也不应有明显的起始时间。你可以将学习到的卷积核应用于任意大小的序列。因此，这些核可以在序列上滑动，不对任何时间点进行特殊处理。只允许过去和当前时间点影响当前或未来结果预测的称为因果。你可以通过只让前一个或当前时间点的值影响当前值的预测来轻松应用因果要求。这导致了所谓的因果卷积。图2.26展示了输入值10、20、30与大小为2的1D卷积核（权重值为1和2）的简单卷积示例。
- en: '![](../Images/2-26.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![2-26.png](../Images/2-26.png)'
- en: Figure 2.26 A simple causal convolution for the values 10, 20, 30 with a kernel
    with weights of 1, 2\. The number 50 after convolution only depends on the past
    and present values (10, 20) but not on the future value of 30.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.26 使用权重为1、2的核对值10、20、30进行简单因果卷积。卷积后的数字50只依赖于过去和当前值（10、20），而不依赖于未来的值30。
- en: You see in figure 2.26 that the second (upper) layer has fewer elements. To
    make all layers the same size, a zero padding is added to the beginning of the
    input layer. In that case, figure 2.26 becomes figure 2.27.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 你在图2.26中可以看到，第二层（上层）的元素较少。为了使所有层的大小相同，我们在输入层的开始处添加了零填充。在这种情况下，图2.26变成了图2.27。
- en: '![](../Images/2-27.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![2-27.png](../Images/2-27.png)'
- en: Figure 2.27 A simple causal convolution for the values 10, 20, 30 and the kernel
    1, 2 with 0 padding
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.27 对于值10、20、30和核1、2的简单因果卷积，使用0填充
- en: '| ![](../Images/computer-icon.png) | Hands-on time If you want to get a better
    understanding how 1D convolution works, you can go through the notebook [http://mng.bz/5aBO](http://mng.bz/5aBO)
    . In this notebook, we also introduce time-dilated causal convolution, allowing
    for long-range time dependencies. |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| ![计算机图标](../Images/computer-icon.png) | 实践时间 如果你想更好地理解一维卷积的工作原理，你可以通过笔记本
    [http://mng.bz/5aBO](http://mng.bz/5aBO) 进行学习。在这个笔记本中，我们还介绍了时间膨胀因果卷积，允许长距离时间依赖。|'
- en: 'Now you’ve seen the basic architectural building blocks used in DL: fully connected,
    convolutional, and recurrent NNs. These are just building blocks, and you can
    use these in combination with each other. For example, you could feed an image
    into a convolutional network, then use an RNN to produce ordered output as text.
    This combination has been successfully used to create captions for images.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了在深度学习中使用的最基本的建筑模块：全连接、卷积和循环神经网络。这些只是构建模块，你可以将它们组合使用。例如，你可以将图像输入到卷积网络中，然后使用循环神经网络产生有序输出作为文本。这种组合已被成功用于为图像创建标题。
- en: Summary
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A fully connected neural network (fcNN) consists of stacked layers of neurons.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全连接神经网络（fcNN）由堆叠的神经元层组成。
- en: In an fcNN, each neuron connects to each neuron of the previous layer.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在全连接神经网络（fcNN）中，每个神经元都与前一层中的每个神经元相连。
- en: The input to a neuron is given by the weighted sum of the connected neurons
    in the previous layer.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经元的输入是由前一层中连接的神经元的加权总和给出的。
- en: That weighted sum passed through an activation function computes the output
    of a neuron.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那个加权的总和通过一个激活函数计算神经元的输出。
- en: The non-linearity of the activation function is essential because a stack of
    layers could otherwise be replaced by one layer.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活函数的非线性是至关重要的，因为否则堆叠的层可以被一层所替代。
- en: Use the `relu` activation function for hidden layers. It is known to yield a
    more efficient training, compared to the sigmoid activation function.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在隐藏层中使用`relu`激活函数。与sigmoid激活函数相比，它已知可以产生更有效的训练。
- en: Use `softmax` as an activation function in the output layer when doing classification.
    The output of the `softmax` function can be interpreted as probability for a certain
    class label.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在进行分类时，在输出层使用`softmax`作为激活函数。`softmax`函数的输出可以解释为某个类标签的概率。
- en: A convolutional neural network (CNN) consists of a convolutional part, where
    features are extracted from the input data, and a fully connected part, where
    the features are combined to the output of the CNN.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）由卷积部分和全连接部分组成，其中卷积部分从输入数据中提取特征，全连接部分将特征组合到CNN的输出中。
- en: The convolutional part of a CNN consists of stacked layers of feature maps.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）的卷积部分由堆叠的特征图层组成。
- en: Each neuron in a feature map only connects to a small patch of the previous
    feature map. This reflects the local structure of image data.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征图中的每个神经元只连接到前一个特征图的一个小区域。这反映了图像数据的局部结构。
- en: The high performance of deep NNs relies on the fact that they learn a hierarchy
    of optimal features for the given task.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度神经网络的高性能依赖于它们学习给定任务的层次化最优特征这一事实。
- en: NNs work best when the NN architecture exploits a known structure of the data
    so that these don’t have to learn it from scratch. Therefore,
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当神经网络架构利用数据已知结构时，神经网络工作得最好，这样它们就不必从头开始学习这些结构。因此，
- en: If your data comes from images (or has other 2D structures), use 2D CNNs to
    exploit the local structure of images by local connections and shared weights.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据来自图像（或具有其他二维结构），请使用二维CNN，通过局部连接和共享权重来利用图像的局部结构。
- en: If your data comes from sequences, use 1D convolutions if possible; otherwise,
    use recurrent NNs.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据来自序列，尽可能使用一维卷积；否则，使用循环神经网络（RNN）。
- en: If you have no particular structure, use fcNNs.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你没有特定的结构，请使用全连接神经网络（fcNN）。
- en: 1.People in the field of DL and computer vision use the word kernel, but sometimes
    you also see the term filter, which can be used as a synonym.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 在深度学习和计算机视觉领域，人们使用“核”这个词，但有时你也会看到“滤波器”这个术语，它可以作为同义词使用。
