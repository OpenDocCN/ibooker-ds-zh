- en: Chapter 51\. Algorithmic Misclassification—the (Pretty) Good, the Bad, and the
    Ugly
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 51 章。算法误分类——（相当）好的、坏的和丑陋的
- en: Arnobio Morelix
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阿诺比奥·莫雷利克斯
- en: '![](Images/Arnobio_Morelix.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/Arnobio_Morelix.png)'
- en: Chief Innovation Officer, Startup Genome
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 创新主管，Startup Genome
- en: Data Scientist-in-Residence, Inc. Magazine
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家驻地，Inc. Magazine
- en: Every day, the systems we build classify the identity and behavior of people
    nonstop. A credit card transaction is labeled “fraudulent” or not. Political campaigns
    decide on “likely voters” for their candidate. People constantly claim and are
    judged on their identity of “not a robot” through captchas. Add to this the classification
    of emails, face recognition in phones, and targeted ads, and it is easy to imagine
    thousands of such classification instances per day for even just one person.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 每天，我们建立的系统不断地对人们的身份和行为进行分类。信用卡交易被标记为“欺诈”或者不是。“政治活动”为他们的候选人决定“可能的选民”。人们通过验证码声称并且被判断为“非机器人”的身份。加上电子邮件的分类，手机上的人脸识别和定向广告，甚至只是一个人每天就可以想象到成千上万次这样的分类实例。
- en: For the most part, these classifications are convenient and pretty good for
    the user and the organizations running them. We mostly forget them, unless they
    go obviously wrong.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，这些分类对用户和运行它们的组织来说都是方便的和相当不错的。我们大多数时候会忘记它们，除非它们显然错误。
- en: I am a Latino living in the US, and I often get ads in Spanish—which would be
    pretty good targeting, except that I am a Brazilian Latino, and my native language
    is Portuguese, not Spanish.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我是居住在美国的拉丁裔，经常收到用西班牙语发布的广告——这本来是相当好的定位，但我是巴西拉丁裔，我的母语是葡萄牙语，而不是西班牙语。
- en: This particular misclassification causes no real harm to me. My online behavior
    might look similar enough to that of a native Spanish speaker living in the US,
    and users like me getting mistargeted ads may be nothing more than a “rounding
    error” by the algorithm. Although it is in no one’s interest that I get these
    ads—I am wasting my time, and the company is wasting money—the targeting is probably
    “good enough.”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这种特定的误分类对我没有造成真正的伤害。我的在线行为可能看起来与居住在美国的西班牙语母语者相似，像我这样的用户接收到的误定位广告可能只是算法的“舍入误差”。尽管没有人希望我接收到这些广告——我浪费了我的时间，公司浪费了金钱——但定位可能是“足够好的”。
- en: This “good enough” mindset is at the heart of a lot of prediction applications
    in data science. As a field, we constantly put people in boxes to make decisions
    about them, even though we inevitably know predictions will not be perfect. “Pretty
    good” is fine most of the time—it generally is for ad targeting.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这种“够用就行”的心态是数据科学中许多预测应用的核心。作为一个领域，我们不断地将人们分类以做出关于他们的决策，尽管我们不可避免地知道预测不会完美无缺。“相当不错”在大多数时候都还好——这通常对于广告定位来说是可以接受的。
- en: But these automatic classifications can quickly go from pretty good to bad to
    ugly—either because of scale of deployment or because of tainted data. As we go
    to higher-stakes fields beyond those they have arguably been perfected for—such
    as social media and online ads—we get into problems.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这些自动分类很快可以从相当不错变成糟糕到丑陋——无论是因为规模的部署还是因为有污染的数据。当我们进入超过它们可以被认为已经完美的更高风险领域——如社交媒体和在线广告——我们会遇到问题。
- en: Take psychometric tests, for example. Companies are increasingly using them
    to weed out job candidates. Some of these companies are reporting good results,
    with higher performance and lower turnover.^([1](ch51.xhtml#idm45346852123464))
    The problem is, although these tests can be pretty good, they are far from great.
    An IQ test, a popular component of psychometric assessments, is a poor predictor
    of cognitive performance across many different tasks—though it is certainly correlated
    to performance in some of them.^([2](ch51.xhtml#idm45346852121064))
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 以心理测量测试为例。公司越来越多地使用它们来筛选求职者。其中一些公司报告了良好的结果，表现更高，流失率更低。^([1](ch51.xhtml#idm45346852123464))
    问题在于，尽管这些测试可能相当不错，但它们远非完美。智商测试，心理测评的一种流行组成部分，是跨多个不同任务的认知表现的差预测器——尽管它确实与其中一些任务的表现相关。^([2](ch51.xhtml#idm45346852121064))
- en: When a single company weeds out a candidate who would otherwise perform well,
    it may not be a big problem by itself. But it *can* be a big problem when the
    tests are used at scale, and a job seeker is consistently excluded from jobs they
    would perform well in. And while the use of these tests by a single private actor
    may well be justified on an efficiency-for-hiring basis, it should give us pause
    to see these tests used at scale for both private and public decision making (e.g.,
    testing students).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个公司淘汰一个本来表现良好的候选人时，单独来看可能不是一个大问题。但当这些测试被大规模使用时，一个求职者在本应表现良好的工作中一再被排除可能就成了一个大问题。虽然单个私人行为者使用这些测试可能基于提高招聘效率，但当我们看到这些测试被用于私人和公共决策的大规模应用时（例如，对学生进行测试），我们应该停下来思考。
- en: 'Problems with “pretty good” classifications also arise from blind spots in
    the prediction, as well as tainted data. Several Somali markets in Seattle were
    unable to accept food stamps because the federal government thought many of their
    transactions looked fraudulent—with many infrequent, large-dollar transactions,
    one after the other. But this algorithmically suspicious pattern had a perfectly
    reasonable explanation: it was driven by the fact that many families in the community
    the markets serve shopped only once a month, often sharing a car to do so. The
    USDA later reversed the decision of rejecting those food stamps, although only
    after four months of trouble for the Somali grocery customers.^([3](ch51.xhtml#idm45346852116712))'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: “相当不错”的分类存在的问题也来自于预测的盲点，以及有问题的数据。在西雅图的几个索马里市场无法接受食品券，是因为联邦政府认为他们的交易看起来有很多欺诈性质——很多交易都是不经常的，金额很大，一个接一个。但这种算法上可疑的模式有一个完全合理的解释：这是由于市场服务的社区中的许多家庭每月只购物一次，通常共用一辆车。
    USDA后来撤销了拒绝给这些索马里食品店顾客发放食品券的决定，尽管在此期间索马里杂货店顾客们经历了长达四个月的麻烦。^([3](ch51.xhtml#idm45346852116712))
- en: Similarly, African American voters in Florida were disproportionately disenfranchised
    because their names were more often automatically matched to felons’ names. This
    was simply because African Americans have a disproportionate share of common last
    names (a legacy of original names being stripped due to slavery).^([4](ch51.xhtml#idm45346852103032))
    Also in Florida, black criminal defendants were more likely to be algorithmically
    classified as being of “high risk” for recidivism, and among those defendants
    who did not reoffend, blacks were over twice as likely as whites to have been
    labeled risky.^([5](ch51.xhtml#idm45346852104072))
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，佛罗里达州的非裔美国选民由于其姓名更容易与重罪犯的姓名自动匹配，导致被剥夺选举权的比例偏高。这仅仅是因为非裔美国人在常见姓氏中所占比例偏高（这是由于原始姓名由于奴隶制度而被剥夺的遗留问题）。^([4](ch51.xhtml#idm45346852103032))
    同样在佛罗里达州，黑人犯罪被告更有可能被算法分类为“高风险”再犯者，而在那些没有再犯的被告中，黑人被标记为高风险的比例是白人的两倍多。^([5](ch51.xhtml#idm45346852104072))
- en: In all of these cases, there is not necessarily evidence of malicious intent.
    The results can be explained by a mix of “pretty good” predictions and data reflecting
    previous patterns of discrimination—even if the people designing and applying
    the algorithms had no intention to discriminate.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些情况中，并不一定有恶意意图的证据。结果可以通过“相当不错”的预测和反映先前歧视模式的数据混合来解释，即使设计和应用算法的人没有歧视的意图。
- en: While the examples I’ve mentioned here have a broad range of technical sophistication,
    there’s no strong reason to believe the most sophisticated techniques are getting
    rid of these problems. Even the newest deep learning techniques excel at identifying
    relatively superficial correlations, not deep patterns or causal paths.^([6](ch51.xhtml#idm45346852099832))
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我在这里提到的例子在技术复杂性上有广泛的范围，但没有强有力的理由认为最复杂的技术能够解决这些问题。即使是最新的深度学习技术也擅长于识别相对表面的相关性，而不是深层模式或因果路径。^([6](ch51.xhtml#idm45346852099832))
- en: The key problem with the explosion in algorithmic classification is the fact
    that we are invariably designing life around a slew of “pretty good” algorithms.
    “Pretty good” may be a great outcome for ad targeting. But when we deploy classification
    algorithms at scale on applications from voter registration exclusions to hiring
    or loan decisions, the final outcomes may well be disastrous.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 算法分类爆炸的关键问题在于，我们无可避免地在“相当不错”的算法周围设计生活。对于广告定位来说，“相当不错”可能是一个很好的结果。但当我们将分类算法大规模应用于从选民注册排除到招聘或贷款决策等应用时，最终结果可能会非常糟糕。
- en: The road to hell is paved with “pretty good” intentions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通往地狱的路是用“相当不错”的意图铺成的。
- en: ^([1](ch51.xhtml#idm45346852123464-marker)) Lauren Weber, “Today’s Personality
    Tests Raise the Bar for Job Seekers,” *Wall Street Journal*, April 14, 2015, [*https://oreil.ly/3kxOL*](https://oreil.ly/3kxOL).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch51.xhtml#idm45346852123464-marker)) Lauren Weber，“今日人格测试提升了求职者的门槛”，《华尔街日报》，2015年4月14日，[*https://oreil.ly/3kxOL*](https://oreil.ly/3kxOL)。
- en: '^([2](ch51.xhtml#idm45346852121064-marker)) Adam Hampshire, Roger R. Highfield,
    Beth L. Parkin, and Adrian M. Owen, “Fractionating Human Intelligence,” *Neuron*
    76, no. 6 (December 2012): 1225–37, [*https://oreil.ly/Dd5M1*](https://oreil.ly/Dd5M1).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch51.xhtml#idm45346852121064-marker)) Adam Hampshire, Roger R. Highfield,
    Beth L. Parkin, and Adrian M. Owen，“人类智能的分析”，《神经元》76卷6期（2012年12月）：1225–37，[*https://oreil.ly/Dd5M1*](https://oreil.ly/Dd5M1)。
- en: ^([3](ch51.xhtml#idm45346852116712-marker)) Florangela Davila, “USDA Disqualifies
    Three Somalian Markets from Accepting Federal Food Stamps,” *Seattle Times*, April
    10, 2002, [*https://oreil.ly/MBHwj*](https://oreil.ly/MBHwj); D. Parvaz, “USDA
    Reverses Itself, to Somali Grocers’ Relief,” *Seattle Post-Intelligencer*, July
    16, 2002, [*https://oreil.ly/jOneZ*](https://oreil.ly/jOneZ).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch51.xhtml#idm45346852116712-marker)) Florangela Davila，“美国农业部取消三家索马里市场接受联邦食品券资格”，《西雅图时报》，2002年4月10日，[*https://oreil.ly/MBHwj*](https://oreil.ly/MBHwj)；D.
    Parvaz，“美国农业部改口，给予索马里杂货店解脱”，《西雅图邮报》，2002年7月16日，[*https://oreil.ly/jOneZ*](https://oreil.ly/jOneZ)。
- en: '^([4](ch51.xhtml#idm45346852103032-marker)) Guy Stuart, “Databases, Felons,
    and Voting: Errors and Bias in the Florida Felons Exclusion List in the 2000 Presidential
    Elections,” Harvard University, Faculty Research Working Papers Series.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch51.xhtml#idm45346852103032-marker)) Guy Stuart，“数据库、重罪犯和选举：2000年总统选举中佛罗里达重罪犯排除名单中的错误与偏见”，哈佛大学，教师研究工作论文系列。
- en: ^([5](ch51.xhtml#idm45346852104072-marker)) Sam Corbett-Davies, Emma Pierson,
    Avi Feller, Sharad Goel, and Aziz Huq, “Algorithmic Decision Making and the Cost
    of Fairness,” Computers and Society, Cornell University, last modified June 10,
    2017, [*https://arxiv.org/abs/1701.08230*](https://arxiv.org/abs/1701.08230).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch51.xhtml#idm45346852104072-marker)) Sam Corbett-Davies, Emma Pierson,
    Avi Feller, Sharad Goel, and Aziz Huq，“算法决策与公平的代价”，康奈尔大学计算机与社会，最后修改于2017年6月10日，[*https://arxiv.org/abs/1701.08230*](https://arxiv.org/abs/1701.08230)。
- en: '^([6](ch51.xhtml#idm45346852099832-marker)) Gary Marcus, “Deep Learning: A
    Critical Appraisal,” Artificial Intelligence, Cornell University, January 2, 2018,
    [*https://arxiv.org/abs/1801.00631*](https://arxiv.org/abs/1801.00631).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch51.xhtml#idm45346852099832-marker)) Gary Marcus，“深度学习：一种批判性评估”，康奈尔大学人工智能，2018年1月2日，[*https://arxiv.org/abs/1801.00631*](https://arxiv.org/abs/1801.00631)。
