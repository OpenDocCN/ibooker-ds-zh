- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Working with unusual data
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 处理不寻常的数据
- en: '**This chapter covers**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**本章涵盖**'
- en: Dealing with various unusual data formats
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理各种不寻常的数据格式
- en: Parsing custom text file formats using regular expressions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则表达式解析自定义文本文件格式
- en: Using web scraping to extract data from web pages
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用网页抓取从网页中提取数据
- en: Working with binary data formats
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理二进制数据格式
- en: In the previous chapter, you learned how to import and export various standard
    and common data formats to the core data representation. In this chapter, we’re
    going to look at several of the more unusual methods of importing data that you
    might need to use from time to time.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了如何将各种标准和常见的数据格式导入到核心数据表示中。在本章中，我们将探讨一些你可能需要不时使用的更不寻常的数据导入方法。
- en: Continuing from chapter 3, let’s say that you’re maintaining a website about
    earthquakes and you need to accept new data from a variety of sources. In this
    chapter, we’ll explore several of the not-so-regular data formats you might need
    or want to support. [Table 4.1](#table4.1) shows the new data formats we’ll cover.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 从第3章继续，假设你正在维护一个关于地震的网站，并且需要从各种来源接受新数据。在本章中，我们将探讨你可能需要或希望支持的几个不太常见的数据格式。[表4.1](#table4.1)显示了我们将涵盖的新数据格式。
- en: Table 4.1 Data formats covered in chapter 4
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.1 第4章涵盖的数据格式
- en: '| **Data Format** | **Data Source** | **Notes** |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| **数据格式** | **数据源** | **备注** |'
- en: '| --- | --- | --- |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Custom text | Text file | Data sometimes comes in custom or proprietary text
    formats. |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| 自定义文本 | 文本文件 | 数据有时以自定义或专有文本格式出现。 |'
- en: '| HTML | Web server / REST API | Data can be scraped from HTML web pages when
    no other convenient access mechanism exists. |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| HTML | Web服务器/REST API | 当没有其他方便的访问机制时，可以从HTML网页中抓取数据。 |'
- en: '| Custom binary | Binary file | Data sometimes comes in custom or proprietary
    binary formats. Or we may choose to use binary data as a more compact representation.
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| 自定义二进制 | 二进制文件 | 数据有时以自定义或专有二进制格式出现。或者我们可能选择使用二进制数据作为更紧凑的表示形式。 |'
- en: In this chapter, we’ll add new tools to our toolkit for dealing with regular
    expressions, doing web scraping and decoding binary files. These tools are listed
    in [Table 4.2](#table4.2).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将为处理正则表达式、进行网页抓取和解码二进制文件添加新的工具到我们的工具箱中。这些工具列在[表4.2](#table4.2)中。
- en: Table 4.2 Chapter 4 tools
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.2 第4章工具
- en: '| **Data Source** | **Data Format** | **Tools** | **Functions** |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| **数据源** | **数据格式** | **工具** | **函数** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Custom text | Custom text | request-promise library | request.get, regular
    expressions |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 自定义文本 | 自定义文本 | request-promise库 | request.get, 正则表达式 |'
- en: '| Web scraping | HTML | request-promise and cheerio libraries | request.get,
    cheerio.load |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 网页抓取 | HTML | request-promise和cheerio库 | request.get, cheerio.load |'
- en: '| Binary files | Custom | Node.js file system API and Buffer class | fs.readFileSync
    fs.writeFileSync'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '| 二进制文件 | 自定义 | Node.js文件系统API和Buffer类 | fs.readFileSync fs.writeFileSync'
- en: Various Buffer functions |
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 各种缓冲函数 |
- en: '| Binary files | BSON | bson library | serialize and deserialize |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 二进制文件 | BSON | bson库 | serialize和deserialize |'
- en: 4.1 Getting the code and data
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.1 获取代码和数据
- en: In this chapter we continue to use the earthquakes data from chapter 3\. The
    code and data for this chapter are available in the Chapter-4 repository in the
    Data Wrangling with JavaScript GitHub organization at [https://github.com/data-wrangling-with-javascript/chapter-4](https://github.com/data-wrangling-with-javascript/chapter-4).
    Please download the code and install the dependencies. Refer to “Getting the code
    and data”*in chapter 2 if you need help with this.*
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们继续使用第3章中的地震数据。本章的代码和数据可在Data Wrangling with JavaScript GitHub组织中的Chapter-4仓库中找到，网址为[https://github.com/data-wrangling-with-javascript/chapter-4](https://github.com/data-wrangling-with-javascript/chapter-4)。请下载代码并安装依赖项。如需帮助，请参考“获取代码和数据”（第2章）。
- en: '*As was the case with chapter 3, the repository for chapter 4 contains the
    code for each code listing in separate JavaScript files in the same directory,
    and they are named according to the listing number. You can install all third-party
    dependencies for all code listings by running `npm install` once in the root directory
    of the repository.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*与第3章的情况一样，第4章的仓库包含每个代码列表的代码，分别存储在同一目录下的单独JavaScript文件中，并且它们根据列表编号命名。您可以通过在仓库的根目录中运行一次`npm
    install`来安装所有代码列表的所有第三方依赖项。'
- en: 4.2 Importing custom data from text files
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.2 从文本文件导入自定义数据
- en: Occasionally you might come across a custom, proprietary, or ad hoc text format
    for which no readily available JavaScript library exists. In cases like this,
    you must write custom parsing code to import your data to the core data representation.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 有时你可能会遇到一个自定义的、专有的或临时的文本格式，对于这种格式没有现成的 JavaScript 库。在这种情况下，你必须编写自定义解析代码来将你的数据导入核心数据表示。
- en: Although various methods exist for parsing, including implementing your own
    parser by hand, in this section I demonstrate parsing using regular expressions.
    After loading our example file earthquakes.txt into memory, we’ll use regular
    expressions to interpret the data and extract the interesting parts to the core
    data representation, as shown in [figure 4.1](#figure4.1).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在各种解析方法，包括手动实现自己的解析器，在本节中，我将演示使用正则表达式进行解析。在将我们的示例文件 earthquakes.txt 加载到内存后，我们将使用正则表达式来解释数据，并将有趣的部分提取到核心数据表示中，如图
    4.1 所示。
- en: '![c04_01.eps](Images/c04_01.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![c04_01.eps](Images/c04_01.png)'
- en: '[Figure 4.1](#figureanchor4.1) Importing a custom text file format to the core
    data representation'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.1](#figureanchor4.1) 将自定义文本文件格式导入核心数据表示'
- en: For the first example of regular expressions, we’ll parse the earthquakes.txt
    text file that was downloaded from the United States Geological Survey (USGS).
    As you can see in [figure 4.2](#figure4.2), earthquakes.txt looks similar to a
    CSV file, but rather than commas, it uses pipe symbols as field separators.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于正则表达式的第一个例子，我们将解析从美国地质调查局（USGS）下载的 earthquakes.txt 文本文件。如图 4.2 所示，earthquakes.txt
    看起来类似于 CSV 文件，但它使用管道符号而不是逗号作为字段分隔符。
- en: '![c04_02.eps](Images/c04_02.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![c04_02.eps](Images/c04_02.png)'
- en: '[Figure 4.2](#figureanchor4.2) Custom text format data file downloaded from
    the USGS'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.2](#figureanchor4.2) 从 USGS 下载的自定义文本格式数据文件'
- en: Regular expressions are a powerful tool, and they’re natively supported by JavaScript.
    They can help you deal with ad hoc or custom file formats, so you don’t need to
    hand-code a parser for every custom format that you come across.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式是一个强大的工具，并且它们在 JavaScript 中是原生支持的。它们可以帮助你处理临时或自定义的文件格式，因此你不需要为遇到的每个自定义格式手动编写解析器。
- en: Our first port of call when working with regular expressions should be to an
    online testing tool such as https://regex101.com. This tool, shown in [figure
    4.3](#figure4.3), allows us to create and test our regular expressions before
    getting anywhere near the code.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用正则表达式时，首先应该使用在线测试工具，例如 https://regex101.com。这个工具，如图 4.3 所示，允许我们在接近代码之前创建和测试我们的正则表达式。
- en: '![c04_03.eps](Images/c04_03.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![c04_03.eps](Images/c04_03.png)'
- en: '[Figure 4.3](#figureanchor4.3) Testing a regular expression with regex101.com'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.3](#figureanchor4.3) 使用 regex101.com 测试正则表达式'
- en: In this example, we’re going to use a simple regular expression, but they can
    be much more complex than this, and we can use them to parse much more complicated
    data formats. A big advantage of using regex101.com is that after we prototype
    and test our regular expression, we can then export working JavaScript code that
    can be included in our application.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用一个简单的正则表达式，但它们可以比这更复杂，我们可以使用它们来解析更复杂的数据格式。使用 regex101.com 的一个重大优势是，在我们原型化和测试我们的正则表达式之后，我们可以导出可以包含在我们的应用程序中的工作
    JavaScript 代码。
- en: After exporting the code from regex101.com, we must modify it so that it reads
    from earthquakes.txt. The resulting code and modifications are shown in the following
    listing. You can run this code from the chapter 4 GitHub repository, and it prints
    out the data that has been decoded by the regular expression.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在从 regex101.com 导出代码后，我们必须修改它，使其从 earthquakes.txt 读取。以下列表显示了结果代码和修改。您可以从第 4
    章的 GitHub 仓库运行此代码，并且它将打印出由正则表达式解码的数据。
- en: Listing 4.1 Importing data from custom text file earthquakes.txt (listing-4.1.js)
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.1 从自定义文本文件 earthquakes.txt 导入数据（listing-4.1.js）
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Notice that, unlike the examples of reading files that we’ve seen in chapter
    3, we haven’t saved a separate toolkit function from [listing 4.1](#listing4.1).
    This is a custom format, and it’s possible we’ll never see it again, so it might
    not be worthwhile creating a reusable toolkit function. In general, we only need
    to add a function to our toolkit when we’re sure we’ll see that data format again
    in the future.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，与我们在第 3 章中看到的读取文件示例不同，我们没有从 [列表 4.1](#listing4.1) 保存一个单独的工具包函数。这是一个自定义格式，我们可能永远不会再次看到它，所以可能不值得创建可重用的工具包函数。一般来说，我们只有在确定我们将来还会看到该数据格式时，才需要向我们的工具包中添加一个函数。
- en: In this example we didn’t add any code to our toolkit, although we did add a
    *technique* to our toolkit. You should recognize regular expressions as a powerful
    technique for parsing unusual data formats. Our first regular expression example
    barely scratched the surface of what’s possible, so let’s look at other examples
    to see where else regular expressions can take this.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们没有向我们的工具箱中添加任何代码，尽管我们确实添加了一种*技术*。你应该将正则表达式视为一种强大的技术，用于解析不寻常的数据格式。我们的第一个正则表达式示例只是触及了可能性的表面，所以让我们看看其他示例，看看正则表达式还能在其他哪些方面发挥作用。
- en: With regular expressions, we could create a much more sophisticated pattern
    for pulling apart each line of our data file. Do you want to ensure that the *Time*
    column is a date/time value? Then create a more advanced pattern that will only
    recognize data/time values for that column of data. The same goes for the other
    columns. You can tighten the pattern to accept only valid data for that column;
    this is a great way to validate that your incoming data conforms to the assumptions
    that you expect.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用正则表达式，我们可以为解析数据文件中的每一行创建一个更复杂的模式。你想要确保*时间*列是一个日期/时间值吗？那么创建一个更高级的模式，它只会识别该数据列的日期/时间值。其他列也是如此。你可以调整模式，只接受该列的有效数据；这是一种验证你的传入数据是否符合你预期的假设的好方法。
- en: Regular expressions are also great for picking out nested data. Say you get
    a data dump of customer comments (added through a form or maybe through email)
    and you need to pick out pertinent details such as the customer email and the
    score they’ve given a particular product.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式也非常适合提取嵌套数据。比如说，你得到了一份客户评论的数据（可能是通过表单或电子邮件添加的），你需要提取相关的细节，比如客户的电子邮件和他们对某个产品的评分。
- en: One thing that you’ll definitely want to use regular expressions for is parsing
    the log files generated by your app or server. This is a fairly regular use case
    for regular expressions—say when you want to extract runtime metrics and other
    details from your log files.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你一定会想用正则表达式来解析你的应用程序或服务器生成的日志文件。这是一个相当常见的正则表达式用例——比如说，当你想从日志文件中提取运行时指标和其他细节时。
- en: 'When you start working with regular expressions, you’ll find that your patterns
    grow complicated quickly. This is one of the downsides of regular expressions:
    you can quickly create unreadable patterns that are difficult to modify later.
    I’ll leave it to your discretion to further explore regular expressions if they
    sound useful to you.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始使用正则表达式时，你会发现你的模式很快就会变得复杂。这是正则表达式的一个缺点：你可以快速创建难以阅读的模式，这些模式在以后修改起来也很困难。如果你觉得正则表达式有用，我会将进一步的探索留给你自己决定。
- en: 4.3 Importing data by scraping web pages
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.3 通过抓取网页导入数据
- en: Sometimes we might see data in a web page that would be useful. We’d like to
    have that data, but there’s no convenient way to access it. We often find that
    important data is embedded in a web page and that the company or organization
    hasn’t shared it in any other way that’s convenient for us to download, such as
    a CSV file download or a REST API.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，我们可能会在网页上看到一些有用的数据。我们希望拥有这些数据，但没有任何方便的方法可以访问它们。我们经常发现，重要的数据被嵌入在网页中，而公司或组织没有以我们方便下载的任何其他方式共享它们，比如CSV文件下载或REST
    API。
- en: Ideally all organizations would share their data in a format that’s easy to
    import into our data pipeline. Unfortunately, though, there are occasionally times
    when *scraping* a web page, extracting the data from it, is the only way to obtain
    the data we need.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，所有组织都会以易于导入我们数据管道的格式共享他们的数据。然而，不幸的是，偶尔会有这样的情况，即*抓取*一个网页，从中提取数据，是我们获取所需数据的唯一途径。
- en: 'Web scraping is tedious, error-prone, and tiresome work. Your web scraping
    script depends on the structure of the page being scraped: if that structure changes,
    then your script will be broken. This makes web scraping scripts inherently fragile.
    For these reasons web scraping as a data source should be considered a last resort;
    you should use a more reliable alternative when possible.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 网页抓取是一项繁琐、易出错且令人疲惫的工作。你的网页抓取脚本依赖于被抓取页面的结构：如果这个结构发生变化，那么你的脚本就会失效。这使得网页抓取脚本本质上很脆弱。因此，将网页抓取作为数据源应被视为最后的手段；在可能的情况下，你应该使用更可靠的替代方案。
- en: 'If web scraping is the only way to access a data set, then we can do it easily
    in JavaScript, despite the aforementioned caveats. The first part is the same
    as importing data from a REST API from chapter 3: we can use `request-promise`
    to retrieve the web page. In this example, we’ll scrape earthquake data from the
    following URL: [https://earthquake.usgs.gov/earthquakes/browse/largest-world.php](https://earthquake.usgs.gov/earthquakes/browse/largest-world.php)[.](http://.)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果抓取网页是访问数据集的唯一方式，那么尽管存在上述警告，我们也可以轻松地在 JavaScript 中完成它。第一部分与第 3 章中从 REST API
    导入数据相同：我们可以使用 `request-promise` 来检索网页。在这个例子中，我们将从以下 URL 抓取地震数据：[https://earthquake.usgs.gov/earthquakes/browse/largest-world.php](https://earthquake.usgs.gov/earthquakes/browse/largest-world.php)[.](http://.)
- en: With the web page downloaded into memory, we’ll use the third-party library
    Cheerio to extract the data from the web page and convert it to the core data
    representation. The process is shown in [figure 4.4](#figure4.4).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当网页下载到内存中时，我们将使用第三方库 Cheerio 从网页中提取数据并将其转换为核心数据表示。这个过程在 [图 4.4](#figure4.4)
    中展示。
- en: '![c04_04.eps](Images/c04_04.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![c04_04.eps](Images/c04_04.png)'
- en: '[Figure 4.4](#figureanchor4.4) Importing data by scraping a web page'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.4](#figureanchor4.4) 通过抓取网页导入数据'
- en: 4.3.1 Identifying the data to scrape
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.1 确定要抓取的数据
- en: We should start any web scraping project by first using our web browser to inspect
    the web page. [Figure 4.5](#figure4.5) shows the largest earthquakes web page
    as viewed in Chrome.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该首先使用我们的网页浏览器来检查网页。[图 4.5](#figureanchor4.5) 展示了在 Chrome 中查看的最大地震网页。
- en: '![c04_05.eps](Images/c04_05.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![c04_05.eps](Images/c04_05.png)'
- en: '[Figure 4.5](#figureanchor4.5) Viewing the largest earthquakes web page in
    a web browser prior to scraping'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.5](#figureanchor4.5) 在抓取之前在网页浏览器中查看最大的地震网页'
- en: Before we start coding, we must determine the HTML elements and CSS classes
    that identify the data embedded in the page. [Figure 4.6](#figure4.6) shows an
    inspection of the page’s element hierarchy using Chrome’s debug tools. The interesting
    elements are `tbody`, `tr,` and `td`; these elements make up the HTML table that
    contains the data.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始编码之前，我们必须确定识别页面中嵌入数据的 HTML 元素和 CSS 类。[图 4.6](#figureanchor4.6) 展示了使用 Chrome
    的调试工具检查页面元素层次结构。有趣的元素是 `tbody`、`tr` 和 `td`；这些元素构成了包含数据的 HTML 表格。
- en: 4.3.2 Scraping with Cheerio
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3.2 使用 Cheerio 抓取
- en: 'We can now identify the data in the web page, and we’re ready to get into the
    code. If you installed all dependencies for the chapter 4 code repository, then
    you already have Cheerio installed. If not, you can install Cheerio in a fresh
    Node.js project as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以识别网页中的数据，并且我们已经准备好进入代码。如果你已经安装了第 4 章代码仓库的所有依赖项，那么你已经有 Cheerio 安装了。如果没有，你可以在新的
    Node.js 项目中安装 Cheerio，如下所示：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Cheerio is a fantastic library that is modeled on jQuery, so if you’re already
    comfortable with jQuery, you’ll be at home with Cheerio. [Listing 4.2](#listing4.2)
    is a working example that scrapes the largest earthquakes web page and extracts
    the embedded data to the core data representation. You can run this code, and
    it will print the scraped data to the console.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Cheerio 是一个基于 jQuery 构建的出色库，因此如果你已经熟悉 jQuery，那么你会在 Cheerio 中感到宾至如归。[列表 4.2](#listing4.2)
    是一个工作示例，它抓取了最大的地震网页并提取了嵌入的数据到核心数据表示。你可以运行此代码，它将抓取的数据打印到控制台。
- en: Listing 4.2 Importing data by scraping a web page (listing-4.2.js)
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.2 通过抓取网页导入数据（列表-4.2.js）
- en: '[PRE2]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Notice that this is another instance, similar to parsing a custom text file,
    where we don’t necessarily need to add a reusable function to our toolkit. Scraping
    a website is such a custom job that there might be little chance to use this same
    code again. We find here that it’s the *technique*, the ability to scrape a website,
    that we’ve added to our toolkit and not the reusable code.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这又是一个实例，类似于解析自定义文本文件，我们不一定需要将可重用函数添加到我们的工具箱中。抓取网站是一项如此定制的任务，以至于很少有机会再次使用相同的代码。我们发现，我们添加到工具箱中的是
    *技术*，即抓取网站的能力，而不是可重用代码。
- en: 4.4 Working with binary data
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4.4 处理二进制数据
- en: It might seem rare, but on occasion as a JavaScript developer, you might need
    or want to work with a binary data format.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可能看起来很少见，但有时作为一个 JavaScript 开发者，你可能会需要或想要处理二进制数据格式。
- en: The first question you should always ask is, “Why?” Given that we already have
    great data formats to work with, such as JSON and CSV, then why work with binary
    data?
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该始终问的第一个问题是，“为什么？”鉴于我们已经有很好的数据格式可以工作，例如 JSON 和 CSV，那么为什么还要处理二进制数据？
- en: Well, the first consideration is that maybe that’s the data that we’re given
    to work with. In the context of the earthquakes website, let’s say we are given
    a binary data dump for earthquakes data. In this case, we need to unpack the binary
    data so that we can work with it.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，首先考虑的是，也许这就是我们用来工作的数据。在地震网站的情况下，让我们假设我们得到了地震数据的二进制数据转储。在这种情况下，我们需要解包二进制数据，以便我们可以处理它。
- en: That’s one reason we might work with binary data, but here’s another. Binary
    data is much more compact than JSON or CSV data. For example, the binary file
    that we’ll look at in a moment, earthquakes.bin, is 24% of the size of the equivalent
    JSON file. That’s a significant saving for disk space and network bandwidth!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们可能处理二进制数据的一个原因，但还有另一个原因。二进制数据比JSON或CSV数据更紧凑。例如，我们即将查看的二进制文件earthquakes.bin的大小是等效JSON文件大小的24%。这对磁盘空间和网络带宽来说是一个显著的节省！
- en: Another reason to choose a binary data format might be due to performance. If
    you hand-code a binary serializer and optimize the heck out of it, you can achieve
    better performance than JSON serialization. But I wouldn’t put too much hope into
    this reason. The built-in JSON serializer is already well optimized and extremely
    fast. You’ll have to be smart and work pretty hard to beat it!
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 选择二进制数据格式的另一个原因可能是由于性能。如果你手动编写二进制序列化器并将其优化到极致，你可以实现比JSON序列化更好的性能。但我不会对这个原因寄予太多希望。内置的JSON序列化器已经非常优化且非常快。你必须聪明并非常努力才能打败它！
- en: Maybe turn to binary data files if you have to or if you need to use a more
    compact format. But think carefully before turning to a binary format to improve
    performance. It might be more difficult than you expect to achieve a performance
    gain, and you can easily make performance worse!
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你必须这样做或者你需要使用更紧凑的格式，也许可以转向二进制数据文件。但在转向二进制格式以提高性能之前，要仔细思考。可能比你预期的更难实现性能提升，而且你很容易使性能变得更差！
- en: Here’s one good reason why we shouldn’t use binary files. Text-based data formats
    are human readable, and we can open them and read them without the need for a
    special viewer app. Don’t underestimate how important this is! It’s a huge help
    when we’re trying to understand or debug a data file to open and view that file
    in a text editor.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个很好的理由说明为什么我们不应该使用二进制文件。基于文本的数据格式是可读的，我们可以打开并阅读它们，而无需特殊查看器应用程序。不要低估这一点的重要性！当我们试图理解或调试数据文件时，在文本编辑器中打开和查看该文件非常有帮助。
- en: '![c04_06.eps](Images/c04_06.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![c04_06.eps](Images/c04_06.png)'
- en: '[Figure 4.6](#figureanchor4.6) Using Chrome devtools to identify HTML elements
    containing data to be scraped'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4.6](#figureanchor4.6) 使用Chrome开发者工具识别包含要抓取数据HTML元素'
- en: 4.4.1 Unpacking a custom binary file
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.1 解包自定义二进制文件
- en: Let’s say you’ve been given the binary file earthquakes.bin and you need to
    import it into your database. How can you decode this file?
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你被给了二进制文件earthquakes.bin，并且你需要将其导入到你的数据库中。你如何解码这个文件？
- en: For a start, you need an idea of how the binary file is structured. This isn’t
    a text-based format, so you can’t peruse it in a text editor to understand it.
    Let’s assume that the provider of the binary file has explained the layout of
    the file to us. They’ve said that it’s a sequence of binary records packed one
    after the other ([figure 4.7](#figure4.7)). The file starts by specifying the
    *number of records* that it contains, and you can see the *Num records* field
    at the start of the file in [figure 4.7](#figure4.7).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要了解二进制文件的结构。这不是基于文本的格式，所以你不能在文本编辑器中浏览它来理解它。假设二进制文件的提供者已经向我们解释了文件布局。他们说过，这是一个由一系列依次打包的二进制记录组成的序列（[图4.7](#figure4.7)）。文件首先指定它包含的*记录数*，你可以在[图4.7](#figure4.7)中看到文件开头的*Num
    records*字段。
- en: '![c04_07.png](Images/c04_07.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![c04_07.png](Images/c04_07.png)'
- en: '[Figure 4.7](#figureanchor4.7) Earthquakes.bin is a binary file that contains
    a sequence of packed records, one after the other.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4.7](#figureanchor4.7) Earthquakes.bin是一个包含一系列依次打包记录的二进制文件。'
- en: The provider of our data has also explained that each record describes an earthquake
    through a series of values ([figure 4.8](#figure4.8)). These are double-precision
    numbers (the standard number format for JavaScript) that indicate the time, location,
    depth, and magnitude of each earthquake.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据提供者还解释说，每个记录通过一系列值来描述一次地震（[图4.8](#figure4.8)）。这些是双精度数字（JavaScript的标准数字格式），表示每次地震的时间、位置、深度和震级。
- en: '![c04_08.png](Images/c04_08.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![c04_08.png](Images/c04_08.png)'
- en: '[Figure 4.8](#figureanchor4.8) Each data record is a sequence of packed values
    that describe an earthquake.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.8](#figureanchor4.8) 每个数据记录是一系列打包的值，描述了一个地震。'
- en: To work with binary files, we’ll use the Node.js file system functions. We’ll
    use the synchronous functions—for example, `readFileSync—`because they make the
    code simpler, although in production you’ll probably want to use asynchronous
    versions for performance of your server. In chapter 3, we read text files into
    memory as strings; here, though, we’ll read our binary file earthquakes.bin into
    a Node.js `Buffer` object.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理二进制文件，我们将使用 Node.js 文件系统函数。我们将使用同步函数——例如，`readFileSync—`因为它们使代码更简单，尽管在生产环境中你可能会想使用异步版本以提高服务器的性能。在第
    3 章中，我们将文本文件作为字符串读入内存；然而，在这里，我们将我们的二进制文件 earthquakes.bin 读入一个 Node.js `Buffer`
    对象。
- en: You can see the steps for this process in [figure 4.9](#figure4.9). First, you
    call `readFileSync` to load earthquakes.bin to a buffer (1). Then you’ll read
    the number of records from the buffer (2). You then start a loop that reads each
    record from the buffer in sequence (3). The fields of the record are extracted
    and used to construct a JavaScript object (4) that’s added to your array of records.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图 4.9 中看到这个过程的步骤。首先，你调用 `readFileSync` 将 earthquakes.bin 载入缓冲区（1）。然后，你将从缓冲区中读取记录数（2）。接下来，你开始一个循环，按顺序从缓冲区中读取每个记录（3）。记录的字段被提取并用于构建一个
    JavaScript 对象（4），该对象被添加到你的记录数组中。
- en: '![c04_09.eps](Images/c04_09.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![c04_09.eps](Images/c04_09.png)'
- en: '[Figure 4.9](#figureanchor4.9) Reading records from earthquakes.bin using a
    Node.js Buffer object'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.9](#figureanchor4.9) 使用 Node.js 缓冲区对象从 earthquakes.bin 读取记录'
- en: '[Figure 4.10](#figure4.10) depicts the construction of the JavaScript object
    that represents an earthquake record. Time (1), latitude (2), and the other fields
    (3) are read from the buffer and assigned to the JavaScript object.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.10](#figure4.10) 描述了表示地震记录的 JavaScript 对象的构建。时间（1）、纬度（2）和其他字段（3）从缓冲区中读取并分配给
    JavaScript 对象。'
- en: The code to unpack earthquakes.bin is remarkably simple, as you can see in the
    following listing. You can run this code, and it will decode the example binary
    file and print the data to the console.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 解码 earthquakes.bin 的代码非常简单，如下所示。你可以运行此代码，它将解码示例二进制文件并将数据打印到控制台。
- en: Listing 4.3 Unpacking the earthquakes.bin binary files with a Node.js Buffer
    object (listing-4.3.js)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.3 使用 Node.js 缓冲区对象解包 earthquakes.bin 二进制文件（listing-4.3.js）
- en: '[PRE3]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![c04_10.eps](Images/c04_10.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![c04_10.eps](Images/c04_10.png)'
- en: '[Figure 4.10](#figureanchor4.10) Reading fields from a binary earthquake record
    to a JavaScript object'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.10](#figureanchor4.10) 从二进制地震记录中读取字段到 JavaScript 对象'
- en: 4.4.2 Packing a custom binary file
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.2 打包自定义二进制文件
- en: In the previous example, we were given earthquakes.bin, a binary file that we
    had to decode to make use of the data that it contained. You might be curious
    to know how such a file is created in the first place.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个例子中，我们得到了 earthquakes.bin，这是一个二进制文件，我们必须解码它才能使用其中包含的数据。你可能很好奇这样一个文件最初是如何创建的。
- en: Packing earthquakes.bin is essentially the reverse of the process we went through
    to unpack it. We start with an array of JavaScript objects that represents the
    earthquakes. As you can see in [figure 4.11](#figure4.11), the fields of an earthquake
    object are packed sequentially to form a binary record. First, the Time field
    is packed (1), followed by the Latitude field (2), and so on until all the fields
    are packed (3) into the buffer.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 打包 earthquakes.bin 实质上是与我们解包它的过程相反。我们从一个表示地震的 JavaScript 对象数组开始。如图 4.11 所示，地震对象的字段是顺序打包以形成一个二进制记录。首先，时间字段被打包（1），然后是纬度字段（2），依此类推，直到所有字段都被打包（3）到缓冲区中。
- en: '![c04_11.eps](Images/c04_11.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![c04_11.eps](Images/c04_11.png)'
- en: '[Figure 4.11](#figureanchor4.11) Packing fields from a JavaScript earthquake
    object into a Node.js buffer'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.11](#figureanchor4.11) 将 JavaScript 地震对象中的字段打包到 Node.js 缓冲区'
- en: You can see in [figure 4.12](#figure4.12) that each record is tightly packed,
    one after the other, into the buffer. We start by creating a Node.js `Buffer`
    object (1). Before writing records to the buffer, we must first record the number
    of records (2), because this allows us to know how many records to expect when
    we later decode the binary file. Then we pack each earthquake record sequentially
    into the buffer (3). Finally, the buffer is written out to our binary file earthquakes.bin
    (4). That’s how we produce the file that was given to us in the earlier example.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[图 4.12](#figure4.12)中看到，每个记录都是紧密地一个接一个地打包到缓冲区中。我们首先创建一个 Node.js `Buffer`
    对象（1）。在将记录写入缓冲区之前，我们必须首先记录记录数（2），因为这允许我们了解在稍后解码二进制文件时预期的记录数。然后我们按顺序将每个地震记录打包到缓冲区中（3）。最后，缓冲区被写入我们的二进制文件
    earthquakes.bin（4）。这就是我们产生之前示例中给出的文件的方法。
- en: The code to convert earthquakes.json to our custom binary format is shown in
    [listing 4.4](#listing4.4); this is a bit more complicated than the code required
    to unpack it, but not by much. You can run this code, and it will read the example
    data from earthquakes.json, pack the data into the binary buffer, and then produce
    the output file earthquakes.bin. If you want to test that the output earthquakes.bin
    is a valid file, you could run it back through the code in [listing 4.3](#listing4.3)
    to test that it can be subsequently unpacked.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 将 earthquakes.json 转换为我们自定义的二进制格式的代码显示在[列表 4.4](#listing4.4)中；这比解包所需的代码复杂一些，但差别不大。你可以运行此代码，它将从
    earthquakes.json 中读取示例数据，将数据打包到二进制缓冲区中，然后生成输出文件 earthquakes.bin。如果你想测试生成的 earthquakes.bin
    是否是一个有效的文件，你可以将其再次通过[列表 4.3](#listing4.3)中的代码运行，以测试它是否可以被随后解包。
- en: '![c04_12.png](Images/c04_12.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![c04_12.png](Images/c04_12.png)'
- en: '[Figure 4.12](#figureanchor4.12) Writing earthquake records to our binary file
    earthquakes.bin'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 4.12](#figureanchor4.12) 将地震记录写入我们的二进制文件 earthquakes.bin'
- en: Listing 4.4 Packing the binary file earthquakes.bin using a Node.js buffer (listing-4.4.js)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.4 使用 Node.js 缓冲区打包二进制文件 earthquakes.bin（listing-4.4.js）
- en: '[PRE4]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note that a dependency on moment was introduced here. This is the fantastic
    library for dealing with dates and times that we first installed in chapter 2.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这里引入了对 moment 的依赖。这是我们首次在第 2 章中安装的用于处理日期和时间的出色库。
- en: Creating our own custom binary data formats is problematic. The code is messy
    and gets much more complicated if we want to handle larger files. The output format
    isn’t human readable, so unless we document the structure of the format, we run
    the risk of forgetting how it works. This might make it difficult to decode our
    data in the future.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 创建我们自己的自定义二进制数据格式是有问题的。代码杂乱无章，如果我们想要处理更大的文件，代码会变得更加复杂。输出格式不是人类可读的，所以除非我们记录格式的结构，否则我们可能会忘记它是如何工作的。这可能会使得未来解码我们的数据变得困难。
- en: 'You have another option, however, if you want the best of both worlds. You
    want something with the convenience and reliability of JSON, but with the compactness
    of binary data: then let me present you with BSON (pronounced *bison*).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你想要两者兼得，你还有一个选择。你想要的是既有 JSON 的便利性和可靠性，又有二进制数据的紧凑性：那么让我向你介绍 BSON（发音为 *bison*）。
- en: 4.4.3 Replacing JSON with BSON
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.3 用 BSON 替换 JSON
- en: BSON, or binary JSON, is a binary encoded serialization of JSON. Although you
    can’t open a BSON file in a text editor, it is (like JSON) a self-describing format.
    You don’t need documentation to understand or remember how to decode the data
    file.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: BSON，或二进制 JSON，是 JSON 的二进制编码序列化。虽然你不能在文本编辑器中打开 BSON 文件，但它（像 JSON 一样）是一个自描述的格式。你不需要文档来理解或记住如何解码数据文件。
- en: BSON is a standard and mature data format. It’s the format that underlies MongoDB.
    It’s almost a drop-in replacement for JSON, and it’s easy to convert between JSON
    and BSON.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: BSON 是一个标准且成熟的数据格式。它是 MongoDB 的基础格式。它几乎可以无缝替换 JSON，并且很容易在 JSON 和 BSON 之间进行转换。
- en: BSON will allow you to store your JSON in a more compact way. This might be
    useful if you are trying to save disk space or network bandwidth. BSON won’t gain
    you anything in performance, though, because it’s slightly slower than JSON serialization.
    To use BSON, you therefore must make a tradeoff between size and performance.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: BSON 将允许你以更紧凑的方式存储你的 JSON。如果你试图节省磁盘空间或网络带宽，这可能很有用。但是，BSON 在性能上不会给你带来任何好处，因为它比
    JSON 序列化稍微慢一些。因此，要使用 BSON，你必须在大小的性能之间做出权衡。
- en: 4.4.4 Converting JSON to BSON
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.4 将 JSON 转换为 BSON
- en: Let’s say that we have a JSON file called earthquakes.json that’s taking up
    too much space on our disk. Let’s convert this file to the BSON format so that
    it takes up less space.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个名为earthquakes.json的JSON文件，它占用了我们磁盘上太多的空间。让我们将此文件转换为BSON格式，以便它占用更少的空间。
- en: 'In these couple of examples, we’ll use the `bson` library. You’ll already have
    it if you installed dependencies for the Chapter-4 code repository, or you can
    install it in a fresh Node.js project as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个示例中，我们将使用`bson`库。如果你已经为第4章代码仓库安装了依赖项，那么你将已经拥有它；或者你可以在新的Node.js项目中按照以下方式安装它：
- en: '[PRE5]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[Listing 4.5](#listing4.5) shows how to convert earthquakes.json to a BSON
    file. We instance the `BSON` object and use its `serialize` function to convert
    our JavaScript data to the binary BSON format. The result is a Node.js `Buffer`
    object that we write to our new data file earthquakes.bson. You can run the code
    for the following listing, and it will convert the example file earthquakes.json
    to the BSON file earthquakes.bson.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表4.5](#listing4.5) 展示了如何将earthquakes.json转换为BSON文件。我们实例化`BSON`对象，并使用其`serialize`函数将我们的JavaScript数据转换为二进制BSON格式。结果是写入我们新数据文件earthquakes.bson的Node.js
    `Buffer`对象。你可以运行以下列表中的代码，它将示例文件earthquakes.json转换为BSON文件earthquakes.bson。'
- en: Listing 4.5 Converting JSON data to BSON (listing-4.5.js)
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.5 将JSON数据转换为BSON（listing-4.5.js）
- en: '[PRE6]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 4.4.5 Deserializing a BSON file
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4.5 反序列化BSON文件
- en: Later on, when we need to decode earthquakes.bson, we can deserialize it back
    to JavaScript data using the `bson` library. We first load the file to a Node.js
    `Buffer` object. We then instance a `BSON` object and use its `deserialize` function
    to decode the data in the buffer. Last, we print our reconstituted JavaScript
    data structure to the console to verify that the data is correct. The code is
    presented in [listing 4.6](#listing4.6), and you can run it on the example BSON
    file to convert it to the equivalent JSON representation. You might even want
    to try running the following listing on the BSON file that you generated earlier
    with the [listing 4.5](#listing4.5) code. You should be able to loop your files
    through [listing 4.5](#listing4.5), then [listing 4.6](#listing4.6), and back
    to [listing 4.5](#listing4.5) and so on.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在之后，当我们需要解码earthquakes.bson时，我们可以使用`bson`库将其反序列化回JavaScript数据。我们首先将文件加载到Node.js
    `Buffer`对象中。然后实例化一个`BSON`对象，并使用其`deserialize`函数解码缓冲区中的数据。最后，我们将重构的JavaScript数据结构打印到控制台以验证数据是否正确。代码在[列表4.6](#listing4.6)中展示，你可以在示例BSON文件上运行它以将其转换为等效的JSON表示。你可能甚至想尝试在之前使用[列表4.5](#listing4.5)代码生成的BSON文件上运行以下列表。你应该能够通过[列表4.5](#listing4.5)，然后[列表4.6](#listing4.6)，再回到[列表4.5](#listing4.5)等等的方式循环处理你的文件。
- en: Listing 4.6 Deserializing BSON data (listing-4.6.js)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.6 反序列化BSON数据（listing-4.6.js）
- en: '[PRE7]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the previous chapter, you learned about importing and exporting various data
    formats. In this chapter, you extended that knowledge to cover several of the
    more esoteric methods of acquiring and storing data. We now have several important
    data-wrangling fundamentals out of the way. In chapter 5, we’ll move on and learn
    the value of exploratory coding for prototyping code and understanding our data.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了导入和导出各种数据格式。在这一章中，你扩展了这方面的知识，涵盖了获取和存储数据的几种更神秘的方法。我们现在已经解决了几个重要的数据处理基础问题。在第5章中，我们将继续前进，学习探索性编码在原型设计和理解数据方面的价值。
- en: Summary
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: You learned how to deal with unusual data formats.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你学习了如何处理不寻常的数据格式。
- en: We discussed parsing custom text file formats using regular expressions.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们讨论了使用正则表达式解析自定义文本文件格式。
- en: We did web scraping to extract data from web pages using `request-promise` and
    Cheerio.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`request-promise`和Cheerio进行了网页抓取，以从网页中提取数据。
- en: We worked through examples of packing and unpacking custom binary formats.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过打包和解包自定义二进制格式的示例进行了操作。
- en: You learned how to work with binary data formats using BSON.*
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你学习了如何使用BSON处理二进制数据格式。*
