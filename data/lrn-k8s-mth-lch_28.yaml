- en: appendix B. Adding observability with containerized monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 B. 通过容器化监控添加可观察性
- en: Autonomous applications scale themselves up and down to meet incoming traffic,
    and they heal themselves when there are intermittent faults. It sounds too good
    to be true—and it probably is. The container platform can do a lot of the operations
    work for you if you build your Docker images with health checks, but you still
    need ongoing monitoring and alerting so humans can get involved when things go
    badly wrong. If you don’t have any insight into your containerized application,
    that’s going to be the number one thing that stops you going to production.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 自主应用程序会根据传入流量自动扩展和缩减，并在出现间歇性故障时自我修复。这听起来太好了，以至于可能不太真实——可能确实如此。如果你在构建 Docker
    镜像时包含健康检查，容器平台可以为你完成很多操作工作，但你仍然需要持续的监控和警报，以便在事情变得糟糕时人类可以介入。如果你对你的容器化应用程序没有任何洞察，这将是你无法进入生产环境的头号障碍。
- en: 'Observability is a critical piece of the software landscape when you’re running
    applications in containers—it tells you what your applications are doing and how
    well they’re performing, and it can help you pinpoint the source of problems.
    In this chapter you’ll learn how to use a well-established approach to monitoring
    with Docker: exposing metrics from your application containers and using Prometheus
    to collect them and Grafana to visualize them in user-friendly dashboards. These
    tools are open source and cross-platform, and they run in containers alongside
    your application. That means you get the same insight into your application performance
    in every environment, from development to production.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在容器中运行应用程序时，可观察性是软件景观中的一个关键部分——它告诉你应用程序在做什么以及它们的性能如何，并且可以帮助你定位问题的根源。在本章中，你将学习如何使用与
    Docker 相结合的成熟监控方法：从你的应用程序容器中公开指标，并使用 Prometheus 收集它们，使用 Grafana 在用户友好的仪表板中可视化它们。这些工具是开源的，跨平台的，并且与你的应用程序一起在容器中运行。这意味着你可以在从开发到生产的每个环境中获得对应用程序性能的相同洞察。
- en: This appendix is reproduced from chapter 9, "Adding Observability with Containerized
    Monitoring," from *Learn Docker in a Month of Lunches* by Elton Stoneman (Manning,
    2020). Any chapter references or references to code repositories refer to the
    chapters or code repositories of that book.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录摘自 Elton Stoneman 所著的《Learn Docker in a Month of Lunches》（Manning，2020）的第
    9 章，“通过容器化监控添加可观察性”。任何章节引用或对代码仓库的引用都指该书的相关章节或代码仓库。
- en: B.1 The monitoring stack for containerized applications
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.1 容器化应用程序的监控堆栈
- en: Monitoring is different when apps are running in containers. In a traditional
    environment, you might have a monitoring dashboard showing a list of servers and
    their current utilization—disk space, memory, CPU—and alerts to tell you if any
    become overworked and are likely to stop responding. Containerized apps are more
    dynamic—they may run across dozens or hundreds of containers that are short-lived
    and are created or removed by the container platform.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用程序在容器中运行时，监控方式有所不同。在传统环境中，你可能有一个监控仪表板显示服务器列表及其当前利用率——磁盘空间、内存、CPU——以及警报来告诉你是否有任何服务器过载并且可能停止响应。容器化应用程序更加动态——它们可能运行在数十或数百个短暂存在的容器中，这些容器由容器平台创建或删除。
- en: You need a monitoring approach that is container—aware, with tools that can
    plug into the container platform for discovery and find all the running applications
    without a static list of container IP addresses. Prometheus is an open source
    project that does just that. It’s a mature product that is overseen by the Cloud
    Native Computing Foundation (the same foundation behind Kubernetes and the containerd
    container runtime). Prometheus runs in a Docker container, so you can easily add
    a monitoring stack to your applications. Figure B.1 shows what that stack looks
    like.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要一个容器感知的监控方法，使用能够连接到容器平台进行发现并找到所有运行中的应用程序的工具，而无需静态的容器 IP 地址列表。Prometheus 是一个开源项目，正是这样做的。它是一个成熟的产品，由云原生计算基金会（Kubernetes
    和 containerd 容器运行时的背后基金会）监督。Prometheus 在 Docker 容器中运行，因此你可以轻松地为你的应用程序添加监控堆栈。图
    B.1 展示了该堆栈的外观。
- en: '![](../Images/B-1.jpg)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![图 B.1 监控容器化应用程序的监控堆栈](../Images/B-1.jpg)'
- en: Figure B.1 Running Prometheus in a container to monitor other containers and
    Docker itself
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.1 在容器中运行 Prometheus 以监控其他容器和 Docker 本身
- en: 'Prometheus brings one very important aspect to monitoring: consistency. You
    can export the same type of metrics for all your applications, so you have a standard
    way to monitor them whether they’re .NET apps in Windows containers or Node.js
    apps in Linux containers. You only have one query language to learn, and you can
    apply it for your whole application stack.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 为监控带来了一个非常重要的方面：一致性。您可以导出所有应用程序的相同类型的指标，因此您有一个标准的方式来监控它们，无论它们是 Windows
    容器中的 .NET 应用还是 Linux 容器中的 Node.js 应用。您只需学习一种查询语言，就可以将其应用于整个应用程序堆栈。
- en: Another good reason for using Prometheus is that the Docker Engine can also
    export metrics in that format, which gives you insight into what’s happening in
    the container platform too. You need to explicitly enable Prometheus metrics in
    your Docker Engine configuration. You can edit the `daemon.json` file directly
    in `C:\ProgramData\docker\config` on Windows, or `/etc/docker` on Linux. Alternatively,
    on Docker Desktop you can right-click the whale icon, choose Settings, and edit
    the configuration in the Daemon section.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Prometheus 的另一个好理由是 Docker 引擎也可以以该格式导出指标，这使您能够深入了解容器平台正在发生的事情。您需要在 Docker
    引擎配置中显式启用 Prometheus 指标。在 Windows 上，您可以直接在 `C:\ProgramData\docker\config` 中编辑
    `daemon.json` 文件，或在 Linux 上的 `/etc/docker`。或者，在 Docker Desktop 上，您可以通过右键单击鲸鱼图标，选择设置，并在守护进程部分编辑配置。
- en: 'Try it now Open your configuration settings and add two new values:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 打开您的配置设置并添加两个新值：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: These settings enable monitoring and publish metrics on port 9323.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设置启用了监控并在端口 9323 上发布指标。
- en: You can see my full configuration file in figure B.2.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在图 B.2 中看到我的完整配置文件。
- en: '![](../Images/B-2.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/B-2.jpg)'
- en: Figure B.2 Configuring the Docker Engine to export metrics in Prometheus format
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.2 配置 Docker 引擎以导出 Prometheus 格式的指标
- en: Docker Engine metrics are currently an experimental feature, which means the
    details it provides could change. But it’s been an experimental feature for a
    long time, and it’s been stable. It’s worth including in your dashboards because
    it adds another layer of detail to the overall health of your system. Now that
    you have metrics enabled, you can browse to http://localhost:9323/metrics and
    see all the information Docker provides. Figure B.3 shows my metrics, which include
    information about the machine Docker is running on as well as the containers Docker
    is managing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 引擎指标目前是一个实验性功能，这意味着它提供的详细信息可能会改变。但它已经是一个实验性功能很长时间了，并且已经稳定。值得将其包含在您的仪表板中，因为它为系统的整体健康状况添加了另一层细节。现在您已经启用了指标，您可以浏览到
    http://localhost:9323/metrics 并查看 Docker 提供的所有信息。图 B.3 显示了我的指标，包括 Docker 运行的机器信息以及
    Docker 管理的容器信息。
- en: '![](../Images/B-3.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/B-3.jpg)'
- en: Figure B.3 Sample metrics captured by Docker and exposed through the HTTP API
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.3 Docker 捕获的样本指标并通过 HTTP API 暴露
- en: This output is in Prometheus format. It’s a simple text-based representation
    where each metric is shown with its name and value, and the metric is preceded
    by some help text stating what the metric is and the type of data. These basic
    lines of text are the core of your container—monitoring solution. Each component
    will expose an endpoint like this providing current metrics; when Prometheus collects
    them, it adds a timestamp to the data and stores them with all the previous collections,
    so you can query data with aggregations or track changes over time.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 此输出格式为 Prometheus。它是一种简单的基于文本的表示，其中每个指标都显示其名称和值，指标前有一些帮助文本说明指标是什么以及数据类型。这些基本的文本行是您容器监控解决方案的核心。每个组件都会暴露一个类似这样的端点，提供当前指标；当
    Prometheus 收集它们时，会在数据中添加时间戳，并将它们与所有之前的收集存储在一起，因此您可以查询聚合数据或跟踪随时间的变化。
- en: 'Try it now You can run Prometheus in a container to read the metrics from your
    Docker machine, but first you need to get the machine’s IP address. Containers
    don’t know the IP address of the server they’re running on, so you need to find
    it first and pass it as an environment variable to the container:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 您可以在容器中运行 Prometheus 以读取 Docker 机器的指标，但首先您需要获取机器的 IP 地址。容器不知道它们运行的服务器的
    IP 地址，因此您需要先找到它，并将其作为环境变量传递给容器：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The configuration in the `diamol/prometheus` Prometheus image uses the `DOCKER_
    HOST` IP address to talk to your host machine and collect the metrics you’ve configured
    in the Docker Engine. It’s rare that you’ll need to access a service on the host
    from inside the container, and if you do, you would usually use your server name
    and Docker would find the IP address. In a development environment that might
    not work, but the IP address approach should be fine.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在`diamol/prometheus` Prometheus镜像中的配置使用`DOCKER_HOST` IP地址与你的主机机器通信并收集你在Docker
    Engine中配置的指标。通常情况下，你不需要从容器内部访问主机上的服务，如果你这样做，你通常会使用你的服务器名称，Docker会找到IP地址。在一个开发环境中，这可能不起作用，但IP地址方法应该没问题。
- en: 'Prometheus is running now. It does several things: it runs a scheduled job
    to pull the metrics from your Docker host, it stores those metric values alongside
    a timestamp in its own database, and it has a basic web UI you can use to navigate
    the metrics. The Prometheus UI shows all the information from Docker’s `/metrics`
    endpoint, and you can filter the metrics and display them in tables or graphs.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus现在正在运行。它执行几件事情：它运行一个计划任务从你的Docker主机拉取指标，它将这些指标值及其时间戳存储在其自己的数据库中，并且它有一个基本的Web
    UI，你可以用它来导航指标。Prometheus UI显示了Docker的`/metrics`端点的所有信息，你可以过滤指标并在表格或图形中显示它们。
- en: Try it now Browse to http://localhost:9090 and you’ll see the Prometheus web
    interface. You can check that Prometheus can access the metrics by browsing to
    the Status > Targets menu option. Your `DOCKER_HOST` state should be green, which
    means Prometheus has found it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 浏览到http://localhost:9090，你会看到Prometheus的Web界面。你可以通过浏览到状态 > 目标菜单选项来检查Prometheus是否可以访问指标。你的`DOCKER_HOST`状态应该是绿色的，这意味着Prometheus已经找到了它。
- en: Then switch to the Graph menu and you’ll see a dropdown list showing all the
    available metrics that Prometheus has collected from Docker. One of those is `engine_daemon_container_actions_seconds_sum`,
    which is a record of how long different container actions have taken. Select that
    metric and click Execute, and your output will be similar to mine in figure B.4,
    showing the time taken to create, delete, and start containers.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然后切换到“图形”菜单，你会看到一个下拉列表，显示Prometheus从Docker收集的所有可用指标。其中之一是`engine_daemon_container_actions_seconds_sum`，它记录了不同容器操作所花费的时间。选择该指标并点击执行，你的输出将类似于我的图B.4，显示创建、删除和启动容器所需的时间。
- en: '![](../Images/B-4.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/B-4.jpg)'
- en: Figure B.4 Prometheus has a simple web UI that you can use to find metrics and
    run queries.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.4 Prometheus有一个简单的Web UI，你可以用它来查找指标和运行查询。
- en: The Prometheus UI is a simple way to see what’s being collected and run some
    queries. Look around the metrics and you’ll see that Docker records a lot of information
    points. Some are high-level readouts, like the number of containers in each state
    and the number of health checks that have failed; others give low-level details,
    like the amount of memory the Docker Engine has allocated; and some are static
    pieces of information, like the number of CPUs Docker has available. These are
    infrastructure-level metrics, which could all be useful things to include in your
    status dashboard.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus UI是一个简单的方式来查看正在收集的内容并运行一些查询。在指标周围看看，你会发现Docker记录了大量的信息点。有些是高级读数，如每个状态的容器数量和失败的检查数量；其他提供低级细节，如Docker
    Engine分配的内存量；还有一些是静态信息，如Docker可用的CPU数量。这些都是基础设施级别的指标，所有这些都可以包括在你的状态仪表板中。
- en: Your applications will expose their own metrics, which will also record details
    at different levels. The goal is to have a metrics endpoint in each of your containers
    and have Prometheus collect metrics from them all on a regular schedule. Prometheus
    will store enough information for you to build a dashboard that shows the overall
    health of the whole system.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你的应用程序将公开它们自己的指标，这些指标也会在不同级别记录详细信息。目标是每个容器都有一个指标端点，并且Prometheus定期从它们中收集指标。Prometheus将存储足够的信息，让你构建一个仪表板，显示整个系统的整体健康状况。
- en: B.2 Exposing metrics from your application
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.2 从你的应用程序公开指标
- en: We’ve looked at the metrics the Docker Engine exposes, because that’s an easy
    way to get started with Prometheus. Exposing a useful set of metrics from each
    of your application containers takes more effort, because you need code to capture
    the metrics and provide the HTTP endpoint for Prometheus to call. It’s not as
    much work as it sounds, because there are Prometheus client libraries for all
    the main programming languages to do that for you.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经查看Docker Engine公开的指标，因为这是一个开始使用Prometheus的简单方法。从每个应用程序容器中公开一组有用的指标需要更多的努力，因为你需要代码来捕获指标并为Prometheus提供HTTP端点。这不像听起来那么困难，因为所有主要编程语言都有Prometheus客户端库来为你做这件事。
- en: In the code for this chapter, I’ve revisited the NASA image gallery app and
    added Prometheus metrics to each of my components. I’m using the official Prometheus
    clients for Java and Go, and the community client library for Node.js. Figure
    B.5 shows how each application container is now packaged with a Prometheus client
    that collects and exposes metrics.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的代码中，我重新审视了NASA图片库应用，并为每个组件添加了Prometheus指标。我使用了Java和Go的官方Prometheus客户端，以及Node.js的社区客户端库。图B.5展示了每个应用程序容器现在都打包了一个Prometheus客户端，该客户端收集并公开指标。
- en: '![](../Images/B-5.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B-5](../Images/B-5.jpg)'
- en: Figure B.5 Prometheus client libraries in your apps make the metrics endpoints
    available in the container.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.5展示了你的应用中的Prometheus客户端库使指标端点在容器中可用。
- en: The information points collected from a Prometheus client library are runtime-level
    metrics. They provide key information regarding what your container is doing and
    how hard it is working, in terms that are relevant to the application runtime.
    The metrics for a Go application include the number of active Goroutines; the
    metrics for a Java application include the memory used in the JVM. Each runtime
    has its own important metrics, and the client libraries do a great job of collecting
    and exporting those.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从Prometheus客户端库收集的信息点是运行时级别的指标。它们提供了关于你的容器正在做什么以及它工作有多努力的关键信息，这些信息与应用程序运行时相关。Go应用程序的指标包括活跃的Goroutines数量；Java应用程序的指标包括JVM使用的内存。每个运行时都有自己的重要指标，客户端库在收集和导出这些指标方面做得很好。
- en: 'Try it now There’s a Docker Compose file in the exercises for this chapter
    that spins up a new version of the image gallery app, with metrics in each container.
    Use the app and then browse to one of the metrics endpoints:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看。本章的练习中有一个Docker Compose文件，它会启动一个带有每个容器中指标的图片库应用版本。使用该应用，然后浏览到其中一个指标端点：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: My output is in figure B.6\. These are the metrics from the Go frontend web
    application—there’s no custom code required to produce this data. You can get
    all this data for free just by adding the Go client library into your application
    and setting it up.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我的结果在图B.6中。这是Go前端Web应用程序的指标——不需要自定义代码来生成这些数据。你只需将Go客户端库添加到应用程序中并设置它，就可以免费获得所有这些数据。
- en: '![](../Images/B-6.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B-6](../Images/B-6.jpg)'
- en: Figure B.6 Prometheus metrics about the Go runtime from the image gallery web
    container
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![图片 B-6](../Images/B-6.jpg) Prometheus关于Go运行时的指标，来自图片库的Web容器'
- en: You’ll see similar metrics for the Java REST API if you browse to http://localhost:8011/
    actuator/prometheus. The metrics endpoints are a sea of text, but all the key
    data points are in there to build a dashboard that will show if the containers
    are running “hot”—if they’re using a lot of compute resources like CPU time, memory,
    or processor threads.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你浏览到http://localhost:8011/actuator/prometheus，你会看到Java REST API的类似指标。指标端点是文本的海洋，但所有关键数据点都在那里，可以构建一个仪表板，显示容器是否运行“过热”——如果它们正在使用大量的计算资源，如CPU时间、内存或处理器线程。
- en: Those runtime metrics are the next level of detail you want after the infrastructure
    metrics from Docker, but those two levels don’t tell you the whole story. The
    final data points are application metrics that you explicitly capture to record
    key information about your application. Those metrics could be operations-focused,
    showing the number of events a component has processed or the average time to
    process a response. Or they could be business-focused, showing the current number
    of active users or the number of people signing up to a new service.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些运行时指标是你在从Docker的基础设施指标之后想要查看的下一级详细信息，但这两个级别并没有告诉你整个故事。最终的数据点是应用程序指标，你明确捕获这些指标以记录关于应用程序的关键信息。这些指标可以是操作导向的，显示组件处理的事件数量或处理响应的平均时间。或者它们可以是业务导向的，显示当前活跃用户数量或注册新服务的人数。
- en: Prometheus client libraries let you record these kind of metrics too, but you
    need to explicitly write the code to capture the information in your app. It’s
    not difficult to do. Listing B.1 shows an example using the Node.js library, which
    is in the code for the `access-log` component in the image gallery app. I don’t
    want to throw a whole bunch of code at you, but as you progress further with containers,
    you’re certain to spend more time with Prometheus, and this snippet from the `server.js`
    file illustrates a couple of key things.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 客户端库也允许您记录这类指标，但您需要显式编写代码来捕获应用程序中的信息。这并不困难。列表 B.1 展示了一个使用 Node.js
    库的示例，该示例位于图像库应用程序 `access-log` 组件的代码中。我不想向您展示一大堆代码，但随着您在容器方面进一步学习，您肯定会在 Prometheus
    上花费更多的时间，而这个来自 `server.js` 文件的片段展示了几个关键点。
- en: Listing B.1 Declaring and using custom Prometheus metric values in Node.js
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.1 在 Node.js 中声明和使用自定义 Prometheus 指标值
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the source code for the chapter, you’ll see how I’ve added metrics in the
    `image-gallery` web application written in Go, and in the `image-of-the-day` REST
    API written in Java. Each Prometheus client library works in a different way.
    In the `main.go` source file I initialize counters and gauges in a similar way
    to the Node.js app but then use instrumented handlers from the client library
    rather than setting metrics explicitly. The Java application is different again—in
    `ImageController.java` I use the `@Timed` attribute and increment a `registry.counter`
    object in the source. Each client library works in the most logical way for the
    language.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的源代码中，您将看到我是如何在用 Go 编写的 `image-gallery` 网络应用程序和用 Java 编写的 `image-of-the-day`
    REST API 中添加指标的。每个 Prometheus 客户端库的工作方式都不同。在 `main.go` 源文件中，我以类似于 Node.js 应用程序的方式初始化计数器和仪表，但随后使用来自客户端库的仪表化处理程序，而不是显式设置指标。Java
    应用程序又有所不同——在 `ImageController.java` 中，我使用了 `@Timed` 属性并在源代码中增加了一个 `registry.counter`
    对象。每个客户端库都以对语言最合理的方式工作。
- en: 'There are different types of metrics in Prometheus—I’ve used the simplest ones
    in these applications: counters and gauges. They’re both numeric values. Counters
    hold a value that increases or stays the same, and gauges hold values that can
    increase or decrease. It’s down to you or your application developers to choose
    the metric type and to set its value at the correct time; the rest is taken care
    of by Prometheus and the client library.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 中有不同的指标类型——我在这些应用程序中使用了最简单的类型：计数器和仪表。它们都是数值。计数器保持一个增加或保持不变的值，而仪表保持可以增加或减少的值。选择指标类型并在正确的时间设置其值取决于您或您的应用程序开发者；其余的由
    Prometheus 和客户端库处理。
- en: 'Try it now You have the image gallery app running from the last exercise, so
    these metrics are already being collected. Run some load into the app, and then
    browse to the Node.js app’s metrics endpoint:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 您已经从上一个练习中运行了图像库应用程序，因此这些指标已经被收集。向应用程序运行一些负载，然后浏览到 Node.js 应用程序的指标端点：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can see my output in figure B.7—I ran a few more loops to send in traffic.
    The first two records show my custom metrics, recording the number of access requests
    received and the total number of IP addresses using the service. These are simple
    data points (and the IP count is actually fake), but they serve the purpose of
    collecting and showing metrics. Prometheus lets you record more complex types
    of metrics, but even with simple counters and gauges you can capture detailed
    instrumentation in your apps.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在图 B.7 中看到我的输出——我运行了更多的循环来发送流量。前两条记录显示了我的自定义指标，记录了接收到的访问请求数量和使用的总 IP 地址数。这些是简单的数据点（而
    IP 计数实际上是假的），但它们起到了收集和展示指标的作用。Prometheus 允许您记录更复杂的指标类型，但即使使用简单的计数器和仪表，您也可以在应用程序中捕获详细的仪表化信息。
- en: '![](../Images/B-7.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/B-7.jpg)'
- en: Figure B.7 A metrics endpoint that includes custom data as well as Node.js runtime
    data
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.7 包含自定义数据和 Node.js 运行时数据的指标端点
- en: What you capture depends on your application, but the following list provides
    some useful guidelines—you can return to these at the end of the month when you’re
    ready to add detailed monitoring to your own apps.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您捕获的内容取决于您的应用程序，但以下列表提供了一些有用的指南——您可以在月底准备为您的应用程序添加详细监控时返回这些指南。
- en: When you talk to external systems, record how long the call took and whether
    the response was successful—you’ll quickly be able to see if another system is
    slowing yours down or breaking it.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您与外部系统通信时，记录调用花费的时间和响应是否成功——您将很快就能看到是否有其他系统正在减慢您的速度或破坏它。
- en: Anything worth logging is potentially worth recording in a metric—it’s probably
    cheaper on memory, disk, and CPU to increment a counter than to write a log entry,
    and it’s easier to visualize how often things are happening.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何值得记录的事件都可能在指标中记录——与写入日志条目相比，在内存、磁盘和 CPU 上增加计数器可能更便宜，而且更容易可视化事件发生的频率。
- en: Any details about application or user behaviors that business teams want to
    report on should be recorded as metrics—that way you can build real-time dashboards
    instead of sending historical reports.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何关于应用或用户行为，业务团队希望报告的细节都应该记录为指标——这样你就可以构建实时仪表板，而不是发送历史报告。
- en: B.3 Running a Prometheus container to collect metrics
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.3 运行 Prometheus 容器以收集指标
- en: Prometheus uses a pull model to collect metrics. Rather than have other systems
    send it data, it fetches data from those systems. It calls this *scraping*, and
    when you deploy Prometheus you configure the endpoints you want it to scrape.
    In a production container platform, you can configure Prometheus so it automatically
    finds all the containers across the cluster. In Docker Compose on a single server,
    you use a simple list of service names, and Prometheus finds the containers through
    Docker’s DNS.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 使用拉模型来收集指标。它不是让其他系统发送数据给它，而是从这些系统中获取数据。它称之为 *抓取*，当你部署 Prometheus
    时，你需要配置它要抓取的端点。在一个生产容器平台上，你可以配置 Prometheus，使其自动发现集群中的所有容器。在单个服务器的 Docker Compose
    中，你使用一个简单的服务名称列表，Prometheus 通过 Docker 的 DNS 来查找容器。
- en: Listing B.2 shows the configuration I’ve used for Prometheus to scrape two of
    the components in my image gallery application. There’s a `global` setting that
    uses a default 10-second interval between scrapes, and then there’s a `job` for
    each component. The job has a name, and the configuration specifies the URL path
    to the metrics endpoint and a list of targets that Prometheus will query. I use
    two types here. First, `static_configs` specifies a target hostname, which is
    fine for a single container. I also use `dns_sd_configs`, which means Prometheus
    will use DNS service discovery—that will find multiple containers for a service,
    and it supports running at scale.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.2 展示了我为 Prometheus 配置的抓取图像库应用中两个组件的配置。有一个 `global` 设置，它使用默认的 10 秒间隔进行抓取，然后为每个组件有一个
    `job`。作业有一个名称，配置指定了指标端点的 URL 路径以及 Prometheus 将查询的目标列表。我这里使用了两种类型。首先，`static_configs`
    指定了一个目标主机名，这对于单个容器来说是可以的。我还使用了 `dns_sd_configs`，这意味着 Prometheus 将使用 DNS 服务发现——这将找到为服务提供的多个容器，并且它支持大规模运行。
- en: Listing B.2 Prometheus configuration for scraping application metrics
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 B.2 Prometheus 用于抓取应用指标的配置
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This configuration sets Prometheus to poll all the containers every 10 seconds.
    It will use DNS to get the container IP addresses, but for the `image-gallery`
    it only expects to find a single container, so you’ll get unexpected behavior
    if you scale that component. Prometheus always uses the first IP address in the
    list if the DNS response contains several, so you’ll get metrics from different
    containers when Docker load balances the request to the metrics endpoint. The
    `accesslog` component is configured to support multiple IP addresses, so Prometheus
    will build a list of all the container IP addresses and poll them all on the same
    schedule. Figure B.8 shows how the scraping process runs.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置将 Prometheus 设置为每 10 秒轮询一次所有容器。它将使用 DNS 获取容器 IP 地址，但对于 `image-gallery`，它只期望找到一个容器，所以如果你扩展该组件，你会得到意外的行为。如果
    DNS 响应包含多个 IP 地址，Prometheus 总是使用列表中的第一个 IP 地址，所以当 Docker 对指标端点进行负载均衡时，你会从不同的容器中获得指标。`accesslog`
    组件配置为支持多个 IP 地址，所以 Prometheus 将构建一个包含所有容器 IP 地址的列表，并按照相同的计划轮询它们。图 B.8 展示了抓取过程是如何运行的。
- en: '![](../Images/B-8.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B-8](../Images/B-8.jpg)'
- en: Figure B.8 Prometheus running in a container, configured to scrape metrics from
    app containers
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.8 Prometheus 在容器中运行，配置为从应用容器抓取指标
- en: I’ve built a custom Prometheus Docker image for the image gallery application.
    It’s based on the official image that the Prometheus team publish on Docker Hub,
    and it copies in my own configuration file (you can find the Dockerfile in the
    source code for this chapter). This approach gives me a preconfigured Prometheus
    image that I can run without any extra configuration, but I can always override
    the config file in other environments if I need to.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我为图像库应用构建了一个定制的 Prometheus Docker 镜像。它基于 Prometheus 团队在 Docker Hub 上发布的官方镜像，并复制了我的配置文件（你可以在本章源代码中找到
    Dockerfile）。这种方法给我提供了一个预配置的 Prometheus 镜像，我可以无需任何额外配置即可运行，但如果需要，我可以在其他环境中覆盖配置文件。
- en: Metrics are more interesting when lots of containers are running. We can scale
    up the Node.js component of the image gallery app to run on multiple containers,
    and Prometheus will scrape and collect metrics from all the containers.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行大量容器时，指标更有趣。我们可以将图像库应用的 Node.js 组件扩展到多个容器上运行，Prometheus 将从所有容器中抓取和收集指标。
- en: 'Try it now There’s another Docker Compose file in the chapter’s exercises folder
    that publishes a random port for the `access-log` service, so that service can
    be run at scale. Run it with three instances and send some more load into the
    website:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 该章节的练习文件夹中还有一个 Docker Compose 文件，它为 `access-log` 服务发布了一个随机端口，因此该服务可以大规模运行。运行三个实例并向网站发送更多负载：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The website makes a call to the `access-log` service every time it processes
    a request—there are three containers running that service, so the calls should
    be load-balanced across them all. How can we check that the load balancing is
    working effectively? The metrics from that component include a label that captures
    the hostname of the machine sending the metrics—in this case that’s the Docker
    container ID. Open the Prometheus UI and check the `access-log` metrics. You should
    see three sets of data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 每次网站处理请求时都会调用 `access-log` 服务——运行该服务的有三个容器，因此调用应该在这所有容器之间进行负载均衡。我们如何检查负载均衡是否有效？该组件的指标包括一个标签，用于捕获发送指标的机器的主机名——在这种情况下是
    Docker 容器 ID。打开 Prometheus UI 并检查 `access-log` 指标。你应该看到三组数据。
- en: Try it now Browse to http://localhost:9090/graph. In the metrics dropdown, select
    `access_log_total` and click Execute.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 浏览到 http://localhost:9090/graph。在指标下拉菜单中，选择 `access_log_total` 并点击执行。
- en: You’ll see something similar to my output in figure B.9—there’s one metric value
    for each of the containers, and the labels contain the hostname. The actual values
    for each container will show you how evenly spread the load balancing is. In an
    ideal scenario, the figures would be equal, but there are a lot of network factors
    in play (like DNS caching and HTTP keep-alive connections), which means you probably
    won’t see that if you’re running on a single machine.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到与我图 B.9 中类似的输出——每个容器都有一个指标值，标签包含主机名。每个容器的实际值将显示负载均衡的均匀程度。在理想情况下，这些数值应该是相等的，但由于存在许多网络因素（如
    DNS 缓存和 HTTP 保持连接），这意味着如果你在单台机器上运行，你可能看不到这种情况。
- en: '![](../Images/B-9.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图 B-9](../Images/B-9.jpg)'
- en: Figure B.9 Processing metrics can be used to verify that requests are being
    load-balanced.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.9 处理指标可以用来验证请求是否正在负载均衡。
- en: Recording extra information with labels is one of the most powerful features
    of Prometheus. It lets you work with a single metric at different levels of granularity.
    Right now you’re seeing the raw data for the metrics, with one line in the table
    for each container showing the most recent metric value. You can aggregate across
    all the containers using a `sum()` query, ignoring the individual labels and showing
    a combined total, and you can display that in a graph to see the increasing usage
    over time.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 使用标签记录额外信息是 Prometheus 最强大的功能之一。它允许你在不同粒度级别上使用单个指标。目前你看到的是指标的原始数据，表格中每行显示每个容器的最新指标值。你可以使用
    `sum()` 查询跨所有容器进行聚合，忽略单个标签并显示总合，你还可以在图中显示随时间增加的使用情况。
- en: 'Try it now In the Prometheus UI, click the Add Graph button to add a new query.
    In the expression text box, paste this query:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 在 Prometheus UI 中，点击添加图形按钮以添加新的查询。在表达式文本框中，粘贴以下查询：
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Click Execute and you’ll see a line graph with a time series, which is how Prometheus
    represents data—a set of metrics, each recorded with a timestamp.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 点击执行，你会看到一个带有时间序列的折线图，这是 Prometheus 表示数据的方式——一组带有时间戳记录的指标。
- en: I sent in some more HTTP requests to my local app before I added the new graph—you
    can see my output in figure B.10.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在我添加新的图形之前，我向本地应用发送了一些更多的 HTTP 请求——你可以在图 B.10 中看到我的输出。
- en: '![](../Images/B-10.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图 B-10](../Images/B-10.jpg)'
- en: Figure B.10 Aggregating a metric to sum values from all containers and showing
    a graph of results
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.10 将指标聚合，从所有容器中汇总值并显示结果图
- en: The `sum()` query is written in Prometheus’s own query language called *PromQL*.
    It’s a powerful language with statistical functions that let you query changes
    over time and rate of change, and you can add subqueries to correlate different
    metrics. But you don’t need to go into any of that complexity to build useful
    dashboards. The Prometheus format is so well structured that you can visualize
    key metrics with simple queries. You can use labels to filter values, and sum
    the results to aggregate, and just those features will give you a useful dashboard.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`sum()` 查询是用 Prometheus 自有的查询语言 *PromQL* 编写的。它是一种功能强大的语言，包含统计函数，允许你查询随时间的变化和变化率，并且你可以添加子查询来关联不同的指标。但是，你不需要深入到任何这种复杂性中就可以构建有用的仪表板。Prometheus
    的格式结构非常良好，你可以通过简单的查询来可视化关键指标。你可以使用标签来过滤值，并汇总结果以进行聚合，仅这些功能就能为你提供一个有用的仪表板。'
- en: '![](../Images/B-11.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B-11](../Images/B-11.jpg)'
- en: Figure B.11 A simple Prometheus query. You don’t need to learn much more PromQL
    than this.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.11 一个简单的 Prometheus 查询。你不需要学习比这更多的 PromQL。
- en: Figure B.11 shows a typical query that will feed into a dashboard. This aggregates
    the value for all the `image_gallery_request` metrics, filtering where the response
    code is `200`, and summing without the `instance` label, so we will get metrics
    from all the containers. The result will be the total number of 200 “OK” responses
    sent by all the containers running the image gallery web application.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.11 展示了一个典型的查询，它将被用于仪表板。这个查询聚合了所有 `image_gallery_request` 指标的值，过滤出响应代码为 `200`
    的情况，并且没有使用 `instance` 标签进行汇总，因此我们将从所有容器中获取指标。结果将是所有运行图像库网络应用程序的容器发送的 200 个“OK”响应的总数。
- en: The Prometheus UI is fine for checking on your configuration, validating that
    all the scrape targets are reachable, and working out queries. But it is not meant
    to be a dashboard—that’s where Grafana comes in.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus UI 适用于检查你的配置，验证所有抓取目标是否可访问，以及制定查询。但它并不是一个仪表板——这正是 Grafana 的作用所在。
- en: B.4 Running a Grafana container to visualize metrics
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.4 运行 Grafana 容器以可视化指标
- en: We’re covering a lot of ground in this chapter because monitoring is a core
    topic for containers, but we’re going quickly because the finer details are all
    very application-dependent. What metrics you need to capture will depend on your
    business and operational needs, and how you capture them will depend on the application
    runtime you’re using and the mechanics of the Prometheus client library for that
    runtime.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了大量的内容，因为监控是容器的一个核心主题，但我们进展很快，因为更详细的内容都是非常依赖于应用程序的。你需要捕获哪些指标将取决于你的业务和运营需求，以及你如何捕获它们将取决于你使用的应用程序运行时以及该运行时的
    Prometheus 客户端库的机制。
- en: Once you have your data in Prometheus, things get simpler—it becomes a pretty
    standard approach for all apps. You’ll use the Prometheus UI to navigate the metrics
    you’re recording and work on queries to get the data that you want to see. Then
    you’ll run Grafana and plug those queries into a dashboard. Each data point shows
    up as a user-friendly visualization, and the dashboard as a whole shows you what’s
    happening with your app.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的数据在 Prometheus 中，事情就变得简单了——它成为所有应用程序的相当标准的做法。你将使用 Prometheus UI 来导航你记录的指标并制定查询以获取你想要看到的数据。然后你将运行
    Grafana 并将这些查询连接到仪表板。每个数据点都以用户友好的可视化形式出现，整个仪表板展示了你的应用程序正在发生的事情。
- en: We’ve been working toward the Grafana dashboard for the image gallery app all
    through this chapter, and figure B.12 shows the final outcome. It’s a very neat
    way to show core information from all the application components and the Docker
    runtime. These queries are also built to support scale, so the same dashboard
    can be used in a production cluster.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在本章中致力于构建图像库应用程序的 Grafana 仪表板，图 B.12 展示了最终结果。这是一种非常整洁的方式来展示所有应用程序组件和 Docker
    运行时的核心信息。这些查询也构建来支持扩展，因此相同的仪表板可以在生产集群中使用。
- en: '![](../Images/B-12.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B-12](../Images/B-12.jpg)'
- en: Figure B.12 The Grafana dashboard for the application. Looks fancy, but it’s
    actually pretty simple to build.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.12 应用程序的 Grafana 仪表板。看起来很复杂，但实际上构建起来相当简单。
- en: The Grafana dashboard conveys key information across many different levels of
    the application. It looks complicated, but each visualization is powered by a
    single PromQL query, and none of the queries do anything more complex than filtering
    and aggregating. The shrunken view in figure B.12 doesn’t give you the full picture,
    but I’ve packaged the dashboard into a custom Grafana image so you can run it
    yourself in a container and explore.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 仪表板在应用程序的许多不同级别传达关键信息。它看起来很复杂，但每个可视化都由一个单一的 PromQL 查询提供支持，并且没有任何查询比过滤和聚合更复杂。图
    B.12 的缩小视图没有给出完整的画面，但我已经将仪表板打包到一个自定义的 Grafana 图像中，这样您就可以在容器中运行它并探索。
- en: 'Try it now You’ll need to capture your computer’s IP address again, this time
    as an environment variable that the Compose file looks for and injects into the
    Prometheus container. Then run the app with Docker Compose and generate some load:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 您需要再次捕获计算机的 IP 地址，这次作为 Compose 文件查找并注入 Prometheus 容器中的环境变量。然后使用 Docker
    Compose 运行应用程序并生成一些负载：
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Grafana uses port 3000 for the web UI. When you first browse, you’ll need to
    sign in—the credentials are username `admin`, password `admin`. You’ll be asked
    to change the admin password on the first login, but I won’t judge you if you
    click Skip instead. When the UI loads, you’ll be in your “home” dashboard—click
    on the Home link at the top left, and you’ll see the dashboard list in figure
    B.13\. Click Image Gallery to load the application dashboard.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 使用端口 3000 用于 Web UI。当您首次浏览时，您需要登录——凭据是用户名 `admin`，密码 `admin`。您将在第一次登录时被要求更改管理员密码，但如果您点击跳过，我不会评判您。当
    UI 加载时，您将进入您的“主页”仪表板——点击左上角的“主页”链接，您将看到图 B.13 中的仪表板列表。点击图像库以加载应用程序仪表板。
- en: '![](../Images/B-13.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B-13](../Images/B-13.jpg)'
- en: Figure B.13 Navigating dashboards in Grafana-recently used folders are shown
    here
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.13 在 Grafana 中导航仪表板——最近使用的文件夹显示在此处
- en: My application dashboard is a reasonable setup for a production system. There
    are some key data points you need, to make sure you’re monitoring the right things-Google
    discusses this in the *Site Reliability Engineering* book ([http://mng.bz/EdZj](http://mng.bz/EdZj)).
    Their focus is on latency, traffic, errors, and saturation, which they call the
    “golden signals.”
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我的仪表板是一个合理的生产系统设置。您需要一些关键数据点，以确保您正在监控正确的事情——Google 在 *网站可靠性工程* 书籍中讨论了这一点 ([http://mng.bz/EdZj](http://mng.bz/EdZj))。他们的重点是延迟、流量、错误和饱和度，他们称之为“黄金信号”。
- en: I’ll go through the first set of my visualizations in detail so you can see
    that a smart dashboard can be built from basic queries and the right choice of
    visualization. Figure B.14 shows the row of metrics for the Image Gallery web
    UI—I’ve chopped the row up to make it easier to see, but these appear on the same
    line in the dashboard.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我将详细说明我的第一组可视化，以便您可以看到一个智能仪表板可以从基本的查询和正确的可视化选择中构建。图 B.14 显示了图像库 Web UI 的指标行——我将这一行分割开来以便更容易查看，但在仪表板上这些指标显示在同一行。
- en: '![](../Images/B-14.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片 B-14](../Images/B-14.jpg)'
- en: Figure B.14 A closer look at the application dashboard and how visualizations
    relate to the golden signals
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.14 更仔细地查看应用程序仪表板以及可视化如何与黄金信号相关
- en: 'There are four metrics here that show how heavily the system is being used,
    and how hard the system is working to support that level of use:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有四个指标显示了系统被使用的程度以及系统为了支持这种使用水平所付出的努力：
- en: '*HTTP 200 Responses*—This is a simple count of how many HTTP “OK” responses
    the website has sent over time. The PromQL query is a sum over the counter metric
    from the application: `sum(image_gallery_requests_total{code="200"})` `without(instance)`.
    I could add a similar graph with a query filtering on `code="500"` to show the
    number of errors.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*HTTP 200 响应*——这是网站随时间发送的 HTTP “OK” 响应的简单计数。PromQL 查询是对应用程序的计数器指标的总和：`sum(image_gallery_requests_total{code="200"})`
    `without(instance)`。我可以添加一个类似的图表，通过查询过滤 `code="500"` 来显示错误数量。'
- en: '*In-Flight Requests*—This shows the number of active requests at any given
    point. It’s a Prometheus gauge, so it can go up or down. There’s no filter for
    this, and the graph will show the total across all containers, so the query is
    another sum: `sum(image_gallery_in_flight_requests)` `without(instance)`.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*飞行请求*——这显示了在任何给定时间点的活动请求数量。这是一个 Prometheus 仪表，因此它可以上升或下降。对此没有过滤器，图表将显示所有容器中的总数，因此查询是另一个求和：`sum(image_gallery_in_flight_requests)`
    `without(instance)`。'
- en: '*Memory In Use*—This shows how much system memory the image gallery containers
    are using. It’s a bar chart, which is easier on the eye for this type of data;
    it will show a bar for each container when I scale up the web component. The PromQL
    query filters on the job name: `go_memstats_stack_inuse_bytes{job="image-gallery"}`.
    I need the filter because this is a standard Go metric, and the Docker Engine
    job returns a metric with the same name.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*内存使用量*——这显示了图像库容器使用的系统内存量。这是一个柱状图，对于这类数据来说更容易观察；当我扩展Web组件时，它将显示每个容器的条形图。PromQL查询根据作业名称进行筛选：`go_memstats_stack_inuse_bytes{job="image-gallery"}`。我需要这个筛选器，因为这是一个标准的Go指标，而Docker
    Engine作业返回的指标具有相同的名称。'
- en: '*Active Goroutines*—this is a rough indicator of how hard the component is
    working-a Goroutine is a unit of work in Go, and many can run concurrently. This
    graph will show if the web component suddenly has a spike of processing activity.
    It’s another standard Go metric, so the PromQL query filters stats from the web
    job and sums them: `sum(go_goroutines{job=\"image-gallery\"})` `without(instance)`.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*活跃的Goroutines*——这是一个粗略的指标，表明组件工作有多努力——Goroutine是Go中的工作单元，可以并发运行多个。这个图表将显示Web组件是否突然出现处理活动的峰值。这是另一个标准的Go指标，所以PromQL查询从Web作业筛选统计信息并求和：`sum(go_goroutines{job="image-gallery"})`
    `without(instance)`。'
- en: The visualizations in the other rows of the dashboards all use similar queries.
    There’s no need for complex PromQL—choosing the right metrics to show and the
    right visualization to display them is all you really need.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板其他行中的可视化都使用类似的查询。不需要复杂的PromQL——选择正确的指标来显示以及正确的可视化方式来展示它们，这才是你真正需要的。
- en: In these visualizations the actual values are less useful than the trends. It
    doesn’t really matter if my web app uses 200 MB of memory on average or 800 MB—what
    matters is when there’s a sudden spike that deviates from the norm. The set of
    metrics for a component should help you quickly see anomalies and find correlations.
    If the graph of error responses is on an upward trend and the number of active
    Goroutines is doubling every few seconds, it’s clear there’s something going wrong—the
    component could be saturated, so you may need to scale up with more containers
    to handle the load.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些可视化中，实际值不如趋势有用。我的Web应用平均使用200 MB内存或800 MB实际上并不重要——重要的是当出现突然的峰值偏离正常情况时。组件的指标集应该帮助你快速看到异常并找到相关性。如果错误响应的图表呈上升趋势，并且每几秒钟活跃的Goroutines数量翻倍，那么很明显有问题——组件可能已饱和，因此你可能需要通过增加更多容器来扩展以处理负载。
- en: Grafana is an extremely powerful tool, but it’s straightforward to use. It’s
    the most popular dashboard system for modern applications, so it’s worth learning—it
    can query lots of different data sources, and it can send alerts out to different
    systems too. Building dashboards is the same as editing existing dashboards—you
    can add or edit visualizations (called *panels*), resize and move them around,
    and then save your dashboard to a file.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana是一个非常强大的工具，但使用起来非常简单。它是现代应用中最受欢迎的仪表板系统，因此值得学习——它可以查询许多不同的数据源，并且可以向不同的系统发送警报。构建仪表板与编辑现有仪表板相同——你可以添加或编辑可视化（称为*面板*），调整大小并移动它们，然后将你的仪表板保存到文件中。
- en: Try it now The Google SRE approach says that an HTTP error count is a core metric,
    and that’s missing from the dashboard, so we’ll add it to the image gallery row
    now. Run the whole image gallery app again if you don’t have it running, browse
    to Grafana at http://locahost:3000, and log in with username `admin` and password
    `admin`.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 Google SRE方法认为HTTP错误计数是一个核心指标，但这个指标在仪表板中缺失，所以我们现在将其添加到图像库行。如果你还没有运行整个图像库应用，请重新运行它，浏览到Grafana的http://locahost:3000，并使用用户名`admin`和密码`admin`登录。
- en: Open the Image Gallery dashboard and click the Add Panel icon at the top right
    of the screen—it’s the bar chart with a plus sign shown in figure B.15.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 打开图像库仪表板，点击屏幕右上角的添加面板图标——如图B.15所示，它是一个带有加号的柱状图。
- en: '![](../Images/B-15.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图B-15](../Images/B-15.jpg)'
- en: Figure B.15 The Grafana toolbar for adding panels, choosing the time period,
    and saving the dashboard
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.15 Grafana工具栏，用于添加面板、选择时间段和保存仪表板
- en: 'Now click Add Query in the new panel window, and you’ll see a screen where
    you can capture all the details of the visualization. Select Prometheus as the
    data source for the query, and in the metrics field paste this PromQL expression:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在点击新面板窗口中的添加查询，你将看到一个屏幕，你可以捕捉到可视化的所有细节。选择Prometheus作为查询的数据源，并在指标字段粘贴以下PromQL表达式：
- en: '[PRE9]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Your panel should look like mine in figure B.16\. The image gallery application
    returns an error response around 10% of the time, so if you make enough requests
    you’ll see some errors in your graph.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您的面板应该看起来像图B.16中的我的那样。图像库应用程序大约有10%的时间会返回错误响应，所以如果您发出足够的请求，您会在图表中看到一些错误。
- en: Press the Escape key to go back to the main dashboard.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 按下Esc键返回主仪表板。
- en: '![](../Images/B-16.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图B-16](../Images/B-16.jpg)'
- en: Figure B.16 Adding a new panel to the Grafana dashboard to show HTTP errors
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图B.16 向Grafana仪表板添加新面板以显示HTTP错误
- en: You can resize panels by dragging the bottom-right corner, and move them by
    dragging the title. When you have the dashboard looking how you want, you can
    click the Share Dashboard icon from the tool panel (see figure B.15 again), where
    you have the option to export the dashboard as a JSON file.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过拖动底右角来调整面板大小，通过拖动标题来移动它们。当仪表板看起来符合您的要求时，您可以从工具面板中点击“共享仪表板”图标（再次查看图B.15），在那里您可以选择将仪表板导出为JSON文件。
- en: The final step with Grafana is packaging your own Docker image, which is already
    configured with Prometheus as a data source and with the application dashboard.
    I’ve done that for the `diamol/ch09-grafana` image. Listing B.3 shows the full
    Dockerfile.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Grafana的最终步骤是打包您自己的Docker镜像，该镜像已经配置了Prometheus作为数据源和应用程序仪表板。我已经为`diamol/ch09-grafana`镜像做了这件事。列表B.3显示了完整的Dockerfile。
- en: Listing B.3 The Dockerfile to package a custom Grafana image
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 列表B.3 打包自定义Grafana镜像的Dockerfile
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The image starts from a specific version of Grafana and then just copies in
    a set of YAML and JSON files. Grafana follows the configuration pattern I’ve promoted
    already in this book—there’s some default configuration built in, but you can
    apply your own. When the container starts, Grafana looks for files in specific
    folders, and it applies any configuration files it finds. The YAML files set up
    the Prometheus connection and load any dashboards that are in the `/var/lib/Grafana/dashboards`
    folder. The final line copies my dashboard JSON into that folder, so it gets loaded
    when the container starts.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像从一个特定的Grafana版本开始，然后只是复制一组YAML和JSON文件。Grafana遵循我在本书中已经推广的配置模式——内置了一些默认配置，但您可以应用自己的配置。当容器启动时，Grafana会在特定文件夹中查找文件，并应用它找到的任何配置文件。YAML文件设置Prometheus连接并加载位于`/var/lib/Grafana/dashboards`文件夹中的任何仪表板。最后一行将我的仪表板JSON复制到该文件夹，因此当容器启动时它会加载。
- en: You can do much more with Grafana provisioning, and you can also use the API
    to create users and set their preferences. It’s not much more work to build a
    Grafana image with multiple dashboards and a read-only user with access to all
    those dashboards, which can be put together in a Grafana playlist. Then you can
    browse to Grafana on a big screen in your office and have it automatically cycle
    through all your dashboards.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Grafana配置进行更多操作，您还可以使用API创建用户并设置他们的偏好。构建一个包含多个仪表板和具有访问所有这些仪表板权限的只读用户（这些仪表板可以组合成一个Grafana播放列表）的Grafana镜像并不需要做太多工作。然后您可以在办公室的大屏幕上浏览Grafana，并自动循环显示所有仪表板。
- en: B.5 Understanding the levels of observability
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.5 理解可观察性的级别
- en: 'Observability is a key requirement when you move from simple proof-of-concept
    containers to getting ready for production. But there’s another very good reason
    I introduced Prometheus and Grafana in this chapter: learning Docker is not just
    about the mechanics of Dockerfiles and Docker Compose files. Part of the magic
    of Docker is the huge ecosystem that’s grown around containers, and the patterns
    that have emerged around that ecosystem.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当您从简单的概念验证容器转移到准备生产时，可观察性是一个关键要求。但我在本章引入Prometheus和Grafana的另一个非常好的原因是：学习Docker不仅仅是关于Dockerfile和Docker
    Compose文件的机制。Docker的魔力之一是围绕容器成长起来的巨大生态系统以及围绕该生态系统出现的模式。
- en: Monitoring was a real headache when containers were first getting popular. My
    production releases back then were as easy to build and deploy as they are today,
    but I had no insight into the apps when they were running. I had to rely on external
    services like Pingdom to check that my APIs were still up, and on user reporting
    to make sure the app was working correctly. Today the approach to monitoring containers
    is a tried-and-trusted path. We’ve followed that path in this chapter, and figure
    B.17 summarizes the approach.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器最初变得流行时，监控确实是个头疼的问题。我那时的生产发布与今天一样容易构建和部署，但我在应用程序运行时没有洞察力。我必须依赖外部服务如 Pingdom
    来检查我的 API 是否仍然可用，并依赖用户报告来确保应用程序运行正确。今天监控容器的做法是一条经过验证且值得信赖的道路。我们在本章中遵循了这条道路，图 B.17
    总结了这种方法。
- en: '![](../Images/B-17.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图 B-17](../Images/B-17.jpg)'
- en: Figure B.17 The architecture of monitoring in a containerized application-Prometheus
    is at the center.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 B.17 容器化应用程序的监控架构-Prometheus 位于中心。
- en: I’ve walked through a single dashboard for the image gallery application, which
    is an overall view of the app. In a production environment, you’d have additional
    dashboards that dig into extra levels of detail. There would be an infrastructure
    dashboard showing free disk space, available CPU, and memory and network saturation
    for all the servers. Each component might have its own dashboard showing additional
    information, like a breakdown of response times for serving each page of a web
    app or each API endpoint.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经为图像库应用程序走过了单个仪表板，这是应用程序的整体视图。在生产环境中，你会有额外的仪表板，深入到更详细的层次。会有一个基础设施仪表板显示所有服务器的可用磁盘空间、可用
    CPU 和内存以及网络饱和度。每个组件可能都有自己的仪表板，显示额外的信息，例如，为 Web 应用程序的每一页或每个 API 端点提供服务的响应时间分解。
- en: The summary dashboard is the critical one. You should be able to pull together
    all the most important data points from your application metrics into a single
    screen, so you can tell at a glance if something is wrong and take evasive action
    before it gets worse.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要仪表板是关键。你应该能够将应用程序指标中的所有最重要的数据点汇总到一个屏幕上，这样你就可以一眼看出是否有问题，并在问题恶化之前采取规避措施。
- en: B.6 Lab
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: B.6 实验室
- en: 'This chapter added monitoring to the image gallery app, and this lab asks you
    to do the same to the to-do list app. You don’t need to dive into source code-I’ve
    already built a new version of the application image that contains Prometheus
    metrics. Run a container from `diamol/ch09-todo-list`, browse to the app, and
    add some items, and you’ll see the metrics available at the `/metrics` URL. For
    the lab, you want to get that app to the same position we have for the image gallery:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 本章为图像库应用程序添加了监控，这个实验室要求你对待办事项列表应用程序做同样的事情。你不需要深入研究源代码——我已经构建了一个包含 Prometheus
    指标的新版本的应用程序镜像。从 `diamol/ch09-todo-list` 运行一个容器，浏览到应用程序，添加一些项目，你将看到 `/metrics`
    URL 上可用的指标。对于实验室，你希望将那个应用程序带到与图像库相同的位置：
- en: Write a Docker Compose file that you can use to run the app, which also starts
    a Prometheus container and a Grafana container.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写一个 Docker Compose 文件，你可以使用它来运行应用程序，它还会启动一个 Prometheus 容器和 Grafana 容器。
- en: The Prometheus container should already be configured to scrape metrics from
    the to-do list app.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus 容器应该已经配置为从待办事项列表应用程序抓取指标。
- en: 'The Grafana container should be configured with a dashboard to show three key
    metrics from the app: number of tasks created, total number of HTTP requests processed,
    and number of HTTP requests currently being processed.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grafana 容器应该配置了一个仪表板，以显示应用程序的三个关键指标：创建的任务数量、处理的 HTTP 请求总数以及当前正在处理的 HTTP 请求数量。
- en: This sounds like a ton of work, but really it’s not—the exercises in this chapter
    cover all the details. It’s a good lab to work through, because it will give you
    experience working with metrics for a new application.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来像是一大堆工作，但实际上并不是——本章的练习涵盖了所有细节。这是一个很好的实验室，因为它将为你提供与新的应用程序一起处理指标的经验。
- en: 'As always, you’ll find my solution on GitHub, together with a graphic of my
    final dashboard: [https://github.com/sixeyed/diamol/blob/master/ch09/lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch09/lab/README.md).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，你可以在 GitHub 上找到我的解决方案，以及我最终仪表板的图形：[https://github.com/sixeyed/diamol/blob/master/ch09/lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch09/lab/README.md)。
