- en: Appendix D. Data and analytics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 D. 数据和分析
- en: Patricia Florissi
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Patricia Florissi
- en: 'This chapter covers:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖：
- en: Understanding portability versus mobility
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解可移植性与移动性
- en: Kubernetes and storage
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 和存储
- en: Anthos and storage
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos 和存储
- en: BigQuery Omni
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BigQuery Omni
- en: Anthos Hybrid AI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos Hybrid AI
- en: Until very recently, Anthos was often referred to in the context of compute
    and network, and rarely, if ever, in the context of storage or data. Nevertheless,
    Anthos has the potential to bring to stateful workloads many of the fundamentals
    it introduces in terms of observability, security, configuration and control.
    Furthermore, Anthos has the potential to disrupt the reachability and accessibility
    of data as much as it has been disrupting the portability and mobility of compute.
    Through Anthos, containers can seamlessly reach storage devices across hybrid
    and multi-cloud environments, with a consistency in provisioning, configuring,
    allocating and accessing these resources.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近，Anthos 通常在计算和网络的环境中提到，很少在存储或数据的环境中提到。尽管如此，Anthos 有潜力将它在可观察性、安全、配置和控制方面引入的许多基本原理带给有状态的工作负载。此外，Anthos
    有潜力像它已经颠覆计算的可移植性和移动性一样，颠覆数据的可达性和可访问性。通过 Anthos，容器可以无缝地跨混合和多云环境访问存储设备，在配置、配置、分配和访问这些资源方面保持一致性。
- en: Once an Anthos cluster enables stateful containers to be deployed across hybrid
    and multi-cloud environments, it provides those containers reach and access to
    data in a secure and consistent manner, the way analytics gets performed becomes
    ripe for a redesign. In a traditional setting, data collected from a myriad of
    data sources gets stored in a central location, in the form of data warehouses
    or data lakes, which is where analytics are executed. As a result, analytics solutions,
    including the ones using Artificial Intelligence (AI) and Machine Learning (ML),
    have long been designed and optimized assuming all the data required could be
    centrally reached.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 Anthos 集群能够使有状态的容器在混合和多云环境中部署，它就为这些容器提供了以安全和一致的方式访问数据的途径，这样分析数据的执行方式就为重新设计做好了准备。在传统的环境中，从众多数据源收集的数据被存储在中央位置，以数据仓库或数据湖的形式存在，这就是分析执行的地方。因此，包括使用人工智能（AI）和机器学习（ML）的分析解决方案，长期以来都是基于假设所有所需数据都可以集中访问而设计和优化的。
- en: Recent events, however, have been challenging the ability to centralize all
    the data before analytics can be performed. Organizations typically have data
    scattered across organizational boundaries or geographic locations, be it hosted
    on-prem or in public clouds. Often, regulatory compliance, security or data privacy
    impose some form of data residency where data must be stored within physical or
    logical fences and cannot be moved outside of that. Furthermore, even if the data
    could cross those boundaries, bandwidth constraints, such as capacity, speed and
    cost, might have imposed limitations on the volume of data that can be transferred
    to a central destination. Anthos makes it easier to bring data analytics to your
    data, meeting the data where the data happens to be, or needs to be, either on-prem
    or in a public cloud.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，最近的事件一直在挑战在分析之前集中所有数据的能力。组织通常会将数据分散在组织边界或地理位置之间，无论是在本地托管还是在公共云中。通常，法规遵从性、安全或数据隐私会强制实施某种形式的数据居住地，数据必须存储在物理或逻辑围栏内，不能移出该围栏。此外，即使数据可以跨越这些边界，带宽限制，如容量、速度和成本，可能会对可以传输到中央目的地的数据量施加限制。Anthos
    使得将数据分析带到数据所在之处变得更加容易，无论是在本地还是在公共云中，数据发生或需要发生的地方。
- en: 'The intersection of Anthos, data, and analytics is but an emerging topic, being
    by far the most nascent in Anthos trajectory towards enabling modern applications.
    As you read this chapter, a tremendous amount of work continues across many areas
    related to how Anthos can enable the next generation of many data services and
    how analytics can seamlessly work in hybrid and multi-cloud, including:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Anthos、数据和分析的交集只是一个新兴话题，在 Anthos 向现代应用程序提供支持的道路上，它是最初级的。随着你阅读本章，大量与如何使 Anthos
    能够支持下一代许多数据服务以及如何使分析在混合和多云环境中无缝工作相关的工作正在许多领域继续进行，包括：
- en: Data backup and disaster recovery, from on-prem to cloud and among clouds;
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据备份和灾难恢复，从本地到云以及云之间的；
- en: Databases, where the compute engine can be container native and the storage
    can be software defined;
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库，其中计算引擎可以是容器原生，存储可以是软件定义的；
- en: Federated Learning, where the training of AI models gets orchestrated across
    several locations, processing the data where it resides, and centrally aggregating
    only the intermediate results of such computations; and
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联邦学习，其中AI模型的训练在多个地点进行协调，处理数据所在地的数据，并仅集中聚合此类计算的中间结果；
- en: AI and ML Pipelines that allow the industrialization of models in a production
    environment, leaving the experimentation phase.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI和ML管道允许在生产环境中实现模型的工业化，从而结束实验阶段。
- en: As you can see from the introduction, data on Anthos opens up a number of additional
    workloads that require data, across various multi and hybrid cloud solutions -
    containers are no longer limited to only stateless workloads. But, before diving
    deeper into using data on Kubernetes and Anthos, we need to understand the differences
    between portability and mobility, which we will discuss in the next section.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从引言中可以看到，Anthos上的数据开放了多种需要数据的额外工作负载，这些工作负载跨越各种多云和混合云解决方案——容器不再仅限于无状态工作负载。但是，在更深入地探讨在Kubernetes和Anthos上使用数据之前，我们需要了解可移植性和移动性之间的区别，这将在下一节中讨论。
- en: D.1 Portability Versus Mobility
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: D.1 可移植性与移动性
- en: When it comes to Anthos and data, the nuances distinguishing portability and
    mobility become fundamental to understanding the challenges behind processing
    data scattered across a hybrid and multi-cloud environment. Portability of applications
    enables Anthos to realize the “write once, run anywhere” premise, while mobility
    of applications enables the extension of that to “write once, run anywhere, move
    anywhere else”. Portability matters to software developers during design time,
    and to administrators during operations, as it reduces the types of environment
    that may need to be provisioned. Mobility matters most to operators during runtime
    as it gives them the ability to re-distribute workloads dynamically, adjusting
    in real-time to demand. Mobility, in many ways, targets avoiding locking-in the
    workload to the specifics of the configuration of where it has been running and
    has been rooted in the adoption of open standards. Together, portability and mobility
    makes industrial scale operations more viable and extensible. Nevertheless, the
    challenges related to portability and to mobility of data can be far more intricate
    than the ones related to portability and to mobility of computation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到Anthos和数据时，区分可移植性和移动性的细微差别对于理解处理混合和多云环境中分散数据背后的挑战至关重要。应用程序的可移植性使Anthos能够实现“一次编写，到处运行”的前提，而应用程序的移动性则使这一概念扩展到“一次编写，到处运行，随意移动”。可移植性在软件设计阶段对软件开发者很重要，在操作阶段对管理员很重要，因为它减少了可能需要配置的环境类型。移动性在运行时对操作者来说最为重要，因为它使他们能够动态地重新分配工作负载，实时调整以满足需求。在许多方面，移动性旨在避免将工作负载锁定在特定配置的具体细节中，并根植于开放标准的采用。可移植性和移动性共同使得工业规模的操作更加可行和可扩展。然而，与可移植性和计算移动性相关的挑战可能比与计算移动性相关的挑战要复杂得多。
- en: 'While increased portability expands the surface of hardware where stateful
    containers can be deployed at, it may not equate directly to the mobility of stateful
    workloads from one location to another. In some cases, a stateful workload, let
    us call it SW, running on a location L1 and accessing a persistent storage PS
    may not be able to move to a location L2\. For example, SW may not be able to
    access PS when running on L2 and the data itself may not have the mobility to
    be transferred to a physical storage accessible from location L2\. Data often
    exhibits an element of gravity, imposing movement challenges due to many factors
    including: the sheer size of the data, financial and operational costs of moving
    the data, bandwidth constraints, security requirements, regulatory compliance
    and privacy constraints. Furthermore, in many cases, data is being created on
    a continuous basis, where applications need to ingest and process an ever-growing
    dataset, often within a time-sensitive window. In these scenarios, a one-time
    copy or a set of discrete data copies may not meet the application requirements.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然增加了可移植性，扩大了有状态容器可以部署的硬件表面，但这并不一定直接等同于有状态工作负载从一个位置移动到另一个位置。在某些情况下，运行在位置L1并访问持久存储PS的有状态工作负载SW可能无法移动到位置L2。例如，SW可能在L2上运行时无法访问PS，而且数据本身可能没有可移植性，无法转移到L2位置可访问的物理存储。数据往往表现出一种重力元素，由于数据本身的巨大规模、移动数据的财务和运营成本、带宽限制、安全要求、法规遵从性和隐私限制等多种因素，这给移动带来了挑战。此外，在许多情况下，数据是持续创建的，应用程序需要在时间敏感的窗口内摄取和处理不断增长的数据集。在这些场景中，一次性复制或一系列离散的数据副本可能无法满足应用程序的要求。
- en: On Portability
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 关于可移植性
- en: Portability refers to the ability to execute on several locations. In many ways,
    portability preceded any concerns around mobility as it related to workload placement.
    Before a workload could run on a location, the workload should be compatible with
    the underlying architecture and there should be enough resources available to
    run the workload. In order to increase portability, development environments seek
    to minimize the dependencies on specific infrastructure configurations and libraries.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 可移植性指的是在多个位置执行的能力。在许多方面，可移植性在涉及工作负载放置的移动性担忧之前就已经存在。在工作负载能够在某个位置运行之前，工作负载应该与底层架构兼容，并且应该有足够的资源来运行工作负载。为了提高可移植性，开发环境寻求最小化对特定基础设施配置和库的依赖。
- en: Portability can be viewed, however, as a requirement for effective mobility.
    A computing workload running at a location should only be moved to other locations
    where it can continue executing. In essence, the more locations an application
    can be made portable to, the more locations it can be moved to. The performance
    of the execution may be different among these locations, because each location
    may have different computing, memory, network and storage configurations but,
    nonetheless, the application can actually execute.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，可移植性可以被视为有效移动性的一个要求。在某个位置运行的计算工作负载应该只移动到它可以在那里继续执行的其他位置。本质上，一个应用程序可以被制作成可移植到更多位置，它就可以移动到更多位置。执行性能在这些位置之间可能会有所不同，因为每个位置可能具有不同的计算、内存、网络和存储配置，但无论如何，应用程序实际上是可以执行的。
- en: Containers increase portability by packaging the application code together with
    all its library dependencies, minimizing requirements around specific library
    configurations that needed to be available at a location before it could run there.
    For stateful containers, portability demands that the way containers interact
    with storage devices in one location are compatible with the way containers interact
    with storage devices in another location.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 容器通过将应用程序代码及其所有库依赖项打包在一起，减少了在特定库配置方面的需求，这些配置需要在运行之前在某个位置可用。对于有状态的容器，可移植性要求容器与一个位置上的存储设备交互的方式与容器与另一个位置上的存储设备交互的方式兼容。
- en: On Mobility
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 关于移动性
- en: In the context of computer science, mobility refers to the ability to transfer
    the location of a resource from one physical place to another. For a computational
    workload, it refers to the transfer of the execution of the workload from a set
    of physical compute resources, such as a server node, to another. For data, it
    refers to moving the content of the data from one physical storage device to another.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机科学领域，移动性指的是将资源的位置从一个物理位置转移到另一个位置的能力。对于计算工作负载，它指的是将工作负载的执行从一组物理计算资源（如服务器节点）转移到另一个资源。对于数据，它指的是将数据内容从物理存储设备移动到另一个设备。
- en: Virtual Machines (VMs) made the ability to move computing across physical boundaries
    a viable approach, often in real-time and with minimal, if any, service disruptions.
    The same mobility has not been granted when it comes to the data accessed by these
    VMs. Moving the data across networks can be subject to not only latency, bandwidth
    constraints, and costs of reading from its location and writing the data into
    its new location, but also to challenges associated with changing the address
    of the data itself mid-flight. Applications typically bind addresses to physical
    locations at the beginning of the execution, and these bindings cannot be easily
    changed. Furthermore, depending on the size of the data that requires moving,
    bandwidth and read/write throughput constraints cannot be overlooked. As size
    increases, data acquires more gravity and loses mobility.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机（VM）使跨物理边界移动计算成为可行的方法，通常在实时进行，并且服务中断最小，如果没有中断。当涉及到这些虚拟机访问的数据时，并没有赋予相同的移动性。在网络上移动数据可能会受到延迟、带宽限制以及从其位置读取和将数据写入新位置的成本的影响，还可能受到在飞行中更改数据地址的挑战。应用程序通常在执行开始时将地址绑定到物理位置，并且这些绑定不容易更改。此外，根据需要移动的数据大小，带宽和读写吞吐量限制不容忽视。随着大小的增加，数据获得更多的重力并失去移动性。
- en: As a result, VMs that required access to data residing in persistent storage
    became bound to moving only to other physical computing resources where the VM
    could still have access to the storage where the data was initially stored. In
    essence, the computing workload moved but the data did not.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，需要访问驻留在持久存储中的数据的虚拟机（VM）只能绑定到移动到其他物理计算资源，这些资源仍然可以访问最初存储数据的位置。本质上，计算工作负载移动了，但数据没有。
- en: Containers added a level of flexibility to mobility when it made it viable and
    easier to move workloads by simply starting new containers in the newly desired
    destinations and then terminating the old ones, as opposed to actually moving
    a running workload. Nevertheless, similar constraints applied to containers that
    accessed persistent storage, referred to as stateful containers. As long as the
    new location of a stateful container had access to the same persistent storage
    that the old container was using in its prior location, mobility was easier. An
    interesting aspect emerges with containers however. Because the container is re-starting
    from scratch, new bindings between the container and the physical storage can
    be made. As a result, containers can also be moved to locations where replicas
    of the data exist, as long as the replicas are an exact mirror of each other.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当通过简单地在新目标位置启动新的容器并终止旧的容器来移动工作负载变得可行且更容易时，容器增加了移动性的灵活性。与实际移动正在运行的工作负载相比，这种方法更加有效。然而，对访问持久存储的容器（称为有状态容器）也适用类似的约束。只要有状态容器的新的位置可以访问与旧容器在其先前位置使用的相同持久存储，移动性就更容易。然而，容器有一个有趣的特点。由于容器是从零开始重新启动的，因此可以在容器和物理存储之间建立新的绑定。因此，只要副本是彼此的精确镜像，容器也可以移动到存在数据副本的位置。
- en: D.1.1 Chapter Organization
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.1.1 章节组织
- en: 'This chapter provides a glimpse into the topic of Anthos, data and analytics,
    and it is organized as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本章简要介绍了 Anthos、数据和数据分析的主题，其组织结构如下：
- en: Section [Kubernetes and Storage](#heading_id_4) reviews some important concepts
    on how Kubernetes interfaces with the storage layer, forming a foundation for
    the next sections;
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第 [Kubernetes 和存储](#heading_id_4) 节回顾了 Kubernetes 如何与存储层交互的一些重要概念，为下一节奠定了基础；
- en: Section [Anthos and Storage](#heading_id_5) discusses how Anthos adds value
    on top of Kubernetes to enhance the portability of workloads that access permanent
    storage;
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第 [Anthos 和存储](#heading_id_5) 节讨论了 Anthos 如何在 Kubernetes 的基础上增加价值，以增强访问持久存储的工作负载的可移植性；
- en: Section [BigQuery Omni Powered by Anthos](#heading_id_6) explains how Anthos
    has enabled BigQuery, a Google Cloud data warehouse analytics engine, to perform
    queries on data that resides on other public cloud platforms;
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[由 Anthos 驱动的 BigQuery](#heading_id_6) 部分解释了 Anthos 如何使 Google Cloud 数据仓库分析引擎
    BigQuery 能够在存储在其他公共云平台上的数据上执行查询；'
- en: Section [Anthos Hybrid AI](#heading_id_19) explains how Anthos has enabled Google
    Cloud analytics solutions to run on-prem, allowing cloud-born analytics to be
    deployed and executed without requiring the data to be moved to the cloud; and
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Anthos 混合人工智能](#heading_id_19) 部分解释了 Anthos 如何使 Google Cloud 分析解决方案在本地运行，允许云原生分析在无需将数据移动到云的情况下部署和执行；'
- en: Section [Summary](#heading_id_7) highlights the main topics covered in this
    chapter.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[摘要](#heading_id_7) 部分概述了本章涵盖的主要主题。'
- en: D.2 Kubernetes and Storage
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: D.2 Kubernetes 和存储
- en: One of the fundamental questions about container-based and Cloud Native Applications
    (CNAs) is how they support persistent data. These questions range from how they
    support something as simple as block or file operations within a cluster, to how
    they interact with transactional databases and object stores of petabyte scale.
    Since Anthos is a management plane on top of Kubernetes, it is paramount to first
    understand how Kubernetes exposes the configuration and management of block and
    file storage, and then understand not only what Anthos adds today on top of Kubernetes
    storage, but also what Anthos can add in the future.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 关于基于容器和云原生应用 (CNAs) 的一个基本问题是它们如何支持持久数据。这些问题范围从它们如何在集群内支持像块或文件操作这样简单的事情，到它们如何与交易数据库和PB级规模的对象存储交互。由于
    Anthos 是 Kubernetes 之上的管理平面，因此首先了解 Kubernetes 如何公开块和文件存储的配置和管理至关重要，然后了解 Anthos
    不仅在今天在 Kubernetes 存储之上添加了什么，而且了解 Anthos 未来可以添加什么。
- en: 'In Kubernetes, a volume represents a unit of storage allocation and the containers
    that interact directly with storage systems are referred to as stateful containers.
    [Figure D.1 Data and Control Planes](#bookmark1) shows the technology stack that
    enables stateful containers to interact with storage systems. Data resides at
    the persistent physical storage layer, the lowest in the stack, which includes,
    for example, [Internet Small Computers Systems Interface (iSCSI)](https://tools.ietf.org/html/rfc3720)
    [Logical Unit Numbers (LUNs)](https://en.wikipedia.org/wiki/LUN), [Network File
    Systems (NFS)](https://en.wikipedia.org/wiki/Network_File_System) shares and cloud
    offerings for object, block and file. On top of the physical layer, at the Operating
    System (OS) level, there are the block and file systems, which can be local or
    networked. These systems implement drivers, often operating at the OS kernel level,
    that allow upper layers to interact with the physical storage using either a block
    level or a file level abstraction. In their most basic form, containers interact
    with storage systems across two planes:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，卷代表存储分配的单位，与存储系统直接交互的容器被称为有状态容器。[图 D.1 数据和控制平面](#bookmark1) 展示了使有状态容器能够与存储系统交互的技术堆栈。数据位于持久物理存储层，这是堆栈中的最低层，包括例如
    [互联网小型计算机系统接口 (iSCSI)](https://tools.ietf.org/html/rfc3720) [逻辑单元号 (LUN)](https://en.wikipedia.org/wiki/LUN)、[网络文件系统
    (NFS)](https://en.wikipedia.org/wiki/Network_File_System) 共享以及对象、块和文件的云服务。在物理层之上，在操作系统
    (OS) 层，有块和文件系统，这些系统可以是本地的或网络化的。这些系统实现了驱动程序，通常在操作系统内核级别运行，允许上层通过块级或文件级抽象与物理存储交互。在最基本的形式中，容器通过两个平面与存储系统交互：
- en: 'Data Plane: used by stateful containers to perform read and write operations.
    To a great extent, the data plane has been standardized. For example, the [Portable
    Operating System Interface (POSIX)](https://www.gnu.org/software/libc/manual/html_node/POSIX.xhtml)
    is the de-facto standard protocol interface for reading and writing data into
    file and block storage.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据平面：由有状态容器用于执行读取和写入操作。在很大程度上，数据平面已经标准化。例如，[可移植操作系统接口 (POSIX)](https://www.gnu.org/software/libc/manual/html_node/POSIX.xhtml)
    是将数据读入和写入文件和块存储的事实上标准协议接口。
- en: 'Control Plane: used by Kubernetes volume plugins to allocate, deallocate and
    manage space in the physical storage.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制平面：由 Kubernetes 存储插件用于在物理存储中分配、释放和管理空间。
- en: Unlike the data plane, the control plane interface had not been standardized
    until very recently. In 2017, an effort across container orchestrators involving
    Kubernetes, Mesos, Docker, Cloud Foundry and a few others, led to the [Container
    Storage Interface (CSI)](https://github.com/container-storage-interface/spec/blob/master/spec.md)
    specification. A storage vendor implements the CSI specification into a driver
    using its specific APIs and storage protocols. A vendor’s CSI driver is then packaged
    and deployed in the Kubernetes cluster as Pods, typically separated into a controller
    deployment and a per-node deployment. Kubernetes calls the appropriate CSI APIs
    implemented by these drivers when orchestrating volumes for container workloads.
    CSI will be further explained in the following sessions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 与数据平面不同，控制平面接口直到最近才实现标准化。2017年，涉及Kubernetes、Mesos、Docker、Cloud Foundry和其他几个容器的容器编排器之间的努力，导致了[容器存储接口（CSI）](https://github.com/container-storage-interface/spec/blob/master/spec.md)规范的制定。存储供应商通过使用其特定的API和存储协议将CSI规范实现为驱动程序。然后，供应商的CSI驱动程序被打包并部署在Kubernetes集群中作为Pods，通常分为控制器部署和每个节点的部署。当编排容器工作负载的卷时，Kubernetes会调用这些驱动程序实现的适当CSI
    API。CSI将在接下来的会话中进一步解释。
- en: '![D_01](../../OEBPS/Images/D_01.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![D_01](../../OEBPS/Images/D_01.png)'
- en: Figure D.1 Data and Control Planes
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图D.1 数据平面和控制平面
- en: Data, in the context of this chapter, refers exclusively to data that persists
    the execution of applications. As a consequence, not only does the data demand
    persistent storage, but it also needs to be addressed and accessed after the application
    that created or changed it has terminated, either normally or abnormally. These
    applications can range from very ephemeral ones, such as a camera application
    in a mobile phone that records a video stream and terminates, to a far more resilient
    database application that can, for example, form the backend of a digital banking
    service.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的上下文中，数据专指持续应用程序执行的数据。因此，数据不仅需要持久存储，而且在创建或更改它的应用程序终止后，无论是正常还是异常终止，都需要对其进行寻址和访问。这些应用程序的范围可以从非常短暂的，例如在手机中记录视频流的相机应用程序，到更具有弹性的数据库应用程序，例如可以成为数字银行服务后端的数据库应用程序。
- en: D.2.1 On the Emergence of a Standard
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.2.1 标准化的出现
- en: Kubernetes volume plugins introduced an abstraction for vendors to add support
    for their block and file storage systems in Kubernetes, automating the provisioning,
    attaching and mounting of storage for containers. Furthermore, Kubernetes abstractions
    of [Persistent Volumes (PVs)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/),
    [Persistent Volumes Claims (PVCs)](https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/)
    and [StorageClass](https://kubernetes.io/docs/concepts/storage/storage-classes/)
    objects enabled portability of storage and stateful containers. But other challenges
    remained.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes卷插件为供应商提供了一个抽象层，以便在Kubernetes中添加对他们的块和文件存储系统的支持，从而自动化容器的存储配置、附加和挂载。此外，Kubernetes对[持久卷（PVs）](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)、[持久卷声明（PVCs）](https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/)和[存储类（StorageClass）](https://kubernetes.io/docs/concepts/storage/storage-classes/)对象的抽象使得存储和有状态容器的可移植性成为可能。但其他挑战仍然存在。
- en: In early 2017, Kubernetes was not yet the most adopted container orchestration
    platform. Mesos, Docker Swarm and others had considerable market share. Each of
    these orchestration systems had a different way to expose volumes into their own
    containers. In order to address the container market, storage vendors needed to
    develop multiple storage plugins, one for each of the container orchestration
    systems, and many decided to delay development until a standard was created or
    a market leader emerged.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在2017年初，Kubernetes还不是最广泛采用的容器编排平台。Mesos、Docker Swarm和其他平台拥有相当大的市场份额。每个编排系统都有不同的方式将卷暴露给它们自己的容器。为了解决容器市场，存储供应商需要为每个容器编排系统开发多个存储插件，许多供应商决定在创建标准或市场领导者出现之前推迟开发。
- en: At the same time, the Kubernetes volume plugin mechanism was facing several
    challenges. Volume plugins had to be implemented in core Kubernetes as an in-tree
    volume plugin. Storage vendors had to implement plugins in the programming language
    Go, contribute source code to the Kubernetes code repository, and release and
    maintain the code as part of the main Kubernetes releases.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，Kubernetes 卷插件机制也面临着几个挑战。卷插件必须作为树内卷插件在核心 Kubernetes 中实现。存储供应商必须使用 Go 编程语言实现插件，向
    Kubernetes 代码仓库贡献源代码，并将代码作为 Kubernetes 主发布的一部分进行发布和维护。
- en: 'The in-tree volume plugins introduced different challenges to different communities,
    as outlined below:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 树内卷插件为不同的社区带来了不同的挑战，如下所述：
- en: 'For the Kubernetes development community: it became daunting to have volume
    plugins embedded right into the repository, as part of the Kubernetes codebase,
    being compiled and implemented within the Kubernetes binary code. The tight coupling
    introduced challenges, including:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 Kubernetes 开发社区：卷插件直接嵌入到仓库中，作为 Kubernetes 代码库的一部分，在 Kubernetes 二进制代码中进行编译和实现，这变得令人畏惧。引入的紧密耦合带来了挑战，包括：
- en: 'Security: volume plugins had full privilege to access all Kubernetes components,
    the entire source tree became exposed to exploitation of security vulnerabilities,;'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全性：卷插件拥有完全权限访问所有 Kubernetes 组件，整个源树都暴露于安全漏洞的利用；
- en: 'Stability: bugs in volume plugins could affect critical Kubernetes components,
    causing component failure or failure of the entire Kubernetes system;'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稳定性：卷插件中的错误可能会影响关键 Kubernetes 组件，导致组件故障或整个 Kubernetes 系统故障；
- en: 'Quality and Testing: testing and maintenance of external code became intertwined
    with CI/CD pipelines and it became increasingly challenging to test Kubernetes
    code against all supported storage configurations before each release. Kubernetes
    developers often lacked access to laboratories that housed all the flavors of
    storage and associated expertise . For some plugins, Kubernetes would depend on
    users to find and report issues, before they could be addressed.'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 质量和测试：外部代码的测试和维护与 CI/CD 管道交织在一起，因此在每次发布之前测试 Kubernetes 代码以针对所有支持的存储配置变得越来越具有挑战性。Kubernetes
    开发者通常无法访问包含所有存储版本及其相关专业知识的研究室。对于某些插件，Kubernetes 依赖于用户在问题得到解决之前找到并报告问题。
- en: 'For storage vendors: in-tree volume plugins slowed down, or even inhibited,
    the development and support of drivers due to challenges across several stages
    of the plugins lifecycle, including:'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于存储供应商：树内卷插件（in-tree volume plugins）的运行速度减慢，甚至阻碍了驱动程序的开发和支持，这归因于插件生命周期多个阶段的挑战，包括：
- en: 'During development: storage vendors were required to effectively extend Kubernetes
    code, and check the code into the Kubernetes core repository, requiring storage
    vendors to acquire expertise in the Go programming language, and Kubernetes. Forcing
    the use of a single programming language, Go, further limited the intellectual
    capital pool, since Go is an emerging language there are less developers available
    in the market than another language like Java or C;'
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在开发期间：存储供应商需要有效地扩展 Kubernetes 代码，并将代码提交到 Kubernetes 核心仓库，这要求存储供应商掌握 Go 编程语言和
    Kubernetes 的专业知识。强制使用单一编程语言 Go 进一步限制了智力资本池，因为 Go 是一种新兴语言，市场上可用的开发者比 Java 或 C 等其他语言要少；
- en: 'During release: storage vendors were required to align with the Kubernetes
    release cycle, limiting them to release new code and updates only when Kubernetes
    released code, four times a year. This tightly coupled release cycle severely
    impacted deployment velocity;'
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在发布期间：存储供应商需要与 Kubernetes 发布周期保持一致，这限制了他们只能在 Kubernetes 发布代码时发布新代码和更新，每年仅四次。这种紧密耦合的发布周期严重影响了部署速度；
- en: 'During commercialization: the code for volume plugins was forced to be open
    sourced;'
  id: totrans-57
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在商业化期间：卷插件的代码被迫开源；
- en: 'For users: these dynamics affected the overall Kubernetes experience for stateful
    containers and prevented adoption at scale because:'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于用户：这些动态影响了有状态容器的整体 Kubernetes 体验，并阻止了大规模采用，因为：
- en: 'Weak ecosystem: as storage vendors struggled to develop plugins, the number
    of storage choices were limited;'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生态系统薄弱：随着存储供应商努力开发插件，存储选择数量有限；
- en: 'Slow velocity: release cycles were long and testing quality poor, users had
    to wait long periods for issues to be addressed.'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 速度慢：发布周期长且测试质量差，用户必须等待很长时间才能解决问题得到解决。
- en: The Kubernetes community, supported with strong Google leadership, decided to
    move away from an in-tree plugin model and create a stand alone approach for vendors
    to develop volume plugins. Kubernetes was not alone. All container orchestration
    systems faced similar challenges -- they needed to expose containers to as many
    different storage vendor products as possible, with as little work as possible,
    in the most secure manner. At the same time, storage vendors also wanted to expose
    their products to as many users as possible, regardless of which container orchestration
    system they were using, leveraging plugins across as many systems as possible,
    with little or no modification to the code. As a result, the Kubernetes community
    formed a coalition with other container orchestration communities and started
    working on a specification to create an extensible volume layer. The initial design
    focused entirely on the user experience and standard storage platform capabilities
    across vendors.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google强有力的领导下，Kubernetes社区决定放弃树内插件模型，并为供应商开发卷插件创建一个独立的方法。Kubernetes并非孤军奋战。所有容器编排系统都面临着类似的挑战——它们需要尽可能多地暴露容器给不同的存储供应商产品，尽可能少的工作，以最安全的方式。同时，存储供应商也希望尽可能多地将其产品暴露给尽可能多的用户，无论他们使用的是哪种容器编排系统，利用尽可能多的系统中的插件，对代码进行很少或没有修改。因此，Kubernetes社区与其他容器编排社区结成联盟，开始制定一个规范以创建一个可扩展的卷层。最初的设计完全集中在用户体验和跨供应商的标准存储平台功能上。
- en: In addition to creating a standard, Kubernetes also had a unique need to provision
    storage on demand, through dynamic storage provisioning. During runtime, applications
    should be able to request storage at any time and Kubernetes should be able to
    reach out to the backend system to obtain the storage needed and make it available
    to the application. No administrators should need to get involved, no disruptions
    to the execution of the application should occur and no exclusive pre-allocation
    of storage per application should be necessary. Once the application would no
    longer need the storage, it should be released back to the pool for re-allocation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 除了创建标准之外，Kubernetes还拥有一个独特的需求，即通过动态存储分配按需提供存储。在运行时，应用程序应能够随时请求存储，Kubernetes应能够联系后端系统以获取所需的存储并将其提供给应用程序。不应需要管理员介入，不应发生对应用程序执行的中断，也不应需要为每个应用程序进行专有的存储预分配。一旦应用程序不再需要存储，它应被释放回池中以供重新分配。
- en: D.2.2 Container Storage Interface
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.2.2 容器存储接口
- en: The Container Storage Interface (CSI) is an open source standard for exposing
    arbitrary block and file storage systems to containerized workloads, managed and
    orchestrated by container orchestration systems, like Kubernetes. The CSI specification
    is just that, a specification. The specification does not define how the plugin
    should be packaged, it does not demand any deployment mechanism, and it does not
    impose or include any information on how it should be monitored.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 容器存储接口（CSI）是一个开源标准，用于将任意块和文件存储系统暴露给由容器编排系统（如Kubernetes）管理的容器化工作负载。CSI规范就是这样一个规范。规范没有定义插件应该如何打包，它不要求任何部署机制，也不强加或包含任何关于如何监控的信息。
- en: 'At its core, CSI provides an interface to execute the following operations:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: CSI的核心功能是提供一个接口以执行以下操作：
- en: Create/delete volumes
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建/删除卷
- en: Attach/detach volume to a node
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将卷附加/从节点分离
- en: Mount/unmount volume on a node for a workload
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在节点上为工作负载挂载/卸载卷
- en: Snapshot a volume and create a new volume from a snapshot
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对卷进行快照并从快照创建新的卷
- en: Clone a volume
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 克隆卷
- en: Resize a volume
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整卷大小
- en: The interfaces in CSI are implemented as three sets of APIs, listed below, and
    all APIs are idempotent, meaning that they can be invoked multiple times by the
    same client and they will yield the same results. These APIs all require a volume
    identifier which allows the receiver of the call to know that the call has been
    made before. Idempotency on the API brings predictability and robustness, allowing
    the system to handle recovery from failures, especially in the communication between
    components.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: CSI中的接口实现为以下三组API，如下所示，并且所有API都是幂等的，这意味着它们可以被同一客户端多次调用，并且会产生相同的结果。这些API都需要一个卷标识符，这允许调用接收者知道之前已经进行了调用。API的幂等性带来了可预测性和鲁棒性，使得系统能够处理从失败中恢复，尤其是在组件之间的通信中。
- en: 'Identity services: operations that give basic information about the plugin,
    such as its name, basic capabilities, and its current state.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 身份服务：提供有关插件的基本信息操作，例如其名称、基本功能和当前状态。
- en: 'Node services: volume operations that need to run on the node where the volume
    will be used, such as mount and unmount.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点服务：需要在将使用卷的节点上运行的卷操作，例如挂载和卸载。
- en: 'Controller services: volume operations that can execute on any node, such as
    volume attach and detach, and volume creation and volume deletion.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制器服务：可以在任何节点上执行的卷操作，例如卷挂载和卸载，以及卷创建和卷删除。
- en: '[gRPC Remote Procedure Call (gRPC)](https://grpc.io/) was selected as the wire
    protocol because it is language agnostic, has a large community of users and has
    a broad set of tools to help implementation. The APIs are synchronous, meaning
    that the caller will block after making the call, waiting until the results come
    along. The specification does not impose any packaging and deployment requirements.
    The only requirement is to provide gRPC endpoints over Unix sockets.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[gRPC远程过程调用（gRPC）](https://grpc.io/)被选为线协议，因为它与语言无关，拥有庞大的用户社区，并有一套广泛的工具来帮助实现。API是同步的，这意味着调用者在调用后将被阻塞，等待结果返回。规范没有强加任何打包和部署要求。唯一的要求是提供通过Unix套接字的gRPC端点。'
- en: D.2.3 Differentiation Behind CSI
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.2.3 CSI背后的差异化
- en: 'The CSI standard emerged in an effort to address several goals, and has truly
    become the foundation for creating a very extensible volume layer. CSI has created
    a storage ecosystem for Kubernetes where not only all major storage vendors support
    it, but end users can also write their own custom CSI drivers specific for their
    applications. In essence, CSI:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: CSI标准是在努力实现几个目标的过程中出现的，并真正成为创建一个非常可扩展的卷层的基础。CSI为Kubernetes创建了一个存储生态系统，其中不仅所有主要存储供应商都支持它，而且最终用户还可以为他们的应用程序编写自己的自定义CSI驱动程序。本质上，CSI：
- en: 'Standardizes the storage control plane: fostering interoperability for storage
    vendors and container orchestrators. Storage vendors build a single driver that
    can be used by any orchestrator, and container orchestrators can interface with
    any driver;'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化存储控制平面：促进存储供应商和容器编排器之间的互操作性。存储供应商构建一个单一驱动程序，任何编排器都可以使用，容器编排器可以与任何驱动程序接口；
- en: 'Supports dynamic storage allocation: eliminating the need for pre-provisioning;'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持动态存储分配：消除预配置的需求；
- en: 'Accelerates the expansion of the storage vendor ecosystem: increasing the number
    of options supported by Kubernetes; and'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速存储供应商生态系统的扩展：增加Kubernetes支持的选择数量；
- en: 'Provides an out-of-source tree design: lowering the entry point for developers
    to implement volume drivers, eliminating risks with source code contributions
    and decoupling Kubernetes release cycles from storage vendors’ development cycles.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了源代码树外的设计：降低开发人员实现卷驱动程序的门槛，消除源代码贡献的风险，并使Kubernetes发布周期与存储供应商的开发周期解耦。
- en: The next section discusses how Anthos makes stateful containers more portable
    through Anthos Ready Storage and the adherence to CSI.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将讨论Anthos如何通过Anthos Ready Storage和遵循CSI来使有状态容器更具可移植性。
- en: D.3 Anthos and Storage
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: D.3 Anthos和存储
- en: The abstraction of storage as a set of persistent volumes of different sizes,
    allocated and de-allocated dynamically, on demand, constitutes a core value of
    what Kubernetes delivers to end users. CSI provides an extensible southbound interface
    to a vendor’s storage system, shielding the heterogeneity across the storage device
    spectrum, delivering a consistent and uniform interface for Kubernetes, and all
    other container orchestration engines. At the same time, Kubernetes provides a
    standard northbound interface for Kubernetes users to interact with storage at
    a higher level of abstraction, in terms of PVs and PVCs, while CSI also allows
    developers to model disk with respect to disk encryption, snapshots and resizing.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 将存储抽象为一系列不同大小的持久卷，这些卷在需求时动态分配和释放，构成了Kubernetes提供给最终用户的核心价值。CSI为供应商的存储系统提供了一个可扩展的南向接口，屏蔽了存储设备谱系的异构性，为Kubernetes以及其他所有容器编排引擎提供了一个一致和统一的接口。同时，Kubernetes为Kubernetes用户提供了一个标准的北向接口，以便以更高层次的抽象（即PV和PVC）与存储进行交互，而CSI还允许开发者根据磁盘加密、快照和调整大小来对磁盘进行建模。
- en: So far, all the CSI topics covered relate to Kubernetes, not Anthos. This raises
    one interesting question. What is the value added, if any, that Anthos brings
    to the storage space, in addition to what Kubernetes does? One easy, perhaps even
    trivial answer, is that Anthos helps in the storage space by simply making the
    deployment and management of Kubernetes environments easier. By supporting CSI,
    Kubernetes is in fact expanding the realm of environments in which Anthos can
    deploy and manage Kubernetes clusters that support stateful containers.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，所有涵盖的CSI主题都与Kubernetes有关，而不是Anthos。这引发了一个有趣的问题。除了Kubernetes所做的工作之外，Anthos在存储领域增加了什么价值（如果有）？一个简单、甚至可能是微不足道的答案是，Anthos通过简化Kubernetes环境的部署和管理来帮助存储空间。通过支持CSI，Kubernetes实际上扩大了Anthos可以部署和管理支持有状态容器的Kubernetes集群的环境范围。
- en: In reality, however, Anthos delivers a lot of value today and has the potential
    to deliver much more in the near future, to support the usage of storage in hybrid
    and multi-cloud environments and to expand portability and management of stateful
    containers.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，实际上，Anthos今天提供了很多价值，并且在未来有潜力提供更多价值，以支持混合和多云环境中的存储使用，并扩展有状态容器的可移植性和管理。
- en: In Anthos, just like in Kubernetes, any pod that requires persistent storage
    constitutes a stateful pod. Persistent storage stores data beyond the lifetime
    of a pod and of any enclosure where it may be housed, such as its VM, its node
    in a cluster, or the cluster itself. In Anthos, the data will only cease to exist
    if the data itself is deleted by an entity that has the required Identity and
    Access Management (IAM) rights to do so
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在Anthos中，就像在Kubernetes中一样，任何需要持久存储的pod都构成一个有状态pod。持久存储存储的数据超出了pod及其可能存放的任何封装物的生命周期，例如其VM、集群中的节点或集群本身。在Anthos中，只有当具有执行此操作所需身份和访问管理（IAM）权限的实体删除数据时，数据才会停止存在。
- en: 'Anthos allows stateful pods to be deployed in hybrid and multi-cloud environments,
    and pods to communicate with data services that may run anywhere across the infrastructure
    spectrum. As depicted in [Figure D.2 Stateful Pods in Anthos](#bookmark2), the
    dashed rectangles delineate different environments, from left to right: GCP cloud
    (in blue), private cloud on-premise (in red), and any public cloud other than
    GCP (in brown). In each of the cloud environments, there are stateful Anthos pods
    running, accessing their own local physical storage for reading or writing data.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Anthos允许在有状态pod在混合和多云环境中部署，并且pod可以与可能运行在基础设施范围内的任何地方的数据服务进行通信。如[图D.2 Anthos中的有状态pod](#bookmark2)所示，虚线矩形界定了从左到右的不同环境：GCP云（蓝色）、本地私有云（红色）以及除GCP以外的任何公共云（棕色）。在每个云环境中，都有运行的有状态Anthos
    pod，它们访问自己的本地物理存储进行读写数据。
- en: '![D_02](../../OEBPS/Images/D_02.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![D_02](../../OEBPS/Images/D_02.png)'
- en: Figure D.2 Stateful Pods in Anthos
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图D.2 Anthos中的有状态pod
- en: 'Anthos offers two approaches to expand the spectrum of infrastructure storage
    that can be utilized, as described in the following sections:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下各节所述，Anthos提供了两种方法来扩展可以利用的基础设施存储范围：
- en: Anthos Managed Storage Drivers
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos托管存储驱动器
- en: Anthos Ready Storage Partner Program
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos Ready Storage Partner Program
- en: D.3.1 Anthos Managed Storage Drivers
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.3.1 Anthos托管存储驱动器
- en: 'Anthos installs, supports and maintains numerous storage drivers on each platform.
    These are the differentiating advantages of Anthos Managed Storage Drivers:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Anthos在每个平台上安装、支持和维护大量存储驱动器。这些是Anthos托管存储驱动器的差异化优势：
- en: 'Automation of driver selection: where Anthos selects the specific versions
    of the drivers that should be supported and managed on each node in a cluster.
    For example, Anthos deploys the GCE Persistent Disk and Filestore drivers on GCP,
    AWS EBS and EFS drivers on AWS, Azure Disk and Azure File drivers on Azure, and
    the vSphere driver on vSphere. Anthos clusters on bare-metal also bundle the [sig-storage-local-static-provisioner.](https://cloud.google.com/anthos/clusters/docs/bare-metal/latest/installing/storage#container_storage_interface_csi_drivers)
    Anthos effectively expands the surface of environments where Kubernetes clusters
    can be deployed and managed in an automated way;'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驱动器选择的自动化：Anthos选择应在集群中的每个节点上支持和管理特定版本的驱动器。例如，Anthos在GCP上部署GCE持久磁盘和文件存储驱动器，在AWS上部署AWS
    EBS和EFS驱动器，在Azure上部署Azure磁盘和Azure文件驱动器，在vSphere上部署vSphere驱动器。在裸金属上的Anthos集群还捆绑了[sig-storage-local-static-provisioner.](https://cloud.google.com/anthos/clusters/docs/bare-metal/latest/installing/storage#container_storage_interface_csi_drivers)。Anthos有效地扩大了可以自动部署和管理Kubernetes集群的环境范围；
- en: 'Management of drivers: as the number of drivers increases, Anthos aids in the
    integration and deployment of these drivers into a customer’s Kubernetes environment.
    As new nodes are created, Anthos ensures that storage is available and accessible
    by the new nodes, dynamically, without user intervention. Anthos automates the
    decision of which driver version to use in specific scenarios. Anthos also has
    the ability to manage the entire driver lifecycle and provide support for them.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驱动程序管理：随着驱动程序数量的增加，Anthos帮助将这些驱动程序集成和部署到客户的Kubernetes环境中。随着新节点的创建，Anthos确保存储对新的节点动态可用且可访问，无需用户干预。Anthos自动化了在特定场景中决定使用哪个驱动程序版本的决策。Anthos还具有管理整个驱动程序生命周期并提供支持的能力。
- en: The Google Cloud [Marketplace](https://cloud.google.com/marketplace) contains
    a [set of stateful engines](https://screenshot.googleplex.com/mdDNpAs6jTh33Ma.png)
    that Anthos customers can use, such as Redis Enterprise.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud [Marketplace](https://cloud.google.com/marketplace) 包含一系列Anthos客户可以使用的[有状态引擎](https://screenshot.googleplex.com/mdDNpAs6jTh33Ma.png)，例如Redis
    Enterprise。
- en: D.3.2 Anthos Ready Storage Partner Program
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.3.2 Anthos Ready Storage合作伙伴计划
- en: In addition to Anthos Managed Storage Drivers, users can bring other storage
    vendors of their choice. Anthos has created the Anthos Ready Storage program to
    work with selected third party storage partners to develop, test and qualify their
    CSI drivers with Anthos. This program ensures that the implementation of the CSI
    driver delivered by these qualifying storage vendor partners provides a seamless
    experience in Anthos. The latest list of qualified drivers can be found on the
    [Anthos Ready Storage partners](https://cloud.google.com/anthos/docs/resources/partner-storage)
    site.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Anthos管理的存储驱动程序之外，用户还可以引入他们选择的其它存储供应商。Anthos创建了Anthos Ready Storage计划，与选定的第三方存储合作伙伴合作，开发、测试和验证他们的CSI驱动程序与Anthos兼容。此计划确保这些资格认证的存储供应商合作伙伴提供的CSI驱动程序的实现，在Anthos中提供无缝体验。合格驱动程序的最新列表可以在[Anthos
    Ready Storage合作伙伴](https://cloud.google.com/anthos/docs/resources/partner-storage)网站上找到。
- en: 'In order for a storage system to be validated as Anthos Ready Storage, it must
    go through the Anthos process for the qualification of CSI drivers. Anthos provides
    a quality assurance process to test drivers and check interoperability between
    Kubernetes, the drivers and underlying storage. This process ensures that third
    party CSI drivers are up to par with Anthos standards. By introducing standardization,
    CSI extended the ecosystem of storage vendors writing plugins and lowered the
    barrier to entry for developing them. As a result, an avalanche of new plugins
    and updates started emerging in the market that required testing and quality assurance.
    The storage vendor’s drivers must meet the following requirements:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使存储系统被验证为Anthos Ready Storage，它必须通过CSI驱动程序的Anthos资格认证流程。Anthos提供了一项质量保证流程来测试驱动程序并检查Kubernetes、驱动程序和底层存储之间的互操作性。此流程确保第三方CSI驱动程序符合Anthos标准。通过引入标准化，CSI扩展了编写插件的存储供应商生态系统，并降低了开发它们的门槛。因此，市场上开始涌现大量新的插件和更新，需要测试和质量保证。存储供应商的驱动程序必须满足以下要求：
- en: Dynamic storage provisioning of volumes and other Kubernetes native storage
    API functions required by customers;
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户所需的卷和其他Kubernetes原生存储API函数的动态存储分配；
- en: Use of Kubernetes for deploying a storage CSI driver and its dependencies;
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kubernetes部署存储CSI驱动程序及其依赖项；
- en: Management of storage for Kubernetes scale up and scale down scenarios; and
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理Kubernetes的扩展和缩减场景中的存储；
- en: Portability of stateful workloads that are using persistent storage.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用持久存储的有状态工作负载的可移植性。
- en: D.3.3 Anthos Backup Services
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.3.3 Anthos备份服务
- en: With well-developed, stable CSI features, users can reliably deploy and run
    their stateful workloads like relational databases in managed Kubernetes clusters
    in Anthos. Stateful workloads typically have additional requirements over stateless
    ones, including the need for backup and storage management.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在Anthos中管理的Kubernetes集群中，具有良好开发、稳定的CSI功能，用户可以可靠地部署和运行他们的有状态工作负载，如关系型数据库。有状态工作负载通常比无状态工作负载有额外的需求，包括备份和存储管理。
- en: Anthos provides a simple to use, cloud-native service, namely [Backup for GKE](https://cloud.google.com/blog/products/storage-data-transfer/google-cloud-launches-backups-for-gke),
    for users to protect, manage and restore their containerized applications and
    data running in Google Cloud GKE clusters.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Anthos提供了一个简单易用的云原生服务，即[Backup for GKE](https://cloud.google.com/blog/products/storage-data-transfer/google-cloud-launches-backups-for-gke)，供用户保护、管理和恢复在Google
    Cloud GKE集群中运行的容器化应用程序和数据。
- en: 'Two forms of data are captured in a backup:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 备份中捕获两种形式的数据：
- en: 'Cluster state backup or config backup: which consists of a set of Kubernetes
    resource descriptions extracted from the API server of the cluster undergoing
    backup; and'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群状态备份或配置备份：它由从正在备份的集群的API服务器中提取的一组Kubernetes资源描述组成；并且
- en: 'Volume backups: which consists of a set of [GCE Persistent Disk (PD)](https://cloud.google.com/persistent-disk)
    volume snapshots that correspond to PersistentVolumeClaim resources found in the
    config backup.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷备份：它由一组与配置备份中找到的PersistentVolumeClaim资源相对应的GCE持久磁盘（PD）卷快照组成。
- en: Backup and restore operations in Backup for GKE are selective. When performing
    a backup, the user may select which workloads to backup, including the option
    to select “all workloads”. Likewise, when performing a restore, the user may select
    which workloads to restore, including the option to select “all workloads that
    were captured in this backup”. You can backup workloads from one cluster and restore
    them into another cluster.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Backup for GKE中的备份和恢复操作是可选的。在执行备份时，用户可以选择要备份的工作负载，包括选择“所有工作负载”的选项。同样，在执行恢复时，用户可以选择要恢复的工作负载，包括选择“在此备份中捕获的所有工作负载”。您可以从一个集群备份工作负载并将它们恢复到另一个集群。
- en: Restore operations involve a carefully orchestrated re-creation of Kubernetes
    resources in the target cluster. Once the resources are created, actual restoration
    of workload functionality is subject to the normal cluster reconciliation process.
    For example, Pods get scheduled to Nodes, and then start on those Nodes. During
    restoration, the user may also optionally apply a set of transformation/substitution
    rules to change specific parameters in specific resources before creating them
    in the target cluster.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 恢复操作涉及在目标集群中精心编排的Kubernetes资源的重新创建。一旦资源创建完成，工作负载功能的实际恢复将受正常集群协调过程的约束。例如，Pods被调度到Nodes，然后在那些Nodes上启动。在恢复过程中，用户还可以选择性地应用一组转换/替换规则，在创建目标集群中的资源之前更改特定资源中的特定参数。
- en: 'This combination of selective backup and selective restore with transformations
    is designed to enable and support a number of different backup and restore scenarios
    including, but not limited to:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这种选择性的备份和恢复与转换的组合旨在启用并支持多种不同的备份和恢复场景，包括但不限于：
- en: Backup all workloads in a cluster and restore them into a separately prepared
    Disaster Recovery (DR) cluster;
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备份集群中的所有工作负载并将它们恢复到单独准备的灾难恢复（DR）集群；
- en: Backup all workloads, but selectively restore, i.e. rollback, a single workload
    in the source cluster;
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备份所有工作负载，但选择性地恢复，即回滚源集群中的单个工作负载；
- en: Backup the resources in one namespace and clone them into another one;
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个命名空间中备份资源并将它们克隆到另一个命名空间中；
- en: Migrate or clone a workload from one cluster to another; and
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将工作负载从一个集群迁移或克隆到另一个集群；并且
- en: Change the storage parameters for a particular workload. For example, move the
    workload from a zonal Persistent Disk (PD) to a regional PD or change the storage
    provisioner from the PD in-tree driver to the CSI driver.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更改特定工作负载的存储参数。例如，将工作负载从区域持久磁盘（PD）移动到区域PD或将存储提供程序从树内PD驱动程序更改为CSI驱动程序。
- en: It is worth noting at this point that Backup for GKE doesn’t backup GKE cluster
    configuration information, such as node configuration, node pools, initial cluster
    size and features enabled. Backup for GKE’s restore does not involve creating
    clusters either. It is up to the user to create a target cluster, if one doesn’t
    already exist, and install the Backup for GKE agent into that cluster before any
    restore operations may commence.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上值得注意，GKE的备份不包括备份GKE集群配置信息，例如节点配置、节点池、初始集群大小和启用的功能。GKE的恢复操作也不涉及创建集群。如果目标集群不存在，用户需要创建一个目标集群，并在任何恢复操作开始之前将Backup
    for GKE代理安装到该集群中。
- en: D.3.4  Looking Ahead
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.3.4  展望未来
- en: 'Looking ahead, Anthos has the potential to make management and usage of storage
    in Kubernetes, across hybrid and multi-cloud environments, significantly simpler
    and more automated. Examples include:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，Anthos有可能使在混合和多云环境中管理和使用Kubernetes存储变得更加简单和自动化。以下是一些例子：
- en: 'Easing the deployment of drivers: by creating blueprints and higher level abstractions
    to facilitate storage vendors in specifying the deployment of their CSI drivers;
    and'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简化驱动器的部署：通过创建蓝图和更高层次的抽象，以方便存储供应商指定其CSI驱动器的部署；
- en: 'Introducing a marketplace for drivers: by offering a one click deployment within
    Google Cloud, instead of requiring users to jump out of context to reach storage
    vendor sites to retrieve YAML files to deploy the drivers themselves.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入一个驱动器市场：通过在谷歌云中提供一键部署，而不是要求用户跳出上下文到达存储供应商网站以检索YAML文件来部署驱动器。
- en: D.4 BigQuery Omni Powered by Anthos
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: D.4 由Anthos驱动的BigQuery Omni
- en: '[BigQuery](https://cloud.google.com/bigquery), a petabyte-scale data warehouse,
    has become a platform for users to access an ever increasing portfolio of Google’s
    analytics products, such as Auto-ML and Tables. The BigQuery team at Google wanted
    to extend these same analytics capabilities to data that resides on other public
    clouds, without requiring customers to migrate or duplicate their data on Google
    Cloud. The ability to analyze data resident in other clouds, without the need
    to move the data, defines a new field referred to as multi-cloud analytics.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[BigQuery](https://cloud.google.com/bigquery)，一个PB级规模的数据仓库，已成为用户访问谷歌不断增长的分析产品组合的平台，例如Auto-ML和Tables。谷歌的BigQuery团队希望将这些相同的分析能力扩展到其他公有云上的数据，而无需要求客户将数据迁移或复制到谷歌云。无需移动数据即可分析其他云中驻留的数据，这定义了一个新的领域，被称为多云分析。'
- en: 'BigQuery Omni extends BigQuery capabilities to analyze data to data residing
    in multiple clouds, be it using standard SQL or be it using all of BigQuery’s
    interactive user experience to perform ad-hoc queries on the data. At a high level,
    BigQuery consists of two completely decoupled [components](https://research.google/pubs/pub36632/):
    compute and storage. The compute component consists of a very resilient and stateless
    query engine, known internally at Google as [Dremel](https://cloud.google.com/files/BigQueryTechnicalWP.pdf),
    capable of executing standard SQL like queries in a very efficient manner. The
    storage component consists of a highly scalable, optimally partitioned, densely
    compressed, columnar based data storage engine. These two components interface
    via a well defined set of APIs. This decoupling allows both components to scale
    independently. For use cases that require more data than analytics, the storage
    scales to accommodate the data size. For analytics intensive use cases, compute
    scales accordingly without requiring more storage to be allocated.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery Omni扩展了BigQuery的能力，以分析驻留在多个云中的数据，无论是使用标准SQL还是使用BigQuery的所有交互式用户体验来对数据进行即席查询。从高层次来看，BigQuery由两个完全解耦的[组件](https://research.google/pubs/pub36632/)组成：计算和存储。计算组件由一个非常健壮且无状态的查询引擎组成，在谷歌内部被称为[Dremel](https://cloud.google.com/files/BigQueryTechnicalWP.pdf)，能够以非常高效的方式执行标准SQL查询。存储组件由一个高度可扩展、最优分区、密集压缩的基于列的数据存储引擎组成。这两个组件通过一组定义良好的API进行交互。这种解耦允许两个组件独立扩展。对于需要比分析更多数据的用例，存储扩展以适应数据大小。对于计算密集型的用例，计算相应扩展，而无需分配更多存储。
- en: The BigQuery Omni engineering team was faced with the challenge of operating
    these components outside of Google's internal "borg" infrastructure. They leverage
    the similarities of Kubernetes and "borg", along with Anthos's multi-cloud support
    to overcome these challenges.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery Omni工程团队面临着在谷歌内部“borg”基础设施之外运行这些组件的挑战。他们利用Kubernetes和“borg”的相似性，以及Anthos的多云支持来克服这些挑战。
- en: BigQuery Omni uses Anthos GKE as the management software to operate the Dremel
    query engine in the same region where your data resides in a public cloud. Dremel
    is deployed, runs and is operated on an Anthos GKE in a Google-managed account
    in the public cloud where the data is stored. With Anthos, Google Cloud has been
    able to launch BigQuery Omni which allows Google Cloud to extend its analytics
    capabilities to data residing on other clouds, such as AWS and Microsoft Azure.
    Please refer to [this link](https://www.youtube.com/watch?v=hNRd6GsXxVE) for a
    demonstration of BigQuery Omni.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery Omni 使用 Anthos GKE 作为管理软件，在公共云中与数据驻留的同一区域运行 Dremel 查询引擎。Dremel 在公共云中存储数据的
    Google 管理账户上的 Anthos GKE 中部署、运行和操作。通过 Anthos，Google Cloud 能够推出 BigQuery Omni，这使得
    Google Cloud 能够将其分析能力扩展到其他云中的数据，例如 AWS 和 Microsoft Azure。请参阅 [此链接](https://www.youtube.com/watch?v=hNRd6GsXxVE)
    以查看 BigQuery Omni 的演示。
- en: It is important to note that, while BigQuery Omni leverages the power of Anthos
    GKE, a user is not obligated to be an Anthos customer. The BigQuery Omni engineering
    team is the Anthos customer in this case and BigQuery Omni users do not interact
    directly with Anthos GKE.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，尽管 BigQuery Omni 利用 Anthos GKE 的强大功能，但用户并不必须成为 Anthos 的客户。在这种情况下，BigQuery
    Omni 工程团队是 Anthos 的客户，BigQuery Omni 用户不会直接与 Anthos GKE 交互。
- en: As depicted in [Figure D.3 BigQuery Omni Technology Stack](#bookmark3), BigQuery
    Omni introduces the ability to run BigQuery query engine, Dremel, both in GCP
    and on other public clouds, such as AWS and Microsoft Azure. The architecture
    components are distributed as follows. In GCP, the BigQuery technology stack remains
    unchanged. From bottom to top, it consists of the BigQuery storage that is connected
    via a Petabit network to the BigQuery compute clusters where Dremel runs. In order
    to temporarily store and cache intermediate query results, which can be of the
    order of terabytes for some complex analytics, Dremel implements a distributed
    memory shuffle tier. When running on a public cloud other than GCP, in AWS for
    example, rather than migrating the data from that cloud to BigQuery’s managed
    storage in Google, BigQuery Omni executes the analytics on the data resident in
    the cloud’s native storage system.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [图 D.3 BigQuery Omni 技术栈](#bookmark3) 所示，BigQuery Omni 引入了在 GCP 和其他公共云（如 AWS
    和 Microsoft Azure）上运行 BigQuery 查询引擎 Dremel 的能力。架构组件分布如下。在 GCP 中，BigQuery 技术栈保持不变。从下到上，它包括通过
    Petabit 网络连接到运行 Dremel 的 BigQuery 计算集群的 BigQuery 存储。为了临时存储和缓存中间查询结果，这些结果对于某些复杂分析可能达到千兆字节级别，Dremel
    实现了一个分布式内存洗牌层。当在除 GCP 之外的公共云（例如 AWS）上运行时，而不是将数据从该云迁移到 Google 管理的 BigQuery 存储中，BigQuery
    Omni 在云的本地存储系统中执行分析。
- en: In BigQuery Omni, when a user performs a query accessing multi-cloud data, BigQuery
    Routers use a secure connection to literally route the query to the Dremel engine
    running where the data resides. The Dremel workload must be given access to the
    data residing on the public cloud. Query results can be exported directly back
    to the data storage, with no cross-cloud movement of the query results or the
    data used for the query. BiqQuery Omni also supports loading files to “regular”
    BigQuery for users needing to join data resident in BigQuery or train ML models
    using VertexAI.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在 BigQuery Omni 中，当用户执行查询以访问多云数据时，BigQuery 路由器会使用安全连接将查询直接路由到数据驻留处的 Dremel 引擎。必须授予
    Dremel 工作负载访问公共云中驻留的数据的权限。查询结果可以直接导回到数据存储，无需跨云移动查询结果或用于查询的数据。BigQuery Omni 还支持将文件加载到“常规”BigQuery
    中，以满足需要将驻留在 BigQuery 中的数据合并或使用 VertexAI 训练 ML 模型的用户。
- en: '![D_03](../../OEBPS/Images/D_03.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![D_03](../../OEBPS/Images/D_03.png)'
- en: Figure D.3 BigQuery Omni Technology Stack
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 D.3 BigQuery Omni 技术栈
- en: D.4.1 Giving BigQuery Access to Data in AWS
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.4.1 授予 BigQuery 访问 AWS 中的数据
- en: In order to enable BigQuery Omni to do a query on data residing on AWS, a user
    needs to have an AWS account and permission to modify the Identity and Access
    Management (IAM) policies of the S3 data to grant BigQuery access. There are several
    steps associated with the process, as outlined in the following sections.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 BigQuery Omni 能够在 AWS 上对驻留的数据进行查询，用户需要拥有 AWS 账户，并有权修改 S3 数据的标识符和访问管理（IAM）策略，以授予
    BigQuery 访问权限。以下各节概述了与此过程相关的几个步骤。
- en: Creating an AWS IAM Role and Read Policy
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 AWS IAM 角色和读取策略
- en: The user must first create an AWS IAM role and a read policy for the S3 the
    user wants to give BigQuery access to, and then attach the role and the police
    together. Please refer to the Google Cloud BigQuery Omni [documentation](https://cloud.google.com/bigquery-omni/docs/aws/create-connection)
    or the AWS documentation for the latest instructions on how to perform these tasks.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 用户必须首先创建一个 AWS IAM 角色和读取策略，以便为用户想要授予 BigQuery 访问权限的 S3 创建，然后将角色和政策一起附加。请参阅 Google
    Cloud BigQuery Omni [文档](https://cloud.google.com/bigquery-omni/docs/aws/create-connection)或
    AWS 文档，获取执行这些任务的最新说明。
- en: Define an External Table
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 定义外部表
- en: After creating the connection, the user needs to create an External Table definition
    for their data stored in S3\. Please refer to the Google Cloud BigQuery Omni [documentation](https://cloud.google.com/bigquery-omni/docs/aws/create-external-table)
    or the AWS documentation for the latest instructions on how to perform these tasks.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 创建连接后，用户需要为存储在 S3 中的数据创建一个外部表定义。请参阅 Google Cloud BigQuery Omni [文档](https://cloud.google.com/bigquery-omni/docs/aws/create-external-table)或
    AWS 文档，获取执行这些任务的最新说明。
- en: D.4.2 Capitalizing on BigQuery’s Storage Design Optimization
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.4.2 利用 BigQuery 存储设计优化
- en: BigQuery’s scalability and high performance derive from a combination of design
    choices made that compound on each other. For example, in order to optimize for
    query analytics, BigQuery storage engine stores data in a [columnar format](https://cloud.google.com/blog/products/gcp/inside-capacitor-bigquerys-next-generation-columnar-storage-format),
    and partitions and clusters the data to reduce the search space of the query.
    If the remote data is not stored and organized in the same manner, this may lead
    to some degradations in performance relative to running BigQuery on Google Cloud.
    However, the benefits of being able to use BigQuery analytics to unlock the value
    of the data, in its existing format and in its existing location, without incurring
    any migration effort may be an acceptable trade off.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery 的可扩展性和高性能源于一系列相互增强的设计选择。例如，为了优化查询分析，BigQuery 存储引擎以 [列式格式](https://cloud.google.com/blog/products/gcp/inside-capacitor-bigquerys-next-generation-columnar-storage-format)存储数据，并对数据进行分区和聚类以减少查询的搜索空间。如果远程数据没有以相同的方式存储和组织，这可能会导致相对于在
    Google Cloud 上运行 BigQuery 的性能有所下降。然而，能够使用 BigQuery 分析来解锁数据的价值，无论其现有格式和位置如何，且无需进行任何迁移工作，这可能是一个可接受的权衡。
- en: 'Users always have the option to optimize the data for BigQuery Omni analytics
    by emulating some of the technology approaches performed by BigQuery, including:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 用户始终可以选择通过模拟 BigQuery 执行的一些技术方法来优化 BigQuery Omni 分析的数据，包括：
- en: 'Conversion of the data into a columnar format: enabling the data to be retrieved
    column by column. In most use cases, analytics look at all the values in columns
    as opposed to doing a range scan of rows in a table. As a result, columnar formats
    such as [Apache Parquet](https://parquet.apache.org/) optimize for retrieval of
    columns, reducing the amount of data accessed during the analytics, and consequently,
    increasing performance and reducing costs.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据转换为列式格式：使数据能够按列检索。在大多数用例中，分析查看列中的所有值，而不是对表中的行进行范围扫描。因此，如 [Apache Parquet](https://parquet.apache.org/)
    这样的列式格式优化了列的检索，减少了分析过程中访问的数据量，从而提高了性能并降低了成本。
- en: 'Compression of the data: enabling less bytes to be retrieved from storage.
    For data stored in columnar formats, compression can capitalize on the fact that
    columnar entries can be very repetitive or follow a pattern, for example, of consecutive
    numbers. Apache Parquet uses [Google Snappy](https://github.com/google/snappy)
    to compress columnar data.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据压缩：使从存储中检索的字节数更少。对于存储在列式格式中的数据，压缩可以利用列式条目非常重复或遵循模式的事实，例如连续数字的模式。Apache Parquet
    使用 [Google Snappy](https://github.com/google/snappy) 来压缩列式数据。
- en: 'Partitioning of the data: enabling a more efficient data scan, when searching
    for specific data values. BigQuery uses [hive partitioning](https://www.tutorialspoint.com/hive/hive_partitioning.htm).'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据分区：在搜索特定数据值时，使数据扫描更加高效。BigQuery 使用 [Hive 分区](https://www.tutorialspoint.com/hive/hive_partitioning.htm)。
- en: D.4.3 Differentiation Behind BigQuery Omni
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.4.3 BigQuery Omni 的差异化
- en: BigQuery Omni differentiates itself from other distributed query engines such
    as [Presto](https://prestodb.io/), in how it can, over time, leverage Anthos as
    a management platform to not only deploy, but also monitor, operate, update and
    administer the entire lifecycle of the query. In essence, BigQuery wanted a multi-cloud
    story for customers. BigQuery needed a Google “borg” like multi-cloud solution
    so that Dremel would work on AWS and Microsoft Azure almost exactly like it does
    on Google Cloud.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery Omni 与其他分布式查询引擎（如 [Presto](https://prestodb.io/)）不同，它能够随着时间的推移，利用 Anthos
    作为管理平台，不仅部署，还能监控、操作、更新和管理查询的整个生命周期。本质上，BigQuery 希望为用户提供一个多云故事。BigQuery 需要一个类似于
    Google “borg” 的多云解决方案，以便 Dremel 能够在 AWS 和 Microsoft Azure 上几乎与在 Google Cloud 上一样工作。
- en: BigQuery query engine also runs on a GKE environment, capitalizing all modern
    features of a cloud native deployment.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery 查询引擎也运行在 GKE 环境中，充分利用了云原生部署的所有现代功能。
- en: It is important to note that, perhaps historically for the first time, a cloud
    vendor, in this case Google, has deployed truly proprietary and differentiated
    code, Dremel, within the boundaries of a cloud competitor. One can argue that
    Google had already run GKE on AWS and MS Azure, and this too is proprietary code.
    But the key differentiation in this case is that GKE is a platform for managing
    containers, a capability that, today, all cloud providers possess, while Dremel
    holds the key to analytics at scale, driving significant value to Google users.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，也许历史上第一次，一个云服务提供商，在这个案例中是 Google，在云竞争对手的边界内部署了真正专有的和差异化的代码，即 Dremel。可以争论说，Google
    已经在 AWS 和 MS Azure 上运行 GKE，这同样是专有代码。但在此案例中的关键区别在于，GKE 是一个管理容器的平台，这是一个今天所有云提供商都拥有的能力，而
    Dremel 则掌握着大规模分析的关键，为 Google 用户带来了显著的价值。
- en: Ultimately, BigQuery Omni brings to the world of multicloud a consistent user
    experience, with a single pane of glass, for data analytics residing in multiple
    clouds, tearing down silos that have been previously cemented around cloud borders.
    With Anthos, BigQuery Omni leverages it as a secure multi-cloud infrastructure
    platform for the foundation to provide analytics on data residing in other clouds.
    And BigQuery does all that without any cross-cloud data movement and without creating
    any copies of the data.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，BigQuery Omni 为多云世界带来了一致的用户体验，通过一个统一的界面，对驻留在多个云中的数据进行数据分析，打破了之前围绕云边界的壁垒。通过
    Anthos，BigQuery Omni 利用它作为安全的多云基础设施平台，为基础提供对驻留在其他云中的数据的分析。BigQuery 做所有这些事情，而不进行任何跨云数据移动，也不创建任何数据的副本。
- en: D.4.4 Anthos Hybrid AI
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.4.4 Anthos 混合 AI
- en: Google is at the forefront of the AI revolution, and infuses its cutting-edge
    AI technology in many of its products giving its users capabilities such as auto-complete
    while typing on any Google product. Google Cloud AI makes available to users many
    of these industry-leading AI technologies that have been ideated, incubated, implemented
    and continuously improved upon by Google Cloud, Google and the broader Alphabet
    family of companies. Google continues to attract and nurture top AI talent. Recently,
    the Turing Award, considered the Nobel Prize in computing, has been awarded to
    two googlers for their contributions in the field. In 2017, David Patterson received
    the award for helping to develop an approach for faster, lower power microprocessors,
    now used in 99% of all microprocessors in smartphones, tablets and many Internet
    of Things (IoT) devices. In 2018, Geoffrey Hinton received the award for laying
    the foundation of deep neural networks which have spurred major advances in computer
    vision, speech recognition and natural language understanding.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Google 是 AI 革命的先锋，并将其最前沿的 AI 技术融入了许多产品中，为用户提供了诸如在输入任何 Google 产品时自动完成等功能。Google
    Cloud AI 向用户提供了许多这些由 Google Cloud、Google 以及更广泛的 Alphabet 公司家族公司构思、孵化、实施并持续改进的行业领先
    AI 技术。Google 继续吸引和培养顶尖的 AI 人才。最近，图灵奖，被认为是计算机领域的诺贝尔奖，授予了两位 Google 员工，以表彰他们在该领域的贡献。2017
    年，David Patterson 因帮助开发了一种更快、功耗更低的微处理器方法而获得奖项，现在这种方法被用于 99% 的智能手机、平板电脑和许多物联网 (IoT)
    设备中的微处理器。2018 年，Geoffrey Hinton 因奠定了深度神经网络的基础而获得奖项，这些神经网络推动了计算机视觉、语音识别和自然语言理解的重大进步。
- en: Up until now, however, customers could only benefit from these technological
    advancements by moving their data to Google Cloud, a requirement that many enterprises
    could not meet due to several constraints including security, privacy, and regulatory
    compliance. Furthermore, even if some portion of the data could be moved to cloud,
    any learnings in terms of software development could not be brought back to the
    remaining on-premise data because the same tools and APIs were not available on-prem.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，到目前为止，客户只能通过将数据移动到谷歌云来从这些技术进步中受益，由于包括安全、隐私和合规性在内的多个限制，许多企业无法满足这一要求。此外，即使部分数据可以移动到云端，由于本地没有相同的工具和
    API，软件开发方面的任何学习都无法带回剩余的本地数据。
- en: With Anthos, Google Cloud has engaged in a strategy to enable users to benefit
    from Google’s advancements in AI without requiring the data to move to Google
    Cloud. Similar to BigQuery Omni where Anthos has enabled the deployment of Google’s
    BigQuery query engine, Dremel, on other public clouds, Google Cloud Hybrid AI
    leverages Anthos to deploy and run Google’s AI services on-prem, close to where
    the data is.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 Anthos，谷歌云推出了一项策略，让用户能够从谷歌在人工智能方面的进步中受益，而无需将数据移动到谷歌云。类似于 Anthos 在 BigQuery
    Omni 中使谷歌的 BigQuery 查询引擎 Dremel 在其他公有云上部署的情况，谷歌云混合人工智能利用 Anthos 在本地部署和运行谷歌的人工智能服务，靠近数据所在的位置。
- en: D.4.5 Hybrid AI Architecture
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.4.5 混合人工智能架构
- en: As depicted in [Figure D.4 Hybrid AI Technology Stack](#bookmark4), Hybrid AI
    enables the same AI models, that have been trained by Google, to be deployed and
    to run on-prem, making the same set of AI APIs used in the cloud accessible on-prem
    as well, where it can reach the local datasets.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图 D.4 混合人工智能技术栈](#bookmark4)所示，混合人工智能使得经过谷歌训练的相同人工智能模型能够在本地部署和运行，使得在云端使用的同一套人工智能
    API 也能在本地使用，从而能够访问本地的数据集。
- en: '![D_04](../../OEBPS/Images/D_04.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![D_04](../../OEBPS/Images/D_04.png)'
- en: Figure D.4 Hybrid AI Technology Stack
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 D.4 混合人工智能技术栈
- en: Hybrid AI starts with the premise that the user has one or more Anthos on-prem
    clusters already registered with GCP. Using [GCP marketplace](https://cloud.google.com/marketplace),
    the user can search for and discover Google Cloud AI solutions, such as a solution
    for converting speech to text, that will be explained in the following section.
    The user can select a solution and click-through deploy on an on-prem Anthos cluster.
    These AI solutions have been packaged as an Anthos App that can be deployed on
    any Anthos clusters, including those running on-prem. These solutions are fully
    managed by Anthos, and benefit from all Anthos capabilities, including auto-scaling
    which guarantees that on-prem compute resources are only allocated while in use,
    and only what is needed. Anthos meters these AI solutions and bills customers
    based only on usage. Anthos Hybrid AI allows AI applications to be deployed, run
    and be un-deployed dynamically, on-demand.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 混合人工智能的起点是用户已经在 GCP 上注册了一个或多个 Anthos 本地集群。通过 [GCP 市场place](https://cloud.google.com/marketplace)，用户可以搜索和发现谷歌云人工智能解决方案，例如下文将要解释的将语音转换为文本的解决方案。用户可以选择一个解决方案，并在本地
    Anthos 集群上点击部署。这些人工智能解决方案被打包成 Anthos 应用，可以在任何 Anthos 集群上部署，包括在本地运行的集群。这些解决方案由
    Anthos 完全管理，并享有所有 Anthos 功能，包括自动扩展，这保证了本地计算资源仅在需要时分配，并且只分配所需的资源。Anthos 对这些人工智能解决方案进行计量，并基于使用情况向客户收费。Anthos
    混合人工智能允许人工智能应用程序动态地部署、运行和卸载。
- en: D.4.6 Hybrid AI Solutions
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.4.6 混合人工智能解决方案
- en: 'The first release of Anthos Hybrid AI makes available the following Google
    Cloud AI services on-prem:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Anthos 混合人工智能的第一个版本在本地提供了以下谷歌云人工智能服务：
- en: 'Optical Character Recognition (OCR): which converts documents into a text in
    digital format; and'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光学字符识别 (OCR)：将文档转换为数字格式的文本；以及
- en: 'Speech-to-Text: which converts voice into text with support including English,
    French, Spanish, Cantonese and Japanese. The [Google Cloud version](https://cloud.google.com/speech-to-text/docs/languages)
    already supports more than one hundred different languages and variations allowing
    for easy inclusion of additional language to the on-prem version, driven by demand.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音转文本：将语音转换为文本，支持包括英语、法语、西班牙语、粤语和日语。[谷歌云版本](https://cloud.google.com/speech-to-text/docs/languages)已经支持一百多种不同的语言和变体，使得轻松将额外的语言包含到本地版本中，由需求驱动。
- en: The following sections discuss each of these use cases in greater detail.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 下文将更详细地讨论这些用例。
- en: Optical Character Recognition
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 光学字符识别
- en: Enterprises have a tremendous amount of data being held hostage in non-digitized
    media, such as paper documents, or hidden inside digital formats that do not allow
    them to be easily analyzed digitally. For example, a scanned digital image of
    an invoice or of a government issued title may function as a record of a transaction
    and a proof of ownership, respectively, but may still remain very challenging
    to extract the individual pieces of information that can be analyzed separately.
    The names of the entities involved in the deal, date, location, value, and specifics
    about the items exchanged may remain buried into the digital image. Previous efforts
    to digitize this information manually with humans entering the data have proven
    themselves to be error-prone, time consuming, cost prohibitive and hard to scale.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '企业持有大量数据被囚禁在非数字化媒体中，如纸质文件，或者隐藏在不允许它们被轻松数字化分析的数据格式中。例如，发票或政府颁发的标题的扫描数字图像可能分别作为交易记录和所有权证明，但仍然非常具有挑战性，难以提取可以单独分析的单个信息片段。交易中涉及的实体的名称、日期、地点、价值以及交换物品的详细信息可能仍然隐藏在数字图像中。以前手动数字化这些信息并让人类输入数据的努力已被证明是易出错的、耗时的、成本高昂且难以扩展。 '
- en: 'Extracting the information from these documents is a prerequisite to fully
    analyzing the data. Once the data being held by contracts, patents, forms, invoices,
    tickets stubs, PDFs, images and documents on many other forms can be decomposed
    into individual digital components, they can be automatically analyzed at scale,
    and may unlock unprecedented insight. This data may allow enterprises, for example,
    to better understand their customers, their products and services, their financial
    operations, their internal processes, their employees performance and many other
    aspects of their businesses. Use cases touch many industries including:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些文档中提取信息是全面分析数据的先决条件。一旦合同、专利、表格、发票、收据、PDF、图像以及许多其他形式的文档中持有的数据可以被分解成单个数字组件，它们就可以在规模上自动分析，并可能解锁前所未有的洞察。这些数据可能使企业能够更好地了解他们的客户、产品和服务、财务运营、内部流程、员工绩效以及他们业务的许多其他方面。用例涉及许多行业，包括：
- en: 'Pharmaceutical: for analyzing drug development data, from laboratory experimentation
    to clinical trial, where data is captured across a diverse set of data sources;'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 药品行业：用于分析从实验室实验到临床试验的药物开发数据，数据来自多样化的数据源；
- en: 'Legal: for doing discovery of information;'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 法律：用于信息发现；
- en: 'Insurance: for processing claims which may include analyzing images, and processing
    hand-written forms; and'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保险：用于处理索赔，这可能包括分析图像和处理手写表格；
- en: 'Asset management: for analyzing warranty, and maintenance data.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资产管理：用于分析保修和维护数据。
- en: Optical Character Recognition (OCR) consists of extracting the individual pieces
    of information residing in documents and converting them to digital format in
    an automated manner. In recent years, AI has brought a significant advancement
    in the automation of this process, relying heavily on Convolution Neural Network
    (CNN) models that can now be trained on massive amounts of data and bring tremendous
    accuracy to the process. tbd@ find some concrete examples and data sizes, and
    accuracy increase to add here.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 光学字符识别（OCR）包括从文档中提取单个信息片段并以自动化的方式将它们转换为数字格式。近年来，人工智能在自动化这一过程中取得了显著进步，严重依赖于卷积神经网络（CNN）模型，这些模型现在可以在大量数据上进行训练，并将巨大的准确性带给这一过程。待定：找到一些具体的例子和数据大小，以及准确度提高的情况添加在此。
- en: While public clouds hold the majority of advancements in OCR technologies and
    offer them in the form of managed services, the content of these documents had
    to be scanned and moved to the cloud for processing. In many cases, the information
    residing in these documents is very sensitive and often holds Personally Identifiable
    Information (PII). As a result, enterprises were reluctant to absorb the risk
    of transferring any of this data to the cloud. Hybrid AI enables organizations
    of all sizes to unlock the value of their on-prem data. Hybrid AI does not require
    to move the data to the cloud and, instead, moves cutting-edge analytics to where
    the data is. In essence, leveraging cloud AI technologies without being forced
    to migrate and host the data in the cloud.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然公共云在OCR技术方面取得了大多数进展，并以托管服务的形式提供，但这些文档的内容必须扫描并移动到云端进行处理。在许多情况下，这些文档中驻留的信息非常敏感，并且通常包含个人可识别信息（PII）。因此，企业不愿意承担将任何此类数据转移到云中的风险。混合人工智能使所有规模的组织都能够释放其本地数据的价值。混合人工智能不需要将数据移动到云端，而是将尖端分析移动到数据所在的位置。本质上，利用云人工智能技术，而无需被迫将数据和托管在云端。
- en: Speech-to-Text
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 语音转文本
- en: Speech, be it in the form of pure audio recording or be it as the audio stream
    in videos or live conversations, comprises yet another format in which valuable
    information remains trapped. A common approach to speech recognition consists
    of first transforming the speech into text, and then using Natural Language Processing
    (NLP) to gain insight into the semantics of the speech. Today, enterprises possess
    speech data that captures human-to-human interactions and human-to-machine interactions.
    For example, customer calls to contact centers may consist of an initial part
    completely assisted by machines, with the purpose of gathering data about the
    issue and more effectively routing the call to an available human agent, and a
    second part where the customer communicates with a human agent to solve the issue.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是以纯音频记录的形式还是作为视频或实时对话中的音频流，语音都构成了另一种格式，其中有价值的信息仍然被困其中。语音识别的常见方法首先是将语音转换为文本，然后使用自然语言处理（NLP）来深入了解语音的语义。如今，企业拥有捕捉人与人之间以及人与机器之间交互的语音数据。例如，客户向客服中心的电话可能包括一个完全由机器辅助的初始部分，目的是收集关于问题的数据并更有效地将电话路由到可用的真人代理，以及一个客户与真人代理沟通以解决问题的第二部分。
- en: Similar to OCR, the data to be converted from speech to text may require data
    to remain on-prem. These recordings may not only contain PII and sensitive information,
    but they may hold Intellectual Property (IP) on many aspects of the business,
    such as executive board level discussions on strategic directions, product launch,
    technologic innovations, and human resource related decisions.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 与OCR类似，需要从语音转换为文本的数据可能需要保留在本地。这些录音不仅可能包含PII和敏感信息，而且可能在许多业务方面持有知识产权（IP），例如战略方向、产品发布、技术创新以及与人力资源相关的决策。
- en: Another challenge with speech-to-text is the vocabulary used in communications.
    Enterprises often differ on the context in which they are talking, which tend
    to be specific to their industry, to their product lines, and code names used
    internally. As a result, generic models need to be customized to be more contextual
    and relevant to each business.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 语音转文本的另一个挑战是与通信中使用的词汇。企业往往在谈话的上下文中存在差异，这些上下文往往特定于其行业、产品线以及内部使用的代号。因此，通用模型需要定制以更具上下文性和相关性，针对每个业务进行优化。
- en: D.4.7 Differentiation Behind Hybrid AI
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: D.4.7 混合人工智能背后的差异化
- en: Hybrid AI introduces a unique approach to capitalizing on best-of-breed solutions
    and technological advancements of Google Cloud AI solutions, where the data residency
    is preserved, and the AI code that has been previously designed, developed, trained
    and tested meets the data where the data is, on-prem, as opposed to forcing the
    data to move to the cloud. By using AI models developed by Google, enterprises
    benefit from models that have been optimized to require less computing resources
    to run, that have been designed and trained to deliver more accurate results,
    and that have been architected to be smaller, consuming less resources.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 混合AI引入了一种独特的方法来利用Google Cloud AI解决方案的最佳解决方案和技术进步，数据驻留得到保留，之前设计、开发、训练和测试的AI代码在数据所在的地方，即在本地，而不是强迫数据移动到云端。通过使用Google开发的AI模型，企业可以受益于经过优化的模型，这些模型运行所需的计算资源更少，设计并训练以提供更准确的结果，并且被设计成更小，消耗更少的资源。
- en: 'By using Anthos, Hybrid AI brings a slew of advantages to how these AI workloads
    run on-prem, reducing their time to production and enabling the use of modern
    practices to manage their entire lifecycle. These AI workloads run on GKE clusters
    on-prem, managed by Anthos and, as a result, they benefit from all Anthos capabilities,
    including:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用Anthos，混合AI为这些AI工作负载在本地运行带来了众多优势，减少了它们的生产时间，并使现代实践得以用于管理其整个生命周期。这些AI工作负载在本地GKE集群上运行，由Anthos管理，因此，它们可以享受所有Anthos功能，包括：
- en: 'One click deployment: where AI applications can be started or terminated with
    one push of a button, and all underlying resources are dynamically allocated or
    unallocated, accordingly. In the case of AI workloads, this may include the usage
    of accelerators, such as GPUs, allowing organizations to leverage any pre-existing
    infrastructure and to increase their utilization;'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一键部署：AI应用可以通过一键操作启动或终止，所有底层资源都会相应地动态分配或释放。在AI工作负载的情况下，这可能包括使用加速器，如GPU，使组织能够利用任何现有的基础设施，并提高其利用率；
- en: 'Auto-scaling: where the clusters running the AI applications automatically
    scale out and in, as models are trained, customized or used for inferencing. This
    tremendously reduces operational efforts associated with AI workloads;'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动扩展：随着模型的训练、定制或用于推理，运行AI应用的集群会自动扩展和缩小，这极大地减少了与AI工作负载相关的运营工作量；
- en: 'A/B testing: where the performance of new AI models can be easily compared
    and contrasted;'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A/B测试：可以轻松比较和对比新AI模型的表现；
- en: 'Canary deployment: where phased deployment of new models can greatly mitigate
    any errors introduced in the customization or re-training of models;'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 金丝雀部署：新模型的分阶段部署可以大大减少在模型定制或再训练中引入的任何错误；
- en: 'Policy management: where AI engineers can manage the deployment and operation
    of these models through declarative policies;'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 政策管理：AI工程师可以通过声明性策略来管理这些模型的部署和运行；
- en: 'Life-cycle management: where AI models can benefit from version control and
    upgrade the deployment of models with one-click;'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生命周期管理：AI模型可以受益于版本控制和一键升级模型部署；
- en: 'Metrics logging and monitoring: where AI models gain all aspects of observability,
    with all logs sent to a centralized location. The status can be automatically
    monitored and the AI models can be managed using the same frameworks and application
    performance tools used for other applications;'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指标日志记录和监控：AI模型获得所有方面的可观察性，所有日志都发送到集中位置。状态可以自动监控，AI模型可以使用与其他应用程序相同的框架和应用性能工具进行管理；
- en: 'Usage based metering: where AI models are billed based only on how much it
    is used;'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于使用量的计费：AI模型仅根据其使用量计费。
- en: 'Service Mesh: where pre-built Istio objects can be leveraged to scale to thousands
    of connections;'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格：可以利用预构建的Istio对象扩展到数千个连接；
- en: '[Marketplace](https://cloud.google.com/marketplace): where AI models can be
    easily searched for and discovered;'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[市场](https://cloud.google.com/marketplace)：在这里可以轻松搜索和发现AI模型；'
- en: 'Consistent Continuous Integration/Continuous Development (CI/CD) processes:
    where the same workflows can be used on-prem and in the cloud; and'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一致的持续集成/持续开发（CI/CD）流程：在本地和云端可以使用相同的流程；以及
- en: 'Single Pane of Glass: where users have the same experience regardless of where
    their AI workloads are running.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单一视角：无论用户的AI工作负载运行在何处，用户都能获得相同的体验。
- en: Hybrid AI also brings a consistent and cohesive user experience for all running
    AI workloads on the cloud and on-prem, allowing users to learn a single set of
    tools to manage the entire lifecycle of AI applications. In addition to that,
    having AI workloads running on a GKE environment, allows these workloads to automatically
    capitalize on all modern features of a cloud native deployment.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 混合 AI 还为云和本地运行的所有 AI 工作负载提供一致和连贯的用户体验，使用户能够学习一套工具来管理 AI 应用程序的生命周期。此外，在 GKE 环境中运行
    AI 工作负载，允许这些工作负载自动利用云原生部署的所有现代功能。
- en: Hybrid AI marks only the beginning of a journey where organizations of all sizes
    can apply AI tools to their data on-prem, to not only customize and deploy models,
    but to also use notebooks for development of new models, tools for managing the
    entire lifecycle of AI applications, and pipelines for managing the data ingestion,
    transformation and storage. Anthos can also be used to enable several types of
    edge based processing, such as using vision recognition for image or object classification.
    In the future, Anthos will also support third party AI models to be deployed on-prem
    in the same manner. In which case, Anthos may also perform binary authorization
    and vulnerability scanning of third party software.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 混合 AI 只是开始，所有规模的组织都可以将 AI 工具应用于本地数据，不仅定制和部署模型，还可以使用笔记本开发新模型，使用工具管理 AI 应用程序的生命周期，以及使用管道管理数据摄取、转换和存储。Anthos
    还可以用于启用多种边缘处理类型，例如使用视觉识别进行图像或对象分类。未来，Anthos 还将支持在本地以相同方式部署第三方 AI 模型。在这种情况下，Anthos
    可能还会执行第三方软件的二进制授权和漏洞扫描。
- en: D.5 Summary
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: D.5 摘要
- en: Anthos and GCP provides portability and mobility to developers, persistent storage
    to accommodate workloads beyond stateless applications, and options for analytics
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos 和 GCP 为开发者提供可移植性和移动性，为超出无状态应用程序的工作负载提供持久存储，并为分析提供选项。
- en: Anthos aims at delivering rigour to data workloads, becoming a single layer
    of control, security, observability and communication between components
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos 致力于为数据工作负载提供严谨性，成为组件之间控制、安全、可观察性和通信的单层。
- en: Anthos manages first party CSI drivers on each platform and the Anthos Ready
    Storage program qualifies third party drivers from industry-leading storage partners.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos 在每个平台上管理第一方 CSI 驱动程序，并且 Anthos Ready Storage 计划认证来自行业领先存储合作伙伴的第三方驱动程序。
- en: Anthos isolates stateful applications from the heterogeneity of the underlying
    hardware and makes stateful containers more portable
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos 将有状态应用程序从底层硬件的异构性中隔离出来，使有状态容器更具可移植性。
- en: Anthos supports a wide selection of storage systems, both first and third party,
    meeting the user where they are and allowing them to leverage their existing storage
    systems
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos 支持广泛的存储系统，包括第一方和第三方，满足用户的需求，并允许他们利用现有的存储系统。
- en: An understanding of portability versus mobility - Portability refers to the
    ability to execute on several locations while mobility refers to the ability to
    transfer the location of a resource from one physical place to another.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解可移植性与移动性的区别 - 可移植性指的是在多个位置执行的能力，而移动性指的是将资源的地理位置从一地转移到另一地的能力。
- en: Kubernetes, and in turn, Anthos, supports storage using the Container Storage
    Interface (CSI).
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 支持使用容器存储接口 (CSI) 进行存储，而 Anthos 则支持这一功能。
- en: BigQuery Omni can execute on a GCP, GKE on AWS or on Microsoft Azure. This allows
    BigQuery query engine to access the customer’s data residing on other public clouds
    without requiring any data to be moved.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BigQuery Omni 可以在 GCP、AWS 上的 GKE 或 Microsoft Azure 上执行。这允许 BigQuery 查询引擎访问位于其他公共云上的客户数据，而无需移动任何数据。
- en: Anthos Hybrid AI enables the deployment and the execution of Google trained
    models on-prem, meeting data residency requirements.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthos 混合 AI 允许在本地部署和执行 Google 训练的模型，以满足数据驻留要求。
- en: Optical Character Recognition (OCR) decomposes documents into a digital format
    where individual components can be analyzed
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 光学字符识别 (OCR) 将文档分解为数字格式，其中可以分析各个组件。
- en: Speech-to-text converts audio recordings into text, where Natural Language Processing
    (NLP) can be used to understand the semantics of the speech
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音转文本将音频记录转换为文本，其中自然语言处理 (NLP) 可用于理解语音的语义。
