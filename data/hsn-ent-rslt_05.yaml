- en: Chapter 5\. Record Blocking
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章。记录阻塞
- en: In [Chapter 4](ch04.html#chapter_4), we introduced probabilistic matching techniques
    to allow us to combine exact equivalence on individual attributes into a weighted
    composite score. That score allowed us to calculate the overall probability that
    two records refer to the same entity.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第四章](ch04.html#chapter_4)中，我们介绍了概率匹配技术，以允许我们将单个属性上的确切等价性组合成加权的复合分数。该分数允许我们计算两个记录指向同一实体的总体概率。
- en: So far we have sought to resolve only small-scale datasets where we could exhaustively
    compare every record with every other to find all possible matches. However, in
    most entity resolution scenarios, we will be dealing with larger datasets where
    this approach isn’t practical or affordable.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只试图解决小规模数据集，其中我们可以逐个比较每条记录，以找到所有可能的匹配项。然而，在大多数实体解析场景中，我们将处理更大的数据集，这种方法并不实用或负担得起。
- en: In this chapter we will introduce record blocking to reduce the number of permutations
    we need to consider while minimizing the likelihood of missing a true positive
    match. We will leverage the Splink framework, introduced in the last chapter,
    to apply the Fellegi-Sunter model and use the expectation-maximization algorithm
    to estimate the model parameters.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍记录阻塞以减少我们需要考虑的排列组合数量，同时最小化漏掉真正匹配的可能性。我们将利用上一章介绍的Splink框架，应用Fellegi-Sunter模型，并使用期望最大化算法来估计模型参数。
- en: Lastly, we will consider how to measure our matching performance over this larger
    dataset.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将考虑如何测量我们在这个更大数据集上的匹配性能。
- en: Sample Problem
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例问题
- en: In previous chapters, we considered the challenge of resolving entities across
    two datasets containing information about members of the UK House of Commons.
    In this chapter, we extend this resolution challenge to a much larger dataset
    containing a list of the persons with significant control of registered UK companies.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们考虑了解决包含有关英国下议院议员信息的两个数据集之间的实体的挑战。在本章中，我们将这一解决方案挑战扩展到一个包含注册英国公司的实质控制人列表的规模更大的数据集。
- en: In the UK, Companies House is an executive agency sponsored by the Department
    for Business and Trade. It incorporates and dissolves limited companies, registering
    company information and making it available to the public.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在英国，公司注册处是由商业和贸易部赞助的执行机构。它合并和解散有限公司，注册公司信息并向公众提供信息。
- en: When registering a UK limited company, there is an obligation to declare who
    owns or controls a company. These entities are known as persons with significant
    control (PSCs); they’re sometimes called “beneficial owners.” Companies House
    provides a downloadable data snapshot containing the full list of PSCs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在注册英国有限公司时，有义务声明谁拥有或控制公司。这些实体称为具有重大控制权的人（PSC）；他们有时被称为“受益所有人”。公司注册处提供一个可下载的数据快照，其中包含所有PSC的完整列表。
- en: For this exercise, we will attempt to resolve the entities listed in this dataset
    with the list of members of Parliament we acquired from Wikipedia. This will show
    us which MPs may be PSC of UK companies.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此练习，我们将尝试解决此数据集中列出的实体与我们从维基百科获取的国会议员名单。这将向我们展示哪些国会议员可能是英国公司的PSC。
- en: Data Acquisition
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据获取
- en: In this example, we will reuse the same Wikipedia source data on MPs returned
    at the 2019 UK general election that we examined in previous chapters. However,
    to allow us to match against a much larger dataset,  without generating an unmanageable
    number of false positives, we need to enrich our initial data with additional
    attributes. Specifically, we will seek to augment our dataset with date of birth
    information, extracted from the individual wiki page associated with each of the
    MPs, to help strengthen the quality of our matches.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们将重复使用我们在之前章节中审查的2019年英国大选返回的相同维基百科来源数据。但是，为了允许我们与一个规模更大的数据集进行匹配，而不产生不可控制的假阳性，我们需要通过附加属性来丰富我们的初始数据。具体而言，我们将寻求使用从每个国会议员关联的个人维基页面中提取的出生日期信息来增强我们的数据集，以帮助增强我们匹配的质量。
- en: We will also download the most recent snapshot of the PSC data published by
    Companies House and then normalize and filter that dataset down to the attributes
    we need for matching.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将下载由公司注册处发布的最新PSC数据快照，然后将该数据集归一化并过滤到我们匹配所需的属性。
- en: Wikipedia Data
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维基百科数据
- en: To create our enriched Wikipedia dataset, we select the MPs from the wiki page
    as we did in [Chapter 2](ch02.html#chapter_2); however, this time we also extract
    the Wikipedia link to each individual MP and append this as an additional column
    in our DataFrame.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建我们增强的维基百科数据集，我们从维基页面中选择了MPs，就像我们在 [第 2 章](ch02.html#chapter_2) 中所做的那样；但是，这次我们还提取了每个个人MP的维基百科链接，并将其作为我们DataFrame中的额外列追加。
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can now follow these links and extract the date of birth information, if
    present, from the web page Infobox. As before, we can use the Beautiful Soup `html
    parser` to find and extract the attribute we need or return a default null value.
    The `apply` method allows us to apply this function to each row in the Wikipedia
    dataset, creating a new column entitled `Birthday`:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以跟随这些链接，并从网页信息框中提取出生日期信息（如果有的话）。与之前一样，我们可以使用Beautiful Soup `html parser`来查找并提取我们需要的属性，或者返回一个默认的空值。`apply`
    方法允许我们将此函数应用于维基百科数据集中的每一行，创建一个名为 `Birthday` 的新列：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: UK Companies House Data
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 英国公司注册处数据
- en: 'Companies House publishes a snapshot of PSC data in JSON format. It is made
    available both as a single ZIP file and as multiple ZIP files for ease of downloading.
    Extracting each partial ZIP file in turn allows us to normalize the JSON structure
    that we concatenate into a composite DataFrame of the attributes we need for matching
    plus the associated unique company number:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 公司注册处以JSON格式发布PSC数据的快照。这些数据既可以作为单个ZIP文件提供，也可以作为多个ZIP文件提供以便下载。依次提取每个部分的ZIP文件允许我们标准化JSON结构，将其拼接成一个复合DataFrame，包括我们需要用于匹配的属性以及相关联的唯一公司编号：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Data Standardization
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据标准化
- en: Now that we have the raw data we need, we standardize the attributes and column
    names across the two datasets. As we will be using the Splink framework, we also
    add a unique ID column.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有了所需的原始数据，我们标准化了两个数据集的属性和列名。由于我们将使用Splink框架，我们还添加了一个唯一的ID列。
- en: Wikipedia Data
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维基百科数据
- en: 'To standardize the date-enriched Wikipedia data, we convert the date column
    into month and year integers. As in [Chapter 2](ch02.html#chapter_2), we extract
    `Firstname` and `Lastname` attributes. We also add a unique ID column and a blank
    company number column to match the equivalent field in the Companies House data.
    Finally, we retain only the columns we need:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了标准化日期增强的维基百科数据，我们将日期列转换为月份和年份的整数。如同 [第 2 章](ch02.html#chapter_2) 中所述，我们提取
    `Firstname` 和 `Lastname` 属性。我们还添加了一个唯一的ID列和一个空的公司编号列，以匹配公司注册处数据中的相应字段。最后，我们保留我们需要的列：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: UK Companies House Data
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 英国公司注册处数据
- en: 'To standardize the UK Companies House data, we first drop any rows with missing
    year or month date of birth columns as we won’t be able to match these records.
    As with the Wikipedia data, we standardize the column names, generate the unique
    ID, and retain the matching subset:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了标准化英国公司注册处数据，我们首先删除了任何缺少出生年月日列的行，因为我们无法匹配这些记录。与维基百科数据一样，我们标准化列名，生成唯一ID，并保留匹配的子集：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let’s look at a few rows (with `Firstname`s and `Lastname`s sanitized), as shown
    in [Figure 5-1](#fig-5-1).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看几行（其中 `Firstname` 和 `Lastname` 已经过清理），如 [图 5-1](#fig-5-1) 所示。
- en: '![](assets/hoer_0501.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0501.png)'
- en: Figure 5-1\. Example rows of UK Companies House persons with significant control
    data
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-1\. 英国公司注册处具有重要控制人数据的示例行
- en: Record Blocking and Attribute Comparison
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记录阻塞和属性比较
- en: Now that we have consistent data, we can configure our matching process. Before
    we do, it’s worth taking a look at the size of the challenge. We have 650 MP records
    and our standardized PSC data has more than 10 million records. If we were to
    consider all permutations, we would have approximately 6 billion comparisons to
    make.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一致的数据，可以配置我们的匹配过程。在我们开始之前，值得一提的是挑战的规模。我们有650个MP记录，而我们标准化后的PSC数据超过1000万条记录。如果我们考虑所有的排列组合，我们将有大约60亿次比较要进行。
- en: 'Performing a simple join on records with matching `Month` and `Year` values,
    we can see the size of the intersection is approximately 11 million records:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在具有匹配 `Month` 和 `Year` 值的记录上执行简单的连接，我们可以看到交集的大小约为1100万条记录：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'A simple exact match on all four attributes yields 266 potential matches:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对所有四个属性进行简单的精确匹配，我们得到了266个潜在的匹配项：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: A sanitized sample of these simple join matches is shown in [Figure 5-2](#fig-5-2).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些简单连接匹配的经过清理的样本如 [图 5-2](#fig-5-2) 所示。
- en: '![](assets/hoer_0502.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0502.png)'
- en: Figure 5-2\. Simple join on `Lastname`, `Firstname`, `Year`, and `Month`
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-2\. 简单地根据 `Lastname`、`Firstname`、`Year` 和 `Month` 进行连接
- en: Record Blocking with Splink
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Splink进行记录阻塞
- en: To reduce the number of record combinations we need to consider, Splink allows
    us to configure blocking rules. These rules determine which record pairs are evaluated
    to determine whether they refer to the same entity. Clearly, considering only
    a subset of the population creates a risk of missing true matches, it’s important
    to select rules that minimize this while at the same time reducing the volume
    as much as possible.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少需要考虑的记录组合数量，Splink允许我们配置阻塞规则。这些规则确定了哪些记录对在评估是否引用同一实体时进行比较。显然，仅考虑人口的一个子集会导致错过真实匹配的风险，因此选择能够最小化这一风险并尽可能减少数量的规则非常重要。
- en: 'Splink allows us to create composite rules, essentially `OR` statements, where
    if any of the conditions are met, then the combination is selected for further
    comparison. However, in this example we’ll use only a single blocking rule that
    selects only records with matching year and month of birth:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Splink允许我们创建组合规则，实质上是`OR`语句，如果满足任何条件，则选择组合进行进一步比较。但在本例中，我们将仅使用一个选择仅具有匹配的年份和月份记录的单个阻塞规则：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Attribute Comparison
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 属性比较
- en: For the record comparisons that are produced by the blocking rules, we will
    determine whether they refer to the same person by using a combination of approximate
    matches scores on first name and last name and exact matches on month and year.
    Because we are comparing names, we use the Jaro-Winkler algorithm from [Chapter 3](ch03.html#chapter_3).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于由阻塞规则产生的记录比较，我们将使用近似匹配分数的组合来确定它们是否指向同一人，其中包括名字和姓氏的近似匹配以及月份和年份的精确匹配。因为我们在比较名字，所以使用了来自[第三章](ch03.html#chapter_3)的Jaro-Winkler算法。
- en: We can configure Splink with a set of minimum threshold values that together
    segment the population; Splink will add an exact match segment and a default zero
    match segment for those attribute pairs that score beneath the minimum value provided.
    In this case, we will just use a single threshold of 0.9 to illustrate the process,
    giving us three segments for each component of the name. Each segment is evaluated
    as a separate attribute for the purposes of calculating the overall match probability
    of the record pair.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以配置Splink的一组最小阈值值，这些值共同分割人群；Splink将为那些得分低于提供的最小值的属性对添加一个精确匹配段和一个默认的零匹配段。在这种情况下，我们将仅使用一个阈值0.9来说明这个过程，为每个名称组件给出三个段。每个段被视为单独的属性，用于计算记录对的整体匹配概率。
- en: 'Now that we have our settings, let’s instantiate our linker and profile the
    matching columns:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了设置，让我们实例化我们的链接器并配置匹配的列：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: You can see the results in [Figure 5-3](#fig-5-3).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[图5-3](#fig-5-3)中看到结果。
- en: '![](assets/hoer_0503.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0503.png)'
- en: Figure 5-3\. First name, last name, month, and year distributions
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-3. 名字、姓氏、月份和年份分布
- en: 'We can see that we have some common first names and last names with a long
    tail of less frequent values. For month of birth, the values are fairly regularly
    distributed but for year, we see some years are more likely than others. We can
    take this frequency distribution into account in our matching process by setting:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，我们有一些常见的名字和姓氏，还有一些不太常见的数值。出生月份的值分布相对均匀，但年份则有些年份比其他年份更常见。在我们的匹配过程中，可以通过设置以下内容考虑这种频率分布：
- en: '[PRE9]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Each year value will be considered separately for the purposes of calculating
    match probabilities; thus a match on an unpopular year will be weighted more highly
    than a match on a more frequently observed value.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 每个年份值将单独考虑，用于计算匹配概率；因此，对于不太流行的年份匹配，将比对较常见的值匹配更高地加权。
- en: As we did in [Chapter 4](ch04.html#chapter_4), we could use the expectation-maximization
    algorithm to determine the *m* and *u* values, that is, the match and not match
    probabilities, for each attribute segment. By default, these calculations consider
    the full population prior to applying the blocking rules.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第四章](ch04.html#chapter_4)中所做的那样，我们可以使用期望最大化算法来确定*m*和*u*值，即每个属性段的匹配和不匹配概率。默认情况下，这些计算考虑应用阻塞规则之前的整体人口。
- en: 'To estimate the *u* values, Splink takes a slightly different approach by taking
    random pairwise record comparisons, assuming they do not match, and computing
    how often these coincidences occur. Since the probability of two random records
    being a match (representing the same entity) is usually very low, this approach
    generates good estimates of the *u* values. An additional benefit of this approach
    is that if the *u* probabilities are correct, it “anchors” the EM estimation procedure
    and greatly improves the chance of it converging to a global, rather than a local,
    minimum. To apply this approach, we need to make sure our random population is
    sufficiently large to be representative of the full range of possible combinations:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了估计*u*值，Splink采取了略有不同的方法，通过随机选择成对记录的对比，假设它们不匹配，并计算这些巧合发生的频率。由于两个随机记录匹配（代表相同实体）的概率通常非常低，这种方法生成了*u*值的良好估计。这种方法的额外好处是，如果*u*概率正确，它会“锚定”EM估计过程，并大大提高其收敛到全局最小值而不是局部最小值的机会。要应用这种方法，我们需要确保我们的随机人群足够大，以代表可能组合的全部范围：
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Splink allows us to set blocking rules for estimating the match probabilities.
    Here the attribute parameters for each segment are estimated on the subset of
    the population according to the first condition and then the process is repeated
    for the subset selected by the second condition. Since the attributes included
    in the blocking condition cannot themselves be estimated, it is essential that
    the conditions overlap, allowing each attribute to be evaluated under at least
    one condition.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Splink允许我们设置阻止规则以估计匹配概率。在这里，根据第一个条件在人群的子集上估计每个段的属性参数，然后重复第二个条件选择的子集。由于包含在阻止条件中的属性本身不能被估计，因此条件的重叠至关重要，允许每个属性至少在一个条件下进行评估。
- en: Random Sample
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机样本
- en: Note that the expectation-maximization method selects records at random, so
    you can expect some variation from the calculated parameters in this book if you
    are following along.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，期望最大化方法是随机选择记录的，因此如果您按照本书进行操作，可以预期计算参数与本书中的计算参数有所不同。
- en: 'In this example, we block on equivalent last name and month, allowing us to
    estimate first name and year segment probabilities, and then we repeat with the
    opposite combination. This way each attribute segment is evaluated at least once:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们在等效的姓和月份上进行阻止，允许我们估计名字和年份段的概率，然后我们以相反的组合重复此过程。这样每个属性段至少被评估一次：
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can examine the resulting match weights using:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下方法检查生成的匹配权重：
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](assets/hoer_0504.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0504.png)'
- en: Figure 5-4\. Model parameters
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-4\. 模型参数
- en: 'In [Figure 5-4](#fig-5-4), we can see a strongly negative prior (starting)
    match weight with positive weights for each attribute exact match and for approximate
    matches on `Firstname` and `Lastname`:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图5-4](#fig-5-4) 中，我们可以看到强烈的负先验（起始）匹配权重，以及每个属性精确匹配和在 `Firstname` 和 `Lastname`
    上近似匹配的正权重：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In [Figure 5-5](#fig-5-5), we can see the proportion of matching and nonmatching
    record comparisons that the expectation maximization algorithm calculates for
    each segment.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [图5-5](#fig-5-5) 中，我们可以看到期望最大化算法为每个段计算的匹配和非匹配记录比例。
- en: '![](assets/hoer_0505.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0505.png)'
- en: Figure 5-5\. Proportion of record comparisons
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-5\. 记录比例
- en: Match Classification
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 匹配分类
- en: 'Now that we have a trained model with optimized match parameters for each attribute,
    we can predict whether the record pairs that aren’t blocked refer to the same
    entity. In this example, we set an overall threshold match probability at 0.99:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了针对每个属性优化的匹配参数的训练模型，我们可以预测未被阻止的记录对是否指向相同的实体。在本示例中，我们将总体阈值匹配概率设置为0.99：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We then join the prediction results to the PSC dataset by unique ID so that
    we can pick up the company number that the matched entity is associated with.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们根据唯一标识将预测结果与PSC数据集连接起来，以便可以获取与匹配实体关联的公司编号。
- en: 'Then we rename our output columns and retain only the ones we need:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们重新命名输出列，并仅保留我们需要的列：
- en: '[PRE15]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: This gives us 346 predicted matches, both exact and approximate, as shown in
    [Figure 5-6](#fig-5-6) (with the PSC first names and last names sanitized).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们提供了346个预测匹配，精确和近似匹配，如 [图5-6](#fig-5-6) 中所示（PSC的名字和姓已经过处理）。
- en: '![](assets/hoer_0506.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0506.png)'
- en: Figure 5-6\. Exact matches on `Lastname` and `Firstname`
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-6\. `Lastname` 和 `Firstname` 的精确匹配
- en: 'If we remove the exact matches, we can examine the additional approximate matches
    to see how well our probabilistic approach has performed. This is shown in [Figure 5-7](#fig-5-7) (with
    the PSC first names and last names sanitized):'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们移除精确匹配，我们可以检查额外的近似匹配，看看我们的概率方法执行得有多好。这在 [图 5-7](#fig-5-7) 中展示（PSC 的名字和姓氏已经过清理）：
- en: '[PRE16]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](assets/hoer_0507.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0507.png)'
- en: Figure 5-7\. Approximate matches—nonexact `Firstname` or `Lastname`
  id: totrans-85
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-7\. 近似匹配 — 非精确的“Firstname”或“Lastname”
- en: Examining the results, shown in [Table 5-1](#table-5-1), we can see several
    candidates that may be true positive matches.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 检查结果，如表 5-1 所示，我们可以看到几位可能是真正的正向匹配的候选人。
- en: Table 5-1\. Approximate matches—manual comparison
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-1\. 近似匹配 — 手动比较
- en: '| `match_weight` | `match_probability` | `Firstname_psc` | `Firstname_w` |
    `Lastname_psc` | `Lastname_w` | `company_​num⁠ber` |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `match_weight` | `match_probability` | `Firstname_psc` | `Firstname_w` |
    `Lastname_psc` | `Lastname_w` | `company_​num⁠ber` |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| 13.51481459 | 0.999914572 | John | John | Mcdonnell | McDonnell | 5350064
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 13.51481459 | 0.999914572 | John | John | Mcdonnell | McDonnell | 5350064
    |'
- en: '| 11.66885836 | 0.999692963 | Stephen | Stephen | Mcpartland | McPartland |
    7572556 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 11.66885836 | 0.999692963 | Stephen | Stephen | Mcpartland | McPartland |
    7572556 |'
- en: '| 11.50728191 | 0.999656589 | James | James | Heappey Mp | Heappey | 5074477
    |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 11.50728191 | 0.999656589 | James | James | Heappey Mp | Heappey | 5074477
    |'
- en: '| 9.637598832 | 0.998746141 | Matt | Matthew | Hancock | Hancock | 14571407
    |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 9.637598832 | 0.998746141 | Matt | Matthew | Hancock | Hancock | 14571407
    |'
- en: '| 13.51481459 | 0.999914572 | John | John | Mcdonnell | McDonnell | 4662034
    |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 13.51481459 | 0.999914572 | John | John | Mcdonnell | McDonnell | 4662034
    |'
- en: '| 9.320995827 | 0.998438931 | Siobhan | Siobhan | Mcdonagh | McDonagh | 246884
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 9.320995827 | 0.998438931 | Siobhan | Siobhan | Mcdonagh | McDonagh | 246884
    |'
- en: '| 11.46050878 | 0.999645277 | Alison | Alison | Mcgovern | McGovern | 10929919
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 11.46050878 | 0.999645277 | Alison | Alison | Mcgovern | McGovern | 10929919
    |'
- en: '| 9.57364719 | 0.998689384 | Jessica | Jess | Phillips | Phillips | 560074
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 9.57364719 | 0.998689384 | Jessica | Jess | Phillips | Phillips | 560074
    |'
- en: '| 12.14926274 | 0.999779904 | Grahame | Grahame | Morris Mp | Morris | 13523499
    |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 12.14926274 | 0.999779904 | Grahame | Grahame | Morris Mp | Morris | 13523499
    |'
- en: '| 11.66885836 | 0.999692963 | Stephen | Stephen | Mcpartland | McPartland |
    9165947 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 11.66885836 | 0.999692963 | Stephen | Stephen | Mcpartland | McPartland |
    9165947 |'
- en: '| 13.51481459 | 0.999914572 | John | John | Mcdonnell | McDonnell | 6496912
    |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 13.51481459 | 0.999914572 | John | John | Mcdonnell | McDonnell | 6496912
    |'
- en: '| 11.62463457 | 0.999683409 | Anna | Anna | Mcmorrin | McMorrin | 9965110 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 11.62463457 | 0.999683409 | Anna | Anna | Mcmorrin | McMorrin | 9965110 |'
- en: Despite our initial data standardization, we can see that we have inconsistent
    capitalization on last name, and we also have a couple of PSC records where the
    last name is appended with “Mp.” This is frequently the case with entity resolution
    problems—we often have to iterate several times, refining our data standardization
    as we learn more about our dataset.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们最初进行了数据标准化，但我们可以看到姓氏的大写不一致，而且我们还有几个 PSC 记录的姓氏末尾附加了“Mp.” 这在实体解析问题中经常出现——我们经常需要多次迭代，随着对数据集了解的增加，不断完善我们的数据标准化。
- en: Measuring Performance
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量性能
- en: 'If we assume that all the exact matches and the approximate matches in [Table 5-1](#table-5-1)
    are true positive matches, then we can calculate our precision metrics as:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们假设所有在表 5-1 中的精确匹配和近似匹配都是真正的正向匹配，那么我们可以计算我们的精度指标如下：
- en: <math alttext="upper T r u e p o s i t i v e m a t c h e s left-parenthesis
    upper F upper P right-parenthesis equals 266 plus 12 equals 278"><mrow><mi>T</mi>
    <mi>r</mi> <mi>u</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi>
    <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi>
    <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>266</mn>
    <mo>+</mo> <mn>12</mn> <mo>=</mo> <mn>278</mn></mrow></math>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper T r u e p o s i t i v e m a t c h e s left-parenthesis
    upper F upper P right-parenthesis equals 266 plus 12 equals 278"><mrow><mi>T</mi>
    <mi>r</mi> <mi>u</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi>
    <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi>
    <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>266</mn>
    <mo>+</mo> <mn>12</mn> <mo>=</mo> <mn>278</mn></mrow></math>
- en: <math alttext="upper F a l s e p o s i t i v e m a t c h e s left-parenthesis
    upper F upper P right-parenthesis equals 80 minus 12 equals 68"><mrow><mi>F</mi>
    <mi>a</mi> <mi>l</mi> <mi>s</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi>
    <mi>t</mi> <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi>
    <mi>h</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo>
    <mn>80</mn> <mo>-</mo> <mn>12</mn> <mo>=</mo> <mn>68</mn></mrow></math>
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper F a l s e p o s i t i v e m a t c h e s left-parenthesis
    upper F upper P right-parenthesis equals 80 minus 12 equals 68"><mrow><mi>F</mi>
    <mi>a</mi> <mi>l</mi> <mi>s</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi>
    <mi>t</mi> <mi>i</mi> <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi>
    <mi>h</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo>
    <mn>80</mn> <mo>-</mo> <mn>12</mn> <mo>=</mo> <mn>68</mn></mrow></math>
- en: <math alttext="upper P r e c i s i o n equals StartFraction upper T upper P
    Over left-parenthesis upper T upper P plus upper F upper P right-parenthesis EndFraction
    equals StartFraction 278 Over left-parenthesis 278 plus 68 right-parenthesis EndFraction
    almost-equals 80 percent-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi>
    <mi>i</mi> <mi>s</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>278</mn> <mrow><mo>(</mo><mn>278</mn><mo>+</mo><mn>68</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>80</mn> <mo>%</mo></mrow></math>
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P r e c i s i o n equals StartFraction upper T upper P
    Over left-parenthesis upper T upper P plus upper F upper P right-parenthesis EndFraction
    equals StartFraction 278 Over left-parenthesis 278 plus 68 right-parenthesis EndFraction
    almost-equals 80 percent-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi>
    <mi>i</mi> <mi>s</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>278</mn> <mrow><mo>(</mo><mn>278</mn><mo>+</mo><mn>68</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>80</mn> <mo>%</mo></mrow></math>
- en: Without manual verification, we don’t definitively know which of our `notmatch`
    population are true or false negatives, and therefore we cannot calculate recall
    or overall accuracy metrics.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 没有手动验证，我们无法确定我们的“notmatch”人群中哪些是真正的假阴性，因此我们无法计算召回率或整体准确度指标。
- en: Summary
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we used approximate matching within a probabilistic framework 
    to identify members of Parliament who may have significant control over UK companies.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用概率框架内的近似匹配来识别可能对英国公司具有重大控制权的国会议员。
- en: We saw how blocking can be used to reduce the number of record pairs we need
    to evaluate to a practical size without unacceptably increasing the risk that
    we miss some important potential matches.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到如何使用阻塞技术来减少我们需要评估的记录对数量，使其保持在一个实际的范围内，同时又不会太大幅度地增加我们错过重要潜在匹配的风险。
- en: We saw how important data standardization is to optimizing performance and how
    getting the best performance in entity resolution is often an iterative process.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到数据标准化对优化性能的重要性，以及在实体解析中获得最佳性能通常是一个迭代的过程。
