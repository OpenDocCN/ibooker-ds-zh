- en: 2 Dealing with threads
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 处理线程
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Modeling concurrency in operating systems
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统中的并发建模
- en: Differentiating between processes and threads
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分进程和线程
- en: Creating goroutines
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建goroutines
- en: Differentiating between concurrency and parallelism
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分并发和并行
- en: The operating system is the gatekeeper of our system resources. It decides when
    and which processes are given access to the various system resources, including
    processing time, memory, and network. As developers, we don’t necessarily need
    to be experts on the inner workings of the operating system. However, we need
    to have a good understanding of how it operates and the tools it provides to make
    our lives as programmers easier.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统是我们系统资源的守门人。它决定何时以及哪些进程可以访问各种系统资源，包括处理时间、内存和网络。作为开发者，我们不一定需要成为操作系统内部运作的专家。然而，我们需要对其运作方式和它提供的工具有一个良好的理解，以便使我们的编程生活更加轻松。
- en: We’ll start this chapter by looking at how the operating system manages and
    allocates resources to run multiple jobs concurrently. In the context of concurrent
    programming, the operating system gives us various tools to help manage this concurrency.
    Two of these tools, processes and threads, represent the concurrent actors in
    our code. They may execute in parallel or interleave and interact with each other.
    We will look, in some detail, at the differences between the two. Later, we will
    also discuss goroutines and where they sit in this context, and then we’ll create
    our first concurrent Go program using goroutines.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从这个章节开始，看看操作系统如何管理和分配资源以并发运行多个作业。在并发编程的背景下，操作系统为我们提供了各种工具来帮助我们管理这种并发。其中两个工具，进程和线程，代表我们代码中的并发参与者。它们可以并行执行或交错并相互交互。我们将详细探讨两者之间的区别。稍后，我们还将讨论goroutines及其在这个背景中的位置，然后我们将使用goroutines创建我们的第一个并发Go程序。
- en: 2.1 Multiprocessing in operating systems
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 操作系统中的多进程
- en: How does an operating system provide abstractions to build and support concurrent
    programs? *Multiprocessing* (sometimes referred to as multiprogramming) is the
    term used when an operating system can handle more than one task at a time. This
    is important because it enables us to make effective use of the CPU. Whenever
    the CPU is idling, such as when the current job is waiting for user input, we
    can have the operating system choose another job to run on the CPU.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统如何提供抽象来构建和支持并发程序？*多进程*（有时称为多道程序设计）是指操作系统可以同时处理多个任务时的术语。这很重要，因为它使我们能够有效地利用CPU。每当CPU空闲时，例如当前作业等待用户输入时，我们可以让操作系统选择另一个作业在CPU上运行。
- en: NOTE When it comes to multiprocessing, modern operating systems have various
    procedures and components to manage their multiple jobs. Understanding this system
    and how it interacts with our programming can help us program in a more effective
    manner.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在多进程方面，现代操作系统有各种程序和组件来管理它们的多个作业。了解这个系统和它如何与我们的编程交互可以帮助我们更有效地编程。
- en: 'Whenever we execute a job on our system, whether it’s our home laptop or a
    cloud server, that execution transitions through various states. To fully understand
    the life cycle that a job goes through, let’s pick an example and walk through
    these states. Let’s say we run a command on our system to search for a particular
    string in a large text file. Suppose our system is a UNIX platform, and we use
    this command:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们在系统上执行什么作业，无论是我们的家用笔记本电脑还是云服务器，该执行都会通过各种状态。为了完全理解作业所经历的生命周期，让我们选择一个示例并走过这些状态。假设我们在系统上运行一个命令来在大型文本文件中搜索特定的字符串。假设我们的系统是UNIX平台，我们使用以下命令：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Figure 2.1 shows an example of the path taken by this job.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1显示了此作业的路径示例。
- en: '![](../../OEBPS/Images/CH02_F01_Cutajar.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH02_F01_Cutajar.png)'
- en: Figure 2.1 The operating system’s job states in a single-CPU system
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 单CPU系统中操作系统的作业状态
- en: NOTE On some operating systems (such as Linux), the ready queue is known as
    the *run queue*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在某些操作系统（如Linux）中，就绪队列被称为*运行队列*。
- en: 'Let’s have a look at each of these states, one step at a time:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步地看看这些状态：
- en: A user submits the string-search job for execution.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户提交字符串搜索作业以执行。
- en: The operating system places this job in the job queue. The job goes into this
    queue in cases when it is not yet ready to run.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 操作系统将此作业放入作业队列。当作业尚未准备好运行时，它会进入此队列。
- en: Once our text search is in a ready-to-run state, it moves to the ready queue.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们的文本搜索处于就绪可运行状态，它就会移动到就绪队列。
- en: At some point, when the CPU is free, the operating system picks up the job from
    the ready queue and starts executing it on the CPU. At this stage, the processor
    is running the instructions contained in the job.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在某个时刻，当 CPU 空闲时，操作系统从就绪队列中提取任务并在 CPU 上开始执行它。在这个阶段，处理器正在运行任务中包含的指令。
- en: As soon as our text-search job requests an instruction to read from a file,
    the operating system removes the job from the CPU and places it in an I/O waiting
    queue. Here it waits until the requested I/O operation returns data. If another
    job is available in the ready queue, the OS will pick it up and execute it on
    the CPU, thus keeping the processor busy.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们的文本搜索任务请求读取文件的指令，操作系统就会将任务从 CPU 中移除并将其放入 I/O 等待队列。在这里，它等待直到请求的 I/O 操作返回数据。如果就绪队列中还有其他任务可用，操作系统将选择它并在
    CPU 上执行，从而保持处理器的忙碌。
- en: The device will perform and complete the I/O operation (reading some bytes from
    the text file).
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该设备将执行并完成 I/O 操作（从文本文件中读取一些字节）。
- en: Once the I/O operation is complete, the job moves back to the ready queue. It’s
    now waiting for the operating system to pick it up so that it can continue its
    execution. The reason for this wait period is that the CPU might be busy executing
    other jobs.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦 I/O 操作完成，任务就会回到就绪队列。现在它正在等待操作系统将其选中以便继续执行。这种等待期的原因是 CPU 可能正忙于执行其他任务。
- en: At some point, the CPU is free again, and the OS picks up the text-search job
    and continues executing its instructions on the CPU. The typical instructions
    in this case would be to try to find a match in the loaded text from the file.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在某个时刻，CPU 再次空闲，操作系统接管文本搜索任务并继续在 CPU 上执行其指令。在这种情况下，典型的指令是尝试从文件中加载的文本中找到匹配项。
- en: At this point, the system might raise an interrupt while the job is in execution.
    An *interrupt* is a mechanism used to stop the current execution and notify the
    system of a particular event. A piece of hardware called the *interrupt controller*
    handles all interrupts coming from multiple devices. This controller then notifies
    the CPU to stop the current job and start on another task. Typically, this task
    involves a call to a device driver or the operating system scheduler. This interrupt
    can be raised for many reasons, such as
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在任务执行过程中，系统可能会在此时引发中断。中断是一种用于停止当前执行并通知系统特定事件的机制。一个称为**中断控制器**的硬件设备处理来自多个设备的所有中断。然后，该控制器通知
    CPU 停止当前任务并开始另一个任务。通常，这个任务涉及调用设备驱动程序或操作系统调度程序。这种中断可能由许多原因引发，例如
- en: An I/O device completes an operation such as reading a file or network or even
    a keystroke on a keyboard.
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 I/O 设备完成了一个操作，例如读取文件或网络，甚至是在键盘上的按键。
- en: Another program requests a software interrupt.
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个程序请求一个软件中断。
- en: A hardware clock (or timer) tick occurs, interrupting the current execution.
    This ensures that other jobs in the ready queue also get their own chance to execute.
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个硬件时钟（或计时器）滴答声发生，中断了当前执行。这确保了就绪队列中的其他任务也有机会执行。
- en: The operating system pauses the execution of the current job and puts the job
    back on the ready queue. The OS will also pick up another item from the ready
    queue and execute it on the CPU. The job of the OS scheduling algorithm is to
    determine which job from the ready queue to pick up for execution.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 操作系统暂停当前任务的执行，并将任务放回就绪队列。操作系统还将从就绪队列中提取另一个项目并在 CPU 上执行它。操作系统调度算法的任务是确定从就绪队列中挑选哪个任务来执行。
- en: At some point, our job is picked up again by the OS scheduler, and its execution
    resumes on the CPU. Steps 4 through 10 will typically repeat multiple times during
    the execution, depending on the size of the text file and how many other jobs
    are running on the system.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在某个时刻，我们的任务再次被操作系统调度程序选中，并在 CPU 上继续执行。步骤 4 到 10 在执行过程中通常会重复多次，具体取决于文本文件的大小以及系统上运行的其他任务数量。
- en: Our text search finishes its programming (completing the search) and terminates.
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的文本搜索完成编程（完成搜索）并终止。
- en: Definition Steps 9 and 10 are an example of a *context switch**,* which occurs
    whenever the system interrupts a job and the operating system steps in to schedule
    another one.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 定义步骤 9 和 10 是**上下文切换**的例子，这发生在系统中断一个任务并且操作系统介入以调度另一个任务时。
- en: A bit of overhead occurs on every context switch—the OS needs to save the current
    job state so that it can later resume where it left off. The OS also needs to
    load the state of the next job to be executed. This state is referred to as the
    *process context block* (PCB). It is a data structure used to store all the details
    about a job, such as the program counter, CPU registers, and memory information.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 每次上下文切换都会产生一些开销——操作系统需要保存当前作业状态，以便稍后可以从中恢复。操作系统还需要加载下一个要执行的作业的状态。这个状态被称为*进程上下文块*（PCB）。它是一种数据结构，用于存储有关作业的所有详细信息，例如程序计数器、CPU寄存器和内存信息。
- en: This context switching creates the impression that many tasks are happening
    at the same time, even when we have only one CPU. When we write concurrent code
    and execute it on a system with only one processor, our code creates a set of
    *jobs* that run in this fashion to give a quicker response. When we have a system
    with multiple CPUs, we can also have true parallelism, in that our jobs are running
    at the same time on different execution units.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这种上下文切换给人一种同时进行许多任务的印象，即使我们只有一个CPU。当我们编写并发代码并在只有一个处理器的系统上执行时，我们的代码会创建一系列*作业*以这种方式运行，以提供更快的响应。当我们有一个多CPU的系统时，我们也可以实现真正的并行性，因为我们的作业在不同的执行单元上同时运行。
- en: In the 1990s, many systems came with dual-processor motherboards, although these
    were generally expensive. The first dual-core processor was available commercially
    (from Intel) in 2005\. In the drive to increase processing power and lengthen
    battery life, most devices now come with multiple cores. This includes cloud server
    setups, home laptops, and mobile phones. Typically, the architecture of these
    processors is such that they share the main memory and a bus interface; however,
    each core has its own CPU and at least one memory cache. The role of the operating
    system remains the same as in a single-core machine, with the difference being
    that now the scheduler has to schedule jobs on more than one CPU. Interrupts are
    quite a bit more complex to implement, and these systems have an advanced interrupt
    controller, which can interrupt one processor or a group of processors together,
    depending on the scenario.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在20世纪90年代，许多系统配备了双处理器主板，尽管这些主板通常价格昂贵。第一个双核处理器于2005年（来自英特尔）商业化。在提高处理能力和延长电池寿命的驱动下，大多数设备现在都配备了多个核心。这包括云服务器配置、家用笔记本电脑和移动电话。这些处理器的架构通常是共享主内存和总线接口；然而，每个核心都有自己的CPU和至少一个内存缓存。操作系统的角色与单核机器相同，区别在于现在调度器必须在多个CPU上调度作业。中断的实现相当复杂，这些系统具有高级中断控制器，可以根据场景中断一个处理器或一组处理器。
- en: Multiprocessing and time sharing
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 多处理和分时
- en: Although many systems adopted multiprocessing in the 1950s, these were usually
    special purpose-built systems. One example is the Semi-Automatic Ground Environment
    (SAGE) system, which the US military developed in the 1950s to monitor airspace.
    SAGE consisted of many remote computers connected using telephone lines. The SAGE
    system was ahead of its time, and its development gave birth to many ideas in
    use today, such as real-time processing, distributed computing, and multiprocessing.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多系统在20世纪50年代采用了多处理，但这些通常是专门定制的系统。一个例子是美国军事在20世纪50年代开发的半自动地面环境（SAGE）系统，用于监控空域。SAGE由许多通过电话线连接的远程计算机组成。SAGE系统在当时是超前的，其发展催生了今天仍在使用的许多想法，如实时处理、分布式计算和多处理。
- en: Later, in the 1960s, IBM introduced System/360\. In various literature, this
    is referred to as the first real operating system, although similar systems available
    earlier were named and referred to differently (such as batch-processing systems).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，在20世纪60年代，IBM推出了System/360。在各种文献中，这被称为第一个真正的操作系统，尽管之前可用的类似系统有不同的名称和称呼（如批处理系统）。
- en: System/360, however, was one of the first commercially available systems that
    had the ability to perform multiprocessing. Prior to this, on some systems, when
    a job required loading data from or saving data to tape, all processing would
    stop until the system accessed the slow tape. This created inefficiencies in programs
    that performed a high proportion of I/O. During this time, the CPU was sitting
    idle and unable to do any useful work. The solution to this was to load more than
    one job at a time and allocate a chunk of fixed memory to each job. When one job
    was waiting for its I/O, the CPU was switched to execute another job.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，System/360 是第一个能够执行多处理器的商用系统之一。在此之前，在某些系统中，当作业需要从磁带加载数据或保存数据到磁带时，所有处理都会停止，直到系统访问慢速磁带。这导致了执行大量I/O的程序的低效率。在这段时间里，CPU处于空闲状态，无法进行任何有用的工作。解决这个问题的方法是同时加载多个作业，并为每个作业分配一块固定内存。当一个作业等待其I/O时，CPU会切换到执行另一个作业。
- en: Another solution that emerged about this time is the idea of time sharing. Prior
    to this, when computers were still large, shared mainframes, programming involved
    submitting the instructions and having to wait for hours for the job to compile
    and execute. If a submitted program had an error in the code, programmers would
    not know until late in the process. The solution to this was to have a *time-sharing*
    system, which is when many programmers are connected via terminals. Since programming
    is mostly a thinking process, only a small proportion of the connected users would
    be compiling and executing jobs. The CPU resources would be allocated alternately
    to this small proportion of users when they needed it, reducing the long feedback
    time.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 大约在这个时候，还出现了一种解决方案，即时间共享的概念。在此之前，当计算机仍然很大，是共享的主机时，编程涉及提交指令并需要等待数小时才能编译和执行作业。如果提交的程序中存在代码错误，程序员直到过程后期才知道。解决这个问题的方法是有一个
    *时间共享* 系统，即许多程序员通过终端连接。由于编程主要是一个思考过程，只有一小部分连接的用户会编译和执行作业。当这些用户需要时，CPU资源会交替分配给这一小部分用户，从而减少了漫长的反馈时间。
- en: So far, we have vaguely referred to these execution units managed by the operating
    system as system jobs. In the next section, we will go into a bit more detail
    to see how the OS provides us with two main abstractions to model these execution
    units.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们模糊地称由操作系统管理的这些执行单元为系统作业。在下一节中，我们将更详细地探讨操作系统如何为我们提供两种主要抽象来模拟这些执行单元。
- en: 2.2 Abstracting concurrency with processes and threads
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 使用进程和线程抽象并发
- en: 'When we need to execute our code and manage concurrency (with jobs running,
    or appearing to run, at the same time), or enable true parallelism in the case
    of a multicore system, the operating system provides two abstractions: processes
    and threads.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们需要执行我们的代码并管理并发（有作业同时运行或看似同时运行）或在多核系统的情况下启用真正的并行性时，操作系统提供了两种抽象：进程和线程。
- en: A *process* represents a program that is currently running on the system. It
    is an essential concept in an operating system. The main purpose of an operating
    system is to efficiently allocate the system’s resources (such as memory and CPUs)
    amongst the many processes that are executing. We can use multiple processes and
    have them run concurrently as outlined in the previous section.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 *进程* 代表当前在系统上运行的程序。它是操作系统中的一个基本概念。操作系统的主要目的是高效地在许多正在执行的过程中分配系统的资源（如内存和CPU）。我们可以使用多个进程，并让它们如前节所述并发运行。
- en: A *thread* is an extra construct that executes within the process context to
    give us a more lightweight and more efficient approach to concurrency. As we shall
    see, each process is started with a single thread of execution, sometimes referred
    to as the primary or main thread. In this section, we’ll look at the differences
    between modeling concurrency with multiple processes and having many threads running
    in a single process.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 *线程* 是在进程上下文中执行的一个额外结构，它为我们提供了一种更轻量级、更高效的并发方法。正如我们将看到的，每个进程都是以一个执行线程开始的，有时被称为主线程或主要线程。在本节中，我们将探讨使用多个进程来模拟并发与在单个进程中运行许多线程之间的区别。
- en: 2.2.1 Concurrency with processes
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.1 使用进程的并发
- en: How can we complete a large piece of work when multiple people are working on
    the task? To pick a concrete example, let’s say we are a group of famous artists,
    and someone commissions us to paint a large piece of art. The deadline is tight,
    so it’s essential we work together as a team to work efficiently and finish on
    time.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当多个人在任务上工作时，我们如何完成一项大型工作？为了举一个具体的例子，让我们假设我们是一群著名的艺术家，有人委托我们画一幅大型艺术品。截止日期很紧，所以我们必须作为一个团队高效地工作并按时完成。
- en: One way of having our artists work on the same picture is to give everyone a
    separate piece of paper and instruct them to draw a different feature of the finished
    painting. Each member of the team would draw their feature on their respective
    piece of paper. When everyone was finished, we would merge our work. We could
    stick our respective pieces of paper onto a blank canvas, paint over the paper
    edges, and consider the job done.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们的艺术家在相同的画上工作的方法之一是给每个人一张单独的纸张，并指示他们绘制完成画作的不同特征。团队成员中的每个人都会在自己的纸张上绘制他们的特征。当每个人都完成时，我们会合并我们的工作。我们可以将各自的纸张粘贴到空白画布上，覆盖纸张边缘的画，然后认为工作完成了。
- en: In this analogy, the various team members represent our CPUs. The instructions
    we are following are our programmed code. The execution of a task by the team
    members (such as painting on the paper) represents a process. We each have our
    own resources (paper, desk space, etc.), we work independently, and at the end,
    we come together to merge our work. In this example, we finish the work in two
    steps. The first step is creating the different parts of the painting in parallel.
    The second step is sticking the different parts together (see figure 2.2).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类比中，不同的团队成员代表我们的CPU。我们遵循的指令是我们的程序代码。团队成员执行任务（如纸张上绘画）代表一个进程。我们每个人都有自己的资源（纸张、办公空间等），我们独立工作，最后我们聚集在一起合并我们的工作。在这个例子中，我们分两步完成工作。第一步是并行创建绘画的不同部分。第二步是将不同的部分粘合在一起（见图2.2）。
- en: '![](../../OEBPS/Images/CH02_F02_Cutajar.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH02_F02_Cutajar.png)'
- en: Figure 2.2 Having your own space while performing a task is analogous to using
    processes.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 在执行任务时拥有自己的空间与使用进程类似。
- en: This is similar to what happens in the operating system with processes. The
    painter’s resources (paper, pencil, etc.) represent the system resources, such
    as memory. Each operating system process has its own memory space, isolated from
    other processes. Typically, a process would work independently, having minimal
    interaction with other processes. Processes provide isolation at the cost of consuming
    more resources. If, for example, one process crashes due to an error, it will
    not affect other processes, since it has its own memory space. The downside of
    this isolation is that we end up consuming more memory. In addition, starting
    up processes takes a bit longer (compared to threads) since we need to allocate
    the memory space and other system resources.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这与操作系统中的进程发生的情况类似。画家的资源（纸张、铅笔等）代表系统资源，例如内存。每个操作系统进程都有自己的内存空间，与其他进程隔离。通常，进程会独立工作，与其他进程的交互最小。进程通过消耗更多资源来提供隔离。例如，如果一个进程由于错误而崩溃，它不会影响其他进程，因为它有自己的内存空间。这种隔离的缺点是我们最终会消耗更多的内存。此外，启动进程需要更长的时间（与线程相比），因为我们需要分配内存空间和其他系统资源。
- en: Since processes do not share memory with each other, they tend to minimize communication
    with other processes. Just like our painter analogy, using processes to synchronize
    and merge work is, in the end, a bit more of a challenge. When processes do need
    to communicate and synchronize with each other, we program them to use operating
    system tools and other applications, such as files, databases, pipes, sockets,
    etc.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于进程之间不共享内存，它们倾向于与其他进程的通信最小化。就像我们的画家类比一样，使用进程来同步和合并工作最终会带来一些挑战。当进程需要相互通信和同步时，我们编程它们使用操作系统工具和其他应用程序，例如文件、数据库、管道、套接字等。
- en: 2.2.2 Creating processes
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.2 创建进程
- en: A process is an abstraction of how the system will execute our code. Telling
    the operating system when to create a process and which code it should execute
    is crucial if we want to execute our code in an isolated manner. Luckily, the
    operating system gives us system calls for creating, starting, and managing our
    processes.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 进程是对系统如何执行我们的代码的一种抽象。如果我们想以隔离的方式执行我们的代码，告诉操作系统何时创建进程以及它应该执行哪个代码至关重要。幸运的是，操作系统为我们提供了创建、启动和管理进程的系统调用。
- en: For example, Windows has a `CreateProcess()` system call. This call creates
    the process, allocates the required resources, loads the program code, and starts
    executing the program as a process.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Windows 有一个 `CreateProcess()` 系统调用。这个调用创建进程，分配所需的资源，加载程序代码，并以进程的形式开始执行程序。
- en: Alternatively, on UNIX systems, there is a `fork()` system call. Using this
    call, we can create a copy of an execution. When we make this system call from
    an executing process, the operating system makes a complete copy of the memory
    space and the process’s resource handlers, including the registers, stack, file
    handlers, and even the program counter. The new process then takes over this new
    memory space and continues execution from that point onward.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，在 UNIX 系统上，有一个 `fork()` 系统调用。使用这个调用，我们可以创建一个执行的副本。当我们从一个正在执行的进程调用这个系统调用时，操作系统会完全复制内存空间和进程的资源处理器，包括寄存器、堆栈、文件处理器，甚至程序计数器。然后，新进程接管这个新的内存空间，并从那个点继续执行。
- en: Definition We refer to the new process as the *child* and the process that created
    it as the *parent*. This child and parent terminology also applies to threads,
    which we shall explore in section 2.2.4.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 定义我们将新进程称为 *子进程*，创建它的进程称为 *父进程*。这个子父术语也适用于线程，我们将在第 2.2.4 节中探讨。
- en: The `fork()` system call returns the process ID on the parent process and a
    value of `0` on the child. After forking into two processes, each process can
    determine what instructions to run based on the return value of the `fork()` system
    call. A child process can decide to use the copied resources (such as data contained
    in memory) or to clear it and start anew. Because each process has its own memory
    space, if one process changes its memory contents (for example, changing a variable’s
    value), the other process will not see this change. Figure 2.3 shows the result
    of the `fork()` system call on UNIX.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`fork()` 系统调用在父进程中返回进程 ID，在子进程中返回 `0`。在创建两个进程之后，每个进程都可以根据 `fork()` 系统调用的返回值来决定要执行哪些指令。子进程可以选择使用复制的资源（例如内存中的数据）或者清除它并重新开始。由于每个进程都有自己的内存空间，如果一个进程更改了其内存内容（例如，更改变量的值），另一个进程将不会看到这个更改。图
    2.3 展示了在 UNIX 上 `fork()` 系统调用的结果。'
- en: '![](../../OEBPS/Images/CH02_F03_Cutajar.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH02_F03_Cutajar.png)'
- en: Figure 2.3 Using the `fork()` system call to create a new process
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 使用 `fork()` 系统调用创建新进程
- en: As you can imagine, since each process has its own memory space, the total memory
    consumed increases every time you spawn a new process. In addition to consuming
    more memory, copying and allocating system resources takes time and consumes precious
    CPU cycles. This means that creating too many processes takes a heavy toll on
    the system. For this reason, it’s quite unusual for one program to use a large
    number of processes concurrently, all working on the same problem.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所想象的那样，由于每个进程都有自己的内存空间，每次您创建一个新进程时，总内存消耗都会增加。除了消耗更多内存外，复制和分配系统资源还需要时间，并消耗宝贵的
    CPU 周期。这意味着创建过多的进程会对系统造成沉重的负担。因此，一个程序同时使用大量进程来处理相同的问题是非常不寻常的。
- en: Copy on write for UNIX processes
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: UNIX 进程的写时复制
- en: Copy on write (COW) is an optimization introduced to the `fork()` system call.
    It reduces the time taken by not copying the entire memory space. For systems
    using this optimization, whenever `fork()` is called, both child and parent processes
    share the same memory pages. Then, if one of the processes tries to modify the
    contents of a memory page, that page is copied to a new location so that each
    process has its own copy. The OS only makes copies of the memory pages that are
    modified. This is a great way to save both memory and time, but if a process modifies
    large parts of its memory, the OS will end up copying most pages anyway.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 写时复制（COW）是引入到 `fork()` 系统调用中的优化。它通过不复制整个内存空间来减少所需的时间。对于使用这种优化的系统，每当调用 `fork()`
    时，子进程和父进程共享相同的内存页面。然后，如果其中一个进程尝试修改一个内存页的内容，该页就会被复制到一个新位置，以便每个进程都有自己的副本。操作系统只复制被修改的内存页面。这是一种节省内存和时间的好方法，但如果一个进程修改了其内存的大部分内容，操作系统最终仍然会复制大多数页面。
- en: Support for creating and forking processes in Go is limited to the `syscall`
    package and is OS-specific. If we look at the package, we’ll find the `CreateProcess()`
    function on Windows and `ForkExec()` and `StartProcess()` on UNIX systems. Go
    also gives us the ability to run commands in a new process by calling the `exec()`
    function, abstracting some of the OS-specific functions in the `syscall` package.
    However, concurrent programming in Go does not typically rely on heavyweight processes.
    As we shall see, Go adopts a more lightweight threading and goroutine concurrency
    model instead.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在Go中，创建和派生进程的支持仅限于`syscall`包，并且是操作系统特定的。如果我们查看该包，我们将在Windows上找到`CreateProcess()`函数，在UNIX系统上找到`ForkExec()`和`StartProcess()`。Go还通过调用`exec()`函数为我们提供了在新的进程中运行命令的能力，抽象了`syscall`包中的一些操作系统特定函数。然而，Go中的并发编程通常不依赖于重量级进程。正如我们将看到的，Go采用了一种更轻量级的线程和goroutine并发模型。
- en: A process will terminate when it has finished executing its code or has encountered
    an error it cannot handle. Once a process terminates, the OS reclaims all its
    resources so they are free to be used by other processes. This includes memory
    space, open file handles, network connections, etc. On UNIX and Windows, when
    a parent process finishes, it does not automatically terminate the child processes.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个进程执行完其代码或遇到无法处理的错误时，它将终止。一旦进程终止，操作系统将回收其所有资源，以便它们可以被其他进程使用。这包括内存空间、打开的文件句柄、网络连接等。在UNIX和Windows上，当父进程完成后，它不会自动终止子进程。
- en: 2.2.3 Using multiprocessing for common tasks
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.3 使用多进程处理常见任务
- en: Have you ever considered what happens behind the scenes when you run a UNIX
    command like this?
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否考虑过当你运行像这样的UNIX命令时幕后发生了什么？
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When we run this command on a UNIX system, the command line is forking two
    concurrent processes. We can check this by opening another terminal and running
    `ps -a`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在UNIX系统上运行此命令时，命令行正在派生两个并发进程。我们可以通过打开另一个终端并运行`ps -a`来检查这一点：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first process (PID 26013, in this example) will run the curl program, which
    will download the text file from the given URL. The second process (PID 26014)
    will run the word count program. In this example, we are feeding the output of
    the first process (curl) into the input of the second one (wc) through a buffer
    (see figure 2.4). Using the pipe operator, we are telling the operating system
    to allocate a buffer and to redirect the output of the curl process and the input
    of the word count to that buffer. The curl process blocks when this buffer is
    full and resumes when the word count process consumes it. The word count process
    blocks when the buffer is empty until curl piles up more data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个进程（PID 26013，在此示例中）将运行curl程序，该程序将从给定的URL下载文本文件。第二个进程（PID 26014）将运行单词计数程序。在此示例中，我们将第一个进程（curl）的输出作为第二个进程（wc）的输入通过一个缓冲区（见图2.4）。使用管道操作符，我们告诉操作系统分配一个缓冲区，并将curl进程的输出和单词计数的输入重定向到该缓冲区。当此缓冲区满时，curl进程会阻塞，而当单词计数进程消耗它时，它会继续。当缓冲区为空时，单词计数进程会阻塞，直到curl积累更多数据。
- en: '![](../../OEBPS/Images/CH02_F04_Cutajar.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH02_F04_Cutajar.png)'
- en: Figure 2.4 Curl and wc running concurrently using a pipe
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 Curl和wc通过管道并发运行
- en: Once curl reads all the text from the web page, it terminates and puts a marker
    on the pipe indicating that no more data is available. This marker acts as a signal
    to the word count process indicating that it can terminate since no more data
    will be coming.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦curl从网页中读取所有文本，它将终止并在管道上放置一个标记，表示没有更多数据可用。这个标记作为对单词计数进程的信号，表明它可以终止，因为没有更多数据将到来。
- en: 2.2.4 Concurrency with threads
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.4 使用线程进行并发
- en: Processes are the heavyweight answer to concurrency. They provide us with good
    isolation, but they consume lots of resources and take a while to create.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 进程是并发问题的重量级解决方案。它们为我们提供了良好的隔离性，但消耗了大量的资源，并且创建需要一段时间。
- en: Threads are the answer to some of the problems that come with using processes
    for concurrency. We can think of threads as the lightweight alternative to multiple
    processes. Creating a thread is much faster (sometimes 100 times faster), and
    a thread consumes fewer system resources than a process. Conceptually, threads
    are another execution context (kind of a microprocess) within a process.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 线程是解决使用进程进行并发时出现的一些问题的答案。我们可以将线程视为多个进程的轻量级替代品。创建一个线程要快得多（有时快100倍），并且线程消耗的系统资源比进程少。从概念上讲，线程是进程内的另一个执行上下文（类似于微进程）。
- en: Let’s continue our simple analogy, where we’re painting a picture with a team
    of people. Instead of each member of our team having their own piece of paper
    and drawing independently, we could have one large, empty canvas and hand everyone
    paintbrushes and pencils. Everyone would share space and draw directly on the
    large canvas (see figure 2.5).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续我们的简单类比，其中我们用一队人画画。而不是让我们的团队成员各自拥有一张纸并独立绘制，我们可以有一个大型的空白画布，并给每个人分发画笔和铅笔。每个人都会共享空间，并直接在大画布上绘制（见图2.5）。
- en: '![](../../OEBPS/Images/CH02_F05_Cutajar.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH02_F05_Cutajar.png)'
- en: Figure 2.5 Painting concurrently and sharing space is analogous to using threads.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5同时绘制和共享空间类似于使用线程。
- en: This is similar to what happens when you use threads. Like when we are sharing
    the canvas, multiple threads will execute concurrently sharing the same memory
    space. This is more efficient because we’re not consuming large amounts of memory
    for each execution. In addition, sharing memory space usually means that we don’t
    have to merge our work at the end. Depending on the problem we’re solving, we
    might reach the solution more efficiently by sharing memory with other threads.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这与使用线程时发生的情况相似。就像我们共享画布一样，多个线程将并发执行并共享相同的内存空间。这更有效率，因为我们不需要为每个执行消耗大量的内存。此外，共享内存空间通常意味着我们不需要在结束时合并我们的工作。根据我们正在解决的问题，我们可能通过与其他线程共享内存来更有效地解决问题。
- en: When we discussed processes, we saw how a process contained both resources (program
    and data in memory) together with the execution that is running the program. Conceptually,
    we can separate the resources from the execution because this lets us create more
    than one execution and share the resources between them. We call each single execution
    a *thread* (or *thread of execution*). When you start a process, it contains one
    main thread by default. When we have more than one thread in a single process,
    we say that the process is *multithreaded.* Multithreaded programming is when
    we code in a manner that has different threads working together in the same application.
    Figure 2.6 shows how two threads can share the same memory, contained in one process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论进程时，我们看到了一个进程如何包含资源（程序和内存中的数据）以及正在运行程序的执行。从概念上讲，我们可以将资源与执行分离，因为这使我们能够创建多个执行并共享它们之间的资源。我们将每个单独的执行称为*线程*（或*执行线程*）。当你启动一个进程时，它默认包含一个主线程。当我们在一个进程中拥有多个线程时，我们说该进程是*多线程的*。多线程编程是指我们在同一应用程序中以不同线程协同工作的方式编写代码。图2.6展示了两个线程如何共享同一个进程的内存。
- en: '![](../../OEBPS/Images/CH02_F06_Cutajar.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH02_F06_Cutajar.png)'
- en: Figure 2.6 Threads sharing the same process memory space
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6线程共享同一进程内存空间
- en: When we create a new thread, the operating system needs to create only enough
    resources to manage the stack space, registers, and a program counter. The new
    thread runs inside the context of the same process. In contrast, when we create
    a new process, the OS needs to allocate a completely new memory space for it.
    For this reason, threads are a lot more lightweight than processes, and we can
    typically create many more threads than processes before the system starts running
    out of resources. In addition, because there are so few new resources to allocate,
    starting a thread is a lot faster than starting a process.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建一个新的线程时，操作系统只需要创建足够的管理栈空间、寄存器和程序计数器的资源。新线程在同一个进程的上下文中运行。相比之下，当我们创建一个新的进程时，操作系统需要为它分配一个全新的内存空间。因此，线程比进程轻量得多，在系统开始耗尽资源之前，我们通常可以创建比进程多得多的线程。此外，因为需要分配的新资源很少，启动线程比启动进程要快得多。
- en: What goes on the stack space?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 栈空间里有什么？
- en: The *stack space* stores the local variables that live within a function. These
    are typically short-lived variables—when the function finishes, they are not used
    anymore. This space does not include variables that are shared between functions
    (using pointers), which are allocated on the main memory space, called the *heap*.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*栈空间*存储函数内部存在的局部变量。这些通常是短生命周期的变量——当函数结束时，它们就不再被使用了。这个空间不包括在函数之间共享的变量（使用指针），这些变量分配在主内存空间，称为*堆*。'
- en: This extra performance comes at a price. Working in the same memory space means
    we don’t get the isolation that processes offer. This can lead to one thread stepping
    over another thread’s work. Communication between and synchronization of the multiple
    threads are important in avoiding this. It’s much the same in our team-of-painters
    analogy. When we are working together on the same project and sharing the same
    resources, we need to have good communication and synchronization between the
    painters. We need to constantly talk to each other about what we are doing and
    when. Without this cooperation, we would risk painting over each other’s art,
    giving us a poor result.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这种额外的性能是有代价的。在相同的内存空间中工作意味着我们无法获得进程提供的隔离性。这可能导致一个线程覆盖另一个线程的工作。在避免这种情况时，多个线程之间的通信和同步非常重要。在我们的画家团队类比中，情况也大致相同。当我们共同在一个项目上工作并共享相同的资源时，我们需要画家之间有良好的沟通和同步。我们需要不断交流我们在做什么以及何时做。如果没有这种合作，我们可能会覆盖彼此的艺术作品，导致结果不佳。
- en: This is similar to how we manage concurrency with multiple threads. Since multiple
    threads are sharing the same memory space, we need to take care so that the threads
    are not stepping over each other and causing problems. We do this by using thread
    communication and synchronization. We’ll examine the types of errors that can
    arise from sharing memory and provide solutions throughout this book.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们在多个线程中管理并发的方式相似。由于多个线程共享相同的内存空间，我们需要注意确保线程不会相互覆盖并引起问题。我们通过使用线程通信和同步来实现这一点。在本书中，我们将检查从共享内存中可能出现的错误类型，并提供解决方案。
- en: Since threads share memory space, any change made in main memory by one thread
    (such as changing a global variable’s value) is visible to every other thread
    in the same process. This is the main advantage of using threads—multiple threads
    can use this shared memory to work on the same problem together. This enables
    us to write concurrent code that is very efficient and responsive.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 由于线程共享内存空间，一个线程对主内存所做的任何更改（例如更改全局变量的值）对同一进程中的其他所有线程都是可见的。这是使用线程的主要优势——多个线程可以一起使用这个共享内存来处理相同的问题。这使得我们能够编写非常高效和响应快速的并发代码。
- en: Note Threads do not share stack space. Although threads share the same memory
    space, it’s important to realize that each thread has its own private stack space
    (as was shown in figure 2.6).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：线程不共享栈空间。尽管线程共享相同的内存空间，但重要的是要认识到每个线程都有自己的私有栈空间（如图2.6所示）。
- en: Whenever we create a local non-shared variable in a function, we are placing
    this variable on the stack space. These local variables are thus visible only
    to the thread that creates them. It’s important that each thread has its own private
    stack space because it might call completely different functions than other threads
    and will need its own private space to store the variables and return values used
    in these functions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们在一个函数中创建一个局部非共享变量时，我们实际上是在栈空间中放置这个变量。因此，这些局部变量只能被创建它们的线程看到。每个线程都有自己的私有栈空间是很重要的，因为它可能调用与其他线程完全不同的函数，并且需要自己的私有空间来存储这些函数中使用的变量和返回值。
- en: We also need each thread to have its own program counter. A *program counter*
    (also known as an *instruction pointer*) is simply a pointer to the instruction
    that the CPU will execute next. Since threads will likely execute different parts
    of our program, each thread needs to have a separate instruction pointer as well.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要每个线程都有自己的程序计数器。*程序计数器*（也称为*指令指针*）简单地说是指向CPU将要执行的下一个指令的指针。由于线程可能会执行我们程序的不同部分，因此每个线程都需要一个独立的指令指针。
- en: When we have multiple threads and only one core processor, each thread in a
    process gets a time slice of the processor. This improves responsiveness, and
    it’s useful in applications where you need to respond to multiple requests concurrently
    (such as in a web server). If multiple processors (or processor cores) are present
    in a system, threads will get to execute in parallel with each other. This gives
    our application a speedup.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们拥有多个线程而只有一个核心处理器时，进程中的每个线程都会获得处理器的时间片。这提高了响应性，在需要同时响应多个请求的应用程序中很有用（例如在Web服务器中）。如果系统中存在多个处理器（或处理器核心），线程将能够相互并行执行。这使我们的应用程序速度加快。
- en: Earlier in this chapter, we discussed how the operating system manages multiprocessing,
    and we talked about jobs being in different states (such as ready to run, running,
    waiting for I/O, etc.). In a system that handles multithreaded programs, these
    states describe each thread of execution on the system. Only threads that are
    ready to run can be picked up and moved to the CPU for execution. If a thread
    requests I/O, the system will move it to the waiting for I/O state, and so on.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的早期部分，我们讨论了操作系统如何管理多进程，并讨论了作业处于不同的状态（例如准备运行、运行中、等待I/O等）。在一个处理多线程程序的系统里，这些状态描述了系统上每个执行线程的状态。只有准备运行的线程才能被选中并移动到CPU进行执行。如果一个线程请求I/O，系统会将其移动到等待I/O状态，依此类推。
- en: When we create a new thread, we give it an instruction pointer in our program
    from where the new execution should start. Many programming languages hide this
    pointer complexity and allow programs to specify target functions (or a method
    or procedure) where the threads should start executing. The operating system allocates
    space only for the new thread state, a stack, registers, and the program counter
    (pointing to the function). The child thread will then run concurrently with the
    parent, sharing the main memory and other resources, such as open files and network
    connections.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建一个新的线程时，我们在程序中给它一个指令指针，指示新执行应该从哪里开始。许多编程语言隐藏了这个指针的复杂性，并允许程序指定线程应该开始执行的目标函数（或方法或过程）。操作系统只为新的线程状态分配空间，包括栈、寄存器和程序计数器（指向函数）。然后，子线程将与父线程并发运行，共享主内存和其他资源，例如打开的文件和网络连接。
- en: Once a thread finishes its execution, it terminates, and the operating system
    reclaims the stack memory space. Depending on the thread implementation, however,
    a thread terminating does not necessarily terminate the entire process. In Go,
    when the main thread of execution terminates, the entire process also terminates,
    even if other threads are still running. This is different than in some other
    languages. In Java, for instance, a process will terminate only when all the threads
    in the process have finished.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦一个线程完成其执行，它就会终止，操作系统会回收栈内存空间。然而，根据线程的实现方式，线程的终止并不一定意味着整个进程都会终止。在Go语言中，当主执行线程终止时，整个进程也会终止，即使其他线程仍在运行。这与某些其他语言不同。例如，在Java中，进程只有在进程中的所有线程都完成时才会终止。
- en: Operating systems and programming languages implement threads in different manners.
    For example, on Windows, we can create a thread using the `CreateThread()` system
    call. On Linux, we can use the `clone()` system call with the `CLONE_THREAD` option.
    There are also differences in how languages represent threads. For example, Java
    models threads as objects, Python blocks multiple threads from executing in parallel
    (using a global interpreter lock), and in Go, as we shall see, there is a finer-grained
    concept of the goroutine.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统和编程语言以不同的方式实现线程。例如，在Windows上，我们可以使用`CreateThread()`系统调用来创建线程。在Linux上，我们可以使用带有`CLONE_THREAD`选项的`clone()`系统调用来创建线程。语言表示线程的方式也存在差异。例如，Java将线程建模为对象，Python使用全局解释器锁来阻止多个线程并行执行，而在Go语言中，正如我们将看到的，有一个更细粒度的goroutine概念。
- en: POSIX Threads
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: POSIX Threads
- en: IEEE attempted to standardize thread implementations using a standard called
    POSIX Threads (pthreads for short). These threads are created, managed, and synchronized
    through the use of a standard POSIX Threads API. Various operating systems, including
    Windows and UNIX systems, offer implementations of this standard. Unfortunately,
    not all languages support the POSIX Thread standard.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: IEEE试图通过一个称为POSIX Threads（简称pthreads）的标准来标准化线程实现。这些线程通过使用标准的POSIX Threads API来创建、管理和同步。包括Windows和UNIX系统在内的各种操作系统都提供了这个标准的实现。不幸的是，并非所有语言都支持POSIX
    Thread标准。
- en: Although differences exist in how threads are created, modeled, and destroyed,
    the concurrency concepts and techniques involved in coding concurrent programs
    will be very similar regardless of what technology you use. Thus, learning about
    the models, techniques, and tools of multithreaded programming in one language
    will be useful in whatever language you decide to use. The differences lie only
    in the language’s multithreading implementation details.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管线程的创建、建模和销毁方式存在差异，但无论使用什么技术，编码并发程序所涉及的并发概念和技术都将非常相似。因此，了解一种语言中多线程编程的模型、技术和工具将有助于你在任何语言中使用。差异仅在于语言的多线程实现细节。
- en: 2.2.5 A multithreaded application in practice
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.5 实际中的多线程应用程序
- en: 'Let’s now look at an example that makes use of multithreading in a web server
    application. Suppose we have developed an application that feeds users, via a
    service, information and scores from their favorite sports teams. This application
    lives on a server and handles users’ requests through their mobile or desktop
    browsers. For example, Paul might want to know the latest score of a football
    game in which his favorite team, the New York Giants, are playing. One architecture
    for this application is shown in figure 2.7\. It’s composed of two main parts:
    the client handler’s threads and a stream reader thread.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看一个利用多线程在Web服务器应用程序中的示例。假设我们已经开发了一个应用程序，通过服务向用户提供他们最喜欢的体育队伍的信息和比分。这个应用程序运行在服务器上，并通过用户的移动或桌面浏览器处理用户的请求。例如，保罗可能想知道他最喜欢的球队纽约巨人队正在进行的足球比赛的最新比分。这个应用程序的一个架构如图2.7所示。它由两个主要部分组成：客户端处理线程和流读取线程。
- en: '![](../../OEBPS/Images/CH02_F07_Cutajar.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH02_F07_Cutajar.png)'
- en: Figure 2.7 A web server application serving sports scores
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 提供体育比分的Web服务器应用程序
- en: The stream reader thread reads match events from a sports feed through a network
    connection. Each message received will tell the application what is happening
    in a particular game. Some examples are points scored, fouls committed, players
    on the field, etc. The stream reader thread uses this information to build a picture
    of the game, storing the score of each game in a shared sports scores data structure.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 流读取线程通过网络连接从体育直播中读取比赛事件。每个接收到的消息都会告诉应用程序特定游戏中的发生情况。例如，得分、犯规、场上的球员等。流读取线程使用这些信息来构建比赛的画面，将每场比赛的比分存储在共享的体育比分数据结构中。
- en: Each client handler thread takes care of user requests. Depending on the request
    coming from the user, the thread will look up and read the required match information
    from the sports scores data structure. It will then return the information to
    the user’s device. We have a pool of these threads so that we’re able to handle
    multiple requests at the same time without making users wait too long for a reply.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 每个客户端处理线程负责处理用户请求。根据用户发出的请求，线程将从体育比分数据结构中查找并读取所需的比赛信息。然后，它将信息返回给用户的设备。我们有一组这样的线程，这样我们就能同时处理多个请求，而不会让用户等待太长时间得到回复。
- en: 'Using threads to implement this type of server application has two benefits:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线程来实现这种类型的服务器应用程序有两个好处：
- en: We consume fewer resources. We can spin up a number of client handler threads
    without taking up too much memory. In addition, we can size up this pool dynamically,
    increasing the thread count when we expect more traffic and reducing it during
    less busy periods. We can do this because spawning and terminating threads is
    cheap and fast (relative to using processes).
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们消耗的资源更少。我们可以启动多个客户端处理线程，而不会占用太多内存。此外，我们可以动态调整这个池的大小，在预期流量增加时增加线程数，在较不繁忙的时期减少它。我们可以这样做，因为创建和终止线程的成本低且速度快（相对于使用进程）。
- en: We have the option to use memory to store and share the sports scores data structure.
    This is easy to do when using threads because they share the same memory space.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有选择使用内存来存储和共享体育比分数据结构。当使用线程时，这很容易做到，因为它们共享相同的内存空间。
- en: 2.2.6 Using multiple processes and threads together
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.6 一起使用多个进程和线程
- en: 'Let’s now think of a hybrid example, such as a modern browser, that could use
    both processes and threads. When a browser is rendering a web page, it needs to
    download various resources for the downloaded page: text, images, videos, and
    so on. To do this efficiently, the browser can use multiple threads working concurrently
    to download and then render the various elements of the page. Threads are ideal
    for this kind of work since the result page can be kept in the threads’ shared
    memory, and the threads can fill it with the various pieces as they complete their
    tasks.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑一个混合示例，比如现代浏览器，它可以使用进程和线程。当浏览器渲染网页时，它需要下载下载页面的各种资源：文本、图像、视频等。为了高效地完成这项任务，浏览器可以使用多个线程同时下载并渲染页面的各个元素。线程非常适合这种工作，因为结果页面可以保存在线程的共享内存中，而线程可以在完成任务时填充它。
- en: If the page includes some scripting that requires heavy computation (such as
    graphics), we can allocate more threads to perform this computation, possibly
    in parallel on a multicore CPU. But what happens when one of those scripts misbehaves
    and crashes? Will it also kill all the other open windows and tabs of the browser?
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果页面包含一些需要大量计算（如图形）的脚本，我们可以分配更多的线程来执行这个计算，可能在多核CPU上并行执行。但是，当其中一个脚本行为不当并崩溃时会发生什么？它也会杀死浏览器中所有其他打开的窗口和标签页吗？
- en: This is where processes might come in handy. We can design the browser to take
    advantage of the isolation of processes, perhaps by using a separate process for
    each window or tab. This ensures that when one web page crashes due to an erroneous
    script, it doesn’t bring down everything, ensuring that the tab containing your
    long draft email is not lost.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是进程可能派上用场的地方。我们可以设计浏览器以利用进程的隔离性，也许为每个窗口或标签页使用一个单独的进程。这确保了当某个网页由于错误的脚本而崩溃时，不会导致一切崩溃，确保包含你长篇草稿电子邮件的标签页不会丢失。
- en: Modern browsers adopt a hybrid thread and process system for this reason. Typically,
    they have a limit on how many processes they can create, after which tabs start
    sharing the same process. This is done to reduce memory consumption.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现代浏览器出于这个原因采用了混合线程和进程系统。通常，它们对可以创建的进程数量有限制，超过这个限制后，标签页开始共享同一个进程。这样做是为了减少内存消耗。
- en: 2.3 What’s so special about goroutines?
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 goroutine有什么特别之处？
- en: Go’s answer to concurrency is the goroutine. As we shall see, it doesn’t tie
    in directly with an operating system thread. Instead, goroutines are managed by
    Go’s runtime at a higher level to give us an even more lightweight construct,
    consuming far fewer resources than an operating system thread. In this section,
    we’ll start by looking at how we create goroutines before moving on to describe
    where goroutines sit in terms of operating system threads and processes.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Go语言对并发的回答是goroutine。正如我们将看到的，它并不直接与操作系统线程绑定。相反，goroutine由Go的运行时在更高层次上管理，以给我们提供一个更轻量级的构造，消耗的资源远少于操作系统线程。在本节中，我们将首先探讨如何创建goroutine，然后再描述goroutine在操作系统线程和进程中的位置。
- en: 2.3.1 Creating goroutines
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.1 创建goroutine
- en: Let’s now look at how we can create goroutines in Go as we transform a sequential
    program into a concurrent one. We’ll start with the following sequential program.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何在Go中创建goroutine，我们将一个顺序程序转换为并发程序。我们将从以下顺序程序开始。
- en: Listing 2.1 Function simulating some work being done
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.1 模拟执行某些工作的函数
- en: '[PRE3]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Simulates doing computation work by sleeping for 1 second
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 通过睡眠1秒来模拟执行计算工作
- en: NOTE Visit [http://github.com/cutajarj/ConcurrentProgrammingWithGo](http://github.com/cutajarj/ConcurrentProgrammingWithGo)
    to see all the listings in this book.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：访问[http://github.com/cutajarj/ConcurrentProgrammingWithGo](http://github.com/cutajarj/ConcurrentProgrammingWithGo)以查看本书中的所有列表。
- en: As you can see, we have a function that simulates doing some work. This work
    could be anything, such as a long-running CPU computation or downloading something
    from a web page. In the function, we pass an integer as an identifier for the
    work. Then we simulate doing some work by putting the execution to sleep for 1
    second. At the end of this sleep period, we print a message containing the work
    identifier to the console to signify that we have completed the work. We also
    print timestamps at the beginning and end to show how long the function takes
    to execute.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们有一个模拟执行一些工作的函数。这项工作可以是任何东西，比如长时间运行的CPU计算或从网页上下载某些内容。在函数中，我们传递一个整数作为工作的标识符。然后我们通过将执行暂停1秒来模拟执行一些工作。在睡眠期结束后，我们将包含工作标识符的消息打印到控制台，以表示我们已经完成了工作。我们还在开始和结束时打印时间戳，以显示函数执行所需的时间。
- en: Let’s run this function several times sequentially. In listing 2.2, we use a
    loop to call the function five times, each time passing a different value for
    `i`, starting at `0` and finishing at `4`. This `main()` function will run in
    our main thread of execution, and the `doWork()` function will be called sequentially
    in the same execution, with one call after the other.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们连续多次运行这个函数。在列表2.2中，我们使用循环调用函数五次，每次传递一个不同的`i`值，从`0`开始，到`4`结束。这个`main()`函数将在我们的主执行线程中运行，`doWork()`函数将以相同的执行顺序依次调用。
- en: Listing 2.2 The `main()` thread calling the `doWork()` function sequentially
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.2 `main()`线程依次调用`doWork()`函数
- en: '[PRE4]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As you might expect, the output lists the work identifiers one after the other,
    each taking 1 second:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所预期的那样，输出列表按顺序列出工作标识符，每个标识符需要1秒：
- en: '[PRE5]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The entire program takes around 5 seconds to complete. When the main thread
    has no more instructions to execute, it terminates the entire process.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 整个程序大约需要5秒钟才能完成。当主线程没有更多的指令可以执行时，它会终止整个进程。
- en: How can we change our instructions so that we perform this work concurrently
    instead of sequentially? We can put the call to the `doWork()` function in a goroutine,
    as shown in listing 2.3\. There are two main changes from our previous sequential
    program. The first is that we are calling the `doWork()` function with the keyword
    `go`. The result is that the function runs in a separate execution concurrently.
    The `main()` function does not wait for it to complete to continue. Instead, it
    goes on to the next instruction, which in this case is to create more goroutines.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何修改我们的指令，以便我们能够并行执行这项工作而不是顺序执行？我们可以在goroutine中放置对`doWork()`函数的调用，如列表2.3所示。与我们的先前顺序程序相比，有两个主要的变化。第一个变化是我们使用关键字`go`调用`doWork()`函数。结果是该函数在单独的执行中并行运行。`main()`函数不会等待它完成就继续执行。相反，它继续执行下一个指令，在这种情况下是创建更多的goroutine。
- en: Listing 2.3 Main thread calling the `doWork()` function in parallel
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.3 主线程并行调用`doWork()`函数
- en: '[PRE6]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Starts a new goroutine that calls the doWork() function
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 启动一个新的goroutine来调用doWork()函数
- en: ❷ Waits for all of the work to finish using a longer sleep
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用更长的sleep等待所有工作完成
- en: We can also refer to this manner of calling functions as an *asynchronous* call,
    meaning that we don’t have to wait for the function to complete to continue executing.
    We can refer to a normal function call as synchronous because we need to wait
    for the function to return before proceeding with other instructions.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以将这种调用函数的方式称为*异步*调用，这意味着我们不需要等待函数完成就可以继续执行。我们可以将正常的函数调用称为同步调用，因为我们需要在继续执行其他指令之前等待函数返回。
- en: 'The second change to our main function is that after we call the `doWork()`
    function asynchronously, the `main()` function sleeps for 2 seconds. The sleep
    instruction needs to be there because in Go, when the main execution runs out
    of instructions to run, the process terminates. Without this sleep, the process
    would terminate without giving the goroutines a chance to run. If we try omitting
    this statement, the program outputs nothing on the console. The output of the
    program shown in listing 2.3 will look something like this:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对`main()`函数的第二个变化是在我们异步调用`doWork()`函数后，`main()`函数休眠2秒钟。这个sleep指令是必要的，因为在Go中，当主执行没有更多的指令可以运行时，进程会终止。如果没有这个sleep，进程就会在没有给goroutine运行机会的情况下终止。如果我们尝试省略这个语句，程序在控制台上将不会输出任何内容。列表2.3中程序的输出将类似于以下内容：
- en: '[PRE7]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The first thing to notice is that the program completes in about 2 seconds instead
    of the 5 seconds it took to execute the sequential version. This is simply because
    we’re now executing the work in parallel. Instead of working on one thing, finishing,
    and then starting another one, we’re doing all of the work at once. You can see
    a representation of this in figure 2.8\. In part *a* of the figure, we have the
    sequential version of this program, showing the `doWork()` function being called
    multiple times, one after the other. In part *b*, we have the goroutine executing
    the `main()` function and spawning five child goroutines, each calling the `doWork()`
    function concurrently.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要注意的是，程序大约在2秒内完成，而不是顺序版本所需的5秒。这仅仅是因为我们现在正在并行执行工作。我们不再是一个接一个地工作，完成一个然后开始另一个，我们一次完成所有的工作。您可以在图2.8中看到这种表示。在图的部分*a*中，我们有这个程序的顺序版本，显示了`doWork()`函数被多次调用，一次接一次。在部分*b*中，我们有goroutine执行`main()`函数并产生五个子goroutine，每个子goroutine都并发调用`doWork()`函数。
- en: '![](../../OEBPS/Images/CH02_F08_Cutajar.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH02_F08_Cutajar.png)'
- en: Figure 2.8 (a) The `doWork()` function called sequentially (b) and the function
    called concurrently
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 (a) 顺序调用`doWork()`函数 (b) 和并发调用函数
- en: 'The second thing to notice when we run the Go program is that the order in
    which the function messages are output has changed. The program is no longer outputting
    the work identifiers in order. Instead, they seem to appear at random. Running
    the program again gives us a different ordering:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行Go程序时，需要注意的第二件事是函数消息输出的顺序已经改变。程序不再按顺序输出工作标识符。相反，它们似乎随机出现。再次运行程序会给我们不同的顺序：
- en: '[PRE8]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This is because when we run jobs concurrently, we can never guarantee the execution
    order of those jobs. When our `main()` function creates the five goroutines and
    submits them, the operating system might pick up the executions in a different
    order than we created them in.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为当我们并发运行作业时，我们永远无法保证这些作业的执行顺序。当我们的`main()`函数创建了五个goroutines并将它们提交时，操作系统可能会以不同于我们创建它们的顺序来选择执行。
- en: 2.3.2 Implementing goroutines in the user space
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.2 在用户空间中实现goroutines
- en: Earlier in this chapter, we talked about operating system processes and threads,
    and we discussed their differences and roles. Where does a goroutine belong within
    this context? Is a goroutine a separate process or a lightweight thread?
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面，我们讨论了操作系统进程和线程，并讨论了它们的不同和角色。goroutine在这个背景下属于哪里？goroutine是一个独立的进程还是一个轻量级线程？
- en: It turns out that goroutines are neither OS threads nor processes. The specification
    for the Go language does not strictly specify how goroutines should be implemented,
    but the current Go implementations group sets of goroutine executions onto another
    set of OS thread executions. To better understand this, let’s first talk about
    another way to model threads of execution, called *user-level* threads.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，goroutines既不是操作系统线程也不是进程。Go语言的规范并没有严格规定goroutines应该如何实现，但当前的Go实现将一组goroutine执行分组到另一组操作系统线程执行上。为了更好地理解这一点，让我们首先谈谈另一种执行线程的建模方式，称为*用户级*线程。
- en: In the previous section, we talked about threads living inside processes and
    being managed by the operating system. The operating system knows all about the
    threads and decides when or whether each thread should execute. The OS also stores
    the context of each thread (registers, stack, and state) and uses it whenever
    the threads need executing. We refer to these types of threads as *kernel-level*
    threads because the operating system manages them. Whenever there is a need for
    a context switch, the operating system intervenes and chooses the next thread
    to execute.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了存在于进程内部的线程并由操作系统管理。操作系统了解所有关于线程的信息，并决定何时或是否应该执行每个线程。操作系统还存储每个线程的上下文（寄存器、堆栈和状态），并在线程需要执行时使用它。我们将这类线程称为*内核级*线程，因为操作系统管理它们。每当需要上下文切换时，操作系统就会介入并选择下一个要执行的线程。
- en: Instead of implementing threads at the kernel level, we can have threads running
    completely in the *user space*, which means the memory space that is part of our
    application, as opposed to the operating system’s space. Using user-level threads
    is like having different threads of execution running inside the main kernel-level
    thread, as shown in figure 2.9.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在内核级别之外实现线程，这样线程就可以完全在*用户空间*中运行，这意味着它是我们应用程序内存空间的一部分，而不是操作系统的空间。使用用户级线程就像在主内核级线程内部运行不同的执行线程，如图2.9所示。
- en: '![](../../OEBPS/Images/CH02_F09_Cutajar.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH02_F09_Cutajar.png)'
- en: Figure 2.9 User-level threads executing within a single kernel-level thread
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 用户级线程在单个内核级线程中执行
- en: From an operating system point of view, a process containing user-level threads
    will appear to have just one thread of execution. The OS doesn’t know anything
    about user-level threads. The process itself is responsible for managing, scheduling,
    and context switching its own user-level threads. To execute this internal context
    switch, there needs to be a separate runtime that maintains a table containing
    all the data (such as the state) of each user-level thread. We are replicating
    on a small scale what the OS does, in terms of thread scheduling and management,
    inside the main thread of the process.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 从操作系统的角度来看，包含用户级线程的进程看起来只有一个执行线程。操作系统对用户级线程一无所知。进程本身负责管理、调度和上下文切换自己的用户级线程。为了执行这个内部上下文切换，需要一个单独的运行时来维护一个包含每个用户级线程所有数据（如状态）的表。我们在进程的主线程内部复制了操作系统在线程调度和管理方面所做的小规模工作。
- en: The main advantage of user-level threads is performance. Context-switching a
    user-level thread is faster than context-switching a kernel-level one. This is
    because for kernel-level context switches, the OS needs to intervene and choose
    the next thread to execute. When we can switch execution without invoking any
    kernel, the executing process can keep hold of the CPU without needing to flush
    its cache and slow us down.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 用户级线程的主要优势是性能。用户级线程的上下文切换比内核级线程的上下文切换要快。这是因为对于内核级上下文切换，操作系统需要介入并选择下一个要执行的线程。当我们可以在不调用任何内核的情况下切换执行时，执行进程可以保持对CPU的控制，而无需刷新其缓存并减慢速度。
- en: The downside of using user-level threads comes when they execute code that invokes
    blocking I/O calls. Consider the situation where we need to read from a file.
    Since the operating system sees the process as having a single thread of execution,
    if a user-level thread performs this blocking read call, the entire process is
    descheduled. If any other user-level threads are present in the same process,
    they will not get to execute until the read operation is complete. This is not
    ideal, since one of the advantages of having multiple threads is to perform computations
    when other threads are waiting for I/O. To work around this limitation, applications
    using user-level threads tend to use non-blocking calls to perform their I/O operations.
    However, using non-blocking I/O is not ideal, since not every device supports
    non-blocking calls.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用用户级线程的缺点在于当它们执行调用阻塞I/O调用的代码时。考虑我们需要从文件中读取的情况。由于操作系统将进程视为只有一个执行线程，如果一个用户级线程执行这个阻塞读取调用，整个进程将被取消调度。如果同一进程中存在其他用户级线程，它们将无法执行，直到读取操作完成。这并不理想，因为拥有多个线程的一个优势是在其他线程等待I/O时执行计算。为了克服这种限制，使用用户级线程的应用程序往往使用非阻塞调用来执行它们的I/O操作。然而，使用非阻塞I/O并不理想，因为并非每个设备都支持非阻塞调用。
- en: Another disadvantage of user-level threads is that if we have a multiprocessor
    or a multicore system, we will be able to utilize only one of the processors at
    any point in time. The OS sees the single kernel-level thread, containing all
    the user-level threads, as a single execution. Thus, the OS executes the kernel-level
    thread on a single processor, so the user-level threads contained in that kernel-level
    thread will not execute in a truly parallel fashion.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 用户级线程的另一个缺点是，如果我们有一个多处理器或多核系统，我们将在任何给定时间点只能利用一个处理器。操作系统将包含所有用户级线程的单个内核级线程视为单个执行。因此，操作系统在一个处理器上执行内核级线程，所以包含在该内核级线程中的用户级线程将不会以真正的并行方式执行。
- en: What about green threads?
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，绿色线程又如何呢？
- en: The term *green thread* was coined in version 1.1 of the Java programming language.
    The original green threads in Java were an implementation of user-level threads.
    They ran only on a single core and were managed completely by the JVM. In Java
    version 1.3, green threads were abandoned in favor of kernel-level threads. Since
    then, many developers have used the term to refer to other implementations of
    user-level threads. It is perhaps inaccurate to refer to Go’s goroutines as green
    threads since, as we shall see, Go’s runtime allows its goroutines to take full
    advantage of multiple CPUs.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: “绿色线程”这个术语是在Java编程语言的1.1版本中提出的。Java最初的绿色线程是用户级线程的一种实现。它们只在单个核心上运行，并且完全由JVM管理。在Java
    1.3版本中，绿色线程被内核级线程所取代。从那时起，许多开发者开始使用这个术语来指代其他用户级线程的实现。将Go的goroutines称为绿色线程可能并不准确，因为正如我们将看到的，Go的运行时允许其goroutines充分利用多个CPU。
- en: To further complicate naming matters, a threading model similar to Go was introduced
    in later versions of Java. However, this time, instead of green threads, the name
    *virtual threads* was used.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步混淆命名问题，在Java的后续版本中引入了一种类似于Go的线程模型。然而，这一次，不是绿色线程，而是使用了“虚拟线程”这个名称。
- en: Go provides a hybrid system that gives us the great performance of user-level
    threads without most of the downsides. It achieves this by using a set of kernel-level
    threads, each managing a queue of goroutines. Since we have more than one kernel-level
    thread, we can utilize more than one processor if multiple ones are available.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: Go提供了一个混合系统，它为我们提供了用户级线程的优秀性能，而没有大多数缺点。它是通过使用一组内核级线程来实现的，每个线程管理一个goroutine队列。由于我们有多于一个的内核级线程，因此如果可用，我们可以利用多个处理器。
- en: To illustrate this hybrid technique, suppose our hardware has just two processor
    cores. We can have a runtime system that creates and uses two kernel-level threads—one
    for each processor core—and each of these kernel-level threads can manage a set
    of user-level threads. At some point, the operating system will schedule the two
    kernel-level threads in parallel, each on a separate processor. We will then have
    a set of user-level threads running on each processor.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这种混合技术，假设我们的硬件恰好有两个处理器核心。我们可以有一个运行时系统，该系统创建并使用两个内核级线程——每个处理器核心一个——并且每个内核级线程可以管理一组用户级线程。在某个时刻，操作系统将并行调度这两个内核级线程，每个线程在一个单独的处理器上。然后，我们将有一组用户级线程在每个处理器上运行。
- en: '*M:N* hybrid threading'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '*M:N* 混合线程'
- en: The system that Go uses for its goroutines is sometimes called the *M:N* threading
    model. This is when you have *M* user-level threads (goroutines) mapped to *N*
    kernel-level threads. This contrasts with normal user-level threads, which are
    referred to as an *N*:1 threading model, meaning N user-level threads to 1 kernel-level
    thread. Implementing a runtime for *M:N* models is substantially more complex
    than other models since it requires many techniques to move around and balance
    the user-level threads on the set of kernel-level threads.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Go为其goroutines使用的系统有时被称为 *M:N* 线程模型。这是当你有 *M* 个用户级线程（goroutines）映射到 *N* 个内核级线程时。这与通常的用户级线程形成对比，用户级线程被称为
    *N*:1 线程模型，意味着N个用户级线程对应1个内核级线程。实现 *M:N* 模型的运行时比其他模型复杂得多，因为它需要许多技术来在内核级线程集合上移动和平衡用户级线程。
- en: Go’s runtime determines how many kernel-level threads to use based on the number
    of logical processors. This is set in the environment variable called `GOMAXPROCS`.
    If this variable is not set, Go populates this variable by querying the operating
    system to determine how many CPUs your system has. You can check how many processors
    Go sees and the value of `GOMAXPROCS` by executing the following code.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: Go的运行时根据逻辑处理器的数量确定要使用多少内核级线程。这通过名为 `GOMAXPROCS` 的环境变量设置。如果没有设置此变量，Go将通过查询操作系统来确定您的系统有多少个CPU。您可以通过执行以下代码来检查Go看到的处理器数量和
    `GOMAXPROCS` 的值。
- en: Listing 2.4 Checking how many CPUs are available
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.4 检查可用的CPU数量
- en: '[PRE9]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Go defaults the value of GOMAXPROCS to the value of NumCPU().
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Go将GOMAXPROCS的默认值设置为NumCPU()的值。
- en: ❷ Calling GOMAXPROCS(n) with n < 1 returns the current value without altering
    it.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 当n < 1时，调用GOMAXPROCS(n)将返回当前值而不更改它。
- en: 'The output of listing 2.4 will depend on the hardware it runs on. Here’s an
    example of the output on a system with eight cores:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.4的输出将取决于其运行的硬件。以下是在具有八个核心的系统上的输出示例：
- en: '[PRE10]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Go’s runtime will assign a local run queue (LRQ) to each of these kernel-level
    threads. Each LRQ will contain a subset of the goroutines in the program. In addition,
    there is a global run queue (GRQ) for goroutines that Go hasn’t yet assigned to
    a kernel-level thread (refer to the left side of figure 2.10). Each of the kernel-level
    threads running on a processor will take care of executing the goroutines present
    in its LRQ.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Go的运行时将为每个内核级线程分配一个本地运行队列（LRQ）。每个LRQ将包含程序中goroutines的一个子集。此外，还有一个全局运行队列（GRQ）用于Go尚未分配给内核级线程的goroutines（参见图2.10的左侧）。在处理器上运行的每个内核级线程将负责执行其LRQ中存在的goroutines。
- en: '![](../../OEBPS/Images/CH02_F10_Cutajar.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH02_F10_Cutajar.png)'
- en: Figure 2.10 (a) Kernel-level threads A and B are executing goroutines from their
    respective LRQs; (b) a goroutine is waiting on I/O blocking thread B, resulting
    in the creation or reuse of a new thread C, stealing work from the previous thread.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10（a）内核级线程A和B正在执行它们各自的LRQ中的goroutines；（b）一个goroutine正在等待I/O阻塞线程B，导致创建或重用新的线程C，从之前的线程中窃取工作。
- en: To work around the problem of blocking calls, Go wraps any blocking operations
    so that it knows when a kernel-level thread is about to be descheduled. When this
    happens, Go creates a new kernel-level thread (or reuses an idle one from a pool)
    and moves the queue of goroutines to this new thread, which picks a goroutine
    from the queue and starts executing it. The old thread with its goroutine waiting
    for I/O is then descheduled by the OS. This system ensures that a goroutine making
    a blocking call will not block the entire local run queue of goroutines (refer
    to the right side of figure 2.10).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决阻塞调用的问题，Go 会包装任何阻塞操作，以便它知道何时内核级线程即将被调度。当这种情况发生时，Go 会创建一个新的内核级线程（或从池中重用空闲的一个）并将
    goroutine 队列移动到这个新线程，该线程从队列中选取一个 goroutine 并开始执行它。然后，带有等待 I/O 的 goroutine 的旧线程被操作系统取消调度。这个系统确保执行阻塞调用的
    goroutine 不会阻塞整个本地 goroutine 运行队列（参见图 2.10 右侧）。
- en: This system of moving goroutines from one queue to another is known in Go as
    *work stealing*. Work stealing does not just happen when a goroutine makes a blocking
    call. Go can also use this mechanism when there is an imbalance in the number
    of goroutines in the queues. For example, if a particular LRQ is empty and the
    kernel-level thread has no more goroutines to execute, it will steal work from
    the queue of another thread. This ensures that our processors are balanced with
    work and that none are idle when there is more work to execute.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Go 中，这种将 goroutine 从一个队列移动到另一个队列的系统被称为 *工作窃取*。工作窃取不仅仅发生在 goroutine 执行阻塞调用时。当队列中
    goroutine 的数量不平衡时，Go 也可以使用这种机制。例如，如果某个特定的 LRQ 为空，且内核级线程没有更多的 goroutine 可执行，它将从另一个线程的队列中窃取工作。这确保了我们的处理器在执行更多工作时有平衡的工作负载，并且当有更多工作要执行时，没有一个是空闲的。
- en: Locking to a kernel-level thread
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 锁定到内核级线程
- en: In Go, we can force a goroutine to lock itself to an OS thread by calling the
    `runtime.LockOSThread()` function. This call binds the goroutine exclusively to
    its kernel-level thread. No other goroutines will run on the same OS thread until
    the goroutine calls `runtime.UnlockOSThread()`.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Go 语言中，我们可以通过调用 `runtime.LockOSThread()` 函数强制一个 goroutine 锁定到操作系统线程。这个调用将
    goroutine 独特地绑定到其内核级线程。除非 goroutine 调用 `runtime.UnlockOSThread()`，否则不会有其他 goroutine
    在同一 OS 线程上运行。
- en: These functions can be used when we need specialized control over the kernel-level
    threads—for example, when we are interfacing with an external C library and need
    to make sure that the goroutine does not move to another kernel-level thread,
    causing problems accessing the library.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数可以在我们需要对内核级线程进行特殊控制时使用——例如，当我们与外部 C 库交互并需要确保 goroutine 不会移动到另一个内核级线程，从而造成访问库的问题。
- en: 2.3.3 Scheduling goroutines
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.3 goroutine 调度
- en: After a kernel-level thread has had its fair share of time on the CPU, the OS
    scheduler context switches the next thread from the run queue. This is known as
    *preemptive scheduling**.* It’s implemented using a system of clock interrupts
    that stops the executing kernel-level thread and calls the OS scheduler. Since
    the interrupt calls only the OS scheduler, the Go scheduler, which runs in the
    user space, needs a different system.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 当内核级线程在 CPU 上已经公平地分配了时间后，操作系统调度器会将运行队列中的下一个线程切换到。这被称为 *抢占式调度**。它通过一个时钟中断系统实现，该系统停止正在执行的内核级线程并调用操作系统调度器。由于中断只调用操作系统调度器，运行在用户空间的
    Go 调度器需要一个不同的系统。
- en: The Go scheduler needs to execute to perform its context switching. Thus, the
    Go scheduler needs user-level events to trigger its execution (see figure 2.11).
    These events include starting a new goroutine (using the keyword `go`), making
    a system call (for example, reading from a file), or synchronizing goroutines.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Go 调度器需要执行以进行上下文切换。因此，Go 调度器需要用户级事件来触发其执行（参见图 2.11）。这些事件包括启动一个新的 goroutine（使用关键字
    `go`）、执行系统调用（例如，从文件中读取）或同步 goroutine。
- en: '![](../../OEBPS/Images/CH02_F11_Cutajar.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH02_F11_Cutajar.png)'
- en: Figure 2.11 Context switching in Go requires user-level events.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 展示了 Go 中的上下文切换需要用户级事件。
- en: We can also call the Go scheduler in our code to try to get the scheduler to
    context-switch to another goroutine. In concurrency lingo, this is usually called
    a *yield* command. It’s when a thread decides to yield control so that another
    thread gets its turn on the CPU. In the following listing, we are using the command
    `runtime.Gosched()` to call the scheduler directly in our `main()` goroutine.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以在我们的代码中调用Go调度器，试图让调度器进行上下文切换到另一个goroutine。在并发术语中，这通常被称为*yield*命令。这是当线程决定放弃控制权，以便其他线程在CPU上获得其轮次时。在下面的列表中，我们使用命令`runtime.Gosched()`在我们的`main()`
    goroutine中直接调用调度器。
- en: Listing 2.5 Calling the Go scheduler
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 列表2.5 调用Go调度器
- en: '[PRE11]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Calling the Go scheduler gives the other goroutine a chance to run.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 调用Go调度器给其他goroutine一个运行的机会。
- en: Without calling the scheduler directly, we have very little chance of getting
    the `sayHello()` function executed. The `main()` goroutine will terminate before
    the goroutine calling the `sayHello()` function gets any time to run on the CPU.
    Since in Go we exit the process when the `main()` goroutine terminates, we wouldn’t
    get to see the text “Hello” printed.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 不直接调用调度器，我们几乎没有机会执行`sayHello()`函数。`main()` goroutine将在调用`sayHello()`函数的goroutine在CPU上获得任何运行时间之前终止。由于在Go中，我们在`main()`
    goroutine终止时退出进程，所以我们不会看到“Hello”文本被打印出来。
- en: WARNING We have no control over which goroutine the scheduler will select to
    execute. When we call the Go scheduler, it might pick up the other goroutine and
    start executing it, or it might continue the execution of the goroutine that called
    the scheduler.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：我们无法控制调度器将选择哪个goroutine来执行。当我们调用Go调度器时，它可能会选择其他goroutine并开始执行它，或者它可能会继续执行调用调度器的goroutine。
- en: In listing 2.5, the scheduler may very well select the `main()` goroutine again,
    and we may never see the “Hello” message. In fact, by calling `runtime.Gosched()`
    in the listing, we are only increasing the chances that `sayHello()` will be executed.
    There is no guarantee that it will.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表2.5中，调度器可能会再次选择`main()` goroutine，我们可能永远看不到“Hello”消息。实际上，通过在列表中调用`runtime.Gosched()`，我们只是在增加`sayHello()`被执行的机会。但这并不能保证它一定会被执行。
- en: As with the OS scheduler, we cannot predictably determine what the Go scheduler
    will execute next. As programmers writing concurrent programs, we must never write
    code that relies on an apparent scheduling order, because the next time we run
    the program, the ordering might be different. If you try executing listing 2.5
    several times, you will eventually get an execution that will output `Finished`
    without executing the `sayHello()` function. If we need to control the order of
    execution of our threads, we’ll need to add synchronization mechanisms to our
    code instead of relying on the scheduler. We’ll discuss these techniques starting
    in chapter 4.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 与操作系统调度器一样，我们无法可预测地确定Go调度器接下来会执行什么。作为编写并发程序的程序员，我们绝不能编写依赖于明显调度顺序的代码，因为下次运行程序时，顺序可能会不同。如果你尝试多次执行列表2.5，你最终会得到一个执行输出`Finished`而不执行`sayHello()`函数的执行。如果我们需要控制线程的执行顺序，我们需要在我们的代码中添加同步机制，而不是依赖于调度器。我们将在第4章开始讨论这些技术。
- en: 2.4 Concurrency versus parallelism
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 并发与并行
- en: Many developers use the terms *concurrency* and *parallelism* interchangeably,
    sometimes referring to them as the same concept. However, many textbooks make
    a clear distinction between the two.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发者将术语*并发*和*并行*互换使用，有时将它们视为同一概念。然而，许多教科书在这两者之间做出了明确的区分。
- en: 'We can think of *concurrency* as an attribute of the program code and *parallelism*
    as a property of the executing program. Concurrent programming occurs whenever
    we write our programs in a way that groups instructions into separate tasks, outlining
    the boundaries and synchronization points. These are some examples of such tasks:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将*并发*视为程序代码的属性，将*并行*视为执行程序的属性。并发编程发生在我们以将指令分组到单独的任务中的方式编写程序时，概述了边界和同步点。以下是一些此类任务的例子：
- en: Handle one user’s request.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理一个用户的请求。
- en: Search one file for some text.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在某个文件中搜索一些文本。
- en: Calculate the result of one row in a matrix multiplication.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算矩阵乘法中一行的结果。
- en: Render one frame of a video game.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 渲染视频游戏的一帧。
- en: These tasks then may or may not execute in parallel. Whether they execute in
    parallel will depend on the hardware and environment where we execute the program.
    For example, if our concurrent matrix multiplication program runs on a multicore
    system, we might be able to perform more than a single row calculation at the
    same time. For parallel execution to happen, we require multiple processing units.
    Otherwise, the system can interleave between the tasks, giving the impression
    that it is doing more than one task at the same time. For example, two threads
    can take turns and share a single processor, each taking a time share. Because
    the OS switches the threads often and quickly, they both seem to be running at
    the same time.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务可能并行执行，也可能不并行执行。它们是否并行执行将取决于我们执行程序时的硬件和环境。例如，如果我们的并发矩阵乘法程序在一个多核系统上运行，我们可能能够同时执行多个行计算。为了发生并行执行，我们需要多个处理单元。否则，系统可以在任务之间交错，给人一种同时执行多个任务的感觉。例如，两个线程可以轮流共享一个处理器，每个线程占用一定的时间份额。因为操作系统频繁且快速地切换线程，它们似乎同时运行。
- en: NOTE Concurrency is about *planning* how to do many tasks at the same time.
    Parallelism is about *performing* many tasks at the same time.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：并发性是关于**规划**如何同时执行多个任务。并行性是关于**执行**多个任务同时进行。
- en: Obviously, definitions overlap. In fact, we can say that parallelism is a subset
    of concurrency. Only concurrent programs can execute in parallel, but not all
    concurrent programs will execute in parallel.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，定义是重叠的。实际上，我们可以这样说，并行性是并发性的一个子集。只有并发程序才能并行执行，但并非所有并发程序都会并行执行。
- en: Can we have parallelism when we have only one processor? You have seen that
    parallelism requires multiple processing units, but if we widen our definition
    of a processing unit, a thread that is waiting for an I/O operation to complete
    is not really idling. Isn’t writing to disk still part of the program’s work?
    If we have two threads, where one is writing to disk and another is executing
    instructions on the CPU, should we consider this to be parallel execution? Other
    components, such as disk and network, can also be working at the same time with
    the CPU for the program. Even in this scenario, we typically reserve the term
    *parallel execution* to refer to computations and not to I/O. However, many textbooks
    mention the term *pseudo-parallel* *execution* in this context. This refers to
    a system with one processor giving the impression that multiple jobs are being
    executed at the same time. The system does this by frequently context-switching
    jobs either on a timer or whenever an executing job requests a blocking I/O operation.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们只有一个处理器时，能否实现并行性？你已经看到，并行性需要多个处理单元，但如果我们扩大处理单元的定义，一个等待I/O操作完成的线程实际上并不是空闲的。写入磁盘不是程序工作的一部分吗？如果我们有两个线程，一个正在写入磁盘，另一个正在CPU上执行指令，我们应该将其视为并行执行吗？其他组件，如磁盘和网络，也可以与CPU同时为程序工作。即使在这样的情况下，我们通常将术语**并行执行**保留用于指代计算，而不是I/O。然而，许多教科书在此背景下提到了术语**伪并行**执行。这指的是一个处理器给人一种同时执行多个作业的印象。系统通过频繁地在定时器或执行作业请求阻塞I/O操作时进行任务上下文切换来实现这一点。
- en: 2.5 Exercises
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 练习
- en: NOTE Visit [http://github.com/cutajarj/ConcurrentProgrammingWithGo](http://github.com/cutajarj/ConcurrentProgrammingWithGo)
    to see all the code solutions.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：访问[http://github.com/cutajarj/ConcurrentProgrammingWithGo](http://github.com/cutajarj/ConcurrentProgrammingWithGo)以查看所有代码解决方案。
- en: 'Write a program similar to the one in listing 2.3 that accepts a list of text
    filenames as arguments. For each filename, the program should spawn a new goroutine
    that will output the contents of that file to the console. You can use the `time.Sleep()`
    function to wait for the child goroutines to complete (until you know how to do
    this better). Call the program `catfiles.go`. Here’s how you can execute this
    Go program:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写一个类似于列表2.3的程序，该程序接受一个文本文件名列表作为参数。对于每个文件名，程序应该启动一个新的goroutine，该goroutine将输出该文件的内容到控制台。你可以使用`time.Sleep()`函数等待子goroutine完成（直到你学会如何更好地做到这一点）。将程序命名为`catfiles.go`。以下是执行此Go程序的方法：
- en: '[PRE12]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Expand the program you wrote in the first exercise so that instead of printing
    the contents of the text files, it searches for a string match. The string to
    search for is the first argument on the command line. When you spawn a new goroutine,
    instead of printing the file’s contents, it should read the file and search for
    a match. If the goroutine finds a match, it should output a message saying that
    the filename contains a match. Call the program `grepfiles.go`. Here’s how you
    can execute this Go program (“bubbles” is the search string in this example):'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展你在第一个练习中编写的程序，使其不再打印文本文件的内容，而是搜索字符串匹配。要搜索的字符串是命令行上的第一个参数。当你启动一个新的 goroutine
    时，它应该读取文件并搜索匹配项，而不是打印文件的内容。如果 goroutine 找到匹配项，它应该输出一条消息，说明文件名包含匹配项。将程序命名为 `grepfiles.go`。以下是如何执行此
    Go 程序的示例（在这个例子中，“bubbles”是搜索字符串）：
- en: '[PRE13]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Change the program you wrote in the second exercise so that instead of passing
    a list of text filenames, you pass a directory path. The program will look inside
    this directory and list the files. For each file, you can spawn a goroutine that
    will search for a string match (the same as before). Call the program `grepdir.go`.
    Here’s how you can execute this Go program:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改你在第二个练习中编写的程序，使其不再传递文本文件名列表，而是传递目录路径。程序将查找此目录并列出文件。对于每个文件，你可以启动一个 goroutine
    来搜索字符串匹配（与之前相同）。将程序命名为 `grepdir.go`。以下是如何执行此 Go 程序的示例：
- en: '[PRE14]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Adapt the program in the third exercise to continue searching recursively in
    any subdirectories. If you give your search goroutine a file, it should search
    for a string match in that file, just like in the previous exercises. Otherwise,
    if you give it a directory, it should recursively spawn a new goroutine for each
    file or directory found inside. Call the program `grepdirrec.go`, and execute
    it by running this command:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将第三个练习中的程序修改为在任意子目录中递归地继续搜索。如果你给你的搜索 goroutine 一个文件，它应该在该文件中搜索字符串匹配，就像之前的练习一样。否则，如果你给它一个目录，它应该递归地为每个找到的文件或目录启动一个新的
    goroutine。将程序命名为 `grepdirrec.go`，通过运行以下命令来执行它：
- en: '[PRE15]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Multiprocessing operating systems and modern hardware provide concurrency through
    their scheduling and abstractions.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多处理操作系统和现代硬件通过它们的调度和抽象提供并发。
- en: Processes are the heavyweight way of modeling concurrency; however, they provide
    isolation.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程是建模并发的重量级方式；然而，它们提供了隔离。
- en: Threads are lightweight and share the same process memory space.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程是轻量级的，并且共享相同的进程内存空间。
- en: User-level threads are even more lightweight and performant, but they require
    complex handling to prevent the process managing all the user-level threads from
    being descheduled.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户级线程更轻量级且性能更好，但它们需要复杂的处理来防止管理所有用户级线程的进程被取消调度。
- en: User-level threads contained in a single kernel-level thread will use only one
    processor at a time, even if the system has multiple processors.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含在单个内核级线程中的用户级线程一次只能使用一个处理器，即使系统有多个处理器。
- en: Goroutines adopt a hybrid threading system with a set of kernel-level threads
    containing a set of goroutines apiece. With this system, multiple processors can
    execute the goroutines in parallel.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goroutines 采用一种混合线程系统，每个内核级线程包含一组 goroutines。使用此系统，多个处理器可以并行执行 goroutines。
- en: Go’s runtime uses a system of work stealing to move goroutines to other kernel-level
    threads whenever there is a load imbalance or a descheduling takes place.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Go 的运行时使用一种工作窃取系统，在出现负载不平衡或发生取消调度时，将 goroutines 移动到其他内核级线程。
- en: Concurrency is about planning how to do many tasks at the same time.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发是关于规划如何同时执行许多任务。
- en: Parallelism is about performing many tasks at the same time.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行是关于同时执行许多任务。
