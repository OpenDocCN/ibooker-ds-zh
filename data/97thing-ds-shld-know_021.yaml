- en: Chapter 19\. Build Multiperspective AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第19章 构建多视角AI
- en: Hassan Masum and
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hassan Masum和
- en: Sébastien Paquet
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Sébastien Paquet
- en: '![](Images/Hassan_Masum.png)![](Images/Sebastien_Paquet.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/Hassan_Masum.png)![](Images/Sebastien_Paquet.png)'
- en: Sr. Director, Analytics, Prodigy Education
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Prodigy Education的高级分析总监
- en: Applied Research Scientist, Element AI
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Element AI的应用研究科学家
- en: How AI and data science are deployed is decided by their makers and owners—but
    other stakeholders are impacted and are sometimes harmed.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学和人工智能的部署是由它们的制造者和所有者决定的，但其他利益相关者有时会受到影响甚至受到伤害。
- en: 'If you care about avoiding harm, you have to consider multiple perspectives
    when deploying data science and AI. You must step into someone else’s shoes by
    asking: if I were that person, how would this system impact my life?'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你关心避免伤害，部署数据科学和人工智能时必须考虑多个视角。你必须站在别人的角度，问自己：如果我是那个人，这个系统会如何影响我的生活？
- en: The impacts of a new technology can be unintended and complex, even for a seemingly
    benign goal such as connecting people. The creator or any single actor cannot
    see the whole picture. But every actor deeply understands their own situation
    and can therefore assess how a given technology serves or harms them.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 新技术的影响可能是意外的和复杂的，即使是对连接人们这样看似良性目标也是如此。创造者或任何单一行为者不能看到整体画面。但每个行为者深刻理解自己的情况，因此可以评估特定技术如何服务或伤害他们。
- en: Learning from stakeholders’ opinions and lived experiences has long been part
    of responsible technology discourse (in ideas like “implementation research” and
    “diffusion of innovations”). That accumulated experience remains relevant in the
    data science age.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 从利益相关者的意见和生活经验中学习长期以来一直是负责任技术讨论的一部分（例如“实施研究”和“创新扩散”中的理念）。在数据科学时代，这些积累的经验仍然具有重要意义。
- en: 'With this in mind, how can you incorporate more points of view in data science
    and AI development? Here are people whose perspectives you should consider incorporating,
    and questions they are likely to care about:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，如何在数据科学和人工智能的发展中融入更多的观点？以下是应考虑融入的人们的视角及其关心的问题：
- en: 'Users think: “Does this AI lessen my problems? Is it safe for me and fair to
    me? What kind of person will it help me to be?”'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 用户们思考：“这个AI能否减轻我的问题？对我而言安全且公平吗？它会帮助我成为怎样的人？”
- en: As the [UK government’s design principles](https://oreil.ly/osClX) and [Digital
    Service Standard](https://oreil.ly/Ig9pY) emphasize, start with user needs. Keen
    users may be especially candid with their feedback; ditto for desperate or frustrated
    users who crave better solutions. Invest time and empathy to get at users’ deeper
    issues and desires.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[英国政府的设计原则](https://oreil.ly/osClX)和[数字服务标准](https://oreil.ly/Ig9pY)所强调的，从用户需求出发。热心的用户可能特别坦率地提供反馈；渴望更好解决方案的绝望或沮丧的用户也是如此。投入时间和同理心，深入了解用户更深层次的问题和愿望。
- en: 'People who care think: “How is this AI helping or harming a user who is my
    friend, colleague, or loved one?”'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 关心他人的人们思考：“这个AI如何帮助或伤害我的朋友、同事或亲人？”
- en: Those who know a person well can often assess what helps or harms them. For
    example, to understand how a child is affected by AI, you could speak with the
    child’s parents, siblings, friends, and teachers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 那些深知一个人的人往往能评估什么对他们有益或有害。例如，要了解一个孩子如何受到AI的影响，你可以与孩子的父母、兄弟姐妹、朋友和老师交流。
- en: 'Impactees think: “How will this AI affect me? Is it harming me even though
    I never asked for it?”'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 受影响者思考：“这个AI会如何影响我？即使我从未请求，它是否正在伤害我？”
- en: Nonusers of an AI can still be affected by it, as with citizens punished by
    algorithms that limit their eligibility for benefits or parole. Such citizens
    could benefit from policies like Article 22 of [the EU’s General Data Protection
    Regulation](https://oreil.ly/sJAc4), which specifies a right for people to express
    their point of view on automated decisions that impact them, to contest such decisions,
    and to obtain human intervention. Before implementing data science at scale, map
    out who would be impacted and how that impact might in turn affect others.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是不使用AI的人也可能受到其影响，比如因算法而被剥夺福利资格或假释资格的公民。这些公民可以从《欧盟一般数据保护条例》第22条（[链接](https://oreil.ly/sJAc4)）这样的政策中获益，该条例规定人们有权表达对影响其自动化决策的观点，对此类决策提出异议，并获得人工干预。在大规模实施数据科学之前，要绘制谁会受到影响以及这种影响可能如何进一步影响其他人的地图。
- en: 'Skeptics think: “Why can’t this AI be improved or abandoned? Who were the idiots
    who built it?”'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 怀疑者们认为：“为什么这个AI不能改进或者放弃？谁是那些建造它的白痴？”
- en: 'Seek constructive skeptics: the most insightful people who *don’t* buy your
    vision. When skeptics seem unconstructive, you can still seek to understand their
    emotions and worldview.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找建设性的怀疑者：那些最具洞察力但 *不* 支持你愿景的人。即使怀疑者看起来无建设性，你仍然可以试图理解他们的情绪和世界观。
- en: 'Regulators and civil society think: “Is this AI operating lawfully? Is it safe
    and fair? How can it serve the public interest and balance different peoples’
    interests?”'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 监管机构和民间社会认为：“这个人工智能操作是否合法？它安全且公平吗？如何能够为公众利益服务并平衡不同人的利益？”
- en: Support effective regulatory and civil oversight that serves the public interest.
    Help oversight to work better, such as by sharing impact information for your
    AI, or by codeveloping standards and algorithmic accountability. (You’ll have
    to decide which countries’ regulatory agencies and ethics to support.)
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 支持有效的监管和民间监督，以符合公众利益。帮助监督工作更有效，例如通过分享你的人工智能的影响信息，或者共同开发标准和算法问责机制。（你需要决定支持哪些国家的监管机构和伦理标准。）
- en: 'Data scientists and AI makers think: “Have I considered my responsibilities
    as a creator, my biases and constraints, and others’ perspectives? Will this be
    legal, safe, and trusted and improve the world?”'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家和人工智能开发者思考：“我是否考虑了我作为创造者的责任、我的偏见和限制，以及他人的视角？这将是合法的、安全的和可信赖的，并且能够改善世界吗？”
- en: Reflect on *your own* perspective. Why are you creating this new technology?
    What shapes your motives, including your work, finances, culture, and personality?
    What obligations hinder you from satisfying users’ and impactees’ needs? Can you
    improve your empathy for and understanding of others?
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 反思 *你自己* 的视角。你为什么要创建这个新技术？什么因素影响了你的动机，包括你的工作、财务、文化和个性？哪些义务阻碍了你满足用户和受影响者的需求？你能提高对他人的同理心和理解力吗？
- en: Doing all this is hard in the onslaught of daily responsibilities. But making
    the time to take a more expansive view of what you build helps to reduce risk,
    delight customers, and make the world a better place.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在日常责任的冲击下，做到这一切并不容易。但是花时间更广泛地审视你所构建的内容，有助于降低风险，让客户满意，并让世界变得更美好。
- en: Listening to diverse stakeholders can be tough but rewarding. So can engaging
    them in diverse ways, such as through surveys, interviews, and ethnographic research.
    If you can do this and build truly multiperspective AI, then you will have a better
    chance of introducing innovations that generate long-term user and social value.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 听取多样化的利益相关者意见可能会很艰难，但也会很有回报。同样，以各种方式参与他们的意见，比如通过调查、访谈和民族志研究。如果你能做到这一点，并构建真正多视角的人工智能，那么你将有更好的机会推出能够产生长期用户和社会价值的创新。
