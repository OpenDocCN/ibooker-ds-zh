- en: Chapter 3\. Assessing the Business Impact of Automated Data Quality Monitoring
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章。评估自动化数据质量监控对业务影响
- en: By automating data quality monitoring with machine learning, you can go beyond
    traditional approaches like metrics monitoring and rule-based testing.  But before
    we get into the implementation details of this approach, we’d like to address
    what might be the elephant in the room (or, at least, on the page). *Is it worth
    it?*
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 通过机器学习自动化数据质量监控，您可以超越传统方法，如度量监控和基于规则的测试。但在深入讨论此方法的实施细节之前，我们想先解决可能存在的疑虑（或至少在页面上）。*是否值得？*
- en: 'We won’t pretend that there’s a single right answer to that question.  Nor
    would we tell everyone to go out and build or buy an automated data quality monitoring
    platform tomorrow. However, what we can do is help you answer questions such as:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会假装这个问题有一个唯一的正确答案。我们也不会告诉每个人明天就去建立或购买自动化数据质量监控平台。但我们可以帮助您回答诸如以下问题：
- en: What kind of data is best suited for automated data quality monitoring?
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最适合自动化数据质量监控的数据类型是什么？
- en: What should our data stack look like before we invest in this?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在我们投资之前，我们的数据堆栈应该是什么样子？
- en: How can we measure the ROI of a new data quality monitoring approach?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何衡量新的数据质量监控方法的投资回报率？
- en: 'Data quality issues are inevitable (see the following sidebar)—but the solution
    you choose is not. By the end of this chapter, you should have all the tools you
    need to perform a self-assessment of what your organization stands to gain from
    an automated approach. We’ll cover the four key factors you should consider: your
    data, your industry, your data maturity, and how your stakeholders stand to benefit.
    Then, we’ll provide insight into how you can assess the pros and cons with an
    ROI analysis.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量问题是不可避免的（见下文侧栏）—但您选择的解决方案并非如此。本章结束时，您应该具备所有必要的工具，以进行对组织从自动化方法中获益的自我评估。我们将涵盖您应考虑的四个关键因素：您的数据、您的行业、您的数据成熟度以及您的利益相关者如何受益。然后，我们将提供有关如何通过ROI分析评估利弊的见解。
- en: Assessing Your Data
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估您的数据
- en: 'Your data and its characteristics can tell you a lot about how (and if) automated
    data quality monitoring can meet your company’s needs.  Years ago, IBM introduced
    the idea of the “Four V’s of Big Data”: volume, variety, velocity, and veracity.
    It remains a useful framing, as shown in the original [infographic](https://oreil.ly/0kYP1).
    Here’s our interpretation of these four aspects and their implications for automated
    data quality monitoring.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据及其特征可以告诉您很多关于自动化数据质量监控如何（以及是否）满足您公司需求的信息。多年前，IBM提出了“大数据的四个V”概念：体积、多样性、速度和真实性。它仍然是一个有用的框架，如原始[信息图](https://oreil.ly/0kYP1)所示。以下是我们对这四个方面及其对自动化数据质量监控的影响的解释。
- en: Volume
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 体积
- en: If data is sufficiently small in volume, then humans can review it by hand.
    But even if there are just dozens of new records per day, that can merit automated
    data quality monitoring. As you approach millions or billions of rows per day,
    then the challenge becomes finding data quality issues in small, but important,
    segments of data—making it essential to invest in unsupervised learning models
    and notifications that avoid alert fatigue (aspects we’ll discuss in future chapters).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据量足够小，那么人们可以手动审查它。但即使每天只有几十条新记录，也可能需要进行自动化数据质量监控。当每天的数据行数接近百万或十亿时，挑战在于找出数据小但重要的部分中的数据质量问题——这使得投资于无监督学习模型和避免警报疲劳的通知变得至关重要（这是我们将在未来章节讨论的方面）。
- en: Variety
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多样性
- en: 'The larger the variety of data an organization is capturing, the greater the
    surface area of risk for data quality issues. Sources of variety include:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 组织捕获的数据种类越多，数据质量问题的风险表面积就越大。多样性的来源包括：
- en: How the data is structured
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的结构如何
- en: How the data is collected
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是如何收集的
- en: How time is measured in the data
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中时间的测量方式
- en: How the data is updated
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据更新的方式
- en: What entity is described in the data
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中描述的实体是什么
- en: How records in the data relate to other records
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中的记录如何与其他记录相关
- en: Variation in the business process being described
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述的业务过程的变化
- en: How granular or summarized the data is
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的粒度或摘要程度如何
- en: 'With different kinds of data, what you care about monitoring often changes.
    Consider, as an example, how columns can typically be categorized as either identifier
    columns, time columns, segment columns, or metric columns. Within each of those
    categories of data, there are different things you might care about monitoring—we’ve
    listed the most important ones here:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不同类型的数据，您关心的监控内容通常会发生变化。例如，考虑一下列可以通常被分类为标识符列、时间列、分段列或度量列。在每一类数据中，您可能关心的监控事项都不同——我们在这里列出了最重要的几项：
- en: Identifier columns (e.g., customer ID)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 标识符列（例如，客户 ID）
- en: 'What to monitor: uniqueness, format, relational integrity'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 需要监控的内容：唯一性，格式，关系完整性
- en: Time columns (e.g., event timestamp)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 时间列（例如，事件时间戳）
- en: 'What to monitor: granularity, sequencing, interarrival times'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 需要监控的内容：粒度，顺序，到达时间间隔
- en: Segment columns (e.g., customer region)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 分段列（例如，客户地区）
- en: 'What to monitor: validity, distribution, cardinality'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 需要监控的内容：有效性，分布，基数
- en: Metric columns (e.g., total daily orders)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 度量列（例如，每日总订单）
- en: 'What to monitor: averages, distribution, outliers'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 需要监控的内容：平均值，分布，异常值
- en: A major aspect of variety in your data is *structure*. How structured your data
    is greatly affects the monitoring strategies that you might want to apply. With
    the right techniques, you can automate data quality monitoring even for unstructured
    data. But in general, the more structured the data is, the easier it will be to
    monitor with an automated approach.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据多样性的一个重要方面是*结构*。您的数据有多结构化将极大地影响您可能想要应用的监控策略。通过合适的技术，即使是非结构化数据，您也可以自动化数据质量监控。但通常来说，数据结构化程度越高，使用自动化方法进行监控就会越容易。
- en: Unstructured data
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 非结构化数据
- en: Unstructured data may include video, images, audio, and text files. When working
    with unstructured data, you’ll need additional algorithms to “decode” its contents
    into values that you can monitor.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 非结构化数据可能包括视频、图像、音频和文本文件。在处理非结构化数据时，您将需要额外的算法来“解码”其内容，以获取您可以监控的值。
- en: One approach is to compute metadata about unstructured data (e.g., the length
    of a video, the size of an image) and monitor that metadata for data quality issues.
    To monitor the data values more directly, you can train an ML classifier in some
    cases—for example, you could imagine training a computer vision model to detect
    blurry images.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是计算关于非结构化数据的元数据（例如视频的长度、图像的大小）并监控该元数据以检测数据质量问题。为了更直接地监控数据值，您有时可以训练一个 ML
    分类器——例如，您可以想象训练一个计算机视觉模型来检测模糊图像。
- en: 'Or, you might already have a deep learning model that uses the data as input,
    such as a model that learns to predict the next word in a sequence by ingesting
    a large volume of unstructured text. If you wanted to try to find issues in the
    input data, you could monitor the model’s *embeddings*: N-dimensional numeric
    vectors that represent the input data. By monitoring for drift in the embeddings
    using an unsupervised ML approach, you can monitor changes in the input data by
    proxy.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可能已经有一个使用数据作为输入的深度学习模型，例如通过摄取大量非结构化文本学习预测序列中下一个词的模型。如果您希望尝试在输入数据中找到问题，您可以通过监控模型的*嵌入*来监控：N维数值向量，代表输入数据。通过使用无监督的
    ML 方法监控嵌入中的漂移，您可以通过代理监控输入数据的变化。
- en: However, every time the model is retrained, its embeddings will shift dramatically.
    So, this monitoring strategy is only useful with a static deep learning model.
    With the rise of [foundation models](https://oreil.ly/uy_Ci),^([1](ch03.html#ch01fn2))
    which are large-scale deep learning models for text and image processing (such
    as DALL-E and GPT-4 from OpenAI), these embeddings are stable in between major
    version upgrades, and so monitoring how your unstructured data is changing in
    these embeddings spaces is a useful proposition.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，每次模型重新训练时，其嵌入会发生巨大变化。因此，这种监控策略仅对静态深度学习模型有效。随着[基础模型](https://oreil.ly/uy_Ci)的崛起^([1](ch03.html#ch01fn2))，这些模型是用于文本和图像处理的大规模深度学习模型（如
    OpenAI 的 DALL-E 和 GPT-4），这些嵌入在主要版本升级之间是稳定的，因此监控您的非结构化数据在这些嵌入空间中如何变化是一个有用的建议。
- en: Understanding the significance and impact of how your unstructured data is changing
    in embedding spaces remains a challenging problem. However, [new breakthroughs
    in the interpretability of individual neurons](https://oreil.ly/nGEs_) in these
    models may make this easier. In addition, organizations can associate their structured
    data with their unstructured data embeddings to characterize which segments of
    their data are experiencing significant shifts. For example, it might be the case
    that a significant distribution change was isolated to customers in a specific
    geography or to product experiences from a specific platform. Finally, you can
    always return to the text itself and examine samples that are unusual, and even
    ask a generative AI model to summarize a sample of these unusual records.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 理解您的非结构化数据在嵌入空间中如何变化的意义和影响仍然是一个具有挑战性的问题。然而，[解释个体神经元的新突破](https://oreil.ly/nGEs_)可能会使这变得更加容易。此外，组织可以将他们的结构化数据与非结构化数据嵌入关联起来，以表征其数据的哪些部分正在经历显著的变化。例如，可能会发现显著的分布变化仅限于特定地理区域的客户或来自特定平台的产品体验。最后，您可以随时返回文本本身，检查那些异常的样本，甚至可以要求生成式AI模型总结这些异常记录的样本。
- en: Semistructured data
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 半结构化数据
- en: Semistructured data doesn’t have a fixed flat tabular structure; its structure
    may be nested and variable over time. But it does have a structure (such as tags
    and positional values) that enforces a certain hierarchy or relationship among
    its elements. To automate monitoring for semistructured data, you generally need
    a mix of schema validation, custom algorithms, and rules.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 半结构化数据没有固定的平面表结构；其结构可能随时间而变化并且可以是嵌套的。但它确实有一个结构（例如标签和位置值），这些结构强制执行其元素之间的某种层次结构或关系。要自动化监视半结构化数据，通常需要混合使用模式验证、定制算法和规则。
- en: 'Many types of domain-specific data—such as geographic data or DNA sequencing—fall
    into this category. But by far the most common type of semistructured data is
    JSON data. Especially when a company is less mature, it’s often easiest for engineers
    to store data as JSON: each record can have a custom schema to capture the idiosyncrasies
    of individual digital events or user profiles, and this schema can be rapidly
    changed over time, so there’s no need to continually [migrate](https://oreil.ly/w2Dba)
    structured data stores.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 许多类型的领域特定数据——例如地理数据或DNA序列——属于这一类别。但到目前为止，半结构化数据最常见的类型是JSON数据。特别是在公司较少成熟时，工程师通常会将数据存储为JSON：每条记录都可以具有自定义模式，以捕获个别数字事件或用户配置文件的特殊性，并且随着时间的推移，此模式可以迅速变化，因此无需不断进行[迁移](https://oreil.ly/w2Dba)结构化数据存储。
- en: 'With JSON data, you’ll need to consider how to monitor two concepts: *objects*,
    or `*{“key”: <value>}*` pairs, and *arrays*, lists of values enclosed by brackets.
    In the most complex cases, you’ll have nested combinations of both objects and
    arrays.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '对于JSON数据，您需要考虑如何监视两个概念：*对象*或`*{"key": <value>}*`对，以及*数组*，由括号括起来的值列表。在最复杂的情况下，您将同时具有对象和数组的嵌套组合。'
- en: 'JSON objects can be easily expanded as additional columns in a given table
    of data. Suppose a column `json` contains the values `{“name”: “bob”, “age”: 32}`.
    This column can be expanded into a string `json.name` column containing `“bob”`
    and an integer `json.age` column containing `32`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 'JSON对象可以作为数据表中给定列的附加列轻松扩展。假设一个列`json`包含值`{"name": "bob", "age": 32}`。该列可以扩展为一个包含`“bob”`的字符串`json.name`列和一个包含`32`的整数`json.age`列：'
- en: '| `json` [json] | `json.name` [string] | `json.age` [integer] |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `json` [json] | `json.name` [string] | `json.age` [integer] |'
- en: '| --- | --- | --- |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| `{“name: “bob,” “age”: 32}` | `“bob”` | `32` |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `{"name": "bob", "age": 32}` | `"bob"` | `32` |'
- en: Some data warehouses will support this type of expansion automatically and help
    you enforce schemas for JSON. However, it’s uncommon for you to know the schema
    ahead of time (as engineers on different teams will often be changing the schema
    or writing new ones). In this case, you need to take the extra step of expanding
    the data before you can monitor it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据仓库将自动支持这种扩展并帮助您强制执行JSON的模式。但是，事先知道模式是不常见的（因为不同团队的工程师经常会更改模式或编写新的模式）。在这种情况下，您需要在监视之前扩展数据。
- en: JSON arrays are tougher to handle. You can think of them as a relational form
    of data that has been “compressed” into a single row. For example, an array might
    be used to specify a customer’s addresses.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: JSON数组更难处理。您可以将它们视为已“压缩”为单行的数据的关系形式。例如，数组可用于指定客户的地址。
- en: 'While you could expand these lists into a relational table, your options are
    not that attractive: you would need to expand each list into a new table with
    a customer ID column (repeated 1 to N times, depending on how many addresses each
    customer had) and address string column that contains the address information
    (essentially, doing database normalization), as shown here:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然你可以将这些列表展开为关系表，但你的选择并不那么吸引人：你需要将每个列表扩展为一个新表，带有客户ID列（根据每个客户的地址数量重复1到N次）和包含地址信息的地址字符串列（实质上是进行数据库标准化），如下所示：
- en: '| `customer_id` [integer] | `address` [string] |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `customer_id` [整数] | `address` [字符串] |'
- en: '| --- | --- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| ... | ... |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... |'
- en: This would isolate this data from the other customer information, making it
    difficult to see correlations between address issues and other data issues, and
    would make it harder to root-cause the address issues using other customer information.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使这些数据与其他客户信息隔离开来，使得难以看到地址问题与其他数据问题之间的相关性，并且使得使用其他客户信息来找到地址问题的根本原因变得更加困难。
- en: 'The alternative is to expand the address information into many columns (most
    of which will be sparse, as many users will have only a small number of addresses,
    but some may have many), as shown here. Neither of these situations lends itself
    well to monitoring with unsupervised ML:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是将地址信息扩展为多个列（其中大多数列将是稀疏的，因为许多用户只有少量地址，但某些用户可能有很多地址），如下所示。这两种情况都不适合使用无监督ML进行监控：
- en: '| `customer.address1` [string] | `customer.address2` [string] | ... | `customer.addressN`
    [string] |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `customer.address1` [字符串] | `customer.address2` [字符串] | ... | `customer.addressN`
    [字符串] |'
- en: '| --- | --- | --- | --- |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| ... | ... | ... | ... |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... | ... | ... |'
- en: One strategy for handling such lists of data is to randomly sample array elements
    and monitor these for data quality issues. This strategy also allows you to gracefully
    handle the cases where objects and arrays are nested. We’ll discuss sampling in
    depth in [Chapter 4](ch04.html#automating_data_quality_monitoring_wi).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 处理此类数据列表的一种策略是随机抽样数组元素，并监视这些元素以发现数据质量问题。此策略还允许你优雅地处理对象和数组嵌套的情况。我们将在[第四章](ch04.html#automating_data_quality_monitoring_wi)深入讨论抽样。
- en: Structured data
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结构化数据
- en: 'Structured, relational data is often the most important type of data to monitor,
    as it’s the form factor most often consumed by analytics platforms, ML models,
    and other data products. While it may not be a large percentage of the total volume
    of data an organization amasses, it makes up a disproportionate amount of the
    *valuable* data. Within this category, there are three kinds of structured data
    you should consider monitoring: normalized relational data, fact tables, and summary
    tables.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 结构化的关系数据通常是最重要的监控数据类型，因为它是最经常被分析平台、ML模型和其他数据产品消耗的形式因子。虽然它可能不占组织累积数据总量的大部分，但它构成了不成比例的*有价值*数据。在此类别中，有三种类型的结构化数据是你应该考虑监控的：标准化的关系数据、事实表和汇总表。
- en: Normalized relational data
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 标准化的关系数据
- en: In the context of data quality monitoring, you can think of normalized relational
    data as data distributed among multiple tables that all relate to one another
    (the exact definition and uses of database normalization are out of scope for
    this book). Each table will have a primary key and data that’s uniquely associated
    with that primary key; each table may also have multiple foreign keys that can
    be used to join to other tables.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据质量监控的背景下，你可以将标准化的关系数据视为分布在多个表中相互关联的数据（数据库标准化的确切定义和用途超出了本书的范围）。每个表都将有一个主键和与该主键唯一相关联的数据；每个表也可能有多个外键，可以用来与其他表进行连接。
- en: This type of data is very common in production applications. It’s the most efficient
    way to store data when reading or writing to databases in an OLTP (Online Transactional
    Processing) mode, where each application interaction will generate DB reads and
    writes associated with it. Many data warehouses will copy normalized data directly
    into the data warehouse as a raw “replica” of the data being stored in the production
    application. Then, this data will be transformed into fact tables or summary data—the
    “data factory” work (see the section [“Issues Inside the Data Factory”](ch01.html#issues_inside_the_data_factory))
    that converts data into a more usable form for dashboards and other data products.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 此类数据在生产应用中非常常见。当在OLTP（在线事务处理）模式下读取或写入数据库时，这是存储数据的最有效方式，每次应用程序交互都会生成与之相关的数据库读取和写入。许多数据仓库会将规范化数据直接复制到数据仓库中，作为存储在生产应用中的数据的原始“副本”。然后，这些数据将转换为事实表或汇总数据——“数据工厂”工作（参见章节[“数据工厂内部的问题”](ch01.html#issues_inside_the_data_factory)），将数据转换为更适用于仪表板和其他数据产品的形式。
- en: Data quality monitoring can and should be directly applied to normalized relational
    data, as this data is often at the “root” of issues that will appear downstream.
    However, this data presents only a limited surface for monitoring because each
    table is narrow and self-contained. To truly understand the scope and context
    of issues, data monitoring solutions will need to join to other tables in the
    relational model—which is expensive if done at query time.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量监控可以并且应该直接应用于规范化的关系数据，因为这些数据通常是下游问题“根源”的关键。然而，这些数据仅提供有限的监控表面，因为每个表都是狭窄且自包含的。要真正理解问题的范围和背景，数据监控解决方案需要与关系模型中的其他表连接——如果在查询时进行，这将是昂贵的。
- en: Fact tables
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 事实表
- en: To overcome the analytical challenges of having to write every query as a complex
    join and aggregation of multiple normalized tables, many organizations create
    “fact” tables, which denormalize data into a single materialized table.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服将每个查询编写为多个规范化表的复杂联接和聚合的分析挑战，许多组织创建了“事实”表，将数据非规范化为一个单一的物化表。
- en: 'For example, an ecommerce company might have a `fact_orders` table, where each
    row represents an order from a customer on their website. In addition to timestamps
    and identifiers associated with that specific order, it might also summarize information
    from other tables:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，电子商务公司可能有一个`fact_orders`表，其中每一行代表客户在其网站上的一个订单。除了与该特定订单相关的时间戳和标识符外，它还可能总结其他表中的信息：
- en: Information about the actions the customer took leading up to the order (from
    a web/mobile events table)
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于客户在订单之前采取的行动的信息（来自网页/移动事件表）
- en: Information about the customer who placed the order (joined from a customer
    table)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于下订单的客户的信息（从客户表中合并）
- en: Information about the items purchased in the order (joined from an items table)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于订单中购买的商品的信息（从商品表中合并）
- en: Timestamps associated with the fulfillment, cancellation, or other processing
    of the order (joined from order processing event tables)
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与订单的履行、取消或其他处理相关的时间戳（从订单处理事件表中合并）
- en: '*These tables are often the most insightful to monitor for data quality issues.*
    Fact tables take very finely grained information, which might otherwise be spread
    across tens or hundreds of tables, and roll it up into an entity with real business
    value. They are also purpose-built and maintained to be a consolidated basis for
    other analytics, ML, and product teams to consume. As a result, issues visible
    at this level are usually important ones; they can be uncovered by a mix of unsupervised
    ML monitoring, rule-based testing, and metric monitoring. Fact tables also provide
    a great deal of context about each record in the table, which can help with understanding
    issues when they do occur.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*这些表通常是监控数据质量问题时最具洞察力的。* 事实表采用非常细粒度的信息，原本可能分散在数十或数百个表中，并将其汇总到具有实际业务价值的实体中。它们也专门设计和维护，以作为其他分析、机器学习和产品团队的集中基础。因此，在这个层面上可见的问题通常是重要的问题；它们可以通过无监督机器学习监控、基于规则的测试和指标监控的组合来发现。事实表还提供了大量关于表中每条记录的上下文，这可以帮助理解问题何时发生。'
- en: Summary tables
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 汇总表
- en: Summary tables are aggregations of relational data or fact tables, often used
    to power dashboards and reports. For example, an ecommerce company might have
    a customer summary table that presents the latest statistics for each customer,
    like their number of orders, satisfaction rating, and expected lifetime value.
    Or a financial services company might maintain a daily aggregate of financial
    performance and risk information for key business segments that is used in generating
    financial reports.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要表是关系数据或事实表的聚合，通常用于支持仪表板和报告。例如，电子商务公司可能有一个客户摘要表，显示每位客户的最新统计信息，如订单数量、满意度评级和预期生命周期价值。或者，金融服务公司可能维护关键业务部门每日财务表现和风险信息的日汇总，用于生成财务报告。
- en: '*These tables are important to monitor for data quality issues, as they are
    foundational for reporting applications.* One wrinkle is that these tables will
    often show only the most recent information for each entity they are summarizing
    over. As such, data monitoring solutions need to take snapshots of these tables
    in order to detect issues that arise over time.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*这些表格对于监控数据质量问题至关重要，因为它们是报告应用程序的基础。*一个微妙之处在于，这些表格通常只会显示每个实体的最新信息。因此，数据监控解决方案需要对这些表格进行快照，以便随时间检测到的问题。'
- en: Velocity
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 速率
- en: Data is collected, aggregated, and distributed at a wide variety of velocities.
    Consider census data generated once per year, compared to transactional product
    data generated once per millisecond.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 数据以各种速率收集、聚合和分发。例如，考虑每年生成的普查数据，与每毫秒生成的交易产品数据进行比较。
- en: '[Table 3-1](#how_monitoring_strategies_vary_with_dat) shows that as the cadence
    of the data varies, so do the appropriate strategies for monitoring data quality
    issues.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[表格 3-1](#how_monitoring_strategies_vary_with_dat) 显示随着数据更新频率的变化，监控数据质量问题的适当策略也在变化。'
- en: Table 3-1\. How monitoring strategies vary with data update cadence
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 3-1\. 数据更新频率与监控策略的变化方式
- en: '| Cadence | Scope | Example | Monitoring | Resolution |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 频率 | 范围 | 示例 | 监控 | 解决 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Year | Census | Large-scale population surveys | Manual | Manual |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 年 | 普查 | 大规模人口调查 | 手动 | 手动 |'
- en: '| Quarter | Financial | Quarterly financial statements |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 季度 | 财务 | 季度财务报表 |'
- en: '| Month | Billing | Monthly billing cycle statements |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 月 | 结算 | 每月结算周期报表 |'
- en: '| Week | Scheduling | Weekly scheduling data for retail | Algorithmic | Human
    review |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 周 | 调度 | 零售业的每周调度数据 | 算法 | 人工审核 |'
- en: '| Day | Summary | Daily user summary statistics |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 日 | 摘要 | 每日用户摘要统计 |'
- en: '| Hour | Context | Medical device summary statistics |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 小时 | 上下文 | 医疗设备摘要统计 |'
- en: '| Minute | Activity | Advertising attribution data | Deterministic | Programmatic
    |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 分钟 | 活动 | 广告归因数据 | 确定性 | 程序化 |'
- en: '| Second | Event | Fraud detection for online activity |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 秒 | 事件 | 在线活动欺诈检测 |'
- en: '| Millisecond | Transactional | Credit card approval process |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 毫秒 | 交易 | 信用卡批准流程 |'
- en: For data arriving less frequently than monthly, data quality monitoring is often
    a manual process. While ML models can be used to compare sets of data from one
    time period to the next, the problem is one of relevance. When data only arrives
    every year, a model needs years to learn about what changes to expect—and in the
    meantime, the processes that generate the data will almost certainly change, rendering
    the model’s knowledge irrelevant.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不频繁到达的数据，数据质量监控通常是一个手动过程。虽然可以使用机器学习模型比较不同时间段的数据集，但问题在于其相关性。当数据每年才到达一次时，模型需要多年时间来学习预期的变化——同时，生成数据的过程几乎肯定会发生变化，使模型的知识变得无关紧要。
- en: For data arriving weekly, daily, or hourly, automated monitoring using unsupervised
    ML becomes possible and powerful. There is enough data history to train models,
    the sample sizes for evaluation are often large enough to detect meaningful differences,
    and the frequency is beginning to be too great to have humans manually review
    the data without significant cost and burden.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每周、每日或每小时到达的数据，可以使用无监督机器学习进行自动监控，这既可能又强大。有足够的数据历史来训练模型，评估样本大小通常足够大以检测有意义的差异，并且频率开始变得过高，以至于无法在没有显著成本和负担的情况下由人类手动审查数据。
- en: For data arriving as fast as every minute, or down to the millisecond, monitoring
    considerations change again. You need to be able to correct any issues in real
    time with a programmatic response—involving humans will be too slow. Therefore,
    while this type of data should be monitored automatically, more deterministic
    solutions are needed (i.e., rules-based testing only) so that there is no risk
    of false positives.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每分钟甚至毫秒级别到达的数据，监控考虑又有所不同。您需要能够通过程序响应实时纠正任何问题——涉及人类将会太慢。因此，尽管应自动监控此类数据，但仍需要更加确定性的解决方案（即仅基于规则的测试），以确保不存在误报的风险。
- en: Veracity
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确性
- en: The veracity of data is essentially the data’s truthfulness or correctness.
    We can’t ever *really* know if data accurately reflects the real world, so to
    get a good approximation of the veracity of a dataset, you can look at the inherent
    risk of new data quality issues being introduced (see [Chapter 1](ch01.html#the_data_quality_imperative)).
    You can also account for factors that may increase your belief in the data’s veracity—for
    example, a contract between data producers and data consumers that contains SLAs
    such as how often the data will be delivered.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的准确性实质上是数据的真实性或正确性。我们无法真正知道数据是否准确地反映了现实世界，因此要对数据集的准确性进行良好的近似评估，您可以查看引入新数据质量问题的固有风险（见[第1章](ch01.html#the_data_quality_imperative)）。您还可以考虑可能增加您对数据准确性信任的因素，例如数据生产者与数据消费者之间包含SLA（服务级别协议）的合同，包括数据交付频率等。
- en: 'The veracity of your data sources will obviously affect how much value you
    get out of data quality monitoring. We suggest reviewing [Chapter 1](ch01.html#the_data_quality_imperative)
    and the [Appendix A](app01.html#types_of_data_quality_issues) for examples of
    data quality issues and why they can occur, and mapping those issues to the types
    of data your business works with. You may also consider auditing the data quality
    issues you have had in the past: their number, severity, etc.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 您的数据源的准确性显然会影响您从数据质量监控中获得的价值。我们建议查阅[第1章](ch01.html#the_data_quality_imperative)和[附录A](app01.html#types_of_data_quality_issues)，了解数据质量问题的示例及其发生原因，并将这些问题映射到您的业务中处理的数据类型。您还可以考虑审计您过去遇到的数据质量问题：数量、严重性等。
- en: 'As a rule of thumb, the following data sources tend to be the least veracious:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 作为经验法则，以下数据源通常是最不可靠的：
- en: Data provided by third parties, though it can be very reliable, can also change
    unexpectedly without any communication with the consuming entities. This is often
    high-priority data to monitor.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管来自第三方的数据通常非常可靠，但其变化可能会出乎意料，而且未必与消费实体进行沟通。这通常是需要优先监控的数据。
- en: Data generated from very complex systems that are interacting with one another
    will be more likely to suffer data quality issues, as assumptions made in one
    system may not be respected by others.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由相互交互的非常复杂系统生成的数据更有可能遭遇数据质量问题，因为一个系统做出的假设可能不被其他系统尊重。
- en: Data generated from systems that are undergoing continuous changes and rapid
    improvements are more likely to suffer data quality issues.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由正在持续变化和快速改进的系统生成的数据更有可能遭遇数据质量问题。
- en: Data generated by legacy systems is also more likely to have problems, as data
    quality tends to degrade over time, and often these systems are not being well-maintained.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由传统系统生成的数据也更有可能存在问题，因为数据质量往往随时间而下降，并且这些系统通常未得到良好的维护。
- en: Special Cases
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特殊情况
- en: 'In rare cases, some types of data are difficult to monitor with unsupervised
    ML. You may need a manual or purely rules-based approach in the following situations:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在极少数情况下，某些类型的数据难以通过无监督的机器学习进行监控。在以下情况下，您可能需要手动或纯粹基于规则的方法：
- en: Data where it’s important to ensure that individual values are collected correctly
    at the point of entry, such as customer addresses that are entered manually. For
    this use case, you’d want a system to validate the data at the time of entry.
    If you don’t detect the issue until it’s in your data warehouse, you’ll have a
    hard time getting it fixed unless you go back to the customer and ask them for
    the address again.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的收集非常重要，尤其是需要手动输入的客户地址等个别数值。对于这种情况，您需要在输入时验证数据。如果直到数据进入数据仓库才发现问题，除非回头向客户再次确认地址，否则很难进行修复。
- en: Data with a very small number of entities or transactions. For example, data
    related to mergers and acquisitions at a financial firm would be hard to automatically
    monitor for data quality. There isn’t likely to be a large amount of this data,
    and transactions will vary greatly in shape and structure.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据中实体或交易数量非常少。例如，金融公司有关并购的数据很难自动监控数据质量。这类数据数量不大，且交易形态和结构各异。
- en: Data that’s collected in a single large, static data dump. For example, consider
    data from a pharmaceutical trial. There may be an argument for data quality monitoring
    if the trial is running over a long period of time, but in most cases like these,
    the data is collected at once using the same process and system. If there are
    data quality issues, they are probably inherent in the data. You would need a
    validation rule to find such problems and to compare your expectation of reality
    with what the data says.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据以单一的大型静态数据转储方式收集。例如，考虑来自制药试验的数据。如果试验持续时间较长，则可能需要进行数据质量监控，但在大多数情况下，这些数据是一次性使用相同的过程和系统收集的。如果存在数据质量问题，这些问题可能是数据固有的。您需要一个验证规则来发现这类问题，并将您对现实的预期与数据所说的进行比较。
- en: Assessing Your Industry
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估您的行业
- en: 'At Anomalo, our customers primarily come from the following industries: financial
    services, ecommerce, media, technology, real estate, and healthcare. While this
    landscape will certainly continue to change and evolve, we’ve done a great deal
    of thinking about why this is the case today. What makes the data quality imperative
    feel so urgent in certain industries?'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在Anomalo，我们的客户主要来自以下行业：金融服务、电子商务、媒体、科技、房地产和医疗保健。虽然这一景观肯定会继续变化和发展，但我们对于为什么今天某些行业对数据质量的重要性感到如此迫切，进行了大量思考。
- en: It’s partly due to the data factors discussed previously. All the industries
    mentioned work with large volumes of data from transactions and events. Some rely
    heavily on third-party data; real estate companies, for example, depend on multiple
    listing service (MLS) data, sourced from many partners with varying formats, timeliness,
    and quality. And in digitally native industries like ecommerce, technology, and
    media, platforms and products are undergoing frequent, rapid changes.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分是由之前讨论的数据因素造成的。所有提到的行业都与大量来自交易和事件的数据打交道。一些行业严重依赖第三方数据；例如，房地产公司依赖于来自多个合作伙伴的多列表服务（MLS）数据，这些数据的格式、及时性和质量各不相同。而在电子商务、科技和媒体等数字原生行业，平台和产品经常快速变化。
- en: However, there are a few additional factors that can make a big difference in
    an industry moving to adopt automated data quality monitoring.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有一些额外因素可能会在推动行业采用自动化数据质量监控方面产生重大影响。
- en: Regulatory Pressure
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监管压力
- en: There’s no doubt that regulations are pushing some organizations to invest in
    automated data quality. Financial institutions, for instance, must meet regulatory
    and supervision requirements with various market authorities or face significant
    repercussions. For example, [Wells Fargo](https://oreil.ly/-iddF) received a $250
    million fine and a legally binding consent order from the US Office of the Comptroller
    of the Currency in 2021 for failing to protect consumers from unsafe practices.
    Citibank [was fined $400 million](https://oreil.ly/nnIMz) “related to deficiencies
    in enterprise-wide risk management, compliance risk management, data governance,
    and internal controls.”
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，监管机构正在推动一些组织投资于自动化数据质量。例如，金融机构必须满足各种市场监管机构的监管要求，否则将面临重大的后果。例如，[富国银行](https://oreil.ly/-iddF)
    在2021年因未能保护消费者免受不安全行为，被美国国家银行监督管理局处以2.5亿美元的罚款和法律约束同意令。花旗银行[被罚款4亿美元](https://oreil.ly/nnIMz)，涉及企业范围内风险管理、合规风险管理、数据治理和内部控制方面的缺陷。
- en: '[EDM Council](https://oreil.ly/XVogi) is a prominent global association that
    provides consultation and advice on enterprise data management and how it intersects
    with regulatory obligations (so don’t go looking for music recommendations). Their
    [Cloud Data Management Capabilities (CDMC) framework](https://oreil.ly/BiFge)
    provides best practices for working with sensitive data and is frequently used
    at financial organizations to ensure compliance. Key aspects of the framework
    include:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[EDM委员会](https://oreil.ly/XVogi)是一个著名的全球性协会，提供企业数据管理及其与监管义务交叉相关的咨询和建议（所以不要寻找音乐推荐）。他们的[云数据管理能力（CDMC）框架](https://oreil.ly/BiFge)为处理敏感数据提供了最佳实践，并经常在金融机构中使用以确保合规性。该框架的关键方面包括：'
- en: CDMC 1.1
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: CDMC 1.1
- en: Automatically monitor key control compliance metrics and generate an alert when
    metrics fall below specific thresholds.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当关键控制合规性指标监测到低于特定阈值时，自动生成警报。
- en: CDMC 1.2
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: CDMC 1.2
- en: Ensure that the ownership field in a data catalog is populated for sensitive
    data that is migrated to or generated within the cloud, and alert customers with
    a triage workflow if a data asset is created that does not have this field populated.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 确保数据目录中的所有权字段对于迁移到或在云中生成的敏感数据是填充的，并且如果创建了未填充此字段的数据资产，则通过分类工作流通知客户。
- en: CDMC 5.2
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: CDMC 5.2
- en: 'Data quality measurement must be enabled for sensitive data, with metrics distributed
    when available. Data quality metrics will enable data owners and data consumers
    to determine if data is fit for purpose. That information needs to be visible
    to both owners and data consumers:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 必须为敏感数据启用数据质量测量，并在可用时分发度量。数据质量指标将使数据所有者和数据消费者能够确定数据是否合适使用。这些信息需要对所有者和数据消费者可见：
- en: Automatically deliver data quality metrics to data owners and data consumers.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动向数据所有者和数据消费者提供数据质量指标。
- en: Make data quality metrics available in the data catalog.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据目录中提供数据质量指标。
- en: Automatically alert data owners to data quality issues.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动警报数据所有者有关数据质量问题。
- en: CDMC 6.0
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: CDMC 6.0
- en: Data lineage information must be available for all sensitive data. This must
    include, at a minimum, the source from which the data was ingested or in which
    it was created in a cloud environment.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 所有敏感数据必须提供数据血统信息。这至少包括数据在云环境中被摄入的源或创建的源。
- en: It’s difficult to imagine how these assurances could be put in place, at scale,
    without the techniques discussed in this book.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 很难想象如何在规模上实现这些保证，如果没有本书讨论的技术。
- en: Even if there isn’t this level of rigor in most industries today, regulations
    often start out in an isolated context with the most urgent cases and over time
    become a model for others. For instance, at one time, only hospital workers would
    regularly wash their hands, to protect ill patients; gradually, this began to
    include other groups like people who prepared food, and finally, it became common
    practice for everyone. Especially as the use of AI/ML grows, we imagine that data
    quality will only become increasingly regulated as it begins to impact more and
    more of our daily lives.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 即使今天大多数行业中没有这种严格的水平，规定通常从最紧急的情况开始在孤立的背景下开始，并随着时间推移成为其他人的榜样。例如，过去只有医院工作人员经常洗手以保护病人；逐渐地，这开始包括其他群体，如食品准备人员，最终成为每个人的常规做法。特别是随着AI/ML的使用增长，我们想象数据质量将会越来越受到监管，因为它开始影响我们日常生活的更多方面。
- en: AI/ML Risks
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI/ML风险
- en: As discussed in [Chapter 1](ch01.html#the_data_quality_imperative), AI/ML models
    will misbehave when the data that they are trained on doesn’t match the data they
    use to make predictions in production. This can be difficult to debug, especially
    because a data quality issue often doesn’t cause a model to completely break in
    an obvious way, but rather to perform worse for certain segments of users or scenarios.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在[第一章](ch01.html#the_data_quality_imperative)讨论的那样，当AI/ML模型在生产中使用的数据与其训练时的数据不匹配时，它们会表现不良。这很难调试，特别是因为数据质量问题通常不会以明显方式完全破坏模型，而是会使某些用户或场景下的表现变差。
- en: If your organization is building models and, especially, if you’re putting them
    in front of users, you’ve probably already invested significantly in data science,
    data engineering, and MLOps. This investment is at risk without automated data
    quality monitoring as part of your AI/ML stack. To illustrate why, let’s take
    a deeper look at the problems that can happen due to data quality issues during
    model training and inference.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的组织正在构建模型，尤其是如果你将它们放在用户面前，那么你可能已经在数据科学、数据工程和MLOps方面进行了重大投资。如果没有将自动化数据质量监控作为AI/ML堆栈的一部分，这些投资将面临风险。为了说明这一点，让我们深入探讨由于数据质量问题在模型训练和推断期间可能发生的问题。
- en: Feature shocks
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征突发
- en: '[Figure 3-1](#a_feature_shock_in_the_data_for_an_ml_m) shows a feature shock:
    a type of data shock that impacts a feature for an ML model. On a single day,
    the data for this feature has leaped far outside the historical norm. What effect
    will this have on a model?'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3-1](#a_feature_shock_in_the_data_for_an_ml_m)展示了一种特征突发：一种影响ML模型特征的数据冲击。在单一天内，此特征的数据跃出了历史正常范围。这会对模型产生什么影响？'
- en: '![A feature shock in the data for an ML model](assets/adqm_0301.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![ML模型中数据的特征突发](assets/adqm_0301.png)'
- en: Figure 3-1\. A feature shock in the data for an ML model. See a full-sized version
    of this image at [*https://oreil.ly/adqm_3_1*](https://oreil.ly/adqm_3_1).
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1\. ML模型数据中的特征突发。请在[*https://oreil.ly/adqm_3_1*](https://oreil.ly/adqm_3_1)查看此图的完整大小版本。
- en: If used in training data, this shock will cause the feature’s importance to
    be dampened, as the model is led to believe that the feature is less reliable
    for making future predictions. If this kind of shock were to occur in production,
    your results would vary based on the type of model used.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在训练数据中使用，这种突发将导致该特征的重要性减弱，因为模型会认为该特征对未来预测的可靠性较低。如果这种类型的突发发生在生产环境中，你的结果将根据所使用的模型类型而变化。
- en: Linear models, by definition, extrapolate linearly. So, if your feature shock
    is five times the expected value, then that feature will contribute a five times
    greater impact to the resulting score. Tree-based models are generally more resilient.
    A feature shock will tend to push the feature to the extreme end of the distribution.
    The model will then begin interpreting these values as being synonymous with whatever
    population was “normally” in the extreme.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型根据定义进行线性外推。因此，如果你的特征突发是预期值的五倍，那么该特征将对结果分数产生五倍更大的影响。基于树的模型通常更具韧性。特征突发将倾向于将特征推向分布的极端端点。然后，模型将开始解释这些值与“通常”处于极端的任何群体是同义的。
- en: Neural networks behave wildly under feature shocks. They have compounding nonlinearities
    in their architectures that can produce erratic behavior when data moves suddenly
    outside of the typical distribution. It can be almost impossible to predict how
    they will behave.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络在特征突发时表现得非常不稳定。它们在架构中具有复合的非线性特性，当数据突然移动到典型分布之外时，可能会产生异常行为。几乎无法预测它们的行为会是怎样的。
- en: NULL increases
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NULL的增加
- en: A spike in NULL values, in the best case, has the same effect on a model as
    a normal feature shock. But in the worst case, it can impact models in even more
    disastrous ways. If NULLs and zeros are treated the same way by the model, the
    spike could make the model believe there’s been an increase in zero values, which
    may trigger unexpected behavior. Or, if the model aggregates feature values, you
    could end up with a problem where the NULLs compound.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: NULL值的突增，在最好的情况下，对模型的影响与正常的特征突发相同。但在最坏的情况下，它可能以更加灾难性的方式影响模型。如果模型将NULL和零视为相同的方式处理，这种突增可能会使模型认为零值增加了，从而触发意外的行为。或者，如果模型聚合特征值，你可能会遇到NULL值叠加的问题。
- en: Imagine you have a table with orders and items in the order, where a data quality
    issue causes one of every 10 item prices to be NULL. In some platforms, if you
    take the average of the item prices, those NULL values may dominate the aggregation,
    turning the `avg_item_price` field per order to NULL for any order that had more
    than one NULL item in it.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你有一张包含订单和订单中物品的表格，其中一个数据质量问题导致每十个物品价格中就有一个为NULL。在某些平台上，如果计算物品价格的平均值，那些NULL值可能会主导聚合，导致每个订单的`avg_item_price`字段为NULL，如果订单中有多个NULL物品的话。
- en: Change in correlation
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关性的改变
- en: Data quality issues can occasionally change the  way that columns are correlated.
    For example, if there is a failure in how IDs are generated that causes a credit
    score dataset to improperly join to loan applications, then the resulting credit
    scores may be distributionally identical to the correct values, but they will
    not be associated with the correct loans. And so they will no longer correlate
    with other features of the data (age, income, credit history, etc.), and also
    will not correlate with future risk outcomes!
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量问题偶尔可能会改变列之间的相关性。例如，如果生成ID的方式出现故障，导致信用评分数据集错误地与贷款申请关联，那么结果的信用评分可能在分布上与正确值相同，但它们将不再与数据的其他特征（年龄、收入、信用历史等）相关联，也不会与未来的风险结果相关联！
- en: 'When there is a sudden change in correlation, the resulting behavior will depend
    on the type of model:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当相关性突然改变时，结果行为将取决于模型的类型：
- en: Linear models can be very sensitive to the correlations of features, especially
    if they are not well regularized (a technique that prevents individual coefficients
    from being any larger than necessary to fit the data). In these cases, a change
    in correlation can cause a large shift in the model’s predictions.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性模型对特征之间的相关性非常敏感，尤其是如果它们没有很好地进行正则化（一种防止单个系数超过适当数值以适应数据的技术）。在这些情况下，相关性的变化可能导致模型预测出现较大偏移。
- en: Tree-based models are also very sensitive to correlations, as they operate by
    partitioning the data recursively one column at a time. A change in correlation
    will route records down entirely different paths, causing wild swings in the predictions.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于树的模型对相关性也非常敏感，因为它们通过逐列递归地对数据进行分区。相关性的变化将会使记录完全沿不同的路径进行路由，导致预测大幅波动。
- en: Neural networks will behave erratically, just as they will with feature shocks,
    as the distribution of the data suddenly begins arriving in a space (in the multivariate
    sense) where the model was not trained.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络会表现得不稳定，就像在特征突变时一样，因为数据分布突然开始进入一个空间（在多元意义上），而该模型并未经过训练。
- en: Duplicate data
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重复数据
- en: Duplicate records can be a major problem for  data scientists developing models.
    If data is duplicated by mistake while creating a training dataset, the model
    will “overfit” on the duplicated information, falsely believing that it’s overrepresented
    in reality.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 重复记录对于开发模型的数据科学家来说可能是一个主要问题。如果在创建训练数据集时错误地重复了数据，模型将在重复的信息上“过度拟合”，错误地认为它在现实中被过度表达。
- en: In training, an ML model learns to “fit” its parameters to the training dataset.
    However, it can actually do this too well if the model starts to learn the noise
    in the training data. This is called “overfitting.” Achieving strong generalization
    performance (and avoiding both under- and overfitting) is one of the primary concerns
    of data scientists when building machine learning models.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练中，ML模型学习将其参数“拟合”到训练数据集。然而，如果模型开始学习训练数据中的噪声，它可能会做得太好。这称为“过度拟合”。当构建机器学习模型时，数据科学家的主要关注之一是实现强大的泛化性能（避免欠拟合和过度拟合）。
- en: Another place where duplication can cause significant issues is when splitting
    data for testing and training. Duplicated records can easily end up appearing
    in both the training and the test data. This will again enable the model to “overfit”
    the training data—in extreme cases, it can simply memorize the data, as the same
    exact records will appear in the test dataset. The result is the model will appear
    to have much better performance than it really does.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重复可能导致严重问题的地方是在拆分用于测试和训练的数据时。重复的记录很容易同时出现在训练数据和测试数据中。这将再次使模型“过度拟合”训练数据——在极端情况下，它可以简单地记住数据，因为相同的记录将出现在测试数据集中。结果是，模型看起来的表现比实际上好得多。
- en: Data as a Product
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据作为产品
- en: When you sell or package data as your product, then the quality of your data
    is the quality of your product, making data quality monitoring more valuable to
    your business. Some companies directly provide data as a service. For a few examples,
    consider credit aggregators in financial services, MLS data aggregators in real
    estate, public company financial performance data in investing, and competitive
    price data in ecommerce.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将数据作为产品出售或打包时，您的数据质量就是您产品的质量，使数据质量监控对您的业务更有价值。一些公司直接提供数据作为服务。例如，金融服务中的信用聚合器、房地产中的MLS数据聚合器、投资中的上市公司财务表现数据以及电子商务中的竞争价格数据。
- en: In other industries, businesses aren’t necessarily selling data, but their data
    is still an important part of their product offering. Consider how media platforms
    make data available to content creators. These creators need accurate metrics
    like view count and watch time to succeed at their work, which sustains the platform
    itself. If there’s an issue in how this data is reported—maybe a bug causes double
    views to be logged for mobile users—it could cause significant  repercussions
    for the  business.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他行业中，企业并不一定在销售数据，但其数据仍然是产品提供中的重要组成部分。考虑媒体平台如何向内容创建者提供数据。这些创建者需要准确的指标，如观看次数和观看时长，以成功完成他们的工作，从而维护平台本身。如果在报告数据的方式上存在问题——也许是一个错误导致移动用户的双倍浏览被记录——这可能会对业务造成重大影响。
- en: Assessing Your Data Maturity
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估您的数据成熟度
- en: As organizations develop and grow, they tend to move  from an “immature” mode
    of just beginning to collect data, to a “mature” one of building AI and running
    advanced analytics. In her Medium article, our friend and advisor Monica Rogati
    summed this up as the [“Data Science Hierarchy of Needs”](https://oreil.ly/YmIce).
    See [Figure 3-2](#the_data_science_hierarchy_of_needs).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 随着组织的发展和成长，它们往往从“不成熟”的阶段，即刚开始收集数据，转向“成熟”的阶段，即构建人工智能和运行高级分析。在她的Medium文章中，我们的朋友和顾问Monica
    Rogati将此总结为[“数据科学需求层次”](https://oreil.ly/YmIce)。参见[图3-2](#the_data_science_hierarchy_of_needs)。
- en: '![The data science hierarchy of needs](assets/adqm_0302.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![数据科学需求层次](assets/adqm_0302.png)'
- en: Figure 3-2\. The data science hierarchy of needs (from Monica Rogati, “The AI
    Hierarchy of Needs,” [Medium](https://oreil.ly/YmIce), August 1, 2017).
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2。数据科学需求层次（来自Monica Rogati的文章，“AI需求层次”，[Medium](https://oreil.ly/YmIce)，2017年8月1日）。
- en: In the early stages of data maturity, you start with data observability questions,
    ones that can be answered by monitoring table metadata. Did the data get ingested?
    When was it last updated?
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据成熟度的早期阶段，您开始关注数据可观察性的问题，这些问题可以通过监控表格元数据来回答。数据是否已被摄取？最近一次更新是什么时候？
- en: When you continue up the pyramid and hit that middle layer where you start to
    explore and transform data, it’s a good time to think about automating your data
    quality monitoring. At this stage, you’ve likely amassed a good amount of data,
    and you want to create a solid foundation for the next stages of aggregation and
    optimization. These future stages will rely on high-quality data in order to be
    effective.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当您继续向金字塔顶部发展，并达到那个中间层时，在这个阶段，您开始探索和转换数据，现在是考虑自动化数据质量监控的好时机。在这个阶段，您很可能已经积累了大量的数据，并且希望为聚合和优化的下一阶段创建一个坚实的基础。这些未来阶段将依赖于高质量的数据，以提高效率。
- en: Having reached the middle of the data maturity pyramid, businesses often feel
    they are missing the resources (analysts, data engineers, product engineers) to
    *fix* the data quality issues that they might find with more extensive monitoring.
    They thus reach the conclusion that they shouldn’t invest in automated monitoring.
    However, we think this is a mistake. Those data quality issues are almost certainly
    disrupting the people they have today in the work they are doing and are building
    an ever-growing debt that will be very difficult to overcome.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 达到数据成熟度金字塔的中间阶段后，企业通常会感到他们缺少资源（分析师、数据工程师、产品工程师）来*解决*可能通过更广泛的监控发现的数据质量问题。因此，他们得出结论认为不应该投资于自动化监控。然而，我们认为这是一个错误。这些数据质量问题几乎肯定正在干扰他们现有的工作人员，并且正在积累一个越来越难以克服的债务。
- en: Rather than avoiding knowing about the issues (and feeling obligated to fix
    them), you should build the muscle to identify issues and aggressively prioritize
    which ones you invest in fixing. Often, this means starting with a smaller number
    of missing critical tables (like fact tables) and agreeing up-front to criteria
    that must be met to warrant investing in fixes for data quality issues in those
    tables.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 与其避免了解问题（并感到有义务去解决它们），您应该建立能够识别问题并积极优先考虑哪些问题值得投资修复的能力。通常情况下，这意味着从少数关键表（如事实表）中开始，同意前期必须满足的标准，以便在这些表中投资于数据质量问题的修复。
- en: Unsure where you stand in terms of data maturity? Your data stack is a good
    indicator.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定您在数据成熟度方面处于何种位置？您的数据堆栈是一个很好的指标。
- en: When a company hasn’t adopted a cloud data warehouse yet, it often suggests
    that their use of the data they are collecting is still immature, and it’s probably
    too early to invest in automating data quality monitoring. It’s very hard to build
    a robust analytics reporting stack and data-driven team culture on top of production
    data stores or on data at rest in cloud storage.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 当一家公司尚未采用云数据仓库时，通常表明他们对所收集的数据的使用还不成熟，现在自动化数据质量监控可能为时过早。在生产数据存储或云存储中的静止数据上构建强大的分析报告堆栈和数据驱动的团队文化非常困难。
- en: Some companies try to tackle data quality before they have invested in a modern
    cloud data warehouse, but this is typically a mistake.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一些公司在投资现代化云数据仓库之前就试图解决数据质量问题，但这通常是一个错误。
- en: Monitoring data directly in  production databases (Oracle, SQL Server, PostgreSQL,
    etc.) can put heavy analytics loads on stores that were not meant to support these
    kinds of queries at scale, which often ends up affecting production traffic. Sometimes
    companies will try to monitor data quality in data at rest in cloud storage formats
    (Amazon S3, etc.), but without some platform to query this data directly, the
    best you can do is monitor the metadata of the files (size, format, date written,
    etc.). A common compromise is to set up a data lakehouse architecture so that
    data can be monitored on demand via query engines like Presto (or Amazon Athena,
    a hosted version of Presto) or Databricks (via Spark SQL). Data can also be monitored
    from a cloud data warehouse like BigQuery or Snowflake as external tables. However,
    each monitoring run will require reading the entirety of each file (modulo caching),
    so loading this data into a data warehouse can ultimately be much less expensive
    and far more performant.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产数据库（Oracle、SQL Server、PostgreSQL等）直接监控数据，可能会给本不支持此类大规模查询的存储系统带来沉重的分析负载，这往往会影响生产流量。有时公司会尝试在云存储格式中监控数据的数据质量（Amazon
    S3等），但如果没有直接查询这些数据的平台，你能做的最好的只是监控文件的元数据（大小、格式、写入日期等）。一种常见的折中方案是建立数据湖仓架构，以便通过查询引擎如Presto（或其托管版本Amazon
    Athena）或Databricks（通过Spark SQL）按需监控数据。数据也可以从云数据仓库如BigQuery或Snowflake作为外部表进行监控。然而，每次监控运行都需要读取每个文件的全部内容（除非缓存），因此将这些数据加载到数据仓库中最终可能成本更低且性能更好。
- en: Another indicator of data maturity is your organization’s use of tools like
    Airflow, Databricks Workbench, and dbt to transform, aggregate, and enrich data
    in the data warehouse. The presence of these activities often suggests a need
    for data quality, as it introduces more risk of data quality issues being introduced.
    Additionally, these services often want to interact with data quality monitoring
    solutions via APIs in order to trigger data quality checks after data is transformed
    or published or wait to process data downstream if upstream sources are failing
    critical data quality checks.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 数据成熟度的另一个指标是您的组织是否使用像Airflow、Databricks Workbench和dbt这样的工具，在数据仓库中进行转换、聚合和丰富数据。这些活动的存在通常表明需要进行数据质量检查，因为它增加了引入数据质量问题的风险。此外，这些服务通常希望通过API与数据质量监控解决方案交互，以在数据转换或发布后触发数据质量检查，或者在上游数据源未通过关键数据质量检查时等待处理下游数据。
- en: Finally, a last indicator of maturity is whether your company has standardized
    on a data catalog. Data catalogs are useful when you have many stakeholders accessing
    a wide range of data; they help with identifying what data is most important.
    This is usually the data that should be monitored most closely for data quality.
    There’s a synergy here, as well, because the results of data quality monitoring
    can be replicated to the data catalog and shown to users to help them understand
    if the data is well tested and of high quality.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，成熟度的最后一个指标是您的公司是否已经在数据目录上进行了标准化。当您有许多利益相关者访问广泛的数据时，数据目录非常有用；它们有助于识别哪些数据最重要。通常应该密切监控数据质量的就是这些数据。这里还存在一种协同效应，因为数据质量监控的结果可以复制到数据目录，并向用户展示，帮助他们了解数据是否经过了充分测试并且质量高。
- en: Assessing Benefits to Stakeholders
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估对利益相关者的益处
- en: As an organization moves up the pyramid of data needs, it tends to acquire a
    larger data team that demands more from a data quality monitoring solution.  For
    example, a team of mostly engineers might be able to get away with just an API
    to monitor data quality, but as the number of nontechnical users grows, having
    a user interface to explore the data and communicate richer insights about discovered
    quality issues becomes increasingly valuable.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 随着组织在数据需求金字塔上的提升，它往往会拥有一个更大的数据团队，对数据质量监控解决方案的要求也更高。例如，大部分工程师组成的团队可能仅需一个API来监控数据质量，但随着非技术用户数量的增加，拥有一个用户界面来探索数据并传达关于发现的质量问题的更丰富见解变得越来越有价值。
- en: When determining if automated data quality monitoring is right for you, there’s
    no better starting point than talking to your stakeholders directly. In the next
    sections, you’ll find descriptions of how many roles in an organization can benefit
    from an automated solution and the types of features that are likely to be of
    interest to them.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 当确定自动化数据质量监控是否适合您时，最好的起点是直接与您的利益相关者进行沟通。在接下来的几节中，您将找到组织中许多角色如何从自动化解决方案中受益以及他们可能感兴趣的功能类型的描述。
- en: Engineers
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工程师
- en: These are data engineers, analytics engineers, or members of the data platform
    team. They’re in charge of managing platforms, ETL pipelines, and updating how
    data is tracked and stored. The kinds of data issues they care most about have
    to do with the freshness and volume of data in movement, and the reconciliation
    of data across different sources.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是数据工程师、分析工程师或数据平台团队成员。他们负责管理平台、ETL管道，并更新数据的跟踪和存储方式。他们最关心的数据问题与数据流动的新鲜度和量、以及不同来源数据的对账有关。
- en: 'It’s likely a team of engineers will be tasked with the technical implementation
    of a data quality monitoring platform. As such, they’ll want something that’s
    easy to configure, as automated as possible, and simple to integrate with other
    parts of your stack. Engineers tend to want a robust API that allows for one or
    more of the following options:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能一个工程团队将被指定负责数据质量监控平台的技术实施。因此，他们希望能够轻松配置、尽可能自动化，并且与堆栈的其他部分简单集成。工程师们通常希望有一个强大的API，允许使用以下一个或多个选项：
- en: Interacting with the API directly via code. This could be calling the endpoints
    directly, or via a Python package. This is the most flexible way of interacting
    with APIs, but not always the easiest.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接通过代码与API进行交互。这可以是直接调用端点，或者通过Python包。这是与API交互最灵活的方式，但不一定是最简单的方式。
- en: Using packages in orchestration platforms like Airflow and Databricks Workbench.
    These consolidate features in the underlying API and directly integrate them into
    the orchestration platform. Here’s an example of the [Anomalo Airflow operator](https://oreil.ly/R7P36).
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在像Airflow和Databricks Workbench这样的编排平台中使用包。这些平台将基础API中的功能整合，并直接集成到编排平台中。这里是[Anomalo
    Airflow操作员](https://oreil.ly/R7P36)的一个示例。
- en: Interacting with configuration files  (e.g., YAML, JSON) that are managed in
    a code versioning system (like Git) and are synchronized with the monitoring platform
    via API. This allows changes in configuration to be managed as code but isn’t
    as flexible as calling the API directly.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与在代码版本控制系统（如Git）中管理的配置文件（例如YAML、JSON）进行交互，并通过API与监控平台同步。这允许配置更改作为代码管理，但不如直接调用API灵活。
- en: Data Leadership
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据领导
- en: Managers of data teams typically want high-level analytics to be able to track
    the health of data quality as a whole, how it’s trending over time, and how users
    are engaging in the platform.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 数据团队经理通常希望通过高级分析来追踪整体数据质量的健康状况、其随时间的趋势以及用户如何参与平台。
- en: 'Typical KPIs of interest to managers are:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 经理们通常感兴趣的典型KPI包括：
- en: Data quality coverage
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量覆盖范围
- en: How many tables have checks defined? How are those checks performing? With a
    high-level view of coverage, leaders can pinpoint blind spots.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 有多少表格定义了检查？这些检查的执行情况如何？领导者可以通过高层次的覆盖视图精确定位盲点。
- en: Data arrival times
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 数据到达时间
- en: Leadership needs to be able to identify tables whose data doesn’t arrive on
    time or meet SLAs.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 领导层需要能够识别表格的数据是否按时到达或符合SLA。
- en: Data quality trends
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量趋势
- en: A snapshot statistic is not enough to track data quality. It’s essential that
    managers can track improvements over time with time series views and week-over-week
    changes.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 快照统计数据并不足以追踪数据质量。管理者必须能够通过时间序列视图和周对周的变化追踪随时间的改进。
- en: Repeat offenders
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 多次违规
- en: It’s helpful if managers can get a list of tables that are the most problematic,
    or checks that fail the most often, to prioritize their next data quality initiatives.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如果经理能够获得最有问题的表格列表或最常失败的检查以优先考虑他们的下一个数据质量倡议，这将非常有帮助。
- en: For examples of how a data quality monitoring solution can provide tools for
    data leadership, see Figures [3-3](#anomaloapostrophes_pulse_dashboard_give) and
    [3-4](#clicking_on_any_of_the_statistics_provi).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解数据质量监控解决方案如何为数据领导提供工具示例，请参见[图 3-3](#anomaloapostrophes_pulse_dashboard_give)和[图
    3-4](#clicking_on_any_of_the_statistics_provi)。
- en: '![Anomalo’s Pulse dashboard gives high-level statistics on data quality at
    an organization](assets/adqm_0303.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![Anomalo 的 Pulse 仪表板提供组织的数据质量高级统计信息](assets/adqm_0303.png)'
- en: Figure 3-3\. Anomalo’s Pulse dashboard gives high-level statistics on data quality
    at an organization.
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. Anomalo 的 Pulse 仪表板提供组织的数据质量高级统计信息。
- en: '![Clicking on any of the statistics provides trends in the data over time and
    identifies tables that are repeat offenders](assets/adqm_0304.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![点击任何统计数据可提供数据随时间的趋势并识别重复出现的表格](assets/adqm_0304.png)'
- en: Figure 3-4\. Clicking on any of the statistics provides trends in the data over
    time and identifies tables that are repeat offenders. See a full-sized version
    of this image at [*https://oreil.ly/adqm_3_4*](https://oreil.ly/adqm_3_4).
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. 点击任何统计数据可提供数据随时间的趋势，并识别重复出现的表格。在[*https://oreil.ly/adqm_3_4*](https://oreil.ly/adqm_3_4)查看此图的完整版本。
- en: Scientists
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 科学家
- en: These are data analysts, data scientists, and members of the ML platform team
    who are involved in building data products and generating insights. They’re typically
    interested in monitoring for missing data, duplicates, and distribution changes.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是数据分析师、数据科学家和 ML 平台团队的成员，他们参与构建数据产品和生成见解。他们通常对监控缺失数据、重复数据和分布变化感兴趣。
- en: Unlike engineers, this group tends to prefer working with an easy-to-use UI,
    not an API. One way that automated data quality monitoring solutions can empower
    scientists is by offering them rich visualizations to explore data and determine
    the root cause of issues.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 与工程师不同，这个群体倾向于使用易于使用的用户界面而不是 API。自动化数据质量监控解决方案可以赋予科学家权力的一种方式是为他们提供丰富的可视化工具来探索数据并确定问题的根本原因。
- en: Consumers
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 消费者
- en: This category encompasses everyone else who relies on the data products built
    by engineers and scientists to make decisions—such as product teams, operations,
    marketing, and compliance. These are often the deepest SMEs in the domains that
    the data is collected about and, as such, have a strong role to play in directing
    data quality monitoring and in triaging issues.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 此类别包括所有依赖工程师和科学家构建的数据产品做出决策的其他人，如产品团队、运营、市场营销和合规性。这些通常是关于收集数据领域的最深的主题专家，并因此在指导数据质量监控和处理问题方面发挥重要作用。
- en: To build trust in the data and avoid a proliferation of disparate tools, the
    monitoring solution should provide this group with a single source of truth about
    data quality. Consumers are unlikely to be involved in issue resolution; rather,
    they should be made aware of data quality issues that might impact their work
    through notifications. These notifications should be clear, easy to understand,
    and delivered with the right level of urgency.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 为了建立对数据的信任并避免分散工具的大量使用，监控解决方案应为该组提供关于数据质量的单一真实来源。消费者不太可能参与问题解决，而应通过通知了解可能影响其工作的数据质量问题。这些通知应该清晰、易于理解，并以正确的紧急程度交付。
- en: Conducting an ROI Analysis
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行 ROI 分析
- en: After assessing the four key factors  discussed—your data, your industry, your
    data maturity, and your stakeholders—you might decide that automating data quality
    monitoring seems like a good idea. In that case, you’ll want to convince yourself
    and others by running an assessment of the likely ROI. Such an analysis should
    account for both quantitative and qualitative metrics.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估所讨论的四个关键因素——您的数据、您的行业、您的数据成熟度和您的利益相关者之后，您可能会决定自动化数据质量监控似乎是个好主意。在这种情况下，您需要通过运行可能的
    ROI 评估来说服自己和其他人。这种分析应考虑定量和定性指标。
- en: For more details on conducting an ROI analysis beyond what’s in this chapter,
    interested readers may want to review the [case study](https://oreil.ly/_K7lj)
    by Prakash Jaganathan, Senior Director of Enterprise Data Platforms at Discover
    Financial Services. Discover’s large suite of digital banking and payment services
    products is supported by hundreds of software applications that produce and persist
    petabytes of data. The case study tells the story of why, to innovate and excel
    in data quality, Discover addressed the fundamental challenges with traditional,
    deterministic data quality monitoring by subscribing to an automated data quality
    monitoring platform powered by machine learning.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对于在本章之外进行 ROI 分析的更多细节，有兴趣的读者可能希望查阅[案例研究](https://oreil.ly/_K7lj)，作者是 Discover
    Financial Services 的企业数据平台高级总监 Prakash Jaganathan。Discover 的大量数字银行和支付服务产品由数百个软件应用程序支持，并持续产生和存储
    petabytes 的数据。该案例研究讲述了为何 Discover 通过订阅机器学习驱动的自动化数据质量监控平台，解决了传统确定性数据质量监控所面临的根本性挑战，以创新和卓越数据质量。
- en: Quantitative Measures
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定量测量
- en: 'You can start an ROI analysis by looking at the frequency of data quality issues
    in your business. How often are they happening on a per-table basis? How much
    does each incident typically cost: in business interruption, investigation and
    resolution time, and other adverse customer or operational impacts? For every
    data quality issue you are aware of, how many are going *undetected* and yet still
    having an adverse impact on your operations?'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始 ROI 分析，可以先看看业务中数据质量问题的频率。每个表发生这些问题的频率如何？每个事件通常造成多少成本：包括业务中断、调查和解决时间，以及其他对客户或运营的不利影响？对于你知道的每个数据质量问题，还有多少是*未被发现*但仍然对你的运营造成了不利影响？
- en: Once you estimate this figure, you can multiply it by the expected number of
    issues per table per year, and the number of tables that are important to monitor.
    You can justify an automated data quality monitoring solution if its total cost
    can reduce the number and severity of these incidents, and their resulting cost.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你估计出这个数字，你可以将其乘以每年每个表预期的问题数量，以及需要监控的重要表的数量。如果自动化数据质量监控解决方案的总成本能够减少这些事件的数量和严重程度，以及其产生的成本，那么你就可以证明其是合理的。
- en: 'In addition, look at the hours your team has spent on data quality–related
    tasks, and the amount you predict this would go down by automating data quality
    monitoring. Typical tasks include:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，看看你的团队在与数据质量相关任务上花费的时间，以及预计通过自动化数据质量监控来减少这些时间。典型任务包括：
- en: Creation and maintenance of automated data checks
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和维护自动化数据检查
- en: Setting up notifications and alerting
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置通知和警报
- en: Investigation, exploration, and root cause analysis
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调查、探索和根本原因分析
- en: Monitoring key metrics over time
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长期监控关键指标
- en: If you have historical statistics on these tasks, then you can calculate the
    likely number of hours you’ll save by implementing automated data quality monitoring.
    These are hours that can give back to your team in terms of time and talent devoted
    to other projects. It’s best if you can run a trial with a vendor to see, for
    example, how long it takes you to set up monitoring on the tables you care about.
    If you’re building in-house, it can be difficult to get clear numbers ahead of
    time, but you can set a target that would make the investment worth it and keep
    that in mind as you build a proof of concept.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有这些任务的历史统计数据，那么你可以计算通过实施自动化数据质量监控预计能够节省的小时数。这些小时可以作为时间和人才投入到其他项目中的回报。最好是能够与供应商进行试验，看看例如你在关心的表上设置监控需要多长时间。如果是内部建设，提前获得清晰的数字可能会有困难，但你可以设定一个目标，使投资变得值得，并在构建概念验证时记住这一点。
- en: 'When speaking with customers, we’re often asked to help estimate the total
    hours to configure tables for monitoring and triage alerts so that they can weigh
    this time against what they’re spending today on data quality. It’s useful to
    keep in mind that with an efficient monitoring platform, most of the data quality
    effort will be focused on a relatively small subset of important tables. In a
    data warehouse with 20,000 tables, we typically see a breakdown like the one in
    [Table 3-2](#monitoring_tables_in_a_data_warehouse):'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在与客户交谈时，我们经常被要求帮助估算配置监控表和分类警报所需的总小时数，以便他们将此时间与今天在数据质量上的支出进行比较。要记住，通过高效的监控平台，大部分数据质量工作将集中在相对较少的重要表上。在一个有
    20,000 张表的数据仓库中，我们通常会看到如[表格 3-2](#monitoring_tables_in_a_data_warehouse)中所示的分布：
- en: 10,000 of the tables (50%) simply aren’t interesting to monitor at all. Usually,
    these are temporary, intermediate, or one-off tables that may be deleted in the
    future.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 10,000个表格（50%）根本就不值得监控。通常这些是临时的、中间的或一次性的表格，可能会在未来被删除。
- en: 9,000 tables are used in processing and should be monitored for data freshness
    and volume using metadata. We refer to this as table observability, and it has
    the advantage of being much cheaper than running ML models across the entire warehouse
    while providing a baseline level of data quality monitoring.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 9,000个表格用于处理，并应使用元数据监控数据新鲜度和数据量。我们称之为表格可观察性，它比在整个仓库上运行ML模型要便宜得多，同时提供基线水平的数据质量监控。
- en: There are 900 important team-specific tables where, in addition to table observability,
    the business wants deep data quality monitoring using automated ML models.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还有900个重要的团队特定表格，除了表格可观察性外，业务还希望使用自动化ML模型进行深入的数据质量监控。
- en: On 90 key tables, they also want to set up validation rules and metrics to monitor
    for some unexpected changes.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在90个关键表格上，他们还希望设置验证规则和指标，以监控一些意外变化。
- en: There may be 10 critical tables that, on top of all the other monitoring, must
    have many validation rules for record-level quality. These tend to be the essential
    fact tables for the business.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另外还可能有10个关键表格，除了所有其他的监控外，还必须具有多个记录级质量验证规则。这些往往是业务上至关重要的事实表。
- en: Table 3-2\. Monitoring tables in a data warehouse
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-2. 数据仓库中的监控表格
- en: '| Type | Tables | Percent of total | Use | Configuration | Monitoring strategy
    | Hours to configure per table | Total hours to configure | Alert frequency per
    table | Total alerts per week | Triage minutes per alert | Triage hours per year
    |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 表格 | 占比 | 用途 | 配置 | 监控策略 | 配置每表小时数 | 总配置小时数 | 每表警报频率 | 每周总警报数 | 每警报处理时间（分钟）
    | 每年处理时间（小时） |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| Temporary | 10,000 | 50% | Staging, testing, or experimentation | No monitoring
    |   | 0 | 0 | Never | 0 | 0 | 0 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 临时 | 10,000 | 50% | 分阶段、测试或实验中 | 无监控 |   | 0 | 0 | 从不 | 0 | 0 | 0 |'
- en: '| Processing | 9,000 | 45% | Production pipelines to producing important datasets
    | Table observability | Automatically detect schema, freshness, and volume issues
    | 0.01 | 90 | 0.5× per year | 87 | 5 | 375 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 处理 | 9,000 | 45% | 用于生成重要数据集的生产管道 | 表格可观察性 | 自动检测架构、新鲜度和数据量问题 | 0.01 | 90
    | 每年0.5次 | 87 | 5 | 375 |'
- en: '| Important | 900 | 5% | Raw data and team-specific datasets | Data quality
    | + automatically detect missing, bad, duplicate, or anomalous data | 0.2 | 180
    | 1× per quarter | 69 | 20 | 1,200 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 重要 | 900 | 5% | 原始数据和团队特定数据集 | 数据质量 | + 自动检测缺失、错误、重复或异常数据 | 0.2 | 180 | 每季度1次
    | 69 | 20 | 1,200 |'
- en: '| Key | 90 | 0.5% | Fact and aggregate tables powering data products and decisions
    | Data quality | + monitor metrics and/or segments for unexpected changes | 8
    | 720 | 1× per month | 21 | 60 | 1,080 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 关键 | 90 | 0.5% | 驱动数据产品和决策的事实和聚合表 | 数据质量 | + 监控指标和/或段以发现意外变化 | 8 | 720 |
    每月1次 | 21 | 60 | 1,080 |'
- en: '| Critical | 10 | 0.1% | Critical data elements and executive level monitoring
    | Data quality | + enforce validation rules for record-level quality | 40 | 400
    | 1× per week | 10 | 60 | 520 |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 关键 | 10 | 0.1% | 关键数据元素和执行级别监控 | 数据质量 | + 强制记录级别质量的验证规则 | 40 | 400 | 每周1次
    | 10 | 60 | 520 |'
- en: '| Total | 20,000 | 100% |   |   |   |   | 1,390 |   |   |   | 3,175 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 20,000 | 100% |   |   |   |   | 1,390 |   |   |   | 3,175 |'
- en: You’ll also want to weigh the setup and operating costs of your solution, such
    as licensing, infrastructure, and computation. Note that an additional consideration
    for these costs may be how predictable the spend (and therefore your budget) will
    be.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应该权衡解决方案的设置和运行成本，如许可证、基础设施和计算。请注意，这些成本的额外考虑因素可能是支出（因此也是您预算）的可预测性如何。
- en: Qualitative Measures
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定性措施
- en: 'Some of the qualitative benefits of automating data quality monitoring are:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化数据质量监控的一些定性好处包括：
- en: Speeding up development cycles because you can catch production issues sooner
    after feature release
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加快开发周期，因为您可以在功能发布后更快地捕捉生产问题。
- en: Improving confidence with partners due to high test coverage, fewer errors,
    and faster response times
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于高测试覆盖率、更少错误和更快的响应时间，与合作伙伴的信心提高
- en: Having an “audit trail” where you can document historical data checks and past
    performance of the data
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有“审计追踪”，您可以记录历史数据检查和数据的过去性能
- en: Democratizing data quality and improving collaboration and ownership, thus increasing
    employee productivity and satisfaction
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 民主化数据质量并提高协作和所有权，从而提高员工的生产力和满意度
- en: Improving the trust in your data and therefore the ROI of other data-related
    efforts
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提升数据的信任度，从而提高其他数据相关工作的投资回报率。
- en: 'Qualitative disadvantages of automating data quality monitoring can include:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化数据质量监控的定性缺点可能包括：
- en: Resistance to change; employees must acquire new skills
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对变革的抵制；员工必须掌握新的技能。
- en: Needing to develop new training and onboarding resources
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要开发新的培训和入职资源。
- en: Potential security risks; for example, if you use a SaaS solution that isn’t
    deployed in a virtual private cloud (VPC)
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 潜在的安全风险；例如，如果您使用的SaaS解决方案没有部署在虚拟私有云（VPC）中。
- en: (If you build in-house) Needing to maintain your solution over time and bear
    responsibility for outages
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （如果您在内部建设）需要随时间维护您的解决方案并承担故障的责任
- en: The risk of false positive or information-poor notifications causing alert fatigue
    (On the other hand, alerts can come with rich context and visualizations that
    characterize the issue, identify the root cause, and help the user understand
    the potential severity of the issue. A UI can also provide the means to triage
    and resolve issues. All of these conveniences go a long way toward reducing alert
    fatigue.)
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在假阳性或信息贫乏通知引起的警报疲劳的风险（另一方面，警报可以带有丰富的上下文和可视化，描述问题特征，识别根本原因，并帮助用户了解问题可能的严重性。用户界面还可以提供分类和解决问题的手段。所有这些便利措施在很大程度上有助于减少警报疲劳。）
- en: Ultimately, we see data leaders contemplate the value of improving data quality
    as a multiplier for the ROI of their entire data budget (technology and people).
    For example, consider an organization that is spending $30M per year on data technology
    and $70M per year on data professionals (fully loaded compensation). The organization
    is investing this $100M per year with an expectation of generating a significant
    return. For simplicity, let’s suppose that is a 20% expected return. Then the
    value they expect to generate per year is $120M, through improved human decision
    making, improved operations and better customer experiences powered by ML and
    AI, and new data products that may be monetized directly.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们看到数据领导者将提高数据质量的价值视为其整个数据预算（技术和人员）投资回报率的乘数。例如，考虑一个每年在数据技术上花费3000万美元，数据专业人员（全面的薪酬）每年花费7000万美元的组织。该组织投资这10000万美元的预期回报率为20%。然后，他们每年预期生成的价值为1.2亿美元，通过改善人类决策，通过ML和AI提供更好的运营和更好的客户体验，以及可以直接货币化的新数据产品。
- en: If data quality could be significantly improved, then it could be reasonable
    to expect that value to increase by as much as 10%. This could happen because
    less time is wasted chasing down data quality issues, and so the people investment
    is more productive. Or it could happen because the quality of the decisions and
    ML models are higher, which directly translates into higher ROI.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据质量能够显著提高，那么预期价值的增加可能会达到高达10%。这可能发生在因为减少了追踪数据质量问题而浪费的时间，因此人力投入更具生产力，或者因为决策和机器学习模型的质量更高，直接转化为更高的投资回报率。
- en: The net effect would mean that the organization would generate $132M of value,
    for an additional $12M of value per year due to higher data quality.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的效果将意味着该组织将创造价值1.32亿美元，每年因更高的数据质量而增加1,200万美元的价值。
- en: In practice, while conducting rigorous ROI analyses may be necessary in some
    cases (especially to convince your finance or procurement functions of the need
    to invest in data quality), many of the large enterprises we work with don’t even
    bother. The case for improving data quality can be so obvious and compelling that
    the question is less about ROI and more about speed.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，虽然在某些情况下进行严格的投资回报率分析可能是必要的（尤其是为了说服您的财务或采购部门需要投资于数据质量），但我们与许多大型企业合作时，很少有企业会费心进行此类分析。改善数据质量的理由可能是如此明显和强有力，以至于问题更少关于投资回报率，而更多关于速度。
- en: Conclusion
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: To automate data quality monitoring at scale, you’ll need to make a number of
    trade-offs. You’ll need to invest in new technologies, introduce new processes,
    and commit to fixing new data quality issues you uncover.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现规模化的数据质量监控自动化，您需要进行多项权衡。您需要投资新技术，引入新流程，并承诺解决您发现的新数据质量问题。
- en: We’ve built an automated data quality monitoring platform because we believe
    these trade-offs are valuable for many companies. Along the way, we’ve had many
    interactions with enterprises and teams that are excited about this solution.
    But we’ve also learned about the situations where the time wasn’t right, or the
    fit wasn’t there. In this chapter, we’ve tried to offer the complete picture of
    why you might benefit from automating data quality monitoring and, on the other
    hand, why it might not be the solution for you.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建立了一个自动化数据质量监控平台，因为我们相信这些权衡对许多公司都是有价值的。沿途中，我们与许多对这一解决方案感到兴奋的企业和团队进行了多次互动。但我们也了解到了时间不合适或者适配不对的情况。在本章中，我们尝试全面阐述为何您可能从自动化数据质量监控中受益，另一方面，它可能不适合您的解决方案。
- en: Excited about the ROI of an automated data quality monitoring platform? In the
    next few chapters, we’ll provide the detailed guidance you need to take the next
    steps. From different modeling techniques and considerations to how you can deliver
    high-quality notifications, the most technical topics in the book are coming up
    next. Get out your notebooks, especially your data science notebooks, because
    it’s time to dive into the implementation details.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 对于自动化数据质量监控平台的投资回报率感到兴奋吗？在接下来的几章中，我们将提供您所需的详细指导，帮助您迈出下一步。从不同的建模技术和考虑因素到如何提供高质量通知，本书中最技术性的主题即将登场。拿出您的笔记本，特别是您的数据科学笔记本，因为现在是深入实施细节的时候了。
- en: ^([1](ch03.html#ch01fn2-marker)) Rishi Bommasani et al., “On the Opportunities
    and Risks of Foundation Models,” July 12, 2022 https://arxiv.org/abs/2108.07258v3.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch03.html#ch01fn2-marker)) Rishi Bommasani 等人，“基础模型的机遇与风险”，2022年7月12日，https://arxiv.org/abs/2108.07258v3。
