- en: Chapter 9\. Unsupervised methods
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章\. 无监督方法
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Using R’s clustering functions to explore data and look for similarities
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R的聚类函数探索数据和寻找相似性
- en: Choosing the right number of clusters
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择合适的聚类数量
- en: Evaluating a cluster
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估一个聚类
- en: Using R’s association rules functions to find patterns of co-occurrence in data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用R的关联规则函数来发现数据中的共现模式
- en: Evaluating a set of association rules
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估一组关联规则
- en: In the previous chapter, we covered using the `vtreat` package to prepare messy
    real-world data for modeling. In this chapter, we’ll look at methods to discover
    unknown relationships in data. These methods are called *unsupervised methods*.
    With unsupervised methods, there’s no outcome that you’re trying to predict; instead,
    you want to discover patterns in the data that perhaps you hadn’t previously suspected.
    For example, you may want to find groups of customers with similar purchase patterns,
    or correlations between population movement and socioeconomic factors. We will
    still consider this pattern discovery to be “modeling,” and as such, the outcomes
    of the algorithms can still be evaluated, as shown in the mental model for this
    chapter ([figure 9.1](../Text/09.xhtml#ch09fig01)).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了使用`vtreat`包来准备用于建模的杂乱的真实世界数据。在本章中，我们将探讨发现数据中未知关系的方法。这些方法被称为*无监督方法*。使用无监督方法时，没有你试图预测的结果；相反，你希望发现数据中的模式，这些模式可能是你之前未曾怀疑的。例如，你可能希望找到具有相似购买模式的客户群体，或者人口流动与社会经济因素之间的相关性。我们仍将这种模式发现视为“建模”，因此算法的结果仍然可以评估，如本章的心理模型所示（[图9.1](../Text/09.xhtml#ch09fig01)）。
- en: Figure 9.1\. Mental model
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1\. 心理模型
- en: '![](Images/09fig01.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/09fig01.jpg)'
- en: Unsupervised analyses are often not ends in themselves; rather, they’re ways
    of finding relationships and patterns that can be used to build predictive models.
    In fact, we encourage you to think of unsupervised methods as exploratory—procedures
    that help you get your hands in the data—rather than as black-box approaches that
    mysteriously and automatically give you “the right answer.”
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督分析通常不是目的本身；相反，它们是寻找可以用于构建预测模型的关系和模式的方法。事实上，我们鼓励您将无监督方法视为探索性的——帮助您接触数据的程序——而不是神秘且自动给出“正确答案”的黑盒方法。
- en: 'In this chapter, we’ll look at two classes of unsupervised methods:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨两类无监督方法：
- en: '*Cluster analysis* finds groups with similar characteristics.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*聚类分析*寻找具有相似特性的群体。'
- en: '*Association rule mining* finds elements or properties in the data that tend
    to occur together.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*关联规则挖掘*寻找数据中倾向于一起出现的元素或属性。'
- en: 9.1\. Cluster analysis
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1\. 聚类分析
- en: 'In cluster analysis, the goal is to group the observations in your data into
    *clusters* such that every datum in a cluster is more similar to other datums
    in the same cluster than it is to datums in other clusters. For example, a company
    that offers guided tours might want to cluster its clients by behavior and tastes:
    which countries they like to visit; whether they prefer adventure tours, luxury
    tours, or educational tours; what kinds of activities they participate in; and
    what sorts of sites they like to visit. Such information can help the company
    design attractive travel packages and target the appropriate segments of their
    client base with them.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在聚类分析中，目标是把你的数据中的观测值分组到*聚类*中，使得每个聚类中的数据点与其他聚类中的数据点相比，更相似。例如，一家提供导游服务的公司可能希望根据行为和口味对其客户进行聚类：他们喜欢访问哪些国家；他们是否更喜欢冒险之旅、奢华之旅还是教育之旅；他们参加的活动类型；以及他们喜欢访问的场所类型。此类信息可以帮助公司设计吸引人的旅游套餐，并针对客户群中的适当细分市场进行定位。
- en: Cluster analysis is a topic worthy of a book in itself; in this chapter, we’ll
    discuss two approaches. *Hierarchical clustering* finds nested groups of clusters.
    An example of hierarchical clustering might be the standard plant taxonomy, which
    classifies plants by family, then genus, then species, and so on. The second approach
    we’ll cover is *k-means*, which is a quick and popular way of finding clusters
    in quantitative data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类分析是一个值得单独成书的话题；在本章中，我们将讨论两种方法。*层次聚类*找到嵌套的聚类群体。层次聚类的例子可能是标准的植物分类学，它按家族、属、种等分类植物。我们将探讨的第二种方法是*k-means*，这是一种快速且流行的在定量数据中寻找聚类的方法。
- en: '* * *'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Clustering and density estimation**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类和密度估计**'
- en: 'Historically, cluster analysis is related to the problem of *density estimation*:
    if you think of your data as living in a large dimensional space, then you want
    to find the regions of the space where the data is densest. If those regions are
    distinct, or nearly so, then you have clusters.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从历史上看，聚类分析与密度估计问题相关：如果你认为你的数据存在于一个高维空间中，那么你想要找到数据最密集的区域。如果这些区域是不同的，或者几乎是不同的，那么你就有了聚类。
- en: '* * *'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 9.1.1\. Distances
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1\. 距离
- en: In order to cluster, you need the notions of *similarity* and *dissimilarity*.
    Dissimilarity can be thought of as distance, so that the points in a cluster are
    closer to each other than they are to the points in other clusters. This is shown
    in [figure 9.2](../Text/09.xhtml#ch09fig02).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行聚类，你需要相似性和不相似性的概念。不相似性可以被视为距离，这样聚类中的点比其他聚类中的点更接近。这如图 [9.2](../Text/09.xhtml#ch09fig02)
    所示。
- en: Figure 9.2\. An example of data in three clusters
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2\. 三簇数据的示例
- en: '![](Images/09fig02_alt.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig02_alt.jpg)'
- en: 'Different application areas will have different notions of distance and dissimilarity.
    In this section, we’ll cover a few of the most common ones:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的应用领域会有不同的距离和相似度概念。在本节中，我们将介绍其中的一些最常见概念：
- en: Euclidean distance
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欧几里得距离
- en: Hamming distance
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 汉明距离
- en: Manhattan (city block) distance
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曼哈顿（城市街区）距离
- en: Cosine similarity
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 余弦相似度
- en: Euclidean distance
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离
- en: '* * *'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*Suppose you have measurements on how many minutes per day subjects spend on
    different activities, and you want to group the subjects by their activity patterns.*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设你测量了每天主体在不同活动上花费的分钟数，并且你想根据他们的活动模式对主体进行分组。*'
- en: '* * *'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Since your measurements are numerical and continuous, *Euclidean distance* is
    a good distance to use for clustering. Euclidean distance is the measure people
    tend to think of when they think of “distance.” Optimizing squared Euclidean distance
    is the basis of k-means. Of course, Euclidean distance only makes sense when all
    the data is real-valued (quantitative). If the data is categorical (in particular,
    binary), then other distances should be used.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你的测量是数值和连续的，*欧几里得距离* 是用于聚类的良好选择。人们通常在想到“距离”时想到的就是欧几里得距离。优化平方欧几里得距离是 k-means
    的基础。当然，欧几里得距离只有在所有数据都是实值（定量）时才有意义。如果数据是分类的（特别是二元的），则应使用其他距离。
- en: The Euclidean distance between two vectors `x` and `y` is defined as
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量 `x` 和 `y` 之间的欧几里得距离定义为
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Hamming distance
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 汉明距离
- en: '* * *'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*Suppose you want to group your recipe box into groups of similar recipes.
    One way to do that is to measure the similarity of their ingredients lists.*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设你想要将你的食谱盒分组为相似食谱的组。一种方法是测量它们的成分列表的相似度。*'
- en: '* * *'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: By this measure, pancakes, waffles, and crepes are highly similar (they have
    almost identical ingredients, and vary only in proportions); they all differ somewhat
    from cornbread (which uses cornmeal, rather than flour); and they all differ to
    a greater degree from mashed potatoes.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个度量，煎饼、华夫饼和可丽饼非常相似（它们的成分几乎相同，只是比例不同）；它们都与玉米面包（使用玉米粉而不是面粉）有所不同；并且它们与土豆泥的差异更大。
- en: 'For categorical variables like recipe ingredients, gender (`male`/`female`),
    or qualitative size (`small`/`medium`/`large`), you can define the distance as
    `0` if two points are in the same category, and `1` otherwise. If all the variables
    are categorical, then you can use *Hamming distance*, which counts the number
    of mismatches:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像食谱成分、性别（`男性`/`女性`）或定性大小（`小`/`中`/`大`）这样的分类变量，你可以定义当两个点属于同一类别时距离为 `0`，否则为 `1`。如果所有变量都是分类的，则可以使用
    *汉明距离*，它计算不匹配的数量：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, `a != b` is defined to have a value of `1` if the expression is true,
    and a value of `0` if the expression is false.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`a != b` 被定义为当表达式为真时取值为 `1`，当表达式为假时取值为 `0`。
- en: You can also expand categorical variables to indicator variables (as we discussed
    in [section 7.1.4](../Text/07.xhtml#ch07lev2sec4)), one for each level of the
    variable.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将分类变量扩展为指示变量（如我们在 [7.1.4 节](../Text/07.xhtml#ch07lev2sec4) 中讨论的），每个变量一个。
- en: If the categories are ordered (like `small`/`medium`/`large`) so that some categories
    are “closer” to each other than others, then you can convert them to a numerical
    sequence. For example, (`small`/`medium`/`large`) might map to (`1`/`2`/`3`).
    Then you can use Euclidean distance or other distances for quantitative data.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果类别是有序的（如`小`/`中`/`大`），使得某些类别比其他类别“更接近”，那么您可以将其转换为数值序列。例如，（`小`/`中`/`大`）可能映射到（`1`/`2`/`3`）。然后您可以使用欧几里得距离或其他距离来处理定量数据。
- en: Manhattan (city block) distance
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 曼哈顿（城市街区）距离
- en: '* * *'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*Suppose you run a delivery service that caters to downtown businesses. You
    want to cluster your clients so that you can place pickup/drop-off boxes that
    are centrally located in each cluster.*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设您经营一家为市中心企业提供服务的快递公司。您想要将客户聚类，以便在每个聚类中放置位于中心位置的取件/投递箱。*'
- en: '* * *'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Manhattan distance measures distance in the number of horizontal and vertical
    units it takes to get from one (real-valued) point to the other (no diagonal moves).
    This is also known as *L1 distance* (and squared Euclidean distance is *L2 distance*
    ).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 曼哈顿距离通过水平单位和垂直单位数来衡量从一个（实值）点到另一个点（没有对角线移动）的距离。这也被称为*L1距离*（而平方欧几里得距离是*L2距离*）。
- en: 'In this example, Manhattan distance is more appropriate because you want to
    measure distance by how far people will walk along the streets, not diagonally
    point-to-point (Euclidean distance). For example, in [figure 9.3](../Text/09.xhtml#ch09fig03),
    client A is 2 blocks north of the site and 2 blocks west, while client B is 3
    blocks south of the site and 1 block east. They are equidistant from the site
    (4 blocks) by Manhattan distance. But client B is further by Euclidean distance:
    the diagonal of a 3-by-1 rectangle is longer than the diagonal of a 2-by-2 square.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，曼哈顿距离更为合适，因为您想要通过人们沿街道行走的距离来衡量距离，而不是通过对角线点对点（欧几里得距离）。例如，在[图9.3](../Text/09.xhtml#ch09fig03)中，客户A位于场地北面2个街区，西面2个街区，而客户B位于场地南面3个街区，东面1个街区。他们通过曼哈顿距离与场地距离相等（4个街区）。但是，客户B通过欧几里得距离更远：3x1矩形的对角线比2x2正方形的对角线长。
- en: Figure 9.3\. Manhattan vs. Euclidean distance
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3\. 曼哈顿距离与欧几里得距离
- en: '![](Images/09fig03_alt.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig03_alt.jpg)'
- en: The Manhattan distance between two vectors `x` and `y` is defined as
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 两个向量`x`和`y`之间的曼哈顿距离定义为
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Cosine similarity
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*Suppose you represent a document as rows of a document-text matrix, as we
    did in [section 6.3.3](../Text/06.xhtml#ch06lev2sec12), where each element i of
    the row vector gives the number of times that word i appeared in the document.
    Then the cosine similarity between two row vectors is a measure of the similarity
    of the corresponding documents.*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设您将文档表示为文档-文本矩阵的行，就像我们在[第6.3.3节](../Text/06.xhtml#ch06lev2sec12)中所做的那样，其中行向量中的每个元素i给出了单词i在文档中出现的次数。然后两个行向量之间的余弦相似度是相应文档相似度的度量。*'
- en: '* * *'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Cosine similarity is a common similarity metric in text analysis. It measures
    the smallest angle between two vectors. In our text example, we assume non-negative
    vectors, so the angle `theta` between two vectors is between 0 and 90 degrees.
    Cosine similarity is shown in [figure 9.4](../Text/09.xhtml#ch09fig04).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度是文本分析中常用的相似度度量。它衡量两个向量之间的最小角度。在我们的文本示例中，我们假设非负向量，因此两个向量之间的角度`theta`在0到90度之间。余弦相似度如图9.4所示。
- en: Figure 9.4\. Cosine similarity
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4\. 余弦相似度
- en: '![](Images/09fig04.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig04.jpg)'
- en: Two perpendicular vectors (`theta` = 90 degrees) are the most dissimilar; the
    cosine of 90 degrees is 0\. Two parallel vectors are the most similar (identical,
    if you assume they’re both based at the origin); the cosine of 0 degrees is 1.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 两个垂直向量（`theta` = 90度）是最不相似的；90度的余弦值为0。两个平行向量是最相似的（如果假设它们都基于原点，则相同）；0度的余弦值为1。
- en: 'From elementary geometry, you can derive that the cosine of the angle between
    two vectors is given by the normalized dot product between the two vectors:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 从初等几何中，您可以推导出两个向量之间角度的余弦值由两个向量的归一化点积给出：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You can turn the cosine similarity into a pseudo distance by subtracting it
    from 1.0 (though to get an actual metric, you should use `1 - 2 * acos(cossim(x,
    y)) / pi`).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过从1.0中减去余弦相似度将其转换为伪距离（尽管要得到一个实际度量，您应该使用`1 - 2 * acos(cossim(x, y)) / pi`）。
- en: Different distance metrics will give you different clusters, as will different
    clustering algorithms. The application domain may give you a hint as to the most
    appropriate distance, or you can try several distance metrics. In this chapter,
    we’ll use (squared) Euclidean distance, as it’s the most natural distance for
    quantitative data.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的距离度量会给出不同的聚类，不同的聚类算法也会如此。应用领域可能会给你一个关于最合适的距离的提示，或者你可以尝试几种距离度量。在本章中，我们将使用（平方）欧几里得距离，因为它是最自然的定量数据距离。
- en: 9.1.2\. Preparing the data
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.2\. 准备数据
- en: To demonstrate clustering, we’ll use a small dataset from 1973 on protein consumption
    from nine different food groups in 25 countries in Europe.^([[1](../Text/09.xhtml#ch09fn1)])
    The goal is to group the countries based on patterns in their protein consumption.
    The dataset is loaded into R as a data frame called `protein`, as shown in the
    next listing.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示聚类，我们将使用1973年关于欧洲25个国家九个不同食物组蛋白质消费的小型数据集.^([[1](../Text/09.xhtml#ch09fn1)])
    目标是根据各国蛋白质消费的模式对国家进行分组。该数据集被加载到R中，作为一个名为`protein`的数据框，如下所示。
- en: ¹
  id: totrans-75
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-76
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The original dataset was from the Data and Story Library, previously hosted
    at CMU. It is no longer online there. A tab-separated text file with the data
    can be found at [https://github.com/WinVector/PDSwR2/tree/master/Protein/](https://github.com/WinVector/PDSwR2/tree/master/Protein/).
    The data file is called protein.txt; additional information can be found in the
    file protein_README.txt.
  id: totrans-77
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始数据集来自数据与故事库，之前托管在CMU。它不再在线上。可以找到带有数据的制表符分隔的文本文件[https://github.com/WinVector/PDSwR2/tree/master/Protein/](https://github.com/WinVector/PDSwR2/tree/master/Protein/)。数据文件名为protein.txt；更多信息可以在文件protein_README.txt中找到。
- en: Listing 9.1\. Reading the protein data
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.1\. 读取蛋白质数据
- en: '[PRE4]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Units and scaling
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 单位和缩放
- en: 'The documentation for this dataset doesn’t mention what the units of measurement
    are; we will assume all the columns are measured in the same units. This is important:
    units (or, more precisely, *disparity* in units ) affect what clusterings an algorithm
    will discover. If you measure vital statistics of your subjects as age in years,
    height in feet, and weight in pounds, you’ll get different distances—and possibly
    different clusters—than if you measure age in years, height in meters, and weight
    in kilograms.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集的文档没有提及测量单位是什么；我们将假设所有列都使用相同的单位进行测量。这很重要：单位（或者更精确地说，*单位差异*）会影响算法会发现哪些聚类。如果你将你的受试者的生命体征测量为年龄（年）、身高（英尺）和体重（磅），你将得到不同的距离——可能还有不同的聚类——如果你将年龄测量为年、身高为米和体重为千克。
- en: Ideally, you want a unit of change in each coordinate to represent the same
    degree of difference. In the `protein` dataset, we assume that the measurements
    are all in the same units, so it might seem that we’re okay. This may well be
    a correct assumption, but different food groups provide different amounts of protein.
    Animal-based food sources in general have more grams of protein per serving than
    plant-based food sources, so one could argue that a change in consumption of five
    grams is a bigger difference in terms of vegetable consumption than it is in terms
    of red meat consumption.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你希望每个坐标的变化单位代表相同程度的不同。在`protein`数据集中，我们假设所有测量都在相同的单位下进行，所以看起来我们可能没问题。这很可能是一个正确的假设，但不同的食物组提供的蛋白质含量不同。一般来说，基于动物的食物来源每份蛋白质的克数比基于植物的食物来源多，因此有人可能会认为在蛋白质摄入量上增加五克，在蔬菜消费方面比在红肉消费方面有更大的差异。
- en: One way to try to make the units of each variable more compatible is to transform
    all the columns to have a mean value of 0 and a standard deviation of 1\. This
    makes the standard deviation the unit of measurement in each coordinate. Assuming
    that your training data has a distribution that accurately represents the population
    at large, then a standard deviation represents approximately the same degree of
    difference in every coordinate.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使每个变量的单位更兼容的一种方法是将所有列转换为单位均值为0、标准差为1。这使得标准差成为每个坐标的测量单位。假设你的训练数据具有准确代表总体的大规模分布，那么标准差在每一个坐标上表示大约相同程度的不同。
- en: You can scale numeric data in R using the function `scale()`. The output of
    `scale()` is a matrix. For the purposes of this chapter, you can mostly think
    of a matrix as a data frame with all numeric columns (this isn’t strictly true,
    but it’s close enough).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用R中的`scale()`函数缩放数值数据。`scale()`的输出是一个矩阵。为了本章的目的，你可以主要将矩阵视为一个包含所有数值列的数据框（这并不完全正确，但足够接近）。
- en: The `scale()` function annotates its output with two attributes—`scaled:center`
    returns the mean values of all the columns, and `scaled:scale` returns the standard
    deviations. You’ll store these away so you can “unscale” the data later.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`scale()` 函数使用两个属性注释其输出——`scaled:center` 返回所有列的均值，而 `scaled:scale` 返回标准差。您将保存这些值，以便稍后“取消缩放”数据。'
- en: Listing 9.2\. Rescaling the dataset
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.2\. 重新缩放数据集
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Uses all the columns except the first (Country)
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用除第一个（国家）之外的所有列
- en: ❷ Stores the scaling attributes
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 存储缩放属性
- en: ❸ Convenience function to remove scale attributes from a scaled matrix.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 用于从缩放矩阵中删除缩放属性的便利函数。
- en: ❹ Nulls out the scale attributes for safety
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 为安全起见，将缩放属性置为零
- en: '[Figure 9.5](../Text/09.xhtml#ch09fig05) shows the effect of scaling on two
    variables, `Fr.Veg` and `RedMeat`. The raw (unscaled) variables have different
    ranges, reflecting the fact that the amount of protein supplied via red meat tends
    to be higher than the amount of protein supplied via fruits and vegetables. The
    scaled variables now have similar ranges, which makes comparing relative variation
    in each variable easier.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9.5](../Text/09.xhtml#ch09fig05) 展示了缩放对两个变量 `Fr.Veg` 和 `RedMeat` 的影响。原始（未缩放）变量有不同的范围，反映了通过红肉提供的蛋白质量往往高于通过水果和蔬菜提供的蛋白质量。缩放后的变量现在具有相似的范围，这使得比较每个变量的相对变化更容易。'
- en: Figure 9.5\. Comparison of `Fr.Veg` and `RedMeat` variables, unscaled (top)
    and scaled (bottom)
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5\. `Fr.Veg` 和 `RedMeat` 变量的比较，未缩放（顶部）和缩放（底部）
- en: '![](Images/09fig05_alt.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/09fig05_alt.jpg)'
- en: Now you are ready to cluster the protein data. We’ll start with hierarchical
    clustering.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经准备好对蛋白质数据进行聚类。我们将从层次聚类开始。
- en: 9.1.3\. Hierarchical clustering with hclust
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.3\. 使用 hclust 进行层次聚类
- en: The `hclust()` function takes as input a distance matrix (as an object of class
    `dist`), which records the distances between all pairs of points in the data (using
    any one of a variety of metrics). You can compute the distance matrix using the
    function `dist()`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`hclust()` 函数接受一个距离矩阵（作为 `dist` 类的对象）作为输入，该矩阵记录了数据中所有点对之间的距离（使用任何一种方法）。您可以使用
    `dist()` 函数计算距离矩阵。'
- en: '`dist()` will calculate distance functions using the (squared) Euclidean distance
    (`method = "euclidean"`), the Manhattan distance (`method = "manhattan"`), and
    something like the Hamming distance, when categorical variables are expanded to
    indicators (`method = "binary"`). If you want to use another distance metric,
    you’ll have to compute the appropriate distance matrix and convert it to a `dist`
    object using the `as.dist()` call (see `help(dist)` for further details).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`dist()` 将使用（平方）欧几里得距离 (`method = "euclidean"`)、曼哈顿距离 (`method = "manhattan"`)
    以及当分类变量扩展为指示符时类似汉明距离的方法来计算距离函数。如果您想使用其他距离度量，您必须计算适当的距离矩阵，并使用 `as.dist()` 调用将其转换为
    `dist` 对象（有关更多详细信息，请参阅 `help(dist)`）。'
- en: '`hclust()` also uses one of a variety of clustering methods to produce a tree
    that records the nested cluster structure. We’ll use Ward’s method, which starts
    out with each data point as an individual cluster and merges clusters iteratively
    so as to minimize the total *within sum of squares* (WSS) of the clustering (we’ll
    explain more about WSS later in the chapter).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`hclust()` 也使用多种聚类方法之一来生成一棵树，该树记录了嵌套的聚类结构。我们将使用沃德方法，该方法最初将每个数据点作为一个单独的聚类，并通过迭代合并聚类以最小化聚类的总
    *内部平方和* (WSS)（我们将在本章后面更详细地解释 WSS）。'
- en: Let’s cluster the protein data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对蛋白质数据进行聚类。
- en: Listing 9.3\. Hierarchical clustering
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.3\. 层次聚类
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Creates the distance matrix
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建距离矩阵
- en: ❷ Does the clustering
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 进行聚类
- en: ❸ Plots the dendrogram
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 绘制树状图
- en: '`hclust()` returns a *dendrogram*: a tree that represents the nested clusters.
    The dendrogram for the protein data is shown in [figure 9.6](../Text/09.xhtml#ch09fig06).
    The leaves of the tree are in the same cluster if there is a path between them.
    By cutting the tree at a certain depth, you disconnect some of the paths, and
    so create more, smaller clusters.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`hclust()` 返回一个 *树状图*：表示嵌套聚类的树。蛋白质数据的树状图显示在 [图 9.6](../Text/09.xhtml#ch09fig06)
    中。如果树中的叶子之间存在路径，则它们位于同一聚类中。通过在某个深度切割树，您将断开一些路径，从而创建更多、更小的聚类。'
- en: Figure 9.6\. Dendrogram of countries clustered by protein consumption
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6\. 蛋白质消费聚类国家的树状图
- en: '![](Images/09fig06_alt.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/09fig06_alt.jpg)'
- en: 'This dendrogram suggests five clusters might be an appropriate number, as shown
    in [figure 9.6](../Text/09.xhtml#ch09fig06). You can draw the rectangles on the
    dendrogram using the function `rect.hclust()`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这棵树状图表明五个集群可能是一个合适的数量，如图 9.6 所示。[figure 9.6](../Text/09.xhtml#ch09fig06)。您可以使用
    `rect.hclust()` 函数在树状图上绘制矩形：
- en: '[PRE7]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: To extract the members of each cluster from the `hclust` object, use `cutree()`.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要从 `hclust` 对象中提取每个集群的成员，请使用 `cutree()`。
- en: Listing 9.4\. Extracting the clusters found by `hclust()`
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.4\. 提取 `hclust()` 找到的集群
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ A convenience function for printing out the countries in each cluster, along
    with the values for red meat, fish, and fruit/vegetable consumption. We’ll use
    this function throughout this section. Note that the function assumes the data
    is in a data.frame (not a matrix).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 打印每个集群中国家的便利函数，以及红肉、鱼类和水果/蔬菜消费的值。在本节中我们将使用此函数。请注意，该函数假定数据在数据框（而非矩阵）中。
- en: 'There’s a certain logic to these clusters: the countries in each cluster tend
    to be in the same geographical region. It makes sense that countries in the same
    region would have similar dietary habits. You can also see that'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这些集群有一定的逻辑性：每个集群中的国家往往位于相同的地理区域。同一地区的国家拥有相似的饮食习惯是有道理的。您还可以看到，
- en: Cluster 2 is made of countries with higher-than-average red meat consumption.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群 2 由消费红肉量高于平均的国家组成。
- en: Cluster 4 contains countries with higher-than-average fish consumption, but
    low produce consumption.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群 4 包含了鱼类消费量高于平均但农产品消费量较低的国家。
- en: Cluster 5 contains countries with high fish and produce consumption.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群 5 包含了鱼类和农产品消费量高的国家。
- en: This dataset has only 25 points; it’s harder to “eyeball” the clusters and the
    cluster members when there are very many data points. In the next few sections,
    we’ll look at some ways to examine clusters more holistically.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集只有 25 个点；当数据点非常多时，很难“目测”集群及其成员。在接下来的几节中，我们将探讨一些更全面地检查集群的方法。
- en: Visualizing clusters using principal components analysis
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 使用主成分分析可视化集群
- en: As we mentioned in [chapter 3](../Text/03.xhtml#ch03), visualization is an effective
    way to get an overall view of the data, or in this case, the clusterings. The
    protein data is nine-dimensional, so it’s hard to visualize with a scatter plot.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在 [第 3 章](../Text/03.xhtml#ch03) 中提到的，可视化是获取数据整体视图的有效方法，或者在这种情况下，是获取聚类视图。蛋白质数据是九维的，因此很难用散点图进行可视化。
- en: We can try to visualize the clustering by projecting the data onto the first
    two *principal components* of the data.^([[1](../Text/09.xhtml#ch09fn2)]) If *N*
    is the number of variables that describe the data, then the principal components
    describe the hyperellipsoid in *N*-space that roughly bounds the data. Each principal
    component is an *N*-dimensional vector that describes an axis of that hyperellipsoid.
    [Figure 9.7](../Text/09.xhtml#ch09fig07) shows this for *N* = 3.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以尝试通过将数据投影到数据的第一个两个 *主成分* 上来可视化聚类。[^[[1](../Text/09.xhtml#ch09fn2)]] 如果 *N*
    是描述数据的变量数量，那么主成分描述了 *N*-空间中大致界定数据的超椭圆体。每个主成分是一个 *N*-维向量，描述了该超椭圆体的一个轴。[图 9.7](../Text/09.xhtml#ch09fig07)
    展示了当 *N* = 3 时的这种情况。
- en: ¹
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We can project the data onto any two of the principal components, but the first
    two are the most likely to show useful information.
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们可以将数据投影到任何两个主成分上，但前两个最有可能显示有用的信息。
- en: Figure 9.7\. The idea behind principal components analysis
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7\. 主成分分析背后的思想
- en: '![](Images/09fig07.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig07.jpg)'
- en: If you order the principal components by the length of the hyperellipsoid’s
    corresponding axes (longest first), then the first two principal components describe
    a plane in *N*-space that captures as much of the variation of the data as can
    be captured in two dimensions. In other words, it describes the best 2-D projection
    of the data. We’ll use the `prcomp()` call to do the principal components decomposition.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您按超椭圆体对应轴的长度（最长优先）对主成分进行排序，那么前两个主成分描述了 *N*-空间中的一个平面，该平面可以捕捉到尽可能多的数据变化，这些变化可以在二维中捕捉到。换句话说，它描述了数据的最佳
    2-D 投影。我们将使用 `prcomp()` 调用来进行主成分分解。
- en: Listing 9.5\. Projecting the clusters on the first two principal components
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.5\. 将集群投影到前两个主成分上
- en: '[PRE9]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Calculates the principal components of the data
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算数据的主成分
- en: ❷ The predict() function will rotate the data into the coordinates described
    by the principal components. The first two columns of the rotated data are the
    projection of the data on the first two principal components.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ `predict()` 函数会将数据旋转到由主成分描述的坐标中。旋转数据的前两列是数据在第一个和第二个主成分上的投影。
- en: ❸ Creates a data frame with the transformed data, along with the cluster label
    and country label of each point
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建一个数据框，包含转换后的数据，以及每个点的聚类标签和国家标签。
- en: ❹ Plot it. Put each cluster in a separate facet for legibility.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 绘制它。为了可读性，将每个集群放在单独的面板中。
- en: You can see in [figure 9.8](../Text/09.xhtml#ch09fig08) that cluster 1 (Romania/Yugoslavia/Bulgaria/Albania)
    and the Mediterranean cluster (cluster 5) are separated from the others. The other
    three clusters comingle in this projection, though they’re probably more separated
    in other projections.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 [图 9.8](../Text/09.xhtml#ch09fig08) 中看到，集群 1（罗马尼亚/南斯拉夫/保加利亚/阿尔巴尼亚）和地中海集群（集群
    5）与其他集群分离。其他三个集群在这个投影中混合在一起，尽管它们在其他投影中可能更分离。
- en: Figure 9.8\. Plot of countries clustered by protein consumption, projected onto
    the first two principal components
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8\. 按蛋白质消耗量聚类的国家，投影到前两个主成分
- en: '![](Images/09fig08_alt.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig08_alt.jpg)'
- en: Bootstrap evaluation of clusters
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 集群的自举评估
- en: An important question when evaluating clusters is whether a given cluster is
    “real”—does the cluster represent actual structure in the data, or is it an artifact
    of the clustering algorithm? As you’ll see, this is especially important with
    clustering algorithms like k-means, where the user has to specify the number of
    clusters beforehand. It’s been our experience that clustering algorithms will
    often produce several clusters that represent actual structure or relationships
    in the data, and then one or two clusters that are buckets that represent “other”
    or “miscellaneous.” Clusters of "other" tend to be made up of data points that
    have no real relationship to each other; they just don’t fit anywhere else.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估集群时，一个重要的问题是给定集群是否“真实”——该集群是否代表数据中的实际结构，或者它是否是聚类算法的产物？正如您将看到的，这对于像 k-means
    这样的聚类算法尤为重要，用户必须事先指定集群的数量。我们的经验表明，聚类算法通常会生成几个代表数据中实际结构或关系的集群，然后是一个或两个代表“其他”或“杂项”的集群。所谓的“其他”集群往往由彼此之间没有真正关系的点组成；它们根本不适合其他任何地方。
- en: One way to assess whether a cluster represents true structure is to see if the
    cluster holds up under plausible variations in the dataset. The `fpc` package
    has a function called `clusterboot()` that uses bootstrap resampling to evaluate
    how stable a given cluster is.^([[1](../Text/09.xhtml#ch09fn3)]) `clusterboot()`
    is an integrated function that both performs the clustering and evaluates the
    final produced clusters. It has interfaces to a number of R clustering algorithms,
    including both `hclust` and `kmeans`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 评估一个集群是否代表真实结构的一种方法是通过观察该集群在数据集的合理变化下是否保持稳定。`fpc` 包含一个名为 `clusterboot()` 的函数，该函数使用自举重采样来评估给定集群的稳定性.^([[1](../Text/09.xhtml#ch09fn3)])
    `clusterboot()` 是一个集成函数，它既执行聚类又评估最终生成的集群。它具有与多个 R 聚类算法的接口，包括 `hclust` 和 `kmeans`。
- en: ¹
  id: totrans-141
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-142
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a full description of the algorithm, see Christian Henning, “Cluster-wise
    assessment of cluster stability,” Research Report 271, Dept. of Statistical Science,
    University College London, December 2006.
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于算法的完整描述，请参阅 Christian Henning 的研究报告，“Cluster-wise assessment of cluster stability”，报告编号
    271，伦敦大学学院统计科学系，2006年12月。
- en: '`clusterboot`’s algorithm uses the *Jaccard coefficient*, a similarity measure
    between sets. The Jaccard similarity between two sets A and B is the ratio of
    the number of elements in the intersection of A and B over the number of elements
    in the union of A and B. This is shown in [figure 9.9](../Text/09.xhtml#ch09fig09).'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`clusterboot` 算法使用 *Jaccard 系数*，它是集合之间的相似度度量。集合 A 和 B 之间的 Jaccard 相似度是 A 和
    B 交集元素数量与 A 和 B 并集元素数量的比率。这如图 9.9 所示。'
- en: Figure 9.9\. Jaccard similarity
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.9\. Jaccard 相似度
- en: '![](Images/09fig09.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig09.jpg)'
- en: 'The basic general strategy is as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的一般策略如下：
- en: Cluster the data as usual.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照常规对数据进行聚类。
- en: Draw a new dataset (of the same size as the original) by resampling the original
    dataset with replacement (meaning that some of the data points may show up more
    than once, and others not at all). Cluster the new dataset.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过对原始数据集进行有放回的重采样（意味着某些数据点可能会出现多次，而其他点则可能一次也不出现）来绘制一个新的数据集（与原始数据集大小相同）。对新数据集进行聚类。
- en: For every cluster in the original clustering, find the most similar cluster
    in the new clustering (the one that gives the maximum Jaccard coefficient) and
    record that value. If this maximum Jaccard coefficient is less than 0.5, the original
    cluster is considered to be *dissolved*—it didn’t show up in the new clustering.
    A cluster that’s dissolved too often is probably not a “real” cluster.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于原始聚类中的每个聚类，找到新聚类中最相似的聚类（给出最大贾卡德系数的那个聚类）并记录该值。如果这个最大贾卡德系数小于 0.5，原始聚类被认为是 *溶解*
    的——它没有出现在新的聚类中。一个经常溶解的聚类可能不是一个“真实”的聚类。
- en: Repeat steps 2–3 several times.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复步骤 2–3 几次。
- en: The *cluster stability* of each cluster in the original clustering is the mean
    value of its Jaccard coefficient over all the bootstrap iterations. As a rule
    of thumb, clusters with a stability value less than 0.6 should be considered unstable.
    Values between 0.6 and 0.75 indicate that the cluster is measuring a pattern in
    the data, but there isn’t high certainty about which points should be clustered
    together. Clusters with stability values above about 0.85 can be considered highly
    stable (they’re likely to be real clusters).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 原始聚类中每个聚类的 *聚类稳定性* 是其在所有自助迭代中贾卡德系数的平均值。一般来说，稳定性值小于 0.6 的聚类应被视为不稳定。介于 0.6 和 0.75
    之间的值表明聚类正在测量数据中的模式，但关于哪些点应该聚类在一起没有很高的确定性。稳定性值高于约 0.85 的聚类可以被认为是高度稳定的（它们很可能是真实聚类）。
- en: Different clustering algorithms can give different stability values, even when
    the algorithms produce highly similar clusterings, so `clusterboot()` is also
    measuring how stable the clustering algorithm is.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的聚类算法即使在产生高度相似的聚类时也可能给出不同的稳定性值，因此 `clusterboot()` 也测量聚类算法的稳定性。
- en: Let’s run `clusterboot()` on the protein data, using hierarchical clustering
    with five clusters. Note that `clusterboot()` is randomized, so you may not get
    identical results.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在蛋白质数据上运行 `clusterboot()`，使用五聚类的层次聚类。请注意，`clusterboot()` 是随机的，因此你可能不会得到相同的结果。
- en: Listing 9.6\. Running `clusterboot()` on the protein data
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.6\. 在蛋白质数据上运行 `clusterboot()`
- en: '[PRE10]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Loads the fpc package. You may have to install it first.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载 fpc 包。你可能需要先安装它。
- en: ❷ Sets the desired number of clusters
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 设置所需的聚类数量
- en: ❸ Runs clusterboot() with hclust (clustermethod = hclustCBI) using Ward’s method
    (method = "ward.D") and kbest_p clusters (k = kbest_p). Returns the results in
    an object called cboot_hclust.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用 hclust (clustermethod = hclustCBI) 和 Ward 方法 (method = "ward.D") 以及 kbest_p
    个聚类 (k = kbest_p) 运行 clusterboot()。结果存储在名为 cboot_hclust 的对象中。
- en: ❹ The results of the clustering are in cboot_hclust$result.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 聚类结果存储在 cboot_hclust$result 中。
- en: ❺ cboot_hclust$result$partition returns a vector of cluster labels.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ cboot_hclust$result$partition 返回一个聚类标签向量。
- en: ❻ The clusters are the same as those produced by a direct call to hclust().
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 聚类结果与直接调用 hclust() 得到的结果相同。
- en: ❻ The vector of cluster stabilities
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 聚类稳定性的向量
- en: ❽ The count of how many times each cluster was dissolved. By default, clusterboot()
    runs 100 bootstrap iterations.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❽ 每个聚类被溶解的次数。默认情况下，clusterboot() 运行 100 次自助迭代。
- en: 'The `clusterboot()` results show that the cluster of countries with high fish
    consumption (cluster 4) is highly stable: the cluster stability is high, and the
    cluster was dissolved relatively few times. Clusters 1 and 2 are also quite stable;
    cluster 5 less so (you can see in [figure 9.8](../Text/09.xhtml#ch09fig08) that
    the members of cluster 5 are separated from the other countries, but also fairly
    separated from each other). Cluster 3 has the characteristics of what we’ve been
    calling the “other” cluster.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`clusterboot()` 的结果显示，高鱼消费国家（聚类 4）的聚类非常稳定：聚类稳定性高，聚类相对较少地被溶解。聚类 1 和 2 也相当稳定；聚类
    5 的稳定性较低（你可以在 [图 9.8](../Text/09.xhtml#ch09fig08) 中看到聚类 5 的成员与其他国家分离，但也相对彼此分离）。聚类
    3 具有我们一直称之为“其他”聚类的特征。'
- en: '`clusterboot()` assumes that you know the number of clusters, *k*. We eyeballed
    the appropriate *k* from the dendrogram, but this isn’t always feasible with a
    large dataset. Can we pick a plausible *k* in a more automated fashion? We’ll
    look at this question in the next section.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`clusterboot()` 假设你知道聚类数量，*k*。我们从树状图中目测了合适的 *k*，但这种方法在大数据集中并不总是可行。我们能否以更自动化的方式选择一个合理的
    *k*？我们将在下一节中探讨这个问题。'
- en: Picking the number of clusters
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 选择聚类数量
- en: There are a number of heuristics and rules of thumb for picking clusters; a
    given heuristic will work better on some datasets than others. It’s best to take
    advantage of domain knowledge to help set the number of clusters, if that’s possible.
    Otherwise, try a variety of heuristics, and perhaps a few different values of
    *k*.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多启发式方法和经验规则用于选择簇；给定的启发式方法在某些数据集上可能比其他数据集上工作得更好。如果可能的话，最好利用领域知识来帮助设置簇的数量。否则，尝试各种启发式方法，也许还有几个不同的*k*值。
- en: Total within sum of squares
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 总内部平方和
- en: One simple heuristic is to compute the total within sum of squares (WSS) for
    different values of *k* and look for an “elbow” in the curve. We'll walk through
    the definition of WSS in this section.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的启发式方法是计算不同*k*值的总内部平方和（WSS），并寻找曲线中的“肘部”。我们将在本节中介绍WSS的定义。
- en: '[Figure 9.10](../Text/09.xhtml#ch09fig10) shows data with four clusters. Define
    the *centroid* of each cluster as the point that is the mean value of all the
    points in the cluster. The centroid will be in the center of the cluster, as shown
    in the figure. The within sum of squares (or `WSS_i`) for a single cluster is
    the summed squared distance of each point in the cluster from the cluster’s centroid.
    This is shown in the figure for cluster 4.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9.10](../Text/09.xhtml#ch09fig10)显示了具有四个簇的数据。定义每个簇的*质心*为簇中所有点的平均值。质心将位于簇的中心，如图所示。单个簇的内部平方和（或`WSS_i`）是簇中每个点与簇质心的平方距离之和。这在图中的簇4中显示出来。'
- en: Figure 9.10\. Cluster WSS and total WSS for a set of four clusters
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.10. 四个簇的簇WSS和总WSS
- en: '![](Images/09fig10_alt.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图9.10的替代图片](Images/09fig10_alt.jpg)'
- en: The total within sum of squares is the sum of the `WSS_i` of all the clusters.
    We show the calculation in the following listing.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 总的内部平方和是所有簇的`WSS_i`的总和。我们将在下面的列表中展示计算过程。
- en: Listing 9.7\. Calculating total within sum of squares
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.7. 计算总内部平方和
- en: '[PRE11]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Function to calculate squared distance between two vectors
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算两个向量之间平方距离的函数
- en: ❷ Function to calculate the WSS for a single cluster, which is represented as
    a matrix (one row for every point)
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算单个簇的WSS的函数，该簇表示为一个矩阵（每行一个点）
- en: ❸ Calculates the centroid of the cluster (the mean of all the points)
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算簇的质心（所有点的平均值）
- en: ❹ Calculates the squared difference of every point in the cluster from the centroid,
    and sums all the distances
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 计算簇中每个点与质心的平方差，并求和所有距离
- en: ❺ Function to compute the total WSS from a set of data points and cluster labels
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 计算从一组数据点和聚类标签中得到的总WSS的函数
- en: ❻ Extracts each cluster, calculates the cluster’s WSS, and sums all the values
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 提取每个簇，计算簇的WSS，并求和所有值
- en: ❻ Calculates the total WSS for the current protein clustering
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 计算当前蛋白质聚类的总WSS。
- en: The total WSS will decrease as the number of clusters increases, because each
    cluster will be smaller and tighter. The hope is that the rate at which the WSS
    decreases will slow down for *k* beyond the optimal number of clusters. In other
    words, the graph of WSS versus *k* should flatten out beyond the optimal *k*,
    so the optimal *k* will be at the “elbow” of the graph. Let’s try calculating
    WSS for up to 10 clusters.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 随着簇数量的增加，总的WSS会减少，因为每个簇将变得更小、更紧密。希望WSS减少的速率会在超过最佳簇数量后的*k*上放缓。换句话说，WSS与*k*的图表应该在最佳*k*之后变平，因此最佳*k*将在图表的“肘部”。让我们尝试计算最多10个簇的WSS。
- en: Listing 9.8\. Plotting WSS for a range of `k`
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.8. 绘制`k`范围的WSS
- en: '[PRE12]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ A function to get the total WSS for a range of clusters from 1 to max
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 一个函数，用于获取从1到最大值的簇的总WSS
- en: ❷ wss[1] is just the WSS of all the data.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ wss[1]只是所有数据的WSS。
- en: ❸ Clusters the data
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 对数据进行聚类
- en: ❹ For each k, calculates the cluster labels and the cluster WSS
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 对于每个k，计算簇标签和簇WSS
- en: ❺ Plots WSS as a function of k
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 绘制WSS随k的变化图
- en: '[Figure 9.11](../Text/09.xhtml#ch09fig11) shows the plot of WSS as a function
    of *k*. Unfortunately, in this case the elbow of the graph is hard to see, although
    if you squint your eyes you might be able to convince yourself that there is an
    elbow at `k = 2`, and another one at `k = 5` or `6`. This means the best clusterings
    might be 2 clusters, 5 clusters, or 6 clusters.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9.11](../Text/09.xhtml#ch09fig11)显示了WSS随*k*变化的曲线图。不幸的是，在这种情况下，曲线的肘部很难看清，尽管如果你眯起眼睛，你可能会说服自己，在`k
    = 2`处有一个肘部，在`k = 5`或`k = 6`处也有一个。这意味着最佳的聚类可能是2个簇，5个簇，或6个簇。'
- en: Figure 9.11\. WSS as a function of `k` for the protein data
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11. 蛋白质数据的WSS随`k`的变化
- en: '![](Images/09fig11_alt.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig11_alt.jpg)'
- en: Calinski-Harabasz index
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Calinski-Harabasz指数
- en: The *Calinski-Harabasz index* is another commonly used measure of cluster goodness.
    It tries to find the point where all the clusters are tight, and also far apart
    from each other. To motivate (and calculate) the Calinski-Harabasz index (CH index,
    for short), we first need to define a few more terms.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**Calinski-Harabasz指数**是衡量聚类好坏的另一种常用指标。它试图找到所有聚类都紧密且彼此之间距离较远的位置。为了说明（并计算）Calinski-Harabasz指数（简称CH指数），我们首先需要定义一些更多术语。'
- en: 'As shown in [figure 9.12](../Text/09.xhtml#ch09fig12), the *total sum of squares*
    (TSS) of a set of points is the sum of the squared distances of all the points
    from the centroid of the data. In the function `get_wss()` of [listing 9.8](../Text/09.xhtml#ch09ex08),
    the value `wss[1]` is the TSS, and it is independent of the clustering. For a
    given clustering with total within sum of squares, we can also define the *between
    sum of squares* (BSS):'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图9.12](../Text/09.xhtml#ch09fig12)所示，一组点的**总平方和**（TSS）是所有点与数据质心的距离平方的和。在[列表9.8](../Text/09.xhtml#ch09ex08)的`get_wss()`函数中，值`wss[1]`是TSS，它与聚类无关。对于具有总内部平方和的给定聚类，我们还可以定义**之间平方和**（BSS）：
- en: '[PRE13]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Figure 9.12\. Total sum of squares for a set of four clusters
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.12\. 四个聚类的总平方和
- en: '![](Images/09fig12_alt.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig12_alt.jpg)'
- en: BSS measures how far apart the clusters are from each other. A good clustering
    has a small WSS (all the clusters are tight around their centers) and a large
    BSS. We can compare how BSS and WSS vary as we vary the number of clusters.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: BSS衡量聚类彼此之间的距离。一个好的聚类具有小的WSS（所有聚类都紧密围绕其中心）和大的BSS。我们可以比较随着聚类数量的变化，BSS和WSS如何变化。
- en: Listing 9.9\. Plotting BSS and WSS as a function of *k*
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.9\. 作为*k*函数绘制BSS和WSS
- en: '[PRE14]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '❶ Calculates the total sum of squares: TSS'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算总平方和：TSS
- en: ❷ Loads the cdata package to reshape the data
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 加载cdata包以重塑数据
- en: ❸ Reshapes cluster_meas so that the WSS and the BSS are in the same column
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将cluster_meas重塑，使WSS和BSS在同一列
- en: '[Figure 9.13](../Text/09.xhtml#ch09fig13) shows that as *k* increases, BSS
    increases, while WSS decreases. We want a clustering with a good balance of BSS
    and WSS. To find such a clustering, we have to look at a couple of measures related
    to the BSS and the WSS.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9.13](../Text/09.xhtml#ch09fig13)显示，随着*k*的增加，BSS增加，而WSS减少。我们希望找到一个具有良好BSS和WSS平衡的聚类。为了找到这样的聚类，我们必须查看与BSS和WSS相关的几个指标。'
- en: Figure 9.13\. BSS and WSS as a function of *k*
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13\. BSS和WSS作为*k*的函数
- en: '![](Images/09fig13_alt.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig13_alt.jpg)'
- en: The *within cluster variance W* is given by
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类内方差W**由以下公式给出'
- en: '[PRE15]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Here, *n* is the number of data points and *k* is the number of clusters. You
    can think of *W* as the “average” WSS.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*n*是数据点的数量，*k*是聚类的数量。你可以将*W*视为“平均”WSS。
- en: The *between cluster variance B* is given by
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类间方差B**由以下公式给出'
- en: '[PRE16]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Again, you can think of *B* as the average contribution to the BSS from each
    cluster.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你可以将*B*视为每个聚类对BSS的平均贡献。
- en: A good clustering should have a small average WSS and a large average BSS, so
    we might try to maximize the ratio of *B* to *W*. This is the Calinski-Harabasz
    (CH) index. Let’s calculate the CH index and plot it for up to 10 clusters.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的聚类应该具有小的平均WSS和大的平均BSS，因此我们可能会尝试最大化*B*与*W*的比率。这就是Calinski-Harabasz（CH）指数。让我们计算CH指数并绘制出最多10个聚类的图像。
- en: Listing 9.10\. The Calinski-Harabasz index
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.10\. Calinski-Harabasz指数
- en: '[PRE17]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Calculates the between cluster variance B
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 计算聚类间方差B
- en: ❷ Calculates the within cluster variance W
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算聚类内方差W
- en: ❸ Calculates the CH index
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算CH指数
- en: Looking at [figure 9.14](../Text/09.xhtml#ch09fig14), you see that the CH criterion
    is maximized at `k = 2`, with another local maximum at `k = 5`. The `k = 2` clustering
    corresponds to the first split of the protein data dendrogram, as shown in [figure
    9.15](../Text/09.xhtml#ch09fig15); if you use `clusterboot()` to do the clustering,
    you’ll see that the clusters are highly stable, though perhaps not very informative.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 观察图9.14，你看到CH标准在`k = 2`时最大化，在`k = 5`处有另一个局部最大值。`k = 2`的聚类对应于蛋白质数据树状图的第一次分割，如图9.15所示；如果你使用`clusterboot()`进行聚类，你会看到聚类高度稳定，尽管可能不是非常有信息量。
- en: Figure 9.14\. The Calinski-Harabasz index as a function of *k*
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.14\. 作为*k*函数的Calinski-Harabasz指数
- en: '![](Images/09fig14_alt.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig14_alt.jpg)'
- en: Figure 9.15\. The protein data dendrogram with two clusters
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.15\. 具有两个聚类的蛋白质数据树状图
- en: '![](Images/09fig15_alt.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig15_alt.jpg)'
- en: '* * *'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**Other measures of cluster quality**'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**聚类质量的其他度量**'
- en: There are several other measures that you can try when picking *k*. The *gap
    statistic*^([[a](../Text/09.xhtml#ch09fn4a)]) is an attempt to automate the “elbow
    finding” on the WSS curve. It works best when the data comes from a mix of populations
    that all have approximately Gaussian distributions (called a *mixture of Gaussians*).
    We’ll see one more measure, the *average silhouette width*, when we discuss `kmeans()`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择*k*时，你可以尝试几种其他度量。*gap统计量*^([[a](../Text/09.xhtml#ch09fn4a)])是尝试自动在WSS曲线上进行“肘部发现”。当数据来自具有近似高斯分布的多个总体（称为*mixture
    of Gaussians*）时，它效果最好。当我们讨论`kmeans()`时，我们还将看到另一个度量，即*平均轮廓宽度*。
- en: ^a
  id: totrans-230
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ^a
- en: ''
  id: totrans-231
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: See Robert Tibshirani, Guenther Walther, and Trevor Hastie, “Estimating the
    number of clusters in a data set via the gap statistic,” *Journal of the Royal
    Statistical Society B*, 2001\. 63(2), pp. 411-423; [www.stanford.edu/~hastie/Papers/gap.pdf](http://www.stanford.edu/~hastie/Papers/gap.pdf).
  id: totrans-232
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 参见Robert Tibshirani，Guenther Walther和Trevor Hastie，“通过gap统计量估计数据集中聚类的数量”，*皇家统计学会B卷*，2001年，第63卷，第2期，第411-423页；[www.stanford.edu/~hastie/Papers/gap.pdf](http://www.stanford.edu/~hastie/Papers/gap.pdf)。
- en: '* * *'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 9.1.4\. The k-means algorithm
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.4\. k-means算法
- en: K-means is a popular clustering algorithm when the data is all numeric and the
    distance metric is squared Euclidean (though you could in theory run it with other
    distance metrics). It’s fairly ad hoc and has the major disadvantage that you
    must pick *k* in advance. On the plus side, it’s easy to implement (one reason
    it’s so popular) and can be faster than hierarchical clustering on large datasets.
    It works best on data that looks like a mixture of Gaussians, which the `protein`
    data unfortunately doesn’t appear to be.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据都是数值且距离度量是平方欧几里得距离时（尽管理论上可以用其他距离度量运行它），K-means是一种流行的聚类算法。它相当随意，并且主要缺点是你必须事先选择*k*。优点是它易于实现（这是它如此受欢迎的原因之一），并且在大型数据集上可能比层次聚类更快。它最适合看起来像高斯混合的数据，不幸的是，`protein`数据看起来并不是这样。
- en: The kmeans() function
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: kmeans()函数
- en: The function to run k-means in R is `kmeans()`. The output of `kmeans()` includes
    the cluster labels, the centers (centroids) of the clusters, the total sum of
    squares, total WSS, total BSS, and the WSS of each cluster.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中运行k-means的函数是`kmeans()`。`kmeans()`的输出包括聚类标签、聚类的中心（质心）、总平方和、总WSS、总BSS以及每个聚类的WSS。
- en: The k-means algorithm is illustrated in [figure 9.16](../Text/09.xhtml#ch09fig16),
    with *k* = 2\. This algorithm isn’t guaranteed to have a unique stopping point.
    K-means can be fairly unstable, in that the final clusters depend on the initial
    cluster centers. It’s good practice to run k-means several times with different
    random starts, and then select the clustering with the lowest total WSS. The `kmeans()`
    function can do this automatically, though it defaults to using only one random
    start.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法在[图9.16](../Text/09.xhtml#ch09fig16)中展示，其中*k* = 2。这个算法不保证有一个唯一的停止点。k-means可能相当不稳定，因为最终的聚类取决于初始的聚类中心。多次使用不同的随机开始运行k-means是一个好习惯，然后选择具有最低总WSS的聚类。`kmeans()`函数可以自动完成此操作，尽管它默认只使用一个随机开始。
- en: Figure 9.16\. The k-means procedure. The two cluster centers are represented
    by the outlined star and diamond.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.16\. k-means过程。两个聚类中心由轮廓星和菱形表示。
- en: '![](Images/09fig16_alt.jpg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/09fig16_alt.jpg)'
- en: Let’s run `kmeans()` on the `protein` data (scaled to 0 mean and unit standard
    deviation, as before). We’ll use `k = 5`, as shown in [listing 9.11](../Text/09.xhtml#ch09ex11).
    Note that `kmeans()` is randomized code, so you may not get exactly the results
    shown.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在`protein`数据上运行`kmeans()`（如前所述，缩放到均值为0和单位标准差）。我们将使用`k = 5`，如[列表9.11](../Text/09.xhtml#ch09ex11)所示。请注意，`kmeans()`是随机化代码，因此你可能不会得到显示的确切结果。
- en: Listing 9.11\. Running k-means with `k = 5`
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.11\. 使用`k = 5`运行k-means
- en: '[PRE18]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Runs kmeans() with five clusters (kbest_p = 5), 100 random starts, and 100
    maximum iterations per run
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用五个聚类（kbest_p = 5），每次运行100次随机开始，每次运行100次最大迭代次数的kmeans()函数
- en: ❷ kmeans() returns all the sum-of-squares measures.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ kmeans()返回所有平方和度量。
- en: ❸ pclusters$centers is a matrix whose rows are the centroids of the clusters.
    Note that pclusters$centers is in the scaled coordinates, not the original protein
    coordinates.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ pclusters$centers是一个矩阵，其行是聚类的质心。请注意，pclusters$centers是在缩放坐标中，而不是原始蛋白质坐标中。
- en: '❹ pclusters$size returns the number of points in each cluster. Generally (though
    not always), a good clustering will be fairly well balanced: no extremely small
    clusters and no extremely large ones.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ `pclusters$size` 返回每个簇中的点数。一般来说（尽管并非总是如此），一个好的聚类将相当平衡：没有极小的簇，也没有极大的簇。
- en: ❺ pclusters$cluster is a vector of cluster labels.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ `pclusters$cluster`是一个簇标签的向量。
- en: ❻ In this case, kmeans() and hclust () return the same clustering. This won’t
    always be true.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 在这种情况下，`kmeans()`和`hclust()`返回相同的聚类。这并不总是正确的。
- en: The kmeansruns() function for picking k
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 选择k的`kmeansruns()`函数
- en: 'To run `kmeans()`, you must know *k*. The `fpc` package (the same package that
    has `clusterboot()`) has a function called `kmeansruns()` that calls `kmeans()`
    over a range of *k* and estimates the best *k*. It then returns its pick for the
    best value of *k*, the output of `kmeans()` for that value, and a vector of criterion
    values as a function of *k*. Currently, `kmeansruns()` has two criteria: the Calinski-Harabasz
    index (`"ch"`) and the *average silhouette width* (`"asw"`). For either criterion,
    the maximum value indicates the optimal number of clusters (for more about silhouette
    clustering, see [http://mng.bz/Qe15](http://mng.bz/Qe15)). It’s a good idea to
    examine the criterion values over the entire range of *k*, since you may see evidence
    for a *k* that the algorithm didn’t automatically pick. The following listing
    illustrates this point.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行`kmeans()`，你必须知道*k*。`fpc`包（与`clusterboot()`相同的包）有一个名为`kmeansruns()`的函数，它在一个*k*的范围内调用`kmeans()`并估计最佳的*k*。然后它返回其选择的最佳*k*值，该值对应的`kmeans()`输出，以及一个关于*k*的标准的向量。目前，`kmeansruns()`有两个标准：Calinski-Harabasz指数（`"ch"`）和平均轮廓宽度（`"asw"`）。对于任何标准，最大值表示最佳簇数（有关轮廓聚类的更多信息，请参阅[http://mng.bz/Qe15](http://mng.bz/Qe15)）。检查整个*k*的范围的标准值是个好主意，因为你可能会看到算法没有自动选择的*k*的证据。下面的列表说明了这一点。
- en: Listing 9.12\. Plotting cluster criteria
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.12。绘制聚类标准
- en: '[PRE19]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Runs kmeansruns() from 1–10 clusters, and the ch criterion. By default, kmeansruns()
    uses 100 random starts and 100 maximum iterations per run.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从1到10个簇运行`kmeansruns()`，并使用ch标准。默认情况下，`kmeansruns()`每个运行使用100个随机起始点和100次最大迭代。
- en: ❷ The ch criterion picks two clusters.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ ch标准选择了两个簇。
- en: ❸ Runs kmeansruns() from 1–10 clusters, and the average silhouette width criterion.
    The average silhouette width picks 3 clusters.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 从1到10个簇运行`kmeansruns()`，并使用平均轮廓宽度标准。平均轮廓宽度选择了3个簇。
- en: ❹ Looks at the values of the asw criterion as a function of k
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 查看asw标准值作为k的函数
- en: ❺ Looks at the values of the ch criterion as a function of k
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 查看ch标准值作为k的函数
- en: ❻ Compares these to the ch values for the hclust() clustering. They’re not quite
    the same, because the two algorithms didn’t pick the same clusters.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 将这些与hclust()聚类的ch值进行比较。它们并不完全相同，因为两种算法没有选择相同的簇。
- en: ❻ kmeansruns() also returns the output of kmeans for k = bestk.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ `kmeansruns()`还返回了`k = bestk`时的`kmeans`输出。
- en: The top graph of [figure 9.17](../Text/09.xhtml#ch09fig17) compares the results
    of the two clustering criteria provided by `kmeansruns`. Both criteria have been
    scaled to be in compatible units. They suggest two to three clusters as the best
    choice. However, if you compare the values of the (unscaled) CH criterion for
    the `kmeans` and `hclust` clusterings, as shown in the bottom graph of [figure
    9.17](../Text/09.xhtml#ch09fig17), you’ll see that the CH criterion produces different
    curves for `kmeans()` and `hclust()` clusterings, but it did pick the same value
    (which probably means it picked the same clusters) for `k = 5` and `k = 6`, which
    might be taken as evidence that either 5 or 6 is the optimal choice for *k*.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.17的顶部图比较了`kmeansruns`提供的两种聚类标准的结果。这两种标准都已被缩放到兼容的单位。它们建议两到三个簇是最好的选择。然而，如果你比较图9.17底部图中`kmeans`和`hclust`聚类的（未缩放）CH标准值，你会发现CH标准为`kmeans()`和`hclust()`聚类产生了不同的曲线，但它确实为`k
    = 5`和`k = 6`选择了相同的值（这可能意味着它选择了相同的簇），这可以被视为5或6是*k*的最佳选择的证据。
- en: 'Figure 9.17\. Top: Comparison of the (scaled) CH and average silhouette width
    indices for `kmeans` clusterings. Bottom: Comparison of CH indices for `kmeans`
    and `hclust` clusterings.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.17。顶部：比较`kmeans`聚类的（缩放）CH和平均轮廓宽度指数。底部：比较`kmeans`和`hclust`聚类的CH指数。
- en: '![](Images/09fig17_alt.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig17_alt.jpg)'
- en: clusterboot() revisited
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: clusterboot()重新审视
- en: We can run `clusterboot()` using the k-means algorithm, as well.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以使用k-means算法运行`clusterboot()`。
- en: Listing 9.13\. Running `clusterboot()` with k-means
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.13\. 使用 k-means 运行 `clusterboot()`
- en: '[PRE20]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ We’ve set the seed for the random generator so the results are reproducible.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们已为随机生成器设置种子，以便结果可重复。
- en: Note that the stability numbers as given by `cboot$bootmean` (and the number
    of times that the clusters were “dissolved” as given by `cboot$bootbrd`) are different
    for the hierarchical clustering and k-means, even though the discovered clusters
    are the same. This shows that the stability of a clustering is partly a function
    of the clustering algorithm, not just the data. Again, the fact that both clustering
    algorithms discovered the same clusters might be taken as an indication that 5
    is the optimal number of clusters.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由 `cboot$bootmean` 提供的稳定性数字（以及由 `cboot$bootbrd` 提供的簇“溶解”次数）在层次聚类和 k-means
    中是不同的，尽管发现的簇是相同的。这表明聚类的稳定性部分是聚类算法的函数，而不仅仅是数据的函数。再次强调，两个聚类算法发现相同的簇可能表明 5 是簇的最佳数量。
- en: 9.1.5\. Assigning new points to clusters
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.5\. 将新点分配给簇
- en: Clustering is often used as part of data exploration, or as a precursor to other
    supervised learning methods. But you may want to use the clusters that you discovered
    to categorize new data, as well. One common way to do so is to treat the centroid
    of each cluster as the representative of the cluster as a whole, and then assign
    new points to the cluster with the nearest centroid. Note that if you scaled the
    original data before clustering, then you should also scale the new data point
    the same way before assigning it to a cluster.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类通常用作数据探索的一部分，或作为其他监督学习方法的先导。但您可能还想使用您发现的簇来对新数据进行分类。这样做的一种常见方式是将每个簇的重心作为整个簇的代表，然后将新点分配给最近的质心所在的簇。请注意，如果您在聚类之前对原始数据进行缩放，那么在将新点分配给簇之前也应以相同的方式进行缩放。
- en: '[Listing 9.14](../Text/09.xhtml#ch09ex14) shows an example of a function that
    assigns a new data point, `newpt` (represented as a vector), to a clustering,
    `centers`, which is represented as a matrix where each row is a cluster centroid.
    This is the representation of cluster centroids that `kmeans()` returns. If the
    data was scaled using `scale()` before clustering, then `xcenter` and `xscale`
    are the `scaled:center` and `scaled:scale` attributes, respectively.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 9.14](../Text/09.xhtml#ch09ex14) 展示了一个函数的示例，该函数将新数据点 `newpt`（表示为向量）分配给聚类
    `centers`，其中 `centers` 表示为矩阵，每行是一个簇中心。这是 `kmeans()` 返回的簇中心表示。如果聚类之前使用 `scale()`
    对数据进行缩放，那么 `xcenter` 和 `xscale` 分别是 `scaled:center` 和 `scaled:scale` 属性。'
- en: Listing 9.14\. A function to assign points to a cluster
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.14\. 将点分配给簇的函数
- en: '[PRE21]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Centers and scales the new data point
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 对新数据点进行中心化和缩放
- en: ❷ Calculates how far the new data point is from each of the cluster centers
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算新数据点到每个簇中心的距离
- en: ❸ Returns the cluster number of the closest centroid
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 返回最近质心的簇编号
- en: Note that the function `sqr_edist()` (the squared Euclidean distance) was defined
    previously, in [section 9.1.1](../Text/09.xhtml#ch09lev2sec1).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，函数 `sqr_edist()`（欧几里得距离的平方）之前已在 [9.1.1 节](../Text/09.xhtml#ch09lev2sec1)
    中定义。
- en: Let’s look at an example of assigning points to clusters, using synthetic data.
    First, we’ll generate the data.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用合成数据来查看将点分配给簇的示例。首先，我们将生成数据。
- en: Listing 9.15\. Generating and clustering synthetic data
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.15\. 生成和聚类合成数据
- en: '[PRE22]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Sets the parameters for three 3D Gaussian clusters
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置三个 3D 高斯簇的参数
- en: ❷ Uses the mvrnorm() function from the MASS package to generate 3D axis-aligned
    Gaussian clusters
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用来自 MASS 包的 `mvrnorm()` 函数生成 3D 对齐的高斯簇
- en: ❸ Scales the synthetic data
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 缩放合成数据
- en: ❹ Gets the scaling attributes, then removes them from the matrix
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 获取缩放属性，然后从矩阵中删除它们
- en: ❺ Clusters the synthetic data into three clusters
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将合成数据聚类为三个簇
- en: ❻ The generated clusters are consistent in size with the true clusters.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 生成的簇的大小与真实簇的大小一致。
- en: Let’s compare the centers of the found k-means clusters to the true cluster
    centers. To do that, we need to unscale `tclusters$centers`. The `scale()` function
    works by subtracting the center vector, then dividing by the scale vector. So
    to reverse the process, first “unscale” the scaled matrix, then “uncenter” it.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较发现的 k-means 簇的中心与真实簇中心。为此，我们需要对 `tclusters$centers` 进行反缩放。`scale()` 函数通过减去中心向量然后除以缩放向量来实现。因此，要逆转这个过程，首先对缩放矩阵进行“反缩放”，然后“去中心化”。
- en: Listing 9.16\. Unscaling the centers
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.16\. 反缩放中心
- en: '[PRE23]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Comparing the unscaled centers to `mean1`, `mean2`, and `mean3` in [listing
    9.15](../Text/09.xhtml#ch09ex15), we see that
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 将未缩放的中心与 [列表 9.15](../Text/09.xhtml#ch09ex15) 中的 `mean1`、`mean2` 和 `mean3` 进行比较，我们看到
- en: 'The first discovered center corresponds to `mean2`: (10, –3, 5).'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个发现的中心对应于 `mean2`： (10, –3, 5)。
- en: 'The second discovered center corresponds to `mean3`: (–5, –5, –5).'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个发现的中心对应于 `mean3`： (–5, –5, –5)。
- en: 'The third discovered center corresponds to `mean1`: (1, 1, 1).'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个发现的中心对应于 `mean1`： (1, 1, 1)。
- en: So it appears that the discovered clusters are consistent with the true clusters.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，似乎发现的聚类与真实聚类一致。
- en: Now we can demonstrate assigning new points to the clusters. Let’s generate
    a point from each of the true clusters, and see which k-means cluster it is assigned
    to.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以演示将新点分配到聚类中。让我们从每个真实聚类生成一个点，并查看它被分配到哪个k-means聚类。
- en: Listing 9.17\. An example of assigning points to clusters
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.17\. 将点分配到聚类的示例
- en: '[PRE24]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ❶ This should be assigned to cluster 3.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这应该被分配到聚类3。
- en: ❷ This should be assigned to cluster 1.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 这应该被分配到聚类1。
- en: ❸ This should be assigned to cluster 2.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 这应该被分配到聚类2。
- en: The `assign_cluster()` function has correctly assigned each point to the appropriate
    cluster.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '`assign_cluster()` 函数已正确地将每个点分配到适当的聚类。'
- en: 9.1.6\. Clustering takeaways
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.6\. 聚类要点
- en: 'At this stage, you have learned how to estimate the appropriate number of clusters
    for a dataset, how to cluster a dataset using both hierarchical clustering and
    k-means, and how to evaluate the resulting clusters. Here’s what you should remember
    about clustering:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你已经学会了如何估计数据集的适当聚类数量，如何使用层次聚类和k-means聚类数据集，以及如何评估结果聚类。以下是关于聚类的你应该记住的内容：
- en: The goal of clustering is to discover or draw out similarities among subsets
    of your data.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类的目标是发现或提取数据子集之间的相似性。
- en: In a good clustering, points in the same cluster should be more similar (nearer)
    to each other than they are to points in other clusters.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一个好的聚类中，同一聚类中的点应该比其他聚类中的点更相似（更近）。
- en: When clustering, the units that each variable is measured in matter. Different
    units cause different distances and potentially different clusterings.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在聚类时，每个变量所测量的单位很重要。不同的单位会导致不同的距离和潜在的不同的聚类。
- en: Ideally, you want a unit change in each coordinate to represent the same degree
    of change. One way to approximate this is to transform all the columns to have
    a mean value of 0 and a standard deviation of 1.0, for example, by using the function
    `scale()`.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理想情况下，你希望每个坐标的单位变化代表相同程度的变化。一种近似方法是，通过使用函数 `scale()` 将所有列转换为具有0均值和1.0标准差，例如。
- en: Clustering is often used for data exploration or as a precursor to supervised
    learning methods.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类通常用于数据探索或作为监督学习方法的前奏。
- en: Like visualization, clustering is more iterative and interactive, and less automated,
    than supervised methods.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与可视化一样，聚类比监督方法更迭代、更交互式，也更少自动化。
- en: Different clustering algorithms will give different results. You should consider
    different approaches, with different numbers of clusters.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的聚类算法将给出不同的结果。你应该考虑不同的方法，使用不同的聚类数量。
- en: There are many heuristics for estimating the best number of clusters. Again,
    you should consider the results from different heuristics and explore various
    numbers of clusters.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在许多启发式方法用于估计最佳聚类数量。再次提醒，你应该考虑不同启发式方法的结果，并探索不同数量的聚类。
- en: Sometimes, rather than looking for subsets of data points that are highly similar
    to each other, you’d like to know what kinds of data (or which data attributes)
    tend to occur together. In the next section, we’ll look at one approach to this
    problem.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，与其寻找彼此高度相似的数据点子集，你更想知道哪些类型的数据（或哪些数据属性）倾向于一起出现。在下一节中，我们将探讨解决此问题的一种方法。
- en: 9.2\. Association rules
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2\. 关联规则
- en: Association rule mining is used to find objects or attributes that frequently
    occur together—for example, products that are often bought together during a shopping
    session, or queries that tend to occur together during a session on a website’s
    search engine. Such information can be used to recommend products to shoppers,
    to place frequently bundled items together on store shelves, or to redesign websites
    for easier navigation.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则挖掘用于寻找经常一起出现的对象或属性——例如，在购物过程中经常一起购买的产品，或者在网站搜索引擎会话中倾向于一起出现的查询。此类信息可用于向购物者推荐产品，将经常捆绑的商品一起放置在商店货架上，或重新设计网站以便更容易导航。
- en: 9.2.1\. Overview of association rules
  id: totrans-316
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1\. 关联规则概述
- en: '* * *'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*Suppose you work in a library. You want to know which books tend to be checked
    out together, to help you make predictions about book availability.*'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设你在图书馆工作。你想知道哪些书籍倾向于一起被借出，以帮助你预测书籍的可用性。*'
- en: '* * *'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The unit of “togetherness” when mining association rules is called a *transaction*.
    Depending on the problem, a transaction could be a single shopping basket, a single
    user session on a website, or even a single customer. The objects that comprise
    a transaction are referred to as *items* in an *itemset*: the products in the
    shopping basket, the pages visited during a website session, the actions of a
    customer. Sometimes transactions are referred to as *baskets*, from the shopping
    basket analogy.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在挖掘关联规则时，“一起”的单位称为*交易*。根据问题，交易可以是单个购物篮、单个网站用户会话，甚至单个客户。构成交易的实体称为*项目集*中的*项目*：购物篮中的产品、网站会话期间访问的页面、客户的操作。有时交易被称为*篮子*，来源于购物篮的类比。
- en: When a library patron checks out a set of books, that’s a transaction; the books
    that the patron checks out are the itemset that comprise the transaction. [Table
    9.1](../Text/09.xhtml#ch09table01) represents a database of transactions (you
    run a library where fantasy is quite popular).
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 当图书馆读者借出一套书时，那是一个交易；读者借出的书构成了交易的项目集。[表格9.1](../Text/09.xhtml#ch09table01)代表交易数据库（你运营的图书馆中奇幻类书籍非常受欢迎）。
- en: Table 9.1\. A database of library transactions
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 表格9.1\. 图书馆交易数据库
- en: '| Transaction ID | Books checked out |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 交易ID | 借出的书籍 |'
- en: '| --- | --- |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| --- | ---'
- en: '| 1 | *The Hobbit*, *The Princess Bride* |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 1 | *《霍比特人》，*《公主新娘》* |'
- en: '| 2 | *The Princess Bride*, *The Last Unicorn* |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 2 | *《公主新娘》，*《最后的独角兽》* |'
- en: '| 3 | *The Hobbit* |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| 3 | *《霍比特人》* |'
- en: '| 4 | *The Neverending Story* |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| 4 | *《永远的故事》* |'
- en: '| 5 | *The Last Unicorn* |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| 5 | *《最后的独角兽》* |'
- en: '| 6 | *The Hobbit*, *The Princess Bride*, *The Fellowship of the Ring* |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| 6 | *《霍比特人》，*《公主新娘》，*《指环王》* |'
- en: '| 7 | *The Hobbit*, *The Fellowship of the Ring*, *The Two Towers*, *The Return
    of the King* |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| 7 | *《霍比特人》，*《指环王》，*《双塔奇兵》，*《王者归来》* |'
- en: '| 8 | *The Fellowship of the Ring*, *The Two Towers*, *The Return of the King*
    |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| 8 | *《指环王》，*《双塔奇兵》，*《王者归来》* |'
- en: '| 9 | *The Hobbit*, *The Princess Bride*, *The Last Unicorn* |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| 9 | *《霍比特人》，*《公主新娘》，*《最后的独角兽》* |'
- en: '| 10 | *The Last Unicorn*, *The Neverending Story* |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| 10 | *《最后的独角兽》，*《永远的故事》* |'
- en: 'Mining for association rules occurs in two steps:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则挖掘分为两个步骤：
- en: Look for all the itemsets (subsets of transactions) that occur more often than
    in a minimum fraction of the transactions.
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 寻找出现频率高于最小交易比例的所有项目集（交易的子集）。
- en: Turn those itemsets into rules.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些项目集转化为规则。
- en: Let's look at the transactions that involve the items *The Hobbit* (H for short)
    and *The Princess Bride* (PB for short). The columns of [table 9.2](../Text/09.xhtml#ch09table02)
    represent transactions; the rows mark the transactions where a given itemset appears.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看涉及物品*《霍比特人》*（简称H）和*《公主新娘》*（简称PB）的交易。表格9.2的列代表交易；行标记了出现给定项目集的交易。[表格9.2](../Text/09.xhtml#ch09table02)代表交易数据库（你运营的图书馆中奇幻类书籍非常受欢迎）。
- en: Table 9.2\. Looking for The Hobbit and The Princess Bride
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 表格9.2\. 寻找《霍比特人》和《公主新娘》
- en: '|   | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | Total |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '|   | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 总计 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| **H** | X |   | X |   |   | X | X |   | X |   | 5 |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| **H** | X |   | X |   |   | X | X |   | X |   | 5 |'
- en: '| **PB** | X | X |   |   |   | X |   |   | X |   | 4 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| **PB** | X | X |   |   |   | X |   |   | X |   | 4 |'
- en: '| {**H**, **PB**} | X |   |   |   |   | X |   |   | X |   | 3 |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| {**H**, **PB**} | X |   |   |   |   | X |   |   | X |   | 3 |'
- en: Looking over all the transactions in [table 9.2](../Text/09.xhtml#ch09table02),
    you find that
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 查看表格9.2中的所有交易，你会发现
- en: '*The Hobbit* is in 5/10, or 50% of all transactions.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《霍比特人》*出现在所有交易的5/10，即50%。'
- en: '*The Princess Bride* is in 4/10, or 40% of all transactions.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*《公主新娘》*出现在所有交易的4/10，即40%。'
- en: Both books are checked out together in 3/10, or 30% of all transactions.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两本书一起被借出发生在3/10，即所有交易中的30%。
- en: We’d say the *support* of the itemset {*The Hobbit*, *The Princess Bride*} is
    30%.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会说项目集*{《霍比特人》，*《公主新娘》}*的支持度为30%。
- en: Of the five transactions that include *The Hobbit*, three (3/5 = 60%) also include
    *The Princess Bride*.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在包含*《霍比特人》*的五个交易中，有三个（3/5 = 60%）也包含了*《公主新娘》*。
- en: 'So you can make a rule: “People who check out *The Hobbit* also check out *The
    Princess Bride*.” This rule should be correct (according to your data) 60% of
    the time. We’d say that the *confidence* of the rule is 60%.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以制定一条规则：“借阅《霍比特人》的人也会借阅《公主新娘》。”这条规则应该有60%的正确率（根据你的数据）。我们会说这条规则的**置信度**是60%。
- en: Conversely, of the four times *The Princess Bride* is checked out, *The Hobbit*
    appears three times, or 3/4 = 75% of the time.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相反，在《公主新娘》被借阅的四次中，有三次出现了《霍比特人》，即3/4 = 75%的时间。
- en: So the rule “People who check out *The Princess Bride* also check out *The Hobbit*”
    has 75% confidence.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，规则“借阅《公主新娘》的人也会借阅《霍比特人》”有75%的置信度。
- en: Let's formally define rules, support, and confidence.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们正式定义规则、支持和置信度。
- en: Rules
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 规则
- en: The rule “if X, then Y” means that every time you see the itemset X in a transaction,
    you expect to also see Y (with a given confidence). For the apriori algorithm
    (which we’ll look at in this section), Y is always an itemset with one item.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 规则“如果X，则Y”意味着每次你在交易中看到项目集X时，你期望也会看到Y（给定一定的置信度）。对于本节将要讨论的Apriori算法，Y始终是一个包含一个项目的项目集。
- en: Support
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度
- en: Suppose that your database of transactions is called T, and X is an itemset.
    Then `support(X)` is the number of transactions that contain X divided by the
    total number of transactions in T.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的交易数据库称为T，X是一个项目集。那么`support(X)`是包含X的交易数量除以T中交易的总数。
- en: Confidence
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 置信度
- en: The confidence of the rule “if X, then Y” gives the fraction or percentage of
    the time that a rule is true, relative to how often you see X. In other words,
    if `support(X)` is how often the itemset X occurs in a transaction, and `support({X,
    Y})` is how often both itemsets X and Y occur in a transaction, then the confidence
    of the rule “if X, then Y” is `support({X, Y})/support(X)`.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 规则“如果X，则Y”的置信度给出了规则为真的频率相对于你看到X的频率的分数或百分比。换句话说，如果`support(X)`是项目集X在交易中出现的频率，而`support({X,
    Y})`是项目集X和Y在交易中同时出现的频率，那么规则“如果X，则Y”的置信度是`support({X, Y})/support(X)`。
- en: The goal in association rule mining is to find all the interesting rules in
    the database with at least a given minimum support (say, 10%) and a minimum given
    confidence (say, 60%).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 关联规则挖掘的目标是在数据库中找到所有至少有给定最小支持度（比如说10%）和最小置信度（比如说60%）的有趣规则。
- en: 9.2.2\. The example problem
  id: totrans-363
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2\. 示例问题
- en: '* * *'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Example
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: '*Suppose you work for a bookstore, and you want to recommend books that a customer
    might be interested in, based on all of their previous purchases and book interests.
    You want to use historical book interest information to develop some recommendation
    rules.*'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '*假设你为一家书店工作，你想根据客户的所有先前购买和书籍兴趣推荐他们可能感兴趣的书籍。你希望使用历史书籍兴趣信息来制定一些推荐规则。*'
- en: '* * *'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'You can get information about customers’ book interests two ways: either they’ve
    purchased a book from you, or they’ve rated a book on your website (even if they
    bought the book somewhere else). In this case, a transaction is a customer, and
    an itemset is all the books that they’ve expressed an interest in, either by purchase
    or by rating.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过两种方式获取客户书籍兴趣的信息：要么他们从你这里购买了一本书，要么他们在你的网站上对一本书进行了评分（即使他们在其他地方购买了这本书）。在这种情况下，一个交易是一个客户，一个项目集是他们通过购买或评分表示兴趣的所有书籍。
- en: 'The data that you’ll use is based on data collected in 2004 from the book community
    Book-Crossing^([[1](../Text/09.xhtml#ch09fn4)]) for research conducted at the
    Institut für Informatik, University of Freiburg.^([[2](../Text/09.xhtml#ch09fn5)])
    The information is condensed into a single tab-separated text file called bookdata.tsv.
    Each row of the file consists of a user ID, a book title (which has been designed
    as a unique ID for each book), and the rating (which you won’t actually use in
    this example):'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用的数据是基于2004年从书籍社区Book-Crossing收集的数据（参考文献[1]），用于弗莱堡大学信息学院的研究（参考文献[2]）。信息被压缩成一个单独的制表符分隔的文本文件，称为bookdata.tsv。文件中的每一行包含一个用户ID、一本书的标题（每个书籍都被设计为唯一的ID）和评分（在这个例子中你实际上不会使用评分）：
- en: ¹
  id: totrans-370
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-371
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The original data repository can be found at [http://mng.bz/2052](http://mng.bz/2052).
    Since some artifacts in the original files caused errors when reading into R,
    we’re providing copies of the data as a prepared RData object: [https://github.com/WinVector/PDSwR2/blob/master/Bookdata/bxBooks.RData](https://github.com/WinVector/PDSwR2/blob/master/Bookdata/bxBooks.RData).
    The prepared version of the data that we’ll use in this section is at [https://github.com/WinVector/PDSwR2/blob/master/Bookdata/bookdata.tsv.gz](https://github.com/WinVector/PDSwR2/blob/master/Bookdata/bookdata.tsv.gz).
    Further information and scripts for preparing the data can be found at [https://github.com/WinVector/PDSwR2/tree/master/Bookdata](https://github.com/WinVector/PDSwR2/tree/master/Bookdata).'
  id: totrans-372
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原始数据存储库可以在[http://mng.bz/2052](http://mng.bz/2052)找到。由于原始文件中的一些工件在读取到R时导致错误，我们提供了数据的准备版RData对象：[https://github.com/WinVector/PDSwR2/blob/master/Bookdata/bxBooks.RData](https://github.com/WinVector/PDSwR2/blob/master/Bookdata/bxBooks.RData)。本节中我们将使用的数据的准备版本是[https://github.com/WinVector/PDSwR2/blob/master/Bookdata/bookdata.tsv.gz](https://github.com/WinVector/PDSwR2/blob/master/Bookdata/bookdata.tsv.gz)。有关准备数据的更多信息和相关脚本可以在[https://github.com/WinVector/PDSwR2/tree/master/Bookdata](https://github.com/WinVector/PDSwR2/tree/master/Bookdata)找到。
- en: ²
  id: totrans-373
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ²
- en: ''
  id: totrans-374
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The researchers’ original paper is “Improving Recommendation Lists Through Topic
    Diversification,” Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Konstan, Georg
    Lausen; Proceedings of the 14th International World Wide Web Conference (WWW ’05),
    May 10-14, 2005, Chiba, Japan. It can be found online at [http://mng.bz/7trR](http://mng.bz/7trR).
  id: totrans-375
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 研究者的原始论文是“通过主题多样化改进推荐列表”，Cai-Nicolas Ziegler，Sean M. McNee，Joseph A. Konstan，Georg
    Lausen；第14届国际万维网会议（WWW ‘05），2005年5月10日至14日，日本千叶。可以在[http://mng.bz/7trR](http://mng.bz/7trR)在线找到。
- en: '[PRE25]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `token` column contains lowercase column strings; the tokens were used to
    identify books with different ISBNs (the original book IDs) that had the same
    title except for casing. The `title` column holds properly capitalized title strings;
    these are unique per book, so for this example you will use them as book IDs.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '`token`列包含小写列字符串；这些标记用于识别具有不同ISBN（原始书籍ID）的书籍，这些书籍的标题除了大小写外都相同。`title`列包含正确大写的标题字符串；这些字符串对每本书都是唯一的，因此在这个例子中，你将使用它们作为书籍ID。'
- en: In this format, the transaction (customer) information is diffused through the
    data, rather than being all in one row; this reflects the way the data would naturally
    be stored in a database, since the customer’s activity would be diffused throughout
    time. Books generally come in different editions or from different publishers.
    For this example, we’ve condensed all different versions into a single item; hence,
    different copies or printings of *Little Women* will all map to the same item
    ID in our data (namely, the title “Little Women”).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种格式中，事务（客户）信息通过数据扩散，而不是全部在一个行中；这反映了数据在数据库中自然存储的方式，因为客户的活动会随时间扩散。书籍通常有不同的版本或来自不同的出版商。在这个例子中，我们将所有不同的版本压缩成一个单独的项目；因此，*小妇人*的不同副本或印刷版都将映射到我们数据中的相同项目ID（即标题“小妇人”）。
- en: The original data includes approximately a million ratings of 271,379 books
    from 278,858 readers. Our data will have fewer books due to the mapping that we
    discussed earlier.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据包括大约一百万条来自278,858位读者的271,379本书的评分。由于我们之前讨论的映射，我们的数据将包含更少的书籍。
- en: Now you’re ready to mine.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以开始挖掘了。
- en: 9.2.3\. Mining association rules with the arules package
  id: totrans-381
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3\. 使用arules包挖掘关联规则
- en: You’ll use the package `arules` for association rule mining. `arules` includes
    an implementation of the popular association rule algorithm *apriori*, as well
    as implementations to read in and examine transaction data.^([[1](../Text/09.xhtml#ch09fn6)])
    The package uses special data types to hold and manipulate the data; you’ll explore
    these data types as you work the example.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用`arules`包进行关联规则挖掘。`arules`包括流行的关联规则算法*apriori*的实现，以及读取和检查事务数据的功能。[^[[1](../Text/09.xhtml#ch09fn6)])
    该包使用特殊的数据类型来存储和处理数据；你将在处理示例时探索这些数据类型。
- en: ¹
  id: totrans-383
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-384
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For a more comprehensive introduction to `arules` than we can give in this chapter,
    please see Hahsler, Grin, Hornik, and Buchta, “Introduction to arules—A computational
    environment for mining association rules and frequent item sets,” online at [cran.r-project.org/web/packages/arules/vignettes/arules.pdf](http://cran.r-project.org/web/packages/arules/vignettes/arules.pdf).
  id: totrans-385
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 对于比本章中我们能提供的更全面的`arules`介绍，请参阅Hahsler, Grin, Hornik和Buchta的“arules介绍——挖掘关联规则和频繁项集的计算环境”，在线阅读[cran.r-project.org/web/packages/arules/vignettes/arules.pdf](http://cran.r-project.org/web/packages/arules/vignettes/arules.pdf)。
- en: Reading in the data
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 读取数据
- en: You can read the data directly from the bookdata.tsv.gz file into the object
    `bookbaskets` using the function `read.transactions()`.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接使用`read.transactions()`函数将数据从`bookdata.tsv.gz`文件读取到`bookbaskets`对象中。
- en: Listing 9.18\. Reading in the book data
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.18\. 读取书籍数据
- en: '[PRE26]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ Loads the arules package
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 加载arules包
- en: ❷ Specifies the file and the file format
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 指定文件和文件格式
- en: ❸ Specifies that the input file has a header
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 指定输入文件有标题行
- en: ❹ Specifies the column separator (a tab)
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 指定列分隔符（制表符）
- en: ❺ Specifies the column of transaction IDs and of item IDs, respectively
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 分别指定事务ID和项目ID的列
- en: ❻ Tells the function to look for and remove duplicate entries (for example,
    multiple entries for “The Hobbit” by the same user)
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 告诉函数查找并删除重复条目（例如，同一用户对《霍比特人》的多个条目）
- en: 'The `read.transactions()` function reads data in two formats: the format where
    every row corresponds to a single item (like bookdata.tsv.gz), and a format where
    each row corresponds to a single transaction, possibly with a transaction ID,
    like [table 9.1](../Text/09.xhtml#ch09table01). To read data in the first format,
    use the argument `format = "single"`; to read data in the second format, use the
    argument `format = "basket"`.'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '`read.transactions()`函数以两种格式读取数据：每行对应一个单一物品的格式（如bookdata.tsv.gz），以及每行对应一个单一事务的格式，可能包含事务ID，如[表9.1](../Text/09.xhtml#ch09table01)。要读取第一种格式的数据，请使用`format
    = "single"`参数；要读取第二种格式的数据，请使用`format = "basket"`参数。'
- en: It sometimes happens that a reader will buy one edition of a book and then later
    add a rating for that book under a different edition. Because of the way we’re
    representing books for this example, these two actions will result in duplicate
    entries. The `rm.duplicates = TRUE` argument will eliminate them. It will also
    output some (not too useful) diagnostics about the duplicates.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 有时会发生读者购买一本书的一个版本，然后后来在另一个版本下为该书添加评分的情况。由于我们在这个例子中代表书籍的方式，这两个动作将导致重复条目。`rm.duplicates
    = TRUE`参数将消除它们。它还会输出一些（不太有用）的关于重复项的诊断信息。
- en: Once you’ve read in the data, you can inspect the resulting object.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 读取数据后，您可以检查生成的对象。
- en: Examining the data
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 检查数据
- en: Transactions are represented as a special object called `transactions`. You
    can think of a `transactions` object as a 0/1 matrix, with one row for every transaction
    (in this example, a customer) and one column for every possible item (in this
    example, a book). The matrix entry (*i*, *j*) is 1 if the *i*th transaction contains
    item *j*, or if customer *i* has expressed an interest in book *j*. There are
    a number of calls you can use to examine the transaction data, as the next listing
    shows.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 事务以一个称为`transactions`的特殊对象表示。您可以将`transactions`对象视为一个0/1矩阵，其中每一行代表一个事务（在这个例子中，是一个顾客），每一列代表每一个可能的物品（在这个例子中，是一本书）。矩阵条目(*i*,
    *j*)为1，如果第*i*个事务包含项目*j*，或者如果顾客*i*对书籍*j*表示了兴趣。您可以使用多个调用来检查事务数据，如下一个列表所示。
- en: Listing 9.19\. Examining the transaction data
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.19\. 检查事务数据
- en: '[PRE27]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ The object is of class transactions.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 该对象是`transactions`类。
- en: ❷ Printing the object tells you its dimensions.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 打印对象会告诉你其维度。
- en: ❸ You can also use dim() to see the dimensions of the matrix.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 您也可以使用`dim()`查看矩阵的维度。
- en: ❹ The columns are labeled by book title.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 列标签为书名
- en: ❺ The rows are labeled by customer.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 行标签为顾客
- en: 'You can examine the distribution of transaction sizes (or basket sizes) with
    the function `size()`:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`size()`函数检查事务大小（或篮子大小）的分布：
- en: '[PRE28]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Most customers (at least half of them, in fact) only expressed interest in one
    book. But someone has expressed interest in more than 10,000! You probably want
    to look more closely at the size distribution to see what’s going on.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数顾客（实际上至少有一半）只对一本书表示了兴趣。但有人对超过10,000本书表示了兴趣！您可能想更仔细地查看大小分布，看看发生了什么。
- en: Listing 9.20\. Examining the size distribution
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 列表9.20\. 检查大小分布
- en: '[PRE29]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: ❶ Looks at the basket size distribution, in 10% increments
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 查看购物篮大小分布，以 10% 的增量
- en: ❷ Plots the distribution to get a better look
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 绘制分布图以获得更好的观察
- en: '[Figure 9.18](../Text/09.xhtml#ch09fig18) shows the distribution of basket
    sizes. 90% of customers expressed interest in fewer than 15 books; most of the
    remaining customers expressed interest in up to about 100 books or so; the call
    `quantile(basketSizes, probs = c(0.99, 1))` will show you that 99% of customers
    expressed interest in 179 books or fewer. Still, a few people have expressed interest
    in several hundred, or even several thousand books.'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 9.18](../Text/09.xhtml#ch09fig18) 显示了购物篮大小的分布。90% 的客户对少于 15 本书表示了兴趣；大多数剩余的客户对大约
    100 本书或更少的书籍表示了兴趣；调用 `quantile(basketSizes, probs = c(0.99, 1))` 将显示 99% 的客户对
    179 本书或更少的书籍表示了兴趣。尽管如此，仍有少数人对几百本甚至几千本书表示了兴趣。'
- en: Figure 9.18\. A density plot of basket sizes
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.18\. 购物篮大小的密度图
- en: '![](Images/09fig18_alt.jpg)'
  id: totrans-417
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/09fig18_alt.jpg)'
- en: Which books are they reading? The function `itemFrequency()` can tell you how
    often each book shows up in the transaction data.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 他们都读了哪些书？函数 `itemFrequency()` 可以告诉你每本书在交易数据中出现的频率。
- en: Listing 9.21\. Counting how often each book occurs
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.21\. 计算每本书出现的频率
- en: '[PRE30]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: You can also find the 10 most frequently occurring books.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以找到出现频率最高的 10 本书。
- en: Listing 9.22\. Finding the 10 most frequently occurring books
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.22\. 找到出现频率最高的 10 本书
- en: '[PRE31]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: ❶ Sorts the counts in decreasing order
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 按计数降序排序
- en: ❷ Displays the top 10 books in a nice format
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 以良好的格式显示前 10 本书籍
- en: ❸ The most popular book in the dataset occurred in fewer than 3% of the baskets.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 数据集中最受欢迎的书籍出现在少于 3% 的购物篮中。
- en: 'The last observation in the preceding listing highlights one of the issues
    with mining high-dimensional data: when you have thousands of variables, or thousands
    of items, almost every event is rare. Keep this point in mind when deciding on
    support thresholds for rule mining; your thresholds will often need to be quite
    low.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的列表中的最后一个观察结果突出了挖掘高维数据时的问题之一：当你有成千上万的变量或项目时，几乎每个事件都是罕见的。在决定规则挖掘的支持度阈值时，请记住这一点；你的阈值通常需要相当低。
- en: 'Before we get to the rule mining, let’s refine the data a bit more. As you
    observed earlier, half of the customers in the data only expressed interest in
    a single book. Since you want to find books that occur together in people’s interest
    lists, you can’t make any direct use of people who haven’t yet shown interest
    in multiple books. You can restrict the dataset to customers who have expressed
    interest in at least two books:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进行规则挖掘之前，让我们进一步精炼数据。正如你之前观察到的，数据中的半数客户只对一本书表示了兴趣。由于你想要找到在人们兴趣列表中一起出现的书籍，你不能直接使用那些尚未对多本书表示兴趣的人。你可以将数据集限制为至少对两本书表示过兴趣的客户：
- en: '[PRE32]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Now you’re ready to look for association rules.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经准备好寻找关联规则了。
- en: The apriori() function
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: apriori() 函数
- en: In order to mine rules, you need to decide on a minimum support level and a
    minimum threshold level. For this example, let’s try restricting the itemsets
    that we’ll consider to those with a minimum support of 0.2%, or 0.002\. This corresponds
    to itemsets that appear at least `0.002 * nrow(bookbaskets_use)` times, which
    is about 82 transactions. We’ll use a confidence threshold of 75%.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 为了挖掘规则，你需要决定一个最小支持度水平和最小阈值水平。对于这个例子，让我们尝试将我们考虑的项目集限制在最小支持度为 0.2%，或 0.002。这对应于至少出现
    `0.002 * nrow(bookbaskets_use)` 次的项目集，大约是 82 笔交易。我们将使用 75% 的置信度阈值。
- en: Listing 9.23\. Finding the association rules
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.23\. 寻找关联规则
- en: '[PRE33]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ Calls apriori() with a minimum support of 0.002 and a minimum confidence of
    0.75
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用最小支持度 0.002 和最小置信度 0.75 调用 apriori()
- en: ❷ The number of rules found
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 找到的规则数量
- en: ❸ The distribution of rule lengths (in this example, most rules contain 3 items—2
    on the left side, X (lhs), and one on the right side, Y (rhs))
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 规则长度的分布（在这个例子中，大多数规则包含 3 个项目——左侧 2 个，X（lhs），右侧 1 个，Y（rhs））
- en: ❹ A summary of rule quality measures, including support and confidence
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 规则质量度量总结，包括支持度和置信度
- en: ❺ Some information on how apriori() was called
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 关于如何调用 apriori() 的相关信息
- en: The quality measures on the rules include a rule’s support and confidence, the
    support count (how many transactions the rule applied to), and a quantity called
    *lift*. Lift compares the frequency of an observed pattern with how often you’d
    expect to see that pattern just by chance. The lift of a rule “if X, then Y” is
    given by `support({X, Y}) / (support(X) * support(Y))`. If the lift is near 1,
    then there’s a good chance that the pattern you observed is occurring just by
    chance. The larger the lift, the more likely that the pattern is “real.” In this
    case, all the discovered rules have a lift of at least 40, so they’re likely to
    be real patterns in customer behavior.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 规则的质量度量包括规则的支持度和置信度、支持度计数（规则应用到的交易数量），以及一个称为 *提升度* 的量。提升度比较观察到的模式的频率与仅通过偶然看到该模式频率的期望。规则“如果
    X，则 Y”的提升度由 `support({X, Y}) / (support(X) * support(Y))` 给出。如果提升度接近 1，那么观察到的模式仅通过偶然发生的可能性很大。提升度越大，模式是“真实”的可能性就越大。在这种情况下，所有发现的规则提升度至少为
    40，因此它们很可能是客户行为的真实模式。
- en: Inspecting and evaluating rules
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 检查和评估规则
- en: 'There are also other metrics and interest measures you can use to evaluate
    the rules by using the function `interestMeasure()`. We’ll look at two of these
    measures: `coverage` and `fishersExactTest`. *Coverage* is the support of the
    left side of the rule (X); it tells you how often the rule would be applied in
    the dataset. *Fisher’s exact test* is a significance test for whether an observed
    pattern is real or chance (the same thing lift measures; Fisher’s test is more
    formal). Fisher’s exact test returns the p-value, or the probability that you
    would see the observed pattern by chance; you want the p-value to be small.'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用其他指标和兴趣度量来通过 `interestMeasure()` 函数评估规则。我们将查看其中两个度量：`coverage` 和 `fishersExactTest`。*覆盖率*
    是规则左侧（X）的支持度；它告诉您规则在数据集中会被应用多少次。*费舍尔精确检验* 是一个用于检验观察到的模式是真实还是偶然（与提升度测量的相同；费舍尔检验更为正式）的显著性检验。费舍尔精确检验返回
    p 值，即您偶然看到观察到的模式的概率；您希望 p 值很小。
- en: Listing 9.24\. Scoring rules
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.24\. 评分规则
- en: '[PRE34]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: ❶ The first argument to interestMeasure() is the discovered rules.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ `interestMeasure()` 的第一个参数是发现的规则。
- en: ❷ The second argument is a list of interest measures to apply.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 第二个参数是应用兴趣度量的列表。
- en: ❸ The last argument is a dataset to evaluate the interest measures over. This
    is usually the same set used to mine the rules, but it needn’t be. For instance,
    you can evaluate the rules over the full dataset, bookbaskets, to get coverage
    estimates that reflect all the customers, not just the ones who showed interest
    in more than one book.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 最后一个参数是用于评估兴趣度量的数据集。这通常是用于挖掘规则的相同集合，但不必如此。例如，您可以在整个数据集 `bookbaskets` 上评估规则，以获得反映所有客户的覆盖率估计，而不仅仅是那些对多本书表示兴趣的客户。
- en: The coverage of the discovered rules ranges from 0.002–0.007, equivalent to
    a range of about 82–286 people. All the p-values from Fisher’s test are small,
    so it’s likely that the rules reflect actual customer behavior patterns.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 发现的规则覆盖率范围在 0.002–0.007 之间，相当于大约 82–286 人的范围。所有费舍尔检验的 p 值都很小，因此这些规则很可能反映了实际的客户行为模式。
- en: You can also call `interestMeasure()` with the methods `support`, `confidence`,
    and `lift`, among others. This would be useful in our example if you wanted to
    get support, confidence, and lift estimates for the full dataset `bookbaskets`,
    rather than the filtered dataset `bookbaskets_use`—or for a subset of the data,
    for instance, only customers from the United States.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用 `interestMeasure()` 函数，通过 `support`、`confidence` 和 `lift` 等方法进行调用。在我们的例子中，如果您想为整个数据集
    `bookbaskets` 获取支持度、置信度和提升度估计，而不是过滤后的数据集 `bookbaskets_use`——或者对于数据的一个子集，例如，仅限于美国客户，这将是有用的。
- en: The function `inspect()` pretty-prints the rules. The function `sort()` allows
    you to sort the rules by a quality or interest measure, like confidence. To print
    the five most confident rules in the dataset, you could use the following statement,
    which we will expand out using pipe notation.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 `inspect()` 会美化打印规则。函数 `sort()` 允许您根据质量或兴趣度量对规则进行排序，例如置信度。要打印数据集中最自信的五个规则，可以使用以下语句，我们将使用管道符号进行扩展。
- en: Listing 9.25\. Getting the five most confident rules
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.25\. 获取最自信的五个规则
- en: '[PRE35]'
  id: totrans-452
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: ❶ Attaches magrittr to get pipe notation
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用 magrittr 添加管道符号
- en: ❷ Sorts rules by confidence
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 按置信度排序规则
- en: ❸ Gets the first five rules
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 获取前五个规则
- en: ❹ Calls inspect() to pretty-print the rules
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 调用 inspect() 函数以美化打印规则
- en: For legibility, we show the output of this command in [table 9.3](../Text/09.xhtml#ch09table03).
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高可读性，我们将此命令的输出显示在 [表 9.3](../Text/09.xhtml#ch09table03) 中。
- en: Table 9.3\. The five most confident rules discovered in the data
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9.3\. 数据中发现的最自信的五个规则
- en: '| Left side | Right side | Support | Confidence | Lift | Count |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| 左侧 | 右侧 | 支持度 | 自信度 | 升值 | 数量 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| *Four to Score* *High Five* *Seven Up* *Two for the Dough* | *Three to Get
    Deadly* | 0.002 | 0.988 | 165 | 84 |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| *四到得分* *高五* *七上* *两块面包* | *三到致命* | 0.002 | 0.988 | 165 | 84 |'
- en: '| *Harry Potter and the Order of the Phoenix* *Harry Potter and the Prisoner
    of Azkaban* *Harry Potter and the Sorcerer’s Stone* | *Harry Potter and the Chamber
    of Secrets* | 0.003 | 0.966 | 73 | 117 |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| *哈利·波特与凤凰社* *哈利·波特与阿兹卡班的囚徒* *哈利·波特与魔法石* | *哈利·波特与密室* | 0.003 | 0.966 | 73
    | 117 |'
- en: '| *Four to Score* *High Five* *One for the Money* *Two for the Dough* | *Three
    to Get Deadly* | 0.002 | 0.966 | 162 | 85 |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| *四到得分* *高五* *一美元一把* *两块面包* | *三到致命* | 0.002 | 0.966 | 162 | 85 |'
- en: '| *Four to Score* *Seven Up* *Three to Get Deadly* *Two for the Dough* | *High
    Five* | 0.002 | 0.966 | 181 | 84 |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| *四到得分* *七上* *三到致命* *两块面包* | *高五* | 0.002 | 0.966 | 181 | 84 |'
- en: '| *High Five* *Seven Up* *Three to Get Deadly* *Two for the Dough* | *Four
    to Score* | 0.002 | 0.966 | 168 | 84 |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| *高五* *七上* *三到致命* *两块面包* | *四到得分* | 0.002 | 0.966 | 168 | 84 |'
- en: 'There are two things to notice in [table 9.3](../Text/09.xhtml#ch09table03).
    First, the rules concern books that come in series: the numbered series of novels
    about bounty hunter Stephanie Plum, and the Harry Potter series. So these rules
    essentially say that if a reader has read four Stephanie Plum or three Harry Potter
    books, they’re almost sure to buy another one.'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [表 9.3](../Text/09.xhtml#ch09table03) 中有两个需要注意的地方。首先，这些规则涉及的是系列书籍：关于赏金猎人斯蒂芬妮·普卢的编号系列小说，以及哈利·波特系列。因此，这些规则本质上表明，如果一个读者读过四本斯蒂芬妮·普卢或三本哈利·波特的书，他们几乎肯定会再买一本。
- en: The second thing to notice is that rules 1, 4, and 5 are permutations of the
    same itemset. This is likely to happen when the rules get long.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个要注意的是，规则 1、4 和 5 是相同项目集的排列。当规则变长时，这种情况很可能会发生。
- en: Restricting which items to mine
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 限制挖掘的项目
- en: You can restrict which items appear in the left side or right side of a rule.
    Suppose you’re interested specifically in books that tend to co-occur with the
    novel *The Lovely Bones*. You can do this by restricting which books appear on
    the right side of the rule, using the `appearance` parameter.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以限制规则左侧或右侧出现的项目。假设你特别感兴趣的是那些倾向于与小说 *The Lovely Bones* 同时出现的书籍。你可以通过限制规则右侧出现的书籍来实现这一点，使用
    `appearance` 参数。
- en: Listing 9.26\. Finding rules with restrictions
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.26\. 带限制条件的规则查找
- en: '[PRE36]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: ❶ Relaxes the minimum support to 0.001 and the minimum confidence to 0.6
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将最小支持度放宽到 0.001，最小置信度放宽到 0.6
- en: ❷ Only “The Lovely Bones” is allowed to appear on the right side of the rules.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 规则的右侧只允许出现“《骨之恋》”。
- en: ❸ By default, all the books can go into the left side of the rules.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 默认情况下，所有书籍都可以进入规则的左侧。
- en: The supports, confidences, counts, and lifts are lower than they were in our
    previous example, but the lifts are still much greater than one, so it’s likely
    that the rules reflect real customer behavior patterns.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 支持度、置信度、数量和升值都比我们之前的例子低，但升值仍然远大于一，因此这些规则很可能反映了真实的客户行为模式。
- en: Let’s inspect the rules, sorted by confidence. Since they’ll all have the same
    right side, you can use the `lhs()` function to only look at the left sides.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查按置信度排序的规则。由于它们都将有相同的右侧，你可以使用 `lhs()` 函数只查看左侧。
- en: Listing 9.27\. Inspecting rules
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.27\. 规则检查
- en: '[PRE37]'
  id: totrans-478
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: ❶ Gets the left-hand side of the sorted rules
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取排序规则的左侧
- en: 'Note that four of the five most confident rules include *Lucky: A Memoir* in
    the left side, which perhaps isn’t surprising, since *Lucky* was written by the
    author of *The Lovely Bones*. Suppose you want to find out about works by other
    authors that are interesting to people who showed interest in *The Lovely Bones*;
    you can use `subset()` to filter down to only rules that don’t include *Lucky*.'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '注意，五个最自信的规则中有四个包括左侧的 *Lucky: A Memoir*，这可能并不令人惊讶，因为 *Lucky* 是 *The Lovely Bones*
    的作者所写。假设你想了解其他作者的作品，这些作品对那些对 *The Lovely Bones* 感兴趣的人也很有趣；你可以使用 `subset()` 函数来筛选出不包括
    *Lucky* 的规则。'
- en: Listing 9.28\. Inspecting rules with restrictions
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 9.28\. 带限制条件的规则检查
- en: '[PRE38]'
  id: totrans-482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: ❶ Restricts to the subset of rules where Lucky is not in the left side
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 限制为不包含Lucky在左侧的规则子集
- en: These examples show that association rule mining is often highly interactive.
    To get interesting rules, you must often set the support and confidence levels
    fairly low; as a result, you can get many, many rules. Some rules will be more
    interesting or surprising to you than others; to find them requires sorting the
    rules by different interest measures, or perhaps restricting yourself to specific
    subsets of rules.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子表明，关联规则挖掘通常是高度交互的。为了得到有趣的规则，你通常必须将支持度和置信度水平设置得相当低；结果，你可以得到许多许多规则。有些规则可能比你想象的更有趣或更令人惊讶；要找到它们，需要按不同的兴趣度量对规则进行排序，或者可能限制自己只关注特定的规则子集。
- en: 9.2.4\. Association rule takeaways
  id: totrans-485
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.4. 关联规则要点
- en: 'You''ve now walked through an example of using association rules to explore
    common patterns in purchase data. Here’s what you should remember about association
    rules:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经通过一个使用关联规则来探索购买数据中常见模式的例子。以下是关于关联规则你应该记住的几点：
- en: 'The goal of association rule mining is to find relationships in the data: items
    or attributes that tend to occur together.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则挖掘的目标是在数据中找到关系：倾向于一起出现的项目或属性。
- en: A good rule “if X then Y” should occur more often than you’d expect to observe
    by chance. You can use lift or Fisher’s exact test to check if this is true.
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个好的规则“如果X，则Y”应该比偶然观察到的频率更高。你可以使用提升或Fisher的精确检验来检查这是否成立。
- en: When it's possible for a large number of different items to be in a basket (in
    our example, thousands of different books), most events will be rare (have low
    support).
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当大量不同项目可能出现在篮子里（在我们的例子中，成千上万的不同书籍）时，大多数事件将是罕见的（支持度低）。
- en: Association rule mining is often interactive, as there can be many rules to
    sort and sift through.
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关联规则挖掘通常是交互式的，因为可能有许多规则需要排序和筛选。
- en: Summary
  id: totrans-491
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you’ve learned how to find similarities in data using two different
    clustering methods in R, and how to find items that tend to occur together in
    data using association rules. You’ve also learned how to evaluate your discovered
    clusters and your discovered rules.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何使用R中的两种不同的聚类方法来寻找数据中的相似性，以及如何使用关联规则来寻找数据中倾向于一起出现的项目。你还学习了如何评估你发现的集群和规则。
- en: Unsupervised methods like the ones we’ve covered in this chapter are really
    more exploratory in nature. Unlike with supervised methods, there’s no “ground
    truth” to evaluate your findings against. But the findings from unsupervised methods
    can be the starting point for more-focused experiments and modeling.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们介绍的无监督方法实质上更具有探索性。与监督方法不同，没有“真实情况”来评估你的发现。但无监督方法的发现可以成为更专注的实验和建模的起点。
- en: In the last few chapters, we’ve covered the most basic modeling and data analysis
    techniques; they’re all good first approaches to consider when you’re starting
    a new project. In the next chapter, we’ll touch on a few more-advanced methods.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后几章中，我们介绍了最基本建模和数据分析技术；它们都是当你开始一个新项目时值得考虑的良好起点。在下一章中，我们将触及一些更高级的方法。
- en: In this chapter you have learned
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 本章你学到了
- en: How to cluster unlabeled data, using both hierarchical methods and k-means
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用层次方法和k-means对无标签数据进行聚类
- en: How to estimate what the appropriate number of clusters should be
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何估计合适的聚类数量
- en: How to evaluate an existing clustering for cluster stability
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何评估现有聚类的聚类稳定性
- en: How to find patterns (association rules) in transaction data using apriori
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用apriori在事务数据中找到模式（关联规则）
- en: How to evaluate and sort through discovered association rules
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何评估和筛选发现的关联规则
