- en: 12 Toward responsiveness with load and chaos testing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 通过负载和混沌测试实现响应性
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Simulating users with Locust
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Locust 模拟用户
- en: Load testing HTTP endpoints with Hey
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Hey 进行 HTTP 端点负载测试
- en: Chaos testing with Pumba
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pumba 进行混沌测试
- en: Mitigating failures with explicit timeouts, circuit breakers, and caches
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用显式超时、断路器和缓存来减轻故障
- en: 'We have now covered all the important technical parts of the 10k steps challenge
    application: how to build web APIs, web applications, and edge services, and how
    to use databases and perform event-stream processing. By using Vert.x’s asynchronous
    and reactive programming, we can expect the set of services that form the application
    to be *reactive* : scalable as workloads grow and resilient as failures happen.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经涵盖了 10k 步挑战应用程序的所有重要技术部分：如何构建 Web API、Web 应用程序和边缘服务，以及如何使用数据库和执行事件流处理。通过使用
    Vert.x 的异步和响应式编程，我们可以期待构成应用程序的服务集是 *响应式的*：随着工作负载的增长而可扩展，并在发生故障时具有弹性。
- en: Are the services that we built actually reactive? Let’s discover that now through
    testing and experimentation, and see where we can make improvements toward being
    reactive.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建的服务实际上是否是响应式的？现在让我们通过测试和实验来发现这一点，并看看我们可以在哪些方面做出改进以实现响应式。
- en: To do that, we will use load testing tools to stress services and measure latencies.
    We will then add failures using chaos testing tools to see how this impacts the
    service behaviors, and we will discuss several options for fixing the problems
    that we identify. You will be able to apply this methodology in your own projects
    too.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们将使用负载测试工具来对服务进行压力测试并测量延迟。然后，我们将使用混沌测试工具添加故障，以查看这如何影响服务行为，并将讨论几种修复我们识别出的问题的选项。您也将能够在自己的项目中应用这种方法。
- en: Software versions
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 软件版本
- en: 'The chapter was written and tested with the following tool versions:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是用以下工具版本编写和测试的：
- en: Locust 1.0.3
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Locust 1.0.3
- en: Python 3.8.2
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.8.2
- en: Hey 0.1.3
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hey 0.1.3
- en: Pumba 0.7.2
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pumba 0.7.2
- en: '12.1 Initial experiments: Is the performance any good?'
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 初始实验：性能是否良好？
- en: This chapter is extensively based on experiments, so we need to generate some
    workloads to assess how the application copes with demanding workloads and failures.
    There are many load testing tools, and it is not always easy to pick one. Some
    tools are very good at stressing a service with a specific request (e.g., “What
    is the latency when issuing 500 requests per second to /api/hello”). Some tools
    provide more flexibility by offering scripting capabilities (e.g., “Simulate a
    user that logs in, then adds items to a cart, then perform a purchase”). And finally,
    some tools do all of that, but the reported metrics may be inaccurate due to how
    such tools are implemented.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章大量基于实验，因此我们需要生成一些工作负载来评估应用程序如何应对繁重的工作负载和故障。有许多负载测试工具，而且并不总是容易选择一个。有些工具在针对特定请求（例如，“每秒发送
    500 个请求到 /api/hello 的延迟是多少”）对服务进行压力测试方面非常出色。有些工具通过提供脚本功能提供了更多的灵活性（例如，“模拟一个登录的用户，然后向购物车添加项目，然后执行购买”）。最后，有些工具做了所有这些，但由于这些工具的实现方式，报告的指标可能不准确。
- en: 'I have chosen two popular and easy-to-use tools to use in this chapter:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经选择了两个流行且易于使用的工具在本章中使用：
- en: '*Locust* --A versatile load testing tool that simulates users through scripts
    written in Python ([https://locust.io/](https://locust.io/))'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Locust* --一个多功能的负载测试工具，通过用 Python 编写的脚本模拟用户 ([https://locust.io/](https://locust.io/))'
- en: '*Hey* --A reliable HTTP load generator ([https://github.com/rakyll/hey](https://github.com/rakyll/hey))'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Hey* --一个可靠的 HTTP 负载生成器 ([https://github.com/rakyll/hey](https://github.com/rakyll/hey))'
- en: These two tools can be used together, or not. Locust allows us to simulate a
    representative workload of users interacting with the application, while Hey give
    us precise metrics of how specific HTTP endpoints behave under stress.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个工具可以一起使用，也可以单独使用。Locust 允许我们通过用 Python 编写的脚本模拟与应用程序交互的用户的工作负载，而 Hey 则为我们提供了在压力下特定
    HTTP 端点行为的精确指标。
- en: Tip Both Locust and Hey work on Linux, macOS, and Windows. As usual, if you
    are a Windows user, I recommend that you use the Windows Subsystem for Linux (WSL).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士：Both Locust 和 Hey 都在 Linux、macOS 和 Windows 上工作。通常，如果您是 Windows 用户，我建议您使用
    Windows Subsystem for Linux (WSL)。
- en: 12.1.1 Some considerations before load testing
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.1 负载测试前的考虑事项
- en: Before we run a load testing tool, I’d like to discuss a few points that have
    to be considered to get representative results. Most importantly, we need to interpret
    them with care.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们运行负载测试工具之前，我想讨论一些必须考虑的点，以确保获得具有代表性的结果。最重要的是，我们需要谨慎地解释它们。
- en: First, when you run the 10k steps application as outlined in chapter 7, all
    services are running locally, while the third-party middleware and services are
    running in Docker containers. This means that everything is actually running on
    the same machine, avoiding real network communications. For instance, when the
    user profile service talks to MongoDB, it goes through virtual network interfaces,
    but it never reaches an actual network interface, so there is no fluctuating latency
    or data loss. We will use other tools later in this chapter to simulate network
    problems and get a more precise understanding of how our services behave.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，当你按照第7章概述的方式运行10k步骤应用时，所有服务都在本地运行，而第三方中间件和服务则在Docker容器中运行。这意味着实际上所有内容都在同一台机器上运行，避免了真正的网络通信。例如，当用户配置文件服务与MongoDB通信时，它将通过虚拟网络接口进行，但永远不会达到实际的网络接口，因此没有波动延迟或数据丢失。我们将在本章后面使用其他工具来模拟网络问题，并更精确地了解我们的服务行为。
- en: Next, there is a good chance that you will be performing these experiments on
    your laptop or desktop. Keep in mind that a real server is different from your
    workstation, both in terms of hardware and software configurations, so you will
    likely perform tests with lower workloads than the services could actually cope
    with in a production setting. For instance, when we use PostgreSQL directly from
    a container, we won’t have done any tuning, which we would do in a production
    setting. More generally, running the middleware services from containers is convenient
    for development purposes, but we would run them differently in production, with
    or without containers. Also note that we will be running the Vert.x-based services
    without any JVM tuning. In a production setting, you’d need to at least adjust
    memory settings and tune the garbage collector.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你很可能会在你的笔记本电脑或台式机上执行这些实验。记住，真实的服务器在硬件和软件配置方面都不同于你的工作站，因此你可能会进行低于服务在生产环境中实际能够处理的负载测试。例如，当我们直接从容器中使用PostgreSQL时，我们不会进行任何调整，这在生产环境中我们会进行。更普遍地说，从容器中运行中间件服务对于开发目的来说很方便，但在生产中我们会以不同的方式运行它们，无论是否使用容器。此外，请注意，我们将不进行任何JVM调整来运行基于Vert.x的服务。在生产环境中，你至少需要调整内存设置并调整垃圾收集器。
- en: Also, each service will run as a single instance, and verticles will also be
    single instances. They have all been designed to work with multiple instances,
    but deploying, say, two instances of the ingestion service would also require
    deploying an HTTP reverse proxy to distribute traffic between the two instances.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每个服务都将作为一个单独的实例运行，verticles也将是单个实例。它们都已被设计为可以与多个实例一起工作，但部署，比如说，两个摄入服务的实例，也要求部署一个HTTP反向代理来在两个实例之间分配流量。
- en: 'Last but not least, it is preferable that you run load tests with two machines:
    one to run the application, and one to run a load testing tool. You can perform
    the tests on a single machine if that is more convenient for you, but keep these
    points in mind:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，最好使用两台机器来运行负载测试：一台运行应用程序，另一台运行负载测试工具。如果你更方便的话，你可以在单台机器上执行测试，但请记住这些要点：
- en: You will not go through the network, which affects results.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将不会通过网络，这会影响结果。
- en: Both the services under test and the load testing tool will compete for operating
    system resources (CPU time, networking, open file descriptors, etc.), which also
    affects the results.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 被测试的服务和负载测试工具将竞争操作系统资源（CPU时间、网络、打开的文件描述符等），这也影响结果。
- en: The results that I present in this chapter are based on experiments conducted
    with two Apple MacBook laptops, which hardly qualify as production-grade servers.
    I am also using a domestic WiFi network, which is not as good as an Ethernet wired
    connection, especially when it comes to having a stable latency. Finally, macOS
    has very low limits on the number of file descriptors that a process can open
    (256), so I had to raise them with the `ulimit` command to run the services and
    the load testing tools--otherwise errors unrelated to the services’ code can arise
    because too many connections have been opened. I will show you how to do that,
    and depending on your system, you will likely have to use this technique to run
    the experiments.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我在本章中展示的结果是基于使用两台苹果 MacBook 笔记本电脑进行的实验，这些电脑几乎不能算作是生产级的服务器。我还使用了一个家庭 WiFi 网络，这不如以太网有线连接好，尤其是在稳定延迟方面。最后，macOS
    对进程可以打开的文件描述符数量有非常低的限制（256），因此我必须使用 `ulimit` 命令来提高这些服务和负载测试工具的限制，否则可能会因为打开太多连接而产生与服务代码无关的错误。我将向您展示如何做到这一点，并且根据您的系统，您可能需要使用这种技术来运行实验。
- en: 12.1.2 Simulating users with Locust
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.2 使用 Locust 模拟用户
- en: Locust is a tool for generating workloads by simulating users interacting with
    a service. You can use it for demonstrations, tests, and measuring performance.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Locust 是一个通过模拟用户与服务交互来生成工作负载的工具。您可以使用它进行演示、测试和性能测量。
- en: You will need a recent version of Python on your machine. If you are new to
    Python, you can read Naomi Ceder’s *Exploring Python Basics* (Manning, 2019) or
    look through one of the many tutorials online. At the time of writing, I am using
    Python 3.8.2.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您的机器上需要安装 Python 的最新版本。如果您是 Python 新手，您可以阅读 Naomi Ceder 的 *Exploring Python
    Basics*（Manning，2019）或浏览网上众多的教程。在撰写本文时，我使用的是 Python 3.8.2。
- en: You can install Locust by running `pip install locust` on the command line,
    where `pip` is the standard Python package manager.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在命令行中运行 `pip install locust` 来安装 Locust，其中 `pip` 是标准的 Python 软件包管理器。
- en: 'The Locust file that we will use is locustfile.py, and it can be found in the
    part2-steps-challenge/load-testing folder of the book’s Git repository. We will
    be simulating the user behaviors illustrated in figure 12.1:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要使用的 Locust 文件是 locustfile.py，它可以在书的 Git 仓库的 part2-steps-challenge/load-testing
    文件夹中找到。我们将模拟图 12.1 中展示的用户行为：
- en: Each new user is generated from random data and a set of predefined cities.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个新用户都是通过随机数据和一组预定义的城市生成的。
- en: A newly created user registers itself through the public API.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新创建的用户通过公共 API 进行注册。
- en: 'A user fetches a JWT token on the first request after having been registered,
    and then periodically makes requests:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户在注册后的第一次请求中获取 JWT 令牌，然后定期发送请求：
- en: The user sends step updates (80% of its requests).
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户发送步数更新（其请求的 80%）。
- en: The user fetches its profile data (5% of its requests).
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户获取其个人资料数据（其请求的 5%）。
- en: The user fetches its total steps count (5% of its requests).
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户获取其总步数（其请求的 5%）。
- en: The user fetches its steps count for the current day (10% of its requests).
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户获取当前日期的步数（其请求的 10%）。
- en: 'This activity covers most of the services: ingesting triggers event exchanges
    between most services, and API queries trigger calls to the activity and user
    profile services.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这种活动涵盖了大多数服务：触发事件交换，以及 API 查询触发对活动和服务用户资料的调用。
- en: '![](../Images/CH12_F01_Ponge.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F01_Ponge.png)'
- en: Figure 12.1 Activity of a simulated user in Locust
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.1 Locust 中模拟用户的活动
- en: The locustfile.py file defines two classes. `UserBehavior` defines the tasks
    performed by a user, and `UserWithDevice` runs these tasks with a random delay
    between 0.5 and 2 seconds. This is a relatively short delay between requests to
    increase the overall number of requests per second.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: locustfile.py 文件定义了两个类。`UserBehavior` 定义了用户执行的任务，而 `UserWithDevice` 则在 0.5 到
    2 秒的随机延迟之间运行这些任务。这是请求之间的相对较短延迟，以增加每秒请求的整体数量。
- en: 'There are two parameters for running a test with Locust:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 Locust 测试有两个参数：
- en: The number of users to simulate
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要模拟的用户数量
- en: The hatch rate, which is the number of new users to create per second during
    the initial ramp-up phase
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 孵化率，即在初始爬坡阶段每秒创建的新用户数量
- en: As described in chapter 7, you need to run the container services with Docker
    Compose from the part2-steps-challenge folder using `docker-compose up` in a terminal.
    Then you can run all Vert.x-based services in another terminal. You can use `foreman
    start` if you have foreman installed, or you can run all services using the commands
    in the Procfile.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如第7章所述，你需要从part2-steps-challenge文件夹中使用终端中的`docker-compose up`命令运行容器服务。然后你可以在另一个终端中运行所有基于Vert.x的服务。如果你安装了foreman，可以使用`foreman
    start`，或者可以使用Procfile中的命令运行所有服务。
- en: The following listing shows the command to perform an initial warm-up run.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了执行初始预热运行的命令。
- en: Listing 12.1 Locust warm-up run
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.1 Locust预热运行
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Raise the number of open file descriptors to 10,000 per process.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将每个进程的打开文件描述符数量提高到10,000个。
- en: ❷ Do not start the Locust web interface.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 不要启动Locust的Web界面。
- en: ❸ Replace this with the IP address of the machine running the services (or in
    the worst case, use localhost).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将此替换为运行服务的机器的IP地址（或者在最坏的情况下，使用localhost）。
- en: ❹ 50 clients, 1 new client per second, 3 minutes of execution
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 50个客户端，每秒1个新客户端，执行3分钟
- en: It is important to do such a warm-up run because the JVM running the various
    services needs to have some workload before it can start to run code efficiently.
    After that, you can run a bigger workload to get a first estimation of how your
    services are going.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 进行这样的预热运行很重要，因为运行各种服务的JVM需要在开始高效运行代码之前有一些工作负载。之后，你可以运行更大的工作负载，以获得对你服务性能的第一估计。
- en: The following listing shows the command to run a test for 5 minutes with 150
    clients and a hatch rate of 2 new users per second.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了运行5分钟测试的命令，使用150个客户端和每秒2个新用户的孵化率。
- en: Listing 12.2 Locust run
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.2 Locust运行
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Output the result to CSV files.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将结果输出到CSV文件中。
- en: Let’s run the experiment and collect results. We’ll get various metrics on each
    type of request, such as the average response time, the minimum/maximum times,
    the median time, and so on. An interesting metric is the latency given a percentile.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行实验并收集结果。我们将得到每种类型请求的各种指标，例如平均响应时间、最小/最大时间、中位数时间等。一个有趣的指标是给定百分比的延迟。
- en: Let’s take the example of the latency at the 80th percentile. This is the maximum
    latency observed for 80% of the requests. If that latency is 100 ms, it means
    that 80% of the requests took less than 100 ms. Similarly, if the 95th percentile
    latency is 150 ms, it means that 95% of the requests took at most 150 ms. The
    100th percentile reveals the worst case observed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以第80百分位的延迟为例。这是80%的请求观察到的最大延迟。如果这个延迟是100毫秒，这意味着80%的请求花费的时间少于100毫秒。同样，如果第95百分位的延迟是150毫秒，这意味着95%的请求花费的时间最多为150毫秒。第100百分位揭示了观察到的最坏情况。
- en: When measuring performance, we are often interested in the latencies between
    the 95th and 100th percentiles. Suppose that latency at the 90th percentile is
    50 ms, but it’s 3 s at the 95th percentile and 20 s at the 99th percentile. In
    such a case, we clearly have a performance problem, because we observe a large
    share of bad latencies. By contrast, observing a latency of 50 ms at the 90th
    percentile and 70 ms at the 99th percentile shows a service with very consistent
    behavior.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在测量性能时，我们通常对第95百分位和第100百分位之间的延迟感兴趣。假设第90百分位的延迟是50毫秒，但在第95百分位是3秒，在第99百分位是20秒。在这种情况下，我们明显存在性能问题，因为我们观察到大量不良延迟。相比之下，在第90百分位观察到50毫秒的延迟，在第99百分位观察到70毫秒的延迟，表明服务具有非常一致的行为。
- en: The latency distribution of a service’s behavior under load tells more than
    the average latency. What we are actually interested in is not the best cases
    but those cases where we observed the worst results. Figure 12.2 shows the latency
    report for a run that I did with 150 users over 5 minutes.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在负载下，一个服务行为的延迟分布比平均延迟更能说明问题。我们真正感兴趣的不是最佳情况，而是那些我们观察到最差结果的情况。图12.2展示了我在5分钟内使用150个用户进行的一次运行延迟报告。
- en: '![](../Images/CH12_F02_Ponge.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图12.2 Locust运行](../Images/CH12_F02_Ponge.png)'
- en: Figure 12.2 Latencies observed with Locust for 150 users over 5 minutes
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 使用Locust在5分钟内观察到的150个用户的延迟
- en: The plot contains values at the 95th, 98th, 99th, and 100th percentiles. The
    reported latencies are under 200 ms at the 99th percentile for all requests, which
    sounds reasonable for a run with imperfect conditions and no tuning. The 100th
    percentile values show us the worst response times observed, and they are all
    under 500 ms.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图表包含第 95、98、99 和 100 个百分位数的值。报告的延迟在所有请求的第 99 个百分位数下都低于 200 毫秒，这在条件不完美且没有调整的情况下听起来是合理的。第
    100 个百分位数的值显示了观察到的最差响应时间，并且它们都在 500 毫秒以下。
- en: 'We could increase the number of users to stress the application even more,
    but we are not going to do precise load testing with Locust. If you raise the
    number of users, you will quickly start seeing increasing latencies and errors
    being raised. This is not due to the application under test but due to a limitation
    of Locust at the time of writing:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以增加用户数量以进一步增加应用程序的压力，但我们不会使用 Locust 进行精确的负载测试。如果你增加用户数量，你将很快看到延迟和错误开始增加。这并不是由于正在测试的应用程序，而是由于撰写本文时
    Locust 的限制：
- en: Locust’s network stack is not very efficient, so we quickly reach limits in
    the number of concurrent users.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Locust 的网络堆栈效率不高，所以我们很快就会达到并发用户的限制。
- en: Like many load testing tools, Locust suffers from *coordinated omission*, a
    problem where time measures are incorrect due to ignoring the wait time before
    the requests are actually made.[1](#pgfId-1014523)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与许多负载测试工具一样，Locust 受到“协调遗漏”问题的影响，这是一个由于忽略了请求实际发出之前的时间而导致的测量时间不正确的问题。[1](#pgfId-1014523)
- en: For accurate load testing, we thus have to use another tool, and Hey is a good
    one.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行准确的负载测试，我们因此必须使用另一个工具，而 Hey 就是一个不错的选择。
- en: Tip Locust is still a great tool for producing a small workload and even automating
    a demo of the project. Once it is started and is simulating users, you can connect
    to the dashboard web application and see it updated live.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：Locust 仍然是一个很好的工具，可以产生少量负载，甚至可以自动化项目的演示。一旦启动并模拟用户，你就可以连接到仪表板 Web 应用程序并实时查看更新。
- en: 12.1.3 Load testing the API with Hey
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.3 使用 Hey 进行 API 压力测试
- en: Hey is a much simpler tool than Locust, as it cannot run scripts and it focuses
    on stressing an HTTP endpoint. It is, however, an excellent tool for getting accurate
    measures on an endpoint under stress.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Hey 比 Locust 简单得多，因为它不能运行脚本，它专注于对 HTTP 端点进行压力测试。然而，它是一个在压力下获取端点准确测量的优秀工具。
- en: We are still going to use Locust on the side to simulate a small number of users.
    This will generate some activity in the system across all services and middleware,
    so our measurements won’t be made on a system that is idle.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍然会在旁边使用 Locust 来模拟少量用户。这将生成系统跨所有服务和中间件的活动，因此我们的测量不会在空闲系统中进行。
- en: 'We are going to stress the public API endpoint with two different requests:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用两种不同的请求来对公共 API 端点进行压力测试：
- en: Get the total number of steps for a user.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取用户的总步骤数。
- en: Authenticate and fetch a JWT token.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行身份验证并获取 JWT 令牌。
- en: This is interesting, because to get the number of steps for a user, the public
    API service needs to make an HTTP request to the activity service, which in turn
    queries a PostgreSQL database. Fetching a JWT token involves more work, as the
    user profile service needs to be queried twice before doing some cryptography
    work and finally returning a JWT token. The overall latency for these requests
    is thus impacted by the work done in the HTTP API, in the user and activity services,
    and finally in the databases.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有趣，因为要获取用户的步骤数，公共 API 服务需要向活动服务发出 HTTP 请求，该服务随后查询 PostgreSQL 数据库。获取 JWT 令牌涉及更多工作，因为用户配置文件服务需要在进行一些加密工作之前查询两次，最后返回
    JWT 令牌。因此，这些请求的总延迟受到 HTTP API、用户和活动服务以及最终数据库中完成的工作的影响。
- en: note The goal here is not to identify the limits of the services in terms of
    maximum throughput and best latency. We want to have a baseline to see how the
    service behaves under a sustained workload, and that will later help us to characterize
    the impact of various types of failures and mitigation strategies.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这里的目的是不是识别服务的最大吞吐量和最佳延迟的限制。我们想要有一个基线来观察服务在持续负载下的行为，这将在以后帮助我们描述各种类型故障和缓解策略的影响。
- en: Since Hey cannot run scripts, we have to focus on one user and wrap calls to
    Hey in shell scripts. You will find helper scripts in the part2-steps-challenge/load-testing
    folder. The first script is create-user.sh, shown in the following listing.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Hey 不能运行脚本，我们必须专注于一个用户，并将对 Hey 的调用封装在 shell 脚本中。你将在 part2-steps-challenge/load-testing
    文件夹中找到辅助脚本。第一个脚本是 create-user.sh，如下所示。
- en: Listing 12.3 Script to create a user
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.3 创建用户的脚本
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Register the loadtesting-user user.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 注册 loadtesting-user 用户。
- en: ❷ Publish 10 updates of 1,200 steps.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 发布 10 次包含 1,200 步的更新。
- en: This script ensures that user `loadtesting-user` is created and that a few updates
    have been recorded.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本确保用户 `loadtesting-user` 已创建，并且已记录了一些更新。
- en: The run-hey-user-steps.sh script shown in the following listing uses Hey and
    fetches the total number of steps for user `loadtesting-user`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表中 run-hey-user-steps.sh 脚本使用 Hey 并获取用户 `loadtesting-user` 的总步数。
- en: Listing 12.4 Script to run Hey and load test for getting a user’s total step
    count
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.4 运行 Hey 和负载测试以获取用户总步骤数的脚本
- en: '[PRE3]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Duration of the run (`10s`, `5m`, etc)
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 运行持续时间（`10s`、`5m` 等）
- en: ❷ Enable CSV output.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 启用 CSV 输出。
- en: ❸ Pass the JWT token for user loadtesting-user.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 传递用户 loadtesting-user 的 JWT 令牌。
- en: ❹ URL to the service, where the hostname is a variable
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 服务的 URL，其中主机名是一个变量
- en: ❺ Redirect the CSV output to a file.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将 CSV 输出重定向到文件。
- en: The run-hey-token.sh script in the following listing is similar and performs
    an authentication request to get a JWT token.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表中 run-hey-token.sh 脚本类似，执行身份验证请求以获取 JWT 令牌。
- en: Listing 12.5 Script to run Hey and load test getting a JWT token
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.5 运行 Hey 和负载测试以获取 JWT 令牌的脚本
- en: '[PRE4]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Specify that this is an HTTP POST request.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 指定这是一个 HTTP POST 请求。
- en: ❷ Send the content of the auth.json file, which has the credentials of the loadtesting-user
    user.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 发送包含 loadtesting-user 用户凭证的 auth.json 文件内容。
- en: ❸ Specify that the payload is some JSON data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 指定有效载荷是某些 JSON 数据。
- en: 'We are now ready to perform a run on the user total steps count endpoint. In
    my case, I’m doing the experiment with a second laptop, while my main laptop runs
    the services and had IP address 192.168.0.23 when I ran the tests. First off,
    we’ll get some light background workload with Locust, again to make sure the system
    is not exactly idle:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好对用户总步骤数端点进行运行。在我的情况下，我使用第二台笔记本电脑进行实验，而我的主要笔记本电脑运行服务，当我在测试时，它的 IP 地址是
    192.168.0.23。首先，我们将使用 Locust 获取一些轻量级背景工作负载，再次确保系统不是完全空闲：
- en: '[PRE5]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In another terminal, we’ll launch the test with Hey for five minutes:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个终端中，我们将使用 Hey 运行五分钟的测试：
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Once we have collected the results, the best way to analyze them is to process
    the data and plot it. You will find Python scripts to do that in the part2-steps-challenge/load-testing
    folder. Figure 12.3 shows the plot for this experiment.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们收集了结果，分析它们最好的方式是处理数据并绘制图表。你将在 part2-steps-challenge/load-testing 文件夹中找到执行此操作的
    Python 脚本。图 12.3 显示了此实验的图表。
- en: '![](../Images/CH12_F03_Ponge.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F03_Ponge.png)'
- en: Figure 12.3 Report for the user total steps count load test
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.3 用户总步骤数负载测试报告
- en: 'The figure contains three subplots:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 该图包含三个子图：
- en: A scattered plot of the request latencies over time
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随时间变化的请求延迟的散点图
- en: A throughput plot that shares the same scale as the requests latencies plot
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与请求延迟图具有相同刻度的吞吐量图
- en: A latency distribution over the 95th to 100th percentiles
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 95% 到 100% 分位数的延迟分布
- en: The 99.99th percentile latency is very good while the throughput is high. We
    get better results with Hey compared to a 100-user workload with Locust. We can
    see a few short throughput drops correlated with higher latency responses, but
    there is nothing to worry about in these conditions. These drops could have been
    caused by various factors, including PostgreSQL, the WiFi network, or a JVM garbage
    collector run. It is easy to get better results with better hardware running Linux,
    a wired network, some JVM tuning, and a properly configured PostgreSQL database
    server.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当吞吐量高时，99.99% 分位数的延迟非常好。与 Locust 的 100 用户负载相比，使用 Hey 我们可以得到更好的结果。我们可以看到一些与更高延迟响应相关的短吞吐量下降，但在这些条件下没有什么需要担心的。这些下降可能是由各种因素引起的，包括
    PostgreSQL、WiFi 网络，或 JVM 垃圾收集器运行。使用更好的硬件（运行 Linux、有线网络、一些 JVM 调优和正确配置的 PostgreSQL
    数据库服务器）很容易得到更好的结果。
- en: 'We can run another load testing experiment, fetching JWT tokens:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以运行另一个负载测试实验，获取 JWT 令牌：
- en: '[PRE7]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The results are shown in figure 12.4.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在图 12.4 中。
- en: '![](../Images/CH12_F04_Ponge.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F04_Ponge.png)'
- en: Figure 12.4 JWT token load test report
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.4 JWT 令牌负载测试报告
- en: These results again show consistent behavior, albeit with a higher latency and
    lower throughput than the step count endpoint could achieve. This is easy to explain,
    as there are two HTTP requests to the user profile service, and then the token
    has to be generated and signed. The HTTP requests are mostly I/O-bound, while
    token signing requires CPU-bound work to be done on the event loop. The results
    are consistent over the five-minute run.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果再次显示了一致的行为，尽管与步骤计数端点相比，延迟更高，吞吐量更低。这很容易解释，因为有两个 HTTP 请求到用户配置文件服务，然后必须生成并签名令牌。HTTP
    请求主要是 I/O 密集型，而令牌签名需要在事件循环上执行 CPU 密集型工作。五分钟运行的结果是一致的。
- en: It is safe to conclude that the tested service implementations deliver solid
    performance under load. You could try to increase the number of workers for Hey
    and see what happens with bigger workloads (see the `-c` flag of the `hey` tool).
    You could also perform latency measures with increasing request rates (see the
    `-q` flag), but note that by default Hey does not do rate limiting, so in the
    previous runs Hey did the best it could with 50 workers (the default).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 可以安全地得出结论，测试的服务实现能够在负载下提供稳定的性能。你可以尝试增加 Hey 的工作者数量，看看在大负载下会发生什么（参见 `hey` 工具的
    `-c` 标志）。你也可以使用增加的请求速率进行延迟测量（参见 `-q` 标志），但请注意，默认情况下 Hey 不进行速率限制，所以在之前的运行中 Hey
    使用了默认的 50 个工作者（默认值）。
- en: Scalability is only half of being reactive, so let’s now see how our services
    behave with the same workloads in the presence of failures.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 可伸缩性只是反应性的半部分，因此现在让我们看看我们的服务在出现故障的情况下，如何处理相同的工作负载。
- en: 12.2 Let’s do some chaos engineering
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 让我们进行一些混沌工程
- en: Strictly speaking, *chaos engineering* is the practice of voluntarily introducing
    failures in production systems to see how they react to unexpected application,
    network, and infrastructure failures. For instance, you can try to shut down a
    database, take down a service, introduce network delays, or even interrupt traffic
    between networks. Instead of waiting for failures to happen in production and
    waking up on-duty site reliability engineers at 4 a.m. on a Sunday, you decide
    to be proactive by periodically introducing failures yourself.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 严格来说，*混沌工程*是指在生产系统中自愿引入故障的实践，以观察它们对意外应用程序、网络和基础设施故障的反应。例如，你可以尝试关闭数据库、停止服务、引入网络延迟，甚至中断网络之间的流量。而不是等待生产中出现故障，在周日早上
    4 点叫醒值班的服务可靠性工程师，你可以选择主动地定期自己引入故障。
- en: 'You can also do chaos engineering before software hits production, as the core
    principle remains the same: run the software with some workload, introduce some
    form of failure, and see how the software behaves.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件投入生产之前，你还可以进行混沌工程，因为核心原则保持不变：运行带有一定工作负载的软件，引入某种形式的故障，并观察软件的表现。
- en: 12.2.1 Test plan
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.1 测试计划
- en: We need a reproducible scenario to evaluate the services, as they will alternate
    between nominal and failure phases. We will introduce failures according to the
    plan in figure 12.5.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个可重复的场景来评估服务，因为它们将在正常和故障阶段之间交替。我们将根据图 12.5 中的计划引入故障。
- en: '![](../Images/CH12_F05_Ponge.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F05_Ponge.png)'
- en: Figure 12.5 Test plan
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.5 测试计划
- en: 'We will run the same load testing experiments as we did in previous sections
    over periods of five minutes. What will change is that we’re going to split it
    into five phases of one minute each:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在五分钟的时间段内运行与之前章节相同的负载测试实验。变化之处在于，我们将将其分为五个阶段，每个阶段为一分钟：
- en: The databases work nominally for the first minute.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据库在第一分钟内正常工作。
- en: We will introduce network delays of three seconds (+/- 500 ms) for all database
    traffic for the second minute.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在第二分钟为所有数据库流量引入三秒（± 500 毫秒）的网络延迟。
- en: We will get back to nominal performance for the third minute.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在第三分钟恢复到正常性能。
- en: We will stop the two databases for the forth minute.
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将停止两个数据库四分钟。
- en: We will get back to nominal performance for the fifth and final minute.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在第五和最后一分钟恢复到正常性能。
- en: Network delays increase latency, but they also simulate an overloaded database
    or service that starts to become unresponsive. With extreme delay values, they
    can also simulate an unreachable host, where establishing TCP connections takes
    a long time to fail. On the other hand, stopping the databases simulates services
    being down while their hosts remain up, which should lead to quick TCP connection
    errors.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 网络延迟增加了延迟，但它们也模拟了一个开始变得不响应的过载数据库或服务。在极端的延迟值下，它们还可以模拟一个不可达的主机，其中建立 TCP 连接需要很长时间才能失败。另一方面，停止数据库模拟了服务已关闭而其主机仍然在线的情况，这应该会导致快速的
    TCP 连接错误。
- en: How are we going to introduce these failures?
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将如何引入这些故障？
- en: 12.2.2 Chaos testing with Pumba
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.2 使用 Pumba 进行混沌测试
- en: 'Pumba is a chaos testing tool for introducing failures in Docker containers
    ([https://github.com/alexei-led/pumba](https://github.com/alexei-led/pumba)).
    It can be used to do the following:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Pumba 是一个用于在 Docker 容器中引入故障的混沌测试工具 ([https://github.com/alexei-led/pumba](https://github.com/alexei-led/pumba))。它可以用于以下操作：
- en: Kill, remove, and stop containers
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 杀死、移除和停止容器
- en: Pause processes in containers
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 暂停容器中的进程
- en: Stress container resources (e.g., CPU, memory, or filesystem)
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 压力容器资源（例如，CPU、内存或文件系统）
- en: Emulate network problems (packet delays, loss, duplication, corruption, etc.)
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仿真网络问题（数据包延迟、丢失、重复、损坏等）
- en: Pumba is a very convenient tool that you can download and run on your machine.
    The only dependency is having Docker running.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Pumba 是一个非常方便的工具，你可以下载并在你的机器上运行。唯一的依赖是 Docker 必须运行。
- en: We are focusing on two types of failures in our test plan because they are the
    most relevant to us. You can play with other types of failures just as easily.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的测试计划中，我们关注两种类型的故障，因为它们对我们来说最相关。你可以轻松地玩其他类型的故障。
- en: With the 10k steps application running locally, let’s play with Pumba and add
    some delay to the MongoDB database traffic. Let’s fetch a JWT token with the load-testing/
    fetch-token.sh script, as follows.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地运行 10k 步应用的情况下，让我们使用 Pumba 并对 MongoDB 数据库流量添加一些延迟。让我们使用 load-testing/fetch-token.sh
    脚本获取 JWT 令牌，如下所示。
- en: Listing 12.6 Fetching a JWT token
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.6 获取 JWT 令牌
- en: '[PRE8]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Found in the part2-steps-challenge folder
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 位于 part2-steps-challenge 文件夹中
- en: In another terminal, let’s introduce the delays with the following command.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个终端中，让我们使用以下命令引入延迟。
- en: Listing 12.7 Introducing some network delays with Pumba
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.7 使用 Pumba 引入一些网络延迟
- en: '[PRE9]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ netem is the subcommand for network problem emulation.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ netem 是网络问题仿真的子命令。
- en: ❷ There will be delays for one minute.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将会有一分钟延迟。
- en: ❸ A helper Docker image
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 一个辅助 Docker 镜像
- en: ❹ Three-second delays +/- 500 ms
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 三秒延迟 ± 500 毫秒
- en: ❺ Name of the target container (you can have regular expressions to target multiple
    containers, etc)
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 目标容器的名称（你可以使用正则表达式来针对多个容器等）
- en: Pumba should now be running for one minute. Try fetching a JWT token again;
    the command should clearly take more time than before, as shown in the following
    listing.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Pumba 现在应该已经运行了一分钟。再次尝试获取 JWT 令牌；命令应该明显比之前花费更多时间，如下所示。
- en: Listing 12.8 Fetching a token with network delays
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.8 带网络延迟获取令牌
- en: '[PRE10]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Use time to measure a process execution time.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用 time 来测量进程执行时间。
- en: The process took 6.157 seconds to fetch a token, due to waiting for I/O. Similarly,
    you can stop a container with the following command.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 由于等待 I/O，进程花费了 6.157 秒来获取令牌。同样，你可以使用以下命令停止一个容器。
- en: Listing 12.9 Stopping a container with Pumba
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.9 使用 Pumba 停止容器
- en: '[PRE11]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Stop, then restart the container.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 停止容器，然后重启。
- en: If you run the script to fetch a token again, you will be waiting, while in
    the logs you will see some errors due to the MongoDB container being down, as
    follows.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你再次运行脚本以获取令牌，你将需要等待，而在日志中你会看到一些错误，因为 MongoDB 容器已关闭，如下所示。
- en: Listing 12.10 Fetching a token with a stopped database server
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.10 带停止的数据库服务器获取令牌
- en: '[PRE12]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ It took a long time!
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 这花了很长时间！
- en: The service is now unresponsive. My request took 57.315 seconds to complete
    because it had to wait for the database to be back.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 服务现在不响应。我的请求花费了 57.315 秒来完成，因为它必须等待数据库恢复。
- en: Let’s get a clearer understanding by running the test plan, and we’ll see what
    happens when these failures happen and the system is under load testing.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行测试计划，我们可以更清楚地了解，当这些故障发生并且系统处于负载测试之下时会发生什么。
- en: 12.2.3 We are not resilient (yet)
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.3 我们（目前）还没有弹性
- en: To run these experiments you will use the same shell scripts to launch Hey as
    we did earlier in this chapter. You will preferably use two machines. The part2-steps-challenge/
    load-testing folder contains a run-chaos.sh shell script to automate the test
    plan by calling Pumba at the right time. The key is to start both the run-chaos.sh
    and Hey scripts (e.g., run-hey-token.sh) at the same time.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行这些实验，你将使用与本章前面相同的shell脚本启动Hey。你最好使用两台机器。part2-steps-challenge/负载测试文件夹包含一个run-chaos.sh
    shell脚本，通过在正确的时间调用Pumba来自动化测试计划。关键是同时启动run-chaos.sh和Hey脚本（例如，run-hey-token.sh）。
- en: Figure 12.6 shows the behavior of the service on getting a user’s total steps
    count. The results show a clear lack of responsiveness when Pumba runs.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6显示了服务在获取用户总步数时的行为。结果显示，当Pumba运行时，响应性明显不足。
- en: '![](../Images/CH12_F06_Ponge.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F06_Ponge.png)'
- en: Figure 12.6 Total step count load test with failures
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 总步数负载测试失败情况
- en: In the phase of network delays, we see a rapid latency increase spike to nearly
    20 seconds, after which the throughput implodes. What happens here is that requests
    are enqueued, waiting for a response in both the public API and user profile services,
    up to the point where the system is at a halt. The database delays are between
    2.5 s and 3.5 s, which can temporarily happen in practice. Of course, the issue
    is vastly amplified here due to load testing, but any service with some sustained
    traffic can show this kind of behavior even with smaller delays.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络延迟的阶段，我们看到延迟迅速增加，达到近20秒，之后吞吐量崩溃。这里发生的情况是，请求被排队等待在公共API和用户配置文件服务中响应，直到系统停止。数据库延迟在2.5秒到3.5秒之间，这在实践中可能会暂时发生。当然，由于负载测试，这个问题被大大放大了，但任何有一定持续流量的服务即使有较小的延迟也可能表现出这种行为。
- en: In the phase where databases are down we see errors for the whole simulated
    outage duration. While it is hard to be surprised about errors, we can see that
    the system has not come to a halt either. This is far from perfect, though, since
    the reduced throughput is a sign that requests need *some* time to be given an
    error, while other requests are waiting until they time out, or they eventually
    complete when the databases restart.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据库关闭的阶段，我们看到了整个模拟故障期间的错误。虽然对错误感到惊讶很难，但我们也可以看到系统并没有完全停止。尽管如此，这还远非完美，因为降低的吞吐量是请求需要“一些”时间才能得到错误信号的一个迹象，而其他请求则等待超时，或者当数据库重新启动时最终完成。
- en: Let’s now look at figure 12.7 and see how fetching JWT tokens goes.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看图12.7，看看获取JWT令牌的过程。
- en: '![](../Images/CH12_F07_Ponge.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F07_Ponge.png)'
- en: Figure 12.7 JWT token load test with failures
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 JWT令牌负载测试失败情况
- en: Network delays also cause the system to come to a halt, but we do not observe
    the same shape in the scatter plot. This is due to the inherently lower throughput
    of the service for this type of request, and also the fact that two HTTP requests
    are needed. Requests pile up, waiting for responses to arrive, and once the delays
    stop, the system gets going again. More interestingly, we do not observe errors
    in the phase where databases have been stopped. There are just no requests being
    served anymore as the system is waiting for databases.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 网络延迟也会导致系统停止，但在散点图中我们没有观察到相同的形状。这是由于此类请求的服务本身吞吐量较低，以及需要两个HTTP请求的事实。请求堆积，等待响应到达，一旦延迟停止，系统再次开始运行。更有趣的是，我们在数据库停止的阶段没有观察到错误。因为系统正在等待数据库，所以不再有请求被服务。
- en: From these two experiments, we can see that the services become unresponsive
    in the presence of failures, so they are not reactive. The good news is that there
    are ways to fix this, so let’s see how we can become reactive, again using the
    public API as a reference. You will then be able to extrapolate the techniques
    to the other services.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 从这两个实验中，我们可以看到在存在失败的情况下，服务变得无响应，因此它们不是反应式的。好消息是，有方法可以解决这个问题，所以让我们看看我们如何再次变得反应式，再次以公共API作为参考。你将能够将技术外推到其他服务。
- en: 12.3 From “scalable” to “scalable and resilient”
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 从“可扩展”到“可扩展且具有弹性”
- en: 'To make our application resilient, we have to make changes to the public API
    and make sure that it responds *quickly* when a failure has been detected. We
    will explore two approaches: enforcing timeouts, and then using a circuit breaker.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们的应用程序具有弹性，我们必须对公共API进行更改，并确保在检测到失败时能够快速响应。我们将探讨两种方法：强制执行超时，然后使用断路器。
- en: 12.3.1 Enforcing timeouts
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.1 强制执行超时
- en: 'Observations in the preceding experiments showed that requests piled up while
    waiting for either the databases to get back to nominal conditions, or for TCP
    errors to arise. A first approach could be to enforce short timeouts in the HTTP
    client requests, so that they fail fast when the user profile or activity services
    take too long to respond. The changes are very simple: we just need to add timeouts
    to the HTTP requests made by the Vert.x web client, as shown in listing 12.11.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的实验观察表明，在等待数据库恢复到正常条件或TCP错误出现时，请求会堆积。一种初步的方法是在HTTP客户端请求中强制执行短超时，这样当用户配置文件或活动服务响应时间过长时，它们会快速失败。更改非常简单：我们只需要向Vert.x网络客户端发出的HTTP请求中添加超时，如图12.11所示。
- en: Tip You can find the corresponding code changes in the chapter12/public-api-with-timeouts
    branch of the Git repository.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：您可以在Git仓库的chapter12/public-api-with-timeouts分支中找到相应的代码更改。
- en: Listing 12.11 Implementation of the `totalSteps` method with timeouts
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.11 带超时的`totalSteps`方法实现
- en: '[PRE13]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Times out after five seconds
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 五秒后超时
- en: The changes are the same in the `fetchUserDetails` and `token` methods. A timeout
    of five seconds is relatively short and ensures a quick notification of an error.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`fetchUserDetails`和`token`方法中的更改相同。五秒的超时相对较短，并确保快速通知错误。'
- en: Intuitively, this should improve the responsiveness of the public API services
    and avoid throughput coming to a halt. Let’s see what happens by running the chaos
    testing experiments again, as shown in figure 12.8.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上看，这应该会提高公共API服务的响应性，并避免吞吐量停滞。让我们通过再次运行混沌测试实验来查看会发生什么，如图12.8所示。
- en: Compared to the experiment in figure 12.6, we still have drastically reduced
    throughputs during failures, but at least we see errors being reported, thanks
    to the timeout enforcements. We also see that the maximum latency is below six
    seconds, which is in line with the five-second timeouts.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 与图12.6中的实验相比，我们在失败期间仍然有大幅降低的吞吐量，但至少我们看到了错误报告，这得益于超时强制执行。我们还看到最大延迟低于六秒，这与五秒的超时相符。
- en: '![](../Images/CH12_F08_Ponge.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F08_Ponge.png)'
- en: Figure 12.8 Total steps count load test with failures and timeouts
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 带有失败和超时的总步骤数负载测试
- en: 'Let’s now see how the JWT token load test behaves, as shown in figure 12.9\.
    This run confirms what we have observed: timeouts get enforced, ensuring that
    some requests are still served during the failures. However, the worst-case latencies
    are worse than without the timeouts: network delays stretch the time for doing
    two HTTP requests to the user profile service, so the higher values correspond
    to those requests where the second request timed out.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看JWT令牌负载测试的行为，如图12.9所示。这次运行确认了我们观察到的结果：超时被强制执行，确保在失败期间仍有部分请求被服务。然而，最坏情况下的延迟比没有超时的情况更差：网络延迟将向用户配置文件服务发送两个HTTP请求的时间拉长，因此较高的值对应于第二个请求超时的情况。
- en: '![](../Images/CH12_F09_Ponge.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F09_Ponge.png)'
- en: Figure 12.9 JWT token load test with failures and timeouts
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 带有失败和超时的JWT令牌负载测试
- en: Timeouts are better than no timeouts when it comes to improving responsiveness,
    but we cannot qualify our public API service as being resilient. What we need
    is a way for the service to *know* that there is a failure happening, so it fails
    *fast* rather than waiting for a timeout to happen. This is exactly what a circuit
    breaker is for!
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在提高响应性方面，超时比没有超时更好，但我们不能将我们的公共API服务称为具有弹性。我们需要的是一种让服务“知道”正在发生故障的方法，这样它就会快速失败，而不是等待超时发生。这正是断路器的作用所在！
- en: 12.3.2 Using a circuit breaker
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.2 使用断路器
- en: The goal of a circuit breaker is to prevent the problems observed in the previous
    section, where requests to unresponsive systems pile up, causing cascading errors
    between distributed services. A circuit breaker acts as a form of proxy between
    the code that makes a (networked) request, such as an RPC call, HTTP request,
    or database call, and the service to be invoked.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 断路器的目的是防止前一部分中观察到的问题，即对无响应系统的请求堆积，导致分布式服务之间发生级联错误。断路器充当发出（网络）请求的代码（如RPC调用、HTTP请求或数据库调用）与要调用的服务之间的代理形式。
- en: Figure 12.10 shows how a circuit breaker works as a finite state machine. The
    idea is quite simple. The circuit breaker starts in the *closed* state, and for
    each request, it observes whether the request succeeded or not. Failing can be
    because an error has been reported (for example, a TCP timeout or TCP connection
    error), or because an operation took too long to complete.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.10 展示了断路器作为有限状态机的工作方式。这个想法相当简单。断路器从 *关闭* 状态开始，对于每个请求，它观察请求是否成功。失败可能是由于报告了错误（例如，TCP
    超时或 TCP 连接错误），或者是因为操作完成得太慢。
- en: '![](../Images/CH12_F10_Ponge.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![电路断路器配置图](../Images/CH12_F10_Ponge.png)'
- en: Figure 12.10 Circuit breaker state machine
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.10 断路器状态机
- en: Once a certain number of errors have been reported, the circuit breaker goes
    to the *open* state. From here, all operations are notified of a failure due to
    the circuit being open. This avoids further requests being issued to an unresponsive
    service, which allows for fast error responses, trying alternative recovery strategies,
    and reducing the pressure on both the service and requester ends.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦报告了一定数量的错误，断路器将进入 *开启* 状态。从这里开始，所有操作都会通知由于电路开启而导致的故障。这避免了向无响应的服务发出进一步请求，从而允许快速错误响应，尝试替代恢复策略，并减轻服务端和请求端的压力。
- en: The circuit breaker leaves the *open* state and goes to the *half-open* state
    after some *reset* timeout. The first request in the *half-open* state determines
    whether the service has recovered. Unlike the *open* state, the *half-open* state
    is where we start doing a real operation again. If it succeeds, the circuit breaker
    goes back to the *closed* state and resumes normal servicing. If not, another
    reset period starts before it goes back to the *half-open* state and checks if
    the service is back.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 断路器在经过一些 *重置* 超时后离开 *开启* 状态并进入 *半开启* 状态。在 *半开启* 状态下的第一个请求确定服务是否已恢复。与 *开启* 状态不同，*半开启*
    状态是我们再次开始执行实际操作的地方。如果成功，断路器将返回到 *关闭* 状态并继续正常服务。如果不成功，在它返回到 *半开启* 状态之前将开始另一个重置周期，并检查服务是否恢复。
- en: Tip You can find the code changes discussed here in the chapter12/public-api-with-circuit-breaker
    branch of the Git repository.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：您可以在 Git 仓库的 chapter12/public-api-with-circuit-breaker 分支中找到这里讨论的代码更改。
- en: 'Vert.x provides the `vertx-circuit-breaker` module that needs to be added to
    the public API project. We will use two circuit breakers: one for token generation
    requests, and one for calls to the activity service (such as getting the total
    steps count for a user). The following listing shows the code to create a circuit
    breaker in the `PublicApiVerticlerxStart` method.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Vert.x 提供了 `vertx-circuit-breaker` 模块，需要将其添加到公共 API 项目中。我们将使用两个断路器：一个用于令牌生成请求，另一个用于对活动服务的调用（例如获取用户的总步数）。以下列表显示了在
    `PublicApiVerticlerxStart` 方法中创建断路器的代码。
- en: Listing 12.12 Creating a circuit breaker
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.12 创建断路器
- en: '[PRE14]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Create a circuit breaker with a name and options.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用名称和选项创建断路器。
- en: ❷ Callback when entering the open state
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 进入开启状态时的回调
- en: ❸ Callback when entering the half-open state
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 进入半开启状态时的回调
- en: ❹ Callback when entering the closed state
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 进入关闭状态时的回调
- en: The `tokenCircuitBreakerName` reference is a field of type `CircuitBreaker`.
    There is another field called `activityCircuitBreaker` for the activity service
    circuit breaker, and the code is identical. The callbacks on state change can
    be optionally set. It is a good idea to log these state changes for diagnosis
    purposes.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`tokenCircuitBreakerName` 引用是一个 `CircuitBreaker` 类型的字段。还有一个名为 `activityCircuitBreaker`
    的字段用于活动服务断路器，代码是相同的。可以在状态变化时可选地设置回调。为了诊断目的，记录这些状态变化是一个好主意。'
- en: The following listing shows a circuit breaker configuration.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了断路器配置。
- en: Listing 12.13 Configuring a circuit breaker
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.13 配置断路器
- en: '[PRE15]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Open after five failures.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 五次失败后开启。
- en: ❷ Do not retry a failed operation.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 不要重试失败的操作。
- en: ❸ Report timeout failures after five seconds.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 五秒后报告超时失败。
- en: ❹ Reset timeout to 10 seconds.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 重置超时设置为 10 秒。
- en: We are going to open the circuit breaker after five failures, including operations
    timing out after five seconds (to be consistent with the previous experiments).
    The reset timeout is set to 10 seconds, which will let us frequently check how
    the service goes. How long this value should be depends on your context, but you
    can anticipate that long timeouts will increase the time a service operates in
    degraded mode or reports errors, whereas short values may diminish the effectiveness
    of using a circuit breaker.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在包括操作在五秒后超时（为了与前述实验保持一致）的五次失败后打开断路器。重置超时设置为10秒，这将让我们能够频繁地检查服务状态。这个值应该是多长取决于你的上下文，但你可以预期，长时间的超时会增加服务在降级模式或报告错误时运行的时间，而短值可能会降低使用断路器的有效性。
- en: The following listing shows the modified `token` method with the code wrapped
    into a circuit breaker call.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了修改后的`token`方法，代码被封装在断路器调用中。
- en: Listing 12.14 Implementation of the token method with a circuit breaker
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.14 使用断路器的token方法实现
- en: '[PRE16]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Execute an operation that provides a String.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 执行返回字符串的操作。
- en: ❷ Regular web client call
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 定期网络客户端调用
- en: ❸ Web client and RxJava operators, as in the previous code
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 网络客户端和RxJava操作符，如前述代码。
- en: ❹ Complete with a successful token.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 成功完成令牌。
- en: ❺ Check if the service returned a non-200 status code and complete.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 检查服务是否返回了非200状态码并完成。
- en: ❻ Fail due to some other error.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 由于其他错误而失败。
- en: ❼ Send the token or manage the authentication error.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 发送令牌或处理认证错误。
- en: The circuit breaker executes an operation, which here is making two HTTP requests
    to the user profile service and then making a JWT token. The operation’s result
    is a `Single<String>` of the JWT token value. The execution method passes a promise
    to the wrapped code, so it can notify if the operation succeeded or not.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 断路器执行一个操作，这里是对用户配置文件服务发起两个HTTP请求，然后生成JWT令牌。操作的结果是一个JWT令牌值的`Single<String>`。执行方法传递一个承诺给封装的代码，以便它可以通知操作是否成功。
- en: The `handleAuthError` method had to be modified as in the following listing
    to check the source of any error.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`handleAuthError`方法必须修改如下，以检查任何错误的来源。'
- en: Listing 12.15 Handling authentication errors
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.15 处理认证错误
- en: '[PRE17]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ The circuit breaker is open.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 断路器处于开启状态。
- en: ❷ The operation timed out.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 操作超时。
- en: ❸ Regular authentication error
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定期认证错误
- en: The circuit breaker reports open circuit conditions and operation timeouts with
    dedicated exceptions. In these cases, we report an HTTP 500 status code or a classic
    401 so the requester knows if a failure is due to bad credentials or not.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 断路器会报告开路条件和操作超时，并使用专用异常。在这些情况下，我们报告HTTP 500状态码或经典的401，以便请求者知道失败是否由于凭证错误。
- en: This is great, but what is the actual effect of the circuit breaker on our system?
    Let’s see by running the experiment on the JWT token generation. The results are
    shown in figure 12.11.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但断路器对我们系统的实际影响是什么？让我们通过在JWT令牌生成上运行实验来查看。结果如图12.11所示。
- en: '![](../Images/CH12_F11_Ponge.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F11_Ponge.png)'
- en: Figure 12.11 JTW token load testing with failures and a circuit breaker
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.11 JTW令牌负载测试，包括故障和断路器
- en: 'The impact of the circuit breaker is striking: the service is now *highly*
    responsive during failure periods! We get a high throughput during failures, as
    the service now fails fast when the circuit breaker is open. Interestingly, we
    can spot when the circuit breaker tries to make requests when in the half-open
    state: these are the high-latency error points at regular intervals. We can also
    see that the 99.99th percentile is back to a lower latency compared to the previous
    runs.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 断路器的影响是显著的：在故障期间，服务现在**高度**响应！在故障期间，我们获得了高吞吐量，因为当断路器打开时，服务现在会快速失败。有趣的是，我们可以看到当断路器处于半开状态时尝试发起请求：这些是定期出现的高延迟错误点。我们还可以看到，第99.99百分位数的延迟与之前的运行相比已经回到了较低的值。
- en: This is all good, but what about fetching the total steps count for a user?
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这都很好，但关于获取用户总步骤数怎么办？
- en: 12.3.3 Resiliency and fallback strategies
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.3 弹性和回退策略
- en: 'The circuit breaker made JWT token generation responsive even with failures,
    so the endpoint is now fully *reactive*. That being said, it did not offer much
    in the way of fallback strategies: if we can’t talk to the user profile service,
    there is no way we can authenticate a user and then generate a JWT token. This
    is why the circuit breaker always reports errors.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 断路器使 JWT 令牌生成即使在失败的情况下也能响应，因此端点现在是完全*响应式*的。然而，它并没有提供很多回退策略：如果我们无法与用户配置文件服务通信，我们就无法验证用户并生成
    JWT 令牌。这就是为什么断路器总是报告错误。
- en: 'We could adopt the same strategy when issuing requests to the activity service,
    and simply report errors. That being said, we could provide further resiliency
    by caching data and provide an older value to a requester. Fallback strategies
    depend on the functional requirements: we cannot generate a JWT token without
    authentication working, but we can certainly serve some older step count data
    if we have it in a cache.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在向活动服务发出请求时采用相同的策略，并简单地报告错误。然而，我们可以通过缓存数据和向请求者提供旧值来提供进一步的弹性。回退策略取决于功能需求：如果没有认证工作，我们无法生成
    JWT 令牌，但如果我们有缓存中的旧步骤计数数据，我们当然可以提供一些。
- en: We will use the efficient in-memory Caffeine caching library ([https://github.com/
    ben-manes/caffeine](https://github.com/ben-manes/caffeine)). This library provides
    configurable strategies for managing cached data, including count, access, and
    time-based eviction policies. We could cache data in a Java `HashMap`, but that
    would quickly expose us to memory exhaustion problems if we didn’t put a proper
    eviction policy in place.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用高效的内存中 Caffeine 缓存库 ([https://github.com/ben-manes/caffeine](https://github.com/ben-manes/caffeine))。这个库提供了管理缓存数据的可配置策略，包括计数、访问和基于时间的驱逐策略。我们可以在
    Java `HashMap` 中缓存数据，但如果没有实施适当的驱逐策略，这会很快使我们面临内存耗尽问题。
- en: The following listing shows how to create a cache of at most 10,000 entries,
    where keys are strings and values are long integers.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的列表显示了如何创建最多包含 10,000 个条目的缓存，其中键是字符串，值是长整数。
- en: Listing 12.16 Creating a cache
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.16 创建缓存
- en: '[PRE18]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Cache at most 10,000 entries.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 缓存最多 10,000 个条目。
- en: We add entries to the cache with the `cacheTotalSteps` method in the following
    listing, and Caffeine evicts older entries when the 10,000 entries limit has been
    reached.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的列表中，我们使用`cacheTotalSteps`方法向缓存中添加条目，当达到 10,000 个条目的限制时，Caffeine 会驱逐较旧的条目。
- en: Listing 12.17 Caching total steps
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.17 缓存总步骤
- en: '[PRE19]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Store data just like in a regular Java map.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 就像在常规 Java 映射中一样存储数据。
- en: The preceding method is used in the `totalSteps` method, shown next, where the
    code has been wrapped using a circuit breaker call.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的方法用于下面的`totalSteps`方法，其中代码被断路器调用封装。
- en: Listing 12.18 Implementation of the `totalSteps` method with a circuit breaker
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.18 使用断路器实现 `totalSteps` 方法
- en: '[PRE20]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ Variant of execute that takes a fallback
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 执行的变体，带有一个回退
- en: ❷ Cache total steps.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 缓存总步骤。
- en: ❸ Try to recover from the cache.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 尝试从缓存中恢复。
- en: ❹ Fall back.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 回退。
- en: We now use a circuit breaker that does not return any value, hence the `Void`
    parametric type. The `executeWithFallback` method allows us to provide a fallback
    when the circuit is open, so we can try to recover a value from the cache. This
    is done in the `tryToRecoverFromCache` method in the following listing.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用一个不返回任何值的断路器，因此使用`Void`参数类型。`executeWithFallback`方法允许我们在断路器打开时提供回退，这样我们就可以尝试从缓存中恢复一个值。这在上面的列表中的`tryToRecoverFromCache`方法中完成。
- en: Listing 12.19 Implementation of the recovery from cache
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.19 缓存恢复的实现
- en: '[PRE21]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Send cached data as a successful response.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将缓存数据作为成功响应发送。
- en: ❷ Send an error because we don’t have any data.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 发送错误，因为我们没有数据。
- en: By recovering from a cache in the `tryToRecoverFromCache` method, we don’t always
    send errors. If we have data in the cache, we can still provide a response, albeit
    with a possibly outdated value.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在`tryToRecoverFromCache`方法中从缓存中恢复，我们并不总是发送错误。如果我们有缓存中的数据，我们仍然可以提供响应，尽管可能是一个过时的值。
- en: note Caching step counts and recovering from older values with a circuit breaker
    fallback could also be done directly in the activity service.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: note 使用断路器回退直接在活动服务中缓存步骤计数和从旧值恢复也可以完成。
- en: It is now time to check the behavior of the service when fetching step counts.
    First, let’s have a cold-start run where the database is initially down and the
    service has just started. Figure 12.12 shows a two-minute run where the database
    starts after a minute.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候检查服务在获取步骤计数时的行为。首先，让我们进行一次冷启动运行，其中数据库最初处于关闭状态，服务刚刚启动。图12.12显示了一分钟后的数据库启动后的两分钟运行。
- en: '![](../Images/CH12_F12_Ponge.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F12_Ponge.png)'
- en: Figure 12.12 Total step count load test with failures, a circuit breaker, and
    a cold start
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.12包含故障、断路器和冷启动的总步骤计数负载测试
- en: The service immediately starts with a few errors, and then the circuit breaker
    opens, at which point the service consistently provides errors with a very low
    latency. Remember that the service hasn’t cached any data yet.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 服务立即开始出现一些错误，然后断路器打开，此时服务以非常低的延迟持续提供错误。请记住，服务还没有缓存任何数据。
- en: When the database starts, we can see a latency spike as errors turn into successes,
    and then the service is able to respond nominally. Note that in the first success
    seconds, the JVM will start optimizing the code that talks to the database, so
    there is an improved throughput.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据库启动时，我们可以看到延迟峰值，错误变为成功，然后服务能够正常响应。请注意，在前几秒钟的成功中，JVM将开始优化与数据库通信的代码，因此吞吐量有所提高。
- en: '![](../Images/CH12_F13_Ponge.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F13_Ponge.png)'
- en: Figure 12.13 Total step count load test with failures and a circuit breaker
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.13包含故障和断路器的总步骤计数负载测试
- en: Figure 12.13 shows the service behavior over the full five-minute test plan.
    Since the test plan starts with databases running nominally, the service manages
    to cache data for the test user. This is why we get no errors across the whole
    run. We see a few successes with higher latency when the network delays appear,
    which actually impact the last few percentiles above 99.99th. These are due to
    the circuit breaker reporting timeouts on making HTTP requests, but note that
    the circuit breaker cannot *cancel* the HTTP requests. Hence, we have a few HTTP
    requests waiting for an unresponsive activity service, while the circuit breaker
    meanwhile completes the corresponding HTTP responses with some cached data.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.13显示了整个五分钟测试计划中的服务行为。由于测试计划从数据库正常运行开始，服务成功缓存了测试用户的数据。这就是为什么在整个运行过程中我们没有出现任何错误。当网络延迟出现时，我们看到了一些成功，但延迟较高，这实际上影响了99.99百分位以上的最后几个百分位。这些是由于断路器在发起HTTP请求时报告超时，但请注意，断路器不能*取消*HTTP请求。因此，我们有一些HTTP请求正在等待一个无响应的活动服务，而此时断路器同时使用一些缓存数据完成相应的HTTP响应。
- en: Figure 12.14 shows the effect of combining the circuit breaker with a five-second
    timeout on the web client HTTP requests (see the chapter12/public-api-with-circuit-breaker-and-timeouts
    branch of the Git repository).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.14显示了将断路器与五秒超时结合使用对Web客户端HTTP请求的影响（请参阅Git仓库的chapter12/public-api-with-circuit-breaker-and-timeouts分支）。
- en: '![](../Images/CH12_F14_Ponge.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F14_Ponge.png)'
- en: Figure 12.14 Total step count load test with failures, timeouts, and a circuit
    breaker
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.14包含故障、超时和断路器的总步骤计数负载测试
- en: This clearly improves the result, as we don’t have any worst-case latency around
    20 seconds anymore. Other than that, the latency and throughputs are consistent
    over the rest of the run, and they’re barely impacted by the databases being stopped
    around minute 4.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这明显提高了结果，因为我们不再有大约20秒的最坏情况延迟。除此之外，延迟和吞吐量在整个运行过程中保持一致，并且几乎不受大约4分钟时数据库停止的影响。
- en: note A circuit breaker is a very useful tool for avoiding cascading failures,
    but you don’t have to wrap every operation over the network in a circuit breaker.
    Every abstraction has a cost, and circuit breakers do add a level of indirection.
    Instead, it is best to use chaos testing and identify where they are most likely
    to have a positive effect on the overall system behavior.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：断路器是一个非常有用的工具，可以避免级联故障，但你不必将每个网络操作都包裹在断路器中。每个抽象都有成本，断路器确实增加了间接层次。相反，最好使用混沌测试并确定它们最有可能对整体系统行为产生积极影响的地方。
- en: 'We now have a reactive service: it is not just resource-efficient and scalable,
    but is also resilient to failures. The service keeps responding in all situations,
    and the latency is kept under control.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个反应式服务：它不仅资源高效且可扩展，而且对故障具有弹性。服务在所有情况下都能持续响应，延迟得到控制。
- en: The next and final chapter discusses running Vert.x applications in container
    environments.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章和最后一章讨论在容器环境中运行Vert.x应用程序。
- en: Summary
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A reactive service is not just scalable; it has to be resilient and responsive.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个反应式服务不仅仅是可扩展的；它必须具有弹性和响应性。
- en: Load testing and chaos testing tools are key to analyzing service behavior both
    when operating in nominal conditions, and when surrounded by failures from the
    network and services it relies on.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 压力测试和混沌测试工具是分析服务行为的关键，无论是处于正常条件下的操作，还是周围有它所依赖的网络和服务的故障。
- en: Circuit breakers are the most efficient tool for shielding a service from unresponsive
    services and network failures.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 断路器是保护服务免受无响应服务和网络故障影响的最有效工具。
- en: A resilient service is not just responsive when it can quickly notify of an
    error; it may still be able to respond successfully, such as by using cached data
    if the application domain allows it.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有弹性的服务不仅在能够快速通知错误时是响应的；它仍然可能能够成功响应，例如，如果应用程序领域允许，可以使用缓存数据。
- en: '* * *'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '***'
- en: 1.Gil Tene, “How NOT to Measure Latency,” talk given at the Strange Loop conference,
    2015; [www.youtube.com/ watch?v=lJ8ydIuPFeU](https://www.youtube.com/watch?v=lJ8ydIuPFeU).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 1. Gil Tene，“如何不测量延迟”，2015年在Strange Loop会议上发表的演讲；[www.youtube.com/watch?v=lJ8ydIuPFeU](https://www.youtube.com/watch?v=lJ8ydIuPFeU)。
