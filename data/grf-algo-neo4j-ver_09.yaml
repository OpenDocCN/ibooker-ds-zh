- en: Chapter 8\. Using Graph Algorithms to Enhance Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章：使用图算法增强机器学习
- en: We’ve covered several algorithms that learn and update state at each iteration,
    such as Label Propagation; however, up until this point, we’ve emphasized graph
    algorithms for general analytics. Because there’s increasing application of graphs
    in machine learning (ML), we’ll now look at how graph algorithms can be used to
    enhance ML workflows.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经涵盖了几种在每次迭代中学习并更新状态的算法，比如标签传播；然而，直到这一点，我们强调了用于一般分析的图算法。因为在机器学习（ML）中图的应用越来越广泛，我们现在将看看图算法如何用于增强ML工作流程。
- en: 'In this chapter, we focus on the most practical way to start improving ML predictions
    using graph algorithms: connected feature extraction and its use in predicting
    relationships. First, we’ll cover some basic ML concepts and the importance of
    contextual data for better predictions. Then there’s a quick survey of ways graph
    features are applied, including uses for spammer fraud, detection, and link prediction.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们专注于通过图算法开始改进ML预测的最实用方式：连接特征提取及其在预测关系中的应用。首先，我们将介绍一些基本的ML概念和上下文数据对于更好预测的重要性。然后，我们快速调查了图特征应用的方式，包括用于垃圾邮件欺诈检测和链接预测。
- en: We’ll demonstrate how to create a machine learning pipeline and then train and
    evaluate a model for link prediction, integrating Neo4j and Spark in our workflow.
    Our example will be based on the Citation Network Dataset, which contains authors,
    papers, author relationships, and citation relationships. We’ll use several models
    to predict whether research authors are likely to collaborate in the future, and
    show how graph algorithms improve the results.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示如何创建一个机器学习流水线，然后在我们的工作流中使用Neo4j和Spark进行链接预测的模型训练和评估。我们的示例将基于引文网络数据集，其中包含作者、论文、作者关系和引文关系。我们将使用几种模型预测研究作者未来是否可能合作，并展示图算法如何改善结果。
- en: Machine Learning and the Importance of Context
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习与上下文的重要性
- en: Machine learning is not artificial intelligence (AI), but a method for achieving
    AI. ML uses algorithms to train software through specific examples and progressive
    improvements based on expected outcome—without explicit programming of how to
    accomplish these better results. Training involves providing a lot of data to
    a model and enabling it to learn how to process and incorporate that information.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习不是人工智能（AI），而是实现AI的一种方法。ML使用算法通过具体示例进行训练，并根据预期结果进行渐进改进——而无需明确编程如何实现这些更好的结果。训练涉及向模型提供大量数据，并使其学习如何处理和整合该信息。
- en: In this sense, learning means that algorithms iterate, continually making changes
    to get closer to an objective goal, such as reducing classification errors in
    comparison to the training data. ML is also dynamic, with the ability to modify
    and optimize itself when presented with more data. This can take place in pre-usage
    training on many batches or as online learning during usage.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，学习意味着算法迭代，不断进行更改以接近目标，比如减少与训练数据相比的分类错误。ML也是动态的，在面对更多数据时能够修改和优化自身。这可以在使用前的许多批次中进行训练，也可以在使用过程中作为在线学习进行。
- en: 'Recent successes in ML predictions, accessibility of large datasets, and parallel
    compute power have made ML more practical for those developing probabilistic models
    for AI applications. As machine learning becomes more widespread, it’s important
    to remember its fundamental goal: making choices similarly to the way humans do.
    If we forget that goal, we may end up with just another version of highly targeted,
    rules-based software.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在ML预测中取得的成功、大型数据集的可访问性以及并行计算能力的提高，使得ML对于开发用于AI应用的概率模型更加实际。随着机器学习的普及，重要的是记住其根本目标：像人类一样做出选择。如果忘记了这个目标，我们可能最终只会得到另一个高度针对性、基于规则的软件版本。
- en: In order to increase machine learning accuracy while also making solutions more
    broadly applicable, we need to incorporate a lot of contextual information—just
    as people should use context for better decisions. Humans use their surrounding
    context, not just direct data points, to figure out what’s essential in a situation,
    estimate missing information, and determine how to apply lessons to new situations.
    Context helps us improve predictions.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高机器学习的准确性，并使解决方案更广泛适用，我们需要整合大量的上下文信息——就像人们应该使用上下文进行更好的决策一样。人类利用周围的上下文，而不仅仅是直接数据点，来确定情境中的重要性，估计缺失信息，并确定如何将教训应用到新情况中。上下文帮助我们改进预测。
- en: Graphs, Context, and Accuracy
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图形、上下文和准确性
- en: Without peripheral and related information, solutions that attempt to predict
    behavior or make recommendations for varying circumstances require more exhaustive
    training and prescriptive rules. This is partly why AI is good at specific, well-defined
    tasks, but struggles with ambiguity. Graph-enhanced ML can help fill in that missing
    contextual information that is so important for better decisions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 没有外围和相关信息，试图预测行为或为不同情况提供建议的解决方案需要更多的训练和规范规则。这部分是为什么人工智能擅长特定、明确定义的任务，但在模糊性方面表现不佳的原因之一。增强图的机器学习可以帮助填补丢失的上下文信息，这对于更好的决策至关重要。
- en: We know from graph theory and from real life that relationships are often the
    strongest predictors of behavior. For example, if one person votes, there’s an
    increased likelihood that their friends, family, and even coworkers will vote.
    [Figure 8-1](#vote-ripple) illustrates a ripple effect based on reported voting
    and Facebook friends from the 2012 research paper [“A 61-Million-Person Experiment
    in Social Influence and Political Mobilization”](https://www.nature.com/articles/nature11421),
    by R. Bond et al.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从图论和现实生活中知道，关系通常是行为的最强预测因素。例如，如果一个人投票，他们的朋友、家人甚至同事投票的可能性也会增加。[图 8-1](#vote-ripple)
    根据R. Bond等人的2012年研究论文《社会影响与政治动员的6100万人实验》（https://www.nature.com/articles/nature11421），展示了基于报告投票和Facebook朋友的涟漪效应。
- en: '![gral 0801](Images/gral_0801.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0801](Images/gral_0801.png)'
- en: Figure 8-1\. People are influenced to vote by their social networks. In this
    example, friends two hops away had more total impact than direct relationships.
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-1\. 人们受他们社交网络影响而投票。在这个例子中，处于两个跳数外的朋友总体上比直接关系产生了更大的影响。
- en: The authors found that friends reporting voting influenced an additional 1.4%
    of users to also claim they’d voted and, interestingly, friends of friends added
    another 1.7%. Small percentages can have a significant impact, and we can see
    in [Figure 8-1](#vote-ripple) that people at two hops out had in total more impact
    than the direct friends alone. Voting and other examples of how our social networks
    impact us are covered in the book *Connected*, by Nicholas Christakis and James
    Fowler (Little, Brown and Company).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 作者发现，报告投票的朋友影响了额外的1.4%用户声称他们也投票了，有趣的是，朋友的朋友增加了另外1.7%。即使是小百分比也可能产生显著影响，我们可以在[图 8-1](#vote-ripple)
    中看到，处于两个跳数外的人群总体上比直接朋友影响更大。投票和我们社交网络如何影响我们的其他例子，都包含在Nicholas Christakis和James
    Fowler的书《Connected》（Little, Brown and Company）中。
- en: Adding graph features and context improves predictions, especially in situations
    where connections matter. For example, retail companies personalize product recommendations
    with not only historical data but also contextual data about customer similarities
    and online behavior. Amazon’s Alexa uses [several layers of contextual models](https://amzn.to/2YmSvqn)
    that demonstrate improved accuracy. In 2018, Amazon also introduced “context carryover”
    to incorporate previous references in a conversation when answering new questions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 添加图形特征和上下文可以提升预测效果，特别是在关系重要的情况下。例如，零售公司不仅通过历史数据个性化产品推荐，还利用客户相似性和在线行为的上下文数据。亚马逊的Alexa使用[多层上下文模型](https://amzn.to/2YmSvqn)，展示了更高的准确性。2018年，亚马逊还引入了“上下文延续”，在回答新问题时整合之前的对话参考信息。
- en: Unfortunately, many machine learning approaches today miss a lot of rich contextual
    information. This stems from ML’s reliance on input data built from tuples, leaving
    out a lot of predictive relationships and network data. Furthermore, contextual
    information is not always readily available or is too difficult to access and
    process. Even finding connections that are four or more hops away can be a challenge
    at scale for traditional methods. Using graphs, we can more easily reach and incorporate
    connected data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，如今许多机器学习方法缺乏丰富的上下文信息。这源自于机器学习依赖于建立在元组基础上的输入数据，忽略了许多预测性关系和网络数据。此外，上下文信息并不总是容易获取或处理。即使是在传统方法的规模上，找到四个或更多跳跃连接也可能是一个挑战。利用图形，我们可以更轻松地获取和整合连接数据。
- en: Connected Feature Extraction and Selection
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接特征提取和选择
- en: Feature extraction and selection helps us take raw data and create a suitable
    subset and format for training our machine learning models. It’s a foundational
    step that, when well executed, leads to ML that produces more consistently accurate
    predictions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提取和选择帮助我们从原始数据中提取并创建适合训练机器学习模型的合适子集和格式。这是一个基础性步骤，当执行良好时，可以产生更一致准确的机器学习预测。
- en: Putting together the right mix of features can increase accuracy because it
    fundamentally influences how our models learn. Because even modest improvements
    can make a significant difference, our focus in this chapter is on *connected
    features*. Connected features are features extracted from the structure of the
    data. These features can be derived from graph-local queries based on parts of
    the graph surrounding a node, or graph-global queries that use graph algorithms
    to identify predictive elements within data based on relationships for connected
    feature extraction.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 通过合理组合特性，可以提高准确性，因为它从根本上影响我们的模型学习。即使是小幅改进也可能产生显著差异，本章重点关注*连接特性*。连接特性是从数据结构中提取的特性。这些特性可以从围绕节点的图局部查询中获取，或者使用图算法进行图全局查询，以识别基于关系的数据中的预测元素，用于连接特性提取。
- en: And it’s not only important to get the right combination of features, but also
    to eliminate unnecessary features to reduce the likelihood that our models will
    be hypertargeted. This keeps us from creating models that only work well on our
    training data (known as *overfitting*) and significantly expands applicability.
    We can also use graph algorithms to evaluate those features and determine which
    ones are most influential to our model for connected feature selection. For example,
    we can map features to nodes in a graph, create relationships based on similar
    features, and then compute the centrality of features. Feature relationships can
    be defined by the ability to preserve cluster densities of data points. This method
    is described using datasets with high dimension and low sample size in [“Unsupervised
    Graph-Based Feature Selection Via Subspace and PageRank Centrality”](https://bit.ly/2HGON5B),
    by K. Henniab, N. Mezghani, and C. Gouin-Vallerand.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅重要的是获取正确的特性组合，还要消除不必要的特性，以减少模型可能过度定制的可能性。这可以避免创建仅在训练数据上表现良好的模型（即所谓的*过拟合*），显著扩展适用性。我们还可以使用图算法评估这些特性，并确定对我们的模型最具影响力的特性用于连接特性选择。例如，我们可以将特性映射到图中的节点，根据相似特性创建关系，然后计算特性的中心性。特性关系可以通过保存数据点的簇密度来定义。这种方法在[“基于子空间和PageRank中心性的无监督图特征选择”](https://bit.ly/2HGON5B)，由K.
    Henniab、N. Mezghani和C. Gouin-Vallerand描述。
- en: Now let’s look at some of the types of connected features and how they are used.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一些连接特性的类型及其使用方法。
- en: Graphy Features
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图特性
- en: '*Graphy features* include any number of connection-related metrics about our
    graph, such as the number of relationships going into or out of nodes, a count
    of potential triangles, and neighbors in common. In our example, we’ll start with
    these measures because they are simple to gather and a good test of early hypotheses.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*图特性*包括关于我们的图的任意数量的连接相关度量，如进出节点的关系数量，潜在三角形的计数以及共同邻居。在我们的示例中，我们将从这些度量开始，因为它们易于获取，并且是早期假设的良好测试。'
- en: In addition, when we know precisely what we’re looking for, we can use feature
    engineering. For instance, if we want to know how many people have a fraudulent
    account at up to four hops out. This approach uses graph traversal to very efficiently
    find deep paths of relationships, looking at things such as labels, attributes,
    counts, and inferred relationships.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当我们准确知道自己要找的是什么时，我们可以使用特征工程。例如，如果我们想知道有多少人在最多四个跳点内有欺诈账户。这种方法使用图遍历来高效地查找深层关系路径，检查标签、属性、计数和推断关系等因素。
- en: We can also easily automate these processes and deliver those predictive graphy
    features into our existing pipeline. For example, we could abstract a count of
    fraudster relationships and add that number as a node attribute to be used for
    other machine learning tasks.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以轻松地自动化这些过程，并将这些预测性图特性传递到我们现有的管道中。例如，我们可以提取欺诈关系的计数，并将该数字作为节点属性添加，以供其他机器学习任务使用。
- en: Graph Algorithm Features
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图算法特性
- en: We can also use graph algorithms to find features where we know the general
    structure we’re looking for but not the exact pattern. As an illustration, let’s
    say we know certain types of community groupings are indicative of fraud; perhaps
    there’s a prototypical density or hierarchy of relationships. In this case, we
    don’t want a rigid feature of an exact organization but rather a flexible and
    globally relevant structure. We’ll use community detection algorithms to extract
    connected features in our example, but centrality algorithms, like PageRank, are
    also frequently applied.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用图算法来查找我们知道大致结构但不知道确切模式的特征。举例来说，假设我们知道某些类型的社群分组是欺诈的指示；也许存在典型的密度或关系层次结构。在这种情况下，我们不需要严格的确切组织特征，而是一个灵活且具有全球性相关结构。我们将使用社群检测算法来在我们的示例中提取连接特征，但像PageRank这样的中心性算法也经常被应用。
- en: Furthermore, approaches that combine several types of connected features seem
    to outperform sticking to one single method. For example, we could combine connected
    features to predict fraud with indicators based on communities found via the Louvain
    algorithm, influential nodes using PageRank, and the measure of known fraudsters
    at three hops out.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，结合几种类型的连接特征的方法似乎优于坚持单一方法。例如，我们可以结合通过Louvain算法找到的社群指标来预测欺诈，使用PageRank确定影响力节点，并且测量三跳之外已知欺诈者的程度。
- en: A combined approach is demonstrated in [Figure 8-3](#graph-algorithms-feature-extraction),
    where the authors combine graph algorithms like PageRank and Coloring with graphy
    measure such as in-degree and out-degree. This diagram is taken from the paper
    [“Collective Spammer Detection in Evolving Multi-Relational Social Networks”](https://bit.ly/2TyG6Mm),
    by S. Fakhraei et al.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[图8-3](#graph-algorithms-feature-extraction)展示了一种结合图算法如PageRank和Coloring以及图度量（如入度和出度）的综合方法。此图摘自论文[“Collective
    Spammer Detection in Evolving Multi-Relational Social Networks”](https://bit.ly/2TyG6Mm)，作者为S.
    Fakhraei等人。'
- en: The Graph Structure section illustrates connected feature extraction using several
    graph algorithms. Interestingly, the authors found extracting connected features
    from multiple types of relationships even more predictive than simply adding more
    features. The Report Subgraph section shows how graph features are converted into
    features that the ML model can use. By combining multiple methods in a graph-enhanced
    ML workflow, the authors were able to improve prior detection methods and classify
    70% of spammers that had previously required manual labeling, with 90% accuracy.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图结构部分展示了使用多种图算法进行连接特征提取。有趣的是，作者们发现从多种关系类型中提取连接特征，比简单添加更多特征更具预测性。报告子图部分展示了如何将图特征转换为机器学习模型可以使用的特征。通过在增强型图机器学习工作流中结合多种方法，作者们成功改进了先前的检测方法，并对以前需要手动标记的垃圾信息进行了70%的分类，并且准确率达到了90%。
- en: Even once we have extracted connected features, we can improve our training
    by using graph algorithms like PageRank to prioritize the features with the most
    influence. This enables us to adequately represent our data while eliminating
    noisy variables that could degrade results or slow processing. With this type
    of information, we can also identify features with high co-occurrence for further
    model tuning via feature reduction. This method is outlined in the research paper
    [“Using PageRank in Feature Selection”](https://bit.ly/2JDDwVw), by D. Ienco,
    R. Meo, and M. Botta.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们已经提取了连接特征，我们仍然可以通过使用PageRank等图算法来优化我们的训练，以优先考虑具有最大影响力的特征。这使我们能够充分代表我们的数据，同时消除可能会降低结果或减慢处理速度的噪声变量。有了这类信息，我们还可以识别具有高共现性的特征，以便通过特征降维进一步调整模型。这种方法在研究论文[“Using
    PageRank in Feature Selection”](https://bit.ly/2JDDwVw)，作者为D. Ienco, R. Meo, 和M.
    Botta中有所阐述。
- en: '![gral 0803](Images/gral_0803.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0803](Images/gral_0803.png)'
- en: Figure 8-3\. Connected feature extraction can be combined with other predictive
    methods to improve results. AUPR refers to the area under the precision-recall
    curve, with higher numbers preferred.
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-3. 连接特征提取可以与其他预测方法结合以改进结果。AUPR指的是精确-召回率曲线下的面积，数字越高越好。
- en: We’ve discussed how connected features are applied to scenarios involving fraud
    and spammer detection. In these situations, activities are often hidden in multiple
    layers of obfuscation and network relationships. Traditional feature extraction
    and selection methods may be unable to detect that behavior without the contextual
    information that graphs bring.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了如何应用连接特征来处理欺诈和垃圾邮件检测的情况。在这些情况下，活动通常隐藏在多层次的混淆和网络关系中。传统的特征提取和选择方法可能无法在没有图形带来的上下文信息的情况下检测到这种行为。
- en: Another area where connected features enhance machine learning (and the focus
    of the rest of this chapter) is *link prediction*. Link prediction is a way to
    estimate how likely a relationship is to form in the future, or whether it should
    already be in our graph but is missing due to incomplete data. Since networks
    are dynamic and can grow fairly quickly, being able to predict links that will
    soon be added has broad applicability, from product recommendations to drug retargeting
    and even inferring criminal relationships.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个增强机器学习的领域（本章剩余部分的重点）是*链接预测*。链接预测是估计未来关系形成的可能性，或者是否应该在我们的图中但由于数据不完整而缺失的一种方法。由于网络是动态的，并且可以相当快速地增长，能够预测即将添加的链接具有广泛的适用性，从产品推荐到药物重定位，甚至推断犯罪关系。
- en: Connected features from graphs are often used to improve link prediction using
    basic graphy features as well as features extracted from centrality and community
    algorithms. Link prediction based on node proximity or similarity is also standard;
    in the paper [“The Link Prediction Problem for Social Networks”](https://bit.ly/2uoyB0q)
    D. Liben-Nowell and J. Kleinberg suggest that the network structure alone may
    contain enough latent information to detect node proximity and outperform more
    direct measures.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从图形中的连接特征经常用于通过基本图形特征以及从中心性和社区算法中提取的特征来改进链接预测。基于节点接近度或相似性的链接预测也很常见；在论文[“社交网络的链接预测问题”](https://bit.ly/2uoyB0q)中，D.
    Liben-Nowell和J. Kleinberg建议，网络结构本身可能包含足够的潜在信息来检测节点接近度，并超过更直接的度量方法。
- en: Now that we’ve looked at ways connected features can enhance machine learning,
    let’s dive into our link prediction example and see how we can apply graph algorithms
    to improve our predictions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看过连接特征如何增强机器学习的方法，让我们深入研究我们的链接预测示例，看看如何应用图算法来改进我们的预测。
- en: 'Graphs and Machine Learning in Practice: Link Prediction'
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实践中的图形与机器学习：链接预测
- en: 'The rest of the chapter will demonstrate a hands-on example, based on the [Citation
    Network Dataset](https://aminer.org/citation), a research dataset extracted from
    DBLP, ACM, and MAG. The dataset is described in the paper [“ArnetMiner: Extraction
    and Mining of Academic Social Networks”](http://bit.ly/2U4C3fb), by J. Tang et
    al. The latest version contains 3,079,007 papers, 1,766,547 authors, 9,437,718
    author relationships, and 25,166,994 citation relationships.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '本章的其余部分将展示一个实际的例子，基于[Citation Network Dataset](https://aminer.org/citation)，这是从DBLP、ACM和MAG提取的研究数据集。该数据集在论文[“ArnetMiner:
    Extraction and Mining of Academic Social Networks”](http://bit.ly/2U4C3fb)中有描述，作者为J.
    Tang等人。最新版本包含3,079,007篇论文，1,766,547名作者，9,437,718个作者关系和25,166,994个引用关系。'
- en: 'We’ll be working with a subset focused on articles that appeared in the following
    publications:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下出版物中发表的文章的子集：
- en: '*Lecture Notes in Computer Science*'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*计算机科学讲义*'
- en: '*Communications of the ACM*'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ACM通信*'
- en: '*International Conference on Software Engineering*'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*国际软件工程大会*'
- en: '*Advances in Computing and Communications*'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*计算与通信的进展*'
- en: Our resulting dataset contains 51,956 papers, 80,299 authors, 140,575 author
    relationships, and 28,706 citation relationships. We’ll create a coauthors graph
    based on authors who have collaborated on papers and then predict future collaborations
    between pairs of authors. We’re only interested in collaborations between authors
    who haven’t collaborated before—we’re not concerned with multiple collaborations
    between pairs of authors.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果数据集包含51,956篇论文，80,299名作者，140,575个作者关系和28,706个引用关系。我们将创建一个基于合作撰写论文的作者的共作者图，然后预测未来作者之间的合作。我们只关注那些之前没有合作过的作者之间的合作，不关心作者对之间的多次合作。
- en: In the remainder of the chapter, we’ll set up the required tools and import
    the data into Neo4j. Then we’ll cover how to properly balance data and split samples
    into Spark DataFrames for training and testing. After that, we explain our hypothesis
    and methods for link prediction before creating a machine learning pipeline in
    Spark. Finally, we’ll walk through training and evaluating various prediction
    models, starting with basic graphy features and adding more graph algorithm features
    extracted using Neo4j.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将设置所需的工具并将数据导入Neo4j。然后，我们将讨论如何正确平衡数据，并将样本拆分为用于训练和测试的Spark DataFrames。之后，我们解释我们的假设和链接预测方法，然后在Spark中创建一个机器学习流水线。最后，我们将逐步训练和评估各种预测模型，从基本的图特征开始，逐步添加使用Neo4j提取的更多图算法特征。
- en: Tools and Data
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具和数据
- en: Let’s get started by setting up our tools and data. Then we’ll explore our dataset
    and create a machine learning pipeline.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始设置我们的工具和数据。然后我们将探索我们的数据集并创建一个机器学习流水线。
- en: 'Before we do anything else, let’s set up the libraries used in this chapter:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们做任何其他事情之前，让我们设置本章中使用的库：
- en: py2neo
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: py2neo
- en: A Neo4j Python library that integrates well with the Python data science ecosystem
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一款与Python数据科学生态系统良好集成的Neo4j Python库
- en: pandas
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: pandas
- en: A high-performance library for data wrangling outside of a database with easy-to-use
    data structures and data analysis tools
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一个高性能的库，用于在数据库之外进行数据整理，具有易于使用的数据结构和数据分析工具
- en: Spark MLlib
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Spark MLlib
- en: Spark’s machine learning library
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的机器学习库
- en: Note
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We use MLlib as an example of a machine learning library. The approach shown
    in this chapter could be used in combination with other ML libraries, such as
    scikit-learn.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以MLlib作为机器学习库的示例。本章展示的方法可以与其他ML库（如scikit-learn）结合使用。
- en: 'All the code shown will be run within the pyspark REPL. We can launch the REPL
    by running the following command:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 所有显示的代码都将在pyspark REPL中运行。我们可以通过运行以下命令来启动REPL：
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is similar to the command we used to launch the REPL in [Chapter 3](ch03.xhtml#graph_platforms),
    but instead of GraphFrames, we’re loading the `spark-tree-plotting` package. At
    the time of writing the latest released version of Spark is *spark-2.4.0-bin-hadoop2.7*,
    but as that may have changed by the time you read this, be sure to change the
    `SPARK_VERSION` environment variable appropriately.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于我们在[第3章](ch03.xhtml#graph_platforms)中用于启动REPL的命令，但是我们加载的是`spark-tree-plotting`包。在撰写本文时，Spark的最新发布版本是*spark-2.4.0-bin-hadoop2.7*，但由于您阅读时可能已有所变更，请相应地更改`SPARK_VERSION`环境变量。
- en: 'Once we’ve launched that we’ll import the following libraries that we’ll be
    using:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们启动了这个，我们将导入我们将要使用的以下库：
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'And now let’s create a connection to our Neo4j database:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们连接到我们的Neo4j数据库：
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Importing the Data into Neo4j
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将数据导入Neo4j
- en: 'Now we’re ready to load the data into Neo4j and create a balanced split for
    our training and testing. We need to download the ZIP file of [Version 10](https://bit.ly/2TszAH3)
    of the dataset, unzip it, and place the contents in our *import* folder. We should
    have the following files:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好将数据加载到Neo4j并为我们的训练和测试创建一个平衡的分割。我们需要下载[版本10](https://bit.ly/2TszAH3)的数据集ZIP文件，解压缩并将内容放入我们的*import*文件夹中。我们应该有以下文件：
- en: '*dblp-ref-0.json*'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*dblp-ref-0.json*'
- en: '*dblp-ref-1.json*'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*dblp-ref-1.json*'
- en: '*dblp-ref-2.json*'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*dblp-ref-2.json*'
- en: '*dblp-ref-3.json*'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*dblp-ref-3.json*'
- en: 'Once we have those files in the *import* folder, we need to add the following
    property to our Neo4j settings file so that we can process them using the APOC
    library:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将这些文件放入*import*文件夹中，我们需要将以下属性添加到我们的Neo4j设置文件中，以便我们可以使用APOC库来处理它们：
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'First we’ll create constraints to ensure we don’t create duplicate articles
    or authors:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建约束条件，以确保我们不创建重复的文章或作者：
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now we can run the following query to import the data from the JSON files:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以运行以下查询来从JSON文件导入数据：
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This results in the graph schema seen in [Figure 8-4](#ch8-citation-graph).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了在[图 8-4](#ch8-citation-graph)中看到的图模式。
- en: '![gral 0804](Images/gral_0804.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0804](Images/gral_0804.png)'
- en: Figure 8-4\. The citation graph
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-4\. 引文图
- en: This is a simple graph that connects articles and authors, so we’ll add more
    information we can infer from relationships to help with predictions.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的连接文章和作者的图，所以我们将添加更多我们可以从关系中推断出的信息，以帮助预测。
- en: The Coauthorship Graph
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合著关系图
- en: 'We want to predict future collaborations between authors, so we’ll start by
    creating a coauthorship graph. The following Neo4j Cypher query will create a
    `CO_AUTHOR` relationship between every pair of authors that have collaborated
    on a paper:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望预测作者之间未来的合作，因此我们将首先创建一个共同作者图。以下 Neo4j Cypher 查询将在每对合作过的作者之间创建一个`CO_AUTHOR`关系：
- en: '[PRE6]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `year` property that we set on the `CO_AUTHOR` relationship in the query
    is the earliest year when those two authors collaborated. We’re only interested
    in the first time that a pair of authors have collaborated—subsequent collaborations
    aren’t relevant.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在查询中设置的`CO_AUTHOR`关系上的`year`属性是这两位作者首次合作的最早年份。我们只关注作者首次合作的时间——随后的合作并不相关。
- en: '[Figure 8-5](#ch8-co-author) is in an example of part of the graph that gets
    created. We can already see some interesting community structures.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 8-5](#ch8-co-author) 是创建的图表的一部分示例。我们已经可以看到一些有趣的社区结构。'
- en: '![gral 0805](Images/gral_0805.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图 8-5](Images/gral_0805.png)'
- en: Figure 8-5\. The coauthor graph
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-5. 共同作者图
- en: Each circle in this diagram represents one author and the lines between them
    are `CO_AUTHOR` relationships, so we have four authors that have all collaborated
    with each other on the left, and then on the right two examples of three authors
    who have collaborated. Now that we have our data loaded and a basic graph, let’s
    create the two datasets we’ll need for training and testing.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 此图中的每个圆代表一个作者，它们之间的连线是`CO_AUTHOR`关系，因此左侧有四个作者彼此都有合作，右侧有两个例子是三位作者之间的合作。现在我们已经加载了数据并有了基本的图表，让我们创建我们将用于训练和测试的两个数据集。
- en: Creating Balanced Training and Testing Datasets
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建平衡的训练和测试数据集
- en: With link prediction problems we want to try and predict the future creation
    of links. This dataset works well for that because we have dates on the articles
    that we can use to split our data. We need to work out which year we’ll use to
    define our training/test split. We’ll train our model on everything before that
    year and then test it on the links created after that date.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于链接预测问题，我们希望尝试预测未来链接的创建。这个数据集非常适合，因为我们可以使用文章上的日期来划分我们的数据。我们需要确定使用哪一年来定义我们的训练/测试划分。我们将在此年份之前训练我们的模型，然后在该日期之后测试它。
- en: 'Let’s start by finding out when the articles were published. We can write the
    following query to get a count of the number of articles, grouped by year:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从了解文章发表的时间开始。我们可以编写以下查询来获取按年份分组的文章数量：
- en: '[PRE7]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let’s visualize this as a bar chart, with the following code:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将其可视化为条形图，使用以下代码：
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can see the chart generated by executing this code in [Figure 8-6](#ch8-articles-by-year).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过执行以下代码生成的图表来看到这个图表，其中[图 8-6](#ch8-articles-by-year)显示了文章按年份划分的情况。
- en: '![gral 0806](Images/gral_0806.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图 8-6](Images/gral_0806.png)'
- en: Figure 8-6\. Articles by year
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-6. 按年份分类的文章
- en: 'Very few articles were published before 1997, and then there were a lot published
    between 2001 and 2006, before a dip and then a gradual climb since 2011 (excluding
    2013). It looks like 2006 could be a good year to split our data for training
    our model and making predictions. Let’s check how many papers were published before
    that year and how many during and after. We can write the following query to compute
    this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 1997 年之前发表的文章极少，2001 年至 2006 年间有大量文章发表，之后出现了一段低谷，但自 2011 年以来（不包括 2013 年），逐渐上升。看起来
    2006 年可以成为我们划分数据、训练模型和进行预测的一个好年份。我们可以检查一下在此年份之前、之间以及之后分别发表了多少篇论文。我们可以编写以下查询来计算这些情况：
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result of this is as follows, where *true* means a paper was published
    before 2006:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果如下所示，其中*true*表示文章在 2006 年之前发表：
- en: '| training | count |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| training | count |'
- en: '| --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| false | 21059 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| false | 21059 |'
- en: '| true | 30897 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| true | 30897 |'
- en: Not bad! 60% of the papers were published before 2006 and 40% during or after
    2006\. This is a fairly balanced split of data for our training and testing.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 不错！60% 的论文发表于 2006 年之前，40% 发表于 2006 年或之后。这对于我们的训练和测试数据来说是一个相当平衡的分布。
- en: 'So now that we have a good split of papers, let’s use the same 2006 split for
    coauthorship. We’ll create a `CO_AUTHOR_EARLY` relationship between pairs of authors
    whose first collaboration was *before 2006*:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了论文的良好分布，让我们在共同作者关系中使用相同的 2006 年分割点。我们将在*2006 年之前*首次合作的作者对之间创建一个`CO_AUTHOR_EARLY`关系：
- en: '[PRE10]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And then we’ll create a `CO_AUTHOR_LATE` relationship between pairs of authors
    whose first collaboration was *during or after 2006*:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将在*2006 年或之后*首次合作的作者对之间创建一个`CO_AUTHOR_LATE`关系：
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Before we build our training and test sets, let’s check how many pairs of nodes
    we have that have links between them. The following query will find the number
    of `CO_AUTHOR_EARLY` pairs:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们构建训练和测试集之前，让我们先检查一下有多少对节点之间存在链接。以下查询将找到`CO_AUTHOR_EARLY`对的数量：
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Running that query will return the result shown here:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 运行该查询将返回以下结果：
- en: '| count |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 数量 |'
- en: '| --- |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 81096 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 81096 |'
- en: 'And this query will find the number of `CO_AUTHOR_LATE` pairs:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 而这个查询将找到`CO_AUTHOR_LATE`对的数量：
- en: '[PRE13]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Running that query returns this result:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 运行该查询将返回此结果：
- en: '| count |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 数量 |'
- en: '| --- |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| 74128 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 74128 |'
- en: Now we’re ready to build our training and test datasets.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备构建我们的训练和测试数据集。
- en: Balancing and splitting data
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平衡和分割数据
- en: The pairs of nodes with `CO_AUTHOR_EARLY` and `CO_AUTHOR_LATE` relationships
    between them will act as our positive examples, but we’ll also need to create
    some negative examples. Most real-world networks are sparse, with concentrations
    of relationships, and this graph is no different. The number of examples where
    two nodes do not have a relationship is much larger than the number that do have
    a relationship.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 有`CO_AUTHOR_EARLY`和`CO_AUTHOR_LATE`关系的节点对将作为我们的正面例子，但我们还需要创建一些负面例子。大多数现实世界的网络都是稀疏的，具有关系的集中区域，这个图也不例外。两个节点没有关系的例子数量远远大于有关系的数量。
- en: 'If we query our `CO_AUTHOR_EARLY` data, we’ll find there are 45,018 authors
    with that type of relationship but only 81,096 relationships between authors.
    That might not sound imbalanced, but it is: the potential maximum number of relationships
    that our graph could have is (45018 * 45017) / 2 = 1,013,287,653, which means
    there are a lot of negative examples (no links). If we used all the negative examples
    to train our model, we’d have a severe class imbalance problem. A model could
    achieve extremely high accuracy by predicting that every pair of nodes doesn’t
    have a relationship.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查询我们的`CO_AUTHOR_EARLY`数据，我们会发现有45,018名作者拥有这种关系类型，但只有81,096个作者之间存在关系。这听起来可能不太平衡，但事实上是：我们的图可能具有的最大关系数是(45018
    * 45017) / 2 = 1,013,287,653，这意味着有很多负面例子（没有链接）。如果我们用所有负面例子来训练我们的模型，我们会面临严重的类别不平衡问题。一个模型可以通过预测每对节点都没有关系来达到极高的准确率。
- en: In their paper [“New Perspectives and Methods in Link Prediction”](https://ntrda.me/2TrSg9K),
    R. Lichtenwalter, J. Lussier, and N. Chawla describe several methods to address
    this challenge. One of these approaches is to build negative examples by finding
    nodes within our neighborhood that we aren’t currently connected to.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的论文[“链接预测的新视角和方法”](https://ntrda.me/2TrSg9K)，R. Lichtenwalter, J. Lussier和N.
    Chawla描述了几种解决这一挑战的方法。其中一种方法是通过找到我们当前未连接到的邻域内的节点来构建负面例子。
- en: We will build our negative examples by finding pairs of nodes that are a mix
    of between two and three hops away from each other, excluding those pairs that
    already have a relationship. We’ll then downsample those pairs of nodes so that
    we have an equal number of positive and negative examples.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过找到两个到三个跳之间的节点对来构建我们的负面例子，排除那些已经有关系的对。然后，我们会对这些节点对进行下采样，以便正负样本数目相等。
- en: Note
  id: totrans-128
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We have 314,248 pairs of nodes that don’t have a relationship between each other
    at a distance of two hops. If we increase the distance to three hops, we have
    967,677 pairs of nodes.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个跳跃距离内，我们有314,248对节点之间没有关系。如果我们将距离增加到三个跳，我们有967,677对节点。
- en: 'The following function will be used to downsample the negative examples:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数将用于对负面例子进行下采样：
- en: '[PRE14]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This function works out the difference between the number of positive and negative
    examples, and then samples the negative examples so that there are equal numbers.
    We can then run the following code to build a training set with balanced positive
    and negative examples:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数计算正负例子之间的差异，然后对负面例子进行采样，以便数目相等。然后我们可以运行以下代码来构建一个具有平衡正负例子的训练集：
- en: '[PRE15]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We’ve now coerced the `label` column to be a category, where `1` indicates
    that there is a link between a pair of nodes, and `0` indicates that there is
    not a link. We can look at the data in our DataFrame by running the following
    code:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经强制`标签`列成为一个类别，其中`1`表示节点对之间存在链接，`0`表示不存在链接。我们可以通过运行以下代码查看DataFrame中的数据：
- en: '[PRE16]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '| node1 | node2 | label |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 节点1 | 节点2 | 标签 |'
- en: '| --- | --- | --- |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 10019 | 28091 | 1 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 10019 | 28091 | 1 |'
- en: '| 10170 | 51476 | 1 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 10170 | 51476 | 1 |'
- en: '| 10259 | 17140 | 0 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 10259 | 17140 | 0 |'
- en: '| 10259 | 26047 | 1 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 10259 | 26047 | 1 |'
- en: '| 10293 | 71349 | 1 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 10293 | 71349 | 1 |'
- en: The results show us a list of node pairs and whether they have a coauthor relationship;
    for example, nodes `10019` and `28091` have a `1` label, indicating a collaboration.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 结果展示了一系列节点对及其是否存在共同作者关系；例如，节点 `10019` 和 `28091` 有一个标签为 `1` 的关系，表示有合作。
- en: 'Now let’s execute the following code to check the summary of contents for the
    DataFrame:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们执行以下代码来检查 DataFrame 的内容摘要：
- en: '[PRE17]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Here’s the result:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '| label | count |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | 计数 |'
- en: '| --- | --- |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0 | 81096 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 81096 |'
- en: '| 1 | 81096 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 81096 |'
- en: 'We’ve created our training set with the same number of positive and negative
    samples. Now we need to do the same for the test set. The following code will
    build a test set with balanced positive and negative examples:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经创建了一个训练集，其中正负样本数量相同。现在我们需要为测试集做同样的事情。以下代码将创建一个包含平衡正负例的测试集：
- en: '[PRE18]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can execute the following code to check the contents of the DataFrame:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以执行以下代码来检查 DataFrame 的内容：
- en: '[PRE19]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Which gives the following result:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了以下结果：
- en: '| label | count |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | 计数 |'
- en: '| --- | --- |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 0 | 74128 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 74128 |'
- en: '| 1 | 74128 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 74128 |'
- en: Now that we have balanced training and test datasets, let’s look at our methods
    for predicting links.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了平衡的训练和测试数据集，让我们来看看我们预测链接的方法。
- en: How We Predict Missing Links
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何预测缺失的链接
- en: 'We need to start with some basic assumptions about what elements in our data
    might predict whether two authors will become coauthors at a later date. Our hypothesis
    would vary by domain and problem, but in this case, we believe the most predictive
    features will be related to communities. We’ll begin with the assumption that
    the following elements increase the probability that authors become coauthors:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要从一些基本假设开始，这些假设可以预测我们的数据中的哪些元素可能会导致两个作者在以后成为共同作者。我们的假设会根据领域和问题而变化，但在这种情况下，我们认为最有预测性的特征将与社区相关。我们将从以下假设开始，认为以下元素会增加作者成为共同作者的概率：
- en: More coauthors in common
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多共同作者
- en: Potential triadic relationships between authors
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作者之间的潜在三元关系
- en: Authors with more relationships
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有更多关系的作者
- en: Authors in the same community
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一社区中的作者
- en: Authors in the same, tighter community
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一个更紧密社区中的作者
- en: We’ll build graph features based on our assumptions and use those to train a
    binary classifier. *Binary classification* is a type of ML with the task of predicting
    which of two predefined groups an element belongs to based on a rule. We’re using
    the classifier for the task of predicting whether a pair of authors will have
    a link or not, based on a classification rule. For our examples, a value of `1`
    means there is a link (coauthorship), and a value of `0` means there isn’t a link
    (no coauthorship).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将基于假设构建图特征，并使用这些特征来训练一个二元分类器。*二元分类*是一种机器学习类型，其任务是根据规则预测元素属于两个预定义组中的哪一个。我们使用分类器来预测一对作者是否会有联系，基于一个分类规则。对于我们的例子，`1`
    的值表示存在联系（共同作者），`0` 的值表示不存在联系（非共同作者）。
- en: We’ll implement our binary classifier as a random forest in Spark. A *random
    forest* is an ensemble learning method for classification, regression, and other
    tasks, as illustrated in [Figure 8-7](#ch8-random-forest).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实现我们的二元分类器作为 Spark 中的随机森林。*随机森林*是一种集成学习方法，用于分类、回归和其他任务，如 [图 8-7](#ch8-random-forest)
    所示。
- en: '![gral 0807](Images/gral_0807.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0807](Images/gral_0807.png)'
- en: Figure 8-7\. A random forest builds a collection of decision trees and then
    aggregates results for a majority vote (for classification) or an average value
    (for regression).
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-7\. 随机森林构建一组决策树，然后对结果进行多数投票（分类）或平均值计算（回归）。
- en: Our random forest classifier will take the results from the multiple decision
    trees we train and then use voting to predict a classification—in our example,
    whether there is a link (coauthorship) or not.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的随机森林分类器将使用我们训练的多个决策树的结果，并使用投票来预测分类——在我们的例子中，是否存在链接（共同作者）。
- en: Now let’s create our workflow.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建我们的工作流程。
- en: Creating a Machine Learning Pipeline
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建机器学习管道
- en: We’ll create our machine learning pipeline based on a random forest classifier
    in Spark. This method is well suited as our dataset will be comprised of a mix
    of strong and weak features. While the weak features will sometimes be helpful,
    the random forest method will ensure we don’t create a model that only fits our
    training data.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将基于Spark中的随机森林分类器创建我们的机器学习管道。这种方法非常适合，因为我们的数据集将由强特征和弱特征的混合组成。虽然弱特征有时会有所帮助，但随机森林方法将确保我们不会创建一个仅适合于我们训练数据的模型。
- en: To create our ML pipeline, we’ll pass in a list of features as the `fields`
    variable—these are the features that our classifier will use. The classifier expects
    to receive those features as a single column called `features`, so we use the
    `VectorAssembler` to transform the data into the required format.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建我们的ML管道，我们将`fields`变量作为特征列表传入--这些是我们的分类器将使用的特征。分类器期望将这些特征作为名为`features`的单列接收，因此我们使用`VectorAssembler`将数据转换为所需的格式。
- en: 'The following code creates a machine learning pipeline and sets up our parameters
    using MLlib:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码创建了一个机器学习管道，并使用MLlib设置了我们的参数：
- en: '[PRE20]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The `RandomForestClassifier` uses these parameters:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`RandomForestClassifier`使用这些参数：'
- en: '`labelCol`'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`labelCol`'
- en: The name of the field containing the variable we want to predict; i.e., whether
    a pair of nodes have a link
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 包含我们想要预测的变量的字段名称；即，节点对是否有链接
- en: '`featuresCol`'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`featuresCol`'
- en: The name of the field containing the variables that will be used to predict
    whether a pair of nodes have a link
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 包含用于预测节点对是否有链接的变量的字段名称
- en: '`numTrees`'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '`numTrees`'
- en: The number of decision trees that form the random forest
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 形成随机森林的决策树数量
- en: '`maxDepth`'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '`maxDepth`'
- en: The maximum depth of the decision trees
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树的最大深度
- en: We chose the number of decision trees and their depth based on experimentation.
    We can think about hyperparameters like the settings of an algorithm that can
    be adjusted to optimize performance. The best hyperparameters are often difficult
    to determine ahead of time, and tuning a model usually requires some trial and
    error.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据实验选择了决策树数量和它们的深度。我们可以考虑超参数，例如可以调整以优化性能的算法设置。最佳超参数通常很难提前确定，并且调整模型通常需要一些试错。
- en: We’ve covered the basics and set up our pipeline, so let’s dive into creating
    our model and evaluating how well it performs.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经介绍了基础知识并设置了我们的管道，现在让我们深入研究创建我们的模型并评估其表现。
- en: 'Predicting Links: Basic Graph Features'
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测链接：基本图特征
- en: 'We’ll start by creating a simple model that tries to predict whether two authors
    will have a future collaboration based on features extracted from common authors,
    preferential attachment, and the total union of neighbors:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从创建一个简单的模型开始，该模型尝试基于从共同作者、优先连接和邻居总并集中提取的特征来预测两位作者是否将来会合作：
- en: Common authors
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 共同作者
- en: Finds the number of potential triangles between two authors. This captures the
    idea that two authors who have coauthors in common may be introduced and collaborate
    in the future.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 发现两位作者之间潜在三角形的数量。这捕捉到的思想是，共同拥有合作者的两位作者可能在未来相互引介并合作。
- en: Preferential attachment
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 优先连接
- en: Produces a score for each pair of authors by multiplying the number of coauthors
    each has. The intuition is that authors are more likely to collaborate with someone
    who already coauthors a lot of papers.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将每个作者拥有的合作者数量相乘来为每对作者产生一个分数。直觉是，作者更有可能与已经合作过多篇论文的人合作。
- en: Total union of neighbors
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 邻居的总并集
- en: Finds the total number of coauthors that each author has, minus the duplicates.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 发现每位作者拥有的总合作者数，减去重复的部分。
- en: 'In Neo4j, we can compute these values using Cypher queries. The following function
    will compute these measures for the training set:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在Neo4j中，我们可以使用Cypher查询计算这些值。以下函数将为训练集计算这些度量：
- en: '[PRE21]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'And the following function will compute them for the test set:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的函数将为测试集计算它们：
- en: '[PRE22]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Both of these functions take in a DataFrame that contains pairs of nodes in
    the columns `node1` and `node2`. We then build an array of maps containing these
    pairs and compute each of the measures for each pair of nodes.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个函数都接收包含`node1`和`node2`列中节点对的DataFrame。然后，我们构建包含这些节点对的映射数组，并计算每对节点的每个度量。
- en: Note
  id: totrans-203
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The `UNWIND` clause is particularly useful in this chapter for taking a large
    collection of node pairs and returning all their features in one query.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，`UNWIND`子句对于一次性获取大量节点对并在一个查询中返回它们的所有特征尤为有用。
- en: 'We can apply these functions in Spark to our training and test DataFrames with
    the following code:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些函数应用到我们的训练和测试 DataFrame 中的 Spark 中，代码如下：
- en: '[PRE23]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let’s explore the data in our training set. The following code will plot a
    histogram of the frequency of `commonAuthors`:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一下我们训练集中的数据。以下代码将绘制`commonAuthors`频率的直方图：
- en: '[PRE24]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We can see the chart generated in [Figure 8-8](#ch8-explore-authors).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[图 8-8](#ch8-explore-authors)中看到生成的图表。
- en: '![gral 0808](Images/gral_0808.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0808](Images/gral_0808.png)'
- en: Figure 8-8\. Frequency of commonAuthors
  id: totrans-211
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-8\. 共同作者频率
- en: On the left we see the frequency of `commonAuthors` when authors have collaborated,
    and on the right we see the frequency of `commonAuthors` when they haven’t. For
    those who haven’t collaborated (right side) the maximum number of common authors
    is 9, but 95% of the values are 1 or 0\. It’s not surprising that of the people
    who have not collaborated on a paper, most also do not have many other coauthors
    in common. For those who have collaborated (left side), 70% have less than five
    coauthors in common, with a spike between one and two other coauthors.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在左侧，我们可以看到当作者合作时`commonAuthors`的频率，而右侧则是他们没有合作时的频率。对于那些没有合作过的人（右侧），最大的共同作者数量是
    9，但是 95% 的值为 1 或 0。并不奇怪，那些没有在论文上合作的人大多数也没有很多其他共同作者。对于那些合作过的人（左侧），70% 的人共同作者少于五个，其中在一个或两个共同作者之间有一个峰值。
- en: 'Now we want to train a model to predict missing links. The following function
    does this:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想要训练一个模型来预测缺失的链接。以下函数完成此操作：
- en: '[PRE25]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We’ll start by creating a basic model that only uses `commonAuthors`. We can
    create that model by running this code:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先创建一个仅使用`commonAuthors`的基本模型。我们可以通过运行以下代码来创建该模型：
- en: '[PRE26]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'With our model trained, let’s check how it performs against some dummy data.
    The following code evaluates the code against different values for `commonAuthors`:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完我们的模型后，让我们检查它在一些虚拟数据上的表现。以下代码评估了对不同`commonAuthors`值的代码：
- en: '[PRE27]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Running that code will give the following result:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 运行该代码将得到以下结果：
- en: '| commonAuthors | probability | prediction |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 共同作者 | 概率 | 预测 |'
- en: '| --- | --- | --- |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0 | [0.7540494940434322,0.24595050595656787] | 0.0 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 0 | [0.7540494940434322,0.24595050595656787] | 0.0 |'
- en: '| 1 | [0.7540494940434322,0.24595050595656787] | 0.0 |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 1 | [0.7540494940434322,0.24595050595656787] | 0.0 |'
- en: '| 2 | [0.0536835525078107,0.9463164474921892] | 1.0 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| 2 | [0.0536835525078107,0.9463164474921892] | 1.0 |'
- en: '| 10 | [0.0536835525078107,0.9463164474921892] | 1.0 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 10 | [0.0536835525078107,0.9463164474921892] | 1.0 |'
- en: If we have a `commonAuthors` value of less than 2 there’s a 75% probability
    that there won’t be a relationship between the authors, so our model predicts
    0. If we have a `commonAuthors` value of 2 or more there’s a 94% probability that
    there will be a relationship between the authors, so our model predicts 1.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的`commonAuthors`值小于 2，那么有 75% 的概率作者之间没有关系，因此我们的模型预测为 0。如果`commonAuthors`值为
    2 或更多，则有 94% 的概率作者之间存在关系，因此我们的模型预测为 1。
- en: 'Let’s now evaluate our model against the test set. Although there are several
    ways to evaluate how well a model performs, most are derived from a few baseline
    predictive metrics, as outlined in [Table 8-1](#predictive-metrics):'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们对我们的模型进行测试集评估。虽然有多种评估模型表现的方法，但大多数都源自几个基线预测性指标，如[表 8-1](#predictive-metrics)所述：
- en: Table 8-1\. Predictive metrics
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8-1\. 预测性指标
- en: '| Measure | Formula | Description |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 度量 | 公式 | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Accuracy | <math display="block" alttext="StartFraction upper T r u e upper
    P o s i t i v e s plus upper T r u e upper N e g a t i v e s Over upper T o t
    a l upper P r e d i c t i o n s EndFraction"><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow>
    <mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>P</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi></mrow></mfrac></math>
    | The fraction of predictions our model gets right, or the total number of correct
    predictions divided by the total number of predictions. Note that accuracy alone
    can be misleading, especially when our data is unbalanced. For example, if we
    have a dataset containing 95 cats and 5 dogs and our model predicts that every
    image is a cat we’ll have a 95% accuracy score despite correctly identifying none
    of the dogs. |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | <math display="block" alttext="StartFraction upper T r u e upper P
    o s i t i v e s plus upper T r u e upper N e g a t i v e s Over upper T o t a
    l upper P r e d i c t i o n s EndFraction"><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow>
    <mrow><mi>T</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi><mi>P</mi><mi>r</mi><mi>e</mi><mi>d</mi><mi>i</mi><mi>c</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>s</mi></mrow></mfrac></math>
    | 我们模型预测正确的比例，或者正确预测的总数除以预测总数。请注意，仅仅依靠准确率可能会产生误导，特别是在数据不平衡的情况下。例如，如果我们的数据集中包含95只猫和5只狗，并且我们的模型预测每张图像都是猫，尽管没有正确识别任何狗，我们的准确率得分为95%。
    |'
- en: '| Precision | <math display="block" alttext="StartFraction upper T r u e upper
    P o s i t i v e s Over upper T r u e upper P o s i t i v e s plus upper F a l
    s e upper P o s i t i v e s EndFraction"><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow>
    <mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow></mfrac></math>
    | The proportion of *positive identifications* that are correct. A low precision
    score indicates more false positives. A model that produces no false positives
    has a precision of 1.0. |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 精确率 | <math display="block" alttext="StartFraction upper T r u e upper P
    o s i t i v e s Over upper T r u e upper P o s i t i v e s plus upper F a l s
    e upper P o s i t i v e s EndFraction"><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow>
    <mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow></mfrac></math>
    | *正例识别*中正确的比例。低精确率表明更多的假阳性。一个不产生假阳性的模型精确率为1.0。 |'
- en: '| Recall (true positive rate) | <math display="block" alttext="StartFraction
    upper T r u e upper P o s i t i v e s Over upper T r u e upper P o s i t i v e
    s plus upper F a l s e upper N e g a t i v e s EndFraction"><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow>
    <mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow></mfrac></math>
    | The proportion of *actual positives* that are identified correctly. A low recall
    score indicates more false negatives. A model that produces no false negatives
    has a recall of 1.0. |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 召回率（真正例率） | <math display="block" alttext="StartFraction upper T r u e upper
    P o s i t i v e s Over upper T r u e upper P o s i t i v e s plus upper F a l
    s e upper N e g a t i v e s EndFraction"><mfrac><mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow>
    <mrow><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow></mfrac></math>
    | *实际正例*中被正确识别的比例。低召回率表明更多的假阴性。一个不产生假阴性的模型召回率为1.0。 |'
- en: '| False positive rate | <math display="block" alttext="StartFraction upper
    F a l s e upper P o s i t i v e s Over upper F a l s e upper P o s i t i v e s
    plus upper T r u e upper N e g a t i v e s EndFraction"><mfrac><mrow><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow>
    <mrow><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow></mfrac></math>
    | The proportion of *incorrect positives* that are identified. A high score indicates
    more false positives. |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 假阳性率 | <math display="block" alttext="StartFraction upper F a l s e upper
    P o s i t i v e s Over upper F a l s e upper P o s i t i v e s plus upper T r
    u e upper N e g a t i v e s EndFraction"><mfrac><mrow><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow>
    <mrow><mi>F</mi><mi>a</mi><mi>l</mi><mi>s</mi><mi>e</mi><mi>P</mi><mi>o</mi><mi>s</mi><mi>i</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi><mo>+</mo><mi>T</mi><mi>r</mi><mi>u</mi><mi>e</mi><mi>N</mi><mi>e</mi><mi>g</mi><mi>a</mi><mi>t</mi><mi>i</mi><mi>v</mi><mi>e</mi><mi>s</mi></mrow></mfrac></math>
    | *错误的阳性* 的比例。高分数表示更多的假阳性。 |'
- en: '| Receiver operating characteristic (ROC) curve | X-Y chart | ROC curve is
    a plot of the Recall (true positive rate) against the False Positive rate at different
    classification thresholds. The area under the curve (AUC) measures the two-dimensional
    area underneath the ROC curve from an X-Y axis (0,0) to (1,1). |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 接收者操作特征（ROC）曲线 | X-Y 图表 | ROC曲线是在不同分类阈值下绘制的召回率（真阳性率）与假阳性率的图表。曲线下面积（AUC）测量了从X-Y轴（0,0）到（1,1）下面的二维区域。
    |'
- en: We’ll use accuracy, precision, recall, and ROC curves to evaluate our models.
    Accuracy is a coarse measure, so we’ll focus on increasing our overall precision
    and recall measures. We’ll use the ROC curves to compare how individual features
    change predictive rates.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用准确率、精确率、召回率和ROC曲线来评估我们的模型。准确率是一个粗略的度量，所以我们将专注于增加整体精确率和召回率。我们将使用ROC曲线来比较单个特征如何改变预测率。
- en: Tip
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Depending on our goals we may want to favor different measures. For example,
    we may want to eliminate all false negatives for disease indicators, but we wouldn’t
    want to push predictions of everything into a positive result. There may be multiple
    thresholds we set for different models that pass some results through to secondary
    inspection on the likelihood of false results.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的目标，我们可能希望偏向不同的度量标准。例如，对于疾病指标，我们可能希望消除所有假阴性，但我们不希望将所有预测推向阳性结果。对于不同的模型，我们可能设置多个阈值，以便在可能出现误报结果的情况下将某些结果传递到二次检查。
- en: Lowering classification thresholds results in more overall positive results,
    thus increasing both false positives and true positives.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 降低分类阈值会导致更多的整体阳性结果，从而增加假阳性和真阳性。
- en: 'Let’s use the following function to compute these predictive measures:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下函数计算这些预测指标：
- en: '[PRE28]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We’ll then write a function to display the results in an easier-to-consume
    format:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将编写一个函数以更易于消化的格式显示结果：
- en: '[PRE29]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can call the function with this code and display the results:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这段代码调用函数并显示结果：
- en: '[PRE30]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The predictive measures for the common authors model are:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 常见作者模型的预测指标是：
- en: '| measure | score |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| measure | score |'
- en: '| --- | --- |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| accuracy | 0.864457 |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | 0.864457 |'
- en: '| recall | 0.753278 |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 召回率 | 0.753278 |'
- en: '| precision | 0.968670 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 精确率 | 0.968670 |'
- en: This is not a bad start given that we’re predicting future collaboration based
    only on the number of common authors in our pairs of authors. However, we get
    a bigger picture if we consider these measures in context with one another. For
    example, this model has a precision of 0.968670, which means it’s very good at
    predicting that *links exist*. However, our recall is 0.753278, which means it’s
    not good at predicting when *links do not exist*.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们仅基于作者对的共同作者数量来预测未来的合作，这并不是一个坏的开端。但是，如果我们将这些度量标准放在一起考虑，我们可以得到更全面的图片。例如，这个模型的精确率为0.968670，这意味着它非常擅长预测*存在链接*。然而，我们的召回率为0.753278，这意味着它在预测*不存在链接*时表现不佳。
- en: 'We can also plot the ROC curve (correlation of true positives and False positives)
    using the following functions:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用以下函数绘制ROC曲线（真阳性和假阳性的相关性）：
- en: '[PRE31]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We call it like this:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这样称呼它：
- en: '[PRE32]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We can see the ROC curve for our basic model in [Figure 8-9](#ch8-roc-basic).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[图8-9](#ch8-roc-basic)中看到我们基本模型的ROC曲线。
- en: '![gral 0809](Images/gral_0809.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0809](Images/gral_0809.png)'
- en: Figure 8-9\. The ROC curve for basic model
  id: totrans-259
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-9\. 基础模型的ROC曲线
- en: The common authors model gives us a 0.86 area under the curve (AUC) score. Although
    this gives us one overall predictive measure, we need the chart (or other measures)
    to evaluate whether this fits our goal. In [Figure 8-9](#ch8-roc-basic) we see
    that as we get close to an 80% true positive rate (recall) our false positive
    rate reaches about 20%. That could be problematic in scenarios like fraud detection
    where false positives are expensive to chase.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 通用作者模型给出了0.86的曲线下面积（AUC）得分。尽管这为我们提供了一个总体预测度量，但我们需要通过图表（或其他措施）来评估是否符合我们的目标。在[图 8-9](#ch8-roc-basic)中，我们看到当真阳性率（召回率）接近80%时，我们的假阳性率达到约20%。在诸如欺诈检测这类场景中，这可能是有问题的，因为追踪假阳性的成本很高。
- en: 'Now let’s use the other graphy features to see if we can improve our predictions.
    Before we train our model, let’s see how the data is distributed. We can run the
    following code to show descriptive statistics for each of our graphy features:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用其他图特征来看看是否可以改进我们的预测。在训练我们的模型之前，让我们看看数据是如何分布的。我们可以运行以下代码来展示每个图特征的描述统计：
- en: '[PRE33]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We can see the results of running those bits of code in the following tables:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在下面的表格中看到运行这些代码段的结果：
- en: '| summary | commonAuthors | prefAttachment | totalNeighbors |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| summary | commonAuthors | prefAttachment | totalNeighbors |'
- en: '| --- | --- | --- | --- |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| count | 81096 | 81096 | 81096 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| count | 81096 | 81096 | 81096 |'
- en: '| mean | 3.5959233501035808 | 69.93537289138798 | 10.082408503502021 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| mean | 3.5959233501035808 | 69.93537289138798 | 10.082408503502021 |'
- en: '| stddev | 4.715942231635516 | 171.47092255919472 | 8.44109970920685 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| stddev | 4.715942231635516 | 171.47092255919472 | 8.44109970920685 |'
- en: '| min | 0 | 1 | 2 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| min | 0 | 1 | 2 |'
- en: '| max | 44 | 3150 | 90 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| max | 44 | 3150 | 90 |'
- en: '| summary | commonAuthors | prefAttachment | totalNeighbors |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| summary | commonAuthors | prefAttachment | totalNeighbors |'
- en: '| --- | --- | --- | --- |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| count | 81096 | 81096 | 81096 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| count | 81096 | 81096 | 81096 |'
- en: '| mean | 0.37666469369635985 | 48.18137762651672 | 12.97586810693499 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| mean | 0.37666469369635985 | 48.18137762651672 | 12.97586810693499 |'
- en: '| stddev | 0.6194576095461857 | 94.92635344980489 | 10.082991078685803 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| stddev | 0.6194576095461857 | 94.92635344980489 | 10.082991078685803 |'
- en: '| min | 0 | 1 | 1 |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| min | 0 | 1 | 1 |'
- en: '| max | 9 | 1849 | 89 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| max | 9 | 1849 | 89 |'
- en: Features with larger differences between links (coauthorship) and no link (no
    coauthorship) should be more predictive because the divide is greater. The average
    value for `prefAttachment` is higher for authors who have collaborated versus
    those who haven’t. That difference is even more substantial for `commonAuthors`.
    We notice that there isn’t much difference in the values for `totalNeighbors`,
    which probably means this feature won’t be very predictive. Also interesting is
    the large standard deviation as well as the minimum and maximum values for preferential
    attachment. This is what we might expect for small-world networks with concentrated
    hubs (superconnectors).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 特征之间差异较大（共同作者关系）和没有连接（无共同作者关系）的特征应该更具预测性，因为分歧更大。对于具有合作的作者而言，`prefAttachment`的平均值更高。这对于`commonAuthors`来说更为显著。我们注意到，对于`totalNeighbors`的值并没有太大的差异，这可能意味着该特征不会很具预测性。此外，优先附加的标准偏差很大，以及最小和最大值也是我们在具有集中枢纽的小世界网络中所预期的。
- en: 'Now let’s train a new model, adding preferential attachment and total union
    of neighbors, by running the following code:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过运行以下代码来训练一个新模型，添加优先附加和总邻居的联合：
- en: '[PRE35]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'And now let’s evaluate the model and display the results:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们评估模型并显示结果：
- en: '[PRE36]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The predictive measures for the graphy model are:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图特征模型的预测性能如下：
- en: '| measure | score |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| measure | score |'
- en: '| --- | --- |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| accuracy | 0.978351 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| accuracy | 0.978351 |'
- en: '| recall | 0.924226 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| recall | 0.924226 |'
- en: '| precision | 0.943795 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| precision | 0.943795 |'
- en: 'Our accuracy and recall have increased substantially, but the precision has
    dropped a bit and we’re still misclassifying about 8% of the links. Let’s plot
    the ROC curve and compare our basic and graphy models by running the following
    code:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的准确率和召回率显著提高，但精确率有所下降，我们仍然在误分类约8%的链接。让我们通过运行以下代码来绘制ROC曲线，并比较基础和图特征模型：
- en: '[PRE37]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We can see the output in [Figure 8-10](#ch8-roc-graphy).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[图 8-10](#ch8-roc-graphy)中看到输出。
- en: '![gral 0810](Images/gral_0810.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0810](Images/gral_0810.png)'
- en: Figure 8-10\. The ROC curve for the graphy model
  id: totrans-294
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-10\. 图特征模型的ROC曲线
- en: Overall it looks like we’re headed in the right direction and it’s helpful to
    visualize comparisons to get a feel for how different models impact our results.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 总体上看，我们的方向是正确的，通过可视化比较来感受不同模型对结果的影响是很有帮助的。
- en: Now that we have more than one feature, we want to evaluate which features are
    making the most difference. We’ll use *feature importance* to rank the impact
    of different features to our model’s prediction. This enables us to evaluate the
    influence on results that different algorithms and statistics have.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有多个特征，我们想评估哪些特征产生了最大的影响。我们将使用*特征重要性*来排名不同特征对我们模型预测影响的程度。这使我们能够评估不同算法和统计数据对结果的影响。
- en: Note
  id: totrans-297
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: To compute feature importance, the random forest algorithm in Spark averages
    the reduction in impurity across all trees in the forest. The *impurity* is the
    frequency at which randomly assigned labels are incorrect.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算特征重要性，Spark中的随机森林算法对森林中所有树的纯度降低进行平均。*纯度*是随机分配标签错误的频率。
- en: Feature rankings are in comparison to the group of features we’re evaluating,
    always normalized to 1. If we rank one feature, its feature importance is 1.0
    as it has 100% of the influence on the model.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 特征排名与我们评估的特征组进行比较，总是标准化为 1。如果我们排名一个特征，其特征重要性为 1.0，因为它对模型有 100% 的影响。
- en: 'The following function creates a chart showing the most influential features:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数创建了一个显示最具影响力特征的图表：
- en: '[PRE38]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'And we call it like this:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们这样调用它：
- en: '[PRE39]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The results of running that function can be seen in [Figure 8-11](#ch8-feature-importance-graphy).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 运行该函数的结果可以在[图 8-11](#ch8-feature-importance-graphy)中看到。
- en: '![gral 0811](Images/gral_0811.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0811](Images/gral_0811.png)'
- en: 'Figure 8-11\. Feature importance: graphy model'
  id: totrans-306
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-11\. 特征重要性：图模型
- en: Of the three features we’ve used so far, `commonAuthors` is the most important
    feature by a large margin.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们使用的三个特征中，`commonAuthors`是最重要的特征，影响力大得多。
- en: 'To understand how our predictive models are created, we can visualize one of
    the decision trees in our random forest using the [spark-tree-plotting library](https://bit.ly/2usxOf2).
    The following code generates a [GraphViz file](http://www.graphviz.org):'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解我们的预测模型是如何创建的，我们可以使用[spark-tree-plotting库](https://bit.ly/2usxOf2)可视化随机森林中的一个决策树。以下代码生成一个[GraphViz文件](http://www.graphviz.org)：
- en: '[PRE40]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We can then generate a visual representation of that file by running the following
    command from the terminal:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过从终端运行以下命令生成该文件的可视化表示：
- en: '[PRE41]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The output of that command can be seen in [Figure 8-12](#ch8-visualize-decision-tree).
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 那个命令的输出可以在[图 8-12](#ch8-visualize-decision-tree)中看到。
- en: '![gral 0812](Images/gral_0812.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0812](Images/gral_0812.png)'
- en: Figure 8-12\. Visualizing a decision tree
  id: totrans-314
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-12\. 可视化决策树
- en: 'Imagine that we’re using this decision tree to predict whether a pair of nodes
    with the following features are linked:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 想象我们正在使用此决策树预测以下具有以下特征的节点对是否连接：
- en: '| commonAuthors | prefAttachment | totalNeighbors |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| commonAuthors | prefAttachment | totalNeighbors |'
- en: '| --- | --- | --- |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 10 | 12 | 5 |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 12 | 5 |'
- en: 'Our random forest walks through several steps to create a prediction:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的随机森林通过几个步骤来创建预测：
- en: We start from `node 0`, where we have more than 1.5 `commonAuthors`, so we follow
    the `False` branch down to `node 2`.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从`节点 0`开始，这里有超过 1.5 个`commonAuthors`，所以我们沿着`False`分支向下到`节点 2`。
- en: We have more than 2.5 `commonAuthors` here, so we follow the `False` branch
    to `node 6`.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里我们有超过 2.5 个`commonAuthors`，所以我们沿着`False`分支到`节点 6`。
- en: We have a score of less than 15.5 for `prefAttachment`, which takes us to `node
    9`.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在`prefAttachment`中得分少于 15.5 分，这将带我们到`节点 9`。
- en: Node 9 is a leaf node in this decision tree, which means that we don’t have
    to check any more conditions—the value of `Prediction` (i.e., `True`) on this
    node is the decision tree’s prediction.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 节点 9 是决策树中的叶节点，这意味着我们不需要再检查任何条件——该节点上的`Prediction`（即`True`）是决策树的预测。
- en: Finally, the random forest evaluates the item being predicted against a collection
    of these decision trees and makes its prediction based on the most popular outcome.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，随机森林评估要预测的项目与这些决策树集合之间的联系，并根据最常见的结果进行预测。
- en: Now let’s look at adding more graph features.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何添加更多的图特征。
- en: 'Predicting Links: Triangles and the Clustering Coefficient'
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测链接：三角形和聚类系数
- en: 'Recommendation solutions often base predictions on some form of triangle metric,
    so let’s see if they further help with our example. We can compute the number
    of triangles that a node is a part of and its clustering coefficient by executing
    the following query:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐解决方案通常基于某种三角度量进行预测，因此让我们看看它们是否能进一步帮助我们的示例。我们可以执行以下查询来计算节点是三角形的一部分及其聚类系数：
- en: '[PRE42]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The following function will add these features to our DataFrames:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的函数将这些特征添加到我们的数据框中：
- en: '[PRE43]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Note
  id: totrans-331
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Notice that we’ve used min and max prefixes for our triangle count and clustering
    coefficient algorithms. We need a way to prevent our model from learning based
    on the order authors in pairs are passed in from our undirected graph. To do this,
    we’ve split these features by the authors with minimum and maximum counts.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们已经使用最小值和最大值前缀来描述我们的三角形计数和聚类系数算法。我们需要一种方法来防止我们的模型基于传入无向图中的作者顺序进行学习。为此，我们已将这些特征按作者的最小计数和最大计数进行了分割。
- en: 'We can apply this function to our training and test DataFrames with the following
    code:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码将此功能应用于我们的训练和测试数据框中：
- en: '[PRE44]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'And run this code to show descriptive statistics for each of our triangle features:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 并运行此代码以显示我们三角形特征的描述性统计：
- en: '[PRE45]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We can see the results of running those bits of code in the following tables.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下表格中看到运行这些代码段的结果。
- en: '| summary | minTriangles | maxTriangles | minCoefficient | maxCoefficient |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 概要 | minTriangles | maxTriangles | minCoefficient | maxCoefficient |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| count | 81096 | 81096 | 81096 | 81096 |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 计数 | 81096 | 81096 | 81096 | 81096 |'
- en: '| mean | 19.478260333431983 | 27.73590559337082 | 0.5703773654487051 | 0.8453786164620439
    |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 19.478260333431983 | 27.73590559337082 | 0.5703773654487051 | 0.8453786164620439
    |'
- en: '| stddev | 65.7615282768483 | 74.01896188921927 | 0.3614610553659958 | 0.2939681857356519
    |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 标准差 | 65.7615282768483 | 74.01896188921927 | 0.3614610553659958 | 0.2939681857356519
    |'
- en: '| min | 0 | 0 | 0.0 | 0.0 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 最小值 | 0 | 0 | 0.0 | 0.0 |'
- en: '| max | 622 | 785 | 1.0 | 1.0 |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 最大值 | 622 | 785 | 1.0 | 1.0 |'
- en: '| summary | minTriangles | maxTriangles | minCoefficient | maxCoefficient |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 概要 | minTriangles | maxTriangles | minCoefficient | maxCoefficient |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| count | 81096 | 81096 | 81096 | 81096 |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 计数 | 81096 | 81096 | 81096 | 81096 |'
- en: '| mean | 5.754661142349808 | 35.651980368945445 | 0.49048921333297446 | 0.860283935358397
    |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| 平均值 | 5.754661142349808 | 35.651980368945445 | 0.49048921333297446 | 0.860283935358397
    |'
- en: '| stddev | 20.639236521699 | 85.82843448272624 | 0.3684138346533951 | 0.2578219623967906
    |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| 标准差 | 20.639236521699 | 85.82843448272624 | 0.3684138346533951 | 0.2578219623967906
    |'
- en: '| min | 0 | 0 | 0.0 | 0.0 |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| 最小值 | 0 | 0 | 0.0 | 0.0 |'
- en: '| max | 617 | 785 | 1.0 | 1.0 |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| 最大值 | 617 | 785 | 1.0 | 1.0 |'
- en: Notice in this comparison that there isn’t as great a difference between the
    coauthorship and no-coauthorship data. This could mean that these features aren’t
    as predictive.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这个比较中，合著关系和非合著关系数据之间的差异并不那么显著。这可能意味着这些特征不太具有预测性。
- en: 'We can train another model by running the following code:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下代码可以训练另一个模型：
- en: '[PRE47]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'And now let’s evaluate the model and display the results:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们评估模型并展示结果：
- en: '[PRE48]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The predictive measures for the triangles model are shown in this table:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 三角形模型的预测指标显示在本表中：
- en: '| measure | score |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 测量 | 分数 |'
- en: '| --- | --- |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| accuracy | 0.992924 |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | 0.992924 |'
- en: '| recall | 0.965384 |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 召回率 | 0.965384 |'
- en: '| precision | 0.958582 |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 精度 | 0.958582 |'
- en: 'Our predictive measures have increased well by adding each new feature to the
    previous model. Let’s add our triangles model to our ROC curve chart with the
    following code:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将每个新特征添加到先前的模型中，我们的预测指标显著提高。让我们使用以下代码将我们的三角形模型添加到ROC曲线图中：
- en: '[PRE49]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: We can see the output in [Figure 8-13](#ch8-roc-triangles).
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[图8-13](#ch8-roc-triangles)中看到输出。
- en: '![gral 0813](Images/gral_0813.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0813](Images/gral_0813.png)'
- en: Figure 8-13\. The ROC curve for triangles model
  id: totrans-368
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-13\. 三角形模型的ROC曲线
- en: 'Our models have generally improved, and we’re in the high 90s for predictive
    measures. This is when things usually get difficult, because the easiest gains
    are made but there’s still room for improvement. Let’s see how the important features
    have changed:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型普遍改善，预测指标已达到90%以上。这通常是最困难的时候，因为最容易获得的收益已经得到，但仍有改进空间。让我们看看重要特征的变化：
- en: '[PRE50]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The results of running that function can be seen in [Figure 8-14](#ch8-feature-importance-triangles).
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 运行该函数的结果可以在[图8-14](#ch8-feature-importance-triangles)中看到。
- en: '![gral 0814](Images/gral_0814.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0814](Images/gral_0814.png)'
- en: 'Figure 8-14\. Feature importance: triangles model'
  id: totrans-373
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图8-14\. 特征重要性：三角形模型
- en: The `common authors` feature still has the greatest single impact on our model.
    Perhaps we need to look at new areas and see what happens when we add community
    information.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '`共同作者`特征仍然对我们的模型产生了最大的单一影响。也许我们需要看看新的领域，看看当我们添加社区信息时会发生什么。'
- en: 'Predicting Links: Community Detection'
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测链接：社区检测
- en: We hypothesize that nodes that are in the same community are more likely to
    have a link between them if they don’t already. Moreover, we believe that the
    tighter a community is, the more likely links are.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设在同一个社区中的节点，如果它们之间尚未有链接，更有可能之后会形成链接。此外，我们认为社区越紧密，链接的可能性就越大。
- en: 'First, we’ll compute more coarse-grained communities using the Label Propagation
    algorithm in Neo4j. We do this by running the following query, which will store
    the community in the property `partitionTrain` for the training set and `partitionTest`
    for the test set:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用Neo4j中的Label Propagation算法计算更粗粒度的社区。我们通过运行以下查询来完成这一操作，该查询将在训练集的`partitionTrain`和测试集的`partitionTest`属性中存储社区：
- en: '[PRE51]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We’ll also compute finer-grained groups using the Louvain algorithm. The Louvain
    algorithm returns intermediate clusters, and we’ll store the smallest of these
    clusters in the property `louvainTrain` for the training set and `louvainTest`
    for the test set:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用Louvain算法计算更精细的群组。Louvain算法返回中间聚类，我们将在训练集的`louvainTrain`和测试集的`louvainTest`属性中存储这些最小的聚类：
- en: '[PRE52]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We’ll now create the following function to return the values from these algorithms:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将创建以下函数，以返回这些算法的值：
- en: '[PRE53]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We can apply this function to our training and test DataFrames in Spark with
    the following code:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在Spark中的训练和测试数据框架上应用该函数，具体代码如下：
- en: '[PRE54]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'And we can run this code to see whether pairs of nodes belong in the same partition:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以运行这段代码，查看节点对是否属于同一分区：
- en: '[PRE55]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: We see the results of running that code in [Figure 8-15](#ch8-explore-community-features-partition).
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[图 8-15](#ch8-explore-community-features-partition)中看到运行该代码的结果。
- en: '![gral 0815](Images/gral_0815.png)'
  id: totrans-388
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0815](Images/gral_0815.png)'
- en: Figure 8-15\. Same partitions
  id: totrans-389
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-15\. 相同的分区
- en: 'It looks like this feature could be quite predictive—authors who have collaborated
    are much more likely to be in the same partition than those who haven’t. We can
    do the same thing for the Louvain clusters by running the following code:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来这个特征可能相当具有预测性—合作过的作者很可能属于同一个分区。我们可以通过以下代码对Louvain聚类做同样的操作：
- en: '[PRE56]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We can see the results of running that code in [Figure 8-16](#ch8-explore-community-features-louvain).
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[图 8-16](#ch8-explore-community-features-louvain)中看到运行该代码的结果。
- en: '![gral 0816](Images/gral_0816.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0816](Images/gral_0816.png)'
- en: Figure 8-16\. Same Louvain clusters
  id: totrans-394
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-16\. 相同的Louvain聚类
- en: It looks like this feature could be quite predictive as well—authors who have
    collaborated are likely to be in the same cluster, and those who haven’t are very
    unlikely to be in the same cluster.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来这个特征也可能相当具有预测性—合作过的作者很可能属于同一个群组，而没有合作过的则几乎不可能。我们可以通过以下代码对Louvain聚类做同样的操作：
- en: 'We can train another model by running the following code:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过运行以下代码训练另一个模型：
- en: '[PRE57]'
  id: totrans-397
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'And now let’s evaluate the model and display the results:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们评估模型并展示结果：
- en: '[PRE58]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The predictive measures for the community model are:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 社区模型的预测指标为：
- en: '| measure | score |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| measure | score |'
- en: '| --- | --- |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| accuracy | 0.995771 |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| accuracy | 0.995771 |'
- en: '| recall | 0.957088 |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| recall | 0.957088 |'
- en: '| precision | 0.978674 |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| precision | 0.978674 |'
- en: 'Some of our measures have improved, so for comparison let’s plot the ROC curve
    for all our models by running the following code:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的一些指标已经改进，因此为了比较，让我们绘制所有模型的ROC曲线，运行以下代码：
- en: '[PRE59]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: We can see the output in [Figure 8-17](#ch8-roc-community).
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[图 8-17](#ch8-roc-community)中看到运行该代码的输出。
- en: '![gral 0817](Images/gral_0817.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0817](Images/gral_0817.png)'
- en: Figure 8-17\. The ROC curve for the community model
  id: totrans-410
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-17\. 社区模型的ROC曲线
- en: 'We can see improvements with the addition of the community model, so let’s
    see which are the most important features:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 通过加入社区模型，我们可以看到改进，接下来让我们看看哪些是最重要的特征：
- en: '[PRE60]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: The results of running that function can be seen in [Figure 8-18](#ch8-feature-importance-community).
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 运行该函数的结果可以在[图 8-18](#ch8-feature-importance-community)中看到。
- en: '![gral 0818](Images/gral_0818.png)'
  id: totrans-414
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0818](Images/gral_0818.png)'
- en: 'Figure 8-18\. Feature importance: community model'
  id: totrans-415
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 8-18\. 特征重要性：社区模型
- en: Although the common authors model is overall very important, it’s good to avoid
    having an overly dominant element that might skew predictions on new data. Community
    detection algorithms had a lot of influence in our last model with all the features
    included, and this helps round out our predictive approach.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管共同作者模型整体上非常重要，但避免有可能对新数据预测产生偏差的过度主导因素是很好的。社区检测算法在我们的最后一个包含所有特征的模型中产生了很大影响，这有助于完善我们的预测方法。
- en: We’ve seen in our examples that simple graph-based features are a good start,
    and then as we add more graphy and graph algorithm–based features, we continue
    to improve our predictive measures. We now have a good, balanced model for predicting
    coauthorship links.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我们的示例，我们看到简单基于图的特征是一个良好的起点，然后随着我们添加更多的图形和图算法特征，我们持续改进我们的预测措施。现在，我们有一个良好、平衡的模型来预测共同作者的联系。
- en: Using graphs for connected feature extraction can significantly improve our
    predictions. The ideal graph features and algorithms vary depending on the attributes
    of the data, including the network domain and graph shape. We suggest first considering
    the predictive elements within your data and testing hypotheses with different
    types of connected features before fine-tuning.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图形进行连接特征提取可以显著提高我们的预测能力。理想的图形特征和算法因数据属性而异，包括网络领域和图形形状。我们建议首先考虑数据中的预测元素，并在不同类型的连接特征下进行假设测试，然后再进行微调。
- en: Summary
  id: totrans-419
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we looked at using graph features and algorithms to enhance
    machine learning. We covered a few preliminary concepts and then walked through
    a detailed example integrating Neo4j and Apache Spark for link prediction. We
    illustrated how to evaluate random forest classifier models and incorporate various
    types of connected features to improve our results.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了使用图形特征和算法来增强机器学习的方法。我们介绍了一些初步概念，然后详细介绍了一个集成Neo4j和Apache Spark用于链接预测的示例。我们说明了如何评估随机森林分类器模型，并整合各种类型的连接特征以改进我们的结果。
- en: Wrapping Things Up
  id: totrans-421
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结一下
- en: In this book, we covered graph concepts as well as processing platforms and
    analytics. We then walked through many practical examples of how to use graph
    algorithms in Apache Spark and Neo4j. We finished with a look at how graphs enhance
    machine learning.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们涵盖了图形概念以及处理平台和分析方法。然后，我们演示了如何在Apache Spark和Neo4j中使用图形算法的许多实际例子。最后，我们看了一下图形如何增强机器学习。
- en: Graph algorithms are the powerhouse behind the analysis of real-world systems—from
    preventing fraud and optimizing call routing to predicting the spread of the flu.
    We hope you join us and develop your own unique solutions that take advantage
    of today’s highly connected data.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 图形算法是分析现实世界系统的强大工具，从防止欺诈和优化呼叫路由到预测流感的传播。我们希望您加入我们，开发出利用今天高度连接数据的独特解决方案。
