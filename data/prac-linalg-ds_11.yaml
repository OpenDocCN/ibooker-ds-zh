- en: Chapter 11\. General Linear Models and Least Squares
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章. 广义线性模型和最小二乘法
- en: The universe is a really big and really complicated place. All animals on Earth
    have a natural curiousity to explore and try to understand their environment,
    but we humans are privileged with the intelligence to develop scientific and statistical
    tools to take our curiousity to the next level. That’s why we have airplanes,
    MRI machines, rovers on Mars, vaccines, and, of course, books like this one.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 宇宙是一个非常大而复杂的地方。地球上的所有动物都有一种探索和理解其环境的自然好奇心，但我们人类则有幸能够发展科学和统计工具，将我们的好奇心提升到更高的水平。这就是为什么我们有飞机、MRI机器、火星探测器、疫苗，当然还有像本书这样的书籍。
- en: How do we understand the universe? By developing mathematically grounded theories,
    and by collecting data to test and improve those theories. And this brings us
    to statistical models. A statistical model is a simplified mathematical representation
    of some aspect of the world. Some statistical models are simple (e.g., predicting
    that the stock market will increase over decades); others are much more sophisticated,
    like the Blue Brain Project that simulates brain activity with such exquisite
    detail that one second of simulated activity requires 40 minutes of computation
    time.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何理解宇宙？通过发展数学基础的理论，并收集数据来测试和改进这些理论。这将我们带到了统计模型。统计模型是世界某些方面的简化数学表示。一些统计模型很简单（例如，预测股市数十年来会上涨），而其他一些则更为复杂，比如蓝脑项目以如此精细的细节模拟脑活动，以至于模拟一秒钟的活动需要40分钟的计算时间。
- en: A key distinction of *statistical* models (as opposed to other mathematical
    models) is that they contain free parameters that are fit to data. For example,
    I know that the stock market will go up over time, but I don’t know by how much.
    Therefore, I allow the change in stock market price over time (that is, the slope)
    to be a free parameter whose numerical value is determined by data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*统计* 模型的一个关键区别（与其他数学模型相对）是它们包含可根据数据进行拟合的自由参数。例如，我知道股市会随时间上涨，但我不知道上涨幅度是多少。因此，我允许随时间变化的股市价格（即斜率）是一个由数据决定数值的自由参数。'
- en: Crafting a statistical model can be difficult and requires creativity, experience,
    and expertise. But finding the free parameters based on fitting the model to data
    is a simple matter of linear algebra—in fact, you already know all the math you
    need for this chapter; it’s just a matter of putting the pieces together and learning
    the statistics terminology.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 制定统计模型可能很困难，需要创造力、经验和专业知识。但根据将模型拟合到数据的自由参数是一件简单的线性代数问题——实际上，你已经掌握了本章所需的所有数学，只是需要将各部分组合起来，并学习统计术语。
- en: General Linear Models
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广义线性模型
- en: A statistical model is a set of equations that relates predictors (called *independent
    variables*) to observations (called the *dependent variable*). In the model of
    the stock market, the independent variable is *time* and the dependent variable
    is *stock market price* (e.g., quantified as the S&P 500 index).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 统计模型是一组方程，将预测变量（称为 *独立变量*）与观察结果（称为 *依赖变量*）相关联。在股市模型中，独立变量是 *时间*，依赖变量是 *股市价格*（例如，以标准普尔500指数量化）。
- en: In this book I will focus on general linear models, which are abbreviated as
    GLM. Regression is a type of GLM, for example.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我将重点介绍广义线性模型（GLM），其简称为GLM。例如，回归是GLM的一种类型。
- en: Terminology
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 术语
- en: Statisticians use slightly different terminology than do linear algebraticians.
    [Table 11-1](#table_11_1) shows the key letters and descriptions for vectors and
    matrices used in the GLM.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学家使用的术语与线性代数学家略有不同。[表 11-1](#table_11_1) 展示了GLM中用于向量和矩阵的关键字母和描述。
- en: Table 11-1\. Table of terms in GLMs
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11-1\. 广义线性模型术语表
- en: '| LinAlg | Stats | Description |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| LinAlg | Stats | 描述 |'
- en: '| --- | --- | --- |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Ax = b | <math alttext="upper X beta equals y"><mrow><mi>X</mi><mi>β</mi><mo>=</mo><mi>y</mi></mrow></math>
    | General linear model (GLM) |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| Ax = b | <math alttext="upper X beta equals y"><mrow><mi>X</mi><mi>β</mi><mo>=</mo><mi>y</mi></mrow></math>
    | 广义线性模型（GLM） |'
- en: '| A | X | Design matrix (columns = independent variables, predictors, regressors)
    |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| A | X | 设计矩阵（列 = 独立变量，预测变量，回归器） |'
- en: '| x | <math alttext="beta"><mi>β</mi></math> | Regression coefficients or beta
    parameters |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| x | <math alttext="beta"><mi>β</mi></math> | 回归系数或贝塔参数 |'
- en: '| b | y | Dependent variable, outcome measure, data |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| b | y | 因变量，结果测量，数据 |'
- en: Setting Up a General Linear Model
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置广义线性模型
- en: Setting up a GLM involves (1) defining an equation that relates the predictor
    variables to the dependent variable, (2) mapping the observed data onto the equations,
    (3) transforming the series of equations into a matrix equation, and (4) solving
    that equation.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 设置一个GLM包括（1）定义一个将预测变量与因变量联系起来的方程，（2）将观察数据映射到这些方程中，（3）将一系列方程转换为矩阵方程，并（4）解决该方程。
- en: 'I’ll use a simple example to make the procedure concrete. I have a model that
    predicts adult height based on weight and on parents’ height. The equation looks
    like this:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我将用一个简单的例子来具体说明这个过程。我有一个模型，根据体重和父母的身高预测成年人的身高。方程如下所示：
- en: <math alttext="y equals beta 0 plus beta 1 w plus beta 2 h plus epsilon" display="block"><mrow><mi>y</mi>
    <mo>=</mo> <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub>
    <mi>w</mi> <mo>+</mo> <msub><mi>β</mi> <mn>2</mn></msub> <mi>h</mi> <mo>+</mo>
    <mi>ϵ</mi></mrow></math>
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals beta 0 plus beta 1 w plus beta 2 h plus epsilon" display="block"><mrow><mi>y</mi>
    <mo>=</mo> <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub>
    <mi>w</mi> <mo>+</mo> <msub><mi>β</mi> <mn>2</mn></msub> <mi>h</mi> <mo>+</mo>
    <mi>ϵ</mi></mrow></math>
- en: '*y* is the height of an individual, *w* is their weight, and *h* is their parents’
    height (the average of mother and father). <math alttext="epsilon"><mi>ϵ</mi></math>
    is an error term (also called a *residual*), because we cannot reasonably expect
    that weight and parents’ height *perfectly determines* an individual’s height;
    there are myriad factors that our model does not account for, and the variance
    not attributable to weight and parents’ height will be absorbed by the residual.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*y* 是个体的身高，*w* 是他们的体重，*h* 是他们父母的身高（母亲和父亲的平均值）。 <math alttext="epsilon"><mi>ϵ</mi></math>
    是一个误差项（也称为 *残差*），因为我们不能合理地期望体重和父母的身高完全决定一个人的身高；我们的模型没有考虑到的各种因素，而不能归因于体重和父母的身高的方差将被残差吸收。'
- en: 'My hypothesis is that weight and parents’ height are important for an individual’s
    height, but I don’t know *how* important each variable is. Enter the <math alttext="beta"><mi>β</mi></math>
    terms: they are the coefficients, or weights, that tell me how to combine weight
    and parents’ height to predict an individual’s height. In other words, a linear
    weighted combination, where the <math alttext="beta"><mi>β</mi></math> s are the
    weights.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我的假设是，体重和父母的身高对个体的身高很重要，但我不知道每个变量有多重要。输入 <math alttext="beta"><mi>β</mi></math>
    项：它们是系数或权重，告诉我如何结合体重和父母的身高来预测个体的身高。换句话说，这是一个线性加权组合，其中 <math alttext="beta"><mi>β</mi></math>
    是权重。
- en: <math alttext="beta 0"><msub><mi>β</mi> <mn>0</mn></msub></math> is called an
    *intercept* (sometimes called a *constant*). The intercept term is a vector of
    all 1s. Without an intercept term, the best-fit line is forced to pass through
    the origin. I’ll explain why, and show a demonstration, toward the end of the
    chapter.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="beta 0"><msub><mi>β</mi> <mn>0</mn></msub></math> 被称为 *截距*（有时称为
    *常数*）。截距项是一个全为1的向量。如果没有截距项，最佳拟合线将被迫通过原点。我将在本章末尾解释为什么，并展示一个演示。
- en: Now we have our equation, our model of the universe (well, one tiny part of
    it). Next, we need to map the observed data onto the equations. For simplicity,
    I’m going to make up some data in [Table 11-2](#table_11_2) (you may imagine that
    *y* and *h* have units of centimeters and *w* has units of kilograms).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了我们的方程，我们的宇宙模型（嗯，它的一个微小部分）。接下来，我们需要将观察数据映射到这些方程中。为了简单起见，我会在 [表11-2](#table_11_2)
    中虚构一些数据（你可以想象 *y* 和 *h* 单位是厘米，*w* 单位是公斤）。
- en: Table 11-2\. Made-up data for our statistical model of height
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 表11-2。我们身高统计模型的虚构数据
- en: '| *y* | *w* | *h* |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| *y* | *w* | *h* |'
- en: '| --- | --- | --- |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 175 | 70 | 177 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 175 | 70 | 177 |'
- en: '| 181 | 86 | 190 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 181 | 86 | 190 |'
- en: '| 159 | 63 | 180 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 159 | 63 | 180 |'
- en: '| 165 | 62 | 172 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 165 | 62 | 172 |'
- en: 'Mapping the observed data onto our statistical model involves replicating the
    equation four times (corresponding to four observations in our dataset), each
    time replacing the variables *y*, *w*, and *h* with the measured data:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 将观察数据映射到我们的统计模型中涉及将方程复制四次（对应我们数据集中的四个观察），每次用实际数据替换变量 *y*、*w* 和 *h*：
- en: <math alttext="StartLayout 1st Row 1st Column 175 2nd Column equals beta 0 plus
    70 beta 1 plus 177 beta 2 2nd Row 1st Column 181 2nd Column equals beta 0 plus
    86 beta 1 plus 190 beta 2 3rd Row 1st Column 159 2nd Column equals beta 0 plus
    63 beta 1 plus 180 beta 2 4th Row 1st Column 165 2nd Column equals beta 0 plus
    62 beta 1 plus 172 beta 2 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mn>175</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <mn>70</mn> <msub><mi>β</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>177</mn> <msub><mi>β</mi> <mn>2</mn></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mn>181</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <mn>86</mn> <msub><mi>β</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>190</mn> <msub><mi>β</mi> <mn>2</mn></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mn>159</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <mn>63</mn> <msub><mi>β</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>180</mn> <msub><mi>β</mi> <mn>2</mn></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mn>165</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <mn>62</mn> <msub><mi>β</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>172</mn> <msub><mi>β</mi> <mn>2</mn></msub></mrow></mtd></mtr></mtable></math>
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column 175 2nd Column equals beta 0 plus
    70 beta 1 plus 177 beta 2 2nd Row 1st Column 181 2nd Column equals beta 0 plus
    86 beta 1 plus 190 beta 2 3rd Row 1st Column 159 2nd Column equals beta 0 plus
    63 beta 1 plus 180 beta 2 4th Row 1st Column 165 2nd Column equals beta 0 plus
    62 beta 1 plus 172 beta 2 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mn>175</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <mn>70</mn> <msub><mi>β</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>177</mn> <msub><mi>β</mi> <mn>2</mn></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mn>181</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <mn>86</mn> <msub><mi>β</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>190</mn> <msub><mi>β</mi> <mn>2</mn></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mn>159</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <mn>63</mn> <msub><mi>β</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>180</mn> <msub><mi>β</mi> <mn>2</mn></msub></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mn>165</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>β</mi> <mn>0</mn></msub> <mo>+</mo> <mn>62</mn> <msub><mi>β</mi> <mn>1</mn></msub>
    <mo>+</mo> <mn>172</mn> <msub><mi>β</mi> <mn>2</mn></msub></mrow></mtd></mtr></mtable></math>
- en: 'I’m omitting the <math alttext="epsilon"><mi>ϵ</mi></math> term for now; I’ll
    have more to say about the residuals later. We now need to translate this system
    of equations into a matrix equation. I know that you know how to do that, so I’ll
    print out the equation here only so you can confirm what you already know from
    [Chapter 10](ch10.xhtml#Chapter_10):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我会省略 <math alttext="epsilon"><mi>ϵ</mi></math> 项；稍后我会详细讨论残差。现在我们需要将这些方程翻译成矩阵方程。我知道你知道如何做，所以我在这里只打印方程，以便你从
    [第10章](ch10.xhtml#Chapter_10) 确认：
- en: <math alttext="Start 4 By 3 Matrix 1st Row 1st Column 1 2nd Column 70 3rd Column
    177 2nd Row 1st Column 1 2nd Column 86 3rd Column 190 3rd Row 1st Column 1 2nd
    Column 63 3rd Column 180 4th Row 1st Column 1 2nd Column 62 3rd Column 172 EndMatrix
    Start 3 By 1 Matrix 1st Row  beta 0 2nd Row  beta 1 3rd Row  beta 2 EndMatrix
    equals Start 4 By 1 Matrix 1st Row  175 2nd Row  181 3rd Row  159 4th Row  165
    EndMatrix" display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>70</mn></mtd> <mtd><mn>177</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>86</mn></mtd> <mtd><mn>190</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>63</mn></mtd> <mtd><mn>180</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>62</mn></mtd> <mtd><mn>172</mn></mtd></mtr></mtable></mfenced> <mfenced
    close="]" open="["><mtable><mtr><mtd><msub><mi>β</mi> <mn>0</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>β</mi> <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>β</mi>
    <mn>2</mn></msub></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]"
    open="["><mtable><mtr><mtd><mn>175</mn></mtd></mtr> <mtr><mtd><mn>181</mn></mtd></mtr>
    <mtr><mtd><mn>159</mn></mtd></mtr> <mtr><mtd><mn>165</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="Start 4 By 3 Matrix 1st Row 1st Column 1 2nd Column 70 3rd Column
    177 2nd Row 1st Column 1 2nd Column 86 3rd Column 190 3rd Row 1st Column 1 2nd
    Column 63 3rd Column 180 4th Row 1st Column 1 2nd Column 62 3rd Column 172 EndMatrix
    Start 3 By 1 Matrix 1st Row  beta 0 2nd Row  beta 1 3rd Row  beta 2 EndMatrix
    equals Start 4 By 1 Matrix 1st Row  175 2nd Row  181 3rd Row  159 4th Row  165
    EndMatrix" display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>70</mn></mtd> <mtd><mn>177</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>86</mn></mtd> <mtd><mn>190</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>63</mn></mtd> <mtd><mn>180</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>62</mn></mtd> <mtd><mn>172</mn></mtd></mtr></mtable></mfenced> <mfenced
    close="]" open="["><mtable><mtr><mtd><msub><mi>β</mi> <mn>0</mn></msub></mtd></mtr>
    <mtr><mtd><msub><mi>β</mi> <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>β</mi>
    <mn>2</mn></msub></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]"
    open="["><mtable><mtr><mtd><mn>175</mn></mtd></mtr> <mtr><mtd><mn>181</mn></mtd></mtr>
    <mtr><mtd><mn>159</mn></mtd></mtr> <mtr><mtd><mn>165</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: And, of course, we can express this equation succinctly as <math alttext="bold
    upper X beta equals bold y"><mrow><mi mathvariant="bold">X</mi><mi mathvariant="bold">β</mi><mo>=</mo><mi
    mathvariant="bold">y</mi></mrow></math>.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们可以简洁地表示这个方程为 <math alttext="bold upper X beta equals bold y"><mrow><mi
    mathvariant="bold">X</mi><mi mathvariant="bold">β</mi><mo>=</mo><mi mathvariant="bold">y</mi></mrow></math>。
- en: Solving GLMs
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决广义线性模型（GLMs）
- en: 'I’m sure you already know the main idea of this section: to solve for the vector
    of unknown coefficients <math alttext="beta"><mi mathvariant="bold">β</mi></math>,
    simply left-multiply both sides of the equation by the left-inverse of <math alttext="bold
    upper X"><mi>𝐗</mi></math> , the design matrix. The solution looks like this:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信你已经了解本节的主要思想：为了求解未知系数向量 <math alttext="beta"><mi mathvariant="bold">β</mi></math>，只需将方程式的两边左乘设计矩阵
    <math alttext="bold upper X"><mi>𝐗</mi></math> 的左逆即可。解决方案如下：
- en: <math alttext="StartLayout 1st Row 1st Column bold upper X beta 2nd Column equals
    bold y 2nd Row 1st Column left-parenthesis bold upper X Superscript upper T Baseline
    bold upper X right-parenthesis Superscript negative 1 Baseline bold upper X Superscript
    upper T Baseline bold upper X beta 2nd Column equals left-parenthesis bold upper
    X Superscript upper T Baseline bold upper X right-parenthesis Superscript negative
    1 Baseline bold upper X Superscript upper T Baseline bold y 3rd Row 1st Column
    beta 2nd Column equals left-parenthesis bold upper X Superscript upper T Baseline
    bold upper X right-parenthesis Superscript negative 1 Baseline bold upper X Superscript
    upper T Baseline bold y EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mrow><mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mi mathvariant="bold">y</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi>
    <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi>
    <mi mathvariant="bold">β</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mi mathvariant="bold">β</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column bold upper X beta 2nd Column equals
    bold y 2nd Row 1st Column left-parenthesis bold upper X Superscript upper T Baseline
    bold upper X right-parenthesis Superscript negative 1 Baseline bold upper X Superscript
    upper T Baseline bold upper X beta 2nd Column equals left-parenthesis bold upper
    X Superscript upper T Baseline bold upper X right-parenthesis Superscript negative
    1 Baseline bold upper X Superscript upper T Baseline bold y 3rd Row 1st Column
    beta 2nd Column equals left-parenthesis bold upper X Superscript upper T Baseline
    bold upper X right-parenthesis Superscript negative 1 Baseline bold upper X Superscript
    upper T Baseline bold y EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mrow><mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mi mathvariant="bold">y</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi>
    <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi>
    <mi mathvariant="bold">β</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mi mathvariant="bold">β</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
- en: 'Please stare at that final equation until it is permanently tattooed into your
    brain. It is called the *least squares solution* and is one of the most important
    mathematical equations in applied linear algebra. You’ll see it in research publications,
    textbooks, blogs, lectures, docstrings in Python functions, billboards in Tajikistan,^([1](ch11.xhtml#idm45733295548016))
    and many other places. You might see different letters, or possibly some additions,
    like the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 请盯着那个最后的方程式直到它永远刻在你的脑海中。它被称为*最小二乘解*，是应用线性代数中最重要的数学方程之一。你会在研究出版物、教科书、博客、讲座、Python
    函数的文档字符串、塔吉克斯坦的广告牌^([1](ch11.xhtml#idm45733295548016))等地方看到它。你可能会看到不同的字母，或者可能会有一些附加内容，如下所示：
- en: <math alttext="bold b equals left-parenthesis bold upper H Superscript upper
    T Baseline bold upper W bold upper H plus lamda bold upper L Superscript upper
    T Baseline bold upper L right-parenthesis Superscript negative 1 Baseline bold
    upper H Superscript upper T Baseline bold x" display="block"><mrow><mi>𝐛</mi>
    <mo>=</mo> <msup><mrow><mo>(</mo><msup><mi>𝐇</mi> <mtext>T</mtext></msup> <mi>𝐖</mi><mi>𝐇</mi><mo>+</mo><mi>λ</mi><msup><mi>𝐋</mi>
    <mtext>T</mtext></msup> <mi>𝐋</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>𝐇</mi> <mtext>T</mtext></msup> <mi>𝐱</mi></mrow></math>
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold b equals left-parenthesis bold upper H Superscript upper
    T Baseline bold upper W bold upper H plus lamda bold upper L Superscript upper
    T Baseline bold upper L right-parenthesis Superscript negative 1 Baseline bold
    upper H Superscript upper T Baseline bold x" display="block"><mrow><mi>𝐛</mi>
    <mo>=</mo> <msup><mrow><mo>(</mo><msup><mi>𝐇</mi> <mtext>T</mtext></msup> <mi>𝐖</mi><mi>𝐇</mi><mo>+</mo><mi>λ</mi><msup><mi>𝐋</mi>
    <mtext>T</mtext></msup> <mi>𝐋</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>𝐇</mi> <mtext>T</mtext></msup> <mi>𝐱</mi></mrow></math>
- en: The meaning of that equation and the interpretation of the additional matrices
    are not important (they are various ways of regularizing the model fitting); what
    is important is that you are able to see the least squares formula embedded in
    that complicated-looking equation (for example, imagine setting <math alttext="bold
    upper W equals bold upper I"><mrow><mi>𝐖</mi> <mo>=</mo> <mi>𝐈</mi></mrow></math>
    and <math alttext="lamda equals 0"><mrow><mi>λ</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    ).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 方程式的含义及附加矩阵的解释并不重要（它们是正则化模型拟合的各种方法）；重要的是，你能够看到最小二乘公式嵌入到那个看似复杂的方程式中（例如，设定 <math
    alttext="bold upper W equals bold upper I"><mrow><mi>𝐖</mi> <mo>=</mo> <mi>𝐈</mi></mrow></math>
    和 <math alttext="lamda equals 0"><mrow><mi>λ</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    ）。
- en: 'The least squares solution via the left-inverse can be translated directly
    into Python code (variable `X` is the design matrix and variable `y` is the data
    vector):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 通过左逆的最小二乘解可以直接翻译成 Python 代码（变量 `X` 是设计矩阵，变量 `y` 是数据向量）：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I will show results from these models—and how to interpret them—later in this
    chapter; for now I’d like you to focus on how the math formulas are translated
    into Python code.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我将在本章后面展示这些模型的结果——以及如何解释它们；现在请你专注于数学公式如何转换为 Python 代码。
- en: Left-Inverse Versus NumPy’s Least Squares Solver
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 左逆与 NumPy 的最小二乘解算器
- en: The code in this chapter is a direct translation of the math into Python code.
    Explicitly computing the left-inverse is not the most numerically stable way to
    solve the GLM (although it is accurate for the simple problems in this chapter),
    but I want you to see that the seemingly abstract linear algebra really works.
    There are more numerically stable ways to solve the GLM, including QR decomposition
    (which you will see later in this chapter) and Python’s more numerically stable
    methods (which you will see in the next chapter).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码直接将数学公式转换为 Python 代码。显式计算左逆不是解决广义线性模型（GLM）最稳定的方式（尽管对本章中的简单问题来说是准确的），但我希望你能看到这些看似抽象的线性代数确实有效。解决
    GLM 的更稳定的方式包括 QR 分解（你将在本章后面看到）和 Python 的更稳定的方法（你将在下一章看到）。
- en: Is the Solution Exact?
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解是否确切？
- en: The equation <math alttext="bold upper X beta equals bold y"><mrow><mi mathvariant="bold">X</mi><mi
    mathvariant="bold">β</mi><mo>=</mo><mi mathvariant="bold">y</mi></mrow></math>
    is exactly solvable when <math alttext="bold y"><mi>𝐲</mi></math> is in the column
    space of the design matrix <math alttext="bold upper X"><mi>𝐗</mi></math> . So
    the question is whether the data vector is guaranteed to be in the column space
    of the statistical model. The answer is no, there is no such guarantee. In fact,
    the data vector <math alttext="bold y"><mi>𝐲</mi></math> is almost never in the
    column space of <math alttext="bold upper X"><mi>𝐗</mi></math> .
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据向量 <math alttext="bold y"><mi>𝐲</mi></math> 在设计矩阵 <math alttext="bold upper
    X"><mi>𝐗</mi></math> 的列空间中时，方程式 <math alttext="bold upper X beta equals bold y"><mrow><mi
    mathvariant="bold">X</mi><mi mathvariant="bold">β</mi><mo>=</mo><mi mathvariant="bold">y</mi></mrow></math>
    是确切可解的。因此问题是数据向量是否确保在统计模型的列空间中。答案是否定的，事实上，数据向量 <math alttext="bold y"><mi>𝐲</mi></math>
    几乎永远不在 <math alttext="bold upper X"><mi>𝐗</mi></math> 的列空间中。
- en: To understand why not, let’s imagine a survey of university students in which
    the researchers are trying to predict average GPA (grade point average) based
    on drinking behavior. The survey may contain data from two thousand students yet
    have only three questions (e.g., how much alcohol do you consume; how often do
    you black out; what is your GPA). The data is contained in a 2000 × 3 table. The
    column space of the design matrix is a 2D subspace inside that 2000D ambient dimensionality,
    and the data vector is a 1D subspace inside that same ambient dimensionality.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解为什么不这样做，让我们想象一项针对大学生的调查，研究人员试图根据饮酒行为预测平均GPA（平均绩点）。调查可能包含来自两千名学生的数据，但只有三个问题（例如，您消费多少酒精；您经常失忆吗；您的GPA是多少）。数据包含在一个2000×3的表格中。设计矩阵的列空间是该2000D环境维度内的一个2D子空间，而数据向量是同一环境维度内的一个1D子空间。
- en: 'If the data is in the column space of the design matrix, it means that the
    model accounts for 100% of the variance in the data. But this almost never happens:
    real-world data contains noise and sampling variability, and the models are simplifications
    that do not account for all of the variability (e.g., GPA is determined by myriad
    factors that our model ignores).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据在设计矩阵的列空间内，意味着模型可以解释数据方差的100%。但这几乎从不会发生：现实世界的数据包含噪声和抽样变异性，而模型只是简化，未能解释所有变异性（例如，GPA由我们模型忽略的多种因素决定）。
- en: 'The solution to this conundrum is that we modify the GLM equation to allow
    for a discrepancy between the model-predicted data and the observed data. It can
    be expressed in several equivalent (up to a sign) ways:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这一难题的方法是修改GLM方程，允许模型预测数据与观察数据之间存在差异。它可以用几种等效（至少在符号上）的方式表示：
- en: <math alttext="StartLayout 1st Row 1st Column bold upper X beta 2nd Column equals
    bold y plus epsilon 2nd Row 1st Column bold upper X beta plus epsilon 2nd Column
    equals bold y 3rd Row 1st Column epsilon 2nd Column equals bold upper X beta minus
    bold y EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi
    mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi mathvariant="bold">y</mi> <mo>+</mo> <mi mathvariant="bold">ϵ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi>
    <mo>+</mo> <mi mathvariant="bold">ϵ</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi
    mathvariant="bold">ϵ</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <mi mathvariant="bold">X</mi>
    <mi mathvariant="bold">β</mi> <mo>-</mo> <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column bold upper X beta 2nd Column equals
    bold y plus epsilon 2nd Row 1st Column bold upper X beta plus epsilon 2nd Column
    equals bold y 3rd Row 1st Column epsilon 2nd Column equals bold upper X beta minus
    bold y EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi
    mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi mathvariant="bold">y</mi> <mo>+</mo> <mi mathvariant="bold">ϵ</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi>
    <mo>+</mo> <mi mathvariant="bold">ϵ</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi
    mathvariant="bold">ϵ</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <mi mathvariant="bold">X</mi>
    <mi mathvariant="bold">β</mi> <mo>-</mo> <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
- en: The interpretation of the first equation is that <math alttext="epsilon"><mi
    mathvariant="bold">ϵ</mi></math> is a residual, or an error term, that you add
    to the data vector so that it fits inside the column space of the design matrix.
    The interpretation of the second equation is that the residual term is an adjustment
    to the design matrix so that it fits the data perfectly. Finally, the interpretation
    of the third equation is that the residual is defined as the difference between
    the model-predicted data and the observed data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个方程的解释是<math alttext="epsilon"><mi mathvariant="bold">ϵ</mi></math>是一个残差，或者说是一个误差项，你需要将它加到数据向量中，使其符合设计矩阵的列空间。第二个方程的解释是残差项是对设计矩阵的调整，以便完美拟合数据。最后，第三个方程的解释是残差被定义为模型预测数据与观察数据之间的差异。
- en: There is another, very insightful, interpretation, which approaches GLMs and
    least squares from a geometric perspective. I’ll get back to this in the next
    section.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一种非常有见地的解释，从几何角度接近GLM和最小二乘法。我将在下一节详细介绍这一点。
- en: The point of this section is that the observed data is almost never inside the
    subspace spanned by the regressors. For this reason, it is also common to see
    the GLM expressed as <math alttext="bold upper X equals beta ModifyingAbove bold
    y With bold caret"><mrow><mi mathvariant="bold">X</mi><mo>=</mo><mi mathvariant="bold">β</mi><mover
    accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover></mrow></math> where
    <math alttext="ModifyingAbove bold y With bold caret equals bold y plus epsilon"><mrow><mover
    accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover><mo>=</mo><mi mathvariant="bold">y</mi><mo>+</mo><mi
    mathvariant="bold">ϵ</mi></mrow></math>.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分的要点是观察到的数据几乎从不在回归向量生成的子空间内。因此，通常将GLM表示为<math alttext="bold upper X equals
    beta ModifyingAbove bold y With bold caret"><mrow><mi mathvariant="bold">X</mi><mo>=</mo><mi
    mathvariant="bold">β</mi><mover accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover></mrow></math>，其中<math
    alttext="ModifyingAbove bold y With bold caret equals bold y plus epsilon"><mrow><mover
    accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover><mo>=</mo><mi mathvariant="bold">y</mi><mo>+</mo><mi
    mathvariant="bold">ϵ</mi></mrow></math>。
- en: Therefore, the goal of the GLM is to find the linear combination of the regressors
    that gets as close as possible to the observed data. More on this point later;
    I now want to introduce you to the geometric perspective of least squares.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，GLM的目标是找到回归变量的线性组合，使其尽可能接近观察数据。关于这一点的更多内容将在后面详细说明；现在我想向你介绍最小二乘法的几何视角。
- en: A Geometric Perspective on Least Squares
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最小二乘法的几何视角
- en: So far I’ve introduced the solution to the GLM from the algebraic perspective
    of solving a matrix equation. There is also a geometric perspective to the GLM,
    which provides an alternative perspective and helps reveal several important features
    of the least squares solution.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我介绍了从解矩阵方程的代数角度解决GLM的方法。GLM还有一种几何视角，提供了一种替代视角，并帮助揭示最小二乘解决方案的几个重要特征。
- en: Let’s consider that the column space of the design matrix <math alttext="upper
    C left-parenthesis bold upper X right-parenthesis"><mrow><mi>C</mi> <mo>(</mo>
    <mi>𝐗</mi> <mo>)</mo></mrow></math> is a subspace of <math alttext="double-struck
    upper R Superscript upper M"><msup><mi>ℝ</mi> <mi>M</mi></msup></math> . It’s
    typically a very low-dimensional subspace (that is, *N* << *M*), because statistical
    models tend to have many more observations (rows) than predictors (columns). The
    dependent variable is a vector <math alttext="bold y element-of double-struck
    upper R Superscript upper M"><mrow><mi>𝐲</mi> <mo>∈</mo> <msup><mi>ℝ</mi> <mi>M</mi></msup></mrow></math>
    . The questions at hand are, is the vector <math alttext="bold y"><mi>𝐲</mi></math>
    in the column space of the design matrix, and if not, what coordinate inside the
    column space of the design matrix is as close as possible to the data vector?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑设计矩阵的列空间<math alttext="upper C left-parenthesis bold upper X right-parenthesis"><mrow><mi>C</mi>
    <mo>(</mo> <mi>𝐗</mi> <mo>)</mo></mrow></math>是<math alttext="double-struck upper
    R Superscript upper M"><msup><mi>ℝ</mi> <mi>M</mi></msup></math>的子空间。通常是一个非常低维的子空间（即，*N*
    << *M*），因为统计模型通常有比预测变量（列）更多的观察（行）。因变量是向量<math alttext="bold y element-of double-struck
    upper R Superscript upper M"><mrow><mi>𝐲</mi> <mo>∈</mo> <msup><mi>ℝ</mi> <mi>M</mi></msup></mrow></math>。所涉及的问题是，向量<math
    alttext="bold y"><mi>𝐲</mi></math>是否在设计矩阵的列空间中，如果不是，那么设计矩阵的列空间内的坐标最接近数据向量是什么？
- en: The answer to the first question is no, as I discussed in the previous section.
    The second question is profound, because you already learned the answer in [Chapter 2](ch02.xhtml#Chapter_2).
    Consider [Figure 11-1](#fig_11_1) while thinking about the solution.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个问题的答案是否定的，正如我在前一节中讨论的那样。第二个问题很深刻，因为你已经在[第二章](ch02.xhtml#Chapter_2)中学习了答案。在考虑解决方案时，请参考[图 11-1](#fig_11_1)。
- en: '![geo of glm](assets/plad_1101.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![glm 的几何](assets/plad_1101.png)'
- en: 'Figure 11-1\. The abstracted geometric view of GLM: find the point in the column
    space of the design matrix that is as close as possible to the data vector'
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-1. GLM 的抽象几何视角：找到设计矩阵列空间中距离数据向量最接近的点
- en: 'So, our goal is to find the set of coefficients <math alttext="beta"><mi mathvariant="bold">β</mi></math>
    such that the weighted combination of columns in <math alttext="bold upper X"><mi>𝐗</mi></math>
    minimizes the distance to data vector <math alttext="bold y"><mi>𝐲</mi></math>
    . We can call that projection vector <math alttext="epsilon"><mi mathvariant="bold">ϵ</mi></math>.
    How do we find the vector <math alttext="epsilon"><mi mathvariant="bold">ϵ</mi></math>
    and the coefficients <math alttext="beta"><mi mathvariant="bold">β</mi></math>?
    We use orthogonal vector projection, just like what you learned in [Chapter 2](ch02.xhtml#Chapter_2).
    This means we can apply the same approach as in [Chapter 2](ch02.xhtml#Chapter_2),
    but using matrices instead of vectors. The key insight is that the shortest distance
    between <math alttext="bold y"><mi>𝐲</mi></math> and <math alttext="bold upper
    X"><mi>𝐗</mi></math> is given by the projection vector <math alttext="bold y minus
    bold upper X beta"><mrow><mi mathvariant="bold">y</mi><mo>-</mo><mi mathvariant="bold">X</mi><mi
    mathvariant="bold">β</mi></mrow></math> that meets <math alttext="bold upper X"><mi>𝐗</mi></math>
    at a right angle:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的目标是找到系数集合<math alttext="beta"><mi mathvariant="bold">β</mi></math>，使得<math
    alttext="bold upper X"><mi>𝐗</mi></math>中列的加权组合最小化到数据向量<math alttext="bold y"><mi>𝐲</mi></math>的距离。我们可以称该投影向量为<math
    alttext="epsilon"><mi mathvariant="bold">ϵ</mi></math>。我们如何找到向量<math alttext="epsilon"><mi
    mathvariant="bold">ϵ</mi></math>和系数<math alttext="beta"><mi mathvariant="bold">β</mi></math>？我们使用正交向量投影，就像你在[第二章](ch02.xhtml#Chapter_2)中学到的那样。这意味着我们可以应用与向量不同的矩阵相同的方法。关键的见解是，<math
    alttext="bold y"><mi>𝐲</mi></math>和<math alttext="bold upper X"><mi>𝐗</mi></math>之间的最短距离由投影向量<math
    alttext="bold y minus bold upper X beta"><mrow><mi mathvariant="bold">y</mi><mo>-</mo><mi
    mathvariant="bold">X</mi><mi mathvariant="bold">β</mi></mrow></math>给出，该向量在<math
    alttext="bold upper X"><mi>𝐗</mi></math>上呈直角：
- en: <math alttext="StartLayout 1st Row 1st Column bold upper X Superscript upper
    T Baseline epsilon 2nd Column equals bold 0 2nd Row 1st Column bold upper X Superscript
    upper T Baseline left-parenthesis bold y minus bold upper X beta right-parenthesis
    2nd Column equals bold 0 3rd Row 1st Column bold upper X Superscript upper T Baseline
    bold y minus bold upper X Superscript upper T Baseline bold upper X beta 2nd Column
    equals bold 0 4th Row 1st Column bold upper X Superscript upper T Baseline bold
    upper X beta 2nd Column equals bold upper X Superscript upper T Baseline bold
    y 5th Row 1st Column beta 2nd Column equals left-parenthesis bold upper X Superscript
    upper T Baseline bold upper X right-parenthesis Superscript negative 1 Baseline
    bold upper X Superscript upper T Baseline bold y EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi mathvariant="bold">X</mi>
    <mtext>T</mtext></msup> <mi mathvariant="bold">ϵ</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mn mathvariant="bold">0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msup><mi
    mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mrow><mo>(</mo> <mi mathvariant="bold">y</mi>
    <mo>-</mo> <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi> <mo>)</mo></mrow></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mn mathvariant="bold">0</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi> <mo>-</mo> <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd> <mtd
    columnalign="left"><mrow><mo>=</mo> <mn mathvariant="bold">0</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd> <mtd
    columnalign="left"><mrow><mo>=</mo> <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi
    mathvariant="bold">β</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <msup><mrow><mo>(</mo><msup><mi
    mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi><mo>)</mo></mrow>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column bold upper X Superscript upper
    T Baseline epsilon 2nd Column equals bold 0 2nd Row 1st Column bold upper X Superscript
    upper T Baseline left-parenthesis bold y minus bold upper X beta right-parenthesis
    2nd Column equals bold 0 3rd Row 1st Column bold upper X Superscript upper T Baseline
    bold y minus bold upper X Superscript upper T Baseline bold upper X beta 2nd Column
    equals bold 0 4th Row 1st Column bold upper X Superscript upper T Baseline bold
    upper X beta 2nd Column equals bold upper X Superscript upper T Baseline bold
    y 5th Row 1st Column beta 2nd Column equals left-parenthesis bold upper X Superscript
    upper T Baseline bold upper X right-parenthesis Superscript negative 1 Baseline
    bold upper X Superscript upper T Baseline bold y EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi mathvariant="bold">X</mi>
    <mtext>T</mtext></msup> <mi mathvariant="bold">ϵ</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mn mathvariant="bold">0</mn></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msup><mi
    mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mrow><mo>(</mo> <mi mathvariant="bold">y</mi>
    <mo>-</mo> <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi> <mo>)</mo></mrow></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mn mathvariant="bold">0</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi> <mo>-</mo> <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd> <mtd
    columnalign="left"><mrow><mo>=</mo> <mn mathvariant="bold">0</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd> <mtd
    columnalign="left"><mrow><mo>=</mo> <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi
    mathvariant="bold">β</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <msup><mrow><mo>(</mo><msup><mi
    mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi><mo>)</mo></mrow>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
- en: 'That progression of equations is remarkable: we started from thinking about
    the GLM as a geometric projection of a data vector onto the column space of a
    design matrix, applied the principle of orthogonal vector projection that you
    learned about early on in the book, and voilà! We have rederived the same left-inverse
    solution that we got from the algebraic approach.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这一系列方程的进展非常引人注目：我们从把广义线性模型（GLM）看作是数据向量在设计矩阵的列空间上的几何投影开始，应用了您在本书早期学到的正交向量投影原理，然后！我们重新导出了从代数方法中得到的相同左逆解。
- en: Why Does Least Squares Work?
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么最小二乘法有效？
- en: Why is it called “least squares”? What are these so-called squares, and why
    does this method give us the least of them?
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么称之为“最小二乘法”？这些所谓的平方是什么，为什么这种方法能使它们最小化？
- en: 'The “squares” here refers to squared errors between the predicted data and
    the observed data. There is an error term for each *i*th predicted data point,
    which is defined as <math alttext="epsilon Subscript i Baseline equals bold upper
    X Subscript i Baseline beta minus bold y Subscript i"><mrow><msub><mi>ϵ</mi> <mi>i</mi></msub>
    <mo>=</mo><msub><mi mathvariant="bold">X</mi> <mi>i</mi></msub> <mi mathvariant="bold">β</mi><mo>-</mo><msub><mi
    mathvariant="bold">y</mi> <mi>i</mi></msub></mrow></math> . Note that each data
    point is predicted using the same set of coefficients (that is, the same weights
    for combining the predictors in the design matrix). We can capture all errors
    in one vector:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的“平方”指的是预测数据与观测数据之间的平方误差。每个第*i*个预测数据点都有一个误差项，定义为<math alttext="epsilon Subscript
    i Baseline equals bold upper X Subscript i Baseline beta minus bold y Subscript
    i"><mrow><msub><mi>ϵ</mi> <mi>i</mi></msub> <mo>=</mo><msub><mi mathvariant="bold">X</mi>
    <mi>i</mi></msub> <mi mathvariant="bold">β</mi><mo>-</mo><msub><mi mathvariant="bold">y</mi>
    <mi>i</mi></msub></mrow></math> 。请注意，每个数据点都使用相同的系数（即设计矩阵中预测器的相同权重组合）。我们可以用一个向量来表示所有的误差：
- en: <math alttext="epsilon equals bold upper X beta minus bold y" display="block"><mrow><mi
    mathvariant="bold">ϵ</mi> <mo>=</mo> <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi>
    <mo>-</mo> <mi mathvariant="bold">y</mi></mrow></math>
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="epsilon equals bold upper X beta minus bold y" display="block"><mrow><mi
    mathvariant="bold">ϵ</mi> <mo>=</mo> <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi>
    <mo>-</mo> <mi mathvariant="bold">y</mi></mrow></math>
- en: 'If the model is a good fit to the data, then the errors should be small. Therefore,
    we can say that the objective of model fitting is to choose the elements in <math
    alttext="beta"><mi mathvariant="bold">β</mi></math> that minimize the elements
    in <math alttext="epsilon"><mi mathvariant="bold">ϵ</mi></math>. But just *minimizing*
    the errors would cause the model to predict values toward negative infinity. Thus,
    instead we minimize the *squared* errors, which correspond to their geometric
    squared distance to the observed data <math alttext="bold y"><mi>𝐲</mi></math>
    , regardless of whether the prediction error itself is positive or negative.^([2](ch11.xhtml#idm45733295319056))
    This is the same thing as minimizing the squared norm of the errors. Hence the
    name “least squares.” That leads to the following modification:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型很好地拟合了数据，那么误差应该很小。因此，我们可以说模型拟合的目标是选择最小化<math alttext="beta"><mi mathvariant="bold">β</mi></math>
    中的元素，这些元素最小化了<math alttext="epsilon"><mi mathvariant="bold">ϵ</mi></math> 中的元素。但是仅仅*最小化*误差会导致模型预测值向负无穷预测。因此，我们最小化*平方*误差，这对应于它们到观测数据<math
    alttext="bold y"><mi>𝐲</mi></math> 的几何平方距离，而不管预测误差本身是正还是负。^([2](ch11.xhtml#idm45733295319056))
    这与最小化误差范数的思想是相同的。因此得名“最小二乘法”。这导致了以下修改：
- en: <math alttext="parallel-to epsilon parallel-to equals parallel-to bold upper
    X beta minus bold y parallel-to" display="block"><mrow><msup><mrow><mo>∥</mo><mi
    mathvariant="bold">ϵ</mi><mo>∥</mo></mrow> <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>∥</mo><mi
    mathvariant="bold">X</mi><mi mathvariant="bold">β</mi><mo>-</mo><mi mathvariant="bold">y</mi><mo>∥</mo></mrow>
    <mn>2</mn></msup></mrow></math>
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="parallel-to epsilon parallel-to equals parallel-to bold upper
    X beta minus bold y parallel-to" display="block"><mrow><msup><mrow><mo>∥</mo><mi
    mathvariant="bold">ϵ</mi><mo>∥</mo></mrow> <mn>2</mn></msup> <mo>=</mo> <msup><mrow><mo>∥</mo><mi
    mathvariant="bold">X</mi><mi mathvariant="bold">β</mi><mo>-</mo><mi mathvariant="bold">y</mi><mo>∥</mo></mrow>
    <mn>2</mn></msup></mrow></math>
- en: 'We can now view this as an optimization problem. In particular, we want to
    find the set of coefficients that minimizes the squared errors. That minimization
    can be expressed as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以把它看作是一个优化问题。特别地，我们想找到一组系数，这些系数最小化了平方误差。这种最小化可以表达如下：
- en: <math alttext="min Underscript beta Endscripts parallel-to bold upper X beta
    minus bold y parallel-to" display="block"><mrow><munder><mo form="prefix" movablelimits="true">min</mo>
    <mi mathvariant="bold">β</mi></munder> <msup><mrow><mo>∥</mo><mi mathvariant="bold">X</mi><mi
    mathvariant="bold">β</mi><mo>-</mo><mi mathvariant="bold">y</mi><mo>∥</mo></mrow>
    <mn>2</mn></msup></mrow></math>
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="min Underscript beta Endscripts parallel-to bold upper X beta
    minus bold y parallel-to" display="block"><mrow><munder><mo form="prefix" movablelimits="true">min</mo>
    <mi mathvariant="bold">β</mi></munder> <msup><mrow><mo>∥</mo><mi mathvariant="bold">X</mi><mi
    mathvariant="bold">β</mi><mo>-</mo><mi mathvariant="bold">y</mi><mo>∥</mo></mrow>
    <mn>2</mn></msup></mrow></math>
- en: 'The solution to this optimization can be found by setting the derivative of
    the objective to zero and applying a bit of differential calculus^([3](ch11.xhtml#idm45733295298448))
    and a bit of algebra:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个优化问题可以通过将目标的导数设为零并应用一点微分计算^([3](ch11.xhtml#idm45733295298448)) 和一点代数来找到。
- en: <math alttext="StartLayout 1st Row 1st Column 0 equals StartFraction d Over
    d beta EndFraction parallel-to bold upper X beta minus bold y parallel-to 2nd
    Column equals 2 bold upper X Superscript upper T Baseline left-parenthesis bold
    upper X beta minus bold y right-parenthesis 2nd Row 1st Column 0 2nd Column equals
    bold upper X Superscript upper T Baseline bold upper X beta minus bold upper X
    Superscript upper T Baseline bold y 3rd Row 1st Column bold upper X Superscript
    upper T Baseline bold upper X beta 2nd Column equals bold upper X Superscript
    upper T Baseline bold y 4th Row 1st Column beta 2nd Column equals left-parenthesis
    bold upper X Superscript upper T Baseline bold upper X right-parenthesis Superscript
    negative 1 Baseline bold upper X Superscript upper T Baseline bold y EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mn>0</mn>
    <mo>=</mo> <mfrac><mi>d</mi> <mrow><mi>d</mi><mi mathvariant="bold">β</mi></mrow></mfrac>
    <msup><mrow><mo>∥</mo><mi mathvariant="bold">X</mi><mi mathvariant="bold">β</mi><mo>-</mo><mi
    mathvariant="bold">y</mi><mo>∥</mo></mrow> <mn>2</mn></msup></mrow></mtd> <mtd
    columnalign="left"><mrow><mo>=</mo> <mn>2</mn> <msup><mi mathvariant="bold">X</mi>
    <mtext>T</mtext></msup> <mrow><mo>(</mo> <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi>
    <mo>-</mo> <mi mathvariant="bold">y</mi> <mo>)</mo></mrow></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mn>0</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi>
    <mi mathvariant="bold">β</mi> <mo>-</mo> <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msup><mi
    mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi>
    <mi mathvariant="bold">β</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mi mathvariant="bold">β</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column 0 equals StartFraction d Over
    d beta EndFraction parallel-to bold upper X beta minus bold y parallel-to 2nd
    Column equals 2 bold upper X Superscript upper T Baseline left-parenthesis bold
    upper X beta minus bold y right-parenthesis 2nd Row 1st Column 0 2nd Column equals
    bold upper X Superscript upper T Baseline bold upper X beta minus bold upper X
    Superscript upper T Baseline bold y 3rd Row 1st Column bold upper X Superscript
    upper T Baseline bold upper X beta 2nd Column equals bold upper X Superscript
    upper T Baseline bold y 4th Row 1st Column beta 2nd Column equals left-parenthesis
    bold upper X Superscript upper T Baseline bold upper X right-parenthesis Superscript
    negative 1 Baseline bold upper X Superscript upper T Baseline bold y EndLayout"
    display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mn>0</mn>
    <mo>=</mo> <mfrac><mi>d</mi> <mrow><mi>d</mi><mi mathvariant="bold">β</mi></mrow></mfrac>
    <msup><mrow><mo>∥</mo><mi mathvariant="bold">X</mi><mi mathvariant="bold">β</mi><mo>-</mo><mi
    mathvariant="bold">y</mi><mo>∥</mo></mrow> <mn>2</mn></msup></mrow></mtd> <mtd
    columnalign="left"><mrow><mo>=</mo> <mn>2</mn> <msup><mi mathvariant="bold">X</mi>
    <mtext>T</mtext></msup> <mrow><mo>(</mo> <mi mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi>
    <mo>-</mo> <mi mathvariant="bold">y</mi> <mo>)</mo></mrow></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mn>0</mn></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi>
    <mi mathvariant="bold">β</mi> <mo>-</mo> <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><msup><mi
    mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">X</mi>
    <mi mathvariant="bold">β</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mi mathvariant="bold">β</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msup><mrow><mo>(</mo><msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">X</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi mathvariant="bold">X</mi> <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
- en: Amazingly enough, we started from a different perspective—minimize the squared
    distance between the model-predicted values and the observed values—and again
    we rediscovered the same solution to least squares that we reached simply by using
    our linear algebra intuition.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 神奇的是，我们从不同的角度出发——最小化模型预测值与观测值之间的平方距离——我们再次通过线性代数的直觉重新发现了最小二乘法的相同解决方案。
- en: '[Figure 11-2](#fig_11_2) shows some observed data (black squares), their model-predicted
    values (gray dots), and the distances between them (gray dashed lines). All model-predicted
    values lie on a line; the goal of least squares is to find the slope and intercept
    of that line that minimizes the distances from predicted to observed data.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 11-2](#fig_11_2)展示了一些观察到的数据（黑色方块），它们的模型预测值（灰色点）以及它们之间的距离（灰色虚线）。所有模型预测值均位于一条直线上；最小二乘法的目标是找到该直线的斜率和截距，使得从预测到观测数据的距离最小化。'
- en: '![pic of glm](assets/plad_1102.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![glm图片](assets/plad_1102.png)'
- en: Figure 11-2\. Visual intuition for least squares
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-2\. 最小二乘法的直观理解
- en: GLM in a Simple Example
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单示例中的广义线性模型（GLM）
- en: You will see several examples with real data in the next chapter; here I want
    to focus on a simple example with fake data. The fake data comes from a fake experiment
    in which I surveyed a random set of 20 of my fake students and asked them to report
    the number of my online courses they have taken and their general satisfaction
    with life.^([4](ch11.xhtml#idm45733295240096))
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章节中，你将看到几个实际数据的示例；在这里，我想集中讨论一个使用虚假数据的简单示例。这些虚假数据来自一个虚构的实验，我在其中随机调查了20位虚构的学生，并询问了他们参加过的在线课程数量以及他们对生活的整体满意度。^([4](ch11.xhtml#idm45733295240096))
- en: '[Table 11-3](#table_11_3) shows the first 4 (out of 20) rows of the data matrix.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 11-3](#table_11_3)展示了数据矩阵的前4行（共20行）。'
- en: Table 11-3\. Data table
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 表 11-3\. 数据表
- en: '| Number of courses | Life happiness |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| Number of courses | Life happiness |'
- en: '| --- | --- |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 4 | 25 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 25 |'
- en: '| 12 | 54 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 12 | 54 |'
- en: '| 3 | 21 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 21 |'
- en: '| 14 | 80 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 14 | 80 |'
- en: The data is easier to visualize in a scatterplot, which you see in [Figure 11-3](#fig_11_3).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 通过散点图更容易将数据可视化，你可以在[图 11-3](#fig_11_3)中看到它。
- en: '![The data](assets/plad_1103.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![数据](assets/plad_1103.png)'
- en: Figure 11-3\. Fake data from a fake survey
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-3\. 来自虚构调查的虚假数据
- en: Notice that the independent variable is plotted on the *x*-axis while the dependent
    variable is plotted on the *y*-axis. That is common convention in statistics.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，独立变量在*x*轴上绘制，而因变量在*y*轴上绘制，这是统计学中的常见惯例。
- en: 'We need to create the design matrix. Because this is a simple model with only
    one predictor, our design matrix is actually only one column vector. Our matrix
    equation <math alttext="bold upper X beta equals bold y"><mrow><mi mathvariant="bold">X</mi><mi
    mathvariant="bold">β</mi><mo>=</mo><mi mathvariant="bold">y</mi></mrow></math>
    looks like this (again, only the first four data values):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要创建设计矩阵。因为这是一个简单的模型，只有一个预测变量，所以我们的设计矩阵实际上只是一个列向量。我们的矩阵方程<math alttext="bold
    upper X beta equals bold y"><mrow><mi mathvariant="bold">X</mi><mi mathvariant="bold">β</mi><mo>=</mo><mi
    mathvariant="bold">y</mi></mrow></math>看起来像这样（再次强调，仅展示前四个数据值）：
- en: <math alttext="Start 4 By 1 Matrix 1st Row  25 2nd Row  54 3rd Row  21 4th Row  80
    EndMatrix Start 1 By 1 Matrix 1st Row  beta EndMatrix equals Start 4 By 1 Matrix
    1st Row  4 2nd Row  12 3rd Row  3 4th Row  14 EndMatrix" display="block"><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mn>25</mn></mtd></mtr> <mtr><mtd><mn>54</mn></mtd></mtr>
    <mtr><mtd><mn>21</mn></mtd></mtr> <mtr><mtd><mn>80</mn></mtd></mtr></mtable></mfenced>
    <mfenced close="]" open="["><mtable><mtr><mtd><mi>β</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>12</mn></mtd></mtr> <mtr><mtd><mn>3</mn></mtd></mtr> <mtr><mtd><mn>14</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="Start 4 By 1 Matrix 1st Row  25 2nd Row  54 3rd Row  21 4th Row  80
    EndMatrix Start 1 By 1 Matrix 1st Row  beta EndMatrix equals Start 4 By 1 Matrix
    1st Row  4 2nd Row  12 3rd Row  3 4th Row  14 EndMatrix" display="block"><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mn>25</mn></mtd></mtr> <mtr><mtd><mn>54</mn></mtd></mtr>
    <mtr><mtd><mn>21</mn></mtd></mtr> <mtr><mtd><mn>80</mn></mtd></mtr></mtable></mfenced>
    <mfenced close="]" open="["><mtable><mtr><mtd><mi>β</mi></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>12</mn></mtd></mtr> <mtr><mtd><mn>3</mn></mtd></mtr> <mtr><mtd><mn>14</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'The following Python code shows the solution. Variables `numcourses` and `happiness`
    contain the data; they are both lists and therefore must be converted into multidimensional
    NumPy arrays:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以下Python代码展示了解决方案。变量`numcourses`和`happiness`包含数据；它们都是列表，因此必须转换为多维NumPy数组：
- en: '[PRE1]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The least squares formula tells us that <math alttext="beta equals 5.95"><mrow><mi
    mathvariant="bold">β</mi><mo>=</mo><mn>5.95</mn></mrow></math>. What does this
    number mean? It is the slope in our formula. In other words, for each additional
    course that someone takes, their self-reported life happiness increases by 5.95
    points. Let’s see how that result looks in a plot. [Figure 11-4](#fig_11_4) shows
    the data (black squares), the predicted happiness values (gray dots connected
    by a line), and the residuals (dashed line connecting each observed value to the
    predicted value).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘公式告诉我们<math alttext="beta equals 5.95"><mrow><mi mathvariant="bold">β</mi><mo>=</mo><mn>5.95</mn></mrow></math>。这个数字的含义是什么？它是我们公式中的斜率。换句话说，每增加一门课程，一个人的自报生活幸福感就增加5.95个点。让我们看看这个结果在图中的表现。[图 11-4](#fig_11_4)展示了数据（黑色方块）、预测的幸福值（由灰色点连接的线）以及残差（连接每个观测值与预测值的虚线）。
- en: '![The data, part deux](assets/plad_1104.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![数据续集](assets/plad_1104.png)'
- en: Figure 11-4\. Observed and predicted data (SSE = sum of squared errors)
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-4\. 观察数据和预测数据（SSE = 平方误差和）
- en: If you experience a feeling of unease while looking at [Figure 11-4](#fig_11_4),
    then that’s good—it means you are thinking critically and noticed that the model
    doesn’t do a great job at minimizing the errors. You can easily imagine pushing
    the left side of the best-fit line up to get a better fit. What’s the problem
    here?
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在观看[图 11-4](#fig_11_4)时感到不安，那是好事——这意味着你在进行批判性思考，并注意到模型在最小化误差方面表现不佳。你可以轻松想象将最佳拟合线的左侧向上推以获得更好的拟合。这里的问题是什么呢？
- en: The problem is that the design matrix contains no intercept. The equation of
    the best-fit line is *y* = *mx*, which means that when *x* = 0, *y* = 0\. That
    constraint doesn’t make sense for this problem—it would be a sad world if anyone
    who doesn’t take my courses is completely devoid of life satisfaction. Instead,
    we want our line to have the form *y* = *mx* + *b*, where *b* is the intercept
    term that allows the best-fit line to cross the *y*-axis at any value. The statistical
    interpretation of the intercept is the expected numerical value of the observations
    when the predictors are set to zero.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于设计矩阵不包含截距项。最佳拟合线的方程是*y* = *mx*，这意味着当*x* = 0时，*y* = 0。这个约束对这个问题来说是没有意义的——如果任何没有参加我的课程的人完全缺乏生活满意度，那将是一个悲哀的世界。相反，我们希望我们的线条具有*y*
    = *mx* + *b*的形式，其中*b*是截距项，允许最佳拟合线在*y*轴上交叉任意值。截距的统计解释是观察数值的期望值，当预测变量设为零时。
- en: 'Adding an intercept term to our design matrix gives the following modified
    equations (again only showing the first four rows):'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 向我们的设计矩阵添加一个截距项会得到以下修改的方程（再次仅显示前四行）：
- en: <math alttext="Start 4 By 2 Matrix 1st Row 1st Column 1 2nd Column 25 2nd Row
    1st Column 1 2nd Column 54 3rd Row 1st Column 1 2nd Column 21 4th Row 1st Column
    1 2nd Column 80 EndMatrix StartBinomialOrMatrix beta 1 Choose beta 2 EndBinomialOrMatrix
    equals Start 4 By 1 Matrix 1st Row  4 2nd Row  12 3rd Row  3 4th Row  14 EndMatrix"
    display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>25</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mn>54</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>21</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>80</mn></mtd></mtr></mtable></mfenced> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>β</mi>
    <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>β</mi> <mn>2</mn></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>12</mn></mtd></mtr> <mtr><mtd><mn>3</mn></mtd></mtr> <mtr><mtd><mn>14</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="Start 4 By 2 Matrix 1st Row 1st Column 1 2nd Column 25 2nd Row
    1st Column 1 2nd Column 54 3rd Row 1st Column 1 2nd Column 21 4th Row 1st Column
    1 2nd Column 80 EndMatrix StartBinomialOrMatrix beta 1 Choose beta 2 EndBinomialOrMatrix
    equals Start 4 By 1 Matrix 1st Row  4 2nd Row  12 3rd Row  3 4th Row  14 EndMatrix"
    display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>25</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mn>54</mn></mtd></mtr>
    <mtr><mtd><mn>1</mn></mtd> <mtd><mn>21</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>80</mn></mtd></mtr></mtable></mfenced> <mfenced close="]" open="["><mtable><mtr><mtd><msub><mi>β</mi>
    <mn>1</mn></msub></mtd></mtr> <mtr><mtd><msub><mi>β</mi> <mn>2</mn></msub></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>12</mn></mtd></mtr> <mtr><mtd><mn>3</mn></mtd></mtr> <mtr><mtd><mn>14</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'The code doesn’t change, with one exception of creating the design matrix:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 代码不变，唯一的例外是创建设计矩阵：
- en: '[PRE2]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we find that <math alttext="beta"><mi mathvariant="bold">β</mi></math> is
    the two-element vector [22.9,3.7]. The expected level of happiness for someone
    who has taken zero courses is 22.9, and for each additional course someone takes,
    their happiness increases by 3.7 points. I’m sure you will agree that [Figure 11-5](#fig_11_5)
    looks much better. And the SSE is around half of what it was when we excluded
    the intercept.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们发现**β**是两元向量[22.9, 3.7]。对于一个零课程的人来说，幸福感的期望水平是22.9，而每增加一门课程，他们的幸福感将增加3.7点。我相信你会同意[图11-5](#fig_11_5)看起来好多了。SSE大约是我们排除截距时的一半。
- en: '![The data, part troi](assets/plad_1105.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![数据，第三部分](assets/plad_1105.png)'
- en: Figure 11-5\. Observed and predicted data, now with an intercept term
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-5。观察和预测数据，现在包含截距项
- en: I will let you draw your own conclusions about the fake results from this fake
    study based on fake data; the point is to see a numerical example of how to solve
    a system of equations by building an appropriate design matrix and solving for
    the unknown regressors using the left-inverse.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我会让你自己对这个基于虚假数据的虚假研究结果做出结论；重点是看到如何通过构建适当的设计矩阵并解未知回归器来解决方程组的数值示例。
- en: Least Squares via QR
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过QR进行最小二乘法
- en: The left-inverse method is theoretically sound, but risks numerical instability.
    This is partly because it requires computing the matrix inverse, which you already
    know can be numerically unstable. But it turns out that the matrix <math alttext="bold
    upper X Superscript upper T Baseline bold upper X"><mrow><msup><mi>𝐗</mi> <mtext>T</mtext></msup>
    <mi>𝐗</mi></mrow></math> itself can introduce difficulties. Multiplying a matrix
    by its transpose has implications for properties such as the norm and the condition
    number. You will learn more about the condition number in [Chapter 14](ch14.xhtml#Chapter_14),
    but I’ve already mentioned that matrices with a high condition number can be numerically
    unstable, and thus a design matrix with a high condition number will become even
    less numerically stable when squared.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 左逆方法在理论上是合理的，但存在数值不稳定的风险。部分原因是它需要计算矩阵的逆，你已经知道这可能导致数值不稳定。但事实证明，矩阵**𝐗<sup>T</sup>𝐗**本身可能会带来困难。将一个矩阵乘以它的转置对诸如范数和条件数等性质有影响。你将在[第14章](ch14.xhtml#Chapter_14)进一步了解条件数，但我已经提到，条件数高的矩阵可能数值不稳定，因此条件数高的设计矩阵在平方后会变得更不稳定。
- en: 'QR decomposition provides a more stable way to solve the least squares problem.
    Observe the following sequence of equations:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: QR分解提供了解决最小二乘问题更稳定的方法。观察以下方程的序列：
- en: <math alttext="StartLayout 1st Row 1st Column bold upper X beta 2nd Column equals
    bold y 2nd Row 1st Column bold upper Q bold upper R beta 2nd Column equals bold
    y 3rd Row 1st Column bold upper R beta 2nd Column equals bold upper Q Superscript
    upper T Baseline bold y 4th Row 1st Column beta 2nd Column equals bold upper R
    Superscript negative 1 Baseline bold upper Q Superscript upper T Baseline bold
    y EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi
    mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><mi
    mathvariant="bold">Q</mi> <mi mathvariant="bold">R</mi> <mi mathvariant="bold">β</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mi mathvariant="bold">y</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mi mathvariant="bold">R</mi> <mi mathvariant="bold">β</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <msup><mi mathvariant="bold">Q</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi
    mathvariant="bold">β</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <msup><mi
    mathvariant="bold">R</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msup><mi mathvariant="bold">Q</mi>
    <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column bold upper X beta 2nd Column equals
    bold y 2nd Row 1st Column bold upper Q bold upper R beta 2nd Column equals bold
    y 3rd Row 1st Column bold upper R beta 2nd Column equals bold upper Q Superscript
    upper T Baseline bold y 4th Row 1st Column beta 2nd Column equals bold upper R
    Superscript negative 1 Baseline bold upper Q Superscript upper T Baseline bold
    y EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi
    mathvariant="bold">X</mi> <mi mathvariant="bold">β</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mrow><mi
    mathvariant="bold">Q</mi> <mi mathvariant="bold">R</mi> <mi mathvariant="bold">β</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mi mathvariant="bold">y</mi></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mi mathvariant="bold">R</mi> <mi mathvariant="bold">β</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <msup><mi mathvariant="bold">Q</mi> <mtext>T</mtext></msup>
    <mi mathvariant="bold">y</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi
    mathvariant="bold">β</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <msup><mi
    mathvariant="bold">R</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msup><mi mathvariant="bold">Q</mi>
    <mtext>T</mtext></msup> <mi mathvariant="bold">y</mi></mrow></mtd></mtr></mtable></math>
- en: These equations are slightly simplified from the actual low-level numerical
    implementations. For example, <math alttext="bold upper R"><mi>𝐑</mi></math> is
    the same shape as <math alttext="bold upper X"><mi>𝐗</mi></math> , i.e., tall
    (and therefore noninvertible), although only the first *N* rows are nonzero (as
    you discovered in [Exercise 9-7](ch09.xhtml#exercise_9_7)), which means that rows
    *N* + 1 through *M* do not contribute to the solution (in matrix multiplication,
    rows of zeros produce results of zeros). Those rows can be removed from <math
    alttext="bold upper R"><mi>𝐑</mi></math> and from <math alttext="bold upper Q
    Superscript upper T Baseline bold y"><mrow><msup><mi>𝐐</mi> <mtext>T</mtext></msup>
    <mi>𝐲</mi></mrow></math> . Secondly, row swaps (implemented via permutation matrices)
    might be used to increase numerical stability.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方程略微简化了实际低级数值实现。例如，<math alttext="bold upper R"><mi>𝐑</mi></math>与<math alttext="bold
    upper X"><mi>𝐗</mi></math>的形状相同，即高而非可逆，尽管仅前*N*行是非零的（如您在[习题 9-7](ch09.xhtml#exercise_9_7)中发现的），这意味着第*N*
    + 1到*M*行不会对解产生贡献（在矩阵乘法中，零行产生零结果）。这些行可以从<math alttext="bold upper R"><mi>𝐑</mi></math>和<math
    alttext="bold upper Q Superscript upper T Baseline bold y"><mrow><msup><mi>𝐐</mi>
    <mtext>T</mtext></msup> <mi>𝐲</mi></mrow></math>中移除。其次，行交换（通过置换矩阵实现）可能用于增加数值稳定性。
- en: 'But here’s the best part: it’s not even necessary to invert <math alttext="bold
    upper R"><mi>𝐑</mi></math> —that matrix is upper-triangular and therefore the
    solution can be obtained via back substitution. It’s the same as solving a system
    of equations via the Gauss-Jordan method: augment the coefficients matrix by the
    constants, row reduce to obtain the RREF, and extract the solution from the final
    column of the augmented matrix.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里最重要的部分是：不需要转置矩阵<math alttext="bold upper R"><mi>𝐑</mi></math> ——该矩阵是上三角的，因此可以通过回代法获得解。这与通过高斯-约当方法解方程组是相同的：将系数矩阵与常数增广，行约简以获得最简行阶梯形式矩阵，并从增广矩阵的最后一列提取解。
- en: The conclusion here is that QR decomposition solves the least squares problem
    without squaring <math alttext="bold upper X Superscript upper T Baseline bold
    upper X"><mrow><msup><mi>𝐗</mi> <mtext>T</mtext></msup> <mi>𝐗</mi></mrow></math>
    and without explicitly inverting a matrix. The main risk of numerical instability
    comes from computing <math alttext="bold upper Q"><mi>𝐐</mi></math> , although
    this is fairly numerically stable when implemented via Householder reflections.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 结论是QR分解解决了最小二乘问题，无需对<math alttext="bold upper X Superscript upper T Baseline
    bold upper X"><mrow><msup><mi>𝐗</mi> <mtext>T</mtext></msup> <mi>𝐗</mi></mrow></math>进行平方，也无需显式求逆矩阵。数值不稳定的主要风险来自计算<math
    alttext="bold upper Q"><mi>𝐐</mi></math>，尽管通过Householder反射实现时，这是相当稳定的。
- en: '[Exercise 11-3](#exercise_11_3) will walk you through this implementation.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[习题 11-3](#exercise_11_3) 将引导您完成这个实现。'
- en: Summary
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Many people think that statistics is hard because the underlying mathematics
    is hard. To be sure, there are advanced statistical methods involving advanced
    mathematics. But many of the commonly used statistical methods are built on linear
    algebra principles that you now understand. That means you no longer have any
    excuses not to master the statistical analyses used in data science!
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人认为统计学很难是因为其基础数学难度很大。确实，涉及高级数学的高级统计方法存在。但许多常用的统计方法是建立在您现在理解的线性代数原理上的。这意味着您不再有任何理由不精通数据科学中使用的统计分析方法了！
- en: The goal of this chapter was to introduce you to the terminology and math underlying
    the general linear model, the geometric interpretation, and the implications of
    the math for minimizing the difference between model-predicated data and observed
    data. I also showed an application of a regression in a simple toy example. In
    the next chapter, you’ll see least squares implemented with real data, and you’ll
    see extensions of least squares in regression, such as polynomial regression and
    regularization.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是介绍通用线性模型的术语和数学基础，几何解释，以及数学对模型预测数据与观察数据差异最小化的影响。我还展示了一个简单玩具示例中回归的应用。在下一章中，您将看到在真实数据中实现最小二乘法，并看到最小二乘法在回归中的扩展，如多项式回归和正则化。
- en: 'Here are the key take-home messages from this chapter:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章的主要要点：
- en: The GLM is a statistical framework for understanding our rich and beautiful
    universe. It works by setting up a system of equations, just like the systems
    of equations you learned about in the previous chapter.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广义线性模型（GLM）是理解我们丰富和美丽宇宙的统计框架。它通过建立一组方程来工作，就像你在上一章中学到的方程组一样。
- en: The terms are somewhat different between linear algebra and statistics; once
    you learn the terminological mappings, statistics becomes easier because you already
    know the math.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性代数和统计学术语有所不同；一旦你了解了术语映射，统计学会变得更容易，因为你已经了解了数学。
- en: The least squares method of solving equations via the left-inverse is the foundation
    of many statistical analyses, and you will often see the least squares solution
    “hidden” inside seemingly complicated formulas.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小二乘方法通过左逆来解方程，是许多统计分析的基础，你经常会在看似复杂的公式中“隐藏”最小二乘解法。
- en: The least squares formula can be derived via algebra, geometry, or calculus.
    This provides multiple ways of understanding and interpreting least squares.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小二乘公式可以通过代数、几何或微积分推导出来。这提供了理解和解释最小二乘的多种方式。
- en: Multiplying the observed data vector by the left-inverse is conceptually the
    right way to think about least squares. In practice, other methods such as LU
    and QR decomposition are more numerically stable. Fortunately, you don’t need
    to worry about this because Python calls low-level libraries (mostly LAPACK) that
    implement the most numerically stable algorithms.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将观测数据向量乘以左逆的概念上是考虑最小二乘的正确方法。在实践中，其他方法如LU和QR分解更加数值稳定。幸运的是，你不需要担心这个，因为Python调用低级别库（主要是LAPACK），这些库实现了最数值稳定的算法。
- en: Code Exercises
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码练习
- en: Exercise 11-1\.
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '-   练习 11-1。'
- en: I explained that the residuals are orthogonal to the predicted data (in other
    words, <math alttext="epsilon Superscript upper T Baseline ModifyingAbove bold
    y With bold caret equals 0"><mrow><msup><mi>ϵ</mi> <mtext>T</mtext></msup> <mover
    accent="true"><mi>𝐲</mi> <mo>^</mo></mover> <mo>=</mo> <mn>0</mn></mrow></math>
    ). Illustrate this in the toy dataset from this chapter. In particular, make a
    scatterplot of the predicted data by the errors (as in [Figure 11-6](#fig_11_6)).
    Then compute the dot product and the correlation coefficient between the residuals
    and the model-predicted data. In theory, both should be exactly zero, although
    there are some rounding errors. Which of those two analyses (dot product or correlation)
    is smaller, and why is that?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我解释了残差与预测数据正交（换句话说，<math alttext="epsilon Superscript upper T Baseline ModifyingAbove
    bold y With bold caret equals 0"><mrow><msup><mi>ϵ</mi> <mtext>T</mtext></msup>
    <mover accent="true"><mi>𝐲</mi> <mo>^</mo></mover> <mo>=</mo> <mn>0</mn></mrow></math>
    ）。在本章中的玩具数据集中说明这一点。特别是，用预测数据和误差制作散点图（如[图 11-6](#fig_11_6)）。然后计算残差与模型预测数据之间的点积和相关系数。理论上，两者应完全为零，尽管存在一些舍入误差。这两种分析（点积或相关性）中哪一种更小，为什么？
- en: '![Ex0](assets/plad_1106.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![Ex0](assets/plad_1106.png)'
- en: Figure 11-6\. Solution to Exercise 11-1
  id: totrans-133
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-6\. 练习 11-1 的解答
- en: Exercise 11-2\.
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '-   练习 11-2。'
- en: 'The model-predicted happiness is merely one way of linearly combining the columns
    of the design matrix. But the residuals vector isn’t only orthogonal to that one
    linear weighted combination; instead, the residuals vector is orthogonal to the
    *entire subspace* spanned by the design matrix. Demonstrate this in Python (hint:
    think of the left-null space and rank).'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 模型预测的幸福感仅仅是线性组合设计矩阵列的一种方式。但是残差向量不仅仅是与该线性加权组合正交；相反，残差向量正交于设计矩阵张成的*整个子空间*。在Python中演示这一点（提示：考虑左零空间和秩）。
- en: Exercise 11-3\.
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '-   练习 11-3。'
- en: 'You are now going to compute least squares via QR decomposition, as I explained
    in [“Least Squares via QR”](#least_squares_via_qr). In particular, compute and
    compare the following solution methods: (1) the left-inverse <math alttext="left-parenthesis
    bold upper X Superscript upper T Baseline bold upper X right-parenthesis Superscript
    negative 1 Baseline bold upper X Superscript upper T Baseline bold y"><mrow><msup><mrow><mo>(</mo><msup><mi>𝐗</mi>
    <mtext>T</mtext></msup> <mi>𝐗</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>𝐗</mi> <mtext>T</mtext></msup> <mi>𝐲</mi></mrow></math> , (2) QR with
    the inverse as <math alttext="bold upper R Superscript negative 1 Baseline bold
    upper Q Superscript upper T Baseline bold y"><mrow><msup><mi>𝐑</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>𝐐</mi> <mtext>T</mtext></msup> <mi>𝐲</mi></mrow></math> , and (3) Gauss-Jordan
    elimination on the matrix <math alttext="bold upper R"><mi>𝐑</mi></math> augmented
    with <math alttext="bold upper Q Superscript upper T Baseline bold y"><mrow><msup><mi>𝐐</mi>
    <mtext>T</mtext></msup> <mi>𝐲</mi></mrow></math> .'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将通过 QR 分解计算最小二乘法，正如我在 [“最小二乘法 via QR”](#least_squares_via_qr) 中所解释的那样。特别是，计算并比较以下解法：(1)
    左逆 <math alttext="left-parenthesis bold upper X Superscript upper T Baseline bold
    upper X right-parenthesis Superscript negative 1 Baseline bold upper X Superscript
    upper T Baseline bold y"><mrow><msup><mrow><mo>(</mo><msup><mi>𝐗</mi> <mtext>T</mtext></msup>
    <mi>𝐗</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msup><mi>𝐗</mi>
    <mtext>T</mtext></msup> <mi>𝐲</mi></mrow></math> ，(2) QR 分解的逆作为 <math alttext="bold
    upper R Superscript negative 1 Baseline bold upper Q Superscript upper T Baseline
    bold y"><mrow><msup><mi>𝐑</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup> <msup><mi>𝐐</mi>
    <mtext>T</mtext></msup> <mi>𝐲</mi></mrow></math> ，以及 (3) 对矩阵 <math alttext="bold
    upper R"><mi>𝐑</mi></math> 和增广矩阵 <math alttext="bold upper Q Superscript upper
    T Baseline bold y"><mrow><msup><mi>𝐐</mi> <mtext>T</mtext></msup> <mi>𝐲</mi></mrow></math>
    进行的高斯-约当消元法。
- en: Print out the beta parameters from the three methods as follows. (Rounding to
    three digits after the decimal point is an optional extra coding challenge.)
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 按以下方式打印出三种方法的 beta 参数。 （将小数点后的结果四舍五入到三位数是一个额外的编码挑战。）
- en: '[PRE3]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Finally, print out the resulting matrices from the QR method as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，按以下方式打印 QR 方法生成的结果矩阵：
- en: '[PRE4]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Exercise 11-4\.
  id: totrans-142
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 11-4\.
- en: '*Outliers* are data values that are unusual or nonrepresentative. Outliers
    can cause significant problems in statistical models, and therefore can cause
    significant headaches for data scientists. In this exercise, we will create outliers
    in the happiness data to observe the effects on the resulting least squares solution.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '*异常值* 是不寻常或不典型的数据值。异常值可能会导致统计模型中的显著问题，因此它们可能会给数据科学家带来头痛。在这个练习中，我们将在幸福数据中创建异常值，以观察对最小二乘解的影响。'
- en: In the data vector, change the first observed data point from `70` to `170`
    (simulating a data-entry typo). Then recompute the least squares fit and plot
    the data. Repeat this outlier simulation but change the final data point from
    `70` to `170` (and set the first data point back to its original `70`). Compare
    with the original data by creating a visualization like [Figure 11-7](#fig_11_7).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据向量中，将第一个观察数据点从 `70` 改为 `170` （模拟数据输入错误）。然后重新计算最小二乘拟合并绘制数据。重复这种异常值模拟，但将最后一个数据点从
    `70` 改为 `170` （并将第一个数据点恢复为其原始值 `70`）。通过创建类似于 [图 11-7](#fig_11_7) 的可视化来与原始数据进行比较。
- en: '![Ex3](assets/plad_1107.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![Ex3](assets/plad_1107.png)'
- en: Figure 11-7\. Solution to Exercise 11-4
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-7\. 练习 11-4 的解答
- en: Interestingly, the outlier was identical in the outcome variable (in both cases,
    the `70` turned into `170`), but the effect on the fit of the model to the data
    was quite different because of the corresponding *x*-axis value. This differential
    impact of outliers is called *leverage* and is something you would learn about
    in a deeper discussion of statistics and model fitting.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，异常值在结果变量中是相同的（在两种情况下，`70` 变成了 `170`），但由于相应的 *x* 轴数值，它们对模型拟合数据的影响却有很大差异。这种异常值对模型拟合的不同影响被称为
    *杠杆效应*，需要在更深入讨论统计学和模型拟合时学习。
- en: Exercise 11-5\.
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 11-5\.
- en: In this exercise, you will compute the matrix inverse using least squares, following
    the interpetation I introduced in the previous chapter. We will consider the equation
    <math alttext="bold upper X bold upper B equals bold upper Y"><mrow><mi>𝐗</mi>
    <mi>𝐁</mi> <mo>=</mo> <mi>𝐘</mi></mrow></math> , where <math alttext="bold upper
    X"><mi>𝐗</mi></math> is the square full-rank matrix to invert, <math alttext="bold
    upper B"><mi>𝐁</mi></math> is the matrix of unknown coefficients (which will be
    the matrix inverse), and <math alttext="bold upper Y"><mi>𝐘</mi></math> is the
    “observed data” (the identity matrix).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，您将使用最小二乘法计算矩阵的逆，按照我在前一章节中介绍的解释进行。我们将考虑方程式<math alttext="bold upper X
    bold upper B equals bold upper Y"><mrow><mi>𝐗</mi> <mi>𝐁</mi> <mo>=</mo> <mi>𝐘</mi></mrow></math>，其中<math
    alttext="bold upper X"><mi>𝐗</mi></math>是要求逆的方阵满秩矩阵，<math alttext="bold upper
    B"><mi>𝐁</mi></math>是未知系数的矩阵（将是矩阵逆），而<math alttext="bold upper Y"><mi>𝐘</mi></math>是“观察到的数据”（单位矩阵）。
- en: You will compute <math alttext="bold upper B"><mi>𝐁</mi></math> in three ways.
    First, use the left-inverse least squares method to compute the matrix one column
    at a time. This is done by computing the least squares fit between the matrix
    <math alttext="bold upper X"><mi>𝐗</mi></math> and each column of <math alttext="bold
    upper Y"><mi>𝐘</mi></math> in a `for` loop. Second, use the left-inverse method
    to compute the entire <math alttext="bold upper B"><mi>𝐁</mi></math> matrix in
    one line of code. Finally, compute <math alttext="bold upper X Superscript negative
    1"><msup><mi>𝐗</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math> using the
    function `np.linalg.inv()`. Mutliply each of those <math alttext="bold upper B"><mi>𝐁</mi></math>
    matrices by <math alttext="bold upper X"><mi>𝐗</mi></math> and show in a figure
    like [Figure 11-8](#fig_11_8). Finally, test whether these three “different” ways
    of computing the inverse are equivalent (they should be, because the matrix inverse
    is unique).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 您将通过三种方式计算<math alttext="bold upper B"><mi>𝐁</mi></math>。首先，使用左逆最小二乘法逐列计算矩阵<math
    alttext="bold upper X"><mi>𝐗</mi></math>和<math alttext="bold upper Y"><mi>𝐘</mi></math>的最小二乘拟合，在`for`循环中执行。其次，使用左逆方法在一行代码中计算整个<math
    alttext="bold upper B"><mi>𝐁</mi></math>矩阵。最后，使用函数`np.linalg.inv()`计算<math alttext="bold
    upper X Superscript negative 1"><msup><mi>𝐗</mi> <mrow><mo>-</mo><mn>1</mn></mrow></msup></math>。将每个<math
    alttext="bold upper B"><mi>𝐁</mi></math>矩阵乘以<math alttext="bold upper X"><mi>𝐗</mi></math>，并展示类似于[Figure 11-8](#fig_11_8)的图表。最后，测试这三种“不同”的逆计算方法是否等效（它们应该是的，因为矩阵逆是唯一的）。
- en: 'Observation: it is rather strange (not to mention circular) to use the inverse
    of <math alttext="bold upper X Superscript upper T Baseline bold upper X"><mrow><msup><mi>𝐗</mi>
    <mtext>T</mtext></msup> <mi>𝐗</mi></mrow></math> to compute the inverse of <math
    alttext="bold upper X"><mi>𝐗</mi></math> . (Indeed, you should confirm with paper
    and pencil that the left-inverse reduces to the full inverse for square full-rank
    <math alttext="bold upper X"><mi>𝐗</mi></math> !) Needless to say, this is not
    a computational method that would be implemented in practice. However, this exercise
    reinforces the interpretation of the matrix inverse as the transformation that
    projects a matrix onto the identity matrix, and that that projection matrix can
    be obtained via least squares. Comparing the least squares solution to `np.linalg.inv`
    also illustrates the numerical inaccuracies that can arise when computing the
    left-inverse.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 观察：使用<math alttext="bold upper X Superscript upper T Baseline bold upper X"><mrow><msup><mi>𝐗</mi>
    <mtext>T</mtext></msup> <mi>𝐗</mi></mrow></math>的逆来计算<math alttext="bold upper
    X"><mi>𝐗</mi></math>的逆显得非常奇怪（更不用说是循环的了）。（确实，您应该通过纸和笔来确认，左逆对于方阵满秩<math alttext="bold
    upper X"><mi>𝐗</mi></math>会简化为完全逆！）不用说，这不是一个实际实施的计算方法。然而，这个练习加强了矩阵逆的解释，即将矩阵投影到单位矩阵的变换，并且该投影矩阵可以通过最小二乘法得到。将最小二乘解与`np.linalg.inv`进行比较，还可以说明计算左逆时可能出现的数值不准确性。
- en: '![Exercise 11-5](assets/plad_1108.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![练习 11-5](assets/plad_1108.png)'
- en: Figure 11-8\. Solution to Exercise 11-5
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-8\. 练习 11-5 的解答
- en: ^([1](ch11.xhtml#idm45733295548016-marker)) Admittedly, I’ve never seen this
    equation on a Tajikistani billboard, but the point is to keep an open mind.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch11.xhtml#idm45733295548016-marker)) 诚然，我从未在塔吉克斯坦广告牌上看到这个方程式，但重点是要保持开放的心态。
- en: ^([2](ch11.xhtml#idm45733295319056-marker)) In case you were wondering, it is
    also possible to minimize the *absolute* distances instead of the *squared* distances.
    Those two objectives can lead to different results; one advantage of squared distance
    is the convenient derivative, which leads to the least squares solution.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch11.xhtml#idm45733295319056-marker)) 如果你在想，也可以将*绝对*距离最小化，而不是*平方*距离。这两个目标可能导致不同的结果；平方距离的一个优点是方便的导数计算，这导致了最小二乘解。
- en: ^([3](ch11.xhtml#idm45733295298448-marker)) If you are not comfortable with
    matrix calculus, then don’t worry about the equations; the point is that we took
    the derivative with respect to **β** using the chain rule.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch11.xhtml#idm45733295298448-marker)) 如果你对矩阵微积分感到不适应，那就不用担心方程式；重点是我们利用链式法则对**β**进行了导数。
- en: '^([4](ch11.xhtml#idm45733295240096-marker)) In case it’s not already clear
    enough: this is completely made-up data for this example; any resemblance to the
    real world is coincidental.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch11.xhtml#idm45733295240096-marker)) 如果还不够清楚：这些数据完全是为这个例子而虚构的；任何与现实世界的相似性都是巧合。
