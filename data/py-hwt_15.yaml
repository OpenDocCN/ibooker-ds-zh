- en: 11 Dealing with files
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 处理文件
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Reading and writing files
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件的读写
- en: Processing tabulated data files
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理表格数据文件
- en: Preserving data as files
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据保存为文件
- en: Managing files on your computer
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理计算机上的文件
- en: Accessing file metadata
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问文件元数据
- en: Files are integral to any computer system or application. We use files to store
    data. We share data with our teammates by using files. When we obtain a file from
    others, we need to open the file, read its content, process the data, and write
    some data to another file or append data to the same file. These operations are
    concerned with the contents of the files. Our application can use hundreds of
    different Python objects, and some objects require excessive calculations or other
    processing steps, so it’s ideal that we can save these objects as files. When
    we need to use these objects again, we can load them from files, which can save
    lots of processing time.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 文件对于任何计算机系统或应用程序都是至关重要的。我们使用文件来存储数据。我们通过使用文件与我们的队友共享数据。当我们从他人那里获取文件时，我们需要打开文件，读取其内容，处理数据，并将一些数据写入另一个文件或追加到同一文件中。这些操作与文件的内容有关。我们的应用程序可以使用数百种不同的Python对象，并且某些对象需要进行大量的计算或其他处理步骤，因此能够将这些对象保存为文件是非常理想的。当我们需要再次使用这些对象时，我们可以从文件中加载它们，这可以节省大量的处理时间。
- en: Files are everywhere in any computer system, and our job can include many kinds
    of file manipulations, such as moving files to a destination, extracting files
    of a specific kind, and finding out the files that we’ve modified in the last
    week. Adequate knowledge of performing these operations in a programmatic way
    allows us to perform jobs that we can’t do easily in a manual way and track any
    changes that we’ve made to the files. In this chapter, we’ll cover important topics
    concerning files—not only reading and writing from a content perspective, but
    also common file operations such as moving and copying files.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 文件在任何计算机系统中无处不在，我们的工作可能包括许多种文件操作，例如将文件移动到目的地、提取特定类型的文件，以及找出我们上周修改过的文件。充分了解以编程方式执行这些操作的知识使我们能够完成我们无法轻松手动完成的任务，并跟踪我们对文件所做的任何更改。在本章中，我们将涵盖与文件相关的重要主题——不仅从内容的角度进行读写，还包括常见的文件操作，如移动和复制文件。
- en: 11.1 How do I read and write files using context management?
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 如何使用上下文管理器读取和写入文件？
- en: Our projects can involve a variety of file types, such as tabulated data, media,
    and pure text files. When we work with these files, the first step is to read
    them to process the contained data. Although we can use special software to manipulate
    files, our projects often require that we process files programmatically, particularly
    when we process many files. To take advantage of Python tools such as pandas to
    process tabulated data, we must also read files programmatically. As you can imagine,
    dealing with files programmatically is an essential operation for general data
    processing. In this section, you’ll learn how to read and write files in Python.
    As textual data is the most common form, we’ll use text files in our examples.
    The general techniques, however, apply to other file formats, such as binary files
    that store byte data.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的项目可能涉及各种文件类型，例如表格数据、媒体和纯文本文件。当我们处理这些文件时，第一步是读取它们以处理包含的数据。虽然我们可以使用特殊软件来操作文件，但我们的项目通常需要我们以编程方式处理文件，尤其是在处理大量文件时。为了利用pandas等Python工具处理表格数据，我们也必须以编程方式读取文件。正如你可以想象的那样，以编程方式处理文件是通用数据处理的基本操作。在本节中，你将学习如何在Python中读取和写入文件。由于文本数据是最常见的格式，我们将使用文本文件作为示例。然而，这些一般技术也适用于其他文件格式，例如存储字节数据的二进制文件。
- en: '11.1.1 Opening and closing files: Context manager'
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.1 打开和关闭文件：上下文管理器
- en: 'The most basic file-handling operations are opening and closing files. In this
    section, we’ll see how to open and close files in two ways: using the basic approach
    and using a context manager (which we’ll discuss soon).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的文件处理操作是打开和关闭文件。在本节中，我们将了解如何以两种方式打开和关闭文件：使用基本方法和使用上下文管理器（我们将在后面讨论）。
- en: 'Suppose that we use text files to store the data for our task management application.
    To start, we can create a text file named tasks.txt, which has the following data:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们使用文本文件来存储我们的任务管理应用程序的数据。首先，我们可以创建一个名为tasks.txt的文本文件，其中包含以下数据：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Each row of the data represents a task’s information: the ID number, the title,
    and the urgency level. For simplicity, we have three rows of data. We can open
    this file by using the built-in open function:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的每一行代表一个任务的信息：ID 号、标题和紧急程度。为了简单起见，我们有三行数据。我们可以使用内置的 open 函数打开此文件：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We inspect the text_file object by using the print function and get four pieces
    of information:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用 print 函数检查 text_file 对象，并获取四条信息：
- en: This object is an instance of the _io.TextIOWrapper, the class that creates
    a buffered text stream providing higher-level access to the underlying text data
    in the file. This kind of object is also known as a *stream* or *file object**.*
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此对象是 _io.TextIOWrapper 类的实例，该类创建了一个提供对文件中底层文本数据的更高级别访问的缓冲文本流。这种对象也被称为 *流* 或
    *文件对象**。
- en: name tells you the file’s name.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称告诉你文件的名称。
- en: mode indicates how the file is read. 'r' means read mode, in which we only read
    the file. In read mode, you can’t perform nonread operations, such as writing
    data to the file.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模式指示文件是如何被读取的。'r' 表示读取模式，在这种模式下，我们只能读取文件。在读取模式下，你不能执行非读取操作，例如将数据写入文件。
- en: The encoding indicates how the text file is encoded. In most cases, you don’t
    need to worry about it, because most data is encoded with UTF-8 (it also has backward
    compatibility with ASCII encoding, if you’ve heard about ASCII), which is the
    most common form of encoding in the Unicode system.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码指示文本文件是如何编码的。在大多数情况下，你不需要担心它，因为大多数数据都是使用 UTF-8 编码的（如果你听说过 ASCII 编码，它也具有与 ASCII
    编码的向后兼容性），这是 Unicode 系统中最常见的编码形式。
- en: With the created file object, we can read the data. We have different ways to
    read the data (section 11.1.2), but the most straightforward one is the read method
    shown in the next listing.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用创建的文件对象，我们可以读取数据。我们有不同的方式来读取数据（第 11.1.2 节），但最直接的方法是下一列表中显示的 read 方法。
- en: Listing 11.1 Reading data as a string
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.1 将数据作为字符串读取
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Checks with type
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用类型检查
- en: 'The read method reads all the text data in the file as a string, and we can
    print out the string to make sure that it indeed matches the text in the file.
    We can apply additional processing steps to this string, such as splitting each
    row to extract the underlying data (section 2.3). When we’re done with the processing,
    we can close the file by using the close method. After we close the file, we can
    verify the status by accessing the closed attribute, which should be True:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 读取方法将文件中的所有文本数据作为一个字符串读取，我们可以打印出这个字符串以确保它确实与文件中的文本匹配。我们可以对此字符串应用额外的处理步骤，例如将每一行分割以提取底层数据（第
    2.3 节）。当我们完成处理时，我们可以使用 close 方法关闭文件。关闭文件后，我们可以通过访问 closed 属性来验证状态，它应该是 True：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You should always close the file when you’re done with it. As files are shared
    resources in your computer, if you forget to close them, any changes you’ve made
    with the file object may get lost in the actual file. After you close the file,
    all the updates to the file are saved, and when other processes access the file,
    they have the latest data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成文件操作后，你应该始终关闭文件。因为文件是计算机中的共享资源，如果你忘记关闭它们，你使用文件对象所做的任何更改可能会在实际文件中丢失。关闭文件后，所有对文件的更新都将保存，当其他进程访问文件时，它们将获得最新的数据。
- en: 'To prevent us from losing data due to forgetting to close a file, we can use
    the *context management* technique: the with statement, which is the Pythonic
    way to read files, as shown in the next listing.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止我们因忘记关闭文件而丢失数据，我们可以使用 *上下文管理* 技术：with 语句，这是 Python 读取文件的方式，如下一列表所示。
- en: Listing 11.2 Using with to open a file
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.2 使用 with 打开文件
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ The with statement
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用 with 语句
- en: 'The syntax of using the with statement is with open("filepath") as file, which
    is the head, and which creates the file object and assigns it to the variable
    file. Then we create an indentation to indicate the body in which we define the
    applicable operations. As you can see in listing 11.2, we obtain the same output
    that we got in listing 11.1\. The most significant advantage of using the with
    statement is that we no longer need to close the file explicitly. When the with
    statement is complete, the file closes automatically:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 with 语句的语法是 with open("filepath") as file，这是头部，它创建文件对象并将其分配给变量 file。然后我们创建缩进来表示定义适用操作的主体。正如你在列表
    11.2 中看到的，我们获得了与列表 11.1 相同的输出。使用 with 语句的最大优点是我们不再需要显式关闭文件。当 with 语句完成后，文件会自动关闭：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The automatic closing of the file results from using the with statement, which
    is known as the context management technique. A context manager establishes a
    connection to the applicable resource object in the with statement’s head, and
    in the body, you manipulate the object. When you complete the body and exit the
    with statement, the context manager automatically closes the connection to the
    resource. For a file, the manager releases the file object. Figure 11.1 shows
    how a context manager works, using the file object as a concrete example.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 文件自动关闭是由于使用了with语句，这被称为上下文管理技术。上下文管理器在with语句的头部建立与适用资源对象的连接，在主体中，你操作这个对象。当你完成主体并退出with语句时，上下文管理器会自动关闭与资源的连接。对于一个文件，管理器会释放文件对象。图11.1展示了上下文管理器是如何工作的，使用文件对象作为具体示例。
- en: '![CH11_F01_Cui](../Images/CH11_F01_Cui.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F01_Cui](../Images/CH11_F01_Cui.png)'
- en: Figure 11.1 The flow of a context manager using file management as an example.
    The with statement consists of the head and the body. The head connects the resource,
    and the body uses the resource. When you exit the with statement, the context
    manager releases the resource.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 以文件管理为例的上下文管理器流程。with语句由头部和主体组成。头部连接资源，主体使用资源。当你退出with语句时，上下文管理器会释放资源。
- en: 11.1.2 Reading data from a file in different ways
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.2 以不同方式从文件中读取数据
- en: Listing 11.1 shows the read method, which obtains the entire text data. When
    the text file is large, it can take considerable time to load all the data, and
    sometimes, a computer may not have enough memory to hold that much data. Thus,
    we must use other ways to read data depending on specific use cases, as we’ll
    discuss in this section.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.1显示了read方法，它获取整个文本数据。当文本文件很大时，加载所有数据可能需要相当长的时间，有时，计算机可能没有足够的内存来存储这么多数据。因此，我们必须根据具体用例使用其他方式来读取数据，正如我们将在本节中讨论的那样。
- en: Reading lines as a generator
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 将行作为生成器读取
- en: In section 7.4, you learned about generators, which are memory-efficient data
    providers because they yield items individually upon request. A file object represents
    a stream of data, and we can use the file object as though it’s a generator, yielding
    each line of data one at a time.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在7.4节中，你学习了生成器，它们是内存高效的数据提供者，因为它们在请求时逐个产生项目。文件对象代表数据流，我们可以将文件对象当作生成器使用，一次产生一行数据。
- en: The most common way to process the file as a generator is to read the lines
    one by one using the for loop so that we process each line of data, as the next
    listing shows. To add some flavor to the file reading, I include some code that
    converts each line to an instance of the Task class.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的将文件作为生成器处理的方式是使用for循环逐行读取，这样我们就可以处理每一行数据，如下一个列表所示。为了给文件读取增添一些趣味，我包括了一些代码，将每一行转换为Task类的实例。
- en: Listing 11.3 Reading the file as a generator
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.3 以生成器读取文件
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Creates a named tuple class
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个命名元组类
- en: ❷ Removes the trailing line break
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 移除尾随的换行符
- en: ❸ Splits the string with commas
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用逗号分割字符串
- en: As you can see, we use the file as the iterator in the for loop, which yields
    each of the lines. Please note that each line ends with an “invisible” line break,
    and you should use strip to remove it. We use the split elements to create an
    instance of the Task class.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们在for循环中将文件用作迭代器，它产生每一行。请注意，每一行都结束于一个“不可见”的换行符，你应该使用strip来移除它。我们使用split元素来创建Task类的实例。
- en: QUESTION What happens if you don’t remove the line break?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：如果你不删除换行符会发生什么？
- en: Reading lines to form a list
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 将行读取以形成列表
- en: If the file doesn’t have too much data, we can read the lines to form a list
    object using the readlines method. Because list objects are mutable, it’ll be
    easier to change the data and save it for other purposes.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果文件数据不是太多，我们可以使用readlines方法读取行以形成一个列表对象。因为列表对象是可变的，这将更容易更改数据并保存以供其他用途。
- en: 'Suppose that we want to extract all the data from the text file tasks.txt as
    a list object, and we want to add a row number to each row. Here is the desired
    output:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要从文本文件tasks.txt中提取所有数据作为一个列表对象，并且我们想要给每一行添加行号。这是期望的输出：
- en: '[PRE7]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Because the expected output is a list object, we can take advantage of readlines
    to create a list object, which allows us to manipulate the data due to its mutability,
    as shown in the next listing.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 因为预期的输出是一个列表对象，我们可以利用readlines创建一个列表对象，这使我们能够由于其可变性来操作数据，如下一个列表所示。
- en: Listing 11.4 Reading the lines as a list
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.4 以列表形式读取行
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ enumerate creates a counter.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ enumerate创建一个计数器。
- en: We use the enumerate function (section 5.3.1) to create a counter for the iteration
    besides the item. Using list comprehension (section 5.2.1), we create the list
    object updated_lines, which matches the expected list object, desired_output.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用enumerate函数（第5.3.1节）为迭代创建一个计数器，除了项目之外。使用列表推导（第5.2.1节），我们创建了一个列表对象updated_lines，它与期望的列表对象desired_output相匹配。
- en: Reading a single line
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 读取单行
- en: In a rarer case, we may want to read a single line. We may want to read only
    the header of a file to find the columns of a CSV file, for example. (For more
    on processing CSV files, see section 11.2.) Although we can read all the lines
    and retrieve the first item, it can be time-consuming to read that much data.
    Instead, we can use the readline method to read the text in a single line, which
    costs less time than reading all the lines.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在更罕见的情况下，我们可能只想读取单行。例如，我们可能只想读取文件的标题以找到CSV文件的列。（有关处理CSV文件的更多信息，请参阅第11.2节。）虽然我们可以读取所有行并检索第一项，但读取这么多数据可能会很耗时。相反，我们可以使用readline方法读取单行文本，这比读取所有行要节省时间。
- en: Notably, we can use readline multiple times. The file object tracks where the
    reading ends every time (like a generator, a file object knows where the item
    is in the order), and the next time we call readline, it continues reading from
    where it left off, as shown in the following listing.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我们可以多次使用readline。文件对象跟踪每次读取结束的位置（就像生成器一样，文件对象知道项目在顺序中的位置），下一次我们调用readline时，它将从上次离开的地方继续读取，如下面的列表所示。
- en: Listing 11.5 Reading a single line
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.5 读取单行
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Prints the following empty line due to the line break
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 由于换行符而打印以下空行
- en: 'Notice three things in listing 11.5:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表11.5中注意以下三点：
- en: readline optionally takes a size argument, which reads up to the number of characters
    in that line. file.readline(5) reads 1003, for example, and file .readline(8)
    reads Grocery,.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: readline可选地接受一个大小参数，该参数读取该行中的字符数。例如，file.readline(5)读取1003，而file.readline(8)读取Grocery,.
- en: We obtain individual lines by calling readline multiple times.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过多次调用readline来获取单独的行。
- en: The line ends with a line break. When we call readline, it reads the entire
    line, including the line break; therefore, there are empty lines in the printout
    message.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行以换行符结束。当我们调用readline时，它会读取整行，包括换行符；因此，在打印消息中会有空行。
- en: Note Like readline, both read and readlines can take the size argument, which
    specifies how many characters to read from the file.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：与readline类似，read和readlines都可以接受大小参数，该参数指定从文件中读取多少个字符。
- en: 11.1.3 Writing data to a file in different ways
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.3 以不同方式将数据写入文件
- en: We read data from a file to process the stored data. When we’re done editing
    or have prepared data from another source, we need to write the data to a file
    for long-term preservation. This section describes common use scenarios in terms
    of writing data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从文件中读取数据以处理存储的数据。当我们完成编辑或从另一个来源准备数据后，我们需要将数据写入文件以进行长期保存。本节以写入数据的使用场景为例进行描述。
- en: Writing string data to a new file
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 将字符串数据写入新文件
- en: 'In many cases, we have our data ready and want to save it to a new file. Suppose
    that we have the following data:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，我们的数据已经准备好，并希望将其保存到新文件中。假设我们有以下数据：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To write this data to a new file, we can create a file object by using the with
    statement. Instead of creating an empty file ahead of time, we call the open function
    with the path for the new file, which creates the new file at the specified path,
    as the next listing shows.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 要将此数据写入新文件，我们可以通过使用with语句创建一个文件对象。我们不是提前创建一个空文件，而是使用带有新文件路径的open函数，如以下列表所示，在指定路径创建新文件。
- en: Listing 11.6 Writing to a new file
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.6 写入新文件
- en: '[PRE11]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Specifies the write mode
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 指定写入模式
- en: In the open function, besides the file path, we specify that the mode for this
    file object is "w", meaning that it’s write mode as opposed to read mode, which
    is the default. From the printout message, we see that the file object does have
    'w' mode. To write the string data to the new file, we call the write method.
    Calling this method returns the number of characters that have been written—in
    our case, 45.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在open函数中，除了文件路径外，我们指定该文件对象的模式为"w"，这意味着它是写入模式，而不是默认的读取模式。从打印消息中我们可以看到文件对象确实具有'w'模式。要将字符串数据写入新文件，我们调用write方法。调用此方法返回已写入的字符数——在我们的例子中是45。
- en: 'Specifying "w" mode for the file object is required for writing operations.
    If you open the file using the default read mode, you can’t write any data, as
    in the following example:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于写入操作，需要为文件对象指定"w"模式。如果你使用默认的读取模式打开文件，你将无法写入任何数据，如下例所示：
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ The default is read mode.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 默认是读取模式。
- en: Writing a list of lines to a new file
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 写入新文件中的行列表
- en: We’ve seen that we can read data from a file in the form of the lines as a list
    object. Not surprisingly, we can also write a list of lines to a file. The method
    involved is writelines. As you do when you write string data, you need to open
    a file with write mode enabled, as shown in the next listing.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，我们可以以行的形式将数据作为列表对象从文件中读取。不出所料，我们也可以将行列表写入文件。涉及的方法是writelines。正如你在写入字符串数据时所做的，你需要以写入模式打开一个文件，如下一列表所示。
- en: Listing 11.7 Writing a list to a file
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.7 向文件写入列表
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ writelines returns None.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ writelines返回None。
- en: 'If you open the tasks_list_write.txt file, you’ll notice that the data may
    not appear to be correct:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打开tasks_list_write.txt文件，你会注意到数据可能看起来不正确：
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This behavior is expected. writelines writes the data sequentially, there are
    no line breaks in any item of the data, and you shouldn’t expect the file to have
    multiple lines. Thus, you need to add line breaks to your data if you want to
    create a file with multiple lines, and I’ll leave that task as a challenge (section
    11.1.5).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这种行为是预期的。writelines按顺序写入数据，数据中的任何项都没有换行符，你不应该期望文件有多个行。因此，如果你想创建一个包含多行的文件，你需要给你的数据添加换行符，我将把这个任务留作挑战（第11.1.5节）。
- en: So far, we’ve seen how to read and write data in different ways by using a variety
    of methods, including read, write, readline, readlines, and writelines. To help
    differentiate them, figure 11.2 illustrates these operations.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了如何通过使用各种方法，包括read、write、readline、readlines和writelines，以不同的方式读取和写入数据。为了帮助区分它们，图11.2展示了这些操作。
- en: '![CH11_F02_Cui](../Images/CH11_F02_Cui.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F02_Cui](../Images/CH11_F02_Cui.png)'
- en: Figure 11.2 Key reading and writing functions with files. When you have data,
    you can write it to the file by using write and writelines. When you read the
    file, you can obtain the text data by calling read, readline, and readlines. These
    functions have different usages.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 文件的关键读取和写入函数。当你有数据时，你可以使用write和writelines将数据写入文件。当你读取文件时，你可以通过调用read、readline和readlines来获取文本数据。这些函数有不同的用法。
- en: As you may notice (or be curious about), the operations between reading and
    writing are almost symmetrical; the only exception is that there’s no writeline
    on the left side. There’s no need for one, however. When you want to write a line,
    use the write method.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如你可能注意到的（或者好奇的），读取和写入之间的操作几乎是对称的；唯一的例外是左侧没有writeline。然而，不需要它。当你想要写入一行时，使用write方法。
- en: Appending string data to an existing file
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 将字符串数据追加到现有文件中
- en: 'When you have new data, you want to append the data to an existing file. Suppose
    that you create a new task, which has the following data:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有新数据时，你想要将数据追加到现有文件中。假设你创建了一个新任务，其数据如下：
- en: '[PRE15]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: You want to write this data to the end of the tasks.txt file. Instead of enabling
    write mode, you should use append mode, as shown in the next listing.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你想要将此数据写入tasks.txt文件的末尾。而不是启用写入模式，你应该使用追加模式，如下一列表所示。
- en: Listing 11.8 Appending data to an existing file
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.8 向现有文件追加数据
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Adds a line break
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 添加换行符
- en: In the open function, specify "a" to open the file in append mode; the write
    method adds data to the end of the file. One thing to note is that the new_task
    is prefixed by a line break (\n) so that you can add the data as a new line instead
    of adding it to the last row of the file.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在open函数中指定"a"以追加模式打开文件；write方法将数据添加到文件末尾。需要注意的是，new_task前面有一个换行符（\n），这样你就可以将数据作为新行添加，而不是添加到文件的最后一行。
- en: The underlying mechanism for the append mode is that when we read or write,
    we’re using the cursor to determine the position of the operation. I’ve mentioned
    that a file object represents a stream of data and the cursor sets the position
    in the stream. Table 11.1 provides more information about the modes and their
    cursor positions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 追加模式的底层机制是，当我们读取或写入时，我们使用光标来确定操作的位置。我已经提到，文件对象代表数据流，光标设置流中的位置。表11.1提供了有关模式和它们的光标位置的更多信息。
- en: Table 11.1 File modes
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 表11.1 文件模式
- en: '| Mode¹ | read | write | create | truncate | Cursor position |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 模式¹ | read | write | create | truncate | 光标位置 |'
- en: '| r | * |  |  |  | Start |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 模式¹ | read | write | create | truncate | 光标位置 |'
- en: '| w |  | * | * | * | Start |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| w |  | * | * | * | 开始 |'
- en: '| a |  | * | * |  | End |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| a |  | * | * |  | 结束 |'
- en: '| r+ | * | * |  |  | Start |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| r+ | * | * |  |  | 开始 |'
- en: '| w+ | * | * | * | * | Start |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| w+ | * | * | * | * | 开始 |'
- en: '| a+ | * | * | * |  | End |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| a+ | * | * | * |  | 结束 |'
- en: '| x |  |  | * |  | Start |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| x |  |  | * |  | 开始 |'
- en: '(¹read: reads the data; write: writes new data; create: creates a new file;
    truncate: resizes the file; cursor position: when the operation starts.)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: (¹读取：读取数据；写入：写入新数据；创建：创建新文件；截断：调整文件大小；光标位置：操作开始时。)
- en: When we have mode "a" for the file, we have the cursor at the end, so the newly
    added text is appended to the end. For the most-used "r" and "w" modes, we have
    the cursor at the beginning, so the corresponding read and write operations start
    from the beginning.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们为文件设置模式"a"时，光标位于文件末尾，因此新添加的文本被附加到末尾。对于最常用的"r"和"w"模式，光标位于开始处，因此相应的读取和写入操作从开始处开始。
- en: 11.1.4 Discussion
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.4 讨论
- en: 'Using the with statement when you read and write files is the Pythonic way.
    The with statement is designed more for context management than for processing
    files. More broadly, we use a context manager when we deal with shared resources,
    such as a connection to a database. As section 14.3 discusses, when you work with
    a SQLite database, you can carry out database operations by using the connection
    under context management, as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在读写文件时使用with语句是Python的方式。with语句设计得更多的是用于上下文管理，而不是用于处理文件。更广泛地说，当我们处理共享资源，如数据库连接时，我们会使用上下文管理器。正如第14.3节所讨论的，当你与SQLite数据库一起工作时，你可以通过上下文管理下的连接执行数据库操作，如下所示：
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 11.1.5 Challenge
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.5 挑战
- en: In Leo’s daily job as an electrical engineer, he often needs to use Python to
    write data to files. One day, he tried to write a list object to a new file, as
    we did in listing 11.7\. But he found that the file only had one line instead
    of multiple lines, with each line representing an item of the list object. How
    can he change the list object so that the file has multiple lines?
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在Leo作为电气工程师的日常工作中，他经常需要使用Python将数据写入文件。有一天，他尝试将列表对象写入一个新文件，就像我们在列表11.7中所做的那样。但他发现文件只有一行，而不是多行，每行代表列表对象的一个项。他如何更改列表对象，以便文件有多个行？
- en: Hint You can append the line break to each item.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：你可以将换行符添加到每个项目。
- en: 11.2 How do I deal with tabulated data files?
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 我如何处理表格数据文件？
- en: Many people use Microsoft Excel to handle data files, and this data is referred
    to as *spreadsheets.* More generally, spreadsheets are known as *tabulated data,*
    which includes rows and columns. A company’s sales data can be saved as tabulated
    data. A school can record exam results as tabulated data. The collected data from
    a research project can be stored as tabulated data. As you can see, tabulated
    data has universal usage, so processing tabulated data is an essential data-handling
    skill. From a general perspective, you can convert tabulated data to CSV (comma-separated
    values) files to facilitate data exchange between different systems. This section
    focuses on processing CSV files—a representative format for tabulated data files.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人使用Microsoft Excel来处理数据文件，这些数据被称为*电子表格*。更普遍地，电子表格被称为*表格数据*，它包括行和列。公司的销售数据可以保存为表格数据。学校可以记录考试成绩为表格数据。研究项目收集的数据可以存储为表格数据。正如你所看到的，表格数据具有通用性，因此处理表格数据是数据处理的基本技能。从一般的角度来看，你可以将表格数据转换为CSV（逗号分隔值）文件，以促进不同系统之间的数据交换。本节重点介绍处理CSV文件——表格数据文件的代表性格式。
- en: 11.2.1 Reading a CSV file using csv reader
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.1 使用csv reader读取CSV文件
- en: 'As always, we start our data processing jobs by reading the data. For frontend
    applications, we need to read the data before we can display it. Suppose that
    our task management application uses a CSV file to store task-related data: the
    file tasks.txt (section 11.1). To show these tasks in our application, we need
    to know how to read a CSV file, as we’ll discuss in this section.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，我们通过读取数据开始我们的数据处理工作。对于前端应用，我们需要在显示数据之前读取数据。假设我们的任务管理应用使用CSV文件来存储任务相关数据：文件tasks.txt（第11.1节）。为了在我们的应用中显示这些任务，我们需要知道如何读取CSV文件，正如我们将在本节中讨论的。
- en: 'Although I didn’t specify it in section 11.1, the tasks.txt file is a CSV file.
    Thus, we’ve learned how to read a CSV file. But we had to split the string ourselves
    to obtain the stored data, which is a common operation in dealing with CSV files.
    Not surprisingly, the standard Python library provides a built-in solution for
    this purpose: the csv module, which allows us to read the data directly with a
    csv_reader, as the next listing shows.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我在 11.1 节中没有指定，但 tasks.txt 文件是一个 CSV 文件。因此，我们已经学会了如何读取 CSV 文件。但是，我们必须自己拆分字符串来获取存储的数据，这在处理
    CSV 文件时是一个常见的操作。不出所料，Python 的标准库为此提供了一个内置的解决方案：csv 模块，它允许我们直接使用 csv_reader 读取数据，如下面的列表所示。
- en: Listing 11.9 Reading a CSV file using the csv module
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.9 使用 csv 模块读取 CSV 文件
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Imports the module
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 导入模块
- en: ❷ You might see another line if you append data in section 11.1.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 如果你在 11.1 节中添加数据，你可能会看到另一行。
- en: Trivia The official Python documentation recommends specifying the newline character
    as “” to ensure cross-platform consistency in the way the system treats it. For
    more information, see [https://docs.python.org/3/library/csv.html](https://docs.python.org/3/library/csv.html).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 事实小贴士：官方 Python 文档建议将换行符指定为 ""，以确保跨平台一致性。更多信息请参阅 [https://docs.python.org/3/library/csv.html](https://docs.python.org/3/library/csv.html)。
- en: As shown in listing 11.9, we create the csv_reader by calling the reader function
    with the file object. The created csv_reader is an iterator, so we can iterate
    over the reader by using a for loop. Each item is a list object that consists
    of the values separated by commas—the same output that we obtained in listing
    11.5\. But we didn’t reinvent the wheel; we used the built-in csv module!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如列表 11.9 所示，我们通过调用带有文件对象的 reader 函数来创建 csv_reader。创建的 csv_reader 是一个迭代器，因此我们可以使用
    for 循环遍历读取器。每个项目是一个由逗号分隔的值组成的列表对象——这与我们在列表 11.5 中获得的结果相同。但我们并没有重新发明轮子；我们使用了内置的
    csv 模块！
- en: Reminder Don’t reinvent the wheel. Always use available solutions, particularly
    those provided by the standard library.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：不要重新发明轮子。始终使用可用的解决方案，尤其是标准库提供的解决方案。
- en: 'Notably, we know that list constructor can take an iterable to create a list
    object. Thus, we can call the list constructor to retrieve all the rows as a list
    object:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我们知道列表构造函数可以接受一个可迭代对象来创建一个列表对象。因此，我们可以调用列表构造函数来检索所有行作为列表对象：
- en: '[PRE19]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 11.2.2 Reading a CSV file that has a header
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.2 读取带有标题的 CSV 文件
- en: 'In the tasks.txt file, we only have three fields of data: the ID number, the
    title, and the urgency level. When your file has many fields, it’s hard to know
    which field keeps what data. Thus, to prevent any ambiguity, many CSV files use
    a header to mark each field. In this section, you’ll learn about reading a CSV
    file with a header. Suppose that we add the field names to the tasks.txt file,
    which has the following data:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在 tasks.txt 文件中，我们只有三个数据字段：ID 编号、标题和紧急程度。当你的文件有很多字段时，很难知道哪个字段保存了什么数据。因此，为了防止任何歧义，许多
    CSV 文件使用标题来标记每个字段。在本节中，你将学习如何使用带有标题的 CSV 文件。假设我们向 tasks.txt 文件添加字段名，该文件包含以下数据：
- en: '[PRE20]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you can see, the first row defines the three fields that map to each value
    in subsequent rows. When you have a CSV file with a header, the best approach
    is to read each row as a dict object, with the header’s field names becoming the
    keys, as the next listing shows.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，第一行定义了映射到后续行中每个值的三个字段。当你有一个带有标题的 CSV 文件时，最佳做法是将每一行读取为字典对象，其中标题的字段名成为键，如下面的列表所示。
- en: Listing 11.10 Reading a CSV file with a header using the csv_reader
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.10 使用 csv_reader 读取带有标题的 CSV 文件
- en: '[PRE21]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Obtains the next item
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取下一个项目
- en: ❷ Creates a dict object
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建一个字典对象
- en: 'As a refresher on several techniques that I’ve covered previously, here are
    the highlights of listing 11.10:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对之前介绍的一些技术的复习，以下是列表 11.10 的要点：
- en: Because the csv_reader is an iterator (section 5.1), we can call the next function
    on it to obtain the first row’s data.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为 csv_reader 是一个迭代器（第 5.1 节），我们可以调用 next 函数来获取第一行数据。
- en: When we consume the first item of the iterator, the iteration continues with
    the second item. In the for loop, the csv_reader yields items starting from the
    second row.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们消费迭代器的第一个项目时，迭代会继续到第二个项目。在 for 循环中，csv_reader 从第二行开始产生项目。
- en: The dict constructor takes an iterable, with each element having two items.
    We use the zip function to create a zip object by joining fields and row. The
    output reveals that we obtain three dict objects that correspond to the data in
    the CSV file.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字典构造函数接受一个可迭代对象，其中每个元素有两个项目。我们使用zip函数通过连接字段和行来创建一个zip对象。输出显示我们获得了三个与CSV文件中的数据相对应的字典对象。
- en: As you may notice, it’s not intuitive to read the first row separately and construct
    the needed data. But CSV files with a header are so common that an easier solution
    must exist. Indeed, the csv module provides an additional reader—DictReader—that
    specifically addresses this need, as shown in the next listing.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所注意到的，单独读取第一行并构建所需数据并不直观。但是，带标题的CSV文件如此常见，必须存在一个更简单的解决方案。确实，csv模块提供了一个额外的reader——DictReader，它专门针对这个需求，如下所示。
- en: Listing 11.11 Reading a CSV file with a header using DictReader
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.11 使用DictReader读取带标题的CSV文件
- en: '[PRE22]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Instead of calling the reader function, we call the DictReader constructor to
    create a DictReader object that takes the first row as the keys. As you can see,
    the solution in listing 11.11 is much cleaner than the one in listing 11.10, which
    highlights the conciseness of Python code if you use the right technique. As a
    side note to facilitate your learning process, if you find common problems on
    your daily job, chances are that Python already has solutions for them, and you
    only need to locate them! In my experience, you can start your search on Google
    with the phrase “Python + your job at hand.” If you want to read PDF files with
    Python, for example, you can search “Python read pdf files.” Usually, the first
    few pages of search results should be sufficient for you to find the potential
    solution.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 而不是调用reader函数，我们调用DictReader构造函数来创建一个DictReader对象，该对象以第一行作为键。正如你所看到的，列表11.11中的解决方案比列表11.10中的解决方案要简洁得多，这突出了如果你使用正确的技术，Python代码的简洁性。作为学习过程中的一个旁注，如果你在日常工作中遇到常见问题，那么Python可能已经有了针对这些问题的解决方案，你只需要找到它们！根据我的经验，你可以在Google上用“Python
    + 你手头的任务”这个短语开始搜索。例如，如果你想用Python读取PDF文件，你可以搜索“Python read pdf files”。通常，搜索结果的前几页应该足以你找到潜在解决方案。
- en: QUESTION As csv_reader is an iterator, how can you retrieve all the data as
    a list object that consists of these dict objects?
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：由于csv_reader是一个迭代器，你如何检索所有数据作为一个由这些字典对象组成的列表？
- en: 11.2.3 Writing data to a CSV file
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.3 向CSV文件写入数据
- en: 'After we have processed our data, it’s time to save that data back to a CSV
    file. reader and DictReader have counterpart writers: writer and DictWriter. As
    you can imagine, writer writes a list object, and DictWriter writes a dict object.
    This section shows how. Because the writers are straightforward, this section
    is short.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们处理完数据后，是时候将数据保存回CSV文件了。reader和DictReader有对应的writer：writer和DictWriter。正如你所想象的，writer写入一个列表对象，而DictWriter写入一个字典对象。本节将展示如何进行。因为writer很简单，所以本节很短。
- en: 'Suppose that we want to add the row 1004,Museum,3 to the CSV file. With a writer,
    we need to convert this string to a list object:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要将行1004,Museum,3添加到CSV文件中。使用writer，我们需要将这个字符串转换为列表对象：
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Creates a list to write using split
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用split创建一个用于写入的列表
- en: 'As with writing data to a regular text file, if we know that the last line
    of data doesn’t end with a line break, we should add a line break: file.write("\n").'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 就像向常规文本文件写入数据一样，如果我们知道数据的最后一行不以换行符结束，我们应该添加一个换行符：file.write("\n")。
- en: Reminder The file mode should be "a"—append mode. If you use "w", all the existing
    data will be erased.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：文件模式应该是“a”——追加模式。如果你使用“w”，所有现有数据将被删除。
- en: 'Sometimes, data is processed in the form of dict objects. Suppose that we want
    to save the following data to a new CSV file:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，数据以字典对象的形式进行处理。假设我们想要将以下数据保存到一个新的CSV文件中：
- en: '[PRE24]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The data is a list object that consists of multiple dict objects. In this case,
    we should use DictWriter, as shown in the following listing.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是一个由多个字典对象组成的列表。在这种情况下，我们应该使用DictWriter，如下所示。
- en: Listing 11.12 Writing data to a CSV using DictWriter
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.12 使用DictWriter向CSV写入数据
- en: '[PRE25]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: ❶ Writes the header
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 写入标题
- en: ❷ Writes multiple rows
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 写入多行
- en: 'Three things are worth noting in listing 11.12:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.12中有三件事值得注意：
- en: When we create an instance of DictWriter, we need to specify the field names
    by setting the fieldnames argument.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们创建DictWriter的实例时，我们需要通过设置fieldnames参数来指定字段名。
- en: We call the writeheader method to write the header.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们调用writeheader方法来写入标题。
- en: Because we have the dict objects as a list object, we can write the entire dataset
    by calling the writerows method instead of the writerow method, which writes only
    one row.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为我们有一个列表对象作为dict对象，我们可以通过调用writerows方法来写入整个数据集，而不是调用writerow方法，后者只写入一行。
- en: 'So far, I’ve covered how to read and write data with a CSV file. As you may
    realize, reading and writing data involves symmetrical operations: reader versus
    writer and DictReader versus DictWriter. Figure 11.3 provides a visual summary
    of these operations. If you work with lists, you should choose reader and writer.
    If you work with dictionaries, you should choose DictReader and DictWriter. Another
    factor to consider is whether the CSV file uses a header; if it does, operations
    are easier with DictReader and DictWriter.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我已经介绍了如何使用CSV文件读取和写入数据。你可能已经意识到，读取和写入数据涉及对称操作：读取器与写入器，以及DictReader与DictWriter。图11.3提供了这些操作的视觉总结。如果你使用列表，你应该选择读取器和写入器。如果你使用字典，你应该选择DictReader和DictWriter。另一个需要考虑的因素是CSV文件是否使用标题；如果使用，DictReader和DictWriter的操作会更简单。
- en: '![CH11_F03_Cui](../Images/CH11_F03_Cui.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F03_Cui](../Images/CH11_F03_Cui.png)'
- en: Figure 11.3 Reading and writing operations using the csv module. Reading operations
    involve reader and DictReader, with the former reading each row as a list and
    the latter reading it as a dict. Writing operations involve writer and DictWriter,
    with the former writing a list to a row and the latter writing a dict.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3展示了使用csv模块的读取和写入操作。读取操作涉及读取器和DictReader，前者将每一行读取为列表，后者将每一行读取为字典。写入操作涉及写入器和DictWriter，前者将列表写入一行，后者将字典写入一行。
- en: 11.2.4 Discussion
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.4 讨论
- en: Tabulated data can be converted to CSV format. Using the built-in csv module,
    we have the capability to process CSV data conveniently, including reading and
    writing data. We need to be familiar with these two-way operations. Notably, if
    we need to perform numeric operations with the CSV data, we need to explore third-party
    libraries, such as pandas, for advanced processing functions. These packages can
    read CSV files with a simple function call. We can call pandas.read_csv("filepath.csv"),
    for example, to create a DataFrame (a tabulated data model) from a CSV file so
    that we can use this DataFrame for a variety of operations.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 表格数据可以转换为CSV格式。使用内置的csv模块，我们可以方便地处理CSV数据，包括读取和写入数据。我们需要熟悉这些双向操作。值得注意的是，如果我们需要对CSV数据进行数值运算，我们需要探索第三方库，如pandas，以获取高级处理功能。这些包可以通过简单的函数调用读取CSV文件。例如，我们可以调用pandas.read_csv("filepath.csv")来从CSV文件创建一个DataFrame（表格数据模型），这样我们就可以使用这个DataFrame进行各种操作。
- en: 11.2.5 Challenge
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.5 挑战
- en: Leo uses CSV files to store some experimental results for his electrical engineering
    work. For one project, he called the writerows method with a DictWriter to write
    a list object that consists of multiple dict objects, as in listing 11.12\. How
    can he use this method with a regular CSV writer to write multiple list objects?
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 利奥使用CSV文件存储他电气工程工作中的一些实验结果。在一个项目中，他使用DictWriter调用writerows方法来写入一个由多个dict对象组成的列表对象，如列表11.12所示。他如何使用这个方法与常规CSV写入器一起写入多个列表对象？
- en: 'Hint You need to organize your data in a list object, with each item representing
    the data for a row:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：你需要将你的数据组织成一个列表对象，其中每个项目代表一行数据：
- en: '[PRE26]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 11.3 How do I preserve data as files using pickling?
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 如何使用序列化将数据保存为文件？
- en: During the execution of our programs, our code generates hundreds of objects.
    When data scientists prepare data, they perform multiple processing steps and
    create a considerable amount of data. Some data is large—hundreds of megabytes
    or even gigabytes—and it can take a long time to rerun the code to generate the
    data. It would be nice to store the data permanently in the form of files on a
    computer.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们程序的执行过程中，我们的代码会生成数百个对象。当数据科学家准备数据时，他们会执行多个处理步骤并创建大量数据。一些数据很大——几百兆字节甚至几吉字节——重新运行代码生成数据可能需要很长时间。将数据永久存储在计算机上的文件形式会更好。
- en: In section 11.2, we studied how to write tabulated data to files. But our data
    can be in other forms, such as dict, list, and tuple, as well as classes and functions.
    Thus, we should have a more general mechanism to preserve data. In this section,
    you’ll learn about pickling, which allows us to preserve various forms of Python
    data.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在11.2节中，我们学习了如何将表格数据写入文件。但我们的数据可以以其他形式存在，例如dict、list、tuple，以及类和函数。因此，我们应该有一个更通用的机制来保存数据。在本节中，你将了解序列化，它允许我们保存各种形式的Python数据。
- en: 11.3.1 Pickling objects for data preservation
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.1 使用序列化对象进行数据保存
- en: The terms *pickle* and *pickling* come from the preservation of food by using
    vinegar, brine, or similar solutions. In Python, *pickling* refers to the process
    of converting objects to a binary format for data preservation. When a normal
    program stops, the data may be lost, which can be undesirable. Some data requires
    excessive time to process, and we want to preserve data so that we can retrieve
    it conveniently later. In this section, we’ll see how to preserve data with the
    built-in pickle module.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 术语 *pickle* 和 *pickling* 来自于使用醋、盐水或类似溶液保存食物的过程。在 Python 中，*pickling* 指的是将对象转换为二进制格式以进行数据保存的过程。当正常程序停止时，数据可能会丢失，这可能是我们不希望的。有些数据需要处理过多的时间，我们希望保存数据以便以后方便地检索。在本节中，我们将了解如何使用内置的
    pickle 模块来保存数据。
- en: Concept *Pickling* is the process of creating a binary format from existing
    objects for data preservation.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 概念 *Pickling* 是从现有对象创建二进制格式以进行数据保存的过程。
- en: 'We can pickle almost any object in Python. Suppose that we use different forms
    of data to store a task’s information in our task management application. Let’s
    see how we can pickle these objects:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 Python 中几乎保存任何对象。假设我们使用不同的数据形式在我们的任务管理应用程序中存储任务信息。让我们看看我们如何可以 pickling
    这些对象：
- en: '[PRE27]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ Imports the module
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 导入模块
- en: In this code snippet, we create one tuple and one dict object for pickling.
    I want to emphasize two key points.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们创建了一个元组和一个字典对象以进行 pickling。我想强调两个关键点。
- en: '*The* dump *function* *saves the data to a file.* When we work with a file,
    we use the open function to create a file object so that we establish a connection
    to the pertinent file.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*dump 函数* *将数据保存到文件中*。当我们与文件一起工作时，我们使用 open 函数创建一个文件对象，以便我们与相关文件建立连接。'
- en: '*When we open the file, we should use* "wb" *mode*. This mode means that we’re
    performing writing operations and that the file should be in binary format. By
    contrast, when we deal with text files, we don’t need to worry about specifying
    the mode, as we use the default mode: "t" for "text".'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*当我们打开文件时，我们应该使用* "wb" *模式*。这种模式意味着我们正在进行写入操作，并且文件应该是二进制格式。相比之下，当我们处理文本文件时，我们不需要担心指定模式，因为我们使用默认模式："t"
    代表 "text"。'
- en: 'After running the code, your current directory has two new files: task_tuple_saved
    .pickle and task_dict_saved.pickle. If you want to open them with a text editor,
    you won’t see anything meaningful. Likewise, when you try to open an image with
    a text editor, you’ll see some readable content mixed with meaningless text because
    of the binary format. How can you use the data saved in the pickle files? The
    next section explains.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码后，你的当前目录中有两个新文件：task_tuple_saved .pickle 和 task_dict_saved.pickle。如果你想要用文本编辑器打开它们，你将看不到任何有意义的内容。同样，当你尝试用文本编辑器打开一个图片时，你会看到一些可读内容与无意义的文本混合，这是因为二进制格式。你如何使用
    pickle 文件中保存的数据？下一节将解释。
- en: 11.3.2 Restoring data by unpickling
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.2 通过 unpickling 恢复数据
- en: We pickle objects to preserve them as a file via a process known as pickling.
    Later, when we need the data again, we retrieve data from a pickle file—the opposite
    process to pickling, called *unpickling.* In this section, you’ll learn about
    restoring data by unpickling.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过一个称为 pickling 的过程将对象保存为文件以进行保存。稍后，当我们再次需要数据时，我们从 pickle 文件中检索数据——与 pickling
    相反的过程，称为 *unpickling*。在本节中，你将学习如何通过 unpickling 来恢复数据。
- en: 'When we discussed JavaScript Object Notation (JSON) data serialization (section
    9.3), we used dump to create a JSON file, which has the same calling signature
    as dump for pickling. When we read JSON files, we used the load function. As you
    may expect, unpickling also uses load:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论 JavaScript 对象表示法 (JSON) 数据序列化（第 9.3 节）时，我们使用了 dump 来创建 JSON 文件，它与 pickling
    的 dump 函数具有相同的调用签名。当我们读取 JSON 文件时，我们使用了 load 函数。正如你所期望的，unpickling 也使用 load：
- en: '[PRE28]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Unpickling requires that we open the file in read mode. Remember that pickle
    files are binary, so we need to use "rb" as the open mode. Unlike the dump function,
    which returns None, we expect to obtain the data by calling the load function
    on the file object. Thus, we assign the return value to a variable.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Unpickling 需要我们以读取模式打开文件。记住，pickle 文件是二进制的，因此我们需要使用 "rb" 作为打开模式。与返回 None 的 dump
    函数不同，我们期望通过在文件对象上调用 load 函数来获取数据。因此，我们将返回值赋给一个变量。
- en: 'To check the fidelity of data preservation, we can compare the unpickled data
    with the original objects. The restored objects are equal to the original ones.
    This fidelity is important, as we’re assured that we can recreate the original
    data after pickling:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查数据保存的保真度，我们可以将 unpickled 数据与原始对象进行比较。恢复的对象与原始对象相等。这种保真度很重要，因为我们确信在 pickling
    后可以重新创建原始数据：
- en: '[PRE29]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Can we pickle the instance objects of custom classes too? The answer is yes.
    Consider the following example:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否也可以序列化自定义类的实例对象？答案是肯定的。考虑以下示例：
- en: '[PRE30]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In this code snippet, we pickle and unpickle an instance object of the Task
    class, and the original object and the pickled/unpickled object have the same
    attributes, as revealed by the comparison of their dictionary representations.
    Notably, they’re not the same object, as revealed by the identity comparison (is
    not).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码片段中，我们序列化和反序列化 Task 类的实例对象，原始对象和序列化/反序列化对象具有相同的属性，这通过它们字典表示形式的比较得到揭示。值得注意的是，它们不是同一个对象，如通过身份比较（is
    not）所示。
- en: 'Although we can pickle instances of custom classes, we should pay extra attention
    to them. The reason is that for built-in classes, when you unpickle these objects,
    Python knows how to unpickle them because their types are known. By contrast,
    Python may not know your custom classes if you haven’t defined them when you unpickle.
    That is, if you unpickle an instance object (in our case, an instance of the Task
    class), you’ll encounter an error when the namespace doesn’t have the Task class.
    Consider the following example:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以序列化自定义类的实例，但我们应特别注意它们。原因是对于内置类，当你反序列化这些对象时，Python 知道如何反序列化它们，因为它们的类型是已知的。相比之下，如果你在反序列化时没有定义它们，Python
    可能不知道你的自定义类。也就是说，如果你反序列化一个实例对象（在我们的例子中，是 Task 类的实例），当命名空间中没有 Task 类时，你会遇到错误。考虑以下示例：
- en: '[PRE31]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: ❶ Removes Task from the global namespace
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从全局命名空间中删除 Task
- en: To mimic a situation in which you unpickle an instance when its class is not
    defined, we remove the Task class from the global namespace by running del Task.
    After that, we can’t obtain the custom instance, as it can’t find the Task class
    for instantiation.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟在实例的类未定义时反序列化实例的情况，我们通过运行 del Task 来从全局命名空间中删除 Task 类。之后，我们无法获取自定义实例，因为它找不到
    Task 类来进行实例化。
- en: Maintainability When you unpickle instances of a custom class, make sure that
    you’ve defined the class in the corresponding namespace.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 可维护性 当你反序列化自定义类的实例时，请确保你在相应的命名空间中已定义了该类。
- en: 'When you learned about JSON data conversion, you learned that dump and load
    are for manipulating JSON files, and dumps and loads are for dealing with JSON
    strings. Pickling has counterpart functions with the same names: dump and load
    for pickle files, and dumps and loads for pickle strings in binary form (known
    as bytes; see listing 11.13), as depicted in figure 11.4.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 当你学习关于 JSON 数据转换时，你了解到 dump 和 load 用于操作 JSON 文件，而 dumps 和 loads 用于处理 JSON 字符串。序列化有对应的同名函数：dump
    和 load 用于 pickle 文件，而 dumps 和 loads 用于二进制形式的 pickle 字符串（称为字节；参见列表 11.13），如图 11.4
    所示。
- en: '![CH11_F04_Cui](../Images/CH11_F04_Cui.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F04_Cui](../Images/CH11_F04_Cui.png)'
- en: Figure 11.4 Pickling and unpickling in the forms of strings and files. In pickling,
    you call dumps to create a binary string and dump to create a binary file. In
    unpickling, you call loads to create an object from a binary string and load to
    create an object from a binary file.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 以字符串和文件形式展示的序列化和反序列化。在序列化中，你调用 dumps 来创建二进制字符串，调用 dump 来创建二进制文件。在反序列化中，你调用
    loads 从二进制字符串创建对象，调用 load 从二进制文件创建对象。
- en: The preceding examples focus on pickle files, and you’ll see some examples of
    pickle-related binary strings in the next section.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 之前示例主要关注 pickle 文件，你将在下一节看到一些与 pickle 相关的二进制字符串的示例。
- en: 11.3.3 Weighing the pros and cons of pickling
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.3 序列化的利弊权衡
- en: We’ve seen how pickling and unpickling work for data preservation. It’s important
    to know the pros and cons of pickling. This section reviews the most important
    aspects of pickling, which will help us determine whether pickling is the right
    choice for data preservation in our project.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了序列化和反序列化在数据保存方面的作用。了解序列化的优缺点很重要。本节回顾了序列化最重要的方面，这将帮助我们确定序列化是否是我们项目中数据保存的正确选择。
- en: Compatibility with most objects
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数对象兼容
- en: As another common storage and data exchange mechanism, JSON is compatible with
    the built-in data types, but it doesn’t work with custom classes unless we provide
    specific JSON serialization instructions, such as by setting the default argument
    in calling dump or dumps (section 9.3). Moreover, JSON can’t natively handle all
    objects, such as functions. By contrast, pickling is compatible with many more
    kinds of objects out of the box. To see pickling’s flexibility, observe an example
    of preserving a simple function in the next listing.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一种常见的存储和数据交换机制，JSON与内置数据类型兼容，但除非我们提供特定的JSON序列化指令，例如通过在调用dump或dumps时设置默认参数（第9.3节），否则它不适用于自定义类。此外，JSON无法原生处理所有对象，例如函数。相比之下，序列化与许多更多类型的对象直接兼容。为了了解序列化的灵活性，请观察下一个列表中保存简单函数的示例。
- en: Listing 11.13 Pickling a function to bytes
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.13 序列化函数到字节
- en: '[PRE32]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As shown in this code, we pickle the function doubler as bytes data, which
    resumes the look of a string but starts with b to denote that it’s a bytes object.
    We can unpickle this bytes object to reconstruct the function, which should do
    the same job as doubler:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如此代码所示，我们将函数doubler序列化为字节数据，它看起来像字符串，但以b开头表示它是一个字节对象。我们可以反序列化这个字节对象来重建函数，它应该与doubler执行相同的任务：
- en: '[PRE33]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We’ve seen that pickling works with custom classes without any specific instructions
    (see listing 11.14), unlike JSON serialization, which requires special instruction
    for encoding instances (section 9.3). But pickling doesn’t work with every object
    in Python. We can’t pickle a module, for example:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，序列化与自定义类兼容，无需任何特定指令（参见列表11.14），这与需要特殊指令进行编码实例的JSON序列化不同（第9.3节）。但是，序列化并不是与Python中的每个对象都兼容。例如，我们不能序列化一个模块：
- en: '[PRE34]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Also, we can’t also pickle file objects and connections to databases, as they
    use resources in a dynamic manner, which pickling can’t handle. Except for these
    limitations, pickling works with most kinds of objects, serving as a versatile
    mechanism for data preservation.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们也不能将文件对象和数据库连接进行序列化，因为它们以动态方式使用资源，而序列化无法处理这种动态性。除了这些限制，序列化与大多数类型的对象兼容，作为一种灵活的数据保存机制。
- en: Data security
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 数据安全
- en: When we deal with any data, the first factor we may fail to consider is data
    security. When we obtain files, we should wonder whether they are safe. The same
    principle applies to pickle files; we should be cautious about pickled data’s
    security.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们处理任何数据时，我们可能首先没有考虑到的因素是数据安全。当我们获取文件时，我们应该考虑它们是否安全。同样的原则也适用于序列化文件；我们应该对序列化数据的安全性保持谨慎。
- en: 'Because pickling allows us to preserve almost any object, hackers have the
    opportunity to embed malicious code inside an object. In sections 11.3.1 and 11.3.2,
    we’ve seen how pickling works with built-in data types, such as tuple and dict.
    You can’t do much with these built-in data types. If someone creates a custom
    class, however, they can define customized behaviors that can hack the pickling
    system. Consider the following example:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 由于序列化允许我们保存几乎任何对象，黑客有机会在对象中嵌入恶意代码。在第11.3.1节和11.3.2节中，我们已经看到了序列化如何与内置数据类型（如元组和字典）一起工作。对于这些内置数据类型，你无法做太多。然而，如果有人创建了一个自定义类，他们可以定义自定义行为，这些行为可以黑客化序列化系统。考虑以下示例：
- en: '[PRE35]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: ❶ Creates one-item tuple
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个单元素元组
- en: In this code snippet, someone defines the class MaliciousTask. This class has
    implemented the special method __reduce__, which is involved in the pickling process.
    The return value, if run, results in creating the hacking.txt file on your computer.
    The file is empty, but it can be programmed to contain malicious code that will
    damage your computer system!
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，有人定义了一个名为MaliciousTask的类。这个类实现了与序列化过程相关的特殊方法__reduce__。如果运行返回值，会在你的计算机上创建hacking.txt文件。这个文件是空的，但它可以被编程包含会损害你的计算机系统的恶意代码！
- en: If you’re not paying attention to this malicious source code and trying to unpickle
    an instance of this class, your computer can become vulnerable because of the
    added file from calling __reduce__. The next listing shows this effect.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有注意到这个恶意源代码，并试图反序列化这个类的实例，你的计算机可能会因为调用__reduce__时添加的文件而变得脆弱。下一个列表显示了这种效果。
- en: Listing 11.14 Pickling an instance of a custom class
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.14 序列化自定义类的实例
- en: '[PRE36]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Note that I included the output "__reduce__ is called" to show you that __reduce__
    is involved in pickling. The command for creating a potentially malicious file
    is part of the pickle file. When you unpickle this kind of file, the following
    problem arises:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我包括了输出"__reduce__被调用"，以显示__reduce__在pickle过程中是涉及的。创建可能恶意文件的命令是pickle文件的一部分。当你反pickle这类文件时，会出现以下问题：
- en: '[PRE37]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: After unpickling the file, if you check your directory, you’ll see that the
    file hacking .txt sneakily shows up! Real malicious code won’t leave such apparent
    traces, however. Thus, you should be cautious when you try to pickle and unpickle
    objects. The rule of thumb is to pickle only objects that come from trusted sources,
    such as the built-in ones, classes that you created yourself, or reputable third-party
    packages.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 反pickle文件后，如果你检查你的目录，你会看到文件hacking.txt偷偷出现！真正的恶意代码不会留下如此明显的痕迹。因此，当你尝试pickle和unpickle对象时，你应该小心。一般来说，只pickle来自可信来源的对象，例如内置的，你自己创建的类，或者信誉良好的第三方包。
- en: Storage size and speed
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 存储大小和速度
- en: Another advantage of pickling is its smaller storage size and faster reading/writing
    speed compared with text-based storage, such as CSV format. I’ve mentioned several
    times that pandas is one of the most prevalent Python packages for data science.
    Its core data model is known as DataFrame, which is a tabulated data structure.
    You can save DataFrame objects as CSV files or pickle files. In general, using
    pickle files to read and write data is much faster than using CSV files, and pickle
    files tend to be smaller than CSV files for storing the same amount of data.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个优点是，与基于文本的存储（如CSV格式）相比，pickle的存储空间更小，读写速度更快。我多次提到，pandas是Python数据科学中最常用的包之一。它的核心数据模型被称为DataFrame，它是一种表格数据结构。您可以将DataFrame对象保存为CSV文件或pickle文件。一般来说，使用pickle文件读写数据比使用CSV文件快得多，并且对于存储相同数量的数据，pickle文件通常比CSV文件小。
- en: 11.3.4 Discussion
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.4 讨论
- en: Pickling is a convenient storage mechanism that is compatible with most kinds
    of Python objects, including custom classes. There are pros and cons to using
    pickles, of course. The rule of thumb is that if you work on data-related projects,
    pickles can be a great choice, providing faster reading/writing speed than CSV
    files. As a reminder, be cautious about the security vulnerability of pickling
    data from untrusted sources.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Pickle是一种方便的存储机制，与大多数Python对象兼容，包括自定义类。当然，使用pickle有优点也有缺点。一般来说，如果你从事与数据相关的项目，pickle可以是一个很好的选择，因为它比CSV文件提供了更快的读写速度。作为提醒，请小心处理来自不可信来源的pickle数据的安全漏洞。
- en: 11.3.5 Challenge
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.5 挑战
- en: As a cybersecurity analyst in a hospital, Roger evaluates security associated
    with the pickling technique in Python. He tried to pickle an instance of the MaliciousTask
    class that adds a file (hacking.txt) to the current working directory, as we did
    in listing 11.14\. How can he modify the class to make it remove the hacking.txt
    file during pickling?
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一家医院的网络安全分析师，Roger评估了Python中pickle技术的安全性。他尝试将MaliciousTask类的实例（如列表11.14中所示）进行pickle，向当前工作目录添加一个文件（hacking.txt）。他如何修改这个类，使其在pickle过程中删除hacking.txt文件？
- en: Hint We used the command touch hacking.txt to create this file. We can use the
    command rm hacking.txt to remove this file. Don’t forget where you should place
    this command.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：我们使用touch hacking.txt命令创建了这个文件。我们可以使用rm hacking.txt命令删除这个文件。别忘了放置这个命令的位置。
- en: 11.4 How do I manage files on my computer?
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.4 如何管理计算机上的文件？
- en: No matter what projects you’re working on, it’s inevitable that you’ll deal
    with files. After all, files are the most versatile containers for storing organized
    information. In the preceding sections, you learned about reading data from files
    and writing data to files. But you haven’t learned anything about manipulating
    files in their entirety (not concerned with the content, but the files themselves),
    as well as manipulating directories, such as by moving and copying files.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你在做什么项目，你不可避免地会处理文件。毕竟，文件是存储组织化信息的最灵活的容器。在前面的章节中，你学习了从文件中读取数据以及将数据写入文件。但你还没有学习如何完全操作文件（不关心内容，而是文件本身），以及如何操作目录，例如通过移动和复制文件。
- en: 'Consider the following use scenario. Suppose that you’re conducting a scientific
    experiment in which each participant completes a reaction time test. This test
    consists of multiple trials, and after the test is run, the software generates
    several files. Because we run the experiment with multiple subjects, the data
    directory has the following files:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下使用场景。假设你正在进行一项科学实验，其中每个参与者完成一个反应时间测试。这个测试包括多个试验，测试运行后，软件会生成几个文件。因为我们用多个受试者进行实验，数据目录中有以下文件：
- en: '[PRE38]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We are concerned about the files of a specific type. Specifically, when we’re
    done with the data collection, how can we extract only those data files (.dat)
    and move them to a new directory? We also want to delete the text files (.txt)
    because we don’t need them.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关注特定类型的文件。具体来说，当我们完成数据收集后，我们如何提取仅包含这些数据文件（.dat）并将它们移动到新目录中？我们还想删除文本文件（.txt），因为我们不需要它们。
- en: In this section, we’ll address these needs and common file-handling techniques.
    Please note that Python is a general-purpose language, and when it comes to file
    handling, there can be multiple solutions involving different libraries, such
    as os and pathlib. I’ll focus on the generalizable ones.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将解决这些需求并介绍常见的文件处理技术。请注意，Python是一种通用语言，在文件处理方面，可能会有多种解决方案，涉及不同的库，如os和pathlib。我将专注于可通用的解决方案。
- en: 11.4.1 Creating a directory and files
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.1 创建目录和文件
- en: 'To follow along with the entire section, you’ll start by learning how to create
    a new directory and a bunch of mock files. When you deal with file paths or directory
    paths, if you’ve been using the os module, I recommend that you use the pathlib
    module instead; it’s a more compact module that specializes in handling paths.
    Using pathlib, you can easily make a new directory:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟随整个章节，你将首先学习如何创建一个新的目录和一系列模拟文件。当你处理文件路径或目录路径时，如果你一直在使用os模块，我建议你使用pathlib模块；这是一个更紧凑的模块，专门用于处理路径。使用pathlib，你可以轻松地创建一个新目录：
- en: '[PRE39]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: ❶ Makes a directory
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建目录
- en: 'The central data model in the pathlib is Path, a class designated for path-related
    operations. To make a directory using the Path object, for example, call the mkdir
    method, which creates the data folder in your current directory. You can check
    its existence programmatically by calling exists:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: pathlib的核心数据模型是Path，这是一个用于路径相关操作的类。例如，要使用Path对象创建目录，可以调用mkdir方法，这将在你的当前目录中创建数据文件夹。你可以通过调用exists来程序化地检查其存在性：
- en: '[PRE40]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'When you have the folder ready, you can create a bunch of mock files, and you’ll
    use these files for manipulation later in this section:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 当你准备好文件夹后，你可以创建一些模拟文件，你将在本节后面的内容中使用这些文件进行操作：
- en: '[PRE41]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: ❶ Creates a file path
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建文件路径
- en: 'For now, you should know how to create a file with some data by using the open
    function in a with statement (section 11.1). One thing to note is that you construct
    a file path by using the operation directory_path / filename. You may know that
    Windows and macOS use different symbols (backslash versus forward slash) to separate
    the levels in a directory: data\subject_123.dat vs. data/subject_123.dat. When
    you create a filepath using directory_path / filename, this operation is operating
    system agnostic, meaning that the same code can run on either of these platforms.
    If you arbitrarily create the path—say, data\subject_123.dat—your code may not
    run on a different system. This cross-platform compatibility is another advantage
    of using pathlib instead of the os module (in which you may have to use the raw
    strings as paths), which is platform dependent.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，你应该知道如何通过在with语句中使用open函数创建一个包含数据的文件（第11.1节）。需要注意的是，你通过使用操作目录_path / 文件名来构造文件路径。你可能知道Windows和macOS使用不同的符号（反斜杠与正斜杠）来分隔目录中的层级：data\subject_123.dat与data/subject_123.dat。当你使用目录_path
    / 文件名创建文件路径时，这个操作是操作系统无关的，这意味着相同的代码可以在这些平台上的任何一个上运行。如果你随意创建路径——比如说，data\subject_123.dat——你的代码可能在不同的系统上无法运行。这种跨平台兼容性是使用pathlib而不是os模块（其中你可能需要使用原始字符串作为路径）的另一个优点，因为os模块是平台相关的。
- en: 11.4.2 Retrieving the list of files of a specific kind
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.2 获取特定类型文件的列表
- en: The next step is retrieving all the .dat files in the directory so that we can
    process these files for scoring data purposes. To retrieve all files of a specific
    kind, we call the glob method on a directory path in which we specify a pattern
    for filenames. All files that match this pattern can be found, as the next listing
    shows.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是检索目录中的所有.dat文件，以便我们可以对这些文件进行评分数据处理。为了检索特定类型的所有文件，我们在目录路径上调用glob方法，并指定一个文件名模式。所有匹配此模式的文件都可以找到，如下一个列表所示。
- en: Listing 11.15 Retrieving files of the same kind
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.15 检索相同类型的文件
- en: '[PRE42]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: ❶ Creates a generator object
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建生成器对象
- en: ❷ Expect a different memory address on your computer.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在你的计算机上预期不同的内存地址。
- en: 'We specify that the pattern is *.dat, locating the files with an extension
    of .dat. Notably, the file list matching this pattern forms a generator, and we
    can use it in a for loop. From the printout message, we see that we indeed obtain
    all the .dat files. One potential drawback is that the list isn’t sorted, which
    may make it hard to eyeball what files have been processed. As an improvement,
    we can sort the generator to organize the files better:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定模式为*.dat，定位具有.dat扩展名的文件。值得注意的是，匹配此模式的文件列表形成一个生成器，我们可以在for循环中使用它。从打印消息中，我们看到我们确实获得了所有.dat文件。一个潜在的缺点是列表没有排序，这可能会使查看哪些文件已被处理变得困难。作为一个改进，我们可以对生成器进行排序以更好地组织文件：
- en: '[PRE43]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: ❶ Recreates the generator
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 重新创建生成器
- en: ❷ Sorts the generator to create a list
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 对生成器进行排序以创建列表
- en: Reminder Generators are consumable. When you exhaust the items in a generator,
    you must recreate the generator, allowing it to yield its items.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒生成器是可消耗的。当你耗尽生成器中的项目时，你必须重新创建生成器，以便它产生其项目。
- en: 11.4.3 Moving files to a different folder
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.3 将文件移动到不同的文件夹
- en: To organize our project’s data in a scientific experiment, we can place a participant’s
    data in their own folders. For the participant with ID number 123, for example,
    we want all their data to reside in the subject_123 folder. In this section, you’ll
    learn about moving files to address this need.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在科学实验中组织我们项目的数据，我们可以将参与者的数据放在他们自己的文件夹中。例如，对于ID号为123的参与者，我们希望所有他们的数据都位于subject_123文件夹中。在本节中，你将了解如何移动文件以满足这一需求。
- en: When we move files, the idea is to “rename” the file’s path. That is, if you
    rename the file data/subject_123.dat to subjects/subject_123/subject_123.dat,
    it moves from the data folder to the subject_123 folder. Using this knowledge,
    we can come up with the solution in listing 11.16\. Please note that we use the
    mkdir method, which allows us to create a multilevel directory even when some
    intermediate levels don’t exist. We set the parents argument as True in the mkdir
    call in the next listing; it creates any missing intermediate levels of the path
    as needed.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们移动文件时，我们的想法是“重命名”文件的路径。也就是说，如果你将文件data/subject_123.dat重命名为subjects/subject_123/subject_123.dat，它将从data文件夹移动到subject_123文件夹。利用这个知识，我们可以在列表11.16中找到解决方案。请注意，我们使用了mkdir方法，它允许我们在某些中间级别不存在的情况下创建多级目录。在下一个列表中，我们将mkdir调用中的parents参数设置为True；它根据需要创建路径中缺失的任何中间级别。
- en: Listing 11.16 Moving files to a target folder
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.16 将文件移动到目标文件夹
- en: '[PRE44]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: ❶ Creates the subject folder
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建主题文件夹
- en: ❷ Gets the filename
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取文件名
- en: ❸ Constructs the target path
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 构建目标路径
- en: 'After running this code, we should see that the current directory has a new
    folder, subjects, which contains three folders for each subject. Moving a file
    generally requires four steps (figure 11.5): identify the file you’re moving,
    retrieve the filename, construct the new filename, and rename the file with the
    new filename.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后，我们应该看到当前目录中有一个新的文件夹subjects，其中包含每个主题的三个文件夹。移动文件通常需要四个步骤（图11.5）：确定你要移动的文件，检索文件名，构建新的文件名，并使用新的文件名重命名文件。
- en: '![CH11_F05_Cui](../Images/CH11_F05_Cui.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F05_Cui](../Images/CH11_F05_Cui.png)'
- en: Figure 11.5 The general process of moving a file. In essence, you rename the
    file from its original path to the target path.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 移动文件的一般过程。本质上，你将文件从原始路径重命名为目标路径。
- en: 11.4.4 Copying files to a different folder
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.4 将文件复制到不同的文件夹
- en: Copying files allows us to keep the original files and have a second copy. Suppose
    that instead of moving the files from data to the subjects folder, we copy the
    data instead. (You need to recreate the initial data files to follow along.) Here,
    I introduce the shutil module, which provides a high-level application programming
    interface (API) for manipulating files.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 复制文件使我们能够保留原始文件并拥有第二个副本。假设我们不是将文件从data文件夹移动到subjects文件夹，而是复制数据。（您需要重新创建初始数据文件才能继续。）在这里，我介绍了shutil模块，它提供了一个高级应用程序编程接口（API）来操作文件。
- en: This module has the copy method and the calling signature copy(src, dst), in
    which src stands for the source file and dst stands for the destination path.
    Using this method, we can copy the files to each subject’s folder, as shown in
    the next listing.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 此模块具有copy方法，其调用签名是copy(src, dst)，其中src表示源文件，dst表示目标路径。使用此方法，我们可以将文件复制到每个受试者的文件夹中，如下一列表所示。
- en: Listing 11.17 Copying files to a target folder
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.17 复制文件到目标文件夹
- en: '[PRE45]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: ❶ Removes a folder and its contents
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 删除文件夹及其内容
- en: ❷ Use an underscore when you don't use a function's return value.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 当您不使用函数的返回值时，请使用下划线。
- en: 'As shown in listing 11.17, we use the rmtree function to remove a folder and
    its contents, as rmtree doesn’t care about the directory’s emptiness. By contrast,
    we could run into a problem if we use Path.rmdir to remove a directory that is
    not empty. Observe this feature:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 如列表11.17所示，我们使用rmtree函数删除文件夹及其内容，因为rmtree不关心目录的空旷。相比之下，如果我们使用Path.rmdir删除一个非空目录，我们可能会遇到问题。观察这个特性：
- en: '[PRE46]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In listing 11.16, we moved files. Copying files involves the same procedure:
    identify the files, obtain the filename, construct the target path, and use the
    copy function of the shutil module.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表11.16中，我们移动了文件。复制文件涉及相同的程序：识别文件，获取文件名，构建目标路径，并使用shutil模块的copy函数。
- en: 11.4.5 Deleting a specific kind of files
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.5 删除特定类型的文件
- en: At section 11.4’s beginning, I mentioned that one business need is to remove
    the .txt files in the data folder—specifically, the individual data files that
    may contain a subject’s privacy data—and we must remove the original files for
    security concerns. From a general perspective, we need to delete a specific kind
    of files, as we’ll discuss in this section.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在11.4节的开头，我提到一个业务需求是删除data文件夹中的.txt文件——特别是可能包含受试者隐私数据的单个数据文件——并且我们必须出于安全考虑删除原始文件。从一般的角度来看，我们需要删除特定类型的文件，正如我们将在本节中讨论的那样。
- en: 'The Path class provides the unlink method to delete a file. To use this feature,
    we need to obtain instances of the Path objects and call unlink on them:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Path类提供了unlink方法来删除文件。要使用此功能，我们需要获取Path对象的实例并在它们上调用unlink：
- en: '[PRE47]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: To show that the deletion works, we check the existence of a file before and
    after the deletion. As you can see, each file exists before the deletion, and
    it’s gone after the deletion.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 为了证明删除是有效的，我们在删除前后检查文件的存在。如您所见，每个文件在删除前都存在，在删除后就不见了。
- en: 11.4.6 Discussion
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.6 讨论
- en: When we manipulate files, we can do the operations manually, but we may lose
    track of what we’ve done with the files. Although we can write down each operation,
    it’s tedious and inconvenient to record all the operations. Thus, to make the
    file operations more reproducible and trackable, we should write code to manipulate
    the files.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们操作文件时，我们可以手动执行操作，但我们可能会失去对文件所做操作的跟踪。虽然我们可以写下每个操作，但记录所有操作既繁琐又麻烦。因此，为了使文件操作更具可重复性和可追踪性，我们应该编写代码来操作文件。
- en: 11.4.7 Challenge
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.7 挑战
- en: Cassi uses Python to manage files on her computer. One lesson she learned is
    that when she copies files to a different folder, she shouldn’t overwrite any
    files. That is, it’s possible that the target folder may have the same files that
    she moved earlier. Moreover, these files may have been processed and contain new
    data. How can she update the code in listing 11.17 so that she copies files only
    if those files don’t exist in the target folder?
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: Cassi使用Python管理她的电脑上的文件。她学到的一个教训是，当她将文件复制到不同的文件夹时，她不应该覆盖任何文件。也就是说，目标文件夹可能已经包含了她之前移动的相同文件。此外，这些文件可能已经被处理并包含新数据。她如何更新列表11.17中的代码，以便只有当这些文件在目标文件夹中不存在时才复制文件？
- en: Hint You can call exists on the Path instance object to determine whether a
    file exists.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：您可以在Path实例对象上调用exists来确定文件是否存在。
- en: 11.5 How do I retrieve file metadata?
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.5 如何检索文件元数据？
- en: In section 11.4, you learned how to manipulate files on a computer. For the
    moving and copying operations, we retrieved the filename by accessing the name
    attribute of the Path object. Besides the filename, a file has metadata that can
    be important in specific use cases. We need to retrieve a file’s directory to
    construct another path to access another file in the same directory, for example.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在 11.4 节中，你学习了如何在计算机上操作文件。对于移动和复制操作，我们通过访问 Path 对象的 name 属性来检索文件名。除了文件名外，文件还有可能在特定用例中很重要的元数据。我们需要检索文件的目录来构建另一个路径以访问同一目录中的另一个文件，例如。
- en: Suppose that we continue to handle the experimental data in section 11.4\. In
    the data folder, we need to process those data (.dat) files. But we must obtain
    additional configuration (.config) files for each subject. We can call glob to
    obtain the list of .dat files. But how can we easily locate the corresponding
    .config file for each subject? This section addresses this question and other
    operations related to accessing a file’s metadata.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们继续处理 11.4 节中的实验数据。在数据文件夹中，我们需要处理那些数据文件（.dat）。但我们必须为每个受试者获取额外的配置文件（.config）。我们可以使用
    glob 获取 .dat 文件的列表。但我们如何轻松地找到每个受试者的对应 .config 文件？本节将解答此问题以及其他与访问文件元数据相关的操作。
- en: 11.5.1 Retrieving the filename-related information
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.1 检索文件名相关信息
- en: When I say *the filename-related information*, I’m referring to the directory,
    filename, and file extension. These pieces of information are attributes of the
    Path class. Let’s use some code examples to learn about them.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 当我说“文件名相关信息”时，我指的是目录、文件名和文件扩展名。这些信息是 Path 类的属性。让我们通过一些代码示例来了解它们。
- en: 'For the problem, we start with the data file: subjects/subject_123/subject_
    123.dat. How can we retrieve subjects/subject_123/subject_123.config? These two
    files have the same directory and filename but have distinct file extensions.
    Observing these characteristics, we can come up with the solution shown in the
    next listing.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题，我们从数据文件开始：subjects/subject_123/subject_123.dat。我们如何检索 subjects/subject_123/subject_123.config？这两个文件具有相同的目录和文件名，但具有不同的文件扩展名。观察这些特征，我们可以提出以下列表中所示的解决方案。
- en: Listing 11.18 Retrieving filename information
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.18 检索文件名信息
- en: '[PRE48]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: ❶ Retrieves all data files
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 检索所有数据文件
- en: ❷ Retrieves the file directory
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 检索文件目录
- en: ❸ Retrieves the filename
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 检索文件名
- en: ❹ Opens both files
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 打开两个文件
- en: 'In listing 11.18, from the printout message, we see that we process each subject’s
    data by accessing both .dat and .config files. Four things are worth noting:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 11.18 中，从打印信息中，我们看到我们通过访问 .dat 和 .config 文件来处理每个受试者的数据。以下四点值得关注：
- en: Because there are folders within subjects_folder, when you try to access files
    within these subdirectories, the pattern involves **/, meaning that the files
    reside in subdirectories.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因为 subjects_folder 中有文件夹，当你尝试访问这些子目录中的文件时，模式涉及 **/，这意味着文件位于子目录中**。
- en: For each Path instance, we can access its parent attribute, which returns the
    directory of the path.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个 Path 实例，我们可以访问其 parent 属性，它返回路径的目录。
- en: For each Path instance, we can access its stem attribute, which returns the
    filename without the extension of the path.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个 Path 实例，我们可以访问其 stem 属性，它返回路径中不带扩展名的文件名。
- en: In the with statement, we can open two files at the same time, creating two
    file objects that we can work on simultaneously.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 with 语句中，我们可以同时打开两个文件，创建两个可以同时处理的文件对象。
- en: 'You can retrieve the entire filename, including the extension, by accessing
    name (listing 11.17), and you can retrieve only the extension by accessing suffix,
    as follows (please note that the extension includes the dot symbol):'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过访问 name（列表 11.17）来检索整个文件名，包括扩展名，也可以通过访问 suffix 来仅检索扩展名，如下所示（请注意，扩展名包括点符号）：
- en: '[PRE49]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Figure 11.6 shows which attributes correspond to filename data.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6 展示了哪些属性对应于文件名数据。
- en: '![CH11_F06_Cui](../Images/CH11_F06_Cui.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![CH11_F06_Cui](../Images/CH11_F06_Cui.png)'
- en: Figure 11.6 Retrieving a file’s filename-related data with an instance of the
    Path class. You can access its parent (the directory), name (filename, including
    extension), stem (filename only, with no extension), and suffix (file extension).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6 使用 Path 类的实例检索文件名相关数据。您可以访问其父目录（目录）、名称（包括扩展名的文件名）、主体（不带扩展名的文件名）和后缀（文件扩展名）。
- en: 11.5.2 Retrieving the file's size and time information
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.2 检索文件的大小和时间信息
- en: When you use a file-explorer app on your computer, you can see a few columns
    other than name, such as file size and the time when the file was last updated.
    This metadata can be useful in specific scenarios. This section discusses a few
    of those scenarios.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在电脑上使用文件资源管理器应用时，你可以看到除了名称之外的一些列，例如文件大小和文件最后更新的时间。这些元数据在特定场景中可能很有用。本节讨论了这些场景中的几个。
- en: For experimental data, it’s typical for each subject’s data file to have a stable
    size if the data recording was done correctly. Thus, without opening the file
    to check the content, we can check a file’s size to quickly determine data integrity
    before applying any processing procedure. The function shown in the next listing
    addresses this need.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实验数据，如果数据记录正确，每个受试者的数据文件通常具有稳定的大小。因此，在不打开文件检查内容的情况下，我们可以检查文件的大小，以快速确定数据完整性，然后再应用任何处理程序。下面列出的函数解决了这个需求。
- en: Listing 11.19 Creating a function to screen file sizes
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.19 创建一个筛选文件大小的函数
- en: '[PRE50]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: ❶ Retrieves the file size
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取文件大小
- en: ❷ Chained comparisons
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 连接比较
- en: 'In this code snippet, we call the stat() to retrieve the file’s status-related
    data, among which st_size is the size information in bytes. Using this function,
    we can test a few variations of the cutoffs to determine data integrity:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码片段中，我们调用 stat() 来获取文件的状态相关数据，其中 st_size 是以字节为单位的大小信息。使用这个函数，我们可以测试几个截止值的变体，以确定数据完整性：
- en: '[PRE51]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: As you can see, when we require the range to be 20-40, all the files are good,
    as all their sizes are 30\. If we define the size window as 40-60, all the files
    are bad.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，当我们要求范围在 20-40 之间时，所有文件都是好的，因为它们的大小都是 30。如果我们定义大小窗口为 40-60，所有文件都是坏的。
- en: 'Sometimes, we screen files based on their content modification time. To retrieve
    time-related metadata, we can call the stat method on the Path instance:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们根据文件的内容修改时间来筛选文件。要检索时间相关的元数据，我们可以在 Path 实例上调用 stat 方法：
- en: '[PRE52]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: ❶ The content modification time
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 内容修改时间
- en: ❷ Converts to human-readable time
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 转换为可读时间
- en: ❷ Expect a different value.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 预期不同的值。
- en: 'In this code, we’re accessing the attribute st_mtime, which is the time when
    the file was modified in terms of content (not filename changes or other metadata).
    This value represents the seconds since the epoch: January 1, 1970, 00:00:00 (UTC).
    We can use the ctime function in the time module to convert this value to a human-readable
    timestamp.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个代码中，我们访问属性 st_mtime，这是文件内容修改的时间（不是文件名更改或其他元数据）。这个值代表自纪元以来的秒数：1970 年 1 月 1
    日 00:00:00（UTC）。我们可以使用 time 模块中的 ctime 函数将这个值转换为可读的时间戳。
- en: 11.5.3 Discussion
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.3 讨论
- en: This section focused on the file’s directory, filename, extension, size, and
    time-related metadata. Note, however, that a file’s metadata contains many other
    pieces of information, such as the file’s permission modes, although your projects
    may need only the metadata covered in this section. When you’re thinking about
    accessing a file’s metadata, you should know that you can call the stat method
    on an instance of the Path class.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 本节重点介绍了文件的目录、文件名、扩展名、大小和时间相关的元数据。请注意，然而，文件的元数据包含许多其他信息，例如文件的权限模式，尽管你的项目可能只需要本节中涵盖的元数据。当你考虑访问文件的元数据时，你应该知道你可以在
    Path 类的实例上调用 stat 方法。
- en: 11.5.4 Challenge
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.5.4 挑战
- en: Albert is a graduate student with a major in chemistry. He loves to use Python
    to manage his computer programmatically. How can he write a function to select
    a directory’s files that were modified in the past 24 hours?
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 阿尔伯特是一名化学专业的硕士研究生。他喜欢使用 Python 以编程方式管理他的电脑。他如何编写一个函数来选择过去 24 小时内修改过的目录文件？
- en: Hint With the time module, you can call time to retrieve the number of seconds
    since the epoch. You can compare a file’s content modification time with this
    value for the 24-hour adjustment. Remember that you need to calculate the number
    of seconds in 24 hours.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：使用 time 模块，你可以调用 time 来获取自纪元以来的秒数。你可以将文件的内容修改时间与这个值进行比较以进行 24 小时调整。记住，你需要计算
    24 小时内的秒数。
- en: Summary
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: When you perform reading/writing operations with a file, use the with statement,
    which closes the file automatically, using a context manager.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你对文件执行读写操作时，使用 with 语句，它会自动关闭文件，使用上下文管理器。
- en: The default open mode is "r" (read). Performing any writing operations requires
    you to use "w" (write) or "a" (append), with the latter appending data to the
    file’s end.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认打开模式是 "r"（读取）。执行任何写入操作都需要你使用 "w"（写入）或 "a"（追加），后者将数据追加到文件的末尾。
- en: The built-in csv module is specialized to read and write CSV data. Although
    this topic isn’t the focus of this book, if you need to perform numeric computations
    and data processing, consider using a third-party library such as pandas.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置的 csv 模块专门用于读取和写入 CSV 数据。尽管这个主题不是本书的重点，如果你需要进行数值计算和数据处理，考虑使用第三方库，如 pandas。
- en: When CSV files have headers, prefer using csv.DictReader, which handles the
    headers, over the other common data reader, csv.reader.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 CSV 文件有标题时，优先使用 csv.DictReader，它处理标题，而不是其他常见的数据读取器 csv.reader。
- en: As the counterparts to csv.reader and csv.DictReader, csv.writer and csv.DictWriter
    are used to create CSV files. The latter is better at handling headers.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为 csv.reader 和 csv.DictReader 的对应物，csv.writer 和 csv.DictWriter 用于创建 CSV 文件。后者在处理标题方面做得更好。
- en: Pickling is a built-in mechanism for storing Python objects as binary data.
    Compared with JSON, pickling is more flexible because it supports more data types,
    including functions.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pickling 是一种将 Python 对象存储为二进制数据的内置机制。与 JSON 相比，Pickling 更灵活，因为它支持更多的数据类型，包括函数。
- en: Be cautious about pickling’s data security. Don’t pickle or unpickle any data
    from potentially untrusted sources.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Pickling 的数据安全性方面要谨慎。不要从可能不可信的来源中 Pickling 或 Unpickling 任何数据。
- en: Instead of using CSV files as a storage mechanism for tabulated data, you can
    use pickling to save data size and increase reading/writing speed.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与使用 CSV 文件作为表格数据的存储机制不同，你可以使用 Pickling 来减小数据大小并提高读写速度。
- en: The built-in module pathlib provides various methods and attributes for its
    Path class. You should be familiar with using pathlib to perform file management,
    such as creating a directory and moving files.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内置的 pathlib 模块为它的 Path 类提供了各种方法和属性。你应该熟悉使用 pathlib 来执行文件管理，例如创建目录和移动文件。
- en: A file doesn’t contain only its content, but also its name, directory, modification
    time, and other metadata that can contain the information you need. You should
    know how to retrieve this data through the Path class.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个文件不仅仅包含其内容，还包含其名称、目录、修改时间以及其他可能包含所需信息的元数据。你应该知道如何通过 Path 类检索这些数据。
