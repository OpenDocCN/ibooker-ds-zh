- en: front matter
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: foreword
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前言
- en: It’s been two years since the publication of the first edition of *Machine Learning
    with TensorFlow*. Two years is a long time in the field of artificial intelligence.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 自第一版《TensorFlow机器学习》出版以来已有两年。在人工智能领域，两年是一段很长的时间。
- en: Today, we are fascinated by a human-language model with more than 80 billion
    artificial neurons that have learned more than 170 billion parameters. The cost
    of training such a model is measured in millions of dollars. Lex Fridman of MIT
    projected that with the improvements in computing and algorithm design, we’ll
    soon train a model the size of the human brain for less than a few thousand dollars.
    Just think—in our near-term future, we’ll train an AI model with the raw capacity
    of the human brain for less than the cost of a Peloton stationary bike.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们对一个拥有超过800亿个人工神经元、学习超过1700亿个参数的人类语言模型感到着迷。训练这样一个模型的成本以百万美元计。麻省理工学院的Lex
    Fridman预测，随着计算和算法设计的改进，我们很快就能以不到几千美元的成本训练出与人类大脑大小相当的模型。想想看——在我们不久的将来，我们将以不到一辆Peloton固定自行车的成本来训练一个具有人类大脑原始容量的AI模型。
- en: Writing a book to capture this fast-moving technology is fraught with risk.
    By the time Chris wrote a few chapters, researchers likely produced newer, more
    elegant approaches to solving the same problems. Yet there are perhaps only 10,000
    people today who understand AI deeply. You want to jump in, learn, and start using
    AI in your work. What is one to do?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 撰写一本捕捉这个快速发展的技术的书充满了风险。当克里斯写了几章时，研究人员可能已经产生了更新、更优雅的解决同样问题的方法。然而，今天可能只有大约1万人真正深刻理解人工智能。你想跳进来，学习，并开始在工作中使用人工智能。该怎么办呢？
- en: 'Buy this book—even if you have the first edition. Pay special attention to
    seven new chapters that walk you through fundamental techniques in AI:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 购买这本书——即使你有第一版。特别关注以下七个新章节，它们将引导你了解人工智能的基本技术：
- en: 'Chapter 6, “Sentiment classification: Large movie-review dataset”'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第6章，“情感分类：大型电影评论数据集”
- en: Chapter 8, “Inferring user activity from Android accelerometer data”
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8章，“从Android加速度计数据推断用户活动”
- en: Chapter 10, “Part-of-speech tagging and word-sense disambiguation”
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10章，“词性标注和词义消歧”
- en: 'Chapter 12, “Applying autoencoders: The CIFAR-10 image dataset”'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第12章，“应用自编码器：CIFAR-10图像数据集”
- en: 'Chapter 15, “Building a real-world CNN: VGG -Face and VGG -Face Lite”'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第15章，“构建真实世界的CNN：VGG-Face和VGG-Face Lite”
- en: Chapter 17, “LSTMs and automatic speech recognition”
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第17章，“LSTMs和自动语音识别”
- en: Chapter 18, “Sequence-to-sequence models for chatbots”
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第18章，“用于聊天机器人的序列到序列模型”
- en: Chris helps you learn how machines see, hear, speak, write, and feel within
    our world. He shows how machines can instantly spot that speck of dust on a windshield,
    much as human eyes do, with autoencoders.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 克里斯帮助你学习机器在我们的世界中如何看、听、说、写和感受。他展示了机器如何像人眼一样，利用自编码器瞬间发现挡风玻璃上的灰尘。
- en: The modeling techniques, which Chris describes with frustratingly delicious,
    hands-on detail, will persist through time. They’re fundamental to framing a problem
    as tensors in, tensors out, flowing through a graph. Framing a problem correctly
    is far more important than describing the individual details of how it is solved.
    Expect those details to change and improve rapidly.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 克里斯用令人沮丧的、实用的细节描述建模技术，这些技术将随着时间的推移而持续存在。它们对于将问题作为张量输入、张量输出、通过图流动是基本的。正确地构建问题比描述解决问题的个别细节更为重要。预期这些细节会迅速变化和改进。
- en: Armed with an appreciation of AI modeling, you’ll be well-prepared to enjoy
    the rapid, exponential journey forward in artificial intelligence. Welcome to
    our world! Jump in, have some fun, crank those GPUs, and do your part to assist
    humanity in solving intelligence. Reimagine our world with smart machines—then
    make it so with TensorFlow.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 带着对AI建模的欣赏，你将准备好享受人工智能快速、指数级的前进旅程。欢迎来到我们的世界！跳进来，享受乐趣，开启那些GPU，并尽你所能帮助人类解决智能问题。用智能机器重新构想我们的世界——然后用TensorFlow实现它。
- en: Chris, thanks for taking the time to be our guide, peppered with that godawful
    dad humor that I just love.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 克里斯，感谢你抽出时间做我们的向导，穿插着那种我非常喜欢的糟糕的父亲幽默。
- en: Scott Penberthy, director of Applied AI at Google
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Scott Penberthy，谷歌应用AI总监
- en: Palo Alto
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 旧金山
- en: California August 2020
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 加利福尼亚州，2020年8月
- en: preface
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前言
- en: It was about 15 months ago to this day that I sat down with my freshly-minted
    copy of the first edition of this book, opened it, and dived right in. I currently
    manage the Artificial Intelligence, Analytics and Innovative Development Division
    at NASA’s Jet Propulsion Laboratory in beautiful Pasadena, California. At the
    time, however, I was the deputy chief technology officer (CTO) for IT, with a
    strong background in data science, information retrieval, and software, but only
    a surface knowledge of the hot topic called machine learning. I had dabbled with
    it, but never dived deep, as they say. Knowing Manning and its coverage of topics
    with practicality, in-depth examples, and most of all humor (I desperately seek
    it in everything ; humor makes things better), I had a good feeling about the
    book. At the time, it had been almost a full year since I’d had the time to read
    a technical book, let alone sit down and try the code and exercises.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 大约15个月前，就在今天，我坐下来，手拿这本书的第一版全新副本，打开它，一头扎了进去。我现在在位于美丽加利福尼亚州帕萨迪纳的NASA喷气推进实验室管理人工智能、分析和创新发展部门。然而，当时我是IT部门的副首席技术官（CTO），在数据科学、信息检索和软件方面有深厚的背景，但对热门话题机器学习只有表面的了解。我尝试过它，但从未深入钻研，就像人们说的那样。鉴于Manning对实用性、深入示例以及最重要的是幽默（我在一切事物中都迫切寻求它；幽默使事物变得更好）的覆盖，我对这本书抱有好感。当时，自从我有时间阅读技术书籍以来，几乎已经过去了一年，更不用说坐下来尝试代码和练习了。
- en: I decided that with this book, I would have to run the code, pull out pencil
    and paper, and draw matrices, and write things down—you know, learn what I was
    reading instead of reading but not learning. Whoo, boy, this book was a doozy.
    It was humorous—probably the easiest introduction to machine learning that I had
    read—and I actually understood it. I remember remarking to my wife one night,
    “This is why all the billionaire CEOs like [Elon] Musk are afraid of AI.” I could
    see its application to a variety of formats, such as text, sound, vision, and
    speech. And it uses this amazing framework called TensorFlow that I had been hearing
    so much about.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定，有了这本书，我必须运行代码，拿出铅笔和纸，绘制矩阵，并写下东西——你知道的，学习我正在阅读的内容，而不是阅读但不学习。哇，这本书真是个大挑战。它很有趣——可能是我读过的最简单的机器学习入门书籍——而且我确实理解了它。我记得有一天晚上对妻子说，“这就是为什么所有亿万富翁CEO，比如[埃隆]马斯克，都害怕AI的原因。”我可以看到它在各种格式中的应用，如文本、声音、视觉和语音。它使用了一个我听说很多的令人惊叹的框架，叫做TensorFlow。
- en: There was one problem, though. The first edition of the book had a habit of
    throwing out a bullet point at the end of the chapter—something to the effect
    of “Well, you’ve just covered AI or ML topic X; you could try building a model
    for X like this state-of-the-art one and test it.” I was curious and willing to
    devote the time. About nine weeks later, I had trained and rebuilt the Visual
    Geometry Group’s (VGG) Face seminal model and found a whole bunch of improvements
    and rebuilt the dataset that no longer existed. I had written code to take Android
    cell phone data and infer the user’s activity, such as running or walking. I had
    built a robust sentiment classifier that would have scored in the top 100 results
    on Kaggle during the Bag of Popcorn Movie Challenge (since closed).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一个问题。这本书的第一版有一个习惯，那就是在每章的结尾抛出一个项目符号——大致意思是“好吧，你刚刚覆盖了AI或ML主题X；你可以尝试构建一个像这个最先进的X模型一样为X构建模型并测试它。”我很好奇，愿意投入时间。大约九周后，我训练并重建了视觉几何组（VGG）的标志性面部模型，并发现了一大堆改进和重建了不再存在的数据集。我编写了代码，从Android手机数据中推断用户的活动，如跑步或行走。我构建了一个强大的情感分类器，在Kaggle的爆米花电影挑战赛（现已关闭）中可能会获得前100名结果。
- en: Ultimately, I had built enough code, notes, and material for a second edition
    of this book. I collected the data, wrote Jupyter notebooks and documented them,
    and fixed the bugs in the code; even in the two years between Nishant Shukla’s
    first edition of the book and this one, TensorFlow had made around 20 releases
    in the 1.x branch, and the 2.x version was about to land (as it did while I wrote
    this book).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我为这本书的第二版积累了足够的代码、笔记和材料。我收集了数据，编写了Jupyter笔记本并对其进行了文档记录，修复了代码中的错误；甚至在Nishant
    Shukla这本书的第一版和这一版之间两年时间里，TensorFlow在1.x分支上发布了大约20个版本，2.x版本也即将推出（在我写这本书的时候已经推出了）。
- en: 'All the code, examples, bug fixes, data downloading, ancillary software library
    installations, and Dockerization are what you get in this book. Don’t think of
    it as yet another *TensorFlow book; I could have easily called it Machine Learning
    with TensorFlow and Friends, 2nd Edition: NumPy, SciPy, Matplotlib, Jupyter, Pandas,
    Tika, SKLearn, TQDM, and More*. You need all these elements to do data science
    and machine learning. To be clear, this book isn’t only about TensorFlow; it’s
    a book about machine learning and how to do it: how to clean data, build a model
    and train it, and (most importantly) how to evaluate it.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所有代码、示例、错误修复、数据下载、辅助软件库安装和Docker化都是这本书中你得到的内容。不要把它想成又一本*TensorFlow书；我本可以轻易地称之为《使用TensorFlow和朋友的机器学习，第2版：NumPy、SciPy、Matplotlib、Jupyter、Pandas、Tika、SKLearn、TQDM以及更多》。你需要所有这些元素来做数据科学和机器学习。为了清楚起见，这本书不仅仅关于TensorFlow；这是一本关于机器学习以及如何做的书：如何清理数据、构建模型并训练它，以及（最重要的是）如何评估它。
- en: I hope you enjoy machine learning as much as I do now and will forever. This
    journey hasn’t been easy, including being caught in a global pandemic while writing,
    but I’ve never been more optimistic, as I’ve seen the light and power of what
    artificial intelligence and machine learning can do. I hope that you will too,
    after reading this book!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你现在和将来都像我一样喜欢机器学习。这段旅程并不容易，包括在写作时被全球大流行病所困扰，但我从未如此乐观，因为我看到了人工智能和机器学习的光明和力量。我希望在阅读这本书后，你也会这样。
- en: acknowledgments
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: I’d be remiss without thanking Nishant Shukla, who wrote the first edition of
    this book. His clever, witty discussion was an inspiration to undertake the journey
    that led me to create this book.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有感谢尼尚特·舒克拉，我将感到失职，他写了这本书的第一版。他聪明、风趣的讨论激发了我踏上这段旅程，最终使我创作了这本书。
- en: I would like to sincerely thank my acquisitions editor, Michael Stephens, for
    believing in my book proposal and sticking with my insistence, passion, and vision
    for the work. The book is better for your strong feedback and critiques. Thanks
    to Marjan Bace, the publisher of Manning, for greenlighting the book idea and
    giving this author another shot 10 years after his first book.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我衷心感谢我的收购编辑迈克尔·斯蒂普斯，他相信我的书稿，并坚持我的坚持、热情和愿景。这本书因你的强烈反馈和批评而变得更好。感谢Manning出版社的出版商Marjan
    Bace，他批准了这本书的想法，并在他第一本书10年后给了这位作者另一次机会。
- en: Toni Arritola, my development editor, has been my biggest cheerleader and strongest
    advocate for ensuring that the book is a success. Her belief in me, the vision,
    and the process, and our trust in each other, made this book an amazing one. Toni’s
    challenges to my AI and data science jargon and her strength in editing and reformulating
    my 50,000-feet concepts into practical solutions and problem solving make machine
    learning with TensorFlow a consumable treat, regardless of your knowledge of coding,
    AI, or ML. Thanks for her calmness, wisdom, and heart.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我的开发编辑托尼·阿里托拉一直是我最大的支持者和确保这本书成功的最坚定的倡导者。她对我的信任、对愿景和过程的信念，以及我们之间的信任，使这本书变得非常出色。托尼对我的AI和数据科学术语的挑战以及她将我的50000英尺概念编辑和重新构思为实用解决方案和解决问题的能力，使无论你对编码、AI还是ML的了解如何，使用TensorFlow进行机器学习都成为一种可口的享受。感谢她的冷静、智慧和心。
- en: Thank you to my technical development editor, Al Krinker, for his technical
    editing and suggestions that no doubt improved the book.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢我的技术发展编辑阿尔·克林克，他的技术编辑和建议无疑提高了这本书的质量。
- en: 'To all the reviewers: Alain Couniot, Alain Lompo, Ariel Gamino, Bhagvan Kommadi,
    David Jacobs, Dinesh Ghanta, Edward Hartley, Eriks Zelenka, Francisco José Lacueva,
    Hilde Van Gysel, Jeon Kang, Johnny L. Hopkins, Ken W. Alger, Lawrence Nderu, Marius
    Kreis, Michael Bright, Teresa Fontanella de Santis, Vishwesh Ravi Shrimali, and
    Vittal Damaraju—your suggestions helped make this a better book. In addition,
    I would like to thank the anonymous reviewers who provided valuable feedback and
    suggestions, and encouraged me to strive for a better installation, which led
    to the comprehensive Docker install and branch in the repository and to better
    organization of the code overall.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 向所有审稿人致谢：Alain Couniot、Alain Lompo、Ariel Gamino、Bhagvan Kommadi、David Jacobs、Dinesh
    Ghanta、Edward Hartley、Eriks Zelenka、Francisco José Lacueva、Hilde Van Gysel、Jeon
    Kang、Johnny L. Hopkins、Ken W. Alger、Lawrence Nderu、Marius Kreis、Michael Bright、Teresa
    Fontanella de Santis、Vishwesh Ravi Shrimali和Vittal Damaraju——你们的建议帮助使这本书变得更好。此外，我还要感谢那些提供了宝贵反馈和建议的匿名审稿人，他们鼓励我努力追求更好的安装，这导致了仓库中的全面Docker安装和分支，以及代码的整体更好组织。
- en: I would like to thank Candace Gillhoolley for organizing what seemed like dozens
    of podcasts, promotions, and connections in promoting the book and getting the
    word out.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我要感谢Candace Gillhoolley组织了数十次播客、推广和联系活动，以推广这本书并传播信息。
- en: Thanks to my colleagues and teammates in the industry for spending their own
    time reading some early drafts of the book chapters and providing critical feedback.
    I especially would like to thank Philip Southam for believing in me and doing
    the early work on Docker installs, and Rob Royce for working the TensorFlow2 branch
    and being interested in the code. I also deeply thank Zhao Zhang for helping to
    flesh out the CNN chapter ideas and Thamme Gowda for providing pointers and discussions.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢我的行业同事和队友抽出他们自己的时间阅读这本书的早期草稿章节，并提供了宝贵的反馈。我特别想感谢Philip Southam对我的信任，以及他在Docker安装方面的早期工作，还有Rob
    Royce在TensorFlow2分支上的工作和对代码的兴趣。我还深深地感谢赵张在CNN章节想法上的帮助，以及Thamme Gowda提供的指导和讨论。
- en: Finally, I thank my amazing wife, Lisa Mattmann, who nearly a decade later let
    me do what I promised her I wouldn’t do again after my last book (and before that,
    my PhD dissertation). I have a terrible track record on staying away from writing,
    but this time was different, in that after nearly 20 years together, she knows
    me and knows that writing is my passion. Thank you, honey.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我要感谢我惊人的妻子，Lisa Mattmann，在将近十年后，她让我再次做我承诺过不会再做的事情（在我上一本书和我的博士论文之前）。我在远离写作方面有着糟糕的记录，但这一次不同，在将近20年的相处中，她了解我，知道写作是我的激情。谢谢你，亲爱的。
- en: I dedicate this book to my children. My eldest son, Christian John (CJ) Mattmann,
    demonstrated interest in the sentiment analysis chapter and text processing. He’s
    a chip off the old block, if you will. I hope that, someday, he’ll have the gumption
    to run the code and perform his own even-better sentiment analysis and ML. I suspect
    that he will. Thanks to Heath and Hailey Mattmann for understanding when Daddy
    was up late at night finishing the book and working through chapters and coding.
    This one’s for you!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我将这本书献给我的孩子们。我的大儿子，Christian John (CJ) Mattmann，对情感分析章节和文本处理表现出兴趣。他真是继承了家族的基因。我希望有一天，他会有勇气运行代码，并执行他自己的甚至更好的情感分析和机器学习。我怀疑他会这样做。感谢Heath和Hailey
    Mattmann理解当爸爸深夜熬夜完成这本书和编写章节以及编码时的情况。这本书献给你们！
- en: about this book
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于这本书
- en: 'To get the most benefit from this book, you’ll want to approach it as two parts:
    a sprinkle of math and theory, followed by practical applications with Python,
    TensorFlow, and friends. When I reference uses of machine-learning techniques
    such as regression or classification in particular domains and cite example datasets
    or problems, think about how you can use those data and/or problem domains to
    test the new machine learning you are using. That’s what I did as a reader of
    the first edition, poring over the chapters and then applying the “what ifs” and
    pointers to datasets to create new chapters for this edition, based on the notebooks
    I made and the work I did.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从这本书中获得最大益处，您应该将其视为两部分：一部分是数学和理论的基础，随后是使用Python、TensorFlow及其相关工具的实际应用。当我特别提到在特定领域使用机器学习技术，如回归或分类，并引用示例数据集或问题时，请思考您如何利用这些数据和/或问题领域来测试您正在使用的新的机器学习技术。这正是我在第一版读者时的做法，仔细研读章节，然后应用“如果...会怎样”的想法和指向数据集的指针，基于我制作的笔记本和我所做的工作，为这一版创建了新的章节。
- en: The whole process took weeks or months to complete for each chapter. I’ve captured
    all the updates in the second edition. As you progress through the early parts
    of the book, you will see that the order of chapters remains similar to that of
    the first edition. After regression, however, there is now a chapter on applying
    regression to the suggested 311 service exercises from the first edition. Likewise,
    the second edition has a full chapter on using classification to perform sentiment
    analysis on the Netflix movie reviews data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程需要花费每个章节数周或数月的时间来完成。我在第二版中记录了所有更新。随着您阅读这本书的前几部分，您会发现章节的顺序与第一版相似。然而，在回归之后，现在有一个章节专门介绍将回归应用于第一版建议的311个服务练习。同样，第二版还有一个完整的章节介绍如何使用分类对Netflix电影评论数据执行情感分析。
- en: Throughout the rest of the book, you will explore topics including unsupervised
    clustering, hidden Markov models (HMMs), autoencoders, deep reinforcement learning,
    convolutional neural networks (CNNs), and CNN classifiers. I’ve also added a chapter
    on taking positional data from Android phones and inferring what type of activity
    the user was doing, as well as a chapter on re-creating the VGG -Face facial identification
    CNN model. To perform some of the later exercises, you will want access to a GPU,
    either locally on your laptop or via some cloud access at Google, Amazon, or one
    of the big providers. I’ll help you along the way.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的其余部分，你将探索包括无监督聚类、隐藏马尔可夫模型（HMMs）、自动编码器、深度强化学习、卷积神经网络（CNNs）和CNN分类器等主题。我还增加了一章，介绍如何从Android手机中提取位置数据，并推断用户正在进行的活动类型，以及一章关于重新创建VGG-Face面部识别CNN模型的内容。为了执行一些后续练习，你可能需要访问GPU，无论是本地在您的笔记本电脑上，还是通过Google、Amazon或其他大型提供商的云访问。我会在这个过程中帮助你。
- en: Please be sure to post any questions, comments, or suggestions you have about
    the book in the liveBook Discussion Forum ([https://livebook.manning.com/book/machine-learning-with-tensorflow-second-edition/discussion](https://livebook.manning.com/book/machine-learning-with-tensorflow-second-edition/discussion)).
    Your feedback is important in keeping the book up-to-date and ensuring that it’s
    the best book possible. I look forward to helping you in your machine-learning
    odyssey!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保在liveBook讨论论坛（[https://livebook.manning.com/book/machine-learning-with-tensorflow-second-edition/discussion](https://livebook.manning.com/book/machine-learning-with-tensorflow-second-edition/discussion)）中发布你关于本书的任何问题、评论或建议。你的反馈对于保持本书的时效性和确保它是最好的书籍至关重要。我期待着在您的机器学习之旅中帮助你！
- en: 'How this book is organized: A roadmap'
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本书是如何组织的：一个路线图
- en: This book is divided into three parts.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本书分为三个部分。
- en: 'Part 1, “Your machine-learning rig,” explains the general theory of machine
    learning and gives some motivation for its massive uptick and use in today’s world,
    grounding the discussion in one of the most widely used frameworks for implementing
    machine learning: TensorFlow.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 第一部分，“你的机器学习配置”，解释了机器学习的一般理论，并给出了一些关于其在当今世界大规模增长和使用的动机，讨论基于最广泛使用的机器学习实现框架之一：TensorFlow。
- en: Chapter 1 introduces machine learning and explains it as teaching a computer
    to classify, predict, aggregate, and identify based on input images, text, sound,
    and other formats.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第1章介绍了机器学习，并解释了它是如何教授计算机根据输入图像、文本、声音和其他格式进行分类、预测、聚合和识别的。
- en: Chapter 2 covers TensorFlow essentials and introduces the reader to the TensorFlow
    framework; the concept of tensors; graph-based execution; and the process of creating,
    training, and saving models.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第2章涵盖了TensorFlow基础知识，并向读者介绍了TensorFlow框架；张量的概念；基于图的执行；以及创建、训练和保存模型的过程。
- en: 'Part 2, “Core learning algorithms,” gives you your machine-learning toolbox:
    regression for learning continuous value prediction or classification for discrete
    categorical prediction and inference. The chapters in this part are paired; one
    chapter focuses on a tool and general theory, and the following chapter provides
    a detailed example problem involving data cleaning, preparation, training, inference,
    and evaluation. Techniques taught include regression, classification, unsupervised
    clustering, and HMMs. All these techniques are explainable in that you can explain
    the steps of the machine-learning process and use math and statistics directly
    to evaluate their value.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 第二部分，“核心学习算法”，为你提供了机器学习工具箱：回归用于学习连续值预测或分类用于离散分类预测和推理。本部分中的章节是配对的；一章专注于工具和一般理论，下一章则提供了一个涉及数据清洗、准备、训练、推理和评估的详细示例问题。教授的技术包括回归、分类、无监督聚类和HMMs。所有这些技术都是可解释的，即你可以解释机器学习过程的步骤，并直接使用数学和统计学来评估它们的值。
- en: Chapter 3 covers regression, which is a modeling problem involving continuous
    input and a possibly discrete or continuous output.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第3章涵盖了回归，这是一个涉及连续输入和可能离散或连续输出的建模问题。
- en: Chapter 4 applies regression to real-world call center data from New York City’s
    311 service, which provides help to citizens. You will collect a dataset of weekly
    call volumes and use regression to predict with high accuracy the number of calls
    expected per week.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第4章将回归应用于来自纽约市311服务机构的真实世界呼叫中心数据，该机构为市民提供帮助。你将收集每周呼叫量的数据集，并使用回归来预测每周预期的呼叫数量。
- en: Chapter 5 covers classification, which is a modeling problem that takes as input
    discrete or continuous data and outputs single or multiple categorical class labels.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第5章涵盖了分类，这是一个建模问题，它接受离散或连续数据作为输入，并输出单个或多个分类类别标签。
- en: Chapter 6 uses classification on Netflix and IMDb movie-review data to build
    a movie sentiment classifier based on reviews that identify a movie as positive
    or negative.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第6章使用Netflix和IMDb电影评论数据对电影进行分类，构建了一个基于评论识别电影为正面或负面的电影情感分类器。
- en: Chapter 7 demonstrates unsupervised clustering, showing automatic grouping of
    input data into discrete categories without labels.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7章演示了无监督聚类，展示了在没有标签的情况下自动将输入数据分组到离散类别中。
- en: Chapter 8 applies automatic clustering to input Android phone positional data
    to show you how to infer user activity based on phone accelerometer positional
    data.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8章将自动聚类应用于输入的Android手机位置数据，向你展示如何根据手机加速度计的位置数据推断用户活动。
- en: Chapter 9 eases you into the topic of HMMs and shows how indirect evidence can
    lead to explainable decisions.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第9章使你轻松进入隐马尔可夫模型（HMMs）的主题，并展示了间接证据如何导致可解释的决策。
- en: Chapter 10 applies HMMs to text input to disambiguate classification of parts
    of speech in text when it’s hard to tell whether engineer is a noun or a verb.
    (When isn’t it, right?)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第10章将隐马尔可夫模型（HMMs）应用于文本输入，以在难以判断engineer是名词还是动词时，对文本中的词性进行区分。（什么时候不是这样呢，对吧？）
- en: 'The final part of the book covers the neural network paradigm that is sweeping
    the community: helping cars to drive automatically, physicians to diagnose cancer,
    and phones to use biometrics like your face to decide whether you can log in.
    A neural network is a particular machine-learning model inspired by the human
    brain and its structure as a graph of neurons that fire based on input, emitting
    predictions, confidence, beliefs, structure, and shapes. Neurons map nicely to
    the concept of tensors, which are nodes in a graph that allow information such
    as scalar values, matrices, and vectors to flow through them, be manipulated,
    transformed, and so on—hence, Google’s framework name TensorFlow. This part of
    the book covers autoencoders for compressing and representing input using hidden
    layers, CNNs for automatically classifying objects and faces in images, and recurrent
    neural networks (RNNs) for time-series data or speech data converted to text.
    Part 3 also covers the seq2seq RNN architecture, which can be used to associate
    input text and statements with responses from an intelligent digital assistant
    such as a chatbot. The last chapter in the book applies neural networks to evaluating
    the utility of a robot folding cloth based on input video and images.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 书的最后一部分涵盖了正在席卷社区的神经网络范式：帮助汽车自动驾驶、医生诊断癌症以及手机使用生物识别技术（如你的面部）来决定你是否可以登录。神经网络是一种受人类大脑及其结构启发的特定机器学习模型，其结构是一个基于输入、发出预测、置信度、信念、结构和形状的神经元图。神经元很好地映射到张量的概念，张量是图中允许标量值、矩阵和向量等信息通过它们流动、被操作、转换等的节点——因此，谷歌框架的名称为TensorFlow。本书的这一部分涵盖了用于压缩和表示输入的自动编码器、用于自动分类图像中对象和面孔的卷积神经网络（CNNs）以及用于时间序列数据或转换为文本的语音数据的循环神经网络（RNNs）。第3部分还涵盖了seq2seq
    RNN架构，它可以用来将输入文本和语句与智能数字助手（如聊天机器人）的响应关联起来。本书的最后一章将神经网络应用于根据输入视频和图像评估机器人折叠布料的效用。
- en: Chapter 11 covers autoencoders, which take input data and compact it into a
    much smaller representation by using hidden layers in a neural network.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第11章涵盖了自动编码器，它们通过使用神经网络中的隐藏层将输入数据压缩成更小的表示。
- en: Chapter 12 explores several types of autoencoders, including stacked and denoising
    autoencoders, and demonstrates how the network learns a compact representation
    of images from the CIFAR-10 dataset.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第12章探讨了多种类型的自动编码器，包括堆叠和去噪自动编码器，并演示了网络如何从CIFAR-10数据集中学习图像的紧凑表示。
- en: 'Chapter 13 introduces the reader to a different kind of network: a deep reinforcement
    learning network, which learns an optimal policy for investing in a stock portfolio.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第13章向读者介绍了一种不同类型的网络：深度强化学习网络，它学习投资股票组合的最佳策略。
- en: Chapter 14 is all about CNN, a neural architecture inspired by the visual cortex.
    CNNs use several convolutional filters to develop a compact representation of
    input images and their higher- and lower-order features.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第14章全部关于卷积神经网络（CNN），这是一种受视觉皮层启发的神经网络架构。CNN使用多个卷积滤波器来开发输入图像及其更高和更低阶特征的紧凑表示。
- en: 'Chapter 15 teaches you how to build two real-world CNNs: one for the CIFAR-10
    dataset for object recognition and another for a facial recognition system called
    VGG -Face.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第15章教你如何构建两个真实世界的CNN：一个用于CIFAR-10数据集的对象识别，另一个用于名为VGG-Face的面部识别系统。
- en: Chapter 16 covers the RNN paradigm for time-series data and represents the decisions
    of neural networks over time, not only in a particular instance.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第16章涵盖了时间序列数据的RNN范式，并代表了神经网络随时间做出的决策，而不仅仅是特定实例中的决策。
- en: Chapter 17 shows you how to build a real-world RNN model type called long short-term
    memory (LSTM) for automatic speech to text recognition, rebuilding the deep-speech
    model architecture made famous by Baidu.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第17章向你展示了如何构建一个名为长短期记忆（LSTM）的真实世界RNN模型类型，用于自动语音到文本识别，重建了百度使其闻名的深度语音模型架构。
- en: Chapter 18 reuses RNNs and demonstrates the seq2seq architecture, which can
    be used to build an intelligent chatbot that responds to user chat with realistic
    responses trained on previous questions and answers.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第18章重用RNN并演示了seq2seq架构，它可以用来构建一个智能聊天机器人，该机器人可以针对用户聊天进行现实反应，这些反应是在之前的问题和答案上训练的。
- en: Chapter 19 rounds out the book by exploring the utility landscape, using neural
    architectures to create image embeddings from videos of cloth-folding and then
    use those embeddings to infer the utility of each step of the task over time.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第19章通过探索效用景观来结束本书，使用神经网络架构从布折叠的视频中创建图像嵌入，然后使用这些嵌入来推断任务每个步骤随时间的效用。
- en: About the code
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于代码
- en: This book contains many examples of source code, both in numbered listings and
    inline with normal text. In both cases, source code is formatted in a `fixed-width
    font like this` to separate it from ordinary text. Sometimes code is also `in`
    `bold` to highlight code that has changed from previous steps in the chapter,
    such as when a new feature adds to an existing line of code.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 本书包含许多源代码示例，无论是编号列表还是与普通文本内联。在这两种情况下，源代码都使用`固定宽度字体`如这样来格式化，以将其与普通文本区分开来。有时代码也会`加粗`以突出显示与章节中先前步骤相比有所改变的代码，例如当新功能添加到现有代码行时。
- en: In many cases, the original source code has been reformatted; we’ve added line
    breaks and reworked indentation to accommodate the available page space in the
    book. In rare cases, even this was not enough, and listings include line-continuation
    markers (➥). Additionally, comments in the source code have often been removed
    from the listings when the code is described in the text. Code annotations accompany
    many of the listings, highlighting important concepts.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，原始源代码已经被重新格式化；我们添加了换行并重新调整了缩进，以适应书籍中可用的页面空间。在极少数情况下，即使这样也不够，列表中还包括了行续接标记（➥）。此外，当代码在文本中描述时，源代码中的注释通常也会从列表中移除。许多列表旁边都有代码注释，突出显示重要概念。
- en: Many graphics in this book include color, which can be viewed in the e-book
    versions. To get your free e-book in PDF, ePub, or Kindle format, go to [http://mng.bz/JxPo](http://mng.bz/JxPo)
    to register your print book.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的许多图形都包含颜色，可以在电子书版本中查看。要获取免费的电子书（PDF、ePub或Kindle格式），请访问[http://mng.bz/JxPo](http://mng.bz/JxPo)注册您的印刷版书籍。
- en: The code for the book is organized by chapter as a series of Jupyter notebooks.
    The associated Docker container that you can pull from Docker Hub or build yourself
    will automatically install Python 3 and Python 2.7 and TensorFlow 1.15 and 1.14,
    respectively, so that you can run all the examples in the book. Listings in the
    book are clearly delineated and numbered; they map to the chapters and listing-numbered
    .ipynb files in the GitHub repo at [http://mng.bz/MoJn](http://mng.bz/MoJn), and
    from the Manning website at [https://www.manning.com/books/machine-learning-with-tensorflow-second-edition](https://www.manning.com/books/machine-learning-with-tensorflow-second-edition).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 书中的代码按章节组织，作为一系列Jupyter笔记本。你可以从Docker Hub拉取或自己构建相关的Docker容器，它会自动安装Python 3和Python
    2.7以及TensorFlow 1.15和1.14，这样你就可以运行书中的所有示例。书中的列表清晰划分并编号；它们对应于GitHub仓库中[http://mng.bz/MoJn](http://mng.bz/MoJn)的章节和列表编号.ipynb文件，以及Manning网站[https://www.manning.com/books/machine-learning-with-tensorflow-second-edition](https://www.manning.com/books/machine-learning-with-tensorflow-second-edition)。
- en: The Docker file automatically downloads and installs third-party libraries (the
    and friends part of TensorFlow and friends, as referenced through the book) and
    the necessary datasets from a remote Dropbox link that you need to run all the
    code. You may also run the download scripts for libraries and data outside the
    Docker container if you installed locally in your own Python environments.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 文件会自动从远程 Dropbox 链接下载并安装第三方库（TensorFlow 及其相关库的部分，如书中所述）和必要的数据集，以便您运行所有代码。如果您在自己的
    Python 环境中本地安装了库和数据，也可以在 Docker 容器外运行库和数据的下载脚本。
- en: The author will be happy to receive reported issues in the code on GitHub and
    even happier to receive pull requests for any issues you discover. There is also
    an active effort to port the listings in the book to TensorFlow2\. You can find
    the current work in the tensorflow2 branch at [https://github.com/chrismattmann/MLwithTensorFlow2ed/tree/tensorflow2](https://github.com/chrismattmann/MLwithTensorFlow2ed/tree/tensorflow2).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 作者将乐意接收在 GitHub 上报告的代码问题，甚至更乐意接收您发现的任何问题的拉取请求。还有一项积极的工作正在将本书中的列表迁移到 TensorFlow2。您可以在
    tensorflow2 分支中找到当前的工作 [https://github.com/chrismattmann/MLwithTensorFlow2ed/tree/tensorflow2](https://github.com/chrismattmann/MLwithTensorFlow2ed/tree/tensorflow2)。
- en: liveBook discussion forum
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: liveBook 讨论论坛
- en: Purchase of Machine Learning with TensorFlow includes free access to a private
    web forum run by Manning Publications where you can make comments about the book,
    ask technical questions, and receive help from the author and from other users.
    To access the forum, go to [https://livebook.manning.com/book/machine-learning-with-tensorflow-second-edition/discussion](https://livebook.manning.com/book/machine-learning-with-tensorflow-second-edition/discussion).
    You can also learn more about Manning’s forums and the rules of conduct at [https://livebook.manning.com/#!/discussion](https://livebook.manning.com/#!/discussion).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 购买《TensorFlow 机器学习》包括免费访问由 Manning Publications 运营的私人网络论坛，您可以在论坛中就本书发表评论、提出技术问题，并从作者和其他用户那里获得帮助。要访问论坛，请访问
    [https://livebook.manning.com/book/machine-learning-with-tensorflow-second-edition/discussion](https://livebook.manning.com/book/machine-learning-with-tensorflow-second-edition/discussion)。您还可以在
    [https://livebook.manning.com/#!/discussion](https://livebook.manning.com/#!/discussion)
    了解更多关于 Manning 论坛和行为准则的信息。
- en: Manning’s commitment to our readers is to provide a venue where a meaningful
    dialogue between individual readers and between readers and the author can take
    place. It is not a commitment to any specific amount of participation on the part
    of the author, whose contribution to the forum remains voluntary (and unpaid).
    We suggest you try asking the author some challenging questions lest his interest
    stray! The forum and the archives of previous discussions will be accessible from
    the publisher’s website as long as the book is in print.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Manning 对读者的承诺是提供一个场所，让读者之间以及读者与作者之间可以进行有意义的对话。这并不是对作者参与特定数量活动的承诺，作者对论坛的贡献仍然是自愿的（且未支付报酬）。我们建议您尝试向作者提出一些挑战性的问题，以免他的兴趣转移！只要本书仍在印刷中，论坛和以前讨论的存档将可通过出版社的网站访问。
- en: about the author
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于作者
- en: Chris Mattmann is division manager of the Artificial Intelligence, Analytics
    and Innovative Development Organization at NASA’s Jet Propulsion Lab, where he
    has been recognized as JPL’s first principal scientist in the area of data science.
    Chris has applied TensorFlow to challenges he’s faced at NASA, including building
    an implementation of Google’s Show & Tell algorithm for image captioning using
    TensorFlow. He contributes to open source projects as a former director of the
    Apache Software Foundation and teaches graduate courses in content detection and
    analysis, as well as search engines and information retrieval, at the University
    of Southern California.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Chris Mattmann 是美国宇航局喷气推进实验室人工智能、分析和创新发展组织部门的部门经理，在那里他被认定为 JPL 数据科学领域的首位首席科学家。Chris
    将 TensorFlow 应用于他在 NASA 面临的挑战，包括使用 TensorFlow 构建谷歌 Show & Tell 算法的图像标题实现。作为 Apache
    软件基金会的前任总监，Chris 为开源项目做出了贡献，并在南加州大学教授内容检测和分析、搜索引擎和信息检索的硕士研究生课程。
- en: about the cover illustration
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于封面插图
- en: The figure on the cover of Machine Learning with TensorFlow is captioned “Man
    from the island Pag, Dalmatia, Croatia.” The illustration is taken from the reproduction,
    published in 2006, of a nineteenth-century collection of costumes and ethnographic
    descriptions titled Dalmatia by Professor Frane Carrara (1812-1854), an archaeologist
    and historian, and the first director of the Museum of Antiquity in Split, Croatia.
    The illustrations were obtained from a helpful librarian at the Ethnographic Museum
    (formerly the Museum of Antiquity), itself situated in the Roman core of the medieval
    center of Split, in the ruins of Emperor Diocletian’s retirement palace from around
    AD 304\. The book includes finely-colored illustrations of figures from different
    regions of Dalmatia, accompanied by descriptions of the costumes and of everyday
    life. Dress codes have changed since the nineteenth century, and the diversity
    by region, so rich at the time, has faded away. It is now hard to tell apart the
    inhabitants of different continents, let alone different towns or regions. Perhaps
    we have traded cultural diversity for a more varied personal life—certainly for
    a more varied and fast-paced technological life.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 《TensorFlow机器学习》的封面上的插图被标注为“来自克罗地亚达尔马提亚的帕格岛的人”。这幅插图取自2006年出版的19世纪服装和民族志描述的复制品，名为《达尔马提亚》，由考古学家和历史学家弗拉内·卡拉拉教授（1812-1854）所著，他是克罗地亚斯普利特古物博物馆的第一任馆长。插图是从斯普利特中世纪中心的罗马核心，即公元304年左右皇帝戴克里先退休宫殿的废墟中，位于民族志博物馆（原古物博物馆）的一位
    helpful librarian那里获得的。书中包含了来自达尔马提亚不同地区的精美彩色插图，并附有服装和日常生活的描述。自19世纪以来，着装规范已经改变，当时丰富的地区多样性已经消失。现在很难区分不同大陆的居民，更不用说不同的城镇或地区了。也许我们用更丰富多彩的个人生活——当然，是更丰富多彩、节奏更快的技术生活——来换取了文化多样性。
- en: At a time when it’s hard to tell one computer book from another, Manning celebrates
    the inventiveness and initiative of the computer business with book covers based
    on the rich diversity of regional life of two centuries ago, brought back to life
    by illustrations from collections such as this one.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在难以区分一本计算机书籍与另一本的时候，曼宁通过书籍封面上的设计，庆祝了计算机行业的创新精神和主动性。这些设计基于两百年前丰富多样的地区生活，通过此类收藏中的插图被重新呈现出来。
