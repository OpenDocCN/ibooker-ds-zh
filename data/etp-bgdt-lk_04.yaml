- en: Chapter 4\. Starting a Data Lake
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章\. 开始建立数据湖
- en: As discussed in the previous chapter, the promise of the data lake is to store
    the enterprise’s data in a way that maximizes its availability and accessibility
    for analytics and data science. But what’s the best way to get started? This chapter
    discusses various paths enterprises take to build a data lake.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前一章所讨论的，数据湖的承诺在于以一种最大化可用性和可访问性的方式存储企业数据，以支持分析和数据科学。但是，最佳的起步方式是什么呢？本章讨论了企业建立数据湖的各种路径。
- en: Apache Hadoop is an open source project that’s frequently used for this purpose.
    While there are many other alternatives, especially in the cloud, Hadoop-based
    data lakes provide a good representation of the advantages they provide, so we
    are going to use Hadoop as an example. We’ll begin by reviewing what it is and
    some of its key advantages for supporting a data lake.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Hadoop 是一个经常用于此目的的开源项目。虽然在云中有许多其他替代品，但基于 Hadoop 的数据湖能很好地展示它们的优势，因此我们将以
    Hadoop 作为例子。我们将从回顾其定义和支持数据湖的一些关键优势开始。
- en: The What and Why of Hadoop
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hadoop 的定义与优势
- en: Hadoop is a massively parallel storage and execution platform that automates
    many of the difficult aspects of building a highly scalable and available cluster.
    It has its own distributed filesystem, HDFS (although some Hadoop distributions,
    like MapR and IBM, provide their own filesystems to replace HDFS). HDFS automatically
    replicates data on the cluster to achieve high parallelism and availability. For
    example, if Hadoop uses the default replication factor of three, it stores each
    block on three different nodes. This way, when a job needs a block of data, the
    scheduler has a choice of three different nodes to use and can decide which one
    is the best based on what other jobs are running on it, what other data is located
    there, and so forth. Furthermore, if one of the three nodes fails, the system
    dynamically reconfigures itself to create another replica of each block that used
    to be on that node while running current jobs on the remaining two nodes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 是一个大规模并行存储和执行平台，自动化了构建高度可伸缩和可用的集群的许多困难方面。它拥有自己的分布式文件系统 HDFS（尽管一些 Hadoop
    发行版如 MapR 和 IBM 提供了自己的文件系统来替代 HDFS）。HDFS 自动在集群上复制数据，以实现高并行性和可用性。例如，如果 Hadoop 使用默认的三倍复制因子，则将每个数据块存储在三个不同的节点上。这样，当作业需要数据块时，调度程序可以选择使用三个不同的节点，并根据正在运行的其他作业以及数据位置等信息决定哪个节点最佳。此外，如果其中一个三个节点失败，系统会动态重新配置自身，以创建每个曾经位于该节点上的数据块的另一个副本，并在其余两个节点上运行当前作业。
- en: As we saw in the previous chapter, MapReduce is a programming model that has
    been implemented to run on top of Hadoop and to take advantage of HDFS to create
    massively parallel applications. It allows developers to create two types of functions,
    known as mappers and reducers. Mappers work in parallel to process the data and
    stream the results to reducers that assemble the data for final output. For example,
    a program that counts words in a file can have a mapper function that reads a
    block in a file, counts the number of words, and outputs the filename and the
    number of words it counted in that block. The reducers will then get a stream
    of word counts from the mappers and add the blocks for each file before outputting
    the final counts. An intermediate service called *sort and shuffle* makes sure
    that the word counts for the same file are routed to the same reducer. The beautiful
    thing about Hadoop is that individual MapReduce jobs do not have to know or worry
    about the location of the data, about optimizing which functions run on which
    nodes, or about which nodes failed and are being recovered—Hadoop takes care of
    all that transparently.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一章中看到的，MapReduce 是一个运行在 Hadoop 之上的编程模型，利用 HDFS 创建大规模并行应用程序。它允许开发人员创建两种类型的函数，称为
    mapper 和 reducer。Mapper 并行处理数据以计算结果，并将结果流向 reducer，用于最终输出数据。例如，一个统计文件中单词数量的程序可以有一个
    mapper 函数，读取文件中的一个数据块，计算单词数量，并输出文件名及其在该数据块中计数的单词数。Reducer 将从 mapper 接收到的单词计数流，并在输出最终计数之前将文件的各个数据块合并。一个中间服务称为
    *排序与洗牌* 确保将同一文件的单词计数路由到同一个 reducer。Hadoop 的美妙之处在于，单个 MapReduce 作业无需知道或担心数据的位置优化，也不需要关注哪些节点失败并正在恢复——Hadoop
    会在背后透明地处理所有这些事务。
- en: Apache Spark, which ships with every Hadoop distribution, provides an execution
    engine that can process large amounts of data in memory across multiple nodes.
    Spark is more efficient and easier to program than MapReduce, much better suited
    for ad hoc or near-real-time processing, and, like Map-Reduce, takes advantage
    of data locality provided by HDFS to optimize processing. Spark comes with an
    array of useful modules, like SparkSQL, which provides a SQL interface to Spark
    programs, and supports universal processing of heterogeneous data sources through
    DataFrames.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark，它随每个 Hadoop 发行版一起提供，提供了一个能够在内存中跨多个节点处理大量数据的执行引擎。Spark 比 MapReduce
    更高效且更易编程，非常适合于即席或接近实时处理，并且像 MapReduce 一样利用由 HDFS 提供的数据本地性来优化处理。Spark 还带有一系列有用的模块，如
    SparkSQL，为 Spark 程序提供了 SQL 接口，并通过 DataFrame 支持异构数据源的通用处理。
- en: 'However, the main attraction of Hadoop is that, as [Figure 4-1](#a_sample_hadoop_architecture)
    demonstrates, it is a whole platform and ecosystem of open source and proprietary
    tools that solve a wide variety of use cases. The most prominent projects include:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Hadoop 的主要吸引力在于，正如 [图 4-1](#a_sample_hadoop_architecture) 所示，它是一个完整的平台和生态系统，包括开源和专有工具，解决各种各样的使用案例。最突出的项目包括：
- en: Hive
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Hive
- en: A SQL-like interface to Hadoop files
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Hadoop 文件类似的 SQL 接口
- en: Spark
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Spark
- en: An in-memory execution system
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 内存中执行系统
- en: Yarn
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Yarn
- en: A distributed resource manager
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式资源管理器
- en: Oozie
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Oozie
- en: A workflow system
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流系统
- en: '![A sample Hadoop architecture](Images/ebdl_0401.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![一个样例 Hadoop 架构](Images/ebdl_0401.png)'
- en: Figure 4-1\. A sample Hadoop architecture
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 一个样例 Hadoop 架构
- en: 'Several properties of Hadoop make it attractive as a long-term data storage
    and management platform. These include:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 的几个特性使其作为长期数据存储和管理平台具有吸引力。这些特性包括：
- en: Extreme scalability
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 极限可扩展性
- en: At most enterprises data only grows, and often exponentially. This growth means
    more and more compute power is required to process the data. Hadoop is designed
    to keep scaling by simply adding more nodes (this is often referred to as “scaling
    out”). It is used in some of the largest clusters in the world, at companies such
    as Yahoo! and Facebook.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数企业的数据都是在不断增长的，通常呈指数增长。这种增长意味着需要更多的计算能力来处理数据。Hadoop 设计上能够通过简单地增加更多节点来保持扩展（通常被称为“横向扩展”）。它被应用在全球一些最大的集群中，如雅虎和Facebook。
- en: Cost-effectiveness
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 成本效益
- en: Hadoop is designed to work with off-the-shelf, lower-cost hardware; run on top
    of Linux; and use many free, open source projects. This makes it very cost-effective.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Hadoop 设计用于与现成的低成本硬件配合使用；运行在 Linux 之上；并使用许多免费的开源项目。这使得它非常具有成本效益。
- en: Modularity
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 模块化
- en: Traditional data management systems are monolithic. For example, in a traditional
    relational database data can only be accessed through relational queries, so if
    someone develops a better data processing tool or a faster query engine, it cannot
    leverage existing data files. RDBMSs also require tight schema control—before
    you can add any data, you have to predefine the structure of that data (called
    the schema), and you have to carefully change that structure if the data changes.
    This approach is referred to as “schema on write.” Hadoop, on the other hand,
    is designed from the ground up to be modular, so the same file can be accessed
    by any application. For example, a file might be accessed by Hive to perform a
    relational query or by a custom MapReduce job to do some heavy-duty analytics.
    This modularity makes Hadoop extremely attractive as a long-term platform for
    managing data, since new data management technologies will be able to use data
    stored in Hadoop through open interfaces.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的数据管理系统是单体化的。例如，在传统的关系数据库中，数据只能通过关系查询来访问，因此如果有人开发出更好的数据处理工具或更快的查询引擎，它无法利用现有的数据文件。关系数据库管理系统（RDBMSs）还需要严格的模式控制——在添加任何数据之前，必须预定义数据的结构（称为模式），并且如果数据发生变化，必须谨慎更改该结构。这种方法被称为“写入时模式”。另一方面，Hadoop
    从头开始设计成模块化的，因此同一个文件可以被任何应用程序访问。例如，一个文件可以被 Hive 访问以执行关系查询，或者被自定义的 MapReduce 作业访问以进行一些重型分析。这种模块化使得
    Hadoop 作为长期管理数据的平台非常有吸引力，因为新的数据管理技术可以通过开放接口使用存储在 Hadoop 中的数据。
- en: Loose schema coupling, or “schema on read”
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 松散的模式耦合，或者“读取时模式”
- en: Unlike a traditional relational database, Hadoop does not enforce any sort of
    schema when the data is written. This allows so-called *frictionless ingest*—data
    can be ingested without any checking or processing. Since we do not necessarily
    know how the data is going to be used, using frictionless ingest allows us to
    avoid the cost of processing and curating data that we may not need, and potentially
    processing it incorrectly for future applications. It is much better to leave
    the data in its original or raw state and do the work as needed when the requirements
    and use case are solidified.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统关系型数据库不同，Hadoop在写入数据时不会强制执行任何类型的模式。这使得所谓的*无摩擦摄入*成为可能——数据可以在不进行任何检查或处理的情况下被摄入。由于我们不一定知道数据将如何被使用，使用无摩擦摄入使我们能够避免处理和策划我们可能不需要的数据，并且可能会在未来的应用程序中处理不正确。将数据保留在其原始或原始状态，并在需求和用例明确时进行工作要好得多。
- en: If you’re building a long-term storage and analytics system for your data, you’ll
    want it to be cost-effective, highly scalable, and available. You’ll also want
    adding data to require minimal work, and you’ll want the system to be extensible
    to support future technologies, applications, and projects. As you can see from
    the brief preceding discussion, Hadoop fits the bill beautifully.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在为数据建立一个长期存储和分析系统，你希望它具有成本效益、高度可扩展和可用性。你还希望添加数据时需要的工作量最小化，并希望系统具有可扩展性，以支持未来的技术、应用和项目。从前文简要讨论中可以看出，Hadoop完全符合这些要求。
- en: Preventing Proliferation of Data Puddles
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 防止数据水坑的扩散
- en: With all the excitement around big data, there are many vendors and system integrators
    out there marketing immediate value to businesses. These folks often promise quick
    return on investment (ROI), with cloud-based solutions. For many business teams
    whose projects languish in IT work queues and who are tired of fighting for priority
    and attention or finding that their IT teams lack the necessary skills to do what
    they are asking, this may seem like a dream come true. In weeks or months, they
    get the projects they have been demanding from IT for years.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大数据的热潮，有许多供应商和系统集成商在市场上向企业推广即时价值。这些人经常承诺快速投资回报（ROI），提供基于云的解决方案。对于许多商业团队来说，他们的项目在IT工作队列中停滞不前，他们厌倦了为优先级和关注而战，或者发现他们的IT团队缺乏完成他们要求的技能，这可能看起来像是梦想成真。几周或几个月后，他们得到了多年来一直要求IT部门完成的项目。
- en: Many of these projects get started and produce quick wins, causing other teams
    to undertake similar projects. Pretty soon, many business groups have their own
    “shadow IT” and their own little Hadoop clusters (sometimes called data puddles)
    on premises and in the cloud. These single-purpose clusters are usually small
    and purpose-built using whatever technology the system integrators (SIs) or enterprise
    developers are familiar with, and are loaded with data that may or may not be
    rigorously sourced.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 许多这些项目开始并产生快速胜利，导致其他团队进行类似的项目。很快，许多业务组都有了自己的“影子IT”和自己的小Hadoop集群（有时被称为数据水坑），无论是在本地还是云中。这些单一用途的集群通常很小，并且是使用系统集成商（SIs）或企业开发人员熟悉的任何技术构建的，并且加载了可能或可能不严格来源的数据。
- en: The unfortunate reality of open source technology is that it is still not stable
    enough, or standard enough, for this proliferation. Once the SIs move on and the
    first major technical challenge hits—jobs don’t run, libraries need to be upgraded,
    technologies are no longer compatible—these data puddles end up being abandoned
    or get thrown back to IT. Furthermore, because data puddles create silos, it is
    difficult to reuse the data in those puddles and the results of the work done
    on that data.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 开源技术的不幸现实是，它仍然不够稳定，也不够标准化，以支持这种大规模扩散。一旦系统集成商（SIs）离开，第一个主要技术挑战出现——作业无法运行，库需要升级，技术不再兼容——这些数据水坑最终被遗弃或者被交还给IT部门。此外，由于数据水坑造成了信息孤岛，难以重新利用其中的数据以及在该数据上进行的工作的结果。
- en: 'To prevent this scenario, many enterprises prefer to get ahead of the train
    and build a centralized data lake. Then, when business teams decide that they
    need Hadoop, the compute resources and the data for their projects are already
    available in the data lake. By providing managed compute resources with preloaded
    data, yet giving users autonomy through self-service, an enterprise data lake
    gives businesses the best of both worlds: support for the components that are
    difficult for them to maintain (through the Hadoop platform and data provisioning),
    and freedom from waiting for IT before working on their projects.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止这种情况发生，许多企业更喜欢提前做好准备，建立一个集中的数据湖。然后，当业务团队决定他们需要Hadoop时，计算资源和项目所需的数据已经在数据湖中准备好了。通过提供预装数据的托管计算资源，同时通过自助服务赋予用户自主权，企业数据湖为企业提供了两全其美的最佳选择：支持难以维护的组件（通过Hadoop平台和数据供应），并免除在开展项目前等待IT的困扰。
- en: While this is a sound defensive strategy, and sometimes a necessary one, to
    take full advantage of what big data has to offer it should be combined with one
    of the strategies described in the following section.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一个合理的防御策略，有时也是必要的，但要充分利用大数据所能提供的一切，它应该与下一节中描述的策略之一相结合。
- en: Taking Advantage of Big Data
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用大数据的优势
- en: In this section, we will cover some of the most popular scenarios for data lake
    adoption. For companies where business leaders are driving the widespread adoption
    of big data, a data lake is often built by IT to try to prevent the proliferation
    of data puddles (small, independent clusters built with different technologies,
    often by SIs who are no longer engaged in the projects).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将涵盖数据湖采用的一些最流行的场景。对于那些业务领导推动大数据广泛采用的公司来说，数据湖通常由IT部门建立，以防止数据小水坑（使用不同技术构建的小型独立集群，通常是由不再参与项目的系统集成商建立）的泛滥。
- en: 'For companies trying to introduce big data, there are a few popular approaches:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于试图引入大数据的公司，有几种流行的方法：
- en: Start by offloading some existing functions to Hadoop and then add more data
    and expand into a data lake.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先将一些现有功能转移到Hadoop，然后添加更多数据并扩展到数据湖。
- en: Start with a data science initiative, show great ROI, and then expand it to
    a full data lake.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从数据科学计划开始，展示出色的投资回报率，然后将其扩展为完整的数据湖。
- en: Build the data lake from scratch as a central point of governance.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从头开始建立数据湖作为治理的中心点。
- en: Which one is right for you? That depends on the stage your company is at in
    its adoption of big data, your role, and a number of other considerations that
    we will examine in this section.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 哪一种适合你？这取决于公司在大数据采用过程中的阶段、你的角色以及我们将在本节中研究的许多其他考虑因素。
- en: Leading with Data Science
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 以数据科学为先导
- en: Identifying a high-visibility data science initiative that affects the top line
    is a very attractive strategy. *Data science* is a general term for applying advanced
    analytics and machine learning to data. Often, data warehouses that start as a
    strategic imperative promising to make the business more effective end up supporting
    reporting and operational analytics. Therefore, while data warehouses remain essential
    to running the business, they are perceived mostly as a necessary overhead, rather
    than a strategic investment. As such, they do not get respect, appreciation, or
    funding priority. Many data warehousing and analytics teams see data science as
    a way to visibly impact the business and the top line and to become strategically
    important again.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 确定一个影响公司业务前景的高能见度数据科学计划是一个非常吸引人的策略。*数据科学*是将高级分析和机器学习应用于数据的通用术语。通常，作为战略必要性起步的数据仓库最终支持报告和运营分析。因此，虽然数据仓库仍然对运行业务至关重要，但它们大多被视为必要的开销，而不是战略性投资。因此，它们没有得到尊重、认可或资金优先级。许多数据仓库和分析团队将数据科学视为能够显著影响业务和业务前景，重新成为战略重要性的一种方式。
- en: 'The most practical way to bring data science into an organization is to find
    a highly visible problem that:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据科学引入组织的最实际方法是找到一个高度可见的问题：
- en: Is well defined and well understood
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义清晰且理解透彻
- en: Can show quick, measurable benefits
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以展示快速、可衡量的好处
- en: Can be solved through machine learning or advanced analytics
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可通过机器学习或高级分析解决
- en: Requires data that the team can easily procure
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要团队能够轻松获取的数据
- en: Would be very difficult or time-consuming to solve without applying data science
    techniques
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果不应用数据科学技术，将会非常困难或耗时很长
- en: While it may seem daunting to find such a project, most organizations can usually
    identify a number of well-known, high-visibility problems that can quickly demonstrate
    benefits, taking care of the first two requirements.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然寻找这样的项目可能看起来令人生畏，但大多数组织通常能够识别出许多知名的、高能见度的问题，可以快速展示好处，满足前两个要求。
- en: 'For the third requirement, it is often possible to identify a good candidate
    in two ways: by searching industry sites and publications for other companies
    that have solved similar problems using machine learning, or by hiring experienced
    consultants who can recommend which of those problems lend themselves to machine
    learning or advanced analytics. Once one or more candidate projects have been
    selected and the data that you need to train the models or apply other machine
    learning techniques has been identified, the data sets can be reviewed in terms
    of ease of procurement. This often depends on who owns the data, access to people
    who understand the data, and the technical challenges of obtaining it.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第三个要求，通常可以通过两种方式识别出一个好的候选项目：通过搜索行业网站和出版物，了解其他公司如何使用机器学习解决类似问题，或者通过聘请经验丰富的顾问，他们可以推荐哪些问题适合机器学习或高级分析。一旦选择了一个或多个候选项目，并且确定了需要训练模型或应用其他机器学习技术的数据，就可以从获取的便利性角度审查数据集。这通常取决于数据的所有者，了解数据的人员的访问权限，以及获取数据的技术挑战。
- en: 'Some examples of common data science–driven projects for different verticals
    are:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 不同行业常见的数据科学驱动项目的一些示例包括：
- en: Financial services
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 金融服务
- en: Governance, risk management, and compliance (GRC), including portfolio risk
    analysis and ensuring compliance with a myriad of regulations (Basel 3, Know Your
    Customer, Anti Money Laundering, and many others); fraud detection; branch location
    optimization; automated trading
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 治理、风险管理和合规（GRC），包括投资组合风险分析和确保符合众多法规（巴塞尔3号、了解你的客户、反洗钱等）；欺诈检测；分支位置优化；自动化交易
- en: Healthcare
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 医疗保健
- en: Governance and compliance, medical research, patient care analytics, IoT medical
    devices, wearable devices, remote healthcare
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 治理和合规，医学研究，患者护理分析，物联网医疗设备，可穿戴设备，远程医疗
- en: Pharmaceuticals
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 制药
- en: Genome research, process manufacturing optimization
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 基因组研究，过程制造优化
- en: Manufacturing
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 制造业
- en: Collecting IoT device information, quality control, preventive maintenance,
    Industry 4.0
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 收集物联网设备信息，质量控制，预防性维护，工业4.0
- en: Education
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 教育
- en: Admissions, student success
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 招生，学生成功
- en: Retail
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 零售
- en: Price optimization, purchase recommendations, propensity to buy
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 价格优化，购买建议，购买倾向
- en: Adtech
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 广告科技
- en: Automated bidding, exchanges
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 自动出价，交易所
- en: Once a problem is identified, most organizations invest in a small Hadoop cluster,
    either on premises or in the cloud (depending on data sensitivity). They bring
    in data science consultants, run through the process, and quickly produce results
    that show the value of a data lake.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了问题，大多数组织会投资于一个小型的Hadoop集群，无论是在本地还是在云端（取决于数据的敏感性）。他们会引入数据科学顾问，经过流程，迅速产生显示数据湖价值的结果。
- en: Typically, two or three of these projects are performed, and then their success
    is used to justify a data lake. This is sometimes referred to as the “Xerox PARC”
    model. Xerox established PARC (the Palo Alto Research Center in California) to
    research “the office of the future” in 1970\. In 1971, a PARC researcher built
    the first laser printer, which became the main staple of Xerox business for years
    to come. But even though many other industry-changing technologies were invented
    at PARC, none were successfully monetized by Xerox on the scale of laser printing.
    The point of comparing data science experiments with PARC is to highlight that
    the results of data science are inherently unpredictable. For example, a long,
    complex project may produce a stable predictive model with a high rate of successful
    predictions, or the model may produce only a marginal improvement (for example,
    if the model is right 60% of the time, that’s only a 10% improvement over randomly
    choosing the outcome, which will be right 50% of the time). Basically, initial
    success on a few low-hanging-fruit projects does not guarantee large-scale success
    for a great number of other data science projects.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 通常会执行两到三个这样的项目，然后利用它们的成功来证明数据湖的必要性。这有时被称为“施乐帕克”模型。施乐成立了加州帕洛阿尔托研究中心（PARC）来研究“未来的办公室”于1970年。1971年，一位PARC研究员制造了第一台激光打印机，这成为施乐业务的主要支柱多年。但尽管PARC发明了许多其他改变行业的技术，没有一种技术像激光打印机那样成功地被施乐在如此大规模上成功商业化。将数据科学实验与PARC进行比较的重点在于突出数据科学的结果本质上是不可预测的。例如，一个长期而复杂的项目可能会产生一个稳定的预测模型，其成功预测率很高，或者模型可能只会产生轻微的改善（例如，如果模型成功率为60%，比随机选择结果的成功率高出10%）。基本上，在一些低
    hanging-fruit 项目上的初步成功并不能保证许多其他数据科学项目的大规模成功。
- en: 'This approach of investing for the future sounds good. It can be very tempting
    to build a large data lake, load it up with data, and declare victory. Unfortunately,
    I have spoken to dozens of companies where exactly such a pattern played out:
    they had a few data science pilots that quickly produced amazing results. They
    used these pilots to secure multi-million-dollar data lake budgets, built large
    clusters, loaded petabytes of data, and are now struggling to get usage or show
    additional value.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这种为未来投资的方法听起来不错。构建一个大型数据湖，加载数据，并宣布胜利，这种方法可能非常诱人。不幸的是，我曾经与许多公司交谈过，它们正是按照这种模式进行的：它们进行了一些数据科学试点项目，很快就取得了惊人的成果。它们利用这些试点项目来确保获得数百万美元的数据湖预算，建立了大型集群，加载了几百万吉字节的数据，但现在却在努力增加使用率或展示额外的价值。
- en: 'If you choose to go the analytical route, consider the following recommendations
    that a number of IT and data science leaders have shared with me:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果选择走分析路线，请考虑以下几点建议，这是许多IT和数据科学领导者与我分享的：
- en: Have a pipeline of very promising data science projects that you will be able
    to execute as you are building up the data lake to keep showing value. Ideally,
    make sure that you can demonstrate one valuable insight per quarter for the duration
    of the data lake construction.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持一个非常有前景的数据科学项目流水线，当您继续建设数据湖时，您将能够执行这些项目，以展示更多的价值。理想情况下，确保您可以在每个季度展示一个有价值的洞察，直到数据湖建设完成。
- en: Broaden the data lake beyond the original data science use cases as soon as
    possible by moving other workloads into the lake, from operational jobs like ETL
    to governance to simple BI and reporting.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽快将数据湖从最初的数据科学用例扩展到更广泛的用途，比如将其他工作负载移入湖中，从ETL到治理再到简单的BI和报告工作。
- en: Don’t try to boil the ocean right away. Keep building up the cluster and adding
    data sources as you keep showing more value.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要试图一下子解决所有问题。继续建设集群并添加数据源，同时继续展示更多的价值。
- en: Focus on getting additional departments, teams, and projects to use the data
    lake.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于让更多部门、团队和项目使用数据湖。
- en: In summary, data science is a very attractive way to get to the data lake. It
    often affects the top line, creating ROI through the value of the business insight
    and raising awareness of the value of data and the services offered by the data
    team. The key to building a successful data lake is to make sure that the team
    can continue producing such valuable insights until the data lake diversifies
    to more use cases and creates sustainable value for a wide range of teams and
    projects.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，数据科学是一种非常有吸引力的方式来利用数据湖。它通常会影响顶线，通过商业洞察的价值创造ROI，并提高数据的价值意识以及数据团队提供的服务的知名度。建立成功的数据湖的关键在于确保团队能够持续生产这样有价值的洞察，直到数据湖多样化到更多用例，并为广泛的团队和项目创造可持续的价值。
- en: 'Strategy 1: Offload Existing Functionality'
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 策略1：卸载现有功能
- en: 'One of the most compelling benefits of big data technology is its cost, which
    can be 10 or more times lower than the cost of a relational data warehouse of
    similar performance and capacity. Because the size of a data warehouse only increases,
    and IT budgets often include the cost of expansion, it is very attractive to offload
    some processing from a data warehouse instead of growing the data warehouse. The
    advantage of this approach is that it does not require a business sponsor because
    the cost usually comes entirely out of the IT budget and because the project’s
    success is primarily dependent on IT: the offloading should be transparent to
    the business users.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 大数据技术最引人注目的好处之一是其成本，可以比类似性能和容量的关系数据仓库低10倍或更多。由于数据仓库的大小只会增加，并且IT预算通常包括扩展的成本，因此将一些处理从数据仓库卸载而不是扩展数据仓库非常具有吸引力。这种方法的优势在于不需要业务赞助，因为成本通常完全由IT预算承担，并且因为项目的成功主要依赖于IT：卸载应对业务用户来说是透明的。
- en: The most common processing task to offload to a big data system is the *T* part
    of *ETL* (extract, transform, load).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 将ETL（提取、转换、加载）的*T*部分卸载到大数据系统中是最常见的处理任务。
- en: 'Teradata is the leading provider of large massively parallel data warehouses.
    For years, Teradata has been advocating an *ELT* approach to loading the data
    warehouse: extract and load the data into Teradata’s data warehouse and then transform
    it using Teradata’s powerful multi-node engines. This strategy was widely adopted
    because general ETL tools did not scale well to handle the volume of data that
    needed to be transformed. Big data systems, on the other hand, can handle the
    volume with ease and very cost-effectively. Therefore, Teradata now advocates
    doing the transformations in a big data framework—specifically, Hadoop—and then
    loading data into Teradata’s data warehouse to perform queries and analytics.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Teradata是大型大规模并行数据仓库的主要提供商。多年来，Teradata一直倡导将数据仓库的加载过程视为ELT（提取和加载数据到Teradata的数据仓库，然后使用Teradata强大的多节点引擎进行转换）。这种策略被广泛采用，因为一般的ETL工具无法有效处理需要转换的大量数据。另一方面，大数据系统可以轻松处理这些数据量，并且具有非常高的成本效益。因此，Teradata现在主张在大数据框架（特别是Hadoop）中进行转换，然后将数据加载到Teradata的数据仓库以执行查询和分析。
- en: Another common practice is to move the processing of non-tabular data to Hadoop.
    Many modern data sources, from web logs to Twitter feeds, are not tabular. Instead
    of the fixed columns and rows of relational data, they have complex data structures
    and a variety of records. These types of data can be processed very efficiently
    in Hadoop in their native format, instead of requiring conversion to a relational
    format and uploading into a data warehouse to be made available for processing
    using relational queries.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的做法是将非表格数据的处理移至Hadoop。许多现代数据来源，从网页日志到Twitter供稿，都不是表格化的。与关系数据的固定列和行不同，它们具有复杂的数据结构和各种记录。这些类型的数据可以在Hadoop中以其原生格式进行非常高效的处理，而不需要转换为关系格式并上传到数据仓库以供关系查询处理。
- en: A third class of processing that’s commonly moved to big data platforms is real-time
    or streaming processing. New technologies like Spark, which allows multi-node
    massively parallel processing of data in memory, and Kafka, a message queuing
    system, are making it very attractive to perform large-scale in-memory processing
    of data for real-time analytics, complex event processing (CEP), and dashboards.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 第三类常被转移到大数据平台的处理是实时或流式处理。像Spark这样的新技术允许在内存中进行多节点大规模并行处理数据，而Kafka则是一种消息队列系统，使得对数据进行实时分析、复杂事件处理（CEP）和仪表板非常有吸引力。
- en: Finally, big data solutions can be used to scale up existing projects at a fraction
    of the cost of legacy technologies. One company that I spoke with had moved some
    complex fraud detection processing to Hadoop. Hadoop was able to process 10 times
    more data, 10 times faster for the same compute resource cost as a relational
    database, creating orders of magnitude more accurate models and detection.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，大数据解决方案可以以比传统技术低得多的成本扩展现有项目。我曾与一家公司交流，他们将一些复杂的欺诈检测处理移至Hadoop。Hadoop能够以与关系数据库相同的计算资源成本，处理10倍更多的数据，速度也快10倍，从而创建数量级更准确的模型和检测。
- en: An example of the benefits of the move to a data lake involves a large device
    manufacturer whose devices send their logs to the factory on daily basis (these
    are called “call home logs”). The manufacturer used to process the logs and store
    just 2% of the data in a relational database to use for predictive modeling. The
    models predicted when a device would fail, when it would need maintenance, and
    so forth. Every time the log format or content changed or the analysts needed
    another piece of data for their predictive models, developers would have to change
    the processing logic and analysts would have to wait months to gather enough data
    before they could run new analytics. With Hadoop, this company is able to store
    all of the log files at a fraction of the previous cost of storing just 2%. Since
    the analysts can now access all the data as far back as they like, they can quickly
    deploy new analytics for internal data quality initiatives as well as customer-facing
    ones.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 移动到数据湖的好处的一个例子涉及一家大型设备制造商，其设备每天将其日志发送到工厂（这些称为“呼叫家庭日志”）。制造商过去会处理日志，并仅将2%的数据存储在关系数据库中，用于预测建模。模型预测设备何时会失败，何时需要维护等等。每当日志格式或内容发生变化，或分析师需要其他数据用于其预测模型时，开发人员必须更改处理逻辑，分析师必须等待几个月以收集足够的数据才能运行新的分析。使用
    Hadoop，这家公司能够以远低于之前仅存储2%数据成本的价格存储所有日志文件。由于分析师现在可以访问所有数据，无论多久以前的数据，他们可以快速为内部数据质量倡议以及面向客户的数据部署新的分析。
- en: 'Once IT teams move such automated processing to big data frameworks and accumulate
    large data sets, they come under pressure to make this data available to data
    scientists and analysts. To go from automated processing to a data lake, they
    usually have to go through the following steps:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当 IT 团队将这种自动化处理转移到大数据框架并积累大量数据集时，他们面临将这些数据提供给数据科学家和分析师的压力。要从自动化处理转向数据湖，他们通常需要经历以下步骤：
- en: Add data that’s not being processed by automated jobs to create a comprehensive
    data lake.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加未被自动作业处理的数据，创建一个全面的数据湖。
- en: Provide data access for non-programmers, enabling them to create data visualizations,
    reports, dashboards, and SQL queries.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为非程序员提供数据访问权限，使他们能够创建数据可视化、报告、仪表板和 SQL 查询。
- en: To facilitate adoption by analysts, provide a comprehensive, searchable catalog.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了促进分析师的采用，提供全面的可搜索目录。
- en: Automate the policies that govern data access, sensitive data handling, data
    quality, and data lifecycle management.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化管理数据访问、敏感数据处理、数据质量和数据生命周期管理的策略。
- en: Ensure that service-level agreements (SLAs) for automated jobs are not affected
    by the work that analysts are doing by setting up prioritized execution and resource
    governance schemes.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过设置优先执行和资源管理方案，确保自动作业的服务级别协议（SLAs）不受分析师工作的影响。
- en: 'Strategy 2: Data Lakes for New Projects'
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 策略 2：为新项目建立数据湖
- en: Instead of offloading existing functionality to a big data platform, some companies
    use it to support a new operational project, such as data science, advanced analytics,
    processing of machine data and logs from IoT devices, or social media customer
    analytics. These projects are usually driven by data science teams or line-of-business
    teams and frequently start as data puddles—small, single-purpose big data environments.
    Then, as more and more use cases are added, they eventually evolve to full-fledged
    data lakes.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 不是将现有功能卸载到大数据平台，一些公司使用它来支持新的运营项目，例如数据科学、高级分析、处理来自物联网设备的机器数据和日志，或者社交媒体客户分析。这些项目通常由数据科学团队或业务线团队推动，并经常作为数据小湖开始，即小型、单一目的的大数据环境。随着越来越多的用例被添加，它们最终演变成成熟的数据湖。
- en: In many ways, the path of starting with a new operational project is similar
    to the offloading process for an existing project. The advantage of a new project
    is that it creates new visible value for the company. The drawback is that it
    requires additional budget. Moreover, a project failure, even if it has nothing
    to do with the data lake, can taint an enterprise’s view of big data technology
    and negatively affect its adoption.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多方面，从新的运营项目开始的路径与为现有项目卸载过程类似。新项目的优势在于它为公司创造了新的显著价值。缺点是它需要额外的预算。此外，即使与数据湖无关，项目失败也可能影响企业对大数据技术的看法，并对其采用产生负面影响。
- en: 'Strategy 3: Establish a Central Point of Governance'
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 策略 3：建立中央治理点
- en: With more and more government and industry regulations and ever-stricter enforcement,
    governance is becoming a major focus for many enterprises. Governance aims at
    providing users with secure, managed access to data that complies with governmental
    and corporate regulations. It generally includes management of sensitive and personal
    data, data quality, the data lifecycle, metadata, and data lineage. ([Chapter 6](ch06.xhtml#optimizing_for_self-service)
    will go into a lot more detail on this topic.) Since governance ensures compliance
    with governmental and corporate regulations and these regulations apply to all
    systems in the enterprise, governance requires enterprises to implement and maintain
    consistent policies. Unfortunately, implementing and maintaining consistent governance
    policies across heterogeneous systems that use different technologies and are
    managed by different teams with different priorities presents a formidable problem
    for most enterprises.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 随着越来越多的政府和行业法规以及愈加严格的执法，治理正在成为许多企业的主要关注点。治理旨在为用户提供符合政府和公司法规的安全管理数据访问。它通常包括对敏感和个人数据、数据质量、数据生命周期、元数据和数据传承的管理。([第
    6 章](ch06.xhtml#optimizing_for_self-service) 将对此主题进行更详细的讨论。) 由于治理确保企业遵守政府和公司法规，而这些法规适用于企业中的所有系统，因此治理要求企业实施和维护一致的政策。不幸的是，对于大多数企业来说，跨使用不同技术的异构系统，并由不同团队管理且具有不同优先级的系统实施和维护一致的治理政策是一个严峻的问题。
- en: Data governance professionals sometimes regard big data and Hadoop as a far-removed,
    future problem. They feel that they first have to implement data governance policies
    for legacy systems before tackling new technologies. This approach, while not
    without merit, misses the opportunity of using Hadoop as a cost-effective platform
    to provide centralized governance and compliance for the enterprise.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 数据治理专业人士有时认为大数据和 Hadoop 是一个遥远的、未来的问题。他们认为他们首先必须为传统系统实施数据治理政策，然后再解决新技术的问题。虽然这种方法并非没有优点，但它忽略了使用
    Hadoop 作为成本效益平台为企业提供集中治理和合规性的机会。
- en: 'Traditionally, governance has required convincing the teams responsible for
    legacy systems to commit their limited personnel resources to retrofitting their
    systems to comply with the governance policies, and to dedicate expensive compute
    resources to executing the rules, checks, and audits associated with those policies.
    It is often much more straightforward and cost-effective to tell the teams responsible
    for legacy systems to ingest their data into Hadoop so a standard set of tools
    can implement consistent governance policies. This approach has the following
    benefits:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，治理要求说服负责传统系统的团队投入有限的人力资源来改装其系统，以符合治理政策，并且将昂贵的计算资源用于执行与这些政策相关的规则、检查和审计。通常，告诉负责传统系统的团队将其数据导入
    Hadoop，以便一套标准的工具可以实施一致的治理政策，会更为简单和经济高效。这种方法具有以下优点：
- en: Data can be profiled and processed by a standard set of data quality technologies
    with uniform data quality rules.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可以通过一套标准的数据质量技术和统一的数据质量规则进行概述和处理。
- en: Sensitive data can be detected and treated by a standard set of data security
    tools.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准的数据安全工具可以检测和处理敏感数据。
- en: Retention and eDiscovery functionality can be implemented in a uniform way across
    the systems.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保留和 eDiscovery 功能可以在各系统中以统一的方式实现。
- en: Compliance reports can be developed against a single unified system.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 合规报告可以针对单一统一系统进行开发。
- en: Furthermore, file-based big data systems such as Hadoop lend themselves well
    to the idea of *bimodal IT*, an approach that recommends creating different zones
    with different degrees of governance. By creating and keeping separate zones for
    raw and clean data, a data lake supports various degrees of governance in one
    cluster.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，基于文件的大数据系统如 Hadoop，非常适合 *双模态 IT* 的理念，该方法建议创建不同区域，具有不同程度的治理。通过为原始数据和干净数据保持分开的区域，数据湖支持同一群集中的各种治理程度。
- en: Which Way Is Right for You?
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对您来说哪种方式是正确的？
- en: Any one of these approaches can lead to a successful data lake. Which way should
    you go? It usually depends on your role, your budget, and the allies you can recruit.
    Generally, it is easiest to start a data lake by using the budget that you control.
    However, regardless of where you start, for a data lake to take off and become
    sustainable, you will need a plan to convince analysts throughout the enterprise
    to start using it for their projects.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法中的任何一种都可以导致成功的数据湖。你应该选择哪一种？通常取决于你的角色、预算以及你能招募的盟友。通常情况下，使用你控制的预算来启动一个数据湖是最容易的。然而，无论从哪里开始，要让数据湖起飞并保持可持续性，你都需要一个计划，说服企业中的分析师开始在他们的项目中使用它。
- en: If you are an IT executive or big data champion, the decision tree in [Figure 4-2](#data_lake_strategy_decision_tree)
    should help you formulate a data lake strategy.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是IT高管或者大数据的倡导者，[图4-2](#data_lake_strategy_decision_tree)中的决策树应该帮助你制定数据湖战略。
- en: 'At a high level, the steps to take are as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，需要采取的步骤如下：
- en: Determine whether there are any data puddles (i.e., are business teams using
    Hadoop clusters on their own?).
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定是否有任何数据水坑（即业务团队是否在他们自己的Hadoop集群上使用？）。
- en: If there are, are there any projects that would agree to move to a centralized
    cluster?
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果有的话，是否有任何项目愿意转移到集中式集群？
- en: If so, use the cost of the project to justify a centralized cluster.
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果是这样，使用项目成本来为集中式集群辩护。
- en: If not, justify building a data lake to avoid proliferation of data puddles.
    Use previous proliferations (e.g., data marts, reporting databases) as examples.
    If you cannot get approval, wait for puddles to run into trouble—it won’t take
    long.
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有，为了避免数据水坑的泛滥，理由充足地建设一个数据湖。可以使用先前的泛滥（例如数据集市，报告数据库）作为例子。如果你无法获得批准，那就等着水坑出问题吧——时间不会太长。
- en: If there are no data puddles, are there groups that are asking for big data
    and/or data science? If not, can you sell them on sponsoring it?
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有数据水坑，是否有团队正在寻求大数据和/或数据科学？如果没有，你能说服他们赞助吗？
- en: Look for the low-hanging fruit. Try to identify low-risk, high-visibility projects.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到低 hanging fruit。尝试识别低风险、高可见性的项目。
- en: Try to line up more than one project per team and more than one team to maximize
    the chances of success.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试为每个团队安排多个项目和多个团队，以最大化成功的机会。
- en: 'Go down the data science/analytics route:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 沿着数据科学/分析的路线走：
- en: If there are no groups ready to sponsor a big data project, is there a data
    governance initiative? If yes, try to propose and get approval for the single
    point of governance route.
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果没有团队准备赞助一个大数据项目，是否有数据治理倡议？如果有，试图提出并获得单一治理点路线的批准。
- en: Otherwise, review the top projects and identify any that require massively parallel
    computing and large data sets and would be more cost-effective using Hadoop.
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 否则，审查顶级项目，并识别任何需要大规模并行计算和大数据集，并且使用Hadoop更具成本效益的项目。
- en: Finally, find existing workloads to offload.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，找到现有的工作负载进行卸载。
- en: '![Data lake strategy decision tree](Images/ebdl_0402.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![数据湖策略决策树](Images/ebdl_0402.png)'
- en: Figure 4-2\. Data lake strategy decision tree
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-2\. 数据湖策略决策树
- en: Conclusion
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'There are many ways to get to a data lake. Although each situation is different,
    successful deployments tend to share several traits: a clear and deliberate plan,
    recruiting enthusiastic early adapters, and demonstrating immediate value.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多方法可以实现数据湖。虽然每种情况都不同，但成功的部署通常会分享几个特征：明确和有计划的计划，招募热情的早期采用者，并展示即时价值。
