- en: 'Chapter 19\. Blastomatic: Parsing Delimited Text Files'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第19章。Blastomatic：解析分隔文本文件
- en: Delimited text files are a standard way to encode columnar data. You are likely
    familiar with spreadsheets like Microsoft Excel or Google Sheets, where each worksheet
    may hold a dataset with columns across the top and records running down. You can
    export this data to a text file where the columns of data are *delimited*, or
    separated by a character. Quite often the delimiter is a comma, and the file will
    have an extension of *.csv*. This format is called *CSV*, for *comma-separated
    values*. When the delimiter is a tab, the extension may be *.tab*, *.txt*, or
    *.tsv* for *tab-separated values*. The first line of the file usually will contain
    the names of the columns. Notably, this is not the case with the tabular output
    from BLAST (Basic Local Alignment Search Tool), one of the most popular tools
    in bioinformatics used to compare sequences. In this chapter, I will show you
    how to parse this output and merge the BLAST results with metadata from another
    delimited text file using the `csv` and `pandas` modules.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分隔文本文件是编码列数据的一种标准方式。你可能熟悉类似于Microsoft Excel或Google Sheets的电子表格，其中每个工作表可能包含具有跨顶部的列和向下运行的记录的数据集。您可以将这些数据导出为文本文件，其中数据的列是*分隔的*，或者由一个字符分隔。很多时候，分隔符是逗号，文件的扩展名为*.csv*。这种格式称为*CSV*，代表*逗号分隔的值*。当分隔符是制表符时，扩展名可能为*.tab*，*.txt*或*.tsv*，代表*制表符分隔的值*。文件的第一行通常包含列的名称。值得注意的是，这不适用于来自BLAST（基本局部比对搜索工具）的表格输出，BLAST是生物信息学中最流行的工具之一，用于比较序列。在本章中，我将向您展示如何解析此输出，并使用`csv`和`pandas`模块将BLAST结果与另一个分隔文本文件中的元数据合并。
- en: 'In this exercise, you will learn:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将学到：
- en: How to use `csvkit` and `csvchk` to view delimited text files
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用`csvkit`和`csvchk`查看分隔文本文件
- en: How to use the `csv` and `pandas` modules to parse delimited text files
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用`csv`和`pandas`模块解析分隔文本文件
- en: Introduction to BLAST
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: BLAST简介
- en: The BLAST program is one of the most ubiquitous tools in bioinformatics for
    determining sequence similarity. In [Chapter 6](ch06.html#ch06), I showed how
    the Hamming distance between two sequences is one measure of similarity and compared
    this to the concept of alignment. Whereas the Hamming distance compares both sequences
    starting from the beginning, an alignment with BLAST starts wherever both sequences
    begin to overlap and will allow for insertions, deletions, and mismatches to find
    the longest possible areas of similarity.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: BLAST程序是生物信息学中用于确定序列相似性的最普遍工具之一。在[第6章](ch06.html#ch06)中，我展示了两个序列之间的Hamming距离是相似性的一种度量，并将其与对齐概念进行了比较。而Hamming距离从开头比较两个序列，BLAST的对齐则从两个序列开始重叠的地方开始，并允许插入、删除和不匹配以找到最长可能的相似区域。
- en: I’ll show you the National Center for Biotechnology (NCBI) BLAST web interface,
    but you can use `blastn` if you have BLAST installed locally. I will compare 100
    sequences from the [Global Ocean Sampling Expedition (GOS)](https://oreil.ly/POkOV)
    to a sequence database at NCBI. GOS is one of the earliest metagenomic studies,
    dating from the early 2000s when Dr. Craig Venter funded a two-year expedition
    to collect and analyze ocean samples from around the globe. It’s a *metagenomic*
    project because the genetic material was taken directly from an environmental
    sample. The purpose of using BLAST is to compare the unknown GOS sequences to
    known sequences at NCBI to determine their possible taxonomic classification.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我将向您展示国家生物技术中心（NCBI）的BLAST网络界面，但如果您在本地安装了BLAST，也可以使用`blastn`。我将比较来自[全球海洋采样探险（GOS）](https://oreil.ly/POkOV)的100个序列与NCBI的序列数据库。GOS是最早的宏基因组研究之一，始于2000年代初，当时克雷格·文特博士资助了一项为期两年的远征，收集和分析来自全球各地海洋样本。这是一个*宏基因组*项目，因为遗传物质直接来自环境样本。使用BLAST的目的是将未知的GOS序列与NCBI中已知的序列进行比较，以确定其可能的分类。
- en: 'I used the FASTX sampler from [Chapter 18](ch18.html#ch18) to randomly select
    the 100 input sequences in *tests/inputs/gos.fa*:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用了来自[第18章](ch18.html#ch18)的FASTX采样器，随机选择了*tests/inputs/gos.fa*中的100个输入序列：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I used [the NCBI BLAST tool](https://oreil.ly/gXErw) to compare these sequences
    to the *nr/nt* (nonredundant nucleotide) database using the `blastn` program to
    compare nucleotides. The results page allows me to select the detailed results
    for each of the 100 sequences. As shown in [Figure 19-1](#fig_19.1), the first
    sequence has four *hits* or matches to known sequences. The first and best hit
    is about 93% identical over 99% of its length to a portion of the genome of [*Candidatus
    Pelagibacter*](https://oreil.ly/qywN2), a marine bacteria of the SAR11 clade.
    Given that the GOS query sequence came from the ocean, this seems a likely match.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用[NCBI BLAST工具](https://oreil.ly/gXErw)将这些序列与*nr/nt*（非冗余核苷酸）数据库进行比较，使用`blastn`程序比较核苷酸。结果页面允许我选择每个100个序列的详细结果。如[Figure 19-1](#fig_19.1)所示，第一个序列有四个匹配到已知序列的*hits*。第一个和最佳匹配在其长度的99%上与[*Candidatus
    Pelagibacter*](https://oreil.ly/qywN2)的某部分基因组大约相似度达到93%。考虑到GOS查询序列来自海洋，这看起来是一个合理的匹配。
- en: '![mpfb 1901](assets/mpfb_1901.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![mpfb 1901](assets/mpfb_1901.png)'
- en: Figure 19-1\. The first GOS sequence has four possible matches from nr/nt
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 19-1\. 第一个GOS序列在nr/nt中有四个可能的匹配
- en: '[Figure 19-2](#fig_19.2) shows how similar the query sequence is to a region
    of the *Candidatus Pelagibacter* genome. Notice how the alignment allows for single-nucleotide
    variations (SNVs) and gaps caused by deletions or insertions between the sequences.
    If you want to challenge yourself, try writing a sequence aligner. You can see
    an example in [Figure 19-2](#fig_19.2).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[Figure 19-2](#fig_19.2)展示了查询序列与*Candidatus Pelagibacter*基因组区域的相似程度。请注意，对齐允许单核苷酸变异（SNVs）以及由序列之间的删除或插入引起的间隙。如果你想挑战自己，请尝试编写一个序列比对工具。你可以在[Figure 19-2](#fig_19.2)中看到一个例子。'
- en: '![mpfb 1902](assets/mpfb_1902.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![mpfb 1902](assets/mpfb_1902.png)'
- en: Figure 19-2\. The alignment of the top BLAST hit
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 19-2\. 最佳BLAST匹配的比对结果
- en: 'As interesting as it is to explore each individual hit, I want to download
    a table of all the hits. There is a Download All menu with 11 download formats.
    I chose the “Hit table(csv)” format and split this data into *hits1.csv* and *hits2.csv*
    in the *tests/inputs* directory:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管逐个探索每个匹配很有趣，但我想下载所有匹配的表格。有一个下载所有菜单，提供11种下载格式。我选择了“Hit table(csv)”格式，并在*tests/inputs*目录下拆分为*hits1.csv*和*hits2.csv*：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you open these files with a text editor, you’ll see they contain comma-separated
    values. You can also open a file with a spreadsheet program like Excel to see
    the data in columnar format, and you may notice that the columns are not named.
    If you were on a remote machine like a cluster node, you would likely not have
    access to a graphical program like Excel to inspect the results. Further, Excel
    is limited to about 1 million rows and 16,000 columns. In real-world bioinformatics,
    it’s pretty easy to exceed both of those values, so I’ll show you command-line
    tools you can use to look at delimited text files.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用文本编辑器打开这些文件，你会看到它们包含逗号分隔的值。你也可以用类似Excel的电子表格程序打开文件，以列格式查看数据，并且你可能会注意到这些列没有名称。如果你在像群集节点这样的远程机器上，可能无法访问像Excel这样的图形程序来检查结果。此外，Excel仅限于大约100万行和16000列。在真实的生物信息学中，很容易超过这两个值，因此我将向你展示一些命令行工具，可以用来查看分隔文本文件。
- en: Using csvkit and csvchk
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用csvkit和csvchk
- en: 'First, I’d like to introduce the `csvkit` module, “a suite of command-line
    tools for converting to and working with CSV.” The *requirements.txt* file for
    the repo lists this as a dependency, so it’s probably installed. If not, you can
    use this command to install it:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我想介绍一下`csvkit`模块，“用于转换和处理CSV的命令行工具套件”。存储库的*requirements.txt*文件列出了这个依赖项，所以它可能已经安装。如果没有安装，你可以使用这个命令来安装它：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will install several useful utilities, and I encourage you to read [the
    documentation](https://oreil.ly/QDAn2) to learn about them. I want to highlight
    `csvlook`, which “renders a CSV file in the console as a Markdown-compatible,
    fixed-width table.” Run **`csvlook --help`** to view the usage and notice there
    is an `-H|--no-header-row` option to view files that have no header row. The following
    command will display the first three rows of the hits table. Depending on the
    size of your screen, this might be unreadable:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这将安装几个有用的工具，我鼓励你阅读[文档](https://oreil.ly/QDAn2)以了解它们。我想强调`csvlook`，它“在控制台中将CSV文件渲染为Markdown兼容的固定宽度表格”。运行**`csvlook
    --help`**以查看用法，并注意有一个`-H|--no-header-row`选项，可以查看没有标题行的文件。以下命令将显示前三行匹配表格。根据你的屏幕大小，这可能无法阅读：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The [`csvchk` program](https://oreil.ly/T2QSo) will transpose a wide record
    like this to a tall one vertically oriented with the column names on the left
    rather than across the top. This, too, should have been installed with other module
    dependencies, but you can use `pip` to install it if needed:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[`csvchk`程序](https://oreil.ly/T2QSo)将一个宽记录转置为一个纵向以列名在左侧而不是在顶部的竖向记录。这也应该已经安装了其他模块依赖项，但如果需要，你可以使用`pip`来安装它：'
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If you read the usage, you’ll see that this tool also has an `-N|--noheaders`
    option. Use `csvchk` to inspect the first record in the same hits file:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你阅读了使用说明，你会发现这个工具还有一个`-N|--noheaders`选项。使用`csvchk`检查相同的hits文件中的第一条记录：
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output files you can download from NCBI BLAST match the output formats
    from the command-line versions of the BLAST programs, like `blastn` for comparing
    nucleotides, `blastp` for comparing proteins, etc. The help documentation for
    `blastn` includes an `-outfmt` option to specify the output format using a number
    between 0 and 18. The preceding output file format is the “Tabular” option 6:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从NCBI BLAST下载的输出文件与BLAST程序的命令行版本匹配，比如用于比较核苷酸的`blastn`，用于比较蛋白质的`blastp`等等。`blastn`的帮助文档包含一个`-outfmt`选项，用于指定输出格式，使用介于0到18之间的数字。前面的输出文件格式是“制表符”选项6：
- en: '[PRE6]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You may find yourself wondering why the tabular output file does not contain
    the column headers. If you read through all the formatting options, you may notice
    that output format 7 is “Tabular with comment lines,” and you may ask yourself:
    Is this the option that will include the column names? Dear reader, you will be
    sorely disappointed to learn it does not.^([1](ch19.html#idm45963626663048)) Option
    7 is the same as the “Hits table(text)” option on the NCBI BLAST page. Download
    and open that file to see that it contains metadata about the search as unstructured
    text on lines that begin with the `#` character. Because so many languages (including
    Python) use this as a comment character to indicate a line that should be ignored,
    it’s common to say that the metadata is *commented out*, and many delimited text
    parsers will skip these lines.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当你发现制表输出文件不包含列标题时，你可能会感到奇怪。如果你仔细阅读所有的格式选项，你可能会注意到输出格式7是“带有注释行的制表符”，然后你可能会问自己：这个选项会包含列名吗？亲爱的读者，你会非常失望地发现它并不会。选项7与NCBI
    BLAST页面上的“Hits table(text)”选项相同。下载并打开该文件，你会发现它包含有关搜索的元数据，这些元数据以`#`字符开头的行中以非结构化文本形式存在。由于许多语言（包括Python）使用这个作为注释字符来指示应该忽略的行，因此通常会说元数据被*注释掉*，许多分隔文本解析器将跳过这些行。
- en: 'So what are the column names? I must parse through hundreds of lines of the
    `blastn` usage to find that “Options 6, 7, 10 and 17 can be additionally configured”
    to include any of 53 optional fields. If the fields are not specified, then the
    default fields are as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 那么列名是什么呢？我必须解析`blastn`使用说明的数百行才能找到“选项6、7、10和17可以被另外配置”以包含任意的53个可选字段。如果未指定字段，则默认字段如下：
- en: '`qaccver`: Query sequence accession/ID'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qaccver`: 查询序列访问号/ID'
- en: '`saccver`: Subject sequence accession/ID'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`saccver`: 主体序列访问号/ID'
- en: '`pident`: Percentage of identical matches'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pident`: 相同匹配的百分比'
- en: '`length`: Alignment length'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`length`: 对齐长度'
- en: '`mismatch`: Number of mismatches'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mismatch`: 不匹配数'
- en: '`gapopen`: Number of gap openings'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gapopen`: 缺口开放数'
- en: '`qstart`: Start of alignment in query'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qstart`: 在查询中对齐的开始位置'
- en: '`qend`: End of alignment in query'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`qend`: 在查询中对齐的结束位置'
- en: '`sstart`: Start of alignment in subject'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sstart`: 在主体中对齐的开始位置'
- en: '`send`: End of alignment in subject'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`send`: 在主体中对齐的结束位置'
- en: '`evalue`: Expect value'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`evalue`: 期望值'
- en: '`bitscore`: Bit score'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bitscore`: 比特分数'
- en: 'If you look again at the usage for `csvchk`, you’ll find there is an option
    to name the `-f|--fieldnames` for the record. Following is how I could view the
    first record from a hits file and specify column names:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你再次查看`csvchk`的用法，你会发现有一个选项可以为记录命名`-f|--fieldnames`。以下是我如何查看一个hits文件的第一条记录并指定列名的方式：
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This is a much more useful output. If you like this command, you can create
    an alias called `blstchk` in `bash`, like so:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个更有用的输出。如果你喜欢这个命令，你可以在`bash`中创建一个名为`blstchk`的别名，就像这样：
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Most shells allow you to define aliases like this in a file that is read each
    time you start a new shell. In `bash`, you could add this line to a file in your
    `$HOME` directory, like *.bash_profile*, *.bashrc*, or *.profile*. Other shells
    have similar properties. Aliases are a handy way to create global shortcuts for
    common commands. If you wish to create a command shortcut inside a particular
    project or directory, consider using a target in a *Makefile*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 shell 允许您在每次启动新 shell 时读取的文件中定义别名，比如在 `bash` 中，您可以将这一行添加到您的 `$HOME` 目录中的一个文件中，比如
    *.bash_profile*、*.bashrc* 或 *.profile*。其他 shell 也有类似的属性。别名是一个方便的方法，用于为常用命令创建全局快捷方式。如果您希望在特定项目或目录中创建命令快捷方式，请考虑在
    *Makefile* 中使用目标。
- en: 'Here is how I use the `blstchk` command:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我如何使用 `blstchk` 命令的方式：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The goal of the program in this chapter is to link the BLAST hits to the depth
    and location of the GOS sequences found in the file *tests/inputs/meta.csv*. I
    will use the `-g|--grep` option to `csvchk` to find the preceding query sequence,
    *CAM_READ_0234442157*:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 本章程序的目标是将 BLAST 命中链接到文件 *tests/inputs/meta.csv* 中找到的 GOS 序列的深度和位置。我将使用 `-g|--grep`
    选项来 `csvchk` 查找前一个查询序列，*CAM_READ_0234442157*：
- en: '[PRE10]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The BLAST results can be joined to the metadata where the former’s `qseqid`
    is equal to the latter’s `seq_id`. There is a command-line tool called `join`
    that will do exactly this. The inputs must both be sorted, and I will use the
    `-t` option to indicate that the comma is the field delimiter. By default, `join`
    assumes the first column in each file is the common value, which is true here.
    The output is a comma-separated union of the fields from both files:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: BLAST 结果可以与元数据结合，其中前者的 `qseqid` 等于后者的 `seq_id`。有一个命令行工具叫做 `join`，会精确执行此操作。输入必须都排序过，我会使用
    `-t` 选项指示逗号是字段分隔符。默认情况下，`join` 假定每个文件的第一列是公共值，这在这里是正确的。输出是两个文件字段的逗号分隔的联合：
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO1-1)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO1-1)'
- en: The two positional inputs to `join` use shell redirection `<` to read in the
    results of sorting the two input files. The output from `join` is piped to `csvchk`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 shell 重定向 `<` 读取排序后的两个输入文件的结果作为 `join` 的两个位置输入。`join` 的输出被导向到 `csvchk`。
- en: Although it’s good to know how to use `join`, this output is not particularly
    useful because it does not have the column headers. (Also, the point is to learn
    how to do this in Python.) How might you add headers to this information? Would
    you cobble together some shell commands in a `bash` script or a *Makefile* target,
    or would you write a Python program? Let’s keep moving, shall we? Next, I’ll show
    you how the program should work and the output it will create.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然了解如何使用 `join` 是好的，但是此输出并不特别有用，因为它没有列标题。（而且，重点是学习如何在 Python 中执行此操作。）您如何向此信息添加标题？您会在
    `bash` 脚本或 *Makefile* 目标中拼凑一些 shell 命令，还是会编写一个 Python 程序？让我们继续前进，好吗？接下来，我将向您展示程序应该如何工作以及它将创建的输出。
- en: Getting Started
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门指南
- en: 'All the code and tests for this exercise can be found in the *19_blastomatic*
    directory of the repository. Change to this directory and copy the second solution
    to the program `blastomatic.py`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此练习的所有代码和测试都可以在存储库的 *19_blastomatic* 目录中找到。切换到此目录并将第二个解决方案复制到程序 `blastomatic.py`：
- en: '[PRE12]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The program will accept the BLAST hits and the metadata file and will produce
    an output file showing the sequence ID, the percent identity match, the depth,
    and the latitude and longitude of the sample. Optionally, the output can be filtered
    by the percent identity. Request help from the program to see the options:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序将接受 BLAST 命中和元数据文件，并将生成一个输出文件，显示序列 ID、百分比身份匹配、深度以及样品的纬度和经度。可选择性地，输出可以按百分比身份进行过滤。请求程序的帮助以查看选项：
- en: '[PRE13]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO2-1)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO2-1)'
- en: The tabular output file from a BLAST search in `-outfmt 6`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 `-outfmt 6` 中的 BLAST 搜索的表格输出文件。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO2-2)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO2-2)'
- en: An annotations file with metadata about the sequences.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关于序列的元数据的注释文件。
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO2-3)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO2-3)'
- en: The name of the output file, which defaults to *out.csv*.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 输出文件的名称，默认为 *out.csv*。
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO2-4)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO2-4)'
- en: The output file delimiter, which defaults to a guess based on the output file
    extension.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 输出文件的分隔符，默认根据输出文件扩展名猜测。
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO2-5)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO2-5)'
- en: The minimum percent identity, which defaults to `0`.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最小百分比标识，默认为 `0`。
- en: 'If I run the program using the first hits file, it will write 500 sequences
    to the output file *out.csv*:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我使用第一个命中文件运行程序，则会将 500 条序列写入输出文件 *out.csv*：
- en: '[PRE14]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'I can use `csvlook` with the `--max-rows` option to view the first two rows
    of the table:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以使用 `csvlook` 和 `--max-rows` 选项查看表格的前两行：
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Or I can use `csvchk` with `-l|--limit` to do the same:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 或者我可以使用 `-l|--limit` 选项与 `csvchk` 进行相同操作：
- en: '[PRE16]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If I want to only export hits with a percent identity greater than or equal
    to 90%, I can use the `-p|--pctid` option to find that only 190 records are found:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我只想导出百分比标识大于或等于 90% 的命中记录，我可以使用 `-p|--pctid` 选项找出仅有 190 条记录：
- en: '[PRE17]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'I can peek at the file to see that it appears to have selected the correct
    data:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以查看文件，确认它似乎已选择了正确的数据：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `blastomatic.py` program defaults to writing the output to the comma-separated
    file *out.csv*. You can use the `-d|--delimiter` option to specify a different
    delimiter and the `-o|--outfile` option to specify a different file. Note that
    the delimiter will be guessed from the extension of the output filename if it
    is not specified. The extension *.csv* will be taken to mean commas, and otherwise
    tabs will be used.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`blastomatic.py` 程序默认将输出写入逗号分隔的文件 *out.csv*。您可以使用 `-d|--delimiter` 选项指定不同的分隔符，并使用
    `-o|--outfile` 选项指定不同的文件。请注意，如果未指定分隔符，将从输出文件名的扩展名猜测分隔符。扩展名 *.csv* 将被视为逗号，否则将使用制表符。'
- en: 'Run **`make test`** to see the full test suite. When you think you understand
    how the program should work, start anew:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 **`make test`** 来查看完整的测试套件。当您认为理解程序应如何工作时，请重新开始：
- en: '[PRE19]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Defining the Arguments
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义参数
- en: 'Here is the class I used to define my arguments:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我用来定义参数的类：
- en: '[PRE20]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO3-1)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO3-1)'
- en: The BLAST hits file will be an open filehandle.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: BLAST 命中文件将是一个打开的文件句柄。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO3-2)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO3-2)'
- en: The metadata file will be an open filehandle.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据文件将是一个打开的文件句柄。
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO3-3)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO3-3)'
- en: The output file will be an open filehandle.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 输出文件将是一个打开的文件句柄。
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO3-4)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO3-4)'
- en: The output file delimiter will be a string.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 输出文件分隔符将是一个字符串。
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO3-5)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO3-5)'
- en: The percent identity will be a floating-point number.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 百分比标识将是一个浮点数。
- en: 'Here is how I parse and validate the arguments:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我解析和验证参数的方式：
- en: '[PRE21]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO4-1)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO4-1)'
- en: The BLAST file must be a readable text file.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: BLAST 文件必须是可读的文本文件。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO4-2)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO4-2)'
- en: The metadata file must be a readable text file.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据文件必须是可读的文本文件。
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO4-3)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO4-3)'
- en: The output file must be a writable text file.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 输出文件必须是可写的文本文件。
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO4-4)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO4-4)'
- en: The output field delimiter is a string that defaults to the empty string I will
    guess from the output filename.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 输出字段分隔符是一个字符串，默认为我从输出文件名中猜测的空字符串。
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO4-5)'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO4-5)'
- en: The minimum percent identity should be a floating-point number that defaults
    to `0`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最小百分比标识应为浮点数，默认为 `0`。
- en: '[![6](assets/6.png)](#co_blastomatic__parsing_delimited_text_files_CO4-6)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_blastomatic__parsing_delimited_text_files_CO4-6)'
- en: Create the `Args` object. Note that the fields of `Args` do not need to match
    the parameter names.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 `Args` 对象。请注意，`Args` 的字段不需要与参数名匹配。
- en: '[![7](assets/7.png)](#co_blastomatic__parsing_delimited_text_files_CO4-7)'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_blastomatic__parsing_delimited_text_files_CO4-7)'
- en: I wrote a function to guess the delimiter from the output filename.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我编写了一个函数，从输出文件名中猜测分隔符。
- en: 'This program has two required file arguments: the BLAST hits, and the annotations.
    I don’t want to make these positional arguments because then my user would have
    to remember the order. It’s better to have these as named options, but then they
    become optional, which I don’t want either. To overcome this, I use `required=True`
    for both the file parameters to ensure the user supplies them.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序有两个必需的文件参数：BLAST hits和注释。我不想将它们作为位置参数，因为那样我的用户必须记住顺序。最好将它们作为命名选项，但这样它们就变成了可选的，而我不想这样。为了克服这个问题，我对两个文件参数都使用了`required=True`，以确保用户提供它们。
- en: 'You might like to start with the `guess_delimiter()` function. Here is the
    test I wrote:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想从`guess_delimiter()`函数开始。这是我编写的测试：
- en: '[PRE22]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Start your `main()` with some minimal code that will work:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一些最小的代码来启动你的`main()`：
- en: '[PRE23]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Verify that this works:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 确保这个工作：
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: At this point, you should be able to pass several tests when you run **`make
    test`**. Next, I’ll show you how to parse the delimited text files.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，当你运行**`make test`**时，你应该能够通过几个测试。接下来，我将向你展示如何解析分隔文本文件。
- en: Parsing Delimited Text Files Using the csv Module
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用csv模块解析分隔文本文件
- en: 'Python has a `csv` module that will handle delimited text files easily, but
    I would first like to show you exactly what it’s doing so you can appreciate how
    much effort it saves. To begin, I will open the metadata file and read the headers
    from the first line. I can call the `fh.readline()` method on a filehandle to
    read one line of text. This will still have the newline attached, so I call `str.rstrip()`
    to remove any whitespace from the right side of the string. Finally, I call `str.split('','')`
    to break the line on the delimiting comma:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Python有一个`csv`模块，可以轻松处理分隔文本文件，但我想首先向你展示它确切的操作，这样你就能够欣赏它节省的努力。首先，我将打开元数据文件并从第一行读取头部。我可以在文件句柄上调用`fh.readline()`方法来读取一行文本。这将仍然包含换行符，因此我调用`str.rstrip()`来移除字符串右侧的任何空白。最后，我调用`str.split(',')`来使用分隔逗号拆分行：
- en: '[PRE25]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'So far, so good. I’ll try parsing the next line of data:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 目前为止，一切都好。我将尝试解析下一行数据：
- en: '[PRE26]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Can you see a problem here? I have split the `lat_lon` field, which contains
    a comma, into two values, giving me eight values for seven fields:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你能看到这里的问题吗？我已经将包含逗号的`lat_lon`字段分割成了两个值，给我七个字段的八个值：
- en: '[PRE27]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Using `str.split()` will not work because it fails to consider when the separator
    is part of the field value. That is, when the field separator is enclosed in quotes,
    it’s not a field separator. Notice that the `lat_lon` value is properly quoted:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`str.split()`将无法正常工作，因为它未考虑分隔符是字段值的一部分的情况。也就是说，当字段分隔符被引号括起来时，它不是字段分隔符。注意`lat_lon`值被正确地引用：
- en: '[PRE28]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'One way to correctly parse this line uses the `pyparsing` module:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一种正确解析这一行的方法是使用`pyparsing`模块：
- en: '[PRE29]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'That’s close, but the `lat_lon` field still has the quotes around it. I can
    use a regular expression to remove them:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 差不多了，但是`lat_lon`字段周围仍然有引号。我可以使用正则表达式将它们移除：
- en: '[PRE30]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO5-1)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO5-1)'
- en: This regular expression replaces a quote anchored to either the beginning or
    the end of a string with the empty string.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这个正则表达式将锚定在字符串开头或结尾的引号替换为空字符串。
- en: 'Now that I have a list of the `headers` and a list of the `data` for a given
    record, I could create a dictionary by zipping these together. I’ve used the `zip()`
    function in Chapters [6](ch06.html#ch06) and [13](ch13.html#ch13) to join two
    lists into a list of tuples. Because `zip()` is a lazy function, I must use the
    `list()` function in the REPL to force the evaluation:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我已经得到了`headers`列表和给定记录的`data`列表，我可以通过将它们压缩在一起创建一个字典。我在第[6](ch06.html#ch06)章和第[13](ch13.html#ch13)章中使用了`zip()`函数将两个列表连接成元组的列表。因为`zip()`是一个惰性函数，我必须在REPL中使用`list()`函数来强制求值：
- en: '[PRE31]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'I can change the `list()` function to `dict()` to turn this into a dictionary:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以将`list()`函数改为`dict()`来将其转换为字典：
- en: '[PRE32]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'I could iterate through each line of the file and create a dictionary of the
    records by zipping the headers and data. That would work just fine, but all this
    work has already been done for me in the `csv` module. Following is how I can
    parse the same file into a list of dictionaries using `csv.DictReader()`. By default,
    it will use the comma as the delimiter:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以迭代文件的每一行，并通过压缩头部和数据创建记录的字典。这样做完全可行，但是所有这些工作在`csv`模块中已经为我完成。以下是如何使用`csv.DictReader()`将同一文件解析为字典列表。默认情况下，它将使用逗号作为分隔符：
- en: '[PRE33]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'That’s much easier. Here’s how I might use this to create a dictionary of all
    the annotations keyed on the sequence ID. Be sure to add `from pprint import pprint`
    for this:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这样就容易多了。以下是我如何使用它来创建以序列 ID 为键的所有注释的字典。为此，请确保添加 `from pprint import pprint`：
- en: '[PRE34]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO6-1)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO6-1)'
- en: Use `csv.DictReader()` to parse the CSV data in the annotations filehandle.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `csv.DictReader()` 解析注释文件句柄中的 CSV 数据。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO6-2)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO6-2)'
- en: Use a dictionary comprehension to create a dictionary keyed on the `seq_id`
    field from each record.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 使用字典推导式创建以每个记录中的 `seq_id` 字段为键的字典。
- en: 'Run this with the input files and see if you get a reasonable-looking data
    structure. Here I’ll redirect `STDOUT` to a file called *out* and use `head` to
    inspect it:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用输入文件运行此程序，并查看是否获得一个看起来合理的数据结构。在这里，我将 `STDOUT` 重定向到名为 *out* 的文件，并使用 `head`
    进行检查：
- en: '[PRE35]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Before I move on to reading the BLAST hits, I’d like to open the output filehandle.
    The format of the output file should be another delimited text file. By default
    it will be a CSV file, but the user may choose something else, like a tab separator.
    The first line of the file should be the headers, so I’ll immediately write those:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续阅读 BLAST 命中结果之前，我想打开输出文件句柄。输出文件的格式应该是另一个分隔文本文件。默认情况下，它将是一个 CSV 文件，但用户可以选择其他格式，如制表符分隔。文件的第一行应该是标题行，因此我将立即写入这些内容：
- en: '[PRE36]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO7-1)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO7-1)'
- en: These are the output file’s column names.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是输出文件的列名。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO7-2)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO7-2)'
- en: '`args.outfile` is a filehandle opened for writing text. Write the headers joined
    on the `args.delimiter` string. Be sure to add a newline.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '`args.outfile` 是用于写入文本的文件句柄。在 `args.delimiter` 字符串上连接标题并写入。请务必添加换行符。'
- en: 'Alternatively, you could use `print()` with a `file` argument:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用带有 `file` 参数的 `print()`：
- en: '[PRE37]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Next, I’ll cycle through the BLAST hits. It’s necessary to supply the `fieldnames`
    to `csv.DictReader()` since the first line of the file is missing the column names:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我将遍历 BLAST 命中结果。由于文件的第一行缺少列名，因此需要为 `csv.DictReader()` 提供 `fieldnames`：
- en: '[PRE38]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO8-1)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO8-1)'
- en: Parse the BLAST CSV file.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 解析 BLAST CSV 文件。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO8-2)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO8-2)'
- en: Iterate through each BLAST hit.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代处理每个 BLAST 命中结果。
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO8-3)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO8-3)'
- en: Skip those hits where the percent ID is less than the minimum. Use the `float()`
    function to convert the text to a floating-point value.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 跳过百分比 ID 小于最小值的命中结果。使用 `float()` 函数将文本转换为浮点值。
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO8-4)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO8-4)'
- en: Print the query sequence ID.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 打印查询序列 ID。
- en: 'Run this version of the program with a minimum percent ID of 90, and verify
    that you get 190 hits from the first file:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 使用最小百分比 ID 为 90 运行此版本的程序，并验证您是否从第一个文件中获得了 190 个命中结果：
- en: '[PRE39]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: If the BLAST hit’s `qseqid` value is found as a `seq_id` in the metadata file,
    then print to the output file the sequence ID, the percent ID from the BLAST hit,
    and the depth and latitude/longitude values from the metadata file. That should
    be enough to get you rolling on this program. Be sure to run the tests to verify
    that your program is correct.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在元数据文件中以 BLAST 命中的 `qseqid` 值作为 `seq_id` 找到，则将序列 ID、来自 BLAST 命中的百分比 ID 以及来自元数据文件的深度和纬度/经度值打印到输出文件中。这应该足以让您开始运行此程序。请务必运行测试以验证您的程序是否正确。
- en: Parsing Delimited Text Files Using the pandas Module
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 pandas 模块解析分隔文本文件
- en: The pandas module presents another effective way to read a delimited file. This
    module, along with NumPy, is one of the foundational Python libraries used in
    data science. I’ll use the `pd.read_csv()` function, which closely resembles the
    `read_csv()` function from the R programming language, if you are familiar with
    that. Note that the function can read text delimited by any delimiter you specify
    using a `sep` field separator, but the default is a comma.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: pandas模块提供了另一种有效的方法来读取分隔文件。 这个模块与NumPy一起是数据科学中使用的基本Python库之一。 如果您熟悉R语言，我将使用`pd.read_csv()`函数，它与R语言中的`read_csv()`函数非常相似。
    注意，该函数可以读取由任何分隔符指定的文本，但默认为逗号。
- en: 'Normally the delimiter is a single character, but it’s possible to split text
    using a string. If you do this, you may encounter the warning “ParserWarning:
    Falling back to the *python* engine because the *c* engine does not support regex
    separators (separators > 1 char and different from *\s+* are interpreted as regex);
    you can avoid this warning by specifying engine=*python*.”'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '通常分隔符是单个字符，但也可以使用字符串拆分文本。 如果这样做，您可能会遇到警告“ParserWarning: Falling back to the
    *python* engine because the *c* engine does not support regex separators (separators
    > 1 char and different from *\s+* are interpreted as regex); you can avoid this
    warning by specifying engine=*python*.”'
- en: 'It’s common to import pandas with the alias `pd`:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 通常使用别名`pd`导入pandas是很常见的：
- en: '[PRE40]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Much of pandas is based on ideas from R. A pandas dataframe is a two-dimensional
    object that holds all the columns and rows of the metadata file in a single object,
    just like a dataframe in R. That is, the `reader` in the previous example is an
    interface used to sequentially retrieve each of the records, but the pandas dataframe
    is a full representation of all the data from the file. As such, the size of a
    dataframe will be limited to the amount of memory on your computer. Just as I’ve
    warned about using `fh.read()` to read an entire file into memory, you must be
    judicious about which files can be practically read using pandas. If you must
    process millions of rows of delimited text in gigabyte-sized files, I would recommend
    using `cvs.DictReader()` to process one record at a time.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: pandas的许多功能都基于R的思想。 pandas数据框是一个二维对象，它将元数据文件中的所有列和行都保存在一个单独的对象中，就像R中的数据框一样。
    也就是说，前面示例中的`reader`是用于顺序检索每个记录的接口，但pandas数据框是文件中所有数据的完整表示。 因此，数据框的大小将受到计算机内存量的限制。
    就像我警告过使用`fh.read()`将整个文件读入内存一样，您必须谨慎选择使用pandas可以实际读取的文件。 如果必须处理数百万行大小为千兆字节的分隔文本文件，我建议使用`csv.DictReader()`逐条处理记录。
- en: 'If you evaluate the `meta` object in the REPL, a sample of the table will be
    shown. You can see that pandas used the first row of the file for the column headers.
    As indicated by ellipses, some of the columns have been elided due to the constrained
    width of the screen:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在REPL中评估`meta`对象，则会显示表格的样本。 您可以看到pandas使用文件的第一行作为列标题。 如省略号所示，由于屏幕宽度受限，一些列已被省略：
- en: '[PRE41]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'To find the number of rows and columns in a dataframe, inspect the `meta.shape`
    attribute. Note that this is not followed by parentheses because it is not a method
    call. This dataframe has 100 rows and 7 columns:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 要查找数据框中行数和列数，请检查`meta.shape`属性。 注意，这不需要加括号，因为它不是方法调用。 此数据框有100行和7列：
- en: '[PRE42]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'I can inspect the `meta.columns` attribute for the column names:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以检查`meta.columns`属性获取列名：
- en: '[PRE43]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'One advantage to dataframes is that you can query all the values from a column
    using a syntax that looks like accessing a field in a dictionary. Here I’ll select
    the salinity values, and note that pandas has converted the values from text to
    floating-point values, with missing values represented, with `NaN` (not a number):'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框的一个优点是，您可以使用类似于访问字典中字段的语法查询列中的所有值。 在这里，我将选择盐度值，并注意pandas已将这些值从文本转换为浮点值，缺失值用`NaN`（不是数字）表示：
- en: '[PRE44]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'I can find the rows with a salinity greater than 50 using syntax almost identical
    to that in R. This returns an array of Boolean values based on the predicate *salinity
    is greater than 50*:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以使用几乎与R中相同的语法找到盐度大于50的行。 这将根据断言*盐度大于50*返回一个布尔值数组：
- en: '[PRE45]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'I can use these Booleans values as a mask to only select the rows where this
    condition is `True`:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以使用这些布尔值作为掩码，仅选择条件为`True`的行：
- en: '[PRE46]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The result is a new dataframe, so I could then look at the salinity values
    that were found:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个新的数据框，所以我可以查看找到的盐度值：
- en: '[PRE47]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'If you read the BLAST hits file with pandas, you will need to supply the column
    names as you did in the previous example:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用pandas读取BLAST hits文件，需要像之前的示例一样提供列名：
- en: '[PRE48]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'One element of this program is to select only those hits with a percent ID
    greater than or equal to some minimum. pandas will automatically convert the `pident`
    column to a floating-point value. Here I will select those hits with a percent
    ID greater than or equal to `90`:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的一个要素是仅选择那些百分比ID大于或等于某个最小值的命中结果。pandas会自动将`pident`列转换为浮点数值。在这里，我将选择那些百分比ID大于或等于`90`的命中结果：
- en: '[PRE49]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'To iterate over the rows in a dataframe, use the `wanted.iterrows()` method.
    Note that this works like the `enumerate()` function in that it returns a tuple
    of the row index and the row value:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要遍历数据框中的行，使用`wanted.iterrows()`方法。请注意，这与`enumerate()`函数类似，返回的是行索引和行值的元组：
- en: '[PRE50]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'To print a single field from a record in the dataframe, you can treat the record
    like a dictionary using field access through square brackets or by using the familiar
    `dict.get()` method. As with dictionaries, the first method will create an exception
    if you misspell a field name, while the latter method will quietly return `None`:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 要从数据框中打印出单个记录的字段，你可以像使用字典一样使用方括号访问字段或者使用熟悉的`dict.get()`方法。与字典类似，前一种方法如果拼写错误将会抛出异常，而后一种方法会静默地返回`None`：
- en: '[PRE51]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'As in the previous example, I recommend you first read the metadata and then
    iterate through the BLAST hits. You can look up the metadata from the `meta` dataframe
    by searching over the `seq_id` field. The sequence IDs in the metadata file are
    unique, so you should only find at most one:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如同前面的示例一样，我建议你先阅读元数据，然后迭代BLAST命中。你可以通过在`meta`数据框中搜索`seq_id`字段来查找元数据。元数据文件中的序列ID是唯一的，所以你应该最多只找到一个：
- en: '[PRE52]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'You can either iterate over the matches or use the `iloc` accessor to get the
    first (zeroth) record:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以遍历匹配项，或者使用`iloc`访问器获取第一个（零号）记录：
- en: '[PRE53]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'If you fail to find any matches, you will get an empty dataframe:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未找到任何匹配项，你将得到一个空的数据框：
- en: '[PRE54]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'You can inspect the `seqs.empty` attribute to see if it’s empty:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以检查`seqs.empty`属性来查看它是否为空：
- en: '[PRE55]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'or inspect the rows value from `seqs.shape`:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 或者从`seqs.shape`中检查行数值：
- en: '[PRE56]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Dataframes can also write their values to a file using the `to_csv()` method.
    As with `read_csv()`, you can specify any `sep` field separator, and the default
    is the comma. Note that by default pandas will include the row index as the first
    field of the output file. I generally use `index=False` to omit this. For example,
    I’ll save the metadata records with a salinity greater than 50 to the *salty.csv*
    file with one line of code:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 数据框也可以使用`to_csv()`方法将其值写入文件。与`read_csv()`类似，你可以指定任何`sep`字段分隔符，默认为逗号。注意，默认情况下，pandas会将行索引包括在输出文件的第一个字段中。我通常使用`index=False`来省略这个。例如，我将保存盐度大于50的元数据记录到*salty.csv*文件中只需一行代码：
- en: '[PRE57]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'I can verify that the data was written using `csvchk` or `csvlook`:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以使用`csvchk`或`csvlook`验证数据是否已写入：
- en: '[PRE58]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: A thorough review of pandas is well beyond the scope of this book, but this
    should be enough for you to figure out a solution. If you would like to learn
    more, I recommend [*Python for Data Analysis*](https://oreil.ly/kAtUU) by Wes
    McKinney (O’Reilly, 2017) and [*Python Data Science Handbook*](https://oreil.ly/1V94U)
    by Jake VanderPlas (O’Reilly, 2016).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 对pandas的全面审查远远超出了本书的范围，但这应该足以让你找到一个解决方案。如果你想了解更多，我推荐阅读[*Python数据分析*](https://oreil.ly/kAtUU)（Wes
    McKinney著，O’Reilly，2017）和[*Python数据科学手册*](https://oreil.ly/1V94U)（Jake VanderPlas著，O’Reilly，2016）。
- en: Solutions
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'I have four solutions, two using the `csv` module and two using pandas. All
    of the solutions use the same `guess_delimiter()` function, which I wrote like
    this:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我有四种解决方案，两种使用`csv`模块，另外两种使用pandas。所有解决方案均使用我编写的`guess_delimiter()`函数，代码如下：
- en: '[PRE59]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO9-1)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO9-1)'
- en: Select the file extension from `os.path.splitext()`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 从`os.path.splitext()`中选择文件扩展名。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO9-2)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO9-2)'
- en: Return a comma if the file extension is *.csv* and the tab character otherwise.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果文件扩展名是*.csv*，则返回逗号，否则返回制表符。
- en: 'Solution 1: Manually Joining the Tables Using Dictionaries'
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案 1：使用字典手动连接表格
- en: 'This version closely follows all the suggestions from earlier in the chapter:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 此版本紧随本章章节早期的所有建议：
- en: '[PRE60]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO10-1)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO10-1)'
- en: Create a parser for the annotations file.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 创建注释文件的解析器。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO10-2)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO10-2)'
- en: Read all the annotations into a dictionary keyed on the sequence ID.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有注释读入以序列 ID 为键的字典中。
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO10-3)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO10-3)'
- en: Define the headers of the output file.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 定义输出文件的标头。
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO10-4)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO10-4)'
- en: Write the headers to the output file.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 将标头写入输出文件。
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO10-5)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO10-5)'
- en: Create a parser for the BLAST hits.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 BLAST 命中的解析器。
- en: '[![6](assets/6.png)](#co_blastomatic__parsing_delimited_text_files_CO10-6)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_blastomatic__parsing_delimited_text_files_CO10-6)'
- en: Initialize a counter for the number of records written.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化记录写入计数器。
- en: '[![7](assets/7.png)](#co_blastomatic__parsing_delimited_text_files_CO10-7)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_blastomatic__parsing_delimited_text_files_CO10-7)'
- en: Iterate through the BLAST hits.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历 BLAST 命中。
- en: '[![8](assets/8.png)](#co_blastomatic__parsing_delimited_text_files_CO10-8)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](assets/8.png)](#co_blastomatic__parsing_delimited_text_files_CO10-8)'
- en: Skip records with a percent ID less than the minimum.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 跳过百分比 ID 小于最小值的记录。
- en: '[![9](assets/9.png)](#co_blastomatic__parsing_delimited_text_files_CO10-9)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '[![9](assets/9.png)](#co_blastomatic__parsing_delimited_text_files_CO10-9)'
- en: Attempt to get the BLAST query sequence ID.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试获取 BLAST 查询序列 ID。
- en: '[![10](assets/10.png)](#co_blastomatic__parsing_delimited_text_files_CO10-10)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '[![10](assets/10.png)](#co_blastomatic__parsing_delimited_text_files_CO10-10)'
- en: Attempt to find this sequence ID in the annotations.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试在注释中找到此序列 ID。
- en: '[![11](assets/11.png)](#co_blastomatic__parsing_delimited_text_files_CO10-11)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '[![11](assets/11.png)](#co_blastomatic__parsing_delimited_text_files_CO10-11)'
- en: If found, increment the counter and write the output values.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 如果找到，则增加计数器并写入输出值。
- en: '[![12](assets/12.png)](#co_blastomatic__parsing_delimited_text_files_CO10-12)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '[![12](assets/12.png)](#co_blastomatic__parsing_delimited_text_files_CO10-12)'
- en: Quote all the fields to ensure the delimiter is protected.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 引用所有字段以确保分隔符受保护。
- en: '[![13](assets/13.png)](#co_blastomatic__parsing_delimited_text_files_CO10-13)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '[![13](assets/13.png)](#co_blastomatic__parsing_delimited_text_files_CO10-13)'
- en: Close the output file.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭输出文件。
- en: '[![14](assets/14.png)](#co_blastomatic__parsing_delimited_text_files_CO10-14)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[![14](assets/14.png)](#co_blastomatic__parsing_delimited_text_files_CO10-14)'
- en: Print a final status to the user. The comma in the formatting for `num_written`
    will add a thousands separator to the number.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 向用户打印最终状态。在 `num_written` 格式化的逗号将为数字添加千位分隔符。
- en: 'Solution 2: Writing the Output File with csv.DictWriter()'
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案 2：使用 `csv.DictWriter()` 编写输出文件
- en: 'This next solution differs from the first only in that I use `csv.DictWriter()`
    to write the output file. I generally prefer to use this method as it will handle,
    for instance, properly quoting fields that contain the field separator:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个解决方案与第一个的不同之处在于我使用 `csv.DictWriter()` 编写输出文件。我通常更喜欢使用这种方法，因为它将处理，例如，包含字段分隔符的字段正确引用：
- en: '[PRE61]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO11-1)'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO11-1)'
- en: Create a writer object to create the delimited text output file.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个写入器对象来创建分隔文本输出文件。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO11-2)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO11-2)'
- en: Write the header row to the output file.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 将标头行写入输出文件。
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO11-3)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO11-3)'
- en: Write a row of data, passing in a dictionary with the same keys as the `fieldnames`
    defined for the writer.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 写入一行数据，传入一个与编写器定义的 `fieldnames` 键相同的字典。
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO11-4)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO11-4)'
- en: The formatting instruction `{:,}` will cause the number to be printed with thousands
    separators.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 使用格式化指令`{:,}`将使数字以千位分隔符打印。
- en: 'Solution 3: Reading and Writing Files Using pandas'
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案 3：使用 Pandas 读写文件
- en: 'The pandas version is a little simpler in some ways and a little more complicated
    in others. I chose to store all the output records in a Python list and instantiate
    a new dataframe from that to write the output file:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些方面，Pandas 版本更为简单，而在其他方面则更为复杂。我选择将所有输出记录存储在 Python 列表中，并从中实例化新的数据帧以编写输出文件：
- en: '[PRE62]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO12-1)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO12-1)'
- en: Read the metadata file into a dataframe.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 将元数据文件读入数据框。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO12-2)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO12-2)'
- en: Read the BLAST hits into a dataframe.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 将 BLAST 命中读入数据框。
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO12-3)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO12-3)'
- en: Initialize a list for the output data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化输出数据的列表。
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO12-4)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO12-4)'
- en: Select all the BLAST hits with a percent ID greater than or equal to the minimum
    percent.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 选择所有百分比 ID 大于或等于最小百分比的 BLAST 命中。
- en: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO12-5)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_blastomatic__parsing_delimited_text_files_CO12-5)'
- en: Select the metadata for the given query sequence ID.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 选择给定查询序列 ID 的元数据。
- en: '[![6](assets/6.png)](#co_blastomatic__parsing_delimited_text_files_CO12-6)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_blastomatic__parsing_delimited_text_files_CO12-6)'
- en: Verify that the metadata is not empty.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 验证元数据不为空。
- en: '[![7](assets/7.png)](#co_blastomatic__parsing_delimited_text_files_CO12-7)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](assets/7.png)](#co_blastomatic__parsing_delimited_text_files_CO12-7)'
- en: Iterate over the metadata records (even though there should only be one).
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代元数据记录（尽管通常只有一个）。
- en: '[![8](assets/8.png)](#co_blastomatic__parsing_delimited_text_files_CO12-8)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](assets/8.png)](#co_blastomatic__parsing_delimited_text_files_CO12-8)'
- en: Store a new dictionary with the output data.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 使用输出数据存储一个新的字典。
- en: '[![9](assets/9.png)](#co_blastomatic__parsing_delimited_text_files_CO12-9)'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '[![9](assets/9.png)](#co_blastomatic__parsing_delimited_text_files_CO12-9)'
- en: Create a new dataframe from the output data.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出数据创建一个新的数据框。
- en: '[![10](assets/10.png)](#co_blastomatic__parsing_delimited_text_files_CO12-10)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '[![10](assets/10.png)](#co_blastomatic__parsing_delimited_text_files_CO12-10)'
- en: Write the dataframe to the output file, omitting the dataframe index values.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据框写入输出文件，省略数据框索引值。
- en: '[![11](assets/11.png)](#co_blastomatic__parsing_delimited_text_files_CO12-11)'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '[![11](assets/11.png)](#co_blastomatic__parsing_delimited_text_files_CO12-11)'
- en: Print the status to the console.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 将状态打印到控制台。
- en: 'Solution 4: Joining Files Using pandas'
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案 4：使用 pandas 连接文件
- en: 'In this last solution, I use pandas to join the metadata and BLAST dataframes,
    much like the `join` program I illustrated earlier in the chapter:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后的解决方案中，我使用 pandas 将元数据和 BLAST 数据框进行连接，就像我在本章早些时候演示的 `join` 程序一样：
- en: '[PRE63]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO13-1)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_blastomatic__parsing_delimited_text_files_CO13-1)'
- en: Read the annotations file and set the index column to `seq_id`.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 读取注释文件并将索引列设置为 `seq_id`。
- en: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO13-2)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_blastomatic__parsing_delimited_text_files_CO13-2)'
- en: Read the BLAST hits and set the index column to `qseqid`.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 读取 BLAST 命中并将索引列设置为 `qseqid`。
- en: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO13-3)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_blastomatic__parsing_delimited_text_files_CO13-3)'
- en: Select the BLAST hits with the desired percent ID, and perform an inner join
    to the annotations using the index columns.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 选择具有所需百分比 ID 的 BLAST 命中，并使用索引列对注释执行内连接。
- en: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO13-4)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_blastomatic__parsing_delimited_text_files_CO13-4)'
- en: Write the desired columns of the `joined` dataframe to the output file using
    the indicated delimiter. Include the index and name it `qseqid`.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 使用指定的分隔符将 `joined` 数据框的所需列写入输出文件。包括索引并命名为 `qseqid`。
- en: 'The join operation is quite complex, so let me take a moment to explain this.
    First, each dataframe must have a unique index, which by default is the row index:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 连接操作非常复杂，让我花点时间解释一下。首先，每个数据框必须具有唯一的索引，默认情况下是行索引：
- en: '[PRE64]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Instead, I want pandas to use the `seq_id` column as the index, which I indicate
    with the `index_col` argument:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我希望 pandas 使用 `seq_id` 列作为索引，我使用 `index_col` 参数指定：
- en: '[PRE65]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'I can also indicate the zeroth field:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我也可以指示零字段：
- en: '[PRE66]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Now the index is set to the `seq_id`:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 现在索引设置为 `seq_id`：
- en: '[PRE67]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Similarly, I want the BLAST hits to be indexed on the query sequence ID:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我希望 BLAST 命中可以根据查询序列 ID 进行索引：
- en: '[PRE68]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'I can select the BLAST hits with `pident` greater than or equal to the minimum.
    For instance, I find 190 rows with a value of 90:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以选择具有 `pident` 大于或等于最小值的 BLAST 命中。例如，我找到了值为 90 的 190 行：
- en: '[PRE69]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: The resulting dataframe is still indexed on the `qseqid` column, so I can join
    it to the annotations where the index values (the sequence IDs) are in common.
    By default, pandas will perform a *left* *join*, selecting all the rows from the
    first or *left* dataframe and substituting null values for rows that have no mate
    in the right dataframe. A *right join* is the opposite of a left join, selecting
    all the records from the *right* dataframe regardless of matches to the left.
    Since I only want the hits that have annotations, I use an *inner* *join*. [Figure 19-3](#fig_19.3)
    demonstrates the joins using Venn diagrams.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 结果数据框仍然以`qseqid`列为索引，因此我可以将其与具有相同索引值（序列 ID）的注释进行连接。默认情况下，pandas 将执行*左* *连接*，选择第一个或*左*数据框中的所有行，并对没有在右数据框中找到配对的行填充空值。*右*
    *连接*与*左*连接相反，选择*右*数据框中的所有记录，而不考虑左数据框中是否有匹配。由于我只想要具有注释的命中，所以我使用*内* *连接*。[图 19-3](#fig_19.3)演示了使用维恩图进行连接的情况。
- en: '![mpfb 1903](assets/mpfb_1903.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![mpfb 1903](assets/mpfb_1903.png)'
- en: Figure 19-3\. A left join selects all the records from the left table, a right
    joins selects all the records from the right table, and an inner join selects
    only those records present in both
  id: totrans-315
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图19-3\. 左连接选择左表中的所有记录，右连接选择右表中的所有记录，内连接仅选择两者都有的记录
- en: 'The join operation creates a new dataframe with the columns of both dataframes,
    just like the `join` tool I showed in [“Using csvkit and csvchk”](#ch19-using-csvkit-and-csvchk):'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 连接操作创建一个新的数据框，其中包含两个数据框的所有列，就像我在 [“使用 csvkit 和 csvchk”](#ch19-using-csvkit-and-csvchk)
    中展示的`join`工具一样：
- en: '[PRE70]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Another way to write this is to use the `pd.merge()` function, which will default
    to an inner join. I must indicate which columns to use for the joins from the
    left and right dataframes, which in this case are the indexes:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种写法是使用`pd.merge()`函数，默认情况下会执行内连接。我必须指示左右数据框中用于连接的列，这种情况下是索引：
- en: '[PRE71]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'I can use the `joined.to_csv()` method to write the dataframe to the output
    file. Note that the common sequence IDs are the index, which has no column name.
    I want the index included in the output file, so I use `index=True` and `index_name=''qseqid''`
    so that the file matches the expected output:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以使用`joined.to_csv()`方法将数据框写入输出文件。请注意，共同的序列 ID 是索引，没有列名。我希望索引包含在输出文件中，因此我使用`index=True`和`index_name='qseqid'`以使文件与预期输出匹配：
- en: '[PRE72]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Going Further
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更进一步
- en: Add the options to filter by other fields like temperature, salinity, or BLAST
    e-value.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 添加按其他字段（如温度、盐度或 BLAST e 值）过滤的选项。
- en: Default to including all the columns from both files in the output file, and
    add an option to select a subset of the columns.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 默认包含输出文件中来自两个文件的所有列，并添加一个选项来选择列的子集。
- en: Review
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复习
- en: 'Key points from this chapter:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点：
- en: Shell aliases can be used to create shortcuts for common commands.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shell 别名可用于为常见命令创建快捷方式。
- en: Delimited text files do not always have column headers. This is the case with
    BLAST’s tabular output formats.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分隔文本文件不总是包含列标题。BLAST 的表格输出格式就是这种情况。
- en: The `csv` and `pandas` modules can read and write delimited text files.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`csv` 和 `pandas` 模块可以读取和写入分隔文本文件。'
- en: Datasets can be joined on common columns using the `join` command-line tool
    or in Python by using common keys from dictionaries or common indexes in pandas
    dataframes.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用`join`命令行工具或在 Python 中使用字典的共同键或 pandas 数据框的共同索引来连接数据集中的共同列。
- en: pandas is a good choice for reading delimited files if you need access to all
    the data in memory—for example, if you need to perform statistical analysis of
    the data or want to quickly access all the values for a column. If you need to
    parse very large delimited files and can process records independently, then use
    the `csv` module for better performance.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您需要在内存中访问所有数据（例如，进行数据的统计分析或快速访问某列的所有值），pandas 是读取分隔文件的良好选择。如果您需要解析非常大的分隔文件并可以独立处理记录，则使用`csv`模块以获得更好的性能。
- en: ^([1](ch19.html#idm45963626663048-marker)) You may say to yourself, “My God!
    What have they done?”
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch19.html#idm45963626663048-marker)) 你可能会自言自语地说，“我的天啊！他们到底做了什么？”
