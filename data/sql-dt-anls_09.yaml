- en: Chapter 9\. Conclusion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 9 章 总结
- en: Throughout the book, we’ve seen how SQL is a flexible and powerful language
    for a range of data analysis tasks. From data profiling to time series, text analysis,
    and anomaly detection, SQL can tackle a number of common requirements. Techniques
    and functions can also be combined in any given SQL statement to perform experiment
    analysis and build complex data sets. While SQL can’t accomplish all analysis
    goals, it fits well into the ecosystem of analysis tools.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们看到 SQL 是一个灵活而强大的语言，可用于各种数据分析任务。从数据概要到时间序列、文本分析和异常检测，SQL 可以处理许多常见需求。可以在任何给定的
    SQL 语句中组合技巧和函数，以进行实验分析并构建复杂数据集。虽然 SQL 不能实现所有分析目标，但它非常适合分析工具生态系统。
- en: In this final chapter, I’ll discuss a few additional types of analysis and point
    out how various SQL techniques covered in the book can be combined to accomplish
    them. Then I’ll wrap up with some resources that you can use to continue your
    journey of mastering data analysis or to dig deeper into specific topics.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个最终章节中，我将讨论一些额外的分析类型，并指出本书涵盖的各种 SQL 技术如何结合起来完成它们。然后我将用一些资源结束，这些资源可以帮助你继续掌握数据分析之旅，或者深入研究特定主题。
- en: Funnel Analysis
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 漏斗分析
- en: A funnel consists of a series of steps that must be completed to reach a defined
    goal. The goal might be registering for a service, completing a purchase, or obtaining
    a course completion certificate. Steps in a website purchase funnel, for example,
    might include clicking the “Add to Cart” button, filling out shipping information,
    entering a credit card, and finally clicking the “Place Order” button.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 漏斗由一系列必须完成的步骤组成，以达到一个明确定义的目标。目标可能是注册服务、完成购买或获得课程完成证书。例如，网站购买漏斗中的步骤可能包括点击“添加到购物车”按钮、填写送货信息、输入信用卡，最后点击“下单”按钮。
- en: Funnel analysis combines elements of time series analysis, discussed in [Chapter 3](ch03.xhtml#time_series_analysis),
    and cohort analysis, discussed in [Chapter 4](ch04.xhtml#cohort_analysis). The
    data for funnel analysis comes from a time series of events, although in this
    case those events correspond to distinct real-world actions rather than being
    repetitions of the same event. Measuring retention from step to step is a key
    goal of funnel analysis, although in this context we often use the term *conversion*.
    Typically, entities drop out along the steps of the process, and a graph of their
    number at each stage ends up looking like a household funnel—hence the name.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 漏斗分析结合了时间序列分析（详见[第 3 章](ch03.xhtml#time_series_analysis)）和队列分析（详见[第 4 章](ch04.xhtml#cohort_analysis)）的元素。漏斗分析的数据来自事件的时间序列，尽管在这种情况下，这些事件对应于不同的现实行为，而不是相同事件的重复。从一步到另一步的留存率是漏斗分析的一个关键目标，尽管在这种情况下，我们经常使用术语*转化*。通常，实体在流程的各个步骤中退出，并且每个阶段的实体数量的图表看起来像一个家庭漏斗—
    因此得名。
- en: This type of analysis is used to identify areas of friction, difficulty, or
    confusion. Steps at which large numbers of users drop out, or that many fail to
    complete, provide insight into opportunities for optimization. For example, a
    checkout process that asks for credit card information before showing the total
    amount including shipping might turn off some would-be purchasers. Showing the
    total before this step may encourage more purchase completions. Such changes are
    often subjects of experiments, discussed in [Chapter 7](ch07.xhtml#experiment_analysis).
    Funnels can also be monitored in order to detect unexpected external events. For
    example, changes in completion rates might correspond to good (or bad) PR or to
    a change in the pricing or tactics of a competitor.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 此类型的分析用于识别摩擦、困难或混淆的领域。大量用户退出或许多用户未完成的步骤提供了优化机会。例如，一个在显示包括运费在内的总金额之前要求信用卡信息的结账流程可能会拒绝一些潜在购买者。在此步骤之前显示总金额可能促进更多完整的购买。这些变化通常是实验的主题，详情请参阅[第
    7 章](ch07.xhtml#experiment_analysis)。漏斗也可以监测以便检测意外的外部事件。例如，完成率的变化可能对应于良好（或不良）的公关活动，或竞争对手的定价或策略的变化。
- en: The first step in a funnel analysis is to figure out the base population of
    all users, customers, or other entities that were eligible to enter the process.
    Next, assemble the data set of completion for each step of interest, including
    the final goal. Often this includes one or more *LEFT JOIN*s in order to include
    all of the base population, along with those who completed each step. Then `count`
    the users in each step and divide these step-wise counts by the total `count`.
    There are two ways to set up the queries, depending on whether all steps are required.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 漏斗分析的第一步是确定所有有资格进入过程的用户、客户或其他实体的基础人口。接下来，组装每个感兴趣步骤的完成数据集，包括最终目标。通常这包括一个或多个*LEFT
    JOIN*，以包括所有基础人口，以及完成每个步骤的人。然后，通过总`count`来计算每个步骤中的用户，并将这些步骤计数按总`count`进行分割。有两种设置查询的方法，取决于是否需要所有步骤。
- en: 'When all steps in the funnel are required—or if you only want to include users
    who have completed all steps—*LEFT JOIN* each table to the previous table:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当漏斗中的所有步骤都是必需的，或者如果您只想包括已完成所有步骤的用户时，将每个表*LEFT JOIN*到前一个表格：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When users can skip a step, or if you want to allow for this possibility, *LEFT
    JOIN* each table to the one containing the full population and calculate the share
    of that starting group:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户可以跳过一步时，或者如果您希望允许这种可能性时，将每个表*LEFT JOIN*到包含完整人群的表格，并计算该起始组的份额：
- en: '[PRE1]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It’s a subtle difference, but it’s one worth paying attention to and tailoring
    to the specific context. Consider including time boxes, to only include users
    who complete an action within a specific time frame, if users can reenter the
    funnel after a lengthy absence. Funnel analyses can also include additional dimensions,
    such as cohort or other entity attributes, to facilitate comparisons and generate
    additional hypotheses about why a funnel is or is not performing well.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个微妙的差别，但值得注意并根据具体情况进行调整。考虑包括时间框，只包括在特定时间范围内完成动作的用户，如果用户在长时间后可以重新进入漏斗。漏斗分析还可以包括其他维度，例如队列或其他实体属性，以促进比较并生成关于为何漏斗表现良好或不佳的额外假设。
- en: Churn, Lapse, and Other Definitions of Departure
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流失、停滞和其他离开的定义
- en: The topic of churn came up in [Chapter 4](ch04.xhtml#cohort_analysis), since
    churn is  essentially the opposite of retention. Often organizations want or need
    to come up with a specific definition of churn in order to measure it directly.
    In some cases, there is a contractually defined end date, such as with B2B software.
    But often churn is a fuzzier concept, and a time-based definition is more appropriate.
    Even when there is a contractual end date, measuring when a customer stops using
    a product can be an early warning sign of an imminent contract cancellation. Churn
    definitions can also be applied to certain products or features, even when the
    customer doesn’t churn from the organization entirely.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](ch04.xhtml#cohort_analysis)中讨论了流失的话题，因为流失本质上是留存的相反。通常组织希望或需要为了直接衡量而制定流失的具体定义。在某些情况下，有合同规定的结束日期，例如B2B软件。但通常流失是一个模糊的概念，基于时间的定义更为合适。即使存在合同结束日期，测量客户停止使用产品的时间也可以是即将取消合同的预警信号。流失定义也可以应用于某些产品或功能，即使客户并未完全从组织中流失。
- en: A time-based churn metric counts customers as churned when they haven’t purchased
    or interacted with a product for a period of time, usually ranging from 30 days
    to as much as a year. The exact length depends a lot on the type of business and
    on typical usage patterns. To arrive at a good churn definition, you can use gap
    analysis to find typical periods between purchases or usage. To do gap analysis,
    you will need a time series of actions or events, the `lag` window function, and
    some date math.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于时间的流失指标是在客户在一段时间内没有购买或与产品互动时算作流失，通常范围从30天到一年不等。确切的时间长度很大程度上取决于业务类型和典型的使用模式。要得出良好的流失定义，您可以使用间隔分析来找到购买或使用之间的典型时间段。要进行间隔分析，您将需要一系列动作或事件的时间序列，`lag`窗口函数以及一些日期数学。
- en: 'As an example, we can calculate the typical gaps between representatives’ terms,
    using the legislators data set introduced in [Chapter 4](ch04.xhtml#cohort_analysis).
    We’ll ignore the fact that politicians are often voted out of office rather than
    choosing to leave, since otherwise this data set has the right structure for this
    type of analysis. First we’ll find the average gap. To do this, we create a subquery
    that calculates the gap between the `start_date` and the previous `start_date`
    for each legislator for each term, and then we find the average value in the outer
    query. The previous `start_date` can be found using the `lag` function, and the
    gap as a time interval is calculated with the `age` function:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，我们可以计算代表们任期间的典型间隔，使用[第4章](ch04.xhtml#cohort_analysis)中介绍的议员数据集。我们将忽略政客通常被选出而不是选择离开的事实，因为除此之外，该数据集具有进行此类分析的正确结构。首先，我们将找到平均间隔。为此，我们创建一个子查询，计算每位立法者每个任期的`start_date`与上一个`start_date`之间的间隔，然后在外部查询中找到平均值。可以使用`lag`函数找到上一个`start_date`，并使用`age`函数计算间隔作为时间间隔：
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As we might expect, the average is close to two years, which makes sense since
    the term length for this office is two years. We can also create a distribution
    of gaps in order to pick a realistic churn threshold. In this case, we’ll transform
    the gap to months:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所预期的那样，平均值接近两年，这是合理的，因为该职位的任期长度为两年。我们还可以创建间隔的分布以选择一个现实的流失阈值。在这种情况下，我们将间隔转换为月份：
- en: '[PRE3]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If `date_part` is not supported in your database, `extract` can be used as an
    alternative. (Refer to [Chapter 3](ch03.xhtml#time_series_analysis) for an explanation
    and examples.) The output can be plotted, as in [Figure 9-1](#distribution_of_length_of_gap_between_r).
    Since there is a long tail of months, this plot is zoomed in to show the range
    in which most gaps fall. The most common gap is 24 months, but there are also
    several hundred instances per month out to 32 months. There is another small bump
    to over 100 at 47 and 48 months. With the average and distribution in hand, I
    would likely set a threshold of either 36 or 48 months and say that any representative
    who hasn’t been reelected within this window has “churned.”
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据库不支持`date_part`，可以使用`extract`作为替代方法（参见[第3章](ch03.xhtml#time_series_analysis)中的说明和示例）。输出可以绘制，如[图9-1](#distribution_of_length_of_gap_between_r)所示。由于存在长尾月份，该图被放大以显示大多数间隔的范围。最常见的间隔是24个月，但每月也有数百个实例延伸至32个月。在47和48个月处还有另一个小峰。有了平均值和分布，我可能会设定36或48个月的阈值，并表示在此窗口内未被重新选举的任何代表已经“流失”。
- en: '![](Images/sfda_0901.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/sfda_0901.png)'
- en: Figure 9-1\. Distribution of length of gap between representative term start
    dates, showing range from 10 to 59 months
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-1\. 代表任期开始日期间隔长度的分布，显示从10到59个月的范围
- en: Once you have a defined threshold for churn, you can monitor the customer base
    with a “time since last” analysis. This can refer to last purchase, last payment,
    last time an app was opened, or whatever time-based metric is relevant for the
    organization. For this calculation, you need a data set that has the most recent
    date or timestamp for each customer. If starting with a time series, first find
    the most recent timestamp for each customer in a subquery. Then apply date math
    to find the time elapsed between that date and the current date, or the latest
    date in the data set if some time has elapsed since the data was assembled.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了客户流失的定义阈值，可以通过“自上次”分析监控客户群体。这可以指上次购买、上次付款、上次打开应用程序的时间，或者对组织相关的任何基于时间的度量。为了进行这种计算，您需要一个包含每位客户最近日期或时间戳的数据集。如果从时间序列开始，首先在子查询中找到每位客户的最近时间戳。然后应用日期数学运算，找到该日期与当前日期之间的经过时间，或者数据集中最新日期，如果数据组装后经过了一段时间。
- en: 'For example, we could find the distribution of years since the last election
    from the `legislators_terms` table. In the subquery, calculate the latest starting
    date using the `max` function and then find the time elapsed since then using
    the `age` function. In this case, the maximum data in the data set, May 5, 2019,
    is used. In a data set with up-to-date data, substitute `current_date` or an equivalent
    expression. The outer query finds the years from the interval using `date_part`
    and counts the number of legislators:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以从`legislators_terms`表中找到距离上次选举的年份分布。在子查询中，使用`max`函数计算最新的起始日期，然后使用`age`函数找出自那时以来的时间间隔。在本例中，数据集中的最大日期是2019年5月5日。在具有最新数据的数据集中，可以替换为`current_date`或等效表达式。外部查询使用`date_part`找到间隔中的年数，并计算立法者的数量：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'A related concept is “lapsed,” which is often used as an intermediate stage
    between fully active customers and churned customers and might alternatively be
    called “dormant.” A lapsed customer may be at higher risk of churning because
    we haven’t seen them for a while but still have a decent likelihood of returning
    based on our past experience. In consumer services, I’ve seen “lapsed” cover periods
    from 7 to 30 days, with “churned” being defined as a customer not using the service
    for more than 30 days. Companies often experiment with reactivating lapsed users,
    using tactics ranging from email to support team outreach. Customers in each state
    can be defined by first finding their “time since last” as above and then tagging
    them with a CASE statement using the appropriate number of days or months. For
    example, we can group the representatives according to how long ago they were
    elected:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 相关概念是“潜伏”，通常作为完全活跃客户和流失客户之间的中间阶段使用，也可能被称为“休眠”。潜伏客户可能更容易流失，因为我们有一段时间没见到他们，但基于我们的过往经验，他们仍然有相当大的可能性会回归。在消费服务中，我见过“潜伏”覆盖从7到30天的期间，“流失”被定义为超过30天不使用服务的客户。公司经常尝试重新激活潜伏用户，使用的策略从电子邮件到支持团队的接触不等。通过首先找到他们的“上次活跃时间”并使用CASE语句根据适当的天数或月数对其进行标记，可以将每个州的客户进行定义。例如，我们可以根据他们当选多久来分组代表：
- en: '[PRE5]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This data set contains more than two hundred years of legislator terms, so of
    course many of the people included have died, and some are still living but are
    retired. In the context of a business, we would hope that our churned customers
    didn’t outnumber our current customers by such a wide margin, and we would want
    to know more about the lapsed customers.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集包含超过两百年的立法者任期，所以当然其中许多人已经去世，有些仍然健在但已经退休。在商业环境中，我们希望我们的流失客户数量没有比我们当前客户多出这么多，我们也想进一步了解潜伏客户的情况。
- en: Most organizations are very concerned about churn, since customers are generally
    more expensive to acquire than to retain. To learn more about the customers in
    any status or about the range of time since last seen, these analyses can be further
    sliced by any of the customer attributes available in the data set.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数组织非常关注客户流失问题，因为获取新客户通常比留住现有客户更昂贵。要了解任何状态下的客户或上次活跃时间范围的更多信息，这些分析可以进一步通过数据集中可用的任何客户属性进行切片分析。
- en: Basket Analysis
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 购物篮分析
- en: 'I have three kids, and when I go to the grocery store, my basket (or more often
    my shopping cart) fills up quickly with grocery items to feed them for the week.
    Milk, eggs, and bread are usually in there, but other items might change depending
    on what produce is in season, whether the kids are in school or on break, or if
    we’re planning to cook a special meal. Basket analysis takes its name from the
    practice of analyzing the products consumers buy together to find patterns that
    can be used for marketing, store placement, or other strategic decisions. The
    goal of a basket analysis may be to find groups of items purchased together. It
    can also be framed around a particular product: when someone buys ice cream, what
    else do they buy?'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我有三个孩子，每次去杂货店时，我的购物篮（或者更常见的购物车）很快就会被各种食品填满，供他们一周食用。牛奶、鸡蛋和面包通常都在其中，但其他物品可能会根据时令水果的变化、孩子们是否在上学或放假以及我们是否计划做特别的餐食而有所改变。购物篮分析的名字来自于分析消费者一起购买的产品，以找出可用于营销、店铺布置或其他战略决策的模式。购物篮分析的目标可能是找到一起购买的物品组合。它也可以围绕特定产品展开：当有人购买冰淇淋时，他们还会购买什么？
- en: Although basket analysis was originally framed around items purchased together
    in a single transaction, the concept can be extended in several ways. A retailer
    or an ecommerce store might be interested in the basket of items a customer purchases
    across their lifetime. Services and product feature usage can also be analyzed
    in this fashion. Services that are commonly purchased together might be bundled
    into a new offering, such as when travel sites offer deals if a flight, hotel,
    and rental car are booked together. Product features that are used together might
    be placed in the same navigation window or used to make suggestions for where
    to go next in an application. Basket analysis can also be used to identify stakeholder
    personas, or segments, which are then used in other types of analysis.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然篮子分析最初是围绕单个交易中一起购买的物品，但这个概念可以通过几种方式扩展。零售商或电子商务店可能对客户在其生命周期内购买的物品篮感兴趣。还可以分析服务和产品功能的使用情况。常一起购买的服务可能会被捆绑成一个新的优惠，例如旅行网站提供的飞行、酒店和租车一起预订的优惠。经常一起使用的产品功能可能会放在同一个导航窗口中，或者用于建议应用程序中的下一步操作。篮子分析还可用于识别利益相关者人物角色或细分，然后用于其他类型的分析。
- en: 'To find the most common baskets, using all items in a basket, we can use the
    `string_agg` function (or an analogous one, depending on the type of database—see
    [Chapter 5](ch05.xhtml#text_analysis)). For example, imagine we have a `purchases`
    table that has one row for each `product` bought by a `customer_id`. First, use
    the `string_agg` function to find the list of products purchased by each customer
    in a subquery. Then *GROUP BY* this list and `count` the number of customers:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要找出最常见的篮子，使用篮子中的所有物品，可以使用`string_agg`函数（或类似的函数，取决于数据库类型——参见[第5章](ch05.xhtml#text_analysis)）。例如，假设我们有一个`purchases`表，每个`customer_id`购买的每个`product`都有一行记录。首先，在子查询中使用`string_agg`函数找到每个客户购买的产品列表。然后按此列表进行*GROUP
    BY*并计算客户数量。
- en: '[PRE6]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This technique works well when there is a relatively small number of possible
    items. Another option is to find pairs of products purchased together. To do this,
    self-*JOIN* the `purchases` table to itself, *JOIN*ing on the `customer_id`. The
    second *JOIN* condition solves the problem of duplicate entries that differ only
    in their order. For example, imagine a customer who purchased apples and bananas—without
    this clause, the result set would include “apples, bananas” and “bananas, apples.”
    The clause `b.product > a.product` ensures only one of these variations is included
    and also filters out results in which a product is matched with itself:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当有相对较少的可能项时，这种技术效果很好。另一个选择是找到一起购买的产品对。为此，将`purchases`表与自身进行*JOIN*，在`customer_id`上*JOIN*。第二个*JOIN*条件解决了仅在顺序不同的重复条目的问题。例如，想象一个购买了苹果和香蕉的客户——如果没有这个子句，结果集将包括“苹果，香蕉”和“香蕉，苹果”。子句`b.product
    > a.product`确保只包括这些变体中的一个，并且还过滤掉与自身匹配的产品：
- en: '[PRE7]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This can be extended to include three or more products by adding additional
    *JOIN*s. To include baskets that contain only one item, change the *JOIN* to a
    *LEFT JOIN*.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过添加额外的*JOIN*来扩展到包含三个或更多产品。要包括仅包含一个项目的篮子，将*JOIN*更改为*LEFT JOIN*。
- en: There are a few common challenges when running a basket analysis. The first
    is performance, particularly when there is a large catalog of products, services,
    or features. The resultant calculations can become slow on the database, particularly
    when the goal is to find groups of three or more items, and thus the SQL contains
    three or more self-*JOIN*s. Consider filtering the tables with *WHERE* clauses
    to remove infrequently purchased items before performing the *JOIN*s. Another
    challenge occurs when a few items are so common that they swamp all other combinations.
    For example, milk is so frequently purchased that groups with it and any other
    item top the list of combinations. The query results, while accurate, may still
    be meaningless in a practical sense. In this case, consider removing the most
    common items entirely, again with a *WHERE* clause, before performing the *JOIN*s.
    This should have the added benefit of improving query performance by making the
    data set smaller.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 运行购物篮分析时存在一些常见挑战。首先是性能问题，特别是在有大量产品、服务或功能的目录时。结果计算在数据库上可能变得缓慢，尤其是当目标是查找包含三个或更多项的组时，因此SQL包含三个或更多个自连接。考虑使用*WHERE*子句过滤表，以移除不经常购买的项目，然后执行*JOIN*。另一个挑战是少数项目非常普遍，以至于淹没所有其他组合。例如，牛奶购买频率如此之高，以至于与任何其他项目一起的组合位于组合列表的顶部。查询结果虽然准确，但在实际意义上可能仍然无意义。在这种情况下，考虑使用*WHERE*子句彻底删除最常见的项目之一，然后执行*JOIN*，这样做还有助于通过使数据集变小来改善查询性能。
- en: A final challenge with basket analysis is the self-fulfilling prophecy. Items
    that show up together in a basket analysis may then be marketed together, increasing
    the frequency with which they are purchased together. This may strengthen the
    case to market them together further, leading to more copurchasing, and so on.
    Products that are even better matches may never have a chance, simply because
    they didn’t appear in the original analysis and become candidates for promotion.
    The famous [beer and diapers correlation](https://oreil.ly/4d5PF) is only one
    example of this. Various machine learning techniques and large online companies
    have tried to tackle this problem, and there are plenty of interesting directions
    for analysis in this area still to be developed.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 购物篮分析的最后一个挑战是自我实现的预言。在购物篮分析中一起出现的物品可能会一起进行营销，增加它们一起购买的频率。这可能加强一起营销的案例，导致更多的共购买，依此类推。甚至更匹配的产品可能永远没有机会，只是因为它们没有出现在原始分析中并成为促销候选。著名的[啤酒和尿布相关性](https://oreil.ly/4d5PF)就是其中的一个例子。各种机器学习技术和大型在线公司已经尝试解决这个问题，这个领域还有许多有趣的分析方向有待开发。
- en: Resources
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源
- en: Data analysis as a profession (or even as a hobby!) requires a mix of technical
    proficiency, domain knowledge, curiosity, and communication skills. I thought
    I would share some of my favorite resources so that you might draw on them as
    you continue your journey, both to learn more and to practice your new skills
    on real data sets.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种职业（甚至是一种爱好！），数据分析需要技术熟练、领域知识、好奇心和沟通技巧的综合运用。我想分享一些我最喜欢的资源，希望你在继续学习和在真实数据集上练习新技能时能够从中受益。
- en: Books and Blogs
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 书籍和博客
- en: 'Although this book assumes a working knowledge of SQL, good resources for the
    basics or for a refresher are:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然本书假设您具有SQL的工作知识，但对于基础知识或复习的良好资源包括:'
- en: 'Forta, Ben. Sams *Teach Yourself SQL in 10 Minutes a Day*. 5th ed. Hoboken,
    NJ: Sams, 2020.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Forta, Ben. Sams *每天10分钟学会SQL*. 第5版. Hoboken, NJ: Sams, 2020.'
- en: The software company Mode offers a [SQL tutorial](https://mode.com/sql-tutorial)
    with an interactive query interface, useful for practicing your skills.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件公司Mode提供一个[SQL教程](https://mode.com/sql-tutorial)，带有交互式查询界面，非常适合练习你的技能。
- en: There is no single universally accepted SQL style, but you may find the [SQL
    Style Guide](https://www.sqlstyle.guide) and the [Modern SQL Style Guide](https://oreil.ly/rsxBh)
    useful. Note that their styles don’t exactly match those used in this book, or
    each other. I believe that using a style that is both consistent with itself and
    readable is the most important consideration.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 没有单一普遍接受的SQL风格，但你可能会发现[SQL风格指南](https://www.sqlstyle.guide)和[现代SQL风格指南](https://oreil.ly/rsxBh)有用。请注意，它们的风格与本书使用的风格或彼此并不完全相同。我认为使用既一致又易读的风格是最重要的考虑因素。
- en: 'Your approach to analysis and to communicating the results can often matter
    just as much as the code you write. Two good books for sharpening both aspects
    are:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 你对分析方法和结果传达方式的处理通常和你编写的代码一样重要。两本锤炼这两个方面的好书是：
- en: 'Hubbard, Douglas W. *How to Measure Anything: Finding the Value of “Intangibles”
    in Business*. 2nd ed. Hoboken, NJ: Wiley, 2010.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hubbard, Douglas W. *How to Measure Anything: Finding the Value of “Intangibles”
    in Business*. 第2版。霍博肯，新泽西州：Wiley，2010年。'
- en: 'Kahneman, Daniel. *Thinking, Fast and Slow*. New York: Farrar, Straus and Giroux,
    2011.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kahneman, Daniel. *Thinking, Fast and Slow*. 纽约：Farrar, Straus and Giroux，2011年。
- en: The [Towards Data Science blog](https://towardsdatascience.com) is a great source
    for articles about many analysis topics. Although many of the posts there focus
    on Python as a programming language, approaches and techniques can often be adapted
    to SQL.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[Towards Data Science 博客](https://towardsdatascience.com)是关于多种分析主题文章的重要来源。尽管许多帖子侧重于
    Python 作为编程语言，但方法和技术通常可以适应 SQL。'
- en: For an amusing take on correlation versus causation, see [Tyler Vigen’s Spurious
    Correlations](http://tylervigen.com/spurious-correlations).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣地探讨相关性与因果关系，请参阅[Tyler Vigen的虚假相关性](http://tylervigen.com/spurious-correlations)。
- en: 'Regular expressions can be tricky. If you’re looking to increase your understanding
    or to solve complex cases not covered in this book, a good resource is:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式可能有些棘手。如果你想增加理解或解决本书未涵盖的复杂情况，一个很好的资源是：
- en: 'Forta, Ben. *Learning Regular Expressions*. Boston: Addison-Wesley, 2018.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Forta, Ben. *Learning Regular Expressions*. 波士顿：Addison-Wesley，2018年。
- en: 'Randomized testing has a long history and touches many fields across the natural
    and social sciences. Compared to statistics, however, analysis of online experiments
    is still relatively new. Many classic statistics texts give a good introduction
    but discuss problems in which the sample size is very small, so they fail to address
    many of the unique opportunities and challenges of online testing. A couple of
    good books that discuss online experiments are:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 随机化测试有着悠久的历史，并涉及自然和社会科学的多个领域。然而，与统计学相比，在线实验分析仍然相对较新。许多经典的统计学文本提供了很好的介绍，但讨论的问题样本量非常小，因此未能解决在线测试的许多独特机会和挑战。几本讨论在线实验的好书包括：
- en: 'Georgiev, Georgi Z. *Statistical Methods in Online A/B Testing*. Sofia, Bulgaria:
    self-published, 2019.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Georgiev, Georgi Z. *Statistical Methods in Online A/B Testing*. 索非亚，保加利亚：自行出版，2019年。
- en: 'Kohavi, Ron, Diane Tang, and Ya Xu. *Trustworthy Online Controlled Experiments:
    A Practical Guide to A/B Testing*. Cambridge, UK: Cambridge University Press,
    2020.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kohavi, Ron, Diane Tang, and Ya Xu. *Trustworthy Online Controlled Experiments:
    A Practical Guide to A/B Testing*. 剑桥，英国：剑桥大学出版社，2020年。'
- en: '[Evan Miller’s Awesome A/B Tools](https://www.evanmiller.org/ab-testing) has
    calculators for both binary and continuous outcome experiments, as well as several
    other tests that may be useful for experiment designs beyond the scope of this
    book.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[Evan Miller的Awesome A/B Tools](https://www.evanmiller.org/ab-testing)提供了用于二元和连续结果实验的计算器，以及几个可能对本书范围之外的实验设计有用的其他测试。'
- en: Data Sets
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集
- en: 'The best way to learn and improve your SQL skills is to put them to use on
    real data. If you are employed and have access to a database within your organization,
    that’s a good place to start since you probably already have context on how the
    data is produced and what it means. There are plenty of interesting public data
    sets that you can analyze instead, however, and these range across a wide variety
    of topics. Listed below are a few good places to start when looking for interesting
    data sets:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 学习和提高 SQL 技能的最佳方法是在真实数据上应用它们。如果你有工作并且可以访问组织内的数据库，那是一个很好的起点，因为你可能已经了解数据生成的背景和含义。然而，有许多有趣的公共数据集可供分析，涵盖各种各样的主题。以下是一些寻找有趣数据集的好去处：
- en: '[Data Is Plural](https://www.data-is-plural.com) is a newsletter of new and
    interesting data sets, and the [Data Is Plural archive](https://dataset-finder.netlify.app)
    is a searchable treasure trove of data sets.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Data Is Plural](https://www.data-is-plural.com)是一份关于新奇数据集的通讯，[Data Is Plural
    档案](https://dataset-finder.netlify.app)是一个可搜索的数据集宝库。'
- en: '[FiveThirtyEight](https://fivethirtyeight.com) is a journalism site that covers
    politics, sports, and science through a data lens. The data sets behind the stories
    are on the [FiveThirtyEight GitHub site](https://github.com/fivethirtyeight/data).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[FiveThirtyEight](https://fivethirtyeight.com)是一个通过数据视角报道政治、体育和科学的新闻网站。这些报道背后的数据集可以在[FiveThirtyEight
    GitHub 站点](https://github.com/fivethirtyeight/data)找到。'
- en: '[Gapminder](https://www.gapminder.org/data) is a Swedish foundation that publishes
    yearly data for many human and economic development indicators, including many
    sourced from the World Bank.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Gapminder](https://www.gapminder.org/data)是一个瑞典基金会，每年发布许多人类和经济发展指标的数据，包括许多来自世界银行的数据。'
- en: The United Nations publishes a number of statistics. The UN’s Department of
    Economic and Social Affairs produces data on [population dynamics](https://population.un.org/wpp/Download/Standard/Population)
    in a relatively easy-to-use format.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 联合国发布了许多统计数据。联合国经济和社会事务部门以相对易用的格式制作了有关[人口动态](https://population.un.org/wpp/Download/Standard/Population)的数据。
- en: Kaggle hosts data analysis competitions and has a [library of data sets](https://www.kaggle.com/datasets)
    that can be downloaded and analyzed even outside of the formal competitions.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaggle主办数据分析竞赛，并有一个可以下载和分析的[数据集库](https://www.kaggle.com/datasets)，即使在正式比赛之外也是如此。
- en: Many governments at all levels, from national to local, have adopted the open
    data movement and publish various statistics. [Data.gov](https://www.data.gov/open-gov)
    maintains a list of sites both in the United States and around the world that
    is a good starting point.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多政府在各级，从国家到地方，都已经采纳了开放数据运动，并发布各种统计数据。[Data.gov](https://www.data.gov/open-gov)维护着一个包括美国和世界各地网站列表，是一个很好的起点。
- en: Final Thoughts
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后思考
- en: I hope you’ve found the techniques and code in this book useful. I believe that
    it’s important to have a good foundation in the tools you’re using, and there
    are many useful SQL functions and expressions that can make your analyses faster
    and more accurate. Developing great analysis skills isn’t just about learning
    the latest fancy techniques or language, however. Great analysis comes from asking
    good questions; taking the time to understand the data and the domain; applying
    appropriate analysis techniques to come up with high-quality, reliable answers;
    and finally, communicating the results to your audience in a way that is relevant
    and supports decision making. Even after almost 20 years of working with SQL,
    I still get excited about finding new ways to apply it, new data sets to apply
    it to, and all of the insights in the world patiently waiting to be discovered.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望您在本书中找到的技术和代码对您有所帮助。我相信，掌握您正在使用的工具的良好基础非常重要，而且有许多有用的SQL函数和表达式可以使您的分析更快速、更准确。然而，开发出色的分析技能不仅仅是学习最新的花哨技术或语言。优秀的分析源于提出良好的问题；花时间理解数据和领域；应用适当的分析技术得出高质量、可靠的答案；最后，以对决策支持相关的方式将结果传达给您的受众。即使在与SQL工作近20年后，我依然对找到新的应用方式、新的数据集以及等待被发现的所有见解感到兴奋。
