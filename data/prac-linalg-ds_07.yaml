- en: Chapter 7\. Matrix Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬7ç« ã€‚çŸ©é˜µåº”ç”¨
- en: 'I hope that now, after the past two theory-heavy chapters, you feel like you
    just finished an intense workout at the gym: exhausted but energized. This chapter
    should feel like a bike ride through the hills in the countryside: effortful at
    times but offering a fresh and inspiring perspective.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›ç°åœ¨ï¼Œåœ¨è¿‡å»ä¸¤ä¸ªç†è®ºå¯†é›†çš„ç« èŠ‚ä¹‹åï¼Œä½ æ„Ÿè§‰å°±åƒåˆšåˆšå®Œæˆäº†ä¸€æ¬¡å¥èº«æˆ¿çš„å‰§çƒˆé”»ç‚¼ï¼šç–²æƒ«ä½†å……æ»¡æ´»åŠ›ã€‚è¿™ä¸€ç« åº”è¯¥æ„Ÿè§‰å°±åƒåœ¨ä¹¡æ‘å°è·¯ä¸Šéª‘è‡ªè¡Œè½¦ï¼šæœ‰æ—¶è´¹åŠ›ä½†æä¾›äº†æ–°é²œä¸”ä»¤äººæŒ¯å¥‹çš„è§†è§’ã€‚
- en: The applications in this chapter are loosely built off of those in [ChapterÂ 4](ch04.xhtml#Chapter_4).
    I did this to have some common threads that bind the chapters on vectors and on
    matrices. And because I want you to see that although the concepts and applications
    become more complex as you progress in linear algebra, the foundations are still
    built on the same simple principles such as linear weighted combinations and the
    dot product.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« çš„åº”ç”¨æ¾æ•£åœ°åŸºäºç¬¬4ç« çš„å†…å®¹ã€‚æˆ‘è¿™æ ·åšæ˜¯ä¸ºäº†åœ¨å‘é‡å’ŒçŸ©é˜µçš„ç« èŠ‚ä¸­ä¿æŒä¸€äº›å…±åŒçš„ä¸»é¢˜çº¿ç´¢ã€‚å› ä¸ºæˆ‘å¸Œæœ›ä½ çœ‹åˆ°ï¼Œå°½ç®¡éšç€çº¿æ€§ä»£æ•°çš„æ·±å…¥ï¼Œæ¦‚å¿µå’Œåº”ç”¨å˜å¾—æ›´åŠ å¤æ‚ï¼Œä½†å…¶åŸºç¡€ä»å»ºç«‹åœ¨è¯¸å¦‚çº¿æ€§åŠ æƒç»„åˆå’Œç‚¹ç§¯ç­‰ç®€å•åŸç†ä¸Šã€‚
- en: Multivariate Data Covariance Matrices
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¤šå…ƒæ•°æ®åæ–¹å·®çŸ©é˜µ
- en: In [ChapterÂ 4](ch04.xhtml#Chapter_4), you learned how to compute the Pearson
    correlation coefficient as the vector dot product between two data variables,
    divided by the product of the vector norms. That formula was for two variables
    (e.g., height and weight); what if you have multiple variables (e.g., height,
    weight, age, weekly exerciseâ€¦)?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨[ç¬¬4ç« ](ch04.xhtml#Chapter_4)ä¸­ï¼Œä½ å­¦ä¼šäº†å¦‚ä½•è®¡ç®—Pearsonç›¸å…³ç³»æ•°ï¼Œå³ä¸¤ä¸ªæ•°æ®å˜é‡ä¹‹é—´çš„å‘é‡ç‚¹ç§¯ï¼Œé™¤ä»¥å‘é‡èŒƒæ•°çš„ä¹˜ç§¯ã€‚é‚£ä¸ªå…¬å¼æ˜¯ç”¨äºä¸¤ä¸ªå˜é‡ï¼ˆä¾‹å¦‚èº«é«˜å’Œä½“é‡ï¼‰çš„ï¼›å¦‚æœä½ æœ‰å¤šä¸ªå˜é‡ï¼ˆä¾‹å¦‚èº«é«˜ã€ä½“é‡ã€å¹´é¾„ã€æ¯å‘¨è¿åŠ¨â€¦â€¦ï¼‰å‘¢ï¼Ÿ
- en: You could imagine writing a double `for` loop over all of the variables, and
    applying the bivariate correlation formula to all pairs of variables. But that
    is cumbersome and inelegant, and therefore antithetical to the spirit of linear
    algebra. The purpose of this section is to show you how to compute covariance
    and correlation *matrices* from multivariate datasets.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥æƒ³è±¡åœ¨æ‰€æœ‰å˜é‡ä¸Šå†™ä¸€ä¸ªåŒé‡`for`å¾ªç¯ï¼Œå¹¶å°†åŒå˜é‡ç›¸å…³æ€§å…¬å¼åº”ç”¨äºæ‰€æœ‰å˜é‡å¯¹ã€‚ä½†é‚£æ ·æ—¢ç¬¨é‡åˆä¸ä¼˜é›…ï¼Œä¸çº¿æ€§ä»£æ•°ç²¾ç¥ç›¸è¿èƒŒã€‚æœ¬èŠ‚çš„ç›®çš„æ˜¯å‘ä½ å±•ç¤ºå¦‚ä½•ä»å¤šå˜é‡æ•°æ®é›†ä¸­è®¡ç®—åæ–¹å·®å’Œç›¸å…³æ€§*çŸ©é˜µ*ã€‚
- en: Letâ€™s start with *covariance*. Covariance is simply the numerator of the correlation
    equationâ€”in other words, the dot product between two mean-centered variables.
    Covariance is interpreted in the same way as correlation (positive when variables
    move together, negative when variables move apart, zero when the variables have
    no linear relationship), except that covariance retains the scale of the data,
    and therefore is not bound by Â±1.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬ä»*åæ–¹å·®*å¼€å§‹ã€‚åæ–¹å·®ç®€å•æ¥è¯´æ˜¯ç›¸å…³æ–¹ç¨‹çš„åˆ†å­éƒ¨åˆ†ï¼Œæ¢å¥è¯è¯´ï¼Œæ˜¯ä¸¤ä¸ªå‡å€¼ä¸­å¿ƒåŒ–å˜é‡çš„ç‚¹ç§¯ã€‚åæ–¹å·®çš„è§£é‡Šä¸ç›¸å…³æ€§ç›¸åŒï¼ˆå˜é‡åŒå‘ç§»åŠ¨æ—¶ä¸ºæ­£ï¼Œåå‘ç§»åŠ¨æ—¶ä¸ºè´Ÿï¼Œæ— çº¿æ€§å…³ç³»æ—¶ä¸ºé›¶ï¼‰ï¼Œä½†åæ–¹å·®ä¿ç•™äº†æ•°æ®çš„å°ºåº¦ï¼Œå› æ­¤ä¸å—Â±1çš„é™åˆ¶ã€‚
- en: 'Covariance also has a normalization factor of *n* âˆ’ 1, where *n* is the number
    of data points. That normalization prevents the covariance from growing larger
    as you sum more data values together (analogous to dividing by *N* to transform
    a sum into an average). Here is the equation for covariance:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: åæ–¹å·®è¿˜æœ‰ä¸€ä¸ª*ï¼ˆn-1ï¼‰*çš„å½’ä¸€åŒ–å› å­ï¼Œå…¶ä¸­*n*æ˜¯æ•°æ®ç‚¹çš„æ•°é‡ã€‚è¿™ç§å½’ä¸€åŒ–é˜²æ­¢äº†éšç€æ•°æ®å€¼çš„ç´¯åŠ åæ–¹å·®å˜å¾—è¶Šæ¥è¶Šå¤§ï¼ˆç±»ä¼¼äºé€šè¿‡*N*æ¥å°†æ€»å’Œè½¬æ¢ä¸ºå¹³å‡å€¼ï¼‰ã€‚ä»¥ä¸‹æ˜¯åæ–¹å·®çš„æ–¹ç¨‹å¼ï¼š
- en: <math alttext="c Subscript a comma b Baseline equals left-parenthesis n minus
    1 right-parenthesis Superscript negative 1 Baseline sigma-summation Underscript
    i equals 1 Overscript n Endscripts left-parenthesis x Subscript i Baseline minus
    x overbar right-parenthesis left-parenthesis y Subscript i Baseline minus y overbar
    right-parenthesis" display="block"><mrow><msub><mi>c</mi> <mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow></msub>
    <mo>=</mo> <msup><mrow><mo>(</mo><mi>n</mi><mo>-</mo><mn>1</mn><mo>)</mo></mrow>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <munderover><mo>âˆ‘</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></munderover> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>-</mo>
    <mover accent="true"><mi>x</mi> <mo>Â¯</mo></mover> <mo>)</mo></mrow> <mrow><mo>(</mo>
    <msub><mi>y</mi> <mi>i</mi></msub> <mo>-</mo> <mover accent="true"><mi>y</mi>
    <mo>Â¯</mo></mover> <mo>)</mo></mrow></mrow></math>
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="c Subscript a comma b Baseline equals left-parenthesis n minus
    1 right-parenthesis Superscript negative 1 Baseline sigma-summation Underscript
    i equals 1 Overscript n Endscripts left-parenthesis x Subscript i Baseline minus
    x overbar right-parenthesis left-parenthesis y Subscript i Baseline minus y overbar
    right-parenthesis" display="block"><mrow><msub><mi>c</mi> <mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow></msub>
    <mo>=</mo> <msup><mrow><mo>(</mo><mi>n</mi><mo>-</mo><mn>1</mn><mo>)</mo></mrow>
    <mrow><mo>-</mo><mn>1</mn></mrow></msup> <munderover><mo>âˆ‘</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></munderover> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>-</mo>
    <mover accent="true"><mi>x</mi> <mo>Â¯</mo></mover> <mo>)</mo></mrow> <mrow><mo>(</mo>
    <msub><mi>y</mi> <mi>i</mi></msub> <mo>-</mo> <mover accent="true"><mi>y</mi>
    <mo>Â¯</mo></mover> <mo>)</mo></mrow></mrow></math>
- en: As in [ChapterÂ 4](ch04.xhtml#Chapter_4), if we call <math alttext="bold x overTilde"><mover
    accent="true"><mi>ğ±</mi> <mo>Ëœ</mo></mover></math> to be the mean-centered variable
    <math alttext="bold x"><mi>ğ±</mi></math> , then covariance is simply <math alttext="bold
    x overTilde Superscript upper T Baseline bold y overTilde slash left-parenthesis
    n minus 1 right-parenthesis"><mrow><msup><mover accent="true"><mi>ğ±</mi> <mo>Ëœ</mo></mover>
    <mtext>T</mtext></msup> <mover accent="true"><mi>ğ²</mi> <mo>Ëœ</mo></mover> <mo>/</mo>
    <mrow><mo>(</mo> <mi>n</mi> <mo>-</mo> <mn>1</mn> <mo>)</mo></mrow></mrow></math>
    .
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚[ç¬¬4ç« ](ch04.xhtml#Chapter_4)ä¸­æ‰€è¿°ï¼Œå¦‚æœæˆ‘ä»¬ç§°<mover accent="true"><mi>ğ±</mi> <mo>Ëœ</mo></mover>ä¸ºå‡å€¼ä¸­å¿ƒåŒ–å˜é‡<mover
    accent="true"><mi>ğ±</mi></mover>ï¼Œé‚£ä¹ˆåæ–¹å·®å°±æ˜¯ç®€å•çš„<mover accent="true"><mi>ğ±</mi> <mo>Ëœ</mo></mover><mtext><msup><mi>T</mi></msup></mtext>
    <mover accent="true"><mi>ğ²</mi> <mo>Ëœ</mo></mover> /ï¼ˆn-1ï¼‰ã€‚
- en: The key insight to implementing this formula for multiple variables is that
    matrix multiplication is an organized collection of dot products between rows
    of the left matrix and columns of the right matrix.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: å®ç°æ­¤å¤šå˜é‡å…¬å¼çš„å…³é”®è§è§£æ˜¯çŸ©é˜µä¹˜æ³•æ˜¯å·¦çŸ©é˜µè¡Œå’Œå³çŸ©é˜µåˆ—çš„ç‚¹ç§¯çš„ç»„ç»‡é›†åˆã€‚
- en: 'So hereâ€™s what we do: create a matrix in which each column corresponds to each
    variable (a variable is a data feature). Letâ€™s call that matrix <math alttext="bold
    upper X"><mi>ğ—</mi></math> . Now, the multiplication <math alttext="bold upper
    X bold upper X"><mrow><mi>ğ—</mi> <mi>ğ—</mi></mrow></math> is not sensible (and
    probably not even valid, because data matrices tend to be tall, thus *M* > *N*).
    But if we were to transpose the first matrix, then the *rows* of <math alttext="bold
    upper X Superscript upper T"><msup><mi>ğ—</mi> <mtext>T</mtext></msup></math> correspond
    to the *columns* of <math alttext="bold upper X"><mi>ğ—</mi></math> . Therefore,
    the matrix product <math alttext="bold upper X Superscript upper T Baseline bold
    upper X"><mrow><msup><mi>ğ—</mi> <mtext>T</mtext></msup> <mi>ğ—</mi></mrow></math>
    encodes all of the pair-wise covariances (assuming the columns are mean centered,
    and when dividing by *n* âˆ’ 1). In other words, the (*i,j*)th element in the covariance
    matrix is the dot product between data features *i* and *j*.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œæˆ‘ä»¬åšçš„æ˜¯ï¼šåˆ›å»ºä¸€ä¸ªçŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸€åˆ—å¯¹åº”ä¸€ä¸ªå˜é‡ï¼ˆå˜é‡æ˜¯æ•°æ®ç‰¹å¾ï¼‰ã€‚è®©æˆ‘ä»¬ç§°è¿™ä¸ªçŸ©é˜µä¸º<math alttext="bold upper X"><mi>ğ—</mi></math>ã€‚ç°åœ¨ï¼Œä¹˜ç§¯<math
    alttext="bold upper X bold upper X"><mrow><mi>ğ—</mi> <mi>ğ—</mi></mrow></math>æ˜¯ä¸åˆç†çš„ï¼ˆç”šè‡³å¯èƒ½æ— æ•ˆï¼Œå› ä¸ºæ•°æ®çŸ©é˜µå¾€å¾€æ˜¯é«˜çš„ï¼Œå› æ­¤*M*
    > *N*)ã€‚ä½†æ˜¯å¦‚æœæˆ‘ä»¬è½¬ç½®ç¬¬ä¸€ä¸ªçŸ©é˜µï¼Œé‚£ä¹ˆ<math alttext="bold upper X Superscript upper T"><msup><mi>ğ—</mi>
    <mtext>T</mtext></msup></math>çš„*è¡Œ*å¯¹åº”äº<math alttext="bold upper X"><mi>ğ—</mi></math>çš„*åˆ—*ã€‚å› æ­¤ï¼ŒçŸ©é˜µä¹˜ç§¯<math
    alttext="bold upper X Superscript upper T Baseline bold upper X"><mrow><msup><mi>ğ—</mi>
    <mtext>T</mtext></msup> <mi>ğ—</mi></mrow></math>ç¼–ç äº†æ‰€æœ‰æˆå¯¹åæ–¹å·®ï¼ˆå‡è®¾åˆ—æ˜¯å‡å€¼å±…ä¸­çš„ï¼Œå¹¶ä¸”åœ¨é™¤ä»¥*n*
    - 1æ—¶ï¼‰ã€‚æ¢å¥è¯è¯´ï¼Œåæ–¹å·®çŸ©é˜µä¸­çš„(*i,j*)å…ƒç´ æ˜¯æ•°æ®ç‰¹å¾*i*å’Œ*j*çš„ç‚¹ç§¯ã€‚
- en: 'The matrix equation for a covariance matrix is elegant and compact:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: åæ–¹å·®çŸ©é˜µçš„çŸ©é˜µæ–¹ç¨‹éå¸¸ä¼˜é›…ä¸”ç´§å‡‘ï¼š
- en: <math alttext="bold upper C equals bold upper X Superscript upper T Baseline
    bold upper X StartFraction 1 Over n minus 1 EndFraction" display="block"><mrow><mi>ğ‚</mi>
    <mo>=</mo> <msup><mi>ğ—</mi> <mtext>T</mtext></msup> <mi>ğ—</mi> <mfrac><mn>1</mn>
    <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></math>
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold upper C equals bold upper X Superscript upper T Baseline
    bold upper X StartFraction 1 Over n minus 1 EndFraction" display="block"><mrow><mi>ğ‚</mi>
    <mo>=</mo> <msup><mi>ğ—</mi> <mtext>T</mtext></msup> <mi>ğ—</mi> <mfrac><mn>1</mn>
    <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></mfrac></mrow></math>
- en: 'Matrix <math alttext="bold upper C"><mi>ğ‚</mi></math> is symmetric. That comes
    from the proof in [ChapterÂ 5](ch05.xhtml#Chapter_5) that any matrix times its
    transpose is square symmetric, but it also makes sense statistically: covariance
    and correlation are symmetric, meaning that, for example, the correlation between
    height and weight is the same as the correlation between weight and height.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ©é˜µ<math alttext="bold upper C"><mi>ğ‚</mi></math>æ˜¯å¯¹ç§°çš„ã€‚è¿™æ¥è‡ªäºç¬¬5ç« ä¸­è¯æ˜çš„ä»»ä½•çŸ©é˜µä¹˜ä»¥å…¶è½¬ç½®éƒ½æ˜¯æ–¹é˜µå¯¹ç§°çš„ï¼Œä½†ä»ç»Ÿè®¡å­¦ä¸Šè®²ä¹Ÿæ˜¯æœ‰é“ç†çš„ï¼šåæ–¹å·®å’Œç›¸å…³æ€§æ˜¯å¯¹ç§°çš„ï¼Œæ„å‘³ç€ä¾‹å¦‚èº«é«˜å’Œä½“é‡ä¹‹é—´çš„ç›¸å…³æ€§ä¸ä½“é‡å’Œèº«é«˜ä¹‹é—´çš„ç›¸å…³æ€§ç›¸åŒã€‚
- en: What are the diagonal elements of <math alttext="bold upper C"><mi>ğ‚</mi></math>
    ? Those contain the covariances of each variable with itself, which in statistics
    is called the *variance*, and quantifies the dispersion around the mean (variance
    is the squared standard deviation).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äº<math alttext="bold upper C"><mi>ğ‚</mi></math>çš„å¯¹è§’å…ƒç´ æ˜¯ä»€ä¹ˆï¼Ÿè¿™äº›å…ƒç´ åŒ…å«æ¯ä¸ªå˜é‡ä¸è‡ªèº«çš„åæ–¹å·®ï¼Œåœ¨ç»Ÿè®¡å­¦ä¸­ç§°ä¸º*æ–¹å·®*ï¼Œç”¨æ¥é‡åŒ–å›´ç»•å‡å€¼çš„ç¦»æ•£ç¨‹åº¦ï¼ˆæ–¹å·®æ˜¯æ ‡å‡†å·®çš„å¹³æ–¹ï¼‰ã€‚
- en: The example in the online code creates a covariance matrix from a publicly available
    dataset on crime statistics. The dataset includes over a hundred features about
    social, economic, educational, and housing information in various communities
    around the US.^([1](ch07.xhtml#idm45733299773872)) The goal of the dataset is
    to use these features to predict levels of crime, but here we will use it to inspect
    covariance and correlation matrices.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åœ¨çº¿ä»£ç ç¤ºä¾‹ä¸­ï¼Œä½¿ç”¨å…¬å¼€å¯ç”¨çš„çŠ¯ç½ªç»Ÿè®¡æ•°æ®é›†åˆ›å»ºäº†ä¸€ä¸ªåæ–¹å·®çŸ©é˜µã€‚è¯¥æ•°æ®é›†åŒ…æ‹¬æœ‰å…³ç¾å›½å„ç¤¾åŒºç¤¾ä¼šã€ç»æµã€æ•™è‚²å’Œä½æˆ¿ä¿¡æ¯çš„ä¸€ç™¾å¤šä¸ªç‰¹å¾^([1](ch07.xhtml#idm45733299773872))ã€‚è¯¥æ•°æ®é›†çš„ç›®æ ‡æ˜¯åˆ©ç”¨è¿™äº›ç‰¹å¾æ¥é¢„æµ‹çŠ¯ç½ªæ°´å¹³ï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬å°†ç”¨å®ƒæ¥æ£€æŸ¥åæ–¹å·®å’Œç›¸å…³çŸ©é˜µã€‚
- en: 'After importing and some light data processing (explained in the online code),
    we have a data matrix called `dataMat`. The following code shows how to compute
    the covariance matrix:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼å…¥å¹¶è¿›è¡Œä¸€äº›è½»å¾®çš„æ•°æ®å¤„ç†åï¼ˆåœ¨åœ¨çº¿ä»£ç ä¸­æœ‰è§£é‡Šï¼‰ï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªåä¸º`dataMat`çš„æ•°æ®çŸ©é˜µã€‚ä»¥ä¸‹ä»£ç æ˜¾ç¤ºå¦‚ä½•è®¡ç®—åæ–¹å·®çŸ©é˜µï¼š
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[FigureÂ 7-1](#fig_7_1) shows an image of the covariance matrix. First of all:
    it looks neat, doesnâ€™t it? I work with multivariate datasets in my â€œday jobâ€ as
    a neuroscience professor, and ogling covariance matrices has never failed to put
    a smile on my face.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 7-1](#fig_7_1)æ˜¾ç¤ºäº†åæ–¹å·®çŸ©é˜µçš„å›¾åƒã€‚é¦–å…ˆï¼šçœ‹èµ·æ¥æ•´æ´ï¼Œä¸æ˜¯å—ï¼Ÿæˆ‘åœ¨â€œæ—¥å¸¸å·¥ä½œâ€ä¸­æ˜¯ä¸€åç¥ç»ç§‘å­¦æ•™æˆï¼Œç»å¸¸ç ”ç©¶å¤šå˜é‡æ•°æ®é›†ï¼Œå¹¶ä¸”ä»°æ…•åæ–¹å·®çŸ©é˜µä»æœªè®©æˆ‘å¤±æœ›è¿‡ã€‚'
- en: In this matrix, light colors indicate variables that covary positively (e.g.,
    percentage of divorced males versus number of people in poverty), dark colors
    indicate variables that covary negatively (e.g., percentage of divorced males
    versus median income), and gray colors indicate variables that are unrelated to
    each other.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªçŸ©é˜µä¸­ï¼Œæµ…è‰²è¡¨ç¤ºæ­£ç›¸å…³çš„å˜é‡ï¼ˆä¾‹å¦‚ï¼Œç¦»å©šç”·æ€§çš„ç™¾åˆ†æ¯”ä¸è´«å›°äººå£æ•°ï¼‰ï¼Œæ·±è‰²è¡¨ç¤ºè´Ÿç›¸å…³çš„å˜é‡ï¼ˆä¾‹å¦‚ï¼Œç¦»å©šç”·æ€§çš„ç™¾åˆ†æ¯”ä¸ä¸­ä½æ”¶å…¥ï¼‰ï¼Œç°è‰²è¡¨ç¤ºå½¼æ­¤æ— å…³çš„å˜é‡ã€‚
- en: As you learned in [ChapterÂ 4](ch04.xhtml#Chapter_4), computing a correlation
    from a covariance simply involves scaling by the norms of the vectors. This can
    be translated into a matrix equation, which will allow you to compute the data
    correlation matrix without `for` loops. [Exercise 7-1](#exercise_7_1) and [Exercise
    7-2](#exercise_7_2) will walk you through the procedure. As I wrote in [ChapterÂ 4](ch04.xhtml#Chapter_4),
    I encourage you to work through those exercises before continuing to the next
    section.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä½ åœ¨[ç¬¬å››ç« ](ch04.xhtml#Chapter_4)ä¸­å­¦åˆ°çš„ï¼Œä»åæ–¹å·®è®¡ç®—ç›¸å…³æ€§ä»…æ¶‰åŠå‘é‡çš„èŒƒæ•°ç¼©æ”¾ã€‚è¿™å¯ä»¥è½¬åŒ–ä¸ºä¸€ä¸ªçŸ©é˜µæ–¹ç¨‹ï¼Œè®©ä½ èƒ½å¤Ÿè®¡ç®—æ•°æ®ç›¸å…³çŸ©é˜µè€Œæ— éœ€ä½¿ç”¨`for`å¾ªç¯ã€‚[ç»ƒä¹ 
    7-1](#exercise_7_1) å’Œ [ç»ƒä¹  7-2](#exercise_7_2) å°†å¼•å¯¼ä½ å®Œæˆè¿™ä¸€è¿‡ç¨‹ã€‚æ­£å¦‚æˆ‘åœ¨[ç¬¬å››ç« ](ch04.xhtml#Chapter_4)ä¸­æ‰€å†™ï¼Œæˆ‘é¼“åŠ±ä½ åœ¨ç»§ç»­ä¸‹ä¸€èŠ‚ä¹‹å‰å…ˆå®Œæˆè¿™äº›ç»ƒä¹ ã€‚
- en: '![covmat](assets/plad_0701.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![covmat](assets/plad_0701.png)'
- en: Figure 7-1\. A data covariance matrix
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 7-1\. æ•°æ®åæ–¹å·®çŸ©é˜µ
- en: 'Final note: NumPy has functions to compute covariance and correlation matrices
    (respectively, `np.cov()` and `np.corrcoef()`). In practice, itâ€™s more convenient
    to use those functions than to write out the code yourself. Butâ€”as always in this
    bookâ€”I want you to understand the math and mechanisms that those functions implement.
    Hence, for these exercises you should implement the covariance as a direct translation
    of the formulas instead of calling NumPy functions.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åæ³¨æ„ï¼šNumPyæœ‰ç”¨äºè®¡ç®—åæ–¹å·®å’Œç›¸å…³çŸ©é˜µçš„å‡½æ•°ï¼ˆåˆ†åˆ«æ˜¯`np.cov()`å’Œ`np.corrcoef()`ï¼‰ã€‚åœ¨å®è·µä¸­ï¼Œä½¿ç”¨è¿™äº›å‡½æ•°æ¯”è‡ªå·±ç¼–å†™ä»£ç æ›´æ–¹ä¾¿ã€‚ä½†æ˜¯â€”â€”æ­£å¦‚æœ¬ä¹¦å§‹ç»ˆå¦‚ä¸€åœ°å¼ºè°ƒçš„â€”â€”æˆ‘å¸Œæœ›ä½ ç†è§£è¿™äº›å‡½æ•°å®ç°çš„æ•°å­¦å’Œæœºåˆ¶ã€‚å› æ­¤ï¼Œåœ¨è¿™äº›ç»ƒä¹ ä¸­ï¼Œä½ åº”è¯¥å°†åæ–¹å·®å®ç°ä¸ºç›´æ¥çš„å…¬å¼ç¿»è¯‘ï¼Œè€Œä¸æ˜¯è°ƒç”¨NumPyå‡½æ•°ã€‚
- en: Geometric Transformations via Matrix-Vector Multiplication
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‡ ä½•å˜æ¢é€šè¿‡çŸ©é˜µ-å‘é‡ä¹˜æ³•å®ç°
- en: I mentioned in [ChapterÂ 5](ch05.xhtml#Chapter_5) that one of the purposes of
    matrix-vector multiplication is to apply a geometric transform to a set of coordinates.
    In this section, you will see this in 2D static images and in animations. Along
    the way, youâ€™ll learn about pure rotation matrices and about creating data animations
    in Python.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨[ç¬¬äº”ç« ](ch05.xhtml#Chapter_5)ä¸­æåˆ°ï¼ŒçŸ©é˜µ-å‘é‡ä¹˜æ³•çš„ä¸€ä¸ªç›®çš„æ˜¯å¯¹ä¸€ç»„åæ ‡åº”ç”¨å‡ ä½•å˜æ¢ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œä½ å°†åœ¨äºŒç»´é™æ€å›¾åƒå’ŒåŠ¨ç”»ä¸­çœ‹åˆ°è¿™ä¸€ç‚¹ã€‚é¡ºä¾¿è¯´ä¸€å¥ï¼Œä½ å°†äº†è§£çº¯æ—‹è½¬çŸ©é˜µä»¥åŠå¦‚ä½•åœ¨Pythonä¸­åˆ›å»ºæ•°æ®åŠ¨ç”»ã€‚
- en: 'A â€œpure rotation matrixâ€ rotates a vector while preserving its length. You
    can think about the hands of an analog clock: as time ticks by, the hands rotate
    but do not change in length. A 2D rotation matrix can be expressed as:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: â€œçº¯æ—‹è½¬çŸ©é˜µâ€æ—‹è½¬ä¸€ä¸ªå‘é‡åŒæ—¶ä¿æŒå…¶é•¿åº¦ä¸å˜ã€‚ä½ å¯ä»¥å°†å…¶ç±»æ¯”ä¸ºæ¨¡æ‹Ÿæ—¶é’Ÿçš„æŒ‡é’ˆï¼šéšç€æ—¶é—´çš„æ¨ç§»ï¼ŒæŒ‡é’ˆæ—‹è½¬ä½†é•¿åº¦ä¸å˜ã€‚ä¸€ä¸ªäºŒç»´æ—‹è½¬çŸ©é˜µå¯ä»¥è¡¨ç¤ºä¸ºï¼š
- en: <math alttext="bold upper T equals Start 2 By 2 Matrix 1st Row 1st Column cosine
    left-parenthesis theta right-parenthesis 2nd Column sine left-parenthesis theta
    right-parenthesis 2nd Row 1st Column minus sine left-parenthesis theta right-parenthesis
    2nd Column cosine left-parenthesis theta right-parenthesis EndMatrix" display="block"><mrow><mi>ğ“</mi>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mo form="prefix">cos</mo>
    <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></mtd> <mtd><mrow><mo form="prefix">sin</mo>
    <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mo form="prefix">-sin</mo>
    <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></mtd> <mtd><mrow><mo form="prefix">cos</mo>
    <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold upper T equals Start 2 By 2 Matrix 1st Row 1st Column cosine
    left-parenthesis theta right-parenthesis 2nd Column sine left-parenthesis theta
    right-parenthesis 2nd Row 1st Column minus sine left-parenthesis theta right-parenthesis
    2nd Column cosine left-parenthesis theta right-parenthesis EndMatrix" display="block"><mrow><mi>ğ“</mi>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mo form="prefix">cos</mo>
    <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></mtd> <mtd><mrow><mo form="prefix">sin</mo>
    <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd><mrow><mo form="prefix">-sin</mo>
    <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></mtd> <mtd><mrow><mo form="prefix">cos</mo>
    <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: A pure rotation matrix is an example of an *orthogonal matrix*. I will write
    more about orthogonal matrices in the next chapter, but I would like to point
    out that the columns of <math alttext="bold upper T"><mi>ğ“</mi></math> are orthogonal
    (their dot product is cos(*Î¸*)sin(*Î¸*) âˆ’ sin(*Î¸*)cos(*Î¸*)) and are unit vectors
    (recall the trig identity that cosÂ²(*Î¸*) + sinÂ²(*Î¸*) = 1.)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: çº¯æ—‹è½¬çŸ©é˜µæ˜¯*æ­£äº¤çŸ©é˜µ*çš„ä¸€ä¸ªç¤ºä¾‹ã€‚æˆ‘å°†åœ¨ä¸‹ä¸€ç« æ›´å¤šåœ°è®¨è®ºæ­£äº¤çŸ©é˜µï¼Œä½†æˆ‘æƒ³æŒ‡å‡º<math alttext="bold upper T"><mi>ğ“</mi></math>çš„åˆ—æ˜¯æ­£äº¤çš„ï¼ˆå®ƒä»¬çš„ç‚¹ç§¯æ˜¯cos(*Î¸*)sin(*Î¸*)
    âˆ’ sin(*Î¸*)cos(*Î¸*)ï¼‰å¹¶ä¸”æ˜¯å•ä½å‘é‡ï¼ˆå›å¿†ä¸‰è§’æ’ç­‰å¼cosÂ²(*Î¸*) + sinÂ²(*Î¸*) = 1ï¼‰ã€‚
- en: To use this transformation matrix, set <math alttext="theta"><mi>Î¸</mi></math>
    to some angle of clockwise rotation, and then muliply matrix <math alttext="bold
    upper T"><mi>ğ“</mi></math> by a <math alttext="2 times upper N"><mrow><mn>2</mn>
    <mo>Ã—</mo> <mi>N</mi></mrow></math> matrix of geometric points, where each column
    in that matrix contains the (X,Y) coordinates for each of *N* data points. For
    example, setting <math alttext="theta equals 0"><mrow><mi>Î¸</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    does not change the pointsâ€™ locations (this is because <math alttext="theta equals
    0"><mrow><mi>Î¸</mi> <mo>=</mo> <mn>0</mn></mrow></math> means <math alttext="bold
    upper T equals bold upper I"><mrow><mi>ğ“</mi> <mo>=</mo> <mi>ğˆ</mi></mrow></math>
    ); setting <math alttext="theta equals pi slash 2"><mrow><mi>Î¸</mi> <mo>=</mo>
    <mi>Ï€</mi> <mo>/</mo> <mn>2</mn></mrow></math> rotates the points by <math alttext="90
    Superscript ring"><msup><mn>90</mn> <mo>âˆ˜</mo></msup></math> around the origin.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¦ä½¿ç”¨æ­¤å˜æ¢çŸ©é˜µï¼Œå°†<math alttext="theta"><mi>Î¸</mi></math>è®¾ç½®ä¸ºæŸä¸ªé¡ºæ—¶é’ˆæ—‹è½¬çš„è§’åº¦ï¼Œç„¶åå°†çŸ©é˜µ<math alttext="bold
    upper T"><mi>ğ“</mi></math>ä¹˜ä»¥ä¸€ä¸ª<math alttext="2 times upper N"><mrow><mn>2</mn>
    <mo>Ã—</mo> <mi>N</mi></mrow></math>å‡ ä½•ç‚¹çŸ©é˜µï¼Œè¯¥çŸ©é˜µä¸­æ¯ä¸€åˆ—åŒ…å«*N*ä¸ªæ•°æ®ç‚¹çš„(X,Y)åæ ‡ã€‚ä¾‹å¦‚ï¼Œè®¾ç½®<math alttext="theta
    equals 0"><mrow><mi>Î¸</mi> <mo>=</mo> <mn>0</mn></mrow></math>ä¸ä¼šæ”¹å˜ç‚¹çš„ä½ç½®ï¼ˆè¿™æ˜¯å› ä¸º<math
    alttext="theta equals 0"><mrow><mi>Î¸</mi> <mo>=</mo> <mn>0</mn></mrow></math>æ„å‘³ç€<math
    alttext="bold upper T equals bold upper I"><mrow><mi>ğ“</mi> <mo>=</mo> <mi>ğˆ</mi></mrow></math>ï¼‰ï¼›è®¾ç½®<math
    alttext="theta equals pi slash 2"><mrow><mi>Î¸</mi> <mo>=</mo> <mi>Ï€</mi> <mo>/</mo>
    <mn>2</mn></mrow></math>ä¼šä½¿ç‚¹å›´ç»•åŸç‚¹é€†æ—¶é’ˆæ—‹è½¬<math alttext="90 Superscript ring"><msup><mn>90</mn>
    <mo>âˆ˜</mo></msup></math>ã€‚
- en: As a simple example, consider a set of points aligned in a vertical line and
    the effect of multiplying those coordinates by <math alttext="bold upper T"><mi>ğ“</mi></math>
    . In [FigureÂ 7-2](#fig_7_2), I set <math alttext="theta equals pi slash 5"><mrow><mi>Î¸</mi>
    <mo>=</mo> <mi>Ï€</mi> <mo>/</mo> <mn>5</mn></mrow></math> .
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¾ä¸ªç®€å•çš„ä¾‹å­ï¼Œè€ƒè™‘ä¸€ç»„å‚ç›´æ’åˆ—çš„ç‚¹é›†ä»¥åŠé€šè¿‡<math alttext="bold upper T"><mi>ğ“</mi></math>ä¹˜ä»¥è¿™äº›åæ ‡çš„æ•ˆæœã€‚åœ¨[å›¾7-2](#fig_7_2)ä¸­ï¼Œæˆ‘è®¾ç½®äº†<math
    alttext="theta equals pi slash 5"><mrow><mi>Î¸</mi> <mo>=</mo> <mi>Ï€</mi> <mo>/</mo>
    <mn>5</mn></mrow></math>ã€‚
- en: '![Pure rotation](assets/plad_0702.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![çº¯æ—‹è½¬](assets/plad_0702.png)'
- en: Figure 7-2\. Twirling points around the origin through a pure rotation matrix
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾7-2. å›´ç»•åŸç‚¹é€šè¿‡çº¯æ—‹è½¬çŸ©é˜µæ—‹è½¬ç‚¹
- en: Before continuing with this section, please inspect the online code that generates
    this figure. Make sure you understand how the math I wrote above is translated
    into code, and take a moment to experiment with different rotation angles. You
    can also try to figure out how to make the rotation counterclockwise instead of
    clockwise; the answer is in the footnote.^([2](ch07.xhtml#idm45733299628944))
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç»§ç»­æœ¬èŠ‚ä¹‹å‰ï¼Œè¯·æ£€æŸ¥ç”Ÿæˆæ­¤å›¾çš„åœ¨çº¿ä»£ç ã€‚ç¡®ä¿æ‚¨ç†è§£æˆ‘ä¸Šé¢å†™çš„æ•°å­¦å¦‚ä½•è½¬åŒ–ä¸ºä»£ç ï¼Œå¹¶èŠ±äº›æ—¶é—´å°è¯•ä¸åŒçš„æ—‹è½¬è§’åº¦ã€‚æ‚¨ä¹Ÿå¯ä»¥å°è¯•å¼„æ¸…æ¥šå¦‚ä½•ä½¿æ—‹è½¬é€†æ—¶é’ˆè€Œä¸æ˜¯é¡ºæ—¶é’ˆï¼›ç­”æ¡ˆåœ¨è„šæ³¨ä¸­ã€‚^([2](ch07.xhtml#idm45733299628944))
- en: Letâ€™s make our investigations of rotations more exciting by using â€œimpureâ€ rotations
    (that is, stretching and rotating, not only rotating) and by animating the transformations.
    In particular, we will smoothly adjust the transformation matrix at each frame
    of a movie.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä½¿ç”¨â€œä¸çº¯â€çš„æ—‹è½¬ï¼ˆå³æ‹‰ä¼¸å’Œæ—‹è½¬ï¼Œè€Œä¸ä»…ä»…æ˜¯æ—‹è½¬ï¼‰ï¼Œå¹¶é€šè¿‡åŠ¨ç”»å˜æ¢æ¥ä½¿æˆ‘ä»¬å¯¹æ—‹è½¬çš„è°ƒæŸ¥æ›´åŠ ç²¾å½©ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å°†åœ¨ç”µå½±çš„æ¯ä¸€å¸§å¹³æ»‘è°ƒæ•´å˜æ¢çŸ©é˜µã€‚
- en: There are several ways to create animations in Python; the method Iâ€™ll use here
    involves defining a Python function that creates the figure content on each movie
    frame, then calling a `matplotlib` routine to run that function on each iteration
    of the movie.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨Pythonä¸­åˆ›å»ºåŠ¨ç”»æœ‰å‡ ç§æ–¹æ³•ï¼›æˆ‘å°†åœ¨è¿™é‡Œä½¿ç”¨çš„æ–¹æ³•æ¶‰åŠå®šä¹‰ä¸€ä¸ªPythonå‡½æ•°ï¼Œåœ¨æ¯ä¸ªç”µå½±å¸§ä¸Šåˆ›å»ºå›¾å½¢å†…å®¹ï¼Œç„¶åè°ƒç”¨`matplotlib`ä¾‹ç¨‹åœ¨æ¯æ¬¡è¿­ä»£ä¸­è¿è¡Œè¯¥å‡½æ•°ã€‚
- en: I call this movie *The Wobbly Circle*. Circles are defined by a set of <math
    alttext="cosine left-parenthesis theta right-parenthesis"><mrow><mo form="prefix">cos</mo>
    <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></math> and <math alttext="sine left-parenthesis
    theta right-parenthesis"><mrow><mo form="prefix">sin</mo> <mo>(</mo> <mi>Î¸</mi>
    <mo>)</mo></mrow></math> points, for a vector of <math alttext="theta"><mi>Î¸</mi></math>
    angles that range from 0 to <math alttext="2 pi"><mrow><mn>2</mn> <mi>Ï€</mi></mrow></math>
    .
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ç§°è¿™éƒ¨ç”µå½±ä¸º*æ‘‡æ‘†çš„åœ†*ã€‚åœ†ç”±ä¸€ç»„<math alttext="cosine left-parenthesis theta right-parenthesis"><mrow><mo
    form="prefix">cos</mo> <mo>(</mo> <mi>Î¸</mi> <mo>)</mo></mrow></math>å’Œ<math alttext="sine
    left-parenthesis theta right-parenthesis"><mrow><mo form="prefix">sin</mo> <mo>(</mo>
    <mi>Î¸</mi> <mo>)</mo></mrow></math>ç‚¹å®šä¹‰ï¼Œå‘é‡<math alttext="theta"><mi>Î¸</mi></math>è§’ä»0åˆ°<math
    alttext="2 pi"><mrow><mn>2</mn> <mi>Ï€</mi></mrow></math>ã€‚
- en: 'I set the transformation matrix to the following:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘è®¾ç½®äº†ä»¥ä¸‹çš„å˜æ¢çŸ©é˜µï¼š
- en: <math alttext="bold upper T equals Start 2 By 2 Matrix 1st Row 1st Column 1
    2nd Column 1 minus phi 2nd Row 1st Column 0 2nd Column 1 EndMatrix" display="block"><mrow><mi>ğ“</mi>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mrow><mn>1</mn>
    <mo>-</mo> <mi>Ï†</mi></mrow></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold upper T equals Start 2 By 2 Matrix 1st Row 1st Column 1
    2nd Column 1 minus phi 2nd Row 1st Column 0 2nd Column 1 EndMatrix" display="block"><mrow><mi>ğ“</mi>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mrow><mn>1</mn>
    <mo>-</mo> <mi>Ï†</mi></mrow></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: Why did I pick these specific values, and how do you interpret a transformation
    matrix? In general, the diagonal elements scale the *x*-axis and *y*-axis coordinates,
    while the off-diagonal elements stretch both axes. The exact values in the matrix
    above were selected by playing around with the numbers until I found something
    that I thought looked neat. Later on, and in the exercises, you will have the
    opportunity to explore the effects of changing the transformation matrix.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¸ºä»€ä¹ˆé€‰æ‹©è¿™äº›å…·ä½“å€¼ï¼Œæ‚¨å¦‚ä½•è§£é‡Šå˜æ¢çŸ©é˜µï¼Ÿä¸€èˆ¬æ¥è¯´ï¼Œå¯¹è§’å…ƒç´ ç¼©æ”¾*x*-è½´å’Œ*y*-è½´åæ ‡ï¼Œè€Œéå¯¹è§’å…ƒç´ åˆ™æ‹‰ä¼¸ä¸¤ä¸ªè½´ã€‚ä¸Šè¿°çŸ©é˜µä¸­çš„ç¡®åˆ‡å€¼æ˜¯é€šè¿‡å°è¯•ä¸åŒçš„æ•°å­—ç›´åˆ°æˆ‘æ‰¾åˆ°çœ‹èµ·æ¥ä¸é”™çš„ç»“æœè€Œé€‰æ‹©çš„ã€‚ç¨åï¼Œåœ¨ç»ƒä¹ ä¸­ï¼Œæ‚¨å°†æœ‰æœºä¼šæ¢ç´¢æ›´æ”¹å˜æ¢çŸ©é˜µçš„æ•ˆæœã€‚
- en: Over the course of the movie, the value of <math alttext="phi"><mi>Ï†</mi></math>
    will smoothly transition from 1 to 0 and back to 1, following the formula <math
    alttext="phi equals x squared comma negative 1 less-than-or-equal-to x less-than-or-equal-to
    1"><mrow><mi>Ï†</mi><mo>=</mo><msup><mi>x</mi> <mn>2</mn></msup> <mo>,</mo><mrow><mo>-</mo><mn>1</mn></mrow><mo>â‰¤</mo><mi>x</mi><mo>â‰¤</mo><mn>1</mn></mrow></math>.
    Note that <math alttext="bold upper T equals bold upper I"><mrow><mi>ğ“</mi> <mo>=</mo>
    <mi>ğˆ</mi></mrow></math> when <math alttext="phi equals 1"><mrow><mi>Ï†</mi> <mo>=</mo>
    <mn>1</mn></mrow></math> .
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç”µå½±çš„è¿‡ç¨‹ä¸­ï¼Œ<math alttext="phi"><mi>Ï†</mi></math> çš„å€¼å°†å¹³ç¨³è¿‡æ¸¡ä» 1 åˆ° 0ï¼Œç„¶åå†åˆ° 1ï¼Œéµå¾ªå…¬å¼ <math
    alttext="phi equals x squared comma negative 1 less-than-or-equal-to x less-than-or-equal-to
    1"><mrow><mi>Ï†</mi><mo>=</mo><msup><mi>x</mi> <mn>2</mn></msup> <mo>,</mo><mrow><mo>-</mo><mn>1</mn></mrow><mo>â‰¤</mo><mi>x</mi><mo>â‰¤</mo><mn>1</mn></mrow>ã€‚æ³¨æ„ï¼Œå½“
    <math alttext="phi equals 1"><mrow><mi>Ï†</mi> <mo>=</mo> <mn>1</mn></mrow> æ—¶ï¼Œ<math
    alttext="bold upper T equals bold upper I"><mrow><mi>ğ“</mi> <mo>=</mo> <mi>ğˆ</mi></mrow></math>ã€‚
- en: 'The Python code for a data animation can be separated into three parts. The
    first part is to set up the figure:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®åŠ¨ç”»çš„ Python ä»£ç å¯ä»¥åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ã€‚ç¬¬ä¸€éƒ¨åˆ†æ˜¯è®¾ç½®å›¾å½¢ï¼š
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The output of `ax.plot` is a variable `plth`, which is a *handle*, or a pointer,
    to the plot object. That handle allows us to update the locations of the dots
    rather than redrawing the figure from scratch on each frame.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`ax.plot` çš„è¾“å‡ºæ˜¯å˜é‡ `plth`ï¼Œå®ƒæ˜¯ä¸€ä¸ª*å¥æŸ„*æˆ–æŒ‡é’ˆï¼ŒæŒ‡å‘ç»˜å›¾å¯¹è±¡ã€‚è¿™ä¸ªå¥æŸ„å…è®¸æˆ‘ä»¬æ›´æ–°ç‚¹çš„ä½ç½®ï¼Œè€Œä¸æ˜¯åœ¨æ¯ä¸€å¸§ä¸Šä»å¤´å¼€å§‹é‡ç»˜å›¾å½¢ã€‚'
- en: 'The second part is to define the function that updates the axis on each frame:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬äºŒéƒ¨åˆ†æ˜¯å®šä¹‰åœ¨æ¯ä¸€å¸§æ›´æ–°åæ ‡è½´çš„å‡½æ•°ï¼š
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we define our transform parameter <math alttext="phi"><mi>Ï†</mi></math>
    and call the `matplotlib` function that creates the animation:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬å®šä¹‰æˆ‘ä»¬çš„å˜æ¢å‚æ•° <math alttext="phi"><mi>Ï†</mi></math> å¹¶è°ƒç”¨åˆ›å»ºåŠ¨ç”»çš„ `matplotlib` å‡½æ•°ï¼š
- en: '[PRE3]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[FigureÂ 7-3](#fig_7_3) show one frame of the movie, and you can watch the entire
    video by running the code. Admittedly, this movie is unlikely to win any awards,
    but it does show how matrix multiplication is used in animations. The graphics
    in CGI movies and video games are slightly more complicated because they use mathematical
    objects called quaternions, which are vectors in <math alttext="double-struck
    upper R Superscript 4"><msup><mi>â„</mi> <mn>4</mn></msup></math> that allow for
    rotations and translations in 3D. But the principleâ€”multiply a matrix of geometric
    coordinates by a transformation matrixâ€”is exactly the same.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 7-3](#fig_7_3) å±•ç¤ºäº†ç”µå½±çš„ä¸€ä¸ªå¸§ï¼Œæ‚¨å¯ä»¥é€šè¿‡è¿è¡Œä»£ç è§‚çœ‹æ•´ä¸ªè§†é¢‘ã€‚è¯šç„¶ï¼Œè¿™éƒ¨ç”µå½±ä¸å¤ªå¯èƒ½èµ¢å¾—ä»»ä½•å¥–é¡¹ï¼Œä½†å®ƒç¡®å®å±•ç¤ºäº†åœ¨åŠ¨ç”»ä¸­å¦‚ä½•ä½¿ç”¨çŸ©é˜µä¹˜æ³•ã€‚CGI
    ç”µå½±å’Œè§†é¢‘æ¸¸æˆä¸­çš„å›¾å½¢ç¨å¾®å¤æ‚ä¸€äº›ï¼Œå› ä¸ºå®ƒä»¬ä½¿ç”¨ç§°ä¸ºå››å…ƒæ•°çš„æ•°å­¦å¯¹è±¡ï¼Œè¿™äº›å››å…ƒæ•°æ˜¯åœ¨ <math alttext="double-struck upper
    R Superscript 4"><msup><mi>â„</mi> <mn>4</mn></msup></math> ä¸­çš„å‘é‡ï¼Œå…è®¸åœ¨ 3D ä¸­è¿›è¡Œæ—‹è½¬å’Œå¹³ç§»ã€‚ä½†åŸç†â€”â€”é€šè¿‡å˜æ¢çŸ©é˜µä¹˜ä»¥å‡ ä½•åæ ‡çš„çŸ©é˜µâ€”â€”å®Œå…¨ç›¸åŒã€‚'
- en: '![Pure rotation](assets/plad_0703.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![çº¯æ—‹è½¬](assets/plad_0703.png)'
- en: Figure 7-3\. A frame of the movie The Wobbly Circle
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 7-3\. ç”µå½±ã€Šæ‘‡æ™ƒçš„åœ†ã€‹çš„ä¸€ä¸ªå¸§
- en: 'Before working through the exercises for this section, I encourage you to spend
    some time playing around with the code for this section. In particular, change
    the transformation matrix by setting one of the diagonal elements to .5 or 2,
    change the lower-left off-diagonal element instead of (or in addition to) the
    upper-right off-diagonal element, parameterize one of the diagonal elements instead
    of the off-diagonal element, and so on. And hereâ€™s a question: can you figure
    out how to get the circle to wobble to the left instead of to the right? The answer
    is in the footnote.^([3](ch07.xhtml#idm45733299335200))'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å¤„ç†æœ¬èŠ‚çš„ç»ƒä¹ ä¹‹å‰ï¼Œæˆ‘é¼“åŠ±æ‚¨èŠ±äº›æ—¶é—´å°è¯•æœ¬èŠ‚çš„ä»£ç ã€‚ç‰¹åˆ«æ˜¯ï¼Œé€šè¿‡å°†å¯¹è§’å…ƒç´ ä¹‹ä¸€è®¾ç½®ä¸º 0.5 æˆ– 2ï¼Œæ›´æ”¹å·¦ä¸‹è§’çš„éå¯¹è§’å…ƒç´ è€Œä¸æ˜¯ï¼ˆæˆ–è€…é™¤æ­¤ä¹‹å¤–è¿˜ï¼‰å³ä¸Šè§’çš„éå¯¹è§’å…ƒç´ ï¼Œå°†å…¶ä¸­ä¸€ä¸ªå¯¹è§’å…ƒç´ å‚æ•°åŒ–è€Œä¸æ˜¯éå¯¹è§’å…ƒç´ ç­‰ã€‚å¹¶ä¸”è¿™é‡Œæœ‰ä¸ªé—®é¢˜ï¼šæ‚¨èƒ½æƒ³å‡ºå¦‚ä½•è®©åœ†å‘å·¦è€Œä¸æ˜¯å‘å³æ‘‡æ‘†å—ï¼Ÿç­”æ¡ˆåœ¨è„šæ³¨ä¸­ã€‚^([3](ch07.xhtml#idm45733299335200))
- en: Image Feature Detection
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å›¾åƒç‰¹å¾æ£€æµ‹
- en: In this section, I will introduce you to image filtering, which is a mechanism
    for image feature detection. Image filtering is actually an extension of time
    series filtering, so having gone through [ChapterÂ 4](ch04.xhtml#Chapter_4) will
    benefit you here. Recall that to filter or detect features in a time series signal,
    you design a kernel, and then create a time series of dot products between the
    kernel and overlapping segments of the signal.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘å°†ä»‹ç»å›¾åƒæ»¤æ³¢ï¼Œè¿™æ˜¯å›¾åƒç‰¹å¾æ£€æµ‹çš„ä¸€ç§æœºåˆ¶ã€‚å›¾åƒæ»¤æ³¢å®é™…ä¸Šæ˜¯æ—¶é—´åºåˆ—æ»¤æ³¢çš„ä¸€ä¸ªå»¶ä¼¸ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œé€šè¿‡[ç¬¬4ç« ](ch04.xhtml#Chapter_4)ä¼šå¯¹ä½ æœ‰åˆ©ã€‚å›æƒ³ä¸€ä¸‹ï¼Œåœ¨æ—¶é—´åºåˆ—ä¿¡å·ä¸­è¿›è¡Œç‰¹å¾è¿‡æ»¤æˆ–æ£€æµ‹æ—¶ï¼Œä½ è®¾è®¡ä¸€ä¸ªæ ¸ï¼Œç„¶ååˆ›å»ºæ ¸ä¸ä¿¡å·é‡å æ®µçš„ç‚¹ä¹˜æ—¶é—´åºåˆ—ã€‚
- en: Image filtering works the same way except in 2D instead of 1D. We design a 2D
    kernel, and then create a new image comprising â€œdot productsâ€ between the kernel
    and overlapping windows of the image.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒæ»¤æ³¢çš„å·¥ä½œæ–¹å¼ä¸1Dç›¸åŒï¼Œåªæ˜¯åœ¨2Dä¸­ã€‚æˆ‘ä»¬è®¾è®¡ä¸€ä¸ª2Dæ ¸ï¼Œç„¶ååˆ›å»ºä¸€ä¸ªæ–°å›¾åƒï¼Œå…¶ä¸­åŒ…å«æ ¸ä¸å›¾åƒé‡å çª—å£ä¹‹é—´çš„â€œç‚¹ä¹˜â€ã€‚
- en: I wrote â€œdot productsâ€ in apology quotes because the operation here is not formally
    the same as the vector dot product. The computation is the sameâ€”element-wise multiplication
    and sumâ€”however, the operation takes place between two matrices, so the implementation
    is Hadamard multiplication and sum over all matrix elements. Graph A in [FigureÂ 7-4](#fig_7_4)
    illustrates the procedure. There are additional details of convolutionâ€”for example,
    padding the image so that the result is the same sizeâ€”that you would learn about
    in an image-processing book. Here Iâ€™d like you to focus on the linear algebra
    aspects, in particular, the idea that the dot product quantifies the relationship
    between two vectors (or matrices), which can be used for filtering and feature
    detection.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨å¼•å·ä¸­å†™äº†â€œç‚¹ä¹˜â€ï¼Œå› ä¸ºè¿™é‡Œçš„æ“ä½œä¸å‘é‡ç‚¹ä¹˜å¹¶ä¸å®Œå…¨ç›¸åŒã€‚è®¡ç®—æ–¹å¼ç›¸åŒâ€”â€”é€å…ƒç´ ç›¸ä¹˜å’Œæ±‚å’Œâ€”â€”ä½†æ˜¯æ“ä½œå‘ç”Ÿåœ¨ä¸¤ä¸ªçŸ©é˜µä¹‹é—´ï¼Œå› æ­¤å®ç°æ˜¯Hadamardä¹˜ç§¯å¹¶å¯¹æ‰€æœ‰çŸ©é˜µå…ƒç´ æ±‚å’Œã€‚å›¾Aåœ¨[å›¾7-4](#fig_7_4)ä¸­è¯´æ˜äº†è¯¥è¿‡ç¨‹ã€‚è¿˜æœ‰å·ç§¯çš„é¢å¤–ç»†èŠ‚â€”â€”ä¾‹å¦‚ï¼Œå¡«å……å›¾åƒä»¥ä½¿ç»“æœå¤§å°ç›¸åŒâ€”â€”ä½ å¯ä»¥åœ¨å›¾åƒå¤„ç†ä¹¦ç±ä¸­äº†è§£ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å¸Œæœ›ä½ ä¸“æ³¨äºçº¿æ€§ä»£æ•°æ–¹é¢ï¼Œç‰¹åˆ«æ˜¯ç‚¹ç§¯é‡åŒ–äº†ä¸¤ä¸ªå‘é‡ï¼ˆæˆ–çŸ©é˜µï¼‰ä¹‹é—´çš„å…³ç³»ï¼Œè¿™å¯ä»¥ç”¨äºæ»¤æ³¢å’Œç‰¹å¾æ£€æµ‹ã€‚
- en: '![imconv](assets/plad_0704.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![imconv](assets/plad_0704.png)'
- en: Figure 7-4\. Mechanism of image convolution
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾7-4. å›¾åƒå·ç§¯æœºåˆ¶
- en: 'Before moving on to the analysis, I will briefly explain how a 2D Gaussian
    kernel is created. A 2D Gaussian is given by the following equation:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›è¡Œåˆ†æä¹‹å‰ï¼Œæˆ‘å°†ç®€è¦è§£é‡Šå¦‚ä½•åˆ›å»ºä¸€ä¸ª2Dé«˜æ–¯æ ¸ã€‚2Dé«˜æ–¯ç”±ä»¥ä¸‹æ–¹ç¨‹ç»™å‡ºï¼š
- en: <math alttext="upper G equals exp left-parenthesis minus left-parenthesis upper
    X squared plus upper Y squared right-parenthesis slash sigma right-parenthesis"
    display="block"><mrow><mi>G</mi> <mo>=</mo> <mo form="prefix">exp</mo> <mo>(</mo>
    <mo>-</mo> <mrow><mo>(</mo> <msup><mi>X</mi> <mn>2</mn></msup> <mo>+</mo> <msup><mi>Y</mi>
    <mn>2</mn></msup> <mo>)</mo></mrow> <mo>/</mo> <mi>Ïƒ</mi> <mo>)</mo></mrow></math>
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper G equals exp left-parenthesis minus left-parenthesis upper
    X squared plus upper Y squared right-parenthesis slash sigma right-parenthesis"
    display="block"><mrow><mi>G</mi> <mo>=</mo> <mo form="prefix">exp</mo> <mo>(</mo>
    <mo>-</mo> <mrow><mo>(</mo> <msup><mi>X</mi> <mn>2</mn></msup> <mo>+</mo> <msup><mi>Y</mi>
    <mn>2</mn></msup> <mo>)</mo></mrow> <mo>/</mo> <mi>Ïƒ</mi> <mo>)</mo></mrow></math>
- en: 'A few notes about that equation: *exp* stands for the natural exponential (the
    constant *e* = 2.71828â€¦), and exp(x) is used instead of *e*^x when the exponential
    term is long. The *X* and *Y* are 2D grids of x,y coordinates on which to evaluate
    the function. Finally, <math alttext="sigma"><mi>Ïƒ</mi></math> is a parameter
    of the function that is often called the â€œshapeâ€ or â€œwidthâ€: smaller values make
    the Gaussian narrower, while larger values make the Gaussian wider. For now, I
    will fix that parameter to certain values, and youâ€™ll get to explore the implications
    of changing that parameter in [Exercise 7-6](#exercise_7_6).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºè¯¥æ–¹ç¨‹çš„ä¸€äº›è¯´æ˜ï¼š*exp*ä»£è¡¨è‡ªç„¶æŒ‡æ•°ï¼ˆå¸¸æ•°*e* = 2.71828â€¦ï¼‰ï¼Œå½“æŒ‡æ•°é¡¹è¾ƒé•¿æ—¶ï¼Œä½¿ç”¨exp(x)è€Œä¸æ˜¯*e*^xã€‚*X*å’Œ*Y*æ˜¯2Dåæ ‡ç½‘æ ¼ï¼Œç”¨äºè¯„ä¼°å‡½æ•°ã€‚æœ€åï¼Œ<math
    alttext="sigma"><mi>Ïƒ</mi></math>æ˜¯å‡½æ•°çš„ä¸€ä¸ªå‚æ•°ï¼Œé€šå¸¸ç§°ä¸ºâ€œå½¢çŠ¶â€æˆ–â€œå®½åº¦â€ï¼šè¾ƒå°çš„å€¼ä½¿é«˜æ–¯å˜çª„ï¼Œè€Œè¾ƒå¤§çš„å€¼ä½¿é«˜æ–¯å˜å®½ã€‚ç°åœ¨ï¼Œæˆ‘å°†è¯¥å‚æ•°å›ºå®šä¸ºæŸäº›å€¼ï¼Œä½ å°†æœ‰æœºä¼šæ¢ç´¢æ”¹å˜è¯¥å‚æ•°çš„å½±å“åœ¨[ç»ƒä¹ 7-6](#exercise_7_6)ä¸­ã€‚
- en: 'Hereâ€™s how that formula translates into code:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯å¦‚ä½•å°†è¯¥å…¬å¼è½¬åŒ–ä¸ºä»£ç ï¼š
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The *X* and *Y* grids go from âˆ’3 to +3 in 21 steps. The width parameter is hard
    coded to 20\. The third line normalizes the values in the kernel so that the sum
    over the entire kernel is 1\. That preserves the original scale of the data. When
    properly normalized, each step of convolutionâ€”and therefore, each pixel in the
    filtered imageâ€”becomes a weighted average of the surrounding pixels, with the
    weights defined by the Gaussian.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*X*å’Œ*Y*ç½‘æ ¼ä»-3åˆ°+3ï¼Œæ­¥é•¿ä¸º21æ­¥ã€‚å®½åº¦å‚æ•°ç¡¬ç¼–ç ä¸º20ã€‚ç¬¬ä¸‰è¡Œå¯¹æ ¸ä¸­çš„å€¼è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿æ•´ä¸ªæ ¸çš„æ€»å’Œä¸º1ã€‚è¿™ä¿æŒäº†æ•°æ®çš„åŸå§‹æ¯”ä¾‹ã€‚å½“æ­£ç¡®å½’ä¸€åŒ–æ—¶ï¼Œæ¯ä¸€æ­¥å·ç§¯â€”â€”å› æ­¤ï¼Œè¿‡æ»¤åå›¾åƒä¸­çš„æ¯ä¸ªåƒç´ â€”â€”éƒ½æˆä¸ºå‘¨å›´åƒç´ çš„åŠ æƒå¹³å‡å€¼ï¼Œæƒé‡ç”±é«˜æ–¯å®šä¹‰ã€‚'
- en: 'Back to the task at hand: we will smooth a random-numbers matrix, similar to
    how we smoothed a random-numbers time series in [ChapterÂ 4](ch04.xhtml#Chapter_4).
    You can see the random-numbers matrix, the Gaussian kernel, and the result of
    convolution in [FigureÂ 7-4](#fig_7_4).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: å›åˆ°æ‰‹å¤´çš„ä»»åŠ¡ï¼šæˆ‘ä»¬å°†å¹³æ»‘ä¸€ä¸ªéšæœºæ•°çŸ©é˜µï¼Œç±»ä¼¼äºæˆ‘ä»¬åœ¨[ç¬¬å››ç« ](ch04.xhtml#Chapter_4)ä¸­å¹³æ»‘éšæœºæ•°æ—¶é—´åºåˆ—çš„æ–¹å¼ã€‚ä½ å¯ä»¥åœ¨[å›¾Â 7-4](#fig_7_4)ä¸­çœ‹åˆ°éšæœºæ•°çŸ©é˜µã€é«˜æ–¯æ ¸ä»¥åŠå·ç§¯ç»“æœã€‚
- en: 'The following Python code shows how image convolution is implemented. Again,
    think back to the time series convolution in [ChapterÂ 4](ch04.xhtml#Chapter_4)
    to appreciate that the idea is the same but with an extra dimension necessitating
    an extra `for` loop:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹Pythonä»£ç å±•ç¤ºäº†å¦‚ä½•å®ç°å›¾åƒå·ç§¯ã€‚å†æ¬¡å›æƒ³ä¸€ä¸‹[ç¬¬å››ç« ](ch04.xhtml#Chapter_4)ä¸­çš„æ—¶é—´åºåˆ—å·ç§¯ï¼Œä½ ä¼šå‘ç°å…¶æ€æƒ³ç›¸åŒï¼Œåªæ˜¯å¤šäº†ä¸€ä¸ªç»´åº¦ï¼Œéœ€è¦é¢å¤–çš„`for`å¾ªç¯ï¼š
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Implementing convolution as a double `for` loop is actually computationally
    inefficient. It turns out that convolution can be implemented faster and with
    less code in the frequency domain. This is thanks to the convolution theorem,
    which states that convolution in the time (or space) domain is equal to multiplication
    in the frequency domain. A full exposition of the convolution theorem is outside
    the scope of this book; I mention it here to justify the recommendation that you
    use SciPyâ€™s `convolve2d` function instead of the double `for` loop implementation,
    particularly for large images.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: å°†å·ç§¯å®ç°ä¸ºåŒé‡`for`å¾ªç¯å®é™…ä¸Šè®¡ç®—æ•ˆç‡ä½ä¸‹ã€‚äº‹å®è¯æ˜ï¼Œåœ¨é¢‘åŸŸä¸­å¯ä»¥æ›´å¿«é€Ÿåœ°å®ç°å·ç§¯ï¼Œå¹¶ä¸”ä»£ç æ›´å°‘ã€‚è¿™è¦å½’åŠŸäºå·ç§¯å®šç†ï¼Œè¯¥å®šç†æŒ‡å‡ºæ—¶é—´ï¼ˆæˆ–ç©ºé—´ï¼‰åŸŸä¸­çš„å·ç§¯ç­‰äºé¢‘ç‡åŸŸä¸­çš„ä¹˜æ³•ã€‚å¯¹å·ç§¯å®šç†çš„å…¨é¢é˜è¿°è¶…å‡ºäº†æœ¬ä¹¦çš„èŒƒå›´ï¼›æˆ‘åœ¨æ­¤æåˆ°å®ƒæ˜¯ä¸ºäº†å»ºè®®ä½ ä½¿ç”¨SciPyçš„`convolve2d`å‡½æ•°è€Œä¸æ˜¯åŒé‡`for`å¾ªç¯å®ç°ï¼Œå°¤å…¶æ˜¯å¯¹äºå¤§å›¾åƒã€‚
- en: Letâ€™s try smoothing a real picture. Weâ€™ll use a picture of the Stedelijk Museum
    in Amsterdam, which I lovingly call â€œthe bathtub from outer space.â€ This image
    is a 3D matrix because it has rows, columns, and depthâ€”the depth contains pixel
    intensity values from the red, green, and blue color channels. This picture is
    stored as a matrix in <math alttext="double-struck upper R Superscript 1675 times
    3000 times 3"><msup><mi>â„</mi> <mrow><mn>1675</mn><mo>Ã—</mo><mn>3000</mn><mo>Ã—</mo><mn>3</mn></mrow></msup></math>
    . Formally, thatâ€™s called a *tensor* because it is a cube, not a spreadsheet,
    of numbers.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬å°è¯•å¹³æ»‘ä¸€å¼ çœŸå®çš„å›¾ç‰‡ã€‚æˆ‘ä»¬å°†ä½¿ç”¨é˜¿å§†æ–¯ç‰¹ä¸¹æ–¯ç‰¹å¾·åˆ©å…‹åšç‰©é¦†çš„å›¾ç‰‡ï¼Œæˆ‘çˆ±ç§°å®ƒä¸ºâ€œå¤–å¤ªç©ºçš„æµ´ç¼¸â€ã€‚è¿™å¼ å›¾ç‰‡æ˜¯ä¸€ä¸ª3DçŸ©é˜µï¼Œå› ä¸ºå®ƒå…·æœ‰è¡Œã€åˆ—å’Œæ·±åº¦â€”â€”æ·±åº¦åŒ…å«äº†æ¥è‡ªçº¢ã€ç»¿å’Œè“è‰²é€šé“çš„åƒç´ å¼ºåº¦å€¼ã€‚è¿™å¼ å›¾ç‰‡å­˜å‚¨ä¸ºä¸€ä¸ªçŸ©é˜µåœ¨<math
    alttext="double-struck upper R Superscript 1675 times 3000 times 3"><msup><mi>â„</mi>
    <mrow><mn>1675</mn><mo>Ã—</mo><mn>3000</mn><mo>Ã—</mo><mn>3</mn></mrow></msup></math>
    ã€‚ä¸¥æ ¼æ¥è¯´ï¼Œè¿™è¢«ç§°ä¸ºä¸€ä¸ª*å¼ é‡*ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªç«‹æ–¹ä½“ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ•°å­—è¡¨æ ¼ã€‚
- en: For now, we will reduce it to a 2D matrix by converting to grayscale. That simplifies
    the computations, although it is not necessary. In [Exercise 7-5](#exercise_7_5),
    you will figure out how to smooth the 3D image. [FigureÂ 7-5](#fig_7_5) shows the
    grayscale image before and after applying the Gaussian smoothing kernel.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ç›®å‰ï¼Œæˆ‘ä»¬å°†é€šè¿‡è½¬æ¢ä¸ºç°åº¦æ¥å°†å…¶å‡å°‘ä¸º2DçŸ©é˜µã€‚è¿™ç®€åŒ–äº†è®¡ç®—ï¼Œå°½ç®¡å¹¶éå¿…è¦ã€‚åœ¨[ç»ƒä¹  7-5](#exercise_7_5)ä¸­ï¼Œæ‚¨å°†äº†è§£å¦‚ä½•å¹³æ»‘3Då›¾åƒã€‚[å›¾Â 7-5](#fig_7_5)å±•ç¤ºäº†åº”ç”¨é«˜æ–¯å¹³æ»‘æ ¸å‰åçš„ç°åº¦å›¾åƒã€‚
- en: '![Smooth the bathtub.](assets/plad_0705.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![å¹³æ»‘æµ´ç¼¸](assets/plad_0705.png)'
- en: Figure 7-5\. A picture of the bathtub museum, before and after a respectable
    smoothing
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 7-5\. æµ´ç¼¸åšç‰©é¦†çš„å›¾ç‰‡ï¼Œåœ¨è¿›è¡Œäº†é€‚å½“å¹³æ»‘å‰å
- en: Both of these examples used a Gaussian kernel. How many other kernels are available?
    An infinite number! In [Exercise 7-7](#exercise_7_7), you will test two other
    kernels that are used to identify vertical and horizontal lines. Those feature
    detectors are common in image processing (and are used by the neurons in your
    brain to detect edges in the patterns of light that hit your retina).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ä¸ªç¤ºä¾‹éƒ½ä½¿ç”¨äº†é«˜æ–¯æ ¸ã€‚è¿˜æœ‰å¤šå°‘å…¶ä»–æ ¸å¯ç”¨ï¼Ÿæ— é™å¤šä¸ªï¼åœ¨[ç»ƒä¹  7-7](#exercise_7_7)ä¸­ï¼Œæ‚¨å°†æµ‹è¯•å¦å¤–ä¸¤ä¸ªç”¨äºè¯†åˆ«å‚ç›´å’Œæ°´å¹³çº¿çš„æ ¸ã€‚è¿™äº›ç‰¹å¾æ£€æµ‹å™¨åœ¨å›¾åƒå¤„ç†ä¸­å¾ˆå¸¸è§ï¼ˆå¹¶ä¸”è¢«ç”¨äºæ‚¨å¤§è„‘ä¸­ç”¨äºæ£€æµ‹å…‰æ¨¡å¼ä¸­è¾¹ç¼˜çš„ç¥ç»å…ƒï¼‰ã€‚
- en: Image convolution kernels are a major topic in computer vision. In fact, the
    incredible performance of convolutional neural networks (the deep learning architecture
    optimized for computer vision) is entirely due to the networkâ€™s ability to craft
    optimal filter kernels through learning.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾åƒå·ç§¯æ ¸åœ¨è®¡ç®—æœºè§†è§‰ä¸­æ˜¯ä¸€ä¸ªé‡è¦çš„ä¸»é¢˜ã€‚äº‹å®ä¸Šï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆä¸“ä¸ºè®¡ç®—æœºè§†è§‰ä¼˜åŒ–çš„æ·±åº¦å­¦ä¹ æ¶æ„ï¼‰çš„æƒŠäººæ€§èƒ½å®Œå…¨å½’å› äºç½‘ç»œé€šè¿‡å­¦ä¹ æ¥åˆ¶ä½œæœ€ä½³çš„æ»¤æ³¢å™¨æ ¸ã€‚
- en: Summary
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: 'Iâ€™ll keep this simple: the point is thatâ€”yet againâ€”incredibly important and
    sophisticated methods in data science and machine learning are built on simple
    linear algebra principles.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ç®€å•è§£é‡Šä¸€ä¸‹ï¼šé‡è¦ä¸”å¤æ‚çš„æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ æ–¹æ³•åˆä¸€æ¬¡æ˜¯å»ºç«‹åœ¨ç®€å•çš„çº¿æ€§ä»£æ•°åŸç†ä¸Šã€‚
- en: Code Exercises
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»£ç ç»ƒä¹ 
- en: Covariance and Correlation Matrices Exercises
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: åæ–¹å·®å’Œç›¸å…³çŸ©é˜µç»ƒä¹ 
- en: Exercise 7-1\.
  id: totrans-79
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Exercise 7-1\.
- en: In this exercise, you will transform the covariance matrix into a correlation
    matrix. The procedure involves dividing each matrix element (that is, the covariance
    between each pair of variables) by the product of the variances of those two variables.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œä½ å°†æŠŠåæ–¹å·®çŸ©é˜µè½¬æ¢ä¸ºç›¸å…³çŸ©é˜µã€‚è¯¥è¿‡ç¨‹æ¶‰åŠå°†æ¯ä¸ªçŸ©é˜µå…ƒç´ ï¼ˆå³æ¯å¯¹å˜é‡ä¹‹é—´çš„åæ–¹å·®ï¼‰é™¤ä»¥è¿™ä¸¤ä¸ªå˜é‡çš„æ–¹å·®çš„ä¹˜ç§¯ã€‚
- en: This is implemented by pre- and postmultiplying the covariance matrix by a diagonal
    matrix containing inverted standard deviations of each variable (standard deviation
    is the square root of variance). The standard deviations are inverted because
    we need to *divide* by the variances although we will *multiply* matrices. The
    reason for pre- and postmultiplying by standard deviations is the special property
    of pre- and postmultiplying by a diagonal matrix, which was explained in [Exercise
    5-11](ch05.xhtml#exercise_5_11).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯é€šè¿‡å°†åæ–¹å·®çŸ©é˜µåˆ†åˆ«é¢„ä¹˜å’Œåä¹˜ä¸€ä¸ªåŒ…å«æ¯ä¸ªå˜é‡æ ‡å‡†å·®çš„å¯¹è§’çŸ©é˜µï¼ˆæ ‡å‡†å·®æ˜¯æ–¹å·®çš„å¹³æ–¹æ ¹ï¼‰æ¥å®ç°çš„ã€‚æ ‡å‡†å·®è¢«å€’ç½®ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦*é™¤ä»¥*æ–¹å·®ï¼Œå°½ç®¡æˆ‘ä»¬å°†*ä¹˜ä»¥*çŸ©é˜µã€‚é¢„ä¹˜å’Œåä¹˜æ ‡å‡†å·®çš„åŸå› æ˜¯é¢„ä¹˜å’Œåä¹˜å¯¹è§’çŸ©é˜µçš„ç‰¹æ®Šæ€§è´¨ï¼Œè¿™åœ¨[Exercise
    5-11](ch05.xhtml#exercise_5_11)ä¸­å·²ç»è§£é‡Šè¿‡äº†ã€‚
- en: '[Equation 7-1](#cov2corr) shows the formula.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[Equation 7-1](#cov2corr)æ˜¾ç¤ºäº†å…¬å¼ã€‚'
- en: Equation 7-1\. Correlation from covariance
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Equation 7-1\. ä»åæ–¹å·®åˆ°ç›¸å…³çš„å…¬å¼
- en: <math alttext="bold upper R equals bold upper S bold upper C bold upper S" display="block"><mrow><mi>ğ‘</mi>
    <mo>=</mo> <mi>ğ’</mi> <mi>ğ‚</mi> <mi>ğ’</mi></mrow></math>
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold upper R equals bold upper S bold upper C bold upper S" display="block"><mrow><mi>ğ‘</mi>
    <mo>=</mo> <mi>ğ’</mi> <mi>ğ‚</mi> <mi>ğ’</mi></mrow></math>
- en: <math alttext="bold upper C"><mi>ğ‚</mi></math> is the covariance matrix, and
    <math alttext="bold upper S"><mi>ğ’</mi></math> is a diagonal matrix of reciprocated
    standard deviations per variable (that is, the *i*th diagonal is <math alttext="1
    slash sigma Subscript i"><mrow><mn>1</mn> <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>i</mi></msub></mrow></math>
    where <math alttext="sigma Subscript i"><msub><mi>Ïƒ</mi> <mi>i</mi></msub></math>
    is the standard deviation of variable *i*).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold upper C"><mi>ğ‚</mi></math>æ˜¯åæ–¹å·®çŸ©é˜µï¼Œ<math alttext="bold upper
    S"><mi>ğ’</mi></math>æ˜¯æ¯ä¸ªå˜é‡çš„å€’æ•°æ ‡å‡†å·®çš„å¯¹è§’çŸ©é˜µï¼ˆå³ç¬¬*i*ä¸ªå¯¹è§’çº¿æ˜¯<math alttext="1 slash sigma Subscript
    i"><mrow><mn>1</mn> <mo>/</mo> <msub><mi>Ïƒ</mi> <mi>i</mi></msub></mrow></math>ï¼Œå…¶ä¸­<math
    alttext="sigma Subscript i"><msub><mi>Ïƒ</mi> <mi>i</mi></msub></math>æ˜¯ç¬¬*i*ä¸ªå˜é‡çš„æ ‡å‡†å·®ï¼‰ã€‚
- en: Your goal in this exercise is to compute the correlation matrix from the covariance
    matrix, by translating [Equation 7-1](#cov2corr) into Python code. You can then
    reproduce [FigureÂ 7-6](#fig_7_6).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œä½ çš„ç›®æ ‡æ˜¯é€šè¿‡å°†[Equation 7-1](#cov2corr)ç¿»è¯‘æˆPythonä»£ç ï¼Œä»åæ–¹å·®çŸ©é˜µè®¡ç®—ç›¸å…³çŸ©é˜µã€‚ç„¶åï¼Œä½ å¯ä»¥é‡ç°[FigureÂ 7-6](#fig_7_6)ã€‚
- en: '![covmat](assets/plad_0706.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![covmat](assets/plad_0706.png)'
- en: Figure 7-6\. Solution to Exercise 7-1
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-6\. Exercise 7-1çš„è§£ç­”
- en: Exercise 7-2\.
  id: totrans-89
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Exercise 7-2\.
- en: NumPy has a function `np.corrcoef()` that returns a correlation matrix, given
    an input data matrix. Use this function to reproduce the correlation matrix you
    created in the previous exercise. Show both matrices, and their difference, in
    a figure like [FigureÂ 7-7](#fig_7_7) to confirm that they are the same.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: NumPyæœ‰ä¸€ä¸ªå‡½æ•°`np.corrcoef()`ï¼Œç»™å®šè¾“å…¥æ•°æ®çŸ©é˜µï¼Œè¿”å›ä¸€ä¸ªç›¸å…³çŸ©é˜µã€‚ä½¿ç”¨è¿™ä¸ªå‡½æ•°é‡ç°ä½ åœ¨ä¸Šä¸€ä¸ªç»ƒä¹ ä¸­åˆ›å»ºçš„ç›¸å…³çŸ©é˜µã€‚åœ¨ç±»ä¼¼[FigureÂ 7-7](#fig_7_7)çš„å›¾ä¸­å±•ç¤ºè¿™ä¸¤ä¸ªçŸ©é˜µåŠå®ƒä»¬çš„å·®å¼‚ï¼Œä»¥ç¡®è®¤å®ƒä»¬æ˜¯ç›¸åŒçš„ã€‚
- en: '![cormat](assets/plad_0707.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![cormat](assets/plad_0707.png)'
- en: Figure 7-7\. Solution to Exercise 7-2\. Note the difference in color scaling.
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 7-7\. Exercise 7-2çš„è§£ç­”ã€‚æ³¨æ„é¢œè‰²æ¯”ä¾‹çš„å·®å¼‚ã€‚
- en: Next, inspect the source code of `np.corrcoef()` by evaluating `??np.corrcoef()`.
    NumPy uses a slightly different implementation of broadcast dividing by the standard
    deviations instead of pre- and postmultiplying by a diagonal matrix of inverted
    standard deviations, but you should be able to understand how their code implementation
    matches the math and the Python code you wrote in the previous exercise.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œé€šè¿‡è¯„ä¼°`??np.corrcoef()`æ¥æ£€æŸ¥`np.corrcoef()`çš„æºä»£ç ã€‚NumPyä½¿ç”¨äº†ä¸€ç§ç¨å¾®ä¸åŒçš„å®ç°ï¼Œé€šè¿‡æ ‡å‡†åå·®çš„å¹¿æ’­é™¤æ³•è€Œä¸æ˜¯é¢„ä¹˜å’Œåä¹˜ä¸€ä¸ªå€’ç½®æ ‡å‡†åå·®çš„å¯¹è§’çŸ©é˜µï¼Œä½†ä½ åº”è¯¥èƒ½å¤Ÿç†è§£å®ƒä»¬çš„ä»£ç å®ç°å¦‚ä½•ä¸ä½ åœ¨å‰ä¸€ä¸ªç»ƒä¹ ä¸­ç¼–å†™çš„æ•°å­¦å’ŒPythonä»£ç ç›¸åŒ¹é…ã€‚
- en: Geometric Transformations Exercises
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‡ ä½•å˜æ¢ç»ƒä¹ 
- en: Exercise 7-3\.
  id: totrans-95
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Exercise 7-3\.
- en: 'The goal of this exercise is to show points in a circle before and after applying
    a transformation, similar to how I showed the line before and after rotation in
    [FigureÂ 7-2](#fig_7_2). Use the following transformation matrix and then create
    a graph that looks like [FigureÂ 7-8](#fig_7_8):'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç»ƒä¹ çš„ç›®æ ‡æ˜¯å±•ç¤ºåº”ç”¨å˜æ¢å‰åçš„åœ†å†…ç‚¹ï¼Œç±»ä¼¼äºæˆ‘åœ¨[å›¾Â 7-2](#fig_7_2)ä¸­å±•ç¤ºçº¿æ®µå‰åæ—‹è½¬çš„æ–¹å¼ã€‚ä½¿ç”¨ä»¥ä¸‹å˜æ¢çŸ©é˜µï¼Œç„¶ååˆ›å»ºä¸€ä¸ªç±»ä¼¼[å›¾Â 7-8](#fig_7_8)çš„å›¾å½¢ï¼š
- en: <math alttext="bold upper T equals Start 2 By 2 Matrix 1st Row 1st Column 1
    2nd Column .5 2nd Row 1st Column 0 2nd Column .5 EndMatrix" display="block"><mrow><mi>ğ“</mi>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mrow><mn>.5</mn></mrow></mtd></mtr>
    <mtr><mtd><mn>0</mn></mtd> <mtd><mrow><mn>.5</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>![A
    circle, transformed](assets/plad_0708.png)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="åŠ ç²—çš„å¤§å†™Tç­‰äºå¼€å§‹2ä¹˜2çŸ©é˜µç¬¬ä¸€è¡Œç¬¬ä¸€åˆ—1ç¬¬äºŒåˆ—.5ç¬¬äºŒè¡Œç¬¬ä¸€åˆ—0ç¬¬äºŒåˆ—.5ç»“æŸçŸ©é˜µ" display="block"><mrow><mi>ğ“</mi>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mrow><mn>.5</mn></mrow></mtd></mtr>
    <mtr><mtd><mn>0</mn></mtd> <mtd><mrow><mn>.5</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>![ä¸€ä¸ªåœ†å½¢ï¼Œç»è¿‡å˜æ¢](assets/plad_0708.png)
- en: Figure 7-8\. Solution to Exercise 7-3
  id: totrans-98
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 7-8\. ç»ƒä¹  7-3 çš„è§£ç­”
- en: Exercise 7-4\.
  id: totrans-99
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  7-4ã€‚
- en: 'Now for another movie. I call this one *The Coiling DNA*. [FigureÂ 7-9](#fig_7_9)
    shows one frame of the movie. The procedure is the same as for *The Wobbly Circle*â€”set
    up a figure, create a Python function that applies a transformation matrix to
    a matrix of coordinates, and tell `matplotlib` to create an animation using that
    function. Use the following transformation matrix:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨çœ‹å¦ä¸€ä¸ªç”µå½±ã€‚æˆ‘ç§°å…¶ä¸º*èºæ—‹çš„DNA*ã€‚[å›¾Â 7-9](#fig_7_9)å±•ç¤ºäº†ç”µå½±çš„ä¸€ä¸ªé•œå¤´ã€‚æ­¥éª¤ä¸*æ‘‡æ‘†çš„åœ†å½¢*ç›¸åŒâ€”â€”è®¾ç½®ä¸€ä¸ªå›¾è¡¨ï¼Œåˆ›å»ºä¸€ä¸ªå°†å˜æ¢çŸ©é˜µåº”ç”¨äºåæ ‡çŸ©é˜µçš„Pythonå‡½æ•°ï¼Œå¹¶å‘Šè¯‰`matplotlib`ä½¿ç”¨è¯¥å‡½æ•°åˆ›å»ºåŠ¨ç”»ã€‚ä½¿ç”¨ä»¥ä¸‹å˜æ¢çŸ©é˜µï¼š
- en: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mi>ğ“</mi></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <mi>Ï†</mi> <mo>/</mo> <mn>3</mn> <mo>)</mo></mrow></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mi>Ï†</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mn>-1</mn> <mo>â‰¤</mo></mrow></mtd> <mtd columnalign="left"><mrow><mi>Ï†</mi>
    <mo>â‰¤</mo> <mn>1</mn></mrow></mtd></mtr></mtable></math>![The bouncing DNA](assets/plad_0709.png)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mi>ğ“</mi></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <mi>Ï†</mi> <mo>/</mo> <mn>3</mn> <mo>)</mo></mrow></mtd>
    <mtd><mn>0</mn></mtd></mtr> <mtr><mtd><mn>0</mn></mtd> <mtd><mi>Ï†</mi></mtd></mtr></mtable></mfenced></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><mn>-1</mn> <mo>â‰¤</mo></mrow></mtd> <mtd columnalign="left"><mrow><mi>Ï†</mi>
    <mo>â‰¤</mo> <mn>1</mn></mrow></mtd></mtr></mtable></math>![å¼¹è·³çš„DNA](assets/plad_0709.png)
- en: Figure 7-9\. Solution to Exercise 7-4
  id: totrans-102
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 7-9\. ç»ƒä¹  7-4 çš„è§£ç­”
- en: Image Feature Detection Exercises
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å›¾åƒç‰¹å¾æ£€æµ‹ç»ƒä¹ 
- en: Exercise 7-5\.
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  7-5ã€‚
- en: Smooth the 3D bathtub picture (if you need a hint, check the footnote^([4](ch07.xhtml#idm45733299011504))).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: å¹³æ»‘3Dæµ´ç¼¸å›¾ç‰‡ï¼ˆå¦‚æœéœ€è¦æç¤ºï¼Œè¯·æŸ¥çœ‹è„šæ³¨^([4](ch07.xhtml#idm45733299011504))ï¼‰ã€‚
- en: The output of the `convolve2d` function has a data type `float64` (you can see
    this yourself by typing `variableName.dtype`). However, `plt.imshow` will give
    a warning about clipping numerical values, and the picture wonâ€™t render properly.
    Therefore, youâ€™ll need to convert the result of convolution to `uint8`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`convolve2d` å‡½æ•°çš„è¾“å‡ºæ•°æ®ç±»å‹ä¸º `float64`ï¼ˆæ‚¨å¯ä»¥é€šè¿‡è¾“å…¥ `variableName.dtype` è‡ªè¡ŒæŸ¥çœ‹ï¼‰ã€‚ç„¶è€Œï¼Œ`plt.imshow`
    å°†ä¼šè­¦å‘Šæœ‰å…³è£å‰ªæ•°å€¼çš„é—®é¢˜ï¼Œå›¾ç‰‡æ— æ³•æ­£å¸¸æ¸²æŸ“ã€‚å› æ­¤ï¼Œæ‚¨éœ€è¦å°†å·ç§¯ç»“æœè½¬æ¢ä¸º `uint8`ã€‚'
- en: Exercise 7-6\.
  id: totrans-107
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  7-6ã€‚
- en: You donâ€™t need to use the same kernel for each color channel. Change the width
    parameter of the Gaussian for each channel according to the values shown in [FigureÂ 7-10](#fig_7_10).
    The effect on the image is subtle, but the different blurs of the different colors
    give it a bit of a 3D look, as if you are looking at a red-blue anaglyph without
    the glasses.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸éœ€è¦ä¸ºæ¯ä¸ªé¢œè‰²é€šé“ä½¿ç”¨ç›¸åŒçš„æ ¸ã€‚æ ¹æ®[å›¾Â 7-10](#fig_7_10)ä¸­æ˜¾ç¤ºçš„å€¼ï¼Œä¸ºæ¯ä¸ªé€šé“æ›´æ”¹é«˜æ–¯çš„å®½åº¦å‚æ•°ã€‚å¯¹å›¾åƒçš„å½±å“å¾®å¦™ï¼Œä½†ä¸åŒé¢œè‰²çš„æ¨¡ç³Šä½¿å…¶å…·æœ‰ä¸€ç§ç¨å¾®ç«‹ä½“çš„å¤–è§‚ï¼Œå°±åƒæ‚¨æ²¡æœ‰æˆ´çœ¼é•œçœ‹çº¢è“ç«‹ä½“ç…§ç‰‡ä¸€æ ·ã€‚
- en: '![Different strokes for different folks.](assets/plad_0710.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![å„å–æ‰€éœ€](assets/plad_0710.png)'
- en: Figure 7-10\. Kernels used per color channel in Exercise 7-6
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 7-10\. ç»ƒä¹  7-6 ä¸­æ¯ä¸ªé¢œè‰²é€šé“ä½¿ç”¨çš„æ ¸
- en: Exercise 7-7\.
  id: totrans-111
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  7-7ã€‚
- en: 'Technically, image smoothing is feature extraction, because it involves extracting
    the smooth features of the signal while dampening the sharp features. Here we
    will change the filter kernels to solve other image feature detection problems:
    identifying horizontal and vertical lines.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ä»æŠ€æœ¯ä¸Šè®²ï¼Œå›¾åƒå¹³æ»‘æ˜¯ç‰¹å¾æå–çš„ä¸€ç§ï¼Œå› ä¸ºå®ƒæ¶‰åŠæå–ä¿¡å·çš„å¹³æ»‘ç‰¹å¾ï¼ŒåŒæ—¶æŠ‘åˆ¶å°–é”ç‰¹å¾ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†æ”¹å˜æ»¤æ³¢å™¨æ ¸ä»¥è§£å†³å…¶ä»–å›¾åƒç‰¹å¾æ£€æµ‹é—®é¢˜ï¼šè¯†åˆ«æ°´å¹³å’Œå‚ç›´çº¿æ¡ã€‚
- en: The two kernels are shown in [FigureÂ 7-11](#fig_7_11), as are their effects
    on the image. You can handcraft the two kernels based on their visual appearance;
    they are <math alttext="3 times 3"><mrow><mn>3</mn> <mo>Ã—</mo> <mn>3</mn></mrow></math>
    and comprise only the numbers âˆ’1, 0, and +1\. Convolve those kernels with the
    2D grayscale picture to create the feature maps shown in [FigureÂ 7-11](#fig_7_11).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸¤ä¸ªå·ç§¯æ ¸å¦‚åŒ[å›¾Â 7-11](#fig_7_11)ä¸­æ‰€ç¤ºï¼Œå®ƒä»¬å¯¹å›¾åƒçš„å½±å“ä¹Ÿè¢«å±•ç¤ºäº†å‡ºæ¥ã€‚æ‚¨å¯ä»¥æ ¹æ®å®ƒä»¬çš„è§†è§‰å¤–è§‚æ‰‹å·¥åˆ¶ä½œè¿™ä¸¤ä¸ªå·ç§¯æ ¸ï¼›å®ƒä»¬æ˜¯<math
    alttext="3 times 3"><mrow><mn>3</mn> <mo>Ã—</mo> <mn>3</mn></mrow></math>çš„çŸ©é˜µï¼ŒåªåŒ…å«æ•°å­—
    âˆ’1ã€0 å’Œ +1\. å°†è¿™äº›å·ç§¯æ ¸ä¸2Dç°åº¦å›¾åƒå·ç§¯ï¼Œä»¥åˆ›å»º[å›¾Â 7-11](#fig_7_11)ä¸­æ˜¾ç¤ºçš„ç‰¹å¾å›¾ã€‚
- en: '![Different strokes for different folks.](assets/plad_0711.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![å„æœ‰æ‰€çˆ±ã€‚](assets/plad_0711.png)'
- en: Figure 7-11\. Results of Exercise 7-7
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 7-11\. ç»ƒä¹  7-7 çš„ç»“æœ
- en: '^([1](ch07.xhtml#idm45733299773872-marker)) M. A. Redmond and A. Baveja, â€œA
    Data-Driven Software Tool for Enabling Cooperative Information Sharing Among Police
    Departments,â€ *European Journal of Operational Research* 141 (2002): 660â€“678.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch07.xhtml#idm45733299773872-marker)) M. A. Redmond å’Œ A. Bavejaï¼Œã€ŠA Data-Driven
    Software Tool for Enabling Cooperative Information Sharing Among Police Departmentsã€‹ï¼Œã€ŠEuropean
    Journal of Operational Researchã€‹141ï¼ˆ2002ï¼‰ï¼š660â€“678ã€‚
- en: ^([2](ch07.xhtml#idm45733299628944-marker)) Swap the minus signs in the sine
    functions.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch07.xhtml#idm45733299628944-marker)) å°†æ­£å¼¦å‡½æ•°ä¸­çš„è´Ÿå·äº’æ¢ã€‚
- en: ^([3](ch07.xhtml#idm45733299335200-marker)) Set the lower-right element to âˆ’1.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch07.xhtml#idm45733299335200-marker)) å°†å³ä¸‹è§’çš„å…ƒç´ è®¾ä¸º âˆ’1ã€‚
- en: '^([4](ch07.xhtml#idm45733299011504-marker)) Hint: smooth each color channel
    separately.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch07.xhtml#idm45733299011504-marker)) æç¤ºï¼šåˆ†åˆ«å¹³æ»‘æ¯ä¸ªé¢œè‰²é€šé“ã€‚
