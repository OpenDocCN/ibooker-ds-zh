- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序言
- en: 'Spark has become the de facto standard for large-scale data analytics. I have
    been using and teaching Spark since its inception nine years ago, and I have seen
    tremendous improvements in Extract, Transform, Load (ETL) processes, distributed
    algorithm development, and large-scale data analytics. I started using Spark with
    Java, but I found that while the code is pretty stable, you have to write long
    lines of code, which can become unreadable. For this book, I decided to use PySpark
    (a Python API for Spark) because it is easier to express the power of Spark in
    Python: the code is short, readable, and maintainable. PySpark is powerful but
    simple to use, and you can express any ETL or distributed algorithm in it with
    a simple set of transformations and actions.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 已经成为大规模数据分析的事实标准。自其成立九年以来，我一直在使用和教授 Spark，并且在数据提取、转换、加载（ETL）过程、分布式算法开发以及大规模数据分析方面见证了巨大的改进。我最初使用
    Java 开发 Spark，但我发现尽管代码非常稳定，但需要编写冗长的代码行，这可能导致代码难以阅读。因此，为了这本书，我决定使用 PySpark（Spark
    的 Python API），因为用 Python 表达 Spark 的强大更为简单：代码简短、易读且易于维护。PySpark 功能强大但使用简单，您可以通过一组简单的转换和操作表达任何
    ETL 或分布式算法。
- en: Why I Wrote This Book
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我为什么写这本书
- en: 'This is an introductory book about data analysis using PySpark. The book consists
    of a set of guidelines and examples intended to help software and data engineers
    solve data problems in the simplest possible way. As you know, there are many
    ways to solve any data problem: PySpark enables us to write simple code for complex
    problems. This is the motto I have tried to express in this book: keep it simple
    and use parameters so that your solution can be reused by other developers. My
    aim is to teach readers how to think about data and understand its origins and
    final intended form, as well as showing how to use fundamental data transformation
    patterns to solve a variety of data problems.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一本关于使用 PySpark 进行数据分析的入门书籍。本书提供了一系列指南和示例，旨在帮助软件和数据工程师以最简单的方式解决数据问题。如您所知，解决任何数据问题的方法有很多种：PySpark
    可以让我们为复杂问题编写简单的代码。这是我在本书中尝试表达的座右铭：保持简单，使用参数，使您的解决方案可以被其他开发人员重用。我旨在教读者如何思考数据、理解其来源和最终预期形式，以及如何使用基本的数据转换模式解决各种数据问题。
- en: Who This Book Is For
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这本书是为谁准备的
- en: To use this book effectively it will be helpful to know the basics of the Python
    programming language, such as how to use conditionals (`if-then-else`), iterate
    through lists, and define and call functions. However, if your background is in
    another programming language (such as Java or Scala) and you do not know Python,
    you will still be able to use the book as I have provided a reasonable introduction
    to Spark and PySpark.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 要有效使用本书，最好了解 Python 编程语言的基础知识，例如如何使用条件语句（`if-then-else`）、遍历列表以及定义和调用函数。然而，如果您的背景是其他编程语言（如
    Java 或 Scala），并且不了解 Python，也可以使用本书，因为我已经提供了关于 Spark 和 PySpark 的合理介绍。
- en: This book is primarily intended for people who want to analyze large amounts
    of data and develop distributed algorithms using the Spark engine and PySpark.
    I have provided simple examples showing how to perform ETL operations and write
    distributed algorithms in PySpark. The code examples are written in such a way
    that you can cut and paste them to get the job done easily.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书主要面向希望使用 Spark 引擎和 PySpark 分析大量数据并开发分布式算法的人群。我提供了简单的示例，展示如何在 PySpark 中执行 ETL
    操作和编写分布式算法。代码示例编写方式简单，可以轻松地复制粘贴以完成工作。
- en: The [sample code provided on GitHub](https://github.com/mahmoudparsian/data-algorithms-with-spark)
    is a great resource to get you started with your own data projects.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[GitHub 提供的示例代码](https://github.com/mahmoudparsian/data-algorithms-with-spark)
    是开始您自己数据项目的绝佳资源。'
- en: How This Book Is Organized
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书的组织方式
- en: 'The book consists of 12 chapters, organized into three parts:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书包含 12 章，分为三个部分：
- en: '[Part I, “Fundamentals”](part01.xhtml#part_1)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[第一部分，“基础”](part01.xhtml#part_1)'
- en: 'The first four chapters cover the fundamentals of Spark and PySpark and introduce
    data transformations such as mappers, filters, and reducers. They contain many
    practical examples to get you started on your own PySpark projects. Approximately
    95% of all data problems can be tackled by using simple PySpark data transformations
    (such as `map()`, `flatMap()`, `filter()`, and `reduceByKey()`) introduced in
    the first four chapters of this book. Here’s a closer look at what you’ll find
    here:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 前四章介绍了Spark和PySpark的基础知识，并介绍了数据转换，如映射器、过滤器和减少器。它们包含许多实际示例，可以帮助您开始自己的PySpark项目。本书的前四章引入了简单的PySpark数据转换（如`map()`、`flatMap()`、`filter()`和`reduceByKey()`），这些转换可以解决大约95%的所有数据问题。以下是这里的详细内容：
- en: '[Chapter 1, “Introduction to Spark and PySpark”](ch01.xhtml#Chapter-01), provides
    a high-level overview of data algorithms and introduces the use of Spark and PySpark
    for solving data analytics problems.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第一章，“介绍Spark和PySpark”](ch01.xhtml#Chapter-01)，提供了数据算法的高级概述，并介绍了使用Spark和PySpark解决数据分析问题的方法。'
- en: '[Chapter 2, “Transformations in Action”](ch02.xhtml#Chapter-02), shows how
    to use Spark transformations (mappers, filters, and reducers) to solve real data
    problems.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第二章，“动作中的转换”](ch02.xhtml#Chapter-02)，展示了如何使用Spark转换（映射器、过滤器和减少器）来解决真实的数据问题。'
- en: '[Chapter 3, “Mapper Transformations”](ch03.xhtml#Chapter-03), introduces the
    most frequently used mapper transformations: `map()`, `filter()`, `flatMap()`,
    and `mapPartitions()`.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第三章，“映射器转换”](ch03.xhtml#Chapter-03)，介绍了最常用的映射器转换：`map()`、`filter()`、`flatMap()`和`mapPartitions()`。'
- en: '[Chapter 4, “Reductions in Spark”](ch04.xhtml#unique_chapter_id_04), focuses
    on reduction transformations (such as `reduceByKey()`, `groupByKey()`, and `combineByKey()`),
    which play a very important role in grouping data by keys. Many simple but useful
    examples are given to make sure that you’ll be able to use these reductions effectively.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第四章，“Spark中的减少”](ch04.xhtml#unique_chapter_id_04)，重点介绍了减少转换（如`reduceByKey()`、`groupByKey()`和`combineByKey()`），它们在按键分组数据中起着非常重要的作用。提供了许多简单但实用的示例，确保您能有效地使用这些减少。'
- en: '[Part II, “Working with Data”](part02.xhtml#part_2)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第二部分，“处理数据”](part02.xhtml#part_2)'
- en: 'The next four chapters cover partitioning data, graph algorithms, reading/writing
    data from/to many different data sources, and ranking algorithms:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的四章涵盖了数据分区、图算法、从/向多种不同数据源读取/写入数据以及排名算法：
- en: '[Chapter 5, “Partitioning Data”](ch05.xhtml#unique_chapter_id_05), presents
    functions to physically partition data on specific data columns. This partitioning
    will enable your SQL queries (e.g., in Amazon Athena or Google BigQuery) to analyze
    a slice of the data rather than the whole dataset, which will improve query performance.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第五章，“数据分区”](ch05.xhtml#unique_chapter_id_05)，介绍了在特定数据列上物理分区数据的函数。这种分区将使您的SQL查询（例如在Amazon
    Athena或Google BigQuery中）能够分析数据的一个切片，而不是整个数据集，从而提高查询性能。'
- en: '[Chapter 6, “Graph Algorithms”](ch06.xhtml#unique_chapter_id_06), introduces
    one of the most important external Spark packages, GraphFrames, which can be used
    to analyze large graphs in Spark’s distributed environment.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第六章，“图算法”](ch06.xhtml#unique_chapter_id_06)，介绍了Spark中一个最重要的外部包，GraphFrames，它可以用于分析Spark分布式环境中的大型图形。'
- en: '[Chapter 7, “Interacting with External Data Sources”](ch07.xhtml#Chapter-07),
    shows you how to read data from and write it to a variety of data sources.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第七章，“与外部数据源交互”](ch07.xhtml#Chapter-07)，展示了如何从各种数据源读取数据并将其写入。'
- en: '[Chapter 8, “Ranking Algorithms”](ch08.xhtml#unique_chapter_id_08), presents
    two important ranking algorithms, PageRank (used in search engines) and rank product
    (used in gene analysis).'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第八章，“排名算法”](ch08.xhtml#unique_chapter_id_08)，介绍了两种重要的排名算法，PageRank（用于搜索引擎）和rank
    product（用于基因分析）。'
- en: '[Part III, “Data Design Patterns”](part03.xhtml#part_3)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[第三部分，“数据设计模式”](part03.xhtml#part_3)'
- en: 'The final four chapters cover practical data design patterns, which are presented
    in an informal way with solid examples:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后四章介绍了实际数据设计模式，以实例形式呈现：
- en: '[Chapter 9, “Classic Data Design Patterns”](ch09.xhtml#unique_chapter_id_09),
    introduces a selection of fundamental data design patterns, or reusable solutions,
    that are commonly used to solve a variety of data problems. Examples include Input-Map-Output
    and Input-Filter-Output.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第九章，“经典数据设计模式”](ch09.xhtml#unique_chapter_id_09)，介绍了一些基本数据设计模式或可重复使用的解决方案，通常用于解决各种数据问题。示例包括Input-Map-Output和Input-Filter-Output。'
- en: '[Chapter 10, “Practical Data Design Patterns”](ch10.xhtml#unique_chapter_id_10),
    introduces common and practical data design patterns, for tasks such as combining,
    summarizing, filtering, and organizing data. These patterns are presented informally,
    with practical examples.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 10 章，“实用数据设计模式”](ch10.xhtml#unique_chapter_id_10)，介绍了常见和实用的数据设计模式，用于组合、汇总、过滤和组织数据等任务。这些模式以实用示例的形式展示。'
- en: '[Chapter 11, “Join Design Patterns”](ch11.xhtml#unique_chapter_id_11), presents
    simple patterns for joining two or more datasets; some performance criteria are
    discussed to improve the efficiency of join algorithms.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 11 章，“连接设计模式”](ch11.xhtml#unique_chapter_id_11)，介绍了用于连接两个或多个数据集的简单模式；讨论了一些提高连接算法效率的性能标准。'
- en: '[Chapter 12, “Feature Engineering in PySpark”](ch12.xhtml#unique_chapter_id_12),
    presents the most common feature engineering techniques used in developing machine
    learning algorithms.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[第 12 章，“PySpark 中的特征工程”](ch12.xhtml#unique_chapter_id_12)，介绍了开发机器学习算法中最常用的特征工程技术。'
- en: Bonus Chapters
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 附加章节
- en: Since I did not want to make this book too bulky, I have included additional
    material on topics such as TF-IDF, correlation, and k-mers as bonus chapters in
    the book’s [GitHub repository](https://github.com/mahmoudparsian/data-algorithms-with-spark).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我不希望使本书变得过于臃肿，我在书的 [GitHub 仓库](https://github.com/mahmoudparsian/data-algorithms-with-spark)
    中包含了有关 TF-IDF、相关性和 k-mer 等主题的额外材料。
- en: Conventions Used in This Book
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书使用的约定
- en: 'The following typographical conventions are used in this book:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用以下排版约定：
- en: '*Italic*'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*斜体*'
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 指示新术语、URL、电子邮件地址、文件名和文件扩展名。
- en: '`Constant width`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`等宽字体`'
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 用于程序清单，以及在段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。
- en: '**`Constant width bold`**'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**`等宽粗体`**'
- en: Shows commands or other text that should be typed literally by the user.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应由用户逐字输入的命令或其他文本。
- en: '*`Constant width italic`*'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*`等宽斜体`*'
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应由用户提供值或由上下文确定值的文本。
- en: Tip
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This element signifies a tip or suggestion.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示提示或建议。
- en: Note
  id: totrans-42
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This element signifies a general note.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示一般注释。
- en: Warning
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: This element indicates a warning or caution.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示警告或注意事项。
- en: Using Code Examples
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用代码示例
- en: Supplemental material (code examples, exercises, etc.) is available for download
    at [*https://github.com/mahmoudparsian/data-algorithms-with-spark*](https://github.com/mahmoudparsian/data-algorithms-with-spark).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 补充材料（例如代码示例、练习等）可在 [*https://github.com/mahmoudparsian/data-algorithms-with-spark*](https://github.com/mahmoudparsian/data-algorithms-with-spark)
    上下载。
- en: If you have a technical question or a problem using the code examples, please
    send email to [*mahmoud.parsian@yahoo.com*](mailto:mahmoud.parsian@yahoo.com).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在使用代码示例时遇到技术问题或困难，请发送电子邮件至 [*mahmoud.parsian@yahoo.com*](mailto:mahmoud.parsian@yahoo.com)。
- en: This book is here to help you get your job done. In general, if example code
    is offered with this book, you may use it in your programs and documentation.
    You do not need to contact us for permission unless you’re reproducing a significant
    portion of the code. For example, writing a program that uses several chunks of
    code from this book does not require permission. Selling or distributing examples
    from O’Reilly books does require permission. Answering a question by citing this
    book and quoting example code does not require permission. Incorporating a significant
    amount of example code from this book into your product’s documentation does require
    permission.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在帮助您完成工作。一般来说，如果本书提供了示例代码，您可以在自己的程序和文档中使用它。除非您复制了大部分代码，否则无需征得我们的许可。例如，编写一个使用本书多个代码片段的程序无需许可。销售或分发
    O’Reilly 书籍中的示例代码则需要许可。引用本书回答问题并引用示例代码无需许可。将本书中大量示例代码整合到产品文档中则需要许可。
- en: 'We appreciate, but generally do not require, attribution. An attribution usually
    includes the title, author, publisher, and ISBN. For example: “*Data Algorithms
    with Spark* by Mahmoud Parsian (O’Reilly). Copyright 2022 Mahmoud Parsian, 978-1-492-08238-5.”'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您的支持，但通常不要求归属。归属通常包括标题、作者、出版商和ISBN。例如：“*Data Algorithms with Spark* by Mahmoud
    Parsian (O’Reilly). Copyright 2022 Mahmoud Parsian, 978-1-492-08238-5.”
- en: If you feel your use of code examples falls outside fair use or the permission
    given above, feel free to contact us at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您认为使用代码示例超出了合理使用范围或以上授权，请随时通过[*permissions@oreilly.com*](mailto:permissions@oreilly.com)与我们联系。
- en: O’Reilly Online Learning
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 奥莱利在线学习
- en: Note
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: For more than 40 years, [*O’Reilly Media*](http://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 40多年来，[*奥莱利传媒*](http://oreilly.com)提供技术和商业培训、知识和洞见，帮助公司取得成功。
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, conferences, and our online learning platform. O’Reilly’s
    online learning platform gives you on-demand access to live training courses,
    in-depth learning paths, interactive coding environments, and a vast collection
    of text and video from O’Reilly and 200+ other publishers. For more information,
    please visit [*http://oreilly.com*](http://oreilly.com).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过书籍、文章、会议以及我们的在线学习平台分享他们的知识和专业知识。奥莱利的在线学习平台为您提供按需访问的实时培训课程、深入学习路径、交互式编码环境以及来自奥莱利和其他200多个出版商的大量文本和视频。有关更多信息，请访问[*http://oreilly.com*](http://oreilly.com)。
- en: How to Contact Us
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 请将关于本书的评论和问题发送至出版商：
- en: O’Reilly Media, Inc.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 奥莱利传媒股份有限公司
- en: 1005 Gravenstein Highway North
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1005 Gravenstein Highway North
- en: Sebastopol, CA 95472
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebastopol, CA 95472
- en: 800-998-9938 (in the United States or Canada)
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-998-9938（美国或加拿大）
- en: 707-829-0515 (international or local)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0515（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/data-algorithms-with-spark*](https://oreil.ly/data-algorithms-with-spark).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为本书创建了一个网页，列出勘误、示例和任何额外信息。您可以访问此页面：[*https://oreil.ly/data-algorithms-with-spark*](https://oreil.ly/data-algorithms-with-spark)。
- en: Email [*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com) to comment
    or ask technical questions about this book.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)以发表评论或提出关于本书的技术问题。
- en: For more information about our books, courses, conferences, and news, see our
    website at [*http://www.oreilly.com*](http://www.oreilly.com).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有关我们的图书、课程、会议和新闻的更多信息，请访问我们的网站：[*http://www.oreilly.com*](http://www.oreilly.com)。
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LinkedIn 上找到我们：[*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)
- en: 'Follow us on Twitter: [*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Twitter 上关注我们：[*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)
- en: 'Watch us on YouTube: [*http://youtube.com/oreillymedia*](http://youtube.com/oreillymedia)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在 YouTube 上关注我们：[*http://youtube.com/oreillymedia*](http://youtube.com/oreillymedia)
- en: Acknowledgments
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: This idea for this book was initiated by Jess Haberman (Senior Acquisitions
    Editor at O’Reilly Media). I am so grateful to her for reaching out—thank you
    very much, Jess! I am indebted to Melissa Potter (Content Development Editor at
    O’Reilly Media), who has worked tirelessly with me since the start of this project
    and has helped me so much to make it a better book. Thank you very much, Melissa!
    Thank you so much to the copyeditor, Rachel Head, who has done a tremendous job
    in editing the whole book; if you can read and understand this book, then it is
    because of Rachel. I want to say a big thank you to Christopher Faucher (the Production
    Editor) for doing a great job and making sure that deadlines were met and everything
    is in its proper place. Taking a book through production is not an easy job at
    all, but Christopher has done a superb job.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的构思是由O'Reilly Media的高级采编编辑Jess Haberman提出的。我非常感激她的联系 —— 非常感谢你，Jess！我感激O'Reilly
    Media的内容开发编辑Melissa Potter，她从项目开始就与我密切合作，并帮助我大大改善了这本书。非常感谢你，Melissa！非常感谢编辑Rachel
    Head，她在整本书的编辑工作中做得非常出色；如果你能读懂并理解这本书，那都是因为Rachel。我要衷心感谢Christopher Faucher（出版编辑），他做得非常好，确保了截稿时间并且一切都井然有序。推动一本书的出版绝非易事，但Christopher做得非常出色。
- en: Thank you so much to technical reviewers Parviz Deyhim and Benjamin Muskalla
    for their very careful review of my book, and for the comments, corrections, and
    suggestions that ensued. I would also like to say a special thank you to my PhD
    advisor and dear friend, Dr. Ramachandran Krishnaswamy, from whom I have learned
    so much; I will cherish my friendship with him forever.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢技术审稿人Parviz Deyhim和Benjamin Muskalla非常仔细地审阅我的书，并就随之而来的评论、修正和建议表示感谢。我还要特别感谢我的博士导师和亲密的朋友，Ramachandran
    Krishnaswamy博士，我从他身上学到了很多；我将永远珍惜与他的友谊。
- en: To add to the PySpark solutions I have provided for all chapters on GitHub,
    Deepak Kumar and Biman Mandal have provided Scala solutions, which is a great
    resource for readers. Thank you very much, Deepak and Biman. Last but not least,
    I want to give a huge, sparkling thank you to Dr. Matei Zaharia (creator of Apache
    Spark) for writing a foreword to my book; I am honored and humbled for his kind
    words.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了增加GitHub上所有章节的PySpark解决方案，Deepak Kumar和Biman Mandal提供了Scala解决方案，这对读者来说是一个很好的资源。非常感谢你们，Deepak和Biman。最后但同样重要的是，我要向Apache
    Spark的创始人Matei Zaharia博士表示巨大的感谢和敬意，他为我的书撰写了前言；我为他的友善言辞感到荣幸和自豪。
