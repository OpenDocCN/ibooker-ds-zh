- en: 13 Deploying distributed applications as stacks in Docker Swarm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 13 在 Docker Swarm 中作为堆栈部署分布式应用程序
- en: I have a confession--in the last chapter I had you spend a lot of time learning
    how to create Docker Swarm services with the command line, but you won’t ever
    do that in a real project. It’s a useful way to get started with orchestration
    and to understand the difference between running containers yourself and having
    an orchestrator manage them for you. But in a real system you won’t connect to
    the manager and send it commands to run services. Instead, you’ll describe your
    application in a YAML file that you’ll send to the manager; it will then decide
    what actions to take to get your app running. It’s the same desired state approach
    that you’ve seen with Docker Compose--the YAML file specifies what you want the
    end state to be, and the orchestrator looks at what’s currently running and figures
    out what it needs to do to get to that state.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一个坦白——在上一章中，我让您花了很多时间学习如何使用命令行创建 Docker Swarm 服务，但在实际项目中您永远不会这样做。这是一种开始编排并理解自己运行容器和由编排器为您管理它们之间的区别的有用方法。但在实际系统中，您不会连接到管理器并发送命令来运行服务。相反，您将在
    YAML 文件中描述您的应用程序，并将该文件发送给管理器；然后它将决定采取哪些行动来使您的应用程序运行。这与您在 Docker Compose 中看到的相同期望状态方法——YAML
    文件指定了您想要的最终状态，编排器查看当前正在运行的内容，并确定它需要做什么才能达到该状态。
- en: Docker Swarm and Kubernetes both use the same desired-state approach, but with
    different YAML syntax. Swarm uses the Docker Compose syntax to define all the
    components of your app, and when you send your YAML to the manager, it creates
    networks and services and anything else you declare. The Compose format is very
    well suited to describing distributed apps for cluster deployment, but there are
    some concepts that only make sense in Swarm mode and some that only make sense
    on a single server. The specification is flexible enough to support both, and
    in this chapter we’ll build on your knowledge of Docker Compose and Docker Swarm
    to run distributed apps in the cluster.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 和 Kubernetes 都使用相同的期望状态方法，但 YAML 语法不同。Swarm 使用 Docker Compose 语法来定义您应用程序的所有组件，当您将您的
    YAML 发送到管理器时，它会创建网络、服务以及您声明的任何其他内容。Compose 格式非常适合描述用于集群部署的分布式应用程序，但有些概念仅在 Swarm
    模式下有意义，有些则仅在单个服务器上有意义。该规范足够灵活，可以支持两者，在本章中，我们将基于您对 Docker Compose 和 Docker Swarm
    的了解，在集群中运行分布式应用程序。
- en: 13.1 Using Docker Compose for production deployments
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.1 使用 Docker Compose 进行生产部署
- en: The real power of Docker Swarm comes from Compose--your production deployments
    use the same file format that you use in dev and test environments, so there’s
    consistency across your artifacts and tooling for every environment and every
    project. The very simplest deployment for a Swarm is identical to a simple Compose
    file--listing 13.1 shows a basic deployment for the to-do app from chapter 6,
    which just specifies the image name and the port to publish.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 的真正力量来自 Compose——您的生产部署使用与您在开发和测试环境中使用的相同文件格式，因此您的每个环境和每个项目的工件和工具都保持一致性。Swarm
    的最简单部署与简单的 Compose 文件相同——列表 13.1 显示了第 6 章中待办事项应用程序的基本部署，它仅指定了镜像名称和要发布的端口。
- en: Listing 13.1 A Compose file that can be deployed to a Swarm
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.1 可以部署到 Swarm 的 Compose 文件
- en: '` version: "3.7"` ` services:` `   todo-web:` `       image: diamol/ch06-todo-list`
    `       ports:` `             - 8080:80`'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '` version: "3.7"` ` services:` `   todo-web:` `       image: diamol/ch06-todo-list`
    `       ports:` `             - 8080:80`'
- en: You can deploy that on a single server using Docker Compose, and you’ll get
    one container running with a published port to access the app. You can deploy
    the exact same file on a Swarm, and you’ll get a service with a single replica
    running, using the ingress network for the published port. You deploy applications
    in Swarm mode by creating a stack, which is just a resource that groups together
    lots of other resources, like services, networks, and volumes.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 Docker Compose 在单个服务器上部署它，您将获得一个运行中的容器，并有一个已发布的端口来访问应用程序。您可以在 Swarm 上部署完全相同的文件，您将获得一个运行单个副本的服务，使用入口网络来发布端口。您通过创建一个堆栈来在
    Swarm 模式下部署应用程序，这只是一个将许多其他资源（如服务、网络和卷）组合在一起的资源。
- en: 'Try it now Deploy that simple Compose file as a stack. You’ll need to have
    initialized your Swarm and then switch to the folder for this chapter’s exercises.
    Deploy the stack and then check what’s running:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 将这个简单的 Compose 文件作为堆栈部署。您需要初始化您的 Swarm 并切换到本章练习的文件夹。部署堆栈后，检查正在运行的内容：
- en: '` cd ch13/exercises`  ` # deploy the stack from the Compose file:` ` docker
    stack deploy -c ./todo-list/v1.yml todo`  ` # list all the stacks and see the
    new one:` ` docker stack ls`  ` # list all services and see the service created
    by the deployment:` ` docker service ls`'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '` cd ch13/exercises`  ` # 从Compose文件部署堆栈：` ` docker stack deploy -c ./todo-list/v1.yml
    todo`  ` # 列出所有堆栈并查看新创建的堆栈：` ` docker stack ls`  ` # 列出所有服务并查看由部署创建的服务：` ` docker
    service ls`'
- en: You can see from my output in figure 13.1 that the behavior is very much like
    Docker Compose, although you use the standard Docker CLI to deploy to a Swarm.
    I sent the Compose file to my cluster, and the manager created a default network
    to plug services into and then created a service for my app. Stacks are a first-class
    resource in Swarm mode; you can use the CLI to create, list, and remove them.
    Deploying the stack in this exercise creates a single service.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从图13.1中的我的输出中看到，行为非常类似于Docker Compose，尽管您使用标准的Docker CLI将服务部署到Swarm中。我将Compose文件发送到我的集群，然后管理器创建了一个默认网络以将服务插入其中，并为我的应用程序创建了一个服务。在Swarm模式下，堆栈是一个一等资源；您可以使用CLI创建、列出和删除它们。在这个练习中部署堆栈创建了一个单一的服务。
- en: '![](../Images/13-1.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图13.1](../Images/13-1.jpg)'
- en: Figure 13.1 Deploying a stack in Swarm mode using a standard Docker Compose
    file
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1 使用标准Docker Compose文件在Swarm模式下部署堆栈
- en: 'If you’re running Linux containers, you can browse to http: */ /* localhost:8080
    and see the app, but if you’re using Windows containers, you still have the problem
    that you can’t browse to the ingress network locally, so you’ll need to browse
    from another machine. It’s the same old to-do app working in the same way, so
    we’ll skip the screenshot. The thing to take away from this exercise is that you’ve
    used a standard Docker Compose file with no extra config to deploy to the Swarm.
    If you had multiple nodes in your Swarm, you’d have high availability--the node
    running the service replica could go offline, and the Swarm would start a replacement
    on another node to keep your app available.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '如果您正在运行Linux容器，您可以通过访问http: */ /* localhost:8080来浏览应用程序，但如果您正在使用Windows容器，您仍然会遇到无法本地浏览到入口网络的问题，因此您需要从另一台机器上浏览。这个待办事项应用程序与之前一样工作，所以我们将跳过截图。从这个练习中您应该吸取的教训是，您已经使用了一个标准的Docker
    Compose文件，没有额外的配置来部署到Swarm。如果您在Swarm中有多个节点，您将拥有高可用性--运行服务副本的节点可以离线，Swarm将在另一个节点上启动一个替换来保持您的应用程序可用。'
- en: Swarm mode has an extra set of features, of course, and you can use them in
    your app by adding a `deploy` section to the service in your Compose file. These
    properties only make sense when you’re running in a cluster, so they get applied
    when you deploy a stack, but you can use the same file with Docker Compose on
    a single server, and the `deploy` settings will be ignored. Listing 13.2 shows
    an updated service definition for the to-do app that includes deployment properties
    to run multiple replicas and to limit the compute resources each replica can use.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，Swarm模式有一套额外的功能，您可以通过在您的Compose文件中的服务中添加一个`deploy`部分来在您的应用程序中使用它们。这些属性仅在您在集群中运行时才有意义，因此它们在部署堆栈时应用，但您可以使用相同的文件在单个服务器上使用Docker
    Compose，并且`deploy`设置将被忽略。列表13.2显示了包含部署属性以运行多个副本并限制每个副本可以使用的计算资源的待办事项应用程序的更新服务定义。
- en: Listing 13.2 Adding Swarm deployment configuration in your Docker Compose file
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.2 在您的Docker Compose文件中添加Swarm部署配置
- en: '` services:` `   todo-web:` `       image: diamol/ch06-todo-list` `       ports:`
    `           - 8080:80` `       deploy:` `           replicas: 2` `           resources:`
    `               limits:` `                   cpus: "0.50"` `                     memory:
    100M`'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '` services:` `   todo-web:` `       image: diamol/ch06-todo-list` `       ports:`
    `           - 8080:80` `       deploy:` `           replicas: 2` `           resources:`
    `               limits:` `                   cpus: "0.50"` `                     memory:
    100M`'
- en: These are the basic properties you’d want to include for a production deployment.
    Running multiple replicas means your app can manage more load, and it also means
    one replica will be available to serve traffic if the other goes offline because
    of a server failure or a service update. You should also specify compute limits
    for all your services when they go live, to protect your cluster from a rogue
    replica consuming all the processing power and memory. Working out the limits
    takes some effort, because you need to know the amount of CPU and memory your
    app needs when it’s working hardest--metrics like those we saw in chapter 9 help
    with this. The resource limits in this application specification restrict each
    replica to a maximum of 50% of one CPU core and 100 MB of memory.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是你希望在生产部署中包含的基本属性。运行多个副本意味着你的应用程序可以管理更多的负载，这也意味着如果一个副本因为服务器故障或服务更新而离线，另一个副本将可用于服务流量。你还应该在服务上线时为所有服务指定计算限制，以保护你的集群免受恶意副本消耗所有处理能力和内存的影响。确定限制需要一些努力，因为你需要知道应用程序在最繁忙时所需的
    CPU 和内存量——第 9 章中看到的那些指标有助于这一点。在此应用程序规范中，资源限制将每个副本限制在一个 CPU 核心的最大 50% 和 100 MB
    的内存。
- en: Deploying updates to a Swarm stack is the same as deploying a new app--you send
    the updated YAML file to the manager, and it makes the changes for you. When you
    deploy the v2 Compose file, the Swarm will create one new replica and replace
    the existing one.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 将更新部署到 Swarm 堆栈与部署新应用程序相同——你将更新的 YAML 文件发送到管理器，它会为你进行更改。当你部署 v2 Compose 文件时，Swarm
    将创建一个新的副本并替换现有的副本。
- en: 'Try it now Run a `stack` `deploy` command using a new Compose file but the
    original stack name--this works like an update to the existing stack. List the
    service tasks and you’ll see how the update happened:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试吧 使用新的 Compose 文件但原始堆栈名称运行 `stack deploy` 命令——这就像更新现有堆栈一样。列出服务任务，你会看到更新是如何发生的：
- en: '` # deploy an updated Compose file for the stack` ` docker stack deploy -c
    ./todo-list/v2.yml todo`  ` # check all the replicas for the web service:` ` docker
    service ps todo_todo-web`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 部署更新后的堆栈 Compose 文件` ` docker stack deploy -c ./todo-list/v2.yml todo` 
    ` # 检查所有 Web 服务的副本:` ` docker service ps todo_todo-web`'
- en: My output is in figure 13.2\. You can see that the stack updates the service,
    and the service has two new replicas. The original replica was replaced because
    adding resource limits in the Compose file changes the container definition, and
    that needs to be actioned with a new container.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我的输出在图 13.2 中。你可以看到堆栈更新了服务，并且服务有两个新的副本。原始副本被替换，因为将资源限制添加到 Compose 文件中会更改容器定义，而这需要通过一个新的容器来执行。
- en: '![](../Images/13-2.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13-2.jpg)'
- en: Figure 13.2 Updating a stack with a new Compose file will update the service
    if the definition has changed.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 使用新的 Compose 文件更新堆栈将更新服务，如果定义已更改。
- en: Docker containers can access all the host machine’s CPU and memory if you don’t
    specify a limit. That’s the default, and it’s fine for non-production environments
    where you want to cram as many apps on your servers as possible and let them use
    the resources they need. In production, however, you want limits to safeguard
    against bad code or malicious users trying to max out your system, but those limits
    are established when the container starts, so if you update them you get a new
    container, which is a replica update in Swarm mode.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有指定限制，Docker 容器可以访问主机机器的所有 CPU 和内存。这是默认设置，对于你希望在服务器上尽可能多地运行应用程序的非生产环境来说，这是可以接受的。然而，在生产环境中，你希望限制来保护系统免受糟糕的代码或恶意用户试图耗尽系统资源的影响，但这些限制是在容器启动时建立的，所以如果你更新它们，你会得到一个新的容器，这在
    Swarm 模式下是一个副本更新。
- en: Swarm stacks are a neat way of grouping applications, which you need because
    a cluster will typically run many apps. You can manage applications as a whole
    using the `stack` commands in the Docker CLI, listing the individual services
    and the service replicas or removing the app altogether.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm 堆栈是一种将应用程序分组的好方法，因为你通常需要在一个集群中运行许多应用程序。你可以使用 Docker CLI 中的 `stack` 命令来整体管理应用程序，列出单个服务及其副本，或者完全删除应用程序。
- en: 'Try it now Stacks are the management unit for applications. They give you a
    simple way to work with an app that could be running multiple services, each with
    multiple replicas. Check what’s running in the to-do app stack and then remove
    it:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试吧 堆栈是应用程序的管理单元。它们为你提供了一个简单的方式来处理可能运行多个服务（每个服务可能有多个副本）的应用程序。检查待办事项应用程序堆栈中正在运行的内容，然后将其删除：
- en: '` # list all the services in the stack:` ` docker stack services todo`  ` #
    list all replicas for all services in the stack:` ` docker stack ps todo`  ` #
    remove the stack:` ` docker stack rm todo`'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 列出堆栈中的所有服务:` ` docker stack services todo`  ` # 列出堆栈中所有服务的所有副本:` ` docker
    stack ps todo`  ` # 删除堆栈:` ` docker stack rm todo`'
- en: This app is a very simple example with a Docker network, one service, and two
    replicas. Larger distributed apps could run dozens of services across hundreds
    of replicas in the Swarm, and you still deploy them in the same way with the Compose
    file and manage them with `docker` `stack` commands. Figure 13.3 shows my output,
    finally removing the whole stack.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个应用程序是一个带有Docker网络、一个服务和两个副本的非常简单的示例。更大的分布式应用程序可以在Swarm中运行数十个服务，跨越数百个副本，并且您仍然可以使用Compose文件以相同的方式部署它们，并使用`docker`
    `stack`命令来管理它们。图13.3显示了我的输出，最终删除了整个堆栈。
- en: '![](../Images/13-3.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13-3.jpg)'
- en: Figure 13.3 Working with the stack using the Docker CLI--you can list resources
    and remove them.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3 使用Docker CLI与堆栈一起工作——您可以列出资源并删除它们。
- en: You can manage all the resources in a stack without needing the Compose file,
    because all the specifications are stored inside the cluster database. That shared
    database is replicated between the Swarm managers, so it’s a safe place to store
    other resources too. It’s how you’ll store application configuration files in
    the Swarm, which you can make available to services in your Compose file.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以管理堆栈中的所有资源，而无需需要Compose文件，因为所有规范都存储在集群数据库中。该共享数据库在Swarm管理器之间进行复制，因此它是一个安全的地方来存储其他资源。这就是您在Swarm中存储应用程序配置文件的方式，您可以在Compose文件中将这些文件提供给服务。
- en: 13.2 Managing app configuration with config objects
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.2 使用配置对象管理应用程序配置
- en: Apps running in containers need to be able to load their configuration settings
    from the platform that is running the container. I’ve covered that with local
    development and test environments using Docker Compose with environment variables.
    Now we can round that out with production, which uses Docker config objects stored
    in the cluster. Figure 13.4 shows how that works, and the important thing here
    is that it’s the exact same Docker image in every environment. It’s just the application
    behavior that changes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器中运行的应用程序需要能够从运行容器的平台加载其配置设置。我使用带有环境变量的Docker Compose在本地开发和测试环境中解决了这个问题。现在我们可以通过使用存储在集群中的Docker配置对象来完善生产环境。图13.4展示了它是如何工作的，这里重要的是每个环境中都是相同的Docker镜像。只是应用程序的行为发生了变化。
- en: '![](../Images/13-4.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13-4.jpg)'
- en: Figure 13.4 Applying configuration from the platform; Swarm mode uses config
    objects and secrets.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4 从平台应用配置；Swarm模式使用配置对象和秘密。
- en: Configuration is such a critical part of deployment that all the orchestrators
    have a first-class resource to hold application configuration. In Swarm these
    are Docker config objects. They’re powerful because they let the container load
    its config from the cluster, but they also decouple the role of application deployment
    from configuration management.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 配置是部署如此关键的一部分，所有编排器都有一个一等资源来保存应用程序配置。在Swarm中，这些是Docker配置对象。它们很强大，因为它们允许容器从集群加载其配置，但它们也解耦了应用程序部署与配置管理的作用。
- en: Organizations often have a config management team that has access to all the
    secrets--API keys, database server passwords, SSL certificates--and those secrets
    are all stored in a secure system. That system is often completely separate from
    the environment where the apps are running, so the team needs a way of applying
    the config from the central system to the application platform. Docker Swarm supports
    that workflow with a specific type of resource--config objects--that you load
    into the cluster from an existing configuration file.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 组织通常有一个配置管理团队，可以访问所有秘密——API密钥、数据库服务器密码、SSL证书——并且这些秘密都存储在一个安全系统中。该系统通常与运行应用程序的环境完全分开，因此团队需要一种方法将中央系统中的配置应用到应用程序平台上。Docker
    Swarm通过一种特定的资源类型——配置对象——支持这种工作流程，您可以从现有的配置文件中将这些对象加载到集群中。
- en: 'Try it now The to-do app uses JSON for configuration. The default config in
    the image uses a local database file for storage, but that doesn’t work if you
    run many replicas--each container will have its own database, and users will see
    different lists depending on which replica services their request. The first step
    to fixing that is deploying a new config file in the cluster:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 待办事项应用程序使用 JSON 进行配置。镜像中的默认配置使用本地数据库文件进行存储，但如果你运行许多副本则不起作用--每个容器将有自己的数据库，并且用户将根据其请求的副本服务看到不同的列表。修复此问题的第一步是在集群中部署新的配置文件：
- en: '` # create the config object from a local JSON file:` ` docker config create
    todo-list-config ./todo-list/configs/config.json`  ` # check the configs in the
    cluster:` ` docker config ls`'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 从本地 JSON 文件创建配置对象：` ` docker config create todo-list-config ./todo-list/configs/config.json` 
    ` # 检查集群中的配置：` ` docker config ls`'
- en: Config objects are created with a name and the path to the config file contents.
    This app uses JSON, but config objects can store any type of data--XML, key/value
    pairs, or even binary files. The Swarm delivers the config object as a file in
    the container’s filesystem, so the application sees the exact same data you uploaded.
    Figure 13.5 shows my output--the config object is created with a long random ID
    in addition to the name.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 配置对象通过名称和配置文件内容的路径来创建。此应用程序使用 JSON，但配置对象可以存储任何类型的数据--XML、键/值对，甚至是二进制文件。Swarm
    将配置对象作为容器文件系统中的文件交付，因此应用程序看到的是你上传的确切相同数据。图 13.5 显示了我的输出--配置对象除了名称外还创建了一个长随机 ID。
- en: '![](../Images/13-5.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13-5.jpg)'
- en: Figure 13.5 Loading a local file into the Swarm cluster as a config object
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5 将本地文件加载到 Swarm 集群作为配置对象
- en: 'You work with config objects like other Docker resources--there are commands
    to remove and inspect them as well as to create them. Inspection is useful because
    it shows you the contents of the config file. That’s an important point about
    config objects: they’re not meant for sensitive data. The file content is not
    encrypted in the Swarm database, nor is it encrypted in transit as it moves from
    the managers to the nodes that are running the replicas.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以像处理其他 Docker 资源一样处理配置对象--有命令可以删除、检查以及创建它们。检查是有用的，因为它显示了配置文件的内容。这是关于配置对象的一个重要观点：它们不是为敏感数据设计的。文件内容在
    Swarm 数据库中未加密，在从管理器移动到运行副本的节点时也不会在传输过程中加密。
- en: 'Try it now You can inspect a config object to read out the complete contents.
    This shows you what the replica will see in the container filesystem when it uses
    the config object:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 你可以检查配置对象以读取其完整内容。这显示了当副本使用配置对象时在容器文件系统中将看到的内容：
- en: '` # inspect the config using the pretty flag to show the contents:` ` docker
    config inspect --pretty todo-list-config`'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 使用 pretty 标志检查配置以显示内容：` ` docker config inspect --pretty todo-list-config`'
- en: Figure 13.6 shows my output, which contains all the metadata about the config
    object and the file contents exactly as they were stored, including whitespace.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 显示了我的输出，其中包含有关配置对象和文件内容的所有元数据，包括空白字符。
- en: '![](../Images/13-6.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13-6.jpg)'
- en: Figure 13.6 Config objects are not secure--anyone with access to the cluster
    can see the contents.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 配置对象不安全--任何有权访问集群的人都可以看到内容。
- en: Managing config objects is a separate workflow from managing the applications
    that use those config objects. In a DevOps workflow, that could all be done by
    the same team or by one automated pipeline, but in larger enterprises you can
    keep the functions separate if that matches your existing processes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 管理配置对象是管理使用这些配置对象的应用程序的工作流程之外的独立流程。在 DevOps 工作流程中，所有这些都可以由同一个团队或一个自动化的管道来完成，但在大型企业中，如果这与你的现有流程相匹配，你可以保持功能分离。
- en: Services consume config objects by specifying them in the Compose file. Listing
    13.3 shows part of the updated definition for the to-do list application (the
    full file is called `v3.yml` ) that loads configuration from the config object.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 服务通过在 Compose 文件中指定配置对象来消费配置对象。列表 13.3 显示了待办事项应用程序更新定义的一部分（完整文件名为 `v3.yml`），该应用程序从配置对象中加载配置。
- en: Listing 13.3 Config objects in services get surfaced to the container filesystem
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.3 服务中的配置对象在容器文件系统中被暴露
- en: '` services:` `   todo-web:` `       image: diamol/ch06-todo-list` `       ports:`
    `           - 8080:80` `       configs:` `           - source: todo-list-config`
    `               target: /app/config/config.json`  ` #...` ` configs:` `   todo-list-config:`
    `         external: true`'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '` services:` `   todo-web:` `       image: diamol/ch06-todo-list` `       ports:`
    `           - 8080:80` `       configs:` `           - source: todo-list-config`
    `               target: /app/config/config.json`  ` #...` ` configs:` `   todo-list-config:`
    `         external: true`'
- en: When a container runs as a replica for this service, it will have the contents
    of the config object loaded from the Swarm into the file at `/app/config/config.json`
    , which is one of the paths the app uses as a configuration source. There’s a
    shorter syntax you can use where you just specify the name of the config object
    and Docker uses a default target path, but the actual path is different for different
    operating systems, so it’s better to explicitly state where you want the file
    to be surfaced. (The forward-slash directory paths work in both Windows and Linux
    containers.)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个容器作为此服务的副本运行时，它将从 Swarm 加载配置对象的全部内容到 `/app/config/config.json` 文件中，这是应用程序用作配置源之一的路径。你可以使用更短的语法，只需指定配置对象的名字，Docker
    就会使用默认的目标路径，但实际路径因不同的操作系统而异，所以最好明确指出你希望文件出现在哪个位置。（正斜杠目录路径在 Windows 和 Linux 容器中都有效。）
- en: The second part of the Compose file in listing 13.3 shows the config object
    itself, with its name and the `external` flag. External is how you specify that
    this resource should already exist on the cluster. The deployment workflow is
    to deploy the config objects first and then the apps that use them. You can do
    that by deploying the v3 Compose file, which also includes a service for the SQL
    database, so multiple web containers can share the same database.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.3 中的 Compose 文件的第二部分显示了配置对象本身，包括其名称和 `external` 标志。`external` 是你指定此资源应该在集群中已经存在的方式。部署工作流程是首先部署配置对象，然后部署使用它们的应用程序。你可以通过部署
    v3 Compose 文件来实现，它还包括一个用于 SQL 数据库的服务，这样多个 Web 容器就可以共享同一个数据库。
- en: 'Try it now Update the application by deploying the YAML file--the `stack` command
    is the same. The Swarm will create a new replica for the database service and
    new replicas for the web application:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在就试试吧！通过部署 YAML 文件来更新应用程序——`stack` 命令是一样的。Swarm 将为数据库服务创建一个新的副本，并为 Web 应用程序创建新的副本：
- en: '` # deploy the updated app definition:` ` docker stack deploy -c ./todo-list/v3.yml
    todo` ` # list the services in the stack:` ` docker stack services todo`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 部署更新的应用程序定义：` ` docker stack deploy -c ./todo-list/v3.yml todo` ` # 列出堆栈中的服务：`
    ` docker stack services todo`'
- en: You removed the old stack in a previous exercise, so this is a new deployment.
    You’ll see a network and two services being created. I’ve scaled the web component
    down to a single replica so we can follow the updates more easily; each of the
    services is now running a single replica. My output is in figure 13.7.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的练习中，你已经移除了旧的堆栈，所以这是一个新的部署。你会看到创建了一个网络和两个服务。我已经将 Web 组件的副本数减少到单个，这样我们就可以更容易地跟踪更新；现在每个服务都在运行单个副本。我的输出在图
    13.7 中。
- en: '![](../Images/13-7.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.7](../Images/13-7.jpg)'
- en: 'Now the app is configured to use Postgres as the database, which is the setting
    the config object loads into the replicas. If you browse to http: */ /* localhost:8080
    (or to your machine from another machine if you’re on Windows), you’ll see the
    app isn’t working. You can check the logs of the web service to see why, and it
    will show a lot of errors about connecting to the database. This deployment configures
    the web app to use Postgres, but the config object doesn’t provide the connection
    details for the database, so the connection fails--we’ll fix that in the next
    exercise.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '现在应用程序已配置为使用 Postgres 作为数据库，这是配置对象加载到副本中的设置。如果你浏览到 http: */ /* localhost:8080（或者如果你在
    Windows 上，从另一台机器访问你的机器），你会看到应用程序没有工作。你可以检查 Web 服务的日志来查看原因，并且它将显示许多关于连接到数据库的错误。这次部署配置了
    Web 应用程序使用 Postgres，但配置对象没有提供数据库的连接细节，所以连接失败——我们将在下一个练习中修复这个问题。'
- en: Sensitive data shouldn’t be kept in config objects, because they’re not encrypted
    and they can be read by anyone who has access to the cluster. That includes database
    connection strings that might have usernames and passwords, and also URLs for
    production services and API keys. You should aim for defense in depth in your
    production environment, so even if the chances of someone gaining access to your
    cluster are slim, you should still encrypt sensitive data inside the cluster.
    Docker Swarm provides secrets for storing this class of config.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感数据不应存储在配置对象中，因为它们未加密，并且任何有权访问集群的人都可以读取。这包括可能包含用户名和密码的数据库连接字符串，以及生产服务的 URL
    和 API 密钥。您应该在生产环境中追求深度防御，即使有人访问您的集群的机会很小，您也应该在集群内部加密敏感数据。Docker Swarm 提供密钥来存储此类配置。
- en: 13.3 Managing confidential settings with secrets
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.3 使用密钥管理机密设置
- en: 'Secrets are a resource in the Swarm that the cluster manages, and they work
    almost exactly like config objects. You create secrets from a local file, and
    that gets stored in the cluster database. Then you reference the secret in a service
    specification, and the contents of the secret get loaded into the container filesystem
    at runtime. The key difference with secrets is that you can only read them in
    plain text at one point in the workflow: inside the container when they are loaded
    from the Swarm.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 密钥是 Swarm 中由集群管理的一种资源，它们几乎与配置对象完全相同。您可以从本地文件创建密钥，并将其存储在集群数据库中。然后，在服务规范中引用密钥，密钥的内容在运行时被加载到容器文件系统中。与密钥的关键区别在于，您只能在工作流程中的一个点上以纯文本形式读取它们：在容器内部，当它们从
    Swarm 加载时。
- en: Secrets are encrypted throughout their lifetime in the cluster. The data is
    stored encrypted in the database shared by the managers, and secrets are only
    delivered to nodes that are scheduled to run replicas that need the secret. Secrets
    are encrypted in transit from the manager node to the worker, and they are only
    unencrypted inside the container, where they appear with the original file contents.
    We’ll use a secret to store the database connection string for the to-do list
    app.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 密钥在其在集群中的整个生命周期内都是加密的。数据以加密形式存储在由管理器共享的数据库中，并且只有计划运行需要密钥的副本的节点才会接收密钥。密钥在从管理节点到工作节点的传输过程中加密，并且只有在容器内部才会解密，在那里它们会以原始文件内容的形式出现。我们将使用密钥来存储待办事项应用的数据库连接字符串。
- en: 'Try it now Create the secret from the local file, and then inspect it to see
    what information Docker gives you about the secret:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下：从本地文件创建密钥，然后检查它以查看 Docker 提供的关于密钥的信息：
- en: '` # create the secret from a local JSON file:` ` docker secret create todo-list-secret
    ./todo-list/secrets/secrets.json`  ` # inspect the secret with the pretty flag
    to see the data:` ` docker secret inspect --pretty todo-list-secret`'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 从本地 JSON 文件创建密钥:` ` docker secret create todo-list-secret ./todo-list/secrets/secrets.json` 
    ` # 使用 pretty 标志检查密钥以查看数据:` ` docker secret inspect --pretty todo-list-secret`'
- en: The user experience for working with secrets is the same as with config objects.
    The only difference is you can’t read the contents of the secret once it’s been
    stored. You can see my output in figure 13.8--inspecting the secret only shows
    the metadata about the resource, not the actual data, which you would see if this
    was a config object.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用密钥的用户体验与配置对象相同。唯一的区别是，一旦密钥被存储，您就无法读取其内容。您可以在图 13.8 中看到我的输出--检查密钥仅显示有关资源的元数据，而不是实际数据，如果您查看的是配置对象，您会看到这些数据。
- en: '![](../Images/13-8.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13-8.jpg)'
- en: Figure 13.8 Once secrets are stored in the Swarm, you can’t read the original
    unencrypted contents.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.8 一旦密钥存储在 Swarm 中，您就无法读取原始未加密的内容。
- en: Now that the secret is stored in the Swarm, we can deploy a new version of the
    app with a service specification that uses the secret. The Compose syntax for
    secrets is very similar to config objects; you specify the source and the target
    path of the secret in the service definition, and then the secret itself gets
    its own definition. Listing 13.4 shows the key sections of the new deployment,
    which is in the `v4.yml` file.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，密钥已存储在 Swarm 中，我们可以使用包含密钥的服务规范部署应用的新版本。密钥的 Compose 语法与配置对象非常相似；您在服务定义中指定密钥的源和目标路径，然后密钥本身获得其自己的定义。列表
    13.4 显示了新部署的关键部分，这些部分位于 `v4.yml` 文件中。
- en: Listing 13.4 Specifying secrets and configs for app configuration
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.4 指定应用配置的密钥和配置
- en: '` services:` `   todo-web:` `       image: diamol/ch06-todo-list` `       ports:`
    `           - 8080:80` `       configs:` `           - source: todo-list-config`
    `               target: /app/config/config.json` `       secrets:` `           -
    source: todo-list-secret` `               target: /app/config/secrets.json`  ` #...`
    ` secrets:` `   todo-list-secret:`'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '` services:` `   todo-web:` `       image: diamol/ch06-todo-list` `       ports:`
    `           - 8080:80` `       configs:` `           - source: todo-list-config`
    `               target: /app/config/config.json` `       secrets:` `           -
    source: todo-list-secret` `               target: /app/config/secrets.json`  ` #...`
    ` secrets:` `   todo-list-secret:` '
- en: The content of that secret is more JSON, loaded into another path where the
    app looks for configuration sources. This sets the app with the connection details
    to use the Postgres container for its data store, so when you deploy the app,
    users will get the same list of items whichever web replica serves them.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 那个秘密的内容是更多的JSON，加载到另一个路径，应用程序会在这里查找配置源。这设置了应用程序使用Postgres容器作为其数据存储的连接细节，因此当你部署应用程序时，无论哪个Web副本提供服务，用户都会得到相同的物品列表。
- en: Try it now Deploy the latest version of the app, which supplies the missing
    database connection string and fixes the web application. This updates the service.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在尝试一下 部署应用程序的最新版本，它提供了缺少的数据库连接字符串并修复了Web应用程序。这将更新服务。
- en: '` # deploy the new version of the app:` ` docker stack deploy -c ./todo-list/v4.yml
    todo`  ` # check the replicas for the stack:` ` docker stack ps todo`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 部署应用程序的新版本:` ` docker stack deploy -c ./todo-list/v4.yml todo` ` # 检查堆栈的副本:`
    ` docker stack ps todo`'
- en: Only the web service definition has changed in the Compose file, but when you
    run this you’ll see Docker state that it’s updating both services. It doesn’t
    actually make any updates to the database service, so this is a slightly misleading
    output from the CLI--it will list all the services in the Compose file as “updating”
    even though they won’t all change. You can see that in my output in figure 13.9.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在Compose文件中的Web服务定义已更改，但当你运行它时，你会看到Docker状态更新了两个服务。实际上，它并没有对数据库服务进行任何更新，所以这是CLI的一个稍微误导性的输出--它将列出Compose文件中的所有服务作为“更新中”，即使它们不会全部更改。你可以在图13.9的输出中看到这一点。
- en: '![](../Images/13-9.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13-9.jpg)'
- en: Figure 13.9 Deploying the latest app version will correct the config and fix
    the app.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.9 部署最新应用程序版本将纠正配置并修复应用程序。
- en: Now the app is working correctly, which you’ll see if you browse to port 8080
    from a remote machine (if you’re using Windows containers) or localhost (if you’re
    using Linux containers). Figure 13.10 shows the infrastructure setup, with the
    containers connecting on the Docker network and the secret loaded from the Swarm.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，应用程序正在正常工作，如果你从远程机器（如果你使用Windows容器）或localhost（如果你使用Linux容器）浏览到端口8080，你会看到这一点。图13.10显示了基础设施设置，容器在Docker网络上连接，并且从Swarm加载了秘密。
- en: The important thing that’s missing from figure 13.10 is the hardware view, and
    that’s because this application has the same deployment architecture on Swarms
    of any size. Secrets and config objects are stored in the managers’ distributed
    database and are available to every node. The stack creates an overlay network
    so containers can connect to each other whichever nodes they’re running on, and
    the service uses the ingress network so consumers can send traffic to any node
    and have it actioned by one of the web replicas.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.10中缺少的重要东西是硬件视图，这是因为这个应用程序在任何大小的Swarm上都有相同的部署架构。秘密和配置对象存储在管理员的分布式数据库中，并且对每个节点都是可用的。堆栈创建了一个覆盖网络，以便容器可以在它们运行的任何节点上相互连接，并且服务使用入口网络，以便消费者可以向任何节点发送流量，并由其中一个Web副本执行操作。
- en: '![](../Images/13-10.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/13-10.jpg)'
- en: Figure 13.10 The to-do app running as a stack uses the key features of Docker
    Swarm.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.10 使用堆栈运行的任务应用程序使用了Docker Swarm的关键特性。
- en: 'One thing you do need to understand about config objects and secrets: they
    can’t be updated. When you create them in the cluster, the contents will always
    be the same, and if you need to update the config for an application, you need
    to replace it. This will involve three steps:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 关于配置对象和秘密，你需要理解的一件事是：它们不能被更新。当你集群中创建它们时，内容总是相同的，如果你需要更新应用程序的配置，你需要替换它。这将涉及三个步骤：
- en: Create a new config object or secret with the updated contents and a different
    name from the previous object.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用更新的内容和一个不同于上一个对象的名称创建一个新的配置对象或秘密。
- en: Update the name of the config object or secret that your app uses in the Compose
    file, specifying the new name.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新Compose文件中应用程序使用的配置对象或秘密的名称，并指定新名称。
- en: Deploy the stack from the updated Compose file.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从更新的Compose文件部署堆栈。
- en: This process means you need to update your service every time you change configuration,
    which means that running containers get replaced with new ones. This is one area
    where orchestrators take different approaches--Kubernetes lets you update existing
    configuration and secret objects in the cluster. That brings its own problems
    though, because some application platforms watch their config files for changes
    and others don’t, so changes may be ignored and you need to replace containers
    anyway. Swarm is consistent--you’ll always need to update your services when you
    roll out configuration changes.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程意味着每次你更改配置时都需要更新你的服务，这意味着正在运行的容器将被新的容器替换。这是编排器采取不同方法的一个领域——Kubernetes允许你在集群中更新现有的配置和秘密对象。但这也会带来自己的问题，因为一些应用平台会监视它们的配置文件以查找更改，而其他平台则不会，因此更改可能会被忽略，你仍然需要替换容器。Swarm是一致的——当你推出配置更改时，你总是需要更新你的服务。
- en: Updating services shouldn’t scare you, though. You’ll be rolling out container
    updates every time you have new features to deploy in your app, or when there
    are security updates in the dependencies you use or the operating system your
    images are based on. At a minimum, you should expect to release updates every
    month, which is how often most operating-system-based images are updated on Docker
    Hub.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，更新服务不应该让你感到害怕。每次你有新功能要部署到你的应用中，或者当你在使用的依赖项或基于你镜像的操作系统中有安全更新时，你都会推出容器更新。至少，你应该预计每个月发布一次更新，这是大多数基于操作系统的镜像在Docker
    Hub上更新的频率。
- en: That brings us to stateful applications in Swarm mode. You’re going to be replacing
    containers regularly, so you’ll need to use Docker volumes for persistent storage,
    and volumes work slightly differently in the Swarm.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这就引出了在Swarm模式下的有状态应用。你将定期替换容器，因此你需要使用Docker卷来持久化存储，而在Swarm中卷的工作方式略有不同。
- en: 13.4 Storing data with volumes in the Swarm
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.4 在Swarm中使用卷存储数据
- en: We covered Docker volumes way back in chapter 6--they’re units of storage that
    have a separate life cycle from containers. Any stateful apps you want to containerize
    can use volumes for storage. Volumes appear as part of the container’s filesystem
    but they’re actually stored outside of the container. Application upgrades replace
    the container and attach the volume to the new container, so the new container
    starts with all the data the previous container had.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第六章中就介绍了Docker卷——它们是具有独立生命周期的存储单元。任何你想容器化的有状态应用都可以使用卷进行存储。卷作为容器文件系统的一部分出现，但实际上它们存储在容器之外。应用升级会替换容器并将卷附加到新容器上，因此新容器启动时将具有前一个容器所有的数据。
- en: Volumes are conceptually the same in orchestrators too; you add a volume mount
    specification for the service in the Compose file, and replicas see that volume
    as a local directory. There’s a big difference in how the data gets stored, though,
    and that’s something you need to understand to make sure your app works as expected.
    In a cluster you’ll have multiple nodes that can run containers, and each node
    has its own disk where it stores local volumes. The simplest way to maintain state
    between updates is to use a local volume.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在编排器中，卷的概念上是相同的；你在Compose文件中为服务添加卷挂载规范，副本将把该卷视为本地目录。然而，数据存储的方式有很大不同，这是你需要理解以确保你的应用按预期工作的事情。在一个集群中，你将有多节点可以运行容器，每个节点都有自己的磁盘，用于存储本地卷。在更新之间保持状态的最简单方法是使用本地卷。
- en: There’s a problem with that approach though--a replacement replica may be scheduled
    to run on a different node from the original, so it won’t have access to the original
    node’s data. You can pin services to specific nodes, which means updates will
    always run on the node that has the data. That works for scenarios where you want
    application data to be stored outside of the container so it survives updates,
    but where you don’t need to run multiple replicas and you don’t need to allow
    for server failure. You apply a label to your node, and in your Compose file you
    restrict replicas to running on that node.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法存在一个问题——替换副本可能被调度在原始节点之外的其他节点上运行，因此它将无法访问原始节点上的数据。你可以将服务固定到特定的节点上，这意味着更新将始终在具有数据的节点上运行。这对于你希望在容器外部存储应用数据以使其在更新中存活，但不需要运行多个副本且不需要允许服务器故障的场景有效。你给你的节点应用一个标签，并在你的Compose文件中限制副本只在那个节点上运行。
- en: 'Try it now You’ve got a single node Swarm, so every replica will run on this
    node anyway, but the labeling process works in the same way for multi-node Swarms.
    Labels can be any key/value pair; we’ll use this one to assign a fictitious storage
    class:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 你有一个单节点 Swarm，所以每个副本无论如何都会在这个节点上运行，但标签过程对于多节点 Swarm 也是相同的。标签可以是任何键/值对；我们将使用这个来分配一个虚构的存储类：
- en: '` # find the ID for your node and update it, adding a label:` ` docker node
    update --label-add storage=raid $(docker node ls -q)`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 找到你的节点 ID 并更新它，添加一个标签：` ` docker node update --label-add storage=raid $(docker
    node ls -q)`'
- en: The output of that command is just the node ID, so we’ll skip the screenshot.
    More interesting is that you now have a way to identify nodes in the cluster,
    and that can be used to constrain where service replicas get scheduled. Listing
    13.5 shows the `constraint` field in the service definition for the to-do database,
    which also now has a volume specified--this is in the `v5.yml` deployment file.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令的输出只是节点 ID，所以我们省略了截图。更有趣的是，你现在有了一种识别集群中节点的方法，这可以用来约束服务副本的调度位置。列表 13.5 显示了待办数据库服务定义中的
    `constraint` 字段，该数据库现在也指定了卷--这位于 `v5.yml` 部署文件中。
- en: Listing 13.5 Configuring constraints and volumes for services in the Swarm
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.5 配置 Swarm 中服务的约束和卷
- en: '` services:` `   todo-db:` `       image: diamol/postgres:11.5` `       volumes:`
    `         - todo-db-data:/var/lib/postgresql/data` `       deploy:` `           placement:`
    `               constraints:` `                   - node.labels.storage == raid` 
    ` #...` ` volumes:` `     todo-db-data:`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '` services:` `   todo-db:` `       image: diamol/postgres:11.5` `       volumes:`
    `         - todo-db-data:/var/lib/postgresql/data` `       deploy:` `           placement:`
    `               constraints:` `                   - node.labels.storage == raid` 
    ` #...` ` volumes:` `     todo-db-data:`'
- en: I haven’t trimmed down the volume specification at the end of the Compose file
    in that listing--the volume name is all there is. This will get created using
    the default volume driver in the Swarm, which uses the local disk. When you deploy
    this to your cluster, it will ensure the database replica runs on the node that
    matches the storage label, and that node will create a local volume called `todo-db-data`
    , which is where the data files get stored.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有在列表末尾的 Compose 文件中缩减卷的指定部分--卷名就是所有内容。这个卷将使用 Swarm 的默认卷驱动程序创建，该驱动程序使用本地磁盘。当你将此部署到你的集群时，它将确保数据库副本在匹配存储标签的节点上运行，并且该节点将创建一个名为
    `todo-db-data` 的本地卷，数据文件将存储在这里。
- en: 'Try it now The constraint in the Compose file matches the label you added to
    your Swarm node, so the database container will run there and use the local volume
    on that node. These commands will explore the volumes on your node before and
    after the deployment:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看 Compose 文件中的约束与你在 Swarm 节点上添加的标签相匹配，所以数据库容器将在这里运行并使用该节点上的本地卷。这些命令将在部署前后探索你节点上的卷：
- en: '` # list all the volumes on your node, showing just IDs:` ` docker volume ls
    -q`  ` # update the stack to v5 - for Linux containers:` ` docker stack deploy
    -c ./todo-list/v5.yml todo`  ` # OR with Windows containers, using Windows-style
    paths for the volume:` ` docker stack deploy -c ./todo-list/v5-windows.yml todo` 
    ` # check the volumes again:` ` docker volume ls -q`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 列出你节点上的所有卷，只显示 ID:` ` docker volume ls -q`  ` # 更新堆栈到 v5 - 对于 Linux 容器：`
    ` docker stack deploy -c ./todo-list/v5.yml todo`  ` # 或者使用 Windows 容器，使用 Windows
    风格的路径来指定卷：` ` docker stack deploy -c ./todo-list/v5-windows.yml todo`  ` # 再次检查卷：`
    ` docker volume ls -q`'
- en: You’ll see there are lots of volumes (you’ll probably have far more than me;
    I cleared mine down with the `docker` `volume` `prune` command before these exercises).
    Images can specify volumes in the Dockerfile, and if services use images with
    volumes, the stack creates a default volume for the service. That volume has the
    same lifetime as the stack, so if you remove the stack, the volumes get removed,
    and if you update services, they’ll get a new default volume. If you want your
    data to persist between updates, you need to use a named volume in your Compose
    file. You can see my output in figure 13.11; deploying the stack created a new
    named volume rather than a default one.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到有很多卷（你可能比我多得多；我在这些练习之前用 `docker` `volume` `prune` 命令清除了我的卷）。镜像可以在 Dockerfile
    中指定卷，如果服务使用带有卷的镜像，堆栈会为服务创建一个默认卷。这个卷的寿命与堆栈相同，所以如果你删除了堆栈，卷也会被删除，如果你更新了服务，它们将获得一个新的默认卷。如果你想使数据在更新之间持久化，你需要在
    Compose 文件中使用一个命名的卷。你可以在图 13.11 中看到我的输出；部署堆栈创建了一个新的命名卷而不是默认卷。
- en: '![](../Images/13-11.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/13-11.jpg)'
- en: Figure 13.11 Deploying stacks creates volumes too, which can be anonymous or
    named.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.11 部署堆栈也会创建卷，这些卷可以是匿名的或命名的。
- en: This deployment provides guarantees for data availability, if the labeled node
    itself is available. If the container fails its health checks and gets replaced,
    the new replica will run on the same node as the previous replica and attach to
    the same named volume. When you update the database service specification, you
    get the same guarantees. That means the database files are persisted between containers,
    and your data is safe. You can add items to your to-do list through the web UI,
    upgrade the database service, and find that the old data is still there in the
    UI from the new database container.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果标记的节点本身可用，这种部署提供了数据可用性的保证。如果容器失败其健康检查并被替换，新的副本将在与先前副本相同的节点上运行，并附加到相同的命名卷。当你更新数据库服务规范时，你将获得相同的保证。这意味着数据库文件在容器之间持久化，你的数据是安全的。你可以通过Web
    UI添加项目到待办事项列表，升级数据库服务，并发现旧数据仍然在新数据库容器中的UI中。
- en: 'Try it now There’s been a new release of the Postgres server since I wrote
    chapter 6, and it’s a good idea to stay current, so we’ll update the database
    service. The Compose spec in `v6.yml` is identical to `v5.yml` except it uses
    the updated version of Postgres:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在试试看。自从我写第6章以来，Postgres服务器已经发布了一个新版本，保持最新是个好主意，所以我们将更新数据库服务。`v6.yml`中的Compose规范与`v5.yml`相同，除了它使用了更新的Postgres版本：
- en: '` # deploy the updated database - for Linux containers:` ` docker stack deploy
    -c ./todo-list/v6.yml todo`  ` # OR for Windows containers:` ` docker stack deploy
    -c ./todo-list/v6-windows.yml todo`  ` # check the tasks in the stack:` ` docker
    stack ps todo`  ` # and check volumes:` ` docker volume ls -q`'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '` # 部署更新的数据库 - 对于Linux容器：` ` docker stack deploy -c ./todo-list/v6.yml todo` 
    ` # 或者对于Windows容器：` ` docker stack deploy -c ./todo-list/v6-windows.yml todo` 
    ` # 检查堆栈中的任务：` ` docker stack ps todo`  ` # 并检查卷：` ` docker volume ls -q`'
- en: You can see my output in figure 13.12\. The new database replica is running
    from an updated Docker image, but it attaches to the volume from the previous
    replica, so all my data is preserved.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图13.12中看到我的输出。新的数据库副本是从更新的Docker镜像运行的，但它附加到来自先前副本的卷，所以我的所有数据都得到了保留。
- en: '![](../Images/13-12.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/13-12.jpg)'
- en: Figure 13.12 Updating a service that uses a named volume preserves the data
    for the new container.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.12 更新使用命名卷的服务可以保留新容器的数据。
- en: This is a simple example, and things get more complex when you have different
    storage requirements for your applications because the data in local volumes is
    not replicated across all the nodes. Applications that use disk as a data cache
    will be fine with local volumes, as the data can be different for each replica,
    but that won’t work for apps that need to access shared state across the cluster.
    Docker has a plugin system for volume drivers, so Swarms can be configured to
    provide distributed storage using a cloud storage system or a storage device in
    the datacenter. Configuring those volumes depends on the infrastructure you’re
    using, but you consume them in the same way, attaching volumes to services.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简单的例子，当你为你的应用程序有不同的存储需求时，事情会变得更加复杂，因为本地卷中的数据不会在所有节点之间复制。使用磁盘作为数据缓存的程序对本地卷可以很好地工作，因为每个副本的数据可以不同，但这对于需要在整个集群中访问共享状态的程序来说是不行的。Docker有一个用于卷驱动程序的插件系统，因此Swarm可以被配置为使用云存储系统或数据中心中的存储设备来提供分布式存储。配置这些卷取决于你使用的基础设施，但你可以以相同的方式消费它们，将卷附加到服务。
- en: 13.5 Understanding how the cluster manages stacks
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.5 理解集群如何管理堆栈
- en: Stacks in Docker Swarm are just groups of resources that the cluster manages
    for you. A production stack will contain many resources, and they all behave slightly
    differently in terms of how the orchestrator manages them. Figure 13.13 shows
    how Swarm manages the typical types of resources.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm中的堆栈只是集群为你管理的资源组。一个生产堆栈将包含许多资源，它们在编排器管理它们的方式上略有不同。图13.13显示了Swarm如何管理典型类型的资源。
- en: '![](../Images/13-13.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/13-13.jpg)'
- en: Figure 13.13 How Docker Swarm resources are managed by stack deployments
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.13 Docker Swarm资源如何通过堆栈部署进行管理
- en: 'There are a few takeaways from this. You’ve already worked through some of
    these scenarios in the exercises, but we’ll finish up the chapter making them
    clear:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个例子中我们可以得到一些启示。你已经在练习中处理了一些这些场景，但我们将完成这一章，使它们变得清晰：
- en: Volumes can be created and removed by the Swarm. Stacks will create a default
    volume if the service image specifies one, and that volume will be removed when
    the stack is removed. If you specify a named volume for the stack, it will be
    created when you deploy, but it won’t be removed when you delete the stack.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm可以创建和删除卷。如果服务镜像指定了默认卷，堆栈将创建一个默认卷，并且当堆栈被删除时，该卷将被删除。如果您为堆栈指定了命名卷，则在部署时将创建它，但在删除堆栈时不会删除它。
- en: Secrets and configs are created when an external file gets uploaded to the cluster.
    They’re stored in the cluster database and delivered to containers where the service
    definition requires them. They are effectively write-once read-many objects and
    can’t be updated. The admin process for storing app configuration in the Swarm
    is separate from the app deployment process.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当外部文件上传到集群时，会创建机密和配置。它们存储在集群数据库中，并交付到需要它们的容器中。它们是实际上写一次读多次的对象，并且不能更新。在Swarm中存储应用程序配置的管理员过程与应用程序部署过程是分开的。
- en: Networks can be managed independently of applications, with admins explicitly
    creating networks for applications to use, or they can be managed by the Swarm,
    which will create and remove them when necessary. Every stack will be deployed
    with a network to attach services to, even if one is not specified in the Compose
    file.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络可以独立于应用程序进行管理，管理员可以明确为应用程序创建网络，或者由Swarm管理，Swarm将在必要时创建和删除它们。每个堆栈都将部署一个网络以附加服务，即使配置文件中没有指定也是如此。
- en: Services are created or removed when stacks are deployed, and while they’re
    running, the Swarm monitors them constantly to ensure the desired service level
    is being met. Replicas that fail health checks get replaced, as do replicas that
    get lost when nodes go offline.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当堆栈部署时，会创建或删除服务，并且在它们运行时，Swarm会持续监控它们以确保达到期望的服务级别。失败健康检查的副本将被替换，当节点离线时丢失的副本也是如此。
- en: The stack is a logical group of components that make up an application, but
    it doesn’t map out a dependency graph between services. When you deploy a stack
    to the cluster, the managers spin up as many service replicas as quickly as they
    can across the cluster. You can’t constrain the cluster to start one service completely
    before starting another, and if you could, that would probably ruin deployment
    performance. Instead you need to assume that your components will start in a random
    order, and capture health and dependency checks in your images so containers fail
    fast if the application can’t run. That way the cluster can repair the damage
    by restarting or replacing containers, and that gets you a self-healing app.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 堆栈是由组成应用程序的组件的逻辑组，但它不会映射出服务之间的依赖关系图。当您将堆栈部署到集群时，管理器将在集群中尽可能快地启动尽可能多的服务副本。您不能限制集群在启动另一个服务之前完全启动一个服务，如果可以，这可能会破坏部署性能。相反，您需要假设您的组件将以随机顺序启动，并在您的镜像中捕获健康和依赖性检查，以便如果应用程序无法运行，容器可以快速失败。这样，集群可以通过重启或替换容器来修复损坏，从而实现自我修复的应用程序。
- en: 13.6 Lab
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.6 实验室
- en: 'Lab! This one will get you some more experience writing Compose files to define
    apps and deploying them as stacks on the Swarm. I’d like you to write a production
    deployment for the image gallery app from chapter 9, which should be in a single
    Compose file that matches these requirements:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 实验室！这个实验将让您获得更多编写Compose文件以定义应用程序并将其作为堆栈在Swarm上部署的经验。我希望您为第9章中的图像库应用程序编写一个生产部署，该部署应在一个符合这些要求的单个Compose文件中：
- en: The access log API uses the image `diamol/ch09-access-log` . It’s an internal
    component only accessed by the web app, and it should run on three replicas.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问日志API使用镜像`diamol/ch09-access-log`。它是一个仅由Web应用程序访问的内部组件，并且应该在三个副本上运行。
- en: The NASA API uses the image `diamol/ch09-image-of-the-day` . That should be
    publicly accessible on port 8088 and run on five replicas to support the expected
    incoming load.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NASA API使用镜像`diamol/ch09-image-of-the-day`。它应该在端口8088上公开访问，并运行在五个副本上以支持预期的入站负载。
- en: The web app uses the image `diamol/ch09-image-gallery` . It should be available
    at the standard HTTP port 80 and run on two replicas.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Web应用程序使用镜像`diamol/ch09-image-gallery`。它应该在标准的HTTP端口80上可用，并运行在两个副本上。
- en: All the components should have sensible CPU and memory limits (this may need
    a few rounds of deployments to work out safe maximums).
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有组件都应该有合理的CPU和内存限制（这可能需要几轮部署来确定安全最大值）。
- en: When you deploy the stack, the app should work.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您部署堆栈时，应用程序应该能够运行。
- en: 'There are no volumes, configs, or secrets to worry about with this app, so
    it should be a pretty simple Compose file. As always, you can find my solution
    on GitHub for reference: *[https://github.com/sixeyed/diamol/blob/master/ch13/lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch13/lab/README.md)*
    .'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此应用无需担心卷积、配置或秘密，因此它应该是一个相当简单的 Compose 文件。一如既往，您可以在 GitHub 上找到我的解决方案作为参考：*[https://github.com/sixeyed/diamol/blob/master/ch13/lab/README.md](https://github.com/sixeyed/diamol/blob/master/ch13/lab/README.md)*
    .
