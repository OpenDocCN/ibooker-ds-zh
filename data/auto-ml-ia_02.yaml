- en: 1 From machine learning to automated machine learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 从机器学习到自动化机器学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Defining and introducing the fundamental concepts of machine learning
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义并介绍机器学习的基本概念
- en: Describing the motivation for and high-level concepts of automated machine learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述自动化机器学习的动机和高级概念
- en: '*Artificial intelligence* (AI), which reaches into many aspects of everyday
    life, has been extensively explored in recent years. It attempts to use computational
    devices to automate tasks by allowing them to perceive the environment as humans
    do. As a branch of AI, *machine learning* (ML) enables a computer to perform a
    task through self-exploration of data. It allows the computer to learn, so it
    can do things that go beyond what we know how to order it to do. But the barriers
    to entry are high: the cost of learning the techniques involved and accumulating
    the necessary experience with applications means practitioners without much expertise
    cannot easily use ML. Taking ML techniques from their ivory tower and making them
    accessible to more people is becoming a key focus of research and industry. Toward
    this end, *automated machine learning* (AutoML) has emerged as a prevailing research
    field. Its aim is to simulate how human experts solve ML problems and discover
    the optimal ML solutions for a given problem automatically, thereby granting practitioners
    without extensive experience access to off-the-shelf ML techniques. As well as
    being beneficial for newcomers, AutoML will relieve experts and data scientists
    of the burden of designing and configuring ML models. Being a cutting-edge topic,
    it is new to most people, and its current capabilities are often exaggerated by
    mass media. To give you a glimpse of what AutoML is, this chapter provides some
    background and an introduction to the fundamental concepts and orients you to
    its research value and practical benefits. Let’s start with a toy example.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能*（AI），它渗透到日常生活的许多方面，近年来已被广泛研究。它试图通过允许计算设备像人类一样感知环境来自动化任务。作为人工智能的一个分支，*机器学习*（ML）使计算机能够通过自我探索数据来执行任务。它允许计算机学习，因此它可以完成我们不知道如何命令它去做的事情。但是，入门的门槛很高：学习涉及的技术和积累应用所需的经验的成本意味着没有太多专业知识的从业者难以使用机器学习。将机器学习技术从象牙塔中取出并使其对更多人可及，正成为研究和工业界的关键焦点。为此，*自动化机器学习*（AutoML）已成为一个主流的研究领域。其目标是模拟人类专家如何解决机器学习问题，并自动发现给定问题的最佳机器学习解决方案，从而让没有丰富经验的从业者能够访问现成的机器学习技术。除了对新手有益外，AutoML还将减轻专家和数据科学家设计和配置机器学习模型的负担。作为一个前沿话题，它对大多数人来说都是新的，其当前的能力常常被大众媒体夸大。为了让你对AutoML有一个大致的了解，本章提供了一些背景知识，介绍了基本概念，并指导你了解其研究价值和实际效益。让我们从一个玩具示例开始。'
- en: 1.1 A glimpse of automated machine learning
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 自动化机器学习的一瞥
- en: Suppose you want to design an ML model to recognize handwritten digits in images.
    The ML model will take the images as inputs and output the corresponding digits
    in each of the images (see figure 1.1).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要设计一个机器学习模型来识别图像中的手写数字。该机器学习模型将图像作为输入，并输出每个图像中相应的数字（见图1.1）。
- en: '![01-01](../Images/01-01.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![01-01](../Images/01-01.png)'
- en: Figure 1.1 Recognizing handwritten digits with an ML model
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 使用机器学习模型识别手写数字
- en: In case you’re not experienced with ML, let’s use a programmatic illustration
    with Pythonic style to show how we usually achieve this goal in practice. We take
    an ML model as an object instantiated from a class, as shown in listing 1.1\.
    This class corresponds to a specific type of ML algorithm (a set of procedures)
    that we would like to use in our model.[¹](#pgfId-1011863) To instantiate a model,
    besides selecting the algorithm class to be used, we also need to feed the algorithm
    some historical data and arguments (arg1 and arg2). The historical data used here
    consists of images of handwritten digits, whose labels (corresponding numbers)
    are already known. This helps the machine (or the ML algorithm) to conduct the
    learning process—that is, to learn how to recognize the digits in images, similar
    to how a child is trained to recognize objects from pictures. (You’ll see the
    details of this process in later sections.) The arguments here are used to control
    the algorithm, instructing it how to do this process. The resulting ML model will
    be able to predict the digits in previously unseen images (see figure 1.1) with
    the second line of code in the next listing.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不熟悉机器学习，让我们用一个具有Python风格的程序示例来说明我们通常如何在实践中实现这个目标。我们以一个从类中实例化的机器学习模型作为对象，如列表1.1所示。这个类对应于我们希望在模型中使用的特定类型的机器学习算法（一系列过程）。[¹](#pgfId-1011863)
    要实例化一个模型，除了选择要使用的算法类之外，我们还需要向算法提供一些历史数据和参数（arg1和arg2）。这里使用的历史数据包括手写数字的图像，其标签（对应的数字）已经已知。这有助于机器（或机器学习算法）进行学习过程——即学习如何识别图像中的数字，类似于如何训练一个孩子从图片中识别物体。（您将在后面的章节中看到这个过程的细节。）这里的参数用于控制算法，指导它如何进行这个过程。生成的机器学习模型将能够使用下一个列表中的第二行代码预测以前未见过的图像中的数字（见图1.1）。
- en: Listing 1.1 A simplified ML process
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.1 简化的机器学习过程
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Creates an ML model
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建机器学习模型
- en: ❷ Makes predictions with the ML model
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用机器学习模型进行预测
- en: 'As you can see from the code, besides the dataset, which we may need to prepare
    ourselves, we need to provide the following two things based on our prior knowledge
    to address the task:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从代码中看到的，除了我们可能需要自己准备的数据集之外，我们还需要根据我们的先验知识提供以下两个东西来处理任务：
- en: The ML algorithm (or method) to be used; that is, MachineLearningAlgorithm1
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要使用的机器学习算法（或方法）；即MachineLearningAlgorithm1
- en: The arguments of the algorithm
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法的参数
- en: Selecting the algorithm and configuring its arguments can be difficult in practice.
    Let’s use algorithm selection as an example. As a beginner, a typical approach
    is to collect some learning materials, explore the code for some related tasks,
    and identify a pool of ML algorithms you might be able to use for the task at
    hand. You can then try them out one by one on your historical data (as we do in
    listing 1.1) and pick the best one based on their performance at recognizing the
    digits in the images. This repetitive process is summarized in the next code sample.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，选择算法和配置其参数可能很困难。让我们以算法选择为例。作为一个初学者，典型的方法是收集一些学习资料，探索一些相关任务的代码，并确定一组您可能能够用于当前任务的机器学习算法。然后，您可以在您的历史数据上逐一尝试它们（正如我们在列表1.1中所做的那样），并根据它们在识别图像中的数字时的性能选择最佳的一个。这个重复的过程将在下一个代码示例中总结。
- en: Listing 1.2 A naive way of selecting ML algorithms
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.2 选择机器学习算法的简单方法
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ A pool of ML algorithms to be tested
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 要测试的机器学习算法池
- en: ❷ Loops over all the candidate ML algorithms
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 遍历所有候选的机器学习算法
- en: ❸ Instantiates and evaluates the ML model based on each ML algorithm
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 根据每个机器学习算法实例化和评估机器学习模型
- en: ❹ Selects the best ML model based on the performance
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 根据性能选择最佳机器学习模型
- en: The process looks intuitive but may take you hours or days if you do not have
    much ML knowledge or experience for a few reasons. First, collecting a pool of
    feasible ML algorithms could be challenging. You may need to explore the literature,
    identify the state-of-the-art algorithms, and learn how to implement them. Second,
    the number of feasible ML algorithms could be huge. Trying them out one by one
    may not be a good choice and may even be prohibitive. Third, each algorithm has
    its own arguments. Configuring them correctly requires expertise, experience,
    and even some luck.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程看起来直观，但如果您没有太多的机器学习知识或经验，可能需要花费数小时或数天。原因有以下几点。首先，收集一组可行的机器学习算法可能具有挑战性。您可能需要探索文献，识别最先进的算法，并学习如何实现它们。其次，可行的机器学习算法数量可能非常大。逐一尝试可能不是一个好的选择，甚至可能成为障碍。第三，每个算法都有自己的参数。正确配置它们需要专业知识、经验和甚至一些运气。
- en: 'Might there be a better way of doing this? Is it possible to let the machine
    perform automatically for you? If you have faced similar problems and want to
    adopt ML in a more labor-saving way, AutoML could be the tool you are looking
    for. Loosely speaking, AutoML mimics the manual process described in the preceding
    pseudocode. It tries to automate the repetitive and tedious process of selecting
    and configuring ML algorithms and can allow you access to many advanced algorithms
    without even knowing they exist. The following two lines of pseudocode illustrate
    how to use an AutoML algorithm to generate the ML solution:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 是否有更好的方法来做这件事？是否有可能让机器自动为你完成？如果你面临过类似的问题，并希望以更节省劳动力的方式采用机器学习（ML），AutoML 可能就是你要找的工具。简单来说，AutoML
    模仿了前面伪代码中描述的手动过程。它试图自动化选择和配置机器学习算法的重复和繁琐的过程，并可能让你访问许多高级算法，即使你不知道它们的存在。以下两行伪代码说明了如何使用
    AutoML 算法生成机器学习解决方案：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Creating an AutoML model object from an AutoML algorithm means you don’t even
    need to provide the pool of ML algorithms to test, and you can generate the desired
    model simply by feeding data into it.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 从 AutoML 算法创建一个 AutoML 模型对象意味着你甚至不需要提供要测试的机器学习算法池，你只需将数据输入其中，就可以生成所需的模型。
- en: But how do you select an AutoML algorithm? What are the ML algorithms it will
    choose from? How does it evaluate them and choose a model? Before going any further,
    I’ll give you some background on ML so you can better understand what AutoML automates
    and how to use it in practice to save yourself time and effort. The focus here
    will be on what you need to know to learn and use AutoML. If you want to learn
    more about these algorithms, I recommend referring to other ML books, such as
    *Machine Learning in Action* by Peter Harrington (Manning, 2012) and *Deep Learning
    with Python*, 2nd ed., by François Chollet (Manning, 2021). For readers who are
    already familiar with the basics of ML, this next section will serve as a recap,
    make sure we’re all on the same page with some terminology, and better motivate
    the following introduction to AutoML.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 但你如何选择一个 AutoML 算法？它将选择哪些机器学习算法？它是如何评估它们并选择一个模型的？在继续之前，我将给你一些关于机器学习的背景知识，这样你就能更好地理解
    AutoML 自动化的内容以及如何在实践中使用它来节省时间和精力。这里的重点将放在你需要了解的内容上，以便学习和使用 AutoML。如果你想了解更多关于这些算法的信息，我建议参考其他机器学习书籍，例如
    Peter Harrington 的《机器学习实战》（Manning, 2012）和 François Chollet 的《Python 深度学习》（2nd
    ed.，Manning, 2021）。对于已经熟悉机器学习基础知识的读者，下一节将作为一个复习，确保我们对一些术语有共同的理解，并为以下对 AutoML 的介绍提供更好的动机。
- en: 1.2 Getting started with machine learning
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 开始学习机器学习
- en: This section provides a brief introduction to ML—what it is, the critical components
    in an ML algorithm, and how an ML model is created based on a selected algorithm
    and data input. Learning these basics is essential to understanding the concepts
    of AutoML introduced in the next sections.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本节简要介绍了机器学习——它是什么，机器学习算法中的关键组件，以及如何根据选定的算法和数据输入创建机器学习模型。学习这些基础知识对于理解下一节中介绍的
    AutoML 概念至关重要。
- en: 1.2.1 What is machine learning?
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 什么是机器学习？
- en: Before the emergence of ML, the dominant paradigm in AI research was *symbolic
    AI*, where the computer could process data only based on predefined rules explicitly
    input by humans. The advent of ML revolutionized the programming paradigm by enabling
    knowledge to be learned from the data implicitly. For example, suppose you want
    a machine to recognize images of apples and bananas automatically. With symbolic
    AI, you would need to provide human-readable rules associated with the reasoning
    process, perhaps specifying features like color and shape, to the AI method. In
    contrast, an ML algorithm takes a bunch of images and their corresponding labels
    (“banana” or “apple”) and outputs the learned rules, which can be used to predict
    unlabeled images (see figure 1.2).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习出现之前，人工智能研究中的主导范式是**符号 AI**，计算机只能根据人类明确输入的预定义规则处理数据。机器学习的出现通过使知识能够从数据中隐式学习而革命性地改变了编程范式。例如，假设你希望机器能够自动识别苹果和香蕉的图像。在符号
    AI 中，你需要向 AI 方法提供与推理过程相关的人类可读规则，可能指定颜色和形状等特征。相比之下，机器学习算法接受一系列图像及其相应的标签（“香蕉”或“苹果”），并输出学习到的规则，这些规则可以用来预测未标记的图像（见图
    1.2）。
- en: '![01-02](../Images/01-02.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![01-02](../Images/01-02.png)'
- en: Figure 1.2 Comparison of symbolic AI and ML
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 符号 AI 和机器学习的比较
- en: The essential goals of ML are *automation* and *generalization*. Automation
    means an ML algorithm is trained on the data provided to automatically extract
    rules (or patterns) from the data. It mimics human thinking and allows the machine
    to improve itself by interacting with the historical data fed to it, which we
    call *training* or *learning*. The rules are then used to perform repetitive predictions
    on new data without human intervention. For example, in figure 1.2, the ML algorithm
    interacts with the apple and banana images provided and extracts a color rule
    that enables it to recognize them through the training process. These rules can
    help the machine classify new images without human supervision, which we call
    *generalizing* to new data. The ability to generalize is an important criterion
    in evaluating whether an ML algorithm is good. In this case, suppose an image
    of a yellow apple is fed to the ML algorithm—the color rule will not enable it
    to correctly discern whether it’s an apple or a banana. An ML algorithm that learns
    and applies a shape feature for prediction may provide better predictions.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的基本目标是*自动化*和*泛化*。自动化意味着ML算法在提供的数据上训练，以自动从数据中提取规则（或模式）。它模仿人类思维，并允许机器通过与提供给它的历史数据进行交互来提高自身，这我们称之为*训练*或*学习*。这些规则随后被用来在新数据上执行重复的预测，而不需要人为干预。例如，在图1.2中，ML算法与提供的苹果和香蕉图像进行交互，并在训练过程中提取一个颜色规则，使其能够通过训练过程识别它们。这些规则可以帮助机器在没有人类监督的情况下对新图像进行分类，这我们称之为对*新数据*的*泛化*。泛化的能力是评估ML算法好坏的重要标准。在这种情况下，假设一个黄色苹果的图像被输入到ML算法中——颜色规则将无法使其正确判断它是苹果还是香蕉。一个学习并应用形状特征进行预测的ML算法可能会提供更好的预测。
- en: 1.2.2 The machine learning process
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 机器学习过程
- en: 'An ML algorithm learns rules through exposure to examples with known outputs.
    The rules are expected to enable it to transform inputs into meaningful outputs,
    such as transforming images of handwritten digits to the corresponding numbers.
    So, the goal of learning can also be thought of as enabling *data transformation*.
    The learning process generally requires the following two components:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ML算法通过接触具有已知输出的示例来学习规则。这些规则预期能够使它将输入转换为有意义的输出，例如将手写数字的图像转换为相应的数字。因此，学习的目标也可以被视为使*数据转换*成为可能。学习过程通常需要以下两个组件：
- en: '*Data inputs*—Data instances of the target task to be fed into the ML algorithm,
    for example, in the image recognition problem (see figure 1.2), a set of apple
    and banana images and their corresponding labels'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据输入*——要输入到ML算法中的目标任务的实例数据，例如，在图像识别问题中（见图1.2），一组苹果和香蕉图像及其相应的标签'
- en: '*Learning algorithm*—A mathematical procedure to derive a model based on the
    data inputs, which contains the following four elements:'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习算法*——一种基于数据输入推导模型的数学过程，它包含以下四个要素：'
- en: An ML model with a set of *parameters* to be learned from the data
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个具有从数据中学习的一组*参数*的ML模型
- en: A *measurement* to measure the model’s performance (such as prediction accuracy)
    with the current parameters
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种测量模型性能（如预测准确度）的*测量*方法，使用当前参数
- en: A way to update the model, which we call an *optimization method*
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种更新模型的方法，我们称之为*优化方法*
- en: A *stop criterion* to determine when the learning process should stop
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个*停止标准*，以确定学习过程何时应该停止
- en: After the model parameters are intialized,[²](#pgfId-1012748) the learning algorithm
    can update the model iteratively by modifying the parameters based on the measurement
    until the stop criterion is reached. This measurement is called a *loss function*
    (or *objective function*) in the training phase; it measures the difference between
    the model’s predictions and the ground-truth targets. This process is illustrated
    in figure 1.3.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型参数初始化后，[²](#pgfId-1012748) 学习算法可以通过根据测量结果迭代地修改参数来更新模型，直到达到停止标准。这个测量结果被称为训练阶段的*损失函数*（或*目标函数*），它衡量模型预测与真实目标之间的差异。这个过程如图1.3所示。
- en: '![01-03](../Images/01-03.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![01-03](../Images/01-03.png)'
- en: Figure 1.3 The process of training an ML model
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 训练ML模型的过程
- en: 'Let’s look at an example to help you better understand the learning process.
    Imagine we have a bunch of data points in two-dimensional space (see figure 1.4).
    Each point is either black or white. We want to build an ML model that, whenever
    a new point arrives, can decide whether this is a black point or a white point
    based on the point’s position. A straightforward way to achieve this goal is to
    draw a horizontal line to separate the two-dimensional space into two parts based
    on the data points in hand. This line could be regarded as an ML model. Its parameter
    is the horizontal position, which can be updated and learned from the provided
    data points. Coupled with the learning process introduced in figure 1.3, the required
    components could be chosen and summarized as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来帮助你更好地理解学习过程。想象一下，我们有一组在二维空间中的数据点（见图1.4）。每个点要么是黑色，要么是白色。我们希望构建一个机器学习模型，每当有一个新的点到来时，可以根据点的位置判断这个点是黑色还是白色。实现这个目标的一个直接方法是根据手头的数据点在二维空间中绘制一条水平线，将其分割成两部分。这条线可以被视为一个机器学习模型。其参数是水平位置，可以通过提供的数据点进行更新和学习。结合图1.3中介绍的学习过程，所需组件可以总结如下：
- en: The data inputs are a bunch of white and black points described by their location
    in the two-dimensional space.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据输入是一组由它们在二维空间中的位置描述的黑白点。
- en: 'The learning algorithm consists of the following four selected components:'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习算法由以下四个选定的组件组成：
- en: '*ML model*—A horizontal line that can be formulated as *y = a*, where *a* is
    the parameter that can be updated by the algorithm.'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习模型*——一条可以表示为 *y = a* 的水平线，其中 *a* 是可以通过算法更新的参数。'
- en: '*Accuracy measurement*—The percentage of points that are labeled correctly
    based on the model.'
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*准确度测量*——根据模型正确标记的点所占的百分比。'
- en: '*Optimization method*—Move the line up or down by a certain distance. The distance
    can be related to the value of the measurement in each iteration. It will not
    stop until the stop criterion is satisfied.'
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*优化方法*——通过一定的距离上下移动线。这个距离可以与每次迭代的测量值相关。它将一直移动，直到满足停止标准。'
- en: '*Stop criterion*—Stop when the measurement is 100%, which means all the points
    in hand are labeled correctly based on the current line.'
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*停止标准*——当测量值为100%时停止，这意味着所有手头的点都根据当前线被正确标记。'
- en: '![01-04](../Images/01-04.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![01-04](../Images/01-04.png)'
- en: 'Figure 1.4 An example of the learning process: Learning a horizontal line to
    split white and black points'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 学习过程的一个示例：学习一条水平线来分割黑白点
- en: In the example shown in figure 1.4, the learning algorithm takes two iterations
    to achieve the desired line, which separates all the input points correctly. But
    in practice, this criterion may not always be satisfied. It depends on the distribution
    of the input data, the selected model type, and how the model is measured and
    updated. We often need to choose different components and try different combinations
    to adjust the learning process to get the expected ML solution. Also, even if
    the learned model is able to label all the training inputs correctly, it is not
    guaranteed to work well on unseen data. In other words, the model’s ability to
    generalize may not be good (we’ll discuss this further in the next section). It’s
    important to select the components and adjust the learning process carefully.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在图1.4所示的例子中，学习算法经过两次迭代就达到了期望的线，这条线正确地分割了所有输入点。但在实际应用中，这个标准可能并不总是满足。它取决于输入数据的分布、选定的模型类型以及模型是如何被测量和更新的。我们通常需要选择不同的组件并尝试不同的组合来调整学习过程，以获得预期的机器学习解决方案。此外，即使学习到的模型能够正确标记所有训练输入，也不能保证它在未见过的数据上表现良好。换句话说，模型泛化能力可能不佳（我们将在下一节中进一步讨论这个问题）。仔细选择组件和调整学习过程非常重要。
- en: 1.2.3 Hyperparameter tuning
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 超参数调整
- en: 'How do we select the proper components to adjust the learning process so that
    we can derive the expected model? To answer this question, we need to introduce
    a concept called *hyperparameters* and clarify the relationship between these
    and the parameters we’ve been discussing as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何选择合适的组件来调整学习过程，以便我们能够推导出预期的模型？为了回答这个问题，我们需要介绍一个称为 *超参数* 的概念，并阐明这些参数与我们之前讨论的参数之间的关系如下：
- en: '*Parameters* are variables that can be updated by the ML algorithm during the
    learning process. They are used to capture the rules from the data. For example,
    the position of the horizontal line is the only parameter in our previous example
    (figure 1.4) to help classify the points. It is adjusted during the training process
    by the optimization method to capture the position rule for splitting the points
    with different colors. By adjusting the parameters, we can derive an ML model
    that can accurately predict the outputs of the given input data.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*参数*是机器学习算法在学习过程中可以更新的变量。它们用于捕捉数据中的规则。例如，水平线的位置是我们之前示例（图1.4）中唯一的参数，用于帮助分类点。它通过优化方法在训练过程中进行调整，以捕捉分割不同颜色点的位置规则。通过调整参数，我们可以得到一个可以准确预测给定输入数据输出的机器学习模型。'
- en: '*Hyperparameters* are also parameters, but they’re ones we predefine for the
    algorithm before the learning process begins, and their values remain fixed during
    the learning process. These include the measurement, the optimization method,
    the speed of learning, the stop criterion, and so on. An ML algorithm usually
    has multiple hyperparameters. Different combinations of them have different effects
    on the learning process, resulting in ML models with different performances. We
    can also consider the algorithm type (or the ML model type) as a hyperparameter,
    because we select it ourselves, and it is fixed during the learning process.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*超参数*也是参数，但它们是在学习过程开始之前我们为算法预先定义的，并且在学习过程中它们的值保持固定。这些包括测量、优化方法、学习速度、停止标准等等。一个机器学习算法通常有多个超参数。它们的不同组合对学习过程有不同的影响，从而产生具有不同性能的机器学习模型。我们也可以将算法类型（或机器学习模型类型）视为超参数，因为我们自己选择它，并且在学习过程中它是固定的。'
- en: The selection of an optimal combination of hyperparameters for an ML algorithm
    is called *hyperparameter tuning* and is often done through an iterative process.
    In each iteration, we select a set of hyperparameters to use to learn an ML model
    with the training dataset. The ML algorithm block in figure 1.5 denotes the learning
    process described in figure 1.3\. By evaluating each learned model on a separate
    dataset called the *validation set*, we can then pick the best one as the final
    model. We can evaluate the generalizability of that model using another dataset
    called the *test set*, which concludes the whole ML workflow.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为机器学习算法选择最佳超参数组合的过程称为*超参数调整*，通常通过迭代过程来完成。在每次迭代中，我们选择一组超参数来使用，以便使用训练数据集学习一个机器学习模型。图1.5中的机器学习算法块表示图1.3中描述的学习过程。通过在称为*验证集*的单独数据集上评估每个学习到的模型，然后我们可以选择最好的一个作为最终模型。我们可以使用另一个称为*测试集*的数据集来评估该模型的泛化能力，这标志着整个机器学习工作流程的结束。
- en: '![01-05](../Images/01-05.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![01-05](../Images/01-05.png)'
- en: Figure 1.5 The classic ML workflow
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 经典机器学习工作流程
- en: 'In general, we will have three datasets in the ML workflow. Each dataset is
    distinct from the other two, as described next:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在机器学习工作流程中，我们将有三个数据集。每个数据集与其他两个都不同，如下所述：
- en: The training set is used during the learning process to train a model given
    a fixed combination of hyperparameters.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集在学习过程中用于使用固定的超参数组合训练模型。
- en: The validation set is used during the tuning process to evaluate the trained
    models to select the best hyperparameters.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证集在调整过程中用于评估训练模型以选择最佳超参数。
- en: The test set is used for the final testing, after the tuning process. It is
    used only once, after the final model is selected, and should not be used for
    training or tuning the ML algorithm.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集在调整过程之后用于最终测试。它只在最终模型选定后使用一次，不应用于训练或调整机器学习算法。
- en: 'The training and test sets are straightforward to understand. The reason we
    want to have an additional validation dataset is to avoid exposing the algorithm
    to all the training data during the tuning stages—this enhances the generalizability
    of the final model to unseen data. If we don’t have a validation set, the best
    model selected in the tuning stage would be the one that focuses on extracting
    any subtle features in the training data to ceaselessly increase the training
    accuracy without caring about any unseen dataset. This situation will likely lead
    to bad performance on the final test set, which contains different data. When
    the model performs worse on the test set (or validation set) than the training
    set, this is called *overfitting*. It’s a well-known problem in ML and often happens
    when the model’s learning capacity is too strong and the size of the training
    dataset is limited. For example, suppose you want to predict the fourth number
    of a series, given the first three numbers as training data: *a*[1] = 1, *a*[2]
    = 2, *a*[3] = 3, *a*[4] = ? (*a*[4] is the validation set here; *a*[5] onward
    are the test sets.) If the right solution is *a*[4] = 4, a naive model, *a[i]*
    = *i*, would provide the correct answer. If you use a third-degree polynomial
    to fit the series, a perfect solution for the training data would be *a[i]* =
    *i*³ - 6*i*² + 12*i* - 6, which will predict *a*[4] as 10\. The validation process
    enables a model’s generalization ability to be better reflected during evaluation
    so that better models can be selected.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 训练集和测试集的理解相对简单。我们想要有一个额外的验证数据集的原因是避免在调整阶段将算法暴露于所有训练数据中——这增强了最终模型对未见数据的泛化能力。如果我们没有验证集，调整阶段选出的最佳模型将是专注于从训练数据中提取任何细微特征以不断增加训练准确率，而不关心任何未见数据集的模型。这种情况很可能会导致最终测试集（包含不同的数据）表现不佳。当模型在测试集（或验证集）上的表现不如训练集时，这被称为*过拟合*。这是机器学习中一个众所周知的问题，通常发生在模型的学习能力太强且训练数据集规模有限的情况下。例如，假设你想要根据前三个数字作为训练数据来预测一个数列的第四个数：*a*[1]
    = 1, *a*[2] = 2, *a*[3] = 3, *a*[4] = ? (*a*[4]在这里是验证集；*a*[5]及以后的是测试集。)如果正确的解是*a*[4]
    = 4，一个简单的模型*a[i]* = *i*会给出正确答案。如果你使用三次多项式来拟合这个数列，一个完美的训练数据解将是*a[i]* = *i*³ - 6*i*²
    + 12*i* - 6，这将预测*a*[4]为10。验证过程使得模型在评估期间能够更好地反映其泛化能力，从而选择出更好的模型。
- en: Note Overfitting is one of the most important problems studied in ML. Besides
    doing validation during the tuning process, we have many other ways to address
    the problem, such as augmenting the dataset, adding regularization to the model
    to constrain its learning capacity during training, and so on. We won’t go into
    this in more depth here. To learn more about this topic, see Chollet’s *Deep Learning
    with Python*.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：过拟合是机器学习中研究的重要问题之一。除了在调整过程中进行验证之外，我们还有许多其他方法来解决这个问题，例如增加数据集、在训练过程中向模型添加正则化以约束其学习能力，等等。我们在这里不会深入探讨这个问题。要了解更多关于这个主题的信息，请参阅Chollet的《用Python进行深度学习》。
- en: 1.2.4 The obstacles to applying machine learning
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.4 应用机器学习的障碍
- en: 'At this point, you should have a basic understanding of what ML is and how
    it proceeds. Although you can make use of many mature ML toolkits, you may still
    face difficulties in practice. This section describes some of these challenges—the
    aim is not to scare you off, but to provide context for the AutoML techniques
    that are described afterward. Obstacles you may meet include the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你应该对机器学习（ML）是什么以及它是如何进行的有一个基本的了解。尽管你可以利用许多成熟的机器学习工具包，但在实践中你仍然可能会遇到困难。本节描述了其中的一些挑战——目的不是让你望而却步，而是为随后描述的自动化机器学习（AutoML）技术提供背景。你可能会遇到的障碍包括以下内容：
- en: '*The cost of learning ML techniques*—We’ve covered the basics, but more knowledge
    is required when applying ML to a real problem. For example, you’ll need to think
    about how to formulate your problem as an ML problem, which ML algorithms you
    could use for your problem and how they work, how to clean and preprocess the
    data into the expected format to input into your ML algorithm, which evaluation
    criteria should be selected for model training and hyperparameter tuning, and
    so on. All these questions need to be answered in advance, and doing so may require
    a large time commitment.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习机器学习技术的成本*——我们已经介绍了基础知识，但在将机器学习应用于实际问题时，还需要更多的知识。例如，你需要考虑如何将你的问题表述为机器学习问题，你可以为你的问题使用哪些机器学习算法以及它们是如何工作的，如何清理和预处理数据以符合输入机器学习算法的预期格式，应该选择哪些评估标准用于模型训练和超参数调整，等等。所有这些问题都需要提前回答，这样做可能需要大量的时间投入。'
- en: '*Implementation complexity*—Even with the necessary knowledge and experience,
    implementing the workflow after selecting an ML algorithm is a complex task. The
    time required for implementation and debugging will grow as more advanced algorithms
    are adopted.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实施复杂性*—即使拥有必要的知识和经验，在选定机器学习算法后实施工作流程也是一个复杂任务。随着更高级算法的采用，实施和调试所需的时间将会增加。'
- en: '*The gap between theory and practice*—The learning process can be hard to interpret,
    and the performance is highly data driven. Furthermore, the datasets used in ML
    are often complex and noisy and can be difficult to interpret, clean, and control.
    This means the tuning process is often more empirical than analytical. Even ML
    experts sometimes cannot achieve the desired results.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*理论与实践之间的差距*—学习过程可能难以解释，性能高度依赖于数据。此外，机器学习中使用的数据集通常复杂且噪声大，难以解释、清理和控制。这意味着调整过程通常比分析过程更经验性。即使是机器学习专家有时也无法达到预期的结果。'
- en: These difficulties significantly impede the democratization of ML to people
    with limited experience and correspondingly increase the burden on ML experts.
    This has motivated ML researchers and practitioners to pursue a solution to lower
    the barriers, circumvent the unnecessary procedures, and alleviate the burden
    of manual algorithm design and tuning—AutoML.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些困难在很大程度上阻碍了机器学习向经验有限的人的普及，并相应地增加了机器学习专家的负担。这促使机器学习研究人员和实践者寻求降低障碍、规避不必要的程序、减轻手动算法设计和调整负担的解决方案——AutoML。
- en: '1.3 AutoML: The automation of automation'
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 AutoML：自动化的自动化
- en: The goal of AutoML is to allow a machine to mimic how humans design, tune, and
    apply ML algorithms so that we can adopt ML more easily (see figure 1.6). Because
    a key property of ML is automation, AutoML can be regarded as automating automation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML的目标是让机器模仿人类如何设计、调整和应用机器学习算法，以便我们更容易地采用机器学习（见图1.6）。因为机器学习的一个关键特性是自动化，所以AutoML可以被视为自动化的自动化。
- en: '![01-06](../Images/01-06.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![01-06](../Images/01-06.png)'
- en: 'Figure 1.6 The main goal of AutoML: taking humans out of the loop of ML algorithm
    design and tuning'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 AutoML的主要目标：将人类从机器学习算法设计和调整的循环中解放出来
- en: To help you understand how AutoML works, let’s first go over the key components.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您理解AutoML是如何工作的，让我们首先回顾其关键组件。
- en: 1.3.1 Three key components of AutoML
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 AutoML的三个关键组件
- en: 'Here’s a recap of the pseudocode introduced in section 1.1:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是对第1.1节中引入的伪代码的回顾：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This pseudocode can be regarded as a simple AutoML algorithm that takes a pool
    of ML algorithms as input, evaluates them one by one, and outputs a model learned
    from the best algorithm. Each AutoML algorithm consists of the following three
    core components (see figure 1.7):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这段伪代码可以被视为一个简单的自动化机器学习（AutoML）算法，它接受一组机器学习算法作为输入，逐一评估它们，并输出从最佳算法中学习到的模型。每个AutoML算法都包含以下三个核心组件（见图1.7）：
- en: '*Search space*—A set of hyperparameters, and the ranges of each hyperparameter
    from which to select. The range of each hyperparameter can be defined based on
    the user’s requirements and knowledge. For example, the search space can be a
    pool of ML algorithms, as shown in the pseudocode. In this case, we treat the
    type of ML algorithm as a hyperparameter to be selected. The search space can
    also be the hyperparameters of a specific ML algorithm, such as the structure
    of the ML model. The design of the search space is highly task-dependent, because
    we may need to adopt different ML algorithms for various tasks. It is also quite
    personalized and ad hoc, depending on the user’s interests, expertise, and level
    of experience. There is always a tradeoff between the convenience you’ll enjoy
    by defining a large search space and the time you’ll spend identifying a good
    model (or the performance of the model you can achieve in a limited amount of
    time). For beginners, it can be tempting to define a broad search space that is
    general enough to apply to any task or situation, such as a search space containing
    all the ML algorithms—but the time and computational cost involved make this a
    poor solution. We’ll discuss these considerations more in the second part of the
    book, where you’ll learn how to customize your search space in different scenarios
    based on additional requirements.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*搜索空间*—一组超参数，以及从中选择的每个超参数的范围。每个超参数的范围可以根据用户的需求和知识来定义。例如，搜索空间可以是一个机器学习算法的集合，如伪代码所示。在这种情况下，我们将机器学习算法的类型视为需要选择的超参数。搜索空间也可以是特定机器学习算法的超参数，例如机器学习模型的结构。搜索空间的设计高度依赖于任务，因为我们可能需要为不同的任务采用不同的机器学习算法。它也非常个性化且具有针对性，取决于用户的兴趣、专业知识和经验水平。在定义一个大的搜索空间带来的便利性和花费在识别一个好的模型（或在一个有限的时间内可以达到的模型性能）之间的权衡总是存在的。对于初学者来说，定义一个足够通用以适用于任何任务或情况的广泛搜索空间可能会很有吸引力，例如包含所有机器学习算法的搜索空间——但所涉及的时间和计算成本使得这成为一个较差的解决方案。我们将在本书的第二部分更详细地讨论这些考虑因素，其中你将学习如何根据额外的要求在不同的场景中自定义你的搜索空间。'
- en: '*Search strategy*—A strategy to select the optimal set of hyperparameters from
    the search space. Because AutoML is often an iterative trial-and-error process,
    the strategy often sequentially selects the hyperparameters in the search space
    and evaluates their performance. It may loop through all the hyperparameters in
    the search space (as in the pseudocode), or the search strategy may be adapted
    based on the hyperparameters that have been evaluated so far to increase the efficiency
    of the later trials. A better search strategy can help you achieve a better ML
    solution within the same amount of time. It may also allow you to use a larger
    search space by reducing the search time and computational cost. How to adopt,
    compare, and implement different search algorithms will be introduced in the third
    part of the book.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*搜索策略*—从搜索空间中选择最佳超参数集的策略。由于AutoML通常是一个迭代试错的过程，该策略通常按顺序选择搜索空间中的超参数并评估其性能。它可能遍历搜索空间中的所有超参数（如伪代码所示），或者根据迄今为止已评估的超参数调整搜索策略，以提高后续试验的效率。一个更好的搜索策略可以帮助你在相同的时间内实现更好的机器学习解决方案。它还可能通过减少搜索时间和计算成本，允许你使用更大的搜索空间。本书的第三部分将介绍如何采用、比较和实现不同的搜索算法。'
- en: '*Performance evaluation strategy*—A way to evaluate the performance of a specific
    ML algorithm instantiated by the selected hyperparameters. The evaluation criteria
    are often the same as the ones used in manual tuning, such as the validation performance
    of the model learned from the selected ML algorithm. In this book, we discuss
    different evaluation strategies in the context of adopting AutoML to solve different
    types of ML tasks.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*性能评估策略*—评估由所选超参数实例化的特定机器学习算法性能的方法。评估标准通常与手动调优中使用的相同，例如从所选机器学习算法中学习到的模型的验证性能。在本书中，我们讨论了在采用AutoML解决不同类型的机器学习任务时采用的不同评估策略。'
- en: '![01-07](../Images/01-07.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![01-07](../Images/01-07.png)'
- en: Figure 1.7 The AutoML process
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 AutoML过程
- en: 'To facilitate the adoption of AutoML algorithms, an AutoML toolkit often wraps
    up these three components and provides some general application programming interfaces
    (APIs) with a default search space and search algorithm so that you don’t need
    to worry about selecting them yourself. For end users, in the simplest case, all
    you need to do to obtain the final model is provide the data, as shown here—you
    don’t even need to split the data into training and validation sets:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进AutoML算法的采用，AutoML工具包通常将这三个组件打包在一起，并提供一些具有默认搜索空间和搜索算法的通用应用程序编程接口（API），这样您就不必担心自己选择它们。对于最终用户来说，在最简单的情况下，您要获得最终模型所需做的只是提供数据，如这里所示——您甚至不需要将数据分成训练集和验证集：
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: But because different users may have different use cases and levels of ML expertise,
    they may need to design their own search spaces, evaluation strategies, and even
    search strategies. Existing AutoML systems, therefore, often also provide APIs
    with configurable arguments to allow you to customize different components. A
    broad spectrum of solutions are available, from the simplest to the most configurable
    (figure 1.8).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 但由于不同用户可能有不同的用例和机器学习专业知识水平，他们可能需要设计自己的搜索空间、评估策略，甚至搜索策略。因此，现有的AutoML系统通常也提供具有可配置参数的API，以便您可以根据需要自定义不同的组件。从最简单的到最可配置的（图1.8），提供了广泛的选择。
- en: '![01-08](../Images/01-08.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![01-08](../Images/01-08.png)'
- en: Figure 1.8 The spectrum of AutoML APIs
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8 AutoML API的范围
- en: The range of APIs available allows you to pick the most suitable one for your
    use case. This book will teach you how to select the right API in an advanced
    AutoML toolkit, *AutoKeras*, for different AutoML applications. You’ll also learn
    how to create your own AutoML algorithm with the help of KerasTuner.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的API范围允许您选择最适合您用例的一个。本书将教会您如何在一个高级AutoML工具包*AutoKeras*中为不同的AutoML应用选择正确的API。您还将学习如何借助KerasTuner创建自己的AutoML算法。
- en: 1.3.2 Are we able to achieve full automation?
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.2 我们能否实现完全自动化？
- en: 'The field of AutoML has been evolving for three decades, with the involvement
    of industry and the open source community. Many successful implementations and
    promising developments have been seen, as described here:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML领域已经发展了三十年，有行业和开源社区的参与。已经看到了许多成功的实施和有希望的发展，如这里所述：
- en: Many company internal tools and open source platforms have been developed to
    help with hyperparameter tuning of ML models and model selection (Google Vizier,
    Facebook Ax, and so on).
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多公司内部工具和开源平台已被开发出来，以帮助进行机器学习模型的超参数调整和模型选择（例如Google Vizier、Facebook Ax等）。
- en: AutoML solutions performing at near human levels have been observed in many
    Kaggle data science competitions.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在许多Kaggle数据科学竞赛中，观察到执行接近人类水平的AutoML解决方案。
- en: Vast open source ML packages for improved hyperparameter tuning and ML pipeline
    creation have been developed, such as Auto-sklearn, AutoKeras, and so on.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已经开发了大量的开源机器学习包，用于改进超参数调整和机器学习管道创建，例如Auto-sklearn、AutoKeras等。
- en: Commercial AutoML products are helping many companies, big and small, to adopt
    ML in production. For example, Disney has successfully used Google Cloud AutoML
    to develop ML solutions for its online store without hiring a team of ML engineers
    ([https://blog.google/products/google-cloud/cloud-automl-making-ai-accessible-every-business/](https://blog.google/products/google-cloud/cloud-automl-making-ai-accessible-every-business/)).
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商业AutoML产品正在帮助许多公司，无论大小，在生产中采用机器学习。例如，迪士尼成功使用了Google Cloud AutoML为其在线商店开发机器学习解决方案，而没有雇佣一支机器学习工程师团队（[https://blog.google/products/google-cloud/cloud-automl-making-ai-accessible-every-business/](https://blog.google/products/google-cloud/cloud-automl-making-ai-accessible-every-business/))。
- en: Researchers in fields other than computer science, such as medicine, neurobiology,
    and economics, are also leveraging the power of AutoML. They can now bring new
    ML solutions to domain-specific problems such as medical image segmentation,[³](#pgfId-1019374)
    genomic research,[⁴](#pgfId-1019396) and animal recognition and protection,[⁵](#pgfId-1019409)
    without going through the long learning curve of ML and programming.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机科学以外的领域的学者，如医学、神经生物学和经济学，也在利用AutoML的力量。他们现在可以将新的机器学习解决方案应用于特定领域的问题，如医学图像分割[³](#pgfId-1019374)、基因组研究[⁴](#pgfId-1019396)和动物识别与保护[⁵](#pgfId-1019409)，而无需经历机器学习和编程的漫长学习曲线。
- en: 'We are still exploring the full capabilities of AutoML to democratize ML techniques
    and make them accessible to more people in different domains. Despite the many
    successful applications of AutoML that have been seen so far, we still have a
    lot of challenges and limitations to further explore and address, including the
    following:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍在探索AutoML的全部功能，以民主化机器学习技术，使不同领域更多的人能够访问。尽管到目前为止已经看到了许多AutoML的成功应用，但我们仍然有许多挑战和限制需要进一步探索和解决，包括以下内容：
- en: '*The difficulty of building AutoML systems*—Compared to building an ML system,
    building an AutoML system from scratch is a more complex and involved process.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*构建AutoML系统的难度*——与构建机器学习系统相比，从头开始构建AutoML系统是一个更复杂且涉及更多的过程。'
- en: '*The automation of collecting and cleaning data*—AutoML still requires people
    to collect, clean, and label data. These processes are often more complicated
    in practice than the design of ML algorithms, and, for now at least, they cannot
    be automated by AutoML. For AutoML to work today, it has to be given a clear task
    and objective with a high-quality dataset.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*收集和清理数据的自动化*——AutoML仍然需要人们来收集、清理和标记数据。在实践中，这些过程通常比机器学习算法的设计更复杂，至少到目前为止，它们不能通过AutoML自动化。为了使AutoML今天能够工作，它必须被赋予一个明确的任务和目标，并使用高质量的数据库。'
- en: '*The costs of selecting and tuning the AutoML algorithm*—The “no free lunch”
    theorem tells us that there is no omnipotent AutoML algorithm that fits any hyperparameter
    tuning problem. The effort you save on selecting and tuning an ML algorithm may
    be amortized or even outweighed by the effort you need to put into selecting and
    tuning the AutoML algorthm.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*选择和调整AutoML算法的成本*——“没有免费午餐”定理告诉我们，没有一种万能的AutoML算法可以适用于任何超参数调整问题。你在选择和调整机器学习算法上节省的努力可能会被分摊，甚至可能被选择和调整AutoML算法所需付出的努力所超过。'
- en: '*Resource costs*—AutoML is a relatively costly process, in terms of both time
    and computational resources. Existing AutoML systems often need to try more hyperparameters
    than human experts to achieve comparable results.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*资源成本*——从时间和计算资源的角度来看，AutoML是一个相对昂贵的流程。现有的AutoML系统通常需要尝试比人类专家更多的超参数才能达到可比的结果。'
- en: '*The cost of human-computer interaction*—Interpreting the solution and the
    tuning process of AutoML may not be easy. As these systems become more complex,
    it will become harder and harder for humans to get involved in the tuning process
    and understand how the final model is achieved.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人机交互的成本*——解释AutoML的解决方案和调整过程可能并不容易。随着这些系统变得更加复杂，人类参与调整过程和理解最终模型是如何实现的将变得越来越困难。'
- en: AutoML is still in its early stages of development, and its continuing progress
    will rely heavily on the participation of researchers, developers, and practitioners
    from different domains. Although you may contribute to that effort one day, the
    goal of this book is more modest. It mainly targets practitioners who have limited
    expertise in machine learning, or who have some experience but want to save themselves
    some effort in creating ML solutions. The book will teach you how to address an
    ML problem automatically with as few as five lines of code. It will gradually
    approach more sophisticated AutoML solutions for more complicated scenarios and
    data types, such as images, text, and so on. To get you started, in the next chapter,
    we’ll dig more deeply into the fundamentals of ML and explore the end-to-end pipeline
    of an ML project. It will help you better understand and make use of AutoML techniques
    in the later chapters.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML仍处于发展的早期阶段，其持续进步将严重依赖于来自不同领域的学者、开发者和实践者的参与。尽管你有一天可能会为这一努力做出贡献，但本书的目标更为谦逊。它主要针对那些在机器学习方面专业知识有限，或者有一定经验但希望节省在创建机器学习解决方案上所花费的努力的从业者。本书将教你如何用不超过五行代码自动解决机器学习问题。它将逐步介绍更复杂的AutoML解决方案，适用于更复杂的情况和数据类型，例如图像、文本等。为了帮助你入门，在下一章中，我们将更深入地探讨机器学习的根本原理，并探索机器学习项目的端到端流程。这将有助于你在后续章节中更好地理解和利用AutoML技术。
- en: Summary
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Machine learning refers to the capacity of a computer to modify its processing
    by interacting with data automatically, without being explicitly programmed.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习是指计算机通过自动与数据交互来修改其处理过程的能力，而不需要被明确编程。
- en: The ML process can be described as an iterative algorithmic process to adjust
    the parameters of an ML model based on the data inputs and certain measurements.
    It stops when the model is able to provide the expected outputs, or when some
    particular criterion defined by the user is reached.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习过程可以描述为一个迭代算法过程，根据数据输入和某些测量来调整机器学习模型的参数。当模型能够提供预期的输出，或者达到用户定义的某些特定标准时，这个过程停止。
- en: Tuning the hyperparameters in an ML algorithm allows you to adjust the learning
    process and select components tailored to the ML problem at hand.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整机器学习算法中的超参数允许你调整学习过程，并选择适合当前机器学习问题的组件。
- en: AutoML aims to learn from the experience of designing and applying ML models
    and automate the tuning process, thereby relieving data scientists of this burden
    and making off-the-shelf ML techniques accessible to practitioners without extensive
    experience.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML旨在从设计和应用机器学习模型的经验中学习，并自动化调整过程，从而减轻数据科学家的负担，并使没有丰富经验的专业人士能够使用现成的机器学习技术。
- en: 'An AutoML algorithm consists of three key components: the search space, search
    strategy, and evaluation strategy. Different AutoML systems provide different
    levels of APIs that either configure these for you or allow you to customize them
    based on your use case.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个AutoML算法由三个关键组件组成：搜索空间、搜索策略和评估策略。不同的AutoML系统提供不同级别的API，这些API要么为你配置这些组件，要么允许你根据你的用例自定义它们。
- en: AutoML contains many unaddressed challenges, preventing it from living up to
    the highest expectations. Achieving true automatic machine learning will be difficult.
    We should be optimistic but also take care to avoid exaggerating AutoML’s current
    capabilities.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML包含许多未解决的问题，阻碍了它达到最高的期望。实现真正的自动机器学习将是困难的。我们应该保持乐观，但也要注意避免夸大AutoML当前的能力。
- en: '* * *'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: ^(1.) Many well-known ML packages provide these kinds of classes corresponding
    to ML algorithms, such as scikit-learn.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: (1.) 许多知名的机器学习包提供了对应于机器学习算法的这些类，例如scikit-learn。
- en: ^(2.) The parameter values may be intialized randomly or assigned following
    a strategy such as a warm start, where you begin with some existing parameters
    learned by similar models.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: (2.) 参数值可能随机初始化，或者按照某种策略分配，例如使用预热启动，在这种情况下，你从一些由类似模型学习到的现有参数开始。
- en: '^(3.) Weng, Yu, et al., “NAS-Unet: Neural Architecture Search for Medical Image
    Segmentation,” *IEEE Access* 7 (2019): 44247-44257.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '(3.) 汪宇，等，“NAS-Unet：用于医学图像分割的神经架构搜索”，*IEEE Access* 7 (2019): 44247-44257。'
- en: '^(4.) Liu, Denghui, et al., “AutoGenome: An AutoML Tool for Genomic Research,”
    bioRxiv (2019): 842526.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '(4.) 刘登辉，等，“AutoGenome：基因组研究的AutoML工具”，bioRxiv (2019): 842526。'
- en: '^(5.) Liu, Yao, and Ze Luo, “Species Recognition of Protected Area Based on
    AutoML,” *Computer Systems and Applications* 28 (2019): 147-153.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '(5.) 刘尧，罗泽，等，“基于AutoML的保护区物种识别”，*计算机系统与应用* 28 (2019): 147-153。'
