- en: Chapter 19\. Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第19章。分类
- en: 'This chapter continues our foray into the fourth stage of the data science
    lifecycle: fitting and evaluating models to understand the world. So far, we’ve
    described how to fit a constant model using absolute error ([Chapter 4](ch04.html#ch-modeling))
    and simple and multiple linear models using squared error ([Chapter 15](ch15.html#ch-linear)).
    We’ve also fit linear models with an asymmetric loss function ([Chapter 18](ch18.html#ch-donkey))
    and with regularized loss ([Chapter 16](ch16.html#ch-risk)). In all of these cases,
    we aimed to predict or explain the behavior of a numeric outcome—bus wait times,
    smoke particles in the air, and donkey weights are all numeric variables.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章继续探讨数据科学生命周期的第四阶段：拟合和评估模型以理解世界。到目前为止，我们已经描述了如何使用绝对误差拟合常数模型（[第四章](ch04.html#ch-modeling)）以及使用平方误差拟合简单和多元线性模型（[第十五章](ch15.html#ch-linear)）。我们还拟合了带有不对称损失函数的线性模型（[第十八章](ch18.html#ch-donkey)）和带有正则化损失的线性模型（[第十六章](ch16.html#ch-risk)）。在所有这些情况下，我们的目标是预测或解释数值结果的行为——公交等待时间、空气中的烟粒子和驴子的体重都是数值变量。
- en: In this chapter we expand our view of modeling. Instead of predicting numeric
    outcomes, we build models to predict nominal outcomes. These sorts of models enable
    banks to predict whether a credit card transaction is fraudulent or not, doctors
    to classify tumors as benign or malignant, and your email service to identify
    spam and set it aside from your usual emails. This type of modeling is called
    *classification* and occurs widely in data science.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们扩展了对建模的视角。我们不再预测数值结果，而是构建模型来预测名义结果。这些模型使银行能够预测信用卡交易是否欺诈，医生能够将肿瘤分类为良性或恶性，以及您的电子邮件服务能够识别垃圾邮件并将其与常规邮件区分开来。这种类型的建模称为*分类*，在数据科学中广泛应用。
- en: Just as with linear regression, we formulate a model, choose a loss function,
    fit the model by minimizing average loss for our data, and assess the fitted model.
    But unlike linear regression, our model is not linear, the loss function is not
    squared error, and our assessment compares different kinds of classification errors.
    Despite these differences, the overall structure of model fitting carries over
    to this setting. Together, regression and classification compose the primary approaches
    for *supervised learning*, the general task of fitting models based on observed
    outcomes and covariates.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 就像线性回归一样，我们制定一个模型，选择一个损失函数，通过最小化数据的平均损失来拟合模型，并评估拟合的模型。但与线性回归不同的是，我们的模型不是线性的，损失函数也不是平方误差，我们的评估比较不同类型的分类错误。尽管存在这些差异，模型拟合的整体结构在这种情况下仍然适用。回归和分类共同组成了*监督学习*的主要方法，即基于观察结果和协变量拟合模型的一般任务。
- en: We begin by introducing an example that we use throughout this chapter.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先介绍一个示例，在本章中我们将一直使用它。
- en: 'Example: Wind-Damaged Trees'
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 例子：受风损坏的树木
- en: In 1999, a huge storm with winds over 90 mph damaged millions of trees in the
    [Boundary Waters Canoe Area Wilderness](https://oreil.ly/O2qOL) (BWCAW), which
    has the largest tract of virgin forest in the eastern US. In an effort to understand
    the susceptibility of trees to wind damage, a researcher named [Roy Lawrence Rich](https://oreil.ly/plX02)
    carried out a ground survey of the BWCAW. In the years following this study, other
    researchers have used this dataset to model *windthrow*, or the uprooting of trees
    in strong winds.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 1999年，一场风速超过90英里每小时的巨大风暴损坏了[边界水道独木舟区野外](https://oreil.ly/O2qOL)（BWCAW）中数百万棵树木，该地区是美国东部最大的原始森林地带。为了了解树木对风害的敏感性，名叫[罗伊·劳伦斯·里奇](https://oreil.ly/plX02)的研究人员对BWCAW进行了地面调查。在此研究后的几年里，其他研究人员利用这一数据集对*风倒*（即树木在强风中被连根拔起）进行了建模。
- en: 'The population under study are the trees in the BWCAW. The access frame are
    *transects*: straight lines that cut through the natural landscape. These particular
    transects begin close to a lake and travel orthogonally to the gradient of the
    land for 250–400 meters. Along these transects, surveyors stop every 25 meters
    and examine a 5-by-5-meter plot. At each plot, trees are counted, categorized
    as blown down or standing, measured in diameter at 6 ft from the ground, and their
    species recorded.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 研究对象是BWCAW中的树木群落。访问框架是*样线*：穿过自然景观的直线。这些特定的样线从湖边开始，沿着地形的梯度直角行驶250至400米。沿着这些样线，调查员每隔25米停下来，检查一个5乘5米的小区。在每个小区，树木被计数，分类为倒伏或直立，以6英尺高处的直径测量，并记录它们的种类。
- en: Sampling protocols like this are common for studying natural resources. In the
    BWCAW, over 80% of the land in the region is within 500 meters of a lake, so the
    access frame nearly covers the population. The study took place over the summers
    of 2000 and 2001, and no other natural disasters happened between the 1999 storm
    and when the data were collected.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样的采样协议在研究自然资源时很常见。在BWCAW中，该地区80%以上的土地距离湖泊不到500米，因此几乎覆盖了整个人口。该研究于2000年和2001年夏季进行，1999年暴风雨和数据收集之间没有发生其他自然灾害。
- en: 'Measurements were collected on over 3,600 trees, but in this example, we examine
    just the black spruce. There are over 650 of them. We read in these data:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 收集了3600多棵树的测量数据，但在这个例子中，我们仅研究了黑云杉。有650多棵。我们读取了这些数据：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '|   | diameter | storm | status |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '|   | 直径 | 暴风雨 | 状态 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **0** | 9.0 | 0.02 | standing |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 9.0 | 0.02 | 站立 |'
- en: '| **1** | 11.0 | 0.03 | standing |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 11.0 | 0.03 | 站立 |'
- en: '| **2** | 9.0 | 0.03 | standing |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 9.0 | 0.03 | 站立 |'
- en: '| **...** | ... | ... | ... |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| **...** | ... | ... | ... |'
- en: '| **656** | 9.0 | 0.94 | fallen |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| **656** | 9.0 | 0.94 | 倒下 |'
- en: '| **657** | 17.0 | 0.94 | fallen |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| **657** | 17.0 | 0.94 | 倒下 |'
- en: '| **658** | 8.0 | 0.98 | fallen |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| **658** | 8.0 | 0.98 | 倒下 |'
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Each row corresponds to a single tree and has the following attributes:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每行对应一个单独的树，具有以下属性：
- en: '`diameter`'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`直径`'
- en: Diameter of the tree in cm, measured at 6 ft above the ground
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 直径为厘米，测量高度在地面以上6英尺处的树木
- en: '`storm`'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`暴风雨`'
- en: Severity of the storm (fraction of trees that fell in a 25-meter-wide area containing
    the tree)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 暴风雨的严重程度（25米宽区域内倒下的树木占比）
- en: '`status`'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`状态`'
- en: Tree has “fallen” or is “standing”
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 树木“倒下”或“站立”
- en: 'Let’s begin with some exploratory analysis before we turn to modeling. First,
    we calculate some simple summary statistics:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们转向建模之前，让我们进行一些探索性分析。首先，我们计算一些简单的摘要统计信息：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '|   | diameter | storm |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '|   | 直径 | 暴风雨 |'
- en: '| --- | --- | --- |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **min** | 5.0 | 0.02 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **最小** | 5.0 | 0.02 |'
- en: '| **25%** | 6.0 | 0.21 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| **25%** | 6.0 | 0.21 |'
- en: '| **50%** | 8.0 | 0.36 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **50%** | 8.0 | 0.36 |'
- en: '| **75%** | 12.0 | 0.55 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| **75%** | 12.0 | 0.55 |'
- en: '| **max** | 32.0 | 0.98 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| **最大** | 32.0 | 0.98 |'
- en: 'Based on the quartiles, the distribution of tree diameter seems skewed right.
    Let’s compare the distribution of diameters for the standing and fallen trees
    with histograms:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 基于四分位数，树直径的分布似乎向右倾斜。让我们用直方图比较站立和倒下树木的直径分布：
- en: '![](assets/leds_19in01.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in01.png)'
- en: The distribution of the diameter of the trees that fell in the storm is centered
    at 12 cm with a right skew. In comparison, the standing trees were nearly all
    under 10 cm in diameter with a mode at about 6 cm (only trees with a diameter
    of at least 5 cm are included in the study).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在暴风雨中倒下的树木直径分布以12厘米为中心，呈右偏态。相比之下，站立的树几乎都在10厘米以下，众数约为6厘米（研究中仅包括直径至少为5厘米的树木）。
- en: 'Another feature to investigate is the strength of the storm. We plot the storm
    strength against the tree diameter using the symbol and marker color to distinguish
    the standing trees from the fallen ones. Since the diameter is essentially measured
    to the nearest cm, many trees have the same diameter, so we jitter the values
    by adding a bit of noise to the diameter values to help reduce overplotting (see
    [Chapter 11](ch11.html#ch-viz)). We also adjust the opacity of the marker colors
    to reveal the denser regions on the plot:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个要调查的特征是暴风雨的强度。我们将暴风雨强度与树木直径绘制成图，使用符号和标记颜色来区分站立的树木和倒下的树木。由于直径基本上是以厘米为单位测量的，所以许多树木具有相同的直径，因此我们通过为直径值添加一些噪声来减少过度绘制（参见[第11章](ch11.html#ch-viz)）。我们还调整了标记颜色的不透明度，以显示图中的密集区域：
- en: '![](assets/leds_19in02.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in02.png)'
- en: 'From this plot, it looks like both the tree diameter and the strength of the
    storm are related to windthrow: whether the tree was uprooted or left standing.
    Notice that windthrow, the feature we want to predict, is a nominal variable.
    In the next section, we consider how this impacts the prediction problem.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从这张图中可以看出，树木直径和暴风雨的强度与风倒有关：树木是被连根拔起还是留在原地。请注意，我们想要预测的风倒是一个名义变量。在下一节中，我们考虑了这如何影响预测问题。
- en: Modeling and Classification
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模和分类
- en: 'We’d like to create a model that explains the susceptibility of trees to windthrow.
    In other words, we need to build a model for a two-level nominal feature: fallen
    or standing. When the response variable is nominal, this modeling task is called
    *classification*. In this case there are only two levels, so this task is more
    specifically called *binary classification*.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望创建一个解释树木易受风倒的模型。换句话说，我们需要为两级名义特征构建模型：倒下或站立。当响应变量是名义的时，这个建模任务称为*分类*。在这种情况下只有两个级别，所以这个任务更具体地称为*二元分类*。
- en: A Constant Model
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个常数模型
- en: 'Let’s start by considering the simplest model: a constant model that always
    predicts one class. We use <math><mi>C</mi></math> to denote the constant model’s
    prediction. For our windthrow dataset, this model will predict either <math><mi>C</mi>
    <mo>=</mo> <mtext>standing</mtext></math> or <math><mi>C</mi> <mo>=</mo> <mtext>fallen</mtext></math>
    for every input.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先考虑最简单的模型：一个始终预测一类的常数模型。我们使用<math><mi>C</mi></math>来表示常数模型的预测。对于我们的风倒数据集，这个模型将为每个输入预测<math><mi>C</mi>
    <mo>=</mo> <mtext>站立</mtext></math>或<math><mi>C</mi> <mo>=</mo> <mtext>倒下</mtext></math>。
- en: 'In classification, we want to track how often our model predicts the correct
    category. For now, we simply use a count of the correct predictions. This is sometimes
    called the *zero-one error* because the loss function takes on one of two possible
    values: 1 when an incorrect prediction is made and 0 for a correct prediction.
    For a given observed outcome <math><msub><mi>y</mi> <mi>i</mi></msub></math> and
    prediction <math><mi>C</mi></math> , we can express this loss function as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类中，我们想追踪我们的模型多频繁地预测了正确的类别。现在，我们只是使用正确预测的计数。这有时被称为*零一误差*，因为损失函数有两个可能的值之一：当进行错误的预测时为
    1，进行正确的预测时为 0。对于给定的观察结果<math><msub><mi>y</mi> <mi>i</mi></msub></math>和预测<math><mi>C</mi></math>，我们可以将这个损失函数表示为：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable displaystyle="true" rowspacing="3pt"><mtr><mtd><mrow><mi>ℓ</mi></mrow>
    <mo stretchy="false">(</mo> <mi>C</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mo>=</mo> <mrow><mo>{</mo> <mtable columnalign="left left" columnspacing="1em"
    rowspacing=".2em"><mtr><mtd><mn>0</mn></mtd> <mtd><mtext>when </mtext> <mi>C</mi>
    <mtext> matches </mtext> <mi>y</mi></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mtext>when </mtext>
    <mi>C</mi> <mtext> is a mismatch for </mtext> <mi>y</mi></mtd></mtr></mtable></mrow></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable displaystyle="true" rowspacing="3pt"><mtr><mtd><mrow><mi>ℓ</mi></mrow>
    <mo stretchy="false">(</mo> <mi>C</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mo>=</mo> <mrow><mo>{</mo> <mtable columnalign="left left" columnspacing="1em"
    rowspacing=".2em"><mtr><mtd><mn>0</mn></mtd> <mtd><mtext>when </mtext> <mi>C</mi>
    <mtext> matches </mtext> <mi>y</mi></mtd></mtr> <mtr><mtd><mn>1</mn></mtd> <mtd><mtext>when </mtext>
    <mi>C</mi> <mtext> is a mismatch for </mtext> <mi>y</mi></mtd></mtr></mtable></mrow></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: 'When we have collected data, <math><mrow><mi mathvariant="bold">y</mi></mrow>
    <mo>=</mo> <mo stretchy="false">[</mo> <msub><mi>y</mi> <mn>1</mn></msub> <mo>,</mo>
    <mo>…</mo> <mo>,</mo> <msub><mi>y</mi> <mi>n</mi></msub> <mo stretchy="false">]</mo></math>
    , then the average loss is:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们收集了数据<math><mrow><mi mathvariant="bold">y</mi></mrow> <mo>=</mo> <mo stretchy="false">[</mo>
    <msub><mi>y</mi> <mn>1</mn></msub> <mo>,</mo> <mo>…</mo> <mo>,</mo> <msub><mi>y</mi>
    <mi>n</mi></msub> <mo stretchy="false">]</mo></math>时，平均损失为：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>L</mi> <mo stretchy="false">(</mo>
    <mi>C</mi> <mo>,</mo> <mrow><mi mathvariant="bold">y</mi></mrow> <mo stretchy="false">)</mo></mtd>
    <mtd><mo>=</mo> <mfrac><mn>1</mn> <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi>
    <mo>=</mo> <mn>1</mn></mrow> <mi>n</mi></munderover> <mrow><mi>ℓ</mi></mrow> <mo
    stretchy="false">(</mo> <mi>C</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo></mtd></mtr>
    <mtr><mtd><mo>=</mo> <mfrac><mrow><mi mathvariant="normal">#</mi> <mtext> mismatches</mtext></mrow>
    <mi>n</mi></mfrac></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>L</mi> <mo stretchy="false">(</mo>
    <mi>C</mi> <mo>,</mo> <mrow><mi mathvariant="bold">y</mi></mrow> <mo stretchy="false">)</mo></mtd>
    <mtd><mo>=</mo> <mfrac><mn>1</mn> <mi>n</mi></mfrac> <munderover><mo>∑</mo> <mrow><mi>i</mi>
    <mo>=</mo> <mn>1</mn></mrow> <mi>n</mi></munderover> <mrow><mi>ℓ</mi></mrow> <mo
    stretchy="false">(</mo> <mi>C</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo></mtd></mtr>
    <mtr><mtd><mo>=</mo> <mfrac><mrow><mi mathvariant="normal">#</mi> <mtext> mismatches</mtext></mrow>
    <mi>n</mi></mfrac></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: For the constant model (see [Chapter 4](ch04.html#ch-modeling)), the model minimizes
    the loss when <math><mi>C</mi></math> is set to the most prevalent category.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于常数模型（见[第四章](ch04.html#ch-modeling)），当<math><mi>C</mi></math>设置为最常见的类别时，模型可以最小化损失。
- en: 'In the case of the black spruce, we have the following proportions of standing
    and fallen trees:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 就黑云杉而言，我们有以下比例的站立和倒下的树木：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: So our prediction is that a tree stands, and the average loss for our dataset
    is <math><mn>0.35</mn></math> .
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们的预测是一棵树站立，而我们数据集的平均损失为<math><mn>0.35</mn></math>。
- en: That said, this prediction is not particularly helpful or insightful. For example,
    in our EDA of the trees dataset, we saw that the size of the tree is correlated
    with whether the tree stands or falls. Ideally, we could incorporate this information
    into the model, but the constant model doesn’t let us do this. Let’s build some
    intuition for how we can incorporate predictors into our model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是说，这个预测并不特别有用或有见地。例如，在我们对树木数据集进行的 EDA 中，我们发现树木的大小与树木是否站立或倒下有关联。理想情况下，我们可以将这些信息纳入模型，但常数模型不允许我们这样做。让我们对如何将预测因子纳入我们的模型建立一些直觉。
- en: Examining the Relationship Between Size and Windthrow
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查尺寸和风倒之间的关系
- en: 'We want to take a closer look at how tree size is related to windthrow. For
    convenience, we transform the nominal windthrow feature into a 0-1 numeric feature
    where 1 stands for a fallen tree and 0 for standing:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想更仔细地研究树木尺寸与风倒的关系。为了方便起见，我们将名义风倒特征转换为 0-1 数字特征，其中 1 表示倒下的树木，0 表示站立的树木：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '|   | diameter | storm | status | status_0_1 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '|   | 直径 | 风暴 | 状态 | 状态_0_1 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **0** | 9.0 | 0.02 | standing | 0 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| **0** | 9.0 | 0.02 | 站立 | 0 |'
- en: '| **1** | 11.0 | 0.03 | standing | 0 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 11.0 | 0.03 | 站立 | 0 |'
- en: '| **2** | 9.0 | 0.03 | standing | 0 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 9.0 | 0.03 | 站立 | 0 |'
- en: '| **...** | ... | ... | ... | ... |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| **...** | ... | ... | ... | ... |'
- en: '| **656** | 9.0 | 0.94 | fallen | 1 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| **656** | 9.0 | 0.94 | 倒下 | 1 |'
- en: '| **657** | 17.0 | 0.94 | fallen | 1 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| **657** | 17.0 | 0.94 | 倒下 | 1 |'
- en: '| **658** | 8.0 | 0.98 | fallen | 1 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| **658** | 8.0 | 0.98 | 倒下 | 1 |'
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This representation is useful in many ways. For example, the average of `status_0_1`
    is the proportion of fallen trees in the dataset:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这种表示在许多方面都是有用的。例如，`status_0_1` 的平均值是数据集中倒下的树木比例：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Having this 0-1 feature also lets us make a plot to show the relationship between
    tree diameter and windthrow. This is analogous to our process for linear regression,
    where we make scatterplots of the outcome variable against explanatory variable(s)
    (see [Chapter 15](ch15.html#ch-linear)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 具备这种 0-1 特征，我们可以制作一张图来展示树木直径与风倒之间的关系。这类似于我们进行线性回归的过程，其中我们绘制结果变量与解释变量之间的散点图（参见
    [第 15 章](ch15.html#ch-linear)）。
- en: 'Here we plot the tree status against the diameter, but we add a small amount
    of random noise to the status to help us see the density of 0 and 1 values at
    each diameter. As before, we jitter the diameter values too and adjust the opacity
    of the markers to reduce overplotting. We also add a horizontal line at the proportion
    of fallen trees:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将树木状态绘制为直径的函数，但是我们在状态中添加了一点随机噪声，以帮助我们查看每个直径处 0 和 1 值的密度。与之前一样，我们也会扰动直径值，并调整标记的不透明度以减少重叠绘制。我们还在倒下的树木比例处添加了一条水平线：
- en: '![](assets/leds_19in03.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in03.png)'
- en: This scatterplot shows that the smaller trees are more likely to be standing
    than the larger trees. Notice that the average status for trees (0.35) essentially
    fits a constant model to the response variable. If we consider tree diameter as
    an explanatory feature, we should be able to improve the model.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这个散点图显示较小的树更有可能直立，而较大的树更有可能倒下。请注意，树木的平均状态（0.35）基本上适合将一个恒定模型应用于响应变量。如果我们将树木直径视为一个解释特征，我们应该能够改进模型。
- en: 'A starting place might be to compute the proportion of fallen trees for different
    diameters. The following block of code divides tree diameter into intervals and
    computes the proportion of fallen trees in each bin:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一个起点可能是计算不同直径树木的倒下比例。以下代码块将树木直径分成区间，并计算每个区间内倒下的树木比例：
- en: '[PRE9]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can plot these proportions against tree diameter:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这些比例绘制成树木直径的函数图：
- en: '![](assets/leds_19in04.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in04.png)'
- en: The size of the markers reflects the number of trees in the diameter bin. We
    can use these proportions to improve our model. For example, for a tree that is
    6 cm in diameter, we would classify it as standing, whereas for a 20 cm tree,
    our classification would be fallen. A natural starting place for binary classification
    is to model the observed proportions and then use these proportions to classify.
    Next, we develop a model for these proportions.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 标记的大小反映了直径区间内树木的数量。我们可以利用这些比例来改进我们的模型。例如，对于直径为 6 厘米的树木，我们会将其分类为直立，而对于 20 厘米的树木，我们的分类则是倒下的。二元分类的一个自然起点是对观察到的比例进行建模，然后利用这些比例进行分类。接下来，我们为这些比例开发一个模型。
- en: Modeling Proportions (and Probabilities)
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模比例（和概率）
- en: 'Recall that when we model, we need to choose three things: a model, a loss
    function, and a method to minimize the average loss on our train set. In the previous
    section, we chose a constant model, the 0-1 loss, and a proof to fit the model.
    However, the constant model doesn’t incorporate predictor variables. In this section,
    we address this issue by introducing a new model called the *logistic* model.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，当我们建模时，我们需要选择三样东西：一个模型，一个损失函数，以及一种方法来最小化训练集上的平均损失。在前一节中，我们选择了一个恒定模型，0-1
    损失，并进行了一些适合模型的证明。然而，这个恒定模型并没有包含预测变量。在本节中，我们通过引入一个称为*逻辑*模型的新模型来解决这个问题。
- en: 'To motivate these models, notice that the relationship between tree diameter
    and the proportion of downed trees does not appear linear. For demonstration,
    let’s fit a simple linear model to these data to show that it has several undesirable
    features. Using the techniques from [Chapter 15](ch15.html#ch-linear), we fit
    a linear model of tree status to diameter:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了推动这些模型，注意到树木直径与倒下树木比例之间的关系似乎不是线性的。为了演示，让我们对这些数据拟合一个简单的线性模型，以显示它具有几个不良特征。使用
    [第 15 章](ch15.html#ch-linear) 中的技术，我们对树木状态与直径进行了线性模型的拟合：
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then we add this fitted line to our scatterplot of proportions:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将这条拟合线添加到比例散点图中：
- en: '![](assets/leds_19in05.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in05.png)'
- en: 'Clearly, the model doesn’t fit the proportions well at all. There are several
    problems:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，模型对比例的拟合效果并不理想。存在几个问题：
- en: The model gives proportions greater than 1 for large trees.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型对大树给出大于 1 的比例。
- en: The model doesn’t pick up the curvature in the proportions.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型没有捕捉到比例中的曲线特征。
- en: An extreme point (such as a tree that’s 30 cm across) shifts the fitted line
    to the right, away from the bulk of the data.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 极端点（例如直径为30厘米的树木）将拟合线向右移动，远离大部分数据。
- en: To address these issues, we introduce the *logistic model*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些问题，我们引入了*逻辑模型*。
- en: A Logistic Model
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑模型
- en: 'The logistic model is one of the most widely used basic models for classification
    and a simple extension of the linear model. The *logistic function*, often called
    the *sigmoid function*, is defined as:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑模型是最广泛使用的基础分类模型之一，是线性模型的简单扩展。*逻辑函数*，通常称为*sigmoid函数*，定义如下：
- en: <math display="block"><mtext mathvariant="bold">logistic</mtext> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn>
    <mo>+</mo> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mo>−</mo> <mi>t</mi>
    <mo stretchy="false">)</mo></mrow></mfrac></math>
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtext mathvariant="bold">logistic</mtext> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn>
    <mo>+</mo> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mo>−</mo> <mi>t</mi>
    <mo stretchy="false">)</mo></mrow></mfrac></math>
- en: Warning
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: The *sigmoid* function is typically denoted by <math><mi>σ</mi> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo></math> . Sadly, the Greek letter <math><mi>σ</mi></math>
    is widely used to mean a lot of things in data science and statistics, like the
    standard deviation, logistic function, and a permutation. You’ll have to be careful
    when seeing <math><mi>σ</mi></math> and use context to understand its meaning.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '*Sigmoid*函数通常用<math><mi>σ</mi> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></math>表示。不幸的是，希腊字母<math><mi>σ</mi></math>在数据科学和统计学中有多种含义，如标准差、逻辑函数和置换。看到<math><mi>σ</mi></math>时，必须根据上下文理解其含义。'
- en: 'We can plot the logistic function to reveal its s-shape (sigmoid-shape) and
    confirm that it outputs numbers between 0 and 1\. The function monotonically increases
    with <math><mi>t</mi></math> , and large values of <math><mi>t</mi></math> get
    close to 1:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以绘制逻辑函数以显示其S形状，并确认其输出在0到1之间。函数随着<math><mi>t</mi></math>单调增加，<math><mi>t</mi></math>的大值接近1：
- en: '[PRE11]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Since the logistic function maps to the interval between 0 and 1, it is commonly
    used when modeling proportions and probabilities. Also, we can write the logistic
    as a function of a line, <math><msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi>
    <mn>1</mn></msub> <mi>x</mi></math> :'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 由于逻辑函数映射到0到1之间的区间，通常用于建模比例和概率。此外，我们可以将逻辑写成线性函数的形式，如<math><msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi></math>：
- en: <math display="block"><mi>σ</mi> <mrow><mo>(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mfrac><mn>1</mn> <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mo>−</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>−</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi> <mo stretchy="false">)</mo></mrow></mfrac></math>
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mi>σ</mi> <mrow><mo>(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mfrac><mn>1</mn> <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mo>−</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>−</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi> <mo stretchy="false">)</mo></mrow></mfrac></math>
- en: 'To help build your intuition for the shape of this function, the following
    plot shows the logistic function as we vary <math><msub><mi>θ</mi> <mn>0</mn></msub></math>
    and <math><msub><mi>θ</mi> <mn>1</mn></msub></math> :'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助你直观地理解该函数的形状，下图显示了我们变化<math><msub><mi>θ</mi> <mn>0</mn></msub></math>和<math><msub><mi>θ</mi>
    <mn>1</mn></msub></math>时的逻辑函数。
- en: '![](assets/leds_19in06.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![leds_19in06.png](assets/leds_19in06.png)'
- en: We can see that changing the magnitude of <math><msub><mrow><mi>θ</mi></mrow>
    <mn>1</mn></msub></math> changes the sharpness of the curve; the farther away
    from 0, the steeper the curve. Flipping the sign of <math><msub><mrow><mi>θ</mi></mrow>
    <mn>1</mn></msub></math> reflects the curve about the vertical line <math><mi>x</mi>
    <mo>=</mo> <mn>0</mn></math> . Changing <math><msub><mi>θ</mi> <mn>0</mn></msub></math>
    shifts the curve left and right.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到改变<math><msub><mrow><mi>θ</mi></mrow> <mn>1</mn></msub></math>的大小会改变曲线的陡峭程度；离0越远，曲线越陡。改变<math><msub><mrow><mi>θ</mi></mrow>
    <mn>1</mn></msub></math>的符号将曲线反映在竖直线<math><mi>x</mi> <mo>=</mo> <mn>0</mn></math>周围。改变<math><msub><mi>θ</mi>
    <mn>0</mn></msub></math>会使曲线左右移动。
- en: 'The logistic function can be seen as a transformation: it transforms a linear
    function into a nonlinear smooth curve, and the output always lies between 0 and
    1\. In fact, the output of a logistic function has a deeper probabilistic interpretation,
    which we describe next.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑函数可以看作是一种转换：将线性函数转换为非线性平滑曲线，其输出始终位于0到1之间。实际上，逻辑函数的输出具有更深层次的概率解释，接下来我们将描述它。
- en: Log Odds
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对数几率
- en: Recall that the odds are the ratio <math><mi>p</mi> <mrow><mo>/</mo></mrow>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo></math>
    for a probability <math><mi>p</mi></math> . For example, when we toss a fair coin,
    the odds of getting heads are 1; for a coin that’s twice as likely to land heads
    as tails ( <math><mi>p</mi> <mo>=</mo> <mn>2</mn> <mrow><mo>/</mo></mrow> <mn>3</mn></math>
    ), the odds of getting heads are 2\. The logistic model is also called the *log
    odds* model because the logistic function coincides with a linear function of
    the log odds.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，赔率是概率<math><mi>p</mi></math>的比率<math><mi>p</mi> <mrow><mo>/</mo></mrow> <mo
    stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo></math>。例如，投掷一个公平硬币时，得到正面的赔率是1；对于一个比尾部更有可能出现两倍的硬币（<math><mi>p</mi>
    <mo>=</mo> <mn>2</mn> <mrow><mo>/</mo></mrow> <mn>3</mn></math>），得到正面的赔率是2。逻辑模型也称为*对数几率*模型，因为逻辑函数与对数几率的线性函数重合。
- en: 'We can see this in the following equations. To show this, we multiply the numerator
    and denominator of the sigmoid function by <math><mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo></math> :'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下方程中看到这一点。为了展示这一点，我们将 Sigmoid 函数的分子和分母分别乘以 <math><mi>exp</mi> <mo>⁡</mo>
    <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></math>：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>σ</mi> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo></mtd> <mtd><mo>=</mo> <mfrac><mn>1</mn>
    <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mo>−</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>exp</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow>
    <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr> <mtr><mtd><mo
    stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd> <mtd><mo>=</mo>
    <mn>1</mn> <mo>−</mo> <mfrac><mrow><mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo></mrow> <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi> <mo>⁡</mo>
    <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>σ</mi> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo></mtd> <mtd><mo>=</mo> <mfrac><mn>1</mn>
    <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mo>−</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>exp</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow>
    <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr> <mtr><mtd><mo
    stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd> <mtd><mo>=</mo>
    <mn>1</mn> <mo>−</mo> <mfrac><mrow><mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mi>t</mi> <mo stretchy="false">)</mo></mrow> <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>1</mn> <mrow><mn>1</mn> <mo>+</mo> <mi>exp</mi> <mo>⁡</mo>
    <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: 'Then we take the logarithm of the odds and simplify:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们取对数几率并简化：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>log</mi> <mo>⁡</mo> <mrow><mo>(</mo>
    <mfrac><mrow><mi>σ</mi> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow>
    <mrow><mn>1</mn> <mo>−</mo> <mi>σ</mi> <mo stretchy="false">(</mo> <mi>t</mi>
    <mo stretchy="false">)</mo></mrow></mfrac> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>exp</mi> <mo>⁡</mo> <mrow><mo
    stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow> <mo stretchy="false">)</mo>
    <mo>=</mo> <mi>t</mi></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>log</mi> <mo>⁡</mo> <mrow><mo>(</mo>
    <mfrac><mrow><mi>σ</mi> <mo stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow>
    <mrow><mn>1</mn> <mo>−</mo> <mi>σ</mi> <mo stretchy="false">(</mo> <mi>t</mi>
    <mo stretchy="false">)</mo></mrow></mfrac> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>exp</mi> <mo>⁡</mo> <mrow><mo
    stretchy="false">(</mo> <mi>t</mi> <mo stretchy="false">)</mo></mrow> <mo stretchy="false">)</mo>
    <mo>=</mo> <mi>t</mi></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: 'So, for <math><mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo></math>
    , we find the log odds are a linear function of <math><mi>x</mi></math> :'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于 <math><mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo></math>
    ，我们发现对数几率是 <math><mi>x</mi></math> 的线性函数：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>log</mi> <mo>⁡</mo> <mrow><mo>(</mo>
    <mfrac><mrow><mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo></mrow>
    <mrow><mn>1</mn> <mo>−</mo> <mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo
    stretchy="false">)</mo></mrow></mfrac> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>exp</mi> <mo>⁡</mo> <mrow><mo
    stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi>
    <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo></mrow> <mo stretchy="false">)</mo>
    <mo>=</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>log</mi> <mo>⁡</mo> <mrow><mo>(</mo>
    <mfrac><mrow><mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo></mrow>
    <mrow><mn>1</mn> <mo>−</mo> <mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo
    stretchy="false">)</mo></mrow></mfrac> <mo>)</mo></mrow></mtd> <mtd><mo>=</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>exp</mi> <mo>⁡</mo> <mrow><mo
    stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi>
    <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo></mrow> <mo stretchy="false">)</mo>
    <mo>=</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: 'This representation of the logistic in terms of log odds gives a useful interpretation
    for the coefficient <math><msub><mi>θ</mi> <mn>1</mn></msub></math> . Suppose
    the explanatory variable increases by 1\. Then the odds change as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 以对数几率的形式表示 logistic 对于系数 <math><msub><mi>θ</mi> <mn>1</mn></msub></math> 给出了一个有用的解释。假设解释变量增加
    1，则几率的变化如下：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mtext> odds </mtext> <mo>=</mo></mtd>
    <mtd><mi>exp</mi> <mo>⁡</mo> <mrow><mo>(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mo stretchy="false">(</mo> <mi>x</mi>
    <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>1</mn></msub> <mo stretchy="false">)</mo> <mo>×</mo> <mi>exp</mi>
    <mo>⁡</mo> <mrow><mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo></mrow></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mtext> odds </mtext> <mo>=</mo></mtd>
    <mtd><mi>exp</mi> <mo>⁡</mo> <mrow><mo>(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mo stretchy="false">(</mo> <mi>x</mi>
    <mo>+</mo> <mn>1</mn> <mo stretchy="false">)</mo> <mo>)</mo></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd> <mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>1</mn></msub> <mo stretchy="false">)</mo> <mo>×</mo> <mi>exp</mi>
    <mo>⁡</mo> <mrow><mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo></mrow></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: We see that the odds increase or decrease by a factor of <math><mi>exp</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mo
    stretchy="false">)</mo></math> .
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到几率增加或减少了 <math><mi>exp</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>1</mn></msub> <mo stretchy="false">)</mo></math> 倍。
- en: Note
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Here, the <math><mi>log</mi></math> function is the natural logarithm. Since
    the natural log is the default in data science, we typically don’t bother to write
    it as <math><mi>ln</mi></math> .
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，<math><mi>log</mi></math> 函数是自然对数。由于自然对数在数据科学中是默认的，因此我们通常不必写成 <math><mi>ln</mi></math>。
- en: Next, let’s add a logistic curve to our plot of proportions to get a sense of
    how well it might fit the data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们在我们的比例图中添加一个 logistic 曲线，以了解它对数据的拟合效果。
- en: Using a Logistic Curve
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Logistic 曲线
- en: 'In the following plot, we’ve added a logistic curve on top of the plot of proportions
    of fallen trees:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图中，我们在倒下的树木比例的图上添加了一个 logistic 曲线：
- en: '![](assets/leds_19in07.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in07.png)'
- en: 'We can see that the curve follows the proportions reasonably well. In fact,
    we selected this particular logistic by fitting it to the data. The fitted logistic
    regression is:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到曲线相对比例很好。事实上，我们选择了这个特定的 logistic 通过将其拟合到数据。拟合的 logistic 回归是：
- en: '[PRE12]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that we’ve seen that logistic curves can model probabilities well, we turn
    to the process of fitting logistic curves to data. In the next section, we proceed
    to our second step in modeling: selecting an appropriate loss function.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到 logistic 曲线可以很好地建模概率，我们转向将 logistic 曲线拟合到数据的过程。在下一节中，我们继续我们建模的第二步：选择一个合适的损失函数。
- en: A Loss Function for the Logistic Model
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Logistic 模型的损失函数
- en: 'The logistic model gives us probabilities (or empirical proportions), so we
    write our loss function as <math><mi>ℓ</mi> <mo stretchy="false">(</mo> <mi>p</mi>
    <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo></math> , where <math><mi>p</mi></math>
    is between 0 and 1\. The response takes on one of two values because our outcome
    feature is a binary classification. Thus, any loss function reduces to:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Logistic 模型给我们提供了概率（或经验比例），因此我们将损失函数写成 <math><mi>ℓ</mi> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo></math> ，其中 <math><mi>p</mi></math>
    在 0 和 1 之间。响应采用两个值之一，因为我们的输出特征是二元分类。因此，任何损失函数都可以简化为：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable displaystyle="true" rowspacing="3pt"><mtr><mtd><mrow><mi>ℓ</mi></mrow>
    <mo stretchy="false">(</mo> <mi>p</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mo>=</mo> <mrow><mo>{</mo> <mtable columnalign="left left" columnspacing="1em"
    rowspacing=".2em"><mtr><mtd><mi>ℓ</mi> <mo stretchy="false">(</mo> <mi>p</mi>
    <mo>,</mo> <mn>0</mn> <mo stretchy="false">)</mo></mtd> <mtd><mrow><mtext>if </mtext>
    <mrow><mi>y</mi></mrow> <mtext> is 0</mtext></mrow></mtd></mtr> <mtr><mtd><mi>ℓ</mi>
    <mo stretchy="false">(</mo> <mi>p</mi> <mo>,</mo> <mn>1</mn> <mo stretchy="false">)</mo></mtd>
    <mtd><mrow><mtext>if </mtext> <mrow><mi>y</mi></mrow> <mtext> is 1</mtext></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable displaystyle="true" rowspacing="3pt"><mtr><mtd><mrow><mi>ℓ</mi></mrow>
    <mo stretchy="false">(</mo> <mi>p</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mo>=</mo> <mrow><mo>{</mo> <mtable columnalign="left left" columnspacing="1em"
    rowspacing=".2em"><mtr><mtd><mi>ℓ</mi> <mo stretchy="false">(</mo> <mi>p</mi>
    <mo>,</mo> <mn>0</mn> <mo stretchy="false">)</mo></mtd> <mtd><mrow><mtext>if </mtext>
    <mrow><mi>y</mi></mrow> <mtext> is 0</mtext></mrow></mtd></mtr> <mtr><mtd><mi>ℓ</mi>
    <mo stretchy="false">(</mo> <mi>p</mi> <mo>,</mo> <mn>1</mn> <mo stretchy="false">)</mo></mtd>
    <mtd><mrow><mtext>if </mtext> <mrow><mi>y</mi></mrow> <mtext> is 1</mtext></mrow></mtd></mtr></mtable></mrow></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: 'Once again, using 0 and 1 to represent the categories has an advantage because
    we can conveniently write the loss as:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 再次使用 0 和 1 来表示类别具有优势，因为我们可以方便地写出损失函数为：
- en: <math display="block"><mi>ℓ</mi> <mo stretchy="false">(</mo> <mi>p</mi> <mo>,</mo>
    <mi>y</mi> <mo stretchy="false">)</mo> <mo>=</mo>  <mi>y</mi> <mi>ℓ</mi> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mo stretchy="false">(</mo>
    <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mi>ℓ</mi> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo></math>
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mi>ℓ</mi> <mo stretchy="false">(</mo> <mi>p</mi> <mo>,</mo>
    <mi>y</mi> <mo stretchy="false">)</mo> <mo>=</mo>  <mi>y</mi> <mi>ℓ</mi> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mo>+</mo> <mo stretchy="false">(</mo>
    <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mi>ℓ</mi> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo></math>
- en: We encourage you to confirm this equivalence by considering the two cases <math><mi>y</mi>
    <mo>=</mo> <mn>1</mn></math> and <math><mi>y</mi> <mo>=</mo> <mn>0</mn></math>
    .
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们鼓励你通过考虑 <math><mi>y</mi> <mo>=</mo> <mn>1</mn></math> 和 <math><mi>y</mi> <mo>=</mo>
    <mn>0</mn></math> 两种情况来确认这种等价性。
- en: 'The logistic model pairs well with *log loss*:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Logistic 模型与*对数损失*配合得很好：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mrow><mi>ℓ</mi></mrow> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mo>=</mo></mtd>
    <mtd><mrow><mo>{</mo> <mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"><mtr><mtd><mo>−</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>p</mi> <mo stretchy="false">)</mo></mtd>
    <mtd><mrow><mtext>if </mtext> <mrow><mi>y</mi></mrow> <mtext> is 1</mtext></mrow></mtd></mtr>
    <mtr><mtd><mo>−</mo> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mn>1</mn>
    <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo></mtd> <mtd><mrow><mtext>if </mtext>
    <mrow><mi>y</mi></mrow> <mtext> is 0</mtext></mrow></mtd></mtr></mtable></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd><mo>−</mo> <mi>y</mi> <mi>log</mi> <mo>⁡</mo>
    <mo stretchy="false">(</mo> <mi>p</mi> <mo stretchy="false">)</mo> <mo>−</mo>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>p</mi>
    <mo stretchy="false">)</mo></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mrow><mi>ℓ</mi></mrow> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mo>=</mo></mtd>
    <mtd><mrow><mo>{</mo> <mtable columnalign="left left" columnspacing="1em" rowspacing=".2em"><mtr><mtd><mo>−</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>p</mi> <mo stretchy="false">)</mo></mtd>
    <mtd><mrow><mtext>if </mtext> <mrow><mi>y</mi></mrow> <mtext> is 1</mtext></mrow></mtd></mtr>
    <mtr><mtd><mo>−</mo> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mn>1</mn>
    <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo></mtd> <mtd><mrow><mtext>if </mtext>
    <mrow><mi>y</mi></mrow> <mtext> is 0</mtext></mrow></mtd></mtr></mtable></mrow></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd><mo>−</mo> <mi>y</mi> <mi>log</mi> <mo>⁡</mo>
    <mo stretchy="false">(</mo> <mi>p</mi> <mo stretchy="false">)</mo> <mo>−</mo>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>p</mi>
    <mo stretchy="false">)</mo></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: 'Note that the log loss is not defined at 0 and 1 because <math><mo>−</mo> <mi>log</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>p</mi> <mo stretchy="false">)</mo></math>
    tends to <math><mi mathvariant="normal">∞</mi></math> as <math><mi>p</mi></math>
    approaches 0, and similarly for <math><mo>−</mo> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mn>1</mn> <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo></math> as <math><mi>p</mi></math>
    tends to 1\. We need to be careful to avoid the end points in our minimization.
    We can see this in the following plot of the two forms of the loss function:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注意log损失在0和1处未定义，因为<math><mo>−</mo> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo stretchy="false">)</mo></math>当<math><mi>p</mi></math>趋向0时趋近于<math><mi
    mathvariant="normal">∞</mi></math>，类似地，<math><mo>−</mo> <mi>log</mi> <mo>⁡</mo>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo></math>当<math><mi>p</mi></math>趋向1时也如此。我们在最小化过程中需要小心避免这些端点。下图显示了这两种损失函数的情况：
- en: '![](assets/leds_19in08.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in08.png)'
- en: When <math><mi>y</mi></math> is 1 (solid line), the loss is small for <math><mi>p</mi></math>
    near 1, and when <math><mi>y</mi></math> is 0 (dotted line), the loss is small
    near 0.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当<math><mi>y</mi></math>为1（实线）时，在<math><mi>p</mi></math>接近1时损失较小，当<math><mi>y</mi></math>为0（虚线）时，在<math><mi>p</mi></math>接近0时损失较小。
- en: 'If our goal is to fit a constant to the data using log loss, then the average
    loss is:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的目标是使用log损失对数据拟合一个常数，那么平均损失为：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>L</mi> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mtext mathvariant="bold">y</mtext> <mo stretchy="false">)</mo>
    <mo>=</mo></mtd> <mtd><mfrac><mn>1</mn> <mi>n</mi></mfrac> <munder><mo>∑</mo>
    <mi>i</mi></munder> <mo stretchy="false">[</mo> <mo>−</mo> <msub><mi>y</mi> <mi>i</mi></msub>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>p</mi> <mo stretchy="false">)</mo>
    <mo>−</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <mo stretchy="false">)</mo> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mn>1</mn> <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo> <mo stretchy="false">]</mo></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd><mo>−</mo> <mfrac><msub><mi>n</mi> <mn>1</mn></msub>
    <mi>n</mi></mfrac> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>p</mi>
    <mo stretchy="false">)</mo> <mo>−</mo> <mfrac><msub><mi>n</mi> <mn>0</mn></msub>
    <mi>n</mi></mfrac> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mn>1</mn>
    <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>L</mi> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mtext mathvariant="bold">y</mtext> <mo stretchy="false">)</mo>
    <mo>=</mo></mtd> <mtd><mfrac><mn>1</mn> <mi>n</mi></mfrac> <munder><mo>∑</mo>
    <mi>i</mi></munder> <mo stretchy="false">[</mo> <mo>−</mo> <msub><mi>y</mi> <mi>i</mi></msub>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>p</mi> <mo stretchy="false">)</mo>
    <mo>−</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <mo stretchy="false">)</mo> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mn>1</mn> <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo> <mo stretchy="false">]</mo></mtd></mtr>
    <mtr><mtd><mo>=</mo></mtd> <mtd><mo>−</mo> <mfrac><msub><mi>n</mi> <mn>1</mn></msub>
    <mi>n</mi></mfrac> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>p</mi>
    <mo stretchy="false">)</mo> <mo>−</mo> <mfrac><msub><mi>n</mi> <mn>0</mn></msub>
    <mi>n</mi></mfrac> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mn>1</mn>
    <mo>−</mo> <mi>p</mi> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: 'Here <math><msub><mi>n</mi> <mn>0</mn></msub></math> and <math><msub><mi>n</mi>
    <mn>1</mn></msub></math> are the number of <math><msub><mi>y</mi> <mi>i</mi></msub></math>
    that are 0 and 1, respectively. We can differentiate with respect to <math><mi>p</mi></math>
    to find the minimizer:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这里<math><msub><mi>n</mi> <mn>0</mn></msub></math>和<math><msub><mi>n</mi> <mn>1</mn></msub></math>分别是值为0和1的<math><msub><mi>y</mi>
    <mi>i</mi></msub></math>的数量。我们可以对<math><mi>p</mi></math>进行微分以找到最小值点。
- en: <math display="block"><mfrac><mrow><mi>∂</mi> <mi>L</mi> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mtext mathvariant="bold">y</mtext> <mo stretchy="false">)</mo></mrow>
    <mrow><mi>∂</mi> <mi>p</mi></mrow></mfrac> <mo>=</mo> <mo>−</mo> <mfrac><msub><mi>n</mi>
    <mn>1</mn></msub> <mrow><mi>n</mi> <mi>p</mi></mrow></mfrac> <mo>+</mo> <mfrac><msub><mi>n</mi>
    <mn>0</mn></msub> <mrow><mi>n</mi> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo>
    <mi>p</mi> <mo stretchy="false">)</mo></mrow></mfrac></math>
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mfrac><mrow><mi>∂</mi> <mi>L</mi> <mo stretchy="false">(</mo>
    <mi>p</mi> <mo>,</mo> <mtext mathvariant="bold">y</mtext> <mo stretchy="false">)</mo></mrow>
    <mrow><mi>∂</mi> <mi>p</mi></mrow></mfrac> <mo>=</mo> <mo>−</mo> <mfrac><msub><mi>n</mi>
    <mn>1</mn></msub> <mrow><mi>n</mi> <mi>p</mi></mrow></mfrac> <mo>+</mo> <mfrac><msub><mi>n</mi>
    <mn>0</mn></msub> <mrow><mi>n</mi> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo>
    <mi>p</mi> <mo stretchy="false">)</mo></mrow></mfrac></math>
- en: 'Then we set the derivative to 0 and solve for the minimizing value <math><mrow><mover><mi>p</mi>
    <mo stretchy="false">^</mo></mover></mrow></math> :'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将导数设置为0并解出最小化值<math><mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow></math>：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mn>0</mn></mtd> <mtd><mo>=</mo>
    <mo>−</mo> <mfrac><msub><mi>n</mi> <mn>1</mn></msub> <mrow><mi>n</mi> <mrow><mrow><mover><mi>p</mi>
    <mo stretchy="false">^</mo></mover></mrow></mrow></mrow></mfrac> <mo>+</mo> <mfrac><msub><mi>n</mi>
    <mn>0</mn></msub> <mrow><mi>n</mi> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo>
    <mrow><mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow></mrow>
    <mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr> <mtr><mtd><mn>0</mn></mtd>
    <mtd><mo>=</mo> <mo>−</mo> <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mrow><mover><mi>p</mi> <mo
    stretchy="false">^</mo></mover></mrow> <mo stretchy="false">)</mo> <mfrac><msub><mi>n</mi>
    <mn>1</mn></msub> <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow></mfrac>
    <mo>+</mo> <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mrow><mover><mi>p</mi> <mo
    stretchy="false">^</mo></mover></mrow> <mo stretchy="false">)</mo> <mfrac><msub><mi>n</mi>
    <mn>0</mn></msub> <mrow><mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mrow><mrow><mover><mi>p</mi>
    <mo stretchy="false">^</mo></mover></mrow></mrow> <mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr>
    <mtr><mtd><mrow><msub><mi>n</mi> <mn>1</mn></msub></mrow> <mo stretchy="false">(</mo>
    <mn>1</mn> <mo>−</mo> <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow>
    <mo stretchy="false">)</mo></mtd> <mtd><mo>=</mo> <mrow><msub><mi>n</mi> <mn>0</mn></msub></mrow>
    <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow></mtd></mtr>
    <mtr><mtd><mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow></mtd>
    <mtd><mo>=</mo> <mfrac><msub><mi>n</mi> <mn>1</mn></msub> <mi>n</mi></mfrac></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mn>0</mn></mtd> <mtd><mo>=</mo>
    <mo>−</mo> <mfrac><msub><mi>n</mi> <mn>1</mn></msub> <mrow><mi>n</mi> <mrow><mrow><mover><mi>p</mi>
    <mo stretchy="false">^</mo></mover></mrow></mrow></mrow></mfrac> <mo>+</mo> <mfrac><msub><mi>n</mi>
    <mn>0</mn></msub> <mrow><mi>n</mi> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo>
    <mrow><mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow></mrow>
    <mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr> <mtr><mtd><mn>0</mn></mtd>
    <mtd><mo>=</mo> <mo>−</mo> <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mrow><mover><mi>p</mi> <mo
    stretchy="false">^</mo></mover></mrow> <mo stretchy="false">)</mo> <mfrac><msub><mi>n</mi>
    <mn>1</mn></msub> <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow></mfrac>
    <mo>+</mo> <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mrow><mover><mi>p</mi> <mo
    stretchy="false">^</mo></mover></mrow> <mo stretchy="false">)</mo> <mfrac><msub><mi>n</mi>
    <mn>0</mn></msub> <mrow><mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mrow><mrow><mover><mi>p</mi>
    <mo stretchy="false">^</mo></mover></mrow></mrow> <mo stretchy="false">)</mo></mrow></mfrac></mtd></mtr>
    <mtr><mtd><mrow><msub><mi>n</mi> <mn>1</mn></msub></mrow> <mo stretchy="false">(</mo>
    <mn>1</mn> <mo>−</mo> <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow>
    <mo stretchy="false">)</mo></mtd> <mtd><mo>=</mo> <mrow><msub><mi>n</mi> <mn>0</mn></msub></mrow>
    <mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow></mtd></mtr>
    <mtr><mtd><mrow><mover><mi>p</mi> <mo stretchy="false">^</mo></mover></mrow></mtd>
    <mtd><mo>=</mo> <mfrac><msub><mi>n</mi> <mn>1</mn></msub> <mi>n</mi></mfrac></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: (The final equation results from noting that <math><msub><mi>n</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>n</mi> <mn>1</mn></msub> <mo>=</mo> <mi>n</mi></math> .)
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: （最终的方程来自于注意到<math><msub><mi>n</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>n</mi>
    <mn>1</mn></msub> <mo>=</mo> <mi>n</mi></math>。）
- en: 'To fit a more complex model based on the logistic function, we can substitute
    <math><mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub>
    <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo></math>
    for <math><mi>p</mi></math> . And the loss for the logistic model becomes:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要基于逻辑函数拟合更复杂的模型，我们可以将<math><mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo
    stretchy="false">)</mo></math>代入<math><mi>p</mi></math>。逻辑模型的损失变为：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mrow><mi>ℓ</mi></mrow> <mo stretchy="false">(</mo>
    <mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo>
    <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo> <mo>,</mo>
    <mi>y</mi> <mo stretchy="false">)</mo></mtd> <mtd><mo>=</mo>  <mi>y</mi> <mi>ℓ</mi>
    <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo
    stretchy="false">)</mo> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mo>+</mo>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mi>ℓ</mi> <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi> <mo stretchy="false">)</mo> <mo>,</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi>
    <mo stretchy="false">)</mo></mtd></mtr> <mtr><mtd><mo>=</mo> <mi>y</mi> <mi>log</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo> <mo>+</mo>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mrow><mi>ℓ</mi></mrow> <mo stretchy="false">(</mo>
    <mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo>
    <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo stretchy="false">)</mo> <mo>,</mo>
    <mi>y</mi> <mo stretchy="false">)</mo></mtd> <mtd><mo>=</mo>  <mi>y</mi> <mi>ℓ</mi>
    <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <mi>x</mi> <mo
    stretchy="false">)</mo> <mo>,</mo> <mi>y</mi> <mo stretchy="false">)</mo> <mo>+</mo>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mi>ℓ</mi> <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi> <mo stretchy="false">)</mo> <mo>,</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi>
    <mo stretchy="false">)</mo></mtd></mtr> <mtr><mtd><mo>=</mo> <mi>y</mi> <mi>log</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo> <mo>+</mo>
    <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <mi>y</mi> <mo stretchy="false">)</mo>
    <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mi>x</mi> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: 'Averaging the loss over the data, we arrive at:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据的损失进行平均，我们得到：
- en: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>L</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>,</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mo>,</mo> <mtext mathvariant="bold">x</mtext> <mo>,</mo> <mtext mathvariant="bold">y</mtext>
    <mo stretchy="false">)</mo> <mo>=</mo> <mfrac><mn>1</mn> <mi>n</mi></mfrac> <munder><mo>∑</mo>
    <mi>i</mi></munder></mtd> <mtd><mo>−</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mi>log</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd></mtr>
    <mtr><mtd><mo>−</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <mo stretchy="false">)</mo> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mn>1</mn> <mo>−</mo> <mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd></mtr></mtable></mtd></mtr></mtable></math>
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtable columnalign="right" columnspacing="0em" displaystyle="true"
    rowspacing="3pt"><mtr><mtd><mtable columnalign="right left" columnspacing="0em"
    displaystyle="true" rowspacing="3pt"><mtr><mtd><mi>L</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>,</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <mo>,</mo> <mtext mathvariant="bold">x</mtext> <mo>,</mo> <mtext mathvariant="bold">y</mtext>
    <mo stretchy="false">)</mo> <mo>=</mo> <mfrac><mn>1</mn> <mi>n</mi></mfrac> <munder><mo>∑</mo>
    <mi>i</mi></munder></mtd> <mtd><mo>−</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mi>log</mi>
    <mo>⁡</mo> <mo stretchy="false">(</mo> <mi>σ</mi> <mo stretchy="false">(</mo>
    <msub><mi>θ</mi> <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd></mtr>
    <mtr><mtd><mo>−</mo> <mo stretchy="false">(</mo> <mn>1</mn> <mo>−</mo> <msub><mi>y</mi>
    <mi>i</mi></msub> <mo stretchy="false">)</mo> <mi>log</mi> <mo>⁡</mo> <mo stretchy="false">(</mo>
    <mn>1</mn> <mo>−</mo> <mi>σ</mi> <mo stretchy="false">(</mo> <msub><mi>θ</mi>
    <mn>0</mn></msub> <mo>+</mo> <msub><mi>θ</mi> <mn>1</mn></msub> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo stretchy="false">)</mo> <mo stretchy="false">)</mo></mtd></mtr></mtable></mtd></mtr></mtable></math>
- en: Unlike with squared loss, there is no closed-form solution to this loss function.
    Instead, we use iterative methods like gradient descent (see [Chapter 20](ch20.html#ch-gd))
    to minimize the average loss. This is also one of the reasons we don’t use squared
    error loss for logistic models—the average squared error is nonconvex, which makes
    it hard to optimize. The notion of convexity is covered in greater detail in [Chapter 20](ch20.html#ch-gd),
    and [Figure 20-4](ch20.html#gd-convex) gives a picture for intuition.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 与平方损失不同，此损失函数没有封闭形式的解。我们使用像梯度下降这样的迭代方法（见[第20章](ch20.html#ch-gd)）来最小化平均损失。这也是我们不在逻辑模型中使用平方误差损失的原因之一——平均平方误差是非凸的，这使得优化变得困难。凸性的概念在[第20章](ch20.html#ch-gd)有更详细的讨论，[图20-4](ch20.html#gd-convex)提供了直观的图示。
- en: Note
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Log loss is also called *logistic loss* and *cross-entropy loss*. Another name
    for it is the *negative log likelihood*. This name refers to the technique of
    fitting models using the likelihood that a probability distribution produced our
    data. We do not go any further into the background of these alternative approaches
    here.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: log损失也称为*逻辑损失*和*交叉熵损失*。它的另一个名称是*负对数似然*。这个名称指的是使用似然性来拟合模型的技术，即我们的数据来自于某个概率分布的似然性。在这里我们不深入探讨这些替代方法的背景。
- en: Fitting the logistic model (with the log loss) is called *logistic regression*.
    Logistic regression is an example of a generalized linear model, a linear model
    with a nonlinear transformation.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合逻辑模型（使用log损失）被称为*逻辑回归*。逻辑回归是广义线性模型的一个示例，它是带有非线性变换的线性模型。
- en: 'We can fit logistic models with `scikit-learn`. The package designers made
    the API very similar to fitting linear models by least squares (see [Chapter 15](ch15.html#ch-linear)).
    First, we import the logistic regression module:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `scikit-learn` 来拟合逻辑模型。包的设计者使 API 与最小二乘法拟合线性模型非常相似（见[第 15 章](ch15.html#ch-linear)）。首先，我们导入逻辑回归模块：
- en: '[PRE13]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then we set up the regression problem with outcome `y`, the status of the tree,
    and covariate `X`, the diameter (which we have log-transformed):'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们用结果 `y`，即树的状态，和协变量 `X`，即直径（我们已对其进行了对数变换），设置回归问题：
- en: '[PRE14]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then we fit the logistic regression and examine the intercept and coefficient
    for diameter:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们拟合逻辑回归，并检查直径的截距和系数：
- en: '[PRE15]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'When making a prediction, the `predict` function returns the predicted (most
    likely) class, and `predict_proba` returns the predicted probability. For a tree
    with diameter 6, we expect the prediction to be 0 (meaning `standing`) with a
    high probability. Let’s check:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行预测时，`predict` 函数返回预测的（最可能的）类别，而 `predict_proba` 返回预测的概率。对于直径为 6 的树，我们预计预测为
    0（即 `站立` ）的概率很高。我们来检查一下：
- en: '[PRE17]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Thus, the model predicts that a tree with a diameter of 6 has a 0.87 probability
    for the class `standing` and a 0.13 probability for `fallen`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，模型预测直径为 6 的树以 `站立` 类别有 0.87 的概率，以 `倒下` 类别有 0.13 的概率。
- en: Now that we’ve fit a model with one feature, we might want to see if including
    another feature like the strength of the storm can improve the model. To do this,
    we can fit a multiple logistic regression by adding a feature to `X` and fitting
    the model again.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经用一个特征拟合了一个模型，我们可能想要看看是否包含另一个特征，比如风暴的强度，是否可以改善模型。为此，我们可以通过将一个特征添加到 `X`
    中，并再次拟合模型来拟合多元逻辑回归。
- en: Notice that the logistic regression fits a model to predict probabilities—the
    model predicts that a tree with diameter 6 has a 0.87 probability of class `standing`
    and a 0.13 probability of class `fallen`. Since probabilities can be any number
    between 0 and 1, we need to convert the probabilities back to categories to perform
    classification. We address this classification problem in the next section.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，逻辑回归拟合一个模型来预测概率——模型预测直径为 6 的树以 `站立` 类别有 0.87 的概率，以 `倒下` 类别有 0.13 的概率。由于概率可以是介于
    0 和 1 之间的任何数，我们需要将概率转换回类别以执行分类。我们将在下一节中解决这个分类问题。
- en: From Probabilities to Classification
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从概率到分类
- en: 'We started this chapter by presenting a binary classification problem where
    we want to model a nominal response variable. At this point, we have used logistic
    regression to model proportions or probabilities, and we’re now ready to return
    to the original problem: we use the predicted probabilities to classify records.
    For our example, this means that for a tree of a particular diameter, we use the
    fitted coefficients from the logistic regression to estimate the chance it is
    fallen. If the chance is high, we classify a tree as fallen; otherwise, we classify
    it as standing. But we need to choose a threshold for making this *decision rule*.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章开始时介绍了一个二元分类问题，我们想要建模一个名义响应变量。到目前为止，我们已经使用逻辑回归来建模比例或概率，现在我们准备返回原始问题：我们使用预测的概率来分类记录。对于我们的例子，这意味着对于特定直径的树，我们使用逻辑回归中拟合的系数来估计其倒下的可能性。如果可能性很高，我们将树分类为倒下；否则，我们将其分类为站立。但是我们需要选择一个阈值来制定这个
    *决策规则*。
- en: 'The `sklearn` logistic regression model’s `predict` function implements the
    basic decision rule: predict `1` if the predicted probability <math><mi>p</mi>
    <mo>></mo> <mn>0.5</mn></math> . Otherwise, predict 0\. We’ve overlaid this decision
    rule on top of the model predictions as a dotted line:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn` 的逻辑回归模型的 `predict` 函数实现了基本的决策规则：如果预测的概率 <math><mi>p</mi> <mo>></mo>
    <mn>0.5</mn></math> ，则预测 `1` 。否则，预测 `0` 。我们将这个决策规则以虚线叠加在模型预测之上：'
- en: '![](assets/leds_19in09.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in09.png)'
- en: In this section, we consider a more general decision rule. For some choice of
    <math><mi>τ</mi></math> , predict 1 if the model’s predicted probability <math><mi>p</mi>
    <mo>></mo> <mi>τ</mi></math> , otherwise predict 0\. By default, `sklearn` sets
    <math><mi>τ</mi> <mo>=</mo> <mn>0.5</mn></math> . Let’s explore what happens when
    <math><mi>τ</mi></math> is set to other values.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们考虑一个更一般的决策规则。对于某些选择的 <math><mi>τ</mi></math> ，如果模型预测的概率 <math><mi>p</mi>
    <mo>></mo> <mi>τ</mi></math> ，则预测 `1` ，否则预测 `0` 。默认情况下，`sklearn` 设置 <math><mi>τ</mi>
    <mo>=</mo> <mn>0.5</mn></math> 。让我们探讨当 <math><mi>τ</mi></math> 被设置为其他值时会发生什么。
- en: 'Choosing an appropriate value for <math><mi>τ</mi></math> depends on our goals.
    Suppose we want to maximize accuracy. The *accuracy* of a classifier is the fraction
    of correct predictions. We can compute the accuracy for different thresholds,
    meaning different <math><mi>τ</mi></math> values:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 选择适当的<math><mi>τ</mi></math>值取决于我们的目标。假设我们希望最大化准确率。分类器的*准确率*是正确预测的分数。我们可以计算不同阈值下的准确率，即不同的<math><mi>τ</mi></math>值：
- en: '[PRE19]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To understand how accuracy changes with respect to <math><mi>τ</mi></math>
    , we make a plot:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解准确率如何随<math><mi>τ</mi></math>变化而变化，我们制作了一个图表：
- en: '![](assets/leds_19in10.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in10.png)'
- en: Notice that the threshold with the highest accuracy isn’t exactly at 0.5\. In
    practice, we should use cross-validation to select the threshold (see [Chapter 16](ch16.html#ch-risk)).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，具有最高准确率的阈值并不完全在0.5处。在实践中，我们应该使用交叉验证来选择阈值（参见[第16章](ch16.html#ch-risk)）。
- en: 'The threshold that maximizes accuracy could be a value other than 0.5 for many
    reasons, but a common one is *class imbalance*, where one category is more frequent
    than another. Class imbalance can lead to a model that classifies a record as
    belonging to the more common category. In extreme cases (like fraud detection)
    when only a tiny fraction of the data contain a particular class, our models can
    achieve high accuracy by simply always predicting the frequent class without learning
    what makes a good classifier for the rare class. There are techniques for managing
    class imbalance, such as:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 最大化准确率的阈值可能不是0.5，这有许多原因，但一个常见的原因是*类别不平衡*，其中一个类别比另一个类别频繁。类别不平衡可能导致模型将记录分类为更常见的类别。在极端情况下（如欺诈检测），当数据中只有很小一部分包含特定类别时，我们的模型可以通过始终预测频繁类别而不学习如何生成适合稀有类别的好分类器来实现高准确率。有一些管理类别不平衡的技术，例如：
- en: Resampling the data to reduce or eliminate the class imbalance
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据进行重新采样以减少或消除类别不平衡
- en: Adjusting the loss function to put a larger penalty on the smaller class
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整损失函数以对较小类别施加更大的惩罚
- en: In our example, the class imbalance is not that extreme, so we continue without
    these adjustments.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，类别不平衡并不那么严重，因此我们继续进行而不进行这些调整。
- en: The problem of class imbalance explains why accuracy alone is often not how
    we want to judge a model. Instead, we want to differentiate between the types
    of correct and incorrect classifications. We describe these next.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 类别不平衡问题解释了为什么单靠准确率通常不是我们评判模型的方式。相反，我们希望区分不同类型的正确和错误分类。我们接下来描述这些内容。
- en: The Confusion Matrix
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'A convenient way to visualize errors in a binary classification is to look
    at the confusion matrix. The confusion matrix compares what the model predicts
    with the actual outcomes. There are two types of error in this situation:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在二元分类中可视化错误的一个方便方法是查看混淆矩阵。混淆矩阵比较模型预测与实际结果。在这种情况下存在两种类型的错误：
- en: '*False positives*'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '*假阳性*'
- en: When the actual class is 0 (false) but the model predicts 1 (true)
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 当实际类别为0（错误）但模型预测为1（真实）
- en: '*False negatives*'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '*假阴性*'
- en: When the actual class is 1 (true) but the model predicts 0 (false)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当实际类别为1（真实）但模型预测为0（错误）
- en: Ideally, we would like to minimize both kinds of errors, but we often need to
    manage the balance between these two sources.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望尽量减少两种错误，但我们经常需要平衡这两种来源之间的关系。
- en: Note
  id: totrans-187
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The terms *positive* and *negative* come from disease testing, where a test
    indicating the presence of a disease is called a positive result. This can be
    a bit confusing because having a disease doesn’t seem like something positive
    at all. And <math><mi>y</mi> <mo>=</mo> <mn>1</mn></math> denotes the “positive”
    case. To keep things straight, it’s a good idea to confirm your understanding
    of what <math><mi>y</mi> <mo>=</mo> <mn>1</mn></math> stands for in the context
    of your data.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: “正面”和“负面”这些术语来自于疾病测试，其中指示存在疾病的测试被称为正面结果。这可能有点令人困惑，因为患病似乎并不是一件积极的事情。而<math><mi>y</mi>
    <mo>=</mo> <mn>1</mn></math>表示“正面”案例。为了保持清晰，确认你对<math><mi>y</mi> <mo>=</mo> <mn>1</mn></math>在你数据背景下的理解是个好主意。
- en: '`scikit-learn` has a function to compute and plot the confusion matrix:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`scikit-learn`有一个函数来计算和绘制混淆矩阵：'
- en: '[PRE20]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](assets/leds_19in11.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in11.png)'
- en: Ideally, we want to see all of the counts in the diagonal squares True negative
    and True positive. That means we have correctly classified everything. But this
    is rarely the case, and we need to assess the size of the errors. For this, it’s
    easier to compare rates than counts. Next, we describe different rates and when
    we might prefer to prioritize one or the other.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望在对角方格中看到所有计数True negative和True positive。这意味着我们已经正确分类了所有内容。但这很少见，我们需要评估错误的规模。为此，比较率而不是计数更容易。接下来，我们描述不同的率以及何时可能更喜欢优先考虑其中之一。
- en: Precision Versus Recall
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精度与召回率
- en: 'In some settings, there might be a much higher cost to missing positive cases.
    For example, if we are building a classifier to identify tumors, we want to make
    sure that we don’t miss any malignant tumors. Conversely, we’re less concerned
    about classifying a benign tumor as malignant because a pathologist would still
    need to take a closer look to verify the malignant classification. In this case,
    we want to have a high true positive rate among the records that are actually
    positive. The rate is called *sensitivity*, or *recall*:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，错过阳性案例的成本可能会更高。例如，如果我们正在构建一个用于识别肿瘤的分类器，我们希望确保不会错过任何恶性肿瘤。相反，我们不太关心将良性肿瘤分类为恶性，因为病理学家仍然需要仔细查看以验证恶性分类。在这种情况下，我们希望在实际上为阳性的记录中具有很高的真阳性率。该率称为*敏感度*或*召回率*：
- en: <math display="block"><mtext>Recall</mtext> <mo>=</mo> <mfrac><mtext>True Positives</mtext>
    <mrow><mtext>True Positives</mtext> <mo>+</mo> <mtext>False Negatives</mtext></mrow></mfrac>
    <mo>=</mo> <mfrac><mtext>True Positives</mtext> <mtext>Actually True</mtext></mfrac></math>
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtext>Recall</mtext> <mo>=</mo> <mfrac><mtext>True Positives</mtext>
    <mrow><mtext>True Positives</mtext> <mo>+</mo> <mtext>False Negatives</mtext></mrow></mfrac>
    <mo>=</mo> <mfrac><mtext>True Positives</mtext> <mtext>Actually True</mtext></mfrac></math>
- en: Higher recall runs the risk of predicting true on false records (false positives).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 较高的召回率会冒着将假记录预测为真的风险（假阳性）。
- en: 'On the other hand, when classifying email as spam (positive) or ham (negative),
    we might be annoyed if an important email gets thrown into our spam folder. In
    this setting, we want high *precision*, the accuracy of the model for positive
    predictions:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，当将电子邮件分类为垃圾邮件（阳性）或非垃圾邮件（阴性）时，如果一封重要的电子邮件被放入垃圾邮件文件夹中，我们可能会感到烦恼。在这种情况下，我们希望有高的*精度*，即模型对于阳性预测的准确性：
- en: <math display="block"><mtext>Precision</mtext> <mo>=</mo> <mfrac><mtext>True
    Positives</mtext> <mrow><mtext>True Positives</mtext> <mo>+</mo> <mtext>False
    Positives</mtext></mrow></mfrac> <mo>=</mo> <mfrac><mtext>True Positives</mtext>
    <mtext>Predicted True</mtext></mfrac></math>
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtext>Precision</mtext> <mo>=</mo> <mfrac><mtext>True
    Positives</mtext> <mrow><mtext>True Positives</mtext> <mo>+</mo> <mtext>False
    Positives</mtext></mrow></mfrac> <mo>=</mo> <mfrac><mtext>True Positives</mtext>
    <mtext>Predicted True</mtext></mfrac></math>
- en: Higher-precision models are often more likely to predict that true observations
    are negative (higher false-negative rate).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 较高精度的模型通常更有可能预测真实观察结果为负（更高的假阴性率）。
- en: 'A common analysis compares the precision and recall at different thresholds:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的分析比较不同阈值下的精度和召回率：
- en: '[PRE22]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To see how precision and recall relate, we plot them both against the threshold
    <math><mi>τ</mi></math> :'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 为了查看精度和召回率之间的关系，我们将它们都绘制在阈值<math><mi>τ</mi></math>上：
- en: '![](assets/leds_19in12.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in12.png)'
- en: 'Another common plot used to evaluate the performance of a classifier is the
    *precision-recall curve*, or PR curve for short. It plots the precision-recall
    pairs for each threshold:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个评估分类器性能的常见图表是*精度-召回率曲线*，简称PR曲线。它绘制了每个阈值的精度-召回率对：
- en: '[PRE23]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '![](assets/leds_19in13.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/leds_19in13.png)'
- en: Notice that the righthand end of the curve reflects the imbalance in the sample.
    The precision matches the fraction of fallen trees in the sample, 0.35\. Plotting
    multiple PR curves for different models can be particularly useful for comparing
    models.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，曲线的右端反映了样本中的不平衡性。精度与样本中倒下树木的比例相匹配，为0.35。为不同模型绘制多个PR曲线可以帮助比较模型。
- en: 'Using precision and recall gives us more control over what kinds of errors
    matter. As an example, let’s suppose we want to ensure that at least 75% of the
    fallen trees are classified as fallen. We can find the threshold where this occurs:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用精度和召回率使我们能够更好地控制哪种类型的错误更重要。例如，假设我们想确保至少75%的倒下树木被分类为倒下。我们可以找到发生这种情况的阈值：
- en: '[PRE24]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We find that about 41% (1 – precision) of the trees that we classify as fallen
    are actually standing. In addition, we find the fraction of trees below this threshold
    to be:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现约41%（1 - 精度）的我们分类为倒下的树实际上是站立的。此外，我们发现低于此阈值的树木比例为：
- en: '[PRE26]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'So, we have classified 52% of the samples as standing (negative). *Specificity*
    (also called *true negative rate*) measures the proportion of data belonging to
    the negative class that the classifier labels as negative:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已将52%的样本分类为站立（负面）。*特异性*（也称为*真负率*）衡量分类器将属于负类的数据标记为负类的比例：
- en: <math display="block"><mtext>Specificity</mtext> <mo>=</mo> <mfrac><mtext>True
    Negatives</mtext> <mrow><mtext>True Negatives</mtext> <mo>+</mo> <mtext>False
    Positives</mtext></mrow></mfrac> <mo>=</mo> <mfrac><mtext>True Negatives</mtext>
    <mtext>Predicted False</mtext></mfrac></math>
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mtext>Specificity</mtext> <mo>=</mo> <mfrac><mtext>True
    Negatives</mtext> <mrow><mtext>True Negatives</mtext> <mo>+</mo> <mtext>False
    Positives</mtext></mrow></mfrac> <mo>=</mo> <mfrac><mtext>True Negatives</mtext>
    <mtext>Predicted False</mtext></mfrac></math>
- en: 'The specificity for our threshold is:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的阈值的特异性为：
- en: '[PRE28]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In other words, 70% of the trees classified as standing are actually standing.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，70%的被分类为站立的树实际上是站立的。
- en: As we’ve seen, there are several ways to use the 2-by-2 confusion matrix. Ideally,
    we want accuracy, precision, and recall to all be high. This happens when most
    predictions fall along the diagonal for the table, so our predictions are nearly
    all correct–true negatives and true positives. Unfortunately, in most scenarios
    our models will have some amount of error. In our example, trees of the same diameter
    include a mix of fallen and standing, so we can’t perfectly classify trees based
    on their diameter. In practice, when data scientists choose a threshold, they
    need to consider their context to decide whether to prioritize precision, recall,
    or specificity.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，有几种使用2x2混淆矩阵的方法。理想情况下，我们希望准确率、精确率和召回率都很高。这种情况发生在大多数预测落在表格的对角线上，因此我们的预测几乎全部正确——真负类和真正类。不幸的是，在大多数情况下，我们的模型会有一定程度的错误。在我们的例子中，相同直径的树木包括倒下的和站立的混合，因此我们不能完美地根据它们的直径分类树木。在实践中，当数据科学家选择一个阈值时，他们需要考虑自己的背景来决定是优先考虑精确率、召回率还是特异性。
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we fit simple logistic regressions with one explanatory variable,
    but we can easily include other variables in the model by adding more features
    to our design matrix. For example, if some predictors are categorical, we can
    include them as one-hot encoded features. These ideas carry over directly from
    [Chapter 15](ch15.html#ch-linear). The technique of regularization ([Chapter 16](ch16.html#ch-risk))
    also applies to logistic regression. We will integrate all of these modeling techniques—including
    using a train-test split to assess the model and cross-validation to choose the
    threshold—in the case study in [Chapter 21](ch21.html#ch-fake-news) that develops
    a model to classify fake news.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们用一个解释变量拟合简单的逻辑回归，但是我们可以通过将更多特征添加到我们的设计矩阵中来轻松地包含模型中的其他变量。例如，如果某些预测变量是分类的，我们可以将它们作为独热编码特征包含进来。这些想法直接延续自[第15章](ch15.html#ch-linear)。正则化技术（来自[第16章](ch16.html#ch-risk)）也适用于逻辑回归。我们将在[第21章](ch21.html#ch-fake-news)的案例研究中整合所有这些建模技术——包括使用训练集-测试集分割来评估模型和交叉验证来选择阈值——以开发一个用于分类假新闻的模型。
- en: Logistic regression is a cornerstone in machine learning since it naturally
    extends to more complex models. For example, logistic regression is one of the
    basic components of a neural network. When the response variable has more than
    two categories, logistic regression can be extended to multinomial logistic regression.
    Another extension of logistic regression for modeling counts is called Poisson
    regression. These different forms of regression are related to maximum likelihood,
    where the underlying model for the response is binomial, multinomial, or Poisson,
    respectively, and the goal is to optimize the likelihood of the data over the
    parameters of the respective distribution. This family of models is also known
    as generalized linear models. In all of these scenarios, closed-form solutions
    for minimizing loss don’t exist, so optimization of the average loss relies on
    numerical methods, which we cover in the next chapter.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是机器学习中的基石，因为它自然地扩展到更复杂的模型中。例如，逻辑回归是神经网络的基本组成部分之一。当响应变量有多于两个类别时，逻辑回归可以扩展为多项逻辑回归。适用于建模计数的逻辑回归的另一个扩展称为泊松回归。这些不同形式的回归与最大似然密切相关，其中响应的潜在模型分别为二项式、多项式或泊松分布，目标是优化参数的数据似然。这些模型家族也被称为广义线性模型。在所有这些场景中，不存在用于最小化损失的封闭形式解决方案，因此平均损失的优化依赖于数值方法，我们将在下一章中介绍。
