- en: 1 An introduction to deep learning systems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 深度学习系统的简介
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Defining a deep learning system
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义深度学习系统
- en: The product development cycle and how a deep learning system supports it
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产品开发周期以及深度学习系统如何支持它
- en: An overview of a basic deep learning system and its components
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本深度学习系统及其组件的概述
- en: Differences between building a deep learning system and developing models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建深度学习系统与开发模型之间的区别
- en: This chapter will prepare you with a big-picture mental model of a deep learning
    system. We will review some definitions and provide a reference system architecture
    design and a complete sample implementation of the architecture. We hope this
    mental model will prime you to see how the rest of the chapters, which address
    each system component in detail, fit into the whole picture.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将为你提供一个关于深度学习系统的整体思维模型。我们将回顾一些定义，并提供一个参考系统架构设计和该架构的完整示例实现。我们希望这个思维模型能帮助你看到后续章节，它们将详细讨论每个系统组件，如何融入整个画面。
- en: 'To begin this chapter, we will discuss an even bigger picture beyond the deep
    learning system: something we call *the deep learning development cycle*. This
    cycle outlines the various roles and stages involved in bringing products based
    on deep learning to market. The model and the platform do not exist in a vacuum;
    they affect and are affected by product management, market research, production,
    and other stages. We believe that engineers design better systems when they understand
    this cycle and know what each team does and what it needs to do its job.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始本章，我们将讨论一个比深度学习系统更大的画面：我们称之为“深度学习开发周期”。这个周期概述了将基于深度学习的产品推向市场所涉及的各个角色和阶段。模型和平台并非孤立存在；它们受产品管理、市场研究、生产和其它阶段的影响，同时也影响这些阶段。我们相信，当工程师了解这个周期并知道每个团队做什么以及他们需要做什么来完成工作的时候，他们会设计出更好的系统。
- en: In section 1.2, we start our discussion of deep learning system design with
    a sample architecture of a typical system that can be adapted for designing your
    own deep learning system. The components described in this section will be explored
    in greater detail in their own chapters. Finally, we will emphasize the differences
    between developing a model and developing a deep learning system. This distinction
    is often a point of confusion, so we want to clear it up right away.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1.2节中，我们开始讨论深度学习系统设计，从一个典型的系统架构示例入手，该架构可以适应设计你自己的深度学习系统。本节中描述的组件将在各自的章节中更详细地探讨。最后，我们将强调开发模型和开发深度学习系统之间的区别。这种区别常常是一个混淆点，所以我们想立即澄清。
- en: After reading this introductory chapter, you will have a solid understanding
    of the deep learning landscape. You will also be able to start creating your own
    deep learning system design, as well as understand existing designs and how to
    use and extend them, so you don’t have to build everything from scratch. As you
    continue reading this book, you will see how everything connects and works together
    as a deep learning system.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读完这一章的介绍之后，你将对深度学习领域有一个扎实的理解。你还将能够开始创建自己的深度学习系统设计，以及理解现有设计及其使用和扩展方法，这样你就不必从头开始构建一切。随着你继续阅读本书，你将看到所有内容是如何连接在一起并作为一个深度学习系统协同工作的。
- en: Terminology
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 术语
- en: Before we proceed with the rest of the chapter (and the rest of the book), let’s
    define and clarify a few terms that we use throughout the book.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续本章（以及本书的其余部分）之前，让我们定义和阐明一下我们在整本书中使用的几个术语。
- en: Deep learning vs. machine learning
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习与机器学习的区别
- en: Deep learning is machine learning, but it is considered an evolution of machine
    learning. Machine learning, by definition, is an application of artificial intelligence
    that includes algorithms that parse data, learn from that data, and then apply
    what it has learned to make informed decisions. Deep learning is a special form
    of machine learning that uses a programmable neural network as the algorithm to
    learn from data and make accurate decisions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习，但被认为是机器学习的一种进化。根据定义，机器学习是一种人工智能的应用，包括解析数据、从数据中学习，然后将所学应用到做出明智决策的算法。深度学习是一种特殊的机器学习方法，它使用可编程神经网络作为从数据中学习和做出准确决策的算法。
- en: Although this book primarily focuses on teaching you how to build the system
    or infrastructure to facilitate deep learning development (all the examples are
    neural network algorithms), the design and project development concepts we discuss
    are all applicable to machine learning as well. So, in this book we use the terms
    *deep learning* and *machine learning* somewhat interchangeably. For example,
    the deep learning development cycle introduced in this chapter and the data management
    service introduced in chapter 2 work in the machine learning context, too.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这本书主要侧重于教你如何构建系统或基础设施以促进深度学习开发（所有示例都是神经网络算法），但我们讨论的设计和项目开发概念也适用于机器学习。因此，在这本书中，我们使用*深度学习*和*机器学习*这两个术语有些交替使用。例如，本章中介绍的深度学习开发周期和第2章中介绍的数据管理服务在机器学习环境中也适用。
- en: Deep learning use case
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习用例
- en: A deep learning use case refers to a scenario that utilizes deep learning technology—in
    other words, a problem that you want to solve using deep learning. Examples include
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习用例指的是利用深度学习技术的一个场景——换句话说，就是你想使用深度学习解决的问题。例如包括
- en: '*Chatbot*—A user can initiate a text-based conversation with a virtual agent
    on a customer support website. The virtual agent uses a deep learning model to
    understand sentences that the user enters and carries on a conversation with the
    user like a real human.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*聊天机器人*—用户可以在客户支持网站上与虚拟代理进行基于文本的对话。虚拟代理使用深度学习模型来理解用户输入的句子，并以类似真实人类的方式与用户进行对话。'
- en: '*Self-driving car*—A driver can put a car into an assistive driving mode that
    automatically steers itself according to road markings. Markings are captured
    by multiple cameras on board the car to form a perception of the road using deep
    learning–based computer vision technology.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动驾驶汽车*—驾驶员可以将汽车置于辅助驾驶模式，该模式会根据道路标记自动转向。这些标记通过汽车上的多个摄像头捕获，使用基于深度学习的计算机视觉技术形成对道路的感知。'
- en: Model, prediction and inference, and model serving
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 模型、预测和推理以及模型服务
- en: 'These three terms are described as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个术语的描述如下：
- en: '*Model*—A deep learning model can be seen as an executable program that contains
    an algorithm (model architecture) and required data to make a prediction.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型*—深度学习模型可以被视为一个包含算法（模型架构）和所需数据以进行预测的可执行程序。'
- en: '*Prediction and inference*—Both model prediction and model inference refer
    to executing the model with given data to get a set of outputs. As prediction
    and inference are used widely in the context of model serving, they are used interchangeably
    in this book.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测和推理*—模型预测和模型推理都指的是使用给定的数据执行模型以获得一组输出。由于预测和推理在模型服务场景中被广泛使用，因此在这本书中它们被交替使用。'
- en: '*Model serving* (prediction service)—This book describes model serving as hosting
    machine learning models in a web application (on the cloud or on premises) and
    allowing deep learning applications to integrate the model functionality into
    their systems through an API. The model serving web program is usually referred
    to as the prediction service or model serving service.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型服务*（预测服务）—本书将模型服务描述为在Web应用程序（在云或本地）中托管机器学习模型，并允许深度学习应用程序通过API将模型功能集成到它们的系统中。模型服务的Web程序通常被称为预测服务或模型服务服务。'
- en: Deep learning application
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习应用程序
- en: 'A deep learning application is a piece of software that utilizes deep learning
    technologies to solve problems. It usually does not perform any computationally
    intensive tasks, such as data crunching, deep learning model training, and model
    serving (with the exception of hosting models at the edge, such as an autonomous
    vehicle). Examples include:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习应用程序是利用深度学习技术解决问题的软件。它通常不执行任何计算密集型任务，如数据处理、深度学习模型训练和模型服务（除非是在边缘托管模型，例如自动驾驶汽车）。例如包括：
- en: A *chatbot application* that provides a UI or APIs to take natural sentences
    as input from a user, interprets them, takes actions, and provides a meaningful
    response to the user. Based on the model output calculated in the deep learning
    system (from model serving service), the chatbot responds and takes action.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个提供用户界面或API的*聊天机器人应用程序*，它可以从用户那里接收自然句子作为输入，对其进行解释，采取行动，并向用户提供有意义的响应。基于深度学习系统中计算的模型输出（来自模型服务服务），聊天机器人进行响应并采取行动。
- en: '*Self-driving software* that takes input from multiple sensors, such as video
    cameras, proximity sensors, and LiDAR, to form a perception of a car’s surroundings
    with the help of deep learning models and drives the car accordingly.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动驾驶软件* 通过从多个传感器（如视频摄像头、接近传感器和激光雷达）获取输入，借助深度学习模型形成对汽车周围环境的感知，并据此驾驶汽车。'
- en: Platform vs. system vs. infrastructure
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 平台 vs. 系统 vs. 基础设施
- en: 'In this book, the terms *deep learning platform*, *deep learning system*, and
    *deep learning infrastructure* all share the same meaning: an underlying system
    that provides all necessary support for building deep learning applications efficiently
    and to scale. We tend to use *system* most commonly, but in the context of this
    book, all three terms have the same meaning.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，术语 *深度学习平台*、*深度学习系统* 和 *深度学习基础设施* 都具有相同的意义：一个提供所有必要支持以高效且可扩展地构建深度学习应用的底层系统。我们通常最常用
    *系统* 这个词，但在本书的上下文中，这三个术语具有相同的意义。
- en: Now that we’re all on the same page about the terms, let’s get started!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们对这些术语有了共识，那我们就开始吧！
- en: 1.1 The deep learning development cycle
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 深度学习开发周期
- en: As we’ve said, deep learning systems are the infrastructure necessary for deep
    learning *project development* to progress efficiently. So, before we dive into
    the structure of a deep learning system, it’s prudent to look at the development
    paradigm that a deep learning system enables. We call this paradigm the *deep
    learning development cycle*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所说的，深度学习系统是深度学习 *项目开发* 高效进行的必要基础设施。因此，在我们深入探讨深度学习系统的结构之前，先看看深度学习系统所支持的开发范式是明智的。我们称这种范式为
    *深度学习开发周期*。
- en: You may wonder why, in a technical book, we want to emphasize something that
    is as nontechnical as product development. The fact is that the goal of most deep
    learning work is, in the end, to bring a product or service to market. Yet many
    engineers are not familiar with the other stages of product development, just
    as many product developers do not know about engineering or modeling. From our
    experience in building deep learning systems, we have learned that persuading
    people in multiple roles in a company to adopt a system largely depends on whether
    the system will actually fix their particular problems. We believe that outlining
    the various stages and roles in the deep learning development cycle helps to articulate,
    address, communicate, and eventually solve everyone’s pain points.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会 wonder 为什么在一本技术书中，我们想要强调像产品开发这样非技术性的内容。事实上，大多数深度学习工作的目标最终是，将产品或服务推向市场。然而，许多工程师并不熟悉产品开发的其它阶段，正如许多产品开发者不了解工程或建模。从我们构建深度学习系统的经验中，我们了解到，说服公司中多个角色的人采用系统很大程度上取决于系统是否真的能解决他们特定的难题。我们相信，概述深度学习开发周期中的各个阶段和角色有助于阐明、解决、沟通，并最终解决每个人的痛点。
- en: Understanding this cycle solves a few other problems, as well. In the last decade,
    many new deep learning software packages have been developed to address different
    areas. Some of them tackle model training and serving, whereas others handle model
    performance tracking and experimentation. Data scientists and engineers would
    piece these tools together each time they needed to solve a specific application
    or use case; this is called MLOps (machine learning operations). As the number
    of these applications grows, piecing these tools together every time from scratch
    for a new application becomes repetitive and time-consuming. At the same time,
    as the importance of these applications grows, so do the expectations for their
    quality. Both of these concerns call for a consistent approach to developing and
    delivering deep learning features quickly and reliably. This consistent approach
    starts with everyone working under the same deep learning development paradigm
    or cycle.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这个周期也解决了其他一些问题。在过去的十年里，许多新的深度学习软件包被开发出来，以解决不同的领域。其中一些处理模型训练和部署，而另一些则处理模型性能跟踪和实验。数据科学家和工程师每次需要解决特定应用或用例时，都会将这些工具拼凑在一起；这被称为
    MLOps（机器学习操作）。随着这些应用的增多，每次从头开始为新应用拼凑这些工具变得重复且耗时。同时，随着这些应用的重要性增加，对其质量的期望也增加。这两个问题都要求以一致的方法快速且可靠地开发和交付深度学习功能。这种一致的方法从每个人都遵循相同的深度学习开发范式或周期开始。
- en: How does the deep learning *system* fit into the deep learning *cycle*? A well-built
    deep learning system would support the product development cycle and make performing
    the cycle easy, quick, and reliable. Ideally, data scientists can use a deep learning
    system as the infrastructure to complete the entire deep learning cycle without
    learning all the engineering details of the underlying complex systems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习**系统**如何融入深度学习**周期**？一个构建良好的深度学习系统将支持产品开发周期，并使执行周期变得容易、快速和可靠。理想情况下，数据科学家可以使用深度学习系统作为基础设施来完成整个深度学习周期，而无需学习底层复杂系统的所有工程细节。
- en: Because every product and organization is unique, it is crucial for system builders
    to understand the unique requirements of the various roles to build a successful
    system. By “successful,” we mean one that helps stakeholders collaborate productively
    to deliver deep learning features quickly. Throughout this book, as we go through
    the design principles of deep learning systems and look at how each component
    works, your understanding of your stakeholder requirements will help you adapt
    this knowledge to form your own system design. As we discuss the technical details,
    we will point out when you need to pay attention to certain types of stakeholders
    during the design of the system. The deep learning development cycle will serve
    as the guiding framework when we consider the design requirements of each component
    of a deep learning system.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于每个产品和组织都是独特的，系统构建者理解各种角色的独特需求对于构建一个成功的系统至关重要。我们所说的“成功”，是指一个有助于利益相关者高效协作以快速交付深度学习功能的系统。在整个本书中，当我们探讨深度学习系统的设计原则并查看每个组件的工作方式时，你对利益相关者需求的理解将帮助你将此知识应用于形成你自己的系统设计。在讨论技术细节时，我们将指出在设计系统时何时需要关注某些类型的利益相关者。深度学习开发周期将作为考虑深度学习系统每个组件设计要求的指导框架。
- en: Let’s start with a picture. Figure 1.1 illustrates what a typical cycle looks
    like. It shows the machine learning (especially deep learning) development progress
    phase by phase. As you can see, cross-functional collaboration happens at almost
    every step. We will discuss each phase and role involved in this diagram in the
    following two sections.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一张图开始。图1.1展示了典型的周期看起来是什么样子。它按阶段展示了机器学习（特别是深度学习）的开发进度。正如你所看到的，跨职能协作几乎在每个步骤都会发生。我们将在接下来的两个部分中讨论图中涉及的这个阶段和角色。
- en: '![](../Images/01-01.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/01-01.png)'
- en: Figure 1.1 A typical scenario to bring deep learning from research to a product.
    We call this *the deep learning development cycle*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 将深度学习从研究应用到产品的一个典型场景。我们称之为**深度学习开发周期**。
- en: 1.1.1 Phases in the deep learning product development cycle
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 深度学习产品开发周期的阶段
- en: 'The deep learning development cycle typically begins with a business opportunity
    and is driven by a product plan and its management. After that, the cycle normally
    goes through four phases: data exploration, prototyping, productionization (shipping
    to production), and application integration. Let’s look at these phases one at
    a time. Then we’ll look at all the roles involved (denoted by the icon of a person
    in figure 1.1).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习开发周期通常从商业机会开始，由产品计划和其管理驱动。之后，周期通常经过四个阶段：数据探索、原型设计、生产化（部署到生产）和应用集成。让我们逐一看看这些阶段。然后我们将看看所有涉及的角色（如图1.1中的人形图标所示）。
- en: Note The number in parentheses next to each following subsection corresponds
    to the same number in figure 1.1.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：每个后续小节旁边的括号中的数字与图1.1中的相同数字相对应。
- en: Product initiation (1)
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 产品启动（1）
- en: First, the business stakeholder (product owner or project manager) analyzes
    the business and identifies a potential business opportunity or problem that can
    be addressed with machine learning.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，业务利益相关者（产品所有者或项目经理）分析业务，并确定一个可以通过机器学习解决的问题或潜在的商业机会。
- en: Data exploration (2)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据探索（2）
- en: When data scientists have a clear understanding of business requirements, they
    begin to work with data engineers to collect as much data as possible, label it,
    and build datasets. Data collection can include searching publicly available data
    and exploring internal sources. Data cleaning may also occur. Data labeling can
    either be outsourced or performed in-house.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据科学家对业务需求有清晰的理解时，他们开始与数据工程师合作，尽可能多地收集数据，对其进行标记，并构建数据集。数据收集可能包括搜索公开可用的数据和探索内部来源。数据清洗也可能发生。数据标记可以是外包的，也可以在内部进行。
- en: Compared to the following phases, this early phase of data exploration is unstructured
    and often done casually. It might be a Python script or shell script, or even
    a manual copy of data. Data scientists often use web-based data analysis applications,
    such as Jupyter Notebook (open source; [https://jupyter.org](https://jupyter.org)),
    Amazon SageMaker Data Wrangler ([https://aws.amazon.com/sagemaker/data-wrangler](https://aws.amazon.com/sagemaker/data-wrangler)),
    and Databricks ([www.databricks.com](http://www.databricks.com)), to analyze data.
    There is no formal data collection pipeline that needs to be built.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 与以下阶段相比，这个早期阶段的数据探索是不规则的，通常随意进行。它可能是一个Python脚本或shell脚本，甚至可能是手动复制的数据。数据科学家通常使用基于Web的数据分析应用程序，如Jupyter
    Notebook（开源；[https://jupyter.org](https://jupyter.org)）、Amazon SageMaker Data
    Wrangler ([https://aws.amazon.com/sagemaker/data-wrangler](https://aws.amazon.com/sagemaker/data-wrangler)）和Databricks
    ([www.databricks.com](http://www.databricks.com)）来分析数据。不需要构建正式的数据收集管道。
- en: Data exploration is not only important but also critical to the success of a
    deep learning project. The more relevant data is available, the higher the likelihood
    of building effective and efficient deep learning models.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据探索不仅重要，而且对于深度学习项目的成功至关重要。可用的相关数据越多，构建有效且高效的深度学习模型的可能性就越高。
- en: Research and prototyping (3, 4)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 研究与原型设计（3, 4）
- en: The goal of prototyping is to find the most feasible algorithm/approach to address
    the business requirement (from product owner) with the given data. In this phase,
    data scientists can work with AI researchers to propose and evaluate different
    training algorithms with datasets built from the previous data exploration phase.
    Data scientists usually pilot multiple ideas in this phase and build proof-of-concept
    (POC) models to evaluate them.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 原型设计的目的是找到最可行的算法/方法来满足给定的数据下的业务需求（来自产品负责人）。在这个阶段，数据科学家可以与AI研究人员合作，提出并评估从之前的数据探索阶段构建的数据集的不同训练算法。数据科学家通常在这个阶段试点多个想法，并构建概念验证（POC）模型来评估它们。
- en: Although newly published algorithms are often considered, most of them will
    not be adopted. The accuracy of an algorithm is not the only factor to be considered;
    one also must consider computing resource requirements, data volume, and algorithm
    implementation cost when evaluating an algorithm. The most practical approach
    is usually the winner.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管通常会考虑新发布的算法，但其中大部分都不会被采用。算法的准确性不是唯一需要考虑的因素；在评估算法时，还必须考虑计算资源需求、数据量以及算法实现成本。通常最实用的方法就是胜者。
- en: Note that due to resource constraints, researchers are not always involved in
    the prototyping phase. Frequently, data scientists do the research work as well
    as build the POC.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于资源限制，研究人员并不总是参与原型设计阶段。通常，数据科学家既做研究工作，也构建POC。
- en: 'You may also notice that in figure 1.1, there is an inner loop (loop A) in
    the big development cycle: Product Initiation > Data Exploration > Deep Learning
    Research > Prototyping > Model > Product Initiation. The purpose of this loop
    is to obtain product feedback in the early phase by building a POC model. We may
    run through this loop multiple times until all stakeholders (data scientists,
    product owners) arrive at a consensus on the algorithms and data that will be
    used to address the business requirement.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能也注意到，在图1.1中，在大开发周期中存在一个内部循环（循环A）：产品启动 > 数据探索 > 深度学习研究 > 原型设计 > 模型 > 产品启动。这个循环的目的是通过构建POC模型在早期阶段获取产品反馈。我们可能需要多次运行这个循环，直到所有利益相关者（数据科学家、产品负责人）就用于解决业务需求的算法和数据达成共识。
- en: 'Multiple hard lessons finally taught us that we must vet the solution with
    the product team or the customer (even better) before starting the expensive process
    of productionization—building production data and training pipelines and hosting
    models. The purpose of a deep learning project is no different from any other
    software development project: to solve a business need. Vetting the approach with
    the product team in the early stage will prevent the expensive and demoralizing
    process of reworking it in later stages.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 多次艰难的教训最终告诉我们，在开始昂贵的产业化过程——构建生产数据、训练管道和托管模型之前，我们必须与产品团队或客户（更好的是）对解决方案进行审查。深度学习项目的目的与其他任何软件开发项目并无不同：解决业务需求。在早期阶段与产品团队审查方法将防止在后期阶段进行昂贵且令人沮丧的重做过程。
- en: Productionization aka MLOps (5)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 产业化即MLOps（5）
- en: Productionization, also called “shipping to production,” is the process of making
    a product production worthy and ready to be consumed by its users. Production
    worthiness is commonly defined as being able to serve customer requests, withstand
    a certain level of request load, and gracefully handle adverse situations such
    as malformed input and request overload. Production worthiness also includes postproduction
    efforts, such as continuous model metric monitoring and evaluation, feedback gathering,
    and model retraining.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 生产化，也称为“产品化”，是将产品制作成适合用户消费的过程。生产性通常定义为能够服务客户请求，承受一定程度的请求负载，并优雅地处理不良情况，如输入错误和请求过载。生产性还包括后期工作，如持续模型指标监控和评估、反馈收集和模型重新训练。
- en: Productionization is the most engineering-intensive part of the development
    cycle because we’ll be converting prototyping experiments into serious production
    processes. A nonexhaustive to-do list of productionization can include
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 生产化是开发周期中最具工程密集型的部分，因为我们将会将原型实验转化为严肃的生产流程。生产化的待办事项清单可能包括：
- en: Building a data pipeline to pull data from different data sources repeatedly
    and keep the dataset versioned and updated.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立数据管道，从不同的数据源重复提取数据，并保持数据集版本化和更新。
- en: Building a data pipeline to preprocess dataset, such as data enhancement or
    enrichment and integrating with external labeling tools.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立数据管道以预处理数据集，例如数据增强或丰富，并集成外部标注工具。
- en: Refactoring and dockerizing the prototyping code to production-quality model
    training code.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将原型代码重构并转换为生产质量模型训练代码。
- en: Making the result of training and serving codes reproducible by versioning and
    tracking the inputs and outputs. For example, we could enable the training code
    to report the training metadata (training date and time, duration, hyperparameters)
    and model metadata (performance metrics, data, and code used) to ensure the full
    traceability of every model training run.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过版本控制和跟踪输入和输出，使训练和服务的代码结果可重现。例如，我们可以使训练代码报告训练元数据（训练日期和时间、持续时间、超参数）和模型元数据（性能指标、数据和使用的代码），以确保每次模型训练运行的完整可追溯性。
- en: Setting up continuous integration (Jenkins, GitLab CI) and continuous deployment
    to automate the code building, validation, and deployment.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置持续集成（Jenkins、GitLab CI）和持续部署，以自动化代码构建、验证和部署。
- en: Building a continuous model training and evaluation pipeline so the model training
    can automatically consume the latest dataset and produce models in a repeatable,
    auditable, and reliable manner.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立持续模型训练和评估管道，以便模型训练可以自动消耗最新的数据集，并以可重复、可审计和可靠的方式产生模型。
- en: Building a model deployment pipeline that automatically releases models that
    have passed the quality gate, so the model serving component can access them;
    `async` or real-time model prediction can be performed depending on the business
    requirements. The model serving component hosts the model and exposes it via a
    web API.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立模型部署管道，自动发布通过质量关卡验证的模型，以便模型服务组件可以访问它们；根据业务需求，可以进行`async`或实时模型预测。模型服务组件托管模型并通过Web
    API公开。
- en: Building continuous-monitoring pipelines that periodically assess the dataset,
    model, and model serving performance to detect potential feature drift (data distribution
    change) in dataset or model performance degradation (concept drifting) and alert
    developers or retrain the model.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立持续监控管道，定期评估数据集、模型和模型服务性能，以检测数据集或模型性能中的潜在特征漂移（数据分布变化）和性能退化（概念漂移），并提醒开发者或重新训练模型。
- en: 'These days, the productionization step has a new alias with buzz: MLOps (machine
    learning operation), which is a vague term, and its definition is ambiguous for
    researchers and professionals. We interpret MLOps to mean bridging the gap between
    model development (experimentation) and operations in production environments
    (Ops) to facilitate productionization of machine learning projects. An example
    might be streamlining the process of taking machine learning models to production
    and then monitoring and maintaining them.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这些天，生产化步骤有一个新的别名，带有炒作：MLOps（机器学习操作），这是一个模糊的术语，其定义对研究人员和专业人员来说是不明确的。我们将MLOps理解为在模型开发（实验）和生产环境中的操作（Ops）之间架起桥梁，以促进机器学习项目的生产化。一个例子可能是简化将机器学习模型推向生产并随后监控和维护的过程。
- en: 'MLOps is a paradigm rooted in the application of similar principles that DevOps
    has to software development. It leverages three disciplines: machine learning,
    software engineering (especially the operation), and data engineering. See figure
    1.2 for a look at deep learning through the lens of MLOps.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps是一种根植于DevOps应用于软件开发类似原则的范式。它利用三个学科：机器学习、软件工程（特别是操作）和数据工程。参见图1.2，了解通过MLOps视角看深度学习。
- en: '![](../Images/01-02.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/01-02.png)'
- en: 'Figure 1.2 MLOps applies DevOps approaches to deep learning for the productionization
    phase, when models get shipped to production. (Source: *Machine Learning Engineering
    in Action*, by Ben Wilson, Manning, 2022, figure 2.7)'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 MLOps将DevOps方法应用于深度学习的生产化阶段，当模型被部署到生产环境中。（来源：《Machine Learning Engineering
    in Action》，作者Ben Wilson，Manning，2022，图2.7）
- en: Because this book is about building machine learning systems that support ML
    operations, we won’t go into details about the practices shown in figure 1.2\.
    But, as you can see, the engineering effort that supports the development of machine
    learning models in production is huge. Compared to what data scientists used to
    do during the previous phase of data exploration and model prototyping, the tooling
    (software), engineering standards, and processes have dramatically changed and
    become much more complex.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书是关于构建支持ML操作的机器学习系统，我们不会深入探讨图1.2中展示的实践。但是，正如您所看到的，支持在生产中开发机器学习模型所需的工程工作量是巨大的。与数据科学家在数据探索和模型原型设计的前一阶段所做的工作相比，工具（软件）、工程标准和流程发生了巨大变化，变得更加复杂。
- en: Why is shipping models to production difficult?
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么将模型部署到生产如此困难？
- en: The massive underlying infrastructure (tools, services, servers) and heavy cross-team
    collaboration are the two biggest hurdles for shipping models to production. This
    section on productionization (aka MLOps) establishes that data scientists need
    to work with data engineers, platform developers, DevOps engineers, and machine
    learning engineers, as well as learn a massive infrastructure (deep learning system),
    to ship an algorithm/model from prototype to production. It's no wonder that productionizing
    a model takes so much time.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 巨大的底层基础设施（工具、服务、服务器）和跨团队的重型协作是部署模型到生产中的两大障碍。本节关于生产化（也称为MLOps）确立了数据科学家需要与数据工程师、平台开发者、DevOps工程师和机器学习工程师合作，以及学习大量的基础设施（深度学习系统），以将算法/模型从原型到生产进行部署。难怪模型的生产化需要花费如此多的时间。
- en: To solve these challenges, we need to abstract away the complexity from data
    scientists when designing and building a deep learning system. As with building
    a car, we want to put data scientists behind the wheel but without asking them
    to know much about the car itself.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些挑战，在设计构建深度学习系统时，我们需要从数据科学家那里抽象出复杂性。就像建造一辆汽车一样，我们希望将数据科学家放在驾驶座上，但不需要他们了解太多关于汽车本身的知识。
- en: Now, returning to the development cycle, you may notice there is *another* inner
    loop (loop B) in figure 1.1 that goes from Productionization (box 5) and Model
    to Product Initiation (box 1). This is the second vet with the product team before
    we integrate the model inference with an AI application.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，回到开发周期，您可能会注意到图1.1中存在另一个内部循环（循环B），它从生产化（框5）到模型到产品启动（框1）。这是在将模型推理与AI应用集成之前，与产品团队进行的第二次审查。
- en: Our second vet (loop B) compares the model and data between prototyping and
    production. We want to ensure the model performance and scalability (for example,
    model serving capacity) match business requirements.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二次审查（循环B）比较了原型和生产线之间的模型和数据。我们希望确保模型性能和可扩展性（例如，模型服务能力）符合业务需求。
- en: 'Note The following two papers are recommended; if you want to learn more about
    MLOps, they are great starting points: “Operationalizing Machine Learning: An
    Interview Study” (arXiv:2209.09125) and “Machine Learning Operations (MLOps):
    Overview, Definition, and Architecture” (arXiv:2205.02302).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '注意：以下两篇论文推荐；如果您想了解更多关于MLOps的信息，它们是很好的起点：“Operationalizing Machine Learning:
    An Interview Study”（arXiv:2209.09125）和“Machine Learning Operations (MLOps): Overview,
    Definition, and Architecture”（arXiv:2205.02302）。'
- en: Application integration (6)
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 应用集成（6）
- en: The last step of the product development cycle is to integrate the model prediction
    to the AI application. The common pattern is to host the models in the model serving
    service (which will be discussed in section 1.2.2) of the deep learning system
    and integrate the business application logic with the model by sending model prediction
    requests over the internet.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 产品开发周期的最后一步是将模型预测集成到人工智能应用程序中。常见的模式是在深度学习系统的模型服务（将在第1.2.2节中讨论）中托管模型，并通过发送模型预测请求通过互联网将业务应用程序逻辑与模型集成。
- en: As a sample user scenario, a chatbot user interacts with the chatbot user interface
    by typing or voicing questions. When the chatbot application receives input from
    the customer, it calls the remote model serving service to run a model prediction
    and then takes action or responds to the customer based on the model prediction
    result.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 作为样本用户场景，聊天机器人用户通过键入或语音提问与聊天机器人用户界面进行交互。当聊天机器人应用程序收到客户输入时，它将调用远程模型服务来运行模型预测，然后根据模型预测结果采取行动或对客户做出响应。
- en: Along with integrating model serving with application logic, this phase also
    involves evaluating metrics important to the product, such as clickthrough rate
    and churn rate. Nice ML-specific metrics (good precision–recall curve) do not
    always guarantee the business requirement is met. So the business stakeholders
    often perform customer interviews and product metric evaluation at this stage.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 除了将模型服务与应用逻辑集成外，此阶段还涉及评估对产品重要的一些指标，例如点击率和流失率。良好的机器学习特定指标（如良好的精确率-召回率曲线）并不总是保证满足业务需求。因此，业务利益相关者通常在此阶段进行客户访谈和产品指标评估。
- en: 1.1.2 Roles in the development cycle
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 开发周期中的角色
- en: Because you now have a clear idea of each step in a typical development cycle,
    let’s look at the key roles that collaborate in this cycle. The definitions, job
    titles, and responsibilities of each role may vary across organizations. So make
    sure you clarify who does what in your organization and adjust your system’s design
    appropriately.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因为您现在对典型开发周期的每个步骤都有一个清晰的认识，让我们看看在这个周期中协作的关键角色。每个角色的定义、职位名称和职责可能因组织而异。所以请确保您明确了解您组织中的职责分配，并相应地调整您的系统设计。
- en: Business stakeholders (product owner)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 业务利益相关者（产品负责人）
- en: 'Many organizations assign the stakeholder role to multiple positions, such
    as product managers, engineering managers, and senior developers. Business stakeholders
    define the business goal of a product and are responsible for communication and
    execution of the product development cycle. The following are their responsibilities:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 许多组织将利益相关者角色分配给多个职位，例如产品经理、工程经理和高级开发者。业务利益相关者定义产品的业务目标，并负责产品开发周期的沟通和执行。以下是他们职责的概述：
- en: Getting inspiration from deep learning research, discussing potential application
    of deep learning features in products, and driving product requirements that in
    turn drive model development
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从深度学习研究中获得灵感，讨论深度学习特性在产品中的潜在应用，并推动产品需求，进而推动模型开发
- en: Owning the product! Communicating with customers and making sure the engineering
    solution meets the business requirement and delivers the results
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有产品！与客户沟通，确保工程解决方案满足业务需求并交付结果
- en: Coordinating cross-functional collaborations between different roles and teams
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协调不同角色和团队之间的跨职能协作
- en: Running project development execution; providing guidance or feedback during
    the entire development cycle to ensure the deep learning features offer real value
    to the customers of the product
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行项目开发执行；在整个开发周期中提供指导或反馈，以确保深度学习特性能为产品的客户提供真实价值
- en: Evaluating the product metrics (such as user churn rate and feature usage)—not
    the model metrics (precision or accuracy)—and driving improvement of model development,
    productionization, or product integration
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估产品指标（如用户流失率和功能使用情况）——而不是模型指标（精确率或准确率）——并推动模型开发、生产化或产品集成的改进
- en: Researchers
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员
- en: Machine learning researchers research and develop new and novel neural network
    architectures. They also develop techniques for improving model accuracy and efficiency
    in training models. These architectures and techniques can be used during model
    development.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习研究人员研究和开发新的、创新的神经网络架构。他们还开发提高模型在训练过程中的准确性和效率的技术。这些架构和技术可以在模型开发中使用。
- en: Note The machine learning researcher role is often associated with big tech
    companies like Google, Microsoft, and Salesforce. In many other companies, data
    scientists fulfill the same role.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：机器学习研究者的角色通常与像谷歌、微软和Salesforce这样的大型科技公司相关联。在许多其他公司，数据科学家承担着相同角色。
- en: Data scientists
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家
- en: Data scientists may wear a research hat, but most of the time, they translate
    a business problem into a machine learning problem and implement it using machine
    learning methods. Data scientists are motivated by the product’s need and apply
    research techniques to production data rather than standard benchmark datasets.
    Besides researching model algorithms, a data scientist’s responsibilities may
    also include
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家可能戴着研究者的帽子，但大多数时候，他们将业务问题转化为机器学习问题，并使用机器学习方法实现它。数据科学家受产品需求驱动，将研究技术应用于生产数据，而不是标准基准数据集。除了研究模型算法外，数据科学家的职责可能还包括
- en: Combining multiple deep learning neural network architectures and/or techniques
    from different research into a solution. Sometimes they apply additional machine
    learning techniques besides pure deep learning.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将多个深度学习神经网络架构和/或来自不同研究的技术结合成一个解决方案。有时他们除了纯深度学习之外，还会应用额外的机器学习技术。
- en: Exploring available data, determining what data is useful, and deciding on how
    to preprocess it before supplying it for training.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索可用数据，确定哪些数据是有用的，并在提供用于训练之前决定如何预处理它。
- en: Prototyping different approaches (writing experimental code) to tackle the business
    problem.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过编写实验代码来原型化不同的方法（解决业务问题）。
- en: Converting model prototyping code into production code with workflow automation.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型原型代码转换为生产代码，并使用工作流程自动化。
- en: Following the engineering process to ship models to production by using the
    deep learning system.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用深度学习系统遵循工程流程将模型部署到生产环境中。
- en: Iterating on the need for any additional data that may help with model development.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复评估可能有助于模型开发的额外数据需求。
- en: Continuously monitoring and evaluating data and model performance in production.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续监控和评估生产中的数据和模型性能。
- en: Troubleshooting model-related problems, such as model degradation.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 排查与模型相关的问题，例如模型退化。
- en: Data engineers
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师
- en: Data engineers help collect data and set up data pipelines for continuous data
    ingestion and processing, including data transformation, enrichment, and labeling.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师帮助收集数据并设置数据管道，以实现连续的数据摄取和处理，包括数据转换、增强和标记。
- en: MLOps engineer/ML engineer
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps工程师/ML工程师
- en: An MLOps engineer fulfills a number of roles across multiple domains, including
    that of data engineer, DevOps (operation) engineer, data scientist, and platform
    engineer. As well as setting up and operating the machine learning infrastructure
    (both systems and hardware), they manage automation pipelines to create datasets
    and train and deploy models. ML infrastructures and user activities, such as training
    and serving, are also monitored by MLOps engineers.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps工程师在多个领域扮演着多种角色，包括数据工程师、DevOps（运维）工程师、数据科学家和平台工程师。他们不仅负责设置和运营机器学习基础设施（包括系统和硬件），还管理自动化管道以创建数据集、训练和部署模型。MLOps工程师还负责监控机器学习基础设施和用户活动，如训练和部署。
- en: As you can see, MLOps is hard, because it requires people to master a set of
    practices across software development, operation, maintenance, and machine learning
    development. MLOps engineers’ goal is to ensure the creation, deployment, monitoring,
    and maintenance of machine learning models are efficient and reliable.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，MLOps很困难，因为它要求人们掌握软件开发、运维、维护和机器学习开发的一系列实践。MLOps工程师的目标是确保机器学习模型的创建、部署、监控和维护既高效又可靠。
- en: Deep learning system/platform engineer
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习系统/平台工程师
- en: Deep learning system engineers build and maintain the general pieces of the
    machine learning infrastructure—the primary focus of this book—to support all
    the machine learning development activities for data scientists, data engineers,
    MLOps engineers, and AI applications. Among the components of the machine learning
    system are data warehouses, compute platforms, workflow orchestration services,
    model metadata and artifact stores, model training services, model serving services,
    and more.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习系统工程师构建和维护机器学习基础设施的一般组件——本书的主要焦点，以支持数据科学家、数据工程师、MLOps工程师和AI应用的所有机器学习开发活动。机器学习系统的组件包括数据仓库、计算平台、工作流程编排服务、模型元数据和工件存储、模型训练服务、模型部署服务等等。
- en: Application engineer
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 应用工程师
- en: Application engineers build customer-facing applications (both frontend and
    backend) to address given business requirements. The application logic will make
    decisions or take actions based on the model prediction for a given customer request.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 应用工程师构建面向客户的程序（包括前端和后端），以满足给定的业务需求。应用程序逻辑将根据给定的客户请求对模型预测做出决策或采取行动。
- en: Note In the future, as machine learning systems (infrastructure) mature, the
    roles involved in deep learning development cycle will merge into fewer and fewer.
    Eventually, data scientists will be able to complete the entire cycle on their
    own.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在未来，随着机器学习系统（基础设施）的成熟，涉及深度学习开发周期的角色将越来越少地合并。最终，数据科学家将能够独立完成整个周期。
- en: 1.1.3 Deep learning development cycle walk-through
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.3 深度学习开发周期概述
- en: 'By giving an example, we can demonstrate the roles and the process in a more
    concrete manner. Suppose you have been assigned the task of building a customer
    support system that answers questions automatically about the company’s product
    lines. The following steps will guide you through the process of bringing that
    product to market:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通过举一个例子，我们可以更具体地展示角色和过程。假设你被分配了一个任务，即构建一个自动回答公司产品线问题的客户支持系统。以下步骤将指导你完成将此产品推向市场的过程：
- en: The product requirement is to build a customer support application that presents
    a menu, so customers can navigate to find answers to commonly asked questions.
    As the number of questions grows, the menu becomes larger, with many layers of
    navigation. Analytics has shown that many customers are confused by the navigation
    system and drop off from navigating the menu while trying to find answers.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 产品需求是构建一个客户支持应用程序，该程序提供一个菜单，以便客户可以导航以找到常见问题的答案。随着问题数量的增加，菜单变得更大，有多个导航层级。分析显示，许多客户被导航系统搞糊涂了，在试图找到答案时放弃了导航菜单。
- en: The product manager (PM) who owns the product is motivated to improve the user
    retention rate and experience (finding the answers quickly). After conducting
    some research with customers, the PM finds that a majority of customers would
    like to obtain answers without a complex menu system, preferably as simple as
    asking questions in their natural language.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 负责产品的产品经理（PM）有动力提高用户留存率和体验（快速找到答案）。在进行了客户调研后，PM发现大多数客户希望在没有复杂的菜单系统的情况下获得答案，最好是像用自然语言提问一样简单。
- en: The PM reaches out to machine learning researchers for a potential solution.
    It turns out that deep learning may help. Experts think the technology is mature
    enough for this use case and suggest a few approaches based on deep learning models.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PM联系机器学习研究人员寻求可能的解决方案。结果发现深度学习可能有所帮助。专家认为这项技术对于这个用例来说已经足够成熟，并基于深度学习模型提出了一些建议。
- en: The PM writes a product spec indicating that the application should take one
    question from a customer at a time, recognize intent from the question, and match
    it with relevant answers.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PM编写产品规范，指出应用程序应一次处理一个客户的问题，从问题中识别意图，并将其与相关答案匹配。
- en: Data scientists receive product requirements and start to prototype deep learning
    models that fit the need. They first start data exploration to collect available
    training data and consult with researchers for the choices of algorithms. And
    then data scientists start to build prototyping code to produce experimental models.
    Eventually, they arrive at some datasets, a few training algorithms, and several
    models. After careful evaluation, one natural language process model is selected
    from various experiments.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据科学家接收到产品需求，开始原型设计适合需求的深度学习模型。他们首先开始数据探索，收集可用的训练数据，并与研究人员咨询算法选择。然后，数据科学家开始编写原型代码以产生实验模型。最终，他们获得了一些数据集、几个训练算法和几个模型。经过仔细评估，从各种实验中选出一个自然语言处理模型。
- en: Then the PM assembles a team of platform engineers, MLOps engineers, and data
    engineers to work with the data scientist to onboard the prototyping code, made
    in step 5, to production. The work includes building a continuous data processing
    pipeline and a continuous model training, deployment, and evaluation pipeline,
    as well as setting up the model serving functionality. The PM also specifies the
    number of predictions per second and the latency required.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，项目经理组建了一个由平台工程师、MLOps工程师和数据工程师组成的团队，与数据科学家合作，将第5步中制作的原型代码投入生产。这项工作包括构建持续的数据处理管道和持续模型训练、部署和评估管道，以及设置模型服务功能。项目经理还指定了每秒的预测次数和所需的延迟。
- en: Once a production setup is complete, the application engineers integrate the
    customer support service’s backend with the model serving service (built in step
    6), so when a user types in a question, the service will return answers based
    on the model prediction. The PM also defines product metrics, such as average
    time spent finding an answer, to evaluate the end result and use it to drive the
    next round of improvement.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦完成生产设置，应用工程师将客户支持服务的后端与第6步中构建的模型服务服务（模型服务）集成，因此当用户输入问题时，服务将根据模型预测返回答案。项目经理还定义了产品指标，例如找到答案的平均时间，以评估最终结果并用于推动下一轮改进。
- en: 1.1.4 Scaling project development
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.4 项目开发扩展
- en: As you saw in section 1.1.2, we need to fill seven different roles to complete
    a deep learning project. The cross-functional collaboration between these roles
    happens at almost every step. For example, data engineers, platform developers,
    and data scientists work together to productionize a project. Anyone who has been
    involved in a project that requires many stakeholders knows how much communication
    and coordination are required to keep a project like this moving forward.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在1.1.2节中看到的，我们需要扮演七个不同的角色来完成一个深度学习项目。这些角色之间的跨职能协作几乎在每个步骤都会发生。例如，数据工程师、平台开发人员和数据科学家会一起合作将项目投入生产。任何参与过需要许多利益相关者的项目的人都知道，为了使这样的项目顺利进行，需要多少沟通和协调。
- en: These challenges make deep learning development hard to scale because we either
    don’t have the resources to fill all the required roles or we can’t meet the product
    timeline due to the communication costs and slowdowns. To reduce the enormous
    amount of operational work, communication, and cross-team coordination costs,
    companies are investing in machine learning infrastructure and reducing the number
    of people and the scope of knowledge required to build a machine learning project.
    The goal of a deep learning infrastructure stack is not only to automate model
    building and data processing but also to make it possible to merge the technical
    roles so that the data scientist is empowered to take care of all these functions
    autonomously within a project.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这些挑战使得深度学习开发难以扩展，因为我们要么没有资源来填补所有必需的角色，要么由于沟通成本和延误而无法满足产品时间表。为了减少大量的运营工作、沟通和跨团队协调成本，公司正在投资于机器学习基础设施，并减少构建机器学习项目所需的人员数量和知识范围。深度学习基础设施堆栈的目标不仅是为了自动化模型构建和数据处理，而且是为了使技术角色能够合并，以便数据科学家能够在项目内部自主处理所有这些功能。
- en: A key success indicator of a deep learning system is to see how smooth the model
    productionization process can be. With a good infrastructure, the data scientist,
    who is not expected to suddenly become an expert DevOps or data engineer, should
    be able to implement models in a scalable manner, set up data pipelines, and deploy
    and monitor models in production independently.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习系统的一个关键成功指标是看到模型生产化过程可以有多顺畅。有了良好的基础设施，数据科学家不应该突然成为专家DevOps或数据工程师，他们应该能够以可扩展的方式实施模型，设置数据管道，并独立地在生产中部署和监控模型。
- en: By using an efficient deep learning system, data scientists will be able to
    complete the development cycle with minimal additional overhead—less communication
    required and less time wasted waiting by others—and focus on the most important
    data science tasks, such as understanding the data and experimenting with algorithms.
    The ability to scale deep learning project development is the true value proposition
    of a deep learning system.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用高效的深度学习系统，数据科学家将能够以最小的额外开销完成开发周期——所需的沟通更少，等待他人浪费的时间更少——并专注于最重要的数据科学任务，例如理解数据和实验算法。能够扩展深度学习项目开发是深度学习系统的真正价值主张。
- en: 1.2 Deep learning system design overview
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 深度学习系统设计概述
- en: 'With the context of section 1.1 in mind, let’s dive into the focus of this
    book: the deep learning system itself. Designing a system—any system—is the art
    of achieving goals under a set of constraints that are unique to your situation.
    This is also true for deep learning systems. For instance, let’s say you have
    a few deep learning models that need to be served at the same time, but your budget
    does not allow you to operate a machine that has enough memory to fit all of them
    at the same time. You may need to design a caching mechanism to swap models between
    memory and disk. Swapping, however, will increase inference latency. Whether this
    solution is feasible will depend on latency requirements. Another possibility
    is to operate multiple smaller machines for each model, if your model sizes and
    budget will allow it.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到1.1节的背景，让我们深入探讨本书的重点：深度学习系统本身。设计一个系统——任何系统——是在一组独特的约束条件下实现目标的艺术。这对深度学习系统也是如此。例如，假设您有一些需要同时服务的深度学习模型，但您的预算不允许您运行一个有足够内存同时容纳所有这些模型的机器。您可能需要设计一个缓存机制，在内存和磁盘之间交换模型。然而，交换会增加推理延迟。这种解决方案是否可行将取决于延迟要求。另一种可能性是，如果您的模型大小和预算允许，为每个模型运行多个较小的机器。
- en: Or, for another example, imagine your company’s product must comply with certain
    certification standards. It may mandate data access policies that pose significant
    limitations to anyone who wants to gain access to data collected by the company’s
    product. You may need to design a framework to allow data access in a compliant
    fashion so that researchers, data scientists, and data engineers can troubleshoot
    problems and develop new models that require such data access in your deep learning
    system.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，以另一个例子来说，假设你们公司的产品必须符合某些认证标准。这可能要求制定数据访问策略，对任何想要访问公司产品收集的数据的人来说，这些策略可能带来重大限制。你可能需要设计一个框架，以便以合规的方式允许数据访问，这样研究人员、数据科学家和数据工程师就可以解决您深度学习系统中的问题，并开发需要此类数据访问的新模型。
- en: As you can see, there are many knobs that can be turned. It will certainly be
    an iterative process to arrive at a design that will satisfy as many requirements
    as possible. But to shorten the iterative process, it is desirable to start with
    a design that is as close to the end state as possible.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，有许多可调节的旋钮。达到一个尽可能满足所有要求的设计肯定是一个迭代的过程。但为了缩短迭代过程，最好从一个尽可能接近最终状态的设计开始。
- en: In this section, we first propose a deep learning system design with only essential
    components and then explain the responsibility of each of the components and user
    workflows. In our experience of designing and tailoring deep learning systems,
    a few key components are common across different designs. We think that they can
    be used as a reasonable starting point for your design. We call this the *reference
    system architecture*.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们首先提出一个仅包含基本组件的深度学习系统设计，然后解释每个组件的责任和用户工作流程。根据我们设计和定制深度学习系统的经验，一些关键组件在不同设计中是通用的。我们认为它们可以作为您设计的合理起点。我们称之为*参考系统架构*。
- en: You can make a copy of this reference for your design project, go through your
    list of goals and constraints, and start by identifying knobs in each component
    that you can adjust to your needs. Because this isn’t an authoritative architecture,
    you should also assess whether all components are really necessary and add or
    remove components as you see fit.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以为您的项目复制这份参考，审视您的目标和约束列表，并从识别每个组件中您可以调整以满足您需求的旋钮开始。因为这不是一个权威的架构，您还应该评估所有组件是否真的必要，并根据您的判断添加或删除组件。
- en: 1.2.1 Reference system architecture
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 参考系统架构
- en: 'Figure 1.3 shows the high-level overview of the reference deep learning system.
    The deep learning system has two major parts. The first is the application programming
    interface (API; box A) for the system, located in the middle of the diagram. The
    second is the collection of components of the deep learning system, which is represented
    by all the rectangular boxes located within the large box, outlined in a dotted
    line and taking up the lower half of the diagram. These boxes each represent a
    system component:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3显示了参考深度学习系统的高级概述。深度学习系统有两个主要部分。第一部分是系统的应用程序编程接口（API；框A），位于图的中部。第二部分是深度学习系统的组件集合，由所有位于大框内、用虚线勾勒并占据图下半部分的矩形框表示。这些框中的每一个代表一个系统组件：
- en: API (box A)
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API（框A）
- en: Dataset manager (box B)
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集管理器（框B）
- en: Model trainer (box C)
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练器（框C）
- en: Model serving (box D)
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型服务（框D）
- en: Metadata and artifacts store (box E)
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据和工件存储（框E）
- en: Workflow orchestration (box F)
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流程编排（框F）
- en: Interactive data science environment (box G)
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交互式数据科学环境（框G）
- en: In this book, we assume that these system components are *microservices*.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们假设这些系统组件是**微服务**。
- en: '![](../Images/01-03.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/01-03.png)'
- en: Figure 1.3 An overview of a typical deep learning system that includes basic
    components to support a deep learning development cycle. This reference architecture
    can be used as a starting point and further tailored. In later chapters, we discuss
    each component in detail and explain how it fits into this big picture.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 一个典型的深度学习系统概述，包括支持深度学习开发周期的基本组件。这个参考架构可以作为起点，并进一步定制。在后面的章节中，我们将详细讨论每个组件，并解释它如何融入这个大局。
- en: Definition There is no single definition for microservices. Here, we will use
    the term to mean processes that communicate over a network with the HTTP or the
    gRPC protocol.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 对于微服务并没有一个统一的定义。在这里，我们将使用这个术语来指代通过HTTP或gRPC协议在网络中通信的进程。
- en: This assumption means we can expect these components to reasonably support multiple
    users with different roles securely and are readily accessible over a network
    or the internet. (This book, however, will not cover all engineering aspects of
    how microservices are designed or built. We will focus our discussion on specifics
    that are relevant to deep learning systems.)
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个假设意味着我们可以期待这些组件能够合理地支持具有不同角色的多个用户，并且可以安全地通过网络或互联网访问。（然而，这本书不会涵盖微服务设计或构建的所有工程方面。我们将专注于与深度学习系统相关的具体内容。）
- en: NOTE You may wonder whether you need to design, build, and host all deep learning
    system components on your own. Indeed, there are open source (Kubeflow) and hosted
    alternatives (Amazon SageMaker) for them. We hope that after you have learned
    the fundamentals of each component, how they fit in the big picture, and how they
    are used by different roles, you will make the best decision for your use case.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 你可能会想知道是否需要自己设计、构建和托管所有深度学习系统组件。确实，对于它们有开源（Kubeflow）和托管替代方案（Amazon SageMaker）。我们希望在你学习了每个组件的基本原理、它们如何融入大局以及它们如何被不同角色使用之后，你能为你的用例做出最佳决策。
- en: 1.2.2 Key components
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 关键组件
- en: Now let’s walk through the key components that we consider essential to a basic
    deep learning system, as shown in figure 1.3\. You may want to add additional
    components or simplify them further as you see fit for your requirements.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来了解一下我们认为对基本深度学习系统至关重要的关键组件，如图1.3所示。你可能需要根据你的需求添加额外的组件或进一步简化它们。
- en: Application programming interface
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序编程接口
- en: The entry point (box A in figure 1.3) of our deep learning system is an API
    that is accessible over a network. We opted for an API because the system needs
    to support not only graphical user interfaces that will be used by researchers,
    data scientists, data engineers, and the like but also applications and possibly
    other systems—for example, a data warehouse from a partner organization.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们深度学习系统的入口点是一个可以通过网络访问的API。我们选择API是因为系统需要支持不仅研究人员、数据科学家、数据工程师等将使用的图形用户界面，还需要应用程序和可能的其他系统——例如，来自合作伙伴组织的数据仓库。
- en: Although conceptually the API is the single point of entry of the system, it
    is entirely possible that the API is defined as the sum of all APIs provided by
    each component, without an extra layer that aggregates everything under a single-service
    endpoint. Throughout this book, we will use the sum of all APIs provided by each
    component directly and skip the aggregation for simplicity.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然从概念上讲，API是系统的唯一入口点，但完全有可能API被定义为每个组件提供的所有API的总和，而没有额外的一层来聚合所有内容到一个单一的服务端点。在这本书中，我们将直接使用每个组件提供的所有API的总和，为了简化起见，我们将跳过聚合。
- en: Note Should you use a centralized or distributed deep learning system API? In
    the reference architecture (figure 1.3), the deep learning system API is shown
    as a single box. It should be interpreted as a logical container for the complete
    set of your deep learning system API, regardless of whether it is implemented
    on single (e.g., an API gateway that proxies for all components) or multiple service
    endpoints (direct interaction with each component). Each implementation has its
    own merits and shortcomings, and you should work with your team to figure out
    what functions best. Direct interaction with each component may be easier if you
    start with a small use case and team.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您应该使用集中式还是分布式深度学习系统API？在参考架构（图1.3）中，深度学习系统API被显示为一个单独的框。它应该被解释为包含您完整深度学习系统API的逻辑容器，无论它是基于单个（例如，代理所有组件的API网关）还是多个服务端点（直接与每个组件交互）。每种实现都有其优点和缺点，您应该与您的团队合作，找出最适合您的方案。如果您从一个小的用例和团队开始，直接与每个组件交互可能更容易。
- en: Dataset manager
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集管理器
- en: Deep learning is based on data. There is no doubt that the data management component
    is a central piece of a deep learning system. Every learning system is a garbage-in,
    garbage-out system, so ensuring good data quality for learning is of paramount
    importance. A good data management component should provide the solution to this
    problem. It enables collecting, organizing, describing, and storing data, which
    in turn makes it possible for data to be explored, labeled, and used for training
    models.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习基于数据。毫无疑问，数据管理组件是深度学习系统的一个核心部分。每个学习系统都是一个垃圾进、垃圾出的系统，因此确保学习数据质量至关重要。一个好的数据管理组件应该提供解决这个问题的方案。它能够收集、组织、描述和存储数据，从而使得数据可以被探索、标记并用于训练模型。
- en: 'In figure 1.3, we can see at least four relationships of the dataset manager
    (box B) with other parties:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在图1.3中，我们可以看到数据集管理器（框B）与其他各方至少有四种关系：
- en: Data collectors push raw data to the dataset manager to create or update datasets.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据收集者将原始数据推送到数据集管理器以创建或更新数据集。
- en: The workflow orchestration service (box F) executes the data process pipeline,
    which pulls data from the dataset manager to enhance the training dataset or transform
    the data format and pushes the result back.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流程编排服务（框F）执行数据处理管道，它从数据集管理器中提取数据以增强训练数据集或转换数据格式，并将结果推回。
- en: Data scientists, researchers, and data engineers use Jupyter Notebook (box G)
    to pull data from the data manager for data exploration and examination.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家、研究人员和数据工程师使用Jupyter Notebook（框G）从数据管理器中提取数据用于数据探索和检查。
- en: The model training service (box C) pulls training data from the data manger
    for model training.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练服务（框C）从数据管理器中提取训练数据用于模型训练。
- en: In chapter 2, we will discuss dataset management in depth. Throughout the book,
    we use the term *dataset* as a unit of collected data that may be related.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二章中，我们将深入讨论数据集管理。在整个书中，我们使用术语“数据集”来表示可能相关的收集数据单元。
- en: Model trainer
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练器
- en: Model trainer (aka, model training service; box C) responds to provide foundational
    computation resources, such as CPUs, RAM, and GPUs, and job management logics
    to run the model training code and produce model files. In figure 1.3, we can
    see that the workflow orchestration service (box F) tells the model trainer to
    execute a model training code. The trainer takes input training data from the
    dataset manager (box B) and produces a model. Then it uploads the model with training
    metrics and metadata to the metadata and artifacts store (box E).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练器（又称模型训练服务；框C）响应提供基础计算资源，例如CPU、RAM和GPU，以及作业管理逻辑来运行模型训练代码并生成模型文件。在图1.3中，我们可以看到工作流程编排服务（框F）告诉模型训练器执行模型训练代码。训练器从数据集管理器（框B）获取输入训练数据并生成模型。然后，它将带有训练指标和元数据的模型上传到元数据和工件存储（框E）。
- en: 'It is usually necessary to perform intense computation on a large dataset to
    produce high-quality deep learning models that can make accurate predictions.
    Adoption of new algorithms and training libraries/frameworks is also a critical
    requirement. These requirements produce challenges on several levels:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 通常需要对大型数据集进行密集计算，以生成高质量的深度学习模型，这些模型可以做出准确的预测。采用新算法和训练库/框架也是一个关键要求。这些要求在多个层面上产生了挑战：
- en: '*Capability of reducing model training time*—Despite the growing size of training
    data and complexity of model architecture, training systems must keep training
    times reasonable.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*减少模型训练时间的能力*—尽管训练数据量和模型架构的复杂性不断增长，训练系统必须保持合理的训练时间。'
- en: '*Horizontal scalability*—An effective production training system should be
    able to support multiple training requests from different applications and users
    simultaneously.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*水平可扩展性*—一个有效的生产训练系统应该能够同时支持来自不同应用程序和用户的多个训练请求。'
- en: '*Cost of adopting new technologies*—The deep learning community is a vigorous
    one, with constant updates and improvements to algorithms and tooling (SDK, framework).
    The training system should be flexible enough to accommodate new innovations easily
    without interfering with the existing workload.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*采用新技术的成本*—深度学习社区是一个充满活力的社区，算法和工具（SDK、框架）不断更新和改进。训练系统应该足够灵活，以便轻松适应新的创新，而不会干扰现有的工作负载。'
- en: In chapter 3, we will investigate different approaches to solving the aforementioned
    problems. We will not go deep into the theoretical aspect of training algorithms
    in this book, as they do not affect how we design the system. In chapter 4, we
    will look at how we can distribute training to accelerate the process. In chapter
    5, we will explore a few different approaches for optimizing training hyperparameters.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3章中，我们将研究解决上述问题的不同方法。本书不会深入探讨训练算法的理论方面，因为它们不会影响我们设计系统的方式。在第4章中，我们将探讨如何分布训练以加速过程。在第5章中，我们将探索优化训练超参数的几种不同方法。
- en: Model serving
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 模型服务
- en: 'Models can be used in various settings, such as online inference for real-time
    predictions or offline inference for batch predictions using large volumes of
    input data. This is where model serving surfaces—when a system hosts the model,
    takes input prediction requests, runs model prediction, and returns the prediction
    to users. There are a few key questions to be answered:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以在各种环境中使用，例如在线推理用于实时预测或离线推理用于使用大量输入数据的批量预测。这就是模型服务出现的地方——当系统托管模型，接收输入预测请求，运行模型预测，并将预测结果返回给用户时。有几个关键问题需要回答：
- en: Are your inference requests coming from over the network? Or are they coming
    from sensors that need to be served locally?
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的推理请求是从网络上来的吗？还是来自需要本地服务的传感器？
- en: What is an acceptable latency? Are inference requests ad hoc or streaming?
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可接受的延迟是多少？推理请求是临时的还是流式的？
- en: How many models are being served? Is each model individually serving a type
    of inference request, or is an ensemble of models doing so?
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正在服务的模型有多少？每个模型是否单独服务一种推理请求，或者是由模型集合来这样做？
- en: How large are model sizes? How much memory capacity do you need to budget?
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型有多大？你需要预留多少内存容量？
- en: What model architectures need to be supported? Does it require a GPU? How much
    computing resources do you need to produce inferences? Are there other supporting
    serving components—for example, embeddings, normalization, aggregation, etc.?
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要支持哪些模型架构？是否需要GPU？你需要多少计算资源来产生推理？是否有其他支持服务组件，例如嵌入、归一化、聚合等？
- en: Are there sufficient resources to keep models online? Or is a swapping (such
    as moving models between memory and disk) strategy needed?
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有足够的资源来保持模型在线？或者是否需要交换（例如在内存和磁盘之间移动模型）策略？
- en: From figure 1.3, the main input and output of the model serving (box D) are
    inference requests and the prediction returned, respectively. To produce inferences,
    models are retrieved from the metadata and artifacts store (box E). Some requests
    and their responses may be logged and sent to the model monitoring and evaluation
    service (not shown in figure 1.3 or covered in this book), which detects anomalies
    from this data and produces alerts. In chapters 6 and 7, we will go deeper into
    model serving architecture, explore these key aspects, and discuss their solutions.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 从图1.3中可以看出，模型服务的主要输入和输出分别是推理请求和返回的预测。为了产生推理，模型从元数据和工件存储（框E）中检索。一些请求及其响应可能会被记录并发送到模型监控和评估服务（图1.3中未显示或本书中未涉及），该服务从这些数据中检测异常并产生警报。在第6章和第7章中，我们将更深入地探讨模型服务架构，探讨这些关键方面，并讨论其解决方案。
- en: Metadata and artifacts store
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据和工件存储
- en: Imagine working on a simple deep learning application as a one-person team,
    where you have to work with only a few datasets and train and deploy only one
    type of model. You can probably keep track of how datasets, training codes, models,
    inference codes, and inferences are related to one another. These relationships
    are essential for model development and troubleshooting as you need to be able
    to trace certain observations back to the cause.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下作为一个单人团队在简单的深度学习应用中工作，你只能处理少量数据集，并且只训练和部署一种类型的模型。你可能能够追踪数据集、训练代码、模型、推理代码和推理之间的关系。这些关系对于模型开发和故障排除至关重要，因为你需要能够将某些观察结果追溯到其根本原因。
- en: Now imagine adding more applications, more people, and more model types. The
    number of these relationships will grow exponentially. In a deep learning system
    that is designed to support multiple types of users working on multiple datasets,
    code, and models at various stages, there is a need for a component that keeps
    track of the web of relationships. The metadata and artifacts store in a deep
    learning system does just that. Artifacts include code that trains models and
    produces inferences, as well as any generated data such as trained models, inferences,
    and metrics. Metadata is any data that describes an artifact or the relationship
    between artifacts. Some concrete examples are
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下增加更多应用程序、更多人员和更多模型类型。这些关系的数量将以指数级增长。在一个旨在支持多种类型用户在多个数据集、代码和模型的不同阶段工作的深度学习系统中，需要一个能够跟踪关系网络的组件。深度学习系统中的元数据和工件存储库正是如此。工件包括训练模型和产生推理的代码，以及任何生成的数据，如训练模型、推理和指标。元数据是描述工件或工件之间关系的任何数据。一些具体的例子包括
- en: The author and version of a piece of training code
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一段训练代码的作者和版本
- en: A reference of the input training dataset and the training environment of a
    trained model
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型的输入训练数据集和训练环境的参考
- en: Training metrics of a trained model, such as training date and time, duration,
    and the owner of the training job
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型的训练指标，例如训练日期和时间、持续时间以及训练作业的所有者
- en: Model-specific metrics, such as model version, model lineage (data and code
    used in training), and performance metrics
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型特定的指标，例如模型版本、模型血统（用于训练的数据和代码）以及性能指标
- en: The model, request, and inference code that produce a certain inference
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产生特定推理的模型、请求和推理代码
- en: Workflow history, tracking each step of the model training and data process
    pipeline runs
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流程历史，跟踪模型训练和数据流程管道运行的每一步
- en: These are just a few examples of what a baseline metadata and artifacts store
    would help track. You should tailor the component to the needs of your team or
    organization.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是基线元数据和工件存储库可以帮助跟踪的几个例子。你应该根据团队或组织的需要调整该组件。
- en: Every other component that generates metadata and artifacts in figure 1.3 would
    flow into the metadata and artifacts store (box E). The store also plays an important
    role in model serving because it provides model files and their metadata to the
    model serving service (box D). Although not shown in the figure, custom tools
    for trace lineage and troubleshooting are usually built at the user interface
    layer, powered by the metadata and artifacts store.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3中生成元数据和工件的每个其他组件都会流入元数据和工件存储库（框E）。存储库在模型服务中也发挥着重要作用，因为它为模型服务服务提供模型文件及其元数据（框D）。尽管图中没有显示，但用于跟踪血统和故障排除的自定义工具通常在用户界面层构建，由元数据和工件存储库提供支持。
- en: As we proceed through chapter 8, we will look at a baseline metadata and artifacts
    store. This store is usually the central component of a deep learning system’s
    user interface.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们进入第8章，我们将探讨一个基线元数据和工件存储库。这个存储库通常是深度学习系统用户界面的核心组件。
- en: Workflow orchestration
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程编排
- en: Workflow orchestration (figure 1.3, box F) is ubiquitous in many systems, where
    it helps to automatically launch computation tasks triggered by programmatic conditions.
    In the context of a machine learning system, the workflow orchestration is the
    driving force behind all the automations running in a deep learning system. It
    allows people to define workflows or pipelines—directed acyclic graphs (DAGs)—to
    glue individual tasks together with an execution order. The workflow orchestration
    component orchestrates the task executions of these workflows. Some typical examples
    are
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程编排（如图1.3中的框F）在许多系统中无处不在，它有助于自动启动由程序性条件触发的计算任务。在机器学习系统的背景下，工作流程编排是驱动深度学习系统中所有自动化运行的驱动力。它允许人们定义工作流程或管道——有向无环图（DAGs）——以执行顺序将单个任务连接起来。工作流程编排组件编排这些工作流程的任务执行。一些典型的例子包括
- en: Launching model training whenever a new dataset is built
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每当构建新的数据集时启动模型训练
- en: Monitoring upstream data sources, augmenting new data, transferring its format,
    notifying external labelers, and merging the new data into existing datasets
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控上游数据源，增强新数据，转换其格式，通知外部标签员，并将新数据合并到现有数据集中
- en: Deploying the trained model to the model server if it passes some accepted criteria
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果训练的模型通过某些可接受的准则，则将其部署到模型服务器
- en: Continually monitoring model performance metrics and alerting developers when
    degradation is detected
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续监控模型性能指标，并在检测到退化时向开发者发出警报
- en: You will learn how to build or set up a workflow orchestration system in chapter
    9.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在第9章中学习如何构建或设置工作流程编排系统。
- en: Interactive data science environment
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 交互式数据科学环境
- en: Customer data and models cannot be downloaded to a local workstation from production
    for compliance and security reasons. For data scientists to interactively explore
    data, troubleshoot pipeline execution in workflow orchestration, and debug models,
    a remote interactive data science environment (figure 1.3, box G) located inside
    the deep learning system is required.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 由于合规性和安全原因，客户数据和模型不能从生产环境中下载到本地工作站。为了使数据科学家能够交互式地探索数据，在流程编排中调试管道执行，并调试模型，需要一个位于深度学习系统内部的远程交互式数据科学环境（如图1.3中的框G）。
- en: It is common for companies to set up their own trusted data science environment
    by using open source Jupyter Notebooks ([https://jupyter.org/](https://jupyter.org/))
    or by utilizing cloud vendors’ JupyterLab-based solutions, such as Amazon SageMaker
    Studio ([https://aws.amazon.com/sagemaker/studio/](https://aws.amazon.com/sagemaker/studio/)).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 公司通常通过使用开源Jupyter Notebooks（[https://jupyter.org/](https://jupyter.org/)）或利用云供应商基于JupyterLab的解决方案（如Amazon
    SageMaker Studio [https://aws.amazon.com/sagemaker/studio/](https://aws.amazon.com/sagemaker/studio/)）来设置自己的可信数据科学环境。
- en: 'A typical interactive data science environment should provide the following
    functionalities:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的交互式数据科学环境应该提供以下功能：
- en: '*Data exploration*—Offers data scientists easy access to customer data but
    keeps it secure and compliant; there are no data leaks, and any unauthorized data
    access will be rejected.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据探索*—为数据科学家提供轻松访问客户数据，但保持其安全和合规；没有数据泄露，任何未经授权的数据访问都将被拒绝。'
- en: '*Model prototyping*—Provides the much-needed tooling for data scientists to
    develop quick POC models inside the deep learning system.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型原型设计*—为数据科学家在深度学习系统中快速开发POC模型提供所需的工具。'
- en: '*Troubleshooting*—Enables engineers to debug any activity happening inside
    the deep learning system, such as downloading the model and playing with it to
    analyze its behavior or checking all the input/output artifacts (intermediate
    datasets or configurations) from a failed pipeline.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*故障排除*—使工程师能够调试深度学习系统内部发生的任何活动，例如下载模型并对其进行操作以分析其行为，或检查失败管道的所有输入/输出工件（中间数据集或配置）。'
- en: 1.2.3 Key user scenarios
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 关键用户场景
- en: To better understand how deep learning systems can be used during the development
    cycle (figure 1.1), we prepared sample scenarios that illustrate how they could
    be used. Let’s start with programmatic consumers, shown in figure 1.4\. Data collectors
    that push data to the system will usually end up at the data management service
    via the API, which collects and organizes raw data for model training.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解在开发周期中如何使用深度学习系统（如图1.1所示），我们准备了示例场景来说明它们的使用方法。让我们从程序性消费者开始，如图1.4所示。将数据推送到系统的数据收集器通常会通过API到达数据管理服务，该服务收集和组织原始数据以供模型训练使用。
- en: '![](../Images/01-04.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/01-04.png)'
- en: Figure 1.4 Data is pushed from sources or collectors, through the API to the
    data management service, where the data is further organized and stored in formats
    that are more friendly for model training.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 数据从源或收集者通过API推送到数据管理服务，在那里数据被进一步组织并以对模型训练更友好的格式存储。
- en: Deep learning applications will usually hit the model inference service to obtain
    inferences from a trained model, which is used to power deep learning features
    that end users will consume. Figure 1.5 shows the sequence of this interaction.
    Scripts, or even full-fledged management services, can be programmatic consumers,
    too. Because they are optional, we omitted them from the figure for simplicity.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习应用通常会调用模型推理服务以从训练模型中获得推理，这些推理用于提供深度学习功能，最终用户将消费这些功能。图1.5显示了这种交互的顺序。脚本甚至完整的管理服务也可以是程序性消费者。由于它们是可选的，为了简化，我们从图中省略了它们。
- en: '![](../Images/01-05.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-05](../Images/01-05.png)'
- en: Figure 1.5 Deep learning applications request inferences through the API. The
    model inference service accepts and processes these requests against trained models
    and produces inferences that are returned back to applications.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 深度学习应用通过API请求推理。模型推理服务接受并处理这些请求，针对训练模型进行处理，并产生返回给应用的推理。
- en: Between human consumers and the API usually lies an extra layer—the user interface.
    The interface can be web based or command-line based. Some power users may even
    skip this interface and consume the API directly. Let’s walk through each persona
    one by one.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在人类消费者和API之间通常存在一个额外的层——用户界面。该界面可以是基于Web的或基于命令行的。一些高级用户甚至可能跳过此界面并直接消费API。让我们逐一了解每个角色。
- en: A typical scenario of researchers using the system is illustrated in figure
    1.6\. Researchers can look up available data to try out their new modeling technique.
    They access the user interface and visit the data exploration and visualization
    section, which pulls data from the data management service. A great deal of manual
    data processing might be involved in massaging it into forms that can be consumed
    by new training techniques. Once researchers settle with a technique, they can
    package it as a library for others’ consumption.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员使用该系统的典型场景如图1.6所示。研究人员可以查找可用数据以尝试他们的新建模技术。他们访问用户界面并访问数据探索和可视化部分，该部分从数据管理服务中提取数据。可能需要进行大量手动数据处理，将其转换为可以由新训练技术消费的形式。一旦研究人员确定了一种技术，他们可以将它打包成库供他人使用。
- en: '![](../Images/01-06.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-06](../Images/01-06.png)'
- en: Figure 1.6 A usage sequence of a researcher who is interested in seeing what
    data is available for researching and developing a new modeling technique. The
    researcher interacts with a user interface that is supported by the API and data
    management behind the scenes.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6 一个研究人员的使用序列，该研究人员对查看可用于研究和开发新建模技术的数据感兴趣。研究人员与API和后台数据管理支持的用户界面进行交互。
- en: Data scientists and engineers can work on use cases by first looking at what
    data is available, similar to what researchers would initially do in the previous
    paragraph. This would be supported by the data management service. They make hypotheses
    and put together data processing and training techniques as code. These steps
    can be combined to form a workflow using the workflow management service.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家和工程师可以通过首先查看可用数据来处理用例，这与前一段中研究人员最初会做的事情类似。这将由数据管理服务支持。他们提出假设，并将数据处理和训练技术作为代码组合起来。这些步骤可以结合使用工作流管理服务来形成一个工作流。
- en: When the workflow management service performs a run of the workflow, it contacts
    the data management service and the model training service to perform actual duties
    and track their progress. Hyperparameters, code versions, model training metrics,
    and test results are all stored to the metadata and artifacts store by each service
    and training code.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 当工作流管理服务执行工作流运行时，它会联系数据管理服务和模型训练服务以执行实际任务并跟踪它们的进度。超参数、代码版本、模型训练指标和测试结果都由每个服务和训练代码存储到元数据和工件存储中。
- en: Through the user interface, data scientists and engineers can compare experimental
    runs and deduce the best way to train models. This aforementioned scenario is
    shown in figure 1.7.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 通过用户界面，数据科学家和工程师可以比较实验运行并推断出训练模型的最佳方式。上述场景如图1.7所示。
- en: '![](../Images/01-07.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-07](../Images/01-07.png)'
- en: Figure 1.7 A usage sequence of a data scientist defining model training workflow,
    running it, and reviewing results
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 数据科学家定义模型训练工作流程、运行它并查看结果的用法序列
- en: Product managers can also look at and query all kinds of metrics throughout
    the system through the user interface. The metrics data can be supplied by the
    metadata and artifacts store.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 产品经理还可以通过用户界面查看和查询系统中的各种指标。指标数据可以由元数据和工件存储提供。
- en: 1.2.4 Derive your own design
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.4 提炼您自己的设计
- en: Now that we have gone over all aspects of the reference system architecture,
    let’s discuss some guidelines for customizing your own version.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经讨论了参考系统架构的所有方面，让我们来讨论一些定制您自己版本的指南。
- en: Gathering goals and requirements
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 收集目标和需求
- en: The first step to designing any successful system design is to have a set of
    clear goals and requirements with which to work. These should ideally come from
    users of your system, either directly or indirectly through the product management
    team or engineering management. This short list of goals and requirements will
    help you form a vision of what your system will look like. This vision, in turn,
    should be the guideline that drives you throughout the design and development
    phases of your system.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 设计任何成功系统设计的第一步是拥有一套清晰的目标和需求，以便进行工作。这些目标理想情况下应来自您的系统用户，无论是直接还是通过产品管理团队或工程管理团队间接获得。这份简短的目标和需求清单将帮助您形成一个关于系统将如何看起来的大致愿景。这个愿景反过来又应该成为指导您在整个系统设计和开发阶段工作的指南。
- en: Note Sometimes engineers are asked to develop a system to support one or more
    deep learning applications that already exist. In this case, you may instead start
    with identifying the set of common requirements among these applications and how
    your system can be designed to help bring innovation quickly to these applications.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：有时工程师会被要求开发一个系统来支持一个或多个已经存在的深度学习应用。在这种情况下，您可能需要从确定这些应用之间的共同需求集以及如何设计您的系统来帮助快速创新这些应用开始。
- en: To collect the system goals and requirements, you need to identify the different
    types of users and stakeholders, or *personas*, of the system. (This is a general
    concept that can be applied to most system design problems.) It is the users,
    after all, who will help you articulate the goals and requirements of the system.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 要收集系统目标和需求，您需要确定系统的不同类型用户和利益相关者，或称为*角色*。（这是一个可以应用于大多数系统设计问题的通用概念。）毕竟，是用户将帮助您阐述系统的目标和需求。
- en: 'Our recommendation is to start with use cases or application requirements if
    you are not sure of a good starting point. Here are some example questions that
    you can ask your users:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不确定一个好的起点，我们建议从用例或应用需求开始。以下是一些您可以向用户提出的问题示例：
- en: '*To data engineers and product managers*—Does the system allow applications
    to collect data for training? Does the system need to handle streaming input data?
    How much data is being collected?'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*针对数据工程师和产品经理*—系统是否允许应用程序收集用于训练的数据？系统是否需要处理流输入数据？正在收集多少数据？'
- en: '*To data scientists and engineers*—How do we process and label the data? Does
    the system need to provide labeling tools for external vendors? How do we evaluate
    the model? How do we handle the test dataset? Is an interactive notebooking user
    interface needed for data science work?'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*针对数据科学家和工程师*—我们如何处理和标记数据？系统是否需要为外部供应商提供标记工具？我们如何评估模型？我们如何处理测试数据集？是否需要交互式笔记簿用户界面来进行数据科学工作？'
- en: '*To researchers and data scientists*—How large of a volume of data is needed
    for training models? What’s the average time of model training runs? How much
    computing and data capacity is needed for research and data science? What kind
    of experiments should the system support? What metadata and metrics need to be
    collected to evaluate different experiments?'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*针对研究人员和数据科学家*—训练模型需要多大的数据量？模型训练的平均运行时间是多少？研究和数据科学需要多少计算和数据容量？系统应该支持哪些类型的实验？需要收集哪些元数据和指标来评估不同的实验？'
- en: '*To product managers and software engineers*—Is model serving done on the remote
    server or on the client? Is it a real-time model inference or offline batch prediction?
    Is there a latency requirement?'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*针对产品经理和软件工程师*—模型服务是在远程服务器上还是在客户端进行？是实时模型推理还是离线批量预测？是否有延迟要求？'
- en: '*To product managers*—What problems are we trying to solve at our organization?
    What is our business model? How are we going to gauge the effectiveness of our
    implementations?'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*面向产品经理*—我们组织试图解决哪些问题？我们的商业模式是什么？我们将如何衡量我们实施的成效？'
- en: '*To security teams*—What level of security is needed in your system? Is data
    access wide open or strictly restricted/isolated? Is there an audit requirement?
    Is there a certain level of compliance or certification (e.g., General Data Protection
    Regulation, System and Organization Controls 2, etc.) that the system needs to
    achieve?'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*面向安全团队*—您的系统中需要达到何种安全级别？数据访问是开放还是严格限制/隔离？是否有审计要求？系统需要达到一定的合规性或认证水平（例如，通用数据保护条例，系统和组织控制2等）吗？'
- en: Customizing the reference architecture
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 定制参考架构
- en: Once the design requirement and scope are clear, we can start to customize the
    reference architecture in figure 1.3\. First, we can decide whether we need to
    add or remove any components. For example, if the requirement is purely managing
    model training in a remote server farm, we could remove the workflow management
    component. If data scientists want to evaluate model performance effectively with
    production data, they could also add an experiment management component. This
    component allows data scientists to perform training and validation using full-scale
    data that already exists in the system and conduct online A/B testing against
    production traffic with previously unseen data.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设计要求和范围明确，我们就可以开始定制图1.3中的参考架构。首先，我们可以决定是否需要添加或删除任何组件。例如，如果要求仅仅是管理远程服务器农场中的模型训练，我们可以移除工作流管理组件。如果数据科学家希望使用生产数据有效地评估模型性能，他们也可以添加一个实验管理组件。该组件允许数据科学家使用系统中已存在的全规模数据进行训练和验证，并使用之前未见过的数据对生产流量进行在线A/B测试。
- en: The second step is to design and implement each key component suite to your
    specific needs. Depending on the requirement, you might exclude the data streaming
    API from the dataset management service and add distributed training support if
    training speed is a concern. You can either build each key component from scratch
    or use open source software. In the rest of the book, we cover both options for
    each key component to ensure you know what to do.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是为满足您的特定需求设计和实施每个关键组件套件。根据需求，您可能需要从数据集管理服务中排除数据流API，如果训练速度是关注点，则添加分布式训练支持。您可以从头构建每个关键组件，或使用开源软件。在本书的其余部分，我们将涵盖每个关键组件的两种选项，以确保您知道该怎么做。
- en: TIP Keep the system design simple and user friendly. The purpose of creating
    such a large deep learning system is to improve the productivity of deep learning
    development, so please keep this in mind when designing it. We want to make it
    easy for data scientists to build high-quality models without the need to learn
    what’s going on in the underlying system.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：保持系统设计简单且用户友好。创建如此庞大的深度学习系统的目的是提高深度学习开发的效率，因此在设计时请牢记这一点。我们希望让数据科学家能够轻松构建高质量模型，而无需学习底层系统的情况。
- en: 1.2.5 Building components on top of Kubernetes
  id: totrans-238
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.5 在Kubernetes上构建组件
- en: We have introduced a list of key components that are implemented as services.
    With this number of services, you may want to manage them with a sophisticated
    system at the infrastructure level, such as Kubernetes.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了一系列作为服务实现的关键组件。随着服务数量的增加，您可能希望在基础设施级别使用复杂的系统来管理它们，例如Kubernetes。
- en: Kubernetes is an open source system for automating deployment, scaling, and
    management of containerized applications, which are applications that run in isolated
    runtime environments—for example, docker containers. We have seen a number of
    deep learning systems that are built on top of Kubernetes. Some people learn how
    to use Kubernetes without ever knowing why it is used to run deep learning services,
    so we want to explain the thinking behind it. If you are familiar with Kubernetes,
    please feel free to skip this section.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个开源系统，用于自动化部署、扩展和管理容器化应用程序，这些应用程序在隔离的运行时环境中运行——例如，docker容器。我们已经看到许多基于Kubernetes构建的深度学习系统。有些人学习如何使用Kubernetes，却从未知道为什么它被用来运行深度学习服务，因此我们想要解释其背后的思考。如果您熟悉Kubernetes，请随意跳过本节。
- en: Note Kubernetes is a complex platform that would require a book-length of material
    to teach, so we are only discussing its merits for a deep learning system. If
    you want to learn Kubernetes, we highly recommend you check out *Kubernetes in
    Action* (Manning, 2018), by Marko Lukša.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：Kubernetes是一个复杂的平台，需要大量的材料来教授，所以我们只讨论其对深度学习系统的优点。如果您想学习Kubernetes，我们强烈推荐您阅读Marko
    Lukša所著的《Kubernetes in Action》（Manning，2018）。
- en: Challenges for managing computing resources
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 管理计算资源的挑战
- en: Executing one docker container on a remote server seems to be a simple task,
    but running 200 containers on 30 different servers is a different story. There
    are many challenges, such as monitoring all remote servers to determine on which
    one to run the container, needing to failover a container to a healthy server,
    restarting a container when it’s stuck, following up each container run and getting
    notified when it completes, etc. To address these challenges, we must monitor
    the hardware, OS processes, and networking ourselves. Not only is it technically
    challenging, but it is also a huge amount of work.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在远程服务器上执行一个Docker容器似乎是一个简单的任务，但在30个不同的服务器上运行200个容器则是另一回事。这里有许多挑战，例如监控所有远程服务器以确定在哪个服务器上运行容器，需要将容器故障转移到健康服务器，当容器卡住时重启容器，跟进每个容器的运行并通知其完成等。为了解决这些挑战，我们必须自己监控硬件、操作系统进程和网络。这不仅技术上具有挑战性，而且工作量也非常大。
- en: How Kubernetes helps
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes如何帮助
- en: 'Kubernetes is an open source container orchestration platform for scheduling
    and automating the deployment, management, and scaling of containerized applications.
    Once you set up a Kubernetes cluster, your server groups’ operation (deployment,
    patching, updates) and resources become manageable. Here is a deployment example:
    you can tell Kubernetes to run a docker image with 16 GB memory and 1 GPU with
    a command; Kubernetes will allocate the resource to run this docker image for
    you.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个开源的容器编排平台，用于调度和自动化容器化应用程序的部署、管理和扩展。一旦您设置了Kubernetes集群，您的服务器组操作（部署、修补、更新）和资源就变得可管理。以下是一个部署示例：您可以使用命令告诉Kubernetes运行具有16
    GB内存和1个GPU的Docker镜像；Kubernetes将分配资源为您运行此Docker镜像。
- en: This is a huge benefit for software developers because not every one of them
    has extensive experience with hardware and deployment. With Kubernetes, we only
    need to declare the end state of our cluster, and Kubernetes will do the actual
    job to meet our goals.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这对软件开发者来说是一个巨大的好处，因为并非每个软件开发者都有丰富的硬件和部署经验。有了Kubernetes，我们只需要声明我们集群的最终状态，Kubernetes就会完成实际工作以满足我们的目标。
- en: 'Besides container deployment benefits, the following are some other key Kubernetes
    functionalities that are crucial for managing our training containers:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 除了容器部署的好处之外，以下是一些其他关键Kubernetes功能，这些功能对于管理我们的训练容器至关重要：
- en: '*Autoscaling features*—Kubernetes automatically resizes the number of nodes
    in the cluster based on the workload. This means if there is a sudden burst of
    user requests, Kubernetes will add the capacity automatically, which is called
    *elastic compute management*.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自动扩展功能*—Kubernetes根据工作负载自动调整集群中节点数量。这意味着如果用户请求突然增加，Kubernetes会自动增加容量，这被称为*弹性计算管理*。'
- en: '*Self-healing capabilities*—Kubernetes restarts, replaces, or reschedules pods
    when they fail or when nodes die. It also kills pods that do not respond to user-defined
    health checks.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自愈能力*—当Pod失败或节点死亡时，Kubernetes会重启、替换或重新调度Pod。它还会杀死对用户定义的健康检查无响应的Pod。'
- en: '*Resource utilization and isolation*—Kubernetes takes care of computing resource
    saturation; it ensures every server is fully utilized. Internally, Kubernetes
    launches application containers in *pods*. Each pod is an isolated environment
    with a computing resource guarantee, and it runs a function unit. In Kubernetes,
    multiple pods can be in one node (server) as long as their combined resource requirements
    (CPU, memory, disk) don’t exceed the node’s limitations, so servers can be shared
    by different function units easily with guaranteed isolation.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*资源利用和隔离*—Kubernetes负责处理计算资源饱和；它确保每个服务器都得到充分利用。内部，Kubernetes在*pods*中启动应用程序容器。每个Pod都是一个具有计算资源保证的独立环境，并运行一个功能单元。在Kubernetes中，只要多个Pod的总资源需求（CPU、内存、磁盘）不超过节点的限制，它们就可以在同一个节点（服务器）上运行，这样不同的功能单元就可以轻松共享服务器，同时保证隔离。'
- en: '*Namespaces*—Kubernetes supports splitting a physical cluster into different
    virtual clusters. These virtual clusters are called *namespaces*. You can define
    resource quota per namespace, which allows you to isolate resources for different
    teams by assigning them to different namespaces.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*命名空间*——Kubernetes支持将物理集群分割成不同的虚拟集群。这些虚拟集群被称为*命名空间*。你可以为每个命名空间定义资源配额，这允许你通过将它们分配到不同的命名空间来隔离不同团队的资源。'
- en: On the flip side, these benefits come at a cost—they consume resources as well.
    When you run a Kubernetes pod, the pod itself takes some amount of system resources
    (CPU, memory). These resources are consumed on top of those that are needed to
    run containers inside pods. Kubernetes’s overhead seems reasonable in many situations;
    for example, from an experiment published in the article “How We Minimized the
    Overhead of Kubernetes in Our Job System” ([http://mng.bz/DZBV](http://mng.bz/DZBV))
    by Lally Singh and Ashwin Venkatesan (February 2021), the CPU overhead per pod
    was about 10 ms per second.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，这些好处是有代价的——它们也会消耗资源。当你运行一个Kubernetes pod时，pod本身会占用一定量的系统资源（CPU、内存）。这些资源是在运行pod内部容器所需的资源之上消耗的。在许多情况下，Kubernetes的开销似乎是合理的；例如，根据Lally
    Singh和Ashwin Venkatesan在2021年2月发表的文章《How We Minimized the Overhead of Kubernetes
    in Our Job System》（[http://mng.bz/DZBV](http://mng.bz/DZBV)）中的实验，每个pod的CPU开销约为每秒10毫秒。
- en: Note We recommend you check out appendix B to see how existing deep learning
    systems relate to the concepts presented in this chapter. In that appendix, we
    compare the reference architecture described in section 1.2.1 with Amazon SageMaker,
    Google Vertex AI, Microsoft Azure Machine Learning, and Kubeflow.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们建议您查看附录B，了解现有的深度学习系统如何与本章中提出的概念相关。在该附录中，我们比较了第1.2.1节中描述的参考架构与Amazon SageMaker、Google
    Vertex AI、Microsoft Azure Machine Learning和Kubeflow。
- en: 1.3 Building a deep learning system vs. developing a model
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 构建深度学习系统与开发模型
- en: 'A final piece of groundwork before we begin: we think it is crucial to call
    out the differences between *building a deep learning system* and *developing
    a deep learning model*. In this book, we define *the practice of developing a
    deep learning model* to solve a problem as the process of'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前的一个最后准备工作：我们认为指出*构建深度学习系统*与*开发深度学习模型*之间的区别至关重要。在这本书中，我们将*开发深度学习模型以解决问题*的实践定义为
- en: Exploring available data and how it can be transformed for training
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索可用数据及其如何用于训练的转换
- en: Determining the effective training algorithm(s) to use for the problem
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定用于该问题的有效训练算法（或算法集）
- en: Training models and developing inference code to test against unseen data
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型并开发推理代码以测试未见数据
- en: Recall that a deep learning system should support not only all tasks required
    by model development but also those that need to be performed by other roles and
    make collaboration between these roles seamless. When building a deep learning
    system, you are not developing deep learning models; you are building a system
    that supports the development of deep learning models, making that process more
    efficient and scalable.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，一个深度学习系统不仅应该支持模型开发所需的所有任务，还应该支持其他角色需要执行的任务，并使这些角色之间的协作无缝。当构建深度学习系统时，你并不是在开发深度学习模型；你是在构建一个支持深度学习模型开发的系统，使该过程更加高效和可扩展。
- en: We have found an abundance of material published about building the models.
    But we have seen precious little written about designing and building the platforms
    or systems that support those models. And that is why we wrote this book.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现有关构建模型的大量材料已经发表。但我们看到关于设计和构建支持这些模型的平台或系统的内容非常少。这就是我们写这本书的原因。
- en: Summary
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'A typical machine learning project development goes through the following cycle:
    product initiation, data exploration, model prototyping, productionization, and
    production integration.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个典型的机器学习项目开发会经历以下周期：产品启动、数据探索、模型原型设计、产品化以及生产集成。
- en: 'There are seven different roles involved in deep learning project development:
    a product manager, researchers, data scientists, data engineers, MLOps engineers,
    machine learning system engineers, and application engineers.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习项目开发涉及七个不同的角色：产品经理、研究人员、数据科学家、数据工程师、MLOps工程师、机器学习系统工程师和应用工程师。
- en: A deep learning system should reduce complexity in the deep learning development
    cycle.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个深度学习系统应该减少深度学习开发周期中的复杂性。
- en: With the help of deep learning systems, the data scientist, who is not expected
    to suddenly become an expert DevOps or data engineer, should be able to implement
    models in a scalable manner, set up data pipelines, and deploy and monitor models
    in production independently.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在深度学习系统的帮助下，数据科学家，不需要突然成为专家DevOps或数据工程师，应该能够以可扩展的方式实现模型，设置数据管道，并在生产中独立部署和监控模型。
- en: An efficient deep learning system should allow data scientists to focus on interesting
    and important data science tasks.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个高效的深度学习系统应该允许数据科学家专注于有趣和重要的数据科学任务。
- en: A high-level reference architecture like the one we present in figure 1.3 can
    help you quickly start a new design. First, make your own copy and then collect
    goals and requirements. Finally, add, modify, or subtract components and their
    relationships as you see fit.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似于我们在图1.3中展示的高级参考架构可以帮助您快速开始新的设计。首先，制作自己的副本，然后收集目标和需求。最后，根据需要添加、修改或删除组件及其关系。
- en: 'A basic deep learning system consists of the following key components: dataset
    manager, model trainer, model serving, metadata and artifacts store, workflow
    orchestration, and data science environment.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个基本的深度学习系统包括以下关键组件：数据集管理器、模型训练器、模型服务、元数据和工件存储、工作流编排和数据科学环境。
- en: The data management component helps collect, organize, describe, and store data
    as datasets that can be used as training input. It also supports data exploration
    activities and tracks lineage between datasets. Chapter 2 will discuss data management
    in detail.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据管理组件帮助收集、组织、描述和存储数据，作为可以用于训练输入的数据集。它还支持数据探索活动并跟踪数据集之间的血缘关系。第2章将详细讨论数据管理。
- en: The model training component is responsible for handling multiple training requests
    and running them efficiently provided a given, limited set of computing resources.
    Chapters 3 and 4 will review the model training component.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练组件负责处理多个训练请求，并在给定的、有限的计算资源下高效地运行它们。第3章和第4章将回顾模型训练组件。
- en: The model serving component handles incoming inference requests, produces inferences
    with models, and returns them to requesters. It will be covered in chapters 6
    and 7.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型服务组件处理传入的推理请求，使用模型生成推理，并将它们返回给请求者。这将在第6章和第7章中介绍。
- en: The metadata and artifacts store component records metadata and stores artifacts
    from the rest of the system. Any data produced by the system can be treated as
    artifacts. Most of them would be models, which come with metadata that will be
    stored in the same component. This provides complete lineage information to support
    experimentation and troubleshooting. We will talk about this component in chapter
    8.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据和工件存储组件记录元数据并存储来自系统其余部分的工件。系统产生的任何数据都可以被视为工件。其中大部分将是模型，它们将带有元数据，这些元数据将存储在相同的组件中。这提供了完整的血缘信息，以支持实验和故障排除。我们将在第8章中讨论该组件。
- en: The workflow management component stores workflow definitions that chain together
    different steps in data processing and model training. It is responsible for triggering
    periodic workflow runs and tracking the progress of each run step that is being
    executed on other components—for instance, a model training step being executed
    on the model training service. In chapter 9, we will provide a walk-through of
    this component.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流管理组件存储工作流定义，这些定义将数据处理的各个步骤串联起来。它负责触发定期的工作流运行并跟踪每个运行步骤的进度，这些步骤在其他组件上执行，例如，在模型训练服务上执行的模型训练步骤。在第9章中，我们将提供该组件的概述。
- en: A deep learning system should support the deep learning development cycle and
    make collaboration between multiple roles easy.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习系统应该支持深度学习开发周期并使多个角色之间的协作变得容易。
- en: Building a deep learning system is different from developing a deep learning
    model. The system is the infrastructure to support deep learning model development.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建深度学习系统与开发深度学习模型不同。系统是支持深度学习模型开发的基础设施。
