- en: 6 Deploying HA Jenkins on multiple cloud providers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 在多个云服务提供商上部署高可用性Jenkins
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Automating the build process of Jenkins VMs with Packer
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Packer自动化Jenkins VM的构建过程
- en: Deploying a Jenkins cluster on Azure, GCP, and DigitalOcean
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Azure、GCP和DigitalOcean上部署Jenkins集群
- en: Reducing the cost of deploying Jenkins workers by creating them on demand
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过按需创建Jenkins工作节点来降低部署成本
- en: Using the same Packer template to create identical Jenkins machine images in
    different cloud providers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用相同的Packer模板在不同的云服务提供商中创建相同的Jenkins机器镜像
- en: You’ve already seen how to accomplish fault tolerance by deploying the Jenkins
    cluster in AWS. The chapter will try to achieve the same required speed and automation
    on the infrastructure level by using the same tools and processes to automate
    the creation of a cluster on different cloud providers such as Microsoft Azure,
    Google Cloud Platform, and DigitalOcean—ranging from infrastructure-as-a-service
    (IaaS) to platform-as-a-service (PaaS) providers.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了如何在AWS上部署Jenkins集群来实现容错。本章将尝试通过使用相同的工具和流程来自动化在Microsoft Azure、Google Cloud
    Platform和DigitalOcean等不同云服务提供商上创建集群，从而在基础设施级别实现相同的需求速度和自动化——从基础设施即服务（IaaS）到平台即服务（PaaS）提供商。
- en: You might notice that some parts of this chapter are similar, or even the same
    as, those you read in the previous chapter. The reason for the partial repetition
    is to achieve the goal of this book, which is to illustrate the use of Jenkins
    with cloud-native applications—and because not everyone is adopting AWS as their
    main cloud provider, I want to make this book useful for others and for those
    who skipped chapter 5 and jumped right here.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到本章的一些部分与上一章中你阅读的内容相似，甚至完全相同。这种部分重复的原因是为了实现本书的目标，即说明如何使用Jenkins与云原生应用结合使用——因为并非每个人都将AWS作为他们的主要云服务提供商，我希望这本书对其他人以及跳过第5章直接到这里的人都有用。
- en: Note Using the providers detailed in this chapter carries some benefits and
    drawbacks. No matter which provider you choose, you'll always encounter issues
    at some point along the way.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：使用本章中详细说明的提供商带来一些好处和缺点。无论你选择哪个提供商，你都会在某个阶段遇到问题。
- en: 6.1 Google Cloud Platform
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 谷歌云平台
- en: We all know that AWS doesn’t have the most user-friendly web console. *Google
    Cloud Platform* (GCP) has managed to outperform AWS by offering a better user
    experience. GCP consists of a variety of services ranging from computing, to network,
    to extract-transform-load (ETL) pipelines that are 25% cheaper than its rival
    (AWS) because of lower-increment billing (10 minutes instead of 1 hour).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都知道AWS没有最友好的Web控制台。*谷歌云平台*（GCP）通过提供更好的用户体验而成功超越了AWS。GCP由各种服务组成，从计算到网络，再到比其竞争对手（AWS）便宜25%的提取-转换-加载（ETL）管道，这得益于更低的增量计费（10分钟而不是1小时）。
- en: Plus, GCP has more expertise when it comes to big data, with services like BigQuery
    ([https://cloud.google.com/bigquery](https://cloud.google.com/bigquery)), Cloud
    Bigtable ([https://cloud.google.com/bigtable](https://cloud.google.com/bigtable)),
    and Dataflow ([https://cloud.google.com/dataflow](https://cloud.google.com/dataflow)).
    In addition, you can run container workloads on Kubernetes and deploy machine
    learning (ML) models with TensorFlow; both Kubernetes and TensorFlow originated
    from Google. However, GCP still lacks features compared to AWS, which is the oldest
    and most mature cloud vendor on the market.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，GCP在处理大数据方面拥有更多专业知识，例如BigQuery ([https://cloud.google.com/bigquery](https://cloud.google.com/bigquery))、Cloud
    Bigtable ([https://cloud.google.com/bigtable](https://cloud.google.com/bigtable))
    和 Dataflow ([https://cloud.google.com/dataflow](https://cloud.google.com/dataflow))等服务。此外，您还可以在Kubernetes上运行容器工作负载，并使用TensorFlow部署机器学习（ML）模型；Kubernetes和TensorFlow都源自Google。然而，与市场上最老练、最成熟的云服务提供商AWS相比，GCP仍缺乏一些功能。
- en: Why use Jenkins with GCP, then? You can have seamless integration with Kubernetes;
    with services like Google Kubernetes Engine (GKE), you can run ephemeral Jenkins
    workers, ensuring that each build runs on a clean environment. Native support
    for Docker containers is another reason, with services like Container Registry
    to store and manage Docker images built within CI/CD pipelines. In addition, you
    can have integrated security and compliance with detailed reports on vulnerability
    impacts and available fixes of build artifacts. Finally, you pay per usage when
    you use GCP virtual machines (VMs) to speed up your Jenkins builds.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么要在 GCP 上使用 Jenkins 呢？您可以与 Kubernetes 实现无缝集成；使用 Google Kubernetes Engine
    (GKE) 等服务，您可以运行短暂的 Jenkins 工作节点，确保每个构建都在干净的环境中运行。原生支持 Docker 容器是另一个原因，例如使用容器注册服务来存储和管理
    CI/CD 管道中构建的 Docker 镜像。此外，您还可以集成安全性和合规性，并获取有关构建工件漏洞影响和可用修复的详细报告。最后，当您使用 GCP 虚拟机
    (VM) 加速 Jenkins 构建时，您将按使用量付费。
- en: With that being said, let’s head over and deploy a Jenkins cluster with Terraform
    and Packer on GCP. To get started, sign up for a free account with a Gmail address
    ([https://console.cloud.google.com/](https://console.cloud.google.com/)). You
    will automatically get a 12-month free trial with a $300 credit. You need to provide
    your credit card details, but you won’t be charged extra until after your trial
    period ends or you have exhausted the $300 credit.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，让我们转到 GCP 上使用 Terraform 和 Packer 部署 Jenkins 集群的步骤。要开始，请使用 Gmail 地址注册一个免费帐户（[https://console.cloud.google.com/](https://console.cloud.google.com/)）。您将自动获得
    12 个月的免费试用，并享有 300 美元的信用额度。您需要提供信用卡详细信息，但在试用期间结束或用完 300 美元信用额度之前，您不会产生额外费用。
- en: Note The estimated cost to deploy a Jenkins cluster is $0.00\. This cost assumes
    that you’re within the GCP Free Tier limits and that you terminate all resources
    within 1 hour of deploying the infrastructure.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：部署 Jenkins 集群的预估成本为 $0.00。此成本假设您处于 GCP 免费层限制内，并且在部署基础设施后的 1 小时内终止所有资源。
- en: 6.1.1 Building Jenkins VM images
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.1 构建 Jenkins 虚拟机镜像
- en: For Packer to build a custom image, it needs to interact with GCP. Therefore,
    we need to create a dedicated service account for Packer to be authorized to access
    resources in Google APIs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让 Packer 构建自定义镜像，它需要与 GCP 交互。因此，我们需要为 Packer 创建一个专用的服务帐户，以便授权其访问 Google API
    中的资源。
- en: Head to the GCP console and navigate to the IAM & Admin dashboard, shown in
    figure 6.1\. In the Service Accounts section, create a new service account with
    `Packer` as a name, and click the Create button.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 前往 GCP 控制台并导航到图 6.1 所示的 IAM & Admin 仪表板。在服务帐户部分，创建一个名为“Packer”的新服务帐户，然后单击“创建”按钮。
- en: '![](Images/CH06_F01_Labouardy.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F01_Labouardy.png)'
- en: Figure 6.1 Creating a Packer service account
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1 创建 Packer 服务帐户
- en: Assign the Project Owner role to the service account (or at least select Compute
    Engine Instance Admin and Service Account User roles) and click the Continue button,
    as shown in figure 6.2.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 将项目所有者角色分配给服务帐户（或至少选择 Compute Engine Instance Admin 和 Service Account User 角色），然后单击“继续”按钮，如图
    6.2 所示。
- en: '![](Images/CH06_F02_Labouardy.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F02_Labouardy.png)'
- en: Figure 6.2 Setting Packer service account permissions
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.2 设置 Packer 服务帐户权限
- en: Each service account is associated with a key (JSON or P12 format), which is
    managed by GCP. This key is used for service-to-service authentication. Download
    the JSON key by clicking the Create Key button. The service account file is created
    and downloaded on the computer. Copy this JSON file and place it in a secure folder.
    Ensure that the Google Compute Engine API is enabled on your GCP project.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 每个服务帐户都与一个密钥（JSON 或 P12 格式）相关联，该密钥由 GCP 管理。此密钥用于服务到服务的身份验证。通过单击“创建密钥”按钮下载 JSON
    密钥。服务帐户文件将在计算机上创建和下载。复制此 JSON 文件并将其放置在安全文件夹中。确保在您的 GCP 项目中启用了 Google Compute Engine
    API。
- en: Note If you’re unfamiliar with Packer, refer to chapter 4 for a step-by-step
    guide on installation and configuration.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您不熟悉 Packer，请参阅第 4 章以获取安装和配置的逐步指南。
- en: Next update the Packer template file for the Jenkins worker provided in chapter
    4’s listing 4.16 with the following content, or copy and paste the content from
    the GitHub repository at chapter6/gcp/packer/worker/setup.sh.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，更新第 4 章列表 4.16 中提供的 Jenkins 工作节点 Packer 模板文件，或从第 6 章 GitHub 仓库 chapter6/gcp/packer/worker/setup.sh
    复制并粘贴以下内容。
- en: Listing 6.1 Jenkins worker template fil.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.1 Jenkins 工作节点模板文件。
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Defines variables that will be provided at runtime. The values can be fetched
    from the GCP dashboard.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义在运行时提供的变量。这些值可以从 GCP 仪表板中获取。
- en: ❷ Runs the shell script in privileged mode to install the Git client, Docker,
    and needed dependencies
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 以特权模式运行shell脚本以安装Git客户端、Docker和所需的依赖项
- en: Note The JSON account file is not required if you’re running the baking process
    from a Google Compute Engine (GCE) instance with a properly configured GCE service
    account. Packer will fetch the credentials from the metadata server.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您从配置了GCE服务账户的Google Compute Engine (GCE)实例运行烘焙过程，则不需要JSON账户文件。Packer将从元数据服务器获取凭证。
- en: Listing 6.1 uses the `googlecompute` builder to create a machine image on top
    of the CentOS base image. Then it uses the shell script provided in chapter 4’s
    listing 4.13 to provision the temporary machine to install all needed dependencies—Git,
    JDK, and Docker.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.1使用`googlecompute`构建器在CentOS基础镜像之上创建机器镜像。然后它使用第4章列表4.13中提供的shell脚本来配置临时机器以安装所有需要的依赖项——Git、JDK和Docker。
- en: The power of Packer comes from leveraging template files to create identical
    virtual machine images independently of the target platform. Therefore, we can
    use the same template file to build an identical Jenkins image for AWS, GCP, or
    Azure.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Packer的强大之处在于利用模板文件来创建与目标平台无关的相同虚拟机镜像。因此，我们可以使用相同的模板文件为AWS、GCP或Azure构建相同的Jenkins镜像。
- en: Note The scripted shell is explained in depth in chapter 4\. All source code
    is available on the GitHub repository in the chapter6 folder.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：脚本化的shell在第4章中有详细解释。所有源代码都可以在GitHub仓库的chapter6文件夹中找到。
- en: The template file in listing 6.1 uses a set of variables such as the service
    account key file created earlier, the name of the zone where the builder machine
    will be provisioned, and the Google Cloud project ID that will own the image.
    The `service_ account` variable can be implicit if you specify the path to the
    JSON file with the `GOOGLE_APPLICATION_CREDENTIALS` environment variable.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.1中的模板文件使用了一组变量，例如之前创建的服务账户密钥文件、构建器机器将要部署的区域名称以及将拥有镜像的Google Cloud项目ID。"service_account"变量可以隐式指定，如果您指定了带有`GOOGLE_APPLICATION_CREDENTIALS`环境变量的JSON文件路径。
- en: Packer will deploy a temporary instance from CentOS 8\. A list of available
    images can be found on the Images dashboard, as you can see in figure 6.3.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Packer将从CentOS 8部署一个临时实例。可在“镜像”仪表板中找到可用镜像列表，如图6.3所示。
- en: '![](Images/CH06_F03_Labouardy.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F03_Labouardy.png)'
- en: Figure 6.3 CentOS base image from GCE images
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3来自GCE镜像的CentOS基础镜像
- en: Note You can also use the `gcloud` `compute` `images` `list` command to list
    available images in a specific GCP location.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您也可以使用`gcloud compute images list`命令列出特定GCP位置上的可用镜像。
- en: 'After supplying all the necessary variables, issue a `packer build` command.
    The output should be similar to the following output, which has been cropped for
    the sake of brevity:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在提供所有必要的变量后，发出`packer build`命令。输出应类似于以下输出，这里为了简洁已裁剪：
- en: '![](Images/CH06_F03_UN01_Labouardy.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F03_UN01_Labouardy.png)'
- en: Once the baking process is done, the Jenkins worker image should be available
    on the Google Compute Engine (GCE) console, as you can see in figure 6.4.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦烘焙过程完成，Jenkins工作节点镜像应该可以在Google Compute Engine (GCE)控制台上找到，如图6.4所示。
- en: '![](Images/CH06_F04_Labouardy.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F04_Labouardy.png)'
- en: Figure 6.4 Jenkins worker custom image
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 Jenkins工作节点自定义镜像
- en: Next, to build the Jenkins master machine image, we will use the same blueprint
    provided in chapter 4’s listing 4.12\. The only difference is the use of `googlecompute`
    in the `builders` section. The full template file, shown in the following listing,
    can be downloaded from chapter6/gcp/packer/master/setup.sh.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为了构建Jenkins主机的机器镜像，我们将使用第4章列表4.12中提供的相同蓝图。唯一的区别是`builders`部分使用了`googlecompute`。完整的模板文件，如以下列表所示，可以从chapter6/gcp/packer/master/setup.sh下载。
- en: Listing 6.2 Jenkins master template fil.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.2 Jenkins主模板文件。
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note This code listing already exists in the GitHub repository. You do not need
    to type it. It is shown for illustration purposes only.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：此代码列表已在GitHub仓库中存在。您无需输入它。这里仅展示用于说明。
- en: 'Before we take this template and build an image from it, let’s validate the
    template by running the following command:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们从模板中构建镜像之前，让我们通过运行以下命令来验证模板：
- en: '[PRE2]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'With a properly validated template, it is time to build the Jenkins images.
    This is done by calling the `packer` `build` command with the template file as
    an argument. The output should look similar to the following. Note that this process
    typically takes a few minutes:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在模板经过适当验证后，是时候构建Jenkins镜像了。这是通过调用带有模板文件的`packer build`命令来完成的。输出应类似于以下内容。请注意，此过程通常需要几分钟时间：
- en: '![](Images/CH06_F04_UN02_Labouardy.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F04_UN02_Labouardy.png)'
- en: When Packer is done building the image, head over to the GCP console, The newly
    created image will be in the Images section, as shown in figure 6.5.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当Packer完成镜像构建后，前往GCP控制台，新创建的镜像将在“镜像”部分，如图6.5所示。
- en: '![](Images/CH06_F05_Labouardy.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F05_Labouardy.png)'
- en: Figure 6.5 Jenkins master custom image
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 Jenkins主自定义镜像
- en: So far, you have learned how to automate the build process for the Jenkins machines
    images on GCP. In the next section, we will use Terraform to deploy VM instances
    based on those images. But first, we will deploy a private network on which our
    Jenkins cluster will be isolated.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经学会了如何在GCP上自动化构建Jenkins机器镜像的过程。在下一节中，我们将使用Terraform根据这些镜像部署VM实例。但首先，我们将部署一个私有网络，我们的Jenkins集群将在这个网络中隔离。
- en: 6.1.2 Configuring a GCP network with Terraform
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.2 使用Terraform配置GCP网络
- en: At the end of this section, you will have an isolated VPN running in different
    zones, as shown in figure 6.6.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节结束时，你将有一个在不同区域运行的独立VPN，如图6.6所示。
- en: '![](Images/CH06_F06_Labouardy.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F06_Labouardy.png)'
- en: Figure 6.6 The Google VPN architecture consists of multiple subnetworks deployed
    in different zones. To access private instances, a bastion host can be used.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 Google VPN架构由多个在不同区域部署的子网络组成。要访问私有实例，可以使用堡垒主机。
- en: The VPC will be spun up in a single GCP region. It will be subdivided into subnets,
    each subnet contained within a single zone. Within a public subnet, a Google compute
    instance will be deployed with a role of a bastion host to give remote access
    to instances deployed in private subnets.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: VPC将在单个GCP区域启动。它将被细分为子网，每个子网都在单个区域中。在公共子网中，将部署一个Google计算实例，其角色为堡垒主机，以提供对私有子网中部署的实例的远程访问。
- en: On the IAM console, shown in figure 6.7, create a dedicated service account
    for Terraform with Project Owner permission and download the JSON private key.
    This file contains credentials that will be needed for Terraform to manage the
    resources on your GCP project.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在IAM控制台，如图6.7所示，为Terraform创建一个具有项目所有者权限的专用服务账户并下载JSON私钥。此文件包含Terraform管理GCP项目中资源所需的凭证。
- en: '![](Images/CH06_F07_Labouardy.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F07_Labouardy.png)'
- en: Figure 6.7 Terraform service account
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 Terraform服务账户
- en: Create a terraform.tf file, declare `google` as a provider, and configure it
    to use the service account created in the previous step; see the following listing.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个terraform.tf文件，声明`google`作为提供者，并将其配置为使用之前步骤中创建的服务账户；请参阅以下列表。
- en: Listing 6.3 Declaring Google as a provider
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.3 声明Google作为提供者
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Create a network.tf file and define a regional VPC network, as shown in the
    following listing. (If you plan to deploy Jenkins instances across multiple GCP
    regions, you need to change the routing mode to global.)
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个network.tf文件并定义一个区域VPC网络，如下所示列表。（如果你计划在多个GCP区域部署Jenkins实例，你需要将路由模式更改为全局。）
- en: Listing 6.4 Defining a GCP network named management
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.4 定义名为management的GCP网络
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Within the same file, declare two public and two private subnets, as shown in
    the next listing. Each subnet has its own CIDR block that is a subset of the network
    CIDR block (10.0.0.0/16).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一文件中，声明两个公共子网和两个私有子网，如下所示列表。每个子网都有自己的CIDR块，它是网络CIDR块的子集（10.0.0.0/16）。
- en: Listing 6.5 Defining public and private subnetworks
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.5 定义公共和私有子网
- en: '[PRE5]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Defines a unique CIDR range within the 10.0.0.0/16 block using the count.index
    variable
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用count.index变量在10.0.0.0/16块内定义一个唯一的CIDR范围
- en: Before applying the changes with `terraform` `apply`, declare variables used
    to parameterize and customize the deployment in variables.tf. Table 6.1 lists
    the variables.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`terraform apply`应用更改之前，声明用于参数化和自定义部署的变量在variables.tf中。表6.1列出了变量。
- en: Table 6.1 GCP Terraform variables
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.1 GCP Terraform变量
- en: '| Name | Type | Value | Description |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 类型 | 值 | 描述 |'
- en: '| `credentials_path` | String | None | The path to the service account key
    file in JSON format. This can be specified using the `GOOGLE_CREDENTIALS` environment
    variable. |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| `credentials_path` | 字符串 | 无 | JSON 格式的服务账户密钥文件的路径。这可以使用 `GOOGLE_CREDENTIALS`
    环境变量来指定。|'
- en: '| `project` | String | None | The default project to manage resources in. If
    another project is specified on a resource, it will take precedence. This can
    also be specified using the `GOOGLE_PROJECT` environment variable. |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| `project` | 字符串 | 无 | 管理资源时的默认项目。如果在资源上指定了另一个项目，则该项目将具有优先权。这也可以使用 `GOOGLE_PROJECT`
    环境变量来指定。|'
- en: '| `region` | String | None | The default region to manage resources in. If
    another region is specified on a regional resource, it will take precedence. Alternatively,
    this can be specified using the `GOOGLE_REGION` environment variable. |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| `region` | 字符串 | 无 | 管理资源时的默认区域。如果在区域资源上指定了另一个区域，则该区域将具有优先权。或者，也可以使用 `GOOGLE_REGION`
    环境变量来指定。|'
- en: '| `network_name` | String | `management` | Name of the virtual network. The
    name must be 1–63 characters long and match the regular expression `[a-z]([-a-z0-9]*[a-z0-9])?`
    |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| `network_name` | 字符串 | `management` | 虚拟网络名称。名称长度必须为 1-63 个字符，并匹配正则表达式 `[a-z]([-a-z0-9]*[a-z0-9])?`
    |'
- en: '| `public_subnets_count` | Number | 2 | The number of public subnetworks. By
    default, we will create two public subnets in different zones for resiliency.
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `public_subnets_count` | 数字 | 2 | 公共子网的数量。默认情况下，我们将为容错性在不同的区域创建两个公共子网。|'
- en: '| `private_subnets_count` | Number | 2 | The number of private subnetworks.
    By default, we will create two private subnets in different zones for resiliency.
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `private_subnets_count` | 数字 | 2 | 私有子网的数量。默认情况下，我们将为容错性在不同的区域创建两个私有子网。|'
- en: 'We can now run Terraform to deploy the infrastructure. First, initialize Terraform
    to download the latest version of the Google Cloud provider plugin:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以运行 Terraform 来部署基础设施。首先，初始化 Terraform 以下载 Google Cloud 提供者插件的最新版本：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The command output is given here:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 命令输出如下：
- en: '![](Images/CH06_F07_UN03_Labouardy.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F07_UN03_Labouardy.png)'
- en: 'Run a `plan` step to validate the configuration syntax and show a preview of
    what will be created:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `plan` 步骤以验证配置语法并预览将要创建的内容：
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note To set lots of variables, it is more convenient to specify their values
    in a variable definitions file (with a filename ending in either .tfvars or .tfvars
    .json) and then specify that file on the command line with the `-var-file` flag.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：为了设置大量变量，在变量定义文件（文件名以 .tfvars 或 .tfvars.json 结尾）中指定它们的值会更方便，然后使用 `-var-file`
    标志在命令行上指定该文件。
- en: 'Now execute the `terraform apply` command to apply those changes:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在执行 `terraform apply` 命令以应用这些更改：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You will see output similar to the following (cropped for brevity):'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到类似以下内容的输出（为了简洁而裁剪）：
- en: '![](Images/CH06_F07_UN04_Labouardy.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F07_UN04_Labouardy.png)'
- en: It should take only a few moments to provision the private network. When it
    is finished, you should see something like figure 6.8.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 配置私有网络应该只需几分钟。完成后，您应该看到类似于图 6.8 的内容。
- en: '![](Images/CH06_F08_Labouardy.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F08_Labouardy.png)'
- en: Figure 6.8 VPC network and its public and private subnets
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.8 VPC 网络及其公共和私有子网
- en: To be able to SSH into private Jenkins instances, we will deploy a bastion host.
    Create bastion.tf and define a VM instance in a public subnet with a static IPv4
    public IP address. To SSH into the bastion instance using Terminal (as opposed
    to the GCP console), you must generate and upload a public SSH key (located by
    default under ~/.ssh/id_rsa.pub, or generate a new one with `ssh-keygen`). The
    `metadata` attribute defined in the following listing references the public SSH
    key.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够通过 SSH 连接到私有 Jenkins 实例，我们将部署一个堡垒主机。创建 bastion.tf 并在公共子网中定义一个具有静态 IPv4 公共
    IP 地址的 VM 实例。要使用终端（而不是 GCP 控制台）通过 SSH 连接到堡垒实例，您必须生成并上传一个公共 SSH 密钥（默认位于 ~/.ssh/id_rsa.pub
    下，或使用 `ssh-keygen` 生成一个新的密钥）。以下列表中定义的 `metadata` 属性引用了公共 SSH 密钥。
- en: Listing 6.6 Bastion host resource
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.6 堡垒主机资源
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Within the same file, create a firewall rule to allow SSH from anywhere on the
    bastion host, as shown in the following listing. (It’s recommended to enable ingress
    from only the IP address you wish to allow access from..
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一文件中，创建一个防火墙规则以允许从堡垒主机上的任何地方进行 SSH，如下所示列表。（建议只启用来自您希望允许访问的 IP 地址的入站流量..）
- en: Listing 6.7 Bastion host firewall rules
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.7 堡垒主机防火墙规则
- en: '[PRE10]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Allows inbound traffic on port 22 (SSH) from anywhere
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 允许来自任何地方的端口 22（SSH）的入站流量
- en: 'Finally, create an outputs.tf file and use the Terraform `output` variable
    to act as helper to expose the public IP address of the bastion virtual machine:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，创建一个 outputs.tf 文件，并使用 Terraform 的 `output` 变量作为助手来暴露堡垒虚拟机的公共 IP 地址：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Outputs the bastion instance’s public IP address
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 输出堡垒实例的公共 IP 地址
- en: 'After the `terraform apply` command has finished, you should see output similar
    to this:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `terraform apply` 命令完成后，您应该看到类似以下输出的内容：
- en: '![](Images/CH06_F08_UN05_Labouardy.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F08_UN05_Labouardy.png)'
- en: On the GCE console, a new VM instance should be deployed, as in figure 6.9.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GCE 控制台中，应该部署一个新的虚拟机实例，如图 6.9 所示。
- en: '![](Images/CH06_F09_Labouardy.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F09_Labouardy.png)'
- en: Figure 6.9 Bastion VM instance
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.9 堡垒虚拟机实例
- en: With the jump box deployed, we can now access private instances in the VPC network.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 跳转盒部署完成后，我们现在可以访问 VPC 网络中的私有实例。
- en: 6.1.3 Deploying Jenkins on Google Compute Engine
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.3 在 Google Compute Engine 上部署 Jenkins
- en: Now that the VPC is created, we will deploy a VM instance based on the Jenkins
    master image within a private subnet and expose a public load balancer to access
    the Jenkins web dashboard on port 8080, as described in figure 6.10.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在VPC已创建，我们将在私有子网中基于 Jenkins 主镜像部署一个虚拟机实例，并公开一个负载均衡器以访问端口 8080 上的 Jenkins 网络仪表板，如图
    6.10 所述。
- en: '![](Images/CH06_F10_Labouardy.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F10_Labouardy.png)'
- en: Figure 6.10 Jenkins master VM inside VPC
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.10 VPC 内的 Jenkins 主虚拟机
- en: Create a jenkins_master.tf file and define a private compute instance with the
    attributes in the following listing.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 jenkins_master.tf 文件，并定义一个具有以下列表中属性的私有计算实例。
- en: Listing 6.8 Jenkins master compute instance
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.8 Jenkins 主计算实例
- en: '[PRE12]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Attaches jenkins-ssh and jenkins-web networks to the VM instance. The groups
    allow inbound traffic on port 22 and 8080 (Jenkins dashboard), respectively.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将 jenkins-ssh 和 jenkins-web 网络连接到虚拟机实例。这些组分别允许端口 22 和 8080（Jenkins 仪表板）上的入站流量。
- en: The compute instance uses the following firewall, which allows SSH from the
    bastion host only and inbound traffic on port 8080 from anywhere. (I recommend
    restricting the traffic to your network CIDR block.)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 计算实例使用以下防火墙，仅允许堡垒主机上的 SSH 访问和来自任何地方的端口 8080 的入站流量。（我建议限制流量到您的网络 CIDR 块。）
- en: Listing 6.9 Jenkins master firewall and traffic control
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.9 Jenkins 主防火墙和流量控制
- en: '[PRE13]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Allows inbound traffic on port 22 (SSH)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 允许端口 22（SSH）上的入站流量
- en: ❷ Allows inbound traffic on port 8080, where the Jenkins dashboard is exposed
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 允许端口 8080 上的入站流量，其中 Jenkins 仪表板被暴露
- en: Use `terraform apply` to deploy the Jenkins compute instance. Once the deployment
    is completed, a new VM will be deployed, as you can see in figure 6.11.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `terraform apply` 来部署 Jenkins 计算实例。一旦部署完成，将部署一个新的虚拟机，如图 6.11 所示。
- en: '![](Images/CH06_F11_Labouardy.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F11_Labouardy.png)'
- en: Figure 6.11 Jenkins master VM instance
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.11 Jenkins 主虚拟机实例
- en: The instance is deployed inside a private subnetwork. To be able to access the
    Jenkins web dashboard, we need to deploy a public load balancer in front of the
    VM instance.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 实例部署在私有子网内。为了能够访问 Jenkins 网络仪表板，我们需要在虚拟机实例前面部署一个公共负载均衡器。
- en: Load balancing on GCP is different than on other cloud providers. The primary
    difference is that GCP uses forwarding rules instead of routing instances. These
    forwarding rules are combined with backend services, target pools, and health
    checks to construct a functional load balancer across an instance group.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: GCP 上的负载均衡与其他云提供商不同。主要区别在于 GCP 使用转发规则而不是路由实例。这些转发规则与后端服务、目标池和健康检查结合，在实例组中构建一个功能性的负载均衡器。
- en: First we define a target pool resource that defines the instances that should
    receive the incoming traffic, as shown in the next listing. In our case, the target
    pool will consist of the Jenkins master VM instance.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义一个目标池资源，该资源定义了应接收传入流量的实例，如下一列表所示。在我们的情况下，目标池将包括 Jenkins 主 VM 实例。
- en: Listing 6.10 Jenkins master target pool
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.10 Jenkins 主目标池
- en: '[PRE14]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Defines Jenkins master VM instance as a target of the network load balancer
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将 Jenkins 主 VM 实例定义为网络负载均衡器的目标
- en: The cloud load balancer forwards traffic to the Jenkins master only if it’s
    up and ready to receive the traffic. That’s why we define a health-check resource
    to send health-check requests to the Jenkins master at a specific frequency on
    port 8080; see the following listing.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当云负载均衡器处于运行状态并准备好接收流量时，才会将流量转发到 Jenkins 主机。这就是为什么我们定义了一个健康检查资源，在端口 8080 上以特定频率向
    Jenkins 主机发送健康检查请求；请参阅以下列表。
- en: Listing 6.11 Jenkins master health check
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.11 Jenkins 主健康检查
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Defines a template for how the Jenkins master should be checked for health,
    via HTTP
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义了如何通过 HTTP 检查 Jenkins 主机的健康状态模板
- en: Finally, in the next listing, we define a forwarding rule to direct traffic
    to the target pool defined earlier.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在下一个列表中，我们定义了一个转发规则，将流量导向之前定义的目标池。
- en: Listing 6.12 Load balancer forwarding rule
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.12 负载均衡器转发规则
- en: '[PRE16]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ If the incoming packet matches the given IP address, IP protocol, and port
    range tuple, it will be forwarded to the Jenkins master target pool.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如果入站数据包与给定的 IP 地址、IP 协议和端口号范围匹配，它将被转发到 Jenkins 主机目标池。
- en: Use `terraform apply` to deploy the public load balancer. On the Network Services
    dashboard, you should have the configuration shown in figure 6.12.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `terraform apply` 来部署公共负载均衡器。在网络服务仪表板上，您应该看到图 6.12 中所示的配置。
- en: '![](Images/CH06_F12_Labouardy.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F12_Labouardy.png)'
- en: Figure 6.12 Public load balancer with Jenkins VM as a backend
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.12 以 Jenkins VM 作为后端的公共负载均衡器
- en: As a backend, the load balancer uses Jenkins master instance and forwards incoming
    traffic on port 8080 to the backend on the same port. Also, it sets up an HTTP
    health check on port 8080.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 作为后端，负载均衡器使用 Jenkins 主机实例，并将入站流量在 8080 端口转发到同一端口的后端。同时，它还在 8080 端口上设置了一个 HTTP
    健康检查。
- en: 'To display the IP address of the load balancer, create an output section in
    the outputs.tf file:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 要显示负载均衡器的 IP 地址，在 outputs.tf 文件中创建一个输出部分：
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Issue the `terraform output` command on the console, and the Jenkins load balancer
    IP address should be displayed:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在控制台上执行 `terraform output` 命令，Jenkins 负载均衡器 IP 地址应该会显示出来：
- en: '![](Images/CH06_F12_UN06_Labouardy.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F12_UN06_Labouardy.png)'
- en: You can now point your browser to the IP address on port 8080 and see the Jenkins
    welcome screen. If you see a screen like the one in figure 6.13, you’ve successfully
    deployed Jenkins on GCP!
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以将浏览器指向 8080 端口的 IP 地址，并看到 Jenkins 欢迎屏幕。如果您看到如图 6.13 所示的屏幕，您已成功在 GCP 上部署了
    Jenkins！
- en: '![](Images/CH06_F13_Labouardy.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F13_Labouardy.png)'
- en: Figure 6.13 Public load balancer IP address to access the Jenkins dashboard
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.13 访问 Jenkins 仪表板的公共负载均衡器 IP 地址
- en: Note The forwarding rule may take several minutes to be provisioned. While it’s
    being created, you might see 404 and 500 errors in the browser.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：转发规则可能需要几分钟才能配置。在创建过程中，您可能在浏览器中看到 404 和 500 错误。
- en: 6.1.4 Launching automanaged workers on GCP
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.4 在 GCP 上启动自动管理的工人
- en: Arguably one of the most powerful features of Jenkins is its ability to dispatch
    build jobs across many workers. It is quite easy to set up a farm of build machines,
    either to share the load across multiple machines or to run build jobs in different
    environments. This is an effective strategy that can potentially increase the
    capacity of your CI infrastructure dramatically.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 不可否认，Jenkins 最强大的功能之一是能够在多个工作节点之间调度构建作业。设置一个构建机器的农场相当简单，无论是为了在多台机器之间共享负载，还是为了在不同的环境中运行构建作业。这是一种有效的策略，有可能显著提高您的
    CI 基础设施的容量。
- en: Demand for Jenkins workers can also fluctuate over time. If you are working
    with product release cycles, you may need to run a much higher number of workers
    toward the end of the cycle. Therefore, to avoid paying for extra resources while
    Jenkins workers are idle, we will deploy Jenkins workers inside an instance group
    and set up autoscaling policies to trigger scale-out or scale-in events that add
    or remove Jenkins workers, respectively, based on metrics such as CPU utilization.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Jenkins 工作节点的需求也可能随时间波动。如果您与产品发布周期一起工作，您可能需要在周期的后期运行更多的工人。因此，为了避免在 Jenkins 工作节点空闲时支付额外资源，我们将在实例组内部部署
    Jenkins 工作节点，并设置自动扩展策略来触发扩展或缩减事件，分别添加或删除 Jenkins 工作节点，基于如 CPU 利用率等指标。
- en: Note In chapter 13, we will cover how to use an open source solution like Prometheus
    to export Jenkins custom metrics, including its integration with the scaling process
    of Jenkins workers.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在第 13 章中，我们将介绍如何使用 Prometheus 等开源解决方案来导出 Jenkins 自定义指标，包括其与 Jenkins 工作节点扩展过程的集成。
- en: Figure 6.14 summarizes the architecture we’re going to deploy in this section.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.14 总结了本节将要部署的架构。
- en: '![](Images/CH06_F14_Labouardy.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F14_Labouardy.png)'
- en: Figure 6.14 Jenkins cluster deployment on Google Cloud
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.14 Google Cloud 上 Jenkins 集群部署
- en: First, create a jenkins_workers.tf file and define the instance template that
    will be used as a blueprint to define the Jenkins workers configurations; see
    the following listing.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个 jenkins_workers.tf 文件，并定义将用作定义 Jenkins 工作节点配置的蓝图；请参阅以下列表。
- en: Listing 6.13 Jenkins worker template configuration
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.13 Jenkins工作模板配置
- en: '[PRE18]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ A shell script that will be executed the first time the VM instance is launched.
    The script will autojoin the instance as a Jenkins agent.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 一个在VM实例首次启动时执行的shell脚本。该脚本将自动将实例加入为Jenkins代理。
- en: We will deploy the instances inside a private subnetwork and will execute the
    startup script in the following listing to make the running virtual machine join
    the cluster. This script is similar to the shell script provided in chapter 5’s
    listing 5.7.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在私有子网络内部署实例，并执行以下列表中的启动脚本，使正在运行的虚拟机加入集群。此脚本类似于第5章列表5.7中提供的shell脚本。
- en: Listing 6.14 Jenkins worker startup script
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.14 Jenkins工作启动脚本
- en: '[PRE19]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ The join-cluster.tpl template file takes as parameters the Jenkins credentials
    and URL. The values will be interpolated at runtime.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ `join-cluster.tpl` 模板文件接受Jenkins凭据和URL作为参数。这些值将在运行时进行插值。
- en: We will be using the Google Cloud metadata server to fetch the instance name
    and private IP address. The metadata server request’s output is in JSON format,
    so we’ll use the `jq` utility to parse the JSON and grab the target attributes.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Google Cloud元数据服务器来获取实例名称和私有IP地址。元数据服务器请求的输出是JSON格式，因此我们将使用`jq`实用程序来解析JSON并获取目标属性。
- en: '[PRE20]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Next, we will define a firewall rule to allow SSH on Jenkins workers from the
    Jenkins master and bastion host, as shown in the following listing.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个防火墙规则，允许从Jenkins主节点和堡垒主机到Jenkins工作节点的SSH访问，如下所示。
- en: Listing 6.15 Jenkins master firewall and traffic control
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.15 Jenkins主防火墙和流量控制
- en: '[PRE21]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ Allows inbound traffic on port 22 (SSH)
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 允许端口22（SSH）上的入站流量
- en: Then, we define an instance group based on the template file with a target size
    of two workers by default; see the next listing.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们基于模板文件定义一个实例组，默认目标大小为两个工作节点；请参阅下一列表。
- en: Listing 6.16 Jenkins worker instance group
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.16 Jenkins工作实例组
- en: '[PRE22]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Creates and manages pools of homogeneous VM instances (two instances) from
    a common instance template (jenkins-worker-template)
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从一个公共实例模板（jenkins-worker-template）创建和管理同质VM实例池（两个实例）
- en: Once the new resources are deployed with `terraform apply`, two worker instances
    should be running, as shown in figure 6.15.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦使用 `terraform apply` 部署了新资源，应该有两个工作实例正在运行，如图6.15所示。
- en: '![](Images/CH06_F15_Labouardy.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F15_Labouardy.png)'
- en: Figure 6.15 Jenkins worker instance groups
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.15 Jenkins工作实例组
- en: However, the number of workers is static and fixed, for now. To be able to scale
    Jenkins workers for heavy build jobs, we will deploy an autoscaler based on CPU
    utilization. Define the following resource to trigger a scale-out event if the
    CPU utilization is over 80%. Within jenkins_workers.tf, add the code in the following
    listing.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，目前工作节点的数量是静态和固定的。为了能够为重构建作业扩展Jenkins工作节点，我们将基于CPU利用率部署一个自动扩展器。定义以下资源以触发超过80%CPU利用率的扩展事件。在jenkins_workers.tf中添加以下列表中的代码。
- en: Listing 6.17 Jenkins worker autoscaler
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.17 Jenkins工作自动扩展器
- en: '[PRE23]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Scales Jenkins worker instances in managed instance groups according to the
    autoscaling policy. The policy is based on the CPU utilization of the instances.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 根据自动扩展策略在托管实例组中扩展Jenkins工作实例。该策略基于实例的CPU利用率。
- en: Once the changes are deployed with Terraform, the autoscaling policy will be
    configured on the Jenkins worker instance group, as you can see in figure 6.16.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦使用Terraform部署了更改，将在Jenkins工作实例组上配置自动扩展策略，如图6.16所示。
- en: '![](Images/CH06_F16_Labouardy.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F16_Labouardy.png)'
- en: Figure 6.16 Instance group scaling based on CPU utilization
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.16基于CPU利用率的实例组扩展
- en: As a result, the workers will automatically join the cluster after the startup
    script is executed (figure 6.17). Awesome! You are running a Jenkins cluster on
    GCP.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在启动脚本执行后，工作节点将自动加入集群（图6.17）。太棒了！您已经在GCP上运行了一个Jenkins集群。
- en: '![](Images/CH06_F17_Labouardy.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F17_Labouardy.png)'
- en: Figure 6.17 Jenkins worker VM instances joined the cluster.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.17 Jenkins工作虚拟机实例已加入集群。
- en: 6.2 Microsoft Azure
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 微软Azure
- en: Both Microsoft Azure and AWS follow a similar approach by offering a variety
    of cloud-based services under one hood. However, organizations that use Microsoft
    software typically have an Enterprise Agreement that provides discounts on that
    software. These organizations can typically obtain significant incentives for
    using Azure.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 微软Azure和AWS通过提供一个云服务集合，采用类似的方法。然而，通常使用微软软件的组织有一个企业协议，该协议提供该软件的折扣。这些组织通常可以获得使用Azure的显著激励。
- en: If you plan to use Azure, you can deploy the Jenkins solution template from
    the Azure Marketplace. However, if you’re looking to have full control over Jenkins,
    follow this section to learn how to build a Jenkins cluster from scratch and scale
    your Jenkins workers on demand based on Azure virtual machines.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划使用Azure，你可以从Azure Marketplace部署Jenkins解决方案模板。然而，如果你想要完全控制Jenkins，请遵循本节学习如何从头开始构建Jenkins集群，并根据Azure虚拟机按需扩展你的Jenkins工作节点。
- en: Note While Azure and Google Cloud have seen a fairly significant amount of growth,
    AWS is still the leader. This is mainly due to AWS being the first to invest in
    and shape the cloud computing industry. Google Cloud and Azure have some catching
    up to do.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：虽然Azure和Google Cloud已经看到了相当显著的增长，但AWS仍然是领导者。这主要是因为AWS是第一个投资并塑造云计算行业的。Google
    Cloud和Azure还有一些追赶的余地。
- en: Before getting started, if you’re new to Azure, you may sign up for an Azure
    free account ([https://portal.azure.com/](https://portal.azure.com/)) to start
    exploring with a free $200 credit.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，如果你是Azure的新用户，你可以注册一个Azure免费账户([https://portal.azure.com/](https://portal.azure.com/))，以免费$200信用额度开始探索。
- en: 6.2.1 Building golden Jenkins VM images in Azure
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 在Azure中构建金 Jenkins VM镜像
- en: During the build process, Packer creates temporary Azure resources as it builds
    the source VM. Therefore, it needs to be authorized to interact with the Azure
    API.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建过程中，Packer在构建源虚拟机时会创建临时Azure资源。因此，它需要被授权与Azure API交互。
- en: Create an Azure service principal (SP) with permissions to create and manage
    resources with the following commands. An SP represents an application accessing
    your Azure resources. It is identified by a client ID (aka *application ID*) and
    can use a password or a certificate for authentication.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令创建一个具有创建和管理资源权限的Azure服务主体（SP）。SP代表一个访问你的Azure资源的应用程序。它通过客户端ID（也称为*应用程序ID*）进行标识，可以使用密码或证书进行身份验证。
- en: 'To create an SP, copy these commands:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个服务主体（SP），请复制以下命令：
- en: '[PRE24]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: You can execute the commands on Azure PowerShell, as shown in figure 6.18.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在Azure PowerShell上执行这些命令，如图6.18所示。
- en: '![](Images/CH06_F18_Labouardy.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F18_Labouardy.png)'
- en: Figure 6.18 Creating Azure credentials
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.18 创建Azure凭据
- en: 'Then output the password and application ID by executing the following commands:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过执行以下命令输出密码和应用程序ID：
- en: '[PRE25]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Save the application ID and password for later.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用程序ID和密码保存以备后用。
- en: To authenticate to Azure, you also need to obtain your Azure tenant and subscription
    IDs, which can be fetched with `Get-AzSubscription` or from Azure Active Directory
    (AD). AD, shown in figure 6.19, is an identity management service that controls
    access and security to Azure resources with the right roles and permissions.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 要对Azure进行身份验证，你还需要获取你的Azure租户和订阅ID，这些可以通过`Get-AzSubscription`或从Azure Active
    Directory (AD)获取。AD，如图6.19所示，是一个身份管理服务，它通过正确的角色和权限控制对Azure资源的访问和安全。
- en: '![](Images/CH06_F19_Labouardy.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F19_Labouardy.png)'
- en: Figure 6.19 Packer registration on Azure Active Directory
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.19 Packer在Azure Active Directory上的注册
- en: Note the client ID and key. This will be used as credentials in Packer to provision
    resources in Azure.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 注意客户端ID和密钥。这将在Packer中用作在Azure中配置资源的凭据。
- en: To build the Jenkins worker image, create a template.json file. In the template,
    you define builders and provisioners that carry out the actual build process.
    Packer has a builder for Azure called `azure-arm` that allows you to define Azure
    images. Add the following content to template.json or download the full template
    from chapter6/azure/packer/worker/template.json.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建Jenkins工作节点镜像，创建一个template.json文件。在模板中，你定义执行实际构建过程的构建器和配置器。Packer有一个名为`azure-arm`的Azure构建器，允许你定义Azure镜像。将以下内容添加到template.json或从chapter6/azure/packer/worker/template.json下载完整的模板。
- en: Listing 6.18 Jenkins worker template with Azure builder
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.18带有Azure构建器的Jenkins工作节点模板
- en: '[PRE26]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ List of runtime variables to make the Packer template portable and reusable
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 运行时变量列表，使Packer模板可移植和可重复使用
- en: ❷ Packer will provision an instance of type Standard_B1s (1 RAM and 1vCPU) based
    on the CentOS 8.0 machine image.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ Packer将基于CentOS 8.0机器镜像部署一个类型为Standard_B1s（1 RAM和1vCPU）的实例。
- en: If you’re running Packer in a virtual machine, you can assign a managed identity
    to the virtual machine. No configuration properties are required to be set.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在一个虚拟机上运行Packer，你可以为虚拟机分配一个托管标识。不需要设置任何配置属性。
- en: The template in listing 6.18 deploys a temporary instance based on CentOS 8.0
    and provisions the instance with a shell script to install needed dependencies.
    The choice of CentOS is not arbitrary. Both Amazon Linux Image and CentOS have
    similarities, especially the support of the Yum package manager. To use the same
    scripts provided in previous chapters and keep consistent and identical Jenkins
    images, we’ll use CentOS.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.18中的模板部署了一个基于CentOS 8.0的临时实例，并使用shell脚本安装所需的依赖项。选择CentOS并非偶然。Amazon Linux镜像和CentOS具有相似之处，特别是对Yum包管理器的支持。为了使用前几章中提供的相同脚本并保持Jenkins镜像的一致性和相同性，我们将使用CentOS。
- en: 'Bake the image with the `packer build` command. Here’s an example of the output:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`packer build`命令烘焙镜像。以下是一个输出示例：
- en: '![](Images/CH06_F19_UN07_Labouardy.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F19_UN07_Labouardy.png)'
- en: It takes a few minutes for Packer to build the VM, run the provisioners, and
    bake the Jenkins worker image. Once completed, the image is created in the resource
    group set in the `resource_group` variable, as shown in figure 6.20.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Packer构建虚拟机、运行配置程序和烘焙Jenkins工作镜像需要几分钟时间。一旦完成，镜像将在`resource_group`变量设置的资源组中创建，如图6.20所示。
- en: '![](Images/CH06_F20_Labouardy.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F20_Labouardy.png)'
- en: Figure 6.20 Jenkins worker machine image
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.20 Jenkins工作机镜像
- en: A similar workflow will be applied to build the Jenkins master image. The following
    is the template.json file (the complete template is available at chapter6/azure/packer/master/template.json).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用类似的流程来构建Jenkins主镜像。以下为template.json文件（完整的模板可在chapter6/azure/packer/master/template.json中找到）。
- en: Listing 6.19 Jenkins worker template with Azure builder
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.19带有Azure构建器的Jenkins工作模板
- en: '[PRE27]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ List of variables has been omitted for brevity; the complete list is in listing
    6.18.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为了简洁起见，省略了变量列表；完整的列表在列表6.18中。
- en: Once the template is defined, bake the image with Packer. The baking process
    should take a few minutes to create the image. Once the image has been created,
    it should be available on the Images dashboard from the Azure portal, as shown
    in figure 6.21.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了模板，就使用Packer烘焙镜像。烘焙过程需要几分钟来创建镜像。一旦镜像创建完成，它应该可以从Azure门户的镜像仪表板中访问，如图6.21所示。
- en: '![](Images/CH06_F21_Labouardy.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F21_Labouardy.png)'
- en: Figure 6.21 Jenkins master machine image
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.21 Jenkins主机机器镜像
- en: With both Jenkins master and worker images available, you can now create a Jenkins
    cluster from your custom images with Terraform.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有了Jenkins主和工镜像，您现在可以使用Terraform从自定义镜像创建Jenkins集群。
- en: 6.2.2 Deploying a private virtual network
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 部署私有虚拟网络
- en: Before deploying the Jenkins cluster, we need to set up a private network with
    the architecture shown in figure 6.22 to secure access to the cluster.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署Jenkins集群之前，我们需要设置一个与图6.22所示的架构相同的私有网络，以保护集群的访问安全。
- en: '![](Images/CH06_F22_Labouardy.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F22_Labouardy.png)'
- en: Figure 6.22 VPN on Azure
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.22 Azure上的VPN
- en: Note To enable Terraform to provision resources into Azure, create an Azure
    Active Directory service principal by following the same steps described in section
    6.2.1.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：为了使Terraform能够将资源部署到Azure，请按照第6.2.1节中描述的相同步骤创建一个Azure Active Directory服务主体。
- en: Create a terraform.tf file and declare `azurerm` as a provider, as shown in
    the following listing. The `provider` section tells Terraform to use an Azure
    provider. To get values for `subscription_id`, `client_id`, `client_secret`, and
    `tenant_id`, see section 6.2.1.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个terraform.tf文件并声明`azurerm`为提供者，如下所示。`provider`部分告诉Terraform使用Azure提供者。要获取`subscription_id`、`client_id`、`client_secret`和`tenant_id`的值，请参阅第6.2.1节。
- en: Listing 6.20 Defining an Azure provider
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.20定义Azure提供者
- en: '[PRE28]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Run `terraform init` to download the latest version of the Azure plugin and
    build the .terraform directory:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`terraform init`以下载最新的Azure插件并构建.terraform目录：
- en: '![](Images/CH06_F22_UN08_Labouardy.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F22_UN08_Labouardy.png)'
- en: Next, create a virtual_network.tf file on which you define a virtual network
    called `management` in the 10.0.0.0/16 address space with public and private subnets
    and an additional subnet called `AzureBastionSubnet` reserved for a bastion host,
    as shown in the following listing.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个virtual_network.tf文件，在该文件中定义一个名为`management`的虚拟网络，该网络位于10.0.0.0/16地址空间内，包含公共和私有子网，以及一个名为`AzureBastionSubnet`的额外子网，用于堡垒主机，如下所示。
- en: Listing 6.21 Azure virtual network definition
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.21 Azure虚拟网络定义
- en: '[PRE29]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: ❶ List of IP addresses of DNS servers
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ DNS服务器IP地址列表
- en: ❷ Defines a list of subnets within the 10.0.0.0/16 space
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在10.0.0.0/16空间内定义子网列表
- en: ❸ Defines a dedicated subnet where the Bastion host will be deployed
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义一个专用的子网，其中将部署堡垒主机
- en: Note We can tag our resources in Azure with a key-value pair. It’s useful for
    cost optimization. So we will add the `environment` tag with value management
    to all the resources we create.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们可以在 Azure 中使用键值对标记我们的资源。这对于成本优化很有用。因此，我们将添加 `environment` 标记并设置值为 management，以标记我们创建的所有资源。
- en: Before applying the changes, declare the variables used to parameterize and
    customize the Terraform deployment in variables.tf. Table 6.2 lists the variables.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用更改之前，在 variables.tf 中声明用于参数化和自定义 Terraform 部署的变量。表 6.2 列出了变量。
- en: Table 6.2 Azure Terraform variables
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6.2 Azure Terraform 变量
- en: '| Name | Type | Value | Description |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 类型 | 值 | 描述 |'
- en: '| `subscription_id` | String | None | The subscription ID to be used. This
    can also be sourced from the `ARM_SUBSCRIPTION_ID` environment variable. |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| `subscription_id` | 字符串 | None | 要使用的订阅 ID。这也可以从 `ARM_SUBSCRIPTION_ID` 环境变量中获取。|'
- en: '| `client_id` | String | None | The client ID to be used. This can also be
    sourced from the `ARM_CLIENT_ID` environment variable. |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| `client_id` | 字符串 | None | 要使用的客户端 ID。这也可以从 `ARM_CLIENT_ID` 环境变量中获取。|'
- en: '| `client_secret` | String | None | The client secret to be used. This can
    also be sourced from the `ARM_CLIENT_SECRET` environment variable. |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| `client_secret` | 字符串 | None | 要使用的客户端密钥。这也可以从 `ARM_CLIENT_SECRET` 环境变量中获取。|'
- en: '| `tenant_id` | String | None | The Tenant/Directory ID to be used. This can
    also be sourced from the `ARM_TENANT_ID` environment variable |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| `tenant_id` | 字符串 | None | 要使用的租户/目录 ID。这也可以从 `ARM_TENANT_ID` 环境变量中获取 |'
- en: '| `resource_group` | String | None | The name of the resource group in which
    to create the virtual network. |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| `resource_group` | 字符串 | None | 创建虚拟网络的资源组名称。|'
- en: '| `location` | String | None | The location/region where the virtual network
    is created. Changing this forces a new resource to be created. Refer to Azure
    Locations documentation for a full list of supported locations. |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| `location` | 字符串 | None | 虚拟网络创建的位置/区域。更改此设置将强制创建新的资源。有关支持位置的全列表，请参阅 Azure
    位置文档。|'
- en: '| `base_cidr_block` | String | `10.0.0.0/16` | The address space (CIDR block)
    that is used for the virtual network. |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| `base_cidr_block` | 字符串 | `10.0.0.0/16` | 用于虚拟网络的地址空间（CIDR 块）。|'
- en: '| `subnets` | Map | None | A map holding a list of subnets to create inside
    the virtual network. |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| `subnets` | 映射 | None | 一个包含要在虚拟网络内部创建的子网列表的映射。|'
- en: 'When authenticating as a service principal using a client certificate, the
    following fields should be set: `client_certificate_password` and `client_certificate_
    path`.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用客户端证书作为服务主体进行身份验证时，应设置以下字段：`client_certificate_password` 和 `client_certificate_path`。
- en: 'Now it’s time to run the `terraform` `apply` command. Terraform will call Azure
    APIs to set up the new virtual network as shown here:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候运行 `terraform` `apply` 命令了。Terraform 将调用 Azure API 来设置新的虚拟网络，如下所示：
- en: '![](Images/CH06_F22_UN09_Labouardy.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F22_UN09_Labouardy.png)'
- en: To verify the results within the Azure portal, browse to the management resource
    group. The new virtual network is located under this group, as shown in figure
    6.23.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Azure 门户中验证结果，请浏览到管理资源组。新的虚拟网络位于此组下，如图 6.23 所示。
- en: To access private Jenkins machines, we need to deploy a gateway or proxy servers,
    also known as jump boxes or bastion hosts. Fortunately, Azure provides a managed
    service called Azure Bastion offering Remote Desktop Protocol (RDP) and SSH access
    to any VM without the need to manage a hardened bastion instance and apply security
    patches (no operational overhead).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问私有 Jenkins 机器，我们需要部署网关或代理服务器，也称为跳板或堡垒主机。幸运的是，Azure 提供了一个名为 Azure Bastion
    的托管服务，它提供远程桌面协议 (RDP) 和 SSH 访问任何 VM，无需管理加固的堡垒实例并应用安全补丁（无运营开销）。
- en: '![](Images/CH06_F23_Labouardy.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F23_Labouardy.png)'
- en: Figure 6.23 Management virtual network
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.23 管理虚拟网络
- en: 'To deploy the Azure Bastion service into the existing Azure virtual network,
    create a bastion.tf file with the following content. The bastion host service
    will be deployed into the dedicated `AzureBastionSubnet` subnet:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Azure Bastion 服务部署到现有的 Azure 虚拟网络中，创建一个包含以下内容的 bastion.tf 文件。堡垒主机服务将部署到专用的
    `AzureBastionSubnet` 子网中：
- en: Listing 6.22 Azure Bastion service deployment
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.22 Azure Bastion 服务部署
- en: '[PRE30]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ❶ Requests a static public IP address
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 请求静态公共 IP 地址
- en: ❷ Reference to a subnet in which the bastion host will be created. It also associates
    the provisioned public IP address to the bastion host.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 引用要创建堡垒主机的子网。它还将已配置的公共 IP 地址关联到堡垒主机。
- en: Use a Terraform output variable to act as a helper to expose the bastion IP
    address by referencing the `azurerm_public_ip` resource.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Terraform输出变量作为辅助工具，通过引用`azurerm_public_ip`资源来公开堡垒IP地址。
- en: Listing 6.23 Bastion host public IP address
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.23堡垒主机公共IP地址
- en: '[PRE31]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Run `terraform` `apply` to apply the configuration. A bastion service will be
    deployed into the `management` resource group, as shown in figure 6.24.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`terraform apply`以应用配置。堡垒服务将部署到`management`资源组中，如图6.24所示。
- en: '![](Images/CH06_F24_Labouardy.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F24_Labouardy.png)'
- en: Figure 6.24 Azure bastion host
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.24 Azure堡垒主机
- en: 6.2.3 Deploying a Jenkins master virtual machine
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.3 部署Jenkins主虚拟机
- en: With the VPN being deployed, we can deploy our Jenkins cluster. Figure 6.25
    summarizes the target architecture.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 部署VPN后，我们可以部署我们的Jenkins集群。图6.25总结了目标架构。
- en: '![](Images/CH06_F25_Labouardy.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F25_Labouardy.png)'
- en: Figure 6.25 Jenkins VM inside a private subnet
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.25私有子网内的Jenkins VM
- en: Deploy a virtual machine based on the Jenkins master image built with Packer
    earlier. Define the resource in jenkins_master.tf with the following code.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 部署一个基于之前使用Packer构建的Jenkins主镜像的虚拟机。在`jenkins_master.tf`中定义资源，以下代码。
- en: Listing 6.24 Jenkins master virtual machine
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.24 Jenkins主虚拟机
- en: '[PRE32]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ Disables password authentication and enables SSH as an authentication mechanism
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 禁用密码验证并启用SSH作为认证机制
- en: ❷ Specifies the type of managed disk that should be created. Possible values
    are Standard_LRS, StandardSSD_LRS, or Premium_LRS.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 指定应创建的托管磁盘类型。可能的值是Standard_LRS、StandardSSD_LRS或Premium_LRS。
- en: ❸ Provisions the VM from the baked Jenkins master image
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 从烘焙的Jenkins主镜像配置VM
- en: ❹ Deletes the OS disk automatically when deleting the VM
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 删除VM时自动删除OS磁盘
- en: Note We allowed 30 GB as the disk size for the virtual machine. Jenkins needs
    some disk space to perform builds and keep archives and build logs.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们为虚拟机允许了30GB的磁盘大小。Jenkins需要一些磁盘空间来执行构建并保存存档和构建日志。
- en: SSH key data is provided in the `ssh_key` section, and the username is provided
    in the `os_profile` section with password authentication disabled.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: SSH密钥数据位于`ssh_key`部分，用户名位于禁用密码验证的`os_profile`部分。
- en: The Jenkins virtual machine uses the B-Series Azure VM family with burstable
    CPU performances. This VM family provides the right balance between computing
    and network bandwidth. I recommend selecting your VM family type based on your
    project build needs and requirements.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: Jenkins虚拟机使用具有可扩展CPU性能的B系列Azure VM家族。这个VM家族在计算和网络带宽之间提供了正确的平衡。我建议根据你的项目构建需求和需求选择你的VM家族类型。
- en: Listing 6.24 created a VM named `jenkins-master`, and now we’ll attach the virtual
    network interface, as shown in the following listing.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.24创建了一个名为`jenkins-master`的VM，现在我们将附加虚拟网络接口，如下所示。
- en: Listing 6.25 Jenkins VM network configuration
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.25 Jenkins VM网络配置
- en: '[PRE33]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ Deploys the Jenkins master instance in a private subnet and assigns a dynamic
    private IP address
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在私有子网中部署Jenkins主实例并分配一个动态私有IP地址
- en: The virtual network interface connects the Jenkins master to the private network
    subnet.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟网络接口将Jenkins主实例连接到私有网络子网。
- en: Once you provide the needed Terraform variables in variables.tfvars, issue `terraform`
    `apply`. Creating the Jenkins VM, shown in figure 6.26, from your Packer image
    and the expected resources takes a few minutes.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在`variables.tfvars`中提供了所需的Terraform变量，就执行`terraform apply`。从你的Packer镜像和预期资源创建Jenkins
    VM（如图6.26所示）需要几分钟。
- en: '![](Images/CH06_F26_Labouardy.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F26_Labouardy.png)'
- en: Figure 6.26 Jenkins master virtual machine
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.26 Jenkins主虚拟机
- en: The Jenkins virtual machine should be accessible through a Bastion host only.
    Figure 6.27 confirms that the machine was deployed within a private subnet.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Jenkins虚拟机应仅通过堡垒主机访问。图6.27确认该机器是在私有子网中部署的。
- en: '![](Images/CH06_F27_Labouardy.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F27_Labouardy.png)'
- en: Figure 6.27 Jenkins master deployed in a private subnet
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.27在私有子网中部署的Jenkins主实例
- en: However, to access the Jenkins dashboard, we will deploy a load balancer in
    front of the VM. Create a loadbalancers.tf file on which you define an Azure load
    balancer and a security rule to serve the Jenkins dashboard and attach it to a
    public IP address, as shown in the following listing.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，要访问Jenkins仪表板，我们将在VM前面部署一个负载均衡器。在`loadbalancers.tf`文件上创建一个文件，定义一个Azure负载均衡器和一条安全规则来服务Jenkins仪表板，并将其附加到公共IP地址，如下所示。
- en: Listing 6.26 Jenkins dashboard load balancer configuration
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.26 Jenkins仪表板负载均衡器配置
- en: '[PRE34]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: ❶ Associates a public IP address to the load balancer
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将公网IP地址关联到负载均衡器
- en: ❷ The load balancer listens on port 80 for incoming requests and communicates
    with the Jenkins master instance through port 8080.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 负载均衡器监听80端口以接收传入请求，并通过8080端口与Jenkins主实例通信。
- en: ❸ The load balancer listens on port 80 for incoming requests and communicates
    with the Jenkins master instance through port 8080.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 负载均衡器监听80端口以接收传入请求，并通过8080端口与Jenkins主实例通信。
- en: Within the same file, define an Azure backend address pool and assign it to
    the load balancer. Then set a health check on port 8080, as shown in the following
    listing.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一文件中，定义一个Azure后端地址池并将其分配给负载均衡器。然后设置端口8080的健康检查，如下所示。
- en: Listing 6.27 Jenkins dashboard health check
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.27 Jenkins仪表板健康检查
- en: '[PRE35]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: ❶ The URI used for requesting health status from the backend endpoint
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 用于从后端端点请求健康状态的URI
- en: ❷ Port on which the probe queries the backend endpoint
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 探针查询后端端点的端口
- en: Azure allows for opening ports to traffic via security groups, which can also
    be managed in the Terraform configuration. Add the following to security_groups.tf
    and proceed to run `plan/apply` to create the security rule to allow inbound traffic
    on port 8080 and SSH traffic on TCP port 22.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: Azure允许通过安全组打开端口以允许流量，这也可以在Terraform配置中管理。将以下内容添加到security_groups.tf中，然后运行`plan/apply`以创建允许在端口8080上入站流量和在TCP端口22上SSH流量的安全规则。
- en: Listing 6.28 Jenkins master security group
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.28 Jenkins主安全组
- en: '[PRE36]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: ❶ Allows inbound traffic on port 22 (SSH) from anywhere
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 允许来自任何地方的22端口（SSH）的入站流量
- en: ❷ Allows inbound traffic on port 8080, where the Jenkins web dashboard is served
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 允许在8080端口上入站流量，这是Jenkins Web仪表板提供服务的端口
- en: Finally, assign the security group to the virtual network interface attached
    to the Jenkins master virtual machine, as shown in the following listing.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将安全组分配给连接到Jenkins主虚拟机的虚拟网络接口，如下所示。
- en: Listing 6.29 Jenkins network interface configuration
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.29 Jenkins网络接口配置
- en: '[PRE37]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: ❶ Assigns the Jenkins security group to the virtual network interface configured
    in a private subnet
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将Jenkins安全组分配给配置在私有子网中的虚拟网络接口
- en: Apply the changes with the `terraform apply` command. Once Terraform completes,
    your load balancer is ready. Obtain its public IP address from outputs.tf by adding
    the following code.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`terraform apply`命令应用更改。一旦Terraform完成，您的负载均衡器就准备好了。通过在outputs.tf中添加以下代码获取其公网IP地址。
- en: Listing 6.30 Jenkins master firewall and traffic control
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.30 Jenkins主防火墙和流量控制
- en: '[PRE38]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Let’s verify the resources by using the Azure portal. As you can see in figure
    6.28, Terraform created all the expected resources under the `management` resource
    group.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Azure门户验证资源。如图6.28所示，Terraform在`management`资源组下创建了所有预期的资源。
- en: '![](Images/CH06_F28_Labouardy.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F28_Labouardy.png)'
- en: Figure 6.28 Public load balancer pointing to Jenkins master VM
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.28指向Jenkins主VM的公共负载均衡器
- en: Now point your web browser to the public IP address of the load balancer in
    the address bar. The default Jenkins home page will be displayed, as shown in
    figure 6.29.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将您的网络浏览器指向地址栏中负载均衡器的公网IP地址。默认的Jenkins主页将显示，如图6.29所示。
- en: '![](Images/CH06_F29_Labouardy.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F29_Labouardy.png)'
- en: Figure 6.29 Jenkins dashboard accessible from LB public IP address
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.29可通过LB公网IP地址访问的Jenkins仪表板
- en: You can now sign in with admin credentials defined in the Groovy init scripts
    while baking the Jenkins master machine image.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在烘焙Jenkins主机镜像时，您可以使用Groovy初始化脚本中定义的管理凭据进行登录。
- en: 6.2.4 Applying autoscaling to Jenkins workers
  id: totrans-334
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.4 将自动扩展应用于Jenkins工作节点
- en: We’re ready to deploy Jenkins workers to offload build projects from the master.
    The workers will be deployed inside an autoscaling set to be provisioned dynamically.
    Figure 6.30 illustrates the target deployment architecture.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好将Jenkins工作节点部署到从主节点卸载构建项目。这些工作节点将在一个自动扩展集中动态配置。图6.30展示了目标部署架构。
- en: '![](Images/CH06_F30_Labouardy.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH06_F30_Labouardy.png)'
- en: Figure 6.30 Jenkins workers scale set
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.30 Jenkins工作节点规模集
- en: We need to deploy Jenkins worker machines inside a machine scale set. A Jenkins
    worker will be based on the Jenkins worker image built earlier with Packer and
    will be deployed inside a private subnet. Create jenkins_workers.tf with the following
    content.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在机器规模集中部署Jenkins工作节点。一个Jenkins工作节点将基于之前使用Packer构建的Jenkins工作节点镜像，并在私有子网内部署。使用以下内容创建jenkins_workers.tf。
- en: Listing 6.31 Jenkins worker machine scale set
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.31 Jenkins工作节点机器规模集
- en: '[PRE39]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: ❶ References the Jenkins worker machine image ID
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 引用Jenkins工作节点机器镜像ID
- en: ❷ Disables password authentication and configures the SSH credentials
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 禁用密码认证并配置SSH凭证
- en: ❸ Assigns a security group to the VM instances and requests private IP addresses
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将安全组分配给虚拟机实例并请求私有IP地址
- en: Note You should test your projects on multiple Azure VM family types to determine
    the appropriate machine type for Jenkins workers, as well as the amount of disk
    space.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您应该在多个Azure VM家族类型上测试您的项目，以确定适合Jenkins工作节点的机器类型以及磁盘空间的大小。
- en: Each Jenkins worker machine will execute a custom script (chapter6/azure/terraform/scripts/join-cluster.tpl)
    at runtime to join the Jenkins cluster; see the following listing.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 每个工作节点机器将在运行时执行一个自定义脚本（chapter6/azure/terraform/scripts/join-cluster.tpl），以加入Jenkins集群；请参阅以下列表。
- en: Listing 6.32 Jenkins workers launch script
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.32 Jenkins工作节点启动脚本
- en: '[PRE40]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: ❶ Initialization script to autojoin the VM as a Jenkins agent
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 初始化脚本以自动将虚拟机作为Jenkins代理加入
- en: 'The script will use Azure Instance Metadata Service (IMDS) to fetch information
    regarding the machine’s private IP address and hostname and will issue a POST
    HTTP request to the Jenkins RESTful API to establish a bidirectional connection
    with the machine and join the cluster:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 该脚本将使用Azure实例元数据服务（IMDS）获取有关机器的私有IP地址和主机名的信息，并将向Jenkins RESTful API发出POST HTTP请求，以建立与机器的双向连接并加入集群：
- en: '[PRE41]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: A security group will be attached to the virtual network interface attached
    to the scale set. It allows inbound traffic on port 22 (SSH), as shown in the
    following listing.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 将安全组附加到与规模集连接的虚拟网络接口。它允许在22端口（SSH）上的入站流量，如下面的列表所示。
- en: Listing 6.33 Jenkins worker security group
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.33 Jenkins工作节点安全组
- en: '[PRE42]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: ❶ Allows incoming traffic on port 22 (SSH) from anywhere. It’s recommended to
    restrict the access to your network CIDR block.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 允许来自任何地方的22端口（SSH）的入站流量。建议限制对您的网络CIDR块的访问。
- en: Once the deployment has completed, the content of the resource group resembles
    that shown in figure 6.31.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 部署完成后，资源组的内文将类似于图6.31所示。
- en: '![](Images/CH06_F31_Labouardy.png)'
  id: totrans-356
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F31_Labouardy.png)'
- en: Figure 6.31 Jenkins worker virtual machine scale set
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.31 Jenkins工作节点虚拟机规模集
- en: By default, two Jenkins workers will be up and running, as shown in figure 6.32.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，将有两个Jenkins工作节点运行，如图6.32所示。
- en: '![](Images/CH06_F32_Labouardy.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F32_Labouardy.png)'
- en: Figure 6.32 Static number of Jenkins workers
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.32 Jenkins工作节点静态数量
- en: To be able to scale workers based on build jobs and pipeline running, we will
    use Azure autoscale policies to trigger a scale-out or scale-in based on CPU utilization
    of the worker machines. Within jenkins_workers.tf, add the following `resource`
    block.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够根据构建作业和正在运行的流水线进行扩展，我们将使用Azure自动缩放策略，根据工作机的CPU利用率触发扩展或缩减。在jenkins_workers.tf中，添加以下`resource`块。
- en: Listing 6.34 Jenkins worker autoscaling policies
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.34 Jenkins工作节点自动缩放策略
- en: '[PRE43]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: ❶ Defines the minimum and maximum numbers of Jenkins workers
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 定义Jenkins工作节点的最小和最大数量
- en: ❷ Monitors the CPU utilization of the workers—if it hits 80%, a new Jenkins
    worker’s VM will be deployed.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 监控工作节点的CPU利用率——如果达到80%，将部署新的Jenkins工作节点虚拟机。
- en: ❸ Monitors the CPU utilization of the workers—if it’s below 20%, an existing
    Jenkins worker VM will be terminated.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 监控工作节点的CPU利用率——如果低于20%，将终止现有的Jenkins工作节点虚拟机。
- en: Apply the changes with `terraform` `apply`. Then, head over to the Jenkins worker
    scale set configuration. In the Scaling section, define a new autoscale policy,
    as shown in figure 6.33.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`terraform apply`应用更改。然后，前往Jenkins工作节点规模集配置。在缩放部分，定义一个新的自动缩放策略，如图6.33所示。
- en: '![](Images/CH06_F33_Labouardy.png)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F33_Labouardy.png)'
- en: Figure 6.33 Jenkins worker autoscaling policies
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.33 Jenkins工作节点自动缩放策略
- en: Note Once you’re finished playing with the Jenkins cluster, you will likely
    want to tear down everything that was created so that you don’t incur any further
    costs.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：一旦您完成对Jenkins集群的实验，您可能希望拆除所有创建的内容，以免产生额外的费用。
- en: Great! You are now able to deploy a self-healing Jenkins cluster on Microsoft
    Azure.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！您现在能够在Microsoft Azure上部署一个自我修复的Jenkins集群。
- en: 6.3 DigitalOcean
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 DigitalOcean
- en: 'When we think of cloud computing providers, we are typically referring to the
    three giants in the industry: Azure, Google Cloud, and AWS. Unlike those providers
    that are known to everyone, DigitalOcean ([www.digitalocean.com](https://www.digitalocean.com))
    is relatively new. You might be wondering why you should choose DigitalOcean over
    other providers. The reason lies in the differences between the three big players
    and DigitalOcean.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想到云服务提供商时，我们通常指的是行业中的三大巨头：Azure、Google Cloud和AWS。与众所周知的服务提供商不同，DigitalOcean
    ([www.digitalocean.com](https://www.digitalocean.com)) 相对较新。你可能会想知道为什么你应该选择DigitalOcean而不是其他提供商。原因在于三大巨头与DigitalOcean之间的差异。
- en: They differ in many aspects. One is small, while the others (AWS, GCP, and Azure)
    are huge. DigitalOcean provides virtual machines (called *Droplets*). There are
    no bells and whistles. You do not get lost in a catalog of services, since they
    are almost nonexistent. Plus, DigitalOcean’s interface allows developers to quickly
    set up machines because of its friendly design. Moreover, it’s affordable and
    has cheaper instances, which is a good starting point for beginner businesses
    and startups. (If you don’t have a DigitalOcean account, you will need to create
    one; you will get $100 of free credits.)
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 它们在许多方面都存在差异。一个是小的，而其他（AWS、GCP和Azure）则是巨大的。DigitalOcean提供虚拟机（称为*Droplets*）。没有花哨的功能。你不会迷失在服务目录中，因为它们几乎不存在。此外，DigitalOcean的界面因其友好的设计而允许开发者快速设置机器。而且，它价格合理，有更便宜的实例，这对于初涉商业和初创企业来说是一个良好的起点。（如果你还没有DigitalOcean账户，你需要创建一个；你将获得100美元的免费信用额。）
- en: To use Packer with DigitalOcean, we first need to generate a DigitalOcean API
    token. This can be done on the DigitalOcean Applications & API page. Click the
    Generate New Token button to obtain a token with read and write permissions, as
    shown in figure 6.34.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Packer与DigitalOcean，我们首先需要生成一个DigitalOcean API令牌。这可以在DigitalOcean应用程序和API页面上完成。点击“生成新令牌”按钮以获取具有读写权限的令牌，如图6.34所示。
- en: '![](Images/CH06_F34_Labouardy.png)'
  id: totrans-376
  prefs: []
  type: TYPE_IMG
  zh: '![Images/CH06_F34_Labouardy.png]'
- en: Figure 6.34 Packer API access token
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.34 Packer API访问令牌
- en: 6.3.1 Creating Jenkins DigitalOcean Snapshots
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.1 创建Jenkins DigitalOcean快照
- en: We’re using the same template covered in listings 6.1 and 6.2; the only difference
    is the use of the `digitalocean` Packer builder to interact with the DigitalOcean
    API. The builder takes a CentOS source image and runs the provisioning necessary—installing
    the tools required for building Jenkins jobs on the image after launching it—and
    then snapshots it into a reusable image; see the following listing. This reusable
    image can then be used as the foundation of new Jenkins workers that are launched
    within DigitalOcean by using Terraform.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用的是与列表6.1和6.2中相同的模板；唯一的区别是使用`digitalocean` Packer构建器与DigitalOcean API交互。构建器使用CentOS源镜像并运行必要的配置程序——在启动后安装构建Jenkins作业所需的工具，然后将其快照到一个可重复使用的镜像中；请参阅以下列表。这个可重复使用的镜像然后可以作为在DigitalOcean中通过Terraform启动的新Jenkins工作节点的基石。 '
- en: Listing 6.35 Jenkins worker image with DigitalOcean builder
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.35使用DigitalOcean构建器的Jenkins工作节点镜像
- en: '[PRE44]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: ❶ DigitalOcean API token and target region
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ DigitalOcean API令牌和目标区域
- en: ❷ The build Droplet will be based on CentOS 8.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 构建的Droplet将基于CentOS 8。
- en: 'Include your DigitalOcean API token and target region (refer to the official
    documentation for a list of supported regions: [http://mng.bz/EDRJ](http://mng.bz/EDRJ)).
    Then run the `packer` `build` `template.json` command. You’ll get a working Jenkins
    worker image in your DigitalOcean account in a couple of minutes, as shown in
    figure 6.35.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 包含你的DigitalOcean API令牌和目标区域（有关支持区域的列表，请参阅官方文档：[http://mng.bz/EDRJ](http://mng.bz/EDRJ)）。然后运行`packer`
    `build` `template.json`命令。几分钟后，你将在DigitalOcean账户中获得一个可工作的Jenkins工作节点镜像，如图6.35所示。
- en: '![](Images/CH06_F35_Labouardy.png)'
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![Images/CH06_F35_Labouardy.png]'
- en: Figure 6.35 Jenkins worker image snapshot
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.35 Jenkins工作节点镜像快照
- en: Similarly, update the Jenkins master template referenced in listing 6.2 to use
    the `digitalocean` builder. The provisioning part creates a Jenkins credential
    based on a private SSH key used to deploy Jenkins workers. This is needed, as
    Jenkins needs to set up a bidirectional connection with workers via SSH.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，更新列表6.2中引用的Jenkins主模板，以使用`digitalocean`构建器。配置部分创建了一个基于用于部署Jenkins工作节点的私有SSH密钥的Jenkins凭据。这是必需的，因为Jenkins需要通过SSH与工作节点建立双向连接。
- en: Listing 6.36 Jenkins master image with DigitalOcean builder
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 列表6.36使用DigitalOcean构建器的Jenkins主镜像
- en: '[PRE45]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This template has been cropped for brevity. The full JSON file can be downloaded
    from [chapter6/digitalocean/packer/master/template.json](https://github.com/mlabouardy/pipeline-as-code-with-jenkins/blob/master/chapter6/digitalocean/packer/master/template.json).
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁，此模板已被裁剪。完整的 JSON 文件可以从 [chapter6/digitalocean/packer/master/template.json](https://github.com/mlabouardy/pipeline-as-code-with-jenkins/blob/master/chapter6/digitalocean/packer/master/template.json)
    下载。
- en: Run the `packer` `validate` command to make sure that everything is copacetic.
    Then issue a `packer` `build` command. Once the build and provisioning part is
    finished, the Jenkins master snapshot should be ready to be used, as shown in
    figure 6.36.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `packer` `validate` 命令以确保一切正常。然后发出一个 `packer` `build` 命令。一旦构建和配置部分完成，Jenkins
    主机快照应该准备好使用，如图 6.36 所示。
- en: '![](Images/CH06_F36_Labouardy.png)'
  id: totrans-392
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F36_Labouardy.png)'
- en: Figure 6.36 Jenkins master image snapshot
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.36 Jenkins 主机镜像快照
- en: 6.3.2 Deploying a Jenkins master Droplet
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.2 部署 Jenkins 主机 Droplet
- en: In this step, you’ll write Terraform template files for automating Jenkins cluster
    Droplet deployments of the snapshot containing the Jenkins master and worker you
    just built using Packer.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，你需要编写 Terraform 模板文件来自动部署包含你刚刚使用 Packer 构建的 Jenkins 主机和工作节点的快照。
- en: Define a terraform.tf file and declare DigitalOcean as a provider. The provider
    needs to be configured with the proper API token before it can be used, as shown
    in the following listing.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个 terraform.tf 文件并声明 DigitalOcean 为提供者。在可以使用之前，提供者需要配置正确的 API 令牌，如下所示。
- en: Listing 6.37 Defining the DigitalOcean provider
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.37 定义 DigitalOcean 提供者
- en: '[PRE46]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Run `terraform` `init` to download the DigitalOcean plugin needed to translate
    the Terraform instructions into API calls:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `terraform` `init` 下载将 Terraform 指令转换为 API 调用的 DigitalOcean 插件：
- en: '![](Images/CH06_F36_UN10_Labouardy.png)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F36_UN10_Labouardy.png)'
- en: Define a single resource of the type `digitalocean_droplet` named `jenkins-
    master` in the jenkins_master.tf file, as shown in Listing 6.38\. Then set its
    parameters according to the variable values and add an SSH key (using its fingerprint)
    from your DigitalOcean account to the Droplet resource. The deployed Droplet will
    be of type `s-1vcpu-2gb`, which comes up with 1 GB of RAM and 1vCPU.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 在 jenkins_master.tf 文件中定义一个名为 `jenkins-master` 的 `digitalocean_droplet` 类型的单个资源，如下所示。然后根据变量值设置其参数，并将来自你的
    DigitalOcean 账户的 SSH 密钥（使用其指纹）添加到 Droplet 资源中。部署的 Droplet 类型将为 `s-1vcpu-2gb`，它包含
    1 GB RAM 和 1vCPU。
- en: 'For heavier workloads and larger projects, and to handle concurrent users connecting
    to the Jenkins web dashboard, a large Droplet type might be required. Refer to
    the official documentation for the list of available Droplet sizes: [http://mng.bz/N4yD](http://mng.bz/N4yD).'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更重的负载和更大的项目，以及处理连接到 Jenkins 网络仪表板的并发用户，可能需要一个大型 Droplet 类型。请参阅官方文档以获取可用的 Droplet
    大小列表：[http://mng.bz/N4yD](http://mng.bz/N4yD)。
- en: Listing 6.38 Jenkins master Droplet
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.38 Jenkins 主机 Droplet
- en: '[PRE47]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: ❶ Uses the Jenkins master image backed previously with Packer
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用之前用 Packer 打包的 Jenkins 主机镜像
- en: ❷ Provisions a Droplet with 2 GB of RAM and 1vCPU
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 配置一个具有 2 GB RAM 和 1vCPU 的 Droplet
- en: On DigitalOcean, you can upload your SSH public key to your account, which lets
    you add it to your Droplets at creation time (figure 6.37). This lets you log
    in to your Jenkins master without a password while still remaining secure.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DigitalOcean 上，你可以将你的 SSH 公钥上传到你的账户，这样你就可以在创建 Droplet 时将其添加到 Droplet 中（如图
    6.37 所示）。这让你可以在 Jenkins 主机上无需密码登录，同时仍然保持安全。
- en: '![](Images/CH06_F37_Labouardy.png)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F37_Labouardy.png)'
- en: Figure 6.37 Adding a public SSH key
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.37 添加公共 SSH 密钥
- en: Next, attach a firewall to the Jenkins master Droplet with rules allowing inbound
    traffic on port 22 and 8080 from anywhere; see the following listing. For security
    purposes, I recommend limiting SSH incoming traffic to your CIDR network block.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，将防火墙附加到 Jenkins 主机 Droplet 上，允许来自任何地方的 22 和 8080 端口的入站流量；请参阅以下列表。出于安全考虑，我建议将
    SSH 入站流量限制到你的 CIDR 网络块。
- en: Listing 6.39 Jenkins master Droplet’s firewall
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.39 Jenkins 主机 Droplet 的防火墙
- en: '[PRE48]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: ❶ Allows inbound traffic on port 22 (SSH) from anywhere
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 允许来自任何地方的 22（SSH）端口的入站流量
- en: ❷ Allows inbound traffic on port 8080, where the Jenkins web dashboard is served
    from
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 允许来自任何地方的 8080 端口的入站流量，其中 Jenkins 网络仪表板提供服务
- en: ❸ Allows outbound traffic on all ports from anywhere
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 允许来自任何地方的任何端口出站流量
- en: Paste the following code to the outputs.tf file to display the IP address of
    the Jenkins master Droplet when the deployment is complete.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 将以下代码粘贴到 outputs.tf 文件中，以显示部署完成后 Jenkins 主机 Droplet 的 IP 地址。
- en: Listing 6.40 Jenkins master public IP address
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.40 Jenkins 主机公共 IP 地址
- en: '[PRE49]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Define the Terraform variables listed in table 6.3 in a new variable.tf file.
    Set their values in variables.tfvars to keep secrets and sensitive information
    out of template files.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在新的 variable.tf 文件中定义表 6.3 中列出的 Terraform 变量。在 variables.tfvars 中设置它们的值，以将秘密和敏感信息从模板文件中排除。
- en: Table 6.3 DigitalOcean Terraform variables
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6.3 DigitalOcean Terraform 变量
- en: '| Name | Type | Value | Description |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| 名称 | 类型 | 值 | 描述 |'
- en: '| `token` | String | None | This is the DigitalOcean API token. Alternatively,
    this can also be specified using `DIGITALOCEAN_TOKEN` environment variables. |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| `token` | 字符串 | 无 | 这是 DigitalOcean API 令牌。或者，也可以使用 `DIGITALOCEAN_TOKEN`
    环境变量指定。 |'
- en: '| `region` | String | None | The DigitalOcean region in which deploy the Jenkins
    master. |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| `region` | 字符串 | 无 | 部署 Jenkins 主机的 DigitalOcean 区域。 |'
- en: '| `jenkins_master_image` | String | None | The name of the Jenkins master image
    that was built previously with Packer. |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| `jenkins_master_image` | 字符串 | 无 | 使用 Packer 前期构建的 Jenkins 主机镜像的名称。 |'
- en: '| `ssh_fingerprint` | String | None | SSH ID or fingerprint. To retrieve the
    info, head to the DigitalOcean Security dashboard. |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| `ssh_fingerprint` | 字符串 | 无 | SSH ID 或指纹。要检索信息，请转到 DigitalOcean 安全仪表板。 |'
- en: 'Run the `terraform` `plan` command to see the effect of the deployment before
    execution:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `terraform plan` 命令以在执行前查看部署的影响：
- en: '![](Images/CH06_F37_UN11_Labouardy.png)'
  id: totrans-427
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F37_UN11_Labouardy.png)'
- en: You can now move on to validating and deploying it on a Droplet with a `terraform
    apply` command. The deployment process should take a few seconds to finish. Then
    a new Jenkins master Droplet will be available in the Droplets console, and Terra-
    form should display the IP address of the Jenkins master Droplet, as you can see
    in figure 6.38.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以使用 `terraform apply` 命令验证并部署到 Droplet 上。部署过程应该只需几秒钟即可完成。然后，新的 Jenkins
    主机 Droplet 将在 Droplets 控制台中可用，Terraform 应该显示 Jenkins 主机 Droplet 的 IP 地址，如图 6.38
    所示。
- en: '![](Images/CH06_F38_Labouardy.png)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F38_Labouardy.png)'
- en: Figure 6.38 Jenkins master Droplet
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.38 Jenkins 主机 Droplet
- en: Open your favorite browser and connect to the public IPv4 that was returned
    by the previous command. A preconfigured Jenkins dashboard should be displayed;
    see figure 6.39.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 打开您喜欢的浏览器，并连接到前一个命令返回的公共 IPv4。应该显示预配置的 Jenkins 仪表板；见图 6.39。
- en: '![](Images/CH06_F39_Labouardy.png)'
  id: totrans-432
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F39_Labouardy.png)'
- en: Figure 6.39 Jenkins dashboard access with Droplet public IP
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.39 使用 Droplet 公共 IP 访问 Jenkins 仪表板
- en: 6.3.3 Building Jenkins worker Droplets
  id: totrans-434
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.3 构建 Jenkins 工作节点 Droplets
- en: Now to delegate build jobs to workers and offload the Jenkins master Droplet.
    Several build workers will be deployed to absorb the build activity.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将构建作业委托给工作节点，并卸载 Jenkins 主机 Droplet。将部署几个构建工作节点以吸收构建活动。
- en: Create a jenkins_workers.tf file where you define Jenkins worker Droplets. The
    workers will be launched from the Jenkins worker image.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 jenkins_workers.tf 文件，在其中定义 Jenkins 工作节点 Droplets。工作节点将从 Jenkins 工作节点镜像启动。
- en: Listing 6.41 Jenkins worker Droplets
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.41 Jenkins 工作节点 Droplets
- en: '[PRE50]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: ❶ The script is used to make the Droplet autojoin the cluster as a Jenkins agent/worker.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 该脚本用于使 Droplet 自动加入集群作为 Jenkins 代理/工作节点。
- en: ❷ Indicates the number of Jenkins workers to create
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 指示要创建的 Jenkins 工作节点数量
- en: ❸ In this Droplet configuration, we’re using 1 GB of RAM and 1vCPU as configuration
    for Jenkins workers.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在此 Droplet 配置中，我们使用 1 GB 的 RAM 和 1vCPU 作为 Jenkins 工作节点的配置。
- en: ❹ The launch script is passed in the user_data section so it can be executed
    the first time the Droplet is running.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 启动脚本通过 user_data 部分传递，以便在 Droplet 首次运行时执行。
- en: 'The `count` variable is used to define the number of workers to deploy. Each
    Droplet will execute a shell script at startup. This script is similar to the
    one provided in previous sections, except for the use of the DigitalOcean metadata
    server to fetch the Droplet IP address and hostname:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '`count` 变量用于定义要部署的工作节点数量。每个 Droplet 启动时将执行一个 shell 脚本。此脚本类似于前面章节中提供的脚本，但使用
    DigitalOcean 元数据服务器来获取 Droplet IP 地址和主机名：'
- en: '[PRE51]'
  id: totrans-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Finally, to set up a bidirectional connection between Jenkins master and workers,
    we define a firewall allowing inbound traffic on TCP port 22.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了在 Jenkins 主机和节点之间设置双向连接，我们定义了一个防火墙，允许 TCP 端口 22 的入站流量。
- en: Listing 6.42 Jenkins worker firewall
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 6.42 Jenkins 工作节点防火墙
- en: '[PRE52]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: ❶ Allows the Jenkins master to SSH to the Jenkins workers
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 允许 Jenkins 主机通过 SSH 连接到 Jenkins 工作节点
- en: After a few minutes, the workers’ Droplets will finish provisioning, and you’ll
    see output similar to figure 6.40.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，工作节点的 Droplets 将完成配置，您将看到类似于图 6.40 的输出。
- en: '![](Images/CH06_F40_Labouardy.png)'
  id: totrans-450
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F40_Labouardy.png)'
- en: Figure 6.40 Jenkins worker Droplets
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.40 Jenkins 工作节点 Droplets
- en: Go back to the Jenkins dashboard. The new deployed workers should join the cluster
    after executing the user data script covered in chapter 5’s listing 5.7; see figure
    6.41.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 返回 Jenkins 仪表板。新部署的工作节点应在执行第 5 章列表 5.7 中的用户数据脚本后加入集群；见图 6.41。
- en: '![](Images/CH06_F41_Labouardy.png)'
  id: totrans-453
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F41_Labouardy.png)'
- en: Figure 6.41 Worker Droplets joining the cluster
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.41 工作节点 Droplets 加入集群
- en: You can take this architecture further by deploying a load balancer in front
    of the Jenkins master Droplet to forward traffic to port 8080 and creating a DNS
    record pointing to the load balancer FQDN; see figure 6.42.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过在 Jenkins 主 Droplet 前部署负载均衡器，将流量转发到端口 8080，并创建一个指向负载均衡器 FQDN 的 DNS 记录来进一步扩展此架构；见图
    6.42。
- en: '![](Images/CH06_F42_Labouardy.png)'
  id: totrans-456
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH06_F42_Labouardy.png)'
- en: Figure 6.42 Jenkins cluster architecture on DigitalOcean
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.42 DigitalOcean 上的 Jenkins 集群架构
- en: 'When you’re finished, clean up the infrastructure by running the following:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，通过运行以下命令清理基础设施：
- en: '[PRE53]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: This chapter has covered how to deploy and operate a resilient and self-healing
    Jenkins cluster from scratch on numerous cloud providers with IaC tools. I’ve
    also explained how to architect Jenkins workers for scale with autoscaling policies
    and metrics alarms. In the next chapter, we will implement pipelines as code on
    Jenkins for numerous cloud-native applications such as Dockerized microservices
    and serverless applications.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了如何使用 IaC 工具从零开始部署和操作具有弹性和自我修复能力的 Jenkins 集群，并在多个云服务提供商上实现。我还解释了如何通过自动缩放策略和指标警报来设计可扩展的
    Jenkins 工作节点。在下一章中，我们将实现 Jenkins 上的代码管道，用于多种云原生应用程序，如 Docker 化的微服务和无服务器应用程序。
- en: Summary
  id: totrans-461
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The power of Packer comes from leveraging template files to create identical
    Jenkins machine images independently of the target platform.
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Packer 的强大之处在于利用模板文件来创建与目标平台无关的相同 Jenkins 机器镜像。
- en: Deploying Jenkins on Google Cloud Platform comes with seamless native support
    for Kubernetes.
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Google Cloud Platform 上部署 Jenkins 带来了对 Kubernetes 的无缝原生支持。
- en: Azure offers a variety of cloud-based services and might be a good alternative
    for running Jenkins on the cloud.
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure 提供了各种基于云的服务，可能是在云上运行 Jenkins 的良好替代方案。
- en: Running Jenkins on DigitalOcean can be a cost-efficient solution for beginner
    businesses and startups.
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 DigitalOcean 上运行 Jenkins 可以是初涉商业和初创企业的成本效益解决方案。
