- en: Chapter 5\. dbt Advanced Topics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 dbt 高级主题
- en: dbt is a tool that focuses on the transformation part of the ELT process. With
    only SQL experience, we can develop all our analytical code with this tool. At
    the same time, in parallel, we can still encapsulate it under a set of best practices
    and standards typically found in software engineering, such as test development,
    automatic deployment, or even documentation built side by side while we develop.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: dbt 是 ELT 过程中专注于转换部分的工具。只需具备 SQL 经验，我们便能利用这一工具开发所有的分析代码。与此同时，我们还可以将其封装在一套通常在软件工程中找到的最佳实践和标准下，例如测试开发、自动部署，甚至是在开发过程中并行构建文档。
- en: In this chapter, our journey through dbt takes a more advanced and subtle turn.
    We will dig into the diverse collection of model materializations in dbt. Beyond
    the traditional views and tables, we’ll explore the potential of ephemeral models,
    leverage materialized views, capture data snapshots at precise moments, and even
    use incremental models, which free you from recurrent, resource-intensive full
    data loads.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们的 dbt 之旅将更加深入和微妙。我们将探索 dbt 中各种类型的模型物化。除了传统的视图和表之外，我们还将探索瞬时模型的潜力，利用物化视图，精确捕获数据快照，甚至使用增量模型，这些都可以使您摆脱重复的、资源密集型的完整数据加载。
- en: But that’s not all. We’ll elevate your analytics code to the next level with
    Jinja, macros, and packages. We’re on a mission to transform your codebase, making
    it more efficient and DRY-er. By the end of this chapter, you’ll be supplied with
    the knowledge and tools to level up your analytics workflow, enabling you to deliver
    insights faster and with even greater precision.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 但这还不是全部。我们将通过 Jinja、宏和包将您的分析代码提升到新的高度。我们的使命是转变您的代码库，使其更高效、更 DRY。在本章结束时，您将掌握提升分析工作流的知识和工具，从而更快、更精准地提供洞察力。
- en: Model Materializations
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型物化
- en: '*Materializations* are strategies for persisting dbt models in a data platform.
    In dbt, materializations can be used to improve the performance and scalability
    of a data model by reducing the need to compute queries and views on the fly.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*物化* 是在数据平台上持久化 dbt 模型的策略。在 dbt 中，物化可以通过减少即时计算查询和视图的需求，来提升数据模型的性能和可扩展性。'
- en: In dbt, various types of materializations can be used, depending on the needs
    and requirements of the project. For example, you might use incremental materializations
    to store the results of queries that need to be updated only incrementally. Additionally,
    you might use snapshots, which are similar to materializations in dbt, but with
    distinct characteristics. Snapshots are used to store the results of a query or
    view at a specific point in time, yet snapshots are not models in dbt. They are
    intentionally designed to be non-idempotent, which sets them apart from most other
    aspects of dbt.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在 dbt 中，可以根据项目的需求和要求使用各种类型的物化。例如，您可以使用增量物化来存储仅需要增量更新的查询结果。此外，您还可以使用快照，它们与 dbt
    中的物化类似，但具有独特的特征。快照用于在特定时间点存储查询或视图的结果，但快照不是 dbt 中的模型。它们被特意设计为非幂等，这使它们与 dbt 的大多数其他方面有所区别。
- en: We’ve used materialization strategies already in [Chapter 4](ch04.html#chapter_id_04),
    such as views and tables. However, it is important to be familiar with all types
    of materializations available, from ephemeral models to incremental data loads
    or even materialized views, so you can take advantage of them while optimizing
    your analytics code and provide accurate and prompt responses to your company’s
    data consumers.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在 [第四章](ch04.html#chapter_id_04) 中使用了诸如视图和表之类的物化策略。然而，了解所有可用的物化类型非常重要，从瞬时模型到增量数据加载或甚至物化视图，这样您就可以在优化分析代码的同时充分利用它们，并为公司的数据消费者提供准确及时的响应。
- en: Tables, Views, and Ephemeral Models
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 表、视图和瞬时模型
- en: We’ve been using view or table materializations to implement our models. This
    chapter aims to dig into both types of materializations and introduce the ephemeral
    models. But let’s first look at [Figure 5-1](#lineage_dim_customer), which presents
    the current lineage of `dim_customers` already built earlier. In this use case,
    we will test the various materialization strategies—in particular, by changing
    the materialization type of the *stg_jaffle_shop_customers.sql* model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在使用视图或表的物化来实现我们的模型。本章旨在深入探讨这两种物化类型并介绍临时模型。但让我们首先看一下 [图 5-1](#lineage_dim_customer)，它展示了之前已经构建的
    `dim_customers` 的当前谱系。在这个用例中，我们将通过更改 *stg_jaffle_shop_customers.sql* 模型的物化类型来测试各种物化策略。
- en: '![Customers data lineage](assets/aesd_0501.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![客户数据谱系](assets/aesd_0501.png)'
- en: Figure 5-1\. `dim_customers` data lineage
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-1\. `dim_customers` 数据谱系
- en: Let’s start with the tables’ materialization type. In dbt, tables are structures
    used to store and organize data, and consist of rows and columns; each row represents
    a record or piece of data, while each column represents a specific attribute or
    field of the data. When you choose this type of materialization, internally, you
    are parameterizing dbt to render the referenced model to be physically created
    in your data platform, with data stored on disk; therefore, it will be slow to
    build. Typically, these materializations are used downstream on the marts layer
    and are recommended when we deal with huge amounts of data and multiple queries
    to our models that require fast response times.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从表的物化类型开始。在 dbt 中，表是用于存储和组织数据的结构，由行和列组成；每一行代表一个记录或数据片段，而每一列则代表数据的特定属性或字段。当您选择这种类型的物化时，内部上，您正在参数化
    dbt 以在您的数据平台中物理创建引用模型，并将数据存储在磁盘上；因此，构建速度会比较慢。通常，这些物化在 marts 层下游使用，并且在处理大量数据和需要快速响应的多个查询到我们的模型时推荐使用。
- en: To test the table materialization, let’s change your YAML file *_jaffle_shop_models.yml*,
    setting the materialization to `table` for the `stg_jaffle_shop_customers` model.
    If you run your code, it should be similar to [Figure 5-2](#models_bigquery_materialized_table)
    in BigQuery.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试表的物化，让我们再次修改您的 YAML 文件 *_jaffle_shop_models.yml*，将 `stg_jaffle_shop_customers`
    模型的物化设置为`table`。如果您运行代码，应该与 BigQuery 中的 [图 5-2](#models_bigquery_materialized_table)
    类似。
- en: '![Customers staging as table](assets/aesd_0502.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![作为表物化的客户分期](assets/aesd_0502.png)'
- en: Figure 5-2\. `stg_jaffle_shop_customers` materialized as a table
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-2\. `stg_jaffle_shop_customers` 作为表物化
- en: '*Views* are virtual tables created by selecting and combining data from one
    or more upstream models. A view does not store any data on its own but instead
    retrieves data from the underlying tables when accessed. Typically, we will use
    views in dbt to simplify complex queries and facilitate the overall transformation
    process or to provide security by hiding specific columns or rows of data from
    users. When we set a model as a view, it will be built as a view in your data
    platform. It is the query itself that is stored in the disk, so only in runtime
    is the data captured and the transformations implemented, which can lead to slower
    query response times.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*视图* 是通过选择和组合来自一个或多个上游模型的数据而创建的虚拟表。视图本身不存储任何数据，而是在访问时从底层表中检索数据。通常，我们会在 dbt
    中使用视图来简化复杂查询并促进整体转换过程，或者通过隐藏特定列或行的数据来提供安全性。当我们将一个模型设置为视图时，它将作为视图在您的数据平台中构建。存储在磁盘上的是查询本身，因此只有在运行时才捕获数据并执行转换，这可能导致查询响应时间较慢。'
- en: To test the usage of views, let’s change your YAML file *_jaffle_shop_models.yml*,
    setting the materialization to `view` for the `stg_jaffle_shop_customers` model.
    Again, run your code. It should be similar to [Figure 5-3](#models_bigquery_materialized_view)
    in BigQuery.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试视图的使用情况，请修改您的 YAML 文件 *_jaffle_shop_models.yml*，将 `stg_jaffle_shop_customers`
    模型的物化设置为`view`。然后再次运行代码。这与 BigQuery 中的 [图 5-3](#models_bigquery_materialized_view)
    应该是类似的。
- en: '![Customers staging as view](assets/aesd_0503.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![作为视图物化的客户分期](assets/aesd_0503.png)'
- en: Figure 5-3\. `stg_jaffle_shop_customers` materialized as a view
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-3\. `stg_jaffle_shop_customers` 作为视图物化
- en: Finally, we have the *ephemeral* models. dbt builds these temporary data models
    on the fly, not persisting them in a database. It’s best to use ephemeral models
    for lightweight data manipulation or analysis tasks that do not require the data
    to be permanently stored. When we go with this strategy, it is essential to remember
    that dbt will interpret this as CTEs in downstream models, which could also increase
    the overall building time of those models. Also, it could bring some complexity
    while debugging your code if we overuse ephemeral models because you cannot query
    them directly in your data platform since they will not exist there.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有*临时*模型。dbt 在运行时构建这些临时数据模型，不在数据库中持久化存储它们。最好用临时模型进行轻量级数据操作或分析任务，这些任务不需要数据永久存储。选择这种策略时，要记住
    dbt 将其解释为下游模型中的 CTEs，这可能会增加那些模型的构建时间。此外，如果滥用临时模型，调试代码时可能会带来一些复杂性，因为在数据平台中无法直接查询它们，因为它们在那里不存在。
- en: To test the ephemeral model, and following the previous examples, change your
    YAML file *_jaffle_shop_models.yml*, setting the materialization to `ephemeral`
    for the `stg_jaffle_shop_customers` model. Since, in this case, you will not have
    an actual materialization in your data platform, look at the `dim_product` compiled
    code. [Figure 5-4](#dim_customer_code_compiled_view_ephemeral) shows the difference
    between your code compiled with the `s⁠t⁠g⁠_​j⁠a⁠f⁠f⁠l⁠e⁠_shop_customers` model
    as a view and as an ephemeral model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试临时模型，并且遵循之前的示例，修改你的 YAML 文件 *_jaffle_shop_models.yml*，将`stg_jaffle_shop_customers`模型的实现设置为`ephemeral`。由于在这种情况下，你的数据平台中不会有实际的实现，看一下
    `dim_product` 的编译代码。[Figure 5-4](#dim_customer_code_compiled_view_ephemeral) 显示了使用视图和临时模型作为
    `stg⁠_⁠j⁠a⁠f⁠f⁠l⁠e⁠_⁠shop_customers` 模型编译的代码之间的区别。
- en: '![snap_order_status_transition data](assets/aesd_0504.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![snap_order_status_transition 数据](assets/aesd_0504.png)'
- en: Figure 5-4\. `dim_customer` code compiled with the `stg_jaffle_shop_customers`
    model using a view (top) and an ephemeral model (bottom)
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-4\. `dim_customer` 代码编译，使用视图作为 `stg_jaffle_shop_customers` 模型的情况（顶部）和使用临时模型的情况（底部）
- en: Incremental Models
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增量模型
- en: In a dbt project, an *incremental model* is designed to process only new or
    changed data rather than all the data in a source. These models can be used to
    improve the efficiency and speed of a data pipeline, especially when working with
    large datasets that are updated frequently.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个 dbt 项目中，*增量模型* 旨在处理源中仅有的新数据或更改的数据，而不是所有的数据。这些模型可以用来提高数据流水线的效率和速度，特别是在处理频繁更新的大型数据集时。
- en: To test incremental models, first you need to configure your model’s YAML file,
    setting the desired model as incremental. We will use an already created model,
    `s⁠t⁠g​_⁠j⁠a⁠f⁠f⁠l⁠e⁠_⁠s⁠h⁠o⁠p_orders`, for our test case. Looking into its YAML
    file *_jaffle_shop_models*, we see it is materialized as `view`, as earlier configured.
    Since we want to make it incremental, the change is straightforward, yet we will
    also embed it with additional capacities, such as the `incremental_type`. So,
    let’s update our model’s YAML file with the code in [Example 5-1](#dbt_project_yml_incremental_model).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试增量模型，首先需要配置模型的 YAML 文件，将所需的模型设置为增量。我们将使用已创建的模型，`s⁠t⁠g​_⁠j⁠a⁠f⁠f⁠l⁠e⁠_⁠s⁠h⁠o⁠p_orders`，作为我们的测试案例。查看其
    YAML 文件 *_jaffle_shop_models*，我们看到它被实现为`view`，如早期配置的那样。由于我们希望将其改为增量，改动是直接的，但我们还将其嵌入额外的能力，如`incremental_type`。因此，让我们使用
    [Example 5-1](#dbt_project_yml_incremental_model) 的代码更新我们模型的 YAML 文件。
- en: Example 5-1\. Incremental model, YAML file configuration
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 5-1\. 增量模型，YAML 文件配置
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'First, we changed the model materialization type to `incremental`. This is
    the core of the incremental models and a mandatory configuration to make an incremental
    model work. In parallel, we’ve included two additional configurations: `incremental_strategy:
    merge` and `unique_key: order_id`. These configurations help you optimize and
    enhance your incremental loads. The incremental strategy is defined as `merge`
    (yet in dbt, you have more options, such as `append` or `insert_overwrite`), where
    each incremental run merges new rows with existing rows based on the identified
    unique key. In this case, if there’s a match for `order_id`, the existing rows
    will be updated with the new information. Otherwise, if there is no match, new
    rows are created. In a standard incremental load, both scenarios occur in parallel.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，我们将模型物化类型更改为 `incremental`。这是增量模型的核心和必选配置，使增量模型能够工作。与此同时，我们还包括了两个额外的配置项：`incremental_strategy:
    merge` 和 `unique_key: order_id`。这些配置帮助您优化和增强增量加载过程。增量策略被定义为 `merge`（在 dbt 中，您还有更多选项，如
    `append` 或 `insert_overwrite`），每次增量运行将根据识别的唯一键将新行与现有行合并。在这种情况下，如果存在 `order_id`
    的匹配项，则现有行将使用新信息更新。否则，如果没有匹配项，则创建新行。在标准的增量加载中，这两种情况同时发生。'
- en: The final step is to arrange the model code to make it compatible with incremental
    loads. In [Example 5-2](#incremental_models_sample_code), you can see how we implement
    this in our `s⁠t⁠g⁠_​j⁠a⁠f⁠f⁠l⁠e⁠_⁠s⁠h⁠o⁠p⁠_⁠o⁠r⁠d⁠e⁠r⁠s` model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将模型代码排列，以使其与增量加载兼容。在 [示例 5-2](#incremental_models_sample_code) 中，您可以看到我们如何在我们的
    `s⁠t⁠g⁠_​j⁠a⁠f⁠f⁠l⁠e⁠_⁠s⁠h⁠o⁠p⁠_⁠o⁠r⁠d⁠e⁠r⁠s` 模型中实现这一点。
- en: Example 5-2\. Incremental model, sample code
  id: totrans-31
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-2\. 增量模型，示例代码
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: By analyzing the query, we leverage Jinja to make our incremental models. Moving
    directly to the `if` statement, we see the usage of the `is_incremental()` macro.
    This macro will return `true` if the running model is configured with `materiali⁠z⁠e⁠d⁠=​'i⁠n⁠c⁠r⁠e⁠m⁠e⁠ntal'`,
    the dbt model already exists, and the dbt is not running in full-refresh mode.
    With `is_incremental()` returning `true`, inside the `if` code block, we have
    the `where` condition that filters rows based on the timestamp column `_etl_loaded_at`.
    It compares this timestamp to the maximum `_etl_loaded_at` timestamp from the
    current table (`{{ this }}`), which effectively checks whether the row’s load
    timestamp is greater than or equal to the maximum load timestamp in the current
    table.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析查询，我们利用 Jinja 制作我们的增量模型。直接进入 `if` 语句，我们看到了 `is_incremental()` 宏的使用。如果正在运行的模型配置为
    `materiali⁠z⁠e⁠d⁠=​'i⁠n⁠c⁠r⁠e⁠m⁠e⁠n⁠t⁠a⁠l'`，则此宏将返回 `true`，而 dbt 模型已存在且不在完全刷新模式下运行。`is_incremental()`
    返回 `true`，在 `if` 代码块内部，我们有基于时间戳列 `_etl_loaded_at` 进行行过滤的 `where` 条件。它将此时间戳与当前表
    (`{{ this }}`) 的最大 `_etl_loaded_at` 时间戳进行比较，有效地检查行的加载时间戳是否大于或等于当前表中的最大加载时间戳。
- en: Incremental models play an essential role in optimizing data pipelines within
    a dbt project. One of their standout advantages is cost efficiency. By adopting
    incremental models, you can significantly reduce the computational resources required
    to process data. This efficiency not only speeds up your data transformation processes
    but also leads to cost savings, as you don’t need to redo unnecessary work.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 增量模型在优化 dbt 项目中的数据管道中扮演着至关重要的角色。它们的一大优势是成本效率。通过采用增量模型，您可以显著减少处理数据所需的计算资源。这种效率不仅加快了数据转换过程，还节省了成本，因为您无需重做不必要的工作。
- en: Moreover, incremental models ensure that your dbt project always operates with
    the most up-to-date data. This type of synchronization with data sources enhances
    the reliability and accuracy of your analytics. Whether you’re dealing with streaming
    data or periodic updates, incremental models keep your analytical insights in
    sync with the evolving data landscape.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，增量模型确保您的 dbt 项目始终使用最新的数据运行。这种与数据源的同步方式增强了分析的可靠性和准确性。无论您处理的是流数据还是周期性更新，增量模型都可以使您的分析洞察与数据变化同步。
- en: Materialized Views
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 物化视图
- en: '*Materialized views*, at their core, are specialized database objects designed
    to store the results of a query as a physically materialized table. Their dynamic
    nature sets them apart from regular tables; the data within a materialized view
    is periodically refreshed to reflect the latest changes in the underlying dataset.
    This refreshing process ensures that materialized views remain up-to-date without
    the need for reprocessing, which makes them ideal when low-latency data access
    is critical.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*物化视图* 本质上是专门设计用来将查询结果作为物理化表存储的数据库对象。它们的动态性质使其与普通表格有所区别；物化视图中的数据定期刷新，以反映底层数据集中的最新变化。这种刷新过程确保物化视图保持最新状态，无需重新处理，这使其在对低延迟数据访问至关重要时成为理想选择。'
- en: Interestingly, materialized views share some common ground with dbt’s incremental
    models, and this resemblance is no coincidence. In many ways, materialized views
    can be considered as successors to incremental models, offering an alternative
    approach to data optimization. Depending on your project’s requirements and your
    chosen data platform, you might even consider replacing all your incremental dbt
    models with materialized view models. This shift simplifies your workflow, eliminating
    the need for manual incremental strategies that detail how dbt should update the
    base table—the data platform handles these tasks seamlessly.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，物化视图与dbt的增量模型分享了一些共同点，这种相似性并非巧合。在许多方面，物化视图可以被视为增量模型的继任者，提供了数据优化的另一种方法。根据项目的要求和所选的数据平台，您甚至可以考虑用物化视图模型替换所有增量dbt模型。这种转变简化了您的工作流程，消除了手动增量策略的需要，详细说明dbt应如何更新基表——数据平台无缝处理这些任务。
- en: However, it’s essential to acknowledge the trade-offs that come with this transition.
    While materialized views offer efficiency, they might result in less fine-grained
    control over your incremental logic and orchestration. By entrusting the data
    platform with defining the logic and execution of updates, you gain convenience
    but may lose some of the specific control that incremental models can provide.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，认识到这一过渡带来的权衡是至关重要的。虽然物化视图提供了效率，但可能会导致对增量逻辑和编排的精细控制减少。通过委托数据平台定义更新逻辑和执行，您获得了便利性，但可能会失去增量模型可以提供的某些具体控制。
- en: The way you test a dbt materialized view may vary depending on your data platform.
    The following method applies if you are using Postgres, Redshift, Databricks,
    or BigQuery (in dbt 1.7) and assumes you want to keep testing the `stg_jaffle_shop_customers`
    model. In the *_jaffle_shop_models.yml* file, change the materialization to `materialized_view`,
    as shown in [Example 5-3](#dbt_project_yml_materialized_view).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 测试dbt物化视图的方法可能因您所用的数据平台而异。如果您使用的是Postgres、Redshift、Databricks或BigQuery（在dbt
    1.7中），并且假设您想保持对 `stg_jaffle_shop_customers` 模型的测试。在 *_jaffle_shop_models.yml*
    文件中，将物化设置为 `materialized_view`，如[示例 5-3](#dbt_project_yml_materialized_view)所示。
- en: Example 5-3\. Materialized view, YAML file configuration
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-3\. 物化视图，YAML文件配置
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'However, if you are using Snowflake instead, the concept varies slightly. Instead
    of materialized views, Snowflake has a distinct concept: *dynamic tables*. The
    basic configuration to use a dynamic table is presented in [Example 5-4](#dbt_project_yml_dynamic_table).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果您使用的是Snowflake，概念稍有不同。Snowflake没有物化视图的概念，而是有一个独特的概念：*动态表*。使用动态表的基本配置如[示例 5-4](#dbt_project_yml_dynamic_table)所示。
- en: Example 5-4\. Dynamic table, YAML file configuration
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-4\. 动态表，YAML文件配置
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In summary, materialized views are an integral part of data optimization, offering
    the benefits of performance improvement and data currency. Their role intersects
    with that of incremental models in dbt, presenting a choice for data engineers
    who want to simplify their workflows while considering the trade-offs in control
    and customization.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，物化视图是数据优化的一个重要组成部分，提供了性能改进和数据实时性的好处。它们的作用与dbt中的增量模型相交，为希望简化工作流程的数据工程师提供了选择，同时考虑控制和定制化的权衡。
- en: Snapshots
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快照
- en: A *snapshot* is a copy of a dataset saved at a specific point in time. Typically,
    we use these snapshots when our analysis needs to look at the previous data states
    in continually updated tables. For example, you can use a snapshot to track the
    history of a dataset, allowing you to see how it has evolved over time. In addition,
    snapshots can be helpful for testing and debugging, as they enable you to compare
    the current state of a dataset to a previous state to identify any changes or
    discrepancies.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 快照是在特定时间点保存的数据集的副本。通常，当我们的分析需要查看不断更新的表中的先前数据状态时，我们使用这些快照。例如，您可以使用快照跟踪数据集的历史，从而了解其随时间如何演变。此外，快照对于测试和调试也很有帮助，因为它们使您可以将数据集的当前状态与先前状态进行比较，以识别任何变化或差异。
- en: dbt snapshots are implemented by applying type 2 slowly changing dimensions
    (SCDs) over mutable source tables. These SCDs identify how a row in a table changes
    over time. Let’s take a look at an example. Using the `jaffle_shop` database,
    imagine that you want to keep a record of the status transition of your orders
    so that you can monitor and inspect the lead times and identify potential bottlenecks
    in a particular status. By looking at the `stg_jaffle_shop_orders` model, we can
    see in [Figure 5-5](#stg_jaffle_shop_orders_dataset) that we already have the
    order status, but we need visibility of all statuses that the order moved through
    until it reached the current status.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: dbt 快照通过在可变源表上应用类型 2 的慢速变化维度（SCDs）来实现。这些 SCD 标识表中行随时间变化的方式。让我们来看一个例子。使用 `jaffle_shop`
    数据库，假设您想要记录订单状态的转换，以便监控和检查交货时间，并识别特定状态下的潜在瓶颈。通过查看 `stg_jaffle_shop_orders` 模型，我们可以看到在
    [Figure 5-5](#stg_jaffle_shop_orders_dataset) 中，我们已经有了订单状态，但我们需要查看订单在达到当前状态之前经历的所有状态的可见性。
- en: '![stg_jaffle_shop_orders data](assets/aesd_0505.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![stg_jaffle_shop_orders 数据](assets/aesd_0505.png)'
- en: Figure 5-5\. `stg_jaffle_shop_orders` transactional dataset
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-5\. `stg_jaffle_shop_orders` 事务数据集
- en: To allow us to track the status transition, we first need to retain the snapshots,
    which in dbt are `select` statements defined within a snapshot block inside a
    *.sql*, in our snapshot folder. So to start, let’s create, in the *snapshots*
    directory, a file named *snap_order_status_transition.sql*, and copy the code
    from [Example 5-5](#snap_order_status_transition).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了允许我们跟踪状态转换，我们首先需要保留快照，在 dbt 中，这些是在快照文件夹中的 *.sql* 文件中快照块内定义的 `select` 语句。因此，首先让我们在
    *snapshots* 目录中创建一个名为 *snap_order_status_transition.sql* 的文件，并从 [Example 5-5](#snap_order_status_transition)
    中复制代码。
- en: Example 5-5\. snap_order_status_transition.sql snapshot creation
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-5\. snap_order_status_transition.sql 快照创建
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Before executing the code, let’s outline what those configurations mean:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行代码之前，让我们先概述这些配置的含义：
- en: '`target_schema`'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`target_schema`'
- en: This is the schema that dbt should render the snapshot table into. In other
    words, dbt allows you to store your snapshots in a different schema in your data
    platform, separate from the actual production environment. It gives you the flexibility
    to take them out and back them up in another place. You can also leverage this
    field with the complement of `target_database` to store those snapshots not only
    in a different schema but also in a different database.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 dbt 应该将快照表渲染到的模式。换句话说，dbt 允许您将快照存储在数据平台中与实际生产环境分开的不同模式中。这使您可以灵活地将它们取出并备份到另一个位置。您还可以利用这个字段与
    `target_database` 的补充一起使用，将这些快照不仅存储在不同的模式中，还存储在不同的数据库中。
- en: '`unique_key`'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`unique_key`'
- en: Typically, this is the record’s primary-key column or expression. It must point
    to a key that is unique.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 典型情况下，这是记录的主键列或表达式。它必须指向一个唯一的键。
- en: '`strategy`'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`strategy`'
- en: This indicates the snapshot strategy to use, either `timestamp` or `check`.
    In the preceding example, we’ve used the `timestamp` strategy. It is the recommended
    strategy since it is scalable for new column addition. Sometimes the timestamp
    is unreliable, and in that case, we can use the `check` strategy to compare the
    current and historical values of a list of columns.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这指示使用的快照策略，可以是 `timestamp` 或 `check`。在前面的示例中，我们使用了 `timestamp` 策略。这是推荐的策略，因为它对于新列的添加是可扩展的。有时候时间戳不可靠，在这种情况下，我们可以使用
    `check` 策略来比较一组列的当前值和历史值。
- en: '`updated_at`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`updated_at`'
- en: When using the `timestamp` strategy, we need to declare which column we need
    to look at in the dataset.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 `timestamp` 策略时，我们需要声明数据集中需要查看的列。
- en: '`check_cols`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`check_cols`'
- en: Used only with the `check` strategy, this is the columns that dbt will need
    to check to generate the snapshot.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 仅在使用 `check` 策略时使用，这是 dbt 将需要检查以生成快照的列。
- en: Now that we understand what those configurations represent, let’s execute the
    snapshot and see its output. For that, in the CLI, run **`dbt snapshot`**. After
    it finishes successfully, take a look at BigQuery. A new schema was created, named
    `snapshots`, with the actual snapshot materialized, as shown in [Figure 5-6](#snap_order_status_transition_bq).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了这些配置代表什么，让我们执行快照并查看其输出。为此，在 CLI 中运行 **`dbt snapshot`**。成功完成后，查看 BigQuery。已创建一个名为
    `snapshots` 的新模式，并实现了实际的快照材料化，如 [图 5-6](#snap_order_status_transition_bq) 所示。
- en: '![snap_order_status_transition data](assets/aesd_0506.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![snap_order_status_transition 数据](assets/aesd_0506.png)'
- en: Figure 5-6\. `snap_order_status_transition` snapshot table inside BigQuery
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-6\. BigQuery 内的 `snap_order_status_transition` 快照表
- en: 'As you can see, dbt created the snapshot `orders_status_snapshot` inside your
    data platform, producing four additional columns:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，dbt 在您的数据平台内创建了名为 `orders_status_snapshot` 的快照，生成了四个额外的列：
- en: '`dbt_scd_id`'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt_scd_id`'
- en: Used internally by dbt, a unique key is generated for each record snapshotted.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: dbt 的内部使用，为每个记录快照生成一个唯一键。
- en: '`dbt_updated_at`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt_updated_at`'
- en: Also used internally by dbt, this field was the `updated_at` timestamp of the
    source record when this snapshot row was inserted.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 也在 dbt 的内部使用，这个字段是在插入这个快照行时源记录的`updated_at`时间戳。
- en: '`dbt_valid_from`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt_valid_from`'
- en: The timestamp when this snapshot row was first inserted. It can be used to order
    the different “versions” of a record.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个快照行首次插入的时间戳。可用于对记录的不同“版本”进行排序。
- en: '`dbt_valid_to`'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '`dbt_valid_to`'
- en: The timestamp when this row became invalidated. It will show `null` if the record
    is still the most recent/valid record.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 当此行变为无效时的时间戳。如果记录仍然是最新/有效的记录，则会显示 `null`。
- en: Note
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Suppose you want to keep exploring the concept of a snapshot. In that case,
    dbt provides comprehensive documentation that covers what we’ve mentioned here
    and additional content, such as best practices and how to handle hard deletes
    from source systems. Just search [Snapshots](https://oreil.ly/541Xm) in the [dbt
    Developer Hub](https://docs.getdbt.com).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您希望继续探索快照的概念。在这种情况下，dbt 提供了详尽的文档，涵盖了我们在这里提到的内容以及额外的内容，如最佳实践和如何处理源系统中的硬删除。只需在
    [dbt Developer Hub](https://docs.getdbt.com) 中搜索 [快照](https://oreil.ly/541Xm)。
- en: Dynamic SQL with Jinja
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Jinja 的动态 SQL
- en: Jinja is a templating language for Python widely used in web development. It
    allows you to create dynamic HTML pages by using variables and expressions and
    easily customize your website’s appearance and behavior. You can also leverage
    it to level up your SQL code with dbt.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Jinja 是一个广泛用于 Python 的模板语言，在 Web 开发中被广泛使用。它允许您通过使用变量和表达式创建动态的 HTML 页面，并轻松定制您网站的外观和行为。您还可以利用它来优化您的
    SQL 代码，与 dbt 一起提升数据操作技能。
- en: One of the key features of Jinja is its ability to insert variables and expressions
    into templates, allowing you to create customized templates for different users
    or contexts without hardcoding the values into the template itself. For example,
    you might want to define some behaviors based on your working environment, like
    limiting the amount of data while working in the development environment. For
    this case, we use the `target name` property in dbt, and then in our SQL code,
    and by leveraging Jinja, we can define the rule to handle it, as shown in [Example 5-6](#jinja_sample_with_targe_name_property).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Jinja 的一个关键特性是能够将变量和表达式插入模板中，允许您为不同的用户或上下文创建定制模板，而无需将值硬编码到模板中。例如，您可能希望根据工作环境定义一些行为，比如在开发环境中限制数据量。对于这种情况，我们使用
    dbt 中的 `target name` 属性，然后在我们的 SQL 代码中，通过利用 Jinja，我们可以定义处理它的规则，如 [示例 5-6](#jinja_sample_with_targe_name_property)
    所示。
- en: Example 5-6\. Jinja sample with the `target name` property
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-6\. 带有 `target name` 属性的 Jinja 示例
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Note that we are using BigQuery and BigQuery syntax. Some functions and syntax
    may differ if you use a different data platform. Now, looking at the preceding
    code, we can see some Jinja notation already being used:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们正在使用 BigQuery 和 BigQuery 语法。如果您使用不同的数据平台，某些函数和语法可能会有所不同。现在，看看前面的代码，我们可以看到已经使用了一些
    Jinja 标记：
- en: '`{% … %}`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`{% … %}`'
- en: Used for statements, these perform any function programming, such as setting
    a variable or starting a `for` loop. In this particular example, we are using
    an `if` statement that checks if the property name is different (`!=`) from the
    `prod` field.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 用于语句，执行任何功能编程，如设置变量或开始`for`循环。在这个特定的例子中，我们使用了一个`if`语句，检查属性名是否与`prod`字段不同(`!=`)。
- en: Jinja also provides a range of control structures, such as loops and conditional
    statements, that allow you to create more complex templates that can adapt to
    different data and contexts. You might use a loop to iterate over a list of items
    and dynamically generate your SQL code instead of manually doing it, field by
    field.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Jinja还提供了一系列控制结构，如循环和条件语句，允许您创建更复杂的模板，以适应不同的数据和上下文。您可以使用循环来迭代项目列表，并动态生成SQL代码，而不是手动逐字段执行。
- en: An ideal example can be demonstrated using the *i⁠n⁠t⁠_⁠p⁠a⁠y⁠m⁠e⁠n⁠t⁠_⁠t⁠y⁠p⁠e⁠_​a⁠m⁠o⁠u⁠n⁠t⁠_per_order.sql*
    model you created earlier in [Example 4-16](ch04.html#int_payment_type_amount_per_order).
    Instead of manually writing the amount metrics per type, you could generate them
    automatically and make them scalable, handling the current and future payment
    types. Look at [Example 5-7](#int_payment_type_amount_per_order_dynamic_jinja)
    and see how we can leverage Jinja to do that.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用您之前在[示例 4-16](ch04.html#int_payment_type_amount_per_order)中创建的*i⁠n⁠t⁠_⁠p⁠a⁠y⁠m⁠e⁠n⁠t⁠_⁠t⁠y⁠p⁠e⁠_​a⁠m⁠o⁠u⁠n⁠t⁠_per_order.sql*模型来演示一个理想的例子。与手动编写每种类型的金额度量相比，您可以自动生成它们，并使其可扩展，处理当前和未来的支付类型。看看[示例 5-7](#int_payment_type_amount_per_order_dynamic_jinja)，看看我们如何利用Jinja来做到这一点。
- en: Example 5-7\. `*int_payment_type_amount_per_order model*` with dynamic Jinja
  id: totrans-90
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-7\. 使用动态Jinja的*i⁠n⁠t⁠_⁠p⁠a⁠y⁠m⁠e⁠n⁠t⁠_⁠t⁠y⁠p⁠e⁠_​a⁠m⁠o⁠u⁠n⁠t⁠_per_order模型
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The preceding code is a more complex usage of Jinja, with loops and declaration
    of variables, yet once compiled, it will look quite similar to the result of the
    code in [Example 5-6](#jinja_sample_with_targe_name_property). Now, if we want
    to consider a new payment type, instead of manually creating a new metric, we
    need to add it to the `payment_types` list, declared at the top of the code.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码是Jinja的更复杂用法，包括循环和变量声明，但一旦编译完成，它看起来与[示例 5-6](#jinja_sample_with_targe_name_property)中的代码结果非常相似。现在，如果我们想考虑一个新的支付类型，而不是手动创建一个新的度量标准，我们需要将其添加到代码顶部声明的`payment_types`列表中。
- en: 'Let’s discuss the Jinja nuances that we can find in [Example 5-7](#int_payment_type_amount_per_order_dynamic_jinja):'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论我们可以在[示例 5-7](#int_payment_type_amount_per_order_dynamic_jinja)中找到的Jinja细微差别：
- en: '`{% … %}`'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`{% … %}`'
- en: 'As a recap, this is used for statements. In this case, we’ve used it in two
    distinct places, different from [Example 5-6](#jinja_sample_with_targe_name_property):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，这用于语句。在这种情况下，我们在两个不同的地方使用了它，不同于[示例 5-6](#jinja_sample_with_targe_name_property)：
- en: '`set payment_types= [''cash'',''credit'']`'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`set payment_types= [''cash'',''credit'']`'
- en: This declares the `payment_types` variable, to be used later in the code. In
    this case, it’s a list with two elements, cash and credit.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这声明了后面代码中将要使用的`payment_types`变量。在这种情况下，它是一个包含两个元素（现金和信用卡）的列表。
- en: '`for payment_type in payment_types`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`for payment_type in payment_types`'
- en: Here, we iterate the different `payment_types` declared at the top. Row by row,
    we will start building our code dynamically.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们迭代在代码顶部声明的不同`payment_types`。逐行，我们将开始动态构建我们的代码。
- en: '`{{ …​ }}`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`{{ …​ }}`'
- en: 'This is used for expressions to print to the template output. In our example,
    we’ve used it for `{{ payment_type }}`, namely, to concatenate with the `amount`
    string to generate the final metric name per payment type. Also, we’ve used the
    actual metric computation on the expression: `when payment_type = ''{{ payment_type
    }}'' and status = ''success''`.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这用于表达式以打印到模板输出。在我们的示例中，我们使用它为`{{ payment_type }}`，即与`amount`字符串连接以生成每种支付类型的最终度量名称。此外，我们还在表达式上使用了实际的度量计算：`when
    payment_type = '{{ payment_type }}' and status = 'success'`。
- en: '`{# … #}`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`{# … #}`'
- en: Used for comments, this allows you to document your code inline.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 用于注释，这使您可以内联文档化您的代码。
- en: Whitespaces
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 空格
- en: This is another small but important detail in the code. You can control them
    by using a hyphen on either side of the Jinja delimiter `{%- … -%}`, which will
    trim the whitespace between the Jinja delimiter on that side of the expression.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码中另一个小但重要的细节。您可以通过在Jinja分隔符的两侧使用连字符`{%- … -%}`来控制它们，这将修剪该表达式的两侧之间的空白。
- en: Tip
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: We recommend exploring dedicated courses or referring to the official [Jinja
    template design documentation](https://oreil.ly/U2gye) for a comprehensive understanding
    of Jinja. These resources can provide valuable insights and help you deepen your
    knowledge of Jinja’s capabilities.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议探索专门的课程或参考官方[Jinja模板设计文档](https://oreil.ly/U2gye)，以全面了解 Jinja。这些资源可以提供有价值的见解，并帮助你深入了解
    Jinja 的功能。
- en: Using SQL Macros
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SQL 宏
- en: '*Macros* are reusable pieces of code used to automate tasks and processes in
    a dbt project. They increase productivity by allowing you to automate repetitive
    or complex tasks, such as queries, data manipulation, and data visualization.
    After you develop your macros, you can call and trigger them in various ways,
    including manually, automatically, or in response to user input.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*宏*是在 dbt 项目中用于自动化任务和流程的可重用代码片段。它们通过允许你自动化重复或复杂的任务，如查询、数据操作和数据可视化，提高了生产效率。开发完成宏后，你可以通过手动、自动或响应用户输入的方式调用和触发它们。'
- en: In a dbt project, a macro is typically defined in a separate file, inside the
    *macros* directory, and written using Jinja syntax. Separating macros from your
    models allows your macros to be utilized in multiple models and other files within
    the project. It also allows macros to be customized using variables and expressions,
    enabling your macro to adapt based on the arguments sent from the specific model.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在 dbt 项目中，宏通常在单独的文件中定义，放在*macros*目录中，并使用 Jinja 语法编写。将宏与模型分开允许在项目中的多个模型和其他文件中使用它们。它还允许使用变量和表达式定制宏，使宏能够根据来自特定模型的参数进行调整。
- en: To use a macro in a dbt project, you will typically call the macro and pass
    any necessary arguments or options using Jinja syntax. Macros can also interact
    with other dbt features, such as views, and other macros, to create more complex
    and robust solutions. For example, you might use a macro to automate refreshing
    a data model, to filter or transform data in specific ways, or to generate reports
    or charts based on the data.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 dbt 项目中使用宏，通常你会使用 Jinja 语法调用宏并传递任何必要的参数或选项。宏还可以与其他 dbt 功能（如视图）和其他宏交互，以创建更复杂和健壮的解决方案。例如，你可以使用宏自动刷新数据模型、以特定方式过滤或转换数据，或基于数据生成报告或图表。
- en: 'Let’s try to create our first macro. Our initial use case is simple: create
    a macro that sums two numbers. Remember, your macro needs to use Jinja syntax.
    First, create a macro file in your dbt project in the *macros* directory, named
    *macro_sum_two_values.sql*. [Example 5-8](#macro_sum_two_values) shows what your
    code should look like.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试创建我们的第一个宏。我们最初的用例很简单：创建一个可以对两个数字求和的宏。记住，你的宏需要使用 Jinja 语法。首先，在你的 dbt 项目中的*macros*目录中创建一个名为*macro_sum_two_values.sql*的宏文件。[示例 5-8](#macro_sum_two_values)展示了你的代码应该是什么样子的。
- en: Example 5-8\. macro_sum_two_values.sql
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-8\. macro_sum_two_values.sql
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let’s test it now. Then, in a new file inside your dbt project, you can use
    the macro by calling it with the desired values for `x` and `y`, as shown in [Example 5-9](#call_macro_sum_two_values).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来测试它。然后，在你的 dbt 项目中的新文件中，你可以通过调用宏并传入所需的`x`和`y`值来使用宏，如[示例 5-9](#call_macro_sum_two_values)所示。
- en: Example 5-9\. Trigger the macro inside macro_sum_two_values.sql
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-9\. 在 macro_sum_two_values.sql 内触发宏
- en: '[PRE8]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[Example 5-9](#call_macro_sum_two_values) will present the result of the macro
    (102) into the output window at the point where the macro is being triggered.
    You can also pass variables or expressions as arguments to the macro rather than
    hardcoded values. Look at [Example 5-10](#call_macro_sum_two_values_with_vars),
    which must produce the same output as the previous example.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 5-9](#call_macro_sum_two_values)将在触发宏时将宏的结果（102）显示在输出窗口中。你也可以将变量或表达式作为参数传递给宏，而不是硬编码的值。看看[示例 5-10](#call_macro_sum_two_values_with_vars)，它必须产生与前一个示例相同的输出。'
- en: Example 5-10\. Trigger the macro inside macro_sum_two_values.sql, defining the
    variables on top
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-10\. 在 macro_sum_two_values.sql 内触发宏，并在顶部定义变量
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Using macros in a dbt project with Jinja allows you to reuse code and customize
    your models flexibly and powerfully. But now, let’s use macros in an example.
    Using the `jaffle_shop` database, the first use case we want to deal with is a
    macro to centralize the payment types configuration to avoid defining it in every
    model, as we did earlier in the new version of *int_payment_type_amount_per_order.sql*.
    To accomplish that, in the *macros* directory, create a new file named *get_payment_types.sql*
    and copy the [Example 5-11](#get_payment_types) code.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在dbt项目中使用Jinja的宏允许您灵活和强大地重复使用代码并自定义您的模型。但现在，让我们举个例子来使用宏。使用`jaffle_shop`数据库，我们想要处理的第一个用例是一个宏，用于集中支付类型配置，以避免在每个模型中重新定义它，就像我们在*int_payment_type_amount_per_order.sql*的新版本中所做的那样。为此，在*macros*目录中，创建一个名为*get_payment_types.sql*的新文件，并复制[示例 5-11](#get_payment_types)的代码。
- en: Example 5-11\. get_payment_types.sql macro
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-11\. get_payment_types.sql 宏
- en: '[PRE10]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Then, in your *int_payment_type_amount_per_order.sql* model, replace the `payment_types`
    variable being declared at the top with the code from [Example 5-12](#int_payment_type_amount_per_order_var_declar_with_macro).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在您的*int_payment_type_amount_per_order.sql*模型中，用来自[示例 5-12](#int_payment_type_amount_per_order_var_declar_with_macro)的代码替换顶部声明的`payment_types`变量。
- en: Example 5-12\. int_payment_type_amount_per_order.sql `*payment_types*` variable
    declaration calling the `*get_payment_types()*` macro
  id: totrans-125
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-12\. int_payment_type_amount_per_order.sql 中的`*payment_types*`变量声明调用了`*get_payment_types()*`宏。
- en: '[PRE11]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now you can use your macro for other use cases, but consider the following:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以为其他用例使用您的宏，但请考虑以下内容：
- en: Typically, macros take arguments, so although [Example 5-11](#get_payment_types)
    is a macro, it doesn’t represent a typical one that you will build. Arguments
    refer to the values passed to a macro when it is called or executed. These arguments
    can be used to modify the behavior of the macro, such as by specifying input data
    sources, defining custom configuration settings, or setting certain parameters
    or flags.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，宏带有参数，因此尽管[示例 5-11](#get_payment_types)是一个宏，但它并不代表您将构建的典型宏。参数指调用或执行宏时传递的值。这些参数可用于修改宏的行为，例如指定输入数据源、定义自定义配置设置或设置某些参数或标志。
- en: In [Example 5-11](#get_payment_types), we’ve used the `return` function to return
    a list—without this function, the macro would return a string.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[示例 5-11](#get_payment_types)中，我们使用了`return`函数来返回一个列表——没有这个函数，宏将返回一个字符串。
- en: 'Looking at what you did, the macro in [Example 5-11](#get_payment_types) doesn’t
    seems to be very powerful or static. How could we optimize it so we avoid relying
    on manual inputs? We can do the following to overcome these issues:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 查看您的操作，[示例 5-11](#get_payment_types)中的宏似乎并不是非常强大或静态。我们如何优化它以避免依赖手动输入？我们可以采取以下措施来解决这些问题：
- en: Understand the source data where we can dynamically pull the payment types.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解源数据，我们可以动态提取支付类型。
- en: Rethink the macro with a modular mindset.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新思考具有模块化思维方式的宏。
- en: We can use the following query from [Example 5-13](#get_distinct_payment_types)
    to overcome the first point.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用从[示例 5-13](#get_distinct_payment_types)获取的以下查询来解决第一个问题。
- en: Example 5-13\. Get distinct payment types query
  id: totrans-134
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-13\. 获取不同支付类型的查询
- en: '[PRE12]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As you can see, if you run the query, it has distinct payment types, so to make
    a macro from it, copy the code from [Example 5-14](#get_payment_types_v2) into
    your *get_payment_types.sql* file.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，如果运行查询，它具有不同的付款类型，因此为了从中制作宏，请将[示例 5-14](#get_payment_types_v2)中的代码复制到您的*get_payment_types.sql*文件中。
- en: Example 5-14\. New version to make `*get_payment_types*` more dynamic and scalable
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-14\. 使`*get_payment_types*`更具动态性和可扩展性的新版本
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let’s see what we did:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们做了什么：
- en: At the top we declared the query `payment_type_query`.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在顶部，我们声明了查询`payment_type_query`。
- en: Right after that, we executed using the `run_query` function and stored the
    output inside the `results` variable.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就在那之后，我们使用`run_query`函数执行并将输出存储在`results`变量中。
- en: Then, we checked whether Jinja is in the `execute` mode—meaning SQL is being
    executed—and if so, we stored the results of the first column of the dataset in
    `results_list`. This first column is the one that will have the distinct values.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们检查了Jinja是否处于`execute`模式——这意味着正在执行SQL——如果是这样，我们将数据集的第一列结果存储在`results_list`中。这个第一列将具有不同的值。
- en: Finally, we returned the `results_list` variable to be used in our models.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们返回`results_list`变量以在我们的模型中使用。
- en: Now, if we compile the *int_payment_type_amount_per_order.sql* model again,
    nothing should change. However, you have implemented a more scalable code. At
    this time, no manual input is required once a new payment type arises. But we
    can do even more with modularity. Imagine that you want to use a similar pattern
    elsewhere in your dbt project (for example, payment methods). In that case, we
    could do something like [Example 5-15](#get_distinct_by_column).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们再次编译 *int_payment_type_amount_per_order.sql* 模型，不应有任何变化。然而，您已实现了更可扩展的代码。此时，不需要手动输入一旦新的支付类型出现。但是，我们可以通过模块化做得更多。想象一下，您希望在
    dbt 项目的其他地方使用类似的模式（例如支付方法）。在那种情况下，我们可以做一些类似 [Example 5-15](#get_distinct_by_column)
    的事情。
- en: Example 5-15\. Reusing our code multiple times for different scenarios
  id: totrans-145
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 5-15\. 为不同情景重复使用我们的代码
- en: '[PRE14]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: By analyzing this code, we can see three macros. The first, `get_column_values()`,
    receives the `column_name` and `table_name` as arguments and will dynamically
    generate a query to execute it, returning the distinct values of the `column_name`
    provided. Next, we’ve implemented two separate calls to that macro that will retrieve
    the distinct `payment_types` with the `get_payment_types()` macro, and the distinct
    `payment_methods` with the `get_payment_methods()` macro. Note also that the macro
    filename was changed to *get_distinct_by_column.sql* to make it more transparent,
    considering its purpose.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析这段代码，我们可以看到三个宏。第一个 `get_column_values()` 接收 `column_name` 和 `table_name`
    作为参数，并动态生成一个执行查询的查询语句，返回提供的 `column_name` 的不同值。接下来，我们分别调用该宏两次，使用 `get_payment_types()`
    宏检索不同的 `payment_types`，并使用 `get_payment_methods()` 宏检索不同的 `payment_methods`。还请注意，宏文件名已更改为
    *get_distinct_by_column.sql*，以使其更加透明，考虑到其目的。
- en: The preceding example presents an interesting demonstration of how to use macros,
    but they can be useful in many more instances. Another good example is to have
    a macro that dynamically validates that we are in a development or deployment
    environment and then automatically filters our dataset. To do that, in the *macros*
    directory, create a new macro named *limit_dataset_if_not_deploy_env.sql* and
    copy the code from [Example 5-16](#limit_dataset_if_not_deploy_env).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例展示了如何使用宏的有趣演示，但它们在许多其他情况下也很有用。另一个很好的例子是有一个宏，动态验证我们是否处于开发或部署环境中，然后自动过滤我们的数据集。为此，在
    *macros* 目录中，创建一个名为 *limit_dataset_if_not_deploy_env.sql* 的新宏，并复制来自 [Example 5-16](#limit_dataset_if_not_deploy_env)
    的代码。
- en: Example 5-16\. `*limit_dataset_if_not_deploy_env*` macro
  id: totrans-149
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 5-16\. `*limit_dataset_if_not_deploy_env*` 宏
- en: '[PRE15]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Then, in the `fct_orders` model, include the code from [Example 5-17](#limit_dataset_if_not_deploy_env_call_fct_ord)
    at the bottom after the left join.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 `fct_orders` 模型中，在左连接之后的底部包含来自 [Example 5-17](#limit_dataset_if_not_deploy_env_call_fct_ord)
    的代码。
- en: Example 5-17\. Call `*limit_dataset_if_not_deploy_env*` macro from `*fct_orders*`
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 5-17\. 从 `*fct_orders*` 调用 `*limit_dataset_if_not_deploy_env*` 宏
- en: '[PRE16]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now compile the code. If you are in the development environment, your *fct_orders.sql*
    model should show a new filter, `where order_date > DATE⁠_⁠S⁠U⁠B​(⁠C⁠U⁠R⁠R⁠E⁠N⁠T_DATE(),
    INTERVAL 3 MONTH)`. In other words, the filter allows your code to distinguish
    between the environments: if not the deployment environment, work only with the
    last three months of data; otherwise, gather the whole dataset. Looking at only
    *N* months in your development environment will substantially reduce the overhead
    in your data platform, while at the same time, you still have a good subset of
    data to work with while developing and testing your code. If this is not the case,
    you can increase for 12, 24, or even 36 months.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在编译代码。如果您处于开发环境，则您的 *fct_orders.sql* 模型应显示一个新的过滤器，`where order_date > DATE⁠_⁠S⁠U⁠B​(⁠C⁠U⁠R⁠R⁠E⁠N⁠T_DATE(),
    INTERVAL 3 MONTH)`。换句话说，在开发环境中，该过滤器仅允许您处理过去三个月的数据；否则，收集整个数据集。在开发环境中仅查看 *N* 个月的数据将大幅减少数据平台的开销，同时，您仍然可以使用一个良好的数据子集来开发和测试代码。如果不是这种情况，您可以增加为
    12、24 或甚至 36 个月。
- en: Finally, it’s important to mention dbt’s adaptability in the ability to customize
    its core macros. These macros serve some of dbt’s core functionalities, offering
    predefined templates for common tasks. One standout example is the `generate_schema_name`
    macro. This macro is responsible for crafting schema names for your dbt models.
    What’s truly remarkable is that you can arrange it to align seamlessly with your
    project’s unique naming conventions. Imagine effortlessly generating schema names
    that mirror your organization’s data structure.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，重要的是提到 dbt 的适应性，能够定制其核心宏的能力。这些宏提供了一些 dbt 的核心功能，为常见任务提供了预定义模板。一个突出的例子是 `generate_schema_name`
    宏。该宏负责为您的 dbt 模型制定模式名称。真正了不起的是，您可以调整它，使其与项目独特的命名约定无缝对接。想象一下，轻松生成与您组织的数据结构相匹配的模式名称。
- en: Customizing these core macros isn’t just a technical feat. It’s a game-changer
    in how you exert dbt’s capabilities, unlocking the potential to craft a data transformation
    process that aligns precisely with your project’s needs.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 定制这些核心宏不仅仅是技术上的壮举。它是改变游戏规则的方法，使您能够发挥 dbt 的能力，释放出根据项目需求精确制定数据转换流程的潜力。
- en: In conclusion, using macros in a dbt project can be a robust and efficient way
    to automate and customize your data models and processes. Macros allow you to
    easily reuse code and adapt your models to different contexts and requirements.
    Using Jinja syntax, you can create flexible and easy-to-maintain macros that can
    be called and triggered in various ways. Overall, macros can help you increase
    your productivity and create more robust and scalable data models.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，在 dbt 项目中使用宏可以是自动化和定制数据模型和流程的强大高效方式。宏使您可以轻松重用代码，并使您的模型适应不同的上下文和需求。使用 Jinja
    语法，您可以创建灵活且易于维护的宏，可以以各种方式调用和触发。总体而言，宏可以帮助您提高生产力，创建更强大和可扩展的数据模型。
- en: dbt Packages
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: dbt 包
- en: '*Packages* are a way to organize and share code and resources, such as models
    and macros, that have already been written, within a dbt project. They allow you
    to structure your project into logical units and to reuse code and resources across
    multiple models and files.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*包*是组织和共享代码和资源的一种方式，例如已编写的模型和宏，在 dbt 项目中。它们允许您将项目结构化为逻辑单元，并在多个模型和文件中重复使用代码和资源。'
- en: In a dbt project, packages are defined inside the *packages.yml* file, installed
    inside the *dbt_packages* directory, and are structured using a hierarchy of directories
    and files. Each package can contain models, tests, macros, and other resources
    that are related to a specific topic or functionality.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在 dbt 项目中，包定义在 *packages.yml* 文件中，安装在 *dbt_packages* 目录中，并使用目录和文件的层次结构进行组织。每个包可以包含与特定主题或功能相关的模型、测试、宏和其他资源。
- en: 'Packages can be used in many ways in a dbt project. For example, you might
    use packages to do the following:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在 dbt 项目中，包可以用多种方式使用。例如，您可以使用包来执行以下操作：
- en: Organize your project into logical units
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 将项目组织成逻辑单元
- en: Packages can help you structure your project in an intuitive and easy way to
    understand grouping together related models, tests, and other resources.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 包可以帮助您以直观且易于理解的方式结构化项目，将相关模型、测试和其他资源组合在一起。
- en: Reuse code and resources
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 重复使用代码和资源
- en: Packages allow you to reuse code and resources across multiple models and files,
    saving time and reducing maintenance overhead.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 包允许您在多个模型和文件之间重复使用代码和资源，节省时间并减少维护开销。
- en: Encapsulate functionality
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 封装功能
- en: Packages can help you encapsulate specific functionality and hide the implementation
    details from other parts of the project, making your project more modular and
    easier to understand.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 包可以帮助您封装特定功能，并隐藏项目其他部分的实现细节，使您的项目更模块化且易于理解。
- en: Share code and resources with others
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 与他人分享代码和资源
- en: Packages can be shared with other users or projects, which allows you to leverage
    the work of others and be part of the community by contributing your own code.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 包可以与其他用户或项目共享，这使您可以利用他人的工作，并通过贡献自己的代码成为社区的一部分。
- en: 'Overall, packages are a valuable feature of dbt that can help you to organize,
    reuse, and share code and resources in your project. You can install dbt packages
    from three distinct places: a public packages hub, Git, or a local directory.
    In this section, we will cover how to install packages and show some examples
    of their usage. We will use one of the most common packages, `dbt_utils`, but
    note that there are a lot of great packages out there. You can find plenty of
    them at the [dbt Hub](https://hub.getdbt.com) or import them directly from GitHub.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，包是 dbt 的一个有价值的功能，可以帮助你在项目中组织、重用和共享代码和资源。你可以从三个不同的地方安装 dbt 包：公共包集、Git 或本地目录。在本节中，我们将介绍如何安装包，并展示它们的使用示例。我们将使用一个最常见的包
    `dbt_utils`，但请注意，还有许多优秀的包可以使用。你可以在 [dbt Hub](https://hub.getdbt.com) 找到大量的包或直接从
    GitHub 导入它们。
- en: Installing Packages
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装包
- en: Installing a package in a dbt project is a straightforward process that can
    help you leverage the work of others and add new functionalities to your project.
    We already gave an overview earlier, but let’s discuss installing packages further.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 安装一个包在一个 dbt 项目中是一个直接的过程，可以帮助你利用他人的工作并为你的项目添加新功能。我们之前已经概述了，但让我们进一步讨论安装包。
- en: 'The step-by-step guide to installing a package is as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 安装包的逐步指南如下：
- en: Create a *packages.yml* file if you don’t already have it. This file is where
    you will configure the dbt packages that need to be installed in your dbt project.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你还没有创建 *packages.yml* 文件，请创建一个。这个文件是你将要在你的 dbt 项目中配置需要安装的 dbt 包的地方。
- en: 'Add the package to your *packages.yml* file: in your dbt project, open the
    file and add an entry for the package you want to install. Keep in mind that before
    installing a package, it is important to ensure that your dbt project meets any
    requirements or dependencies that the package may have. These may include specific
    versions of dbt or other packages, and system or software requirements.'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将包添加到你的 *packages.yml* 文件中：在你的 dbt 项目中打开文件，并为你想要安装的包添加一个条目。请注意，在安装包之前，确保你的 dbt
    项目符合包可能具有的任何要求或依赖关系是非常重要的。这些可能包括特定版本的 dbt 或其他包，以及系统或软件要求。
- en: Install the package by running the **`dbt deps`** command in your terminal.
    This will install the package and its dependencies in your dbt project.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中运行 **`dbt deps`** 命令来安装包及其依赖项到你的 dbt 项目中。
- en: Test the package to ensure it is working correctly. You can run the **`dbt test`**
    command and verify that the package’s models and tests pass.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试包以确保它正常工作。你可以运行 **`dbt test`** 命令并验证包的模型和测试是否通过。
- en: 'Let’s try installing one of the most common packages available: [`dbt_utils`](https://oreil.ly/W-rZN),
    which you can find at the [dbt Hub](https://hub.getdbt.com). Typically, using
    the public packages hub will give you all the configurations that need to be inside
    your *packages.yml* file for a specific dbt package, resulting in a smoother installation.
    So, to install `dbt_utils`, copy the config from [Example 5-18](#package_yam_dbt_utils)
    into your *packages.yml* file.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试安装一个最常见的可用包：[`dbt_utils`](https://oreil.ly/W-rZN)，你可以在 [dbt Hub](https://hub.getdbt.com)
    找到它。通常，使用公共包集中将为你提供必须放在你的 *packages.yml* 文件中特定 dbt 包的所有配置，从而实现更顺利的安装。因此，要安装 `dbt_utils`，请将配置从
    [示例 5-18](#package_yam_dbt_utils) 复制到你的 *packages.yml* 文件中。
- en: Example 5-18\. `*dbt_utils*` package configuration
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-18\. `*dbt_utils*` 包配置
- en: '[PRE17]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Save your YAML file and run **`dbt deps`** in your CLI. Everything should be
    fine if you get a success message, as shown in [Figure 5-7](#package_installation_log_success).
    Later in the chapter, we will use `dbt_utils` to see if everything is running
    as expected.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 保存你的 YAML 文件，并在你的 CLI 中运行 **`dbt deps`**。如果你收到像 [图 5-7](#package_installation_log_success)
    中显示的成功消息，一切应该没问题。稍后在本章中，我们将使用 `dbt_utils` 来查看一切是否运行如预期。
- en: '![Package installation success](assets/aesd_0507.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![包安装成功](assets/aesd_0507.png)'
- en: Figure 5-7\. Success message on logs, after `*dbt_utils*` installation
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-7\. `*dbt_utils*` 安装后日志中的成功消息
- en: Note
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you receive a package incompatibility issue with your dbt version, ensure
    you’re running a version of dbt that’s compatible with the package you want to
    use. Check the package’s documentation or repository for information on the supported
    dbt versions. You can also update the package version to be compatible with your
    dbt version. Finally, alternative packages that provide similar functionality
    and are compatible with your dbt version can be a solution.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在使用 dbt 版本时遇到包不兼容问题，请确保您正在运行与您想要使用的包兼容的 dbt 版本。查看包的文档或存储库，了解支持的 dbt 版本信息。您也可以更新包版本以与您的
    dbt 版本兼容。最后，您还可以选择其他提供类似功能并与您的 dbt 版本兼容的包作为解决方案。
- en: Exploring the dbt_utils Package
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 `dbt_utils` 包
- en: 'First things first, let’s meet the package that we will use for our examples:
    `dbt_utils`. This package is developed and maintained by dbt Labs, the creators
    of the dbt. It contains a collection of utility functions, macros, and other resources
    that are useful to extend and enhance the functionality of a dbt project.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们介绍一下我们将用于示例的包：`dbt_utils`。这个包由 dbt 的创建者 dbt Labs 开发和维护。它包含一系列实用函数、宏和其他资源，可以扩展和增强
    dbt 项目的功能。
- en: 'Here are some examples of the types of resources included in the `dbt_utils`
    package:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些包含在 `dbt_utils` 包中的资源类型示例：
- en: Helper functions used to perform common tasks, such as generating lists of columns,
    formatting dates and timestamps, and handling null values
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于执行常见任务的辅助函数，如生成列列表、格式化日期和时间戳以及处理空值
- en: Custom data types used to represent data more expressively and flexibly, such
    as arrays, ranges, and intervals
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义数据类型用于更具表现力和灵活性地表示数据，例如数组、范围和间隔
- en: Debugging and testing tools for your dbt projects, such as logging functions
    and test frameworks
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于您的 dbt 项目的调试和测试工具，如日志记录函数和测试框架
- en: Macros and models for performing a wide range of tasks, such as data manipulation,
    visualization, and testing
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于执行各种任务的宏和模型，如数据操作、可视化和测试
- en: In conclusion, `dbt_utils` is a helpful package for dbt users who want to extend
    and customize their projects in various ways. It is constantly being updated and
    expanded to include new features and resources.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，`dbt_utils` 是一个有助于 dbt 用户通过各种方式扩展和定制其项目的有用包。它正在不断更新和扩展，以包含新功能和资源。
- en: Using Packages Inside Macros and Models
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在宏和模型内部使用包
- en: In a dbt project, you can use packages inside macros to access other macros,
    models, tests, and other resources defined in the package. This allows you to
    reuse code and resources across multiple models and files, modularize your project,
    and, therefore, have DRY-er code.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在 dbt 项目中，您可以在宏中使用包来访问其他宏、模型、测试和包中定义的其他资源。这使您可以在多个模型和文件中重用代码和资源，模块化您的项目，并因此编写更干净的代码（DRY）。
- en: Once the package is installed, as we outlined in [“Installing Packages”](#installing_packages_chapter),
    you can access its macros by using the package name as a prefix, following a specific
    syntax, as shown in [Example 5-19](#sample_package_macro).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了包，在我们[“安装包”](#installing_packages_chapter)中概述的步骤后，您可以通过在包名称前加上前缀并按照特定语法使用其宏来访问其宏，如[示例 5-19](#sample_package_macro)所示。
- en: Example 5-19\. Sample macro call
  id: totrans-197
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-19\. 示例宏调用
- en: '[PRE18]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Using `dbt_utils`, we can generate a series of numbers or dates in a database
    that can be useful for various use cases. But let’s take a look at a practical
    example. Let’s experiment with the `date_spine()` macro. Copy the code from [Example 5-20](#dbt_util_data_spine_package_macro)
    and execute it.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `dbt_utils`，我们可以在数据库中生成一系列数字或日期，这对于各种用例非常有用。但让我们看一个实际的例子。让我们尝试一下 `date_spine()`
    宏。复制来自[示例 5-20](#dbt_util_data_spine_package_macro)的代码并执行它。
- en: Example 5-20\. `*date_spine*` macro inside `*dbt_utils*`
  id: totrans-200
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-20\. `*date_spine*` 宏位于 `*dbt_utils*` 内部。
- en: '[PRE19]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The output expected is a list of dates between January 1, 2023 and, but not
    including, February 1, 2023\. The `date_spine` macro is an effective and flexible
    function that can help you work with dates, generate sequences of dates, or perform
    other tasks that involve dates, such as creating a `dim_date` dimension in your
    analytics model.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 期望输出是从2023年1月1日到2023年2月1日之间的日期列表，但不包括2月1日。`date_spine` 宏是一个有效且灵活的函数，可以帮助您处理日期、生成日期序列或执行涉及日期的其他任务，例如在分析模型中创建
    `dim_date` 维度。
- en: Another use case is to use your installed packages directly in your developed
    models. For example, suppose you want to compute the percentage that the `cash_amount`
    has in a specific order, yet you need to ensure that for orders when the `total_amount`
    is 0, your code will not break, reporting a division-by-zero error. You can certainly
    do this logic by yourself, but `dbt_utils` already has a built-in function that
    handles it. Let’s take a look at the code in [Example 5-21](#dbt_util_safe_divide_package_macro).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个用例是在您开发的模型中直接使用已安装的包。例如，假设您想计算 `cash_amount` 在特定订单中所占的百分比，但需要确保在 `total_amount`
    为 0 的订单中，您的代码不会因除以零而报错。您当然可以自行实现这个逻辑，但 `dbt_utils` 已经有一个内置函数可以处理此问题。让我们来看看在 [Example 5-21](#dbt_util_safe_divide_package_macro)
    中的代码。
- en: Example 5-21\. `*safe_divide*` macro inside `*dbt_utils*`
  id: totrans-204
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Example 5-21\. `*safe_divide*` 宏在 `*dbt_utils*` 内部
- en: '[PRE20]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This code uses the `safe_divide` macro to divide the numerator, `cash_amount`,
    by the denominator, `total_amount`, and to store the result in a variable called
    `result`. If the denominator is 0 or null, the `safe_divide` macro will return
    `null` instead of raising an error.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用 `safe_divide` 宏将分子 `cash_amount` 除以分母 `total_amount`，并将结果存储在名为 `result`
    的变量中。如果分母为 0 或 null，则 `safe_divide` 宏将返回 `null` 而不是引发错误。
- en: The `safe_divide` macro is great for performing division operations in a dbt
    project, especially when working with data that may contain null or 0 values.
    It can save time and reduce maintenance overhead by eliminating the need to manually
    check for null or 0 values.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`safe_divide` 宏非常适合在 dbt 项目中执行除法操作，特别是在处理可能包含 null 或 0 值的数据时。它可以通过消除手动检查 null
    或 0 值的需要，节省时间并减少维护开销。'
- en: dbt packages are a versatile tool to help you build better and more efficient
    data transformation pipelines. In this chapter, we’ve covered `dbt_utils`, which
    offers a collection of useful macros and functions that streamline common data
    modeling tasks, making it a valuable addition to your toolkit. Another interesting
    package is [`dbt_expectations`](https://oreil.ly/p0Gmi), which empowers you to
    define, document, and test your data expectations, ensuring data quality and reliability.
    Additionally, [`dbt_date`](https://oreil.ly/LFm4q) simplifies date-related calculations
    and manipulations in your data models. By leveraging these packages and others,
    you can simplify your code sharing and collaboration, reduce duplication of effort,
    and create more scalable and maintainable data models.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: dbt 包是一种多功能工具，可帮助您构建更好、更高效的数据转换管道。在本章中，我们介绍了 `dbt_utils`，它提供了一组有用的宏和函数，简化了常见的数据建模任务，是您工具包的宝贵补充。另一个有趣的包是
    [`dbt_expectations`](https://oreil.ly/p0Gmi)，它使您能够定义、记录和测试数据期望，确保数据质量和可靠性。此外，[`dbt_date`](https://oreil.ly/LFm4q)
    简化了数据模型中与日期相关的计算和操作。通过利用这些包和其他工具，您可以简化代码共享和协作，减少重复劳动，并创建更可扩展和可维护的数据模型。
- en: dbt Semantic Layer
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: dbt 语义层
- en: In data analytics, a *semantic layer* plays a key role, acting as a bridge between
    raw data and meaningful insights. This logical abstraction is a decisive translator,
    simplifying complex data structures and facilitating a common understanding of
    data throughout an organization. Doing so transforms complex database setups into
    a user-friendly language that empowers a diverse audience, from data analysts
    to business leaders, to access and understand data effortlessly. Beyond simplification,
    the semantic layer also provides data integrity and reliability, guaranteeing
    that data is understandable and trustworthy.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据分析中，*语义层* 发挥着关键作用，充当原始数据与有意义洞察之间的桥梁。这种逻辑抽象是一个决策性的翻译器，简化复杂的数据结构，并促进组织内对数据的共同理解。这样做将复杂的数据库设置转化为用户友好的语言，赋予数据分析师到业务领导层等广泛观众轻松访问和理解数据的能力。除了简化外，语义层还提供数据的完整性和可靠性，确保数据可理解和可信任。
- en: The essence of the dbt semantic layer distinguishes it fundamentally from conventional
    semantic layers. In many semantic layers, users delineate connections within the
    data by explicitly specifying the left and right join keys. However, the dbt semantic
    layer specification adopts a unique approach by introducing *entities*. These
    entities enable us to automatically infer data connections, the graph’s edges,
    within the layer. For instance, consider a customer table with a `customer_id`
    as its primary key and an orders table with a `customer_id` entity as a foreign
    key—this can form a relationship, or, more precisely, an edge in our data graph.
    This innovation significantly reduces the need for manual logic maintenance, as
    a graph usually has fewer nodes than edges.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: dbt语义层的精髓在于，它从根本上区别于传统的语义层。在许多语义层中，用户通过明确指定左右连接键来描述数据中的连接关系。然而，dbt语义层规范采用了一种独特的方法，引入了*实体*的概念。这些实体使我们能够在该层内自动推断数据连接，即图中的边。例如，考虑一个顾客表，其主键为`customer_id`，以及一个带有`customer_id`实体作为外键的订单表——这可以形成一个关系，或者更准确地说，是我们数据图中的一条边。这种创新显著减少了手动逻辑维护的需求，因为一个图通常具有比节点更少的边。
- en: The beauty of this approach lies in its simplicity and efficiency. It encapsulates
    semantic logic in an exceptionally DRY manner, facilitates a broader array of
    metric and dimension combinations, and results in cleaner SQL. These advantages
    make it easier for data teams to oversee, evolve, and leverage their data models.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的美妙之处在于其简洁性和效率。它以极其DRY的方式封装语义逻辑，促进更广泛的度量和维度组合，以及更清晰的SQL。这些优势使得数据团队更容易监督、演化和利用他们的数据模型。
- en: 'At the core of the dbt semantic layer lie two essential components: semantic
    models and metrics. *Semantic models* are the foundational building blocks, comprising
    three key elements: entities, dimensions, and measures for creating a metric.
    These components empower MetricFlow, the framework powering our semantic layer,
    to construct queries for defining metrics.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在dbt语义层的核心是两个基本组件：语义模型和度量。*语义模型*是构建基础，包括三个关键元素：实体、维度和度量，用于创建度量标准。这些组件赋予了MetricFlow框架，即支持我们语义层的框架，构建查询以定义度量标准的能力。
- en: '*Metrics*, on the other hand, are the tools we employ to measure and analyze
    our data. They operate atop the semantic models, enabling the creation of sophisticated
    and elaborate definitions built upon reusable components.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '*度量*则是我们用来衡量和分析数据的工具。它们位于语义模型之上，能够基于可重用组件创建复杂和精细的定义。'
- en: 'As previously mentioned, the semantic layer relies on three fundamental concepts
    to create metrics: entities, dimensions, and measures.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 正如先前提到的，语义层依赖于三个基本概念来创建度量标准：实体、维度和度量。
- en: An *entity* refers to an independent and identifiable object within a specific
    context. In the language of databases, entities typically correspond to tables,
    serving as the core subjects of our data collection efforts. Entities represent
    real-world concepts within a business, containing, for example, customers or orders.
    In our semantic models, entities are represented using ID columns, which function
    as join keys to connect with other semantic models in the semantic graph.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '*实体*指的是特定上下文中独立且可识别的对象。在数据库的术语中，实体通常对应于表，作为我们数据收集工作的核心主体。实体代表业务中的现实概念，例如顾客或订单。在我们的语义模型中，实体使用ID列表示，这些列作为连接键与语义图中的其他语义模型连接。'
- en: Entities are essential in helping the Semantic Engine understand the relationships
    among tables or datasets. This enables the engine to comprehend how data is interconnected,
    ensuring that when a query is made concerning a specific entity, the engine knows
    where to retrieve the relevant information.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 实体在帮助语义引擎理解表或数据集之间关系中至关重要。这使引擎能够理解数据如何相互连接，确保在查询特定实体相关信息时，引擎知道从哪里检索相关信息。
- en: On the other hand, *dimensions* provide context to measures by serving as categorical
    attributes that allow the breakdown of the data in different ways during the analysis.
    Dimensions typically describe the characteristics associated with other elements
    within the model.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*维度*通过作为分类属性来为度量提供上下文，允许在分析过程中以不同方式对数据进行分解。维度通常描述模型中其他元素相关的特征。
- en: Dimensions are configured to empower users to explore and analyze data from
    diverse perspectives. The Semantic Engine utilizes these dimensions to tailor
    queries according to user preferences.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 维度被配置为增强用户从不同角度探索和分析数据的能力。语义引擎利用这些维度根据用户的偏好定制查询。
- en: Finally, *measures* are the quantifiable data points that are the primary focus
    of analysis, representing the metrics we intend to examine. Measures are often
    subject to aggregation, and in many cases, a fundamental role of a BI tool is
    to aggregate these measures across various dimensions. The definition of measures
    ensures that calculations maintain consistency across all queries and reports,
    eliminating any semantic ambiguity.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，*度量* 是分析的主要关注点的可量化数据点，代表我们打算检查的度量。度量通常会被聚合，而在许多情况下，BI 工具的一个基本作用就是跨多个维度聚合这些度量。度量的定义确保计算在所有查询和报告中保持一致，消除任何语义模糊。
- en: Let’s illustrate how to build a dbt semantic layer. We’ll keep using the example
    of customers and orders entities. We want to measure the total amount paid (`total_amount`)
    and have a split for what was paid in cash (`cash_amount`) and what was paid in
    credit (`credit_amount`). Finally, we also want to have the total number of orders
    made (`order_count`) and the number of customers with orders (`customers_with_orders`).
    We also want to know the capacity to slide per day (`order_date`) and whether
    orders completed or not (`is_order_completed`).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来说明如何构建一个 dbt 语义层。我们将继续使用客户和订单实体的示例。我们希望衡量支付的总金额（`total_amount`），并分别列出现金支付金额（`cash_amount`）和信用支付金额（`credit_amount`）。最后，我们还希望知道订单总数（`order_count`）以及有订单的客户数量（`customers_with_orders`）。我们还希望了解每天的滑动能力（`order_date`）以及订单是否完成（`is_order_completed`）。
- en: Considering these requirements, the full semantic model is shown in [Example 5-22](#dbt_project_yml_semantic_model).
    You can add it to the respective YAML file previously created, *_core_models.yml*,
    or create a new one for the semantic model.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些要求，完整的语义模型显示在 [示例 5-22](#dbt_project_yml_semantic_model) 中。您可以将其添加到先前创建的相应
    YAML 文件 *_core_models.yml* 中，或者为语义模型创建一个新文件。
- en: Example 5-22\. YAML file configuration for the semantic model
  id: totrans-223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-22\. 用于语义模型的 YAML 文件配置
- en: '[PRE21]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Moving to the last stage, all the components covered previously require the
    involvement of a Semantic Engine to operationalize them. This engine plays a fundamental
    role in interpreting the provided data and constructing analytical queries in
    accordance with those definitions. For example, even after meticulously specifying
    all the aspects of customer orders, we still depend on an engine to parse the
    semantic model and generate a query that calculates the desired metrics. Within
    the domain of dbt, this function is fulfilled by MetricFlow.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 转向最后阶段，所有先前涵盖的组件都需要语义引擎的参与来使它们操作化。这个引擎在解释提供的数据并根据这些定义构建分析查询方面发挥了基础作用。例如，即使在详细指定客户订单的所有方面之后，我们仍然依赖于一个引擎来解析语义模型并生成计算所需度量的查询。在
    dbt 的领域内，MetricFlow 实现了这一功能。
- en: The Semantic Engine concept is analogous to a dbt Documentation Engine. When
    you create a YAML file for a model, it remains inert by itself, lacking significant
    functionality. However, the dbt Documentation Engine transforms this data into
    practical tools, including a documentation website, dbt tests, alert systems,
    data contracts, and more. Similarly, MetricFlow operates as a dbt Semantic Engine,
    leveraging its capacity to interpret semantic data and generate valuable outcomes,
    particularly standardized and reusable analytical queries.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 语义引擎的概念类似于 dbt 文档引擎。当您为一个模型创建一个 YAML 文件时，它本身是惰性的，缺乏显著的功能。然而，dbt 文档引擎将这些数据转化为实用工具，包括文档网站、dbt
    测试、警报系统、数据合同等等。类似地，MetricFlow 作为 dbt 语义引擎运作，利用其解释语义数据和生成有价值结果的能力，特别是标准化和可重用的分析查询。
- en: To use MetricFlow for the generation of analytical queries, the initial step
    consists of establishing metrics based on the semantic model you’ve meticulously
    constructed. You can define metrics in the same YAML files as your semantic models
    or create a new file.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 MetricFlow 生成分析查询，初始步骤包括基于您精心构建的语义模型建立度量。您可以在与语义模型相同的 YAML 文件中定义度量，也可以创建一个新文件。
- en: To illustrate the process of metrics creation, let’s first clarify the specific
    metrics we intend to develop. To maintain simplicity while retaining interest,
    it’s worthwhile to include a metric that calculates the total amount of orders
    (`order_total`). Furthermore, we can create another metric that tracks the count
    of orders placed (`order_count`). Finally, we’ll explore a metric that, based
    on the number count of orders placed, filters the metric itself, revealing what
    portion of the orders placed were completed. [Example 5-23](#dbt_project_yml_metrics)
    provides a YAML file demonstrating the proper configuration of these metrics.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明指标创建的过程，让我们首先澄清我们打算开发的具体指标。为了保持简单同时保持趣味性，包括计算订单总金额 (`order_total`) 的指标是值得的。此外，我们可以创建另一个跟踪下订单数量
    (`order_count`) 的指标。最后，我们将探索一个基于下订单数量的指标，过滤指标本身，显示完成的订单占比。[示例 5-23](#dbt_project_yml_metrics)
    提供了一个 YAML 文件，演示了这些指标的正确配置。
- en: Example 5-23\. Metrics YAML file configuration
  id: totrans-229
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-23\. 指标 YAML 文件配置
- en: '[PRE22]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As an example, to get MetricFlow working on `order_total`, use the CLI command
    `mf query --metric order_total`. MetricFlow will interpret this definition alongside
    the measure’s definition (outlined in the semantic model) to produce the query
    in [Example 5-24](#order_total_query_produced).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，要让 MetricFlow 在 `order_total` 上工作，使用 CLI 命令 `mf query --metric order_total`。MetricFlow
    将根据这个定义以及度量的定义（在语义模型中概述）生成查询，详见 [示例 5-24](#order_total_query_produced)。
- en: Example 5-24\. Order total query
  id: totrans-232
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 5-24\. 订单总额查询
- en: '[PRE23]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note
  id: totrans-234
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: While this chapter aims to showcase the workings of the semantic layer within
    dbt, note that there may be better choices for organization-wide deployment than
    `mf query`. For broader and more robust usage across your organization, consider
    utilizing the APIs provided by dbt. Additionally, we recommend referring to the
    [“Set Up the dbt Semantic Layer” page](https://oreil.ly/UaZbt) for the most up-to-date
    and accurate installation instructions for the semantic layer and MetricFlow,
    as it is regularly updated with the latest information and developments.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本章旨在展示 dbt 内的语义层的工作原理，但请注意，在 `mf query` 方面，组织范围内可能有更好的选择。为了在整个组织中更广泛且更强大地使用，考虑使用
    dbt 提供的 API。此外，我们建议参考 [“设置 dbt 语义层” 页面](https://oreil.ly/UaZbt) 获取语义层和 MetricFlow
    的最新安装指南，因为它定期更新以反映最新信息和发展。
- en: Having established a dbt semantic layer, you’ve effectively created an abstraction
    layer over your data. Regardless of any modifications made to the orders dataset,
    anyone seeking the total order amount can easily access the `order_total` metric.
    This empowers users to analyze the orders data according to their specific requirements.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在建立了 dbt 语义层之后，您有效地创建了一个数据的抽象层。无论对订单数据集进行了任何修改，任何想要获取订单总金额的人都可以轻松访问 `order_total`
    指标。这使用户能够根据他们的具体需求分析订单数据。
- en: Summary
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: In this chapter, we’ve dug into advanced topics in the world of dbt, expanding
    our understanding of this transformative tool. We explored the power of dbt models
    and materializations, uncovering how they enable us to manage complex data transformations
    while ensuring efficient performance optimization. Using dynamic SQL with Jinja
    has allowed us to create dynamic and reusable queries that adapt to changing requirements,
    thus enhancing the agility of our data processes.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了 dbt 世界中的高级主题，扩展了我们对这个变革性工具的理解。我们探讨了 dbt 模型和材料化的威力，揭示了它们如何使我们能够管理复杂的数据转换，同时确保高效的性能优化。使用
    Jinja 动态 SQL 允许我们创建动态和可重用的查询，适应不断变化的需求，从而增强了我们数据处理的灵活性。
- en: Moving beyond the fundamentals, we presented SQL macros, unlocking a new level
    of automation and reusability in our codebase. Through insightful examples, we
    saw how SQL macros can drastically streamline our code and bring consistency to
    our data transformations.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 超越基础知识，我们介绍了 SQL 宏，解锁了我们代码库中自动化和可重用性的新水平。通过深入的示例，我们看到了 SQL 宏如何极大地简化我们的代码并为数据转换带来一致性。
- en: Moreover, the concept of dbt packages emerged as a cornerstone of collaboration
    and knowledge sharing in our data ecosystem. We discussed how dbt packages allow
    us to encapsulate logic, best practices, and reusable code, fostering a culture
    of collaboration and accelerating development cycles.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，dbt 包的概念作为我们数据生态系统中协作和知识共享的基石出现。我们讨论了 dbt 包如何允许我们封装逻辑、最佳实践和可重复使用的代码，促进协作文化并加速开发周期。
- en: Finally, we’ve demonstrated how the dbt semantic layer can enhance your analytics
    solution by providing an abstraction layer over your data. This layer ensures
    consistency and exactness across all reports and analyses because the business
    logic is centralized and verified within the semantic layer, minimizing the risk
    of disparities or mistakes. Furthermore, as the database expands or undergoes
    modifications, having a semantic layer allows you to make adjustments in a single
    location, eliminating the need to update numerous reports or queries individually.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们展示了dbt语义层如何通过为数据提供抽象层来增强您的分析解决方案。这一层确保了所有报告和分析的一致性和准确性，因为业务逻辑在语义层中是集中和验证的，从而最小化了差异或错误的风险。此外，随着数据库的扩展或经历修改，拥有语义层使您可以在单一位置进行调整，无需单独更新多个报告或查询。
- en: As we conclude this chapter, we’ve embarked on a journey through various advanced
    dbt topics, equipping ourselves with the knowledge and tools required to optimize
    our data processes. These advanced concepts elevate our data transformations and
    empower us to elevate our data analytics to unprecedented heights. Armed with
    these insights, we’ve competently navigated the complexities of data challenges
    while promoting innovation in our data-driven endeavors.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束本章时，我们已经深入探讨了各种高级dbt主题，装备了优化数据流程所需的知识和工具。这些高级概念提升了我们的数据转换能力，并使我们能够将数据分析提升到前所未有的高度。凭借这些见解，我们在处理数据挑战的复杂性同时促进了数据驱动的创新。
- en: However, it’s important to note that while this has been a comprehensive guide
    to dbt, the dbt universe is vast and continually evolving. Several additional
    topics are worth exploring, such as advanced deployment techniques like blue/green,
    canary, or shadow deployments. Additionally, digging into the usage of Write-Audit-Process
    (WAP) patterns can provide teams with greater control over data quality and traceability.
    Also, exploring how dbt interfaces with other tools in the data ecosystem would
    be valuable, as well as understanding how to work with multiproject organizations.
    Indeed, dbt is a dynamic and expansive world; there’s always more to learn and
    discover on this exciting data journey.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要注意的是，尽管本指南全面介绍了dbt，但dbt的宇宙是广阔且不断发展的。还有一些值得探索的附加主题，例如高级部署技术，比如蓝/绿、金丝雀或阴影部署。此外，深入研究Write-Audit-Process（WAP）模式的使用可以为团队提供对数据质量和可追溯性更大的控制。同时，探索dbt如何与数据生态系统中的其他工具交互将非常有价值，以及如何与多项目组织合作。确实，dbt是一个充满活力和广阔的世界；在这个激动人心的数据旅程中，总是有更多可以学习和发现的内容。
