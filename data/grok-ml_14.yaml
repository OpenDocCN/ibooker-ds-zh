- en: Appendix A. Solutions to the exercises
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 A. 练习题解答
- en: 'Chapter 2: Types of machine learning'
  id: totrans-1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二章：机器学习类型
- en: For the questions in this chapter, your answers don’t need to match mine. If
    you have different ideas for models used in these applications, they might be
    great! I encourage you to look them up in the literature, and if they don’t exist,
    try to implement them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章的问题，你的答案不需要与我的一致。如果你对这些应用中使用的模型有不同想法，那可能是个好主意！我鼓励你在文献中查找它们，如果它们不存在，尝试实现它们。
- en: Exercise 2.1
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 2.1
- en: For each of the following scenarios, state if it is an example of supervised
    or unsupervised learning. Explain your answers. In cases of ambiguity, pick one
    and explain why you picked it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下每个场景，说明它是否是监督学习或无监督学习的例子。解释你的答案。在模糊不清的情况下，选择一个并解释你为什么选择它。
- en: A recommendation system on a social network that recommends potential friends
    to a user
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个社交网络上的推荐系统，向用户推荐潜在的朋友
- en: A system in a news site that divides the news into topics
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个新闻网站上按主题划分新闻的系统
- en: The Google autocomplete feature for sentences
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Google 自动补全功能的句子
- en: A recommendation system on an online retailer that recommends to users what
    to buy based on their past purchasing history
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个在线零售商上的推荐系统，根据用户的过去购买历史向用户推荐购买商品
- en: A system in a credit card company that captures fraudulent transactions
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个信用卡公司中捕捉欺诈交易的系统
- en: Solution
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: Depending on how you interpreted the problem and the dataset, each of these
    can be considered an example of supervised or unsupervised learning. It is completely
    OK (and encouraged!) to have different answers, as long as the reasoning behind
    them is correct.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你对问题和数据集的解释，每个这些都可以被认为是监督学习或无监督学习的例子。完全没问题（并且鼓励！）有不同的答案，只要背后的推理是正确的。
- en: 'This is an example of both supervised and unsupervised learning. Supervised
    learning: for a particular user, we can build a classification model where the
    label of every other user is positive if they are a potential friend and negative
    if they are not a potential friend.'
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这也是一个监督学习和无监督学习的例子。监督学习：对于特定用户，我们可以构建一个分类模型，其中其他每个用户的标签如果是潜在朋友则为正，如果不是潜在朋友则为负。
- en: 'This is also an example of both supervised and unsupervised learning. Supervised
    learning: a classification model where the label of each news article is the topic,
    for example, politics, sports, or science. Unsupervised learning: we can cluster
    the articles and then manually check if the topics in each cluster are similar.
    If this is the case, then we can manually label each cluster by the most common
    topic. There are some more advanced unsupervised learning techniques such as latent
    Dirichlet allocation, which you can learn in this video: [https://www.youtube.com/watch?v=T05t-SqKArY](https://www.youtube.com/watch?v=T05t-SqKArY).'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这也是一个监督学习和无监督学习的例子。监督学习：一个分类模型，其中每篇新闻文章的标签是主题，例如政治、体育或科学。无监督学习：我们可以对文章进行聚类，然后手动检查每个聚类的主题是否相似。如果相似，那么我们可以手动通过最常见的主题为每个聚类打标签。还有一些更高级的无监督学习技术，如潜在狄利克雷分配，你可以在这个视频中学习到：[https://www.youtube.com/watch?v=T05t-SqKArY](https://www.youtube.com/watch?v=T05t-SqKArY)。
- en: This one is more of a supervised learning task. We can build a classification
    model in which the features are the last few words the user has typed, and the
    label is the next word they’ll type. In that way, the prediction of the model
    is the word we’ll suggest to the user.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个例子更偏向于监督学习任务。我们可以构建一个分类模型，其中特征是用户最后输入的几个单词，标签是他们将要输入的下一个单词。这样，模型的预测就是我们将建议给用户的单词。
- en: 'This is similar to a), and it can be considered a supervised or an unsupervised
    learning problem. Supervised learning: for a particular user, we can build a classification
    model for all the products, where for each product, we predict whether the user
    will buy it. We can also build a regression model in which we predict how much
    money the user will spend on that particular product. Unsupervised learning: we
    can cluster the users. If a user has bought a product, we can recommend that same
    product to other users in the cluster. We can also cluster the products, and if
    a user has bought a product, we recommend products in the same cluster.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这与a)类似，它可以被认为是一个监督学习或无监督学习问题。监督学习：对于特定用户，我们可以为所有产品构建一个分类模型，其中对于每个产品，我们预测用户是否会购买它。我们也可以构建一个回归模型，其中我们预测用户将在这个特定产品上花费多少钱。无监督学习：我们可以对用户进行聚类。如果一个用户购买了一个产品，我们可以向该聚类中的其他用户推荐相同的产品。我们也可以对产品进行聚类，如果一个用户购买了一个产品，我们推荐同一聚类中的产品。
- en: This one is more of a supervised learning task. We can build a classification
    model that predicts whether a certain transaction is fraudulent or not, based
    on the characteristics of that transaction. It can also be seen as an unsupervised
    learning task in which we cluster the transactions, and those left as outliers
    have a higher chance of being fraudulent.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个任务更倾向于监督学习。我们可以构建一个分类模型，根据交易的特性预测某个交易是否是欺诈的。它也可以被视为一个无监督学习任务，其中我们聚类交易，那些被留下的异常值有更高的可能性是欺诈的。
- en: Exercise 2.2
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 2.2
- en: For each of the following applications of machine learning, would you use regression
    or classification to solve it? Explain your answers. In cases of ambiguity, pick
    one and explain why you picked it.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下机器学习的应用，你会使用回归还是分类来解决它？解释你的答案。在存在歧义的情况下，选择一个并解释你为什么选择了它。
- en: An online store predicting how much money a user will spend on their site
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个在线商店预测用户在其网站上会花费多少钱
- en: A voice assistant decoding voice and turning it into text
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个语音助手解码语音并将其转换为文本
- en: Selling or buying stock from a particular company
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从特定公司买卖股票
- en: YouTube recommending a video to a user
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: YouTube向用户推荐视频
- en: Solution
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: Regression, because we are trying to predict the amount of money that the user
    spends, and this is a numerical feature.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回归，因为我们试图预测用户花费的金额，这是一个数值特征。
- en: Classification, because we are trying to predict whether the sentence the user
    has spoken is directed to Alexa, and this is a categorical feature.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类，因为我们试图预测用户所说的句子是否是针对Alexa的，这是一个分类特征。
- en: This could be regression or classification. If we are trying to predict the
    expected gain or the expected risk to help us in our decision, it is regression.
    If we are trying to predict whether we should buy the stock, it is classification.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这可能是回归或分类。如果我们试图预测预期的收益或预期的风险以帮助我们做出决策，那么它是回归。如果我们试图预测我们是否应该购买股票，那么它是分类。
- en: This can again be regression or classification. If we are trying to predict
    how much time the user will spend watching the video in order to recommend it,
    it is regression. If we are trying to predict whether the user will watch a video,
    it is classification.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这又可以再次是回归或分类。如果我们试图预测用户观看视频的时间以推荐它，那么它是回归。如果我们试图预测用户是否会观看视频，那么它是分类。
- en: Exercise 2.3
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 2.3
- en: Your task is to build a self-driving car. Give at least three examples of machine
    learning problems that you would have to solve to build it. In each example, explain
    whether you are using supervised/unsupervised learning, and if supervised, whether
    you are using regression or classification. If you are using other types of machine
    learning, explain which ones and why.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你的任务是构建一辆自动驾驶汽车。至少给出三个你必须解决的机器学习问题示例。在每个例子中，解释你是否使用监督学习/无监督学习，如果是监督学习，是否使用回归或分类。如果你使用其他类型的机器学习，解释这些类型以及为什么。
- en: Solution
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: A classification model, which, based on the image, determines whether there
    are pedestrians, stop signs, lanes, other cars, and so on. This is a large area
    of machine learning called computer vision, which I highly encourage you to explore
    further!
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个分类模型，根据图像确定是否存在行人、停车标志、车道、其他车辆等。这是一个称为计算机视觉的机器学习大领域，我强烈建议你进一步探索！
- en: A similar classification model as the previous one, which determines what objects
    are around the car based on the signals from all the different sensors in the
    car (lidar, etc).
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与前一个类似的分类模型，它根据汽车中所有不同传感器（激光雷达等）的信号来确定汽车周围的对象。
- en: A machine learning model that finds the closest path to our desired destination.
    This is not precisely supervised or unsupervised learning. There are some more
    classical artificial intelligence algorithms such as A* (A-star) search that can
    be used here.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个机器学习模型，用于找到到达我们期望目的地的最近路径。这既不是精确的监督学习，也不是无监督学习。这里还可以使用一些更经典的的人工智能算法，例如 A*（A-星）搜索算法。
- en: 'Chapter 3: Drawing a line close to our points: Linear regression'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 3 章：在点附近画线：线性回归
- en: Exercise 3.1
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 3.1
- en: A website has trained a linear regression model to predict the amount of minutes
    that a user will spend on the site. The formula they have obtained is
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一个网站已经训练了一个线性回归模型来预测用户将在网站上花费的分钟数。他们得到的公式是
- en: '*t̂* = 0.8*d* + 0.5*m* + 0.5*y* + 0.2*a* + 1.5'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '*t̂* = 0.8*d* + 0.5*m* + 0.5*y* + 0.2*a* + 1.5'
- en: 'where *t̂* is the predicted time in minutes, and *d*, *m*, *y*, and *a* are
    indicator variables (namely, they take only the values 0 or 1) defined as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *t̂* 是预测的分钟数，而 *d*、*m*、*y* 和 *a* 是指示变量（即，它们只取 0 或 1 的值），定义如下：
- en: '*d* is a variable that indicates if the user is on desktop.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*d* 是一个变量，表示用户是否在使用桌面设备。'
- en: '*m* is a variable that indicates if the user is on mobile device.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*m* 是一个变量，表示用户是否在使用移动设备。'
- en: '*y* is a variable that indicates if the user is young (under 21 years old).'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y* 是一个变量，表示用户是否年轻（21 岁以下）。'
- en: '*a* is a variable that indicates if the user is an adult (21 years old or older).'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*a* 是一个变量，表示用户是否是成年人（21 岁或以上）。'
- en: 'Example: If a user is 30 years old and on desktop, then *d* = 1, *m* = 0, *y*
    = 0, and *a* = 1.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 示例：如果用户 30 岁，并且使用桌面设备，那么 *d* = 1，*m* = 0，*y* = 0，*a* = 1。
- en: If a 45-year-old user looks at the website from their phone, what is the expected
    time they will spend on the site?
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个 45 岁的用户用手机查看网站，他们预计会在网站上花费多少时间？
- en: Solution
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'In this case, the values of the variables are the following:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，变量的值如下：
- en: '*d* = 0 because the user is not on desktop.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*d* = 0 因为用户不在桌面设备上。'
- en: '*m* = 1 because the user is on mobile.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*m* = 1 因为用户在使用移动设备。'
- en: '*y* = 0 because the user is not under 21.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y* = 0 因为用户不是 21 岁以下。'
- en: '*a* = 1 because the user is over 21.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*a* = 1 因为用户年龄超过 21 岁。'
- en: When we plug them into the formula, we get
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将它们代入公式时，我们得到
- en: '*t̂* = 0.8 · 0 + 0.5 · 1 + 0.5 · 0 + 0.2 · 1 + 1.5 = 2.2.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*t̂* = 0.8 · 0 + 0.5 · 1 + 0.5 · 0 + 0.2 · 1 + 1.5 = 2.2。'
- en: This means the model predicts that this user will spend 2.2 minutes on the website.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着模型预测这位用户将在网站上花费 2.2 分钟。
- en: Exercise 3.2
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 3.2
- en: Imagine that we trained a linear regression model in a medical dataset. The
    model predicts the expected lifetime of a patient. To each of the features in
    our dataset, the model would assign a weight.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在一个医学数据集上训练了一个线性回归模型。该模型预测患者的预期寿命。模型会为我们的数据集中的每个特征分配一个权重。
- en: 'a) For the following quantities, state if you believe the weight attached to
    this quantity is a positive number, a negative number, or zero. Note: if you believe
    that the weight is a very small number, whether positive or negative, you can
    say zero.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: a) 对于以下数量，说明你认为附加到这个数量的权重是正数、负数还是零。注意：如果你认为权重是一个非常小的数，无论是正数还是负数，你可以说零。
- en: Number of hours of exercise the patient gets per week
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 患者每周的锻炼小时数
- en: Number of cigarettes the patient smokes per week
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 患者每周吸烟的数量
- en: Number of family members with heart problems
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 患者家庭成员中患有心脏病的人数
- en: Number of siblings of the patient
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 患者的兄弟姐妹数量
- en: Whether or not the patient has been hospitalized
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 患者是否曾住院
- en: b) The model also has a bias. Do you think the bias is positive, negative, or
    zero?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: b) 模型还有一个偏差。你认为偏差是正数、负数还是零？
- en: Solution
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'a) We’ll make some generalizations based on general medical knowledge. For
    a particular patient, the following are not necessarily true, but we’ll make the
    assumption that they are true for the general population:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: a) 我们将基于一般的医学知识进行一些概括。对于特定的患者，以下情况不一定成立，但我们将假设它们对整个人群是成立的：
- en: A patient who exercises a lot is expected to live longer than a similar patient
    who doesn’t. Thus, this weight should be a positive number.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预期一个经常锻炼的患者比不锻炼的类似患者寿命更长。因此，这个权重应该是正数。
- en: A patient who smokes many cigarettes a week is expected to live shorter than
    a similar patient who doesn’t. Thus, this weight should be a negative number.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一位每周吸烟很多支的病人预期寿命会比不吸烟的类似病人短。因此，这个权重应该是负数。
- en: A patient who has many family members with heart problems has a higher likelihood
    of having heart problems, and thus they are expected to live shorter than a similar
    patient that doesn’t have them. Thus, this weight should be a negative number.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一位有很多家庭成员患有心脏病的病人，患心脏病的可能性更高，因此他们预期寿命会比没有这些疾病的类似病人短。因此，这个权重应该是负数。
- en: The number of siblings tends to be independent of the expected lifetime, so
    we expect this weight to be a very small number, or zero.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 兄弟姐妹的数量通常与预期寿命无关，因此我们预计这个权重将是一个非常小的数字，或者为零。
- en: A patient who has been hospitalized in the past is likely to have had previous
    health problems. Thus, their expected lifetime is shorter than a similar patient
    that hasn’t been hospitalized before. Therefore, this weight should be a negative
    number. Of course, the hospitalization could be for a reason that doesn’t affect
    expected lifetime (such as a broken leg), but on average, we can say that if a
    patient has been to the hospital in the past, they have a higher probability to
    have health problems.
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一位过去曾经住院的病人可能之前就有健康问题。因此，他们的预期寿命会比之前从未住院的类似病人短。因此，这个权重应该是负数。当然，住院可能是因为不影响预期寿命的原因（例如骨折），但平均来说，我们可以这样说，如果病人过去曾经去过医院，他们有更高的可能性有健康问题。
- en: b) The bias is the prediction for a patient for which every feature is zero
    (i.e., a patient who doesn’t smoke, doesn’t exercise, has zero family members
    with heart condition, zero siblings, and has never been hospitalized). Because
    this patient is expected to live a positive number of years, the bias of this
    model must be a positive number.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: b) 偏差是对一个所有特征都为零的病人的预测（即一个不吸烟、不运动、没有心脏病家族成员、没有兄弟姐妹且从未住院的病人）。因为这个病人预期会活很多年，所以这个模型的偏差必须是正数。
- en: Exercise 3.3
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 练习3.3
- en: The following is a dataset of houses with sizes (in square feet) and prices
    (in dollars).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一组房屋数据集，包括面积（平方英尺）和价格（美元）。
- en: '|  | Size (s) | Prize (p) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | 面积(s) | 奖金(p) |'
- en: '| House 1 | 100 | 200 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 房屋1 | 100 | 200 |'
- en: '| House 2 | 200 | 475 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 房屋2 | 200 | 475 |'
- en: '| House 3 | 200 | 400 |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 房屋3 | 200 | 400 |'
- en: '| House 4 | 250 | 520 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 房屋4 | 250 | 520 |'
- en: '| House 5 | 325 | 735 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 房屋5 | 325 | 735 |'
- en: 'Suppose we have trained the model where the prediction for the price of the
    house based on size is the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们已经训练了一个模型，该模型根据房屋面积预测价格如下：
- en: '![](../Images/p_cf.png) = 2s + 50'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/p_cf.png) = 2s + 50'
- en: Calculate the predictions that this model makes on the dataset.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算该模型在数据集上的预测结果。
- en: Calculate the mean absolute error of this model.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算该模型的平均绝对误差。
- en: Calculate the root mean square error of this model.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算该模型的均方根误差。
- en: Solution
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'The predicted prices based on the model follow:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于模型的预测价格如下：
- en: 'House 1: ![](../Images/p_cf.png) = 2 · 100 + 50 = 250'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '房屋1: ![](../Images/p_cf.png) = 2 · 100 + 50 = 250'
- en: 'House 2: ![](../Images/p_cf.png) = 2 · 200 + 50 = 450'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '房屋2: ![](../Images/p_cf.png) = 2 · 200 + 50 = 450'
- en: 'House 3: ![](../Images/p_cf.png) = 2 · 200 + 50 = 450'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '房屋3: ![](../Images/p_cf.png) = 2 · 200 + 50 = 450'
- en: 'House 4: ![](../Images/p_cf.png) = 2 · 250 + 50 = 550'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '房屋4: ![](../Images/p_cf.png) = 2 · 250 + 50 = 550'
- en: 'House 5: ![](../Images/p_cf.png) = 2 · 325 + 50 = 700'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '房屋5: ![](../Images/p_cf.png) = 2 · 325 + 50 = 700'
- en: The mean absolute error is
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 平均绝对误差是
- en: '![](../Images/AppA_00_E01.png)'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../Images/AppA_00_E01.png)'
- en: The mean square error is
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 均方误差是
- en: '![](../Images/AppA_00_E02.png)'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../Images/AppA_00_E02.png)'
- en: Therefore, the root mean square error is √1550 = 39.37.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，均方根误差是 √1550 = 39.37。
- en: Exercise 3.4
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 练习3.4
- en: Our goal is to move the line with equation *ŷ* = 2*x* + 3 closer to the point
    (*x*, *y*) = (5, 15) using the tricks we’ve learned in this chapter. For the following
    two problems, use the learning rate *η* = 0.01.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是使用本章学到的技巧将方程 *ŷ* = 2*x* + 3 的直线移动到点 (*x*, *y*) = (5, 15) 附近。对于以下两个问题，使用学习率
    *η* = 0.01。
- en: Apply the absolute trick to modify the line above to be closer to the point.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用绝对技巧修改上述行，使其更接近该点。
- en: Apply the square trick to modify the line above to be closer to the point.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用平方技巧修改上述行，使其更接近该点。
- en: Solution
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: The prediction that this model makes at the point is *ŷ* = 2 · 5 + 3 = 13.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在这一点上的预测是 *ŷ* = 2 · 5 + 3 = 13。
- en: Because the prediction is 13, which is smaller than the label 15, the point
    is underneath the line.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为预测值是13，小于标签值15，所以这个点位于线下方。
- en: In this model, the slope is *m* = 2 and the *y*-intercept is *b* = 3\. The absolute
    trick involves adding *x**η* = 5 · 0.01 = 0.05 to the slope, and *η* = 0.01 to
    the *y*-intercept, thus obtaining the model with equation
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个模型中，斜率是 *m* = 2，*y* 截距是 *b* = 3。绝对技巧涉及将 *x**η* = 5 · 0.01 = 0.05 添加到斜率，将
    *η* = 0.01 添加到 *y* 截距，从而得到具有以下方程的模型
- en: '*ŷ* = 2.05*x* + 3.01.'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*ŷ* = 2.05*x* + 3.01.'
- en: The square trick involves adding (*y* – *ŷ*)*x**η* = (15 – 13) · 5 · 0.01 =
    0.1 to the slope, and (*y* – *ŷ*)*η* = (15 – 13) · 0.01 = 0.02 to the *y*-intercept,
    thus obtaining the model with equation
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 平方技巧涉及将 (*y* – *ŷ*)*x**η* = (15 – 13) · 5 · 0.01 = 0.1 添加到斜率，将 (*y* – *ŷ*)*η*
    = (15 – 13) · 0.01 = 0.02 添加到 *y* 截距，从而得到具有以下方程的模型
- en: '*ŷ* = 2.1*x* + 3.02.'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*ŷ* = 2.1*x* + 3.02.'
- en: 'Chapter 4: Optimizing the training process: Underfitting, overfitting, testing,
    and regularization'
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四章：优化训练过程：欠拟合、过拟合、测试和正则化
- en: Exercise 4.1
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 练习4.1
- en: We have trained four models in the same dataset with different hyperparameters.
    In the following table we have recorded the training and testing errors for each
    of the models.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在同一数据集上使用不同的超参数训练了四个模型。在下面的表中，我们记录了每个模型的训练和测试误差。
- en: '| Model | Training error | Testing error |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 训练误差 | 测试误差 |'
- en: '| 1 | 0.1 | 1.8 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.1 | 1.8 |'
- en: '| 2 | 0.4 | 1.2 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.4 | 1.2 |'
- en: '| 3 | 0.6 | 0.8 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.6 | 0.8 |'
- en: '| 4 | 1.9 | 2.3 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1.9 | 2.3 |'
- en: Which model would you select for this dataset?
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于这个数据集，你会选择哪个模型？
- en: Which model looks like it’s underfitting the data?
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个模型看起来像是对数据进行欠拟合？
- en: Which model looks like it’s overfitting the data?
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个模型看起来像是对数据进行过拟合？
- en: Solution
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: The best model is the one with the smallest testing error, which is model 3.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最佳模型是测试误差最小的模型，即模型3。
- en: Model 4 looks like it is underfitting because it has large training and testing
    errors.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型4看起来像是对数据进行欠拟合，因为它有较大的训练和测试误差。
- en: Models 1 and 2 look like they are overfitting, because they have small training
    errors but large testing errors.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型1和2看起来像是对数据进行过拟合，因为它们的训练误差小，但测试误差大。
- en: Exercise 4.2
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 练习4.2
- en: 'We are given the following dataset:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们给出了以下数据集：
- en: '| *x*   | *y*   |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| *x*   | *y*   |'
- en: '| 1 | 2 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 |'
- en: '| 2 | 2.5 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 2.5 |'
- en: '| 3 | 6 |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 6 |'
- en: '| 4 | 14.5 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 14.5 |'
- en: '| 5 | 34 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 34 |'
- en: We train the polynomial regression model that predicts the value of *y* as *ŷ*,
    where
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练的预测 *y* 值为 *ŷ* 的多项式回归模型
- en: '*ŷ* = 2*x*² *–* 5*x* + 4*.*'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '*ŷ* = 2*x*² *–* 5*x* + 4*.*'
- en: 'If the regularization parameter is λ = 0.1 and the error function we’ve used
    to train this dataset is the mean absolute value (MAE), determine the following:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 如果正则化参数 λ = 0.1，并且我们用来训练这个数据集的错误函数是平均绝对误差（MAE），确定以下内容：
- en: The lasso regression error of our model (using the L1-norm)
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们模型（使用L1范数）的lasso回归误差
- en: The ridge regression error of our model (using the L2-norm)
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们模型（使用L2范数）的岭回归误差
- en: Solution
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: First we need to find the predictions to calculate the mean absolute error of
    the model. In the following table, we can find the prediction calculated by the
    formula *ŷ* = 2*x*² *–* 5*x* + 4, and the absolute value of the difference between
    the prediction and the label |*y* – *ŷ*|.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要找到预测值来计算模型的平均绝对误差。在下面的表中，我们可以找到使用公式 *ŷ* = 2*x*² *–* 5*x* + 4 计算的预测值，以及预测值和标签之间的差的绝对值
    |*y* – *ŷ*|。
- en: '| *x*   | *y*   | *ŷ*   | &#124;*y – ŷ*&#124; |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| *x*   | *y*   | *ŷ*   | |*y – ŷ*| |'
- en: '| 1 | 2 | 1 | 1 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 2 | 1 | 1 |'
- en: '| 2 | 2.5 | 2 | 0.5 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 2.5 | 2 | 0.5 |'
- en: '| 3 | 6 | 7 | 1 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 6 | 7 | 1 |'
- en: '| 4 | 14.5 | 16 | 1.5 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 14.5 | 16 | 1.5 |'
- en: '| 5 | 34 | 29 | 5 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 34 | 29 | 5 |'
- en: Thus, the mean absolute error is the average of the numbers in the fourth row,
    namely
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，平均绝对误差是第四行数字的平均值
- en: '![](../Images/AppA_00_E03.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/AppA_00_E03.png)'
- en: First we need to find the L1-norm of the polynomial. This is the sum of the
    absolute values of the nonconstant coefficients, namely, |2| + |–5| = 7\. To find
    the L1-regularization cost of the model, we add the mean absolute error and the
    L1-norm times the regularization parameter, to obtain 1.8 + 0.1 · 7 = 2.5.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要找到多项式的L1范数。这是非常数系数的绝对值之和，即 |2| + |–5| = 7。为了找到模型的L1正则化成本，我们需要将平均绝对误差和L1范数乘以正则化参数相加，得到
    1.8 + 0.1 · 7 = 2.5。
- en: In a similar way, we find the L1-norm of the polynomial by adding the squares
    of nonconstant coefficients to get 2² + (–5)² = 29\. As before, the L2-regularization
    cost of the model is 1.8 + 0.1 · 29 = 4.7.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以类似的方式，我们通过将非常数系数的平方相加来找到多项式的L1范数，即 2² + (–5)² = 29。与之前一样，模型的L2正则化成本是 1.8 +
    0.1 · 29 = 4.7。
- en: 'Chapter 5: Using lines to split our points: The perceptron algorithm'
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第五章：使用线分割我们的点：感知器算法
- en: Exercise 5.1
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 5.1
- en: The following is a dataset of patients who have tested positive or negative
    for COVID-19\. Their symptoms are cough (C), fever (F), difficulty breathing (B),
    and tiredness (T).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个数据集，其中包含已测试 COVID-19 阳性或阴性的患者。他们的症状是咳嗽 (C)、发烧 (F)、呼吸困难 (B) 和疲劳 (T)。
- en: '|  | Cough (C) | Fever (F) | Difficulty breathing (B) | Tiredness (T) | Diagnosis
    (D) |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  | 咳嗽 (C) | 发烧 (F) | 呼吸困难 (B) | 疲劳 (T) | 诊断 (D) |'
- en: '| Patient 1 |  | X | X | X | Sick |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 1 |  | X | X | X | 病例 |'
- en: '| Patient 2 | X | X |  | X | Sick |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 2 | X | X |  | X | 病例 |'
- en: '| Patient 3 | X |  | X | X | Sick |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 3 | X |  | X | X | 病例 |'
- en: '| Patient 4 | X | X | X |  | Sick |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 4 | X | X | X |  | 病例 |'
- en: '| Patient 5 | X |  |  | X | Healthy |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 5 | X |  |  | X | 健康 |'
- en: '| Patient 6 |  | X | X |  | Healthy |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 6 |  | X | X |  | 健康 |'
- en: '| Patient 7 |  | X |  |  | Healthy |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 7 |  | X |  |  | 健康 |'
- en: '| Patient 8 |  |  |  | X | Healthy |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 8 |  |  |  | X | 健康 |'
- en: Build a perceptron model that classifies this dataset.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个分类此数据集的感知器模型。
- en: hint You can use the perceptron algorithm, but you may be able to eyeball a
    good perceptron model that works.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：你可以使用感知器算法，但你可能能够通过直观地找到一个有效的感知器模型。
- en: Solution
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'If we count how many symptoms each patient has, we notice that the sick patients
    show three or more symptoms, whereas the healthy patients show two or fewer symptoms.
    Thus, the following model works to predict the diagnosis *D*:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们计算每个患者有多少症状，我们会注意到，病例患者表现出三个或更多的症状，而健康患者表现出两个或更少的症状。因此，以下模型可以用来预测诊断 *D*：
- en: '*D̂* = *step*(*C* + *F* + *B* + *T* – 2.5)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '*D̂* = *step*(*C* + *F* + *B* + *T* – 2.5)'
- en: Exercise 5.2
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 5.2
- en: Consider the perceptron model that assigns to the point (*x*[1], *x*[2]) the
    prediction *ŷ* = *step*(2*x*[1] + 3*x*[2] – 4). This model has as a boundary line
    with equation 2*x*[1] + 3*x*[2] – 4 = 0\. We have the point *p* = (1, 1) with
    label 0.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑将预测 *ŷ* = *step*(2*x*[1] + 3*x*[2] – 4) 分配给点 (*x*[1]，*x*[2]) 的感知器模型。此模型具有方程
    2*x*[1] + 3*x*[2] – 4 = 0 的边界线。我们有一个点 *p* = (1, 1)，其标签为 0。
- en: Verify that the point *p* is misclassified by the model.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证点 *p* 是否被模型错误分类。
- en: Calculate the perceptron error that the model produces at the point *p*.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算模型在点 *p* 处产生的感知器误差。
- en: Use the perceptron trick to obtain a new model that still misclassifies *p*
    but that produces a smaller error. You can use *η* = 0.01 as the learning rate.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用感知器技巧获得一个新的模型，该模型仍然错误地分类 *p*，但产生的误差更小。你可以使用 *η* = 0.01 作为学习率。
- en: Find the prediction given by the new model at the point *p*, and verify that
    the perceptron error obtained is smaller than the original.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到新模型在点 *p* 处给出的预测，并验证得到的感知器误差小于原始误差。
- en: Solution
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: The prediction for the point *p* is
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点 *p* 的预测为
- en: '*ŷ* = *step*(2*x*[1] + 3*x*[2] – 4) = *step*(2 · 1 + 3 · 1 – 4) = *step*(1)
    = 1.'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*ŷ* = *step*(2*x*[1] + 3*x*[2] – 4) = *step*(2 · 1 + 3 · 1 – 4) = *step*(1)
    = 1。'
- en: Because the label of the point is 0, the point is misclassified.
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因为点的标签是 0，所以点被错误分类。
- en: The perceptron error is the absolute value of the score. The score is 2*x*[1]
    + 3*x*[2] – 4 = 2 · 1 + 3 · 1 – 4 = 1, so the perceptron error is 1.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 感知器误差是得分的绝对值。得分为 2*x*[1] + 3*x*[2] – 4 = 2 · 1 + 3 · 1 – 4 = 1，因此感知器误差为 1。
- en: 'The weights of the model are 2, 3, and –4, and the coordinates of the point
    are (1, 1). The perceptron trick does the following:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的权重是 2、3 和 –4，点的坐标是 (1, 1)。感知器技巧执行以下操作：
- en: Replaces 2 with 2 – 0.01 · 1 = 1.99
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 2 替换为 2 – 0.01 · 1 = 1.99
- en: Replaces 3 with 3 – 0.01 · 1 = 2.99
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 3 替换为 3 – 0.01 · 1 = 2.99
- en: Replaces –4 with –1 – 0.01 · 1 = –4.01
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 –4 替换为 –1 – 0.01 · 1 = –4.01
- en: Thus, the new model is the one that makes the prediction *ŷ* = *step*(1.99*x*[1]
    + 2.99*x*[2] – 4.01).
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，新模型是预测 *ŷ* = *step*(1.99*x*[1] + 2.99*x*[2] – 4.01) 的模型。
- en: Note that at our point, the new prediction is *ŷ* = *step*(1.99*x*[1] + 2.99*x*[2]
    – 4.01) = *step*(0.97) = 0, which means the model still misclassifies the point.
    However, the new perceptron error is |1.99 · 1 + 2.99 · 1 – 4.01| = 0.97, which
    is smaller than 1, the previous error.
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，在我们当前的位置，新的预测是 *ŷ* = *step*(1.99*x*[1] + 2.99*x*[2] – 4.01) = *step*(0.97)
    = 0，这意味着模型仍然错误地分类了该点。然而，新的感知器误差是 |1.99 · 1 + 2.99 · 1 – 4.01| = 0.97，这小于之前的误差
    1。
- en: Exercise 5.3
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 5.3
- en: Perceptrons are particularly useful for building logical gates such as AND and
    OR.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器对于构建逻辑门（如 AND 和 OR）特别有用。
- en: 'Build a perceptron that models the AND gate. In other words, build a perceptron
    to fit the following dataset (where *x*[1], *x*[2] are the features and *y* is
    the label):'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个模拟 AND 门的感知器。换句话说，构建一个感知器来拟合以下数据集（其中 *x*[1]，*x*[2] 是特征，*y* 是标签）：
- en: '| *x*[1] | *x*[2] | *y*   |'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *x*[1] | *x*[2] | *y*   |'
- en: '| 0 | 0 | 0 |'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 0 | 0 | 0 |'
- en: '| 0 | 1 | 0 |'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 0 | 1 | 0 |'
- en: '| 1 | 0 | 0 |'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 1 | 0 | 0 |'
- en: '| 1 | 1 | 1 |'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 1 | 1 | 1 |'
- en: 'Similarly, build a perceptron that models the OR gate, given by the following
    dataset:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似地，构建一个感知器来模拟 OR 门，给定以下数据集：
- en: '| *x*[1] | *x*[2] | *y*   |'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *x*[1] | *x*[2] | *y*   |'
- en: '| 0 | 0 | 0 |'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 0 | 0 | 0 |'
- en: '| 0 | 1 | 1 |'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 0 | 1 | 1 |'
- en: '| 1 | 0 | 1 |'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 1 | 0 | 1 |'
- en: '| 1 | 1 | 1 |'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 1 | 1 | 1 |'
- en: 'Show that there is no perceptron that models the XOR gate, given by the following
    dataset:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 证明对于以下数据集，不存在模拟 XOR 门的感知器：
- en: '| *x*[1] | *x*[2] | *y*   |'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| *x*[1] | *x*[2] | *y*   |'
- en: '| 0 | 0 | 0 |'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 0 | 0 | 0 |'
- en: '| 0 | 1 | 1 |'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 0 | 1 | 1 |'
- en: '| 1 | 0 | 1 |'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 1 | 0 | 1 |'
- en: '| 1 | 1 | 0 |'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 1 | 1 | 0 |'
- en: Solution
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: For simplicity, we plot the data points in the figure that follows.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，我们在下面的图中绘制了数据点。
- en: '![](../Images/A-11.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-11.png)'
- en: Note that a perceptron classifier is precisely a line that would split the black
    and white dots in the above plots.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，感知器分类器恰好是上述图中将黑白点分开的线。
- en: For the AND and OR datasets, we can easily split the black and white points
    with a line, as seen next.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 AND 和 OR 数据集，我们可以很容易地用线分开黑白点，如以下所示。
- en: '![](../Images/A-21.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-21.png)'
- en: Many equations work for the line separating the AND dataset. We’ll pick the
    line with equation *x*[1] + *x*[2] – 1.5\. Thus, the perceptron that classifies
    this dataset makes the prediction *ŷ* = *step*(*x*[1] + *x*[2] – 1.5).
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 许多方程适用于分离 AND 数据集的线。我们将选择方程为 *x*[1] + *x*[2] – 1.5 的线。因此，对这一数据集进行分类的感知器做出的预测是
    *ŷ* = *step*(*x*[1] + *x*[2] – 1.5)。
- en: Similarly, many equations work for the OR dataset, and we pick the line with
    equation *x*[1] + *x*[2] – 0.5\. The equation for the prediction is *ŷ* = *step*(*x*[1]
    + *x*[2] – 0.5).
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似地，对于 OR 数据集，许多方程都适用，我们选择方程为 *x*[1] + *x*[2] – 0.5 的线。预测的方程是 *ŷ* = *step*(*x*[1]
    + *x*[2] – 0.5)。
- en: Notice that the dataset for XOR is impossible to separate using a single line.
    Thus, there is no perceptron model that perfectly fits the XOR dataset. However,
    a combination of perceptrons can separate this dataset. These are also called
    multilayer perceptrons, or neural networks, and we’ll see them in chapter 10\.
    If you’re curious, take a look at exercise 10.2.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，使用单条线无法分离 XOR 数据集。因此，没有感知器模型能够完美地拟合 XOR 数据集。然而，感知器的组合可以分离这个数据集。这些也被称为多层感知器，或神经网络，我们将在第
    10 章中看到它们。如果你好奇，可以看看练习 10.2。
- en: 'Chapter 6: A continuous approach to splitting points: Logistic classifiers'
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 6 章：分割点的连续方法：逻辑分类器
- en: Exercise 6.1
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 6.1
- en: A dentist has trained a logistic classifier on a dataset of patients to predict
    if they have a decayed tooth. The model has determined that the probability that
    a patient has a decayed tooth is
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 一位牙医在一个患者数据集上训练了一个逻辑分类器，以预测他们是否有蛀牙。模型确定患者有蛀牙的概率是
- en: '*σ*(*d* + 0.5*c* – 0.8),'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '*σ*(*d* + 0.5*c* – 0.8),'
- en: where
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '*d* is a variable that indicates whether the patient has had another decayed
    tooth in the past, and'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*d* 是一个变量，表示患者过去是否有过蛀牙，并且'
- en: '*c* is a variable that indicates whether the patient eats candy.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*c* 是一个变量，表示患者是否吃糖果。'
- en: For example, if a patient eats candy, then *c* = 1, and if they don’t, then
    *c* = 0\. What is the probability that a patient that eats candy and was treated
    for a decayed tooth last year has a decayed tooth today?
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果患者吃糖果，则 *c* = 1，如果不吃，则 *c* = 0。那么，一个既吃糖果又去年接受过蛀牙治疗的患者今天有蛀牙的概率是多少？
- en: Solution
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: If the patient eats candy, then *c* = 1\. If the patient was treated for tooth
    decay last year, then *d* = 1\. Thus, according to the model, the probability
    that the patient has a decayed tooth is
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果患者吃糖果，则 *c* = 1。如果患者去年接受了蛀牙治疗，则 *d* = 1。因此，根据模型，患者有蛀牙的概率是
- en: '*σ*(1 + 0.5 · 1 – 0.8) = *σ*(0.7) = 0.668.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '*σ*(1 + 0.5 · 1 – 0.8) = *σ*(0.7) = 0.668。'
- en: Exercise 6.2
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 6.2
- en: Consider the logistic classifier that assigns to the point (*x*[1], *x*[2])
    the prediction *ŷ* = *σ*(2*x*[1] + 3*x*[2] – 4), and the point *p* = (1, 1) with
    label 0.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑将预测 *ŷ* = *σ*(2*x*[1] + 3*x*[2] – 4) 分配给点 (*x*[1], *x*[2]) 的逻辑分类器，以及点 *p*
    = (1, 1) 的标签为 0。
- en: Calculate the prediction *ŷ* that the model gives to the point *p*.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算模型对点 *p* 的预测 *ŷ*。
- en: Calculate the log loss that the model produces at the point *p*.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算模型在点 *p* 处产生的对数损失。
- en: Use the logistic trick to obtain a new model that produces a smaller log loss.
    You can use *η* = 0.1 as the learning rate.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用逻辑技巧获得一个产生更小对数损失的新的模型。你可以使用 *η* = 0.1 作为学习率。
- en: Find the prediction given by the new model at the point *p*, and verify that
    the log loss obtained is smaller than the original.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到新模型在点 *p* 处的预测值，并验证得到的对数损失小于原始值。
- en: Solution
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: The prediction is *ŷ* = *σ*(2 · 1 + 3 · 1 – 4) = *σ*(1) = 0.731
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测值为 *ŷ* = *σ*(2 · 1 + 3 · 1 – 4) = *σ*(1) = 0.731
- en: The log loss is
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对数损失为
- en: '*log loss* = –*y* *ln* (*ŷ*) – (1 – *y*) *ln* (1 – *ŷ*)'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*log loss* = –*y* *ln* (*ŷ*) – (1 – *y*) *ln* (1 – *ŷ*)'
- en: = –0 *ln* (0.731) – (1 – 0) *ln* (1 – 0.731)
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: = –0 *ln* (0.731) – (1 – 0) *ln* (1 – 0.731)
- en: = 1.313.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: = 1.313。
- en: 'Recall that the perceptron trick for the logistic regression model with prediction
    *ŷ* = *σ*(*w*[1]*x*[1] + *w*[1]*x*[1] + *b*) gives us the following new weights:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回想一下，对于预测 *ŷ* = *σ*(*w*[1]*x*[1] + *w*[1]*x*[1] + *b*) 的逻辑回归模型，感知器技巧给出了以下新的权重：
- en: '*w*[1]*''* = *w*[1] + *η*(*y* – *ŷ*) *x*[1] for *i* = 1,2'
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[1]*''* = *w*[1] + *η*(*y* – *ŷ*) *x*[1] 对于 *i* = 1,2'
- en: '*b**''* = *b* + *η*(*y* – *ŷ*) for *i* = 1,2'
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*b**''* = *b* + *η*(*y* – *ŷ*) 对于 *i* = 1,2'
- en: 'These are the values to plug into the previous formulas:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些是插入到先前公式中的值：
- en: '*y* = 0'
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y* = 0'
- en: '*ŷ* = 0.731'
  id: totrans-238
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ŷ* = 0.731'
- en: '*w*[1] = 2'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[1] = 2'
- en: '*w*[2] = 3'
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[2] = 3'
- en: '*b* = –4'
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*b* = –4'
- en: '*η* = 0.1'
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*η* = 0.1'
- en: '*x*[1] = 1'
  id: totrans-243
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x*[1] = 1'
- en: '*x*[2] = 1'
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x*[2] = 1'
- en: 'We obtain the following new weights for our classifier:'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们得到了以下新的权重，用于我们的分类器：
- en: '*w*[1]'' = 2 + 0.1 · (0 – 0.731) · 1 = 1.9269'
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[1]'' = 2 + 0.1 · (0 – 0.731) · 1 = 1.9269'
- en: '*w*[2]'' = 3 + 0.1 · (0 – 0.731) · 1 = 2.9269'
  id: totrans-247
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[2]'' = 3 + 0.1 · (0 – 0.731) · 1 = 2.9269'
- en: '*b* = –4 + 0.1 · (0 – 0.731) = –4.0731'
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*b* = –4 + 0.1 · (0 – 0.731) = –4.0731'
- en: Thus, our new classifier is the one that makes the prediction *ŷ* = *σ*(1.9269*x*[1]
    + 2.9269*x*[2] – 4.0731).
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，我们的新分类器是做出预测 *ŷ* = *σ*(1.9269*x*[1] + 2.9269*x*[2] – 4.0731) 的那个。
- en: The prediction at the point *p* is *ŷ* =*σ*(1.9269 · 1 + 2.9269 · 1 – 4.0731)
    = 0.686\. Notice that because the label is 0, the prediction has improved from
    the original 0.731, to the actual 0.686.
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在点 *p* 处的预测是 *ŷ* =*σ*(1.9269 · 1 + 2.9269 · 1 – 4.0731) = 0.686。注意，因为标签是 0，预测值从原始的
    0.731 提高到了实际的 0.686。
- en: The log loss for this prediction is –*y* *ln*(*ŷ*) – (1 – *y*) *ln*(1 – *ŷ*)
    = –0 *ln*(0.686) – (1 – 0) *ln*(1 – 0.686) = 1.158\. Note that this is smaller
    than the original log loss of 1.313.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个预测的对数损失为 –*y* *ln*(*ŷ*) – (1 – *y*) *ln*(1 – *ŷ*) = –0 *ln*(0.686) – (1 –
    0) *ln*(1 – 0.686) = 1.158。注意，这个值小于原始的对数损失 1.313。
- en: Exercise 6.3
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 6.3
- en: Using the first model in exercise 6.2, construct a point for which the prediction
    is 0.8.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 使用第 6.2 节中的第一个模型，构建一个预测值为 0.8 的点。
- en: hint First find the score that will give a prediction of 0.8, and recall that
    the prediction is *ŷ* = *σ*(score).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：首先找到给出预测值为 0.8 的分数，并记住预测值是 *ŷ* = *σ*(分数)。
- en: Solution
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: First, we need to find a score such that *σ*(score) = 0.8\. This is equivalent
    to
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要找到一个分数，使得 *σ*(分数) = 0.8。这相当于
- en: '![](../Images/AppA_00_E04.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/AppA_00_E04.png)'
- en: Recall that for the point (*x*[1], *x*[2]), the score is 2*x*[1] + 3*x*[2] –
    4\. Many points (*x*[1], *x*[2]) satisfy that the score is 1.386, but in particular,
    let’s pick one in which *x*[2] = 0 for convenience. We need to solve the equation
    2*x*[1] + 3 · 0 – 4 = 1.386, which has as a solution, *x*[1] = 2.693\. Thus, a
    point that gives a prediction of 0.8 is the point (2.693, 0).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，对于点 (*x*[1], *x*[2])，分数是 2*x*[1] + 3*x*[2] – 4。许多点 (*x*[1], *x*[2]) 满足分数为
    1.386，但为了方便起见，我们特别选择一个 *x*[2] = 0 的点。我们需要解方程 2*x*[1] + 3 · 0 – 4 = 1.386，其解为 *x*[1]
    = 2.693。因此，给出预测值为 0.8 的点是 (2.693, 0)。
- en: 'Chapter 7: How do you measure classification models? Accuracy and its friends'
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第七章：如何衡量分类模型？准确率及其朋友
- en: Exercise 7.1
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7.1
- en: A video site has established that a particular user likes animal videos and
    absolutely nothing else. In the next figure, we can see the recommendations that
    this user got when logging in to the site.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 一个视频网站已经确定一个特定用户喜欢动物视频，而且其他什么也不喜欢。在下一张图中，我们可以看到当用户登录网站时收到的推荐。
- en: '![](../Images/A-31.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-31.png)'
- en: 'If this is all the data we have on the model, answer the following questions:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是我们对模型拥有的所有数据，请回答以下问题：
- en: What is the accuracy of the model?
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的准确率是多少？
- en: What is the recall of the model?
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的召回率是多少？
- en: What is the precision of the model?
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的精确率是多少？
- en: What is the *F*[1]-score of the model?
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的 *F*[1]-score 是多少？
- en: Would you say that this is a good recommendation model?
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会认为这是一个好的推荐模型吗？
- en: Solution
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: First, let’s write the confusion matrix. In this case, we label the videos that
    are about animals as *positive*, and the videos that are recommended as *predicted
    positive*.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们写出混淆矩阵。在这种情况下，我们将关于动物的视频标记为 *positive*，将推荐的视频标记为 *predicted positive*。
- en: There are four recommended videos. Out of them, three are about animals, which
    means they are good recommendations. The other one is not about animals, so it
    is a false positive.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有四个推荐视频。其中三个是关于动物的，这意味着它们是好的推荐。另一个不是关于动物的，所以它是假阳性。
- en: There are six videos that are not recommended. Out of them, two are about animals,
    which should have been recommended. Thus, they are false negatives. The other
    four are not about animals, so it was correct not to recommend them.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有六个不推荐的视频。其中两个是关于动物的，本应被推荐。因此，它们是假阴性。其他四个不是关于动物的，所以不推荐它们是正确的。
- en: 'Thus, the confusion matrix is the following:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，混淆矩阵如下：
- en: '|  | Predicted positive (recommended) | Predicted negative (not recommended)
    |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '|  | 预测阳性（推荐） | 预测阴性（不推荐） |'
- en: '| Positive (about animals) | 3 | 2 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 正面（关于动物） | 3 | 2 |'
- en: '| Negative (not about animals) | 1 | 4 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 负面（非关于动物） | 1 | 4 |'
- en: Now we can calculate the metrics.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算指标了。
- en: '![](../Images/AppA_03_E01.png)'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![](../Images/AppA_03_E01.png)'
- en: '![](../Images/AppA_03_E02.png)'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![](../Images/AppA_03_E02.png)'
- en: '![](../Images/AppA_03_E03.png)'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![](../Images/AppA_03_E03.png)'
- en: '![](../Images/AppA_03_E04.png)'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![](../Images/AppA_03_E04.png)'
- en: This is a subjective answer. A medical model with these metrics may not be good
    enough. However, if a recommendation model has decent accuracy, precision, and
    recall, it is considered a good model, because making a couple of mistakes in
    a recommendation model is not as crucial.
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个主观答案。具有这些指标的医学模型可能不够好。然而，如果一个推荐模型的准确度、精确度和召回率都相当不错，那么它被认为是一个好的模型，因为在推荐模型中犯几个错误并不那么关键。
- en: Exercise 7.2
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7.2
- en: 'Find the sensitivity and specificity of the medical model with the following
    confusion matrix:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 找出具有以下混淆矩阵的医学模型的灵敏度和特异性：
- en: '|  | Predicted sick | Predicted healthy |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '|  | 预测患病 | 预测健康 |'
- en: '| Sick | 120 | 22 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 患病 | 120 | 22 |'
- en: '| Healthy | 63 | 795 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 健康 | 63 | 795 |'
- en: Solution
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: The sensitivity is the number of correctly predicted sick people divided by
    the total number of sick people. This is 120/142= 0.845.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 灵敏度是正确预测的患病人数除以总患病人数。这是 120/142= 0.845。
- en: The specificity is the number of correctly predicted healthy people divided
    by the total number of healthy people. This is 795/858= 0.927.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 特异性是正确预测的健康人数除以总健康人数。这是 795/858= 0.927。
- en: Exercise 7.3
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7.3
- en: For the following models, determine which error is worse, a false positive or
    a false negative. Based on that, determine which of the two metrics, precision
    or recall, we should emphasize when evaluating each of the models.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下模型，确定哪种错误更严重，是假阳性还是假阴性。基于此，确定在评估每个模型时，我们应该强调哪个指标，是精确度还是召回率。
- en: A movie recommendation system that predicts whether a user will watch a movie.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个电影推荐系统，用于预测用户是否会观看电影。
- en: An image-detection model used in self-driving cars that detects whether an image
    contains a pedestrian.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在自动驾驶汽车中使用的图像检测模型，用于检测图像中是否包含行人。
- en: A voice assistant at home that predicts whether the user gave it an order.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个家庭语音助手，预测用户是否向它下达了命令。
- en: Solution
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: note In all of the following models, a false negative and a false positive are
    bad, and we want to avoid both of them. However, we show an argument for which
    one of the two is worse. These are all conceptual questions, so if you have a
    different idea, as long as you can argue it well, it is valid! These are the kind
    of discussions that arise in a team of data scientists, and it is important to
    have healthy opinions and arguments supporting each point of view.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在所有以下模型中，假阴性和假阳性都是不好的，我们希望避免两者。然而，我们展示了一个关于哪个更糟糕的论点。这些都是概念性问题，所以如果你有不同的想法，只要你能很好地论证，它就是有效的！这些是在数据科学家团队中出现的讨论类型，拥有健康观点和支撑每个观点的论据非常重要。
- en: In this model, we label the movies that the user wants to watch as positives.
    A false positive occurs any time we recommend a movie that the user doesn’t want
    to watch. A false negative occurs any time there is a movie that the user wants
    to watch, but we don’t recommend it. Which is worse, a false negative or a false
    positive? Because the homepage shows many recommendations and the user ignores
    most of them, this model has many false negatives that don’t affect the user experience
    much. However, if there is a great movie that the user would like to watch, it
    is crucial to recommend it to them. Therefore, in this model, a false negative
    is worse than a false positive, so we should evaluate this model using **recall**.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个模型中，我们将用户想要观看的电影标记为正面。任何我们推荐用户不想要观看的电影都称为假阳性。当有用户想要观看的电影，但我们没有推荐时，这种情况称为假阴性。哪种情况更糟，假阴性还是假阳性？因为主页显示了众多推荐，而用户通常忽略大部分，所以这个模型有很多假阴性，这对用户体验影响不大。然而，如果有一部用户非常想看的好电影，向他们推荐它至关重要。因此，在这个模型中，假阴性比假阳性更糟，所以我们应该使用**召回率**来评估这个模型。
- en: In this model, we label the existence of a pedestrian as a positive. A false
    positive occurs when there is no pedestrian, but the car thinks there is a pedestrian.
    A false negative occurs when the car doesn’t detect a pedestrian that is in front
    of the car. In the case of a false negative, the car may hit a pedestrian. In
    the case of a false positive, the car may brake unnecessarily, which may or may
    not lead to an accident. Although both are serious, it is much worse to hit a
    pedestrian. Therefore, in this model, a false negative is worse than a false positive,
    so we should evaluate this model using **recall**.
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个模型中，我们将行人的存在标记为正面。当没有行人，但汽车认为有行人时，这种情况称为假阳性。当汽车没有检测到汽车前方行人时，这种情况称为假阴性。在假阴性的情况下，汽车可能会撞到行人。在假阳性的情况下，汽车可能会不必要地刹车，这可能会导致或不会导致事故。尽管两者都很严重，但撞到行人更糟糕。因此，在这个模型中，假阴性比假阳性更糟，所以我们应该使用**召回率**来评估这个模型。
- en: In this model, we label a voice command as a positive. A false positive occurs
    when the user is not talking to the voice assistant, but the voice assistant responds.
    A false negative occurs when the user is talking to the voice assistant, but the
    voice assistant doesn’t respond. As a personal choice, I prefer to have to repeat
    to my voice assistant than to have her speak to me out of the blue. Thus, in this
    model, a false positive is worse than a false negative, so we should evaluate
    this model using **precision**.
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个模型中，我们将语音命令标记为正面。当用户没有与语音助手交谈，但语音助手响应时，这种情况称为假阳性。当用户与语音助手交谈，但语音助手没有响应时，这种情况称为假阴性。作为一个个人选择，我更喜欢重复对我的语音助手说话，而不是让她突然对我说话。因此，在这个模型中，假阳性比假阴性更糟，所以我们应该使用**精确度**来评估这个模型。
- en: Exercise 7.4
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7.4
- en: 'We are given the following models:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们给出了以下模型：
- en: A self-driving car model for detecting a pedestrian based on the image from
    the car’s camera
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个基于汽车摄像头图像检测行人的自动驾驶汽车模型
- en: A medical model for diagnosing a deadly illness based on the patient’s symptoms
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个基于患者症状诊断致命疾病的医学模型
- en: A recommendation system for movies based on the user’s previous movies watched
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个基于用户之前观看的电影推荐电影的推荐系统
- en: A voice assistant that determines whether the user needs assistance given the
    voice command
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个根据用户的语音命令确定用户是否需要帮助的语音助手
- en: A spam-detection model that determines whether an email is spam based on the
    words in the email
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个基于电子邮件中文字的垃圾邮件检测模型，用于判断一封电子邮件是否为垃圾邮件
- en: We are given the task of evaluating these models using *F*[β]-scores. However,
    we haven’t been given the values of *β* to use. What value of *β* would you use
    to evaluate each of the models?
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的任务是使用*F*[β]-分数来评估这些模型。然而，我们没有给出使用*β*的值。您会使用什么值的*β*来评估每个模型？
- en: Solution
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: Remember that for models in which precision is more important than recall, we
    use an *F*[β]-score with a small value of *β*. In contrast, for models in which
    recall is more important than precision, we use an *F*[β]-score with a large value
    of *β*.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，对于精度比召回率更重要的模型，我们使用小值的*β*的*F*[β]-分数。相比之下，对于召回率比精度更重要的模型，我们使用大值的*β*的*F*[β]-分数。
- en: note If you have different scores than this solution, that is completely OK,
    as long as you have an argument for which is more important between precision
    and recall, and for the value of *β* that you choose.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: note 如果你的得分与这个解决方案不同，那完全没问题，只要你有论据来说明精确度和召回率哪个更重要，以及你选择的 *β* 值。
- en: For the self-driving car and the medical models, recall is tremendously important
    because we want very few false negatives. Thus, I would use a large value of *β*,
    such as 4.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于自动驾驶汽车和医疗模型，召回率非常重要，因为我们希望很少出现误判。因此，我会使用一个较大的 *β* 值，例如 4。
- en: For the spam-detection model, precision is important, because we want very few
    false positives. Thus, I would use a small value of *β*, such as 0.25.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于垃圾邮件检测模型，精确度很重要，因为我们希望很少出现误报。因此，我会使用一个较小的 *β* 值，例如 0.25。
- en: For the recommendation system, recall is more important (see exercise 7.3),
    although precision also matters. Thus, I would use a large value of *β*, such
    as 2.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于推荐系统，召回率更重要（参见练习 7.3），尽管精确度也很重要。因此，我会使用一个较大的 *β* 值，例如 2。
- en: For the voice assistant, precision is more important, although recall also matters
    (see exercise 7.3). Thus, I would use a small value for *β*, such as 0.5.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于语音助手，精确度更重要，尽管召回率也很重要（参见练习 7.3）。因此，我会使用一个较小的 *β* 值，例如 0.5。
- en: '![](../Images/A-41.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/A-41.png)'
- en: 'Chapter 8: Using probability to its maximum: The naive Bayes model'
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第八章：充分利用概率：朴素贝叶斯模型
- en: Exercise 8.1
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 8.1
- en: For each pair of events A and B, determine whether they are independent or dependent.
    For (a) to (d), provide mathematical justification. For (e) and (f) provide verbal
    justification.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每一对事件 A 和 B，确定它们是独立的还是依赖的。对于 (a) 到 (d)，提供数学解释。对于 (e) 和 (f)，提供口头解释。
- en: 'Throwing three fair coins:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 抛掷三枚公平硬币：
- en: 'A: First one falls on heads. B: Third one falls on tails.'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A：第一次投掷正面朝上。B：第三次投掷反面朝上。
- en: 'A: First one falls on heads. B: There is an odd number of heads among the three
    throws.'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A：第一次投掷正面朝上。B：三次投掷中正面朝上的次数是奇数。
- en: 'Rolling two dice:'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 抛掷两枚骰子：
- en: 'A: First one shows a 1\. B: Second one shows a 2.'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A：第一次显示 1。B：第二次显示 2。
- en: 'A: First one shows a 3\. B: Second one shows a higher value than the first
    one.'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A：第一次显示 3。B：第二次显示的数值比第一次高。
- en: For the following, provide a verbal justification. Assume that for this problem,
    we live in a place with seasons.
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于以下内容，提供口头解释。假设对于这个问题，我们生活在一个有季节的地方。
- en: 'A: It’s raining outside. B: It’s Monday.'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A：外面在下雨。B：今天是星期一。
- en: 'A: It’s raining outside. B: It’s June.'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: A：外面在下雨。B：现在是六月。
- en: Solution
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: Solution
- en: Some of the following can be deduced by intuition. However, sometimes intuition
    fails when determining whether two events are independent. For this reason, unless
    the events are obviously independent, we’ll stick to checking whether two events
    A and B are independent if *P*(*A* ∩ *B*) = *P*(*A*) *P*(*B*).
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的一些内容可以通过直觉推断出来。然而，在确定两个事件是否独立时，有时直觉会失效。因此，除非事件显然是独立的，否则我们将坚持检查两个事件 A 和 B
    是否独立，如果 *P*(*A* ∩ *B*) = *P*(*A*) *P*(*B*)。
- en: Because A and B correspond to tossing different coins, they are independent
    events.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为 A 和 B 对应于抛掷不同的硬币，所以它们是独立事件。
- en: '![](../Images/AppA_08_Ea01.png) because flipping a fair coin results in two
    equally likely scenarios. For the calculation of *P*(*B*), we’ll use “h” for heads
    and “t” for tails. This way, the event “hth” corresponds to the first and third
    coin toss landing on heads and the second one landing on tails. Thus, if we throw
    three coins, the eight equally likely possibilities are {hhh, hht, hth, htt, thh,
    tht, tth, ttt}. ![](../Images/AppA_08_Ea02.png) because among the eight equally
    likely possibilities (hhh, hht, hth, htt, thh, tht, tth, ttt), only four of them
    have an odd number of heads, namely, {hhh, htt, tht, tth}. ![](../Images/AppA_08_Ea03.png)
    because among the eight possibilities, only two satisfy that the first one falls
    on heads, and there are an odd number of heads, namely, {hhh, htt}. ![](../Images/AppA_08_Ea04.png),
    so the events A and B are independent.'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![图片](../Images/AppA_08_Ea01.png) 因为公平硬币的翻转会产生两个等可能的情况。在计算 *P*(*B*) 时，我们将使用“h”代表正面，“t”代表反面。这样，事件“hth”对应于第一和第三次硬币投掷正面朝上，第二次投掷反面朝上。因此，如果我们抛掷三枚硬币，就有八种等可能的情况：{hhh,
    hht, hth, htt, thh, tht, tth, ttt}。![图片](../Images/AppA_08_Ea02.png) 因为在八种等可能的情况（hhh,
    hht, hth, htt, thh, tht, tth, ttt）中，只有四种有奇数个正面，即 {hhh, htt, tht, tth}。![图片](../Images/AppA_08_Ea03.png)
    因为在八种可能的情况中，只有两种满足第一次投掷正面朝上且正面朝上的次数是奇数，即 {hhh, htt}。![图片](../Images/AppA_08_Ea04.png)，因此事件
    A 和 B 是独立的。'
- en: Because A and B correspond to tossing different dice, they are independent events.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为A和B对应于掷不同的骰子，所以它们是独立事件。
- en: '![](../Images/AppA_08_Ea05.png), because it corresponds to tossing a die and
    obtaining a particular value. ![](../Images/AppA_08_Ea06.png) for the following
    reason. Notice that the 36 equally likely possibilities for the scores of the
    two dice are {11, 12, 13, …, 56, 66}. In six of these, the two dice show the same
    value. The remaining 30 correspond to 15 in which the first value is higher, and
    15 in which the second value is higher, by symmetry. Therefore, there are 15 scenarios
    in which the second die shows a higher value than the third one, so ![](../Images/AppA_08_Ea07.png).
    ![](../Images/AppA_08_Ea08.png) for the following reason. If the first die falls
    on 3, we have a total of six equally likely scenarios, namely, {31, 32, 33, 34,
    35, 36}. Out of these six, the second number is higher for three of them. Thus,
    ![](../Images/AppA_08_Ea09.png). Because *P*(*A*) *P*(*B*) ≠ *P*(*A* ∩ *B*), the
    events A and B are dependent.'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](../Images/AppA_08_Ea05.png)，因为它对应于掷骰子得到特定的值。![](../Images/AppA_08_Ea06.png)的原因如下。注意，两个骰子得分的36种等可能的可能性是
    {11, 12, 13, …, 56, 66}。在这其中，有六种情况两个骰子显示相同的值。剩下的30种对应于15种情况，其中第一个值更高，还有15种情况，第二个值更高，对称性使得如此。因此，有15种情况是第二个骰子的值比第三个骰子高，所以
    ![](../Images/AppA_08_Ea07.png)。![](../Images/AppA_08_Ea08.png)的原因如下。如果第一个骰子落在3上，我们总共有六种等可能的情况，即
    {31, 32, 33, 34, 35, 36}。在这六种情况中，有三个情况第二个数字更高。因此，![](../Images/AppA_08_Ea09.png)。因为
    *P*(*A*) *P*(*B*) ≠ *P*(*A* ∩ *B*)，事件A和B是相关的。'
- en: For this problem, we’ll make the assumption that A and B are independent, namely,
    that weather is not dependent on the day of the week. This is a fair assumption,
    given our knowledge of weather, but if we wanted to be surer, we could look at
    weather datasets and verify this by calculating the corresponding probabilities.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于这个问题，我们将假设A和B是独立的，也就是说，天气不依赖于星期几。这是一个合理的假设，鉴于我们对天气的了解，但如果我们想更确定，我们可以查看天气数据集并通过计算相应的概率来验证这一点。
- en: Because we’ve assumed that we live in a place with seasons, June is summer in
    the northern hemisphere and winter in the southern hemisphere. Depending on where
    we live, it may rain more in the winter or in the summer. Thus, we can assume
    that events A and B are dependent.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为我们已经假设我们生活在一个有季节变化的地方，所以在北半球六月是夏天，而在南半球是冬天。根据我们居住的地方，冬天可能比夏天下雨更多。因此，我们可以假设事件A和B是相关的。
- en: Exercise 8.2
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 练习8.2
- en: There is an office where we have to go regularly for some paperwork. This office
    has two clerks, Aisha and Beto. We know that Aisha works there three days a week,
    and Beto works the other two However, the schedules change every week, so we never
    know which three days Aisha is there, and which two days Beto is there.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个办公室，我们必须定期去那里办理一些文件工作。这个办公室有两个职员，Aisha和Beto。我们知道Aisha每周工作三天，而Beto工作剩下的两天。然而，每周的日程都会变化，所以我们永远不知道Aisha会在哪三天，Beto会在哪两天。
- en: If we show up on a random day to the office, what is the probability that Aisha
    is the clerk?
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们随机一天去办公室，Aisha是职员的概率是多少？
- en: We look from outside and notice that the clerk is wearing a red sweater, although
    we can’t tell who the clerk is. We’ve been going to that office a lot, so we know
    that Beto tends to wear red more often than Aisha. In fact, Aisha wears red one
    day out of three (one-third of the time), and Beto wears red one day out of two
    (half of the time).
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们从外面看，注意到职员穿着一件红色毛衣，尽管我们无法确定是哪位职员。我们经常去那个办公室，所以知道Beto比Aisha更倾向于穿红色。事实上，Aisha有三分之一的时间会穿红色，而Beto有二分之一的时间会穿红色。
- en: What is the probability that Aisha is the clerk, knowing that the clerk is wearing
    red today?
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们知道今天职员穿着红色，Aisha是职员的概率是多少？
- en: Solution
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'Let’s use the following notation for events:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为事件使用以下符号：
- en: 'A: the event that the clerk is Aisha'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A：职员是Aisha的事件
- en: 'B: The event that the clerk is Beto'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B：职员是Beto的事件
- en: 'R: The event that the clerk is wearing red'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R：职员穿着红色的事件
- en: Because Aisha works at the office three days and Beto works two days, the probability
    that Aisha is the clerk is ![](../Images/AppA_08_Eb01.png), or 60%. In addition,
    the probability that Beto is the clerk is ![](../Images/AppA_08_Eb02.png), or
    40%.
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为Aisha在办公室工作三天，Beto工作两天，所以Aisha是职员的概率是 ![](../Images/AppA_08_Eb01.png)，即60%。此外，Beto是职员的概率是
    ![](../Images/AppA_08_Eb02.png)，即40%。
- en: Intuitively, because Beto wears red more often than Aisha, we imagine that the
    probability that the clerk is Aisha is lower than in part a). Let’s check whether
    the math agrees with us. We know the clerk is wearing red, so we need to find
    the probability that the clerk is Aisha *knowing that* the clerk is wearing red.
    This is *P*(*A*|*R*).
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直觉上，因为贝托比艾莎更常穿红色，我们想象店员是艾莎的概率比部分 a) 中的概率低。让我们检查数学是否与我们一致。我们知道店员穿着红色，所以我们需要找到在店员穿着红色的情况下，店员是艾莎的概率。这是
    *P*(*A*|*R*).
- en: The probability that Aisha wears red is ![](../Images/AppA_08_Eb03a.png), so
    ![](../Images/AppA_08_Eb03b.png). The probability that Beto wears red is ![](../Images/AppA_08_Eb04a.png),
    so ![](../Images/AppA_08_Eb04b.png).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 艾莎穿红色的概率是 ![图片](../Images/AppA_08_Eb03a.png)，所以 ![图片](../Images/AppA_08_Eb03b.png)。贝托穿红色的概率是
    ![图片](../Images/AppA_08_Eb04a.png)，所以 ![图片](../Images/AppA_08_Eb04b.png)。
- en: We can use Bayes theorem to obtain
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用贝叶斯定理来获得
- en: '![](../Images/AppA_03_E05.png)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/AppA_03_E05.png)'
- en: A similar calculation shows that the probability that Beto is the clerk is ![](../Images/AppA_08_Ec01.png),
    or 50%.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 类似的计算表明，贝托是店员的可能性是 ![图片](../Images/AppA_08_Ec01.png)，或 50%。
- en: In effect, the probability that Aisha is the clerk is smaller than the one obtained
    in part a), so our intuition was right.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，艾莎是店员的可能性比部分 a) 中得到的小，所以我们的直觉是对的。
- en: Exercise 8.3
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 8.3
- en: The following is a dataset of patients who have tested positive or negative
    for COVID-19\. Their symptoms are cough (C), fever (F), difficulty breathing (B),
    and tiredness (T).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个数据集，其中包含已测试为阳性或阴性的 COVID-19 患者。他们的症状是咳嗽 (C)、发烧 (F)、呼吸困难 (B) 和疲劳 (T)。
- en: '|  | Cough (C) | Fever (F) | Difficulty breathing (B) | Tiredness (T) | Diagnosis
    |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '|  | 咳嗽 (C) | 发烧 (F) | 呼吸困难 (B) | 疲劳 (T) | 诊断 |'
- en: '| Patient 1 |  | X | X | X | Sick |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 1 |  | X | X | X | 病人 |'
- en: '| Patient 2 | X | X |  | X | Sick |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 2 | X | X |  | X | 病人 |'
- en: '| Patient 3 | X |  | X | X | Sick |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 3 | X |  | X | X | 病人 |'
- en: '| Patient 4 | X | X | X |  | Sick |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 4 | X | X | X |  | 病人 |'
- en: '| Patient 5 | X |  |  | X | Healthy |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 5 | X |  |  | X | 健康 |'
- en: '| Patient 6 |  | X | X |  | Healthy |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 6 |  | X | X |  | 健康 |'
- en: '| Patient 7 |  | X |  |  | Healthy |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 7 |  | X |  |  | 健康 |'
- en: '| Patient 8 |  |  |  | X | Healthy |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 8 |  |  |  | X | 健康 |'
- en: 'The goal of this exercise is to build a naive Bayes model that predicts the
    diagnosis from the symptoms. Use the naive Bayes algorithm to find the following
    probabilities:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的目的是构建一个朴素贝叶斯模型，从症状预测诊断。使用朴素贝叶斯算法找到以下概率：
- en: note For the following questions, the symptoms that are not mentioned are completely
    unknown to us. For example, if we know that the patient has a cough, but nothing
    is said about their fever, it does not mean the patient doesn’t have a fever.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：对于以下问题，未提及的症状对我们来说是完全未知的。例如，如果我们知道患者有咳嗽，但没有任何关于发烧的说明，并不意味着患者没有发烧。
- en: The probability that a patient is sick given that the patient has a cough
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在患者有咳嗽的情况下，患者生病的概率
- en: The probability that a patient is sick given that the patient is not tired
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在患者不疲劳的情况下，患者生病的概率
- en: The probability that a patient is sick given that the patient has a cough and
    a fever
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在患者有咳嗽和发烧的情况下，患者生病的概率
- en: The probability that a patient is sick given that the patient has a cough and
    a fever, but no difficulty breathing
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在患者有咳嗽和发烧，但没有呼吸困难的情况下，患者生病的概率
- en: Solution
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'For this problem, we have the following events:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个问题，我们有以下事件：
- en: 'C: the event that the patient has a cough'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C：患者有咳嗽的事件
- en: 'F: the event that the patient has a fever'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F：患者发烧的事件
- en: 'B: the event that the patient has difficulty breathing'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B：患者有呼吸困难的事件
- en: 'T: the event that the patient is tired'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T：患者疲劳的事件
- en: 'S: the event that the patient has been diagnosed as sick'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: S：患者被诊断为生病的事件
- en: 'H: the event that the patient has been diagnosed as healthy'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: H：患者被诊断为健康的事件
- en: Furthermore, *A*^c denotes the complement (opposite) of the event *A*. Thus,
    for example, *T*^c represents the event that the patient is not tired.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，*A*^c 表示事件 *A* 的补集（对立事件）。例如，*T*^c 表示患者不疲劳的事件。
- en: First, let’s calculate *P*(*S*) and *P*(*H*). Note that because the dataset
    contains four healthy and four sick patients, both of these (prior) probabilities
    are ![](../Images/frac_1-2.png), or 50%.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们计算 *P*(*S*) 和 *P*(*H*)。注意，因为数据集包含四个健康和四个生病的患者，这两个（先验）概率都是 ![图片](../Images/frac_1-2.png)，或
    50%。
- en: Because four patients have a cough and three of them are sick, ![](../Images/AppA_08_Ed01.png),
    or 75%.
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为有四个病人咳嗽，其中三个是生病的，![图片](../Images/AppA_08_Ed01.png)，即75%。
- en: 'Equivalently, we can use Bayes’ theorem in the following way: first, we calculate
    ![](../Images/AppA_08_Ed02.png) by noticing that there are four sick patients,
    and three of them have a cough. We also notice that ![](../Images/AppA_08_Ed03.png),
    because there are four healthy patients, and only one of them has a cough.'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 同样地，我们可以用以下方式应用贝叶斯定理：首先，我们注意到有四个生病的病人，其中三个有咳嗽。我们还注意到![图片](../Images/AppA_08_Ed03.png)，因为有四个健康病人，其中只有一个是咳嗽的。
- en: Now we can use the formula
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们可以使用公式
- en: '![](../Images/AppA_08_E01.png)'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](../Images/AppA_08_E01.png)'
- en: Because four patients have a cough and three of them are sick, ![](../Images/AppA_08_Ee01.png),
    or 33.3%.
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为有四个病人咳嗽，其中三个是生病的，![图片](../Images/AppA_08_Ee01.png)，即33.3%。
- en: We can also use Bayes’ theorem as before. Notice that ![](../Images/AppA_08_Ee02.png)
    because only one out of the four sick patients is not tired. Also, ![](../Images/AppA_08_Ee03.png),
    because two out of the four healthy patients are not tired.
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们也可以像以前一样使用贝叶斯定理。注意![图片](../Images/AppA_08_Ee02.png)，因为四个生病的病人中只有一个不累。同样，四个健康病人中有两个不累，![图片](../Images/AppA_08_Ee03.png)。
- en: By Bayes’ theorem,
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过贝叶斯定理，
- en: '![](../Images/AppA_08_E02.png)'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](../Images/AppA_08_E02.png)'
- en: '*C* ∩ *F* represents the event that the patient has a cough and a fever, so
    we need to calculate *P*(*S*|*C* ∩ *F*).'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*C* ∩ *F* 表示病人有咳嗽和发烧的事件，因此我们需要计算 *P*(*S*|*C* ∩ *F*)。'
- en: Recall from part a) that ![](../Images/AppA_08_Ef01.png) and ![](../Images/AppA_08_Ef02.png).
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 回想一下部分a)中的![图片](../Images/AppA_08_Ef01.png)和![图片](../Images/AppA_08_Ef02.png)。
- en: Now we need to calculate *P*(*F*|*S*) and *P*(*F*|*H*). Note that because there
    are four sick patients and three of them have a fever, ![](../Images/AppA_08_Ef03.png).
    Similarly, two out of the four healthy patients have a fever, so ![](../Images/AppA_08_Ef04.png).
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们需要计算 *P*(*F*|*S*) 和 *P*(*F*|*H*)。注意，因为有四个生病的病人，其中三个有发烧，![图片](../Images/AppA_08_Ef03.png)。同样，四个健康病人中有两个发烧，![图片](../Images/AppA_08_Ef04.png)。
- en: We are ready to use the naive Bayes algorithm to estimate the probability that
    the patient is sick given that they have a cough and fever. Using the formula
    in the section “What about two words? The naive Bayes algorithm” in chapter 8,
    we get
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们现在可以使用朴素贝叶斯算法来估计在病人咳嗽和发烧的情况下他们生病的概率。使用第8章“关于两个单词？朴素贝叶斯算法”部分中的公式，我们得到
- en: '![](../Images/AppA_08_E03.png)'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](../Images/AppA_08_E03.png)'
- en: For this exercise we need to find *P*(*S*|*C* ∩ *F* ∩ *B*^c)
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于这个练习，我们需要找到 *P*(*S*|*C* ∩ *F* ∩ *B*^c)
- en: Note that because there are four sick patients and only one of them has no difficulty
    breathing, ![](../Images/AppA_08_Eg01.png). Similarly, there are four healthy
    patients and three of them have no difficulty breathing, so ![](../Images/AppA_08_Eg02.png).
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，因为有四个生病的病人，其中只有一个是无呼吸困难，![图片](../Images/AppA_08_Eg01.png)。同样，有四个健康病人，其中三个无呼吸困难，![图片](../Images/AppA_08_Eg02.png)。
- en: As before, we can use the naive Bayes algorithm.
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 和以前一样，我们可以使用朴素贝叶斯算法。
- en: '![](../Images/AppA_08_E04.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/AppA_08_E04.png)'
- en: 'Chapter 9: Splitting data by asking questions: Decision trees'
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第9章：通过提问分割数据：决策树
- en: Exercise 9.1
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 9.1
- en: In the following spam-detection decision tree model, determine whether an email
    from your mom with the subject line “Please go to the store, there’s a sale,”
    will be classified as spam.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下垃圾邮件检测决策树模型中，确定来自你妈妈的标题为“请去商店，有促销活动”的电子邮件是否会被分类为垃圾邮件。
- en: '![](../Images/A-51.png)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/A-51.png)'
- en: Solution
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: First we check whether the sender is unknown. Because the sender is our mom,
    the sender is not unknown. Thus, we take the branch on the right. We must check
    whether the email contains the word “sale.” The email contains the word “sale,”
    so the classifier (incorrectly) classifies it as spam.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们检查发送者是否未知。因为发送者是我们的妈妈，所以发送者不是未知的。因此，我们选择右边的分支。我们必须检查电子邮件是否包含单词“sale”。电子邮件确实包含单词“sale”，所以分类器（错误地）将其分类为垃圾邮件。
- en: Exercise 9.2
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 9.2
- en: 'Our goal is to build a decision tree model to determine whether credit card
    transactions are fraudulent. We use the dataset of credit card transactions below,
    with the following features:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是构建一个决策树模型来决定信用卡交易是否欺诈。我们使用以下信用卡交易数据集，具有以下特征：
- en: '**Value**: value of the transaction.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**值**：交易的价值。'
- en: '**Approved vendor**: the credit card company has a list of approved vendors.
    This variable indicates whether the vendor is in this list.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批准的供应商**：信用卡公司有一份批准的供应商名单。这个变量表示供应商是否在这个名单上。'
- en: '|  | Value | Approved vendor | Fraudulent |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '|  | 值 | 已批准的供应商 | 欺诈 |'
- en: '| Transaction 1 | $100 | Not approved | Yes |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 交易 1 | $100 | 未批准 | 是 |'
- en: '| Transaction 2 | $100 | Approved | No |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| 交易 2 | $100 | 已批准 | 否 |'
- en: '| Transaction 3 | $10,000 | Approved | No |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 交易 3 | $10,000 | 已批准 | 否 |'
- en: '| Transaction 4 | $10,000 | Not approved | Yes |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| 交易 4 | $10,000 | 未批准 | 是 |'
- en: '| Transaction 5 | $5,000 | Approved | Yes |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| 交易 5 | $5,000 | 已批准 | 是 |'
- en: '| Transaction 6 | $100 | Approved | No |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| 交易 6 | $100 | 已批准 | 否 |'
- en: 'Build the first node of the decision tree under the following specifications:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 根据以下规范构建决策树的第一节点：
- en: Using the Gini impurity index
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用基尼不纯度指数
- en: Using entropy
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用熵
- en: Solution
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: In both cases, the best split is obtained using the Approved vendor feature,
    as in the next image.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，最佳分割是通过使用已批准的供应商特征获得的，如下一图所示。
- en: '![](../Images/A-70.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-70.png)'
- en: Let’s call the transactions *T*[1], *T*[2], *T*[3], *T*[4], *T*[5], and *T*[6].
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们称交易为 *T*[1], *T*[2], *T*[3], *T*[4], *T*[5], 和 *T*[6]。
- en: 'First, let’s look at all the following splits we can make. The split using
    Approved vendor is easy, because this is a categorical variable with two categories.
    The Value column is more complicated—we can use it to split the data in two possible
    ways. One is when the cutoff is some value between $100 and $5,000, and the other
    one when it is some value between $5,000 and $10,000\. To summarize, these are
    all the possible splits:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看我们可以做出的所有以下分割。使用已批准的供应商进行分割是容易的，因为这是一个有两个类别的分类变量。值列更复杂——我们可以用它以两种可能的方式分割数据。一种是在
    $100 和 $5,000 之间的某个值作为截止值，另一种是在 $5,000 和 $10,000 之间的某个值作为截止值。总结一下，这些都是所有可能的分割：
- en: '**Value 1**: where the cutoff value is between $100 and $5,000\. The two classes
    here are {*T*[1], *T*[2], *T*[6]} and {*T*[3], *T*[4], *T*[5]}.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**值 1**：其中截止值介于 $100 和 $5,000 之间。这里的两个类别是 {*T*[1], *T*[2], *T*[6]} 和 {*T*[3],
    *T*[4], *T*[5]}。'
- en: '**Value 2**: where the cutoff value is some value between $5,000 and $10,000\.
    The two classes here are {*T*[1], *T*[2], *T*[5], *T*[6]} and {*T*[3], *T*[4]}.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**值 2**：其中截止值是介于 $5,000 和 $10,000 之间的某个值。这里的两个类别是 {*T*[1], *T*[2], *T*[5],
    *T*[6]} 和 {*T*[3], *T*[4]}。'
- en: '**Approved vendor**: the two classes are “approved” and “not approved,” or
    equivalently, {*T*[2], *T*[3], *T*[5], *T*[6]} and {*T*[1], *T*[4]}.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**已批准的供应商**：两个类别是“已批准”和“未批准”，或者等价地，{*T*[2], *T*[3], *T*[5], *T*[6]} 和 {*T*[1],
    *T*[4]}。'
- en: 'Let’s calculate the Gini impurity index for each one of the following four
    splits:'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们计算以下四个分割中的每个分割的基尼不纯度指数：
- en: '**Value 1**: cutoff value between $100 and $5,000'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**值 1**：介于 $100 和 $5,000 之间的截止值'
- en: Note that for the first class {*T*[1], *T*[2], *T*[6]}, the labels in the Fraudulent
    column are {“yes”, “no”, “no”}. The Gini impurity index of this split is ![](../Images/AppA_09_E01.png).
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，对于第一类 {*T*[1], *T*[2], *T*[6]}，欺诈列中的标签是 {“是”， “否”， “否”}。这个分割的基尼不纯度指数是 ![](../Images/AppA_09_E01.png)。
- en: Note that for the second class {*T*[3], *T*[4], *T*[5]}, the labels in the Fraudulent
    column are {“no”, “yes”, “yes”}. The Gini impurity index of this split is ![](../Images/AppA_09_E02.png).
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，对于第二类 {*T*[3], *T*[4], *T*[5]}，欺诈列中的标签是 {“否”， “是”， “是”}。这个分割的基尼不纯度指数是 ![](../Images/AppA_09_E02.png)。
- en: Thus, the weighted Gini impurity index for this split is ![](../Images/AppA_09_E03.png).
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，这个分割的加权基尼不纯度指数是 ![](../Images/AppA_09_E03.png)。
- en: '**Value 2**: cutoff value between $5,000 and $10,000'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**值 2**：介于 $5,000 和 $10,000 之间的截止值'
- en: For the first class {*T*[1], *T*[2], *T*[5], *T*[6]}, the labels in the Fraudulent
    column are {“yes”, “no”, “yes”, “no”}. The Gini impurity index of this split is
    ![](../Images/AppA_09_E04.png).
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于第一类 {*T*[1], *T*[2], *T*[5], *T*[6]}，欺诈列中的标签是 {“是”， “否”， “是”， “否”}。这个分割的基尼不纯度指数是
    ![](../Images/AppA_09_E04.png)。
- en: Note that for the second class {*T*[3], *T*[4]}, the labels in the Fraudulent
    column are {“no”, “yes”}. The Gini impurity index of this split is ![](../Images/AppA_09_E05.png).
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，对于第二类 {*T*[3], *T*[4]}，欺诈列中的标签是 {“否”， “是”}。这个分割的基尼不纯度指数是 ![](../Images/AppA_09_E05.png)。
- en: Thus, the weighted Gini impurity index for this split is ![](../Images/AppA_09_E06.png)*.*
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，这个分割的加权基尼不纯度指数是 ![](../Images/AppA_09_E06.png)*.*
- en: 'Approved vendor:'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 已批准的供应商：
- en: For the first class {*T*[2], *T*[3], *T*[5], *T*[6]}, the labels in the Fraudulent
    column are {“no”, “no”, “yes,” “no”}. The Gini impurity index of this split is
    ![](../Images/AppA_09_E07.png).
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于第一类 {*T*[2], *T*[3], *T*[5], *T*[6]}，欺诈列中的标签是 {“否”， “否”， “是”， “否”}。这个分割的基尼不纯度指数是
    ![](../Images/AppA_09_E07.png)。
- en: For the second class {*T*[1], *T*[4]}, the labels in the Fraudulent column are
    {“yes”, “yes”}. The Gini impurity index of this split is 1 – 1² = 0.
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于第二类 {*T*[1], *T*[4]}，欺诈列中的标签是 {“是”， “是”}。这个分割的基尼不纯度指数是 1 – 1² = 0。
- en: Thus, the weighted Gini impurity index for this split is ![](../Images/AppA_09_E08.png).
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，这个分割的加权基尼不纯度指数为 ![图片](../Images/AppA_09_E08.png)。
- en: Notice that out of these three values, the lowest is 0.25, corresponding to
    the Approved vendor column. This implies that the best way to split this data
    is using the Approved vendor feature.
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意到这三个值中，最低的是 0.25，对应于“批准的供应商”列。这意味着分割这些数据的最佳方式是使用“批准的供应商”特征。
- en: For this part, we’ve done most of the heavy lifting already. We’ll follow the
    same procedure as in part a), except calculating the entropy at each stage instead
    of the Gini impurity index.
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于这部分，我们已经做了大部分繁重的工作。我们将遵循与部分 a) 相同的程序，只是在每个阶段计算熵而不是基尼不纯度指数。
- en: '**Value 1**: cutoff value between $100 and $5,000'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**值 1**：$100 和 $5,000 之间的截断值'
- en: The entropy of the set {“yes”, “no”, “no”} is ![](../Images/AppA_09_E09.png).
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 集合 {“是”，“否”，“否”} 的熵为 ![图片](../Images/AppA_09_E09.png)。
- en: The entropy of the set {“no”, “yes”, “yes”} is also ![](../Images/AppA_09_E10.png).
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 集合 {“否”，“是”，“是”} 的熵也是 ![图片](../Images/AppA_09_E10.png)。
- en: Thus, the weighted entropy for this split is ![](../Images/AppA_09_E11.png).
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，这个分割的加权熵为 ![图片](../Images/AppA_09_E11.png)。
- en: '**Value 2**: cutoff value between $5,000 and $10,000'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**值 2**：$5,000 和 $10,000 之间的截断值'
- en: The entropy of the set {“yes”, “no”, “yes”, “no”} is ![](../Images/AppA_09_E12.png).
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 集合 {“是”，“否”，“是”，“否”} 的熵为 ![图片](../Images/AppA_09_E12.png)。
- en: The entropy of the set {“no”, “yes”} is ![](../Images/AppA_09_E13.png).
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 集合 {“否”，“是”} 的熵为 ![图片](../Images/AppA_09_E13.png)。
- en: Thus, the weighted entropy for this split is ![](../Images/AppA_09_E14.png).
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，这个分割的加权熵为 ![图片](../Images/AppA_09_E14.png)。
- en: 'Approved vendor:'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批准的供应商：
- en: The entropy of the set {“no”, “no”, “yes”, “no”} is ![](../Images/AppA_09_E15.png).
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 集合 {“否”，“否”，“是”，“否”} 的熵为 ![图片](../Images/AppA_09_E15.png)。
- en: The entropy of the set {“yes”, “yes”} is ![](../Images/AppA_09_E16.png).
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 集合 {“是”，“是”} 的熵为 ![图片](../Images/AppA_09_E16.png)。
- en: Thus, the weighted entropy for this split is ![](../Images/AppA_09_E17.png).
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，这个分割的加权熵为 ![图片](../Images/AppA_09_E17.png)。
- en: Notice that among these three, the smallest entropy is 0.541, corresponding
    to the Approved vendor column. Thus, the best way to split this data is, again,
    using the Approved vendor feature.
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意到在这些中，最小的熵是 0.541，对应于“批准的供应商”列。因此，再次分割这些数据的最佳方式仍然是使用“批准的供应商”特征。
- en: Exercise 9.3
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 9.3
- en: A dataset of patients who have tested positive or negative for COVID-19 follows.
    Their symptoms are cough (C), fever (F), difficulty breathing (B), and tiredness
    (T).
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个患者数据集，这些患者已检测出 COVID-19 的阳性或阴性。他们的症状是咳嗽 (C)、发热 (F)、呼吸困难 (B) 和疲劳 (T)。
- en: '|  | Cough (C) | Fever (F) | Difficulty breathing (B) | Tiredness (T) | Diagnosis
    |'
  id: totrans-456
  prefs: []
  type: TYPE_TB
  zh: '|  | 咳嗽 (C) | 发热 (F) | 呼吸困难 (B) | 疲劳 (T) | 诊断 |'
- en: '| Patient 1 |  | X | X | X | Sick |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 1 |  | X | X | X | 病人 |'
- en: '| Patient 2 | X | X |  | X | Sick |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 2 | X | X |  | X | 病人 |'
- en: '| Patient 3 | X |  | X | X | Sick |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 3 | X |  | X | X | 病人 |'
- en: '| Patient 4 | X | X | X |  | Sick |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 4 | X | X | X |  | 病人 |'
- en: '| Patient 5 | X |  |  | X | Healthy |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 5 | X |  |  | X | 健康 |'
- en: '| Patient 6 |  | X | X |  | Healthy |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 6 |  | X | X |  | 健康 |'
- en: '| Patient 7 |  | X |  |  | Healthy |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 7 |  | X |  |  | 健康 |'
- en: '| Patient 8 |  |  |  | X | Healthy |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| 患者编号 8 |  |  |  | X | 健康 |'
- en: Using accuracy, build a decision tree of height 1 (a decision stump) that classifies
    this data. What is the accuracy of this classifier on the dataset?
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 使用准确率，构建一个高度为 1 的决策树（决策树桩），用于分类这些数据。这个分类器在数据集上的准确率是多少？
- en: Solution
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案
- en: Let’s call the patients *P*[1] up to *P*[8]. The sick patients will be denoted
    by “s,” and the healthy ones by “h.”
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们称患者为 *P*[1] 到 *P*[8]。病人将用“s”表示，健康的人用“h”表示。
- en: First notice that the first split can be any of the four features C, F, B, and
    T. Let’s first calculate the accuracy of the classifier obtained by splitting
    the data on feature C, namely, the classifier we build based on the question,
    “Does the patient have a cough?”
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 首先注意到第一次分割可以是四个特征 C、F、B 和 T 中的任何一个。让我们首先计算基于特征 C 分割数据的分类器准确率，即基于问题“患者是否有咳嗽？”构建的分类器。
- en: 'Splitting based on the C feature:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 C 特征的分割：
- en: 'Patients with a cough: {*P*[2], *P*[3], *P*[4], *P*[5]}. Their labels are {*s*,
    *s*, *s*, *h*}.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有咳嗽的患者：{*P*[2], *P*[3], *P*[4], *P*[5]}。他们的标签是 {*s*, *s*, *s*, *h*}。
- en: 'Patients without a cough: {*P*[1], *P*[6], *P*[7], *P*[8]} . Their labels are
    {*s*, *h*, *h*, *h*}.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无咳嗽的患者：{*P*[1], *P*[6], *P*[7], *P*[8]}。他们的标签是 {*s*, *h*, *h*, *h*}。
- en: Looking at this, we can see that the most accurate classifier (only based on
    the C feature) is the one that classifies every person with a cough as sick and
    every person without a cough as healthy. This classifier correctly classifies
    six out of the eight patients (three sick and three healthy), so its accuracy
    is 6/8, or 75%.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 看这个，我们可以看到最准确的分类器（仅基于 C 特征）是将所有咳嗽的人分类为病态，而没有咳嗽的人分类为健康的分类器。这个分类器正确地将八名患者中的六名（三名病态和三名健康）分类，因此其准确率为
    6/8，即 75%。
- en: Now, let’s follow the same procedure with the other three features.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们用同样的方法处理其他三个特征。
- en: 'Splitting based on the F feature:'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 F 特征进行分割：
- en: 'Patients with a fever: {*P*[1], *P*[2], *P*[4], *P*[6], *P*[7]}. Their labels
    are {*s*, *s*, *s*, *h*, *h*}.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发烧的病人：{*P*[1], *P*[2], *P*[4], *P*[6], *P*[7]}. 他们的标签是 {*s*, *s*, *s*, *h*,
    *h*}.
- en: 'Patients without a fever: {*P*[3], *P*[5], *P*[8]}. Their labels are {*s*,
    *h*, *h*}.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无发烧的病人：{*P*[3], *P*[5], *P*[8]}. 他们的标签是 {*s*, *h*, *h*}.
- en: Looking at this, we can see that the most accurate classifier (only based on
    the F feature) is the one that classifies every patient with a fever as sick and
    every patient without a fever as healthy. This classifier correctly classifies
    five out of the eight patients (three sick and two healthy), so its accuracy is
    5/8, or 62.5%.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 看这个，我们可以看到最准确的分类器（仅基于 F 特征）是将所有发烧的患者分类为病态，而没有发烧的患者分类为健康的分类器。这个分类器正确地将八名患者中的五名（三名病态和两名健康）分类，因此其准确率为
    5/8，即 62.5%。
- en: 'Splitting based on the B feature:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 B 特征进行分割：
- en: 'Patients showing difficulty breathing: {*P*[1], *P*[3], *P*[4], *P*[5]}. Their
    labels are {*s*, *s*, *s*, *h*}.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表现出呼吸困难的患者：{*P*[1], *P*[3], *P*[4], *P*[5]}. 他们的标签是 {*s*, *s*, *s*, *h*}.
- en: 'Patients not showing difficulty breathing: {*P*[2], *P*[6], *P*[7], *P*[8]}.
    Their labels are {*s*, *h*, *h*, *h*}.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有表现出呼吸困难的患者：{*P*[2], *P*[6], *P*[7], *P*[8]}. 他们的标签是 {*s*, *h*, *h*, *h*}.
- en: Looking at this, we can see that the most accurate classifier (based only on
    the B feature) is the one that classifies every patient showing difficulty breathing
    as sick and every patient not showing difficulty breathing as healthy. This classifier
    correctly classifies six out of the eight patients (three sick and three healthy),
    so its accuracy is 6/8, or 75%.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 看这个，我们可以看到最准确的分类器（仅基于 B 特征）是将所有表现出呼吸困难的患者分类为病态，而没有表现出呼吸困难的患者分类为健康的分类器。这个分类器正确地将八名患者中的六名（三名病态和三名健康）分类，因此其准确率为
    6/8，即 75%。
- en: 'Splitting based on the T feature:'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 T 特征进行分割：
- en: 'Patients that are tired: {*P*[1], *P*[2], *P*[3], *P*[5], *P*[8]}. Their labels
    are {*s*, *s*, *s*, *h*, *h*}.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 疲劳的病人：{*P*[1], *P*[2], *P*[3], *P*[5], *P*[8]}. 他们的标签是 {*s*, *s*, *s*, *h*,
    *h*}.
- en: 'Patients that are not tired: {*P*[4], *P*[5], *P*[7]}. Their labels are {*s*,
    *h*, *h*}.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无疲劳的病人：{*P*[4], *P*[5], *P*[7]}. 他们的标签是 {*s*, *h*, *h*}.
- en: Looking at this, we can see that the most accurate classifier (based only on
    the F feature) is the one that classifies every tired patient as sick and every
    patient that is not tired as healthy. This classifier correctly classifies five
    out of the eight patients (three sick and two healthy), so its accuracy is 5/8,
    or 62.5%.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 看这个，我们可以看到最准确的分类器（仅基于 F 特征）是将所有疲劳的病人分类为病态，而没有疲劳的病人分类为健康的分类器。这个分类器正确地将八名患者中的五名（三名病态和两名健康）分类，因此其准确率为
    5/8，即 62.5%。
- en: 'Note that the two features that give us the best accuracy are C (cough) and
    B (difficulty breathing). The decision tree will pick one of these at random.
    Let’s pick the first one, C. After we split the data using the C feature, we obtain
    the following two datasets:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，给我们带来最佳准确率的两个特征是 C（咳嗽）和B（呼吸困难）。决策树将随机选择这两个中的一个。让我们选择第一个，C。使用 C 特征分割数据后，我们得到以下两个数据集：
- en: 'Patients with a cough: {*P*[2], *P*[3], *P*[4], *P*[5]}. Their labels are {*s*,
    *s*, *s*, *h*}.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有咳嗽的病人：{*P*[2], *P*[3], *P*[4], *P*[5]}. 他们的标签是 {*s*, *s*, *s*, *h*}.
- en: 'Patients without a cough: {*P*[1], *P*[6], *P*[7], *P*[8]}. Their labels are
    {*s*, *h*, *h*, *h*}.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无咳嗽的病人：{*P*[1], *P*[6], *P*[7], *P*[8]}. 他们的标签是 {*s*, *h*, *h*, *h*}.
- en: This gives us our tree of depth 1 that classifies the data with a 75% accuracy.
    The tree is depicted in the next figure.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们提供了一个深度为 1 的树，该树以 75% 的准确率对数据进行分类。该树在下一张图中展示。
- en: '![](../Images/A-71.png)'
  id: totrans-490
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-71.png)'
- en: 'Chapter 10: Combining building blocks to gain more power: Neural networks'
  id: totrans-491
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 10 章：组合构建块以获得更多力量：神经网络
- en: Exercise 10.1
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 10.1
- en: The following image shows a neural network in which all the activations are
    sigmoid functions.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个所有激活都是Sigmoid函数的神经网络。
- en: '![](../Images/A-81.png)'
  id: totrans-494
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-81.png)'
- en: What would this neural network predict for the input (1,1)?
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 这个神经网络会对输入(1,1)做出什么预测？
- en: Solution
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'Let’s call the outputs of the middle nodes *η*[1] and *η*[2]. These are calculated
    as follows:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们称中间节点的输出为*η*[1]和*η*[2]。这些计算如下：
- en: '*h*[1] = *σ*(1 · *x*[1] – 2 · *x*[2] – 1)'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '*h*[1] = *σ*(1 · *x*[1] – 2 · *x*[2] – 1)'
- en: '*h*[2] =*σ*(–1 · *x*[1] + 3 · *x*[2] – 1)'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: '*h*[2] =*σ*(–1 · *x*[1] + 3 · *x*[2] – 1)'
- en: 'Plugging in *x*[1] = 1 and *x*[2] = 1, we get the following:'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 将*x*[1] = 1和*x*[2] = 1代入，我们得到以下结果：
- en: '*h*[1] = *σ*(–2) = 0.119'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '*h*[1] = *σ*(–2) = 0.119'
- en: '*h*[2] = *σ*(1) = 0.731'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '*h*[2] = *σ*(1) = 0.731'
- en: The final layer is
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 最终层是
- en: '*ŷ* = *σ*(–1 · *h*[1] + 2 · *h*[2] + 1).'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: '*ŷ* = *σ*(–1 · *h*[1] + 2 · *h*[2] + 1).'
- en: Replacing the values previously obtained for *h*[1] and *h*[2], we get
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 用之前得到的*h*[1]和*h*[2]的值替换，我们得到
- en: '*ŷ* = *σ*(–0.119 + 2 · 0.731 + 1) = *σ*(2.343) = 0.912.'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '*ŷ* = *σ*(–0.119 + 2 · 0.731 + 1) = *σ*(2.343) = 0.912.'
- en: Thus, the output of the neural network is 0.912.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，神经网络的输出是0.912。
- en: Exercise 10.2
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 练习10.2
- en: 'As we learned in exercise 5.3, it is impossible to build a perceptron that
    mimics the XOR gate. In other words, it is impossible to fit the following dataset
    with a perceptron and obtain 100% accuracy:'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在练习5.3中学到的，无法构建一个模仿XOR门的感知器。换句话说，无法使用感知器拟合以下数据集并获得100%的准确率：
- en: '| *x*[1] | *x*[2] | *y*   |'
  id: totrans-510
  prefs: []
  type: TYPE_TB
  zh: '| *x*[1] | *x*[2] | *y*   |'
- en: '| 0 | 0 | 0 |'
  id: totrans-511
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 0 |'
- en: '| 0 | 1 | 1 |'
  id: totrans-512
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1 | 1 |'
- en: '| 1 | 0 | 1 |'
  id: totrans-513
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | 1 |'
- en: '| 1 | 1 | 0 |'
  id: totrans-514
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 0 |'
- en: This is because the dataset is not linearly separable. Using a neural network
    of depth 2, build a perceptron that mimics the XOR gate shown previously. As the
    activation functions, use the step function instead of the sigmoid function to
    get discrete outputs.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为数据集不是线性可分的。使用深度为2的神经网络，构建一个模仿之前展示的XOR门的感知器。作为激活函数，使用步进函数而不是sigmoid函数以获得离散输出。
- en: hint This will be hard to do using a training method; instead, try eyeballing
    the weights. Try (or search online how) to build an XOR gate using AND, OR, and
    NOT gates, and use the results of exercise 5.3 to help you.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：使用训练方法来做这个可能很难；相反，尝试通过观察权重来尝试。尝试（或在网上搜索如何）使用AND、OR和NOT门构建一个XOR门，并使用练习5.3的结果来帮助你。
- en: Solution
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: Note that the following combination of AND, OR, and NOT gates forms an XOR gate
    (where the NAND gate is the combination of an AND gate and a NOT gate).
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 注意以下AND、OR和NOT门的组合形成了一个XOR门（其中NAND门是AND门和NOT门的组合）。
- en: '![](../Images/A-91.png)'
  id: totrans-519
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-91.png)'
- en: The following truth table illustrates it.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的真值表说明了这一点。
- en: '| *x*[1] | *x*[2] | *h*[1] = *x*[1] *OR* *x*[2] | *h*[2] = *x*[1] *NAND* *x*[2]
    | *h*[1] *AND* *η*[2] | *x*[1] *XOR* *x*[2] |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
  zh: '| *x*[1] | *x*[2] | *h*[1] = *x*[1] *OR* *x*[2] | *h*[2] = *x*[1] *NAND* *x*[2]
    | *h*[1] *AND* *η*[2] | *x*[1] *XOR* *x*[2] |'
- en: '| 0 | 0 | 0 | 1 | 0 | 0 |'
  id: totrans-522
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 0 | 1 | 0 | 0 |'
- en: '| 0 | 1 | 1 | 1 | 1 | 1 |'
  id: totrans-523
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1 | 1 | 1 | 1 | 1 |'
- en: '| 1 | 0 | 1 | 1 | 1 | 1 |'
  id: totrans-524
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | 1 | 1 | 1 | 1 |'
- en: '| 1 | 1 | 1 | 0 | 0 | 0 |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 1 | 0 | 0 | 0 |'
- en: As we did in exercise 5.3, here are perceptrons that mimic the OR, NAND, and
    AND gates. The NAND gate is obtained by negating all the weights in the AND gate.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在练习5.3中所做的那样，这里有一些感知器，它们模仿了OR、NAND和AND门。NAND门是通过取AND门中所有权重的反得到。
- en: '![](../Images/A-101.png)'
  id: totrans-527
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-101.png)'
- en: Joining these together, we get the neural network shown in the next figure.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 将这些组合在一起，我们得到下一张图中所示的神经网络。
- en: '![](../Images/A-112.png)'
  id: totrans-529
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-112.png)'
- en: I encourage you to verify that this network does indeed mimic the XOR logic
    gate. This is done by inputting the four vectors (0,0), (0,1), (1,0), (1,1) through
    the network and verifying that the outputs are 0, 1, 1, 0.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你验证这个网络确实模仿了XOR逻辑门。这是通过将四个向量(0,0)、(0,1)、(1,0)、(1,1)输入网络并验证输出为0、1、1、0来完成的。
- en: Exercise 10.3
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 练习10.3
- en: At the end of the section “A graphical representation of neural networks,” we
    saw that the neural network in figure 10.13 with the activation function doesn’t
    fit the dataset in table 10.1, because the point (1,1) is misclassified.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 在“神经网络图形表示”部分的结尾，我们看到了图10.13中的神经网络，由于激活函数的原因，它不适合表10.1中的数据集，因为点(1,1)被错误分类。
- en: Verify that this is the case.
  id: totrans-533
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证这是否是情况。
- en: Change the weights so that the neural network classifies every point correctly.
  id: totrans-534
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 改变权重，使神经网络能够正确分类每个点。
- en: Solution
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'For the point (*x*[a], *x*[b]) = (1, 1), the predictions are the following:'
  id: totrans-536
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于点(*x*[a]，*x*[b]) = (1, 1)，预测如下：
- en: '*C* = *σ*(6 · 1 + 10 · 1 – 15) = *σ*(1) = 0.731'
  id: totrans-537
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*C* = *σ*(6 · 1 + 10 · 1 – 15) = *σ*(1) = 0.731'
- en: '*F* = *σ*(10 · 1 + 6 · 1 – 15) = *σ*(1) = 0.731'
  id: totrans-538
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*F* = *σ*(10 · 1 + 6 · 1 – 15) = *σ*(1) = 0.731'
- en: '*ŷ* = *σ*(1 · 0.731 + 1 · 0.731 – 1.5) = *σ*(–0.39) = 0.404'
  id: totrans-539
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*ŷ* = *σ*(1 · 0.731 + 1 · 0.731 – 1.5) = *σ*(–0.39) = 0.404'
- en: Because the prediction is closer to 0 than to 1, the point is misclassified.
  id: totrans-540
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因为预测值更接近于0而不是1，所以这个点被错误分类。
- en: Reducing the bias in the final node to anything less than 2 · 0.731 = 1.461
    will do. For example, if this bias was 1.4, the prediction at the point (1,1)
    would be higher than 0.5\. As an exercise, I encourage you to verify that this
    new neural network correctly predicts the labels for the remaining points.
  id: totrans-541
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将最终节点的偏差降低到小于2 · 0.731 = 1.461 的任何值都可以。例如，如果这个偏差是1.4，那么在点（1,1）的预测值将高于0.5。作为一个练习，我鼓励你验证这个新的神经网络是否正确地预测了剩余点的标签。
- en: 'Chapter 11: Finding boundaries with style: Support vector machines and the
    kernel method'
  id: totrans-542
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第11章：以风格寻找边界：支持向量机和核方法
- en: Exercise 11.1
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.1
- en: (This exercise completes the calculation needed in the section “Distance error
    function.”)
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: （此练习完成了“距离误差函数”部分所需的计算。）
- en: Show that the distance between the lines with equations *w*[1]*x*[1] + *w*[2]*x*[2]
    + *b* = 1 and *w*[1]*x*[1] + *w*[2]*x*[2] + *b* = –1 is precisely ![](../Images/AppA_11_E01.png).
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 证明方程 *w*[1]*x*[1] + *w*[2]*x*[2] + *b* = 1 和 *w*[1]*x*[1] + *w*[2]*x*[2] + *b*
    = –1 的直线之间的距离恰好是 ![](../Images/AppA_11_E01.png)。
- en: '![](../Images/AppA_11_E00.png)'
  id: totrans-546
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/AppA_11_E00.png)'
- en: Solution
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'First, let us call the lines as follows:'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们这样称呼这些线：
- en: '*L*[1] is the line with equation *w*[1]*x*[1] + *w*[2]*x*[2] + *b* = 1.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*L*[1] 是方程 *w*[1]*x*[1] + *w*[2]*x*[2] + *b* = 1 的直线。'
- en: '*L*[2] is the line with equation *w*[1]*x*[1] + *w*[2]*x*[2] + *b* = –1.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*L*[2] 是方程 *w*[1]*x*[1] + *w*[2]*x*[2] + *b* = –1 的直线。'
- en: Note that we can rewrite the equation *w*[1]*x*[1] + *w*[2]*x*[2] + *b* = 0
    as ![](../Images/AppA_11_E02.png) with slope ![](../Images/AppA_11_E03.png). Any
    perpendicular to this line has slope ![](../Images/AppA_11_E04.png). In particular,
    the line with equation ![](../Images/AppA_11_E05.png) is perpendicular to both
    *L*[1] and *L*[2]. We’ll call this line *L*[3].
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们可以将方程 *w*[1]*x*[1] + *w*[2]*x*[2] + *b* = 0 重新写为 ![](../Images/AppA_11_E02.png)，其斜率为
    ![](../Images/AppA_11_E03.png)。任何与此线垂直的线的斜率为 ![](../Images/AppA_11_E04.png)。特别是，方程为
    ![](../Images/AppA_11_E05.png) 的线与 *L*[1] 和 *L*[2] 都垂直。我们将这条线称为 *L*[3]。
- en: 'Next, we solve for the points of intersection of *L*[3] with each of the lines
    *L*[1] and *L*[2]. The point of intersection of *L*[1] and *L*[3] is the solution
    to the following equations:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们解出 *L*[3] 与每条线 *L*[1] 和 *L*[2] 的交点。*L*[1] 和 *L*[3] 的交点是以下方程的解：
- en: '![](../Images/AppA_11_E06.png)'
  id: totrans-553
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/AppA_11_E06.png)'
- en: We can plug the second equation into the first one, to obtain
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将第二个方程代入第一个方程，得到
- en: '![](../Images/AppA_11_E07.png),'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/AppA_11_E07.png),'
- en: and subsequently solve for *x*[1] to obtain
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 然后解出 *x*[1]，得到
- en: '![](../Images/AppA_11_E08.png).'
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/AppA_11_E08.png)。'
- en: Therefore, because every point in *L*[2] has the form ![](../Images/AppA_11_E09.png)
    the point of intersection of *L*[1] and *L*[3] is the point with coordinates ![](../Images/AppA_11_E10.png).
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，因为 *L*[2] 中的每个点都有形式 ![](../Images/AppA_11_E09.png)，*L*[1] 和 *L*[3] 的交点是坐标为
    ![](../Images/AppA_11_E10.png) 的点。
- en: A similar calculation will show that the point of intersection of *L*[2] and
    *L*[3] is the point with coordinates ![](../Images/AppA_11_E11.png).
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 类似的计算将表明，*L*[2] 和 *L*[3] 的交点是坐标为 ![](../Images/AppA_11_E11.png) 的点。
- en: To find the distance between these two points, we can use the Pythagorean theorem.
    This distance is
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到这两个点之间的距离，我们可以使用勾股定理。这个距离是
- en: '![](../Images/AppA_11_E12.png)'
  id: totrans-561
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/AppA_11_E12.png)'
- en: as desired.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 如此。
- en: '![](../Images/A-131.png)'
  id: totrans-563
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/A-131.png)'
- en: Exercise 11.2
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 练习11.2
- en: 'As we learned in exercise 5.3, it is impossible to build a perceptron model
    that mimics the XOR gate. In other words, it is impossible to fit the following
    dataset (with 100% accuracy) with a perceptron model:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在练习5.3中学到的，不可能构建一个模仿XOR门的感知器模型。换句话说，不可能用感知器模型（以100%的准确率）拟合以下数据集：
- en: '| *x*[1] | *x*[2] | *y*   |'
  id: totrans-566
  prefs: []
  type: TYPE_TB
  zh: '| *x*[1] | *x*[2] | *y*   |'
- en: '| 0 | 0 | 0 |'
  id: totrans-567
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 0 |'
- en: '| 0 | 1 | 1 |'
  id: totrans-568
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1 | 1 |'
- en: '| 1 | 0 | 1 |'
  id: totrans-569
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0 | 1 |'
- en: '| 1 | 1 | 0 |'
  id: totrans-570
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 0 |'
- en: This is because the dataset is not linearly separable. An SVM has the same problem,
    because an SVM is also a linear model. However, we can use a kernel to help us
    out. What kernel should we use to turn this dataset into a linearly separable
    one? What would the resulting SVM look like?
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为数据集不是线性可分的。支持向量机（SVM）也有同样的问题，因为SVM也是一个线性模型。然而，我们可以使用核函数来帮助我们。我们应该使用什么核函数将这个数据集转换为线性可分的数据集？转换后的SVM会是什么样子？
- en: hint Look at example 2 in the section “Using polynomial equations to your benefit,”
    which solves a very similar problem.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：查看“利用多项式方程为你带来好处”部分的例子2，它解决了一个非常类似的问题。
- en: Solution
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'Considering the polynomial kernel of degree two, we get the following dataset:'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到二次多项式核，我们得到以下数据集：
- en: '| *x*[1] | *x*[2] | *x*[1]² | *x*[1] *x*[2] | *x*[2]² | *y*   |'
  id: totrans-575
  prefs: []
  type: TYPE_TB
  zh: '| *x*[1] | *x*[2] | *x*[1]² | *x*[1] *x*[2] | *x*[2]² | *y*   |'
- en: '| 0 | 0 | 0 | 0 | 0 | 0 |'
  id: totrans-576
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 0 | 0 | 0 | 0 |'
- en: '| 0 | 1 | 0 | 0 | 1 | 1 |'
  id: totrans-577
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1 | 0 | 0 | 1 | 1 |'
- en: '| 1 | 1 | 1 | 0 | 0 | 1 |'
  id: totrans-578
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 1 | 0 | 0 | 1 |'
- en: '| 1 | 1 | 1 | 1 | 1 | 0 |'
  id: totrans-579
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 | 1 | 1 | 1 | 0 |'
- en: Several classifiers work on this modified dataset. For example, the one with
    equation *ŷ* = *step*(*x*[1] + *x*[2] – 2*x*[1]*x*[2] – 0.5) classifies the data
    correctly.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 几个分类器在这个修改后的数据集上工作。例如，具有方程 *ŷ* = *step*(*x*[1] + *x*[2] – 2*x*[1]*x*[2] – 0.5)
    的分类器正确地分类了数据。
- en: 'Chapter 12: Combining models to maximize results: Ensemble learning'
  id: totrans-581
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 12 章：结合模型以最大化结果：集成学习
- en: Exercise 12.1
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 12.1
- en: A boosted strong learner *L* is formed by three weak learners, *L*[1], *L*[2],
    and *L*[3]. Their weights are 1, 0.4, and 1.2, respectively. For a particular
    point, *L*[1] and *L*[2] predict that its label is positive, and *L*[3] predicts
    that it’s negative. What is the final prediction the learner *L* makes on this
    point?
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 由三个弱学习器 *L*[1]、*L*[2] 和 *L*[3] 组成的强学习器 *L* 通过三个弱学习器形成。它们的权重分别为 1、0.4 和 1.2。对于特定点，*L*[1]
    和 *L*[2] 预测其标签为正，而 *L*[3] 预测其为负。学习器 *L* 对此点的最终预测是什么？
- en: Solution
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: Because *L*[1] and *L*[2] predicted that the label is positive and *L*[3] predicted
    that it is negative, the sum of votes is
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 *L*[1] 和 *L*[2] 预测标签为正，而 *L*[3] 预测标签为负，所以投票总和为
- en: 1 + 0.4 – 1.2 = 0.2.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 1 + 0.4 – 1.2 = 0.2。
- en: This result is positive, which means that the strong learner predicts that the
    label of this point is positive.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果是正的，这意味着强学习器预测这个点的标签为正。
- en: Exercise 12.2
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 12.2
- en: We are in the middle of training an AdaBoost model on a dataset of size 100\.
    The current weak learner classifies 68 out of the 100 data points correctly. What
    is the weight that we’ll assign to this learner in the final model?
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在对大小为 100 的数据集训练 AdaBoost 模型。当前的弱学习器正确分类了 68 个数据点中的 100 个。我们将为这个学习器在最终模型中分配什么权重？
- en: Solution
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: This weight is the log odds, or the natural logarithm of the odds. The odds
    are 68/32, because the classifier classifies 68 points correctly and misclassifies
    the remaining 32\. Therefore, the weight assigned to this weak learner is
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 这个权重是 log 概率，即概率的自然对数。概率为 68/32，因为分类器正确分类了 68 个点，错误分类了剩余的 32 个。因此，分配给这个弱学习器的权重是
- en: '![](../Images/AppA_12_E01.png)'
  id: totrans-592
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/AppA_12_E01.png)'
- en: 'Chapter 13: Putting it all in practice: A real-life example of data engineering
    and machine learning'
  id: totrans-593
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 13 章：付诸实践：数据工程和机器学习的真实案例
- en: Exercise 13.1
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 13.1
- en: The repository contains a file called test.csv. This is a file with more passengers
    on the *Titanic*, except it doesn’t have the Survived column.
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 仓库中包含一个名为 test.csv 的文件。这是一个包含更多 *泰坦尼克号* 乘客的文件，但它没有“Survived”列。
- en: Preprocess the data in this file as we did in this chapter.
  id: totrans-596
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照本章中的方法预处理此文件中的数据。
- en: Use any of the models to predict labels in this dataset. According to your model,
    how many passengers survived?
  id: totrans-597
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用任何模型来预测此数据集中的标签。根据你的模型，你认为有多少乘客幸存了？
- en: Comparing the performance of all the models in this chapter, how many passengers
    from the test set would you think actually survived?
  id: totrans-598
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 比较本章中所有模型的性能，你认为测试集中有多少乘客实际上幸存了？
- en: Solution
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 解答
- en: 'The solution is at the end of the following notebook: [https://github.com/luisguiserrano/manning/tree/master/Chapter_13_End_to_end_example](https://github.com/luisguiserrano/manning/tree/master/Chapter_13_End_to_end_example).'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: 解答位于以下笔记本的末尾：[https://github.com/luisguiserrano/manning/tree/master/Chapter_13_End_to_end_example](https://github.com/luisguiserrano/manning/tree/master/Chapter_13_End_to_end_example).
