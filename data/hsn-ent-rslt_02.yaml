- en: Chapter 2\. Data Standardization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 数据标准化
- en: As we discussed in [Chapter 1](ch01.html#chapter_1), before we can successfully
    match or deduplicate data sources we need to ensure our data is presented in a
    consistent manner and that any anomalies are removed or corrected. We will use
    the term *data standardization* to cover both the transformation of datasets into
    consistent formats and the cleansing of data to remove unhelpful extra characters
    that would otherwise interfere with the matching process.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第1章](ch01.html#chapter_1)中讨论的，要成功地匹配或去重数据源，我们需要确保我们的数据呈现一致的方式，并删除或修正任何异常。我们将使用术语*数据标准化*来涵盖数据集转换为一致格式以及清洗数据以删除否则会干扰匹配过程的无用额外字符。
- en: In this chapter, we will get hands on and work through a real-world example
    of this process. We will create our working environment, acquire the data we need,
    cleanse that data, and then perform a simple entity resolution exercise to allow
    us to perform some simple analysis. We will conclude by examining the performance
    of our data matching process and consider how we might improve it.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将动手操作，并通过一个真实的例子来进行这个过程。我们将创建我们的工作环境，获取我们需要的数据，清洗这些数据，然后执行一个简单的实体解析练习，以便进行一些简单的分析。我们将通过检查我们的数据匹配过程的性能，并考虑如何改进它来结束。
- en: First, let’s introduce our example and why we need entity resolution to solve
    it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们介绍我们的示例以及为什么我们需要实体解析来解决它。
- en: Sample Problem
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例问题
- en: Let’s work through an example problem to illustrate some of the common challenges
    we see in resolving entities between data sources and why data cleansing is an
    essential first step. As we are constrained to use openly available public sources
    of data, the example is slightly contrived but hopefully illustrates the need
    for entity resolution.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个示例问题来说明在解决数据源之间实体匹配中常见的一些挑战，以及为什么数据清洗是必不可少的第一步。由于我们受限于使用公开可用的公共数据源，这个例子有点刻意，但希望能说明实体解析的必要性。
- en: Let’s imagine we are researching factors that may influence whether members
    of the House of Commons, the lower house of the Parliament of the United Kingdom
    (UK), are reelected. We surmise that politicians with an active social media presence
    might be more successful in securing reelection. For the purposes of this example,
    we are going to consider Facebook presence, and so we look at the last UK general
    election and examine how many politicians who held onto their seat have Facebook
    accounts.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象我们正在研究可能影响英国下议院（议会的下议院）议员是否连任的因素。我们推测，拥有活跃的社交媒体存在可能会更有利于确保连任。为了本例，我们将考虑Facebook存在，因此我们查看了最后一次英国大选，并检查了保住议席的议员中有多少人拥有Facebook账号。
- en: Wikipedia has a web page that lists the members of Parliament (MPs) returned
    at the 2019 general election, including whether they were reelected, but it lacks
    social media information for those individuals. However, the [TheyWorkForYou website](https://theyworkforyou.com)
    does record information on current MPs, including links to their Facebook accounts.
    So if we combine these datasets we can begin to test our hypothesis that reelection
    and social media presence are related.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科有一个网页列出了2019年大选中当选的议员名单，包括他们是否再次当选，但缺乏这些个人的社交媒体信息。然而，[TheyWorkForYou 网站](https://theyworkforyou.com)记录了当前议员的信息，包括链接到他们的Facebook账号。因此，如果我们结合这些数据集，我们可以开始测试我们的假设，即连任和社交媒体存在相关性。
- en: TheyWorkForYou
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TheyWorkForYou
- en: TheyWorkForYou was founded to make Parliament more accessible and accountable.
    TheyWorkForYou is run by mySociety, a UK charity that puts power in more people’s
    hands through the use of digital tools and data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: TheyWorkForYou 的成立旨在使议会更加透明和负责任。TheyWorkForYou 由英国慈善组织 mySociety 运营，通过使用数字工具和数据来增加更多人的权力。
- en: How can we join these two datasets? Although both datasets include the name
    of the constituency that each MP represents, we can’t use this as a common key,
    because since the 2019 general election, a number of by-elections have taken place,
    returning new MPs.^([1](ch02.html#id309)) These new members may have Facebook
    accounts but should not be considered in the reelection population as this might
    skew our analysis. Therefore, we need to connect our data by matching the names
    of the MPs between the two sets of records, i.e., resolving these entities so
    that we can create a single combined record for each MP.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将这两个数据集连接起来？尽管两个数据集都包括每位议员所代表选区的名称，但我们不能将此作为公共键，因为自2019年大选以来，已经发生了一些补选，选出了新的议员。^([1](ch02.html#id309))
    这些新成员可能有Facebook账户，但不应被视为再选人群，因为这可能会扭曲我们的分析结果。因此，我们需要通过匹配议员姓名来连接我们的数据集，即解决这些实体，以便我们可以为每位议员创建一个单一的合并记录。
- en: Environment Setup
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环境设置
- en: Our first task is to set up our entity resolution environment. In this book,
    we will be using Python and the JupyterLab IDE.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个任务是设置我们的实体解析环境。在本书中，我们将使用Python和JupyterLab IDE。
- en: To begin, you’ll need Python installed on your machine. If you don’t already
    have it, you can download it from [their website](http://www.python.org).^([2](ch02.html#id312))
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，您需要在计算机上安装Python。如果尚未安装，请从[官网](http://www.python.org)下载。^([2](ch02.html#id312))
- en: Add Python to PATH
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Python添加到PATH
- en: If installing Python for the first time, make sure to select the “Add Python
    to PATH” option to ensure you can run Python from your command line.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果首次安装Python，请确保选择“将Python添加到PATH”选项，以确保您可以从命令行运行Python。
- en: To download the code examples that accompany this book it is convenient to use
    the Git version control system. A guide to installing Git can be found on the
    [GitHub website](https://github.com/git-guides/install-git).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载本书附带的代码示例，建议使用Git版本控制系统非常方便。有关安装Git的指南可以在[GitHub网站](https://github.com/git-guides/install-git)找到。
- en: 'Once Git is installed, you can clone (that is, take a copy of) the GitHub repository
    that accompanies this book onto your machine. Run this command from the parent
    directory of your choice:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 安装Git后，您可以从选择的父目录克隆（即复制）本书附带的GitHub仓库到您的计算机。请从您选择的父目录运行此命令：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This will create a subdirectory called *HandsOnEntityResolution*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为*HandsOnEntityResolution*的子目录。
- en: Python Virtual Environment
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python虚拟环境
- en: 'I recommend you use a virtual Python environment to work through the examples
    in this book. This will allow you to maintain the necessary Python package configuration
    without interfering with any other projects you may have. The following command
    creates a new environment in the *HandsOnEntityResolution* directory created by
    Git:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议您使用虚拟Python环境来完成本书中的示例。这将允许您在不干扰其他项目的情况下维护所需的Python软件包配置。以下命令将在由Git创建的*HandsOnEntityResolution*目录中创建一个新环境：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To activate the environment, run the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要激活环境，请运行以下命令：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will prefix your command prompt to show the environment name based on
    the directory name:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在命令提示符前缀中显示基于目录名称的环境名称：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once you’ve finished, it’s important to deactivate the environment:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，请务必停用环境：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, change into this directory:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，切换到此目录：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To set up our JupyterLab code environment and the packages required, we will
    use the Python package manager pip, which should be included with your Python
    installation. You can check using:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置我们的JupyterLab代码环境及所需的软件包，我们将使用Python软件包管理器pip，这应该已包含在您的Python安装中。您可以使用以下命令检查：
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can then install the packages you will need throughout the book from the
    *requirements.txt* file using:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从*requirements.txt*文件中安装本书中需要的软件包：
- en: '[PRE7]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, configure a Python kernel associated with our virtual environment for
    our notebooks to pick up:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，配置一个与我们虚拟环境关联的Python内核，以便我们的笔记本可以使用：
- en: '[PRE8]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then start JupyterLab with:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用以下命令启动JupyterLab：
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: While it’s pretty self-explanatory, instructions on how to get started with
    Jupyter are available in [the documentation](https://docs.jupyter.org/en/latest).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这相当简单明了，但如何开始使用Jupyter的说明可在[文档](https://docs.jupyter.org/en/latest)中找到。
- en: Acquiring Data
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据
- en: Now that we have our environment configured, our next task is to acquire the
    data we need. It’s often the case that the data we need comes in a variety of
    formats and presentations. The examples included in this book will illustrate
    how to deal with some of the most common formats we encounter.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经配置好了环境，我们的下一个任务是获取我们需要的数据。通常我们需要的数据以各种格式和展示方式呈现。本书中的示例将演示如何处理我们遇到的一些最常见的格式。
- en: Wikipedia Data
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Wikipedia 数据
- en: 'Opening *Chapter2.ipynb* in our Jupyter environment, we start by defining the
    Wikipedia URL for the list of MPs returned in the 2019 UK general election:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 Jupyter 环境中打开 *Chapter2.ipynb*，我们首先定义了 2019 年英国大选中返回的议员列表的 Wikipedia URL：
- en: '[PRE10]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then we can import the requests and Beautiful Soup Python packages and use
    them to download a copy of the Wikipedia text. Then run an `html parser` to extract
    all the tables present on the page:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以导入 requests 和 Beautiful Soup Python 包，并使用它们下载 Wikipedia 文本的副本。然后运行 `html
    parser` 来提取页面上存在的所有表格：
- en: '[PRE11]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Beautiful Soup
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Beautiful Soup
- en: Beautiful Soup is a Python package that makes it easy to scrape information
    from web pages. More details are available [online](https://oreil.ly/YB8H3).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Beautiful Soup 是一个 Python 包，可以轻松地从网页中抓取信息。更多详细信息请参阅[在线文档](https://oreil.ly/YB8H3)。
- en: 'Next, we need to find the table we want within the page. In this case we select
    the table that includes the text “Member returned” (a column name). Within this
    table, we extract the column names as headers and then iterate through all the
    remaining rows and elements, building a list of lists. These lists are then loaded
    into a pandas DataFrame, setting the extracted headers as DataFrame column names:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要找到页面中我们想要的表格。在这种情况下，我们选择包含“Member returned”（一个列名）文本的表格。在该表格内，我们提取列名作为标题，然后迭代所有剩余的行和元素，构建一个列表的列表。然后，将这些列表加载到
    pandas DataFrame 中，并设置提取的标题作为 DataFrame 的列名：
- en: '[PRE12]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The result is a pandas DataFrame, shown in [Figure 2-1](#fig-2-1), which we
    can examine using the `info` method.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个 pandas DataFrame，如[图 2-1](#fig-2-1)所示，我们可以使用 `info` 方法来查看。
- en: '![](assets/hoer_0201.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0201.png)'
- en: Figure 2-1\. Wikipedia MP information
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-1\. Wikipedia 的议员信息
- en: We have 652 entries of 5 columns. This looks encouraging because in each column,
    650 rows have nonnull values, which matches the number of UK House of Commons
    parliamentary constituencies.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有 652 条记录，5 列。这看起来很有前景，因为在每列中，有 650 行具有非空值，这与英国下议院议席的数量相匹配。
- en: 'Finally, we can simplify our dataset by retaining only the columns we need:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以通过保留我们需要的列来简化我们的数据集：
- en: '[PRE13]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: TheyWorkForYou Data
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TheyWorkForYou 数据
- en: 'Now we can move on to downloading our second dataset and loading it into a
    separate DataFrame, as shown in [Figure 2-2](#fig-2-2):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以继续下载我们的第二个数据集，并将其加载到单独的 DataFrame 中，如[图 2-2](#fig-2-2)所示：
- en: '[PRE14]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](assets/hoer_0202.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0202.png)'
- en: Figure 2-2\. TheyWorkForYou MP information
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-2\. TheyWorkForYou 的议员信息
- en: Post 2024/25 UK General Election
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2024/25 年英国大选后
- en: If you’re reading this book after the 2024/25 UK general election, then the
    TheyWorkForYou website will likely be updated with the new MPs. If you’re following
    along on your own machine, then please use the *mps_they_raw.csv* file supplied
    in the GitHub repository that accompanies this book. The raw Wikipedia data *mps_wiki_raw.csv*
    is also provided.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 2024/25 年英国大选后阅读本书，那么 TheyWorkForYou 网站可能会更新新的议员信息。如果你在自己的机器上跟着操作，请使用附带本书的
    GitHub 仓库中提供的 *mps_they_raw.csv* 文件。原始的 Wikipedia 数据 *mps_wiki_raw.csv* 也已提供。
- en: '[Figure 2-3](#fig-2-3) lists the first few rows of the DataFrame so that we
    can see information these fields typically contain.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2-3](#fig-2-3) 列出了 DataFrame 的前几行，以便我们可以查看这些字段通常包含的信息。'
- en: '![](assets/hoer_0203.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0203.png)'
- en: Figure 2-3\. First five rows of the TheyWorkForYou dataset
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-3\. TheyWorkForYou 数据集的前五行
- en: To discover whether each MP has an associated Facebook account we need to follow
    the link in the URI column to look up their TheyWorkForYou homepage. We’ll need
    to do this for each row, so we define a function that we can apply along the axis
    of the DataFrame.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 要发现每个议员是否有关联的 Facebook 账户，我们需要跟随 URI 列中的链接查看他们的 TheyWorkForYou 主页。我们需要为每一行执行此操作，因此我们定义一个函数，可以沿着
    DataFrame 的轴应用该函数。
- en: Adding Facebook links
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加 Facebook 链接
- en: 'The function uses the same Beautiful Soup package we used to parse the Wikipedia
    web page. In this case, we extract all the links to *facebook.com*. We then examine
    the first link. If this link is the account of TheyWorkForYou, then the site doesn’t
    have a Facebook account listed for the MP, so we return a nil string; if it does,
    then we return that link:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数使用了与我们用来解析维基百科网页的Beautiful Soup包相同的方法。在这种情况下，我们提取所有指向*facebook.com*的链接。然后我们检查第一个链接。如果这个链接是TheyWorkForYou的账户，那么该网站没有列出该议员的Facebook账户，因此我们返回一个空字符串；如果有，那么我们返回该链接：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We can apply this function to every row in the DataFrame using the `apply` method
    to call the `facelink` function, passing the `URI` value as the URL. The value
    returned from the function is added to a new column that Flink appended to the
    DataFrame.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`apply`方法将这个函数应用到DataFrame的每一行，调用`facelink`函数，将`URI`值作为URL传递。函数返回的值被添加到一个新列中，该列由Flink附加到DataFrame中。
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Be patient—this function has to do quite a bit of work, so it may take a few
    minutes to run on your machine. Once this completes we can view the first few
    rows again, as shown in [Figure 2-4](#fig-2-4), to check if we are getting the
    Facebook links we expect.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请耐心等待—这个函数需要做很多工作，所以在您的机器上可能需要几分钟才能运行完毕。一旦完成，我们可以再次查看前几行，如[图 2-4](#fig-2-4)所示，检查我们是否得到了期望的Facebook链接。
- en: '![](assets/hoer_0204.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0204.png)'
- en: Figure 2-4\. First five rows of the TheyWorkForYou dataset with Facebook links
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-4\. TheyWorkForYou数据集中带有Facebook链接的前五行
- en: 'Finally, we can simplify our dataset by retaining only the columns we need:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以简化我们的数据集，只保留我们需要的列：
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Cleansing Data
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清洗
- en: Now that we have our raw datasets we can begin our data cleansing process. We
    will perform some initial cleansing on the Wikipedia dataset first and then the
    TheyWorkForYou data. We will then attempt to join these datasets and see what
    further inconsistencies are revealed that we need to standardize.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了原始数据集，我们可以开始我们的数据清洗过程。我们将首先对维基百科数据集进行一些初始清洗，然后是TheyWorkForYou的数据。然后我们将尝试连接这些数据集，并查看我们需要标准化的进一步不一致性。
- en: Wikipedia
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维基百科
- en: Let’s have a look at the first and last few rows in the Wikipedia dataset, as
    shown in [Figure 2-5](#fig-2-5).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看维基百科数据集中的前几行和最后几行，如[图 2-5](#fig-2-5)所示。
- en: '![](assets/hoer_0205.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0205.png)'
- en: Figure 2-5\. First and last 5 rows of the Wikipedia data
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-5\. 维基百科数据的前五行和最后五行
- en: 'The first task in our cleansing process is to standardize our column names:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们数据清洗过程中的第一个任务是标准化我们的列名：
- en: '[PRE18]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can also see that the output of our parser has a blank row at the start and
    end of our DataFrame, and it appears we have `\n` characters appended to each
    element. These additions would clearly interfere with our match, so they need
    to be removed.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到我们的解析器的输出在DataFrame的开头和结尾有空白行，并且似乎每个元素末尾都有`\n`字符。这些附加内容显然会干扰我们的匹配，所以需要移除它们。
- en: 'To remove the blank rows we can use:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除空白行，我们可以使用：
- en: '[PRE19]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To remove the trailing `\n` characters:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 要去除末尾的`\n`字符：
- en: '[PRE20]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: To be sure we now have a clean `Fullname` we can check for any other `\n` characters.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们现在有一个干净的`Fullname`，我们可以检查是否还有其他的`\n`字符。
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This simple check shows that we also have leading values that we need to remove:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的检查显示，我们也有需要移除的前导值：
- en: '[PRE22]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Our next task is to split our `Fullname` into `Firstname` and `Lastname` so
    that we can match these values independently. For the purposes of this example,
    we are going to use a simple method, selecting the first substring as the `Firstname`
    and the remaining substrings, separated by spaces, as the `Lastname`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一个任务是将我们的`Fullname`拆分为`Firstname`和`Lastname`，以便我们可以独立匹配这些值。为了本例的目的，我们将使用一个简单的方法，选择第一个子字符串作为`Firstname`，剩余的由空格分隔的子字符串作为`Lastname`。
- en: '[PRE23]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We can check how well this basic method has worked by looking for `Lastname`
    entries that contain spaces. [Figure 2-6](#fig-2-6) shows the remaining `Lastname`
    entries with spaces present.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过查看包含空格的`Lastname`条目来检查这种基本方法的工作情况。[图 2-6](#fig-2-6)展示了仍然存在空格的`Lastname`条目。
- en: '![](assets/hoer_0206.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0206.png)'
- en: Figure 2-6\. Check for compound `Lastname` entries in Wikipedia data
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-6\. 检查维基百科数据中复合`Lastname`条目
- en: We now have a sufficiently clean dataset to attempt a first match, so we’ll
    move on to our second dataset.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个足够干净的数据集，可以尝试第一次匹配，所以我们将转向我们的第二个数据集。
- en: TheyWorkForYou
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TheyWorkForYou
- en: 'As we saw earlier, the TheyWorkForYou data is already pretty clean, so at this
    stage all we need to do is standardize the column names with those of the previous
    DataFrame. This will make our life easier as we attempt to match:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，TheyWorkForYou的数据已经相当干净，所以在这个阶段，我们所需要做的就是将列名与前一个DataFrame的列名标准化。这将使我们在尝试匹配时更加轻松：
- en: '[PRE24]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Attribute Comparison
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 属性比较
- en: 'Now that we have two similarly formatted DataFrames, we can experiment with
    the next stage of the entity resolution process. Because our datasets are small
    we don’t need to employ record blocking, and so we can proceed directly to try
    a simple exact match of `Firstname`, `Lastname`, and `Constituency`. The `merge`
    method (similar to a database `join`) does this exact matching for us:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有两个格式类似的DataFrame，我们可以尝试实体解析过程的下一阶段。因为我们的数据集很小，我们不需要使用记录阻塞，所以我们可以直接尝试对`Firstname`、`Lastname`和`Constituency`进行简单的精确匹配。`merge`方法（类似于数据库的`join`）可以为我们执行这种精确匹配：
- en: '[PRE25]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We find that 599 of 650 are perfect matches of all three attributes—not bad!
    Matching on just `Constituency` and `Lastname` gives us 607 perfect matches, so
    we clearly have 8 mismatching `Firstname` entries:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现650个中有599个完美匹配所有三个属性——不错！仅在`Constituency`和`Lastname`上进行匹配，我们得到607个完美匹配，因此显然有8个不匹配的`Firstname`条目：
- en: '[PRE26]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Repeating the process for the remaining permutations of `Firstname`, `Lastname`,
    and `Constituency` gives us the Venn diagram of match counts shown in [Figure 2-7](#fig-2-7).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对`Firstname`、`Lastname`和`Constituency`的剩余排列重复这个过程，得到了匹配计数的维恩图，如[图 2-7](#fig-2-7)所示。
- en: '![](assets/hoer_0207.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0207.png)'
- en: Figure 2-7\. Venn diagram
  id: totrans-111
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-7\. 维恩图
- en: A simple join on `Firstname` gives 2,663 matches and the equivalent match on
    `Lastname` has 982 matches. These counts exceed the number of MPs and arise because
    of repeated common names that match more than once between the two datasets.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地在`Firstname`上进行连接给出了2663个匹配，而在`Lastname`上的等效匹配则有982个匹配。这些计数超过了议员的数量，因为有重复的常见名称在两个数据集之间匹配了多次。
- en: 'We have 599 matches out of 650 so far, but can we do better? Let’s start with
    examining the `Constituency` attribute in our datasets. As a categorical variable,
    we would expect this to be pretty easy to match:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在650个选区中有599个匹配，但是我们能做得更好吗？让我们从检查数据集中的`Constituency`属性开始。作为一个分类变量，我们预计这应该是相当容易匹配的：
- en: '[PRE27]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We have 623 matches, leaving 27 unmatched. Why? Surely we’d expect the same
    constituencies to be present in both datasets, so what is going wrong?
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有623个匹配项，还剩下27个未匹配的。为什么？我们肯定期望两个数据集中存在相同的选区，那么问题出在哪里？
- en: Constituency
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选区
- en: Let’s have a look at the first five of the unmatched population in both datasets.
    To do this we perform an outer join between the DataFrames using the `Constituency`
    attribute and then select those records found in either the right (Wikipedia)
    or left (TheyWorkForYou) DataFrame. The results are shown in [Figure 2-8](#fig-2-8).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看两个数据集中未匹配人口的前五名。为此，我们使用`Constituency`属性在DataFrame之间执行外部连接，然后选择那些在右侧（维基百科）或左侧（TheyWorkForYou）DataFrame中找到的记录。结果显示在[图 2-8](#fig-2-8)中。
- en: '![](assets/hoer_0208.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0208.png)'
- en: Figure 2-8\. Constituency mismatches
  id: totrans-119
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-8\. 选区不匹配
- en: 'We can see that the first dataset from the TheyWorkForYou website has commas
    embedded in the constituency names, whereas the Wikipedia data does not. This
    explains why they don’t match. To ensure consistency, let’s remove any commas
    from both DataFrames:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，TheyWorkForYou网站的第一个数据集中选区名称中嵌有逗号，而维基百科的数据集中没有。这解释了它们为什么不匹配。为了确保一致性，让我们从两个DataFrame中都删除逗号：
- en: '[PRE28]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'After applying this cleansing we have a perfect match on all 650 constituencies:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用此清理后，我们在所有650个选区上都实现了完美匹配：
- en: '[PRE29]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Case Sensitivity
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区分大小写
- en: In this simple example, we have matching case conventions (e.g., initial capitalization)
    between the two datasets. In many situations this won’t be the case, and you’ll
    need to standardize on upper- or lowercase characters. We’ll see how this can
    be done in later chapters.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的例子中，我们在两个数据集之间有匹配的大小写约定（例如，初始大写）。在许多情况下，情况可能并非如此，您可能需要标准化为大写或小写字符。我们将在后面的章节中看到如何做到这一点。
- en: 'Repeating our perfect match on all three attributes, we can now match 624 records:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有三个属性上重复我们的完美匹配，现在我们可以匹配624条记录：
- en: '[PRE30]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: What about the other 26?
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 那其他的26个呢？
- en: A little domain knowledge is useful here. As we considered at the start of the
    chapter, between the election in 2019 and the time of writing, a number of by-elections
    took place. If we look at constituencies where neither the first name nor the
    last name matches then, for this simple example at least, we can identify likely
    candidates, as shown in [Figure 2-9](#fig-2-9).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里一点领域知识是有用的。正如我们在本章开头所考虑的那样，在2019年选举和写作时期之间，发生了一些补选。如果我们看看既不匹配名字也不匹配姓氏的选区，那么至少对于这个简单的例子来说，我们可以确定可能的候选人，如[图2-9](#fig-2-9)所示。
- en: '![](assets/hoer_0209.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0209.png)'
- en: Figure 2-9\. Potential by-elections
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-9\. 潜在的补选
- en: Of our 14 by-election candidates, we have 13 cases where the names are entirely
    different, suggesting we are correct to discount them, but the candidate for Newton
    Abbot appears to be a potential match because the middle name “Morris” has been
    included in the last name in one dataset and in the first name in the other, frustrating
    our exact match on both attributes.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的14个补选候选人中，有13个案例，名字完全不同，这表明我们有理由排除它们，但牛顿阿伯特的候选人似乎是一个潜在的匹配，因为在一个数据集中的中间名“莫里斯”已经包含在姓氏中，在另一个数据集中包含在名字中，这使得我们在两个属性上的精确匹配受到阻碍。
- en: In fact, we can verify our conclusion with data from the [UK Parliament website](https://oreil.ly/eWhWf).
    This confirms that by-elections have been held in the matching constituencies.
    So this explains 13 of our 26 unmatched records—what about the rest? Let’s pick
    out where either the first name or the last name matches but the other doesn’t.
    This subset is shown in [Figure 2-10](#fig-2-10).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们可以用来自[英国议会网站](https://oreil.ly/eWhWf)的数据来验证我们的结论。这证实了在匹配的选区内已经举行了补选。这解释了我们26条未匹配记录中的13条——剩下的呢？让我们挑选出只有名字或姓氏匹配但另一个不匹配的情况。这个子集在[图2-10](#fig-2-10)中展示。
- en: '![](assets/hoer_0210.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0210.png)'
- en: Figure 2-10\. Potential by-elections
  id: totrans-135
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-10\. 潜在的补选
- en: We can see that the remaining 12 records, as listed in [Table 2-1](#table-2-1),
    display a variety of the matching issues that we discussed in [Chapter 1](ch01.html#chapter_1).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到剩下的12条记录，如[表2-1](#table-2-1)所示，展示了我们在[第1章](ch01.html#chapter_1)中讨论的各种匹配问题。
- en: Table 2-1\. Matching issues summary table
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 表2-1\. 匹配问题总结表
- en: '| Matching issue | **TheyWorkForYou** | **Wikipedia** |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 匹配问题 | **他们为你工作** | **维基百科** |'
- en: '| --- | --- | --- |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Shortened names | Dan | Daniel |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 缩写名 | 丹 | 丹尼尔 |'
- en: '|   | Tan | Tanmanjeet |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|   | 坦 | 坦曼吉特 |'
- en: '|   | Liz | Elizabeth |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|   | 丽兹 | 伊丽莎白 |'
- en: '|   | Chris | Christopher |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|   | 克里斯 | 克里斯托弗 |'
- en: '|   | Nus | Nusrat |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '|   | 努斯 | 努斯拉特 |'
- en: '| Middle initials included | Diana R. | Diana |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 包括中间名 | 黛安娜·R. | 黛安娜 |'
- en: '|   | Jeffrey M. | Jeffrey |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|   | 杰弗里·M. | 杰弗里 |'
- en: '| Middle name included | Preet Kaur | Preet |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 包含中间名 | 普里特·卡尔 | 普里特 |'
- en: '|   | John Martin | John |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '|   | 约翰·马丁 | 约翰 |'
- en: '| Last name suffix | Paisley Jnr | Paisley |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 姓氏后缀 | 佩斯利（二世） | 佩斯利 |'
- en: '| Double-barreled last names | Docherty | Docherty-Hughes |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 双姓 | 多克蒂 | 多克蒂-休斯 |'
- en: 'There is one remaining mismatch that is really hard to resolve: a change of
    the last name Kniveton (previously Griffiths) in the Burton constituency. Now
    we have accounted for all 650 constituencies.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个剩余的难以解决的不匹配情况：在伯顿选区，上一次的名字是格里菲斯，现在是克尼维顿。现在我们已经统计了所有650个选区。
- en: 'If we further cleanse the `Firstname` from the TheyWorkForYou data, removing
    any middle initials or names, we can improve our matches still further:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们进一步从TheyWorkForYou数据中清除`Firstname`，删除任何中间名或姓名，我们可以进一步提高我们的匹配度：
- en: '[PRE31]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can now match another four records:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以匹配另外四条记录：
- en: '[PRE32]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This brings us to end of our introduction to basic data cleansing techniques.
    We now have only nine unresolved records, as shown in [Figure 2-11](#fig-2-11). In
    the next chapter, we will see how more approximate text matching techniques can
    help us resolve some of these too.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们结束了基本数据清理技术的介绍。现在我们只剩下九条未解决的记录，如[图2-11](#fig-2-11)所示。在下一章中，我们将看到更多近似文本匹配技术如何帮助我们解决其中一些问题。
- en: '![](assets/hoer_0211.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0211.png)'
- en: Figure 2-11\. Unresolved entities
  id: totrans-158
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-11\. 未解决实体
- en: Measuring Performance
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测量表现
- en: 'Let’s evaluate our performance using a simple exact matching method based on
    the metrics we defined in [Chapter 1](ch01.html#chapter_1). Our total population
    size is 650, within which we have:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用基于我们在[第1章](ch01.html#chapter_1)中定义的指标的简单精确匹配方法来评估我们的表现。我们的总人口规模是650，其中：
- en: <math alttext="upper T r u e p o s i t i v e m a t c h e s left-parenthesis
    upper T upper P right-parenthesis equals 628"><mrow><mi>T</mi> <mi>r</mi> <mi>u</mi>
    <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>v</mi>
    <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi>
    <mo>(</mo> <mi>T</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>628</mn></mrow></math>
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper T r u e p o s i t i v e m a t c h e s left-parenthesis
    upper T upper P right-parenthesis equals 628"><mrow><mi>T</mi> <mi>r</mi> <mi>u</mi>
    <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi> <mi>v</mi>
    <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi>
    <mo>(</mo> <mi>T</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>628</mn></mrow></math>
- en: <math alttext="upper F a l s e p o s i t i v e m a t c h e s left-parenthesis
    upper F upper P right-parenthesis equals 0"><mrow><mi>F</mi> <mi>a</mi> <mi>l</mi>
    <mi>s</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi>
    <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math>
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper F a l s e p o s i t i v e m a t c h e s left-parenthesis
    upper F upper P right-parenthesis equals 0"><mrow><mi>F</mi> <mi>a</mi> <mi>l</mi>
    <mi>s</mi> <mi>e</mi> <mi>p</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi>
    <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>P</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math>
- en: <math alttext="upper T r u e n e g a t i v e m a t c h e s left-parenthesis
    upper T upper N right-parenthesis equals 13 left-parenthesis upper B y minus e
    l e c t i o n s right-parenthesis"><mrow><mi>T</mi> <mi>r</mi> <mi>u</mi> <mi>e</mi>
    <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi> <mi>v</mi> <mi>e</mi>
    <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo>
    <mi>T</mi> <mi>N</mi> <mo>)</mo> <mo>=</mo> <mn>13</mn> <mo>(</mo> <mi>B</mi>
    <mi>y</mi> <mo>-</mo> <mi>e</mi> <mi>l</mi> <mi>e</mi> <mi>c</mi> <mi>t</mi> <mi>i</mi>
    <mi>o</mi> <mi>n</mi> <mi>s</mi> <mo>)</mo></mrow></math>
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper T r u e n e g a t i v e m a t c h e s left-parenthesis
    upper T upper N right-parenthesis equals 13 left-parenthesis upper B y minus e
    l e c t i o n s right-parenthesis"><mrow><mi>T</mi> <mi>r</mi> <mi>u</mi> <mi>e</mi>
    <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi> <mi>v</mi> <mi>e</mi>
    <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi> <mi>s</mi> <mo>(</mo>
    <mi>T</mi> <mi>N</mi> <mo>)</mo> <mo>=</mo> <mn>13</mn> <mo>(</mo> <mi>B</mi>
    <mi>y</mi> <mo>-</mo> <mi>e</mi> <mi>l</mi> <mi>e</mi> <mi>c</mi> <mi>t</mi> <mi>i</mi>
    <mi>o</mi> <mi>n</mi> <mi>s</mi> <mo>)</mo></mrow></math>
- en: <math alttext="upper F a l s e n e g a t i v e m a t c h e s left-parenthesis
    upper F upper N right-parenthesis equals 9"><mrow><mi>F</mi> <mi>a</mi> <mi>l</mi>
    <mi>s</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi>
    <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>N</mi> <mo>)</mo> <mo>=</mo> <mn>9</mn></mrow></math>
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper F a l s e n e g a t i v e m a t c h e s left-parenthesis
    upper F upper N right-parenthesis equals 9"><mrow><mi>F</mi> <mi>a</mi> <mi>l</mi>
    <mi>s</mi> <mi>e</mi> <mi>n</mi> <mi>e</mi> <mi>g</mi> <mi>a</mi> <mi>t</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>m</mi> <mi>a</mi> <mi>t</mi> <mi>c</mi> <mi>h</mi> <mi>e</mi>
    <mi>s</mi> <mo>(</mo> <mi>F</mi> <mi>N</mi> <mo>)</mo> <mo>=</mo> <mn>9</mn></mrow></math>
- en: 'We can calculate our performance metrics as:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算我们的表现指标如下：
- en: <math alttext="upper P r e c i s i o n equals StartFraction upper T upper P
    Over left-parenthesis upper T upper P plus upper F upper P right-parenthesis EndFraction
    equals StartFraction 628 Over left-parenthesis 628 plus 0 right-parenthesis EndFraction
    equals 100 percent-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi> <mi>i</mi>
    <mi>s</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>628</mn> <mrow><mo>(</mo><mn>628</mn><mo>+</mo><mn>0</mn><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mn>100</mn> <mo>%</mo></mrow></math>
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper P r e c i s i o n equals StartFraction upper T upper P
    Over left-parenthesis upper T upper P plus upper F upper P right-parenthesis EndFraction
    equals StartFraction 628 Over left-parenthesis 628 plus 0 right-parenthesis EndFraction
    equals 100 percent-sign"><mrow><mi>P</mi> <mi>r</mi> <mi>e</mi> <mi>c</mi> <mi>i</mi>
    <mi>s</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>628</mn> <mrow><mo>(</mo><mn>628</mn><mo>+</mo><mn>0</mn><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mn>100</mn> <mo>%</mo></mrow></math>
- en: <math alttext="upper R e c a l l equals StartFraction upper T upper P Over left-parenthesis
    upper T upper P plus upper F upper N right-parenthesis EndFraction equals StartFraction
    628 Over left-parenthesis 628 plus 9 right-parenthesis EndFraction almost-equals
    98.6 percent-sign"><mrow><mi>R</mi> <mi>e</mi> <mi>c</mi> <mi>a</mi> <mi>l</mi>
    <mi>l</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow> <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>628</mn> <mrow><mo>(</mo><mn>628</mn><mo>+</mo><mn>9</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>98</mn> <mo>.</mo> <mn>6</mn> <mo>%</mo></mrow></math>
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper R e c a l l equals StartFraction upper T upper P Over left-parenthesis
    upper T upper P plus upper F upper N right-parenthesis EndFraction equals StartFraction
    628 Over left-parenthesis 628 plus 9 right-parenthesis EndFraction almost-equals
    98.6 percent-sign"><mrow><mi>R</mi> <mi>e</mi> <mi>c</mi> <mi>a</mi> <mi>l</mi>
    <mi>l</mi> <mo>=</mo> <mfrac><mrow><mi>T</mi><mi>P</mi></mrow> <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mn>628</mn> <mrow><mo>(</mo><mn>628</mn><mo>+</mo><mn>9</mn><mo>)</mo></mrow></mfrac>
    <mo>≈</mo> <mn>98</mn> <mo>.</mo> <mn>6</mn> <mo>%</mo></mrow></math>
- en: <math alttext="upper A c c u r a c y equals StartFraction left-parenthesis upper
    T upper P plus upper T upper N right-parenthesis Over left-parenthesis upper T
    upper P plus upper T upper N plus upper F upper P plus upper F upper N right-parenthesis
    EndFraction equals StartFraction left-parenthesis 628 plus 13 right-parenthesis
    Over 650 EndFraction almost-equals 98.6 percent-sign"><mrow><mi>A</mi> <mi>c</mi>
    <mi>c</mi> <mi>u</mi> <mi>r</mi> <mi>a</mi> <mi>c</mi> <mi>y</mi> <mo>=</mo> <mfrac><mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>)</mo></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mo>(</mo><mn>628</mn><mo>+</mo><mn>13</mn><mo>)</mo></mrow>
    <mn>650</mn></mfrac> <mo>≈</mo> <mn>98</mn> <mo>.</mo> <mn>6</mn> <mo>%</mo></mrow></math>
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="upper A c c u r a c y equals StartFraction left-parenthesis upper
    T upper P plus upper T upper N right-parenthesis Over left-parenthesis upper T
    upper P plus upper T upper N plus upper F upper P plus upper F upper N right-parenthesis
    EndFraction equals StartFraction left-parenthesis 628 plus 13 right-parenthesis
    Over 650 EndFraction almost-equals 98.6 percent-sign"><mrow><mi>A</mi> <mi>c</mi>
    <mi>c</mi> <mi>u</mi> <mi>r</mi> <mi>a</mi> <mi>c</mi> <mi>y</mi> <mo>=</mo> <mfrac><mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>)</mo></mrow>
    <mrow><mo>(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>)</mo></mrow></mfrac>
    <mo>=</mo> <mfrac><mrow><mo>(</mo><mn>628</mn><mo>+</mo><mn>13</mn><mo>)</mo></mrow>
    <mn>650</mn></mfrac> <mo>≈</mo> <mn>98</mn> <mo>.</mo> <mn>6</mn> <mo>%</mo></mrow></math>
- en: Our precision is perfect because we are setting a very high bar—an exact match
    on first name, last name, and constituency; if we declare a match, we always get
    it right. Our recall is also extremely good; we rarely fail to find a match we
    should have found. Finally, our overall accuracy is also very high.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的精确度非常高，因为我们设定了一个非常高的标准：在名字、姓氏和选区完全匹配的情况下；如果我们宣布匹配，我们总是正确的。我们的召回率也非常高；我们很少找不到应该找到的匹配项。最后，我们的总体准确率也非常高。
- en: Of course, this is a simple example with relatively high-quality data and we
    have the advantage of a very strong categorical variable (constituency) to match
    against.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这只是一个简单的例子，数据质量相对较高，我们有一个非常强的分类变量（选区）来进行匹配。
- en: Sample Calculation
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例计算
- en: We have successfully resolved the names between our two datasets, so now we
    can use the combined information to test our hypothesis about the correlation
    between social media presence and the likelihood of reelection. Our resolved data
    now has everything we need in one table. [Figure 2-12](#fig-2-12) shows the first
    few rows of this table.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功解决了两个数据集之间的姓名冲突，所以现在我们可以使用合并后的信息来验证我们关于社交媒体存在与议员连任可能性相关性的假设。我们解决后的数据现在在一个表格中包含了我们需要的所有信息。[图2-12](#fig-2-12)展示了这个表格的前几行。
- en: '![](assets/hoer_0212.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/hoer_0212.png)'
- en: Figure 2-12\. Sample of resolved entities
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-12\. 已解决实体的示例
- en: 'We can calculate the number of MPs who currently have Facebook accounts who
    held their seats in the 2019 election:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算目前在Facebook上有账号并在2019年选举中保住席位的议员数量：
- en: '[PRE33]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'As a percentage: <math alttext="StartFraction 474 Over 628 EndFraction almost-equals
    75 percent-sign"><mrow><mfrac><mn>474</mn> <mn>628</mn></mfrac> <mo>≈</mo> <mn>75</mn>
    <mo>%</mo></mrow></math> .'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 以百分比表示：<math alttext="StartFraction 474 Over 628 EndFraction almost-equals 75
    percent-sign"><mrow><mfrac><mn>474</mn> <mn>628</mn></mfrac> <mo>≈</mo> <mn>75</mn>
    <mo>%</mo></mrow></math> 。
- en: 'Finally, we’ll save our cleansed datasets locally so that we can use them in
    subsequent chapters:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们会将我们清洗后的数据集保存在本地，以便在接下来的章节中使用：
- en: '[PRE34]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Summary
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'To summarize, we used five simple techniques to standardize and cleanse our
    data:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们使用了五种简单的技术来标准化和清理我们的数据：
- en: Removed null records
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除空记录
- en: Removed leading and trailing unwanted characters
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除前导和尾随的不需要的字符
- en: Split full name into first name and last name
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将全名拆分为名字和姓氏
- en: Removed commas from constituency
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从选区中移除逗号
- en: Removed middle names and initials from first name
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从名字中移除中间名和首字母缩写
- en: As a result we were able to join our datasets and then calculate a simple metric
    that we otherwise could not. Alas, there is no ubiquitous cleansing process; it
    depends on the datasets you have.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这一操作，我们能够合并我们的数据集，然后计算一个简单的度量标准，否则我们是无法做到的。唉，没有普适的清理过程；它取决于你所拥有的数据集。
- en: In the next chapter we will see how fuzzy matching techniques can improve our
    performance even more.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到模糊匹配技术如何进一步提升我们的性能。
- en: ^([1](ch02.html#id309-marker)) A by-election, also known as a special election
    in the United States, is an election used to fill an office that has become vacant
    between general elections. In the UK Parliament, a seat in the House of Commons
    can become vacant when an MP resigns or dies.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch02.html#id309-marker)) 补选，也称为美国的特别选举，是用来填补在大选之间出现空缺的职位的选举。在英国议会，众议院的一个席位在议员辞职或去世时可能会出现空缺。
- en: ^([2](ch02.html#id312-marker)) Software products identified in this book are
    suggestions only. You are responsible for evaluating whether to use any particular
    software and accept its license terms.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch02.html#id312-marker)) 本书中标识的软件产品仅供参考。您有责任评估是否使用任何特定软件并接受其许可条款。
