- en: 8 Serverless deep learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 无服务器深度学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Serving models with TensorFlow Lite—a lightweight environment for applying TensorFlow
    models
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Lite 提供模型服务——一个轻量级的环境，用于应用 TensorFlow 模型
- en: Deploying deep learning models with AWS Lambda
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AWS Lambda 部署深度学习模型
- en: Exposing the lambda function as a web service via API Gateway
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 API Gateway 将 lambda 函数作为 Web 服务公开
- en: In the previous chapter, we trained a deep learning model for categorizing images
    of clothing. Now we need to deploy it, making the model available for other services.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们训练了一个用于分类服装图像的深度学习模型。现在我们需要部署它，使模型可供其他服务使用。
- en: We have many possible ways of doing this. We have already covered the basics
    of model deployment in chapter 5, where we talked about using Flask, Docker, and
    AWS Elastic Beanstalk for deploying a logistic regression model.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有做这件事的许多可能方法。我们已经在第 5 章中介绍了模型部署的基础知识，其中我们讨论了使用 Flask、Docker 和 AWS Elastic
    Beanstalk 来部署逻辑回归模型。
- en: In this chapter, we’ll talk about the serverless approach for deploying models—we’ll
    use AWS Lambda.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论部署模型的无服务器方法——我们将使用 AWS Lambda。
- en: '8.1 Serverless: AWS Lambda'
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 无服务器：AWS Lambda
- en: AWS Lambda is a service from Amazon. Its main promise is that you can “run code
    without thinking about servers.”
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Lambda 是亚马逊的一项服务。它的主要承诺是您可以“无需考虑服务器即可运行代码。”
- en: 'It lives up to the promise: in AWS Lambda, we just need to upload some code.
    The service takes care of running it and scales it up and down according to the
    load.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 它实现了承诺：在 AWS Lambda 中，我们只需上传一些代码。服务会负责运行它并根据负载进行扩展和缩减。
- en: Additionally, you only need to pay for the time when the function is actually
    used. When nobody uses the model and invokes our service, you don’t pay for anything.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您只需为函数实际使用的时间付费。当没有人使用模型并调用我们的服务时，您不需要支付任何费用。
- en: In this chapter, we use AWS Lambda for deploying the model we trained previously.
    For doing that, we’ll also use TensorFlow Lite—a lightweight version of TensorFlow
    that has only the most essential functions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用 AWS Lambda 来部署我们之前训练的模型。为此，我们还将使用 TensorFlow Lite——TensorFlow 的轻量级版本，它只包含最基本的功能。
- en: '![](../Images/08-01.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08-01.png)'
- en: 'Figure 8.1 Overview of the service: it gets the URL of an image, applies the
    model, and returns the predictions.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 服务概述：它获取图像的 URL，应用模型，并返回预测结果。
- en: We want to build a web service that
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要构建一个 Web 服务，它
- en: Gets the URL in the request
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取请求中的 URL
- en: Loads the image from this URL
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从此 URL 加载图像
- en: Uses TensorFlow Lite to apply the model to the image and get the predictions
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Lite 将模型应用于图像并获取预测结果
- en: Responds with the results (figure 8.1)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回结果（图 8.1）
- en: To create this service, we will need to
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建此服务，我们需要
- en: Convert the model from Keras to the TensorFlow Lite format
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型从 Keras 转换为 TensorFlow Lite 格式
- en: Preprocess the images—resize them and apply the preprocessing function
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理图像——调整大小并应用预处理函数
- en: Package the code in a Docker image, and upload it to ECR (the Docker registry
    from AWS)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将代码打包成 Docker 镜像，并上传到 ECR（AWS 的 Docker 仓库）
- en: Create and test the lambda function on AWS
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AWS 上创建和测试 lambda 函数
- en: Make the lambda function available to everyone with AWS API Gateway
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 AWS API Gateway 使 lambda 函数对每个人可用
- en: We assume you have an AWS account and have configured the AWS CLI tool. For
    details, please refer to appendix A.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设您有一个 AWS 账户并且已经配置了 AWS CLI 工具。有关详细信息，请参阅附录 A。
- en: Note At the time of writing, AWS Lambda is covered by the AWS free tier. This
    means that it’s possible to do all the experiments in this chapter for free. To
    check the conditions, refer to the AWS documentation ([https://aws.amazon.com/free/](https://aws.amazon.com/free/)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在撰写本文时，AWS Lambda 由 AWS 免费层覆盖。这意味着您可以免费进行本章的所有实验。要检查条件，请参阅 AWS 文档（[https://aws.amazon.com/free/](https://aws.amazon.com/free/)）。
- en: We use AWS here, but this approach also works for other serverless platforms.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用 AWS，但这种方法也适用于其他无服务器平台。
- en: The code for this chapter is available in the book’s GitHub repository ([https://github.com/alexeygrigorev/mlbookcamp-code/](https://github.com/alexeygrigorev/mlbookcamp-code/))
    in the chapter-08-serverless folder.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可在本书的 GitHub 仓库中找到（[https://github.com/alexeygrigorev/mlbookcamp-code/](https://github.com/alexeygrigorev/mlbookcamp-code/)）的
    chapter-08-serverless 文件夹中。
- en: Let’s start by discussing TensorFlow Lite.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先来讨论 TensorFlow Lite。
- en: 8.1.1 TensorFlow Lite
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.1 TensorFlow Lite
- en: 'TensorFlow is a great framework with a rich set of features. However, most
    of these features are not needed for model deployment, and they take up a lot
    of space: when compressed, TensorFlow takes up more than 1.5 GB of space.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 是一个功能丰富的框架。然而，其中大部分功能对于模型部署来说并不需要，而且它们占用了大量的空间：当压缩时，TensorFlow 占用超过
    1.5 GB 的空间。
- en: TensorFlow Lite (usually abbreviated as “TF Lite”), on the other hand, takes
    up only 50 MB of space. It’s optimized for mobile devices and contains only the
    essential parts. With TF Lite, you can use the model only for making predictions
    and nothing else, including training new models.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，TensorFlow Lite（通常简称为“TF Lite”）仅占用 50 MB 的空间。它针对移动设备进行了优化，只包含基本部分。使用 TF
    Lite，你只能使用模型进行预测，不能做其他任何事情，包括训练新模型。
- en: Even though it was originally created for mobile devices, it’s applicable for
    more cases. We can use it whenever we have a TensorFlow model but can’t afford
    to take the entire TensorFlow package with us.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它最初是为移动设备创建的，但它适用于更多情况。只要我们有 TensorFlow 模型但无法承担携带整个 TensorFlow 包的费用，我们就可以使用它。
- en: Note The TF Lite library is under active development and changes rather quickly.
    It’s possible that the way you install this library has changed since the book
    was published. Please refer to the official documentation for up-to-date instructions
    ([https://www.tensorflow.org/lite/guide/python](https://www.tensorflow.org/lite/guide/python)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：TF Lite 库正在积极开发中，变化相当快。自本书出版以来，安装此库的方式可能已经改变。请参阅官方文档以获取最新说明（[https://www.tensorflow.org/lite/guide/python](https://www.tensorflow.org/lite/guide/python)）。
- en: 'Let’s install the library now. We can do so with `pip`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来安装这个库。我们可以使用 `pip` 来做：
- en: '[PRE0]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: When running `pip` `install`, we add the `extra-index-url` parameter. The library
    we install is not available in the central repository with Python packages, but
    it’s available in a different repository. We need to point to this repository.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行 `pip install` 时，我们添加 `extra-index-url` 参数。我们安装的库不在 Python 包的中央仓库中可用，但它存在于另一个仓库中。我们需要指向这个仓库。
- en: 'Note For non-Debian-based Linux distributions, like CentOS, Fedora, or Amazon
    Linux, the library installed this way might not work: you might get an error when
    trying to import the library. If that’s the case, you need to compile this library
    yourself. Refer to the instructions here for more details: [https://github.com/alexeygrigorev/serverless-deep-learning](https://github.com/alexeygrigorev/serverless-deep-learning).
    For MacOS and Windows, it should work as expected.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：对于非 Debian 基础的 Linux 发行版，如 CentOS、Fedora 或 Amazon Linux，以这种方式安装的库可能不起作用：当你尝试导入库时可能会出错。如果是这种情况，你需要自己编译这个库。有关更多详细信息，请参阅此处说明：[https://github.com/alexeygrigorev/serverless-deep-learning](https://github.com/alexeygrigorev/serverless-deep-learning)。对于
    MacOS 和 Windows，它应该按预期工作。
- en: TF Lite uses a special optimized format for storing models. To use our model
    with TF Lite, we need to convert our model to this format. We’ll do that next.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: TF Lite 使用一种特殊的优化格式来存储模型。为了使用 TF Lite 的模型，我们需要将我们的模型转换为这种格式。我们将在下一步进行转换。
- en: 8.1.2 Converting the model to TF Lite format
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.2 将模型转换为 TF Lite 格式
- en: We used the h5 format for saving the model from the previous chapter. This format
    is suitable for storing Keras models, but it won’t work for TF Lite. So, we need
    to convert our model to TF-Lite format.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 h5 格式保存了前一章中的模型。这种格式适合存储 Keras 模型，但它不适用于 TF Lite。因此，我们需要将我们的模型转换为 TF-Lite
    格式。
- en: 'If you don’t have the model from the previous chapter, go ahead and download
    it:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有前一章中的模型，请继续下载它：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now let’s create a simple script for converting this model—convert.py.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个简单的脚本来转换这个模型——convert.py。
- en: 'First, start with imports:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从导入开始：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, load the Keras model:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，加载 Keras 模型：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'And finally, convert it to TF Lite:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将其转换为 TF Lite：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s run it:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行它：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After running it, we should have a file named clothing-model-v4.tflite in our
    directory.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 运行后，我们应该在我们的目录中有一个名为 clothing-model-v4.tflite 的文件。
- en: We’re ready to use this model now for image classification, applying the model
    to images of clothing to understand if a given image is a T-shirt, pants, a skirt,
    or something else. However, remember that before we can use a model for classifying
    an image, the image needs to be preprocessed. We’ll see how to do that next.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以为此模型进行图像分类，将模型应用于服装图像，以了解给定的图像是否是T恤、裤子、裙子或其他东西。然而，记住在我们可以使用模型对图像进行分类之前，图像需要进行预处理。我们将在下一节中看到如何进行预处理。
- en: 8.1.3 Preparing the images
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.3 准备图像
- en: 'Previously, when testing the model in Keras, we preprocessed each image using
    the `preprocess_input` function. This is how we imported it in the previous chapter:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前，当在Keras中测试模型时，我们使用`preprocess_input`函数对每个图像进行预处理。这是我们在上一章中导入它的方式：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: And then we applied this function to images before we put them into models.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们在将图像放入模型之前应用了这个函数。
- en: However, we can’t use the same function when deploying our model. This function
    is a part of the TensforFlow package, and there’s no equivalent in TF Lite. We
    don’t want to depend on TensorFlow just for this simple preprocessing function.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当部署我们的模型时，我们不能使用相同的函数。这个函数是TensorFlow包的一部分，在TF Lite中没有等效函数。我们不想仅仅为了这个简单的预处理函数就依赖TensorFlow。
- en: 'Instead, we can use a special library that has only the code we need: `keras_`
    `image_helper`. This library was written to simplify the explanation in this book.
    If you want to know how images are pre-processed in more detail, check the source
    code. It’s available at [https://github.com/alexeygrigorev/keras-image-helper](https://github.com/alexeygrigorev/keras-image-helper).
    This library can load an image, resize it, and apply other preprocessing transformations
    that Keras models require.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以使用一个只包含我们需要的代码的特殊库：`keras_image_helper`。这个库是为了简化本书中的解释而编写的。如果您想了解更多关于图像如何进行预处理的详细信息，请查看源代码。它可在[https://github.com/alexeygrigorev/keras-image-helper](https://github.com/alexeygrigorev/keras-image-helper)找到。这个库可以加载图像，调整大小，并应用Keras模型所需的其它预处理转换。
- en: 'Let’s install it with `pip`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`pip`安装它：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Next, open Jupyter, and create a notebook called chapter-08-model-test.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，打开Jupyter，创建一个名为chapter-08-model-test的笔记本。
- en: 'We start by importing the `create_preprocessor` function from the library:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从库中导入`create_preprocessor`函数：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The function `create_preprocessor` takes two arguments:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`create_preprocessor`接受两个参数：
- en: '`name`: The name of the model. You can see the list of available models at
    [https://keras.io/api/applications/](https://keras.io/api/applications/).'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：模型的名称。您可以在[https://keras.io/api/applications/](https://keras.io/api/applications/)中查看可用的模型列表。'
- en: '`target_size`: The size of the image that the neural network expects to get.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_size`：神经网络期望获取的图像大小。'
- en: 'We used the Xception model, and it expects an image of size 299 × 299\. Let’s
    create a preprocessor for our model:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了Xception模型，它期望的图像大小为299 × 299。让我们为我们的模型创建一个预处理程序：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now let’s get a picture of pants (figure 8.2), and prepare it:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们获取一条裤子的图片（图8.2），并对其进行准备：
- en: '[PRE10]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](../Images/08-02.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08-02.png)'
- en: Figure 8.2 The picture of pants that we use for testing
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 我们用于测试的裤子图片
- en: 'The result is a NumPy array of shape (1, 299, 299, 3):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个形状为(1, 299, 299, 3)的NumPy数组：
- en: It’s a batch of one image only.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个仅包含一张图像的批次。
- en: 299 × 299 is the size of the image.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 299 × 299是图像的大小。
- en: 'There are three channels: red, green, and blue.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有三个通道：红色、绿色和蓝色。
- en: We have prepared the image, and we’re ready to use the model for classifying
    it. Let’s see how we can do this with TF Lite.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好了图像，并且准备好使用模型对其进行分类。让我们看看如何使用TF Lite来完成这项工作。
- en: 8.1.4 Using the TensorFlow Lite model
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.4 使用TensorFlow Lite模型
- en: We have the array `X` from the previous step, and now we can use TF Lite for
    classifying it.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有了上一步的数组`X`，现在我们可以使用TF Lite对其进行分类。
- en: 'First, import TF Lite:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入TF Lite：
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Load the model we previously converted:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 加载我们之前转换的模型：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Creates the TF Lite interpreter
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建TF Lite解释器
- en: ❷ Initializes the interpreter with the model
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用模型初始化解释器
- en: 'To be able to use the model, we need to get its input (where `X` will go) and
    the output (where we get the predictions from):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够使用模型，我们需要获取其输入（`X`将放入其中）和输出（我们从其中获取预测结果）：
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '❶ Gets the input: the part of the network that takes in the array X'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取输入：网络中接受数组X的部分
- en: '❷ Gets the output: the part of the network with final predictions'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取输出：网络中具有最终预测的部分
- en: 'To apply the model, take the `X` we previously prepared, put it into the input,
    invoke the interpreter, and get the results from the output:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用模型，将之前准备的`X`放入输入，调用解释器，并从输出获取结果：
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Puts X into the input
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将X放入输入
- en: ❷ Runs the model to get predictions
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 运行模型以获取预测
- en: ❸ Gets the predictions from the output
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 从输出获取预测
- en: 'The `preds` array contains the predictions:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`preds`数组包含预测结果：'
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now we can do the same thing with it as previously—assign the label to each
    element of this array:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以像之前一样使用它——将标签分配给数组的每个元素：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'It’s done! We have the predictions in the `results` variable:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 完成了！我们在`results`变量中有了预测结果：
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We see that the `pants` label has the highest score, so this must be a picture
    of pants.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到`pants`标签的分数最高，所以这肯定是一张裤子的图片。
- en: Let’s now use this code for our future AWS Lambda function!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用这段代码来构建我们未来的AWS Lambda函数！
- en: 8.1.5 Code for the lambda function
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.5 Lambda函数的代码
- en: In the previous section, we wrote all the code we need for the lambda function.
    Let’s put it together in a single script—lambda_function.py.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们编写了lambda函数所需的全部代码。现在让我们将其整合到一个名为lambda_function.py的单个脚本中。
- en: 'As usual, start with imports:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，从导入开始：
- en: '[PRE18]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, create the preprocessor:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，创建预处理程序：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next, load the model, and get the output and input:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，加载模型，获取输出和输入：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To make it a bit cleaner, we can put all the code for making a prediction together
    in one function:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让它更整洁，我们可以将所有生成预测的代码放在一个函数中：
- en: '[PRE21]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, let’s make another function for preparing the results:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们创建另一个用于准备结果的函数：
- en: '[PRE22]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, put everything together in one function—`lambda_handler`—which is
    the function invoked by the AWS Lambda environment. It will use all the things
    we defined previously:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将所有内容整合到一个名为`lambda_handler`的函数中——这是AWS Lambda环境调用的函数。它将使用我们之前定义的所有内容：
- en: '[PRE23]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In this case, the `event` parameter contains all the information we pass to
    the lambda function in our request (figure 8.3). The `context` parameter is typically
    not used.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`event`参数包含我们请求中传递给lambda函数的所有信息（图8.3）。`context`参数通常不使用。
- en: '![](../Images/08-03.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-03.png)'
- en: 'Figure 8.3 The input and the output of the lambda function: the input goes
    to the `event` parameter, and the predictions are returned as the output.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 Lambda函数的输入和输出：输入传递给`event`参数，预测结果作为输出返回。
- en: We’re ready to test it now! To do it locally, we need to put this code into
    the Python Docker container for AWS Lambda.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以开始测试了！为了本地测试，我们需要将此代码放入AWS Lambda的Python Docker容器中。
- en: 8.1.6 Preparing the Docker image
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.6 准备Docker镜像
- en: 'First, create a file named Dockerfile:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建一个名为Dockerfile的文件：
- en: '[PRE24]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ❶ Uses the official Docker image
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用官方Docker镜像
- en: ❷ Installs keras_image_helper
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 安装keras_image_helper
- en: ❸ Installs TF Lite
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 安装TF Lite
- en: ❹ Copies the model
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 复制模型
- en: ❺ Copies the lambda function
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 复制lambda函数
- en: ❻ Defines the location of the lambda function
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 定义lambda函数的位置
- en: 'Let’s take a look at each line of the file. First ❶, we use the official Python
    3.7 Docker image for Lambda from AWS. You can see other available images here:
    [https://gallery.ecr.aws/](https://gallery.ecr.aws/). Then ❷, we install the keras_image_helper
    library.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看文件中的每一行。首先 ❶，我们使用AWS Lambda的官方Python 3.7 Docker镜像。你可以在这里看到其他可用的镜像：[https://gallery.ecr.aws/](https://gallery.ecr.aws/)。然后
    ❷，我们安装keras_image_helper库。
- en: 'Next ❸, we install a special version of TF Lite that was compiled to work with
    Amazon Linux. The installation instructions we used in this chapter earlier don’t
    work for Amazon Linux, only for Ubuntu (and other Debian-based distributions).
    That’s why we need to use a special version. You can read more about it here:
    [https://github.com/alexeygrigorev/serverless-deep-learning.](https://github.com/alexeygrigorev/serverless-deep-learning)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来 ❸，我们安装了一个专门为与Amazon Linux一起工作而编译的TF Lite特殊版本。我们本章前面使用的安装说明在Amazon Linux上不适用，只适用于Ubuntu（以及其他基于Debian的发行版）。这就是为什么我们需要使用特殊版本。你可以在这里了解更多信息：[https://github.com/alexeygrigorev/serverless-deep-learning.](https://github.com/alexeygrigorev/serverless-deep-learning)
- en: Then ❹, we copy the model to the image. When we do so, the model becomes a part
    of the image. This way, it’s simpler to deploy the model. We could use an alternative
    approach—the model can be put to S3 and loaded when the script starts. It’s more
    complex but also more flexible. For the book, we went with the simpler approach.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然后 ❹，我们将模型复制到镜像中。这样做后，模型成为镜像的一部分。这样，部署模型就更加简单。我们也可以使用另一种方法——模型可以放在S3上，在脚本启动时加载。这更复杂，但也更灵活。对于本书，我们选择了更简单的方法。
- en: Then ❺, we copy the code of the lambda function we prepared earlier.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然后 ❺，我们复制之前准备的lambda函数的代码。
- en: Finally ❻, we tell the `lambda` environment that it needs to look for the file
    named lambda_function and look for the function `lambda_handler` inside this function.
    This is the function we prepared in the previous section.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 最后 ❻，我们告诉`lambda`环境需要查找名为lambda_function的文件，并在该文件中查找名为`lambda_handler`的函数。这是我们之前章节中准备的函数。
- en: 'Let’s build this image:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建这个镜像：
- en: '[PRE25]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, we need to check that the lambda function works. Let’s run the image:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要检查lambda函数是否正常工作。让我们运行这个镜像：
- en: '[PRE26]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: It’s running! We can test it now.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 它正在运行！我们现在可以测试它了。
- en: 'We can continue using the Jupyter Notebook we created earlier, or we can create
    a separate Python file named test.py. It should have the following content—and
    you’ll note it’s very similar to the code we wrote in chapter 5 for testing our
    web service:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续使用我们之前创建的Jupyter Notebook，或者我们可以创建一个名为test.py的单独Python文件。它应该包含以下内容——你会注意到它与我们在第5章中为测试我们的网络服务所编写的代码非常相似：
- en: '[PRE27]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ Prepares the request
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ❶准备请求
- en: ❷ Specifies the URL
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❷指定URL
- en: ❸ Sends a POST request to the service
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❸向服务发送POST请求
- en: First, we define the `data` variable in ❶—this is our request. Then we specify
    the URL of the service in ❷—this is the location where the function is currently
    deployed. Finally, in ❸, we use the POST method to submit the request and get
    back the predictions in the `results` variable.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们在❶中定义`data`变量——这是我们请求。然后我们指定服务的URL在❷——这是函数当前部署的位置。最后，在❸中，我们使用POST方法提交请求，并在`results`变量中获取预测结果。
- en: 'When we run it, we get the following response:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行它时，我们得到以下响应：
- en: '[PRE28]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The model works!
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 模型工作正常！
- en: We’re almost ready to deploy it to AWS. To do that, we first need to publish
    this image to ECR—the Docker container registry from AWS.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎准备好将其部署到AWS了。为此，我们首先需要将此镜像发布到ECR——AWS的Docker容器注册表。
- en: 8.1.7 Pushing the image to AWS ECR
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.7 将镜像推送到AWS ECR
- en: 'To publish this Docker image to AWS, we first need to create a registry using
    the AWS CLI tool:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要将此Docker镜像发布到AWS，我们首先需要使用AWS CLI工具创建一个注册表：
- en: '[PRE29]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'It will return back an URL that looks like this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 它将返回一个看起来像这样的URL：
- en: '[PRE30]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: You’ll need this URL.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要这个URL。
- en: Alternatively, it’s possible to create the registry using the AWS Console.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，也可以使用AWS控制台创建注册表。
- en: 'Once the registry is created, we need to push the image there. Because this
    registry belongs to our account, we first need to authenticate our Docker client.
    On Linux and MacOS, you can do this:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建注册表，我们需要将镜像推送到那里。因为这个注册表属于我们的账户，我们首先需要验证我们的Docker客户端。在Linux和MacOS上，你可以这样做：
- en: '[PRE31]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: On Windows, run `aws` `ecr` `get-login` `--no-include-email`, copy the output,
    enter it into the terminal, and execute it manually.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上，运行`aws` `ecr` `get-login` `--no-include-email`，复制输出，将其输入到终端，并手动执行。
- en: 'Now let’s use the registry URL to push the image to ECR:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用注册表URL将镜像推送到ECR：
- en: '[PRE32]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ Specify the region and your AWS account ID.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❶指定区域和您的AWS账户ID。
- en: Now it’s pushed, and we can use it to create a lambda function in AWS.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经推送，我们可以用它来在AWS中创建一个lambda函数。
- en: 8.1.8 Creating the lambda function
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.8 创建lambda函数
- en: This step is easier to do with the AWS Console, so open it, go to services,
    and select Lambda.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个步骤使用AWS控制台更容易完成，所以打开它，转到服务，并选择Lambda。
- en: Next, click Create Function. Select Container Image (figure 8.4).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，点击创建函数。选择容器镜像（图8.4）。
- en: '![](../Images/08-04.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-04.png)'
- en: Figure 8.4 When creating a `lambda` function, select Container Image.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.4 创建`lambda`函数时，选择容器镜像。
- en: After that, fill in the details (figure 8.5).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，填写详细信息（图8.5）。
- en: '![](../Images/08-05.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-05.png)'
- en: Figure 8.5 Enter the function name and the container image URI.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.5 输入函数名称和容器镜像URI。
- en: 'The container image URI should be the image we created earlier and pushed to
    ECR:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 容器镜像URI应该是我们之前创建并推送到ECR的镜像：
- en: '[PRE33]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You can use the Browse Images button to find it (figure 8.5). Keep the rest
    unchanged, and click Create Function. The function is created!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用浏览图片按钮找到它（图8.5）。其余部分保持不变，然后点击创建函数。函数已创建！
- en: Now we need to give our function more memory and let it run for a longer time
    without timing out. For that, select the Configuration tab, choose General Configuration,
    and then click Edit (figure 8.6).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要给我们的函数更多的内存，并让它运行更长的时间而不超时。为此，选择配置选项卡，选择常规配置，然后点击编辑（图8.6）。
- en: '![](../Images/08-06.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-06.png)'
- en: 'Figure 8.6 The default settings of a lambda function: the default amount of
    memory (128 MB) is not enough, so we need to increase it. Click Edit to do so.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.6 Lambda函数的默认设置：默认的内存量（128 MB）不足，因此我们需要增加它。点击编辑来进行修改。
- en: The default settings are not good for deep learning models. We need to configure
    this function to give it more RAM and allow it to take more time.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 默认设置对深度学习模型来说不好。我们需要配置这个函数，给它更多的RAM，并允许它有更多的时间。
- en: For that, click the Edit button, give it 1024 MB of RAM, and set the timeout
    to 30 seconds (figure 8.7).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 为了这样做，点击编辑按钮，给它1024 MB的RAM，并将超时设置为30秒（图8.7）。
- en: '![](../Images/08-07.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-07.png)'
- en: Figure 8.7 Increase the amount of memory to 1024 MB and set the timeout to 30
    seconds.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.7 将内存量增加到1024 MB，并将超时设置为30秒。
- en: Save it.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 保存它。
- en: It’s ready! To test it, go to the Test tab (figure 8.8).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 已准备好！要测试它，请转到“测试”标签页（图8.8）。
- en: '![](../Images/08-08.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-08.png)'
- en: Figure 8.8 The Test button is located at the top of the screen. Click it to
    test the function.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.8 测试按钮位于屏幕顶部。点击它以测试函数。
- en: 'It’ll suggest creating a test event. Give it a name (for example, test), and
    put the following content in the request body:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 它会建议创建一个测试事件。给它起个名字（例如，test），并在请求体中放入以下内容：
- en: '[PRE34]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Save it and click the Test button again. After approximately 15 seconds, you
    should see “Execution results: succeeded” (figure 8.9).'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 保存并再次点击“测试”按钮。大约15秒后，你应该会看到“执行结果：成功”（图8.9）。
- en: '![](../Images/08-09.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-09.png)'
- en: Figure 8.9 The predictions of our model. The prediction for `pants` has the
    highest score.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.9 我们模型的预测。对于“裤子”的预测得分最高。
- en: When we run the test for the first time, it needs to pull the image from ECR,
    load all the libraries in memory, and do some other things to “warm up.” But once
    it’s done it, the consequent invocations take less time—approximately two seconds
    for this model.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们第一次运行测试时，它需要从ECR拉取镜像，将所有库加载到内存中，并做一些其他事情以“预热”。但一旦完成，后续的调用所需时间会更少——这个模型大约需要两秒钟。
- en: We have successfully deployed our model to AWS Lambda, and it’s working!
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功将模型部署到AWS Lambda，并且它正在运行！
- en: Also, remember that you pay only when the function is invoked, so you don’t
    need to worry about deleting this function if it’s not used. And you don’t need
    to worry about managing EC2 instances at all—AWS Lambda takes care of everything
    for us.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请记住，你只有在函数被调用时才需要付费，所以如果你没有使用这个函数，你不需要担心删除它。而且你也不需要担心管理EC2实例——AWS Lambda会为我们处理一切。
- en: 'It’s already possible to use this model for many things: AWS Lambda integrates
    well with a lot of other services from AWS. But if we want to use it as a web
    service and send requests over HTTP, we need to expose it through API Gateway.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 已经可以使用这个模型做很多事情：AWS Lambda与AWS的许多其他服务很好地集成。但如果我们想将其作为Web服务并通过HTTP发送请求，我们需要通过API网关将其公开。
- en: We’ll see how to do this next.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一部分展示如何进行这项操作。
- en: 8.1.9 Creating the API Gateway
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.9 创建API网关
- en: 'In the AWS Console, find the API Gateway service. Create a new API: select
    REST API, and click Build.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS控制台中，找到API网关服务。创建一个新的API：选择REST API，并点击“构建”。
- en: Then select New API, and call it clothes-classification (figure 8.10). Click
    Create API.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 然后选择“新建API”，将其命名为“clothes-classification”（图8.10）。点击“创建API”。
- en: '![](../Images/08-10.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-10.png)'
- en: Figure 8.10 Creating a new REST API Gateway in AWS
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.10 在AWS中创建新的REST API网关
- en: Next, click the Actions button and select Resource. Then, create a resource
    predict (figure 8.11).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，点击“操作”按钮并选择“资源”。然后，创建一个名为predict的资源（图8.11）。
- en: '![](../Images/08-11.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-11.png)'
- en: Figure 8.11 Creating a predict resource
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.11 创建预测资源
- en: 'Note The name predict doesn’t follow the REST naming standards: usually resources
    should be nouns. However, it’s common to name endpoints for predictions as predict;
    that’s why we don’t follow the REST convention.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：predict这个名字不符合REST命名规范：通常资源应该是名词。然而，将预测端点命名为predict是常见的；这就是为什么我们不遵循REST规范。
- en: 'After creating the resource, create a POST method for it (figure 8.12):'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 创建资源后，为它创建一个POST方法（图8.12）：
- en: Click Predict.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“预测”。
- en: Click Actions.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“操作”。
- en: Select Create Method.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“创建方法”。
- en: Choose POST from the list.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从列表中选择POST。
- en: Click the tick button.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击勾选按钮。
- en: '![](../Images/08-12.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-12.png)'
- en: Figure 8.12 Create a POST method for the predict resource.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.12 为预测资源创建一个POST方法。
- en: We’re almost ready!
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎准备好了！
- en: Now select Lambda Function as the integration type and enter the name of your
    lambda function (figure 8.13).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将Lambda函数作为集成类型，并输入你的lambda函数名称（图8.13）。
- en: '![](../Images/08-13.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-13.png)'
- en: Figure 8.13 Configuring the POST action for the predict resource. Make sure
    Proxy Integration is not checked.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.13 为预测资源配置POST操作。确保不要勾选“代理集成”。
- en: Note Make sure you don’t use proxy integration—this checkbox should remain unchecked.
    If you use this option, API Gateway adds some extra information to the request,
    and we would need to adjust the lambda function.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：确保不要使用代理集成——这个复选框应该保持未勾选状态。如果你使用这个选项，API网关会在请求中添加一些额外的信息，我们就需要调整lambda函数。
- en: After doing this, we should see the integration (figure 8.14).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些操作后，我们应该能看到集成（图8.14）。
- en: '![](../Images/08-14.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-14.png)'
- en: Figure 8.14  Deploying the API
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.14 部署API
- en: 'Let’s test it. Click TEST, and put the same request in the request body as
    previously:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下。点击 TEST，并在请求体中放入之前相同的请求：
- en: '[PRE35]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The response is the same: the predicted class is `pants` (figure 8.15).'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 响应相同：预测的类别是 `pants`（图 8.15）。
- en: '![](../Images/08-15.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-15.png)'
- en: Figure 8.15 The response from the lambda function. The `pants` category has
    the highest score.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.15 lambda 函数的响应。`pants` 类别的分数最高。
- en: To use it externally, we need to deploy the API. Select Deploy API from the
    list of actions (figure 8.16).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要在外部使用它，我们需要部署 API。从操作列表中选择部署 API（图 8.16）。
- en: '![](../Images/08-16.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-16.png)'
- en: Figure 8.16 The function `clothes-classification` is now connected to the POST
    method of the predict resource in the API Gateway. The TEST button helps with
    verifying that the connection with lambda works.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.16 函数 `clothes-classification` 现在已连接到 API Gateway 中的 predict 资源的 POST 方法。TEST
    按钮有助于验证与 lambda 的连接。
- en: Next, create a new stage test (figure 8.17).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建一个新的阶段测试（图 8.17）。
- en: '![](../Images/08-17.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/08-17.png)'
- en: Figure 8.17 Configuring the stage for the API
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.17 配置 API 的阶段
- en: 'By clicking Deploy, we deploy the API. Now find the Invoke URL field. It should
    look like this:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 点击部署，我们部署了 API。现在找到调用 URL 字段。它应该看起来像这样：
- en: '[https://0a1v3fyo2m.execute-api.eu-west-1.amazonaws.com/test](https://0a1v3fyo2m.execute-api.eu-west-1.amazonaws.com/test)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://0a1v3fyo2m.execute-api.eu-west-1.amazonaws.com/test](https://0a1v3fyo2m.execute-api.eu-west-1.amazonaws.com/test)'
- en: All we need to do now to invoke the lambda function is to add “/predict” at
    the end of this URL.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只需要在 URL 末尾添加“/predict”即可调用 lambda 函数。
- en: 'Let’s take the test.py script we created previously and replace the URL there:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用之前创建的 test.py 脚本并替换那里的 URL：
- en: '[PRE36]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Run it:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 运行它：
- en: '[PRE37]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The response is the same as previously:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 响应与之前相同：
- en: '[PRE38]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Now our model is exposed with a web service that we can use from anywhere.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的模型通过一个我们可以从任何地方使用的网络服务公开。
- en: 8.2 Next steps
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 下一步
- en: 8.2.1 Exercises
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 练习
- en: 'Try the following to further explore the topics of serverless model deployment:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试以下操作以进一步探索无服务器模型部署的主题：
- en: AWS Lambda is not the only serverless environment. You can also experiment with
    cloud functions in Google Cloud and Azure functions on Azure.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Lambda 不是唯一的无服务器环境。你还可以在 Google Cloud 中实验云函数，以及在 Azure 上的 Azure 函数。
- en: SAM (Serverless Application Model) is a tool from AWS for making the process
    of creating AWS Lambda functions easier ([https://aws.amazon.com/serverless /sam/](https://aws.amazon.com/serverless/sam/)).
    You can use it to reimplement the project from this chapter.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SAM（Serverless Application Model）是 AWS 的一项工具，用于简化创建 AWS Lambda 函数的过程([https://aws.amazon.com/serverless/sam/](https://aws.amazon.com/serverless/sam/))。你可以使用它来重新实现本章的项目。
- en: Serverless ([https://www.serverless.com/](https://www.serverless.com/)) is a
    framework similar to SAM. It’s not specific to AWS and works for other cloud providers.
    You can experiment with it and deploy the project from this chapter.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器([https://www.serverless.com/](https://www.serverless.com/))是一个类似于 SAM 的框架。它不仅限于
    AWS，也适用于其他云服务提供商。你可以尝试它，并从本章部署项目。
- en: 8.2.2 Other projects
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 其他项目
- en: 'You can do many other projects:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以做很多其他项目：
- en: AWS Lambda is a convenient platform for hosting machine learning models. In
    this chapter, we deployed a deep learning model. You can also experiment with
    it more and deploy the models we trained in the previous chapters as well as the
    models you developed as a part of the exercises.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS Lambda 是托管机器学习模型的便捷平台。在本章中，我们部署了一个深度学习模型。你也可以进一步实验，并将我们在前几章训练的模型以及作为练习一部分开发的模型部署。
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: TensorFlow Lite is a lightweight alternative to “full” TensorFlow. It contains
    only the most important parts that are needed for using deep learning models.
    Using it makes the process of deploying models with AWS Lambda faster and simpler.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Lite 是“完整”TensorFlow 的轻量级替代品。它只包含使用深度学习模型所需的最重要部分。使用它可以使使用 AWS Lambda
    部署模型的过程更快、更简单。
- en: Lambda functions can be run locally using Docker. This way, we can test our
    code without deploying it to AWS.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lambda 函数可以在本地使用 Docker 运行。这样，我们可以在不部署到 AWS 的情况下测试我们的代码。
- en: To deploy a lambda function, we need to put its code in Docker, publish the
    Docker image to ECR, and then use the URI of the image when creating a lambda
    function.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要部署 lambda 函数，我们需要将其代码放入 Docker 中，将 Docker 镜像发布到 ECR，然后在创建 lambda 函数时使用镜像的 URI。
- en: To expose the lambda function, we use API Gateway. This way, we make the lambda
    function available as a web service, so it could be used by anyone.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了暴露 Lambda 函数，我们使用了 API Gateway。这样，我们将 Lambda 函数作为一项网络服务提供，任何人都可以使用它。
- en: In this chapter, we’ve used AWS Lambda—the serverless approach for deploying
    deep learning models. We didn’t want to worry about servers and let the environment
    worry about it instead.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用了 AWS Lambda——一种用于部署深度学习模型的免服务器方法。我们不想担心服务器，而是让环境来处理这个问题。
- en: In the next chapter, we actually think about servers, and we use a Kubernetes
    cluster for deploying a model.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们实际上开始考虑服务器，并使用 Kubernetes 集群来部署模型。
