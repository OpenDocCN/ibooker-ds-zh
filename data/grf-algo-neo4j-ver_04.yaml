- en: Chapter 3\. Graph Platforms and Processing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章。图平台和处理
- en: In this chapter, we’ll quickly cover different methods for graph processing
    and the most common platform approaches. We’ll look more closely at the two platforms
    used in this book, Apache Spark and Neo4j, and when they may be appropriate for
    different requirements. Platform installation guidelines are included to prepare
    you for the next several chapters.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将快速介绍图处理的不同方法和最常见的平台方法。我们将更仔细地查看本书中使用的两个平台，Apache Spark 和 Neo4j，以及它们在不同需求下的适用情况。平台安装指南将为您准备好接下来的几章。
- en: Graph Platform and Processing Considerations
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图平台和处理考虑因素
- en: Graph analytical processing has unique qualities such as computation that is
    structure-driven, globally focused, and difficult to parse. In this section we’ll
    look at the general considerations for graph platforms and processing.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图分析处理具有结构驱动、全局聚焦和难以解析等独特特性。在本节中，我们将讨论图平台和处理的一般考虑因素。
- en: Platform Considerations
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平台考虑因素
- en: There’s debate as to whether it’s better to scale up or scale out graph processing.
    Should you use powerful multicore, large-memory machines and focus on efficient
    data structures and multithreaded algorithms? Or are investments in distributed
    processing frameworks and related algorithms worthwhile?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人们对于图处理是扩展还是分布式处理更好存在争论。您应该使用强大的多核大内存机器，并专注于高效的数据结构和多线程算法吗？还是投资于分布式处理框架和相关算法值得？
- en: A useful evaluation approach is the *Configuration that Outperforms a Single
    Thread* (COST), as described in the research paper [“Scalability! But at What
    COST?”](https://bit.ly/2Ypjhyv) by F. McSherry, M. Isard, and D. Murray. COST
    provides us with a way to compare a system’s scalability with the overhead the
    system introduces. The core concept is that a well-configured system using an
    optimized algorithm and data structure can outperform current general-purpose
    scale-out solutions. It’s a method for measuring performance gains without rewarding
    systems that mask inefficiencies through parallelization. Separating the ideas
    of scalability and efficient use of resources will help us build a platform configured
    explicitly for our needs.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有用的评估方法是《超越单线程的配置》（COST），如F. McSherry、M. Isard和D. Murray在研究论文《可扩展性！但以何种代价？》中所述。COST为我们提供了一种比较系统可扩展性与系统引入的开销的方法。其核心概念是，使用优化的算法和数据结构的良好配置系统可以胜过当前通用的扩展解决方案。这是一种测量性能增益的方法，而不是奖励通过并行化掩盖低效率的系统。将可扩展性和资源有效利用的分离概念将帮助我们构建一个专门为我们的需求配置的平台。
- en: Some approaches to graph platforms include highly integrated solutions that
    optimize algorithms, processing, and memory retrieval to work in tighter coordination.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一些图平台方法包括高度集成的解决方案，优化算法、处理和内存检索以在更紧密的协调中工作。
- en: Processing Considerations
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理考虑因素
- en: 'There are different approaches for expressing data processing; for example,
    stream or batch processing or the map-reduce paradigm for records-based data.
    However, for graph data, there also exist approaches which incorporate the data
    dependencies inherent in graph structures into their processing:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 表达数据处理的不同方法存在不同的方法；例如，流处理或批处理或基于记录的数据的映射-减少范式。然而，对于图数据，还存在将图结构中的数据依赖性纳入其处理的方法：
- en: Node-centric
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以节点为中心的
- en: This approach uses nodes as processing units, having them accumulate and compute
    state and communicate state changes via messages to their neighbors. This model
    uses the provided transformation functions for more straightforward implementations
    of each algorithm.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法使用节点作为处理单元，使其通过消息将状态的积累和计算状态变化传递给它们的邻居。这种模型使用提供的转换函数来更简单地实现每个算法。
- en: Relationship-centric
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 以关系为中心的
- en: This approach has similarities with the node-centric model but may perform better
    for subgraph and sequential analysis.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法与节点为中心的模型有相似之处，但对子图和顺序分析可能性能更好。
- en: Graph-centric
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以图为中心的
- en: These models process nodes within a subgraph independently of other subgraphs
    while (minimal) communication to other subgraphs happens via messaging.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型独立处理子图内的节点，而与其他子图的（最小）通信通过消息传递进行。
- en: Traversal-centric
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以遍历为中心的
- en: These models use the accumulation of data by the traverser while navigating
    the graph as their means of computation.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型利用遍历者在导航图时累积数据作为它们的计算手段。
- en: Algorithm-centric
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以算法为中心的
- en: These approaches use various methods to optimize implementations per algorithm.
    This is a hybrid of the previous models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法使用各种方法来优化每个算法的实现。这是前几种模型的混合体。
- en: Note
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '[*Pregel*](https://bit.ly/2Twj9sY) is a node-centric, fault-tolerant parallel
    processing framework created by Google for performant analysis of large graphs.
    Pregel is based on the *bulk synchronous parallel* (BSP) model. BSP simplifies
    parallel programming by having distinct computation and communication phases.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[*Pregel*](https://bit.ly/2Twj9sY) 是由Google创建的基于节点中心的、容错的并行处理框架，用于大规模图的高效分析。Pregel基于*批量同步并行*（BSP）模型。BSP通过具有明确的计算和通信阶段简化了并行编程。'
- en: Pregel adds a node-centric abstraction atop BSP whereby algorithms compute values
    from incoming messages from each node’s neighbors. These computations are executed
    once per iteration and can update node values and send messages to other nodes.
    The nodes can also combine messages for transmission during the communication
    phase, which helpfully reduces the amount of network chatter. The algorithm completes
    when either no new messages are sent or a set limit has been reached.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Pregel 在BSP之上添加了一个以节点为中心的抽象，算法通过每个节点邻居发送的传入消息计算值。这些计算每次迭代执行一次，可以更新节点值并向其他节点发送消息。节点还可以在通信阶段组合消息以减少网络通信量。算法在不再发送新消息或达到设定的限制时完成。
- en: Most of these graph-specific approaches require the presence of the entire graph
    for efficient cross-topological operations. This is because separating and distributing
    the graph data leads to extensive data transfers and reshuffling between worker
    instances. This can be difficult for the many algorithms that need to iteratively
    process the global graph structure.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数这些专门用于图的方法需要整个图的存在以进行高效的跨拓扑操作。这是因为将图数据分离和分布会导致工作者实例之间的大量数据传输和重新排序。这对需要迭代处理全局图结构的许多算法来说可能会很困难。
- en: Representative Platforms
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代表性平台
- en: 'To address the requirements of graph processing, several platforms have emerged.
    Traditionally there was a separation between graph compute engines and graph databases,
    which required users to move their data depending on their process needs:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足图处理的需求，出现了几个平台。传统上，图计算引擎和图数据库是分开的，用户需要根据其处理需求移动其数据：
- en: Graph compute engines
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图计算引擎
- en: These are read-only, nontransactional engines that focus on efficient execution
    of iterative graph analytics and queries of the whole graph. Graph compute engines
    support different definition and processing paradigms for graph algorithms, like
    node-centric (e.g., Pregel, Gather-Apply-Scatter) or MapReduce-based approaches
    (e.g., PACT). Examples of such engines are Giraph, GraphLab, Graph-Engine, and
    Apache Spark.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是只读的、非事务性引擎，专注于整个图的迭代图分析和查询的高效执行。图计算引擎支持不同的图算法定义和处理范式，如节点中心（例如Pregel，Gather-Apply-Scatter）或基于MapReduce的方法（例如PACT）。此类引擎的示例包括Giraph、GraphLab、Graph-Engine和Apache
    Spark。
- en: Graph databases
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图数据库
- en: From a transactional background, these focus on fast writes and reads using
    smaller queries that generally touch a small fraction of a graph. Their strengths
    are in operational robustness and high concurrent scalability for many users.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从事务背景出发，这些方法侧重于使用较小的查询进行快速写入和读取，通常仅涉及图的一小部分。它们的优势在于操作的稳健性和对许多用户的高并发可扩展性。
- en: Selecting Our Platform
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择我们的平台
- en: Choosing a production platform involves many considersations, such as the type
    of analysis to be run, performance needs, the existing environment, and team preferences.
    We use Apache Spark and Neo4j to showcase graph algorithms in this book because
    they both offer unique advantages.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 选择生产平台涉及许多考虑因素，如要运行的分析类型、性能需求、现有环境和团队偏好。我们在本书中使用Apache Spark和Neo4j展示图算法，因为它们都具有独特的优势。
- en: 'Spark is an example of a scale-out and node-centric graph compute engine. Its
    popular computing framework and libraries support a variety of data science workflows.
    Spark may be the right platform when our:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Spark是一个例子，它是一个分布式的、节点中心的图计算引擎。其流行的计算框架和库支持各种数据科学工作流。当我们：
- en: Algorithms are fundamentally parallelizable or partitionable.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法基本上是可并行化或可分区的。
- en: Algorithm workflows need “multilingual” operations in multiple tools and languages.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法工作流需要在多个工具和语言中进行“多语言”操作。
- en: Analysis can be run offline in batch mode.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以离线批处理运行分析。
- en: Graph analysis is on data not transformed into a graph format.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图分析涉及未转换为图格式的数据时。
- en: Team needs and has the expertise to code and implement their own algorithms.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 团队需要并具备编写和实现自己算法的专业知识时。
- en: Team uses graph algorithms infrequently.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 团队偶尔使用图形算法时。
- en: Team prefers to keep all data and analysis within the Hadoop ecosystem.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 希望将所有数据和分析保留在Hadoop生态系统内时。
- en: 'The Neo4j Graph Platform is an example of a tightly integrated graph database
    and algorithm-centric processing, optimized for graphs. It is popular for building
    graph-based applications and includes a graph algorithms library tuned for its
    native graph database. Neo4j may be the right platform when our:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[Neo4j图平台](https://example.org/neo4j_graph_platform)是一个紧密集成的图数据库和以算法为中心的处理的示例，优化用于图形的应用程序构建。它因构建基于图形的应用程序而受欢迎，并包括针对其本机图数据库优化的图形算法库。当我们的团队：'
- en: Algorithms are more iterative and require good memory locality.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法更为迭代且需要良好的内存局部性时。
- en: Algorithms and results are performance sensitive.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法和结果对性能敏感。
- en: Graph analysis is on complex graph data and/or requires deep path traversal.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图分析涉及复杂图数据和/或需要深度路径遍历时。
- en: Analysis/results are integrated with transactional workloads.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析/结果与事务工作负载集成时。
- en: Results are used to enrich an existing graph.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果用于丰富现有图形。
- en: Team needs to integrate with graph-based visualization tools.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 团队需要与基于图形的可视化工具集成时。
- en: Team prefers prepackaged and supported algorithms.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 团队更喜欢预打包和支持的算法时。
- en: 'Finally, some organizations use both Neo4j and Spark for graph processing:
    Spark for the high-level filtering and preprocessing of massive datasets and data
    integration, and Neo4j for more specific processing and integration with graph-based
    applications.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一些组织同时使用Neo4j和Spark进行图处理：Spark用于大规模数据集的高级过滤和预处理以及数据集成，而Neo4j则用于更具体的处理和与基于图形的应用程序集成。
- en: Apache Spark
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache Spark
- en: Apache Spark (henceforth just Spark) is an analytics engine for large-scale
    data processing. It uses a table abstraction called a DataFrame to represent and
    process data in rows of named and typed columns. The platform integrates diverse
    data sources and supports languages such as Scala, Python, and R. Spark supports
    various analytics libraries, as shown in [Figure 3-1](#spark-platform). Its memory-based
    system operates by using efficiently distributed compute graphs.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Spark（以下简称Spark）是一个用于大规模数据处理的分析引擎。它使用称为DataFrame的表抽象来表示和处理以命名和类型化列的行数据。该平台集成了多种数据源，并支持Scala、Python和R等多种编程语言。Spark支持各种分析库，如[图3-1](#spark-platform)所示。其基于内存的系统通过高效分布式计算图操作。
- en: 'GraphFrames is a graph processing library for Spark that succeeded GraphX in
    2016, although it is separate from the core Apache Spark. GraphFrames is based
    on GraphX, but uses DataFrames as its underlying data structure. GraphFrames has
    support for the Java, Scala, and Python programming languages. In spring 2019,
    the “Spark Graph: Property Graphs, Cypher Queries, and Algorithms” proposal was
    accepted (see [“Spark Graph Evolution”](#future-graphs-spark)). We expect this
    to bring a number of graph features using the DataFrame framework and Cypher query
    language into the core Spark project. However, in this book our examples will
    be based on the Python API (PySpark) because of its current popularity with Spark
    data scientists.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: GraphFrames是一个用于Spark的图处理库，于2016年取代了GraphX，尽管它与核心Apache Spark是分开的。GraphFrames基于GraphX，但使用DataFrame作为其底层数据结构。GraphFrames支持Java、Scala和Python编程语言。2019年春，“Spark图形：属性图、Cypher查询和算法”提案被接受（参见[“Spark图形演变”](#future-graphs-spark)）。我们预计这将通过DataFrame框架和Cypher查询语言为核心Spark项目引入多个图特性。然而，在本书中，我们的示例将基于Python
    API（PySpark），因为它目前在Spark数据科学家中非常流行。
- en: '![gral 0301](Images/gral_0301.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0301](Images/gral_0301.png)'
- en: Figure 3-1\. Spark is an open-source distributed and general-purpose clustercomputing
    framework. It includes several modules for various workloads.
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1。Spark是一个开源的分布式通用集群计算框架。它包括多个模块，用于处理各种工作负载。
- en: Nodes and relationships are represented as DataFrames with a unique ID for each
    node and a source and destination node for each relationship. We can see an example
    of a nodes DataFrame in [Table 3-1](#ch3-nodes-dataframe) and a relationships
    DataFrame in [Table 3-2](#ch3-rels-dataframe). A GraphFrame based on these DataFrames
    would have two nodes, `JFK` and `SEA`, and one relationship, from `JFK` to `SEA`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 节点和关系分别表示为带有每个节点唯一标识符以及每个关系源和目标节点的数据框。我们可以在[表 3-1](#ch3-nodes-dataframe)中看到一个节点数据框的示例，以及在[表 3-2](#ch3-rels-dataframe)中看到一个关系数据框的示例。基于这些数据框的
    GraphFrame 将包含两个节点，`JFK` 和 `SEA`，以及一个关系，从 `JFK` 到 `SEA`。
- en: Table 3-1\. Nodes DataFrame
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-1\. 节点数据框
- en: '| id | city | state |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| id | 城市 | 状态 |'
- en: '| --- | --- | --- |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| JFK | New York | NY |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| JFK | 纽约 | 纽约州 |'
- en: '| SEA | Seattle | WA |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| SEA | 西雅图 | 华盛顿州 |'
- en: Table 3-2\. Relationships DataFrame
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3-2\. 关系数据框
- en: '| src | dst | delay | tripId |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| src | dst | delay | tripId |'
- en: '| --- | --- | --- | --- |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| JFK | SEA | 45 | 1058923 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| JFK | SEA | 45 | 1058923 |'
- en: The nodes DataFrame must have an `id` column—the value in this column is used
    to uniquely identify each node. The relationships DataFrame must have `src` and
    `dst` columns—the values in these columns describe which nodes are connected and
    should refer to entries that appear in the `id` column of the nodes DataFrame.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 节点数据框必须具有 `id` 列——此列中的值用于唯一标识每个节点。关系数据框必须具有 `src` 和 `dst` 列——这些列中的值描述了连接的节点，并应引用节点数据框的
    `id` 列中出现的条目。
- en: The nodes and relationships DataFrames can be loaded using any of the [DataFrame
    data sources](http://bit.ly/2CN7LDV), including Parquet, JSON, and CSV. Queries
    are described using a combination of the PySpark API and Spark SQL.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 节点和关系数据框可以使用任何[数据框数据源](http://bit.ly/2CN7LDV)（包括 Parquet、JSON 和 CSV）加载。查询使用
    PySpark API 和 Spark SQL 结合描述。
- en: GraphFrames also provides users with [an extension point](http://bit.ly/2Wo6Hxg)
    to implement algorithms that aren’t available out of the box.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: GraphFrames 还为用户提供了[一个扩展点](http://bit.ly/2Wo6Hxg)，以实现默认不可用的算法。
- en: Installing Spark
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 Spark
- en: 'You can download Spark from the [Apache Spark website](http://bit.ly/1qnQ5zb).
    Once you’ve downloaded it, you need to install the following libraries to execute
    Spark jobs from Python:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[Apache Spark 网站](http://bit.ly/1qnQ5zb)下载 Spark。下载完成后，您需要安装以下库以从 Python
    执行 Spark 作业：
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can then launch the *pyspark* REPL by executing the following command:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过执行以下命令启动 *pyspark* REPL：
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: At the time of writing the latest released version of Spark is *spark-2.4.0-bin-hadoop2.7*,
    but that may have changed by the time you read this. If so, be sure to change
    the `SPARK_VERSION` environment variable appropriately.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，最新发布的 Spark 版本为 *spark-2.4.0-bin-hadoop2.7*，但在您阅读本文时可能已经有所改变。如果是这样，请确保相应更改
    `SPARK_VERSION` 环境变量。
- en: Note
  id: totrans-73
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Although Spark jobs should be executed on a cluster of machines, for demonstration
    purposes we’re only going to execute the jobs on a single machine. You can learn
    more about running Spark in production environments in [*Spark: The Definitive
    Guide*](http://shop.oreilly.com/product/0636920034957.do), by Bill Chambers and
    Matei Zaharia (O’Reilly).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然 Spark 作业应在一组机器上执行，但出于演示目的，我们仅在单台机器上执行作业。您可以在《*Spark: The Definitive Guide*》（O’Reilly
    出版）中了解更多关于在生产环境中运行 Spark 的信息。'
- en: You’re now ready to learn how to run graph algorithms on Spark.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以学习如何在 Spark 上运行图算法了。
- en: Neo4j Graph Platform
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Neo4j 图平台
- en: The Neo4j Graph Platform supports transactional processing and analytical processing
    of graph data. It includes graph storage and compute with data management and
    analytics tooling. The set of integrated tools sits on top of a common protocol,
    API, and query language (Cypher) to provide effective access for different uses,
    as shown in [Figure 3-2](#neo4j-graph-platform).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j 图平台支持图数据的事务处理和分析处理。它包括具有数据管理和分析工具的图存储和计算。一组集成工具基于通用协议、API 和查询语言（Cypher），为不同用途提供有效访问，如[图 3-2](#neo4j-graph-platform)所示。
- en: '![gral 0302](Images/gral_0302.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0302](Images/gral_0302.png)'
- en: Figure 3-2\. The Neo4j Graph Platform is built around a native graph database
    that supports transactional applications and graph analytics.
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-2\. Neo4j 图平台建立在原生图数据库之上，支持事务应用和图分析。
- en: In this book, we’ll be using the [Neo4j Graph Algorithms library](https://bit.ly/2uonX9Y).
    The library is installed as a plug-in alongside the database and provides a set
    of [user-defined procedures](https://bit.ly/2OmidGK) that can be executed via
    the Cypher query language.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将使用[Neo4j 图算法库](https://bit.ly/2uonX9Y)。该库作为数据库的插件安装，并提供一组[用户定义的过程](https://bit.ly/2OmidGK)，可以通过
    Cypher 查询语言执行。
- en: The graph algorithm library includes parallel versions of algorithms supporting
    graph analytics and machine learning workflows. The algorithms are executed on
    top of a task -based parallel computation framework and are optimized for the
    Neo4j platform. For different graph sizes there are internal implementations that
    scale up to tens of billions of nodes and relationships.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图算法库包括支持图分析和机器学习工作流程的并行版本算法。这些算法在基于任务的并行计算框架之上执行，并针对 Neo4j 平台进行了优化。对于不同的图大小，有内部实现可以扩展到数百亿个节点和关系。
- en: Results can be streamed to the client as a tuples stream and tabular results
    can be used as a driving table for further processing. Results can also be optionally
    written back to the database efficiently as node properties or relationship types.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 结果可以作为元组流直接传输到客户端，并且表格结果可以用作进一步处理的驱动表。结果还可以选择以节点属性或关系类型的形式有效地写回到数据库。
- en: Note
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In this book, we’ll also be using the [Neo4j Awesome Procedures on Cypher (APOC)
    library](https://bit.ly/2JDfSbS). APOC consists of more than 450 procedures and
    functions to help with common tasks such as data integration, data conversion,
    and model refactoring.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们还将使用[Neo4j Cypher 的 Awesome Procedures on Cypher (APOC) 库](https://bit.ly/2JDfSbS)。APOC
    包含超过 450 个过程和函数，用于帮助处理常见任务，如数据集成、数据转换和模型重构。
- en: Installing Neo4j
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 Neo4j
- en: Neo4j Desktop is a convenient way for developers to work with local Neo4j databases.
    It can be downloaded from the [Neo4j website](https://neo4j.com/download/). The
    graph algorithms and APOC libraries can be installed as plug-ins once you’ve installed
    and launched the Neo4j Desktop. In the lefthand menu, create a project and select
    it. Then click Manage on the database where you want to install the plug-ins.
    On the Plugins tab, you’ll see options for several plug-ins. Click the Install
    button for graph algorithms and APOC. See Figures [3-3](#install-graph-algos)
    and [3-4](#install-apoc).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j Desktop 是开发人员与本地 Neo4j 数据库进行交互的便捷方式。可以从[Neo4j 网站](https://neo4j.com/download/)下载。一旦安装并启动了
    Neo4j Desktop，可以安装图算法和 APOC 库作为插件。在左侧菜单中，创建项目并选择它。然后点击要安装插件的数据库上的“管理”。在插件选项卡上，您将看到几个插件选项。点击图算法和
    APOC 的安装按钮。参见图 [3-3](#install-graph-algos) 和 [3-4](#install-apoc)。
- en: '![gral 0303](Images/gral_0303.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0303](Images/gral_0303.png)'
- en: Figure 3-3\. Installing the graph algorithms library
  id: totrans-88
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-3\. 安装图算法库
- en: '![gral 0304](Images/gral_0304.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![gral 0304](Images/gral_0304.png)'
- en: Figure 3-4\. Installing the APOC library
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 3-4\. 安装 APOC 库
- en: Jennifer Reif explains the installation process in more detail in her blog post
    [“Explore New Worlds—Adding Plugins to Neo4j”](https://bit.ly/2TU0Lj3). You’re
    now ready to learn how to run graph algorithms in Neo4j.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Jennifer Reif 在她的博客文章[“探索新世界——向 Neo4j 添加插件”](https://bit.ly/2TU0Lj3)中更详细地解释了安装过程。现在，您已经准备好学习如何在
    Neo4j 中运行图算法了。
- en: Summary
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In the previous chapters we’ve described why graph analytics is important to
    studying real-world networks and looked at fundamental graph concepts, analysis,
    and processing. This puts us on solid footing for understanding how to apply graph
    algorithms. In the next chapters, we’ll discover how to run graph algorithms with
    examples in Spark and Neo4j.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们已经描述了为什么图分析对研究现实世界的网络至关重要，并介绍了基本的图概念、分析和处理。这使我们在理解如何应用图算法方面有了坚实的基础。在接下来的章节中，我们将通过
    Spark 和 Neo4j 的示例学习如何运行图算法。
