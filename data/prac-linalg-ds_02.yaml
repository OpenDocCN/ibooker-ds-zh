- en: Chapter 2\. Vectors, Part 1
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬2ç« ã€‚å‘é‡ï¼Œç¬¬1éƒ¨åˆ†
- en: Vectors provide the foundations upon which all of linear algebra (and therefore,
    the rest of this book) is built.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡æä¾›äº†æ„å»ºçº¿æ€§ä»£æ•°ï¼ˆå› æ­¤ä¹Ÿæ˜¯æœ¬ä¹¦å…¶ä½™éƒ¨åˆ†ï¼‰çš„åŸºç¡€ã€‚
- en: 'By the end of this chapter, you will know all about vectors: what they are,
    what they do, how to interpret them, and how to create and work with them in Python.
    You will understand the most important operations acting on vectors, including
    vector algebra and the dot product. Finally, you will learn about vector decompositions,
    which is one of the main goals of linear algebra.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ç»“æŸæ—¶ï¼Œä½ å°†äº†è§£å…³äºå‘é‡çš„ä¸€åˆ‡ï¼šå®ƒä»¬æ˜¯ä»€ä¹ˆï¼Œå®ƒä»¬çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Œå¦‚ä½•è§£é‡Šå®ƒä»¬ï¼Œä»¥åŠå¦‚ä½•åœ¨Pythonä¸­åˆ›å»ºå’Œæ“ä½œå®ƒä»¬ã€‚ä½ å°†ç†è§£æœ€é‡è¦çš„ä½œç”¨äºå‘é‡çš„æ“ä½œï¼ŒåŒ…æ‹¬å‘é‡ä»£æ•°å’Œç‚¹ç§¯ã€‚æœ€åï¼Œä½ å°†å­¦ä¹ å‘é‡åˆ†è§£ï¼Œè¿™æ˜¯çº¿æ€§ä»£æ•°çš„ä¸»è¦ç›®æ ‡ä¹‹ä¸€ã€‚
- en: Creating and Visualizing Vectors in NumPy
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åœ¨NumPyä¸­åˆ›å»ºå’Œå¯è§†åŒ–å‘é‡
- en: In linear algebra, a *vector* is an ordered list of numbers. (In abstract linear
    algebra, vectors may contain other mathematical objects including functions; however,
    because this book is focused on applications, we will only consider vectors comprising
    numbers.)
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çº¿æ€§ä»£æ•°ä¸­ï¼Œ*å‘é‡* æ˜¯ä¸€ç»„æœ‰åºçš„æ•°å­—åˆ—è¡¨ã€‚ï¼ˆåœ¨æŠ½è±¡çš„çº¿æ€§ä»£æ•°ä¸­ï¼Œå‘é‡å¯ä»¥åŒ…å«å…¶ä»–æ•°å­¦å¯¹è±¡ï¼ŒåŒ…æ‹¬å‡½æ•°ï¼›ä½†ç”±äºæœ¬ä¹¦ä¸“æ³¨äºåº”ç”¨ï¼Œæˆ‘ä»¬åªè€ƒè™‘ç”±æ•°å­—ç»„æˆçš„å‘é‡ã€‚ï¼‰
- en: 'Vectors have several important characteristics. The first two we will start
    with are:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡å…·æœ‰å‡ ä¸ªé‡è¦ç‰¹å¾ã€‚æˆ‘ä»¬å°†ä»å‰ä¸¤ä¸ªå¼€å§‹ï¼š
- en: Dimensionality
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ç»´åº¦
- en: The number of numbers in the vector
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡ä¸­çš„æ•°å­—æ•°é‡
- en: Orientation
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ–¹å‘
- en: Whether the vector is in *column orientation* (standing up tall) or *row orientation*
    (laying flat and wide)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡æ˜¯åœ¨ *åˆ—æ–¹å‘*ï¼ˆç«–ç›´ï¼‰æˆ– *è¡Œæ–¹å‘*ï¼ˆæ°´å¹³ï¼‰çš„æƒ…å†µä¸‹
- en: Dimensionality is often indicated using a fancy-looking <math alttext="double-struck
    upper R Superscript upper N"><msup><mi>â„</mi> <mi>N</mi></msup></math> , where
    the <math alttext="double-struck upper R"><mi>â„</mi></math> indicates real-valued
    numbers (cf. <math alttext="double-struck upper C"><mi>â„‚</mi></math> for complex-valued
    numbers) and the <math alttext="Superscript upper N"><msup><mi>N</mi></msup></math>
    indicates the dimensionality. For example, a vector with two elements is said
    to be a member of <math alttext="double-struck upper R squared"><msup><mi>â„</mi>
    <mn>2</mn></msup></math> . That special <math alttext="double-struck upper R"><mi>â„</mi></math>
    character is made using latex code, but you can also write RÂ², R2, or R^2.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç»´åº¦å¸¸ç”¨ä¸€ä¸ªçœ‹èµ·æ¥å¾ˆå¤æ‚çš„ <math alttext="double-struck upper R Superscript upper N"><msup><mi>â„</mi>
    <mi>N</mi></msup></math> è¡¨ç¤ºï¼Œå…¶ä¸­ <math alttext="double-struck upper R"><mi>â„</mi></math>
    è¡¨ç¤ºå®æ•°ï¼ˆå¯¹æ¯” <math alttext="double-struck upper C"><mi>â„‚</mi></math> è¡¨ç¤ºå¤æ•°ï¼‰ï¼Œè€Œ <math
    alttext="Superscript upper N"><msup><mi>N</mi></msup></math> è¡¨ç¤ºç»´åº¦ã€‚ä¾‹å¦‚ï¼Œå…·æœ‰ä¸¤ä¸ªå…ƒç´ çš„å‘é‡ç§°ä¸º
    <math alttext="double-struck upper R squared"><msup><mi>â„</mi> <mn>2</mn></msup></math>
    çš„æˆå‘˜ã€‚è¿™ä¸ªç‰¹æ®Šçš„ <math alttext="double-struck upper R"><mi>â„</mi></math> å­—ç¬¦æ˜¯ä½¿ç”¨LaTeXä»£ç åˆ¶ä½œçš„ï¼Œä½†ä½ ä¹Ÿå¯ä»¥å†™æˆ
    RÂ²ã€R2 æˆ–è€… R^2ã€‚
- en: '[Equation 2-1](#eq-1) shows a few examples of vectors; please determine their
    dimensionality and orientation before reading the subsequent paragraph.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ–¹ç¨‹2-1](#eq-1) å±•ç¤ºäº†å‡ ä¸ªå‘é‡çš„ä¾‹å­ï¼›è¯·åœ¨é˜…è¯»åç»­æ®µè½ä¹‹å‰ç¡®å®šå®ƒä»¬çš„ç»´åº¦å’Œæ–¹å‘ã€‚'
- en: Equation 2-1\. Examples of column vectors and row vectors
  id: totrans-12
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹2-1ã€‚åˆ—å‘é‡å’Œè¡Œå‘é‡çš„ä¾‹å­
- en: <math display="block"><mrow><mi>ğ±</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd></mtr> <mtr><mtd><mn>6</mn></mtd></mtr></mtable></mfenced>
    <mo>,</mo> <mi>ğ²</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mn>.3</mn></mrow></mtd></mtr>
    <mtr><mtd><mrow><mo>-</mo> <mn>7</mn></mrow></mtd></mtr></mtable></mfenced> <mo>,</mo>
    <mi>ğ³</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>4</mn></mtd> <mtd><mn>5</mn></mtd> <mtd><mn>6</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mi>ğ±</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd></mtr>
    <mtr><mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd></mtr> <mtr><mtd><mn>6</mn></mtd></mtr></mtable></mfenced>
    <mo>,</mo> <mi>ğ²</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mn>.3</mn></mrow></mtd></mtr>
    <mtr><mtd><mrow><mo>-</mo> <mn>7</mn></mrow></mtd></mtr></mtable></mfenced> <mo>,</mo>
    <mi>ğ³</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>4</mn></mtd> <mtd><mn>5</mn></mtd> <mtd><mn>6</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'Here are the answers: **x** is a 4D column vector, **y** is a 2D column vector,
    and **z** is a 4D row vector. You can also write, e.g., <math alttext="bold x
    element-of double-struck upper R Superscript 4"><mrow><mi>ğ±</mi> <mo>âˆˆ</mo> <msup><mi>â„</mi>
    <mn>4</mn></msup></mrow></math> , where the <math alttext="element-of"><mo>âˆˆ</mo></math>
    symbol means â€œis contained in the set of.â€'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯ç­”æ¡ˆï¼š**x** æ˜¯ä¸€ä¸ª4ç»´åˆ—å‘é‡ï¼Œ**y** æ˜¯ä¸€ä¸ª2ç»´åˆ—å‘é‡ï¼Œè€Œ **z** æ˜¯ä¸€ä¸ª4ç»´è¡Œå‘é‡ã€‚ä½ ä¹Ÿå¯ä»¥å†™æˆï¼Œä¾‹å¦‚ï¼Œ<math alttext="bold
    x element-of double-struck upper R Superscript 4"><mrow><mi>ğ±</mi> <mo>âˆˆ</mo>
    <msup><mi>â„</mi> <mn>4</mn></msup></mrow></math>ï¼Œå…¶ä¸­ <math alttext="element-of"><mo>âˆˆ</mo></math>
    ç¬¦å·è¡¨ç¤ºâ€œå±äºé›†åˆâ€ã€‚
- en: Are **x** and **z** the same vector? Technically they are different, even though
    they have the same elements in the same order. See [â€œDoes Vector Orientation Matter?â€](#vector-orientation)
    for more discussion.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**x** å’Œ **z** æ˜¯åŒä¸€ä¸ªå‘é‡å—ï¼Ÿä»æŠ€æœ¯ä¸Šè®²ï¼Œå®ƒä»¬æ˜¯ä¸åŒçš„ï¼Œå³ä½¿å®ƒä»¬çš„å…ƒç´ é¡ºåºç›¸åŒã€‚è¯¦ç»†è®¨è®ºè¯·å‚è§ [â€œå‘é‡æ–¹å‘æ˜¯å¦é‡è¦ï¼Ÿâ€](#vector-orientation)ã€‚'
- en: You will learn, in this book and throughout your adventures integrating math
    and coding, that there are differences between math â€œon the chalkboardâ€ versus
    implemented in code. Some discrepancies are minor and inconsequential, while others
    cause confusion and errors. Let me now introduce you to a terminological difference
    between math and coding.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å°†ä¼šåœ¨æœ¬ä¹¦ä»¥åŠåœ¨æ•´åˆæ•°å­¦å’Œç¼–ç¨‹çš„å†’é™©ä¸­å­¦åˆ°ï¼Œæ•°å­¦â€œåœ¨é»‘æ¿ä¸Šâ€çš„æ–¹å¼ä¸åœ¨ä»£ç ä¸­å®ç°çš„æ–¹å¼ä¹‹é—´å­˜åœ¨å·®å¼‚ã€‚æœ‰äº›å·®å¼‚å¾®ä¸è¶³é“ï¼Œä¸é‡è¦ï¼Œè€Œå…¶ä»–åˆ™ä¼šå¯¼è‡´æ··æ·†å’Œé”™è¯¯ã€‚ç°åœ¨ï¼Œè®©æˆ‘å‘ä½ ä»‹ç»æ•°å­¦å’Œç¼–ç¨‹ä¹‹é—´æœ¯è¯­ä¸Šçš„å·®å¼‚ã€‚
- en: I wrote earlier that the *dimensionality* of a vector is the number of elements
    in that vector. However, in Python, the dimensionality of a vector or matrix is
    the number of geometric dimensions used to print out a numerical object. For example,
    all of the vectors shown above are considered â€œtwo-dimensional arraysâ€ in Python,
    regardless of the number of elements contained in the vectors (which is the mathematical
    dimensionality). A list of numbers without a particular orientation is considered
    a 1D array in Python, regardless of the number of elements (that array will be
    printed out as a row, but, as youâ€™ll see later, it is treated differently from
    row vectors). The mathematical dimensionalityâ€”the number of elements in the vectorâ€”is
    called the *length* or the *shape* of the vector in Python.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹‹å‰å†™é“ï¼Œå‘é‡çš„*ç»´æ•°*æ˜¯å‘é‡ä¸­å…ƒç´ çš„æ•°é‡ã€‚ç„¶è€Œï¼Œåœ¨ Python ä¸­ï¼Œå‘é‡æˆ–çŸ©é˜µçš„ç»´æ•°æ˜¯ç”¨äºæ‰“å°æ•°å€¼å¯¹è±¡çš„å‡ ä½•ç»´åº¦çš„æ•°é‡ã€‚ä¾‹å¦‚ï¼Œä¸Šé¢æ˜¾ç¤ºçš„æ‰€æœ‰å‘é‡åœ¨
    Python ä¸­éƒ½è¢«è®¤ä¸ºæ˜¯â€œäºŒç»´æ•°ç»„â€ï¼Œæ— è®ºå‘é‡ä¸­åŒ…å«çš„å…ƒç´ æ•°é‡æ˜¯å¤šå°‘ï¼ˆè¿™æ˜¯æ•°å­¦ä¸Šçš„ç»´æ•°ï¼‰ã€‚åœ¨ Python ä¸­ï¼Œæ²¡æœ‰ç‰¹å®šæ–¹å‘çš„æ•°å­—åˆ—è¡¨è¢«è®¤ä¸ºæ˜¯ä¸€ç»´æ•°ç»„ï¼Œæ— è®ºå…ƒç´ æ•°é‡å¦‚ä½•ï¼ˆè¯¥æ•°ç»„å°†è¢«æ‰“å°ä¸ºä¸€è¡Œï¼Œä½†æ˜¯ï¼Œæ­£å¦‚æ‚¨ç¨åå°†çœ‹åˆ°çš„ï¼Œå®ƒä¸è¡Œå‘é‡çš„å¤„ç†æ–¹å¼ä¸åŒï¼‰ã€‚åœ¨
    Python ä¸­ï¼Œå‘é‡çš„æ•°å­¦ç»´æ•°â€”â€”å‘é‡ä¸­çš„å…ƒç´ æ•°é‡â€”â€”ç§°ä¸ºå‘é‡çš„*é•¿åº¦*æˆ–*å½¢çŠ¶*ã€‚
- en: This inconsistent and sometimes conflicting terminology can be confusing. Indeed,
    terminology is often a sticky issue at the intersection of different disciplines
    (in this case, mathematics and computer science). But donâ€™t worry, youâ€™ll get
    the hang of it with some experience.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§ä¸ä¸€è‡´ä¸”æœ‰æ—¶å†²çªçš„æœ¯è¯­å¯èƒ½ä¼šä»¤äººå›°æƒ‘ã€‚äº‹å®ä¸Šï¼Œåœ¨ä¸åŒå­¦ç§‘ï¼ˆåœ¨æœ¬ä¾‹ä¸­æ˜¯æ•°å­¦å’Œè®¡ç®—æœºç§‘å­¦ï¼‰äº¤æ±‡å¤„ï¼Œæœ¯è¯­é€šå¸¸æ˜¯ä¸€ä¸ªæ£˜æ‰‹çš„é—®é¢˜ã€‚ä½†åˆ«æ‹…å¿ƒï¼Œé€šè¿‡ä¸€äº›å®è·µä½ ä¼šæ…¢æ…¢æŒæ¡ã€‚
- en: When referring to vectors, it is common to use lowercase bolded Roman letters,
    like **v** for â€œvector v.â€ Some texts use italics (*v*) or print an arrow on top
    ( <math alttext="ModifyingAbove v With right-arrow"><mover accent="true"><mi>v</mi>
    <mo>â†’</mo></mover></math> ).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æ¶‰åŠåˆ°å‘é‡æ—¶ï¼Œé€šå¸¸ä½¿ç”¨å°å†™åŠ ç²—çš„ç½—é©¬å­—æ¯ï¼Œæ¯”å¦‚**v**è¡¨ç¤ºâ€œå‘é‡ vâ€ã€‚æœ‰äº›æ–‡æœ¬ä½¿ç”¨æ–œä½“ï¼ˆ*v*ï¼‰æˆ–åœ¨é¡¶éƒ¨æ‰“å°ä¸€ä¸ªç®­å¤´ï¼ˆ <math alttext="ModifyingAbove
    v With right-arrow"><mover accent="true"><mi>v</mi> <mo>â†’</mo></mover></math>
    ï¼‰ã€‚
- en: Linear algebra convention is to assume that vectors are in column orientation
    unless otherwise specified. Row vectors are written as <math alttext="bold w Superscript
    upper T"><msup><mi>ğ°</mi> <mtext>T</mtext></msup></math> . The <math alttext="Superscript
    upper T"><msup><mtext>T</mtext></msup></math> indicates the *transpose operation*,
    which youâ€™ll learn more about later; for now, suffice it to say that the transpose
    operation transforms a column vector into a row vector.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§ä»£æ•°çš„æƒ¯ä¾‹æ˜¯é»˜è®¤å‘é‡ä¸ºåˆ—å‘é‡ï¼Œé™¤éå¦æœ‰è¯´æ˜ã€‚è¡Œå‘é‡å†™ä½œ <math alttext="bold w Superscript upper T"><msup><mi>ğ°</mi>
    <mtext>T</mtext></msup></math> ã€‚<math alttext="Superscript upper T"><msup><mtext>T</mtext></msup></math>
    è¡¨ç¤º*è½¬ç½®æ“ä½œ*ï¼Œæ‚¨ç¨åä¼šäº†è§£æ›´å¤šï¼›ç°åœ¨åªéœ€çŸ¥é“è½¬ç½®æ“ä½œå°†åˆ—å‘é‡è½¬æ¢ä¸ºè¡Œå‘é‡ã€‚
- en: Does Vector Orientation Matter?
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‘é‡çš„æ–¹å‘é‡è¦å—ï¼Ÿ
- en: Do you really need to worry about whether vectors are column- or row-oriented,
    or orientationless 1D arrays? Sometimes yes, sometimes no. When using vectors
    to store data, orientation usually doesnâ€™t matter. But some operations in Python
    can give errors or unexpected results if the orientation is wrong. Therefore,
    vector orientation is important to understand, because spending 30 minutes debugging
    code only to realize that a row vector needs to be a column vector is guaranteed
    to give you a headache.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨çœŸçš„éœ€è¦æ‹…å¿ƒå‘é‡æ˜¯åˆ—å‘é‡è¿˜æ˜¯è¡Œå‘é‡ï¼Œæˆ–è€…æ˜¯æ— æ–¹å‘çš„ä¸€ç»´æ•°ç»„å—ï¼Ÿæœ‰æ—¶æ˜¯ï¼Œæœ‰æ—¶ä¸æ˜¯ã€‚åœ¨ä½¿ç”¨å‘é‡å­˜å‚¨æ•°æ®æ—¶ï¼Œæ–¹å‘é€šå¸¸å¹¶ä¸é‡è¦ã€‚ä½†æ˜¯ï¼Œå¦‚æœæ–¹å‘é”™è¯¯ï¼ŒPython
    ä¸­çš„æŸäº›æ“ä½œå¯èƒ½ä¼šå¯¼è‡´é”™è¯¯æˆ–æ„å¤–ç»“æœã€‚å› æ­¤ï¼Œç†è§£å‘é‡çš„æ–¹å‘æ˜¯å¾ˆé‡è¦çš„ï¼Œå› ä¸ºèŠ±è´¹30åˆ†é’Ÿè°ƒè¯•ä»£ç ï¼Œæœ€åå‘ç°ä¸€ä¸ªè¡Œå‘é‡åº”è¯¥æ˜¯ä¸€ä¸ªåˆ—å‘é‡ï¼Œè‚¯å®šä¼šè®©æ‚¨å¤´ç—›ä¸å·²ã€‚
- en: 'Vectors in Python can be represented using several data types. The `list` type
    may seem like the simplest way to represent a vectorâ€”and it is for for some applications.
    But many linear algebra operations wonâ€™t work on Python lists. Therefore, most
    of the time itâ€™s best to create vectors as NumPy arrays. The following code shows
    four ways of creating a vector:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Python ä¸­ï¼Œå‘é‡å¯ä»¥ç”¨å‡ ç§æ•°æ®ç±»å‹è¡¨ç¤ºã€‚`list` ç±»å‹å¯èƒ½çœ‹èµ·æ¥æ˜¯è¡¨ç¤ºå‘é‡æœ€ç®€å•çš„æ–¹å¼ï¼Œå¹¶ä¸”å¯¹äºæŸäº›åº”ç”¨æ¥è¯´ç¡®å®å¦‚æ­¤ã€‚ä½†æ˜¯ï¼Œè®¸å¤šçº¿æ€§ä»£æ•°è¿ç®—åœ¨
    Python åˆ—è¡¨ä¸Šä¸èµ·ä½œç”¨ã€‚å› æ­¤ï¼Œå¤§å¤šæ•°æ—¶å€™æœ€å¥½å°†å‘é‡åˆ›å»ºä¸º NumPy æ•°ç»„ã€‚ä»¥ä¸‹ä»£ç å±•ç¤ºäº†åˆ›å»ºå‘é‡çš„å››ç§æ–¹å¼ï¼š
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The variable `asArray` is an *orientationless* array, meaning it is neither
    a row nor a column vector but simply a 1D list of numbers in NumPy. Orientation
    in NumPy is given by brackets: the outermost brackets group all of the numbers
    together into one object. Then, each additional set of brackets indicates a row:
    a row vector (variable `rowVec`) has all numbers in one row, while a column vector
    (variable `colVec`) has multiple rows, with each row containing one number.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: å˜é‡ `asArray` æ˜¯ä¸€ä¸ª*æ— æ–¹å‘*æ•°ç»„ï¼Œæ„å‘³ç€å®ƒæ—¢ä¸æ˜¯è¡Œå‘é‡ä¹Ÿä¸æ˜¯åˆ—å‘é‡ï¼Œåªæ˜¯ NumPy ä¸­çš„ä¸€ä¸ªä¸€ç»´æ•°å­—åˆ—è¡¨ã€‚åœ¨ NumPy ä¸­ï¼Œæ–¹å‘ç”±æ‹¬å·å†³å®šï¼šæœ€å¤–å±‚çš„æ‹¬å·å°†æ‰€æœ‰æ•°å­—ç»„åˆæˆä¸€ä¸ªå¯¹è±¡ã€‚ç„¶åï¼Œæ¯ä¸€ç»„é¢å¤–çš„æ‹¬å·è¡¨ç¤ºä¸€è¡Œï¼šè¡Œå‘é‡ï¼ˆå˜é‡
    `rowVec`ï¼‰å°†æ‰€æœ‰æ•°å­—æ”¾åœ¨ä¸€è¡Œä¸­ï¼Œè€Œåˆ—å‘é‡ï¼ˆå˜é‡ `colVec`ï¼‰æœ‰å¤šè¡Œï¼Œæ¯è¡ŒåŒ…å«ä¸€ä¸ªæ•°å­—ã€‚
- en: 'We can explore these orientations by examining the shapes of the variables
    (inspecting variable shapes is often very useful while coding):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥é€šè¿‡æ£€æŸ¥å˜é‡çš„å½¢çŠ¶æ¥æ¢ç´¢è¿™äº›æ–¹å‘ï¼ˆåœ¨ç¼–ç æ—¶æ£€æŸ¥å˜é‡å½¢çŠ¶é€šå¸¸éå¸¸æœ‰ç”¨ï¼‰ï¼š
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Hereâ€™s what the output looks like:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The output shows that the 1D array `asArray` is of size (`3`), whereas the orientation-endowed
    vectors are 2D arrays and are stored as size (`1,3`) or (`3,1`) depending on the
    orientation. Dimensions are always listed as (rows,columns).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: è¾“å‡ºæ˜¾ç¤ºä¸€ç»´æ•°ç»„ `asArray` çš„å¤§å°ä¸ºï¼ˆ`3`ï¼‰ï¼Œè€Œæœ‰æ–¹å‘çš„å‘é‡æ˜¯äºŒç»´æ•°ç»„ï¼Œå…¶å¤§å°ä¸ºï¼ˆ`1,3`ï¼‰æˆ–ï¼ˆ`3,1`ï¼‰ï¼Œå…·ä½“å–å†³äºæ–¹å‘ã€‚ç»´åº¦æ€»æ˜¯æŒ‰ç…§ï¼ˆè¡Œæ•°,åˆ—æ•°ï¼‰åˆ—å‡ºã€‚
- en: Geometry of Vectors
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‘é‡çš„å‡ ä½•
- en: '*Ordered list of numbers* is the algebraic interpretation of a vector; the
    geometric interpretation of a vector is a straight line with a specific length
    (also called *magnitude*) and direction (also called *angle*; it is computed relative
    to the positive *x*-axis). The two points of a vector are called the tail (where
    it starts) and the head (where it ends); the head often has an arrow tip to disambiguate
    from the tail.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*æœ‰åºæ•°å­—åˆ—è¡¨* æ˜¯å‘é‡çš„ä»£æ•°è§£é‡Šï¼›å‘é‡çš„å‡ ä½•è§£é‡Šæ˜¯å…·æœ‰ç‰¹å®šé•¿åº¦ï¼ˆä¹Ÿç§°ä¸º*å¤§å°*ï¼‰å’Œæ–¹å‘ï¼ˆä¹Ÿç§°ä¸º*è§’åº¦*ï¼›ç›¸å¯¹äºæ­£ *x*-è½´è®¡ç®—ï¼‰ã€‚å‘é‡çš„ä¸¤ä¸ªç‚¹ç§°ä¸ºå°¾éƒ¨ï¼ˆèµ·å§‹ç‚¹ï¼‰å’Œå¤´éƒ¨ï¼ˆç»“æŸç‚¹ï¼‰ï¼›å¤´éƒ¨é€šå¸¸å¸¦æœ‰ç®­å¤´æç¤ºä»¥åŒºåˆ†å°¾éƒ¨ã€‚'
- en: You may think that a vector encodes a geometric coordinate, but vectors and
    coordinates are actually different things. They are, however, concordant when
    the vector starts at the origin. This is called the *standard position* and is
    illustrated in [FigureÂ 2-1](#fig_2_1).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½è®¤ä¸ºå‘é‡ç¼–ç äº†ä¸€ä¸ªå‡ ä½•åæ ‡ï¼Œä½†å‘é‡å’Œåæ ‡å®é™…ä¸Šæ˜¯ä¸åŒçš„ä¸œè¥¿ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨å‘é‡ä»åŸç‚¹å¼€å§‹æ—¶æ˜¯åè°ƒçš„ã€‚è¿™è¢«ç§°ä¸º*æ ‡å‡†ä½ç½®*ï¼Œå¹¶ä¸”åœ¨ [å›¾ 2-1](#fig_2_1)
    ä¸­æœ‰æ‰€è¯´æ˜ã€‚
- en: '![A vector, repeated in space.](assets/plad_0201.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![ç©ºé—´ä¸­é‡å¤çš„å‘é‡ã€‚](assets/plad_0201.png)'
- en: Figure 2-1\. All arrows express the same vector. A vector in standard position
    has its tail at the origin and its head at the concordant geometric coordinate.
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2-1\. æ‰€æœ‰ç®­å¤´è¡¨ç¤ºç›¸åŒçš„å‘é‡ã€‚ä½äºæ ‡å‡†ä½ç½®çš„å‘é‡å…¶å°¾éƒ¨ä½äºåŸç‚¹ï¼Œå…¶å¤´éƒ¨ä½äºåè°ƒçš„å‡ ä½•åæ ‡ã€‚
- en: Conceptualizing vectors either geometrically or algebraically facilitates intuition
    in different applications, but these are simply two sides of the same coin. For
    example, the geometric interpretation of a vector is useful in physics and engineering
    (e.g., representing physical forces), and the algebraic interpretation of a vector
    is useful in data science (e.g., storing sales data over time). Oftentimes, linear
    algebra concepts are learned geometrically in 2D graphs, and then are expanded
    to higher dimensions using algebra.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºæ˜¯å‡ ä½•ä¸Šè¿˜æ˜¯ä»£æ•°ä¸Šæ„æƒ³å‘é‡éƒ½æœ‰åŠ©äºåœ¨ä¸åŒåº”ç”¨ä¸­å½¢æˆç›´è§‰ï¼Œä½†è¿™åªæ˜¯åŒä¸€ä¸ªé—®é¢˜çš„ä¸¤é¢ã€‚ä¾‹å¦‚ï¼Œå‘é‡çš„å‡ ä½•è§£é‡Šåœ¨ç‰©ç†å­¦å’Œå·¥ç¨‹å­¦ä¸­å¾ˆæœ‰ç”¨ï¼ˆä¾‹å¦‚è¡¨ç¤ºç‰©ç†åŠ›é‡ï¼‰ï¼Œè€Œå‘é‡çš„ä»£æ•°è§£é‡Šåœ¨æ•°æ®ç§‘å­¦ä¸­å¾ˆæœ‰ç”¨ï¼ˆä¾‹å¦‚å­˜å‚¨éšæ—¶é—´å˜åŒ–çš„é”€å”®æ•°æ®ï¼‰ã€‚é€šå¸¸ï¼Œçº¿æ€§ä»£æ•°æ¦‚å¿µåœ¨äºŒç»´å›¾è¡¨ä¸­ä»¥å‡ ä½•æ–¹å¼å­¦ä¹ ï¼Œç„¶åé€šè¿‡ä»£æ•°æ‰©å±•åˆ°æ›´é«˜ç»´åº¦ã€‚
- en: Operations on Vectors
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‘é‡çš„æ“ä½œ
- en: Vectors are like nouns; they are the characters in our linear algebra story.
    The fun in linear algebra comes from the verbsâ€”the actions that breathe life into
    the characters. Those actions are called *operations*.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡å°±åƒåè¯ä¸€æ ·ï¼›å®ƒä»¬æ˜¯æˆ‘ä»¬çº¿æ€§ä»£æ•°æ•…äº‹ä¸­çš„è§’è‰²ã€‚çº¿æ€§ä»£æ•°çš„ä¹è¶£æ¥è‡ªäºåŠ¨è¯â€”â€”ç»™è¿™äº›è§’è‰²æ³¨å…¥ç”Ÿå‘½çš„è¡ŒåŠ¨ã€‚è¿™äº›è¡ŒåŠ¨ç§°ä¸º*æ“ä½œ*ã€‚
- en: Some linear algebra operations are simple and intuitive and work exactly how
    youâ€™d expect (e.g., addition), whereas others are more involved and require entire
    chapters to explain (e.g., singular value decomposition). Letâ€™s begin with simple
    operations.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›çº¿æ€§ä»£æ•°æ“ä½œç®€å•ç›´è§‚ï¼Œå¹¶ä¸”å®Œå…¨ç¬¦åˆé¢„æœŸï¼ˆä¾‹å¦‚åŠ æ³•ï¼‰ï¼Œè€Œå…¶ä»–ä¸€äº›æ“ä½œåˆ™æ›´å¤æ‚ï¼Œéœ€è¦æ•´æ•´å‡ ç« æ¥è§£é‡Šï¼ˆä¾‹å¦‚å¥‡å¼‚å€¼åˆ†è§£ï¼‰ã€‚è®©æˆ‘ä»¬ä»ç®€å•çš„æ“ä½œå¼€å§‹ã€‚
- en: Adding Two Vectors
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ·»åŠ ä¸¤ä¸ªå‘é‡
- en: 'To add two vectors, simply add each corresponding element. [Equation 2-2](#eq-2)
    shows an example:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: è¦æ·»åŠ ä¸¤ä¸ªå‘é‡ï¼Œåªéœ€å°†æ¯ä¸ªå¯¹åº”çš„å…ƒç´ ç›¸åŠ ã€‚[æ–¹ç¨‹ 2-2](#eq-2) å±•ç¤ºäº†ä¸€ä¸ªä¾‹å­ï¼š
- en: Equation 2-2\. Adding two vectors
  id: totrans-42
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 2-2\. å‘é‡ç›¸åŠ 
- en: <math alttext="Start 3 By 1 Matrix 1st Row  4 2nd Row  5 3rd Row  6 EndMatrix
    plus Start 3 By 1 Matrix 1st Row  10 2nd Row  20 3rd Row  30 EndMatrix equals
    Start 3 By 1 Matrix 1st Row  14 2nd Row  25 3rd Row  36 EndMatrix" display="block"><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd></mtr>
    <mtr><mtd><mn>6</mn></mtd></mtr></mtable></mfenced> <mo>+</mo> <mfenced close="]"
    open="["><mtable><mtr><mtd><mn>10</mn></mtd></mtr> <mtr><mtd><mn>20</mn></mtd></mtr>
    <mtr><mtd><mn>30</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]"
    open="["><mtable><mtr><mtd><mn>14</mn></mtd></mtr> <mtr><mtd><mn>25</mn></mtd></mtr>
    <mtr><mtd><mn>36</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="Start 3 By 1 Matrix 1st Row  4 2nd Row  5 3rd Row  6 EndMatrix
    plus Start 3 By 1 Matrix 1st Row  10 2nd Row  20 3rd Row  30 EndMatrix equals
    Start 3 By 1 Matrix 1st Row  14 2nd Row  25 3rd Row  36 EndMatrix" display="block"><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>5</mn></mtd></mtr>
    <mtr><mtd><mn>6</mn></mtd></mtr></mtable></mfenced> <mo>+</mo> <mfenced close="]"
    open="["><mtable><mtr><mtd><mn>10</mn></mtd></mtr> <mtr><mtd><mn>20</mn></mtd></mtr>
    <mtr><mtd><mn>30</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]"
    open="["><mtable><mtr><mtd><mn>14</mn></mtd></mtr> <mtr><mtd><mn>25</mn></mtd></mtr>
    <mtr><mtd><mn>36</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: As you might have guessed, vector addition is defined only for two vectors that
    have the same dimensionality; it is not possible to add, e.g., a vector in <math
    alttext="double-struck upper R cubed"><msup><mi>â„</mi> <mn>3</mn></msup></math>
    with a vector in <math alttext="double-struck upper R Superscript 5"><msup><mi>â„</mi>
    <mn>5</mn></msup></math> .
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä½ å¯èƒ½çŒœåˆ°çš„é‚£æ ·ï¼Œå‘é‡åŠ æ³•ä»…å¯¹å…·æœ‰ç›¸åŒç»´åº¦çš„ä¸¤ä¸ªå‘é‡å®šä¹‰ï¼›ä¾‹å¦‚ï¼Œåœ¨ <math alttext="åŒåˆ’çº¿ä¸Šçš„ R ç«‹æ–¹"><msup><mi>â„</mi>
    <mn>3</mn></msup></math> ä¸­çš„å‘é‡å’Œåœ¨ <math alttext="åŒåˆ’çº¿ä¸Šçš„ R ä¸Šæ ‡ 5"><msup><mi>â„</mi>
    <mn>5</mn></msup></math> ä¸­çš„å‘é‡ä¸èƒ½ç›¸åŠ ã€‚
- en: 'Vector subtraction is also what youâ€™d expect: subtract the two vectors element-wise.
    [Equation 2-3](#eq-3) shows an example:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡å‡æ³•ä¹Ÿä¸é¢„æœŸç›¸åŒï¼šé€å…ƒç´ å‡å»ä¸¤ä¸ªå‘é‡ã€‚æ–¹ç¨‹ 2-3 ç¤ºèŒƒäº†ä¸€ä¸ªä¾‹å­ï¼š
- en: Equation 2-3\. Subtracting two vectors
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 2-3\. å‘é‡ç›¸å‡
- en: <math alttext="Start 3 By 1 Matrix 1st Row  4 2nd Row  5 3rd Row  6 EndMatrix
    minus Start 3 By 1 Matrix 1st Row  10 2nd Row  20 3rd Row  30 EndMatrix equals
    Start 3 By 1 Matrix 1st Row  negative 6 2nd Row  negative 15 3rd Row  negative
    24 EndMatrix" display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>5</mn></mtd></mtr> <mtr><mtd><mn>6</mn></mtd></mtr></mtable></mfenced>
    <mo>-</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd></mtr>
    <mtr><mtd><mn>20</mn></mtd></mtr> <mtr><mtd><mn>30</mn></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mo>-</mo> <mn>6</mn></mrow></mtd></mtr>
    <mtr><mtd><mrow><mo>-</mo> <mn>15</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mo>-</mo>
    <mn>24</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="Start 3 By 1 Matrix 1st Row  4 2nd Row  5 3rd Row  6 EndMatrix
    minus Start 3 By 1 Matrix 1st Row  10 2nd Row  20 3rd Row  30 EndMatrix equals
    Start 3 By 1 Matrix 1st Row  negative 6 2nd Row  negative 15 3rd Row  negative
    24 EndMatrix" display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>5</mn></mtd></mtr> <mtr><mtd><mn>6</mn></mtd></mtr></mtable></mfenced>
    <mo>-</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd></mtr>
    <mtr><mtd><mn>20</mn></mtd></mtr> <mtr><mtd><mn>30</mn></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mo>-</mo> <mn>6</mn></mrow></mtd></mtr>
    <mtr><mtd><mrow><mo>-</mo> <mn>15</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mo>-</mo>
    <mn>24</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'Adding vectors is straightforward in Python:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Python ä¸­ï¼Œå‘é‡ç›¸åŠ æ˜¯ç›´æ¥çš„ï¼š
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Does vector orientation matter for addition? Consider [Equation 2-4](#eq-4):'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡åŠ æ³•æ˜¯å¦å—å‘é‡æ–¹å‘çš„å½±å“ï¼Ÿè€ƒè™‘æ–¹ç¨‹ 2-4ï¼š
- en: Equation 2-4\. Can you add a row vector to a column vector?
  id: totrans-51
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 2-4\. ä½ èƒ½å°†è¡Œå‘é‡åŠ åˆ°åˆ—å‘é‡ä¸­å—ï¼Ÿ
- en: <math alttext="Start 3 By 1 Matrix 1st Row  4 2nd Row  5 3rd Row  6 EndMatrix
    plus Start 1 By 3 Matrix 1st Row 1st Column 10 2nd Column 20 3rd Column 30 EndMatrix
    equals question-mark" display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>5</mn></mtd></mtr> <mtr><mtd><mn>6</mn></mtd></mtr></mtable></mfenced>
    <mo>+</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd> <mtd><mn>20</mn></mtd>
    <mtd><mn>30</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mo>?</mo></mrow></math>
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="Start 3 By 1 Matrix 1st Row  4 2nd Row  5 3rd Row  6 EndMatrix
    plus Start 1 By 3 Matrix 1st Row 1st Column 10 2nd Column 20 3rd Column 30 EndMatrix
    equals question-mark" display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>4</mn></mtd></mtr>
    <mtr><mtd><mn>5</mn></mtd></mtr> <mtr><mtd><mn>6</mn></mtd></mtr></mtable></mfenced>
    <mo>+</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd> <mtd><mn>20</mn></mtd>
    <mtd><mn>30</mn></mtd></mtr></mtable></mfenced> <mo>=</mo> <mo>?</mo></mrow></math>
- en: 'You might think that there is no difference between this example and the one
    shown earlierâ€”after all, both vectors have three elements. Letâ€™s see what Python
    does:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å¯èƒ½è®¤ä¸ºè¿™ä¸ªä¾‹å­ä¸ä¹‹å‰æ˜¾ç¤ºçš„ä¾‹å­æ²¡æœ‰åŒºåˆ«â€”â€”æ¯•ç«Ÿï¼Œè¿™ä¸¤ä¸ªå‘é‡éƒ½æœ‰ä¸‰ä¸ªå…ƒç´ ã€‚è®©æˆ‘ä»¬çœ‹çœ‹ Python åšäº†ä»€ä¹ˆï¼š
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The result may seem confusing and inconsistent with the definition of vector
    addition given earlier. In fact, Python is implementing an operation called *broadcasting*.
    You will learn more about broadcasting later in this chapter, but I encourage
    you to spend a moment pondering the result and thinking about how it arose from
    adding a row and a column vector. Regardless, this example shows that orientation
    is indeed important: *two vectors can be added together only if they have the
    same dimensionality **and** the same orientation*.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“æœå¯èƒ½çœ‹èµ·æ¥ä»¤äººå›°æƒ‘ï¼Œå¹¶ä¸”ä¸å‰æ–‡æ‰€è¿°çš„å‘é‡åŠ æ³•å®šä¹‰ä¸ä¸€è‡´ã€‚äº‹å®ä¸Šï¼ŒPython æ­£åœ¨æ‰§è¡Œä¸€ç§ç§°ä¸º*å¹¿æ’­*çš„æ“ä½œã€‚æ‚¨å°†åœ¨æœ¬ç« åé¢æ›´å¤šåœ°äº†è§£å¹¿æ’­ï¼Œä½†æˆ‘é¼“åŠ±æ‚¨èŠ±ä¸€ç‚¹æ—¶é—´æ€è€ƒè¿™ä¸ªç»“æœï¼Œå¹¶æ€è€ƒå®ƒæ˜¯å¦‚ä½•ç”±æ·»åŠ è¡Œå‘é‡å’Œåˆ—å‘é‡è€Œæ¥çš„ã€‚æ— è®ºå¦‚ä½•ï¼Œè¿™ä¸ªä¾‹å­è¡¨æ˜æ–¹å‘ç¡®å®å¾ˆé‡è¦ï¼š*åªæœ‰å…·æœ‰ç›¸åŒç»´åº¦
    **å’Œ** ç›¸åŒæ–¹å‘çš„ä¸¤ä¸ªå‘é‡æ‰èƒ½ç›¸åŠ *ã€‚
- en: Geometry of Vector Addition and Subtraction
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‘é‡åŠ æ³•ä¸å‡æ³•çš„å‡ ä½•æ€§è´¨
- en: 'To add two vectors geometrically, place the vectors such that the tail of one
    vector is at the head of the other vector. The summed vector traverses from the
    tail of the first vector to the head of the second (graph A in [FigureÂ 2-2](#fig_2_2)).
    You can extend this procedure to sum any number of vectors: simply stack all the
    vectors tail-to-head, and then the sum is the line that goes from the first tail
    to the final head.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: è¦åœ¨å‡ ä½•ä¸Šæ·»åŠ ä¸¤ä¸ªå‘é‡ï¼Œè¯·å°†å‘é‡æ”¾ç½®åœ¨ä¸€ä¸ªå‘é‡çš„å°¾éƒ¨ä½äºå¦ä¸€ä¸ªå‘é‡çš„å¤´éƒ¨çš„ä½ç½®ï¼ˆå›¾ A å‚è§[å›¾Â 2-2](#fig_2_2)ï¼‰ã€‚æ‚¨å¯ä»¥å°†æ­¤è¿‡ç¨‹æ‰©å±•åˆ°å¯¹ä»»æ„æ•°é‡çš„å‘é‡æ±‚å’Œï¼šç®€å•åœ°å°†æ‰€æœ‰å‘é‡ä¾æ¬¡å †å ï¼Œç„¶åå’Œå‘é‡æ˜¯ä»ç¬¬ä¸€ä¸ªå°¾åˆ°æœ€åä¸€ä¸ªå¤´çš„çº¿ã€‚
- en: '![What does this do?](assets/plad_0202.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![è¿™æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ](assets/plad_0202.png)'
- en: Figure 2-2\. The sum and difference of two vectors
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 2-2\. ä¸¤ä¸ªå‘é‡çš„å’Œä¸å·®
- en: 'Subtracting vectors geometrically is slightly different but equally straightforward:
    line up the two vectors such that their tails are at the same coordinate (this
    is easily accomplished by having both vectors in standard position); the difference
    vector is the line that goes from the head of the â€œnegativeâ€ vector to the head
    of the â€œpositiveâ€ vector (graph B in [FigureÂ 2-2](#fig_2_2)).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å‡ ä½•ä¸Šå‡å»å‘é‡ç•¥æœ‰ä¸åŒï¼Œä½†åŒæ ·ç›´æ¥ï¼šå°†ä¸¤ä¸ªå‘é‡æ’åˆ—åœ¨ä¸€èµ·ï¼Œä½¿å®ƒä»¬çš„å°¾éƒ¨ä½äºç›¸åŒçš„åæ ‡ï¼ˆè¿™å¯ä»¥é€šè¿‡å°†ä¸¤ä¸ªå‘é‡æ”¾åœ¨æ ‡å‡†ä½ç½®è½»æ¾å®ç°ï¼‰ï¼›å·®å‘é‡æ˜¯ä»â€œè´Ÿâ€å‘é‡çš„å¤´åˆ°â€œæ­£â€å‘é‡çš„å¤´çš„çº¿ï¼ˆå›¾
    B å‚è§[å›¾Â 2-2](#fig_2_2)ï¼‰ã€‚
- en: 'Do not underestimate the importance of the geometry of vector subtraction:
    it is the basis for orthogonal vector decomposition, which in turn is the basis
    for linear least squares, which is one of the most important applications of linear
    algebra in science and engineering.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è¦ä½ä¼°å‘é‡å‡æ³•çš„å‡ ä½•æ€§è´¨çš„é‡è¦æ€§ï¼šå®ƒæ˜¯æ­£äº¤å‘é‡åˆ†è§£çš„åŸºç¡€ï¼Œè€Œæ­£äº¤å‘é‡åˆ†è§£åˆæ˜¯çº¿æ€§æœ€å°äºŒä¹˜çš„åŸºç¡€ï¼Œè¿™æ˜¯ç§‘å­¦å’Œå·¥ç¨‹ä¸­çº¿æ€§ä»£æ•°çš„æœ€é‡è¦åº”ç”¨ä¹‹ä¸€ã€‚
- en: Vector-Scalar Multiplication
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å‘é‡-æ ‡é‡ä¹˜æ³•
- en: A *scalar* in linear algebra is a number on its own, not embedded in a vector
    or matrix. Scalars are typically indicated using lowercase Greek letters such
    as Î± or Î». Therefore, vector-scalar multiplication is indicated as, for example,
    Î²**u**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§ä»£æ•°ä¸­çš„*æ ‡é‡*æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æ•°å­—ï¼Œä¸åµŒå…¥åœ¨å‘é‡æˆ–çŸ©é˜µä¸­ã€‚æ ‡é‡é€šå¸¸ç”¨å°å†™å¸Œè…Šå­—æ¯è¡¨ç¤ºï¼Œå¦‚Î±æˆ–Î»ã€‚å› æ­¤ï¼Œå‘é‡-æ ‡é‡ä¹˜æ³•è¡¨ç¤ºä¸ºï¼Œä¾‹å¦‚ï¼ŒÎ²**u**ã€‚
- en: 'Vector-scalar multiplication is very simple: multiply each vector element by
    the scalar. One numerical example ([Equation 2-5](#eq-5)) will suffice for understanding:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡-æ ‡é‡ä¹˜æ³•éå¸¸ç®€å•ï¼šå°†æ¯ä¸ªå‘é‡å…ƒç´ ä¹˜ä»¥æ ‡é‡ã€‚ä¸€ä¸ªæ•°å€¼ç¤ºä¾‹ï¼ˆ[æ–¹ç¨‹ 2-5](#eq-5)ï¼‰è¶³ä»¥ç†è§£ï¼š
- en: 'Equation 2-5\. Vector-scalar multiplication (or: scalar-vector multiplication)'
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 2-5\. å‘é‡-æ ‡é‡ä¹˜æ³•ï¼ˆæˆ–ï¼šæ ‡é‡-å‘é‡ä¹˜æ³•ï¼‰
- en: <math alttext="lamda equals 4 comma bold w equals Start 3 By 1 Matrix 1st Row  9
    2nd Row  4 3rd Row  1 EndMatrix comma lamda bold w equals Start 3 By 1 Matrix
    1st Row  36 2nd Row  16 3rd Row  4 EndMatrix" display="block"><mrow><mi>Î»</mi>
    <mo>=</mo> <mn>4</mn> <mo>,</mo> <mi>ğ°</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>9</mn></mtd></mtr>
    <mtr><mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd></mtr></mtable></mfenced>
    <mo>,</mo> <mi>Î»</mi> <mi>ğ°</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>36</mn></mtd></mtr>
    <mtr><mtd><mn>16</mn></mtd></mtr> <mtr><mtd><mn>4</mn></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="lamda equals 4 comma bold w equals Start 3 By 1 Matrix 1st Row  9
    2nd Row  4 3rd Row  1 EndMatrix comma lamda bold w equals Start 3 By 1 Matrix
    1st Row  36 2nd Row  16 3rd Row  4 EndMatrix" display="block"><mrow><mi>Î»</mi>
    <mo>=</mo> <mn>4</mn> <mo>,</mo> <mi>ğ°</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>9</mn></mtd></mtr>
    <mtr><mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>1</mn></mtd></mtr></mtable></mfenced>
    <mo>,</mo> <mi>Î»</mi> <mi>ğ°</mi> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>36</mn></mtd></mtr>
    <mtr><mtd><mn>16</mn></mtd></mtr> <mtr><mtd><mn>4</mn></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'I wrote earlier that the data type of a variable storing a vector is sometimes
    important and sometimes unimportant. Vector-scalar multiplication is an example
    where data type matters:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹‹å‰æåˆ°ï¼Œå­˜å‚¨å‘é‡çš„å˜é‡çš„æ•°æ®ç±»å‹æœ‰æ—¶é‡è¦ï¼Œæœ‰æ—¶ä¸é‡è¦ã€‚å‘é‡-æ ‡é‡ä¹˜æ³•å°±æ˜¯ä¸€ä¸ªæ•°æ®ç±»å‹é‡è¦çš„ä¾‹å­ï¼š
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The code creates a scalar (variable `s`) and a vector as a list (variable `a`),
    then converts that into a NumPy array (variable `b`). The asterisk is overloaded
    in Python, meaning its behavior depends on the variable type: scalar multiplying
    a list repeats the list `s` times (in this case, twice), which is definitely *not*
    the linear algebra operation of scalar-vector multiplication. When the vector
    is stored as a NumPy array, however, the asterisk is interpreted as element-wise
    multiplication. (Hereâ€™s a small exercise for you: what happens if you set `s =
    2.0`, and why?^([1](ch02.xhtml#idm45733300824976))) Both of these operations (list
    repetition and vector-scalar multiplication) are used in real-world coding, so
    be mindful of the distinction.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç åˆ›å»ºäº†ä¸€ä¸ªæ ‡é‡ï¼ˆå˜é‡ `s`ï¼‰å’Œä¸€ä¸ªä½œä¸ºåˆ—è¡¨çš„å‘é‡ï¼ˆå˜é‡ `a`ï¼‰ï¼Œç„¶åå°†å…¶è½¬æ¢ä¸ºNumPyæ•°ç»„ï¼ˆå˜é‡ `b`ï¼‰ã€‚åœ¨Pythonä¸­ï¼Œæ˜Ÿå·çš„è¡Œä¸ºå–å†³äºå˜é‡ç±»å‹ï¼šæ ‡é‡ä¹˜ä»¥åˆ—è¡¨ä¼šé‡å¤åˆ—è¡¨
    `s` æ¬¡ï¼ˆåœ¨æœ¬ä¾‹ä¸­æ˜¯ä¸¤æ¬¡ï¼‰ï¼Œè¿™æ˜¾ç„¶*ä¸æ˜¯*æ ‡é‡-å‘é‡ä¹˜æ³•çš„çº¿æ€§ä»£æ•°æ“ä½œã€‚ç„¶è€Œï¼Œå½“å‘é‡å­˜å‚¨ä¸ºNumPyæ•°ç»„æ—¶ï¼Œæ˜Ÿå·è¢«è§£é‡Šä¸ºå…ƒç´ çº§ä¹˜æ³•ã€‚ï¼ˆè¿™é‡Œæœ‰ä¸ªå°ç»ƒä¹ ï¼šå¦‚æœä½ è®¾ç½®
    `s = 2.0`ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ^([1](ch02.xhtml#idm45733300824976))ï¼‰è¿™ä¸¤ç§æ“ä½œï¼ˆåˆ—è¡¨é‡å¤å’Œå‘é‡-æ ‡é‡ä¹˜æ³•ï¼‰åœ¨å®é™…ç¼–ç ä¸­éƒ½æœ‰ç”¨åˆ°ï¼Œæ‰€ä»¥è¦æ³¨æ„åŒºåˆ«ã€‚
- en: Scalar-Vector Addition
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ ‡é‡-å‘é‡åŠ æ³•
- en: 'Adding a scalar to a vector is not formally defined in linear algebra: they
    are two separate kinds of mathematical objects and cannot be combined. However,
    numerical processing programs like Python will allow adding scalars to vectors,
    and the operation is comparable to scalar-vector multiplication: the scalar is
    added to each vector element. The following code illustrates the idea:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çº¿æ€§ä»£æ•°ä¸­ï¼Œå‘é‡åŠ æ ‡é‡æ²¡æœ‰æ­£å¼å®šä¹‰ï¼šå®ƒä»¬æ˜¯ä¸¤ç§ä¸åŒçš„æ•°å­¦å¯¹è±¡ï¼Œä¸èƒ½ç»“åˆåœ¨ä¸€èµ·ã€‚ç„¶è€Œï¼ŒåƒPythonè¿™æ ·çš„æ•°å€¼å¤„ç†ç¨‹åºå…è®¸å°†æ ‡é‡æ·»åŠ åˆ°å‘é‡ä¸­ï¼Œæ“ä½œç±»ä¼¼äºæ ‡é‡ä¸å‘é‡çš„ä¹˜æ³•ï¼šå°†æ ‡é‡æ·»åŠ åˆ°æ¯ä¸ªå‘é‡å…ƒç´ ä¸Šã€‚ä»¥ä¸‹ä»£ç é˜æ˜äº†è¿™ä¸ªæ¦‚å¿µï¼š
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The geometry of vector-scalar multiplication
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å‘é‡-æ ‡é‡ä¹˜æ³•çš„å‡ ä½•å­¦
- en: Why are scalars called â€œscalarsâ€? That comes from the geometric interpretation.
    Scalars scale vectors without changing their direction. There are four effects
    of vector-scalar multiplication that depend on whether the scalar is greater than
    1, between 0 and 1, exactly 0, or negative. [FigureÂ 2-3](#fig_2_3) illustrates
    the concept.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆæ ‡é‡è¢«ç§°ä¸ºâ€œæ ‡é‡â€ï¼Ÿè¿™æºäºå‡ ä½•è§£é‡Šã€‚æ ‡é‡è°ƒæ•´å‘é‡çš„å¤§å°è€Œä¸æ”¹å˜å…¶æ–¹å‘ã€‚æ ‡é‡ä¸å‘é‡ç›¸ä¹˜æœ‰å››ç§æ•ˆæœï¼Œè¿™å–å†³äºæ ‡é‡æ˜¯å¤§äº1ã€åœ¨0å’Œ1ä¹‹é—´ã€æ°å¥½ä¸º0è¿˜æ˜¯è´Ÿæ•°ã€‚[å›¾Â 2-3](#fig_2_3)
    é˜è¿°äº†è¿™ä¸ªæ¦‚å¿µã€‚
- en: '![Scaling vectors](assets/plad_0203.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![ç¼©æ”¾å‘é‡](assets/plad_0203.png)'
- en: Figure 2-3\. The same vector (black arrow) multiplied by different scalars <math
    alttext="sigma"><mi>Ïƒ</mi></math> (gray line; shifted slightly for visibility)
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2-3\. ç›¸åŒå‘é‡ï¼ˆé»‘è‰²ç®­å¤´ï¼‰ä¹˜ä»¥ä¸åŒæ ‡é‡ <math alttext="sigma"><mi>Ïƒ</mi></math> ï¼ˆç°çº¿ï¼›ç•¥æœ‰ä½ç§»ä»¥ä¾¿çœ‹æ¸…æ¥šï¼‰
- en: I wrote earlier that scalars do not change the direction of the vector. But
    the figure shows that the vector direction flips when the scalar is negative (that
    is, its angle rotates by 180Â°. That might seem a contradiction, but there is an
    interpretation of vectors as pointing along an infinitely long line that passes
    through the origin and goes to infinity in both directions (in the next chapter,
    Iâ€™ll call this a â€œone-dimensional subspaceâ€). In that sense, the â€œrotatedâ€ vector
    still points along the same infinite line and thus the negative scalar does not
    change the direction. This interpretation is important for matrix spaces, eigenvectors,
    and singular vectors, all of which are introduced in later chapters.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹‹å‰å†™è¿‡ï¼Œæ ‡é‡ä¸ä¼šæ”¹å˜å‘é‡çš„æ–¹å‘ã€‚ä½†å›¾ä¸­æ˜¾ç¤ºï¼Œå½“æ ‡é‡ä¸ºè´Ÿæ•°æ—¶å‘é‡æ–¹å‘ä¼šç¿»è½¬ï¼ˆå³å…¶è§’åº¦æ—‹è½¬180Â°ï¼‰ã€‚è¿™ä¼¼ä¹æ˜¯ä¸ªçŸ›ç›¾ï¼Œä½†å¯¹å‘é‡çš„è§£é‡Šæ˜¯æ²¿ç€ä¸€ä¸ªé€šè¿‡åŸç‚¹å¹¶ä¸”æ— é™å»¶ä¼¸åˆ°ä¸¤ä¸ªæ–¹å‘çš„æ— é™é•¿çº¿çš„çº¿ï¼ˆåœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘å°†ç§°å…¶ä¸ºâ€œä¸€ç»´å­ç©ºé—´â€ï¼‰ã€‚ä»è¿™ä¸ªæ„ä¹‰ä¸Šè®²ï¼Œâ€œæ—‹è½¬â€çš„å‘é‡ä»ç„¶æ²¿ç€åŒä¸€æ¡æ— é™çº¿æŒ‡å‘ï¼Œå› æ­¤è´Ÿæ ‡é‡ä¸ä¼šæ”¹å˜å…¶æ–¹å‘ã€‚è¿™ç§è§£é‡Šå¯¹äºçŸ©é˜µç©ºé—´ã€ç‰¹å¾å‘é‡å’Œå¥‡å¼‚å‘é‡éƒ½å¾ˆé‡è¦ï¼Œè¿™äº›æ¦‚å¿µå°†åœ¨åé¢çš„ç« èŠ‚ä¸­ä»‹ç»ã€‚
- en: 'Vector-scalar multiplication in combination with vector addition leads directly
    to *vector averaging*. Averaging vectors is the same as averaging numbers: sum
    and divide by the number of numbers. So, to average two vectors, add them and
    then scalar multiply by .5\. In general, to average *N* vectors, sum them and
    scalar multiply the result by *1/N*.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡æ ‡é‡ä¹˜æ³•ä¸å‘é‡åŠ æ³•ç»“åˆç›´æ¥å¯¼è‡´*å‘é‡å¹³å‡*ã€‚å¯¹å‘é‡è¿›è¡Œå¹³å‡å°±åƒå¯¹æ•°å­—è¿›è¡Œå¹³å‡ä¸€æ ·ï¼šæ±‚å’Œç„¶åé™¤ä»¥æ•°å­—çš„æ•°é‡ã€‚å› æ­¤ï¼Œè¦å¯¹ä¸¤ä¸ªå‘é‡è¿›è¡Œå¹³å‡ï¼Œå…ˆå°†å®ƒä»¬ç›¸åŠ ï¼Œç„¶åä¹˜ä»¥0.5ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œè¦å¯¹*N*ä¸ªå‘é‡è¿›è¡Œå¹³å‡ï¼Œå°†å®ƒä»¬æ±‚å’Œï¼Œç„¶åå°†ç»“æœä¹˜ä»¥*1/N*ã€‚
- en: Transpose
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è½¬ç½®
- en: 'You already learned about the transpose operation: it converts column vectors
    into row vectors, and vice versa. Let me provide a slightly more formal definition
    that will generalize to transposing matrices (a topic in [ChapterÂ 5](ch05.xhtml#Chapter_5)).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å·²ç»äº†è§£äº†è½¬ç½®æ“ä½œï¼šå®ƒå°†åˆ—å‘é‡è½¬æ¢ä¸ºè¡Œå‘é‡ï¼Œåä¹‹äº¦ç„¶ã€‚è®©æˆ‘æä¾›ä¸€ä¸ªç¨å¾®æ›´æ­£å¼çš„å®šä¹‰ï¼Œå°†æ¨å¹¿åˆ°è½¬ç½®çŸ©é˜µï¼ˆè¿™æ˜¯[ç¬¬5ç« ](ch05.xhtml#Chapter_5)ä¸­çš„ä¸€ä¸ªä¸»é¢˜ï¼‰ã€‚
- en: 'A matrix has rows and columns; therefore, each matrix element has a (*row,column*)
    index. The transpose operation simply swaps those indices. This is formalized
    in [Equation 2-6](#eq-6):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: çŸ©é˜µæœ‰è¡Œå’Œåˆ—ï¼›å› æ­¤ï¼Œæ¯ä¸ªçŸ©é˜µå…ƒç´ éƒ½æœ‰ä¸€ä¸ª(*è¡Œ,åˆ—*)ç´¢å¼•ã€‚è½¬ç½®æ“ä½œç®€å•åœ°äº¤æ¢è¿™äº›ç´¢å¼•ã€‚è¿™åœ¨[æ–¹ç¨‹2-6](#eq-6)ä¸­å¾—åˆ°äº†æ­£å¼åŒ–ï¼š
- en: Equation 2-6\. The transpose operation
  id: totrans-82
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹2-6ã€‚è½¬ç½®æ“ä½œ
- en: <math alttext="bold m Subscript i comma j Superscript upper T Baseline equals
    bold m Subscript j comma i" display="block"><mrow><msubsup><mi>ğ¦</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow>
    <mtext>T</mtext></msubsup> <mo>=</mo> <msub><mi>ğ¦</mi> <mrow><mi>j</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow></math>
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold m Subscript i comma j Superscript upper T Baseline equals
    bold m Subscript j comma i" display="block"><mrow><msubsup><mi>ğ¦</mi> <mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow>
    <mtext>T</mtext></msubsup> <mo>=</mo> <msub><mi>ğ¦</mi> <mrow><mi>j</mi><mo>,</mo><mi>i</mi></mrow></msub></mrow></math>
- en: Vectors have either one row or one column, depending on their orientation. For
    example, a 6D row vector has *i* = 1 and *j* indices from 1 to 6, whereas a 6D
    column vector has *i* indices from 1 to 6 and *j* = 1\. So swapping the *i,j*
    indices swaps the rows and columns.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡çš„æ–¹å‘æœ‰ä¸€è¡Œæˆ–ä¸€åˆ—ï¼Œè¿™å–å†³äºå®ƒä»¬çš„æ–¹å‘ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ª6ç»´è¡Œå‘é‡æœ‰*i* = 1å’Œ*j*ä»1åˆ°6çš„ç´¢å¼•ï¼Œè€Œä¸€ä¸ª6ç»´åˆ—å‘é‡æœ‰*i*ä»1åˆ°6çš„ç´¢å¼•å’Œ*j*
    = 1ã€‚å› æ­¤ï¼Œäº¤æ¢*i,j*ç´¢å¼•ä¼šäº¤æ¢è¡Œå’Œåˆ—ã€‚
- en: 'Hereâ€™s an important rule: transposing twice returns the vector to its original
    orientation. In other words, <math alttext="bold v Superscript TT Baseline equals
    bold v"><mrow><msup><mi>ğ¯</mi> <mtext>TT</mtext></msup> <mo>=</mo> <mi>ğ¯</mi></mrow></math>
    . That may seem obvious and trivial, but it is the keystone of several important
    proofs in data science and machine learning, including creating symmetric covariance
    matrices as the data matrix times its transpose (which in turn is the reason why
    a principal components analysis is an orthogonal rotation of the data spaceâ€¦donâ€™t
    worry, that sentence will make sense later in the book!).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªé‡è¦çš„è§„åˆ™ï¼šä¸¤æ¬¡è½¬ç½®å°†å‘é‡è¿”å›åˆ°å…¶åŸå§‹æ–¹å‘ã€‚æ¢å¥è¯è¯´ï¼Œ<math alttext="bold v Superscript TT Baseline
    equals bold v"><mrow><msup><mi>ğ¯</mi> <mtext>TT</mtext></msup> <mo>=</mo> <mi>ğ¯</mi></mrow></math>
    ã€‚è¿™å¯èƒ½çœ‹èµ·æ¥æ˜¾è€Œæ˜“è§å’Œçç¢ï¼Œä½†å®ƒæ˜¯æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ ä¸­å‡ ä¸ªé‡è¦è¯æ˜çš„åŸºçŸ³ï¼ŒåŒ…æ‹¬åˆ›å»ºå¯¹ç§°åæ–¹å·®çŸ©é˜µä½œä¸ºæ•°æ®çŸ©é˜µä¹˜ä»¥å…¶è½¬ç½®ï¼ˆè¿™ä¹Ÿæ˜¯ä¸»æˆåˆ†åˆ†æå°†æ•°æ®ç©ºé—´è¿›è¡Œæ­£äº¤æ—‹è½¬çš„åŸå› â€¦â€¦åˆ«æ‹…å¿ƒï¼Œè¿™ä¸ªå¥å­ä»¥ååœ¨æœ¬ä¹¦ä¸­ä¼šæœ‰æ›´å¤šè§£é‡Šï¼ï¼‰ã€‚
- en: Vector Broadcasting in Python
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pythonä¸­çš„å‘é‡å¹¿æ’­
- en: Broadcasting is an operation that exists only in modern computer-based linear
    algebra; this is not a procedure you would find in a traditional linear algebra
    textbook.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¿æ’­æ˜¯ä¸€ç§ä»…å­˜åœ¨äºç°ä»£åŸºäºè®¡ç®—æœºçš„çº¿æ€§ä»£æ•°ä¸­çš„æ“ä½œï¼›è¿™ä¸æ˜¯ä¼ ç»Ÿçº¿æ€§ä»£æ•°æ•™ç§‘ä¹¦ä¸­ä¼šæ‰¾åˆ°çš„è¿‡ç¨‹ã€‚
- en: 'Broadcasting essentially means to repeat an operation multiple times between
    one vector and each element of another vector. Consider the following series of
    equations:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¿æ’­æœ¬è´¨ä¸Šæ„å‘³ç€åœ¨ä¸€ä¸ªå‘é‡å’Œå¦ä¸€ä¸ªå‘é‡çš„æ¯ä¸ªå…ƒç´ ä¹‹é—´å¤šæ¬¡é‡å¤ä¸€ä¸ªæ“ä½œã€‚è€ƒè™‘ä»¥ä¸‹ä¸€ç³»åˆ—æ–¹ç¨‹ï¼š
- en: <math alttext="StartLayout 1st Row  Start 1 By 2 Matrix 1st Row 1st Column 1
    2nd Column 1 EndMatrix plus Start 1 By 2 Matrix 1st Row 1st Column 10 2nd Column
    20 EndMatrix 2nd Row  Start 1 By 2 Matrix 1st Row 1st Column 2 2nd Column 2 EndMatrix
    plus Start 1 By 2 Matrix 1st Row 1st Column 10 2nd Column 20 EndMatrix 3rd Row  Start
    1 By 2 Matrix 1st Row 1st Column 3 2nd Column 3 EndMatrix plus Start 1 By 2 Matrix
    1st Row 1st Column 10 2nd Column 20 EndMatrix EndLayout" display="block"><mtable><mtr><mtd><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced>
    <mo>+</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd> <mtd><mn>20</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr>
    <mtr><mtd><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>2</mn></mtd>
    <mtd><mn>2</mn></mtd></mtr></mtable></mfenced> <mo>+</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd>
    <mtd><mn>20</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr> <mtr><mtd><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mn>3</mn></mtd> <mtd><mn>3</mn></mtd></mtr></mtable></mfenced>
    <mo>+</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd> <mtd><mn>20</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row  Start 1 By 2 Matrix 1st Row 1st Column 1
    2nd Column 1 EndMatrix plus Start 1 By 2 Matrix 1st Row 1st Column 10 2nd Column
    20 EndMatrix 2nd Row  Start 1 By 2 Matrix 1st Row 1st Column 2 2nd Column 2 EndMatrix
    plus Start 1 By 2 Matrix 1st Row 1st Column 10 2nd Column 20 EndMatrix 3rd Row  Start
    1 By 2 Matrix 1st Row 1st Column 3 2nd Column 3 EndMatrix plus Start 1 By 2 Matrix
    1st Row 1st Column 10 2nd Column 20 EndMatrix EndLayout" display="block"><mtable><mtr><mtd><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd> <mtd><mn>1</mn></mtd></mtr></mtable></mfenced>
    <mo>+</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd> <mtd><mn>20</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr>
    <mtr><mtd><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>2</mn></mtd>
    <mtd><mn>2</mn></mtd></mtr></mtable></mfenced> <mo>+</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd>
    <mtd><mn>20</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr> <mtr><mtd><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mn>3</mn></mtd> <mtd><mn>3</mn></mtd></mtr></mtable></mfenced>
    <mo>+</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>10</mn></mtd> <mtd><mn>20</mn></mtd></mtr></mtable></mfenced></mrow></mtd></mtr></mtable></math>
- en: 'Notice the patterns in the vectors. We can implement this set of equations
    compactly by condensing those patterns into vectors [1 2 3] and [10 20], and then
    broadcasting the addition. Hereâ€™s how it looks in Python:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„å‘é‡ä¸­çš„æ¨¡å¼ã€‚æˆ‘ä»¬å¯ä»¥å°†è¿™ç»„æ–¹ç¨‹ç´§å‡‘åœ°å®ç°ä¸ºå‘é‡[1 2 3]å’Œ[10 20]ï¼Œç„¶åå¹¿æ’­åŠ æ³•ã€‚ä»¥ä¸‹æ˜¯Pythonä¸­çš„å®ç°æ–¹å¼ï¼š
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here again you can see the importance of orientation in linear algebra operations:
    try running the code above, changing `v` into a row vector and `w` into a column
    vector.^([2](ch02.xhtml#idm45733308090944))'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å†æ¬¡å¯ä»¥çœ‹åˆ°çº¿æ€§ä»£æ•°æ“ä½œä¸­æ–¹å‘çš„é‡è¦æ€§ï¼šå°è¯•è¿è¡Œä¸Šé¢çš„ä»£ç ï¼Œå°†`v`å˜æˆä¸€ä¸ªè¡Œå‘é‡å’Œ`w`å˜æˆä¸€ä¸ªåˆ—å‘é‡ã€‚^([2](ch02.xhtml#idm45733308090944))
- en: Because broadcasting allows for efficient and compact computations, it is used
    often in numerical coding. Youâ€™ll see several examples of broadcasting in this
    book, including in the section on *k*-means clustering ([ChapterÂ 4](ch04.xhtml#Chapter_4)).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºå¹¿æ’­å…è®¸è¿›è¡Œé«˜æ•ˆç´§å‡‘çš„è®¡ç®—ï¼Œå®ƒç»å¸¸åœ¨æ•°å€¼ç¼–ç ä¸­ä½¿ç”¨ã€‚æ‚¨å°†åœ¨æœ¬ä¹¦ä¸­çœ‹åˆ°å‡ ä¸ªå¹¿æ’­çš„ä¾‹å­ï¼ŒåŒ…æ‹¬* k * -å‡å€¼èšç±»éƒ¨åˆ†ï¼ˆ[ç¬¬4ç« ](ch04.xhtml#Chapter_4)ï¼‰ã€‚
- en: Vector Magnitude and Unit Vectors
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‘é‡å¤§å°å’Œå•ä½å‘é‡
- en: 'The *magnitude* of a vectorâ€”also called the *geometric length* or the *norm*â€”is
    the distance from tail to head of a vector, and is computed using the standard
    Euclidean distance formula: the square root of the sum of squared vector elements
    (see [Equation 2-7](#vector-norm)). Vector magnitude is indicated using double-vertical
    bars around the vector: <math alttext="parallel-to bold v parallel-to"><mrow><mo>âˆ¥</mo>
    <mi>ğ¯</mi> <mo>âˆ¥</mo></mrow></math> .'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªå‘é‡çš„*å¤§å°* â€”â€” ä¹Ÿç§°ä¸º*å‡ ä½•é•¿åº¦* æˆ– *èŒƒæ•°* â€”â€” æ˜¯ä»å‘é‡çš„å°¾åˆ°å¤´çš„è·ç¦»ï¼Œå¹¶ä¸”ä½¿ç”¨æ ‡å‡†æ¬§å‡ é‡Œå¾·è·ç¦»å…¬å¼è®¡ç®—ï¼šå‘é‡å…ƒç´ çš„å¹³æ–¹å’Œçš„å¹³æ–¹æ ¹ï¼ˆè§
    [æ–¹ç¨‹ 2-7](#vector-norm)ï¼‰ã€‚å‘é‡å¤§å°ç”¨åŒç«–çº¿æ ‡ç¤ºåœ¨å‘é‡å‘¨å›´ï¼š<math alttext="parallel-to bold v parallel-to"><mrow><mo>âˆ¥</mo>
    <mi>ğ¯</mi> <mo>âˆ¥</mo></mrow></math> ã€‚
- en: Equation 2-7\. The norm of a vector
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 2-7\. çŸ¢é‡çš„èŒƒæ•°
- en: <math alttext="parallel-to bold v parallel-to equals StartRoot sigma-summation
    Underscript i equals 1 Overscript n Endscripts v Subscript i Superscript 2 Baseline
    EndRoot" display="block"><mrow><mrow><mo>âˆ¥</mo> <mi>ğ¯</mi> <mo>âˆ¥</mo></mrow> <mo>=</mo>
    <msqrt><mrow><msubsup><mo>âˆ‘</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <msubsup><mi>v</mi> <mi>i</mi> <mn>2</mn></msubsup></mrow></msqrt></mrow></math>
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="parallel-to bold v parallel-to equals StartRoot sigma-summation
    Underscript i equals 1 Overscript n Endscripts v Subscript i Superscript 2 Baseline
    EndRoot" display="block"><mrow><mrow><mo>âˆ¥</mo> <mi>ğ¯</mi> <mo>âˆ¥</mo></mrow> <mo>=</mo>
    <msqrt><mrow><msubsup><mo>âˆ‘</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <msubsup><mi>v</mi> <mi>i</mi> <mn>2</mn></msubsup></mrow></msqrt></mrow></math>
- en: Some applications use squared magnitudes (written âˆ¥ ğ¯ âˆ¥Â²), in which case the
    square root term on the right-hand side drops out.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº›åº”ç”¨ç¨‹åºä½¿ç”¨å¹³æ–¹å¹…åº¦ï¼ˆå†™æˆ âˆ¥ ğ¯ âˆ¥Â² ï¼‰ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå³ä¾§çš„å¹³æ–¹æ ¹é¡¹æ¶ˆå¤±ã€‚
- en: 'Before showing the Python code, let me explain some more terminological discrepancies
    between â€œchalkboardâ€ linear algebra and Python linear algebra. In mathematics,
    the dimensionality of a vector is the number of elements in that vector, while
    the length is a geometric distance; in Python, the function `len()` (where `len`
    is short for *length*) returns the *dimensionality* of an array, while the function
    `np.norm()` returns the geometric length (magnitude). In this book, I will use
    the term *magnitude* (or *geometric length*) instead of *length* to avoid confusion:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨å±•ç¤º Python ä»£ç ä¹‹å‰ï¼Œè®©æˆ‘è§£é‡Šä¸€äº›â€œé»‘æ¿â€çº¿æ€§ä»£æ•°ä¸ Python çº¿æ€§ä»£æ•°ä¹‹é—´çš„æœ¯è¯­å·®å¼‚ã€‚åœ¨æ•°å­¦ä¸­ï¼Œå‘é‡çš„ç»´æ•°æ˜¯è¯¥å‘é‡ä¸­å…ƒç´ çš„æ•°é‡ï¼Œè€Œé•¿åº¦æ˜¯å‡ ä½•è·ç¦»ï¼›åœ¨
    Python ä¸­ï¼Œå‡½æ•° `len()`ï¼ˆå…¶ä¸­ `len` ç¼©å†™ä¸º *length*ï¼‰è¿”å›æ•°ç»„çš„ *ç»´æ•°*ï¼Œè€Œå‡½æ•° `np.norm()` è¿”å›å‡ ä½•é•¿åº¦ï¼ˆå¤§å°ï¼‰ã€‚åœ¨æœ¬ä¹¦ä¸­ï¼Œæˆ‘å°†ä½¿ç”¨æœ¯è¯­
    *å¤§å°*ï¼ˆæˆ– *å‡ ä½•é•¿åº¦*ï¼‰ä»£æ›¿ *é•¿åº¦*ï¼Œä»¥é¿å…æ··æ·†ï¼š
- en: '[PRE8]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: There are some applications where we want a vector that has a geometric length
    of one, which is called a *unit vector*. Example applications include orthogonal
    matrices, rotation matrices, eigenvectors, and singular vectors.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰äº›åº”ç”¨ç¨‹åºéœ€è¦ä¸€ä¸ªå‡ ä½•é•¿åº¦ä¸ºä¸€çš„å‘é‡ï¼Œè¿™è¢«ç§°ä¸º*å•ä½å‘é‡*ã€‚ä¾‹å¦‚åº”ç”¨åŒ…æ‹¬æ­£äº¤çŸ©é˜µã€æ—‹è½¬çŸ©é˜µã€ç‰¹å¾å‘é‡å’Œå¥‡å¼‚å‘é‡ã€‚
- en: A unit vector is defined as <math alttext="parallel-to bold v parallel-to equals
    1"><mrow><mo>âˆ¥</mo> <mi>ğ¯</mi> <mo>âˆ¥</mo> <mo>=</mo> <mn>1</mn></mrow></math>
    .
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: å•ä½å‘é‡è¢«å®šä¹‰ä¸º <math alttext="parallel-to bold v parallel-to equals 1"><mrow><mo>âˆ¥</mo>
    <mi>ğ¯</mi> <mo>âˆ¥</mo> <mo>=</mo> <mn>1</mn></mrow></math> ã€‚
- en: 'Needless to say, lots of vectors are not unit vectors. (Iâ€™m tempted to write
    â€œmost vectors are not unit vectors,â€ but there is an infinite number of unit vectors
    and nonunit vectors, although the set of infinite nonunit vectors is larger than
    the set of infinite unit vectors.) Fortunately, any nonunit vector has an associated
    unit vector. That means that we can create a unit vector in the same direction
    as a nonunit vector. Creating an associated unit vector is easy; you simply scalar
    multiply by the reciprocal of the vector norm ([Equation 2-8](#eq-vecnorm)):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯«æ— ç–‘é—®ï¼Œå¤§é‡å‘é‡å¹¶éå•ä½å‘é‡ã€‚ï¼ˆæˆ‘å¾ˆæƒ³å†™â€œå¤§å¤šæ•°å‘é‡ä¸æ˜¯å•ä½å‘é‡â€ï¼Œä½†æ˜¯éå•ä½å‘é‡å’Œå•ä½å‘é‡éƒ½æœ‰æ— ç©·å¤šä¸ªï¼Œå°½ç®¡éå•ä½å‘é‡çš„é›†åˆå¤§äºå•ä½å‘é‡çš„é›†åˆã€‚ï¼‰å¹¸è¿çš„æ˜¯ï¼Œä»»ä½•éå•ä½å‘é‡éƒ½æœ‰ä¸€ä¸ªç›¸å…³è”çš„å•ä½å‘é‡ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªä¸éå•ä½å‘é‡æ–¹å‘ç›¸åŒçš„å•ä½å‘é‡ã€‚åˆ›å»ºç›¸å…³è”çš„å•ä½å‘é‡å¾ˆå®¹æ˜“ï¼›ä½ åªéœ€ä¹˜ä»¥çŸ¢é‡èŒƒæ•°çš„å€’æ•°ï¼ˆ[æ–¹ç¨‹
    2-8](#eq-vecnorm)ï¼‰ï¼š
- en: Equation 2-8\. Creating a unit vector
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹ 2-8\. åˆ›å»ºå•ä½å‘é‡
- en: <math alttext="ModifyingAbove bold v With caret equals StartFraction 1 Over
    parallel-to bold v parallel-to EndFraction bold v" display="block"><mrow><mover
    accent="true"><mi>ğ¯</mi> <mo>^</mo></mover> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mo>âˆ¥</mo><mi>ğ¯</mi><mo>âˆ¥</mo></mrow></mfrac>
    <mi>ğ¯</mi></mrow></math>
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="ModifyingAbove bold v With caret equals StartFraction 1 Over
    parallel-to bold v parallel-to EndFraction bold v" display="block"><mrow><mover
    accent="true"><mi>ğ¯</mi> <mo>^</mo></mover> <mo>=</mo> <mfrac><mn>1</mn> <mrow><mo>âˆ¥</mo><mi>ğ¯</mi><mo>âˆ¥</mo></mrow></mfrac>
    <mi>ğ¯</mi></mrow></math>
- en: You can see the common convention for indicating unit vectors ( <math alttext="ModifyingAbove
    bold v With caret"><mover accent="true"><mi>ğ¯</mi> <mo>^</mo></mover></math> )
    in the same direction as their parent vector <math alttext="bold v"><mi>ğ¯</mi></math>
    . [FigureÂ 2-4](#fig_2_4) illustrates these cases.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯ä»¥çœ‹åˆ°è¡¨ç¤ºå•ä½å‘é‡çš„å¸¸è§çº¦å®šï¼ˆ <math alttext="ModifyingAbove bold v With caret"><mover accent="true"><mi>ğ¯</mi>
    <mo>^</mo></mover></math> ï¼‰ä¸å…¶çˆ¶å‘é‡ <math alttext="bold v"><mi>ğ¯</mi></math> åœ¨ç›¸åŒæ–¹å‘ä¸Šçš„æƒ…å†µã€‚[å›¾
    2-4](#fig_2_4) é˜æ˜äº†è¿™äº›æƒ…å†µã€‚
- en: '![Vector buddies](assets/plad_0204.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![çŸ¢é‡æœ‹å‹ä»¬](assets/plad_0204.png)'
- en: Figure 2-4\. A unit vector (gray arrow) can be crafted from a nonunit vector
    (black arrow); both vectors have the same angle but different magnitudes
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2-4\. ä¸€ä¸ªå•ä½å‘é‡ï¼ˆç°è‰²ç®­å¤´ï¼‰å¯ä»¥ä»ä¸€ä¸ªéå•ä½å‘é‡ï¼ˆé»‘è‰²ç®­å¤´ï¼‰ä¸­åˆ¶ä½œå‡ºæ¥ï¼›è¿™ä¸¤ä¸ªå‘é‡æœ‰ç›¸åŒçš„è§’åº¦ä½†ä¸åŒçš„å¤§å°ã€‚
- en: Actually, the claim that â€œ*any* nonunit vector has an associated unit vectorâ€
    is not entirely true. There is a vector that has nonunit length and yet has no
    associated unit vector. Can you guess which vector it is?^([3](ch02.xhtml#idm45733307857968))
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œâ€œ*ä»»ä½•* éå•ä½å‘é‡éƒ½æœ‰ç›¸å…³è”çš„å•ä½å‘é‡â€è¿™ä¸€è¯´æ³•å¹¶ä¸å®Œå…¨æ­£ç¡®ã€‚æœ‰ä¸€ä¸ªçŸ¢é‡å…¶é•¿åº¦ä¸ºéå•ä½é•¿åº¦ï¼Œä½†æ²¡æœ‰ç›¸å…³è”çš„å•ä½å‘é‡ã€‚ä½ èƒ½çŒœå‡ºè¿™æ˜¯å“ªä¸ªå‘é‡å—ï¼Ÿ^([3](ch02.xhtml#idm45733307857968))
- en: Iâ€™m not showing Python code to create unit vectors here, because thatâ€™s one
    of the exercises at the end of this chapter.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œä¸å±•ç¤ºåˆ›å»ºå•ä½å‘é‡çš„ Python ä»£ç ï¼Œå› ä¸ºè¿™æ˜¯æœ¬ç« æœ«å°¾çš„ä¸€ä¸ªç»ƒä¹ ä¹‹ä¸€ã€‚
- en: The Vector Dot Product
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‘é‡ç‚¹ç§¯
- en: The *dot product* (also sometimes called the *inner product*) is one of the
    most important operations in all of linear algebra. It is the basic computational
    building block from which many operations and algorithms are built, including
    convolution, correlation, the Fourier transform, matrix multiplication, linear
    feature extraction, signal filtering, and so on.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*ç‚¹ç§¯*ï¼ˆæœ‰æ—¶ä¹Ÿç§°ä¸º*å†…ç§¯*ï¼‰æ˜¯çº¿æ€§ä»£æ•°ä¸­æœ€é‡è¦çš„æ“ä½œä¹‹ä¸€ã€‚å®ƒæ˜¯è®¸å¤šæ“ä½œå’Œç®—æ³•çš„åŸºæœ¬è®¡ç®—æ¨¡å—ï¼ŒåŒ…æ‹¬å·ç§¯ã€ç›¸å…³æ€§ã€å‚…é‡Œå¶å˜æ¢ã€çŸ©é˜µä¹˜æ³•ã€çº¿æ€§ç‰¹å¾æå–ã€ä¿¡å·è¿‡æ»¤ç­‰ã€‚'
- en: There are several ways to indicate the dot product between two vectors. I will
    mostly use the common notation <math alttext="bold a Superscript upper T Baseline
    bold b"><mrow><msup><mi>ğš</mi> <mtext>T</mtext></msup> <mi>ğ›</mi></mrow></math>
    for reasons that will become clear after learning about matrix multiplication.
    In other contexts you might see <math alttext="bold a dot bold b"><mrow><mi>ğš</mi>
    <mo>Â·</mo> <mi>ğ›</mi></mrow></math> or <math alttext="mathematical left-angle
    bold a comma bold b mathematical right-angle"><mrow><mo>âŒ©</mo> <mi>ğš</mi> <mo>,</mo>
    <mi>ğ›</mi> <mo>âŒª</mo></mrow></math> .
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰å‡ ç§æ–¹æ³•å¯ä»¥è¡¨ç¤ºä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç‚¹ç§¯ã€‚å‡ºäºæŸäº›åŸå› ï¼Œåœ¨å­¦ä¹ çŸ©é˜µä¹˜æ³•åï¼Œæˆ‘å°†ä¸»è¦ä½¿ç”¨å¸¸è§çš„ç¬¦å· <math alttext="bold a Superscript
    upper T Baseline bold b"><mrow><msup><mi>ğš</mi> <mtext>T</mtext></msup> <mi>ğ›</mi></mrow></math>
    ã€‚åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œæ‚¨å¯èƒ½ä¼šçœ‹åˆ° <math alttext="bold a dot bold b"><mrow><mi>ğš</mi> <mo>Â·</mo> <mi>ğ›</mi></mrow></math>
    æˆ– <math alttext="mathematical left-angle bold a comma bold b mathematical right-angle"><mrow><mo>âŒ©</mo>
    <mi>ğš</mi> <mo>,</mo> <mi>ğ›</mi> <mo>âŒª</mo></mrow></math> ã€‚
- en: The dot product is a single number that provides information about the relationship
    between two vectors. Letâ€™s first focus on the algorithm to compute the dot product,
    and then Iâ€™ll discuss how to interpret it.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹ç§¯æ˜¯ä¸€ä¸ªå•ä¸€çš„æ•°å­—ï¼Œæä¾›å…³äºä¸¤ä¸ªå‘é‡ä¹‹é—´å…³ç³»çš„ä¿¡æ¯ã€‚è®©æˆ‘ä»¬é¦–å…ˆä¸“æ³¨äºè®¡ç®—ç‚¹ç§¯çš„ç®—æ³•ï¼Œç„¶åæˆ‘ä¼šè®¨è®ºå¦‚ä½•è§£é‡Šå®ƒã€‚
- en: 'To compute the dot product, you multiply the corresponding elements of the
    two vectors, and then sum over all the individual products. In other words: element-wise
    multiplication and sum. In [Equation 2-9](#dp-alg), **a** and **b** are vectors,
    and a[i] indicates the *i*th element of **a**.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: è¦è®¡ç®—ç‚¹ç§¯ï¼Œæ‚¨éœ€è¦å°†ä¸¤ä¸ªå‘é‡çš„å¯¹åº”å…ƒç´ ç›¸ä¹˜ï¼Œç„¶åå°†æ‰€æœ‰å•ä¸ªä¹˜ç§¯æ±‚å’Œã€‚æ¢å¥è¯è¯´ï¼šé€å…ƒç´ ä¹˜æ³•å’Œæ±‚å’Œã€‚åœ¨ [æ–¹ç¨‹å¼ 2-9](#dp-alg) ä¸­ï¼Œ**a**
    å’Œ **b** æ˜¯å‘é‡ï¼Œa[i] è¡¨ç¤º **a** çš„ç¬¬ *i* ä¸ªå…ƒç´ ã€‚
- en: Equation 2-9\. Dot product formula
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹å¼ 2-9\. ç‚¹ç§¯å…¬å¼
- en: <math alttext="delta equals sigma-summation Underscript i equals 1 Overscript
    n Endscripts a Subscript i Baseline b Subscript i" display="block"><mrow><mi>Î´</mi>
    <mo>=</mo> <munderover><mo>âˆ‘</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></munderover> <msub><mtext>a</mtext> <mi>i</mi></msub> <msub><mtext>b</mtext>
    <mi>i</mi></msub></mrow></math>
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="delta equals sigma-summation Underscript i equals 1 Overscript
    n Endscripts a Subscript i Baseline b Subscript i" display="block"><mrow><mi>Î´</mi>
    <mo>=</mo> <munderover><mo>âˆ‘</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></munderover> <msub><mtext>a</mtext> <mi>i</mi></msub> <msub><mtext>b</mtext>
    <mi>i</mi></msub></mrow></math>
- en: 'You can tell from the formula that the dot product is valid only between two
    vectors of the same dimensionality. [Equation 2-10](#dp-cal) shows a numerical
    example:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ä»å…¬å¼å¯ä»¥çœ‹å‡ºï¼Œç‚¹ç§¯åªåœ¨ç›¸åŒç»´åº¦çš„ä¸¤ä¸ªå‘é‡ä¹‹é—´æœ‰æ•ˆã€‚[æ–¹ç¨‹å¼ 2-10](#dp-cal) å±•ç¤ºäº†ä¸€ä¸ªæ•°å€¼ç¤ºä¾‹ï¼š
- en: Equation 2-10\. Example dot product calculation
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹å¼ 2-10\. ç¤ºä¾‹ç‚¹ç§¯è®¡ç®—
- en: <math alttext="StartLayout 1st Row 1st Column Start 1 By 4 Matrix 1st Row 1st
    Column 1 2nd Column 2 3rd Column 3 4th Column 4 EndMatrix dot Start 1 By 4 Matrix
    1st Row 1st Column 5 2nd Column 6 3rd Column 7 4th Column 8 EndMatrix 2nd Column
    equals 1 times 5 plus 2 times 6 plus 3 times 7 plus 4 times 8 2nd Row 1st Column
    Blank 2nd Column equals 5 plus 12 plus 21 plus 32 3rd Row 1st Column Blank 2nd
    Column equals 70 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>2</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>4</mn></mtd></mtr></mtable></mfenced>
    <mo>Â·</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>5</mn></mtd> <mtd><mn>6</mn></mtd>
    <mtd><mn>7</mn></mtd> <mtd><mn>8</mn></mtd></mtr></mtable></mfenced></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mn>1</mn> <mo>Ã—</mo> <mn>5</mn> <mo>+</mo>
    <mn>2</mn> <mo>Ã—</mo> <mn>6</mn> <mo>+</mo> <mn>3</mn> <mo>Ã—</mo> <mn>7</mn> <mo>+</mo>
    <mn>4</mn> <mo>Ã—</mo> <mn>8</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mo>=</mo>
    <mn>5</mn> <mo>+</mo> <mn>12</mn> <mo>+</mo> <mn>21</mn> <mo>+</mo> <mn>32</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mo>=</mo> <mn>70</mn></mrow></mtd></mtr></mtable></math>
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column Start 1 By 4 Matrix 1st Row 1st
    Column 1 2nd Column 2 3rd Column 3 4th Column 4 EndMatrix dot Start 1 By 4 Matrix
    1st Row 1st Column 5 2nd Column 6 3rd Column 7 4th Column 8 EndMatrix 2nd Column
    equals 1 times 5 plus 2 times 6 plus 3 times 7 plus 4 times 8 2nd Row 1st Column
    Blank 2nd Column equals 5 plus 12 plus 21 plus 32 3rd Row 1st Column Blank 2nd
    Column equals 70 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>1</mn></mtd>
    <mtd><mn>2</mn></mtd> <mtd><mn>3</mn></mtd> <mtd><mn>4</mn></mtd></mtr></mtable></mfenced>
    <mo>Â·</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mn>5</mn></mtd> <mtd><mn>6</mn></mtd>
    <mtd><mn>7</mn></mtd> <mtd><mn>8</mn></mtd></mtr></mtable></mfenced></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mn>1</mn> <mo>Ã—</mo> <mn>5</mn> <mo>+</mo>
    <mn>2</mn> <mo>Ã—</mo> <mn>6</mn> <mo>+</mo> <mn>3</mn> <mo>Ã—</mo> <mn>7</mn> <mo>+</mo>
    <mn>4</mn> <mo>Ã—</mo> <mn>8</mn></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mo>=</mo>
    <mn>5</mn> <mo>+</mo> <mn>12</mn> <mo>+</mo> <mn>21</mn> <mo>+</mo> <mn>32</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="left"><mrow><mo>=</mo> <mn>70</mn></mrow></mtd></mtr></mtable></math>
- en: Irritations of Indexing
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç´¢å¼•çš„çƒ¦æ¼
- en: Standard mathematical notation, and some math-oriented numerical processing
    programs like MATLAB and Julia, start indexing at 1 and stop at *N*, whereas some
    programming languages like Python and Java start indexing at 0 and stop at *N*
    âˆ’ 1\. We need not debate the merits and limitations of each conventionâ€”though
    I do sometimes wonder how many bugs this inconsistency has introduced into human
    civilizationâ€”but it is important to be mindful of this difference when translating
    formulas into Python code.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: æ ‡å‡†æ•°å­¦è¡¨ç¤ºæ³•å’Œä¸€äº›æ•°å­¦å¯¼å‘çš„æ•°å€¼å¤„ç†ç¨‹åºï¼Œå¦‚ MATLAB å’Œ Juliaï¼Œä»1å¼€å§‹ç´¢å¼•ï¼Œåˆ° *N* ç»“æŸï¼›è€Œä¸€äº›ç¼–ç¨‹è¯­è¨€å¦‚ Python å’Œ Java
    ä»0å¼€å§‹ç´¢å¼•ï¼Œåˆ° *N* âˆ’ 1 ç»“æŸã€‚æˆ‘ä»¬ä¸éœ€è¦è¾©è®ºæ¯ç§çº¦å®šçš„ä¼˜ç¼ºç‚¹ â€” è™½ç„¶æˆ‘æœ‰æ—¶ä¼šæƒ³çŸ¥é“è¿™ç§ä¸ä¸€è‡´æ€§å¼•å…¥äº†å¤šå°‘é”™è¯¯åˆ°äººç±»æ–‡æ˜ä¸­ â€” ä½†åœ¨å°†å…¬å¼ç¿»è¯‘ä¸º
    Python ä»£ç æ—¶æ³¨æ„è¿™ç§å·®å¼‚æ˜¯å¾ˆé‡è¦çš„ã€‚
- en: 'There are multiple ways to implement the dot product in Python; the most straightforward
    way is to the use the `np.dot()` function:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Python ä¸­å®ç°ç‚¹ç§¯æœ‰å¤šç§æ–¹æ³•ï¼›æœ€ç›´æ¥çš„æ–¹æ³•æ˜¯ä½¿ç”¨ `np.dot()` å‡½æ•°ã€‚
- en: '[PRE9]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note About np.dot()
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…³äº np.dot() çš„æ³¨æ„äº‹é¡¹
- en: The function `np.dot()` does not actually implement the vector dot product;
    it implements matrix multiplication, which is a collection of dot products. This
    will make more sense after learning about the rules and mechanisms of matrix multiplication
    ([ChapterÂ 5](ch05.xhtml#Chapter_5)). If you want to explore this now, you can
    modify the previous code to endow both vectors with orientations (row versus column).
    You will discover that the output is the dot product only when the first input
    is a row vector and the second input is a column vector.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: å‡½æ•°`np.dot()`å®é™…ä¸Šå¹¶æ²¡æœ‰å®ç°å‘é‡çš„ç‚¹ç§¯ï¼›å®ƒå®ç°çš„æ˜¯çŸ©é˜µä¹˜æ³•ï¼Œè€ŒçŸ©é˜µä¹˜æ³•æ˜¯ä¸€ç»„ç‚¹ç§¯çš„é›†åˆã€‚åœ¨å­¦ä¹ çŸ©é˜µä¹˜æ³•çš„è§„åˆ™å’Œæœºåˆ¶ä¹‹åä¼šæ›´åŠ æ¸…æ™°ï¼ˆ[ç¬¬5ç« ](ch05.xhtml#Chapter_5)ï¼‰ã€‚å¦‚æœä½ æƒ³ç°åœ¨å°±æ¢ç´¢è¿™ä¸€ç‚¹ï¼Œå¯ä»¥ä¿®æ”¹ä¹‹å‰çš„ä»£ç ï¼Œç»™ä¸¤ä¸ªå‘é‡åˆ†åˆ«èµ‹äºˆæ–¹å‘ï¼ˆè¡Œå‘é‡å¯¹æ¯”åˆ—å‘é‡ï¼‰ã€‚ä½ ä¼šå‘ç°ï¼Œåªæœ‰åœ¨ç¬¬ä¸€ä¸ªè¾“å…¥æ˜¯è¡Œå‘é‡ï¼Œç¬¬äºŒä¸ªè¾“å…¥æ˜¯åˆ—å‘é‡æ—¶ï¼Œè¾“å‡ºæ‰æ˜¯ç‚¹ç§¯ã€‚
- en: 'Here is an interesting property of the dot product: scalar multiplying one
    vector scales the dot product by the same amount. We can explore this by expanding
    the previous code:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹ç§¯çš„ä¸€ä¸ªæœ‰è¶£å±æ€§æ˜¯ï¼šæ ‡é‡ä¹˜ä»¥ä¸€ä¸ªå‘é‡ä¼šæŒ‰ç›¸åŒçš„æ¯”ä¾‹æ‰©å±•ç‚¹ç§¯ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡æ‰©å±•ä¹‹å‰çš„ä»£ç æ¥æ¢ç´¢è¿™ä¸€ç‚¹ï¼š
- en: '[PRE10]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The dot product of `v` and `w` is 70, and the dot product using `s*v` (which,
    in math notation, would be written as <math alttext="sigma bold v Superscript
    upper T Baseline bold w"><mrow><mi>Ïƒ</mi> <msup><mi>ğ¯</mi> <mtext>T</mtext></msup>
    <mi>ğ°</mi></mrow></math> ) is 700\. Now try it with a negative scalar, e.g., `s
    = -1`. Youâ€™ll see that the dot product magnitude is preserved but the sign is
    reversed. Of course, when `s = 0` then the dot product is zero.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: å‘é‡`v`å’Œ`w`çš„ç‚¹ç§¯ä¸º70ï¼Œä½¿ç”¨`s*v`è¿›è¡Œçš„ç‚¹ç§¯ï¼ˆåœ¨æ•°å­¦ç¬¦å·ä¸­å¯ä»¥å†™ä¸º<math alttext="sigma bold v Superscript
    upper T Baseline bold w"><mrow><mi>Ïƒ</mi> <msup><mi>ğ¯</mi> <mtext>T</mtext></msup>
    <mi>ğ°</mi></mrow></math>ï¼‰ä¸º700ã€‚ç°åœ¨å°è¯•ä¸€ä¸ªè´Ÿæ ‡é‡ï¼Œä¾‹å¦‚`s = -1`ã€‚ä½ ä¼šçœ‹åˆ°ç‚¹ç§¯çš„å¤§å°ä¿æŒä¸å˜ï¼Œä½†ç¬¦å·è¢«åè½¬ã€‚å½“ç„¶ï¼Œå½“`s
    = 0`æ—¶ï¼Œç‚¹ç§¯ä¸ºé›¶ã€‚
- en: Now you know how to compute the dot product. What does the dot product mean
    and how do we interpret it?
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä½ çŸ¥é“å¦‚ä½•è®¡ç®—ç‚¹ç§¯äº†ã€‚ç‚¹ç§¯æ„å‘³ç€ä»€ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•è§£é‡Šå®ƒï¼Ÿ
- en: The dot product can be interpreted as a measure of *similarity* or *mapping*
    between two vectors. Imagine that you collected height and weight data from 20
    people, and you stored those data in two vectors. You would certainly expect those
    variables to be related to each other (taller people tend to weigh more), and
    therefore you could expect the dot product between those two vectors to be large.
    On the other hand, the magnitude of the dot product depends on the scale of the
    data, which means the dot product between data measured in grams and centimeters
    would be larger than the dot product between data measured in pounds and feet.
    This arbitrary scaling, however, can be eliminated with a normalization factor.
    In fact, the normalized dot product between two variables is called the *Pearson
    correlation coefficient*, and it is one of the most important analyses in data
    science. More on this in [ChapterÂ 4](ch04.xhtml#Chapter_4)!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹ç§¯å¯ä»¥è¢«è§£é‡Šä¸ºä¸¤ä¸ªå‘é‡ä¹‹é—´çš„*ç›¸ä¼¼æ€§*æˆ–*æ˜ å°„*çš„åº¦é‡ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œä½ ä»20ä¸ªäººé‚£é‡Œæ”¶é›†äº†èº«é«˜å’Œä½“é‡æ•°æ®ï¼Œå¹¶å°†è¿™äº›æ•°æ®å­˜å‚¨åœ¨ä¸¤ä¸ªå‘é‡ä¸­ã€‚ä½ è‚¯å®šå¸Œæœ›è¿™äº›å˜é‡ä¹‹é—´æœ‰å…³è”ï¼ˆèº«é«˜è¾ƒé«˜çš„äºº
    tend to weigh moreï¼‰ï¼Œå› æ­¤ä½ å¯ä»¥æœŸæœ›è¿™ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç‚¹ç§¯è¾ƒå¤§ã€‚ç„¶è€Œï¼Œç‚¹ç§¯çš„å¤§å°å–å†³äºæ•°æ®çš„æ¯”ä¾‹ï¼Œè¿™æ„å‘³ç€ä»¥å…‹å’Œå˜ç±³æµ‹é‡çš„æ•°æ®ä¹‹é—´çš„ç‚¹ç§¯å°†å¤§äºä»¥ç£…å’Œè‹±å°ºæµ‹é‡çš„æ•°æ®ä¹‹é—´çš„ç‚¹ç§¯ã€‚ç„¶è€Œï¼Œè¿™ç§ä»»æ„çš„ç¼©æ”¾å¯ä»¥é€šè¿‡å½’ä¸€åŒ–å› å­æ¥æ¶ˆé™¤ã€‚äº‹å®ä¸Šï¼Œä¸¤ä¸ªå˜é‡çš„å½’ä¸€åŒ–ç‚¹ç§¯è¢«ç§°ä¸º*çš®å°”é€Šç›¸å…³ç³»æ•°*ï¼Œå®ƒæ˜¯æ•°æ®ç§‘å­¦ä¸­æœ€é‡è¦çš„åˆ†æä¹‹ä¸€ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è§[ç¬¬4ç« ](ch04.xhtml#Chapter_4)ï¼
- en: The Dot Product Is Distributive
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç‚¹ç§¯å…·æœ‰åˆ†é…æ€§è´¨
- en: 'The distributive property of mathematics is that <math alttext="a left-parenthesis
    b plus c right-parenthesis equals a b plus a c"><mrow><mi>a</mi> <mo>(</mo> <mi>b</mi>
    <mo>+</mo> <mi>c</mi> <mo>)</mo> <mo>=</mo> <mi>a</mi> <mi>b</mi> <mo>+</mo> <mi>a</mi>
    <mi>c</mi></mrow></math> . Translated into vectors and the vector dot product,
    it means that:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°å­¦çš„åˆ†é…æ€§è´¨æ˜¯ï¼š<math alttext="a left-parenthesis b plus c right-parenthesis equals
    a b plus a c"><mrow><mi>a</mi> <mo>(</mo> <mi>b</mi> <mo>+</mo> <mi>c</mi> <mo>)</mo>
    <mo>=</mo> <mi>a</mi> <mi>b</mi> <mo>+</mo> <mi>a</mi> <mi>c</mi></mrow></math>ã€‚è½¬åŒ–ä¸ºå‘é‡å’Œå‘é‡ç‚¹ç§¯çš„æœ¯è¯­ï¼Œæ„å‘³ç€ï¼š
- en: <math alttext="bold a Superscript upper T Baseline left-parenthesis bold b plus
    bold c right-parenthesis equals bold a Superscript upper T Baseline bold b plus
    bold a Superscript upper T Baseline bold c" display="block"><mrow><msup><mi>ğš</mi>
    <mtext>T</mtext></msup> <mrow><mo>(</mo> <mi>ğ›</mi> <mo>+</mo> <mi>ğœ</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msup><mi>ğš</mi> <mtext>T</mtext></msup> <mi>ğ›</mi> <mo>+</mo> <msup><mi>ğš</mi>
    <mtext>T</mtext></msup> <mi>ğœ</mi></mrow></math>
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold a Superscript upper T Baseline left-parenthesis bold b plus
    bold c right-parenthesis equals bold a Superscript upper T Baseline bold b plus
    bold a Superscript upper T Baseline bold c" display="block"><mrow><msup><mi>ğš</mi>
    <mtext>T</mtext></msup> <mrow><mo>(</mo> <mi>ğ›</mi> <mo>+</mo> <mi>ğœ</mi> <mo>)</mo></mrow>
    <mo>=</mo> <msup><mi>ğš</mi> <mtext>T</mtext></msup> <mi>ğ›</mi> <mo>+</mo> <msup><mi>ğš</mi>
    <mtext>T</mtext></msup> <mi>ğœ</mi></mrow></math>
- en: In words, you would say that the dot product of a vector sum equals the sum
    of the vector dot products.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œä¸€ä¸ªå‘é‡å’Œçš„ç‚¹ç§¯ç­‰äºå„ä¸ªå‘é‡ç‚¹ç§¯çš„å’Œã€‚
- en: 'The following Python code illustrates the distributivity property:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹Pythonä»£ç å±•ç¤ºäº†åˆ†é…æ€§è´¨ï¼š
- en: '[PRE11]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The two outcomes `res1` and `res2` are the same (with these vectors, the answer
    is 110), which illustrates the distributivity of the dot product. Notice how the
    mathematical formula is translated into Python code; translating formulas into
    code is an important skill in math-oriented coding.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªç»“æœ `res1` å’Œ `res2` æ˜¯ç›¸åŒçš„ï¼ˆå¯¹äºè¿™äº›å‘é‡ï¼Œç­”æ¡ˆæ˜¯110ï¼‰ï¼Œè¿™è¯´æ˜äº†ç‚¹ç§¯çš„åˆ†é…æ€§è´¨ã€‚æ³¨æ„æ•°å­¦å…¬å¼å¦‚ä½•è¢«è½¬åŒ–ä¸ºPythonä»£ç ï¼›å°†å…¬å¼è½¬åŒ–ä¸ºä»£ç æ˜¯æ•°å­¦å¯¼å‘ç¼–ç¨‹ä¸­çš„é‡è¦æŠ€èƒ½ã€‚
- en: Geometry of the Dot Product
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç‚¹ç§¯çš„å‡ ä½•æ€§è´¨
- en: There is also a geometric definition of the dot product, which is the product
    of the magnitudes of the two vectors, scaled by the cosine of the angle between
    them ([Equation 2-11](#dp-geom)).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹ç§¯è¿˜æœ‰ä¸€ä¸ªå‡ ä½•å®šä¹‰ï¼Œå³ä¸¤ä¸ªå‘é‡çš„å¤§å°ä¹˜ç§¯ï¼Œä¹˜ä»¥å®ƒä»¬ä¹‹é—´çš„ä½™å¼¦å€¼ï¼ˆ[æ–¹ç¨‹å¼ 2-11](#dp-geom)ï¼‰ã€‚
- en: Equation 2-11\. Geometric definition of the vector dot product
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹å¼ 2-11\. å‘é‡ç‚¹ç§¯çš„å‡ ä½•å®šä¹‰
- en: <math alttext="alpha equals cosine left-parenthesis theta Subscript bold v comma
    bold w Baseline right-parenthesis parallel-to bold v parallel-to parallel-to bold
    w parallel-to" display="block"><mrow><mi>Î±</mi> <mo>=</mo> <mo form="prefix">cos</mo>
    <mo>(</mo> <msub><mi>Î¸</mi> <mrow><mi>ğ¯</mi><mo>,</mo><mi>ğ°</mi></mrow></msub>
    <mo>)</mo> <mo>âˆ¥</mo> <mi>ğ¯</mi> <mo>âˆ¥</mo> <mo>âˆ¥</mo> <mi>ğ°</mi> <mo>âˆ¥</mo></mrow></math>
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="alpha equals cosine left-parenthesis theta Subscript bold v comma
    bold w Baseline right-parenthesis parallel-to bold v parallel-to parallel-to bold
    w parallel-to" display="block"><mrow><mi>Î±</mi> <mo>=</mo> <mo form="prefix">cos</mo>
    <mo>(</mo> <msub><mi>Î¸</mi> <mrow><mi>ğ¯</mi><mo>,</mo><mi>ğ°</mi></mrow></msub>
    <mo>)</mo> <mo>âˆ¥</mo> <mi>ğ¯</mi> <mo>âˆ¥</mo> <mo>âˆ¥</mo> <mi>ğ°</mi> <mo>âˆ¥</mo></mrow></math>
- en: '[Equation 2-9](#dp-alg) and [Equation 2-11](#dp-geom) are mathematically equivalent
    but expressed in different forms. The proof of their equivalence is an interesting
    exercise in mathematical analysis, but would take about a page of text and relies
    on first proving other principles including the Law of Cosines. That proof is
    not relevant for this book and so is omitted.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[æ–¹ç¨‹å¼ 2-9](#dp-alg) å’Œ [æ–¹ç¨‹å¼ 2-11](#dp-geom) åœ¨æ•°å­¦ä¸Šæ˜¯ç­‰ä»·çš„ï¼Œä½†è¡¨è¾¾å½¢å¼ä¸åŒã€‚å®ƒä»¬çš„ç­‰ä»·æ€§è¯æ˜æ˜¯æ•°å­¦åˆ†æä¸­æœ‰è¶£çš„ç»ƒä¹ ï¼Œä½†éœ€è¦å¤§çº¦ä¸€é¡µçš„æ–‡æœ¬ï¼Œä¾èµ–äºé¦–å…ˆè¯æ˜åŒ…æ‹¬ä½™å¼¦å®šç†åœ¨å†…çš„å…¶ä»–åŸç†ã€‚è¿™ä¸ªè¯æ˜å¯¹æœ¬ä¹¦ä¸ç›¸å…³ï¼Œå› æ­¤è¢«çœç•¥ã€‚'
- en: Notice that vector magnitudes are strictly positive quantities (except for the
    zeros vector, which has <math alttext="parallel-to bold 0 parallel-to equals 0"><mrow><mo>âˆ¥</mo>
    <mn mathvariant="bold">0</mn> <mo>âˆ¥</mo> <mo>=</mo> <mn>0</mn></mrow></math> ),
    while the cosine of an angle can range between âˆ’1 and +1\. This means that the
    sign of the dot product is determined entirely by the geometric relationship between
    the two vectors. [FigureÂ 2-5](#fig_2_5) shows five cases of the dot product sign,
    depending on the angle between the two vectors (in 2D for visualization, but the
    principle holds for higher dimensions).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„å‘é‡çš„å¤§å°ä¸¥æ ¼ä¸ºæ­£ï¼ˆé™¤äº†é›¶å‘é‡ï¼Œå…¶é•¿åº¦ä¸º <math alttext="parallel-to bold 0 parallel-to equals
    0"><mrow><mo>âˆ¥</mo> <mn mathvariant="bold">0</mn> <mo>âˆ¥</mo> <mo>=</mo> <mn>0</mn></mrow></math>
    ï¼‰ï¼Œè€Œè§’çš„ä½™å¼¦å€¼å¯ä»¥åœ¨ -1 åˆ° +1 ä¹‹é—´ã€‚è¿™æ„å‘³ç€ç‚¹ç§¯çš„ç¬¦å·å®Œå…¨ç”±ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„å‡ ä½•å…³ç³»å†³å®šã€‚[å›¾Â 2-5](#fig_2_5) å±•ç¤ºäº†ä¸¤ä¸ªå‘é‡ä¹‹é—´è§’åº¦çš„äº”ç§ç‚¹ç§¯ç¬¦å·æƒ…å†µï¼ˆåœ¨äºŒç»´ä¸­ç”¨äºå¯è§†åŒ–ï¼Œä½†åŸç†é€‚ç”¨äºæ›´é«˜ç»´åº¦ï¼‰ã€‚
- en: '![What does this do?](assets/plad_0205.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![è¿™ä¸ªåšä»€ä¹ˆï¼Ÿ](assets/plad_0205.png)'
- en: Figure 2-5\. The sign of the dot product between two vectors reveals the geometric
    relationship between those vectors
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2-5\. ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ç‚¹ç§¯ç¬¦å·æ˜¾ç¤ºäº†è¿™äº›å‘é‡ä¹‹é—´çš„å‡ ä½•å…³ç³»
- en: 'Memorize This: Orthogonal Vectors Have a Zero Dot Product'
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è®°ä½è¿™ä¸ªï¼šæ­£äº¤å‘é‡çš„ç‚¹ç§¯ä¸ºé›¶
- en: 'Some math teachers insist that you shouldnâ€™t memorize formulas and terms, and
    instead should understand procedures and proofs. But letâ€™s be honest: memorization
    is an important and inescapable part of learning mathematics. Fortunately, linear
    algebra isnâ€™t excessively memorization-heavy, but there are a few things youâ€™ll
    simply need to commit to memory.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›æ•°å­¦è€å¸ˆåšæŒè®¤ä¸ºä½ ä¸åº”è¯¥è®°å¿†å…¬å¼å’Œæœ¯è¯­ï¼Œè€Œåº”è¯¥ç†è§£è¿‡ç¨‹å’Œè¯æ˜ã€‚ä½†è®©æˆ‘ä»¬è¯šå®åœ°è¯´ï¼šè®°å¿†æ˜¯å­¦ä¹ æ•°å­¦ä¸­é‡è¦ä¸”ä¸å¯é¿å…çš„ä¸€éƒ¨åˆ†ã€‚å¹¸è¿çš„æ˜¯ï¼Œçº¿æ€§ä»£æ•°å¹¶ä¸éœ€è¦è¿‡å¤šçš„è®°å¿†è´Ÿæ‹…ï¼Œä½†æœ‰ä¸€äº›äº‹æƒ…ä½ å¿…é¡»ç®€å•åœ°è®°ä½ã€‚
- en: 'Here is one: orthogonal vectors have a dot product of zero (that claim goes
    both waysâ€”when the dot product is zero, then the two vectors are orthogonal).
    So, the following statements are equivalent: two vectors are orthogonal; two vectors
    have a dot product of zero; two vectors meet at a 90Â° angle. Repeat that equivalence
    until itâ€™s permanently etched into your brain.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸¾ä¸ªä¾‹å­ï¼šæ­£äº¤å‘é‡çš„ç‚¹ç§¯ä¸ºé›¶ï¼ˆåä¹‹äº¦ç„¶â€”â€”å½“ç‚¹ç§¯ä¸ºé›¶æ—¶ï¼Œä¸¤ä¸ªå‘é‡æ˜¯æ­£äº¤çš„ï¼‰ã€‚å› æ­¤ï¼Œä»¥ä¸‹é™ˆè¿°æ˜¯ç­‰ä»·çš„ï¼šä¸¤ä¸ªå‘é‡æ˜¯æ­£äº¤çš„ï¼›ä¸¤ä¸ªå‘é‡çš„ç‚¹ç§¯ä¸ºé›¶ï¼›ä¸¤ä¸ªå‘é‡æˆ90Â°è§’ã€‚é‡å¤è¿™ç§ç­‰ä»·æ€§ï¼Œç›´åˆ°å®ƒæ°¸ä¹…åœ°åˆ»åœ¨ä½ çš„å¤§è„‘ä¸­ã€‚
- en: Other Vector Multiplications
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å…¶ä»–å‘é‡ä¹˜æ³•
- en: The dot product is perhaps the most important, and most frequently used, way
    to multiply vectors. But there are several other ways to multiply vectors.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹ä¹˜å¯èƒ½æ˜¯æœ€é‡è¦ã€ä¹Ÿæ˜¯æœ€ç»å¸¸ä½¿ç”¨çš„ä¸€ç§å‘é‡ä¹˜æ³•æ–¹å¼ã€‚ä½†è¿˜æœ‰å‡ ç§å…¶ä»–å‘é‡ä¹˜æ³•æ–¹å¼ã€‚
- en: Hadamard Multiplication
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å“ˆè¾¾ç›ä¹˜æ³•
- en: 'This is just a fancy term for element-wise multiplication. To implement Hadamard
    multiplication, each corresponding element in the two vectors is multiplied. The
    product is a vector of the same dimensionality as the two multiplicands. For example:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™åªæ˜¯ä¸€ä¸ªå…ƒç´ çº§ä¹˜æ³•çš„èŠ±å“¨æœ¯è¯­ã€‚è¦å®ç°å“ˆè¾¾ç›ä¹˜æ³•ï¼Œéœ€è¦å°†ä¸¤ä¸ªå‘é‡ä¸­å¯¹åº”çš„æ¯ä¸ªå…ƒç´ ç›¸ä¹˜ã€‚ä¹˜ç§¯æ˜¯ä¸ä¸¤ä¸ªä¹˜æ•°ç›¸åŒç»´åº¦çš„å‘é‡ã€‚ä¾‹å¦‚ï¼š
- en: <math display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>5</mn></mtd></mtr>
    <mtr><mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>8</mn></mtd></mtr> <mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced>
    <mo>âŠ™</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>1</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>0</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>.5</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mo>-</mo> <mn>1</mn></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>5</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>0</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>4</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: <math display="block"><mrow><mfenced close="]" open="["><mtable><mtr><mtd><mn>5</mn></mtd></mtr>
    <mtr><mtd><mn>4</mn></mtd></mtr> <mtr><mtd><mn>8</mn></mtd></mtr> <mtr><mtd><mn>2</mn></mtd></mtr></mtable></mfenced>
    <mo>âŠ™</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>1</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>0</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>.5</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mo>-</mo> <mn>1</mn></mrow></mtd></mtr></mtable></mfenced>
    <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>5</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>0</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mphantom><mo>-</mo></mphantom>
    <mn>4</mn></mrow></mtd></mtr> <mtr><mtd><mrow><mo>-</mo> <mn>2</mn></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'In Python, the asterisk indicates element-wise multiplication for two vectors
    or matrices:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ Python ä¸­ï¼Œæ˜Ÿå·è¡¨ç¤ºä¸¤ä¸ªå‘é‡æˆ–çŸ©é˜µçš„é€å…ƒç´ ä¹˜æ³•ï¼š
- en: '[PRE12]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Try running that code in Python andâ€¦uh oh! Python will give an error. Find and
    fix the bug. What have you learned about Hadamard multiplication from that error?
    Check the footnote for the answer.^([4](ch02.xhtml#idm45733308534784))
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: å°è¯•åœ¨ Python ä¸­è¿è¡Œè¯¥ä»£ç ç„¶åâ€¦â€¦å“å‘€ï¼Python ä¼šæŠ¥é”™ã€‚æ‰¾åˆ°å¹¶ä¿®å¤äº†é”™è¯¯ã€‚ä»è¯¥é”™è¯¯ä¸­ï¼Œä½ å­¦åˆ°äº†ä»€ä¹ˆå…³äºå“ˆè¾¾ç›ä¹˜æ³•ï¼ŸæŸ¥çœ‹è„šæ³¨è·å–ç­”æ¡ˆã€‚^([4](ch02.xhtml#idm45733308534784))
- en: Hadamard multiplication is a convenient way to organize multiple scalar multiplications.
    For example, imagine you have data on the number of widgets sold in different
    shops and the price per widget at each shop. You could represent each variable
    as a vector, and then Hadamard-multiply those vectors to compute the widget revenue
    *per shop* (this is different from the total revenue across *all shops*, which
    would be computed as the dot product).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: å“ˆè¾¾ç›ä¹˜ç§¯æ˜¯ç»„ç»‡å¤šä¸ªæ ‡é‡ä¹˜æ³•çš„ä¾¿æ·æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œæƒ³è±¡ä¸€ä¸‹ä½ æœ‰ä¸åŒå•†åº—é”€å”®çš„å°éƒ¨ä»¶æ•°é‡ä»¥åŠæ¯ä¸ªå•†åº—æ¯ä»¶å°éƒ¨ä»¶çš„ä»·æ ¼çš„æ•°æ®ã€‚ä½ å¯ä»¥å°†æ¯ä¸ªå˜é‡è¡¨ç¤ºä¸ºå‘é‡ï¼Œç„¶åå¯¹è¿™äº›å‘é‡è¿›è¡Œå“ˆè¾¾ç›ä¹˜æ³•ä»¥è®¡ç®—æ¯ä¸ªå•†åº—çš„å°éƒ¨ä»¶æ”¶å…¥ï¼ˆè¿™ä¸è·¨æ‰€æœ‰å•†åº—çš„æ€»æ”¶å…¥ä¸åŒï¼Œåè€…å¯ä»¥é€šè¿‡ç‚¹ç§¯è®¡ç®—ï¼‰ã€‚
- en: Outer Product
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤–ç§¯
- en: 'The outer product is a way to create a matrix from a column vector and a row
    vector. Each row in the outer product matrix is the row vector scalar multiplied
    by the corresponding element in the column vector. We could also say that each
    column in the product matrix is the column vector scalar multiplied by the corresponding
    element in the row vector. In [ChapterÂ 6](ch06.xhtml#Chapter_6), Iâ€™ll call this
    a â€œrank-1 matrix,â€ but donâ€™t worry about the term for now; instead, focus on the
    pattern illustrated in the following example:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: å¤–ç§¯æ˜¯é€šè¿‡ä¸€ä¸ªåˆ—å‘é‡å’Œä¸€ä¸ªè¡Œå‘é‡åˆ›å»ºçŸ©é˜µçš„ä¸€ç§æ–¹å¼ã€‚å¤–ç§¯çŸ©é˜µä¸­çš„æ¯ä¸€è¡Œæ˜¯è¡Œå‘é‡ä¸åˆ—å‘é‡ä¸­å¯¹åº”å…ƒç´ çš„æ ‡é‡ä¹˜ç§¯ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥è¯´å¤–ç§¯çŸ©é˜µä¸­çš„æ¯ä¸€åˆ—æ˜¯åˆ—å‘é‡ä¸è¡Œå‘é‡ä¸­å¯¹åº”å…ƒç´ çš„æ ‡é‡ä¹˜ç§¯ã€‚åœ¨[ç¬¬
    6 ç« ](ch06.xhtml#Chapter_6)ä¸­ï¼Œæˆ‘å°†ç§°ä¹‹ä¸ºâ€œç§©-1 çŸ©é˜µâ€ï¼Œä½†ç°åœ¨ä¸è¦æ‹…å¿ƒè¿™ä¸ªæœ¯è¯­ï¼›è€Œæ˜¯è¦ä¸“æ³¨äºä¸‹é¢ç¤ºä¾‹ä¸­å±•ç¤ºçš„æ¨¡å¼ï¼š
- en: <math alttext="Start 3 By 1 Matrix 1st Row  a 2nd Row  b 3rd Row  c EndMatrix
    Start 1 By 2 Matrix 1st Row 1st Column d 2nd Column e EndMatrix equals Start 3
    By 2 Matrix 1st Row 1st Column a d 2nd Column a e 2nd Row 1st Column b d 2nd Column
    b e 3rd Row 1st Column c d 2nd Column c e EndMatrix" display="block"><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mi>a</mi></mtd></mtr> <mtr><mtd><mi>b</mi></mtd></mtr>
    <mtr><mtd><mi>c</mi></mtd></mtr></mtable></mfenced> <mfenced close="]" open="["><mtable><mtr><mtd><mi>d</mi></mtd>
    <mtd><mi>e</mi></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>a</mi>
    <mi>d</mi></mrow></mtd> <mtd><mrow><mi>a</mi> <mi>e</mi></mrow></mtd></mtr> <mtr><mtd><mrow><mi>b</mi>
    <mi>d</mi></mrow></mtd> <mtd><mrow><mi>b</mi> <mi>e</mi></mrow></mtd></mtr> <mtr><mtd><mrow><mi>c</mi>
    <mi>d</mi></mrow></mtd> <mtd><mrow><mi>c</mi> <mi>e</mi></mrow></mtd></mtr></mtable></mfenced></mrow></math>
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="Start 3 By 1 Matrix 1st Row  a 2nd Row  b 3rd Row  c EndMatrix
    Start 1 By 2 Matrix 1st Row 1st Column d 2nd Column e EndMatrix equals Start 3
    By 2 Matrix 1st Row 1st Column a d 2nd Column a e 2nd Row 1st Column b d 2nd Column
    b e 3rd Row 1st Column c d 2nd Column c e EndMatrix" display="block"><mrow><mfenced
    close="]" open="["><mtable><mtr><mtd><mi>a</mi></mtd></mtr> <mtr><mtd><mi>b</mi></mtd></mtr>
    <mtr><mtd><mi>c</mi></mtd></mtr></mtable></mfenced> <mfenced close="]" open="["><mtable><mtr><mtd><mi>d</mi></mtd>
    <mtd><mi>e</mi></mtd></mtr></mtable></mfenced> <mo>=</mo> <mfenced close="]" open="["><mtable><mtr><mtd><mrow><mi>a</mi>
    <mi>d</mi></mrow></mtd> <mtd><mrow><mi>a</mi> <mi>e</mi></mrow></mtd></mtr> <mtr><mtd><mrow><mi>b</mi>
    <mi>d</mi></mrow></mtd> <mtd><mrow><mi>b</mi> <mi>e</mi></mrow></mtd></mtr> <mtr><mtd><mrow><mi>c</mi>
    <mi>d</mi></mrow></mtd> <mtd><mrow><mi>c</mi> <mi>e</mi></mrow></mtd></mtr></mtable></mfenced></mrow></math>
- en: 'The outer product is quite different from the dot product: it produces a matrix
    instead of a scalar, and the two vectors in an outer product can have different
    dimensionalities, whereas the two vectors in a dot product must have the same
    dimensionality.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: å¤–ç§¯ä¸ç‚¹ç§¯æœ‰å¾ˆå¤§çš„ä¸åŒï¼šå®ƒäº§ç”Ÿä¸€ä¸ªçŸ©é˜µè€Œä¸æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå¹¶ä¸”å¤–ç§¯ä¸­çš„ä¸¤ä¸ªå‘é‡å¯ä»¥å…·æœ‰ä¸åŒçš„ç»´åº¦ï¼Œè€Œç‚¹ç§¯ä¸­çš„ä¸¤ä¸ªå‘é‡å¿…é¡»å…·æœ‰ç›¸åŒçš„ç»´åº¦ã€‚
- en: The outer product is indicated as <math alttext="bold v bold w Superscript upper
    T"><mrow><mi>ğ¯</mi> <msup><mi>ğ°</mi> <mtext>T</mtext></msup></mrow></math> (remember
    that we assume vectors are in column orientation; therefore, the outer product
    involves multiplying a column by a row). Note the subtle but important difference
    between notation for the dot product ( <math alttext="bold v Superscript upper
    T Baseline bold w"><mrow><msup><mi>ğ¯</mi> <mtext>T</mtext></msup> <mi>ğ°</mi></mrow></math>
    ) and the outer product ( <math alttext="bold v bold w Superscript upper T"><mrow><mi>ğ¯</mi>
    <msup><mi>ğ°</mi> <mtext>T</mtext></msup></mrow></math> ). This might seem strange
    and confusing now, but I promise it will make perfect sense after learning about
    matrix multiplication in [ChapterÂ 5](ch05.xhtml#Chapter_5).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: å¤–ç§¯è¡¨ç¤ºä¸º<math alttext="bold v bold w Superscript upper T"><mrow><mi>ğ¯</mi> <msup><mi>ğ°</mi>
    <mtext>T</mtext></msup></mrow></math>ï¼ˆè¯·è®°ä½æˆ‘ä»¬å‡è®¾å‘é‡æ˜¯åˆ—å‘é‡ï¼Œå› æ­¤å¤–ç§¯æ¶‰åŠå°†åˆ—ä¹˜ä»¥è¡Œï¼‰ã€‚æ³¨æ„ç‚¹ç§¯ï¼ˆ<math alttext="bold
    v Superscript upper T Baseline bold w"><mrow><msup><mi>ğ¯</mi> <mtext>T</mtext></msup>
    <mi>ğ°</mi></mrow></math>ï¼‰ä¸å¤–ç§¯ï¼ˆ<math alttext="bold v bold w Superscript upper T"><mrow><mi>ğ¯</mi>
    <msup><mi>ğ°</mi> <mtext>T</mtext></msup></mrow></math>ï¼‰ä¹‹é—´çš„å¾®å¦™ä½†é‡è¦çš„å·®å¼‚ã€‚ç°åœ¨è¿™å¯èƒ½çœ‹èµ·æ¥å¥‡æ€ªå’Œä»¤äººå›°æƒ‘ï¼Œä½†æˆ‘ä¿è¯åœ¨å­¦ä¹ ç¬¬
    5 ç« å…³äºçŸ©é˜µä¹˜æ³•åï¼Œè¿™å°†å˜å¾—éå¸¸æ¸…æ™°ã€‚
- en: 'The outer product is similar to broadcasting, but they are not the same: *broadcasting*
    is a general coding operation that is used to expand vectors in arithmetic operations
    such as addition, multiplication, and division; the *outer product* is a specific
    mathematical procedure for multiplying two vectors.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: å¤–ç§¯ç±»ä¼¼äºå¹¿æ’­ï¼Œä½†å®ƒä»¬å¹¶ä¸ç›¸åŒï¼š*å¹¿æ’­*æ˜¯ä¸€ç§é€šç”¨çš„ç¼–ç æ“ä½œï¼Œç”¨äºåœ¨ç®—æœ¯è¿ç®—ï¼ˆå¦‚åŠ æ³•ã€ä¹˜æ³•å’Œé™¤æ³•ï¼‰ä¸­æ‰©å±•å‘é‡ï¼›*å¤–ç§¯*æ˜¯ä¸€ç§ç‰¹å®šçš„æ•°å­¦è¿‡ç¨‹ï¼Œç”¨äºä¸¤ä¸ªå‘é‡çš„ä¹˜æ³•ã€‚
- en: NumPy can compute the outer product via the function `np.outer()` or the function
    `np.dot()` if the two input vectors are in, respectively, column and row orientation.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy å¯ä»¥é€šè¿‡å‡½æ•°`np.outer()`æˆ–å‡½æ•°`np.dot()`è®¡ç®—å¤–ç§¯ï¼Œå¦‚æœä¸¤ä¸ªè¾“å…¥å‘é‡åˆ†åˆ«æ˜¯åˆ—å‘é‡å’Œè¡Œå‘é‡ã€‚
- en: Cross and Triple Products
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: äº¤å‰ä¹˜ç§¯å’Œä¸‰é‡ç§¯
- en: There are a few other ways to multiply vectors such as the cross product or
    triple product. Those methods are used in geometry and physics, but donâ€™t come
    up often enough in tech-related applications to spend any time on in this book.
    I mention them here only so you have passing familiarity with the names.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '"è¿˜æœ‰å…¶ä»–å‡ ç§å‘é‡ä¹˜æ³•æ–¹æ³•ï¼Œå¦‚å‰ç§¯æˆ–ä¸‰é‡ç§¯ã€‚è¿™äº›æ–¹æ³•ç”¨äºå‡ ä½•å’Œç‰©ç†å­¦ä¸­ï¼Œä½†åœ¨æŠ€æœ¯ç›¸å…³åº”ç”¨ä¸­å¾ˆå°‘å‡ºç°ï¼Œæœ¬ä¹¦ä¸ä¼šèŠ±æ—¶é—´ä»‹ç»å®ƒä»¬ã€‚æˆ‘åœ¨è¿™é‡Œæåˆ°å®ƒä»¬åªæ˜¯è®©ä½ å¯¹è¿™äº›åè¯æœ‰æ‰€äº†è§£ã€‚"'
- en: Orthogonal Vector Decomposition
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '"æ­£äº¤å‘é‡åˆ†è§£"'
- en: To â€œdecomposeâ€ a vector or matrix means to break up that matrix into multiple
    simpler pieces. Decompositions are used to reveal information that is â€œhiddenâ€
    in a matrix, to make the matrix easier to work with, or for data compression.
    It is no understatement to write that much of linear algebra (in the abstract
    and in practice) involves matrix decompositions. Matrix decompositions are a big
    deal.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '"çŸ©é˜µæˆ–å‘é‡çš„â€œåˆ†è§£â€æ„å‘³ç€å°†è¯¥çŸ©é˜µåˆ†è§£ä¸ºå¤šä¸ªæ›´ç®€å•çš„éƒ¨åˆ†ã€‚åˆ†è§£ç”¨äºæ­ç¤ºçŸ©é˜µä¸­â€œéšè—â€çš„ä¿¡æ¯ï¼Œä½¿çŸ©é˜µæ›´æ˜“äºå¤„ç†ï¼Œæˆ–ç”¨äºæ•°æ®å‹ç¼©ã€‚å¯ä»¥æ¯«ä¸å¤¸å¼ åœ°è¯´ï¼Œçº¿æ€§ä»£æ•°çš„å¾ˆå¤šå†…å®¹ï¼ˆæ— è®ºæ˜¯æŠ½è±¡çš„è¿˜æ˜¯å®é™…çš„ï¼‰éƒ½æ¶‰åŠçŸ©é˜µåˆ†è§£ã€‚çŸ©é˜µåˆ†è§£éå¸¸é‡è¦ã€‚"'
- en: 'Let me introduce the concept of a decomposition using two simple examples with
    scalars:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '"è®©æˆ‘ç”¨ä¸¤ä¸ªç®€å•çš„æ ‡é‡ç¤ºä¾‹ä»‹ç»åˆ†è§£çš„æ¦‚å¿µï¼š"'
- en: 'We can decompose the number 42.01 into two pieces: 42 and .01\. Perhaps .01
    is noise to be ignored, or perhaps the goal is to compress the data (the integer
    42 requires less memory than the floating-point 42.01). Regardless of the motivation,
    the decomposition involves representing one mathematical object as the sum of
    simpler objects (42 = 42 + .01).'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"æˆ‘ä»¬å¯ä»¥å°†æ•°å­—42.01åˆ†è§£ä¸ºä¸¤éƒ¨åˆ†ï¼š42å’Œ.01ã€‚ä¹Ÿè®¸.01æ˜¯è¦å¿½ç•¥çš„å™ªéŸ³ï¼Œæˆ–è€…ç›®æ ‡æ˜¯å‹ç¼©æ•°æ®ï¼ˆæ•´æ•°42æ¯”æµ®ç‚¹æ•°42.01éœ€è¦æ›´å°‘çš„å†…å­˜ï¼‰ã€‚æ— è®ºåŠ¨æœºå¦‚ä½•ï¼Œåˆ†è§£æ¶‰åŠå°†ä¸€ä¸ªæ•°å­¦å¯¹è±¡è¡¨ç¤ºä¸ºæ›´ç®€å•å¯¹è±¡çš„å’Œï¼ˆ42
    = 42 + .01ï¼‰ã€‚"'
- en: 'We can decompose the number 42 into the product of prime numbers 2, 3, and
    7\. This decomposition is called *prime factorization* and has many applications
    in numerical processing and cryptography. This example involves products instead
    of sums, but the point is the same: decompose one mathematical object into smaller,
    simpler pieces.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"æˆ‘ä»¬å¯ä»¥å°†æ•°å­—42åˆ†è§£ä¸ºè´¨æ•°2ã€3å’Œ7çš„ä¹˜ç§¯ã€‚è¿™ç§åˆ†è§£ç§°ä¸º*è´¨å› æ•°åˆ†è§£*ï¼Œåœ¨æ•°å€¼å¤„ç†å’Œå¯†ç å­¦ä¸­æœ‰è®¸å¤šåº”ç”¨ã€‚è¿™ä¸ªä¾‹å­æ¶‰åŠä¹˜ç§¯è€Œä¸æ˜¯æ±‚å’Œï¼Œä½†è¦ç‚¹æ˜¯ç›¸åŒçš„ï¼šå°†ä¸€ä¸ªæ•°å­¦å¯¹è±¡åˆ†è§£ä¸ºæ›´å°ã€æ›´ç®€å•çš„éƒ¨åˆ†ã€‚"'
- en: In this section, we will begin exploring a simple yet important decomposition,
    which is to break up a vector into two separate vectors, one of which is orthogonal
    to a reference vector while the other is parallel to that reference vector. Orthogonal
    vector decomposition directly leads to the Gram-Schmidt procedure and QR decomposition,
    which is used frequently when solving inverse problems in statistics.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '"åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å¼€å§‹æ¢è®¨ä¸€ä¸ªç®€å•ä½†é‡è¦çš„åˆ†è§£æ–¹æ³•ï¼Œå³å°†ä¸€ä¸ªå‘é‡åˆ†è§£ä¸ºä¸¤ä¸ªåˆ†å¼€çš„å‘é‡ï¼Œå…¶ä¸­ä¸€ä¸ªä¸å‚è€ƒå‘é‡æ­£äº¤ï¼Œå¦ä¸€ä¸ªä¸è¯¥å‚è€ƒå‘é‡å¹³è¡Œã€‚æ­£äº¤å‘é‡åˆ†è§£ç›´æ¥å¯¼è‡´äº†æ ¼æ‹‰å§†-æ–½å¯†ç‰¹è¿‡ç¨‹å’ŒQRåˆ†è§£ï¼Œè¿™åœ¨è§£å†³ç»Ÿè®¡å­¦ä¸­çš„é€†é—®é¢˜æ—¶ç»å¸¸ä½¿ç”¨ã€‚"'
- en: 'Letâ€™s begin with a picture so you can visualize the goal of the decomposition.
    [FigureÂ 2-6](#fig_2_6) illustrates the situation: we have two vectors <math alttext="bold
    a"><mi>ğš</mi></math> and <math alttext="bold b"><mi>ğ›</mi></math> in standard
    position, and our goal is find the point on <math alttext="bold a"><mi>ğš</mi></math>
    that is as close as possible to the head of <math alttext="bold b"><mi>ğ›</mi></math>
    . We could also express this as an optimization problem: project vector <math
    alttext="bold b"><mi>ğ›</mi></math> onto vector <math alttext="bold a"><mi>ğš</mi></math>
    such that the projection distance is minimized. Of course, that point on <math
    alttext="bold a"><mi>ğš</mi></math> will be a scaled version of <math alttext="bold
    a"><mi>ğš</mi></math> ; in other words, <math alttext="beta bold a"><mrow><mi>Î²</mi>
    <mi>ğš</mi></mrow></math> . So now our goal is to find the scalar <math alttext="beta"><mi>Î²</mi></math>
    . (The connection to orthogonal vector decomposition will soon be clear.)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '"è®©æˆ‘ä»¬ä»ä¸€å¹…å›¾å¼€å§‹ï¼Œè¿™æ ·ä½ å¯ä»¥çœ‹åˆ°åˆ†è§£çš„ç›®æ ‡ã€‚[å›¾2-6](#fig_2_6)è¯´æ˜äº†è¿™ç§æƒ…å†µï¼šæˆ‘ä»¬æœ‰ä¸¤ä¸ªä½äºæ ‡å‡†ä½ç½®çš„å‘é‡ <math alttext="bold
    a"><mi>ğš</mi></math> å’Œ <math alttext="bold b"><mi>ğ›</mi></math> ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ° <math
    alttext="bold b"><mi>ğ›</mi></math> å¤´éƒ¨æœ€æ¥è¿‘çš„ <math alttext="bold a"><mi>ğš</mi></math>
    ç‚¹ã€‚æˆ‘ä»¬è¿˜å¯ä»¥å°†å…¶è¡¨è¾¾ä¸ºä¸€ä¸ªä¼˜åŒ–é—®é¢˜ï¼šå°†å‘é‡ <math alttext="bold b"><mi>ğ›</mi></math> æŠ•å½±åˆ°å‘é‡ <math alttext="bold
    a"><mi>ğš</mi></math> ä¸Šï¼Œä½¿å¾—æŠ•å½±è·ç¦»æœ€å°åŒ–ã€‚å½“ç„¶ï¼Œåœ¨ <math alttext="bold a"><mi>ğš</mi></math>
    ä¸Šçš„é‚£ä¸€ç‚¹å°†ä¼šæ˜¯ <math alttext="beta bold a"><mrow><mi>Î²</mi> <mi>ğš</mi></mrow></math>
    çš„ç¼©æ”¾ç‰ˆæœ¬ã€‚æ‰€ä»¥æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ°æ ‡é‡ <math alttext="beta"><mi>Î²</mi></math> ã€‚ï¼ˆä¸æ­£äº¤å‘é‡åˆ†è§£çš„è”ç³»å¾ˆå¿«ä¼šå˜å¾—æ¸…æ™°ã€‚ï¼‰"'
- en: '![The picture.](assets/plad_0206.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '"![å›¾ç‰‡ã€‚](assets/plad_0206.png)"'
- en: Figure 2-6\. To project a point at the head of <math alttext="bold b"><mi>ğ›</mi></math>
    onto a vector <math alttext="bold a"><mi>ğš</mi></math> with minimum distance,
    we need a formula to compute <math alttext="beta"><mi>Î²</mi></math> such that
    the length of the projection vector <math alttext="left-parenthesis bold b minus
    beta bold a right-parenthesis"><mrow><mo>(</mo> <mi>ğ›</mi> <mo>-</mo> <mi>Î²</mi>
    <mi>ğš</mi> <mo>)</mo></mrow></math> is minimized
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2-6\. æŠ•å½± <math alttext="bold b"><mi>ğ›</mi></math> å¤´éƒ¨çš„ç‚¹åˆ°å‘é‡ <math alttext="bold
    a"><mi>ğš</mi></math> ä¸Šï¼Œä»¥è·å¾—æœ€å°è·ç¦»ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªè®¡ç®— <math alttext="beta"><mi>Î²</mi></math>
    çš„å…¬å¼ï¼Œä½¿æŠ•å½±å‘é‡ <math alttext="left-parenthesis bold b minus beta bold a right-parenthesis"><mrow><mo>(</mo>
    <mi>ğ›</mi> <mo>-</mo> <mi>Î²</mi> <mi>ğš</mi> <mo>)</mo></mrow></math> çš„é•¿åº¦æœ€å°åŒ–ã€‚
- en: Importantly, we can use vector subtraction to define the line from <math alttext="bold
    b"><mi>ğ›</mi></math> to <math alttext="beta bold a"><mrow><mi>Î²</mi> <mi>ğš</mi></mrow></math>
    . We could give this line its own letter, e.g., vector <math alttext="bold c"><mi>ğœ</mi></math>
    , but the subtraction is necessary for discovering the solution.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å‘é‡å‡æ³•æ¥å®šä¹‰ä» <math alttext="bold b"><mi>ğ›</mi></math> åˆ° <math alttext="beta
    bold a"><mrow><mi>Î²</mi> <mi>ğš</mi></mrow></math> çš„ç›´çº¿ã€‚æˆ‘ä»¬å¯ä»¥ç»™è¿™æ¡çº¿ä¸€ä¸ªç‹¬ç«‹çš„å­—æ¯ï¼Œä¾‹å¦‚å‘é‡ <math
    alttext="bold c"><mi>ğœ</mi></math> ï¼Œä½†å‡æ³•å¯¹äºå‘ç°è§£å†³æ–¹æ¡ˆæ˜¯å¿…è¦çš„ã€‚
- en: The key insight that leads to the solution to this problem is that the point
    on <math alttext="bold a"><mi>ğš</mi></math> that is closest to the head of <math
    alttext="bold b"><mi>ğ›</mi></math> is found by drawing a line from <math alttext="bold
    b"><mi>ğ›</mi></math> that meets <math alttext="bold a"><mi>ğš</mi></math> at a
    right angle. The intuition here is to imagine a triangle formed by the origin,
    the head of <math alttext="bold b"><mi>ğ›</mi></math> , and <math alttext="beta
    bold a"><mrow><mi>Î²</mi> <mi>ğš</mi></mrow></math> ; the length of the line from
    <math alttext="bold b"><mi>ğ›</mi></math> to <math alttext="beta bold a"><mrow><mi>Î²</mi>
    <mi>ğš</mi></mrow></math> gets longer as the angle <math alttext="measured-angle
    beta bold a"><mrow><mi>âˆ¡</mi> <mi>Î²</mi> <mi>ğš</mi></mrow></math> gets smaller
    than <math alttext="90 Superscript ring"><msup><mn>90</mn> <mo>âˆ˜</mo></msup></math>
    or larger than <math alttext="90 Superscript ring"><msup><mn>90</mn> <mo>âˆ˜</mo></msup></math>
    .
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¼è‡´è§£å†³æ­¤é—®é¢˜çš„å…³é”®è§è§£æ˜¯ï¼Œè·ç¦» <math alttext="bold b"><mi>ğ›</mi></math> å¤´éƒ¨æœ€è¿‘çš„ <math alttext="bold
    a"><mi>ğš</mi></math> ä¸Šçš„ç‚¹æ˜¯é€šè¿‡ä» <math alttext="bold b"><mi>ğ›</mi></math> åˆ° <math
    alttext="beta bold a"><mrow><mi>Î²</mi> <mi>ğš</mi></mrow></math> ç”»ä¸€æ¡ç›´çº¿æ¥æ‰¾åˆ°çš„ï¼Œè¯¥ç›´çº¿ä¸
    <math alttext="bold a"><mi>ğš</mi></math> å‚ç›´ã€‚è¿™é‡Œçš„ç›´è§‰æ˜¯æƒ³è±¡ä¸€ä¸ªç”±åŸç‚¹ã€<math alttext="bold
    b"><mi>ğ›</mi></math> å¤´éƒ¨å’Œ <math alttext="beta bold a"><mrow><mi>Î²</mi> <mi>ğš</mi></mrow></math>
    ç»„æˆçš„ä¸‰è§’å½¢ï¼›ä» <math alttext="bold b"><mi>ğ›</mi></math> åˆ° <math alttext="beta bold a"><mrow><mi>Î²</mi>
    <mi>ğš</mi></mrow></math> çš„çº¿æ®µé•¿åº¦éšè§’åº¦ <math alttext="measured-angle beta bold a"><mrow><mi>âˆ¡</mi>
    <mi>Î²</mi> <mi>ğš</mi></mrow></math> å°äº <math alttext="90 Superscript ring"><msup><mn>90</mn>
    <mo>âˆ˜</mo></msup></math> æˆ–å¤§äº <math alttext="90 Superscript ring"><msup><mn>90</mn>
    <mo>âˆ˜</mo></msup></math> è€Œå˜é•¿ã€‚
- en: 'Putting this together, we have deduced that <math alttext="left-parenthesis
    bold b minus beta bold a right-parenthesis"><mrow><mo>(</mo> <mi>ğ›</mi> <mo>-</mo>
    <mi>Î²</mi> <mi>ğš</mi> <mo>)</mo></mrow></math> is orthogonal to <math alttext="beta
    bold a"><mrow><mi>Î²</mi> <mi>ğš</mi></mrow></math> , which is the same thing as
    saying that those vectors are perpendicular. And that means that the dot product
    between them must be zero. Letâ€™s transform those words into an equation:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: æŠŠè¿™äº›æ”¾åœ¨ä¸€èµ·ï¼Œæˆ‘ä»¬æ¨æ–­å‡º <math alttext="left-parenthesis bold b minus beta bold a right-parenthesis"><mrow><mo>(</mo>
    <mi>ğ›</mi> <mo>-</mo> <mi>Î²</mi> <mi>ğš</mi> <mo>)</mo></mrow></math> å‚ç›´äº <math
    alttext="beta bold a"><mrow><mi>Î²</mi> <mi>ğš</mi></mrow></math> ï¼Œè¿™æ„å‘³ç€è¿™äº›å‘é‡æ˜¯å‚ç›´çš„ã€‚è¿™æ„å‘³ç€å®ƒä»¬çš„ç‚¹ç§¯å¿…é¡»ä¸ºé›¶ã€‚è®©æˆ‘ä»¬æŠŠè¿™äº›è¯è¯­è½¬åŒ–ä¸ºä¸€ä¸ªæ–¹ç¨‹ï¼š
- en: <math alttext="bold a Superscript upper T Baseline left-parenthesis bold b minus
    beta bold a right-parenthesis equals 0" display="block"><mrow><msup><mi>ğš</mi>
    <mtext>T</mtext></msup> <mrow><mo>(</mo> <mi>ğ›</mi> <mo>-</mo> <mi>Î²</mi> <mi>ğš</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mn>0</mn></mrow></math>
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold a Superscript upper T Baseline left-parenthesis bold b minus
    beta bold a right-parenthesis equals 0" display="block"><mrow><msup><mi>ğš</mi>
    <mtext>T</mtext></msup> <mrow><mo>(</mo> <mi>ğ›</mi> <mo>-</mo> <mi>Î²</mi> <mi>ğš</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mn>0</mn></mrow></math>
- en: 'From here, we can apply some algebra to solve for <math alttext="beta"><mi>Î²</mi></math>
    (note the application of the distributive property of dot products), which is
    shown in [Equation 2-12](#orth_proj_dot):'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ä»è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥åº”ç”¨ä¸€äº›ä»£æ•°æ¥è§£ <math alttext="beta"><mi>Î²</mi></math> çš„é—®é¢˜ï¼ˆæ³¨æ„ç‚¹ç§¯çš„åˆ†é…æ€§è´¨çš„åº”ç”¨ï¼‰ï¼Œå¦‚
    [æ–¹ç¨‹å¼ 2-12](#orth_proj_dot) æ‰€ç¤ºï¼š
- en: Equation 2-12\. Solving the orthogonal projection problem
  id: totrans-182
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹å¼ 2-12\. è§£å†³æ­£äº¤æŠ•å½±é—®é¢˜
- en: <math alttext="StartLayout 1st Row 1st Column bold a Superscript upper T Baseline
    bold b minus beta bold a Superscript upper T Baseline bold a 2nd Column equals
    0 2nd Row 1st Column beta bold a Superscript upper T Baseline bold a 2nd Column
    equals bold a Superscript upper T Baseline bold b 3rd Row 1st Column beta 2nd
    Column equals StartFraction bold a Superscript upper T Baseline bold b Over bold
    a Superscript upper T Baseline bold a EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>ğš</mi> <mtext>T</mtext></msup>
    <mi>ğ›</mi> <mo>-</mo> <mi>Î²</mi> <msup><mi>ğš</mi> <mtext>T</mtext></msup> <mi>ğš</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><mi>Î²</mi> <msup><mi>ğš</mi> <mtext>T</mtext></msup>
    <mi>ğš</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <msup><mi>ğš</mi>
    <mtext>T</mtext></msup> <mi>ğ›</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>Î²</mi></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mfrac><mrow><msup><mi>ğš</mi> <mtext>T</mtext></msup>
    <mi>ğ›</mi></mrow> <mrow><msup><mi>ğš</mi> <mtext>T</mtext></msup> <mi>ğš</mi></mrow></mfrac></mrow></mtd></mtr></mtable></math>
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column bold a Superscript upper T Baseline
    bold b minus beta bold a Superscript upper T Baseline bold a 2nd Column equals
    0 2nd Row 1st Column beta bold a Superscript upper T Baseline bold a 2nd Column
    equals bold a Superscript upper T Baseline bold b 3rd Row 1st Column beta 2nd
    Column equals StartFraction bold a Superscript upper T Baseline bold b Over bold
    a Superscript upper T Baseline bold a EndFraction EndLayout" display="block"><mtable
    displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mi>ğš</mi> <mtext>T</mtext></msup>
    <mi>ğ›</mi> <mo>-</mo> <mi>Î²</mi> <msup><mi>ğš</mi> <mtext>T</mtext></msup> <mi>ğš</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mn>0</mn></mrow></mtd></mtr> <mtr><mtd
    columnalign="right"><mrow><mi>Î²</mi> <msup><mi>ğš</mi> <mtext>T</mtext></msup>
    <mi>ğš</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <msup><mi>ğš</mi>
    <mtext>T</mtext></msup> <mi>ğ›</mi></mrow></mtd></mtr> <mtr><mtd columnalign="right"><mi>Î²</mi></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mfrac><mrow><msup><mi>ğš</mi> <mtext>T</mtext></msup>
    <mi>ğ›</mi></mrow> <mrow><msup><mi>ğš</mi> <mtext>T</mtext></msup> <mi>ğš</mi></mrow></mfrac></mrow></mtd></mtr></mtable></math>
- en: 'This is quite beautiful: we began with a simple geometric picture, explored
    the implications of the geometry, expressed those implications as a formula, and
    then applied a bit of algebra. And the upshot is that we discovered a formula
    for projecting a point onto a line with minimum distance. This is called *orthogonal
    projection*, and it is the basis for many applications in statistics and machine
    learning, including the famous least squares formula for solving linear models
    (youâ€™ll see orthogonal projections in Chapters [9](ch09.xhtml#Chapter_09), [10](ch10.xhtml#Chapter_10),
    and [11](ch11.xhtml#Chapter_11)).'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™çœŸæ˜¯å¤ªç¾å¦™äº†ï¼šæˆ‘ä»¬ä»ä¸€ä¸ªç®€å•çš„å‡ ä½•å›¾åƒå¼€å§‹ï¼Œæ¢ç´¢äº†å‡ ä½•å›¾åƒçš„å«ä¹‰ï¼Œå°†è¿™äº›å«ä¹‰è¡¨è¾¾ä¸ºä¸€ä¸ªå…¬å¼ï¼Œç„¶ååº”ç”¨äº†ä¸€ç‚¹ä»£æ•°ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªå°†ç‚¹æŠ•å½±åˆ°å…·æœ‰æœ€å°è·ç¦»çš„çº¿ä¸Šçš„å…¬å¼ã€‚è¿™è¢«ç§°ä¸º*æ­£äº¤æŠ•å½±*ï¼Œå®ƒæ˜¯ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ ä¸­è®¸å¤šåº”ç”¨çš„åŸºç¡€ï¼ŒåŒ…æ‹¬è‘—åçš„æœ€å°äºŒä¹˜æ³•å…¬å¼ï¼ˆä½ å°†åœ¨ç¬¬
    [9](ch09.xhtml#Chapter_09)ã€[10](ch10.xhtml#Chapter_10) å’Œ [11](ch11.xhtml#Chapter_11)
    ç« èŠ‚ä¸­çœ‹åˆ°æ­£äº¤æŠ•å½±ï¼‰ã€‚
- en: I can imagine that youâ€™re super curious to see what the Python code would look
    like to implement this formula. But youâ€™re going to have to write that code yourself
    in [Exercise 2-8](#exercise_2_8) at the end of this chapter. If you canâ€™t wait
    until the end of the chapter, feel free to solve that exercise now, and then continue
    learning about orthogonal decomposition.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¯ä»¥æƒ³è±¡ä½ è‚¯å®šéå¸¸æƒ³çœ‹çœ‹å¦‚ä½•ä½¿ç”¨ Python ä»£ç æ¥å®ç°è¿™ä¸ªå…¬å¼ã€‚ä½†ä½ éœ€è¦è‡ªå·±åœ¨æœ¬ç« æœ«å°¾çš„ [ç»ƒä¹  2-8](#exercise_2_8) ä¸­ç¼–å†™è¿™æ®µä»£ç ã€‚å¦‚æœä½ ç­‰ä¸åŠæƒ³è¦å…ˆè§£å†³è¿™ä¸ªç»ƒä¹ ï¼Œç„¶åç»§ç»­å­¦ä¹ æ­£äº¤åˆ†è§£ã€‚
- en: You might be wondering how this is related to orthogonal vector decomposition,
    i.e., the title of this section. The minimum distance projection is the necessary
    grounding, and youâ€™re now ready to learn the decomposition.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ å¯èƒ½ä¼šæƒ³çŸ¥é“è¿™ä¸æ­£äº¤å‘é‡åˆ†è§£ï¼Œä¹Ÿå°±æ˜¯æœ¬èŠ‚æ ‡é¢˜æœ‰ä»€ä¹ˆå…³ç³»ã€‚æœ€å°è·ç¦»æŠ•å½±æ˜¯å¿…è¦çš„åŸºç¡€ï¼Œä½ ç°åœ¨å·²ç»å‡†å¤‡å¥½å­¦ä¹ è¿™ç§åˆ†è§£äº†ã€‚
- en: As usual, we start with the setup and the goal. We begin with two vectors, which
    Iâ€™ll call the â€œtarget vectorâ€ and the â€œreference vector.â€ Our goal is to decompose
    the target vector into two other vectors such that (1) those two vectors sum to
    the target vector, and (2) one vector is orthogonal to the reference vector while
    the other is parallel to the reference vector. The situation is illustrated in
    [FigureÂ 2-7](#fig_2_7).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: é€šå¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä»è®¾ç½®å’Œç›®æ ‡å¼€å§‹ã€‚æˆ‘ä»¬æœ‰ä¸¤ä¸ªå‘é‡ï¼Œæˆ‘å°†å®ƒä»¬ç§°ä¸ºâ€œç›®æ ‡å‘é‡â€å’Œâ€œå‚è€ƒå‘é‡â€ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†ç›®æ ‡å‘é‡åˆ†è§£ä¸ºå¦å¤–ä¸¤ä¸ªå‘é‡ï¼Œè¿™ä¸¤ä¸ªå‘é‡çš„å’Œç­‰äºç›®æ ‡å‘é‡ï¼Œå¹¶ä¸”å…¶ä¸­ä¸€ä¸ªå‘é‡å‚ç›´äºå‚è€ƒå‘é‡ï¼Œå¦ä¸€ä¸ªå¹³è¡Œäºå‚è€ƒå‘é‡ã€‚è¿™ç§æƒ…å†µåœ¨
    [å›¾Â 2-7](#fig_2_7) ä¸­æœ‰æ‰€è¯´æ˜ã€‚
- en: 'Before starting with the math, letâ€™s get our terms straight: I will call the
    target vector <math alttext="bold t"><mi>ğ­</mi></math> and the reference vector
    <math alttext="bold r"><mi>ğ«</mi></math> . Then, the two vectors formed from the
    target vector will be called the *perpendicular component*, indicated as <math
    alttext="bold t Subscript up-tack bold r"><msub><mi>ğ­</mi> <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub></math>
    , and the *parallel component*, indicated as <math alttext="bold t Subscript parallel-to
    bold r"><msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></math> .'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿›è¡Œæ•°å­¦æ¨å¯¼ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆææ¸…æ¥šæœ¯è¯­ï¼šæˆ‘å°†ç§°ç›®æ ‡å‘é‡ä¸º <math alttext="bold t"><mi>ğ­</mi></math>ï¼Œå‚è€ƒå‘é‡ä¸º
    <math alttext="bold r"><mi>ğ«</mi></math>ã€‚ç„¶åï¼Œä»ç›®æ ‡å‘é‡å½¢æˆçš„ä¸¤ä¸ªå‘é‡å°†è¢«ç§°ä¸º*å‚ç›´åˆ†é‡*ï¼Œè¡¨ç¤ºä¸º <math alttext="bold
    t Subscript up-tack bold r"><msub><mi>ğ­</mi> <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub></math>ï¼Œä»¥åŠ*å¹³è¡Œåˆ†é‡*ï¼Œè¡¨ç¤ºä¸º
    <math alttext="bold t Subscript parallel-to bold r"><msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></math>ã€‚
- en: '![What does this do?](assets/plad_0207.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![è¿™æ˜¯åšä»€ä¹ˆçš„ï¼Ÿ](assets/plad_0207.png)'
- en: 'Figure 2-7\. Illustration of orthogonal vector decomposition: decompose vector
    <math alttext="bold t"><mi>ğ­</mi></math> into the sum of two other vectors that
    are orthogonal and parallel to vector <math alttext="bold r"><mi>ğ«</mi></math>'
  id: totrans-190
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2-7\. æ­£äº¤å‘é‡åˆ†è§£çš„ç¤ºä¾‹ï¼šå°†å‘é‡ <math alttext="bold t"><mi>ğ­</mi></math> åˆ†è§£ä¸ºä¸å‘é‡ <math
    alttext="bold r"><mi>ğ«</mi></math> æ­£äº¤ä¸”å¹³è¡Œçš„ä¸¤ä¸ªå‘é‡ä¹‹å’Œã€‚
- en: 'We begin by defining the parallel component. What is a vector that is parallel
    to <math alttext="bold r"><mi>ğ«</mi></math> ? Well, any scaled version of <math
    alttext="bold r"><mi>ğ«</mi></math> is obviously parallel to <math alttext="bold
    r"><mi>ğ«</mi></math> . So, we find <math alttext="bold t Subscript parallel-to
    bold r"><msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></math> simply
    by applying the orthogonal projection formula that we just discovered ([Equation
    2-13](#find-tParallel)):'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä»å®šä¹‰å¹³è¡Œåˆ†é‡å¼€å§‹ã€‚ä»€ä¹ˆæ˜¯ä¸<math alttext="bold r"><mi>ğ«</mi></math>å¹³è¡Œçš„å‘é‡ï¼Ÿæ˜¾ç„¶ï¼Œä»»ä½•<math alttext="bold
    r"><mi>ğ«</mi></math>çš„ç¼©æ”¾ç‰ˆæœ¬éƒ½ä¸<math alttext="bold r"><mi>ğ«</mi></math>å¹³è¡Œã€‚å› æ­¤ï¼Œæˆ‘ä»¬é€šè¿‡åˆšåˆšå‘ç°çš„æ­£äº¤æŠ•å½±å…¬å¼ï¼ˆ[Equation
    2-13](#find-tParallel)ï¼‰æ¥ç®€å•åœ°æ‰¾åˆ°<math alttext="bold t Subscript parallel-to bold
    r"><msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></math>ã€‚
- en: Equation 2-13\. Computing the parallel component of **t** with respect to **r**
  id: totrans-192
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹å¼2-13ã€‚è®¡ç®—**t**ç›¸å¯¹äº**r**çš„å¹³è¡Œåˆ†é‡
- en: <math alttext="bold t Subscript parallel-to bold r Baseline equals bold r StartFraction
    bold t Superscript upper T Baseline bold r Over bold r Superscript upper T Baseline
    bold r EndFraction" display="block"><mrow><msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub>
    <mo>=</mo> <mi>ğ«</mi> <mfrac><mrow><msup><mi>ğ­</mi> <mtext>T</mtext></msup> <mi>ğ«</mi></mrow>
    <mrow><msup><mi>ğ«</mi> <mtext>T</mtext></msup> <mi>ğ«</mi></mrow></mfrac></mrow></math>
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="bold t Subscript parallel-to bold r Baseline equals bold r StartFraction
    bold t Superscript upper T Baseline bold r Over bold r Superscript upper T Baseline
    bold r EndFraction" display="block"><mrow><msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub>
    <mo>=</mo> <mi>ğ«</mi> <mfrac><mrow><msup><mi>ğ­</mi> <mtext>T</mtext></msup> <mi>ğ«</mi></mrow>
    <mrow><msup><mi>ğ«</mi> <mtext>T</mtext></msup> <mi>ğ«</mi></mrow></mfrac></mrow></math>
- en: 'Note the subtle difference to [Equation 2-12](#orth_proj_dot): there we only
    computed the scalar <math alttext="beta"><mi>Î²</mi></math> ; here we want to compute
    the scaled vector <math alttext="beta bold r"><mrow><mi>Î²</mi> <mi>ğ«</mi></mrow></math>
    .'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: æ³¨æ„ä¸[Equation 2-12](#orth_proj_dot)çš„å¾®å¦™å·®åˆ«ï¼šé‚£é‡Œæˆ‘ä»¬åªè®¡ç®—äº†æ ‡é‡<math alttext="beta"><mi>Î²</mi></math>ï¼›è€Œè¿™é‡Œæˆ‘ä»¬è¦è®¡ç®—ç¼©æ”¾å‘é‡<math
    alttext="beta bold r"><mrow><mi>Î²</mi> <mi>ğ«</mi></mrow></math>ã€‚
- en: 'Thatâ€™s the parallel component. How do we find the perpendicular component?
    That one is easier, because we already know that the two vector components must
    sum to the original target vector. Thus:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£å°±æ˜¯å¹³è¡Œåˆ†é‡ã€‚æˆ‘ä»¬å¦‚ä½•æ‰¾åˆ°å‚ç›´åˆ†é‡å‘¢ï¼Ÿè¿™æ›´å®¹æ˜“ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»çŸ¥é“è¿™ä¸¤ä¸ªå‘é‡åˆ†é‡å¿…é¡»ç­‰äºåŸå§‹ç›®æ ‡å‘é‡ã€‚å› æ­¤ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column bold t 2nd Column equals bold
    t Subscript up-tack bold r Baseline plus bold t Subscript parallel-to bold r Baseline
    2nd Row 1st Column bold t Subscript up-tack bold r 2nd Column equals bold t minus
    bold t Subscript parallel-to bold r EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mi>ğ­</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>ğ­</mi> <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub> <mo>+</mo> <msub><mi>ğ­</mi>
    <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>ğ­</mi>
    <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi>ğ­</mi> <mo>-</mo> <msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></mrow></mtd></mtr></mtable></math>
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column bold t 2nd Column equals bold
    t Subscript up-tack bold r Baseline plus bold t Subscript parallel-to bold r Baseline
    2nd Row 1st Column bold t Subscript up-tack bold r 2nd Column equals bold t minus
    bold t Subscript parallel-to bold r EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd
    columnalign="right"><mi>ğ­</mi></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <msub><mi>ğ­</mi> <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub> <mo>+</mo> <msub><mi>ğ­</mi>
    <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></mrow></mtd></mtr> <mtr><mtd columnalign="right"><msub><mi>ğ­</mi>
    <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mi>ğ­</mi> <mo>-</mo> <msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></mrow></mtd></mtr></mtable></math>
- en: In other words, we subtract off the parallel component from the original vector,
    and the residual is our perpendicular component.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: æ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬ä»åŸå§‹å‘é‡ä¸­å‡å»å¹³è¡Œåˆ†é‡ï¼Œå‰©ä½™éƒ¨åˆ†å³ä¸ºæˆ‘ä»¬çš„å‚ç›´åˆ†é‡ã€‚
- en: 'But is that perpendicular component *really* orthogonal to the reference vector?
    Yes, it is! To prove it, you show that the dot product between the perpendicular
    component and the reference vector is zero:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯é‚£ä¸ªå‚ç›´åˆ†é‡*çœŸçš„*ä¸å‚è€ƒå‘é‡æ­£äº¤å—ï¼Ÿæ˜¯çš„ï¼Œå®ƒæ˜¯ï¼ä¸ºäº†è¯æ˜è¿™ä¸€ç‚¹ï¼Œä½ å¯ä»¥å±•ç¤ºå‚ç›´åˆ†é‡ä¸å‚è€ƒå‘é‡çš„ç‚¹ç§¯ä¸ºé›¶ï¼š
- en: <math alttext="StartLayout 1st Row 1st Column left-parenthesis bold t Subscript
    up-tack bold r Baseline right-parenthesis Superscript upper T Baseline bold r
    2nd Column equals 0 2nd Row 1st Column left-parenthesis bold t minus bold r StartFraction
    bold t Superscript upper T Baseline bold r Over bold r Superscript upper T Baseline
    bold r EndFraction right-parenthesis Superscript upper T Baseline bold r 2nd Column
    equals 0 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mrow><mo>(</mo><msub><mi>ğ­</mi>
    <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub> <mo>)</mo></mrow> <mtext>T</mtext></msup>
    <mi>ğ«</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <mn>0</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msup><mrow><mo>(</mo><mi>ğ­</mi><mo>-</mo><mi>ğ«</mi><mfrac><mrow><msup><mi>ğ­</mi>
    <mtext>T</mtext></msup> <mi>ğ«</mi></mrow> <mrow><msup><mi>ğ«</mi> <mtext>T</mtext></msup>
    <mi>ğ«</mi></mrow></mfrac><mo>)</mo></mrow> <mtext>T</mtext></msup> <mi>ğ«</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mn>0</mn></mrow></mtd></mtr></mtable></math>
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="StartLayout 1st Row 1st Column left-parenthesis bold t Subscript
    up-tack bold r Baseline right-parenthesis Superscript upper T Baseline bold r
    2nd Column equals 0 2nd Row 1st Column left-parenthesis bold t minus bold r StartFraction
    bold t Superscript upper T Baseline bold r Over bold r Superscript upper T Baseline
    bold r EndFraction right-parenthesis Superscript upper T Baseline bold r 2nd Column
    equals 0 EndLayout" display="block"><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><msup><mrow><mo>(</mo><msub><mi>ğ­</mi>
    <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub> <mo>)</mo></mrow> <mtext>T</mtext></msup>
    <mi>ğ«</mi></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo> <mn>0</mn></mrow></mtd></mtr>
    <mtr><mtd columnalign="right"><mrow><msup><mrow><mo>(</mo><mi>ğ­</mi><mo>-</mo><mi>ğ«</mi><mfrac><mrow><msup><mi>ğ­</mi>
    <mtext>T</mtext></msup> <mi>ğ«</mi></mrow> <mrow><msup><mi>ğ«</mi> <mtext>T</mtext></msup>
    <mi>ğ«</mi></mrow></mfrac><mo>)</mo></mrow> <mtext>T</mtext></msup> <mi>ğ«</mi></mrow></mtd>
    <mtd columnalign="left"><mrow><mo>=</mo> <mn>0</mn></mrow></mtd></mtr></mtable></math>
- en: Working through the algebra of this proof is straightforward but tedious, so
    Iâ€™ve omitted it. Instead, youâ€™ll work on building intuition using Python code
    in the exercises.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: å®Œæˆè¿™ä¸ªè¯æ˜çš„ä»£æ•°è¿‡ç¨‹æ˜¯ç›´æ¥ä½†ä¹å‘³çš„ï¼Œæ‰€ä»¥æˆ‘çœç•¥äº†å®ƒã€‚ç›¸åï¼Œä½ å°†é€šè¿‡Pythonä»£ç æ¥å»ºç«‹ç›´è§‰ã€‚
- en: 'I hope you enjoyed learning about orthogonal vector decomposition. Note again
    the general principle: we break apart one mathematical object into a combination
    of other objects. The details of the decomposition depend on our constraints (in
    this case, orthogonal and parallel to a reference vector), which means that different
    constraints (that is, different goals of the analysis) can lead to different decompositions
    of the same vector.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›ä½ å–œæ¬¢å­¦ä¹ æ­£äº¤å‘é‡åˆ†è§£ã€‚å†æ¬¡æ³¨æ„ä¸€èˆ¬åŸåˆ™ï¼šæˆ‘ä»¬å°†ä¸€ä¸ªæ•°å­¦å¯¹è±¡åˆ†è§£ä¸ºå…¶ä»–å¯¹è±¡çš„ç»„åˆã€‚åˆ†è§£çš„ç»†èŠ‚å–å†³äºæˆ‘ä»¬çš„çº¦æŸæ¡ä»¶ï¼ˆåœ¨æœ¬ä¾‹ä¸­ä¸ºæ­£äº¤å’Œå¹³è¡Œäºå‚è€ƒå‘é‡ï¼‰ï¼Œè¿™æ„å‘³ç€ä¸åŒçš„çº¦æŸæ¡ä»¶ï¼ˆå³åˆ†æç›®æ ‡çš„ä¸åŒï¼‰å¯ä»¥å¯¼è‡´ç›¸åŒå‘é‡çš„ä¸åŒåˆ†è§£ã€‚
- en: Summary
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: The beauty of linear algebra is that even the most sophisticated and computationally
    intense operations on matrices are made up of simple operations, most of which
    can be understood with geometric intuition. Do not underestimate the importance
    of studying simple operations on vectors, because what you learned in this chapter
    will form the basis for the rest of the bookâ€”and the rest of your career as an
    *applied linear algebratician* (which is what you really are if you do anything
    with data science, machine learning, AI, deep learning, image processing, computational
    vision, statistics, blah blah blah).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: çº¿æ€§ä»£æ•°çš„ç¾åœ¨äºï¼Œå³ä½¿æ˜¯å¯¹çŸ©é˜µè¿›è¡Œæœ€å¤æ‚å’Œè®¡ç®—å¯†é›†çš„æ“ä½œï¼Œä¹Ÿå¯ä»¥åˆ†è§£ä¸ºç®€å•æ“ä½œï¼Œå…¶ä¸­å¤§éƒ¨åˆ†å¯ä»¥é€šè¿‡å‡ ä½•ç›´è§‰æ¥ç†è§£ã€‚ä¸è¦ä½ä¼°å¯¹å‘é‡è¿›è¡Œç®€å•æ“ä½œçš„é‡è¦æ€§ï¼Œå› ä¸ºä½ åœ¨æœ¬ç« å­¦åˆ°çš„å°†æ„æˆæœ¬ä¹¦ä»¥åŠä½ ä½œä¸º*åº”ç”¨çº¿æ€§ä»£æ•°å­¦å®¶*ï¼ˆå¦‚æœä½ ä»äº‹æ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€æ·±åº¦å­¦ä¹ ã€å›¾åƒå¤„ç†ã€è®¡ç®—è§†è§‰ã€ç»Ÿè®¡ç­‰å·¥ä½œï¼Œè¿™æ‰æ˜¯ä½ çœŸæ­£çš„èº«ä»½ï¼‰èŒä¸šç”Ÿæ¶¯çš„åŸºç¡€ã€‚
- en: 'Here are the most important take-home messages of this chapter:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æœ¬ç« æœ€é‡è¦çš„è¦ç‚¹ï¼š
- en: A vector is an ordered list of numbers that is placed in a column or in a row.
    The number of elements in a vector is called its dimensionality, and a vector
    can be represented as a line in a geometric space with the number of axes equal
    to the dimensionality.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘é‡æ˜¯ä¸€ä¸ªæŒ‰é¡ºåºæ’åˆ—çš„æ•°å­—åˆ—è¡¨ï¼Œå¯ä»¥æ”¾ç½®åœ¨åˆ—æˆ–è¡Œä¸­ã€‚å‘é‡çš„å…ƒç´ æ•°ç§°ä¸ºå…¶ç»´æ•°ï¼Œå‘é‡å¯ä»¥åœ¨å‡ ä½•ç©ºé—´ä¸­è¡¨ç¤ºä¸ºå…·æœ‰ä¸ç»´æ•°ç›¸ç­‰çš„è½´æ•°çš„çº¿ã€‚
- en: Several arithmetic operations (addition, subtraction, and Hadamard multiplication)
    on vectors work element-wise.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘é‡çš„å‡ ä¸ªç®—æœ¯è¿ç®—ï¼ˆåŠ æ³•ã€å‡æ³•å’ŒHadamardä¹˜æ³•ï¼‰æŒ‰å…ƒç´ é€ä¸ªæ“ä½œã€‚
- en: The dot product is a single number that encodes the relationship between two
    vectors of the same dimensionality, and is computed as element-wise multiplication
    and sum.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç‚¹ç§¯æ˜¯ä¸€ä¸ªå•ä¸€çš„æ•°å­—ï¼Œç¼–ç äº†ä¸¤ä¸ªç›¸åŒç»´åº¦å‘é‡ä¹‹é—´çš„å…³ç³»ï¼Œè®¡ç®—æ–¹æ³•æ˜¯å…ƒç´ é€ä¸ªç›¸ä¹˜å¹¶æ±‚å’Œã€‚
- en: The dot product is zero for vectors that are orthogonal, which geometrically
    means that the vectors meet at a right angle.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹äºæ­£äº¤å‘é‡ï¼Œç‚¹ç§¯ä¸ºé›¶ï¼Œå‡ ä½•ä¸Šæ„å‘³ç€å‘é‡åœ¨ç›´è§’å¤„ç›¸äº¤ã€‚
- en: Orthogonal vector decomposition involves breaking up a vector into the sum of
    two other vectors that are orthogonal and parallel to a reference vector. The
    formula for this decomposition can be rederived from the geometry, but you should
    remember the phrase â€œmapping over magnitudeâ€ as the concept that that formula
    expresses.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­£äº¤å‘é‡åˆ†è§£æ¶‰åŠå°†ä¸€ä¸ªå‘é‡åˆ†è§£ä¸ºå¦å¤–ä¸¤ä¸ªä¸å‚è€ƒå‘é‡æ­£äº¤ä¸”å¹³è¡Œçš„å‘é‡ä¹‹å’Œã€‚è¿™ç§åˆ†è§£çš„å…¬å¼å¯ä»¥ä»å‡ ä½•ä¸­é‡æ–°æ¨å¯¼å‡ºæ¥ï¼Œä½†ä½ åº”è¯¥è®°ä½â€œæ˜ å°„åˆ°å¤§å°â€çš„æ¦‚å¿µæ­£æ˜¯è¿™ä¸ªå…¬å¼è¡¨è¾¾çš„æ¦‚å¿µã€‚
- en: Code Exercises
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»£ç ç»ƒä¹ 
- en: I hope you donâ€™t see these exercises as tedious work that you need to do. Instead,
    these exercises are opportunities to polish your math and coding skills, and to
    make sure that you really understand the material in this chapter.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘å¸Œæœ›ä½ ä¸è¦æŠŠè¿™äº›ç»ƒä¹ çœ‹ä½œæ˜¯ä½ éœ€è¦å®Œæˆçš„çƒ¦äººå·¥ä½œã€‚ç›¸åï¼Œè¿™äº›ç»ƒä¹ æ˜¯æå‡ä½ çš„æ•°å­¦å’Œç¼–ç æŠ€èƒ½çš„æœºä¼šï¼Œç¡®ä¿ä½ çœŸæ­£ç†è§£æœ¬ç« å†…å®¹ã€‚
- en: 'I also want you to see these exercises as a springboard to continue exploring
    linear algebra using Python. Change the code to use different numbers, different
    dimensionalities, different orientations, etc. Write your own code to test other
    concepts mentioned in the chapter. Most importantly: have fun and embrace the
    learning experience.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä¹Ÿå¸Œæœ›ä½ æŠŠè¿™äº›ç»ƒä¹ çœ‹ä½œæ˜¯ä½¿ç”¨Pythonç»§ç»­æ¢ç´¢çº¿æ€§ä»£æ•°çš„è·³æ¿ã€‚æ›´æ”¹ä»£ç ä»¥ä½¿ç”¨ä¸åŒçš„æ•°å­—ã€ä¸åŒçš„ç»´åº¦ã€ä¸åŒçš„æ–¹å‘ç­‰ã€‚ç¼–å†™è‡ªå·±çš„ä»£ç æ¥æµ‹è¯•ç« èŠ‚ä¸­æåˆ°çš„å…¶ä»–æ¦‚å¿µã€‚æœ€é‡è¦çš„æ˜¯ï¼šäº«å—å­¦ä¹ è¿‡ç¨‹ï¼Œæ‹¥æŠ±å­¦ä¹ çš„ä½“éªŒã€‚
- en: 'As a reminder: the solutions to all the exercises can be viewed or downloaded
    from [*https://github.com/mikexcohen/LA4DataScience*](https://github.com/mikexcohen/LA4DataScience).'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºæé†’ï¼šæ‰€æœ‰ç»ƒä¹ çš„è§£ç­”å¯ä»¥åœ¨[*https://github.com/mikexcohen/LA4DataScience*](https://github.com/mikexcohen/LA4DataScience)ä¸ŠæŸ¥çœ‹æˆ–ä¸‹è½½ã€‚
- en: Exercise 2-1\.
  id: totrans-214
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-1ã€‚
- en: The online code repository is â€œmissingâ€ code to create [FigureÂ 2-2](#fig_2_2).
    (Itâ€™s not really *missing*â€”I moved it into the solution to this exercise.) So,
    your goal here is to write your own code to produce [FigureÂ 2-2](#fig_2_2).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨çº¿ä»£ç åº“â€œä¸¢å¤±â€äº†åˆ›å»º[FigureÂ 2-2](#fig_2_2)çš„ä»£ç ã€‚ï¼ˆå®é™…ä¸Šå¹¶ä¸æ˜¯çœŸçš„â€œä¸¢å¤±â€ â€” æˆ‘æŠŠå®ƒç§»åˆ°äº†è¿™ä¸ªç»ƒä¹ çš„è§£å†³æ–¹æ¡ˆä¸­ã€‚ï¼‰å› æ­¤ï¼Œä½ çš„ç›®æ ‡æ˜¯ç¼–å†™è‡ªå·±çš„ä»£ç æ¥ç”Ÿæˆ[FigureÂ 2-2](#fig_2_2)ã€‚
- en: Exercise 2-2\.
  id: totrans-216
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-2ã€‚
- en: Write an algorithm that computes the norm of a vector by translating [Equation
    2-7](#vector-norm) into code. Confirm, using random vectors with different dimensionalities
    and orientations, that you get the same result as `np.linalg.norm()`. This exercise
    is designed to give you more experience with indexing NumPy arrays and translating
    formulas into code; in practice, itâ€™s often easier to use `np.linalg.norm()`.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ªç®—æ³•ï¼Œé€šè¿‡å°†[Equation 2-7](#vector-norm)ç¿»è¯‘æˆä»£ç æ¥è®¡ç®—å‘é‡çš„èŒƒæ•°ã€‚ä½¿ç”¨ä¸åŒç»´åº¦å’Œæ–¹å‘çš„éšæœºå‘é‡æ¥ç¡®è®¤ï¼Œä½ å¾—åˆ°çš„ç»“æœä¸`np.linalg.norm()`ç›¸åŒã€‚è¿™ä¸ªç»ƒä¹ æ—¨åœ¨è®©ä½ æ›´å¤šåœ°ç»ƒä¹ ç´¢å¼•NumPyæ•°ç»„å’Œå°†å…¬å¼è½¬åŒ–ä¸ºä»£ç ï¼›å®é™…ä¸Šï¼Œä½¿ç”¨`np.linalg.norm()`é€šå¸¸æ›´å®¹æ˜“ã€‚
- en: Exercise 2-3\.
  id: totrans-218
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-3ã€‚
- en: Create a Python function that will take a vector as input and output a unit
    vector in the same direction. What happens when you input the zeros vector?
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ›å»ºä¸€ä¸ªPythonå‡½æ•°ï¼Œå°†ä¸€ä¸ªå‘é‡ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸ä¹‹æ–¹å‘ç›¸åŒçš„å•ä½å‘é‡ã€‚å½“ä½ è¾“å…¥é›¶å‘é‡æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ
- en: Exercise 2-4\.
  id: totrans-220
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-4ã€‚
- en: You know how to create *unit* vectors; what if you want to create a vector of
    any arbitrary magnitude? Write a Python function that will take a vector and a
    desired magnitude as inputs and will return a vector in the same direction but
    with a magnitude corresponding to the second input.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ä½ çŸ¥é“å¦‚ä½•åˆ›å»º*å•ä½*å‘é‡ï¼›å¦‚æœä½ æƒ³åˆ›å»ºä»»æ„å¤§å°çš„å‘é‡æ€ä¹ˆåŠï¼Ÿç¼–å†™ä¸€ä¸ªPythonå‡½æ•°ï¼Œå®ƒå°†æ¥å—ä¸€ä¸ªå‘é‡å’Œä¸€ä¸ªæœŸæœ›çš„å¤§å°ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¿”å›ä¸€ä¸ªæ–¹å‘ç›¸åŒä½†å¤§å°å¯¹åº”äºç¬¬äºŒä¸ªè¾“å…¥çš„å‘é‡ã€‚
- en: Exercise 2-5\.
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-5ã€‚
- en: Write a `for` loop to transpose a row vector into a column vector without using
    a built-in function or method such as `np.transpose()` or `v.T`. This exercise
    will help you create and index orientation-endowed vectors.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–å†™ä¸€ä¸ª`for`å¾ªç¯ï¼Œå°†è¡Œå‘é‡è½¬ç½®ä¸ºåˆ—å‘é‡ï¼Œè€Œä¸ä½¿ç”¨å¦‚`np.transpose()`æˆ–`v.T`ç­‰å†…ç½®å‡½æ•°æˆ–æ–¹æ³•ã€‚è¿™ä¸ªç»ƒä¹ å°†å¸®åŠ©ä½ åˆ›å»ºå’Œç´¢å¼•å…·æœ‰æ–¹å‘æ€§çš„å‘é‡ã€‚
- en: Exercise 2-6\.
  id: totrans-224
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-6ã€‚
- en: 'Here is an interesting fact: you can compute the squared norm of a vector as
    the dot product of that vector with itself. Look back to [Equation 2-8](#eq-vecnorm)
    to convince yourself of this equivalence. Then confirm it using Python.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªæœ‰è¶£çš„äº‹å®ï¼šä½ å¯ä»¥è®¡ç®—å‘é‡çš„å¹³æ–¹èŒƒæ•°ï¼Œå°±åƒå°†å‘é‡ä¸è‡ªèº«çš„ç‚¹ç§¯ä¸€æ ·ã€‚å›é¡¾ [æ–¹ç¨‹ 2-8](#eq-vecnorm) ä»¥ç¡®ä¿¡è¿™ä¸¤è€…æ˜¯ç­‰ä»·çš„ã€‚ç„¶åä½¿ç”¨
    Python æ¥ç¡®è®¤å®ƒã€‚
- en: Exercise 2-7\.
  id: totrans-226
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-7ã€‚
- en: Write code to demonstrate that the dot product is *commutative*. Commutative
    means that <math alttext="a times b equals b times a"><mrow><mi>a</mi> <mo>Ã—</mo>
    <mi>b</mi> <mo>=</mo> <mi>b</mi> <mo>Ã—</mo> <mi>a</mi></mrow></math> , which,
    for the vector dot product, means that <math alttext="bold a Superscript upper
    T Baseline bold b equals bold b Superscript upper T Baseline bold a"><mrow><msup><mi>ğš</mi>
    <mtext>T</mtext></msup> <mi>ğ›</mi> <mo>=</mo> <msup><mi>ğ›</mi> <mtext>T</mtext></msup>
    <mi>ğš</mi></mrow></math> . After demonstrating this in code, use equation [Equation
    2-9](#dp-alg) to understand why the dot product is commutative.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–å†™ä»£ç æ¥è¯æ˜ç‚¹ç§¯æ˜¯*å¯äº¤æ¢*çš„ã€‚å¯äº¤æ¢æ„å‘³ç€ <math alttext="a times b equals b times a"><mrow><mi>a</mi>
    <mo>Ã—</mo> <mi>b</mi> <mo>=</mo> <mi>b</mi> <mo>Ã—</mo> <mi>a</mi></mrow></math>
    ï¼Œå¯¹äºå‘é‡çš„ç‚¹ç§¯æ¥è¯´ï¼Œæ„å‘³ç€ <math alttext="bold a Superscript upper T Baseline bold b equals
    bold b Superscript upper T Baseline bold a"><mrow><msup><mi>ğš</mi> <mtext>T</mtext></msup>
    <mi>ğ›</mi> <mo>=</mo> <msup><mi>ğ›</mi> <mtext>T</mtext></msup> <mi>ğš</mi></mrow></math>
    ã€‚åœ¨ç”¨ä»£ç æ¼”ç¤ºåï¼Œä½¿ç”¨æ–¹ç¨‹ [æ–¹ç¨‹ 2-9](#dp-alg) æ¥ç†è§£ç‚¹ç§¯ä¸ºä½•æ˜¯å¯äº¤æ¢çš„ã€‚
- en: Exercise 2-8\.
  id: totrans-228
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-8ã€‚
- en: Write code to produce [FigureÂ 2-6](#fig_2_6). (Note that your solution doesnâ€™t
    need to look *exactly* like the figure, as long as the key elements are present.)
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–å†™ä»£ç ç”Ÿæˆ [å›¾ 2-6](#fig_2_6)ã€‚ (æ³¨æ„ï¼Œä½ çš„è§£å†³æ–¹æ¡ˆä¸éœ€è¦ä¸å›¾å®Œå…¨ç›¸åŒï¼Œåªè¦å…³é”®å…ƒç´ å­˜åœ¨å³å¯ã€‚)
- en: Exercise 2-9\.
  id: totrans-230
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-9ã€‚
- en: Implement orthogonal vector decomposition. Start with two random-number vectors
    <math alttext="bold t"><mi>ğ­</mi></math> and <math alttext="bold r"><mi>ğ«</mi></math>
    , and reproduce [FigureÂ 2-8](#fig_2_8) (note that your plot will look somewhat
    different due to random numbers). Next, confirm that the two components sum to
    <math alttext="bold t"><mi>ğ­</mi></math> and that <math alttext="bold t Subscript
    up-tack bold r"><msub><mi>ğ­</mi> <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub></math>
    and <math alttext="bold t Subscript parallel-to bold r"><msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></math>
    are orthogonal.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: å®ç°æ­£äº¤å‘é‡åˆ†è§£ã€‚ä»ä¸¤ä¸ªéšæœºæ•°å‘é‡ <math alttext="bold t"><mi>ğ­</mi></math> å’Œ <math alttext="bold
    r"><mi>ğ«</mi></math> å¼€å§‹ï¼Œå¹¶é‡ç° [å›¾ 2-8](#fig_2_8)ï¼ˆæ³¨æ„ï¼Œç”±äºéšæœºæ•°çš„åŸå› ï¼Œä½ çš„å›¾çœ‹èµ·æ¥å¯èƒ½æœ‰æ‰€ä¸åŒï¼‰ã€‚æ¥ä¸‹æ¥ï¼Œç¡®è®¤è¿™ä¸¤ä¸ªåˆ†é‡çš„å’Œæ˜¯
    <math alttext="bold t"><mi>ğ­</mi></math> ï¼Œå¹¶ä¸” <math alttext="bold t Subscript up-tack
    bold r"><msub><mi>ğ­</mi> <mrow><mo>âŠ¥</mo><mi>ğ«</mi></mrow></msub></math> å’Œ <math
    alttext="bold t Subscript parallel-to bold r"><msub><mi>ğ­</mi> <mrow><mo>âˆ¥</mo><mi>ğ«</mi></mrow></msub></math>
    æ˜¯æ­£äº¤çš„ã€‚
- en: '![solution to Exercise 2-9](assets/plad_0208.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![ç»ƒä¹  2-9 çš„è§£ç­”](assets/plad_0208.png)'
- en: Figure 2-8\. Exercise 9
  id: totrans-233
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 2-8ã€‚ç»ƒä¹  9ã€‚
- en: Exercise 2-10\.
  id: totrans-234
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  2-10ã€‚
- en: An important skill in coding is finding bugs. Letâ€™s say there is a bug in your
    code such that the denominator in the projection scalar of [Equation 2-13](#find-tParallel)
    is <math alttext="bold t Superscript upper T Baseline bold t"><mrow><msup><mi>ğ­</mi>
    <mtext>T</mtext></msup> <mi>ğ­</mi></mrow></math> instead of <math alttext="bold
    r Superscript upper T Baseline bold r"><mrow><msup><mi>ğ«</mi> <mtext>T</mtext></msup>
    <mi>ğ«</mi></mrow></math> (an easy mistake to make, speaking from personal experience
    while writing this chapter!). Implement this bug to check whether it really deviates
    from the accurate code. What can you do to check whether the result is correct
    or incorrect? (In coding, confirming code with known results is called *sanity-checking*.)
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ç¼–ç¨‹ä¸­çš„ä¸€ä¸ªé‡è¦æŠ€èƒ½æ˜¯æŸ¥æ‰¾é”™è¯¯ã€‚å‡è®¾ä½ çš„ä»£ç ä¸­æœ‰ä¸€ä¸ª bugï¼Œå¯¼è‡´ [æ–¹ç¨‹ 2-13](#find-tParallel) ä¸­çš„æŠ•å½±æ ‡é‡çš„åˆ†æ¯æ˜¯ <math
    alttext="bold t Superscript upper T Baseline bold t"><mrow><msup><mi>ğ­</mi> <mtext>T</mtext></msup>
    <mi>ğ­</mi></mrow></math> è€Œä¸æ˜¯ <math alttext="bold r Superscript upper T Baseline
    bold r"><mrow><msup><mi>ğ«</mi> <mtext>T</mtext></msup> <mi>ğ«</mi></mrow></math>
    ï¼ˆè¿™æ˜¯æˆ‘åœ¨å†™è¿™ä¸€ç« èŠ‚æ—¶ä¸ªäººç»å†çš„ä¸€ä¸ªå®¹æ˜“çŠ¯çš„é”™è¯¯ï¼ï¼‰ã€‚å®ç°è¿™ä¸ª bug æ¥æ£€æŸ¥å®ƒæ˜¯å¦çœŸçš„å¯¼è‡´äº†ä»£ç åç¦»æ­£ç¡®ç»“æœã€‚ä½ å¯ä»¥åšä»€ä¹ˆæ¥ç¡®è®¤ç»“æœæ˜¯æ­£ç¡®çš„è¿˜æ˜¯é”™è¯¯çš„ï¼Ÿï¼ˆåœ¨ç¼–ç¨‹ä¸­ï¼Œç”¨å·²çŸ¥ç»“æœæ¥ç¡®è®¤ä»£ç çš„æ­£ç¡®æ€§è¢«ç§°ä¸º*åˆç†æ£€æŸ¥*ã€‚ï¼‰
- en: ^([1](ch02.xhtml#idm45733300824976-marker)) `a*s` throws an error, because list
    repetition can only be done using integers; itâ€™s not possible to repeat a list
    2.72 times!
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch02.xhtml#idm45733300824976-marker)) `a*s` æŠ›å‡ºä¸€ä¸ªé”™è¯¯ï¼Œå› ä¸ºåˆ—è¡¨é‡å¤åªèƒ½ä½¿ç”¨æ•´æ•°ï¼›ä¸å¯èƒ½å°†åˆ—è¡¨é‡å¤
    2.72 æ¬¡ï¼
- en: ^([2](ch02.xhtml#idm45733308090944-marker)) Python still broadcasts, but the
    result is a 3 Ã— 2 matrix instead of a 2 Ã— 3 matrix.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch02.xhtml#idm45733308090944-marker)) Python ä»ç„¶è¿›è¡Œå¹¿æ’­ï¼Œä½†ç»“æœæ˜¯ä¸€ä¸ª 3 Ã— 2 çš„çŸ©é˜µï¼Œè€Œä¸æ˜¯ä¸€ä¸ª
    2 Ã— 3 çš„çŸ©é˜µã€‚
- en: ^([3](ch02.xhtml#idm45733307857968-marker)) The zeros vector has a length of
    0 but no associated unit vector, because it has no direction and because it is
    impossible to scale the zeros vector to have nonzero length.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch02.xhtml#idm45733307857968-marker)) é›¶å‘é‡çš„é•¿åº¦ä¸º0ï¼Œä½†æ²¡æœ‰ç›¸å…³çš„å•ä½å‘é‡ï¼Œå› ä¸ºå®ƒæ²¡æœ‰æ–¹å‘ï¼Œå¹¶ä¸”ä¸å¯èƒ½å°†é›¶å‘é‡ç¼©æ”¾ä¸ºéé›¶é•¿åº¦ã€‚
- en: ^([4](ch02.xhtml#idm45733308534784-marker)) The error is that the two vectors
    have different dimensionalities, which shows that Hadamard multiplication is defined
    only for two vectors of equal dimensionality. You can fix the problem by removing
    one number from `a` or adding one number to `b`.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch02.xhtml#idm45733308534784-marker)) é”™è¯¯åœ¨äºè¿™ä¸¤ä¸ªå‘é‡çš„ç»´åº¦ä¸åŒï¼Œè¿™è¡¨æ˜å“ˆè¾¾ç›ä¹˜ç§¯ä»…å¯¹ç»´åº¦ç›¸åŒçš„ä¸¤ä¸ªå‘é‡å®šä¹‰ã€‚ä½ å¯ä»¥é€šè¿‡ä»`a`ä¸­ç§»é™¤ä¸€ä¸ªæ•°å­—æˆ–å‘`b`ä¸­æ·»åŠ ä¸€ä¸ªæ•°å­—æ¥ä¿®å¤é—®é¢˜ã€‚
