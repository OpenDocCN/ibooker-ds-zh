- en: 1 Introducing evolutionary deep learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 介绍进化深度学习
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: What evolutionary computation is and how it can be integrated into deep learning
    systems
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进化计算是什么以及它如何集成到深度学习系统中
- en: Applications of evolutionary deep learning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进化深度学习应用
- en: Establishing patterns for optimizing deep learning networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立优化深度学习网络的模式
- en: The role automated machine learning plays in optimizing networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化机器学习在优化网络中所扮演的角色
- en: Applications of evolutionary computational methods to enhance deep learning
    development
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将进化计算方法应用于增强深度学习开发的应用
- en: '*Deep learning* (DL) has become the ubiquitous technology most associated with
    artificial intelligence (AI) and the explosion of machine learning (ML). It has
    grown from being considered a pseudoscience (see *The Deep Learning Revolution*
    by Terrence J. Sejnowski, 2018, MIT Press) to being used in mainstream applications
    for everything from diagnosing breast cancer to driving cars. While many consider
    it a technology of the future, others take a more pragmatic and practical approach
    to its growing complexity and thirst for data.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*深度学习*（DL）已经成为与人工智能（AI）和机器学习（ML）爆炸最相关的普遍技术。它已经从被认为是一种伪科学（参见 Terrence J. Sejnowski
    的《深度学习革命》，2018年，麻省理工学院出版社）发展到被用于从诊断乳腺癌到驾驶汽车的各种主流应用。虽然许多人认为它是一种未来的技术，但其他人则采取更务实和实际的方法来应对其日益增长的复杂性和对数据的需求。'
- en: As DL becomes more complex, we force-feed it more and more data, in the hopes
    of having some grand epiphany in a particular domain. Unfortunately, this is rarely
    the case, and all too frequently, we are left with bad models, poor results, and
    angry bosses. This is a problem that will continue to persist until we develop
    efficient processes for our DL systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习的日益复杂，我们不断地给它喂入更多的数据，希望在某一个特定领域有某种伟大的顿悟。不幸的是，这种情况很少发生，我们经常留下糟糕的模型、糟糕的结果和愤怒的老板。这是一个将持续存在，直到我们开发出高效的深度学习系统流程的问题。
- en: The process of building effective and robust DL systems mirrors—or should mirror—that
    of any other ML or data science (DS) project. While some phases may vary in required
    resources and complexity, all steps will remain the same. What is often lacking
    in the relatively new DL world is a tool belt that can help automate some of those
    processes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 构建有效且健壮的深度学习系统的过程与任何其他机器学习（ML）或数据科学（DS）项目的过程相似——或者应该相似。虽然某些阶段在所需资源和复杂性方面可能有所不同，但所有步骤都将保持不变。在相对较新的深度学习世界中，通常缺乏一个工具包可以帮助自动化这些过程中的某些部分。
- en: Enter *evolutionary deep learning* (EDL). EDL is such a tool belt or set of
    patterns and practices that can help automate the development of a DL system.
    The term *EDL* used in this book encompasses a broad spectrum of evolutionary
    computational methods and patterns applied to various aspects of DL systems across
    the ML process.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 进入 *进化深度学习*（EDL）。EDL 是这样一个工具包或一系列模式和惯例，可以帮助自动化深度学习系统的开发。本书中使用的 *EDL* 术语涵盖了广泛的应用进化计算方法和模式，应用于机器学习过程中深度学习系统的各个方面。
- en: 1.1 What is evolutionary deep learning?
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 什么是进化深度学习？
- en: Evolutionary deep learning, a term first described in this book, is a general
    categorization and grouping of a set of techniques that combine evolutionary methods
    with DL. These methods can be used to optimize a DL system, from the collection
    of data to validation. EDL is not new; tools for combining evolutionary methods
    with DL have gone by many names, including Deep Neural Evolution, Evolutionary
    Neural AutoML, Neuroevolution, Evolutionary AI, and others.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 进化深度学习（EDL），这个术语首次在本书中描述，是对一系列结合进化方法和深度学习的技术的一般分类和分组。这些方法可以用来优化深度学习系统，从数据收集到验证。EDL
    并非新事物；将进化方法与深度学习结合的工具已经有许多名称，包括深度神经网络进化、进化神经网络自动机器学习、神经进化、进化人工智能等。
- en: 'EDL is the merger of two unique subfields of AI: evolutionary computation (EC)
    and the application of DL to automate and improve models. EC itself is a family
    of methods by which biological or natural processes are simulated to solve complex
    problems. That, in turn, can be applied on top of DL to automate and optimize
    solutions but has the potential to uncover new strategies and architectures.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: EDL 是人工智能（AI）两个独特子领域的融合：进化计算（EC）和将深度学习（DL）应用于自动化和改进模型。进化计算本身是一系列方法，通过模拟生物或自然过程来解决复杂问题。反过来，这些方法可以应用于深度学习之上，以自动化和优化解决方案，同时具有发现新策略和架构的潜力。
- en: The broad category of methods we will encompass under EDL is by no means new,
    having been around for over 20 years. While much of that research has shown to
    be successful in auto-tuning DL models, it has received secondary attention behind
    the AI hype of more cutting-edge, handcrafted examples. In many papers, the authors
    discuss the extensive time taken to data or feature engineer and hyperparameter
    tune an innovative model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在EDL下涵盖的广泛方法绝非新颖，它们已经存在了20多年。虽然其中许多研究已经证明在自动调整深度学习模型方面是成功的，但它们在人工智能炒作的更前沿、手工制作的例子之后受到了次要的关注。在许多论文中，作者讨论了进行数据或特征工程以及超参数调整一个创新模型所花费的大量时间。
- en: However, for many now embracing DL, the challenge of building robust, high-performance
    models is daunting and riddled with challenges. Many of these challenges require
    advanced and sophisticated knowledge of all the options and quirks of one’s chosen
    DL framework to understand when the model may just be incorrectly fitting. EDL
    as an automated machine learning (AutoML) solution is presented here to address
    most of the problems practitioners—experienced or novice—will face.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于许多现在正在拥抱深度学习的开发者来说，构建稳健、高性能模型是一个艰巨的挑战，充满了困难。许多这些挑战需要对其选择的深度学习框架的所有选项和怪癖有深入和复杂的知识，以便理解模型可能只是错误地拟合。在这里，我们提出了EDL（进化深度学习）作为自动化机器学习（AutoML）的解决方案，以解决实践者——无论是经验丰富的还是新手——将面临的大部分问题。
- en: EDL’s purpose is to provide a better mechanism and tool set for providing optimizations
    and AutoML for building DL solutions. Evolutionary methods are an excellent and
    relatively easy mechanism to provide a broad set of optimization tools that can
    be applied to DL. While there is potential that evolutionary techniques could
    automate the construction of more advanced AI, that is not the current intent
    of EDL or this book.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: EDL的目的是提供更好的机制和工具集，以提供优化和AutoML，用于构建深度学习解决方案。进化方法是一种优秀且相对简单的机制，可以提供一套广泛的优化工具，这些工具可以应用于深度学习。虽然进化技术有可能自动化更高级人工智能的构建，但这不是EDL或本书的当前意图。
- en: Instead, we focus on building better-optimized networks using evolutionary techniques.
    Before we do that though, we cover the operations and discuss the use of EC and
    evolutionary algorithms (EAs) to get aquatinted with the basic concepts in significant
    depth, starting with a brief introduction to evolution and evolutionary processes
    in the next section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们专注于使用进化技术构建更好的优化网络。在我们这样做之前，我们将介绍操作并讨论使用进化计算（EC）和进化算法（EAs）来深入了解基本概念，下一节将简要介绍进化和进化过程。
- en: 1.1.1 Introducing evolutionary computation
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 介绍进化计算
- en: Evolutionary computation is a subfield of AI that uses biological and naturally
    inspired processes to solve complex problems. The word *evolution* is used to
    describe this family of algorithms, since many use the theory of natural selection
    as a base.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 进化计算是人工智能的一个子领域，它使用生物和自然启发的过程来解决复杂问题。这个词“进化”用来描述这一系列算法，因为许多算法以自然选择理论为基础。
- en: The theory of natural selection, developed by Charles Darwin in his book *On
    the Origin of Species* (1859, John Murray), defined the evolutionary process of
    life on Earth. It describes how the strongest and fittest of life will continue
    to grow, while the weak or ill-equipped will die and become extinct. He developed
    this theory from his experience as a naturalist aboard the *HMS Beagle* as it
    circumvented South America circa 1837\. Darwin, being deeply religious, would
    wrestle with his findings for another 22 years before publishing the famous work.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 查尔斯·达尔文在其著作《物种起源》（1859年，约翰·默里出版社）中提出的自然选择理论，定义了地球上生命的进化过程。它描述了最强壮和最适应的生命将不断增长，而弱小或不适应的生命将死亡并灭绝。他从1837年左右在南美洲环航期间作为自然学家在“贝格尔号”上的经历中发展了这一理论。作为虔诚的宗教徒，达尔文在出版著名的作品之前，又与他的发现斗争了22年。
- en: Based on Darwin’s theory, a cornerstone of EC is the concept of simulating an
    individual or population of individuals in a system to find the best. The purpose
    is to derive or evolve an individual who can survive and thrive in such an artificial
    environment by allowing them to change. This mechanism of an individual’s change
    will vary by EC method, but in all cases, we require a mechanism that quantifies
    how well an individual is surviving.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 基于达尔文的学说，进化计算的一个基石是模拟系统中的个体或个体群体以找到最佳的方法。目的是通过允许它们改变，推导或进化出能够在这样的人工环境中生存和繁荣的个体。这种个体变化的机制将因进化计算方法而异，但在所有情况下，我们都需要一个量化个体生存能力的机制。
- en: The term we use to quantify how well an individual may survive or thrive is
    called *fitness*. This is a universal term used across EC that defines how well
    an individual can survive or perform in an environment. Fitness can be measured
    in a multitude of ways, but in all cases, it is the grand determiner of how efficient
    an individual or population of individuals is at solving a problem.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用来量化个体可能存活或繁荣程度的术语称为**适应度**。这是一个在EC中广泛使用的通用术语，它定义了个体在环境中的生存或表现能力。适应度可以通过多种方式来衡量，但在所有情况下，它都是决定个体或个体群体解决问题效率的终极决定因素。
- en: 'The concepts of natural selection and fitness have been used as the cornerstones
    of several computational methods developed to replicate the biological process
    of reproduction, either loosely or in great depth. Some of these methods even
    simulate the genetic mitosis in cells that takes place during the division of
    chromosomes and sharing of DNA. The following list is a summary of current notable
    EC algorithms:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 自然选择和适应度的概念已被用作构建计算方法的基石，这些方法旨在复制生物繁殖过程，无论是粗略地还是深入地。其中一些方法甚至模拟了细胞在染色体分裂和DNA共享过程中发生的遗传有丝分裂。以下列表是当前一些显著的EC算法的总结：
- en: '*Artificial life*—Going back as far as Conway’s Game of Life and the Von Neumann
    cellular automaton, these processes simulate the artificial process of life itself,
    using agents. In this algorithm, agents often move, flow, live, or die based on
    their proximity to other agents or environments. While agent simulation is often
    done to mimic the real world, it can also be used to optimize processes.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工生命**——从康威的生命游戏和冯·诺伊曼的细胞自动机回溯，这些过程通过代理模拟了生命本身的模拟过程。在这个算法中，代理通常根据它们与其他代理或环境的接近程度移动、流动、生存或死亡。虽然代理模拟通常用于模拟现实世界，但它也可以用于优化过程。'
- en: '*Differential evolution*—A process in which search is optimized by combining
    differential calculus with evolutionary algorithms. This technique will often
    be layered in with another EC method, like artificial life. In this algorithm,
    agents evolve or change by taking the vector differences and reapplying them to
    the population.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**差分进化**——一个将微分计算与进化算法相结合以优化搜索的过程。这种技术通常与其他EC方法，如人工生命，结合使用。在这个算法中，代理通过取向量差异并将其重新应用于群体来进化或改变。'
- en: '*Evolutionary algorithms*—A broader category of EC methods that apply evolution,
    in the form of natural selection, to a problem. These methods often focus on simulating
    a population of individuals.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进化算法**——一个更广泛的EC方法类别，它将自然选择的形式应用于问题。这些方法通常侧重于模拟个体群体。'
- en: '*Evolutionary programming*—A specialized form of evolutionary algorithms that
    create algorithms using code. In this algorithm, an individual is represented
    by a block of code, and its respective fitness is measured to some optimal value
    generated by running the code. There are several ways of implementing code generation
    for EP, and in many cases, we will defer to more specific methods, like gene expression.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进化编程**——一种使用代码创建算法的专门进化算法形式。在这个算法中，个体由一段代码表示，其相应的适应度通过运行代码产生的某个最优值来衡量。EP的代码生成有几种实现方式，在许多情况下，我们将依赖于更具体的方法，如基因表达。'
- en: '*Genetic algorithm*—This algorithm uses the low-level cellular mitosis we see
    in organisms that allows for the passing of genetic traits to offspring. A genetic
    algorithm (GA) is the simulation of this process by encoding an individual’s characteristics
    into a gene sequence, where this arbitrary gene sequence, which could be as simple
    as a sequence of 0s or 1s, evaluates to some fitness metric. That fitness is used
    to simulate the biological selection process and mating of parent individuals
    to produce new combined offspring.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遗传算法**——这个算法使用我们在生物体中看到的低级细胞有丝分裂，允许将遗传特征传递给后代。遗传算法（GA）是通过将个体的特征编码到基因序列中来模拟这个过程，这个任意的基因序列可能只是一个0s或1s的序列，它评估为某个适应度指标。这个适应度用于模拟生物选择过程和父代个体的交配，以产生新的结合后代。'
- en: '*Genetic programming*—This algorithm builds programming code using GA. In GA,
    an individual’s traits are more generic, but in genetic programming (GP), a trait
    or gene could represent any number of functions or other code logic. GP is a specialized
    technique that allows new algorithmic code to be developed. Examples of this have
    been used to write agent simulation code that could solve a maze or create pictures.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*遗传编程*—这个算法使用遗传算法（GA）构建编程代码。在GA中，个体的特征更为通用，但在遗传编程（GP）中，一个特征或基因可以代表任意数量的函数或其他代码逻辑。GP是一种专门的技术，允许开发新的算法代码。这种技术的例子已被用于编写能够解决迷宫或创建图片的代理模拟代码。'
- en: '*Gene expression programming*—This algorithm is a further extension of genetic
    programming that develops code or mathematical functions. With GP, code is abstracted
    to high-level functions, whereas in gene expression programming (GEP), the purpose
    is to develop specific mathematical equations. A key difference between GEP and
    GP is the use of expression trees to represent functions. While in GP, expression
    trees represent code, in GEP expressions, they represent a mathematical expression
    tree. The benefit is that the code will follow a well-defined order of operations
    based on placement.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基因表达式编程*—这个算法是遗传编程的进一步扩展，用于开发代码或数学函数。在遗传编程（GP）中，代码被抽象为高级函数，而在基因表达式编程（GEP）中，目的是开发特定的数学方程。GEP与GP之间的一个关键区别是使用表达式树来表示函数。在GP中，表达式树表示代码，而在GEP中，表达式表示一个数学表达式树。其好处是代码将遵循基于位置的运算顺序。'
- en: '*Particle swarm optimization*—This falls under a subset of artificial life
    and is the simulation of artificial and somewhat-smart particles. In this algorithm,
    each particle’s fitness is evaluated, and the best particle becomes the focus
    for the remaining particles to swarm around.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*粒子群优化*—这属于人工生命的一个子集，是对人工和相对智能粒子的模拟。在这个算法中，评估每个粒子的适应性，最好的粒子成为剩余粒子围绕其群聚的焦点。'
- en: '*Swarm intelligence*—This algorithm is a search method that simulates the behavior
    of swarm insects or birds to find peak values for optimization problems. It is
    very similar to particle swarm optimization (PSO) but varies in implementation,
    depending on the evaluation of fitness.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*群体智能*—这个算法是一种搜索方法，模拟群体昆虫或鸟类的行为以找到优化问题的峰值。它与粒子群优化（PSO）非常相似，但在实现上有所不同，这取决于适应性评估。'
- en: Figure 1.1 shows a hierarchy of EC methods used throughout this book for the
    application of EDL. Several other methods of EC could be used to improve DL models,
    but as an introduction, we will cover the basic methods in the figure, focusing
    on the areas of life and genetic simulation.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1显示了本书中用于应用EDL的EC方法层次结构。还可以使用其他EC方法来改进深度学习模型，但作为介绍，我们将涵盖图中的基本方法，重点关注生命和遗传模拟领域。
- en: '![](../Images/CH01_F01_Lanham.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F01_Lanham.png)'
- en: Figure 1.1 Subset of EC used to apply EDL
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 用于应用EDL的EC子集
- en: Life simulation is a specific subset of EC that takes an approach to simulate
    observed natural processes we see in nature, such as the way particles or birds
    swarm. Genetic simulation, on the other hand, mimics the process of cellular mitosis
    we observe in biological life. More specifically, it simulates the genetic transference
    of genes and chromosomes through an organism’s evolution.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 生命模拟是进化计算（EC）的一个特定子集，它采用了一种模拟我们在自然界中观察到的自然过程的方法，例如粒子或鸟类的群聚方式。另一方面，遗传模拟模仿我们在生物生命中观察到的细胞有丝分裂过程。更具体地说，它模拟了基因和染色体通过生物体的进化进行遗传转移。
- en: 1.2 The why and where of evolutionary deep learning
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 进化深度学习的为什么和在哪里
- en: Evolutionary deep learning is as much a concept as a set of tools and techniques
    for DL optimization. Conceptually, EDL is the pattern and practice of employing
    EC for the optimization of DL networks. Yet it also presents a set of tools that
    can be layered on top of DL—or even act as a replacement for DL.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 进化深度学习（EDL）既是一个概念，也是一组用于深度学习优化（DL）的工具和技术。从概念上讲，EDL是使用进化计算（EC）来优化深度学习网络的模式和惯例。然而，它也提供了一套可以叠加在深度学习之上或甚至作为深度学习替代品的工具。
- en: Why and where you would use EDL depends on not only your level of expertise
    in DL but also your need to push the limits. That doesn’t mean novices of DL could
    not benefit from using EDL. Indeed, this book explores many nuances of neural
    networks that are exposed with EDL and can be of benefit to any practitioner.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么以及在哪里使用EDL不仅取决于你在深度学习（DL）方面的专业知识水平，还取决于你推动极限的需求。这并不意味着深度学习的新手不能从使用EDL中受益。实际上，这本书探讨了使用EDL暴露出的许多神经网络细微差别，这些差别对任何从业者都有益。
- en: 'The answer to where EDL can be used is simple: anywhere. It can be used for
    basic hyperparameter optimization, neural weight search for discontinuous solutions,
    balancing adversarial networks in generative adversarial networks, and even replacing
    deep reinforcement learning. You really can apply the techniques presented in
    this book to any DL system.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: EDL 可以使用的答案很简单：任何地方。它可以用于基本的超参数优化、神经权重搜索以解决不连续的解决方案、平衡生成对抗网络中的对抗网络，甚至可以替代深度强化学习。你真的可以将本书中介绍的技术应用到任何深度学习系统中。
- en: Answering the *why* of EDL comes down to necessity. Evolutionary methods provide
    an option for further optimization or enhanced solution to any DL system. Yet
    EDL is computationally intensive and may not be appropriate for simpler systems.
    However, for complex or novel problems, evolution presents a new bag of tricks
    to any DL practitioner.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 回答 EDL 的 *为什么* 的问题归结为必要性。进化方法为任何深度学习系统提供了进一步优化或改进解决方案的选项。然而，EDL 计算密集，可能不适合简单的系统。但是，对于复杂或新颖的问题，进化为任何深度学习从业者提供了一套新的技巧。
- en: 1.3 The need for deep learning optimization
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 深度学习优化的必要性
- en: DL is a powerful, yet somewhat new and oft-misunderstood, technology that provides
    a plethora of benefits as well as downsides. One such downside is the requirement
    to understand and optimize a model. This is a process that may require hours of
    data annotation or model hyperparameter tuning.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是一种强大、但相对较新且常被误解的技术，它提供了众多好处以及一些缺点。其中一个缺点是需要理解和优化模型。这是一个可能需要数小时数据标注或模型超参数调整的过程。
- en: In almost all cases, we can never use a model directly out of the box, and we
    often need to optimize various aspects of the DL system, from tuning the learning
    rate to choosing the activation function. Optimizing a network model often becomes
    the primary exercise, and if done manually, this can take some substantial effort.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在几乎所有情况下，我们无法直接使用现成的模型，我们通常需要优化深度学习系统的各个方面，从调整学习率到选择激活函数。优化网络模型通常成为主要练习，如果手动进行，这可能需要相当大的努力。
- en: Optimizing a DL network can encompass a wide variety of factors. Aside from
    the usual hyperparameter tuning, we also need to look at the network architecture
    itself.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 优化深度学习网络可以包括广泛的因素。除了通常的超参数调整之外，我们还需要考虑网络架构本身。
- en: 1.3.1 Optimizing the network architecture
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3.1 优化网络架构
- en: As a network becomes more sophisticated with the addition of layers or various
    node types, it directly affects how the loss/error is backpropagated through it.
    Figure 1.2 demonstrates the most common problems encountered when growing more
    complex and larger DL systems.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 随着网络通过添加层或各种节点类型而变得更加复杂，它直接影响了损失/误差如何通过它反向传播。图 1.2 展示了在增长更复杂和更大的深度学习系统时遇到的最常见问题。
- en: '![](../Images/CH01_F02_Lanham.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F02_Lanham.png)'
- en: Figure 1.2 Common problems when growing DL systems
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 增长深度学习系统时常见的问题
- en: In larger networks, the amount of loss needs to be divided into smaller and
    smaller components that eventually approach zero. When these loss components or
    gradients approach zero, we call it a *vanishing gradient problem*, which is often
    associated with deep networks. Conversely, components may also get exceptionally
    large by passing through successive layers that magnify those input signals. This
    results in gradient components getting large, or what are called *exploding gradients*.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在更大的网络中，损失量需要分成越来越小的组件，最终接近零。当这些损失组件或梯度接近零时，我们称之为 *梯度消失问题*，这通常与深度网络相关。相反，组件也可能通过逐层传递而变得异常大，这些层放大了输入信号。这导致梯度组件变得很大，或者称为
    *梯度爆炸*。
- en: Both gradient problems can be resolved using various techniques, like normalizing
    input data and, again, through the layers. Special types of layer functions called
    *normalization* and *dropout* are shown in figure 1.2\. These techniques add to
    the computational complexity and requirements for the network and may also overtly
    smooth over important and characteristic features in data. Thus, larger and more
    diverse training datasets are required to develop good network performance.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种梯度问题都可以使用各种技术来解决，例如标准化输入数据和，再次通过层。图 1.2 中展示了称为 *标准化* 和 *dropout* 的特殊层函数。这些技术增加了网络的计算复杂性和要求，也可能过分平滑数据中的重要和特征性特征。因此，需要更大的和多样化的训练数据集来开发良好的网络性能。
- en: Normalization may solve the vanishing and exploding gradient problems of deep
    networks, but as models grow, these manifest other concerns. As they grow, models’
    ability to digest larger sets of input and images, for example, increases. However,
    this may cause a side effect known as *network memorization*, which can occur
    if the input training set is too small. This occurs because the network is so
    large that it may start to memorize sets of input chunks or even whole images
    or sets of text.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化可以解决深层网络的梯度消失和爆炸问题，但随着模型的增长，这些会引发其他担忧。随着模型的增长，模型处理更大输入集和图像的能力增加。然而，这可能导致称为*网络记忆*的副作用，如果输入训练集太小，就会发生这种情况。这是因为网络如此之大，它可能开始记忆输入块集或甚至整个图像或文本集。
- en: The cutting-edge DL models you may have heard about, like the GPT-3, a natural
    language processor from OpenAI, suffer in part from memorization. This problem
    comes up even after billions of documents representing multiple forms of text
    have been fed into such models. Even with such diverse and massive training sets,
    models like GPT-3 have been shown to replay whole paragraphs of remembered text.
    This “problem” may be an effective feature for a database that doesn’t fit well
    into a DL model.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过的尖端深度学习模型，如来自OpenAI的自然语言处理器GPT-3，部分受到记忆问题的困扰。即使向这些模型输入了代表多种文本形式的数十亿份文档，这个问题仍然存在。即使拥有如此多样化和庞大的训练集，GPT-3之类的模型也已被证明会重放记忆中的整段文本。这个问题可能是一个对不适合深度学习模型的数据库来说有效的特征。
- en: There have been workarounds developed for the memorization problem called *dropout*,
    a process by which a certain percentage of the nodes within network layers may
    be deactivated through each training pass. As a result of turning nodes off and
    on within each pass, a more general network is created. This, however, is at the
    cost of requiring the network to now be 100% to 200% larger.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 已经开发出了一些针对称为*dropout*的记忆问题的解决方案，这是一个通过在每个训练过程中关闭网络层中一定比例的节点的过程。通过在每个过程中开关节点，创建了一个更通用的网络。然而，这需要网络现在变得100%到200%更大。
- en: On top of these problems, the addition of more layers to deeper networks adds
    more weights—weights that need to be individually trained over billions and trillions
    of iterations. Exponential growth in computational power is required to train
    such models, and many of the top, cutting-edge models are now only developed within
    organizations that can afford this high cost.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些问题之上，向更深层的网络添加更多层会增加更多权重——这些权重需要在数十亿到数万亿次的迭代中单独训练。训练此类模型需要指数级增长的计算能力，许多顶级、尖端模型现在仅由能够承担这种高成本的组织开发。
- en: Many see the trend of wider and deeper networks soon reaching a plateau for
    most DL practitioners, leaving any future cutting-edge development to the AI giants,
    like Google DeepMind. The simple solution is to, therefore, look at alternative
    approaches that can streamline the development of such large networks. This is
    where we come back to applying EC to DL to optimize the network architecture,
    weights, or both.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人认为更宽、更深的网络趋势很快就会达到大多数深度学习实践者的平台期，将未来的尖端发展留给像Google DeepMind这样的AI巨头。因此，简单的解决方案是考虑其他可以简化如此大型网络开发的替代方法。这就是我们回到应用EC于DL以优化网络架构、权重或两者都优化的时候了。
- en: Fortunately, EDL provides several potential methods, in that it can automatically
    optimize the size and form of a network for a variety of problems we will look
    at in this book. Automatic optimization is a cornerstone of EDL and will be a
    focus of many exercises demonstrating these techniques in this book.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，EDL提供了几种潜在的方法，因为它可以自动优化我们将在本书中探讨的各种问题的网络大小和形式。自动优化是EDL的基石，并将成为本书中许多练习的重点，这些练习展示了这些技术。
- en: Since evolutionary algorithms provide for several optimization patterns that
    can solve a multitude of problems, EDL can work across various aspects of the
    ML development process. These include tuning model hyperparameters to data or
    feature engineering, model validation, model selection, and architecture.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于进化算法提供了多种优化模式，可以解决众多问题，因此EDL可以在机器学习开发过程的各个方面发挥作用。这包括调整模型超参数以适应数据或特征工程、模型验证、模型选择和架构。
- en: 1.4 Automating optimization with automated machine learning
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 使用自动机器学习自动化优化
- en: EDL provides a set of tools to help automate the optimization of DL systems
    for more robust models. As such, it should be considered an AutoML tool. Many
    commercial AutoML platforms, such as Google AutoML, use various evolutionary methods
    to develop models.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: EDL提供了一套工具，以帮助自动化深度学习系统的优化，以创建更稳健的模型。因此，它应被视为一个AutoML工具。许多商业AutoML平台，如Google
    AutoML，使用各种进化方法来开发模型。
- en: Before we continue, we also need to discuss the branding or misnaming of the
    terms *automated machine learning* and *AutoML*. In this book, we will interchange
    between using *AML* and *AutoML*; they are often considered the same, and for
    our purposes, they are. However, AML and AutoML may be considered different in
    that the former is often used to describe a black box system that produces optimized
    models.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，我们还需要讨论术语*自动化机器学习*和*AutoML*的品牌或误命名问题。在这本书中，我们将交替使用*AML*和*AutoML*；它们通常被认为是相同的，并且就我们的目的而言，它们是相同的。然而，AML和AutoML可能被认为是不同的，因为前者通常用来描述一个产生优化模型的黑盒系统。
- en: Automating the optimization and development of any AI/ML model is considered
    the next step in the development process for any research and development project.
    It is the evolution of moving beyond research and development and formalizing
    the model-building process, which allows practitioners to take models into full-scale
    commercialization and productization.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化任何AI/ML模型的优化和开发被认为是任何研究和发展项目开发过程中的下一步。它是超越研究和开发并正式化模型构建过程的演变，这使得从业者可以将模型带入全面商业化和产品化。
- en: 1.4.1 What is automated machine learning?
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.1 什么是自动化机器学习？
- en: Automated machine learning, or AutoML, is a tool or set of tools used to automate
    and enhance the building of AI/ML. It is not a specific technology but a collection
    of methods and strategies in which evolutionary algorithms or evolutionary optimization
    methods would be considered a subset. It is a tool that can be used throughout
    the AI/ML workflow, as depicted in figure 1.3.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化机器学习，或AutoML，是一套用于自动化和增强AI/ML构建的工具或工具集。它不是一个特定的技术，而是一系列方法，其中进化算法或进化优化方法被视为一个子集。它是一个可以在AI/ML工作流程的任何阶段使用的工具，如图1.3所示。
- en: '![](../Images/CH01_F03_Lanham.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F03_Lanham.png)'
- en: Figure 1.3 Steps for developing a good AI/ML model with AutoML and/or EDL
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 使用AutoML和/或EDL开发良好AI/ML模型的步骤
- en: AutoML tools
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML工具
- en: 'The following is a list of tools and platforms that provide AutoML:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个提供AutoML的工具和平台列表：
- en: '*DataRobot*—Seen as the first platform and starting point of AutoML, DataRobot
    provides a diverse set of tools to auto-build models.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DataRobot*—被视为AutoML的第一个平台和起点，DataRobot提供了一套用于自动构建模型的多样化工具。'
- en: '*Google Cloud AutoML*—This popular and robust platform is from the current
    main player in AI. This platform handles a diverse set of data, from images to
    structured data.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Google Cloud AutoML*—这是一个由当前人工智能领域的领军企业推出的流行且稳健的平台。该平台处理各种类型的数据，从图像到结构化数据。'
- en: '*Amazon SageMaker AutoPilo*t—This powerful platform is good for automating
    development models dependent on structured data.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Amazon SageMaker AutoPilot*—这个强大的平台非常适合自动化依赖于结构化数据的模型开发。'
- en: '*H2O AutoML*—This tool provides various functions to automate the machine learning
    workflow.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*H2O AutoML*—这个工具提供了各种自动化机器学习工作流程的功能。'
- en: '*Azure Machine Learning*—This platform provides automated processes of tuning
    models on diverse forms of data.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Azure Machine Learning*—这个平台提供了对各种形式数据的模型调优的自动化流程。'
- en: '*AutoKeras*—This excellent tool provides automated development of network architecture.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AutoKeras*—这个出色的工具提供了自动开发网络架构的功能。'
- en: '*AutoTorch*—This tool provides automatic architecture search.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AutoTorch*—这个工具提供了自动架构搜索的功能。'
- en: Many other tools and platforms are available, beyond the scope of this list.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 许多其他工具和平台都可用，但超出了这个列表的范围。
- en: 'Figure 1.3 depicts the typical AI/ML workflow for building a good model to
    be used for confident inference of new data. This workflow is often undertaken
    manually by various practitioners of AI/ML, but there have been various attempts
    to automate all steps. The following is a summary of each of these steps in greater
    detail, including how they may be automated with AML:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3展示了用于构建用于对新数据进行自信推断的良好模型的典型AI/ML工作流程。这个工作流程通常由各种AI/ML从业者手动执行，但已经尝试自动化所有步骤。以下是对这些步骤的更详细总结，包括它们如何通过AML进行自动化：
- en: '*Data preparation*—Preparing data for AI/ML training is time-consuming and
    expensive. In general, preparing data and automating this task can dramatically
    increase the performance of data workflows critical for fine-tuning complex models.
    AutoML online services often assume the user has already prepared and cleaned
    data, as required by most ML models. With evolutionary methods, there are several
    ways to automate the preparation of data, and while this task is not specific
    to EDL, we will cover it in later chapters.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据准备*—为人工智能/机器学习训练准备数据既耗时又昂贵。一般来说，准备数据和自动化这一任务可以显著提高对微调复杂模型至关重要的数据工作流程的性能。AutoML在线服务通常假设用户已经根据大多数机器学习模型的要求准备和清理了数据。使用进化方法，有几种自动化数据准备的方法，尽管这项任务并非特定于EDL，我们将在后面的章节中介绍它。'
- en: '*Feature engineering*—This is the process of extracting relevant features in
    data using prior domain knowledge, with experts selecting relevant features based
    on their intuition and experience. Since domain experts are expensive and opinionated,
    automating this task reduces costs and improves standardization. Depending on
    the AutoML tool, feature engineering may be included in the process.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征工程*—这是使用先前的领域知识从数据中提取相关特征的过程，专家根据他们的直觉和经验选择相关特征。由于领域专家昂贵且固执己见，自动化这一任务可以降低成本并提高标准化。根据AutoML工具的不同，特征工程可能包含在过程中。'
- en: '*Model selection*—As AI/ML has advanced, hundreds of model types that can solve
    similar problems have been created. Often, data scientists will spend days or
    weeks just selecting a group of models to further evaluate. Automating this process
    speeds up model development and helps the data scientist affirm they are using
    the right model for the job. A good AutoML tool may choose from dozens or hundreds
    of models, including DL variations or model ensembles.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型选择*—随着人工智能/机器学习的进步，已经创建了数百种可以解决类似问题的模型类型。通常，数据科学家会花费几天或几周的时间来选择一组模型以进行进一步评估。自动化这一过程可以加快模型开发，并帮助数据科学家确认他们正在使用适合工作的正确模型。一个好的AutoML工具可以从数十或数百个模型中进行选择，包括深度学习变体或模型集成。'
- en: '*Model architecture*—Depending on the area of AI/ML and deep learning, defining
    the right model architecture is often critical. Getting this right in an automated
    way alleviates countless hours of tuning architecture and rerunning models. Depending
    on the implementation, some AutoML systems vary in model architecture, but this
    is typically limited to well-known variations.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型架构*—根据人工智能/机器学习和深度学习领域，定义正确的模型架构通常至关重要。以自动化的方式正确完成这一点可以减轻无数小时的架构调整和模型重新运行的工作。根据实现方式，一些AutoML系统在模型架构上有所不同，但这通常仅限于众所周知的变体。'
- en: '*Hyperparameter optimization*—The process of fine-tuning a model’s hyperparameters
    can be time-consuming and prone to errors. To overcome these problems, many practitioners
    rely on intuition and previous experience. While this has been successful in the
    past, increasing model complexity now makes this task untenable. By automating
    HP tuning, we not only alleviate work from the builders, but we also uncover potential
    flaws in the model selection or architecture.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*超参数优化*—微调模型超参数的过程可能耗时且容易出错。为了克服这些问题，许多从业者依赖直觉和以往的经验。虽然这在过去是成功的，但随着模型复杂性的增加，这项任务变得难以承受。通过自动化HP调整，我们不仅减轻了构建者的工作负担，还揭示了模型选择或架构中可能存在的潜在缺陷。'
- en: '*Validation selection*—There are many options for evaluating the performance
    of a model, from deciding on how much data to use for training and testing to
    visualizing the output performance of a model. Automating the validation of a
    model provides a robust means of recharacterizing model performance when data
    changes and makes a model more explainable long-term. For online AutoML services,
    this is a key strength that provides a compelling reason to employ such tools.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*验证选择*—评估模型性能有许多选项，从决定用于训练和测试的数据量到可视化模型的输出性能。自动化模型的验证提供了一种稳健的方法，在数据变化时重新表征模型性能，并使模型长期更具可解释性。对于在线AutoML服务，这是关键优势之一，为采用此类工具提供了令人信服的理由。'
- en: The typical AML/AutoML workflow only attempts to tackle the feature engineering
    step and beyond, where the process is often done iteratively, either over a single
    step or multiple steps combined. Some steps, like hyperparameter tuning, are specific
    to model type and, in the case of DL, could require significant time to optimize
    the model.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的自动化机器学习（AML）/自动化机器学习（AutoML）工作流程仅尝试解决特征工程步骤及其之后的步骤，这个过程通常是迭代进行的，无论是单个步骤还是多个步骤的组合。一些步骤，如超参数调整，是特定于模型类型的，在深度学习（DL）的情况下，可能需要大量时间来优化模型。
- en: While this new wave of commercial AutoML service is successful in processing
    a wide variety of data types and forms, the produced models lack innovation and
    can be quite expensive. It takes a substantial amount of computing power to crunch
    through all the tasks AutoML needs to perform to build a tuned model, and the
    models developed are essentially reconstructions of previous-generation benchmarks
    and often lack any novel insight into optimization.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这股新的商业自动化机器学习（AutoML）服务浪潮在处理各种数据类型和形式方面取得了成功，但产生的模型缺乏创新，并且可能相当昂贵。构建调整后的模型需要大量的计算能力来处理自动化机器学习（AutoML）需要执行的所有任务，而这些开发出的模型基本上是前一代基准的重建，并且通常缺乏对优化的任何新颖见解。
- en: Those AI/ML practitioners wanting more innovative automated models on a budget
    often turn to developing their AutoML solutions, with EDL being a prime candidate.
    As we will see in later chapters of this book, evolutionary methods can provide
    a wide variety of solutions to auto-building and optimizing DL models, hyperparameters,
    feature engineering, and network architecture.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 那些希望以预算获得更多创新自动化模型的AI/ML从业者通常会转向开发他们的自动化机器学习（AutoML）解决方案，进化深度学习（EDL）是一个主要候选者。正如我们将在本书的后续章节中看到的那样，进化方法可以为自动构建和优化深度学习（DL）模型、超参数、特征工程和网络架构提供各种各样的解决方案。
- en: 1.5 Applications of evolutionary deep learning
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 进化深度学习的应用
- en: Now that we understand *why* we would need to combine EC and DL into an AutoML
    solution, we can move on to *how*. That is, how can we apply methods like GAs
    on top of DL to improve working AI solutions? There are likely countless possibilities
    that would allow for EC to be merged with DL, but in this book, we will stick
    to some basic practical strategies.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经理解了为什么需要将进化计算（EC）和深度学习（DL）结合到自动化机器学习（AutoML）解决方案中，我们就可以继续探讨如何实现。也就是说，我们如何将遗传算法（GAs）等方法应用于深度学习（DL）之上以改进现有的AI解决方案？可能存在无数种可能性，允许将进化计算（EC）与深度学习（DL）合并，但在这本书中，我们将坚持一些基本的实用策略。
- en: Understanding these strategies will allow you to alter existing DL networks
    or create new combined EC/DL models of your own. This will allow you to create
    cutting-edge optimized networks in a shorter amount of time and with fewer resources,
    providing you the ability to pick and choose strategies or even develop new ones
    as your experience progresses.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这些策略将使您能够修改现有的深度学习（DL）网络或创建您自己的结合进化计算（EC）/深度学习（DL）的模型。这将使您能够在更短的时间内和更少的资源下创建尖端优化的网络，并赋予您选择和选择策略甚至随着经验增长开发新策略的能力。
- en: To accomplish such lofty goals, we will explore the fundamentals of both DL
    and a specific subset of EC from the ground up. We will build basic models to
    solve problems with both subfields, and then in later chapters, we will look at
    how we may combine them for improved performance and automation.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现如此宏伟的目标，我们将从深度学习（DL）和进化计算（EC）的一个特定子集的基础知识开始探索。我们将构建基本模型来解决这两个子领域的问题，然后在后面的章节中，我们将探讨如何将它们结合起来以实现更好的性能和自动化。
- en: EC can be applied to DL in several forms to cover various automated strategies
    wrapped in AutoML. Figure 1.4 demonstrates the various subsets of EC or EDL that
    can be applied to DL and where they may be applied across the AI/ML model development
    workflow.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 进化计算（EC）可以以几种形式应用于深度学习（DL），以涵盖自动化机器学习（AutoML）中包裹的各种自动化策略。图1.4展示了可以应用于深度学习（DL）的进化计算（EC）或进化深度学习（EDL）的各个子集，以及它们在AI/ML模型开发工作流程中可能的应用位置。
- en: '![](../Images/CH01_F04_Lanham.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F04_Lanham.png)'
- en: Figure 1.4 Applying EC (EDL) to the AI/ML model development workflow for DL
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 将进化计算（EDL）应用于深度学习（DL）的AI/ML模型开发工作流程
- en: '1.5.1 Model selection: Weight search'
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.1 模型选择：权重搜索
- en: As previously mentioned, the selected base model and layer types will often
    be dictated by the type of problem being solved. In most cases, optimizing the
    model selection can be done quickly and manually. However, model selection is
    not just about selecting the type of layers; it can also include the form of optimization,
    starting weights, and loss used to train a model.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，所选的基础模型和层类型通常由要解决的问题类型决定。在大多数情况下，模型选择优化可以快速手动完成。然而，模型选择不仅仅是选择层类型；它还可以包括优化形式、起始权重以及用于训练模型的损失。
- en: By optimizing the model layer types, optimization mechanism, and even forms
    of loss, a network can be made more robust to learn more efficiently. We will
    look at examples where initial mode weights, types of optimizations, and measures
    of loss are tuned to fit a variety of problems.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过优化模型层类型、优化机制甚至损失形式，可以使网络更鲁棒，从而更有效地学习。我们将探讨一些示例，其中初始模型权重、优化类型和损失度量被调整以适应各种问题。
- en: '1.5.2 Model architecture: Architecture optimization'
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.2 模型架构：架构优化
- en: Many times, when building DL networks, we often oversize the model or number
    of nodes and layers in a model. Then over time, we will scale the network back,
    so it becomes more optimal for the problem. In many cases, having too large of
    a network can result in the memorization of input data, resulting in overfitting.
    Conversely, a network that is too small to learn the variety and amount of data
    will typically suffer from underfitting.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 许多时候，在构建深度学习网络时，我们常常会过度设计模型或模型中的节点和层数量。随着时间的推移，我们会将网络规模缩小，使其更适合问题。在许多情况下，网络过大可能会导致对输入数据的记忆化，从而引起过拟合。相反，如果网络太小，无法学习数据的多样性和数量，通常会导致欠拟合。
- en: To resolve over- and underfitting problems, we can apply GA to automatically
    prune a network to its lowest form. This not only improves model performance and
    limits over- or undertraining, but it also decreases training times by decreasing
    the network size. This is a technique that works well when trying to optimize
    larger, deeper networks.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决过拟合和欠拟合问题，我们可以应用遗传算法自动修剪网络到其最低形式。这不仅提高了模型性能并限制了过拟合或欠拟合，而且通过减小网络规模减少了训练时间。这是一种在尝试优化更大、更深网络时效果很好的技术。
- en: 1.5.3 Hyperparameter tuning/optimization
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.3 超参数调整/优化
- en: '*Hyperparameter* *tuning* is a process we undertake in AI and ML that requires
    the optimization of a model by tweaking the various control variables that define
    it. In DL, parameters are used to denote the weights of the model; we differentiate
    between them by calling the control variables *hyperparameters*.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '*超参数* *调整* 是我们在人工智能和机器学习中所进行的过程，需要通过调整定义模型的各个控制变量来优化模型。在深度学习中，参数用于表示模型的权重；我们通过称控制变量为*超参数*来区分它们。'
- en: EC provides several alternative measures to add automatic HP optimization across
    a wide variety of models, including DL. Particle swarm optimization, differential
    evolution, and genetic algorithms have all been used with success. Each of these
    methods will be explored across a variety of frameworks to measure performance.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: EC提供了几种替代措施，以在广泛的模型中添加自动超参数优化，包括深度学习。粒子群优化、微分进化以及遗传算法都已被成功应用。这些方法中的每一种都将被探索，以在各种框架中衡量性能。
- en: 1.5.4 Validation and loss function optimization
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.4 验证和损失函数优化
- en: When developing robust DL models, we often rely on several established patterns
    to generate quality networks. This may include validating a model’s training and
    performance by reviewing training and test loss iteratively. We want to make sure
    both measures of loss don’t diverge too far from one another.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发鲁棒的深度学习模型时，我们通常依赖于几种已建立的模式来生成高质量的网络。这可能包括通过迭代地审查训练和测试损失来验证模型的训练和性能。我们希望确保损失的两个度量指标不要相差太远。
- en: In a typical supervised learning training scenario, we will often use established
    measures that align with label comparisons. With more advanced generative DL scenarios,
    opportunities to optimize the form of loss and even measures of validation become
    available.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型的监督学习训练场景中，我们通常会使用与标签比较相一致的标准度量。在更高级的生成式深度学习场景中，优化损失形式甚至验证度量的机会变得可用。
- en: Network architectures like autoencoders, embedding layers, and generative adversarial
    networks provide the opportunity to employ combinatory determinations of loss
    and model validation. Using EC, we can use methods to optimize these forms of
    networks in an AutoML manner.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如自动编码器、嵌入层和生成对抗网络等网络架构提供了应用组合损失和模型验证的机会。使用EC，我们可以使用方法以AutoML的方式优化这些网络形式。
- en: 1.5.5 Neuroevolution of augmenting topologies
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.5 增强拓扑的神经进化
- en: '*Neuroevolution* *of augmenting topologies* (NEAT) is a technique that combines
    hyperparameter and architecture optimization with weight search to automatically
    build new DL models that may also develop their method of loss and validation.
    While NEAT was developed almost 20 years ago, it wasn’t until fairly recently
    that this technique has been applied to various applications of DL and deep reinforcement
    learning.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*增强拓扑的神经进化*（NEAT）是一种将超参数和架构优化与权重搜索相结合的技术，可以自动构建新的DL模型，这些模型还可以发展它们自己的损失和验证方法。虽然NEAT几乎20年前就已经开发出来，但直到最近，这项技术才被应用于DL和深度强化学习的各种应用中。'
- en: 1.5.6 Goals
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.6 目标
- en: In this book, we look at the previously noted set of techniques and how they
    may be applied to DL. We focus on practical techniques that can be applied to
    a variety of problems using working solutions, paying particular attention to
    how various forms of AML/ AutoML may also be applied to optimizing DL systems
    and evaluating performance across techniques. Our focus also includes a broader
    range of techniques outside of evolutionary methods.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们探讨之前提到的技术集合以及它们如何应用于DL。我们关注实用的技术，这些技术可以通过实际解决方案应用于各种问题，特别关注如何将各种形式的AML/AutoML也应用于优化DL系统和评估技术间的性能。我们的关注范围还包括进化方法之外的更广泛的技术。
- en: In the following chapters, we work through sections of the AutoML process that
    progressively introduce key concepts to someone familiar with DL. After covering
    the basics of EC, we move on to showcasing hyperparameter optimization and then
    data and feature engineering, model option selection, and model architecture.
    Finally, we progress to more complex examples that look to improve on generative
    DL and deep reinforcement learning problems.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将逐步介绍AutoML过程的部分内容，向熟悉DL的人介绍关键概念。在介绍EC的基础知识之后，我们将展示超参数优化，然后是数据和特征工程、模型选项选择和模型架构。最后，我们将进一步探讨更复杂的示例，旨在改进生成性DL和深度强化学习问题。
- en: By the end of this book, you should feel comfortable describing and using both
    DL and certain subsets of EC alone or in combination to optimize networks. You
    will be able to build models to solve problems using both subfields as well as
    understand which works better for specific classes of problems, including the
    ability to apply EC on top of DL models for various optimizations and applications
    of AutoML.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 到这本书结束时，你应该能够舒适地描述和使用DL以及EC的某些子集，无论是单独使用还是组合使用来优化网络。你将能够构建模型来解决使用这两个子领域的问题，并理解哪些更适合特定类别的问题，包括在DL模型上应用EC进行各种优化和应用AutoML的能力。
- en: Summary
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: DL is a powerful technology capable of solving many AI and ML tasks, but it
    is complex; requires significant amounts of data; and is expensive to develop,
    train, and optimize.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DL是一种强大的技术，能够解决许多AI和ML任务，但它很复杂；需要大量的数据；并且开发、训练和优化的成本很高。
- en: EC is a subfield of AI and ML that is defined by the theory of natural selection.
    It has not matured as quickly as DL but still provides techniques for solving
    a wide variety of complex problems.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EC是AI和ML的一个子领域，其定义基于自然选择理论。它的发展速度没有DL快，但仍然提供了解决各种复杂问题的技术。
- en: EDL is a broad term encompassing the combination of evolutionary methods with
    DL. Neuroevolution, evolutionary hyperparameter optimization, and neuroevolution
    of augmenting topologies are examples of EDL. EDL defines a subset of EC methods
    that may be used to automate and improve the development of DL models across many
    stages of the ML workflow.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EDL是一个广泛的概念，包括进化方法和DL的结合。神经进化、进化超参数优化和增强拓扑的神经进化是EDL的例子。EDL定义了EC方法的一个子集，可用于自动化和改进ML工作流程中许多阶段的DL模型开发。
- en: AML and AutoML define a set of tools and techniques that look to automate the
    entire AI and ML model development workflow. Many forms of evolutionary computation
    have been and can be used to automate the model development workflow. Google and
    other companies have invested significantly into developing AutoML to assist consumers
    in building robust models for their own needs. While these services are powerful,
    they often work like a black box and limit more agile customization of new cutting-edge
    models.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AML（自动化机器学习）和AutoML定义了一套旨在自动化整个AI和ML模型开发工作流程的工具和技术。许多形式的进化计算已经被使用，并且可以用于自动化模型开发工作流程。谷歌和其他公司已经大量投资于AutoML的开发，以帮助消费者根据自身需求构建稳健的模型。尽管这些服务功能强大，但它们通常像黑盒一样工作，限制了新前沿模型更敏捷的定制化。
