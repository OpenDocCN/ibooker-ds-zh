- en: Chapter 24\. Is It Wrong to Be Right?
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第24章。对于正确是否错误？
- en: Marty Ellingsworth
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Marty Ellingsworth
- en: '![](Images/marty_ellingsworth.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/marty_ellingsworth.png)'
- en: Senior Analyst, Celent
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Celent 高级分析师
- en: Better data, better models, and better decision engines get better results.
    Whether you hand train a model, use automated machine learning systems, or employ
    any of the newest “x”-learning nets with pretraining, does it really matter why
    your model performs so well as long as it has great performance? Should not the
    most accurate model be used everywhere and anywhere in all situations? That’s
    progress, right? Should your model be allowed to learn on its own to further this
    progress and self-calibrate for better personalization? Practically, if there
    is no harm, then there is no foul, right?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的数据、更好的模型和更好的决策引擎带来更好的结果。无论是手动训练模型，使用自动化机器学习系统，还是采用任何最新的“x”学习网络进行预训练，只要模型表现出色，为什么它能够表现得如此出色并不重要呢？最精确的模型不应该在所有情况下都能够使用吗？这就是进步，对吧？应该允许您的模型自行学习以进一步推动此进展并进行更好的个性化吗？实际上，如果没有伤害，那么就没有犯规，对吧？
- en: Academically, many argue it’s all about the lift, correct for the data. Professionally,
    the standards of care are still emerging. There are dozens of fields of practice
    in which better models and better data appear magically, regularly, and at scale,
    for better results—no questions asked—resulting in delighted users, inventors,
    and investors. Privacy rights advocates sound warnings.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 学术上，许多人认为这一切都关乎对数据的提升和修正。在职业上，关怀标准仍在逐步形成中。有数十个实践领域，其中更好的模型和更好的数据似乎会神奇地、定期地和规模化地出现，以获得更好的结果——无需质疑——从而使用户、发明家和投资者感到满意。隐私权倡导者发出警告。
- en: Legally, we are in a technological sprint that is far ahead of existing laws
    and compliance regulations. Many of today’s controls emerged back in the 1970s
    and 1980s around fairness in employment, lending, and housing, and in the 1990s
    and early 2000s around fraud, theft, collusion, money laundering, and terrorism
    concerns. Known legal lines are often well defined yet are often not well understood
    by those closest to the data. Oftentimes there are compound definitions that define
    something as prohibited or restricted (who, what, when, where, why, how, how much,
    by what means, in what use case, for what age group, and in which jurisdiction).
    This can leave more situations undefined than prescribed. If it’s not against
    the law, is it still OK?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在法律上，我们正处在科技飞速发展的阶段，远远超出了现有法律和合规法规的范畴。今天许多控制措施是在上世纪70年代和80年代关于就业公平、贷款和住房方面出现的，并且在上世纪90年代和21世纪初关于欺诈、盗窃、勾结、洗钱和恐怖主义问题方面出现的。已知的法律条文通常定义得很明确，但是这些最接近数据的人通常对其并不了解。往往存在复合定义，将某事物定义为禁止或受限（谁、什么、何时、何地、为何、如何、多少、以何方式、在什么使用案例中、适合什么年龄群体以及在哪个司法管辖区）。这可能导致更多的情况未被界定而非被预言。如果不违法，那还可以吗？
- en: Ethically, “what’s OK” is often a moving target. Business impact drives the
    need for better results, and the public can be fickle as well as persuaded and
    even paid in value for particular information. Who is the ethical gatekeeper,
    when do they engage, and when do they reengage as situations change? This is an
    emerging issue in data science.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 从伦理角度看，“什么是可以接受的”往往是一个不断变化的目标。业务影响推动了对更好结果的需求，公众也可能善变，并且为特定信息可能会被说服甚至是支付价值。在数据科学中，谁是伦理门户，何时他们参与，以及在情况变化时何时重新参与？这是一个新兴的问题。
- en: The rubber on the road usually shows as a variety of skid marks over time. Big
    skids occur when great predictions don’t hold up for subgroups, and when specific
    protected subgroups get predicted at all. When to predict and when not to predict
    is an ethical question perhaps broader than “business ethics.”
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，道路上的橡胶通常会显示出多种时间上的打滑痕迹。当优秀的预测对子群体不起作用时，或者当特定受保护的子群体被预测时，会发生重大打滑。何时预测，何时不预测可能是一个比“商业道德”更广泛的伦理问题。
- en: Many bosses kill the messenger. Most ethics departments sprang from a lapse.
    Many small companies don’t even have ethics departments. Non-US companies may
    have different ethics, as may different companies in the same industries with
    the same customers in the same geographies. Which ethical framework should be
    the standard is unclear. Until then, more common will be the cases in which disparate
    impact on a protected class or infringement of illegal variables occurs. This
    may be due to bias introduced by underlying data, by poor management of specific
    types of data, or by distinguishing characteristics of embeddable minutiae (especially
    when text, image, scan, diagnostic, sound, video, temporal, transaction, biologic,
    demographic, medical, dental, geographic, sensor, social network, knowledge graph
    association, past history, current activity, behavior, online activity, purchase,
    personal interaction, and location data are considered).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 许多老板会打击报信者。大多数伦理部门都源于某种失误。许多小公司甚至没有伦理部门。非美国公司可能具有不同的伦理标准，同行业内服务相同客户和相同地理位置的不同公司也可能如此。哪种伦理框架应当成为标准尚不明确。在那之前，更常见的情况将是对受保护类别的不同影响或违法变量的侵害。这可能是由于基础数据引入的偏见，特定类型数据的管理不善，或者可嵌入微小细节的区分特征（特别是在考虑文本、图像、扫描、诊断、声音、视频、时间、交易、生物、人口统计、医疗、牙科、地理位置、传感器、社交网络、知识图谱关联、过去历史、当前活动、行为、在线活动、购买、个人互动和位置数据时）造成的。
- en: Data, analytics, and decision support systems, especially those that can learn
    post hoc, are all susceptible to risk. They can learn bad behavior, overrepresent
    unbalanced demographics, “cheat” by mimicking processors in a process, leverage
    illegal and protected information unwittingly, or find distinguishing characteristics
    in a data sample that may drift or disappear in a production setting.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据、分析和决策支持系统，特别是那些可以事后学习的系统，都存在风险。它们可能学习到不良行为，过度代表不平衡的人群统计数据，“作弊”通过模拟处理器在流程中的行为，无意间利用非法和受保护信息，或者在数据样本中找到在生产环境中可能漂移或消失的特征。
- en: Automated machine learning and AI that just needs component assembly with prepackaged
    data feeds are putting more analytic model building capabilities in the hands
    of businesspeople and other “citizen data scientists.” But making models easy
    to build does not address the art, craft, and ethics of picking good problems
    and solving them with ethics at the core.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化机器学习和需要仅进行组件装配的人工智能正在将更多的分析模型构建能力交给业务人员和其他“公民数据科学家”。但是，简化模型构建并不能解决选择好问题、以伦理为核心解决问题的艺术、技艺和伦理问题。
- en: So many times in an analytics practice, the art of problem definition and the
    craft of knowing the context of the underlying data before using it in production
    run up against the delight in a well-performing model and the urgency of a near-term
    delivery date—not to mention the millions and billions of dollars seemingly raining
    down on herds of unicorns in the start-up space.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析实践中，很多时候，问题定义的艺术和在生产中使用数据之前了解其背景的技艺与良好模型的表现喜悦及近期交付日期的紧迫性发生冲突——更不用说似乎在初创公司领域的独角兽群体上空似乎如雨般的数百万和数十亿美元。
- en: Can the ends justify the means? It’s a question that every data scientist—as
    well as their employer, board of directors, auditors, regulators, and investors—needs
    to consider.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 目的是否能够证明手段正当？这是每个数据科学家以及他们的雇主、董事会、审计员、监管者和投资者都需要考虑的问题。
