- en: 12 Running Java in containers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 在容器中运行 Java
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Why container-driven development is important for the well-grounded Java developer
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么容器驱动的开发对于扎实的 Java 开发者很重要
- en: The difference between an OS, a VM, a container, and orchestration
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统、虚拟机、容器和编排之间的区别
- en: Docker
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker
- en: Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes
- en: Practical guidance on running Java workloads in containers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在容器中运行 Java 工作负载的实用指南
- en: Performance and observability in containers
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器中的性能和可观察性
- en: Docker ([https://www.docker.com/](https://www.docker.com/)) containers have
    become the de facto standard for packaging Java applications for deployment, and
    Kubernetes ([https://kubernetes.io/](https://kubernetes.io/)) (k8s) is the most
    popular option for orchestrating those containers. Especially if you are deploying
    to any of the major cloud providers, you will need to know about these technologies
    and, more importantly, how Java behaves with them.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Docker ([https://www.docker.com/](https://www.docker.com/)) 容器已成为打包 Java 应用程序进行部署的事实标准，而
    Kubernetes ([https://kubernetes.io/](https://kubernetes.io/))（k8s）是编排这些容器的最受欢迎的选择。特别是如果您要将应用程序部署到任何主要云服务提供商，您将需要了解这些技术，更重要的是，了解
    Java 与它们的交互行为。
- en: Note Although other container and container orchestration technologies exist,
    Docker and Kubernetes dominate the container and orchestration markets, respectively.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：尽管存在其他容器和容器编排技术，但 Docker 和 Kubernetes 分别在容器和编排市场中占据主导地位。
- en: 12.1 Why containers matter for a well-grounded developer
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 为什么容器对于扎实的开发者很重要
- en: 'To better understand what containers are and why they are important for a well-grounded
    Java developer, we will look at the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解容器是什么以及为什么它们对于一个扎实的 Java 开发者来说很重要，我们将查看以下内容：
- en: Host operating system versus virtual machines versus containers
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 宿主操作系统与虚拟机与容器的比较
- en: The benefits of containers
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器的优点
- en: The drawbacks of containers
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器的缺点
- en: 12.1.1 Host operating systems vs. virtual machines vs. containers
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.1 宿主操作系统与虚拟机与容器的比较
- en: Since the early days of computing, we’ve been introducing layers of abstraction
    between our software and the hardware that it runs on. Containers are another
    natural step in this progression. Let’s take a brief tour through these layers
    to see how containers fix in.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自从计算机的早期阶段起，我们就一直在在软件和它运行的硬件之间引入抽象层。容器是这一进步中的另一个自然步骤。让我们简要地浏览这些层，看看容器是如何嵌入其中的。
- en: Bare metal
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 裸金属
- en: Let us start by going right back to basics—a *bare metal machine* that has no
    host operating system installed. This bare metal machine represents a set of finite
    resources to whatever software might be installed on it, including CPU, RAM, hard
    disk, networking and so forth.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从最基本的概念开始——一个没有安装宿主操作系统的 *裸金属机器*。这块裸金属机器代表了一组有限资源，这些资源可以提供给可能安装在其上的任何软件，包括
    CPU、RAM、硬盘、网络等等。
- en: Note This concept of finite resources is a critical one to keep in your head.
    Far too often, developers are fooled into thinking that containers somehow give
    them magical infinite resources!
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这个有限资源的概念是您需要牢记的关键概念。开发者常常被误导，认为容器以某种方式给了他们神奇的无尽资源！
- en: Always remember that underneath the host operating system, virtual machines,
    or containers is a piece of bare metal with *finite resources*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 总要记住，在宿主操作系统、虚拟机或容器之下，是一块带有 *有限资源* 的裸金属。
- en: Host operating system or type 1 hypervisor
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 宿主操作系统或类型 1 虚拟化程序
- en: In modern data centers, the bare metal machines have either a host operating
    system (e.g., Linux) or a Type 1 hypervisor (e.g., VMWare ESXi, Microsoft Hyper-V)
    installed on them. Hypervisor is the term for software that enables the creation
    and management of virtual machines. Hypervisors can exist at multiple layers of
    the stack. A Type 1 hypervisor is installed on bare metal and serves as a lightweight
    operating system, dedicating most of the machine’s resources to the virtual machines
    it runs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代数据中心，裸金属机器上要么安装了宿主操作系统（例如，Linux）或类型 1 虚拟化程序（例如，VMWare ESXi、Microsoft Hyper-V）。虚拟化程序是能够创建和管理虚拟机的软件的术语。虚拟化程序可以存在于堆栈的多个层级。类型
    1 虚拟化程序安装在裸金属上，充当轻量级操作系统，将机器的大部分资源分配给其运行的虚拟机。
- en: Whether running a traditional operating system or a hypervisor, this first layer
    is typically lightweight and doesn’t do much more than look after security guarantees
    and allow for higher-level abstractions to be installed on top. That said, the
    host operating system does require some CPU, RAM, and networking to run.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 无论运行的是传统操作系统还是虚拟机管理程序，这一层通常是轻量级的，并且做的不仅仅是确保安全保证，并允许在顶部安装高级抽象。尽管如此，宿主操作系统运行确实需要一些CPU、RAM和网络资源。
- en: Type 2 Hypervisors
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Type 2 虚拟机管理程序
- en: If our bare metal has a traditional operating system such as Linux installed,
    then the next layer up is usually a Type 2 hypervisor. Whether Type 1 or Type
    2, hypervisors are responsible for managing the resources of the underlying hardware
    for the virtual machines (VMs) with guest operating systems.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的裸机安装了传统的操作系统，如Linux，那么下一层通常是Type 2虚拟机管理程序。无论是Type 1还是Type 2，虚拟机管理程序负责管理带有客户操作系统的虚拟机（VMs）的底层硬件资源。
- en: For example, a bare metal machine with 32 GB of RAM and a 16 core CPU with a
    Linux host operating system could run a Type 2 hypervisor, which in turn hosts
    four VMs, each running a Linux guest operating system with what appears to be
    8 GB of RAM and 4 CPU cores each. Modern hypervisors normally don’t take up much
    of the underlying resources to run themselves. If a Type 1 hypervisor is used
    directly on our bare metal, it’s ready to run the next layer, virtual machines,
    without additional intervention.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一台裸机机器，拥有32 GB的RAM和16核心CPU，运行Linux宿主操作系统，可以运行一个Type 2虚拟机管理程序，该虚拟机管理程序反过来可以托管四个虚拟机（VMs），每个虚拟机运行一个Linux客户操作系统，看起来每个虚拟机有8
    GB的RAM和4个CPU核心。现代虚拟机管理程序通常不会占用太多底层资源来运行自身。如果直接在我们的裸机上使用Type 1虚拟机管理程序，它就可以准备运行下一层，即虚拟机，而无需额外的干预。
- en: Virtual machines
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机
- en: Each VM is fully self-contained. As far as the user is concerned, it has its
    own CPU, RAM, network, and disk resources. When you log on to a server in a production
    environment, chances are that you are logging on to a VM and not a bare metal
    server.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 每个虚拟机都是完全自包含的。对于用户来说，它有自己的CPU、RAM、网络和磁盘资源。当你登录到生产环境中的服务器时，很可能会登录到一个虚拟机而不是裸机服务器。
- en: The self-contained VM also has its own operating system, referred to as the
    guest operating system. In the past, VMs paid a performance penalty to provide
    this isolated environment, but advances in the technology have removed many of
    those issues over the years.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 自包含的虚拟机也有自己的操作系统，称为客户操作系统。在过去，虚拟机为了提供这种隔离环境而付出了性能代价，但随着技术的进步，这些问题的许多方面在近年来已经得到了解决。
- en: Remember what we said about finite resources? Each virtual machine is just that—*virtual*.
    When the hypervisor isn’t configured correctly, or virtual machines are given
    more resources than what physically exists, or are not dedicated to you (very
    common in cloud environments), you can have unpredictable performance.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 记得我们提到的有限资源吗？每个虚拟机只是那样——*虚拟的*。当虚拟机管理程序配置不正确，或者虚拟机被分配了比物理存在更多的资源，或者不是专门为用户分配的（在云环境中非常常见），你可能会遇到不可预测的性能。
- en: Container engines
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 容器引擎
- en: Prior to modern container engine technology, it was common to run a container
    engine on top of the guest operating system. This container engine could itself
    then run multiple containers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代容器引擎技术之前，通常在客户操作系统之上运行容器引擎。这个容器引擎本身可以运行多个容器。
- en: This layer demonstrates one of the main differences between VMs and containers,
    because one of the container engine’s key responsibilities is sharing access to
    a single operating system kernel across the containers it runs. This setup is
    much lighter than the VM model, where each instance has a full copy of its own
    operating system. This advantage, though, requires a lot of support from many
    different parts of the Linux kernel itself.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这一层展示了虚拟机和容器之间主要区别之一，因为容器引擎的关键职责之一是在它运行的容器之间共享单个操作系统内核的访问权限。这种设置比虚拟机模型轻得多，在虚拟机模型中，每个实例都有自己的操作系统完整副本。然而，这种优势需要Linux内核本身许多不同部分的很大支持。
- en: Containers
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 容器
- en: Finally we arrive at the container. You can think of a container as a custom-built,
    isolated environment in which to run an application. A container has a filesystem
    and runs at least one process. Although the processes in that container can all
    communicate with a kernel, many limits are imposed to keep the container separate
    from the rest of the world, including limits on memory, CPU, network (usage and
    visibility), and disk.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后我们来到了容器。你可以将容器想象成一个定制的、隔离的环境，用于运行应用程序。容器有一个文件系统，并至少运行一个进程。尽管该容器中的进程都可以与内核通信，但许多限制被施加以保持容器与其他世界的隔离，包括对内存、CPU、网络（使用和可见性）和磁盘的限制。
- en: Inside containers, you run your Java application, data store, or other services
    that you require. Let’s look at all of those layers of abstraction.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器内部，你运行你的Java应用程序、数据存储或其他所需的服务。让我们看看所有这些抽象层。
- en: '![](../Images/CH12_F01_Evans2.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F01_Evans2.png)'
- en: Figure 12.1 Target environment for Java applications
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 Java应用程序的目标环境
- en: In Figure 12.1, the host operating system is the bottom layer of abstraction.
    The hypervisor is the next layer, followed by the container engine, the container,
    and the Java application. That seems a little over the top, doesn’t it? In more
    pure container environments, it is, so in the past few years, you’ll see dedicated
    container host machines, shown in figure 12.2, which remove the hypervisor and
    guest operating system layers.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在图12.1中，主机操作系统是抽象的最底层。虚拟机管理程序是下一层，然后是容器引擎、容器和Java应用程序。这似乎有点过分，不是吗？在更纯粹的容器环境中，确实如此，所以过去几年里，你会看到专门的容器主机机，如图12.2所示，它们移除了虚拟机管理程序和客户操作系统层。
- en: '![](../Images/CH12_F02_Evans2.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F02_Evans2.png)'
- en: Figure 12.2 Target environment for Java applications on dedicated container
    engines
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2在专用容器引擎上Java应用程序的目标环境
- en: That’s much better! That said, most developers aren’t sure what their target
    environment looks like. The takeaway here is to make sure you check with your
    system administrators to understand exactly what your target environment looks
    like and how much of that bare metal finite resource is being allocated at each
    layer.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这要好得多！话虽如此，大多数开发者并不确定他们的目标环境是什么样的。这里的要点是确保你与系统管理员联系，了解你的目标环境的确切样子以及每一层分配了多少裸金属有限资源。
- en: Despite all of the complexity within these layers of abstraction, as a Java
    developer, you will be focused mainly on the container as a deployment target,
    and this way of doing things has some important benefits.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些抽象层中存在所有这些复杂性，但作为一个Java开发者，你将主要关注容器作为部署目标，这种方式做事情有一些重要的好处。
- en: 12.1.2 Benefits of containers
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.2 容器的优势
- en: With all the additional moving parts needed to run containers, why have they
    become the new standard for deployment? One of the key benefits is the ability
    of containers to apply limits, isolating individual running processes from each
    other. In the past, if you deployed two Java applications on the same host, there
    was a high probability that they could interfere with each other’s performance—stealing
    too much CPU time or gobbling up more than their fair share of memory. Mitigations
    existed, but these ideas are baked into the fundamental layers of containers.
    In fact, having limits we can trust, in practice, allows us to more thoroughly
    use our computing resources, running more software on a host than would have felt
    safe before containers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行容器所需的额外移动部件中，为什么它们成为了新的部署标准？其中一个关键好处是容器能够应用限制，将单个运行进程彼此隔离。在过去，如果你在同一主机上部署了两个Java应用程序，它们相互干扰性能的可能性很高——窃取过多的CPU时间或占用超过其公平份额的内存。虽然存在缓解措施，但这些想法已经融入了容器的基本层。实际上，拥有我们可以信赖的限制，在实践中，使我们能够更充分地使用计算资源，在主机上运行比容器出现之前更安全的更多软件。
- en: This isolation is so key that for the remainder of the chapter we’ll illustrate
    the relationship between containers, hosts, and processes by showing nested rather
    than stacked images. Both ways of visualizing the relationship are valid, so don’t
    be surprised to find both in the wild, depending on the context.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种隔离如此关键，以至于在本章的剩余部分，我们将通过展示嵌套而不是堆叠的图像来展示容器、主机和进程之间的关系。这两种可视化关系都是有效的，所以不要对在野外找到两者感到惊讶，这取决于上下文。
- en: Containers have also ushered in a world of more consistent packaging for deployment.
    How you copied the bits for your application to the deployment environment, how
    you managed the operating system dependencies, and even how you managed process
    startup used to be all up for grabs. Containers provide an answer to all of that,
    making a gigantic pile of tooling and custom scripts unnecessary. They also provide
    insulation between our deployment environment and the container’s contents. Our
    container engine doesn’t have to care how we lay out the internals of our container—it
    just has to know how to start itself when asked. Packaging of container images
    is a key example of Infrastructure as a Service (IaaS), with a declarative, source-controlled
    description of layers in our system, which used to require careful, imperative
    construction.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 容器还引领了一个更一致打包的世界，用于部署。你如何将应用程序的代码复制到部署环境，如何管理操作系统依赖，甚至如何管理进程启动，这些都曾经是随意的事情。容器为所有这些问题提供了答案，使得大量的工具和定制脚本变得不再必要。它们还为我们部署环境和容器内容之间提供了隔离。我们的容器引擎不需要关心我们如何安排容器内部结构——它只需要知道在请求时如何启动自己。容器镜像的打包是基础设施即服务（IaaS）的一个关键例子，它使用声明性、源代码控制的系统层描述，这在以前需要仔细的命令性构建。
- en: A final benefit builds on that consistent packaging—the ecosystem that’s developed
    around containers. Today almost any significant piece of software that you want
    to run has likely been packaged in a container already on Docker Hub or elsewhere.
    Vast READMEs of installation instructions or custom install scripts are now unnecessary.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个好处建立在一致的打包上——围绕容器开发的生态系统。今天，几乎任何你想运行的软件的重要部分可能已经在Docker Hub或其他地方打包成容器了。大量的安装说明或定制安装脚本现在变得不再必要。
- en: But it can’t all be upsides, right? What are the drawbacks to running in containers?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 但不可能全是优点，对吧？运行在容器中有什么缺点？
- en: 12.1.3 Drawbacks of containers
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.3 容器的缺点
- en: As it turns out, the first point that we listed as a benefit for containers—their
    built-in isolation—is actually one of the difficulties in using them. The job
    of containers is keeping the world inside the container separate from the outside
    world, and that outside world includes you, the developer. Many of the techniques
    and tools that you commonly use outside of containers may require special handling
    and configuration with a move to containers.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，我们列出的容器好处中的第一个——内置隔离——实际上在使用它们时却是一个难点。容器的任务是保持容器内部世界与外部世界的分离，而这个外部世界包括你，开发者。你在外部容器中常用的许多技术和工具在迁移到容器时可能需要特殊处理和配置。
- en: This can be especially true when trying to factor containers into your local
    development processes. Longer builds and time spent shuffling huge container images
    around may not always feel worth it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是在尝试将容器纳入你的本地开发流程时，这一点更为明显。更长的构建时间和在容器镜像之间移动大量时间可能并不总是值得。
- en: And although containers introduce a consistent interface for how we package
    and start our application, real-world deployment isn’t always simple. For example,
    an application that expects full access to the disk on its host may require configuration
    to make the required files visible to the container. If a set of processes communicate
    with each other, separating them into containers will need explicit configuration
    for how they can access each other. Capturing and applying this sort of configuration
    is a key task for orchestrators such as Kubernetes. Be aware, however, that Kubernetes,
    which we’ll examine briefly in this chapter, is a topic fit to fill books, and
    the ecosystem continues to develop rapidly.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管容器为我们打包和启动应用程序引入了一致接口，但现实世界的部署并不总是简单。例如，一个期望对其宿主机的磁盘有完全访问权限的应用程序可能需要配置，以便使所需的文件对容器可见。如果一组进程相互通信，将它们分离到容器中需要显式配置它们如何相互访问。捕获和应用此类配置是Kubernetes等编排器的一个关键任务。然而，请注意，我们将在本章简要介绍的Kubernetes是一个适合填满书籍的主题，并且该生态系统仍在快速发展。
- en: Although containers are becoming entirely mainstream, the well-grounded developer
    knows how to examine the trade-offs to find the right balance for their system.
    Let’s start to see how to use these tools, so we can get a feel for where they
    fit.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管容器已经成为完全主流的技术，但经验丰富的开发者知道如何权衡利弊，为他们的系统找到合适的平衡点。让我们开始了解如何使用这些工具，以便我们能够感受到它们适合的位置。
- en: 12.2 Docker fundamentals
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 Docker基础知识
- en: Though many of the constituent technologies that make up containers existed
    earlier, Docker introduced convenient tooling and abstractions that catapulted
    containerization to the mainstream. Let’s take a look at two central pieces of
    functionality that Docker gives us—building images and running containers—and
    see how we interact with those as Java developers in practice.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多构成容器的技术在此之前就已经存在，但 Docker 引入了方便的工具和抽象，将容器化推向了主流。让我们看看 Docker 给我们提供的两个核心功能——构建镜像和运行容器——以及我们作为
    Java 开发者在实践中如何与之交互。
- en: 12.2.1 Building Docker images
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.1 构建 Docker 镜像
- en: A Docker container is launched from an *image*. An image is essentially a snapshot
    that captures all the filesystem dependencies needed to run a piece of software.
    An image includes native libraries, languages runtimes, tools, and, most importantly,
    a specific version of your software to run.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 容器是从 *镜像* 启动的。镜像本质上是一个快照，它捕获了运行软件所需的所有文件系统依赖项。镜像包括本地库、语言运行时、工具，最重要的是，运行你的软件的特定版本。
- en: 'The `Dockerfile` is typical format for capturing the set of steps to build
    an image. The simplest image possible, one which is entirely empty, looks like
    this:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dockerfile` 是捕获构建镜像步骤集的典型格式。可能的最简单镜像，一个完全为空的镜像，看起来像这样：'
- en: '[PRE0]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We build the image using the `docker build` command as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下 `docker build` 命令构建镜像：
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ The sha256 ID 71de114... uniquely identifies the resulting image. We’ll see
    how to give things a more friendly name in a moment.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ sha256 ID 71de114... 唯一标识生成的图像。我们稍后将看到如何给事物起一个更友好的名字。
- en: 'Of course, an empty image isn’t much use. In practice, many base images exist
    with useful software already installed. The default source of these base images
    is Docker Hub ([https://hub.docker.com/](https://hub.docker.com/)). We’ll talk
    more later about selecting the right Java base image, but for now, let’s start
    building an image off an Eclipse Temurin version of OpenJDK provided by Adoptium.
    We’ll specifically choose the `eclipse-temurin:11` image as show here, which contains
    the latest version of Java 11:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一个空图像并没有太大的用处。在实践中，存在许多已经安装了有用软件的基础镜像。这些基础镜像的默认来源是 Docker Hub ([https://hub.docker.com/](https://hub.docker.com/))。我们稍后会更多地讨论如何选择合适的
    Java 基础镜像，但现在，让我们从一个由 Adoptium 提供的 Eclipse Temurin 版本的 OpenJDK 开始构建镜像。我们将特别选择这里显示的
    `eclipse-temurin:11` 镜像，它包含 Java 11 的最新版本：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'By default, recent versions of Docker will dynamically hide output when building
    in an interactive terminal. We’ll use `--progress plain` here to get a clearer
    picture of what’s happening:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Docker 的最新版本在交互式终端中构建时会动态隐藏输出。我们将使用 `--progress plain` 来获得更清晰的了解：
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Internal steps Docker takes when preparing to build our images
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Docker 在准备构建我们的镜像时采取的内部步骤
- en: ❷ Retrieving our requested base image
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 获取我们请求的基础镜像
- en: ❸ Our RUN command is executed during the build, and we can see its output.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 我们的 `RUN` 命令在构建过程中执行，我们可以看到它的输出。
- en: You may note that this code takes longer to run, at least the first time, because
    Docker has to download the relevant base image from Docker Hub. The `RUN` command
    we’ve added introduces our own new step on top of that base image. `RUN` can execute
    any valid command in the container environment. If the command alters the filesystem,
    those changes are captured as part of our final image. This example doesn’t actually
    alter the filesystem, but `RUN` is frequently used to download files (e.g., via
    `curl`), install operating system packages with standard package managers, or
    make other local modifications.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，这段代码至少第一次运行需要更长的时间，因为 Docker 必须从 Docker Hub 下载相关的基镜像。我们添加的 `RUN` 命令在基镜像之上引入了我们自己的新步骤。`RUN`
    可以在容器环境中执行任何有效的命令。如果命令改变了文件系统，这些更改将作为我们最终镜像的一部分被捕获。这个例子实际上并没有改变文件系统，但 `RUN` 经常用于下载文件（例如，通过
    `curl`），使用标准包管理器安装操作系统包，或进行其他本地修改。
- en: 'We can see another important part of building Docker images if we run the same
    build command again without touching the `Dockerfile` like this:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们不触摸 `Dockerfile` 而再次运行相同的构建命令，我们可以看到构建 Docker 镜像的另一个重要部分：
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Docker informs us when it skipped a step because the result was cached.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Docker 会在跳过某个步骤时通知我们，因为结果被缓存了。
- en: Each of the leading commands (like `FROM` and `RUN`) in the `Dockerfile` creates
    what is called a *layer*. Because these commands can often be time-consuming,
    those layers are cached, and Docker does its best to avoid unnecessary work.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dockerfile` 中每个前导命令（如 `FROM` 和 `RUN`）都创建了一个称为 *层* 的东西。因为这些命令通常很耗时，所以这些层被缓存，Docker
    尽力避免不必要的操作。'
- en: 'Now that our container has a Java environment, we can run our own code there.
    We’ll create a simple Java file alongside our `Dockerfile` in `HelloDocker.java`.
    To keep things easy to start, we’ll use the Java single-file execution to run
    this instead of putting a full build together yet. The basic code looks like this:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了Java环境，我们可以在那里运行自己的代码。我们将在`Dockerfile`旁边创建一个简单的Java文件，命名为`HelloDocker.java`。为了便于启动，我们将使用Java的单文件执行来运行它，而不是现在就构建一个完整的构建。基本代码如下：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can then instruct the Docker build to include this file in our image and
    set the default command for containers running this image as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以指示Docker构建将此文件包含在我们的镜像中，并设置运行此镜像的容器的默认命令如下：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Copies our file to whatever that current working directory Docker has set
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将我们的文件复制到Docker当前工作目录
- en: ❷ Sets the default command for the image. Note each command-line argument is
    in its own separate string.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 设置镜像的默认命令。注意每个命令行参数都在其单独的字符串中。
- en: '`COPY` (and the more complex `ADD` command) take files from our local build
    environment and puts them in our container. `ADD`, in particular, has a lot of
    options, including fetching from remote source and auto-extracting TAR files,
    but generally, you’ll be better off with a simple `COPY` where you can.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`COPY`（以及更复杂的`ADD`命令）将文件从我们的本地构建环境复制到我们的容器中。`ADD`特别具有许多选项，包括从远程源获取和自动提取TAR文件，但通常，如果您可以使用简单的`COPY`，那么您会更好。'
- en: '`CMD` points us to the next stage in an image’s lifecycle. We aren’t just building
    these images for fun—we want to run the software we’re configuring in them. As
    mentioned earlier, each image has a unique SHA256 identity, but those are cumbersome
    to work with and change every time you build. Before we get to running our image,
    let’s tag our image with an easier name, as shown next:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`CMD`指向镜像生命周期的下一个阶段。我们不仅仅是为了好玩而构建这些镜像——我们希望运行我们在其中配置的软件。如前所述，每个镜像都有一个唯一的SHA256身份标识，但这些标识难以处理，并且每次构建时都会改变。在我们运行镜像之前，让我们用更简单的名称标记我们的镜像，如下所示：'
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Our image’s SHA256 identity
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们镜像的SHA256身份标识
- en: ❷ The tag we’ve applied to the final image
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们应用到最后镜像上的标签
- en: Our `hello` image is available only locally at this point, but we’ve already
    seen via the `FROM` line that images can be shared. This is accomplished through
    what’s known as a *container registry*. When we asked for the `eclipse-temurin:11`
    base image, Docker defaulted to looking for that image on Docker Hub ([https://hub.docker.com/](https://hub.docker.com/)).
    Other container registries exist, and, in fact, they can be run internally for
    hosting your application images.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们的`hello`镜像仅在本地上可用，但通过`FROM`行我们已经看到镜像是可以共享的。这是通过所谓的*容器仓库*来实现的。当我们请求`eclipse-temurin:11`基础镜像时，Docker默认会在Docker
    Hub([https://hub.docker.com/](https://hub.docker.com/))上查找该镜像。其他容器仓库也存在，实际上，它们可以在内部运行以托管您的应用程序镜像。
- en: 'You can push and pull images via the `docker push` and `docker pull` commands,
    respectively, as shown in the following code. If working with a non-default registry,
    that name is given before the image and tag name:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过`docker push`和`docker pull`命令分别推送和拉取镜像，如下面的代码所示。如果与默认仓库一起工作，那么该名称将放在镜像和标签名称之前：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ k8s.gcr.io is the registry domain, echoserver is the image name, and 1.4 is
    the tag.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ k8s.gcr.io是仓库域名，echoserver是镜像名称，1.4是标签。
- en: If the registry requires authentication, you may have to use `docker login`
    before proceeding. Publicly available images on Docker Hub don’t require that
    step, though.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仓库需要身份验证，您可能在使用之前必须使用`docker login`。不过，Docker Hub上公开可用的镜像不需要这一步。
- en: There’s a lot more to building good Docker images, and we’ll cycle back to some
    of those topics later. But first, let’s see how to turn these images into running
    containers.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 构建好的Docker镜像还有很多内容，我们将在稍后回到一些这些主题。但首先，让我们看看如何将这些镜像转换为运行中的容器。
- en: 12.2.2 Running Docker containers
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.2 运行Docker容器
- en: 'For all the hype and discussion you hear around Docker and containers, the
    central idea is simply being able to execute a well-defined process in a strictly
    controlled environment. The environment is largely defined by the image that we
    construct. Docker allows us to run a container with the `docker run` command,
    as shown here:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管您可能听到关于Docker和容器的所有炒作和讨论，但核心思想仅仅是能够在严格控制的环境中执行一个定义良好的过程。环境主要是由我们构建的镜像定义的。Docker允许我们通过`docker
    run`命令运行容器，如下所示：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this command, Docker created a new filesystem based on our image, applied
    limits and controls (such as CPU and memory), and then started the default process
    defined by `CMD`. Our program outputs a message and exits, but it could as easily
    have started a a server and kept running indefinitely.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个命令中，Docker基于我们的镜像创建了一个新的文件系统，应用了限制和控制（如CPU和内存），然后启动了由`CMD`定义的默认进程。我们的程序输出一条消息并退出，但它同样可以启动一个服务器并无限期地运行。
- en: In figure 12.3, we can see the `java` process we listed in the `CMD` for the
    image. Remember that the host shown here may in fact hide many additional layers
    before you reach the bare metal machine.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在图12.3中，我们可以看到我们在镜像的`CMD`中列出的`java`进程。请记住，这里显示的主机实际上在到达裸机之前可能隐藏了许多额外的层。
- en: '![](../Images/CH12_F03_Evans2.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F03_Evans2.png)'
- en: Figure 12.3 Running a basic container
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 运行基本容器
- en: 'Our `CMD` defines only the default command for starting the container. We can
    ask Docker to run the image with any alternative command we wish. We mentioned
    earlier that the container has a working directory, much like your interactive
    terminals do. We can ask the container what that path is with the `pwd` command
    as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`CMD`仅定义了启动容器的默认命令。我们可以要求Docker使用我们想要的任何替代命令来运行镜像。我们之前提到容器有一个工作目录，就像你的交互式终端一样。我们可以使用`pwd`命令来询问容器该路径是什么，如下所示：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As Figure 12.4 shows, when we run an alternative command to start the container,
    the default `CMD` process is nowhere to be seen.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如图12.4所示，当我们运行一个替代命令来启动容器时，默认的`CMD`进程就无处可寻。
- en: '![](../Images/CH12_F04_Evans2.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F04_Evans2.png)'
- en: Figure 12.4 Running an alternative command in a container
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 在容器中运行替代命令
- en: We can write configuration into our image via files, but it’s often desirable
    to allow defining them at runtime. One of the principles from the Twelve-Factor
    App ([https://12factor.net/](https://12factor.net/)), an influential set of ideas
    about running software such as containers, is defining configuration via the *environment*
    so the same built resource (in our case, the image) can be deployed to new destinations
    without changing code.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过文件将配置写入我们的镜像中，但通常希望允许在运行时定义它们。十二要素应用（[https://12factor.net/](https://12factor.net/)）中的一个原则，这是一套关于运行软件（如容器）的有影响力的思想，是通过*环境*来定义配置，这样相同的构建资源（在我们的情况下，是镜像）可以在不更改代码的情况下部署到新的目的地。
- en: 'As shown in the following code snippet, we can alter the environment variables
    within our container when we start it using the `-e` flag, which may be passed
    multiple times. In our application code, these variables may be read via standard
    means such as the `System.getenv()` method:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下代码片段所示，我们可以使用`-e`标志在启动容器时更改容器内的环境变量，这个标志可以多次传递。在我们的应用程序代码中，这些变量可以通过标准方式（如`System.getenv()`方法）读取：
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Runs the standard env command to see our container’s environment
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 运行标准env命令以查看容器的环境
- en: ❷ Our full environment variable list
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们完整的环境变量列表
- en: 'Let’s discuss one last technique before we look at more realistic approaches
    to building our Java applications in containers: interactively running an image.
    We’ve seen changing the default command to run in the container. We can use that
    same ability to start a shell such as `bash` in the container for additional debugging.
    This requires extra flags to `docker run`—specifically `-i`, so `STDIN` is attached
    for our input to reach the container, and `-t`, so the container starts an interactive
    TTY for us, as shown here:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨更现实的构建Java应用程序在容器中的方法之前，让我们讨论一种最后的技巧：交互式运行镜像。我们已经看到如何更改默认命令以在容器中运行。我们可以使用同样的能力在容器中启动一个shell，如`bash`，以进行额外的调试。这需要额外的`docker
    run`标志——具体来说，是`-i`，以便`STDIN`连接到容器，以及`-t`，以便容器为我们启动一个交互式TTY，如下所示：
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Interactively enters shell commands to inspect the container
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 交互式输入shell命令以检查容器
- en: This lets us see the world precisely as our deployed applications will within
    the container.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我们能够精确地看到容器内部署的应用程序的世界。
- en: It’s all well and good to copy a hello world single-file app into a container,
    but let’s look now at more realistic approaches to using Docker and Java together.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 将hello world单文件应用程序复制到容器中固然很好，但现在让我们看看更现实的将Docker和Java结合使用的方法。
- en: 12.3 Developing Java applications with Docker
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 使用Docker开发Java应用程序
- en: In this section, we’ll tackle a variety of practical considerations for developing
    Java applications with Docker. We’ll start with looking a bit deeper at our JVM
    base images and how to build our images. From there, we’ll dig into various considerations
    about configuring, running, and debugging our containers. Our container has to
    get a JVM from somewhere, which brings us to the topic of choosing a base image.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨使用Docker开发Java应用程序的各种实际考虑因素。我们将从更深入地了解我们的JVM基镜像以及如何构建我们的镜像开始。从那里，我们将深入研究配置、运行和调试我们的容器时的各种考虑因素。我们的容器必须从某处获取JVM，这把我们带到了选择基镜像的话题上。
- en: 12.3.1 Selecting your base image
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.1 选择您的基镜像
- en: 'There isn’t a single answer to what the “right” base image is for running your
    JVM application. Determining what image works for you requires considering the
    following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对于运行你的JVM应用程序的“正确”基镜像并没有一个单一的答案。确定适合你的镜像需要考虑以下因素：
- en: What vendor do I want?
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我想要哪个供应商？
- en: What operating system do I want inside my container?
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我想在容器内使用什么操作系统？
- en: What system architectures do I need to run on?
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我需要在什么系统架构上运行？
- en: 'The choice of vendor also includes a number of factors that may influence your
    choice (we discussed this briefly back in chapter 1), including the following:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 供应商的选择也包含了一些可能影响你选择的因素（我们曾在第1章中简要讨论过），包括以下内容：
- en: Support availability and contracts
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持可用性和合同
- en: Security update policies and timeliness
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全更新策略和及时性
- en: Special considerations for cloud deployment—Microsoft Build of OpenJDK for Azure,
    Amazon Corretto for AWS
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云部署的特殊考虑——Azure的Microsoft Build of OpenJDK，AWS的Amazon Corretto
- en: The cloud vendor–specific builds, while based on OpenJDK, may include performance
    and other enhancements that are beneficial in that vendor’s cloud. They also may
    have additional support and release-frequency benefits.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 云供应商特定的构建，虽然基于OpenJDK，但可能包括在该供应商的云中具有益处的性能和其他增强功能。它们也可能有额外的支持和发布频率的好处。
- en: Most vendors provide support on more than one operating system in their containers.
    It’s common to see Debian, Ubuntu, or Alpine, along with some other Linux variants.
    The choice of operating system largely dictates what package manager is used to
    install native dependencies and what additional tooling is available within the
    container. If your requirements don’t dictate a specific operating system, keeping
    to the more mainstream options like Debian/Ubuntu often avoids difficulties in
    finding and updating packages.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数供应商在其容器中提供对多个操作系统的支持。常见的有Debian、Ubuntu或Alpine，以及一些其他Linux变体。操作系统的选择在很大程度上决定了用于安装本地依赖项的包管理器以及容器内可用的额外工具。如果你的需求没有指定特定的操作系统，坚持使用更主流的选项，如Debian/Ubuntu，通常可以避免在查找和更新软件包时遇到困难。
- en: Note Take particular care with Alpine Linux. Until very recently, no official
    images for Java on Alpine existed. You should check with your Java vendor and
    make sure that they provide images for Alpine.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：特别小心使用Alpine Linux。直到最近，Alpine上还没有官方的Java镜像。你应该与你的Java供应商联系，并确保他们为Alpine提供镜像。
- en: If you need to run on an operating system that isn’t directly shipped by the
    vendor, don’t despair. In these cases, you can build an image yourself that will
    use the system’s typical package management to install the JDK manually. Remember,
    base images and our Docker builds are just about getting the right bits in the
    container’s filesystem. There’s often more than one way to get to that end result
    you’re after.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要在供应商直接提供的操作系统上运行，不要灰心。在这些情况下，你可以自己构建一个镜像，该镜像将使用系统的典型包管理器手动安装JDK。记住，基镜像和我们的Docker构建只是确保容器文件系统中有了正确的位。通常有不止一种方法可以达到你想要的结果。
- en: A final note is on system architecture for images. It is becoming increasingly
    common to run on ARM-based chips, especially in the cloud. Although this has performance
    advantages, be aware that you’ll need images that are built specifically for that
    architecture. If you need to run across architectures, you may end up having to
    build and publish multiple images, but the Docker tooling supports this well already.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点是关于镜像的系统架构。在云环境中，使用基于ARM的芯片越来越普遍。尽管这具有性能优势，但请注意，你需要为该架构专门构建的镜像。如果你需要在不同的架构上运行，你可能最终不得不构建和发布多个镜像，但Docker工具已经很好地支持了这一点。
- en: 12.3.2 Building an image with Gradle
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.2 使用Gradle构建镜像
- en: As we saw in chapter 11, any sizeable Java project will benefit from using a
    consistent build tool. For demonstration purposes, we’ll walk through how to construct
    an image based on a Gradle build, but a similar Maven version is available in
    the resources.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第11章中看到的，任何大型的Java项目都将从使用一致的构建工具中受益。为了演示目的，我们将通过Gradle构建来构建一个镜像，但在资源中还有一个类似的Maven版本。
- en: 'At a minimum, our image needs to contain all our application’s JARs (or class
    files) and all the dependencies for our classpath. For our sample, our application
    takes a dependency on `org.apache.commons:commons-lang3`, as shown next:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 至少，我们的镜像需要包含我们应用程序的所有JAR文件（或类文件）以及我们类路径的所有依赖项。在我们的示例中，我们的应用程序依赖于`org.apache.commons:commons-lang3`，如下所示：
- en: '[PRE13]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We need a slightly different command from our usual `build` or `assemble`,
    but Gradle’s defaults have what we need wrapped up via `installDist`, as shown
    here:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个与通常的`build`或`assemble`命令略有不同的命令，但Gradle的默认设置通过`installDist`为我们提供了所需的功能，如下所示：
- en: '[PRE14]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The simplified build result from this command follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 从此命令生成的简化构建结果如下：
- en: '[PRE15]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We could just take the JAR files and run from them in the container, but Gradle
    has created some helper scripts for starting our application. Let’s take advantage
    of those next:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以直接从JAR文件中运行容器，但Gradle已经为我们创建了一些启动应用程序的辅助脚本。让我们利用这些脚本：
- en: '[PRE16]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Ensures the directory exists for us to copy results into
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 确保目录存在，以便我们将结果复制进去
- en: ❷ Gradle’s startup scripts expect the working directory to be bin, so set that
    as the default location for Docker to start.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ Gradle的启动脚本期望工作目录为bin，因此将bin设置为Docker启动的默认位置。
- en: ❸ Copies the entire install results tree into the container
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将整个安装结果树复制到容器中
- en: ❹ The default command to run is now the startup script from Gradle.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 现在默认的运行命令是Gradle的启动脚本。
- en: You can find out more about Gradle’s start scripts in the documentation for
    the Application plugin (see [http://mng.bz/yvxJ](http://mng.bz/yvxJ)).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在应用程序插件的文档中了解更多关于Gradle的启动脚本的信息（见[http://mng.bz/yvxJ](http://mng.bz/yvxJ))。
- en: This approach assumes that we have an appropriate JDK installed locally to build
    with Gradle before copying the results into our image. Up next, we’ll see how
    we can wrap that up entirely in Docker.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法假设我们已经在本地安装了适当的JDK，以便在将结果复制到我们的镜像之前使用Gradle构建。接下来，我们将看到如何完全使用Docker来实现这一点。
- en: 12.3.3 Running the build in Docker
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.3 在Docker中运行构建
- en: A key promise of containers is the ability to create an isolated, repeatable
    environment for our software to run in. This is a huge advantage for deploying
    our services, but it doesn’t stop there. A classic problem for many projects is
    setting up a local environment for development. If you’ve ever plowed through
    a README with step after step of installs, making sure you got the right versions
    of everything, you know this pain. Containers can help us escape this. Let’s examine
    how we can alter our build to leverage that isolation.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 容器的一个关键承诺是能够为我们的软件创建一个隔离的、可重复的环境。这对于部署我们的服务是一个巨大的优势，但这并不止于此。许多项目的经典问题是设置本地开发环境。如果你曾经逐个步骤地阅读过README，确保你得到了所有正确的版本，你就知道这种痛苦。容器可以帮助我们摆脱这种痛苦。让我们看看我们如何改变我们的构建以利用这种隔离。
- en: Our `Dockerfile` to date has involved only the one resulting image that we’re
    trying to construct. But Docker allows us to define multiple images in the same
    file and, most important, copy between them. With this ability, we can construct
    an image in which to build our application—fully removed from whatever JDKs our
    local system has—and then copy the results into our deployment image. This has
    advantages for both security and image sizes.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的`Dockerfile`只涉及我们试图构建的一个结果镜像。但Docker允许我们在同一个文件中定义多个镜像，并且最重要的是，可以在它们之间复制内容。利用这种能力，我们可以构建一个用于构建我们应用程序的镜像——完全独立于本地系统上的任何JDK——然后将结果复制到我们的部署镜像中。这对安全和镜像大小都有优势。
- en: 'This process is referred to as a *multistage build*, and you can see it in
    action when a `Dockerfile` has multiple `FROM` statements. `FROM` lines that are
    just intermediate stages of the build also include an `AS` keyword to name them
    for later use in the `Dockerfile`, whereas our main resulting image is left as
    before, as shown here:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程被称为*多阶段构建*，当`Dockerfile`中有多个`FROM`语句时，你可以看到它的实际操作。只是构建的中间阶段的`FROM`行也包括一个`AS`关键字来命名它们，以便在`Dockerfile`中稍后使用，而我们的主要结果镜像保持不变，如下所示：
- en: '[PRE17]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Our container to run the compile in, named build
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 运行编译的容器，命名为build
- en: ❷ Creates a location for our source code and sets it as the default working
    directory
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建源代码的位置并将其设置为默认工作目录
- en: ❸ Copies our full project into the container
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将我们的完整项目复制到容器中
- en: ❹ Builds our application (in this case, the Gradle version) as before, locally
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 如同之前一样，在本地构建我们的应用程序（在这种情况下，是Gradle版本）
- en: ❺ Our deployment image can now just use the JRE, which is much smaller.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 我们的部署镜像现在只需使用JRE，它要小得多。
- en: ❻ COPY --from=build takes files from our build image instead of the local filesystem.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 使用`COPY --from=build`从我们的构建镜像而不是本地文件系统获取文件。
- en: Now our continuous integration environment needs only Docker, not a JDK installed,
    to be able to build our application for deployment. As figure 12.5 shows, all
    the necessary components for the build remain fully within the containers.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在持续集成环境只需要Docker，而不需要安装JDK，就能构建我们的应用程序以进行部署。如图12.5所示，所有必要的构建组件都完全位于容器内。
- en: '![](../Images/CH12_F05_Evans2.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F05_Evans2.png)'
- en: Figure 12.5 Multistage builds in Docker
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.5 Docker中的多阶段构建
- en: It’s worth calling out that this is close to the minimal setup for this type
    of build, but it has some downsides around build times. As we mentioned, each
    Docker command creates a layer that is cached, but those caches can be invalidated
    unnecessarily if we’re not careful.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 值得指出的是，这几乎是最小化的此类构建设置，但它有一些关于构建时间的缺点。正如我们提到的，每个Docker命令都会创建一个被缓存的层，但如果我们不小心，这些缓存可能会被不必要地失效。
- en: 'One source of such cache breaking in our current `Dockerfile` is where we copy
    the full project directory into the container. Any file change, no matter how
    small, will invalidate the `COPY . .` line, and we have to run everything after
    that fresh. It’s possible that some local files don’t matter to our build, though—for
    instance, our git history, IDE files, and local build output really don’t need
    to end up in our build container image. Fortunately, we can exclude such files
    from Docker’s consideration by placing a `.dockerignore` file alongside our `Dockerfile`.
    The format is simple and may be familiar if you’ve worked with `.gitignore` files
    before. As shown in the next code snippet, each line expresses a pattern (standard
    shell wildcarding allowed) that Docker should ignore when finding files to copy:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当前的`Dockerfile`中导致此类缓存失效的一个来源是将完整的项目目录复制到容器中。任何文件更改，无论多小，都会使`COPY . .`行失效，我们必须重新运行之后的所有内容。尽管如此，有些本地文件可能对我们的构建并不重要——例如，我们的git历史、IDE文件和本地构建输出实际上不需要最终出现在我们的构建容器镜像中。幸运的是，我们可以通过在`Dockerfile`旁边放置一个`.dockerignore`文件来排除这些文件。格式简单，如果你之前使用过`.gitignore`文件，可能会很熟悉。如下代码片段所示，每一行都表达了一个模式（允许标准shell通配符），Docker在查找要复制的文件时应忽略：
- en: '[PRE18]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: A second more subtle issue is with our Gradle wrapper. If we watch the output
    when running the build, we’ll see that it spends a while on startup downloading
    the proper distribution. Because our containers start without any of Gradle’s
    local caching, this download repeats each time we run.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个更为微妙的问题是我们的Gradle包装器。如果我们运行构建时观察输出，我们会看到它在启动时花费一段时间下载正确的分发。由于我们的容器启动时没有Gradle的本地缓存，这个下载每次运行都会重复。
- en: 'Avoiding this repetition requires breaking out a first execution of Gradle
    into a separate set of layers which happen before copying our full project into
    the container, as shown next. We want to copy only the minimum required for Gradle
    to run its download, so this layer’s cache breaks only if we alter our Gradle
    wrapper (e.g., updating the version):'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 避免这种重复需要将Gradle的第一次执行分离成一组单独的层，这些层在将我们的完整项目复制到容器之前发生。我们只想复制Gradle运行下载所需的最小文件，因此这个层的缓存只有在我们的Gradle包装器被更改（例如，更新版本）时才会失效：
- en: '[PRE19]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Copies just enough Gradle configuration to run
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 仅复制足够的Gradle配置以运行
- en: ❷ Running ./gradlew alone forces the distribution download, now cached in its
    own layer.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 仅运行`./gradlew`会强制下载分发，现在它被缓存在自己的层中。
- en: ❸ Our build carries on as before, with our COPY likely refreshed every time
    (assuming our code changed).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 我们的构建继续进行，我们的`COPY`操作很可能每次都会刷新（假设我们的代码已更改）。
- en: This is just the beginning of the sorts of optimizations that can be applied
    in the construction of your container images. The key to take away is carefully
    considering what belongs in each layer. If parts of your system will change at
    different paces, giving them separate layers may be beneficial.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是你在构建容器镜像时可以应用的各种优化类型的一个开始。需要记住的关键点是仔细考虑每个层应该包含什么。如果你的系统部分将以不同的速度发生变化，为它们提供单独的层可能是有益的。
- en: We’ve shown a fairly raw approach to building Docker images. As you might expect,
    a ton of plugins for both Maven and Gradle exist if you want to wrap up this functionality
    and not hand-code your Dockerfiles. There are even options like Jib ([https://github.com/GoogleContainerTools/jib](https://github.com/GoogleContainerTools/jib)),
    which avoid using the Docker tools at all. All of these are useful, but a well-grounded
    developer is aided by understanding more deeply how containers are built, even
    if they get help doing it day to day.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经展示了构建Docker镜像的相当原始的方法。正如你可能预料的那样，如果你想要封装这个功能而不手动编写Dockerfile，Maven和Gradle都有一系列插件。甚至有像Jib([https://github.com/GoogleContainerTools/jib](https://github.com/GoogleContainerTools/jib))这样的选项，可以完全不使用Docker工具。所有这些都很实用，但一个扎实的开发者通过更深入地了解容器是如何构建的，即使他们在日常工作中得到帮助，也会得到帮助。
- en: 12.3.4 Ports and hosts
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.4 端口和主机
- en: Along with providing our application with its own isolated filesystem, containers
    also do the same for the network. With our sample application, let’s imagine that
    we added code to run a standard HTTP server, for example, the basic one provided
    in the JDK at `com.sun.net.httpserver.HttpServer`. If we `docker run` our container,
    we’ll find that there’s no way to call that HTTP endpoint.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 除了为我们应用程序提供其自己的独立文件系统外，容器还为网络做了同样的事情。以我们的示例应用程序为例，让我们假设我们添加了代码来运行一个标准的HTTP服务器，例如，在JDK中提供的`com.sun.net.httpserver.HttpServer`中的基本服务器。如果我们运行我们的容器，我们会发现没有方法可以调用那个HTTP端点。
- en: 'To address this, we need to ask Docker to make a port available to us. We can
    do this directly by adding to our run command as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们需要要求Docker为我们提供一个可用的端口。我们可以通过直接添加到我们的运行命令来实现这一点，如下所示：
- en: '[PRE20]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '`-p` takes a pair of ports separated by a `:`. The first value is the port
    that we want available *outside* the container. The second value is the port that
    our software *inside* the container is listening on. If we go to another terminal
    (or a web browser) we can see it working, as shown here and in figure 12.6:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`-p`接受一个由冒号分隔的端口对。第一个值是我们希望在容器外部可用的端口。第二个值是我们软件在容器内部监听的端口。如果我们去另一个终端（或网页浏览器），我们可以看到它的工作情况，如下所示，以及图12.6：'
- en: '[PRE21]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](../Images/CH12_F06_Evans2.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F06_Evans2.png)'
- en: Figure 12.6 Exposing a port in Docker
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 在Docker中暴露端口
- en: 'As you might expect from the format and Figure 12.6, these two port values
    don’t have to match. If we instead run with this command-line:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如你从格式和图12.6中预期的那样，这两个端口值不必匹配。如果我们使用以下命令行运行：
- en: '[PRE22]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Port 9000 will be visible outside the container, connected to port 8080 on
    the process inside the container.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 端口9000将在容器外部可见，连接到容器内部进程的端口8080。
- en: 'we’ll now see a good response on port 9000, whereas 8080 is no longer accessible,
    as shown here:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将在端口9000上看到良好的响应，而8080不再可访问，如下所示：
- en: '[PRE23]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Exposing ports is such a fundamental part of how containers are deployed that
    the `Dockerfile` allows us to note the ports our image is expected to provide,
    like this:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 暴露端口是容器部署的基本部分，因此`Dockerfile`允许我们记录我们的镜像预期提供的端口，如下所示：
- en: '[PRE24]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'If we set this, `docker build` again, and run without the port switches, you
    might be surprised to find that Docker doesn’t default to making the `EXPOSE`
    ports available. However, if you provide the `-P` switch by itself (note the uppercase
    and lack of arguments), Docker will bind each `EXPOSE` port in our image to a
    random, or *ephemeral*, port. Because we can’t guess what port will be assigned,
    we need a new command to peek and find our ephemeral port. This is done with `docker
    ps` as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们设置这个，再次运行`docker build`，并且不使用端口开关运行，你可能会惊讶地发现Docker不会默认使`EXPOSE`端口可用。然而，如果你只提供`-P`开关（注意大写和没有参数），Docker将把我们的镜像中的每个`EXPOSE`端口绑定到一个随机或*临时*端口。因为我们无法猜测分配的端口是什么，我们需要一个新的命令来窥视并找到我们的临时端口。这可以通过以下`docker
    ps`来完成：
- en: '[PRE25]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The value `0.0.0.0:55031->8080/tcp` tells us that port 55031 outside the container
    is bound to port 8080 inside.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 值`0.0.0.0:55031->8080/tcp`告诉我们，容器外部的端口55031绑定到了容器内部的端口8080。
- en: This ephemeral port business may seem like an annoyance at first, particularly
    when testing, because the port shifts around. But it’s actually a critical feature
    when running containers in production. Imagine that you have a host that you want
    to fully utilize running many different Java containers. Each of those applications
    may want to run using the same port, but the host can assign that port only once.
    Although it requires additional coordination in other parts of the system, assigning
    ephemeral ports allows the containers to keep their simpler view of the world—“I
    run on 8080”—while still coexisting in a broader, more complex environment.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 这种临时端口的业务可能一开始看起来像是一种烦恼，尤其是在测试时，因为端口会变动。但实际上，当在生产环境中运行容器时，这是一个关键特性。想象一下，你有一个主机，你希望充分利用它运行许多不同的
    Java 容器。这些应用程序中的每一个都可能想要使用相同的端口，但主机只能分配一次该端口。尽管这需要在系统的其他部分进行额外的协调，但分配临时端口允许容器保持对世界的简单看法——“我运行在
    8080”——同时仍然在一个更广泛、更复杂的环境中共存。
- en: That gets us set to talk to our application when running it in a container locally.
    But what about the other direction—when our container needs to reach out to another
    services such as a database?
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们准备好在本地运行容器时与我们的应用程序进行通信。但另一方面——当我们的容器需要连接到其他服务，如数据库时，怎么办呢？
- en: When we’re running in production, it’s a good practice to explicitly configure
    locations of services and use normal load balancing and DNS to reach them. These
    can be injected into containers via environment variables or other service discovery
    systems, but the key is that you don’t assume where resources are located in relation
    to your container.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在生产环境中运行时，明确配置服务位置并使用正常的负载均衡和 DNS 来访问它们是一种良好的做法。这些可以通过环境变量或其他服务发现系统注入到容器中，但关键是你不要假设资源相对于你的容器所在的位置。
- en: But this gets much harder when working locally, because a normal developer setup
    isn’t going to have that same sort of infrastructure available. If you’re using
    Docker for Mac or Docker for Windows, you can use the name `host.docker.internal`
    inside your containers, which automatically points to your host machine. Docker
    for Linux can have the same set on container startup with the `--add-host host.docker.internal
    :host-gateway` flag. In these cases, if your application is set up to receive
    such locations via environment variables, you can point your container to that
    hostname.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 但在本地工作时，这会变得更加困难，因为普通的开发者设置不会提供那种类型的基础设施。如果你使用 Docker for Mac 或 Docker for Windows，你可以在容器内部使用名称
    `host.docker.internal`，它自动指向你的主机机器。Docker for Linux 可以在容器启动时使用 `--add-host host.docker.internal
    :host-gateway` 标志设置相同的设置。在这些情况下，如果你的应用程序设置为通过环境变量接收此类位置，你可以将你的容器指向该主机名。
- en: If this doesn’t work for your given environment, an IP address for your host
    exists inside the container. Commands such as `sudo ip addr show` may give you
    hints on the location, but this gets tedious in a hurry.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这在你给定的环境中不起作用，容器内部存在一个主机的 IP 地址。例如，`sudo ip addr show` 这样的命令可能会给你一些关于位置的提示，但这很快就会变得繁琐。
- en: Containers have a lot of networking options that are beyond the scope of this
    book, but some of them that can help us with this exact issue are used by a tool
    called Docker Compose. Let’s see how containers can help us locally solve our
    external resource access problems.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 容器拥有许多网络选项，这些选项超出了本书的范围，但其中一些可以帮助我们解决这个具体问题的选项被一个名为 Docker Compose 的工具所使用。让我们看看容器如何帮助我们本地解决外部资源访问问题。
- en: 12.3.5 Local development with Docker Compose
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.5 使用 Docker Compose 进行本地开发
- en: Much like the dreaded install list for a new project, it’s common for applications
    to also require multiple other services at runtime as well. Maybe you’ve got a
    database, a cache, a NoSQL store, or even other custom applications, which all
    have to be up and running for your application to work locally.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 就像令人畏惧的新项目安装列表一样，应用程序在运行时通常也需要多个其他服务。也许你有一个数据库、一个缓存、一个 NoSQL 存储，甚至其他自定义应用程序，所有这些都必须运行起来，你的应用程序才能在本地工作。
- en: Docker Compose is a tool for declaring and running sets of containers. It lets
    us capture the precise set of services and start them together. It also manages
    saving state for these containers so we can stop and restart without having to
    do everything from scratch.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose 是一个用于声明和运行容器集的工具。它让我们能够捕获精确的服务集并一起启动它们。它还管理这些容器的状态保存，这样我们就可以停止和重新启动，而无需从头开始做所有事情。
- en: If this sounds similar to orchestration tools like Kubernetes, you’re not wrong.
    There is overlap in the container management aspects of both tools. However, Docker
    Compose is aimed at running on a single machine, which excludes it as a reasonable
    choice for many production environments.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这听起来类似于 Kubernetes 这样的编排工具，你并没有错。这两个工具在容器管理方面有重叠。然而，Docker Compose 是针对单台机器运行的，这使其不适合许多生产环境。
- en: Note Docker Compose was originally a separate tool, but it has been integrated
    as another command within `docker` itself. If you see information on the internet
    suggesting running `docker-compose`, you can just replace the `-` with a space
    these days.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 Docker Compose 最初是一个独立的工具，但它已被集成到 `docker` 本身中的另一个命令中。如果你在网上看到有关运行 `docker-compose`
    的信息，现在你只需将 `-` 替换为空格即可。
- en: 'By default we describe our configuration in a file called `docker-compose.yml`.
    For a start, let’s tell Docker Compose about our application as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，我们在名为 `docker-compose.yml` 的文件中描述我们的配置。首先，让我们这样告诉 Docker Compose 关于我们的应用程序：
- en: '[PRE26]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ The Docker Compose file version
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Docker Compose 文件版本
- en: ❷ Declares a service to run called app
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 声明一个名为 app 的服务来运行
- en: ❸ Instructs Docker Compose to run a typical docker build in the current directory
    to generate the image for this service
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 指示 Docker Compose 在当前目录中运行一个典型的 Docker 构建来生成此服务的镜像
- en: ❹ Port declarations, like on our manual docker run before
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 端口声明，就像我们在之前的手动 docker run 中做的那样
- en: 'We run this at the command line with `docker compose up`. This will show our
    familiar build output as it starts, and then some new output as it starts our
    container, as shown next:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在命令行中使用 `docker compose up` 运行它。这将显示我们熟悉的构建输出，当它启动时，然后显示一些新的输出，当它启动我们的容器时，如下所示：
- en: '[PRE27]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Our `docker-compose.yml` can contain multiple services, as we’ll see in a moment.
    The output from each gets prefixed with a name to distinguish them, by default
    based on our current directory and the service name, so ours is `docker-gradle-app-1`.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `docker-compose.yml` 可以包含多个服务，我们将在稍后看到。每个服务的输出都带有名称前缀以区分它们，默认情况下基于我们的当前目录和服务名称，因此我们的名称是
    `docker-gradle-app-1`。
- en: 'Let’s say that our application needs a Redis instance. We add that as a new
    key we’ll call `redis` under the `services` key like this:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的应用程序需要一个 Redis 实例。我们将其添加为一个新的键，我们将其称为 `redis`，在 `services` 键下，如下所示：
- en: '[PRE28]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: ❶ The redis:alpine image from Docker Hub
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 来自 Docker Hub 的 redis:alpine 镜像
- en: 'Now when we run, Docker Compose will pull the `redis:alpine` image and start
    it with our application container. Figure 12.7 and the next code sample illustrate
    these containers running in relation to each other:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们运行时，Docker Compose 将拉取 `redis:alpine` 镜像，并使用我们的应用程序容器启动它。图 12.7 和接下来的代码示例说明了这些容器之间的关系：
- en: '[PRE29]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: ❶ Redis container output
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Redis 容器输出
- en: ❷ Our application container output
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 我们的应用程序容器输出
- en: '![](../Images/CH12_F07_Evans2.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F07_Evans2.png)'
- en: Figure 12.7 Docker Compose containers running
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.7 Docker Compose 容器运行
- en: This is already convenient—we can get the precise right version of our databases
    and other external services locally without manual installation. But Docker Compose
    brings another helpful feature to avoid many of the networking struggles we saw
    before. During initial startup, there was a message reading `Network docker-gradle_default
    Created`. This informed us that Docker Compose had created a new, separate network
    namespace `docker-gradle_default`. This network is shared between all the services
    that Docker Compose has started for us. Even better, each service name we spelled
    out in our `docker-compose.yml`—`app` and `redis`—shows up like a real host name
    inside all of the containers.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这已经很方便了——我们可以本地获取数据库和其他外部服务的精确版本，而无需手动安装。但是 Docker Compose 带来了另一个有用的功能，可以避免我们之前看到的许多网络问题。在初始启动期间，有一条消息显示
    `Network docker-gradle_default Created`。这告诉我们 Docker Compose 创建了一个新的、独立的网络命名空间
    `docker-gradle_default`。这个网络在我们为 Docker Compose 启动的所有服务之间共享。更好的是，我们在 `docker-compose.yml`
    中指定的每个服务名称——`app` 和 `redis`——在所有容器内部都显示为真实的主机名。
- en: 'If we’ve designed our application with the Twelve-factor principles and pass
    in the location of Redis via an environment variable, we can configure this entirely
    in the `docker-compose.yml`, as shown here:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们根据十二要素原则设计了我们的应用程序，并通过环境变量传递 Redis 的位置，我们可以在 `docker-compose.yml` 中完全配置它，如下所示：
- en: '[PRE30]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ❶ The first redis is the URL scheme, and the second redis is the hostname.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 第一个 redis 是 URL 方案，第二个 redis 是主机名。
- en: This just scratches the surface of Docker Compose. All the common options for
    controlling `docker run` can be set in `docker-compose.yml`, and it’s a great
    way to smooth ramp-up on local development.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是Docker Compose表面的冰山一角。所有控制`docker run`的常见选项都可以在`docker-compose.yml`中设置，这是平滑本地开发的一个很好的方法。
- en: 12.3.6 Debugging in Docker
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.6 Docker中的调试
- en: 'When our software isn’t behaving, sometimes we need to peek inside the boundaries
    that our containers set up for us. Earlier we met `docker ps` for determining
    the port that our container was exposing. `docker ps` provides us more information
    than just that, though. In particular, by default, a container is given a handy,
    randomly generated name that it can be referred to by, as shown next:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的软件表现不佳时，有时我们需要查看容器为我们设置的边界内部。之前我们遇到了`docker ps`来确定容器暴露的端口。然而，`docker ps`提供的信息远不止这些。特别是，默认情况下，容器会被赋予一个方便的、随机生成的名称，我们可以通过它来引用，如下所示：
- en: '[PRE31]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This container can be referred to as `vigilant_austin`. If you want to avoid
    having the name change every time your container runs, you can control this with
    the `--name container-name` parameter on `docker run`. You’ll want to couple that
    with `--rm` to remove the container when it exits; otherwise, the name won’t be
    available for reuse the second time you run.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这个容器可以被称为`vigilant_austin`。如果你想要避免每次容器运行时名称都改变，你可以在`docker run`的`--name container-name`参数上控制它。你可能会想将它与`--rm`结合使用，以便在容器退出时删除它；否则，名称在第二次运行时将不可用。
- en: 'Having the name of the container allows us to take other debugging steps. With
    `docker exec`, we can execute commands in the running container. As we saw with
    `docker run -it` before, we can even get an interactive shell inside the container,
    as shown here, assuming it has `bash` or something similar installed:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 有了容器的名称，我们可以采取其他调试步骤。使用`docker exec`，我们可以在运行中的容器中执行命令。正如我们之前在`docker run -it`中看到的那样，我们甚至可以在容器内获得一个交互式shell，如下所示，假设它已安装了`bash`或类似的东西：
- en: '[PRE32]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: It’s important to remember that `exec` doesn’t start a new container—it attaches
    to an existing one. Figure 12.8 shows how the processes coexist within the single
    container.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要记住，`exec`不会启动一个新的容器——它只是附加到一个现有的容器上。图12.8展示了进程如何在单个容器中共存。
- en: '![](../Images/CH12_F08_Evans2.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F08_Evans2.png)'
- en: Figure 12.8 `docker exec` into a container
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 `docker exec`进入容器
- en: 'We aren’t limited to just basic Unix commands, though. For instance, we can
    use `jps` and `jcmd` to inspect the running JVMs in our container as follows:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们并不局限于仅使用基本的Unix命令，例如，我们可以使用`jps`和`jcmd`来检查容器中运行的JVM，如下所示：
- en: '[PRE33]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In chapter 7, we explored the deep visibility we can gain with the JFR (JDK
    Flight Recorder) tools. With a shell into the running container, we can gather
    JFR data with a few simple commands. If it’s not already running, we tell JFR
    to start recording like this:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在第7章中，我们探讨了使用JFR（JDK飞行记录器）工具可以获得的深度可见性。通过进入运行中的容器，我们可以使用几个简单的命令来收集JFR数据。如果它还没有运行，我们告诉JFR像这样开始记录：
- en: '[PRE34]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'After we’ve let the application gather data for a while, we save the current
    recording to a file inside the container as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在让应用程序收集数据一段时间后，我们将当前记录保存到容器内的文件中，如下所示：
- en: '[PRE35]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'To inspect the file offline, we’ll need to copy it out of the container. Back
    on our host system, we can do this with the `docker cp` command, as shown in the
    next code sample. Again, our container name comes in handy to specify where to
    grab the file from:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 要离线检查文件，我们需要将其从容器中复制出来。回到我们的主机系统，我们可以使用`docker cp`命令来完成，如下面的代码示例所示。同样，我们的容器名称在这里派上了用场，可以用来指定从哪里获取文件：
- en: '[PRE36]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: ❶ The first parameter to cp is the file source, and the second, its destination.
    It’s specified with the format container-name:path. The second parameter is local,
    so we don’t need a container name and just use the path.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ `cp`命令的第一个参数是文件源，第二个参数是目标。它以`container-name:path`的格式指定。第二个参数是本地的，所以我们不需要容器名称，只需使用路径。
- en: '`capture.jfr` is now available on your local system to open via JDK Mission
    Control (JMC).'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`capture.jfr`现在可在您的本地系统上打开，通过JDK任务控制（JMC）。'
- en: Because Docker exposes an API, your `docker` commands can be pointed at a remote
    host instead of your local environment. See the Docker documentation at [https://docs.docker.com/](https://docs.docker.com/)
    for details on how to configure that.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 因为Docker公开了一个API，所以你的`docker`命令可以指向远程主机而不是本地环境。有关如何配置的详细信息，请参阅Docker文档[https://docs.docker.com/](https://docs.docker.com/)。
- en: 'All of these shells and command-line options are good for getting at the low
    level of what’s happening in our containers. But what if we just want a breakpoint
    in our IDE for the Java application in a local container? Fortunately the JDK’s
    remote debugging facilities have all the pieces we need to configure this, as
    shown next:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些shell和命令行选项都是获取我们容器中发生事情的低级别信息的好方法。但如果我们只想在本地容器中的Java应用程序的IDE中设置一个断点呢？幸运的是，JDK的远程调试功能包含了我们配置此功能所需的所有组件，如下所示：
- en: '[PRE37]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In addition to the normal output of our application starting up, you should
    see a message like this indicating the remote debugging port is available:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 除了应用程序启动的正常输出外，你还应该看到如下消息，表明远程调试端口可用：
- en: '[PRE38]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: From here you can use your IDE features to debug a Remote JVM, pointed at port
    8090\. Everything should behave much like debugging the application on your local
    environment, but all from the cozy, bounded world of the container.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，你可以使用你的IDE功能来调试指向端口8090的远程JVM。一切都应该表现得与在本地环境中调试应用程序非常相似，但都是在容器这个舒适、受限的世界中。
- en: 12.3.7 Logging with Docker
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.7 使用Docker进行日志记录
- en: As we’ve seen repeatedly, the separation that containers introduce from their
    host environment requires a change of mind-set. One common stumbling block is
    logging. Whether you use one of the popular logging frameworks or simply write
    to `System .out`, it’s common for a service to produce output when running. We
    don’t want to lose access to this information just because we’ve moved into a
    container.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们反复看到的，容器从其宿主环境引入的隔离需要思维方式的转变。一个常见的障碍是日志记录。无论你使用的是流行的日志框架还是简单地写入`System.out`，在运行时产生输出是很常见的。我们不想因为迁移到容器而失去对这些信息的访问。
- en: 'You can take a manual approach with techniques we’ve already seen in this chapter.
    Simply write your logs to disk as before. When you need to examine them, you can
    use `docker exec` or `docker cp` to access to the files like this:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用我们在本章中已经看到的技术采取手动方法。简单地像以前一样将你的日志写入磁盘。当你需要检查它们时，你可以使用`docker exec`或`docker
    cp`来访问文件，如下所示：
- en: '[PRE39]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: However, this introduces some friction in retrieving this information—and the
    potential for data loss if the container is fully removed prematurely.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这引入了一些在检索这些信息时的摩擦，并且如果容器过早完全移除，可能会导致数据丢失。
- en: A common practice—with or without containers—is to forward logs from the application
    to a central location. The destination of this forwarding could be just centralized
    storage, an indexing service such as Elasticsearch, or even a fully external logging
    provider.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的做法——无论是否有容器——是将应用程序的日志转发到中央位置。这个转发的目的地可以是集中式存储，一个索引服务，如Elasticsearch，甚至是一个完全外部的日志提供商。
- en: If we try to keep the simple practice of writing to a local file in our containers,
    though, we must answer the question of where our log-forwarding application runs.
    Putting it inside the containers consumes additional memory and resources we need
    to account for, and generally it’s recommended to avoid having multiple things
    within a single container. Containers allow for mounting a volume so log files
    could be shared between the containers and host, but this requires configuration
    and isn’t always performant.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果我们试图在容器中保持将日志写入本地文件的简单做法，我们必须回答我们的日志转发应用程序在哪里运行的问题。将其放入容器中会消耗额外的内存和资源，我们需要考虑，通常建议避免在单个容器中放置多个东西。容器允许挂载卷，这样日志文件可以在容器和主机之间共享，但这需要配置，并且并不总是性能最佳。
- en: A better alternative is to lean on the fact that Docker captures anything our
    containers write to the typical output streams, `STDOUT` and `STDERR`. On the
    host, these streams are saved to well-known file locations for every container
    being run. This simplifies configuration because we can install log forwarding
    once on the host and just tell our individual containers to write to `STDOUT`
    instead of files. It’s also compatible with existing logging libraries such as
    `log4j2`, which has appenders to write to `CONSOLE` for exactly this purpose.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更好的选择是依靠Docker捕捉我们的容器写入典型输出流的事实，即`STDOUT`和`STDERR`。在主机上，这些流被保存到每个正在运行的容器的已知文件位置。这简化了配置，因为我们可以在主机上一次性安装日志转发，并只需告诉我们的各个容器将日志写入`STDOUT`而不是文件。它还与现有的日志库兼容，例如`log4j2`，它有写入`CONSOLE`的附加器，正好用于这个目的。
- en: 'This type of infrastructure setup around how to run your containers and capture
    their logs is an example of issues that come with scaling containers beyond a
    single host. Providing a systematic way to address such questions is one of the
    key benefits of our next topic: Kubernetes.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这种围绕如何运行容器和捕获其日志的基础设施设置是一个例子，说明了在单个主机之外扩展容器时可能出现的问题。提供一种系统化的方法来回答这些问题是我们下一个主题的关键好处之一：Kubernetes。
- en: 12.4 Kubernetes
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 Kubernetes
- en: This introduction to Docker really only scratches the surface of configuring
    and customizing our containers. In a real production environment, you may need
    many instances of your containers. Managing large fleets of containers with just
    `docker` commands quickly gets out of control, and it’s not uncommon for a production
    environment to have hundreds of separate containers. You need to automate these
    tasks. The general term for such automation is an *orchestrator*, and although
    there are many options in the field, Kubernetes is the dominant solution.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这本Docker入门书实际上只是触及了配置和定制我们容器的表面。在实际的生产环境中，您可能需要许多容器实例。仅使用`docker`命令管理大量容器会很快变得难以控制，并且生产环境中有数百个独立的容器并不罕见。您需要自动化这些任务。此类自动化的通用术语是*编排器*，尽管该领域有许多选项，但Kubernetes是主导解决方案。
- en: Kubernetes (often referred to as K8s) is an open source project originally derived
    out of Google’s internal work on container orchestration. At its heart, it provides
    standard, API-driven tools to describe the desired state for a system and then
    ensure that state is maintained over time.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes（通常称为K8s）是一个开源项目，最初源于谷歌在容器编排方面的内部工作。在其核心，它提供了一套标准、API驱动的工具来描述系统的期望状态，并确保该状态在一段时间内得到维护。
- en: Kubernetes models your system as a set of *objects* of different types. A set
    of *controllers* run continually, watching the actual state of the system and
    applying changes (such as creating a new container if an old one dies) so the
    desired and actual state of the system match.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes将您的系统建模为不同类型的*对象*集合。一组*控制器*持续运行，监视系统的实际状态并应用更改（例如，如果旧容器死亡则创建一个新的容器），以确保系统的期望状态和实际状态相匹配。
- en: A full treatment of Kubernetes is far beyond the scope of this book, but to
    get a taste of how it works, let’s look at the most basic object types and how
    we’d use them with the container skills we’ve gotten so far.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 对Kubernetes的全面介绍远远超出了本书的范围，但为了了解其工作原理，让我们看看最基本的对象类型以及我们如何使用我们迄今为止获得的容器技能来使用它们。
- en: '*Cluster*—A single installation of Kubernetes on anything from a single machine
    to many hundreds of nodes'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Cluster*—在单台机器到数百个节点上的单个Kubernetes安装'
- en: '*Node*—A single machine (virtual or physical) in the cluster'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Node*—集群中的单个机器（虚拟或物理）'
- en: '*Pod*—A deployable unit of one (or more) containers'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pod*—一个可部署的容器单元（或多个容器）'
- en: '*Deployment*—A declarative way to deploy a pod'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Deployment*—部署Pod的声明性方式'
- en: '*Service*—An object exposing containers in the cluster to callers'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Service*—一个对象，将集群中的容器暴露给调用者'
- en: To step through these ideas and demonstrate we’ll use `minikube`, a local development
    environment from the Kubernetes project itself. See the linked instructions for
    current installation instructions on your OS ([https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 为了逐步介绍这些概念并演示，我们将使用`minikube`，这是Kubernetes项目本身提供的本地开发环境。请参阅链接中的说明，获取您操作系统上的当前安装说明（[https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)）。
- en: 'Once installed we can start a local cluster with the command `minikube start`,
    as shown next. Note this may take several minutes the first time to download all
    the required images:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，我们可以使用`minikube start`命令启动本地集群，如下所示。请注意，第一次可能需要几分钟来下载所有必需的镜像：
- en: '[PRE40]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Our Kubernetes cluster is now running locally. We can stop the cluster with
    the `minikube stop` command or, if we’re entirely finished experimenting, remove
    it with `minikube delete`.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在运行的Kubernetes集群是本地的。我们可以使用`minikube stop`命令停止集群，或者如果我们完全完成了实验，可以使用`minikube
    delete`命令将其删除。
- en: 'Although Kubernetes provides a REST API for systems to interact with, there’s
    a convenient wrapper more suitable for human consumption via the `kubectl` command.
    We can use this to view, create, and edit the objects in our cluster. For instance,
    `minikube` takes care of creating our node objects by default, but we can `kubectl
    describe node` to see what it set up on our behalf. This listing highlights only
    a few portions of the output as it provides a lot of detail:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Kubernetes为系统提供了REST API以进行交互，但通过`kubectl`命令有一个更适合人类消费的方便包装器。我们可以使用它来查看、创建和编辑集群中的对象。例如，`minikube`默认负责创建我们的节点对象，但我们可以使用`kubectl
    describe node`来查看它代表我们设置了什么。此列表仅突出显示输出的一小部分，因为它提供了大量详细信息：
- en: '[PRE41]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: ❶ Kubernetes itself runs in pods on the node, listed here.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Kubernetes本身在节点上运行在Pod中，如下所示。
- en: ❷ Events can be helpful when debugging if unexpected problems occur in a node.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 如果节点中出现意外问题时，事件可能会有所帮助。
- en: With `minikube` providing our cluster and node, we’re ready to run some software.
    To keep things simple we’ll use the `k8s.gcr.io/echoserver:1.4` image, which as
    the name suggests just echoes back information about HTTP requests sent to it.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`minikube`为我们提供了集群和节点，我们已准备好运行一些软件。为了保持简单，我们将使用`k8s.gcr.io/echoserver:1.4`镜像，正如其名称所暗示的，它只是将发送给它的HTTP请求的信息回显。
- en: Note `minikube` supports working with local images, but it runs a separate Docker
    daemon, so the image management gets a little more complex. Consult the README
    at [https://github.com/kubernetes/minikube](https://github.com/kubernetes/minikube)
    if you are looking to do more local development using `minikube`. We’ll stick
    to published images in our examples to keep it simple.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`minikube`支持使用本地镜像进行工作，但它运行一个独立的Docker守护进程，因此镜像管理变得稍微复杂一些。如果您想使用`minikube`进行更多本地开发，请参阅[https://github.com/kubernetes/minikube](https://github.com/kubernetes/minikube)的README。在我们的示例中，我们将坚持使用已发布的镜像以保持简单。
- en: 'Our first goal is to get a pod on the cluster running the `echoserver` container.
    We do that by asking `kubectl` to create a deployment, as shown in the next code
    snippet. The deployment object tells the Kubernetes cluster the desired state
    of having our pod running. Kubernetes’s control loop notices the desired state
    doesn’t match reality and start our pods for us to address that:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的首要目标是让集群上运行`echoserver`容器的Pod运行。我们通过请求`kubectl`创建一个部署来实现这一点，如以下代码片段所示。部署对象告诉Kubernetes集群我们希望Pod运行的状态。Kubernetes的控制循环注意到期望状态与实际情况不匹配，并为我们启动Pod以解决这个问题：
- en: '[PRE42]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We can inspect the cluster to see that our deployment exists using the standard
    `kubectl get` command, as follows. This command works across any type of object
    in the system:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用标准的`kubectl get`命令检查集群，以查看我们的部署是否存在，如下所示。此命令适用于系统中的任何类型的对象：
- en: '[PRE43]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: If we look for pods, we’ll also see shortly that the cluster has aligned its
    actual state with what our deployment requested, as shown here. Figure 12.9 gives
    a visual of the single pod state we’ve reached.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查找Pod，我们很快就会看到集群已经将其实际状态与我们的部署请求对齐，如下所示。图12.9展示了我们达到的单个Pod状态。
- en: '[PRE44]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![](../Images/CH12_F09_Evans2.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F09_Evans2.png)'
- en: Figure 12.9 Kubernetes cluster with one pod running
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9运行一个Pod的Kubernetes集群
- en: 'The `kubectl create deployment` command is an easy way to get started, but
    its arguments only scratch the surface of what Kubernetes can configure. The natural
    representation of a Kubernetes object is given in YAML, and we can access the
    full picture via `kubectl edit deployment echoes`, as shown in the next code sample.
    This will open your default editor with the object’s current YAML. If you make
    changes to the file, they are applied when the editor exits. We won’t discuss
    all of these options, so refer to the documentation at [http://mng.bz/M5m2](http://mng.bz/M5m2)
    for further information:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl create deployment`命令是一个简单的入门方式，但它的参数只是触及了Kubernetes可以配置的表面。Kubernetes对象的自然表示形式是YAML，我们可以通过`kubectl
    edit deployment echoes`来访问完整的图片，如下所示。这将打开您的默认编辑器，并显示对象的当前YAML。如果您对文件进行了更改，它们将在编辑器退出时应用。我们不会讨论所有这些选项，因此请参阅[http://mng.bz/M5m2](http://mng.bz/M5m2)的文档以获取更多信息：'
- en: '[PRE45]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: ❶ The echoes name we gave our deployment
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们为部署给出的echo名称
- en: ❷ spec describes the desired state of our deployment.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ spec描述了我们的部署所需的状态。
- en: ❸ An important value we’ll discuss in a moment that determines the number of
    pods we want running
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 我们将在稍后讨论的一个重要值，它决定了我们希望运行的Pod数量
- en: ❹ The image we requested for our pods to run
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 我们为Pod运行请求的镜像
- en: ❺ status tells us what’s currently observed about the state of the deployment.
    Note that it also has replicas, telling us how many are seen running now.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ `status` 告诉我们目前观察到的部署状态。请注意，它还有一个副本，告诉我们现在有多少正在运行。
- en: 'What happens if we change the `spec` value of `replicas: 1` to `3`? Kubernetes
    will see the mismatch between the deployment state and what’s actually on the
    cluster and start new containers on our behalf, as shown next. Figure 12.10 shows
    the result after the containers have had a chance to start up.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '如果我们将 `replicas: 1` 的 `spec` 值更改为 `3`，会发生什么？Kubernetes 会看到部署状态与集群实际状态之间的不匹配，并代表我们启动新的容器，如下所示。图
    12.10 显示了容器启动后的结果。'
- en: '[PRE46]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![](../Images/CH12_F10_Evans2.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F10_Evans2.png)'
- en: Figure 12.10 Kubernetes cluster with multiple pods running
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.10 多个 pod 运行的 Kubernetes 集群
- en: In practice, you likely won’t be hand-editing YAML files on a production Kubernetes
    cluster, but all the tooling builds on this—CI/CD systems, generated or source-controlled
    Kubernetes manifests—are just helpers creating the right YAML and API calls for
    us.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你很可能不会在生产 Kubernetes 集群上手动编辑 YAML 文件，但所有工具都是基于此构建的——CI/CD 系统、生成的或源控制的 Kubernetes
    清单只是帮助我们创建正确的 YAML 和 API 调用的辅助工具。
- en: 'On our local system, the same tricks we played before with `docker ps` and
    `docker exec` will work to let us take a closer look at the running containers.
    Once we know the container name, `kubectl` has a slightly cleaner command for
    letting us start a shell inside the pod, as shown here:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的本地系统上，我们之前用 `docker ps` 和 `docker exec` 玩过的同样的技巧将适用于让我们更仔细地查看正在运行的容器。一旦我们知道容器名称，`kubectl`
    就有一个稍微干净一点的命令，允许我们在 pod 内部启动一个 shell，如下所示：
- en: '[PRE47]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: One last step is needed to make this deployment more useful. By default we can’t
    talk to the pods in the cluster at all. If we look at the `docker ps` for the
    containers, you’ll see that no ports are exposed.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 需要再进行最后一步才能使这次部署更有用。默认情况下，我们根本无法与集群中的 pod 进行通信。如果我们查看容器的 `docker ps`，你会看到没有任何端口被暴露。
- en: 'Kubernetes addresses this via its *service* abstraction, which is a general
    interface for working with various load balancing and traffic routing into the
    cluster. The details here quickly get beyond the scope of this introduction, but
    we’ll set up the simplest of them, called a `NodePort` with `kubectl expose`,
    as follows:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 通过其 *服务* 抽象来解决这一问题，这是一个用于处理集群中各种负载均衡和流量路由的通用接口。这里的细节很快就会超出本介绍的范畴，但我们将设置其中最简单的一个，称为
    `NodePort`，使用 `kubectl expose` 如下所示：
- en: '[PRE48]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: As seen in figure 12.11, this creates a new object in the cluster representing
    our `NodePort`.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 12.11 所示，这会在集群中创建一个新的对象，代表我们的 `NodePort`。
- en: '![](../Images/CH12_F11_Evans2.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F11_Evans2.png)'
- en: Figure 12.11 `NodePort` and services in the Kubernetes cluster
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.11 Kubernetes 集群中的 `NodePort` 和服务
- en: 'Viewing the services, we can see a `NodePort` configured in the cluster, as
    shown next:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 查看服务，我们可以看到集群中配置了 `NodePort`，如下所示：
- en: '[PRE49]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Internally, this means that port 8080 is available on every node in the cluster
    and will forward traffic to our pods. Now that we have a way for traffic to reach
    our pods, we still need to reveal this outside the cluster to be able to call
    it. `kubectl` supports this with its port-forwarding feature like this:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 内部来说，这意味着集群中的每个节点上都可用端口 8080，并将流量转发到我们的 pod。现在我们已经有了让流量到达我们的 pod 的方法，我们仍然需要将其暴露在集群外部才能调用它。`kubectl`
    通过其端口转发功能支持这一点，如下所示：
- en: '[PRE50]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: With this forwarding running in a terminal, we can visit 127.0.0.1:7080 in the
    browser, and we’ll see our request echoed back. Figure 12.12 shows the flow of
    traffic through the various components to the pods.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端中运行此转发，我们可以在浏览器中访问 127.0.0.1:7080，我们会看到我们的请求被回显。图 12.12 显示了流量通过各个组件到达 pod
    的流程。
- en: '![](../Images/CH12_F12_Evans2.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F12_Evans2.png)'
- en: Figure 12.12 Port-forwarding into our Kubernetes cluster
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.12 Kubernetes 集群中的端口转发
- en: Kubernetes is a large step up in complexity from just running our Docker containers
    locally, but it also provides a solution to the difficulties of running containers
    at scale. Whether or not we’re running on Kubernetes, though, we almost always
    care about the performance of our services. Let’s examine how to manage how well
    our containers are running in production.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的复杂性比仅在本地上运行我们的 Docker 容器要高得多，但它也提供了解决大规模运行容器困难的方法。然而，无论我们是否在 Kubernetes
    上运行，我们几乎总是关心我们服务的性能。让我们来看看如何管理我们的容器在生产中的运行情况。
- en: 12.5 Observability and performance
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.5 可观察性和性能
- en: Java technology was originally designed for a world where JVMs ran on bare metal
    in data centers, and where the developer could remain relatively isolated from
    (or even ignorant of) the details of the deployment environment. The world is
    changing at a fundamental level, however. Cloud native deployments—especially
    containers—are here and are being adopted quickly (but at varying rates across
    different parts of the industry).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: Java技术最初是为一个在数据中心裸金属上运行JVMs的世界而设计的，在这个世界中，开发者可以相对独立于（甚至对）部署环境的细节保持无知。然而，世界正在从根本上发生变化。云原生部署——尤其是容器——已经到来，并且正在迅速被采用（但不同行业的各个部分采用的速度不同）。
- en: Containers present some particular challenges for understanding the details
    of what is happening in a modern application. For example, it is not common practice
    for containers to run services such as an ssh daemon, making it impossible to
    log in to a container to observe what is happening. Instead, any data about the
    health of applications must be exported out of the container.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 容器在理解现代应用程序发生的细节方面提出了一些特定的挑战。例如，容器运行诸如ssh守护程序等服务并不是常见的做法，这使得无法登录到容器中观察正在发生的事情。相反，任何关于应用程序健康状况的数据都必须从容器中导出。
- en: The DevOps practice known as *observability* grew out of several separate strands
    of modern development practice, including both the application performance monitoring
    (APM) space and the need for visibility into orchestrated systems, such as Kubernetes.
    It aims to provide highly granular insights into the behavior of systems along
    with rich context. The techniques it provides are very useful, if not essential,
    for understanding and tuning the performance of Java applications in containers.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 被称为*可观测性*的DevOps实践源于现代开发实践的几个不同分支，包括应用性能监控（APM）领域以及对编排系统（如Kubernetes）可见性的需求。它的目标是提供对系统行为的非常细粒度的洞察，以及丰富的上下文。它提供的技术对于理解和调整容器中Java应用程序的性能非常有用，如果不是必不可少的。
- en: 12.5.1 Observability
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.1 可观测性
- en: 'Overall, observability is fairly simple set of concepts:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，可观测性是一个相当简单的概念集合：
- en: Instrument systems and applications to collect relevant data
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仪器化和应用程序以收集相关数据
- en: Send this data to a system that can store and analyze it (including query capability)
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些数据发送到可以存储和分析的系统（包括查询能力）
- en: Provide visualizations and insights into systems as a whole
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供对整个系统的可视化洞察
- en: The query and visualization capability is the key to the power of observability.
    It has been described as being the ability to “Get answers to questions that you
    didn’t know you’d need to ask”—and this is possible only via the collection of
    sufficient data to accurately model the system’s internal state.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 查询和可视化能力是可观测性力量的关键。它被描述为“回答你不知道需要问的问题”——而这只有通过收集足够的数据来准确建模系统的内部状态才能实现。
- en: 'Note The theory behind Observability comes from system control theory—essentially
    the question: “How well can the internal state of a system be inferred from outside?”'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：可观测性背后的理论来自系统控制理论——本质上是一个问题：“从外部可以多好地推断出系统的内部状态？”
- en: Ultimately, the goal is to be able to obtain *actionable* insights from, and
    about, the entire system. This should replace fragmentary views that are based
    on just one or two pieces of the overall system.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的目标是能够从整个系统中获得*可操作的*洞察，这应该取代仅基于整体系统的一两个部分的片段性观点。
- en: So, while incident resolution is an obvious use case that is a good fit for
    observability—it is where the practice originated after all—it is also true that
    the potential domain of applicability is much larger. If the right data is being
    collected, the stakeholders for observability are much broader than just software
    reliability engineers (SREs), production support, and DevOps folks.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，虽然事件解决是一个显然适合可观测性的用例——毕竟，这是该实践起源的地方——但事实也是，潜在的适用范围要大得多。如果收集了正确的数据，可观测性的利益相关者远不止软件可靠性工程师（SREs）、生产支持和DevOps人员。
- en: Observability is particularly relevant to containerized applications, because
    these deployments tend to be more complex than traditional on-premises applications.
    There are typically more services and components in cloud-deployed application,
    with more complex topology as well as a much faster pace of change (driven by
    practices such as continuous deployment).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性对于容器化应用程序尤其相关，因为这些部署通常比传统的本地应用程序更复杂。云部署的应用程序通常有更多的服务和组件，以及更复杂的拓扑结构，以及变化的速度更快（由持续部署等实践驱动）。
- en: This is also combined with the increasing popularity of new Cloud native technologies
    that have new operational behaviors. This includes Kubernetes, as well as Function
    as a Service deployments, such as AWS Lambda. This new world makes root cause
    analysis and incident resolution potentially a lot harder.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这也与新兴云原生技术的日益普及相结合，这些技术具有新的操作行为。这包括 Kubernetes，以及作为服务的函数部署，如 AWS Lambda。这个新世界使得根本原因分析和事件解决可能变得相当困难。
- en: 'Observability data is often conceptualized in terms of “three pillars.” This
    is a simple mental model (some would argue *too* simple) but is useful for developers
    who are new to observability. The pillars follow:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性数据通常用“三个支柱”来概念化。这是一个简单的思维模型（有些人可能会认为*太简单*），但对于刚开始接触可观察性的开发者来说很有用。支柱如下：
- en: '*Distributed traces*—Records of a single service invocation, corresponding
    to a single request from a user'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分布式跟踪*——单个服务调用的记录，对应于用户的一个请求'
- en: '*Metrics*—Values measuring specific activity over a time interval'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*度量*——在时间间隔内测量特定活动的值'
- en: '*Logs*—Immutable records of discrete events that happen over time (can be plain
    text, structured, or binary)'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*日志*——随时间发生的不变事件记录（可以是纯文本、结构化或二进制）'
- en: The core libraries and instrumentation components are all open source, and most
    of them are managed through industry bodies such as the Cloud Native Compute Foundation
    (CNCF).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 核心库和仪器组件都是开源的，其中大部分由云原生计算基金会（CNCF）等行业协会管理。
- en: OpenTelemetry
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry
- en: The OpenTelemetry project ([https://opentelemetry.io/](https://opentelemetry.io/)),
    a major project within CNCF, is a set of standards, formats, client libraries,
    and associated software components for providing observability. The standards
    are explicitly cross-platform and not tied to any particular technology stack.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 项目（[https://opentelemetry.io/](https://opentelemetry.io/)），作为
    CNCF 中的一个主要项目，是一套标准、格式、客户端库和相关软件组件，用于提供可观察性。这些标准是明确跨平台的，并且不依赖于任何特定的技术堆栈。
- en: This provides a framework that integrates with OSs and commercial products and
    can collect observability data from apps written in many languages. Because the
    implementations are open source, they are of varying levels of technical maturity,
    depending on the interest that OpenTelemetry has attracted in the particular language
    community.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了一个框架，可以与操作系统和商业产品集成，并可以从用多种语言编写的应用程序中收集可观察性数据。由于实现是开源的，它们的技术成熟度各不相同，这取决于
    OpenTelemetry 在特定语言社区中吸引的兴趣。
- en: OpenTelemetry came from the merger of two prior open source projects, OpenTracing
    and OpenCensus projects. Although OpenTelemetry is still maturing, it is gaining
    momentum and an increasing number of applications and teams are investigating
    and implementing it. This number seems set to grow significantly during 2022 and
    2023.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 项目源于两个先前开源项目的合并，即 OpenTracing 和 OpenCensus 项目。尽管 OpenTelemetry
    仍在不断发展，但它正在获得动力，越来越多的应用程序和团队正在研究和实施它。这个数字似乎在 2022 年和 2023 年将显著增长。
- en: 'From our perspective, the Java/JVM implementation is one of the most mature
    available and has a number of advantages over traditional APM/monitoring. In particular,
    the use of an open standard provides the following:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的角度来看，Java/JVM 实现是最成熟的可用的之一，并且与传统 APM/监控相比具有许多优势。特别是，使用开放标准提供了以下优势：
- en: Vastly reduced vendor lock-in
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大大减少了供应商锁定
- en: Open specification wire protocols
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开放规范线协议
- en: Open source client components
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开源客户端组件
- en: Standardized architecture patterns
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化架构模式
- en: Increasing quantity and quality of open source backend components
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开源后端组件的数量和质量不断提高
- en: OpenTelemetry has several subprojects that make up the standard as a whole,
    and they are not all at the same level of maturity in terms of their overall lifecycle.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 有几个子项目构成了整个标准，它们在其整体生命周期方面并不处于相同的成熟度水平。
- en: The Distributed Tracing specification is at v1.0 and is being actively deployed
    into production systems. It replaces OpenTracing completely, and the OpenTracing
    project has been officially archived. The Jaeger project, one of the most popular
    distributing tracing backends, has also discontinued its client libraries and
    will default to OpenTelemetry protocols going forward.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式跟踪规范已达到v1.0，并正在积极部署到生产系统中。它完全取代了OpenTracing，OpenTracing项目已被官方存档。最受欢迎的分布式跟踪后端之一，Jaeger项目也已经停止其客户端库的开发，并将默认使用OpenTelemetry协议。
- en: The OpenTelemetry Metrics project is not quite as advanced but has reached v1.0
    and general availability (GA). At time of writing, the protocol is stable, and
    the API is at feature-freeze.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry度量项目虽然不算特别先进，但已经达到了v1.0和通用可用性（GA）阶段。在撰写本文时，该协议是稳定的，API处于特性冻结状态。
- en: Finally, the Logging specification is still in draft and is not expected to
    reach v1.0 until late 2022\. There is still acknowledged to be a certain amount
    of work to do on the spec.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，日志规范仍在草案阶段，预计要到2022年底才能达到v1.0。目前仍认为在规范上还有一定的工作要做。
- en: Overall, OpenTelemetry as a whole will be considered to be v1.0/GA when the
    Metrics standard reaches v1.0 alongside Tracing.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，当度量标准达到v1.0并与跟踪一起时，OpenTelemetry作为一个整体将被视为v1.0/GA。
- en: The Java libraries for OpenTelemetry can be deployed into your application using
    either manual methods (where the developer must consciously choose which parts
    of the application need to be instrumented) or the use of automatic instrumentation
    (using a Java agent). Java components for OpenTelemetry can be found on GitHub
    and live in several projects, including [http://mng.bz/aJyJ](http://mng.bz/aJyJ).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry的Java库可以通过手动方法（开发者必须明确选择应用中需要被检测的部分）或使用自动检测（使用Java代理）部署到您的应用中。OpenTelemetry的Java组件可以在GitHub上找到，并存在于多个项目中，包括[http://mng.bz/aJyJ](http://mng.bz/aJyJ)。
- en: A full discussion of how to implement a full observability solution (whether
    based on OpenTelemetry or another stack) is outside the scope of this book, but
    the well-grounded Java developer would be well advised to explore this area thoroughly.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 完全可观测性解决方案的实施方法（无论基于OpenTelemetry还是其他堆栈）超出了本书的范围，但经验丰富的Java开发者应该彻底探索这个领域。
- en: Related to observability are some performance subtleties that engineers who
    are not Java/VM specialists may not be aware of. Let’s take a closer look.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 与可观测性相关的一些性能细节，对于不是Java/VM专家的工程师来说可能并不了解。让我们更深入地了解一下。
- en: 12.5.2 Performance in containers
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.2 容器中的性能
- en: Many developers, when migrating their Java applications into containers, will
    try to use the smallest possible containers. This seems to make sense, because
    cloud-based applications are typically charged by the amount of RAM and CPU that
    they use.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发者在将Java应用程序迁移到容器时，会尝试使用尽可能小的容器。这似乎是有道理的，因为基于云的应用通常按使用的RAM和CPU数量计费。
- en: However, the JVM is a very dynamic platform, and certain important parameters
    are automatically determined by the JVM at startup time, based on the observed
    properties of the machine the JVM is running on.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，JVM是一个非常动态的平台，某些重要的参数在启动时由JVM根据JVM运行所在机器的观察属性自动确定。
- en: 'These properties include the type and count of the CPUs and the physical memory.
    The behavior of the running application can and will be different when running
    on differently sized machines—and this includes containers. Some of these dynamic
    properties follow:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 这些属性包括CPU的类型和数量以及物理内存。当在不同的机器上运行时，运行中的应用程序的行为可能会不同，这包括容器。以下是一些动态属性：
- en: JVM Intrinsics, a JIT technique that can make use of very specific CPU features
    (e.g. vector support)
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JVM内省，一种可以利用非常具体的CPU特性（例如向量支持）的JIT技术
- en: Sizing of internal threadpools (such as the “common pool”)
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内部线程池（如“通用池”）的大小
- en: Number of threads used for GC
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于GC的线程数量
- en: Just from this list, we can see that incorrectly choosing the size of the container
    image can cause problems related to GC or common thread operations. However, the
    problem is fundamentally deeper than this.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 只从这份列表中，我们就可以看出，错误地选择容器镜像的大小可能会导致与GC或常见线程操作相关的问题。然而，这个问题在本质上比这更深。
- en: 'Current versions of Java, including Java 17, perform some dynamic checks and
    decide the GC to use *ergonomically* (automatically), if a GC is not explicitly
    specified on the command line. If you didn’t specify a collector, then the logic
    is as follows:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 当前版本的 Java，包括 Java 17，在命令行未显式指定 GC 的情况下，会进行一些动态检查并** ergonomically**（自动地）决定使用哪种
    GC。如果您没有指定收集器，那么逻辑如下：
- en: If the machine is “server class,” choose G1 (Parallel for Java 8).
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果机器是“服务器级”，则选择 G1（Java 8 的并行）。
- en: If the machine is not “server class,” then choose Serial.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果机器不是“服务器级”，则选择 Serial。
- en: 'The working definition of a server class machine is: >= two physical CPUs and
    >=2 GB of memory'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器级机器的工作定义是：>= 两个物理 CPU 和 >= 2 GB 内存
- en: 'This means that if a Java application is run on a machine that appears to have
    less than two CPUs and 2 GB of memory, then unless a specific collector algorithm
    is explicitly chosen, the Serial algorithm will be used. This is usually not what
    teams want—and leads to the following best practice:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着如果 Java 应用程序在一个看起来少于两个 CPU 和 2 GB 内存的机器上运行，除非显式选择特定的收集器算法，否则将使用 Serial 算法。这通常不是团队想要的，并导致以下最佳实践：
- en: tip Always run Java applications in containers with at least two CPUs and 2
    GB of memory.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 建议：始终以至少两个 CPU 和 2 GB 内存运行 Java 应用程序。
- en: 'It is also important to recognize that the traditional Java application lifecycle
    consists of a number of phases: bootstrap, intense class loading, warmup (with
    JIT compilation), and then a long-lived steady state (lasting for days or weeks)
    with relatively little class loading and JIT. This model is challenged by cloud
    deployments where containers may live for much shorter time periods and cluster
    sizes may be dynamically readjusted.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 同样重要的是要认识到，传统的 Java 应用程序生命周期包括多个阶段：引导、密集的类加载、预热（带有 JIT 编译），然后是一个长期稳定的状态（可能持续数天或数周），在此期间类加载和
    JIT 相对较少。这种模式在云部署中受到挑战，因为容器可能存在的时间更短，集群大小可能会动态调整。
- en: 'In this new world, Java has to ensure that it remains competitive along several
    key axes, including the following:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个新世界中，Java 必须确保它在几个关键轴上保持竞争力，包括以下方面：
- en: Footprint
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 占用空间
- en: Density
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密度
- en: Startup time
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动时间
- en: Fortunately, there is ongoing work and research into making sure that the platform
    continues to optimize for these characteristics—we’ll hear more about it in chapter
    18\.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，正在进行确保平台继续优化这些特性的工作和研究——我们将在第 18 章中了解更多关于它。
- en: Summary
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Containers have radically changed how we package and deploy applications and
    require some new techniques and ideas.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器彻底改变了我们打包和部署应用程序的方式，并需要一些新的技术和想法。
- en: Containers represent another layer of abstraction on top of the classic operating
    systems, hypervisors, and VMs that we’ve seen in the past.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器在经典操作系统、虚拟机管理程序和过去我们看到的虚拟机之上提供了一个另一层抽象。
- en: Docker is the most common tool for building, publishing, and running container
    images.
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 是构建、发布和运行容器镜像最常用的工具。
- en: We specify a container image via a `Dockerfile`. The resulting image contains
    our application and a complete environment in which it can run, including the
    JVM, native dependencies, and additional tooling.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过 `Dockerfile` 指定容器镜像。生成的镜像包含我们的应用程序和一个完整的运行环境，包括 JVM、本地依赖项和额外的工具。
- en: Containers introduce an additional layer to networking in particular. In its
    most basic form, we have to manage the ports that our containers expose for them
    to be accessible to the outside world.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器在特定于网络方面引入了一个额外的层。在其最基本的形式中，我们必须管理容器暴露的端口，以便它们对外部世界是可访问的。
- en: Running fleets of containers at scale is a lot to keep track of, so orchestrators
    are used to do that systematically. The most popular choice for this is Kubernetes.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大规模上运行容器集群需要跟踪很多东西，因此使用编排器来系统地完成这项工作。最受欢迎的选择是 Kubernetes。
- en: Kubernetes provides a rich, extensible API for declaring the desired state of
    your system and bringing that to life at runtime. It is accessible via the command
    line and a REST API with an enormous ecosystem of supporting tools around it.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 提供了一个丰富的、可扩展的 API，用于声明系统的期望状态，并在运行时实现该状态。它可以通过命令行和一个 REST API 访问，周围有一个庞大的支持工具生态系统。
- en: A key feature of containers is enforcing constraints around resources. These
    limits on memory and CPU can have performance implications for your application
    running in a container.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器的一个关键特性是强制资源约束。这些对内存和 CPU 的限制可能对在容器中运行的应用程序的性能产生影响。
