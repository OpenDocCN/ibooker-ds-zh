- en: 12 Evolutionary machine learning and beyond
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 12 进化机器学习及其超越
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节涵盖
- en: Evolution and ML with gene expression programming
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基因表达编程与进化与机器学习
- en: Revisiting reinforcement learning with Geppy
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新审视使用Geppy的强化学习
- en: Instinctual learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本能学习
- en: Generalized learning with genetic programming
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用遗传编程的广义学习
- en: The future of evolutionary machine learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进化机器学习的未来
- en: Generalization with instinctual deep and deep reinforcement learning
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于本能的深度学习和深度强化学习的泛化
- en: In the last chapter, we looked deeply at how evolutionary solutions like NEAT
    could be applied to solve RL. In this chapter, we continue with some of those
    same concepts but also take a step back and look at how evolutionary methods can
    be applied to expand our understanding of ML. Specifically, looking at what role
    evolutionary search plays can expand how we develop generalized ML.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们深入探讨了如何将进化解决方案如NEAT应用于解决强化学习问题。在本章中，我们继续探讨这些相同的概念，同时也退后一步，探讨进化方法如何应用于扩展我们对机器学习的理解。具体来说，研究进化搜索在其中的作用可以扩展我们开发广义机器学习的方法。
- en: Generalized ML (aka generalized AI)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 广义机器学习（又称广义人工智能）
- en: '*Generalized machine learning*, or generalized intelligence, is an area that
    focuses on building models that can solve more than one task. Typically, in ML,
    we develop models to classify or regress on a single source of data, training
    the model iteratively and validating performance with similar data. Generalized
    ML’s goal is to develop models that can predict over multiple disparate forms
    of data or environments. In data science, you may hear this problem referred to
    as *cross-domain* or *multimodal*, meaning we are building a model to tackle problems
    across domains.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*广义机器学习*，或称广义智能，是一个专注于构建能够解决多个任务的模型的研究领域。通常，在机器学习中，我们开发模型来对单一数据源进行分类或回归，通过迭代训练模型并使用相似数据验证性能。广义机器学习的目标是开发能够预测多种不同形式的数据或环境的模型。在数据科学中，你可能听到这个问题被称为*跨领域*或*多模态*，这意味着我们正在构建一个模型来处理跨领域的问题。'
- en: DL is tailored for function approximation and optimization that is often designed
    to solve specific problems. Throughout this book, we have looked at ways of augmenting
    or improving DL in that respect by taking such steps as improving hyperparameter
    search, optimizing network architecture, and neuroevolving networks.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习针对的是函数逼近和优化，通常是为了解决特定问题而设计的。在本书中，我们探讨了通过改进超参数搜索、优化网络架构和神经进化网络等方法来增强或改进深度学习的方法。
- en: In this chapter, we divert our attention from DL and look at examples that use
    evolution to help generalize the way we solve ML problems. We start by looking
    at evolving functions and then move on to developing more generalized functions
    that may solve multiple problems. Expanding on generalization, we then look at
    an idea that attempts to encapsulate generalized function learning, called *instinctual
    learning*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将注意力从深度学习转向，探讨使用进化来帮助我们泛化解决机器学习问题的一些例子。我们首先研究进化的函数，然后转向开发可能解决多个问题的更广义的函数。在扩展泛化的基础上，我们接着探讨一个试图封装广义函数学习的想法，称为*本能学习*。
- en: From generalized instinctual learning, we move on to an interesting example
    that trains an `ant` agent using genetic programming. Then, we explore how a specific
    agent can be generalized through further evolution. Finally, we finish this final
    chapter with a discussion of the future of evolution in ML. In the next section,
    we begin by looking at the core of ML—the function—and how it can be evolved with
    gene expression programming (GEP).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 从广义本能学习出发，我们转向一个有趣的例子，使用遗传编程训练一个`蚂蚁`智能体。然后，我们探讨如何通过进一步的进化使特定智能体泛化。最后，我们以讨论机器学习中进化的未来作为本章的结尾。在下一节中，我们首先关注机器学习的核心——函数，以及它如何可以通过基因表达编程（GEP）进行进化。
- en: 12.1 Evolution and machine learning with gene expression programming
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.1 基因表达编程与进化与机器学习
- en: A function, or a function approximator, is at the core of any ML algorithm.
    The role of this function is to take in data or input and output a result or prediction.
    Figure 12.1 shows the various forms of learning we have covered in this book,
    using DL as the function or function approximator targeted for each type of learning.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 函数，或函数逼近器，是任何机器学习算法的核心。这个函数的作用是接收数据或输入并输出结果或预测。图12.1展示了本书中涵盖的各种学习形式，使用深度学习作为针对每种学习类型的函数或函数逼近器。
- en: '![](../Images/CH12_F01_Lanham.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F01_Lanham.png)'
- en: Figure 12.1 Examples of learning functions
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 学习函数的例子
- en: In this section, we look at a notebook that builds the actual function, not
    an approximation using evolution. The benefit here is that evolution removes the
    need to employ a loss or error function within the learning process. Figure 12.2
    shows how this type of learning operates. If you look back to chapter 11, this
    is the same process we performed with NEAT as a function approximator, replacing
    traditional DL.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们查看一个笔记本，它构建了实际函数，而不是使用进化的近似。这里的优点是进化消除了在学习过程中使用损失或误差函数的需求。图12.2展示了这种类型的学习是如何操作的。如果你回顾第11章，这就是我们使用NEAT作为函数逼近器执行的过程，取代了传统的深度学习。
- en: '![](../Images/CH12_F02_Lanham.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F02_Lanham.png)'
- en: Figure 12.2 Evolutionary learning
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 进化学习
- en: For the notebook in this section, we use Geppy, an extension to DEAP that improves
    on DEAP implementation of GEP. If you recall, we have already looked at GEP in
    chapter 3\. The work we do here is specific to evolving functions and how this
    relates to general ML.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本节中的笔记本，我们使用Geppy，这是DEAP的扩展，它改进了GEP的DEAP实现。如果你还记得，我们在第3章已经看过GEP。我们在这里做的工作是关于进化函数以及它与通用机器学习的关系。
- en: Open the EDL_12_1_GEPPY.ipynb notebook in Google Colab. Refer to the appendix
    if you need assistance. Run all the cells in the notebook by selecting Runtime
    > Run All from the menu.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Colab中打开EDL_12_1_GEPPY.ipynb笔记本。如需帮助，请参阅附录。通过选择菜单中的“运行”>“运行所有”来运行笔记本中的所有单元。
- en: Since Geppy is an extension of DEAP, most of the code looks very similar to
    what we have covered previously; as such, we only review new features here. The
    first code cell block we look at, shown in the following listing, shows the target
    function we are evolving a solution for. This simple linear function is the target
    function we want to replicate through evolution.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Geppy是DEAP的扩展，大部分代码看起来与我们之前覆盖的非常相似；因此，我们在这里只回顾新特性。我们首先查看的第一个代码单元块，如下所示，展示了我们正在进化的解决方案的目标函数。这个简单的线性函数是我们希望通过进化复制的目标函数。
- en: 'Listing 12.1 EDL_12_1_GEPPY.ipynb: Defining the target function'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.1 EDL_12_1_GEPPY.ipynb：定义目标函数
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ A ground truth function
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 地面真实函数
- en: This notebook uses a base set of expression operators to generate the expression
    tree, as shown in the following listing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这个笔记本使用一组基本的表达式运算符来生成表达式树，如下所示。
- en: 'Listing 12.2 EDL_12_1_GEPPY.ipynb: Adding expression operators'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.2 EDL_12_1_GEPPY.ipynb：添加表达式运算符
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Builds the set of operators
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 构建运算符集合
- en: ❷ Adds standard math operators
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加标准数学运算符
- en: ❸ Adds a special operator for division
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加一个用于除法的特殊运算符
- en: ❹ Adds a constant/ephemeral operator
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 添加一个常数/瞬时运算符
- en: Next, we jump down to the `evaluate` function, which shows how we determine
    the `fitness` of each `individual` in the `population`. The `toolbox.compile`
    function generates the function from the `individual` `gene` sequence. Then, the
    output is generated from the sample `X1` input. After that, the `fitness` is returned
    by calculating the mean absolute error, as shown in the following listing.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们跳转到`evaluate`函数，它展示了我们如何确定种群中每个`individual`的`fitness`。`toolbox.compile`函数从`individual`的`gene`序列生成函数。然后，从样本`X1`输入生成输出。之后，通过计算平均绝对误差来返回`fitness`，如下所示。
- en: 'Listing 12.3 EDL_12_1_GEPPY.ipynb: The `evaluate` function'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.3 EDL_12_1_GEPPY.ipynb：`evaluate`函数
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Compiles the function from the individual
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从个体编译函数
- en: ❷ Outputs the prediction
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 输出预测结果
- en: ❸ Returns the mean absolute error
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 返回平均绝对误差
- en: ❹ Registers the function with the toolbox
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在工具箱中注册函数
- en: The benefit of using Geppy over the base gene expression library from DEAP is
    that we have access to several helpful extensions and operators relevant to this
    form evolution. These new operators aid GEP evolution through tweaks in the `mutation`
    and `crossover` genetic operators, as shown in listing 12.4\. The additional `mutation`
    operators, prefixed with `mut_`, allow the function to be inverted and transposed.
    Following that, the extra `crossover` operators, prefixed with `cx_`, provide
    two-point `crossover` and `gene` `crossover`. Two-point `crossover` allows the
    `gene` sequence to be split into two locations along a `gene` sequence. The process
    of `gene` `crossover` allows each `gene` `chromosome` to `crossover`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Geppy 而不是 DEAP 的基本基因表达库的好处是我们可以访问一些与这种形式进化相关的有用扩展和算子。这些新算子通过调整`突变`和`交叉`遗传算子来帮助
    GEP 进化，如列表 12.4 所示。额外的`突变`算子，以`mut_`为前缀，允许函数被反转和转置。随后，额外的`交叉`算子，以`cx_`为前缀，提供两点`交叉`和`基因``交叉`。两点`交叉`允许将`基因`序列沿`基因`序列分割成两个位置。`基因``交叉`的过程允许每个`基因``染色体`进行`交叉`。
- en: 'Listing 12.4 EDL_12_1_GEPPY.ipynb: Registering custom operators'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.4 EDL_12_1_GEPPY.ipynb：注册自定义算子
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Added for mutation
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为突变添加
- en: ❷ Added for crossover
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为交叉添加
- en: ❸ Handles constants/ephermeral operators
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 处理常数/临时算子
- en: Previously, we have usually represented our genetic encoding in a single `gene`
    sequence. Geppy works by breaking the `gene` sequence into components, or `chromosomes`.
    Breaking the `gene` sequence into `chromosomes` allows complex `gene` sequences
    to be isolated into useful parts. Then, through evolution, these parts can be
    swapped during `crossover` operations, thereby maintaining useful sections.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前，我们通常用一个单一的`基因`序列来表示我们的遗传编码。Geppy 通过将`基因`序列分解成组件，或`染色体`来工作。将`基因`序列分解成`染色体`可以将复杂的`基因`序列隔离成有用的部分。然后，通过进化，这些部分可以在`交叉`操作期间交换，从而保持有用的部分。
- en: We can see how `gene` `chromosomes` are defined by looking at the registration
    of the `gene`, as shown in listing 12.5\. The parameter `h` represents the number
    of `chromosomes`, and the parameter `n_genes` represents the number of `genes`
    in each `chromosome`. The `chromosome` template and `gene` sequence are registered
    in the `toolbox`, as we have previously seen.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看`基因`的注册，我们可以看到`基因`和`染色体`是如何定义的，如列表 12.5 所示。参数`h`代表`染色体`的数量，参数`n_genes`代表每个`染色体`中`基因`的数量。`染色体`模板和`基因`序列在`toolbox`中注册，正如我们之前所看到的。
- en: 'Listing 12.5 EDL_12_1_GEPPY.ipynb: Defining the `gene`, `head`, and `chromosomes`'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.5 EDL_12_1_GEPPY.ipynb：定义`基因`、`头部`和`染色体`
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Sets the head length
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置头部长度
- en: ❷ The number of genes in the chromosome
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 染色体中的基因数量
- en: ❸ Registers the gene chromosome
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 注册基因染色体
- en: ❹ Registers the gene sequence
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 注册基因序列
- en: The code to evolve the function, shown in listing 12.6, is only a few lines
    long, starting with creating the `population` and setting the number of best `individuals`
    to track with the `HallOfFame` class. After that, it’s a simple matter of calling
    `gep_simple` to evolve the solution over `n_gen` `generations`.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 进化函数的代码，如列表 12.6 所示，只有几行长，从创建`种群`和设置使用`HallOfFame`类跟踪的最佳`个体`数量开始。之后，只需调用`gep_simple`来在`n_gen`代`进化`解决方案即可。
- en: 'Listing 12.6 EDL_12_1_GEPPY.ipynb: Evolving the function'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.6 EDL_12_1_GEPPY.ipynb：进化函数
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ The parameters for population and generations
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 种群和代数的参数
- en: ❷ Creates the population
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建种群
- en: ❸ Sets the max number of best
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 设置最佳值的最大数量
- en: ❹ Evolves
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 进化
- en: Since most raw evolved functions have redundant terms or operators, a useful
    feature offered by Geppy is *simplification*. Calling the `gep.simplify` function
    using the best `individual` generates the top solved function. As you can see
    from the results in the following listing, the final function matches exactly
    what the target function was in listing 12.1.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数原始进化函数都有冗余项或算子，Geppy 提供的一个有用功能是*简化*。使用最佳`个体`调用`gep.simplify`函数生成顶级解决方案。正如您可以从以下列表的结果中看到的那样，最终函数与列表
    12.1 中的目标函数完全匹配。
- en: 'Listing 12.7 EDL_12_1_GEPPY.ipynb: The evolved function simplified'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.7 EDL_12_1_GEPPY.ipynb：简化的进化函数
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Gets the best solution
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取最佳解
- en: ❷ Extracts the simplified view
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 提取简化视图
- en: ❸ Displays the output
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 显示输出
- en: The last cell of the notebook, shown in listing 12.8, renders the raw, not simplified
    function, using another helpful feature of Geppy. The call to `gep.export_expression_
    tree` renders the function in the nice-looking plot shown in figure 12.3\. Note
    that the raw plot you see may look different from that in the figure, but the
    result—a simplified expression—should be the same.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本中的最后一个单元，如列表12.8所示，使用Geppy的另一个有用功能渲染原始函数，而不是简化函数。对`gep.export_expression_tree`的调用将函数渲染成如图12.3所示的漂亮图表。请注意，您看到的原始图表可能与图中的不同，但结果——一个简化的表达式——应该是相同的。
- en: '![](../Images/CH12_F03_Lanham.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F03_Lanham.png)'
- en: Figure 12.3 An evolved equation expression tree
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.3 进化方程表达式树
- en: 'Listing 12.8 EDL_12_1_GEPPY.ipynb: Displaying an evolved equation'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.8 EDL_12_1_GEPPY.ipynb：显示进化方程
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Generates an image of an expression tree
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 生成表达式树的图像
- en: ❷ Displays the tree in the notebook
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在笔记本中显示树
- en: The point of this notebook is to showcase a useful tool that can derive explicit
    functions. In this example, the resulting function is identical to the target
    function, but that won’t always be the case. In many cases, the resulting function
    can provide insight into the data relationships not previously understood, as
    we see later in the chapter. Before that, though, let’s jump into some learning
    exercises in the next section.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个笔记本的目的是展示一个可以推导出显式函数的有用工具。在这个例子中，得到的函数与目标函数相同，但这种情况并不总是如此。在许多情况下，得到的函数可以提供对数据关系的洞察，这些关系之前并未被理解，正如我们在本章后面所看到的。在此之前，让我们跳到下一节的一些学习练习。
- en: 12.1.1 Learning exercises
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1.1 学习练习
- en: 'Use these exercises to help you improve your knowledge of the content:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些练习帮助您提高对内容的知识：
- en: Alter the target function in listing 12.1 and then rerun the notebook. How well
    does the evolution perform?
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改列表12.1中的目标函数，然后重新运行笔记本。进化的表现如何？
- en: Modify the `chromosomes` by altering the `head`, `h`, and the number of `genes`,
    `n_genes`, parameters from listing 12.5\. Rerun the notebook to see what effect
    this had on the evolutionary process.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过修改列表12.5中的`head`、`h`和基因数量`n_genes`参数来修改`chromosomes`。重新运行笔记本以查看这对进化过程有何影响。
- en: Add or remove expression operators to listing 12.2\. You can add operators like
    `cos` or `sin`, for example—just check the DEAP documentation. Make sure to also
    update the labels from listing 12.8.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向列表12.2中添加或删除表达式运算符。例如，您可以添加`cos`或`sin`等运算符——只需检查DEAP文档。确保还更新列表12.8中的标签。
- en: In the next section, we move away from simple examples and on to a classic control
    problem by revisiting the OpenAI Gym.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将从简单的例子转向经典控制问题，通过重新审视OpenAI Gym。
- en: 12.2 Revisiting reinforcement learning with Geppy
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.2 使用Geppy重新审视强化学习
- en: To demonstrate how effective Geppy can be at evolving equations, we look at
    a class control problem via the OpenAI Gym. The idea is to let Geppy evolve an
    equation that can drive a couple of the most complex OpenAI Gym environments.
    This example mirrors what we did with NEAT in chapter 11, and if you need to review
    some elements, refer to those notebooks.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示Geppy在进化方程方面的有效性，我们通过OpenAI Gym查看一个班级控制问题。想法是让Geppy进化一个可以驱动几个最复杂的OpenAI
    Gym环境的方程。这个例子反映了我们在第11章中用NEAT所做的工作，如果您需要回顾一些元素，请参考那些笔记本。
- en: Open the EDL_12_2_GEPPY_Gym.ipynb notebook in Google Colab. Refer to the appendix
    if you need assistance. Run all the cells in the notebook by selecting Runtime
    > Run All from the menu.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Colab中打开EDL_12_2_GEPPY_Gym.ipynb笔记本。如果您需要帮助，请参阅附录。通过从菜单中选择运行时 > 运行所有来运行笔记本中的所有单元。
- en: Potentially unstable
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 可能不稳定
- en: As mentioned in chapter 11, because of the virtual driver setup and other custom-installed
    components, these notebooks can be prone to crashing. If the notebook crashes
    during execution, disconnect and delete the runtime and then restart and rerun.
    From the menu, select Runtime > Disconnect and Delete Runtime and then Runtime
    > Run All.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如第11章所述，由于虚拟驾驶员设置和其他自定义安装的组件，这些笔记本电脑可能会出现崩溃。如果在执行过程中笔记本电脑崩溃，请断开连接并删除运行时，然后重新启动并重新运行。从菜单中选择运行时
    > 断开连接并删除运行时，然后运行时 > 运行所有。
- en: 'In this notebook, we attempt to solve two `continuous` control problems: the
    mountain car (continuous) and the pendulum (continuous). The word *continuous*
    is used to define the `action` and `observation` (`state`) spaces of the environment.
    Coincidentally, and slightly confusingly, *continuous* may also refer to the agent
    receiving continuous rewards. That is, at each step, the environment yields a
    reward, negative or positive. Setting up the notebooks and rendering their `action`
    or `observation` spaces is quite simple, as shown in the following listing.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个笔记本中，我们尝试解决两个`连续`控制问题：山车（连续）和摆锤（连续）。"连续"这个词用来定义环境的`动作`和`观察`（状态）空间。巧合的是，也可能有些令人困惑，"连续"也可能指代接收连续奖励的代理。也就是说，在每一步，环境都会提供一个奖励，无论是正面的还是负面的。设置笔记本和渲染它们的`动作`或`观察`空间相当简单，如下面的列表所示。
- en: 'Listing 12.9 EDL_12_2_GEPPY_Gym.ipynb: Rendering the environment spaces'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.9 EDL_12_2_GEPPY_Gym.ipynb：渲染环境空间
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Environment options for the Colab form
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Colab表单的环境选项
- en: ❷ Creates the environment
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建环境
- en: ❸ Renders an image of the environment
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 渲染环境的图像
- en: ❹ Displays action/ observation spaces
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 显示动作/观察空间
- en: 'Figure 12.4 shows both environments we try to evolve solution equations for.
    Both environments use a continuous `action` space, while the Gym environments
    we explored in chapter 11 used discrete `action` spaces. *Continuous* means an
    `action` can now be a real value within the given range: –2 to +2 for pendulum
    and –1 to +1 for mountain car. This is perfect, since our derived equation can
    now just output a value within that range.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4显示了我们要尝试进化解决方案方程的两个环境。这两个环境都使用连续的`动作空间`，而我们在第11章中探索的Gym环境使用的是离散的`动作空间`。"连续"意味着`动作`现在可以是给定范围内的实数值：摆锤为-2到+2，山车为-1到+1。这是完美的，因为我们的导出方程现在可以输出该范围内的值。
- en: '![](../Images/CH12_F04_Lanham.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F04_Lanham.png)'
- en: Figure 12.4 Rendering environments and spaces
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 渲染环境和空间
- en: The `observation` space for each environment is different, so we must make a
    slight change to the way we define the `PrimitiveSet`, as shown in listing 12.10\.
    Since the two environments use different `observation` spaces, we need to account
    for those changes when setting up the base set of inputs. For the pendulum, the
    `observation` space is the `x`, `y` coordinates of the pendulum. Likewise, for
    mountain car, the `observation` space is the `x`, `y` coordinates of the car and
    its `velocity`. This means the function for pendulum is `f(x,` `y)`, and for mountain
    car, it is `f(x,` `y,` `velocity)`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 每个环境的`观察空间`都不同，因此我们必须对定义`原始集`的方式做轻微的调整，如列表12.10所示。由于这两个环境使用不同的`观察`空间，因此在设置输入的基本集合时，我们需要考虑这些变化。对于摆锤，`观察空间`是摆锤的`x`、`y`坐标。同样，对于山车，`观察空间`是汽车的`x`、`y`坐标及其`速度`。这意味着摆锤的函数是`f(x,
    y)`，而对于山车，它是`f(x, y, 速度)`。
- en: 'Listing 12.10 EDL_12_2_GEPPY_Gym.ipynb: Setting the `primitive` set'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.10 EDL_12_2_GEPPY_Gym.ipynb：设置`原始`集
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Sets for pendulum
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 摆锤的集合
- en: ❷ Sets for mountain car
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 山车的集合
- en: ❸ Creates the remainder set, as before
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 如前所述创建剩余集合
- en: As we did in chapter 11, we determine the `fitness` of an `individual` based
    on their ability to accumulate rewards. Instead of using a NEAT network to predict
    the `action`, though, this time we use the evolved function/equation to calculate
    the `action`. In this code block, shown in listing 12.11, two simple functions
    have been written for each environment. These examples are just used for testing
    and do not represent the final evolved solution internally. The call to `func`,
    depending on the environment, uses the unroll operator `*` to expand the observed
    `state` into arguments to the function. Then, the output of the function, which
    could be anything, is converted to the appropriate `action` space of the environment
    with the `convert_to_action` and `clamp` functions.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第11章中所做的那样，我们根据个体积累奖励的能力来确定其`适应度`。然而，这次我们不是使用NEAT网络来预测`动作`，而是使用进化的函数/方程来计算`动作`。在这个代码块中，如列表12.11所示，为每个环境编写了两个简单的函数。这些示例仅用于测试，并不代表内部最终进化的解决方案。根据环境，对`func`的调用使用展开运算符`*`将观察到的`状态`展开为函数的参数。然后，函数的输出，可以是任何东西，通过`convert_to_action`和`clamp`函数转换为环境适当的`动作空间`。
- en: 'Listing 12.11 EDL_12_2_GEPPY_Gym.ipynb: Determining `individual` `fitness`'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.11 EDL_12_2_GEPPY_Gym.ipynb：确定`个体``适应度`
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ The sample function
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 样本函数
- en: ❷ Limits values to within the range
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 限制值在范围内
- en: ❸ Converts the calculated value to the environment
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将计算值转换到环境中
- en: ❹ Calculates/converts to the output action
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 计算/转换成输出动作
- en: ❺ Adds reward to the total fitness
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将奖励添加到总适应度
- en: Now, the real `evaluate` function, shown in the following listing, can be written
    from listing 12.11.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，真正的 `evaluate` 函数，如下面的列表所示，可以从列表 12.11 编写。
- en: 'Listing 12.12 EDL_12_2_GEPPY_Gym.ipynb: The real `evaluate` function'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.12 EDL_12_2_GEPPY_Gym.ipynb：真正的 `evaluate` 函数
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Compiles the function from the individual
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从个体编译函数
- en: ❷ Calculates/converts the action
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算/转换动作
- en: ❸ Takes a step
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 取得一步
- en: ❹ Adds the reward to the total fitness
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将奖励添加到总适应度
- en: ❺ Registers the function
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 注册函数
- en: The code to run the evolution is quite straightforward, as shown in the following
    listing.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 运行进化的代码相当直接，如下面的列表所示。
- en: 'Listing 12.13 EDL_12_2_GEPPY_Gym.ipynb: Evolving the solution'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.13 EDL_12_2_GEPPY_Gym.ipynb：进化解决方案
- en: '[PRE12]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ The evolution hyperparameters
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 进化超参数
- en: ❷ Evolves for a generation
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 进化一代
- en: ❸ Shows the performance of the best individual
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 展示最佳个体的性能
- en: After each `generation`, we call the `show_best` function to run the `individual`
    through a simulation and render it to video, as shown in the following listing.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个 `generation` 之后，我们调用 `show_best` 函数运行 `individual` 通过模拟并将其渲染成视频，如下面的列表所示。
- en: 'Listing 12.14 EDL_12_2_GEPPY_Gym.ipynb: Showing the fittest'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.14 EDL_12_2_GEPPY_Gym.ipynb：展示最适应的
- en: '[PRE13]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Compiles to the function
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 编译成函数
- en: ❷ Simulates the function over one run
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在一次运行中模拟函数
- en: ❸ Renders the recorded sim to video
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将记录的模拟渲染成视频
- en: ❹ Shows the simplified form of the function
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 展示函数的简化形式
- en: Figure 12.5 shows the results of the `mountain car` solution with the simplified
    equation. The resulting output shows the derived equations being used to get good
    rewards from the different environments. It is also interesting to note how different
    each of the equations are, given their similarity in tasks and inputs.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.5 展示了使用简化方程的 `mountain car` 解决方案的结果。结果输出显示了推导出的方程被用来从不同的环境中获得良好的奖励。值得注意的是，由于任务和输入的相似性，每个方程都是不同的。
- en: '![](../Images/CH12_F05_Lanham.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F05_Lanham.png)'
- en: Figure 12.5 The results of evolving the equation on environments
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.5 在环境中进化方程的结果
- en: The ability to solve these environments with Geppy evolving an equation is impressive.
    It demonstrates how effective evolution can be at overcoming control problems.
    Our goal in this chapter, however, is to look at how more generalized learning
    solutions may be evolved. We cover this in greater depth in the next section,
    but for now, let’s jump into some learning tasks that can help reinforce this
    section’s concepts.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Geppy 进化方程解决这些环境的能力令人印象深刻。它展示了进化在克服控制问题上的有效性。然而，我们本章的目标是探讨如何进化更通用的学习解决方案。我们将在下一节中更深入地探讨这一点，但现在，让我们跳入一些可以帮助加强本节概念的学习任务。
- en: 12.2.1 Learning exercises
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2.1 学习练习
- en: 'Use these exercises to go back over the material and reinforce what you’ve
    learned:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些练习回顾材料并加强你所学的知识：
- en: Search the internet for other potential OpenAI Gym environments we could potentially
    solve with this technique.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在互联网上搜索其他可能的 OpenAI Gym 环境，我们可能可以用这种技术解决。
- en: Add new expression operators, like `cos` or `sin`, to the set. Rerun the notebook
    to see if and how these operators are used in the resulting derived equation.
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向集合中添加新的表达式运算符，如 `cos` 或 `sin`。重新运行笔记本以查看这些运算符是否以及如何被用于结果推导出的方程中。
- en: Try to obtain the best `fitness` you can with either pendulum or mountain car.
    This can be done in several ways, including increasing the `population`, increasing
    the number of `generations` to start, and introducing new expressions.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试使用摆锤或山车获得最佳的 `fitness`。这可以通过多种方式完成，包括增加 `population`、增加起始的 `generations` 数量以及引入新的表达式。
- en: In the next section, we expand on our understanding of using evolution to evolve
    more generalized solutions.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将扩展我们对使用进化来进化更通用解决方案的理解。
- en: 12.3 Introducing instinctual learning
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.3 介绍本能学习
- en: Instinctual learning (IL) is a concept developed by the author of this book
    that attempts to generalize how traits or functions can be both evolved and learned.
    It is based on biological observations of humans and other organisms and borrows
    concepts from RL and other behavioral learning methods. In our next notebook,
    we employ some IL concepts to attempt to evolve a more generalized solution to
    the example of the last section. Before that, though, let’s take a more in-depth
    look at what IL is.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 本能学习（IL）是本书作者提出的一个概念，旨在概括特质或功能如何既可以通过进化也可以通过学习而发展。它基于对人类和其他生物体的生物学观察，并借鉴了强化学习（RL）和其他行为学习方法的概念。在我们接下来的笔记本中，我们将运用一些本能学习的概念，尝试为上一节中的例子进化出一种更通用的解决方案。在此之前，让我们更深入地了解一下什么是本能学习。
- en: 12.3.1 The basics of instinctual learning
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.1 本能学习的基本原理
- en: IL is an abstract thought model intended to guide the development of more generalized
    ML using evolution. The initiative of IL is that if evolution can develop human
    generalization, it can likewise develop digital life. Of course, evolving some
    form of generalized digital life is no trivial task, so IL attempts to describe
    some basic patterns and starting points.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: IL是一个抽象的思维模型，旨在指导使用进化来开发更通用的机器学习。IL的倡议是，如果进化可以发展人类的一般化，它同样可以发展数字生命。当然，进化出某种形式的通用数字生命并非易事，因此IL试图描述一些基本模式和起点。
- en: In nature, we observe that many organisms have what we refer to as *instincts*,
    which describe some form of learned or evolved behavior. For many species, differentiating
    between learned and evolved instincts may be obvious. A great example of this
    is the dog, for which some breeds are associated with specific natural behaviors;
    however, dogs can also learn new behaviors that can become instincts.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然界中，我们观察到许多生物体都有我们所说的*本能*，这描述了一些形式的学习或进化行为。对于许多物种来说，区分学习和进化的本能可能是显而易见的。一个很好的例子是狗，其中一些品种与特定的自然行为相关联；然而，狗也可以学习新的行为，这些行为可以成为本能。
- en: A dog typically learns an instinct through behavioral learning, such as reinforcement
    or rewards-based learning. Initially, training the dog for a task takes a repetitive
    trial-and-error process, but after some amount of this training, the dog “just
    knows.” That stage where the dog just knows is what we call the *transition to
    an instinct*. Before we get into how the transition occurs, let’s dig a bit deeper
    into general theories of how a biological mind works in the next section.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一条狗通常通过行为学习来学习本能，例如通过强化或基于奖励的学习。最初，训练狗完成一项任务需要重复的试错过程，但经过一定量的训练后，狗“就知道了”。狗“就知道”的那个阶段就是我们所说的*本能的过渡*。在我们深入探讨这种过渡是如何发生之前，让我们在下节中更深入地探讨生物心智如何工作的通用理论。
- en: The dual-process theory of thought
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 思维的双过程理论
- en: 'The dual-process theory of thought describes a theory of the higher-order thought
    process in biological life. The idea is that we have two processes functioning
    within our brains: one low-level process, called *system 1*, and another more
    conscious process, called *system 2*. Figure 12.6 shows the key differences between
    these two processes.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 思维的双过程理论描述了生物生命中的高级思维过程。其观点是我们的大脑中有两个过程在起作用：一个低级过程，称为*系统1*，另一个更自觉的过程，称为*系统2*。图12.6展示了这两个过程之间的关键区别。
- en: '![](../Images/CH12_F06_Lanham.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![图12.6 双过程理论](../Images/CH12_F06_Lanham.png)'
- en: Figure 12.6 Dual-process theory
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.6 双过程理论
- en: These two processes of thought are generally considered separate, but the thoughts
    or behaviors from system 2 can be converted to system 1, given enough training
    and practice. The conscious act of RL is, therefore, a system-2 process that converts
    to system-1 process, with enough trial and error. We may refer to this transitional
    process as *conditioning*, originating from Pavlovian conditioning.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个思维过程通常被认为是分开的，但系统2中的思维或行为可以通过足够的训练和实践转化为系统1。因此，强化学习的有意识行为是一个系统2过程，通过足够的试错转化为系统1过程。我们可以将这种过渡过程称为*条件反射*，它起源于巴甫洛夫式条件反射。
- en: Pavlov’s dog and Pavlovian conditioning
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 巴甫洛夫的狗和巴甫洛夫式条件反射
- en: Ivan Pavlov (1849–1936) was a psychologist who showed through reinforcement
    (rewards-based) learning that a dog could be conditioned to salivate at the sound
    of a bell. This conditioned or learned behavior demonstrates the transition from
    a system-2 process to a system-1 process, where through continued training, the
    dog instinctually salivated at the sound of a bell.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 伊万·巴甫洛夫（1849–1936）是一位心理学家，他通过强化（基于奖励）学习表明，狗可以被训练在听到铃声时分泌唾液。这种条件或学习行为展示了从系统2过程到系统1过程的转变，通过持续训练，狗本能地在听到铃声时分泌唾液。
- en: Figure 12.7 depicts dual-process theory in terms of IL. From evolution, an organism
    derives certain genetic traits or instincts. According to dual-process theory,
    the organism can think and potentially convert thoughts and actions to instincts.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7从本能学习的角度描述了双过程理论。根据进化，生物体获得某些遗传特征或本能。根据双过程理论，生物体可以思考和将思想和行动转化为本能。
- en: '![](../Images/CH12_F07_Lanham.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F07_Lanham.png)'
- en: Figure 12.7 Dual-process theory and instinctual learning
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.7 双过程理论与本能学习
- en: Assuming dual-process theory is accurate, we can also assume evolution developed
    this process as an efficiency. In other words, we assume at some point in the
    evolution of higher life, evolution transitioned from building hardcoded instincts
    to letting organisms develop their own instincts. This means, then, that at some
    point, an organism evolved the instinct that became what we now call dual-process
    theory.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 假设双过程理论是准确的，我们也可以假设进化发展了这一过程以提高效率。换句话说，我们假设在高等生命进化的某个阶段，进化从构建硬编码的本能转变为让生物体发展自己的本能。这意味着，在某个时刻，生物体进化出了我们现在称之为双过程理论的本能。
- en: IL is the search for the evolutionary foundations that derived this dual process
    or system-2 instinct. It is about understanding how at some point in the evolution
    of life, instincts became thoughts. Reinforcement learning is, therefore, an example
    of a simple form of dual-process theory, and IL is the search for the origins
    of RL. The notebook example we look at in the next section demonstrates how inefficient
    evolving generalized instincts (functions) can be.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: IL是寻找衍生出这种双过程或系统2本能的进化基础。它关乎理解在生命进化的某个时刻，本能如何变成了思想。因此，强化学习是双过程理论的一种简单形式，而IL是寻找RL起源的搜索。下一节中我们看到的笔记本示例展示了进化泛化本能（函数）可能有多么低效。
- en: 12.3.2 Developing generalized instincts
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.2 发展泛化本能
- en: The next notebook demonstrates how and why organisms may have moved from just
    developing instincts to higher forms of thought. In the following notebook, we
    use just evolution to attempt to develop a single equation (instinct) that can
    solve both Gym problems. In RL, this is called multitask RL and is considered
    by many to be a difficult problem.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 下一本笔记本展示了生物体如何以及为什么可能从仅仅发展本能发展到更高层次的思想形式。在接下来的笔记本中，我们仅使用进化来尝试发展一个单一的方程（本能），以解决这两个Gym问题。在强化学习（RL）中，这被称为多任务RL，许多人认为这是一个难题。
- en: Open the EDL_12_3_GEPPY_Instinctual.ipynb notebook in Google Colab. Refer to
    the appendix if you need assistance. Run all the cells in the notebook by selecting
    Runtime > Run All from the menu.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Colab中打开EDL_12_3_GEPPY_Instinctual.ipynb笔记本。如有需要，请参考附录。通过选择菜单中的“运行”>“运行所有”来运行笔记本中的所有单元格。
- en: In this notebook, we look at how potentially learned instincts evolved in the
    last exercise and can be used to generalize learning. The first thing we look
    at, then, is how those previously developed instincts (aka equations or functions)
    can be reused, as shown in the following listing. Function `instinct1` is evolved
    from running the EDL_12_2_GEPPY_Gyms.ipynb notebook on the pendulum environment.
    Likewise, `instinct2` evolved from the same notebook over mountain car. Refer
    to figure 12.5 for a review of those generated equations.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个笔记本中，我们研究在上一项练习中可能学习到的本能是如何进化的，以及如何用于泛化学习。因此，我们首先研究的是那些先前开发的本能（即方程或函数）如何被重用，如下列所示。函数`instinct1`是从在摆动环境中运行EDL_12_2_GEPPY_Gyms.ipynb笔记本中进化的。同样，`instinct2`是从同一笔记本在山车环境中进化的。请参考图12.5来回顾那些生成的方程。
- en: 'Listing 12.15 EDL_12_3_GEPPY_Instinctual.ipynb: Adding the instincts'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.15 EDL_12_3_GEPPY_Instinctual.ipynb：添加本能
- en: '[PRE14]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Avoids division by zero
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 避免除以零
- en: ❷ The function that solved pendulum
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 解决摆动问题的函数
- en: ❸ The function that solved mountain car
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 解决山车问题的函数
- en: A primary concept in IL is that instincts or functions are layered and developed
    or added over time. This notebook attempts to prove how simulated organisms successful
    in two distinct tasks could be combined to generate a third evolved organism,
    with this third organism being able to evolve a tertiary, or higher-level, instinct
    to generalize the solution for both environments.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在 IL（智能学习）中的一个主要概念是本能或函数是分层的，并且随着时间的推移而发展和添加。这个笔记本试图证明在两个不同任务中成功的模拟生物如何结合生成第三个进化的生物，这个第三个生物能够进化一个三级或更高层次的本能，以泛化两个环境的解决方案。
- en: Next, we look at how these newly defined instincts are added to the `primitive`
    set, as shown in listing 12.16\. For the `PrimitiveSet` definition, we set the
    inputs to include `x`, `y`, and `velocity` as well as a new input, `e`, that represents
    the environment. Then, we simplify the possible function operators to only include
    `add`, `sub`, and `mul`, along with the new instinct operators. The ephemeral
    constant operators were removed, since the base-level instincts should contain
    the constants needed.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来看这些新定义的本能如何添加到 `primitive` 集中，如列表 12.16 所示。对于 `PrimitiveSet` 定义，我们将输入设置为包括
    `x`、`y` 和 `velocity` 以及一个新的输入 `e`，它代表环境。然后，我们将可能的功能操作符简化为仅包括 `add`、`sub` 和 `mul`，以及新的本能操作符。由于基础本能应该包含所需的常数，因此移除了瞬时常数操作符。
- en: 'Listing 12.16 EDL_12_3_GEPPY_Instinctual.ipynb: Completing the `primitive`
    set'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.16 EDL_12_3_GEPPY_Instinctual.ipynb：完成 `primitive` 集合
- en: '[PRE15]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Generalized inputs and environment
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 泛化输入和环境
- en: ❷ Simplifies the function set
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 简化函数集
- en: ❸ Adds with two operators
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用两个操作符进行添加
- en: ❹ Adds with three operators
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用三个操作符进行添加
- en: ❺ Eliminates constants
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 消除常数
- en: Unlike in previous notebooks, this time we evolve an agent to solve both environments
    simultaneously. To do this, we create a list of environments we use to evolve
    the agent on, as shown in the following listing.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的笔记本不同，这次我们进化一个智能体同时解决两个环境。为此，我们创建了一个环境列表，我们使用这个列表来进化智能体，如下面的列表所示。
- en: 'Listing 12.17 EDL_12_3_GEPPY_Instinctual.ipynb: Creating environments'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.17 EDL_12_3_GEPPY_Instinctual.ipynb：创建环境
- en: '[PRE16]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ A list of environments to evaluate on
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 要评估的环境列表
- en: ❷ Converts to a string before printing
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在打印前转换为字符串
- en: 'The next cell block we look at, shown in listing 12.18, contains the `evaluate`
    function. This time, the function starts by looping over the `environments` list
    and running a set of simulations for each environment. Input `e` simply represents
    the environment index and is fed as the first parameter to the target function.
    Since each environment has a different `observation` `state`, when running the
    pendulum problem with just `2` states, we append a `0` to the `state` space to
    represent the third input: `velocity`. At the end of the function, the `fitness`
    values for both environments are averaged and returned.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来要查看的下一个单元格块，如列表 12.18 所示，包含 `evaluate` 函数。这次，函数首先遍历 `environments` 列表，并为每个环境运行一系列模拟。输入
    `e` 简单地表示环境索引，并将其作为第一个参数传递给目标函数。由于每个环境都有不同的 `observation` 状态，当仅用 `2` 个状态运行摆动问题时，我们在状态空间中追加一个
    `0` 来表示第三个输入：`速度`。在函数结束时，两个环境的 `fitness` 值被平均并返回。
- en: 'Listing 12.18 EDL_12_3_GEPPY_Instinctual.ipynb: Building the `evaluate` function'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.18 EDL_12_3_GEPPY_Instinctual.ipynb：构建 `evaluate` 函数
- en: '[PRE17]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Loops through the environments
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 遍历环境
- en: ❷ Populates e, based on the environment index
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 根据环境索引填充 e
- en: ❸ Appends to the state if needed
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 如有必要则追加到状态
- en: ❹ Converts to an action
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 转换为动作
- en: ❺ Returns an average fitness
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 返回平均适应度
- en: The next thing we look at is the updated `show_best` function, which now combines
    the simulation runs of the agent over both environments into a single video. This
    time, the function loops over the environments and simulates the agent on each.
    Since each environment renders to a different window size, we use the `cv2.resize`
    function to make all frames the same size, as shown in listing 12.19\. This needs
    to be done to combine all the frames into a single video. At the end of the function,
    the expression tree is saved to a file for sidecar viewing. You can view the evolution
    of the expression tree by opening the system folders on the left side, finding
    the file in the data folder, and then double-clicking on it to open a side window.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来要查看的是更新的`show_best`函数，它现在将代理在两个环境中的模拟运行合并成一个视频。这次，函数遍历环境并对每个环境进行模拟。由于每个环境渲染到不同的窗口大小，我们使用`cv2.resize`函数将所有帧调整为相同的大小，如列表12.19所示。这样做是为了将所有帧合并成一个视频。在函数的末尾，表达式树被保存到文件中以便侧边观看。你可以通过打开左侧的系统文件夹，在数据文件夹中找到文件，然后双击它以打开一个侧边窗口来查看表达式树的进化。
- en: 'Listing 12.19 EDL_12_3_GEPPY_Instinctual.ipynb: Updating the `show_best` function'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.19 EDL_12_3_GEPPY_Instinctual.ipynb：更新`show_best`函数
- en: '[PRE18]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Adds labels for instinct functions
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为本能函数添加标签
- en: ❷ Loops over the environments
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 遍历环境
- en: ❸ Resizes the captured frame
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 调整捕获帧的大小
- en: ❹ Renders the video
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 渲染视频
- en: ❺ Saves the expression tree output
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 保存表达式树输出
- en: Figure 12.8 shows captured output from the generated video running the evolution
    over 250 `generations` with 1,000 `individuals`. You may see the agent solve one
    or both environments much sooner.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8显示了在250 `代`和1,000 `个体`的进化过程中生成的视频的捕获输出。你可能看到代理在很短的时间内就解决了其中一个或两个环境。
- en: '![](../Images/CH12_F08_Lanham.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F08_Lanham.png)'
- en: Figure 12.8 An agent solving both environments simultaneously
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.8 一个代理同时解决两个环境
- en: Figure 12.9 shows the final evolved expression tree. If you run this notebook,
    you may see a different tree, but overall, it will likely be similar. What is
    interesting about this expression tree is the reuse and chaining of the `instinct1`
    and `instinct2` functions. In fact, they become the primary operators in the equation,
    but they are not used at all the way we would expect. Notice how the inputs, in
    most cases, don’t even align with the instinct’s original inputs.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9显示了最终进化的表达式树。如果你运行这个笔记本，你可能会看到不同的树，但总体上，它可能很相似。这个表达式树有趣的地方在于`instinct1`和`instinct2`函数的重用和链式调用。实际上，它们成为了方程中的主要操作符，但它们并没有像我们预期的那样被完全使用。注意，在大多数情况下，输入甚至没有与本能的原始输入对齐。
- en: '![](../Images/CH12_F09_Lanham.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F09_Lanham.png)'
- en: Figure 12.9 The final evolved expression tree
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.9 最终进化的表达式树
- en: At this point, you may be wondering whether we could just let the agent evolve
    a single function, without the added instinctual operators. This is a fair question,
    so let’s see how it works in the next section.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你可能想知道我们是否可以仅仅让代理进化一个单一函数，而不添加本能操作符。这是一个合理的问题，所以让我们看看在下一节中它是如何工作的。
- en: 12.3.3 Evolving generalized solutions without instincts
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.3 无本能地进化通用解
- en: In the following notebook, we take an opposing approach to the last exercise
    and assume nothing of instincts and IL. This means we allow the agent using evolution
    to solve both environments by deriving a single equation with no instinctual operators.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的笔记本中，我们采取与上一个练习相反的方法，对本能和IL不做任何假设。这意味着我们允许代理通过推导一个没有本能操作符的单一代数来解决两个环境。
- en: Open the EDL_12_3_GEPPY_Generalize.ipynb notebook in Google Colab. Refer to
    the appendix if you need assistance. Run all the cells in the notebook by selecting
    Runtime > Run All from the menu.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Colab中打开EDL_12_3_GEPPY_Generalize.ipynb笔记本。如需帮助，请参阅附录。通过选择菜单中的“运行”>“运行所有”来运行笔记本中的所有单元格。
- en: The only change to this notebook is the definition of the `primitive` set being
    used to build the expression tree, as shown in listing 12.20\. The main change
    from the IL example is the omission of the instinct operators and the addition
    of the `protected_ div` and `ephemeral` constants. Aside from the extra inputs,
    this set of operators is the same as the one we used for the base function derivation
    on a single environment.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这个笔记本的唯一变化是用于构建表达式树的`primitive`集的定义，如列表12.20所示。与IL示例相比，主要变化是省略了本能操作符，并添加了`protected_
    div`和`ephemeral`常量。除了额外的输入外，这个操作符集与我们用于单个环境上的基本函数推导所使用的操作符集相同。
- en: 'Listing 12.20 EDL_12_3_GEPPY_Generalize.ipynb: Setting up the `primitive` set'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.20 EDL_12_3_GEPPY_Generalize.ipynb：设置`原始`集
- en: '[PRE19]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Uses the same inputs
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用相同的输入
- en: ❷ Includes the complex operators
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 包含复杂的操作符
- en: ❸ Doesn’t include instincts
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 不包含本能
- en: ❹ Adds constants
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 添加常数
- en: The rest of the notebook is the same as we saw previously, so just sit back
    and watch the evolution—or, perhaps, lack thereof. Indeed, by running this example
    over multiple environments, you will find that, at best, the agent converges to
    only getting close to solving a single environment. Figure 12.10 shows an example
    of the video output displaying this failure.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本中的其余部分与我们之前看到的一样，所以请放松并观看进化过程——或者，也许，缺乏进化。确实，通过在多个环境中运行此示例，你会发现，在最理想的情况下，智能体只能接近解决单个环境。图12.10展示了显示这种失败的示例视频输出。
- en: '![](../Images/CH12_F10_Lanham.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F10_Lanham.png)'
- en: Figure 12.10 The failure of an agent to generalize across both tasks
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.10 智能体无法在两个任务中推广的失败
- en: So what’s going on? How is it possible that reusing previously developed functions
    or instincts as operators in a new function derivation is more successful than
    deriving a new equation? The simple answer to the problem is limiting complexity
    and choices. Reusable instincts reduce complexity and choices when evolving new
    functions.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，发生了什么？为什么将先前开发的函数或本能作为新函数导出的操作符比导出新方程更成功？对这个问题的简单答案是限制复杂性和选择。可重用的本能降低了在进化新函数时的复杂性和选择。
- en: This concept of reuse and development of reusable code and functions is a cornerstone
    of today’s software development best practices. Today, coders build applications
    from numerous previously developed components or functions. What has evolved today
    in the software industry could very well just be mimicking an evolutionary best
    practice developed millions of years ago.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这种重用和开发可重用代码和函数的概念是当今软件开发最佳实践的基石。今天，编码者从众多先前开发的组件或函数中构建应用程序。今天软件行业所发展的，可能只是模仿数百万年前形成的进化最佳实践。
- en: 'Figure 12.11 shows how instincts may evolve over time, using an example of
    cephalopod (octopus) evolution. Early on, the organism may have evolved hardcoded
    instincts not unlike what we did in the EDL_12_2_GEPPY_Gyms.ipynbnotebook. Through
    another stage of evolution, the organism then may evolve a tertiary instinct that
    allows itself to use both instincts at the same time. Finally, at the last stage
    of evolution, the cephalopod develops a new type of instinct: a system-2 instinct,
    or an instinct that allows itself to think.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.11展示了本能如何随时间进化，以章鱼（章鱼）进化为例。在早期，生物体可能进化了硬编码的本能，这与我们在EDL_12_2_GEPPY_Gyms.ipynb笔记本中所做的不太一样。通过进化的另一个阶段，生物体可能进化出一种三级本能，使其能够同时使用两种本能。最后，在进化的最后阶段，头足类发展出一种新的本能类型：系统-2本能，或允许其思考的本能。
- en: Cephalopod (octopus) evolution
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 头足类（章鱼）进化
- en: The octopus is an incredible creature that shows advanced intelligence in the
    form of tool use and conscious behavior. What makes the octopus especially unique
    is that its evolutionary path is far removed from what we normally consider higher
    life forms to have developed from. It is also unique in that it has no central
    nervous system or brain, and it is believed that much of an octopus’s thoughts
    are generated throughout its body. Understanding how cephalopods evolve will likely
    provide us with incredible insight not only into the validity of IL but how all
    conscious thought may have evolved.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 章鱼是一种令人难以置信的生物，它以工具使用和有意识的行为形式表现出高级智力。使章鱼特别独特的是，它的进化路径与我们通常认为的高等生命形式从哪里发展出来的大相径庭。它还独特之处在于它没有中枢神经系统或大脑，据信章鱼的大多数思想是在其整个身体中产生的。了解头足类的进化可能会为我们提供关于IL的有效性以及所有有意识的思想可能如何进化的深刻见解。
- en: '![](../Images/CH12_F11_Lanham.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F11_Lanham.png)'
- en: Figure 12.11 IL during evolution
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.11 进化过程中的IL
- en: In the next section, we look at one possible approach to modeling, developing,
    and evolving a dual-process system level-2 instinct. Before that, though, let’s
    look at some helpful learning examples that will help your recall.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨一种可能的建模、开发和进化双过程系统级-2本能的方法。在此之前，让我们看看一些有用的学习示例，这将有助于你的回忆。
- en: 12.3.4 Learning exercises
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3.4 学习练习
- en: 'Use the following exercises to improve your understanding of the material and
    perhaps even develop new tricks and techniques on your own:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习来提高你对材料的理解，也许甚至可以自己开发新的技巧和技术：
- en: Remove one of the base instincts from the `primitive` set of notebook example
    EDL_12_3_GEPPY_Instinctual.ipynb and then run the exercise again. Are you getting
    similar results using only a single instinct?
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从笔记本示例 EDL_12_3_GEPPY_Instinctual.ipynb 的 `原始` 集合中移除一个基本本能，然后再次运行练习。你只使用一个本能就能得到类似的结果吗？
- en: Go back and run the EDL_12_2_GEPPY_Gyms.ipynb notebook to derive new equations
    that use different operators. Try adding new operators, like `cos` or `sin`. Next,
    use those equations in notebook EDL_12_3_GEPPY_Instinctual .ipynb to see the results.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回并运行 EDL_12_2_GEPPY_Gyms.ipynb 笔记本，以推导出使用不同运算符的新方程。尝试添加新的运算符，如 `cos` 或 `sin`。接下来，将这些方程用于笔记本
    EDL_12_3_GEPPY_Instinctual .ipynb 中，以查看结果。
- en: Add more operators to the EDL_12_3_GEPPY_Instinctual.ipynb, including the instincts,
    and see what effect this has on agent generalization.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向 EDL_12_3_GEPPY_Instinctual.ipynb 添加更多运算符，包括本能，并看看这对代理泛化有什么影响。
- en: In the next section, we continue looking at ways to generalize learning by looking
    at another approach to developing dual-process system-2 instincts.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们继续探讨通过查看开发双过程系统-2 本能的另一种方法来泛化学习。
- en: 12.4 Generalized learning with genetic programming
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.4 使用遗传编程进行泛化学习
- en: Genetic programming is the basis for the GEP techniques we have been exploring
    with GEPPY. With GP, it is possible to develop structured code that can emulate
    decision-making processes with Boolean logic, for instance. Not only is GP a powerful
    ML technique capable of developing interesting solutions, but it can also illuminate
    how a system-2 thought process or instinct can be evolved.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传编程是我们使用 GEPPY 探索的 GEP 技术的基础。使用 GP，可以开发出能够用布尔逻辑模拟决策过程的结构化代码，例如。GP 不仅是一种强大的机器学习技术，能够开发出有趣的解决方案，而且还能阐明系统-2
    思维过程或本能如何进化。
- en: 'In this section, we look at a classic genetic programming example: the genetic
    ant. In the example, an `ant` agent evolves to search through an environment to
    find and consume food. This example was derived from the standard DEAP examples
    and modified here to demonstrate important concepts and show how the `ant` could
    be generalized to eat from multiple different environments.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们查看一个经典的遗传编程示例：遗传蚂蚁。在这个示例中，一个 `ant` 代理通过在环境中搜索以找到并消耗食物而进化。这个示例是从标准的 DEAP
    示例中派生出来的，并在此处修改以展示重要概念，并展示如何将 `ant` 泛化以从多个不同的环境中进食。
- en: Open the EDL_12_4_DEAP_Ant.ipynb notebook in Google Colab. Refer to the appendix
    if you need assistance. Run all the cells in the notebook by selecting Runtime
    > Run All from the menu.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Google Colab 中打开 EDL_12_4_DEAP_Ant.ipynb 笔记本。如有需要，请参考附录。通过选择菜单中的“运行”>“运行所有”来运行笔记本中的所有单元格。
- en: This notebook uses the GP components from DEAP, and as such, the example is
    somewhat different, but much of the code is the same as we have seen several times
    previously. GP is very similar to GEP and uses a `primitive` set to define the
    main set of functions, as shown in listing 12.21\. Unlike GEP with GEPPY, the
    functions in GP are not expression trees but actual code implementations. If you
    scroll down to the setup of the `primitive` set, you can see how the base functions
    are added. Notice how `PrimitiveSet` is constructed to accept no inputs. This
    is because the generated code pulls the needed inputs on its own as it runs. Next,
    we see the addition of three `primitive` binary or tertiary operators followed
    by terminal node functions. These functions are executed when the GP expression
    tree or code `routine` is executed.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这个笔记本使用了 DEAP 的 GP 组件，因此示例有些不同，但大部分代码与我们之前多次看到的代码相同。GP 与 GEP 非常相似，使用 `原始` 集合来定义主要函数集，如列表
    12.21 所示。与使用 GEPPY 的 GEP 不同，GP 中的函数不是表达式树，而是实际的代码实现。如果你向下滚动到 `原始` 集合的设置，可以看到如何添加基本函数。注意
    `PrimitiveSet` 是如何构建的，它不接受任何输入。这是因为生成的代码在运行时会自行拉取所需的输入。接下来，我们看到添加了三个 `原始` 二进制或三元运算符，随后是终端节点函数。这些函数在
    GP 表达式树或代码 `例程` 执行时执行。
- en: 'Listing 12.21 EDL_12_4_DEAP_Ant.ipynb: Setting up the `primitive` set'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.21 EDL_12_4_DEAP_Ant.ipynb：设置 `原始` 集合
- en: '[PRE20]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ Represents the agent or environment
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 代表代理或环境
- en: ❷ A new set with no inputs
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 一个没有输入的新集合
- en: ❸ Defines the base primitive operators
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义基本原始运算符
- en: ❹ Defines the terminal or execution functions
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 定义终端或执行函数
- en: Now, we can look at the definitions of the `primitive` operators used to define
    the `ant` agent’s logic. The set up of these functions uses the `partial` function—a
    helper that allows base functions to be wrapped and exposes variable input parameters.
    The three operators used by `ant` are `prog2`, `prog3`, and `if_then_else`, but
    notice how, internally, each function executes the terminal input it is passed,
    as shown in the following listing. That means the higher-level operators consume
    Boolean logic for operation. As a result, the terminal functions, which we look
    at shortly, return `True` or `False`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以查看用于定义蚂蚁代理逻辑的`原始`操作符的定义。这些函数的设置使用`partial`函数——一个允许基础函数被包装并暴露变量输入参数的辅助函数。蚂蚁使用的三个操作符是`prog2`、`prog3`和`if_then_else`，但请注意，在内部，每个函数都会执行它接收的终端输入，如下面的列表所示。这意味着高级操作符消耗布尔逻辑进行操作。因此，我们稍后将看到的终端函数返回`True`或`False`。
- en: 'Listing 12.22 EDL_12_4_DEAP_Ant.ipynb: Setting up the logic functions'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.22 EDL_12_4_DEAP_Ant.ipynb：设置逻辑函数
- en: '[PRE21]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ The base partial function
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 基础部分函数
- en: ❷ The operator accepts two inputs
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 操作符接受两个输入
- en: ❸ The operator accepts three inputs
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 操作符接受三个输入
- en: ❹ The conditional operator
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 条件操作符
- en: The terminal functions are written into the `AntSimulator` class, as shown in
    listing 12.23\. Don’t be too concerned about the actual code within each function.
    This code deals with the `ant` agent’s position, movement, and facing on a grid
    environment. It is interesting to note that these terminal functions take and
    express no outputs.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 终端函数被写入`AntSimulator`类中，如列表12.23所示。不要过于关注每个函数中的实际代码。这段代码处理蚂蚁代理在网格环境中的位置、移动和朝向。值得注意的是，这些终端函数既不接收也不输出任何输出。
- en: 'Listing 12.23 EDL_12_4_DEAP_Ant.ipynb: Terminal functions'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.23 EDL_12_4_DEAP_Ant.ipynb：终端函数
- en: '[PRE22]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ Turns the ant to face 90 degrees left
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将蚂蚁转向90度向左
- en: ❷ Turns the ant to face 90 degrees right
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将蚂蚁转向90度向右
- en: ❸ Moves the ant forward and consumes any food
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 蚂蚁向前移动并消耗任何食物
- en: From the terminal functions, we move on to look at the one-operator custom function
    the `ant` implements. Again, the code within the function checks the grid to determine
    whether the `ant` senses food ahead of itself and the direction it is facing.
    The `sense_ food` function, shown in the following listing, is what detects whether
    the `ant` is currently facing food.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 从终端函数中，我们继续查看蚂蚁实现的单操作符自定义函数。再次强调，函数内的代码会检查网格以确定蚂蚁是否感知到前方有食物以及它面对的方向。下面的列表中展示的`sense_food`函数就是检测蚂蚁当前是否面对食物的函数。
- en: 'Listing 12.24 EDL_12_4_DEAP_Ant.ipynb: Custom operator functions'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.24 EDL_12_4_DEAP_Ant.ipynb：自定义操作符函数
- en: '[PRE23]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ❶ Custom operator functions
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 自定义操作符函数
- en: ❷ The internal terminal helper function
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 内部终端辅助函数
- en: ❸ Uses the predefined operator function if_then_else
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用预定义的操作符函数if_then_else
- en: The `evaluate` function, called `evalArtificalAnt` here, used to determine `individual`
    `fitness` is simple. It starts by first converting the `individual gene` sequence
    to compiled Python code using `gp.compile`. The output `routine` is run using
    the `AntSimulator` `run` function. After that, the `fitness` of the `ant` is output,
    based on the number of food squares the `ant` consumed, as shown in the following
    listing.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 被称为`evalArtificalAnt`的`evaluate`函数用于确定`个体`的`适应度`很简单。它首先使用`gp.compile`将`个体基因`序列转换为编译后的Python代码。然后，使用`AntSimulator`的`run`函数运行输出`例程`。之后，根据蚂蚁消耗的食物方格数量输出蚂蚁的`适应度`，如下面的列表所示。
- en: 'Listing 12.25 EDL_12_4_DEAP_Ant.ipynb: The `fitness` `evaluate` function'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.25 EDL_12_4_DEAP_Ant.ipynb：`fitness` `evaluate`函数
- en: '[PRE24]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ❶ Compiles to Python code
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 编译成Python代码
- en: ❷ Runs the script routine
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 运行脚本例程
- en: ❸ Returns the fitness based on the food eaten
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 根据消耗的食物返回适应度
- en: The `run` function of the `AntSimulator` is where the resulting expression code
    tree is executed. Before executing that, though, the environment is reset, as
    is typical. Then, if the `ant` agent has remaining moves, it executes a move by
    calling the generated or evolved `routine` function, as shown in the following
    listing. You can think of this as some form of conscious decision-making thought
    process, described in dual-process theory as system 2.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '`AntSimulator`的`run`函数是执行结果表达式代码树的地方。在执行之前，环境通常会重置。然后，如果蚂蚁代理还有剩余的动作，它会通过调用生成的或进化的`例程`函数来执行一个动作，如下面的列表所示。你可以将其视为某种形式的意识决策思维过程，这在双过程理论中被描述为系统2。'
- en: 'Listing 12.26 EDL_12_4_DEAP_Ant.ipynb: Running routines'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.26 EDL_12_4_DEAP_Ant.ipynb：运行例程
- en: '[PRE25]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: ❶ Resets the simulation environment
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 重置模拟环境
- en: ❷ Checks if there are moves remaining
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 检查是否有剩余的动作
- en: ❸ Executes the GP code
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 执行 GP 代码
- en: Unlike the Gym environments we looked at previously, the `AntSimulator` can
    load an arbitrarily described environment, as shown in the following listing.
    The first environment we try to evolve an `ant` to be successful in is from the
    original DEAP example.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前查看的 Gym 环境 不同，`AntSimulator` 可以加载任意描述的环境，如下面的列表所示。我们首先尝试进化一个`ant`以在原始 DEAP
    示例中成功。
- en: 'Listing 12.27 EDL_12_4_DEAP_Ant.ipynb: Defining the environment'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.27 EDL_12_4_DEAP_Ant.ipynb：定义环境
- en: '[PRE26]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: ❶ Writes the file to the file system with a name
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将文件以名称写入文件系统
- en: ❷ S represents the starting location.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ S代表起始位置。
- en: '❸ # is food.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '❸ #是食物。'
- en: ❺ . is empty space.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ .是空空间。
- en: This example is very quick to run, and after it completes, you get to witness
    how the best `ant` moves through the environment in real time, as shown in figure
    12.12\. As you watch the `ant`, notice how it moves through the grid space.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子运行非常快，完成后，你可以实时见证最佳`ant`如何在环境中移动，如图 12.12 所示。当你观察`ant`时，注意它是如何穿过网格空间的。
- en: '![](../Images/CH12_F12_Lanham.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F12_Lanham.png)'
- en: Figure 12.12 The `ant` moving through the environment
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.12 `ant` 在环境中移动
- en: This is a fun example to run and explore. It also demonstrates the power of
    genetic programming for creating code, but more importantly, it exposes a method
    to create that instinctual system level-2 thought process. To further demonstrate
    this capability, let’s continue with the same notebook.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很有趣的例子，可以运行和探索。它还展示了遗传编程在创建代码方面的力量，但更重要的是，它揭示了一种创建本能的系统级 2 思维过程的方法。为了进一步展示这种能力，让我们继续使用相同的笔记本。
- en: '![](../Images/CH12_F13_Lanham.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F13_Lanham.png)'
- en: Figure 12.13 Adding two environments
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.13 添加两个环境
- en: Continue with the EDL_12_4_DEAP_Ant.ipynb notebook in Colab. Assuming the notebook
    has completed execution, we just review the remaining cells to see how an `ant`
    can be evolved to generalize across environments. Figure 12.13 shows the two additional
    environments we load into the `AntSimulator` with the hope the evolved `ants`
    can generalize across environments. Next, we look at the code to add those environments
    to the `ant` simulator, shown in listing 12.28.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Colab 中继续使用 EDL_12_4_DEAP_Ant.ipynb 笔记本。假设笔记本已完成执行，我们只需查看剩余的单元格，以了解如何进化`ant`以泛化到不同环境。图
    12.13 显示了我们加载到`AntSimulator`中的两个附加环境，希望进化的`ants`可以跨环境泛化。接下来，我们查看将那些环境添加到`ant`模拟器的代码，如下列
    12.28 所示。
- en: 'Listing 12.28 EDL_12_4_DEAP_Ant.ipynb: Adding environments to the simulator'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.28 EDL_12_4_DEAP_Ant.ipynb：将环境添加到模拟器
- en: '[PRE27]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: ❶ The clear existing environment
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 清除现有环境
- en: ❷ Adds environment 2
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加环境 2
- en: ❸ Adds environment 3
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加环境 3
- en: Without performing any further evolution, we can test the current best `ant`
    on these new environments by simply running the `visual_run` function, as shown
    in the following listing. As we can see from running the `ant` on these two new
    environments, they don’t perform very well. We can improve on this by evolving
    the `ant` in all three environments simultaneously.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在不进行任何进一步进化的情况下，我们可以通过简单地运行`visual_run`函数来测试当前最佳`ant`在这些新环境中的表现，如下面的列表所示。从在两个新环境中运行`ant`的结果来看，它们的性能并不好。我们可以通过同时在这三个环境中进化`ant`来改进这一点。
- en: 'Listing 12.29 EDL_12_4_DEAP_Ant.ipynb: Testing the `ant`'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.29 EDL_12_4_DEAP_Ant.ipynb：测试`ant`
- en: '[PRE28]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: ❶ Visualizes the ant on new environments
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在新环境中可视化`ant`
- en: Evolving the `ant` on all three environments is now just a matter of adding
    the specific environments to the simulator and rerunning the evolution. Internally,
    an `ant` evaluating the call to the `reset` function puts the `ant` into an environment
    chosen at random. Since the `ant` is now randomly switching to different environments,
    the resulting code `routine` must account for a better search for food, as shown
    in the following listing.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有三个环境中进化`ant`现在只是将特定环境添加到模拟器中并重新运行进化的简单问题。内部，一个评估`reset`函数调用的`ant`将`ant`放入随机选择的环境。由于`ant`现在可以随机切换到不同的环境，所以生成的代码`routine`必须考虑到更好的食物搜索，如下面的列表所示。
- en: 'Listing 12.30 EDL_12_4_DEAP_Ant.ipynb: Generalizing the `ant`'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.30 EDL_12_4_DEAP_Ant.ipynb：泛化`ant`
- en: '[PRE29]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: ❶ Clears existing environments
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 清除现有环境
- en: ❷ Adds new environments
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加新环境
- en: ❸ Evolves the ant
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 进化`ant`
- en: After the evolution has completed, you can visualize how well the `ant` now
    performs by, again, running the `ant.visualize_run` function call. This exercise
    demonstrates how well genetic programming can be used to generalize an agent to
    solve for multiple environments. It does this by separating the lower-level terminal
    functions, or what we may call *activities* or *instincts*, from the higher-level
    Boolean logic that may represent thought. As a result, the `ant` agent doesn’t
    just derive a single core function or expression tree but, rather, two distinct
    systems of operation or thought.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 进化完成后，你可以通过再次运行`ant.visualize_run`函数调用来可视化`蚂蚁`现在的表现。这个练习展示了基因编程如何被用来泛化一个智能体以解决多个环境。它是通过将低级终端函数，或我们可能称之为*活动*或*本能*，与可能代表思维的更高级布尔逻辑分开来做到这一点的。因此，`蚂蚁`智能体不仅推导出一个单一的核心函数或表达式树，而是两个不同的操作或思维系统。
- en: Genetic programming is, therefore, a potential path in the search for the instinct
    or process that describes the dual-process system’s level-2 thought. But keep
    in mind that one system of thought may not resemble others, and it still needs
    to be determined if this can lead to higher forms of generalization and consciousness
    in AI. We discuss evolution and the search for a higher form of AI and ML in greater
    depth in the next section. Before that, though, let’s explore some learning exercises.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基因编程是寻找描述双过程系统级2思维的本能或过程的潜在途径。但请记住，一个思维系统可能与其他系统不相似，并且还需要确定这能否导致AI和机器学习中的更高形式的一般化和意识。我们在下一节更深入地讨论了进化和寻找更高形式的人工智能和机器学习。在此之前，让我们先探索一些学习练习。
- en: 12.4.1 Learning exercises
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4.1 学习练习
- en: 'Use the following exercises to expand your knowledge of genetic programming
    and the genetic ant problem:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习来扩展你对基因编程和遗传蚂蚁问题的知识：
- en: Add a few new environments for the `ant` to explore and evolve on. Make sure
    these new environments have roughly the same number of food squares.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为`蚂蚁`添加一些新的环境以供探索和进化。确保这些新环境有大致相同数量的食物方块。
- en: Think of ways you could alter or add to the terminal functions. Perhaps, you
    can add a `jump` or `fly` function that moves the `ant` several spaces in the
    direction it is facing.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 想想你可以如何改变或添加终端函数。也许，你可以添加一个`跳`或`飞`函数，使`蚂蚁`在它面对的方向上移动几个空间。
- en: Add a new operator `sense` function, like `sense_food`, that could be used to
    sense food, or anything else, at distances.
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个新的操作符`感知`函数，如`感知食物`，可以在一定距离上感知食物或其他任何东西。
- en: Genetic programming gives us a potential base for potentially finding a higher-order,
    dual-process system level-2 function or instinct. We discuss the potential future
    of IL and EDL in the next section of the book.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 基因编程为我们提供了一个潜在的基础，以寻找更高阶、双过程系统级2功能或本能。我们在本书的下一节讨论了IL和EDL的潜在未来。
- en: 12.5 The future of evolutionary machine learning
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.5 进化机器学习的未来
- en: In this section, we look into the future of evolutionary search for the application
    of improving ML and, of course, DL. While our focus in this book has been on DL,
    evolutionary search has far-reaching applications in other forms of ML. Evolutionary
    search has the potential to help guide us to new forms of learning or sublearning
    methods, like IL. We start our journey toward what may be possible with evolution
    search in the next section with a discussion on whether evolution itself may be
    broken.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了进化搜索在改善机器学习（ML）和，当然，深度学习（DL）应用方面的未来。虽然本书的重点是深度学习，但进化搜索在其他形式的机器学习中有广泛的应用。进化搜索有潜力帮助我们引导到新的学习形式或子学习方法，如IL。我们通过讨论进化本身是否可能出了问题，开始我们的旅程，探讨进化搜索可能带来的可能性，在下一节中。
- en: 12.5.1 Is evolution broken?
  id: totrans-314
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.1 进化是否出了问题？
- en: In recent years, our understanding of the evolutionary process has come under
    harsh scrutiny. Now, evolution being scrutinized is nothing new, but this time
    the critics are evolutionists themselves. Evolutionists claim our current understanding
    of the evolutionary process does not account for the dramatic changes we see between
    steps in evolution.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，我们对进化过程的理解受到了严厉的审视。现在，受到审视的进化并不是什么新鲜事，但这一次，批评者本身就是进化论者。进化论者声称，我们对进化过程的当前理解没有解释进化步骤之间的巨大变化。
- en: Darwin himself questioned his theory of evolution for 2 decades for very similar
    reasons. He wrestled with the uneasy feeling that mutation, the cornerstone of
    evolutionary change, could not develop something so complex as the human eye.
    Over time and with enormous statistical and fossil evidence, mutation-driven evolution
    became accepted.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 达尔文本人也因非常类似的原因对进化理论质疑了20年。他挣扎于一种不安的感觉，即作为进化变化基石的突变无法发展出像人眼这样复杂的东西。随着时间的推移和大量的统计和化石证据，突变驱动的进化被接受。
- en: You may have also had similar feelings toward evolution if you have run through
    many of the longer-running exercises in this book. Some of those exercises simulated
    `mutation`-based evolution over a thousand `individuals` for thousands of `generations`,
    only producing very minor changes. It is certainly easy to question `mutation`
    as the primary director of change, but what else could there be?
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经尝试过这本书中许多持续时间较长的练习，你可能也对进化也有过类似的感受。其中一些练习模拟了基于`突变`的进化过程，涉及成千上万的`个体`和成千代的`世代`，只产生了非常微小的变化。当然，质疑`突变`作为变化的主要导演是很容易的，但除此之外还有什么可能呢？
- en: 12.5.2 Evolutionary plasticity
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.2 进化塑性
- en: '*Evolutionary* *plasticity*, derived from the concept of phenotypic plasticity,
    attempts to describe possible genetic changes without mutation. The basic concept
    is that genetic changes may occur within an organism during its lifetime, and
    these changes then get passed on to future `generations`. The changes are not
    random, as they are in mutation, but a direct result of interacting with other
    organisms and the environment.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '*进化* *塑性*，源于表型塑性的概念，试图描述没有突变的可能遗传变化。基本概念是，遗传变化可能发生在生物在其一生中，然后这些变化被传递给未来的`世代`。这些变化不是随机的，就像突变那样，而是与其他生物和环境相互作用的直接结果。'
- en: Our modern and rapid innovations in DNA research and the understanding of our
    and other species’ genomes have changed our understanding of what is possible.
    No longer do we need to perform selective breeding to enforce genetic changes,
    but rather, we can now directly modify genomes and let those modifications pass
    on to future `generations`. What has also been shown is the ease at which those
    changes can be undertaken—which also brings to question our understanding of evolution.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在DNA研究和我们及其他物种基因组理解方面的现代和快速创新改变了我们对可能性的理解。我们不再需要通过选择性育种来强制遗传变化，而是现在可以直接修改基因组，并让这些修改传递给未来的`世代`。也已经显示，这些变化可以很容易地进行——这也对我们的进化理解提出了质疑。
- en: CRISPR technology
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: CRISPR技术
- en: '*Clustered regularly interspaced short palindromic repeats* (CRISPR) is a very
    new technology that allows humans to modify ourselves and other species by essentially
    performing gene splicing. In some cases, this means removing bad genes, and in
    others, it simply means replacing genes to produce some new effect, like glowing.
    What makes this technology so impressive is that it provides a low tech means
    to alter the genome of a species. You can, for instance, buy CRISPR kits on the
    internet that allow you to alter bacteria or even frogs’ DNA.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '*成簇规律间隔短回文重复序列*（CRISPR）是一项非常新的技术，它允许人类通过基因拼接的方式修改自身和其他物种。在某些情况下，这意味着移除不良基因，而在其他情况下，它仅仅意味着替换基因以产生一些新的效果，比如发光。这项技术之所以令人印象深刻，是因为它提供了一种低技术手段来改变物种的基因组。例如，你可以在互联网上购买CRISPR套件，允许你改变细菌甚至青蛙的DNA。'
- en: What comes into question, then, is whether a genome can be altered through very
    specific environmental changes and how we account for such changes in evolution.
    For a traditional evolutionist, this may just be another form of mutation, and
    mutation can describe those changes effectively enough. However, for us digital
    evolutionists, this presents some interesting opportunities for other forms of
    simulation.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，问题就来了，基因组是否可以通过非常具体的环境变化来改变，以及我们如何在进化中解释这些变化。对于一个传统的进化论者来说，这可能只是另一种形式的突变，而突变可以有效地描述这些变化。然而，对于我们这些数字进化论者来说，这提供了其他形式模拟的一些有趣机会。
- en: Either way, evolutionary plasticity likely indicates our understanding of evolution
    is subject to change and, with it, the application of digital evolutionary search,
    where instead of driving evolution through slow and rare mutation, we use other
    genetic operators that provide quicker, selectively driven changes. In the next
    section, we look at our final notebook, which demonstrates evolution with plasticity.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 无论哪种方式，进化塑性可能表明我们对进化的理解是会变化的，随之而来的是数字进化搜索的应用，在这种搜索中，我们不是通过缓慢且罕见的变异来驱动进化，而是使用其他遗传算子，这些算子提供了更快、选择性驱动的变化。在下一节中，我们将查看我们的最终笔记本，该笔记本展示了具有塑性的进化。
- en: 12.5.3 Improving evolution with plasticity
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.3 使用塑性改进进化
- en: In the notebook in this section, we revisit one of our original examples that
    initially demonstrated GA trying to replicate images, like the *Mona Lisa*. We
    make a single and simple change here that implements a new `plasticity` operator
    that could be used to enhance digital evolution. The implementation of this operator
    is just one interpretation of how a `plasticity` operator may function.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中的笔记本中，我们回顾了我们最初演示GA尝试复制图像（如*蒙娜丽莎*）的一个原始示例。在这里，我们进行了一个单一且简单的更改，实现了一个新的`塑性`算子，该算子可以用来增强数字进化。这个算子的实现只是对`塑性`算子可能如何工作的一种解释。
- en: Open the EDL_12_5_Genetic_Plasticity.ipynb notebook as well as EDL_2_6_ Genetic_Algorithms.ipynb,
    for comparison. Go ahead and run both notebooks via Runtime > Run All from the
    menu.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 打开EDL_12_5_Genetic_Plasticity.ipynb笔记本以及EDL_2_6_Genetic_Algorithms.ipynb，以便进行比较。请从菜单中选择运行>运行所有来运行这两个笔记本。
- en: Review the code for both notebooks. We only focus on the implementation of the
    `plasticity` operator here. In biology, plasticity assumes that any environmental
    change is positive for the organism, so to simulate a `plasticity` operator, we
    first determine `individual` `fitness` as a baseline, as shown in the following
    listing. Then, we enforce a 100% chance of `mutation` of a new `individual` and
    determine the changed `fitness`. If the change improves `fitness`, the modified
    `individual` is returned; otherwise, we keep the original.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 检查两个笔记本的代码。我们在这里只关注`塑性`算子的实现。在生物学中，塑性假设任何环境变化对生物体都是有益的，因此为了模拟`塑性`算子，我们首先确定`个体`的`适应性`作为基准，如下所示。然后，我们强制执行100%的新`个体`变异机会，并确定变化的`适应性`。如果变化提高了`适应性`，则返回修改后的`个体`；否则，我们保留原始内容。
- en: 'Listing 12.31 EDL_12_5_Genetic_Plasticity.ipynb: The genetic `plasticity` operator'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.31 EDL_12_5_Genetic_Plasticity.ipynb：遗传`塑性`算子
- en: '[PRE30]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ❶ Makes a copy to keep the original
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建副本以保留原始内容
- en: ❷ Determines the fitness before and after the change
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在更改前后确定适应性
- en: ❸ Enforces the mutated change
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 强制执行变异后的更改
- en: ❹ Returns the more fit individual
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 返回适应性更高的个体
- en: Figure 12.14 shows the results of the evolution for the original genetic operator’s
    example from chapter 2 and the new one that includes `plasticity`. The output
    was generated by evolving a `population` of 300 `individuals` over 10,000 `generations`
    in both notebooks.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.14显示了第2章中原始遗传算子示例以及包含`塑性`的新算子的进化结果。这两个笔记本中的输出是通过在10,000代中进化300个`个体`的种群来生成的。
- en: '![](../Images/CH12_F14_Lanham.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH12_F14_Lanham.png)'
- en: Figure 12.14 The results of using the genetic `plasticity` operator
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.14 使用遗传`塑性`算子的结果
- en: Computationally, the implementation of this form of `plasticity` is expensive.
    If you run the notebooks side by side, you will clearly notice this difference.
    However, computational differences aside, what is evident is how well this new
    `plasticity` operator improves on the finer details. Perhaps ironically, the eyes
    in the improved notebook are the first to become clearly recognizable.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 从计算角度来看，这种形式的`塑性`实现成本较高。如果你并排运行笔记本，你会清楚地注意到这种差异。然而，除了计算差异之外，明显的是这种新的`塑性`算子如何改进了更细微的细节。也许具有讽刺意味的是，改进后的笔记本中的眼睛首先变得清晰可辨。
- en: The `plasticity` operator developed for this example is an example of how evolution
    can be improved using a slightly modified form of `mutation`. This new operator
    does perform better, as we have seen in this isolated example. Because of the
    added computational expense and the yet unproven theory of plasticity, we have
    not used it in the examples in this book. However, it does pose an interesting
    question about the future of both biological and digital evolution. This example
    does showcase, however, how limiting computation is when using evolutionary search,
    which is something we explore in the next section.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 为此例开发的 `塑性` 操作符是进化如何通过稍微修改的 `变异` 形式得到改进的一个例子。正如我们在这一独立例子中看到的，这个新操作符确实表现得更好。由于额外的计算费用和尚未证实的塑性理论，我们还没有在本书的例子中使用它。然而，它确实提出了一个关于生物和数字进化未来的有趣问题。然而，这个例子确实展示了在进化搜索中使用计算的限制，这是我们将在下一节中探讨的内容。
- en: 12.5.4 Computation and evolutionary search
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.5.4 计算和进化搜索
- en: One of, perhaps, the key limiting factors in using evolutionary search for optimizing
    DL or ML is the additional cost of the computation. This is something we witnessed
    and struggled to accommodate in several examples in this book. It also becomes
    a key limiting factor in the practical application of evolutionary search.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 使用进化搜索来优化深度学习（DL）或机器学习（ML）的一个可能的关键限制因素是额外的计算成本。这是我们在这本书的几个例子中见证并努力适应的事情。这也成为进化搜索在实际应用中的关键限制因素。
- en: DL has reaped the benefits of advances in the gaming industry that allowed it
    to use fast GPUs to reduce computational costs immensely. It is because of those
    computational advancements that DL has the edge to become a key AI and ML technology
    of the future. But what if computationally evolutionary search could also be improved
    upon using distributed computing or perhaps even quantum computers?
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）已经从游戏行业的进步中受益，这使得它能够使用快速的 GPU 来大幅降低计算成本。正是因为这些计算进步，DL 才有优势成为未来人工智能（AI）和机器学习（ML）的关键技术。但如果我们能够通过分布式计算或甚至量子计算机来改进计算上的进化搜索呢？
- en: In this book, DEAP has been applied with Google Colab, which limits the use
    of the framework-distributed computational abilities. For any serious projects,
    though, using distributed computing would likely alleviate much of the additional
    computational cost. Unfortunately, not a lot of work has been done in this area
    yet, so how effective this is remains to be seen.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，DEAP 已经与 Google Colab 结合使用，这限制了框架分布式计算能力的应用。然而，对于任何严肃的项目来说，使用分布式计算可能会大大减轻额外的计算成本。不幸的是，在这个领域还没有做很多工作，所以它的有效性还有待观察。
- en: However, if the cost or time of evolutionary search can be reduced, then this
    opens further possibilities for more expensive exploration. Techniques like IL
    or using evolution to search for new learning methods may be more practical. Instead
    of researchers spending hours developing new algorithms, the search could potentially
    be performed by evolution. In the next and final section of this book, we explore
    a technique using IL and DL.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果进化搜索的成本或时间可以降低，那么这将为更昂贵的探索开辟更多的可能性。像 IL 或使用进化来寻找新的学习方法等技术可能更加实用。研究人员不必花费数小时开发新算法，搜索可能由进化来完成。在本书的下一节和最后一节中，我们将探讨一种使用
    IL 和 DL 的技术。
- en: 12.6 Generalization with instinctual deep and deep reinforcement learning
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12.6 本能深度学习和深度强化学习中的泛化
- en: In this final section, we look at a notebook that demonstrates IL being applied
    to DRL to generalize an agent across multiple environments. This exercise mimics
    the IL generalization example we developed previously but this time applied through
    DRL. DRL networks like the one we used for the DQN example are quite simple and
    make a good foundation for an application of IL.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的最后，我们查看了一个笔记本，展示了如何将 IL 应用到 DRL 中，以泛化多个环境中的智能体。这个练习模仿了我们之前开发的 IL 泛化例子，但这次是通过
    DRL 应用。像我们在 DQN 例子中使用的 DRL 网络相当简单，为 IL 的应用提供了一个良好的基础。
- en: 'Figure 12.15 shows how a pair of DQN DRL networks are used to solve two different
    environments. However, the middle layer of each network has been split into three
    distinct shareable instinct slots, where the goal of generalizing the learning
    for both networks is to find a shared base set of instincts: the instinct pool.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.15 展示了一对 DQN DRL 网络如何用于解决两个不同的环境。然而，每个网络的中层已经被分割成三个不同的可共享本能槽位，这两个网络学习的目标是找到一组共享的基本本能：本能池。
- en: '![](../Images/CH12_F15_Lanham.png)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F15_Lanham.png)'
- en: Figure 12.15 IL applied to DL
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.15 将IL应用于DL
- en: We can also see in figure 12.15 that shared instincts don’t have to be in the
    same position in either network. Again, as we saw in the exercise with Geppy,
    reused instinct function operators are often mixed and matched to solve both environments.
    However, unlike with Geppy, we strictly limit the placement of these instincts
    and how they operate, even going a bit further and allowing the top and bottom
    layers of each network to be trained specifically to the environment.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在图12.15中看到，共享本能不必在两个网络中的相同位置。同样，正如我们在Geppy练习中看到的那样，重用的本能函数操作符通常混合匹配来解决两个环境。然而，与Geppy不同，我们严格限制这些本能的放置和操作方式，甚至更进一步，允许每个网络的顶层和底层专门针对环境进行训练。
- en: Open the EDL_12_6_Instinctual_DQN_GYMS.ipynb notebook. Go ahead and run both
    notebooks via Runtime > Run All from the menu. This notebook has been extended
    from EDL_11_5_DQN_GYMS.ipynb, so if you need a review on DQN or DRL, refer to
    section 11.5.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 打开EDL_12_6_Instinctual_DQN_GYMS.ipynb笔记本。请通过菜单中的“运行”>“运行所有”来运行这两个笔记本。这个笔记本是从EDL_11_5_DQN_GYMS.ipynb扩展而来的，所以如果你需要回顾DQN或DRL，请参考第11.5节。
- en: The first thing we look at is the modification of the `DQNAgent` class`_build_model`
    function, as shown in listing 12.32\. To slice the network up into functional
    chunks (instincts), we use the Keras functional API, which allows a DL network
    to be described in terms of functions. That also means each layer section can
    be treated as a function. So instead of building the model from a static set of
    layer or function definitions, we pass in a block of layers in the instincts list.
    The first and last elements of this list are layers defined specifically for the
    environment, and the middle layers or functions are the reusable instincts. Figure
    12.16 explains how the `build_model` function is converted from a standard DL
    network to an instinctual one.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先关注的是对`DQNAgent`类`_build_model`函数的修改，如列表12.32所示。为了将网络分割成功能块（本能），我们使用了Keras功能API，它允许深度学习网络以函数的形式进行描述。这也意味着每个层部分都可以被视为一个函数。因此，我们不是从一组静态的层或函数定义中构建模型，而是将本能列表中的层块传递进去。这个列表的第一个和最后一个元素是专门为环境定义的层，中间的层或函数是可重用的本能。图12.16解释了如何将`build_model`函数从标准深度学习网络转换为本能网络。
- en: 'Listing 12.32 EDL_12_6_Instinctual_DQN_GYMS.ipynb: Building the model'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.32 EDL_12_6_Instinctual_DQN_GYMS.ipynb：构建模型
- en: '[PRE31]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: ❶ Switches to a Keras functional API
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 切换到Keras功能API
- en: ❷ Loads the layers/instincts
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 加载层/本能
- en: ❸ Executes the forward pass
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 执行前向传递
- en: ❹ Concatenates the instincts
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 连接本能
- en: ❺ Builds/compiles and returns the model
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 构建/编译并返回模型
- en: '![](../Images/CH12_F16_Lanham.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F16_Lanham.png)'
- en: Figure 12.16 Converting to IL
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.16 转换为IL
- en: The notebook contains several example cells that demonstrate how the instincts
    list of layers is populated and then used to create the `DQNAgent`. Here, we focus
    on how the instinct layers are created for training or finding instincts in multiple
    environments, as shown in listing 12.33\. This code creates the base set of instincts
    in the shared layer pool—in this case, a standard `Dense` layer with `8` nodes,
    using `ReLU` activation. Then, we create environment-specific layers for inputs
    and outputs as well as a memory `dequeue` for each environment. In this example,
    we use just two environments, so a pool of four layers will work. If you are applying
    this technique to more than two environments, you may want to increase the size
    of the shared pool.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 这个笔记本包含几个示例单元，展示了如何填充层本能列表并用于创建`DQNAgent`。在这里，我们关注的是如何为多个环境创建本能层，如图列表12.33所示。这段代码在共享层池中创建了本能的基础集合——在这种情况下，是一个具有`8`个节点的标准`Dense`层，使用`ReLU`激活。然后，我们为输入和输出创建了特定于环境的层，以及每个环境的内存`dequeue`。在这个例子中，我们只使用了两个环境，所以四个层的池子就足够了。如果你将这项技术应用于超过两个环境，你可能需要增加共享池的大小。
- en: 'Listing 12.33 EDL_12_6_Instinctual_DQN_GYMS.ipynb: Creating layers'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 列表12.33 EDL_12_6_Instinctual_DQN_GYMS.ipynb：创建层
- en: '[PRE32]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ Gets the number of environments
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 获取环境的数量
- en: ❷ Creates the instinct pool
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建本能池
- en: ❸ Creates input environment-specific layers
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 创建特定于输入环境的层
- en: ❹ Creates output environment-specific layers
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 创建特定于输出环境的层
- en: ❺ Creates a holder for environment memories
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 创建环境内存的持有者
- en: 'Now, to find how the base instincts (functional layers) are shared and reused
    to solve both environments simultaneously, we, of course, use evolutionary search,
    reverting to our old friend: GAs with DEAP. Since we only use three instincts
    per environment, a simple `gene` sequence can be built with three `genes` per
    environment, where each `gene` represents an index into the shared instinct layer
    pool. Figure 12.17 shows how the `gene` sequence is constructed, where each environmental
    model describes a set of indexes that link back to the shared layer pool.'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了找到基本本能（功能层）是如何共享和重用来同时解决两个环境的，我们当然使用进化搜索，回归到我们老朋友：带有 DEAP 的遗传算法（GAs）。由于我们每个环境只使用三个本能，因此可以构建一个简单的`基因`序列，每个环境有三个`基因`，其中每个`基因`代表对共享本能层池的索引。图
    12.17 展示了`基因`序列是如何构建的，其中每个环境模型描述了一组索引，这些索引链接回共享层池。
- en: '![](../Images/CH12_F17_Lanham.png)'
  id: totrans-371
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH12_F17_Lanham.png)'
- en: Figure 12.17 The `gene` sequence of an `individual`
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.17 个体`基因`序列
- en: We can see how this all comes together in the `evaluate` function. The code
    starts by looping over each environment and converting the `gene` sequence to
    layer indexes. This then constructs the set of specific and shared layers to pass
    into the model. Then, a new agent model is constructed and `evaluated` for each
    environment. Notice how the training is blocked until the `evaluate` function
    is called with `train=True` in the following listing—we get to why this is shortly.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在`evaluate`函数中看到这一切是如何结合在一起的。代码首先遍历每个环境，将`基因`序列转换为层索引。然后，构建一组特定和共享层以传递到模型中。然后，为每个环境构建一个新的代理模型并进行`评估`。注意，在以下列表中，训练被阻塞，直到`evaluate`函数以`train=True`被调用——我们很快就会明白这是为什么。
- en: 'Listing 12.34 EDL_12_6_Instinctual_DQN_GYMS.ipynb: The `evaluate` function'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.34 EDL_12_6_Instinctual_DQN_GYMS.ipynb：`evaluate` 函数
- en: '[PRE33]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ Extracts layer indexes from the gene sequence
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从基因序列中提取层索引
- en: ❷ Sets the layers for the model
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为模型设置层
- en: ❸ Creates an agent wrapper for the layers
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 为层创建代理包装器
- en: ❹ Evaluates the agent model on the environment
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在环境中评估代理模型
- en: ❺ Only trains when required
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 仅在需要时进行训练
- en: ❻ Returns the average fitness
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 返回平均适应度
- en: The reason we don’t train the derived model and the specific and shared layers
    for every `individual` is that this can cause internal conflicts or duality. We
    saw this when we tried to train a single model in both environments without using
    instincts. Instead, our goal is to only train the best agent for each `generation`.
    That means all layers are only trained or updated on the best `individual` once
    per evolutionary `generation`. If we were trying to adhere to a strict evolutionary
    search, we would never do this. But if we were to borrow the concept of `plasticity`,
    covered earlier, we could accept this training process is a reactionary improvement
    or `mutation` from the environment.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不针对每个`个体`训练派生模型和特定及共享层的原因是，这可能会导致内部冲突或二义性。我们在尝试在不使用本能的情况下在两个环境中训练单个模型时看到了这一点。相反，我们的目标是只为每个`代`训练最佳的代理。这意味着所有层在每个进化`代`中只针对最佳的`个体`进行一次训练或更新。如果我们试图坚持严格的进化搜索，我们永远不会这样做。但如果我们借鉴之前提到的`可塑性`概念，我们可以接受这种训练过程是来自环境的反应性改进或`变异`。
- en: That means when evolving the environment, we now perform training of the DL
    layers on the best current `individual`, as shown in listing 12.35\. Notice that
    no other training is performed, which means updating or tuning the weights of
    the model is specific to the models’ instincts, which can vary. Because of this
    near randomness of our DQN agent, we remove any exploration or randomness in training.
    You can see this if you look at the `DQNAgent.act` function.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在进化环境时，我们现在在最佳当前`个体`上执行深度学习层（DL）的训练，如列表 12.35 所示。注意，没有进行其他训练，这意味着更新或调整模型权重是针对模型的本能的，这些本能可能不同。正因为我们的
    DQN 代理具有这种近乎随机的特性，所以我们从训练中移除了任何探索或随机性。如果你查看`DQNAgent.act`函数，你会看到这一点。
- en: 'Listing 12.35 EDL_12_6_Instinctual_DQN_GYMS.ipynb: Evolving the instincts'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 12.35 EDL_12_6_Instinctual_DQN_GYMS.ipynb：进化本能
- en: '[PRE34]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: ❶ Performs a generation of evolution
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 执行一代进化
- en: ❷ Runs evaluate on the best and does training
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在最佳个体上运行评估并进行训练
- en: This example has now been simplified for explanation over performance, where
    appropriate. It can produce a generalized set of instincts that can be used to
    solve both environments, but evolution and training take time. A more robust instinctual
    deep learner would likely use smaller and a larger number of instincts, perhaps
    even sharing instincts for both input and output layers.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子现在已经被简化，以解释性能，在适当的情况下。它可以产生一组通用的本能，可以用来解决两种环境，但进化和训练需要时间。一个更健壮的本能深度学习器可能会使用更小和更多数量的本能，甚至可能共享输入和输出层的本能。
- en: The primary goal of IL is to find the base set of instincts or functions that
    can be reused on disparate tasks to generalize a model. The goal is to allow reusing
    functions (instincts) to excel in the way systems generalize learning. IL’s secondary
    goal is finding the function (instinct) that can dynamically reorganize these
    instincts by process or thought.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: IL 的主要目标是找到一组基础本能或函数，可以在不同的任务上重复使用以泛化模型。目标是允许重复使用函数（本能）以在系统泛化学习方面表现出色。IL 的次要目标是找到可以动态重组这些本能的函数（本能），通过过程或思维。
- en: IL is still early in its development, yet it is getting close to solving its
    primary goal. There are still several alternative DL network types, applications,
    and evolutionary search methods that can be applied. It is my hope that researchers
    and students embrace the path to finding these base instinct functions shared
    amongst networks.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: IL 仍处于发展的早期阶段，但正接近解决其首要目标。仍然有几种替代的 DL 网络类型、应用和进化搜索方法可以应用。我希望能有研究人员和学生拥抱寻找这些在网络中共享的基本能函数的道路。
- en: Summary
  id: totrans-391
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Evolution can be applied to many other forms of ML and provides new opportunities
    for expanding our knowledge.
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进化可以应用于许多其他形式的机器学习，并为扩展我们的知识提供了新的机会。
- en: Geppy and gene expression programming are extensions to GAs that work by writing
    coherent code or functions. Geppy can be an excellent tool for generating readable
    functions for complex function approximation problems.
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geppy 和基因表达式编程是 GAs 的扩展，通过编写连贯的代码或函数来工作。Geppy 可以是生成复杂函数逼近问题的可读函数的绝佳工具。
- en: Geppy can be applied to evolutionary search on a DRL problem as a function approximation
    tool to generate single readable functions. Generated functions can then be used
    to apply and solve complex control environments from the OpenAI Gym tool kit.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Geppy 可以作为函数逼近工具应用于 DRL 问题上的进化搜索，以生成单个可读的函数。生成的函数可以用来应用并解决来自 OpenAI Gym 工具包的复杂控制环境。
- en: IL is a pattern of combining evolutionary methods with DL to find new methods
    for modeling and solving complex problems.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IL 是一种将进化方法与深度学习结合的模式，以寻找建模和解决复杂问题的新的方法。
- en: 'Fundamental to IL is the instinct, or the core learned behavior of a model
    or organism:'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IL 的基础是本能，或模型或生物体的核心学习行为：
- en: In nature, biological life develops instincts to solve tasks, like eating or
    walking. The number, size, and complexity of instincts tend to diminish the more
    complex a life form becomes.
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在自然界中，生物体发展出本能来解决任务，如进食或行走。本能的数量、大小和复杂性往往随着生命形式的复杂化而减少。
- en: Instead, the life form often must learn to control its base instincts to accomplish
    basic or complex tasks.
  id: totrans-398
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相反，生命形式通常必须学会控制其基本本能以完成基本或复杂任务。
- en: The concept of evolution and our understanding of evolution itself may adapt
    and evolve to allow us to evolve ML and DL further. Theoretical concepts like
    evolutionary plasticity—that organisms may be able to evolve outside of reproduction—may
    have interesting applications in EC and EDL.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进化的概念以及我们对进化的理解可能会适应和进化，以使我们能够进一步进化机器学习和深度学习。像进化可塑性这样的理论概念——生物体可能能够在繁殖之外进化——可能在进化计算和进化深度学习中具有有趣的应用。
- en: The basic premise of IL can be demonstrated by breaking down a DQN agent network
    into instincts and then letting an agent train those instincts against multiple
    tasks. An agent that can generalize to multiple tasks using IL can be shown to
    approach more generalized models across tasks.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IL 的基本原理可以通过将 DQN 代理网络分解为本能，然后让代理针对多个任务训练这些本能来展示。能够使用 IL 泛化到多个任务的代理可以展示出在任务之间接近更通用的模型。
