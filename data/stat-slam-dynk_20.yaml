- en: 20 Finishing up
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 20 完成工作
- en: Our purpose in these last few pages is to survey the results from chapters 2
    through 19 and review the techniques we used along the way. Rather than go chapter
    by chapter and therefore repeat our journey in the same sequence, we’ll instead
    consolidate our findings into nine “learning areas” that are further broken down
    by packages, applied techniques, and chapter references. For instance, between
    chapters 5 and 14, we developed four types of models—linear regression, regression
    tree, analysis of variance (ANOVA), and logistic regression—using a mix of base
    R and packaged functions; accordingly, modeling is one of our nine learning areas.
    Once we get to section 20.4, we’ll review which models were applied where and
    for what ends.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些最后几页中，我们的目的是概述第2章至第19章的结果，并回顾我们在过程中使用的技术。我们不会逐章进行，从而重复相同的旅程顺序，而是将我们的发现整合到九个“学习领域”中，这些领域进一步按包、应用技术和章节参考细分。例如，在第5章和第14章之间，我们开发了四种类型的模型——线性回归、回归树、方差分析（ANOVA）和逻辑回归——使用基础R和包装函数的混合；因此，建模是我们九个学习领域之一。一旦我们到达第20.4节，我们将回顾哪些模型在哪里以及为了什么目的被应用。
- en: 'The following learning areas are listed in the order in which they will be
    presented:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 以下学习领域按它们将呈现的顺序列出：
- en: Cluster analysis (20.1)
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类分析 (20.1)
- en: Significance testing (20.2)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显著性测试 (20.2)
- en: Effect size testing (20.3)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 效应量测试 (20.3)
- en: Modeling (20.4)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型 (20.4)
- en: Operations research (20.5)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运筹学 (20.5)
- en: Probability (20.6)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率 (20.6)
- en: Statistical dispersion (20.7)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计分散 (20.7)
- en: Standardization (20.8)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化 (20.8)
- en: Summary statistics and visualization (20.9)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率统计和可视化 (20.9)
- en: In addition, we’ve created a series of Sankey diagrams (see chapter 3), one
    for each learning area, that plot the relationships between learning areas, packages
    and base R functions, techniques, and chapter numbers. These final visualizations
    are therefore visual snapshots of the same confluences.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们创建了一系列桑基图（见第3章），每个学习领域一个，这些图显示了学习领域、包和基础R函数、技术和章节编号之间的关系。因此，这些最终可视化是相同汇聚点的视觉快照。
- en: 20.1 Cluster analysis
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.1 聚类分析
- en: Cluster analysis is a type of unsupervised learning method and multivariate
    analysis technique that classifies objects (e.g., automobiles, neighborhoods,
    almost anything, really) into one of multiple groups, or clusters, based on their
    similarity. A department store chain might segment its customers based on demographic
    data and prior purchases with the intent of then mapping made-to-order marketing
    strategies with clusters. No doubt, the most common or most popular clustering
    algorithms are hierarchical clustering and K-means clustering. We featured these
    two clustering techniques in chapters 3 and 11, respectively.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类分析是一种无监督学习方法和多元分析技术，它根据对象的相似性将对象（例如，汽车、社区、几乎任何东西）分类到多个组或簇中。一家百货连锁店可能会根据人口统计数据和以前的购买记录来细分其客户，目的是随后根据簇来制定定制营销策略。毫无疑问，最常见或最受欢迎的聚类算法是层次聚类和K-means聚类。我们在第3章和第11章分别介绍了这两种聚类技术。
- en: We began this journey by making the case that tanking is a perfectly logical
    (albeit repugnant) strategy for down-and-out NBA teams who plan to rebuild their
    rosters through the amateur draft. That’s because the league rewards its worst
    teams with the first few picks, and about the only possible way of selecting a
    future superstar—the sort of player who can reverse a team’s fortunes—is to pick
    at or near the very top of the draft. We concluded our case by developing a hierarchical
    clustering using a series of base R functions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始这次旅程时，提出了一个论点，即摆烂是一种完全合乎逻辑（尽管令人厌恶）的策略，对于计划通过业余选秀重建阵容的处境不佳的NBA球队来说。这是因为联赛奖励其最差的球队以几个首轮选秀权，而选择未来超级巨星——那种可以扭转球队命运的球员——的唯一可能方式是在选秀中或接近最顶端进行选择。我们通过开发一系列基础R函数的层次聚类来结束我们的论点。
- en: More to the point, we created a distance matrix based on mean career win shares
    grouped by first-round pick number from the 2000 to 2009 NBA drafts. A hierarchical
    clustering begins by treating every object, or observation, as its own cluster.
    It then iterates by merging two similar clusters at a time until all the clusters—30
    in our case, or 1 cluster per first-round selection—are merged into one. The end
    result is a dendrogram, or upside-down tree, that displays the original clusters
    along the x-axis and results from the distance matrix along the y-axis.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，我们基于按第一轮选秀号码分组的第一轮选秀到2000年至2009年NBA选秀的平均职业生涯胜利份额创建了一个距离矩阵。层次聚类开始时，将每个对象或观察值视为其自己的簇。然后它通过每次合并两个相似的簇进行迭代，直到所有簇（在我们的案例中是30个，或每个首轮选秀一个簇）合并成一个。最终结果是树状图，或倒置的树，它在x轴上显示原始簇，在y轴上显示距离矩阵的结果。
- en: What’s especially nice about creating dendrograms in R is that we have the option
    of drawing a *K* number of transparent boxes on top of the plot to further differentiate
    clusters. We set *K* equal to 2 to see if R would then draw one transparent box
    around draft picks 1 through 5 and another box around picks 6 through 30, and
    therefore return similar results from our previous analyses. Sure enough, that’s
    exactly what R did for us.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中创建树状图特别好的是，我们有选项在图上绘制*K*个透明的框来进一步区分簇。我们将*K*设置为2，看看R是否会绘制一个透明的框围绕选秀1到5的选秀，另一个框围绕6到30的选秀，从而返回与我们之前分析相似的结果。果然，这正是R为我们做的。
- en: In chapter 10 and again in chapter 11, we explored the relationship between
    team payrolls and regular season wins, postseason appearances, and championships—concluding
    that, minus a couple of exceptions, team payrolls are otherwise leading indicators
    of team trajectories. We finished our analysis with a K-means clustering.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在第10章和第11章中，我们探讨了球队薪资与常规赛胜利、季后赛出场和冠军之间的关系——得出结论，除了少数例外，球队薪资通常是球队轨迹的领先指标。我们以K-means聚类分析结束我们的分析。
- en: A K-means clustering differs from a hierarchical clustering in at least two
    ways—(1) we must tell R up front how many clusters to create, and (2) we get a
    *K* number of clusters based on two or more continuous variables that, for plotting
    purposes, are automatically standardized or rescaled for us. We plotted adjusted
    payrolls and regular season wins between the 2000 and 2017 seasons.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: K-means聚类与层次聚类至少有两点不同——（1）我们必须提前告诉R要创建多少个簇，并且（2）我们根据两个或更多连续变量得到*K*个簇，为了绘图目的，这些变量会自动为我们标准化或缩放。我们在2000年至2017个赛季之间绘制了调整后的薪资和常规赛胜利。
- en: We first demonstrated a pair of methods to compute optimal cluster counts (versus
    randomly generating *K* ), using functions from the `factoextra` package. The
    within-cluster sum of squares method, sometimes called the elbow method because
    it suggests an optimal cluster count at the (unprecise) location where the ensuing
    scree plot bends, returned six clusters; the silhouette method returned two clusters.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先演示了两种计算最佳簇数（与随机生成*K*）的方法，使用`factoextra`包中的函数。簇内平方和法，有时被称为肘部法，因为它建议在（不精确的）随后scree图弯曲的位置有一个最佳簇数，返回六个簇；轮廓法返回两个簇。
- en: We decided to split the difference and instruct R to segment the results into
    four clusters. A K-means clustering crunches numbers through (possibly) several
    iterative steps until the total sum of squares between the data and their respective
    centroid, or the center position of a cluster, is minimized, without, of course,
    violating the predetermined requirement for *K.* Maybe the most fascinating part
    of our results is that R relegated the New York Knicks, which had a payroll more
    than three standard deviations *above* the league mean and a regular season win
    count more than one standard deviation *below* the mean, to its own cluster. Meanwhile,
    the San Antonio Spurs, winners of more regular season games between 2000 and 2017
    than any other team on a below-average payroll, were clustered with 10 other teams.
    Results were returned from base R functionality and then visualized through the
    `factoextra` package.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们决定折中一下，并指示R将结果分割成四个集群。K-means聚类通过（可能）几个迭代步骤来处理数字，直到数据与它们各自的质心或集群的中心位置之间的总平方和最小化，当然，不违反对*K*预定的要求。我们结果中最令人着迷的部分可能是R将纽约尼克斯队降级到了它自己的集群，该队的工资水平比联赛平均水平高出三个标准差以上，而常规赛的胜利次数比平均水平低一个标准差以上。与此同时，圣安东尼奥马刺队，在2000年至2017年之间赢得的常规赛比赛比任何其他工资水平低于平均水平的球队都要多，与10个其他球队聚类在一起。结果是通过基础R功能返回的，然后通过`factoextra`包进行可视化。
- en: Unsupervised learning methods in general and cluster analysis in particular
    return results that are more subjective than, let’s say, a linear regression or
    a t-test. We further demonstrated in chapter 11 that results can and will vary
    significantly when we apply different values to *K*; thus, the idiosyncrasies
    of cluster analysis, especially K-means, escalate as we increase *K*. A pair of
    customers who seemingly share similar profiles and therefore deserve to be on
    the receiving end of like marketing campaigns when *K* equals 2 can and do get
    partitioned into different clusters when *K* then equals 3 or more. Nevertheless,
    cluster analysis is an essential technique for exploring data and evaluating groups,
    as well as a critical enabler for applying different treatments that usually get
    better returns than all-in-one strategies.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一般的无监督学习方法，特别是聚类分析，返回的结果比线性回归或t检验等更为主观。我们在第11章进一步演示了，当我们对*K*应用不同的值时，结果可以并且会显著变化；因此，随着*K*的增加，聚类分析，尤其是K-means的个性特征会加剧。当*K*等于2时，看似具有相似轮廓并因此值得在类似营销活动中接受的一对客户，当*K*等于3或更多时，可能会被划分到不同的集群中。尽管如此，聚类分析是探索数据和评估群体的一种基本技术，也是应用不同治疗手段的关键推动者，这些手段通常比一揽子策略带来更好的回报。
- en: The first of our Sankey diagrams—indeed, all of the Sankey diagrams that follow—should
    be read from left to right (see figure 20.1). The left-most node is the applicable
    learning area; the next node, or series of nodes, represents the packages and/or
    built-in functions that were called; the next set of nodes represents the applied
    techniques; and the right-most set of nodes are the chapter references. So hierarchical
    clustering was developed with base R functions only, whereas our K-means clustering
    was developed with a combination of base R and `factoextra` functions. Hierarchical
    clustering was demonstrated in chapter 3 and K-means clustering was demonstrated
    in chapter 11\. (By the way, the width of the connectors, or links, between node
    groupings doesn’t mean anything.)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一张桑基图——实际上，所有随后的桑基图——都应该从左到右阅读（见图20.1）。最左边的节点是适用的学习区域；下一个节点或一系列节点代表被调用的包和/或内置函数；下一组节点代表应用的技术；最右边的节点组是章节引用。因此，层次聚类仅使用基础R函数开发，而我们的K-means聚类则是结合了基础R和`factoextra`函数开发的。层次聚类在第3章中进行了演示，K-means聚类在第11章中进行了演示。（顺便说一下，节点组之间连接线或链接的宽度没有任何意义。）
- en: '![CH20_F01_Sutton](../../OEBPS/Images/CH20_F01_Sutton.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![CH20_F01_Sutton](../../OEBPS/Images/CH20_F01_Sutton.png)'
- en: Figure 20.1 Hierarchical clustering was demonstrated in chapter 3 as the final
    piece of evidence supporting tanking; K-means clustering was demonstrated in chapter
    11 as a way of segmenting like teams based on a combination of their respective
    payrolls and regular season wins. Our hierarchical clustering was developed and
    visualized exclusively with base R functions; conversely, our K-means clustering
    was mostly developed with built-in functions, but visualized through the `factoextra`
    package.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.1 层次聚类在第三章中被展示为支持“摆烂”策略的最终证据；K-means聚类在第11章中被展示为基于各队工资和常规赛胜利的组合来划分类似队伍的方法。我们的层次聚类完全使用基础R函数开发和可视化；相反，我们的K-means聚类主要使用内置函数开发，但通过`factoextra`包进行可视化。
- en: 20.2 Significance testing
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.2 显著性检验
- en: Any significance test—whether a t-test, a chi-square test for independence,
    a correlation test, or an F-test—should revolve around a null hypothesis (*H*[0])
    and its opposite, an alternative hypothesis (*H*[1]). We always start with a null
    hypothesis; that is, we assume going in that any variances are due to chance.
    We then run a significance test that tells us either to reject the null hypothesis
    or to fail to reject it. By rejecting the null hypothesis, we’re therefore accepting
    the alternative hypothesis.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 任何显著性检验——无论是t检验、独立性的卡方检验、相关性检验还是F检验——都应该围绕一个零假设（*H*[0]）及其对立面，备择假设（*H*[1]）。我们始终从零假设开始；也就是说，我们假设进入时任何方差都是由于偶然。然后我们运行一个显著性检验，告诉我们是拒绝零假设还是未能拒绝它。通过拒绝零假设，因此我们接受备择假设。
- en: Let’s say we have two like groups of delinquent customers getting different
    collections treatments. A significance test tells us if performance differences
    are due to chance or if they should instead be attributed to dissimilarities in
    treatments. We fail to reject the null hypothesis if the former, or we reject
    the null hypothesis if the latter. If the results are significant, it would then
    make sense to apply the winning treatment to all customers.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有两组类似的不良客户，他们接受了不同的催收处理。显著性检验告诉我们性能差异是由于偶然还是应该归因于处理方式的差异。如果前者，我们未能拒绝零假设；如果后者，我们拒绝零假设。如果结果是显著的，那么将获胜的处理方式应用于所有客户就变得有意义。
- en: The p-value from a significance test tells us whether to reject a null hypothesis.
    We consistently applied a predefined 5% threshold, which is most common—when the
    returned p-value was greater than 5%, we failed to reject our null hypothesis,
    and when it was instead less than 5%, we rejected that null hypothesis and accepted
    the alternative hypothesis. Significance thresholds are sometimes set as low as
    1% and sometimes as high as 10%. This means a significance test essentially returns
    a binary result; that is, based on the applied significance threshold, observed
    variances are either immaterial or consequential.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 显著性检验的p值告诉我们是否拒绝零假设。我们一致地应用了一个预定义的5%阈值，这是最常见的——当返回的p值大于5%时，我们未能拒绝我们的零假设，而当它小于5%时，我们拒绝那个零假设并接受备择假设。显著性阈值有时设定得非常低，如1%，有时设定得非常高，如10%。这意味着显著性检验本质上返回一个二元结果；也就是说，基于应用的意义阈值，观察到的方差要么是不重要的，要么是重要的。
- en: Bear in mind that results from significance testing, especially t-tests and
    chi-square tests for independence, are based on the variances as well as the size
    of the data. If you’re ever asked to design a test and control (sometimes referred
    to as a champion/challenger), you should divide your test and control populations
    and determine the duration of your test accordingly.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，显著性检验的结果，尤其是独立性的t检验和卡方检验，是基于方差以及数据的大小。如果你被要求设计一个测试和控制（有时被称为冠军/挑战者），你应该将测试和控制群体分开，并相应地确定测试的持续时间。
- en: In chapter 7, we explored the possibility that home-court advantage, so prevalent
    in the NBA, could be due, at least in part, to biased officiating. Of course,
    officials don’t influence which shots are made or missed or which team recovers
    a loose ball, but they are responsible for calling—or not calling—personal fouls,
    which are typically discretionary. Personal foul calls usually result in free
    throw attempts—and more points—for the opposing team. But in a broader sense,
    they can disrupt substitution patterns and therefore affect the flow of a game.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在第7章中，我们探讨了NBA中普遍存在的主场优势，至少部分可能归因于裁判的偏见。当然，裁判不会影响投篮是否命中或失误，或者哪个队伍夺回篮板球，但他们负责吹罚——或者不吹罚——个人犯规，这通常是酌情处理的。个人犯规的吹罚通常会导致对方队伍获得罚球机会——以及更多的分数。但从更广泛的角度来看，它们可以打乱换人模式，从而影响比赛的流畅性。
- en: Visiting teams are whistled for more personal foul calls than home teams, and
    as a result, home teams attempt more free throws than visiting teams, at least
    based on data from the 2018-19 and 2019-20 seasons. Raw numbers, however, don’t
    tell us if these variances are merely due to chance or if there’s some meaning
    behind them. This is where significance testing comes in.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 访问队伍比主场队伍受到更多的个人犯规吹罚，因此，主场队伍尝试的罚球次数比访问队伍多，至少根据2018-19赛季和2019-20赛季的数据来看是这样。然而，原始数据并不能告诉我们这些差异仅仅是由于偶然，还是背后有某种含义。这正是显著性检验的作用所在。
- en: A t-test is an appropriate significance, or hypothesis, test when we want to
    compare means from two groups—and only two groups—and we have continuous data
    to work with. Our null, or going-in, hypothesis is that the group means are essentially
    equal; we therefore require a very low p-value to reject a null hypothesis that
    the means are statistically equal and instead accept the alternative hypothesis
    that something other than chance is at the root cause of any variances. We ran
    eight t-tests in chapter 7; while the raw numbers were consistently slanted in
    favor of home teams—or even *designated* home teams when games were played at
    a neutral site—our tests returned statistically significant results where we had
    large record counts and insignificant results otherwise. Significant tests, including
    t-tests, are usually run from base R functions, but in chapter 7, we also ran
    t-tests from the `ggpubr` package, which then allowed us to automatically insert
    the results into `ggplot2` boxplots.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要比较两组——而且只有两组——的均值，并且我们有连续数据可供工作时，t检验是一种适当的显著性或假设检验。我们的零假设，或初始假设，是两组的均值基本上是相等的；因此，我们需要一个非常低的p值来拒绝均值在统计上相等的零假设，并接受备择假设，即任何差异的根源不是偶然。在第7章中，我们进行了八次t检验；虽然原始数据始终偏向主场队伍——甚至在比赛在中立场地进行时，被指定为主场队伍的队伍——但我们的测试在记录数量大的情况下返回了统计上显著的结果，在其他情况下则没有显著结果。包括t检验在内的显著性检验通常从基本的R函数中运行，但在第7章中，我们还从`ggpubr`包中运行了t检验，这使得我们能够自动将结果插入到`ggplot2`箱线图中。
- en: Then, in chapters 12 and 13, we discovered that championship-winning teams between
    1991 and 2018 have more unequal salary distributions and more unequal win share
    distributions than other teams; by the same token, winning teams—not just winning
    teams that then won a league title, but teams with regular season winning percentages
    above .500—have more unequal salary distributions and more unequal win share distributions
    than losing teams. We ran additional t-tests to determine if the variances in
    the Gini coefficient means between groups was or was not statistically significant;
    every t-test returned a p-value below the .05 threshold for significance. In layman
    terms, the salary distributions and win share distributions are key differentiators
    when it comes to winning, and winning championships.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在第12章和第13章中，我们发现1991年至2018年间获得冠军的队伍，其薪资分布和赢分分布比其他队伍更加不平等；同样，获胜队伍——不仅是指后来赢得联赛冠军的队伍，还包括常规赛胜率超过.500的队伍——其薪资分布和赢分分布比输掉比赛的队伍更加不平等。我们进行了额外的t检验，以确定组间基尼系数均值差异是否具有统计显著性；每次t检验都返回了低于.05显著性阈值的p值。用通俗的话说，薪资分布和赢分分布是决定胜负的关键因素，也是赢得冠军的关键。
- en: A correlation test is another significance test run with continuous data. We
    ran our first correlation test in chapter 10 to determine whether team payrolls
    and regular season wins, at least between the 2000 and 2017 seasons, have a statistically
    significant association, or relationship. Our null hypothesis is that they don’t,
    but our cor- relation test returned a p-value below .05, so we rejected the null
    hypothesis and instead concluded that there is, in fact, a meaningful relationship
    between payrolls and wins.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性检验是另一种在连续数据上运行的显著性检验。我们在第10章运行了我们的第一个相关性检验，以确定至少在2000年至2017赛季之间，球队薪资和常规赛胜利之间是否存在统计学上显著的关联或关系。我们的零假设是它们之间没有关联，但我们的相关性检验返回的p值低于.05，因此我们拒绝了零假设，并得出结论，实际上薪资和胜利之间存在有意义的关系。
- en: We ran two more correlation tests in chapter 14—the first between wins and points
    allowed and the second between wins and points scored. Our variables were first
    rescaled to mitigate the effects of time. You might recall that our purpose in
    chapter 14 was to measure the relative influences of defense and offense on winning.
    If defense truly matters more than offense, as conventional thinking has suggested
    for many years, then our two correlation tests should return very different results.
    They didn’t, however—our two tests returned statistically significant and identical
    results, thereby suggesting that defense and offense have equal effects on winning.
    Correlation tests are run from the base R functionality.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在第14章，我们运行了另外两个相关性检验——第一个是胜利和允许得分之间的关系，第二个是胜利和得分之间的关系。我们的变量首先进行了缩放，以减轻时间的影响。你可能还记得，在第14章中，我们的目的是衡量防守和进攻对胜利的相对影响。如果正如传统思维多年来所暗示的那样，防守比进攻更重要，那么我们的两个相关性检验应该返回非常不同的结果。然而，它们并没有——我们的两个测试返回了统计学上显著且相同的结果，这表明防守和进攻对胜利的影响是相等的。相关性检验是从基本的R功能运行的。
- en: Switching gears a bit, we ran a different sort of significance test, a chi-square
    test for independence, in chapter 9, where we explored wins and losses between
    home and visiting teams based on different permutations of prior days of rest.
    A chi-square test rather than a t-test (or certainly a correlation test) was the
    more appropriate significance test because we were working with categorical data
    in chapter 9 instead of continuous data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 稍微转换一下话题，我们在第9章进行了一种不同类型的显著性检验，即独立性卡方检验。在这一章中，我们根据前一天休息日的不同排列组合，探讨了主队和客队之间的胜负情况。由于在第9章我们处理的是分类数据而非连续数据，因此使用卡方检验而不是t检验（或者当然也不是相关性检验）是更合适的显著性检验方法。
- en: Nevertheless, we start with a null hypothesis and then reject, or fail to reject,
    that null hypothesis based on the test’s p-value. We ultimately rejected the null
    hypothesis and therefore concluded that permutations of days of rest matter in
    wins and losses. Our chi-square test for independence was run from base R, and
    we then visualized the results two ways, once from the `gtools` package and again
    from the `vcd` package.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们还是从零假设开始，然后根据测试的p值拒绝或未能拒绝该零假设。我们最终拒绝了零假设，因此得出结论，休息日的排列组合对胜负有影响。我们的独立性卡方检验是从基本的R函数运行的，然后我们以两种方式可视化了结果，一次是从`gtools`包，另一次是从`vcd`包。
- en: Finally, we ran an F-test from base R in chapter 13 to help us decide which
    results to accept from three competing effect size tests (see section 20.3). As
    with t-tests and chi-square tests, our starting point is a null hypothesis, and
    the finish line is a p-value less than or equal to .05\. Our second Sankey diagram
    (see figure 20.2) visually summarizes the significance testing learning area.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在第13章从基本的R函数运行了一个F检验，以帮助我们决定从三个相互竞争的效果量检验中接受哪些结果（参见第20.3节）。与t检验和卡方检验一样，我们的起点是零假设，终点是小于或等于.05的p值。我们的第二个桑基图（见图20.2）从视觉上总结了显著性检验的学习领域。
- en: '![CH20_F02_Sutton](../../OEBPS/Images/CH20_F02_Sutton.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![CH20_F02_Sutton](../../OEBPS/Images/CH20_F02_Sutton.png)'
- en: Figure 20.2 Significance tests start with a null hypothesis that is subsequently
    rejected or not rejected based on a p-value with a 5% threshold. Which significance
    test to run is conditioned on the data (usually, but not always, continuous versus
    categorical). Significance tests are usually run from base R functions, and the
    results are typically visualized through packaged functions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.2 显著性检验从零假设开始，该假设随后根据p值和5%的阈值被拒绝或未被拒绝。进行哪种显著性检验取决于数据（通常，但并非总是，是连续数据还是分类数据）。显著性检验通常从基本的R函数运行，并且结果通常通过包装函数进行可视化。
- en: 20.3 Effect size testing
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.3 效果量检验
- en: 'Whereas a statistical test of significance returns a p-value that tells us,
    usually at a 5% threshold, whether or not the variance between observed and expected
    results are statistically significant, effect size tests tell us how large or
    not so large that same variance happens to be. Consider the following about effect
    size testing:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 与显著性统计测试返回的 p 值告诉我们，通常在 5% 的阈值下，观察结果和预期结果之间的方差是否在统计上显著不同，效应量测试告诉我们这种相同的方差有多大或有多小。关于效应量测试的以下内容需要考虑：
- en: Effect size tests should complement, or supplement, statistical tests of significance
    and not take their place. We don’t reject or fail to reject a null hypothesis
    based on effect size testing.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 效应量测试应该补充或补充显著性统计测试，而不是取代它们。我们不会根据效应量测试拒绝或未能拒绝零假设。
- en: Like other statistical tests, choosing the right effect size test depends on
    the data. Cohen’s d, Hedges’ g, and Glass’s delta effect size tests are run against
    continuous data, so they complement t-tests. A Cramer’s V effect size test, on
    the other hand, is run against categorical data, so it complements chi-square
    tests for independence.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他统计测试一样，选择正确的效应量测试取决于数据。Cohen’s d、Hedges’ g 和 Glass’s delta 效应量测试是对连续数据进行运行的，因此它们补充了
    t 测试。另一方面，Cramer’s V 效应量测试是对分类数据进行运行的，因此它补充了独立性卡方测试。
- en: Cohen’s d is the most popular effect size test for continuous data. We ran Cohen’s
    d tests in chapters 7, 12, and 13, and we ran Hedges’ g and Glass’s delta tests
    in chapter 13 only.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohen’s d 是连续数据的最受欢迎的效应量测试。我们在第 7、12 和 13 章中运行了 Cohen’s d 测试，并且只在第 13 章中运行了
    Hedges’ g 和 Glass’s delta 测试。
- en: Our Cohen’s d tests were run from the `effsize` package in chapters 7, 12, and
    13 and again from the `effectsize` package in chapter 13 only. Our Hedges’ g and
    Glass’s delta tests were therefore run from the `effectsize` package only.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的 Cohen’s d 测试是在第 7、12 和 13 章中从 `effsize` 包中运行的，并且在第 13 章中只从 `effectsize`
    包中再次运行。因此，我们的 Hedges’ g 和 Glass’s delta 测试只从 `effectsize` 包中运行。
- en: Cramer’s V is the go-to effect size test for categorical data. We twice ran
    Cramer’s V effect size tests in chapter 9, once from the `questionr` package and
    again from the `rcompanion` package.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cramer’s V 是分类数据的首选效应量测试。我们在第 9 章中两次运行了 Cramer’s V 效应量测试，一次来自 `questionr` 包，另一次来自
    `rcompanion` 包。
- en: Results between statistical tests of significance and effect size tests might
    not always line up. For instance, a t-test that returns a p-value well below the
    5% threshold won’t necessarily translate into a large effect size; conversely,
    a t-test or other significance test that returns a p-value above 5% might, in
    fact, equate to a large effect size. Once more, significance tests consider record
    counts, whereas effect size tests do not.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显著性统计测试和效应量测试的结果可能并不总是吻合。例如，返回 p 值远低于 5% 阈值的 t 测试不一定转化为大的效应量；相反，返回 p 值高于 5%
    的 t 测试或其他显著性测试实际上可能等同于大的效应量。再次强调，显著性测试考虑记录数，而效应量测试不考虑。
- en: In general, when the quantitative result equals 0.2 or less, the effect size
    is considered small; when the result is at or around 0.5, the effect size is considered
    to be medium; and when the result is equal to or above 0.8, the effect size is
    considered to be large.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，当定量结果等于 0.2 或更少时，效应量被认为是小的；当结果在 0.5 或附近时，效应量被认为是中等的；当结果等于或高于 0.8 时，效应量被认为是大的。
- en: Our next Sankey diagram (see figure 20.3) visualizes these very same associations.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来的桑基图（见图 20.3）展示了这些非常相同的关联。
- en: '![CH20_F03_Sutton](../../OEBPS/Images/CH20_F03_Sutton.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![CH20_F03_Sutton](../../OEBPS/Images/CH20_F03_Sutton.png)'
- en: Figure 20.3 Effect size tests should complement or supplement, and not replace,
    significance testing. Cohen’s d, Hedges’ g, and Glass’s delta are effect size
    tests that were run to complement t-tests, where the data is continuous; Cramer’s
    V is an effect size test that was run to complement a chi-square test for independence,
    where the data is categorical rather than continuous. A Cohen’s d test, the most
    popular effect size test for continuous data, was run from the `effsize` package
    in chapters 7, 12, and 13 and from the `effectsize` package in chapter 13; Hedges’
    g and Glass’s delta tests were run from the `effectsize` package in chapter 13
    only. Cramer’s V was run twice in chapter 9, once from the `questionr` package
    and once from the `rcompanion` package.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.3效果量测试应该补充或补充，而不是取代，显著性测试。Cohens’ d、Hedges’ g和Glass’s delta是作为t检验（数据连续）的补充运行的效果量测试；Cramer’s
    V是作为独立性卡方检验（数据为分类而非连续）的补充运行的效果量测试。Cohens’ d测试，连续数据的最受欢迎的效果量测试，在第7、12和13章以及第13章的`effectsize`包中运行；Hedges’
    g和Glass’s delta测试仅在第13章的`effectsize`包中运行。Cramer’s V在第9章运行了两次，一次来自`questionr`包，一次来自`rcompanion`包。
- en: In chapter 7, we explored the possibility that game officials are biased toward
    home teams by quantifying personal foul calls and free throw attempts between
    road and home teams and then testing and measuring the variances. Regardless of
    the preceding t-test results, our Cohens’ d tests—where group means and standard
    deviations are crunched and record counts are ignored—returned negligible effect
    sizes. We tested the 2018-19 regular season and postseason and the 2019-20 regular
    season, pre- and post-COVID.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在第7章中，我们通过量化客场和主队之间的个人犯规和罚球尝试次数，然后测试和测量方差，探讨了游戏官员可能偏向主队的可能性。无论前期的t检验结果如何，我们的Cohens’
    d检验——其中计算组均值和标准差，而忽略记录计数——返回了可忽略的效果量。我们测试了2018-19赛季常规赛和季后赛以及2019-20赛季常规赛，包括和疫情前后的情况。
- en: In chapter 12, we explored the relationship between salary inequality and winning,
    using a data set that spanned 28 NBA seasons. We discovered that teams with higher
    regular season winning percentages have more unequal salary distributions than
    teams with lower winning percentages; we also discovered that championship-winning
    teams have more unequal salary distributions than the rest of the league. We then
    ran a pair of Cohen’s d effect size tests to measure the salary distribution differences—in
    both cases, Cohen’s d returned medium effect sizes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在第12章中，我们使用涵盖28个NBA赛季的数据集，探讨了薪资不平等与胜利之间的关系。我们发现，常规赛胜率较高的球队比胜率较低的球队薪资分布更不平等；我们还发现，冠军球队比其他联盟球队的薪资分布更不平等。然后我们运行了两个Cohens’
    d效果量测试来衡量薪资分布差异——在两种情况下，Cohens’ d都返回了中等效果量。
- en: In chapter 13, we analyzed win share distributions across teams (as a substitute
    for salary inequality) versus winning. We subsequently learned that teams with
    more unequal win share distributions are the same teams that win more regular
    season games and also win championships. We used chapter 13 as an opportunity
    to further demonstrate effect size testing by introducing another package, which
    then allowed us to run Hedges’ g and Glass’s delta effect size tests in addition
    to Cohen’s d tests. These other tests returned the same results as our final Cohen’s
    d tests, despite small differences in how the effect sizes are computed. The effect
    sizes were small irrespective of the method and regardless of the test.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在第13章中，我们分析了球队之间的胜利份额分布（作为薪资不平等的一种替代）与胜利之间的关系。随后我们了解到，胜利份额分布不均等的球队是那些赢得更多常规赛比赛和冠军的球队。我们利用第13章的机会，通过引入另一个包来进一步展示效果量测试，这使我们能够除了Cohens’
    d测试外，还运行Hedges’ g和Glass’s delta效果量测试。这些其他测试的结果与我们的最终Cohens’ d测试相同，尽管在效果量计算方式上存在微小差异。无论方法如何，无论测试如何，效果量都相对较小。
- en: As for our Cramer’s V tests from chapter 9, where we set out to measure the
    effect size between rest and winning versus losing, our results indicated that
    rest has a small to moderate effect on game results, at least based on regular
    season games between the 2012-13 and 2017-18 seasons.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 至于我们第9章的Cramer’s V测试，我们旨在衡量休息与胜利与失败之间的效果量，我们的结果表明，至少基于2012-13赛季和2017-18赛季之间的常规赛比赛，休息对比赛结果有轻微到中等的影响。
- en: 20.4 Modeling
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.4 模型
- en: In the 2016-17 regular season, the NBA started measuring hustle statistics—plays
    such as blocked shots, deflections, and loose balls recovered. We set out in chapter
    5 to investigate which of these hustle statistics, if any, matter in the grand
    scheme of wins and losses.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在2016-17赛季的常规赛季中，NBA开始测量努力统计数据——例如封盖、干扰和捡回松散球等。我们在第5章中着手调查这些努力统计数据中，如果有的话，哪些在胜负大局中至关重要。
- en: 'Our starting point was a multiple linear regression, where regular season wins
    (a continuous variable) were regressed against the NBA’s hustle statistics (other
    continuous variables), prefaced by an exhaustive data exploration and data wrangling
    effort that included the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的起点是多重线性回归，其中常规赛季的胜利（一个连续变量）被回归到NBA的努力统计数据（其他连续变量）上，这之前包括以下详尽的数据探索和数据整理工作：
- en: Identifying outliers by drawing boxplots for each variable and, where outliers
    were present, eliminating them by increasing their value to equal the so-called
    minimum or decreasing their value to equal the maximum—because outliers could
    disproportionately bias model results. The process of “capping” values is called
    winsorization.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过为每个变量绘制箱线图来识别异常值，并在存在异常值的情况下，通过增加其值以等于所谓的最小值或减少其值以等于最大值来消除它们——因为异常值可能会不成比例地偏模型结果。将值“封顶”的过程称为winsorization。
- en: Checking for normal distributions by drawing density plots and running Shapiro-Wilk
    tests and, where applicable, removing variables with non-normal distributions
    as candidate predictors—because linear regression assumes, even requires, that
    variables take on a Gaussian distribution. We assume normality when a Shapiro-Wilk
    test returns a p-value above 0.05.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过绘制密度图和运行Shapiro-Wilk测试来检查正态分布，并在适用的情况下，移除具有非正态分布的变量作为候选预测因子——因为线性回归假设，甚至要求变量采用高斯分布。当Shapiro-Wilk测试返回的p值高于0.05时，我们假设正态性。
- en: Creating a matrix that displays the correlations between every pair of remaining
    variables and returns the correlation coefficients between the same—because we
    wanted to identify those variables that had the most promise as predictors.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个矩阵，显示每对剩余变量之间的相关性，并返回相同变量的相关系数——因为我们想确定那些最有希望作为预测因子的变量。
- en: 'Furthermore, we followed other best practices in the model development process,
    including the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们在模型开发过程中遵循其他最佳实践，包括以下内容：
- en: Splitting the data into mutually exclusive subsets for developing and predicting
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据分割成互斥的子集以进行开发和预测。
- en: Checking for multicollinearity among the predictors
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查预测因子之间的多重共线性。
- en: Running diagnostics
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行诊断。
- en: Fitting a second, or competing, model and comparing our two regressions for
    the best fit of the data
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配合第二个或竞争性模型，并比较我们的两个回归以获得数据的最佳拟合。
- en: Our best multiple linear regression explains less than 20% of the variance in
    regular season wins (the total variance ties back to the R2, or better yet, adjusted
    R2 statistics); however, our intent wasn’t to explain wins but rather to isolate
    those hustle statistics that actually influence wins and to quantify their collective
    effect. Points scored from screens, pass deflections on defense, and loose balls
    recovered have a statistically significant influence on the variance in regular
    season wins; that is, our best regression returned p-values less than .05 for
    these three variables.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最佳多重线性回归解释了常规赛季胜利中不到20%的方差（总方差与R2相关，或者更好的是，调整R2统计量）；然而，我们的意图并不是解释胜利，而是隔离那些真正影响胜利的努力统计数据，并量化它们的总效应。来自挡拆的得分、防守端的传球干扰和捡回的松散球对常规赛季胜利的方差有统计学意义上的影响；也就是说，我们最佳回归的这三个变量的p值小于.05。
- en: Whereas linear regression draws a straight but diagonal line that minimizes
    the distances between it and the data, a regression tree—often referred to as
    a decision tree regression—draws a jagged line over the data through a series
    of if-else statements. We then fit a regression tree to see if a different type
    of model would return similar or dissimilar results.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 而线性回归绘制一条直线但斜线，以最小化其与数据之间的距离，回归树——通常被称为决策树回归——通过一系列的if-else语句在数据上绘制一条锯齿线。然后我们拟合一个回归树，看看不同类型的模型是否会返回相似或不同的结果。
- en: In addition, whereas results from linear models are returned in tabular format
    (aside from the diagnostics), the results from tree-based models are returned
    in graphical format only. We get an upside-down tree by which the most significant
    predictors and splits are at the “top” of the tree, and the remaining predictors
    and splits are at the “bottom.” It turned out that our regression tree isolated
    the same three variables—points from screens, deflections, and loose balls recovered—as
    having the most influence on regular season wins.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，虽然线性模型的结果以表格格式返回（除了诊断信息外），但基于树的模型的结果仅以图形格式返回。我们得到一个倒置的树，其中最重要的预测变量和分割点位于树的“顶部”，而其余的预测变量和分割点位于“底部”。结果证明，我们的回归树将来自屏幕的得分、偏转和失球回收这三个变量隔离出来，认为它们对常规赛胜利的影响最大。
- en: Linear regressions are developed from base R. We checked for multicollinearity
    by using the `car` package, and we called on functions from the `broom` package—part
    of the `tidyverse` universe of packages—to return a subset of our results. Our
    regression tree was developed from the `tree` package (though R offers other packaged
    alternatives) and visualized from base R.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归是从基础R语言中发展而来的。我们通过使用`car`包来检查多重共线性，并调用`broom`包中的函数——它是`tidyverse`包集合的一部分，以返回我们结果的一个子集。我们的回归树是由`tree`包开发的（尽管R提供了其他包装好的替代方案），并通过基础R进行可视化。
- en: We returned to modeling in chapter 14 as part of our effort to establish—or
    refute—the idea that defense matters more than offense, using a data set that
    spanned the 2007 through 2018 seasons. An analysis of variance (ANOVA) requires
    a continuous, or quantitative, dependent variable and a categorical predictor
    variable split between at least three data series. We separately tested a standardized
    conversion of regular season wins against standardized conversions of points allowed
    and then points scored; if defense is more important than offense, then our first
    model should better explain wins than our second model. However, the two models
    returned identical results. ANOVAs are fit using base R.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第14章中回到建模，作为我们努力建立或反驳“防守比进攻更重要”这一观点的一部分，使用的数据集涵盖了2007年至2018赛季。方差分析（ANOVA）需要一个连续的或定量的因变量和一个至少分为三个数据系列的分类预测变量。我们分别测试了常规赛胜利的标准化转换与允许的得分和得分的标准化转换；如果防守比进攻更重要，那么我们的第一个模型应该比第二个模型更好地解释胜利。然而，两个模型返回了相同的结果。ANOVA使用基础R进行拟合。
- en: A logistic regression requires a binary dependent variable and one or more (usually)
    continuous predictor variables. We separately regressed a dependent variable that
    equals `0` for teams that failed to qualify for postseason play and equals `1`
    for teams that did make the postseason against the same predictors we threw into
    our ANOVAs. Again, if defense actually matters more than offense, our first logistic
    regression should better explain or predict whether or not teams qualify for postseason
    play. In fact, our first regression was stronger than our second model, but the
    differences were negligible. Overall, the fairest conclusion we could come to
    is that defense and offense have roughly equal influences on regular season wins
    and whether or not teams qualify for the postseason.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归需要一个二元因变量和一个或多个（通常是）连续的自变量。我们分别对等于`0`的因变量进行了回归，这些因变量代表未能晋级季后赛的球队，以及等于`1`的因变量，代表成功晋级季后赛的球队，这些因变量与我们投入ANOVA中的相同。再次强调，如果防守实际上比进攻更重要，那么我们的第一个逻辑回归应该更好地解释或预测球队是否晋级季后赛。事实上，我们的第一个回归模型比第二个模型更强，但差异微乎其微。总体而言，我们得出的最公平的结论是，防守和进攻对常规赛胜利以及球队是否晋级季后赛的影响大致相等。
- en: Logistic regressions are developed from base R; however, we then called a mix
    of packaged functions to get our results. Those details are reflected in the following
    Sankey diagram (see figure 20.4).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归也是从基础R语言中发展而来的；然而，我们随后调用了一系列包装好的函数来获取我们的结果。这些细节反映在下面的桑基图中（见图20.4）。
- en: '![CH20_F04_Sutton](../../OEBPS/Images/CH20_F04_Sutton.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![CH20_F04_Sutton](../../OEBPS/Images/CH20_F04_Sutton.png)'
- en: Figure 20.4 In chapter 5, we developed linear regression and regression tree
    models to isolate hustle statistics that might have a statistically significant
    effect on wins and losses. From both model types, we discovered that points scored
    from screens, pass deflections on defense, and loose balls recovered matter more
    than other like statistics and do, in fact, contribute to wins and losses. In
    chapter 14, we developed ANOVA and logistic regression models to establish if
    defense matters more than offense in terms of regular season wins from the former
    and postseason qualification from the latter. Our models returned statistically
    significant results, but it wasn’t clear and unmistakable that defense matters
    more than offense.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.4 在第5章中，我们开发了线性回归和回归树模型来隔离可能对胜负有统计学意义的 hustle 统计数据。从这两种模型类型中，我们发现来自挡拆得分的得分、防守端的传球干扰和捡回的
    loose balls 比其他类似统计数据更重要，并且实际上确实对胜负有贡献。在第14章中，我们开发了方差分析和逻辑回归模型来建立防守是否比进攻更重要，前者是常规赛的胜负，后者是季后赛的资格。我们的模型返回了具有统计学意义的成果，但并不明确和不可否认的是防守比进攻更重要。
- en: 20.5 Operations research
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.5 运筹学
- en: 'Unlike the previous learning areas, operations research contains a melting
    pot of techniques. Once more, we made a case for tanking in chapters 2 and 3 *for
    teams that choose to rebuild via the amateur draft*. Other teams, however, can
    and do choose instead to rebuild their rosters by acquiring veteran players via
    free agency. In chapter 4, we demonstrated how a fictional NBA team could optimize
    their free agent acquisitions and eliminate the guesswork by setting up a constrained
    optimization problem. Constrained optimization is an operations research technique
    by which some function is maximized or minimized while obeying one or more hard
    constraints. Our fictional team sought to maximize projected win shares across
    its free agent acquisitions within the following constraints:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的学习领域不同，运筹学包含了一个技术的大熔炉。再次，我们在第2章和第3章中为选择通过业余选秀重建的球队提出了“摆烂”的论点。然而，其他球队可以选择并通过自由球员收购来重建阵容。在第4章中，我们展示了虚构的NBA球队如何通过设置约束优化问题来优化他们的自由球员收购，并消除猜测。约束优化是一种运筹学技术，通过遵守一个或多个硬约束来最大化或最小化某个函数。我们的虚构球队寻求在其自由球员收购中最大化预期的赢分，同时遵守以下约束：
- en: Exactly five free agents must be acquired.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须收购恰好五名自由球员。
- en: Each free agent must play a unique position.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每位自由球员必须担任一个独特的位置。
- en: Annual salaries could not exceed $90,000,000; salaries could be distributed
    any which way between the five free agents, but their aggregated annual salaries
    must equal $90,000,000 or less.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年薪不得超过9000万美元；薪资可以在五名自由球员之间以任何方式分配，但他们的累计年薪必须等于或低于9000万美元。
- en: The average age of the five free agents at the time of signing must not exceed
    30; there were no age limits per free agent, but the average must be equal to
    or less than 30.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在签约时，五名自由球员的平均年龄不得超过30岁；每个自由球员没有年龄限制，但平均年龄必须等于或低于30岁。
- en: 'The heavy lifting comes from the `lpSolve` package—the function to be maximized
    or minimized must be linear and continuous (win shares—check) and the constraints
    must also be linear and continuous (exact number of free agent acquisitions—check,
    exact number of acquisitions by position—check, maximum salary allocation per
    year—check, maximum average age when signed—check). From a short list of 24 available
    players, our constrained optimization problem returned the names of five free
    agents to acquire: one point guard, one shooting guard, one center, one power
    forward, and one small forward with annual salary demands that totaled $89,500,000
    and an average age that equaled 28.4.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 重量级的工作来自 `lpSolve` 包——要最大化或最小化的函数必须是线性和连续的（赢分——检查）并且约束也必须是线性和连续的（精确的自由球员收购数量——检查，按位置精确的收购数量——检查，每年最大薪资分配——检查，签约时的最大平均年龄——检查）。从24名可用球员的短名单中，我们的约束优化问题返回了五名自由球员的收购名单：一名控球后卫，一名得分后卫，一名中锋，一名大前锋和一名小前锋，他们的年薪总额为8950万美元，平均年龄为28.4岁。
- en: Any other solution would have been less than optimal or would have necessitated
    a breach of one or more of the hard constraints. Our constrained optimization
    problem can easily be repurposed by simply changing out the function to be maximized
    or minimized and by changing out the constraints.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 任何其他解决方案都会低于最佳方案，或者需要违反一个或多个硬约束。我们的约束优化问题可以通过简单地更换要最大化或最小化的函数以及更换约束来轻松地重新定位。
- en: By the time we reached chapter 8, we had effectively transitioned from “front
    office” analytics to “in-game” analytics. Here, we explored how well the optimal
    stopping rule applies when teams have 24 seconds by which to attempt a shot and
    avoid a turnover. There’s a reason why optimal stopping is also known as the 37%
    rule—NBA teams should theoretically pass and dribble, not shoot, during the first
    37% of their allotted time and then take the first shot that compares favorably
    to a previous shot opportunity. Likewise, if you’re a hiring manager interviewing
    for an open role in your organization, you should automatically pass on the first
    37% of the candidates and then hire the first applicant who compares favorably
    to the previous candidates. Optimal stopping is fixed on returning the highest
    probability of a best outcome, versus several alternatives, while preempting wasteful
    efforts—*when there are no second chances*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 到我们到达第8章时，我们已经有效地从“前办公室”分析过渡到了“比赛”分析。在这里，我们探讨了当球队有24秒时间尝试投篮并避免失误时，最优停止规则适用得如何。最优停止也被称为37%规则的原因是——理论上，NBA球队应该在分配时间的头37%内传球和运球，而不是投篮，然后选择第一个与先前投篮机会相比更有利的投篮。同样，如果你是面试你组织中的空缺职位的招聘经理，你应该自动淘汰前37%的候选人，然后雇佣第一个与先前候选人相比更有利的申请人。最优停止专注于在几种替代方案中返回最高概率的最佳结果，同时避免浪费的努力——*当没有第二次机会时*。
- en: Our analysis suggested that the *letter* of optimal stopping applied fairly
    well to the Milwaukee Bucks and Charlotte Hornets, but not necessarily to the
    Atlanta Hawks; further analysis also suggested that ongoing, or back-and-forth,
    regressions to the mean were more at play than the optimal stopping rule. However,
    the *spirit* of optimal stopping applied very well to the league as a whole; points
    scored and field goal percentage both dropped precipitously as the shot clock
    ticked down. Over the course of this analysis, we used a combination of functions
    from the `tidyverse` universe of packages as well as from the `janitor` package.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分析表明，最优停止的*原则*对密尔沃基雄鹿队和夏洛特黄蜂队适用得相当好，但对亚特兰大老鹰队则不一定适用；进一步的分析还表明，持续的或来回的回归均值比最优停止规则更为重要。然而，最优停止的*精神*对整个联赛适用得非常好；得分和投篮命中率都随着比赛时间的推移而急剧下降。在整个分析过程中，我们使用了`tidyverse`宇宙包中的函数以及`janitor`包中的函数的组合。
- en: 'In chapter 9, before we explored the influence of rest on wins and losses,
    we had a very fundamental problem to resolve first: with respect to prior days
    of rest between opposing home and road teams, are we dealing with combinations
    or permutations? Ultimately, our intent was to tally and plot results by every
    conceivable grouping of prior days off, but because combinations and permutations
    aren’t synonymous and are therefore computed differently, it was imperative that
    we first correctly established which was which.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在第9章中，在我们探讨休息对胜负的影响之前，我们首先需要解决一个非常基本的问题：关于对抗主队和客队之间的先前休息日，我们是处理组合还是排列？最终，我们的意图是按每一种可能的先前休息日组合来统计和绘制结果，但由于组合和排列不是同义的，因此它们的计算方式不同，我们首先正确地确定哪一个是哪一个是至关重要的。
- en: To be brief, we’re dealing with permutations because the order matters. (In
    fact, your combination lock should actually be called a permutation lock.) For
    any given game, the home team might be playing on two days of rest while the road
    team might be playing on just one day of rest, which, of course, isn’t the same
    as the home team having one day off and the visiting team two days off. In fact,
    we’re actually dealing with permutations *with replacement* instead of permutations
    *without replacement* because home and road teams could absolutely have the same
    number of prior days off, and they frequently do. From the `gtools` package, we
    computed the number of permutations we needed to account for and then provided
    instructions to R to print the actual permutations.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们处理的是排列问题，因为顺序很重要。（实际上，你的组合锁应该实际上被称为排列锁。）对于任何特定的比赛，主队可能在休息两天后进行比赛，而客队可能只在休息一天后进行比赛，这当然与主队休息一天而客队休息两天的情况不同。实际上，我们实际上处理的是带替换的排列，而不是不带替换的排列，因为主队和客队可能有相同数量的先前休息日，而且他们经常是这样。从`gtools`包中，我们计算了我们需要考虑的排列数量，然后提供了指令给R来打印实际的排列。
- en: In chapter 15, we explored the parallels between the Lindy effect, right-skewed
    probability distributions, nonlinearity, and the 80-20 rule. Our specific interest
    was around measuring the distribution of games played and won across the NBA’s
    franchises between 1946 and 2020—could it be that 20% of the league’s franchises
    account for 80% of all the games that have been played and won?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在第15章中，我们探讨了林迪效应、右偏概率分布、非线性与80-20规则之间的相似性。我们的具体兴趣在于衡量1946年至2020年之间NBA各球队的比赛中获胜的比赛分布——是否可能有20%的联赛球队占有了80%的所有比赛和获胜？
- en: You can’t perform an 80-20 analysis without creating a Pareto chart. A Pareto
    chart is a combination bar chart and line chart with primary and secondary y-axes.
    The bar length can represent *unit* frequency, but it can also represent units
    of time, money, or some other cost function; they are usually arranged vertically,
    must absolutely be in descending order, and tie back to the primary y-axis. The
    line represents *cumulative* frequency measured in percentages, and it ties back
    to the secondary y-axis. The point is to visualize, let’s say, how many problems
    can be solved with a much smaller number of fixes.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 没有创建帕累托图，就无法进行80-20分析。帕累托图是一种组合条形图和折线图，具有主要和次要y轴。条形长度可以代表*单位*频率，但也可以代表时间、金钱或其他成本函数的单位；它们通常垂直排列，必须绝对按降序排列，并回溯到主要y轴。线代表按百分比测量的*累积*频率，并回溯到次要y轴。目的是可视化，比如说，可以用多少更少的修复来解决多少问题。
- en: A Pareto chart is basically a quality control tool that provides a visual representation
    of causes and effects that are usually nonlinear and sometimes as extreme as 80-20\.
    It should therefore come as no surprise that we used a pair of quality control
    packages to draw two Pareto charts. The first of these, from the `ggQC` package,
    displayed the number of games played per each NBA franchise, with `ggplot2` aesthetics,
    whereas the second chart, from the `qcc` package, displayed the number of games
    won per franchise. The Pareto charts clearly showed nonlinearity in effect, but
    not on the order of 80-20.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 帕累托图基本上是一种质量控制工具，它以视觉方式表示通常非线性，有时甚至像80-20那样极端的原因和效果。因此，我们使用了一对质量控制包来绘制两个帕累托图。其中第一个，来自`ggQC`包，显示了每个NBA球队每场比赛的数量，使用`ggplot2`美学，而第二个图表，来自`qcc`包，显示了每个球队的获胜比赛数量。帕累托图清楚地显示了非线性效果，但不是80-20的程度。
- en: Our next Sankey diagram (see figure 20.5) visualizes the operations research
    learning area.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来的桑基图（见图20.5）可视化了运筹学学习领域。
- en: '![CH20_F05_Sutton](../../OEBPS/Images/CH20_F05_Sutton.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![CH20_F05_Sutton](../../OEBPS/Images/CH20_F05_Sutton.png)'
- en: Figure 20.5 The operations research learning area contains a hodgepodge of techniques.
    In chapter 4, we demonstrated how an NBA team in the free agent market could get
    the biggest bang for its buck by setting up a constrained optimization problem;
    in chapter 8, we tested how well the optimal stopping rule, otherwise known as
    the 37% rule, works with a 24-second shot clock; in chapter 9, we examined permutations
    versus combinations (before computing permutations of prior days off between home
    and road teams); and in chapter 15, we demonstrated the 80-20 rule, often called
    the Pareto principle, and visualized how it applies to games played and won by
    all-time NBA franchises.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.5 运筹学学习领域包含了一系列技术。在第4章中，我们展示了如何通过建立一个约束优化问题，一支NBA球队在自由球员市场上能够以最少的投入获得最大的回报；在第8章中，我们测试了最优停止规则，即通常所说的37%规则，与24秒投篮钟的匹配效果；在第9章中，我们考察了排列与组合（在计算主队和客队之间前几天的休息日的排列之前）；在第15章中，我们展示了80-20规则，通常称为帕累托原理，并可视化地展示了它如何适用于所有NBA球队的比赛中获胜的比赛。
- en: 20.6 Probability
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.6 概率
- en: Let’s look back to chapter 3 one more time to discuss expected value analysis—a
    technique in which contending outcomes are multiplied by their probabilities,
    and their products are then summed to get an expected value. We computed the expected
    value of a top-five draft pick as well as the expected value of any other first-round
    selection, anticipating that R would return very different results.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次回顾第3章，讨论一下期望值分析——这是一种将竞争结果乘以其概率，然后将它们的乘积相加以得到期望值的技巧。我们计算了前五顺位选秀权的期望值以及任何其他第一轮选秀权的期望值，预计R将返回非常不同的结果。
- en: First-round selections from the 2000 to 2009 NBA drafts were assigned one of
    five statuses, or career outcomes, based on their subsequent win shares; for instance,
    a first-round pick was designated a superstar if he then earned more than 100
    career win shares. We then computed the probabilities for each career outcome,
    split by whether or not the player was a top-five pick. The probability of getting
    a future superstar when selecting at or near the top of the draft equals 24%;
    when selecting anywhere else in the first round, the probability equals just 1%.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 2000年至2009年NBA选秀的第一轮选择被分配了五种状态之一，或职业生涯结果，根据他们随后的胜利份额；例如，如果一个首轮选秀球员随后获得了超过100个职业生涯胜利份额，则他被指定为超级巨星。然后，我们计算了每种职业生涯结果的概率，根据球员是否为前五名选择进行划分。在选秀中或在接近前五名选择时获得未来超级巨星的概率为24%；在其他任何位置选择时，概率仅为1%。
- en: Then, we computed the median win shares for each outcome, again split by whether
    or not the player was a top-five selection. A future superstar picked in the top
    five then earned an average of 127 career win shares; future superstars picked
    below the top five averaged 111 career win shares.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们计算了每个结果的平均胜利份额，再次根据球员是否为前五名选择进行划分。被选中为前五名的未来超级巨星平均获得了127个职业生涯胜利份额；被选中为前五名以下的前景超级巨星平均获得了111个职业生涯胜利份额。
- en: The expected values were reached by multiplying probabilities by median win
    shares and then tallying the products. The expected value of a top-five pick equals
    57.53 win shares, whereas the expected value of any other first-round pick equals
    just 21.21 win shares. This is the difference between getting a long-time starter
    versus just a marginal player—and further explains why getting to the top of the
    draft, by any means necessary, makes perfect sense. We called a combination of
    base R and `dplyr` functions to get these results, as the top-half of our next
    Sankey diagram shows (see figure 20.6).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 预期值是通过将概率乘以中值胜利份额然后总计乘积来得到的。前五名选秀的预期值为57.53个胜利份额，而任何其他首轮选秀的预期值仅为21.21个胜利份额。这是获得长期首发球员与仅仅是一名边缘球员之间的区别——并进一步解释了为什么通过任何必要手段进入选秀榜首是完美的选择。我们调用了一组基础R和`dplyr`函数来获取这些结果，如我们下一个桑基图的上半部分所示（见图20.6）。
- en: '![CH20_F06_Sutton](../../OEBPS/Images/CH20_F06_Sutton.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![CH20_F06_Sutton](../../OEBPS/Images/CH20_F06_Sutton.png)'
- en: Figure 20.6 Our expected value analysis in chapter 3 clearly demonstrated that
    not all first-round NBA picks are created equal; teams should have very different
    expectations of their first-round selections depending on where they are drafting
    from. Then, in chapter 16, we set out to determine if free throw shooting resembles
    a Laplace probability curve, where success fuels additional success, or if it
    appears more random instead; we ultimately concluded the latter.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.6 第3章中的预期值分析清楚地表明，并非所有首轮NBA选秀球员都是相同的；球队应该根据他们从哪里选秀而有非常不同的期望。然后，在第16章中，我们试图确定罚球投篮是否类似于拉普拉斯概率曲线，其中成功促进更多成功，或者它是否看起来更随机；我们最终得出结论，后者更符合。
- en: In chapter 16, we examined free throw shooting—specifically, streaks of successful
    free throw attempts—to determine if such shooting streaks best resemble a Laplace
    probability curve or flips of a coin. If the hot hand is a real phenomenon, a
    player’s ongoing free throw percentage—his probability of success on the next
    attempt—should increase with each successive made shot. On the other hand, if
    a player’s free throw percentage plotted by the length of consecutive makes fails
    to follow a Laplace probability curve, or at least thereabouts, then we should
    dismiss the hot hand phenomenon and instead conclude that free throw shooting
    is more random.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在第16章中，我们研究了罚球投篮——特别是成功的罚球尝试的连串——以确定这种投篮连串是否更类似于拉普拉斯概率曲线或硬币的翻转。如果“手感热”是一种真实现象，那么球员的连续罚球百分比——他下一次尝试成功的概率——应该随着每一次成功的投篮而增加。另一方面，如果球员按连续命中次数绘制的罚球百分比没有遵循拉普拉斯概率曲线，或者至少接近，那么我们应该摒弃“手感热”现象，并得出结论，罚球投篮更随机。
- en: 'We first examined the free throw shooting of three players, all of whom finished
    the 2019-20 season among the lead leaders in free throw attempts: Giannis Antetokounmpo
    (roughly a 63% free throw shooter), Julius Randle (73%), and James Harden (86%).
    Using the `runner` package, we tallied streaks of successful free throws and then
    computed the shooting percentage for each integer of consecutive makes. At the
    end of the day, free throw shooting appeared to be random. To prove this, we simulated
    700 coin flips (Antetokounmpo attempted just over 700 free throws in 2019-20);
    our simulation returned streaks (tails) that very much resembled Antetokounmpo’s
    free throw percentages.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先检查了三名球员的罚球命中率，这三位球员在2019-20赛季的罚球尝试中均位于领先者行列：Giannis Antetokounmpo（大约63%的罚球命中率），Julius
    Randle（73%），和James Harden（86%）。使用`runner`包，我们统计了成功罚球的连击次数，然后计算了连续命中每个整数的投篮命中率。最终，罚球命中率看起来是随机的。为了证明这一点，我们模拟了700次抛硬币（Antetokounmpo在2019-20赛季尝试了700多次罚球）；我们的模拟返回的连击（反面）与Antetokounmpo的罚球百分比非常相似。
- en: But then, we plotted free throw percentages across the entire NBA—and got very
    different results. By grouping every player into a single series of computations,
    we got free throw percentages that, when plotted, looked much more like a Laplace
    probability curve than did our player-level analyses. Our key takeaway, however,
    was that the player-specific results were far more meaningful than the league-wide
    results because the hot hand, if it exists, applies to individual players performing
    within discrete periods of time, and not toward many players performing in different
    spaces at different times.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 但然后，我们绘制了整个NBA的罚球命中率，并得到了非常不同的结果。通过将每个球员分组到一个单独的计算系列中，我们得到的罚球命中率，当绘制时，看起来比我们的球员级分析更像是拉普拉斯概率曲线。然而，我们的主要收获是，球员特定的结果比联赛范围内的结果更有意义，因为“手感”如果存在，是针对在离散时间段内进行单个球员的表现，而不是针对在不同时间和不同空间进行的不同球员的表现。
- en: 20.7 Statistical dispersion
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.7 统计离散度
- en: 'We worked with Gini coefficients, using the `ineq` package, in chapters 12
    and 13 (see sections 20.2 and 20.3), but it was really in chapter 18 where we
    most seriously considered measures of statistical dispersion. The NBA introduced
    a player salary cap just before the start of the 1984-85 season, ostensibly to
    create or at least improve parity across the league. We set about measuring pre-salary
    cap intra-season parity to determine if the NBA had a legitimate parity problem
    before 1984 that absolutely required corrective action and post-salary cap intra-season
    parity to establish whether the salary cap then improved the situation. The following
    methods were applied:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第12章和第13章中使用了基尼系数，使用了`ineq`包（参见20.2节和20.3节），但实际上，我们最认真地考虑统计离散度措施是在第18章。NBA在1984-85赛季开始前引入了球员薪资上限，表面上是为了在整个联盟中创造或至少改善平等性。我们着手测量薪资上限前的赛季内平等性，以确定NBA在1984年之前是否真的存在需要采取纠正行动的平等性问题，以及薪资上限后的赛季内平等性，以确定薪资上限当时是否改善了情况。以下方法被应用：
- en: '*Variance method*—Equal to squaring the difference between each value in a
    data set and the mean of all values in the same data set and dividing it by the
    number of observations'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*方差法*—等于将数据集中每个值与同一数据集中所有值的平均值之间的差值平方，然后除以观测值的数量'
- en: '*Standard deviation method*—Equal to the square root of the variance'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*标准差法*—等于方差的平方根'
- en: '*Range method*—Equal to the difference between the highest and lowest values
    in a data set'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*范围法*—等于数据集中最高值和最低值之间的差'
- en: '*Mean absolute deviation method*—Equal to the aggregated and absolute difference
    between each data point from a data set and the mean from the same data divided
    by the number of records'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*平均绝对偏差法*—等于每个数据点与同一数据集中平均值之间的聚合绝对差值，除以记录数'
- en: '*Median absolute deviation method*—Equal to the aggregated and absolute difference
    between each data point from a data set and the median from the same data divided
    by the number of records'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*中值绝对偏差法*—等于每个数据点与同一数据集中中位数之间的聚合绝对差值，除以记录数'
- en: With respect to the variance and standard deviation methods, base R functions
    were called; with respect to the range, mean absolute deviation, and median absolute
    deviation methods, arithmetic operations, which also come out-of-the-box, were
    written. When considering thoroughness, ease, and identification, the standard
    deviation method strikes the best balance of all the methods that were tested.
    However, there is no one-size-fits-all measure of statistical dispersion; all
    methods should be applied to gain a best understanding of the data. Our next Sankey
    diagram (see figure 20.7) captures what methods were used and where.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 关于方差和标准差方法，我们调用了基础R函数；至于范围、平均绝对偏差和中位数绝对偏差方法，我们编写了也现成的算术运算。在考虑全面性、易用性和识别度时，标准差方法在所有测试方法中取得了最佳平衡。然而，没有一种统计分散度的通用度量标准；所有方法都应被应用，以获得对数据的最佳理解。我们的下一个桑基图（见图20.7）捕捉了使用了哪些方法和在哪里使用。
- en: '![CH20_F07_Sutton](../../OEBPS/Images/CH20_F07_Sutton.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![CH20_F07_Sutton](../../OEBPS/Images/CH20_F07_Sutton.png)'
- en: Figure 20.7 We worked with Gini coefficients in chapters 12 and 13 and showed
    that teams with unequal salary and win share distributions, by that measure, were
    more successful than other teams. Five measures of statistical dispersion were
    then demonstrated in chapter 18 to quantify pre-salary cap and post-salary cap
    intra-season parity across the NBA. By all five measures of dispersion, intra-season
    parity actually improved between the 1970-71 and 1983-84 seasons and then worsened
    between the 1984-85 and 1997-98 seasons. Base R functions were used throughout.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.7 我们在第12章和第13章中使用了基尼系数，并表明在薪资和赢分分布不均的球队，根据这一衡量标准，比其他球队更成功。然后在第18章中展示了五个统计分散度的指标，以量化NBA在薪资上限前后的赛季内公平性。根据所有五个分散度指标，1970-71赛季到1983-84赛季之间赛季内的公平性实际上有所改善，然后在1984-85赛季到1997-98赛季之间恶化。整个过程中使用了基础R函数。
- en: Our analysis failed to establish what the NBA might have been thinking when
    it claimed back in the day that it had a parity problem. We clearly demonstrated
    that, by the same five measures, the salary cap didn’t produce its intended (or,
    at least, declaratory) effect.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的分析未能确定NBA在当年声称存在公平性问题时的想法。我们清楚地表明，通过相同的五个指标，薪资上限并没有产生预期的（或至少是声明的）效果。
- en: 20.8 Standardization
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.8 标准化
- en: We worked with z-scores—a z-score tells us how far a raw value is above or below
    a population mean—in chapter 11 and again in chapter 14, but it was in chapter
    19 where we most purposely worked with z-scores and other data standardization
    techniques (see figure 20.8).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第11章和第14章中使用了z分数——z分数告诉我们原始值相对于总体平均值的距离——但在第19章中，我们更有目的地使用了z分数和其他数据标准化技术（见图20.8）。
- en: '![CH20_F08_Sutton](../../OEBPS/Images/CH20_F08_Sutton.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![CH20_F08_Sutton](../../OEBPS/Images/CH20_F08_Sutton.png)'
- en: Figure 20.8 While we worked with z-scores in chapters 11 and 14, it was in chapter
    19 when we gave them, along with other standardization techniques, their full
    due. In chapter 19, we standardized historical points per game averages to mitigate
    the effects of rules changes and style of play transformations and, in the process,
    provided a fresh perspective on the past.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.8 虽然我们在第11章和第14章中使用了z分数，但直到第19章，我们才给予它们，连同其他标准化技术，充分的重视。在第19章中，我们将每场比赛的历史平均得分标准化，以减轻规则变化和比赛风格转变的影响，在这个过程中，对过去提供了一个新的视角。
- en: Back in the 1961-62 season, the great Wilt Chamberlain averaged 50.4 points
    per game, and then in 1962-63, he averaged 44.8 points scored per game. (Chamberlain
    actually led the NBA in scoring for seven consecutive seasons, from 1960 through
    1966.) No other player, before or since, has even averaged 40 points per game.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 回到1961-62赛季，伟大的威尔特·张伯伦平均每场比赛得到50.4分，然后在1962-63赛季，他平均每场比赛得到44.8分。（张伯伦实际上在1960年至1966年连续七个赛季中领导NBA得分。）在此之前或之后，没有其他球员甚至平均每场比赛得到40分。
- en: Chamberlain was absolutely a one-of-a-kind player, yet our ongoing admiration
    for his scoring prowess nevertheless ignores the fact that rule changes and playing
    style transformations have affected the pace of play from the NBA’s first season
    through today. Teams attempted fewer field goals and fewer free throws before
    and after Chamberlain’s dominance in the 1960s; consequently, fewer points were
    scored in the 1940s and 1950s and then again from the 1970s onward.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 查尔斯·巴克利绝对是一位独一无二的球员，然而我们对他的得分能力的持续钦佩却忽略了这样一个事实：规则变化和比赛风格的变化已经影响了从NBA第一个赛季到现在的比赛节奏。在巴克利在20世纪60年代的统治之前和之后，球队尝试的投篮和罚球次数都减少了；因此，在20世纪40年代和50年代以及从20世纪70年代开始，得分都减少了。
- en: 'We control for changes over time by standardizing the raw data; we therefore
    put a fresh perspective on historical points per game averages (or almost anything,
    really) by comparing annual scoring leaders against the league means of their
    time instead of across a span of several decades. Using base R functions, we tested
    the following four methods:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过标准化原始数据来控制时间上的变化；因此，我们通过将年度得分领袖与当时联盟的平均得分进行比较，而不是跨越几十年的时间跨度，对每场比赛的平均得分（或几乎所有其他事物）提出了新的视角。使用基本的R函数，我们测试了以下四种方法：
- en: '*Z-score method*—Equal to the raw data minus the population mean and then dividing
    the difference by the standard deviation'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Z分数法*—等于原始数据减去总体均值，然后除以标准差'
- en: '*Standard deviation method*—Equal to the raw data divided by the standard deviation'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*标准差法*—等于原始数据除以标准差'
- en: '*Centering method*—Equal to the raw data minus the mean'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*中心化法*—等于原始数据减去均值'
- en: '*Range method*—Equal to the raw data divided by the difference between the
    maximum and minimum values'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*范围法*—等于原始数据除以最大值和最小值之间的差'
- en: The z-score and standard deviation methods returned very different looks and
    results from the conventional perspective. According to both methods, George Mikan,
    in 1950, might very well have had the league’s best scoring average between that
    year and 1999\. Mikan’s 1950 scoring average was 6.8 standard deviations above
    the league mean; by comparison, Chamberlain’s 50.4 average more than a decade
    later was just 3.7 standard deviations above the league mean. The standard deviation
    method returned an even larger discrepancy between Mikan and Chamberlain. In other
    words, Mikan was a better scorer in his day than Chamberlain was in his.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Z分数法和标准差法从传统角度来看，返回了非常不同的外观和结果。根据这两种方法，乔治·米坎在1950年可能非常有可能在那一年的1999年之间拥有联盟的最佳得分平均分。米坎1950年的得分平均分比联盟均值高出6.8个标准差；相比之下，查尔斯·巴克利在十多年后的50.4平均得分仅比联盟均值高出3.7个标准差。标准差法在米坎和巴克利之间返回了更大的差异。换句话说，米坎在他那个时代比巴克利在他那个时代表现得更好。
- en: 20.9 Summary statistics and visualization
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 20.9 概率统计和可视化
- en: 'Our last learning area, summary statistics and visualization, is a sort of
    catch-all. That’s because every previous chapter, to some extent, contains summary
    (or descriptive) statistics complemented by a mix of visualizations. To avoid
    any repetition from the prior learning areas, our scope is therefore relegated
    to the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后一个学习领域，概率统计和可视化，是一种包罗万象的东西。这是因为前几章在某种程度上都包含了一些汇总（或描述性）统计，辅以各种可视化。为了避免与先前学习领域有任何重复，因此我们的范围被限制在以下内容：
- en: The automated (exploratory data analysis) EDA packages—`tableone`, `DataExplorer`,
    and `SmartEDA`—that were featured in chapter 17.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第17章中介绍过的自动化（探索性数据分析）EDA包—`tableone`、`DataExplorer`和`SmartEDA`。
- en: The manual EDA exercises that were especially exhaustive or weren’t necessarily
    complemented by the subsequent application of one or more statistical techniques.
    For instance, chapter 2 was almost wholly a demonstration of best EDA practices;
    chapter 5 showed how to best go about exploring a data set (and then wrangling
    it, as necessary) in preparation for fitting linear regressions; and though we
    introduced correlation tests in chapter 10, we otherwise relied solely on computing
    summary statistics and plotting the same.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 那些特别详尽或没有必然补充一个或多个统计技术的手动EDA练习。例如，第二章几乎完全是最佳EDA实践的演示；第五章展示了如何最好地探索数据集（然后根据需要对其进行整理）以准备拟合线性回归；尽管我们在第十章介绍了相关性测试，但我们否则仅依赖于计算汇总统计和绘图。
- en: All of this, of course, makes our scope somewhat subjective, but no less weighty
    than our other learning areas. Our next and final Sankey diagram (see figure 20.9)
    provides a visual snapshot of the discussion to come.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，所有这些都使我们的范围具有一定的主观性，但并不亚于我们的其他学习领域。我们接下来的最后一张桑基图（见图20.9）提供了一个即将讨论的视觉快照。
- en: '![CH20_F09_Sutton](../../OEBPS/Images/CH20_F09_Sutton.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![CH20_F09_Sutton](../../OEBPS/Images/CH20_F09_Sutton.png)'
- en: Figure 20.9 We computed summary, or descriptive, statistics in every chapter
    and then visualized the same by demonstrating a wide range of plotting techniques.
    However, the manual EDA exercises in chapters 2, 5, 6, 10, and 14, plus the automated
    EDA demonstrations in chapter 17, were more exhaustive than like efforts from
    other chapters.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图20.9 我们在每一章都计算了总结性或描述性统计量，然后通过展示各种绘图技术来可视化这些统计量。然而，第2、5、6、10和14章中的手动EDA练习，以及第17章中的自动化EDA演示，比其他章节的努力更为详尽。
- en: Our purpose in chapter 17 was to investigate opening totals versus closing totals
    and opening point spreads versus closing point spreads. Over the course of that
    investigation, we introduced and demonstrated a trio of automated EDA packages
    that subsequently provided the first indications that closing totals and closing
    point spreads, influenced by thousands of gamblers risking their own earnings,
    are usually more accurate than the opening totals and opening point spreads established
    by a much smaller number of oddsmakers and data scientists employed by Las Vegas
    casinos.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在第17章中，我们的目的是研究开盘总额与收盘总额，以及开盘点数差与收盘点数差。在调查过程中，我们介绍并演示了三个自动化的EDA包，这些包随后提供了第一个迹象，即受成千上万的赌徒冒险投入自己的收入影响的收盘总额和收盘点数差，通常比由拉斯维加斯赌场雇佣的少数赔率分析师和数据科学家建立的开盘总额和开盘点数差更准确。
- en: 'Here are the specifics:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是具体细节：
- en: We called on the `tableone` package to baseline our data set and return results
    in tabular formats.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们调用`tableone`包来建立我们的数据集基线，并以表格格式返回结果。
- en: We then pivoted to the `DataExplorer` package for insights into opening and
    closing totals (otherwise known as the opening and closing over/under), which
    returned a combination of results in tabular and visual formats.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们随后转向`DataExplorer`包，以深入了解开盘和收盘总额（也称为开盘和收盘上下波动），该包以表格和视觉格式返回了结果组合。
- en: Finally, we demonstrated the `SmartEDA` package when we needed initial insights
    into opening and closing point spreads.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，当我们需要初步了解开盘和收盘点数差时，我们展示了`SmartEDA`包。
- en: What’s especially nice about the `DataExplorer` and `SmartEDA` packages is that
    both aggregate several EDA commands—that we then demonstrated manually—into a
    single operation and then output the results to a standalone HTML file.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataExplorer`和`SmartEDA`包特别令人愉快的是，它们将我们随后手动演示的多个EDA命令聚合到一个单一操作中，然后将结果输出到一个独立的HTML文件。'
- en: On the whole, however, if it were simply one or the other, we prefer manual
    EDA over automated EDA, due to content control and required brainpower. In chapter
    2, we computed basic statistics and then created a mix of visualizations—one histogram,
    one correlation matrix, and several boxplots, bar charts, and facet plots—to best
    understand how our data was associated with career win shares.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，总的来说，如果我们只能选择其中之一，我们更喜欢手动EDA而不是自动化EDA，因为手动EDA可以更好地控制内容，并且需要更多的脑力。在第2章中，我们计算了基本统计量，然后创建了一系列可视化——一个直方图、一个相关矩阵以及几个箱线图、条形图和分面图，以最好地理解我们的数据与职业生涯胜利份额之间的关联。
- en: In chapter 5, we drew boxplots, over scatterplots and histograms, to help us
    identify (and then remove) outliers in our data; density plots to help us determine
    if our variables were normally distributed; and a correlation matrix to isolate
    the best candidate predictors in preparation for linear models to come (also see
    section 20.4).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在第5章中，我们绘制了箱线图，覆盖散点图和直方图，以帮助我们识别（然后移除）数据中的异常值；密度图帮助我们确定我们的变量是否呈正态分布；以及一个相关矩阵来隔离最佳候选预测因子，为即将到来的线性模型做准备（也参见20.4节）。
- en: In chapter 6, we relied solely on basic data analysis and data visualization
    techniques to show that games aren’t usually won in the fourth quarter, as conventional
    thinking has suggested for decades, but that they are actually won, more often
    than not, in the third quarter.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在第6章中，我们完全依赖基本的数据分析和数据可视化技术来表明，比赛通常不是在第四季度赢得的，正如几十年来传统思维所暗示的那样，但实际上，比赛往往是在第三季度赢得的。
- en: In chapter 10, we created correlation plots (and computed correlation coefficients)
    to show that team payrolls and regular season wins are positively correlated;
    dot plots binned by three season-ending classifications to show that teams with
    the highest payrolls win championships and generally qualify for postseason play,
    whereas teams with the lowest payrolls usually fail to make the playoffs; and
    lollipop charts, an alternative to bar charts, that show an even more definite
    association between payrolls and end-of-season disposition, especially since the
    2006 season.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在第10章中，我们创建了相关性图（并计算了相关系数）来显示球队薪资和常规赛胜利之间存在正相关；按三个赛季结束分类进行分组的点图，以显示薪资最高的球队赢得冠军并通常有资格参加季后赛，而薪资最低的球队通常无法进入季后赛；以及棒棒糖图，作为条形图的替代品，它显示了薪资和赛季结束处置之间的更明确关联，尤其是在2006赛季之后。
- en: In chapter 14, we called on a number of EDA techniques that returned results,
    even before we ran our statistical tests, suggesting defense and offense more
    or less equally contribute to winning games and championships, rather than defense
    mattering more than offense.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在第14章中，我们使用了多种EDA技术，甚至在运行统计测试之前就得到了结果，这表明防守和进攻在赢得比赛和冠军方面贡献几乎相等，而不是防守比进攻更重要。
- en: Finally, this brings us back to chapter 1 and specifically how this book was
    intended to work. Our goal from the very beginning was to deliver a different—yet
    more effective and more interesting—way of learning statistics using the R programming
    language. While there are hundreds of websites and several books in print that,
    for instance, more than adequately demonstrate how to summarize data or create
    a `ggplot2` bar chart or fit a linear regression, *none* explain how to tie together
    very different, seemingly unrelated, techniques and deliver actionable insights.
    There’s no such thing as a data summarization project, a data visualization project,
    or a linear regression project, but *every* project in the real world requires
    you to logically and sequentially apply some combination of these and other techniques
    with foresight and prudence. Your data, for example, must first be summarized—and
    maybe transposed and wrangled as well—in a precise format to then use it as a
    source for a fixed plot or to run a suitable statistical test.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这让我们回到了第1章，特别是这本书的预期工作方式。从一开始，我们的目标就是通过R编程语言提供一种不同——但更有效、更有趣——的学习统计方法。尽管有数百个网站和几本书详细介绍了如何总结数据或创建`ggplot2`条形图或拟合线性回归，但*没有*一本书解释如何将非常不同、看似无关的技术结合起来，并提供可操作见解。没有数据总结项目、数据可视化项目或线性回归项目，但*每个*现实世界中的项目都需要你具有预见性和谨慎地逻辑和顺序地应用这些以及其他技术的组合。例如，你的数据首先必须被总结——也许还需要进行转置和整理——以精确的格式使用，然后作为固定图表的来源或运行合适的统计测试。
- en: The most compelling way to deliver actionable insights is to visualize your
    results, if at all possible. Our visualizations were intended to be unassuming
    on one hand and always professional grade on the other. It’s way more important
    to create plots that allow your readers to readily draw at minimum two or three
    critical conclusions than to dazzle them with aesthetics. We demonstrated how
    to create *lots* of visualizations, many of which—dendrograms, Sankey diagrams,
    pyramid plots, facet plots, Cleveland dot plots, and Lorenz curves, to name just
    a few—are outside the mainstream. Our intent wasn’t to be different, per se, but
    to otherwise demonstrate that there’s a proper time and space for these and other
    types of visualizations.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 最有说服力的方式是将你的结果可视化，如果可能的话。我们的可视化旨在一方面保持低调，另一方面始终保持专业水准。创建能够让你的读者轻松得出至少两个或三个关键结论的图表，比用美学来眩惑他们要重要得多。我们展示了如何创建*大量*可视化，其中许多——如树状图、桑基图、金字塔图、分面图、克利夫兰点图和洛伦兹曲线，仅举几例——都属于非主流。我们的意图并不是要与众不同，而是要展示这些以及其他类型的可视化有合适的时间和空间。
- en: Finally, while it’s unlikely you’re in the business of analyzing basketball
    statistics, hopefully the use of NBA data sets made the learning more captivating
    than if we had instead imported packaged data sets or even used mocked-up data.
    Notwithstanding the common thread of NBA data sets, every technique we demonstrated
    is absolutely transferrable to your line of work—professional, academic, or otherwise.
    Even the concepts that we presented, from constrained optimization, for instance,
    to optimal stopping, to the 80-20 rule, have an infinite number of use cases in
    almost any vertical.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，虽然你很可能不在分析篮球统计数据这一行，但希望使用NBA数据集让学习过程比我们导入打包的数据集或使用模拟数据更加引人入胜。尽管NBA数据集有共同的主题，但我们展示的每一项技术都可以完全转移到你的工作中——无论是专业、学术还是其他方面。甚至我们提出的概念，例如从约束优化到最优停止，再到80-20法则，几乎在任何一个领域都有无限的应用场景。
- en: Now, make it happen!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让它成为现实吧！
