- en: Chapter 2\. The data science process
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二章. 数据科学流程
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Understanding the flow of a data science process
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解数据科学流程的流程
- en: Discussing the steps in a data science process
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 讨论数据科学流程的步骤
- en: The goal of this chapter is to give an overview of the data science process
    without diving into big data yet. You’ll learn how to work with big data sets,
    streaming data, and text data in subsequent chapters.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是在不深入大数据之前概述数据科学流程。你将在后续章节中学习如何处理大数据集、流数据以及文本数据。
- en: 2.1\. Overview of the data science process
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1. 数据科学流程概述
- en: 'Following a structured approach to data science helps you to maximize your
    chances of success in a data science project at the lowest cost. It also makes
    it possible to take up a project as a team, with each team member focusing on
    what they do best. Take care, however: this approach may not be suitable for every
    type of project or be the only way to do good data science.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 采取结构化的数据科学方法有助于你在最低成本的情况下最大限度地提高数据科学项目的成功率。这也使得以团队形式承担项目成为可能，每个团队成员都专注于他们最擅长的事情。但是请注意：这种方法可能不适合所有类型的项目，也不一定是做好数据科学的唯一方式。
- en: The typical data science process consists of six steps through which you’ll
    iterate, as shown in [figure 2.1](#ch02fig01).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的数据科学流程包括六个步骤，你将通过这些步骤进行迭代，如图2.1所示。
- en: Figure 2.1\. The six steps of the data science process
  id: totrans-8
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.1. 数据科学流程的六个步骤
- en: '![](Images/02fig01_alt.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig01_alt.jpg)'
- en: '[Figure 2.1](#ch02fig01) summarizes the data science process and shows the
    main steps and actions you’ll take during a project. The following list is a short
    introduction; each of the steps will be discussed in greater depth throughout
    this chapter.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2.1](#ch02fig01)总结了数据科学流程，并显示了在项目期间你将采取的主要步骤和行动。以下列表是一个简要介绍；本章将更深入地讨论每个步骤。'
- en: '**1**.  The first step of this process is setting a *research goal*. The main
    purpose here is making sure all the stakeholders understand the *what*, *how*,
    and *why* of the project. In every serious project this will result in a project
    charter.'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**1**. 这个流程的第一步是设定一个**研究目标**。这里的主要目的是确保所有利益相关者都理解项目的**目标**、**方法**和**原因**。在每一个严肃的项目中，这都会导致一个项目章程的产生。'
- en: '**2**.  The second phase is *data retrieval*. You want to have data available
    for analysis, so this step includes finding suitable data and getting access to
    the data from the data owner. The result is data in its raw form, which probably
    needs polishing and transformation before it becomes usable.'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2**. 第二个阶段是**数据检索**。你希望有可用于分析的数据，因此这一步骤包括寻找合适的数据并从数据所有者那里获取数据。结果是原始形式的数据，这可能在变成可用的之前需要抛光和转换。'
- en: '**3**.  Now that you have the raw data, it’s time to *prepare* it. This includes
    transforming the data from a raw form into data that’s directly usable in your
    models. To achieve this, you’ll detect and correct different kinds of errors in
    the data, combine data from different data sources, and transform it. If you have
    successfully completed this step, you can progress to data visualization and modeling.'
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**3**. 现在你已经拥有了原始数据，是时候对其进行**准备**了。这包括将数据从原始形式转换为可以直接用于你模型的格式。为了实现这一点，你需要检测和纠正数据中的不同类型错误，合并来自不同数据源的数据，并进行转换。如果你已经成功完成了这一步，你就可以继续进行数据可视化和建模。'
- en: '**4**.  The fourth step is *data exploration*. The goal of this step is to
    gain a deep understanding of the data. You’ll look for patterns, correlations,
    and deviations based on visual and descriptive techniques. The insights you gain
    from this phase will enable you to start modeling.'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**4**. 第四步是**数据探索**。这一步骤的目标是深入理解数据。你将基于视觉和描述性技术寻找模式、相关性和偏差。从这个阶段获得的洞察将使你能够开始建模。'
- en: '**5**.  Finally, we get to the sexiest part: *model building* (often referred
    to as “data modeling” throughout this book). It is now that you attempt to gain
    the insights or make the predictions stated in your project charter. Now is the
    time to bring out the heavy guns, but remember research has taught us that often
    (but not always) a combination of simple models tends to outperform one complicated
    model. If you’ve done this phase right, you’re almost done.'
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**5**. 最后，我们来到了最吸引人的部分：**模型构建**（本书中通常称为“数据建模”）。现在是你尝试从项目章程中陈述的洞察或预测的时候了。现在是时候拿出重型武器了，但请记住，研究告诉我们，通常（但不总是）简单模型的组合往往比一个复杂的模型表现更好。如果你正确完成了这一阶段，你几乎就完成了。'
- en: '**6**.  The last step of the data science model is *presenting your results
    and automating the analysis,* if needed. One goal of a project is to change a
    process and/or make better decisions. You may still need to convince the business
    that your findings will indeed change the business process as expected. This is
    where you can shine in your influencer role. The importance of this step is more
    apparent in projects on a strategic and tactical level. Certain projects require
    you to perform the business process over and over again, so automating the project
    will save time.'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**6**. 数据科学模型的最后一步是*展示你的结果和自动化分析*，如果需要的话。项目的一个目标就是改变流程和/或做出更好的决策。你可能仍然需要说服企业你的发现确实会按照预期改变业务流程。这就是你可以在你的影响力角色中发光的时候。这一步骤的重要性在战略和战术层面的项目中更为明显。某些项目需要你反复执行业务流程，因此自动化项目可以节省时间。'
- en: In reality you won’t progress in a linear way from step 1 to step 6\. Often
    you’ll regress and iterate between the different phases.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实中，你不会以线性方式从步骤1进展到步骤6。你通常会在这不同阶段之间回退和迭代。
- en: 'Following these six steps pays off in terms of a higher project success ratio
    and increased impact of research results. This process ensures you have a well-defined
    research plan, a good understanding of the business question, and clear deliverables
    before you even start looking at data. The first steps of your process focus on
    getting high-quality data as input for your models. This way your models will
    perform better later on. In data science there’s a well-known saying: *Garbage
    in equals garbage out*.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这六个步骤进行，可以提高项目成功率并增加研究结果的影響力。这个过程确保你在开始查看数据之前就有一个明确的研究计划，对商业问题的良好理解，以及清晰的交付成果。你流程的第一步是关注获取高质量数据作为你模型的输入。这样你的模型在后期将表现得更好。在数据科学中，有一句众所周知的话：*垃圾输入等于垃圾输出*。
- en: Another benefit of following a structured approach is that you work more in
    *prototype mode* while you search for the best model. When building a *prototype,*
    you’ll probably try multiple models and won’t focus heavily on issues such as
    program speed or writing code against standards. This allows you to focus on bringing
    business value instead.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 跟随一种结构化方法的好处之一是，你在寻找最佳模型的同时，更多地处于*原型模式*。在构建*原型*时，你可能会尝试多个模型，而不会过分关注程序速度或编写符合标准代码等问题。这让你能够专注于带来商业价值。
- en: Not every project is initiated by the business itself. Insights learned during
    analysis or the arrival of new data can spawn new projects. When the data science
    team generates an idea, work has already been done to make a proposition and find
    a business sponsor.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 并非每个项目都是由企业自身发起的。在分析过程中获得的认识或新数据的到来可以催生新的项目。当数据科学团队产生一个想法时，已经进行了工作来提出建议并找到商业赞助者。
- en: Dividing a project into smaller stages also allows employees to work together
    as a team. It’s impossible to be a specialist in everything. You’d need to know
    how to upload all the data to all the different databases, find an optimal data
    scheme that works not only for your application but also for other projects inside
    your company, and then keep track of all the statistical and data-mining techniques,
    while also being an expert in presentation tools and business politics. That’s
    a hard task, and it’s why more and more companies rely on a team of specialists
    rather than trying to find one person who can do it all.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 将项目划分为更小的阶段也允许员工作为一个团队一起工作。不可能在所有事情上都是专家。你需要知道如何将所有数据上传到所有不同的数据库中，找到一个既适合你的应用程序也适合公司内部其他项目的最佳数据方案，然后跟踪所有统计和数据挖掘技术，同时还要成为演示工具和商业政治的专家。这是一项艰巨的任务，这也是为什么越来越多的公司依赖于一个专家团队而不是试图找到一个人能做所有的事情。
- en: The process we described in this section is best suited for a data science project
    that contains only a few models. It’s not suited for every type of project. For
    instance, a project that contains millions of real-time models would need a different
    approach than the flow we describe here. A beginning data scientist should get
    a long way following this manner of working, though.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中描述的流程最适合只包含几个模型的数据科学项目。它并不适合所有类型的项目。例如，包含数百万个实时模型的项目需要比我们描述的流程不同的方法。尽管如此，一个初出茅庐的数据科学家按照这种方式工作可以走得很远。
- en: 2.1.1\. Don’t be a slave to the process
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1\. 不要成为过程的奴隶
- en: Not every project will follow this blueprint, because your process is subject
    to the preferences of the data scientist, the company, and the nature of the project
    you work on. Some companies may require you to follow a strict protocol, whereas
    others have a more informal manner of working. In general, you’ll need a structured
    approach when you work on a complex project or when many people or resources are
    involved.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 并非每个项目都会遵循这个蓝图，因为你的流程受数据科学家、公司以及你所从事的项目性质的影响。一些公司可能要求你遵循严格的协议，而其他公司则可能采用更为非正式的工作方式。通常情况下，当你处理复杂项目或涉及多人或资源时，你需要一个结构化的方法。
- en: The *agile* project model is an alternative to a sequential process with iterations.
    As this methodology wins more ground in the IT department and throughout the company,
    it’s also being adopted by the data science community. Although the agile methodology
    is suitable for a data science project, many company policies will favor a more
    rigid approach toward data science.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*敏捷*项目模型是迭代顺序流程的替代方案。随着这种方法在IT部门和整个公司中赢得更多支持，它也被数据科学社区所采纳。尽管敏捷方法适合数据科学项目，但许多公司政策可能会倾向于更严格的数据科学方法。'
- en: Planning every detail of the data science process upfront isn’t always possible,
    and more often than not you’ll iterate between the different steps of the process.
    For instance, after the briefing you start your normal flow until you’re in the
    exploratory data analysis phase. Your graphs show a distinction in the behavior
    between two groups—men and women maybe? You aren’t sure because you don’t have
    a variable that indicates whether the customer is male or female. You need to
    retrieve an extra data set to confirm this. For this you need to go through the
    approval process, which indicates that you (or the business) need to provide a
    kind of project charter. In big companies, getting all the data you need to finish
    your project can be an ordeal.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在一开始就规划数据科学流程的每一个细节并不总是可能的，而且你通常会在流程的不同步骤之间迭代。例如，在简报之后，你开始你的正常流程，直到你进入探索性数据分析阶段。你的图表显示了两组——男性和女性——之间的行为差异。你不确定，因为你没有变量来指示客户是男性还是女性。你需要检索额外的数据集来确认这一点。为此，你需要通过审批流程，这表明你（或业务）需要提供一种项目章程。在大公司中，获取完成项目所需的所有数据可能是一项艰巨的任务。
- en: '2.2\. Step 1: Defining research goals and creating a project charter'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2. 第一步：定义研究目标和创建项目章程
- en: A project starts by understanding the *what*, the *why*, and the *how* of your
    project ([figure 2.2](#ch02fig02)). What does the company expect you to do? And
    why does management place such a value on your research? Is it part of a bigger
    strategic picture or a “lone wolf” project originating from an opportunity someone
    detected? Answering these three questions (what, why, how) is the goal of the
    first phase, so that everybody knows what to do and can agree on the best course
    of action.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 项目开始于理解项目的*目标*、*原因*和*方法*（[图2.2](#ch02fig02)）。公司期望你做什么？管理层为什么如此重视你的研究？它是更大战略图景的一部分，还是源于某人发现的机会的“孤狼”项目？回答这三个问题（目标、原因、方法）是第一阶段的目标，这样每个人都知道该做什么，并可以就最佳行动方案达成一致。
- en: 'Figure 2.2\. Step 1: Setting the research goal'
  id: totrans-29
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.2. 第一步：设定研究目标
- en: '![](Images/02fig02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig02.jpg)'
- en: The outcome should be a clear research goal, a good understanding of the context,
    well-defined deliverables, and a plan of action with a timetable. This information
    is then best placed in a project charter. The length and formality can, of course,
    differ between projects and companies. In this early phase of the project, people
    skills and business acumen are more important than great technical prowess, which
    is why this part will often be guided by more senior personnel.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该是一个明确的研究目标、对背景的良好理解、定义清晰的交付成果以及一个包含时间表的行动计划。这些信息最好放在项目章程中。当然，项目章程的长度和正式程度在不同项目和公司之间可能会有所不同。在这个项目的早期阶段，人际交往能力和商业洞察力比卓越的技术能力更为重要，这就是为什么这部分工作通常由更有经验的人员指导。
- en: 2.2.1\. Spend time understanding the goals and context of your research
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1. 花时间理解你的研究目标和背景
- en: 'An essential outcome is the research goal that states the purpose of your assignment
    in a clear and focused manner. Understanding the business goals and context is
    critical for project success. Continue asking questions and devising examples
    until you grasp the exact business expectations, identify how your project fits
    in the bigger picture, appreciate how your research is going to change the business,
    and understand how they’ll use your results. Nothing is more frustrating than
    spending months researching something until you have that one moment of brilliance
    and solve the problem, but when you report your findings back to the organization,
    everyone immediately realizes that you misunderstood their question. Don’t skim
    over this phase lightly. Many data scientists fail here: despite their mathematical
    wit and scientific brilliance, they never seem to grasp the business goals and
    context.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基本的结果是研究目标，它以清晰和专注的方式陈述了你的作业目的。理解业务目标和背景对于项目成功至关重要。继续提问和设计例子，直到你掌握确切的业务期望，确定你的项目如何融入更大的图景，欣赏你的研究如何改变业务，以及他们如何使用你的结果。没有什么比花了几个月研究某件事，直到那一刻的灵感迸发并解决问题，但当你向组织报告你的发现时，每个人都立即意识到你误解了他们的问题更令人沮丧的了。不要轻率地跳过这个阶段。许多数据科学家在这里失败：尽管他们有数学智慧和科学才华，但他们似乎从未真正理解业务目标和背景。
- en: 2.2.2\. Create a project charter
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2\. 创建项目章程
- en: Clients like to know upfront what they’re paying for, so after you have a good
    understanding of the business problem, try to get a formal agreement on the deliverables.
    All this information is best collected in a project charter. For any significant
    project this would be mandatory.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 客户喜欢事先知道他们支付了什么，所以在你对业务问题有很好的理解之后，尝试就可交付成果达成正式协议。所有这些信息最好收集在项目章程中。对于任何重大项目，这将是强制性的。
- en: 'A project charter requires teamwork, and your input covers at least the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 项目章程需要团队合作，你的输入至少包括以下内容：
- en: A clear research goal
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清晰的研究目标
- en: The project mission and context
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目使命和背景
- en: How you’re going to perform your analysis
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将如何进行你的分析
- en: What resources you expect to use
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你期望使用的资源
- en: Proof that it’s an achievable project, or proof of concepts
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证明这是一个可实现的项目的证据，或者概念证明
- en: Deliverables and a measure of success
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可交付成果和成功的衡量标准
- en: A timeline
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间表
- en: Your client can use this information to make an estimation of the project costs
    and the data and people required for your project to become a success.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你的客户可以使用这些信息来估算项目成本以及使你的项目成功所需的数据和人员。
- en: '2.3\. Step 2: Retrieving data'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 第2步：检索数据
- en: The next step in data science is to retrieve the required data ([figure 2.3](#ch02fig03)).
    Sometimes you need to go into the field and design a data collection process yourself,
    but most of the time you won’t be involved in this step. Many companies will have
    already collected and stored the data for you, and what they don’t have can often
    be bought from third parties. Don’t be afraid to look outside your organization
    for data, because more and more organizations are making even high-quality data
    freely available for public and commercial use.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学的下一步是检索所需的数据（[图2.3](#ch02fig03)）。有时你需要进入现场并自己设计数据收集过程，但大多数时候你不会参与这一步骤。许多公司已经为你收集和存储了数据，而且他们没有的通常可以从第三方购买。不要害怕在你的组织之外寻找数据，因为越来越多的组织甚至将高质量的数据免费提供给公众和商业使用。
- en: 'Figure 2.3\. Step 2: Retrieving data'
  id: totrans-47
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.3\. 第2步：检索数据
- en: '![](Images/02fig03.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig03.jpg)'
- en: 'Data can be stored in many forms, ranging from simple text files to tables
    in a database. The objective now is acquiring all the data you need. This may
    be difficult, and even if you succeed, data is often like a diamond in the rough:
    it needs polishing to be of any use to you.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以以多种形式存储，从简单的文本文件到数据库中的表格。现在的目标是获取所有你需要的数据。这可能很困难，即使你成功了，数据通常就像未经雕琢的钻石：它需要抛光才能对你有任何用处。
- en: 2.3.1\. Start with data stored within the company
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1\. 从公司内部存储的数据开始
- en: Your first act should be to assess the relevance and quality of the data that’s
    readily available within your company. Most companies have a program for maintaining
    key data, so much of the cleaning work may already be done. This data can be stored
    in official data repositories such as *databases*, *data marts*, *data warehouses*,
    and *data lakes* maintained by a team of IT professionals. The primary goal of
    a database is data storage, while a data warehouse is designed for reading and
    analyzing that data. A data mart is a subset of the data warehouse and geared
    toward serving a specific business unit. While data warehouses and data marts
    are home to preprocessed data, data lakes contains data in its natural or raw
    format. But the possibility exists that your data still resides in Excel files
    on the desktop of a domain expert.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您的第一步应该是评估公司内部可轻松获取的数据的相关性和质量。大多数公司都有维护关键数据的计划，因此大部分清理工作可能已经完成。这些数据可以存储在由IT专业人员维护的官方数据存储库中，例如*数据库*、*数据集市*、*数据仓库*和*数据湖*。数据库的主要目标是数据存储，而数据仓库旨在读取和分析这些数据。数据集市是数据仓库的子集，旨在服务于特定的业务单元。虽然数据仓库和数据集市是预加工数据的家园，但数据湖包含的是其自然或原始格式的数据。但仍然存在可能性，即您的数据仍然存储在领域专家的桌面上的Excel文件中。
- en: Finding data even within your own company can sometimes be a challenge. As companies
    grow, their data becomes scattered around many places. Knowledge of the data may
    be dispersed as people change positions and leave the company. Documentation and
    metadata aren’t always the top priority of a delivery manager, so it’s possible
    you’ll need to develop some Sherlock Holmes–like skills to find all the lost bits.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在您自己的公司内部找到数据有时也可能是一项挑战。随着公司的发展，他们的数据会分散在许多地方。随着人们更换职位和离开公司，数据知识可能会分散。文档和元数据并不总是交付经理的首要任务，因此您可能需要发展一些福尔摩斯式的技能来找到所有丢失的部分。
- en: Getting access to data is another difficult task. Organizations understand the
    value and sensitivity of data and often have policies in place so everyone has
    access to what they need and nothing more. These policies translate into physical
    and digital barriers called *Chinese walls*. These “walls” are mandatory and well-regulated
    for customer data in most countries. This is for good reasons, too; imagine everybody
    in a credit card company having access to your spending habits. Getting access
    to the data may take time and involve company politics.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 获取数据访问权限是另一项困难的任务。组织理解数据的价值和敏感性，并通常有政策来确保每个人都能访问他们所需的数据，而无需更多。这些政策转化为被称为*防火墙*的物理和数字障碍。这些“墙”在大多数国家对于客户数据来说是强制性和规范化的。这也是出于好理由；想象一下，信用卡公司的每个人都能够访问您的消费习惯。获取数据访问权限可能需要时间，并可能涉及公司政治。
- en: 2.3.2\. Don’t be afraid to shop around
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2\. 不要害怕四处寻找
- en: If data isn’t available inside your organization, look outside your organization’s
    walls. Many companies specialize in collecting valuable information. For instance,
    Nielsen and GFK are well known for this in the retail industry. Other companies
    provide data so that you, in turn, can enrich their services and ecosystem. Such
    is the case with Twitter, LinkedIn, and Facebook.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您所在的组织内部没有数据，那么就看看组织外部。许多公司专门从事收集有价值的信息。例如，尼尔森和GFK在零售行业因这一点而闻名。其他公司提供数据，以便您反过来丰富他们的服务和生态系统。推特、领英和Facebook就是这种情况。
- en: Although data is considered an asset more valuable than oil by certain companies,
    more and more governments and organizations share their data for free with the
    world. This data can be of excellent quality; it depends on the institution that
    creates and manages it. The information they share covers a broad range of topics
    such as the number of accidents or amount of drug abuse in a certain region and
    its demographics. This data is helpful when you want to enrich proprietary data
    but also convenient when training your data science skills at home. [Table 2.1](#ch02table01)
    shows only a small selection from the growing number of open-data providers.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然某些公司认为数据比石油更有价值，但越来越多的政府和组织正将他们的数据免费与世界共享。这些数据的质量可能非常优秀；这取决于创建和管理它的机构。他们分享的信息涵盖了广泛的主题，例如某个地区的意外事故数量或药物滥用情况及其人口统计。当你想要丰富专有数据时，这些数据很有帮助；同时，在家训练数据科学技能时也非常方便。[表2.1](#ch02table01)
    仅展示了日益增长的开放数据提供者中的一小部分。
- en: Table 2.1\. A list of open-data providers that should get you started
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表2.1\. 应该帮助您开始的开放数据提供者列表
- en: '| Open data site | Description |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 开放数据网站 | 描述 |'
- en: '| --- | --- |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Data.gov | The home of the US Government’s open data |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| Data.gov | 美国政府开放数据的家园 |'
- en: '| [https://open-data.europa.eu/](https://open-data.europa.eu/) | The home of
    the European Commission’s open data |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| [https://open-data.europa.eu/](https://open-data.europa.eu/) | 欧洲委员会开放数据的家园
    |'
- en: '| Freebase.org | An open database that retrieves its information from sites
    like Wikipedia, MusicBrains, and the SEC archive |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Freebase.org | 从维基百科、MusicBrains和SEC档案等网站检索信息的开放数据库 |'
- en: '| Data.worldbank.org | Open data initiative from the World Bank |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| Data.worldbank.org | 世界银行开放数据倡议 |'
- en: '| Aiddata.org | Open data for international development |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| Aiddata.org | 国际发展开放数据 |'
- en: '| Open.fda.gov | Open data from the US Food and Drug Administration |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| Open.fda.gov | 美国食品药品监督管理局的开放数据 |'
- en: 2.3.3\. Do data quality checks now to prevent problems later
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.3\. 现在进行数据质量检查，以防止以后出现问题
- en: Expect to spend a good portion of your project time doing data correction and
    cleansing, sometimes up to 80%. The retrieval of data is the first time you’ll
    inspect the data in the data science process. Most of the errors you’ll encounter
    during the data-gathering phase are easy to spot, but being too careless will
    make you spend many hours solving data issues that could have been prevented during
    data import.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 预计您将花费项目的大部分时间进行数据校正和清洗，有时高达80%。数据的检索是您在数据科学流程中第一次检查数据。在数据收集阶段，您会遇到的大部分错误都很容易发现，但过于粗心大意会使您花费许多小时解决本可以在数据导入期间预防的数据问题。
- en: 'You’ll investigate the data during the import, data preparation, and exploratory
    phases. The difference is in the goal and the depth of the investigation. During
    *data retrieval*, you check to see if the data is equal to the data in the source
    document and look to see if you have the right data types. This shouldn’t take
    too long; when you have enough evidence that the data is similar to the data you
    find in the source document, you stop. With *data preparation*, you do a more
    elaborate check. If you did a good job during the previous phase, the errors you
    find now are also present in the source document. The focus is on the content
    of the variables: you want to get rid of typos and other data entry errors and
    bring the data to a common standard among the data sets. For example, you might
    correct USQ to USA and United Kingdom to UK. During the *exploratory phase* your
    focus shifts to what you can learn from the data. Now you assume the data to be
    clean and look at the statistical properties such as distributions, correlations,
    and outliers. You’ll often iterate over these phases. For instance, when you discover
    outliers in the exploratory phase, they can point to a data entry error. Now that
    you understand how the quality of the data is improved during the process, we’ll
    look deeper into the data preparation step.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在导入、数据准备和探索阶段调查数据。区别在于调查的目标和深度。在*数据检索*阶段，您检查数据是否与源文档中的数据相等，并查看您是否拥有正确的数据类型。这不应该花费太多时间；当您有足够的证据表明数据与您在源文档中找到的数据相似时，您就停止。在*数据准备*阶段，您进行更细致的检查。如果您在前一阶段做得很好，现在发现的错误也存在于源文档中。重点是变量的内容：您希望消除拼写错误和其他数据输入错误，并将数据带到数据集的共同标准。例如，您可能将USQ更正为USA，将联合王国更正为UK。在*探索阶段*，您的重点转向从数据中可以学习到什么。现在您假设数据是干净的，并查看统计属性，如分布、相关性和异常值。您通常会反复进行这些阶段。例如，当您在探索阶段发现异常值时，它们可以指向数据输入错误。现在您已经了解了数据质量在流程中是如何得到提高的，我们将更深入地探讨数据准备步骤。
- en: '2.4\. Step 3: Cleansing, integrating, and transforming data'
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4\. 第3步：清洗、集成和转换数据
- en: 'The data received from the data retrieval phase is likely to be “a diamond
    in the rough.” Your task now is to sanitize and prepare it for use in the modeling
    and reporting phase. Doing so is tremendously important because your models will
    perform better and you’ll lose less time trying to fix strange output. It can’t
    be mentioned nearly enough times: garbage in equals garbage out. Your model needs
    the data in a specific format, so data transformation will always come into play.
    It’s a good habit to correct data errors as early on in the process as possible.
    However, this isn’t always possible in a realistic setting, so you’ll need to
    take corrective actions in your program.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据检索阶段接收到的数据可能“像粗糙的钻石。”您的任务现在是对其进行净化和准备，以便在建模和报告阶段使用。这样做非常重要，因为您的模型将表现得更好，您将花费更少的时间来修复奇怪的输出。这几乎无法用足够多的次数来提及：垃圾输入等于垃圾输出。您的模型需要特定格式的数据，因此数据转换总是起作用。尽早纠正数据错误是一个好习惯。然而，在现实环境中，这并不总是可能的，因此您需要在程序中采取纠正措施。
- en: '[Figure 2.4](#ch02fig04) shows the most common actions to take during the data
    cleansing, integration, and transformation phase.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 2.4](#ch02fig04) 展示了在数据清洗、集成和转换阶段最常见的行为。'
- en: 'Figure 2.4\. Step 3: Data preparation'
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.4\. 第 3 步：数据准备
- en: '![](Images/02fig04_alt.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig04_alt.jpg)'
- en: This mind map may look a bit abstract for now, but we’ll handle all of these
    points in more detail in the next sections. You’ll see a great commonality among
    all of these actions.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这个思维导图现在可能看起来有点抽象，但我们在下一节中会更详细地处理所有这些点。您将看到所有这些行动之间有很大的共性。
- en: 2.4.1\. Cleansing data
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.1\. 数据清洗
- en: Data cleansing is a subprocess of the data science process that focuses on removing
    errors in your data so your data becomes a true and consistent representation
    of the processes it originates from.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洗是数据科学过程中的一个子过程，它专注于去除数据中的错误，以便您的数据成为其来源过程的真正和一致的表现。
- en: 'By “true and consistent representation” we imply that at least two types of
    errors exist. The first type is the *interpretation error*, such as when you take
    the value in your data for granted, like saying that a person’s age is greater
    than 300 years. The second type of error points to *inconsistencies* between data
    sources or against your company’s standardized values. An example of this class
    of errors is putting “Female” in one table and “F” in another when they represent
    the same thing: that the person is female. Another example is that you use Pounds
    in one table and Dollars in another. Too many possible errors exist for this list
    to be exhaustive, but [table 2.2](#ch02table02) shows an overview of the types
    of errors that can be detected with easy checks—the “low hanging fruit,” as it
    were.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过“真正和一致的表现”，我们意味着至少存在两种类型的错误。第一种是*解释错误*，例如，当您理所当然地接受数据中的值时，比如说某人的年龄大于300岁。第二种错误指向数据源之间的*不一致性*或与您公司标准化的值相矛盾。这类错误的一个例子是在一个表中将“Female”放入，在另一个表中将“F”放入，尽管它们代表的是同一件事：这个人女性。另一个例子是在一个表中使用磅，在另一个表中使用美元。可能的错误太多，无法一一列举，但[表
    2.2](#ch02table02) 展示了可以通过简单检查检测到的错误类型概述——“低垂的果实”。
- en: Table 2.2\. An overview of common errors
  id: totrans-78
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 2.2\. 常见错误的概述
- en: '| General solution |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 一般解决方案 |'
- en: '| --- |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| Try to fix the problem early in the data acquisition chain or else fix it
    in the program. |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 尝试在数据获取链的早期修复问题，或者在其他地方修复它。 |'
- en: '| **Error description** | **Possible solution** |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| **错误描述** | **可能的解决方案** |'
- en: '| *Errors pointing to false values within one data set* |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| *指向一个数据集中错误值的错误* |'
- en: '| Mistakes during data entry | Manual overrules |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 数据输入错误 | 手动覆盖 |'
- en: '| Redundant white space | Use string functions |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 空白冗余 | 使用字符串函数 |'
- en: '| Impossible values | Manual overrules |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 不可能的值 | 手动覆盖 |'
- en: '| Missing values | Remove observation or value |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 缺失值 | 删除观测值或值 |'
- en: '| Outliers | Validate and, if erroneous, treat as missing value (remove or
    insert) |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 异常值 | 验证，如果错误，则将其视为缺失值（删除或插入） |'
- en: '| *Errors pointing to inconsistencies between data sets* |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| *指向数据集之间不一致性的错误* |'
- en: '| Deviations from a code book | Match on keys or else use manual overrules
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 与代码簿的偏差 | 通过键匹配或使用手动覆盖 |'
- en: '| Different units of measurement | Recalculate |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 不同的度量单位 | 重新计算 |'
- en: '| Different levels of aggregation | Bring to same level of measurement by aggregation
    or extrapolation |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 不同聚合级别 | 通过聚合或外推将其提升到相同的测量水平 |'
- en: Sometimes you’ll use more advanced methods, such as simple modeling, to find
    and identify data errors; diagnostic plots can be especially insightful. For example,
    in [figure 2.5](#ch02fig05) we use a measure to identify data points that seem
    out of place. We do a regression to get acquainted with the data and detect the
    influence of individual observations on the regression line. When a single observation
    has too much influence, this can point to an error in the data, but it can also
    be a valid point. At the data cleansing stage, these advanced methods are, however,
    rarely applied and often regarded by certain data scientists as overkill.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 有时你会使用更高级的方法，例如简单的建模，来寻找和识别数据错误；诊断图可以特别有洞察力。例如，在[图2.5](#ch02fig05)中，我们使用一个度量来识别看起来不合适的数据点。我们进行回归以熟悉数据并检测单个观察值对回归线的影响。当一个单独的观察值有太大的影响时，这可以表明数据中存在错误，但也可能是一个有效的点。然而，在数据清洗阶段，这些高级方法很少被应用，并且通常被某些数据科学家视为过度。
- en: Figure 2.5\. The encircled point influences the model heavily and is worth investigating
    because it can point to a region where you don’t have enough data or might indicate
    an error in the data, but it also can be a valid data point.
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.5\. 被圈出的点对模型有重大影响，值得调查，因为它可能指向一个数据不足的区域，或者可能表明数据中存在错误，但它也可能是一个有效的数据点。
- en: '![](Images/02fig05_alt.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig05_alt.jpg)'
- en: Now that we’ve given the overview, it’s time to explain these errors in more
    detail.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经给出了概述，是时候更详细地解释这些错误了。
- en: Data entry errors
  id: totrans-97
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据输入错误
- en: Data collection and data entry are error-prone processes. They often require
    human intervention, and because humans are only human, they make typos or lose
    their concentration for a second and introduce an error into the chain. But data
    collected by machines or computers isn’t free from errors either. Errors can arise
    from human sloppiness, whereas others are due to machine or hardware failure.
    Examples of errors originating from machines are transmission errors or bugs in
    the extract, transform, and load phase (ETL).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集和数据输入是容易出错的过程。它们通常需要人工干预，由于人类只是人类，他们可能会犯拼写错误或分心一秒钟，从而在链中引入错误。但由机器或计算机收集的数据也不是没有错误的。错误可能源于人类粗心大意，而另一些则是由于机器或硬件故障。机器产生的错误示例包括传输错误或提取、转换和加载阶段（ETL）中的错误。
- en: 'For small data sets you can check every value by hand. Detecting data errors
    when the variables you study don’t have many classes can be done by tabulating
    the data with counts. When you have a variable that can take only two values:
    “Good” and “Bad”, you can create a frequency table and see if those are truly
    the only two values present. In [table 2.3](#ch02table03), the values “Godo” and
    “Bade” point out something went wrong in at least 16 cases.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于小数据集，你可以手动检查每个值。当研究的变量没有很多类别时，可以通过计数表来检测数据错误。当你有一个只能取两个值：“好”和“坏”的变量时，你可以创建一个频率表，看看这些是否真的是唯一存在的两个值。在[表2.3](#ch02table03)中，值“Godo”和“Bade”指出至少在16个案例中出了问题。
- en: Table 2.3\. Detecting outliers on simple variables with a frequency table
  id: totrans-100
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表2.3\. 使用频率表检测简单变量的异常值
- en: '| Value | Count |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 值 | 数量 |'
- en: '| --- | --- |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Good | 1598647 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 好 | 1598647 |'
- en: '| Bad | 1354468 |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 差 | 1354468 |'
- en: '| Godo | 15 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Godo | 15 |'
- en: '| Bade | 1 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Bade | 1 |'
- en: 'Most errors of this type are easy to fix with simple assignment statements
    and if-then-else rules:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的错误大多数都可以通过简单的赋值语句和if-then-else规则轻松修复：
- en: '[PRE0]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Redundant whitespace
  id: totrans-109
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 空白字符重复
- en: 'Whitespaces tend to be hard to detect but cause errors like other redundant
    characters would. Who hasn’t lost a few days in a project because of a bug that
    was caused by whitespaces at the end of a string? You ask the program to join
    two keys and notice that observations are missing from the output file. After
    looking for days through the code, you finally find the bug. Then comes the hardest
    part: explaining the delay to the project stakeholders. The cleaning during the
    ETL phase wasn’t well executed, and keys in one table contained a whitespace at
    the end of a string. This caused a mismatch of keys such as “FR” – “FR”, dropping
    the observations that couldn’t be matched.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 空白字符往往难以检测，但会导致与其他冗余字符一样的问题。谁没有因为字符串末尾的空白字符而丢失几天项目时间呢？你要求程序合并两个键，却发现输出文件中缺少了一些观察值。经过几天在代码中寻找，你终于找到了错误。然后是最难的部分：向项目利益相关者解释延迟。ETL阶段的清理没有很好地执行，一个表中的键在字符串末尾包含了一个空白字符。这导致了“FR”
    – “FR”这样的键不匹配，丢弃了无法匹配的观察值。
- en: If you know to watch out for them, fixing redundant whitespaces is luckily easy
    enough in most programming languages. They all provide string functions that will
    remove the leading and trailing whitespaces. For instance, in Python you can use
    the `strip()` function to remove leading and trailing spaces.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你知道要留意它们，修复多余的空白符在大多数编程语言中都很幸运地足够简单。它们都提供了字符串函数，可以删除前导和尾随空白。例如，在Python中，你可以使用`strip()`函数来删除前导和尾随空格。
- en: '|  |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Fixing capital letter mismatches
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 修复大写字母不匹配问题
- en: Capital letter mismatches are common. Most programming languages make a distinction
    between “Brazil” and “brazil”. In this case you can solve the problem by applying
    a function that returns both strings in lowercase, such as `.lower()` in Python.
    `"Brazil".lower() == "brazil".lower()` should result in `true`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 大写字母不匹配很常见。大多数编程语言在“巴西”和“brazil”之间做出区分。在这种情况下，你可以通过应用一个返回两个字符串都为小写的函数来解决问题，例如Python中的`.lower()`。`"Brazil".lower()
    == "brazil".lower()`应该返回`true`。
- en: '|  |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Impossible values and sanity checks
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 不可能的值和合理性检查
- en: 'Sanity checks are another valuable type of data check. Here you check the value
    against physically or theoretically impossible values such as people taller than
    3 meters or someone with an age of 299 years. Sanity checks can be directly expressed
    with rules:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 合理性检查是另一种有价值的数据检查类型。在这里，你检查值是否与物理上或理论上不可能的值相匹配，例如身高超过3米的人或年龄为299岁的人。合理性检查可以直接用规则表示：
- en: '[PRE1]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Outliers
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 异常值
- en: An outlier is an observation that seems to be distant from other observations
    or, more specifically, one observation that follows a different logic or generative
    process than the other observations. The easiest way to find outliers is to use
    a plot or a table with the minimum and maximum values. An example is shown in
    [figure 2.6](#ch02fig06).
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值是一个似乎与其他观察值距离较远的观察值，或者更具体地说，是一个遵循与其他观察值不同的逻辑或生成过程的观察值。找到异常值的最简单方法是使用包含最小值和最大值的图表或表格。一个例子显示在[图2.6](#ch02fig06)中。
- en: Figure 2.6\. Distribution plots are helpful in detecting outliers and helping
    you understand the variable.
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.6\. 分布图有助于检测异常值并帮助你理解变量。
- en: '![](Images/02fig06_alt.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig06_alt.jpg)'
- en: The plot on the top shows no outliers, whereas the plot on the bottom shows
    possible outliers on the upper side when a normal distribution is expected. The
    normal distribution, or Gaussian distribution, is the most common distribution
    in natural sciences. It shows most cases occurring around the average of the distribution
    and the occurrences decrease when further away from it. The high values in the
    bottom graph can point to outliers when assuming a normal distribution. As we
    saw earlier with the regression example, outliers can gravely influence your data
    modeling, so investigate them first.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 顶部的图表显示没有异常值，而底部的图表显示在期望正态分布时，上侧可能存在异常值。正态分布，或高斯分布，是自然科学中最常见的分布。它表明大多数情况发生在分布的平均值附近，并且当距离平均值更远时，发生频率会降低。底部图表中的高值在假设正态分布时可能指向异常值。正如我们之前在回归示例中看到的，异常值可能会严重影响你的数据建模，因此首先要调查它们。
- en: Dealing with missing values
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: Missing values aren’t necessarily wrong, but you still need to handle them separately;
    certain modeling techniques can’t handle missing values. They might be an indicator
    that something went wrong in your data collection or that an error happened in
    the ETL process. Common techniques data scientists use are listed in [table 2.4](#ch02table04).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失值不一定错误，但你仍然需要单独处理它们；某些建模技术无法处理缺失值。它们可能是数据收集过程中出现问题或ETL过程中发生错误的指标。数据科学家常用的常见技术列在[表2.4](#ch02table04)中。
- en: Table 2.4\. An overview of techniques to handle missing data
  id: totrans-126
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表2.4\. 处理缺失数据的技术概述
- en: '| Technique | Advantage | Disadvantage |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 技术 | 优点 | 缺点 |'
- en: '| --- | --- | --- |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Omit the values | Easy to perform | You lose the information from an observation
    |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 忽略值 | 易于执行 | 你会丢失观察值的信息 |'
- en: '| Set value to null | Easy to perform | Not every modeling technique and/or
    implementation can handle null values |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 将值设置为null | 易于执行 | 并非每个建模技术/实现都可以处理null值 |'
- en: '| Impute a static value such as 0 or the mean | Easy to perform You don’t lose
    information from the other variables in the observation | Can lead to false estimations
    from a model |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 填充静态值，如0或平均值 | 易于执行 你不会从观察到的其他变量中丢失信息 | 可能会导致模型产生错误的估计 |'
- en: '| Impute a value from an estimated or theoretical distribution | Does not disturb
    the model as much | Harder to execute You make data assumptions |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 从估计或理论分布中插入一个值 | 不会太多地干扰模型 | 执行起来更困难 | 您做出数据假设 |'
- en: '| Modeling the value (nondependent) | Does not disturb the model too much |
    Can lead to too much confidence in the model Can artificially raise dependence
    among the variables Harder to execute You make data assumptions |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 建模值（非相关） | 不会太多地干扰模型 | 可能会导致对模型过度自信 | 可能人为地提高变量之间的依赖性 | 执行起来更困难 | 您做出数据假设
    |'
- en: 'Which technique to use at what time is dependent on your particular case. If,
    for instance, you don’t have observations to spare, omitting an observation is
    probably not an option. If the variable can be described by a stable distribution,
    you could impute based on this. However, maybe a missing value actually means
    “zero”? This can be the case in sales for instance: if no promotion is applied
    on a customer basket, that customer’s promo is missing, but most likely it’s also
    0, no price cut.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 何时使用哪种技术取决于您的具体情况。例如，如果您没有多余的观测值，省略观测值可能不是一个选择。如果变量可以用稳定的分布来描述，您可以根据这一点进行插补。然而，缺失值实际上可能意味着“零”？这在销售中可能是这种情况：如果没有促销应用于客户篮子，该客户的促销信息缺失，但很可能它也是0，没有价格折扣。
- en: Deviations from a code book
  id: totrans-135
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 与代码簿的偏差
- en: 'Detecting errors in larger data sets against a code book or against standardized
    values can be done with the help of set operations. A code book is a description
    of your data, a form of metadata. It contains things such as the number of variables
    per observation, the number of observations, and what each encoding within a variable
    means. (For instance “0” equals “negative”, “5” stands for “very positive”.) A
    code book also tells the type of data you’re looking at: is it hierarchical, graph,
    something else?'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 通过代码簿或标准值来检测较大数据集中的错误可以使用集合操作来完成。代码簿是您数据的描述，是一种元数据。它包含诸如每个观测值的变量数量、观测值的数量以及变量中每种编码的含义等信息。（例如，“0”等于“负”，“5”表示“非常积极”）。代码簿还说明了您正在查看的数据类型：它是层次结构、图还是其他类型？
- en: You look at those values that are present in set A but not in set B. These are
    values that should be corrected. It’s no coincidence that *sets* are the data
    structure that we’ll use when we’re working in code. It’s a good habit to give
    your data structures additional thought; it can save work and improve the performance
    of your program.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您查看那些存在于集合A中但不在集合B中的值。这些是需要纠正的值。*集合*是我们工作时使用的数据结构，这并非巧合。仔细考虑您的数据结构是一个好习惯；它可以节省工作并提高程序的性能。
- en: If you have multiple values to check, it’s better to put them from the code
    book into a table and use a difference operator to check the discrepancy between
    both tables. This way, you can profit from the power of a database directly. More
    on this in [chapter 5](kindle_split_013.xhtml#ch05).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您要检查多个值，最好将它们从代码簿放入表格中，并使用差异运算符来检查两个表格之间的差异。这样，您可以直接利用数据库的力量。更多关于这一点的内容请参阅[第5章](kindle_split_013.xhtml#ch05)。
- en: Different units of measurement
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 不同的测量单位
- en: When integrating two data sets, you have to pay attention to their respective
    units of measurement. An example of this would be when you study the prices of
    gasoline in the world. To do this you gather data from different data providers.
    Data sets can contain prices per gallon and others can contain prices per liter.
    A simple conversion will do the trick in this case.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当整合两个数据集时，您必须注意它们各自的测量单位。一个例子是研究世界各地的汽油价格。为此，您需要从不同的数据提供者那里收集数据。数据集可以包含每加仑的价格，而其他数据集可以包含每升的价格。在这种情况下，简单的转换就可以解决问题。
- en: Different levels of aggregation
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 不同的聚合级别
- en: Having different levels of aggregation is similar to having different types
    of measurement. An example of this would be a data set containing data per week
    versus one containing data per work week. This type of error is generally easy
    to detect, and *summarizing* (or the inverse, *expanding*) the data sets will
    fix it.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有不同的聚合级别类似于拥有不同的测量类型。一个例子是包含每周数据的数据集与包含工作周数据的数据集。这类错误通常很容易检测到，通过*总结*（或其逆操作，*展开*）数据集可以修复它。
- en: After cleaning the data errors, you combine information from different data
    sources. But before we tackle this topic we’ll take a little detour and stress
    the importance of cleaning data as early as possible.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在清理数据错误后，您会结合来自不同数据源的信息。但在我们探讨这个主题之前，我们将稍微偏离一下，强调尽早清理数据的重要性。
- en: 2.4.2\. Correct errors as early as possible
  id: totrans-144
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.2. 尽早纠正错误
- en: A good practice is to mediate data errors as early as possible in the data collection
    chain and to fix as little as possible inside your program while fixing the origin
    of the problem. Retrieving data is a difficult task, and organizations spend millions
    of dollars on it in the hope of making better decisions. The data collection process
    is error-prone, and in a big organization it involves many steps and teams.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的做法是在数据收集链中尽早调解数据错误，并在尽可能少地在你程序内部修复问题的源头的同时修复问题。检索数据是一项困难的任务，组织在它上面花费数百万美元，希望做出更好的决策。数据收集过程容易出错，在一个大组织中，它涉及许多步骤和团队。
- en: 'Data should be cleansed when acquired for many reasons:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 数据应在获取时进行清理，原因有很多：
- en: Not everyone spots the data anomalies. Decision-makers may make costly mistakes
    on information based on incorrect data from applications that fail to correct
    for the faulty data.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非每个人都能发现数据异常。决策者可能会基于未能纠正错误数据的应用程序提供的不正确数据做出代价高昂的错误决策。
- en: If errors are not corrected early on in the process, the cleansing will have
    to be done for every project that uses that data.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果在流程的早期没有纠正错误，那么每个使用该数据的项目的清理工作都必须进行。
- en: Data errors may point to a business process that isn’t working as designed.
    For instance, both authors worked at a retailer in the past, and they designed
    a couponing system to attract more people and make a higher profit. During a data
    science project, we discovered clients who abused the couponing system and earned
    money while purchasing groceries. The goal of the couponing system was to stimulate
    cross-selling, not to give products away for free. This flaw cost the company
    money and nobody in the company was aware of it. In this case the data wasn’t
    technically wrong but came with unexpected results.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据错误可能指向一个不符合设计的工作流程。例如，两位作者过去都在一家零售商工作，他们设计了一个优惠券系统来吸引更多人并创造更高的利润。在数据科学项目中，我们发现客户滥用优惠券系统并在购买杂货时赚钱。优惠券系统的目标是刺激交叉销售，而不是免费赠送产品。这个缺陷使公司损失了金钱，公司里没有人意识到这一点。在这种情况下，数据在技术上并没有错误，但带来了意外的结果。
- en: Data errors may point to defective equipment, such as broken transmission lines
    and defective sensors.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据错误可能指向设备故障，例如损坏的传输线和有缺陷的传感器。
- en: Data errors can point to bugs in software or in the integration of software
    that may be critical to the company. While doing a small project at a bank we
    discovered that two software applications used different local settings. This
    caused problems with numbers greater than 1,000\. For one app the number 1.000
    meant one, and for the other it meant one thousand.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据错误可能指向软件或软件集成中的错误，这些错误可能对公司至关重要。在我们为一家银行做一个小项目时，我们发现两个软件应用程序使用了不同的本地设置。这导致大于1,000的数字出现问题。对于一款应用程序，数字1.000代表一个，而对于另一款则代表一千。
- en: Fixing the data as soon as it’s captured is nice in a perfect world. Sadly,
    a data scientist doesn’t always have a say in the data collection and simply telling
    the IT department to fix certain things may not make it so. If you can’t correct
    the data at the source, you’ll need to handle it inside your code. Data manipulation
    doesn’t end with correcting mistakes; you still need to combine your incoming
    data.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在理想世界中，一旦数据被捕获就修复数据是很好的。遗憾的是，数据科学家并不总是对数据收集有发言权，仅仅告诉IT部门修复某些事情可能并不会让它变得如此。如果你不能在源头纠正数据，你需要在你的代码中处理它。数据操作并不随着纠正错误而结束；你仍然需要组合你的
    incoming data。
- en: 'As a final remark: always keep a copy of your original data (if possible).
    Sometimes you start cleaning data but you’ll make mistakes: impute variables in
    the wrong way, delete outliers that had interesting additional information, or
    alter data as the result of an initial misinterpretation. If you keep a copy you
    get to try again. For “flowing data” that’s manipulated at the time of arrival,
    this isn’t always possible and you’ll have accepted a period of tweaking before
    you get to use the data you are capturing. One of the more difficult things isn’t
    the data cleansing of individual data sets however, it’s combining different sources
    into a whole that makes more sense.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点：始终保留原始数据的副本（如果可能的话）。有时你开始清理数据，但会犯错误：以错误的方式估计变量，删除具有有趣额外信息的异常值，或者由于最初的误解而更改数据。如果你保留副本，你就有机会再次尝试。对于在到达时被操作的“流动数据”，这并不总是可能的，你将不得不在能够使用你捕获的数据之前接受一段时间的调整。然而，更困难的事情并不是单个数据集的数据清理，而是将不同的来源组合成一个更有意义的整体。
- en: 2.4.3\. Combining data from different data sources
  id: totrans-154
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.3\. 从不同的数据源组合数据
- en: Your data comes from several different places, and in this substep we focus
    on integrating these different sources. Data varies in size, type, and structure,
    ranging from databases and Excel files to text documents.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数据来自几个不同的地方，在这个子步骤中，我们专注于整合这些不同的来源。数据在大小、类型和结构上有所不同，从数据库和Excel文件到文本文档都有。
- en: We focus on data in table structures in this chapter for the sake of brevity.
    It’s easy to fill entire books on this topic alone, and we choose to focus on
    the data science process instead of presenting scenarios for every type of data.
    But keep in mind that other types of data sources exist, such as key-value stores,
    document stores, and so on, which we’ll handle in more appropriate places in the
    book.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，本章我们专注于表格结构中的数据。仅就这个主题而言，完全可以写满整本书，而我们选择专注于数据科学过程，而不是为每种类型的数据提供场景。但请记住，还存在其他类型的数据源，例如键值存储、文档存储等，我们将在书中更合适的地方处理这些内容。
- en: The different ways of combining data
  id: totrans-157
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 组合数据的不同方式
- en: 'You can perform two operations to combine information from different data sets.
    The first operation is *joining*: enriching an observation from one table with
    information from another table. The second operation is *appending* or *stacking*:
    adding the observations of one table to those of another table.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以执行两个操作来合并来自不同数据集的信息。第一个操作是*连接*：用一个表中的信息丰富另一个表中的观察结果。第二个操作是*追加*或*堆叠*：将一个表中的观察结果添加到另一个表中。
- en: When you combine data, you have the option to create a new physical table or
    a virtual table by creating a view. The advantage of a view is that it doesn’t
    consume more disk space. Let’s elaborate a bit on these methods.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当你合并数据时，你可以选择通过创建视图来创建一个新的物理表或虚拟表。视图的优势是它不会消耗更多的磁盘空间。让我们详细说明这些方法。
- en: Joining tables
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 连接表格
- en: Joining tables allows you to combine the information of one observation found
    in one table with the information that you find in another table. The focus is
    on enriching a single observation. Let’s say that the first table contains information
    about the purchases of a customer and the other table contains information about
    the region where your customer lives. Joining the tables allows you to combine
    the information so that you can use it for your model, as shown in [figure 2.7](#ch02fig07).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 连接表格允许你将一个表中找到的观察结果的信息与另一个表中找到的信息结合起来。重点是丰富单个观察结果。比如说，第一个表包含有关客户购买的信息，而另一个表包含有关客户居住区域的信
- en: Figure 2.7\. Joining two tables on the Item and Region keys
  id: totrans-162
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.7\. 在项目键和区域键上连接两个表格
- en: '![](Images/02fig07.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig07.jpg)'
- en: To join tables, you use variables that represent the same object in both tables,
    such as a date, a country name, or a Social Security number. These common fields
    are known as keys. When these keys also uniquely define the records in the table
    they are called *primary keys*. One table may have buying behavior and the other
    table may have demographic information on a person. In [figure 2.7](#ch02fig07)
    both tables contain the client name, and this makes it easy to enrich the client
    expenditures with the region of the client. People who are acquainted with Excel
    will notice the similarity with using a lookup function.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要连接表格，你使用代表两个表中相同对象的变量，例如日期、国家名称或社会保障号码。这些公共字段被称为键。当这些键也唯一地定义表中的记录时，它们被称为*主键*。一个表可能包含购买行为，而另一个表可能包含关于个人的人口统计信息。在[图2.7](#ch02fig07)中，两个表都包含客户名称，这使得丰富客户支出与客户所在的区域变得容易。熟悉Excel的人会注意到这与使用查找函数的相似性。
- en: The number of resulting rows in the output table depends on the exact join type
    that you use. We introduce the different types of joins later in the book.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 输出表中结果的行数取决于你使用的确切连接类型。我们将在本书的后面部分介绍不同类型的连接。
- en: Appending tables
  id: totrans-166
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 添加表格
- en: Appending or stacking tables is effectively adding observations from one table
    to another table. [Figure 2.8](#ch02fig08) shows an example of appending tables.
    One table contains the observations from the month January and the second table
    contains observations from the month February. The result of appending these tables
    is a larger one with the observations from January as well as February. The equivalent
    operation in set theory would be the union, and this is also the command in SQL,
    the common language of relational databases. Other set operators are also used
    in data science, such as set difference and intersection.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 附加或堆叠表实际上是向另一个表中添加一个表中的观测值。[图 2.8](#ch02fig08) 展示了附加表的例子。一个表包含一月份的观测值，第二个表包含二月份的观测值。这些表附加的结果是一个更大的表，包含一月份和二月份的观测值。在集合论中，这相当于并集操作，这也是关系数据库的通用语言
    SQL 中的命令。在数据科学中，也使用了其他集合运算符，如集合差和交集。
- en: Figure 2.8\. Appending data from tables is a common operation but requires an
    equal structure in the tables being appended.
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.8\. 从表中附加数据是一个常见的操作，但需要附加的表具有相同的结构。
- en: '![](Images/02fig08_alt.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig08_alt.jpg)'
- en: Using views to simulate data joins and appends
  id: totrans-170
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用视图模拟数据连接和附加
- en: To avoid duplication of data, you virtually combine data with views. In the
    previous example we took the monthly data and combined it in a new physical table.
    The problem is that we duplicated the data and therefore needed more storage space.
    In the example we’re working with, that may not cause problems, but imagine that
    every table consists of terabytes of data; then it becomes problematic to duplicate
    the data. For this reason, the concept of a view was invented. A view behaves
    as if you’re working on a table, but this table is nothing but a virtual layer
    that combines the tables for you. [Figure 2.9](#ch02fig09) shows how the sales
    data from the different months is combined virtually into a yearly sales table
    instead of duplicating the data. Views do come with a drawback, however. While
    a table join is only performed once, the join that creates the view is recreated
    every time it’s queried, using more processing power than a pre-calculated table
    would have.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免数据重复，你实际上是通过视图来组合数据的。在先前的例子中，我们取了月度数据并在一个新的物理表中将其组合。问题是，我们重复了数据，因此需要更多的存储空间。在我们正在处理的例子中，这可能不会造成问题，但想象一下，每个表都包含数以兆字节的数据；那么重复数据就变得有问题了。因此，发明了视图的概念。视图表现得就像你在操作一个表一样，但这个表实际上只是一个为你组合表的虚拟层。[图
    2.9](#ch02fig09) 展示了如何将不同月份的销售数据虚拟组合成年度销售表，而不是重复数据。然而，视图也有缺点。虽然表连接只执行一次，但创建视图的连接每次查询时都会被重新创建，这比预先计算的表需要更多的处理能力。
- en: Figure 2.9\. A view helps you combine data without replication.
  id: totrans-172
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.9\. 视图帮助您在不复制数据的情况下组合数据。
- en: '![](Images/02fig09_alt.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig09_alt.jpg)'
- en: Enriching aggregated measures
  id: totrans-174
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 丰富聚合度量
- en: Data enrichment can also be done by adding calculated information to the table,
    such as the total number of sales or what percentage of total stock has been sold
    in a certain region ([figure 2.10](#ch02fig10)).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 通过向表中添加计算信息也可以进行数据丰富，例如总销售额或某个地区已售出总库存的百分比（[图 2.10](#ch02fig10)）。
- en: Figure 2.10\. Growth, sales by product class, and rank sales are examples of
    derived and aggregate measures.
  id: totrans-176
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.10\. 增长、按产品类别划分的销售和排名销售是派生和聚合度量的例子。
- en: '| Product class | Product | Sales in $ | Sales t-1 in $ | Growth | Sales by
    product class | Rank sales |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 产品类别 | 产品 | 销售额（$） | 上月销售额（$） | 增长 | 按产品类别划分的销售 | 排名销售 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| A | B | X | Y | (X-Y) / Y | AX | NX |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| A | B | X | Y | (X-Y) / Y | AX | NX |'
- en: '| Sport | Sport 1 | 95 | 98 | –3.06% | 215 | 2 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 运动 | 运动 1 | 95 | 98 | –3.06% | 215 | 2 |'
- en: '| Sport | Sport 2 | 120 | 132 | –9.09% | 215 | 1 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 运动 | 运动 2 | 120 | 132 | –9.09% | 215 | 1 |'
- en: '| Shoes | Shoes 1 | 10 | 6 | 66.67% | 10 | 3 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 鞋类 | 鞋类 1 | 10 | 6 | 66.67% | 10 | 3 |'
- en: Extra measures such as these can add perspective. Looking at [figure 2.10](#ch02fig10),
    we now have an aggregated data set, which in turn can be used to calculate the
    participation of each product within its category. This could be useful during
    data exploration but more so when creating data models. As always this depends
    on the exact case, but from our experience models with “relative measures” such
    as % sales (quantity of product sold/total quantity sold) tend to outperform models
    that use the raw numbers (quantity sold) as input.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 类似这样的额外措施可以提供新的视角。查看[图2.10](#ch02fig10)，我们现在有一个汇总的数据集，这反过来可以用来计算每个产品在其类别中的参与度。这在数据探索期间可能很有用，但在创建数据模型时更有用。像往常一样，这取决于具体案例，但根据我们的经验，使用“相对度量”如%销售额（产品销售数量/总销售数量）的模型往往优于使用原始数字（销售数量）作为输入的模型。
- en: 2.4.4\. Transforming data
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.4.4\. 数据转换
- en: 'Certain models require their data to be in a certain shape. Now that you’ve
    cleansed and integrated the data, this is the next task you’ll perform: transforming
    your data so it takes a suitable form for data modeling.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 某些模型需要其数据具有特定的形状。现在你已经清理并整合了数据，这是你接下来要执行的任务：将你的数据转换成适合数据建模的合适形式。
- en: Transforming data
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据转换
- en: Relationships between an input variable and an output variable aren’t always
    linear. Take, for instance, a relationship of the form *y* = *ae^(bx)*. Taking
    the log of the independent variables simplifies the estimation problem dramatically.
    [Figure 2.11](#ch02fig11) shows how transforming the input variables greatly simplifies
    the estimation problem. Other times you might want to combine two variables into
    a new variable.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 输入变量和输出变量之间的关系并不总是线性的。以形式 *y* = *ae^(bx)* 的关系为例。对独立变量取对数可以极大地简化估计问题。[图2.11](#ch02fig11)展示了如何通过转换输入变量来极大地简化估计问题。有时你可能想将两个变量合并成一个新的变量。
- en: Figure 2.11\. Transforming x to log x makes the relationship between x and y
    linear (right), compared with the non-log x (left).
  id: totrans-188
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.11\. 将x转换为log x使x和y之间的关系线性化（右），与未取对数的x（左）相比。
- en: '![](Images/02fig11_alt.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![替代图2.11](Images/02fig11_alt.jpg)'
- en: Reducing the number of variables
  id: totrans-190
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 减少变量数量
- en: Sometimes you have too many variables and need to reduce the number because
    they don’t add new information to the model. Having too many variables in your
    model makes the model difficult to handle, and certain techniques don’t perform
    well when you overload them with too many input variables. For instance, all the
    techniques based on a Euclidean distance perform well only up to 10 variables.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候你有很多变量，需要减少数量，因为它们不会向模型添加新信息。模型中变量过多会使模型难以处理，并且当输入变量过多时，某些技术表现不佳。例如，所有基于欧几里得距离的技术在变量数量不超过10个时表现良好。
- en: '|  |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Euclidean distance**'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**欧几里得距离**'
- en: 'Euclidean distance or “ordinary” distance is an extension to one of the first
    things anyone learns in mathematics about triangles (trigonometry): Pythagoras’s
    leg theorem. If you know the length of the two sides next to the 90° angle of
    a right-angled triangle you can easily derive the length of the remaining side
    (hypotenuse). The formula for this is hypotenuse = ![](Images/041equ01.jpg). The
    Euclidean distance between two points in a two-dimensional plane is calculated
    using a similar formula: distance = ![](Images/041equ02.jpg). If you want to expand
    this distance calculation to more dimensions, add the coordinates of the point
    within those higher dimensions to the formula. For three dimensions we get distance
    = ![](Images/041equ03.jpg).'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离或“普通”距离是对数学中关于三角形（三角学）的第一件事的扩展：毕达哥拉斯定理。如果你知道直角三角形中90°角相邻两边的长度，你可以轻松地推导出剩余边的长度（斜边）。这个公式是斜边
    = ![公式](Images/041equ01.jpg)。在二维平面上的两点之间的欧几里得距离是使用类似公式计算的：距离 = ![公式](Images/041equ02.jpg)。如果你想将这个距离计算扩展到更多维度，将那些更高维度中点的坐标加到公式中。对于三维，我们得到距离
    = ![公式](Images/041equ03.jpg)。
- en: '|  |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Data scientists use special methods to reduce the number of variables but retain
    the maximum amount of data. We’ll discuss several of these methods in [chapter
    3](kindle_split_011.xhtml#ch03). [Figure 2.12](#ch02fig12) shows how reducing
    the number of variables makes it easier to understand the key values. It also
    shows how two variables account for 50.6% of the variation within the data set
    (component1 = 27.8% + component2 = 22.8%). These variables, called “component1”
    and “component2,” are both combinations of the original variables. They’re the
    *principal components* of the underlying data structure. If it isn’t all that
    clear at this point, don’t worry, principal components analysis (PCA) will be
    explained more thoroughly in [chapter 3](kindle_split_011.xhtml#ch03). What you
    can also see is the presence of a third (unknown) variable that splits the group
    of observations into two.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家使用特殊方法来减少变量的数量，但保留最大量的数据。我们将在[第3章](kindle_split_011.xhtml#ch03)中讨论这些方法中的几个。[图2.12](#ch02fig12)展示了减少变量数量如何使理解关键值更容易。它还展示了两个变量如何解释数据集中50.6%的变异（component1
    = 27.8% + component2 = 22.8%）。这些变量被称为“component1”和“component2”，都是原始变量的组合。它们是数据结构的基础的*主成分*。如果现在还不那么清楚，不要担心，主成分分析（PCA）将在[第3章](kindle_split_011.xhtml#ch03)中更详细地解释。你还可以看到第三个（未知）变量的存在，它将观察结果分组分成两个。
- en: Figure 2.12\. Variable reduction allows you to reduce the number of variables
    while maintaining as much information as possible.
  id: totrans-197
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.12\. 变量减少可以在尽可能多的信息的情况下减少变量的数量。
- en: '![](Images/02fig12_alt.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig12_alt.jpg)'
- en: Turning variables into dummies
  id: totrans-199
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 将变量转换为虚拟变量
- en: 'Variables can be turned into dummy variables ([figure 2.13](#ch02fig13)). *Dummy
    variables* can only take two values: true(1) or false(0). They’re used to indicate
    the absence of a categorical effect that may explain the observation. In this
    case you’ll make separate columns for the classes stored in one variable and indicate
    it with 1 if the class is present and 0 otherwise. An example is turning one column
    named Weekdays into the columns Monday through Sunday. You use an indicator to
    show if the observation was on a Monday; you put 1 on Monday and 0 elsewhere.
    Turning variables into dummies is a technique that’s used in modeling and is popular
    with, but not exclusive to, economists.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 变量可以被转换为虚拟变量（[图2.13](#ch02fig13)）。*虚拟变量*只能取两个值：真（1）或假（0）。它们用于表示可能解释观察结果的分类效应的缺失。在这种情况下，你将为存储在一个变量中的类别创建单独的列，如果该类别存在，则用1表示，否则用0表示。一个例子是将一个名为“工作日”的列转换为从星期一到星期日的列。你使用一个指标来显示观察结果是否在星期一；你在星期一上放置1，在其他地方放置0。将变量转换为虚拟变量是一种在建模中使用的技巧，它受到经济学家的欢迎，但并非仅限于经济学家。
- en: 'Figure 2.13\. Turning variables into dummies is a data transformation that
    breaks a variable that has multiple classes into multiple variables, each having
    only two possible values: 0 or 1.'
  id: totrans-201
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.13\. 将变量转换为虚拟变量是一种数据转换，它将具有多个类别的变量分解成多个变量，每个变量只有两种可能的值：0或1。
- en: '![](Images/02fig13.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig13.jpg)'
- en: In this section we introduced the third step in the data science process—cleaning,
    transforming, and integrating data—which changes your raw data into usable input
    for the modeling phase. The next step in the data science process is to get a
    better understanding of the content of the data and the relationships between
    the variables and observations; we explore this in the next section.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了数据科学过程中的第三步——清理、转换和整合数据，这将您的原始数据转换为建模阶段的可用输入。数据科学过程的下一步是更好地理解数据的内容以及变量和观察结果之间的关系；我们将在下一节中探讨这一点。
- en: '2.5\. Step 4: Exploratory data analysis'
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5\. 第4步：探索性数据分析
- en: During exploratory data analysis you take a deep dive into the data (see [figure
    2.14](#ch02fig14)). Information becomes much easier to grasp when shown in a picture,
    therefore you mainly use graphical techniques to gain an understanding of your
    data and the interactions between variables. This phase is about exploring data,
    so keeping your mind open and your eyes peeled is essential during the exploratory
    data analysis phase. The goal isn’t to cleanse the data, but it’s common that
    you’ll still discover anomalies you missed before, forcing you to take a step
    back and fix them.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索性数据分析过程中，你将深入挖掘数据（见图2.14）。当信息以图片形式展示时，信息变得更容易理解，因此你主要使用图形技术来了解你的数据和变量之间的相互作用。这一阶段是关于探索数据，所以在探索性数据分析阶段保持开放的心态和敏锐的观察力是至关重要的。目标不是清理数据，但通常你仍然会发现之前遗漏的异常，迫使你退一步并修复它们。
- en: 'Figure 2.14\. Step 4: Data exploration'
  id: totrans-206
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.14。步骤4：数据探索
- en: '![](Images/02fig14.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig14.jpg)'
- en: The visualization techniques you use in this phase range from simple line graphs
    or histograms, as shown in [figure 2.15](#ch02fig15), to more complex diagrams
    such as Sankey and network graphs. Sometimes it’s useful to compose a composite
    graph from simple graphs to get even more insight into the data. Other times the
    graphs can be animated or made interactive to make it easier and, let’s admit
    it, way more fun. An example of an interactive Sankey diagram can be found at
    [http://bost.ocks.org/mike/sankey/](http://bost.ocks.org/mike/sankey/).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一阶段，你使用的可视化技术从简单的折线图或直方图，如图2.15所示，到更复杂的图表，如桑基图和网络图。有时，从简单的图表中组合成复合图，可以更深入地了解数据。有时，图表可以动画化或交互化，使其更容易，让我们承认，更有趣。一个交互式桑基图的例子可以在[http://bost.ocks.org/mike/sankey/](http://bost.ocks.org/mike/sankey/)找到。
- en: Figure 2.15\. From top to bottom, a bar chart, a line plot, and a distribution
    are some of the graphs used in exploratory analysis.
  id: totrans-209
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.15。从上到下，柱状图、折线图和分布图是探索性分析中使用的一些图表。
- en: '![](Images/02fig15.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig15.jpg)'
- en: Mike Bostock has interactive examples of almost any type of graph. It’s worth
    spending time on his website, though most of his examples are more useful for
    data presentation than data exploration.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Mike Bostock提供了几乎所有类型图表的交互式示例。尽管他的大多数示例在数据展示方面更有用，但花时间在他的网站上还是值得的。
- en: These plots can be combined to provide even more insight, as shown in [figure
    2.16](#ch02fig16).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图表可以组合起来提供更多的见解，如图2.16所示。
- en: Figure 2.16\. Drawing multiple plots together can help you understand the structure
    of your data over multiple variables.
  id: totrans-213
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.16。将多个图表一起绘制可以帮助你理解多个变量中的数据结构。
- en: '![](Images/02fig16_alt.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig16_alt.jpg)'
- en: Overlaying several plots is common practice. In [figure 2.17](#ch02fig17) we
    combine simple graphs into a Pareto diagram, or 80-20 diagram.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个图表上叠加是常见的做法。在[图2.17](#ch02fig17)中，我们将简单的图表组合成帕累托图，或80-20图。
- en: Figure 2.17\. A Pareto diagram is a combination of the values and a cumulative
    distribution. It’s easy to see from this diagram that the first 50% of the countries
    contain slightly less than 80% of the total amount. If this graph represented
    customer buying power and we sell expensive products, we probably don’t need to
    spend our marketing budget in every country; we could start with the first 50%.
  id: totrans-216
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.17。帕累托图是值和累积分布的组合。从这个图中很容易看出，前50%的国家包含略少于80%的总金额。如果这个图代表了客户的购买力，而我们销售昂贵的产品，我们可能不需要在每个国家花费我们的营销预算；我们可以从前50%开始。
- en: '![](Images/02fig17_alt.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig17_alt.jpg)'
- en: '[Figure 2.18](#ch02fig18) shows another technique: *brushing and linking*.
    With brushing and linking you combine and link different graphs and tables (or
    views) so changes in one graph are automatically transferred to the other graphs.
    An elaborate example of this can be found in [chapter 9](kindle_split_017.xhtml#ch09).
    This interactive exploration of data facilitates the discovery of new insights.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2.18](#ch02fig18)展示了另一种技术：*刷选和链接*。通过刷选和链接，你可以将不同的图表和表格（或视图）组合并链接起来，这样在一个图表中的变化会自动转移到其他图表。这种交互式数据探索有助于发现新的见解。一个详细的例子可以在[第9章](kindle_split_017.xhtml#ch09)中找到。这一阶段的数据探索有助于发现新的见解。'
- en: Figure 2.18\. Link and brush allows you to select observations in one plot and
    highlight the same observations in the other plots.
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.18。链接和刷选允许你在一张图上选择观测值，并在其他图上突出显示相同的观测值。
- en: '![](Images/02fig18_alt.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig18_alt.jpg)'
- en: '[Figure 2.18](#ch02fig18) shows the average score per country for questions.
    Not only does this indicate a high correlation between the answers, but it’s easy
    to see that when you select several points on a subplot, the points will correspond
    to similar points on the other graphs. In this case the selected points on the
    left graph correspond to points on the middle and right graphs, although they
    correspond better in the middle and right graphs.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2.18](#ch02fig18)显示了每个国家的问题的平均得分。这不仅表明了答案之间的高度相关性，而且很容易看出，当你选择子图的几个点时，这些点将对应于其他图表上相似的点。在这种情况下，左图上选定的点对应于中间和右图上的点，尽管它们在中间和右图上对应得更好。'
- en: Two other important graphs are the histogram shown in [figure 2.19](#ch02fig19)
    and the boxplot shown in [figure 2.20](#ch02fig20).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两个重要的图表是[图2.19](#ch02fig19)中显示的直方图和[图2.20](#ch02fig20)中显示的箱线图。
- en: 'Figure 2.19\. Example histogram: the number of people in the age-groups of
    5-year intervals'
  id: totrans-223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.19. 示例直方图：5年年龄间隔内的人数
- en: '![](Images/02fig19.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig19.jpg)'
- en: 'Figure 2.20\. Example boxplot: each user category has a distribution of the
    appreciation each has for a certain picture on a photography website.'
  id: totrans-225
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.20. 示例箱线图：每个用户类别在摄影网站上对某一图片的喜爱程度的分布。
- en: '![](Images/02fig20_alt.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig20_alt.jpg)'
- en: In a histogram a variable is cut into discrete categories and the number of
    occurrences in each category are summed up and shown in the graph. The boxplot,
    on the other hand, doesn’t show how many observations are present but does offer
    an impression of the distribution within categories. It can show the maximum,
    minimum, median, and other characterizing measures at the same time.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在直方图中，一个变量被划分为离散类别，每个类别中的发生次数被汇总并显示在图表中。另一方面，箱线图不显示有多少观测值，但它确实提供了类别内分布的印象。它可以同时显示最大值、最小值、中位数和其他特征度量。
- en: The techniques we described in this phase are mainly visual, but in practice
    they’re certainly not limited to visualization techniques. Tabulation, clustering,
    and other modeling techniques can also be a part of exploratory analysis. Even
    building simple models can be a part of this step.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本阶段描述的技巧主要是视觉的，但在实践中，它们当然不仅限于可视化技术。制表、聚类和其他建模技术也可以是探索性分析的一部分。甚至构建简单的模型也可以是这一步骤的一部分。
- en: 'Now that you’ve finished the data exploration phase and you’ve gained a good
    grasp of your data, it’s time to move on to the next phase: building models.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经完成了数据探索阶段，并且对数据有了很好的掌握，是时候进入下一个阶段：构建模型。
- en: '2.6\. Step 5: Build the models'
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.6. 步骤5：构建模型
- en: With clean data in place and a good understanding of the content, you’re ready
    to build models with the goal of making better predictions, classifying objects,
    or gaining an understanding of the system that you’re modeling. This phase is
    much more focused than the exploratory analysis step, because you know what you’re
    looking for and what you want the outcome to be. [Figure 2.21](#ch02fig21) shows
    the components of model building.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据清洁且对内容有良好理解的基础上，你准备好构建模型，目标是做出更好的预测、分类对象或理解你正在建模的系统。这一阶段比探索性分析步骤更加专注，因为你知道你在寻找什么，以及你希望的结果是什么。[图2.21](#ch02fig21)显示了模型构建的组成部分。
- en: 'Figure 2.21\. Step 5: Data modeling'
  id: totrans-232
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.21. 步骤5：数据建模
- en: '![](Images/02fig21.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig21.jpg)'
- en: The techniques you’ll use now are borrowed from the field of machine learning,
    data mining, and/or statistics. In this chapter we only explore the tip of the
    iceberg of existing techniques, while [chapter 3](kindle_split_011.xhtml#ch03)
    introduces them properly. It’s beyond the scope of this book to give you more
    than a conceptual introduction, but it’s enough to get you started; 20% of the
    techniques will help you in 80% of the cases because techniques overlap in what
    they try to accomplish. They often achieve their goals in similar but slightly
    different ways.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在将使用的技巧来自机器学习、数据挖掘和/或统计学领域。在本章中，我们只探索了现有技术的一小部分，而[第3章](kindle_split_011.xhtml#ch03)将适当地介绍它们。本书的范围超出了提供更多概念性介绍的范畴，但这对你的入门已经足够；20%的技术将帮助你解决80%的情况，因为技术之间存在重叠，它们试图实现的目标相似但略有不同。
- en: 'Building a model is an iterative process. The way you build your model depends
    on whether you go with classic statistics or the somewhat more recent machine
    learning school, and the type of technique you want to use. Either way, most models
    consist of the following main steps:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 建立模型是一个迭代的过程。你建立模型的方式取决于你是否选择经典统计学或相对较新的机器学习学派，以及你想要使用的技巧类型。无论如何，大多数模型都包括以下主要步骤：
- en: '**1**.  Selection of a modeling technique and variables to enter in the model'
  id: totrans-236
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**1**. 选择建模技巧和要进入模型中的变量'
- en: '**2**.  Execution of the model'
  id: totrans-237
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**2**. 执行模型'
- en: '**3**.  Diagnosis and model comparison'
  id: totrans-238
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**3**. 诊断和模型比较'
- en: 2.6.1\. Model and variable selection
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.6.1\. 模型和变量选择
- en: 'You’ll need to select the variables you want to include in your model and a
    modeling technique. Your findings from the exploratory analysis should already
    give a fair idea of what variables will help you construct a good model. Many
    modeling techniques are available, and choosing the right model for a problem
    requires judgment on your part. You’ll need to consider model performance and
    whether your project meets all the requirements to use your model, as well as
    other factors:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要选择你想要包含在模型中的变量和建模技巧。探索性分析的结果应该已经给你一个相当明确的想法，哪些变量将帮助你构建一个好的模型。有许多建模技巧可供选择，为问题选择正确的模型需要你自己的判断。你需要考虑模型性能以及你的项目是否满足使用模型的所有要求，以及其他因素：
- en: Must the model be moved to a production environment and, if so, would it be
    easy to implement?
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是否需要转移到生产环境，如果是的话，是否容易实现？
- en: 'How difficult is the maintenance on the model: how long will it remain relevant
    if left untouched?'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的维护有多困难：如果保持不变，它将保持多久的相关性？
- en: Does the model need to be easy to explain?
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是否需要易于解释？
- en: When the thinking is done, it’s time for action.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 当思考完成时，就是采取行动的时候了。
- en: 2.6.2\. Model execution
  id: totrans-245
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.6.2\. 模型执行
- en: Once you’ve chosen a model you’ll need to implement it in code.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你选择了一个模型，你将需要用代码实现它。
- en: '|  |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Remark
  id: totrans-248
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 备注
- en: This is the first time we’ll go into actual Python code execution so make sure
    you have a virtual env up and running. Knowing how to set this up is required
    knowledge, but if it’s your first time, check out [appendix D](kindle_split_021.xhtml#app04).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们第一次进入实际的Python代码执行，所以请确保你的虚拟环境已经启动并运行。了解如何设置这是必需的知识，但如果这是你第一次尝试，请查看[附录D](kindle_split_021.xhtml#app04)。
- en: All code from this chapter can be downloaded from [https://www.manning.com/books/introducing-data-science](https://www.manning.com/books/introducing-data-science).
    This chapter comes with an ipython (.ipynb) notebook and Python (.py) file.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码都可以从[https://www.manning.com/books/introducing-data-science](https://www.manning.com/books/introducing-data-science)下载。本章附带一个ipython
    (.ipynb) 笔记本和一个Python (.py) 文件。
- en: '|  |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Luckily, most programming languages, such as Python, already have libraries
    such as StatsModels or Scikit-learn. These packages use several of the most popular
    techniques. Coding a model is a nontrivial task in most cases, so having these
    libraries available can speed up the process. As you can see in the following
    code, it’s fairly easy to use linear regression ([figure 2.22](#ch02fig22)) with
    StatsModels or Scikit-learn. Doing this yourself would require much more effort
    even for the simple techniques. The following listing shows the execution of a
    linear prediction model.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，大多数编程语言，如Python，已经拥有StatsModels或Scikit-learn等库。这些包使用了多种最流行的技巧。在大多数情况下，编码一个模型是一个非平凡的任务，因此拥有这些库可以加快这个过程。正如以下代码所示，使用StatsModels或Scikit-learn进行线性回归（[图2.22](#ch02fig22)）相当容易。如果你自己来做，即使是简单的技巧也需要更多的努力。以下列表显示了线性预测模型的执行。
- en: Figure 2.22\. Linear regression tries to fit a line while minimizing the distance
    to each point
  id: totrans-253
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.22\. 线性回归试图拟合一条线，同时最小化到每个点的距离
- en: '![](Images/02fig22.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig22.jpg)'
- en: Listing 2.1\. Executing a linear prediction model on semi-random data
  id: totrans-255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.1\. 在半随机数据上执行线性预测模型
- en: '![](Images/049fig01_alt.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/049fig01_alt.jpg)'
- en: Okay, we cheated here, quite heavily so. We created predictor values that are
    meant to predict how the target variables behave. For a linear regression, a “linear
    relation” between each x (predictor) and the y (target) variable is assumed, as
    shown in [figure 2.22](#ch02fig22).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，我们在这里作弊了，相当严重。我们创建了预测值，目的是预测目标变量的行为。对于线性回归，假设每个x（预测变量）和y（目标变量）之间存在“线性关系”，如图2.22所示。
- en: We, however, created the target variable, based on the predictor by adding a
    bit of randomness. It shouldn’t come as a surprise that this gives us a well-fitting
    model. The `results.summary()` outputs the table in [figure 2.23](#ch02fig23).
    Mind you, the exact outcome depends on the random variables you got.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们，然而，通过添加一点随机性，基于预测变量创建了目标变量。这给我们一个拟合良好的模型并不令人惊讶。`results.summary()` 输出了 [图2.23](#ch02fig23)
    中的表格。请注意，确切的结果取决于你得到的随机变量。
- en: Figure 2.23\. Linear regression model information output
  id: totrans-259
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.23\. 线性回归模型信息输出
- en: '![](Images/02fig23_alt.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig23_alt.jpg)'
- en: 'Let’s ignore most of the output we got here and focus on the most important
    parts:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们忽略这里得到的输出的大部分内容，专注于最重要的部分：
- en: '***Model fit*** —For this the R-squared or adjusted R-squared is used. This
    measure is an indication of the amount of variation in the data that gets captured
    by the model. The difference between the adjusted R-squared and the R-squared
    is minimal here because the adjusted one is the normal one + a penalty for model
    complexity. A model gets complex when many variables (or features) are introduced.
    You don’t need a complex model if a simple model is available, so the adjusted
    R-squared punishes you for overcomplicating. At any rate, 0.893 is high, and it
    should be because we cheated. Rules of thumb exist, but for models in businesses,
    models above 0.85 are often considered good. If you want to win a competition
    you need in the high 90s. For research however, often very low model fits (<0.2
    even) are found. What’s more important there is the influence of the introduced
    predictor variables.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***模型拟合*** —这里使用 R 平方或调整 R 平方。这个指标是模型捕捉数据中变化量的一个指示。调整 R 平方和 R 平方之间的差异在这里是最小的，因为调整后的
    R 平方是正常的 R 平方加上对模型复杂性的惩罚。当引入许多变量（或特征）时，模型会变得复杂。如果你有一个简单的模型可用，你不需要复杂的模型，所以调整 R
    平方会惩罚你过度复杂化。无论如何，0.893 是很高的，这应该是由于我们作弊了。存在一些经验法则，但对于商业中的模型，通常认为 R 平方大于 0.85 的模型是好的。如果你想赢得比赛，你需要达到
    90% 以上。然而，对于研究来说，通常会发现模型拟合度非常低（甚至小于 0.2）。更重要的是，引入的预测变量对的影响。'
- en: '***Predictor variables have a coefficient*** —For a linear model this is easy
    to interpret. In our example if you add “1” to x1, it will change y by “0.7658”.
    It’s easy to see how finding a good predictor can be your route to a Nobel Prize
    even though your model as a whole is rubbish. If, for instance, you determine
    that a certain gene is significant as a cause for cancer, this is important knowledge,
    even if that gene in itself doesn’t determine whether a person will get cancer.
    The example here is classification, not regression, but the point remains the
    same: detecting influences is more important in scientific studies than perfectly
    fitting models (not to mention more realistic). But when do we know a gene has
    that impact? This is called significance.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***预测变量有一个系数*** —对于线性模型来说，这很容易解释。在我们的例子中，如果你给 x1 加上“1”，它将使 y 变化“0.7658”。很容易看出找到一个好的预测变量如何成为你获得诺贝尔奖的途径，即使你的整体模型很糟糕。例如，如果你确定某个基因是癌症的一个显著原因，这是一个重要的知识，即使这个基因本身并不决定一个人是否会得癌症。这里的例子是分类，而不是回归，但观点是一样的：在科学研究中，检测影响比完美拟合模型（更不用说更现实）更重要。但何时我们知道一个基因有这种影响？这被称为显著性。'
- en: '***Predictor significance*** —Coefficients are great, but sometimes not enough
    evidence exists to show that the influence is there. This is what the p-value
    is about. A long explanation about type 1 and type 2 mistakes is possible here
    but the short explanations would be: if the p-value is lower than 0.05, the variable
    is considered significant for most people. In truth, this is an arbitrary number.
    It means there’s a 5% chance the predictor doesn’t have any influence. Do you
    accept this 5% chance to be wrong? That’s up to you. Several people introduced
    the extremely significant (p<0.01) and marginally significant thresholds (p<0.1).'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***预测变量的重要性*** —系数很好，但有时没有足够的证据来显示影响的存在。这就是 p 值的作用。在这里可以长篇大论地解释类型1和类型2错误，但简短的解释将是：如果
    p 值低于 0.05，大多数人认为该变量是显著的。实际上，这是一个任意数字。这意味着预测变量没有任何影响的概率是 5%。你是否接受这种 5% 的错误概率？这取决于你。一些人引入了极端显著（p<0.01）和边际显著阈值（p<0.1）。'
- en: Linear regression works if you want to predict a value, but what if you want
    to classify something? Then you go to classification models, the best known among
    them being k-nearest neighbors.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归适用于你想预测一个值的情况，但如果你想要对某物进行分类呢？那么你就转向分类模型，其中最著名的是 k-最近邻。
- en: As shown in [figure 2.24](#ch02fig24), k-nearest neighbors looks at labeled
    points nearby an unlabeled point and, based on this, makes a prediction of what
    the label should be.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图2.24](#ch02fig24)所示，k最近邻算法查看一个未标记点附近的标记点，并根据这个预测标签应该是什么。
- en: Figure 2.24\. K-nearest neighbor techniques look at the k-nearest point to make
    a prediction.
  id: totrans-267
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.24。K最近邻技术通过查看最近的k个点来进行预测。
- en: '![](Images/02fig24_alt.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig24_alt.jpg)'
- en: Let’s try it in Python code using the Scikit learn library, as in this next
    listing.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用Python代码和Scikit learn库来尝试，如下所示。
- en: Listing 2.2\. Executing k-nearest neighbor classification on semi-random data
  id: totrans-270
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.2。在半随机数据上执行k最近邻分类
- en: '![](Images/052fig01_alt.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/052fig01_alt.jpg)'
- en: As before, we construct random correlated data and surprise, surprise we get
    85% of cases correctly classified. If we want to look in depth, we need to score
    the model. Don’t let `knn.score()` fool you; it returns the model accuracy, but
    by “scoring a model” we often mean applying it on data to make a prediction.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 和之前一样，我们构建了随机相关数据，令人惊讶的是，我们正确分类了85%的情况。如果我们想深入了解，我们需要评估模型。不要让`knn.score()`欺骗你；它返回模型准确率，但当我们说“评估模型”时，我们通常是指将其应用于数据以进行预测。
- en: '[PRE2]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now we can use the prediction and compare it to the real thing using a confusion
    matrix.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用预测结果，并使用混淆矩阵将其与实际情况进行比较。
- en: '[PRE3]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We get a 3-by-3 matrix as shown in [figure 2.25](#ch02fig25).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一个3x3的矩阵，如[图2.25](#ch02fig25)所示。
- en: 'Figure 2.25\. Confusion matrix: it shows how many cases were correctly classified
    and incorrectly classified by comparing the prediction with the real values. Remark:
    the classes (0,1,2) were added in the figure for clarification.'
  id: totrans-277
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.25。混淆矩阵：它通过比较预测值与真实值来显示正确分类和错误分类的案例数量。备注：图中的类别（0，1，2）是为了说明而添加的。
- en: '![](Images/02fig25_alt.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/02fig25_alt.jpg)'
- en: 'The confusion matrix shows we have correctly predicted 17+405+5 cases, so that’s
    good. But is it really a surprise? No, for the following reasons:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵显示我们正确预测了17+405+5个案例，所以这是好的。但这真的是一个惊喜吗？不，以下是一些原因：
- en: For one, the classifier had but three options; marking the difference with last
    time `np.around()` will round the data to its nearest integer. In this case that’s
    either 0, 1, or 2\. With only 3 options, you can’t do much worse than 33% correct
    on 500 guesses, even for a real random distribution like flipping a coin.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，分类器只有三个选项；通过`np.around()`标记与上一次的差异，将数据四舍五入到最接近的整数。在这种情况下，要么是0，1，或2。只有3个选项，即使对于像抛硬币这样的真实随机分布，在500次猜测中，你不可能做得比33%正确更差。
- en: Second, we cheated again, correlating the response variable with the predictors.
    Because of the way we did this, we get most observations being a “1”. By guessing
    “1” for every case we’d already have a similar result.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二，我们又作弊了，将响应变量与预测变量相关联。由于我们这样做的方式，我们得到大多数观测值都是“1”。如果我们为每个案例猜测“1”，我们就会得到类似的结果。
- en: We compared the prediction with the real values, true, but we never predicted
    based on fresh data. The prediction was done using the same data as the data used
    to build the model. This is all fine and dandy to make yourself feel good, but
    it gives you no indication of whether your model will work when it encounters
    truly new data. For this we need a holdout sample, as will be discussed in the
    next section.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们比较了预测值与真实值，是的，但我们从未基于新数据做出预测。预测是使用构建模型时使用的相同数据进行的。这所有的一切都很好，可以让你感觉良好，但它并不能告诉你你的模型在遇到真正的新数据时是否会工作。为此，我们需要一个保留样本，这将在下一节中讨论。
- en: Don’t be fooled. Typing this code won’t work miracles by itself. It might take
    a while to get the modeling part and all its parameters right.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 不要被欺骗。仅仅输入这段代码本身并不能创造奇迹。可能需要一段时间才能正确设置建模部分及其所有参数。
- en: To be honest, only a handful of techniques have industry-ready implementations
    in Python. But it’s fairly easy to use models that are available in R within Python
    with the help of the RPy library. RPy provides an interface from Python to R.
    *R* is a free software environment, widely used for statistical computing. If
    you haven’t already, it’s worth at least a look, because in 2014 it was still
    one of the most popular (if not the most popular) programming languages for data
    science. For more information, see [http://www.kdnuggets.com/polls/2014/languages-analytics-data-mining-data-science.html](http://www.kdnuggets.com/polls/2014/languages-analytics-data-mining-data-science.html).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 说实话，只有少数技术有在Python中的行业级实现。但是，借助RPy库，在Python中使用R中可用的模型相当容易。RPy为Python提供了到R的接口。*R*是一个免费软件环境，广泛用于统计分析。如果你还没有尝试过，至少值得一试，因为2014年它仍然是数据科学中最受欢迎（如果不是最受欢迎）的编程语言之一。更多信息，请参阅[http://www.kdnuggets.com/polls/2014/languages-analytics-data-mining-data-science.html](http://www.kdnuggets.com/polls/2014/languages-analytics-data-mining-data-science.html)。
- en: 2.6.3\. Model diagnostics and model comparison
  id: totrans-285
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.6.3\. 模型诊断和模型比较
- en: 'You’ll be building multiple models from which you then choose the best one
    based on multiple criteria. Working with a holdout sample helps you pick the best-performing
    model. A holdout sample is a part of the data you leave out of the model building
    so it can be used to evaluate the model afterward. The principle here is simple:
    the model should work on unseen data. You use only a fraction of your data to
    estimate the model and the other part, the holdout sample, is kept out of the
    equation. The model is then unleashed on the unseen data and error measures are
    calculated to evaluate it. Multiple error measures are available, and in [figure
    2.26](#ch02fig26) we show the general idea on comparing models. The error measure
    used in the example is the mean square error.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 你将构建多个模型，然后根据多个标准从中选择最佳模型。使用保留样本可以帮助你选择表现最好的模型。保留样本是你从模型构建中排除的一部分数据，以便在之后评估模型。这里的原理很简单：模型应该在未见过的数据上工作。你只使用你数据的一部分来估计模型，而另一部分，即保留样本，则被排除在外。然后模型被释放到未见过的数据上，并计算误差度量来评估它。有多种误差度量可用，在[图2.26](#ch02fig26)中我们展示了比较模型的一般思想。示例中使用的误差度量是均方误差。
- en: Figure 2.26\. Formula for mean square error
  id: totrans-287
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.26\. 均方误差公式
- en: '![](Images/02fig26.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig26.jpg)'
- en: 'Mean square error is a simple measure: check for every prediction how far it
    was from the truth, square this error, and add up the error of every prediction.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 均方误差是一个简单的度量：检查每个预测与真实值有多远，平方这个误差，并将每个预测的误差相加。
- en: '[Figure 2.27](#ch02fig27) compares the performance of two models to predict
    the order size from the price. The first model is *size = 3 * price* and the second
    model is *size = 10*. To estimate the models, we use 800 randomly chosen observations
    out of 1,000 (or 80%), without showing the other 20% of data to the model. Once
    the model is trained, we predict the values for the other 20% of the variables
    based on those for which we already know the true value, and calculate the model
    error with an error measure. Then we choose the model with the lowest error. In
    this example we chose model 1 because it has the lowest total error.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '[图2.27](#ch02fig27)比较了两个模型从价格预测订单大小的性能。第一个模型是*大小 = 3 * 价格*，第二个模型是*大小 = 10*。为了估计模型，我们从1,000个观测值中随机选择了800个（或80%），没有向模型展示其他20%的数据。一旦模型训练完成，我们根据已知真实值的变量预测其他20%的变量的值，并使用误差度量计算模型误差。然后我们选择误差最低的模型。在这个例子中，我们选择了模型1，因为它具有最低的总误差。'
- en: Figure 2.27\. A holdout sample helps you compare models and ensures that you
    can generalize results to data that the model has not yet seen.
  id: totrans-291
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.27\. 保留样本有助于你比较模型，并确保你可以将结果推广到模型尚未见过的数据。
- en: '![](Images/02fig27_alt.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/02fig27_alt.jpg)'
- en: Many models make strong assumptions, such as independence of the inputs, and
    you have to verify that these assumptions are indeed met. This is called *model
    diagnostics*.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 许多模型都做出了强烈的假设，例如输入的独立性，你必须验证这些假设确实得到了满足。这被称为*模型诊断*。
- en: This section gave a short introduction to the steps required to build a valid
    model. Once you have a working model you’re ready to go to the last step.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 本节简要介绍了构建有效模型所需的步骤。一旦你有了可工作的模型，你就可以进入最后一步。
- en: '2.7\. Step 6: Presenting findings and building applications on top of them'
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.7\. 第6步：展示发现并在此基础上构建应用
- en: After you’ve successfully analyzed the data and built a well-performing model,
    you’re ready to present your findings to the world ([figure 2.28](#ch02fig28)).
    This is an exciting part; all your hours of hard work have paid off and you can
    explain what you found to the stakeholders.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在你成功分析了数据并构建了一个表现良好的模型之后，你准备好向世界展示你的发现（[图2.28](#ch02fig28)）。这是一个令人兴奋的部分；你所有辛勤工作的小时都得到了回报，你可以向利益相关者解释你发现了什么。
- en: 'Figure 2.28\. Step 6: Presentation and automation'
  id: totrans-297
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.28. 第6步：演示和自动化
- en: '![](Images/02fig28.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图2.28](Images/02fig28.jpg)'
- en: Sometimes people get so excited about your work that you’ll need to repeat it
    over and over again because they value the predictions of your models or the insights
    that you produced. For this reason, you need to automate your models. This doesn’t
    always mean that you have to redo all of your analysis all the time. Sometimes
    it’s sufficient that you implement only the model scoring; other times you might
    build an application that automatically updates reports, Excel spreadsheets, or
    PowerPoint presentations. The last stage of the data science process is where
    your *soft skills* will be most useful, and yes, they’re extremely important.
    In fact, we recommend you find dedicated books and other information on the subject
    and work through them, because why bother doing all this tough work if nobody
    listens to what you have to say?
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候人们对你工作的兴奋程度如此之高，以至于你需要一遍又一遍地重复它，因为他们重视你模型的预测或你产生的见解。因此，你需要自动化你的模型。这并不总是意味着你必须不断地重做所有的分析。有时，仅实现模型评分就足够了；其他时候，你可能需要构建一个自动更新报告、Excel电子表格或PowerPoint演示文稿的应用程序。数据科学过程的最后阶段是您**软技能**最能发挥作用的阶段，而且它们确实非常重要。事实上，我们建议你找到关于这个主题的专用书籍和其他信息，并努力去学习，因为如果没有人听你说话，你为什么要做所有这些艰苦的工作呢？
- en: If you’ve done this right, you now have a working model and satisfied stakeholders,
    so we can conclude this chapter here.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经正确地完成了这项工作，你现在拥有了一个工作模型和满意的利益相关者，因此我们可以在这里结束这一章节。
- en: 2.8\. Summary
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.8. 摘要
- en: 'In this chapter you learned the data science process consists of six steps:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了数据科学过程包括六个步骤：
- en: '***Setting the research goal*** —Defining the what, the why, and the how of
    your project in a project charter.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设定研究目标** —在项目章程中定义项目的“是什么”、“为什么”和“如何”。'
- en: '***Retrieving data*** —Finding and getting access to data needed in your project.
    This data is either found within the company or retrieved from a third party.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索数据** —寻找并获取你项目中需要的数据。这些数据可能在公司内部找到，也可能从第三方获取。'
- en: '***Data preparation*** —Checking and remediating data errors, enriching the
    data with data from other data sources, and transforming it into a suitable format
    for your models.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据准备** —检查和修复数据错误，用来自其他数据源的数据丰富数据，并将其转换为适合你模型的格式。'
- en: '***Data exploration*** —Diving deeper into your data using descriptive statistics
    and visual techniques.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据探索** —使用描述性统计和可视化技术深入挖掘你的数据。'
- en: '***Data modeling*** —Using machine learning and statistical techniques to achieve
    your project goal.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据建模** —使用机器学习和统计技术来实现你的项目目标。'
- en: '***Presentation and automation*** —Presenting your results to the stakeholders
    and industrializing your analysis process for repetitive reuse and integration
    with other tools.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**演示和自动化** —向利益相关者展示你的结果，并将你的分析过程工业化，以便重复使用和与其他工具集成。'
