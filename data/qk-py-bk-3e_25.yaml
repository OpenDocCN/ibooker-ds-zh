- en: Chapter 22\. Data over the network
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第22章. 网络上的数据
- en: '*This chapter covers*'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Fetching files via FTP/SFTP, SSH/SCP, and HTTPS
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过FTP/SFTP、SSH/SCP和HTTPS获取文件
- en: Getting data via APIs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过API获取数据
- en: 'Structured data file formats: JSON and XML'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化数据文件格式：JSON和XML
- en: Scraping data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据抓取
- en: You’ve seen how to deal with text-based data files. In this chapter, you use
    Python to move data files over the network. In some cases, those files might be
    text or spreadsheet files, as discussed in [chapter 21](kindle_split_034.html#ch21),
    but in other cases, they might be in more structured formats and served from REST
    or SOAP application programming interfaces (APIs). Sometimes, getting the data
    may mean scraping it from a website. This chapter discusses all of these situations
    and shows some common use cases.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了如何处理基于文本的数据文件。在本章中，你将使用Python在网络中移动数据文件。在某些情况下，这些文件可能是文本或电子表格文件，如第21章所述，但在其他情况下，它们可能是更结构化的格式，并从REST或SOAP应用程序编程接口（API）提供服务。有时，获取数据可能意味着从网站上抓取。本章讨论了所有这些情况，并展示了常见的用例。
- en: 22.1\. Fetching files
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 22.1. 获取文件
- en: Before you can do anything with data files, you have to get them. Sometimes,
    this process is very easy, such as manually downloading a single zip archive,
    or maybe the files have been pushed to your machine from somewhere else. Quite
    often, however, the process is more involved. Maybe a large number of files needs
    to be retrieved from a remote server, files need to be retrieved regularly, or
    the retrieval process is sufficiently complex to be a pain to do manually. In
    any of those cases, you might well want to automate fetching the data files with
    Python.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在你可以对数据文件进行任何操作之前，你必须获取它们。有时，这个过程非常简单，比如手动下载单个zip存档，或者文件可能已经被从其他地方推送到你的机器上。然而，很多时候，这个过程更为复杂。可能需要从远程服务器检索大量文件，或者需要定期检索文件，或者检索过程足够复杂，手动操作会变得痛苦。在任何这些情况下，你很可能希望使用Python自动化获取数据文件。
- en: First of all, I want to be clear that using a Python script isn’t the only way,
    or always the best way, to retrieve files. The following sidebar offers more explanation
    of the factors I consider when deciding whether to use a Python script for file
    retrieval. Assuming that using Python does make sense for your particular use
    case, however, this section illustrates some common patterns you might employ.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我想明确指出，使用Python脚本并不是唯一的方式，也不一定是最佳的方式，来获取文件。以下边栏提供了更多关于我在决定是否使用Python脚本进行文件检索时考虑的因素的解释。然而，假设使用Python确实适合你的特定用例，本节将展示你可能采用的一些常见模式。
- en: '|  |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Do I use Python?**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**我是否应该使用Python？**'
- en: Although using Python to retrieve files can work very well, it’s not always
    the best choice. In making a decision, you might want to consider two things.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使用Python获取文件可以非常有效，但这并不总是最佳选择。在做出决定时，你可能需要考虑两个因素。
- en: '*Are simpler options available?* Depending on your operating system and your
    experience, you may find that simple shell scripts and command-line tools are
    simpler and easier to configure. If you don’t have those tools available or aren’t
    comfortable using them (or the people who will be maintaining them aren’t comfortable
    with them), you may want to consider a Python script.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*是否有更简单的选项？* 根据你的操作系统和经验，你可能会发现简单的shell脚本和命令行工具更简单，更容易配置。如果你没有这些工具可用，或者不习惯使用它们（或者将维护它们的人不习惯使用它们），你可能希望考虑一个Python脚本。'
- en: '*Is the retrieval process complex or tightly coupled with processing?* Although
    those situations are never desirable, they can occur. My rule these days is that
    if a shell script requires more than a few lines, or if I have to think hard about
    how to do something in a shell script, it’s probably time to switch to Python.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*获取过程复杂吗？或者与处理过程紧密耦合？* 虽然这些情况通常不理想，但它们可能会发生。我现在的规则是，如果shell脚本需要超过几行，或者我必须认真思考如何在shell脚本中完成某事，那么可能就是时候切换到Python了。'
- en: '|  |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 22.1.1\. Using Python to fetch files from an FTP server
  id: totrans-16
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 22.1.1. 使用Python从FTP服务器获取文件
- en: 'File Transfer Protocol (FTP) has been around for a very long time, but it’s
    still a simple and easy way to share files when security isn’t a huge concern.
    To access an FTP server in Python, you can use the `ftplib` module from the standard
    library. The steps to follow are straightforward: create an FTP object, connect
    to a server, and then log in with a username and password (or, quite commonly,
    with a username of “anonymous” and an empty password).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 文件传输协议（FTP）已经存在很长时间了，但它在安全性不是主要关注点时，仍然是一种简单易用的文件共享方式。要在Python中访问FTP服务器，你可以使用标准库中的`ftplib`模块。要遵循的步骤很简单：创建一个FTP对象，连接到服务器，然后使用用户名和密码（或者相当常见的是，使用用户名为“anonymous”和空密码）登录。
- en: 'To continue working with weather data, you can connect to the National Oceanic
    and Atmospheric Administration (NOAA) FTP server, as shown here:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要继续处理天气数据，你可以连接到国家海洋和大气管理局（NOAA）的FTP服务器，如下所示：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When you’re connected, you can use the `ftp` object to list and change directories:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当你连接时，你可以使用`ftp`对象来列出和更改目录：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then you can fetch, for example, the latest METAR report for Chicago O’Hare
    International Airport:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以获取例如芝加哥奥黑尔国际机场的最新METAR报告：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You pass the `ftp.retrbinary` method both the path to the file on the remote
    server and a method to handle that file’s data on your end—in this case, the `write`
    method of a file you open for binary writing with the same name. When you look
    at KORD.TXT, you see that it contains the downloaded data:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你将远程服务器上文件的路径和一种处理该文件数据的本地方法传递给`ftp.retrbinary`方法——在这种情况下，是使用相同名称打开的文件用于二进制写入的`write`方法。当你查看KORD.TXT时，你会看到它包含下载的数据：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can also use `ftplib` to connect to servers using TLS encryption by using
    FTP_TLS instead of FTP:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用`ftplib`通过使用FTP_TLS而不是FTP来连接使用TLS加密的服务器：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 22.1.2\. Fetching files with SFTP
  id: totrans-28
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 22.1.2\. 使用SFTP获取文件
- en: If the data requires more security, such as in a corporate context in which
    business data is being transferred over the network, it’s fairly common to use
    SFTP. SFTP is a full-featured protocol that allows file access, transfer, and
    management over a Secure Shell (SSH) connection. Even though SFTP stands for SSH
    File Transfer Protocol and FTP stands for File Transfer Protocol, the two aren’t
    related. SFTP isn’t a reimplementation of FTP on SSH, but a fresh design specifically
    for SSH.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据需要更高的安全性，例如在业务数据通过网络传输的企业环境中，使用SFTP相当普遍。SFTP是一个功能齐全的协议，它允许通过Secure Shell
    (SSH)连接进行文件访问、传输和管理。尽管SFTP代表SSH文件传输协议，而FTP代表文件传输协议，但这两个协议并不相关。SFTP不是在SSH上重新实现FTP，而是一个专门为SSH设计的全新设计。
- en: Using SSH-based transfers is attractive both because SSH is already the de facto
    standard for accessing remote servers and because enabling support for SFTP on
    a server is fairly easy (and quite often on by default).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基于SSH的传输很有吸引力，因为SSH已经是访问远程服务器的既定标准，并且启用服务器上的SFTP支持相当简单（并且通常默认开启）。
- en: Python doesn’t have an SFTP/SCP client module in its standard library, but a
    community-developed library called `paramiko` manages SFTP operations as well
    as SSH connections. To use `paramiko`, the easiest thing is to install it via
    `pip`. If the NOAA site mentioned earlier in this chapter were using SFTP (which
    it doesn’t, so this code won’t work!), the SFTP equivalent of the code above would
    be
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Python的标准库中没有SFTP/SCP客户端模块，但一个社区开发的库`paramiko`可以管理SFTP操作以及SSH连接。要使用`paramiko`，最简单的方法是通过`pip`安装它。如果本章前面提到的NOAA网站使用SFTP（它实际上没有使用，所以这段代码将无法工作！），上述代码的SFTP等价物将是
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It’s also worth noting that although `paramiko` supports running commands on
    a remote server and receiving its outputs, just like a direct `ssh` session, it
    doesn’t include an `scp` function. This function is rarely something you’ll miss;
    if all you want to do is move a file or two over an `ssh` connection, a command-line
    `scp` utility usually makes the job easier and simpler.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，尽管`paramiko`支持在远程服务器上运行命令并接收其输出，就像直接的`ssh`会话一样，但它不包含`scp`功能。这个功能很少是你会错过的东西；如果你只想通过`ssh`连接移动一个或两个文件，命令行的`scp`实用程序通常会使工作更简单、更简单。
- en: 22.1.3\. Retrieving files over HTTP/HTTPS
  id: totrans-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 22.1.3\. 通过HTTP/HTTPS检索文件
- en: The last common option for retrieving data files that I discuss in this chapter
    is getting files over an HTTP or HTTPS connection. This option is probably the
    easiest of all the options; you are in effect retrieving your data from a web
    server, and support for accessing web servers is very widespread. Again, in this
    case you may not need to use Python. Various command-line tools retrieve files
    via HTTP/HTTPS connections and have most of the capabilities you might need. The
    two most common of these tools are wget and curl. If you have a reason to do the
    retrieval in your Python code, however, that process isn’t much harder. The `requests`
    library is by far the easiest and most reliable way to access HTTP/HTTPS servers
    from Python code. Again, `requests` is easiest to install with `pip install requests`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我讨论的最后一种获取数据文件的方法是通过HTTP或HTTPS连接获取文件。这个选项可能是所有选项中最简单的；实际上，你是在从Web服务器获取数据，访问Web服务器的支持非常广泛。同样，在这种情况下，你可能不需要使用Python。各种命令行工具通过HTTP/HTTPS连接检索文件，并具有你可能需要的几乎所有功能。其中最常见的是wget和curl。然而，如果你有理由在Python代码中执行检索，这个过程并不困难。`requests`库是从Python代码访问HTTP/HTTPS服务器最简单、最可靠的方式。再次强调，`requests`可以通过`pip
    install requests`命令轻松安装。
- en: 'When you have requests installed, fetching a file is straightforward: import
    `requests` and use the correct HTTP verb (usually, GET) to connect to the server
    and return your data.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当你安装了`requests`后，获取文件的过程很简单：导入`requests`并使用正确的HTTP动词（通常是GET）连接到服务器并返回你的数据。
- en: 'The following example code fetches the monthly temperature data for Heathrow
    Airport since 1948—a text file that’s served via a web server. If you want to,
    you can put the URL in your browser, load the page, and then save it. If the page
    is large or you have a lot of pages to get, however, it’s easier to use code like
    this:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例代码获取了自1948年以来希思罗机场的月度温度数据——一个通过Web服务器提供的文本文件。如果你想的话，可以将URL输入到浏览器中，加载页面，然后保存它。然而，如果页面很大或者你需要获取很多页面，使用像这样的代码会更容易一些：
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The response will have a fair amount of information, including the header returned
    by the web server, which can be helpful in debugging if things aren’t working.
    The part of the response object you’ll most often be interested in, however, is
    data returned. To retrieve this data, you want to access the response’s `text`
    property, which contains the response body as a string, or the `content` property,
    which contains the response body as bytes:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 响应将包含相当多的信息，包括Web服务器返回的头部信息，如果出现问题，这些信息在调试时可能很有帮助。然而，你通常最感兴趣的响应对象部分是返回的数据。为了检索这些数据，你需要访问响应的`text`属性，它包含响应体作为字符串，或者`content`属性，它包含响应体作为字节：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Typically, you’d write the response text to a file for later processing, but
    depending on your needs, you might first do some cleaning or even process directly.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你会将响应文本写入文件以供以后处理，但根据你的需求，你可能首先进行一些清理，甚至直接处理。
- en: '|  |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Try this: Retrieving A file'
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 尝试这个：检索一个文件
- en: If you’re working with the example data file and want to break each line into
    separate fields, how might you do that? What other processing would you expect
    to do? Try writing some code to retrieve this file and calculate the average annual
    rainfall or (for more of a challenge) the average maximum and minimum temperature
    for each year.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在处理示例数据文件，并且想要将每一行拆分成单独的字段，你该如何做？你预期还会进行哪些其他处理？尝试编写一些代码来检索这个文件，并计算平均年降雨量，或者（更具挑战性）计算每年平均最高和最低温度。
- en: '|  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 22.2\. Fetching data via an API
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 22.2. 通过API获取数据
- en: Serving data by way of an API is quite common, following a trend toward decoupling
    applications into services that communicate via APIs. APIs can work in several
    ways, but they commonly operate over regular HTTP/HTTPS protocols using the standard
    HTTP verbs, GET, POST, PUT, and DELETE. Fetching data this way is very similar
    to retrieving a file, as in [section 22.1.3](#ch22lev2sec3), but the data isn’t
    in a static file. Instead of the application serving static files that contain
    the data, it queries some other data source and then assembles and serves the
    data dynamically on request.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通过API提供数据是一种相当常见的方式，这遵循了将应用程序解耦成通过API通信的服务的发展趋势。API可以通过多种方式工作，但它们通常通过标准的HTTP/HTTPS协议使用标准的HTTP动词，如GET、POST、PUT和DELETE来操作。以这种方式获取数据与[第22.1.3节](#ch22lev2sec3)中检索文件非常相似，但数据不是静态文件。不是应用程序提供包含数据的静态文件，而是查询其他数据源，然后在请求时动态组装和提供数据。
- en: Although there’s a lot of variation in the ways that an API can be set up, one
    of the most common is a RESTful (REpresentational State Transfer) interface that
    operates over the same HTTP/HTTPS protocols as the web. There are endless variations
    on how an API might work, but commonly, data is fetched by using a GET request,
    which is what your web browser uses to request a web page. When you’re fetching
    via a GET request, the parameters to select the data you want are often appended
    to the URL in a query string.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然API的设置方式有很多种变化，但最常见的一种是RESTful（表示状态转移）接口，它通过相同的HTTP/HTTPS协议运行，就像网络一样。API可能的工作方式有无数种变化，但通常，数据是通过使用GET请求来获取的，这就是你的网络浏览器用来请求网页的方式。当你通过GET请求获取数据时，选择所需数据的参数通常会被附加到URL的查询字符串中。
- en: If you want to get the current weather on Mars from the Curiosity rover, use
    [http://mng.bz/g6UY](http://mng.bz/g6UY) as your URL.^([[1](#ch22fn1)]) The `?format=json`
    is a query string parameter that specifies that the information be returned in
    JSON, which I discuss in [section 22.3.1](#ch22lev2sec4). If you want the Martian
    weather for a specific Martian day, or sol, of its mission—say, the 155th sol—use
    the URL [http://mng.bz/4e0r](http://mng.bz/4e0r). If you want to get the weather
    on Mars for a range of Earth dates, such as the month of October 2012, use [http://mng.bz/83WO](http://mng.bz/83WO).
    Notice that the elements of the query string are separated by ampersands (`&`).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要从好奇号火星车获取火星上的当前天气，请使用[http://mng.bz/g6UY](http://mng.bz/g6UY)作为你的URL.^([[1](#ch22fn1)])
    `?format=json`是一个查询字符串参数，指定信息以JSON格式返回，我在[第22.3.1节](#ch22lev2sec4)中讨论了这一点。如果你想要获取任务中特定火星日（或sol）的火星天气，比如第155个sol，请使用URL
    [http://mng.bz/4e0r](http://mng.bz/4e0r)。如果你想要获取特定地球日期范围内的火星天气，例如2012年10月，请使用[http://mng.bz/83WO](http://mng.bz/83WO)。请注意，查询字符串的元素之间由和号(`&`)分隔。
- en: ¹
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ¹
- en: ''
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The site ([ingenology.com](http://ingenology.com)) has been reliable in the
    past, but is down at the time of this writing and its future is uncertain.
  id: totrans-52
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 该网站([ingenology.com](http://ingenology.com))过去一直很可靠，但在撰写本文时已关闭，其未来尚不确定。
- en: 'When you know the URL to use, you can use the requests library to fetch data
    from an API and either process it on the fly or save it to a file for later processing.
    The simplest way to do this is exactly like retrieving a file:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当你知道要使用的URL时，你可以使用requests库从API获取数据，并可以选择即时处理它或将其保存到文件以供稍后处理。这样做最简单的方式就是像检索文件一样：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Keep in mind that you should escape spaces and most punctuation in your query
    parameters, because those elements aren’t allowed in URLs even though many browsers
    automatically do the escaping on URLs.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，你应该在查询参数中转义空格和大多数标点符号，因为这些元素在URL中是不允许的，尽管许多浏览器会自动对URL进行转义。
- en: For a final example, suppose that you want to grab the crime data for Chicago
    between noon and 1 PM on Jan. 10, 2017\. The way that the API works, you specify
    a date range with the query string parameters of `$where date=between <start datetime>`
    and `<end datetime>`, where the start and end datetimes are quoted in ISO format.
    So the URL for getting that one hour of Chicago crime data would be [https://data.cityofchicago.org/resource/6zsd-86xi.json?$where=datebetween’2015-01-10T12:00:00’and’2015-01-10T13:00:00’](https://data.cityofchicago.org/resource/6zsd-86xi.json?%24where=datebetween%E2%80%992015-01-10T12:00:00%E2%80%99and%E2%80%992015-01-10T13:00:00%E2%80%99).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的例子，假设你想要获取2017年1月10日中午12点到下午1点之间芝加哥的犯罪数据。API的工作方式是，你通过查询字符串参数指定一个日期范围，即`$where
    date=between <start datetime>`和`<end datetime>`，其中起始和结束的日期时间以ISO格式引用。因此，获取那一小时芝加哥犯罪数据的URL将是[https://data.cityofchicago.org/resource/6zsd-86xi.json?$where=datebetween’2015-01-10T12:00:00’and’2015-01-10T13:00:00’](https://data.cityofchicago.org/resource/6zsd-86xi.json?%24where=datebetween%E2%80%992015-01-10T12:00:00%E2%80%99and%E2%80%992015-01-10T13:00:00%E2%80%99).
- en: In the example, several characters aren’t welcome in URLs, such as the quote
    characters and the spaces. This is another situation in which the requests library
    makes good on its aim of making things easier for the user, because before it
    sends the URL, it takes care of quoting it properly. The URL that the request
    actually sends is [https://data.cityofchicago.org/resource/6zsd-86xi.json?$where=date%20between%20%222015-01-10T12:00:00%22%20and%20%222015-01-10T14:00:00%22’](https://data.cityofchicago.org/resource/6zsd-86xi.json?%24where=date%20between%20%222015-01-10T12:00:00%22%20and%20%222015-01-10T14:00:00%22%E2%80%99).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在示例中，一些字符在URL中不受欢迎，例如引号字符和空格。这是requests库实现其让用户更轻松目标的一个例子，因为它在发送URL之前，会妥善地对其进行引号处理。实际发送的URL是[https://data.cityofchicago.org/resource/6zsd-86xi.json?$where=date%20between%20%222015-01-10T12:00:00%22%20and%20%222015-01-10T14:00:00%22’](https://data.cityofchicago.org/resource/6zsd-86xi.json?%24where=date%20between%20%222015-01-10T12:00:00%22%20and%20%222015-01-10T14:00:00%22%E2%80%99)。
- en: Note that all of the single-quote characters have been quoted with %22 and all
    of the spaces with %20 without your even needing to think about it.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，所有单引号字符都已用%22引号括起来，所有空格都已用%20替换，而你甚至不需要考虑这一点。
- en: '|  |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Try this: Accessing an API'
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 尝试这个操作：访问API
- en: Write some code to fetch some data from the city of Chicago website. Look at
    the fields mentioned in the results, and see whether you can select records based
    on another field in combination with the date range.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一些代码从芝加哥市的网站获取数据。查看结果中提到的字段，看看你是否可以根据日期范围结合另一个字段来选择记录。
- en: '|  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 22.3\. Structured data formats
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 22.3. 结构化数据格式
- en: Although APIs sometimes serve plain text, it’s much more common for data served
    from APIs to be served in a structured file format. The two most common file formats
    are JSON and XML. Both of these formats are built on plain text but structure
    their contents so that they’re more flexible and able to store more complex information.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然API有时会提供纯文本，但数据通常以结构化文件格式从API提供。最常用的两种文件格式是JSON和XML。这两种格式都基于纯文本，但它们以更灵活的方式组织内容，能够存储更复杂的信息。
- en: 22.3.1\. JSON data
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 22.3.1. JSON数据
- en: 'JSON, which stands for JavaScript Object Notation, dates to 1999\. It consists
    of only two structures: key-value pairs, called *structures*, that are very similar
    to Python dictionaries; and ordered lists of values, called *arrays*, that are
    very much like Python lists.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: JSON，即JavaScript对象表示法，起源于1999年。它仅由两种结构组成：称为*结构*的键值对，这些结构与Python字典非常相似；以及称为*数组*的有序值列表，这些列表与Python列表非常相似。
- en: Keys can be only strings in double quotes, and values can be strings in double
    quotes, numbers, true, false, null, arrays, or objects. These elements make JSON
    a lightweight way to represent most data in a way that’s easily transmitted over
    the network and also fairly easy for humans to read. JSON is so common that most
    languages have features to translate JSON to and from native data types. In the
    case of Python, that feature is the `json` module, which became part of the standard
    library with version 2.6\. The original externally maintained version of the module
    is available as `simplejson`, which is still available. In Python 3, however,
    it’s far more common to use the standard library version.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 键只能是双引号内的字符串，值可以是双引号内的字符串、数字、true、false、null、数组或对象。这些元素使得JSON成为表示大多数数据的一种轻量级方式，这种方式易于在网络中传输，并且对人类来说也相对容易阅读。JSON如此普遍，以至于大多数语言都有将JSON转换为本地数据类型以及从本地数据类型转换为JSON的功能。在Python的情况下，这个功能是`json`模块，它从版本2.6开始成为标准库的一部分。该模块的原始外部维护版本作为`simplejson`提供，目前仍然可用。然而，在Python
    3中，使用标准库版本更为常见。
- en: 'The data you retrieved from the Mars rover and the city of Chicago APIs in
    [section 22.2](#ch22lev1sec2) is in JSON format. To send JSON across the network,
    the JSON object needs to be serialized—that is, transformed into a sequence of
    bytes. So although the batch of data you retrieved from the Mars rover and Chicago
    APIs looks like JSON, in fact it’s just a byte string representation of a JSON
    object. To transform that byte string into a real JSON object and translate it
    into a Python dictionary, you need to use the JSON `loads()` function. If you
    want to get the Mars weather report, for example, you can do that just as you
    did previously, but this time you’ll convert it to a Python dictionary:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 你从火星漫游车和芝加哥 API 中检索的数据在 [第 22.2 节](#ch22lev1sec2) 中是 JSON 格式。为了在网络中发送 JSON，JSON
    对象需要被序列化——也就是说，转换成一系列字节。所以，尽管你从火星漫游车和芝加哥 API 检索的数据看起来像是 JSON，但实际上它只是 JSON 对象的字节字符串表示。为了将这个字节字符串转换成真正的
    JSON 对象并将其转换为 Python 字典，你需要使用 JSON 的 `loads()` 函数。例如，如果你想获取火星天气报告，你可以像之前一样做，但这次你需要将其转换为
    Python 字典：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that the call to `json.loads()`is what takes the string representation
    of the JSON object and transforms, or loads, it into a Python dictionary. Also,
    a `json.load()` function will read from any filelike object that supports a read
    method.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`json.loads()` 的调用是将 JSON 对象的字符串表示形式转换或加载成 Python 字典。此外，`json.load()` 函数将读取任何支持读取方法的文件对象。
- en: 'If you look at a dictionary’s representation as earlier, it can be very hard
    to make sense of what’s going on. Improved formatting, also called *pretty printing*,
    can make data structures much easier to understand. Use the Python `prettyprint`
    module to see what’s in the example dictionary:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看字典的表示形式，就像之前一样，可能会很难理解其含义。改进的格式化，也称为 *美化打印*，可以使数据结构更容易理解。使用 Python 的 `prettyprint`
    模块查看示例字典中的内容：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Both load functions can be configured to control how to parse and decode the
    original JSON to Python objects, but the default translation is listed in [table
    22.1](#ch22table01).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 两个加载函数都可以配置以控制如何解析和解码原始 JSON 到 Python 对象，但默认的转换列在 [表 22.1](#ch22table01) 中。
- en: Table 22.1\. JSON to Python default decoding
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 22.1\. JSON 到 Python 默认解码
- en: '| JSON | Python |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| JSON | Python |'
- en: '| --- | --- |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| object | dict |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 对象 | dict |'
- en: '| array | list |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 数组 | list |'
- en: '| string | str |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 字符串 | str |'
- en: '| number (int) | int |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 数字 (int) | int |'
- en: '| number (real) | float |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 实数 (number) | float |'
- en: '| true | True |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| true | True |'
- en: '| false | False |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| false | False |'
- en: '| null | None |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| null | None |'
- en: '|  |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Fetching JSON with the requests library**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 requests 库获取 JSON**'
- en: 'In this section, you used the requests library to retrieve the JSON formatted
    data and then used the `json.loads()` method to parse it into a Python object.
    This technique works fine, but because the requests library is used so often for
    exactly this purpose, the library provides a shortcut: The response object actually
    has a `json()` method that does that conversion for you. So in the example, instead
    of'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你使用了 requests 库来检索 JSON 格式的数据，然后使用 `json.loads()` 方法将其解析为 Python 对象。这种技术效果不错，但由于
    requests 库经常用于此目的，因此库提供了一个快捷方式：响应对象实际上有一个 `json()` 方法，它会为你完成这个转换。所以在这个例子中，你不需要这样做：
- en: '[PRE11]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: you could have used
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你本可以使用
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The result is the same, but the code is simpler, more readable, and more Pythonic.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 结果相同，但代码更简单、更易读、更符合 Python 风格。
- en: '|  |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'If you want to write JSON to a file or serialize it to a string, the reverse
    of `load()` and `loads()` is `dump()` and `dumps()`. `json.dump()` takes a file
    object with a `write()` method as a parameter, and `json.dumps()`returns a string.
    In both cases, the encoding to a JSON formatted string can be highly customized,
    but the default is still based on [table 22.1](#ch22table01). So if you want to
    write your Martian weather report to a JSON file, you could do this:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要将 JSON 写入文件或将其序列化为字符串，`load()` 和 `loads()` 的逆操作是 `dump()` 和 `dumps()`。`json.dump()`
    函数接受一个带有 `write()` 方法的文件对象作为参数，而 `json.dumps()` 返回一个字符串。在这两种情况下，将编码为 JSON 格式字符串的过程可以高度定制，但默认仍然基于
    [表 22.1](#ch22table01)。所以，如果你想将你的火星天气报告写入 JSON 文件，你可以这样做：
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As you can see, the entire object has been encoded as a single string. Here
    again, it might be handy to format the string in a more readable way, just as
    you did by using the `pprint` module. To do so easily, use the `indent` parameter
    with the `dump` or `dumps` function:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，整个对象都被编码为单个字符串。在这里，再次可能需要以更可读的方式格式化字符串，就像你使用 `pprint` 模块所做的那样。为了轻松做到这一点，使用
    `indent` 参数与 `dump` 或 `dumps` 函数一起使用：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You should be aware, however, that if you use repeated calls to `json.dump()`
    to write a series of objects to a file, the result is a *series* of legal JSON-formatted
    objects, but the contents of the file *as a whole* is *not* a legal JSON-formatted
    object, and attempting to read and parse the entire file by using a single call
    to `json.load()` will fail. If you have more than one object that you’d like to
    encode as a single JSON object, you need to put all those objects into a list
    (or, better still, an object) and then encode that item to the file.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该意识到，然而，如果你使用重复调用`json.dump()`将一系列对象写入文件，结果是*一系列*合法的JSON格式对象，但文件*整体*的内容*不是*一个合法的JSON格式对象，并且尝试通过单次调用`json.load()`来读取和解析整个文件将会失败。如果你有多个对象想要编码成一个单一的JSON对象，你需要将这些对象全部放入一个列表（或者，更好的是，一个对象）中，然后将这个项目编码到文件中。
- en: 'If you have two or more days’ worth of Martian weather data that you want to
    store as JSON, you have to make a choice. You could use `json.dump()`once for
    each object, which would result in a file containing JSON-formatted objects. If
    you assume that `weather_list` is a list of weather-report objects, the code might
    look like this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有两三天火星天气数据想要存储为JSON，你必须做出选择。你可以为每个对象使用一次`json.dump()`，这将导致包含JSON格式对象的文件。如果你假设`weather_list`是一个天气报告对象的列表，代码可能看起来像这样：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'If you do this, then you need to load each line as a separate JSON-formatted
    object:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你这样做，那么你需要将每一行作为单独的JSON格式对象加载：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As an alternative, you could put the list into a single JSON object. Because
    there’s a possible vulnerability with top-level arrays in JSON, the recommended
    way is to put the array in a dictionary:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一种选择，你可以将列表放入一个单一的JSON对象中。因为JSON中顶层数组的可能存在漏洞，推荐的方式是将数组放入一个字典中：
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'With this approach, you can use one operation to load the JSON-formatted object
    from the file:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，你可以使用一个操作从文件中加载JSON格式的对象：
- en: '[PRE18]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The second approach is fine if the size of your JSON files is manageable, but
    it may be less than ideal for very large files, because handling errors may be
    a bit harder and you may run out of memory.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法如果JSON文件的大小可管理，那么是可行的，但对于非常大的文件来说可能不是最佳选择，因为处理错误可能有点困难，你可能会耗尽内存。
- en: '|  |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'Try this: Saving some JSON crime data'
  id: totrans-108
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 尝试这样做：保存一些JSON犯罪数据
- en: Modify the code you wrote in [section 22.2](#ch22lev1sec2) to fetch the Chicago
    crime data. Then convert the fetched data from a JSON-formatted string to a Python
    object. Next, see whether you can save the crime events as a series of separate
    JSON objects in one file and as one JSON object in another file. Then see what
    code is needed to load each file.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 修改你在[第22.2节](#ch22lev1sec2)中编写的代码以获取芝加哥犯罪数据。然后将获取的数据从JSON格式字符串转换为Python对象。接下来，看看你是否可以将犯罪事件作为一系列单独的JSON对象保存到一个文件中，以及作为单个JSON对象保存到另一个文件中。然后看看加载每个文件所需的代码。
- en: '|  |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 22.3.2\. XML data
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 22.3.2. XML数据
- en: XML (eXtensible Markup Language) has been around since the end of the 20th century.
    XML uses an angle-bracket tag notation similar to HTML, and elements are nested
    within other elements to form a tree structure. XML was intended to be readable
    by both machines and humans, but XML is often so verbose and complex that it’s
    very difficult for people to understand. Nevertheless, because XML is an established
    standard, it’s quite common to find data in XML format. And although XML is machine-readable,
    it’s very likely that you’ll want to translate it into something a bit easier
    to deal with.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: XML（可扩展标记语言）自20世纪末以来一直存在。XML使用类似于HTML的尖括号标签符号，元素嵌套在其他元素中形成树结构。XML旨在被机器和人类阅读，但由于XML通常非常冗长和复杂，因此人们很难理解。尽管如此，由于XML是一个既定的标准，因此在XML格式中找到数据是很常见的。尽管XML是机器可读的，但你很可能希望将其转换为更容易处理的东西。
- en: 'Take a look at some XML data, in this case the XML version of weather data
    for Chicago:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下一些XML数据，在这个例子中是芝加哥天气数据的XML版本：
- en: '[PRE19]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This example is just the first section of the document, with most of the data
    omitted. Even so, it illustrates some of the issues you typically find in XML
    data. In particular, you can see the verbose nature of the protocol, with the
    tags in some cases taking more space than the value contained in them. This sample
    also shows the nested or tree structure common in XML, as well as the common use
    of a sizeable header of metadata before the actual data begins. On a spectrum
    from simple to complex for data files, you could think of CSV or delimited files
    as being at the simple end and XML at the complex end.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子只是文档的第一部分，省略了大部分数据。即便如此，它也说明了你在XML数据中通常会遇到的一些问题。特别是，你可以看到协议的冗长性质，在某些情况下，标签所占的空间比它们包含的值还要多。这个样本还展示了XML中常见的嵌套或树结构，以及在实际数据开始之前使用大量元数据作为标题的常见做法。从简单到复杂的数据文件来看，你可以将CSV或定界文件视为简单端，而XML视为复杂端。
- en: 'Finally, this file illustrates another feature of XML that makes pulling data
    a bit more of a challenge. XML supports the use of attributes to store data as
    well as the text values within the tags. So if you look at the point element at
    the bottom of this sample, you see that the `point` element doesn’t have a text
    value. That element has just latitude and longitude values within the `<point>`
    tag itself:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个文件展示了XML的另一个特性，这使得提取数据变得更加具有挑战性。XML支持使用属性来存储数据，以及标签内的文本值。所以如果你查看这个样本底部的`point`元素，你会看到`point`元素没有文本值。该元素在`<point>`标签内部只包含经纬度值：
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This code is certainly legal XML, and it works for storing the data, but it
    would also be possible (likely, even) for the same data to be stored as
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码无疑是合法的XML，并且可以用来存储数据，但同样有可能（甚至很可能）以相同的方式存储相同的数据
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You really don’t know which way any given bit of data will be handled without
    carefully inspecting the data or studying a specification document.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 没有仔细检查数据或研究规范文档，你真的不知道任何给定数据位将被如何处理。
- en: This kind of complexity can make simple data extraction from XML more of a challenge.
    You have several ways to handle XML. The Python standard library comes with modules
    that parse and handle XML data, but none of them is particularly convenient for
    simple data extraction.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这种复杂性可能会使得从XML中提取简单数据变得更加具有挑战性。你有几种处理XML的方法。Python标准库包含解析和处理XML数据的模块，但没有一个特别适合简单的数据提取。
- en: For simple data extraction, the handiest utility I’ve found is a library called
    `xmltodict`, which parses your XML data and returns a dictionary that reflects
    the tree. In fact, behind the scenes it uses the standard library’s expat XML
    parser, parses your XML document into a tree, and uses that tree to create the
    dictionary. As a result, `xmltodict` can handle whatever the parser can, and it’s
    also able to take a dictionary and “unparse” it to XML if necessary, making it
    a very handy tool. Over several years of use, I found this solution to be up to
    all my XML handling needs. To get `xmltodict`, you can again use `pip install
    xmltodict`.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 对于简单的数据提取，我发现最方便的实用工具是一个名为`xmltodict`的库，它解析你的XML数据并返回一个反映树的字典。实际上，在幕后它使用标准库的expat
    XML解析器，将你的XML文档解析成树，并使用该树来创建字典。因此，`xmltodict`可以处理解析器可以处理的所有内容，并且它还能在必要时将字典“反解析”为XML，使其成为一个非常方便的工具。在多年的使用中，我发现这个解决方案完全满足我的XML处理需求。要获取`xmltodict`，你可以再次使用`pip
    install xmltodict`。
- en: 'To convert the XML to a dictionary, you can import `xmltodict` and use the
    `parse` method on an XML formatted string:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要将XML转换为字典，你可以导入`xmltodict`并使用XML格式字符串上的`parse`方法：
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In this case, for compactness, pass the contents of the file directly to the
    `parse` method. After being parsed, this data object is an ordered dictionary
    with the same values it would have if it had been loaded from this JSON:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，为了简洁，直接将文件内容传递给`parse`方法。解析后，这个数据对象是一个有序字典，其值与如果从该JSON加载的值相同：
- en: '[PRE23]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Notice that the attributes have been pulled out of the tags, but with an `@`
    prepended to indicate that they were originally attributes of their parent tag.
    If an XML node has both a text value and a nested element in it, notice that the
    key for the text value is `"#text"`, as in the `"sub-center"` element under `"production-center"`.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，属性已经被从标签中提取出来，但前面加上了`@`符号来表示它们原本是其父标签的属性。如果一个XML节点既有文本值又有嵌套元素，请注意文本值的键是`"#text"`，就像在`"production-center"`元素下的`"sub-center"`元素一样。
- en: 'Earlier, I said that the result of parsing is an *ordered dictionary* (officially,
    an `OrderedDict`), so if you print it, the code looks like this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我说过，解析的结果是一个*有序字典*（官方名称为`OrderedDict`），所以如果你打印它，代码看起来就像这样：
- en: '[PRE24]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Even though the representation of an `OrderedDict`, with its lists of tuples,
    looks rather strange, it behaves exactly the same way as a normal `dict` except
    that it promises to maintain the order of elements, which is useful in this case.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 即使`OrderedDict`及其元组的列表表示看起来相当奇怪，但它的行为与正常的`dict`完全相同，只是它承诺保持元素的顺序，这在这种情况下很有用。
- en: 'If an element is repeated, it becomes a list. In a further section of the full
    version of the file shown previously the following element occurs (some elements
    omitted from this sample):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个元素被重复，它就变成了一个列表。在之前显示的文件的完整版本的一个进一步部分中，以下元素出现（一些元素被省略在这个样本中）：
- en: '[PRE25]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Note that two elements—“`start-valid-time`” and “`end-valid-time`”—repeat in
    alternation. These two repeating elements are each translated to a list in the
    dictionary, keeping each set of elements in their proper order:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，两个元素——“`start-valid-time`”和“`end-valid-time`”——交替重复。这两个重复的元素在字典中各自被转换成列表，保持每组元素的正确顺序：
- en: '[PRE26]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Because dictionaries and lists, even nested dictionaries and lists, are fairly
    easy to deal with in Python, using `xmltodict` is an effective way to handle most
    XML. In fact, I’ve used it for the past several years in production on a variety
    of XML documents and never had a problem.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在Python中处理字典和列表（即使是嵌套的字典和列表）相对容易，因此使用`xmltodict`是处理大多数XML的有效方法。实际上，我在过去几年中在生产环境中使用它处理了各种XML文档，从未遇到过问题。
- en: '|  |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Try this: Fetching and Parsing XML'
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 尝试这样做：获取和解析XML
- en: 'Write the code to pull the Chicago XML weather forecast from [http://mng.bz/103V](http://mng.bz/103V).
    Then use `xmltodict` to parse the XML into a Python dictionary and extract tomorrow’s
    forecast maximum temperature. Hint: To match up time layouts and values, compare
    the layout-key value of the first time-layout section and the time-layout attribute
    of the temperature element of the parameters element.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 编写代码以从[http://mng.bz/103V](http://mng.bz/103V)获取芝加哥XML天气预报。然后使用`xmltodict`将XML解析成Python字典，并提取明天的最高温度预报。提示：为了匹配时间布局和值，比较第一个时间布局部分的布局-key值和参数元素中温度元素的time-layout属性。
- en: '|  |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 22.4\. Scraping web data
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 22.4. 爬取网页数据
- en: In some cases, the data is on a website but for whatever reason isn’t available
    anywhere else. In those situations, it may make sense to collect the data from
    the web pages themselves through a process called *crawling* or *scraping*.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，数据在网站上，但由于某种原因在其他地方不可用。在这些情况下，可能有必要通过称为*爬取*或*抓取*的过程从网页本身收集数据。
- en: 'Before saying anything more about scraping, let me make a disclaimer: Scraping
    or crawling websites that you don’t own or control is at best a legal grey area,
    with a host of inconclusive and contradictory considerations involving things
    such as the terms of use of the site, the way in which the site is accessed, and
    the use to which the scraped data is put. Unless you have control of the site
    you want to scrape, the answer to the question “Is it legal for me to scrape this
    site?” usually is “It depends.”'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步讨论爬取之前，让我先声明一下：爬取或抓取你并不拥有或控制的网站，在最好的情况下也是一个法律灰色地带，涉及许多不明确且相互矛盾的考虑因素，例如网站的条款、访问网站的方式以及抓取数据的用途。除非你控制你想爬取的网站，否则对于“我爬取这个网站是否合法？”这个问题，通常的回答是“这取决于。”
- en: If you do decide to scrape a production website, you also need to be sensitive
    to the load you’re putting on the site. Although an established, high-traffic
    site might well be able to handle anything you can throw at it, a smaller, less-active
    site might be brought to a standstill by a series of continuous requests. At the
    very least, you need to be careful that your scraping doesn’t turn into an inadvertent
    denial-of-service attack.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你确实决定爬取一个生产网站，你还需要对你在网站上施加的负载保持敏感。虽然一个建立已久、流量大的网站可能能够处理你扔给它的任何东西，但一个较小、不太活跃的网站可能会因为一系列连续的请求而陷入停滞。至少，你需要小心，确保你的爬取不会变成一个无意的拒绝服务攻击。
- en: Conversely, I’ve worked in situations in which it was actually easier to scrape
    our own website to get some needed data than it was to go through corporate channels.
    Although scraping web data has its place, it’s too complex for full treatment
    here. In this section, I present a very simple example to give you a general idea
    of the basic method and follow up with suggestions to pursue in more complex cases.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我曾在某些情况下发现，爬取我们自己的网站以获取一些所需数据实际上比通过公司渠道更容易。尽管爬取网络数据有其位置，但在这里全面处理它过于复杂。在本节中，我提供了一个非常简单的例子，以给你一个基本方法的一般概念，并在更复杂的情况下提供进一步的建议。
- en: 'Scraping a website consists of two parts: fetching the web page and extracting
    the data from it. Fetching the page can be done via requests and is fairly simple.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 爬取网站包括两个部分：获取网页和从中提取数据。获取页面可以通过请求完成，这相当简单。
- en: Consider the code of a very simple web page with only a little content and no
    CSS or JavaScript, as this one.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个非常简单的网页的代码，内容很少，没有CSS或JavaScript，就像这样。
- en: Listing 22.1\. File test.html
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表22.1\. 文件test.html
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Suppose that you’re interested in only a couple of kinds of data from this
    page: anything in an element with a class name of `"special"` and any links. You
    can process the file by searching for the strings `''class="special"''` and `"<a
    href"` and then write code to pick out the data from there, but even using regular
    expressions, this process will be tedious, bug-prone, and hard to maintain. It’s
    much easier to use a library that knows how to parse HTML, such as Beautiful Soup.
    If you want to try the following code and experiment with parsing HTML pages,
    you can use `pip install bs4`.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你只对这个页面上的几种数据感兴趣：任何具有`"special"`类名的元素以及任何链接。你可以通过搜索字符串`'class="special"'`和`"<a
    href"`来处理文件，然后编写代码从那里挑选数据，但即使使用正则表达式，这个过程也会很繁琐，容易出错，难以维护。使用知道如何解析HTML的库，如Beautiful
    Soup，会容易得多。如果你想尝试以下代码并实验解析HTML页面，可以使用`pip install bs4`。
- en: When you have Beautiful Soup installed, parsing a page of HTML is simple. For
    this example, assume that you’ve already retrieved the web page (presumably, using
    the requests library), so you’ll just parse the HTML.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当你安装了Beautiful Soup后，解析HTML页面就变得简单了。在这个例子中，假设你已经获取了网页（可能使用requests库），所以你只需解析HTML。
- en: 'The first step is to load the text and create a Beautiful Soup parser:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是加载文本并创建Beautiful Soup解析器：
- en: '[PRE28]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This code is all it takes to parse the HTML into the parser object `bs`. A
    Beautiful Soup parser object has a lot of cool tricks, and if you’re working with
    HTML at all, it’s really worth your time to experiment a bit and get a feel for
    what it can do for you. For this example, you look at only two things: extracting
    content by HTML tag and getting data by CSS class.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是将HTML解析到解析器对象`bs`所需的全部代码。Beautiful Soup解析器对象有很多酷炫的技巧，如果你在处理HTML，花点时间去实验并了解它能为你做什么是非常值得的。在这个例子中，你只看两件事：通过HTML标签提取内容以及通过CSS类获取数据。
- en: 'First, find the link. The HTML tag for a link is `<a>` (Beautiful Soup by default
    converts all tags to lowercase), so to find all link tags, you can use the `"a"`
    as a parameter and call the `bs` object itself:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，找到链接。链接的HTML标签是`<a>`（Beautiful Soup默认将所有标签转换为小写），所以为了找到所有链接标签，你可以使用`"a"`作为参数并调用`bs`对象本身：
- en: '[PRE29]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now you have a list of all (one in this case) of the HTML link tags. If that
    list is all you get, that’s not so bad, but in fact, the elements returned in
    the list are also parser objects and can do the rest of the work of getting the
    link and text for you:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有一个包含所有（在这个例子中只有一个）HTML链接标签的列表。如果这就是你得到的所有内容，那倒也还不错，但实际上，列表中返回的元素也是解析器对象，并且可以为你完成获取链接和文本的其余工作：
- en: '[PRE30]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The other feature you’re looking for is anything with a CSS class of `"special"`,
    which you can extract by using the parser’s `select` method as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你正在寻找的另一个功能是任何具有`"special"`CSS类的元素，你可以通过使用解析器的`select`方法如下提取：
- en: '[PRE31]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Because the items returned by the tag or by the `select` method are themselves
    parser objects, you can nest them, which allows you to extract just about anything
    from HTML or even XML.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 因为标签或`select`方法返回的项目本身就是解析器对象，所以你可以嵌套它们，这允许你从HTML甚至XML中提取几乎所有内容。
- en: '|  |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'Try this: Parsing HTML'
  id: totrans-162
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 尝试这个：解析HTML
- en: Given the file forecast.html (which you can find in the code on this book’s
    website), write a script using Beautiful Soup that extracts the data and saves
    it as a CSV file, shown here.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 给定文件`forecast.html`（你可以在本书的网站上找到该代码），编写一个使用Beautiful Soup提取数据并将其保存为CSV文件的脚本，如下所示。
- en: '|  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: Listing 22.2\. File forecast.html
  id: totrans-165
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 22.2\. 文件 forecast.html
- en: '[PRE32]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '|  |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'Lab 22: Track Curiosity’s Weather'
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 实验 22：跟踪“好奇号”的天气
- en: 'Use the API described in [section 22.2](#ch22lev1sec2) to gather a weather
    history of *Curiosity*’s stay on Mars for a month. Hint: You can specify Martian
    days (sols) by adding ?sol=*sol_number* to the end of the archive query, like
    this:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 [第 22.2 节](#ch22lev1sec2) 中描述的 API 来收集“好奇号”在火星上停留一个月的天气历史。提示：你可以通过在存档查询的末尾添加
    ?sol=*sol_number* 来指定火星日（sols），如下所示：
- en: '[http://marsweather.ingenology.com/v1/archive/?sol=155](http://marsweather.ingenology.com/v1/archive/?sol=155)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://marsweather.ingenology.com/v1/archive/?sol=155](http://marsweather.ingenology.com/v1/archive/?sol=155)'
- en: Transform the data so that you can load it into a spreadsheet and graph it.
    For a version of this project, see the book’s source code.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据转换成可以加载到电子表格和绘制图表的形式。有关此项目的版本，请参阅书籍的源代码。
- en: '|  |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Summary
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: Using a Python script may not be the best choice for fetching files. Be sure
    to consider the options.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 脚本来获取文件可能不是最佳选择。请务必考虑其他选项。
- en: Using the `requests` module is your best bet for fetching files by using HTTP/HTTPS
    and Python.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `requests` 模块通过 HTTP/HTTPS 和 Python 获取文件是最佳选择。
- en: Fetching files from an API is very similar to fetching static files.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 API 获取文件与获取静态文件非常相似。
- en: Parameters for API requests often need to be quoted and added as a query string
    to the request URL.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API 请求的参数通常需要引用并作为查询字符串添加到请求 URL 中。
- en: JSON-formatted strings are quite common for data served from APIs, and XML is
    also used.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON 格式的字符串在 API 提供的数据中很常见，XML 也被使用。
- en: Scraping sites that you don’t control may not be legal or ethical and requires
    consideration not to overload the server.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爬取你无法控制的网站可能不合法或不道德，并且需要考虑不要过度负载服务器。
