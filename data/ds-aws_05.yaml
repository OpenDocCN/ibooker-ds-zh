- en: Chapter 5\. Explore the Dataset
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。探索数据集
- en: In the previous chapter, we demonstrated how to ingest data into the cloud with
    Amazon Athena and Redshift. Amazon Athena offers ad hoc, serverless SQL queries
    for data in S3 without needing to set up, scale, and manage any clusters. Amazon
    Redshift provides the fastest query performance for enterprise reporting and business
    intelligence workloads—particularly those involving complex SQL with multiple
    joins and subqueries across many data sources, including relational databases
    and flat files. We created a data-catalog mapping for our S3-based data lake in
    S3 using AWS Glue Catalog. We ran ad hoc queries on our data lake with Athena.
    And we ran queries on our data warehouse with Amazon Redshift.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一章中，我们演示了如何使用Amazon Athena和Redshift将数据导入到云中。Amazon Athena提供无服务器的即席SQL查询，用于处理S3中的数据，无需设置、扩展和管理任何集群。Amazon
    Redshift提供企业报告和商业智能工作负载的最快查询性能，特别是涉及到复杂SQL、跨多个数据源（包括关系数据库和平面文件）的多个连接和子查询的情况。我们使用AWS
    Glue Catalog在S3中创建了基于数据湖的数据目录映射。我们使用Athena在我们的数据湖上运行了即席查询。我们使用Amazon Redshift在我们的数据仓库上运行了查询。
- en: 'We also had a first peek into our dataset. As we’ve learned, the Amazon Customer
    Reviews Dataset consists of more than 150+ million of those customer reviews of
    products across 43 different product categories on the Amazon.com website from
    1995 until 2015\. The dataset contains the actual customer reviews text together
    with additional metadata. It comes in two formats: row-based tab-separated values
    (TSV) and column-based Apache Parquet.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还初步了解了我们的数据集。正如我们所了解的，亚马逊顾客评论数据集包含自1995年至2015年在亚马逊网站上对超过150+万个产品的43个不同产品类别的客户评论。数据集包含实际的客户评论文本以及附加的元数据。数据集有两种格式：基于行的制表符分隔值（TSV）和基于列的Apache
    Parquet。
- en: In this chapter, we will use the SageMaker Studio integrated development environment
    (IDE) as our main workspace for data analysis and the model development life cycle.
    SageMaker Studio provides fully managed Jupyter Notebook servers. With just a
    couple of clicks, we can provision the SageMaker Studio IDE and start using Jupyter
    notebooks to run ad hoc data analysis and launch Apache Spark–based data-quality
    jobs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用SageMaker Studio集成开发环境（IDE）作为我们的主要工作空间，用于数据分析和模型开发生命周期。SageMaker Studio提供完全托管的Jupyter
    Notebook服务器。只需点击几下，我们就可以配置SageMaker Studio IDE并开始使用Jupyter notebooks进行即席数据分析和启动基于Apache
    Spark的数据质量作业。
- en: We will use SageMaker Studio throughout the rest of the book to launch data
    processing and feature engineering jobs in [Chapter 6](ch06.html#prepare_the_dataset_for_model_training),
    train models in [Chapter 7](ch07.html#train_your_first_model), optimize models
    in [Chapter 8](ch08.html#train_and_optimize_models_at_scale), deploy models in
    [Chapter 9](ch09.html#deploy_models_to_production), build pipelines in [Chapter 10](ch10.html#pipelines_and_mlops),
    develop streaming applications in [Chapter 11](ch11.html#streaming_analytics_and_machine_lear),
    and secure our data science projects in [Chapter 12](ch12.html#secure_data_science_on_aws).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书的其余部分使用SageMaker Studio启动数据处理和特征工程作业，如[第6章](ch06.html#prepare_the_dataset_for_model_training)中的数据准备，[第7章](ch07.html#train_your_first_model)中的模型训练，[第8章](ch08.html#train_and_optimize_models_at_scale)中的模型优化，[第9章](ch09.html#deploy_models_to_production)中的模型部署，[第10章](ch10.html#pipelines_and_mlops)中的流水线构建，[第11章](ch11.html#streaming_analytics_and_machine_lear)中的流处理应用以及[第12章](ch12.html#secure_data_science_on_aws)中的数据科学项目安全性。
- en: Let’s explore our dataset in more depth and analyze our data for correlations,
    anomalies, bias, imbalances, and useful business insights. The knowledge from
    this data analysis and exploration will prepare us for data bias, feature selection,
    and feature engineering in [Chapter 6](ch06.html#prepare_the_dataset_for_model_training)
    as well as model bias, fairness, and explainability analysis in Chapters [7](ch07.html#train_your_first_model)
    and [9](ch09.html#deploy_models_to_production).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地探索我们的数据集，分析数据的相关性、异常、偏见、不平衡和有用的业务见解。这些数据分析和探索的知识将为我们在[第6章](ch06.html#prepare_the_dataset_for_model_training)中的数据偏见、特征选择和特征工程，以及在第[7章](ch07.html#train_your_first_model)和第[9章](ch09.html#deploy_models_to_production)中的模型偏见、公平性和可解释性分析做准备。
- en: Tools for Exploring Data in AWS
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在AWS中探索数据的工具
- en: Let’s introduce some tools and services that will assist us in our data exploration
    task. In order to choose the right tool for the right purpose, we will describe
    the breadth and depth of tools available within AWS and use these tools to answer
    questions about our Amazon Customer Reviews Dataset.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们介绍一些工具和服务，这些工具和服务将帮助我们完成数据探索任务。为了选择正确的工具以实现正确的目的，我们将描述AWS中可用的工具的广度和深度，并使用这些工具来回答有关我们的Amazon
    Customer Reviews数据集的问题。
- en: To interact with AWS resources from Jupyter notebooks running within SageMaker
    Studio IDE, we leverage the AWS Python SDK [Boto3](https://oreil.ly/byebi) and
    the Python DB client [PyAthena](https://oreil.ly/DTQS8) to connect to Athena,
    the Python SQL toolkit [SQLAlchemy](https://oreil.ly/q0DC0) to connect to Amazon
    Redshift, and the open source [AWS Data Wrangler library](https://oreil.ly/rUvry)
    to facilitate data movement between pandas and Amazon S3, Athena, Redshift, Glue,
    and EMR.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 要从运行在SageMaker Studio IDE中的Jupyter笔记本与AWS资源进行交互，我们利用AWS Python SDK [Boto3](https://oreil.ly/byebi)
    和Python DB客户端 [PyAthena](https://oreil.ly/DTQS8) 连接到Athena，Python SQL工具包 [SQLAlchemy](https://oreil.ly/q0DC0)
    连接到Amazon Redshift，以及开源的 [AWS Data Wrangler library](https://oreil.ly/rUvry) 用于在pandas和Amazon
    S3、Athena、Redshift、Glue和EMR之间进行数据移动。
- en: Tip
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The open source [AWS Data Wrangler library](https://oreil.ly/5Eq4H) is not related
    to SageMaker Data Wrangler. This is an unfortunate name clash. AWS Data Wrangler
    is focused on general data ingestion into—and between—AWS storage services like
    Amazon S3, Athena, Redshift, etc., while SageMaker Data Wrangler is focused on
    ML-based data ingestion, analysis, and transformation for reproducible pipelines.
    We will describe SageMaker Data Wrangler in more detail later in this chapter
    and describe when to use one over the other.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 开源的 [AWS Data Wrangler library](https://oreil.ly/5Eq4H) 与SageMaker Data Wrangler无关。这是一个不幸的名称冲突。AWS
    Data Wrangler专注于将数据引入和在AWS存储服务（如Amazon S3、Athena、Redshift等）之间移动，而SageMaker Data
    Wrangler专注于基于ML的数据引入、分析和转换，以便可重复使用的流水线。我们稍后在本章中将更详细地描述SageMaker Data Wrangler，并描述何时使用其中之一。
- en: Amazon EMR supports flexible, highly distributed, data-processing and analytics
    frameworks such as Apache Spark and Hadoop. Amazon EMR is a managed service with
    automated cluster setup and autoscaling and supports Spot Instances. Amazon EMR
    lets us run custom jobs with specific compute, memory, and storage parameters
    to optimize our analytics queries. Amazon EMR Studio is a unified IDE for data
    processing on AWS. SageMaker Studio also supports Amazon EMR through EMR-specific
    Jupyter kernels, including PySpark.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon EMR支持灵活的、高度分布式的数据处理和分析框架，如Apache Spark和Hadoop。Amazon EMR是一个托管服务，具有自动化的集群设置和自动缩放功能，并支持Spot实例。Amazon
    EMR允许我们运行具有特定计算、内存和存储参数的自定义作业，以优化我们的分析查询。Amazon EMR Studio是AWS上的统一IDE，用于数据处理。SageMaker
    Studio也通过EMR特定的Jupyter内核支持Amazon EMR。
- en: QuickSight is a fast, easy-to-use business intelligence service to build visualizations,
    perform ad hoc analysis, and build dashboards from many data sources—across many
    devices.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: QuickSight是一项快速、易于使用的业务智能服务，可从多个数据源（跨多个设备）构建可视化、执行即席分析并构建仪表板。
- en: Visualize Our Data Lake with SageMaker Studio
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SageMaker Studio可视化我们的数据湖
- en: 'In this section, we will start working with the Amazon SageMaker Studio IDE,
    which provides us with managed Jupyter notebooks. We will use the Amazon Customer
    Reviews Dataset which we introduced in [Chapter 4](ch04.html#ingest_data_into_the_cloud).
    Here’s another quick overview of the dataset schema:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将开始使用Amazon SageMaker Studio IDE，该IDE为我们提供托管的Jupyter笔记本。我们将使用我们在[第四章](ch04.html#ingest_data_into_the_cloud)介绍的Amazon
    Customer Reviews数据集。以下是数据集模式的快速概述：
- en: marketplace
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: marketplace
- en: Two-letter country code (in this case, just “US”).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 两位字母国家代码（在本例中仅为“US”）。
- en: customer_id
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: customer_id
- en: Random identifier used to aggregate reviews written by a single author.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 用于聚合单个作者撰写的评论的随机标识符。
- en: review_id
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: review_id
- en: Unique ID for the review.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 评论的唯一ID。
- en: product_id
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: product_id
- en: Amazon Standard Identification Number (ASIN).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊标准识别号（ASIN）。
- en: product_parent
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: product_parent
- en: Multiple ASINs (variations of the same product) can roll up into a single parent.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 多个ASIN（同一产品的变体）可以汇总为一个父级。
- en: product_title
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: product_title
- en: Title description of the product.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 产品的标题描述。
- en: product_category
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 产品类别
- en: Broad product category used to group reviews.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 广泛的产品类别用于组织评论。
- en: star_rating
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 星级评分
- en: The review’s rating of 1 to 5 stars, where 1 is the worst and 5 is the best.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 评论的评级从1到5星，其中1星是最差，5星是最好。
- en: helpful_votes
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 有用投票数
- en: Number of helpful votes for the review.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对评论的有用投票数。
- en: total_votes
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: total_votes
- en: Total number of votes for the review.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 评论的总票数。
- en: vine
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: vine
- en: Was the review written as part of the Vine program?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 评论是否作为 Vine 计划的一部分编写？
- en: verified_purchase
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: verified_purchase
- en: Was the review from a verified purchase?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 评论是否来自已验证购买？
- en: review_headline
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: review_headline
- en: Title of the review.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 评论的标题。
- en: review_body
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: review_body
- en: Actual text of the review.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 实际评论文本。
- en: review_date
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: review_date
- en: Date the review was submitted.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 评论提交日期。
- en: Prepare SageMaker Studio to Visualize Our Dataset
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备 SageMaker Studio 以可视化我们的数据集
- en: 'For our exploratory data analysis in this Jupyter notebook, we will use [pandas](https://pandas.pydata.org),
    [NumPy](https://numpy.org), [Matplotlib](https://matplotlib.org), and [Seaborn](https://oreil.ly/ysj3B),
    which are probably the most commonly used libraries for data analysis and data
    visualization in Python. Seaborn is built on top of Matplotlib, adds support for
    pandas, and offers more advanced visualizations with a streamlined API. We will
    also use [PyAthena](https://oreil.ly/d5wwh), the Python DB Client for Amazon Athena,
    to run Athena queries right from our notebook:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本 Jupyter 笔记本中进行探索性数据分析时，我们将使用 [pandas](https://pandas.pydata.org)，[NumPy](https://numpy.org)，[Matplotlib](https://matplotlib.org)
    和 [Seaborn](https://oreil.ly/ysj3B)，这些库可能是 Python 中最常用的用于数据分析和数据可视化的库。Seaborn
    基于 Matplotlib 构建，增加了对 pandas 的支持，并通过简化的 API 提供了更高级的可视化功能。我们还将使用 [PyAthena](https://oreil.ly/d5wwh)，这是
    Amazon Athena 的 Python 数据库客户端，可以直接从我们的笔记本中运行 Athena 查询：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Tip
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: When using a Mac with a Retina display, make sure to specify the `retina` setting
    for much higher-resolution images with Matplotlib on a Mac.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用具有 Retina 显示的 Mac 时，请确保在 Matplotlib 上指定 `retina` 设置，以获得更高分辨率的图像。
- en: 'Let’s define the database and table holding our Amazon Customer Reviews Dataset
    information in Amazon Athena:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Amazon Athena 中定义包含我们的亚马逊客户评论数据集信息的数据库和表：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: With that, we are now ready to run our first SQL queries right from the notebook.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已准备好从笔记本中直接运行我们的第一个 SQL 查询了。
- en: Run a Sample Athena Query in SageMaker Studio
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 SageMaker Studio 中运行示例 Athena 查询
- en: 'In the first example shown in the following, we will query our dataset to give
    us a list of the distinct product categories. PyAthena sets up a connection to
    the data source. We will then execute SQL commands with pandas, passing the SQL
    statement to execute and the PyAthena connection object:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下显示的第一个示例中，我们将查询数据集以获取不同产品类别的列表。PyAthena 建立了与数据源的连接。然后我们将使用 pandas 执行 SQL
    命令，将 SQL 语句传递给执行和 PyAthena 连接对象：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here is the result of the `read_sql()` call that queries all product categories:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这是查询所有产品类别的 `read_sql()` 调用结果：
- en: '| product_category | product_category (continued) |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 产品类别 | 产品类别（续） |'
- en: '| --- | --- |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Apparel | Luggage |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 行李 |'
- en: '| Automotive | Major Appliances |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 大型家电 |'
- en: '| Baby | Mobile_Apps |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 婴儿 | 移动应用 |'
- en: '| Beauty | Mobile_Electronics |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 美容 | 移动电子产品 |'
- en: '| Books | Music |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 书籍 | 音乐 |'
- en: '| Camera | Musical Instruments |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 相机 | 音乐乐器 |'
- en: '| Digital_Ebook_Purchase | Office Products |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 数字电子书购买 | 办公用品 |'
- en: '| Digital_Music_Purchase | Outdoors |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 数字音乐购买 | 户外 |'
- en: '| Digital_Software | PC |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 数字软件 | 个人电脑 |'
- en: '| Digital_Video_Download | Personal_Care_Appliances |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 数字视频下载 | 个人护理电器 |'
- en: '| Digital_Video_Games | Pet Products |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 数字视频游戏 | 宠物产品 |'
- en: '| Electronics | Shoes |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 电子产品 | 鞋类 |'
- en: '| Furniture | Software |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 家具 | 软件 |'
- en: '| Gift Card | Sports |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 礼品卡 | 运动 |'
- en: '| Grocery | Tools |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 食品杂货 | 工具 |'
- en: '| Health & Personal Care | Toys |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 健康与个人护理 | 玩具 |'
- en: '| Home | Video |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 家 | 视频 |'
- en: '| Home Entertainment | Video DVD |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 家庭娱乐 | 视频 DVD |'
- en: '| Home Improvement | Video Games |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 家庭装修 | 视频游戏 |'
- en: '| Jewelry | Watches |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 珠宝 | 手表 |'
- en: '| Kitchen | Wireless |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 厨房 | 无线 |'
- en: '| Lawn and Garden |   |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 草坪和花园 |   |'
- en: Note
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We may need to use pandas cursors if we are working with a large dataset that
    exceeds the memory available to the notebook server. Pay attention to the file
    size when reading data into the DataFrame. We can easily exceed available memory
    when working with large datasets.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们处理的数据集过大，超过笔记本服务器可用的内存，我们可能需要使用 pandas 游标。在读取数据进 DataFrame 时要注意文件大小。处理大数据集时，很容易超出可用内存。
- en: Dive Deep into the Dataset with Athena and SageMaker
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入研究 Athena 和 SageMaker 中的数据集
- en: We need to understand our data in order to prepare for the next steps of feature
    selection and feature engineering. We will run queries across the data to learn
    about data correlations, identify data anomalies, and class imbalances.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要了解我们的数据，以便为特征选择和特征工程的下一步准备。我们将跨数据运行查询，了解数据相关性，识别数据异常和类别不平衡。
- en: 'Let’s use Athena, SageMaker Studio, Matplotlib, and Seaborn to track down answers
    to the following questions over the entire dataset:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Athena、SageMaker Studio、Matplotlib和Seaborn来跟踪整个数据集中以下问题的答案：
- en: Which product categories are the highest rated by average rating?
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些产品类别的平均评分最高？
- en: Which product categories have the most reviews?
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些产品类别有最多的评论？
- en: When did each product category become available in the Amazon catalog based
    on the date of the first review?
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据首次评论日期，每个产品类别何时在Amazon目录中可用？
- en: What is the breakdown of star ratings (1–5) per product category?
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个产品类别的星级评分（1–5）分布如何？
- en: How have the star ratings changed over time? Is there a drop-off point for certain
    product categories throughout the year?
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 产品类别的星级评分如何随时间变化？某些产品类别在年内是否存在评分下降点？
- en: Which star ratings (1–5) are the most helpful?
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些星级评分（1–5）最有帮助？
- en: What is the distribution of review lengths (number of words)?
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评论长度（字数）的分布是怎样的？
- en: Note
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: From this point, we will only show the Athena query and the results. The full
    source code to execute and render the results is available in the accompanying
    GitHub repo.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从这一点开始，我们只会展示Athena查询和结果。执行和渲染结果的完整源代码可在附带的GitHub存储库中找到。
- en: 1\. Which product categories are the highest rated by average rating?
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 哪些产品类别的平均评分最高？
- en: 'Here is the SQL query that will answer this question:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可以回答这个问题的SQL查询：
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Let’s plot the results in a horizontal bar chart using Seaborn and Matplotlib
    to provide a high-level overview of which product categories are more popular
    than others, on average. We may want to consider this distribution when we select
    our training dataset in the next few chapters.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用Seaborn和Matplotlib绘制水平条形图，以提供哪些产品类别比其他产品类别更受欢迎的高级概述。在接下来的几章中选择我们的训练数据集时，我们可能需要考虑这种分布。
- en: '[Figure 5-1](#amazon_gift_cards_are_the_highest_rated) shows that Amazon Gift
    Cards are the highest-rated product category, with an average star rating of 4.73,
    followed by Music Purchase, with an average of 4.64 and Music, with an average
    of 4.44.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-1](#amazon_gift_cards_are_the_highest_rated)显示Amazon礼品卡是评分最高的产品类别，平均星级为4.73，其次是音乐购买，平均为4.64，以及音乐，平均为4.44。'
- en: '![](assets/dsaw_0501.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0501.png)'
- en: Figure 5-1\. Gift Cards are the highest rated product category at the Amazon.com
    marketplace.
  id: totrans-101
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1\. 在Amazon.com市场上，礼品卡是评分最高的产品类别。
- en: 2\. Which product categories have the most reviews?
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 哪些产品类别有最多的评论？
- en: 'Here is the SQL query that will answer this question:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可以回答这个问题的SQL查询：
- en: '[PRE4]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Let’s plot the result again in a horizontal bar chart using Seaborn and Matplotlib,
    shown in [Figure 5-2](#the_books_product_category_has_close_to).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次使用Seaborn和Matplotlib将结果绘制为水平条形图，显示在[图5-2](#the_books_product_category_has_close_to)中。
- en: '![](assets/dsaw_0502.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0502.png)'
- en: Figure 5-2\. The Books product category has close to 20 million reviews.
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2\. 图书产品类别有接近2000万条评论。
- en: We can see in [Figure 5-2](#the_books_product_category_has_close_to) that the
    “Books” product category has the most reviews, with close to 20 million. This
    makes sense as [Amazon.com initially launched as the “Earth’s Biggest Bookstore”](https://oreil.ly/q11mI)
    back in 1995.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在[图5-2](#the_books_product_category_has_close_to)中看到，“图书”产品类别的评论最多，接近2000万条。这是因为[Amazon.com最初作为“地球上最大的书店”](https://oreil.ly/q11mI)于1995年开始运营。
- en: The second most reviewed category is “Digital_Ebook_Purchase,” representing
    Kindle book reviews. So we notice that book reviews—whether printed or as ebooks—still
    count the most reviews.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 第二评论数量最多的类别是“数字电子书购买”，代表Kindle书籍评论。因此，我们注意到无论是印刷书籍还是电子书籍，书籍评论仍然占据了大多数评论。
- en: “Personal_Care_Appliances” has the least number of reviews. This could potentially
    be due to the fact that the product category was added more recently.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: “个人护理电器”评论数量最少。这可能是因为该产品类别是最近添加的原因。
- en: Let’s check this out by querying for the first review in each category, which
    will give us a rough timeline of product category introductions.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过查询每个类别的第一条评论来检查这一点，这将为我们提供产品类别引入的大致时间表。
- en: 3\. When did each product category become available in the Amazon catalog?
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 每个产品类别何时在Amazon目录中可用？
- en: 'The initial review date is a strong indicator of when each product category
    went live on Amazon.com. Here is the SQL query that will answer this question:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 初审日期是每个产品类别何时在Amazon.com上线的强有力指标。以下是可以回答这个问题的SQL查询：
- en: '[PRE5]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result should look similar to this:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该类似于这样：
- en: '| product_category | first_review_year |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 产品类别 | 首次评论年份 |'
- en: '| --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Books | 1995 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 图书 | 1995 |'
- en: '| Video Games | 1997 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 视频游戏 | 1997 |'
- en: '| Office Products | 1998 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 办公用品 | 1998 |'
- en: '| Pet Products | 1998 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 宠物用品 | 1998 |'
- en: '| Software | 1998 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 软件 | 1998 |'
- en: '| Gift Card | 2004 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 礼品卡 | 2004 |'
- en: '| Digital_Video_Games | 2006 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 数字视频游戏 | 2006 |'
- en: '| Digital_Software | 2008 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 数字软件 | 2008 |'
- en: '| Mobile_Apps | 2010 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 移动应用 | 2010 |'
- en: We can see that personal care appliances were indeed added somewhat later to
    the Amazon.com catalog, but that doesn’t seem to be the only reason for the low
    number of reviews. Mobile apps appear to have been added around 2010.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到个人护理电器确实是稍后添加到Amazon.com目录中的，但这似乎并不是评论数量较低的唯一原因。移动应用似乎是在2010年左右添加的。
- en: Let’s visualize the number of first reviews per category per year, shown in
    [Figure 5-3](#our_dataset_includes_onethree_first_pro).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看每个产品类别每年的首次评论数量，如[图5-3](#our_dataset_includes_onethree_first_pro)所示。
- en: '![](assets/dsaw_0503.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0503.png)'
- en: Figure 5-3\. Our dataset includes 13 first product category reviews in 1999.
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-3\. 我们的数据集包括1999年的13个首次产品类别评论。
- en: We notice that a lot of our first product category reviews (13) happened in
    1999\. Whether this is really related to the introduction of those product categories
    around this time or is just a coincidence created by the available data in our
    dataset, we can’t tell for sure.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到我们的首次产品类别评论中有很多（13条）发生在1999年。无论这是否真的与这些产品类别在此时期的引入有关，还是仅仅是由我们数据集中的可用数据造成的巧合，我们无法确定。
- en: 4\. What is the breakdown of star ratings (1–5) per product category?
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 每个产品类别的星级评分（1-5）的详细情况是什么？
- en: 'Here is the SQL query that will answer this question:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这是能够回答此问题的SQL查询：
- en: '[PRE6]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The result should look similar to this (shortened):'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该与此类似（缩短版）：
- en: '| product_category | star_rating | count_reviews |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 产品类别 | 星级评分 | 评论数量 |'
- en: '| --- | --- | --- |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Apparel | 5 | 3320566 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 5 | 3320566 |'
- en: '| Apparel | 4 | 1147237 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 4 | 1147237 |'
- en: '| Apparel | 3 | 623471 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 3 | 623471 |'
- en: '| Apparel | 2 | 369601 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 2 | 369601 |'
- en: '| Apparel | 1 | 445458 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 1 | 445458 |'
- en: '| Automotive | 5 | 2300757 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 5 | 2300757 |'
- en: '| Automotive | 4 | 526665 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 4 | 526665 |'
- en: '| Automotive | 3 | 239886 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 3 | 239886 |'
- en: '| Automotive | 2 | 147767 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 2 | 147767 |'
- en: '| Automotive | 1 | 299867 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 1 | 299867 |'
- en: '| ... | ... | ... |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... | ... |'
- en: 'With this information, we can also quickly group by star ratings and count
    the reviews for each rating (5, 4, 3, 2, 1):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些信息，我们还可以快速按星级评分进行分组，并计算每个评分（5、4、3、2、1）的评论数量：
- en: '[PRE7]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The result should look similar to this:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该与此类似：
- en: '| star_rating | count_reviews |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 星级评分 | 评论数量 |'
- en: '| --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 5 | 93200812 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 93200812 |'
- en: '| 4 | 26223470 |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 26223470 |'
- en: '| 3 | 12133927 |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 12133927 |'
- en: '| 2 | 7304430 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 7304430 |'
- en: '| 1 | 12099639 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 12099639 |'
- en: Approximately 62% of all reviews have a 5-star rating. We will come back to
    this relative imbalance of star ratings when we perform feature engineering to
    prepare for model training.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 大约62%的所有评论都获得了5星评级。当我们进行特征工程准备模型训练时，我们将回到这种星级评分的相对不平衡。
- en: We can now visualize a stacked percentage horizontal bar plot, showing the proportion
    of each star rating per product category, as shown in [Figure 5-4](#distribution_of_reviews_per_star_rating).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以可视化堆叠百分比水平条形图，显示每个产品类别中每个星级评分的比例，如[图5-4](#distribution_of_reviews_per_star_rating)所示。
- en: '![](assets/dsaw_0504.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0504.png)'
- en: Figure 5-4\. Distribution of reviews per star rating (5, 4, 3, 2, 1) per product
    category.
  id: totrans-162
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-4\. 每个产品类别的星级评分分布（5、4、3、2、1）。
- en: We see that 5- and 4-star ratings make up the largest proportion within each
    product category. But let’s see if we can spot differences in product satisfaction
    over time.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到每个产品类别中5星和4星评级占据了最大比例。但让我们看看是否能够发现不同产品满意度随时间的差异。
- en: 5\. How have the star ratings changed over time? Is there a drop-off point for
    certain product categories throughout the year?
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. 评星随时间的变化如何？某些产品类别在一年中是否存在评星下降点？
- en: 'Let’s first have a look at the average star rating across all product categories
    over the years. Here is the SQL query that will answer this question:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看看各产品类别在多年间的平均星级评分。这是能够回答此问题的SQL查询：
- en: '[PRE8]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The result should look similar to this:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该与此类似：
- en: '| year | avg_rating |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 年份 | 平均评分 |'
- en: '| --- | --- |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1995 | 4.6169 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 1995 | 4.6169 |'
- en: '| 1996 | 4.6003 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 1996 | 4.6003 |'
- en: '| 1997 | 4.4344 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 1997 | 4.4344 |'
- en: '| 1998 | 4.3607 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 1998 | 4.3607 |'
- en: '| 1999 | 4.2819 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 1999 | 4.2819 |'
- en: '| 2000 | 4.2569 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 2000 | 4.2569 |'
- en: '| ... | ... |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... |'
- en: '| 2010 | 4.069 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 2010 | 4.069 |'
- en: '| 2011 | 4.0516 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 2011 | 4.0516 |'
- en: '| 2012 | 4.1193 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 2012 | 4.1193 |'
- en: '| 2013 | 4.1977 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 2013 | 4.1977 |'
- en: '| 2014 | 4.2286 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 2014 | 4.2286 |'
- en: '| 2015 | 4.2495 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 4.2495 |'
- en: If we plot this, as shown in [Figure 5-5](#average_star_rating_across_all_product),
    we notice the general upward trend, with two lows in 2004 and 2011.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们绘制这个，如[图表 5-5](#average_star_rating_across_all_product)所示，我们注意到总体上升趋势，但在2004年和2011年有两次低谷。
- en: '![](assets/dsaw_0505.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0505.png)'
- en: Figure 5-5\. Average star rating across all product categories over time.
  id: totrans-185
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图表 5-5\. 所有产品类别的平均星级评分随时间变化。
- en: 'Let’s take a look now at our top five product categories by number of ratings
    (`''Books''`, `''Digital_Ebook_Purchase''`, `''Wireless''`, `''PC''`, and `''Home''`).
    Here is the SQL query that will answer this question:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看我们的五大产品类别按评分数量排名（`'Books'`, `'Digital_Ebook_Purchase'`, `'Wireless'`,
    `'PC'`, 和 `'Home'`）。这是能回答这个问题的 SQL 查询：
- en: '[PRE9]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The result should look similar to this (shortened):'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该类似于这样（缩短）：
- en: '| product_category | year | avg_rating_category |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 产品类别 | 年份 | 平均评分类别 |'
- en: '| --- | --- | --- |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Books | 1995 | 4.6111 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| 书籍 | 1995 | 4.6111 |'
- en: '| Books | 1996 | 4.6024 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 书籍 | 1996 | 4.6024 |'
- en: '| Books | 1997 | 4.4339 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 书籍 | 1997 | 4.4339 |'
- en: '| Home | 1998 | 4.4 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 主页 | 1998 | 4.4 |'
- en: '| Wireless | 1998 | 4.5 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 无线 | 1998 | 4.5 |'
- en: '| Books | 1998 | 4.3045 |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| 书籍 | 1998 | 4.3045 |'
- en: '| Home | 1999 | 4.1429 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 主页 | 1999 | 4.1429 |'
- en: '| Digital_Ebook_Purchase | 1999 | 5.0 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 数字电子书购买 | 1999 | 5.0 |'
- en: '| PC | 1999 | 3.7917 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| PC | 1999 | 3.7917 |'
- en: '| Wireless | 1999 | 4.1471 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 无线 | 1999 | 4.1471 |'
- en: If we plot this now, as shown in [Figure 5-6](#average_star_rating_over_time_per_prod),
    we can see something interesting.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在绘制，如[图表 5-6](#average_star_rating_over_time_per_prod)所示，我们可以看到一些有趣的东西。
- en: '![](assets/dsaw_0506.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0506.png)'
- en: Figure 5-6\. Average star rating over time per product category (top 5).
  id: totrans-203
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图表 5-6\. 产品类别随时间变化的平均星级评分（前五名）。
- en: While books have been relatively consistent in `star_rating` with values between
    4.1 and 4.6, the other categories are more affected by customer satisfaction.
    Digital ebook purchases (Kindle books) seem to spike a lot, dropping as low as
    3.5 in 2005 and rising as high as 5.0 in 2003\. This would definitely require
    a closer look into our dataset to decide whether this is due to limited reviews
    in that time or some sort of skewed data or if it really reflected the voice of
    our customers.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然书籍的`star_rating`相对稳定，值在4.1到4.6之间，但其他类别更受客户满意度的影响。数字电子书购买（Kindle books）似乎波动较大，在2005年低至3.5，在2003年高达5.0。这绝对需要仔细查看我们的数据集，以决定这是否由于当时评论有限或某种数据偏斜导致，或者这确实反映了客户的声音。
- en: 6\. Which star ratings (1–5) are the most helpful?
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6\. 哪些星级评价（1-5）最有帮助？
- en: 'Here is the SQL query that will answer this question:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这是能回答这个问题的 SQL 查询：
- en: '[PRE10]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The result should look similar to this:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该类似于这样：
- en: '| star_rating | avg_helpful_votes |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| star_rating | avg_helpful_votes |'
- en: '| --- | --- |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 5 | 1.672697561905362 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 1.672697561905362 |'
- en: '| 4 | 1.6786973653753678 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 1.6786973653753678 |'
- en: '| 3 | 2.048089542651773 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 2.048089542651773 |'
- en: '| 2 | 2.5066350146417995 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 2.5066350146417995 |'
- en: '| 1 | 3.6846412525200134 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 3.6846412525200134 |'
- en: We see that customers find negative reviews more helpful than positive reviews,
    which is visualized in [Figure 5-7](#customers_find_negative_reviews_left_pa).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现客户认为负面评价比正面评价更有帮助，这在[图表 5-7](#customers_find_negative_reviews_left_pa)中有可视化。
- en: '![](assets/dsaw_0507.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0507.png)'
- en: Figure 5-7\. Customers find negative reviews (1-star ratings) the most helpful.
  id: totrans-218
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图表 5-7\. 客户认为负面评价（1星评级）最有帮助。
- en: 7\. What is the distribution of review lengths (number of words)?
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7\. 评论长度（单词数量）的分布是什么？
- en: 'Here is the SQL query that will answer this question:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这是能回答这个问题的 SQL 查询：
- en: '[PRE11]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can describe the resulting distribution through percentiles:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过百分位数描述结果分布：
- en: '[PRE12]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The summary result should look similar to this:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 总结结果应该类似于这样：
- en: '[PRE13]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: If we plot this now, as shown in [Figure 5-8](#eightzeropercent_of_our_reviews_have_si),
    we can see that 80% of our reviews have 63 words or less.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在绘制，如[图表 5-8](#eightzeropercent_of_our_reviews_have_si)所示，我们可以看到80%的评论只有63个单词或更少。
- en: '![](assets/dsaw_0508.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0508.png)'
- en: Figure 5-8\. The histogram visualizes the distribution of review lengths.
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图表 5-8\. 直方图可视化评论长度的分布。
- en: Query Our Data Warehouse
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询我们的数据仓库。
- en: At this point, we will use Amazon Redshift to query and visualize use cases.
    Similar to the Athena example, we first need to prepare our SageMaker Studio environment.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们将使用 Amazon Redshift 查询和可视化用例。与 Athena 示例类似，我们首先需要准备 SageMaker Studio 环境。
- en: Run a Sample Amazon Redshift Query from SageMaker Studio
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 SageMaker Studio 中运行 Amazon Redshift 示例查询。
- en: 'In the following example, we will query our dataset to give us the number of
    unique customers per product category. We can use the pandas `read_sql_query`
    function to run our SQLAlchemy query and store the query result in a pandas DataFrame:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将查询数据集，以获得每个产品类别的唯一客户数量。我们可以使用pandas的`read_sql_query`函数运行我们的SQLAlchemy查询，并将查询结果存储在pandas
    DataFrame中：
- en: '[PRE14]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`df.head(10)`'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`df.head(10)`'
- en: 'The output should look similar to this:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果应类似于这样：
- en: '| product_category | num_customers |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 产品类别 | 客户数量 |'
- en: '| --- | --- |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Wireless | 1979435 |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 无线通讯 | 1979435 |'
- en: '| Digital_Ebook_Purchase | 1857681 |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 数字电子书购买 | 1857681 |'
- en: '| Books | 1507711 |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 书籍 | 1507711 |'
- en: '| Apparel | 1424202 |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 1424202 |'
- en: '| Home | 1352314 |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| 家居 | 1352314 |'
- en: '| PC | 1283463 |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 个人电脑 | 1283463 |'
- en: '| Health & Personal Care | 1238075 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 健康与个人护理 | 1238075 |'
- en: '| Beauty | 1110828 |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| 美容 | 1110828 |'
- en: '| Shoes | 1083406 |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 鞋类 | 1083406 |'
- en: '| Sports | 1024591 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 运动 | 1024591 |'
- en: We can see that the `Wireless` product category has the most unique customers
    providing reviews, followed by the `Digital_Ebook_Purchase` and `Books` categories.
    We are all set now to query Amazon Redshift for some deeper customer insights.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到`Wireless`产品类别拥有最多提供评论的独特客户，其次是`Digital_Ebook_Purchase`和`Books`类别。现在我们准备从Amazon
    Redshift查询更深入的客户洞察。
- en: Dive Deep into the Dataset with Amazon Redshift and SageMaker
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入挖掘Amazon Redshift和SageMaker数据集
- en: 'Now, let’s query our data from 2015 in Amazon Redshift for deeper insight into
    our customers and find answers to the following questions:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们从Amazon Redshift中查询2015年的数据，深入了解我们的客户，并找到以下问题的答案：
- en: Which product categories had the most reviews in 2015?
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2015年哪些产品类别的评论最多？
- en: Which products had the most helpful reviews in 2015? How long were those reviews?
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2015年哪些产品评论最有帮助？这些评论的长度是多少？
- en: How did the star ratings change during 2015? Was there a drop-off point for
    certain product categories throughout the year?
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2015年星级评分如何变化？在整年中，是否有某些产品类别的评分出现了下降点？
- en: Which customers wrote the most helpful reviews in 2015? How many reviews did
    they write? Across how many categories? What was their average star rating?
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2015年哪些客户写了最有帮助的评论？他们分别写了多少评论？涵盖了多少个类别？他们的平均星级评分是多少？
- en: Which customers provided more than one review for the same product in 2015?
    What was their average star rating for each product?
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2015年哪些客户为同一产品提供了多于一条评论？每个产品的平均星级评分是多少？
- en: Note
  id: totrans-256
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: As with the Athena examples, we will only show the Amazon Redshift SQL query
    and the results. The full source code to execute and render the results is available
    in the accompanying GitHub repo.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 与Athena示例一样，我们将只展示Amazon Redshift的SQL查询和结果。执行和呈现结果的完整源代码可在附带的GitHub仓库中找到。
- en: Let’s run the queries and find out the answers!
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行查询，找出答案吧！
- en: 1\. Which product categories had the most reviews in 2015?
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 2015年哪些产品类别的评论最多？
- en: 'Here is the SQL query that will answer this question:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是将回答此问题的SQL查询：
- en: '[PRE15]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The result should look similar to this subset of data:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应类似于以下数据子集：
- en: '| year | product_category | count_star_rating |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 年份 | 产品类别 | 评分计数 |'
- en: '| --- | --- | --- |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 2015 | Digital_Ebook_Purchase | 4533519 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 数字电子书购买 | 4533519 |'
- en: '| 2015 | Wireless | 2998518 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 无线通讯 | 2998518 |'
- en: '| 2015 | Books | 2808751 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 书籍 | 2808751 |'
- en: '| 2015 | Apparel | 2369754 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 服装 | 2369754 |'
- en: '| 2015 | Home | 2172297 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 家居 | 2172297 |'
- en: '| 2015 | Health & Personal Care | 1877971 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 健康与个人护理 | 1877971 |'
- en: '| 2015 | PC | 1877971 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 个人电脑 | 1877971 |'
- en: '| 2015 | Beauty | 1816302 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 美容 | 1816302 |'
- en: '| 2015 | Digital_Video_Download | 1593521 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 数字视频下载 | 1593521 |'
- en: '| 2015 | Sports | 1571181 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 2015 | 运动 | 1571181 |'
- en: '| ... | ... | ... |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... | ... |'
- en: We notice that books are still the most reviewed product categories, but it’s
    actually the ebooks (Kindle books) now. Let’s visualize the result in a horizontal
    bar plot, as shown in [Figure 5-9](#for_the_year_twozeroonefivecomma_digita).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到书籍仍然是最多评论的产品类别，但实际上现在是电子书（Kindle书籍）。让我们在水平条形图中将结果可视化，如[图5-9](#for_the_year_twozeroonefivecomma_digita)所示。
- en: '![](assets/dsaw_0509.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0509.png)'
- en: Figure 5-9\. For the year 2015, Digital_Ebook_Purchase has the most reviews.
  id: totrans-278
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-9\. 2015年，数字电子书购买拥有最多的评论。
- en: 2\. Which products had the most helpful reviews in 2015?
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 2015年哪些产品评论最有帮助？
- en: 'Also, how long were those reviews? Here is the SQL query that will answer this
    question:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些评论的长度是多少？以下是将回答此问题的SQL查询：
- en: '[PRE16]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The result should look similar to this:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应类似于以下内容：
- en: '| product_title | helpful_votes | review_body_length | review_body_substring
    |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| product_title | helpful_votes | review_body_length | review_body_substring
    |'
- en: '| --- | --- | --- | --- |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Fitbit Charge HR Wireless Activity Wristband | 16401 | 2824 | Full disclosure,
    I ordered the Fitbit Charge HR only after I gave up on Jawbone fulfilling my preord
    |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| Fitbit Charge HR Wireless Activity Wristband | 16401 | 2824 | 完全公开，我只在放弃Jawbone未能按时交货之后才订购Fitbit
    Charge HR'
- en: '| Kindle Paperwhite | 10801 | 16338 | Review updated September 17, 2015<br
    /><br />As a background, I am a retired Information Systems pro |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| Kindle Paperwhite | 10801 | 16338 | 评价更新于2015年9月17日<br /><br />作为背景，我是一名退休的信息系统专业人员'
- en: '| Kindle Paperwhite | 8542 | 9411 | [[VIDEOID:755c0182976ece27e407ad23676f3ae8]]If
    you’re reading reviews of the new 3rd generation Pape |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| Kindle Paperwhite | 8542 | 9411 | [[VIDEOID:755c0182976ece27e407ad23676f3ae8]]如果你正在阅读关于新第三代Pape的评论'
- en: '| Weslo Cadence G 5.9 Treadmill | 6246 | 4295 | I got the Weslo treadmill and
    absolutely dig it. I’m 6’2&#34;, 230 lbs. and like running outside (ab |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| Weslo Cadence G 5.9 Treadmill | 6246 | 4295 | 我得到了Weslo跑步机，非常喜欢它。我身高6''2"，体重230磅，喜欢在外面跑步（ab'
- en: '| Haribo Gummi Candy Gold-Bears | 6201 | 4736 | It was my last class of the
    semester, and the final exam was worth 30% of our grade.<br />After a la |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| Haribo Gummi Candy Gold-Bears | 6201 | 4736 | 这是我本学期最后一节课，期末考占了我们成绩的30%。<br
    />在一个长'
- en: '| FlipBelt - World’s Best Running Belt & Fitness Workout Belt | 6195 | 211
    | The size chart is wrong on the selection. I’ve attached a photo so you can see
    what you really need. |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| FlipBelt - World’s Best Running Belt & Fitness Workout Belt | 6195 | 211
    | 选择上尺码表有误。我已附上照片，你可以看看真正需要的。'
- en: '| Amazon.com eGift Cards | 5987 | 3498 | I think I am just wasting time writing
    this, but this must have happened to someone else. Something |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| Amazon.com eGift Cards | 5987 | 3498 | 我觉得写这个可能只是在浪费时间，但一定也发生在其他人身上。某事'
- en: '| Melanie’s Marvelous Measles | 5491 | 8028 | If you enjoyed this book, check
    out these other fine titles from the same author:<br /><br />Abby’s |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| Melanie’s Marvelous Measles | 5491 | 8028 | 如果你喜欢这本书，可以看看同一作者的其他精彩作品：<br
    /><br />Abby’s'
- en: '| Tuft & Needle Mattress | 5404 | 4993 | tl;dr: Great mattress, after some
    hurdles that were deftly cleared by stellar customer service. The |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| Tuft & Needle Mattress | 5404 | 4993 | 简而言之：经过一些难关，绝佳的客户服务使得这款床垫非常出色。The'
- en: '| Ring Wi-Fi Enabled Video Doorbell | 5399 | 3984 | First off, the Ring is
    very cool. I really like it and many people that come to my front door (sale |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| Ring Wi-Fi Enabled Video Doorbell | 5399 | 3984 | 首先，Ring门铃非常酷。我真的很喜欢它，许多来我家门口的人（销售）'
- en: We see that the “Fitbit Charge HR Wireless Activity Wristband” had the most
    helpful review in 2015, with a total of 16,401 votes and a decent-sized review
    length of 2,824 characters. It’s followed by two reviews for the “Kindle Paperwhite,”
    where people were writing longer reviews of 16,338 and 9,411 characters, respectively.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到“Fitbit Charge HR Wireless Activity Wristband”在2015年拥有最多的有用评价，共16,401票，并且评论长度为2,824个字符。其后是两篇关于“Kindle
    Paperwhite”的评论，人们写了长达16,338和9,411个字符的评论。
- en: 3\. How did the star ratings change during 2015?
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 2015年星级评分发生了什么变化？
- en: 'Also, was there a drop-off point for certain product categories throughout
    the year? Here is the SQL query that will answer this question:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，某些产品类别是否在全年内有下降点？以下是能回答这个问题的SQL查询：
- en: '[PRE17]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The result should look similar to this:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该与以下类似：
- en: '| month | avg_rating |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| month | avg_rating |'
- en: '| --- | --- |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | 4.277998926134835 |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 4.277998926134835 |'
- en: '| 2 | 4.267851231035101 |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 4.267851231035101 |'
- en: '| 3 | 4.261042822856084 |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 4.261042822856084 |'
- en: '| 4 | 4.247727865199895 |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 4.247727865199895 |'
- en: '| 5 | 4.239633709986397 |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 4.239633709986397 |'
- en: '| 6 | 4.235766635971452 |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 4.235766635971452 |'
- en: '| 7 | 4.230284081689972 |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 4.230284081689972 |'
- en: '| 8 | 4.231862792031927 |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 4.231862792031927 |'
- en: We notice that we only have data until August 2015\. We can also spot that the
    average rating is slowly declining, as we can easily see in [Figure 5-10](#average_star_rating_throughout_twozeroo).
    While we don’t have a precise explanation, this decline was likely investigated
    in 2015.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们注意到我们只有到2015年8月的数据。我们还可以看到平均评分在缓慢下降，正如我们在[Figure 5-10](#average_star_rating_throughout_twozeroo)中清楚地看到的。尽管我们没有确切的解释，但这种下降很可能在2015年得到调查。
- en: '![](assets/dsaw_0510.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0510.png)'
- en: Figure 5-10\. Average star rating throughout 2015 across all product categories.
  id: totrans-312
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 5-10\. 2015年各产品类别的平均星级评分。
- en: 'Now let’s explore whether this is due to a certain product category dropping
    drastically in customer satisfaction or is more of a trend across all categories.
    Here is the SQL query that will answer this question:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们探讨这是否由于某个产品类别在客户满意度上急剧下降，还是所有类别都有这种趋势。以下是能回答这个问题的SQL查询：
- en: '[PRE18]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The result should look similar to this (shortened):'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该类似于这样（缩短版）：
- en: '| product_category | month | avg_rating |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 产品类别 | 月份 | 平均评分 |'
- en: '| --- | --- | --- |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Apparel | 1 | 4.159321618698804 |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 1 | 4.159321618698804 |'
- en: '| Apparel | 2 | 4.123969612021801 |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 2 | 4.123969612021801 |'
- en: '| Apparel | 3 | 4.109944336469443 |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 3 | 4.109944336469443 |'
- en: '| Apparel | 4 | 4.094360325567125 |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 4 | 4.094360325567125 |'
- en: '| Apparel | 5 | 4.0894595692213125 |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 5 | 4.0894595692213125 |'
- en: '| Apparel | 6 | 4.09617799917213 |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 6 | 4.09617799917213 |'
- en: '| Apparel | 7 | 4.097665115845663 |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 7 | 4.097665115845663 |'
- en: '| Apparel | 8 | 4.112790034578352 |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 服装 | 8 | 4.112790034578352 |'
- en: '| Automotive | 1 | 4.325502388403887 |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 1 | 4.325502388403887 |'
- en: '| Automotive | 2 | 4.318120214368761 |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| 汽车 | 2 | 4.318120214368761 |'
- en: '| ... | ... | ... |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... | ... |'
- en: Let’s visualize the result to make it easier to spot the trends, as shown in
    [Figure 5-11](#average_star_rating_over_time_per_produ).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过可视化结果来更容易地发现趋势，如[图5-11](#average_star_rating_over_time_per_produ)所示。
- en: '![](assets/dsaw_0511.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0511.png)'
- en: Figure 5-11\. Average star rating over time per product category in 2015.
  id: totrans-331
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-11\. 2015年每个产品类别的平均星级评分。
- en: 'While the figure is a bit messy, we can see that most categories follow the
    same average star rating over the months, with three categories fluctuating more
    than others: “Digital Software,” “Software,” and “Mobile Electronics.” They are,
    however, improving throughout the year, which is good.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个图表有点凌乱，但我们可以看到大多数类别在月份间都有相同的平均星级评分，其中三个类别比其他类别波动更大：“数字软件”，“软件”和“移动电子产品”。不过，它们在整年内都有所改善，这是好事。
- en: 4\. Which customers wrote the most helpful reviews in 2015?
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 哪些客户在2015年写的评论最有帮助？
- en: 'Also, how many reviews did they write? Across how many categories? What was
    their average star rating? Here is the SQL query that will answer the questions:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，他们写了多少评论？跨多少个类别？平均星级评分是多少？以下是能回答这些问题的SQL查询：
- en: '[PRE19]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The result should look similar to this:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该类似于这样：
- en: '| customer_id | avg_helpful_votes | review_count | product_category_count |
    avg_star_rating |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| 客户ID | 平均有用票数 | 评论数 | 产品类别数 | 平均星级评分 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 35360512 | 48 | 168 | 26 | 4.5 |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| 35360512 | 48 | 168 | 26 | 4.5 |'
- en: '| 52403783 | 44 | 274 | 25 | 4.9 |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| 52403783 | 44 | 274 | 25 | 4.9 |'
- en: '| 28259076 | 40 | 123 | 7 | 4.3 |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| 28259076 | 40 | 123 | 7 | 4.3 |'
- en: '| 15365576 | 37 | 569 | 30 | 4.9 |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| 15365576 | 37 | 569 | 30 | 4.9 |'
- en: '| 14177091 | 29 | 187 | 15 | 4.4 |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| 14177091 | 29 | 187 | 15 | 4.4 |'
- en: '| 28021023 | 28 | 103 | 18 | 4.5 |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| 28021023 | 28 | 103 | 18 | 4.5 |'
- en: '| 20956632 | 25 | 120 | 23 | 4.8 |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| 20956632 | 25 | 120 | 23 | 4.8 |'
- en: '| 53017806 | 25 | 549 | 30 | 4.9 |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| 53017806 | 25 | 549 | 30 | 4.9 |'
- en: '| 23942749 | 25 | 110 | 22 | 4.5 |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| 23942749 | 25 | 110 | 22 | 4.5 |'
- en: '| 44834233 | 24 | 514 | 32 | 4.4 |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| 44834233 | 24 | 514 | 32 | 4.4 |'
- en: We can see the customers that wrote reviews that produced the most helpful votes
    on average (with more than one hundred reviews provided) across many different
    categories; the reviews generally reflected a positive sentiment.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到那些写了平均评分最有帮助票数的评论（提供了一百多条评论）的客户，这些评论通常反映了积极的情绪。
- en: 5\. Which customers provided more than one review for the same product in 2015?
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. 哪些客户在2015年为同一产品提供了多次评论？
- en: 'Also, what was their average star rating for each product? Here is the SQL
    query that will answer this question:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每个产品的平均星级评分是多少？以下是能回答这个问题的SQL查询：
- en: '[PRE20]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The result should look similar to this:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该类似于这样：
- en: '| customer_id | product_category | product_title | avg_star_rating | review_count
    |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| 客户ID | 产品类别 | 产品标题 | 平均星级评分 | 评论数 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 2840168 | Camera | (Create a generic Title per Amazon’s guidelines) | 5.0
    | 45 |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| 2840168 | 相机 | （按照亚马逊指南创建一个通用标题） | 5.0 | 45 |'
- en: '| 9016330 | Video Games | Disney INFINITY Disney Infinity: Marvel Super Heroes
    (2.0 Edition) Characters | 5.0 | 23 |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| 9016330 | 视频游戏 | 迪士尼无限 迪士尼无限：漫威超级英雄（2.0版）角色 | 5.0 | 23 |'
- en: '| 10075230 | Video Games | Skylanders Spyro’s Adventure: Character Pack | 5.0
    | 23 |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| 10075230 | 视频游戏 | 天降奇兵：斯派罗历险记：角色包 | 5.0 | 23 |'
- en: '| 50600878 | Digital_Ebook_Purchase | The Art of War | 2.35 | 20 |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| 50600878 | 数字电子书购买 | 孙子兵法 | 2.35 | 20 |'
- en: '| 10075230 | Video Games | Activision Skylanders Giants Single Character Pack
    Core Series 2 | 4.85 | 20 |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| 10075230 | 视频游戏 | Activision Skylanders Giants Single Character Pack Core
    Series 2 | 4.85 | 20 |'
- en: Note that the `avg_star_rating` is not always a whole number. This means some
    customers rated the product differently over time.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`avg_star_rating`并非始终是整数。这意味着一些顾客随着时间的推移对产品的评价有所不同。
- en: 'It’s good to know that customer 9016330 finds the Disney Infinity: Marvel Super
    Heroes Video Game to be 5 stars—even after playing it 23 times! Customer 50600878
    has been fascinated enough to read *The Art of War* 20 times, but is still struggling
    to find a positive sentiment there.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，顾客9016330发现迪士尼无限：漫威超级英雄视频游戏获得了5星评价——即使玩了23次！顾客50600878已经着迷到阅读《孙子兵法》20次，但仍在努力寻找其中的积极情绪。
- en: Create Dashboards with Amazon QuickSight
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Amazon QuickSight创建仪表板。
- en: QuickSight is a managed, serverless, and easy-to-use business analytics service
    that we can leverage to quickly build powerful visualizations. QuickSight automatically
    discovers the data sources in our AWS account, including MySQL, Salesforce, Amazon
    Redshift, Athena, S3, Aurora, RDS, and many more.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: QuickSight是一种托管、无服务器且易于使用的业务分析服务，我们可以利用它快速构建强大的可视化效果。QuickSight会自动发现我们AWS账户中的数据源，包括MySQL、Salesforce、Amazon
    Redshift、Athena、S3、Aurora、RDS等等。
- en: Let’s use QuickSight to create a dashboard with our Amazon Customer Reviews
    Dataset. In just a few clicks, we can have a visualization of review counts per
    product category, accessible by any device, even our mobile phone. We can automatically
    refresh the dashboard after data ingestion using the QuickSight Python SDK. Using
    the QuickSight UI, we can see the imbalance in our dataset, as shown in [Figure 5-12](#visualizing_review_counts_per_product_c).
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用QuickSight创建一个仪表板，展示我们的Amazon顾客评论数据集。只需点击几下，我们就可以在任何设备上获得产品类别评论数量的可视化效果，甚至是我们的手机。我们可以使用QuickSight
    Python SDK在数据摄入后自动刷新仪表板。通过QuickSight UI，我们可以看到我们数据集中的不平衡情况，如[图 5-12](#visualizing_review_counts_per_product_c)所示。
- en: '![](assets/dsaw_0512.png)'
  id: totrans-366
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0512.png)'
- en: Figure 5-12\. Visualizing review counts per product category in QuickSight.
  id: totrans-367
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-12。在QuickSight中可视化产品类别的评论数量。
- en: The product categories Books and Digital_Ebook_Purchase have by far the most
    reviews. We will analyze and address this imbalance in more detail in the next
    chapter, when we prepare the dataset to train our models.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 产品类别Books和Digital_Ebook_Purchase拥有迄今为止最多的评论。在下一章节中，当我们准备数据集来训练我们的模型时，我们将更详细地分析和解决这种不平衡。
- en: Detect Data-Quality Issues with Amazon SageMaker and Apache Spark
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Amazon SageMaker和Apache Spark检测数据质量问题。
- en: Data is never perfect—especially in a dataset with 150+ million rows spread
    across 20 years! Additionally, data quality may actually degrade over time as
    new application features are introduced and others are retired. Schemas evolve,
    code gets old, and queries get slow.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 数据从未完美——特别是在一个跨越20年、拥有1.5亿行数据的数据集中！此外，随着引入新的应用功能和淘汰旧功能，数据质量实际上可能会随时间推移而下降。架构演变，代码老化，查询变慢。
- en: Since data quality is not always a priority for the upstream application teams,
    the downstream data engineering and data science teams need to handle bad or missing
    data. We want to make sure that our data is high quality for our downstream consumers,
    including the business intelligence, ML engineering, and data science teams.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据质量对上游应用团队并非总是优先考虑，因此下游的数据工程和数据科学团队需要处理糟糕或缺失的数据。我们希望确保我们的数据对包括商业智能、ML工程和数据科学团队在内的下游消费者是高质量的。
- en: '[Figure 5-13](#applications_generate_data_for_engineer) shows how applications
    generate data for engineers, scientists, and analysts to consume—as well as which
    tools and services the various teams are likely to use when accessing that data.'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5-13](#applications_generate_data_for_engineer)显示了应用程序如何为工程师、科学家和分析师生成数据，以及这些团队在访问数据时可能使用的工具和服务。'
- en: '![](assets/dsaw_0513.png)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0513.png)'
- en: Figure 5-13\. Engineers, scientists and analysts use various tools and services
    to access data.
  id: totrans-374
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-13。工程师、科学家和分析师使用各种工具和服务访问数据。
- en: Data quality can halt a data processing pipeline in its tracks. If these issues
    are not caught early, they can lead to misleading reports (i.e., double-counted
    revenue), biased AI/ML models (skewed toward/against a single gender or race),
    and other unintended data products.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量问题可能会阻碍数据处理流水线。如果不能及早发现这些问题，可能会导致误导性报告（例如重复计算的收入）、偏倚的AI/ML模型（偏向/反对单一性别或种族）以及其他意外的数据产品。
- en: To catch these data issues early, we use two open source libraries from AWS,
    [Deequ](https://oreil.ly/CVaTM) and [PyDeequ](https://oreil.ly/K9Ydj). These libraries
    use Apache Spark to analyze data quality, detect anomalies, and enable us to “notify
    the Data Scientist at 3 a.m.” about a data issue. Deequ continuously analyzes
    data throughout the complete, end-to-end lifetime of the model, from feature engineering
    to model training to model serving in production. [Figure 5-14](#overview_of_deequ_components_constrain)
    shows a high-level overview of the Deequ architecture and components.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 要尽早捕捉这些数据问题，我们使用了来自AWS的两个开源库，[Deequ](https://oreil.ly/CVaTM) 和 [PyDeequ](https://oreil.ly/K9Ydj)。这些库利用Apache
    Spark分析数据质量，检测异常，并能在“凌晨3点通知数据科学家”发现数据问题。Deequ在整个模型的完整生命周期内持续分析数据，从特征工程到模型训练再到生产环境中的模型服务。[图 5-14](#overview_of_deequ_components_constrain)展示了Deequ架构和组件的高级概述。
- en: Learning from run to run, Deequ will suggest new rules to apply during the next
    pass through the dataset. Deequ learns the baseline statistics of our dataset
    at model training time, for example, then detects anomalies as new data arrives
    for model prediction. This problem is classically called “training-serving skew.”
    Essentially, a model is trained with one set of learned constraints, then the
    model sees new data that does not fit those existing constraints. This is a sign
    that the data has shifted—or skewed—from the original, expected distribution used
    during training.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 从一次运行到下一次运行学习，Deequ将建议在下一次通过数据集时应用的新规则。例如，在模型训练时，Deequ学习我们数据集的基线统计信息，然后在新数据到达进行模型预测时检测异常。这个问题经典上称为“训练-服务偏差”。基本上，一个模型是用一组学习到的约束进行训练的，然后模型看到不符合这些现有约束的新数据。这表明数据从最初预期的分布发生了移动或偏差。
- en: '![](assets/dsaw_0514.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0514.png)'
- en: 'Figure 5-14\. Deequ’s components: constraints, metrics, and suggestions.'
  id: totrans-379
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-14\. Deequ的组件：约束、指标和建议。
- en: Since we have 150+ million reviews, we need to run Deequ on a cluster versus
    inside our notebook. This is the trade-off of working with data at scale. Notebooks
    work fine for exploratory analytics on small datasets but are not suitable to
    process large datasets or train large models. We will use a notebook to kick off
    a Deequ Spark job on a separate, ephemeral, and serverless Apache Spark cluster
    using SageMaker Processing Jobs.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们有超过1.5亿条评论，我们需要在集群上运行Deequ，而不是在我们的笔记本内部运行。这是在大规模数据处理中的一个权衡。笔记本对小数据集的探索性分析效果良好，但不适合处理大数据集或训练大模型。我们将使用笔记本在独立的、短暂的、无服务器的Apache
    Spark集群上启动Deequ Spark作业，以触发处理作业。
- en: SageMaker Processing Jobs
  id: totrans-381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SageMaker处理作业
- en: SageMaker Processing Jobs can run any Python script—or custom Docker image—on
    the fully managed, pay-as-you-go AWS infrastructure using familiar open source
    tools such as scikit-learn and Apache Spark. [Figure 5-15](#container_for_an_amazon_sagemaker_proce)
    shows the SageMaker Processing Job container.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SageMaker处理作业可以在完全托管、按需付费的AWS基础设施上运行任何Python脚本或自定义Docker镜像，使用熟悉的开源工具如scikit-learn和Apache
    Spark。[图 5-15](#container_for_an_amazon_sagemaker_proce)展示了SageMaker处理作业容器。
- en: '![](assets/dsaw_0515.png)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0515.png)'
- en: Figure 5-15\. Container for an Amazon SageMaker Processing Job.
  id: totrans-384
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-15\. 亚马逊SageMaker处理作业容器。
- en: Fortunately, Deequ is a high-level API on top of Apache Spark, so we use SageMaker
    Processing Jobs to run our large-scale analysis job.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Deequ是建立在Apache Spark之上的高级API，因此我们使用SageMaker处理作业来运行我们的大规模分析作业。
- en: Note
  id: totrans-386
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Deequ is similar to TensorFlow Extended in concept—specifically, the TensorFlow
    Data Validation component. However, Deequ builds upon popular open source Apache
    Spark to increase usability, debug-ability, and scalability. Additionally, Apache
    Spark and Deequ natively support the Parquet format—our preferred file format
    for analytics.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: Deequ在概念上类似于TensorFlow Extended，特别是TensorFlow数据验证组件。然而，Deequ在流行的开源Apache Spark基础上构建，以增加可用性、调试能力和可扩展性。此外，Apache
    Spark和Deequ本地支持Parquet格式——我们首选的分析文件格式。
- en: Analyze Our Dataset with Deequ and Apache Spark
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Deequ和Apache Spark分析我们的数据集
- en: '[Table 5-1](#sample_deequ_metrics) shows just a few of the metrics that Deequ
    supports.'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 5-1](#sample_deequ_metrics)展示了Deequ支持的部分指标。'
- en: Table 5-1\. Sample Deequ metrics
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5-1\. Deequ指标示例
- en: '| Metric | Description | Usage example |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | 描述 | 使用示例 |'
- en: '| --- | --- | --- |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| ApproxCountDistinct | Approximate number of distinct values using HLL++ |
    ApproxCountDistinct(“review_id”) |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| ApproxCountDistinct | 使用HLL++的近似不同值数量 | ApproxCountDistinct(“review_id”)
    |'
- en: '| ApproxQuantiles | Approximate quantiles of a distribution | ApproxQuantiles(“star_rating”,
    quantiles = Seq(0.1, 0.5, 0.9)) |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| ApproxQuantiles | Approximate quantiles of a distribution | ApproxQuantiles(“star_rating”,
    quantiles = Seq(0.1, 0.5, 0.9)) |'
- en: '| Completeness | Fraction of non-null values in a column | Completeness(“review_id”)
    |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| Completeness | Fraction of non-null values in a column | Completeness(“review_id”)
    |'
- en: '| Compliance | Fraction of rows that comply with the given column constraint
    | Compliance(“top star_rating”, “star_rating >= 4.0”) |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| Compliance | Fraction of rows that comply with the given column constraint
    | Compliance(“top star_rating”, “star_rating >= 4.0”) |'
- en: '| Correlation | Pearson correlation coefficient | Correlation(“total_votes”,
    “star_rating”) |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| Correlation | Pearson correlation coefficient | Correlation(“total_votes”,
    “star_rating”) |'
- en: '| Maximum | Maximum value | Maximum(“star_rating”) |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| Maximum | Maximum value | Maximum(“star_rating”) |'
- en: '| Mean | Mean value; null valuesexcluded | Mean(“star_rating”) |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| Mean | Mean value; null valuesexcluded | Mean(“star_rating”) |'
- en: '| Minimum | Minimum value | Minimum(“star_rating”) |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| Minimum | Minimum value | Minimum(“star_rating”) |'
- en: '| MutualInformation | How much information about one column can be inferred
    from another column | MutualInformation(Seq(“total_votes”, “star_rating”)) |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| MutualInformation | How much information about one column can be inferred
    from another column | MutualInformation(Seq(“total_votes”, “star_rating”)) |'
- en: '| Size | Number of rows in a DataFrame | Size() |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| Size | Number of rows in a DataFrame | Size() |'
- en: '| Sum | Sum of all values of a column | Sum(“total_votes”) |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| Sum | Sum of all values of a column | Sum(“total_votes”) |'
- en: '| Uniqueness | Fraction of unique values | Uniqueness(“review_id”) |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| Uniqueness | Fraction of unique values | Uniqueness(“review_id”) |'
- en: 'Let’s kick off the Apache Spark–based Deequ analyzer job by invoking the `PySparkProcessor`
    and launching a 10-node Apache Spark Cluster right from our notebook. We chose
    the high-memory `r5` instance type because Spark typically performs better with
    more memory:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过调用`PySparkProcessor`启动基于Apache Spark的Deequ分析作业，并从笔记本电脑上启动一个包含10个节点的Apache
    Spark集群。我们选择高内存的`r5`实例类型，因为Spark通常在更多内存的情况下表现更好：
- en: '[PRE21]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Following is our Deequ code specifying the various constraints we wish to apply
    to our TSV dataset. We are using TSV in this example to maintain consistency with
    the rest of the examples, but we could easily switch to Parquet with just a one-line
    code change:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我们的Deequ代码，指定了我们希望应用于TSV数据集的各种约束条件。在此示例中，我们使用TSV以保持与其他示例的一致性，但只需更改一行代码即可轻松切换到Parquet：
- en: '[PRE22]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Define the analyzers:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 定义分析器：
- en: '[PRE23]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Define the checks, compute the metrics, and verify check conditions:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 定义检查、计算指标并验证检查条件：
- en: '[PRE24]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We have defined our set of constraints and assertions to apply to our dataset.
    Let’s run the job and ensure that our data is what we expect. [Table 5-2](#deequ_job_results)
    shows the results from our Deequ job, summarizing the results of the constraints
    and checks that we specified.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已定义了要应用于数据集的一组约束和断言。让我们运行作业并确保我们的数据符合预期。[Table 5-2](#deequ_job_results)显示了我们Deequ作业的结果，总结了我们指定的约束和检查结果。
- en: Table 5-2\. Deequ job results
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 表5-2\. Deequ作业结果
- en: '| check_name | columns | value |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| check_name | columns | value |'
- en: '| --- | --- | --- |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| ApproxCountDistinct | review_id | 149075190 |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| ApproxCountDistinct | review_id | 149075190 |'
- en: '| Completeness | review_id | 1.00 |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| Completeness | review_id | 1.00 |'
- en: '| Compliance | Marketplace contained in US,UK, DE,JP,FR | 1.00 |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| Compliance | Marketplace contained in US,UK, DE,JP,FR | 1.00 |'
- en: '| Compliance | top star_rating | 0.79 |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| Compliance | top star_rating | 0.79 |'
- en: '| Correlation | helpful_votes,total_votes | 0.99 |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| Correlation | helpful_votes,total_votes | 0.99 |'
- en: '| Correlation | total_votes,star_rating | -0.03 |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| Correlation | total_votes,star_rating | -0.03 |'
- en: '| Maximum | star_rating | 5.00 |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| Maximum | star_rating | 5.00 |'
- en: '| Mean | star_rating | 4.20 |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| Mean | star_rating | 4.20 |'
- en: '| Minimum | star_rating | 1.00 |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| Minimum | star_rating | 1.00 |'
- en: '| Size | * | 150962278 |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| Size | * | 150962278 |'
- en: '| Uniqueness | review_id | 1.00 |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| Uniqueness | review_id | 1.00 |'
- en: 'We learned the following:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学到了以下内容：
- en: '`review_id` has no missing values and approximately (within 2% accuracy) 149,075,190
    unique values.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`review_id`没有缺失值，大约（精确度在2%以内）有149,075,190个唯一值。'
- en: 79% of reviews have a “top” `star_rating` of 4 or higher.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 79%的评价具有“顶级”`star_rating`为4或更高。
- en: '`total_votes` and `star_rating` are weakly correlated.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`total_votes`和`star_rating`之间存在弱相关性。'
- en: '`helpful_votes` and `total_votes` are strongly correlated.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`helpful_votes`和`total_votes`之间存在强相关性。'
- en: The average `star_rating` is 4.20.
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均`star_rating`为4.20。
- en: The dataset contains exactly 150,962,278 reviews (1.27% different than `ApproxCountDistinct`).
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集包含确切的150,962,278条评价（与`ApproxCountDistinct`相比略有不同，差异为1.27%）。
- en: 'Deequ supports the concept of a `MetricsRepository` to track these metrics
    over time and potentially halt our pipeline if we detect degradation in data quality.
    Following is the code to create a `FileSystemMetricsRepository`, start tracking
    our metrics with a revised `AnalysisRunner`, and load our metrics for comparison:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: Deequ 支持 `MetricsRepository` 的概念，以跟踪这些指标随时间的变化，并在检测到数据质量下降时可能停止我们的流水线。以下是创建
    `FileSystemMetricsRepository`、使用修订后的 `AnalysisRunner` 开始跟踪我们的指标以及加载我们的指标进行比较的代码：
- en: '[PRE25]'
  id: totrans-436
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Deequ also suggests useful constraints based on the current characteristics
    of our dataset. This is useful when we have new data entering the system that
    may differ statistically from the original dataset. In the real world, this is
    very common because new data is coming in all the time.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: Deequ 还根据我们数据集的当前特征提出了有用的约束条件。当我们有新数据进入系统时，这是非常有用的，因为新数据在统计上可能与原始数据集不同。在现实世界中，这是非常常见的，因为新数据随时都在进入。
- en: In [Table 5-3](#deequ_suggestions_for_checks_to_be_adde) are the checks—and
    the accompanying code—that Deequ suggests we add to detect anomalies as new data
    arrives into the system.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [表格 5-3](#deequ_suggestions_for_checks_to_be_adde) 中，Deequ 建议我们添加以下检查和相应的代码，以便在新数据进入系统时检测异常。
- en: Table 5-3\. Deequ suggestions for checks to be added
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 5-3\. Deequ 建议添加的检查
- en: '| column | check | deequ_code |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| column | check | deequ_code |'
- en: '| --- | --- | --- |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| customer_id | `''customer_id''` has type Integral | `.hasDataType(\"customer_id\",
    ConstrainableDataTypes.Integral)"` |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| customer_id | `''customer_id''`具有整数类型 | `.hasDataType(\"customer_id\", ConstrainableDataTypes.Integral)"`
    |'
- en: '| helpful_votes | `''helpful_votes''` has no negative values | `.isNonNegative(\"helpful_votes\")"`
    |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| helpful_votes | `''helpful_votes''`没有负值 | `.isNonNegative(\"helpful_votes\")"`
    |'
- en: '| review_headline | `''review_headline''` has less than 1% missing values |
    `.hasCompleteness(\"review_headline\", lambda x: x >= 0.99, Some(\"It should be
    above 0.99!\"))"` |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| review_headline | `''review_headline''`有不到1%的缺失值 | `.hasCompleteness(\"review_headline\",
    lambda x: x >= 0.99, Some(\"应该高于0.99！\"))"` |'
- en: '| product_category | `''product_category''` has value range `''Books''`, `''Digital_Ebook_Purchase''`,
    `''Wireless''`, `''PC''`, `''Home''`, `''Apparel''`, `''Health & Personal Care''`,
    `''Beauty''`, `''Video DVD''`, `''Mobile_Apps''`, `''Kitchen''`, `''Toys''`, `''Sports''`,
    `''Music''`, `''Shoes''`, `''Digital_Video_Download''`, `''Automotive''`, `''Electronics''`,
    `''Pet Products''`, `''Office Products''`, `''Home Improvement''`, `''Lawn and
    Garden''`, `''Grocery''`, `''Outdoors''`, `''Camera''`, `''Video Games''`, `''Jewelry''`,
    `''Baby''`, `''Tools''`, `''Digital_Music_Purchase''`, `''Watches''`, `''Musical
    Instruments''`, `''Furniture''`, `''Home Entertainment''`, `''Video''`, `''Luggage''`,
    `''Software''`, `''Gift Card''`, `''Digital_Video_Games''`, `''Mobile_Electronics''`,
    `''Digital_Software''`, `''Major Appliances''`, `''Personal_Care_Appliances''`
    | `.isContainedIn(\"product_category\", Array(\"Books\", \"Digital_Ebook_Purchase\",
    \"Wireless\", \"PC\", \"Home\", \"Apparel\", \"Health & Personal Care\", \"Beauty\",
    \"Video DVD\", \"Mobile_Apps\", \"Kitchen\", \"Toys\", \"Sports\", \"Music\",
    \"Shoes\", \"Digital_Video_Download\", \"Automotive\", \"Electronics\", \"Pet
    Products\", \"Office Products\", \"Home Improvement\", \"Lawn and Garden\", \"Grocery\",
    \"Outdoors\", \"Camera\", \"Video Games\", \"Jewelry\", \"Baby\", \"Tools\", \"Digital_Music_Purchase\",
    \"Watches\", \"Musical Instruments\", \"Furniture\", \"Home Entertainment\", \"Video\",
    \"Luggage\", \"Software\", \"Gift Card\", \"Digital_Video_Games\", \"Mobile_Electronics\",
    \"Digital_Software\", \"Major Appliances\", \"Personal_Care_Appliances\"))"` |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| product_category | `''product_category''`的值范围包括 `''Books''`, `''Digital_Ebook_Purchase''`,
    `''Wireless''`, `''PC''`, `''Home''`, `''Apparel''`, `''Health & Personal Care''`,
    `''Beauty''`, `''Video DVD''`, `''Mobile_Apps''`, `''Kitchen''`, `''Toys''`, `''Sports''`,
    `''Music''`, `''Shoes''`, `''Digital_Video_Download''`, `''Automotive''`, `''Electronics''`,
    `''Pet Products''`, `''Office Products''`, `''Home Improvement''`, `''Lawn and
    Garden''`, `''Grocery''`, `''Outdoors''`, `''Camera''`, `''Video Games''`, `''Jewelry''`,
    `''Baby''`, `''Tools''`, `''Digital_Music_Purchase''`, `''Watches''`, `''Musical
    Instruments''`, `''Furniture''`, `''Home Entertainment''`, `''Video''`, `''Luggage''`,
    `''Software''`, `''Gift Card''`, `''Digital_Video_Games''`, `''Mobile_Electronics''`,
    `''Digital_Software''`, `''Major Appliances''`, `''Personal_Care_Appliances''`
    | `.isContainedIn(\"product_category\", Array(\"Books\", \"Digital_Ebook_Purchase\",
    \"Wireless\", \"PC\", \"Home\", \"Apparel\", \"Health & Personal Care\", \"Beauty\",
    \"Video DVD\", \"Mobile_Apps\", \"Kitchen\", \"Toys\", \"Sports\", \"Music\",
    \"Shoes\", \"Digital_Video_Download\", \"Automotive\", \"Electronics\", \"Pet
    Products\", \"Office Products\", \"Home Improvement\", \"Lawn and Garden\", \"Grocery\",
    \"Outdoors\", \"Camera\", \"Video Games\", \"Jewelry\", \"Baby\", \"Tools\", \"Digital_Music_Purchase\",
    \"Watches\", \"Musical Instruments\", \"Furniture\", \"Home Entertainment\", \"Video\",
    \"Luggage\", \"Software\", \"Gift Card\", \"Digital_Video_Games\", \"Mobile_Electronics\",
    \"Digital_Software\", \"Major Appliances\", \"Personal_Care_Appliances\"))"` |'
- en: '| vine | `''vine''` has value range `''N''` for at least 99.0% of values |
    `.isContainedIn(\"vine\", Array(\"N\"), lambda x: x >= 0.99, Some(\"It should
    be above 0.99!\"))"` |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| vine | `''vine''` 的值范围至少有 99.0% 的值为 `''N''` | `.isContainedIn(\"vine\", Array(\"N\"),
    lambda x: x >= 0.99, Some(\"It should be above 0.99!\"))"` |'
- en: In addition to the Integral type and not-negative checks, Deequ also suggests
    that we constrain `product_category` to the 43 currently known values, including
    `Books`, `Software`, etc. Deequ also recognized that at least 99% of the `vine`
    values are `N` and < 1% of `review_headline` values are empty, so it recommends
    that we add checks for these conditions moving forward.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 除了整型和非负数检查外，Deequ 还建议我们将 `product_category` 限制为目前已知的 43 个值，包括 `Books`、`Software`
    等。Deequ 还意识到至少 99% 的 `vine` 值为 `N`，并且 `< 1%` 的 `review_headline` 值为空，因此建议我们在未来增加对这些条件的检查。
- en: Detect Bias in Our Dataset
  id: totrans-448
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检测数据集中的偏见
- en: Using just a few lines of Python code with the Seaborn library, shown in the
    following, we can identify an imbalance in the number of reviews for three sample
    product categories across the five different `star_rating` classes in our pandas
    DataFrame. [Figure 5-16](#the_dataset_is_imbalanced_in_number_of) visualizes this
    imbalance for this sample of data.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Seaborn 库的几行 Python 代码，如下所示，我们可以识别出 pandas DataFrame 中三个样本产品类别在五个不同 `star_rating`
    类别中评论数量的不平衡。[Figure 5-16](#the_dataset_is_imbalanced_in_number_of) 可视化了这些数据的不平衡。
- en: '[PRE26]'
  id: totrans-450
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](assets/dsaw_0516.png)'
  id: totrans-451
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0516.png)'
- en: Figure 5-16\. The dataset is imbalanced in number of reviews across star rating
    classes and product categories.
  id: totrans-452
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-16。数据集在星级评分类别和产品类别的评论数量上存在不平衡。
- en: We will now use SageMaker Data Wrangler and Clarify to analyze imbalance and
    other potential bias in our dataset at scale.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用 SageMaker Data Wrangler 和 Clarify 在规模上分析数据集中的不平衡和其他潜在的偏见。
- en: Generate and Visualize Bias Reports with SageMaker Data Wrangler
  id: totrans-454
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 SageMaker Data Wrangler 生成和可视化偏见报告
- en: SageMaker Data Wrangler is integrated with SageMaker Studio and is designed
    specifically for machine learning, data analysis, feature engineering, feature-importance
    analysis, and bias detection. With Data Wrangler, we can specify custom Apache
    Spark user-defined functions, pandas code, and SQL queries. Additionally, Data
    Wrangler provides over 300 built-in data transformations for feature engineering
    and bias mitigation. We will dive deeper into SageMaker Data Wrangler for feature
    engineering in [Chapter 6](ch06.html#prepare_the_dataset_for_model_training).
    For now, let’s analyze the dataset with Data Wrangler and SageMaker Clarify, a
    feature of Amazon SageMaker that we will use throughout the rest of this book
    to evaluate bias, statistical drift/shift, fairness, and explainability.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Data Wrangler 与 SageMaker Studio 集成，专为机器学习、数据分析、特征工程、特征重要性分析和偏差检测而设计。通过
    Data Wrangler，我们可以指定自定义的 Apache Spark 用户定义函数、pandas 代码和 SQL 查询。此外，Data Wrangler
    还提供超过 300 种内置的数据转换功能，用于特征工程和偏差缓解。我们将在 [第 6 章](ch06.html#prepare_the_dataset_for_model_training)
    深入研究 SageMaker Data Wrangler 进行特征工程。现在，让我们使用 Data Wrangler 和 SageMaker Clarify
    分析数据集，后者是亚马逊 SageMaker 的一个功能，我们将在本书的其余部分中使用它来评估偏见、统计漂移/偏移、公平性和可解释性。
- en: Note
  id: totrans-456
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The SageMaker Data Wrangler service is different from the open source AWS Data
    Wrangler project. AWS Data Wrangler is used primarily for data ingestion and moving
    data between AWS services. SageMaker Data Wrangler is the preferred tool for ML-focused
    data ingestion, analysis, and transformation as it maintains full data lineage
    throughout the machine learning pipeline.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker Data Wrangler 服务与开源 AWS Data Wrangler 项目不同。AWS Data Wrangler 主要用于数据摄取和在
    AWS 服务之间传输数据。SageMaker Data Wrangler 则是首选的面向 ML 的数据摄取、分析和转换工具，因为它在整个机器学习流水线中保持完整的数据血统。
- en: Let’s use SageMaker Data Wrangler to analyze class imbalance relative to the
    `product_category` column, or “facet,” as it is commonly called in this context.
    Typically, we are analyzing sensitive facets like age and race. We have chosen
    to analyze the `product_category` facet since there may be differences in language
    used when writing gift card reviews versus software reviews, for example.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 SageMaker Data Wrangler 分析相对于 `product_category` 列的类别不平衡，或者在这种情况下通常称为“facet”的情况。通常，我们正在分析像年龄和种族这样敏感的“facet”。我们选择分析
    `product_category` facet，因为在撰写礼品卡评论与软件评论时可能存在语言使用的差异。
- en: Class imbalance is one example of data bias and, if not mitigated, may lead
    to model bias where the model disproportionately favors an overrepresented class,
    such as `Gift Card`, at the expense of an underrepresented class, such as `Digital_Software`.
    This may result in higher training error for the underrepresented, disadvantaged
    class.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 类不平衡是数据偏差的一个例子，如果不加以缓解，可能导致模型偏差，即模型不成比例地偏向过度表示的类别，例如`Gift Card`，而损害到欠表示的类别，例如`Digital_Software`。这可能导致欠表示的劣势类别训练误差较高。
- en: In other words, our model may more accurately predict the `star_rating` for
    gift cards versus software since our dataset has more gift cards reviews than
    software reviews. This is often called “selection bias” for the given facet, `product_category`
    in our case. We use SageMaker Data Wrangler and Clarify to generate a bias report
    with many metrics, including class imbalance (CI), difference in positive proportion
    labels (DPL), and Jensen–Shannon divergence (JS), among many others. [Figure 5-17](#detect_class_imbalance_through_a_sagema)
    shows a class imbalance for a subset of our dataset relative to the `Gift Card`
    product category and target `star_rating` of 5 and 4.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们的模型可能更准确地预测礼品卡的`star_rating`，而不是软件，因为我们的数据集中礼品卡的评论比软件的多。对于我们的情况，这通常被称为“选择偏差”关于`product_category`这一维度。我们使用SageMaker
    Data Wrangler和Clarify生成包括类不平衡（CI）、正面比例标签差异（DPL）和Jensen-Shannon散度（JS）在内的多个度量的偏差报告。[图 5-17](#detect_class_imbalance_through_a_sagema)
    显示了我们数据集的一个子集在`Gift Card`产品类别和目标`star_rating`为5和4时的类不平衡情况。
- en: This bias report shows a class imbalance of 0.45 for the `Gift Card` product
    category facet. The class imbalance values range over the interval [-1, 1]. Values
    closer to 0 indicate a balanced distribution of samples relative to the facet
    being analyzed. Values closer to -1 and 1 indicate an imbalanced dataset and may
    require balancing before proceeding with feature selection, feature engineering,
    and model training.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 这份偏差报告显示了`Gift Card`产品类别维度的0.45的类不平衡。类不平衡的值范围在[-1, 1]区间内。值接近0表明样本在分析的维度上分布均衡。接近-1和1的值表明数据集不平衡，可能需要在进行特征选择、特征工程和模型训练之前进行平衡处理。
- en: '![](assets/dsaw_0517.png)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0517.png)'
- en: Figure 5-17\. Detect class imbalance through a SageMaker Data Wrangler bias
    report.
  id: totrans-463
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-17\. 通过SageMaker Data Wrangler偏差报告检测类不平衡。
- en: In addition to detecting data bias with SageMaker Data Wrangler, SageMaker Clarify
    helps select the best columns (aka “features”) for model training, detects bias
    in our models after training, explains model predictions, and detects statistical
    drift of model prediction inputs and outputs. [Figure 5-18](#measure_data_biascomma_model_biascomma)
    shows where SageMaker Clarify is used throughout the remaining phases of the machine
    learning pipeline, including model training, tuning, and deployment.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用SageMaker Data Wrangler检测数据偏差外，SageMaker Clarify还帮助选择最佳的列（也称为“特征”）进行模型训练，在训练后检测模型的偏差，解释模型预测，并检测模型预测输入和输出的统计漂移。[图 5-18](#measure_data_biascomma_model_biascomma)
    显示了SageMaker Clarify在机器学习流水线的其余阶段中的使用，包括模型训练、调优和部署。
- en: '![](assets/dsaw_0518.png)'
  id: totrans-465
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0518.png)'
- en: Figure 5-18\. Measure data bias, model bias, feature importance, and model explainability
    with SageMaker Clarify.
  id: totrans-466
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-18\. 使用SageMaker Clarify测量数据偏差、模型偏差、特征重要性和模型可解释性。
- en: In [Chapter 7](ch07.html#train_your_first_model), we will calculate “post-training”
    metrics to detect bias in our model predictions in a similar fashion. In [Chapter 9](ch09.html#deploy_models_to_production),
    we will calculate drift in data distributions and model explainability on our
    live models in production by setting thresholds for various distribution-distance
    metrics, comparing the live metrics to a baseline set of metrics created from
    our trained model before the model is deployed, and alerting us when the thresholds
    are exceeded after the model is deployed.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](ch07.html#train_your_first_model)中，我们将计算“后训练”指标，以类似的方式检测模型预测中的偏差。在[第9章](ch09.html#deploy_models_to_production)中，我们将通过设定各种分布距离指标的阈值，将数据分布的漂移和模型可解释性计算在我们的生产中的实时模型上，将实时指标与从我们部署模型前的训练模型创建的基线指标进行比较，并在超过阈值后通知我们。
- en: Detect Bias with a SageMaker Clarify Processing Job
  id: totrans-468
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用SageMaker Clarify处理作业检测偏差
- en: 'We can also run Clarify as a SageMaker Processing Job to continually analyze
    our dataset at scale and calculate bias metrics as new data arrives. Following
    is the code to configure and run the `SageMakerClarifyProcessor` job using a `DataConfig`
    to specify our input dataset and `BiasConfig` to specify our `product_category`
    facet to analyze:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将Clarify作为SageMaker处理作业运行，以持续分析我们的数据集并在新数据到达时计算偏差度量。以下是配置和运行`SageMakerClarifyProcessor`作业的代码示例，使用`DataConfig`指定我们的输入数据集和`BiasConfig`指定我们要分析的`product_category`类别：
- en: '[PRE27]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We are using `methods='all'` to calculate all data-bias metrics during this
    “pre-training” phase, but we can specify the list of metrics, including CI, DPL,
    JS, Kullback–Leibler divergence (KL), Lp-norm (LP), total variation distance (TVD),
    the Kolmogorov–Smirnov metric (KS), and conditional demographic disparity (CDD).
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用`methods='all'`来在“预训练”阶段计算所有数据偏差度量，但我们可以指定度量列表，包括CI、DPL、JS、Kullback–Leibler
    divergence (KL)、Lp-norm (LP)、total variation distance (TVD)、Kolmogorov–Smirnov
    metric (KS)和conditional demographic disparity (CDD)。
- en: Once the `SageMakerClarifyProcessor` job finishes analyzing our dataset for
    bias, we view the generated bias reports in SageMaker Studio, as shown in [Figure 5-19](#extract_from_a_sagemaker_clarify_bias_r).
    In addition, SageMaker Clarify generates *analysis.json* with bias metrics and
    *report.ipynb* to visualize the bias metrics and share with our colleagues.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦`SageMakerClarifyProcessor`作业完成对我们的数据集进行偏差分析，我们可以在SageMaker Studio中查看生成的偏差报告，如[图 5-19](#extract_from_a_sagemaker_clarify_bias_r)所示。此外，SageMaker
    Clarify生成*analysis.json*文件以及包含偏差度量的*report.ipynb*文件，用于可视化偏差度量并与同事分享。
- en: '![](assets/dsaw_0519.png)'
  id: totrans-473
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0519.png)'
- en: Figure 5-19\. Extract from a SageMaker Clarify Bias Report generated by the
    SageMaker Processing Job.
  id: totrans-474
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-19\. 由SageMaker Processing Job生成的SageMaker Clarify偏差报告摘录。
- en: Integrate Bias Detection into Custom Scripts with SageMaker Clarify Open Source
  id: totrans-475
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将偏差检测集成到自定义脚本中，使用SageMaker Clarify开源工具
- en: 'SageMaker also offers Clarify as a standalone, [open source Python library](https://oreil.ly/9qIUn)
    to integrate bias and drift detection into our custom Python scripts. Following
    is an example using the `smclarify` Python library to detect bias and class imbalance
    from a Python script using a CSV file. To install this library, use `pip install
    smclarify`:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker还将Clarify作为独立的、[开源Python库](https://oreil.ly/9qIUn)提供，以将偏差和漂移检测集成到我们的自定义Python脚本中。以下是使用`smclarify`
    Python库从CSV文件中检测偏差和类不平衡的示例。要安装此库，请使用`pip install smclarify`：
- en: '[PRE28]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The result looks similar to this:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '[PRE29]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Mitigate Data Bias by Balancing the Data
  id: totrans-480
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过平衡数据来减少数据偏差
- en: 'We can mitigate the imbalances in our dataset by balancing the number of reviews
    across star rating classes and product categories, as shown in the following.
    [Figure 5-20](#the_number_of_reviews_is_now_balanced_a) visualizes the results
    for three sample product categories using Seaborn:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 通过平衡评级星级和产品类别中评论数量的平衡来减少数据集中的不平衡，如下所示。[图 5-20](#the_number_of_reviews_is_now_balanced_a)展示了使用Seaborn对三个样本产品类别进行的结果可视化：
- en: '[PRE30]'
  id: totrans-482
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![](assets/dsaw_0520.png)'
  id: totrans-483
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0520.png)'
- en: Figure 5-20\. The number of reviews is now balanced across star rating classes
    and product categories.
  id: totrans-484
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 5-20\. 现在评级星级和产品类别中的评论数量已经平衡。
- en: 'We can rerun the bias analysis using SageMaker Clarify on the balanced dataset.
    The following is a sample result for the facet value “Gift Card”:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在平衡数据集上重新运行SageMaker Clarify的偏差分析。以下是“Gift Card”类别面值的样本结果：
- en: '[PRE31]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can see that all but one of the bias metrics values equal 0, which indicates
    an equal distribution across the three product categories. The class imbalance
    metric value of 0.33 is evenly balanced since we have three total product categories.
    The other two product categories, Digital_Software and Digital_Video_Games, also
    have a class imbalance metric value of 0.33, as shown in the following:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到除一个偏差度量值外，所有偏差度量值均为0，这表明三个产品类别之间的分布是均等的。类不平衡度量值为0.33表示均衡，因为我们总共有三个产品类别。其他两个产品类别，Digital_Software和Digital_Video_Games，其类不平衡度量值也为0.33，如下所示：
- en: '[PRE32]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: A class imbalance metric value of 0.33 represents an evenly balanced dataset
    since we are analyzing three product categories. If we analyzed four product categories,
    the ideal class imbalance metric value would be 0.25 for all four product categories.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 类不平衡度量值为0.33表示数据集均衡，因为我们正在分析三个产品类别。如果我们分析四个产品类别，每个产品类别的理想类不平衡度量值将为0.25。
- en: Detect Different Types of Drift with SageMaker Clarify
  id: totrans-490
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SageMaker Clarify检测不同类型的漂移
- en: Statistical changes in data distributions are often called “shifts” in statistics
    terms or “drifts” in applied data science terms. There are multiple types of drifts,
    including “covariate,” “label shift,” and “concept shift.” Covariate shifts occur
    in the data distribution of model inputs (independent variables). Label shifts
    occur in the data distribution of model outputs (dependent variables). Concept
    shifts occur when the actual definition of a label changes depending on a particular
    feature, such as geographical location or age group.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分布中的统计变化通常称为统计术语中的“变化”，或者应用数据科学术语中的“漂移”。漂移的多种类型包括“协变量漂移”、“标签漂移”和“概念漂移”。协变量漂移发生在模型输入（自变量）的数据分布中。标签漂移发生在模型输出（因变量）的数据分布中。概念漂移发生在标签的实际定义因特定特征（如地理位置或年龄组）而改变时。
- en: Note
  id: totrans-492
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Throughout the book, we use the terms *drift* and *shift* interchangeably to
    represent changes in statistical distributions. For more information on types
    of distribution drifts/shifts, see [d2l.ai](https://oreil.ly/HjtbC).
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中，我们通常将“漂移”和“变化”这两个术语互换使用，以表示统计分布的变化。有关分布漂移/变化类型的更多信息，请参见[d2l.ai](https://oreil.ly/HjtbC)。
- en: Let’s analyze concept drift by analyzing how different regions of the United
    States have different names for “soft drinks.” The eastern region of the US calls
    soft drinks “soda,” the northern-middle region calls them “pop,” and the southern
    region calls them “coke.” The change in labels relative to geographical location
    (the concept drift) is illustrated in [Figure 5-21](#concept_shift_on_soft_drink_names_in_th).
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过分析美国不同地区对“软饮料”有不同名称来分析概念漂移。美国东部地区称软饮料为“苏打水”，北中部地区称其为“汽水”，南部地区则称其为“可乐”。相对于地理位置的标签变化（概念漂移）在[图5-21](#concept_shift_on_soft_drink_names_in_th)中有所说明。
- en: '![](assets/dsaw_0521.png)'
  id: totrans-495
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0521.png)'
- en: 'Figure 5-21\. Concept shift on soft drink names in the US. Source: [*http://popvssoda.com*](http://popvssoda.com).'
  id: totrans-496
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-21\. 美国软饮料名称的概念漂移。来源：[*http://popvssoda.com*](http://popvssoda.com).
- en: Another example of concept drift involved one of our early book reviewers, who
    used the term “beef” to describe [Chapter 9](ch09.html#deploy_models_to_production).
    While this term was initially interpreted as negative by the US- and Germany-based
    authors of this book, we realized that the term “beef” means something positive
    in the reviewer’s geographical location and age group. If we were building a model
    to classify reviews of our book, we may want to adjust for this concept drift
    by factoring in the reviewers’ location and age—or perhaps build separate models
    for different locations and age.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个概念漂移的例子涉及我们早期的书评者，他在描述[第9章](ch09.html#deploy_models_to_production)时使用“牛肉”一词。虽然这个术语最初被本书的美国和德国作者解释为负面的，但我们意识到在书评者的地理位置和年龄组中，“牛肉”一词意味着积极的含义。如果我们要建立一个用于分类我们书评的模型，我们可能需要考虑到评审人员的地理位置和年龄，或者也许为不同的地点和年龄建立单独的模型。
- en: To detect covariate and label drift, we calculate baseline statistics during
    model training. We then can set thresholds using various statistical distribution-distance
    metrics discussed earlier, like KL, KS, LP, L-infinity norm, and more. These metrics
    answer various questions about the bias. For example, the divergence metric KL
    answers “How different are the distributions of star ratings for different product
    categories?” Whereas the KS metric answers “Which star ratings cause the greatest
    disparity per product category?”
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 要检测协变量漂移和标签漂移，我们在模型训练期间计算基线统计信息。然后，我们可以使用之前讨论过的各种统计分布距离度量设置阈值，例如KL、KS、LP、L-infinity
    norm等。这些度量回答了关于偏差的各种问题。例如，散度度量KL回答了“不同产品类别的星级评分分布有多不同？”而KS度量则回答了“每个产品类别中哪些星级评分造成了最大的差异？”
- en: If the calculated drift is greater than the given threshold, SageMaker can alert
    us and automatically trigger a retrain action, for example. To detect concept
    drift in the predicted labels relative to a particular feature, we capture live
    model inputs and outputs using SageMaker Model Monitor and send the model inputs
    to an offline human labeling workflow to create the ground truth labels. We compare
    the captured model outputs to the ground truth labels provided by humans using
    SageMaker Clarify. If the distribution of model outputs differs beyond a given
    threshold relative to the ground truth labels, SageMaker can notify us and automatically
    trigger a model retrain, for example. We demonstrate how to use SageMaker Model
    Monitor and Clarify to monitor live predictions in [Chapter 9](ch09.html#deploy_models_to_production).
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 如果计算得出的漂移大于给定的阈值，SageMaker可以警告我们并自动触发重新训练操作。例如，为了检测预测标签相对于特定特征的概念漂移，我们使用SageMaker模型监控捕获实时模型输入和输出，并将模型输入发送到线下人工标注工作流程以创建地面真实标签。我们使用SageMaker
    Clarify将捕获的模型输出与人类提供的地面真实标签进行比较。如果模型输出的分布相对于地面真实标签超出了给定阈值，SageMaker可以通知我们并自动触发模型重新训练。我们展示了如何使用SageMaker模型监控和Clarify来监控[第9章](ch09.html#deploy_models_to_production)中的实时预测。
- en: Also in [Chapter 9](ch09.html#deploy_models_to_production), we demonstrate how
    SageMaker Model Monitor samples live model inputs and outputs, calculates model
    feature-importance and model-explainability statistics, and compares these statistics
    to a baseline created from our trained model. If SageMaker Model Monitor detects
    a shift in feature importance and model explainability relative to the baseline,
    it can automatically trigger a model retrain and notify the appropriate on-call
    scientist or engineer.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第9章](ch09.html#deploy_models_to_production)中，我们展示了SageMaker模型监控如何对实时模型输入和输出进行采样，计算模型特征重要性和可解释性统计，并将这些统计数据与从我们训练的模型创建的基准进行比较。如果SageMaker模型监控检测到特征重要性和模型可解释性相对于基准的变化，它可以自动触发模型重新训练，并通知适当的科学家或工程师。
- en: Analyze Our Data with AWS Glue DataBrew
  id: totrans-501
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AWS Glue DataBrew分析我们的数据
- en: 'We can use Glue DataBrew to analyze our data as well. While not natively integrated
    with SageMaker lineage and artifact tracking, DataBrew provides a slick, interactive
    visual interface to ingest and analyze data without writing any code. We can connect
    data sources from data lakes, data warehouses, and databases. Let’s load the Amazon
    Customer Reviews Dataset (Parquet) into DataBrew and analyze some of the visualizations:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用Glue DataBrew来分析我们的数据。虽然它与SageMaker的谱系和工件跟踪没有原生集成，但DataBrew提供了一个流畅、互动的视觉界面，可以在不编写任何代码的情况下进行数据摄取和分析。我们可以连接来自数据湖、数据仓库和数据库的数据源。让我们将亚马逊客户评论数据集（Parquet格式）加载到DataBrew中，并分析一些可视化效果：
- en: '[PRE33]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Once the dataset is created within DataBrew, we start seeing correlations and
    other summary statistics, as shown in [Figure 5-22](#aws_glue_databrew_shows_correlations_be).
    Specifically, we can see a strong correlation between `helpful_votes` and `total_votes`,
    while `star_rating` is not correlated with either `helpful_votes` or `total_votes`.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在DataBrew中创建了数据集，我们开始看到相关性和其他摘要统计信息，如[图5-22](#aws_glue_databrew_shows_correlations_be)所示。具体来说，我们可以看到`helpful_votes`和`total_votes`之间存在强相关性，而`star_rating`与`helpful_votes`或`total_votes`均不相关。
- en: In addition to correlations, DataBrew highlights missing cells, duplicate rows,
    and class imbalances, as shown in [Figure 5-23](#aws_glue_databrew_highlights_class_imba).
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 除了相关性之外，DataBrew还突出显示了缺失单元格、重复行和类别不平衡情况，如[图5-23](#aws_glue_databrew_highlights_class_imba)所示。
- en: '![](assets/dsaw_0522.png)'
  id: totrans-506
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0522.png)'
- en: Figure 5-22\. Glue DataBrew shows correlations between dataset columns.
  id: totrans-507
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-22\. Glue DataBrew展示了数据集列之间的相关性。
- en: '![](assets/dsaw_0523.png)'
  id: totrans-508
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dsaw_0523.png)'
- en: Figure 5-23\. Glue DataBrew highlights class imbalances between star rating
    classes 1–5.
  id: totrans-509
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-23\. Glue DataBrew突出显示了星级评分类别1-5之间的类别不平衡情况。
- en: We can use Glue DataBrew for a lot of data analysis and transformation use cases,
    but we should use SageMaker Data Wrangler for machine-learning-based workloads
    to better track our data and model lineage throughout the pipeline.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Glue DataBrew进行大量数据分析和转换用例，但是对于基于机器学习的工作负载，我们应该使用SageMaker Data Wrangler以便在整个流水线中更好地跟踪我们的数据和模型谱系。
- en: Reduce Cost and Increase Performance
  id: totrans-511
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 降低成本，提高性能
- en: In this section, we want to provide some tips and tricks to reduce cost and
    increase performance during data exploration. We can optimize expensive SQL `COUNT`
    queries across large datasets by using approximate counts. Leveraging Redshift
    AQUA, we can reduce network I/O and increase query performance. And if we feel
    our QuickSight dashboards could benefit from a performance increase, we should
    consider enabling QuickSight SPICE.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们希望提供一些技巧，帮助在数据探索过程中降低成本并提高性能。我们可以通过使用近似计数来优化大数据集中昂贵的 SQL `COUNT` 查询。利用
    Redshift AQUA，我们可以减少网络 I/O 并提升查询性能。如果我们觉得 QuickSight 仪表板的性能可以得到提升，可以考虑启用 QuickSight
    SPICE。
- en: Use a Shared S3 Bucket for Nonsensitive Athena Query Results
  id: totrans-513
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用共享的 S3 存储桶存储非敏感 Athena 查询结果
- en: 'By choosing a shared S3 location for Athena query results across our team,
    we can reuse cached query results, improve query performance, and save on data-transfer
    costs. The following code sample highlights `s3_staging_dir`, which can be shared
    across different team members to improve the performance of commonly executed
    queries by reusing cached results:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 通过为我们团队选择一个共享的 S3 位置来存储 Athena 查询结果，我们可以重复使用缓存的查询结果，提升查询性能，并节省数据传输成本。以下代码示例突出了
    `s3_staging_dir`，这个目录可以在不同的团队成员之间共享，以改善常见查询的性能：
- en: '[PRE34]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Approximate Counts with HyperLogLog
  id: totrans-516
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 HyperLogLog 进行近似计数
- en: Counting is a big deal in analytics. We always need to count users (daily active
    users), orders, returns, support calls, etc. Maintaining super-fast counts in
    an ever-growing dataset can be a critical advantage over competitors.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析中，计数是非常重要的。我们经常需要计算用户数（日活跃用户）、订单数、退货数、支持电话等。在不断增长的数据集中保持超快速的计数能力可能是与竞争对手的关键优势。
- en: Both Amazon Redshift and Athena support HyperLogLog (HLL), a type of “cardinality-estimation”
    or `COUNT DISTINCT` algorithm designed to provide highly accurate counts (< 2%
    error) in a small amount of time (seconds) requiring a tiny fraction of the storage
    (1.2 KB) to store 150+ million separate counts. HLL is a probabilistic data structure
    that is common in counting use cases such as number of likes, number of page visits,
    number of click-throughs, etc.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Redshift 和 Athena 都支持 HyperLogLog（HLL），这是一种“基数估计”或 `COUNT DISTINCT` 算法，旨在在很短的时间内提供高度精确的计数（<
    2% 的误差），并且只需很小的存储空间（1.2 KB）来存储 1.5 亿个以上的计数。HLL 是一种概率数据结构，在计数类似点赞数、页面访问数、点击量等场景中非常常见。
- en: Note
  id: totrans-519
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Other forms of HLL include HyperLogLog++, Streaming HyperLogLog, and HLL-TailCut+,
    among others. Count-Min Sketch and Bloom Filters are similar algorithms for approximating
    counts and set membership, respectively. Locality Sensitive Hashing (LSH) is another
    popular algorithm for calculating “fuzzy” similarity metrics on large datasets
    with a small footprint.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: 其他形式的 HLL 包括 HyperLogLog++、Streaming HyperLogLog 和 HLL-TailCut+ 等。Count-Min
    Sketch 和 Bloom Filters 是用于近似计数和集合成员关系的类似算法。局部敏感哈希（LSH）是另一种在大数据集上计算“模糊”相似度度量的流行算法，且占用空间很小。
- en: The way this works is that Amazon Redshift and Athena update a tiny HLL data
    structure when inserting new data into the database (think of a tiny hash table).
    The next time a count query arrives from a user, Amazon Redshift and Athena simply
    look up the value in the HLL data structure and quickly return the value—without
    having to physically scan all the disks in the cluster to perform the count.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 这种工作方式是，当在数据库中插入新数据时，Amazon Redshift 和 Athena 会更新一个小的 HLL 数据结构（类似于一个小型哈希表）。当用户发送计数查询时，Amazon
    Redshift 和 Athena 只需在 HLL 数据结构中查找该值，然后快速返回结果，而无需物理扫描整个集群中的所有磁盘进行计数。
- en: 'Let’s compare the execution times of both `SELECT APPROXIMATE COUNT()` and
    `SELECT COUNT()` in Amazon Redshift. Here is `SELECT APPROXIMATE COUNT()`:'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较在 Amazon Redshift 中 `SELECT APPROXIMATE COUNT()` 和 `SELECT COUNT()` 的执行时间。以下是
    `SELECT APPROXIMATE COUNT()` 的执行示例：
- en: '[PRE35]'
  id: totrans-523
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'For this query, we should see output similar to this:'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个查询，我们应该看到类似于以下输出：
- en: '[PRE36]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Next up, `SELECT COUNT()`:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是，`SELECT COUNT()`：
- en: '[PRE37]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'For this query, we should see output similar to this:'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个查询，我们应该看到类似于以下输出：
- en: '[PRE38]'
  id: totrans-529
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Note
  id: totrans-530
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Note that we run the `APPROXIMATE COUNT` first to factor out the performance
    boost of the query cache. The `COUNT` is much slower. If we rerun, both queries
    will be very fast due to the query cache.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们首先运行 `APPROXIMATE COUNT` 来排除查询缓存带来的性能提升。`COUNT` 的速度要慢得多。如果我们重新运行，由于查询缓存的存在，这两个查询都将变得非常快。
- en: We see that `APPROXIMATE COUNT DISTINCT` is 160% faster than regular `COUNT
    DISTINCT` in this case. The results were approximately 1.2% different—satisfying
    the < 2% error guaranteed by HLL.
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，在这种情况下，`APPROXIMATE COUNT DISTINCT`比常规的`COUNT DISTINCT`快160%。结果大约相差1.2%，满足HLL保证的小于2%的误差。
- en: Remember that HLL is an approximation and may not be suitable for use cases
    that require exact numbers (e.g., financial reporting).
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，HLL是一种近似方法，可能不适用于需要精确数字（例如财务报告）的用例。
- en: Dynamically Scale a Data Warehouse with AQUA for Amazon Redshift
  id: totrans-534
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用AQUA动态扩展Amazon Redshift的数据仓库
- en: Existing data warehouses move data from storage nodes to compute nodes during
    query execution. This requires high network I/O between the nodes—and reduces
    overall query performance. AQUA (Advanced Query Accelerator) is a hardware-accelerated,
    distributed cache on top of our Amazon Redshift data warehouse. AQUA uses custom,
    AWS-designed chips to perform computations directly in the cache. This reduces
    the need to move data from storage nodes to compute nodes—therefore reducing network
    I/O and increasing query performance. These AWS-designed chips are implemented
    in field programmable gate arrays and help speed up data encryption and compression
    for maximum security of our data. AQUA dynamically scales out more capacity as
    well.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的数据仓库在查询执行期间将数据从存储节点移动到计算节点。这需要节点间的高网络I/O，降低了整体查询性能。AQUA（高级查询加速器）是我们Amazon
    Redshift数据仓库顶部的硬件加速、分布式缓存。AQUA使用定制的AWS设计芯片直接在缓存中执行计算。这减少了从存储节点到计算节点移动数据的需求，因此减少了网络I/O并增加了查询性能。这些AWS设计的芯片采用可编程门阵列实现，有助于加快数据加密和压缩，确保我们数据的最大安全性。AQUA还可以动态扩展更多的容量。
- en: Improve Dashboard Performance with QuickSight SPICE
  id: totrans-536
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用QuickSight SPICE改进仪表板性能
- en: QuickSight is built with the “Super-fast, Parallel, In-memory Calculation Engine,”
    or SPICE. SPICE uses a combination of columnar storage, in-memory storage, and
    machine code generation to run low-latency queries on large datasets. QuickSight
    updates its cache as data changes in the underlying data sources, including Amazon
    S3 and Redshift.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: QuickSight是使用“超快、并行、内存计算引擎”SPICE构建的。SPICE使用列存储、内存存储和机器代码生成的组合来在大型数据集上运行低延迟查询。QuickSight在底层数据源（包括Amazon
    S3和Redshift）数据更改时更新其缓存。
- en: Summary
  id: totrans-538
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we answered various questions about our data using tools from
    the AWS analytics stack, including Athena and Amazon Redshift. We created a business
    intelligence dashboard using QuickSight and deployed a SageMaker Processing Job
    using open source AWS Deequ and Apache Spark to continuously monitor data quality
    and detect anomalies as new data arrives. This continuous data-quality monitoring
    creates confidence in our data pipelines and allows downstream teams, including
    data scientists and AI/ML engineers, to develop highly accurate and relevant models
    for our applications to consume. We also used Glue DataBrew and SageMaker Data
    Wrangler to analyze our data for correlations, anomalies, imbalances, and bias.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用AWS分析堆栈中的工具（包括Athena和Amazon Redshift）回答了关于我们数据的各种问题。我们使用QuickSight创建了业务智能仪表板，并使用开源的AWS
    Deequ和Apache Spark部署了SageMaker Processing Job，以持续监控数据质量并在新数据到达时检测异常。这种持续的数据质量监控增强了我们数据管道的信心，并允许包括数据科学家和AI/ML工程师在内的下游团队开发高度精确和相关的模型，供我们的应用程序消费。我们还使用Glue
    DataBrew和SageMaker Data Wrangler分析我们的数据，寻找相关性、异常、不平衡和偏见。
- en: In [Chapter 6](ch06.html#prepare_the_dataset_for_model_training), we will select
    and prepare features from our dataset to use in the model training and optimization
    phases in Chapters [7](ch07.html#train_your_first_model) and [8](ch08.html#train_and_optimize_models_at_scale),
    respectively.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](ch06.html#prepare_the_dataset_for_model_training)中，我们将从数据集中选择并准备特征，以在第[7章](ch07.html#train_your_first_model)和第[8章](ch08.html#train_and_optimize_models_at_scale)中用于模型训练和优化阶段。
