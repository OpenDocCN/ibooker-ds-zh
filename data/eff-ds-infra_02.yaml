- en: 2 The toolchain of data science
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 数据科学工具链
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节涵盖
- en: The key activities that the data scientist engages in on a daily basis
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家在日常生活中参与的关键活动
- en: The essential toolchain that makes the data scientist productive
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使数据科学家高效的基本工具链
- en: The role of workflows in the infrastructure stack
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流程在基础设施堆栈中的作用
- en: Every profession has its tools of the trade. If you are a carpenter, you need
    saws, rulers, and chisels. If you are a dentist, you need mirrors, drills, and
    syringes. If you are a data scientist, what are the essential tools that you need
    in your daily job?
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 每个职业都有其行业工具。如果你是一名木匠，你需要锯子、尺子和凿子。如果你是一名牙医，你需要镜子、钻头和注射器。如果你是一名数据科学家，你在日常工作中需要哪些基本工具呢？
- en: Obviously, you need a computer. But what’s the purpose of the computer? Should
    it be used to run heavy computation, train models, and such, or should it be just
    a relatively dumb terminal for typing code and analyzing results? Because production
    applications execute outside personal laptops, maybe prototyping should happen
    as close to the real production environment as possible, too. Answering questions
    like this can be surprisingly nontrivial, and the answers can have deep implications
    for the whole infrastructure stack.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，你需要一台电脑。但电脑的用途是什么？它应该用于运行重型计算、训练模型等，还是仅仅作为一个相对笨拙的终端，用于编写代码和分析结果？由于生产应用程序在个人笔记本电脑之外执行，也许原型设计应该尽可能接近真实的生产环境。回答这类问题可能出人意料地复杂，而且答案可能对整个基础设施堆栈产生深远的影响。
- en: 'As we highlighted in chapter 1, ultimately these tools exist to boost the productivity
    of the data scientist. We must carefully think through the actions that form the
    body of the data scientist’s daily work: exploring and analyzing data, writing
    code, evaluating it, and inspecting results. How can we make these actions as
    frictionless as possible, knowing that they may be repeated hundreds of times
    every day? There isn’t a single right answer. This chapter will give you food
    for thought and technical guidance for setting up a toolchain that works for your
    company and technical environment.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第一章中强调的，这些工具最终存在是为了提高数据科学家的生产力。我们必须仔细思考构成数据科学家日常工作主体的行动：探索和分析数据、编写代码、评估它并检查结果。如何使这些行动尽可能无摩擦，考虑到它们每天可能重复数百次？没有唯一的正确答案。本章将为你提供思考和技术指导，以设置适合您公司和技术环境的工具链。
- en: Think of the full stack of data science as a jet fighter—a complex feat of engineering
    consisting of a myriad of interconnected components. This chapter deals with the
    cockpit and the dashboard that the pilot uses to operate the machine. In the engineering
    point of view, the cockpit might feel a bit secondary, essentially just a control
    stick and a bunch of buttons (or in the case of data science, just an editor and
    a notebook) compared to 30,000 pounds of heavy engineering underneath, but often
    it is the component that determines the success or failure of a mission.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据科学的全栈想象成一架喷气式战斗机——一个由无数相互连接的组件组成的复杂工程壮举。本章将探讨飞行员操作机器时使用的驾驶舱和仪表盘。从工程的角度来看，驾驶舱可能感觉有些次要，本质上只是一个控制杆和一些按钮（在数据科学的情况下，只是一个编辑器和笔记本），与下面的3万磅重的重型工程相比，但往往正是决定任务成功或失败的那个组件。
- en: Following the journey of a data scientist
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 跟随数据科学家的旅程
- en: To make the discussion more concrete and grounded to the needs of real-world
    businesses, we will follow the journey of a hypothetical data scientist, Alex,
    throughout the book. Alex’s journey features typical challenges that a data scientist
    faces in a modern business environment. Alex helps to keep our focus on human-centric
    infrastructure and to demonstrate how infrastructure can grow incrementally together
    with the company. Each section begins with a motivating scenario related to Alex’s
    life at work, which we will analyze and address in the section in detail.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使讨论更加具体和贴近现实商业需求，我们将跟随一位假设的数据科学家，亚历克斯，在整个书中展开旅程。亚历克斯的旅程展示了数据科学家在现代商业环境中面临的典型挑战。亚历克斯帮助我们保持对以人为本的基础设施的聚焦，并展示基础设施如何与公司一起逐步增长。每个部分都以与亚历克斯工作生活相关的激励场景开始，我们将详细分析和解决这些问题。
- en: Besides Alex the data scientist, the cast of characters includes Harper, who
    is the founder of the startup where Alex works. We will also meet Bowie, who is
    an infrastructure engineer whose duties include providing support for data scientists.
    This book is targeted at all the Alexes and Bowies out there, but the broader
    context might be interesting for Harpers, too.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据科学家亚历克斯之外，角色还包括哈珀，他是亚历克斯工作的初创公司的创始人。我们还将遇到波维，他是一位基础设施工程师，其职责包括为数据科学家提供支持。这本书的目标是针对所有像亚历克斯和波维这样的人，但更广泛的环境也可能对哈珀们来说很有趣。
- en: '*Alex has a PhD in marine biology. After realizing that people with skills
    in statistical analysis, basic machine learning, and rudimentary knowledge of
    Python are highly valued as data scientists, Alex decides to move from academia
    to industry.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*亚历克斯拥有海洋生物学博士学位。在意识到具有统计分析、基本机器学习以及Python基础知识的人作为数据科学家非常受重视后，亚历克斯决定从学术界转向工业界。*'
- en: '![CH02_00_UN01_Tuulos](../../OEBPS/Images/CH02_00_UN01_Tuulos.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_00_UN01_Tuulos](../../OEBPS/Images/CH02_00_UN01_Tuulos.png)'
- en: 2.1 Setting up a development environment
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 设置开发环境
- en: '*Alex joins Harper’s startup, Caveman Cupcakes, which manufactures and delivers
    soon-to-be-personalized paleo cupcakes, as its first data scientist. Bowie, who
    is an infrastructure engineer at Caveman, helps Alex get started. Alex asks Bowie
    if data scientists at Caveman can use Jupyter notebooks to get their job done.
    It would be great if they did, because Alex became very familiar with notebooks
    in academia. Hearing this makes Bowie realize that data scientists have special
    tooling needs. What tools should they install, and how should they be configured
    to make Alex most productive?*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*亚历克斯加入了哈珀的初创公司Caveman Cupcakes，该公司作为其首位数据科学家，负责制造和交付即将个性化的原始人风格杯型蛋糕。波维，作为Caveman的基础设施工程师，帮助亚历克斯开始工作。亚历克斯询问波维，Caveman的数据科学家是否可以使用Jupyter笔记本来完成工作。如果他们能这样做，那就太好了，因为亚历克斯在学术界已经非常熟悉笔记本了。听到这个，波维意识到数据科学家有特殊的工具需求。他们应该安装哪些工具，以及如何配置这些工具以使亚历克斯的工作效率最大化？*'
- en: '![CH02_00_UN02_Tuulos](../../OEBPS/Images/CH02_00_UN02_Tuulos.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_00_UN02_Tuulos](../../OEBPS/Images/CH02_00_UN02_Tuulos.png)'
- en: If you have time to set up only one piece of infrastructure well, make it the
    development environment for data scientists. Although this may sound obvious,
    you would be surprised to know how many companies have a well-tuned, scalable
    production infrastructure, but the question of how the code is developed, debugged,
    and tested in the first place is solved in an ad hoc manner. Instead of treating
    personal workstations merely as an IT problem, we should consider the development
    environment as an integral part of the effective infrastructure. After all, arguably
    the most important success factor of any data science project is the people involved
    and their productivity.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只有时间设置好一项基础设施，那就让它是数据科学家的开发环境。虽然这听起来可能很显然，但你可能会惊讶地发现，许多公司都有调校良好、可扩展的生产基础设施，但最初代码的开发、调试和测试问题却以临时方式解决。我们不应仅仅将个人工作站视为一个IT问题，而应将开发环境视为有效基础设施的有机组成部分。毕竟，任何数据科学项目最重要的成功因素是参与其中的人及其工作效率。
- en: 'A dictionary defines *ergonomics* as “the study of people’s efficiency in their
    working environment,” which nicely summarizes the focus of this chapter. The development
    environment for data science needs to optimize the ergonomics of the following
    two human activities:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 词典将*人体工程学*定义为“研究人们在工作环境中的效率”，这很好地总结了本章的重点。数据科学的发展环境需要优化以下两种人类活动的效率：
- en: '*Prototyping*—The iterative process that translates human knowledge and expertise
    into functional code and models'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*原型设计*——将人类知识和专业知识转化为功能性代码和模型的过程'
- en: '*Interaction with production deployments*—The act of connecting the code and
    models to surrounding systems and operating these production deployments so that
    they can produce sustainable business value'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*与生产部署的交互*——将代码和模型连接到周围系统，并运行这些生产部署，以便它们能够产生可持续的商业价值'
- en: 'The prototyping loop, which is depicted in the figure 2.1, is familiar from
    software engineering where it is called the *REPL*, the read-evaluate-print loop.
    You develop code in an editor, evaluate it with an interactive interpreter or
    a terminal, and analyze the results. Based on the results, you fix and improve
    the code and restart the loop. The loop works similarly for data science: you
    develop a model or code that processes data, evaluate it, and analyze the results.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1中展示的原型循环在软件工程中很常见，被称为*REPL*，即读取-评估-打印循环。你在编辑器中编写代码，用交互式解释器或终端评估它，并分析结果。根据结果，你修复并改进代码，然后重新启动循环。这个循环在数据科学中也同样适用：你开发一个处理数据的模型或代码，评估它，并分析结果。
- en: '![CH02_F01_Tuulos](../../OEBPS/Images/CH02_F01_Tuulos.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F01_Tuulos](../../OEBPS/Images/CH02_F01_Tuulos.png)'
- en: Figure 2.1 Prototyping loop
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 原型循环
- en: 'To boost the productivity of data scientists, we want to make each iteration
    of this loop as quick and effortless as possible. This involves optimizing each
    step as well as the transitions between the steps: how long does it take to write
    a snippet of code and evaluate it? How easily can you fetch the results and start
    analyzing them? Is it easy to explore, analyze, and understand the outcomes and
    change the code accordingly? Ultimately, we need cooperation between all layers
    of the infrastructure stack to answer these questions, but we will start laying
    the groundwork in the following subsections.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高数据科学家的生产力，我们希望使这个循环的每一次迭代尽可能快且不费力。这涉及到优化每个步骤以及步骤之间的转换：编写并评估一小段代码需要多长时间？你能否轻松地获取结果并开始分析它们？是否容易探索、分析和理解结果，并相应地更改代码？最终，我们需要基础设施堆栈所有层的合作来回答这些问题，但我们将从以下小节开始奠定基础。
- en: 'After countless iterations of the prototyping loop, the data scientist has
    a piece of code that produces a promising model or other desired output. Although
    this is a big milestone for the data scientist, many open questions remain: will
    the model produce expected results when connected to real-world data? Will the
    model scale to all data it needs to handle? Is the model robust against changes
    that will happen over time? Will there be any other operational surprises?'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 经过无数次的原型循环迭代后，数据科学家拥有了一段能够产生有希望模型或其他所需输出的代码。尽管这对数据科学家来说是一个重要的里程碑，但许多开放性问题仍然存在：当连接到真实世界数据时，模型会产生预期的结果吗？模型能否扩展到它需要处理的所有数据？模型能否抵御随时间发生的变化？是否会有其他运营意外？
- en: Trying to answer these questions in a prototyping environment is hard. Instead,
    we should make it easy to deploy the model to a production environment as an experiment,
    so we can observe how the model performs in practice. It is expected that the
    first versions of the model won’t work flawlessly, but production failures provide
    invaluable information that we can use to improve the model.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在原型环境中尝试回答这些问题是困难的。相反，我们应该使模型作为实验部署到生产环境变得容易，这样我们就可以观察模型在实际中的表现。预计模型的第一个版本可能不会完美运行，但生产故障提供了宝贵的见解，我们可以利用这些见解来改进模型。
- en: Conducting controlled empirical experiments like this is the core of the scientific
    method. The scientist formulates a hypothesis, performs an experiment, and analyzes
    the results. Compare this to how SpaceX developed a new reusable rocket, Falcon
    9, iteratively through 20 test launches before the first successful booster landing,
    as depicted in figure 2.2.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 进行此类受控的实证实验是科学方法的核心。科学家提出一个假设，进行实验，并分析结果。将此与SpaceX如何通过20次测试发射迭代开发新的可重复使用的火箭Falcon
    9，并在图2.2中展示的第一次成功助推器着陆之前，进行对比。
- en: '![CH02_F02_Tuulos](../../OEBPS/Images/CH02_F02_Tuulos.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F02_Tuulos](../../OEBPS/Images/CH02_F02_Tuulos.png)'
- en: Figure 2.2 SpaceX iterating on Falcon 9
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 SpaceX对Falcon 9的迭代
- en: This cycle of deploying to production, observing issues, and fixing them using
    the prototyping loop forms a higher-order loop, which we call *interaction with
    production deployments*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 将部署到生产环境、观察问题并使用原型循环解决问题这一周期形成一个更高层次的循环，我们称之为*与生产部署的交互*。
- en: 'As shown in figure 2.3, a production deployment is not a one-way waterfall
    but an iterative loop, working in conjunction with the prototyping loop. We want
    to make it easy for the data scientist to understand how and why the model fails
    in production and help them reproduce any issues locally, so they can improve
    the model using their familiar prototyping loop. Notably, in successful projects,
    these loops become infinite loops: a successful model is subject to never-ending
    improvement and debugging.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如图2.3所示，生产部署不是一个单向的瀑布流程，而是一个迭代循环，与原型设计循环协同工作。我们希望让数据科学家更容易理解模型在生产中失败的原因和方式，并帮助他们本地重现任何问题，以便他们可以使用他们熟悉的原型设计循环来改进模型。值得注意的是，在成功的项目中，这些循环变成了无限循环：一个成功的模型会不断受到改进和调试的考验。
- en: '![CH02_F03_Tuulos](../../OEBPS/Images/CH02_F03_Tuulos.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F03_Tuulos](../../OEBPS/Images/CH02_F03_Tuulos.png)'
- en: Figure 2.3 Interaction with production deployments
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 与生产部署的交互
- en: 'In the world of software engineering, the concept is called *continuous delivery*
    (CD). Although CD systems, like GitHub Actions ([github.com/features/actions](https://github.com/features/actions)),
    can be used to facilitate data science deployments, some crucial differences exist
    between data science applications and traditional software. Consider the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件工程的世界里，这个概念被称为*持续交付*（CD）。尽管CD系统，如GitHub Actions ([github.com/features/actions](https://github.com/features/actions))，可以用来促进数据科学部署，但数据科学应用与传统软件之间存在一些关键差异。考虑以下内容：
- en: '*Correctness*—It is relatively easy to confirm through automated tests that
    traditional software works correctly *before* it is deployed to production. This
    is typically not the case with data science. The goal of deploying, such as performing
    an A/B experiment, is to validate the correctness *after* the deployment.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*正确性*—通过自动化测试相对容易确认传统软件在部署到生产之前是否正确工作。在数据科学中通常并非如此。部署的目标，例如执行A/B测试，是在部署后验证正确性。'
- en: '*Stability*—Again, it is relatively easy to confirm through automated tests
    that traditional software works as expected in its well-defined environment. In
    contrast, data science applications are subject to constantly changing data, which
    exposes them to surprises that happen after deployment.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*稳定性*—同样，通过自动化测试相对容易确认传统软件在其定义良好的环境中按预期工作。相比之下，数据科学应用受到不断变化的数据的影响，这使得它们在部署后面临意外情况。'
- en: '*Variety*—It is possible to develop a traditional software component that does
    the job it is intended to do more or less perfectly. In contrast, it is hard to
    reach such a level of perfection with models because we always have new ideas
    and data that we can test. Correspondingly, it is desirable to be able to deploy
    many versions of the model in parallel and iterate quickly.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多样性*—可以开发一个传统软件组件，使其能够相对完美地完成预期的工作。相比之下，由于我们总是有新的想法和数据可以测试，因此很难达到这样的完美水平。相应地，能够并行部署多个模型版本并快速迭代是可取的。'
- en: '*Culture*—The world of DevOps and infrastructure engineering has a deep culture
    and jargon of its own, which is not covered by most data science curricula. Following
    our human-centric ethos, it is not reasonable to expect that data scientists,
    who are experts in their own domain, will suddenly become experts in another domain.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文化*—DevOps和基础设施工程的世界有其自己的深厚文化和术语，这通常不被大多数数据科学课程所涵盖。遵循我们以人为本的伦理，我们不应该期望数据科学家，他们在自己的领域是专家，会突然成为另一个领域的专家。'
- en: We can learn from and partially leverage existing CD systems as we build effective
    infrastructure tailored for the needs of data science. The two loops introduced
    earlier are conceptual sequences of actions that the scientist repeats to develop,
    deploy, and debug data science applications. The remainder of this chapter will
    make them more concrete. We will cover the actual tools that the data scientist
    should use and discuss how to best set them up. Though it is impossible to prescribe
    a single correct way of configuring your data science environment—details depend
    on your surrounding business infrastructure—we will provide enough technical background
    and evaluation rubrics so you will be able to make informed decisions based on
    your exact needs. Figure 2.4 gives you an idea of what to expect.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建针对数据科学需求量身定制的基础设施时，我们可以从现有的CD系统中学习和部分利用。前面引入的两个循环是科学家重复以开发、部署和调试数据科学应用程序的概念性行动序列。本章的剩余部分将使它们更加具体。我们将介绍数据科学家应该使用的实际工具，并讨论如何最佳地设置它们。尽管无法规定配置数据科学环境的唯一正确方式——细节取决于你的业务基础设施——但我们将提供足够的技术背景和评估标准，以便你能够根据你的具体需求做出明智的决定。图2.4为你提供了一个预期概念。
- en: '![CH02_F04_Tuulos](../../OEBPS/Images/CH02_F04_Tuulos.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F04_Tuulos](../../OEBPS/Images/CH02_F04_Tuulos.png)'
- en: Figure 2.4 The elements of the data science toolchain
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 数据科学工具链的元素
- en: 'Our focal point is the data scientist, who will use the toolchain to power
    the two core activities: prototyping loop (A) and interaction with production
    deployments (B).'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的关注点是数据科学家，他将使用工具链来推动两个核心活动：原型循环（A）和生产部署的交互（B）。
- en: In the following subsections, we will cover the key productivity tools that
    we should provide for the scientist.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下小节中，我们将介绍我们应该为科学家提供的核心生产力工具。
- en: In section 2.2, we will highlight why it is useful to structure data science
    applications as workflows.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在2.2节中，我们将强调将数据科学应用程序结构化为工作流的有用之处。
- en: We will also make the case for running the prototyping loop in an environment
    that resembles the production environment as closely as possible—in practice,
    backing the prototyping loop with a cloud instance.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将论证在尽可能类似于生产环境的环境中运行原型循环的合理性——在实践中，通过云实例支持原型循环。
- en: This chapter introduces a user interface, a cockpit that the scientist uses
    to command and control the production environment, which will be covered in detail
    in subsequent chapters.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章介绍了用户界面，一个科学家用来指挥和控制生产环境的驾驶舱，这将在后续章节中详细说明。
- en: 2.1.1 Cloud account
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.1 云账户
- en: The infrastructure we will build in this book assumes that you have an account
    with a public cloud provider such as Amazon Web Services (AWS), Google Cloud Platform
    (GCP), or Microsoft Azure. We will use AWS in all the examples because it is the
    most widely used cloud platform today. You should be able to adapt examples and
    concepts to other cloud environments, including private clouds, relatively easily.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 本书我们将构建的基础设施假设你已经在公共云提供商（如亚马逊网络服务（AWS）、谷歌云平台（GCP）或微软Azure）有一个账户。我们将使用AWS作为所有示例，因为它是目前最广泛使用的云平台。你应该能够相对容易地将示例和概念适应到其他云环境中，包括私有云。
- en: AWS provides a free tier that allows you to set up the bare-bones infrastructure
    introduced in this book for minimal or no cost. Hence, it is highly encouraged
    that you create an AWS account, unless you have one already. Creating one is easy—just
    follow the instructions at [aws.amazon.com/free](https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsf.Free%20Tier%20Categories=*all).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: AWS提供免费层，允许你以最低或无成本设置本书中介绍的裸机基础设施。因此，强烈建议你创建一个AWS账户，除非你已经有了一个。创建一个账户很简单——只需遵循[aws.amazon.com/free](https://aws.amazon.com/free/?all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc&awsf.Free%20Tier%20Types=*all&awsf.Free%20Tier%20Categories=*all)上的说明。
- en: Many companies have existing cloud accounts. You should be able to use them
    for the purposes of this book. We won’t cover how to configure user accounts and
    perform authentication and authorization, such as IAM users and policies for AWS.
    These concerns are not specific to data science, and you should be able to use
    the same policies that you have used before.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 许多公司已有现成的云账户。你应该能够为本书的目的使用它们。我们不会涵盖如何配置用户账户以及执行身份验证和授权，例如AWS的IAM用户和政策。这些问题并不特定于数据科学，你应该能够使用你之前使用过的相同策略。
- en: 2.1.2 Data science workstation
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.2 数据科学工作站
- en: The data scientist needs a workstation to drive the prototyping loop, that is,
    develop, test, and deploy code and models. These days, the physical workstation
    is typically a personal laptop. However, the production code and models should
    never run on a laptop, due to the need for high availability and scalability.
    Instead, we deploy the production models in a cloud environment. In addition to
    differences in development and production hardware, the operating system is often
    different. It is common to use either OS X or Windows on laptops and Linux on
    servers.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家需要一个工作站来驱动原型循环，即开发、测试和部署代码和模型。如今，物理工作站通常是个人笔记本电脑。然而，由于需要高可用性和可扩展性，生产代码和模型不应在笔记本电脑上运行。相反，我们在云环境中部署生产模型。除了开发和生产硬件的差异外，操作系统也往往不同。在笔记本电脑上通常使用
    OS X 或 Windows，而在服务器上使用 Linux。
- en: A technical gap often occurs between the development workstation and the production
    environment, which can cause friction when interacting with production deployments.
    The gap is not unique to data science. For instance, web application developers
    often operate in a similar environment. However, the gap is especially problematic
    for data science for a few reasons. The modern modeling libraries tend to be highly
    optimized to specific GPU and CPU architectures, in contrast to, say, JavaScript
    libraries. Also, large-scale data processing tends to push both hardware and software
    much harder than typical non-data science applications, amplifying any differences
    in behavior between the environments.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 开发工作站和生产环境之间通常存在技术差距，这在与生产部署交互时可能会引起摩擦。这个差距并不仅限于数据科学。例如，网络应用开发者通常在类似的环境中工作。然而，这个差距对于数据科学来说尤其有问题。现代建模库往往高度优化以适应特定的
    GPU 和 CPU 架构，与 JavaScript 库等相比。此外，大规模数据处理往往比典型的非数据科学应用对硬件和软件的要求更高，放大了环境之间行为差异。
- en: As many software developers have experienced the hard way, it can be frustrating
    to debug your code when the production environment differs significantly from
    the development environment. We can address the gap by unbundling the prototyping
    loop. Instead of running every step—development, evaluation, and analysis—on laptops,
    we can run any or all of these steps in the cloud. In practice, this means that
    we need a semipersistent Linux instance or a container in the cloud that the data
    scientist can connect to.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如许多软件开发人员所经历的艰难方式，当生产环境与开发环境存在显著差异时，调试代码可能会令人沮丧。我们可以通过解包原型循环来解决这个问题。我们不是在笔记本电脑上运行每个步骤——开发、评估和分析——而是在云中运行这些步骤中的任何或所有步骤。在实践中，这意味着我们需要一个半持久性的
    Linux 实例或云中的容器，数据科学家可以连接到它。
- en: Setting up a system that can launch and terminate such instances on demand requires
    upfront configuration as well as training for data scientists. When deciding whether
    you want to provide a fully local (laptop-based), a fully remote (cloud-based),
    or a hybrid solution, consider the list of pros and cons presented in table 2.1.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 设置一个可以按需启动和终止此类实例的系统需要预先配置以及为数据科学家提供培训。在决定您是想提供完全本地（基于笔记本电脑）、完全远程（基于云）还是混合解决方案时，请考虑表
    2.1 中列出的优缺点。
- en: Table 2.1 Laptops vs. a cloud instance as a development environment
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.1 笔记本电脑与云实例作为开发环境对比
- en: '|  | Laptop | Cloud instance |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '|  | 笔记本电脑 | 云实例 |'
- en: '| **Ease of setup** | Instantly familiar. | Has a learning curve. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| **设置易用性** | 立即熟悉。 | 有学习曲线。 |'
- en: '| **Ease of use** | Easy initially, harder for complex cases, such as deployments.
    | Harder initially; benefits clearer in more complex cases. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| **易用性** | 初始使用简单，但对于复杂情况，如部署，则较难。 | 初始使用较难；在更复杂的情况下，优势更为明显。 |'
- en: '| **Speed of prototyping loop** | Rapid transitions between steps, but the
    evaluation speed may be slower because of limited hardware. | Potentially slower
    transitions between steps, but higher evaluation speed. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| **原型循环速度** | 步骤之间快速转换，但评估速度可能较慢，因为硬件有限。 | 步骤之间可能转换较慢，但评估速度更快。 |'
- en: '| **Ease of support** | Harder to monitor; harder to provide interactive support
    remotely. | Easy—a support person can use standard monitoring tools to observe
    the instance and/or log in to the instance remotely. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| **支持易用性** | 监控较难；远程提供交互式支持较难。 | 易于支持——支持人员可以使用标准监控工具来观察实例，或远程登录实例。 |'
- en: '| **Scalability** | Not scalable—the hardware is fixed. | Scalable—the instance
    size can be chosen based on the use case. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| **可扩展性** | 不可扩展——硬件是固定的。 | 可扩展——实例大小可以根据用例选择。 |'
- en: '| **Interaction with production deployments** | Potential cross-platform issues
    (OS X vs. Linux). | Minimal difference between prototyping and production environments.
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| **与生产部署的交互** | 可能的跨平台问题（OS X与Linux）。 | 原型环境和生产环境之间的最小差异。 |'
- en: '| **Security** | Many issues because the same laptop is used for many purposes
    besides data science; the laptop may get lost physically. | Easier to secure and
    monitor—similar to any other cloud instance. It is possible to use standard cloud-based
    authentication and authorization systems like AWS IAM. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| **安全性** | 由于同一台笔记本电脑被用于许多除了数据科学之外的目的，因此存在许多问题；笔记本电脑可能会丢失。 | 更容易保护和监控——类似于任何其他云实例。可以使用标准的基于云的认证和授权系统，如AWS
    IAM。 |'
- en: '| **Homogeneity** | Every data scientist is likely to have a slightly different
    environment, which makes issues harder to debug. | Easier to ensure that the environments
    are highly uniform. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| **同质性** | 每个数据科学家可能都有一个略有不同的环境，这使得问题更难调试。 | 更容易确保环境高度统一。 |'
- en: To summarize table 2.1, a cloud-based workstation requires more up-front work
    on the infrastructure side, but it can pay big dividends when it comes to security,
    operational concerns, scalability, and interaction with production deployments.
    This will become more clear as you go through the later chapters in the book.
    However, you can certainly get started quickly with a laptop-based approach and
    revisit the decision later as your needs grow.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 总结表2.1，基于云的工作站需要在基础设施方面做更多前期工作，但在安全性、运营关注点、可扩展性和与生产部署的交互方面可以带来巨大的回报。随着你阅读本书后面的章节，这一点将变得更加清晰。然而，你可以通过基于笔记本电脑的方法快速开始，随着需求的增长，稍后再重新审视这个决定。
- en: 'How to provide a cloud-based workstation depends on your business environment:
    what cloud providers you use, how the rest of your infrastructure is set up, and
    what kind of security policies data scientists need to comply with. To give you
    an idea of available options, we list a few prototypical examples next. It is
    likely that new solutions will become available over the coming years, so this
    list is far from comprehensive.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 提供基于云的工作站的方式取决于你的业务环境：你使用的云提供商、你的基础设施如何设置以及数据科学家需要遵守的安全策略类型。为了给你一个可用的选项的概览，我们接下来列出了一些典型的例子。预计在未来几年内，新的解决方案将变得可用，所以这个列表远非详尽无遗。
- en: 'A general-purpose cloud IDE: AWS Cloud9'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一个通用云IDE：AWS Cloud9
- en: 'AWS Cloud9 is a general-purpose, cloud-based integrated development environment
    (IDE)—a code editor—that works in the browser backed by servers provided by AWS—EC2
    instances—running Linux. Using AWS Cloud9 feels pretty similar to using your laptop
    in the following ways:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Cloud9是一个通用、基于云的集成开发环境（IDE）——一个代码编辑器——它通过AWS提供的服务器（EC2实例）在浏览器中运行，运行Linux。使用AWS
    Cloud9的感觉与使用你的笔记本电脑在以下方面相似：
- en: The editor feels like a local editor, and it comes with a built-in debugger.
    The command-line session feels like a local terminal.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编辑器感觉像是一个本地编辑器，它内置了调试器。命令行会话感觉像是一个本地终端。
- en: It manages a standard EC2 instance attached to an editor session, which you
    can use to back the prototyping loop and to interact with production deployments.
    Alternatively, you can configure it to connect to an existing EC2 instance for
    more control.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它管理着一个连接到编辑会话的标准EC2实例，你可以用它来支持原型循环并与生产部署进行交互。或者，你可以配置它连接到现有的EC2实例以获得更多控制。
- en: There is no extra cost besides the usual EC2 fees, and unused instances are
    stopped automatically, so it can be a very cost-effective solution.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了通常的EC2费用外，没有额外的费用，未使用的实例会自动停止，因此它可能是一个非常经济有效的解决方案。
- en: A downside is that AWS Cloud9 doesn’t have any built-in support notebooks (more
    about notebooks in the next section), although with some custom work, it is possible
    to use the underlying EC2 to back notebook kernels, too.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一个缺点是AWS Cloud9没有内置对笔记本的支持（关于笔记本的更多信息将在下一节中介绍），尽管通过一些定制工作，也可以使用底层的EC2来支持笔记本内核。
- en: 'A data science-specific environment: Amazon SageMaker Studio'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一个针对数据科学的环境：Amazon SageMaker Studio
- en: 'Amazon SageMaker Studio is a hosted version of the JupyterLab data science
    environment, which is tightly integrated with the AWS data science services. Although
    you can use it as a general-purpose code editor, similar to AWS Cloud9, it is
    more centered around notebooks in the following ways:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker Studio是JupyterLab数据科学环境的托管版本，它与AWS数据科学服务紧密集成。虽然你可以像AWS Cloud9一样将其用作通用代码编辑器，但它更侧重于以下方面的笔记本：
- en: SageMaker Studio manages instances backing notebooks and terminals for you,
    similar to AWS Cloud9, but instead of using normal EC2 instances, it uses more
    expensive ML-specific instance types.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker Studio为您管理支持笔记本和终端的实例，类似于 AWS Cloud9，但它使用的是更昂贵的、针对机器学习特定的实例类型，而不是普通的
    EC2 实例。
- en: Existing users of Jupyter and JupyterLab will feel right at home.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现有的 Jupyter 和 JupyterLab 用户会感到非常熟悉。
- en: Integration to the AWS data science services is handy if you use them.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您使用 AWS 数据科学服务，集成到 AWS 数据科学服务中会非常方便。
- en: Other cloud providers have similar offerings as a part of their platform, such
    as Azure Machine Learning Studio by Microsoft. A complete data science environment
    is most useful if you want to leverage the provider’s other services that are
    integrated with it. Otherwise, a simpler editor might be easier to use and operate.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 其他云服务提供商也提供了类似的服务作为其平台的一部分，例如微软的 Azure Machine Learning Studio。如果您想利用与它集成的其他服务，一个完整的数据科学环境非常有用。否则，一个更简单的编辑器可能更容易使用和操作。
- en: 'A local editor backed by a cloud instance: Visual Studio Code'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由云实例支持的本地编辑器：Visual Studio Code
- en: Both AWS Cloud9 and SageMaker Studio are fully cloud-based, including a browser-based
    editor. Although this approach has many benefits—it is easy operationally and
    can be very secure—some people find browser-based editors more cumbersome to use
    than local editors. A happy medium can be to use a local editor, like PyCharm
    or Visual Studio Code (VS Code), backed by a cloud instance.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: AWS Cloud9 和 SageMaker Studio 都是完全基于云的，包括基于浏览器的编辑器。尽管这种方法有很多好处——操作简单且非常安全——但有些人发现基于浏览器的编辑器比本地编辑器更繁琐。一个折中的方法是使用由云实例支持的本地编辑器，如
    PyCharm 或 Visual Studio Code (VS Code)。
- en: In particular, VS Code is a popular, very capable editor, which comes with well-integrated
    support for remote code execution, called Visual Studio Code Remote—SSH. Using
    this feature, you can evaluate any code using an arbitrary cloud instance of your
    choosing. Also, VS Code comes with built-in support for notebooks, which it can
    run on the same remote instance, providing a frictionless user experience for
    data scientists.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是VS Code是一个非常受欢迎、功能强大的编辑器，它提供了对远程代码执行的良好集成支持，称为Visual Studio Code Remote—SSH。使用此功能，您可以使用您选择的任意云实例评估任何代码。此外，VS
    Code还内置了对笔记本的支持，它可以在同一远程实例上运行，为数据科学家提供无缝的用户体验。
- en: The main downside of the hybrid approach is that you have to deploy a mechanism
    to manage the cloud instances used by the local editor. This can be accomplished
    with a project like Gitpod ([https://www.gitpod.io](https://www.gitpod.io)). For
    instance, a relatively simple approach could be to launch a container for each
    user and configure their editors to connect to their personal container automatically.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 混合方法的主要缺点是您必须部署一个机制来管理本地编辑器使用的云实例。这可以通过像 Gitpod ([https://www.gitpod.io](https://www.gitpod.io))
    这样的项目来实现。例如，一个相对简单的方法可能是为每个用户启动一个容器，并配置他们的编辑器自动连接到他们的个人容器。
- en: 2.1.3 Notebooks
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.3 笔记本
- en: 'The previous section covered the very basics of the prototyping loop: develop
    code in an editor, evaluate it in a terminal, and analyze results printed out
    on the terminal. This has been the classic way of developing software for decades.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节介绍了原型循环的非常基础的部分：在编辑器中编写代码，在终端中评估它，并分析终端上打印出的结果。这几十年来一直是开发软件的经典方式。
- en: 'Many data scientists are familiar with another way of software development:
    writing and evaluating code in a single document called a notebook. A defining
    feature of the notebook approach is that code can be authored incrementally as
    small snippets, or cells, which can be evaluated on the fly so that their results
    are shown and stored next to the code. Notebooks support rich output types, so
    instead of just outputting plain text, as in a terminal, the output can include
    arbitrary visualizations. This method is convenient when prototyping new data
    science applications or analyzing existing data or models.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据科学家熟悉另一种软件开发方式：在称为笔记本的单个文档中编写和评估代码。笔记本方法的一个定义性特征是代码可以作为小的片段或单元格增量编写，可以即时评估，以便其结果显示并存储在代码旁边。笔记本支持丰富的输出类型，因此，与终端中仅输出纯文本不同，输出可以包括任意可视化。当原型新的数据科学应用或分析现有数据或模型时，这种方法很方便。
- en: Many independent notebook environments are available, most of them targeting
    specific programming languages. Well-known environments include RMarkdown notebooks
    for R, Zeppelin and Polynote for Scala, Mathematica for Wolfram Language, and
    Jupyter for Python (and other languages), which is the most popular notebook environment
    today.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 许多独立的笔记本环境可供选择，其中大多数针对特定的编程语言。知名的环境包括用于R的RMarkdown笔记本、用于Scala的Zeppelin和Polynote、用于Wolfram语言的Mathematica，以及用于Python（和其他语言）的Jupyter，这是目前最受欢迎的笔记本环境。
- en: 'Given the ubiquity and usefulness of notebooks in data science, it would be
    hard to imagine an infrastructure for data science that didn’t support notebooks.
    Some infrastructures take the approach to the extreme and suggest that all data
    science code should be authored in notebooks, as notebooks. Although notebooks
    are undoubtedly useful for exploratory programming, analysis, teaching, and quick
    prototypes, it is less clear if they are the best approach for general software
    development, which is a big part of real-world data science projects. To better
    understand the role of notebooks in the data science stack, let’s start by looking
    at their unique benefits, which follow:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到笔记本在数据科学中的普遍性和实用性，很难想象一个不支持笔记本的数据科学基础设施。一些基础设施将这种方法推向了极端，并建议所有数据科学代码都应该以笔记本的形式编写。尽管笔记本无疑对探索性编程、分析、教学和快速原型设计很有用，但它们是否是通用软件开发的最佳方法尚不清楚，而这在现实世界的数据科学项目中是一个很大的部分。为了更好地理解笔记本在数据科学堆栈中的作用，让我们首先看看它们的独特优势，如下所述：
- en: The prototyping loop is extremely fast. You write a snippet of code in a cell,
    and with a click of a button, you can evaluate it and see the results next to
    the code. No need to switch between windows or tabs.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原型设计循环非常快。你可以在单元格中编写一段代码，然后点击一下按钮，就可以评估它并看到结果紧挨着代码。无需在窗口或标签页之间切换。
- en: Results can be plots, graphs, or arbitrary visualizations. Data frames, that
    is, tables of data, are automatically visualized in a tabular format.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果可以是图表、图形或任意可视化。数据框，即数据表，会自动以表格格式可视化。
- en: The notebook format encourages creation of linear narratives, which can be easy
    for humans to read and understand. The result can look like an executable research
    paper.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 笔记本格式鼓励创建线性叙述，这对人类来说容易阅读和理解。结果可能看起来像一份可执行的研究论文。
- en: Most notebook GUIs work in the browser with a simple backend process that can
    be run locally, so you can get started with minimal setup.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大多数笔记本GUI在浏览器中运行，后端过程可以本地运行，因此您可以以最小的设置开始。
- en: In particular, different platforms widely use, teach, and support Jupyter notebooks.
    Correspondingly, tons of materials and examples are available online.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尤其是不同平台广泛使用、教授和支持Jupyter笔记本。相应地，网上有大量的资料和示例。
- en: Many modern data science libraries are designed to be used in notebooks. They
    come with built-in visualizations and APIs that make notebook use convenient.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多现代数据科学库都是为在笔记本中使用而设计的。它们带有内置的可视化和API，使得笔记本使用变得方便。
- en: All the benefits of notebooks relate to the user experience. They can make data
    scientists, not computers, more effective and efficient. On the flip side, notebooks
    require a stack of infrastructure of their own, resulting in extra complexity,
    which can lead to brittleness. Because computers don’t care about notebooks, we
    can execute code without them when humans are not in the loop, which is the case
    in production deployments.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本的所有优势都与用户体验相关。它们可以使数据科学家而不是计算机更加高效和高效。另一方面，笔记本需要一套自己的基础设施，这导致额外的复杂性，可能导致脆弱性。因为计算机不关心笔记本，当人类不在循环中时，我们可以不使用它们执行代码，这在生产部署中是常见的情况。
- en: Another question relates to the linear, narrative nature of notebooks. Whereas
    humans are good at reading and understanding linearly progressing stories, like
    the one you are reading right now, computer programs tend to be nonlinear in nature.
    It is considered a good software engineering practice to structure a program as
    independent but interacting modules, each of which has a clear logical role. The
    modules call each other arbitrarily, forming a call graph rather than a linear
    narrative.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题与笔记本的线性、叙述性质有关。虽然人类擅长阅读和理解线性发展的故事，比如你现在正在阅读的，但计算机程序在本质上往往是非线性的。将程序结构为独立但相互交互的模块，每个模块都有一个清晰的逻辑角色，被认为是良好的软件工程实践。模块可以任意调用彼此，形成一个调用图而不是线性叙述。
- en: You can also reuse and share these modules across many projects, complicating
    the dependency graph further. To manage a large software project, a version control
    system like Git is a must. Technically it is possible to write arbitrary code
    in notebooks, version-control them, and maybe even create composable notebooks,
    but this is pushing the limits of the paradigm, requiring layers of nonstandard
    tooling.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将这些模块跨多个项目重用和共享，进一步复杂化依赖图。为了管理大型软件项目，Git这样的版本控制系统是必不可少的。技术上，在笔记本中编写任意代码、对其进行版本控制，甚至可能创建可组合的笔记本是可能的，但这正在推动该范式的极限，需要多层非标准工具。
- en: Whereas notebooks with their mixed-media outputs are great for exploration and
    analysis, traditional IDEs and code editors are optimized for structured programming.
    They make it easy to manage and author even large codebases that are divided across
    multiple files. Some modern IDEs like PyCharm, VS Code, or JupyterLab support
    both modalities in a single interface, trying to combine the best of both worlds.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 而混合媒体输出的笔记本对于探索和分析来说非常出色，传统的IDE和代码编辑器则针对结构化编程进行了优化。它们使得管理并编写跨越多个文件的甚至大型代码库变得容易。一些现代IDE，如PyCharm、VS
    Code或JupyterLab，在单个界面中支持这两种模式，试图结合两者的优点。
- en: 'This book advocates for a pragmatic approach: we can use notebooks for the
    use cases where they shine and stick with traditional software engineering tools
    elsewhere. Figure 2.5 extends the earlier figure 2.3 by overlaying the suggested
    tools in the prototyping and production loops.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 本书提倡一种实用主义方法：我们可以在笔记本闪耀用例中使用笔记本，在其他地方坚持使用传统的软件工程工具。图2.5通过叠加原型设计和生产循环中的建议工具扩展了之前的图2.3。
- en: '![CH02_F05_Tuulos](../../OEBPS/Images/CH02_F05_Tuulos.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F05_Tuulos](../../OEBPS/Images/CH02_F05_Tuulos.png)'
- en: Figure 2.5 Suggested tools for the prototyping and production loops
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 建议用于原型设计和生产循环的工具
- en: Imagine starting to work on a new data science project. Even before you start
    creating the first prototype, that is, entering the prototyping loop, you might
    want to spend some time just understanding the data and the problem domain. Notebooks
    are a good tool for such open-ended exploration, which doesn’t aim at producing
    any persistent software artifacts.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下开始一个新的数据科学项目。甚至在开始创建第一个原型，即进入原型设计循环之前，你可能想花些时间仅仅理解数据和问题域。笔记本是这种开放式探索的好工具，这种探索不旨在产生任何持久的软件工件。
- en: 'After the initial exploration phase, you start prototyping a solution. The
    solution, a data science application, is fundamentally a piece of software, often
    consisting of multiple modules, so we can use a tool optimized for this purpose:
    an IDE or a code editor. The result is an application, a script, which we can
    evaluate as plain code both locally and in production without any added complexity.
    When code fails or you want to improve the model, you can go back to notebooks
    again for analysis and exploration. We will see in later chapters what this might
    look like in practice. As noted earlier, modern IDEs can make switching between
    the notebook and the editor modes seamless, so transitioning between the steps
    of the loop can happen with minimal friction.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在初步探索阶段之后，你开始原型设计解决方案。该解决方案，一个数据科学应用，本质上是一块软件，通常由多个模块组成，因此我们可以使用针对此目的优化的工具：集成开发环境（IDE）或代码编辑器。结果是应用程序，一个脚本，我们可以在本地和生产环境中将其作为普通代码进行评估，而无需任何额外的复杂性。当代码失败或你想改进模型时，你可以再次回到笔记本中进行分析和探索。我们将在后面的章节中看到这可能在实践中是什么样子。正如之前所述，现代IDE可以使在笔记本和编辑器模式之间切换变得无缝，因此循环步骤之间的转换可以发生得尽可能无摩擦。
- en: Setting up a Jupyter Notebook environment
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 设置Jupyter笔记本环境
- en: What does setting up a notebook environment mean in practice? First, let’s consider
    the high-level architecture of Jupyter (many other notebook environments have
    a similar architecture), as presented in figure 2.6.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上设置笔记本环境意味着什么？首先，让我们考虑Jupyter（许多其他笔记本环境都有类似的架构）的高级架构，如图2.6所示。
- en: '![CH02_F06_Tuulos](../../OEBPS/Images/CH02_F06_Tuulos.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F06_Tuulos](../../OEBPS/Images/CH02_F06_Tuulos.png)'
- en: Figure 2.6 A Jupyter client and server
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6 Jupyter客户端和服务器
- en: 'Notebooks consist of two major parts: a web-based UI that runs in the browser
    and a backend process, a kernel, which manages all state and computation requested
    by the UI. Each notebook session is backed by a unique kernel, so it is common
    to have multiple kernels running in parallel when multiple notebooks are open
    in separate browser tabs.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本由两个主要部分组成：一个在浏览器中运行的基于 Web 的用户界面和一个后端进程，即内核，它管理 UI 所请求的所有状态和计算。每个笔记本会话都由一个唯一的内核支持，因此当多个笔记本在不同的浏览器标签页中打开时，通常会有多个内核并行运行。
- en: In the point of view of infrastructure, the key question is where to run the
    kernel. It is a Python process that needs to be executed on a server of some kind.
    The simplest option is to run the kernel on the user’s laptop as a local process,
    which is the leftmost option 1 presented in figure 2.7.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 从基础设施的角度来看，关键问题是内核在哪里运行。它是一个需要在某种服务器上执行的过程。最简单的选项是将内核作为本地进程运行在用户的笔记本电脑上，如图 2.7
    中展示的最左侧选项 1。
- en: '![CH02_F07_Tuulos](../../OEBPS/Images/CH02_F07_Tuulos.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F07_Tuulos](../../OEBPS/Images/CH02_F07_Tuulos.png)'
- en: Figure 2.7 Three options for running the Jupyter kernel
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 运行 Jupyter 内核的三个选项
- en: 'In option 1, all computation initiated by the notebook happens on the user’s
    laptop, similar to any Python script. This approach has all the pros and cons
    of local code evaluation, which we covered in table 2.1\. In particular, the environment
    is unscalable and hard to control in a uniform manner. The main upside of this
    approach is simplicity—you can get going by executing the following commands on
    your laptop:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在选项 1 中，所有由笔记本发起的计算都在用户的笔记本电脑上完成，类似于任何 Python 脚本。这种方法具有本地代码评估的所有优缺点，我们在表 2.1
    中已经讨论过。特别是，环境不可扩展，难以统一控制。这种方法的主要优点是简单——你可以在笔记本电脑上执行以下命令来开始：
- en: '[PRE0]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Option 2 works around the limitations of the local approach by running the kernel
    on a cloud instance—the same cloud workstation that we discussed in the previous
    section. The cloud workstation can be scaled based on the needs of the user and
    use case, and it can provide a uniform environment for all data scientists. A
    downside is that an infrastructure team needs to set up the workstation, including
    a secure network connection, such as a virtual private network (VPN), between
    the cloud workstation and local laptop. However, after the initial configuration
    cost, this setup can be highly productive for data science.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 选项 2 通过在云实例上运行内核来克服本地方法的局限性——与上一节中讨论的相同云工作站。云工作站可以根据用户和用例的需求进行扩展，并为所有数据科学家提供一个统一的环境。一个缺点是，基础设施团队需要设置工作站，包括在云工作站和本地笔记本电脑之间建立安全网络连接，例如虚拟专用网络（VPN）。然而，在初始配置成本之后，这种设置对数据科学来说可以非常高效。
- en: Option 3 is a “serverless” approach to notebooks. Whereas option 2 provides
    an illusion of a persistent, stateful laptop-in-the-cloud—like a personal workstation—option
    3 eliminates the notion that any server is required to run the kernel in the first
    place. After all, all the user sees is the browser-based Jupyter UI, so they shouldn’t
    have to care about the backend.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 选项 3 是笔记本的“无服务器”方法。而选项 2 提供了一种持续、有状态的云中笔记本电脑的错觉——就像个人工作站一样——选项 3 消除了最初需要服务器来运行内核的概念。毕竟，用户看到的是基于浏览器的
    Jupyter UI，所以他们不需要关心后端。
- en: In practice, option 3 requires a portal that allows one to open a notebook.
    When a notebook is opened, an ephemeral instance is provisioned for the notebook
    on the fly. Examples of this approach include Google Colab and an open source
    [MyBinder.org](https://mybinder.org/).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，选项 3 需要一个门户，允许用户打开笔记本。当打开笔记本时，会动态地为笔记本分配一个临时实例。这种方法的例子包括 Google Colab 和开源
    [MyBinder.org](https://mybinder.org/)。
- en: The main downside of this approach, besides operational complexity, is that
    notebooks are stateless. There is no persistent local filesystem or dependencies
    that automatically persist across notebook kernels. This makes the experience
    quite different from a local laptop that maintains state until you explicitly
    erase it. Also, this approach doesn’t allow interaction with local editors, like
    VS Code, which is possible with option 2\. Option 3 can be great for quick scratchpad
    environments or for users who don’t need a full-fledged persistent workstation.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的主要缺点，除了操作复杂性之外，就是笔记本是无状态的。没有持久的本地文件系统或依赖项可以自动跨笔记本内核持久化。这使得体验与维护状态直到你明确删除它的本地笔记本电脑大不相同。此外，这种方法不允许与本地编辑器（如
    VS Code）交互，而选项 2 是可以做到的。选项 3 对于快速便笺环境或不需要完整持久工作站的用户来说可能非常好。
- en: 2.1.4 Putting everything together
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.4 将一切整合
- en: 'Let’s summarize what we have covered in the previous sections:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下在前几节中我们所学到的内容：
- en: 'To boost the productivity of data scientists, we should optimize the ergonomics
    of two key activities: the prototyping loop and interaction with production deployments.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了提高数据科学家的生产力，我们应该优化两个关键活动的舒适性：原型循环和与生产部署的交互。
- en: There are many good reasons to enable data scientists to work seamlessly with
    the cloud from the get-go. In particular, it will make interaction with production
    deployments easier.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有许多很好的理由让数据科学家从一开始就能无缝地在云端工作。特别是，这将使与生产部署的交互变得更加容易。
- en: Modern editors make it possible to push code evaluation to the cloud. This can
    make the evaluation environments more scalable, easier to manage, and closer to
    the production deployments than evaluating code on the laptop. However, they require
    some up-front configuration effort by the infrastructure team.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现代编辑器使得将代码评估推向云端成为可能。这可以使评估环境更具可扩展性，更容易管理，并且比在笔记本电脑上评估代码更接近生产部署。然而，这需要基础设施团队进行一些前期配置工作。
- en: Notebooks are an indispensable tool for some data science activities, complementing
    traditional software development tools. You can run notebooks on the same cloud
    workstation that supports other code evaluation.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 笔记本是某些数据科学活动不可或缺的工具，它补充了传统的软件开发工具。你可以在支持其他代码评估的同一云工作站上运行笔记本。
- en: Figure 2.8 illustrates the architecture of a cloud workstation for data science.
    You have many ways to implement the setup in practice. You can pick an editor
    or an IDE that works for your needs. You can use notebooks either in a standalone
    fashion in the browser or embedded in the editor, such as using Visual Studio
    Code or PyCharm. Or you can pick a notebook environment that includes a full-fledged
    code editor, like JupyterLab. The workstation instance can be a container running
    on a cloud-based container platform, for example, AWS Elastic Container Service
    (ECS).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8展示了数据科学云工作站的架构。在实际应用中，你有多种方式来实现这种设置。你可以选择一个适合你需求的编辑器或IDE。你可以在浏览器中以独立的方式使用笔记本，或者将其嵌入到编辑器中，例如使用Visual
    Studio Code或PyCharm。或者你可以选择一个包含完整代码编辑器的笔记本环境，如JupyterLab。工作站实例可以是一个在基于云的容器平台上运行的容器，例如AWS弹性容器服务（ECS）。
- en: '![CH02_F08_Tuulos](../../OEBPS/Images/CH02_F08_Tuulos.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F08_Tuulos](../../OEBPS/Images/CH02_F08_Tuulos.png)'
- en: Figure 2.8 Cloud workstation for data science
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 数据科学云工作站
- en: Figure 2.9 shows a Visual Studio Code session with an embedded editor, terminal,
    and notebook. With a single click, the scientist can execute the code in the editor
    on the terminal. With another click, they can update the notebook view that visualizes
    the results. The terminal and the notebook kernel can either execute locally or
    on a cloud workstation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9显示了一个包含嵌入式编辑器、终端和笔记本的Visual Studio Code会话。通过单次点击，科学家可以在终端上执行编辑器中的代码。通过另一次点击，他们可以更新可视化结果的笔记本视图。终端和笔记本内核可以本地执行或在云工作站上执行。
- en: '![CH02_F09_Tuulos](../../OEBPS/Images/CH02_F09_Tuulos.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F09_Tuulos](../../OEBPS/Images/CH02_F09_Tuulos.png)'
- en: Figure 2.9 A Visual Studio Code setup that covers the complete prototyping loop
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 一个涵盖完整原型循环的Visual Studio Code设置
- en: With a setup like this, the scientist can quickly iterate through the steps
    of the prototyping loop, as overlaid in the figure.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种设置下，科学家可以快速迭代原型循环的步骤，如图中所示。
- en: 2.2 Introducing workflows
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 工作流程介绍
- en: '*On the second day at Caveman, Alex joins an onboarding session led by Harper.
    Harper explains how the company sources their organic ingredients from multiple
    vendors, how they produce a wide variety of cupcakes using artisanal methods,
    and how they handle nationwide logistics. Alex is puzzled by the intricate value
    chain that it takes to produce paleo cupcakes. How are data scientists at the
    company supposed to process all relevant data, keep models up-to-date, and send
    updated predictions to various business systems? The level of complexity seems
    to be beyond what Alex had had to deal with previously in academia using notebooks.*'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '*在洞穴人公司的第二天，亚历克斯加入了由哈珀主持的入职培训。哈珀解释了公司如何从多个供应商那里采购有机原料，如何使用手工方法生产各种纸杯蛋糕，以及他们如何处理全国范围内的物流。亚历克斯对生产原始人纸杯蛋糕所涉及的复杂价值链感到困惑。公司里的数据科学家应该如何处理所有相关数据，保持模型更新，并将更新后的预测发送到各个业务系统？这种复杂性似乎超出了亚历克斯在学术界使用笔记本时必须处理的范围。*'
- en: '![CH02_F09_UN03_Tuulos](../../OEBPS/Images/CH02_F09_UN03_Tuulos.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F09_UN03_Tuulos](../../OEBPS/Images/CH02_F09_UN03_Tuulos.png)'
- en: The development environment we introduced in the previous section was the very
    first stop in our journey in producing robust, production-ready data science applications.
    It provides the means to write code, evaluate it, and analyze the results. Now,
    what code should we write and how?
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节中介绍的开发环境是我们生产健壮、生产就绪的数据科学应用的旅程中的第一个停靠点。它提供了编写代码、评估它和分析结果的方法。现在，我们应该编写什么代码以及如何编写？
- en: When terms like *machine learning*, *artificial intelligence*, or *data science*
    are mentioned, they often evoke the idea of a *model*. By a model, we mean any
    kind of computational abstraction of the world that takes some input, performs
    some computation, and produces an output, as concisely depicted in figure 2.10\.
    In the realm of data science, these models are often expressed as artificial neural
    networks or using statistical methods like logistic regression.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 当提到像*机器学习*、*人工智能*或*数据科学*这样的术语时，它们通常会唤起一个*模型*的概念。我们所说的模型是指任何对世界的计算抽象，它接受一些输入，执行一些计算，并产生一个输出，如图2.10所示。在数据科学的领域内，这些模型通常被表示为人工神经网络或使用如逻辑回归这样的统计方法。
- en: '![CH02_F10_Tuulos](../../OEBPS/Images/CH02_F10_Tuulos.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F10_Tuulos](../../OEBPS/Images/CH02_F10_Tuulos.png)'
- en: Figure 2.10 A model
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10 一个模型
- en: Building accurate models for real-world phenomena is not easy. Historically,
    it has been done by scientists who have gone through extensive theoretical training
    and who have a deep understanding of their problem domain. Depending on the company,
    there may be an expectation that data scientists mainly focus on building models.
    However, building practically useful models in a business context is quite a different
    experience from publishing model designs in a research paper.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为现实世界现象构建准确的模型并不容易。历史上，这通常由经过广泛理论培训并对他们的问题领域有深刻理解的科学家来完成。根据公司的不同，可能会有这样的期望，即数据科学家主要专注于构建模型。然而，在商业环境中构建实际有用的模型与在研究论文中发布模型设计是截然不同的体验。
- en: 'Consider a common business context like that of Caveman Cupcakes introduced
    earlier. Alex the data scientist faces the following three challenges:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个常见的商业环境，比如前面提到的Caveman Cupcakes。数据科学家Alex面临着以下三个挑战：
- en: It is probably not feasible to model the whole business of Caveman Cupcakes
    as a single model. Instead, the data scientist is expected to focus on modeling
    some specific business problems, for example, to build a computer vision model
    to detect faulty cupcakes on the production line automatically, or to use mixed-integer
    programming to optimize logistics. As a result, over time data scientists at the
    company will produce a set of models, each with its own requirements and characteristics.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 很可能无法将Caveman Cupcakes的整个业务作为一个单一模型来建模。相反，数据科学家被期望专注于建模一些特定的业务问题，例如，构建一个计算机视觉模型来自动检测生产线上的次品蛋糕，或者使用混合整数规划来优化物流。因此，随着时间的推移，该公司的数据科学家将产生一系列模型，每个模型都有其特定的要求和特征。
- en: In a business context, the model can’t be just an abstract mathematical construct.
    It needs to perform the computation in practice, which means that it needs to
    be implemented in a programming language, and it needs to execute reliably. This
    can be a highly nontrivial exercise in software engineering, in particular because
    we can’t wait for the results infinitely. We may need to run some operations in
    parallel and some on specialized hardware like GPUs.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在商业环境中，模型不能仅仅是一个抽象的数学结构。它需要在实践中执行计算，这意味着它需要用编程语言实现，并且需要可靠地执行。这可能是一项高度非平凡的软件工程练习，特别是因为我们不能无限期地等待结果。我们可能需要并行运行一些操作，并在像GPU这样的专用硬件上运行一些操作。
- en: 'Besides the big circle in figure 2.10, the model, we must not forget the two
    arrows: the input and the output. Our model needs to receive accurate, often constantly
    updating data, which is not a small feat. Finally, the results of a model need
    to end up somewhere where they can benefit the business, such as a database, a
    planning spreadsheet, or another software component.'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了图2.10中的大圆圈，我们不应忘记两个箭头：输入和输出。我们的模型需要接收准确、通常不断更新的数据，这并非易事。最后，模型的结果需要最终到达一个可以为企业带来利益的地方，比如数据库、规划电子表格或另一个软件组件。
- en: To summarize, the data scientist needs to understand the business problem that
    needs to be solved, design a model, implement it as software, make sure it gets
    the correct data, and figure out where to send the results. To make this happen,
    the data scientist spends a good amount of time in the prototyping loop we introduced
    in the previous section.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，数据科学家需要理解需要解决的业务问题，设计一个模型，将其实现为软件，确保它获得正确的数据，并找出结果发送的位置。为了实现这一点，数据科学家在上一节中介绍的原型设计循环上花费了大量时间。
- en: Once we solve this particular business problem adequately, we repeat the same
    process for another business problem. This cycle is repeated infinitely. The models
    are never perfect, and rarely does a company run out of business problems to optimize.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们适当地解决了这个特定的业务问题，我们就对另一个业务问题重复同样的过程。这个循环无限重复。模型从不完美，而且很少有公司会缺乏业务问题来优化。
- en: Furthermore, all these systems must be kept running reliably, preferably 24/7\.
    This requires a lot of interaction with production deployments, because models
    are constantly exposed to real-world entropy and data, which erodes them, similar
    to any real-world machine that is exposed to the elements. This is the second
    loop we discussed in the previous section.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，所有这些系统都必须可靠地运行，最好是24/7。这需要与生产部署进行大量交互，因为模型不断暴露于现实世界的熵和数据中，这会侵蚀它们，就像任何暴露于自然元素中的现实世界机器一样。这是我们在上一节中讨论的第二个循环。
- en: As a result, we get a jungle of data pipelines and models—a big humming factory
    as depicted in figure 2.11—which requires constant maintenance. To keep the factory
    understandable and operable, we need to impose some structure on how these models
    are built. This is the main motivation for making the modeling and data pipelines,
    or workflows, as first-class entities in our infrastructure.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得到了一个数据管道和模型的丛林——如图2.11所示的一个大型的嗡嗡作响的工厂——这需要持续的维护。为了使工厂可理解和可操作，我们需要对如何构建这些模型施加一些结构。这是将建模和数据管道，或工作流，作为我们基础设施中一等实体的主要动机。
- en: '![CH02_F11_Tuulos](../../OEBPS/Images/CH02_F11_Tuulos.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F11_Tuulos](../../OEBPS/Images/CH02_F11_Tuulos.png)'
- en: Figure 2.11 Many models and data pipelines
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.11 许多模型和数据管道
- en: 2.2.1 The basics of workflows
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.1 工作流的基本概念
- en: In this context, a workflow is a *directed graph*, that is, a set of nodes or
    steps (depicted as circles in figure 2.12) connected by directional edges (arrows).
    This representation captures the before-and-after relationship between steps.
    For instance, in figure 2.12, we know unambiguously that A must happen before
    B.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，工作流是一个**有向图**，即由节点或步骤（如图2.12中的圆圈所示）通过有向边（箭头）连接的集合。这种表示方式捕捉了步骤之间的先后关系。例如，在图2.12中，我们可以明确知道A必须在B之前发生。
- en: '![CH02_F12_Tuulos](../../OEBPS/Images/CH02_F12_Tuulos.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F12_Tuulos](../../OEBPS/Images/CH02_F12_Tuulos.png)'
- en: Figure 2.12 A workflow where A happens before B
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.12 A在B之前发生的工作流
- en: The order of steps isn’t always fully unambiguous. In figure 2.13, we know that
    A must execute before B and C that execute before D, but the mutual order between
    B and C is left undefined.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤的顺序并不总是完全明确的。在图2.13中，我们知道A必须在B之前执行，C必须在D之前执行，但B和C之间的相互顺序是未定义的。
- en: '![CH02_F13_Tuulos](../../OEBPS/Images/CH02_F13_Tuulos.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F13_Tuulos](../../OEBPS/Images/CH02_F13_Tuulos.png)'
- en: Figure 2.13 A workflow where B and C may be executed in any order
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.13 B和C可以以任何顺序执行的工作流
- en: We can use workflows like this to indicate that we don’t care whether B executes
    before C, as long as both of them are executed before D. This feature is useful
    because it allows us to execute B and C in parallel.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用这样的工作流来表示，我们不在乎B是否在C之前执行，只要两者都在D之前执行。这个特性很有用，因为它允许我们并行执行B和C。
- en: 'Figure 2.14 depicts a directed graph that has a cycle: after C, we go back
    to A again. Naturally, this results in an infinite loop unless we define some
    kind of conditional that defines a stopping condition. Alternatively, we can just
    disallow graphs with cycles and decide that only such graphs, directed acyclic
    graphs or DAGs, are valid workflows. In fact, just supporting DAGs is a common
    choice made by workflow engines.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.14描述了一个具有循环的有向图：在C之后，我们再次回到A。自然地，这会导致无限循环，除非我们定义某种条件来定义停止条件。或者，我们可以简单地禁止具有循环的图，并决定只有这样的图，有向无环图或DAG，才是有效的工作流。实际上，仅支持DAG是工作流引擎中常见的选择。
- en: '![CH02_F14_Tuulos](../../OEBPS/Images/CH02_F14_Tuulos.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F14_Tuulos](../../OEBPS/Images/CH02_F14_Tuulos.png)'
- en: Figure 2.14 A workflow with a cycle, i.e., a cyclic graph
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.14 带有循环的工作流，即循环图
- en: 'Why should Alex or any other data scientist care about DAGs? Consider the following
    three reasons:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么亚历克斯或其他数据科学家应该关心DAGs？考虑以下三个原因：
- en: They introduce a common vocabulary—steps and transitions between them—which
    make it easier to write and understand nontrivial applications that are structured
    as DAGs.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们引入了一个共同的词汇——步骤及其之间的转换——这使得编写和理解结构化为DAGs的非平凡应用变得更加容易。
- en: They allow us to be explicit about the order of operations. This is useful especially
    when the order is anything more complex than a simple linear order, like what
    you see in a notebook. By making the order of operations clear and explicit, our
    jungle of data pipelines and models becomes more manageable.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们使我们能够明确操作顺序。这在操作顺序比简单的线性顺序更复杂时尤其有用，比如你在笔记本中看到的那样。通过使操作顺序清晰明确，我们的数据管道和模型丛林变得更加易于管理。
- en: They allow us to indicate when the order of operations doesn’t matter, like
    in figure 2.13\. We can parallelize these operations automatically, which is the
    key to high performance. Plenty of opportunities for parallelization arise in
    a typical data science application, but in most cases, computers can’t figure
    them out automatically if they are not made explicit.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们允许我们指出操作顺序无关紧要的情况，如图2.13所示。我们可以自动并行化这些操作，这是高性能的关键。在典型的数据科学应用中，并行化的机会很多，但如果它们不是明确指出，大多数情况下计算机无法自动识别。
- en: To summarize, at the high level, you can view DAGs as a language, not so much
    as a programming language but rather as a formal construct for human-to-human
    communication. They allow us to speak about even complex sequences of operations
    in a concise and understandable manner.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，在高层面上，你可以将DAGs视为一种语言，与其说是编程语言，不如说是人类之间交流的正式结构。它们允许我们以简洁易懂的方式讨论复杂的操作序列。
- en: 2.2.2 Executing workflows
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.2 执行工作流程
- en: If DAGs are just an abstract way to talk about the structure of data science
    applications, how does the rubber meet the road—that is, how are workflows executed
    in practice? Ultimately, executing a workflow is a job of a *workflow orchestrator**,*
    aka a *job scheduler*, which we will discuss next. Before we dive deeper into
    various orchestrators—and there are hundreds of them—it is useful to take a deeper
    look at the concerns required to turn an abstract DAG into executing code.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果DAGs只是谈论数据科学应用结构的抽象方式，那么实际操作中是如何实现工作流程执行的？最终，执行工作流程是**工作流程编排器**（也称为**作业调度器**）的工作，我们将在下一节讨论。在我们深入探讨各种编排器——而且有成百上千种之前——深入了解将抽象DAG转换为执行代码所需关注点是很有用的。
- en: 'Concrete workflows involve three separate concerns: what code should be executed
    (what’s inside a step), where the code should be executed concretely (a computer
    somewhere needs to execute the code), and how the steps should be orchestrated.
    The three concerns map to the different layers of the infrastructure stack we
    introduced in chapter 1, as depicted in figure 2.15.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 具体的工作流程涉及三个独立的关注点：应该执行什么代码（步骤内部的代码是什么），代码应该在何处具体执行（某个地方的计算机需要执行代码），以及步骤应该如何编排。这三个关注点对应于我们在第1章中介绍的基础设施堆栈的不同层，如图2.15所示。
- en: '![CH02_F15_Tuulos](../../OEBPS/Images/CH02_F15_Tuulos.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![CH02_F15_Tuulos](../../OEBPS/Images/CH02_F15_Tuulos.png)'
- en: Figure 2.15 The three concerns of workflow execution
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.15 工作流程执行的三关注点
- en: The architecture layer defines what code the data scientist is supposed to write
    in a step. It is *the user interface layer* to workflows. Different workflow frameworks
    provide different kinds of abstractions, optimized for different use cases. Some
    of them are graphical (you can define a workflow by dragging and dropping circles),
    some are configuration-based, and some are defined as code.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 架构层定义了数据科学家在步骤中应该编写什么代码。它是工作流程的**用户界面层**。不同的工作流程框架提供不同类型的抽象，针对不同的用例进行了优化。其中一些是图形化的（你可以通过拖放圆圈来定义工作流程），一些是基于配置的，还有一些是定义为代码的。
- en: In the data scientist’s point of view, the architecture layer is the most visible
    part of workflows. The layers toward the top of the stack are closer to the data
    scientist’s interests. The architecture layer pretty much defines what kind of
    data science applications are natural to express in the system, which makes it
    perhaps the most important consideration when choosing a workflow framework.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据科学家的角度来看，架构层是工作流程中最明显的一部分。堆栈顶部的层更接近数据科学家的兴趣。架构层在很大程度上定义了在系统中自然表达的数据科学应用类型，这使得它可能是选择工作流程框架时最重要的考虑因素。
- en: The *compute resources* layer determines where the user’s code is executed concretely.
    Imagine a workflow with 600 parallel steps. Each step executes for 30 seconds
    on a 16-core CPU. If the compute layer includes only one 16-core instance (maybe
    the compute layer is a laptop!), executing the steps takes five hours. In contrast,
    if the compute layer is a cluster of 100 instances, the steps execute in three
    minutes. As you can see, the compute layer makes a big difference for the *scalability*
    of workflows, which we will discuss in detail in chapters 4 and 5.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '*计算资源*层决定了用户的代码具体在哪里执行。想象一下一个包含600个并行步骤的工作流程。每个步骤在一个16核CPU上执行30秒。如果计算层只包含一个16核实例（也许计算层是一台笔记本电脑！），执行这些步骤需要五小时。相比之下，如果计算层是一个包含100个实例的集群，这些步骤将在三分钟内执行。正如你所看到的，计算层对工作流程的*可扩展性*有很大影响，我们将在第4章和第5章中详细讨论这一点。'
- en: Finally, we need a system that walks through the DAG, sending each step to the
    compute layer and waiting for their completion before continuing. We call this
    system a job scheduler. The scheduler layer doesn’t need to care about what code
    is being executed and where computers that execute the code reside exactly. Its
    sole responsibility is to schedule the steps in the right order as defined by
    the DAG, making sure that a step finishes successfully before its successors in
    the graph are executed (the technical term for this is *topological order*).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要一个系统来遍历DAG（有向无环图），将每一步发送到计算层，并在继续之前等待它们的完成。我们称这个系统为作业调度器。调度层不需要关心正在执行什么代码以及执行代码的计算机具体位于何处。它的唯一责任是按照DAG定义的顺序调度步骤，确保在图中的后续步骤执行之前，每个步骤都成功完成（这个术语的技术名称是*拓扑顺序*）。
- en: Although this process may sound deceptively simple, the job scheduler layer
    is the guarantor of the *robustness* *and operability* of workflows. It needs
    to monitor whether the compute layer completes steps successfully, and if it doesn’t,
    it needs to retry them. It may need to do this for hundreds of thousands of concurrently
    executing steps across tens of thousands of workflows. In the user’s point of
    view, it is desirable that the job scheduler has a way to observe executions,
    maybe a GUI, and a way to alert owners if their workflow fails.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个过程可能听起来欺骗性地简单，但作业调度器层是工作流程的*鲁棒性*和*可操作性*的保证。它需要监控计算层是否成功完成步骤，如果不成功，它需要重试。它可能需要为成千上万的并发执行步骤和成千上万个工作流程做这件事。从用户的角度来看，作业调度器有观察执行的方式，可能是一个GUI，以及如果工作流程失败，向所有者发出警报的方式是理想的。
- en: Besides operational concerns, we can distinguish between two major types of
    job schedulers based on how they want the DAG to be specified. Schedulers that
    require the DAG to be fully specified before an execution starts are called to
    schedule *static DAGs*. The other type of schedulers allow the DAG to be constructed
    incrementally during execution, which is called a *dynamic DAG*. Both approaches
    have their pros and cons.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 除了操作方面的考虑，我们可以根据它们想要如何指定DAG来区分两种主要的作业调度器类型。那些要求在执行开始之前完全指定DAG的调度器被称为调度*静态DAG*。另一种类型的调度器允许在执行过程中增量地构建DAG，这被称为*动态DAG*。这两种方法都有其优缺点。
- en: Every workflow framework needs to address all three concerns. Each concern is
    a deep topic in itself, requiring nontrivial efforts in engineering. On top of
    this, the concerns interact in various ways. Different frameworks end up making
    different technical choices that affect scalability and robustness, and these
    choices affect the user experience, depending on what use cases they target and
    what kind of tradeoffs they are ready to make. As a result, hundreds of workflow
    frameworks all look seemingly similar on the surface—all of them claim to execute
    DAGs—but significant differences exist under the hood.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 每个工作流程框架都需要解决这三个问题。每个问题本身都是一个深奥的主题，需要大量的工程努力。除此之外，这些问题以各种方式相互作用。不同的框架最终会做出不同的技术选择，这些选择会影响可扩展性和鲁棒性，并影响用户体验，这取决于它们针对的使用案例以及他们愿意做出的权衡。因此，表面上看似相似的数百个工作流程框架——它们都声称可以执行DAGs——但在底层存在显著差异。
- en: 2.2.3 The world of workflow frameworks
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.3 工作流程框架的世界
- en: The Wikipedia article for *scientific workflow systems* lists 20 notable workflow
    frameworks that target scientific applications. Another article for *workflow
    management systems* lists many more such systems for business-oriented use cases.
    Both lists miss many popular open source frameworks and well-funded startups.
    The landscape is also changing quickly, so by the time you are reading this book,
    any attempt to list all frameworks would be woefully outdated.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科上关于*科学工作流程系统*的文章列出了20个针对科学应用的知名工作流程框架。另一篇关于*工作流程管理系统*的文章列出了更多针对面向业务用例的系统。这两个列表都遗漏了许多流行的开源框架和资金充足的新创公司。这个领域也在迅速变化，所以当你阅读这本书的时候，任何试图列出所有框架的尝试都会显得过时。
- en: 'Instead of trying to rank all frameworks out there, we provide the following
    rubric for evaluating frameworks. The rubric is based on the three concerns we
    touched in the previous section:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不试图对所有现有的框架进行排名，而是提供以下标准来评估框架。这个标准基于我们在上一节中提到的三个问题：
- en: '*Architecture*—What the actual code looks like and how the system looks and
    feels to the data scientist. Do the abstractions provided by the system make data
    scientists more productive and allow them to ship end-to-end data science applications
    faster?'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*架构*—实际的代码看起来是什么样子，以及系统对数据科学家来说看起来和感觉如何。系统提供的抽象是否使数据科学家更有效率，并允许他们更快地交付端到端的数据科学应用？'
- en: '*Job scheduler*—How workflows are triggered, executed, and monitored, and how
    failures are handled. How easy it is to manage a whole jungle of workflows without
    downtime?'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*作业调度器*—工作流程是如何被触发、执行和监控的，以及如何处理失败。在没有停机时间的情况下管理整个工作流程丛林有多容易？'
- en: '*Compute resources*—Where the code executes in practice. Can the system handle
    steps with different resource requirements, such as GPUs, and how many steps can
    the system execute in parallel?'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*计算资源*—代码在实际中执行的位置。系统能否处理具有不同资源需求（如GPU）的步骤，以及系统能并行执行多少步骤？'
- en: Your particular use cases and business environment should determine how you
    weigh these three dimensions. For a small startup with a handful of small use
    cases, compute resources might not be a big concern. For a company that has one
    large-scale use case, compute resources may be more important than anything else.
    A desirable architecture looks very different for a tightly knit team of Haskell
    experts versus a large, distributed organization of data scientists from diverse
    backgrounds.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 你的特定用例和业务环境应该决定你如何权衡这三个维度。对于一个只有几个小型用例的小型初创公司来说，计算资源可能不是一个大问题。对于一个有一个大型用例的公司来说，计算资源可能比其他任何东西都重要。对于一个由
    Haskell 专家紧密团结在一起的团队来说，一个理想的架构与一个由来自不同背景的数据科学家组成的大型、分布式组织相比，看起来非常不同。
- en: 'Table 2.2 provides an example rubric for comparing workflow frameworks. We
    chose five popular frameworks for illustration. Because this book is about infrastructure
    for data science, we focused the comparison to the following concerns that matter
    to data science applications:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.2提供了一个比较工作流程框架的示例标准。我们选择了五个流行的框架进行说明。因为这本书是关于数据科学基础设施的，所以我们把比较集中在以下对数据科学应用重要的问题上：
- en: Is the architecture specifically designed to support data science applications,
    or is it generic in nature?
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 架构是否专门设计来支持数据科学应用，还是它是通用的？
- en: Is the scheduler highly available (HA) by design, that is, is the scheduler
    itself a single point of failure? This is important, because none of the workflows
    can be more reliable than the scheduler that orchestrates them. Optimally, we
    would like to be able to keep any number of workflows running without having to
    worry about the scheduler ever failing.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度器是否设计为高可用（HA），即调度器本身是否是单点故障？这很重要，因为没有任何工作流比协调它们的工作流调度器更可靠。理想情况下，我们希望能够保持任意数量的工作流运行，而无需担心调度器会失败。
- en: How flexible is the support for compute resources? Data science applications
    tend to be compute-heavy and sometimes finicky about their hardware requirements
    (e.g., particular models of GPUs), so this is a useful feature.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对计算资源支持有多灵活？数据科学应用程序通常计算密集，有时对硬件要求（例如，特定的 GPU 模型）很挑剔，因此这是一个有用的功能。
- en: Table 2.2 An example rubric for evaluating workflow frameworks
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.2 评估工作流框架的示例标准
- en: '|  | Architecture | Scheduler | Compute |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '|  | 架构 | 调度器 | 计算 |'
- en: '| Apache Airflow | Arbitrary Python code, not specific to data science | Nice
    GUI; scheduler not HA | Many backends supported through *executors*. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| Apache Airflow | 任意 Python 代码，不特定于数据科学 | 优秀的 GUI；调度器非高可用 | 通过 *executors*
    支持许多后端。|'
- en: '| Luigi | Arbitrary Python code, not specific to data science | Bare-bones;
    not HA | By default, the scheduler executes Python classes, *Tasks*, locally.
    They can push work to other systems. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| Luigi | 任意 Python 代码，不特定于数据科学 | 基础版本；非高可用 | 默认情况下，调度器在本地执行 Python 类，*Tasks*。它们可以将工作推送到其他系统。|'
- en: '| Kubeflow Pipelines | Python, targeting data science use cases | Nice GUI;
    uses a project called Argo under the hood; some HA provided by Kubernetes | Steps
    are run on a Kubernetes cluster. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Kubeflow Pipelines | Python，针对数据科学用例 | 优秀的 GUI；底层使用名为 Argo 的项目；由 Kubernetes
    提供一些高可用性 | 步骤在 Kubernetes 集群上运行。|'
- en: '| AWS Step Functions | JSON-based configuration called Amazon States Language
    | HA by design; managed by AWS | Integrations with some AWS services. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| AWS Step Functions | 基于 Amazon States Language 的 JSON 配置 | 设计为高可用；由 AWS 管理
    | 与一些 AWS 服务集成。|'
- en: '| Metaflow | Python, targeting data science use cases | Local scheduler for
    prototyping; supports HA schedulers like Step Functions for production | Supports
    local *tasks* as well as external compute platforms. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| Metaflow | Python，针对数据科学用例 | 用于原型设计的本地调度器；支持生产中的高可用调度器如 Step Functions |
    支持本地 *tasks* 以及外部计算平台。|'
- en: 'Here’s a quick overview of the covered frameworks:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是对所涵盖框架的快速概述：
- en: '*Apache Airflow* is a popular open source workflow management system that was
    released by Airbnb in 2015\. It is implemented in Python and uses Python to define
    workflows. Multiple commercial vendors, including AWS and GCP, provide managed
    Airflow as a service.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Apache Airflow* 是 Airbnb 在 2015 年发布的一个流行的开源工作流管理系统。它使用 Python 实现，并使用 Python
    定义工作流。包括 AWS 和 GCP 在内的多个商业供应商提供托管 Airflow 作为服务。'
- en: '*Luigi* is another well-known Python-based framework that was open sourced
    by Spotify in 2012\. It is based on the idea of dynamic DAGs, defined through
    data dependencies.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Luigi* 是另一个知名的基于 Python 的框架，由 Spotify 在 2012 年开源。它基于动态 DAG 的概念，通过数据依赖定义。'
- en: '*Kubeflow Pipelines* is a workflow system embedded in the open source Kubeflow
    framework for data science applications running on Kubernetes. The framework was
    published by Google in 2018\. Under the hood, the workflows are scheduled by an
    open source scheduler called Argo that is popular in the Kubernetes ecosystem.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubeflow Pipelines* 是一个嵌入在开源 Kubeflow 框架中的工作流系统，用于在 Kubernetes 上运行的数据科学应用程序。该框架由
    Google 在 2018 年发布。在底层，工作流由一个名为 Argo 的开源调度器进行调度，它在 Kubernetes 生态系统中很受欢迎。'
- en: '*AWS Step Functions* is a managed, not open source, service that AWS released
    in 2016\. DAGs are defined in the JSON format using Amazon States Language. A
    unique feature of Step Functions is that workflows can run for a very long time,
    up to a year, relying on the guarantees of high availability provided by AWS.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AWS Step Functions* 是 AWS 在 2016 年发布的一个托管服务，不是开源服务。DAGs 使用 Amazon States Language
    以 JSON 格式定义。Step Functions 的一个独特功能是工作流程可以运行很长时间，长达一年，依赖于 AWS 提供的高可用性保证。'
- en: '*Metaflow* is a full-stack framework for data science applications, originally
    started by the author of this book and open sourced by Netflix in 2019\. Metaflow
    focuses on boosting the productivity of data scientists holistically, treating
    workflows as a first-class construct. To achieve scalability and high availability,
    Metaflow integrates with schedulers like AWS Step Functions.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Metaflow* 是一个针对数据科学应用程序的全栈框架，最初由本书的作者发起，并于2019年由Netflix开源。Metaflow专注于全面提高数据科学家的生产力，将工作流程视为一等构造。为了实现可扩展性和高可用性，Metaflow与调度器如AWS
    Step Functions集成。'
- en: Besides the frameworks listed here, many other promising frameworks exist, some
    of which target data science applications specifically. Instead of focusing on
    any particular framework, which are well documented online, the purpose of this
    book is to introduce the full stack of data science infrastructure, which workflows
    are a part of, so that you can choose the best technical approach for each layer.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这里列出的框架外，还存在许多其他有希望的框架，其中一些专门针对数据科学应用程序。本书的目的不是专注于任何特定的框架，这些框架在网上有很好的文档，而是介绍数据科学基础设施的全栈，工作流程只是其中一部分，以便您可以为每一层选择最佳的技术方法。
- en: 'When choosing a workflow framework specifically for data science use cases,
    keep the following factors in mind:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 当选择专门针对数据科学用例的工作流程框架时，请考虑以下因素：
- en: In most business environments, productivity of data scientists should be a top
    priority. Choose a framework with an architecture that works well for data science
    use cases specifically. Building data science applications takes much more than
    just workflows, so consider the full data science stack (figure 1.3) when making
    the choice, not just the scheduler layer.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在大多数商业环境中，数据科学家的生产力应该是首要考虑的。选择一个针对数据科学用例特别适合的架构框架。构建数据科学应用程序需要的不仅仅是工作流程，因此在做出选择时，要考虑完整的数据科学堆栈（图1.3），而不仅仅是调度层。
- en: In the long term, operational concerns such as robustness, scalability, and
    high availability of the system tend to dominate other technical concerns. These
    features are both an emergent characteristic of the design of the system as well
    as a result of years of battle-hardening with actual use cases, so fixing them
    overnight is not easy. Hence, it makes sense to choose a system with an established
    track record of operability and scalability. We will cover this topic in detail
    in chapter 4.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从长远来看，系统的鲁棒性、可扩展性和高可用性等运营问题往往会超越其他技术问题。这些特性既是系统设计的涌现特性，也是多年与实际用例战斗的结果，因此一夜之间修复这些问题并不容易。因此，选择一个具有稳定操作性和可扩展性记录的系统是有意义的。我们将在第4章中详细讨论这个话题。
- en: Not being constrained by compute resources can be a huge productivity boost,
    so choose a framework that integrates seamlessly with your compute layer. More
    about this in chapter 3.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不受计算资源的限制可以大幅提高生产力，因此请选择一个与您的计算层无缝集成的框架。关于这一点，请参阅第3章。
- en: In the following chapters we will use Metaflow, which hits the three marks listed
    previously, as an example framework. The principles and examples are generic enough
    so that it shouldn’t be hard to adapt the examples to other frameworks if needed.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将使用符合前面提到的三个标准的Metaflow作为示例框架。其原则和示例足够通用，以至于如果需要，应该不难将示例适应到其他框架。
- en: If setting up everything we covered in this chapter feels like a large investment,
    don’t worry—you can scale the capabilities of the toolchain in stages as the needs
    of your business grow. Table 2.3 provides the recommended configurations for organizations
    of different sizes, based on the number of data scientists served by the infrastructure.
    The options in parentheses refer to figure 2.7.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果设置本章涵盖的所有内容感觉像是一项巨大的投资，请不要担心——随着您业务需求的增长，您可以分阶段扩展工具链的功能。表2.3根据基础设施服务的数据科学家数量，为不同规模的组织提供了推荐的配置。括号中的选项指的是图2.7。
- en: Table 2.3 How much to invest in a development environment
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.3 开发环境投资多少
- en: '|  | Small (1-3 users) | Medium (3-20 users) | Large (20+ users) |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '|  | 小型（1-3用户） | 中型（3-20用户） | 大型（20+用户） |'
- en: '| Cloud account | Recommended | Must | Must |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 云账户 | 推荐 | 必需 | 必需 |'
- en: '| Data science workstation | A laptop will suffice. Specify a common setup
    for all data scientists. | Consider an off-the-shelf cloud offering or a simple
    manually launched cloud workstation with an integrated IDE. | Invest in a self-service,
    automatically provisioned workstation with an integrated IDE. |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 数据科学工作站 | 笔记本电脑就足够了。为所有数据科学家指定一个通用设置。 | 考虑使用现成的云服务或一个简单的手动启动的集成IDE的云工作站。
    | 投资于一个自助、自动配置的集成IDE工作站。 |'
- en: '| Notebooks | Run notebook kernels locally on laptops (option 1). | A simple
    approach is to support notebook kernels on the cloud workstation (option 2). If
    notebooks are leveraged actively, consider providing ephemeral notebooks as well
    (option 3). |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 笔记本 | 在笔记本电脑上本地运行笔记本内核（选项1）。 | 一种简单的方法是在云工作站上支持笔记本内核（选项2）。如果笔记本被积极利用，考虑提供临时笔记本（选项3）。
    |'
- en: '| Workflows | Highly recommended—you can run workflows on a single instance
    using a simple scheduler. | Choose a workflow scheduler that maximizes productivity
    and speed of iteration. | Choose a scheduler that provides high-availability,
    observability, and scalability, in addition to productivity. |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 工作流程 | 非常推荐——您可以使用简单的调度器在单个实例上运行工作流程。 | 选择一个最大化生产力和迭代速度的工作流程调度器。 | 选择一个除了生产力外，还提供高可用性、可观察性和可伸缩性的调度器。
    |'
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Data scientists need a development environment that provides excellent ergonomics
    for the following two key activities:'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学家需要一个提供以下两个关键活动优秀人体工程学的开发环境：
- en: 'Prototyping loop: writing, evaluating, and analyzing application code'
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原型循环：编写、评估和分析应用程序代码
- en: 'Interaction with production deployments: deploying, monitoring, and debugging
    production applications'
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与生产部署的交互：部署、监控和调试生产应用程序
- en: A cloud-backed data science workstation is an effective way to handle the two
    activities. You can develop code locally but evaluate it in an environment that
    resembles production.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于云的数据科学工作站是处理两项活动的一种有效方式。您可以在本地开发代码，但在类似于生产的环境中进行评估。
- en: Notebooks are a necessary but not sufficient part of the data science toolchain.
    Notebooks excel at scratchpad-style prototyping and at analyzing results. You
    can integrate them to work in tandem with an IDE and a terminal on the workstation.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 笔记本是数据科学工具链的必要但不充分的部分。笔记本在刮擦板式原型设计和分析结果方面表现出色。您可以将它们集成到与工作站上的IDE和终端协同工作的环境中。
- en: 'Workflows are a useful abstraction for structuring data science applications.
    Workflows provide a number of benefits: they are easy to understand and explain,
    they help in managing complexity as the number of data science applications grows,
    and they can make execution more scalable and performant.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流程是结构化数据科学应用程序的有用抽象。工作流程提供了一系列好处：它们易于理解和解释，有助于管理随着数据科学应用程序数量的增长而增加的复杂性，并且可以使执行更可扩展和高效。
- en: Tens of different workflow frameworks exist. Pick one that provides excellent
    ergonomics for building data science applications specifically.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在数十种不同的工作流程框架。选择一个为构建数据科学应用程序提供优秀人体工程学的框架。
- en: A job scheduler is responsible for executing workflows. Pick a scheduler that
    integrates well with your compute infrastructure and is sufficiently scalable
    and highly available.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个作业调度器负责执行工作流程。选择一个与您的计算基础设施集成良好、足够可扩展且高度可用的调度器。
