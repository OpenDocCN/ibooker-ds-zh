- en: Chapter 4\. Exploratory Data Analysis with R
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章。R的探索性数据分析
- en: Pat is a manager in the purchasing department at Big Bonanza Warehouse. His
    department specializes in the manufacture of tubing for a variety of construction
    industries, which requires procuring a lot of raw and semi-raw materials. However,
    Pat has a problem; he receives up to a hundred purchase requisitions per day in
    SAP, which need approval before becoming purchase orders. It is a burdensome and
    time-consuming process he would like help streamlining. He decides to ask his
    IT department and the SAP team if anything can be done to help.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Pat是大富翁仓库采购部门的经理。他的部门专门生产各种建筑行业的管子，这需要采购大量的原材料和半成品。然而，Pat有一个问题；他每天在SAP系统中收到多达一百份采购申请，需要经过批准才能成为采购订单。这是一个繁重且耗时的过程，他希望能够得到帮助来优化流程。他决定向IT部门和SAP团队寻求帮助。
- en: 'The SAP team has already configured the system to be optimal for the purchase
    requisition process. When Pat and the SAP team reach out to their colleagues on
    the data science team, they immediately wonder: “Could we build a model to learn
    if a purchase requisition is going to be approved?” There is ample data in the
    SAP system—nearly 10 years of historical data—for which they know all the requisition
    approvals and rejections. It turns out to be millions of records of labeled data.
    All those records indicate approval or rejection. Doesn’t this fall into supervised
    learning? It certainly does!'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: SAP团队已经对系统进行了优化，使采购申请流程变得更加高效。当Pat和SAP团队联系他们的数据科学团队时，他们立刻想到：“我们能否建立一个模型来学习采购申请是否会被批准？”
    SAP系统中有大量数据——近10年的历史数据——他们知道所有的采购申请批准和拒绝情况。原来有数百万条带标签的数据记录，所有这些记录都指示被批准或被拒绝。这不就是监督学习吗？当然是！
- en: 'We introduced four different types of learning models in [Chapter 2](ch02.html#ch02).
    Those are:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第2章](ch02.html#ch02)介绍了四种不同类型的学习模型。它们分别是：
- en: Supervised
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习
- en: Unsupervised
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Semi-supervised
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半监督学习
- en: Reinforcement
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习
- en: We are inclined to think that the scenario mentioned here is a supervised one
    because we have data that is labeled. That is, we have purchase requisitions that
    have been approved and rejected. We can train a model on this labeled data, therefore
    it is a supervised scenario. Having identified the type of learning model we are
    working, the next step is to explore the data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们倾向于认为这里提到的场景是监督学习，因为我们有带标签的数据。也就是说，我们有已经批准和被拒绝的采购申请。我们可以在这些带标签的数据上训练一个模型，因此这是一个监督学习的场景。确定了我们正在使用的学习模型的类型之后，下一步是探索数据。
- en: One of the most vital processes in the data scientist’s workflow is exploratory
    data analysis (EDA). The data scientist uses this process to explore the data
    and determine whether it can be modeled, and if so, how. EDA’s goal is to understand
    the data by summarizing the main characteristics, most often using visualizations.
    This is the step in the data science process that asks the data scientist to become
    familiar with the data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家工作流程中最关键的过程之一是探索性数据分析（EDA）。数据科学家使用这个过程来探索数据，并确定是否能够对其进行建模，以及如何进行建模。EDA的目标是通过总结主要特征来了解数据，通常使用可视化来实现。这一步要求数据科学家熟悉数据。
- en: 'Readers who know SAP well: if you think you’re familiar with your data, go
    through this exercise. You’ll be surprised how much you learn. There’s a vast
    difference between knowing the general shape of the relational data and knowing
    the cleaned, analyzed, and fully modeled results of EDA.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉SAP系统的读者：如果您认为您已经熟悉了您的数据，请尝试进行这项练习。您会惊讶地发现自己学到了多少东西。对于了解关系型数据的一般形式和了解清理、分析和完全建模的结果之间存在着巨大的差异。
- en: 'In this chapter we will walk through the EDA process. To make it more understandable,
    we will go through it in real time. That is, we will not manipulate data to make
    this lesson easy to write; rather, we’re going to make this as realistic and relatable
    as possible. We will run into problems along the way, and we will work through
    them as a real scenario. As shown in [Figure 4-1](#workflow_for_exploratory_data_analysis),
    EDA runs through four main phases: collection, cleansing, analysis, and modeling.
    Let’s break down each phase briefly before we dive deeper into our scenario.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将详细介绍探索性数据分析（EDA）的过程。为了使其更易理解，我们将实时进行。也就是说，我们不会操纵数据以便更轻松地编写本课程；相反，我们将尽可能真实和贴近实际地进行。在我们的情景中，我们将遇到问题，并像处理真实情景一样解决它们。如图
    [4-1](#workflow_for_exploratory_data_analysis) 所示，EDA 包括四个主要阶段：收集、清洗、分析和建模。在深入探讨我们的情景之前，让我们简要介绍每个阶段。
- en: '![Workflow for Exploratory Data Analysis](assets/pdss_0401.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![探索性数据分析工作流程](assets/pdss_0401.png)'
- en: Figure 4-1\. Workflow for exploratory data analysis
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 探索性数据分析工作流程
- en: The Four Phases of EDA
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EDA 的四个阶段
- en: In the *Collect Data* phase, we start with our source system’s data. It’s important
    to understand how the source system records data. If, for example, we don’t know
    what purchase requisitions look like in SAP tables, we can’t pull them out for
    later analysis.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在*收集数据*阶段，我们从源系统的数据开始。了解源系统如何记录数据是很重要的。例如，如果我们不知道SAP表中的采购申请是什么样的，我们就无法将其提取出来进行后续分析。
- en: Once we’ve understood the source data, we choose the methods and tools to get
    it out and examine it. In this chapter, we use a flat-file extraction from SAP
    as an intermediate storage, and the R data analysis language as the method to
    process and play with the data. In EDA that focuses on business scenarios it’s
    important to iterate on hypotheses quickly. Therefore, choose tools that you are
    comfortable and familiar with.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们理解了源数据，我们选择方法和工具来提取并检查数据。在本章中，我们使用了从SAP中的平面文件提取作为中间存储，使用R数据分析语言来处理和分析数据。在专注于业务场景的EDA中，迅速迭代假设是非常重要的。因此，请选择您熟悉和习惯的工具。
- en: If you’re not familiar with any tools yet, fear not! Many options exist for
    extracting and analyzing. [Chapter 3](ch03.html#ch03) discusses several alternative
    SAP data extraction methods and later chapters of this book use many of them.
    The R language is a favorite among statisticians and data scientists, but Python
    also has a very strong community. In this book we’ll use examples and tools from
    both languages.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对任何工具还不熟悉，不要担心！有许多选项可供提取和分析。[第三章](ch03.html#ch03) 讨论了几种替代的SAP数据提取方法，本书的后续章节使用了其中的许多方法。R语言在统计学家和数据科学家中很受欢迎，但Python也有一个非常强大的社区。在本书中，我们将使用这两种语言的示例和工具。
- en: After successfully extracting the data, we enter the *Clean Data* phase. The
    source system’s database, data maintenance rules, and the method we choose to
    extract can all leave their own unique marks on the data. For example, as we’ll
    see sometimes a CSV extract can have extra unwanted header rows. Sometimes an
    API extraction can format numbers in a way incompatible with the analysis tool.
    It can—and often does—happen that when we extract years’ worth of data the source
    system’s own internal rules for governing data has changed.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 成功提取数据后，我们进入*清洗数据*阶段。源系统的数据库、数据维护规则以及我们选择的提取方法都可能在数据上留下自己的独特痕迹。例如，有时CSV提取可能会有额外的不需要的标题行。有时API提取可能会以不兼容分析工具的方式格式化数字。经常出现的情况是，当我们提取多年数据时，源系统的数据管理规则已经发生了变化。
- en: When we clean the data right after extracting, we’re looking for the things
    that are obviously wrong or inconsistent. In this chapter we use R methods to
    clean the data whereas you may feel more comfortable in another language. Whatever
    your approach, our goal for this phase is having the data stripped of obviously
    bad things.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在提取后立即清洗数据时，我们寻找那些明显错误或不一致的事物。在本章中，我们使用R方法来清洗数据，而您可能会更喜欢其他语言。无论您的方法是什么，我们在这个阶段的目标是清除数据中明显存在的问题。
- en: Having met the goal of removing those bad things, it’s time to proceed to the
    *Analysis* phase. This is where we begin to set up hypotheses and explore questions.
    Since the data is in a state we can trust after cleansing, we can visualize relationships
    and decide which ones are the strongest and most deserving of further modeling.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 达到去除这些不良元素的目标后，是时候进入*分析*阶段了。这是我们开始建立假设并探索问题的地方。由于数据在经过清洗后可以信任，我们可以可视化关系并确定哪些关系最强大且值得进一步建模。
- en: In this phase, we will often find ourselves reshaping and reformatting the data.
    It’s a form of cleansing the data that is not focused on removing bad (or badly
    formatted) data; rather, it’s focused on taking good data and shaping it so that
    it can effectively be used in the next phase. The Analysis phase often presents
    several opportunities for this further reshaping.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们经常会发现自己在重塑和重新格式化数据。这是一种清理数据的形式，重点不是去除不良（或格式不佳）的数据，而是专注于将好的数据塑造成下一个阶段可以有效使用的形式。分析阶段通常会为进一步重塑提供几个机会。
- en: 'The final phase is *Modeling*. By this phase, we’ve discovered several relationships
    within the data that are worth pursuing. Our goal here: create a model that allows
    us to draw insightful conclusions or make evidence-supported predictions. The
    model ought to be reliable and repeatable. By modeling this purchasing scenario,
    the SAP team seeks to arm Pat the purchasing manager with information and tools
    that have an insightful impact on his business processes.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个阶段是*建模*。到了这个阶段，我们已经在数据中发现了几个值得追求的关系。我们的目标是：创建一个模型，使我们能够得出见解深刻的结论或进行基于证据的预测。该模型应该是可靠且可重复的。通过对此采购场景进行建模，SAP团队旨在为采购经理帕特提供具有深刻影响的信息和工具。
- en: Greg and Paul know this process well, so let’s get started!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 格雷格和保罗对这个流程非常熟悉，所以让我们开始吧！
- en: 'Phase 1: Collecting Our Data'
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一阶段：收集我们的数据
- en: 'An easy way to get data out of SAP is by using the ABAP QuickViewer. This transaction
    allows the user to view fields of a table or a collection of tables joined together.
    For the purchase requisition to purchase order scenario we need two tables: EBAN
    for purchase requisitions and EKPO for purchase order lines. Use transaction code
    SQVI to start the QuickViewer transaction.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从SAP获取数据的简便方法是使用ABAP QuickViewer。此事务允许用户查看表格或连接在一起的表格集合的字段。对于采购申请到采购订单的情景，我们需要两个表格：采购申请的EBAN和采购订单行的EKPO。使用事务代码SQVI启动QuickViewer事务。
- en: Enter a name for the QuickView ([Figure 4-2](#quick_view_first_screen)).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 输入快速查看的名称（如图 4-2](#quick_view_first_screen)）。
- en: '![Quick View first screen](assets/pdss_0402.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![快速查看第一个屏幕](assets/pdss_0402.png)'
- en: Figure 4-2\. QuickView first screen
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 快速查看第一个屏幕
- en: Click on the Create button and give the QuickView a title ([Figure 4-3](#quick_view_title)).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“创建”按钮并给快速视图命名一个标题（见图 4-3](#quick_view_title)）。
- en: '![Quick View title](assets/pdss_0403.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![快速查看标题](assets/pdss_0403.png)'
- en: Figure 4-3\. QuickView title
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-3\. 快速视图标题
- en: Change the “Data source” to “Table join” ([Figure 4-4](#quick_view_type_options)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 将“数据源”更改为“表连接”（如图 4-4](#quick_view_type_options)）。
- en: '![Quick View type options](assets/pdss_0404.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![快速查看类型选项](assets/pdss_0404.png)'
- en: Figure 4-4\. QuickView type options
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-4\. 快速查看类型选项
- en: Click on the Enter button, then click on the Insert Table button (indicated
    in [Figure 4-5](#fquick_view_create_table)).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“输入”按钮，然后点击“插入表格”按钮（如图 4-5](#fquick_view_create_table)）。
- en: '![FQuick View Create Table](assets/pdss_0405.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![快速查看创建表格](assets/pdss_0405.png)'
- en: Figure 4-5\. QuickView Insert Table button
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-5\. 快速视图插入表格按钮
- en: Enter the name of the first table and click Enter ([Figure 4-6](#first_quick_view_table)).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 输入第一个表格的名称，然后点击“输入”（如图 4-6](#first_quick_view_table)）。
- en: '![First Quick View Table](assets/pdss_0406.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![第一个快速查看表格](assets/pdss_0406.png)'
- en: Figure 4-6\. First QuickView Table
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-6\. 第一个快速查看表格
- en: Repeat the process, click on the Insert Table button, and then click Enter ([Figure 4-7](#second_quick_view_table)).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 重复此过程，点击“插入表格”按钮，然后点击“输入”（如图 4-7](#second_quick_view_table)）。
- en: '![Second Quick View Table](assets/pdss_0407.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![第二个快速查看表格](assets/pdss_0407.png)'
- en: Figure 4-7\. Second Quick View Table
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-7\. 第二个快速查看表格
- en: The tables will be displayed on the screen with their default relationships
    determined ([Figure 4-8](#quick_view_default_join_properties)). Always check these
    relationships to make sure they are what is wanted. In this case, four relationships
    were determined but only two are needed.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 表格将显示在屏幕上，其默认关系已确定（见图 4-8](#quick_view_default_join_properties)）。始终检查这些关系，确保它们符合要求。在这种情况下，确定了四个关系，但只需要两个。
- en: '![Quick View default join properties](assets/pdss_0408.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View 的默认连接属性](assets/pdss_0408.png)'
- en: Figure 4-8\. QuickView default join properties
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-8\. QuickView 的默认连接属性
- en: Right-click on the links for BANFN and BNFPO and select Delete Link ([Figure 4-9](#quick_view_remove_a_default_join)).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 右键单击 BANFN 和 BNFPO 的链接，选择删除连接（见图 4-9）。
- en: '![Quick View remove a default join](assets/pdss_0409.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View 移除默认连接](assets/pdss_0409.png)'
- en: Figure 4-9\. Removing a default join in a QuickView
  id: totrans-49
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-9\. 移除 QuickView 中的默认连接
- en: Double-check the remaining two relationships to make sure they are correct.
    Tables EBAN and EKPO should be linked by EBELN and EBELP ([Figure 4-10](#quick_view_confirm_remaining_join));
    these are the purchase order number and the purchase order item.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 双重检查剩余的两个关系以确保它们是正确的。表 EBAN 和 EKPO 应该通过 EBELN 和 EBELP 进行关联（见图 4-10）；这些是采购订单号和采购订单项。
- en: '![Quick View confirm remaining join](assets/pdss_0410.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View 确认剩余连接](assets/pdss_0410.png)'
- en: Figure 4-10\. Confirming remaining joins in a QuickView
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-10\. 确认 QuickView 中剩余的连接
- en: Click on the Back button. The next screen allows for the selection of fields
    for the report. Open the caret on the left to show all the fields for a table
    ([Figure 4-11](#quick_view_open_table)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 点击返回按钮。下一个屏幕允许选择报表字段。展开左侧的小箭头以显示表的所有字段（见图 4-11）。
- en: '![Quick View open table](assets/pdss_0411.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View 打开表格](assets/pdss_0411.png)'
- en: Figure 4-11\. QuickViewer open table
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-11\. QuickViewer 打开表格
- en: Select the fields to be seen in the first column and the selection parameters
    for the table in the second column ([Figure 4-12](#quick_view_selection_and_list_options)).
    Choosing fields as selection parameters enables those fields for filtering the
    overall results.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一列中选择要显示的字段，并在第二列中选择表的选择参数（见图 4-12）。
- en: '![Quick View selection and list options](assets/pdss_0412.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View 的选择和列表选项](assets/pdss_0412.png)'
- en: Figure 4-12\. Selection and list options for a QuickView
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-12\. QuickView 的选择和列表选项
- en: Next, repeat the process for the Purchase Document Item table.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，重复这个过程来处理采购文档条目表。
- en: Click on the Execute button to run the report. Because the data may be very
    large, we made one of the selection criteria the Changed On date. This allows
    us to narrow the result data. Set the date range and then click on the Execute
    button. For our example, we will select a small one-month set of data just to
    see if the results are what we expect. Then we will rerun the report for the full
    10 years of data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 点击执行按钮以运行报表。由于数据可能非常庞大，我们将其中一个选择标准设置为更改日期。这允许我们缩小结果数据。设置日期范围，然后点击执行按钮。在我们的示例中，我们将选择一个小的一个月数据集，只是为了看看结果是否符合预期。然后我们将为全部
    10 年的数据重新运行报告。
- en: '![Quick View test report](assets/pdss_0413.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View 测试报告](assets/pdss_0413.png)'
- en: Figure 4-13\. QuickView test report
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-13\. QuickView 测试报告
- en: The report is displayed with the fields selected ([Figure 4-14](#quick_view_alv_report)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 报告显示所选字段（见图 4-14）。
- en: '![Quick View ALV report](assets/pdss_0414.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View ALV 报表](assets/pdss_0414.png)'
- en: Figure 4-14\. QuickView ALV (ABAP List Viewer) report
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-14\. QuickView ALV（ABAP 列表查看器）报表
- en: Click on the Export button (circled in [Figure 4-14](#quick_view_alv_report))
    and select Spreadsheet.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 点击导出按钮（见图 4-14 中的圆圈）并选择电子表格。
- en: '![Quick View export options](assets/pdss_0415.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View 导出选项](assets/pdss_0415.png)'
- en: Figure 4-15\. QuickView export options
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-15\. QuickView 导出选项
- en: Accept the default setting for Excel and click Enter ([Figure 4-16](#quick_view_export_to_xlsx)).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接受 Excel 的默认设置并点击 Enter（见图 4-16）。
- en: '![Quick View export to xlsx](assets/pdss_0416.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View 导出为 xlsx](assets/pdss_0416.png)'
- en: Figure 4-16\. QuickView export to xlsx
  id: totrans-71
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-16\. QuickView 导出为 xlsx
- en: Format options here will depend on the SAP version, so the screen may look slightly
    different. Whatever other formats are visible, make sure to choose Excel.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的格式选项取决于 SAP 版本，所以屏幕可能看起来稍有不同。无论其他可见的格式如何，确保选择 Excel。
- en: Name the file and save it ([Figure 4-17](#quick_view_save_dialog)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 给文件命名并保存它（见图 4-17）。
- en: '![Quick View save dialog](assets/pdss_0417.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![Quick View 保存对话框](assets/pdss_0417.png)'
- en: Figure 4-17\. QuickView Save As dialog box
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-17\. QuickView 另存为对话框
- en: Excel will open automatically. Save it as a CSV file so it can easily be loaded
    into R or Python.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Excel 将会自动打开。将其保存为 CSV 文件，以便轻松加载到 R 或 Python 中。
- en: Importing with R
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 R 进行导入
- en: If you have not yet done anything with R or R Studio,^([1](ch04.html#ch04fn2))
    there are many excellent resources online with step-by-step installation guides.
    It is no more difficult than installing any other software on your computer. While
    this book is not intended to be a tutorial in R, we will cover a few of the basics
    to get you started. Once you have installed R Studio, double-click on the icon
    in [Figure 4-18](#r_studio_icon) to start it.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您还没有使用R或R Studio做任何事情，^([1](ch04.html#ch04fn2))在线有许多优秀的资源，提供逐步安装指南。这与在计算机上安装任何其他软件一样简单。虽然本书不打算成为R的教程，但我们将介绍一些基础知识，以帮助您入门。安装了R
    Studio后，双击[图 4-18](#r_studio_icon)中的图标来启动它。
- en: '![R Studio Icon.](assets/pdss_0418.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![R Studio 图标。](assets/pdss_0418.png)'
- en: Figure 4-18\. R Studio icon
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-18\. R Studio 图标
- en: One of the basic concepts in R is the use of packages. These are collections
    of functions, data, and compiled code in a well-defined format. They make coding
    much easier and consistent. You will need to install the necessary packages in
    order to use them. One of our favorites is [`tidyverse`](https://www.tidyverse.org/).
    There are two ways to install this package. You can do it from the console window
    in R Studio using the `install.packages()` function as shown in [Figure 4-19](#install_packages_from_the_console_window).
    Simply hit Enter, and it will download and install the package for you.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: R 中的基本概念之一是使用软件包。这些是以良好定义的格式收集函数、数据和编译代码的集合。它们使编码更加简单和一致。您需要安装必要的软件包才能使用它们。我们最喜欢的之一是[`tidyverse`](https://www.tidyverse.org/)。安装此软件包有两种方法。您可以在R
    Studio的控制台窗口中使用`install.packages()`函数，如[图 4-19](#install_packages_from_the_console_window)所示。只需按Enter键，它将为您下载并安装软件包。
- en: '![Install packages from the console window.](assets/pdss_0419.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![从控制台窗口安装软件包。](assets/pdss_0419.png)'
- en: Figure 4-19\. Install packages from the console window
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-19\. 从控制台窗口安装软件包
- en: The other method of installation is from the menu path Tools → Install Packages
    as shown in [Figure 4-20](#install_packages_from_the_menu_path).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种安装方法是从菜单路径Tools → Install Packages，如[图 4-20](#install_packages_from_the_menu_path)所示。
- en: '![Install packages from the menu path.](assets/pdss_0420.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![从菜单路径安装软件包。](assets/pdss_0420.png)'
- en: Figure 4-20\. Install packages from the menu path
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-20\. 从菜单路径安装软件包
- en: Start typing the package name in the Packages line and then select it from the
    options, as in [Figure 4-21](#select_package_from_the_drop-down_option).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在“Packages”行中开始键入软件包名称，然后从选项中选择，如[图 4-21](#select_package_from_the_drop-down_option)所示。
- en: '![Select package from the drop-down options.](assets/pdss_0421.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![从下拉选项中选择软件包。](assets/pdss_0421.png)'
- en: Figure 4-21\. Select package from the drop-down options
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-21\. 从下拉选项中选择软件包
- en: Finish by clicking on the Install button.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“Install”按钮完成。
- en: Now that you’ve installed one package, let’s start a new script. Click on the
    New button and select R Script from the drop-down menu, as in [Figure 4-22](#starting_a_new_r_studio_script).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完一个软件包后，让我们开始一个新脚本。单击“New”按钮，从下拉菜单中选择R Script，如[图 4-22](#starting_a_new_r_studio_script)所示。
- en: '![Starting a new R Studio script.](assets/pdss_0422.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![开始一个新的R Studio脚本。](assets/pdss_0422.png)'
- en: Figure 4-22\. Starting a new R Studio script
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-22\. 开始一个新的R Studio脚本
- en: Now you will have a blank canvas from which to start your data exploration using
    the R programming language.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您将有一个空白画布，可以开始使用R编程语言进行数据探索。
- en: 'Now, let’s get started. It is easy to import data into R or R Studio using
    the `read.csv()` function. We read the file with the following settings: `header`
    is set to `TRUE` because we have a header on the file. We do not want the strings
    set to factors so `stringsAsFactors` is set to `FALSE`.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始。使用`read.csv()`函数轻松导入数据到R或R Studio。我们使用以下设置读取文件：`header`设置为`TRUE`，因为文件有标题。我们不希望字符串设置为因子，所以`stringsAsFactors`设置为`FALSE`。
- en: Tip
  id: totrans-96
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: It often makes sense to set your strings to factors. Factors represent categorical
    data and can be ordered or unordered. If you plan on manipulating or formatting
    your data after loading it, most often you will not want them as factors. You
    can always convert your categorical variables to factors later using the `factor()`
    function.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 将字符串设置为因子通常是有意义的。因子表示分类数据，并可以是有序或无序的。如果您计划在加载数据后操作或格式化数据，通常不希望它们作为因子存在。您可以随时使用`factor()`函数将分类变量转换为因子。
- en: 'Finally, we want any empty lines or single blank spaces set to NA:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们希望将任何空行或单个空格设置为NA：
- en: '[PRE0]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once the data has loaded we can view a snippet of the file using the `head`
    command, as shown in Figures [4-23](#viewing_header_data_frame_in_r) and [4-24](#viewing_header_data_frame_in_r_continued).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载后，我们可以使用`head`命令查看文件的一部分，如图 [4-23](#viewing_header_data_frame_in_r) 和 [4-24](#viewing_header_data_frame_in_r_continued)
    所示。
- en: '[PRE1]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Viewing header data frame in r](assets/pdss_0423.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![在 R 中查看头数据帧](assets/pdss_0423.png)'
- en: Figure 4-23\. Viewing header dataframe in R
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-23\. 在 R 中查看头数据帧
- en: '![Viewing header data frame in r continued](assets/pdss_0424.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![在 R 中查看头数据帧继续](assets/pdss_0424.png)'
- en: Figure 4-24\. Viewing header dataframe in R continued
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-24\. 在 R 中查看头数据帧继续
- en: We can quickly see that some cleanup is in order. The row numbers came in as
    columns and some formatting problems created some arbitrary columns such as X
    and X.1\. Cleaning them up is our first task.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快就能看到需要进行一些清理的地方。行号作为列导入，并且一些格式问题导致了一些任意的列，比如 X 和 X.1\. 清理它们是我们的第一个任务。
- en: 'Phase 2: Cleaning Our Data'
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二阶段：清理我们的数据
- en: Our goal in this phase is to remove or correct the obvious errors within the
    extraction. By taking the time to clean the data now, we greatly improve the effectiveness
    of our analysis and modeling steps. Greg and Paul know that cleaning can take
    up a major portion of the EDA time so they hunker down with R Studio at the ready.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们的目标是删除或纠正提取过程中明显的错误。现在花时间清理数据，可以极大地提高我们分析和建模步骤的效率。格雷格和保罗知道清理可能占据探索性数据分析时间的很大一部分，所以他们已经准备好用
    R Studio 进行工作。
- en: Null Removal
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 空值移除
- en: 'First, we remove all rows where there is no purchase requisition number. This
    is erroneous data. There may not actually be any rows to remove, but this is a
    good standard process. Making sure that the key features of the data actually
    have entries is a good start:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们删除所有没有采购申请号的行。这是错误的数据。实际上可能没有任何需要移除的行，但这是一个良好的标准过程。确保数据的关键特征确实有条目是一个很好的开始：
- en: '[PRE2]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Binary Indicators
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二进制指示器
- en: 'Next, the D and the D.1 columns are our deletion or rejection indicators for
    the purchase requisition. Making that a binary will be a true or false indicator.
    We can easily do that by making blanks equal to 0 (false) and any other entry
    equal to 1 (true). Why use a binary and not just put in text as “Rejected” or
    “Not Rejected”? Keep in mind that you will be visualizing and perhaps modeling
    this data. Models and visualizations do not do well with categorical variables
    or text. However, visualizing and modeling 0 and 1 is easy:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，D 和 D.1 列是我们的采购申请的删除或拒绝指标。将其作为二进制将是一个真假指示器。我们可以很容易地通过将空白等于 0（假）和任何其他条目等于
    1（真）来实现这一点。为什么使用二进制而不只是插入“已拒绝”或“未拒绝”的文本？请记住，您将会可视化和可能对这些数据进行建模。模型和可视化在处理分类变量或文本时表现不佳。然而，可视化和建模
    0 和 1 是很容易的：
- en: '[PRE3]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Removing Extraneous Columns
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除多余的列
- en: 'Let’s get rid of the worthless and erroneous columns. Why do this? Why not
    simply ignore those columns? Keeping the data free of extra columns frees up memory
    for processing. In our current example, this is not truly necessary. However,
    later if we build a neural network we want to be as efficient as possible. It
    is simply good practice to have clean and tidy^([2](ch04.html#ch04fn4)) data.
    We create a list of column names and assign them to the “drops”variable. Then
    we create a new dataframe that is old dataframe with the “drops” excluded:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们摆脱那些无用和错误的列。为什么要这样做？为什么不简单地忽略那些列？保持数据没有额外的列可以释放出用于处理的内存。在我们当前的示例中，这并不是真正必要的。然而，如果稍后我们构建一个神经网络，我们希望尽可能高效。拥有干净整洁的数据是一个简单而有效的做法^([2](ch04.html#ch04fn4))。我们创建一个列名列表，并将其赋给“drops”变量。然后我们创建一个新的数据框，它是旧数据框去掉“drops”的结果：
- en: '[PRE4]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Tip
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: There are many different types of data structures in R. A dataframe is a table
    in which each column represents a variable and each row contains values for each
    column, much like a table in Excel.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在 R 中有许多不同类型的数据结构。数据框（dataframe）是一个表格，其中每列代表一个变量，每行包含每列的值，就像 Excel 中的表格一样。
- en: Whitespace
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 空白
- en: 'A common problem when working with data is whitespace. Whitespace can cause
    lookup and merge problems later. For instance, you want to merge two dataframes
    by the column *customer*. One data frame column has “Smith DrugStore” and the
    other has “ Smith DrugStore”. Notice the spaces before and after the name in the
    second dataframe? R will not think that these two customers are the same. These
    spaces or blanks in the data look like legitimate entries to the program. It is
    a good idea to remove whitespace and other “invisible” elements early. We can
    clean that up easily for all columns in the dataframe with the following code:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 处理数据时常见的问题之一是空白。空白可能会导致后续查找和合并问题。例如，您想要通过*customer*列合并两个数据框。一个数据框列有“Smith DrugStore”，另一个数据框有“
    Smith DrugStore”。注意第二个数据框中名称前后的空格？R将不会认为这两个客户是相同的。这些数据中的空格或空白看起来像程序的合法输入。早期删除空格和其他“隐形”元素是个好主意。我们可以使用以下代码轻松地为数据框中的所有列清理它们：
- en: '[PRE5]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: What is that `lapply()` function doing? Read up on these useful [functions](http://bit.ly/2khPSHb)
    to get more out of your R code.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '`lapply()`函数是做什么的？阅读这些有用的[函数](http://bit.ly/2khPSHb)可以让你更好地使用你的R代码。'
- en: Numbers
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Numbers
- en: 'Next, we modify the columns that are numeric or integer to have that characteristic.
    If your column has a numeric value then it should not be stored as a character.
    This can happen during the loading of data. Simply put, a value of 1 does not
    equal the value of “1”. Making sure the columns in our dataframe are correctly
    classified with the right type is another one of the key cleaning steps that will
    solve potential problems later:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们修改数值或整数列，使其具有这种特性。如果您的列具有数值，则不应将其存储为字符。这可能会在加载数据时发生。简而言之，值1不等于“1”的值。确保我们数据框中的列正确分类和正确类型是另一个关键的清理步骤，可以解决以后可能出现的问题：
- en: '[PRE6]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we replace NA values with zeros in the numeric values we just created.
    NA simply means the value is not present. R will not assume discrete variables
    such as quantity will have a value of zero if the value is not present. In our
    circumstance, however, we want the NAs to have a value of zero:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在我们刚创建的数值中用零替换NA值。NA表示该值不存在。R不会假设像数量这样的离散变量在值不存在时为零。然而，在我们的情况下，我们希望NA值为零：
- en: '[PRE7]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, we clean up those categorical variables by replacing any blanks with
    NA. This will come in handy later when looking for missing values...blanks can
    sometimes look like values in categorical variables, therefore NA is more reliable.
    We already treated whitespace earlier, but this is another good practice step
    that will help us to avoid problems later:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过用NA替换任何空白来清理这些分类变量。在查找缺失值时，这将很有用……空白有时看起来像分类变量中的值，因此NA更可靠。我们之前已经处理了空白，但这是另一个很好的实践步骤，将帮助我们避免以后的问题：
- en: '[PRE8]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Phase 3: Analyzing Our Data'
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三阶段：分析我们的数据
- en: 'We’ve cleaned up the data and are now entering the analysis phase. We’ll recall
    two key goals of this phase: asking deeper questions to form hypotheses, and shaping
    and formatting the data appropriately for the Modeling phase. Greg and Paul’s
    cleanup process left them with data in a great position to continue into the Analysis
    phase.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经清理了数据，现在进入分析阶段。我们将回顾此阶段的两个关键目标：提出更深层次的问题来形成假设，以及为建模阶段适当地塑造和格式化数据。Greg和Paul的清理过程让他们的数据处于一个继续进入分析阶段的良好位置。
- en: DataExplorer
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DataExplorer
- en: Let’s cheat and take some shortcuts. That is part of the glory of all the libraries
    that R has to offer. Some very quick and easy data exploration can be done using
    the `DataExplorer` library.^([3](ch04.html#ch04fn6))
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们取个捷径。这也是R提供的所有库的光辉的一部分。使用`DataExplorer`库可以进行一些非常快速和简单的数据探索。^([3](ch04.html#ch04fn6))
- en: 'Install and include the library using the following R commands:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下R命令安装并包括库：
- en: '[PRE9]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Perform a quick visualization of the overall structure of the data ([Figure 4-25](#viewing_overall_structure_of_data_using)):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据整体结构进行快速可视化（[Figure 4-25](#viewing_overall_structure_of_data_using)）：
- en: '[PRE10]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Viewing overall structure of data using DataExplorer](assets/pdss_0425.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![使用DataExplorer查看数据的整体结构](assets/pdss_0425.png)'
- en: Figure 4-25\. Viewing overall structure of data using DataExplorer
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-25。使用DataExplorer查看数据的整体结构
- en: 'We can use the `introduce` command from the `DataExplorer` package to get an
    overview of our data:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`DataExplorer`包中的`introduce`命令来概述我们的数据：
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We see that we have over three million rows of data with thirteen columns. Nine
    of them are discrete and four of them are continuous.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到我们有超过三百万行数据，共十三列。其中九列为离散变量，四列为连续变量。
- en: 'It is important to see if any of the columns are missing a lot of data. In
    general, columns that are largely empty (over 90%) don’t have any value in modeling
    ([Figure 4-26](#identifying_missing_or_near_missing_vari)):'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 看看是否有某些列缺少大量数据非常重要。一般来说，大部分为空的列（超过 90%）在建模中没有任何价值（参见 [图 4-26](#identifying_missing_or_near_missing_vari)）：
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Because of the large number of missing entries for the `Des.Vendor` field we
    will remove it:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`Des.Vendor`字段中缺失条目较多，我们将其删除：
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Identifying missing or near missing variables with DataExplorer](assets/pdss_0426.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![使用DataExplorer识别缺失或近乎缺失的变量。](assets/pdss_0426.png)'
- en: Figure 4-26\. Identifying missing or near missing variables with DataExplorer
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-26\. 使用DataExplorer识别缺失或近乎缺失的变量
- en: Discrete Features
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 离散特征
- en: 'Understanding the discrete features^([4](ch04.html#ch04fn7)) helps in selecting
    data that will improve model performance, and removing data that does not. We
    can plot the distribution of all discrete features quite easily (Figures [4-27](#bar_charts_of_discrete_features)
    through [4-29](#bar_charts_of_discrete_features-id0001)):'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 了解离散特征^([4](ch04.html#ch04fn7))有助于选择能提升模型性能的数据，以及删除没有用的数据。我们可以很容易地绘制所有离散特征的分布（图
    [4-27](#bar_charts_of_discrete_features) 到 [4-29](#bar_charts_of_discrete_features-id0001)）：
- en: '[PRE14]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note
  id: totrans-153
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Discrete variables with more than 50 entries are excluded.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 排除具有超过 50 个条目的离散变量。
- en: 'What we notice right away is that there is a mysterious and obvious erroneous
    entry. In the distribution for Document Type there is a document type called…“Document
    Type.” Same with all the other discrete features. Let’s find out where that line
    is and take a look at it:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们立即注意到一个神秘而明显的错误条目。在“文档类型”分布中有一个名为…“文档类型”的文档类型。其他离散特征也是如此。让我们找出那一行并查看一下：
- en: '[PRE15]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'What we see is a list and count of 49 entries where the document type is “Document
    Type” and all other columns have the description of the column and not a valid
    value. It is likely that the extraction from SAP had breaks at certain intervals
    where there were header rows. It is easy to remove:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了一个包含 49 个条目的列表和计数，其中文档类型为“文档类型”，而其他所有列都有列描述而不是有效值。很可能是从 SAP 提取时，在某些间隔处有头行。很容易移除：
- en: '[PRE16]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Bar charts of discrete features.](assets/pdss_0427.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![离散特征的条形图。](assets/pdss_0427.png)'
- en: Figure 4-27\. Bar charts of discrete features (part I)
  id: totrans-160
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-27\. 离散特征的条形图（第一部分）
- en: '![Bar charts of discrete features continued.](assets/pdss_0428.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![继续离散特征的条形图。](assets/pdss_0428.png)'
- en: Figure 4-28\. Bar charts of discrete features (part II)
  id: totrans-162
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-28\. 离散特征的条形图（第二部分）
- en: '![Bar charts of discrete features continued.](assets/pdss_0429.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![继续离散特征的条形图。](assets/pdss_0429.png)'
- en: Figure 4-29\. Bar charts of discrete features (part III)
  id: totrans-164
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-29\. 离散特征的条形图（第三部分）
- en: When we run `plot_bar(pr)` again we see that these bad rows have been removed.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们再次运行`plot_bar(pr)`时，我们看到这些不良行已被删除。
- en: 'We also noticed that some of the variables were not plotted. This is because
    they had more than 50 unique values. If a discrete variable has too many unique
    values it will be difficult to code for in the model. We can use this bit of code
    to see the count of unique values in the variable `Material`:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还注意到一些变量没有被绘制出来。这是因为它们有超过 50 个唯一值。如果一个离散变量有太多唯一值，在模型中编码会很困难。我们可以使用以下代码来查看变量`Material`中唯一值的计数：
- en: '[PRE17]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Wow, we find that we have more than 500,000 unique values. Let’s think about
    this. Will the material itself make a good feature for the model? We also have
    a variable `Matl.Group`, which represents the grouping into which the material
    belongs. This could be office supplies, IT infrastructure, raw materials, or something
    similar. This categorization is more meaningful to us than an exact material number.
    So we’ll remove those material number values as well:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，我们发现我们有超过 500,000 个唯一值。让我们仔细考虑一下。材料本身能成为模型的一个良好特征吗？我们还有一个名为`Matl.Group`的变量，表示材料所属的分类。这可以是办公用品、IT基础设施、原材料或类似的内容。对我们来说，这种分类比确切的材料编号更有意义。因此，我们也将删除那些材料编号的值：
- en: '[PRE18]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We also notice from this bar plot that the variable `Cat` only has one unique
    value. This variable will have no value in determining the approval or disapproval
    of a purchase requisition. We’ll delete that variable as well:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还从这个条形图中注意到，变量`Cat`只有一个唯一值。这个变量在决定采购申请的批准或不批准方面毫无价值。我们将删除该变量：
- en: '[PRE19]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Continuous Features
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连续特征
- en: Next we want to get to know our numeric/continuous variables, such as Net.Price.
    Do our continuous variables have a normal bell-shaped distribution? This is helpful
    in modeling, because machine learning and neural networks prefer distributions
    that are not skewed left or right. Our suspicions are that the continuous variables
    are all right skewed. There will be more purchase requisition requests for one
    or two items than 20 or 30\. Let’s see if that suspicion is correct.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们想要了解我们的数值/连续变量，比如Net.Price。我们的连续变量是否呈正态钟形分布？这在建模中很有帮助，因为机器学习和神经网络更喜欢不偏斜的分布。我们怀疑连续变量都呈右偏态。一两件物品的采购申请请求会比20或30件更多。让我们看看这种怀疑是否正确。
- en: Tip
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Nature loves a uniform/Gaussian distribution. School grades, rainfall over a
    number of years or by country, and individual heights and weights all follow a
    Gaussian distribution. Machine learning and neural networks prefer these distributions.
    If your data is not Gaussian, it is a good choice to log transform, scale, or
    normalize the data.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 自然喜欢均匀/高斯分布。学校成绩，多年来或按国家划分的降雨量，以及个体身高和体重都遵循高斯分布。机器学习和神经网络更喜欢这些分布。如果您的数据不是高斯分布，对数据进行对数变换、缩放或归一化是一个不错的选择。
- en: 'We can see a distribution of the data with a simple histogram plot. Using the
    `DataExplorer` package in R makes it easy to plot a histogram of all continuous
    variables at once ([Figure 4-30](#histograms_of_continuous_features)):'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过简单的直方图显示数据的分布。在R中使用`DataExplorer`包可以轻松地同时绘制所有连续变量的直方图（参见[图4-30](#histograms_of_continuous_features)）：
- en: '[PRE20]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Histograms of continuous features.](assets/pdss_0430.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![连续特征的直方图。](assets/pdss_0430.png)'
- en: Figure 4-30\. Histograms of continuous features
  id: totrans-179
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-30\. 连续特征的直方图
- en: We are only concerned with the histograms for Qty.Requested, Valn.Price, and
    Net.Price. The deletion column we know is just a binary we created where 1 means
    the item was rejected (deleted) and 0 means it was not. We quickly see that all
    histograms are right skewed as we suspected. They have a tail running off to the
    right. It is important to know this as we may need to perform some standardization
    or normalization before modeling the data.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只关心Qty.Requested，Valn.Price和Net.Price的直方图。我们知道删除列只是我们创建的一个二进制列，其中1表示物品被拒绝（删除），0表示未被拒绝。我们很快就看到所有直方图都呈右偏态，正如我们所怀疑的那样。它们向右延伸。了解这一点很重要，因为在对数据进行建模之前，我们可能需要进行一些标准化或归一化处理。
- en: Note
  id: totrans-181
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注
- en: 'Normalization reduces the scale of the data to be in a range from 0 to 1:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化将数据的尺度缩小到0到1的范围内：
- en: X[normalized] = X−X[min / (]X[max]−X[min)]
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: X[归一化] = X−X[min / (]X[max]−X[min)]
- en: 'Standardization reduces the scale of the data to have a mean(μ) of 0 and a
    standard deviation(σ) of 1:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 标准化将数据的尺度缩小到均值（μ）为0，标准差（σ）为1：
- en: X[standardized] = X−μ / σ
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: X[标准化] = X−μ / σ
- en: Another test is the QQ plot (quantile-quantile). This will also show us if our
    continuous variables have a normal distribution. We know that the distributions
    were not normally distributed by the histograms. The QQ plot here is for illustration
    purposes.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个测试是QQ图（分位数-分位数图）。这也会显示我们的连续变量是否呈正态分布。通过直方图我们知道这些分布不是正态分布。这里的QQ图仅供示意。
- en: 'A QQ plot will display a diagonal straight line if it is normally distributed.
    In our observations we can quickly see that these variables are not normally distributed.
    The QQ plot in DataExplorer (see [Figure 4-31](#qqplots_continuous_features) for
    interesting continuous features, and [Figure 4-32](#deletion_flag) for the deletion
    flag) by default compares the data to a normal distribution:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果QQ图呈对角直线，说明数据是正态分布的。通过我们的观察，我们很快就能看出这些变量并不呈正态分布。DataExplorer中的QQ图（参见[图4-31](#qqplots_continuous_features)以查看有趣的连续特征，和[图4-32](#deletion_flag)以查看删除标记）默认将数据与正态分布进行比较：
- en: '[PRE21]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![QQplots of continuous features.](assets/pdss_0432.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![连续特征的QQ图。](assets/pdss_0432.png)'
- en: Figure 4-31\. QQ plots of continuous features
  id: totrans-190
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-31\. 连续特征的QQ图
- en: '![QQ plots showing the data is not normally distributed](assets/pdss_0431.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![QQ图显示数据不符合正态分布](assets/pdss_0431.png)'
- en: Figure 4-32\. QQ plots showing the data is not normally distributed
  id: totrans-192
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-32\. QQ图显示数据不符合正态分布
- en: 'Phase 4: Modeling Our Data'
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四阶段：建模我们的数据
- en: Now that we’ve familiarized ourselves with the data, it’s time to shape and
    feed it into a neural network to check whether it can learn if a purchase requisition
    is approved or rejected. We will be using TensorFlow and Keras in R to do this.
    Greg and Paul know that the Modeling phase is where value actually gets extracted—if
    they approach modeling correctly, they know they’ll glean valuable insight unlocked
    by following through on the Collect, Clean, and Analyze phases.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了数据，是时候将其塑造并输入神经网络以检查它是否能学会购买申请是否被批准或拒绝。我们将在R中使用TensorFlow和Keras来完成这个任务。Greg和Paul知道建模阶段才是实际价值被提取的地方——如果他们正确地进行建模，他们知道将通过“收集、清洗和分析”阶段获得宝贵的见解。
- en: TensorFlow and Keras
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow和Keras
- en: Before we dive deep into our model, we should pause a bit and discuss TensorFlow
    and Keras. In the data science and machine learning world, they’re two of the
    most widely used tools.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入研究我们的模型之前，我们应该稍作停顿，讨论一下TensorFlow和Keras。在数据科学和机器学习领域，它们是两个最广泛使用的工具。
- en: TensorFlow is an open source software library that, especially since its 1.0.0
    release in 2017, has quickly grown into widespread use in numerical computation.
    While high-performance numerical computation applies across many domains, TensorFlow
    grew up inside the Google Brain team in their AI focus. That kind of pedigree
    gives its design high adaptability to machine learning and deep learning tasks.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是一个开源软件库，特别是自2017年发布1.0.0版本以来，在数值计算方面迅速被广泛使用。尽管高性能数值计算适用于许多领域，但TensorFlow在Google
    Brain团队的AI专注中成长起来。这种血统使其设计对机器学习和深度学习任务具有高适应性。
- en: Even though TensorFlow’s hardest-working code is highly tuned and compiled C++,
    it provides a great Python and R API for easy consumption. You can program directly
    using [TensorFlow](http://bit.ly/2mfiwsY) or use Keras. Keras is a higher level
    API for TensorFlow that is user-friendly, modular, and easy to extend. You can
    use TensorFlow and Keras on Windows, macOS, Linux, and Android/iOS. The coolest
    piece of the TensorFlow universe is that Google has even created custom hardware
    to supercharge TensorFlow performance. Tensor Processing Units (TPUs) were at
    the heart of the most advanced versions of AlphaGo and AlphaZero, the game-focused
    AIs that conquered the game of Go—long thought to be decades away from machine
    mastery.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管TensorFlow最辛勤工作的代码是高度调整和编译的C++，它为简单消费提供了出色的Python和R API。你可以直接使用[TensorFlow](http://bit.ly/2mfiwsY)编程，或者使用Keras。Keras是TensorFlow的高级API，用户友好、模块化且易于扩展。你可以在Windows、macOS、Linux和Android/iOS上使用TensorFlow和Keras。TensorFlow宇宙中最酷的部分是，Google甚至创建了定制硬件来增强TensorFlow的性能。Tensor
    Processing Units (TPUs)是AlphaGo和AlphaZero最先进版本的核心，这些专注于游戏的AI征服了围棋——长期以来被认为是机器精通的几十年之外的游戏。
- en: Core TensorFlow is great for setting up powerful computation in complex data
    science scenarios. But it’s often helpful for data scientists to model their work
    at a higher level and abstract away some of the lower-level details.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 核心TensorFlow非常适合在复杂的数据科学场景中设置强大的计算。但对于数据科学家来说，通常有助于在更高的抽象级别建模工作，并抽象掉一些底层细节。
- en: Enter Keras. It’s extensible enough to run on top of several of the major lower-level
    ML toolkits, like TensorFlow, Theano, or the Microsoft Cognitive Toolkit. Keras’
    design focuses on Pythonic and R user-friendliness in quickly setting up and experimenting
    on deep neural network models. And as data scientists, we know that quick experiments
    provide the best results—they allow you to fail fast and move toward being more
    correct!
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 进入Keras。它足够可扩展，可以在几个主要的底层ML工具包（如TensorFlow、Theano或Microsoft Cognitive Toolkit）之上运行。Keras的设计侧重于Python和R的用户友好性，快速建立和实验深度神经网络模型。作为数据科学家，我们知道快速实验提供了最好的结果——它们允许你快速失败并朝着更正确的方向前进！
- en: Quick pause over. Let’s dive back into the scenario. We will be using TensorFlow
    and Keras in a bit, but first we’ll use basic R programming.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 快速停顿结束。让我们回到场景中。我们将稍后在TensorFlow和Keras中使用它们，但首先我们会使用基本的R编程。
- en: Training and Testing Split
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和测试分离
- en: The first step of the process is to split the data into training and testing
    sets. This is easy with the [library *rsample*](http://bit.ly/2mk4iHr).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的第一步是将数据分割成训练集和测试集。使用[库*rsample*](http://bit.ly/2mk4iHr)很容易实现这一点。
- en: '[PRE22]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Looking in the global environments of R Studio shows there are two new dataframes:
    TRN for training and TST for testing ([Figure 4-33](#view_of_the_training_and_testing_data_fr)).'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在R Studio的全局环境中查看，有两个新的数据框：TRN用于训练，TST用于测试（[图4-33](#view_of_the_training_and_testing_data_fr)）。
- en: '![View of the training and testing data frames.](assets/pdss_0433.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![训练和测试数据框的视图。](assets/pdss_0433.png)'
- en: Figure 4-33\. View of the training and testing dataframes
  id: totrans-207
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-33\. 训练和测试数据框的视图
- en: Shaping and One-Hot Encoding
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据整形和独热编码
- en: 'We are still in the process of shaping our data for TensorFlow and Keras. We
    continue with basic R programming in the next steps. The next steps are to shape
    the data such that it will work well with a neural network. Neural networks, in
    general, work best on data that is normally distributed. The data that we are
    feeding into our network needs to be nominal: we can’t feed the categorical variables
    we find in our purchase requisition data into the model. The network wouldn’t
    know what to do with something such as “Material Group.” We will convert our categorical
    data to sparse data using a process called *one-hot encoding*.^([5](ch04.html#ch04fn10))
    For instance, the result of a one-hot encoding for the Matl.Group column would
    look like [Figure 4-34](#visualization_of_one-hot_encoding).'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仍在为 TensorFlow 和 Keras 整形我们的数据过程中。我们将在接下来的步骤中继续基本的 R 编程。下一步是整形数据，使其可以与神经网络很好地配合。总的来说，神经网络对正态分布的数据表现最佳。我们正在向网络中输入的数据必须是名义的：我们不能将我们在采购申请数据中发现的分类变量输入到模型中。网络不会知道如何处理诸如“物料组”之类的内容。我们将使用称为
    *独热编码* 的过程将我们的分类数据转换为稀疏数据。^([5](ch04.html#ch04fn10)) 例如，Matl.Group 列的独热编码的结果将如
    [图 4-34](#visualization_of_one-hot_encoding) 所示。
- en: '![Visualization of one-hot encoding.](assets/pdss_0434.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![独热编码的可视化。](assets/pdss_0434.png)'
- en: Figure 4-34\. Visualization of one-hot encoding
  id: totrans-211
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-34\. 独热编码的可视化
- en: 'We know that we want to one-hot encode our categorical variables, but what
    do we want to do with the others, if anything? Consider the Qty.Requested column,
    and the number of options on a purchase requisition for quantity requested. A
    purchase requisition for a new vehicle would likely not be more than one. However,
    the quantity requested for batches of raw materials might be a thousand pounds.
    This makes us curious, what is the range of values in the Qty.Requested column?
    We can see that easily with these commands:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道我们想要对分类变量进行独热编码，但对于其他变量，我们想要做些什么呢？考虑到请求数量列和采购申请的数量选项。新车的采购申请可能不会超过一个。然而，原材料批次的请求数量可能是一千磅。这让我们很好奇，请求数量列的值范围是多少？我们可以轻松地用以下命令看到：
- en: '[PRE23]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We see that the values range from 0 to 986\. What? Quantities of zero? How many
    of them are there?
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到值的范围是从 0 到 986。什么？零的数量？有多少个？
- en: '[PRE24]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We see that there are 313 rows with a quantity of 0! What could this mean? We
    are confused about this data, so do we throw it out? Data science is not a vacuum,
    as much as us coders would like it to be. We have to return to the business with
    a couple examples of purchase requisitions with quantities of zero and ask them
    if they know why. If they don’t, then we’ll toss the rows with zero quantities.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到有 313 行的数量为 0！这是什么意思？我们对这些数据感到困惑，那我们应该将它们删除吗？数据科学并不是真空的，尽管我们编码人员希望它是。我们必须回到业务部门，拿几个数量为零的采购申请的例子，并问他们是否知道原因。如果他们不知道，那么我们将删除这些数量为零的行。
- en: 'We learned something through this process. When Pat is asked about these strange
    requisitions he says, “Sometimes when I’m not at my computer and someone calls
    about a purchase requisition that I reject, they zero out the quantity because
    they don’t have authority to reject the line.” In essence, zero quantity purchase
    requisitions are rejected purchase requisitions. We have to convert the deletion
    indicator on these to 1 to indicate they are rejected:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个过程，我们学到了一些东西。当问及帕特关于这些奇怪的申请时，他说：“有时候当我不在电脑旁，有人打电话来询问我拒绝的采购申请，他们会将数量归零，因为他们没有拒绝该行的权利。”
    实质上，数量为零的采购申请是被拒绝的采购申请。我们必须将这些的删除指示器转换为 1，以表示它们被拒绝：
- en: '[PRE25]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Now that we’ve properly dealt with zero quantity purchase requisitions we return
    to the task at hand. The model will not perform optimally on individual variables
    from 0 to a thousand. Bucketing these order quantities into groups will allow
    the model to perform better. We will create three buckets of values. We’ve chosen
    this value rather arbitrarily and can change it later as we test the performance
    of our model.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经适当处理了数量为零的采购申请，我们回到手头的任务。模型将无法在从 0 到一千的单个变量上表现最佳。将这些订单数量分成几组将使模型表现更好。我们将创建三个值桶。我们选择这个值相当随意，可以在测试模型性能时稍后更改。
- en: Recipes
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配方
- en: We’ve decided to one-hot encode our categorical variables and scale and bucket
    our numeric ones. To do this we will use the [`recipes`](http://bit.ly/2NHJ9SY)
    library in R. This very convenient library allows us to create “recipes” for our
    data transformation.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们决定对我们的分类变量进行独热编码，以及对我们的数值变量进行缩放和分桶。为此，我们将在R中使用[`recipes`](http://bit.ly/2NHJ9SY)库。这个非常方便的库允许我们为数据转换创建“配方”。
- en: 'The *recipes* concept is intuitive: define a recipe that can be used later
    to apply encodings and processing. The final result can then be applied to machine
    learning or neural networks.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '*recipes*的概念很直观：定义一个配方，以便稍后应用编码和处理。最终的结果可以应用于机器学习或神经网络。'
- en: We’ve already decided what we want to do with our data to prepare it for a network.
    Let’s go through the code from the `recipes` package that will make that happen.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经决定了如何处理数据以准备用于网络。让我们通过`recipes`包中的代码来实现这一点。
- en: 'First we want to create a `recipe` object that defines what we are analyzing.
    In this code we say we want to predict the deletion indicator based on the other
    features in our data:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们想创建一个`recipe`对象，定义我们要分析的内容。在这段代码中，我们说我们希望根据数据中的其他特征预测删除指示器：
- en: '[PRE26]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note
  id: totrans-226
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'If you run into memory errors such as “Error: cannot allocate vector of size
    x.x Gb” you can increase the memory allowed by using the following command (the
    first two numbers indicate how many gigs you are allocating; in this case, it’s
    12):'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '如果遇到内存错误，如“Error: cannot allocate vector of size x.x Gb”，可以使用以下命令增加内存分配（前两个数字表示分配的几个Gigabytes，本例中为12）：'
- en: '[PRE27]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Our next step is to take that `recipe` object and apply some ingredients to
    it. We already stated that we want to put our quantity and price values into three
    bins. We use the `step_discretize` function from `recipes` to do that:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一步是取出`recipe`对象，并对其应用一些成分。我们已经说明了我们希望将我们的数量和价格值放入三个桶中。我们使用`recipes`中的`step_discretize`函数来实现这一点：
- en: Tip
  id: totrans-230
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Some modelers prefer binning and some prefer keeping continuous variables continuous.
    We bin here to improve performance of our model later.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 一些建模者更喜欢分箱，而另一些则喜欢保持连续变量的连续性。在这里，我们分箱以提高模型的性能。
- en: '[PRE28]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We wanted to also one-hot encode all of our categorical variables. We could
    list them out one at a time, or we could use one of the many selectors that come
    with the `recipes` package. We use the `step_dummy` function to perform the encoding
    and the `all_nominal` selector to select all of our categorical variables:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还希望对所有的分类变量进行独热编码。我们可以一次列出它们，也可以使用`recipes`包中的许多选择器之一。我们使用`step_dummy`函数执行编码，并使用`all_nominal`选择器选择所有的分类变量：
- en: '[PRE29]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then we need to scale and center all the values. As mentioned earlier, our
    data is not Gaussian (normally distributed) and therefore some sort of scaling
    is in order:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们需要对所有的值进行缩放和居中处理。如前所述，我们的数据不服从高斯分布，因此需要进行某种形式的缩放：
- en: '[PRE30]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Tip
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: There are many normalization methods; in our example, we use min-max feature
    scaling and standard score.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多归一化方法；在我们的例子中，我们使用了最小-最大特征缩放和标准分数。
- en: 'Notice so far that we’ve not done anything with the recipe. Now we need to
    prepare the data and apply the recipe to it using the `prep` command:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们还没有对这个配方做任何操作。现在我们需要准备数据，并使用`prep`命令将配方应用到数据上：
- en: '[PRE31]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now we can apply the recipe to any dataset we have. We will start with our
    training set and also put in a command to exclude the deletion indicator:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将这个配方应用到任何我们有的数据集上。我们将从我们的训练集开始，并在命令中排除删除指示器：
- en: '[PRE32]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Preparing Data for the Neural Network
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为神经网络准备数据
- en: Now that we are done with our recipe, we need to prepare the data for the neural
    network.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们完成了我们的配方，需要为神经网络准备数据。
- en: Tip
  id: totrans-245
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Our favorite (and commonly excepted best) technique is to *not* jump directly
    into a neural network model. It is best to grow from least to most complex models,
    set a performance bar, and then try to beat it with ever more increasingly complex
    models. For instance, we should first try a simple linear regression. Because
    we are trying to classify approved and not-approved purchase requisitions we may
    then try classification machine learning techniques such as a [support vector
    machine](http://bit.ly/2Zzy7FX) (SVM) and/or a [random forest](http://bit.ly/2ZDrK4u).
    Finally, we may come to a neural network. However, for teaching purposes we will
    go directly to the neural network. There was no a priori knowledge that led to
    this decision; it is just a teaching example.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最喜欢（并且通常被接受为最好的）的技术是*不*直接跳入神经网络模型。最好是从最简单的模型逐步增长到最复杂的模型，设定一个性能标准，然后尝试用越来越复杂的模型超越它。例如，我们应该首先尝试简单的线性回归。因为我们试图分类批准和未批准的采购申请，我们之后可以尝试分类机器学习技术，如支持向量机（SVM）和/或随机森林。最后，我们可能会使用神经网络。然而，出于教学目的，我们将直接使用神经网络。没有先验知识导致了这个决定；这只是一个教学示例。
- en: 'First we want to create a vector of the deletion values:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们要创建一个删除值的向量：
- en: '[PRE33]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'If this is your first time using TensorFlow and Keras you will need to install
    it. It is a little different than regular libraries so we’ll cover the steps here.
    First you install the package like you would any other package using the following
    command:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是你第一次使用 TensorFlow 和 Keras，你需要安装它。这与常规库有些不同，所以我们在这里介绍一下步骤。首先，像安装任何其他包一样安装包：
- en: '[PRE34]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Then, to use TensorFlow you need an additional function call after the library
    declaration:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，要使用 TensorFlow，你需要在库声明之后进行额外的函数调用：
- en: '[PRE35]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, it is good process to check and make sure it is working with the common
    print hello lines below. If you get the “Hello, TensorFlow!"” statement, it’s
    working:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，很好的流程是使用以下常见的打印语句检查它是否工作。如果你得到了“Hello, TensorFlow!” 的语句，那么它正在工作：
- en: '[PRE36]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Keras installs like any other R library. Let’s create our model in Keras. The
    first step is to initialize the model, which we will do using the `keras_model_sequential()`
    function:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 安装与其他 R 库类似。让我们在 Keras 中创建我们的模型。第一步是初始化模型，我们将使用 `keras_model_sequential()`
    函数进行初始化：
- en: '[PRE37]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Models consist of layers. The next step is to create those layers.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 模型由多层组成。接下来的步骤是创建这些层。
- en: Our first layer is an input layer. Input layers require the shape of the input.
    Subsequent layers infer the shape from the first input layer. In our case this
    is simple, the input shape is the number of columns in our training set *ncol(x_trn)*.
    We will set the number of units to 18\. There are two key decisions to play with
    while testing your neural network. These are the number of units per layer and
    the number of layers.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一层是一个输入层。输入层需要输入的形状。随后的层根据第一个输入层推断形状。在我们的情况下，这很简单，输入形状是我们训练集中列的数量 *ncol(x_trn)*。我们将单元数设置为
    18。在测试神经网络时有两个关键决策要考虑。这些是每层单元的数量和层数。
- en: Our next layer is a hidden layer with the same number of inputs. Notice that
    it is the same as the previous layer but we did not have to specify the shape.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一层是一个隐藏层，具有相同数量的输入。请注意，它与前一层相同，但我们无需指定形状。
- en: Our third layer is a dropout layer set to 10%. That is, randomly 10% of the
    neurons in this layer will be *dropped*.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第三层是一个 10% 的 Dropout 层。也就是说，该层的神经元中将随机地失活 10%。
- en: Tip
  id: totrans-261
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Dropout layers control overfitting, which is when a model in a sense has memorized
    the training data. When this happens, the model does not do well on data it has
    not seen...kind of defeating the purpose of a neural network. Dropout is used
    during the training phase and essentially randomly drops out a set of neurons.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout 层控制过拟合，当模型在某种程度上记住了训练数据时发生。当这种情况发生时，模型在未见过的数据上表现不佳……这有点违背了神经网络的目的。Dropout
    在训练阶段使用，随机地使一组神经元失活。
- en: Our final layer is the output layer. The number of units is 1 because the result
    is mutually exclusive. That is, either the purchase requisition is approved or
    it is not.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最后一层是输出层。单元数为 1，因为结果是互斥的。也就是说，要么采购申请被批准，要么没有。
- en: 'Finally, we will compile the model or *build* it. We need to set three basic
    compilation settings:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将编译模型或 *构建* 它。我们需要设置三个基本的编译设置：
- en: Optimizer
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 优化器
- en: The technique by which the weights of the model are adjusted. A very common
    starting point is the `Adam` optimizer.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 调整模型权重的技术。一个非常常见的起点是`Adam`优化器。
- en: Initializer
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化器
- en: The way that the model sets the [initial random weights of the layers](https://keras.io/initializers/).
    There are many options; a common starting point is `uniform`.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 模型设置层的[初始随机权重的方式](https://keras.io/initializers/)。有许多选项；一个常见的起点是`uniform`。
- en: Activation
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 激活
- en: Refer to [Chapter 2](ch02.html#ch02) for a description of activation functions.
    Keras has a number of easily available [activation functions](https://keras.io/activations/).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 参考[第二章](ch02.html#ch02)了解激活函数的描述。Keras提供了许多易于使用的[激活函数](https://keras.io/activations/)。
- en: '[PRE38]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Tip
  id: totrans-272
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Setting the parameters of your neural network is as much an art as it is a science.
    Play with the number of neurons in the layers, the dropout rate, the loss optimizer,
    and others. This is where you experiment and tune your network to get more accuracy
    and lower loss.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 设置神经网络的参数既是艺术也是科学。调整层中神经元的数量、丢失率、损失优化器等。这是您实验和调整网络以获得更高准确度和更低损失的地方。
- en: 'To take a look at the model, type `**k_model**`:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看模型，请键入`**k_model**`：
- en: '[PRE39]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The final step is to fit the model to the data. We use the data that we *baked*
    with the recipe, which is the `x_trn`:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是将模型拟合到数据上。我们使用了用配方“烘焙”的数据，即`x_trn`：
- en: '[PRE40]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The model displays a log while it is running:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在运行时显示日志：
- en: '[PRE41]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Results
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: What we want from our model is for the accuracy to be high and for it to improve
    over the number of epochs. However, this is not what we see. Note the second graph
    in [Figure 4-35](#accuracy_and_loss_results_from_the_model). We see that the accuracy
    is very high from the start and never improves. The loss function also does not
    decrease but stays relatively steady.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望从我们的模型中得到的是高准确率，并随着时代的推移得到改进。然而，这并不是我们看到的。请注意图中的第二张图表[图4-35](#accuracy_and_loss_results_from_the_model)。我们看到准确率从一开始就非常高，并且从未改善。损失函数也没有减少，而是保持相对稳定。
- en: This tells us that the model did not learn anything. Or rather, it learned something
    quickly that made it very accurate and quit learning from that point. We can try
    a number of tuning options, perhaps different optimizers and loss functions. We
    can also remodel the neural network to have more or less layers. However, let’s
    think at a higher level for a minute and turn back to the raw data with some questions.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们模型没有学到任何东西。或者更确切地说，它很快学到了一些东西，使其非常准确，并从那时起停止学习。我们可以尝试许多调整选项，也许不同的优化器和损失函数。我们还可以重新设计神经网络，增加或减少层数。但是，让我们高层次地思考一分钟，回到原始数据，并提出一些问题。
- en: Did we select the right features from SAP from the beginning? Are there any
    other features that might be helpful?
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否从一开始就选择了正确的SAP特征？还有其他可能有帮助的特征吗？
- en: '![Accuracy and loss results from the model learning](assets/pdss_0435.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![模型学习的准确性和损失结果](assets/pdss_0435.png)'
- en: Figure 4-35\. Accuracy and loss results from the model learning
  id: totrans-285
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4-35\. 模型学习的准确性和损失结果
- en: Did we make mistakes along the way or did we make assumptions that were incorrect?
    This requires a review of the process.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在途中是否犯过错误或者做出了错误的假设？这需要对整个过程进行回顾。
- en: Is this data that can be modeled? Not all data is model ready.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据可以被建模吗？并非所有数据都适合建模。
- en: After going through these questions we stumble upon this. What if the number
    of approved purchase requisitions is overwhelming? What if the model just learned
    to say “Yes” to everything because during training it was nearly always the right
    answer? If we go back and look at the numbers before any modeling, we see that
    Pat approves over 99% of all purchase requisitions. We can try different models
    and different features in our data, but the likely truth to this data exploration
    saga is that this data cannot be modeled. Or rather it can be modeled, but because
    of the high number of approvals the model will learn only to approve. It will
    find it has great accuracy and low loss and therefore on the surface it is a good
    model.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在回答这些问题之后，我们偶然发现了这一点。如果批准的采购申请数量过多怎么办？如果模型只学会了一直回答“是”，因为在训练过程中几乎总是正确的答案呢？如果我们回过头来看一下建模之前的数字，我们会发现帕特批准了超过99%的所有采购申请。我们可以尝试不同的模型和数据中的不同特征，但是数据探索传奇的真相很可能是这些数据不能被建模。或者更确切地说，它可以被建模，但是由于批准数量过多，模型只会学会批准。它将发现自己有很高的准确性和低损失，因此表面上看是一个很好的模型。
- en: Summary
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Despite the failure to model the purchase requisition data, this example teaches
    a lot of good lessons. Sometimes data can’t be modeled, it just happens...and
    it happens a lot. A model that has high accuracy and low loss doesn’t mean it
    is a good model. Our model had 99% accuracy, which should raise a suspicious eyebrow
    from the start. But it was a worthless model; it didn’t learn. A common role of
    a data scientist is to report on findings and to propose next steps. We failed,
    but we failed fast and can move past it toward the right solution.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们未能对采购申请数据进行建模，但这个例子教会了我们许多宝贵的经验。有时候数据无法被建模，它就是这样发生的……而且经常发生。一个准确率高、损失低的模型并不意味着它是一个好模型。我们的模型准确率达到了99%，这从一开始就应该引起怀疑。但它是一个毫无价值的模型；它没有学到任何东西。数据科学家通常的角色是报告发现并提出下一步的建议。我们失败了，但我们快速失败并能够朝着正确的解决方案迈进。
- en: It could be argued that Greg and Paul failed Pat. After all, we can’t make any
    good predictions based on the data we found and explored. But just because we
    didn’t find a way to predictively model the scenario doesn’t mean we failed. We
    learned! If data science is *truly* science, it must admit negative results as
    well as positive. We didn’t learn to predict purchase requisition behavior, but
    we did learn that trying to do so wouldn’t be cost effective. We learned that
    Pat and his colleagues have created solid processes that make the business very
    disciplined in its purchasing behavior.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，格雷格和保罗辜负了帕特。毕竟，我们无法根据我们找到和探索的数据做出任何良好的预测。但仅仅因为我们没有找到预测建模方案的方法，并不意味着我们失败了。我们学到了！如果数据科学真的是科学，它必须承认负面结果和正面结果一样。我们没有学会预测采购申请行为，但我们确实了解到尝试这样做不具成本效益。我们了解到帕特和他的同事们创建了一套使企业在采购行为上非常有纪律性的稳健流程。
- en: In exploratory data analysis, the only failure is failing to learn. The model
    may not have learned, but the data scientists did. Greg and Paul congratulate
    themselves with an extra trip to the coffee machine.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索性数据分析中，唯一的失败是没有学到东西。模型可能没有学到东西，但数据科学家们学到了。格雷格和保罗为此多做了一次去咖啡机的旅行来庆祝。
- en: In this chapter we have identified a business need, extracted the necessary
    data from SAP, cleansed the data, explored the data, modeled the data, and drawn
    conclusions from the results. We discovered that we could not get our model to
    learn with the current data and surmised this was because the data is highly skewed
    in favor of approvals. At this point, we are making educated guesses; we could
    do more.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们确定了一个业务需求，从SAP中提取了必要的数据，清理了数据，探索了数据，建模了数据，并从结果中得出结论。我们发现我们无法让我们的模型学习当前的数据，并推测这是因为数据明显偏向批准。在这一点上，我们正在做出合理的猜测；我们可以做得更多。
- en: There are other approaches we could take. For instance, we could augment the
    data using encoders, which would be beyond the scope of this book. We could weight
    the variables such that the rejected purchase requisitions have greater value
    than the accepted ones. In testing this approach, however, the model simply loses
    all accuracy and fails for an entirely different reason. We could also treat the
    purchase requisitions that are rejected as anomalies and use a completely different
    approach. In [Chapter 5](ch05.html#anomaly_detection_with_r_and_python), we will
    dig into anomaly detection, which might provide other answers if applied to this
    data.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以采取其他方法。例如，我们可以使用编码器来增强数据，这超出了本书的范围。我们可以对变量进行加权，使被拒绝的采购申请比被接受的具有更大的价值。然而，在测试这种方法时，模型简单地失去了所有的准确性，因为完全不同的原因失败了。我们还可以将被拒绝的采购申请视为异常，并采用完全不同的方法。在[第五章](ch05.html#anomaly_detection_with_r_and_python)中，我们将深入研究异常检测，这可能为应用于这些数据提供其他答案。
- en: We have decided that the final course of action to be taken in our example is
    not a data approach (much to our chagrin). The business should be informed that
    because over 99% of all purchase requisitions are approved, the model could not
    find salient features to determine when a rejection would occur. Without significantly
    more work, this is likely a dead end. Perhaps there are different IT solutions,
    such as a phone app that could help Pat do his job more efficiently. The likely
    solution, however, cannot be found through machine learning and data science.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们决定在我们的示例中采取的最终行动方案并不是一个数据方法（这让我们感到遗憾）。应该告知业务，因为超过99%的所有采购申请都得到批准，模型无法找到显著特征来确定何时会发生拒绝。如果不做大量的工作，这可能是个死胡同。也许有不同的IT解决方案，比如一个手机应用程序可以帮助帕特更有效地完成工作。然而，这种解决方案很可能无法通过机器学习和数据科学找到。
- en: ^([1](ch04.html#ch04fn2-marker)) For instructions on how to install R Studio
    and R, go to [*https://www.rstudio.com/products/rstudio/download/*](https://www.rstudio.com/products/rstudio/download/).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch04.html#ch04fn2-marker)) 安装R Studio和R的说明，请访问[*https://www.rstudio.com/products/rstudio/download/*](https://www.rstudio.com/products/rstudio/download/)。
- en: '^([2](ch04.html#ch04fn4-marker)) We have referenced this before, but we’ll
    link to it again (it is that good): [*https://vita.had.co.nz/papers/tidy-data.pdf*](https://vita.had.co.nz/papers/tidy-data.pdf).'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch04.html#ch04fn4-marker)) 我们以前提到过这个链接，但我们会再次链接（因为它非常好）：[*https://vita.had.co.nz/papers/tidy-data.pdf*](https://vita.had.co.nz/papers/tidy-data.pdf)。
- en: ^([3](ch04.html#ch04fn6-marker)) Dive deep into DataExplorer using the vignette
    available at [*https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html*](https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch04.html#ch04fn6-marker)) 深入了解DataExplorer，可参考[*https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html*](https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html)提供的详细介绍。
- en: ^([4](ch04.html#ch04fn7-marker)) Remember from [Chapter 2](ch02.html#ch02) that
    discrete or categorical features are features with definable boundaries. Think
    *categories* such as colors or types of dogs.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch04.html#ch04fn7-marker)) 请记住，在[第二章](ch02.html#ch02)中提到，离散或分类特征是具有明确定义边界的特征。例如*颜色*或狗的种类。
- en: ^([5](ch04.html#ch04fn10-marker)) Sometimes called creating “dummy variables.”
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch04.html#ch04fn10-marker)) 有时也称为创建“虚拟变量”。
