- en: 16 Filtering a time series with CNN
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 16 使用 CNN 过滤时间序列
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Examining the CNN architecture
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查卷积神经网络（CNN）架构
- en: Implementing a CNN with Keras
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Keras 实现CNN
- en: Combining a CNN with an LSTM
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合 CNN 和 LSTM
- en: In the last chapter, we examined and implemented a long short-term memory (LSTM)
    network, which is a type of recurrent neural network (RNN) that processes sequences
    of data especially well. Its implementation was the top performing architecture
    for the single-step model, multi-step model, and multi-output model.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们检查并实现了一个长短期记忆（LSTM）网络，这是一种处理数据序列特别好的循环神经网络（RNN）。它的实现是单步模型、多步模型和多输出模型中表现最好的架构。
- en: Now we’re going to explore the *convolutional neural network* (CNN). CNNs are
    mostly applied in the field of computer vision, and this architecture is behind
    many algorithms for image classification and image segmentation.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将探索 *卷积神经网络* (CNN)。CNN 主要应用于计算机视觉领域，这种架构是许多图像分类和图像分割算法背后的基础。
- en: Of course, this architecture can also be used for time series analysis. It turns
    out that CNNs are noise resistant and can effectively filter out the noise in
    a time series with the *convolution* operation. This allows the network to produce
    a set of robust features that do not include abnormal values. In addition, CNNs
    are usually faster to train than LSTMs, as their operations can be parallelized.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这种架构也可以用于时间序列分析。结果证明，CNN 具有抗噪声能力，可以通过 *卷积* 操作有效地过滤时间序列中的噪声。这使得网络能够生成一组稳健的特征，不包含异常值。此外，CNN
    通常比 LSTM 训练得更快，因为它们的操作可以并行化。
- en: In this chapter, we’ll first explore the CNN architecture and understand how
    the network filters a time series and creates a unique set of features. Then we’ll
    implement a CNN using Keras to produce forecasts. We’ll also combine the CNN architecture
    with the LSTM architecture to see if we can further improve the performance of
    our deep learning models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先探索 CNN 架构，了解网络如何过滤时间序列并创建一组独特的特征。然后我们将使用 Keras 实现一个 CNN 来生成预测。我们还将结合
    CNN 架构和 LSTM 架构，看看我们是否可以进一步提高我们深度学习模型的表现。
- en: 16.1 Examining the convolutional neural network (CNN)
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.1 检查卷积神经网络（CNN）
- en: A convolutional neural network is a deep learning architecture that makes use
    of the convolution operation. The convolution operation allows the network to
    create a reduced set of features. Therefore, it is a way of regularizing the network,
    preventing overfitting, and effectively filtering the inputs. Of course, for this
    to make sense, you must first understand the convolution operation and how it
    impacts the inputs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络是一种利用卷积操作的深度学习架构。卷积操作允许网络创建一组减少的特征。因此，这是一种正则化网络、防止过拟合和有效过滤输入的方法。当然，为了使这有意义，你必须首先了解卷积操作及其对输入的影响。
- en: In mathematical terms, a convolution is an operation on two functions that generates
    a third function that expresses how the shape of one function is changed by the
    other. In a CNN, this operation occurs between the inputs and a *kernel* (also
    known as a *filter*). The kernel is simply a matrix that is placed on top of the
    feature matrix. In figure 16.1, the kernel is slid along the time axis, taking
    the dot product between the kernel and the features. This results in a reduced
    set of features, achieving regularization and the filtering of abnormal values.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学的角度来看，卷积是两个函数之间的操作，它生成一个第三函数，该函数表达了其中一个函数的形状如何被另一个函数改变。在 CNN 中，这种操作发生在输入和一个
    *核*（也称为 *滤波器*）之间。核只是一个放置在特征矩阵上的矩阵。在图 16.1 中，核沿着时间轴滑动，计算核与特征之间的点积。这导致特征集的减少，实现了正则化和异常值的过滤。
- en: '![](../../OEBPS/Images/16-01.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/16-01.png)'
- en: Figure 16.1 Visualizing the kernel and the feature map. The kernel is the light
    gray matrix that is applied on top of the feature map. Each row corresponds to
    a feature of the dataset, while the length is the time axis.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16.1 展示核和特征图。核是应用在特征图上的浅灰色矩阵。每一行对应于数据集的一个特征，而长度是时间轴。
- en: To better understand the convolution operation, let’s consider a simple example
    with only one feature and one kernel, as shown in figure 16.2\. To make things
    simple, we’ll consider only one row of features. Keep in mind that the horizontal
    axis remains the time dimension. The kernel is a smaller vector that is used to
    perform the convolution operation. Do not worry about the values used inside the
    kernel and the feature vector. They are arbitrary values. The values of the kernel
    are optimized and will change as the network is trained.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解卷积操作，让我们考虑一个只有一个特征和一个核的简单示例，如图16.2所示。为了简化问题，我们只考虑一个特征行。记住，水平轴仍然是时间维度。核是一个较小的向量，用于执行卷积操作。不用担心核和特征向量内部使用的值。它们是任意值。核的值是经过优化的，并且随着网络的训练而改变。
- en: '![](../../OEBPS/Images/16-02.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/16-02.png)'
- en: Figure 16.2 A simple example of one row of features and one kernel.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.2 一个特征行和一个核的简单示例。
- en: We can visualize the convolution operation and its result in figure 16.3\. At
    first, the kernel is aligned with the beginning of the feature vector and the
    dot product is taken between the kernel and the values of the feature vector that
    are aligned with it. Once this is done, the kernel shifts one timestep to the
    right—this is also called a *stride* of one timestep. The dot product is again
    taken between the kernel and the feature vector, again only with the values that
    are aligned with the kernel. The kernel again shifts one timestep to the right,
    and the process is repeated until the kernel reaches the end of the feature vector.
    This happens when the kernel cannot be shifted any further with all of its values
    having an aligned feature value.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在图16.3中可视化卷积操作及其结果。起初，核与特征向量的开始对齐，并与与之对齐的特征向量值进行点积。一旦完成，核向右移动一个时间步长——这也可以称为一个时间步长的*步长*。然后再次在核和特征向量之间进行点积，这次只与核对齐的值。核再次向右移动一个时间步长，这个过程重复进行，直到核到达特征向量的末尾。当核无法再进一步移动，且所有值都与其对齐的特征值对齐时，这种情况发生。
- en: '![](../../OEBPS/Images/16-03.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/16-03.png)'
- en: Figure 16.3 The full convolution operation. The operation starts with the kernel
    aligned at the beginning of the feature vector in step 1\. The dot product is
    computed as shown by the intermediary equation of step 1, resulting in the first
    value in our output vector. In step 2, the kernel shifts one timestep to the right,
    and the dot product is taken again, resulting in the second value in the output
    vector. The process is repeated two more times until the kernel reaches the end
    of the feature vector.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.3 完整的卷积操作。操作从第1步中核与特征向量开始对齐开始。第1步的计算如中间方程所示，得到输出向量的第一个值。在第2步中，核向右移动一个时间步长，再次进行点积，得到输出向量的第二个值。这个过程重复两次，直到核到达特征向量的末尾。
- en: In figure 16.3 you can see that using a feature vector of length 6 and a kernel
    of length 3, we obtain an output vector of length 4\. Thus, in general, the length
    of the output vector of a convolution is given by equation 16.1.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在图16.3中，你可以看到使用长度为6的特征向量和长度为3的核，我们得到一个长度为4的输出向量。因此，一般来说，卷积的输出向量长度由方程16.1给出。
- en: output length = input length – kernel length + 1
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 输出长度 = 输入长度 - 核长度 + 1
- en: Equation 16.1
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 方程16.1
- en: Note that since the kernel is moving only in one direction (to the right), this
    is a *1D convolution*. Luckily, Keras comes with the `Conv1D` layer, allowing
    us to easily implement it in Python. This is mostly used for time series forecasting,
    as the kernel can only move in the time dimension. For image processing, you’ll
    often see 2D or 3D convolutions, but that is outside of the scope of this book.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于核只在一个方向上移动（向右），这是一个*1D卷积*。幸运的是，Keras自带`Conv1D`层，允许我们轻松地在Python中实现它。这主要用于时间序列预测，因为核只能在时间维度上移动。对于图像处理，你经常会看到2D或3D卷积，但这超出了本书的范围。
- en: A convolution layer reduces the length of the set of features, and performing
    many convolutions will keep reducing the feature space. This can be problematic,
    as it limits the number of layers in the network, and we might lose too much information
    in the process. A common technique to prevent that is *padding*. Padding simply
    means adding values before and after the feature vector to keep the output length
    equivalent to the input length. Padding values are often zeros. You can see this
    in action in figure 16.4, where the output of the convolution is the same length
    as the input.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层减少了特征集的长度，进行多次卷积将不断减少特征空间。这可能会成为问题，因为它限制了网络中的层数，我们可能在过程中丢失太多信息。防止这种情况的常见技术是*填充*。填充简单地说就是在特征向量前后添加值，以保持输出长度与输入长度相同。填充值通常是零。你可以在图16.4中看到这一点，其中卷积的输出长度与输入相同。
- en: '![](../../OEBPS/Images/16-04.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/16-04.png)'
- en: Figure 16.4 Convolution with padding. Here we padded the original input vector
    with zeros, as shown by the black squares. The output of the convolution thus
    has a length of 6, just like the original feature vector.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.4 带填充的卷积。在这里，我们用黑色方块将原始输入向量填充为零。因此，卷积的输出长度为6，与原始特征向量相同。
- en: You can thus see how padding keeps the dimension of the output constant, allowing
    us to stack more convolution layers, and allowing the network to process features
    for a longer time. We use zeroes for padding because a multiplication by 0 is
    ignored. Thus, using zeroes as padding values is usually a good initial option.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以看到填充是如何保持输出维度恒定的，这使我们能够堆叠更多的卷积层，并允许网络处理更长时间的特征。我们使用零进行填充，因为乘以零会被忽略。因此，通常使用零作为填充值是一个很好的初始选项。
- en: Convolutional neural network (CNN)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）
- en: A convolutional neural network (CNN) is a deep learning architecture that uses
    the convolution operation. This allows the network to reduce the feature space,
    effectively filtering the inputs and preventing overfitting.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）是一种深度学习架构，它使用卷积操作。这使得网络能够减少特征空间，有效地过滤输入并防止过拟合。
- en: The convolution is performed with a kernel, which is also trained during model
    fitting. The stride of the kernel determines the number of steps it shifts at
    each step of the convolution. In time series forecasting, only 1D convolution
    is used.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积是通过内核进行的，内核在模型拟合期间也会被训练。内核的步长决定了它在卷积的每一步中移动的步数。在时间序列预测中，仅使用1D卷积。
- en: To avoid reducing the feature space too quickly, we can use padding, which adds
    zeros before and after the input vector. This keeps the output dimension the same
    as the original feature vector, allowing us to stack more convolution layers,
    which in turn allows the network to process the features for a longer time.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免过快地减少特征空间，我们可以使用填充，即在输入向量前后添加零。这保持了输出维度与原始特征向量相同，使我们能够堆叠更多的卷积层，这反过来又允许网络处理更长时间的特征。
- en: Now that you understand the inner working of a CNN, we can implement it with
    Keras and see if a CNN can produce more accurate predictions than the models we
    have built so far.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了卷积神经网络（CNN）的内部工作原理，我们可以使用Keras来实现它，看看CNN能否比我们迄今为止构建的模型产生更准确的预测。
- en: 16.2 Implementing a CNN
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.2 实现CNN
- en: As in previous chapters, we’ll implement the CNN architecture as a single-step
    model, a multi-step model, and a multi-output model. The single-step model will
    predict the traffic volume for the next timestep only, the multi-step model will
    predict the traffic volume for the next 24 hours, and the multi-output model will
    predict the temperature and traffic volume at the next timestep.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 与前几章一样，我们将实现CNN架构作为单步模型、多步模型和多输出模型。单步模型将仅预测下一个时间步的流量，多步模型将预测未来24小时的流量，而多输出模型将预测下一个时间步的温度和流量。
- en: Make sure you have the `DataWindow` class and the `compile_and_fit` function
    (from chapters 13 to 15) in your notebook or Python script, as we’ll use both
    pieces of code to create windows of data and train the CNN model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你的笔记本或Python脚本中有`DataWindow`类和`compile_and_fit`函数（来自第13章到第15章），因为我们将使用这两段代码来创建数据窗口并训练CNN模型。
- en: 'Note The source code for this chapter is available on GitHub: [https://github.com/marcopeix/TimeSeriesForecastingInPython/tree/master/CH16](https://github.com/marcopeix/TimeSeriesForecastingInPython/tree/master/CH16).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：本章的源代码可在GitHub上找到：[https://github.com/marcopeix/TimeSeriesForecastingInPython/tree/master/CH16](https://github.com/marcopeix/TimeSeriesForecastingInPython/tree/master/CH16)。
- en: In this chapter, we’ll also combine the CNN architecture with the LSTM architecture.
    It can be interesting to see if filtering our time series with a convolution layer
    and then processing the filtered sequence with an LSTM will improve the accuracy
    of our predictions. Thus, we’ll implement both a CNN only, and the combination
    of a CNN with an LSTM.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们还将CNN架构与LSTM架构相结合。看看使用卷积层过滤我们的时间序列，然后用LSTM处理过滤后的序列是否会提高我们预测的准确性，这可能会很有趣。因此，我们将实现一个仅CNN的模型，以及一个CNN与LSTM的组合。
- en: Of course, the other prerequisite is to read the training set, the validation
    set, and the test set, so let’s do that right now.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，另一个先决条件是阅读训练集、验证集和测试集，所以让我们现在就做这件事。
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Finally, we’ll use a kernel length of three timesteps in our CNN implementation.
    This is an arbitrary value, and you will have a chance to experiment with various
    kernel lengths in this chapter’s exercises and see how they impact the model’s
    performance. However, your kernel should have a length greater than 1; otherwise,
    you are simply multiplying the feature space by a scalar, and no filtering will
    be achieved.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在CNN实现中将核长度设置为三个时间步。这是一个任意值，你将在本章的练习中有机会尝试各种核长度，并看到它们如何影响模型的表现。然而，你的核长度应该大于1；否则，你只是在特征空间上乘以一个标量，不会实现任何过滤。
- en: 16.2.1 Implementing a CNN as a single-step model
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.1 实现单步CNN模型
- en: We’ll start by implementing a CNN as a single-step model. Recall that the single-step
    model outputs a prediction for traffic volume at the next timestep using the last
    known feature.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先实现一个单步CNN模型。回想一下，单步模型使用最后一个已知特征来预测下一个时间步的交通量。
- en: 'In this case, however, it does not make sense to provide the CNN model with
    only one timestep as an input because we want to run a convolution. We will instead
    use three input values to generate a prediction for the next timestep. That way
    we’ll have a sequence of data on which we can run a convolution operation. Furthermore,
    our input sequence must have a length at least equal to the kernel’s length, which
    in our case is 3\. Recall that we expressed the relationship between the input
    length, kernel length, and output length in equation 16.1:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在这种情况下，只向CNN模型提供一个时间步作为输入是不合理的，因为我们想运行卷积。我们将使用三个输入值来生成对下一个时间步的预测。这样我们就会有一个可以运行卷积操作的数据序列。此外，我们的输入序列长度至少应该等于核的长度，在我们的例子中是3。回想一下，我们在方程16.1中表达了输入长度、核长度和输出长度之间的关系：
- en: output length = input length – kernel length + 1
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 输出长度 = 输入长度 - 核长度 + 1
- en: In this equation, no length can be equal to 0, since that would mean that no
    data is being processed or output. The condition that no length can be 0 is only
    satisfied if the input length is greater than or equal to the kernel length. Therefore,
    our input sequence must have at least three timesteps.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，没有任何长度可以等于0，因为这意味着没有数据处理或输出。只有当输入长度大于或等于核长度时，长度不能为0的条件才成立。因此，我们的输入序列必须至少有三个时间步。
- en: We can thus define the data window that will be used to train the model.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以定义用于训练模型的数据窗口。
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For plotting purposes, we would like to see the predictions of the model over
    a period of 24 hours. That way, we can evaluate the rolling forecasts of the model
    1 timestep at a time, over 24 timesteps. Thus, we need to define another data
    window with a `label_width` of 24\. The `shift` remains 1, as the model only predicts
    the next timestep. The input length is obtained by rearranging equation 16.1 as
    equation 16.2.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了绘图目的，我们希望看到模型在24小时内的预测。这样，我们可以逐个时间步评估模型的滚动预测，共24个时间步。因此，我们需要定义另一个具有`label_width`为24的数据窗口。`shift`保持为1，因为模型只预测下一个时间步。输入长度是通过将方程16.1重新排列为方程16.2来获得的。
- en: output length = input length – kernel length + 1
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 输出长度 = 输入长度 - 核长度 + 1
- en: input length = output length + kernel length – 1
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 输入长度 = 输出长度 + 核长度 - 1
- en: Equation 16.2
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 方程16.2
- en: We can now simply compute the required input length to generate predictions
    over a sequence of 24 timesteps. In this case, the input length is 24 + 3– 1 =
    26. That way, we avoid using padding. Later, in the exercises, you’ll be able
    to try using padding instead of a longer input sequence to accommodate the output
    length.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以简单地计算生成24个时间步序列预测所需的输入长度。在这种情况下，输入长度是24 + 3 - 1 = 26。这样，我们就可以避免使用填充。稍后，在练习中，你将能够尝试使用填充而不是更长的输入序列来适应输出长度。
- en: We can now define our data window for plotting the predictions of the model.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以定义我们的数据窗口，以便绘制模型的预测。
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ From equation 16.2
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 来自方程16.2
- en: With all the data windows ready, we can define our CNN model. Again, we’ll use
    the `Sequential` model from Keras to stack different layers. Then we’ll use the
    `Conv1D` layer, as we are working with time series, and the kernel only moves
    in the temporal dimension. The `filters` parameter is equivalent to the `units`
    parameter of the `Dense` layer, and it simply represents the number of neurons
    in the convolutional layer. We’ll set the `kernel_size` to the width of our kernel,
    which is 3\. We don’t need to specify the other dimensions, as Keras will automatically
    take the right shape to accommodate the inputs. Then we’ll pass the output of
    the CNN to a `Dense` layer. That way, the model will be learning on a reduced
    set of features that were previously filtered by the convolutional step. We’ll
    finally output a prediction with a `Dense` layer of only one unit, as we are forecasting
    only the traffic volume for the next timestep.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有数据窗口准备就绪后，我们可以定义我们的CNN模型。同样，我们将使用Keras的`Sequential`模型来堆叠不同的层。然后我们将使用`Conv1D`层，因为我们正在处理时间序列，核只移动在时间维度上。`filters`参数等同于`Dense`层的`units`参数，它简单地表示卷积层中的神经元数量。我们将`kernel_size`设置为核的宽度，即3。我们不需要指定其他维度，因为Keras会自动取正确的形状以适应输入。然后我们将CNN的输出传递到一个`Dense`层。这样，模型将在之前由卷积步骤过滤的减少特征集上学习。我们最终将使用只有一个单位的`Dense`层输出预测，因为我们只预测下一个时间步的交通量。
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ The filters parameter is equivalent to the units parameter of the Dense layer;
    it defines the number of neurons in the convolutional layer.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 过滤器参数等同于密集层的`units`参数；它定义了卷积层的神经元数量。
- en: ❷ The width of the kernel is specified, but the other dimensions are left out,
    as Keras automatically adapts to the shape of the inputs.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 核宽被指定，但其他维度被省略，因为Keras会自动适应输入的形状。
- en: Next, we’ll compile and fit the model, and we’ll store its performance metrics
    for comparison later.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将编译和拟合模型，并将存储其性能指标以供后续比较。
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We can visualize the predictions against the labels using the `plot` method
    of our data window. The result is shown in figure 16.5.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用数据窗口的`plot`方法可视化预测与标签。结果如图16.5所示。
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](../../OEBPS/Images/16-05.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/16-05.png)'
- en: Figure 16.5 Predicting traffic volume with a CNN as a single-step model. The
    model takes three values as an input, which is why we only see a prediction at
    the fourth timestep. Again, many predictions (shown as crosses) overlap labels
    (shown as squares), meaning that the model is fairly accurate.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.5 使用CNN作为单步模型预测交通量。该模型以三个值作为输入，这就是为什么我们只在第四个时间步看到预测。同样，许多预测（以十字表示）与标签（以正方形表示）重叠，这意味着模型相当准确。
- en: As you can see in figure 16.5, many predictions overlap labels, meaning that
    we have fairly accurate predictions. Of course, we must compare this model’s performance
    metrics to those of the other models to properly assess its performance.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在图16.5中看到的，许多预测与标签重叠，这意味着我们的预测相当准确。当然，我们必须将这个模型的性能指标与其他模型的性能指标进行比较，以正确评估其性能。
- en: Before doing that, let’s combine the CNN and LSTM architectures into a single
    model. You saw in the previous chapter how the LSTM architecture resulted in the
    best-performing models so far. Thus, it is a reasonable hypothesis that filtering
    our input sequence before feeding it to an LSTM might improve the performance.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在做那之前，让我们将CNN和LSTM架构组合成一个单一模型。您在前一章中看到LSTM架构产生了迄今为止性能最好的模型。因此，一个合理的假设是在将输入序列馈送到LSTM之前过滤它可能会提高性能。
- en: Thus, we’ll follow the `Conv1D` layer with two LSTM layers. This is an arbitrary
    choice, so make sure you experiment with it later on. There is rarely only one
    good way of building models, so it is important to showcase what is possible.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将使用两个LSTM层来跟随`Conv1D`层。这是一个任意的选择，所以请确保您稍后进行实验。构建模型很少只有一种好的方法，因此展示可能的方法是很重要的。
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We’ll then fit the model and store its evaluation metrics.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将拟合模型并存储其评估指标。
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With both models built and evaluated, we can look at the MAE of our newly built
    models in figure 16.6\. As you can see, the CNN model did not perform any better
    than the LSTM, and the combination of CNN and LSTM resulted in a slightly higher
    MAE than the CNN alone.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建并评估了两个模型之后，我们可以查看图16.6中我们新构建模型的MAE。如图所示，CNN模型并没有比LSTM模型表现得更好，而且CNN和LSTM的组合比单独的CNN产生了略高的MAE。
- en: '![](../../OEBPS/Images/16-06.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图16.6](../../OEBPS/Images/16-06.png)'
- en: Figure 16.6 The MAE of all the single-step models built so far. You can see
    that the CNN did not improve upon the LSTM performance. Combining the CNN with
    an LSTM did not help either, and the combination even performed slightly worse
    than the CNN.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.6 到目前为止构建的所有单步模型的平均绝对误差（MAE）。你可以看到，CNN并没有在LSTM的性能上有所提升。将CNN与LSTM结合使用也没有帮助，而且这种组合的性能甚至略低于CNN。
- en: These results might be explained by the length of the input sequence. The model
    is given only an input sequence of three values, which might not be sufficient
    for the CNN to extract valuable features for predictions. While a CNN is better
    than the baseline model and the linear model, the LSTM remains the best-performing
    single-step model for now.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果可能可以由输入序列的长度来解释。模型只得到了三个值的输入序列，这可能不足以让CNN提取对预测有价值的特征。虽然CNN比基线模型和线性模型更好，但LSTM仍然是目前表现最好的单步模型。
- en: 16.2.2 Implementing a CNN as a multi-step model
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.2 将卷积神经网络（CNN）实现为多步模型
- en: We’ll now move on to the multi-step model. Here we’ll use the last known 24
    hours to forecast the traffic volume over the next 24 hours.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将继续进行多步模型的讨论。在这里，我们将使用最后已知的24小时来预测接下来的24小时的交通量。
- en: Again, keep in mind that the convolution reduces the length of the features,
    but we still expect the model to generate 24 predictions in a single shot. Therefore,
    we’ll reuse equation 16.2 and feed the model an input sequence with a length of
    26 to make sure that we get an output of length 24\. This, of course, means that
    we’ll keep the kernel length of 3\. We can thus define our data window for the
    multi-step model.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，卷积操作会减少特征长度，但我们仍然期望模型能够一次性生成24个预测。因此，我们将重用方程16.2，并给模型提供一个长度为26的输入序列，以确保我们得到长度为24的输出。这当然意味着我们将保持核长度为3。因此，我们可以为多步模型定义我们的数据窗口。
- en: '[PRE8]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Next, we’ll define the CNN model. Again, we’ll use the `Sequential` model, in
    which we’ll stack the `Conv1D` layer, followed by a `Dense` layer with 32 neurons,
    and then a `Dense` layer with one unit, since we are predicting only traffic volume.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将定义CNN模型。同样，我们将使用`Sequential`模型，其中我们将堆叠`Conv1D`层，然后是一个具有32个神经元的`Dense`层，接着是一个只有一个单位的`Dense`层，因为我们只预测交通量。
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We can then train the model and store its performance metrics for comparison
    later.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以训练模型并存储其性能指标以供后续比较。
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Optionally, we can visualize the forecasts of the model using `multi_window
    .plot(ms_cnn_model)`. For now, let’s skip this and combine the CNN architecture
    with the LSTM architecture as previously. Here we’ll simply replace the intermediate
    `Dense` layer with an `LSTM` layer. Once the model is defined, we can fit it and
    store its performance metrics.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，我们可以使用`multi_window .plot(ms_cnn_model)`可视化模型的预测结果。目前，让我们跳过这一步，并将CNN架构与LSTM架构结合，如之前所述。在这里，我们将简单地用`LSTM`层替换中间的`Dense`层。一旦模型定义完成，我们就可以对其进行拟合并存储其性能指标。
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: With the two new models trained, we can evaluate their performance against all
    the multi-step models built so far. As you can see in figure 16.7, the CNN model
    did not improve upon the LSTM model. However, combining both models resulted in
    the lowest MAE of all the multi-step models, meaning that it generates the most
    accurate predictions. The LSTM model is thus dethroned, and we have a new winning
    model.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练并评估了两个新模型之后，我们可以评估它们与迄今为止构建的所有多步模型的性能。如图16.7所示，CNN模型并没有在LSTM模型上有所改进。然而，将两个模型结合起来，结果产生了所有多步模型中最低的MAE，这意味着它产生了最准确的预测。因此，LSTM模型被取代，我们有一个新的获胜模型。
- en: '![](../../OEBPS/Images/16-07.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![图16.7](../../OEBPS/Images/16-07.png)'
- en: Figure 16.7 The MAE of all multi-step models built so far. The CNN model is
    worse than the LSTM model, since it has a higher MAE. However, combining the CNN
    with an LSTM resulted in the lowest MAE of all.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.7 到目前为止构建的所有多步模型的平均绝对误差（MAE）。由于CNN模型的MAE更高，因此其性能不如LSTM模型。然而，将CNN与LSTM结合使用，结果产生了所有模型中最低的MAE。
- en: 16.2.3 Implementing a CNN as a multi-output model
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 16.2.3 将卷积神经网络（CNN）实现为多输出模型
- en: Finally, we’ll implement the CNN architecture as a multi-output model. In this
    case, we wish to forecast the temperature and traffic volume for the next timestep
    only.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将实现CNN架构作为多输出模型。在这种情况下，我们希望仅预测下一个时间步的温度和交通量。
- en: We have seen that giving an input sequence of length 3 was not sufficient for
    the CNN model to extract meaningful features, so we will use the same input length
    as for the multi-step model. This time, however, we are forecasting one timestep
    at a time over 24 timesteps.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，长度为3的输入序列对于CNN模型提取有意义特征是不够的，因此我们将使用与多步模型相同的输入长度。然而，这次我们将在24个时间步中逐个时间步预测。
- en: 'We’ll define our data window as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义我们的数据窗口如下：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: By now you should be comfortable building models with Keras, so defining the
    CNN architecture as a multi-output model should be straightforward. Again, we’ll
    use the `Sequential` model, in which we’ll stack a `Conv1D` layer, followed by
    a `Dense` layer, allowing the network to learn on a set of filtered features.
    The output layer will have two neurons, since we’re forecasting both the temperature
    and the traffic volume. Next we’ll fit the model and store its performance metrics.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该已经熟悉了使用Keras构建模型，因此定义CNN架构作为多输出模型应该是直接的。再次强调，我们将使用`Sequential`模型，其中我们将堆叠一个`Conv1D`层，然后是一个`Dense`层，允许网络在一系列过滤特征上学习。输出层将有两个神经元，因为我们正在预测温度和交通量。接下来我们将拟合模型并存储其性能指标。
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can also combine the CNN architecture with the LSTM architecture as done
    previously. We’ll simply replace the intermediate `Dense` layer with an `LSTM`
    layer, fit the model, and store its metrics.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以像之前那样将CNN架构与LSTM架构相结合。我们将简单地用`LSTM`层替换中间的`Dense`层，拟合模型并存储其指标。
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As usual, we’ll compare the performance of the new models with the previous
    multi-output models in figure 16.8\. You’ll notice that the CNN, and the combination
    of CNN and LSTM, did not result in an improvement over the LSTM. In fact, all
    three models achieve the same MAE.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，我们将在图16.8中比较新模型与之前的多输出模型的性能。你会注意到，CNN以及CNN和LSTM的组合并没有在LSTM模型上带来改进。事实上，所有三个模型都实现了相同的平均绝对误差（MAE）。
- en: '![](../../OEBPS/Images/16-08.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/16-08.png)'
- en: Figure 16.8 The MAE of all multi-output models built so far. As you can see,
    the CNN and the combination of CNN and LSTM did not result in improvements over
    the LSTM model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图16.8迄今为止构建的所有多输出模型的平均绝对误差（MAE）。如图所示，CNN以及CNN和LSTM的组合并没有在LSTM模型上带来改进。
- en: Explaining this behavior is hard, as deep learning models are black boxes, meaning
    that they are hard to interpret. While they can be very performant, the tradeoff
    lies in their explicability. Methods to interpret neural network models do exist,
    but they are outside of the scope of this book. If you want to learn more, take
    a look at Christof Molnar’s book, *Interpretable Machine Learning*, *Second Edition*
    ([https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 解释这种行为是困难的，因为深度学习模型是黑盒，这意味着它们难以解释。虽然它们可以非常高效，但权衡在于它们的可解释性。存在解释神经网络模型的方法，但它们超出了本书的范围。如果你想了解更多，可以看看Christof
    Molnar的书籍，《可解释机器学习》（*Interpretable Machine Learning*，*Second Edition*），[https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)。
- en: 16.3 Next steps
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.3 下一步
- en: In this chapter, we examined the architecture of the CNN. We observed how the
    convolution operation is used in the network and how it effectively filters the
    input sequence with the use of a kernel. We then implemented the CNN architecture
    and combined it with the LSTM architecture to produce two new single-step models,
    multi-step models, and multi-output models.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了卷积神经网络（CNN）的架构。我们观察了卷积操作在网络中的应用以及如何使用核函数有效地过滤输入序列。然后我们实现了CNN架构，并将其与LSTM架构相结合，产生了两个新的单步模型、多步模型和多输出模型。
- en: In the case of the single-step models, using a CNN did not improve the results.
    In fact, it performed worse than the LSTM alone. For the multi-step models, we
    observed a slight performance boost and obtained the best-performing multi-step
    model with the combination of a CNN and an LSTM. In the case of the multi-output
    model, the use of a CNN resulted in constant performance, so we have a tie between
    the CNN, the LSTM, and the combination of CNN and LSTM. Thus, we can see that
    a CNN does not necessarily result in the best-performing model. In one situation
    it did, in another it did not, and in another there was no difference.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在单步模型的情况下，使用CNN并没有提高结果。事实上，它的表现比单独使用LSTM还要差。对于多步模型，我们观察到轻微的性能提升，并获得了最佳表现的多步模型，该模型结合了CNN和LSTM。在多输出模型的情况下，使用CNN导致了恒定的性能，因此CNN、LSTM以及CNN和LSTM的组合之间有平局。因此，我们可以看到CNN并不一定导致最佳表现模型。在某些情况下它做到了，在另一些情况下没有，在某些情况下没有差异。
- en: It is important to consider the CNN architecture as a tool in your toolset when
    it comes to modeling with deep learning. Models will perform differently depending
    on the dataset and the forecasting goal. The key lies in windowing your data correctly,
    as is done by the `DataWindow` class, and in following a testing methodology,
    as we have done by keeping the training set, validation set, and testing set constant
    and evaluating all models using the MAE against baseline models.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到使用深度学习进行建模时，将CNN架构视为你的工具集中的一个工具是很重要的。模型的表现将根据数据集和预测目标的不同而有所不同。关键在于正确地窗口化你的数据，就像`DataWindow`类所做的那样，并且遵循测试方法，就像我们通过保持训练集、验证集和测试集不变，并使用MAE对基线模型进行评估所做的那样。
- en: The last deep learning architecture that we are going to explore specifically
    concerns the multi-step models. Up until now, all multi-step models have output
    predictions for the next 24 hours in a single shot. However, it is possible to
    gradually predict the next 24 hours and feed a past prediction back into the model
    to output the next prediction. This is especially done with the LSTM architecture,
    resulting in an *autoregressive LSTM* (ARLSTM). This will be the subject of the
    next chapter.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要特别探索的最后一个深度学习架构是关于多步模型。到目前为止，所有多步模型都是一次性预测未来24小时的输出。然而，可以逐步预测未来24小时，并将过去的预测反馈到模型中以输出下一个预测。这特别适用于LSTM架构，结果是一个*自回归LSTM*（ARLSTM）。这将是下一章的主题。
- en: 16.4 Exercises
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16.4 练习
- en: 'In the previous chapter’s exercises, you built LSTM models. Now you’ll experiment
    with a CNN and a combination of CNN and LSTM to see if you can gain in performance.
    The solutions to these exercises are available on GitHub: [https://github.com/marcopeix/TimeSeriesForecastingInPython/tree/master/CH16](https://github.com/marcopeix/TimeSeriesForecastingInPython/tree/master/CH16).'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章的练习中，你构建了LSTM模型。现在你将尝试CNN和CNN与LSTM的组合，看看你是否能提高性能。这些练习的解决方案可在GitHub上找到：[https://github.com/marcopeix/TimeSeriesForecastingInPython/tree/master/CH16](https://github.com/marcopeix/TimeSeriesForecastingInPython/tree/master/CH16)。
- en: 'For the single-step model:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于单步模型：
- en: Build a CNN model. Set the kernel width to 3.
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个CNN模型。设置核宽度为3。
- en: Plot its predictions.
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制其预测图。
- en: Evaluate the model using the mean absolute error (MAE) and store the MAE.
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用平均绝对误差（MAE）评估模型并存储MAE。
- en: Build a CNN + LSTM model.
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个CNN + LSTM模型。
- en: Plot its predictions.
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制其预测图。
- en: Evaluate the model using the MAE and store the MAE.
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MAE评估模型并存储MAE。
- en: Which model performs best?
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个模型表现最好？
- en: 'For the multi-step model:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于多步模型：
- en: Build a CNN model. Set the kernel width to 3.
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个CNN模型。设置核宽度为3。
- en: Plot its predictions.
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制其预测图。
- en: Evaluate the model using the MAE and store the MAE.
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MAE评估模型并存储MAE。
- en: Build a CNN+LSTM model.
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个CNN+LSTM模型。
- en: Plot its predictions.
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制其预测图。
- en: Evaluate the model using the MAE and store the MAE.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MAE评估模型并存储MAE。
- en: Which model performs best?
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个模型表现最好？
- en: 'Multi-output model:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 多输出模型：
- en: Build a CNN model. Set the kernel width to 3.
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个CNN模型。设置核宽度为3。
- en: Plot its predictions.
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制其预测图。
- en: Evaluate the model using the MAE and store the MAE.
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MAE评估模型并存储MAE。
- en: Build a CNN + LSTM model.
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个CNN + LSTM模型。
- en: Plot its predictions.
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制其预测图。
- en: Evaluate the model using the MAE and store the MAE.
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用MAE评估模型并存储MAE。
- en: Which model performs best?
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个模型表现最好？
- en: 'As always, this is an occasion to experiment. You can explore the following:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，这是一个实验的机会。你可以探索以下内容：
- en: Add more layers.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加更多层。
- en: Change the number of units.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改变单元数量。
- en: Pad the sequence instead of increasing the input length. This is done in the
    `Conv1D` layer using the parameter `padding="same"`. In that case, your input
    sequence must have a length of 24.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用填充序列代替增加输入长度。这通过在`Conv1D`层中使用参数`padding="same"`来实现。在这种情况下，你的输入序列必须长度为24。
- en: Use different layer initializers.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同的层初始化器。
- en: Summary
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: The convolutional neural network (CNN) is a deep learning architecture that
    makes use of the convolution operation.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）是一种利用卷积操作的深度学习架构。
- en: The convolution operation is performed between a kernel and the feature space.
    It is simply the dot product between the kernel and the feature vector.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积操作是在内核和特征空间之间进行的。它仅仅是内核和特征向量之间的点积。
- en: Running a convolution operation results in an output sequence that is shorter
    than the input sequence. Running many convolutions can therefore decrease the
    output length quickly. Padding can be used to prevent that.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行卷积操作会导致输出序列比输入序列短。因此，多次执行卷积可以快速减少输出长度。可以使用填充来防止这种情况。
- en: 'In time series forecasting, the convolution is performed in one dimension only:
    the temporal dimension.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在时间序列预测中，卷积仅在单维进行：时间维度。
- en: The CNN is just another model in your toolbox and may not always be the best-performing
    model. Make sure you window your data correctly with `DataWindow`, and keep your
    testing methodology valid by keeping each set of data constant, building baseline
    models, and evaluating all models with the same error metric.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN只是你的工具箱中的另一个模型，并不总是性能最好的模型。确保你使用`DataWindow`正确地窗口化你的数据，并通过保持每套数据恒定、构建基线模型以及使用相同的误差指标评估所有模型来确保你的测试方法有效。
