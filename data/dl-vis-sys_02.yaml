- en: 1 Welcome to computer vision
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 欢迎来到计算机视觉
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Components of the vision system
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视觉系统组件
- en: Applications of computer vision
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机视觉应用
- en: Understanding the computer vision pipeline
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解计算机视觉流程
- en: Preprocessing images and extracting features
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理图像和提取特征
- en: Using classifier learning algorithms
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分类学习算法
- en: 'Hello! I’m very excited that you are here. You are making a great decision--to
    grasp deep learning (DL) and computer vision (CV). The timing couldn’t be more
    perfect. CV is an area that’s been advancing rapidly, thanks to the huge AI and
    DL advances of recent years. Neural networks are now allowing self-driving cars
    to figure out where other cars and pedestrians are and navigate around them. We
    are using CV applications in our daily lives more and more with all the smart
    devices in our homes--from security cameras to door locks. CV is also making face
    recognition work better than ever: smartphones can recognize faces for unlocking,
    and smart locks can unlock doors. I wouldn’t be surprised if sometime in the near
    future, your couch or television is able to recognize specific people in your
    house and react according to their personal preferences. It’s not just about recognizing
    objects--DL has given computers the power to imagine and create new things like
    artwork; new objects; and even unique, realistic human faces.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 嘿！我非常激动你能在这里。你做出了一个伟大的决定--掌握深度学习（DL）和计算机视觉（CV）。时机再合适不过了。得益于近年来人工智能和深度学习的巨大进步，CV
    领域正在快速发展。神经网络现在使得自动驾驶汽车能够确定其他车辆和行人的位置，并绕过它们。我们越来越多地在家中的智能设备中使用 CV 应用程序--从安全摄像头到门锁。CV
    还使面部识别工作得比以往任何时候都要好：智能手机可以识别面部以解锁，智能锁可以解锁门。如果在未来某个时候，你的沙发或电视能够识别你家中特定的人并根据他们的个人喜好做出反应，我并不会感到惊讶。这不仅仅是识别物体--DL
    已经赋予了计算机想象和创造新事物（如艺术品；新物体；甚至独特、逼真的面部）的能力。
- en: The main reason that I’m excited about deep learning for computer vision, and
    what drew me to this field, is how rapid advances in AI research are enabling
    new applications to be built every day and across different industries, something
    not possible just a few years ago. The unlimited possibilities of CV research
    is what inspired me to write this book. By learning these tools, perhaps you will
    be able to invent new products and applications. Even if you end up not working
    on CV per se, you will find many concepts in this book useful for some of your
    DL algorithms and architectures. That is because while the main focus is CV applications,
    this book covers the most important DL architectures, such as artificial neural
    networks (ANNs), convolutional networks (CNNs), generative adversarial networks
    (GANs), transfer learning, and many more, which are transferable to other domains
    like natural language processing (NLP) and voice user interfaces (VUIs).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我对深度学习在计算机视觉中的兴奋，以及是什么吸引我进入这个领域的主要原因，是 AI 研究的快速进步正在使每天都能在不同行业中构建新的应用，这在几年前是不可能的。CV
    研究的无限可能性激发了我写这本书的灵感。通过学习这些工具，也许你将能够发明新的产品和应用。即使你最终没有从事 CV 工作，你也会发现这本书中的许多概念对你的某些
    DL 算法和架构非常有用。那是因为虽然主要关注 CV 应用，但本书涵盖了最重要的 DL 架构，如人工神经网络（ANNs）、卷积网络（CNNs）、生成对抗网络（GANs）、迁移学习以及更多，这些可以转移到其他领域，如自然语言处理（NLP）和语音用户界面（VUIs）。
- en: 'The high-level layout of this chapter is as follows:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的高级布局如下：
- en: 'Computer vision intuition --We will start with visual perception intuition
    and learn the similarities between humans and machine vision systems. We will
    look at how vision systems have two main components: a sensing device and an interpreting
    device. Each is tailored to fulfill a specific task.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机视觉直觉 -- 我们将从视觉感知直觉开始，学习人类与机器视觉系统之间的相似性。我们将探讨视觉系统有两个主要组件：一个感知设备和解释设备。每个设备都针对完成特定任务而定制。
- en: Applications of CV --Here, we will take a bird’s-eye view of the DL algorithms
    used in different CV applications. We will then discuss vision in general for
    different creatures.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机视觉应用 -- 在这里，我们将从宏观角度审视不同计算机视觉应用中使用的深度学习算法。然后，我们将讨论不同生物的视觉问题。
- en: 'Computer vision pipeline --Finally, we will zoom in on the second component
    of vision systems: the interpreting device. We will walk through the sequence
    of steps taken by vision systems to process and understand image data. These are
    referred to as a computer vision pipeline. The CV pipeline is composed of four
    main steps: image input, image preprocessing, feature extraction, and an ML model
    to interpret the image. We will talk about image formation and how computers see
    images. Then, we will quickly review image-processing techniques and extracting
    features.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机视觉流程--最后，我们将聚焦于视觉系统的第二个组成部分：解释设备。我们将逐步讲解视觉系统在处理和解析图像数据时所采取的步骤序列。这些步骤被称为计算机视觉流程。CV流程由四个主要步骤组成：图像输入、图像预处理、特征提取以及用于解释图像的机器学习模型。我们将讨论图像形成以及计算机是如何“看”图像的。然后，我们将快速回顾图像处理技术和特征提取。
- en: Ready? Let’s get started!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好了吗？让我们开始吧！
- en: 1.1 Computer vision
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 计算机视觉
- en: 'The core concept of any AI system is that it can perceive its environment and
    take actions based on its perceptions. Computer vision is concerned with the visual
    perception part: it is the science of perceiving and understanding the world through
    images and videos by constructing a physical model of the world so that an AI
    system can then take appropriate actions. For humans, vision is only one aspect
    of perception. We perceive the world through our sight, but also through sound,
    smell, and our other senses. It is similar with AI systems--vision is just one
    way to understand the world. Depending on the application you are building, you
    select the sensing device that best captures the world.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 任何人工智能系统的核心概念是它能够感知其环境并根据其感知采取行动。计算机视觉关注的是视觉感知部分：它是通过构建世界的物理模型，使人工智能系统能够采取适当的行动，通过图像和视频感知和理解世界的一门科学。对于人类来说，视觉只是感知的一个方面。我们通过视觉感知世界，但也通过声音、气味以及我们的其他感官。对于人工智能系统来说也是如此--视觉只是理解世界的一种方式。根据你正在构建的应用，你选择最能捕捉世界的传感器。
- en: 1.1.1 What is visual perception?
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.1 视觉感知是什么？
- en: Visual perception, at its most basic, is the act of observing patterns and objects
    through sight or visual input. With an autonomous vehicle, for example, visual
    perception means understanding the surrounding objects and their specific details--such
    as pedestrians, or whether there is a particular lane the vehicle needs to be
    centered in--and detecting traffic signs and understanding what they mean. That’s
    why the word perception is part of the definition. We are not just looking to
    capture the surrounding environment. We are trying to build systems that can actually
    understand that environment through visual input.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉感知在最基本的意义上是通过视觉或视觉输入观察模式和对象的行为。例如，对于自动驾驶汽车来说，视觉感知意味着理解周围的对象及其具体细节--例如行人，或者车辆是否需要保持在特定车道中央--以及检测交通标志并理解其含义。这就是为什么“感知”这个词是定义的一部分。我们不仅仅是想要捕捉周围的环境。我们试图构建能够通过视觉输入真正理解该环境的系统。
- en: 1.1.2 Vision systems
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.2 视觉系统
- en: In past decades, traditional image-processing techniques were considered CV
    systems, but that is not totally accurate. A machine processing an image is completely
    different from that machine understanding what’s happening within the image, which
    is not a trivial task. Image processing is now just a piece of a bigger, more
    complex system that aims to interpret image content.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几十年里，传统的图像处理技术被认为是计算机视觉系统，但这并不完全准确。一个处理图像的机器与理解图像中发生的事情的机器完全不同，这并不是一个简单任务。现在，图像处理只是更大、更复杂系统的一部分，该系统旨在解释图像内容。
- en: Human vision systems
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人类视觉系统
- en: At the highest level, vision systems are pretty much the same for humans, animals,
    insects, and most living organisms. They consist of a sensor or an eye to capture
    the image and a brain to process and interpret the image. The system then outputs
    a prediction of the image components based on the data extracted from the image
    (figure 1.1).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在最高层面上，视觉系统对于人类、动物、昆虫以及大多数生物体来说几乎是相同的。它们由一个传感器或眼睛来捕捉图像，以及一个大脑来处理和解释图像。系统随后根据从图像中提取的数据输出对图像组件的预测（图1.1）。
- en: '![](../Images/1-1.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-1.png)'
- en: Figure 1.1 The human vision system uses the eye and brain to sense and interpret
    an image.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 人类视觉系统利用眼睛和大脑来感知和解释图像。
- en: Let’s see how the human vision system works. Suppose we want to interpret the
    image of dogs in figure 1.1\. We look at it and directly understand that the image
    consists of a bunch of dogs (three, to be specific). It comes pretty natural to
    us to classify and detect objects in this image because we have been trained over
    the years to identify dogs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看人类视觉系统是如何工作的。假设我们想要解释图1.1中的狗的图像。我们看它，并直接理解图像由一群狗（具体来说是三只）组成。对我们来说，在这个图像中分类和检测物体是非常自然的，因为我们多年来一直在接受识别狗的训练。
- en: 'Suppose someone shows you a picture of a dog for the first time--you definitely
    don’t know what it is. Then they tell you that this is a dog. After a couple experiments
    like this, you will have been trained to identify dogs. Now, in a follow-up exercise,
    they show you a picture of a horse. When you look at the image, your brain starts
    analyzing the object features: hmmm, it has four legs, long face, long ears. Could
    it be a dog? “Wrong: this is a horse,” you’re told. Then your brain adjusts some
    parameters in its algorithm to learn the differences between dogs and horses.
    Congratulations! You just trained your brain to classify dogs and horses. Can
    you add more animals to the equation, like cats, tigers, cheetahs, and so on?
    Definitely. You can train your brain to identify almost anything. The same is
    true of computers. You can train machines to learn and identify objects, but humans
    are much more intuitive than machines. It takes only a few images for you to learn
    to identify most objects, whereas with machines, it takes thousands or, in more
    complex cases, millions of image samples to learn to identify objects.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有人第一次给你看一张狗的图片--你肯定不知道这是什么。然后他们告诉你这是一只狗。经过几次这样的实验后，你将接受训练来识别狗。现在，在接下来的练习中，他们给你看一张马的图片。当你看这张图片时，你的大脑开始分析物体特征：嗯嗯，它有四条腿，长脸，长耳朵。它可能是一只狗吗？“错误：这是一匹马，”你被告知。然后你的大脑在其算法中调整了一些参数来学习狗和马之间的差异。恭喜！你刚刚训练了你的大脑来分类狗和马。你能把更多的动物加到等式中，比如猫、老虎、猎豹等等吗？当然可以。你可以训练你的大脑来识别几乎任何东西。对计算机来说也是如此。你可以训练机器来学习和识别物体，但人类比机器更直观。你只需要几幅图像就能学会识别大多数物体，而机器则需要成千上万，甚至在更复杂的情况下，数百万个图像样本来学习识别物体。
- en: The ML perspective
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的视角
- en: 'Let’s look at the previous example from the machine learning perspective:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从机器学习的角度来回顾之前的例子：
- en: You learned to identify dogs by looking at examples of several dog-labeled images.
    This approach is called supervised learning.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你通过观察几个标注为狗的图像的例子来学习识别狗。这种方法被称为监督学习。
- en: 'Labeled data is data for which you already know the target answer. You were
    shown a sample image of a dog and told that it was a dog. Your brain learned to
    associate the features you saw with this label: dog.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标注数据是指你已经知道目标答案的数据。你被展示了一幅狗的样本图像，并被告知这是一只狗。你的大脑学会了将你看到的特征与这个标签“狗”相关联。
- en: You were then shown a different object, a horse, and asked to identify it. At
    first, your brain thought it was a dog, because you hadn’t seen horses before,
    and your brain confused horse features with dog features. When you were told that
    your prediction was wrong, your brain adjusted its parameters to learn horse features.
    “Yes, both have four legs, but the horse’s legs are longer. Longer legs indicate
    a horse.” We can run this experiment many times until the brain makes no mistakes.
    This is called training by trial and error.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，你被展示了一个不同的物体，一匹马，并被要求识别它。起初，你的大脑认为它是一只狗，因为你之前没有见过马，你的大脑将马的特征与狗的特征混淆了。当你被告知你的预测是错误的时，你的大脑调整了它的参数来学习马的特征。“是的，两者都有四条腿，但马的腿更长。更长的腿意味着这是一匹马。”我们可以多次运行这个实验，直到大脑不再犯错误。这被称为通过试错进行训练。
- en: AI vision systems
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人工智能视觉系统
- en: 'Scientists were inspired by the human vision system and in recent years have
    done an amazing job of copying visual ability with machines. To mimic the human
    vision system, we need the same two main components: a sensing device to mimic
    the function of the eye and a powerful algorithm to mimic the brain function in
    interpreting and classifying image content (figure 1.2).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 科学家们受到人类视觉系统的启发，近年来在用机器复制视觉能力方面做了惊人的工作。为了模仿人类视觉系统，我们需要相同的两个主要组件：一个感知设备来模仿眼睛的功能，以及一个强大的算法来模仿大脑在解释和分类图像内容时的功能（图1.2）。
- en: '![](../Images/1-2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-2.png)'
- en: Figure 1.2 The components of the computer vision system are a sensing device
    and an interpreting device.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 计算机视觉系统的组成部分包括一个感知设备和解释设备。
- en: 1.1.3 Sensing devices
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.3 感知设备
- en: Vision systems are designed to fulfill a specific task. An important aspect
    of design is selecting the best sensing device to capture the surroundings of
    a specific environment, whether that is a camera, radar, X-ray, CT scan, Lidar,
    or a combination of devices to provide the full scene of an environment to fulfill
    the task at hand.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉系统旨在完成特定任务。设计的一个重要方面是选择最佳的感应设备来捕捉特定环境的周围环境，无论是摄像头、雷达、X射线、CT扫描、激光雷达，还是提供完整环境场景以完成任务的设备组合。
- en: Let’s look at the autonomous vehicle (AV) example again. The main goal of the
    AV vision system is to allow the car to understand the environment around it and
    move from point A to point B safely and in a timely manner. To fulfill this goal,
    vehicles are equipped with a combination of cameras and sensors that can detect
    360 degrees of movement--pedestrians, cyclists, vehicles, roadwork, and other
    objects--from up to three football fields away.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次看看自动驾驶汽车（AV）的例子。AV视觉系统的主要目标是让汽车能够理解其周围的环境，并安全、及时地从A点移动到B点。为了实现这一目标，车辆配备了包括摄像头和传感器在内的组合设备，这些设备可以检测到360度的运动——行人、骑自行车的人、车辆、道路施工和其他物体——从最远三个足球场外的地方。
- en: 'Here are some of the sensing devices usually used in self-driving cars to perceive
    the surrounding area:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些通常用于自动驾驶汽车中感知周围区域的感应设备：
- en: Lidar, a radar-like technique, uses invisible pulses of light to create a high-resolution
    3D map of the surrounding area.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激光雷达，一种类似雷达的技术，使用不可见的光脉冲来创建周围区域的高分辨率3D地图。
- en: Cameras can see street signs and road markings but cannot measure distance.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 照相机可以看到街牌和路面标记，但不能测量距离。
- en: Radar can measure distance and velocity but cannot see in fine detail.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雷达可以测量距离和速度，但不能看到细节。
- en: Medical diagnosis applications use X-rays or CT scans as sensing devices. Or
    maybe you need to use some other type of radar to capture the landscape for agricultural
    vision systems. There are a variety of vision systems, each designed to perform
    a particular task. The first step in designing vision systems is to identify the
    task they are built for. This is something to keep in mind when designing end-to-end
    vision systems.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 医学诊断应用使用X射线或CT扫描作为感应设备。或者，你可能需要使用其他类型的雷达来捕捉农业视觉系统的景观。有各种各样的视觉系统，每个系统都设计来执行特定的任务。设计视觉系统的第一步是确定它们是为完成什么任务而构建的。在设计端到端视觉系统时，这一点需要牢记在心。
- en: Recognizing images
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 识别图像
- en: Animals, humans, and insects all have eyes as sensing devices. But not all eyes
    have the same structure, output image quality, and resolution. They are tailored
    to the specific needs of the creature. Bees, for instance, and many other insects,
    have compound eyes that consist of multiple lenses (as many as 30,000 lenses in
    a single compound eye). Compound eyes have low resolution, which makes them not
    so good at recognizing objects at a far distance. But they are very sensitive
    to motion, which is essential for survival while flying at high speed. Bees don’t
    need high-resolution pictures. Their vision systems are built to allow them to
    pick up the smallest movements while flying fast.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 动物、人类和昆虫都使用眼睛作为感应设备。但并非所有眼睛的结构、输出图像质量和分辨率都相同。它们是根据生物体的特定需求定制的。例如，蜜蜂和许多其他昆虫都有复眼，由多个透镜组成（单个复眼中多达30,000个透镜）。复眼分辨率低，这使得它们在远距离识别物体方面不太擅长。但它们对运动非常敏感，这对于高速飞行时的生存至关重要。蜜蜂不需要高分辨率的图像。它们的视觉系统被构建成能够在快速飞行时捕捉到最小的运动。
- en: '![](../Images/1-unnumb-1.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-unnumb-1.png)'
- en: Compound eyes are low resolution but sensitive to motion.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 复眼分辨率低，但对运动敏感。
- en: 1.1.4 Interpreting devices
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1.4 解释设备
- en: Computer vision algorithms are typically employed as interpreting devices. The
    interpreter is the brain of the vision system. Its role is to take the output
    image from the sensing device and learn features and patterns to identify objects.
    So we need to build a brain. Simple! Scientists were inspired by how our brains
    work and tried to reverse engineer the central nervous system to get some insight
    on how to build an artificial brain. Thus, artificial neural networks (ANNs) were
    born (figure 1.3).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉算法通常用作解释设备。解释器是视觉系统的“大脑”。其作用是从感应设备获取输出图像，学习特征和模式以识别物体。因此，我们需要构建一个大脑。简单！科学家们受到我们大脑工作方式的启发，试图逆向工程中枢神经系统，以获得有关如何构建人工大脑的见解。因此，人工神经网络（ANNs）应运而生（图1.3）。
- en: '![](../Images/1-3.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-3.png)'
- en: Figure 1.3 The similarities between biological neurons and artificial systems
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 生物神经元与人工系统之间的相似性
- en: In figure 1.3, we can see an analogy between biological neurons and artificial
    systems. Both contain a main processing element, a neuron, with input signals
    (*x*[1], *x*[2], ..., *x[n]*) and an output.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在图1.3中，我们可以看到生物神经元与人工系统之间的类比。两者都包含一个主要处理元素，即神经元，它有输入信号（*x*[1]，*x*[2]，...，*x[n]*)和一个输出。
- en: The learning behavior of biological neurons inspired scientists to create a
    network of neurons that are connected to each other. Imitating how information
    is processed in the human brain, each artificial neuron fires a signal to all
    the neurons that it’s connected to when enough of its input signals are activated.
    Thus, neurons have a very simple mechanism on the individual level (as you will
    see in the next chapter); but when you have millions of these neurons stacked
    in layers and connected together, each neuron is connected to thousands of other
    neurons, yielding a learning behavior. Building a multilayer neural network is
    called deep learning (figure 1.4).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 生物神经元的 学习行为启发了科学家们创建一个相互连接的神经元网络。模仿人类大脑中信息处理的方式，当足够多的输入信号被激活时，每个人工神经元会向它所连接的所有神经元发送信号。因此，神经元在个体层面上具有非常简单的机制（你将在下一章中看到）；但是当你有成千上万的这些神经元堆叠在层中并相互连接时，每个神经元都连接到成千上万的其它神经元，从而产生学习行为。构建多层神经网络被称为深度学习（图1.4）。
- en: '![](../Images/1-4.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-4.png)'
- en: Figure 1.4 Deep learning involves layers of neurons in a network.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 深度学习涉及网络中的神经元层。
- en: DL methods learn representations through a sequence of transformations of data
    through layers of neurons. In this book, we will explore different DL architectures,
    such as ANNs and convolutional neural networks, and how they are used in CV applications.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习方法通过数据在神经元层中的连续变换来学习表示。在这本书中，我们将探讨不同的深度学习架构，例如人工神经网络和卷积神经网络，以及它们在计算机视觉应用中的使用。
- en: Can machine learning achieve better performance than the human brain?
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 机器学习能否比人类大脑实现更好的性能？
- en: 'Well, if you had asked me this question 10 years ago, I would’ve probably said
    no, machines cannot surpass the accuracy of a human. But let’s take a look at
    the following two scenarios:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，如果你在10年前问我这个问题，我可能会说不可能，机器无法超越人类的准确率。但让我们看看以下两个场景：
- en: Suppose you were given a book of 10,000 dog images, classified by breed, and
    you were asked to learn the properties of each breed. How long would it take you
    to study the 130 breeds in 10,000 images? And if you were given a test of 100
    dog images and asked to label them based on what you learned, out of the 100,
    how many would you get right? Well, a neural network that is trained in a couple
    of hours can achieve more than 95% accuracy.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设你被给了一本包含10,000张狗的照片的书，这些照片按品种分类，并要求你学习每种品种的特性。你需要在10,000张照片中学习130种品种需要多长时间？如果你被要求对100张狗的照片进行测试，并基于你所学的内容进行标记，那么在这100张照片中，你能正确标记多少张？嗯，经过几小时训练的神经网络可以达到超过95%的准确率。
- en: On the creation side, a neural network can study the patterns in the strokes,
    colors, and shading of a particular piece of art. Based on this analysis, it can
    then transfer the style from the original artwork into a new image and create
    a new piece of original art within a few seconds.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在创作方面，神经网络可以研究特定艺术品笔触、色彩和阴影中的模式。基于这种分析，它可以将原始艺术作品的风格转移到新图像中，并在几秒钟内创建出新的原创艺术品。
- en: Recent AI and DL advances have allowed machines to surpass human visual ability
    in many image classification and object detection applications, and capacity is
    rapidly expanding to many other applications. But don’t take my word for it. In
    the next section, we’ll discuss some of the most popular CV applications using
    DL technology.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 最近人工智能和深度学习的发展使得机器在许多图像分类和目标检测应用中超越了人类的视觉能力，并且这种能力正在迅速扩展到许多其他应用。但不要仅凭我的话，在下一节中，我们将讨论一些使用深度学习技术的最流行的计算机视觉应用。
- en: 1.2 Applications of computer vision
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 计算机视觉的应用
- en: 'Computers began to be able to recognize human faces in images decades ago,
    but now AI systems are rivaling the ability of computers to classify objects in
    photos and videos. Thanks to the dramatic evolution in both computational power
    and the amount of data available, AI and DL have managed to achieve superhuman
    performance on many complex visual perception tasks like image search and captioning,
    image and video classification, and object detection. Moreover, deep neural networks
    are not restricted to CV tasks: they are also successful at natural language processing
    and voice user interface tasks. In this book, we’ll focus on visual applications
    that are applied in CV tasks.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 几十年前，计算机开始能够在图像中识别人脸，但现在人工智能系统正在与计算机在照片和视频中分类对象的能力相媲美。得益于计算能力和可用数据量的显著进步，人工智能和深度学习已经在许多复杂的视觉感知任务上实现了超越人类的表现，如图像搜索和字幕、图像和视频分类以及物体检测。此外，深度神经网络不仅限于计算机视觉任务：它们在自然语言处理和语音用户界面任务中也取得了成功。在这本书中，我们将重点关注应用于计算机视觉任务的视觉应用。
- en: DL is used in many computer vision applications to recognize objects and their
    behavior. In this section, I’m not going to attempt to list all the CV applications
    that are out there. I would need an entire book for that. Instead, I’ll give you
    a bird’s-eye view of some of the most popular DL algorithms and their possible
    applications across different industries. Among these industries are autonomous
    cars, drones, robots, in-store cameras, and medical diagnostic scanners that can
    detect lung cancer in early stages.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习被用于许多计算机视觉应用中，以识别对象及其行为。在本节中，我不会尝试列出所有现有的计算机视觉应用。那需要一本书的篇幅。相反，我将为您提供一个鸟瞰图，展示一些最受欢迎的深度学习算法及其在不同行业中的可能应用。这些行业包括自动驾驶汽车、无人机、机器人、店内摄像头和能够检测早期肺癌的医疗诊断扫描仪。
- en: 1.2.1 Image classification
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.1 图像分类
- en: 'Image classification is the task of assigning to an image a label from a predefined
    set of categories. A convolutional neural network is a neural network type that
    truly shines in processing and classifying images in many different applications:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是将图像分配到预定义类别集合中的标签的任务。卷积神经网络是一种在处理和分类图像方面真正发光的神经网络类型，它在许多不同的应用中表现出色：
- en: Lung cancer diagnosis --Lung cancer is a growing problem. The main reason lung
    cancer is very dangerous is that when it is diagnosed, it is usually in the middle
    or late stages. When diagnosing lung cancer, doctors typically use their eyes
    to examine CT scan images, looking for small nodules in the lungs. In the early
    stages, the nodules are usually very small and hard to spot. Several CV companies
    decided to tackle this challenge using DL technology.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 肺癌诊断 -- 肺癌是一个日益严重的问题。肺癌非常危险的主要原因是在诊断时通常处于中期或晚期。在诊断肺癌时，医生通常用眼睛检查CT扫描图像，寻找肺中的小结节。在早期阶段，结节通常非常小，难以发现。几家计算机视觉公司决定利用深度学习技术来应对这一挑战。
- en: Almost every lung cancer starts as a small nodule, and these nodules appear
    in a variety of shapes that doctors take years to learn to recognize. Doctors
    are very good at identifying mid- and large-size nodules, such as 6-10 mm. But
    when nodules are 4 mm or smaller, sometimes doctors have difficulty identifying
    them. DL networks, specifically CNNs, are now able to learn these features automatically
    from X-ray and CT scan images and detect small nodules early, before they become
    deadly (figure 1.5).
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 几乎所有的肺癌都是从一个小结节开始的，这些结节以医生需要多年时间才能学会识别的各种形状出现。医生在识别中等大小和大结节，如6-10毫米的结节方面非常擅长。但当结节为4毫米或更小时，有时医生难以识别它们。深度学习网络，特别是卷积神经网络，现在能够自动从X射线和CT扫描图像中学习这些特征，并在它们变得致命之前早期检测到小结节（图1.5）。
- en: '![](../Images/1-5.png)'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](../Images/1-5.png)'
- en: Figure 1.5 Vision systems are now able to learn patterns in X-ray images to
    identify tumors in earlier stages of development.
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.5 现在的视觉系统能够从X射线图像中学习模式，以识别早期发展阶段的肿瘤。
- en: Traffic sign recognition --Traditionally, standard CV methods were employed
    to detect and classify traffic signs, but this approach required time-consuming
    manual work to handcraft important features in images. Instead, by applying DL
    to this problem, we can create a model that reliably classifies traffic signs,
    learning to identify the most appropriate features for this problem by itself
    (figure 1.6).
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交通标志识别 -- 传统上，标准计算机视觉方法被用于检测和分类交通标志，但这种方法需要耗时的人工工作来手工制作图像中的重要特征。相反，通过将深度学习应用于这个问题，我们可以创建一个可靠地分类交通标志的模型，该模型通过自身学习识别最合适的特征（图1.6）。
- en: '![](../Images/1-6.png)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](../Images/1-6.png)'
- en: Figure 1.6 Vision systems can detect traffic signs with very high performance.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.6 视觉系统可以以非常高的性能检测交通标志。
- en: NOTE Increasing numbers of image classification tasks are being solved with
    convolutional neural networks. Due to their high recognition rate and fast execution,
    CNNs have enhanced most CV tasks, both pre-existing and new. Just like the cancer
    diagnosis and traffic sign examples, you can feed tens or hundreds of thousands
    of images into a CNN to label them into as many classes as you want. Other image
    classification examples include identifying people and objects, classifying different
    animals (like cats versus dogs versus horses), different breeds of animals, types
    of land suitable for agriculture, and so on. In short, if you have a set of labeled
    images, convolutional networks can classify them into a set of predefined classes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：越来越多的图像分类任务正在使用卷积神经网络得到解决。由于它们的高识别率和快速执行，CNNs极大地提升了大多数计算机视觉任务，无论是现有的还是新的。就像癌症诊断和交通标志的例子一样，你可以将成千上万的图像输入到CNN中，将它们标注成你想要的任意多类。其他图像分类的例子包括识别人物和物体、区分不同的动物（如猫、狗和马）、不同品种的动物、适合农业的土地类型等等。简而言之，如果你有一组标注好的图像，卷积网络可以将它们分类到一组预定义的类别中。
- en: 1.2.2 Object detection and localization
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.2 物体检测与定位
- en: Image classification problems are the most basic applications for CNNs. In these
    problems, each image contains only one object, and our task is to identify it.
    But if we aim to reach human levels of understanding, we have to add complexity
    to these networks so they can recognize multiple objects and their locations in
    an image. To do that, we can build object detection systems like YOLO (you only
    look once), SSD (single-shot detector), and Faster R-CNN, which not only classify
    images but also can locate and detect each object in images that contain multiple
    objects. These DL systems can look at an image, break it up into smaller regions,
    and label each region with a class so that a variable number of objects in a given
    image can be localized and labeled (figure 1.7). You can imagine that such a task
    is a basic prerequisite for applications like autonomous systems.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类问题是CNNs最基本的应用。在这些问题中，每张图像只包含一个物体，我们的任务是识别它。但如果我们希望达到人类水平的理解，我们必须增加这些网络的复杂性，以便它们能够识别图像中的多个物体及其位置。为此，我们可以构建YOLO（你只需看一次）、SSD（单次检测器）和Faster
    R-CNN等目标检测系统，这些系统不仅能够对图像进行分类，还能够定位和检测包含多个物体的图像中的每个物体。这些深度学习系统可以观察一张图像，将其分解成更小的区域，并为每个区域标注一个类别，以便在给定的图像中定位和标注可变数量的物体（图1.7）。你可以想象，这样的任务对于自动驾驶系统等应用来说是基本的前提条件。
- en: '![](../Images/1-7.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-7.png)'
- en: Figure 1.7 Deep learning systems can segment objects in an image.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7 深度学习系统可以在图像中分割物体。
- en: 1.2.3 Generating art (style transfer)
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.3 生成艺术（风格迁移）
- en: 'Neural style transfer, one of the most interesting CV applications, is used
    to transfer the style from one image to another. The basic idea of style transfer
    is this: you take one image--say, of a city--and then apply a style of art to
    that image--say, The Starry Night (by Vincent Van Gogh)--and output the same city
    from the original image, but looking as though it was painted by Van Gogh (figure
    1.8).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 神经风格迁移是计算机视觉中最有趣的 应用之一，它用于将一种图像的风格转移到另一种图像上。风格迁移的基本思想是这样的：你取一张图像——比如说，一座城市的图像——然后为这张图像应用一种艺术风格——比如说，文森特·梵高的《星夜》——输出与原始图像相同的城市，但看起来像是梵高所绘（图1.8）。
- en: '![](../Images/1-8.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-8.png)'
- en: Figure 1.8 Style transfer from Van Gogh’s The Starry Night onto the original
    image, producing a piece of art that feels as though it was created by the original
    artist
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8 将梵高的《星夜》风格转移到原始图像上，产生了一件感觉像是原始艺术家创作的艺术品
- en: This is actually a neat application. The astonishing thing, if you know any
    painters, is that it can take days or even weeks to finish a painting, and yet
    here is an application that can paint a new image inspired by an existing style
    in a matter of seconds.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是一个很酷的应用。如果你了解任何画家，令人惊讶的是，完成一幅画可能需要几天甚至几周的时间，然而这里有一个应用可以在几秒钟内根据现有的风格创作出新的图像。
- en: 1.2.4 Creating images
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.4 创建图像
- en: 'Although the earlier examples are truly impressive CV applications of AI, this
    is where I see the real magic happening: the magic of creation. In 2014, Ian Goodfellow
    invented a new DL model that can imagine new things called generative adversarial
    networks (GANs). The name makes them sound a little intimidating, but I promise
    you that they are not. A GAN is an evolved CNN architecture that is considered
    a major advancement in DL. So when you understand CNNs, GANs will make a lot more
    sense to you.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然早期的例子确实是AI在计算机视觉应用方面的真正令人印象深刻的例子，但我看到真正的魔法在这里发生：创造的魔法。2014年，Ian Goodfellow发明了一种新的深度学习模型，可以想象新事物，称为生成对抗网络（GANs）。这个名字听起来有点吓人，但我向你保证它们并不如此。GAN是一种演化的CNN架构，被认为是深度学习中的一个重大进步。所以当你理解CNNs时，GANs将对你来说更有意义。
- en: GANs are sophisticated DL models that generate stunningly accurate synthesized
    images of objects, people, and places, among other things. If you give them a
    set of images, they can make entirely new, realistic-looking images. For example,
    StackGAN is one of the GAN architecture variations that can use a textual description
    of an object to generate a high-resolution image of the object matching that description.
    This is not just running an image search on a database. These “photos” have never
    been seen before and are totally imaginary (figure 1.9).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: GANs（生成对抗网络）是复杂的深度学习模型，可以生成令人惊叹的、逼真的合成图像，包括物体、人物和地点等。如果你给他们一组图像，他们可以制作出全新的、看起来非常逼真的图像。例如，StackGAN是GAN架构变体之一，可以使用对象的文本描述来生成与该描述匹配的高分辨率图像。这不仅仅是数据库中的图像搜索。这些“照片”以前从未见过，完全是虚构的（图1.9）。
- en: '![](../Images/1-9.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-9](../Images/1-9.png)'
- en: Figure 1.9 Generative adversarial networks (GANS) can create new, “made-up”
    images from a set of existing images.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9 生成对抗网络（GANs）可以从一组现有图像中创建新的、“虚构”的图像。
- en: 'The GAN is one of the most promising advancements in machine learning in recent
    years. Research into GANs is new, and the results are overwhelmingly promising.
    Most of the applications of GANs so have far have been for images. But it makes
    you wonder: if machines are given the power of imagination to create pictures,
    what else can they create? In the future, will your favorite movies, music, and
    maybe even books be created by computers? The ability to synthesize one data type
    (text) to another (image) will eventually allow us to create all sorts of entertainment
    using only detailed text descriptions.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: GAN是近年来机器学习中最有希望的发展之一。对GAN的研究是新的，结果非常令人鼓舞。到目前为止，GANs的大部分应用都是图像相关的。但它让你想：如果机器被赋予创造图片的想象力，它们还能创造什么？在未来，你最喜欢的电影、音乐，甚至书籍会不会由计算机创造？将一种数据类型（文本）合成另一种（图像）的能力最终将使我们能够仅使用详细的文本描述来创造各种娱乐。
- en: GANs create artwork
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: GANs创作艺术品
- en: In October 2018, an AI-created painting called The Portrait of Edmond Belamy
    sold for $432,500\. The artwork features a fictional person named Edmond de Belamy,
    possibly French and--to judge by his dark frock coat and plain white collar--a
    man of the church.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 2018年10月，一幅名为《Edmond Belamy肖像》的AI创作画作以43.25万美元的价格售出。这件艺术品展示了一个名为Edmond de Belamy的虚构人物，可能是法国人——从他的深色大衣和平凡的白色领口来看，他可能是一位牧师。
- en: '![](../Images/1-unnumb-2.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-未编号-2](../Images/1-unnumb-2.png)'
- en: AI-generated artwork featuring a fictional person named Edmond de Belamy sold
    for $432,500.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一幅以虚构人物Edmond de Belamy命名的AI生成艺术品以43.25万美元的价格售出。
- en: The artwork was created by a team of three 25-year-old French students using
    GANs. The network was trained on a dataset of 15,000 portraits painted between
    the fourteenth and twentieth centuries, and then it created one of its own. The
    team printed the image, framed it, and signed it with part of a GAN algorithm.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这件艺术品是由三位25岁的法国学生使用GANs创作的。该网络在14至20世纪之间绘制的15,000幅肖像画数据集上进行了训练，然后创作了自己的作品。该团队打印了这幅画，装裱并签署了GAN算法的一部分。
- en: 1.2.5 Face recognition
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.5 人脸识别
- en: Face recognition (FR) allows us to exactly identify or tag an image of a person.
    Day-to-day applications include searching for celebrities on the web and auto-tagging
    friends and family in images. Face recognition is a form of fine-grained classification.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸识别（FR）使我们能够精确地识别或标记一个人的图像。日常应用包括在网络上搜索名人以及在图像中自动标记朋友和家人。人脸识别是一种细粒度分类。
- en: 'The famous Handbook of Face Recognition (Li et al., Springer, 2011) categorizes
    two modes of an FR system:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 著名的《人脸识别手册》（Li等人，Springer，2011）将FR系统的两种模式进行了分类：
- en: Face identification --Face identification involves one-to-many matches that
    compare a query face image against all the template images in the database to
    determine the identity of the query face. Another face recognition scenario involves
    a watchlist check by city authorities, where a query face is matched to a list
    of suspects (one-to-few matches).
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部识别——面部识别涉及一对一的匹配，将查询面部图像与数据库中的所有模板图像进行比较，以确定查询面的身份。另一个面部识别场景涉及城市当局的观察名单检查，其中查询面与嫌疑人名单（一对一的匹配）进行匹配。
- en: Face verification --Face verification involves a one-to-one match that compares
    a query face image against a template face image whose identity is being claimed
    (figure 1.10).
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面部验证——面部验证涉及一对一的匹配，将查询面部图像与声称身份的模板面部图像进行比较（见图1.10）。
- en: '![](../Images/1-10.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-10](../Images/1-10.png)'
- en: Figure 1.10 Example of face verification (left) and face recognition (right)
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.10 面部验证（左）和面部识别（右）的示例
- en: 1.2.6 Image recommendation system
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2.6 图像推荐系统
- en: In this task, a user seeks to find similar images with respect to a given query
    image. Shopping websites provide product suggestions (via images) based on the
    selection of a particular product, for example, showing a variety of shoes similar
    to those the user selected. An example of an apparel search is shown in figure
    1.11.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个任务中，用户试图根据给定的查询图像找到相似的图像。购物网站根据特定产品的选择提供产品建议（通过图像），例如，显示与用户选择的鞋子相似的各种鞋子。图1.11展示了服装搜索的一个例子。
- en: '![](../Images/1-11.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-11](../Images/1-11.png)'
- en: 'Figure 1.11 Apparel search. The leftmost image in each row is the query/clicked
    image, and the subsequent columns show similar apparel. (Source: Liu et al., 2016.)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11 服装搜索。每行最左边的图像是查询/点击的图像，后续的列显示了相似的服装。（来源：刘等，2016年。）
- en: '1.3 Computer vision pipeline: The big picture'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 计算机视觉流程：全景
- en: 'Okay, now that I have your attention, let’s dig one level deeper into CV systems.
    Remember that earlier in this chapter, we discussed how vision systems are composed
    of two main components: sensing devices and interpreting devices (figure 1.12
    offers a reminder). In this section, we will take a look at the pipeline the interpreting
    device component uses to process and understand images.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我已经吸引了你的注意，让我们深入一层了解计算机视觉系统。记住，在本章前面，我们讨论了视觉系统由两个主要组件组成：感知设备和解释设备（图1.12提供了一个提醒）。在本节中，我们将探讨解释设备组件用于处理和理解图像的流程。
- en: '![](../Images/1-12.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-12](../Images/1-12.png)'
- en: Figure 1.12 Focusing on the interpreting device in computer vision systems
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.12 关注计算机视觉系统中的解释设备
- en: Applications of CV vary, but a typical vision system uses a sequence of distinct
    steps to process and analyze image data. These steps are referred to as a computer
    vision pipeline. Many vision applications follow the flow of acquiring images
    and data, processing that data, performing some analysis and recognition steps,
    and then finally making a prediction based on the extracted information (figure
    1.13).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉的应用多种多样，但典型的视觉系统使用一系列不同的步骤来处理和分析图像数据。这些步骤被称为计算机视觉流程。许多视觉应用遵循获取图像和数据、处理这些数据、执行一些分析和识别步骤，然后基于提取的信息进行预测的流程（见图1.13）。
- en: '![](../Images/1-13.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-13](../Images/1-13.png)'
- en: Figure 1.13 The computer vision pipeline, which takes input data, processes
    it, extracts information, and then sends it to the machine learning model to learn
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.13 计算机视觉流程，它接收输入数据，处理它，提取信息，然后将它发送到机器学习模型进行学习
- en: 'Let’s apply the pipeline in figure 1.13 to an image classifier example. Suppose
    we have an image of a motorcycle, and we want the model to predict the probability
    of the object from the following classes: motorcycle, car, and dog (see figure
    1.14).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将图1.13中的流程应用于图像分类器示例。假设我们有一张摩托车的图片，我们希望模型从以下类别中预测该对象的可能性：摩托车、汽车和狗（见图1.14）。
- en: '![](../Images/1-14.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图片1-14](../Images/1-14.png)'
- en: Figure 1.14 Using the machine learning model to predict the probability of the
    motorcycle object from the motorcycle, car, and dog classes
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.14 使用机器学习模型从摩托车、汽车和狗类别预测摩托车对象的可能性
- en: DEFINITIONS An image classifier is an algorithm that takes in an image as input
    and outputs a label or “class” that identifies that image. A class (also called
    a category) in machine learning is the output category of your data.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 定义：图像分类器是一种算法，它接收图像作为输入，并输出一个标签或“类别”，以识别该图像。在机器学习中，类别（也称为类别）是数据的输出类别。
- en: 'Here is how the image flows through the classification pipeline:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这是图像通过分类管道的流程：
- en: A computer receives visual input from an imaging device like a camera. This
    input is typically captured as an image or a sequence of images forming a video.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算机从像相机这样的成像设备接收视觉输入。这种输入通常以图像或形成视频的图像序列的形式捕获。
- en: Each image is then sent through some preprocessing steps whose purpose is to
    standardize the images. Common preprocessing steps include resizing an image,
    blurring, rotating, changing its shape, or transforming the image from one color
    to another, such as from color to grayscale. Only by standardizing the images--for
    example, making them the same size--can you then compare them and further analyze
    them.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后每个图像都会通过一些预处理步骤，其目的是标准化图像。常见的预处理步骤包括调整图像大小、模糊、旋转、改变其形状，或者将图像从一种颜色转换到另一种颜色，例如从彩色转换为灰度。只有通过标准化图像——例如，使它们具有相同的大小——你才能然后比较它们并进一步分析它们。
- en: We extract features. Features are what help us define objects, and they are
    usually information about object shape or color. For example, some features that
    distinguish a motorcycle are the shape of the wheels, headlights, mudguards, and
    so on. The output of this process is a feature vector that is a list of unique
    shapes that identify the object.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们提取特征。特征是我们定义对象的东西，它们通常是关于对象形状或颜色的信息。例如，区分摩托车的一些特征是车轮的形状、车头灯、泥板等。这个过程输出的结果是特征向量，它是一系列独特的形状列表，用于识别对象。
- en: 'The features are fed into a classification model. This step looks at the feature
    vector from the previous step and predicts the class of the image. Pretend that
    you are the classifier model for a few minutes, and let’s go through the classification
    process. You look at the list of features in the feature vector one by one and
    try to determine what’s in the image:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征被输入到分类模型中。这一步查看前一步的特征向量并预测图像的类别。假设你是一名分类器模型几分钟，让我们通过分类过程。你逐个查看特征向量中的特征列表，并试图确定图像中有什么：
- en: First you see a wheel feature; could this be a car, a motorcycle, or a dog?
    Clearly it is not a dog, because dogs don’t have wheels (at least, normal dogs,
    not robots). Then this could be an image of a car or a motorcycle.
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先你看到一个轮子特征；这可能是一辆汽车、一辆摩托车还是一只狗？显然它不是狗，因为狗没有轮子（至少，正常的狗，不是机器人）。然后这可能是一张汽车或摩托车的照片。
- en: You move on to the next feature, the headlights. There is a higher probability
    that this is a motorcycle than a car.
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你继续到下一个特征，即车头灯。它更有可能是摩托车而不是汽车。
- en: The next feature is rear mudguards --again, there is a higher probability that
    it is a motorcycle.
  id: totrans-123
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个特征是后泥板——同样，它更有可能是摩托车。
- en: The object has only two wheels; this is closer to a motorcycle.
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个物体只有两个轮子；这更接近于摩托车。
- en: And you keep going through all the features like the body shape, pedal, and
    so on, until you arrive at a best guess of the object in the image.
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你继续分析所有特征，如车身形状、踏板等，直到你到达对图像中物体的最佳猜测。
- en: The output of this process is the probability of each class. As you can see
    in our example, the dog has the lowest probability, 1%, whereas there is an 85%
    probability that this is a motorcycle. You can see that, although the model was
    able to predict the right class with the highest probability, it is still a little
    confused about distinguishing between cars and motorcycles--it predicted that
    there is a 14% chance this is an image of a car. Since we know that it is a motorcycle,
    we can say that our ML classification algorithm is 85% accurate. Not bad! To improve
    this accuracy, we may need to do more of step 1 (acquire more training images),
    or step 2 (more processing to remove noise), or step 3 (extract better features),
    or step 4 (change the classifier algorithm and tune some hyperparameters), or
    even allow more training time. The many different approaches we can take to improve
    the performance of our model all lie in one or more of the pipeline steps.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的输出是每个类别的概率。正如你在我们的例子中所看到的，狗的概率最低，只有1%，而这是一个摩托车的概率是85%。你可以看到，尽管模型能够以最高的概率预测正确的类别，但它仍然对区分汽车和摩托车有些困惑——它预测有14%的可能性这是一张汽车的照片。既然我们知道它是一辆摩托车，我们可以说我们的机器学习分类算法的准确率是85%。还不错！为了提高这个准确率，我们可能需要做更多步骤1（获取更多的训练图像），或者步骤2（更多的处理以去除噪声），或者步骤3（提取更好的特征），或者步骤4（更改分类器算法并调整一些超参数），或者甚至允许更多的训练时间。我们可以采取的许多不同方法来提高我们模型的表现力都包含在一个或多个的管道步骤中。
- en: That was the big picture of how images flow through the CV pipeline. Next, we’ll
    zoom in one level deeper on each of the pipeline steps.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 那是图像如何在CV管道中流动的大致情况。接下来，我们将深入探讨管道的每个步骤。
- en: 1.4 Image input
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 图像输入
- en: In CV applications, we deal with images or video data. Let’s talk about grayscale
    and color images for now, and in later chapters, we will talk about videos, since
    videos are just stacked sequential frames of images.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在CV应用中，我们处理图像或视频数据。现在让我们谈谈灰度图像和彩色图像，在后面的章节中，我们将讨论视频，因为视频只是图像的堆叠顺序帧。
- en: 1.4.1 Image as functions
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.1 图像作为函数
- en: An image can be represented as a function of two variables *x* and y, which
    define a two-dimensional area. A digital image is made of a grid of pixels. The
    pixel is the raw building block of an image. Every image consists of a set of
    pixels in which their values represent the intensity of light that appears in
    a given place in the image. Let’s take a look at the motorcycle example again
    after applying the pixel grid to it (figure 1.15).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一张图像可以被表示为两个变量 *x* 和 y 的函数，它们定义了一个二维区域。数字图像由像素网格组成。像素是图像的基本构建块。每个图像都由一组像素组成，这些像素的值代表图像中特定位置的光强度。让我们再次看看摩托车示例，在应用像素网格后（图1.15）。
- en: '![](../Images/1-15.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-15.png)'
- en: Figure 1.15 Images consists of raw building blocks called pixels. The pixel
    values represent the intensity of light that appears in a given place in the image.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.15 图像由称为像素的原始构建块组成。像素值代表图像中特定位置出现的光强度。
- en: The image in figure 1.14 has a size of 32 × 16\. This means the dimensions of
    the image are 32 pixels wide and 16 pixels tall. The x-axis goes from 0 to 31,
    and the y-axis from 0 to 16\. Overall, the image has 512 (32 × 16) pixels. In
    this grayscale image, each pixel contains a value that represents the intensity
    of light on that specific pixel. The pixel values range from 0 to 255\. Since
    the pixel value represents the intensity of light, the value 0 represents very
    dark pixels (black), 255 is very bright (white), and the values in between represent
    the intensity on the grayscale.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.14中的图像大小为 32 × 16。这意味着图像的尺寸是 32 像素宽和 16 像素高。x轴从 0 到 31，y轴从 0 到 16。总的来说，该图像有
    512（32 × 16）个像素。在这张灰度图像中，每个像素包含一个值，代表该特定像素上的光强度。像素值范围从 0 到 255。由于像素值代表光强度，值 0
    代表非常暗的像素（黑色），255代表非常亮（白色），而中间的值代表灰度上的强度。
- en: 'You can see that the image coordinate system is similar to the Cartesian coordinate
    system: images are two-dimensional and lie on the x-y plane. The origin (0, 0)
    is at the top left of the image. To represent a specific pixel, we use the following
    notations: F as a function, and x, *y* as the location of the pixel in x- and
    y-coordinates. For example, the pixel located at *x* = 12 and *y* = 13 is white;
    this is represented by the following function: F(12, 13) = 255\. Similarly, the
    pixel (20, 7) that lies on the front of the motorcycle is black, represented as
    F(20, 7) = 0.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到图像坐标系与笛卡尔坐标系相似：图像是二维的，位于x-y平面上。原点（0, 0）位于图像的左上角。为了表示特定的像素，我们使用以下符号：F作为函数，x，*y*作为像素在x和y坐标中的位置。例如，位于
    *x* = 12 和 *y* = 13 的像素是白色的；这由以下函数表示：F(12, 13) = 255。同样，位于摩托车前部的像素（20, 7）是黑色的，表示为
    F(20, 7) = 0。
- en: '[PRE0]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: That was for grayscale images. How about color images?
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 那是关于灰度图像的情况。彩色图像又是如何呢？
- en: 'In color images, instead of representing the value of the pixel by just one
    number, the value is represented by three numbers representing the intensity of
    each color in the pixel. In an RGB system, for example, the value of the pixel
    is represented by three numbers: the intensity of red, intensity of green, and
    intensity of blue. There are other color systems for images like HSV and Lab.
    All follow the same concept when representing the pixel value (more on color images
    soon). Here is the function representing color images in the RGB system:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在彩色图像中，不是只用一个数字来表示像素的值，而是用三个数字来表示像素中每种颜色的强度。例如，在RGB系统中，像素的值由三个数字表示：红色强度、绿色强度和蓝色强度。图像还有其他颜色系统，如HSV和Lab。所有这些在表示像素值时都遵循相同的概念（关于彩色图像的更多内容将在后面讨论）。以下是RGB系统中表示彩色图像的函数：
- en: '[PRE1]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Thinking of an image as a function is very useful in image processing. We can
    think of an image as a function of F(*x, y*) and operate on it mathematically
    to transform it to a new image function G(*x, y*). Let’s take a look at the image
    transformation examples in table 1.1.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 将图像视为一个函数在图像处理中非常有用。我们可以将图像视为F(*x, y*)的函数，并在数学上对其操作以将其转换为新的图像函数G(*x, y*)。让我们看看表1.1中的图像变换示例。
- en: Table 1.1 Image transformation example functions
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.1 图像变换示例函数
- en: '| Application | Transformation |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 应用 | 变换 |'
- en: '| Darken the image. | `G(*x, y*) = 0.5 * F(*x, y*)` |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 使图像变暗。 | `G(*x, y*) = 0.5 * F(*x, y*)` |'
- en: '| Brighten the image. | `G(*x, y*) = 2 * F(*x, y*)` |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 使图像变亮。 | `G(*x, y*) = 2 * F(*x, y*)` |'
- en: '| Move an object down 150 pixels. | `G(*x, y*) = F(x, *y* + 150)` |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 将对象向下移动150个像素。 | `G(*x, y*) = F(x, *y* + 150)` |'
- en: '| Remove the gray in an image to transform the image into black and white.
    | `G(*x, y*) = { 0 if F(*x, y*) < 130, 255 otherwise }` |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 将图像中的灰色去除以将图像转换为黑白。 | `G(*x, y*) = { 0 if F(*x, y*) < 130, 255 otherwise
    }` |'
- en: 1.4.2 How computers see images
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.2 计算机如何识别图像
- en: When we look at an image, we see objects, landscape, colors, and so on. But
    that’s not the case with computers. Consider figure 1.16\. Your human brain can
    process it and immediately know that it is a picture of a motorcycle. To a computer,
    the image looks like a 2D matrix of the pixels’ values, which represent intensities
    across the color spectrum. There is no context here, just a massive pile of data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们看图像时，我们看到物体、风景、颜色等等。但计算机并不是这样。考虑图1.16。你的人类大脑可以处理它，并立即知道这是一张摩托车图片。对于计算机来说，图像看起来像像素值的2D矩阵，这些值代表颜色光谱中的强度。这里没有上下文，只是一大堆数据。
- en: '![](../Images/1-16.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-16.png)'
- en: Figure 1.16 A computer sees images as matrices of values. The values represent
    the intensity of the pixels across the color spectrum. For example, grayscale
    images range between pixel values of 0 for black and 255 for white.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.16 计算机将图像视为值的矩阵。这些值代表像素在颜色光谱中的强度。例如，灰度图像的像素值范围在0（黑色）到255（白色）之间。
- en: 'The image in figure 1.16 is of size 24 × 24\. This size indicates the width
    and height of the image: there are 24 pixels horizontally and 24 vertically. That
    means there is a total of 576 (24 × 24) pixels. If the image is 700 × 500, then
    the dimensionality of the matrix will be (700, 500), where each pixel in the matrix
    represents the intensity of brightness in that pixel. Zero represents black, and
    255 represents white.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.16中的图像大小为24 × 24。这个大小表示图像的宽度和高度：水平方向有24个像素，垂直方向也有24个像素。这意味着总共有576（24 × 24）个像素。如果图像大小为700
    × 500，那么矩阵的维度将是（700，500），其中矩阵中的每个像素代表该像素的亮度强度。0代表黑色，255代表白色。
- en: 1.4.3 Color images
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4.3 彩色图像
- en: 'In grayscale images, each pixel represents the intensity of only one color,
    whereas in the standard RGB system, color images have three channels (red, green,
    and blue). In other words, color images are represented by three matrices: one
    represents the intensity of red in the pixel, one represents green, and one represents
    blue (figure 1.17).'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在灰度图像中，每个像素只代表一种颜色的强度，而在标准的RGB系统中，彩色图像有三个通道（红色、绿色和蓝色）。换句话说，彩色图像由三个矩阵表示：一个表示像素中红色的强度，一个表示绿色，一个表示蓝色（图1.17）。
- en: '![](../Images/1-17.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-17.png)'
- en: Figure 1.17 Color images are represented by red, green, and blue channels, and
    matrices can be used to indicate those colors’ intensity.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.17 彩色图像由红色、绿色和蓝色通道表示，矩阵可以用来表示这些颜色的强度。
- en: 'As you can see in figure 1.17, the color image is composed of three channels:
    red, green, and blue. Now the question is, how do computers see this image? Again,
    they see the matrix, unlike grayscale images, where we had only one channel. In
    this case, we will have three matrices stacked on top of each other; that’s why
    it’s a 3D matrix. The dimensionality of 700 × 700 color images is (700, 700, 3).
    Let’s say the first matrix represents the red channel; then each element of that
    matrix represents an intensity of red color in that pixel, and likewise with green
    and blue. Each pixel in a color image has three numbers (0 to 255) associated
    with it. These numbers represent intensity of red, green, and blue color in that
    particular pixel.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如图1.17所示，彩色图像由三个通道组成：红色、绿色和蓝色。现在的问题是，计算机是如何看到这张图像的？同样，它们看到的是一个矩阵，与只有单一通道的灰度图像不同。在这种情况下，我们将有三个矩阵堆叠在一起；这就是为什么它是一个3D矩阵。700×700彩色图像的维度是（700,
    700, 3）。假设第一个矩阵代表红色通道；那么该矩阵的每个元素代表该像素中红色颜色的强度，绿色和蓝色同理。彩色图像中的每个像素都与三个数字（0到255）相关联。这些数字代表该特定像素中红色、绿色和蓝色的强度。
- en: If we take the pixel (0,0) as an example, we will see that it represents the
    top-left pixel of the image of green grass. When we view this pixel in the color
    images, it looks like figure 1.18\. The example in figure 1.19 shows some shades
    of the color green and their RGB values.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 以像素（0,0）为例，我们可以看到它代表的是绿色草地的左上角像素。当我们查看这个像素在彩色图像中的样子时，它看起来就像图1.18所示。图1.19中的例子展示了绿色的一些色调及其RGB值。
- en: How do computers see color?
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机是如何看到颜色的？
- en: 'Computers see an image as matrices. Grayscale images have one channel (gray);
    thus, we can represent grayscale images in a 2D matrix, where each element represents
    the intensity of brightness in that particular pixel. Remember, 0 means black
    and 255 means white. Grayscale images have one channel, whereas color images have
    three channels: red, green, and blue. We can represent color images in a 3D matrix
    where the depth is three.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机将图像视为矩阵。灰度图像有一个通道（灰色）；因此，我们可以用二维矩阵来表示灰度图像，其中每个元素代表该特定像素的亮度强度。记住，0代表黑色，255代表白色。灰度图像有一个通道，而彩色图像有三个通道：红色、绿色和蓝色。我们可以用三维矩阵来表示彩色图像，其中深度为三。
- en: We’ve also seen how images can be treated as functions of space. This concept
    allows us to operate on images mathematically and change or extract information
    from them. Treating images as functions is the basis of many image-processing
    techniques, such as converting color to grayscale or scaling an image. Each of
    these steps is just operating mathematical equations to transform an image pixel
    by pixel.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也看到了图像如何被当作空间函数来处理。这个概念使我们能够在数学上操作图像，并从中改变或提取信息。将图像视为函数是许多图像处理技术的基础，例如将彩色转换为灰度或缩放图像。这些步骤只是通过数学方程对图像像素进行逐像素的转换。
- en: 'Grayscale: *f*(*x, y*) gives the intensity at position (*x, y*)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 灰度图：*f*(*x, y*)给出位置(*x, y*)的强度
- en: 'Color image: *f*(*x, y*) = [ red (*x, y*), green (*x, y*), blue (*x, y*) ]'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 彩色图像：*f*(*x, y*) = [红色(*x, y*)，绿色(*x, y*)，蓝色(*x, y*)]
- en: '![](../Images/1-unnumb-3a.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-unnumb-3a.png)'
- en: An image of green grass is actually made of three colors of varying intensity.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 绿色草地的图像实际上是由不同强度的三种颜色组成的。
- en: '![](../Images/1-19.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-19.png)'
- en: Figure 1.19 Different shades of green mean different intensities of the three
    image colors (red, green, blue).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.19展示了不同深度的绿色代表三种图像颜色（红色、绿色、蓝色）的不同强度。
- en: 1.5 Image preprocessing
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 图像预处理
- en: In machine learning (ML) projects, you usually go through a data preprocessing
    or cleaning step. As an ML engineer, you will spend a good amount of time cleaning
    up and preparing the data before you build your learning model. The goal of this
    step is to make your data ready for the ML model to make it easier to analyze
    and process computationally. The same thing is true with images. Based on the
    problem you are solving and the dataset in hand, some data massaging is required
    before you feed your images to the ML model.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）项目中，你通常会经历一个数据预处理或清洗步骤。作为一名机器学习工程师，在构建学习模型之前，你将花费大量时间清理和准备数据。这一步骤的目标是使数据准备好，以便机器学习模型更容易分析和处理。对于图像来说，也是如此。根据你要解决的问题和手头的数据集，在将图像输入机器学习模型之前，可能需要进行一些数据整理。
- en: Image processing could involve simple tasks like image resizing. Later, you
    will learn that in order to feed a dataset of images to a convolutional network,
    the images all have to be the same size. Other processing tasks can take place,
    like geometric and color transformation, converting color to grayscale, and many
    more. We will cover various image-processing techniques throughout the chapters
    of this book and in the projects.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图像处理可能涉及简单的任务，如图像缩放。稍后，您将了解到为了将图像数据集输入到卷积网络中，所有图像都必须具有相同的大小。其他处理任务也可以进行，如几何和颜色变换、将颜色转换为灰度等。本书的章节和项目中我们将涵盖各种图像处理技术。
- en: The acquired data is usually messy and comes from different sources. To feed
    it to the ML model (or neural network), it needs to be standardized and cleaned
    up. Preprocessing is used to conduct steps that will reduce the complexity and
    increase the accuracy of the applied algorithm. We can’t write a unique algorithm
    for each of the conditions in which an image is taken; thus, when we acquire an
    image, we convert it into a form that would allow a general algorithm to solve
    it. The following subsections describe some data-preprocessing techniques.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 获得的数据通常很杂乱，来自不同的来源。为了将其输入到机器学习模型（或神经网络）中，它需要被标准化和清理。预处理用于执行将减少算法复杂度并提高准确性的步骤。我们不能为图像拍摄的每种条件编写一个独特的算法；因此，当我们获取图像时，我们将其转换为一种形式，以便通用的算法可以解决它。以下小节描述了一些数据预处理技术。
- en: 1.5.1 Converting color images to grayscale to reduce computation complexity
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.5.1 将彩色图像转换为灰度图像以降低计算复杂性
- en: Sometimes you will find it useful to remove unnecessary information from your
    images to reduce space or computational complexity. For example, suppose you want
    to convert your colored images to grayscale, because for many objects, color is
    not necessary to recognize and interpret an image. Grayscale can be good enough
    for recognizing certain objects. Since color images contain more information than
    black-and-white images, they can add unnecessary complexity and take up more space
    in memory. Remember that color images are represented in three channels, which
    means that converting them to grayscale will reduce the number of pixels that
    need to be processed (figure 1.20).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，您可能会发现从图像中删除不必要的信 息以减少空间或计算复杂度很有用。例如，假设您想将彩色图像转换为灰度图像，因为对于许多物体来说，颜色并不是识别和解释图像所必需的。灰度图像可能足以识别某些物体。由于彩色图像包含比黑白图像更多的信息，它们可能会增加不必要的复杂性，并在内存中占用更多空间。请记住，彩色图像以三个通道表示，这意味着将它们转换为灰度图像将减少需要处理的像素数量（图1.20）。
- en: '![](../Images/1-20.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-20.png)'
- en: Figure 1.20 Converting color images to grayscale results in a reduced number
    of pixels that need to be processed. This could be a good approach for applications
    that do not rely a lot on the color information loss due to the conversion.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.20 将彩色图像转换为灰度图像会减少需要处理的像素数量。这对于不依赖于颜色信息损失的应用程序来说可能是一个好的方法。
- en: In this example, you can see how patterns of brightness and darkness (intensity)
    can be used to define the shape and characteristics of many objects. However,
    in other applications, color is important to define certain objects, like skin
    cancer detection, which relies heavily on skin color (red rashes).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，您可以看到如何使用亮度和暗度（强度）的模式来定义许多物体的形状和特征。然而，在其他应用中，颜色对于定义某些物体很重要，例如皮肤癌检测，它严重依赖于皮肤颜色（红色皮疹）。
- en: '*Standardizing images* --As you will see in chapter 3, one important constraint
    that exists in some ML algorithms, such as CNNs, is the need to resize the images
    in your dataset to unified dimensions. This implies that your images must be preprocessed
    and scaled to have identical widths and heights before being fed to the learning
    algorithm.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*标准化图像* ——正如您将在第3章中看到的那样，某些机器学习算法（如CNN）存在的一个重要约束是，需要将数据集中的图像调整到统一的尺寸。这意味着在将图像输入到学习算法之前，您的图像必须进行预处理并缩放，以具有相同的宽度和高度。'
- en: When is color important?
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 何时颜色很重要？
- en: 'Converting an image to grayscale might not be a good decision for some problems.
    There are a number of applications for which color is very important: for example,
    building a diagnostic system to identify red skin rashes in medical images. This
    application relies heavily on the intensity of the red color in the skin. Removing
    colors from the image will make it harder to solve this problem. In general, color
    images provide very helpful information in many medical applications.'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将图像转换为灰度可能不是某些问题的好选择。有一些应用中颜色非常重要：例如，在医学图像中建立一个诊断系统来识别红色皮肤疹。这个应用严重依赖于皮肤中红色颜色的强度。从图像中移除颜色将使解决这个问题更加困难。一般来说，彩色图像在许多医学应用中提供了非常有帮助的信息。
- en: Another example of the importance of color in images is lane-detection applications
    in a self-driving car, where the car has to identify the difference between yellow
    and white lines, because they are treated differently. Grayscale images do not
    provide enough information to distinguish between the yellow and white lines.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图像中颜色重要性的另一个例子是自动驾驶汽车中的车道检测应用，其中汽车必须区分黄色和白色线条，因为它们被处理方式不同。灰度图像无法提供足够的信息来区分黄色和白色线条。
- en: '![](../Images/1-unnumb-3b.png)'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](../Images/1-unnumb-3b.png)'
- en: Grayscale-based image processors cannot differentiate between color images.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于灰度的图像处理器无法区分彩色图像。
- en: The rule of thumb to identify the importance of colors in your problem is to
    look at the image with the human eye. If you are able to identify the object you
    are looking for in a gray image, then you probably have enough information to
    feed to your model. If not, then you definitely need more information (colors)
    for your model. The same rule can be applied for most other preprocessing techniques
    that we will discuss.
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 识别问题中颜色重要性的经验法则是用肉眼观察图像。如果你能够在灰度图像中识别你正在寻找的对象，那么你可能已经提供了足够的信息给你的模型。如果不能，那么你的模型肯定需要更多的信息（颜色）。同样的规则可以应用于我们将要讨论的大多数其他预处理技术。
- en: '*Data augmentation* --Another common preprocessing technique involves augmenting
    the existing dataset with modified versions of the existing images. Scaling, rotations,
    and other affine transformations are typically used to enlarge your dataset and
    expose the neural network to a wide variety of variations of your images. This
    makes it more likely that your model will recognize objects when they appear in
    any form and shape. Figure 1.21 shows an example of image augmentation applied
    to a butterfly image.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据增强* --另一种常见的预处理技术是将现有数据集与现有图像的修改版本相结合。缩放、旋转和其他仿射变换通常用于扩大你的数据集，使神经网络接触到你图像的广泛变化。这使得你的模型更有可能在任何形式和形状中出现时识别对象。图1.21展示了应用于蝴蝶图像的图像增强的一个例子。'
- en: '![](../Images/1-21.png)'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图片](../Images/1-21.png)'
- en: Figure 1.21 Image-augmentation techniques create modified versions of the input
    image to provide more examples for the ML model to learn from.
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.21 图像增强技术创建了输入图像的修改版本，为机器学习模型提供更多学习样本。
- en: Other techniques --Many more preprocessing techniques are available to get your
    images ready for training an ML model. In some projects, you might need to remove
    the background color from your images to reduce noise. Other projects might require
    that you brighten or darken your images. In short, any adjustments that you need
    to apply to your dataset are part of preprocessing. You will select the appropriate
    processing techniques based on the dataset at hand and the problem you are solving.
    You will see many image-processing techniques throughout this book, helping you
    build your intuition of which ones you need when working on your own projects.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他技术 --有许多预处理技术可供选择，以便为训练机器学习模型准备你的图像。在某些项目中，你可能需要从你的图像中移除背景颜色以减少噪声。在其他项目中，可能需要你调整图像的亮度或暗度。简而言之，你需要应用到数据集上的任何调整都是预处理的一部分。你将根据手头的数据集和你要解决的问题选择合适的处理技术。在这本书中，你将看到许多图像处理技术，这有助于你建立自己在项目工作中需要哪些技术的直觉。
- en: No free lunch theorem
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 免费午餐定理
- en: This is a phrase that was introduced by David Wolpert and William Macready in
    “No Free Lunch Theorems for Optimizations” (IEEE Transactions on Evolutionary
    Computation 1, 67). You will often hear this said when a team is working on an
    ML project. It means that no one prescribed recipe fits all models. When working
    on ML projects, you will need to make many choices like building your neural network
    architecture, tuning hyperparameters, and applying the appropriate data preprocessing
    techniques. While there are some rule-of-thumb approaches to tackle certain problems,
    there is really no single recipe that is guaranteed to work well in all situations.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个由David Wolpert和William Macready在“优化中的无免费午餐定理”（IEEE Transactions on Evolutionary
    Computation 1, 67）中提出的短语。当团队在机器学习项目中工作时，你经常会听到这句话。这意味着没有一种规定的食谱适合所有模型。在机器学习项目中工作时，你需要做出许多选择，比如构建你的神经网络架构、调整超参数以及应用适当的数据预处理技术。虽然有一些经验法则可以解决某些问题，但事实上并没有一种保证在所有情况下都能有效工作的单一食谱。
- en: You must make certain assumptions about the dataset and the problem you are
    trying to solve. For some datasets, it is best to convert the colored images to
    grayscale, while for other datasets, you might need to keep or adjust the color
    images.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须对你正在尝试解决的问题的数据集和问题做出某些假设。对于某些数据集，最好将彩色图像转换为灰度图像，而对于其他数据集，你可能需要保留或调整彩色图像。
- en: The good news is that, unlike traditional machine learning, DL algorithms require
    minimum data preprocessing because, as you will see soon, neural networks do most
    of the heavy lifting in processing an image and extracting features.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，与传统的机器学习不同，深度学习算法需要最少的数据预处理，因为正如你很快就会看到的，神经网络在处理图像和提取特征方面做了大部分繁重的工作。
- en: 1.6 Feature extraction
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.6 特征提取
- en: Feature extraction is a core component of the CV pipeline. In fact, the entire
    DL model works around the idea of extracting useful features that clearly define
    the objects in the image. So we’ll spend a little more time here, because it is
    important that you understand what a feature is, what a vector of features is,
    and why we extract features.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提取是CV流程的核心组件。实际上，整个深度学习模型都是围绕提取有用特征的想法展开的，这些特征可以清楚地定义图像中的对象。因此，我们将在这里花更多的时间，因为了解什么是特征、什么是特征向量以及为什么我们要提取特征是非常重要的。
- en: 'DEFINITION A feature in machine learning is an individual measurable property
    or characteristic of an observed phenomenon. Features are the input that you feed
    to your ML model to output a prediction or classification. Suppose you want to
    predict the price of a house: your input features (properties) might include `square_foot`,
    `number_of_rooms`, `bathrooms`, and so on, and the model will output the predicted
    price based on the values of your features. Selecting good features that clearly
    distinguish your objects increases the predictive power of ML algorithms.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 在机器学习中，特征是观察现象的个别可测量属性或特征。特征是你输入到你的机器学习模型中以输出预测或分类的数据。假设你想预测房屋的价格：你的输入特征（属性）可能包括`square_foot`（面积）、`number_of_rooms`（房间数）、`bathrooms`（浴室数量）等，模型将根据你的特征值输出预测价格。选择能够清楚地区分你的对象的良好特征可以增加机器学习算法的预测能力。
- en: 1.6.1 What is a feature in computer vision?
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6.1 计算机视觉中的特征是什么？
- en: In CV, a feature is a measurable piece of data in your image that is unique
    to that specific object. It may be a distinct color or a specific shape such as
    a line, edge, or image segment. A good feature is used to distinguish objects
    from one another. For example, if I give you a feature like a wheel and ask you
    to guess whether an object is a motorcycle or a dog, what would your guess be?
    A motorcycle. Correct! In this case, the wheel is a strong feature that clearly
    distinguishes between motorcycles and dogs. However, if I give you the same feature
    (a wheel) and ask you to guess whether an object is a bicycle or a motorcycle,
    this feature is not strong enough to distinguish between those objects. You need
    to look for more features like a mirror, license plate, or maybe a pedal, that
    collectively describe an object. In ML projects, we want to transform the raw
    data (image) into a feature vector to show to our learning algorithm, which can
    learn the characteristics of the object (figure 1.22).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉（CV）中，一个特征是图像中一个可测量的数据片段，它对该特定物体是独特的。它可能是一种独特的颜色或特定的形状，如线条、边缘或图像片段。一个好的特征被用来区分不同的物体。例如，如果我给你一个像轮子这样的特征，并让你猜测一个物体是摩托车还是狗，你会怎么猜？摩托车。正确！在这种情况下，轮子是一个强大的特征，它清楚地区分了摩托车和狗。然而，如果我给你同样的特征（一个轮子）并让你猜测一个物体是自行车还是摩托车，这个特征就不足以区分这些物体。你需要寻找更多像镜子、车牌或可能还有踏板这样的特征，这些特征共同描述了一个物体。在机器学习（ML）项目中，我们希望将原始数据（图像）转换成特征向量，以展示给我们的学习算法，这样算法就可以学习物体的特征（图1.22）。
- en: '![](../Images/1-22.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-22.png)'
- en: Figure 1.22 Example input image fed to a feature-extraction algorithm to find
    patterns within the image and create the feature vector
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.22 示例输入图像被输入到特征提取算法中，以在图像中找到模式并创建特征向量
- en: In the figure, we feed the raw input image of a motorcycle into a feature extraction
    algorithm. Let’s treat the feature extraction algorithm as a black box for now,
    and we will come back to it. For now, we need to know that the extraction algorithm
    produces a vector that contains a list of features. This feature vector is a 1D
    array that makes a robust representation of the object.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，我们将摩托车原始输入图像输入到特征提取算法中。现在，让我们将特征提取算法视为一个黑盒，我们稍后再来讨论它。现在，我们需要知道提取算法产生一个包含特征列表的向量。这个特征向量是一个一维数组，它对物体提供了一个稳健的表示。
- en: Feature generalizability
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 特征泛化能力
- en: It is important to point out that figure 1.22 reflects features extracted from
    just one motorcycle. A very important characteristic of a feature is repeatability.
    The feature should be able to detect motorcycles in general, not just this specific
    one. So in real-world problems, a feature is not an exact copy of a piece of the
    input image.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 需要强调的是，图1.22 反映的是仅从一辆摩托车中提取的特征。一个特征的重要特性是可重复性。特征应该能够检测到一般的摩托车，而不仅仅是这一特定的摩托车。因此，在现实世界的问题中，一个特征并不是输入图像中某一部分的精确副本。
- en: '![](../Images/1-unnumb-4K.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-unnumb-4K.png)'
- en: Features need to detect general patterns.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 特征需要检测一般模式。
- en: If we take the wheel feature, for example, the feature doesn’t look exactly
    like the wheel of one particular motorcycle. Instead, it looks like a circular
    shape with some patterns that identify wheels in all images in the training dataset.
    When the feature extractor sees thousands of images of motorcycles, it recognizes
    patterns that define wheels in general, regardless of where they appear in the
    image and what type of motorcycle they are part of.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 以轮子特征为例，这个特征并不完全像某一特定摩托车的轮子。相反，它看起来像是一个带有一些识别训练数据集中所有图像中轮子的模式的圆形形状。当特征提取器看到成千上万张摩托车的图像时，它识别出定义一般轮子的模式，而不管它们在图像中的位置和它们属于哪种类型的摩托车。
- en: 1.6.2 What makes a good (useful) feature?
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6.2 什么因素使一个特征（有用的）变得好？
- en: Machine learning models are only as good as the features you provide. That means
    coming up with good features is an important job in building ML models. But what
    makes a good feature? And how can you tell?
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型的好坏取决于你提供的特征。这意味着提出好的特征是构建机器学习模型的重要工作。但什么因素使一个特征变得好？你如何判断？
- en: 'Let’s discuss this with an example. Suppose we want to build a classifier to
    tell the difference between two types of dogs: Greyhound and Labrador. Let’s take
    two features--the dogs’ height and their eye color--and evaluate them (figure
    1.23).'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个例子来讨论这个问题。假设我们想要构建一个分类器来区分两种类型的狗：灰狗和拉布拉多。让我们选取两个特征——狗的高度和它们的眼睛颜色——并对它们进行评估（图1.23）。
- en: '![](../Images/1-23.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-23.png)'
- en: Figure 1.23 Example of Greyhound and Labrador dogs
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.23 灰狗和拉布拉多狗的例子
- en: Let’s begin with height. How useful do you think this feature is? Well, on average,
    Greyhounds tend to be a couple of inches taller than Labradors, but not always.
    There is a lot of variation in the dog world. So let’s evaluate this feature across
    different values in both breeds’ populations. Let’s visualize the height distribution
    on a toy example in the histogram in figure 1.24.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从高度开始。你认为这个特征有多有用？嗯，平均来说，灰狗通常比拉布拉多高几英寸，但并不总是这样。狗的世界中有很多变化。所以让我们评估这两种品种群体中不同值上的这个特征。让我们在图1.24中的直方图上可视化玩具例子中的高度分布。
- en: '![](../Images/1-24.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-24.png)'
- en: Figure 1.24 A visualization of the height distribution on a toy dogs dataset
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.24 玩具狗数据集上高度分布的可视化
- en: 'From the histogram, we can see that if the dog’s height is 20 inches or less,
    there is more than an 80% probability that the dog is a Labrador. On the other
    side of the histogram, if we look at dogs that are taller than 30 inches, we can
    be pretty confident the dog is a Greyhound. Now, what about the data in the middle
    of the histogram (heights from 20 to 30 inches)? We can see that the probability
    of each type of dog is pretty close. The thought process in this case is as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 从直方图上，我们可以看到，如果狗的高度是20英寸或更少，有超过80%的概率这只狗是拉布拉多。在直方图的另一边，如果我们看那些身高超过30英寸的狗，我们可以相当有信心地说这只狗是灰狗。那么，关于直方图中间的数据（20到30英寸的高度）呢？我们可以看到，每种类型狗的概率相当接近。在这种情况下，思考过程如下：
- en: 'if height ≤ 20:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如果高度 ≤ 20：
- en: return higher probability to Labrador
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 返回更高的拉布拉多概率
- en: 'if height ≥ 30:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果高度 ≥ 30：
- en: return higher probability to Greyhound
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 返回更高的灰狗概率
- en: 'if 20 < height < 30:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果20 < 高度 < 30：
- en: look for other features to classify the object
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 寻找其他特征来分类对象
- en: So the height of the dog in this case is a useful feature because it helps (adds
    information) in distinguishing between both dog types. We can keep it. But it
    doesn’t distinguish between Greyhounds and Labradors in all cases, which is fine.
    In ML projects, there is usually no one feature that can classify all objects
    on its own. That’s why, in machine learning, we almost always need multiple features,
    where each feature captures a different type of information. If only one feature
    would do the job, we could just write `if-else` statements instead of bothering
    with training a classifier.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，狗的高度是一个有用的特征，因为它有助于（增加信息）区分两种狗类型。我们可以保留它。但是，它并不总是能区分灰狗和拉布拉多，这是可以接受的。在机器学习项目中，通常没有一种特征可以单独对所有的对象进行分类。这就是为什么在机器学习中，我们几乎总是需要多个特征，每个特征捕捉不同类型的信息。如果只有一个特征就能完成这项工作，我们就可以直接写`if-else`语句，而不用费心训练分类器。
- en: TIP Similar to what we did earlier with color conversion (color versus grayscale),
    to figure out which features you should use for a specific problem, do a thought
    experiment. Pretend you are the classifier. If you want to differentiate between
    Greyhounds and Labradors, what information do you need to know? You might ask
    about the hair length, the body size, the color, and so on.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士：类似于我们之前在颜色转换（颜色与灰度）中做的，为了确定你应该为特定问题使用哪些特征，进行一个思想实验。假装你是分类器。如果你想区分灰狗和拉布拉多，你需要知道哪些信息？你可能会问关于毛发长度、身体大小、颜色等等。
- en: For another quick example of a non-useful feature to drive this idea home, let’s
    look at dog eye color. For this toy example, imagine that we have only two eye
    colors, blue and brown. Figure 1.25 shows what a histogram might look like for
    this example.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速举例说明一个无用的特征，让我们看看狗的眼睛颜色。在这个玩具例子中，假设我们只有两种眼睛颜色，蓝色和棕色。图1.25显示了这种例子可能看起来像直方图。
- en: '![](../Images/1-25.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-25.png)'
- en: Figure 1.25 A visualization of the eye color distribution in a toy dogs dataset
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.25 玩具狗数据集中眼睛颜色分布的可视化
- en: It is clear that for most values, the distribution is about 50/50 for both types.
    So practically, this feature tells us nothing, because it doesn’t correlate with
    the type of dog. Hence, it doesn’t distinguish between Greyhounds and Labradors.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，对于大多数值，两种类型的分布大约是50/50。所以实际上，这个特征告诉我们 nothing，因为它与狗的类型不相关。因此，它不能区分灰狗和拉布拉多。
- en: What makes a good feature for object recognition?
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是物体识别的好特征？
- en: 'A good feature will help us recognize an object in all the ways it may appear.
    Characteristics of a good feature follow:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的特征将帮助我们以所有可能的方式识别一个对象。一个好的特征的特点如下：
- en: Identifiable
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可识别
- en: Easily tracked and compared
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易追踪和比较
- en: Consistent across different scales, lighting conditions, and viewing angles
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不同尺度、光照条件和视角下保持一致性
- en: Still visible in noisy images or when only part of an object is visible
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使在噪声图像中或只有部分对象可见时仍然可见
- en: 1.6.3 Extracting features (handcrafted vs. automatic extracting)
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.6.3 提取特征（手工提取与自动提取）
- en: This is a large topic in machine learning that could take up an entire book.
    It’s typically described in the context of a topic called feature engineering.
    In this book, we are only concerned with extracting features in images. So I’ll
    touch on the idea very quickly in this chapter and build on it in later chapters.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在机器学习中一个很大的主题，可能需要一整本书来阐述。它通常在被称为特征工程的主题背景下进行描述。在这本书中，我们只关注从图像中提取特征。因此，我将在本章中简要介绍这个想法，并在后面的章节中进一步展开。
- en: Traditional machine learning using handcrafted features
  id: totrans-233
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 传统机器学习使用手工特征
- en: 'In traditional ML problems, we spend a good amount of time in manual feature
    selection and engineering. In this process, we rely on our domain knowledge (or
    partner with domain experts) to create features that make ML algorithms work better.
    We then feed the produced features to a classifier like a support vector machine
    (SVM) or AdaBoost to predict the output (figure 1.26). Some of the handcrafted
    feature sets are these:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的机器学习问题中，我们花费大量时间在手工特征选择和工程上。在这个过程中，我们依赖我们的领域知识（或与领域专家合作）来创建使机器学习算法表现更好的特征。然后，我们将生成的特征输入到支持向量机（SVM）或AdaBoost等分类器中，以预测输出（图1.26）。一些手工特征集包括以下内容：
- en: Histogram of oriented gradients (HOG)
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方向梯度直方图（HOG）
- en: Haar Cascades
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haar级联
- en: Scale-invariant feature transform (SIFT)
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尺度不变特征变换（SIFT）
- en: Speeded-Up Robust Feature (SURF)
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速鲁棒特征（SURF）
- en: '![](../Images/1-26.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图1-26](../Images/1-26.png)'
- en: Figure 1.26 Traditional machine learning algorithms require handcrafted feature
    extraction.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.26 传统机器学习算法需要手工特征提取。
- en: Deep learning using automatically extracted features
  id: totrans-241
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用自动提取特征的深度学习
- en: In DL, however, we do not need to manually extract features from the image.
    The network extracts features automatically and learns their importance on the
    output by applying weights to its connections. You just feed the raw image to
    the network, and while it passes through the network layers, the network identifies
    patterns within the image with which to create features (figure 1.27). Neural
    networks can be thought of as feature extractors plus classifiers that are end-to-end
    trainable, as opposed to traditional ML models that use handcrafted features.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在深度学习中，我们不需要从图像中手动提取特征。网络自动提取特征，并通过对其连接应用权重来学习它们在输出中的重要性。你只需将原始图像输入到网络中，当它通过网络层时，网络会识别图像中的模式以创建特征（图1.27）。可以将神经网络视为特征提取器加分类器，它们是端到端可训练的，与传统机器学习模型使用的手工特征形成对比。
- en: '![](../Images/1-27.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图1-27](../Images/1-27.png)'
- en: Figure 1.27 A deep neural network passes the input image through its layers
    to automatically extract features and classify the object. No handcrafted features
    are needed.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.27 深度神经网络通过其层自动提取特征并对对象进行分类。不需要手工特征。
- en: How do neural networks distinguish useful features from non-useful features?
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是如何区分有用特征和非有用特征的？
- en: You might get the impression that neural networks only understand the most useful
    features, but that’s not entirely true. Neural networks scoop up all the features
    available and give them random weights. During the training process, the neural
    network adjusts these weights to reflect their importance and how they should
    impact the output prediction. The patterns with the highest appearance frequency
    will have higher weights and are considered more useful features. Features with
    the lowest weights will have very little impact on the output. This learning process
    will be discussed in deeper detail in the next chapter.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会觉得神经网络只理解最有用的特征，但这并不完全正确。神经网络会收集所有可用的特征并给它们随机分配权重。在训练过程中，神经网络调整这些权重以反映它们的重要性以及它们应该如何影响输出预测。出现频率最高的模式将具有更高的权重，被认为是更有用的特征。权重最低的特征对输出的影响非常小。这个过程将在下一章中更详细地讨论。
- en: '![](../Images/1-unnumb-5key.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图1-未编号-5关键点](../Images/1-unnumb-5key.png)'
- en: Weighting different features to reflect their importance in identifying the
    object
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 对不同特征进行加权以反映其在识别对象中的重要性
- en: Why use features?
  id: totrans-249
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 为什么使用特征？
- en: The input image has too much extra information that is not necessary for classification.
    Therefore, the first step after preprocessing the image is to simplify it by extracting
    the important information and throwing away nonessential information. By extracting
    important colors or image segments, we can transform complex and large image data
    into smaller sets of features. This makes the task of classifying images based
    on their features simpler and faster.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像包含太多不必要的额外信息，这些信息对于分类来说是不必要的。因此，预处理图像后的第一步是通过提取重要信息并丢弃非必要信息来简化它。通过提取重要的颜色或图像片段，我们可以将复杂和大量的图像数据转换为更小的特征集。这使得基于特征对图像进行分类的任务更加简单和快速。
- en: Consider the following example. Suppose we have a dataset of 10,000 images of
    motorcycles, each of 1,000 width by 1,000 height. Some images have solid backgrounds,
    and others have busy backgrounds of unnecessary data. When these thousands of
    images are fed to the feature extraction algorithms, we lose all the unnecessary
    data that is not important to identify motorcycles, and we only keep a consolidated
    list of useful features that can be fed directly to the classifier (figure 1.28).
    This process is a lot simpler than having the classifier look at the raw dataset
    of 10,000 images to learn the properties of motorcycles.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下示例。假设我们有一个包含10,000张摩托车图像的数据集，每张图像的宽度为1,000像素，高度为1,000像素。一些图像有均匀的背景，而其他图像则有繁忙的背景和不必要的数据。当这些数千张图像被输入到特征提取算法中时，我们丢失了所有对识别摩托车不重要的非必要数据，我们只保留了一个可以直接输入到分类器中的有用特征列表（图1.28）。这个过程比让分类器查看10,000张图像的原始数据集来学习摩托车的属性要简单得多。
- en: '![](../Images/1-28.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![图1-28](../Images/1-28.png)'
- en: Figure 1.28 Extracting and consolidating features from thousands of images in
    one feature vector to be fed to the classifier
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.28 从数千张图像中提取并巩固特征，形成一个特征向量以供分类器使用
- en: 1.7 Classifier learning algorithm
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.7 分类学习算法
- en: 'Here is what we have discussed so far regarding the classifier pipeline:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，关于分类器管道我们已经讨论了以下几点：
- en: Input image --We’ve seen how images are represented as functions, and that computers
    see images as a 2D matrix for grayscale images and a 3D matrix (three channels)
    for colored images.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入图像 -- 我们已经看到图像是如何表示为函数的，以及计算机将图像视为灰度图像的二维矩阵和彩色图像的三维矩阵（三个通道）。
- en: Image preprocessing --We discussed some image-preprocessing techniques to clean
    up our dataset and make it ready as input to the ML algorithm.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像预处理 -- 我们讨论了一些图像预处理技术，以清理我们的数据集并使其准备好作为机器学习算法的输入。
- en: Feature extraction --We converted our large dataset of images into a vector
    of useful features that uniquely describe the objects in the image.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取 -- 我们将我们的大量图像数据集转换为一个描述图像中对象的独特有用特征的向量。
- en: Now it is time to feed the extracted feature vector to the classifier to output
    a class label for the images (for example, motorcycle or otherwise).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候将提取的特征向量输入到分类器中，以输出图像的类别标签（例如，摩托车或其他）。
- en: 'As we discussed in the previous section, the classification task is done one
    of these ways: traditional ML algorithms like SVMs, or deep neural network algorithms
    like CNNs. While traditional ML algorithms might get decent results for some problems,
    CNNs truly shine in processing and classifying images in the most complex problems.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中讨论的，分类任务可以通过以下方式之一完成：传统的机器学习算法，如支持向量机（SVMs），或深度神经网络算法，如卷积神经网络（CNNs）。虽然传统的机器学习算法可能在某些问题上获得相当好的结果，但CNNs在处理和分类最复杂的问题中的表现尤为出色。
- en: 'In this book, we will discuss neural networks and how they work in detail.
    For now, I want you to know that neural networks automatically extract useful
    features from your dataset, and they act as a classifier to output class labels
    for your images. Input images pass through the layers of the neural network to
    learn their features layer by layer (figure 1.29). The deeper your network is
    (the more layers), the more it will learn the features of the dataset: hence the
    name deep learning. More layers come with some trade-offs that we will discuss
    in the next two chapters. The last layer of the neural network usually acts as
    the classifier that outputs the class label.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将详细讨论神经网络以及它们是如何工作的。现在，我想让你知道神经网络会自动从你的数据集中提取有用特征，并充当分类器，为你的图像输出类别标签。输入图像通过神经网络的层来学习它们的特征，一层一层地学习（图1.29）。你的网络越深（层越多），它就会学习到数据集的更多特征：因此得名深度学习。更多的层伴随着一些权衡，我们将在下一章中讨论。神经网络的最外层通常充当分类器，输出类别标签。
- en: '![](../Images/1-29.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![图1-29](../Images/1-29.png)'
- en: Figure 1.29 Input images pass through the layers of a neural network so it can
    learn features layer by layer.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.29 输入图像通过神经网络的层，以便它可以逐层学习特征。
- en: Summary
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Both human and machine vision systems contain two basic components: a sensing
    device and an interpreting device.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类和机器视觉系统都包含两个基本组件：一个感知设备和解释设备。
- en: 'The interpreting process consists of four steps: input the data, preprocess
    it, do feature extraction, and produce a machine learning model.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释过程包括四个步骤：输入数据，预处理，进行特征提取，并生成机器学习模型。
- en: 'An image can be represented as a function of *x* and *y*. Computers see an
    image as a matrix of pixel values: one channel for grayscale images and three
    channels for color images.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一张图像可以被表示为 *x* 和 *y* 的函数。计算机将图像视为像素值的矩阵：灰度图像有一个通道，彩色图像有三个通道。
- en: Image-processing techniques vary for each problem and dataset. Some of these
    techniques are converting images to grayscale to reduce complexity, resizing images
    to a uniform size to fit your neural network, and data augmentation.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像处理技术因问题和数据集而异。这些技术中的一些是将图像转换为灰度以降低复杂性，将图像调整到统一大小以适应您的神经网络，以及数据增强。
- en: Features are unique properties in the image that are used to classify its objects.
    Traditional ML algorithms use several feature-extraction methods.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征是图像中用于分类其对象的独特属性。传统的机器学习算法使用多种特征提取方法。
