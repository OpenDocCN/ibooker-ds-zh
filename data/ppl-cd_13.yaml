- en: 10 Cloud-native applications on Docker Swarm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 在 Docker Swarm 上运行的云原生应用程序
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Deploying a self-healing Swarm cluster on AWS and using an S3 bucket for node
    discovery
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AWS 上部署自修复的 Swarm 集群并使用 S3 存储桶进行节点发现
- en: Running SSH-based commands within Jenkins pipelines and configuring SSH agents
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Jenkins 管道中运行基于 SSH 的命令并配置 SSH 代理
- en: Automating deployment of Dockerized applications to Swarm
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动部署 Docker 化应用程序到 Swarm
- en: Integrating Slack to manage releases and build notifications of CI/CD pipelines
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Slack 集成到 CI/CD 管道的发布和构建通知管理中
- en: Continuous delivery to production and user manual approvals within Jenkins
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Jenkins 中进行持续交付到生产以及用户手动批准
- en: The previous chapter covered how to set up a continuous integration pipeline
    for a containerized microservice application with Jenkins. This chapter covers
    how to automate the deployment and manage multiple application environments. By
    the end of this chapter, you will be familiar with continuous deployment and delivery
    (figure 10.1) for containerized microservices running in a Docker Swarm cluster.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章介绍了如何使用 Jenkins 为容器化的微服务应用程序设置持续集成管道。本章将介绍如何自动化部署和管理多个应用程序环境。在本章结束时，你将熟悉在
    Docker Swarm 集群中运行的容器化微服务的持续部署和交付（图 10.1）。
- en: '![](Images/CH10_F01_Labouardy.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F01_Labouardy.png)'
- en: Figure 10.1 A complete CI/CD pipeline workflow
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 完整的 CI/CD 管道工作流程
- en: One of the basic solutions to run multiple containers across a set of machines
    is Swarm ([https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/)),
    which comes bundled with Docker Engine. By the end of this chapter, you should
    be able to build a CI/CD pipeline from scratch for services running inside a Docker
    Swarm cluster, as shown in figure 10.2.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在多台机器上运行多个容器的基本解决方案之一是 Swarm ([https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/))，它捆绑在
    Docker 引擎中。在本章结束时，你应该能够从头开始构建一个 CI/CD 管道，用于在 Docker Swarm 集群内部运行的服务，如图 10.2 所示。
- en: '![](Images/CH10_F02_Labouardy.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F02_Labouardy.png)'
- en: Figure 10.2 Target CI/CD pipeline
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 目标 CI/CD 管道
- en: 10.1 Running a distributed Docker Swarm cluster
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 运行分布式 Docker Swarm 集群
- en: Docker Swarm was originally released as a standalone product that ran master
    and agent containers on a cluster of servers to orchestrate the deployment of
    containers. This changed with the release of Docker 1.12 in 2016\. Docker Swarm
    became officially part of Docker Engine and was built right into every Docker
    installation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 最初作为一个独立产品发布，在服务器集群上运行主容器和代理容器以编排容器的部署。2016 年 Docker 1.12 版本的发布改变了这一点。Docker
    Swarm 成为 Docker 引擎的官方部分，并直接集成到每个 Docker 安装中。
- en: Note This is just a brief overview of the capabilities of Docker Swarm in Docker.
    For further reading, feel free to explore the Docker Swarm official documentation
    ([https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这只是 Docker 中 Docker Swarm 功能的简要概述。欲了解更多信息，请自由探索 Docker Swarm 的官方文档([https://docs.docker.com/engine/swarm/](https://docs.docker.com/engine/swarm/))。
- en: To illustrate the deployment of containers into a Swarm cluster from a CI/CD
    pipeline defined in Jenkins, we need to deploy a Swarm cluster.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明从 Jenkins 中定义的 CI/CD 管道将容器部署到 Swarm 集群的过程，我们需要部署一个 Swarm 集群。
- en: 'The Swarm cluster will be deployed inside a VPC with two Auto Scaling groups:
    one for Swarm managers and another for Swarm workers. Both ASGs will be deployed
    within private subnets that spin up across multiple availability zones for resiliency.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm 集群将在一个 VPC 内部部署，包含两个自动扩展组：一个用于 Swarm 管理器，另一个用于 Swarm 工作节点。这两个 ASG 都将在多个可用区中启动的私有子网内部部署，以提高弹性。
- en: Once the ASGs are created, setting up the Swarm requires manual initialization
    of the managers, and adding new nodes to the cluster requires additional information
    (a cluster join token) provided by the first manager when the Swarm is created.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了 ASGs，设置 Swarm 需要手动初始化管理器，并且将新节点添加到集群中需要额外的信息（一个集群加入令牌），这是在创建 Swarm 时由第一个管理器提供的。
- en: This step can be automated with configuration management tools like Ansible
    or Chef. However, it requires manual interaction. To address this, and to provide
    automatic Swarm initialization, we will run a one-shot Docker container on instance
    launch; the container uses an S3 bucket as a cluster discovery registry to find
    active managers and join tokens.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤可以使用 Ansible 或 Chef 等配置管理工具自动化。然而，它需要手动交互。为了解决这个问题，并提供自动 Swarm 初始化，我们将在实例启动时运行一个单次
    Docker 容器；该容器使用 S3 存储桶作为集群发现注册表以找到活动管理器和加入令牌。
- en: Figure 10.3 summarizes the architecture we will deploy. We will focus on AWS,
    but the same architecture can be applied in other cloud providers or locally.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3总结了我们将部署的架构。我们将专注于AWS，但相同的架构也可以应用于其他云提供商或本地环境。
- en: '![](Images/CH10_F03_Labouardy.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F03_Labouardy.png)'
- en: Figure 10.3 Swarm architecture in AWS
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 AWS中的Swarm架构
- en: Note A distributed, consistent key-value store such as etcd ([https://etcd.io/](https://etcd.io/)),
    HashiCorp’s Consul ([www.consul.io](http://www.consul.io)), or Apache ZooKeeper
    ([https://zookeeper.apache.org/](https://zookeeper.apache.org/)) can be used as
    service discovery to make the nodes autojoin the Swarm cluster.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：可以使用分布式、一致性的键值存储，如etcd([https://etcd.io/](https://etcd.io/))、HashiCorp的Consul([www.consul.io](http://www.consul.io))或Apache
    ZooKeeper([https://zookeeper.apache.org/](https://zookeeper.apache.org/))作为服务发现，使节点自动加入Swarm集群。
- en: To deploy Swarm instances, we need to provide an AMI with Docker Engine preinstalled.
    By now, you should be familiar with Packer. We will create a template.json file
    with the content in the following listing. (The full template can be downloaded
    from chapter10/swarm/packer/docker-ce/template.json.)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署Swarm实例，我们需要提供一个预安装了Docker Engine的AMI。到目前为止，你应该熟悉Packer。我们将创建一个包含以下列表内容的template.json文件。(完整的模板可以从chapter10/swarm/packer/docker-ce/template.json下载。)
- en: Listing 10.1 Docker AMI’s Packer template
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.1 Docker AMI的Packer模板
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The base image is Amazon Linux 2, which will be provisioned with a shell script
    that installs the most recent Docker Community Edition package. Then it adds the
    `ec2-user` username to the `docker` group, to be able to execute Docker commands
    without using the `sudo` command; see the following listing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 基础镜像为Amazon Linux 2，它将通过一个shell脚本安装最新的Docker社区版软件包。然后它将`ec2-user`用户名添加到`docker`组中，以便能够在不使用`sudo`命令的情况下执行Docker命令；请参阅以下列表。
- en: Listing 10.2 Docker Community Edition installation
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.2 Docker社区版安装
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Issue a `packer build` command to bake the Docker AMI. Once the provisioning
    process is completed, the new baked AMI should be available on the Images section
    on the AWS Management Console (figure 10.4).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 执行`packer build`命令来烘焙Docker AMI。一旦配置过程完成，新的烘焙AMI应该在AWS管理控制台上的“图像”部分可用（图10.4）。
- en: '![](Images/CH10_F04_Labouardy.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F04_Labouardy.png)'
- en: Figure 10.4  Docker Community Edition AMI
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 Docker社区版AMI
- en: Next, deploy the infrastructure with Terraform, and create a dedicated VPC called
    `sandbox` with a 10.1.0.0/16 CIDR block to isolate the sandbox application and
    workload. Define the block in listing 10.3 in the vpc.tf file.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用Terraform部署基础设施，并创建一个名为`sandbox`的专用VPC，使用10.1.0.0/16 CIDR块来隔离沙盒应用程序和工作负载。在vpc.tf文件中定义列表10.3中的块。
- en: Note Deploying the cluster on a different VPC is not mandatory, but following
    the best practices by isolating your workload environments for auditing and security
    compliance is strongly recommended.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在不同的VPC上部署集群不是强制性的，但强烈建议遵循最佳实践，通过隔离工作负载环境以进行审计和安全合规性。
- en: Listing 10.3 Sandbox VPC resource
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.3沙盒VPC资源
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The Swarm manager needs a way of passing the worker token to the workers after
    it has initialized. The best way to do that is to have the Swarm manager’s user
    data trigger generating the token and putting it into an S3 bucket. Define a private
    S3 bucket resource in s3.tf with the code in the following listing.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm管理器需要在初始化后有一种方式将工作令牌传递给工作节点。最佳方式是让Swarm管理器的用户数据触发生成令牌并将其放入S3桶中。在s3.tf中使用以下列表中的代码定义一个私有S3桶资源。
- en: Listing 10.4 Swarm discovery S3 bucket resource
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.4 Swarm发现S3桶资源
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note The AWS Systems Manager Parameter Store ([http://mng.bz/r6GX](https://shortener.manning.com/r6GX))
    can also be used as a shared encrypted store to store and retrieve the join token
    for Swarm workers.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：AWS系统管理器参数存储([http://mng.bz/r6GX](https://shortener.manning.com/r6GX))也可以用作共享加密存储，用于存储和检索Swarm工作节点的加入令牌。
- en: An IAM instance profile is necessary for EC2 instances to be able to interact
    with the S3 bucket to store or fetch the Swarm token for an autojoin operation.
    Define an IAM role policy within the iam.tf file, as shown in the next listing.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: IAM实例配置文件对于EC2实例能够与S3桶交互以存储或检索用于自动加入操作的工作令牌是必要的。在iam.tf文件中定义IAM角色策略，如下所示。
- en: Listing 10.5 Swarm nodes IAM policy
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.5 Swarm节点IAM策略
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then, we create a launch configuration for Swarm managers that uses the Docker
    AMI baked with Packer and run a startup script configured on user data. Use the
    following listing to define the code in swarm_managers.tf.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们为 Swarm 管理器创建一个启动配置，该配置使用 Packer 烤制的 Docker AMI，并在用户数据上运行配置的启动脚本。使用以下列表在
    swarm_managers.tf 中定义代码。
- en: Listing 10.6 Swarm managers launch configuration
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.6 Swarm 管理器启动配置
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The startup script uses the name of the cluster discovery S3 bucket and the
    role of the running instance (manager or worker), as shown in the next listing.
    Based on the instance role, the `docker` `swarm` `join` command will use the right
    token (`workers` token or `managers` token).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 启动脚本使用集群发现 S3 存储桶的名称和运行实例的角色（管理器或工作节点），如下所示。根据实例角色，`docker` `swarm` `join` 命令将使用正确的令牌（`workers`
    令牌或 `managers` 令牌）。
- en: Listing 10.7 Swarm managers user data
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.7 Swarm 管理器用户数据
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The shell script [joint-swarm.tpl](https://plugins.jenkins.io/credentials-binding/),
    shown in the following listing, uses EC2 metadata to fetch the instance private
    IP address. The script then executes a container that uses the S3 bucket to store
    the state of the Swarm once it’s created or creates a new Swarm if no state already
    exists in the bucket.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，shell 脚本 [joint-swarm.tpl](https://plugins.jenkins.io/credentials-binding/)
    使用 EC2 元数据获取实例的私有 IP 地址。脚本随后执行一个容器，该容器使用 S3 存储桶存储 Swarm 的状态，一旦创建或如果存储桶中不存在状态，则创建一个新的
    Swarm。
- en: Listing 10.8 Swarm nodes startup script
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.8 Swarm 节点启动脚本
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Note The mlabouardy/swarm-discovery full Python script and Dockerfile is given
    in the GitHub repository: pipeline-as-code-with-jenkins/tree/master/chapter10/discovery.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您可以使用 CloudWatch 告警定义自动扩展策略，根据 CPU 利用率或 Swarm 节点的自定义指标触发扩展或缩减事件。
- en: From there, we will create an ASG of managers. By default, we will create one
    manager for the cluster. But I recommend using an odd number when running Swarm
    in production, as a majority vote is needed among managers to agree on proposed
    management tasks. An odd—rather than even—number is strongly recommended to have
    a tie-breaking consensus. However, for a sandbox cluster, we will keep it simple
    and go with one Swarm manager. In swarm_mangers.tf, define the ASG resource as
    shown in the following listing.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，我们将创建一个管理器的自动扩展组（ASG）。默认情况下，我们将为集群创建一个管理器。但是，我建议在生产环境中使用奇数，因为管理器之间需要多数投票来就提议的管理任务达成一致。奇数（而不是偶数）强烈推荐用于打破平局。然而，对于沙盒集群，我们将保持简单，使用一个
    Swarm 管理器。在 swarm_mangers.tf 中，定义如下所示的 ASG 资源。
- en: Listing 10.9 Swarm managers Auto Scaling group
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10.1 Swarm 集群安全组规则
- en: '[PRE8]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note You can define autoscaling policies with CloudWatch alarms to trigger scale-out
    or scale-in events based on CPU utilization or custom metrics of the Swarm nodes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.10 Swarm 工作节点 ASG
- en: Similarly, we will create an ASG for workers, and we will go with two Swarm
    workers. Note the use of the `depends_on` keyword to create an implicit dependency
    on the `swarm_managers` resource. Terraform uses this information to determine
    the correct order for creating resources.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们将为工作节点创建一个 ASG，我们将使用两个 Swarm 工作节点。注意使用 `depends_on` 关键字创建对 `swarm_managers`
    资源的隐式依赖。Terraform 使用此信息来确定创建资源的正确顺序。
- en: In this example, Terraform will create Swarm managers first. That way, we guarantee
    the Swarm initialization and the availability of a join token in the S3 bucket.
    Add the resource in the following listing in the swarm_workers.tf file.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '| 协议 | 端口 | 来源 | 描述 |'
- en: Listing 10.10 Swarm workers ASG
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.9 Swarm 管理器自动扩展组
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Finally, allow the firewall rules in table 10.1 on the security group assigned
    to the Swarm cluster instances.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，允许分配给 Swarm 集群实例的安全组中的表 10.1 中的防火墙规则。
- en: Table 10.1 Swarm cluster security group rules
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '| TCP | 7946 | Swarm | 所有节点之间的控制平面 Gossip 发现通信 |'
- en: '| Protocol | Port | Source | Description |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| TCP | 2377 | Swarm | 集群管理和 raft 同步通信 |'
- en: '| TCP | 2377 | Swarm | Cluster management and raft sync communications |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: 注意：mlabouardy/swarm-discovery 完整的 Python 脚本和 Dockerfile 在 GitHub 仓库中给出：pipeline-as-code-with-jenkins/tree/master/chapter10/discovery。
- en: '| TCP | 7946 | Swarm | Control-plane gossip discovery communication among all
    nodes |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| UDP | 7946 | Swarm | 来自其他 Swarm 节点的容器网络发现 |'
- en: '| UDP | 7946 | Swarm | Container network discovery from other Swarm nodes |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 协议 | 端口 | 来源 | 描述 |'
- en: '| UDP | 4789 | Swarm | Data-plane VXLAN overlay network traffic |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: 在此示例中，Terraform 将首先创建 Swarm 管理器。这样，我们保证 Swarm 初始化和 S3 存储桶中存在加入令牌的可用性。在 swarm_workers.tf
    文件中添加以下列表中的资源。
- en: '| TCP | 22 | Jenkins and Bastion SGs | SSH traffic from Jenkins master and
    bastion security groups |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| TCP | 22 | Jenkins和防火墙SG | 来自Jenkins主和防火墙安全组的SSH流量 |'
- en: The following listing provides the security group definition.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表提供了安全组定义。
- en: Listing 10.11 Swarm nodes security group
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.11 Swarm节点安全组
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note I recommend using an S3 backend with encryption and versioning enabled
    to remotely store the Terraform state files.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我建议使用启用加密和版本控制的S3后端来远程存储Terraform状态文件。
- en: Define the required Terraform variables in variables.tfvars as listed in table
    10.2.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在`variables.tfvars`中定义所需的Terraform变量，如表10.2所示。
- en: Table 10.2 Swarm Terraform variables
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.2 Swarm Terraform变量
- en: '| Variable | Type | Value | Description |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 变量 | 类型 | 值 | 描述 |'
- en: '| `region` | String | None | The name of the region, such as `eu-central-1`,
    in which to deploy the Swarm cluster |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| `region` | 字符串 | None | 部署Swarm集群的区域的名称，例如`eu-central-1` |'
- en: '| `shared_credentials_file` | String | `~/.aws/credentials` | The path to the
    shared credentials file. If this is not set and a profile is specified, `~/.aws/credentials`
    will be used. |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| `shared_credentials_file` | 字符串 | `~/.aws/credentials` | 共享凭据文件的路径。如果没有设置且指定了配置文件，则使用`~/.aws/credentials`。
    |'
- en: '| `aws_profile` | String | `profile` | The AWS profile name as set in the shared
    credentials file |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| `aws_profile` | 字符串 | `profile` | 在共享凭据文件中设置的AWS配置文件名称 |'
- en: '| `author` | String | None | Name of the owner of the Swarm cluster. It’s optional,
    but recommended, to tag your AWS resources to track the monthly costs by owner
    or environment. |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| `author` | 字符串 | None | Swarm集群所有者的名称。标记您的AWS资源以跟踪按所有者或环境划分的月度成本是可选的，但建议这么做。
    |'
- en: '| `key_name` | String | None | SSH key pair |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| `key_name` | 字符串 | None | SSH密钥对 |'
- en: '| `availability_zones` | List | None | Availability zone where you’ll spin
    up the VPC subnet |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| `availability_zones` | 列表 | None | 启动VPC子网的可用区 |'
- en: '| `bastion_sg_id` | String | None | The bastion host security group ID |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| `bastion_sg_id` | 字符串 | None | 防火墙主机安全组的ID |'
- en: '| `jenkins_sg_id` | String | None | The Jenkins master security group ID |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `jenkins_sg_id` | 字符串 | None | Jenkins主安全组的ID |'
- en: '| `vpc_name` | String | `sandbox` | The name of the VPC |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `vpc_name` | 字符串 | `sandbox` | VPC的名称 |'
- en: '| `environment` | String | `sandbox` | The runtime environment name |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| `environment` | 字符串 | `sandbox` | 运行时环境名称 |'
- en: '| `cidr_block` | String | `10.1.0.0/16` | The VPC CIDR block |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `cidr_block` | 字符串 | `10.1.0.0/16` | VPC的CIDR块 |'
- en: '| `cluster_name` | String | `sandbox` | The Swarm cluster’s name |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `cluster_name` | 字符串 | `sandbox` | Swarm集群的名称 |'
- en: '| `public_subnets_count` | Number | 2 | The number of public subnets to create
    |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `public_subnets_count` | 数字 | 2 | 需要创建的公共子网数量 |'
- en: '| `private_subnets_count` | Number | 2 | The number of private subnets to create
    |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| `private_subnets_count` | 数字 | 2 | 需要创建的私有子网数量 |'
- en: '| `swarm_discovery_bucket` | String | `swarm-discovery-cluster` | The S3 bucket
    where the Swarm tokens will be stored |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `swarm_discovery_bucket` | 字符串 | `swarm-discovery-cluster` | 存储Swarm令牌的S3存储桶
    |'
- en: '| `manager_instance_type` | String | `t2.small` | The EC2 instance type for
    Swarm managers |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `manager_instance_type` | 字符串 | `t2.small` | Swarm管理员的EC2实例类型 |'
- en: '| `worker_instance_type` | String | `t2.large` | The EC2 instance type for
    Swarm workers |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `worker_instance_type` | 字符串 | `t2.large` | Swarm工作节点的EC2实例类型 |'
- en: Then, use the `terraform apply` command to start the deployment process. Once
    deployed, the ASGs will be created, the Swarm discovery container will be launched
    on each instance, and the first manager to be run will execute the `swarm init`
    command and store the token on the S3 bucket (figure 10.5), which will be used
    by other instances to join the cluster.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用`terraform apply`命令开始部署过程。一旦部署完成，将创建自动扩展组（ASGs），在每个实例上启动Swarm发现容器，第一个运行的经理将执行`swarm
    init`命令并将令牌存储在S3存储桶中（图10.5），其他实例将使用此令牌加入集群。
- en: Note You can have as many or as few worker groups as you wish, running in as
    many different configurations as you choose (CPU or memory-optimized workers alongside
    general-purpose Swarm workers).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您可以拥有任意数量的工作节点组，运行在您选择的任意配置中（CPU或内存优化的工作节点与通用Swarm工作节点一起运行）。
- en: '![](Images/CH10_F05_Labouardy.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F05_Labouardy.png)'
- en: Figure 10.5 Swarm state stored in an S3 bucket
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 存储在S3存储桶中的Swarm状态
- en: If you decide to create a dedicated VPC for the Swarm cluster, you need to set
    up VPC peering between management and sandbox VPCs, as shown in figure 10.6\.
    For a step-by-step guide on how to set up peering with Terraform, refer to the
    official Terraform documentation at [http://mng.bz/VBw5](http://mng.bz/VBw5).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您决定为 Swarm 集群创建一个专用的 VPC，您需要设置管理和沙盒 VPC 之间的 VPC 对等连接，如图 10.6 所示。有关如何使用 Terraform
    设置对等的分步指南，请参阅官方 Terraform 文档，网址为 [http://mng.bz/VBw5](http://mng.bz/VBw5)。
- en: '![](Images/CH10_F06_Labouardy.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.11 创建部署仓库的分支](Images/CH10_F06_Labouardy.png)'
- en: Figure 10.6 VPC peering between management and sandbox VPCs
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 管理和沙盒 VPC 之间的 VPC 对等连接
- en: Note If you intend to use the VPC peering connection, make sure the VPCs don’t
    have matching or overlapping IPv4 CIDR blocks. In our example, the management
    and sandbox CIDR blocks are 10.0.0.0/16 and 10.1.0.0/16, respectively.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您打算使用 VPC 对等连接，请确保 VPC 不具有匹配或重叠的 IPv4 CIDR 块。在我们的示例中，管理和沙盒 CIDR 块分别为 10.0.0.0/16
    和 10.1.0.0/16。
- en: From the VPC dashboard, navigate to Peering Connections and create a new one.
    Configure the peering as shown in figure 10.7.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 从 VPC 仪表板导航到对等连接，创建一个新的对等连接。配置对等连接，如图 10.7 所示。
- en: '![](Images/CH10_F07_Labouardy.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.7 配置管理和沙盒 VPC 的对等连接](Images/CH10_F07_Labouardy.png)'
- en: Figure 10.7 Configuring the peering of management and sandbox VPCs
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7 配置管理和沙盒 VPC 的对等连接
- en: After creating the peering connection, you’ll see Pending Acceptance in the
    status bar. If you are using a different account or different region, go to the
    corresponding VPC console, where you can see Pending Acceptance in the status
    bar of the peering connection. From the Actions drop-down, choose Accept Request,
    as shown in figure 10.8\. Then, in the Accept VPC Peering Connection Request prompt
    box, click Yes, Accept.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 创建对等连接后，您将在状态栏中看到“待接受”。如果您使用的是不同的账户或不同的区域，请转到相应的 VPC 控制台，在那里您可以在对等连接的状态栏中看到“待接受”。从“操作”下拉菜单中选择“接受请求”，如图
    10.8 所示。然后，在“接受 VPC 对等连接请求”提示框中，单击“是，接受”。
- en: '![](Images/CH10_F08_Labouardy.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.10 Swarm 集群节点列表](Images/CH10_F08_Labouardy.png)'
- en: Figure 10.8 Accepting VPC peering request
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 接受 VPC 对等连接请求
- en: To send and receive traffic across this VPC peering connection, you must add
    a route to the peered VPC in one or more of your VPC route tables. In the route
    tables associated with the subnets of the VPC, create a route with the CIDR block
    of the peer VPC as a destination, and the ID of the VPC peering connection as
    a target.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过此 VPC 对等连接发送和接收流量，您必须在您的 VPC 路由表中添加一个路由到对等 VPC。在关联 VPC 子网的路由表中，创建一个以对等 VPC
    的 CIDR 块为目标，以 VPC 对等连接的 ID 为目标的路由。
- en: Repeat the same setups for all other VPC route tables. Once everything is set
    up, your routing table will look like figure 10.9.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对所有其他 VPC 路由表重复相同的设置。一旦设置完成，您的路由表将类似于图 10.9。
- en: '![](Images/CH10_F09_Labouardy.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.7 配置管理和沙盒 VPC 的对等连接](Images/CH10_F09_Labouardy.png)'
- en: Figure 10.9 Sandbox VPC’s route table update
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 沙盒 VPC 的路由表更新
- en: 'To view the Swarm state, set up an SSH tunnel by using the bastion host deployed
    in chapter 5’s section 5.2.4:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看 Swarm 状态，请使用第 5 章第 5.2.4 节中部署的堡垒主机设置 SSH 隧道：
- en: '[PRE11]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Replace `SWARM_MANAGER_IP` with the Swarm manager private IP address. Once
    connected, if you type the `docker info` command, the `Swarm:` `active` attribute
    should confirm that Swarm has been properly configured:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `SWARM_MANAGER_IP` 替换为 Swarm 管理器的私有 IP 地址。一旦连接，如果您输入 `docker info` 命令，`Swarm:`
    `active` 属性应确认 Swarm 已正确配置：
- en: '![](Images/CH10_F09_UN01_Labouardy.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.10 Swarm 的连接节点](Images/CH10_F09_UN01_Labouardy.png)'
- en: Run `docker node ls` from the manager machine to view your Swarm’s connected
    nodes. As you can see in figure 10.10, we now have one manager and two workers.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从管理机器上运行 `docker node ls` 命令以查看您的 Swarm 的连接节点。如图 10.10 所示，我们现在有一个管理节点和两个工作节点。
- en: '[PRE12]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](Images/CH10_F10_Labouardy.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.10 Swarm 的连接节点](Images/CH10_F10_Labouardy.png)'
- en: Figure 10.10 Swarm cluster nodes list
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10 Swarm 集群节点列表
- en: With our Swarm up and running, let’s deploy the Dockerized-based application
    with Jenkins.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 随着 Swarm 运行起来，让我们使用 Jenkins 部署基于 Docker 的应用程序。
- en: 10.2 Defining a continuous deployment process
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 定义持续部署流程
- en: 'Create a new GitHub repository for deployment. Because deployment options are
    often changed, we will store the deployment part on a different Git repo. Then,
    create three main branches: develop, preprod, and master, as in figure 10.11.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为部署创建一个新的 GitHub 仓库。由于部署选项经常更改，我们将部署部分存储在不同的 Git 仓库中。然后，创建三个主要分支：develop、preprod
    和 master，如图 10.11 所示。
- en: Docker Swarm mode now integrates directly with Docker Compose v3 and officially
    supports the deployment of *stacks* (groups of services) via docker-compose.yml
    files. The same docker-compose.yml file you would use to test your application
    locally can now be used to deploy your application to Swarm.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm 模式现在直接集成到 Docker Compose v3，并正式支持通过 docker-compose.yml 文件部署 *stacks*（服务组）。您用于在本地测试应用程序的相同的
    docker-compose.yml 文件现在可以用于将应用程序部署到 Swarm。
- en: '![](Images/CH10_F11_Labouardy.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F11_Labouardy.png)'
- en: Figure 10.11 GitHub deployment repository
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11 GitHub 部署仓库
- en: To do a Docker Swarm deployment from Jenkins, we need a docker-compose file
    that contains the references to Docker images along with the configuration settings
    such as port, network name, labels, and constraints. To run this file, we need
    to execute the `docker stack deployment` command over SSH on a manager machine.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要从 Jenkins 进行 Docker Swarm 部署，我们需要一个包含 Docker 镜像引用以及配置设置（如端口、网络名称、标签和约束）的 docker-compose
    文件。要运行此文件，我们需要在管理机器上通过 SSH 执行 `docker stack deployment` 命令。
- en: On the develop branch, create a docker-compose.yml file by using your favorite
    text editor or IDE, with the content in the following listing.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在 develop 分支上，使用您喜欢的文本编辑器或 IDE 创建 docker-compose.yml 文件，内容如下所示。
- en: Listing 10.12  Application Docker Compose
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.12 应用 Docker Compose
- en: '[PRE13]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note Substitute the `ID`, `REGION`, and `USER` with your own AWS Account ID,
    AWS region, and ECR URI.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：将 `ID`、`REGION` 和 `USER` 替换为您的 AWS 账户 ID、AWS 区域和 ECR URI。
- en: Each service uses the image we built in chapter 9 and references the `develop`
    tag. This tag is dedicated to sandbox deployment and contains the codebase of
    the develop branch. Also, we have defined a MongoDB service that will be used
    by both the movies-store and movies-parser services.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 每个服务都使用我们在第 9 章中构建的镜像，并引用 `develop` 标签。此标签专门用于沙盒部署，包含 develop 分支的代码库。此外，我们还定义了一个
    MongoDB 服务，该服务将被 movies-store 和 movies-parser 服务使用。
- en: 'The MongoDB service credentials are in plaintext. However, you shouldn’t commit
    sensitive information under any circumstances and opt for managed solutions like
    HashiCorp Vault or AWS SSM Parameter Store to encrypt your credentials and access
    tokens. You can also use an integrated feature of Docker called Secrets to create
    database credentials:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: MongoDB 服务的凭据是明文。然而，在任何情况下都不应提交敏感信息，并选择像 HashiCorp Vault 或 AWS SSM Parameter
    Store 这样的托管解决方案来加密您的凭据和访问令牌。您还可以使用 Docker 的集成功能 Secrets 创建数据库凭据：
- en: '[PRE14]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'And update docker-compose.yml to use the secret instead of the plaintext password:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 并更新 docker-compose.yml 以使用密钥而不是明文密码：
- en: '[PRE15]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note If the MongoDB service crashes for unknown reasons or has been removed,
    its data will be lost. To avoid this loss of data, you should mount a persistent
    volume. Depending on the cloud provider used, Docker volumes support use of external
    persistent storage such as Amazon EBS.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果 MongoDB 服务因未知原因崩溃或已被删除，其数据将丢失。为了避免数据丢失，您应该挂载一个持久卷。根据所使用的云提供商，Docker 卷支持使用外部持久存储，如
    Amazon EBS。
- en: To decouple the crawling and parsing of HTML pages, we are using a distributed
    queue between the movies-loader and movies-parser services. In addition to its
    high availability, this will allow us to deploy additional movies-parser workers
    based on the number of HTML pages to parse. Create an SQS for the sandbox environment
    called `movies_to_parse_sandbox` with Terraform (chapter10/swarm/terraform/sqs.tf),
    as shown in figure 10.12\. This queue will be used by movies-loader to push movies
    into, and then it will be consumed by movies-parser workers.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解耦 HTML 页面的爬取和解析，我们在 movies-loader 和 movies-parser 服务之间使用分布式队列。除了其高可用性外，这还将允许我们根据要解析的
    HTML 页面数量部署额外的 movies-parser 工作节点。使用 Terraform（chapter10/swarm/terraform/sqs.tf）创建一个名为
    `movies_to_parse_sandbox` 的沙盒环境 SQS，如图 10.12 所示。此队列将由 movies-loader 用于推送电影，然后它将被
    movies-parser 工作节点消费。
- en: '![](Images/CH10_F12_Labouardy.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F12_Labouardy.png)'
- en: Figure 10.12 Sandbox queue settings
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.12 沙盒队列设置
- en: 'With Docker Compose out of the way, we can proceed and create a Jenkinsfile,
    shown in listing 10.13, with these steps:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理完 Docker Compose 后，我们可以继续创建 Jenkinsfile，如列表 10.13 所示，包含以下步骤：
- en: Clone the GitHub repository (chapter10/deployment/sandbox/Jenkinsfile) and check
    out the develop branch.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆 GitHub 仓库（chapter10/deployment/sandbox/Jenkinsfile）并检出 develop 分支。
- en: Send the docker-compose.yml file over SSH to the manager node and execute the
    command `docker stack deploy`.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 SSH 将 docker-compose.yml 文件发送到管理节点并执行 `docker stack deploy` 命令。
- en: Note We use the master label to constrain the pipeline to be executed on the
    Jenkins master only. Workers’ machines might also be used for this job.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们使用master标签来限制管道仅在Jenkins主节点上执行。工作机的机器也可能用于此作业。
- en: Listing 10.13 Deployment Jenkinsfile
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.13 部署Jenkinsfile
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Replace with your own AWS default region.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 替换为你的AWS默认区域。
- en: 'This Jenkinsfile uses Amazon ECR as a private registry. If you’re using a private
    registry that requires username and password authentication (such as Nexus, DockerHub,
    Azure, or Cloud Container Registry), you can use the Credentials Binding plugin
    [https://plugins.jenkins.io/credentials-binding/](https://plugins.jenkins.io/credentials-binding/)),
    which is installed by default, to allow registry credentials to be bounded to
    `USERNAME` and `PASSWORD` variables. Then, pass those variables to the `docker
    login` command for authentication:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 此Jenkinsfile使用Amazon ECR作为私有仓库。如果你使用的是需要用户名和密码认证的私有仓库（例如Nexus、DockerHub、Azure或Cloud
    Container Registry），你可以使用默认安装的Credentials Binding插件（[https://plugins.jenkins.io/credentials-binding/](https://plugins.jenkins.io/credentials-binding/)），将仓库凭据绑定到`USERNAME`和`PASSWORD`变量。然后，将这些变量传递给`docker
    login`命令进行认证：
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Push the Jenkinsfile and docker-compose.yml files to the develop branch with
    the following commands:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令将Jenkinsfile和docker-compose.yml文件推送到develop分支：
- en: '[PRE18]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Head over to Jenkins, and create a new multibranch pipeline job called watchlist-deployment.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 前往Jenkins，创建一个名为watchlist-deployment的新多分支管道作业。
- en: Note For a step-by-step guide on how to create and configure multibranch pipeline
    jobs on Jenkins, check out chapter 7.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：有关如何在Jenkins上创建和配置多分支管道作业的逐步指南，请参阅第7章。
- en: Set the GitHub repository HTTPS clone URL and allow Jenkins to discover all
    branches looking for a Jenkinsfile on the root repository, as shown in figure
    10.13.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 设置GitHub仓库HTTPS克隆URL，并允许Jenkins发现所有分支，寻找根仓库中的Jenkinsfile，如图10.13所示。
- en: '![](Images/CH10_F13_Labouardy.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F13_Labouardy.png)'
- en: Figure 10.13 Branch sources configuration
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.13 分支源配置
- en: For now, the job pipeline should discover the develop branch and execute the
    stages defined in the Jenkinsfile, as shown in figure 10.14.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，作业管道应该发现develop分支并执行Jenkinsfile中定义的阶段，如图10.14所示。
- en: '![](Images/CH10_F14_Labouardy.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F14_Labouardy.png)'
- en: Figure 10.14 Deployment job on Jenkins
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.14 Jenkins上的部署作业
- en: The pipeline should fail and turn red at the Copy stage, as shown in figure
    10.15\. The Jenkins master cannot SSH to the Swarm manager because the Jenkins
    master has the wrong private SSH key.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 管道应该在复制阶段失败并变成红色，如图10.15所示。Jenkins主节点无法SSH到Swarm管理器，因为Jenkins主节点有错误的私钥。
- en: '![](Images/CH10_F15_Labouardy.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F15_Labouardy.png)'
- en: Figure 10.15 SCP command logs
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.15 SCP命令日志
- en: For Jenkins to continuously deploy to the Swarm, it needs access to the Swarm
    manager. Create a new credential of type SSH Username with Private Key on Jenkins
    to access the Swarm sandbox. On a private-key field, paste the content of the
    key pair used while creating Swarm EC2 instances. Then, call it `swarm-sandbox`,
    as shown in figure 10.16.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让Jenkins持续部署到Swarm，它需要访问Swarm管理器。在Jenkins上创建一个新的SSH用户名凭据，带有私钥，以访问Swarm沙盒。在私钥字段中粘贴创建Swarm
    EC2实例时使用的密钥对的内容。然后，将其命名为`swarm-sandbox`，如图10.16所示。
- en: '![](Images/CH10_F16_Labouardy.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F16_Labouardy.png)'
- en: Figure 10.16 Jenkins credential with Swarm SSH key pair
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.16 Jenkins凭据与Swarm SSH密钥对
- en: Note Jenkins would need access to only the Swarm manager. The other nodes are
    managed by the Swarm manager, so Jenkins does not need direct access to them.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：Jenkins只需要访问Swarm管理器。其他节点由Swarm管理器管理，因此Jenkins不需要直接访问它们。
- en: Update the Jenkinsfile to use the SSH agent plugin (Credentials Binding plugin)
    to inject the credentials. The `sshagent` block should wrap all SSH- and SCP-based
    commands, as shown in the following listing.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 更新Jenkinsfile以使用SSH代理插件（Credentials Binding插件）注入凭据。`sshagent`块应该包装所有基于SSH和SCP的命令，如下面的列表所示。
- en: Listing 10.14 SSH agent configuration
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.14 SSH代理配置
- en: '[PRE19]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Push the changes to the develop branch. A new build should be triggered on the
    develop branch’s nested job of the watchlist-deployment item.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改推送到develop分支。watchlist-deployment项目的develop分支的嵌套作业应该触发一个新的构建。
- en: Note For continuous deployment, create a GitHub webhook on the GitHub repository
    to notify Jenkins on push events.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：为了实现持续部署，请在GitHub仓库上创建一个GitHub webhook，以便在推送事件时通知Jenkins。
- en: This time, the pipeline should be successful and turns green (figure 10.17).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，管道应该成功并变成绿色（图10.17）。
- en: '![](Images/CH10_F17_Labouardy.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F17_Labouardy.png)'
- en: Figure 10.17 Continuous deployment pipeline
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.17 持续部署管道
- en: On the build logs side, Jenkins will run `docker` `stack` `deploy` over SSH
    on the Swarm manager, and the services in figure 10.18 will be deployed based
    on the `develop` tag image.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建日志方面，Jenkins将在Swarm管理器上通过SSH运行`docker` `stack` `deploy`，并根据`develop`标签图像部署图10.18中的服务。
- en: '![](Images/CH10_F18_Labouardy.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F18_Labouardy.png)'
- en: Figure 10.18 Output from `docker stack deploy`
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.18 `docker stack deploy`的输出
- en: Note If you plan to use Amazon ECR as a remote repository, you need to assign
    an ECR IAM policy to the IAM instance profile assigned to Swarm instances.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果您计划将Amazon ECR用作远程存储库，您需要将ECR IAM策略分配给分配给Swarm实例的IAM实例配置文件。
- en: 'On Swarm, type the following command, and we should be able to view the status
    of the stack and the services running within it:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在Swarm上，输入以下命令，我们应该能够查看堆栈的状态以及其中运行的服务：
- en: '[PRE20]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The four microservices should be deployed alongside a MongoDB service, as shown
    in figure 10.19.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 四个微服务应与MongoDB服务一起部署，如图10.19所示。
- en: '![](Images/CH10_F19_Labouardy.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F19_Labouardy.png)'
- en: Figure 10.19 Stack successfully deployed on Swarm sandbox
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.19 Swarm沙盒上成功部署的堆栈
- en: 'Next, we will deploy an open source tool called Visualizer to visualize Docker
    services across a set of machines. Execute these commands on the Swarm manager
    machine:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将部署一个名为Visualizer的开源工具，以可视化跨一组机器的Docker服务。在Swarm管理器机器上执行以下命令：
- en: '[PRE21]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Once the service is deployed, we will create a public load balancer to forward
    incoming HTTP and HTTPS (optional) traffic to port 8080, which is the port the
    Visualizer UI is exposed to. Declare the ELB resource in the following listing
    or download the resources file from chapter8/services/loadbalancers.tf.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦服务部署完成，我们将创建一个公共负载均衡器，将传入的HTTP和HTTPS（可选）流量转发到8080端口，这是Visualizer UI暴露的端口。在以下列表中声明ELB资源或从chapter8/services/loadbalancers.tf下载资源文件。
- en: Listing 10.15 Visualizer load balancer
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.15 Visualizer负载均衡器
- en: '[PRE22]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Then, we attach the load balancer to the ASG of the Swarm managers. The load
    balancer can also be assigned to the Swarm workers. In fact, all of the nodes
    within the Swarm cluster are aware of the location of every container within the
    cluster via the gossip network. If an incoming request hits a node that is not
    currently running the service for which that request was intended, the request
    will be routed to a node that is running a container for that service.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将负载均衡器附加到Swarm管理器的ASG。负载均衡器也可以分配给Swarm工作节点。实际上，Swarm集群中的所有节点都通过gossip网络知道集群中每个容器的位置。如果传入的请求击中了当前未运行该请求所针对服务的服务的节点，请求将被路由到运行该服务容器的节点。
- en: 'This is so nodes don’t have to be purpose-built for specific services. Any
    node can run any service, and every node can be load balanced equally, reducing
    complexity and the number of resources needed for an application. This feature
    is called *mesh routing*:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做是为了避免节点需要为特定服务专门构建。任何节点都可以运行任何服务，并且每个节点都可以进行均衡负载，从而减少复杂性和应用程序所需的资源数量。这个特性被称为
    *网状路由*：
- en: '[PRE23]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The following listing (chapter8/services/dns.tf) is not mandatory, but can be
    used to create a friendly DNS record pointing to the Visualizer load balancer
    FQDN.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表（chapter8/services/dns.tf）不是必需的，但可以用来创建一个友好的DNS记录，指向Visualizer负载均衡器的FQDN。
- en: Listing 10.16 Visualizer DNS configuration
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.16 Visualizer DNS配置
- en: '[PRE24]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Note Update the security group of the Swarm cluster to allow incoming inbound
    traffic on port 8080 from the load balancer security group. Add an ingress rule
    for port 8080 and use `terraform` `apply` for changes to take effect.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：更新Swarm集群的安全组，允许来自负载均衡器安全组的8080端口进入流量。为8080端口添加入站规则，并使用`terraform` `apply`使更改生效。
- en: Once changes are issued, point the browser to the load balancer URL displayed
    in the `Outputs` section in your terminal session. This handy tool, shown in figure
    10.20, helps you see which containers are running, and on which nodes.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦发布更改，将浏览器指向终端会话中“输出”部分显示的负载均衡器URL。这个实用的工具，如图10.20所示，可以帮助您查看哪些容器正在运行，以及它们在哪些节点上。
- en: Note This tool works only with Docker Swarm mode in Docker Engine 1.12.0 and
    later. It does not work with the separate Docker Swarm project.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：此工具仅在Docker Engine 1.12.0及以后的Docker Swarm模式下工作。它不与单独的Docker Swarm项目一起工作。
- en: '![](Images/CH10_F20_Labouardy.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F20_Labouardy.png)'
- en: Figure 10.20 Visualizer dashboard
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.20 可视化仪表板
- en: Note Containers are deployed on the manager, too. If you want to restrict deployment
    to workers, use Docker constraints with labels.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：容器也部署在管理器上。如果您想限制部署到工作节点，请使用带有标签的 Docker 约束。
- en: We have successfully deployed our application stack to Swarm. However, for now,
    the deployment is triggered manually. Ultimately, we want the deployment job to
    be executed at the end of each CI pipeline’s successful execution.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功将应用程序堆栈部署到 Swarm。然而，目前部署是手动触发的。最终，我们希望部署作业在每个 CI 管道成功执行结束时运行。
- en: 'To do so, update the Jenkinsfile (chapter10/pipelines/movies-loader/Jenkinsfile)
    to trigger the external job with the `build job` keyword. For example, on the
    movies-loader Jenkinsfile, add the following `Deploy` stage code block to the
    end of the pipeline:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 要这样做，请更新 Jenkinsfile（chapter10/pipelines/movies-loader/Jenkinsfile），使用 `build
    job` 关键字触发外部作业。例如，在 movies-loader Jenkinsfile 中，将以下 `Deploy` 阶段代码块添加到管道末尾：
- en: '[PRE25]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Commit and push the changes to a feature branch. Then create a pull request
    (PR) to merge to develop. A new build should be triggered on the feature branch,
    and once it’s done, Jenkins will post the build status on the PR, as shown in
    figure 10.21.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改提交并推送到功能分支。然后创建一个拉取请求（PR）以合并到开发分支。应在功能分支上触发新的构建，一旦完成，Jenkins 将在 PR 上发布构建状态，如图
    10.21 所示。
- en: '![](Images/CH10_F21_Labouardy.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F21_Labouardy.png)'
- en: Figure 10.21 Pull request build status
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.21 拉取请求构建状态
- en: Once the pull request is validated, we merge to the develop branch, and a new
    build will be triggered on that branch, as shown in figure 10.22.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦拉取请求得到验证，我们就将其合并到开发分支，并在此分支上触发新的构建，如图 10.22 所示。
- en: '![](Images/CH10_F22_Labouardy.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F22_Labouardy.png)'
- en: Figure 10.22 Jenkins CI/CD pipeline for the movies-loader project
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.22 movies-loader 项目的 Jenkins CI/CD 管道
- en: At the end of the CI pipeline, the deploy stage will be executed, and watchlist-deployment
    will be triggered on the develop branch, as shown in figure 10.23.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在 CI 管道的末尾，将执行部署阶段，并在开发分支上触发 watchlist-deployment，如图 10.23 所示。
- en: '![](Images/CH10_F23_Labouardy.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F23_Labouardy.png)'
- en: Figure 10.23 External job triggering
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.23 外部作业触发
- en: That will trigger the deployment job, which will deploy the stack and force
    the pull of new Docker images with the `develop` tag. Repeat the same process
    for other GitHub repositories. In the end, each repository will trigger a deployment
    to sandbox if the CI is successfully executed, as shown in figure 10.24.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这将触发部署作业，该作业将部署堆栈并强制拉取带有 `develop` 标签的新 Docker 镜像。对其他 GitHub 仓库重复相同的流程。最终，如果
    CI 成功执行，每个仓库将触发沙盒的部署，如图 10.24 所示。
- en: '![](Images/CH10_F24_Labouardy.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F24_Labouardy.png)'
- en: Figure 10.24 Marketplace CI/CD pipeline execution
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.24 市场CI/CD管道执行
- en: Note In chapters 11 and 12, we will cover how to run automated health checks
    and post-integration tests on the deployed application from Jenkins within the
    CI/CD pipeline.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：在第 11 章和第 12 章中，我们将介绍如何在 CI/CD 管道中从 Jenkins 运行部署应用的自动化健康检查和集成测试。
- en: 'By now, our application is deployed to the Swarm sandbox environment. To access
    the application, we need to create two public load balancers: one for the API
    (movies-store) and another for the frontend (movies-marketplace). Use Terraform
    template files available in the GitHub repository (under the /chapter8/services
    folder) to create the AWS resources, and then issue `terraform apply` to provision
    the resources. At the end of the deployment process, the marketplace and store
    API access URLs will be displayed in the `Outputs` section, as shown in figure
    10.25.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的应用程序已部署到 Swarm 沙盒环境。要访问应用程序，我们需要创建两个公共负载均衡器：一个用于 API（movies-store）和另一个用于前端（movies-marketplace）。使用
    GitHub 仓库中可用的 Terraform 模板文件（位于 /chapter8/services 文件夹下）创建 AWS 资源，然后发出 `terraform
    apply` 命令以配置资源。在部署过程结束时，市场和企业 API 访问 URL 将在 `输出` 部分显示，如图 10.25 所示。
- en: '![](Images/CH10_F25_Labouardy.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F25_Labouardy.png)'
- en: Figure 10.25 Terraform apply output
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.25 Terraform 应用输出
- en: Note Make sure to allow inbound traffic on ports 80 (frontend), 8080 (visualizer),
    and 3000 (API) from the security group attached to the Swarm EC2 instances.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：确保允许来自连接到 Swarm EC2 实例的安全组对端口 80（前端）、8080（可视化器）和 3000（API）的入站流量。
- en: For the marketplace to be able to interact with the RESTful API to show a list
    of crawled movies, we need to inject the API URL at the build time of the marketplace
    Docker image. The source code of the marketplace contains multiple files based
    on the target environment (figure 10.26).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使市场能够与RESTful API交互并显示爬取的电影列表，我们需要在市场Docker镜像构建时注入API URL。市场源代码根据目标环境包含多个文件（图10.26）。
- en: '![](Images/CH10_F26_Labouardy.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F26_Labouardy.png)'
- en: Figure 10.26 Angular environment files
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.26 Angular环境文件
- en: Each file contains the right API URL. For the sandbox environment, the environment
    .sandbox.ts file will be used, as shown in the following listing.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 每个文件都包含正确的API URL。对于沙盒环境，将使用环境.sandbox.ts文件，如下所示。
- en: Listing 10.17 Marketplace sandbox environment variables
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.17 市场沙盒环境变量
- en: '[PRE26]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The marketplace Docker image will be built using the `ng` `build` `-c` `sandbox`
    flag, which will replace the environment.ts file with environment.sandbox.ts values;
    see figure 10.27.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 市场Docker镜像将使用`ng` `build` `-c` `sandbox`标志构建，这将用环境.sandbox.ts的值替换环境.ts文件；见图10.27。
- en: '![](Images/CH10_F27_Labouardy.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F27_Labouardy.png)'
- en: Figure 10.27 Docker image build execution
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.27 Docker镜像构建执行
- en: Once the new image is deployed to Swarm, point your browser to the marketplace
    URL. It should display the top 100 IMDb best movies in history, as shown in figure
    10.28.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦将新镜像部署到Swarm，请将您的浏览器指向市场URL。它应该显示历史上IMDb排名前100的电影，如图10.28所示。
- en: '![](Images/CH10_F28_Labouardy.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F28_Labouardy.png)'
- en: Figure 10.28 Watchlist marketplace dashboard
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.28 观看列表市场仪表板
- en: That’s how to reach continuous deployment. However, we want to alert the development
    and product teams of the deployment and CI/CD status of the project.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是实现持续部署的方法。然而，我们希望提醒开发和产品团队项目的部署和CI/CD状态。
- en: 10.3 Integrating Jenkins with Slack notifications
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 将Jenkins与Slack通知集成
- en: At certain stages of the pipeline, you may decide you want to send out a Slack
    notification to your team to inform them of the build status. To send Slack messages
    through Jenkins, we need to provide a way for our job to authorize itself with
    Slack.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在管道的某些阶段，您可能决定想要向团队发送Slack通知，告知他们构建状态。为了通过Jenkins发送Slack消息，我们需要为我们的作业提供一个授权自身与Slack的方式。
- en: Luckily for us, Slack has a prebuilt Jenkins integration that makes things pretty
    easy. Install the plugin from [http://mng.bz/xXOB](http://mng.bz/xXOB). Replace
    `WORKSPACE` with your Slack workspace name, as shown in figure 10.29.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Slack有一个预构建的Jenkins集成，使得事情变得相当简单。从[http://mng.bz/xXOB](http://mng.bz/xXOB)安装插件。将`WORKSPACE`替换为如图10.29所示的Slack工作区名称。
- en: '![](Images/CH10_F29_Labouardy.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F29_Labouardy.png)'
- en: Figure 10.29 Jenkins CI Slack integration
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.29 Jenkins CI Slack集成
- en: Click the Add to Slack button. Then select the channel on which you want Jenkins
    to send notifications, as shown in figure 10.30.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“添加到Slack”按钮。然后选择Jenkins发送通知的频道，如图10.30所示。
- en: '![](Images/CH10_F30_Labouardy.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F30_Labouardy.png)'
- en: Figure 10.30 Slack channel configuration
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.30 Slack频道配置
- en: After that, we need to set the configuration on the Jenkins Slack Notification
    plugin ([https://plugins.jenkins.io/slack/](https://plugins.jenkins.io/slack/)),
    which is already installed on the baked Jenkins master machine image. Enter the
    team workspace name, integration token created on your slack, and channel name,
    as shown in figure 10.31, and click the Apply and Save buttons.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们需要在Jenkins Slack通知插件（[https://plugins.jenkins.io/slack/](https://plugins.jenkins.io/slack/））上设置配置，该插件已经安装在预制的Jenkins主机镜像上。输入团队工作区名称、在您的Slack上创建的集成令牌和频道名称，如图10.31所示，然后点击应用和保存按钮。
- en: '![](Images/CH10_F31_Labouardy.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F31_Labouardy.png)'
- en: Figure 10.31 Jenkins Slack Notification plugin
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.31 Jenkins Slack通知插件
- en: 'Now that we have Slack properly configured in Jenkins, we can configure our
    CI/CD pipeline to send a notification to broadcast the status of the build with
    the following method:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在Jenkins中正确配置了Slack，我们可以配置我们的CI/CD管道，使用以下方法发送通知以广播构建状态：
- en: '[PRE27]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Let’s add this instruction at the end of the CI/CD pipeline for the movies-loader
    service as an example; see the following listing.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 以电影加载器服务的CI/CD管道为例，让我们在管道末尾添加此指令；见以下列表。
- en: Listing 10.18 Jenkins Slack plugin DSL
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.18 Jenkins Slack插件DSL
- en: '[PRE28]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note For simplicity, I skipped steps that run unit tests, build the image, and
    push the image to the registry. You’re advised to put them inside the workflow
    we are about to explore.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：为了简化，我跳过了运行单元测试、构建镜像和将镜像推送到注册表的步骤。建议您将这些步骤放入我们即将探索的工作流程中。
- en: Push the changes to a feature branch, and then merge to develop. At the end
    of the pipeline, a new Slack notification will be sent, as shown in figure 10.32.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改推送到功能分支，然后合并到 develop。在管道结束时，将发送一个新的 Slack 通知，如图 10.32 所示。
- en: '![](Images/CH10_F32_Labouardy.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F32_Labouardy.png)'
- en: Figure 10.32 Jenkins Slack notification
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.32 Jenkins Slack 通知
- en: While this works, we also want to be notified when the pipeline fails. That’s
    where `try-catch` blocks come into play to handle errors thrown by pipeline stages;
    see the following listing.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这可行，但我们还希望在管道失败时收到通知。这就是 `try-catch` 块发挥作用来处理管道阶段抛出的错误的地方；请参见以下列表。
- en: Listing 10.19 Slack notifications within Jenkins
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.19 Jenkins 中的 Slack 通知
- en: '[PRE29]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This time, a `notifySlack()` method is used, which sends a notification with
    a different color based on the pipeline build status, as shown in the following
    listing.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，使用了 `notifySlack()` 方法，该方法根据管道构建状态发送不同颜色的通知，如以下列表所示。
- en: Listing 10.20 Custom Slack notification message color
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.20 自定义 Slack 通知消息颜色
- en: '[PRE30]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: ❶ Colors the border along the left side of the message
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 在消息的左侧边框上着色
- en: ❷ Sends a Slack message with the job name by using the env.JOB_NAME, and build
    status by using the buildStatus variable
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用 env.JOB_NAME 发送带有作业名称的 Slack 消息，并使用 buildStatus 变量发送构建状态
- en: Based on your build result, the code sends Slack notifications as shown in figure
    10.33.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的构建结果，代码将发送如图 10.33 所示的 Slack 通知。
- en: '![](Images/CH10_F33_Labouardy.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F33_Labouardy.png)'
- en: Figure 10.33 Build status notification
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.33 构建状态通知
- en: 'Let’s simulate a build failure by throwing an error, by adding the following
    instruction to the `Build` stage:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过抛出错误来模拟构建失败，将以下指令添加到 `Build` 阶段：
- en: '[PRE31]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Push the changes to GitHub. The pipeline will fail at the `Build` stage (figure
    10.34).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改推送到 GitHub。在 `Build` 阶段，管道将失败（见图 10.34）。
- en: '![](Images/CH10_F34_Labouardy.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F34_Labouardy.png)'
- en: Figure 10.34 Throwing an error within the Jenkins pipeline
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.34 在 Jenkins 管道中抛出错误
- en: On the Slack channel, this time we will receive a notification with the build
    status set to Failure, as you can see in figure 10.35.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Slack 频道中，这次我们将收到构建状态设置为失败的通知，如图 10.35 所示。
- en: '![](Images/CH10_F35_Labouardy.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F35_Labouardy.png)'
- en: Figure 10.35 Build failure Slack notification
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.35 构建失败 Slack 通知
- en: In the following listing, we take this further. We’ll add more information to
    the notification, such as the author of the push event, Git commit ID, and message.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下列表中，我们将进一步扩展。我们将在通知中添加更多信息，例如推送事件的作者、Git 提交 ID 和消息。
- en: Listing 10.21 Custom Slack notification message attributes
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.21 自定义 Slack 通知消息属性
- en: '[PRE32]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: ❶ Displays the job’s name, its status, and build number
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 显示作业的名称、状态和构建号
- en: ❷ Holds the subject’s value and Git info (author, commit message) and build
    URL
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 保存主题值和 Git 信息（作者、提交消息）以及构建 URL
- en: The `notifySlack()` method will call `commitAuthor``()` and `commitMessage``()`
    to get the appropriate information. The `commitAuthor()` method will return the
    name of the commit author by executing the `git show` command, as shown in the
    following listing.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '`notifySlack()` 方法将调用 `commitAuthor()` 和 `commitMessage()` 来获取适当的信息。`commitAuthor()`
    方法将通过执行 `git show` 命令返回提交作者的名称，如以下列表所示。'
- en: Listing 10.22 Git helper function to fetch the author
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.22 获取作者的 Git 辅助函数
- en: '[PRE33]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: ❶ Displays the commit message’s author with the git show command, saves the
    output to the commitAuthor file
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用 git show 命令显示提交消息的作者，并将输出保存到 commitAuthor 文件中
- en: ❷ Reads the commitAuthor file and trims extra spaces
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 读取 commitAuthor 文件并删除额外空格
- en: And the `commitMessage()` method will use the `git` `log` command alongside
    the `HEAD` flag to fetch the commit message description; see the following listing.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '`commitMessage()` 方法将使用带有 `HEAD` 标志的 `git log` 命令来获取提交消息描述；请参见以下列表。'
- en: Listing 10.23 Git helper function to fetch the commit message
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.23 获取提交消息的 Git 辅助函数
- en: '[PRE34]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: ❶ Displays the last commit message description and saves the output in a commitMessage
    file
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 显示最后提交的消息描述，并将输出保存到 commitMessage 文件中
- en: ❷ Reads the commitMessage content and trims extra spaces
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 读取 commitMessage 内容并删除额外空格
- en: If we push the changes, at the end of the CI/CD pipeline, the Slack notifications
    should contain the name of Jenkins job, build ID and its status, author name,
    and commit description, as shown in figure 10.36.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们推送更改，在 CI/CD 管道的末尾，Slack 通知应包含 Jenkins 作业名称、构建 ID 和其状态、作者姓名和提交描述，如图 10.36
    所示。
- en: '![](Images/CH10_F36_Labouardy.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F36_Labouardy.png)'
- en: Figure 10.36 Slack notification with Git commit details
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.36 带有 Git 提交详细信息的 Slack 通知
- en: Apply the same changes for the movies-store, movies-marketplace, and movies-parser
    Jenkinsfiles.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 对 movies-store、movies-marketplace 和 movies-parser 的 Jenkinsfiles 应用相同的更改。
- en: Note Chapter 11 covers how to use the Jenkins Slack Notification plugin to send
    a notification with a changelog as an attachment.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：第 11 章介绍了如何使用 Jenkins Slack 通知插件发送带有更改日志附件的通知。
- en: 10.4 Handling code promotion with Jenkins
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 使用 Jenkins 处理代码升级
- en: Maintaining multiple Swarm cluster environments makes sense to avoid breaking
    things while promoting code to production. Also, having a production-like environment
    can help you keep a mirror of your application running in production and reproducing
    issues in the staging environment without impacting your clients. But this comes
    at a price.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 维护多个 Swarm 集群环境在将代码升级到生产时是有意义的，可以避免在生产中破坏东西。同时，拥有类似生产的环境可以帮助您在生产中运行应用程序的镜像，并在预发布环境中重现问题，而不会影响您的客户。但这是有代价的。
- en: Note You can reduce the costs of the sandbox and staging environments by shutting
    down instances outside of regular business hours.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：您可以通过在正常工作时间之外关闭实例来降低沙箱和预发布环境的成本。
- en: With that being said, create a new Swarm cluster for the staging environment
    in a dedicated staging VPC with a 10.2.0.0/16 CIDR block, or deploy it within
    the same management VPC where Jenkins is deployed, as shown in figure 10.37.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，在专用预发布 VPC 中创建一个新的 Swarm 集群用于预发布环境，该 VPC 使用 10.2.0.0/16 CIDR 块，或者将其部署在
    Jenkins 部署的同一管理 VPC 中，如图 10.37 所示。
- en: '![](Images/CH10_F37_Labouardy.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F37_Labouardy.png)'
- en: Figure 10.37 Deployment of sandbox and staging Swarm clusters and Jenkins within
    the same VPC
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.37 在同一 VPC 内部署沙箱和预发布 Swarm 集群以及 Jenkins
- en: 'Create a preprod branch on the watchlist-deployment GitHub repository by running
    this command:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令在 watchlist-deployment GitHub 仓库上创建一个预生产分支：
- en: '[PRE35]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Create a docker-compose.yml file that uses the `preprod` tag, and update the
    SQS URL to use the staging queue, as shown in the following listing.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个使用 `preprod` 标签的 docker-compose.yml 文件，并将 SQS URL 更新为使用预发布队列，如下所示。
- en: Listing 10.24 Docker Compose for staging deployment
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.24 预发布部署的 Docker Compose
- en: '[PRE36]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Create a Jenkins credential of type SSH Username with Private Key with the SSH
    key pair used to deploy the Swarm staging cluster. Give it a name of `swarm-staging`,
    as shown in figure 10.38.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 使用用于部署 Swarm 预发布集群的 SSH 密钥对创建一个 Jenkins 凭据，类型为 SSH 用户名和私钥。给它命名为 `swarm-staging`，如图
    10.38 所示。
- en: '![](Images/CH10_F38_Labouardy.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F38_Labouardy.png)'
- en: Figure 10.38 Swarm staging cluster SSH credentials
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.38 Swarm 预发布集群 SSH 凭据
- en: Create a Jenkinsfile similar to the one in the develop branch, as shown in the
    following listing. Update the `swarmManager` variable to reference the manager
    staging the IP or DNS record instead. Also update the SSH agent credentials to
    use the Swarm staging credential.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个类似于 develop 分支中的 Jenkinsfile，如下所示。更新 `swarmManager` 变量以引用预发布的 IP 或 DNS 记录。同时更新
    SSH 代理凭据以使用 Swarm 预发布凭据。
- en: Listing 10.25 Jenkinsfile for staging deployment
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.25 用于预发布部署的 Jenkinsfile
- en: '[PRE37]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: ❶ Swarm manager DNS alias record or private IP address
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ Swarm 管理器 DNS 别名记录或私有 IP 地址
- en: ❷ AWS region where the ECR repositories are created
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建 ECR 存储库的 AWS 区域
- en: ❸ Copies docker-compose.yml to the Swarm manager instance over SSH
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 通过 SSH 将 docker-compose.yml 复制到 Swarm 管理实例
- en: ❹ Authenticates with ECR and redeploys the application stack over SSH
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 使用 ECR 进行身份验证并通过 SSH 重新部署应用程序堆栈
- en: Push the changes to the preprod branch. A new preprod nested job should be triggered
    on the watchlist-deployment item on Jenkins upon the push event, as shown in figure
    10.39.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改推送到预生产分支。在 Jenkins 上，当推送事件发生时，应在 watchlist-deployment 项目上触发一个新的预生产嵌套作业，如图
    10.39 所示。
- en: '![](Images/CH10_F39_Labouardy.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F39_Labouardy.png)'
- en: Figure 10.39 Stack deployment on staging
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.39 预发布上的堆栈部署
- en: At the end of the pipeline, the application stack will be deployed to Swarm
    staging. Similarly, to access the application, use Terraform to deploy a public
    load balancer for the marketplace and the store API.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在管道的末尾，应用程序堆栈将被部署到 Swarm 预发布。同样，要访问应用程序，使用 Terraform 部署一个用于市场的公共负载均衡器和商店 API
    的公共负载均衡器。
- en: Finally, to trigger autodeployment on preprod, we need to update the Jenkinsfile
    for each project to trigger the watchlist-deployment on preprod—for example, for
    movies-loader Jenkinsfile. We build and push a Docker image with the `preprod`
    tag, as shown in the next listing.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了在 preprod 上触发自动部署，我们需要为每个项目更新 Jenkinsfile，以触发 preprod 上的 watchlist-deployment——例如，对于
    movies-loader Jenkinsfile。我们构建并推送带有 `preprod` 标签的 Docker 镜像，如下一列表所示。
- en: Listing 10.26 Tagging a Docker image based on the Git branch
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.26 基于Git分支标记Docker镜像
- en: '[PRE38]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: ❶ Authenticates with ECR by using AWS CLI
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用 AWS CLI 通过 ECR 进行认证
- en: ❷ Tags the image with the current Git commit ID and stores it in ECR
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用当前的 Git 提交 ID 标记镜像并将其存储在 ECR 中
- en: ❸ Based on the current Git branch name, the Docker image is tagged with a unique
    tag.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 基于当前 Git 分支名称，Docker 镜像被标记为唯一的标签。
- en: In the following listing, we update the `Deploy` stage’s `if` clause condition
    to trigger the deployment of the external job if the branch name is preprod.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下列表中，我们更新 `Deploy` 阶段的 `if` 子句条件，以在分支名称是 preprod 时触发外部作业的部署。
- en: Listing 10.27 Triggering external deployment job
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.27 触发外部部署作业
- en: '[PRE39]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Push the changes to the develop branch. Then create a pull request to merge
    develop to the preprod branch after Jenkins posts the build status regarding develop
    changes (figure 10.40).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改推送到 develop 分支。然后，在 Jenkins 发布关于 develop 变更的构建状态（如图 10.40）后，创建一个拉取请求以合并 develop
    到 preprod 分支。
- en: '![](Images/CH10_F40_Labouardy.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F40_Labouardy.png)'
- en: Figure 10.40 Pull request build status
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.40 拉取请求构建状态
- en: When the merge occurs, a new build should be triggered on the preprod branch,
    as you can see in the Blue Ocean view in figure 10.41.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 当发生合并时，应该在 preprod 分支上触发一个新的构建，如图 10.41 中的 Blue Ocean 视图所示。
- en: '![](Images/CH10_F41_Labouardy.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F41_Labouardy.png)'
- en: Figure 10.41 Build trigger on preprod branch
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.41 preprod 分支上的构建触发
- en: Once the `Push` stage is executed, a new image with a `preprod` tag should be
    pushed to the Docker registry (figure 10.42).
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦执行了 `Push` 阶段，应该将带有 `preprod` 标签的新镜像推送到 Docker 仓库（如图 10.42）。
- en: '![](Images/CH10_F42_Labouardy.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F42_Labouardy.png)'
- en: Figure 10.42 Docker image with `preprod` tag stored in ECR
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.42 存储在 ECR 中的带有 `preprod` 标签的 Docker 镜像
- en: Then, the deployment job on the preprod branch will be executed to deploy the
    changes on the Docker Swarm staging environment (figure 10.43).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，preprod 分支上的部署作业将被执行，以在 Docker Swarm 阶段环境中部署更改（如图 10.43）。
- en: '![](Images/CH10_F43_Labouardy.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F43_Labouardy.png)'
- en: Figure 10.43 Staging deployment triggered automatically
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.43 自动触发的阶段部署
- en: Make the same changes for other microservices, except for movies-marketplace.
    For movies-marketplace, we need to update the build stage, as shown in the following
    listing, to inject the appropriate environment and point the frontend to the right
    API URL.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 对其他微服务进行相同的更改，除了 movies-marketplace。对于 movies-marketplace，我们需要更新构建阶段，如以下列表所示，以注入适当的环境和将前端指向正确的
    API URL。
- en: Listing 10.28 Injecting API URL during build
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.28 在构建过程中注入 API URL
- en: '[PRE40]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: ❶ If the branch name is develop, we set the environment to sandbox, so the sandbox
    settings are loaded.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 如果分支名称是 develop，我们将环境设置为 sandbox，因此会加载 sandbox 设置。
- en: ❷ If the branch name doesn’t match develop or preprod, the sandbox settings
    will be loaded by default.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 如果分支名称不匹配 develop 或 preprod，则默认加载 sandbox 设置。
- en: Push the changes to GitHub. This time, the Docker build process will be executed
    with the `ENVIRONMENT` argument set to `staging` (when the current branch is preprod),
    as shown in figure 10.44\. This will replace the environment.ts file with environment
    .staging.ts values.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改推送到 GitHub。这次，Docker 构建过程将以 `ENVIRONMENT` 参数设置为 `staging`（当当前分支是 preprod）的方式执行，如图
    10.44 所示。这将用 environment .staging.ts 的值替换 environment.ts 文件。
- en: '![](Images/CH10_F44_Labouardy.png)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F44_Labouardy.png)'
- en: Figure 10.44 Docker build with the environment as an argument
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.44 以环境作为参数的 Docker 构建
- en: 10.5 Implementing the Jenkins delivery pipeline
  id: totrans-346
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 实现 Jenkins 交付管道
- en: Finally, to deploy our application stack to production, you need to spin up
    a new Swarm cluster for the production environment. Once again, I opted to isolate
    the production workload in a dedicated production VPC with the 10.3.0.0/16 CIDR
    block and to set up a VPC peering between the management VPC (where Jenkins is
    located) and production VPC (where Swarm production is deployed). Figure 10.45
    summarizes the deployed architecture.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，要将我们的应用程序堆栈部署到生产环境，您需要为生产环境启动一个新的 Swarm 集群。再次，我选择将生产工作负载隔离在专用的生产 VPC 中，该
    VPC 使用 10.3.0.0/16 CIDR 块，并在管理 VPC（Jenkins 所在位置）和生产 VPC（Swarm 生产部署位置）之间设置 VPC
    对等连接。图 10.45 总结了已部署的架构。
- en: '![](Images/CH10_F45_Labouardy.png)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F45_Labouardy.png)'
- en: Figure 10.45 VPC peering with multiple Swarm cluster VPCs. The management VPC
    where the Jenkins cluster is deployed has access to the sandbox, staging, and
    production VPCs.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.45 多个 Swarm 集群 VPC 的 VPC 对等连接。部署 Jenkins 集群的 VPC 可以访问沙盒、测试和生产 VPC。
- en: Note VPC peering doesn’t support transitive peering. The production, staging,
    and sandbox environments are fully isolated, and packets cannot be routed directly
    from sandbox to production, for example, through the management VPC.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：VPC 对等连接不支持传递对等连接。生产、测试和沙盒环境是完全隔离的，例如，数据包不能直接从沙盒路由到生产环境，通过管理 VPC 进行路由。
- en: On the master branch of the watchlist-deployment repository, create a docker-compose
    .yml file. This time, we use the `latest` tag for services running in production,
    as shown in the next listing.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在 watchlist-deployment 仓库的主分支上创建一个 docker-compose .yml 文件。这次，我们使用 `latest` 标签为生产环境中的服务，如下所示。
- en: Listing 10.29 Docker Compose for production deployment
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.29 生产部署的 Docker Compose。
- en: '[PRE41]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Create a Jenkins credential with the SSH key used to deploy the Swarm cluster
    for the production environment and call it `swarm-production`, as shown in figure
    10.46.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个 Jenkins 凭据，使用用于部署生产环境 Swarm 集群的 SSH 密钥，并将其命名为 `swarm-production`，如图 10.46
    所示。
- en: '![](Images/CH10_F46_Labouardy.png)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F46_Labouardy.png)'
- en: Figure 10.46 Swarm production cluster SSH credentials
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.46 Swarm 生产集群 SSH 凭据。
- en: Then, create a Jenkinsfile, shown in the following listing, to remotely upload
    the docker-compose.yml file to the manager machine. Execute the `docker` `stack`
    `deploy` command to deploy the application.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，创建一个 Jenkinsfile，如下所示，以远程上传 docker-compose.yml 文件到管理机器。执行 `docker stack deploy`
    命令以部署应用程序。
- en: Listing 10.30 Jenkinsfile for production deployment
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.30 生产部署的 Jenkinsfile。
- en: '[PRE42]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: ❶ Clones the GitHub repository—refer to listing 10.25 for instructions.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 克隆 GitHub 仓库——有关说明，请参阅 10.25 列表。
- en: ❷ Copies docker-compose.yml to the Swarm manager over SSH—refer to listing 10.25
    for instructions
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 通过 SSH 将 docker-compose.yml 复制到 Swarm 管理器——有关说明，请参阅 10.25 列表。
- en: ❸ Redeploys the Docker Compose stack over SSH—refer to listing 10.25 for instructions
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 通过 SSH 重新部署 Docker Compose 堆栈——有关说明，请参阅 10.25 列表。
- en: Push the changes to the master branch. The GitHub repository should look like
    fig-ure 10.47.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改推送到主分支。GitHub 仓库应类似于图 10.47。
- en: '![](Images/CH10_F47_Labouardy.png)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F47_Labouardy.png)'
- en: Figure 10.47 Deployment files stored in the GitHub repository
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.47 存储在 GitHub 仓库中的部署文件。
- en: The Jenkins pipeline will be triggered on the master branch. Once the pipeline
    is finished, the application stack will be deployed to the production environment,
    as you can see in figure 10.48.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: Jenkins 管道将在主分支上触发。一旦管道完成，应用程序堆栈将被部署到生产环境，如图 10.48 所示。
- en: '![](Images/CH10_F48_Labouardy.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/CH10_F48_Labouardy.png)'
- en: Figure 10.48 Deployment triggered in the master branch
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.48 在主分支中触发的部署。
- en: To trigger the deployment of production at the end of the CI pipeline, update
    the GitHub repository to trigger the deployment job if the current branch is master.
    For instance, update the movies-loader’s Jenkinsfile to build the image for production
    and push the result to the Docker registry with the `latest` tag, as shown in
    the following listing.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 CI 管道末尾触发生产部署，请更新 GitHub 仓库以触发部署作业，如果当前分支是 master。例如，更新 movies-loader 的 Jenkinsfile
    以构建生产镜像，并使用 `latest` 标签将结果推送到 Docker 仓库，如下所示。
- en: Listing 10.31 Tagging the production image
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.31 标记生产镜像。
- en: '[PRE43]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'For the deployment part, we can simply update the `if` clause to support deployment
    on the master branch too:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 对于部署部分，我们可以简单地更新 `if` 子句以支持在主分支上部署：
- en: '[PRE44]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: However, we want to require manual validation before deploying to production
    to simulate the product/business validation (or QA team running tests before approving
    for production) before deploying releases to production.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们希望在部署到生产之前要求手动验证，以模拟产品/业务验证（或QA团队在生产批准前运行测试）在部署发布到生产之前。
- en: To do so, you can use the Input Step plugin to pause the pipeline execution
    and allow the user to interact and control the deployment process to production,
    as shown in the following listing.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 要这样做，您可以使用输入步骤插件暂停管道执行，并允许用户交互和控制部署过程到生产环境，如下面的列表所示。
- en: Listing 10.32 Requiring user approval before production deployment
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.32 在生产部署前要求用户批准
- en: '[PRE45]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Here, we set the time-out to be 2 hours to give developers enough time to validate
    the release. When the 2-hour time-out is reached, the pipeline will be aborted.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将超时设置为2小时，以给开发者足够的时间验证发布。当2小时超时到达时，管道将被终止。
- en: Note To avoid having a Jenkins worker doing nothing for 2 hours, you can move
    the `Deploy` stage outside a node block. You can also send a Slack reminder when
    waiting for user input.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：为了避免Jenkins工作节点在2小时内无所事事，您可以将`Deploy`阶段移出节点块。您还可以在等待用户输入时发送Slack提醒。
- en: Push the changes to a feature branch, and raise a pull request to merge changes
    to the develop branch after the feature branch is successfully built and approved
    by Jenkins (figure 10.49).
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改推送到功能分支，并在功能分支成功构建并被Jenkins批准后（图10.49），提出合并更改到develop分支的拉取请求。
- en: '![](Images/CH10_F49_Labouardy.png)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F49_Labouardy.png)'
- en: Figure 10.49 Merging the feature branch into develop
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.49 将功能分支合并到develop分支
- en: Merge the changes to the develop branch and delete the feature branch. A new
    build should be triggered on the develop branch, which will deploy the image to
    the Swarm sandbox cluster; see figure 10.50.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 将更改合并到develop分支并删除功能分支。应在develop分支上触发新的构建，这将部署镜像到Swarm沙箱集群；见图10.50。
- en: '![](Images/CH10_F50_Labouardy.png)'
  id: totrans-384
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F50_Labouardy.png)'
- en: Figure 10.50 Deployment to sandbox triggered
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.50 触发沙箱部署
- en: Next, raise a pull request to merge develop into the preprod branch (figure
    10.51).
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，提出合并develop到preprod分支的拉取请求（图10.51）。
- en: Once the PR is merged, a new build will be triggered on the preprod branch,
    at the end of the CI/CD pipeline. The changes will be deployed into the Swarm
    staging cluster, as shown in figure 10.52.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦PR合并，预生产分支将触发新的构建，在CI/CD管道的末尾。更改将被部署到Swarm预发布集群，如图10.52所示。
- en: '![](Images/CH10_F51_Labouardy.png)'
  id: totrans-388
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F51_Labouardy.png)'
- en: Figure 10.51 Merging the develop branch into preprod
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.51 将develop分支合并到preprod
- en: '![](Images/CH10_F52_Labouardy.png)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F52_Labouardy.png)'
- en: Figure 10.52 Deployment to staging cluster triggered
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.52 触发到预发布集群的部署
- en: Finally, create a pull request to merge preprod into the master branch (figure
    10.53).
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，创建一个拉取请求将预生产合并到主分支（图10.53）。
- en: '![](Images/CH10_F53_Labouardy.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F53_Labouardy.png)'
- en: Figure 10.53 Merging the preprod branch into master
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.53 将preprod分支合并到master
- en: When the merge occurs, Jenkins will trigger a build on the master branch of
    the movies-loader service, as illustrated in figure 10.54\. However, this time,
    once it reaches the deploy stage, an input dialog will pop up for deployment confirmation.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 当合并发生时，Jenkins将在movies-loader服务的master分支上触发构建，如图10.54所示。然而，这次，一旦达到部署阶段，将弹出部署确认对话框。
- en: '![](Images/CH10_F54_Labouardy.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F54_Labouardy.png)'
- en: Figure 10.54 CI/CD pipeline execution on the master branch
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.54 主分支上的CI/CD管道执行
- en: As you can see in figure 10.55, the interactive input will ask whether we approve
    the deployment.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 正如图10.55所示，交互式输入将询问我们是否批准部署。
- en: '![](Images/CH10_F55_Labouardy.png)'
  id: totrans-399
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F55_Labouardy.png)'
- en: Figure 10.55 Deployment user input dialog
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.55 部署用户输入对话框
- en: If we click Yes, the pipeline will be resumed, and the deployment job will be
    triggered on the master, as shown in figure 10.56.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们点击是，管道将被恢复，并在master上触发部署作业，如图10.56所示。
- en: '![](Images/CH10_F56_Labouardy.png)'
  id: totrans-402
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F56_Labouardy.png)'
- en: Figure 10.56 Production deployment approval
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.56 生产部署批准
- en: At the end of the deployment process, the new stack will be deployed to Swarm
    production, and a Slack notification will be sent to the configured Slack channel
    (figure 10.57).
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署过程结束时，新的堆栈将被部署到Swarm生产环境中，并且会向配置的Slack频道发送通知（图10.57）。
- en: '![](Images/CH10_F57_Labouardy.png)'
  id: totrans-405
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F57_Labouardy.png)'
- en: Figure 10.57 Production deployment success notification
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.57 生产部署成功通知
- en: With the production deployment covered, you have seen how to deploy containerized
    microservice applications to multiple environments and how to handle code promotion
    within a CI/CD pipeline. However, because we’re managing only three environments
    (sandbox, staging, and production), we will limit the discovering behavior of
    the deployment job to the three main branches by defining a regular expression,
    as shown in figure 10.58.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成生产部署后，您已经了解了如何将容器化的微服务应用程序部署到多个环境，以及如何在 CI/CD 管道中处理代码升级。然而，因为我们只管理三个环境（沙盒、预发布和生产），我们将通过定义正则表达式将部署作业的发现行为限制为三个主要分支，如图
    10.58 所示。
- en: '![](Images/CH10_F58_Labouardy.png)'
  id: totrans-408
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F58_Labouardy.png)'
- en: Figure 10.58 Jenkins discovery behavior based on a regular expression
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.58 基于 regular expression 的 Jenkins 发现行为
- en: As a result, Jenkins will discover and be triggered only if one of the three
    main branches has changed; see figure 10.59.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，只有当三个主要分支之一发生变化时，Jenkins 才会发现并触发；见图 10.59。
- en: '![](Images/CH10_F59_Labouardy.png)'
  id: totrans-411
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/CH10_F59_Labouardy.png)'
- en: Figure 10.59 Deployment multibranch job
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.59 部署多分支作业
- en: So now if we make any change to our application, CI/CD pipelines will be triggered
    and `docker` `stack` `deploy` will be executed, which will update any services
    that were changed from the previous version.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在如果我们对我们的应用程序进行任何更改，CI/CD 管道将被触发，并且将执行 `docker` `stack` `deploy`，这将更新任何从上一个版本更改的服务。
- en: Note If the deployment target is one single host, a swarm is not needed. The
    same docker-compose.yml and procedure explained in this chapter should be sufficient
    to continuously deploy your application on a single-host deployment environment.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：如果部署目标是单个主机，则不需要 Swarm。本章中解释的相同的 docker-compose.yml 和程序足以在单主机部署环境中持续部署您的应用程序。
- en: Summary
  id: totrans-415
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: An S3 bucket or distributed consistent key-value store such as etcd, Consul,
    or ZooKeeper can be used as service discovery to make the nodes autojoin a Swarm
    cluster.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用 S3 存储桶或分布式一致性的键值存储，如 etcd、Consul 或 ZooKeeper，作为服务发现，使节点自动加入 Swarm 集群。
- en: Continuous deployment of containers on a Swarm cluster can be reached by executing
    `docker` `stack` `deploy` over SSH on a Swarm manager.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过在 Swarm 管理器上通过 SSH 执行 `docker` `stack` `deploy`，可以在 Swarm 集群上实现容器的持续部署。
- en: Adding Slack notifications within CI/CD pipelines makes the product delivery
    faster. The sooner the team members are aware of a build, integration, or deployment
    failure, the quicker they can act.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 CI/CD 管道中添加 Slack 通知可以加快产品交付。团队成员越早意识到构建、集成或部署失败，他们就能越快采取行动。
- en: To simulate business/product validation before deploying a production release,
    the Jenkins Input Step plugin can prompt the user for manual validation before
    deployment.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在部署生产版本之前模拟业务/产品验证，Jenkins 输入步骤插件可以在部署前提示用户进行手动验证。
