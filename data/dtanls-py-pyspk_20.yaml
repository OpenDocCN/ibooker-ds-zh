- en: Appendix C. Some useful Python concepts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 C. 一些有用的 Python 概念
- en: Python is a fascinating and complex language. While there is a trove of beginners
    guides to learn the basics of the language, some new or more complex aspects of
    Python are less discussed. This appendix is a nonexhaustive compendium of intermediate
    to advanced Python concepts that will be useful when working with PySpark.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是一种既迷人又复杂的语言。虽然有很多初学者指南可以学习语言的基础，但关于 Python 的一些新或更复杂的功能讨论较少。本附录是非详尽的关于中级到高级
    Python 概念的汇编，这些概念在处理 PySpark 时将非常有用。
- en: C.1 List comprehensions
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C.1 列表解析
- en: List comprehensions are one of Python’s constructs that, once you understand,
    you’ll wonder how you were able to code without using them. At the core, they
    are nothing more than iterations over a list. Their power comes from their conciseness
    and how readable they are. We start using them in chapter 4 when providing multiple
    columns to methods like `select()` and `drop()`, most often to select/drop a subset
    of columns.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 列表解析是 Python 的构造之一，一旦你理解了它，你就会想知道在没有使用它们的情况下是如何进行编码的。本质上，它们只是对列表的迭代。它们的强大之处在于它们的简洁性和可读性。我们从第
    4 章开始使用它们，当时我们向 `select()` 和 `drop()` 等方法提供多个列，通常是为了选择/删除列的子集。
- en: When working with lists, tuples, and dictionaries, it’ll often happen that you
    want to apply an operation to every element in the list. For this, you can use
    the `for` loop, like in the first half of listing C.1 where I create a list of
    columns to delete in my data frame. This is completely valid, if a little long,
    at five lines of code.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 当与列表、元组和字典一起工作时，你经常会想对列表中的每个元素执行一个操作。为此，你可以使用 `for` 循环，就像列表 C.1 的前半部分那样，我在其中创建了一个要删除的数据框列的列表。这是完全有效的，尽管有点长，有五行代码。
- en: We can also use a list comprehension as a replacement for the list creation
    and iteration. This way, we can avoid useless variable assignment, like in the
    second half of listing C.1\. The focus is also squarely on the `drop()` method,
    compared to the loop approach, where we focus more on creating the subset of columns.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用列表解析来替换列表创建和迭代。这样，我们可以避免无用的变量分配，就像列表 C.1 的后半部分那样。焦点也完全集中在 `drop()` 方法上，与循环方法相比，我们更关注创建列的子集。
- en: Listing C.1 Applying a function to every column of my data frame
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.1 将函数应用于数据框的每一列
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: List comprehensions can be especially useful when you consider that PySpark
    can store computations aside from the main code using the `Column` object. In
    listing C.2, for instance, using the `gsod` data at the end of chapter 9, we can
    compute the maximum of the `temp` and `temp_norm` without having to resort to
    typing everything. We also use argument unpacking through the star operator. (See
    section C.2 for more details on this.)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 列表解析在考虑 PySpark 可以使用 `Column` 对象存储除主代码之外的计算时特别有用。例如，在列表 C.2 中，使用第 9 章末的 `gsod`
    数据，我们可以计算 `temp` 和 `temp_norm` 的最大值，而无需键入所有内容。我们还使用了星号操作符进行参数解包。（有关此内容的更多详细信息，请参阅
    C.2 节。）
- en: Listing C.2 Computing the maximum of the `temp` and `temp_norm`
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.2 计算 `temp` 和 `temp_norm` 的最大值
- en: '[PRE1]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ The star prefix operator unpacks the list (see section C.2).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 星号前缀操作符解包列表（请参阅 C.2 节）。
- en: Visually, in figure C.1, we can envision the process in which the new list gets
    built out of the previous list passed as input (through the keyword `in` within
    the list comprehension). The result is a new list, where each element comes from
    the input list, processed through the function at the start.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从视觉上看，在图 C.1 中，我们可以设想新列表是如何从之前作为输入传递的列表（通过列表解析中的关键字 `in`）构建出来的。结果是新的列表，其中每个元素都来自输入列表，并通过开始处的函数进行处理。
- en: '![](../Images/C-01.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/C-01.png)'
- en: Figure C.1 Using a simple list comprehension for computing the max of multiple
    columns
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 C.1 使用简单的列表解析计算多个列的最大值
- en: List comprehension can be much more complex. Here is an artificial example with
    two input lists and an `if` clause to filter out the result.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 列表解析可以更加复杂。这里有一个包含两个输入列表和 `if` 子句以过滤结果的假设示例。
- en: Listing C.3 A more ambitious list comprehension
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.3 更复杂的列表解析
- en: '[PRE2]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Including multiple lists to iterate over will yield a cartesian product of
    the input lists. Here, we have nine elements before the filtering.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 包含多个列表进行迭代会产生输入列表的笛卡尔积。在这里，我们在过滤之前有九个元素。
- en: '![](../Images/C-02.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/C-02.png)'
- en: Figure C.2 A more ambitious list comprehension. Each combination of elements
    from the input list are in the output list, unless they get filtered by the `if`
    clause.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 C.2 一个更有雄心的列表推导。输入列表中元素的所有组合都在输出列表中，除非它们被 `if` 子句过滤掉。
- en: C.2 Packing and unpacking arguments (*args and **kwargs)
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C.2 打包和解包参数 (*args 和 **kwargs)
- en: 'A number of Python and PySpark functions and methods work with a variable number
    of arguments. As an example, in PySpark, we can `select()` one, two, three, and
    so on columns using the same method: the `select()` method. Under the hood, Python
    uses argument packing and unpacking to allow this flexibility. This section introduces
    argument packing and unpacking in the context of PySpark operations. Knowing when
    and how to leverage those techniques goes a long way toward making your code more
    robust and simple.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 Python 和 PySpark 函数和方法可以处理可变数量的参数。以 PySpark 为例，我们可以使用相同的 `select()` 方法选择一个、两个、三个等列：`select()`
    方法。在底层，Python 使用参数打包和解包来允许这种灵活性。本节介绍了在 PySpark 操作上下文中的参数打包和解包。了解何时以及如何利用这些技术对于使你的代码更加健壮和简单大有裨益。
- en: 'As a matter of fact, some of PySpark’s most common data frame methods, such
    as `select()`, `groupby()`, `drop()`, `summary()`, and `describe()` (see chapters
    4 and 5 for more content on those methods), work with an arbitrary number of arguments.
    By going into the documentation, we can see that the argument is prefixed with
    a `*`, just like `drop()`. This is how we can recognize that a method/function
    works with multiple arguments:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，PySpark 中一些最常用的数据框方法，如 `select()`、`groupby()`、`drop()`、`summary()` 和 `describe()`（有关这些方法的更多内容，请参阅第
    4 章和第 5 章），可以与任意数量的参数一起使用。通过查看文档，我们可以看到参数前面有一个 `*`，就像 `drop()` 一样。这就是我们如何识别一个方法/函数可以处理多个参数的方法：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This syntax can look a little confusing if you’ve never encountered it. On the
    other hand, it is so useful, especially in the context of PySpark, that it’s worth
    internalizing it.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从未遇到过这种语法，它可能会让你感到有些困惑。另一方面，它在 PySpark 的上下文中非常有用，因此值得记住。
- en: Taking the `drop()` example, let’s assume that we have a simple four-column
    data frame like in listing C.4\. The columns are named `feat1`, `pred1`, `pred2`,
    and `feat2`; imagine that `feat` columns are features and the `pred` columns are
    predictions from an ML model. In practice, we might have an arbitrarily large
    number of columns we wish to delete, and not just two ML models.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以 `drop()` 为例，假设我们有一个像列表 C.4 中的简单四列数据框。列名为 `feat1`、`pred1`、`pred2` 和 `feat2`；想象一下
    `feat` 列是特征，而 `pred` 列是从机器学习模型得到的预测。在实践中，我们可能有一个任意数量的列需要删除，而不仅仅是两个机器学习模型。
- en: Listing C.4 A simple data frame with four columns
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.4 一个具有四列的简单数据框
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: What is the best way to delete *every* column that has the `pred` prefix? One
    solution is to pass the names of the columns directly to drop, like `sample.drop("pred1",`
    `"pred2")`. This will work as long as we have those two columns named this way.
    What if we have `pred3` and `pred74`?
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的方法是什么来删除所有带有 `pred` 前缀的列？一个解决方案是直接将列名传递给 `drop`，例如 `sample.drop("pred1",
    "pred2")`。只要我们有两个以这种方式命名的列，这就会起作用。如果我们有 `pred3` 和 `pred74` 呢？
- en: For a given data frame `sample`, we saw in chapter 5 that we can use a list
    comprehension (see section C.1 for more information on the topic) to work with
    the list of columns using `sample.columns`. With that, we can easily get the columns,
    starting with `pred`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对于给定的数据框 `sample`，我们在第 5 章中看到，我们可以使用列表推导（有关此主题的更多信息，请参阅 C.1 节）通过 `sample.columns`
    来处理列列表。有了这个，我们可以轻松地获取以 `pred` 开头的列。
- en: Listing C.5 Filtering the columns of the `sample` data frame
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.5 过滤 `sample` 数据框的列
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If we try to perform the `sample.drop(to_delete)` operation, we’ll get a `TypeError:`
    `col` `should` `be` `a` `string` `or` `a` `Column` message. `drop()` takes multiple
    arguments that each are either a string or a `Column`, and we have a list of strings.
    Enter `*args`, also called *argument packing and unpacking*.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试执行 `sample.drop(to_delete)` 操作，我们会得到一个 `TypeError:` `col` `should` `be`
    `a` `string` `or` `a` `Column` 消息。`drop()` 接受多个参数，每个参数要么是一个字符串，要么是一个 `Column`，而我们有一个字符串列表。输入
    `*args`，也称为*参数打包和解包*。
- en: 'The `*` prefix operator operates in two directions: when using it in a function,
    it *unpacks* the argument so it looks like it was individually passed. Used in
    a function definition, it *packs* all the arguments of the function call into
    a tuple.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 前缀运算符 `*` 在两个方向上操作：当在函数中使用它时，它将参数*解包*，使其看起来像单独传递的。在函数定义中使用时，它将函数调用的所有参数打包成一个元组。
- en: C.2.1 Argument unpacking
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2.1 参数解包
- en: Let’s start with the unpacking, as it is the situation we face right now. We
    have a list of strings that we need to extract from each element to pass as arguments
    to `drop()`. Prefixing `to_delete` with a star in `drop()`, just like in the next
    listing, does the trick.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从解包开始，因为这是我们目前面临的情况。我们有一个字符串列表，我们需要从每个元素中提取出来，作为参数传递给`drop()`。在`drop()`中将`to_delete`前加上星号，就像在下一个列表中一样，就能做到这一点。
- en: Listing C.6 Dropping multiple columns at once using the argument unpacking operator
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 列表C.6 使用参数解包操作符一次性删除多个列
- en: '[PRE6]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ pred1 and pred2 are no more!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ pred1和pred2不再存在！
- en: 'I like to think of argument unpacking as a *syntax-ic transformation*, where
    the star “eats” the container of a tuple or list, leaving the elements bare. This
    is best seen visually. In figure C.3, we see the duality: adding the star as a
    prefix to `*to_delete` is equivalent to passing each element of the list as a
    distinct argument.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢将参数解包想象成一个*语法性转换*，其中星号“吞噬”元组或列表的容器，留下元素裸露。这最好通过视觉来理解。在图C.3中，我们看到双重性：将星号作为前缀添加到`*to_delete`中，相当于将列表的每个元素作为独立的参数传递。
- en: '![](../Images/C-03.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图C-03](../Images/C-03.png)'
- en: Figure C.3 Prefixing a list/tuple argument with a stat “unpacks” each element
    into a distinct argument.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图C.3 在列表/元组参数前加上一个状态“解包”会将每个元素解包为一个独立的参数。
- en: C.2.2 Argument packing
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2.2 参数打包
- en: Now that unpacking has been covered, what about packing? For this, let’s create
    a simple implementation of `drop()`. In chapter 4, we saw that drop is equivalent
    to `select()`-ing the columns we don’t want to drop. `drop()` needs to take a
    variable number of arguments. A simple implementation is shown in the next listing.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经介绍了解包，那么打包呢？为此，让我们创建一个简单的`drop()`实现。在第4章中，我们看到了`drop`与`select()`选择我们不希望删除的列是等价的。`drop()`需要接受可变数量的参数。下一个列表显示了简单实现。
- en: Listing C.7 Implementing a simple equivalent of the `drop()` method
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表C.7 实现简单的`drop()`方法等价
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ We pack every argument (other than the first, called df) into a tuple called
    cols.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们将每个参数（除了第一个，称为df）打包到一个名为cols的元组中。
- en: With the function defined, we can see how Python packs the `"pred1"` and `"pred2"`
    arguments into a tuple called `cols` to be used within the function. Again, we
    can use the same `*` prefix to unpack an argument list, as shown on the right
    of figure C.4\.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 函数定义好后，我们可以看到Python如何将`"pred1"`和`"pred2"`参数打包到一个名为`cols`的元组中，以便在函数内部使用。同样，我们可以使用相同的`*`前缀来解包参数列表，如图C.4的右侧所示。
- en: '![](../Images/C-04.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图C-04](../Images/C-04.png)'
- en: Figure C.4 Using `*args` in a function definition. Every argument after the
    first gets lumped into a tuple named `cols`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图C.4 在函数定义中使用`*args`。第一个参数之后的每个参数都会被合并成一个名为`cols`的元组。
- en: C.2.3 Packing and unpacking keyword arguments
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C.2.3 关键字参数的打包和解包
- en: Python also accepts packing and unpacking keyword arguments through the `**`
    prefix operator. If you see a function with `**kwargs` in its signature as illustrated
    in figure C.5, it means it will pack named arguments into a `dictionary` named
    `kwargs` (you don’t have to name it `kwargs`, just like you don’t have to name
    the classical un/packing `args`). PySpark doesn’t use it as much, reserving it
    for optional named parameters for methods taking options. `DataFrame.orderBy()`
    is the best example, where `ascending` is captured as a keyword argument.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Python还接受通过`**`前缀操作符打包和解包关键字参数。如果你看到一个函数的签名中有`**kwargs`，如图C.5所示，这意味着它将命名参数打包到一个名为`kwargs`的`字典`中（你不必将其命名为`kwargs`，就像你不必将经典的不/解包命名为`args`一样）。PySpark并不常用它，而是将其保留用于方法的可选命名参数。`DataFrame.orderBy()`是最好的例子，其中`ascending`被捕获为一个关键字参数。
- en: '![](../Images/C-05.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图C-05](../Images/C-05.png)'
- en: 'Figure C.5 Keyword argument packing and unpacking: The names of the arguments
    are dict keys, and the arguments themselves are values.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图C.5 关键字参数的打包和解包：参数的名称是字典键，参数本身是值。
- en: 'Argument packing and unpacking make Python functions more flexible: we don’t
    have to implement `select1()`, `select2()`, `select3()`, for selecting one, two,
    or three columns. It also makes the syntax easier to remember, as we don’t have
    to pack the columns we wish to select in a list just to make the function happy.
    It also helps with making Python-static typing tools happier, which happens to
    be the topic of the next section.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 参数打包和解包使Python函数更加灵活：我们不必为选择一列、两列或三列实现`select1()`、`select2()`、`select3()`。它还使语法更容易记住，因为我们不必将我们希望选择的列打包成一个列表，只是为了使函数满意。它还有助于使Python静态类型工具更满意，这恰好是下一节的主题。
- en: C.3 Python’s typing and mypy/pyright
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C.3 Python的类型和mypy/pyright
- en: Python is a strongly, yet dynamically typed language. When I was learning to
    program, I recall many more experienced developers chanting this like a mantra.
    I also recall many puzzled looks when I asked, “What does that mean?” The inclusion
    of typing tools—the topic of this section—added a layer of mystique to Python’s
    type story. This section starts with a working definition of strong and dynamic
    typing, before reviewing how Python, and more specifically PySpark, use types
    to simplify and increase the robustness of data-processing and analysis code.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是一种强类型但动态类型语言。在我学习编程的时候，我记得许多经验丰富的开发者像念经一样重复这句话。我也记得当我问“那是什么意思？”时，很多人露出困惑的表情。类型工具的引入——本节的主题——给
    Python 的类型故事增添了一层神秘感。本节从对强类型和动态类型的定义性描述开始，然后回顾 Python 以及更具体地说 PySpark 如何使用类型来简化并增强数据处理和分析代码的健壮性。
- en: 'Strong typing, in the context of a programming language, means that every variable
    has a type. As an example, in Python, the statement `a` `=` `"the` `letter` `a"`
    assigns the string `the` `letter` `a` to the variable `a`. This means that any
    operation we perform on `a` needs to have an implementation that will work on
    a string. Some languages, such as Python, are more flexible in their typing, where
    they’ll allow some function to apply to many types, as long as a behavior is defined.
    Let’s take our string example: in listing C.8, we see that, while we can’t add
    `1` to `a`, we can “add” a string to make a longer string. In Python, every variable
    has a type, and this type matters when performing operations: the `+` operator
    won’t work with an `int` and a `str`, but will work with two `ints` or two `strs`.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在编程语言的环境中，强类型意味着每个变量都有一个类型。例如，在 Python 中，语句 `a = "the letter a"` 将字符串 `the letter
    a` 分配给变量 `a`。这意味着我们对 `a` 执行的任何操作都需要有一个适用于字符串的实现。一些语言，如 Python，在类型方面更加灵活，只要定义了行为，它们就会允许某些函数应用于许多类型。让我们以我们的字符串示例为例：在列表
    C.8 中，我们看到，虽然我们不能将 `1` 加到 `a` 上，但我们可以在 `a` 上“添加”一个字符串来创建一个更长的字符串。在 Python 中，每个变量都有一个类型，并且在执行操作时这个类型很重要：`+`
    操作符不能与 `int` 和 `str` 一起使用，但可以与两个 `int` 或两个 `str` 一起使用。
- en: Listing C.8 Addition between numbers and between strings (concatenation)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.8 数字与字符串之间的加法（连接）
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: A weakly typed language could perform something when passed `a` `+` `1` rather
    than throwing a type error. Weak and strongly typed languages form a gradient
    rather than two clans; the clear boundary between weak and strong typing is still
    up for debate. In our specific case, it is enough to remember that Python carries
    a type for every variable. The type of a variable matters when performing an operation,
    and performing an operation on incompatible types, such as adding `1` to `a` `string`,
    will yield a type error.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 弱类型语言在传递 `a + 1` 时可能会执行某些操作，而不是抛出类型错误。弱类型和强类型语言形成的是一个梯度，而不是两个阵营；弱类型和强类型之间的明确界限仍然有待商榷。在我们的特定情况下，记住
    Python 为每个变量都有一个类型就足够了。变量的类型在执行操作时很重要，对不兼容类型执行操作，例如将 `1` 加到 `a` 字符串上，将产生类型错误。
- en: 'Python is also dynamically typed, which means that type resolution/errors are
    found at runtime, or when the program runs. This is in contrast to *static* typing,
    which means that types are inferred (or known) during compilation. Languages like
    Haskell, OCaml, and even Java are great examples of statically typed languages:
    where Python will throw a runtime error when performing type-incompatible operations,
    a statically typed language will refuse to run the program outright or even compile
    the source code. Whether strict or dynamic typing is best is a matter of personal
    preference. Some argue that strict typing ensures better discipline when coding
    and eliminating type errors. It is also believed that dynamic types help get things
    done without getting sidetracked with extraneous ceremony from the type verification.
    Like many things in programming, it is a topic that is heavily debated, mostly
    by people who have not tried both sides extensively.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Python 还是一种动态类型语言，这意味着类型解析/错误是在运行时或程序运行时发现的。这与 *静态* 类型形成对比，静态类型意味着类型是在编译期间推断（或已知）的。像
    Haskell、OCaml 以及甚至 Java 这样的语言是静态类型语言的优秀例子：当 Python 在执行类型不兼容的操作时会产生运行时错误，而静态类型语言会直接拒绝运行程序或甚至编译源代码。严格的或动态类型哪种更好是一个个人偏好的问题。有些人认为严格的类型可以确保在编码时更好的纪律性，并消除类型错误。也有人认为动态类型有助于在不被类型验证的额外仪式所分散注意力的前提下完成任务。像编程中的许多事情一样，这是一个被广泛讨论的话题，大多数讨论这个话题的人都没有充分尝试过两种方法。
- en: Python 3.5 changed the game slightly by introducing type hints within the language.
    While they do not mean that Python is now a statically typed language, the inclusion
    of optional type checking means that we can reap some of the benefits of static
    checking without having to contend with the very rigid framework they can force.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Python 3.5 通过在语言中引入类型提示而略微改变了游戏规则。虽然这并不意味着 Python 现在是一个静态类型语言，但包含可选的类型检查意味着我们可以获得一些静态检查的好处，而无需与它们可能强加的非常严格的框架抗争。
- en: To start with type checking, you need to get a type checker. The easiest way
    to start is with `mypy` ([http://mypy-lang.org/](http://mypy-lang.org/)); I use
    it for the examples in this section. You can also check pytype (from Google),
    Pyright/Pylance (from Microsoft, bundled with VS Code), and Pyre (from Facebook)
    for alternatives. PyCharm also bundles a type-checking tool out of the box. Refer
    to your editor/type-checker documentation for installation instructions.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始类型检查，你需要获取一个类型检查器。最简单的方法是使用 `mypy` ([http://mypy-lang.org/](http://mypy-lang.org/))；我在本节的示例中使用了它。你也可以检查
    pytype（来自 Google）、Pyright/Pylance（来自 Microsoft，与 VS Code 一起捆绑）、以及 Pyre（来自 Facebook）作为替代方案。PyCharm
    也自带了一个类型检查工具。请参考你的编辑器/类型检查器文档以获取安装说明。
- en: Let’s create a small example where the types do not match. In the following
    code, we have an obvious type error, where we (again!) add an integer value to
    a string (I’ll never learn).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个简单的例子，其中类型不匹配。在下面的代码中，我们有一个明显的类型错误，我们（再次！）将一个整数值添加到一个字符串中（我永远不会学到这一点）。
- en: 'Listing C.9 `type_error.py`: Creating a type error on purpose'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.9 `type_error.py`：故意创建类型错误
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ By annotating value as a float, we indicate that we can pass an int or float
    (every int is a float, but not every float is an int).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 通过将值注解为浮点数，我们表明我们可以传递一个整数或浮点数（每个整数都是浮点数，但不是每个浮点数都是整数）。
- en: ❷ "twenty" is not a float. This is a type error.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ "twenty" 不是一个浮点数。这是一个类型错误。
- en: If you have configured your editor to do type checking as you type, you should
    get an error pretty much right after you type the last line of listing C.9\. If
    not, use the command line tool `mypy` to check your file, as in the following
    listing.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经配置了你的编辑器在编写时进行类型检查，那么在你输入列表 C.9 的最后一行后，你应该几乎立即得到一个错误。如果没有，请使用命令行工具 `mypy`
    来检查你的文件，如下面的列表所示。
- en: Listing C.10 Using the `mypy` command line tool to identify the type error
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.10 使用 `mypy` 命令行工具来识别类型错误
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This is a very simple example, but type hints can be helpful when you design
    your own functions. Not only do they serve as indications about the kind of arguments
    to expect (and return) for the function’s potential users, but they can help enforce
    some desired behavior and explain `TypeError`. In PySpark, they are used to dispatch
    a type of pandas UDF (see chapter 9) without requiring any special annotations
    beyond the types. As an example, I reproduced the `f_to_c` function in listing
    C.11: the signature of the function is `(degrees:` `pd.Series)` `->` `pd.Series`,
    meaning that it takes a single argument that must be a pandas Series and return
    a pandas Series. PySpark takes that typing information and knows automatically
    that it is a Series to Series UDF. Before the introduction of type hints for pandas
    UDFs, you needed to add a second argument to the decorator (see section C.5) to
    help with the dispatch.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的例子，但类型提示在你设计自己的函数时非常有用。它们不仅作为对函数潜在用户期望（和返回）的参数类型的指示，还可以帮助强制执行一些期望的行为并解释
    `TypeError`。在 PySpark 中，它们用于分发 pandas UDF 的类型（见第 9 章），而无需添加任何特殊的类型注解。例如，我在列表 C.11
    中重现了 `f_to_c` 函数：函数的签名是 `(degrees:` `pd.Series)` `->` `pd.Series`，这意味着它接受一个必须是
    pandas Series 的单一参数，并返回一个 pandas Series。PySpark 会自动获取这个类型信息，知道它是一个 Series 到 Series
    的 UDF。在引入 pandas UDF 的类型提示之前，你需要向装饰器添加第二个参数（见第 C.5 节）以帮助分发。
- en: Listing C.11 Typing hints in the `f_to_c` function
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.11 `f_to_c` 函数中的类型提示
- en: '[PRE11]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ f_to_c takes a Series and returns a Series. We know because it’s annotated.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ `f_to_c` 函数接收一个 Series 并返回一个 Series。我们知道这一点，因为它有注解。
- en: 'We end this section with useful typing constructors to use when building your
    own functions. (For more information, refer to PEP484—Type Hints [[https://www.python.org/dev/peps/pep-0484/](https://www.python.org/dev/peps/pep-0484/)].)
    All five constructors, `Iterator`, `Union`, `Optional`, `Tuple`, and `Callable`,
    are imported from the `typing` module when using Python 3.8 (the semantics changed
    slightly in Python 3.9, and they are available without explicit importing; see
    PEP585—Type Hinting Generics In Standard Collections [[https://www.python.org/dev/peps/pep-0585/](https://www.python.org/dev/peps/pep-0585/)]):'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节结束时提供了一些有用的类型构造函数，这些函数可以在构建自己的函数时使用。（更多信息，请参阅PEP484—类型提示 [[https://www.python.org/dev/peps/pep-0484/](https://www.python.org/dev/peps/pep-0484/)]。）当使用Python
    3.8时（Python 3.9中语义略有变化，并且它们可以在不进行显式导入的情况下使用；参见PEP585—标准集合中的类型提示 [[https://www.python.org/dev/peps/pep-0585/](https://www.python.org/dev/peps/pep-0585/)]），所有五个构造函数，`Iterator`、`Union`、`Optional`、`Tuple`和`Callable`，都是从`typing`模块导入的：
- en: '[PRE12]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We’ve encountered `Iterator` from the Iterator of Series (single and multiple)
    in chapter 9\. The `Iterator` type hint means that you are dealing with a collection
    that can be iterated over, for instance a list, a dict, a tuple, or even the content
    of a file. It suggests that this variable will be iterated over, probably by using
    a `for` loop.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第9章中遇到了来自Series（单个和多个）的`Iterator`。`Iterator`类型提示意味着你正在处理一个可以迭代的集合，例如列表、字典、元组，甚至是文件的内容。它暗示这个变量将被迭代，可能通过使用`for`循环。
- en: A `Union` type hint means that the variable can be either type within the union.
    For instance, many PySpark functions have a signature of `Union[Column,` `str]`,
    meaning that they accept either a `Column` object (seen in `pyspark.sql`) or a
    string as an argument. `Optional[...]` is equivalent to `Union[...,` `None]`,
    where we put a type in the ellipsis.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`Union`类型提示意味着变量可以是联合中的任何类型。例如，许多PySpark函数的签名是`Union[Column, str]`，这意味着它们接受`Column`对象（在`pyspark.sql`中看到）或字符串作为参数。`Optional[...]`等同于`Union[...,
    None]`，其中我们在省略号中放置一个类型。'
- en: '`Tuple` is used in the Iterator of multiple Series UDF. Since tuples are immutable
    in Python (you can’t change them in place), we can enforce a strict type through
    annotations. A tuple of three pandas Series would be `Tuple[pd.Series,` `pd.Series,`
    `pd.Series]`.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`Tuple`在多个Series UDF的`Iterator`中使用。由于在Python中元组是不可变的（你无法就地更改它们），我们可以通过注解强制执行严格类型。三个pandas
    Series的元组将是`Tuple[pd.Series, pd.Series, pd.Series]`。'
- en: '`Callable` is addressed in the next section, where we talk about Python closure
    and the `transform()` method. It refers to the type of a function (an object that
    takes arguments to return another object). For instance, the type of the `add_one`
    function in listing C.11 is `Callable[[float],` `float]`: the list in first position
    is the input parameters, and the second is the return value.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`Callable`将在下一节中介绍，我们将讨论Python闭包和`transform()`方法。它指的是函数的类型（一个接受参数以返回另一个对象的对象）。例如，列表C.11中`add_one`函数的类型是`Callable[[float],
    float]`：第一个位置是输入参数，第二个是返回值。'
- en: 'Before ending this section, I encourage you to use type hints as a tool: no
    more, no less. Because type checking is a recent addition to Python, there are
    some rough edges, and we have uneven coverage between different type checkers.
    It is too easy to become obsessed with finding the perfect type signature, which
    will steal precious time from doing useful work.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束本节之前，我鼓励您将类型提示作为一个工具来使用：不多也不少。因为类型检查是Python的一个较新特性，存在一些粗糙的边缘，并且不同类型检查器之间的覆盖范围不均。很容易沉迷于寻找完美的类型签名，这会从做有用的工作中窃取宝贵的时间。
- en: C.4 Python closures and the PySpark transform() method
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C.4 Python闭包和PySpark的transform()方法
- en: If I were to summarize this section in a few words, I would say that you can
    create functions in Python that return functions. This can prove useful when you
    are using higher-order functions (such as `map()` and `reduce()`, seen in chapter
    8), but it also unlocks a very useful—but optional—code pattern when transforming
    data in PySpark.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我要用几个词总结本节，我会说，你可以在Python中创建返回函数的函数。这在使用高阶函数（如第8章中看到的`map()`和`reduce()`）时非常有用，但它也解锁了一个非常有用但可选的代码模式，当在PySpark中转换数据时。
- en: 'In chapter 1, I introduced method chaining as the preferred way of organizing
    data transformation code. The code we submitted as a job in chapter 3, reproduced
    in the next listing, illustrates this concept well: we see a column of dots, each
    a method called on the data frame returned via the previous application.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，我介绍了方法链作为组织数据转换代码的首选方式。我们在第三章提交作为作业的代码，在下述列表中重现，很好地说明了这个概念：我们看到一列点，每个点都是一个对通过前一次应用返回的数据帧调用的方法。
- en: Listing C.12 The word count submit program, with its series of method chaining
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.12 单词计数提交程序，及其一系列方法链
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ The alignment of the code highlights the method chaining.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 代码的对齐突出了方法链。
- en: What if you need to go beyond `select()`, `where()`, `groupby()`, `count()`,
    or any of the methods available out of the box via the data frame API?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要超越 `select()`、`where()`、`groupby()`、`count()` 或通过数据帧 API 可用的任何其他方法呢？
- en: 'Enter the `transform()` method. The `transform()` method takes one argument:
    a function that takes a single parameter. It returns the result of applying the
    function to the data frame. As an example, let’s say we want to compute the modulo
    of a given column. Let’s create a function that takes a data frame as an argument
    and returns the modulo of a column as a new column. Our function takes four arguments:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 进入 `transform()` 方法。`transform()` 方法接受一个参数：一个接受单个参数的函数。它返回将函数应用于数据帧的结果。作为一个例子，假设我们想要计算给定列的模数。让我们创建一个函数，它接受一个数据帧作为参数，并返回一个新列的模数。我们的函数接受四个参数：
- en: The data frame itself
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据帧本身
- en: The name of the old column
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旧列的名称
- en: The name of the new column
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新列的名称
- en: The modulo value
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模数值
- en: Listing C.13 The `modulo_of` function taking four parameters
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.13 接受四个参数的 `modulo_of` 函数
- en: '[PRE14]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: If we want to apply this function to a data frame, we need to apply the function
    like a regular function, such as `modulo_of(df,` `"old",` `"new",` `2)`. This
    breaks the chain of methods, cluttering the code between function application
    and method application. To use the `transform()` method with `modulo_of()`, we
    need to make it a function of a single parameter, the data frame.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要将此函数应用于数据帧，我们需要像常规函数一样应用此函数，例如 `modulo_of(df, "old", "new", 2)`。这打破了方法链，在函数应用和方法应用之间使代码变得杂乱。为了使用
    `transform()` 方法与 `modulo_of()`，我们需要将其变成一个接受数据帧作为单个参数的函数。
- en: In listing C.14, we rewrite our `modulo_of` function to fulfill this contract.
    The return value of `modulo_of()` is a function/callable, taking a data frame
    as an argument and returning a data frame. To have a function to return, we create
    an `_inner_` `func()` that takes a data frame as an argument and returns a transformed
    data frame. `_inner_func()` has access to the parameters passed to `modulo_of()`,
    namely `new_name`, `old_col`, and `modulo_value`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 C.14 中，我们重写我们的 `modulo_of` 函数以满足此协议。`modulo_of()` 的返回值是一个函数/可调用对象，接受一个数据帧作为参数并返回一个数据帧。为了有一个返回函数，我们创建了一个
    `_inner_` `func()`，它接受一个数据帧作为参数并返回一个转换后的数据帧。`_inner_func()` 可以访问传递给 `modulo_of()`
    的参数，即 `new_name`、`old_col` 和 `modulo_value`。
- en: Listing C.14 Rewriting the `modulo_of` function
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.14 重写 `modulo_of` 函数
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ modulo_of() returns a function from a DataFrame to a DataFrame.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ `modulo_of()` 从数据帧返回一个函数到数据帧。
- en: ❷ _inner_func() has access to the parameters passed to modulo_of(), namely new_name,
    old_col, and modulo_value.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ `_inner_func()` 可以访问传递给 `modulo_of()` 的参数，即 `new_name`、`old_col` 和 `modulo_value`。
- en: ❸ We return the function as if it was any other object (it is).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 我们像任何其他对象一样返回函数（它就是）。
- en: How does it work?
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 它是如何工作的？
- en: In Python, functions can return functions, as they are just like any other object.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Python 中，函数可以返回函数，因为它们就像任何其他对象一样。
- en: A function created inside a function in Python has access to the environment
    (defined variables) where it was defined. In the case of `_inner_func()`, the
    helper function `DataFrame` → `DataFrame` we created to return has access to `new_name`,
    `old_col`, and `modulo_value`. This will work even after we end the enclosing
    function block. This is called *closing on a function*, and the resulting function
    is called a *closure*.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Python 中，函数内部创建的函数可以访问其定义的环境（定义的变量）。在 `_inner_func()` 的情况下，我们创建的辅助函数 `DataFrame`
    → `DataFrame` 可以访问 `new_name`、`old_col` 和 `modulo_value`。这即使在结束包围函数块之后也会工作。这被称为
    *函数闭包*，产生的函数被称为 *闭包*。
- en: The result is akin to partially evaluating a function, where we set all the
    parameters in the first “application,” and then set the data frame in the second
    data frame.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果类似于部分评估一个函数，其中我们在第一次“应用”中设置所有参数，然后在第二个数据帧中设置数据帧。
- en: Now we can simply use `transform()` with our newly created “transform-enabled”
    function.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以简单地使用`transform()`与我们的新创建的“允许转换”的函数。
- en: Listing C.15 Applying the `modulo_of()` function to a sample data frame
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 列表C.15 将`modulo_of()`函数应用于样本数据帧
- en: '[PRE16]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To close the loop, what if we wanted to use our new `modulo_of()` function
    like a function, without `transform()`? We just need to apply it two times: the
    first application will return a function taking a data frame as sole argument.
    The second application will return the transformed data frame:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了闭合循环，如果我们想像函数一样使用我们新的`modulo_of()`函数，而不使用`transform()`，那会怎样？我们只需要应用两次：第一次应用将返回一个只接受数据帧作为唯一参数的函数。第二次应用将返回转换后的数据帧：
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Transform-enabled functions are not necessary to write performant and maintainable
    programs. On the other hand, they enable us to embed arbitrary logic through the
    transform method, which keeps the method-chaining code organization pattern. This
    yields cleaner, more readable code.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 允许转换的函数并非编写高性能和可维护程序所必需。另一方面，它们使我们能够通过转换方法嵌入任意逻辑，这保持了方法链代码组织模式。这产生了更干净、更易读的代码。
- en: 'C.5 Python decorators: Wrapping a function to change its behavior'
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: C.5 Python装饰器：包装函数以改变其行为
- en: 'Decorators, at least in the context we encounter them, are a construction that
    allow modification of a function without changing the body of the code. They are
    pretty simple constructions that look complex because of their rather unique syntax.
    Decorators rely on Python’s ability to treat functions as objects: you can pass
    them as arguments and return them from functions (see section C.4). Put simply,
    a decorator is a simplified syntax to wrap a function around a function passed
    as an argument.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 至少在我们遇到的情况下，装饰器是一种允许在不更改代码主体的情况下修改函数的构造。它们看起来很复杂，因为它们的语法相当独特。装饰器依赖于Python将函数视为对象的能力：你可以将它们作为参数传递，并从函数中返回它们（参见C.4节）。简单来说，装饰器是将一个函数包装在作为参数传递的函数周围的一种简化语法。
- en: Decorators can do a lot of things. Because of this, it’s best to focus on how
    they are used in PySpark. In PySpark, we use Python decorators to transform a
    function into a UDF (regular or vectorized/pandas). As an example, let’s review
    the `f_to_c()` UDF we created in chapter 9\. If we recall how the `pandas_udf`
    decorator works, when applied to a function, here `f_to_c()`, the function no
    longer applies to a pandas Series. The decorator transforms it into a UDF that
    can be applied to a Spark `Column`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 装饰器可以做很多事情。正因为如此，最好关注它们在PySpark中的使用。在PySpark中，我们使用Python装饰器将函数转换成UDF（常规或矢量化/熊猫）。作为一个例子，让我们回顾一下在第9章中创建的`f_to_c()`
    UDF。如果我们回想一下`pandas_udf`装饰器的工作原理，当应用于一个函数，这里`f_to_c()`，该函数不再应用于pandas Series。装饰器将其转换为一个可以应用于Spark
    `Column`的UDF。
- en: Listing C.16 The `f_to_c` UDF
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 列表C.16 `f_to_c` UDF
- en: '[PRE18]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ Upon applying the decorator, the f_to_c function is no longer a simple function
    on a pandas Series, but a vectorized UDF to be used on a Spark data frame.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 应用装饰器后，f_to_c函数不再是pandas Series上的简单函数，而是一个用于Spark数据帧的矢量化UDF。
- en: Under the hood, creating UDFs requires some JVM (Java Virtual Machine, as Spark
    is written in Scala, and PySpark leverages the Java API) gymnastics. We can use
    the pseudocode of the `pandas_udf()` decorator to better understand how decorators
    work and how to create one, if needed.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，创建UDF需要一些JVM（Java虚拟机，因为Spark是用Scala编写的，而PySpark利用Java API）技巧。我们可以使用`pandas_udf()`装饰器的伪代码来更好地理解装饰器是如何工作的，以及如何在需要时创建一个装饰器。
- en: Decorators are functions—for completeness, we can have decorator classes, but
    they are not used in the user-facing API for PySpark—that take at least a function
    `f` as an argument. Usually, the decorator perform additional work around the
    function `f` before returning (its return value).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 装饰器是函数——为了完整性，我们可以有装饰器类，但它们在PySpark的用户界面API中并不使用——它们至少需要一个函数`f`作为参数。通常，装饰器在返回（其返回值）之前会在函数`f`周围执行额外的操作。
- en: Listing C.17 The pseudocode for the `pandas_udf` decorator function
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 列表C.17 `pandas_udf`装饰器函数的伪代码
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Let’s create a decorator `record_counter` that will count and print the number
    of records before and after transforming our data frame. `record_counter` takes
    only one argument, the function we want to decorate, and returns a wrapper that
    counts the number of records, applies the function, counts the number of records
    of the result of the function, and returns the result of the function.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个装饰器 `record_counter`，它将计算并打印在转换我们的数据帧之前和之后的记录数。`record_counter` 只接受一个参数，即我们想要装饰的函数，并返回一个包装器，该包装器计算记录数，应用函数，计算函数结果的记录数，并返回函数的结果。
- en: Listing C.18 A simple decorator function
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.18 一个简单的装饰器函数
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ We create a function inside the decorator function, just like with the transform-enabled
    function. This function will be the one returned from applying the decorator.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们在装饰器函数内部创建一个函数，就像在启用转换的函数中做的那样。这个函数将是应用装饰器后返回的函数。
- en: ❷ Before actually applying the function passed as argument, we print the number
    of records.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在实际应用传递给函数的参数之前，我们打印记录数。
- en: ❸ We apply the function and save the value to return at the end of the wrapper
    function.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 我们应用函数并将返回值保存到包装函数的末尾。
- en: ❹ We return the result of the function. Forgetting this would mean that decorating
    a function with record_counter would return nothing.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 我们返回函数的结果。忘记这一点意味着使用 `record_counter` 装饰的函数将返回空值。
- en: ❺ We return the wrapper as a result of the decorator function.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 我们将包装器作为装饰器函数的结果返回。
- en: To apply a decorator to a function, we prefix the function definition with `@record_
    counter`. Python assigns the function on the line right after the decorator as
    the first argument to `record_counter`. When applying a decorator with no additional
    parameter than the function, we don’t have to add parentheses `()` at the end
    of the decorator name.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要将装饰器应用于函数，我们在函数定义前加上 `@record_counter`。Python 将装饰器之后的一行中的函数分配给 `record_counter`
    的第一个参数。当应用没有额外参数（除了函数）的装饰器时，我们不需要在装饰器名称的末尾添加括号 `()`。
- en: Listing C.19 Applying the `record_counter` to a function
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.19 将 `record_counter` 应用到函数中
- en: '[PRE21]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ❶ We put the decorator on top of the function definition. Since our decorator
    takes no additional parameters, we don’t need to add the parentheses at the end.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们将装饰器放在函数定义的顶部。由于我们的装饰器不接收额外的参数，我们不需要在末尾添加括号。
- en: Since a decorated function is a function, we can use it in the same way we would
    use any function. In the case of the pandas UDF, the decorator actually changes
    the nature of the object, so it’s being used differently, but still has that function
    flavor.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 由于装饰后的函数是一个函数，我们可以像使用任何其他函数一样使用它。在 pandas UDF 的情况下，装饰器实际上改变了对象的性质，所以它被以不同的方式使用，但仍然具有函数风味。
- en: Listing C.20 Using our decorated function like any other function
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.20 将我们的装饰函数像任何其他函数一样使用
- en: '[PRE22]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: ❶ We see the before and after counting on top of the show() method of the function
    passed as argument.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 我们在传递给函数的参数的 show() 方法的上方看到计数前后的情况。
- en: 'Since a decorator function is a function, we can also use it without resorting
    to the `@` pattern. For this, we use `record_counter()` as a regular function
    and assign the result to a variable. I personally find the decorator pattern quite
    attractive and clean, as it avoids having two variables: one for the original
    function (`modulo_data_frame2`) and one for the decorated one (`modulo_data_frame_d2`).'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 由于装饰器函数是一个函数，我们也可以不使用 `@` 模式来使用它。为此，我们使用 `record_counter()` 作为常规函数，并将结果赋给一个变量。我个人觉得装饰器模式非常吸引人且简洁，因为它避免了有两个变量：一个用于原始函数（`modulo_data_frame2`）和一个用于装饰后的函数（`modulo_data_frame_d2`）。
- en: Listing C.21 Avoiding the decorator pattern by using a regular function application
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.21 通过使用常规函数应用避免装饰器模式
- en: '[PRE23]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Finally, when working with UDFs, you can still access the original function
    (the one working on Python or pandas objects) through the `func` attribute. This
    is useful when unit testing a function that is already user-defined. It can also
    ensure consistent behavior between pandas and PySpark.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当与 UDF 一起工作时，您仍然可以通过 `func` 属性访问原始函数（在 Python 或 pandas 对象上工作的函数）。这在单元测试已经用户定义的函数时很有用。它还可以确保
    pandas 和 PySpark 之间的一致行为。
- en: Listing C.22 Accessing the original function from the UDF through the `func`
    attribute
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 C.22 通过 `func` 属性从 UDF 访问原始函数
- en: '[PRE24]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Decorators are useful in PySpark for signaling that a function is user-defined
    (as well as in signaling its type). Because decorators are regular Python language
    constructions, we are not limited to using them solely for UDFs: whenever you
    want to add new functionality (we demonstrated logging) to a set of functions,
    decorators are a very readable option.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 装饰器在 PySpark 中非常有用，用于表示一个函数是用户自定义的（以及表示其类型）。因为装饰器是常规的 Python 语言结构，所以我们不仅限于仅将它们用于
    UDFs：无论何时你想向一组函数添加新功能（我们展示了日志记录），装饰器都是一个非常可读的选项。
