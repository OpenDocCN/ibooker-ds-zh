- en: 'Part 3\. Get confident: Using machine learning with PySpark'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分。建立信心：使用PySpark进行机器学习
- en: Parts 1 and 2 were all about data transformation, but we’re going to go above
    and beyond that by tackling scalable machine learning in part 3\. While not a
    complete treatment of machine learning in itself, this part will give you the
    foundation to write your own ML programs in a robust and repeatable fashion.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 第1部分和第2部分都是关于数据转换的，但在第3部分，我们将通过解决可扩展的机器学习来超越这一点。虽然这部分本身并不是对机器学习的完整处理，但它将为你编写稳健且可重复的机器学习程序提供基础。
- en: Chapter 12 sets the stage for machine learning by building features, curated
    bits of information to use for the training process. Feature engineering itself
    is akin to purposeful data transformation. Get ready to use the skills learned
    in parts 1 and 2!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 第12章通过构建特征为机器学习奠定了基础，这些特征是用于训练过程的信息片段。特征工程本身类似于有目的的数据转换。准备好使用在第1部分和第2部分中学到的技能！
- en: Chapter 13 introduces ML pipelines, Spark’s way to encapsulate ML workflows
    in a robust and repeatable way. Now, more importantly than ever, good code structure
    makes or breaks ML programs, so this tool will keep you sane as you build your
    models.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 第13章介绍了机器学习管道，这是Spark以稳健和可重复的方式封装机器学习工作流的方法。现在，比以往任何时候都更重要的是，良好的代码结构决定了机器学习程序的成功或失败，所以这个工具将帮助你保持理智，在你构建模型时。
- en: Finally, chapter 14 extends the ML pipeline abstraction by creating our own
    components. With this, your ML workflows will be infinitely versatile without
    compromising robustness and predictability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，第14章通过创建我们自己的组件扩展了机器学习管道的抽象。有了这个，你的机器学习工作流将无限灵活，同时不会牺牲稳健性和可预测性。
- en: At the end of part 3, you’ll be ready to scale your ML programs. Bring in the
    big data—time for some big insights!
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3部分的结尾，你将准备好扩展你的机器学习程序。引入大数据——是时候获得一些深刻的见解了！
