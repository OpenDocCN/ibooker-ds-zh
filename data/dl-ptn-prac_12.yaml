- en: Part 3\. Working with pipelines
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分\. 使用管道
- en: In this third part, you learn to design and build production pipelines for model
    training, deployment, and serving. We start by introducing you to how hyperparameter
    tuning works under the surface and then show you both a do-it-yourself (DIY) method
    and automatic hyperparameter tuning using KerasTuner. In both cases, effective
    hyperparameter tuning requires good judgement in choosing the search space, so
    we discuss these best practices.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本第三部分，你将学习如何设计和构建用于模型训练、部署和服务的生产级管道。我们首先向你介绍超参数调优在底层是如何工作的，然后展示使用KerasTuner的DIY方法和自动超参数调优。在两种情况下，有效的超参数调优都需要在选择搜索空间时做出良好的判断，因此我们讨论了这些最佳实践。
- en: Next, we turn to transfer learning. In transfer learning, you reuse the weights
    from another trained model and fine-tune a new model with less data and less training
    time. We cover several variations of transfer learning, one for when the domain
    of the new dataset is very similar to the trained model (for example, vegetables
    versus fruits), and another when the domain is very different. Finally, we cover
    domain transfer techniques for initializing models when doing full training.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将转向迁移学习。在迁移学习中，你将重用另一个训练模型的权重，并使用更少的数据和更少的训练时间微调新的模型。我们涵盖了迁移学习的几种变体，一种是在新数据集的领域与训练模型非常相似时（例如，蔬菜与水果），另一种是在领域非常不同时。最后，我们介绍了在完整训练时初始化模型的领域迁移技术。
- en: In the remaining chapters, we dive deep into the entire production-level pipeline.
    We start with the concepts behind data distributions and how they affect the ability
    of a deployed model to generalize to input in the real world that was unseen during
    training. You will learn techniques to improve training the model for generalization.
    Next, we go deep into the components, design, and configuration of a data pipeline,
    covering data warehousing, the ETL process, and model feeding. You’ll learn to
    code these pipelines in a variety of ways, using TF.Keras, `tf.data`, TFRecords,
    and TensorFlow Extended (TFX).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在剩余的章节中，我们将深入探讨整个生产级管道。我们首先探讨数据分布背后的概念以及它们如何影响部署的模型对训练期间未见过的真实世界输入的泛化能力。你将学习提高模型泛化训练的技术。接下来，我们将深入研究数据管道的组件、设计和配置，包括数据仓库、ETL过程和模型喂养。你将学习以多种方式编码这些管道，使用TF.Keras、`tf.data`、TFRecords和TensorFlow
    Extended (TFX)。
- en: Finally, we pull it all together and show how a pipeline extends into training,
    then deployment, and then serving. You’ll see hardware resource details for deployment,
    like sandboxing, load balancing, and autoscaling. In serving, you learn to serve
    from the cloud by using prebuilt and custom containers, and from the edge, and
    get familiar with the details of doing production rollouts and A/B testing.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将所有内容整合在一起，展示管道如何扩展到训练、部署，然后是服务。你将看到部署的硬件资源细节，如沙箱、负载均衡和自动扩展。在服务方面，你将学习如何通过使用预构建和自定义容器从云端提供服务，以及从边缘提供服务，并熟悉生产部署和A/B测试的细节。
