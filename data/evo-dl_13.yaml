- en: '10 NEAT: NeuroEvolution of Augmenting Topologies'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 NEAT：增强拓扑结构的神经进化
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Building evolving augmenting topological networks
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建进化的增强拓扑结构网络
- en: Visualizing a NeuroEvolution of Augmenting Topologies network
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化增强拓扑结构的神经进化网络
- en: Exercising the capabilities of NeuroEvolution of Augmenting Topologies
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锻炼增强拓扑结构的神经进化能力
- en: Exercising NeuroEvolution of Augmenting Topologies to classify images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锻炼增强拓扑结构的神经进化以对图像进行分类
- en: Uncovering the role of speciation in neuroevolution
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 揭示物种形成在神经进化中的作用
- en: Over the course of the last couple of chapters, we explored the evolutionary
    optimization of generative adversarial and autoencoder networks. Much like our
    previous chapters, in those exercises, we layered or wrapped evolutionary optimization
    around DL networks. In this chapter, we break from distributed evolutionary algorithms
    in Python (DEAP) and Keras to explore a neuroevolutionary framework called *NeuroEvolution
    of Augmenting Topologies* (NEAT).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几章的内容中，我们探讨了生成对抗网络和自编码器网络的进化优化。与之前的章节类似，在这些练习中，我们在深度学习网络周围叠加或包裹了进化优化。在本章中，我们脱离了Python中的分布式进化算法（DEAP）和Keras，来探索一个名为*增强拓扑结构的神经进化*（NEAT）的神经进化框架。
- en: NEAT was developed by Ken Stanley in 2002 while at the University of Texas at
    Austin. At the time, GAs (evolutionary computation) and DL (advanced neural networks)
    were equals, and both were considered the next big things in AI. Stanley’s NEAT
    framework captured the attention of many because it combined neural networks with
    evolution to not just optimize hyperparameters, weight parameters, and architecture
    but the actual neural connections themselves.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: NEAT是由肯·斯坦利在2002年开发的，当时他在德克萨斯大学奥斯汀分校。当时，遗传算法（进化计算）和深度学习（高级神经网络）是平等的，并且都被认为是人工智能的下一个大事物。斯坦利的NEAT框架吸引了众多人的注意，因为它将神经网络与进化相结合，不仅优化了超参数、权重参数和架构，而且还优化了实际的神经网络连接本身。
- en: Figure 10.1 shows a comparison between a regular DL network and an evolved NEAT
    network. In the figure, new connections have been added and removed, and the position
    of a node has been removed and/or altered in the evolved NEAT network. Notice
    how this differs from our previous efforts of simply altering the number of nodes
    in a DL-connected layer.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1显示了常规深度学习网络和进化NEAT网络之间的比较。在图中，已经添加和删除了新的连接，并且在进化NEAT网络中删除和/或改变了节点的位置。注意这与我们之前仅仅改变深度学习连接层中节点数量的努力有何不同。
- en: '![](../Images/CH10_F01_Lanham.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F01_Lanham.png)'
- en: Figure 10.1 A comparison between DL and NEAT networks
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 深度学习网络和NEAT网络的比较
- en: NEAT takes the concept of evolving a DL network to the limit by allowing the
    network’s neural connections and number of nodes to evolve. Since NEAT also internally
    evolves the network weights of each node, the complexities of calculating backpropagation
    of errors using calculus are eliminated. This allows NEAT networks to evolve to
    some complex interwoven and interconnected graphs. It can even allow networks
    to evolve recurrent connections, as we see in the next chapter when we explore
    NEAT in greater depth.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: NEAT通过允许网络的神经连接和节点数量进化，将进化深度学习网络的概念推向了极致。由于NEAT还内部进化每个节点的网络权重，因此消除了使用微积分计算误差反向传播的复杂性。这使得NEAT网络能够进化到一些复杂的交织和互联的图。它甚至允许网络进化循环连接，正如我们在下一章深入探讨NEAT时所看到的。
- en: 'In this chapter, we explore the basics of NEAT and dig into a Python implementation
    called NEAT-Python. This framework does a good job of abstracting the finer details
    of setting up evolution and DL systems. The following list identifies each component
    of NEAT that encompasses many of the other methods used throughout this book:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了NEAT的基本原理，并深入研究了名为NEAT-Python的Python实现。这个框架很好地抽象了设置进化和深度学习系统的细节。以下列表标识了NEAT的每个组件，这些组件涵盖了本书中使用的许多其他方法：
- en: '*Neuroevolution of parameters*—Weights and parameters in NEAT evolve as part
    of the system. In chapter 6, we used evolution to alter the weights of a neural
    network.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*参数的神经进化*——NEAT中的权重和参数作为系统的一部分进化。在第6章中，我们使用进化来改变神经网络的权重。'
- en: '*Neuroevolution of architecture*—NEAT evolves network layers, and the structure
    itself adapts through evolution. See chapter 7, in which we covered neuroevolving
    architectures using genetic algorithms, for more on the topic.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*架构的神经进化*——NEAT进化网络层，结构本身通过进化进行适应。参见第7章，其中我们介绍了使用遗传算法进行神经进化架构的内容，以了解更多相关信息。'
- en: '*Hyperparameter optimization*—NEAT doesn’t use learning rates, optimizers,
    or other standard DL assisters. As such, it doesn’t need to optimize those parameters.
    However, NEAT, as we will see, introduces several hyperparameters to control network
    evolution.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*超参数优化*——NEAT不使用学习率、优化器或其他标准深度学习辅助工具。因此，它不需要优化这些参数。然而，正如我们将看到的，NEAT引入了几个超参数来控制网络进化。'
- en: In the next section, we start our exploration of NEAT by starting with the basics.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们从基础知识开始，开始探索NEAT。
- en: 10.1 Exploring NEAT with NEAT-Python
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 使用NEAT-Python探索NEAT
- en: The first notebook we look at in this chapter sets up a NEAT network to solve
    the classic first-order XOR problem. NEAT exposes several configuration options,
    and this first exercise showcases some of the most important ones. Open your web
    browser, and let’s start looking at some code.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们首先考虑的笔记本设置了一个NEAT网络来解决经典的一阶XOR问题。NEAT提供了几个配置选项，这个第一个练习展示了其中一些最重要的选项。打开您的网络浏览器，让我们开始查看一些代码。
- en: Open the EDL_10_1_NEAT_XOR.ipynb notebook in Google Colab. Refer to the appendix
    if you need assistance. Run all the cells in the notebook by selecting Runtime
    > Run All from the menu.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Colab中打开EDL_10_1_NEAT_XOR.ipynb笔记本。如需帮助，请参阅附录。通过选择菜单中的“运行”>“运行所有”来运行笔记本中的所有单元格。
- en: NEAT-Python is still in active development, and at the time of writing, the
    best practice is to install it directly from the GitHub repository rather than
    the PyPi package. The first code cell in the notebook does this using `pip` on
    the first line, as shown in the following listing. Then, the next line imports
    the package with `import neat`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: NEAT-Python仍在积极开发中，截至写作时，最佳实践是直接从GitHub仓库安装它，而不是从PyPi包安装。笔记本中的第一个代码单元格使用`pip`在第一行执行此操作，如下所示。然后，下一行使用`import
    neat`导入包。
- en: 'Listing 10.1 EDL_10_1_NEAT_XOR.ipynb: Install NEAT-Python'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.1 EDL_10_1_NEAT_XOR.ipynb：安装NEAT-Python
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Installs from the GitHub repository
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从GitHub仓库安装
- en: ❷ Imports the package
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 导入包
- en: Scrolling down, the next cell shows the setup of the data, divided into the
    `xor_inputs` (X) and the `xor_outputs` (Y), as shown in the following listing.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动到下一个单元格，显示数据的设置，分为`xor_inputs`（X）和`xor_outputs`（Y），如下所示。
- en: 'Listing 10.2 EDL_10_1_NEAT_XOR.ipynb: The data setup'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.2 EDL_10_1_NEAT_XOR.ipynb：数据设置
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '❶ Inputs: X'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 输入：X
- en: '❷ Outputs: Y'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 输出：Y
- en: Next, as we have done several times before, we build an evaluation function
    to calculate the `fitness` of an evolved NEAT network. The concept here should
    be quite familiar now, and the code is similar to that in previous exercises.
    Unlike with DEAP, the evaluation function takes a set of `gene` sequences called
    `genomes`. The function loops through the `genomes` and calculates the `fitness`
    for each, starting by assigning some maximum `fitness`, as shown in listing 10.3\.
    Then, it creates a new version of a classic feed-forward network using the `FeedForwardNetwork.create`
    function passing in the `genome` and a config. The constructed network is then
    exercised on all the data by using the `net.activate` function, passing in one
    of the `X` or `xi` values and producing the `Y` output. After each input is activated,
    the output is compared with the expected output, `xo`, and the mean squared error
    (MSE) is subtracted from the `genome.fitness`. Finally, the result of the `eval_genomes`
    function updates the current `fitness` of each evolved `genome`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，正如我们之前多次做的那样，我们构建一个评估函数来计算进化NEAT网络的“适应度”。这个概念现在应该相当熟悉了，代码与之前的练习相似。与DEAP不同，评估函数接受一组称为“基因组”的“基因”序列。函数遍历“基因组”，并为每个计算“适应度”，首先分配一些最大“适应度”，如列表10.3所示。然后，它使用`FeedForwardNetwork.create`函数创建一个经典的前馈网络的新版本，传入`genome`和配置。然后，通过使用`net.activate`函数对所有数据进行测试，传入`X`或`xi`值之一，并产生`Y`输出。每次激活输入后，输出与预期的输出`xo`进行比较，从`genome.fitness`中减去均方误差（MSE）。最后，`eval_genomes`函数的结果更新了每个进化“基因组”的当前“适应度”。
- en: 'Listing 10.3 EDL_10_1_NEAT_XOR.ipynb: Creating the evaluation function'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.3 EDL_10_1_NEAT_XOR.ipynb：创建评估函数
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Loops through genomes
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 遍历基因组
- en: ❷ Assigns the maximum fitness
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 分配最大适应度
- en: ❸ Creates a NEAT network from the genome
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 从基因组创建NEAT网络
- en: ❹ Loops through the data
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 遍历数据
- en: ❺ Calculates the MSE and then subtracts from the fitness
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 计算均方误差（MSE）然后从适应度中减去
- en: 'The next cell sets up the configuration file we use to configure and run the
    NEAT code. NEAT-Python (NP) is primarily configuration driven, and there are several
    options you can alter or tweak. To keep things simple, we just review the primary
    options in listing 10.4: the first two sections. The `config` starts by setting
    the `fitness` criterion, a `fitness` threshold, `population` size, and `reset`
    option. After that, the default `genome` configuration is set, first with the
    option for activation, which, in this case, is simply the `sigmoid` function.
    NEAT allows you to choose from a number of activation functions as options used
    for both internal interconnected nodes and outputs.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个单元格设置了用于配置和运行NEAT代码的配置文件。NEAT-Python（NP）主要是由配置驱动的，你可以更改或微调几个选项。为了保持简单，我们只回顾列表10.4中的主要选项：前两个部分。`config`首先设置`fitness`标准、`fitness`阈值、种群大小和`reset`选项。之后，设置默认的`genome`配置，首先是激活选项，在这种情况下，只是`sigmoid`函数。NEAT允许你从多个激活函数中选择选项，这些选项用于内部互联节点和输出。
- en: 'Listing 10.4 EDL_10_1_NEAT_XOR.ipynb: Configuration setup'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.4 EDL_10_1_NEAT_XOR.ipynb：配置设置
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Writes the contents of a cell to a file called config
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将单元格内容写入名为config的文件
- en: ❷ The general configuration parameters
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 一般配置参数
- en: ❸ Sets the number of individuals to evolve
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 设置要进化的个体数量
- en: ❹ The genome configuration parameters
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 基因配置参数
- en: ❺ The default activation function
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 默认激活函数
- en: The last code cell in the notebook contains all the code we need to evolve a
    NEAT network. We start by reviewing the first few lines in listing 10.5\. The
    code starts by loading the configuration and setting the base assumptions for
    the type of `genome`, `reproduction`, `speciation`, and `stagnation`. We cover
    each of those defaults later in this and the next chapter. After that, the `genome`
    `population` is created from the `config`. Then, a reporter, the `StdOutReporter`,
    is added to the `population` object to track the evolutionary process. Notice
    how the `population` object `p` becomes the focus for evolution and is how it
    differs from DEAP.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本中的最后一个代码单元格包含我们进化NEAT网络所需的所有代码。我们首先回顾列表10.5中的前几行。代码首先加载配置并设置基因、繁殖、物种和停滞的基础假设。我们将在本章和下一章中介绍这些默认值。之后，从`config`创建`genome`种群。然后，向`population`对象添加报告器`StdOutReporter`以跟踪进化过程。注意`population`对象`p`是如何成为进化的焦点，以及它与DEAP的不同之处。
- en: 'Listing 10.5 EDL_10_1_NEAT_XOR.ipynb: Setting up NEAT evolution'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.5 EDL_10_1_NEAT_XOR.ipynb：设置NEAT进化
- en: '[PRE4]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Loads the configuration from the config file
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从配置文件中加载配置
- en: ❷ Creates the population
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建种群
- en: ❸ Adds a reporter to see results while evolving
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在进化过程中添加报告器以查看结果
- en: Running or performing the evolution of the `population` is simply done by calling
    the `run` function on the `population` object, as shown in the following listing.
    After evolution is complete, the code prints out the winner, or `genome` with
    the best `fitness`, and outputs the prediction over the XOR inputs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在`population`对象上调用`run`函数，简单地运行或执行种群的进化，如下所示。进化完成后，代码将打印出获胜者，即具有最佳`fitness`的`genome`，并输出对XOR输入的预测。
- en: 'Listing 10.6 EDL_10_1_NEAT_XOR.ipynb: Evolving the `population`'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.6 EDL_10_1_NEAT_XOR.ipynb：进化种群
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Performs evolution on the population
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 对种群执行进化
- en: ❷ Prints out the best genome
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 打印出最佳基因
- en: ❸ Uses the genome to predict XOR and display
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用基因预测XOR并显示
- en: The output of running this example is shown in figure 10.2\. Unlike DEAP, NP
    uses the concept of `fitness` thresholds to control evolution iterations. If you
    recall, in the `config` setup, we set the `fitness_threshold` to `3.99` (see listing
    10.4). The figure also shows the textual output of the network configuration and
    weights. Of course, this is not something easily visualized, but we cover that
    in a future section. At the bottom of the figure, you can see how well the XOR
    inputs are being correctly predicted.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此示例的输出如图10.2所示。与DEAP不同，NP使用`fitness`阈值的概念来控制进化迭代次数。如果你还记得，在`config`设置中，我们将`fitness_threshold`设置为`3.99`（见列表10.4）。图中还显示了网络配置和权重的文本输出。当然，这并不是容易可视化的东西，但我们将在未来的章节中介绍。在图的下端，你可以看到XOR输入被正确预测的程度。
- en: '![](../Images/CH10_F02_Lanham.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F02_Lanham.png)'
- en: Figure 10.2 The final output of evolving a NEAT network on XOR
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 在XOR上进化NEAT网络的最终输出
- en: This exercise demonstrated how we can quickly set up a NEAT evolution to create
    a network capable of predicting the XOR function. As you can see, there are plenty
    of details abstracted through the code, but hopefully, at this stage, you understand
    some of the inner workings of how evolution is being applied. Aside from the augmenting
    node topologies, we have performed everything being done internally previously
    with DEAP.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习演示了我们可以如何快速设置NEAT进化来创建一个能够预测XOR函数的网络。正如你所看到的，代码中抽象了很多细节，但希望在这个阶段，你理解了进化是如何被应用的内部工作原理的一些内容。除了增强节点拓扑结构之外，我们之前使用DEAP完成了所有内部操作。
- en: 10.1.1 Learning exercises
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 学习练习
- en: 'Use the following learning exercises to understand more about NEAT:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下学习练习来了解更多关于NEAT的信息：
- en: Alter the `population` size (`pop_size`) in listing 10.4 and then rerun the
    notebook. How does `population` size affect evolution?
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在列表10.4中更改`population`大小（`pop_size`），然后重新运行笔记本。`population`大小如何影响进化？
- en: Decrease the `fitness_threshold` in listing 10.4 and then see what effect this
    has on the results after rerunning the notebook.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在列表10.4中减小`fitness_threshold`，然后重新运行笔记本，看看这会对结果产生什么影响。
- en: Change the inputs or outputs to match another function or write a function to
    create the outputs in listing 10.2\. Then, rerun the notebook to see the results
    of approximating the new function.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改输入或输出以匹配另一个函数，或者编写一个函数来创建列表10.2中的输出。然后，重新运行笔记本以查看近似新函数的结果。
- en: From this basic introduction, we move on to explore visualizing what an evolved
    NEAT network looks like in the next section.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个基本介绍开始，我们将在下一节中探索可视化进化的NEAT网络看起来是什么样子。
- en: 10.2 Visualizing an evolved NEAT network
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 可视化进化的NEAT网络
- en: Now that we have the basics of setting up NEAT-Python out of the way, we can
    look at adding some useful tools to our tool belt. Visualizing a NEAT network
    can be useful for understanding how the network architecture is forming. It also
    highlights how well the network is overfitting or underfitting a problem.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将NEAT-Python的基本设置完成，我们可以看看添加一些有用的工具到我们的工具箱中。可视化NEAT网络对于理解网络架构是如何形成的非常有用。它还突出了网络在拟合或欠拟合问题上的表现如何。
- en: In this section, we take the previous notebook example and add the ability to
    visualize the evolved best `genome` network. We also take a close look at how
    the evaluation `fitness` function is developed.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们采用之前的笔记本示例，并添加了可视化进化的最佳`genome`网络的能力。我们还仔细研究了评估`fitness`函数是如何开发的。
- en: Open the EDL_10_2_NEAT_XOR_Visualized.ipynb notebook in Google Colab. Refer
    to the appendix if you need assistance. Run all the cells in the notebook by selecting
    Runtime > Run All from the menu.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Colab中打开EDL_10_2_NEAT_XOR_Visualized.ipynb笔记本。如需帮助，请参阅附录。通过选择菜单中的“运行”>“运行所有”来运行笔记本中的所有单元格。
- en: Jump down to the code cell after the `config` is loaded to start. All this code
    is normally handled within the `population` class, but we extracted this small
    section, shown in listing 10.7, to highlight building an evaluation function.
    In NP, all `genomes` need a key or unique identifier, and here we arbitrarily
    use `fred`. Then, a `genome` is created from `config` based on the default type—in
    this case, a `DefaultGenome`. After that, the `genome` is configured with `genome.configure_new`
    passing in the `genome_config`. Finally, a new `fred` 1.0 random network is created,
    with `FeedForwardNetwork.create` passing in the `genome` and `config`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 跳到加载`config`后的代码单元格开始。所有这些代码通常都在`population`类中处理，但我们提取了这个小节，如列表10.7所示，以突出构建评估函数。在NP中，所有`genomes`都需要一个键或唯一标识符，这里我们任意使用`fred`。然后，根据默认类型从`config`创建一个`genome`——在这个例子中，是一个`DefaultGenome`。之后，使用`genome_config`通过`genome.configure_new`配置`genome`。最后，通过`FeedForwardNetwork.create`传递`genome`和`config`创建了一个新的`fred`
    1.0随机网络。
- en: 'Listing 10.7 EDL_10_2_NEAT_XOR_Visualized.ipynb: Creating a `genome` network'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.7 EDL_10_2_NEAT_XOR_Visualized.ipynb：创建`genome`网络
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Gives the genome a key
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为基因组分配一个键
- en: ❷ Creates the genome type
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 创建基因组类型
- en: ❸ Configures the genome from config
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 从配置中配置基因组
- en: ❹ Creates a FeedForwardNetwork from the genome
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 从基因组创建前馈网络
- en: Next, the network `net` is `evaluated`, using a `for` loop to iterate over the
    data to accumulate the MSE subtracted from a max `fitness`, as shown in listing
    10.8\. Recall that within the actual evaluation function in listing 10.4, the
    code also looped through the full `population` of `genomes`. For simplicity, we
    just `evaluate` the `genome` `fred` here. The output of this code block shows
    the input and output from the network as well as the total `fitness`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，网络`net`被`评估`，使用`for`循环遍历数据，从最大`适应度`中减去MSE，如列表10.8所示。回想一下，在实际评估函数列表10.4中，代码也遍历了整个`基因组`的`种群`。为了简单起见，我们在这里只`评估`了`基因组`
    `fred`。此代码块的输出显示了网络的输入和输出以及总`适应度`。
- en: 'Listing 10.8 EDL_10_2_NEAT_XOR_Visualized.ipynb: Evaluating the `genome`'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.8 EDL_10_2_NEAT_XOR_Visualized.ipynb：评估`基因组`
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Assigns a maximum value for fitness
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 分配最大适应度值
- en: ❷ Loops through the x and y values
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 遍历x和y值
- en: ❸ Activates the network on the input
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在输入上激活网络
- en: ❹ Calculates the MSE and then subtracts
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 计算MSE然后减去
- en: Following the setup of `fred`, we move on to the `draw_net` function. This function
    has been directly extracted from the NEAT examples and uses Graphviz to draw an
    evolved network. Go ahead and review the code on your own, but we won’t focus
    on the specifics here. Rather, we want to look at how to call the function and
    what it generates.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置`fred`之后，我们继续到`draw_net`函数。此函数已直接从NEAT示例中提取，并使用Graphviz绘制一个进化的网络。您可以自己查看代码，但在这里我们不会关注具体细节。相反，我们想看看如何调用该函数以及它生成的内容。
- en: Calling the `draw_net` function is shown next; it starts with naming the input
    and output nodes in a dictionary. After that, the `draw_net` function is called
    by passing in the `config`, a `genome`, and the names of the primary nodes (input
    and output). We pass in the value `True` to visualize the output, as shown in
    the following listing.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是调用`draw_net`函数；它首先在字典中命名输入和输出节点。之后，通过传递`config`、`genome`和主要节点（输入和输出）的名称来调用`draw_net`函数。我们传递值`True`以可视化输出，如下所示。
- en: 'Listing 10.9 EDL_10_2_NEAT_XOR_Visualized.ipynb: Calling the `draw_net` function'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.9 EDL_10_2_NEAT_XOR_Visualized.ipynb：调用`draw_net`函数
- en: '[PRE8]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Name the input and output nodes.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 命名输入和输出节点。
- en: ❷ Call the function with True to view.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用True调用函数以查看。
- en: Figure 10.3 shows the output of the base and unevolved `genome` we have called
    `fred`. As you can see, the network is a very simple one-node network with two
    inputs, labeled `X1` and `X2`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3显示了我们所称的`fred`的基本和未进化的`基因组`的输出。如图所示，网络是一个非常简单的单节点网络，有两个输入，分别标记为`X1`和`X2`。
- en: '![](../Images/CH10_F03_Lanham.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F03_Lanham.png)'
- en: Figure 10.3 A beginning NEAT network visualized
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 一个初始的NEAT网络可视化
- en: At this point, the NEAT `population` should have evolved, and we can again call
    the `draw_net` function, this time passing in the winning `genome` `winner`. Calling
    `run` on `population` outputs the winner, or best `genome`. Then, the network
    is created from the winner to demonstrate activations. Next, `draw_net` is called
    with the winner’s `genome` to visualize the network, as shown in the following
    listing.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，NEAT的`种群`应该已经进化，我们可以再次调用`draw_net`函数，这次传入获胜的`基因组` `winner`。在`种群`上调用`run`会输出获胜者，或最佳`基因组`。然后，从获胜者创建网络以展示激活。接下来，使用获胜者的`基因组`调用`draw_net`来可视化网络，如下所示。
- en: 'Listing 10.10 EDL_10_2_NEAT_XOR_Visualized.ipynb: Visualizing the winning `genome`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.10 EDL_10_2_NEAT_XOR_Visualized.ipynb：可视化获胜`基因组`
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ❶ Evolves the winner genome
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 进化获胜基因组
- en: ❷ Outputs the winner score
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 输出获胜分数
- en: ❸ Loops through and shows activations
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 遍历并显示激活
- en: ❹ Draws the evolved winning genome
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 绘制进化的获胜基因组
- en: Figure 10.4 shows the output of the winning `genome` network. This certainly
    doesn’t resemble the classic DL network with regular layers. Instead, what we
    see here is an optimized network capable of efficiently processing the XOR problem.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4显示了获胜`基因组`网络的输出。这显然与经典的深度学习网络中的常规层不相似。相反，我们在这里看到的是一个能够高效处理XOR问题的优化网络。
- en: '![](../Images/CH10_F04_Lanham.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F04_Lanham.png)'
- en: Figure 10.4 Visualizing the winning `genome` network
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 显示获胜`基因组`网络
- en: Being able to visualize the resulting evolved network is helpful for understanding
    how NEAT works. It can also be helpful to visualize an evolving network to see
    and understand if the configuration parameters are adequate. As we see in the
    next section, NEAT has many knobs and dials we need to understand to develop solutions
    to more complex problems.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 能够可视化最终演化的网络有助于理解NEAT的工作原理。可视化一个演化的网络也有助于了解配置参数是否足够。正如我们在下一节中看到的，NEAT有许多旋钮和开关，我们需要理解它们来开发解决更复杂问题的解决方案。
- en: 10.3 Exercising the capabilities of NEAT
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.3 锻炼NEAT的能力
- en: NEAT and its implementation in NEAT-Python are tools that encapsulate many of
    the optimization patterns we have practiced in this book. NEAT incorporates network
    hyperparameter, architecture, and parameter optimization as well as augmenting
    topologies. But does it do it well?
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: NEAT及其在NEAT-Python中的实现是封装了我们在这本书中实践过的许多优化模式的工具。NEAT将网络超参数、架构和参数优化以及拓扑增强纳入其中。但它做得好吗？
- en: In this section, we revisit one of our fun visual classification examples that
    used the sklearn package to make example datasets. If you recall, we demonstrated
    parameter weight optimization with EC in chapter 6\. Not only does this provide
    an excellent baseline, but it also demonstrates several other configuration options
    of NEAT.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们回顾了我们使用sklearn包制作示例数据集的一个有趣的视觉分类示例。如果你还记得，我们在第6章中展示了使用EC进行参数权重优化。这不仅提供了一个很好的基线，还展示了NEAT的几个其他配置选项。
- en: Open the EDL_10_3_NEAT_Circles.ipynb notebook in Google Colab. Refer to the
    appendix if you need assistance. Run all the cells in the notebook by selecting
    Runtime > Run All from the menu.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Colab中打开EDL_10_3_NEAT_Circles.ipynb笔记本。如需帮助，请参考附录。通过菜单选择Runtime > Run
    All来运行笔记本中的所有单元格。
- en: '![](../Images/CH10_F05_Lanham.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F05_Lanham.png)'
- en: Figure 10.5 Configuring parameters for dataset generation
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 配置数据集生成参数
- en: We start with the Dataset Parameters form and output shown in figure 10.5\.
    This is the same form we used in earlier chapters to generate various forms of
    classification problem datasets. To start, we use the moons problem to generate
    a simple dataset. The generated output shows a dataset that should be relatively
    easy to classify with a simple network.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从数据集参数表和图10.5所示的输出开始。这是我们之前章节中用来生成各种分类问题数据集的相同表单。首先，我们使用月亮问题生成一个简单的数据集。生成的输出显示了一个应该相对容易用简单网络进行分类的数据集。
- en: Since we are handling more complex problems than XOR now, we want to alter the
    configuration options in the NEAT config file. Listing 10.11 is still only a partial
    view of all the `config` options, and we again highlight the critical ones, starting
    with reducing the maximum `fitness_threshold` to `3.0` out of `4.0`, or 75%. Then,
    we increase or add a middle or in-between node layer. With NEAT, we don’t think
    of nodes in layers; rather, we only concern ourselves with the number of input/output
    and middle, or in-between, nodes. If those middle nodes happen to align in layers,
    that is a happy accident but not something to be expected. Next, we are presented
    with a couple of options, starting with compatibility. These options are for `speciation`
    and will be covered later. The last thing to note is that we’ve updated the activation
    options by adding two other possible functions (`identity` and `relu`).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在处理的问题比XOR更复杂，我们希望修改NEAT配置文件中的配置选项。列表10.11仍然只是所有`config`选项的部分视图，我们再次强调关键的选项，首先是将最大`fitness_threshold`从`4.0`降低到`3.0`，即75%。然后，我们增加或添加一个中间或中间节点层。在NEAT中，我们不按层来考虑节点；我们只关心输入/输出和中间或中间节点的数量。如果这些中间节点恰好按层排列，那是一个愉快的意外，但不是可以预期的。接下来，我们面临几个选项，首先是兼容性。这些选项是用于`speciation`的，将在稍后介绍。最后要注意的是，我们已经通过添加另外两个可能的功能（`identity`和`relu`）来更新了激活选项。
- en: 'Listing 10.11 EDL_10_3_NEAT_Circles.ipynb: Checking the configuration options'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.11 EDL_10_3_NEAT_Circles.ipynb：检查配置选项
- en: '[PRE10]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ The fitness_threshold is reduced to 3.0.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将fitness_threshold降低到3.0。
- en: ❷ Increases the number of hidden middle nodes
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 增加隐藏中间节点的数量
- en: ❸ Used for speciation
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 用于物种形成
- en: ❹ The activation options are expanded.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 激活选项已扩展。
- en: Figure 10.6 shows the output of a starting `genome` network, with the new configuration
    options applied. It is interesting to note that not all nodes are connected to
    the output and node 10 is not connected to inputs or outputs. This allows the
    network to eliminate unneeded nodes, which prevents problems of over- or underfitting.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6显示了应用新配置选项的起始`genome`网络的输出。值得注意的是，并非所有节点都连接到输出，节点10既没有连接到输入也没有连接到输出。这允许网络消除不必要的节点，从而防止过拟合或欠拟合的问题。
- en: '![](../Images/CH10_F06_Lanham.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F06_Lanham.png)'
- en: Figure 10.6 The output of an unevolved random network
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 未进化的随机网络的输出
- en: At this point, jump down to the bottom of the notebook and review the evolution
    code, as shown in the following listing. Most of this code has been covered, but
    notice the addition of the `CustomReporter` = to the `population`, `p`, with the
    `add_reporter` function call. The addition of this custom report allows us to
    fine-tune the evolution output and allows us to add visuals.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，跳到笔记本的底部并查看以下列表中的进化代码。大部分代码已经介绍过，但请注意添加了`CustomReporter`到`population`，`p`，使用`add_reporter`函数调用。添加这个自定义报告允许我们微调进化输出，并允许我们添加可视化。
- en: 'Listing 10.12 EDL_10_3_NEAT_Circles.ipynb: Evolving the network'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.12 EDL_10_3_NEAT_Circles.ipynb：进化网络
- en: '[PRE11]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ Creates the population
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建人口
- en: ❷ Adds CustomReporter for visuals
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 添加CustomReporter进行可视化
- en: ❸ Evaluates a winner
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 评估胜者
- en: ❹ Outputs results
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 输出结果
- en: Scroll up to the `CustomReporter` class definition, shown in listing 10.13\.
    NEAT-Python allows for various customizations, and this implementation is just
    a copy of the standard reporter, with a small addition for visualizing fitting
    progress. Inside this new reporter class, we add custom code to the `post_evaluate`
    function, which is called after the `genomes` are `evaluated`. We don’t want this
    code to render for every iteration, so we add a modulo check that is controlled
    with a new `self.gen_display` parameter set in the `init` function. If the `generation`
    is equal to the display gen, then the code creates a network from the `genome`
    and `evaluates` it in an update `show_ predictions` function.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动到`CustomReporter`类定义，如列表10.13所示。NEAT-Python允许进行各种自定义，而这个实现只是标准报告器的副本，增加了一些用于可视化拟合进度的代码。在这个新的报告器类中，我们在`post_evaluate`函数中添加了自定义代码，该函数在`genomes`被`evaluated`后调用。我们不希望这段代码在每次迭代时都渲染，因此我们添加了一个模检查，该检查由在`init`函数中设置的新的`self.gen_display`参数控制。如果`generation`等于显示的gen，则代码从`genome`创建一个网络，并在更新`show_predictions`函数中对其进行`evaluate`。
- en: 'Listing 10.13 EDL_10_3_NEAT_Circles.ipynb: The `CustomReporter` class definition'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.13 EDL_10_3_NEAT_Circles.ipynb：`CustomReporter`类定义
- en: '[PRE12]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ The class definition extends from BaseReporter.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 类定义继承自BaseReporter。
- en: ❷ The init function, shown for reference
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 初始化函数，仅供参考
- en: ❸ Adds to post_evaluate
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 添加到post_evaluate
- en: ❹ The start of the custom code
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 自定义代码的开始
- en: Recall from chapter 6 how we first used the `show_predictions` function on Keras
    networks. Using this function on NEAT has been updated, which we can see in the
    following listing. The main change from the previous code is using the `net.activate`
    function instead of `model.predict` from Keras.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 回想第6章中我们如何首先在Keras网络上使用`show_predictions`函数。在NEAT上使用此函数已经更新，如下面的列表所示。与前一段代码的主要变化是使用`net.activate`函数而不是Keras中的`model.predict`。
- en: 'Listing 10.14 EDL_10_3_NEAT_Circles.ipynb: The updated `show_predictions` function'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.14 EDL_10_3_NEAT_Circles.ipynb：更新的`show_predictions`函数
- en: '[PRE13]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ❶ Creates a grid of inputs and outputs
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建输入和输出的网格
- en: ❷ Activates the network and output results
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 激活网络并输出结果
- en: ❸ Plots the results with a spectral map
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 使用光谱图绘制结果
- en: ❹ Shows the output
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 显示输出
- en: Figure 10.7 shows the results of evolving a NEAT network over the moons problem
    dataset. Notice how most of the network nodes don’t output to the output node.
    Your results and network may vary, but in the figure, you can see only two nodes
    are relevant and connect to the output.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7显示了在月亮问题数据集上进化NEAT网络的结果。注意，网络中的大多数节点都没有输出到输出节点。你的结果和网络可能会有所不同，但在图中，你可以看到只有两个节点是相关的，并且连接到输出节点。
- en: '![](../Images/CH10_F07_Lanham.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F07_Lanham.png)'
- en: Figure 10.7 The output of evolving a NEAT network on the moons problem
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 进化NEAT网络在月亮问题上的输出
- en: If you recall, in chapter 6, our most difficult problem was the circles problem.
    Go ahead and switch the problem to circles and then run the notebook again. From
    experience, we know this problem is solvable using a standard Keras network. However,
    given our current configuration options, it is unlikely a solution will be found.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得，在第 6 章中，我们最困难的问题是圆的问题。请将问题切换到圆，然后再次运行笔记本。根据经验，我们知道这个问题可以使用标准的 Keras 网络解决。然而，鉴于我们当前的配置选项，找到解决方案的可能性不大。
- en: 10.3.1 Learning exercises
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3.1 学习练习
- en: 'Use the following exercises to explore the capabilities of NEAT:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习来探索 NEAT 的能力：
- en: Alter the number of data samples in figure 10.5\. Observe what effect this has
    on NEAT approximation.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改图 10.5 中的数据样本数量。观察这对 NEAT 近似的影响。
- en: Change the problem type in figure 10.5 and then rerun the notebook. Does NEAT
    handle certain problems better than others?
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改图 10.5 中的问题类型，然后重新运行笔记本。NEAT 是否比其他问题处理得更好？
- en: Increase or decrease the number of hidden nodes (`num_hidden`) in listing 10.11\.
    Then, try solving various problem types. What effect does the number of hidden
    nodes have on building solutions?
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在列表 10.11 中增加或减少隐藏节点 (`num_hidden`) 的数量。然后尝试解决各种问题类型。隐藏节点的数量对构建解决方案有什么影响？
- en: Before we get into properly solving the circles problem, we dive into a more
    practical example using NEAT in the next section.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们正确解决圆的问题之前，我们将在下一节中深入探讨使用 NEAT 的一个更实际的例子。
- en: 10.4 Exercising NEAT to classify images
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.4 练习 NEAT 进行图像分类
- en: 'To really understand the limitations and capabilities of NEAT, we offer a practical
    comparison in this section. A well-established one comes to mind: image classification
    with the MNIST Handwritten Digits dataset. For our next exercise, we use NEAT
    to classify the MNIST dataset.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了真正理解 NEAT 的局限性和能力，我们在本节提供了一个实际的比较。一个著名的例子是：使用 MNIST 手写数字数据集进行图像分类。对于我们的下一个练习，我们使用
    NEAT 来分类 MNIST 数据集。
- en: Open the EDL_10_4_NEAT_Images.ipynb notebook in Google Colab. Refer to the appendix
    if you need assistance. Run all the cells in the notebook by selecting Runtime
    > Run All from the menu.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Google Colab 中打开 EDL_10_4_NEAT_Images.ipynb 笔记本。如需帮助，请参考附录。通过菜单选择运行 > 运行所有来运行笔记本中的所有单元格。
- en: This notebook loads the MNIST dataset, as shown in figure 10.8\. We only use
    the training data portion of the dataset to `evaluate` the `genome` `fitness`
    over a batch sample. After the data is loaded, it is normalized, and then a sample
    digit is displayed. Note that we are using all 10 classes from the full dataset.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这个笔记本加载了 MNIST 数据集，如图 10.8 所示。我们只使用数据集的训练数据部分来 `evaluate` 批量样本上的 `genome` `fitness`。数据加载后，它被归一化，然后显示一个样本数字。请注意，我们正在使用完整数据集的所有
    10 个类别。
- en: '![](../Images/CH10_F08_Lanham.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F08_Lanham.png)'
- en: Figure 10.8 Loading the MNIST training dataset
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 加载 MNIST 训练数据集
- en: Next, we look at the various changes to the NEAT configuration options, shown
    in listing 10.15\. The first change is the `fitness` threshold is now set to `.25`,
    or 25%. We will be updating the `fitness` function to score the evolving networks
    on accuracy rather than errors. Then, notice how the inputs have been increased
    to `784` to match the input images’ 28×28 pixels, which are no different from
    a Keras model. In this exercise, we set the number of hidden nodes to `10` for
    demonstration. After that, we change the `initial_connection` option to `full_direct`.
    This essentially means we are starting with a fully connected network, not unlike
    a Keras sequential model. Near the bottom of the shown configuration options,
    we can see options set for the `activation` function, `identity`, and `relu`.
    Finally, we see a new aggregation option being employed. Aggregation is the operation
    that occurs inside the node or perceptron, and by default, we always assume it
    to be summation. With NEAT, we can alter the aggregation function a node uses,
    as we do here.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们查看 NEAT 配置选项的各种更改，如列表 10.15 所示。第一个更改是将 `fitness` 阈值设置为 `.25`，即 25%。我们将更新
    `fitness` 函数，以评分演化的网络在准确性而不是错误上的表现。然后，注意输入已增加到 `784`，以匹配输入图像的 28×28 像素，这与 Keras
    模型没有区别。在这个练习中，我们为了演示将隐藏节点的数量设置为 `10`。之后，我们将 `initial_connection` 选项更改为 `full_direct`。这实际上意味着我们从一个完全连接的网络开始，这与
    Keras 顺序模型没有太大区别。在显示的配置选项底部附近，我们可以看到为 `activation` 函数、`identity` 和 `relu` 设置的选项。最后，我们看到一个新的聚合选项正在被采用。聚合是在节点或感知器内部发生的操作，默认情况下，我们总是假设它是求和。在
    NEAT 中，我们可以更改节点使用的聚合函数，就像我们在这里做的那样。
- en: 'Listing 10.15 EDL_10_4_NEAT_Images.ipynb: Updated configuration options'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.15 EDL_10_4_NEAT_Images.ipynb：更新配置选项
- en: '[PRE14]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ❶ Fitness is now accuracy.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ `Fitness`现在是准确率。
- en: ❷ Flattened image inputs
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 展平的图像输入
- en: ❸ The maximum number of middle nodes
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 中间节点的最大数量
- en: ❹ Always starts fully connected
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 总是开始完全连接
- en: ❺ The choice of activation functions
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 激活函数的选择
- en: ❻ Alters the node aggregation function
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 修改节点聚合函数
- en: ❼ Always starts fully connected
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 总是开始完全连接
- en: From configuration, we jump down to updating the `evaluation` function, shown
    in listing 10.16\. Recall that we want to use accuracy for scoring `fitness` now,
    since our networks will be classifying images. That means we want to score the
    network on a set of images—typically, the training set. However, scoring the entire
    set of training images is not practical, so instead, we take random batches of
    images to `evaluate` a `genome`. In this notebook, we use a value of `256` to
    speed up performance. This batch size is used to generate a random set of indexes
    that will be used to pull data from the training sets `X` and `Y`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 从配置中，我们跳转到更新`evaluation`函数，如列表10.16所示。回想一下，我们现在想使用准确率来评分`fitness`，因为我们的网络将用于图像分类。这意味着我们想在图像集——通常是训练集——上评分网络。然而，评分整个训练图像集是不切实际的，所以我们取随机批次的图像来`evaluate`一个`genome`。在这个笔记本中，我们使用`256`的值来加速性能。这个批次大小用于生成一个随机索引集，该索引集将用于从训练集`X`和`Y`中提取数据。
- en: 'Listing 10.16 EDL_10_4_NEAT_Images.ipynb: Random batching images'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.16 EDL_10_4_NEAT_Images.ipynb：随机批处理图像
- en: '[PRE15]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ Sets the constant
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 设置常数
- en: ❷ Samples random indexes
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 抽取随机索引
- en: ❸ Extracts the batch from the original data
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 从原始数据中提取批次
- en: 'After the evaluation batch of images and labels are extracted, we can `evaluate`
    a `genome` network for accuracy, as shown in listing 10.17\. As the code loops
    through each image and label in the batch, it first flattens the 2D 28×28 image
    into 784 inputs. From there, it activates the network and applies `SoftMax` and
    `np.argmax` functions to get the predicted class. The class predictions are collected
    in a `yis` variable and later used to extract a balanced accuracy score with the
    `balanced_accuracy_score` function. A detailed explanation of balanced accuracy
    can be found on the excellent SciKit Learn documentation page covering the types
    of loss and metrics: [http://mng.bz/Q8G4](http://mng.bz/Q8G4). In summary, balanced
    accuracy balances predictions from unbalanced datasets. Since the batch data we
    are using for evaluation is random, we can’t assume predictions will be balanced.
    Using balanced accuracy allows the evaluation to overcome any bias.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估图像批次和标签提取之后，我们可以根据准确率评估`genome`网络，如列表10.17所示。随着代码遍历批次中的每个图像和标签，它首先将2D 28×28图像展平为784个输入。从那里，它激活网络并应用`SoftMax`和`np.argmax`函数来获取预测类别。类别预测被收集在`yis`变量中，并随后使用`balanced_accuracy_score`函数提取平衡准确率分数。关于平衡准确率的详细解释可以在优秀的SciKit
    Learn文档页面上找到，该页面涵盖了损失和指标类型：[http://mng.bz/Q8G4](http://mng.bz/Q8G4)。总之，平衡准确率平衡了来自不平衡数据集的预测。由于我们用于评估的批次数据是随机的，我们不能假设预测将是平衡的。使用平衡准确率可以使评估克服任何偏差。
- en: 'Listing 10.17 EDL_10_4_NEAT_Images.ipynb: Evaluating a `genome` `fitness`'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.17 EDL_10_4_NEAT_Images.ipynb：评估`genome` `fitness`
- en: '[PRE16]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: ❶ Loops through batch data
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 遍历批次数据
- en: ❷ Flattens the image
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 展平图像
- en: ❸ Activates and scores the output by class
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 激活并按类别评分输出
- en: ❹ Evaluates the genome balanced accuracy
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 评估基因平衡准确率
- en: Scrolling down to the next cell, shown in the following listing, we can see
    the finished evaluation function the NEAT evolution will use. The code is the
    same as what we just reviewed, but it showcases it in the `genome` set evaluation
    function.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动到下一个单元，如下面的列表所示，我们可以看到NEAT进化将使用的完成评估函数。代码与我们刚才审查的相同，但它展示了它在`genome`集评估函数中的应用。
- en: 'Listing 10.18 EDL_10_4_NEAT_Images.ipynb: The `evaluate` `fitness` function'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 列表10.18 EDL_10_4_NEAT_Images.ipynb：`evaluate` `fitness`函数
- en: '[PRE17]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ❶ Extracts a random batch of data
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 提取随机批次数据
- en: ❷ Flattens the image
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 展平图像
- en: ❸ Gets the predicted class
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 获取预测类别
- en: ❹ Evaluates all predictions
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 评估所有预测
- en: The code to run the evolution is the same as the code previously shown. Running
    this code to achieve just 25% accuracy will take some time, even with a few of
    the performance tweaks we added (e.g., setting the batch size). This is an unfortunate
    consequence of the current NEAT-Python implementation. DEAP, the framework we
    wrapped around Keras/PyTorch in previous examples, provides options for distributed
    computation. NEAT, being a much older framework, does not have this option.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 运行进化的代码与之前显示的代码相同。即使添加了一些性能调整（例如，设置批量大小），运行此代码以达到25%的准确率也需要一些时间。这是当前NEAT-Python实现的一个不幸后果。DEAP，我们在之前的例子中将其包装在Keras/PyTorch周围，提供了分布式计算选项。NEAT作为一个更老的框架，没有这个选项。
- en: Figure 10.9 demonstrates the predictive accuracy of a network trained to 25%
    accuracy. This figure was generated from the `plot_classify` function shown in
    previous notebooks. As you can see, the results are OK, given the evaluation is
    on the training set. Your results may be less accurate and will depend greatly
    on the batch size you set. Larger batch sizes increase accuracy but also extend
    evolution time to several minutes, or even hours.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9展示了训练到25%准确率的网络的预测准确性。此图是从之前笔记本中显示的`plot_classify`函数生成的。如您所见，考虑到评估是在训练集上进行的，结果是可以接受的。您的结果可能不太准确，并且将很大程度上取决于您设置的批量大小。较大的批量大小可以提高准确性，但也会将进化时间延长到几分钟甚至几小时。
- en: '![](../Images/CH10_F09_Lanham.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F09_Lanham.png)'
- en: Figure 10.9 The winning network prediction results
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 获胜网络预测结果
- en: Finally, the last block of code in this notebook draws the winning `genomes`
    network using the `draw_net` function we have used previously. Unfortunately,
    the output of this network is unreadable, due to the plethora of connections.
    In most cases, evolved networks with the chosen configuration options have 10,000
    or more connections—yes, you read that right.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个笔记本中的最后一块代码使用我们之前使用的`draw_net`函数绘制了获胜的`genomes`网络。遗憾的是，由于连接过多，这个网络的输出无法阅读。在大多数情况下，具有所选配置选项的进化网络有10,000个或更多的连接——是的，您读对了。
- en: So given the poor performance of this image classification notebook, what are
    the benefits of using a framework like NEAT? Well, much like several of the evolutionary
    examples of the previous chapters, NEAT works best on closed-form, smaller dataset
    optimization problems. As discussed later, that doesn’t mean evolving topologies
    isn’t a viable application of EDL but one that requires more fine-tuning.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，鉴于这个图像分类笔记本表现不佳，使用NEAT这样的框架有什么好处呢？嗯，与之前章节中的一些进化示例一样，NEAT在封闭形式、较小的数据集优化问题上表现最佳。正如稍后讨论的那样，这并不意味着进化拓扑不是EDL的一个可行应用，但这是一个需要更多微调的应用。
- en: 10.4.1 Learning exercises
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.4.1 学习练习
- en: 'Use the following exercises to test the limits of NEAT further:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习来进一步测试NEAT的极限：
- en: Swap the target dataset from MNIST Handwritten Digits to Fashion-MNIST. Does
    the model perform any better?
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将目标数据集从MNIST手写数字更改为Fashion-MNIST。模型的表现是否有所改善？
- en: Increase or decrease the number of hidden nodes (`num_hidden`) in listing 10.15
    and then rerun the notebook.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在列表10.15中增加或减少隐藏节点（`num_hidden`）的数量，然后重新运行笔记本。
- en: Play with the hyperparameters in listing 10.15 to attempt to improve the results.
    How well can you get the evolved network to classify digits or fashion?
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在列表10.15中调整超参数，尝试提高结果。您能将进化网络分类数字或时尚的程度如何？
- en: We explore another evolving topology framework in the final chapter of the book.
    For now, though, we look at an interesting feature of NEAT that improves evolution,
    called `speciation`, in the next section.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本书的最后一章探索另一个进化拓扑框架。然而，现在我们将在下一节中查看NEAT的一个有趣特性，该特性可以改善进化，称为`speciation`。
- en: 10.5 Uncovering the role of speciation in evolving topologies
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.5 揭示拓扑进化中物种的作用
- en: In the next notebook, we look at how NEAT employs a feature called `speciation`
    to track `population` diversity. *Speciation*, originating in biology, is a way
    of describing how similar organisms evolve unique traits to become different species.
    The concept of *species*, first developed by Darwin, is a way of describing or
    breaking down how life evolved on Earth.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个笔记本中，我们将探讨NEAT如何使用一个名为`speciation`的功能来跟踪`population`多样性。*Speciation*起源于生物学，是一种描述相似生物如何进化出独特特征以成为不同物种的方式。*物种*的概念，首先由达尔文提出，是一种描述或分解地球生命进化方式的方法。
- en: '![](../Images/CH10_F10_Lanham.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH10_F10_Lanham.png)'
- en: Figure 10.10 The taxonomy of a dog breed
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 狗品种的分类学
- en: Figure 10.10 shows how a biologist would identify the species and subspecies
    of a dog in a taxonomy chart. *Taxonomy* is a tool biologists use to show or classify
    the evolution of life on Earth. At the top of the figure, a dog subspecies is
    identified, showing how a biologist would define the common household dog.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10 展示了生物学家如何在分类学图表中识别狗的物种和亚种。*分类学* 是生物学家用来展示或分类地球上生命进化的工具。在图的最上方，一个狗亚种被识别出来，展示了生物学家如何定义常见的家犬。
- en: NEAT uses the same concept of grouping `genomes` into species for optimization
    and diversification. Grouping `genomes` into species highlights how a diverse
    `population` of networks may evolve. If you recall from previous chapters, we
    often want to keep a `population` diverse to avoid falling into the trap of some
    local maxima or minima.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: NEAT 使用将 `基因组` 分组到物种的概念来进行优化和多样化。将 `基因组` 分组到物种突出了如何使一个多样化的 `种群` 网络进化。如果你回忆起前面的章节，我们通常希望保持
    `种群` 的多样化，以避免陷入某些局部极大值或极小值的陷阱。
- en: Not encouraging diversity often causes an evolving `population` to become too
    specialized or fixed to some local minima/maxima. In the real world, organisms
    that become overly specialized and unable to adapt go extinct, due to constant
    changes.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 不鼓励多样性往往会导致一个进化的 `种群` 过度专业化或固定在某个局部极小值/极大值。在现实世界中，过度专业化且无法适应的有机体会因为不断的变化而灭绝。
- en: Extinction bias
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 演化偏差
- en: In our world, we often view species extinction purely as a bad event. This is
    certainly because we, as humans, are now able to identify the role of our own
    actions in the ongoing extinction of thousands of species worldwide. Without human
    intervention, though, extinction is a natural process that life has undergone
    for billions of years on Earth. Within evolutionary computation, extinction can
    also be a good thing, as it encourages diversity and better individual performance.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的世界中，我们通常将物种灭绝纯粹视为一个坏事件。这当然是因为我们，作为人类，现在能够识别我们自己的行动在全世界数千种物种持续灭绝中的作用。然而，如果没有人类的干预，灭绝是一个生命在地球上经过数十亿年的自然过程。在进化计算中，灭绝也可以是一件好事，因为它鼓励多样性和更好的个体表现。
- en: NEAT also uses the concept of extinction to force species to constantly evolve
    or become extinct. Doing so promotes species from becoming stagnant or overly
    specialized and encourages `population` diversity. In the next section, we look
    at how using `speciation` can help NEAT solve complex problems.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: NEAT 还使用灭绝的概念来迫使物种不断进化或灭绝。这样做可以防止物种停滞或过度专业化，并鼓励 `种群` 多样化。在下一节中，我们将探讨使用 `物种形成`
    如何帮助 NEAT 解决复杂问题。
- en: 10.5.1 Tuning NEAT speciation
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.1 调整 NEAT 物种形成
- en: The next notebook revisits the circles set of problems we looked at in the previous
    notebook. This time, we look at making a few minor improvements to the notebook
    and how the NEAT `speciation` feature can help. We also explore some more of the
    NEAT configuration options, of which there are several.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 下一笔记本回顾了我们在前一个笔记本中查看的圆圈问题集。这次，我们看看对笔记本进行一些小的改进，以及 NEAT 的 `物种形成` 功能如何有所帮助。我们还探索了更多
    NEAT 配置选项，其中有很多。
- en: Open the EDL_10_5_NEAT_Speciation.ipynb notebook in Google Colab. Refer to the
    appendix if you need assistance. Run all the cells in the notebook by selecting
    Runtime > Run All from the menu.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Google Colab 中打开 EDL_10_5_NEAT_Speciation.ipynb 笔记本。如有需要，请参考附录。通过选择菜单中的“运行”>“运行所有”来运行笔记本中的所有单元格。
- en: NEAT-Python is heavily driven by configuration options that can control every
    aspect of the `genome`’s evolution, including the node connections, nodes, activation/
    aggregation functions, and weights. All those options give a lot of power to NEAT,
    but they also make it more difficult to evolve networks over complex problems.
    To solve the circles problem, we need to better understand how those configuration
    options play with each other.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: NEAT-Python 主要由配置选项驱动，这些选项可以控制 `基因组` 进化的各个方面，包括节点连接、节点、激活/聚合函数和权重。所有这些选项都赋予了
    NEAT 很大的能力，但它们也使得在复杂问题上进化网络变得更加困难。为了解决圆圈问题，我们需要更好地理解这些配置选项是如何相互作用的。
- en: Scroll down to the NEAT configuration options section, shown in listing 10.19\.
    For this notebook, we have updated the `fitness` function to produce a maximum
    `fitness` of `1.0`. Because of that, we have also updated the `fitness_threshold`.
    The number of middle nodes has also been increased to `25` to allow the network
    topology room to grow. From experience, we know the circles problem is solvable,
    given a simple few-layer architecture. To reduce the number of topological changes
    within a network, we have greatly reduced the connection and node’s chances of
    addition or deletion.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动到 NEAT 配置选项部分，如列表 10.19 所示。对于这个笔记本，我们已更新 `fitness` 函数以产生最大 `fitness` 为 `1.0`。因此，我们也更新了
    `fitness_threshold`。中间节点的数量也增加到 `25`，以允许网络拓扑有更多的增长空间。根据经验，我们知道在简单的几层架构下，圆的问题是可以解决的。为了减少网络内部拓扑变化的数量，我们大大减少了连接和节点的添加或删除的可能性。
- en: 'Listing 10.19 EDL_10_5_NEAT_Speciation.ipynb: NEAT configuration options'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.19 EDL_10_5_NEAT_Speciation.ipynb：NEAT 配置选项
- en: '[PRE18]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: ❶ The revised fitness function replaces the threshold.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 修订后的 `fitness` 函数替换了阈值。
- en: ❷ Increases the middle layer
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 增加中间层
- en: ❸ Reduces the rate of connection changes
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 降低连接变化率
- en: ❹ Reduces the rate of node changes
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 降低节点变化率
- en: Since we know the circles problem can be solved with just weight alteration,
    we focus on minimizing weight changes here. The idea here is to allow a `genome`
    to gradually adapt and slowly adjust weights. This is similar to the way we would
    reduce the learning rate when training a DL network. At the bottom of the file,
    we also updated two options to better control `speciation`, as shown in listing
    10.20\. The first option, `compatibility_threshold`, controls the distance between
    species—we will see what that means in a minute. The second is `max_stagnation`,
    which controls the number of `generations` to wait before checking for species
    extinction.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们知道圆的问题可以通过仅改变权重来解决，所以我们专注于最小化权重变化。这里的想法是允许 `genome` 逐渐适应并缓慢调整权重。这与我们在训练深度学习网络时降低学习率的方式类似。在文件底部，我们还更新了两个选项以更好地控制
    `speciation`，如列表 10.20 所示。第一个选项是 `compatibility_threshold`，它控制物种之间的距离——我们将在下一分钟看到这意味着什么。第二个是
    `max_stagnation`，它控制等待检查物种灭绝之前的 `generations` 数量。
- en: 'Listing 10.20 EDL_10_5_NEAT_Speciation.ipynb: More NEAT configuration options'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.20 EDL_10_5_NEAT_Speciation.ipynb：更多 NEAT 配置选项
- en: '[PRE19]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ❶ Reduces the chance of weight mutation
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 降低权重突变的可能性
- en: ❷ Reduces the chance of weight replacement
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 降低权重替换的可能性
- en: ❸ Reduces the amount of weight mutation
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 降低权重突变的数量
- en: ❹ Reduces compatibility between species
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 降低物种间的兼容性
- en: ❺ Increases species stagnation generations
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 增加物种停滞代数
- en: Next, we look at how the `fitness` evaluation function has been updated to better
    `evaluate` the binary classification problem. If you recall, we used MSE for `fitness`
    evaluation previously. This time, we modify this slightly to better account for
    incorrect class classification. We could use a function like binary cross-entropy
    to calculate the error here, but instead, we use a simpler method of calculating
    the distance from the expected class. Thus, if the expected class is `0` and the
    network outputs `.9`, then the error is `-.9`. Likewise, if the class is `1` and
    the network outputs `.2`, the error is `.8`. Squaring the errors and appending
    them to the results removes the sign and allows us to use `np.mean` to extract
    the average error later. The total `fitness` is then calculated by subtracting
    the max `fitness`, now `1`, from the average/mean error, as shown in the following
    listing.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们看看 `fitness` 评估函数是如何更新的，以更好地评估二分类问题。如果你还记得，我们之前使用 MSE 进行 `fitness` 评估。这次，我们对此进行了一些修改，以更好地考虑错误的类别分类。我们可以使用类似二元交叉熵的函数来计算这里的错误，但相反，我们使用了一种更简单的方法来计算预期类别与网络输出之间的距离。因此，如果预期类别是
    `0` 且网络输出 `.9`，则误差是 `-.9`。同样，如果类别是 `1` 且网络输出 `.2`，则误差是 `.8`。将误差平方并附加到结果中消除了符号，并允许我们使用
    `np.mean` 在以后提取平均误差。然后，通过从最大 `fitness`（现在为 `1`）中减去平均/均值误差来计算总 `fitness`，如下面的列表所示。
- en: 'Listing 10.21 EDL_10_5_NEAT_Speciation.ipynb: Updating `fitness` evaluation'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 10.21 EDL_10_5_NEAT_Speciation.ipynb：更新 `fitness` 评估
- en: '[PRE20]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ Predicts the class value between 0 and 1
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 预测介于 0 和 1 之间的类别值
- en: ❷ Calculates the error for class 0
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 计算类别 0 的误差
- en: ❸ Calculates the error for class 1
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 计算类别 1 的误差
- en: ❹ Appends the squared error
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 添加平方误差
- en: ❺ Max fitness(1) – average error
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 最大 `fitness`(1) - 平均误差
- en: As the notebook is running, scroll down to the evolution code and view the results.
    Figure 10.11 shows the results of evolving the network over a few `generations`.
    On the left side of the figure, earlier on in evolution, NEAT is only tracking
    three species (groups) of networks. The number of `individuals` in each species
    is controlled by the `compatibility_threshold` option we saw earlier. Compatibility
    is a measure of similarity between networks that may differ by the number of connections,
    connection weights, nodes, and so on. Reducing the compatibility threshold creates
    more species because the difference in compatibility/similarity between networks
    is small. Likewise, increasing this threshold reduces the number of species.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 当笔记本正在运行时，向下滚动到进化代码并查看结果。图10.11显示了网络在几代内的进化结果。在图的左侧，进化初期，NEAT只跟踪三个网络（组）的物种。每个物种中的个体数量由我们之前看到的`compatibility_threshold`选项控制。兼容性是网络之间相似性的度量，可能因连接数、连接权重、节点等因素而不同。降低兼容性阈值会创建更多物种，因为网络之间兼容性/相似性的差异很小。同样，提高这个阈值会减少物种数量。
- en: '![](../Images/CH10_F11_Lanham.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH10_F11_Lanham.png)'
- en: Figure 10.11 The results of training NEAT on circles
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11 在圆上训练NEAT的结果
- en: NEAT tracks the history of each `speciation` over the course of the evolutionary
    process. The `max_stagnation` option controls how many `generations` to wait before
    evaluating the progress of a particular species. After the `stagnation` period
    has elapsed, species are `evaluated` for progress changes or advances. If at this
    point, a species hasn’t changed during the `stagnation` period, it becomes extinct
    and is removed from the `population`. In figure 10.11, on the right side of the
    figure, all species have been marked as extinct. This has happened because the
    species stagnated, with no discernable changes to improving `fitness`. As it happens,
    the results of the current winning `genome` look relatively good, so it is likely
    the `stagnation` period may be too short.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: NEAT跟踪每个“物种形成”在整个进化过程中的历史。`max_stagnation`选项控制等待多少代来评估特定物种的进度。停滞期过后，物种将根据进度变化或进步进行评估。如果在这个时候，一个物种在停滞期内没有变化，它就会灭绝并被从种群中移除。在图10.11的右侧，所有物种都被标记为灭绝。这是由于物种停滞，没有明显的改进`fitness`的变化。实际上，当前获胜的`genome`的结果看起来相对较好，所以停滞期可能太短了。
- en: Now it is your turn to go back and explore the various configuration options
    and see if you can solve the circles problem with greater than `.95` `fitness`.
    Go ahead and make changes to the configuration options file, and after each change,
    select Runtime > Run All from the menu to rerun the entire notebook.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在轮到你了，回到前面去探索各种配置选项，看看你是否能用大于`.95`的`fitness`解决圆的问题。前往并修改配置选项文件，并在每次更改后，从菜单中选择运行
    > 运行全部来重新运行整个笔记本。
- en: 'Go ahead and consult the NEAT-Python configuration options documentation, found
    here: [http://mng.bz/X58E](http://mng.bz/X58E). This document provides further
    insights and detail into the many options available.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 前往并查阅NEAT-Python配置选项文档，可在此处找到：[http://mng.bz/X58E](http://mng.bz/X58E)。此文档提供了关于许多可用选项的更多见解和细节。
- en: '`Speciation` not only provides for increased diversity in `populations`, but
    it also demonstrates how evolving networks can become stagnant or stuck. The key
    to NEAT successfully solving complex problems then becomes balancing configuration
    option tuning. Fortunately, the more you work with NEAT, much like anything, the
    more you will understand how to turn those dials for better results.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: “物种形成”不仅为种群提供了更多的多样性，还展示了进化网络如何变得停滞或陷入困境。NEAT成功解决复杂问题的关键在于平衡配置选项的调整。幸运的是，就像任何事情一样，你越是用NEAT工作，你就越会了解如何调整这些旋钮以获得更好的结果。
- en: 10.5.2 Learning exercises
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.5.2 学习练习
- en: 'Use the following exercises to improve your understanding of NEAT `speciation`:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下练习来提高你对NEAT“物种形成”的理解：
- en: Increase or decrease the `compatibility_threshold` in listing 10.20 and then
    rerun the notebook to see what effect this has on the number of species.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在列表10.20中增加或减少`compatibility_threshold`的值，然后重新运行笔记本以查看这对物种数量有何影响。
- en: Increase or decrease the number of maximum `stagnation` `generations` (`max_
    stagnation`) in listing 10.20 and then rerun the notebook to see the results.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在列表10.20中增加或减少最大“停滞”代数（`max_stagnation`）的数量，然后重新运行笔记本以查看结果。
- en: Increase or decrease the `population` size to see what effect this may have
    on `speciation`. What happens when you use very small `populations`?
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增加或减少`种群`大小，看看这可能会对`物种形成`产生什么影响。当你使用非常小的`种群`时会发生什么？
- en: In the next chapter, we spend more time with NEAT (NEAT-Python) and explore
    more interesting and fun problems to solve.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将花更多的时间研究NEAT（NEAT-Python），并探索更多有趣和有趣的问题来解决。
- en: Summary
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: NeuroEvolution of Augmenting Topologies (NEAT) is an evolutionary framework
    that employs numerous techniques from hyperparameter optimization to evolving
    network architecture. NEAT-Python is an excellent framework that wraps all these
    complexities into a simple configuration-driven solution. NEAT is an evolutionary
    self-adapting architecture for DL networks.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经进化拓扑增强（NEAT）是一个进化框架，它采用了从超参数优化到进化网络架构的多种技术。NEAT-Python是一个优秀的框架，它将这些复杂性封装成一个简单的配置驱动解决方案。NEAT是深度学习网络的一种进化自适应性架构。
- en: NEAT adapts and evolves the node weights and network architecture over `generations`.
    Visualizing and inspecting NEAT networks as they change topology can be informative
    in understanding how the framework functions.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NEAT在`代际`中适应和进化节点权重和网络架构。随着拓扑结构的变化可视化并检查NEAT网络，可以有助于理解框架的工作原理。
- en: NEAT can solve various problems, like discontinuous function approximation and
    other complex classification problems as well as other difficult, closed-form
    problems.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NEAT可以解决各种问题，如不连续函数逼近以及其他复杂的分类问题，以及其他难以解决的封闭形式问题。
- en: NEAT can be used to perform image classification tasks with some limited results.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NEAT可以用于执行图像分类任务，并取得一些有限的结果。
- en: '`Speciation` is an evolutionary term that refers to classes or subsets of `individuals`
    being grouped by similar features. NEAT uses `speciation` to `evaluate` the performance
    of groups of `individuals` (species) that may have become stagnant. Stagnant species
    can then be culled for extinction and removed from the `population` pool. Extinction
    allows new groups of `individuals` to be established within a fixed `population`.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`物种形成`是一个进化术语，指的是根据相似特征将`个体`分类或分组成类或子集。NEAT使用`物种形成`来`评估`可能已经停滞的`个体`（物种）组的性能。停滞的物种随后可以被淘汰，并从`种群`池中移除。灭绝允许在固定的`种群`内建立新的`个体`群体。'
