- en: 5 Basic probability and statistical analysis using SciPy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SciPy进行5个基本概率和统计分析
- en: This section covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本节涵盖
- en: Analyzing binomials using the SciPy library
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SciPy库分析二项式
- en: Defining dataset centrality
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义数据集中心性
- en: Defining dataset dispersion
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义数据集分散度
- en: Computing the centrality and dispersion of probability distributions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算概率分布的中心性和分散度
- en: Statistics is a branch of mathematics dealing with the collection and interpretation
    of numeric data. It is the precursor of all modern data science. The term *statistic*
    originally signified “the science of the state” because statistical methods were
    first developed to analyze the data of state governments. Since ancient times,
    government agencies have gathered data pertaining to their populace. That data
    would be used to levy taxes and organize large military campaigns. Hence, critical
    state decisions depended on the quality of data. Poor record keeping could lead
    to potentially disastrous results. That is why state bureaucrats were very concerned
    by any random fluctuations in their records. Probability theory eventually tamed
    these fluctuations, making the randomness interpretable. Ever since then, statistics
    and probability theory have been closely intertwined.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学是数学的一个分支，涉及数字数据的收集和解释。它是所有现代数据科学的先驱。术语“统计”最初表示“国家科学”，因为统计方法最初是为了分析政府数据而开发的。自古以来，政府机构就收集有关其民众的数据。这些数据将被用来征税和组织大规模军事行动。因此，关键的国家决策取决于数据的质量。记录不良可能导致灾难性的后果。这就是为什么国家官僚对他们的记录中的任何随机波动都非常关心。概率论最终驯服了这些波动，使随机性变得可解释。从那时起，统计学和概率论就紧密相连。
- en: Statistics and probability theory are closely related, but in some ways, they
    are very different. Probability theory studies random processes over a potentially
    infinite number of measurements. It is not bound by real-world limitations. This
    allows us to model the behavior of a coin by imagining millions of coin flips.
    In real life, flipping a coin millions of times is a pointlessly time-consuming
    endeavor. Surely we can sacrifice some data instead of flipping coins all day
    and night. Statisticians acknowledge these constraints placed on us by the data-gathering
    process. Real-world data collection is costly and time consuming. Every data point
    carries a price. We cannot survey a country’s population without employing government
    officials. We cannot test our online ads without paying for every ad that’s clicked.
    Thus, the size of our final dataset usually depends on the size of our initial
    budget. If the budget is constrained, then the data will also be constrained.
    This trade-off between data and resourcing lies at the heart of modern statistics.
    Statistics help us understand exactly how much data is sufficient to draw insights
    and make impactful decisions. The purpose of statistics is to find meaning in
    data even when that data is limited in size.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学和概率论密切相关，但在某些方面，它们非常不同。概率论研究在可能无限多个测量上的随机过程。它不受现实世界限制的约束。这使我们能够通过想象数百万次抛硬币来模拟硬币的行为。在现实生活中，抛硬币数百万次是一项毫无意义的耗时工作。我们当然可以牺牲一些数据，而不是整天整夜地抛硬币。统计学家承认数据收集过程对我们施加的这些限制。现实世界的数据收集既昂贵又耗时。每个数据点都有一份代价。我们无法调查一个国家的人口而不雇佣政府官员。我们无法测试我们的在线广告而不为点击的每个广告付费。因此，我们最终数据集的大小通常取决于我们初始预算的大小。如果预算有限，那么数据也会有限。这种数据与资源之间的权衡是现代统计学的核心。统计学帮助我们了解确切需要多少数据才能得出见解并做出有影响力的决策。统计学的目的是在数据有限的情况下找到数据的意义。
- en: Statistics is highly mathematical and usually taught using math equations. Nevertheless,
    direct exposure to equations is not a prerequisite for statistical understanding.
    In fact, many data scientists do not write formulas when running statistical analyses.
    Instead, they use Python libraries such as SciPy, which handle all the complex
    math calculations. However, proper library usage still requires an intuitive understanding
    of statistical procedures. In this section, we cultivate our understanding of
    statistics by applying probability theory to real-world problems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 统计学高度数学化，通常使用数学方程式进行教学。然而，直接接触方程式并不是理解统计学的先决条件。实际上，许多数据科学家在进行统计分析时并不编写公式。相反，他们使用Python库，如SciPy，这些库处理所有复杂的数学计算。然而，正确使用库仍然需要直观理解统计程序。在本节中，我们通过将概率理论应用于现实世界问题来培养我们对统计学的理解。
- en: 5.1 Exploring the relationships between data and probability using SciPy
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 使用 SciPy 探索数据与概率之间的关系
- en: 'SciPy, which is short for *Scientific Python*, provides many useful methods
    for scientific analysis. The SciPy library includes an entire module for addressing
    problems in probability and statistics: `scipy.stats`. Let’s install the library
    and import the `stats` module.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: SciPy，即 *Scientific Python*，提供了许多用于科学分析的实用方法。SciPy 库包括一个用于解决概率和统计问题的完整模块：`scipy.stats`。让我们安装这个库并导入
    `stats` 模块。
- en: Note Call `pip install scipy` from the command line terminal to install the
    SciPy library.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 从命令行终端调用 `pip install scipy` 来安装 SciPy 库。
- en: Listing 5.1 Importing the `stats` module from SciPy
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.1 从 SciPy 导入 `stats` 模块
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `stats` module is very useful for assessing the randomness of data. For
    example, in section 1, we computed the probability of a fair coin producing at
    least 16 heads after 20 flips. Our calculations required us to examine all possible
    combinations of 20 flipped coins. Then we computed the probability of observing
    16 or more heads or 16 or more tails to measure the randomness of our observations.
    SciPy allows us to measure this probability directly using the `stats.binom_test`
    method. The method is named after the binomial distribution, which governs how
    a flipped coin might fall. The method requires three parameters: the number of
    heads, the total number of coin flips, and the probability of a coin landing on
    heads. Let’s apply the binomial test to 16 heads observed from 20 coin flips.
    Our output should equal the previously computed value of approximately 0.011.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '`stats` 模块对于评估数据的随机性非常有用。例如，在第 1 节中，我们计算了公平硬币在 20 次抛掷后至少出现 16 次正面的概率。我们的计算需要我们检查所有可能的
    20 次抛掷硬币的组合。然后我们计算观察到 16 次或更多正面或 16 次或更多反面的概率，以衡量我们观察的随机性。SciPy 允许我们直接使用 `stats.binom_test`
    方法来测量这个概率。该方法以二项分布命名，它决定了抛掷硬币可能的结果。该方法需要三个参数：正面的数量、总的抛掷次数以及硬币落在正面的概率。让我们对 20 次抛掷中观察到的
    16 次正面应用二项测试。我们的输出应该等于之前计算的大约 0.011 的值。'
- en: Note SciPy and standard Python handle low-value decimal points differently.
    In section 1, when we computed the probability, the final value was rounded to
    17 significant digits. SciPy, on the other hand, returns a value containing 18
    significant digits. Thus, for consistency’s sake, we round our SciPy output to
    17 digits.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 SciPy 和标准 Python 处理低值小数点的方式不同。在第 1 节中，当我们计算概率时，最终值被四舍五入到 17 位有效数字。另一方面，SciPy
    返回一个包含 18 位有效数字的值。因此，为了保持一致性，我们将 SciPy 的输出四舍五入到 17 位数字。
- en: Listing 5.2 Analyzing extreme head counts using SciPy
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.2 使用 SciPy 分析极端正面次数
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It’s worth emphasizing that `stats.binom_test` did not compute the probability
    of observing 16 heads. Rather, it returned the probability of seeing a coin-flip
    sequence where 16 or more coins fell on the same face. If we want the probability
    of seeing exactly 16 heads, then we must utilize the `stats.binom.pmf` method.
    That method represents the *probability mass function* of the binomial distribution.
    A probability mass function maps inputted integer values to their probability
    of occurrence. Thus, calling `stats.binom.pmf(num_heads, num_flips, prob_heads)`
    returns the likelihood of a coin yielding `num_heads` number of heads. Under current
    settings, this equals the probability of a fair coin falling on heads 16 out of
    20 times.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 值得强调的是，`stats.binom_test` 并没有计算观察到 16 次正面的概率。相反，它返回了看到硬币抛掷序列中 16 次或更多硬币落在同一面的概率。如果我们想看到正好
    16 次正面的概率，那么我们必须使用 `stats.binom.pmf` 方法。该方法表示二项分布的 *概率质量函数*。概率质量函数将输入的整数值映射到它们发生的概率。因此，调用
    `stats.binom.pmf(num_heads, num_flips, prob_heads)` 返回硬币产生 `num_heads` 次正面的可能性。在当前设置下，这等于公平硬币在
    20 次抛掷中有 16 次落在正面的概率。
- en: Listing 5.3 Computing an exact probability using `stats.binom.pmf`
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.3 使用 `stats.binom.pmf` 计算精确概率
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We’ve used `stats.binom.pmf` to find the probability of seeing exactly 16 heads.
    However, that method is also able to compute multiple probabilities simultaneously.
    Multiple head-count probabilities can be processed by passing in a list of head-count
    values. For instance, passing `[4, 16]` returns a two-element NumPy array containing
    the probabilities of seeing 4 heads and 16 heads, respectively. Conceptually,
    the probability of seeing 4 heads and 16 tails equals the probability of seeing
    4 tails and 16 heads. Thus, executing `stats.binom.pmf([4, 16], num_flips, prob_head)`
    should return a two-element array whose elements are equal. Let’s confirm.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`stats.binom.pmf`来找到恰好出现16个头的概率。然而，该方法也能够同时计算多个概率。可以通过传递头数值的列表来处理多个头数概率。例如，传递`[4,
    16]`将返回一个包含4个头和16个头出现概率的二维NumPy数组。从概念上讲，4个头和16个尾的概率等于4个尾和16个头的概率。因此，执行`stats.binom.pmf([4,
    16], num_flips, prob_head)`应该返回一个包含相等元素的二维数组。让我们来验证。
- en: Listing 5.4 Computing an array of probabilities using `stats.binom.pmf`
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.4：使用`stats.binom.pmf`计算概率数组
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: List-passing allows us to compute probabilities across intervals. For example,
    if we pass `range(21)` into `stats.binom.pmf`, then the outputted array will contain
    all probabilities across the interval of every possible head count. As we learned
    in section 1, the sum of these probabilities should equal 1.0.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列表传递使我们能够计算区间概率。例如，如果我们把`range(21)`传递给`stats.binom.pmf`，那么输出的数组将包含每个可能头数区间的所有概率。正如我们在第1节中学到的，这些概率的总和应该等于1.0。
- en: Note Summing low-value decimals is computationally tricky. Over the course of
    the summation, tiny errors accumulate. Due to these errors, our final summed probability
    will marginally diverge from 1.0 unless we round it to 14 significant digits.
    We do this rounding in the next listing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：对低值小数求和在计算上很棘手。在求和过程中，微小的误差会累积。由于这些误差，我们最终的求和概率将略微偏离1.0，除非我们将它四舍五入到14位有效数字。我们将在下一个列表中进行这种四舍五入。
- en: Listing 5.5 Computing an interval probability using `stats.binom.pmf`
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.5：使用`stats.binom.pmf`计算区间概率
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Also, as discussed in section 2, plotting `interval_all_counts` versus `probabilities`
    reveals the shape of our 20-coin-flip distribution. Thus, we can generate the
    distribution plot without having to iterate through possible coin-flip combinations
    (figure 5.1).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如第2节所述，将`interval_all_counts`与`probabilities`绘制成图，可以揭示我们20次抛硬币分布的形状。因此，我们可以在不遍历所有可能的抛硬币组合的情况下生成分布图（图5.1）。
- en: '![](../Images/05-01.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-01.png)'
- en: Figure 5.1 The probability distribution for 20 coin flips, generated using SciPy
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1：使用SciPy生成的20次抛硬币的概率分布
- en: Listing 5.6 Plotting a 20-coin-flip binomial distribution
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.6：绘制20次抛硬币的二项分布
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In section 2, our ability to visualize the binomial was limited by the total
    number of coin-flip combinations that we needed to compute. This is no longer
    the case. The `stats.binom.pmf` method lets us display any distribution associated
    with an arbitrary coin-flip count. Let’s use our newfound freedom to simultaneously
    plot the distributions for 20, 80, 140, and 200 coin flips (figure 5.2).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在第2节中，我们可视化二项分布的能力受到我们需要计算的总抛硬币组合数的限制。这种情况不再存在。`stats.binom.pmf`方法使我们能够显示与任意抛硬币次数相关的任何分布。让我们利用我们新获得的自由，同时绘制20次、80次、140次和200次抛硬币的分布图（图5.2）。
- en: Listing 5.7 Plotting five different binomial distributions
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.7：绘制五个不同的二项分布
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![](../Images/05-02.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-02.png)'
- en: Figure 5.2 Multiple binomial probability distributions across 20, 80, 140, and
    200 coin flips. The distribution centers shift right as the coin-flip count goes
    up. Also, every distribution becomes more dispersed around its center as the coin-flip
    count increases.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2展示了20次、80次、140次和200次抛硬币的多个二项概率分布。随着抛硬币次数的增加，分布中心向右移动。此外，随着抛硬币次数的增加，每个分布在其中心周围变得更加分散。
- en: Within the plot, the central peak of each binomial appears to shift rightward
    as the coin-flip count goes up. Also, the 20-coin-flip distribution is noticeably
    thinner than the 200-coin-flip distribution. In other words, the plotted distributions
    grow more dispersed around their central positions as these central positions
    move to the right.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，每个二项分布的中央峰值似乎随着抛硬币次数的增加而向右移动。此外，20次抛硬币的分布明显比200次抛硬币的分布薄。换句话说，随着这些中心位置向右移动，绘制的分布在其中心位置周围变得更加分散。
- en: Such shifts in centrality and dispersion are commonly encountered in data analysis.
    We previously observed dispersion shifts in section 3, where we used randomly
    sampled data to visualize several histogram distributions. Subsequently, we observed
    that the plotted histogram thickness was dependent on our sample size. At the
    time, our observations were purely qualitative since we lacked a metric for comparing
    the thickness of two plots. However, simply noting that one plot appears thicker
    than another is insufficient. Likewise, stating that one plot is more rightward
    than another is also insufficient. We need to quantify our distribution differences.
    We must assign specific numbers to centrality and dispersion to discern how these
    numbers change from plot to plot. Doing so requires that we familiarize ourselves
    with the concepts of *variance* and *mean*.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据分析中，这种中心趋势和离散度的变化是常见的。我们在第3节中观察到了离散度的变化，当时我们使用随机样本数据来可视化几个直方图分布。随后，我们观察到绘制的直方图厚度取决于我们的样本大小。当时，我们的观察完全是定性的，因为我们缺乏比较两个图表厚度的指标。然而，仅仅指出一个图表看起来比另一个厚是不够的。同样，说一个图表比另一个更向右也是不够的。我们需要量化我们的分布差异。我们必须给中心趋势和离散度分配具体的数字，以辨别这些数字是如何从图表到图表变化的。这样做需要我们熟悉*方差*和*均值*的概念。
- en: 5.2 Mean as a measure of centrality
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 均值作为中心趋势的度量
- en: Suppose we wish to study our local temperature over the first week of summer.
    When summer comes around, we glance at the thermometer outside our window. At
    noon, the temperature is exactly 80 degrees. We repeat our noon measurements over
    the next six days. Our measurements are 80, 77, 73, 61, 74, 79, and 81 degrees.
    Let’s store these measurements in a NumPy array.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们希望研究夏季第一周我们当地的温度。当夏天来临时，我们瞥了一眼窗户外的温度计。中午，温度正好是80度。我们在接下来的六天里重复进行中午的测量。我们的测量值是80，77，73，61，74，79和81度。让我们将这些测量值存储在一个NumPy数组中。
- en: Listing 5.8 Storing recorded temperatures in a NumPy array
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.8 将记录的温度存储在NumPy数组中
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We’ll now attempt to summarize our measurements using a single central value.
    First, we sort the measurements in place by calling `measurements.sort()`. Then,
    we plot the sorted temperatures in order to evaluate their centrality (figure
    5.3).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将尝试使用一个单一的中心值来总结我们的测量结果。首先，我们通过调用`measurements.sort()`就地排序测量值。然后，我们按顺序绘制排序后的温度，以评估它们的中心趋势（图
    5.3）。
- en: Listing 5.9 Plotting the recorded temperatures
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.9 绘制记录的温度
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Based on the plot, a central temperature exists somewhere between 60 degrees
    and 80 degrees. Therefore, we can naively estimate the center as approximately
    70 degrees. Let’s quantify our estimate as the midpoint between the lowest value
    and the highest value in the plot. We compute that midpoint by taking half the
    difference between the minimum and maximum temperatures and adding it to the minimum
    temperature. (We can also obtain the same value by summing the minimum and maximum
    directly and dividing that sum by 2.)
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图表，中心温度存在于60度和80度之间。因此，我们可以天真地估计中心大约是70度。让我们将我们的估计量化为图表中最低值和最高值之间的中点。我们通过取最小值和最大值之间差的一半并加到最小温度上来计算这个中点。（我们也可以通过直接相加最小值和最大值，然后除以2来获得相同的值。）
- en: '![](../Images/05-03.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-03.png)'
- en: Figure 5.3 A plot containing seven sorted temperatures. A central temperature
    exists somewhere between 60 and 80 degrees.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 包含七个排序后的温度的图表。存在一个介于60度和80度之间的中心温度。
- en: Listing 5.10 Finding the midpoint temperature
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.10 查找中点温度
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The midpoint temperature is 71 degrees. Let’s mark that midpoint on our plot
    using a horizontal line. We draw the horizontal line by calling `plt.axhline(midpoint)`
    (figure 5.4).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 中点温度是71度。让我们在图表上用一条水平线标记这个中点。我们通过调用`plt.axhline(midpoint)`（图 5.4）来绘制这条水平线。
- en: '![](../Images/05-04.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-04.png)'
- en: 'Figure 5.4 A plot containing seven sorted temperatures. A temperature of 71
    degrees marks the midpoint between the highest and lowest temperatures. That midpoint
    seems low: six of seven temperatures are above the midpoint value.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 包含七个排序后的温度的图表。71度的温度标志着最高和最低温度之间的中点。这个中点看起来很低：七个温度中有六个高于中点值。
- en: Listing 5.11 Plotting the midpoint temperature
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.11 绘制中点温度
- en: '[PRE10]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Our plotted midpoint seems a little low: six of our seven measurements are
    higher than the midpoint. Intuitively, our central value should split the measurements
    more evenly—the number of temperatures above and below the center should be approximately
    equal. We can achieve this equality by choosing the middle element in our sorted
    seven-element array. The middle element, which statisticians call the *median*,
    will split our measurements into two equal parts. Three measurements will appear
    below the median, and three measurements will appear above it. 3 is also the index
    in the `measurements` array where the median is present. Let’s add the median
    to our plot (figure 5.5).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们绘制的中间值似乎有点低：我们七个测量值中的六个都高于中间值。直观上，我们的中心值应该更均匀地分割测量值——高于和低于中心的温度数量应该大致相等。我们可以通过选择排序后的七个元素数组中的中间元素来实现这种平等。这个中间元素，统计学家称之为*中位数*，将把我们的测量值分成两部分。三个测量值将出现在中位数以下，三个测量值将出现在中位数以上。3也是中位数在`measurements`数组中的索引。让我们将中位数添加到我们的图中（图5.5）。
- en: '![](../Images/05-05.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-05.png)'
- en: 'Figure 5.5 A plot containing seven sorted temperatures. A median of 77 degrees
    splits the temperatures in half. The median appears slightly off balance: it is
    closer to the three upper temperatures than to the three lower temperatres.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 包含七个排序温度的图。77度的中位数将温度分成两半。中位数看起来稍微不平衡：它比三个较低的温度更接近三个较高的温度。
- en: Listing 5.12 Plotting the median temperature
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.12 绘制中位数温度
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Our median of 77 degrees splits the temperatures in half. However, the split
    is not well balanced since the median is closer to the upper three temperatures
    in the plot. In particular, the median is noticeably far from our minimum measure
    of 61 degrees. Perhaps we can balance the split by penalizing the median for being
    too far from the minimum. We’ll implement this penalty using the *squared distance*,
    which is simply the square of the difference between two values. The squared distance
    grows quadratically as the two values are pushed further apart. Thus, if we penalize
    our central value based on its distance to 61, the squared distance penalty will
    grow noticeably larger as it drifts away from 61 degrees (figure 5.6).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们77度的中位数将温度分成两半。然而，分割并不平衡，因为中位数在图中更接近上三个温度。特别是，中位数与我们的最小测量值61度明显相距甚远。也许我们可以通过惩罚中位数离最小值太远来平衡分割。我们将使用*平方距离*来实现这种惩罚，它只是两个值之间差异的平方。随着两个值被推得更远，平方距离呈二次增长。因此，如果我们根据中心值与61的距离来惩罚它，那么随着它远离61度，平方距离惩罚将显著增大（图5.6）。
- en: '![](../Images/05-06.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-06.png)'
- en: Figure 5.6 A plot of possible centers penalized based on their squared distances
    relative to the minimum temperature of 61 degrees. Not surprisingly, the minimum
    penalty occurs at 61 degrees. Unfortunately, the penalty doesn’t take into account
    the distance to the remaining six recorded temperatures.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 基于与最小温度61度的平方距离惩罚的可能中心的图。不出所料，最小惩罚发生在61度。不幸的是，惩罚没有考虑到与剩余六个记录温度的距离。
- en: Listing 5.13 Penalizing centers using the squared distance from the minimum
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.13 使用与最小温度61度的平方距离来惩罚中心
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Uses the range of values between the minimum and maximum measured temperatures
    as our set of possible centers
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 使用最小和最大测量温度之间的值范围作为我们可能的中心集
- en: Our plot displays the penalty across a range of possible centers based on their
    distance to our minimum. As the centers shift toward 61, the penalty drops, but
    their distance to the remaining six measurements increases. Thus, we ought to
    penalize each potential center based on its squared distance to all seven measurements.
    We’ll do so by defining a sum of squared distances function, which will add up
    the squared distances between some value and the measurement array. That function
    will serve as our new penalty. Plotting the possible centers against their penalties
    will allow us to find the center whose penalty is minimized (figure 5.7).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的图显示了基于它们与我们最小值的距离的可能的中心处的惩罚。当中心向61移动时，惩罚降低，但它们与剩余六个测量值的距离增加。因此，我们应该根据每个潜在中心与所有七个测量值的平方距离来惩罚它。我们将通过定义一个平方距离和函数来实现这一点，该函数将累加某个值与测量数组之间的平方距离。该函数将作为我们新的惩罚。将可能的中心与它们的惩罚绘制在一起将允许我们找到惩罚最小化的中心（图5.7）。
- en: '![](../Images/05-07.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-07.png)'
- en: Figure 5.7 A plot of possible centers penalized based on the sum of their squared
    distances relative to all recorded temperatures. The minimum penalty occurs at
    75 degrees.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 基于所有记录温度的平方距离之和的可能的中心惩罚图。最低惩罚发生在 75 度。
- en: Listing 5.14 Penalizing centers using the total sum of squared distances
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.14 使用总平方距离之和惩罚中心
- en: '[PRE13]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Based on our plot, the temperature of 75 degrees incurs the lowest penalty.
    We’ll informally refer to this temperature value as our “least-penalized center.”
    Let’s demarcate it using a horizontal line on our temperature plot (figure 5.8).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的图表，75 度的温度产生了最低的惩罚。我们将非正式地称这个温度值为我们的“最低惩罚中心”。让我们在温度图（图 5.8）上用一条水平线来标记它。
- en: '![](../Images/05-08.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-08.png)'
- en: Figure 5.8 A plot containing seven sorted temperatures. The least-penalized
    center of 75 degrees splits the temperatures in a balanced manner.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 包含七个排序温度的图表。75 度的最低惩罚中心以平衡的方式分割温度。
- en: Listing 5.15 Plotting the least-penalized temperature
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.15 绘制最低惩罚温度图
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The least-penalized center splits the measured temperatures fairly evenly:
    four measurements appear above it, and three measurements appear below it. Thus,
    this center maintains a balanced data split while providing a closer distance
    to the coldest recorded temperature relative to the median.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最低惩罚中心将测量的温度分割得相当均匀：四个测量值出现在它上方，三个测量值出现在它下方。因此，这个中心在保持平衡数据分割的同时，提供了相对于中位数更接近最冷记录温度的距离。
- en: The least-penalized center is a good measure of centrality. It minimizes all
    the penalties incurred for being too far from any given point, which leads to
    balanced distances between the center and every data point. Unfortunately, our
    computation of that center was very inefficient. Scanning all possible penalties
    is not a scalable solution. Is there a more efficient way to compute the center?
    Yes! Mathematicians have shown that the sum-of-squared-distances error is always
    minimized by the *average* value of a dataset. Thus, we can compute the least-penalized
    center directly. We simply need to sum all the elements in `measurements` and
    then divide that sum by the array size.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最低惩罚中心是中心性的良好度量。它最小化了所有因距离任何给定点太远而造成的惩罚，这导致了中心与每个数据点之间的平衡距离。不幸的是，我们计算该中心的方法非常低效。扫描所有可能的惩罚不是一个可扩展的解决方案。有没有更有效的方法来计算中心？是的！数学家已经证明，平方距离误差总是由数据集的
    *平均值* 最小化。因此，我们可以直接计算最低惩罚中心。我们只需要将 `measurements` 中的所有元素相加，然后将这个总和除以数组大小。
- en: Listing 5.16 Computing the least-penalized center using an average value
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.16 使用平均值计算最低惩罚中心
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: A summed array of values divided by array size is formally called the *arithmetic
    mean*. Informally, the value is referred to as the *mean* or the average of the
    array. The mean can be computed by calling the `mean` method of a NumPy array.
    We can also compute the mean by calling the `np.mean` and `np.average` methods.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将值的总和除以数组大小正式称为 *算术平均值*。非正式地，这个值被称为数组的 *平均值* 或平均。平均值可以通过调用 NumPy 数组的 `mean`
    方法来计算。我们也可以通过调用 `np.mean` 和 `np.average` 方法来计算平均值。
- en: Listing 5.17 Computing the mean using NumPy
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.17 使用 NumPy 计算平均值
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `np.average` method differs from the `np.mean` method because it takes as
    input an optional `weights` parameter. The `weights` parameter is a list of numeric
    weights that capture the importance of the measurements relative to each other.
    When all the weights are equal, the output of `np.average` is no different from
    `np.mean`. However, adjusting the weights leads to a difference in the outputs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`np.average` 方法与 `np.mean` 方法不同，因为它接受一个可选的 `weights` 参数。`weights` 参数是一个包含数值权重的列表，这些权重捕捉了测量值相对于彼此的重要性。当所有权重相等时，`np.average`
    的输出与 `np.mean` 无异。然而，调整权重会导致输出结果的不同。'
- en: Listing 5.18 Passing weights into `np.average`
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.18 将权重传递给 `np.average`
- en: '[PRE17]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The `weights` parameter is useful for computing the mean across duplicate measurements.
    Suppose we analyze 10 temperature measurements where 75 degrees appears 9 times
    and 77 degrees appears just once. The full list of measurements is represented
    by `9 * [75] + [77]`. We can compute the mean by calling `np.mean` on that list.
    We can also compute the mean by calling `np.average([75, 77], weights=[9, 1])`;
    both computations are equal.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`weights`参数对于计算重复测量值的均值非常有用。假设我们分析了10次温度测量，其中75度出现了9次，而77度只出现了一次。完整的测量列表表示为`9
    * [75] + [77]`。我们可以通过调用`np.mean`来计算该列表的均值。我们也可以通过调用`np.average([75, 77], weights=[9,
    1])`来计算均值；这两种计算是相等的。'
- en: Listing 5.19 Computing the weighted mean of duplicate values
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.19 计算重复值的加权均值
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Computing the weighted mean serves as a shortcut for computing the regular mean
    when duplicates are present. In the computation, the relative ratio of unique
    measurement counts is represented by the ratio of the weights. Thus, even if we
    convert our absolute counts of 9 and 1 into relative weights of 900 and 100, the
    final value of `weighted_mean` should remain the same. This is also true if the
    weights are converted into relative probabilities of 0.9 and 0.1.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 计算加权均值是计算存在重复值时的常规均值的快捷方式。在计算中，唯一测量计数的相对比率由权重的比率表示。因此，即使我们将9和1的绝对计数转换为900和100的相对权重，`weighted_mean`的最终值也应保持不变。如果将权重转换为0.9和0.1的相对概率，这也同样适用。
- en: Listing 5.20 Computing the weighted mean of relative weights
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.20 计算相对权重的加权均值
- en: '[PRE19]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We can treat probabilities as weights. Consequently, this allows us to compute
    the mean of any probability distribution.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将概率视为权重。因此，这使我们能够计算任何概率分布的均值。
- en: 5.2.1 Finding the mean of a probability distribution
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 求概率分布的均值
- en: At this point in the book, we are intimately familiar with the 20-coin-flip
    binomial distribution. The distribution’s peak is symmetrically centered at 10
    heads. How does that peak compare to the distribution’s mean? Let’s find out.
    We compute the mean by passing a `probabilities` array into the `weights` parameter
    of `np.average`. Then we plot the mean as a vertical line that cuts across the
    distribution (figure 5.9).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的这一部分，我们与20次抛硬币的二项式分布非常熟悉。该分布的峰值对称地位于10个正面中间。这个峰值与分布的均值相比如何？让我们来看看。我们通过将`probabilities`数组传递给`np.average`的`weights`参数来计算均值。然后我们以一条垂直线绘制均值，该线穿过分布（图5.9）。
- en: '![](../Images/05-09.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-09.png)'
- en: Figure 5.9 A 20-coin-flip binomial distribution bisected by its mean. The mean
    is positioned directly in the distribution’s center.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9 一个20次抛硬币的二项式分布，其均值将其一分为二。均值位于分布中心的直接位置。
- en: Listing 5.21 Computing the mean of a binomial distribution
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.21 计算二项式分布的均值
- en: '[PRE20]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ❶ The axvline method plots a vertical line at a specified x coordinate.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ `axvline`方法在指定的x坐标处绘制一条垂直线。
- en: 'The mean of the binomial is 10 heads. It cuts across the distribution’s central
    peak and perfectly captures the binomial’s centrality. For this reason, SciPy
    allows us to obtain the mean of any binomial simply by calling `stats.binom.mean`.
    The `stats.binom.mean` method takes as input two parameters: the number of coin
    flips and the probability of heads.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 二项式的均值是10个正面。它穿过分布的中心峰值，完美地捕捉了二项式的中心性。因此，SciPy允许我们通过调用`stats.binom.mean`来简单地获得任何二项式的均值。`stats.binom.mean`方法接受两个参数：抛硬币的次数和正面的概率。
- en: Listing 5.22 Computing the binomial mean using SciPy
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.22 使用SciPy计算二项式均值
- en: '[PRE21]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Using the `stats.binom.mean` method, we can rigorously analyze the relationship
    between binomial centrality and coin-flip count. Let’s plot the binomial mean
    across a range of coin-flip counts from 0 through 500 (figure 5.10).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`stats.binom.mean`方法，我们可以严格分析二项式中心性与抛硬币次数之间的关系。让我们绘制从0次到500次的抛硬币次数范围内的二项式均值（图5.10）。
- en: Listing 5.23 Plotting multiple binomial means
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.23 绘制多个二项式均值的分布图
- en: '[PRE22]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The coin-flip count and mean share a linear relationship in which the mean is
    equal to half the coin-flip count. With this in mind, let’s consider the mean
    of the single coin-flip binomial distribution (commonly called the *Bernoulli
    distribution*). The Bernoulli distribution has a coin-flip count of 1, so its
    mean is equal to 0.5\. Not surprisingly, the probability of a fair coin landing
    on heads is equal to the Bernoulli mean.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 抛硬币的次数和平均值之间存在线性关系，其中平均值等于抛硬币次数的一半。考虑到这一点，让我们考虑单次抛硬币的二项分布（通常称为 *伯努利分布*）。伯努利分布的抛硬币次数为
    1，因此其平均值等于 0.5。不出所料，公平硬币落在正面朝上的概率等于伯努利平均值。
- en: Listing 5.24 Predicting the mean of a Bernoulli distribution
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.24 预测伯努利分布的平均值
- en: '[PRE23]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We can use the observed linear relationship to predict the mean of a 1,000-coin-flip
    distribution. We expect that mean to equal 500 and be positioned in the distribution’s
    center. Let’s confirm that this is the case (figure 5.11).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用观察到的线性关系来预测 1,000 次抛硬币分布的平均值。我们预计这个平均值等于 500，并且位于分布的中心。让我们确认这一点（图 5.11）。
- en: '![](../Images/05-10.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-10.png)'
- en: Figure 5.10 Coin-flip count plotted against binomial mean. The relationship
    is linear. The mean of each binomial is equal to half its coin-flip count.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 抛硬币次数与二项分布平均值的关系图。这种关系是线性的。每个二项分布的平均值等于其抛硬币次数的一半。
- en: Listing 5.25 Predicting the mean of a 1,000-coin-flip distribution
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.25 预测 1,000 次抛硬币分布的平均值
- en: '[PRE24]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: A distribution’s mean serves as an excellent measure of centrality. Let’s now
    explore the use of variance as a measure of dispersion.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分布的平均值是衡量中心性的优秀指标。现在让我们探讨方差作为分散度衡量指标的使用。
- en: 5.3 Variance as a measure of dispersion
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 方差作为分散度的衡量指标
- en: '*Dispersion* is the scattering of data points around some central value. A
    smaller dispersion indicates more predictable data. A larger dispersion indicates
    greater data fluctuations. Consider a scenario where we measure summer temperatures
    in California and Kentucky. We gather three measurements for each state, at random
    locations. California is a huge state, with very diverse climates, so we expect
    to see fluctuations in our measurements. Our measured California temperatures
    are 52, 77, and 96 degrees. Our measured Kentucky temperatures are 71, 75, and
    79 degrees. We store these measured temperatures and compute their means.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*分散度* 是数据点围绕某个中心值的散布。较小的分散度表示数据更可预测。较大的分散度表示数据波动更大。考虑一个场景，我们测量加利福尼亚和肯塔基州的夏季温度。我们对每个州在随机位置进行三次测量。加利福尼亚是一个巨大的州，气候非常多样，因此我们预计我们的测量值会有波动。我们测量的加利福尼亚温度是
    52 度、77 度和 96 度。我们测量的肯塔基温度是 71 度、75 度和 79 度。我们存储这些测量值并计算它们的平均值。'
- en: '![](../Images/05-11.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-11.png)'
- en: Figure 5.11 A 1,000-coin-flip binomial distribution bisected by its mean. The
    mean is positioned directly in the distribution’s center.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 一个由其平均值分割的 1,000 次抛硬币的二项分布。平均值直接位于分布的中心。
- en: Listing 5.26 Measuring the means of multiple temperature arrays
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.26 测量多个温度数组的平均值
- en: '[PRE25]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The means of the two measurement arrays both equal 75\. California and Kentucky
    appear to share the same central temperature value. Despite this, the two measurement
    arrays are far from equal. The California temperatures are much more dispersed
    and unpredictable: they range from 52 to 96 degrees. Meanwhile, the stable Kentucky
    temperatures range from the low 70s to high 70s. They are more closely centered
    around the mean. We visualize this difference in dispersion by plotting the two
    measurement arrays (figure 5.12). Additionally, we demarcate the mean by plotting
    a horizontal line.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 两个测量数组的平均值都等于 75。加利福尼亚和肯塔基似乎共享相同的中心温度值。尽管如此，这两个测量数组远非相等。加利福尼亚的温度分散性更大且不可预测：它们从
    52 度到 96 度不等。与此同时，稳定的肯塔基温度从 70 多度到 80 多度不等。它们更接近平均值。我们通过绘制两个测量数组来可视化这种分散度的差异（图
    5.12）。此外，我们通过绘制一条水平线来标记平均值。
- en: Listing 5.27 Visualizing the difference in dispersion
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.27 可视化分散度的差异
- en: '[PRE26]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](../Images/05-12.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/05-12.png)'
- en: Figure 5.12 A plot of sorted temperatures for California and Kentucky. Temperatures
    in both states share a mean of 75 degrees. The California temperatures are more
    dispersed around that mean.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 加利福尼亚和肯塔基州的排序温度图。两州的平均温度均为 75 度。加利福尼亚的温度围绕该平均值更为分散。
- en: Within the plot, the three Kentucky temperatures nearly overlap with the flat
    mean. Meanwhile, the majority of California temperatures are noticeably more distant
    from the mean. We can quantify these observations if we penalize the California
    measurements for being too distant from their center. Previously, we computed
    such penalties using the sum-of-squared-distances function. Now we’ll compute
    the sum of squared distances between the California measurements and their mean.
    Statisticians refer to the sum of squared distances from the mean as simply the
    *sum of squares*. We define a `sum_of_squares` function and then apply it to our
    California temperatures.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，肯塔基的温度几乎与平坦的平均值重叠。同时，加利福尼亚的温度大多数明显偏离平均值。如果我们对加利福尼亚的测量值因偏离其中心太远而进行惩罚，我们就可以量化这些观察结果。之前，我们使用平方距离之和函数来计算这样的惩罚。现在我们将计算加利福尼亚测量值与其平均值之间的平方距离之和。统计学家将平均值到平方距离之和简称为*平方和*。我们定义一个`sum_of_squares`函数，然后将其应用于我们的加利福尼亚温度。
- en: Listing 5.28 Computing California’s sum of squares
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.28 计算加利福尼亚的平方和
- en: '[PRE27]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: California’s sum of squares is 974\. We expect Kentucky’s sum of squares to
    be noticeably lower. Let’s confirm.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 加利福尼亚的平方和为 974。我们预计肯塔基的平方和将明显较低。让我们来确认一下。
- en: Listing 5.29 Computing Kentucky’s sum of squares
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.29 计算肯塔基的平方和
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Kentucky’s sum of squares is 32\. Thus, we see a thirtyfold difference between
    our California results and our Kentucky calculations. This isn’t surprising, because
    the Kentucky data points are much less dispersed. The sum of squares helps measure
    that dispersion—however, the measurement is not perfect. Suppose we duplicate
    the temperatures in the `California` array by recording each temperature twice.
    The level of dispersion will remain the same even though the sum of squares will
    double.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 肯塔基的平方和为 32。因此，我们看到加利福尼亚的结果和肯塔基的计算之间有三十倍的差异。这并不令人惊讶，因为肯塔基的数据点分散程度较低。平方和有助于衡量这种分散——然而，这种测量并不完美。假设我们通过记录每个温度两次来复制`California`数组中的温度。即使平方和加倍，分散程度也将保持不变。
- en: Listing 5.30 Computing sum of squares after array duplication
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.30 在数组复制后计算平方和
- en: '[PRE29]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The sum of squares is not a good measure of dispersion because it’s influenced
    by the size of the inputted array. Fortunately, that influence is easy to eliminate
    if we divide the sum of squares by the array size. Dividing `california_sum_squares`
    by `california.size` produces a value equal to `duplicated_sum_squares / california_
    duplicated.size`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 平方和不是衡量分散程度的好方法，因为它受输入数组大小的影响。幸运的是，如果我们通过除以数组大小来消除这种影响，那么这种影响就很容易消除。将`california_sum_squares`除以`california.size`产生一个等于`duplicated_sum_squares
    / california_duplicated.size`的值。
- en: Listing 5.31 Dividing sum of squares by array size
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.31 将平方和除以数组大小
- en: '[PRE30]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Dividing the sum of squares by the number of measurements produces what statisticians
    call the *variance*. Conceptually, the variance is equal to the average squared
    distance from the mean.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 将平方和除以测量次数产生统计学家所说的*方差*。从概念上讲，方差等于平均平方距离。
- en: Listing 5.32 Computing the variance from mean squared distance
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.32 从平均平方距离计算方差
- en: '[PRE31]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The variances for the `california` and `california_duplicated` arrays are equal
    since their levels of dispersion are identical.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`california`和`california_duplicated`数组的方差相等，因为它们的分散程度相同。'
- en: Listing 5.33 Computing the variance after array duplication
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.33 在数组复制后计算方差
- en: '[PRE32]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Meanwhile, the variances for the `California` and `Kentucky` arrays retain their
    thirtyfold ratio caused by a difference in dispersion.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，`California`和`Kentucky`数组的方差保持了由于分散程度差异而产生的三十倍比率。
- en: Listing 5.34 Comparing the variances of California and Kentucky
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.34 比较加利福尼亚和肯塔基的方差
- en: '[PRE33]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Variance is a good measure of dispersion. It can be computed by calling `np.var`
    on a Python list or NumPy array. The variance of a NumPy array can also be computed
    using the array’s built-in `var` method.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 方差是衡量分散程度的好方法。可以通过在 Python 列表或 NumPy 数组上调用`np.var`来计算方差。NumPy 数组的方差也可以使用数组的内置`var`方法来计算。
- en: Listing 5.35 Computing the variance using NumPy
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.35 使用 NumPy 计算方差
- en: '[PRE34]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Variance is dependent on the mean. If we compute a weighted mean, then we must
    also compute a weighted variance. Computing the weighted variance is easy: as
    stated earlier, the variance is simply the average of all the squared distances
    from the mean, so the weighted variance is the weighted average of all the squared
    distances from the weighted mean. Let’s define a `weighted_variance` function
    that takes as input two parameters: a data list and weights. It then computes
    the weighted mean and uses the `np.average` method to compute the weighted average
    of the squared distances from that mean.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 方差依赖于均值。如果我们计算加权均值，那么我们也必须计算加权方差。计算加权方差很简单：如前所述，方差是所有平方距离的平均值，因此加权方差是所有平方距离从加权均值的加权平均值。让我们定义一个`weighted_variance`函数，它接受两个参数：数据列表和权重。然后它计算加权均值并使用`np.average`方法计算从该均值到所有平方距离的加权平均值。
- en: Listing 5.36 Computing the weighted variance using `np.average`
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.36 使用`np.average`计算加权方差
- en: '[PRE35]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: ❶ weighted_variance lets us treat duplicated elements as weights.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ `weighted_variance`允许我们将重复元素视为权重。
- en: The `weighted_variance` function can take as its input an array of probabilities.
    This allows us to compute the variance of any probability distribution.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`weighted_variance`函数可以接受概率数组作为输入。这允许我们计算任何概率分布的方差。'
- en: 5.3.1 Finding the variance of a probability distribution
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 求概率分布的方差
- en: Let’s compute the variance of the binomial distribution associated with 20 fair
    coin flips. We run the computation by assigning a `probabilities` array to the
    `weights` parameter of `weighted_variance`.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们计算与20次公平硬币翻转相关的二项分布的方差。我们通过将`probabilities`数组分配给`weighted_variance`的`weights`参数来运行计算。
- en: Listing 5.37 Computing the variance of a binomial distribution
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.37 计算二项分布的方差
- en: '[PRE36]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The binomial’s variance is 5, which is equal to half of the binomial’s mean.
    That variance can be computed more directly using SciPy’s `stats.binom.var` method.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 二项分布的方差是5，这等于二项分布均值的二分之一。这个方差可以使用SciPy的`stats.binom.var`方法更直接地计算。
- en: Listing 5.38 Computing the binomial variance using SciPy
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.38 使用SciPy计算二项分布的方差
- en: '[PRE37]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Using the `stats.binom.var` method, we can rigorously analyze the relationship
    between binomial dispersion and coin-flip count. Let’s plot the binomial variance
    across a range of coin-flip counts from 0 to 500 (figure 5.13).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`stats.binom.var`方法，我们可以严格分析二项分布的离散性与硬币翻转次数之间的关系。让我们绘制从0到500次硬币翻转的范围内二项分布方差的变化图（图5.13）。
- en: '![](../Images/05-13.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/05-13.png)'
- en: Figure 5.13 Coin-flip count plotted against binomial variance. The relationship
    is linear. The variance of each binomial is equal to one-fourth of its coin-flip
    count.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13 硬币翻转次数与二项分布方差的关系图。这种关系是线性的。每个二项分布的方差等于其硬币翻转次数的四分之一。
- en: Listing 5.39 Plotting multiple binomial variances
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.39 绘制多个二项分布的方差
- en: '[PRE38]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The binomial’s variance, like its mean, is linearly related to the coin-flip
    count. The variance is equal to one-fourth of the coin-flip count. Thus, the Bernoulli
    distribution has a variance of 0.25 because its coin-flip count is 1\. By this
    logic, we can expect a variance of 250 for a 1,000-coin-flip distribution.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 二项分布的方差，就像它的均值一样，与硬币翻转次数线性相关。方差等于硬币翻转次数的四分之一。因此，伯努利分布的方差为0.25，因为它的硬币翻转次数为1。按照这个逻辑，我们可以预期1000次硬币翻转分布的方差为250。
- en: Listing 5.40 Predicting binomial variances
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.40 预测二项分布的方差
- en: '[PRE39]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Common SciPy methods for binomial analysis
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的SciPy二项分析方法
- en: '`stats.binom.mean(num_flips, prob_heads)`—Returns the mean of a binomial where
    the flip count equals `num_flips` and the probability of heads equals `prob_heads`.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stats.binom.mean(num_flips, prob_heads)`—返回一个二项分布的均值，其中翻转次数等于`num_flips`，正面出现的概率等于`prob_heads`。'
- en: '`stats.binom.var(num_flips, prob_heads)`—Returns the variance of a binomial
    where the flip count equals `num_flips` and probability of heads equals `prob_heads`.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stats.binom.var(num_flips, prob_heads)`—返回一个二项分布的方差，其中翻转次数等于`num_flips`，正面出现的概率等于`prob_heads`。'
- en: '`stats.binom.pmf(head_count_int, num_flips, prob_heads)`—Returns the probability
    of observing `head_count_int` heads out of `num_flips` coin flips. A single coin
    flip’s probability of heads is set to `prob_heads`.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stats.binom.pmf(head_count_int, num_flips, prob_heads)`—返回在`num_flips`次硬币翻转中出现`head_count_int`次正面的概率。单次翻转出现正面的概率设置为`prob_heads`。'
- en: '`stats.binom.pmf(head_count_array, num_flips, prob_heads)`—Returns an array
    of binomial probabilities. These are obtained by executing `stats .binom.pmf(e,
    num_flips, prob_head)` on each element `e` of `head_count_ array`.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stats.binom.pmf(head_count_array, num_flips, prob_heads)`—返回一个二项概率数组。这些概率是通过在每个`head_count_array`的元素`e`上执行`stats
    .binom.pmf(e, num_flips, prob_head)`获得的。'
- en: '`stats.binom_test(head_count_int, num_flips, prob_heads)`—Returns the probability
    of `num_flips` coin flips generating at least `head_count_int` heads or `tail_count_int`
    tails. A single coin flip’s probability of heads is set to `prob_heads`.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stats.binom_test(head_count_int, num_flips, prob_heads)`—返回`num_flips`次硬币翻转产生至少`head_count_int`次正面或`tail_count_int`次反面的概率。单次抛硬币正面的概率设置为`prob_heads`。'
- en: The variance is a powerful measure of data dispersion. However, statisticians
    often use an alternative measure, which they call the *standard deviation*. The
    standard deviation is equal to the square root of the variance. It can be computed
    by calling `np.std`. Squaring the output of `np.std` naturally returns the variance.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 方差是衡量数据离散度的强大指标。然而，统计学家经常使用一个替代指标，他们称之为*标准差*。标准差等于方差的平方根。可以通过调用`np.std`来计算。`np.std`的输出平方自然返回方差。
- en: Listing 5.41 Computing the standard deviation
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 列表5.41 计算标准差
- en: '[PRE40]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We sometimes use standard deviation instead of variance to track units more
    easily. All measurements have units. For example, our temperatures were in units
    of degrees Fahrenheit. When we squared the distances of the temperature to their
    mean, we also squared their units; therefore, our variance was in units of degrees
    Fahrenheit squared. Such squared units are very tricky to conceptualize. Taking
    the square root converts the units back to degrees Fahrenheit: a standard deviation
    in units of degrees Fahrenheit is more easily interpretable than the variance.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有时使用标准差而不是方差来更容易地跟踪单位。所有测量都有单位。例如，我们的温度是以华氏度为单位。当我们平方温度到其均值的距离时，我们也平方了它们的单位；因此，我们的方差是以华氏度平方为单位。这样的平方单位很难理解。取平方根将单位转换回华氏度：华氏度的标准差比方差更容易解释。
- en: 'The mean and standard deviation are incredibly useful values. They allow us
    to do the following:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 均值和标准差是极其有用的数值。它们使我们能够做以下事情：
- en: '*Compare numeric datasets.* Suppose we’re given two arrays of recorded temperatures
    for two consecutive summers. We can quantify the differences between these summer
    records using mean and standard deviation.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*比较数值数据集。* 假设我们得到了两个连续夏季记录的温度数组。我们可以使用均值和标准差来量化这些夏季记录之间的差异。'
- en: '*Compare probability distributions.* Suppose two climate research labs publish
    probability distributions. Each distribution captures all temperature probabilities
    across a standard summer day. We can summarize the differences between the two
    distributions by comparing their means and standard deviations.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*比较概率分布。* 假设有两个气候研究实验室发布了概率分布。每个分布都捕捉了标准夏日一天内的所有温度概率。我们可以通过比较它们的均值和标准差来总结这两个分布之间的差异。'
- en: '*Compare a numeric dataset to a probability distribution.* Suppose a well-known
    probability distribution captures a decade’s worth of temperature probabilities.
    However, recently recorded summer temperatures appear to contradict these probability
    outputs. Is this a sign of climate change or simply a random anomaly? We can find
    out by juxtaposing the centrality and dispersion for the distribution and the
    temperature dataset.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*比较数值数据集与概率分布。* 假设一个著名的概率分布捕捉了十年温度概率。然而，最近记录的夏季温度似乎与这些概率输出相矛盾。这是气候变化的迹象，还是仅仅是一个随机异常？我们可以通过比较分布的中心和离散度以及温度数据集来找出答案。'
- en: The third use case underlies much of statistics. In the subsequent sections,
    we learn how to compare datasets to distribution likelihoods. Many of our comparisons
    focus on the normal distribution, which commonly arises in data analysis. Conveniently,
    that distribution’s bell-shaped curve is a direct function of mean and standard
    deviation. We’ll soon use SciPy, along with these two parameters, to better grasp
    the normal curve’s significance.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个用例是统计学中许多内容的基础。在接下来的章节中，我们将学习如何将数据集与分布似然进行比较。我们的许多比较都集中在正态分布上，这在数据分析中很常见。方便的是，该分布的钟形曲线是均值和标准差的直接函数。我们将很快使用SciPy，以及这两个参数，来更好地理解正态曲线的重要性。
- en: Summary
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A *probability mass function* maps inputted integer values to their probability
    of occurrence.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*概率质量函数*将输入的整数值映射到它们发生的概率。'
- en: The probability mass function for the binomial distribution can be generated
    by calling `stats.binom.pmf`.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过调用 `stats.binom.pmf` 来生成二项分布的概率质量函数。
- en: '*Mean* is a good measure of a dataset’s centrality. It minimizes the *sum of
    squares* relative to the dataset. We can compute an unweighted mean by summing
    the dataset values and dividing by the dataset size. We can also compute a weighted
    mean by inputting a `weights` array into `np.average`. The weighted mean of the
    binomial distribution increases linearly with the coin-flip count.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*均值* 是衡量数据集中心性的良好指标。它相对于数据集最小化了平方和。我们可以通过将数据集值相加并除以数据集大小来计算未加权均值。我们还可以通过将 `weights`
    数组输入到 `np.average` 中来计算加权均值。二项分布的加权均值随着抛硬币次数的增加而线性增长。'
- en: '*Variance* is a good measure of a dataset’s dispersion. It equals the average
    squared distance of the data point from the mean. The weighted variance of the
    binomial distribution increases linearly with the coin-flip count.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*方差* 是衡量数据集分散程度的良好指标。它等于数据点与均值之间的平均平方距离。二项分布的加权方差随着抛硬币次数的增加而线性增长。'
- en: The *standard deviation* is an alternative measure of dispersion. It equals
    the square root of the variance. The standard deviation maintains the units used
    in a dataset.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*标准差* 是分散程度的另一种衡量指标。它等于方差的平方根。标准差保持了数据集中使用的单位。'
