- en: 1 What is machine learning? It is common sense, except done by a computer
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 什么是机器学习？它只是由计算机完成的常识
- en: In this chapter
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容
- en: what is machine learning
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是机器学习
- en: 'is machine learning hard (spoiler: no)'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习难吗？（剧透：不难）
- en: what do we learn in this book
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在这本书中学到了什么
- en: what is artificial intelligence, and how does it differ from machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能是什么，它与机器学习有何不同
- en: how do humans think, and how can we inject those ideas into a machine
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类是如何思考的，我们如何将这些想法注入到机器中
- en: some basic machine learning examples in real life
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些现实生活中的基本机器学习实例
- en: '![](../Images/1-unnumb.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-unnumb.png)'
- en: I am super happy to join you in your learning journey!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我非常高兴能与你一起踏上学习之旅！
- en: Welcome to this book! I’m super happy to be joining you in this journey through
    understanding machine learning. At a high level, machine learning is a process
    in which the computer solves problems and makes decisions in much the same way
    as humans.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到这本书！我非常高兴能与你一起加入理解机器学习的旅程。从高层次来看，机器学习是一个计算机以类似于人类的方式解决问题和做出决策的过程。
- en: 'In this book, I want to bring one message to you: machine learning is easy!
    You do not need to have a heavy math and programming background to understand
    it. You do need some basic mathematics, but the main ingredients are common sense,
    a good visual intuition, and a desire to learn and apply these methods to anything
    that you are passionate about and where you want to make an improvement in the
    world. I’ve had an absolute blast writing this book, because I love growing my
    understanding of this topic, and I hope you have a blast reading it and diving
    deep into machine learning!'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我想给你传达一个信息：机器学习很简单！你不需要有深厚的数学和编程背景就能理解它。你确实需要一些基本的数学知识，但主要成分是常识、良好的视觉直觉，以及将学习这些方法应用于你热爱的任何事物并希望在世界中做出改进的愿望。我写这本书时非常开心，因为我喜欢增长对这个主题的理解，我希望你在阅读它并深入研究机器学习时也能感到兴奋！
- en: Machine learning is everywhere
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习无处不在
- en: 'Machine learning is everywhere. This statement seems to be truer every day.
    I have a hard time imagining a single aspect of life that cannot be improved in
    some way or another by machine learning. For any job that requires repetition
    or looking at data and gathering conclusions, machine learning can help. During
    the last few years, machine learning has seen tremendous growth due to the advances
    in computing power and the ubiquity of data collection. Just to name a few applications
    of machine learning: recommendation systems, image recognition, text processing,
    self-driving cars, spam recognition, medical diagnoses . . . the list goes on.
    Perhaps you have a goal or an area in which you want to make an impact (or maybe
    you are already making it!). Very likely, machine learning can be applied to that
    field—perhaps that is what brought you to this book. Let’s find out together!'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习无处不在。这句话似乎每天都在变得更加真实。我很难想象生活中有任何方面不能通过机器学习以某种方式得到改善。对于任何需要重复操作或查看数据并得出结论的工作，机器学习都能提供帮助。在过去的几年里，由于计算能力的提升和数据收集的普遍性，机器学习经历了巨大的增长。仅举几个机器学习的应用实例：推荐系统、图像识别、文本处理、自动驾驶汽车、垃圾邮件识别、医疗诊断……这个列表还在继续。也许你有一个目标或一个你想要产生影响（或者你可能已经做到了！）的领域！很可能，机器学习可以应用于那个领域——也许这正是你来到这本书的原因。让我们一起来看看吧！
- en: Do I need a heavy math and coding background to understand machine learning?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我需要深厚的数学和编程背景来理解机器学习吗？
- en: No. Machine learning requires imagination, creativity, and a visual mind. Machine
    learning is about picking up patterns that appear in the world and using those
    patterns to make predictions in the future. If you enjoy finding patterns and
    spotting correlations, then you can do machine learning. If I were to tell you
    that I stopped smoking and am eating more vegetables and exercising, what would
    you predict will happen to my health in one year? Perhaps that it will improve.
    If I were to tell you that I’ve switched from wearing red sweaters to green sweaters,
    what would you predict will happen to my health in one year? Perhaps that it won’t
    change much (it may, but not based on the information I gave you). Spotting these
    correlations and patterns is what machine learning is about. The only difference
    is that in machine learning, we attach formulas and numbers to these patterns
    to get computers to spot them.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: No. 机器学习需要想象力、创造力和视觉思维。机器学习是关于捕捉世界中出现模式，并使用这些模式来对未来进行预测。如果你喜欢寻找模式和发现相关性，那么你可以从事机器学习。如果我要告诉你我已经戒烟，并且开始多吃蔬菜和锻炼，你预测我的健康状况在一年后会发生什么？或许会变好。如果我要告诉你我已经从穿红色毛衣换成了绿色毛衣，你预测我的健康状况在一年后会发生什么？或许变化不会很大（可能会，但不是基于你提供的信息）。发现这些相关性和模式正是机器学习的内容。唯一的区别在于，在机器学习中，我们将公式和数字附加到这些模式上，以便让计算机发现它们。
- en: Some mathematics and coding knowledge are needed to do machine learning, but
    you don’t need to be an expert. If you *are* an expert in either of them, or both,
    you will certainly find your skills will be rewarded. But if you are not, you
    can still learn machine learning and pick up the mathematics and coding as you
    go. In this book, we introduce all the mathematical concepts we need at the moment
    we need them. When it comes to coding, how much code you write in machine learning
    is up to you. Machine learning jobs range from those who code all day long, to
    those who don’t code at all. Many packages, APIs, and tools help us do machine
    learning with minimal coding. Every day, machine learning is more available to
    everyone in the world, and I’m glad you’ve jumped on the bandwagon!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 进行机器学习需要一些数学和编码知识，但你不需要成为专家。如果你在任何一个领域或两个领域都是专家，你的技能肯定会得到回报。但如果你不是，你仍然可以学习机器学习，并在学习过程中掌握数学和编码。在这本书中，我们会在需要的时候介绍我们需要的所有数学概念。至于编码，你在机器学习中需要编写多少代码取决于你。机器学习的工作范围从整天编码的人到完全不编码的人都有。许多软件包、API和工具帮助我们用最少的编码来进行机器学习。每天，机器学习对世界上每个人来说都更加容易获得，我很高兴你加入了这趟列车！
- en: Formulas and code are fun when seen as a language
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 将公式和代码视为一种语言时，它们变得很有趣
- en: 'In most machine learning books, algorithms are explained mathematically using
    formulas, derivatives, and so on. Although these precise descriptions of the methods
    work well in practice, a formula sitting by itself can be more confusing than
    illustrative. However, like a musical score, a formula may hide a beautiful melody
    behind the confusion. For example, let’s look at this formula: Σ[i]⁴[=1]*i*. It
    looks ugly at first glance, but it represents a very simple sum, namely, 1 + 2
    + 3 + 4\. And what about Σ[i]^n[=1]*w*[i]? That is simply the sum of many (*n*)
    numbers. But when I think of a sum of many numbers, I’d rather imagine something
    like 3 + 2 + 4 + 27, rather than 1 Σ[i]^n[=1]*w*[i]. Whenever I see a formula,
    I immediately have to imagine a small example of it, and then the picture is clearer
    in my mind. When I see something like *P*(*A*|*B*), what comes to mind? That is
    a conditional probability, so I think of some sentence along the lines of “The
    probability that an event A occurs given that another event B already occurs.”
    For example, if A represents rain today and B represents living in the Amazon
    rain forest, then the formula *P*(*A*|*B*) = 0.8 simply means “The probability
    that it rains today given that we live in the Amazon rain forest is 80%.”'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数机器学习书籍中，算法都是通过公式、导数等方式进行数学解释的。虽然这些方法的精确描述在实践中效果很好，但一个单独的公式可能比说明性更强。然而，就像音乐乐谱一样，一个公式可能隐藏在混乱背后的美丽旋律。例如，让我们看看这个公式：Σ[i]⁴[=1]*i*。乍一看，它看起来很丑，但它代表一个非常简单的求和，即1
    + 2 + 3 + 4。那么关于Σ[i]^n[=1]*w*[i]呢？这仅仅是许多(*n*)个数的总和。但当我想到许多数的总和时，我更愿意想象像3 + 2 +
    4 + 27这样的东西，而不是1 Σ[i]^n[=1]*w*[i]。每次我看到一个公式，我立刻就得想象一个它的小例子，然后我的脑海中画面就更加清晰了。当我看到像*P*(*A*|*B*)这样的东西时，我脑海中会想什么？那是一个条件概率，所以我想到一些类似“在另一个事件B已经发生的情况下，事件A发生的概率”的句子。例如，如果A代表今天的雨，B代表居住在亚马逊雨林，那么公式*P*(*A*|*B*)
    = 0.8就简单地意味着“在我们居住在亚马逊雨林的情况下，今天下雨的概率是80%。”
- en: If you do love formulas, don’t worry—this book still has them. But they will
    appear right after the example that illustrates them.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你确实喜欢公式，不用担心——这本书中仍然有它们。但它们将出现在说明它们的示例之后。
- en: The same phenomenon happens with code. If we look at code from far away, it
    may look complicated, and we might find it hard to imagine that someone could
    fit all of that in their head. However, code is simply a sequence of steps, and
    normally each of these steps is simple. In this book, we’ll write code, but it
    will be broken down into simple steps, and each step will be carefully explained
    with examples or illustrations. During the first few chapters, we will be coding
    our models from scratch to understand how they work. In the later chapters, however,
    the models get more complicated. For these, we will use packages such as Scikit-Learn,
    Turi Create, or Keras, which have implemented most machine learning algorithms
    with great clarity and power.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的现象也发生在代码上。如果我们从远处看代码，它可能看起来很复杂，我们可能很难想象有人能把所有这些内容都装进脑子里。然而，代码只是一系列步骤，通常每个步骤都很简单。在这本书中，我们将编写代码，但我们会将其分解成简单的步骤，并且每个步骤都会通过示例或插图进行仔细解释。在前几章中，我们将从头开始编写我们的模型代码，以了解它们是如何工作的。然而，在后面的章节中，模型会变得更加复杂。对于这些，我们将使用Scikit-Learn、Turi
    Create或Keras等包，这些包已经以清晰和强大的方式实现了大多数机器学习算法。
- en: OK, so what exactly is machine learning?
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 好吧，那么机器学习究竟是什么呢？
- en: 'To define machine learning, first let’s define a more general term: artificial
    intelligence.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要定义机器学习，首先让我们定义一个更广泛的概念：人工智能。
- en: What is artificial intelligence?
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能是什么？
- en: '*Artificial* *intelligence* (AI) is a general term, which we define as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能*（AI）是一个通用术语，我们将其定义为以下内容：'
- en: artificial intelligence The set of all tasks in which a computer can make decisions
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能：计算机可以做出决策的所有任务的集合
- en: In many cases, a computer makes these decisions by mimicking the ways a human
    makes decisions. In other cases, they may mimic evolutionary processes, genetic
    processes, or physical processes. But in general, any time we see a computer solving
    a problem by itself, be it driving a car, finding a route between two points,
    diagnosing a patient, or recommending a movie, we are looking at artificial intelligence.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，计算机通过模仿人类决策的方式做出这些决策。在其他情况下，它们可能模仿进化过程、遗传过程或物理过程。但总的来说，每次我们看到计算机通过自己解决问题时，无论是开车、在两点之间找到路线、诊断病人还是推荐电影，我们都在看到人工智能。
- en: What is machine learning?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是什么？
- en: 'Machine learning is similar to artificial intelligence, and often their definitions
    are confused. Machine learning (ML) is a part of artificial intelligence, and
    we define it as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习类似于人工智能，并且它们的定义经常被混淆。机器学习（ML）是人工智能的一部分，我们将其定义为以下内容：
- en: machine learning The set of all tasks in which a computer can make decisions
    *based on data*
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习 是计算机可以基于数据做出决策的所有任务的集合
- en: What does this mean? Allow me to illustrate with the diagram in figure 1.1.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这是什么意思？让我用图1.1中的图表来解释。
- en: '![](../Images/1-11.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-11.png)'
- en: Figure 1.1 Machine learning is a part of artificial intelligence.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 机器学习是人工智能的一部分。
- en: 'Let’s go back to looking at how humans make decisions. In general terms, we
    make decisions in the following two ways:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下人类是如何做决定的。一般来说，我们通过以下两种方式来做决定：
- en: By using logic and reasoning
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用逻辑和推理
- en: By using our experience
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用我们的经验
- en: For example, imagine that we are trying to decide what car to buy. We can look
    carefully at the features of the car, such as price, fuel consumption, and navigation,
    and try to figure out the best combination of them that adjusts to our budget.
    That is using logic and reasoning. If instead we ask all our friends what cars
    they own, and what they like and dislike about them, we form a list of information
    and use that list to decide, then we are using experience (in this case, our friends’
    experiences).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，想象一下我们正在尝试决定买什么车。我们可以仔细查看汽车的特征，如价格、油耗和导航，并试图找出最适合我们预算的最佳组合。这就是使用逻辑和推理。如果我们向所有朋友询问他们拥有的汽车以及他们喜欢和不喜欢的地方，我们就会形成一份信息列表，并使用这份列表来做决定，那么我们就是在使用经验（在这种情况下，我们的朋友的经历）。
- en: 'Machine learning represents the second method: making decisions using our experience.
    In computer lingo, the term for *experience* is *data*. Therefore, in machine
    learning, computers make decisions based on data. Thus, any time we get a computer
    to solve a problem or make a decision using only data, we are doing machine learning.
    Colloquially, we could describe machine learning in the following way:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习代表了第二种方法：使用我们的经验来做决定。在计算机术语中，*经验*的术语是*数据*。因此，在机器学习中，计算机基于数据做决定。因此，每次我们让计算机仅使用数据解决问题或做决定时，我们就是在做机器学习。通俗地说，我们可以这样描述机器学习：
- en: Machine learning is common sense, except done by a computer.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是常识，只是由计算机来完成。
- en: Going from solving problems using any means necessary to solving problems using
    only data may feel like a small step for a computer, but it has been a huge step
    for humanity (figure 1.2). Once upon a time, if we wanted to get a computer to
    perform a task, we had to write a program, namely, a whole set of instructions
    for the computer to follow. This process is good for simple tasks, but some tasks
    are too complicated for this framework. For example, consider the task of identifying
    if an image contains an apple. If we start writing a computer program to develop
    this task, we quickly find out that it is hard.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从使用任何必要手段解决问题到仅使用数据解决问题，对于计算机来说可能感觉像是一小步，但对于人类来说却是一大步（图1.2）。曾经，如果我们想让计算机执行一项任务，我们必须编写一个程序，即一系列计算机需要遵循的指令。这个过程对于简单任务来说是好的，但有些任务对于这个框架来说太复杂了。例如，考虑识别图像中是否包含苹果的任务。如果我们开始编写一个计算机程序来开发这个任务，我们很快就会发现这很困难。
- en: '![](../Images/1-21.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-21.png)'
- en: Figure 1.2 Machine learning encompasses all the tasks in which computers make
    decisions based on data. In the same way that humans make decisions based on previous
    experiences, computers can make decisions based on previous data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 机器学习涵盖了所有计算机基于数据做出决策的任务。就像人类基于以往的经验做决定一样，计算机也可以基于以往的数据做决定。
- en: Let’s take a step back and ask the following question. How did we, as humans,
    learn how an apple looks? The way we learned most words was not by someone explaining
    to us what they mean; we learned them by repetition. We saw many objects during
    our childhood, and adults would tell us what these objects were. To learn what
    an apple was, we saw many apples throughout the years while hearing the word *apple*,
    until one day it clicked, and we knew what an apple was. In machine learning,
    that is what we get the computer to do. We show the computer many images, and
    we tell it which ones contain an apple (that constitutes our data). We repeat
    this process until the computer catches the right patterns and attributes that
    constitute an apple. At the end of the process, when we feed the computer a new
    image, it can use these patterns to determine whether the image contains an apple.
    Of course, we still need to program the computer so that it catches these patterns.
    For that, we have several techniques, which we will learn in this book.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们退一步，提出以下问题。作为人类，我们是如何学会苹果的外观的呢？我们学习大多数单词的方式并不是通过有人向我们解释它们的意思；我们是通过重复来学习的。在我们童年时期，我们看到了许多物体，成年人会告诉我们这些物体的名称。为了学习苹果是什么，我们在多年间看到了许多苹果，同时听到“苹果”这个词，直到有一天它突然明白了，我们就知道了苹果是什么。在机器学习中，这就是我们让计算机去做的事情。我们向计算机展示许多图像，并告诉它哪些图像包含苹果（这构成了我们的数据）。我们重复这个过程，直到计算机捕捉到构成苹果的正确模式和属性。在过程的最后，当我们向计算机提供一张新图像时，它可以使用这些模式来确定图像中是否包含苹果。当然，我们仍然需要编程计算机以便它能够捕捉到这些模式。为此，我们有几种技术，这些技术我们将在本书中学习。
- en: And now that we’re at it, what is deep learning?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经进入这个话题了，那么什么是深度学习呢？
- en: 'In the same way that machine learning is part of artificial intelligence, deep
    learning is a part of machine learning. In the previous section, we learned we
    have several techniques we use to get the computer to learn from data. One of
    these techniques has been performing tremendously well, so it has its own field
    of study called *deep learning* (DL), which we define as follows and as shown
    in figure 1.3:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 与机器学习是人工智能的一部分一样，深度学习是机器学习的一部分。在上一节中，我们了解到我们有几种技术用来让计算机从数据中学习。其中一种技术表现非常出色，因此它有一个自己的研究领域，称为“深度学习”（DL），我们如下定义，如图1.3所示：
- en: deep learning The field of machine learning that uses certain objects called
    *neural networks*
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习 使用称为“神经网络”的某些对象的机器学习领域
- en: What are neural networks? We’ll learn about them in chapter 10\. Deep learning
    is arguably the most used type of machine learning because it works really well.
    If we are looking at any of the cutting-edge applications, such as image recognition,
    text generation, playing Go, or self-driving cars, very likely we are looking
    at deep learning in some way or another.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是什么？我们将在第10章中学习它们。深度学习可以说是最常用的机器学习类型，因为它效果非常好。如果我们正在查看任何前沿应用，例如图像识别、文本生成、玩围棋或自动驾驶汽车，那么我们很可能以某种方式看到了深度学习。
- en: '![](../Images/1-3.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图1-3](../Images/1-3.png)'
- en: Figure 1.3 Deep learning is a part of machine learning.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 深度学习是机器学习的一部分。
- en: In other words, deep learning is part of machine learning, which in turn is
    part of artificial intelligence. If this book were about transportation, then
    AI would be vehicles, ML would be cars, and DL would be Ferraris.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，深度学习是机器学习的一部分，而机器学习又是人工智能的一部分。如果这本书是关于交通的，那么AI就是车辆，ML就是汽车，DL就是法拉利。
- en: How do we get machines to make decisions with data? The remember-formulate-predict
    framework
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们如何让机器通过数据做出决策？记住-制定-预测框架
- en: In the previous section, we discussed that machine learning consists of a set
    of techniques that we use to get the computer to make decisions based on data.
    In this section, we learn what is meant by making decisions based on data and
    how some of these techniques work. For this, let’s again analyze the process humans
    use to make decisions based on experience. This is what is called the *remember-formulate-predict
    framework*, shown in figure 1.4\. The goal of machine learning is to teach computers
    how to think in the same way, following the same framework.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了机器学习是由一系列技术组成的，我们使用这些技术让计算机根据数据做出决策。在本节中，我们将学习根据数据做出决策的含义以及一些这些技术是如何工作的。为此，让我们再次分析人类用来根据经验做出决策的过程。这就是所谓的“记住-制定-预测框架”，如图1.4所示。机器学习的目标是教会计算机以相同的方式、遵循相同的框架进行思考。
- en: How do humans think?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 人类是如何思考的？
- en: 'When we, as humans, need to make a decision based on our experience, we normally
    use the following framework:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们作为人类需要根据我们的经验做出决定时，我们通常使用以下框架：
- en: We **remember** past situations that were similar.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们**记住**过去类似的情况。
- en: We **formulate** a general rule.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们**制定**一个一般规则。
- en: We use this rule to **predict** what may happen in the future.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用这个规则来**预测**未来可能发生的事情。
- en: 'For example, if the question is, “Will it rain today?,” the process to make
    a guess is the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果问题是，“今天会下雨吗？”，做出猜测的过程如下：
- en: We **remember** that last week it rained most of the time.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们**记住**上周大部分时间都在下雨。
- en: We **formulate** that in this place, it rains most of the time.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们**制定**在这个地方，大部分时间都在下雨。
- en: We **predict** that today it will rain.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们**预测**今天会下雨。
- en: We may be right or wrong, but at least we are trying to make the most accurate
    prediction we can based on the information we have.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能对或错，但至少我们是在尝试根据我们所拥有的信息做出尽可能准确的预测。
- en: '![](../Images/1-4.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-4.png)'
- en: 'Figure 1.4 The remember-formulate-predict framework is the main framework we
    use in this book. It consists of three steps: (1) We remember previous data; (2)
    we formulate a general rule; and (3) we use that rule to make predictions about
    the future.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 记住-制定-预测框架是我们在这本书中使用的主体框架。它包括三个步骤：（1）我们记住以前的数据；（2）我们制定一个一般规则；（3）我们使用这个规则对未来做出预测。
- en: Some machine learning lingo—models and algorithms
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一些机器学习术语——模型和算法
- en: 'Before we delve into more examples that illustrate the techniques used in machine
    learning, let’s define some useful terms that we use throughout this book. We
    know that in machine learning, we get the computer to learn how to solve a problem
    using data. The way the computer solves the problem is by using the data to build
    a *model*. What is a model? We define a model as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨更多说明机器学习中使用的技术示例之前，让我们定义一些在这本书中经常使用的有用术语。我们知道在机器学习中，我们让计算机通过数据学习如何解决问题。计算机解决问题的方法是通过使用数据来构建一个*模型*。什么是模型？我们定义模型如下：
- en: model A set of rules that represent our data and can be used to make predictions
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 模型：一组规则，代表我们的数据，可以用来做出预测
- en: 'We can think of a model as a representation of reality using a set of rules
    that mimic the existing data as closely as possible. In the rain example in the
    previous section, the model was our representation of reality, which is a world
    in which it rains most of the time. This is a simple world with one rule: it rains
    most of the time. This representation may or may not be accurate, but according
    to our data, it is the most accurate representation of reality that we can formulate.
    We later use this rule to make predictions on unseen data.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将模型视为使用一组规则来模拟现实，尽可能接近地模仿现有数据。在上一个章节中关于下雨的例子中，模型是我们对现实的表示，这是一个大部分时间都在下雨的世界。这是一个只有一个规则的简单世界：大部分时间都在下雨。这种表示可能准确或不准确，但根据我们的数据，这是我们能够构建的现实的最准确表示。我们后来使用这个规则来对未见数据做出预测。
- en: 'An *algorithm* is the process that we used to build the model. In the current
    example, the process is simple: we looked at how many days it rained and realized
    it was the majority. Of course, machine learning algorithms can get much more
    complicated than that, but at the end of the day, they are always composed of
    a set of steps. Our definition of algorithm follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*算法*是我们用来构建模型的过程。在当前示例中，这个过程很简单：我们观察了多少天下雨，并意识到这是多数情况。当然，机器学习算法可能比这复杂得多，但最终，它们总是由一系列步骤组成。我们关于算法的定义如下：'
- en: algorithm A procedure, or a set of steps, used to solve a problem or perform
    a computation. In this book, the goal of an algorithm is to build a model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 算法：用于解决问题或执行计算的过程或一系列步骤。在这本书中，算法的目标是构建一个模型。
- en: In short, a model is what we use to make predictions, and an algorithm is what
    we use to build the model. Those two definitions are easy to confuse and are often
    interchanged, but to keep them clear, let’s look at a few examples.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，模型是我们用来做出预测的工具，算法是我们用来构建模型的方法。这两个定义很容易混淆，并且经常被互换使用，但为了保持它们清晰，让我们看看一些例子。
- en: Some examples of models that humans use
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 人类使用的模型的一些例子
- en: 'In this section we focus on a common application of machine learning: spam
    detection. In the following examples, we will detect spam and non-spam emails.
    Non-spam emails are also referred to as *ham*.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们关注机器学习的一个常见应用：垃圾邮件检测。在下面的例子中，我们将检测垃圾邮件和非垃圾邮件。非垃圾邮件也被称为*ham*。
- en: spam and ham *spam* is the common term used for junk or unwanted email, such
    as chain letters, promotions, and so on. The term comes from a 1972 Monty Python
    sketch in which every item in the menu of a restaurant contained Spam as an ingredient.
    Among software developers, the term *ham* is used to refer to non-spam emails.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 垃圾邮件和正常邮件*垃圾邮件*是用于垃圾邮件或不受欢迎的电子邮件的常用术语，例如连锁信件、促销等。这个术语来自1972年蒙提·派森的一个喜剧片段，其中餐厅菜单上的每一项都包含斯帕姆作为配料。在软件开发者中，术语*正常邮件*用于指非垃圾邮件。
- en: 'Example 1: An annoying email friend'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 1：一个令人烦恼的电子邮件朋友
- en: In this example, our friend Bob likes to send us email. A lot of his emails
    are spam, in the form of chain letters. We are starting to get a bit annoyed with
    him. It is Saturday, and we just got a notification of an email from Bob. Can
    we guess if this email is spam or ham without looking at it?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们的朋友鲍勃喜欢给我们发邮件。他发的大部分邮件都是垃圾邮件，形式为连锁信件。我们开始对他有点烦恼。现在是星期六，我们刚刚收到鲍勃发来的邮件通知。在不看邮件的情况下，我们能猜出这封邮件是垃圾邮件还是正常邮件吗？
- en: 'To figure this out, we use the remember-formulate-predict method. First, let
    us **remember**, say, the last 10 emails that we got from Bob. That is our data.
    We remember that six of them were spam, and the other four were ham. From this
    information, we can **formulate** the following model:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找出这一点，我们使用记住-制定-预测的方法。首先，让我们**记住**，比如说，我们从鲍勃那里收到的最后10封电子邮件。这是我们数据。我们记住其中6封是垃圾邮件，其余4封是正常邮件。从这个信息中，我们可以**制定**以下模型：
- en: '**Model 1**: Six out of every 10 emails that Bob sends us are spam.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 1**：鲍勃发送给我们的每10封电子邮件中有6封是垃圾邮件。'
- en: This rule will be our model. Note, this rule does not need to be true. It could
    be outrageously wrong. But given our data, it is the best that we can come up
    with, so we’ll live with it. Later in this book, we learn how to evaluate models
    and improve them when needed.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这条规则将成为我们的模型。请注意，这条规则不一定需要是正确的。它可能是极其错误的。但鉴于我们的数据，这是我们所能想到的最好的，所以我们将接受它。在这本书的后面部分，我们将学习如何评估模型并在需要时改进它们。
- en: Now that we have our rule, we can use it to **predict** whether the email is
    spam. If six out of 10 of Bob’s emails are spam, then we can assume that this
    new email is 60% likely to be spam and 40% likely to be ham. Judging by this rule,
    it’s a little safer to think that the email is spam. Therefore, we predict that
    the email is spam (figure 1.5).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了我们的规则，我们可以用它来**预测**邮件是否是垃圾邮件。如果鲍勃的10封电子邮件中有6封是垃圾邮件，那么我们可以假设这封新邮件有60%的可能性是垃圾邮件，40%的可能性是正常邮件。根据这个规则判断，认为这封邮件是垃圾邮件会更安全。因此，我们预测这封邮件是垃圾邮件（图1.5）。
- en: Again, our prediction may be wrong. We may open the email and realize it is
    ham. But we have made the prediction *to the best of our knowledge*. This is what
    machine learning is all about.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们的预测可能是错误的。我们打开邮件后可能会意识到它是一封正常邮件。但我们已经尽我们所能做出了预测。这正是机器学习的全部内容。
- en: You may be thinking, can we do better? We seem to be judging every email from
    Bob in the same way, but there may be more information that can help us tell the
    spam and ham emails apart. Let’s try to analyze the emails a little more. For
    example, let’s see when Bob sent the emails to see if we find a pattern.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，我们能做得更好吗？我们似乎是以相同的方式判断鲍勃的每一封电子邮件，但可能有更多的信息可以帮助我们区分垃圾邮件和正常邮件。让我们尝试更深入地分析电子邮件。例如，让我们看看鲍勃发送邮件的时间，看看是否能找到某种模式。
- en: '![](../Images/1-5.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/1-5.png)'
- en: Figure 1.5 A very simple machine learning model
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5 一个非常简单的机器学习模型
- en: 'Example 2: A seasonal annoying email friend'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 2：一个季节性的令人烦恼的电子邮件朋友
- en: 'Let’s look more carefully at the emails that Bob sent us in the previous month.
    More specifically, we’ll look at what day he sent them. Here are the emails with
    dates and information about being spam or ham:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看鲍勃上个月发送给我们的电子邮件。更具体地说，我们将查看他发送邮件的日期。以下是带有日期和垃圾邮件或正常邮件信息的电子邮件：
- en: 'Monday: Ham'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期一：正常邮件
- en: 'Tuesday: Ham'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期二：正常邮件
- en: 'Saturday: Spam'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期六：垃圾邮件
- en: 'Sunday: Spam'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期日：垃圾邮件
- en: 'Sunday: Spam'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期日：垃圾邮件
- en: 'Wednesday: Ham'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期三：正常邮件
- en: 'Friday: Ham'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期五：正常邮件
- en: 'Saturday: Spam'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期六：垃圾邮件
- en: 'Tuesday: Ham'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期二：正常邮件
- en: 'Thursday: Ham'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期四：正常邮件
- en: 'Now things are different. Can you see a pattern? It seems that every email
    Bob sent during the week is ham, and every email he sent during the weekend is
    spam. This makes sense—maybe during the week he sends us work email, whereas during
    the weekend, he has time to send spam and decides to roam free. So, we can **formulate**
    a more educated rule, or model, as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在情况不同了。你能看到某种模式吗？似乎鲍勃在星期内发送的每一封邮件都是正常邮件，而在周末发送的每一封邮件都是垃圾邮件。这很有道理——也许在工作日他发送的是工作邮件，而在周末，他有时间发送垃圾邮件，并决定自由地漫游。因此，我们可以**制定**一个更明智的规则或模型，如下所示：
- en: '**Model 2**: Every email that Bob sends during the week is ham, and those he
    sends during the weekend are spam.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 2**：鲍勃在工作日发送的每一封邮件都是正常邮件，而在周末发送的邮件都是垃圾邮件。'
- en: Now let’s look at what day it is today. If it is Sunday and we just got an email
    from Bob, then we can **predict** with great confidence that the email he sent
    is spam (figure 1.6). We make this prediction, and without looking, we send the
    email to the trash and carry on with our day.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看今天是星期几。如果今天是星期天，而我们刚刚收到了鲍勃的邮件，那么我们可以非常有信心地**预测**他发送的邮件是垃圾邮件（图 1.6）。我们做出这个预测，并且不看邮件就把它送到垃圾桶，继续我们的日子。
- en: '![](../Images/1-6.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-6.png)'
- en: Figure 1.6 A slightly more complex machine learning model
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 一个稍微复杂一些的机器学习模型
- en: 'Example 3: Things are getting complicated!'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 3：事情变得越来越复杂了！
- en: Now, let’s say we continue with this rule, and one day we see Bob in the street,
    and he asks, “Why didn’t you come to my birthday party?” We have no idea what
    he is talking about. It turns out last Sunday he sent us an invitation to his
    birthday party, and we missed it! Why did we miss it? Because he sent it on the
    weekend, and we assumed that it would be spam. It seems that we need a better
    model. Let’s go back to look at Bob’s emails—this is our **remember** step. Let’s
    see if we can find a pattern.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设我们继续使用这个规则，有一天我们在街上看到鲍勃，他问，“你为什么没来参加我的生日派对？”我们不知道他在说什么。结果上上周日他给我们发了一份生日派对的邀请，我们错过了！我们为什么错过了？因为他是在周末发的，我们假设它会是垃圾邮件。看起来我们需要一个更好的模型。让我们回到鲍勃的邮件上——这是我们**记住**的步骤。让我们看看我们是否能找到一种模式。
- en: '1 KB: Ham'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 KB：正常邮件
- en: '2 KB: Ham'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 KB：正常邮件
- en: '16 KB: Spam'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 16 KB：垃圾邮件
- en: '20 KB: Spam'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 20 KB：垃圾邮件
- en: '18 KB: Spam'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 18 KB：垃圾邮件
- en: '3 KB: Ham'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 KB：正常邮件
- en: '5 KB: Ham'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5 KB：正常邮件
- en: '25 KB: Spam'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 25 KB：垃圾邮件
- en: '1 KB: Ham'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1 KB：正常邮件
- en: '3 KB: Ham'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3 KB：正常邮件
- en: What do we see? It seems that the large emails tend to be spam, whereas the
    smaller ones tend to be ham. This makes sense, because the spam emails frequently
    have large attachments.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了什么？看起来大邮件往往是垃圾邮件，而小邮件往往是正常邮件。这很有道理，因为垃圾邮件通常有大的附件。
- en: 'So, we can **formulate** the following rule:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以**制定**以下规则：
- en: '**Model 3**: Any email of size 10 KB or larger is spam, and any email of size
    less than 10 KB is ham.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 3**：任何大小为 10 KB 或更大的邮件是垃圾邮件，任何小于 10 KB 的邮件是正常邮件。'
- en: Now that we have formulated our rule, we can make a **prediction**. We look
    at the email we received today from Bob, and the size is 19 KB. So, we conclude
    that it is spam (figure 1.7).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经制定了规则，我们可以做出**预测**。我们查看今天收到的鲍勃的邮件，大小是 19 KB。因此，我们得出结论，它是垃圾邮件（图 1.7）。
- en: '![](../Images/1-7.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-7.png)'
- en: Figure 1.7 Another slightly more complex machine learning model
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7 另一个稍微复杂一些的机器学习模型
- en: Is *this* the end of the story? Not even close.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是故事的结尾吗？远远不是。
- en: But before we keep going, notice that to make our predictions, we used the day
    of the week and the size of the email. These are examples of *features*. A feature
    is one of the most important concepts in this book.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们继续之前，请注意，为了做出我们的预测，我们使用了星期几和邮件的大小。这些都是特征的例子。特征是本书中最重要概念之一。
- en: feature Any property or characteristic of the data that the model can use to
    make predictions
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 特征 模型可以用来做出预测的数据的任何属性或特征
- en: You can imagine that there are many more features that could indicate if an
    email is spam or ham. Can you think of some more? In the next paragraphs, we’ll
    see a few more features.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象，还有很多其他特征可以用来判断一封邮件是垃圾邮件还是正常邮件。你能想到更多吗？在接下来的段落中，我们将看到更多特征。
- en: 'Example 4: More?'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 示例 4：更多？
- en: 'Our two classifiers were good, because they rule out large emails and emails
    sent on the weekends. Each one of them uses exactly one of these two features.
    But what if we wanted a rule that worked with both features? Rules like the following
    may work:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的两种分类器都很好，因为它们排除了大邮件和周末发送的邮件。每一个都恰好使用这两个特征中的一个。但如果我们想要一个同时使用这两个特征的规则呢？以下规则可能有效：
- en: '**Model 4**: If an email is larger than 10 KB or it is sent on the weekend,
    then it is classified as spam. Otherwise, it is classified as ham.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 4**：如果一封邮件的大小大于 10 KB 或者它是在周末发送的，那么它被分类为垃圾邮件。否则，它被分类为正常邮件。'
- en: '**Model 5**: If the email is sent during the week, then it must be larger than
    15 KB to be classified as spam. If it is sent during the weekend, then it must
    be larger than 5 KB to be classified as spam. Otherwise, it is classified as ham.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 5**：如果邮件是在工作日发送的，那么它的大小必须大于 15 KB 才能被分类为垃圾邮件。如果它是在周末发送的，那么它的大小必须大于 5 KB
    才能被分类为垃圾邮件。否则，它被分类为正常邮件。'
- en: Or we can get even more complicated.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 或者我们可以变得更复杂。
- en: '**Model 6**: Consider the number of the day, where Monday is 0, Tuesday is
    1, Wednesday is 2, Thursday is 3, Friday is 4, Saturday is 5, and Sunday is 6\.
    If we add the number of the day and the size of the email (in KB), and the result
    is 12 or more, then the email is classified as spam (figure 1.8). Otherwise, it
    is classified as ham.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 6**：考虑星期几的数字，其中星期一是 0，星期二是 1，星期三是 2，星期四是 3，星期五是 4，星期六是 5，星期天是 6。如果我们加上星期几和电子邮件的大小（以
    KB 计），并且结果是 12 或更多，那么电子邮件会被归类为垃圾邮件（图 1.8）。否则，它会被归类为正常邮件。'
- en: '![](../Images/1-8.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-8.png)'
- en: Figure 1.8 An even more complex machine learning model
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8 一个更复杂的机器学习模型
- en: All of these are valid models. We can keep creating more and more models by
    adding layers of complexity or by looking at even more features. Now the question
    is, which is the best model? This is where we start to need the help of a computer.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都是有效的模型。我们可以通过增加复杂层或查看更多特征来创建更多和更多的模型。现在的问题是，哪个是最好的模型？这正是我们需要计算机帮助的地方。
- en: Some examples of models that machines use
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 机器使用的模型的一些例子
- en: 'The goal is to make the computer think the way we think, namely, use the remember-formulate-predict
    framework. In a nutshell, here is what the computer does in each of the steps:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是让计算机以我们的思维方式思考，即使用记忆-制定-预测框架。简而言之，以下是计算机在每个步骤中执行的操作：
- en: '**Remember**: Look at a huge table of data.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**记住**：查看一个巨大的数据表。'
- en: '**Formulate**: Create models by going through many rules and formulas, and
    check which model fits the data best.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**制定**：通过许多规则和公式创建模型，并检查哪个模型最适合数据。'
- en: '**Predict**: Use the model to make predictions about future data.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**预测**：使用模型对未来数据进行预测。'
- en: 'This process is not much different than what we did in the previous section.
    The great advancement here is that the computer can build models quickly by going
    through many formulas and combinations of rules until it finds one that fits the
    existing data well. For example, we can build a spam classifier with features
    such as the sender, the date and time of day, the number of words, the number
    of spelling mistakes, and the appearances of certain words such as *buy* or *win*.
    A model could easily look like the following logical statement:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程与我们之前章节中做的不太一样。这里的重大进步是，计算机可以通过遍历许多公式和规则的组合，快速构建模型，直到找到一个与现有数据很好地匹配的模型。例如，我们可以构建一个具有以下特征的垃圾邮件分类器：发件人、日期和时间、单词数量、拼写错误数量，以及诸如
    *buy* 或 *win* 这样的特定单词的出现。一个模型可能看起来像以下逻辑陈述：
- en: '**Model 7**:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 7**：'
- en: If the email has two or more spelling mistakes, then it is classified as spam.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果邮件有两个或更多的拼写错误，那么它会被归类为垃圾邮件。
- en: If it has an attachment larger than 10 KB, it is classified as spam.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它有一个大于 10 KB 的附件，它会被归类为垃圾邮件。
- en: If the sender is not in our contact list, it is classified as spam.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果发件人不在我们的联系名单中，它会被归类为垃圾邮件。
- en: If it has the words *buy* and *win*, it is classified as spam.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它包含 *buy* 和 *win* 这两个词，它会被归类为垃圾邮件。
- en: Otherwise, it is classified as ham.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则，它会被归类为正常邮件。
- en: 'It could also look like the following formula:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 它也可能看起来像以下公式：
- en: '**Model 8**: If (size) + 10 (number of spelling mistakes) – (number of appearances
    of the word “mom”) + 4 (number of appearances of the word “buy”) > 10, then we
    classify the message as spam (figure 1.9). Otherwise, we classify it as ham.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型 8**：如果 (大小) + 10 (拼写错误数量) – (“mom”一词的出现次数) + 4 (“buy”一词的出现次数) > 10，那么我们将消息归类为垃圾邮件（图
    1.9）。否则，我们将其归类为正常邮件。'
- en: '![](../Images/1-9.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1-9.png)'
- en: Figure 1.9 A much more complex machine learning model, found by a computer
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9 一个由计算机发现的更复杂的机器学习模型
- en: Now the question is, which is the best rule? The quick answer is the one that
    fits the data best, although the real answer is the one that best generalizes
    to new data. At the end of the day, we
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的问题是，哪个是最好的规则？快速的答案是那个最适合数据的规则，尽管真正的答案是那个最好推广到新数据的规则。最终，我们
- en: may end up with a complicated rule, but the computer can formulate it and use
    it to make predictions quickly. Our next question is, how do we build the best
    model? That is exactly what this book is about.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会得到一个复杂的规则，但计算机可以制定它并快速使用它进行预测。我们的下一个问题是，我们如何构建最好的模型？这正是本书的主题。
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Machine learning is easy! Anyone can learn it and use it, regardless of their
    background. All that is needed is a desire to learn and great ideas to implement!
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习很简单！任何人都可以学习并使用它，无论他们的背景如何。所需的一切就是学习的愿望和伟大的实施想法！
- en: Machine learning is tremendously useful, and it is used in most disciplines.
    From science to technology to social problems and medicine, machine learning is
    making an impact and will continue doing so.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习非常有用，并且它被广泛应用于各个学科。从科学到技术，再到社会问题和医学，机器学习正在产生影响，并将继续这样做。
- en: Machine learning is common sense, done by a computer. It mimics the ways humans
    think to make decisions quickly and accurately.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习是常识，由计算机完成。它模仿人类思考的方式，以便快速且准确地做出决策。
- en: Just like humans make decisions based on experience, computers can make decisions
    based on previous data. This is what machine learning is all about.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就像人类根据经验做出决策一样，计算机可以根据之前的数据做出决策。这正是机器学习的核心所在。
- en: 'Machine learning uses the remember-formulate-predict framework, as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习使用记住-制定-预测框架，如下所示：
- en: '**Remember**: look at the previous data.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**记住**：查看之前的数据。'
- en: '**Formulate**: build a model, or a rule, based on this data.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**制定**：基于这些数据构建一个模型或规则。'
- en: '**Predict**: use the model to make predictions about future data.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测**：使用模型对未来数据进行预测。'
