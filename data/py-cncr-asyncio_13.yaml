- en: 13 Managing subprocesses
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 13 管理子进程
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了
- en: Running multiple subprocesses asynchronously
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异步运行多个子进程
- en: Handling standard output from subprocesses
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理子进程的标准输出
- en: Communicating with subprocesses using standard input
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用标准输入与子进程通信
- en: Avoiding deadlocks and other pitfalls with subprocesses
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免子进程的死锁和其他陷阱
- en: Many applications will never need to leave the world of Python. We’ll call code
    from other Python libraries and modules or use multiprocessing or multithreading
    to run Python code concurrently. However, not everything we’ll want to interact
    with is written in Python. We may have an already built application that is written
    in C++, Go, Rust, or some other language that provides better runtime characteristics
    or is simply already there for us to use without reimplementing. We may also want
    to use OS provided command-line utilities, such as GREP for searching through
    large files, cURL for making HTTP requests, or any of the numbers of applications
    we have at our disposal.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 许多应用程序可能永远不会需要离开Python的世界。我们将从其他Python库和模块中调用代码，或者使用多进程或多线程来并发运行Python代码。然而，我们想要与之交互的并不都是用Python编写的。我们可能已经有一个用C++、Go、Rust或其他语言编写的应用程序，这些语言提供了更好的运行时特性，或者它已经存在，我们无需重新实现就可以使用。我们可能还希望使用操作系统提供的命令行工具，例如GREP用于搜索大文件，cURL用于发送HTTP请求，或者我们拥有的任何数量的应用程序。
- en: In standard Python, we can use the subprocess module to run different applications
    in separate processes. Like most other Python modules, the standard subprocess
    API is blocking, making it incompatible with asyncio without multithreading or
    multiprocessing. asyncio provides a module modeled on the subprocess module to
    create and manage subprocesses asynchronously with coroutines.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准Python中，我们可以使用subprocess模块在不同的进程中运行不同的应用程序。像大多数其他Python模块一样，标准的subprocess
    API是阻塞的，这使得它在没有多线程或多进程的情况下与asyncio不兼容。asyncio提供了一个基于subprocess模块的模块，用于使用协程异步创建和管理子进程。
- en: In this chapter, we’ll learn the basics of creating and managing subprocesses
    with asyncio by running an application written in a different language. We’ll
    also learn how to handle input and output, reading standard output, and sending
    input from our application to our subprocesses.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过运行用不同语言编写的应用程序来学习使用asyncio创建和管理子进程的基础知识。我们还将学习如何处理输入和输出，读取标准输出，以及从我们的应用程序向我们的子进程发送输入。
- en: 13.1 Creating a subprocess
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.1 创建子进程
- en: Suppose you’d like to extend the functionality of an existing Python web API.
    Another team within your organization has already built the functionality you’d
    like in a command-line application for a batch processing mechanism they have,
    but there is a major problem in that the application is written in Rust. Given
    the application already exists, you don’t want to reinvent the wheel by reimplementing
    it in Python. Is there a way we can still use this application’s functionality
    within our existing Python API?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想扩展现有Python Web API的功能。你组织内的另一个团队已经为他们的批量处理机制构建了你想要的功能的命令行应用程序，但有一个主要问题，即该应用程序是用Rust编写的。鉴于应用程序已经存在，你不想通过在Python中重新实现它来重新发明轮子。我们还有没有其他方法可以在现有的Python
    API中使用这个应用程序的功能？
- en: Since this application has a command-line interface, we can use subprocesses
    to reuse this application. We’ll call the application via its command-line interface
    and run it in a separate subprocess. We can then read the results of the application
    and use it within our existing API as needed, saving us the trouble of having
    to reimplement the application.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个应用程序具有命令行界面，我们可以使用子进程来重用这个应用程序。我们将通过其命令行界面调用应用程序，并在单独的子进程中运行它。然后我们可以读取应用程序的结果，并在需要时将其用于我们现有的API中，从而避免重新实现应用程序的麻烦。
- en: 'So how do we create a subprocess and execute it? asyncio provides two coroutine
    functions out of the box to create subprocesses: `asyncio.create_subprocess_shell`
    and `asyncio.create_subprocess_exec`. Each of these coroutine functions returns
    an instance of a `Process`, which has methods to let us wait for the process to
    finish and terminate the process as well as a few others. Why are there two coroutines
    to accomplish seemingly the same task? When would we want to use one over the
    other? The `create_subprocess_shell` coroutine function creates a subprocess within
    a shell installed on the system it runs on such as `zsh` or `bash`. Generally
    speaking, you’ll want to use `create_subprocess_exec` unless you need to use functionality
    from the shell. Using the shell can have pitfalls, such as different machines
    having different shells or the same shell configured differently. This can make
    it hard to guarantee your application will behave the same on different machines.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何创建一个子进程并执行它呢？`asyncio`库提供了两个现成的协程函数来创建子进程：`asyncio.create_subprocess_shell`
    和 `asyncio.create_subprocess_exec`。这些协程函数中的每一个都返回一个 `Process` 实例，该实例具有让我们等待进程完成和终止进程的方法，以及其他一些方法。为什么有两个协程来完成看似相同的工作？我们何时会想要使用其中一个而不是另一个？`create_subprocess_shell`
    协程函数在系统上安装的 shell（如 `zsh` 或 `bash`）内部创建一个子进程。一般来说，除非你需要使用 shell 的功能，否则你会想要使用 `create_subprocess_exec`。使用
    shell 可能会有一些陷阱，比如不同的机器可能安装了不同的 shell，或者同一个 shell 的配置可能不同。这可能会使得很难保证你的应用程序在不同的机器上表现一致。
- en: To learn the basics of how to create a subprocess, let’s write an asyncio application
    to run a simple command-line program. We’ll start with the `ls` program, which
    lists the contents of the current directory to test things out, although we wouldn’t
    likely do this in the real world. If you’re running on a Windows machine, replace
    `ls` `-l` with `cmd` `/c` `dir`.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何创建子进程的基本知识，让我们编写一个 `asyncio` 应用程序来运行一个简单的命令行程序。我们将从 `ls` 程序开始，该程序列出当前目录的内容以进行测试，尽管在现实世界中我们不太可能这样做。如果你在
    Windows 机器上运行，请将 `ls -l` 替换为 `cmd /c dir`。
- en: Listing 13.1 Running a simple command in a subprocess
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.1 在子进程中运行简单命令
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the preceding listing, we create a `Process` instance to run the `ls` command
    with `create_subprocess_exec`. We can also specify other arguments to pass to
    the program by adding them after. Here we pass in `-l`, which adds some extra
    information around who created the files in the directory. Once we’ve created
    the process, we print out the process ID and then call the `wait` coroutine. This
    coroutine will wait until the process finishes, and once it does it will return
    the subprocesses status code; in this case it should be zero. By default, standard
    output from our subprocess will be piped to standard output of our own application,
    so when you run this you should see something like the following, differing based
    in what you have in your directory:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的列表中，我们使用 `create_subprocess_exec` 创建了一个 `Process` 实例来运行 `ls` 命令。我们还可以通过添加其他参数来指定传递给程序的参数。这里我们传递了
    `-l`，这会在目录中创建文件的创建者周围添加一些额外的信息。一旦我们创建了进程，我们就打印出进程 ID，然后调用 `wait` 协程。这个协程将等待进程完成，一旦完成，它将返回子进程的状态码；在这种情况下应该是零。默认情况下，子进程的标准输出将被管道传输到我们自己的应用程序的标准输出，所以当你运行这个程序时，你应该会看到以下类似的内容，具体取决于你的目录内容：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that the `wait` coroutine will block until the application terminates,
    and there are no guarantees as to how long a process will take to terminate, let
    alone if it will terminate at all. If you’re concerned about a runaway process,
    you’ll need to introduce a timeout with `asyncio.wait_for`. There is a caveat
    to this, however. Recall that `wait_ for` will terminate the coroutine that it
    is running if it times out. You may assume that this will terminate the process,
    but it does not. It only terminates the task that is waiting for the process to
    finish, and not the underlying process.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`wait` 协程将阻塞直到应用程序终止，而且没有任何保证关于进程将花费多长时间终止，更不用说是否真的会终止。如果你担心一个失控的进程，你需要使用
    `asyncio.wait_for` 引入超时。然而，这里有一个注意事项。回想一下，如果超时，`wait_for` 将终止它正在运行的协程。你可能认为这将终止进程，但实际上它不会。它只终止等待进程完成的任务，而不是底层进程。
- en: 'We’ll need a better way to shut down the process when it times out. Luckily,
    `Process` has two methods that can help us out in this situation: `terminate`
    and `kill`. The `terminate` method will send the `SIGTERM` signal to the subprocess,
    and kill will send the `SIGKILL` signal. Note that both these methods are not
    coroutines and are also non-blocking. They just send the signal. If you want to
    try and get the return code once you’ve terminated the subprocess or you want
    to wait for any cleanup, you’ll need to call `wait` again.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个更好的方法来在超时时关闭进程。幸运的是，`Process`有两个方法可以帮助我们在这个情况下：`terminate`和`kill`。`terminate`方法会向子进程发送`SIGTERM`信号，而`kill`会发送`SIGKILL`信号。请注意，这两个方法都不是协程，并且是非阻塞的。它们只是发送信号。如果你想在终止子进程后尝试获取返回代码，或者你想等待任何清理，你需要再次调用`wait`。
- en: Let’s test out terminating a long-running application with the `sleep` command
    line application (for Windows users, replace `'sleep',` `'3'` with the more complicated
    `'cmd',` `'start',` `'/wait',` `'timeout',` `'3'`). We’ll create a subprocess
    that sleeps for a few seconds and try to terminate it before it has a chance to
    finish.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下使用`sleep`命令行应用程序（对于Windows用户，将`'sleep',` `'3'`替换为更复杂的`'cmd',` `'start',`
    `'/wait',` `'timeout',` `'3'`）终止长时间运行的应用程序。我们将创建一个睡眠几秒钟的子进程，并尝试在它有机会完成之前终止它。
- en: Listing 13.2 Terminating a subprocess
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.2 终止子进程
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the preceding listing, we create a subprocess that will take 3 seconds to
    complete but wrap it in a `wait_for` with a 1-second timeout. After 1 second,
    `wait_for` will throw a `TimeoutError`, and in the `except` block we terminate
    the process and wait for it to finish, printing out its status code. This should
    give us output similar to the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的列表中，我们创建了一个需要3秒钟才能完成的子进程，但用`wait_for`包装了它，并设置了1秒的超时。1秒后，`wait_for`将抛出`TimeoutError`，在`except`块中我们将终止进程并等待它完成，打印出其状态码。这应该会给出类似于以下输出：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: One thing to watch out for when writing your own code is the `wait` inside of
    the `except` block still has a chance of taking a long time, and you may want
    to wrap this in a `wait_for` if this is a concern.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写自己的代码时需要注意的一点是，`except`块中的`wait`仍然有可能花费很长时间，如果你对此有顾虑，你可能需要将其包装在`wait_for`中。
- en: 13.1.1 Controlling standard output
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.1 控制标准输出
- en: In the previous examples, the standard output of our subprocess went directly
    to our application’s standard output. What if we don’t want this behavior? Perhaps
    we want to do additional processing on the output, or maybe the output is inconsequential,
    and we can safely ignore it. The `create_subprocess_exec` coroutine has a `stdout`
    parameter that let us specify where we want standard output to go. This parameter
    takes in an `enum` that lets us specify if we want to redirect the subprocess’s
    output to our own standard output, pipe it to a `StreamReader`, or ignore it entirely
    by redirecting it to `/dev/null`.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们的子进程的标准输出直接流向了应用程序的标准输出。如果我们不希望这种行为呢？也许我们想在输出上做额外的处理，或者也许输出并不重要，我们可以安全地忽略它。`create_subprocess_exec`协程有一个`stdout`参数，允许我们指定标准输出应该去哪里。这个参数接受一个`enum`，允许我们指定是否要将子进程的输出重定向到我们自己的标准输出，将其管道传输到`StreamReader`，或者通过将其重定向到`/dev/null`完全忽略它。
- en: Let’s say we’re planning to run multiple subprocesses concurrently and echo
    their output. We’d like to know which subprocess generated the output to avoid
    confusion. To make this output easier to read, we’ll add some extra data about
    which subprocess generated the output before writing it to our application’s standard
    output. We’ll prepend the command that generated the output before printing it
    out.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们计划并发运行多个子进程并回显它们的输出。我们想知道哪个子进程生成了输出以避免混淆。为了使输出更容易阅读，我们将在将其写入应用程序的标准输出之前添加一些关于哪个子进程生成了输出的额外数据。我们将在打印之前将生成输出的命令添加到前面。
- en: To do this, the first thing we’ll need to do is set the `stdout` parameter to
    `asyncio .subprocess.PIPE`. This tells the subprocess to create a new `StreamReader`
    instance we can use to read output from the process. We can then access this stream
    reader with the `Proccess.stdout` field. Let’s try this with our `ls` `-la` command.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，我们首先需要将`stdout`参数设置为`asyncio .subprocess.PIPE`。这告诉子进程创建一个新的`StreamReader`实例，我们可以使用它来读取进程的输出。然后我们可以通过`Proccess.stdout`字段访问这个流读取器。让我们用我们的`ls`
    `-la`命令试一试。
- en: Listing 13.3 Using the standard output stream reader
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.3 使用标准输出流读取器
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the preceding listing, we first create a coroutine `write_output` to prepend
    a prefix to output from a stream reader line by line. Then, in our main coroutine,
    we create a subprocess specifying we want to pipe `stdout`. We also create a task
    to run `write_output`, passing in the process’s standard output stream reader,
    and run this concurrently with `wait`. When running this, you’ll see the output
    prepended with the command:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的列表中，我们首先创建了一个协程 `write_output`，它逐行将前缀添加到流读取器的输出。然后，在我们的主协程中，我们创建了一个子进程，指定我们想要管道
    `stdout`。我们还创建了一个任务来运行 `write_output`，传入进程的标准输出流读取器，并与 `wait` 并发运行。当运行这个时，你会看到输出前添加了以下命令：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: One crucial aspect of using pipes, and dealing with subprocesses input and output
    in general, is that they are susceptible to deadlocks. The `wait` coroutine is
    especially susceptible to this if our subprocess generates a lot of output, and
    we don’t properly consume it. To demonstrate this, let’s look at a simple example
    by generating a Python application that writes a lot of data to standard output
    and flushes it all at once.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用管道处理的一个关键方面，以及处理子进程的输入和输出，是它们容易发生死锁。如果我们的子进程生成大量输出，而我们没有正确地消耗它，`wait` 协程尤其容易受到这种影响。为了演示这一点，让我们通过生成一个将大量数据写入标准输出并一次性刷新的
    Python 应用程序来查看一个简单的示例。
- en: Listing 13.4 Generating a lot of output
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.4 生成大量输出
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The preceding listing writes `Hello` `there!!` to the standard output buffer
    1,000,000 times and flushes it all at once. Let’s see what happens if we use a
    pipe with this application but don’t consume the data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的列表将 `Hello` `there!!` 写入标准输出缓冲区 1,000,000 次，并一次性刷新它。让我们看看如果我们使用管道与这个应用程序，但不消耗数据会发生什么。
- en: Listing 13.5 A deadlock with pipes
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.5 管道导致的死锁
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If you run the preceding listing, you’ll see the process `pid` printed out and
    then nothing more. The application will hang forever, and you’ll need to forcefully
    terminate it. If this does not happen on your system, simply increase the number
    of times we output data in the output application, and you’ll eventually run into
    the problem.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行前面的列表，你会看到打印出进程 `pid`，然后就没有更多内容了。应用程序将永远挂起，你需要强制终止它。如果你的系统没有发生这种情况，只需增加输出应用程序中输出数据的次数，你最终会遇到这个问题。
- en: Our application seems simple enough, so why are we running into this deadlock?
    The issue lies in how the stream reader’s buffer works. When the stream reader’s
    buffer fills up, any more calls to write into it block until more space in the
    buffer becomes available. While our stream reader buffer is blocked because its
    buffer is full, our process is still trying to finish writing its large output
    to the stream reader. This makes our process dependent on the stream reader becoming
    unblocked, but the stream reader will never become unblocked because we never
    free up any space in the buffer. This is a circular dependency and therefore a
    deadlock.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的应用程序看起来很简单，那么为什么我们会遇到这个死锁呢？问题在于流读取器的缓冲区是如何工作的。当流读取器的缓冲区填满时，任何更多的写入调用都会阻塞，直到缓冲区中有更多空间。当我们的流读取器缓冲区因为缓冲区已满而阻塞时，我们的进程仍在尝试将大量输出写入流读取器。这使得我们的进程依赖于流读取器变得未阻塞，但流读取器永远不会变得未阻塞，因为我们从未释放缓冲区中的任何空间。这是一个循环依赖，因此是一个死锁。
- en: Previously, we avoided this issue entirely by reading from the standard output
    stream reader concurrently as we were waiting for the process to finish. This
    meant that even if the buffer filled, we would drain it such that the process
    wouldn’t block indefinitely waiting to write additional data. When dealing with
    pipes, you’ll need to be careful about consuming stream data, so you don’t run
    into deadlocks.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们通过在等待进程完成的同时从标准输出流读取器并发读取来完全避免这个问题。这意味着即使缓冲区满了，我们也会将其排空，这样进程就不会无限期地等待写入更多数据。在处理管道时，你需要小心处理流数据，以免遇到死锁。
- en: You can also address this issue by avoiding use of the `wait` coroutine. In
    addition, the `Process` class has another coroutine method called `communicate`
    that avoids deadlocks entirely. This coroutine blocks until the subprocess completes
    and concurrently consumes standard output and standard error, returning the output
    complete once the application finishes. Let’s adapt our previous example to use
    `communicate` to fix the issue.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过避免使用 `wait` 协程来解决这个问题。此外，`Process` 类还有一个名为 `communicate` 的协程方法，它可以完全避免死锁。这个协程会阻塞，直到子进程完成，并并发地消耗标准输出和标准错误，一旦应用程序完成，就返回完整的输出。让我们修改之前的示例，使用
    `communicate` 来解决这个问题。
- en: Listing 13.6 Using communicate
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.6 使用 communicate
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: When you run the preceding listing, you’ll see all the application’s output
    printed to the console all at once (and `None` printed once, since we didn’t write
    anything to standard output). Internally, `communicate` creates a few tasks that
    constantly read output from standard output and standard error into an internal
    buffer, thus, avoiding any deadlock issues. While we avoid potential deadlocks,
    we have a serious drawback in that we can’t interactively process output from
    standard output. If you’re in a situation in which you need to react to output
    from an application (perhaps you need to terminate when you encounter a certain
    message or spawn another task), you’ll need to use `wait`, but be careful to read
    output from your stream reader appropriately to avoid deadlocks.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行前面的列表时，你会看到所有应用程序的输出一次性打印到控制台（并且打印一次 `None`，因为我们没有写入任何内容到标准输出）。内部，`communicate`
    创建了一些任务，这些任务会不断地从标准输出和标准错误读取输出到内部缓冲区，从而避免了任何死锁问题。虽然我们避免了潜在的死锁，但我们有一个严重的缺点，那就是我们无法交互式地处理标准输出的输出。如果你处于需要响应应用程序输出的情况（可能需要在你遇到某些消息时终止，或者启动另一个任务），你需要使用
    `wait`，但要注意适当地从你的流读取器读取输出，以避免死锁。
- en: An additional drawback is that communicate buffers *all* the data from standard
    output and standard input in memory. If you’re working with a subprocess that
    could produce a large amount of data, you run the risk of running out of memory.
    We’ll see how to address these shortcomings in the next section.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个缺点是 `communicate` 会将标准输出和标准输入的所有数据缓冲在内存中。如果你正在处理一个可能会产生大量数据的子进程，你可能会面临内存不足的风险。我们将在下一节中看到如何解决这些缺点。
- en: 13.1.2 Running subprocesses concurrently
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 13.1.2 并发运行子进程
- en: Now that we know the basics of creating, terminating, and reading output from
    subprocesses, it is added with our existing knowledge to run multiple applications
    concurrently. Let’s imagine we need to encrypt multiple pieces of text that we
    have in memory, and for security purposes we’d like to use the Twofish cipher
    algorithm. This algorithm isn’t supported by the `hashlib` module, so we’ll need
    an alternative. We can use the `gpg` (short for GNU Privacy Guard, which is a
    free software replacement of PGP [pretty good privacy]) command-line application.
    You can download gpg at [https://gnupg.org/download/](https://gnupg.org/download/).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了创建、终止和从子进程中读取输出的基础知识，我们可以将这些知识添加到我们的现有知识中，以并发运行多个应用程序。让我们想象一下，我们需要加密内存中存储的多个文本片段，出于安全考虑，我们希望使用
    Twofish 加密算法。这个算法不被 `hashlib` 模块支持，因此我们需要一个替代方案。我们可以使用 `gpg`（代表 GNU Privacy Guard，它是
    PGP [相当好的隐私] 的免费软件替代品）命令行应用程序。您可以从 [https://gnupg.org/download/](https://gnupg.org/download/)
    下载 gpg。
- en: 'First, let’s define the command we’ll want to use for our encryption. We can
    use gpg by defining a passcode and setting an algorithm with command line parameters.
    Then, it is a matter of echoing text to the application. For example, to encrypt
    the text “encrypt this!”, we can run the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义我们将要使用的加密命令。我们可以通过定义一个密码并使用命令行参数设置一个算法来使用 gpg。然后，只需要将文本回显到应用程序即可。例如，为了加密文本“encrypt
    this!”，我们可以运行以下命令：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This should produce encrypted output to standard output similar to the following:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该在标准输出产生加密输出，类似于以下内容：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This will work on our command line, but it won’t work if we’re using `create_
    subprocess_exec`, since we won’t have the `|` pipe operator available (`create_
    subprocess_shell` will work if you truly need a pipe). So how can we pass in the
    text we want to encrypt? In addition to allowing us to pipe standard output and
    standard error, `communicate` and `wait` let us pipe in standard input as well.
    The `communicate` coroutine also lets us specify input bytes when we start the
    application. If we’ve piped standard input when we created our process, these
    bytes will get sent to the application. This will work nicely for us; we’ll simply
    pass the string we want to encrypt with the `communicate` coroutine.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在我们的命令行中工作，但如果我们在使用 `create_subprocess_exec`，则不会工作，因为我们不会有 `|` 管道操作符可用（如果你确实需要管道，`create_subprocess_shell`
    将会工作）。那么我们如何传递我们想要加密的文本呢？除了允许我们将标准输出和标准错误管道化外，`communicate` 和 `wait` 还允许我们将标准输入管道化。`communicate`
    协程还允许我们在启动应用程序时指定输入字节。如果我们创建进程时已经管道化了标准输入，这些字节将被发送到应用程序。这对我们来说将非常合适；我们只需通过 `communicate`
    协程传递我们想要加密的字符串即可。
- en: Let’s try this out by generating random pieces of text and encrypting them concurrently.
    We’ll create a list of 100 random text strings with 1,000 characters each and
    run `gpg` on each of them concurrently.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过生成随机文本并对其进行并发加密来尝试一下。我们将创建一个包含100个随机文本字符串的列表，每个字符串有1,000个字符，并对它们中的每一个进行并发运行`gpg`。
- en: Listing 13.7 Encrypting text concurrently
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.7 并发加密文本
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the preceding listing, we define a coroutine called `encrypt` that creates
    a gpg process and sends in the text we want to encrypt with `communicate`. For
    simplicity, we just return the standard output result and don’t do any error handling;
    in a real-world application you’d likely want to be more robust here. Then, in
    our main coroutine we create a list of random text and create an `encrypt` task
    for each piece of text. We then run them all concurrently with `gather` and print
    out the total runtime and encrypted bits of text. You can compare the concurrent
    runtime with the synchronous runtime by putting `await` in front of `asyncio.create_task`
    and removing the `gather`, and you should see a reasonable speedup.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的列表中，我们定义了一个名为`encrypt`的协程，它创建一个gpg进程，并通过`communicate`发送我们想要加密的文本。为了简单起见，我们只返回标准输出结果，并不进行任何错误处理；在实际应用中你可能会希望这里更健壮。然后，在我们的主协程中，我们创建一个随机文本列表并为每篇文本创建一个`encrypt`任务。然后我们使用`gather`并发运行它们，并打印出总运行时间和加密的文本位数。你可以通过在`asyncio.create_task`前放置`await`并移除`gather`来比较并发运行时间和同步运行时间，你应该会看到合理的加速。
- en: In this listing, we only had 100 pieces of text. What if we had thousands or
    more? Our current code takes 100 pieces of text and tries to encrypt them all
    concurrently; this means that we create 100 processes at the same time. This poses
    a challenge because our machines are resource constrained, and one process could
    eat up a lot of memory. In addition, spinning up hundreds or thousands of processes
    creates nontrivial context-switching overhead.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个列表中，我们只有100篇文本。如果我们有数千篇甚至更多呢？我们当前的代码会处理100篇文本并尝试并发加密它们；这意味着我们同时创建100个进程。这提出了一个挑战，因为我们的机器资源有限，一个进程可能会消耗大量内存。此外，启动数百或数千个进程会创建非平凡的上下文切换开销。
- en: 'In our case we have another wrinkle caused by gpg, since it relies on shared
    state to encrypt data. If you take the code in listing 13.7 and increase the number
    of pieces of text into the thousands, you’ll likely start to see the following
    printed to standard error:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，由于gpg依赖于共享状态来加密数据，所以我们遇到了另一个问题。如果你将列表13.7中的代码中的文本数量增加到数千，你可能会开始看到以下内容打印到标准错误：
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: So not only have we created a lot of processes and all the overhead associated
    with that, but we’ve also created processes that are actually blocked on shared
    state that gpg needs. So how can we limit the number of processes running to circumvent
    this issue? This is a perfect example of when a semaphore comes in handy. Since
    our work is CPU-bound, adding a semaphore to limit the number of processes to
    the number of CPU cores we have available makes sense. Let’s try this out by using
    a semaphore that is limited to the number of CPU cores on our system and encrypting
    1,000 pieces of text to see if this can improve our performance.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们不仅创建了许多进程以及与之相关的所有开销，而且还创建了实际上被gpg需要的共享状态所阻塞的进程。那么我们如何限制运行进程的数量以规避这个问题呢？这是一个当信号量派上用场时的完美例子。由于我们的工作是CPU密集型的，添加一个信号量来限制进程数量到我们可用的CPU核心数是有意义的。让我们通过使用限制在我们系统CPU核心数上的信号量来加密1,000篇文本，看看这能否提高我们的性能。
- en: Listing 13.8 Subprocesses with a semaphore
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 列表13.8 使用信号量的子进程
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Comparing this with the runtime of 1,000 pieces of text with an unbounded set
    of subprocesses you should see some performance improvement, alongside a reduction
    in memory usage. You might think this is similar to what we saw in chapter 6 with
    a `ProcessPoolExecutor`’s concept of maximum workers, and you’d be correct. Internally,
    a `ProcessPoolExecutor` uses a semaphore to manage how many processes run concurrently.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 将此与具有无界子进程集的1,000篇文本的运行时间进行比较，你应该会看到一些性能提升，同时内存使用量也会减少。你可能会认为这与我们在第6章中看到的`ProcessPoolExecutor`的最大工作者概念类似，而且你是对的。内部，`ProcessPoolExecutor`使用信号量来管理同时运行多少个进程。
- en: We’ve now seen the basics around creating, terminating, and running multiple
    subprocesses concurrently. Next, we’ll take a look at how to communicate with
    subprocesses in a more interactive manner.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经看到了创建、终止和并发运行多个子进程的基本知识。接下来，我们将探讨如何以更交互式的方式与子进程进行通信。
- en: 13.2 Communicating with subprocesses
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13.2 与子进程通信
- en: Up to this point, we’ve been using one-way, noninteractive communication with
    processes. But what if we’re working with an application that may require user
    input? For example, we may be asked for a passphrase, username, or any other number
    of inputs.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在使用单向、非交互式通信与进程进行通信。但如果我们正在处理可能需要用户输入的应用程序怎么办？例如，我们可能被要求输入密码短语、用户名或其他多种输入。
- en: In the case in which we know we only have one piece of input to deal with, using
    `communicate` is ideal. We saw this previously using gpg to send in text to encrypt,
    but let’s try it when the subprocess explicitly asks for input. We’ll first create
    a simple Python program to ask for a username and echo it to standard output.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们知道我们只需要处理一条输入的情况下，使用 `communicate` 是理想的。我们之前使用 gpg 发送要加密的文本时看到了这一点，但现在让我们尝试当子进程明确请求输入时。我们首先创建一个简单的
    Python 程序来请求用户名并将其回显到标准输出。
- en: Listing 13.9 Echoing user input
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.9 回显用户输入
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, we can use `communicate` to input the username.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 `communicate` 来输入用户名。
- en: Listing 13.10 Using communicate with standard input
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.10 使用 communicate 与标准输入
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When we run this code, we’ll see `b'Please` `enter` `a` `username:` `Your` `username`
    `is` `Zoot\n'` printed to the console, as our application terminates right after
    our first user input. This won’t work if we have a more interactive application.
    For example, take this application, which repeatedly asks for user input and echoes
    it until the user types `quit`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行此代码时，我们将在控制台看到打印出 `b'Please` `enter` `a` `username:` `Your` `username`
    `is` `Zoot\n'`，因为我们的应用程序在第一次用户输入后立即终止。如果我们有一个更交互式的应用程序，这将不起作用。例如，考虑这个应用程序，它反复请求用户输入并回显输入，直到用户输入
    `quit`。
- en: Listing 13.11 An echo application
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.11 一个回显应用程序
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Since `communicate` waits until the process terminates, we’ll need to use `wait`
    and process standard output and standard input concurrently. The `Process` class
    exposes `StreamWriter` in a `stdin` field we can use when we’ve set standard input
    to `PIPE`. We can use this concurrently with the standard output `StreamReader`
    to handle these types of applications. Let’s see how to do this with the following
    listing, where we’ll create an application to write a few pieces of text to our
    subprocess.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `communicate` 等待进程终止，我们需要使用 `wait` 并并发处理标准输出和标准输入。`Process` 类在 `stdin` 字段中公开
    `StreamWriter`，我们可以在将标准输入设置为 `PIPE` 时使用它。我们可以与此标准输出 `StreamReader` 并发使用来处理这些类型的应用程序。让我们通过以下列表看看如何做到这一点，我们将创建一个应用程序向我们的子进程写入一些文本。
- en: Listing 13.12 Using the echo application with subprocesses
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.12 使用回显应用程序与子进程
- en: '[PRE17]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In the preceding listing, we define a `consume_and_send` coroutine that reads
    standard output until we receive the expected message for a user to specify input.
    Once we’ve received this message, we dump the data to our own application’s standard
    output and write the strings in `''text_list''` to standard input. We repeat this
    until we’ve sent all data into our subprocess. When we run this, we should see
    all of our output was sent to our subprocess and properly echoed:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的列表中，我们定义了一个 `consume_and_send` 协程，它读取标准输出，直到我们收到用户指定输入的预期消息。一旦我们收到这个消息，我们就将数据转储到我们自己的应用程序的标准输出，并将
    `'text_list'` 中的字符串写入标准输入。我们重复此操作，直到将所有数据发送到我们的子进程。当我们运行这个程序时，我们应该看到所有的输出都发送到了我们的子进程，并且得到了适当的回显：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The application we’re currently running has the luxury of producing deterministic
    output and stopping at deterministic points to ask for input. This makes managing
    standard output and standard input relatively straightforward. What if the application
    we’re running in a subprocess only asks for input sometimes or could write a lot
    of data before asking for input? Let’s adapt our sample echo program to be a bit
    more complicated. We’ll have it echo user input between 1 and 10 times randomly,
    and we’ll `sleep` for a half second between each echo.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们目前正在运行的应用程序有产生确定性输出并在确定性点停止以请求输入的便利。这使得管理标准输出和标准输入相对简单。如果我们正在子进程中运行的应用程序有时才请求输入或可能在请求输入之前写入大量数据怎么办？让我们将我们的示例回显程序调整为更复杂一些。我们将使其随机回显用户输入
    1 到 10 次，并在每次回显之间 `sleep` 半秒。
- en: Listing 13.13 A more complex echo application
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.13 一个更复杂的回显应用程序
- en: '[PRE19]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: If we run this application as a subprocess with a similar approach to listing
    13.12, it will work because we’re still deterministic in that we eventually ask
    for input with a known piece of text. However, the drawback of using this approach
    is that our code to read from standard output and write to standard input is strongly
    coupled. This combined with increasing complexity of our input/output logic can
    make the code hard to follow and maintain.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们以与列表 13.12 类似的方式将此应用程序作为子进程运行，它将工作，因为我们仍然具有确定性，我们最终会以已知文本请求输入。然而，使用这种方法的一个缺点是我们的从标准输出读取和写入标准输入的代码紧密耦合。这加上我们输入/输出逻辑的日益复杂，可能会使代码难以理解和维护。
- en: We can address this by decoupling reading standard output from writing data
    to standard input, thus, separating the concerns of reading standard output and
    writing to standard input. We’ll create one coroutine to read standard output
    and one coroutine to write text to standard input. Our coroutine that reads standard
    output will set an event once it has received the input prompt we expect. Our
    coroutine that writes to standard input will wait for that event to be set, then
    once it is, it will write the specified text. We’ll then take these two coroutines
    and run them concurrently with `gather`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过解耦读取标准输出与写入标准输入的数据，从而分离读取标准输出和写入标准输入的职责。我们将创建一个协程来读取标准输出，并创建另一个协程来将文本写入标准输入。我们的标准输出读取协程在接收到预期的输入提示后，将设置一个事件。我们的标准输入写入协程将等待该事件被设置，一旦设置，它将写入指定的文本。然后我们将这两个协程通过`gather`并发运行。
- en: Listing 13.14 Decoupling output reading from input writing
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 13.14 解耦输出读取与输入写入
- en: '[PRE20]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In the preceding listing, we first define an `output_consumer` coroutine function.
    This function takes in an `input_ready` event as well as a `StreamReader` that
    will reference standard output and reads from standard output until we encounter
    the text `Enter` `text` `to` `echo:`. Once we see this text, we know that the
    standard input of our subprocess is ready to accept input, so we set the `input_ready`
    event.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的列表中，我们首先定义了一个`output_consumer`协程函数。这个函数接收一个`input_ready`事件以及一个将引用标准输出的`StreamReader`，并从标准输出读取，直到我们遇到文本`Enter`
    `text` `to` `echo:`。一旦我们看到这个文本，我们就知道我们的子进程的标准输入已经准备好接受输入，因此我们设置`input_ready`事件。
- en: 'Our `input_writer` coroutine function iterates over our input list and waits
    on our event for standard input to become ready. Once standard input is ready,
    we write out our input and clear the event so that on the next iteration of our
    `for` loop we’ll block until standard input becomes ready again. With this implementation
    we now have two coroutine functions, each with one clear responsibility: one to
    write to standard input and one to read to standard output, increasing the readability
    and maintainability of our code.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`input_writer`协程函数遍历我们的输入列表，并等待我们的事件，直到标准输入准备好。一旦标准输入准备好，我们写入我们的输入并清除事件，这样在`for`循环的下一个迭代中，我们将阻塞，直到标准输入再次准备好。通过这种实现，我们现在有两个协程函数，每个函数都有一个明确的职责：一个用于写入标准输入，一个用于读取标准输出，这增加了我们代码的可读性和可维护性。
- en: Summary
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: We can use asyncio’s subprocess module to launch subprocesses asynchronously
    with `create_subprocess_shell` and `create_subprocess_exec`. Whenever possible,
    prefer `create_subprocess_exec`, as it ensures consistent behavior across machines.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用`asyncio`的子进程模块通过`create_subprocess_shell`和`create_subprocess_exec`异步启动子进程。尽可能使用`create_subprocess_exec`，因为它确保了跨机器的一致行为。
- en: By default, output from subprocesses will go to our own application’s standard
    output. If we need to read and interact with standard input and standard output,
    we’ll need to configure them to pipe to `StreamReader` and `StreamWriter` instances.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，子进程的输出将流向我们自己的应用程序的标准输出。如果我们需要读取和交互标准输入和标准输出，我们需要将它们配置为通过管道连接到`StreamReader`和`StreamWriter`实例。
- en: When we pipe standard output or standard error, we need to be careful to consume
    output. If we don’t, we could deadlock our application.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们管道标准输出或标准错误时，我们需要小心消费输出。如果我们不这样做，我们可能会使我们的应用程序陷入死锁。
- en: When we have a large amount of subprocesses to run concurrently, semaphores
    can make sense to avoid abusing system resources and creating unneeded contention.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们同时运行大量子进程时，信号量可以合理地避免滥用系统资源和不必要的竞争。
- en: We can use the `communicate` coroutine method to send input to standard input
    on a subprocess.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用`communicate`协程方法向子进程的标准输入发送输入。
