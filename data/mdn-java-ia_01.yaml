- en: Part 2\. Functional-style data processing with streams
  id: totrans-0
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二部分。使用流的函数式数据处理
- en: The second part of this book is a deep exploration of the new Streams API, which
    lets you write powerful code that processes a collection of data in a declarative
    way. By the end of this second part, you’ll have a full understanding of what
    streams are and how you can use them in your codebase to process a collection
    of data concisely and efficiently.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书第二部分深入探讨了新的Streams API，它允许你以声明式的方式编写处理数据集合的强大代码。到第二部分的结尾，你将全面理解流是什么以及你如何在代码库中使用它们来简洁高效地处理数据集合。
- en: '[Chapter 4](kindle_split_015.xhtml#ch04) introduces the concept of a stream
    and explains how it compares with a collection.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](kindle_split_015.xhtml#ch04)介绍了流的定义，并解释了它与集合的比较。'
- en: '[Chapter 5](kindle_split_016.xhtml#ch05) investigates in detail the stream
    operations available to express sophisticated data-processing queries. You’ll
    look at many patterns such as filtering, slicing, finding, matching, mapping,
    and reducing.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[第5章](kindle_split_016.xhtml#ch05)详细调查了可用于表达复杂数据处理查询的流操作。你将查看许多模式，如过滤、切片、查找、匹配、映射和归约。'
- en: '[Chapter 6](kindle_split_017.xhtml#ch06) covers collectors—a feature of the
    Streams API that lets you express even more complex data-processing queries.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](kindle_split_017.xhtml#ch06)介绍了收集器——Streams API的一个特性，它允许你表达更复杂的数据处理查询。'
- en: In [chapter 7](kindle_split_018.xhtml#ch07), you’ll learn about how streams
    can automatically run in parallel and leverage your multicore architectures. In
    addition, you’ll learn about various pitfalls to avoid when using parallel streams
    correctly and effectively.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](kindle_split_018.xhtml#ch07)中，你将了解流如何自动并行运行并利用你的多核架构。此外，你还将了解在使用并行流时需要避免的各种陷阱。
- en: Chapter 4\. Introducing streams
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4章。流的介绍
- en: '*This chapter covers*'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: What is a stream?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是流？
- en: Collections versus streams
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集合与流
- en: Internal versus external iteration
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内部迭代与外部迭代
- en: Intermediate versus terminal operations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中间操作与终端操作
- en: 'What would you do without collections in Java? Nearly every Java application
    *makes* and *processes* collections. Collections are fundamental to many programming
    tasks: they let you group and process data. To illustrate collections in action,
    imagine you are tasked to create a collection of dishes to represent a menu to
    calculate different queries. For example, you may want to find out the total number
    of calories for the menu. Or, you may need to filter the menu to select only low-calorie
    dishes for a special healthy menu. But despite collections being necessary for
    almost any Java application, manipulating collections is far from perfect:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 没有集合的Java你会做什么？几乎每个Java应用程序都会*创建*和*处理*集合。集合对于许多编程任务来说是基本的：它们允许你分组和处理数据。为了说明集合的实际应用，假设你被要求创建一个代表菜单的菜肴集合以计算不同的查询。例如，你可能想计算出菜单的总卡路里。或者，你可能需要过滤菜单以选择仅包含低卡路里菜肴的特殊健康菜单。但尽管集合对于几乎任何Java应用程序都是必要的，但操作集合远非完美：
- en: 'Much business logic entails database-like operations such as *grouping* a list
    of dishes by category (for example, all vegetarian dishes) or *finding* the most
    expensive dish. How many times do you find yourself re-implementing these operations
    using iterators? Most databases let you specify such operations declaratively.
    For example, the following SQL query lets you select (or “filter”) the names of
    dishes that are low in calories: `SELECT name FROM dishes WHERE calorie < 400`.
    As you can see, in SQL you don’t need to implement *how* to filter using the `calorie`
    attribute of a dish (as you would with Java collections, for example, using an
    iterator and an accumulator). Instead, you write *what* you want as result. This
    basic idea means that you worry less about how to explicitly implement such queries—it’s
    handled for you! Why can’t you do something similar with collections?'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多业务逻辑涉及类似数据库的操作，例如按类别（例如，所有素食菜肴）*分组*菜肴列表或*查找*最昂贵的菜肴。你发现自己多少次需要使用迭代器重新实现这些操作？大多数数据库都允许你声明式地指定此类操作。例如，以下SQL查询允许你选择（或“过滤”）卡路里低的菜肴名称：`SELECT
    name FROM dishes WHERE calorie < 400`。正如你所看到的，在SQL中，你不需要实现使用菜肴的`calorie`属性（例如，使用Java集合，例如使用迭代器和累加器）来过滤的方式。相反，你只需写出你想要的结果。这个基本想法意味着你不必过多担心如何显式地实现此类查询——它为你处理了！为什么你不能用类似的方法处理集合？
- en: How would you process a large collection of elements? To gain performance you’d
    need to process it in parallel and use multicore architectures. But writing parallel
    code is complicated in comparison to working with iterators. In addition, it’s
    no fun to debug!
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你会如何处理大量元素？为了提高性能，你需要并行处理它并使用多核架构。但是，与使用迭代器相比，编写并行代码更复杂。此外，调试起来也没有乐趣！
- en: 'What could the Java language designers do to save your precious time and make
    your life as programmers easier? You may have guessed: the answer is *streams*.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Java 语言设计者能做些什么来节省你宝贵的时间，并使你的编程生活更轻松？你可能已经猜到了：答案是 *流*。
- en: 4.1\. What are streams?
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 什么是流？
- en: '*Streams* are an update to the Java API that let you manipulate collections
    of data in a declarative way (you express a query rather than code an ad hoc implementation
    for it). For now you can think of them as fancy iterators over a collection of
    data. In addition, streams can be processed in parallel *transparently*, without
    you having to write any multithreaded code! We explain in detail in [chapter 7](kindle_split_018.xhtml#ch07)
    how streams and parallelization work. To see the benefits of using streams, compare
    the following code to return the names of dishes that are low in calories, sorted
    by number of calories—first in Java 7 and then in Java 8 using streams. Don’t
    worry about the Java 8 code too much; we explain it in detail in the next sections!'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*流* 是 Java API 的一个更新，它允许你以声明式的方式操作数据集合（你表达一个查询而不是为它编写特定的实现）。现在你可以把它们想象成数据集合上的高级迭代器。此外，流可以透明地并行处理，而不需要你编写任何多线程代码！我们将在
    [第 7 章](kindle_split_018.xhtml#ch07) 中详细解释流和并行化是如何工作的。要看到使用流的好处，比较以下代码返回低卡路里菜肴的名称，按卡路里数量排序——首先是
    Java 7，然后是使用流的 Java 8。不必太担心 Java 8 的代码；我们将在下一节中详细解释它！'
- en: 'Before (Java 7):'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在 (Java 7) 之前：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '***1* Filters the elements using an accumulator**'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 使用累加器过滤元素**'
- en: '***2* Sorts the dishes with an anonymous class**'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 使用匿名类对菜肴进行排序**'
- en: '***3* Processes the sorted list to select the names of dishes**'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 处理排序后的列表以选择菜肴的名称**'
- en: In this code you use a “garbage variable,” `lowCaloricDishes`. Its only purpose
    is to act as an intermediate throwaway container. In Java 8, this implementation
    detail is pushed into the library where it belongs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，你使用了一个“垃圾变量”，`lowCaloricDishes`。它的唯一目的是作为一个中间的临时容器。在 Java 8 中，这个实现细节被推入库中，属于它应该去的地方。
- en: 'After (Java 8):'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在 (Java 8) 之后：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '***1* Selects dishes that are below 400 calories**'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 选择卡路里低于 400 的菜肴**'
- en: '***2* Sorts them by calories**'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 按卡路里排序**'
- en: '***3* Extracts the names of these dishes**'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 提取这些菜肴的名称**'
- en: '***4* Stores all the names in a List**'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 将所有名称存储在列表中**'
- en: 'To exploit a multicore architecture and execute this code in parallel, you
    need only to change `stream()` to `parallelStream()`:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要利用多核架构并行执行此代码，你只需要将 `stream()` 改为 `parallelStream()`：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You may be wondering what exactly happens when you invoke the method `parallelStream`.
    How many threads are being used? What are the performance benefits? Should you
    use this method at all? [Chapter 7](kindle_split_018.xhtml#ch07) covers these
    questions in detail. For now, you can see that the new approach offers several
    immediate benefits from a software engineering point of view:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道当你调用 `parallelStream` 方法时会发生什么。使用了多少线程？性能有什么好处？你是否应该使用这个方法？[第 7 章](kindle_split_018.xhtml#ch07)
    详细介绍了这些问题。现在，你可以看到从软件工程的角度来看，这种方法提供了几个立即的好处：
- en: 'The code is written in a *declarative way*: you specify *what* you want to
    achieve (*filter* dishes that are *low* in calories) as opposed to specifying
    *how* to implement an operation (using control-flow blocks such as loops and `if`
    conditions). As you saw in the previous chapter, this approach, together with
    behavior parameterization, enables you to cope with changing requirements: you
    could easily create an additional version of your code to filter high-calorie
    dishes using a lambda expression, without having to copy and paste code. Another
    way to think about the benefit of this approach is that the threading model is
    decoupled from the query itself. Because you are providing a recipe for a query,
    it could be executed sequentially or in parallel. You will learn more about this
    in [chapter 7](kindle_split_018.xhtml#ch07).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码以*声明式*方式编写：你指定*想要实现什么*（过滤*低卡路里*的菜品）而不是指定*如何实现操作*（使用控制流块，如循环和`if`条件）。正如你在上一章中看到的，这种方法，加上行为参数化，使你能够应对不断变化的需求：你可以轻松地创建代码的附加版本，使用lambda表达式过滤高卡路里菜品，而无需复制和粘贴代码。关于这种方法的好处，另一种思考方式是线程模型与查询本身解耦。因为你提供了一个查询的配方，它可以是顺序执行或并行执行。你将在[第7章](kindle_split_018.xhtml#ch07)中了解更多关于这一点。
- en: You chain together several building-block operations to express a complicated
    data-processing pipeline (you chain the `filter` by linking `sorted`, `map`, and
    `collect` operations, as illustrated in [figure 4.1](#ch04fig01)) while keeping
    your code readable and its intent clear. The result of the `filter` is passed
    to the `sorted` method, which is then passed to the `map` method and then to the
    `collect` method.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你将把几个构建块操作链接起来，以表达一个复杂的数据处理管道（通过链接`sorted`、`map`和`collect`操作来链接`filter`，如图4.1所示），同时保持代码的可读性和意图清晰。`filter`的结果传递给`sorted`方法，然后传递给`map`方法，最后传递给`collect`方法。
- en: Figure 4.1\. Chaining stream operations forming a stream pipeline
  id: totrans-35
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.1\. 连接流操作形成流管道
- en: '![](Images/04fig01_alt.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig01_alt.jpg)'
- en: 'Because operations such as `filter` (or `sorted`, `map`, and `collect`) are
    available as *high-level building blocks* that don’t depend on a specific threading
    model, their internal implementation could be single-threaded or could potentially
    maximize your multicore architecture transparently! In practice, this means you
    no longer have to worry about threads and locks to figure out how to parallelize
    certain data processing tasks: the Streams API does it for you!'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因为`filter`（或`sorted`、`map`和`collect`）等操作作为*高级构建块*可用，它们不依赖于特定的线程模型，它们的内部实现可以是单线程的，也可以潜在地透明地最大化你的多核架构！在实践中，这意味着你不再需要担心线程和锁来弄清楚如何并行化某些数据处理任务：Streams
    API会为你完成这一切！
- en: 'The new Streams API is expressive. For example, after reading this chapter
    and [chapters 5](kindle_split_016.xhtml#ch05) and [6](kindle_split_017.xhtml#ch06),
    you’ll be able to write code like the following:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 新的 Streams API 表达力强。例如，阅读完本章以及[第5章](kindle_split_016.xhtml#ch05)和[第6章](kindle_split_017.xhtml#ch06)后，你将能够编写如下代码：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This particular example is explained in detail in [chapter 6](kindle_split_017.xhtml#ch06).
    It groups dishes by their types inside a `Map`. For example, the `Map` may contain
    the following result:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个特定的例子在[第6章](kindle_split_017.xhtml#ch06)中有详细解释。它在一个`Map`内部按类型分组菜品。例如，`Map`可能包含以下结果：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now consider how you’d implement this with the typical imperative programming
    approach using loops. But don’t waste too much of your time. Instead, embrace
    the power of streams in this and the following chapters!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑如何使用典型的命令式编程方法（使用循环）来实现这一点。但不要浪费太多时间。相反，拥抱本章和以下章节中流的强大功能！
- en: '|  |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Other libraries: Guava, Apache, and lambdaj**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**其他库：Guava、Apache 和 lambdaj**'
- en: There have been many attempts at providing Java programmers with better libraries
    to manipulate collections. For example, Guava is a popular library created by
    Google. It provides additional container classes such as multimaps and multisets.
    The Apache Commons Collections library provides similar features. Finally, lambdaj,
    written by Mario Fusco, coauthor of this book, provides many utilities to manipulate
    collections in a declarative manner, inspired by functional programming.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了给Java程序员提供更好的库来操作集合，已经进行了许多尝试。例如，Guava是由Google创建的一个流行的库。它提供了额外的容器类，如multimaps和multisets。Apache
    Commons Collections库提供了类似的功能。最后，由本书的合著者Mario Fusco编写的lambdaj提供了许多在声明式编程中操作集合的实用工具，灵感来源于函数式编程。
- en: Now, Java 8 comes with its own official library for manipulating collections
    in a more declarative style.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Java 8自带了一个官方库，用于以更声明性的方式操作集合。
- en: '|  |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: To summarize, the Streams API in Java 8 lets you write code that’s
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，Java 8的Streams API允许你编写代码，使其
- en: '***Declarative*—** More concise and readable'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***声明性*—** 更简洁、更易读'
- en: '***Composable*—** Greater flexibility'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***可组合*—** 更大的灵活性'
- en: '***Parallelizable*—** Better performance'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***可并行化*—** 更好的性能'
- en: 'For the remainder of this chapter and the next, we’ll use the following domain
    for our examples: a `menu` that’s nothing more than a list of dishes'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分和下一章中，我们将使用以下领域作为我们的示例：一个`menu`，它不过是一个菜肴列表
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: where a `Dish` is an immutable class defined as
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，一个`Dish`是一个不可变的类，定义为
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We’ll now explore how you can use the Streams API in more detail. We’ll compare
    streams to collections and provide some background. In the next chapter, we’ll
    investigate in detail the stream operations available to express sophisticated
    data processing queries. We’ll look at many patterns such as filtering, slicing,
    finding, matching, mapping, and reducing. There will be many quizzes and exercises
    to try to solidify your understanding.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将更详细地探索如何使用Streams API。我们将比较流和集合，并提供一些背景信息。在下一章中，我们将详细研究可用于表达复杂数据处理查询的流操作。我们将查看许多模式，如过滤、切片、查找、匹配、映射和归约。将有许多测验和练习来帮助你巩固理解。
- en: Next, we’ll discuss how you can create and manipulate numeric streams (for example,
    to generate a stream of even numbers or Pythagorean triples). Finally, we’ll discuss
    how you can create streams from different sources, such as from a file. We’ll
    also discuss how to generate streams with an infinite number of elements—something
    you definitely can’t do with collections!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论如何创建和操作数值流（例如，生成偶数流或毕达哥拉斯三元组流）。最后，我们将讨论如何从不同的源创建流，例如从文件中创建流。我们还将讨论如何生成具有无限元素数量的流——这是你绝对不能使用集合完成的！
- en: 4.2\. Getting started with streams
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 开始使用流
- en: We start our discussion of streams with collections, because that’s the simplest
    way to begin working with streams. Collections in Java 8 support a new `stream`
    method that returns a stream (the interface definition is available in `java.util.stream.Stream`).
    You’ll later see that you can also get streams in various other ways (for example,
    generating stream elements from a numeric range or from I/O resources).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从集合开始讨论流，因为这是开始使用流的最简单方式。Java 8中的集合支持一个新的`stream`方法，该方法返回一个流（接口定义在`java.util.stream.Stream`中）。你稍后会发现，你还可以以各种其他方式获取流（例如，从数值范围或I/O资源生成流元素）。
- en: 'First, what exactly is a *stream*? A short definition is “a sequence of elements
    from a source that supports data-processing operations.” Let’s break down this
    definition step-by-step:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，什么是*流*？一个简短的定义是“从支持数据处理操作的数据源中获取元素序列。”让我们一步一步地分解这个定义：
- en: '***Sequence of elements*—** Like a collection, a stream provides an interface
    to a sequenced set of values of a specific element type. Because collections are
    data structures, they’re mostly about storing and accessing elements with specific
    time/space complexities (for example, an `ArrayList` versus a `LinkedList`). But
    streams are about expressing computations such as `filter`, `sorted`, and `map`,
    which you saw earlier. Collections are about data; streams are about computations.
    We explain this idea in greater detail in the coming sections.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***元素序列*—** 与集合一样，流提供了一个接口，用于访问特定元素类型的有序值集。因为集合是数据结构，所以它们主要关于存储和访问具有特定时间/空间复杂性的元素（例如，`ArrayList`与`LinkedList`）。但流是关于表达计算，如`filter`、`sorted`和`map`，这些你之前已经看到。集合关于数据；流关于计算。我们将在接下来的章节中更详细地解释这个概念。'
- en: '***Source*—** Streams consume from a data-providing source such as collections,
    arrays, or I/O resources. Note that generating a stream from an ordered collection
    preserves the ordering. The elements of a stream coming from a list will have
    the same order as the list.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***源*—** 流从数据提供源（如集合、数组或I/O资源）中消费。请注意，从有序集合生成流会保留顺序。来自列表的流元素将具有与列表相同的顺序。'
- en: '***Data-processing operations*—** Streams support database-like operations
    and common operations from functional programming languages to manipulate data,
    such as `filter`, `map`, `reduce`, `find`, `match`, `sort`, and so on. Stream
    operations can be executed either sequentially or in parallel.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***数据处理操作*—** 流支持类似数据库的操作和函数式编程语言中的常见操作来操作数据，例如`filter`、`map`、`reduce`、`find`、`match`、`sort`等。流操作可以顺序执行或并行执行。'
- en: 'In addition, stream operations have two important characteristics:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，流操作有两个重要的特性：
- en: '***Pipelining*—** Many stream operations return a stream themselves, allowing
    operations to be chained to form a larger pipeline. This enables certain optimizations
    that we explain in the next chapter, such as *laziness* and *short-circuiting*.
    A pipeline of operations can be viewed as a database-like query on the data source.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***管道化*—** 许多流操作返回一个流本身，允许操作被链式连接以形成一个更大的管道。这使我们能够进行某些优化，我们将在下一章中解释，例如*惰性*和*短路*。操作管道可以看作是对数据源的一个类似数据库的查询。'
- en: '***Internal iteration*—** In contrast to collections, which are iterated explicitly
    using an iterator, stream operations do the iteration behind the scenes for you.
    We briefly mentioned this idea in [chapter 1](kindle_split_011.xhtml#ch01) and
    will return to it later in the next section.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***内部迭代*—** 与显式使用迭代器迭代集合不同，流操作在幕后为你进行迭代。我们曾在[第1章](kindle_split_011.xhtml#ch01)中简要提到过这个概念，将在下一节中再次讨论。'
- en: 'Let’s look at a code example to explain all of these ideas:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个代码示例来解释所有这些概念：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '***1* Gets a stream from menu (the list of dishes)**'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 从菜单（菜肴列表）获取流**'
- en: '***2* Creates a pipeline of operations: first filter high-calorie dishes**'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 创建一个操作管道：首先过滤高卡路里菜肴**'
- en: '***3* Gets the names of the dishes**'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 获取菜肴的名称**'
- en: '***4* Selects only the first three**'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 仅选择前三个**'
- en: '***5* Stores the results in another List**'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 将结果存储在另一个列表中**'
- en: '***6* Gives results [pork, beef, chicken]**'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 结果为[pork, beef, chicken]**'
- en: 'In this example, you first get a stream from the list of dishes by calling
    the `stream` method on `menu`. The *data source* is the list of dishes (the menu)
    and it provides *a sequence of elements* to the stream. Next, you apply a series
    of *data-processing operations* on the stream: `filter`, `map`, `limit`, and `collect`.
    All these operations except `collect` return another stream so they can be connected
    to form a *pipeline*, which can be viewed as a query on the source. Finally, the
    `collect` operation starts processing the pipeline to return a result (it’s different
    because it returns something other than a stream—here, a `List`). No result is
    produced, and indeed no element from `menu` is even selected, until `collect`
    is invoked. You can think of it as if the method invocations in the chain are
    queued up until `collect` is called. [Figure 4.2](#ch04fig02) shows the sequence
    of stream operations: `filter`, `map`, `limit`, and `collect`, each of which is
    briefly described here:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，你首先通过在`menu`上调用`stream`方法从菜肴列表中获取一个流。数据源是菜肴列表（菜单），它为流提供了一系列元素。接下来，你在流上应用一系列数据处理操作：`filter`、`map`、`limit`和`collect`。除了`collect`之外，所有这些操作都返回另一个流，因此可以将它们连接起来形成一个*管道*，这可以看作是对源的一个查询。最后，`collect`操作开始处理管道以返回一个结果（它与流不同，因为它返回了其他东西——这里是一个`List`）。在没有调用`collect`之前，不会产生任何结果，实际上甚至没有从`menu`中选择任何元素。你可以将其视为链中的方法调用在`collect`被调用之前排队。[图4.2](#ch04fig02)显示了流操作的顺序：`filter`、`map`、`limit`和`collect`，下面将简要描述每个操作：
- en: '**`filter`—** Takes a lambda to exclude certain elements from the stream. In
    this case, you select dishes that have more than 300 calories by passing the lambda
    `d -> d.getCalories() > 300`.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`filter`—** 接受一个lambda表达式来排除流中的某些元素。在这种情况下，你通过传递lambda表达式`d -> d.getCalories()
    > 300`选择卡路里超过300的菜肴。'
- en: '**`map`—** Takes a lambda to transform an element into another one or to extract
    information. In this case, you extract the name for each dish by passing the method
    reference `Dish::getName`, which is equivalent to the lambda `d -> d.getName()`.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`map`—** 接受一个lambda表达式将一个元素转换成另一个元素或提取信息。在这种情况下，你通过传递方法引用`Dish::getName`（相当于lambda表达式`d
    -> d.getName()`）提取每个菜肴的名称。'
- en: '**`limit`—** Truncates a stream to contain no more than a given number of elements.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`limit`—** 截断流，使其包含不超过给定数量的元素。'
- en: '**`collect`—** Converts a stream into another form. In this case you convert
    the stream into a list. It looks like a bit of magic; we’ll describe how `collect`
    works in more detail in [chapter 6](kindle_split_017.xhtml#ch06). At the moment,
    you can see `collect` as an operation that takes as an argument various recipes
    for accumulating the elements of a stream into a summary result. Here, `toList()`
    describes a recipe for converting a stream into a list.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`collect`—** 将流转换为另一种形式。在这种情况下，您将流转换为列表。这看起来有点像魔法；我们将在第 6 章中更详细地描述 `collect`
    的工作原理。目前，您可以将 `collect` 视为一个操作，它接受各种将流元素累积到汇总结果中的方法作为参数。在这里，`toList()` 描述了一个将流转换为列表的方法。'
- en: Figure 4.2\. Filtering a menu using a stream to find out three high-calorie
    dish names
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.2\. 使用流过滤菜单以找出三个高热量菜品的名称
- en: '![](Images/04fig02_alt.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig02_alt.jpg)'
- en: 'Notice how the code we described is different than what you’d write if you
    were to process the list of menu items step-by-step. First, you use a much more
    declarative style to process the data in the menu where you say *what* needs to
    be done: “Find names of three high-calorie dishes.” You don’t implement the filtering
    (`filter`), extracting (`map`), or truncating (`limit`) functionalities; they’re
    available through the Streams library. As a result, the Streams API has more flexibility
    to decide how to optimize this pipeline. For example, the filtering, extracting,
    and truncating steps could be merged into a single pass and stop as soon as three
    dishes are found. We show an example to demonstrate that in the next chapter.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们描述的代码与您逐个处理菜单项列表时的代码有何不同。首先，您使用一种更声明性的风格来处理菜单中的数据，您说的是“需要做什么”： “找出三个高热量菜品的名称。”
    您没有实现过滤（`filter`）、提取（`map`）或截断（`limit`）功能；这些功能通过 Streams 库提供。因此，Streams API 具有更多的灵活性来决定如何优化这个管道。例如，过滤、提取和截断步骤可以合并为单次遍历，并在找到三个菜品后立即停止。我们将在下一章中展示一个示例来证明这一点。
- en: Let’s stand back a little and examine the conceptual differences between the
    Collections API and the new Streams API before we explore in more detail what
    operations you can perform with a stream.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们更详细地探讨如何使用流进行操作之前，让我们稍微退后一步，来检查 Collections API 和新的 Streams API 之间的概念差异。
- en: 4.3\. Streams vs. collections
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 流与集合的比较
- en: Both the existing Java notion of collections and the new notion of streams provide
    interfaces to data structures representing a sequenced set of values of the element
    type. By *sequenced*, we mean that we commonly step through the values in turn
    rather than randomly accessing them in any order. What’s the difference?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的 Java 集合概念和新的流概念都提供了表示元素类型值的有序集合的数据结构的接口。通过 *有序*，我们是指我们通常按顺序遍历值，而不是以任何顺序随机访问它们。那么区别在哪里呢？
- en: We’ll start with a visual metaphor. Consider a movie stored on a DVD. This is
    a collection (perhaps of bytes or of frames—we don’t care which here) because
    it contains the whole data structure. Now consider watching the same video when
    it’s being *streamed* over the internet. This is now a stream (of bytes or frames).
    The streaming video player needs to have downloaded only a few frames in advance
    of where the user is watching, so you can start displaying values from the beginning
    of the stream before most of the values in the stream have even been computed
    (consider streaming a live football game). Note particularly that the video player
    may lack the memory to buffer the whole stream in memory as a collection—and the
    startup time would be appalling if you had to wait for the final frame to appear
    before you could start showing the video. You might choose for video-player implementation
    reasons to *buffer* a part of a stream into a collection, but this is distinct
    from the conceptual difference.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一种视觉隐喻开始。考虑一个存储在 DVD 上的电影。这是一个集合（可能是字节或帧——这里我们不在乎是哪一个），因为它包含了整个数据结构。现在考虑当它通过互联网
    *流式传输* 时观看相同的视频。现在这是一个流（字节或帧）。流式视频播放器只需要下载用户正在观看之前的一小部分帧，这样您就可以在流中的大多数值甚至还没有被计算出来之前，从流的开始处显示值（考虑流式传输一场实时足球比赛）。请注意，视频播放器可能没有足够的内存来将整个流作为集合缓冲在内存中——如果您必须等待最后一帧出现才能开始显示视频，启动时间将会令人难以置信。出于视频播放器实现的考虑，您可能会选择
    *缓冲* 流的一部分到集合中，但这与概念上的差异是不同的。
- en: In coarsest terms, the difference between collections and streams has to do
    with *when* things are computed. A collection is an in-memory data structure that
    holds *all* the values the data structure currently has—every element in the collection
    has to be computed before it can be added to the collection. (You can add things
    to, and remove them from, the collection, but at each moment in time, every element
    in the collection is stored in memory; elements have to be computed before becoming
    part of the collection.)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在最粗略的层面上，集合和流之间的区别在于**何时**进行计算。集合是一个内存中的数据结构，它持有数据结构当前拥有的**所有**值——集合中的每个元素在可以添加到集合之前都必须被计算。（你可以向集合中添加东西，也可以从中移除东西，但在这个时间点的每个时刻，集合中的每个元素都存储在内存中；元素在成为集合的一部分之前必须被计算。）
- en: 'By contrast, a stream is a conceptually fixed data structure (you can’t add
    or remove elements from it) whose elements are *computed on demand*. This gives
    rise to significant programming benefits. In [chapter 6](kindle_split_017.xhtml#ch06),
    we’ll show how simple it is to construct a stream containing all the prime numbers
    (2, 3, 5, 7, 11, . . .) even though there are an infinite number of them. The
    idea is that a user will extract only the values they require from a stream and
    these elements are produced—invisibly to the user—only *as* and *when* required.
    This is a form of a producer-consumer relationship. Another view is that a stream
    is like a lazily constructed collection: values are computed when they’re solicited
    by a consumer (in management speak this is demand-driven, or even just-in-time,
    manufacturing).'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，流是一个概念上固定的数据结构（你不能从中添加或删除元素），其元素是**按需计算**的。这带来了显著的编程优势。在[第6章](kindle_split_017.xhtml#ch06)中，我们将展示如何构建一个包含所有素数（2，3，5，7，11，……）的流是多么简单，尽管素数的数量是无限的。其理念是，用户将只从流中提取他们所需的价值，这些元素仅在**需要时**和**需要时**产生——对用户来说是隐形的。这是一种生产者-消费者关系的形式。另一种观点是，流就像是一个懒加载的集合：当消费者请求时，值才会被计算（用管理术语来说，这是需求驱动，甚至可以说是即时制造）。
- en: 'In contrast, a collection is eagerly constructed (supplier-driven: fill your
    warehouse before you start selling, like a Christmas novelty that has a limited
    life). Imagine applying this to the primes example. Attempting to construct a
    collection of all prime numbers would result in a program loop that forever computes
    a new prime—adding it to the collection—but could never finish making the collection,
    so the consumer would never get to see it.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，集合是积极构建的（供应商驱动：在你开始销售之前先填满你的仓库，就像一个有限寿命的圣诞新品），想象一下将其应用于素数示例。尝试构建一个包含所有素数的集合会导致一个程序循环，它永远在计算一个新的素数——将其添加到集合中——但永远不会完成构建集合，因此消费者永远不会看到它。
- en: '[Figure 4.3](#ch04fig03) illustrates the difference between a stream and a
    collection, applied to our DVD versus internet streaming example.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '[图4.3](#ch04fig03)说明了流和集合之间的区别，应用于我们的DVD与互联网流媒体示例。'
- en: Figure 4.3\. Streams versus collections
  id: totrans-91
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图4.3. 流与集合的比较
- en: '![](Images/04fig03_alt.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/04fig03_alt.jpg)'
- en: Another example is a browser internet search. Suppose you search for a phrase
    with many matches in Google or in an e-commerce online shop. Instead of waiting
    for the whole collection of results along with their photographs to be downloaded,
    you get a stream whose elements are the best 10 or 20 matches, along with a button
    to click for the next 10 or 20\. When you, the consumer, click for the next 10,
    the supplier computes these on demand, before returning them to your browser for
    display.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是浏览器互联网搜索。假设你在谷歌或在线电商商店中搜索一个有很多匹配项的短语。你不需要等待整个结果集及其照片下载完成，而是会得到一个流，其元素是最佳的前10个或20个匹配项，还有一个按钮可以点击来获取下一个10个或20个。当你，作为消费者，点击获取下一个10个时，供应商会根据需求计算这些结果，然后再将它们返回到你的浏览器进行显示。
- en: 4.3.1\. Traversable only once
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1. 只能遍历一次
- en: 'Note that, similarly to iterators, a stream can be traversed only once. After
    that a stream is said to be consumed. You can get a new stream from the initial
    data source to traverse it again as you would for an iterator (assuming it’s a
    repeatable source like a collection; if it’s an I/O channel, you’re out of luck).
    For example, the following code would throw an exception indicating the stream
    has been consumed:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，与迭代器类似，流也只能遍历一次。之后，流就被认为是已经被消费了。你可以从初始数据源获取一个新的流来再次遍历，就像迭代器一样（假设它是一个可重复的源，如集合；如果它是一个I/O通道，你就无能为力了）。例如，以下代码会抛出一个异常，表明流已经被消费：
- en: '[PRE8]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '***1* Prints each word in the title**'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 打印标题中的每个单词**'
- en: '***2* java.lang.IllegalStateException: stream has already been operated upon
    or closed**'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* java.lang.IllegalStateException: 流已被操作或关闭**'
- en: Keep in mind that you can consume a stream only once!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，流只能消费一次！
- en: '|  |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Streams and collections philosophically**'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**流与集合的哲学**'
- en: For readers who like philosophical viewpoints, you can see a stream as a set
    of values spread out in time. In contrast, a collection is a set of values spread
    out in space (here, computer memory), which all exist at a single point in time—and
    which you access using an iterator to access members inside a `for-each` loop.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于喜欢哲学观点的读者，你可以将流视为在时间上分散的一组值。相比之下，集合是一组在空间（在此处为计算机内存）上分散的值，它们在时间上的一个点上存在——并且你可以使用迭代器通过
    `for-each` 循环访问集合内部的成员。
- en: '|  |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Another key difference between collections and streams is how they manage the
    iteration over data.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 集合和流之间的另一个关键区别是它们如何管理数据迭代。
- en: 4.3.2\. External vs. internal iteration
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2\. 外部迭代与内部迭代
- en: Using the `Collection` interface requires iteration to be done by the user (for
    example, using `for-each`); this is called *external iteration*. The Streams library,
    by contrast, uses *internal iteration*—it does the iteration for you and takes
    care of storing the resulting stream value somewhere; you merely provide a function
    saying what’s to be done. The following code listings illustrate this difference.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `Collection` 接口需要用户进行迭代（例如，使用 `for-each`）；这被称为*外部迭代*。相比之下，Streams 库使用*内部迭代*——它为你执行迭代并负责将结果流值存储在某个地方；你只需提供一个函数，说明要做什么。以下代码示例说明了这种区别。
- en: 'Listing 4.1\. Collections: external iteration with a `for-each` loop'
  id: totrans-107
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.1\. 集合：使用 `for-each` 循环的外部迭代
- en: '[PRE9]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '***1* Explicitly iterates the list of menu sequentially**'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 显式顺序迭代菜单列表**'
- en: '***2* Extracts the name and adds it to an accumulator**'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 提取名称并将其添加到累加器中**'
- en: Note that the `for-each` hides some of the iteration complexity. The `for-each`
    construct is syntactic sugar that translates into something much uglier using
    an `Iterator` object.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`for-each` 隐藏了一些迭代复杂性。`for-each` 结构是语法糖，它通过使用 `Iterator` 对象转换为更丑陋的代码。
- en: 'Listing 4.2\. Collections: external iteration using an iterator behind the
    scenes'
  id: totrans-112
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.2\. 集合：使用迭代器进行的外部迭代
- en: '[PRE10]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '***1* Iterates explicitly**'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 显式迭代列表**'
- en: 'Listing 4.3\. Streams: internal iteration'
  id: totrans-115
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 4.3\. 流：内部迭代
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '***1* Parameterizes map with the getName method to extract the name of a dish**'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 使用 `getName` 方法参数化地图以提取菜肴的名称**'
- en: '***2* Starts executing the pipeline of operations; no iteration**'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 开始执行操作管道；没有迭代**'
- en: 'Let’s use an analogy to understand the differences and benefits of internal
    iteration. Let’s say you’re talking to your two-year-old daughter, Sofia, and
    want her to put her toys away:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个类比来理解内部迭代的差异和好处。假设你正在和你两岁的女儿索菲亚交谈，并希望她把玩具收起来：
- en: 'You: “Sofia, let’s put the toys away. Is there a toy on the ground?”'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你：“索菲亚，让我们把玩具收起来。地上有玩具吗？”
- en: 'Sofia: “Yes, the ball.”'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索菲亚：“是的，球。”
- en: 'You: “Okay, put the ball in the box. Is there something else?”'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你：“好吧，把球放进盒子里。还有别的东西吗？”
- en: 'Sofia: “Yes, there’s my doll.”'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索菲亚：“是的，我的娃娃在这里。”
- en: 'You: “Okay, put the doll in the box. Is there something else?”'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你：“好吧，把娃娃放进盒子里。还有别的东西吗？”
- en: 'Sofia: “Yes, there’s my book.”'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索菲亚：“是的，我的书。”
- en: 'You: “Okay, put the book in the box. Is there something else?”'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你：“好吧，把书放进盒子里。还有别的东西吗？”
- en: 'Sofia: “No, nothing else.”'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索菲亚：“没有，没有别的东西。”
- en: 'You: “Fine, we’re finished.”'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你：“好的，我们完成了。”
- en: 'This is exactly what you do every day with your Java collections. You iterate
    a collection *externally*, explicitly pulling out and processing the items one
    by one. It would be far better if you could tell Sofia, “Put all the toys that
    are on the floor inside the box.” There are two other reasons why an internal
    iteration is preferable: first, Sofia could choose to take the doll with one hand
    and the ball with the other at the same time, and second, she could decide to
    take the objects closest to the box first and then the others. In the same way,
    using an internal iteration, the processing of items could be transparently done
    in parallel or in a different order that may be more optimized. These optimizations
    are difficult if you iterate the collection externally as you’re used to doing
    in Java. This may seem like nit-picking, but it’s much of the raison-d’être of
    Java 8’s introduction of streams. The internal iteration in the Streams library
    can automatically choose a data representation and implementation of parallelism
    to match your hardware. By contrast, once you’ve chosen external iteration by
    writing `for-each`, then you’ve committed to self-manage any parallelism. (*Self-managing*
    in practice means either “one fine day we’ll parallelize this” or “starting the
    long and arduous battle involving tasks and `synchronized`.”) Java 8 needed an
    interface like `Collection` but without iterators, ergo `Stream`! [Figure 4.4](#ch04fig04)
    illustrates the difference between a stream (internal iteration) and a collection
    (external iteration).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是你每天在使用 Java 集合时所做的。你外部迭代一个集合，明确地逐个取出并处理项目。如果能够告诉索菲亚，“把地板上的所有玩具都放进盒子里。”那就好多了。还有两个其他原因说明为什么内部迭代更可取：首先，索菲亚可以选择用一只手拿娃娃，另一只手拿球，其次，她可以决定先拿离盒子最近的对象，然后再拿其他的。同样，使用内部迭代，项目的处理可以透明地并行进行或以不同的顺序进行，这可能会更优化。如果你像在
    Java 中那样外部迭代集合，这些优化就变得很困难。这看起来可能是在吹毛求疵，但这是 Java 8 引入流的主要原因之一。Streams 库中的内部迭代可以自动选择数据表示和并行实现的实现，以匹配你的硬件。相比之下，一旦你通过编写
    `for-each` 来选择外部迭代，那么你就承诺了自行管理任何并行性。（在实践中，“自行管理”意味着“某天我们会并行化这个”或“开始涉及任务和 `synchronized`
    的漫长而艰巨的战斗。”）Java 8 需要一个像 `Collection` 这样的接口，但没有迭代器，因此有 `Stream`！[图 4.4](#ch04fig04)
    展示了流（内部迭代）和集合（外部迭代）之间的差异。
- en: Figure 4.4\. Internal versus external iteration
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.4\. 内部迭代与外部迭代
- en: '![](Images/04fig04_alt.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig04_alt.jpg)'
- en: We’ve described the conceptual differences between collections and streams.
    Specifically, streams make use of internal iteration, where a library takes care
    of iterating for you. But this is useful only if you have a list of predefined
    operations to work with (for example, `filter` or `map`) that hide the iteration.
    Most of these operations take lambda expressions as arguments so you can parameterize
    their behavior as we showed in the previous chapter. The Java language designers
    shipped the Streams API with an extensive list of operations you can use to express
    complicated data processing queries. We’ll briefly look at this list of operations
    now and explore them in more detail with examples in the next chapter. To check
    your understanding of external versus internal iteration, try quiz 4.1 below.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经描述了集合和流之间的概念差异。具体来说，流使用内部迭代，其中库为你处理迭代。但这只有在你有预定义的操作列表（例如，`filter` 或 `map`）来处理时才有用，这些操作隐藏了迭代。这些操作中的大多数都接受
    lambda 表达式作为参数，因此你可以像我们在上一章中展示的那样参数化它们的行为。Java 语言设计者提供了 Streams API，其中包含了一长串你可以用来表达复杂数据处理查询的操作。我们现在将简要地查看这个操作列表，并在下一章通过示例进行更详细的探索。为了检查你对外部迭代和内部迭代的理解，尝试下面的
    4.1 测试题。
- en: '|  |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Quiz 4.1: External vs. internal iteration**'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**测试题 4.1：外部迭代与内部迭代**'
- en: Based on what you learned about external iteration in [listing 4.1](#ch04ex01)
    and [4.2](#ch04ex02), which stream operation would you use to refactor the following
    code?
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 [列表 4.1](#ch04ex01) 和 [4.2](#ch04ex02) 中关于外部迭代的学习，你会使用哪个流操作来重构以下代码？
- en: '[PRE12]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Answer:** You need to use the `filter` pattern'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**你需要使用 `filter` 模式'
- en: '[PRE13]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Don’t worry if you’re still unfamiliar with how to precisely write a stream
    query, you will learn this in more detail in the next chapter.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对如何精确地编写流查询还不熟悉，不要担心，你将在下一章中详细了解这一点。
- en: '|  |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 4.4\. Stream operations
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 流操作
- en: 'The streams interface in `java.util.stream.Stream` defines many operations.
    They can be classified into two categories. Let’s look at our previous example
    once again:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`java.util.stream.Stream` 中的流接口定义了许多操作。它们可以分为两类。让我们再次看看我们的上一个例子：'
- en: '[PRE14]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '***1* Gets a stream from the list of dishes**'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 从菜式列表中获取流**'
- en: '***2* Intermediate operation**'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 中间操作**'
- en: '***3* Converts the Stream into a List**'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 将流转换为列表**'
- en: 'You can see two groups of operations:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到两组操作：
- en: '`filter`, `map`, and `limit` can be connected together to form a pipeline.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter`、`map` 和 `limit` 可以连接起来形成一个管道。'
- en: '`collect` causes the pipeline to be executed and closes it.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`collect` 导致管道执行并关闭它。'
- en: Stream operations that can be connected are called *intermediate operations*,
    and operations that close a stream are called *terminal operations*. [Figure 4.5](#ch04fig05)
    highlights these two groups. Why is the distinction important?
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 可以连接的流操作称为 *中间操作*，而关闭流的操作称为 *终端操作*。[图 4.5](#ch04fig05) 突出了这两组操作。这种区分为什么很重要？
- en: Figure 4.5\. Intermediate versus terminal operations
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 4.5\. 中间操作与终端操作
- en: '![](Images/04fig05_alt.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/04fig05_alt.jpg)'
- en: 4.4.1\. Intermediate operations
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.1\. 中间操作
- en: Intermediate operations such as `filter` or `sorted` return another stream as
    the return type. This allows the operations to be connected to form a query. What’s
    important is that intermediate operations don’t perform any processing until a
    terminal operation is invoked on the stream pipeline—they’re lazy. This is because
    intermediate operations can usually be merged and processed into a single pass
    by the terminal operation.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 中间操作，如 `filter` 或 `sorted`，返回另一个流作为返回类型。这允许操作连接起来形成一个查询。重要的是，中间操作在流管道上调用终端操作之前不会执行任何处理——它们是惰性的。这是因为中间操作通常可以被合并并处理为终端操作的单个遍历。
- en: To understand what’s happening in the stream pipeline, modify the code so each
    lambda also prints the current dish it’s processing. (Like many demonstration
    and debugging techniques, this is appalling programming style for production code,
    but directly explains the order of evaluation when you’re learning.)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解流管道中发生的事情，修改代码，使每个 lambda 也打印出它正在处理的当前菜式。（像许多演示和调试技术一样，这对于生产代码来说是一种糟糕的编程风格，但在学习时可以直接解释评估的顺序。）
- en: '[PRE15]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '***1* Prints the dishes as they’re filtered**'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 在过滤过程中打印菜式**'
- en: '***2* Prints the dishes as you extract their names**'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 按提取名称的顺序打印菜式**'
- en: 'This code, when executed, will print the following:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当执行此代码时，将打印以下内容：
- en: '[PRE16]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: By doing this, you can notice that the Streams library performs several optimizations
    exploiting the lazy nature of streams. First, despite the fact that many dishes
    have more than 300 calories, only the first three are selected! This is because
    of the `limit` operation and a technique called *short-circuiting*, as we’ll explain
    in the next chapter. Second, despite the fact that `filter` and `map` are two
    separate operations, they were merged into the same pass (compiler experts call
    this technique *loop fusion*).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，你可以注意到 Streams 库通过利用流的惰性特性执行了几个优化。首先，尽管许多菜式的卡路里超过 300，但只选择了前三个！这是因为 `limit`
    操作和称为 *短路* 的技术，我们将在下一章中解释。其次，尽管 `filter` 和 `map` 是两个不同的操作，但它们被合并到了同一个遍历中（编译器专家称这种技术为
    *循环融合*）。
- en: 4.4.2\. Terminal operations
  id: totrans-162
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.2\. 终端操作
- en: 'Terminal operations produce a result from a stream pipeline. A result is any
    non-stream value such as a `List`, an `Integer`, or even `void`. For example,
    in the following pipeline, `forEach` is a terminal operation that returns `void`
    and applies a lambda to each dish in the source. Passing `System.out.println`
    to `forEach` asks it to print every `Dish` in the stream created from `menu`:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 终端操作从流管道生成一个结果。结果可以是任何非流值，例如 `List`、`Integer`，甚至是 `void`。例如，在下面的管道中，`forEach`
    是一个终端操作，它返回 `void` 并对源中的每个菜式应用 lambda。将 `System.out.println` 传递给 `forEach` 是要求它打印从
    `menu` 创建的流中的每个 `Dish`：
- en: '[PRE17]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To check your understanding of intermediate versus terminal operations, try
    out quiz 4.2.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检验你对中间操作与终端操作的理解，尝试练习 4.2。
- en: '|  |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Quiz 4.2: Intermediate vs. terminal operations**'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 4.2：中间操作与终端操作**'
- en: In the stream pipeline that follows, can you identify the intermediate and terminal
    operations?
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的流管道中，你能识别出中间操作和终端操作吗？
- en: '[PRE18]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**Answer:**'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: The last operation in the stream pipeline `count` returns a `long`, which is
    a non-stream value. It’s therefore a *terminal operation*. All previous operations,
    `filter`, `distinct`, `limit`, are connected and return a stream. They are therefore
    *intermediate operations*.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 流管道中的最后一个操作 `count` 返回一个 `long`，这是一个非流值。因此，它是一个 *终端操作*。所有之前的操作，`filter`、`distinct`、`limit`，都是连接的，并返回一个流。因此，它们是
    *中间操作*。
- en: '|  |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 4.4.3\. Working with streams
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.3\. 使用流
- en: 'To summarize, working with streams in general involves three items:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 总结起来，使用流通常涉及三个项目：
- en: A *data source* (such as a collection) to perform a query on
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据源*（如集合）用于执行查询'
- en: A chain of *intermediate operations* that form a stream pipeline
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 形成流管道的 *中间操作* 链
- en: A *terminal operation* that executes the stream pipeline and produces a result
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行流管道并产生结果的 *终端操作*
- en: The idea behind a stream pipeline is similar to the builder pattern (see [http://en.wikipedia.org/wiki/Builder_pattern](http://en.wikipedia.org/wiki/Builder_pattern)).
    In the builder pattern, there’s a chain of calls to set up a configuration (for
    streams this is a chain of intermediate operations), followed by a call to a `build`
    method (for streams this is a terminal operation).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 流管道背后的思想与构建器模式类似（见 [http://en.wikipedia.org/wiki/Builder_pattern](http://en.wikipedia.org/wiki/Builder_pattern)）。在构建器模式中，有一系列设置配置的调用链（对于流来说，这是一系列中间操作），然后是一个调用
    `build` 方法的调用（对于流来说，这是一个终端操作）。
- en: For convenience, [tables 4.1](#ch04table01) and [4.2](#ch04table02) summarize
    the intermediate and terminal stream operations you’ve seen in the code examples
    so far. Note that this is an incomplete list of operations provided by the Streams
    API; you’ll see several more in the next chapter!
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，[表 4.1](#ch04table01) 和 [4.2](#ch04table02) 总结了您在迄今为止的代码示例中看到的中间和终端流操作。请注意，这是
    Streams API 提供的操作的不完整列表；您将在下一章中看到更多操作！
- en: Table 4.1\. Intermediate operations
  id: totrans-180
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.1\. 中间操作
- en: '| Operation | Type | Return type | Argument of the operation | Function descriptor
    |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 类型 | 返回类型 | 操作的参数 | 函数描述符 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| filter | Intermediate | Stream<T> | Predicate<T> | T -> boolean |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| filter | 中间操作 | Stream<T> | Predicate<T> | T -> boolean |'
- en: '| map | Intermediate | Stream<R> | Function<T, R> | T -> R |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| map | 中间操作 | Stream<R> | Function<T, R> | T -> R |'
- en: '| limit | Intermediate | Stream<T> |   |   |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| limit | 中间操作 | Stream<T> |   |   |'
- en: '| sorted | Intermediate | Stream<T> | Comparator<T> | (T, T) -> int |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| sorted | 中间操作 | Stream<T> | Comparator<T> | (T, T) -> int |'
- en: '| distinct | Intermediate | Stream<T> |   |   |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| distinct | 中间操作 | Stream<T> |   |   |'
- en: Table 4.2\. Terminal operations
  id: totrans-188
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 4.2\. 终端操作
- en: '| Operation | Type | Return type | Purpose |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 类型 | 返回类型 | 目的 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| forEach | Terminal | void | Consumes each element from a stream and applies
    a lambda to each of them. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| forEach | 终端操作 | void | 消费流中的每个元素，并对每个元素应用 lambda 函数。|'
- en: '| count | Terminal | long | Returns the number of elements in a stream. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| count | 终端操作 | long | 返回流中的元素数量。|'
- en: '| collect | Terminal | (generic) | Reduces the stream to create a collection
    such as a List, a Map, or even an Integer. See [chapter 6](kindle_split_017.xhtml#ch06)
    for more detail. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| collect | 终端操作 | (泛型) | 将流缩减为一个集合，如 List、Map 或甚至 Integer。有关更多详细信息，请参阅 [第
    6 章](kindle_split_017.xhtml#ch06)。'
- en: 4.5\. Road map
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5\. 路线图
- en: In the next chapter, we’ll detail the available stream operations with use cases
    so you can see what kinds of queries you can express with them. We look at many
    patterns such as filtering, slicing, finding, matching, mapping, and reducing,
    which can be used to express sophisticated data-processing queries.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将详细说明可用的流操作及其用例，以便您可以看到您可以使用它们表达哪些类型的查询。我们将探讨许多模式，如过滤、切片、查找、匹配、映射和归约，这些模式可以用来表达复杂的数据处理查询。
- en: '[Chapter 6](kindle_split_017.xhtml#ch06) then explores collectors in detail.
    In this chapter we have only made use of the `collect()` terminal operation on
    streams (see [table 4.2](#ch04table02)) in the stylized form of `collect(toList())`,
    which creates a `List` whose elements are the same as those of the stream it’s
    applied to.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[第 6 章](kindle_split_017.xhtml#ch06) 详细探讨了收集器。在本章中，我们只使用了流上的 `collect()` 终端操作（见
    [表 4.2](#ch04table02)），其形式为 `collect(toList())`，它创建了一个 `List`，其元素与应用于它的流的元素相同。'
- en: Summary
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: A stream is a sequence of elements from a source that supports data-processing
    operations.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流是从支持数据处理操作的数据源中获取的一系列元素。
- en: 'Streams make use of internal iteration: the iteration is abstracted away through
    operations such as `filter`, `map`, and `sorted`.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流使用内部迭代：迭代通过`filter`、`map`和`sorted`等操作被抽象化。
- en: 'There are two types of stream operations: intermediate and terminal operations.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有两种类型的流操作：中间操作和终端操作。
- en: Intermediate operations such as `filter` and `map` return a stream and can be
    chained together. They’re used to set up a pipeline of operations but don’t produce
    any result.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中间操作，如`filter`和`map`，返回一个流并可以串联在一起。它们用于设置操作管道，但不会产生任何结果。
- en: Terminal operations such as `forEach` and `count` return a non-stream value
    and process a stream pipeline to return a result.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 终端操作，如`forEach`和`count`，返回非流值并处理流管道以返回结果。
- en: The elements of a stream are computed on demand (“lazily”).
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流的元素是按需计算的（“延迟”计算）。
- en: Chapter 5\. Working with streams
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第5章\. 使用流
- en: '*This chapter covers*'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Filtering, slicing, and mapping
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤、切片和映射
- en: Finding, matching, and reducing
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找、匹配和归约
- en: Using numeric streams (primitive stream specializations)
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用数值流（原始流特殊化）
- en: Creating streams from multiple sources
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从多个来源创建流
- en: Infinite streams
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无限流
- en: In the previous chapter, you saw that streams let you move from *external iteration*
    to *internal iteration*. Instead of writing code, as follows, where you explicitly
    manage the iteration over a collection of data (external iteration),
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你看到流让你从*外部迭代*转移到*内部迭代*。你不需要编写代码，如下所示，其中你明确管理数据集合的迭代（外部迭代），
- en: '[PRE19]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'you can use the Streams API (internal iteration), which supports the `filter`
    and `collect` operations, to manage the iteration over the collection of data
    for you. All you need to do is pass the filtering behavior as argument to the
    `filter` method:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用Streams API（内部迭代），它支持`filter`和`collect`操作，来为你管理数据集合的迭代。你需要做的只是将过滤行为作为参数传递给`filter`方法：
- en: '[PRE20]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This different way of working with data is useful because you let the Streams
    API manage how to process the data. As a consequence, the Streams API can work
    out several optimizations behind the scenes. In addition, using internal iteration,
    the Streams API can decide to run your code in parallel. Using external iteration,
    this isn’t possible because you’re committed to a single-threaded step-by-step
    sequential iteration.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这种不同的数据处理方式很有用，因为你可以让Streams API管理如何处理数据。因此，Streams API可以在幕后进行优化。此外，使用内部迭代，Streams
    API可以决定是否并行运行你的代码。使用外部迭代，这是不可能的，因为你承诺进行单线程的逐步顺序迭代。
- en: 'In this chapter, you’ll have an extensive look at the various operations supported
    by the Streams API. You will learn about operations available in Java 8 and also
    new additions in Java 9\. These operations will let you express complex data-processing
    queries such as filtering, slicing, mapping, finding, matching, and reducing.
    Next, we’ll explore special cases of streams: numeric streams, streams built from
    multiple sources such as files and arrays, and finally infinite streams.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将全面了解Streams API支持的各项操作。你将了解Java 8中可用的操作以及Java 9中的新增功能。这些操作将让你能够表达复杂的数据处理查询，如过滤、切片、映射、查找、匹配和归约。接下来，我们将探讨流的特殊情况：数值流、从多个来源（如文件和数组）构建的流，以及最终的无限流。
- en: 5.1\. Filtering
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. 过滤
- en: 'In this section, we’ll look at the ways to select elements of a stream: filtering
    with a predicate and filtering only unique elements.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨选择流元素的方法：使用谓词进行过滤和过滤唯一元素。
- en: 5.1.1\. Filtering with a predicate
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1\. 使用谓词进行过滤
- en: 'The `Stream` interface supports a `filter` method (which you should be familiar
    with by now). This operation takes as argument a *predicate* (a function returning
    a `boolean`) and returns a stream including all elements that match the predicate.
    For example, you can create a vegetarian menu by filtering all vegetarian dishes
    as illustrated in [figure 5.1](#ch05fig01) and the code that follows it:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream`接口支持一个`filter`方法（你现在应该很熟悉了）。这个操作接受一个*谓词*（返回`boolean`值的函数）作为参数，并返回一个包含所有匹配谓词的元素的流。例如，你可以通过过滤所有素食菜肴来创建一个素食菜单，如图5.1所示及其后的代码：'
- en: Figure 5.1\. Filtering a stream with a predicate
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.1\. 使用谓词过滤流
- en: '![](Images/05fig01_alt.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/05fig01_alt.jpg)'
- en: '[PRE21]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '***1* Use a method reference to check if a dish is vegetarian friendly.**'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 使用方法引用来检查一道菜是否适合素食者食用。**'
- en: 5.1.2\. Filtering unique elements
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2\. 过滤唯一元素
- en: Streams also support a method called `distinct` that returns a stream with unique
    elements (according to the implementation of the `hashcode` and `equals` methods
    of the objects produced by the stream). For example, the following code filters
    all even numbers from a list and then eliminates duplicates (using the `equals`
    method for the comparison). [Figure 5.2](#ch05fig02) shows this visually.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 流还支持一个名为 `distinct` 的方法，该方法返回一个包含唯一元素的流（根据流生成的对象的 `hashcode` 和 `equals` 方法的实现）。例如，以下代码从列表中过滤出所有偶数，然后消除重复项（使用
    `equals` 方法进行比较）。[图 5.2](#ch05fig02) 以可视化的方式展示了这一点。
- en: '[PRE22]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Figure 5.2\. Filtering unique elements in a stream
  id: totrans-228
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.2\. 在流中过滤唯一元素
- en: '![](Images/05fig02_alt.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/05fig02_alt.jpg)'
- en: 5.2\. Slicing a stream
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 切片流
- en: '![](Images/java.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/java.jpg)'
- en: In this section, we’ll discuss how to select and skip elements in a stream in
    different ways. There are operations available that let you efficiently select
    or drop elements using a predicate, ignore the first few elements of a stream,
    or truncate a stream to a given size.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论如何以不同的方式在流中选择和跳过元素。有操作可以让你高效地使用谓词选择或丢弃元素，忽略流的前几个元素，或者截断流到给定的大小。
- en: 5.2.1\. Slicing using a predicate
  id: totrans-233
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1\. 使用谓词切片
- en: 'Java 9 added two new methods that are useful for efficiently selecting elements
    in a stream: `takeWhile` and `dropWhile`.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: Java 9 添加了两个对在流中高效选择元素有用的新方法：`takeWhile` 和 `dropWhile`。
- en: Using takeWhile
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用 takeWhile
- en: 'Let’s say you have the following special list of dishes:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个以下特殊的菜肴列表：
- en: '[PRE23]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'How would you select the dishes that have fewer than 320 calories? Instinctively,
    you know already from the previous section that the operation `filter` can be
    used as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 你会如何选择少于 320 卡路里的菜肴？从上一节中，你可能会本能地知道可以使用 `filter` 操作如下：
- en: '[PRE24]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '***1* Lists seasonal fruit, prawns**'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 列出季节性水果，虾**'
- en: 'But, you’ll notice that the initial list was already sorted on the number of
    calories! The downside of using the `filter` operation here is that you need to
    iterate through the whole stream and the predicate is applied to each element.
    Instead, you could stop once you found a dish that is greater than (or equal to)
    320 calories. With a small list this may not seem like a huge benefit, but it
    can become useful if you work with potentially large stream of elements. But how
    do you specify this? The `takeWhile` operation is here to rescue you! It lets
    you slice any stream (even an infinite stream as you will learn later) using a
    predicate. But thankfully, it stops once it has found an element that fails to
    match. Here’s how you can use it:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，你会注意到初始列表已经按卡路里数量排序了！在这里使用 `filter` 操作的缺点是，你需要遍历整个流，并且谓词应用于每个元素。相反，你可以在找到卡路里大于（或等于）320
    的菜肴时停止。对于小型列表，这可能看起来不是什么大好处，但如果你处理的是可能非常大的元素流，它就会变得有用。但你怎么指定这个？`takeWhile` 操作就是为了解决这个问题而存在的！它允许你使用谓词切片任何流（甚至是一个无限流，你将在后面学到），但幸运的是，它会在找到不匹配的元素时停止。以下是如何使用它的示例：
- en: '[PRE25]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '***1* Lists seasonal fruit, prawns**'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 列出季节性水果，虾**'
- en: Using dropWhile
  id: totrans-244
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用 dropWhile
- en: 'How about getting the other elements though? How about finding the elements
    that have greater than 320 calories? You can use the `dropWhile` operation for
    this:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 那么其他元素怎么办？如何找到卡路里超过 320 的元素？你可以使用 `dropWhile` 操作来完成这个任务：
- en: '[PRE26]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '***1* Lists rice, chicken, french fries**'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 列出米饭，鸡肉，薯条**'
- en: The `dropWhile` operation is the complement of `takeWhile`. It throws away the
    elements at the start where the predicate is false. Once the predicate evaluates
    to true it stops and returns all the remaining elements, and it even works if
    there are an infinite number of remaining elements!
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`dropWhile` 操作是 `takeWhile` 的补充。它丢弃起始处为假值的元素。一旦谓词评估为真，它就会停止并返回所有剩余的元素，即使剩余元素是无限数量的也能工作！'
- en: 5.2.2\. Truncating a stream
  id: totrans-249
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2\. 截断流
- en: 'Streams support the `limit(n)` method, which returns another stream that’s
    no longer than a given size. The requested size is passed as argument to `limit`.
    If the stream is ordered, the first elements are returned up to a maximum of `n`.
    For example, you can create a `List` by selecting the first three dishes that
    have more than 300 calories as follows:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 流支持 `limit(n)` 方法，该方法返回另一个长度不超过给定大小的流。请求的大小作为参数传递给 `limit`。如果流是有序的，则返回前 `n`
    个元素，最多不超过 `n`。例如，你可以通过以下方式创建一个 `List`，选择前三个卡路里超过 300 的菜肴：
- en: '[PRE27]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '***1* Lists rice, chicken, french fries**'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 列出米饭，鸡肉，薯条**'
- en: '[Figure 5.3](#ch05fig03) illustrates a combination of `filter` and `limit`.
    You can see that only the first three elements that match the predicate are selected,
    and the result is immediately returned.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5.3](#ch05fig03)展示了`filter`和`limit`的组合。你可以看到，只有符合谓词的前三个元素被选中，并且结果立即返回。'
- en: Figure 5.3\. Truncating a stream
  id: totrans-254
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.3\. 截断流
- en: '![](Images/05fig03_alt.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/05fig03_alt.jpg)'
- en: Note that `limit` also works on unordered streams (for example, if the source
    is a `Set`). In this case you shouldn’t assume any order on the result produced
    by `limit`.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`limit`也适用于无序流（例如，如果源是`Set`）。在这种情况下，你不应该假设`limit`产生的结果有任何顺序。
- en: 5.2.3\. Skipping elements
  id: totrans-257
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3\. 跳过元素
- en: Streams support the `skip(n)` method to return a stream that discards the first
    `n` elements. If the stream has fewer than `n` elements, an empty stream is returned.
    Note that `limit(n)` and `skip(n)` are complementary! For example, the following
    code skips the first two dishes that have more than 300 calories and returns the
    rest. [Figure 5.4](#ch05fig04) illustrates this query.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 流支持`skip(n)`方法，用于返回一个丢弃前`n`个元素的流。如果流中的元素少于`n`个，则返回一个空流。请注意，`limit(n)`和`skip(n)`是互补的！例如，以下代码跳过了前两个超过300卡路里的菜品，并返回了剩余的菜品。[图5.4](#ch05fig04)展示了这个查询。
- en: '[PRE28]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Figure 5.4\. Skipping elements in a stream
  id: totrans-260
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图5.4\. 跳过流中的元素
- en: '![](Images/05fig04_alt.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/05fig04_alt.jpg)'
- en: Put what you’ve learned in this section into practice with quiz 5.1 before we
    move to mapping operations.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们转向映射操作之前，请将本节学到的内容通过练习5.1进行实践。
- en: '|  |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Quiz 5.1: Filtering**'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习5.1：过滤**'
- en: How would you use streams to filter the first two meat dishes?
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 你将如何使用流来过滤前两个肉菜？
- en: '**Answer:**'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: 'You can solve this problem by composing the methods `filter` and `limit` together
    and using `collect(toList())` to convert the stream into a list as follows:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过组合`filter`和`limit`方法并使用`collect(toList())`将流转换为列表来解决此问题：
- en: '[PRE29]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '|  |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 5.3\. Mapping
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. 映射
- en: A common data processing idiom is to select information from certain objects.
    For example, in SQL you can select a particular column from a table. The Streams
    API provides similar facilities through the `map` and `flatMap` methods.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 从某些对象中选择信息是一种常见的数据处理惯用方法。例如，在SQL中，你可以从表中选择特定的列。Streams API通过`map`和`flatMap`方法提供了类似的设施。
- en: 5.3.1\. Applying a function to each element of a stream
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1\. 将函数应用于流中的每个元素
- en: 'Streams support the `map` method, which takes a function as argument. The function
    is applied to each element, mapping it into a new element (the word *mapping*
    is used because it has a meaning similar to *transforming* but with the nuance
    of “creating a new version of” rather than “modifying”). For example, in the following
    code you pass a method reference `Dish::getName` to the `map` method to *extract*
    the names of the dishes in the stream:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 流支持`map`方法，该方法接受一个函数作为参数。该函数应用于每个元素，将其映射到新元素（单词*mapping*用于表示，因为它有一个类似于*transforming*的含义，但带有“创建新版本”而不是“修改”的细微差别）。例如，在以下代码中，你将方法引用`Dish::getName`传递给`map`方法来*提取*流中的菜品名称：
- en: '[PRE30]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Because the method `getName` returns a string, the stream outputted by the `map`
    method is of type `Stream<String>`.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 因为`getName`方法返回一个字符串，所以`map`方法输出的流类型为`Stream<String>`。
- en: 'Let’s take a slightly different example to solidify your understanding of `map`.
    Given a list of words, you’d like to return a list of the number of characters
    for each word. How would you do it? You’d need to apply a function to each element
    of the list. This sounds like a job for the `map` method! The function to apply
    should take a word and return its length. You can solve this problem, as follows,
    by passing a method reference `String::length` to `map`:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个稍微不同的例子来巩固你对`map`的理解。给定一个单词列表，你想要返回每个单词的字符数列表。你将如何做？你需要对列表中的每个元素应用一个函数。这听起来像是`map`方法的用武之地！要应用的函数应该接受一个单词并返回其长度。你可以通过将方法引用`String::length`传递给`map`来解决此问题：
- en: '[PRE31]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let’s return to the example where you extracted the name of each dish. What
    if you wanted to find out the length of the name of each dish? You could do this
    by chaining another `map` as follows:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到提取每个菜品名称的例子。如果你想知道每个菜品名称的长度，你可以通过以下方式链式使用另一个`map`：
- en: '[PRE32]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 5.3.2\. Flattening streams
  id: totrans-280
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2\. 扁平化流
- en: 'You saw how to return the length for each word in a list using the `map` method.
    Let’s extend this idea a bit further: How could you return a list of all the *unique
    characters* for a list of words? For example, given the list of words `["Hello,"
    "World"]` you’d like to return the list `["H," "e," "l," "o," "W," "r," "d"]`.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了如何使用 `map` 方法返回列表中每个单词的长度。让我们进一步扩展这个想法：你如何返回一个单词列表的所有 *唯一字符* 的列表？例如，给定单词列表
    `["Hello," "World"]`，你希望返回列表 `["H," "e," "l," "o," "W," "r," "d"]`。
- en: 'You might think that this is easy, that you can map each word into a list of
    characters and then call `distinct` to filter duplicate characters. A first go
    could be like the following:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能认为这很简单，你可以将每个单词映射到一个字符列表，然后调用 `distinct` 来过滤重复的字符。第一次尝试可能如下所示：
- en: '[PRE33]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The problem with this approach is that the lambda passed to the `map` method
    returns a `String[]` (an array of String) for each word. The stream returned by
    the `map` method is of type `Stream<String[]>`. What you want is `Stream<String>`
    to represent a stream of characters. [Figure 5.5](#ch05fig05) illustrates the
    problem.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的问题在于传递给 `map` 方法的 lambda 返回每个单词的 `String[]`（字符串数组）。`map` 方法返回的流是 `Stream<String[]>`
    类型。你想要的应该是 `Stream<String>` 来表示字符流。[图 5.5](#ch05fig05) 展示了这个问题。
- en: Figure 5.5\. Incorrect use of `map` to find unique characters from a list of
    words
  id: totrans-285
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.5\. 使用 `map` 错误地从单词列表中找到唯一字符
- en: '![](Images/05fig05_alt.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/05fig05_alt.jpg)'
- en: Luckily there’s a solution to this problem using the method `flatMap`! Let’s
    see step-by-step how to solve it.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有一个使用 `flatMap` 方法的解决方案来解决这个问题！让我们一步一步地看看如何解决这个问题。
- en: Attempt using map and Arrays.stream
  id: totrans-288
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 尝试使用 map 和 Arrays.stream
- en: 'First, you need a stream of characters instead of a stream of arrays. There’s
    a method called `Arrays.stream()`that takes an array and produces a stream:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要一个字符流而不是数组流。有一个名为 `Arrays.stream()` 的方法，它接受一个数组并产生一个流：
- en: '[PRE34]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Use it in the previous pipeline to see what happens:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的管道中使用它，看看会发生什么：
- en: '[PRE35]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '***1* Converts each word into an array of its individual letters**'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 将每个单词转换为它各个字母的数组**'
- en: '***2* Makes each array into a separate stream**'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将每个数组转换为单独的流**'
- en: The current solution still doesn’t work! This is because you now end up with
    a list of streams (more precisely, `List<Stream<String>>`). Indeed, you first
    convert each word into an array of its individual letters and then make each array
    into a separate stream.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的解决方案仍然不起作用！这是因为你现在得到了一个流列表（更准确地说，是 `List<Stream<String>>`）。确实，你首先将每个单词转换成它各个字母的数组，然后将每个数组转换成单独的流。
- en: Using flatMap
  id: totrans-296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用 flatMap
- en: 'You can fix this problem by using `flatMap` as follows:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下方式使用 `flatMap` 来解决这个问题：
- en: '[PRE36]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '***1* Converts each word into an array of its individual letters**'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 将每个单词转换为它各个字母的数组**'
- en: '***2* Flattens each generated stream into a single stream**'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将生成的每个流扁平化为单个流**'
- en: Using the `flatMap` method has the effect of mapping each array not with a stream
    but *with the contents of that stream*. All the separate streams that were generated
    when using `map(Arrays::stream)` get amalgamated—flattened into a single stream.
    [Figure 5.6](#ch05fig06) illustrates the effect of using the `flatMap` method.
    Compare it with what `map` does in [figure 5.5](#ch05fig05).
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `flatMap` 方法的效果是将每个数组映射到一个流，而不是映射到流的内容。使用 `map(Arrays::stream)` 生成时产生的所有单独的流都被合并——扁平化为一个单一的流。[图
    5.6](#ch05fig06) 展示了使用 `flatMap` 方法的效果。与图 5.5 中的 `map` 的效果进行比较。
- en: Figure 5.6\. Using `flatMap` to find the unique characters from a list of words
  id: totrans-302
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.6\. 使用 `flatMap` 从单词列表中找到唯一字符
- en: '![](Images/05fig06_alt.jpg)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/05fig06_alt.jpg)'
- en: In a nutshell, the `flatMap` method lets you replace each value of a stream
    with another stream and then concatenates all the generated streams into a single
    stream.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，`flatMap` 方法允许你用另一个流替换流中的每个值，然后将所有生成的流连接成一个单一的流。
- en: We’ll come back to `flatMap` in [chapter 11](kindle_split_024.xhtml#ch11) when
    we discuss more advanced Java 8 patterns such as using the new library class `Optional`
    for `null` checking. To solidify your understanding of `map` and `flatMap`, try
    out quiz 5.2.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们讨论更高级的 Java 8 模式，例如使用新的库类 `Optional` 进行 `null` 检查时，我们将在第 11 章回到 `flatMap`。为了巩固你对
    `map` 和 `flatMap` 的理解，尝试练习 5.2。
- en: '|  |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Quiz 5.2: Mapping**'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 5.2：映射**'
- en: 1\. Given a list of numbers, how would you return a list of the square of each
    number? For example, given [1, 2, 3, 4, 5] you should return [1, 4, 9, 16, 25].
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 给定一个数字列表，你如何返回每个数字的平方列表？例如，给定 [1, 2, 3, 4, 5]，你应该返回 [1, 4, 9, 16, 25]。
- en: '**Answer:**'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: 'You can solve this problem by using `map` with a lambda that takes a number
    and returns the square of the number:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用带有lambda的`map`来解决此问题，该lambda接受一个数字并返回该数字的平方：
- en: '[PRE37]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 2\. Given two lists of numbers, how would you return all pairs of numbers? For
    example, given a list [1, 2, 3] and a list [3, 4] you should return [(1, 3), (1,
    4), (2, 3), (2, 4), (3, 3), (3, 4)]. For simplicity, you can represent a pair
    as an array with two elements.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 给定两个数字列表，你将如何返回所有数字对？例如，给定一个列表 [1, 2, 3] 和一个列表 [3, 4]，你应该返回 [(1, 3), (1,
    4), (2, 3), (2, 4), (3, 3), (3, 4)]。为了简单起见，你可以将一对表示为包含两个元素的数组。
- en: '**Answer:**'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: 'You could use two `map`s to iterate on the two lists and generate the pairs.
    But this would return a `Stream<Stream<Integer[]>>`. What you need to do is flatten
    the generated streams to result in a `Stream<Integer[]>`. This is what `flatMap`
    is for:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用两个`map`来遍历两个列表并生成对。但这将返回一个`Stream<Stream<Integer[]>>`。你需要做的是展平生成的流，以得到一个`Stream<Integer[]>`。这就是`flatMap`的作用：
- en: '[PRE38]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 3\. How would you extend the previous example to return only pairs whose sum
    is divisible by 3?
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 你会如何扩展前面的例子以返回和为3的倍数的所有对？
- en: '**Answer:**'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: 'You saw earlier that `filter` can be used with a predicate to filter elements
    from a stream. Because after the `flatMap` operation you have a stream of `int[]`
    that represent a pair, you only need a predicate to check if the sum is divisible
    by 3:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 你之前看到`filter`可以与谓词一起使用，从流中过滤元素。因为`flatMap`操作后，你有一个表示对的`int[]`流，你只需要一个谓词来检查和是否为3的倍数：
- en: '[PRE39]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The result is [(2, 4), (3, 3)].
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是 [(2, 4), (3, 3)]。
- en: '|  |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 5.4\. Finding and matching
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4. 查找和匹配
- en: Another common data processing idiom is finding whether some elements in a set
    of data match a given property. The Streams API provides such facilities through
    the `allMatch`, `anyMatch`, `noneMatch`, `findFirst`, and `findAny` methods of
    a stream.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的数据处理惯用方法是检查数据集中的一些元素是否匹配给定的属性。Streams API通过流的方法`allMatch`、`anyMatch`、`noneMatch`、`findFirst`和`findAny`提供了这样的功能。
- en: 5.4.1\. Checking to see if a predicate matches at least one element
  id: totrans-324
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.4.1. 检查谓词是否匹配至少一个元素
- en: 'The `anyMatch` method can be used to answer the question “Is there an element
    in the stream matching the given predicate?” For example, you can use it to find
    out whether the menu has a vegetarian option:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '`anyMatch`方法可以用来回答“流中是否存在匹配给定谓词的元素？”例如，你可以用它来找出菜单中是否有素食选项：'
- en: '[PRE40]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The `anyMatch` method returns a `boolean` and is therefore a terminal operation.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '`anyMatch`方法返回一个`boolean`，因此是一个终端操作。'
- en: 5.4.2\. Checking to see if a predicate matches all elements
  id: totrans-328
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.4.2. 检查谓词是否匹配所有元素
- en: 'The `allMatch` method works similarly to `anyMatch` but will check to see if
    all the elements of the stream match the given predicate. For example, you can
    use it to find out whether the menu is healthy (all dishes are below 1000 calories):'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '`allMatch`方法与`anyMatch`类似，但会检查流中的所有元素是否匹配给定的谓词。例如，你可以用它来找出菜单是否健康（所有菜品的热量都低于1000卡路里）：'
- en: '[PRE41]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: noneMatch
  id: totrans-331
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: noneMatch
- en: 'The opposite of `allMatch` is `noneMatch`. It ensures that no elements in the
    stream match the given predicate. For example, you could rewrite the previous
    example as follows using `noneMatch`:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '`allMatch`的相反操作是`noneMatch`。它确保流中没有任何元素匹配给定的谓词。例如，你可以使用`noneMatch`将前面的例子重写如下：'
- en: '[PRE42]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: These three operations—`anyMatch`, `allMatch`, and `noneMatch`—make use of what
    we call *short-circuiting*, a stream version of the familiar Java short-circuiting
    `&&` and `||` operators.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个操作——`anyMatch`、`allMatch`和`noneMatch`——利用了我们所说的*短路*，这是熟悉的Java短路`&&`和`||`运算符的流版本。
- en: '|  |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Short-circuiting evaluation**'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '**短路评估**'
- en: Some operations don’t need to process the whole stream to produce a result.
    For example, say you need to evaluate a large `boolean` expression chained with
    `and` operators. You need only find out that one expression is `false` to deduce
    that the whole expression will return `false`, no matter how long the expression
    is; there’s no need to evaluate the entire expression. This is what *short-circuiting*
    refers to.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 一些操作不需要处理整个流就能产生结果。例如，假设你需要评估一个由`and`运算符连接的大`boolean`表达式。你只需要找出其中一个表达式是`false`，就可以推断出整个表达式将返回`false`，无论表达式有多长；没有必要评估整个表达式。这就是*短路*的含义。
- en: In relation to streams, certain operations such as `allMatch`, `noneMatch`,
    `findFirst`, and `findAny` don’t need to process the whole stream to produce a
    result. As soon as an element is found, a result can be produced. Similarly, `limit`
    is also a short-circuiting operation. The operation only needs to create a stream
    of a given size without processing all the elements in the stream. Such operations
    are useful (for example, when you need to deal with streams of infinite size,
    because they can turn an infinite stream into a stream of finite size). We’ll
    show examples of infinite streams in [section 5.7](#ch05lev1sec7).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 与流相关，某些操作如`allMatch`、`noneMatch`、`findFirst`和`findAny`不需要处理整个流来产生结果。一旦找到元素，就可以产生结果。同样，`limit`也是一个短路操作。该操作只需要创建一个给定大小的流，而不需要处理流中的所有元素。这样的操作很有用（例如，当你需要处理无限大小的流时，因为它们可以将无限流转换为有限大小的流）。我们将在第5.7节中展示无限流的示例。
- en: '|  |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 5.4.3\. Finding an element
  id: totrans-340
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.4.3\. 查找元素
- en: 'The `findAny` method returns an arbitrary element of the current stream. It
    can be used in conjunction with other stream operations. For example, you may
    wish to find a dish that’s vegetarian. You can combine the `filter` method and
    `findAny` to express this query:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '`findAny`方法返回当前流的任意元素。它可以与其他流操作结合使用。例如，你可能希望找到一个素食菜。你可以将`filter`方法和`findAny`结合起来表达这个查询：'
- en: '[PRE43]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The stream pipeline will be optimized behind the scenes to perform a single
    pass and finish as soon as a result is found by using short-circuiting. But wait
    a minute; what’s this `Optional` thing in the code?
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，流管道将被优化以执行单次遍历，并在找到结果后立即完成，这是通过短路实现的。但是等等；代码中的这个`Optional`是什么东西？
- en: Optional in a nutshell
  id: totrans-344
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Optional概述
- en: 'The `Optional<T>` class (`java.util.Optional`) is a container class to represent
    the existence or absence of a value. In the previous code, it’s possible that
    `findAny` doesn’t find any element. Instead of returning `null`, which is well
    known for being error-prone, the Java 8 library designers introduced `Optional<T>`.
    We won’t go into the details of `Optional` here, because we’ll show in detail
    in [chapter 11](kindle_split_024.xhtml#ch11) how your code can benefit from using
    `Optional` to avoid bugs related to `null` checking. But for now, it’s good to
    know that there are a few methods available in `Optional` that force you to explicitly
    check for the presence of a value or deal with the absence of a value:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '`Optional<T>`类（`java.util.Optional`）是一个容器类，用于表示值的存在或不存在。在之前的代码中，`findAny`可能找不到任何元素。而不是返回`null`，这众所周知是容易出错的，Java
    8库设计者引入了`Optional<T>`。我们不会在这里详细介绍`Optional`，因为我们将在第11章中详细展示如何使用`Optional`来避免与`null`检查相关的错误。但到目前为止，了解`Optional`中有一些方法可以强制你显式检查值的存在或处理值不存在的情况是很好的：'
- en: '`isPresent()` returns `true` if `Optional` contains a value, `false` otherwise.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`isPresent()`方法返回`true`如果`Optional`包含一个值，否则返回`false`。'
- en: '`ifPresent(Consumer<T> block)` executes the given block if a value is present.
    We introduced the `Consumer` functional interface in [chapter 3](kindle_split_013.xhtml#ch03);
    it lets you pass a lambda that takes an argument of type `T` and returns `void`.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ifPresent(Consumer<T> block)`如果存在值，则执行给定的块。我们在第3章中介绍了`Consumer`函数式接口；它允许你传递一个接受类型为`T`的参数并返回`void`的lambda表达式。'
- en: '`T get()` returns the value if present; otherwise it throws a `NoSuchElement-Exception`.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`T get()`如果存在值，则返回该值；否则抛出`NoSuchElementException`。'
- en: '`T orElse(T other)` returns the value if present; otherwise it returns a default
    value.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`T orElse(T other)`如果存在值，则返回该值；否则返回默认值。'
- en: 'For example, in the previous code you’d need to explicitly check for the presence
    of a dish in the `Optional` object to access its name:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在之前的代码中，你需要显式检查`Optional`对象中是否存在一个菜，才能访问其名称：
- en: '[PRE44]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '***1* Returns an Optional<Dish>.**'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 返回一个`Optional<Dish>`。**'
- en: '***2* If a value is contained, it’s printed; otherwise nothing happens.**'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 如果包含值，则打印；否则不发生任何操作。**'
- en: 5.4.4\. Finding the first element
  id: totrans-354
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.4.4\. 查找第一个元素
- en: 'Some streams have an *encounter order* that specifies the order in which items
    logically appear in the stream (for example, a stream generated from a `List`
    or from a sorted sequence of data). For such streams you may wish to find the
    first element. There’s the `findFirst` method for this, which works similarly
    to `findAny` (for example, the code that follows, given a list of numbers, finds
    the first square that’s divisible by 3):'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 一些流有一个 *encounter order*，它指定了项目在流中逻辑上出现的顺序（例如，从 `List` 或排序的数据序列生成的流）。对于这样的流，你可能希望找到第一个元素。有
    `findFirst` 方法可以做到这一点，它的工作方式与 `findAny` 类似（例如，下面的代码给出了一个数字列表，找到第一个能被 3 整除的平方数）：
- en: '[PRE45]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '|  |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**When to use findFirst and findAny**'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用 findFirst 和 findAny**'
- en: You may wonder why we have both `findFirst` and `findAny`. The answer is parallelism.
    Finding the first element is more constraining in parallel. If you don’t care
    about which element is returned, use `findAny` because it’s less constraining
    when using parallel streams.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么我们既有 `findFirst` 又有 `findAny`。答案是并行处理。在并行处理中找到第一个元素有更多的限制。如果你不关心返回哪个元素，可以使用
    `findAny`，因为它在并行流中使用时限制较少。
- en: '|  |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 5.5\. Reducing
  id: totrans-361
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5. Reducing
- en: The terminal operations you’ve seen either return a `boolean` (`allMatch` and
    so on), `void` (`forEach`), or an `Optional` object (`findAny` and so on). You’ve
    also been using `collect` to combine all elements in a stream into a `List`.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 你所看到的终端操作要么返回一个 `boolean`（`allMatch` 等），要么返回 `void`（`forEach`），或者返回一个 `Optional`
    对象（`findAny` 等）。你还在使用 `collect` 将流中的所有元素组合成一个 `List`。
- en: In this section, you’ll see how you can combine elements of a stream to express
    more complicated queries such as “Calculate the sum of all calories in the menu,”
    or “What is the highest calorie dish in the menu?” using the `reduce` operation.
    Such queries combine all the elements in the stream repeatedly to produce a single
    value such as an `Integer`. These queries can be classified as *reduction operations*
    (a stream is reduced to a value). In functional programming-language jargon, this
    is referred to as a *fold* because you can view this operation as repeatedly folding
    a long piece of paper (your stream) until it forms a small square, which is the
    result of the fold operation.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将了解如何使用 `reduce` 操作将流中的元素组合起来，以表达更复杂的查询，例如“计算菜单中所有卡路里的总和”，或者“菜单中最高卡路里的菜品是什么？”这样的查询会将流中的所有元素反复组合，以产生一个单一值，例如一个
    `Integer`。这些查询可以归类为 *reduction operations*（流被缩减为一个值）。在函数式编程语言的术语中，这被称为 *fold*，因为你可以将这个操作视为反复折叠一张长纸（你的流）直到它形成一个小的正方形，这就是折叠操作的结果。
- en: 5.5.1\. Summing the elements
  id: totrans-364
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.5.1. 求和元素
- en: 'Before we investigate how to use the `reduce` method, it helps to first see
    how you’d sum the elements of a list of numbers using a `for-each` loop:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨如何使用 `reduce` 方法之前，先看看如何使用 `for-each` 循环来计算一个数字列表的元素总和是有帮助的：
- en: '[PRE46]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Each element of `numbers` is combined iteratively with the addition operator
    to form a result. You *reduce* the list of numbers into one number by repeatedly
    using addition. There are two parameters in this code:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '`numbers` 的每个元素都会通过迭代使用加法运算符来组合成一个结果。你通过反复使用加法来 *reduce* 数字列表到一个数字。这段代码中有两个参数：'
- en: The initial value of the sum variable, in this case `0`
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总和变量的初始值，在这种情况下是 `0`
- en: The operation to combine all the elements of the list, in this case `+`
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将列表中的所有元素组合起来的操作，在这种情况下是 `+`
- en: 'Wouldn’t it be great if you could also multiply all the numbers without having
    to repeatedly copy and paste this code? This is where the `reduce` operation,
    which abstracts over this pattern of repeated application, can help. You can sum
    all the elements of a stream as follows:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你可以不重复粘贴代码就能将所有数字相乘，那岂不是很好？这就是 `reduce` 操作发挥作用的地方，它抽象了这种重复应用的模式。你可以如下方式计算流中所有元素的总和：
- en: '[PRE47]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '`reduce` takes two arguments:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '`reduce` 接受两个参数：'
- en: An initial value, here `0`.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个初始值，这里 `0`。
- en: A `BinaryOperator<T>` to combine two elements and produce a new value; here
    you use the lambda `(a, b) -> a + b`.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 `BinaryOperator<T>` 用于合并两个元素并产生一个新值；在这里你使用的是 lambda 表达式 `(a, b) -> a + b`。
- en: 'You could just as easily multiply all the elements by passing a different lambda,
    `(a, b) -> a * b`, to the `reduce` operation:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过传递不同的 lambda 表达式 `(a, b) -> a * b` 到 `reduce` 操作中，来轻松地将所有元素相乘：
- en: '[PRE48]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[Figure 5.7](#ch05fig07) illustrates how the `reduce` operation works on a
    stream: the lambda combines each element repeatedly until the stream containing
    the integers 4, 5, 3, 9, are reduced to a single value.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 5.7](#ch05fig07) 展示了 `reduce` 操作在流上的工作方式：lambda 重复组合每个元素，直到包含整数 4、5、3、9
    的流被缩减为一个单一值。'
- en: Figure 5.7\. Using `reduce` to sum the numbers in a stream
  id: totrans-378
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.7\. 使用 `reduce` 对流中的数字求和
- en: '![](Images/05fig07_alt.jpg)'
  id: totrans-379
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/05fig07_alt.jpg)'
- en: Let’s take an in-depth look into how the `reduce` operation happens to sum a
    stream of numbers. First, `0` is used as the first parameter of the lambda (`a`),
    and `4` is consumed from the stream and used as the second parameter (`b`). `0
    + 4` produces `4`, and it becomes the new accumulated value. Then the lambda is
    called again with the accumulated value and the next element of the stream, `5`,
    which produces the new accumulated value, `9`. Moving forward, the lambda is called
    again with the accumulated value and the next element, `3`, which produces `12`.
    Finally, the lambda is called with `12` and the last element of the stream, `9`,
    which produces the final value, `21`.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨 `reduce` 操作是如何将数字流求和的。首先，`0` 被用作 lambda 的第一个参数（`a`），然后从流中消耗 `4` 并用作第二个参数（`b`）。`0
    + 4` 产生 `4`，这成为新的累积值。然后 lambda 再次被调用，使用累积值和流的下一个元素 `5`，这产生了新的累积值 `9`。继续前进，lambda
    再次被调用，使用累积值和下一个元素 `3`，这产生了 `12`。最后，lambda 被调用，使用 `12` 和流的最后一个元素 `9`，这产生了最终值 `21`。
- en: 'You can make this code more concise by using a method reference. From Java
    8 the `Integer` class now comes with a static `sum` method to add two numbers,
    which is what you want instead of repeatedly writing out the same code as lambda:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用方法引用使这段代码更加简洁。从 Java 8 开始，`Integer` 类现在包含一个静态的 `sum` 方法来添加两个数字，这正是你想要的，而不是反复编写相同的
    lambda 代码：
- en: '[PRE49]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: No initial value
  id: totrans-383
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 没有初始值
- en: 'There’s also an overloaded variant of `reduce` that doesn’t take an initial
    value, but it returns an `Optional` object:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '`reduce` 也有一个不带初始值的重载变体，它返回一个 `Optional` 对象：'
- en: '[PRE50]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Why does it return an `Optional<Integer>`? Consider the case when the stream
    contains no elements. The `reduce` operation can’t return a sum because it doesn’t
    have an initial value. This is why the result is wrapped in an `Optional` object
    to indicate that the sum may be absent. Now see what else you can do with `reduce`.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么它返回 `Optional<Integer>`？考虑流中没有元素的情况。`reduce` 操作不能返回一个和，因为它没有初始值。这就是为什么结果被包裹在一个
    `Optional` 对象中，以表明和可能不存在。现在看看你还能用 `reduce` 做些什么。
- en: 5.5.2\. Maximum and minimum
  id: totrans-387
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.5.2\. 最大值和最小值
- en: 'It turns out that reduction is all you need to compute maxima and minima as
    well! Let’s see how you can apply what you just learned about `reduce` to calculate
    the maximum or minimum element in a stream. As you saw, `reduce` takes two parameters:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，计算最大值和最小值只需要 `reduce` 操作！让我们看看如何将你刚刚学到的关于 `reduce` 的知识应用到计算流中的最大或最小元素。正如你所看到的，`reduce`
    接受两个参数：
- en: An initial value
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始值
- en: A lambda to combine two stream elements and produce a new value
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于组合两个流元素并产生新值的 lambda
- en: The lambda is applied step-by-step to each element of the stream with the addition
    operator, as shown in [figure 5.7](#ch05fig07). You need a lambda that, given
    two elements, returns the maximum of them. The `reduce` operation will use the
    new value with the next element of the stream to produce a new maximum until the
    whole stream is consumed! You can use `reduce` as follows to calculate the maximum
    in a stream; this is illustrated in [figure 5.8](#ch05fig08).
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: lambda 按步骤应用于流中的每个元素，使用加法运算符，如 [图 5.7](#ch05fig07) 所示。你需要一个 lambda，给定两个元素，返回它们的最大值。`reduce`
    操作将使用新的值与流的下一个元素一起产生一个新的最大值，直到整个流被消耗！你可以如下使用 `reduce` 来计算流中的最大值；这在 [图 5.8](#ch05fig08)
    中有说明。
- en: '[PRE51]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'To calculate the minimum, you need to pass `Integer.min` to the `reduce` operation
    instead of `Integer.max`:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算最小值，你需要将 `Integer.min` 传递给 `reduce` 操作，而不是 `Integer.max`：
- en: '[PRE52]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'You could have equally well used the lambda `(x, y) -> x < y ? x : y` instead
    of `Integer-::min`, but the latter is definitely easier to read!'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '你同样可以使用 lambda `(x, y) -> x < y ? x : y` 来代替 `Integer-::min`，但后者显然更容易阅读！'
- en: Figure 5.8\. A `reduce` operation—calculating the maximum
  id: totrans-396
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.8\. `reduce` 操作——计算最大值
- en: '![](Images/05fig08_alt.jpg)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/05fig08_alt.jpg)'
- en: To test your understanding of the `reduce` operation, try quiz 5.3.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试你对 `reduce` 操作的理解，尝试练习 5.3。
- en: '|  |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Quiz 5.3: Reducing**'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 5.3：reduce**'
- en: How would you count the number of dishes in a stream using the `map` and `reduce`
    methods?
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 你将如何使用 `map` 和 `reduce` 方法来计算流中菜品的数量？
- en: '**Answer:**'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: 'You can solve this problem by mapping each element of a stream into the number
    1 and then summing them using `reduce`! This is equivalent to counting, in order,
    the number of elements in the stream:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过将流中的每个元素映射到数字1，然后使用 `reduce` 求和来解决此问题！这相当于按顺序计数流中的元素数量：
- en: '[PRE53]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'A chain of `map` and `reduce` is commonly known as the map-reduce pattern,
    made famous by Google’s use of it for web searching because it can be easily parallelized.
    Note that in [chapter 4](kindle_split_015.xhtml#ch04) you saw the built-in method
    `count` to count the number of elements in the stream:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '`map` 和 `reduce` 的链通常被称为map-reduce模式，由于Google在网页搜索中使用它而闻名，因为它可以很容易地并行化。注意，在第4章（kindle_split_015.xhtml#ch04）中，你看到了内置方法
    `count` 来计算流中的元素数量：'
- en: '[PRE54]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '|  |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '|  |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Benefit of the reduce method and parallelism**'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '**减少方法和并行性的好处**'
- en: 'The benefit of using `reduce` compared to the step-by-step iteration summation
    that you wrote earlier is that the iteration is abstracted using internal iteration,
    which enables the internal implementation to choose to perform the `reduce` operation
    in parallel. The iterative summation example involves shared updates to a `sum`
    variable, which doesn’t parallelize gracefully. If you add in the needed synchronization,
    you’ll likely discover that thread contention robs you of all the performance
    that parallelism was supposed to give you! Parallelizing this computation requires
    a different approach: partition the input, sum the partitions, and combine the
    sums. But now the code is starting to look very different. You’ll see what this
    looks like in [chapter 7](kindle_split_018.xhtml#ch07) using the fork/join framework.
    But for now it’s important to realize that the mutable-accumulator pattern is
    a dead end for parallelization. You need a new pattern, and this is what `reduce`
    provides you. You’ll also see in [chapter 7](kindle_split_018.xhtml#ch07) that
    to sum all the elements in parallel using streams, there’s almost no modification
    to your code: `stream()` becomes `parallelStream()`:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `reduce` 相比于你之前编写的逐步迭代求和的好处是，迭代被内部迭代抽象化，这使得内部实现可以选择并行执行 `reduce` 操作。迭代求和示例涉及到对
    `sum` 变量的共享更新，这并不容易并行化。如果你添加所需的同步，你可能会发现线程竞争会剥夺你本应从并行性中获得的所有性能！并行化这个计算需要不同的方法：划分输入，求和分区，然后合并求和。但现在代码开始看起来非常不同。你将在[第7章](kindle_split_018.xhtml#ch07)中看到使用fork/join框架的样子。但到目前为止，重要的是要意识到可变累加器模式对于并行化来说是一个死胡同。你需要一个新的模式，这正是
    `reduce` 为你提供的。你还会在第7章中看到，为了并行求和流中的所有元素，几乎不需要修改你的代码：`stream()` 变为 `parallelStream()`：
- en: '[PRE55]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'But there’s a price to pay to execute this code in parallel, as we’ll explain
    later: the lambda passed to `reduce` can’t change state (for example, instance
    variables), and the operation needs to be associative and commutative so it can
    be executed in any order.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 但执行此代码并行化需要付出代价，我们将在后面解释：传递给 `reduce` 的lambda不能改变状态（例如，实例变量），并且操作需要是结合律和交换律，这样它就可以按任何顺序执行。
- en: '|  |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'You have seen reduction examples that produced an `Integer`: the sum of a stream,
    the maximum of a stream, or the number of elements in a stream. You’ll see, in
    [section 5.6](#ch05lev1sec6), that additional built-in methods such as `sum` and
    `max` are available to help you write slightly more concise code for common reduction
    patterns. We’ll investigate a more complex form of reductions using the `collect`
    method in the next chapter. For example, instead of reducing a stream into an
    `Integer`, you can also reduce it into a `Map` if you want to group dishes by
    types.'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了产生 `Integer` 的归约示例：流的和、流的最大值或流的元素数量。你将在[5.6节](#ch05lev1sec6)中看到，有额外的内置方法如
    `sum` 和 `max` 可用于帮助你编写更简洁的代码，用于常见的归约模式。我们将在下一章中调查使用 `collect` 方法的更复杂形式的归约。例如，你不仅可以把流归约成一个
    `Integer`，如果你想要按类型分组菜品，你也可以把它归约成一个 `Map`。
- en: '|  |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Stream operations: stateless vs. stateful**'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '**流操作：无状态与有状态**'
- en: You’ve seen a lot of stream operations. An initial presentation can make them
    seem a panacea. Everything works smoothly, and you get parallelism for free when
    you use `parallelStream` instead of `stream` to get a stream from a collection.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了很多流操作。一个初步的介绍可能会使它们看起来像万能药。一切都很顺利，当你使用 `parallelStream` 而不是 `stream` 从集合中获取流时，你会免费获得并行性。
- en: Certainly for many applications this is the case, as you’ve seen in the previous
    examples. You can turn a list of dishes into a stream, `filter` to select various
    dishes of a certain type, then `map` down the resulting stream to add on the number
    of calories, and then `reduce` to produce the total number of calories of the
    menu. You can even do such stream calculations in parallel. But these operations
    have different characteristics. There are issues about what internal state they
    need to operate.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，对于许多应用来说，情况确实如此，正如你在前面的例子中看到的。你可以将菜肴列表转换为流，使用`filter`选择特定类型的各种菜肴，然后`map`到结果流中添加卡路里数，最后`reduce`以生成菜单的总卡路里数。你甚至可以在并行中进行这样的流计算。但是，这些操作有不同的特性。它们在操作时需要什么样的内部状态存在一些问题。
- en: 'Operations like `map` and `filter` take *each* element from the input stream
    and produce *zero or one* result in the output stream. These operations are in
    general *stateless*: they don’t have an internal state (assuming the user-supplied
    lambda or method reference has no internal mutable state).'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '`map`和`filter`这样的操作从输入流中取每个元素，并在输出流中产生零个或一个结果。这些操作通常是**无状态的**：它们没有内部状态（假设用户提供的lambda表达式或方法引用没有内部可变状态）。'
- en: But operations like `reduce`, `sum`, and `max` need to have internal state to
    accumulate the result. In this case the internal state is small. In our example
    it consisted of an `int` or `double`. The internal state is of *bounded size*
    no matter how many elements are in the stream being processed.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 但是像`reduce`、`sum`和`max`这样的操作需要内部状态来累积结果。在这种情况下，内部状态很小。在我们的例子中，它由一个`int`或`double`组成。无论正在处理的流中有多少元素，内部状态的大小都是有限的。
- en: By contrast, some operations such as `sorted` or `distinct` seem at first to
    behave like `filter` or `map`—all take a stream and produce another stream (an
    intermediate operation)—but there’s a crucial difference. Both sorting and removing
    duplicates from a stream require knowing the previous history to do their job.
    For example, sorting requires *all the elements to be buffered* before a single
    item can be added to the output stream; the storage requirement of the operation
    is *unbounded*. This can be problematic if the data stream is large or infinite.
    (What should reversing the stream of all prime numbers do? It should return the
    largest prime number, which mathematics tells us doesn’t exist.) We call these
    operations *stateful operations*.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，一些操作如`sorted`或`distinct`最初看起来像`filter`或`map`——所有这些操作都接受一个流并产生另一个流（一个中间操作），但有一个关键的区别。排序和从流中删除重复项都需要知道之前的历史才能完成它们的工作。例如，排序需要在向输出流添加单个项目之前将所有元素缓冲；该操作的存储需求是**无界的**。如果数据流很大或无限，这可能会成为问题。（反转所有质数流应该做什么？它应该返回最大的质数，数学告诉我们这是不存在的。）我们称这些操作为**有状态的操作**。
- en: '|  |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: You’ve now seen a lot of stream operations that you can use to express sophisticated
    data processing queries! [Table 5.1](#ch05table01) summarizes the operations seen
    so far. You get to practice them in the next section through an exercise.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经看到了很多可以用来表达复杂数据处理查询的流操作！[表5.1](#ch05table01)总结了迄今为止看到的操作。你将在下一节通过练习来练习它们。
- en: Table 5.1\. Intermediate and terminal operations
  id: totrans-424
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表5.1\. 中间和终端操作
- en: '| Operation | Type | Return type | Type/functional interface used | Function
    descriptor |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 类型 | 返回类型 | 类型/功能接口 | 函数描述符 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| filter | Intermediate | Stream<T> | Predicate<T> | T -> boolean |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| filter | 中间操作 | Stream<T> | Predicate<T> | T -> boolean |'
- en: '| distinct | Intermediate (stateful-unbounded) | Stream<T> |   |   |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| distinct | 中间操作（有状态-无界） | Stream<T> |  |  |'
- en: '| takeWhile | Intermediate | Stream<T> | Predicate<T> | T -> boolean |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| takeWhile | 中间操作 | Stream<T> | Predicate<T> | T -> boolean |'
- en: '| dropWhile | Intermediate | Stream<T> | Predicate<T> | T -> boolean |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| dropWhile | 中间操作 | Stream<T> | Predicate<T> | T -> boolean |'
- en: '| skip | Intermediate (stateful-bounded) | Stream<T> | long |   |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| skip | 中间操作（有状态-有界） | Stream<T> | long |  |'
- en: '| limit | Intermediate (stateful-bounded) | Stream<T> | long |   |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| limit | 中间操作（有状态-有界） | Stream<T> | long |  |'
- en: '| map | Intermediate | Stream<R> | Function<T, R> | T -> R |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| map | 中间操作 | Stream<R> | Function<T, R> | T -> R |'
- en: '| flatMap | Intermediate | Stream<R> | Function<T, Stream<R>> | T -> Stream<R>
    |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| flatMap | 中间操作 | Stream<R> | Function<T, Stream<R>> | T -> Stream<R> |'
- en: '| sorted | Intermediate (stateful-unbounded) | Stream<T> | Comparator<T> |
    (T, T) -> int |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| sorted | 中间操作（有状态-无界） | Stream<T> | Comparator<T> | (T, T) -> int |'
- en: '| anyMatch | Terminal | boolean | Predicate<T> | T -> boolean |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| anyMatch | 终端操作 | boolean | Predicate<T> | T -> boolean |'
- en: '| noneMatch | Terminal | boolean | Predicate<T> | T -> boolean |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| noneMatch | 终端 | boolean | Predicate<T> | T -> boolean |'
- en: '| allMatch | Terminal | boolean | Predicate<T> | T -> boolean |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| allMatch | 终端 | boolean | Predicate<T> | T -> boolean |'
- en: '| findAny | Terminal | Optional<T> |   |   |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| findAny | 终端 | Optional<T> |   |   |'
- en: '| findFirst | Terminal | Optional<T> |   |   |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| findFirst | 终端 | Optional<T> |   |   |'
- en: '| forEach | Terminal | void | Consumer<T> | T -> void |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| forEach | 终端 | void | Consumer<T> | T -> void |'
- en: '| collect | Terminal | R | Collector<T, A, R> |   |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| collect | 终端 | R | Collector<T, A, R> |   |'
- en: '| reduce | Terminal (stateful-bounded) | Optional<T> | BinaryOperator<T> |
    (T, T) -> T |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| reduce | 终端（有状态有界） | Optional<T> | BinaryOperator<T> | (T, T) -> T |'
- en: '| count | Terminal | long |   |   |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| count | 终端 | long |   |   |'
- en: 5.6\. Putting it all into practice
  id: totrans-445
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.6\. 将所有内容付诸实践
- en: 'In this section, you get to practice what you’ve learned about streams so far.
    We now explore a different domain: traders executing transactions. You’re asked
    by your manager to find answers to eight queries. Can you do it? We give the solutions
    in [section 5.6.2](#ch05lev2sec15), but you should try them yourself first to
    get some practice:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你可以练习到目前为止所学的关于流的知识。我们现在探索一个不同的域：执行交易的交易者。你的经理要求你找到对八个查询的答案。你能做到吗？我们在[5.6.2节](#ch05lev2sec15)中给出了解决方案，但你应该先尝试一下，以获得一些练习：
- en: Find all transactions in the year 2011 and sort them by value (small to high).
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到2011年所有的交易并按价值排序（从小到大）。
- en: What are all the unique cities where the traders work?
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 交易者工作过的所有独特城市有哪些？
- en: Find all traders from Cambridge and sort them by name.
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到所有来自剑桥的交易者并按名称排序。
- en: Return a string of all traders’ names sorted alphabetically.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回一个按字母顺序排序的所有交易者名称的字符串。
- en: Are any traders based in Milan?
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有任何交易者基于米兰吗？
- en: Print the values of all transactions from the traders living in Cambridge.
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印居住在剑桥的交易者的所有交易的价值。
- en: What’s the highest value of all the transactions?
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有交易中价值最高的是多少？
- en: Find the transaction with the smallest value.
  id: totrans-454
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到价值最小的交易。
- en: '5.6.1\. The domain: Traders and Transactions'
  id: totrans-455
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.6.1\. 域：交易者和交易
- en: 'Here’s the domain you’ll be working with, a list of `Trader`s and `Transaction`s:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是你将工作的域，一个包含`Trader`s和`Transaction`s的列表：
- en: '[PRE56]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '`Trader` and `Transaction` are classes defined as follows:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '`Trader`和`Transaction`是如下定义的类：'
- en: '[PRE57]'
  id: totrans-459
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 5.6.2\. Solutions
  id: totrans-460
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.6.2\. 解决方案
- en: We now provide the solutions in the following code listings, so you can verify
    your understanding of what you’ve learned so far. Well done!
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在在以下代码列表中提供解决方案，以便你可以验证你对所学内容的理解。做得好！
- en: Listing 5.1\. Finds all transactions in 2011 and sort by value (small to high)
  id: totrans-462
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.1\. 找到2011年所有的交易并按价值排序（从小到大）
- en: '[PRE58]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '***1* Passes a predicate to filter to select transactions in year 2011**'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 传递一个谓词以过滤选择2011年的交易**'
- en: '***2* Sorts them by using the value of the transaction**'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 使用交易的价值对它们进行排序**'
- en: '***3* Collects all the elements of the resulting Stream into a List**'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 将结果流的全部元素收集到一个列表中**'
- en: Listing 5.2\. What are all the unique cities where the traders work?
  id: totrans-467
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.2\. 交易者工作过的所有独特城市有哪些？
- en: '[PRE59]'
  id: totrans-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '***1* Extracts the city from each trader associated with the transaction**'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 从与交易关联的交易者中提取城市**'
- en: '***2* Selects only unique cities**'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 仅选择独特的城市**'
- en: You haven’t seen this yet, but you could also drop `distinct()` and use `toSet()`
    instead, which would convert the stream into a set. You’ll learn more about it
    in [chapter 6](kindle_split_017.xhtml#ch06).
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 你还没有看到这个，但你也可以省略`distinct()`并使用`toSet()`代替，这将把流转换成集合。你将在第6章中了解更多关于它的内容。
- en: '[PRE60]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Listing 5.3\. Finds all traders from Cambridge and sort them by name
  id: totrans-473
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.3\. 找到所有来自剑桥的交易者并按名称排序
- en: '[PRE61]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '***1* Extracts all traders from the transactions**'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 从交易中提取所有交易者**'
- en: '***2* Selects only the traders from Cambridge**'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 仅选择来自剑桥的交易者**'
- en: '***3* Removes any duplicates**'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 移除任何重复项**'
- en: '***4* Sorts the resulting stream of traders by their names**'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 按交易者的名称对生成的流进行排序**'
- en: Listing 5.4\. Returns a string of all traders’ names sorted alphabetically
  id: totrans-479
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表5.4\. 返回一个按字母顺序排序的所有交易者名称的字符串
- en: '[PRE62]'
  id: totrans-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '***1* Extracts all the names of the traders as a Stream of Strings**'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 提取所有交易者的名称作为字符串流**'
- en: '***2* Removes duplicate names**'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 移除重复的名称**'
- en: '***3* Sorts the names alphabetically**'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 按字母顺序排序名称**'
- en: '***4* Combines the names one by one to form a String that concatenates all
    the names**'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 逐个合并名称以形成一个包含所有名称的字符串**'
- en: 'Note that this solution is inefficient (all Strings are repeatedly concatenated,
    which creates a new `String` object at each iteration). In the next chapter, you’ll
    see a more efficient solution that uses `joining()` as follows (which internally
    makes use of a `StringBuilder`):'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这个解决方案效率不高（所有字符串都会被反复连接，这会在每次迭代中创建一个新的 `String` 对象）。在下一章中，你将看到一种更高效的解决方案，它使用
    `joining()` 如下（内部使用 `StringBuilder`）：
- en: '[PRE63]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Listing 5.5\. Are any traders based in Milan?
  id: totrans-487
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.5\. 是否有任何商人是基于米兰的？
- en: '[PRE64]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '***1* Pass a predicate to anyMatch to check if there’s a trader from Milan.**'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 将一个谓词传递给 anyMatch 以检查是否有来自米兰的商人。**'
- en: Listing 5.6\. Prints all transactions’ values from the traders living in Cambridge
  id: totrans-490
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.6\. 打印居住在剑桥的商人的所有交易值
- en: '[PRE65]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '***1* Selects the transactions where the traders live in Cambridge**'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 选择居住在剑桥的交易**'
- en: '***2* Extracts the values of these trades**'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 提取这些交易的值**'
- en: '***3* Prints each value**'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 打印每个值**'
- en: Listing 5.7\. What’s the highest value of all the transactions?
  id: totrans-495
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.7\. 所有交易中最高值是多少？
- en: '[PRE66]'
  id: totrans-496
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '***1* Extracts the value of each transaction**'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 提取每笔交易的价值**'
- en: '***2* Calculates the max of the resulting stream**'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 计算结果流的最大值**'
- en: Listing 5.8\. Finds the transaction with the smallest value
  id: totrans-499
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 5.8\. 找到价值最小的交易
- en: '[PRE67]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '***1* Finds the smallest transaction by repeatedly comparing the values of
    each transaction**'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 通过反复比较每笔交易的价值来找到最小的交易**'
- en: 'You can do better. A stream supports the methods `min` and `max` that take
    a `Comparator` as argument to specify which key to compare with when calculating
    the minimum or maximum:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以做得更好。流支持 `min` 和 `max` 方法，这些方法接受一个 `Comparator` 作为参数，以指定在计算最小值或最大值时与哪个键进行比较：
- en: '[PRE68]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 5.7\. Numeric streams
  id: totrans-504
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.7\. 数值流
- en: 'You saw earlier that you could use the `reduce` method to calculate the sum
    of the elements of a stream. For example, you can calculate the number of calories
    in the menu as follows:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 你之前已经看到可以使用 `reduce` 方法来计算流中元素的总和。例如，你可以这样计算菜单中的卡路里总数：
- en: '[PRE69]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: The problem with this code is that there’s an insidious boxing cost. Behind
    the scenes each `Integer` needs to be unboxed to a primitive before performing
    the summation. In addition, wouldn’t it be nicer if you could call a `sum` method
    directly as follows?
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代码的问题在于存在一个隐蔽的装箱成本。在幕后，每个 `Integer` 需要被解箱为原始类型，然后才能执行求和操作。此外，如果你可以直接像下面这样调用
    `sum` 方法，不是更好吗？
- en: '[PRE70]'
  id: totrans-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: But this isn’t possible. The problem is that the method `map` generates a `Stream<T>`.
    Even though the elements of the stream are of type `Integer`, the `streams` interface
    doesn’t define a `sum` method. Why not? Say you had only a `Stream<Dish>` like
    the `menu`; it wouldn’t make any sense to be able to sum dishes. But don’t worry;
    the Streams API also supplies *primitive stream specializations* that support
    specialized methods to work with streams of numbers.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 但这是不可能的。问题是 `map` 方法生成一个 `Stream<T>`。即使流中的元素类型为 `Integer`，`Streams` 接口也没有定义
    `sum` 方法。为什么没有？假设你只有一个像 `menu` 这样的 `Stream<Dish>`；能够对菜肴求和是没有意义的。但不用担心；Streams
    API 还提供了 *原始流特殊化*，它们支持用于处理数字流的专业方法。
- en: 5.7.1\. Primitive stream specializations
  id: totrans-510
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.7.1\. 原始流特殊化
- en: Java 8 introduces three primitive specialized stream interfaces to tackle this
    issue, `IntStream`, `DoubleStream`, and `LongStream`, which respectively specialize
    the elements of a stream to be `int`, `long`, and `double`—and thereby avoid hidden
    boxing costs. Each of these interfaces brings new methods to perform common numeric
    reductions, such as `sum` to calculate the sum of a numeric stream and `max` to
    find the maximum element. In addition, they have methods to convert back to a
    stream of objects when necessary. The thing to remember is that the additional
    complexity of these specializations isn’t inherent to streams. It reflects the
    complexity of boxing—the (efficiency-based) difference between `int` and `Integer`
    and so on.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: Java 8 引入了三个原始特殊化流接口来解决这个问题，`IntStream`、`DoubleStream` 和 `LongStream`，它们分别将流中的元素特殊化为
    `int`、`long` 和 `double`——从而避免了隐藏的装箱成本。这些接口中的每一个都带来了新的方法来执行常见的数值归约，例如 `sum` 用于计算数值流的总和，`max`
    用于找到最大元素。此外，它们在必要时还有将它们转换回对象流的方法。需要记住的是，这些特殊化的额外复杂性并非固有的。它反映了装箱的复杂性——基于效率的 `int`
    和 `Integer` 以及其他类型的差异。
- en: Mapping to a numeric stream
  id: totrans-512
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 映射到数值流
- en: 'The most common methods you’ll use to convert a stream to a specialized version
    are `mapToInt`, `mapToDouble`, and `mapToLong`. These methods work exactly like
    the method `map` that you saw earlier but return a specialized stream instead
    of a `Stream<T>`. For example, you can use `mapToInt` as follows to calculate
    the sum of calories in the `menu`:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 你将最常使用的将流转换为特殊版本的方法是 `mapToInt`、`mapToDouble` 和 `mapToLong`。这些方法的工作方式与之前看到的
    `map` 方法完全相同，但返回的是特殊流而不是 `Stream<T>`。例如，你可以使用 `mapToInt` 如下计算 `menu` 中的卡路里总和：
- en: '[PRE71]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '***1* Returns a Stream<Dish>**'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 返回一个 Stream<Dish>**'
- en: '***2* Returns an IntStream**'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 返回一个 IntStream**'
- en: Here, the method `mapToInt` extracts all the calories from each dish (represented
    as an `Integer)` and returns an `IntStream` as the result (rather than a `Stream<Integer>`).
    You can then call the `sum` method defined on the `IntStream` interface to calculate
    the sum of calories! Note that if the stream were empty, `sum` would return `0`
    by default. `IntStream` also supports other convenience methods such as `max`,
    `min`, and `average`.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，方法 `mapToInt` 从每个菜品（表示为 `Integer`）中提取所有卡路里，并返回一个 `IntStream` 作为结果（而不是 `Stream<Integer>`）。然后你可以调用定义在
    `IntStream` 接口上的 `sum` 方法来计算卡路里的总和！注意，如果流为空，`sum` 将默认返回 `0`。`IntStream` 还支持其他便利方法，如
    `max`、`min` 和 `average`。
- en: Converting back to a stream of objects
  id: totrans-518
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 将对象流转换回
- en: 'Similarly, once you have a numeric stream, you may be interested in converting
    it back to a nonspecialized stream. For example, the operations of an `IntStream`
    are restricted to produce primitive integers: the `map` operation of an `IntStream`
    takes a lambda that takes an `int` and produces an `int` (an `IntUnaryOperator`).
    But you may want to produce a different value such as a `Dish`. For this you need
    to access the operations defined in the `Streams` interface that are more general.
    To convert from a primitive stream to a general stream (each `int` will be boxed
    to an `Integer`) you can use the method `boxed,` as follows:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，一旦你有了数字流，你可能想将其转换回非特殊化流。例如，`IntStream` 的操作限制为产生原始整数：`IntStream` 的 `map` 操作接受一个接受
    `int` 并产生 `int`（`IntUnaryOperator`）的 lambda。但你可能想产生不同的值，例如 `Dish`。为此，你需要访问定义在
    `Streams` 接口上的更通用的操作。要从原始流转换为通用流（每个 `int` 将被装箱为 `Integer`），你可以使用 `boxed` 方法，如下所示：
- en: '[PRE72]'
  id: totrans-520
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '***1* Converts a Stream to a numeric stream**'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 将流转换为数字流**'
- en: '***2* Converts the numeric stream to a Stream**'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将数字流转换为 Stream**'
- en: You’ll learn in the next section that `boxed` is particularly useful when you
    deal with numeric ranges that need to be boxed into a general stream.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在下一节中了解到 `boxed` 在处理需要装箱到通用流中的数字范围时特别有用。
- en: 'Default values: OptionalInt'
  id: totrans-524
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 默认值：OptionalInt
- en: 'The sum example was convenient because it has a default value: `0`. But if
    you want to calculate the maximum element in an `IntStream`, you’ll need something
    different because `0` is a wrong result. How can you differentiate that the stream
    has no element and that the real maximum is `0`? Earlier we introduced the `Optional`
    class, which is a container that indicates the presence or absence of a value.
    `Optional` can be parameterized with reference types such as `Integer`, `String`,
    and so on. There’s a primitive specialized version of `Optional` as well for the
    three primitive stream specializations: `OptionalInt`, `OptionalDouble`, and `OptionalLong`.'
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 总和示例很方便，因为它有一个默认值：`0`。但如果你想在 `IntStream` 中计算最大元素，你需要不同的方法，因为 `0` 是一个错误的结果。如何区分流没有元素和实际最大值是
    `0` 呢？我们之前介绍了 `Optional` 类，它是一个表示值存在或不存在的内容容器。`Optional` 可以与 `Integer`、`String`
    等引用类型参数化。还有 `Optional` 的原始特殊版本，用于三种原始流特殊化：`OptionalInt`、`OptionalDouble` 和 `OptionalLong`。
- en: 'For example, you can find the maximal element of an `IntStream` by calling
    the `max` method, which returns an `OptionalInt`:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以通过调用 `max` 方法来找到 `IntStream` 的最大元素，该方法返回一个 `OptionalInt`：
- en: '[PRE73]'
  id: totrans-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'You can now process the `OptionalInt` explicitly to define a default value
    if there’s no maximum:'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以显式处理 `OptionalInt` 来定义一个默认值，如果没有最大值：
- en: '[PRE74]'
  id: totrans-529
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '***1* Provides an explicit default maximum if there’s no value**'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 提供一个明确的默认最大值，如果没有值**'
- en: 5.7.2\. Numeric ranges
  id: totrans-531
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.7.2\. 数字范围
- en: 'A common use case when dealing with numbers is working with ranges of numeric
    values. For example, suppose you’d like to generate all numbers between 1 and
    100\. Java 8 introduces two static methods available on `IntStream` and `LongStream`
    to help generate such ranges: `range` and `rangeClosed`. Both methods take the
    starting value of the range as the first parameter and the end value of the range
    as the second parameter. But `range` is exclusive, whereas `rangeClosed` is inclusive.
    Let’s look at an example:'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数字时，一个常见的用例是处理数值范围。例如，假设你想生成 1 到 100 之间的所有数字。Java 8 在 `IntStream` 和 `LongStream`
    上引入了两个静态方法来帮助生成这样的范围：`range` 和 `rangeClosed`。这两个方法都接受范围的起始值作为第一个参数，范围的结束值作为第二个参数。但是
    `range` 是排他的，而 `rangeClosed` 是包含的。让我们看一个例子：
- en: '[PRE75]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '***1* Represents the range 1 to 100**'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 代表范围 1 到 100**'
- en: '***2* Represents stream of even numbers from 1 to 100**'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 代表从 1 到 100 的偶数流**'
- en: '***3* Represents 50 even numbers from 1 to 100**'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 代表从 1 到 100 的 50 个偶数**'
- en: Here you use the `rangeClosed` method to generate a range of all numbers from
    1 to 100\. It produces a stream so you can chain the `filter` method to select
    only even numbers. At this stage no computation has been done. Finally, you call
    `count` on the resulting stream. Because `count` is a terminal operation, it will
    process the stream and return the result `50`, which is the number of even numbers
    from 1 to 100, inclusive. Note that by comparison, if you were using `IntStream.range(1,
    100)` instead, the result would be `49` even numbers because `range` is exclusive.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你使用 `rangeClosed` 方法生成从 1 到 100 的所有数字的范围。它产生一个流，你可以链式调用 `filter` 方法来选择仅包含偶数的数字。在这个阶段还没有进行任何计算。最后，你在结果流上调用
    `count`。因为 `count` 是一个终端操作，它将处理流并返回结果 `50`，这是从 1 到 100（包括 100）的偶数数量。请注意，相比之下，如果你使用
    `IntStream.range(1, 100)`，结果将是 `49` 个偶数，因为 `range` 是排他的。
- en: '5.7.3\. Putting numerical streams into practice: Pythagorean triples'
  id: totrans-538
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.7.3\. 将数值流应用于实践：毕达哥拉斯三元组
- en: Now we’ll look at a more difficult example so you can solidify what you’ve learned
    about numeric streams and all the stream operations you’ve learned so far. Your
    mission, if you choose to accept it, is to create a stream of Pythagorean triples.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将看一个更复杂的例子，这样你可以巩固你关于数值流以及你迄今为止学到的所有流操作的知识。如果你的选择是接受这个任务，你的任务是创建一个毕达哥拉斯三元组的流。
- en: Pythagorean triple
  id: totrans-540
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 毕达哥拉斯三元组
- en: What’s a Pythagorean triple? We have to go back a few years in the past. In
    one of your exciting math classes, you learned that the famous Greek mathematician
    Pythagoras discovered that certain triples of numbers `(a, b, c)` satisfy the
    formula `a * a + b * b = c * c` where `a`, `b`, and `c` are integers. For example,
    (3, 4, 5) is a valid Pythagorean triple because 3 * 3 + 4 * 4 = 5 * 5 or 9 + 16
    = 25\. There are an infinite number of such triples. For example, (5, 12, 13),
    (6, 8, 10), and (7, 24, 25) are all valid Pythagorean triples. Such triples are
    useful because they describe the three side lengths of a right-angled triangle,
    as illustrated in [figure 5.9](#ch05fig09).
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是毕达哥拉斯三元组？我们需要回顾一下过去的几年。在你的数学课上，你了解到著名的古希腊数学家毕达哥拉斯发现，某些数字三元组 `(a, b, c)` 满足公式
    `a * a + b * b = c * c`，其中 `a`、`b` 和 `c` 是整数。例如，(3, 4, 5) 是一个有效的毕达哥拉斯三元组，因为 3
    * 3 + 4 * 4 = 5 * 5 或者 9 + 16 = 25。这样的三元组有无限多个。例如，(5, 12, 13)、(6, 8, 10) 和 (7,
    24, 25) 都是有效的毕达哥拉斯三元组。这样的三元组很有用，因为它们描述了直角三角形的三个边长，如图 [图 5.9](#ch05fig09) 所示。
- en: Figure 5.9\. The Pythagorean theorem
  id: totrans-542
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 5.9\. 毕达哥拉斯定理
- en: '![](Images/05fig09.jpg)'
  id: totrans-543
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/05fig09.jpg)'
- en: Representing a triple
  id: totrans-544
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表示三元组
- en: Where do you start? The first step is to define a triple. Instead of (more properly)
    defining a new class to represent a triple, you can use an array of `int` with
    three elements. For example, `new int[]{3, 4, 5}` to represent the tuple (3, 4,
    5). You can now access each individual component of the tuple using array indexing.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 你从哪里开始？第一步是定义一个三元组。而不是（更确切地）定义一个新的类来表示三元组，你可以使用一个包含三个元素的 `int` 数组。例如，`new int[]{3,
    4, 5}` 来表示元组 (3, 4, 5)。现在你可以使用数组索引访问元组的每个单独的组件。
- en: Filtering good combinations
  id: totrans-546
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 过滤好的组合
- en: 'Let’s assume someone provides you with the first two numbers of the triple:
    `a` and `b`. How do you know whether that will form a good combination? You need
    to test whether the square root of `a * a + b * b` is a whole number. This is
    expressed in Java as `Math.sqrt(a*a + b*b) % 1 == 0`. (Given a floating-point
    number, x, in Java its fractional part is obtained using x `% 1.0`, and whole
    numbers like 5.0 have zero fractional part.) Our code uses this idea in a `filter`
    operation (you’ll see how to use this later to form valid code):'
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有人提供了三元组的前两个数字：`a`和`b`。你怎么知道这将形成一个好的组合？你需要测试`a * a + b * b`的平方根是否是一个整数。在Java中，这表示为`Math.sqrt(a*a
    + b*b) % 1 == 0`。（给定一个浮点数x，在Java中，它的分数部分是通过x `% 1.0`获得的，而像5.0这样的整数有零分数部分。）我们的代码在`filter`操作中使用了这个想法（你稍后会看到如何使用它来形成有效的代码）：
- en: '[PRE76]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Assuming that surrounding code has given a value for `a`, and assuming `stream`
    provides possible values for `b`, `filter` will select only those values for `b`
    that can form a Pythagorean triple with `a`.
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 假设周围的代码已经为`a`提供了一个值，并且假设`stream`提供了`b`的可能值，`filter`将只选择那些可以与`a`形成勾股数的三元组的`b`值。
- en: Generating tuples
  id: totrans-550
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成元组
- en: 'Following the `filter`, you know that both `a` and `b` can form a correct combination.
    You now need to create a triple. You can use the `map` operation to transform
    each element into a Pythagorean triple as follows:'
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 在`filter`之后，你知道`a`和`b`可以形成一个正确的组合。你现在需要创建一个三元组。你可以使用`map`操作将每个元素转换为一个勾股数三元组，如下所示：
- en: '[PRE77]'
  id: totrans-552
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Generating b values
  id: totrans-553
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成b值
- en: 'You’re getting closer! You now need to generate values for `b`. You saw that
    `Stream .rangeClosed` allows you to generate a stream of numbers in a given interval.
    You can use it to provide numeric values for `b`, here 1 to 100:'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 你越来越接近了！你现在需要为`b`生成值。你看到`Stream.rangeClosed`允许你生成一个给定区间的数字流。你可以用它来为`b`提供数值，这里是从1到100：
- en: '[PRE78]'
  id: totrans-555
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Note that you call `boxed` after the `filter` to generate a `Stream<Integer>`
    from the `IntStream` returned by `rangeClosed`. This is because `map` returns
    an array of `int` for each element of the stream. The `map` method from an `IntStream`
    expects only another `int` to be returned for each element of the stream, which
    isn’t what you want! You can rewrite this using the method `mapToObj` of an `IntStream`,
    which returns an object-valued stream:'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你在`filter`之后调用`boxed`，以从`rangeClosed`返回的`IntStream`生成一个`Stream<Integer>`。这是因为`map`为流中的每个元素返回一个`int`数组。`IntStream`的`map`方法期望每个流元素只返回另一个`int`，这不是你想要的！你可以使用`IntStream`的`mapToObj`方法重写它，它返回一个对象值流：
- en: '[PRE79]'
  id: totrans-557
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Generating a values
  id: totrans-558
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成值
- en: 'There’s one crucial component that we assumed was given: the value for `a`.
    You now have a stream that produces Pythagorean triples provided the value `a`
    is known. How can you fix this? Just like with `b`, you need to generate numeric
    values for `a`! The final solution is as follows:'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设的一个关键组件是`a`的值。你现在有一个生成勾股数三元的流，只要知道`a`的值。你怎么解决这个问题？就像`b`一样，你需要为`a`生成数值！最终的解决方案如下：
- en: '[PRE80]'
  id: totrans-560
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Okay, what’s the `flatMap` about? First, you create a numeric range from 1 to
    100 to generate values for `a`. For each given value of `a` you’re creating a
    stream of triples. Mapping a value of `a` to a stream of triples would result
    in a stream of streams! The `flatMap` method does the mapping and also flattens
    all the generated streams of triples into a single stream. As a result, you produce
    a stream of triples. Note also that you change the range of `b` to be `a` to 100\.
    There’s no need to start the range at the value `1` because this would create
    duplicate triples (for example, (3, 4, 5) and (4, 3, 5)).
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，`flatMap`是什么意思？首先，你从1到100创建一个数值范围来生成`a`的值。对于每个给定的`a`值，你创建一个三元组的流。将`a`的值映射到三元组的流会导致一个流中的流！`flatMap`方法执行映射并将所有生成的三元组流合并成一个单一的流。结果，你产生了一个三元组的流。注意，你还改变了`b`的范围为从`a`到100。没有必要从值`1`开始，因为这会创建重复的三元组（例如，(3,
    4, 5)和(4, 3, 5))。
- en: Running the code
  id: totrans-562
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 运行代码
- en: 'You can now run your solution and select explicitly how many triples you’d
    like to return from the generated stream using the `limit` operation that you
    saw earlier:'
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以运行你的解决方案，并使用你之前看到的`limit`操作显式地选择从生成的流中返回多少个三元组：
- en: '[PRE81]'
  id: totrans-564
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: This will print
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印
- en: '[PRE82]'
  id: totrans-566
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Can you do better?
  id: totrans-567
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 你能做得更好吗？
- en: 'The current solution isn’t optimal because you calculate the square root twice.
    One possible way to make your code more compact is to generate all triples of
    the form `(a*a, b*b, a*a+b*b)` and then filter the ones that match your criteria:'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 当前解决方案不是最优的，因为您计算了平方根两次。一种使代码更紧凑的可能方法是生成所有形式为 `(a*a, b*b, a*a+b*b)` 的三元组，然后过滤出符合您标准的三元组：
- en: '[PRE83]'
  id: totrans-569
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '***1* Produces triples**'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 生成三元组**'
- en: '***2* The third element of the tuple must be a whole number.**'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 元组的第三个元素必须是整数。**'
- en: 5.8\. Building streams
  id: totrans-572
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.8\. 构建流
- en: Hopefully, by now you’re convinced that streams are powerful and useful to express
    data-processing queries. You were able to get a stream from a collection using
    the `stream` method. In addition, we showed you how to create numerical streams
    from a range of numbers. But you can create streams in many more ways! This section
    shows how you can create a stream from a sequence of values, from an array, from
    a file, and even from a generative function to create infinite streams!
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 希望到现在您已经相信流是强大且非常有用的，可以用来表达数据处理查询。您能够使用 `stream` 方法从集合中获取流。此外，我们还向您展示了如何从一系列数字创建数值流。但您可以通过许多其他方式创建流！本节展示了您如何从一系列值、数组、文件以及甚至从生成函数创建无限流！
- en: 5.8.1\. Streams from values
  id: totrans-574
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.8.1\. 从值流
- en: 'You can create a stream with explicit values by using the static method `Stream.of`,
    which can take any number of parameters. For example, in the following code you
    create a stream of strings directly using `Stream.of`. You then convert the strings
    to uppercase before printing them one by one:'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用静态方法 `Stream.of` 通过显式值创建一个流，该方法可以接受任意数量的参数。例如，在以下代码中，您直接使用 `Stream.of`
    创建一个字符串流。然后，在打印之前将字符串转换为大写：
- en: '[PRE84]'
  id: totrans-576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'You can get an empty stream using the `empty` method as follows:'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 `empty` 方法获取一个空流，如下所示：
- en: '[PRE85]'
  id: totrans-578
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 5.8.2\. Stream from nullable
  id: totrans-579
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.8.2\. 从可空类型流
- en: 'In Java 9, a new method was added that lets you create a stream from a nullable
    object. After playing with streams, you may have encountered a situation where
    you extracted an object that may be null and then needs to be converted into a
    stream (or an empty stream for null). For example, the method `System.getProperty`
    returns `null` if there is no property with the given key. To use it together
    with a stream, you’d need to explicitly check for null as follows:'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Java 9 中，添加了一个新方法，允许您从可空对象创建流。在玩转流之后，您可能遇到了一个从可能为 null 的对象中提取对象的情况，然后需要将其转换为流（或对于
    null，为空流）。例如，`System.getProperty` 方法在没有给定键的属性时返回 `null`。要与其一起使用流，您需要显式检查 null，如下所示：
- en: '[PRE86]'
  id: totrans-581
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Using `Stream.ofNullable` you can rewrite this code more simply:'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `Stream.ofNullable` 您可以更简单地重写此代码：
- en: '[PRE87]'
  id: totrans-583
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'This pattern can be particularly handy in conjunction with `flatMap` and a
    stream of values that may include nullable objects:'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式与 `flatMap` 和可能包含可空对象的值流结合使用时特别有用：
- en: '[PRE88]'
  id: totrans-585
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 5.8.3\. Streams from arrays
  id: totrans-586
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.8.3\. 从数组流
- en: 'You can create a stream from an array using the static method `Arrays.stream`,
    which takes an array as parameter. For example, you can convert an array of primitive
    `int`s into an `IntStream` and then sum the `IntStream` to produce an `int`, as
    follows:'
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用静态方法 `Arrays.stream` 从数组创建一个流，该方法接受一个数组作为参数。例如，您可以将原始 `int` 数组转换为 `IntStream`，然后对
    `IntStream` 进行求和以生成一个 `int`，如下所示：
- en: '[PRE89]'
  id: totrans-588
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '***1* The sum is 41.**'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 总和为 41。**'
- en: 5.8.4\. Streams from files
  id: totrans-590
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.8.4\. 从文件流
- en: 'Java’s NIO API (non-blocking I/O), which is used for I/O operations such as
    processing a file, has been updated to take advantage of the Streams API. Many
    static methods in `java.nio.file.Files` return a stream. For example, a useful
    method is `Files.lines`, which returns a stream of lines as strings from a given
    file. Using what you’ve learned so far, you could use this method to find out
    the number of unique words in a file as follows:'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: Java 的 NIO API（非阻塞 I/O），用于处理文件等 I/O 操作，已更新以利用 Streams API。`java.nio.file.Files`
    中的许多静态方法返回一个流。例如，一个有用的方法是 `Files.lines`，它从给定的文件返回字符串流。使用您到目前为止所学的内容，您可以使用此方法来找出文件中的唯一单词数量，如下所示：
- en: '[PRE90]'
  id: totrans-592
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '***1* Streams are AutoCloseable so there’s no need for try-finally**'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 流是 AutoCloseable，因此不需要 try-finally**'
- en: '***2* Generates a stream of words**'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 生成单词流**'
- en: '***3* Removes duplicates**'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 移除重复项**'
- en: '***4* Counts the number of unique words**'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 计算唯一单词的数量**'
- en: '***5* Deals with the exception if one occurs when opening the file**'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 处理打开文件时发生的异常**'
- en: You use `Files.lines` to return a stream where each element is a line in the
    given file. This call is surrounded by a `try/catch` block because the source
    of the stream is an I/O resource. In fact, the call `Files.lines` will open an
    I/O resource, which needs to be closed to avoid a leak. In the past, you’d need
    an explicit `finally` block to do this. Conveniently, the `Stream` interface implements
    the interface `AutoCloseable`. This means that the management of the resource
    is handled for you within the `try` block. Once you have a stream of lines, you
    can then split each line into words by calling the `split` method on `line`. Notice
    how you use `flatMap` to produce one flattened stream of words instead of multiple
    streams of words for each line. Finally, you count each distinct word in the stream
    by chaining the methods `distinct` and `count`.
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用 `Files.lines` 返回一个流，其中每个元素都是给定文件中的一行。由于流的来源是一个I/O资源，因此此调用被一个 `try/catch`
    块包围。实际上，`Files.lines` 调用将打开一个I/O资源，需要关闭以避免泄漏。在过去，您需要一个显式的 `finally` 块来完成此操作。方便的是，`Stream`
    接口实现了 `AutoCloseable` 接口。这意味着资源的管理是在 `try` 块中为您处理的。一旦您有了行流，您就可以通过在 `line` 上调用
    `split` 方法来将每一行拆分成单词。注意您是如何使用 `flatMap` 来生成一个单词的扁平化流，而不是为每一行生成多个单词流。最后，您通过链式调用
    `distinct` 和 `count` 方法来计算流中的每个不同单词。
- en: '5.8.5\. Streams from functions: creating infinite streams!'
  id: totrans-599
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.8.5\. 从函数中生成流：创建无限流！
- en: 'The Streams API provides two static methods to generate a stream from a function:
    `Stream.iterate` and `Stream.generate`. These two operations let you create what
    we call an *infinite stream*, a stream that doesn’t have a fixed size like when
    you create a stream from a fixed collection. Streams produced by `iterate` and
    `generate` create values on demand given a function and can therefore calculate
    values forever! It’s generally sensible to use `limit(n)` on such streams to avoid
    printing an infinite number of values.'
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: Streams API提供了两个静态方法来从函数生成流：`Stream.iterate` 和 `Stream.generate`。这两个操作允许您创建我们所说的
    *无限流*，这种流没有固定的大小，就像您从固定集合创建流时那样。由 `iterate` 和 `generate` 生成的流根据函数按需创建值，因此可以无限计算值！通常，在这样流上使用
    `limit(n)` 是合理的，以避免打印无限数量的值。
- en: Iterate
  id: totrans-601
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 迭代
- en: 'Let’s look at a simple example of how to use `iterate` before we explain it:'
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们解释它之前，让我们看看如何使用 `iterate` 的一个简单示例：
- en: '[PRE91]'
  id: totrans-603
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'The `iterate` method takes an initial value, here `0`, and a lambda (of type
    `Unary-Operator<T>`) to apply successively on each new value produced. Here you
    return the previous element added with `2` using the lambda `n -> n + 2`. As a
    result, the `iterate` method produces a stream of all even numbers: the first
    element of the stream is the initial value `0`. Then it adds `2` to produce the
    new value `2`; it adds `2` again to produce the new value `4` and so on. This
    `iterate` operation is fundamentally sequential because the result depends on
    the previous application. Note that this operation produces an *infinite stream*—the
    stream doesn’t have an end because values are computed on demand and can be computed
    forever. We say the stream is *unbounded*. As we discussed earlier, this is a
    key difference between a stream and a collection. You’re using the `limit` method
    to explicitly limit the size of the stream. Here you select only the first 10
    even numbers. You then call the `forEach` terminal operation to consume the stream
    and print each element individually.'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '`iterate` 方法接受一个初始值，这里 `0`，以及一个应用于每个新产生的值的lambda（类型为 `Unary-Operator<T>`）。在这里，您使用lambda
    `n -> n + 2` 返回前一个元素加上 `2`。因此，`iterate` 方法产生一个所有偶数的流：流中的第一个元素是初始值 `0`。然后它加上 `2`
    产生新值 `2`；再次加上 `2` 产生新值 `4`，依此类推。这个 `iterate` 操作本质上是有序的，因为结果依赖于前一次应用。请注意，这个操作产生一个
    *无限流*——流没有结束，因为值是按需计算的，可以无限计算。我们说流是 *无界的*。正如我们之前讨论的，这是流和集合之间的一个关键区别。您使用 `limit`
    方法来显式限制流的大小。在这里，您只选择前10个偶数。然后您调用 `forEach` 最终操作来消费流并单独打印每个元素。'
- en: 'In general, you should use `iterate` when you need to produce a sequence of
    successive values (for example, a date followed by its next date: January 31,
    February 1, and so on). To see a more difficult example of how you can apply `iterate`,
    try out quiz 5.4.'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当您需要生成一系列连续的值时（例如，一个日期后面跟着它的下一个日期：1月31日，2月1日，等等），您应该使用 `iterate`。要查看如何应用
    `iterate` 的更复杂示例，请尝试练习题5.4。
- en: '|  |'
  id: totrans-606
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Quiz 5.4: Fibonacci tuples series**'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习题5.4：斐波那契元组序列**'
- en: 'The Fibonacci series is famous as a classic programming exercise. The numbers
    in the following sequence are part of the Fibonacci series: 0, 1, 1, 2, 3, 5,
    8, 13, 21, 34, 55\. . . . The first two numbers of the series are 0 and 1, and
    each subsequent number is the sum of the previous two.'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: 斐波那契数列因其是经典的编程练习而闻名。以下序列中的数字是斐波那契数列的一部分：0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55...
    数列的前两个数字是0和1，每个后续数字都是前两个数字的和。
- en: 'The series of Fibonacci tuples is similar; you have a sequence of a number
    and its successor in the series: (0, 1), (1, 1), (1, 2), (2, 3), (3, 5), (5, 8),
    (8, 13), (13, 21). . . .'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: 斐波那契元组的序列类似；你有一个数字及其在序列中的后续数字的序列：(0, 1), (1, 1), (1, 2), (2, 3), (3, 5), (5,
    8), (8, 13), (13, 21)...。
- en: Your task is to generate the first 20 elements of the series of Fibonacci tuples
    using the `iterate` method!
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: 你的任务是使用`iterate`方法生成斐波那契数列的前20个元素！
- en: 'Let us help you get started. The first problem is that the `iterate` method
    takes a `UnaryOperator<T>` as argument, and you need a stream of tuples such as
    (0, 1). You can, again rather sloppily, use an array of two elements to represent
    a tuple. For example, `new int[]{0, 1}` represents the first element of the Fibonacci
    series (0, 1). This will be the initial value of the `iterate` method:'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们帮你开始。第一个问题是`iterate`方法接受一个`UnaryOperator<T>`作为参数，你需要一个元组流，如(0, 1)。你可以再次相当草率地使用一个包含两个元素的数组来表示一个元组。例如，`new
    int[]{0, 1}`表示斐波那契数列的第一个元素(0, 1)。这将作为`iterate`方法的初始值：
- en: '[PRE92]'
  id: totrans-612
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: In this quiz, you need to figure out the highlighted `???` in the code. Remember
    that `iterate` will apply the given lambda successively.
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个测验中，你需要找出代码中高亮的`???`。记住，`iterate`会连续应用给定的lambda。
- en: '**Answer:**'
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: '[PRE93]'
  id: totrans-615
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'How does it work? `iterate` needs a lambda to specify the successor element.
    In the case of the tuple (3, 5) the successor is (5, 3+5) = (5, 8). The next one
    is (8, 5+8). Can you see the pattern? Given a tuple, the successor is (t[1], t[0]
    + t[1]). This is what the following lambda specifies: `t -> new int[]{t[1],t[0]
    + t[1]}`. By running this code you’ll get the series (0, 1), (1, 1), (1, 2), (2,
    3), (3, 5), (5, 8), (8, 13), (13, 21). . . . Note that if you wanted to print
    the normal Fibonacci series, you could use a `map` to extract only the first element
    of each tuple:'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 它是如何工作的？`iterate`需要一个lambda来指定后续元素。在(3, 5)这个元组的情况下，后续元素是(5, 3+5) = (5, 8)。下一个是(8,
    5+8)。你能看到模式吗？给定一个元组，其后续元素是(t[1], t[0] + t[1])。这正是以下lambda所指定的：`t -> new int[]{t[1],t[0]
    + t[1]}`。运行此代码，你会得到序列(0, 1), (1, 1), (1, 2), (2, 3), (3, 5), (5, 8), (8, 13),
    (13, 21)...。注意，如果你想要打印正常的斐波那契数列，你可以使用`map`来提取每个元组的第一个元素：
- en: '[PRE94]'
  id: totrans-617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'This code will produce the Fibonacci series: 0, 1, 1, 2, 3, 5, 8, 13, 21, 34
    . . .'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将生成斐波那契数列：0, 1, 1, 2, 3, 5, 8, 13, 21, 34...。
- en: '|  |'
  id: totrans-619
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'In Java 9, the `iterate` method was enhanced with support for a predicate.
    For example, you can generate numbers starting at 0 but stop the iteration once
    the number is greater than 100:'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: 在Java 9中，`iterate`方法增加了对谓词的支持。例如，你可以从0开始生成数字，一旦数字大于100就停止迭代：
- en: '[PRE95]'
  id: totrans-621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'The `iterate` method takes a predicate as its second argument that tells you
    when to continue iterating up until. Note that you may think that you can use
    the `filter` operation to achieve the same result:'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: '`iterate`方法接受一个谓词作为其第二个参数，它告诉你何时继续迭代直到。请注意，你可能认为你可以使用`filter`操作来实现相同的结果：'
- en: '[PRE96]'
  id: totrans-623
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Unfortunately that isn’t the case. In fact, this code wouldn’t terminate! The
    reason is that there’s no way to know in the filter that the numbers continue
    to increase, so it keeps on filtering them infinitely! You could solve the problem
    by using `takeWhile`, which would short-circuit the stream:'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 但事实并非如此。实际上，这段代码不会终止！原因是过滤器中无法知道数字会无限增加，所以它会无限期地过滤它们！你可以通过使用`takeWhile`来解决这个问题，它会短路流：
- en: '[PRE97]'
  id: totrans-625
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: But, you have to admit that `iterate` with a predicate is a bit more concise!
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，你必须承认，带有谓词的`iterate`要简洁得多！
- en: Generate
  id: totrans-627
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成
- en: 'Similarly to the method `iterate`, the method `generate` lets you produce an
    infinite stream of values computed on demand. But `generate` doesn’t apply successively
    a function on each new produced value. It takes a lambda of type `Supplier<T>`
    to provide new values. Let’s look at an example of how to use it:'
  id: totrans-628
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`iterate`方法，`generate`方法允许你按需生成一个无限值的流。但`generate`不会对每个新产生的值连续应用一个函数。它接受一个类型为`Supplier<T>`的lambda来提供新值。让我们看看如何使用它的一个例子：
- en: '[PRE98]'
  id: totrans-629
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'This code will generate a stream of five random double numbers from 0 to 1\.
    For example, one run gives the following:'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码将生成从0到1的五个随机双精度浮点数的流。例如，一次运行给出以下结果：
- en: '[PRE99]'
  id: totrans-631
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: The static method `Math.random` is used as a generator for new values. Again
    you limit the size of the stream explicitly using the `limit` method; otherwise
    the stream would be unbounded!
  id: totrans-632
  prefs: []
  type: TYPE_NORMAL
  zh: 静态方法 `Math.random` 被用作新值的生成器。再次使用 `limit` 方法显式限制流的大小；否则，流将是无界的！
- en: 'You may be wondering whether there’s anything else useful you can do using
    the method `generate`. The supplier we used (a method reference to `Math.random`)
    was stateless: it wasn’t recording any values somewhere that can be used in later
    computations. But a supplier doesn’t have to be stateless. You can create a supplier
    that stores state that it can modify and use when generating the next value of
    the stream. As an example, we’ll show how you can also create the Fibonacci series
    from quiz 5.4 using `generate` so that you can compare it with the approach using
    the `iterate` method! But it’s important to note that a supplier that’s stateful
    isn’t safe to use in parallel code. The stateful `IntSupplier` for Fibonacci is
    shown at the end of this chapter for completeness but should generally be avoided!
    We discuss the problem of operations with side effects and parallel streams further
    in [chapter 7](kindle_split_018.xhtml#ch07).'
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道是否还有其他有用的方法可以使用 `generate` 方法。我们使用的供应商（`Math.random` 的方法引用）是无状态的：它没有记录任何可以用于后续计算的值。但供应商不必是无状态的。你可以创建一个可以存储并修改状态以生成流中下一个值的供应商。作为一个例子，我们将展示如何使用
    `generate` 创建 quiz 5.4 中的斐波那契数列，以便你可以将其与使用 `iterate` 方法的方案进行比较！但重要的是要注意，有状态的供应商在并行代码中是不安全的。为了完整性，本章末尾展示了斐波那契的
    `IntSupplier`，但通常应避免使用！我们将在第 7 章[中进一步讨论具有副作用的操作和并行流]([chapter 7](kindle_split_018.xhtml#ch07))。
- en: 'We’ll use an `IntStream` in our example to illustrate code that’s designed
    to avoid boxing operations. The `generate` method on `IntStream` takes an `IntSupplier`
    instead of a `Supplier<T>`. For example, here’s how to generate an infinite stream
    of ones:'
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，我们将使用 `IntStream` 来说明旨在避免装箱操作的代码。`IntStream` 上的 `generate` 方法接受一个 `IntSupplier`
    而不是 `Supplier<T>`。例如，以下是如何生成一个无限流中的 `1`：
- en: '[PRE100]'
  id: totrans-635
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'You saw in [chapter 3](kindle_split_013.xhtml#ch03) that lambdas let you create
    an instance of a functional interface by providing the implementation of the method
    directly inline. You can also pass an explicit object, as follows, by implementing
    the `getAsInt` method defined in the `IntSupplier` interface (although this seems
    gratuitously long-winded, please bear with us):'
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 你在 [第 3 章](kindle_split_013.xhtml#ch03) 中看到，lambda 允许你通过直接提供方法的实现来创建函数式接口的实例。你也可以通过实现
    `IntSupplier` 接口中定义的 `getAsInt` 方法来传递一个显式的对象，如下所示（尽管这看起来有些冗长，但请耐心等待我们）：
- en: '[PRE101]'
  id: totrans-637
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: The `generate` method will use the given supplier and repeatedly call the `getAsInt`
    method, which always returns `2`. But the difference between the anonymous class
    used here and a lambda is that the anonymous class can define state via fields,
    which the `getAsInt` method can modify. This is an example of a side effect. All
    lambdas you’ve seen so far were side-effect free; they didn’t change any state.
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: '`generate` 方法将使用给定的供应商并反复调用 `getAsInt` 方法，该方法始终返回 `2`。但这里使用的匿名类与 lambda 的区别在于，匿名类可以通过字段定义状态，而
    `getAsInt` 方法可以修改这种状态。这是一个副作用示例。迄今为止你看到的所有 lambda 都是无副作用的；它们没有改变任何状态。'
- en: 'To come back to our Fibonacci tasks, what you need to do now is create an `Int-Supplier`
    that maintains in its state the previous value in the series, so `getAsInt` can
    use it to calculate the next element. In addition, it can update the state of
    the `IntSupplier` for the next time it’s called. The following code shows how
    to create an `IntSupplier` that will return the next Fibonacci element when it’s
    called:'
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的斐波那契任务，你现在需要做的是创建一个 `Int-Supplier`，它在状态中维护序列中的前一个值，这样 `getAsInt` 就可以使用它来计算下一个元素。此外，它还可以在下次调用时更新
    `IntSupplier` 的状态。以下代码展示了如何创建一个在调用时将返回下一个斐波那契元素的 `IntSupplier`：
- en: '[PRE102]'
  id: totrans-640
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'The code creates an instance of `IntSupplier`. This object has a *mutable*
    state: it tracks the previous Fibonacci element and the current Fibonacci element
    in two instance variables. The `getAsInt` method changes the state of the object
    when it’s called so that it produces new values on each call. In comparison, our
    approach using `iterate` was purely *immutable*; you didn’t modify existing state
    but were creating new tuples at each iteration. You’ll learn in [chapter 7](kindle_split_018.xhtml#ch07)
    that you should always prefer an *immutable approach* in order to process a stream
    in parallel and expect a correct result.'
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: 代码创建了一个`IntSupplier`实例。此对象具有*可变*状态：它通过两个实例变量跟踪前一个斐波那契元素和当前斐波那契元素。`getAsInt`方法在调用时改变对象的状态，以便每次调用都产生新的值。相比之下，我们使用`iterate`的方法是纯*不可变*的；您没有修改现有状态，而是在每次迭代中创建新的元组。您将在[第7章](kindle_split_018.xhtml#ch07)中了解到，为了并行处理流并期望得到正确的结果，您应该始终优先选择*不可变方法*。
- en: Note that because you’re dealing with a stream of infinite size, you have to
    limit its size explicitly using the operation `limit`; otherwise, the terminal
    operation (in this case `forEach`) will compute forever. Similarly, you can’t
    sort or reduce an infinite stream because all elements need to be processed, but
    this would take forever because the stream contains an infinite number of elements!
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于您正在处理无限大小的流，您必须使用操作`limit`显式地限制其大小；否则，终端操作（在这种情况下为`forEach`）将永远计算。同样，您不能对无限流进行排序或归约，因为所有元素都需要被处理，但这将永远无法完成，因为流包含无限数量的元素！
- en: 5.9\. Overview
  id: totrans-643
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.9. 概述
- en: It’s been a long but rewarding chapter! You can now process collections more
    effectively. Indeed, streams let you express sophisticated data processing queries
    concisely. In addition, streams can be parallelized transparently.
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个漫长但收获颇丰的章节！您现在可以更有效地处理集合。确实，流让您能够简洁地表达复杂的数据处理查询。此外，流可以透明地并行化。
- en: Summary
  id: totrans-645
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: The Streams API lets you express complex data processing queries. Common stream
    operations are summarized in [table 5.1](#ch05table01).
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Streams API 允许您表达复杂的数据处理查询。常见的流操作总结在[表5.1](#ch05table01)中。
- en: You can filter and slice a stream using the `filter`, `distinct`, `takeWhile`
    (Java 9), `dropWhile` (Java 9), `skip`, and `limit` methods.
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用`filter`、`distinct`、`takeWhile`（Java 9）、`dropWhile`（Java 9）、`skip`和`limit`方法过滤和切片流。
- en: The methods `takeWhile` and `dropWhile` are more efficient than a filter when
    you know that the source is sorted.
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您知道源已排序时，`takeWhile`和`dropWhile`方法比过滤器更高效。
- en: You can extract or transform elements of a stream using the `map` and `flatMap`
    methods.
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用`map`和`flatMap`方法从流中提取或转换元素。
- en: You can find elements in a stream using the `findFirst` and `findAny` methods.
    You can match a given predicate in a stream using the `allMatch`, `noneMatch`,
    and `anyMatch` methods.
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用`findFirst`和`findAny`方法在流中查找元素。您可以使用`allMatch`、`noneMatch`和`anyMatch`方法在流中匹配给定的谓词。
- en: 'These methods make use of short-circuiting: a computation stops as soon as
    a result is found; there’s no need to process the whole stream.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些方法利用了短路：一旦找到结果，计算就会停止；无需处理整个流。
- en: You can combine all elements of a stream iteratively to produce a result using
    the `reduce` method, for example, to calculate the sum or find the maximum of
    a stream.
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用`reduce`方法迭代地组合流的所有元素以产生一个结果，例如，计算流的和或找到流的最大值。
- en: 'Some operations such as `filter` and `map` are stateless: they don’t store
    any state. Some operations such as `reduce` store state to calculate a value.
    Some operations such as `sorted` and `distinct` also store state because they
    need to buffer all the elements of a stream before returning a new stream. Such
    operations are called *stateful operations*.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些操作，如`filter`和`map`，是无状态的：它们不存储任何状态。一些操作，如`reduce`，存储状态以计算值。一些操作，如`sorted`和`distinct`，也存储状态，因为它们需要在返回新的流之前缓冲流的所有元素。这些操作被称为*有状态操作*。
- en: 'There are three primitive specializations of streams: `IntStream`, `DoubleStream`,
    and `LongStream`. Their operations are also specialized accordingly.'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流有三种原始特化：`IntStream`、`DoubleStream`和`LongStream`。它们的操作也相应地进行了特化。
- en: Streams can be created not only from a collection but also from values, arrays,
    files, and specific methods such as `iterate` and `generate`.
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流不仅可以从集合中创建，还可以从值、数组、文件以及特定的方法（如`iterate`和`generate`）中创建。
- en: An infinite stream has an infinite number of elements (for example all possible
    strings). This is possible because the elements of a stream are only produced
    *on demand*. You can get a finite stream from an infinite stream using methods
    such as `limit`.
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无限流具有无限数量的元素（例如所有可能的字符串）。这是可能的，因为流的元素仅在需要时才被生成。您可以使用 `limit` 等方法从无限流中获取有限流。
- en: Chapter 6\. Collecting data with streams
  id: totrans-657
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 6 章\. 使用流收集数据
- en: '*This chapter covers*'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Creating and using a collector with the `Collectors` class
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `Collectors` 类创建和使用收集器
- en: Reducing streams of data to a single value
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据流减少到单个值
- en: Summarization as a special case of reduction
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摘要作为减少的特殊情况
- en: Grouping and partitioning data
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的分组和分区
- en: Developing your own custom collectors
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发您自己的自定义收集器
- en: 'You learned in the previous chapter that streams help you process collections
    with database-like operations. You can view Java 8 streams as fancy lazy iterators
    of sets of data. They support two types of operations: intermediate operations
    such as `filter` or `map` and terminal operations such as `count`, `findFirst`,
    `forEach`, and `reduce`. Intermediate operations can be chained to convert a stream
    into another stream. These operations don’t consume from a stream; their purpose
    is to set up a pipeline of streams. By contrast, terminal operations *do* consume
    from a stream—to produce a final result (for example, returning the largest element
    in a stream). They can often shorten computations by optimizing the pipeline of
    a stream.'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您了解到流可以帮助您使用类似数据库的操作处理集合。您可以将 Java 8 流视为数据集的高级懒迭代器。它们支持两种类型的操作：中间操作，如
    `filter` 或 `map`，以及终端操作，如 `count`、`findFirst`、`forEach` 和 `reduce`。中间操作可以链接起来，将一个流转换为另一个流。这些操作不会从流中消耗资源；它们的目的只是设置一个流管道。相比之下，终端操作
    *确实* 会从流中消耗资源，以产生最终结果（例如，返回流中的最大元素）。它们通常可以通过优化流管道来缩短计算。
- en: We already used the `collect` terminal operation on streams in [chapters 4](kindle_split_015.xhtml#ch04)
    and [5](kindle_split_016.xhtml#ch05), but we employed it there mainly to combine
    all the elements of a stream into a `List`. In this chapter, you’ll discover that
    `collect` is a reduction operation, like `reduce`, that takes as an argument various
    recipes for accumulating the elements of a stream into a summary result. These
    recipes are defined by a new `Collector` interface, so it’s important to distinguish
    `Collection`, `Collector`, and `collect`!
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在第 [4](kindle_split_015.xhtml#ch04) 和 [5](kindle_split_016.xhtml#ch05) 章节中使用了流上的
    `collect` 终端操作，但我们在那里主要用它来将流的所有元素组合成一个 `List`。在本章中，您将发现 `collect` 是一个类似于 `reduce`
    的减少操作，它接受将流元素累积到摘要结果的各种配方作为参数。这些配方由一个新的 `Collector` 接口定义，因此区分 `Collection`、`Collector`
    和 `collect` 非常重要！
- en: 'Here are some example queries of what you’ll be able to do using `collect`
    and collectors:'
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些使用 `collect` 和收集器的示例查询：
- en: Group a list of transactions by currency to obtain the sum of the values of
    all transactions with that currency (returning a `Map<Currency, Integer>`)
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按货币将交易列表分组，以获得具有该货币的所有交易的价值总和（返回一个 `Map<Currency, Integer>`）
- en: 'Partition a list of transactions into two groups: expensive and not expensive
    (returning a `Map<Boolean, List<Transaction>>`)'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将交易列表划分为两组：昂贵和不昂贵（返回一个 `Map<Boolean, List<Transaction>>`）
- en: Create multilevel groupings, such as grouping transactions by cities and then
    further categorizing by whether they’re expensive or not (returning a `Map<String`,
    `Map<Boolean`, `List<Transaction>>>`)
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建多级分组，例如按城市分组交易，然后进一步根据它们是否昂贵进行分类（返回一个 `Map<String, Map<Boolean, List<Transaction>>>`）
- en: Excited? Great. Let’s start by exploring an example that benefits from collectors.
    Imagine a scenario where you have a `List` of `Transaction`s, and you want to
    group them based on their nominal currency. Prior to Java 8, even a simple use
    case like this is cumbersome to implement, as shown in the following listing.
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: 激动吗？太好了。让我们从一个受益于收集器的示例开始探索。想象一个场景，您有一个 `Transaction` 的 `List`，并且您想根据它们的名义货币对它们进行分组。在
    Java 8 之前，即使是这样一个简单的用例也难以实现，如下面的列表所示。
- en: Listing 6.1\. Grouping transactions by currency in imperative style
  id: totrans-671
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.1\. 以命令式方式按货币分组交易
- en: '[PRE103]'
  id: totrans-672
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '***1* Creates the Map where the grouped transaction will be accumulated**'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建一个地图，其中将累积分组交易**'
- en: '***2* Iterates the List of Transactions**'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 遍历交易列表**'
- en: '***3* Extracts the Transaction’s currency**'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 提取交易的货币**'
- en: '***4* If there’s no entry in the grouping Map for this currency, creates it**'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 如果分组映射中没有这个货币的条目，则创建它**'
- en: '***5* Adds the currently traversed Transaction to the List of Transactions
    with the same currency**'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 将当前遍历的交易添加到具有相同货币的交易列表中**'
- en: 'If you’re an experienced Java developer, you’ll probably feel comfortable writing
    something like this, but you have to admit that it’s a lot of code for such a
    simple task. Even worse, this is probably harder to read than to write! The purpose
    of the code isn’t immediately evident at first glance, even though it can be expressed
    in a straightforward manner in plain English: “Group a list of transactions by
    their currency.” As you’ll learn in this chapter, you can achieve exactly the
    same result with a single statement by using a more general `Collector` parameter
    to the `collect` method on stream rather than the `toList` special case used in
    the previous chapter:'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一位经验丰富的Java开发者，你可能觉得写这样的代码很舒服，但你必须承认，对于这样一个简单的任务来说，这需要很多代码。更糟糕的是，这比写代码还难读！代码的目的在第一眼看来并不明显，尽管它可以用简单的英语直接表达：“按货币将交易列表分组。”正如你将在本章中学到的，你可以通过使用更通用的`Collector`参数来对流的`collect`方法进行操作，而不是使用前一章中使用的`toList`特殊情况，从而用单个语句达到完全相同的结果：
- en: '[PRE104]'
  id: totrans-679
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: The comparison is quite embarrassing, isn’t it?
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 这种比较相当尴尬，不是吗？
- en: 6.1\. Collectors in a nutshell
  id: totrans-681
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1\. 简要介绍收集器
- en: 'The previous example clearly shows one of the main advantages of functional-style
    programming over an imperative approach: you have to formulate the result you
    want to obtain the “what” and not the steps performed to obtain it, the “how.”
    In the previous example, the argument passed to the `collect` method is an implementation
    of the `Collector` interface, which is a recipe for how to build a summary of
    the elements in the stream. In the previous chapter, the `toList` recipe said,
    “Make a list of each element in turn.” In this example, the `groupingBy` recipe
    says, “Make a `Map` whose keys are (currency) buckets and whose values are a list
    of elements in those buckets.”'
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的例子清楚地展示了函数式编程相对于命令式方法的一个主要优势：你必须制定你想要获得的结果的“是什么”，而不是获得它的步骤，即“怎么做”。在前面的例子中，传递给`collect`方法的参数是实现`Collector`接口的实例，这是一个如何构建流中元素摘要的配方。在前一章中，`toList`配方说，“依次列出每个元素。”在这个例子中，`groupingBy`配方说，“创建一个`Map`，其键是（货币）桶，其值是这些桶中的元素列表。”
- en: 'The difference between the imperative and functional versions of this example
    is even more pronounced if you perform multilevel groupings: in that case the
    imperative code quickly becomes harder to read, maintain, and modify due to the
    number of deeply nested loops and conditions required. In comparison, the functional-style
    version, as you’ll discover in [section 6.3](#ch06lev1sec3), can be easily enhanced
    with an additional collector.'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你进行多级分组，这个例子中命令式和函数式版本之间的差异就更加明显：在这种情况下，由于需要大量嵌套循环和条件，命令式代码很快就会变得难以阅读、维护和修改。相比之下，正如你将在[第6.3节](#ch06lev1sec3)中发现的那样，函数式风格的版本可以很容易地通过添加额外的收集器来增强。
- en: 6.1.1\. Collectors as advanced reductions
  id: totrans-684
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.1\. 收集器作为高级归约
- en: 'This last observation brings up another typical benefit of a well-designed
    functional API: its higher degree of composability and reusability. Collectors
    are extremely useful, because they provide a concise yet flexible way to define
    the criteria that `collect` uses to produce the resulting collection. More specifically,
    invoking the `collect` method on a stream triggers a reduction operation (parameterized
    by a `Collector`) on the elements of the stream itself. This *reduction operation*,
    illustrated in [figure 6.1](#ch06fig01), does for you internally what you had
    to code imperatively in [listing 6.1](#ch06ex01). It traverses each element of
    the stream and lets the `Collector` process them.'
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 这个最后的观察结果又提出了另一个典型的好处：一个精心设计的函数式API具有更高的可组合性和可重用性。收集器非常有用，因为它们提供了一种简洁而灵活的方式来定义`collect`用于生成结果集合的准则。更具体地说，在流上调用`collect`方法会触发一个（由`Collector`参数化的）对流本身的元素进行的归约操作（如[图6.1](#ch06fig01)所示）。它遍历流中的每个元素，并让`Collector`处理它们。
- en: Figure 6.1\. The reduction process grouping the transactions by currency
  id: totrans-686
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.1\. 按货币对交易进行分组的过程
- en: '![](Images/06fig01_alt.jpg)'
  id: totrans-687
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/06fig01_alt.jpg)'
- en: Typically, the `Collector` applies a transforming function to the element. Quite
    often this is the identity transformation, which has no effect (for example, as
    in `toList`). The function then accumulates the result in a data structure that
    forms the final output of this process. For instance, in our transaction-grouping
    example shown previously, the transformation function extracts the currency from
    each transaction, and subsequently the transaction itself is accumulated in the
    resulting `Map`, using the currency as key.
  id: totrans-688
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，`Collector`会对元素应用一个转换函数。这通常是无效果的恒等转换（例如，在`toList`中）。然后该函数将结果累积在构成此过程最终输出的数据结构中。例如，在我们之前展示的交易分组示例中，转换函数从每个交易中提取货币，然后交易本身使用货币作为键累积到结果`Map`中。
- en: 'The implementation of the methods of the `Collector` interface defines how
    to perform a reduction operation on a stream, such as the one in our currency
    example. We’ll investigate how to create customized collectors in [sections 6.5](#ch06lev1sec5)
    and [6.6](#ch06lev1sec6). But the `Collectors` utility class provides lots of
    static factory methods to conveniently create an instance of the most common collectors
    that are ready to use. The most straightforward and frequently used collector
    is the `toList` static method, which gathers all the elements of a stream into
    a `List`:'
  id: totrans-689
  prefs: []
  type: TYPE_NORMAL
  zh: '`Collector`接口方法的实现定义了如何在流上执行减少操作，例如我们货币示例中的那种。我们将在[第6.5节](#ch06lev1sec5)和[第6.6节](#ch06lev1sec6)中研究如何创建自定义收集器。但`Collectors`实用类提供了许多静态工厂方法，方便地创建最常用的收集器实例，这些收集器已准备好使用。最直接且最常用的收集器是`toList`静态方法，它将流的所有元素收集到一个`List`中：'
- en: '[PRE105]'
  id: totrans-690
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 6.1.2\. Predefined collectors
  id: totrans-691
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.2\. 预定义收集器
- en: 'In the rest of this chapter, we’ll mainly explore the features of the predefined
    collectors, those that can be created from the factory methods (such as `groupingBy`)
    provided by the `Collectors` class. These offer three main functionalities:'
  id: totrans-692
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的剩余部分，我们将主要探讨预定义收集器的功能，这些收集器可以通过`Collectors`类提供的工厂方法（例如`groupingBy`）创建。这些提供了三个主要功能：
- en: Reducing and summarizing stream elements to a single value
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将流元素减少并汇总为单个值
- en: Grouping elements
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元素分组
- en: Partitioning elements
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元素分区
- en: We start with collectors that allow you to reduce and summarize. These are handy
    in a variety of use cases, such as finding the total amount of the transacted
    values in the list of transactions in the previous example.
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从允许您减少和汇总的收集器开始。这些在多种用例中都很方便，例如在先前的示例中找到交易列表中交易值的总额。
- en: You’ll then see how to group the elements of a stream, generalizing the previous
    example to multiple levels of grouping or combining different collectors to apply
    further reduction operations on each of the resulting subgroups. We’ll also describe
    *partitioning* as a special case of grouping, using a predicate (a one-argument
    function returning a boolean) as a grouping function.
  id: totrans-697
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您将了解如何对流的元素进行分组，将先前的示例推广到多级分组或结合不同的收集器以对每个结果子组应用进一步的减少操作。我们还将描述*分区*作为分组的一个特殊情况，使用谓词（一个返回布尔值的单参数函数）作为分组函数。
- en: At the end of [section 6.4](#ch06lev1sec4) you’ll find a table summarizing all
    the predefined collectors explored in this chapter. Finally, in [section 6.5](#ch06lev1sec5)
    you’ll learn more about the `Collector` interface before you explore (in [section
    6.6](#ch06lev1sec6)) how you can create your own custom collectors to be used
    in the cases not covered by the factory methods of the `Collectors` class.
  id: totrans-698
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6.4节](#ch06lev1sec4)的末尾，您将找到一个总结本章中探索的所有预定义收集器的表格。最后，在[第6.5节](#ch06lev1sec5)中，在您探索（在[第6.6节](#ch06lev1sec6)）如何创建自己的自定义收集器以用于`Collectors`类的工厂方法未涵盖的情况之前，您将了解更多关于`Collector`接口的信息。
- en: 6.2\. Reducing and summarizing
  id: totrans-699
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2\. 减少 和 汇总
- en: 'To illustrate the range of possible collector instances that can be created
    from the `Collectors` factory class, we’ll reuse the domain we introduced in the
    previous chapter: a menu consisting of a list of delicious dishes!'
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明可以从`Collectors`工厂类创建的可能收集器实例的范围，我们将重用我们在前一章中引入的领域：一份由美味佳肴组成的菜单！
- en: 'As you learned, collectors (the parameters to the `stream` method `collect`)
    are typically used in cases where it’s necessary to reorganize the stream’s items
    into a collection. But more generally, they can be used every time you want to
    combine all the items in the stream into a single result. This result can be of
    any type, as complex as a multilevel map representing a tree or as simple as a
    single integer, perhaps representing the sum of all the calories in the menu.
    We’ll look at both of these result types: single integers in [section 6.2.2](#ch06lev2sec4)
    and multilevel grouping in [section 6.3.1](#ch06lev2sec7).'
  id: totrans-701
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所学的，收集器（`stream` 方法的 `collect` 参数）通常用于需要将流的项目重新组织到集合中的情况。但更普遍的是，它们可以在你想将流中的所有项目组合成单个结果时使用。这个结果可以是任何类型，从表示树的复杂的多级映射到表示菜单中所有卡路里总和的单个整数。我们将查看这两种结果类型：[第6.2.2节](#ch06lev2sec4)
    中的单个整数和 [第6.3.1节](#ch06lev2sec7) 中的多级分组。
- en: 'As a first simple example, let’s count the number of dishes in the menu, using
    the collector returned by the `counting` factory method:'
  id: totrans-702
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一个简单的例子，让我们使用由 `counting` 工厂方法返回的收集器来计算菜单中的菜品种数：
- en: '[PRE106]'
  id: totrans-703
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: You can write this far more directly as
  id: totrans-704
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以更直接地写成这样
- en: '[PRE107]'
  id: totrans-705
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: but the `counting` collector can be useful when used in combination with other
    collectors, as we’ll demonstrate later.
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，当与其他收集器结合使用时，`counting` 收集器可能很有用，我们将在后面演示。
- en: In the rest of this chapter, we’ll assume that you’ve imported all the static
    factory methods of the `Collectors` class with
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将假设你已经导入了 `Collectors` 类的所有静态工厂方法，如下所示：
- en: '[PRE108]'
  id: totrans-708
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: so you can write `counting()` instead of `Collectors.counting()` and so on.
  id: totrans-709
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以写 `counting()` 而不是 `Collectors.counting()` 等等。
- en: Let’s continue exploring simple predefined collectors by looking at how you
    can find the maximum and minimum values in a stream.
  id: totrans-710
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续通过查看如何在流中找到最大值和最小值来探索简单的预定义收集器。
- en: 6.2.1\. Finding maximum and minimum in a stream of values
  id: totrans-711
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1\. 在值流中查找最大值和最小值
- en: 'Suppose you want to find the highest-calorie dish in the menu. You can use
    two collectors, `Collectors.maxBy` and `Collectors.minBy`, to calculate the maximum
    or minimum value in a stream. These two collectors take a `Comparator` as argument
    to compare the elements in the stream. Here you create a `Comparator` comparing
    dishes based on their calorie content and pass it to `Collectors.maxBy`:'
  id: totrans-712
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想要找到菜单中卡路里最高的菜。你可以使用两个收集器，`Collectors.maxBy` 和 `Collectors.minBy`，来计算流中的最大值或最小值。这两个收集器接受一个
    `Comparator` 作为参数，用于比较流中的元素。在这里，你创建了一个基于卡路里含量的 `Comparator`，并将其传递给 `Collectors.maxBy`：
- en: '[PRE109]'
  id: totrans-713
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: You may wonder what the `Optional<Dish>` is about. To answer this we have to
    ask the question, ”What if `menu` were empty?” There’s no dish to return! Java
    8 introduces `Optional`, which is a container that may or may not contain a value.
    Here it perfectly represents the idea that there may or may not be a dish returned.
    We briefly mentioned it in [chapter 5](kindle_split_016.xhtml#ch05) when you encountered
    the method `findAny`. Don’t worry about it for now; we devote [chapter 11](kindle_split_024.xhtml#ch11)
    to the study of `Optional<T>` and its operations.
  id: totrans-714
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道 `Optional<Dish>` 是什么意思。为了回答这个问题，我们必须问，“如果 `menu` 是空的怎么办？”没有菜可以返回！Java
    8 引入了 `Optional`，它是一个可能包含或不包含值的容器。在这里，它完美地代表了可能返回或不返回菜的想法。我们简要地提到了它，在 [第5章](kindle_split_016.xhtml#ch05)
    中，当你遇到 `findAny` 方法时。现在不必担心它；我们将在 [第11章](kindle_split_024.xhtml#ch11) 中专门研究 `Optional<T>`
    及其操作。
- en: Another common reduction operation that returns a single value is to sum the
    values of a numeric field of the objects in a stream. Alternatively, you may want
    to average the values. Such operations are called *summarization* operations.
    Let’s see how you can express them using collectors.
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的返回单个值的归约操作是将流中对象的数值字段的值相加。或者，你可能想要计算平均值。这样的操作称为 *汇总* 操作。让我们看看你如何使用收集器来表示它们。
- en: 6.2.2\. Summarization
  id: totrans-716
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2\. 汇总
- en: 'The `Collectors` class provides a specific factory method for summing: `Collectors
    .summingInt`. It accepts a function that maps an object into the `int` that has
    to be summed and returns a collector that, when passed to the usual `collect`
    method, performs the requested summarization. For instance, you can find the total
    number of calories in your menu list with'
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: '`Collectors` 类提供了一个特定的工厂方法用于求和：`Collectors.summingInt`。它接受一个函数，该函数将一个对象映射到要相加的
    `int` 值，并返回一个收集器，当传递给常规的 `collect` 方法时，执行所需的汇总。例如，你可以使用以下方法找到菜单列表中的总卡路里数：'
- en: '[PRE110]'
  id: totrans-718
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: Here the collection process proceeds as illustrated in [figure 6.2](#ch06fig02).
    While traversing the stream each dish is mapped into its number of calories, and
    that number is added to an accumulator starting from an initial value (in this
    case the value is `0`).
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，收集过程如[图6.2](#ch06fig02)所示。在遍历流的过程中，每个菜品被映射为其卡路里数，然后从这个初始值（在这种情况下是`0`）开始将该数字添加到一个累加器中。
- en: Figure 6.2\. The aggregation process of the `summingInt` collector
  id: totrans-720
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.2\. `summingInt`收集器的聚合过程
- en: '![](Images/06fig02_alt.jpg)'
  id: totrans-721
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/06fig02_alt.jpg)'
- en: The `Collectors.summingLong` and `Collectors.summingDouble` methods behave exactly
    the same way and can be used where the field to be summed is respectively a `long`
    or a `double`.
  id: totrans-722
  prefs: []
  type: TYPE_NORMAL
  zh: '`Collectors.summingLong`和`Collectors.summingDouble`方法的行为完全相同，并且可以在需要分别求和的字段是`long`或`double`时使用。'
- en: 'But there’s more to summarization than mere summing. A `Collectors.averaging-Int`,
    together with its `averagingLong` and `averagingDouble` counterparts, is also
    available to calculate the average of the same set of numeric values:'
  id: totrans-723
  prefs: []
  type: TYPE_NORMAL
  zh: 但总结不仅仅是简单的求和。`Collectors.averaging-Int`及其对应的`averagingLong`和`averagingDouble`也可用于计算相同数值集合的平均值：
- en: '[PRE111]'
  id: totrans-724
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'So far, you’ve seen how to use collectors to count the elements in a stream,
    find the maximum and minimum values of a numeric property of those elements, and
    calculate their sum and average. Quite often, though, you may want to retrieve
    two or more of these results, and possibly you’d like to do it in a single operation.
    In this case, you can use the collector returned by the `summarizingInt` factory
    method. For example, you can count the elements in the menu and obtain the sum,
    average, maximum, and minimum of the calories contained in each dish with a single
    `summarizing` operation:'
  id: totrans-725
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经看到了如何使用收集器来计算流中的元素数量，找到这些元素的数值属性的极大值和极小值，并计算它们的总和和平均值。尽管如此，你经常可能想要检索两个或多个这些结果，并且可能希望在一个操作中完成。在这种情况下，你可以使用由`summarizingInt`工厂方法返回的收集器。例如，你可以通过单个`summarizing`操作来计算菜单中的元素数量，并获取每个菜品中包含的卡路里的总和、平均值、最大值和最小值：
- en: '[PRE112]'
  id: totrans-726
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'This collector gathers all that information in a class called `IntSummaryStatistics`
    that provides convenient getter methods to access the results. Printing the `menu-Statistic`
    object produces the following output:'
  id: totrans-727
  prefs: []
  type: TYPE_NORMAL
  zh: 这个收集器将所有信息收集到一个名为`IntSummaryStatistics`的类中，该类提供了方便的getter方法来访问结果。打印`menu-Statistic`对象将产生以下输出：
- en: '[PRE113]'
  id: totrans-728
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: As usual, there are corresponding `summarizingLong` and `summarizingDouble`
    factory methods with associated types `LongSummaryStatistics` and `DoubleSummary-Statistics`.
    These are used when the property to be collected is a primitive-type `long` or
    a `double`.
  id: totrans-729
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，还有相应的`summarizingLong`和`summarizingDouble`工厂方法，以及相关的类型`LongSummaryStatistics`和`DoubleSummary-Statistics`。这些在需要收集的属性是原始类型的`long`或`double`时使用。
- en: 6.2.3\. Joining Strings
  id: totrans-730
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.3\. 连接字符串
- en: 'The collector returned by the `joining` factory method concatenates into a
    single string, all strings resulting from invoking the `toString` method on each
    object in the stream. This means you can concatenate the names of all the dishes
    in the menu as follows:'
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 由`joining`工厂方法返回的收集器将所有从流中每个对象调用`toString`方法得到的字符串连接成一个单一的字符串。这意味着你可以按照以下方式连接菜单中所有菜品的名称：
- en: '[PRE114]'
  id: totrans-732
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'Note that `joining` internally makes use of a `StringBuilder` to append the
    generated strings into one. Also note that if the `Dish` class had a `toString`
    method returning the dish’s name, you’d obtain the same result without needing
    to map over the original stream with a function extracting the name from each
    dish:'
  id: totrans-733
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`joining`内部使用`StringBuilder`来将生成的字符串追加到一个字符串中。另外，注意如果`Dish`类有一个返回菜品名称的`toString`方法，你将获得相同的结果，而无需使用函数从每个菜品中提取名称来映射原始流：
- en: '[PRE115]'
  id: totrans-734
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: Both produce the string
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 它们都产生相同的字符串
- en: '[PRE116]'
  id: totrans-736
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: which is hard to read. Fortunately, the `joining` factory method is overloaded,
    with one of its overloaded variants taking a string used to delimit two consecutive
    elements, so you can obtain a comma-separated list of the dishes’ names with
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 这很难阅读。幸运的是，`joining`工厂方法是重载的，其中一个重载变体接受一个用于分隔两个连续元素的字符串，因此你可以使用逗号分隔的菜品名称列表：
- en: '[PRE117]'
  id: totrans-738
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: which, as expected, will generate
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期，这将生成
- en: '[PRE118]'
  id: totrans-740
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: Until now, we’ve explored various collectors that reduce a stream to a single
    value. In the next section, we’ll demonstrate how all the reduction processes
    of this form are special cases of the more general reduction collector provided
    by the `Collectors .reducing` factory method.
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，我们探讨了各种将流归约到单个值的收集器。在下一节中，我们将演示所有这种形式的归约过程都是`Collectors.reducing`工厂方法提供的更一般归约收集器的特例。
- en: 6.2.4\. Generalized summarization with reduction
  id: totrans-742
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.4\. 使用归约进行泛化总结
- en: 'All the collectors we’ve discussed so far are, in reality, only convenient
    specializations of a reduction process that can be defined using the `reducing`
    factory method. The `Collectors.reducing` factory method is a generalization of
    all of them. The special cases discussed earlier are arguably provided only for
    programmer convenience. (But remember that programmer convenience and readability
    are of prime importance!) For instance, it’s *possible* to calculate the total
    calories in your menu with a collector created from the `reducing` method as follows:'
  id: totrans-743
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论的所有收集器实际上只是可以使用`reducing`工厂方法定义的归约过程的便利特例。`Collectors.reducing`工厂方法是对它们的泛化。前面讨论的特殊情况可能只是为了程序员的便利而提供的。（但请记住，程序员的便利性和可读性是最重要的！）例如，你可以使用从`reducing`方法创建的收集器来计算菜单中的总卡路里，如下所示：
- en: '[PRE119]'
  id: totrans-744
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'It takes three arguments:'
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 它需要三个参数：
- en: The first argument is the starting value of the reduction operation and will
    also be the value returned in the case of a stream with no elements, so clearly
    `0` is the appropriate value in the case of a numeric sum.
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个参数是归约操作的起始值，在没有元素的流的情况下，它也将是返回的值，因此显然在数值求和的情况下`0`是合适的值。
- en: The second argument is the same function you used in [section 6.2.2](#ch06lev2sec4)
    to transform a dish into an `int` representing its calorie content.
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个参数是你在[第6.2.2节](#ch06lev2sec4)中用来将菜品转换为一个表示其卡路里含量的`int`的同一个函数。
- en: The third argument is a `BinaryOperator` that aggregates two items into a single
    value of the same type. Here, it sums two `int`s.
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个参数是一个`BinaryOperator`，它将两个项目聚合为同一类型的单个值。在这里，它将两个`int`相加。
- en: 'Similarly, you could find the highest-calorie dish using the one-argument version
    of `reducing` as follows:'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你可以使用`reducing`的一个参数版本找到最高卡路里的菜品，如下所示：
- en: '[PRE120]'
  id: totrans-750
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: You can think of the collector created with the one-argument `reducing` factory
    method as a particular case of the three-argument method, which uses the first
    item in the stream as a starting point and an *identity function* (a function
    that returns its input argument as is) as a transformation function. This also
    implies that the one-argument `reducing` collector won’t have any starting point
    when passed to the `collect` method of an empty stream and, as we explained in
    [section 6.2.1](#ch06lev2sec3), for this reason it returns an `Optional<Dish>`
    object.
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将使用一个参数的`reducing`工厂方法创建的收集器视为三个参数方法的特例，它使用流中的第一个项目作为起点，并使用一个*恒等函数*（一个返回其输入参数不变的功能）作为转换函数。这也意味着当将一个参数的`reducing`收集器传递给空流的`collect`方法时，它将没有起始点，正如我们在[第6.2.1节](#ch06lev2sec3)中解释的那样，因此它返回一个`Optional<Dish>`对象。
- en: '|  |'
  id: totrans-752
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Collect vs. reduce**'
  id: totrans-753
  prefs: []
  type: TYPE_NORMAL
  zh: '**收集与归约**'
- en: 'We’ve discussed reductions a lot in the previous chapter and this one. You
    may wonder what the differences between the `collect` and `reduce` methods of
    the stream interface are, because often you can obtain the same results using
    either method. For instance, you can achieve what is done by the `toList Collector`
    using the `reduce` method as follows:'
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一章和这一章中讨论了很多归约。你可能想知道流接口的`collect`和`reduce`方法之间的区别，因为通常你可以使用任一方法获得相同的结果。例如，你可以使用`reduce`方法实现`toList
    Collector`所做的工作，如下所示：
- en: '[PRE121]'
  id: totrans-755
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'This solution has two problems: a semantic one and a practical one. The semantic
    problem lies in the fact that the `reduce` method is meant to combine two values
    and produce a new one; it’s an immutable reduction. In contrast, the `collect`
    method is designed to mutate a container to accumulate the result it’s supposed
    to produce. This means that the previous snippet of code is misusing the `reduce`
    method, because it’s mutating in place the `List` used as accumulator. As you’ll
    see in more detail in the next chapter, using the `reduce` method with the wrong
    semantic is also the cause of a practical problem: this reduction process can’t
    work in parallel, because the concurrent modification of the same data structure
    operated by multiple threads can corrupt the `List` itself. In this case, if you
    want thread safety, you’ll need to allocate a new `List` every time, which would
    impair performance by object allocation. This is the main reason why the `collect`
    method is useful for expressing reduction working on a mutable container but crucially
    in a parallel-friendly way, as you’ll learn later in the chapter.'
  id: totrans-756
  prefs: []
  type: TYPE_NORMAL
  zh: 这种解决方案有两个问题：一个是语义问题，另一个是实际问题。语义问题在于`reduce`方法旨在合并两个值并产生一个新的值；它是一个不可变的归约。相比之下，`collect`方法旨在修改一个容器以累积它应该产生的结果。这意味着之前的代码片段错误地使用了`reduce`方法，因为它正在原地修改用作累加器的`List`。正如你将在下一章中更详细地看到的那样，使用具有错误语义的`reduce`方法也是实际问题的原因：这个归约过程不能并行工作，因为多个线程对相同数据结构的并发修改可能会损坏`List`本身。在这种情况下，如果你想保证线程安全，你将需要每次都分配一个新的`List`，这将通过对象分配来损害性能。这正是`collect`方法在表达对可变容器进行归约时非常有用，但关键是在并行友好方式下的原因，你将在本章后面学到。
- en: '|  |'
  id: totrans-757
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'Collection framework flexibility: doing the same operation in different ways'
  id: totrans-758
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 集合框架灵活性：以不同的方式执行相同的操作
- en: 'You can further simplify the previous sum example using the `reducing` collector
    by using a reference to the `sum` method of the `Integer` class instead of the
    lambda expression you used to encode the same operation. This results in the following:'
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`reducing`收集器进一步简化之前的求和示例，通过使用`Integer`类的`sum`方法的引用来代替你用来编码相同操作的lambda表达式。这导致以下结果：
- en: '[PRE122]'
  id: totrans-760
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '***1* Initial value**'
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 初始值**'
- en: '***2* Transformation function**'
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 变换函数**'
- en: '***3* Aggregating function**'
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 聚合函数**'
- en: Logically, this reduction operation proceeds as shown in [figure 6.3](#ch06fig03),
    where an accumulator—initialized with a starting value—is iteratively combined
    using an aggregating function, with the result of the application of the transforming
    function on each element of the stream.
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: 从逻辑上讲，这种归约操作按照[图6.3](#ch06fig03)所示进行，其中累加器使用起始值初始化，然后通过聚合函数迭代组合，每个流元素的变换函数应用的结果。
- en: Figure 6.3\. The reduction process calculating the total number of calories
    in the menu
  id: totrans-765
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.3. 计算菜单中总卡路里数的归约过程
- en: '![](Images/06fig03_alt.jpg)'
  id: totrans-766
  prefs: []
  type: TYPE_IMG
  zh: '![图6.3](Images/06fig03_alt.jpg)'
- en: 'The `counting` collector we mentioned at the beginning of [section 6.2](#ch06lev1sec2)
    is, in reality, similarly implemented using the three-argument `reducing` factory
    method. It transforms each element in the stream into an object of type `Long`
    with value `1` and then sums all these ones. It is implemented as follows:'
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第6.2节](#ch06lev1sec2)开头提到的`counting`收集器实际上是通过使用三个参数的`reducing`工厂方法类似实现的。它将流中的每个元素转换为一个类型为`Long`且值为`1`的对象，然后对所有这些`1`求和。它的实现如下：
- en: '[PRE123]'
  id: totrans-768
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '|  |'
  id: totrans-769
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Use of the generic `?` wildcard**'
  id: totrans-770
  prefs: []
  type: TYPE_NORMAL
  zh: '**泛型`?`通配符的使用**'
- en: In the code snippet just shown, you probably noticed the `?` wildcard, used
    as the second generic type in the signature of the collector returned by the `counting`
    factory method. You should already be familiar with this notation, especially
    if you use the Java Collection Framework quite frequently. But here it means only
    that the type of the collector’s accumulator is unknown, or equivalently the accumulator
    itself can be of any type. We used it here to exactly report the signature of
    the method as originally defined in the `Collectors` class, but in the rest of
    the chapter, we avoid any wildcard notation to keep the discussion as simple as
    possible.
  id: totrans-771
  prefs: []
  type: TYPE_NORMAL
  zh: 在刚刚展示的代码片段中，你可能注意到了用作`counting`工厂方法返回的收集器签名的第二个泛型类型中的`?`通配符。你应该已经熟悉这种表示法，尤其是如果你经常使用Java集合框架的话。但在这里，它仅仅意味着收集器的累加器类型是未知的，或者等价地说，累加器本身可以是任何类型。我们在这里使用它是为了精确地报告方法在`Collectors`类中最初定义的签名，但在本章的其余部分，我们避免使用任何通配符表示法，以使讨论尽可能简单。
- en: '|  |'
  id: totrans-772
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: 'We already observed in [chapter 5](kindle_split_016.xhtml#ch05) that there’s
    another way to perform the same operation without using a collector—by mapping
    the stream of dishes into the number of calories of each dish and then reducing
    this resulting stream with the same method reference used in the previous version:'
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第5章](kindle_split_016.xhtml#ch05)中观察到，还有另一种方法可以执行相同的操作而不使用收集器——通过将菜品流映射到每个菜品的卡路里数，然后使用与上一个版本中相同的方法引用来减少这个结果流：
- en: '[PRE124]'
  id: totrans-774
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: 'Note that, like any one-argument `reduce` operation on a stream, the invocation
    `reduce(Integer::sum)` doesn’t return an `int` but an `Optional<Integer>` to manage
    the case of a reduction operation over an empty stream in a null-safe way. Here
    you extract the value inside the `Optional` object using its `get` method. Note
    that in this case using the `get` method is safe only because you’re sure that
    the stream of dishes isn’t empty. In general, as you’ll learn in [chapter 10](kindle_split_022.xhtml#ch10),
    it’s safer to unwrap the value eventually contained in an `Optional` using a method
    that also allows you to provide a default, such as `orElse` or `orElseGet`. Finally,
    and even more concisely, you can achieve the same result by mapping the stream
    to an `IntStream` and then invoking the `sum` method on it:'
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，像任何在流上的单参数`reduce`操作一样，调用`reduce(Integer::sum)`返回的不是`int`，而是一个`Optional<Integer>`，以安全的方式处理空流上的归约操作。在这里，您使用其`get`方法提取`Optional`对象内的值。请注意，在这种情况下使用`get`方法是安全的，仅因为您确信菜品的流不为空。一般来说，正如您将在[第10章](kindle_split_022.xhtml#ch10)中学习的，使用允许您提供默认值的方法（如`orElse`或`orElseGet`）来解包`Optional`中最终包含的值更安全。最后，并且更加简洁，您可以通过将流映射到`IntStream`并对其调用`sum`方法来实现相同的结果：
- en: '[PRE125]'
  id: totrans-776
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: Choosing the best solution for your situation
  id: totrans-777
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 选择最适合您情况的最佳解决方案
- en: Once again, this demonstrates how functional programming in general (and the
    new API based on functional-style principles added to the Collections framework
    in Java 8 in particular) often provides multiple ways to perform the same operation.
    This example also shows that collectors are somewhat more complex to use than
    the methods directly available on the Streams interface, but in exchange they
    offer higher levels of abstraction and generalization and are more reusable and
    customizable.
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: 再次证明，一般而言（特别是在Java 8中添加到Collections框架中的基于函数式原则的新API），函数式编程通常提供多种执行相同操作的方法。此示例还表明，收集器比直接在Streams接口上可用的方法稍微复杂一些，但作为交换，它们提供了更高层次的抽象和泛化，并且更可重用和可定制。
- en: Our suggestion is to explore the largest number of solutions possible to the
    problem at hand, but always choose the most specialized one that’s general enough
    to solve it. This is often the best decision for both readability and performance
    reasons. For instance, to calculate the total calories in our menu, we’d prefer
    the last solution (using `IntStream`) because it’s the most concise and likely
    also the most readable one. At the same time, it’s also the one that performs
    best, because `IntStream` lets us avoid all the *auto-unboxing* operations, or
    implicit conversions from `Integer` to `int`, that are useless in this case.
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的建议是探索尽可能多的解决方案来解决问题，但始终选择最专业化的解决方案，它足够通用以解决问题。这通常是考虑可读性和性能的最佳决定。例如，为了计算我们菜单中的总卡路里，我们更喜欢最后一个解决方案（使用`IntStream`），因为它最简洁，也可能是最易读的。同时，它也是性能最好的，因为`IntStream`让我们避免了所有无用的*自动装箱*操作，或者从`Integer`到`int`的隐式转换，在这种情况下这些操作都是不必要的。
- en: Next, test your understanding of how `reducing` can be used as a generalization
    of other collectors by working through the exercise in quiz 6.1.
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，通过完成第6.1节的练习来测试您对如何将`reducing`用作其他收集器泛化的理解。
- en: '|  |'
  id: totrans-781
  prefs: []
  type: TYPE_TB
  zh: '|'
- en: '**Quiz 6.1: Joining strings with reducing**'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习6.1：使用reducing连接字符串**'
- en: Which of the following statements using the `reducing` collector are valid replacements
    for this `joining` collector (as used in [section 6.2.3](#ch06lev2sec5))?
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: 以下哪个使用`reducing`收集器的陈述是此`joining`收集器（如[第6.2.3节](#ch06lev2sec5)中所述）的有效替代品？
- en: '[PRE126]'
  id: totrans-784
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '[PRE127]'
  id: totrans-785
  prefs:
  - PREF_OL
  type: TYPE_PRE
  zh: '[PRE127]'
- en: '[PRE128]'
  id: totrans-786
  prefs:
  - PREF_OL
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '[PRE129]'
  id: totrans-787
  prefs:
  - PREF_OL
  type: TYPE_PRE
  zh: '[PRE129]'
- en: '**Answer:**'
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: Statements 1 and 3 are valid, whereas 2 doesn’t compile.
  id: totrans-789
  prefs: []
  type: TYPE_NORMAL
  zh: 陈述1和3是有效的，而2无法编译。
- en: This converts each dish in its name, as done by the original statement using
    the `joining` collector, and then reduces the resulting stream of strings using
    a `String` as accumulator and appending to it the names of the dishes one by one.
  id: totrans-790
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将每个菜品的名称转换为，就像原始语句使用`joining`收集器所做的那样，然后使用`String`作为累加器，并逐个将菜品的名称追加到它上面。
- en: This doesn’t compile because the one argument that `reducing` accepts is a `BinaryOperator<T>`
    that’s a `BiFunction<T,T,T>`. This means that it wants a function taking two arguments
    and returns a value of the same type, but the lambda expression used there has
    two dishes as arguments but returns a string.
  id: totrans-791
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这不能编译，因为`reducing`接受的单一参数是一个`BinaryOperator<T>`，它是一个`BiFunction<T,T,T>`。这意味着它需要一个接受两个参数并返回相同类型值的函数，但那里使用的lambda表达式有两个菜肴作为参数，但返回一个字符串。
- en: This starts the reduction process with an empty string as the accumulator, and
    when traversing the stream of dishes, it converts each dish to its name and appends
    this name to the accumulator. Note that, as we mentioned, `reducing` doesn’t need
    the three arguments to return an `Optional` because in the case of an empty stream
    it can return a more meaningful value, which is the empty string used as the initial
    accumulator value.
  id: totrans-792
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这以空字符串作为累加器开始减少过程，并在遍历菜肴流时，将每个菜肴转换为它的名称并将其追加到累加器中。注意，正如我们提到的，`reducing`不需要三个参数来返回一个`Optional`，因为在空流的情况下，它可以返回一个更有意义的值，即用作初始累加器值的空字符串。
- en: Note that even though statements 1 and 3 are valid replacements for the `joining`
    collector, they’ve been used here to demonstrate how the `reducing` one can be
    seen, at least conceptually, as a generalization of all other collectors discussed
    in this chapter. Nevertheless, for all practical purposes we always suggest using
    the `joining` collector for both readability and performance reasons.
  id: totrans-793
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，尽管语句1和3是`joining`收集器的有效替代，但它们在这里被用来展示`reducing`至少在概念上可以被视为本章讨论的所有其他收集器的泛化。尽管如此，出于所有实际目的，我们始终建议出于可读性和性能原因使用`joining`收集器。
- en: '|  |'
  id: totrans-794
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 6.3\. Grouping
  id: totrans-795
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3\. 分组
- en: 'A common database operation is to group items in a set, based on one or more
    properties. As you saw in the earlier transactions-currency-grouping example,
    this operation can be cumbersome, verbose, and error-prone when implemented with
    an imperative style. But it can be easily translated in a single, readable statement
    by rewriting it in a more functional style as encouraged by Java 8\. As a second
    example of how this feature works, suppose you want to classify the dishes in
    the menu according to their type, putting the ones containing meat in a group,
    the ones with fish in another group, and all others in a third group. You can
    easily perform this task using a collector returned by the `Collectors.groupingBy`
    factory method, as follows:'
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的数据库操作是根据一个或多个属性对集合中的项目进行分组。正如你在前面的交易货币分组示例中看到的，当以命令式风格实现时，这个操作可能会很繁琐、冗长且容易出错。但通过使用Java
    8鼓励的更函数式风格的单一、可读的语句，它可以很容易地翻译成。作为此功能如何工作的第二个示例，假设你想要根据类型对菜单中的菜肴进行分类，将含肉的菜肴放在一个组中，含鱼的放在另一个组中，所有其他菜肴放在第三个组中。你可以很容易地使用由`Collectors.groupingBy`工厂方法返回的收集器执行此任务，如下所示：
- en: '[PRE130]'
  id: totrans-797
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'This will result in the following `Map`:'
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下`Map`：
- en: '[PRE131]'
  id: totrans-799
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: Here, you pass to the `groupingBy` method a `Function` (expressed in the form
    of a method reference) extracting the corresponding `Dish.Type` for each `Dish`
    in the stream. We call this `Function` a *classification* function specifically
    because it’s used to classify the elements of the stream into different groups.
    The result of this grouping operation, shown in [figure 6.4](#ch06fig04), is a
    `Map` having as map key the value returned by the classification function and
    as corresponding map value a list of all the items in the stream having that classified
    value. In the menu-classification example, a key is the type of dish, and its
    value is a list containing all the dishes of that type.
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你将一个`Function`（以方法引用的形式表达）传递给`groupingBy`方法，该`Function`提取流中每个`Dish`对应的`Dish.Type`。我们称这个`Function`为*分类*函数，特别是因为它用于将流中的元素分类到不同的组中。这种分组操作的结果，如[图6.4](#ch06fig04)所示，是一个`Map`，其映射键是分类函数返回的值，相应的映射值是具有该分类值的流中所有项的列表。在菜单分类示例中，键是菜肴的类型，其值是包含该类型所有菜肴的列表。
- en: Figure 6.4\. Classification of an item in the stream during the grouping process
  id: totrans-801
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.4\. 分组过程中流中项目的分类
- en: '![](Images/06fig04_alt.jpg)'
  id: totrans-802
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/06fig04_alt.jpg)'
- en: 'But it isn’t always possible to use a method reference as a classification
    function, because you may wish to classify using something more complex than a
    simple property accessor. For instance, you could decide to classify as “diet”
    all dishes with 400 calories or fewer, set to “normal” the dishes having between
    400 and 700 calories, and set to “fat” the ones with more than 700 calories. Because
    the author of the `Dish` class unhelpfully didn’t provide such an operation as
    a method, you can’t use a method reference in this case, but you can express this
    logic in a lambda expression:'
  id: totrans-803
  prefs: []
  type: TYPE_NORMAL
  zh: 但并不是总是可以使用方法引用作为分类函数，因为你可能希望使用比简单的属性访问器更复杂的东西进行分类。例如，你可以决定将所有卡路里在400或以下的菜品分类为“减肥”，将400到700卡路里的菜品设置为“正常”，将超过700卡路里的菜品设置为“高脂肪”。因为
    `Dish` 类的作者没有提供这样的操作作为方法，所以在这种情况下你不能使用方法引用，但你可以在 lambda 表达式中表达这个逻辑：
- en: '[PRE132]'
  id: totrans-804
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: Now you’ve seen how to group the dishes in the menu, both by their type and
    by calories, but it could be also quite common that you may need to further manipulate
    the results of the original grouping, and in the next section we’ll show how you
    achieve this.
  id: totrans-805
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了如何根据菜品的类型和卡路里将菜单中的菜品分组，但也许你还需要进一步操作原始分组的成果，在下一节中我们将展示如何实现这一点。
- en: 6.3.1\. Manipulating grouped elements
  id: totrans-806
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.1\. 操作分组元素
- en: 'Frequently after performing a grouping operation you may need to manipulate
    the elements in each resulting group. Suppose, for example, that you want to filter
    only the caloric dishes, let’s say the ones with more than 500 calories. You may
    argue that in this case you could apply this filtering predicate before the grouping
    like the following:'
  id: totrans-807
  prefs: []
  type: TYPE_NORMAL
  zh: 经常在执行分组操作后，你可能需要操作每个结果组中的元素。例如，假设你只想过滤卡路里较高的菜品，比如说超过500卡路里的。你可能认为在这种情况下，你可以在分组之前应用这个过滤谓词，如下所示：
- en: '[PRE133]'
  id: totrans-808
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: 'This solution works but has a possibly relevant drawback. If you try to use
    it on the dishes in our menu, you will obtain a `Map` like the following:'
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: 这个解决方案是可行的，但可能有一个相关的缺点。如果你尝试在我们的菜单中的菜品上使用它，你将获得如下所示的 `Map`：
- en: '[PRE134]'
  id: totrans-810
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: 'Do you see the problem there? Because there is no dish of type FISH satisfying
    our filtering predicate, that key totally disappeared from the resulting map.
    To workaround this problem the `Collectors` class overloads the `groupingBy` factory
    method, with one variant also taking a second argument of type `Collector` along
    with the usual classification function. In this way, it’s possible to move the
    filtering predicate inside this second `Collector`, as follows:'
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到了那里的问题吗？因为没有一种类型的鱼满足我们的过滤谓词，所以这个键在结果映射中完全消失了。为了解决这个问题，`Collectors` 类重载了 `groupingBy`
    工厂方法，其中一个变体也接受一个类型为 `Collector` 的第二个参数，以及通常的分类函数。这样，就可以将过滤谓词移动到这个第二个 `Collector`
    中，如下所示：
- en: '[PRE135]'
  id: totrans-812
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'The `filtering` method is another static factory method of the `Collectors`
    class accepting a `Predicate` to filter the elements in each group and a further
    `Collector` that is used to regroup the filtered elements. In this way, the resulting
    `Map` will also keep an entry for the FISH type even if it maps an empty List:'
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: '`filtering` 方法是 `Collectors` 类的另一个静态工厂方法，它接受一个 `Predicate` 来过滤每个组中的元素，以及一个用于重新分组过滤元素的进一步
    `Collector`。这样，结果 `Map` 也将保留鱼类型的条目，即使它映射了一个空列表：'
- en: '[PRE136]'
  id: totrans-814
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'Another even more common way in which it could be useful to manipulate the
    grouped elements is transforming them through a mapping function. To this purpose,
    similarly to what you have seen for the `filtering Collector`, the `Collectors`
    class provides another `Collector` through the `mapping` method that accepts a
    mapping function and another `Collector` used to gather the elements resulting
    from the application of that function to each of them. By using it you can, for
    instance, convert each `Dish` in the groups into their respective names in this
    way:'
  id: totrans-815
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可能非常有用的操作分组元素的方法是通过映射函数进行转换。为此，类似于你看到的 `filtering Collector`，`Collectors`
    类通过 `mapping` 方法提供了另一个 `Collector`，它接受一个映射函数和另一个用于收集应用该函数到每个元素的结果的 `Collector`。通过使用它，你可以将组中的每个
    `Dish` 转换为它们各自的名字，如下所示：
- en: '[PRE137]'
  id: totrans-816
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: 'Note that in this case each group in the resulting `Map` is a `List` of `Strings`
    rather than one of `Dishes` as it was in the former examples. You could also use
    a third `Collector` in combination with the `groupingBy` to perform a `flatMap`
    transformation instead of a plain `map`. To demonstrate how this works let’s suppose
    that we have a `Map` associating to each `Dish` a list of tags as it follows:'
  id: totrans-817
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这种情况下，结果 `Map` 中的每个组都是一个 `Strings` 的 `List`，而不是像前例中的 `Dishes`。你也可以使用第三个
    `Collector` 与 `groupingBy` 结合来执行 `flatMap` 转换，而不是普通的 `map`。为了演示这是如何工作的，让我们假设我们有一个
    `Map`，将每个 `Dish` 关联到一个标签列表，如下所示：
- en: '[PRE138]'
  id: totrans-818
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: 'In case you are required to extract these tags for each group of type of dishes
    you can easily achieve this using the `flatMapping Collector`:'
  id: totrans-819
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要提取每个菜肴类型的标签，你可以轻松地使用 `flatMapping Collector` 来实现这一点：
- en: '[PRE139]'
  id: totrans-820
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: 'Here for each `Dish` we are obtaining a `List` of tags. So analogously to what
    we have already seen in the former chapter, we need to perform a `flatMap` in
    order to flatten the resulting two-level list into a single one. Also note that
    this time we collected the result of the `flatMapping` operations executed in
    each group into a `Set` instead of using a `List` as we did before, in order to
    avoid repetitions of same tags associated to more than one `Dish` in the same
    type. The `Map` resulting from this operation is then the following:'
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，对于每个 `Dish`，我们得到一个标签的 `List`。所以，类似于我们在前一章节中已经看到的，我们需要执行一个 `flatMap` 来将结果的两级列表展平成一个单一的列表。此外，请注意，这次我们将每个组中执行的
    `flatMapping` 操作的结果收集到一个 `Set` 中，而不是像之前那样使用 `List`，以避免同一类型的多个 `Dish` 关联到相同的标签。这个操作的结果
    `Map` 如下所示：
- en: '[PRE140]'
  id: totrans-822
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: Until this point we only used a single criterion to group the dishes in the
    menu, for instance by their type or by calories, but what if you want to use more
    than one criterion at the same time? Grouping is powerful because it composes
    effectively. Let’s see how to do this.
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只使用单一标准对菜单中的菜肴进行分组，例如按类型或卡路里，但如果你想同时使用多个标准怎么办？分组之所以强大，是因为它能够有效地组合。让我们看看如何做到这一点。
- en: 6.3.2\. Multilevel grouping
  id: totrans-824
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.2\. 多级分组
- en: The two arguments `Collectors.groupingBy` factory method that we used in a former
    section to manipulate the elements in the groups resulting from the grouping operation
    can be used also to perform a two-level grouping. To achieve this you can pass
    to it a second inner `groupingBy` to the outer `groupingBy`, defining a second-level
    criterion to classify the stream’s items, as shown in the next listing.
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前一节中使用过的两个参数 `Collectors.groupingBy` 工厂方法，用于操作分组操作产生的组中的元素，也可以用来执行两级分组。为了实现这一点，你可以向它传递一个第二级的内部
    `groupingBy` 给外部的 `groupingBy`，定义一个第二级标准来分类流的项目，如下一列表所示。
- en: Listing 6.2\. Multilevel grouping
  id: totrans-826
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.2\. 多级分组
- en: '[PRE141]'
  id: totrans-827
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: '***1* First-level classification function**'
  id: totrans-828
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 第一级分类函数**'
- en: '***2* Second-level classification function**'
  id: totrans-829
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 第二级分类函数**'
- en: 'The result of this two-level grouping is a two-level `Map` like the following:'
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: 这两级分组的结果是类似于以下的两级 `Map`：
- en: '[PRE142]'
  id: totrans-831
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: 'Here the outer `Map` has as keys the values generated by the first-level classification
    function: fish, meat, other. The values of this `Map` are in turn other `Map`s,
    having as keys the values generated by the second-level classification function:
    normal, diet, or fat. Finally, the second-level `Map`s have as values the `List`
    of the elements in the stream returning the corresponding first- and second-level
    key values when applied respectively to the first and second classification functions:
    salmon, pizza, and so on. This multilevel grouping operation can be extended to
    any number of levels, and an *n*-level grouping has as a result an *n*-level `Map`,
    modeling an *n*-level tree structure.'
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，外部的 `Map` 的键是由第一级分类函数生成的值：鱼、肉、其他。这个 `Map` 的值又是其他 `Map`s，它们的键是由第二级分类函数生成的值：正常、减肥或脂肪。最后，第二级的
    `Map`s 的值是流中元素的 `List`，当分别应用于第一和第二分类函数时，返回相应的一级和二级键值：三文鱼、披萨等等。这种多级分组操作可以扩展到任意数量的级别，一个
    *n*- 级分组的结果是一个 *n*- 级 `Map`，模拟一个 *n*- 级树结构。
- en: '[Figure 6.5](#ch06fig05) shows how this structure is also equivalent to an
    *n*-dimensional table, highlighting the classification purpose of the grouping
    operation.'
  id: totrans-833
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 6.5](#ch06fig05) 展示了这种结构也等同于一个 *n*- 维表，突出了分组操作的分类目的。'
- en: Figure 6.5\. Equivalence between *n*-level nested map and *n*-dimensional classification
    table
  id: totrans-834
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 6.5\. 多级嵌套映射与 *n*- 维分类表的等价性
- en: '![](Images/06fig05_alt.jpg)'
  id: totrans-835
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/06fig05_alt.jpg)'
- en: In general, it helps to think that `groupingBy` works in terms of “buckets.”
    The first `groupingBy` creates a bucket for each key. You then collect the elements
    in each bucket with the downstream collector and so on to achieve *n*-level groupings!
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，将`groupingBy`视为“桶”是有帮助的。第一个`groupingBy`为每个键创建一个桶。然后你使用下游收集器收集每个桶中的元素，以此类推，以实现*n*-级分组！
- en: 6.3.3\. Collecting data in subgroups
  id: totrans-837
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.3\. 在子组中收集数据
- en: 'In the previous section, you saw that it’s possible to pass a second `groupingBy`
    collector to the outer one to achieve a multilevel grouping. But more generally,
    the second collector passed to the first `groupingBy` can be any type of collector,
    not just another `groupingBy`. For instance, it’s possible to count the number
    of `Dish`es in the menu for each type, by passing the `counting` collector as
    a second argument to the `groupingBy` collector:'
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，你看到了可以通过传递第二个`groupingBy`收集器到外部的`groupingBy`来达到多级分组。但更一般地，传递给第一个`groupingBy`的第二个收集器可以是任何类型的收集器，而不仅仅是另一个`groupingBy`。例如，可以通过将`counting`收集器作为第二个参数传递给`groupingBy`收集器来计算菜单中每种类型的`Dish`数量：
- en: '[PRE143]'
  id: totrans-839
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: 'The result is the following `Map`:'
  id: totrans-840
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是以下`Map`：
- en: '[PRE144]'
  id: totrans-841
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: Also note that the regular one-argument `groupingBy(f)`, where `f` is the classification
    function is, in reality, shorthand for `groupingBy(f, toList())`.
  id: totrans-842
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，实际上，只有一个参数的`groupingBy(f)`，其中`f`是分类函数，是`groupingBy(f, toList())`的简写。
- en: 'To give another example, you could rework the collector you already used to
    find the highest-calorie dish in the menu to achieve a similar result, but now
    classified by the *type* of dish:'
  id: totrans-843
  prefs: []
  type: TYPE_NORMAL
  zh: 再举一个例子，你可以重新设计你已经用过的收集器，以找到菜单中热量最高的菜品，以实现类似的结果，但现在按菜品的**类型**进行分类：
- en: '[PRE145]'
  id: totrans-844
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: 'The result of this grouping is then clearly a `Map`, having as keys the available
    types of `Dish`es and as values the `Optional<Dish>`, wrapping the corresponding
    highest-calorie `Dish` for a given type:'
  id: totrans-845
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分组的最终结果显然是一个`Map`，其键是可用的`Dish`类型，值是`Optional<Dish>`，包装了对应类型中热量最高的`Dish`：
- en: '[PRE146]'
  id: totrans-846
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: '|  |'
  id: totrans-847
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Note
  id: totrans-848
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 注意
- en: The values in this `Map` are `Optional`s because this is the resulting type
    of the collector generated by the `maxBy` factory method, but in reality if there’s
    no `Dish` in the menu for a given type, that type won’t have an `Optional.empty()`
    as value; it won’t be present at all as a key in the `Map`. The `groupingBy` collector
    lazily adds a new key in the grouping `Map` only the first time it finds an element
    in the stream, producing that key when applying on it the grouping criteria being
    used. This means that in this case, the `Optional` wrapper isn’t useful, because
    it’s not modeling a value that could be possibly absent but is there incidentally,
    only because this is the type returned by the reducing collector.
  id: totrans-849
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`Map`中的值是`Optional`s，因为这是`maxBy`工厂方法生成的收集器的结果类型，但在现实中，如果菜单中没有给定类型的`Dish`，那么这个类型就不会有`Optional.empty()`作为值；它根本不会作为键出现在`Map`中。`groupingBy`收集器在第一次在流中找到元素时，会懒加载地在一个分组的`Map`中添加一个新的键，在应用分组标准时产生这个键。这意味着在这种情况下，`Optional`包装器是没有用的，因为它不是模拟一个可能缺失但意外存在的值，而只是因为这个类型是减少收集器返回的类型。
- en: '|  |'
  id: totrans-850
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Adapting the collector result to a different type
  id: totrans-851
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 调整收集器结果到不同类型
- en: Because the `Optional`s wrapping all the values in the `Map` resulting from
    the last grouping operation aren’t useful in this case, you may want to get rid
    of them. To achieve this, or more generally, to adapt the result returned by a
    collector to a different type, you could use the collector returned by the `Collectors.collectingAndThen`
    factory method, as shown in the following listing.
  id: totrans-852
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在最后分组操作的结果中包装所有值的`Optional`s在这种情况下没有用，你可能想去掉它们。为了实现这一点，或者更一般地，为了调整收集器返回的结果到不同类型，你可以使用`Collectors.collectingAndThen`工厂方法返回的收集器，如下所示。
- en: Listing 6.3\. Finding the highest-calorie dish in each subgroup
  id: totrans-853
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 6.3\. 在每个子组中找到热量最高的菜品
- en: '[PRE147]'
  id: totrans-854
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: '***1* Classification function**'
  id: totrans-855
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 分组函数**'
- en: '***2* Wrapped collector**'
  id: totrans-856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 包装收集器**'
- en: '***3* Transformation function**'
  id: totrans-857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 转换函数**'
- en: 'This factory method takes two arguments—the collector to be adapted and a transformation
    function—and returns another collector. This additional collector acts as a wrapper
    for the old one and maps the value it returns using the transformation function
    as the last step of the `collect` operation. In this case, the wrapped collector
    is the one created with `maxBy`, and the transformation function, `Optional::get`,
    extracts the value contained in the `Optional` returned. As we’ve said, here this
    is safe because the `reducing` collector will never return an `Optional.empty().`
    The result is the following `Map`:'
  id: totrans-858
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工厂方法接受两个参数——要适配的收集器和转换函数，并返回另一个收集器。这个额外的收集器作为旧收集器的包装器，并在`collect`操作的最后一步使用转换函数映射返回的值。在这种情况下，包装的收集器是使用`maxBy`创建的，转换函数`Optional::get`提取`Optional`返回的值。正如我们所说的，这里这是安全的，因为`reducing`收集器永远不会返回`Optional.empty()`。结果是以下`Map`：
- en: '[PRE148]'
  id: totrans-859
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: 'It’s quite common to use multiple nested collectors, and at first the way they
    interact may not always be obvious. [Figure 6.6](#ch06fig06) helps you visualize
    how they work together. From the outermost layer and moving inward, note the following:'
  id: totrans-860
  prefs: []
  type: TYPE_NORMAL
  zh: 使用多个嵌套收集器相当常见，起初它们之间的交互方式可能并不总是明显。[图6.6](#ch06fig06)可以帮助你可视化它们是如何一起工作的。从最外层开始向内移动，注意以下内容：
- en: The collectors are represented by the dashed lines, so `groupingBy` is the outermost
    one and groups the menu stream into three substreams according to the different
    dishes’ types.
  id: totrans-861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集器由虚线表示，因此`groupingBy`是最外层的，根据不同菜肴的类型将菜单流分组为三个子流。
- en: The `groupingBy` collector wraps the `collectingAndThen` collector, so each
    substream resulting from the grouping operation is further reduced by this second
    collector.
  id: totrans-862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`groupingBy`收集器包装了`collectingAndThen`收集器，因此每个分组操作产生的子流都进一步通过这个第二个收集器进行减少。'
- en: The `collectingAndThen` collector wraps in turn a third collector, the `maxBy`
    one.
  id: totrans-863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`collectingAndThen`收集器依次包装了一个第三个收集器，即`maxBy`。'
- en: The reduction operation on the substreams is then performed by the reducing
    collector, but the `collectingAndThen` collector containing it applies the `Optional::get`
    transformation function to its result.
  id: totrans-864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 子流的减少操作随后由`reducing`收集器执行，但包含它的`collectingAndThen`收集器对其结果应用了`Optional::get`转换函数。
- en: The three transformed values, being the highest-calorie `Dish`es for a given
    type (resulting from the execution of this process on each of the three substreams),
    will be the values associated with the respective classification keys, the types
    of `Dish`es, in theMap returned by the `groupingBy` collector.
  id: totrans-865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于给定的类型，三个转换后的值，即最高卡路里的`Dish`（通过在每个三个子流上执行此过程的结果），将是`groupingBy`收集器返回的`Map`中与相应分类键关联的值，即`Dish`的类型。
- en: Figure 6.6\. Combining the effect of multiple collectors by nesting one inside
    the other
  id: totrans-866
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.6\. 通过嵌套一个收集器在另一个内部来组合多个收集器的影响
- en: '![](Images/06fig06_alt.jpg)'
  id: totrans-867
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/06fig06_alt.jpg)'
- en: Other examples of collectors used in conjunction with groupingBy
  id: totrans-868
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 与`groupingBy`一起使用的收集器的其他示例
- en: 'More generally, the collector passed as second argument to the `groupingBy`
    factory method will be used to perform a further reduction operation on all the
    elements in the stream classified into the same group. For example, you could
    also reuse the collector created to sum the calories of all the dishes in the
    menu to obtain a similar result, but this time for each group of `Dish`es:'
  id: totrans-869
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地说，作为`groupingBy`工厂方法的第二个参数传递的收集器将被用来对分类到同一组的流中的所有元素执行进一步的减少操作。例如，你也可以重用创建来计算菜单中所有菜肴卡路里总和的收集器，以获得类似的结果，但这次是为每个`Dish`组：
- en: '[PRE149]'
  id: totrans-870
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: 'Yet another collector, commonly used in conjunction with `groupingBy,` is one
    generated by the `mapping` method. This method takes two arguments: a function
    transforming the elements in a stream and a further collector accumulating the
    objects resulting from this transformation. Its purpose is to adapt a collector
    accepting elements of a given type to one working on objects of a different type,
    by applying a mapping function to each input element before accumulating them.
    To see a practical example of using this collector, suppose you want to know which
    `CaloricLevel`s are available in the menu for each type of `Dish`. You could achieve
    this result combining a `groupingBy` and a `mapping` collector, as follows:'
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常用的收集器，通常与`groupingBy`一起使用，是由`mapping`方法生成的收集器。此方法接受两个参数：一个将流中的元素转换成另一个类型的函数，以及一个进一步收集此转换结果的收集器。它的目的是通过在累积之前对每个输入元素应用映射函数，将接受给定类型元素的收集器适配到处理不同类型对象的收集器。为了看到使用此收集器的实际示例，假设您想知道菜单中每种`Dish`类型可用的`CaloricLevel`。您可以通过结合使用`groupingBy`和`mapping`收集器来实现此结果，如下所示：
- en: '[PRE150]'
  id: totrans-872
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: 'Here the transformation function passed to the mapping method maps a `Dish`
    into its `CaloricLevel`, as you’ve seen before. The resulting stream of `CaloricLevel`s
    is then passed to a `toSet` collector, analogous to the `toList` one, but accumulating
    the elements of a stream into a `Set` instead of into a `List`, to keep only the
    distinct values. As in earlier examples, this mapping collector will then be used
    to collect the elements in each substream generated by the grouping function,
    allowing you to obtain as a result the following `Map`:'
  id: totrans-873
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，传递给映射方法的转换函数将`Dish`映射到其`CaloricLevel`，正如您之前所看到的。然后，将`CaloricLevel`的流传递给一个`toSet`收集器，类似于`toList`，但它将流元素累积到一个`Set`中，而不是累积到一个`List`中，以保留唯一的值。与早期示例一样，这个映射收集器将用于收集由分组函数生成的每个子流中的元素，从而使您能够获得以下`Map`作为结果：
- en: '[PRE151]'
  id: totrans-874
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: 'From this you can easily figure out your choices. If you’re in the mood for
    fish and you’re on a diet, you could easily find a dish; likewise, if you’re hungry
    and want something with lots of calories, you could satisfy your robust appetite
    by choosing something from the meat section of the menu. Note that in the previous
    example, there are no guarantees about what type of `Set` is returned. But by
    using `toCollection`, you can have more control. For example, you can ask for
    a `HashSet` by passing a constructor reference to it:'
  id: totrans-875
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里您可以轻松地了解您的选择。如果您想吃鱼并且正在节食，您可以轻松地找到一道菜；同样，如果您饿了并且想要高热量的食物，您可以通过选择菜单中的肉类部分来满足您强烈的食欲。注意，在前面的例子中，没有关于返回的`Set`类型的保证。但通过使用`toCollection`，您可以有更多的控制。例如，您可以通过传递一个构造器引用来请求一个`HashSet`：
- en: '[PRE152]'
  id: totrans-876
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: 6.4\. Partitioning
  id: totrans-877
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4\. 分区
- en: 'Partitioning is a special case of grouping: having a predicate called a *partitioning
    function* as a classification function. The fact that the partitioning function
    returns a boolean means the resulting grouping `Map` will have a `Boolean` as
    a key type, and therefore, there can be at most two different groups—one for `true`
    and one for `false`. For instance, if you’re vegetarian or have invited a vegetarian
    friend to have dinner with you, you may be interested in partitioning the menu
    into vegetarian and nonvegetarian dishes:'
  id: totrans-878
  prefs: []
  type: TYPE_NORMAL
  zh: 分区是分组的特殊情况：有一个称为*分区函数*的谓词作为分类函数。分区函数返回布尔值的事实意味着结果分组`Map`将有一个`Boolean`作为键类型，因此，最多可以有两个不同的组——一个用于`true`，一个用于`false`。例如，如果您是素食主义者或者邀请了素食朋友一起吃饭，您可能对将菜单分为素食和非素食菜肴感兴趣：
- en: '[PRE153]'
  id: totrans-879
  prefs: []
  type: TYPE_PRE
  zh: '[PRE153]'
- en: '***1* Partitioning function**'
  id: totrans-880
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 分区函数**'
- en: 'This will return the following `Map`:'
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回以下`Map`：
- en: '[PRE154]'
  id: totrans-882
  prefs: []
  type: TYPE_PRE
  zh: '[PRE154]'
- en: 'So you could retrieve all the vegetarian dishes by getting from this `Map`
    the value indexed with the key `true`:'
  id: totrans-883
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您可以通过从这个`Map`中获取以`true`为键的值来检索所有素食菜肴：
- en: '[PRE155]'
  id: totrans-884
  prefs: []
  type: TYPE_PRE
  zh: '[PRE155]'
- en: 'Note that you could achieve the same result by filtering the stream created
    from the menu `List` with the same predicate used for partitioning and then collecting
    the result in an additional `List`:'
  id: totrans-885
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，您可以通过使用与分区相同的谓词过滤从“列表”菜单创建的流，然后将结果收集到一个额外的“列表”中，从而实现相同的结果：
- en: '[PRE156]'
  id: totrans-886
  prefs: []
  type: TYPE_PRE
  zh: '[PRE156]'
- en: 6.4.1\. Advantages of partitioning
  id: totrans-887
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.1\. 分区的优点
- en: 'Partitioning has the advantage of keeping both lists of the stream elements,
    for which the application of the partitioning function returns `true` or `false`.
    In the previous example, you can obtain the `List` of the nonvegetarian `Dish`es
    by accessing the value of the key `false` in the `partitionedMenu Map`, using
    two separate filtering operations: one with the predicate and one with its negation.
    Also, as you already saw for grouping, the `partitioningBy` factory method has
    an overloaded version to which you can pass a second collector, as shown here:'
  id: totrans-888
  prefs: []
  type: TYPE_NORMAL
  zh: 分区的好处是保留了流元素的两个列表，对于分区函数返回`true`或`false`的应用。在先前的例子中，你可以通过访问`partitionedMenu
    Map`中键`false`的值来获得非素食`Dish`的`List`，使用两个单独的过滤操作：一个使用谓词，另一个使用其否定。同样，正如你已经看到的分组，`partitioningBy`工厂方法有一个重载版本，你可以传递第二个收集器，如下所示：
- en: '[PRE157]'
  id: totrans-889
  prefs: []
  type: TYPE_PRE
  zh: '[PRE157]'
- en: '***1* Partitioning function**'
  id: totrans-890
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 分区函数**'
- en: '***2* Second collector**'
  id: totrans-891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 第二个收集器**'
- en: 'This will produce a two-level `Map`:'
  id: totrans-892
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生一个两级的`Map`：
- en: '[PRE158]'
  id: totrans-893
  prefs: []
  type: TYPE_PRE
  zh: '[PRE158]'
- en: 'Here the grouping of the dishes by their type is applied individually to both
    of the substreams of vegetarian and nonvegetarian dishes resulting from the partitioning,
    producing a two-level `Map` that’s similar to the one you obtained when you performed
    the two-level grouping in [section 6.3.1](#ch06lev2sec7). As another example,
    you can reuse your earlier code to find the most caloric dish among both vegetarian
    and nonvegetarian dishes:'
  id: totrans-894
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，将菜肴按其类型分组的方法被单独应用于由分区产生的素食和非素食菜肴的两个子流，从而生成一个类似于你在[第6.3.1节](#ch06lev2sec7)中执行的两级分组时获得的二级`Map`。作为另一个例子，你可以重用你之前的代码来找出素食和非素食菜肴中最高卡路里的菜肴：
- en: '[PRE159]'
  id: totrans-895
  prefs: []
  type: TYPE_PRE
  zh: '[PRE159]'
- en: 'That will produce the following result:'
  id: totrans-896
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下结果：
- en: '[PRE160]'
  id: totrans-897
  prefs: []
  type: TYPE_PRE
  zh: '[PRE160]'
- en: 'We started this section by saying that you can think of partitioning as a special
    case of grouping. It’s worth also noting that the `Map` implementation returned
    by `partitioningBy` is more compact and efficient as it only needs to contain
    two keys: true and false. In fact, the internal implementation is a specialized
    `Map` with two fields. The analogies between the `groupingBy` and `partitioningBy`
    collectors don’t end here; as you’ll see in the next quiz, you can also perform
    multilevel partitioning in a way similar to what you did for grouping in [section
    6.3.1](#ch06lev2sec7).'
  id: totrans-898
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节开始时说，你可以将分区视为分组的一个特殊情况。还值得注意的是，`partitioningBy`返回的`Map`实现更紧凑、更高效，因为它只需要包含两个键：true和false。事实上，内部实现是一个具有两个字段的专用`Map`。`groupingBy`和`partitioningBy`收集器之间的类比并不止于此；正如你将在下一个练习中看到的，你也可以以类似于你在[第6.3.1节](#ch06lev2sec7)中分组的方式执行多级分区。
- en: '|  |'
  id: totrans-899
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Quiz 6.2: Using partitioningBy**'
  id: totrans-900
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习6.2：使用partitioningBy**'
- en: As you’ve seen, like the `groupingBy` collector, the `partitioningBy` collector
    can be used in combination with other collectors. In particular it could be used
    with a second `partitioningBy` collector to achieve a multilevel partitioning.
    What will be the result of the following multilevel partitionings?
  id: totrans-901
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，与`groupingBy`收集器一样，`partitioningBy`收集器也可以与其他收集器结合使用。特别是它可以与第二个`partitioningBy`收集器一起使用，以实现多级分区。以下多级分区的结果会是什么？
- en: '[PRE161]'
  id: totrans-902
  prefs:
  - PREF_OL
  type: TYPE_PRE
  zh: '[PRE161]'
- en: '[PRE162]'
  id: totrans-903
  prefs:
  - PREF_OL
  type: TYPE_PRE
  zh: '[PRE162]'
- en: '[PRE163]'
  id: totrans-904
  prefs:
  - PREF_OL
  type: TYPE_PRE
  zh: '[PRE163]'
- en: '**Answer:**'
  id: totrans-905
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: 'This is a valid multilevel partitioning, producing the following two-level
    `Map`:'
  id: totrans-906
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一个有效的多级分区，产生了以下两级的`Map`：
- en: '[PRE164]'
  id: totrans-907
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE164]'
- en: This won’t compile because `partitioningBy` requires a predicate, a function
    returning a boolean. And the method reference `Dish::getType` can’t be used as
    a predicate.
  id: totrans-908
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将无法编译，因为`partitioningBy`需要一个谓词，一个返回布尔值的函数。方法引用`Dish::getType`不能用作谓词。
- en: 'This counts the number of items in each partition, resulting in the following
    `Map`:'
  id: totrans-909
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这计算了每个分区中的项目数量，从而产生了以下`Map`：
- en: '[PRE165]'
  id: totrans-910
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE165]'
- en: '|  |'
  id: totrans-911
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: 'To give one last example of how you can use the `partitioningBy` collector,
    we’ll put aside the menu data model and look at something a bit more complex but
    also more interesting: partitioning numbers into prime and nonprime.'
  id: totrans-912
  prefs: []
  type: TYPE_NORMAL
  zh: 为了给出一个如何使用`partitioningBy`收集器的最后一个例子，我们将暂时放下菜单数据模型，看看一些更复杂但也更有趣的东西：将数字分为质数和非质数。
- en: 6.4.2\. Partitioning numbers into prime and nonprime
  id: totrans-913
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.4.2\. 将数字分为质数和非质数
- en: 'Suppose you want to write a method accepting as argument an `int` *n* and partitioning
    the first *n* natural numbers into prime and nonprime. But first, it will be useful
    to develop a predicate that tests to see if a given candidate number is prime
    or not:'
  id: totrans-914
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想编写一个接受`int` *n* 作为参数的方法，并将前*n*个自然数分为质数和非质数。但首先，开发一个测试给定候选数字是否为质数的谓词将是有用的：
- en: '[PRE166]'
  id: totrans-915
  prefs: []
  type: TYPE_PRE
  zh: '[PRE166]'
- en: '***1* Generates a range of natural numbers starting from and including 2, up
    to but excluding candidate**'
  id: totrans-916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 从2开始生成一个自然数范围，包括2，但不包括候选数**'
- en: '***2* Returns true if the candidate isn’t divisible for any of the numbers
    in the stream**'
  id: totrans-917
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 如果候选数不能被流中的任何数整除，则返回true**'
- en: 'A simple optimization is to test only for factors less than or equal to the
    square root of the candidate:'
  id: totrans-918
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的优化是只测试小于或等于候选数的平方根的因子：
- en: '[PRE167]'
  id: totrans-919
  prefs: []
  type: TYPE_PRE
  zh: '[PRE167]'
- en: 'Now the biggest part of the job is done. To partition the first *n* numbers
    into prime and nonprime, it’s enough to create a stream containing those *n* numbers,
    and reduce it with a `partitioningBy` collector using as predicate the `isPrime`
    method you just developed:'
  id: totrans-920
  prefs: []
  type: TYPE_NORMAL
  zh: 现在大部分工作已经完成。要将前*n*个数字分成质数和非质数，只需创建一个包含这些*n*个数字的流，然后使用`partitioningBy`收集器将其与您刚刚开发的`isPrime`方法作为谓词进行归约即可：
- en: '[PRE168]'
  id: totrans-921
  prefs: []
  type: TYPE_PRE
  zh: '[PRE168]'
- en: We’ve now covered all the collectors that can be created using the static factory
    methods of the `Collectors` class, showing practical examples of how they work.
    [Table 6.1](#ch06table01) brings them all together with the type they return when
    applied to a `Stream<T>`, and a practical example of their use on a `Stream<Dish>`
    named `menuStream`.
  id: totrans-922
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经涵盖了可以使用`Collectors`类的静态工厂方法创建的所有收集器，展示了它们如何工作的实际示例。[表6.1](#ch06table01)将它们全部汇总在一起，包括它们应用于`Stream<T>`时返回的类型，以及它们在名为`menuStream`的`Stream<Dish>`上的实际使用示例。
- en: Table 6.1\. The main static factory methods of the `Collectors` class
  id: totrans-923
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表6.1\. `Collectors`类的主要静态工厂方法
- en: '| Factory method | Returned type | Used to |'
  id: totrans-924
  prefs: []
  type: TYPE_TB
  zh: '| 工厂方法 | 返回类型 | 用于 |'
- en: '| --- | --- | --- |'
  id: totrans-925
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| toList | List<T> | Gather all the stream’s items in a List. |'
  id: totrans-926
  prefs: []
  type: TYPE_TB
  zh: '| toList | List<T> | 将流中的所有项目收集到列表中。|'
- en: '| Example use: List<Dish> dishes = menuStream.collect(toList()); |'
  id: totrans-927
  prefs: []
  type: TYPE_TB
  zh: '| Example use: List<Dish> dishes = menuStream.collect(toList()); |'
- en: '| toSet | Set<T> | Gather all the stream’s items in a Set, eliminating duplicates.
    |'
  id: totrans-928
  prefs: []
  type: TYPE_TB
  zh: '| toSet | Set<T> | 将流中的所有项目收集到集合中，消除重复项。|'
- en: '| Example use: Set<Dish> dishes = menuStream.collect(toSet()); |'
  id: totrans-929
  prefs: []
  type: TYPE_TB
  zh: '| Example use: Set<Dish> dishes = menuStream.collect(toSet()); |'
- en: '| toCollection | Collection<T> | Gather all the stream’s items in the collection
    created by the provided supplier. |'
  id: totrans-930
  prefs: []
  type: TYPE_TB
  zh: '| toCollection | Collection<T> | 将流中的所有项目收集到由提供的供应商创建的集合中。|'
- en: '| Example use: Collection<Dish> dishes = menuStream.collect(toCollection(),
    ArrayList::new); |'
  id: totrans-931
  prefs: []
  type: TYPE_TB
  zh: '| Example use: Collection<Dish> dishes = menuStream.collect(toCollection(),
    ArrayList::new); |'
- en: '| counting | Long | Count the number of items in the stream. |'
  id: totrans-932
  prefs: []
  type: TYPE_TB
  zh: '| counting | Long | 计算流中项目的数量。|'
- en: '| Example use: longhowManyDishes = menuStream.collect(counting()); |'
  id: totrans-933
  prefs: []
  type: TYPE_TB
  zh: '| Example use: long howManyDishes = menuStream.collect(counting()); |'
- en: '| summingInt | Integer | Sum the values of an Integer property of the items
    in the stream. |'
  id: totrans-934
  prefs: []
  type: TYPE_TB
  zh: '| summingInt | Integer | 对流中项目的Integer属性值求和。|'
- en: '| Example use: int totalCalories = menuStream.collect(summingInt(Dish::getCalories));
    |'
  id: totrans-935
  prefs: []
  type: TYPE_TB
  zh: '| Example use: int totalCalories = menuStream.collect(summingInt(Dish::getCalories));
    |'
- en: '| averagingInt | Double | Calculate the average value of an Integer property
    of the items in the stream. |'
  id: totrans-936
  prefs: []
  type: TYPE_TB
  zh: '| averagingInt | Double | 计算流中项目Integer属性的平均值。|'
- en: '| Example use: double avgCalories = menuStream.collect(averagingInt(Dish::getCalories));
    |'
  id: totrans-937
  prefs: []
  type: TYPE_TB
  zh: '| Example use: double avgCalories = menuStream.collect(averagingInt(Dish::getCalories));
    |'
- en: '| summarizingInt | IntSummaryStatistics | Collect statistics regarding an Integer
    property of the items in the stream, such as the maximum, minimum, total, and
    average. |'
  id: totrans-938
  prefs: []
  type: TYPE_TB
  zh: '| summarizingInt | IntSummaryStatistics | 收集有关流中项目Integer属性（如最大值、最小值、总和和平均值）的统计信息。|'
- en: '| Example use: IntSummaryStatistics menuStatistics = menuStream.collect(summarizingInt(Dish::getCalories));
    |'
  id: totrans-939
  prefs: []
  type: TYPE_TB
  zh: '| Example use: IntSummaryStatistics menuStatistics = menuStream.collect(summarizingInt(Dish::getCalories));
    |'
- en: '| joining | String | Concatenate the strings resulting from the invocation
    of the toString method on each item of the stream. |'
  id: totrans-940
  prefs: []
  type: TYPE_TB
  zh: '| joining | String | 将流中每个项目调用toString方法的结果连接起来。|'
- en: '| Example use: String shortMenu = menuStream.map(Dish::getName).collect(joining(",
    ")); |'
  id: totrans-941
  prefs: []
  type: TYPE_TB
  zh: '| Example use: String shortMenu = menuStream.map(Dish::getName).collect(joining(",
    ")); |'
- en: '| maxBy | Optional<T> | An Optional wrapping the maximal element in this stream
    according to the given comparator or Optional.empty() if the stream is empty.
    |'
  id: totrans-942
  prefs: []
  type: TYPE_TB
  zh: '| maxBy | Optional<T> | 一个Optional，包含根据给定的比较器在此流中的最大元素，如果流为空，则为Optional.empty()。|'
- en: '| Example use: Optional<Dish> fattest = menuStream.collect(maxBy(comparingInt(Dish::getCalories)));
    |'
  id: totrans-943
  prefs: []
  type: TYPE_TB
  zh: '| Example use: Optional<Dish> fattest = menuStream.collect(maxBy(comparingInt(Dish::getCalories)));
    |'
- en: '| minBy | Optional<T> | An Optional wrapping the minimal element in this stream
    according to the given comparator or Optional.empty() if the stream is empty.
    |'
  id: totrans-944
  prefs: []
  type: TYPE_TB
  zh: '| minBy | Optional<T> | 一个Optional，包含根据给定的比较器在此流中的最小元素，如果流为空，则为Optional.empty()。|'
- en: '| Example use: Optional<Dish> lightest = menuStream.collect(minBy(comparingInt(Dish::getCalories)));
    |'
  id: totrans-945
  prefs: []
  type: TYPE_TB
  zh: '| Example use: Optional<Dish> lightest = menuStream.collect(minBy(comparingInt(Dish::getCalories)));
    | |'
- en: '| reducing | The type produced by the reduction operation | Reduce the stream
    to a single value starting from an initial value used as accumulator and iteratively
    combining it with each item of the stream using a BinaryOperator. |'
  id: totrans-946
  prefs: []
  type: TYPE_TB
  zh: '| reducing | 归约操作产生的类型 | 从一个用作累加器的初始值开始，迭代地将每个流项目与一个二元操作符组合，以将流归约为一个单一值。 |'
- en: '| Example use: int totalCalories = menuStream.collect(reducing(0, Dish::getCalories,
    Integer::sum)); |'
  id: totrans-947
  prefs: []
  type: TYPE_TB
  zh: '| Example use: int totalCalories = menuStream.collect(reducing(0, Dish::getCalories,
    Integer::sum)); | |'
- en: '| collectingAndThen | The type returned by the transforming function | Wrap
    another collector and apply a transformation function to its result. |'
  id: totrans-948
  prefs: []
  type: TYPE_TB
  zh: '| collectingAndThen | 转换函数返回的类型 | 包装另一个收集器并对其结果应用转换函数。 |'
- en: '| Example use: int howManyDishes = menuStream.collect(collectingAndThen(toList(),
    List::size)); |'
  id: totrans-949
  prefs: []
  type: TYPE_TB
  zh: '| Example use: int howManyDishes = menuStream.collect(collectingAndThen(toList(),
    List::size)); | |'
- en: '| groupingBy | Map<K, List<T>> | Group the items in the stream based on the
    value of one of their properties and use those values as keys in the resulting
    Map. |'
  id: totrans-950
  prefs: []
  type: TYPE_TB
  zh: '| groupingBy | Map<K, List<T>> | 根据流中项目的一个属性值对项目进行分组，并使用这些值作为结果Map的键。 |'
- en: '| Example use: Map<Dish.Type,List<Dish>> dishesByType = menuStream.collect(groupingBy(Dish::getType));
    |'
  id: totrans-951
  prefs: []
  type: TYPE_TB
  zh: '| Example use: Map<Dish.Type,List<Dish>> dishesByType = menuStream.collect(groupingBy(Dish::getType));
    | |'
- en: '| partitioningBy | Map<Boolean, List<T>> | Partition the items in the stream
    based on the result of the application of a predicate to each of them. |'
  id: totrans-952
  prefs: []
  type: TYPE_TB
  zh: '| partitioningBy | Map<Boolean, List<T>> | 根据对每个项目应用谓词的结果对流中的项目进行分区。 |'
- en: '| Example use: Map<Boolean,List<Dish>> vegetarianDishes = menuStream.collect(partitioningBy(Dish::isVegetarian));
    |'
  id: totrans-953
  prefs: []
  type: TYPE_TB
  zh: '| Example use: Map<Boolean,List<Dish>> vegetarianDishes = menuStream.collect(partitioningBy(Dish::isVegetarian));
    | |'
- en: As we mentioned at the beginning of the chapter, all these collectors implement
    the `Collector` interface, so in the remaining part of the chapter we investigate
    this interface in more detail. We investigate the methods in that interface and
    then explore how you can implement your own collectors.
  id: totrans-954
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章开头所述，所有这些收集器都实现了`Collector`接口，因此在本章剩余部分，我们将更详细地研究这个接口。我们研究该接口中的方法，然后探索如何实现你自己的收集器。
- en: 6.5\. The Collector interface
  id: totrans-955
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5。`Collector`接口
- en: The `Collector` interface consists of a set of methods that provide a blueprint
    for how to implement specific reduction operations (collectors). You’ve seen many
    collectors that implement the `Collector` interface, such as `toList` or `groupingBy`.
    This also implies that you’re free to create customized reduction operations by
    providing your own implementation of the `Collector` interface. In [section 6.6](#ch06lev1sec6)
    we’ll show how you can implement the `Collector` interface to create a collector
    to partition a stream of numbers into prime and nonprime more efficiently than
    what you’ve seen so far.
  id: totrans-956
  prefs: []
  type: TYPE_NORMAL
  zh: '`Collector`接口包含一组方法，为如何实现特定的归约操作（收集器）提供了一个蓝图。你已经看到了许多实现了`Collector`接口的收集器，例如`toList`或`groupingBy`。这也意味着你可以自由地创建定制的归约操作，通过提供自己的`Collector`接口实现。在[第6.6节](#ch06lev1sec6)中，我们将展示如何实现`Collector`接口以创建一个收集器，将数字流划分为质数和非质数，比之前看到的方法更高效。'
- en: 'To get started with the `Collector` interface, we focus on one of the first
    collectors you encountered at the beginning of this chapter: the `toList` factory
    method, which gathers all the elements of a stream in a `List`. We said that you’ll
    frequently use this collector in your day-to-day job, but it’s also one that,
    at least conceptually, is straightforward to develop. Investigating in more detail
    how this collector is implemented is a good way to understand how the `Collector`
    interface is defined and how the functions returned by its methods are internally
    used by the `collect` method.'
  id: totrans-957
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用`Collector`接口，我们关注本章开头遇到的第一批收集器之一：`toList`工厂方法，它将流中的所有元素收集到一个`List`中。我们说过，你将在日常工作中经常使用这个收集器，但至少在概念上，它也是容易开发的。更详细地研究这个收集器的实现方式是了解`Collector`接口定义以及其方法返回的函数如何被`collect`方法内部使用的好方法。
- en: Let’s start by taking a look at the definition of the `Collector` interface
    in the next listing, which shows the interface signature together with the five
    methods it declares.
  id: totrans-958
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看下一列表中`Collector`接口的定义，它显示了接口签名以及它声明的五个方法。
- en: Listing 6.4\. The `Collector` interface
  id: totrans-959
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.4。`Collector`接口
- en: '[PRE169]'
  id: totrans-960
  prefs: []
  type: TYPE_PRE
  zh: '[PRE169]'
- en: 'In this listing, the following definitions apply:'
  id: totrans-961
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个列表中，以下定义适用：
- en: '`T` is the generic type of the items in the stream to be collected.'
  id: totrans-962
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`T` 是要收集的流中项的泛型类型。'
- en: '`A` is the type of the accumulator, the object on which the partial result
    will be accumulated during the collection process.'
  id: totrans-963
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`A` 是累加器的类型，在收集过程中，部分结果将累积在这个对象上。'
- en: '`R` is the type of the object (typically, but not always, the collection) resulting
    from the collect operation.'
  id: totrans-964
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`R` 是收集操作结果的对象类型（通常是，但不总是，集合）。'
- en: For instance, you could implement a `ToListCollector<T>` class that gathers
    all the elements of a `Stream<T>` into a `List<T>` having the following signature
  id: totrans-965
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以实现一个 `ToListCollector<T>` 类，该类将 `Stream<T>` 的所有元素收集到一个具有以下签名的 `List<T>`
    中
- en: '[PRE170]'
  id: totrans-966
  prefs: []
  type: TYPE_PRE
  zh: '[PRE170]'
- en: where, as we’ll clarify shortly, the object used for the accumulation process
    will also be the final result of the collection process.
  id: totrans-967
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，正如我们很快就会澄清的，用于累积过程的对象也将是收集过程的最终结果。
- en: 6.5.1\. Making sense of the methods declared by Collector interface
  id: totrans-968
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.5.1. 理解 Collector 接口声明的方法
- en: We can now analyze the five methods declared by the `Collector` interface one
    by one. When we do so, you’ll notice that each of the first four methods returns
    a function that will be invoked by the `collect` method, whereas the fifth one,
    `characteristics`, provides a set of characteristics that’s a list of hints used
    by the `collect` method itself to know which optimizations (for example, parallelization)
    it’s allowed to employ while performing the reduction operation.
  id: totrans-969
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以逐个分析 `Collector` 接口声明的五种方法。当我们这样做时，你会注意到前四种方法返回一个函数，该函数将由 `collect` 方法调用，而第五种方法
    `characteristics` 提供了一组特性，这是一个由 `collect` 方法本身使用的提示列表，以知道在执行归约操作时允许使用哪些优化（例如，并行化）。
- en: 'Making a new result container: the supplier method'
  id: totrans-970
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 创建新的结果容器：供应商方法
- en: 'The `supplier` method has to return a `Supplier` of an empty accumulator—a
    parameterless function that when invoked creates an instance of an empty accumulator
    used during the collection process. Clearly, for a collector returning the accumulator
    itself as result, like our `ToListCollector`, this empty accumulator will also
    represent the result of the collection process when performed on an empty stream.
    In our `ToListCollector` the `supplier` will then return an empty `List`, as follows:'
  id: totrans-971
  prefs: []
  type: TYPE_NORMAL
  zh: '`supplier` 方法必须返回一个空的累加器的 `Supplier`——一个无参数的函数，当调用时创建用于收集过程的空累加器实例。显然，对于返回累加器本身作为结果的收集器，如我们的
    `ToListCollector`，这个空累加器也将代表在空流上执行收集过程的结果。在我们的 `ToListCollector` 中，`supplier`
    将返回一个空的 `List`，如下所示：'
- en: '[PRE171]'
  id: totrans-972
  prefs: []
  type: TYPE_PRE
  zh: '[PRE171]'
- en: 'Note that you could also pass a constructor reference:'
  id: totrans-973
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，你也可以传递一个构造器引用：
- en: '[PRE172]'
  id: totrans-974
  prefs: []
  type: TYPE_PRE
  zh: '[PRE172]'
- en: 'Adding an element to a result container: the accumulator method'
  id: totrans-975
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 向结果容器添加元素：累加器方法
- en: 'The `accumulator` method returns the function that performs the reduction operation.
    When traversing the *n*th element in the stream, this function is applied with
    two arguments, the accumulator being the result of the reduction (after having
    collected the first *n*–1 items of the stream) and the *n*th element itself. The
    function returns `void` because the accumulator is modified in place, meaning
    that its internal state is changed by the function application to reflect the
    effect of the traversed element. For `ToListCollector`, this function merely has
    to add the current item to the list containing the already traversed ones:'
  id: totrans-976
  prefs: []
  type: TYPE_NORMAL
  zh: '`accumulator` 方法返回执行归约操作的函数。当遍历流中的第 *n* 个元素时，此函数将使用两个参数应用，累加器是归约的结果（在收集了流的前
    *n*–1 个元素之后）以及第 *n* 个元素本身。该函数返回 `void`，因为累加器是在原地修改的，这意味着其内部状态通过函数应用被改变，以反映遍历元素的效果。对于
    `ToListCollector`，此函数只需将当前项添加到包含已遍历项的列表中：'
- en: '[PRE173]'
  id: totrans-977
  prefs: []
  type: TYPE_PRE
  zh: '[PRE173]'
- en: 'You could instead use a method reference, which is more concise:'
  id: totrans-978
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用方法引用，这更简洁：
- en: '[PRE174]'
  id: totrans-979
  prefs: []
  type: TYPE_PRE
  zh: '[PRE174]'
- en: 'Applying the final transformation to the result container: the finisher method'
  id: totrans-980
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对结果容器应用最终转换：完成器方法
- en: 'The `finisher` method has to return a function that’s invoked at the end of
    the accumulation process, after having completely traversed the stream, in order
    to transform the accumulator object into the final result of the whole collection
    operation. Often, as in the case of the `ToListCollector`, the accumulator object
    already coincides with the final expected result. As a consequence, there’s no
    need to perform a transformation, so the `finisher` method has to return the `identity`
    function:'
  id: totrans-981
  prefs: []
  type: TYPE_NORMAL
  zh: '`finisher`方法必须返回一个函数，在完全遍历流并在累积过程结束时调用，以便将累加器对象转换为整个收集操作的最终结果。通常，就像在`ToListCollector`的情况下，累加器对象已经与最终预期的结果一致。因此，不需要执行转换，所以`finisher`方法必须返回`identity`函数：'
- en: '[PRE175]'
  id: totrans-982
  prefs: []
  type: TYPE_PRE
  zh: '[PRE175]'
- en: These first three methods are enough to execute a sequential reduction of the
    stream that, at least from a logical point of view, could proceed as in [figure
    6.7](#ch06fig07). The implementation details are a bit more difficult in practice
    due to both the lazy nature of the stream, which could require a pipeline of other
    intermediate operations to execute before the `collect` operation, and the possibility,
    in theory, of performing the reduction in parallel.
  id: totrans-983
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种方法足以执行流的顺序减少，从逻辑角度来看，可以像[图6.7](#ch06fig07)中所示那样进行。在实践中，由于流的惰性特性，可能需要在`collect`操作之前执行一系列其他中间操作，以及理论上可以并行执行减少的可能性，实现细节要复杂一些。
- en: Figure 6.7\. Logical steps of the sequential reduction process
  id: totrans-984
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.7\. 顺序减少过程的逻辑步骤
- en: '![](Images/06fig07_alt.jpg)'
  id: totrans-985
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/06fig07_alt.jpg)'
- en: 'Merging two result containers: the combiner method'
  id: totrans-986
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 合并两个结果容器：合并方法
- en: 'The `combiner` method, the last of the four methods that return a function
    used by the reduction operation, defines how the accumulators resulting from the
    reduction of different subparts of the stream are combined when the subparts are
    processed in parallel. In the `toList` case, the implementation of this method
    is simple; add the list containing the items gathered from the second subpart
    of the stream to the end of the list obtained when traversing the first subpart:'
  id: totrans-987
  prefs: []
  type: TYPE_NORMAL
  zh: '`combiner`方法，这是四种返回由减少操作使用的函数的方法中的最后一种，定义了当子部分并行处理时，从流的不同子部分减少产生的累加器如何合并。在`toList`的情况下，此方法的实现很简单；将包含从流的第二部分收集到的项目的列表添加到遍历第一部分时获得的列表的末尾：'
- en: '[PRE176]'
  id: totrans-988
  prefs: []
  type: TYPE_PRE
  zh: '[PRE176]'
- en: The addition of this fourth method allows a parallel reduction of the stream.
    This uses the fork/join framework introduced in Java 7 and the `Spliterator` abstraction
    that you’ll learn about in the next chapter. It follows a process similar to the
    one shown in [figure 6.8](#ch06fig08) and described in detail here.
  id: totrans-989
  prefs: []
  type: TYPE_NORMAL
  zh: 添加这种第四种方法允许流进行并行减少。这使用了Java 7中引入的fork/join框架和你在下一章中将学习的`Spliterator`抽象。它遵循一个类似于[图6.8](#ch06fig08)中所示的过程，并在此处详细描述。
- en: The original *stream* is recursively split in substreams until a condition defining
    whether a stream needs to be further divided becomes false (parallel computing
    is often slower than sequential computing when the units of work being distributed
    are too small, and it’s pointless to generate many more parallel tasks than you
    have processing cores).
  id: totrans-990
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始的 *流* 会被递归地分割成子流，直到一个定义流是否需要进一步分割的条件变为假（当被分配的工作单元太小，并行计算通常比顺序计算慢，生成比你的处理核心更多的并行任务是没有意义的）。
- en: At this point, all *substreams* can be processed in parallel, each of them using
    the sequential reduction algorithm shown in [figure 6.7](#ch06fig07).
  id: totrans-991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到这一点，所有 *子流* 都可以并行处理，每个子流都使用[图6.7](#ch06fig07)中所示的顺序减少算法。
- en: Finally, all the partial results are combined pairwise using the function returned
    by the `combiner` method of the collector. This is done by combining results corresponding
    to substreams associated with each split of the original stream.
  id: totrans-992
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，所有部分结果都通过收集器的`combiner`方法返回的函数成对合并。这是通过将对应于原始流每个分割的子流的减少结果组合起来完成的。
- en: Figure 6.8\. Parallelizing the reduction process using the `combiner` method
  id: totrans-993
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图6.8\. 使用`combiner`方法并行化减少过程
- en: '![](Images/06fig08_alt.jpg)'
  id: totrans-994
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/06fig08_alt.jpg)'
- en: The characteristics method
  id: totrans-995
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 特征方法
- en: 'The last method, `characteristics`, returns an immutable set of `Characteristics`,
    defining the behavior of the collector—in particular providing hints about whether
    the stream can be reduced in parallel and which optimizations are valid when doing
    so. `Characteristics` is an enumeration containing three items:'
  id: totrans-996
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个方法`characteristics`返回一个不可变的`Characteristics`集合，定义了收集器的行为——特别是提供有关流是否可以并行归约以及在这种情况下哪些优化是有效的提示。`Characteristics`是一个枚举，包含三个条目：
- en: '**`UNORDERED`—** The result of the reduction isn’t affected by the order in
    which the items in the stream are traversed and accumulated.'
  id: totrans-997
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`UNORDERED`—** 归约的结果不受流中项目遍历和累积顺序的影响。'
- en: '**`CONCURRENT`—** The `accumulator` function can be called concurrently from
    multiple threads, and then this collector can perform a parallel reduction of
    the stream. If the collector isn’t also flagged as `UNORDERED`, it can perform
    a parallel reduction only when it’s applied to an unordered data source.'
  id: totrans-998
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`CONCURRENT`—** 累加器函数可以从多个线程中并发调用，然后这个收集器可以对流进行并行归约。如果收集器没有也标记为`UNORDERED`，它只能在应用于无序数据源时执行并行归约。'
- en: '**`IDENTITY_FINISH`—** This indicates the function returned by the finisher
    method is the identity one, and its application can be omitted. In this case,
    the accumulator object is directly used as the final result of the reduction process.
    This also implies that it’s safe to do an unchecked cast from the accumulator
    `A` to the result `R`.'
  id: totrans-999
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`IDENTITY_FINISH`—** 这表示由finisher方法返回的函数是恒等函数，其应用可以省略。在这种情况下，累加器对象直接用作归约过程的最终结果。这也意味着从累加器`A`到结果`R`的不检查类型转换是安全的。'
- en: The `ToListCollector` developed so far is `IDENTITY_FINISH`, because the `List`
    used to accumulate the elements in the stream is already the expected final result
    and doesn’t need any further transformation, but it isn’t `UNORDERED` because
    if you apply it to an ordered stream you want this ordering to be preserved in
    the resulting `List`. Finally, it’s `CONCURRENT`, but following what we just said,
    the stream will be processed in parallel only if its underlying data source is
    unordered.
  id: totrans-1000
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止开发的`ToListCollector`是`IDENTITY_FINISH`，因为用于在流中累积元素的`List`已经是预期的最终结果，不需要任何进一步的转换，但它不是`UNORDERED`，因为如果你将其应用于有序流，你希望这种顺序在结果`List`中得以保留。最后，它是`CONCURRENT`的，但根据我们刚才所说的，只有当其底层数据源是无序时，流才会并行处理。
- en: 6.5.2\. Putting them all together
  id: totrans-1001
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.5.2\. 将它们全部放在一起
- en: The five methods analyzed in the preceding subsection are everything you need
    to develop your own `ToListCollector` so you can implement it by putting all of
    them together, as the next listing shows.
  id: totrans-1002
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个子节中分析的五个方法是你开发自己的`ToListCollector`所需的一切，你可以通过将它们全部放在一起来实现它，如以下列表所示。
- en: Listing 6.5\. The `ToListCollector`
  id: totrans-1003
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.5\. `ToListCollector`
- en: '[PRE177]'
  id: totrans-1004
  prefs: []
  type: TYPE_PRE
  zh: '[PRE177]'
- en: '***1* Creates the collection operation starting point**'
  id: totrans-1005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 创建集合操作的起点**'
- en: '***2* Accumulates the traversed item, modifying the accumulator in place**'
  id: totrans-1006
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 累积遍历的项目，就地修改累加器**'
- en: '***3* Identifies function**'
  id: totrans-1007
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 识别函数**'
- en: '***4* Modifies the first accumulator, combining it with the content of the
    second one**'
  id: totrans-1008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 修改第一个累加器，将其与第二个的内容合并**'
- en: '***5* Returns the modified first accumulator**'
  id: totrans-1009
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 返回修改后的第一个累加器**'
- en: '***6* Flags the collector as IDENTITY_FINISH and CONCURRENT**'
  id: totrans-1010
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 将收集器标记为 IDENTITY_FINISH 和 CONCURRENT**'
- en: 'Note that this implementation isn’t identical to the one returned by the `Collectors
    .toList` method, but it differs only in some minor optimizations. These optimizations
    are mostly related to the fact that the collector provided by the Java API uses
    the `Collections.emptyList()` singleton when it has to return an empty list. This
    means that it could be safely used in place of the original Java as an example
    to gather a list of all the `Dish`es of a menu stream:'
  id: totrans-1011
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这个实现与`Collectors.toList`方法返回的实现并不相同，但它们之间的差异仅在于一些小的优化。这些优化主要与Java API提供的收集器在需要返回空列表时使用`Collections.emptyList()`单例的事实有关。这意味着它可以安全地用作原始Java的示例，以收集菜单流中所有`Dish`的列表：
- en: '[PRE178]'
  id: totrans-1012
  prefs: []
  type: TYPE_PRE
  zh: '[PRE178]'
- en: The remaining difference from this and the standard formulation
  id: totrans-1013
  prefs: []
  type: TYPE_NORMAL
  zh: 与标准公式的剩余差异
- en: '[PRE179]'
  id: totrans-1014
  prefs: []
  type: TYPE_PRE
  zh: '[PRE179]'
- en: is that `toList` is a factory, whereas you have to use `new` to instantiate
    your `ToList-Collector`.
  id: totrans-1015
  prefs: []
  type: TYPE_NORMAL
  zh: 是`toList`是一个工厂，而你必须使用`new`来实例化你的`ToList-Collector`。
- en: Performing a custom collect without creating a Collector implementation
  id: totrans-1016
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 执行自定义收集而不创建收集器实现
- en: 'In the case of an `IDENTITY_FINISH` collection operation, there’s a further
    possibility of obtaining the same result without developing a completely new implementation
    of the `Collector` interface. Streams has an overloaded `collect` method accepting
    the three other functions—`supplier`, `accumulator`, and `combiner`—having exactly
    the same semantics as the ones returned by the corresponding methods of the `Collector`
    interface. For instance, it’s possible to collect in a `List` all the items in
    a stream of dishes, as follows:'
  id: totrans-1017
  prefs: []
  type: TYPE_NORMAL
  zh: 在`IDENTITY_FINISH`集合操作的情况下，还有进一步的可能性获得相同的结果，而无需开发一个全新的`Collector`接口实现。Streams有一个重载的`collect`方法，接受三个其他函数——`supplier`、`accumulator`和`combiner`——它们具有与`Collector`接口相应方法返回的函数完全相同的语义。例如，可以将流中所有菜肴的所有项收集到一个`List`中，如下所示：
- en: '[PRE180]'
  id: totrans-1018
  prefs: []
  type: TYPE_PRE
  zh: '[PRE180]'
- en: '***1* Supplier**'
  id: totrans-1019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 供应者**'
- en: '***2* Accumulator**'
  id: totrans-1020
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 累加器**'
- en: '***3* Combiner**'
  id: totrans-1021
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 组合器**'
- en: We believe that this second form, even if more compact and concise than the
    former one, is rather less readable. Also, developing an implementation of your
    custom collector in a proper class promotes its reuse and helps avoid code duplication.
    It’s also worth noting that you’re not allowed to pass any `Characteristics` to
    this second `collect` method, so it always behaves as an `IDENTITY_FINISH` and
    `CONCURRENT` but not `UNORDERED` collector.
  id: totrans-1022
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为，这种第二种形式，即使比前者更紧凑和简洁，但可读性较低。此外，在适当的类中开发您自定义收集器的实现可以促进其重用，并有助于避免代码重复。还值得注意的是，不允许向这个第二个`collect`方法传递任何`Characteristics`，因此它始终表现为`IDENTITY_FINISH`和`CONCURRENT`收集器，而不是`UNORDERED`收集器。
- en: In the next section, you’ll take your new knowledge of implementing collectors
    to the next level. You’ll develop your own custom collector for a more complex
    but hopefully more specific and compelling use case.
  id: totrans-1023
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将把实现收集器的新的知识提升到下一个层次。您将为更复杂但希望更具体和有说服力的用例开发自己的自定义收集器。
- en: 6.6\. Developing your own collector for better performance
  id: totrans-1024
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6\. 开发自己的收集器以获得更好的性能
- en: In [section 6.4](#ch06lev1sec4), where we discussed partitioning, you created
    a collector using one of the many convenient factory methods provided by the `Collectors`
    class, which divides the first *n* natural numbers into primes and nonprimes,
    as shown in the following listing.
  id: totrans-1025
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6.4节](#ch06lev1sec4)中，我们讨论了分区，您使用`Collectors`类提供的许多方便的工厂方法之一创建了一个收集器，将前*n*个自然数分为素数和非素数，如下所示。
- en: Listing 6.6\. Partitioning the first *n* natural numbers into primes and nonprimes
  id: totrans-1026
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.6\. 将前*n*个自然数分为素数和非素数
- en: '[PRE181]'
  id: totrans-1027
  prefs: []
  type: TYPE_PRE
  zh: '[PRE181]'
- en: 'There you achieved an improvement over the original `isPrime` method by limiting
    the number of divisors to be tested against the candidate prime to those not bigger
    than the candidate’s square root:'
  id: totrans-1028
  prefs: []
  type: TYPE_NORMAL
  zh: 在那里，你通过限制要测试的候选素数的除数数量不超过候选数的平方根，从而在原始`isPrime`方法上实现了改进：
- en: '[PRE182]'
  id: totrans-1029
  prefs: []
  type: TYPE_PRE
  zh: '[PRE182]'
- en: Is there a way to obtain even better performances? The answer is yes, but for
    this you’ll have to develop a custom collector.
  id: totrans-1030
  prefs: []
  type: TYPE_NORMAL
  zh: 有没有一种方法可以获得更好的性能？答案是肯定的，但为此你必须开发一个自定义收集器。
- en: 6.6.1\. Divide only by prime numbers
  id: totrans-1031
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.6.1\. 只除以素数
- en: One possible optimization is to test only if the candidate number is divisible
    by prime numbers. It’s pointless to test it against a divisor that’s not itself
    prime! You can limit the test to only the prime numbers found before the current
    candidate. The problem with the predefined collectors you’ve used so far, and
    the reason you have to develop a custom one, is that during the collecting process
    you don’t have access to the partial result. This means that when testing whether
    a given candidate number is prime or not, you don’t have access to the list of
    the other prime numbers found so far.
  id: totrans-1032
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可能的优化是只测试候选数是否能被素数整除。测试一个非素数的除数是没有意义的！你可以将测试限制为只针对在当前候选数之前找到的素数。你之前使用的预定义收集器的问题，以及你必须开发一个自定义收集器的原因，是在收集过程中你无法访问部分结果。这意味着在测试给定的候选数是否为素数时，你无法访问到目前为止找到的其他素数列表。
- en: 'Suppose you had this list; you could pass it to the `isPrime` method and rewrite
    it as follows:'
  id: totrans-1033
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个这样的列表；你可以将它传递给`isPrime`方法，并按如下方式重写：
- en: '[PRE183]'
  id: totrans-1034
  prefs: []
  type: TYPE_PRE
  zh: '[PRE183]'
- en: 'Also, you should implement the same optimization you used before and test only
    with primes smaller than the square root of the candidate number. You need a way
    to stop testing whether the candidate is divisible by a prime as soon as the next
    prime is greater than the candidate’s root. You can easily do this by using the
    Stream’s `takeWhile` method:'
  id: totrans-1035
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还应该实现之前使用的相同优化，并且只对小于候选数平方根的素数进行测试。你需要一种方法，一旦下一个素数大于候选数的根，就可以立即停止测试候选数是否能被素数整除。你可以通过使用
    Stream 的 `takeWhile` 方法轻松实现这一点：
- en: '[PRE184]'
  id: totrans-1036
  prefs: []
  type: TYPE_PRE
  zh: '[PRE184]'
- en: '|  |'
  id: totrans-1037
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Quiz 6.3: Simulating takeWhile in Java 8**'
  id: totrans-1038
  prefs: []
  type: TYPE_NORMAL
  zh: '**练习 6.3：在 Java 8 中模拟 takeWhile**'
- en: The `takeWhile` method was introduced in Java 9, so unfortunately you cannot
    use this solution if you are still using Java 8\. How could you work around this
    limitation and achieve something similar in Java 8?
  id: totrans-1039
  prefs: []
  type: TYPE_NORMAL
  zh: '`takeWhile` 方法是在 Java 9 中引入的，所以不幸的是，如果你还在使用 Java 8，则无法使用此解决方案。你该如何解决这个问题，并在
    Java 8 中实现类似的功能？ '
- en: '**Answer:**'
  id: totrans-1040
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案：**'
- en: 'You could implement your own `takeWhile` method, which, given a sorted list
    and a predicate, returns the longest prefix of this list whose elements satisfy
    the predicate:'
  id: totrans-1041
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以实现自己的 `takeWhile` 方法，该方法给定一个排序后的列表和一个谓词，返回满足谓词的列表的最长前缀：
- en: '[PRE185]'
  id: totrans-1042
  prefs: []
  type: TYPE_PRE
  zh: '[PRE185]'
- en: '***1* Checks if the current item in the list satisfies the Predicate**'
  id: totrans-1043
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 检查列表中的当前项是否满足谓词**'
- en: '***2* If it doesn’t, returns the sublist prefix until the item before the tested
    one**'
  id: totrans-1044
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 如果不是，则返回测试项之前子列表的前缀**'
- en: '***3* All the items in the list satisfy the Predicate, so returns the list
    itself**'
  id: totrans-1045
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 列表中的所有项都满足谓词，因此返回列表本身**'
- en: 'Using this method, you can rewrite the `isPrime` method and once again testing
    only the candidate prime against only the primes that aren’t greater than its
    square root:'
  id: totrans-1046
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个方法，你可以重写 `isPrime` 方法，并且再次只对候选素数与小于其平方根的素数进行测试：
- en: '[PRE186]'
  id: totrans-1047
  prefs: []
  type: TYPE_PRE
  zh: '[PRE186]'
- en: Note that, unlike the one provided by the Streams API, this implementation of
    `takeWhile` is eager. When possible, always prefer the Java 9 Stream’s lazy version
    of `takeWhile` so it can be merged with the `noneMatch` operation.
  id: totrans-1048
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，与 Streams API 提供的不同，这个 `takeWhile` 的实现是 eager 的。在可能的情况下，始终优先选择 Java 9 Stream
    的 lazy 版本的 `takeWhile`，以便它可以与 `noneMatch` 操作合并。
- en: '|  |'
  id: totrans-1049
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: With this new `isPrime` method in hand, you’re now ready to implement your own
    custom collector. First, you need to declare a new class that implements the `Collector`
    interface. Then, you need to develop the five methods required by the `Collector`
    interface.
  id: totrans-1050
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有这个新的 `isPrime` 方法后，你现在可以准备实现你自己的自定义收集器。首先，你需要声明一个新的类，该类实现了 `Collector` 接口。然后，你需要开发
    `Collector` 接口所需的五个方法。
- en: 'Step 1: Defining the Collector class signature'
  id: totrans-1051
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第一步：定义收集器类的签名
- en: Let’s start with the class signature, remembering that the `Collector` interface
    is defined as
  id: totrans-1052
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从类签名开始，记住 `Collector` 接口被定义为
- en: '[PRE187]'
  id: totrans-1053
  prefs: []
  type: TYPE_PRE
  zh: '[PRE187]'
- en: 'where `T`, `A`, and `R` are respectively the type of the elements in the stream,
    the type of the object used to accumulate partial results, and the type of the
    final result of the `collect` operation. In this case, you want to collect streams
    of `Integer`s while both the accumulator and the result types are `Map<Boolean,
    List<Integer>>` (the same `Map` you obtained as a result of the former partitioning
    operation in [listing 6.6](#ch06ex06)), having as keys `true` and `false` and
    as values respectively the `List`s of prime and nonprime numbers:'
  id: totrans-1054
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 `T`、`A` 和 `R` 分别是流中元素的类型、用于累积部分结果的对象的类型以及 `collect` 操作的最终结果类型。在这种情况下，你想要收集
    `Integer` 类型的流，同时累积器和结果类型都是 `Map<Boolean, List<Integer>>`（与在 [列表 6.6](#ch06ex06)
    中的前一个分区操作得到的相同 `Map`），键为 `true` 和 `false`，值分别为素数和非素数的列表：
- en: '[PRE188]'
  id: totrans-1055
  prefs: []
  type: TYPE_PRE
  zh: '[PRE188]'
- en: '***1* The type of the elements in the stream**'
  id: totrans-1056
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 流中元素的类型**'
- en: '***2* The type of the accumulator**'
  id: totrans-1057
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 累积器的类型**'
- en: '***3* The type of the result of the collect operation**'
  id: totrans-1058
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 收集操作的结果类型**'
- en: 'Step 2: Implementing the reduction process'
  id: totrans-1059
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第二步：实现减少过程
- en: 'Next, you need to implement the five methods declared in the `Collector` interface.
    The `supplier` method has to return a function that when invoked creates the accumulator:'
  id: totrans-1060
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你需要实现 `Collector` 接口中声明的五个方法。`supplier` 方法必须返回一个函数，当调用该函数时，会创建累积器：
- en: '[PRE189]'
  id: totrans-1061
  prefs: []
  type: TYPE_PRE
  zh: '[PRE189]'
- en: 'Here you’re not only creating the `Map` that you’ll use as the accumulator,
    but you’re also initializing it with two empty lists under the `true` and `false`
    keys. This is where you’ll add respectively the prime and nonprime numbers during
    the collection process. The most important method of your collector is the `accumulator`
    method, because it contains the logic defining how the elements of the stream
    have to be collected. In this case, it’s also the key to implementing the optimization
    we described previously. At any given iteration you can now access the partial
    result of the collection process, which is the accumulator containing the prime
    numbers found so far:'
  id: totrans-1062
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你不仅创建了一个将用作累加器的`Map`，而且还使用两个空列表在`true`和`false`键下初始化它。这就是你在收集过程中分别添加素数和非素数的地方。你收集器最重要的方法是`accumulator`方法，因为它包含了定义流元素如何收集的逻辑。在这种情况下，它也是实现我们之前描述的优化的关键。在任何给定的迭代中，你现在可以访问收集过程的局部结果，即包含迄今为止找到的素数的累加器：
- en: '[PRE190]'
  id: totrans-1063
  prefs: []
  type: TYPE_PRE
  zh: '[PRE190]'
- en: '***1* Gets the list of prime or nonprime numbers depending on the result of
    isPrime**'
  id: totrans-1064
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 根据isPrime的结果获取素数或非素数列表**'
- en: '***2* Adds the candidate to the appropriate list**'
  id: totrans-1065
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将候选者添加到适当的列表**'
- en: In this method, you invoke the `isPrime` method, passing to it (together with
    the number for which you want to test whether it’s prime or not) the list of the
    prime numbers found so far. (These are the values indexed by the `true` key in
    the accumulating `Map.)` The result of this invocation is then used as the key
    to get the list of either the prime or nonprime numbers, so you can add the new
    candidate to the right list.
  id: totrans-1066
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方法中，你调用`isPrime`方法，将其（连同你想要测试是否为素数的数字）以及迄今为止找到的素数列表传递给它。（这些是累积`Map`中由`true`键索引的值。）然后，这个调用的结果被用作键来获取素数或非素数列表，这样你就可以将新的候选者添加到正确的列表中。
- en: 'Step 3: Making the collector work in parallel (if possible)'
  id: totrans-1067
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第3步：使收集器并行工作（如果可能）
- en: 'The next method has to combine two partial accumulators in the case of a parallel
    collection process, so in this case it has to merge the two `Map`s by adding all
    the numbers in the prime and nonprime lists of the second `Map` to the corresponding
    lists in the first `Map`:'
  id: totrans-1068
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个方法必须在并行收集过程中合并两个部分累加器，因此在这种情况下，它必须通过将第二个`Map`中素数和非素数列表的所有数字添加到第一个`Map`中相应的列表来合并这两个`Map`：
- en: '[PRE191]'
  id: totrans-1069
  prefs: []
  type: TYPE_PRE
  zh: '[PRE191]'
- en: Note that in reality this collector can’t be used in parallel, because the algorithm
    is inherently sequential. This means the `combiner` method won’t ever be invoked,
    and you could leave its implementation empty (or better, throw an `UnsupportedOperation-Exception`).
    We decided to implement it anyway only for completeness.
  id: totrans-1070
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，实际上这个收集器不能并行使用，因为算法本质上是顺序的。这意味着`combiner`方法永远不会被调用，你可以将其实现留空（或者更好，抛出`UnsupportedOperationException`）。我们决定仍然实现它，只是为了完整性。
- en: 'Step 4: The finisher method and the collector’s characteristic method'
  id: totrans-1071
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 第4步：finisher方法和收集器的特征方法
- en: 'The implementation of the last two methods is quite straightforward. As we
    said, the `accumulator` coincides with the collector’s result so it won’t need
    any further transformation, and the `finisher` method returns the `identity` function:'
  id: totrans-1072
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个方法的实现相当直接。正如我们所说，`accumulator`与收集器的结果相同，因此不需要任何进一步的转换，而`finisher`方法返回`identity`函数：
- en: '[PRE192]'
  id: totrans-1073
  prefs: []
  type: TYPE_PRE
  zh: '[PRE192]'
- en: 'As for the characteristic method, we already said that it’s neither `CONCURRENT`
    nor `UNORDERED` but is `IDENTITY_FINISH`:'
  id: totrans-1074
  prefs: []
  type: TYPE_NORMAL
  zh: 关于特征方法，我们之前已经说过，它既不是`CONCURRENT`也不是`UNORDERED`，而是`IDENTITY_FINISH`：
- en: '[PRE193]'
  id: totrans-1075
  prefs: []
  type: TYPE_PRE
  zh: '[PRE193]'
- en: The following listing shows the final implementation of `PrimeNumbersCollector`.
  id: totrans-1076
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了`PrimeNumbersCollector`的最终实现。
- en: Listing 6.7\. The `PrimeNumbersCollector`
  id: totrans-1077
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.7. `PrimeNumbersCollector`
- en: '[PRE194]'
  id: totrans-1078
  prefs: []
  type: TYPE_PRE
  zh: '[PRE194]'
- en: '***1* Starts the collection process with a Map containing two empty Lists**'
  id: totrans-1079
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 使用包含两个空列表的Map开始收集过程**'
- en: '***2* Passes to the isPrime method the list of already found primes**'
  id: totrans-1080
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将已找到的素数列表传递给isPrime方法**'
- en: '***3* Gets from the Map the list of prime or nonprime numbers, according to
    what the isPrime method returned, and adds to it the current candidate**'
  id: totrans-1081
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 从Map中获取素数或非素数列表，根据isPrime方法返回的结果，并将当前候选者添加到其中**'
- en: '***4* Merges the second Map into the first one**'
  id: totrans-1082
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 将第二个Map合并到第一个Map中**'
- en: '***5* No transformation necessary at the end of the collection process, so
    terminate it with the identity function**'
  id: totrans-1083
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 收集过程结束时不需要转换，因此使用恒等函数终止它**'
- en: '***6* This collector is IDENTITY_FINISH but neither UNORDERED nor CONCURRENT
    because it relies on the fact that prime numbers are discovered in sequence.**'
  id: totrans-1084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 这个收集器是IDENTITY_FINISH，但既不是UNORDERED也不是CONCURRENT，因为它依赖于质数是按顺序发现的这一事实。**'
- en: 'You can now use this new custom collector in place of the former one created
    with the `partitioningBy` factory method in [section 6.4](#ch06lev1sec4) and obtain
    exactly the same result:'
  id: totrans-1085
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以使用这个新的自定义收集器来替代之前使用`partitioningBy`工厂方法在[第6.4节](#ch06lev1sec4)中创建的旧收集器，并得到完全相同的结果：
- en: '[PRE195]'
  id: totrans-1086
  prefs: []
  type: TYPE_PRE
  zh: '[PRE195]'
- en: 6.6.2\. Comparing collectors’ performances
  id: totrans-1087
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.6.2\. 比较收集器的性能
- en: 'The collector created with the `partitioningBy` factory method and the custom
    one you just developed are functionally identical, but did you achieve your goal
    of improving the performance of the `partitioningBy` collector with your custom
    one? Let’s write a quick harness to check this:'
  id: totrans-1088
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`partitioningBy`工厂方法创建的收集器和您刚刚开发的自定义收集器在功能上是相同的，但您是否通过自定义收集器实现了提高`partitioningBy`收集器性能的目标？让我们快速编写一个测试程序来检查这一点：
- en: '[PRE196]'
  id: totrans-1089
  prefs: []
  type: TYPE_PRE
  zh: '[PRE196]'
- en: '***1* Runs the test 10 times**'
  id: totrans-1090
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 运行测试10次**'
- en: '***2* Partitions the first million natural numbers into primes and nonprimes**'
  id: totrans-1091
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 将前一百万个自然数分为质数和非质数**'
- en: '***3* The duration in milliseconds**'
  id: totrans-1092
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 持续时间（毫秒）**'
- en: '***4* Checks if this execution is the fastest one**'
  id: totrans-1093
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 检查这是否是执行最快的**'
- en: 'Note that a more scientific benchmarking approach would be to use a framework
    such as Java Microbenchmark Harness (JMH), but we didn’t want to add the complexity
    of using such a framework here and, for this use case, the results provided by
    this small benchmarking class are accurate enough. This class partitions the first
    million natural numbers into primes and nonprimes, invoking the method using the
    collector created with the `partitioningBy` factory method 10 times and registering
    the fastest execution. Running it on an Intel i5 2.4 GHz, it prints the following
    result:'
  id: totrans-1094
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，一个更科学的基准测试方法将是使用一个框架，例如Java Microbenchmark Harness (JMH)，但我们不想在这里增加使用此类框架的复杂性，并且对于这个用例，这个小基准测试类提供的结果已经足够准确。这个类将前一百万个自然数分为质数和非质数，使用`partitioningBy`工厂方法创建的收集器调用该方法10次，并记录最快的执行时间。在Intel
    i5 2.4 GHz上运行它，它将打印以下结果：
- en: '[PRE197]'
  id: totrans-1095
  prefs: []
  type: TYPE_PRE
  zh: '[PRE197]'
- en: Now replace `partitionPrimes` with `partitionPrimesWithCustomCollector` in the
    harness, in order to test the performances of the custom collector you developed.
    Now the program prints
  id: totrans-1096
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将测试程序中的`partitionPrimes`替换为`partitionPrimesWithCustomCollector`，以测试您开发的自定义收集器的性能。现在程序将打印
- en: '[PRE198]'
  id: totrans-1097
  prefs: []
  type: TYPE_PRE
  zh: '[PRE198]'
- en: 'Not bad! This means you didn’t waste your time developing this custom collector
    for two reasons: First, you learned how to implement your own collector when you
    need it. And second, you achieved a performance improvement of around 32%.'
  id: totrans-1098
  prefs: []
  type: TYPE_NORMAL
  zh: 还不错！这意味着您没有浪费时间开发这个自定义收集器，原因有两个：首先，当您需要时，您学习了如何实现自己的收集器。其次，您实现了大约32%的性能提升。
- en: 'Finally, it’s important to note that, as you did for the `ToListCollector`
    in [listing 6.5](#ch06ex05), it’s possible to obtain the same result by passing
    the three functions implementing the core logic of `PrimeNumbersCollector` to
    the overloaded version of the `collect` method, taking them as arguments:'
  id: totrans-1099
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，重要的是要注意，正如您在[列表6.5](#ch06ex05)中对`ToListCollector`所做的那样，通过将实现`PrimeNumbersCollector`核心逻辑的三个函数传递给`collect`方法的重载版本，作为参数，您可以得到相同的结果：
- en: '[PRE199]'
  id: totrans-1100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE199]'
- en: '***1* Supplier**'
  id: totrans-1101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 供应者**'
- en: '***2* Accumulator**'
  id: totrans-1102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 累加器**'
- en: '***3* Combiner**'
  id: totrans-1103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 组合器**'
- en: As you can see, in this way you can avoid creating a completely new class that
    implements the `Collector` interface; the resulting code is more compact, even
    if it’s also probably less readable and certainly less reusable.
  id: totrans-1104
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，这样您可以避免创建一个完全新的实现`Collector`接口的类；生成的代码更加紧凑，即使它可能也难以阅读，并且肯定不太可重用。
- en: Summary
  id: totrans-1105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: '`collect` is a terminal operation that takes as argument various recipes (called
    collectors) for accumulating the elements of a stream into a summary result.'
  id: totrans-1106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`collect`是一个终端操作，它接受各种配方（称为收集器）作为参数，用于将流中的元素累积到总结结果中。'
- en: Predefined collectors include reducing and summarizing stream elements into
    a single value, such as calculating the minimum, maximum, or average. Those collectors
    are summarized in [table 6.1](#ch06table01).
  id: totrans-1107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预定义的收集器包括将流元素减少和总结为单个值，例如计算最小值、最大值或平均值。这些收集器在[表6.1](#ch06table01)中总结。
- en: Predefined collectors let you group elements of a stream with `groupingBy` and
    partition elements of a stream with `partitioningBy`.
  id: totrans-1108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预定义的收集器允许您使用`groupingBy`对流的元素进行分组，并使用`partitioningBy`对流的元素进行分区。
- en: Collectors compose effectively to create multilevel groupings, partitions, and
    reductions.
  id: totrans-1109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集器有效地组合以创建多级分组、分区和归约。
- en: You can develop your own collectors by implementing the methods defined in the
    `Collector` interface.
  id: totrans-1110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过实现`Collector`接口中定义的方法来开发自己的收集器。
- en: Chapter 7\. Parallel data processing and performance
  id: totrans-1111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第7章\. 并行数据处理和性能
- en: '*This chapter covers*'
  id: totrans-1112
  prefs: []
  type: TYPE_NORMAL
  zh: '*本章涵盖*'
- en: Processing data in parallel with parallel streams
  id: totrans-1113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用并行流并行处理数据
- en: Performance analysis of parallel streams
  id: totrans-1114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行流的性能分析
- en: The fork/join framework
  id: totrans-1115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分支/合并框架
- en: Splitting a stream of data using a `Spliterator`
  id: totrans-1116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`Spliterator`分割数据流
- en: In the last three chapters, you’ve seen how the new `Streams` interface lets
    you manipulate collections of data in a declarative way. We also explained that
    the shift from external to internal iteration enables the native Java library
    to gain control over processing the elements of a stream. This approach relieves
    Java developers from explicitly implementing optimizations necessary to speed
    up the processing of collections of data. By far the most important benefit is
    the possibility of executing a pipeline of operations on these collections that
    automatically makes use of the multiple cores on your computer.
  id: totrans-1117
  prefs: []
  type: TYPE_NORMAL
  zh: 在前三章中，您已经看到新的`Streams`接口如何让您以声明性方式操作数据集合。我们还解释了，从外部迭代到内部迭代的转变使得Java库能够控制流元素的处理。这种方法减轻了Java开发者显式实现优化以加快数据集合处理速度的负担。迄今为止，最重要的好处是能够在这些集合上执行操作管道，这会自动利用您计算机上的多个核心。
- en: For instance, before Java 7, processing a collection of data in parallel was
    extremely cumbersome. First, you needed to explicitly split the data structure
    containing your data into subparts. Second, you needed to assign each of these
    subparts to a different thread. Third, you needed to synchronize them opportunely
    to avoid unwanted race conditions, wait for the completion of all threads, and
    finally combine the partial results. Java 7 introduced a framework called *fork/join*
    to perform these operations more consistently and in a less error-prone way. We’ll
    explore this framework in [section 7.2](#ch07lev1sec2).
  id: totrans-1118
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在Java 7之前，并行处理数据集合非常繁琐。首先，您需要显式地将包含您数据的结构分割成子部分。其次，您需要将这些子部分分配给不同的线程。第三，您需要适当地同步它们以避免不希望的竞态条件，等待所有线程完成，最后合并部分结果。Java
    7引入了一个名为*fork/join*的框架来更一致且更不易出错地执行这些操作。我们将在[第7.2节](#ch07lev1sec2)中探讨这个框架。
- en: In this chapter, you’ll discover how the `Streams` interface gives you the opportunity
    to execute operations in parallel on a collection of data without much effort.
    It lets you declaratively turn a sequential stream into a parallel one. Moreover,
    you’ll see how Java can make this magic happen or, more practically, how parallel
    streams work under the hood by employing the fork/join framework introduced in
    Java 7\. You’ll also discover that it’s important to know how parallel streams
    work internally, because if you ignore this aspect, you could obtain unexpected
    (and likely wrong) results by misusing them.
  id: totrans-1119
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将发现`Streams`接口如何让您有机会在数据集合上轻松执行并行操作。它允许您声明性地将顺序流转换为并行流。此外，您还将看到Java如何通过使用在Java
    7中引入的分支/合并框架来实现这一魔法，或者更实际地说，并行流是如何在底层工作的。您还将发现了解并行流内部工作方式的重要性，因为如果您忽略这个方面，您可能会通过误用它们而获得意外的（并且可能是错误的）结果。
- en: In particular, we’ll demonstrate that the way a parallel stream gets divided
    into chunks, before processing the different chunks in parallel, can in some cases
    be the origin of these incorrect and apparently unexplainable results. For this
    reason, you’ll learn how to take control of this splitting process by implementing
    and using your own `Spliterator`.
  id: totrans-1120
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是您将发现，在并行处理不同块之前，并行流被分割成块的方式在某些情况下可能是这些不正确且看似无法解释的结果的来源。因此，您将学习如何通过实现和使用自己的`Spliterator`来控制这个分割过程。
- en: 7.1\. Parallel streams
  id: totrans-1121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1\. 并行流
- en: 'In [chapter 4](kindle_split_015.xhtml#ch04), we briefly mentioned that the
    `Streams` interface allows you to process its elements in parallel in a convenient
    way: it’s possible to turn a collection into a parallel stream by invoking the
    method `parallelStream` on the collection source. A *parallel* stream is a stream
    that splits its elements into multiple chunks, processing each chunk with a different
    thread. Thus, you can automatically partition the workload of a given operation
    on all the cores of your multicore processor and keep all of them equally busy.
    Let’s experiment with this idea by using a simple example.'
  id: totrans-1122
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](kindle_split_015.xhtml#ch04)中，我们简要提到了`Streams`接口允许你以方便的方式并行处理其元素：可以通过在集合源上调用`parallelStream`方法将一个集合转换为并行流。一个*并行*流是一个将元素分割成多个块，并使用不同的线程处理每个块的流。因此，你可以自动将给定操作的工作负载分配到多核处理器的所有核心上，并保持它们都同样忙碌。让我们通过一个简单的例子来实验这个想法。
- en: 'Let’s suppose you need to write a method accepting a number *n* as argument
    and returning the sum of the numbers from one to *n*. A straightforward (perhaps
    naïve) approach is to generate an infinite stream of numbers, limiting it to the
    passed numbers, and then reduce the resulting stream with a `BinaryOperator` that
    sums two numbers, as follows:'
  id: totrans-1123
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你需要编写一个方法，该方法接受一个数字*n*作为参数，并返回从1到*n*的数字之和。一个直接（可能有些天真）的方法是生成一个无限数字流，限制它只包含传入的数字，然后使用`BinaryOperator`将两个数字相加的归约操作来减少生成的流，如下所示：
- en: '[PRE200]'
  id: totrans-1124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE200]'
- en: '***1* Generates the infinite stream of natural numbers**'
  id: totrans-1125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 生成自然数的无限流**'
- en: '***2* Limits it to the first *n* numbers**'
  id: totrans-1126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 限制它只包含前*n*个数字**'
- en: '***3* Reduces the stream by summing all the numbers**'
  id: totrans-1127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 通过求和所有数字来减少流**'
- en: 'In more traditional Java terms, this code is equivalent to its iterative counterpart:'
  id: totrans-1128
  prefs: []
  type: TYPE_NORMAL
  zh: 在更传统的Java术语中，这段代码与其迭代对应物等价：
- en: '[PRE201]'
  id: totrans-1129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE201]'
- en: This operation seems to be a good candidate to use parallelization, especially
    for large values of *n*. But where do you start? Do you synchronize on the result
    variable? How many threads do you use? Who does the generation of numbers? Who
    adds them up?
  id: totrans-1130
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作似乎是一个很好的并行化候选，特别是对于大的*n*值。但你应该从哪里开始？你是在结果变量上同步吗？你使用多少线程？谁生成数字？谁将它们加起来？
- en: Don’t worry about all of this. It’s a much simpler problem to solve if you adopt
    parallel streams!
  id: totrans-1131
  prefs: []
  type: TYPE_NORMAL
  zh: 不要担心这些。如果你采用并行流，这是一个要简单得多的问题！
- en: 7.1.1\. Turning a sequential stream into a parallel one
  id: totrans-1132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.1\. 将顺序流转换为并行流
- en: 'You can make the former functional reduction process (summing) run in parallel
    by turning the stream into a parallel one; call the method `parallel` on the sequential
    stream:'
  id: totrans-1133
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过将流转换为并行流来使前面的函数式归约过程（求和）并行运行；在顺序流上调用`parallel`方法：
- en: '[PRE202]'
  id: totrans-1134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE202]'
- en: '***1* Turns the stream into a parallel one**'
  id: totrans-1135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 将流转换为并行流**'
- en: In the previous code, the reduction process used to sum all the numbers in the
    stream works in a way that’s similar to what’s described in [section 5.4.1](kindle_split_016.xhtml#ch05lev2sec8).
    The difference is that the stream is now internally divided into multiple chunks.
    As a result, the reduction operation can work on the various chunks independently
    and in parallel, as shown in [figure 7.1](#ch07fig01). Finally, the same reduction
    operation combines the values resulting from the partial reductions of each substream,
    producing the result of the reduction process on the whole initial stream.
  id: totrans-1136
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码中，用于对流中所有数字求和的归约过程的工作方式与[第5.4.1节](kindle_split_016.xhtml#ch05lev2sec8)中描述的方式类似。不同之处在于，流现在被内部分割成多个块。因此，归约操作可以独立且并行地在各个块上工作，如图7.1所示。最后，相同的归约操作将每个子流的局部归约结果值合并，从而产生整个初始流的归约过程的结果。
- en: Figure 7.1\. A parallel reduction operation
  id: totrans-1137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.1\. 并行归约操作
- en: '![](Images/07fig01_alt.jpg)'
  id: totrans-1138
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/07fig01_alt.jpg)'
- en: 'Note that, in reality, calling the method `parallel` on a sequential stream
    doesn’t imply any concrete transformation on the stream itself. Internally, a
    `boolean` flag is set to signal that you want to run in parallel all the operations
    that follow the invocation to `parallel`. Similarly, you can turn a parallel stream
    into a sequential one by invoking the method `sequential` on it. Note that you
    might think that by combining these two methods you could achieve finer-grained
    control over which operations you want to perform in parallel and which ones sequentially
    while traversing the stream. For example, you could do something like the following:'
  id: totrans-1139
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在现实中，在顺序流上调用`parallel`方法并不意味着对流本身进行任何具体的转换。内部，会设置一个`boolean`标志来表示你希望并行执行所有跟随`parallel`调用之后的操作。同样，你也可以通过在并行流上调用`sequential`方法将其转换为顺序流。注意，你可能认为通过结合这两种方法，你可以更精细地控制你在遍历流时希望并行执行哪些操作以及哪些操作是顺序执行的。例如，你可以做如下操作：
- en: '[PRE203]'
  id: totrans-1140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE203]'
- en: But the last call to `parallel` or `sequential` wins and affects the pipeline
    globally. In this example, the pipeline will be executed in parallel because that’s
    the last call in the pipeline.
  id: totrans-1141
  prefs: []
  type: TYPE_NORMAL
  zh: 但最后调用`parallel`或`sequential`的会生效并影响整个流水线。在这个例子中，流水线将并行执行，因为这是流水线中的最后一个调用。
- en: '|  |'
  id: totrans-1142
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: '**Configuring the thread pool used by parallel streams**'
  id: totrans-1143
  prefs: []
  type: TYPE_NORMAL
  zh: '**配置并行流使用的线程池**'
- en: Looking at the stream’s `parallel` method, you may wonder where the threads
    used by the parallel stream come from, how many there are, and how you can customize
    the process.
  id: totrans-1144
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下流的`parallel`方法，你可能想知道并行流使用的线程从哪里来，有多少个，以及如何自定义这个过程。
- en: Parallel streams internally use the default `ForkJoinPool` (you’ll learn more
    about the fork/join framework in [section 7.2](#ch07lev1sec2)), which by default
    has as many threads as you have processors, as returned by `Runtime.getRuntime().available-Processors()`.
  id: totrans-1145
  prefs: []
  type: TYPE_NORMAL
  zh: 并行流内部使用默认的`ForkJoinPool`（你将在[第7.2节](#ch07lev1sec2)中了解更多关于fork/join框架的信息），默认情况下，线程的数量与处理器数量相同，由`Runtime.getRuntime().availableProcessors()`返回。
- en: 'But you can change the size of this pool using the system property `java.util.concurrent.ForkJoinPool.common.parallelism`,
    as in the following example:'
  id: totrans-1146
  prefs: []
  type: TYPE_NORMAL
  zh: 但你可以使用系统属性`java.util.concurrent.ForkJoinPool.common.parallelism`来改变这个池的大小，如下例所示：
- en: '[PRE204]'
  id: totrans-1147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE204]'
- en: This is a global setting, so it will affect all the parallel streams in your
    code. Conversely, it currently isn’t possible to specify this value for a single
    parallel stream. In general, having the size of the `ForkJoinPool` equal to the
    number of processors on your machine is a meaningful default, and we strongly
    suggest that you not modify it unless you have a good reason for doing so.
  id: totrans-1148
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个全局设置，因此它将影响你代码中的所有并行流。相反，目前还不可能为单个并行流指定这个值。一般来说，让`ForkJoinPool`的大小等于机器上的处理器数量是一个有意义的默认值，我们强烈建议除非你有充分的理由，否则不要修改它。
- en: '|  |'
  id: totrans-1149
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Returning to the number-summing exercise, we said that you can expect a significant
    performance improvement in its parallel version when running it on a multicore
    processor. You now have three methods executing exactly the same operation in
    three different ways (iterative style, sequential reduction, and parallel reduction),
    so let’s see which is the fastest one!
  id: totrans-1150
  prefs: []
  type: TYPE_NORMAL
  zh: 回到求和练习，我们说过，当在多核处理器上运行其并行版本时，你可以期待显著的性能提升。现在你有三种方法以三种不同的方式执行完全相同的操作（迭代风格、顺序归约和并行归约），那么让我们看看哪个是最快的！
- en: 7.1.2\. Measuring stream performance
  id: totrans-1151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.2. 测量流性能
- en: 'We claimed that the parallelized summing method should perform better than
    the sequential and the iterative methods. Nevertheless, in software engineering,
    guessing is never a good idea! When optimizing performance, you should always
    follow three golden rules: measure, measure, measure. To this purpose we will
    implement a microbenchmark using a library called Java Microbenchmark Harness
    (JMH). This is a toolkit that helps to create, in a simple, annotation-based way,
    reliable microbenchmarks for Java programs and for any other language targeting
    the Java Virtual Machine (JVM). In fact, developing correct and meaningful benchmarks
    for programs running on the JVM is not an easy task, because there are many factors
    to consider like the warm-up time required by HotSpot to optimize the bytecode
    and the overhead introduced by the garbage collector. If you’re using Maven as
    your build tool, then to start using JMH in your project you add a couple of dependencies
    to your `pom.xml` file (which defines the Maven build process).'
  id: totrans-1152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声称并行化求和的方法应该比顺序和迭代方法表现更好。然而，在软件工程中，猜测永远不是一个好主意！在优化性能时，你应该始终遵循三个黄金法则：测量，测量，再测量。为此，我们将使用名为
    Java Microbenchmark Harness (JMH) 的库来实现一个微基准测试。这是一个工具包，它以简单、基于注解的方式帮助创建可靠的微基准测试，用于
    Java 程序以及任何其他针对 Java 虚拟机 (JVM) 的语言。实际上，为在 JVM 上运行的程序开发正确且有意义的基准测试并不容易，因为有许多因素需要考虑，例如
    HotSpot 需要多少预热时间来优化字节码以及垃圾收集器引入的开销。如果你使用 Maven 作为构建工具，那么要开始在项目中使用 JMH，你需要在 `pom.xml`
    文件（它定义了 Maven 构建过程）中添加几个依赖项。
- en: '[PRE205]'
  id: totrans-1153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE205]'
- en: 'The first library is the core JMH implementation while the second contains
    an annotation processor that helps to generate a Java Archive (JAR) file through
    which you can conveniently run your benchmark once you have also added the following
    plugin to your Maven configuration:'
  id: totrans-1154
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个库是 JMH 的核心实现，而第二个包含一个注解处理器，它有助于通过生成 Java 归档（JAR）文件来运行你的基准测试，一旦你也在你的 Maven
    配置中添加了以下插件：
- en: '[PRE206]'
  id: totrans-1155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE206]'
- en: Having done this, you can benchmark the `sequentialSum` method introduced at
    the beginning of this section in this simple way, as shown in the next listing.
  id: totrans-1156
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，你可以以这种方式基准测试本节开头引入的 `sequentialSum` 方法，如下一个列表所示。
- en: Listing 7.1\. Measuring performance of a function summing the first *n* numbers
  id: totrans-1157
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.1\. 测量累加前 *n* 个数字的函数的性能
- en: '[PRE207]'
  id: totrans-1158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE207]'
- en: '***1* Measures the average time taken to the benchmarked method**'
  id: totrans-1159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 测量基准测试方法的平均耗时**'
- en: '***2* Prints benchmark results using milliseconds as time unit**'
  id: totrans-1160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 使用毫秒作为时间单位打印基准测试结果**'
- en: '***3* Executes the benchmark 2 times to increase the reliability of results,
    with 4Gb of heap space**'
  id: totrans-1161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 执行基准测试 2 次，以增加结果的可靠性，使用 4Gb 的堆空间**'
- en: '***4* The method to be benchmarked**'
  id: totrans-1162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 要基准测试的方法**'
- en: '***5* Tries to run the garbage collector after each iteration of the benchmark**'
  id: totrans-1163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 尝试在基准测试的每次迭代后运行垃圾收集器**'
- en: 'When you compile this class, the Maven plugin configured before generates a
    second JAR file named benchmarks.jar that you can run as follows:'
  id: totrans-1164
  prefs: []
  type: TYPE_NORMAL
  zh: 当你编译这个类时，之前配置的 Maven 插件会生成一个名为 benchmarks.jar 的第二个 JAR 文件，你可以按照以下方式运行它：
- en: '[PRE208]'
  id: totrans-1165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE208]'
- en: We configured the benchmark to use an oversized heap to avoid any influence
    of the garbage collector as much as possible, and for the same reason, we tried
    to enforce the garbage collector to run after each iteration of our benchmark.
    Despite all these precautions, it has to be noted that the results should be taken
    with a grain of salt. Many factors will influence the execution time, such as
    how many cores your machine supports! You can try this on your own machine by
    running the code available on the book’s repository.
  id: totrans-1166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们配置基准测试使用过大的堆来尽可能避免垃圾收集器的影响，出于同样的原因，我们尝试强制垃圾收集器在基准测试的每次迭代后运行。尽管采取了所有这些预防措施，但必须注意的是，结果应该带着怀疑的态度来看待。许多因素会影响执行时间，例如你的机器支持多少核心！你可以通过运行书中仓库中提供的代码在自己的机器上尝试这个。
- en: 'When you launch the former, command JMH to execute 20 warm-up iterations of
    the benchmarked method to allow HotSpot to optimize the code, and then 20 more
    iterations that are used to calculate the final result. These 20+20 iterations
    are the default behavior of JMH, but you can change both values either through
    other JMH specific annotations or, even more conveniently, by adding them to the
    command line using the `-w` and `-i` flags. Executing it on a computer equipped
    with an Intel i7-4600U 2.1 GHz quad-core, it prints the following result:'
  id: totrans-1167
  prefs: []
  type: TYPE_NORMAL
  zh: 当你启动前者时，让JMH执行20次基准方法的预热迭代，以允许HotSpot优化代码，然后执行20次更多迭代，这些迭代用于计算最终结果。这20+20次迭代是JMH的默认行为，但你可以通过其他JMH特定注解或更方便地通过使用`-w`和`-i`标志将它们添加到命令行来更改这两个值。在配备Intel
    i7-4600U 2.1 GHz四核的计算机上执行它，会打印出以下结果：
- en: '[PRE209]'
  id: totrans-1168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE209]'
- en: You should expect that the iterative version using a traditional `for` loop
    runs much faster because it works at a much lower level and, more important, doesn’t
    need to perform any boxing or unboxing of the primitive values. We can check this
    intuition by adding a second method to the benchmarking class of [listing 7.1](#ch07ex01)
    and also annotate it with `@Benchmark:`
  id: totrans-1169
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该预期使用传统`for`循环的迭代版本会运行得更快，因为它在更低级别工作，更重要的是，它不需要执行任何原始值的装箱或拆箱。我们可以通过向[列表7.1](#ch07ex01)的基准测试类添加第二个方法并使用`@Benchmark`注解来检查这个直觉。
- en: '[PRE210]'
  id: totrans-1170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE210]'
- en: 'Running this second benchmark (possibly having commented out the first one
    to avoid running it again) on our testing machine, we obtained the following result:'
  id: totrans-1171
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的测试机器上运行这个第二个基准（可能已经注释掉第一个以避免再次运行）后，我们得到了以下结果：
- en: '[PRE211]'
  id: totrans-1172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE211]'
- en: 'This confirmed our expectations: the iterative version is almost 40 times faster
    than the one using the sequential stream for the reasons we anticipated. Now let’s
    do the same with the version using the parallel stream, also adding that method
    to our benchmarking class. We obtained the following outcome:'
  id: totrans-1173
  prefs: []
  type: TYPE_NORMAL
  zh: 这证实了我们的预期：迭代版本几乎比我们预期的使用顺序流的版本快40倍。现在让我们用使用并行流的版本做同样的操作，也将该方法添加到我们的基准测试类中。我们得到了以下结果：
- en: '[PRE212]'
  id: totrans-1174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE212]'
- en: 'This is quite disappointing: the parallel version of the summing method isn’t
    taking any advantage of our quad-core CPU and is around five times slower than
    the sequential one. How can you explain this unexpected result? Two issues are
    mixed together:'
  id: totrans-1175
  prefs: []
  type: TYPE_NORMAL
  zh: 这相当令人失望：求和方法的并行版本并没有充分利用我们的四核CPU，其速度比顺序版本慢大约五倍。你如何解释这个意外的结果？有两个问题混合在一起：
- en: '`iterate` generates boxed objects, which have to be unboxed to numbers before
    they can be added.'
  id: totrans-1176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iterate`生成装箱对象，在它们可以相加之前必须将它们拆箱成数字。'
- en: '`iterate` is difficult to divide into independent chunks to execute in parallel.'
  id: totrans-1177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iterate`难以分割成可以独立执行的独立块。'
- en: The second issue is particularly interesting because you need to keep a mental
    model that some stream operations are more parallelizable than others. Specifically,
    the `iterate` operation is hard to split into chunks that can be executed independently,
    because the input of one function application always depends on the result of
    the previous application, as illustrated in [figure 7.2](#ch07fig02).
  id: totrans-1178
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问题特别有趣，因为你需要保持一个心理模型，即某些流操作比其他操作更容易并行化。具体来说，`iterate`操作难以分割成可以独立执行的块，因为一个函数应用的输入总是依赖于前一个应用的结果，如[图7.2](#ch07fig02)所示。
- en: Figure 7.2\. `iterate` is inherently sequential.
  id: totrans-1179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.2\. `iterate`本质上是顺序的。
- en: '![](Images/07fig02.jpg)'
  id: totrans-1180
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/07fig02.jpg)'
- en: 'This means that in this specific case the reduction process isn’t proceeding
    as depicted in [figure 7.1](#ch07fig01): the whole list of numbers isn’t available
    at the beginning of the reduction process, making it impossible to efficiently
    partition the stream in chunks to be processed in parallel. By flagging the stream
    as parallel, you’re adding the overhead of allocating each sum operation on a
    different thread to the sequential processing.'
  id: totrans-1181
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在这个特定情况下，减少过程并没有像[图7.1](#ch07fig01)中描述的那样进行：在减少过程的开始时，整个数字列表不可用，这使得无法有效地将流分成要并行处理的块。通过将流标记为并行，你给顺序处理增加了在每个不同线程上分配每个求和操作的开销。
- en: This demonstrates how parallel programming can be tricky and sometimes counterintuitive.
    When misused (for example, using an operation that’s not parallel-friendly, like
    `iterate`) it can worsen the overall performance of your programs, so it’s mandatory
    to understand what happens behind the scenes when you invoke that apparently magic
    `parallel` method.
  id: totrans-1182
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了并行编程可能很棘手，有时甚至反直觉。当误用（例如，使用不友好的并行操作，如 `iterate`）时，它可能会降低程序的整体性能，因此理解当你调用那个看似神奇的
    `parallel` 方法时幕后发生了什么是强制性的。
- en: Using more specialized methods
  id: totrans-1183
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用更专业的方法
- en: 'So how can you use your multicore processors and use the stream to perform
    a parallel sum in an effective way? We discussed a method called `LongStream.rangeClosed`
    in [chapter 5](kindle_split_016.xhtml#ch05). This method has two benefits compared
    to `iterate`:'
  id: totrans-1184
  prefs: []
  type: TYPE_NORMAL
  zh: 那么你如何有效地使用多核处理器和流来执行并行求和呢？我们已经在[第5章](kindle_split_016.xhtml#ch05)中讨论了一种名为 `LongStream.rangeClosed`
    的方法。与 `iterate` 相比，这种方法有两个优点：
- en: '`LongStream.rangeClosed` works on primitive `long` numbers directly so there’s
    no boxing and unboxing overhead.'
  id: totrans-1185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LongStream.rangeClosed` 直接在原始 `long` 数字上工作，因此没有装箱和拆箱的开销。'
- en: '`LongStream.rangeClosed` produces ranges of numbers, which can be easily split
    into independent chunks. For example, the range 1–20 can be split into 1–5, 6–10,
    11–15, and 16–20.'
  id: totrans-1186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LongStream.rangeClosed` 生成数字范围，这些范围可以轻松地分割成独立的块。例如，范围 1–20 可以分割成 1–5、6–10、11–15
    和 16–20。'
- en: 'Let’s first see how it performs on a sequential stream by adding the following
    method to our benchmarking class to check if the overhead associated with unboxing
    is relevant:'
  id: totrans-1187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先通过向我们的基准测试类添加以下方法来查看它在顺序流上的性能，以检查与拆箱相关的开销是否相关：
- en: '[PRE213]'
  id: totrans-1188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE213]'
- en: This time the output is
  id: totrans-1189
  prefs: []
  type: TYPE_NORMAL
  zh: 这次输出的是
- en: '[PRE214]'
  id: totrans-1190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE214]'
- en: The numeric stream is much faster than the earlier sequential version, generated
    with the `iterate` factory method, because the numeric stream avoids all the overhead
    caused by all the unnecessary autoboxing and auto-unboxing operations performed
    by the nonspecialized stream. This is evidence that choosing the right data structures
    is often more important than parallelizing the algorithm that uses them. But what
    happens if you try to use a parallel stream in this new version that follows?
  id: totrans-1191
  prefs: []
  type: TYPE_NORMAL
  zh: 数字流比之前使用 `iterate` 工厂方法生成的早期顺序版本要快得多，因为数字流避免了所有由非专业流执行的所有不必要的自动装箱和自动拆箱操作造成的开销。这是选择正确数据结构通常比并行化使用它们的算法更重要这一点的证据。但是，如果你尝试使用这个新版本中的并行流会怎样呢？
- en: '[PRE215]'
  id: totrans-1192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE215]'
- en: Now, adding this method to our benchmarking class we obtained
  id: totrans-1193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将此方法添加到我们的基准测试类中，我们得到了
- en: '[PRE216]'
  id: totrans-1194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE216]'
- en: Finally, we got a parallel reduction that’s faster than its sequential counterpart,
    because this time the reduction operation can be executed as shown in [figure
    7.1](#ch07fig01). This also demonstrates that using the right data structure *and*
    then making it work in parallel guarantees the best performance. Note that this
    latest version is also around 20% faster than the original iterative one, demonstrating
    that, when used correctly, the functional-programming style allows us to use the
    parallelism of modern multicore CPUs in a simpler and more straightforward way
    than its imperative counterpart.
  id: totrans-1195
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们得到了一个比其顺序对应版本更快的并行归约，因为这次归约操作可以像在[图7.1](#ch07fig01)中所示的那样执行。这也表明，使用正确的数据结构*并且*使其并行运行可以保证最佳性能。请注意，这个最新版本也比原始迭代版本快约20%，这表明，当正确使用时，函数式编程风格允许我们以比命令式对应物更简单、更直接的方式使用现代多核CPU的并行性。
- en: Nevertheless, keep in mind that parallelization doesn’t come for free. The parallelization
    process itself requires you to recursively partition the stream, assign the reduction
    operation of each substream to a different thread, and then combine the results
    of these operations in a single value. But moving data between multiple cores
    is also more expensive than you might expect, so it’s important that work to be
    done in parallel on another core takes longer than the time required to transfer
    the data from one core to another. In general, there are many cases where it isn’t
    possible or convenient to use parallelization. But before you use a parallel `stream`
    to make your code faster, you have to be sure that you’re using it correctly;
    it’s not helpful to produce a result in less time if the result will be wrong.
    Let’s look at a common pitfall.
  id: totrans-1196
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，请记住，并行化并非免费午餐。并行化过程本身要求你递归地分割流，将每个子流的归约操作分配给不同的线程，然后在一个单一值中合并这些操作的结果。但将数据在多个核心之间移动比你预期的要昂贵得多，因此，确保在另一个核心上并行执行的工作比从一个核心到另一个核心传输数据所需的时间更长是很重要的。一般来说，有许多情况下无法或不太方便使用并行化。但在你使用并行`stream`来加速你的代码之前，你必须确保你使用它是正确的；如果结果会出错，那么即使结果更快也是没有帮助的。让我们看看一个常见的陷阱。
- en: 7.1.3\. Using parallel streams correctly
  id: totrans-1197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.3\. 正确使用并行流
- en: 'The main cause of errors generated by misuse of parallel streams is the use
    of algorithms that mutate some shared state. Here’s a way to implement the sum
    of the first *n* natural numbers by mutating a shared accumulator:'
  id: totrans-1198
  prefs: []
  type: TYPE_NORMAL
  zh: 由滥用并行流产生的错误的主要原因是在算法中修改了一些共享状态。以下是通过修改共享累加器来实现前 *n* 个自然数之和的方法：
- en: '[PRE217]'
  id: totrans-1199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE217]'
- en: 'It’s quite common to write this sort of code, especially for developers who
    are familiar with imperative programming paradigms. This code closely resembles
    what you’re used to doing when iterating imperatively a list of numbers: you initialize
    an accumulator and traverse the elements in the list one by one, adding them on
    the accumulator.'
  id: totrans-1200
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的代码很常见，尤其是对于熟悉命令式编程范式的开发者来说。这段代码与你习惯于迭代数字列表时的操作非常相似：你初始化一个累加器，逐个遍历列表中的元素，并将它们添加到累加器中。
- en: 'What’s wrong with this code? Unfortunately, it’s irretrievably broken because
    it’s fundamentally sequential. You have a data race on every access of `total`.
    And if you try to fix that with synchronization, you’ll lose all your parallelism.
    To understand this, let’s try to turn the `stream` into a parallel one:'
  id: totrans-1201
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码有什么问题？不幸的是，它是无法恢复的，因为它是基本顺序的。你每次访问 `total` 时都会有一个数据竞争。如果你尝试通过同步来修复它，你将失去所有的并行性。为了理解这一点，让我们尝试将
    `stream` 转换为并行流：
- en: '[PRE218]'
  id: totrans-1202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE218]'
- en: 'Try to run this last method with the harness of [listing 7.1](#ch07ex01), also
    printing the result of each execution:'
  id: totrans-1203
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用[列表 7.1](#ch07ex01)的 harness 运行这个最后的方法，并打印每次执行的输出：
- en: '[PRE219]'
  id: totrans-1204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE219]'
- en: 'You could obtain something like the following:'
  id: totrans-1205
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会得到以下类似的结果：
- en: '[PRE220]'
  id: totrans-1206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE220]'
- en: This time the performance of your method isn’t important. The only relevant
    thing is that each execution returns a different result, all distant from the
    correct value of `50000005000000`. This is caused by the fact that multiple threads
    are concurrently accessing the accumulator and, in particular, executing `total
    += value`, which, despite its appearance, isn’t an atomic operation. The origin
    of the problem is that the method invoked inside the `forEach` block has the side
    effect of changing the mutable state of an object shared among multiple threads.
    It’s mandatory to avoid these kinds of situations if you want to use parallel
    streams without incurring similar bad surprises.
  id: totrans-1207
  prefs: []
  type: TYPE_NORMAL
  zh: 这次你的方法性能并不重要。唯一相关的是，每次执行都返回不同的结果，所有结果都与正确的值 `50000005000000` 相去甚远。这是由于多个线程同时访问累加器，特别是执行
    `total += value`，尽管它看起来是原子的，但实际上并不是。问题的根源在于 `forEach` 块内部调用的方法具有改变多个线程之间共享对象可变状态的外部效应。如果你想在没有任何类似坏惊喜的情况下使用并行流，就必须避免这些情况。
- en: Now you know that a shared mutable state doesn’t play well with parallel streams
    and with parallel computations in general. We’ll come back to this idea of avoiding
    mutation in [chapters 18](kindle_split_033.xhtml#ch18) and [19](kindle_split_034.xhtml#ch19)
    when discussing functional programming in more detail. For now, keep in mind that
    avoiding a shared mutable state ensures that your parallel stream will produce
    the right result. Next, we’ll look at some practical advice you can use to figure
    out when it’s appropriate to use parallel streams to gain performance.
  id: totrans-1208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道共享可变状态与并行流以及一般的并行计算不太兼容。我们将在第 [18](kindle_split_033.xhtml#ch18) 章和第 [19](kindle_split_034.xhtml#ch19)
    章中更详细地讨论函数式编程时回到避免突变这个想法。现在，请记住，避免共享可变状态可以确保你的并行流产生正确的结果。接下来，我们将探讨一些实用的建议，你可以使用这些建议来确定何时使用并行流以获得性能提升。
- en: 7.1.4\. Using parallel streams effectively
  id: totrans-1209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.4\. 高效使用并行流
- en: 'In general, it’s impossible (and pointless) to try to give any quantitative
    hint on when to use a parallel stream, because any specific criterion such as
    “only when the stream contains more than a thousand elements” could be correct
    for a specific operation running on a specific machine, but completely wrong in
    a marginally different context. Nonetheless, it’s at least possible to provide
    some qualitative advice that could be useful when deciding whether it makes sense
    to use a parallel stream in a certain situation:'
  id: totrans-1210
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，尝试给出何时使用并行流的任何定量提示都是不可能的（也是没有意义的），因为任何特定的标准，例如“只有当流包含超过一千个元素时”，对于在特定机器上运行的特定操作可能是正确的，但在略微不同的环境中则完全错误。尽管如此，至少可以提供一些定性的建议，这些建议在决定在某种情况下是否使用并行流时可能是有用的：
- en: If in doubt, measure. Turning a sequential stream into a parallel one is trivial
    but not always the right thing to do. As we already demonstrated in this section,
    a parallel stream isn’t always faster than the corresponding sequential version.
    Moreover, parallel streams can sometimes work in a counterintuitive way, so the
    first and most important suggestion when choosing between sequential and parallel
    streams is to always check their performance with an appropriate benchmark.
  id: totrans-1211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有疑问，请进行测量。将顺序流转换为并行流是微不足道的，但并不总是正确的事情。正如我们已经在本节中展示的那样，并行流并不总是比相应的顺序版本快。此外，并行流有时可能会以反直觉的方式工作，因此在选择顺序流和并行流时，最重要的建议是始终使用适当的基准测试来检查它们的性能。
- en: Watch out for boxing. Automatic boxing and unboxing operations can dramatically
    hurt performance. Java 8 includes primitive streams (`IntStream`, `LongStream`,
    and `DoubleStream`) to avoid such operations, so use them when possible.
  id: totrans-1212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意装箱问题。自动装箱和拆箱操作可能会严重影响性能。Java 8 包含原始流（`IntStream`、`LongStream` 和 `DoubleStream`），以避免此类操作，因此尽可能使用它们。
- en: Some operations naturally perform worse on a parallel stream than on a sequential
    stream. In particular, operations such as `limit` and `findFirst` that rely on
    the order of the elements are expensive in a parallel stream. For example, `findAny`
    will perform better than `findFirst` because it isn’t constrained to operate in
    the encounter order. You can always turn an ordered stream into an unordered stream
    by invoking the method `unordered` on it. For instance, if you need *N* elements
    of your stream and you’re not necessarily interested in the *first N* ones, calling
    `limit` on an unordered parallel stream may execute more efficiently than on a
    stream with an encounter order (for example, when the source is a `List`).
  id: totrans-1213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些操作在并行流上的性能不如在顺序流上。特别是，依赖于元素顺序的操作，如 `limit` 和 `findFirst`，在并行流中成本较高。例如，`findAny`
    的性能将优于 `findFirst`，因为它不受操作顺序的限制。你可以通过调用 `unordered` 方法将有序流转换为无序流。例如，如果你需要流中的 *N*
    个元素，而你并不一定对前 *N* 个元素感兴趣，对无序并行流调用 `limit` 可能比在有序流（例如，当源是 `List` 时）上执行更有效。
- en: Consider the total computational cost of the pipeline of operations performed
    by the stream. With *N* being the number of elements to be processed and *Q* the
    approximate cost of processing one of these elements through the stream pipeline,
    the product of *N*Q* gives a rough qualitative estimation of this cost. A higher
    value for *Q* implies a better chance of good performance when using a parallel
    stream.
  id: totrans-1214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑流执行的操作的总计算成本。其中 *N* 是要处理的元素数量，*Q* 是通过流管道处理这些元素之一的近似成本，*N*Q* 的乘积给出了这种成本的大致定性估计。*Q*
    的值越高，使用并行流时获得良好性能的机会就越大。
- en: For a small amount of data, choosing a parallel stream is almost never a winning
    decision. The advantages of processing in parallel only a few elements aren’t
    enough to compensate for the additional cost introduced by the parallelization
    process.
  id: totrans-1215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于少量数据，选择并行流几乎从未是明智的决定。并行处理仅几个元素的优势不足以弥补并行化过程带来的额外成本。
- en: Take into account how well the data structure underlying the stream decomposes.
    For instance, an `ArrayList` can be split much more efficiently than a `LinkedList`,
    because the first can be evenly divided without traversing it, as it’s necessary
    to do with the second. Also, the primitive streams created with the `range` factory
    method can be decomposed quickly. Finally, as you’ll learn in [section 7.3](#ch07lev1sec3),
    you can get full control of this decomposition process by implementing your own
    `Spliterator`.
  id: totrans-1216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑底层数据结构如何有效地分解流。例如，`ArrayList`比`LinkedList`更有效地分割，因为前者可以均匀分割而不需要遍历，而后者则必须这样做。此外，使用`range`工厂方法创建的原始流可以快速分解。最后，正如你将在[第7.3节](#ch07lev1sec3)中学习的，你可以通过实现自己的`Spliterator`来完全控制这个分解过程。
- en: The characteristics of a stream, and how the intermediate operations through
    the pipeline modify them, can change the performance of the decomposition process.
    For example, a `SIZED` stream can be divided into two equal parts, and then each
    part can be processed in parallel more effectively, but a filter operation can
    throw away an unpredictable number of elements, making the size of the stream
    itself unknown.
  id: totrans-1217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流的特性以及通过管道进行的中间操作如何修改它们，可以改变分解过程的表现。例如，一个`SIZED`流可以被分成两个相等的部分，然后每个部分可以更有效地并行处理，但过滤器操作可能会丢弃不可预测数量的元素，使得流本身的大小变得未知。
- en: Consider whether a terminal operation has a cheap or expensive merge step (for
    example, the `combiner` method in a `Collector`). If this is expensive, then the
    cost caused by the combination of the partial results generated by each substream
    can outweigh the performance benefits of a parallel stream.
  id: totrans-1218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑终端操作是否具有昂贵或便宜的合并步骤（例如，`Collector`中的`combiner`方法）。如果这是昂贵的，那么由每个子流生成的部分结果的合并所造成的成本可能会超过并行流带来的性能优势。
- en: '[Table 7.1](#ch07table01) gives a summary of the parallel-friendliness of certain
    stream sources in terms of their decomposability.'
  id: totrans-1219
  prefs: []
  type: TYPE_NORMAL
  zh: '[表7.1](#ch07table01)总结了某些流源在可分解性方面的并行友好性。'
- en: Table 7.1\. Stream sources and decomposability
  id: totrans-1220
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表7.1\. 流源和可分解性
- en: '| Source | Decomposability |'
  id: totrans-1221
  prefs: []
  type: TYPE_TB
  zh: '| 源 | 可分解性 |'
- en: '| --- | --- |'
  id: totrans-1222
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| ArrayList | Excellent |'
  id: totrans-1223
  prefs: []
  type: TYPE_TB
  zh: '| ArrayList | 优秀 |'
- en: '| LinkedList | Poor |'
  id: totrans-1224
  prefs: []
  type: TYPE_TB
  zh: '| LinkedList | 差 |'
- en: '| IntStream.range | Excellent |'
  id: totrans-1225
  prefs: []
  type: TYPE_TB
  zh: '| IntStream.range | 优秀 |'
- en: '| Stream.iterate | Poor |'
  id: totrans-1226
  prefs: []
  type: TYPE_TB
  zh: '| Stream.iterate | 差 |'
- en: '| HashSet | Good |'
  id: totrans-1227
  prefs: []
  type: TYPE_TB
  zh: '| HashSet | 良好 |'
- en: '| TreeSet | Good |'
  id: totrans-1228
  prefs: []
  type: TYPE_TB
  zh: '| TreeSet | 良好 |'
- en: Finally, we need to emphasize that the infrastructure used behind the scenes
    by parallel streams to execute operations in parallel is the fork/join framework
    introduced in Java 7\. The parallel summing example proved that it’s vital to
    have a good understanding of the parallel stream internals in order to use them
    correctly, so we’ll investigate in detail the fork/join framework in the next
    section.
  id: totrans-1229
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要强调，并行流在幕后使用的用于并行执行操作的架构是Java 7中引入的分支/合并框架。并行求和示例证明，为了正确使用并行流，了解并行流的内部机制至关重要，因此我们将在下一节详细研究分支/合并框架。
- en: 7.2\. The fork/join framework
  id: totrans-1230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2\. 分支/合并框架
- en: The fork/join framework was designed to recursively split a parallelizable task
    into smaller tasks and then combine the results of each subtask to produce the
    overall result. It’s an implementation of the `ExecutorService` interface, which
    distributes those subtasks to worker threads in a thread pool, called `ForkJoinPool`.
    Let’s start by exploring how to define a task and subtasks.
  id: totrans-1231
  prefs: []
  type: TYPE_NORMAL
  zh: 分支/合并框架被设计为递归地将可并行化的任务分解成更小的任务，然后将每个子任务的输出组合起来以产生整体结果。它是`ExecutorService`接口的实现，将这些子任务分配到线程池中的工作线程，称为`ForkJoinPool`。让我们首先探索如何定义任务和子任务。
- en: 7.2.1\. Working with RecursiveTask
  id: totrans-1232
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.1\. 与RecursiveTask一起工作
- en: 'To submit tasks to this pool, you have to create a subclass of `RecursiveTask<R>`,
    where `R` is the type of the result produced by the parallelized task (and each
    of its subtasks) or of `RecursiveAction` if the task returns no result (it could
    be updating other nonlocal structures, though). To define `RecursiveTask`s you
    need only implement its single abstract method, `compute`:'
  id: totrans-1233
  prefs: []
  type: TYPE_NORMAL
  zh: 要向此池提交任务，您必须创建一个 `RecursiveTask<R>` 的子类，其中 `R` 是并行化任务（及其每个子任务）产生的结果的类型，或者如果任务不返回结果（尽管它可能更新其他非局部结构），则为
    `RecursiveAction`。要定义 `RecursiveTask`s，您只需要实现其单个抽象方法 `compute`：
- en: '[PRE221]'
  id: totrans-1234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE221]'
- en: 'This method defines both the logic of splitting the task at hand into subtasks
    and the algorithm to produce the result of a single subtask when it’s no longer
    possible or convenient to further divide it. For this reason an implementation
    of this method often resembles the following pseudocode:'
  id: totrans-1235
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法定义了将当前任务拆分为子任务的逻辑以及当不再可能或方便进一步拆分时产生单个子任务结果的算法。因此，此方法的实现通常类似于以下伪代码：
- en: '[PRE222]'
  id: totrans-1236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE222]'
- en: In general, there are no precise criteria for deciding whether a given task
    should be further divided or not, but there are various heuristics that you can
    follow to help you with this decision. We clarify them in more detail in [section
    7.2.2](#ch07lev2sec6). The recursive task-splitting process is visually synthesized
    by [figure 7.3](#ch07fig03).
  id: totrans-1237
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，没有精确的标准来决定是否应该进一步拆分给定的任务，但有各种启发式方法可以帮助您做出这个决定。我们将在 [7.2.2 节](#ch07lev2sec6)
    中更详细地说明这些方法。递归任务拆分过程在 [图 7.3](#ch07fig03) 中以视觉形式综合展示。
- en: Figure 7.3\. The fork/join process
  id: totrans-1238
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 7.3\. Fork/join 过程
- en: '![](Images/07fig03_alt.jpg)'
  id: totrans-1239
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/07fig03_alt.jpg)'
- en: As you might have noticed, this is nothing more than the parallel version of
    the well-known divide-and-conquer algorithm. To demonstrate a practical example
    of how to use the fork/join framework and to build on our previous examples, let’s
    try to calculate the sum of a range of numbers (here represented by an array of
    numbers `long[]`) using this framework. As explained, you need to first provide
    an implementation for the `RecursiveTask` class, as shown by the `ForkJoinSumCalculator`
    in listing 7.2.
  id: totrans-1240
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所注意到的，这不过是众所周知的分而治之算法的并行版本。为了演示如何使用 fork/join 框架并基于我们之前的示例，让我们尝试使用此框架计算一系列数字（在此由数字数组
    `long[]` 表示）的总和。如前所述，您需要首先为 `RecursiveTask` 类提供一个实现，如列表 7.2 中的 `ForkJoinSumCalculator`
    所示。
- en: Listing 7.2\. Executing a parallel sum using the fork/join framework
  id: totrans-1241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.2\. 使用 fork/join 框架执行并行求和
- en: '[PRE223]'
  id: totrans-1242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE223]'
- en: '***1* Extends RecursiveTask to create a task usable with the fork/join framework**'
  id: totrans-1243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 将 RecursiveTask 扩展为可用于 fork/join 框架的任务**'
- en: '***2* The array of numbers to be summed**'
  id: totrans-1244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 要求和的数字数组**'
- en: '***3* The initial and final positions of the subarray processed by this subtask**'
  id: totrans-1245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 此子任务处理的子数组的初始和最终位置**'
- en: '***4* The size threshold for splitting into subtasks**'
  id: totrans-1246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 将任务拆分为子任务的大小阈值**'
- en: '***5* Public constructor to create the main task**'
  id: totrans-1247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 公共构造函数用于创建主任务**'
- en: '***6* Private constructor to create subtasks of the main task**'
  id: totrans-1248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 私有构造函数用于创建主任务的子任务**'
- en: '***7* Override the abstract method of RecursiveTask**'
  id: totrans-1249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 覆盖 RecursiveTask 的抽象方法**'
- en: '***8* The size of the subarray summed by this task**'
  id: totrans-1250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 此任务求和的子数组的大小**'
- en: '***9* If the size is less than or equal to the threshold, computes the result
    sequentially**'
  id: totrans-1251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***9* 如果大小小于或等于阈值，则按顺序计算结果**'
- en: '***10* Creates a subtask to sum the first half of the array**'
  id: totrans-1252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***10* 创建一个子任务来求和数组的前半部分**'
- en: '***11* Asynchronously executes the newly created subtask using another thread
    of ForkJoinPool**'
  id: totrans-1253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***11* 使用 ForkJoinPool 的另一个线程异步执行新创建的子任务**'
- en: '***12* Creates a subtask to sum the second half of the array**'
  id: totrans-1254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***12* 创建一个子任务来求和数组的后半部分**'
- en: '***13* Executes this second subtask synchronously, potentially allowing further
    recursive splits**'
  id: totrans-1255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***13* 同步执行此第二个子任务，可能允许进一步的递归拆分**'
- en: '***14* Reads the result of the first subtask—waiting if it isn’t ready**'
  id: totrans-1256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***14* 读取第一个子任务的结果——如果它尚未准备好则等待**'
- en: '***15* Combines the results of the two subtasks**'
  id: totrans-1257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***15* 合并两个子任务的结果**'
- en: '***16* A simple sequential algorithm for sizes below the threshold**'
  id: totrans-1258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***16* 低于阈值的简单顺序算法**'
- en: 'Writing a method performing a parallel sum of the first *n* natural numbers
    is now straightforward. You need to pass the desired array of numbers to the constructor
    of `ForkJoinSumCalculator`:'
  id: totrans-1259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在编写一个执行并行求和前 *n* 个自然数的方法的步骤非常简单。您需要将所需的数字数组传递给 `ForkJoinSumCalculator` 构造函数：
- en: '[PRE224]'
  id: totrans-1260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE224]'
- en: Here, you generate an array containing the first *n* natural numbers using a
    `Long-Stream`. Then you create a `ForkJoinTask` (the superclass of `RecursiveTask`),
    passing this array to the public constructor of the `ForkJoinSumCalculator` shown
    in [listing 7.2](#ch07ex02). Finally, you create a new `ForkJoinPool` and pass
    that task to its `invoke` method. The value returned by this last method is the
    result of the task defined by the `ForkJoin-SumCalculator` class when executed
    inside the `ForkJoinPool`.
  id: totrans-1261
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您使用`Long-Stream`生成一个包含前*n*个自然数的数组。然后，您创建一个`ForkJoinTask`（`RecursiveTask`的父类），将此数组传递给[列表7.2](#ch07ex02)中所示的`ForkJoinSumCalculator`的公共构造函数。最后，您创建一个新的`ForkJoinPool`并将该任务传递给其`invoke`方法。此最后方法的返回值是`ForkJoin-SumCalculator`类在`ForkJoinPool`内部执行时定义的任务的结果。
- en: Note that in a real-world application, it doesn’t make sense to use more than
    one `ForkJoinPool`. For this reason, what you typically should do is instantiate
    it only once and keep this instance in a static field, making it a singleton,
    so it could be conveniently reused by any part of your software. Here, to create
    it you’re using its default no-argument constructor, meaning that you want to
    allow the pool to use all the processors available to the JVM. More precisely,
    this constructor will use the value returned by `Runtime.availableProcessors`
    to determine the number of threads used by the pool. Note that the `availableProcessors`
    method, despite its name, in reality returns the number of available cores, including
    any virtual ones due to hyperthreading.
  id: totrans-1262
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在实际应用中，使用多个`ForkJoinPool`是没有意义的。因此，您通常应该只实例化一次，并将此实例保留在静态字段中，使其成为单例，这样它就可以方便地被软件的任何部分重用。在这里，为了创建它，您正在使用它的默认无参数构造函数，这意味着您希望池使用JVM可用的所有处理器。更确切地说，此构造函数将使用`Runtime.availableProcessors`返回的值来确定池使用的线程数。请注意，尽管`availableProcessors`方法的名字如此，但实际上它返回的是可用的核心数，包括由于超线程而产生的任何虚拟核心。
- en: Running the ForkJoinSumCalculator
  id: totrans-1263
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 运行ForkJoinSumCalculator
- en: When you pass the `ForkJoinSumCalculator` task to the `ForkJoinPool`, this task
    is executed by a thread of the pool that in turn calls the `compute` method of
    the task. This method checks to see if the task is small enough to be performed
    sequentially; otherwise, it splits the array of numbers to be summed into two
    halves and assigns them to two new `ForkJoinSumCalculator`s that are scheduled
    to be executed by the `Fork-JoinPool`. As a result, this process can be recursively
    repeated, allowing the original task to be divided into smaller tasks, until the
    condition used to check if it’s no longer convenient or no longer possible to
    further split it is met (in this case, if the number of items to be summed is
    less than or equal to 10,000). At this point, the result of each subtask is computed
    sequentially, and the (implicit) binary tree of tasks created by the forking process
    is traversed back toward its root. The result of the task is then computed, combining
    the partial results of each subtask. This process is shown in [figure 7.4](#ch07fig04).
  id: totrans-1264
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将`ForkJoinSumCalculator`任务传递给`ForkJoinPool`时，此任务由池中的一个线程执行，该线程随后调用任务的`compute`方法。此方法检查任务是否足够小，可以顺序执行；否则，它将待求和的数字数组分成两半，并将它们分配给两个新的`ForkJoinSumCalculator`，这些新任务被安排由`Fork-JoinPool`执行。因此，此过程可以递归重复，直到满足不再方便或不再可能进一步拆分的条件（在这种情况下，如果待求和的项目数小于或等于10,000）。在此点，每个子任务的结果顺序计算，并通过分支过程创建的任务的二叉树回溯到其根。然后计算任务的结果，结合每个子任务的局部结果。此过程在[图7.4](#ch07fig04)中显示。
- en: Figure 7.4\. The fork/join algorithm
  id: totrans-1265
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.4\. 分支/合并算法
- en: '![](Images/07fig04_alt.jpg)'
  id: totrans-1266
  prefs: []
  type: TYPE_IMG
  zh: '![图片](Images/07fig04_alt.jpg)'
- en: 'Once again you can check the performance of the summing method explicitly using
    the fork/join framework with the harness developed at the beginning of this chapter:'
  id: totrans-1267
  prefs: []
  type: TYPE_NORMAL
  zh: 再次使用本章开头开发的 harness，您可以使用分支/合并框架显式检查求和方法的性能：
- en: '[PRE225]'
  id: totrans-1268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE225]'
- en: 'In this case it produces the following output:'
  id: totrans-1269
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，它产生以下输出：
- en: '[PRE226]'
  id: totrans-1270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE226]'
- en: Here, the performance is worse than the version using the parallel stream, but
    only because you’re obliged to put the whole stream of numbers into a `long[]`
    before being allowed to use it in the `ForkJoinSumCalculator` task.
  id: totrans-1271
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，性能不如使用并行流的版本，但这仅仅是因为您被迫在允许使用`ForkJoinSumCalculator`任务之前，将整个数字流放入一个`long[]`数组中。
- en: 7.2.2\. Best practices for using the fork/join framework
  id: totrans-1272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.2\. 使用分支/合并框架的最佳实践
- en: 'Even though the fork/join framework is relatively easy to use, unfortunately
    it’s also easy to misuse. Here are a few best practices to use it effectively:'
  id: totrans-1273
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管fork/join框架相对容易使用，但不幸的是，它也很容易误用。以下是一些有效使用它的最佳实践：
- en: Invoking the `join` method on a task blocks the caller until the result produced
    by that task is ready. For this reason, it’s necessary to call it after the computation
    of both subtasks has been started. Otherwise, you’ll end up with a slower and
    more complex version of your original sequential algorithm because every subtask
    will have to wait for the other one to complete before starting.
  id: totrans-1274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任务上调用`join`方法会阻塞调用者，直到该任务产生的结果准备好。因此，必须在启动两个子任务的计算之后调用它。否则，你最终会得到一个比原始顺序算法更慢、更复杂的版本，因为每个子任务都必须等待另一个子任务完成才能开始。
- en: The `invoke` method of a `ForkJoinPool` shouldn’t be used from within a `RecursiveTask`.
    Instead, you should always call the methods `compute` or `fork` directly; only
    sequential code should use `invoke` to begin parallel computation.
  id: totrans-1275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ForkJoinPool`的`invoke`方法不应该在`RecursiveTask`内部使用。相反，你应该始终直接调用`compute`或`fork`方法；只有顺序代码应该使用`invoke`来开始并行计算。'
- en: Calling the `fork` method on a subtask is the way to schedule it on the `Fork-JoinPool`.
    It might seem natural to invoke it on both the left and right subtasks, but this
    is less efficient than directly calling `compute` on one of them. Doing this allows
    you to reuse the same thread for one of the two subtasks and avoid the overhead
    caused by the unnecessary allocation of a further task on the pool.
  id: totrans-1276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在子任务上调用`fork`方法是将其调度到`Fork-JoinPool`上的方式。虽然对左右子任务都调用它看起来很自然，但这样做不如直接在其中一个上调用`compute`更有效率。这样做允许你为两个子任务中的任何一个重用相同的线程，并避免由于在池中不必要的进一步任务分配而产生的开销。
- en: Debugging a parallel computation using the fork/join framework can be tricky.
    In particular, it’s ordinarily quite common to browse a stack trace in your favorite
    IDE to discover the cause of a problem, but this can’t work with a fork/join computation
    because the call to `compute` occurs in a different thread than the conceptual
    caller, which is the code that called `fork`.
  id: totrans-1277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用fork/join框架调试并行计算可能很棘手。特别是，通常在最喜欢的IDE中浏览堆栈跟踪以发现问题的原因是非常常见的，但这种方法不适用于fork/join计算，因为`compute`的调用发生在与概念调用者不同的线程中，而概念调用者是调用`fork`的代码。
- en: As you’ve discovered with parallel streams, you should never take for granted
    that a computation using the fork/join framework on a multicore processor is faster
    than the sequential counterpart. We already said that a task should be decomposable
    into several independent subtasks in order to be parallelizable with a relevant
    performance gain. All of these subtasks should take longer to execute than forking
    a new task; one idiom is to put I/O into one subtask and computation into another,
    thereby overlapping computation with I/O. Moreover, you should consider other
    things when comparing the performance of the sequential and parallel versions
    of the same algorithm. Like any other Java code, the fork/join framework needs
    to be “warmed up,” or executed, a few times before being optimized by the JIT
    compiler. This is why it’s always important to run the program multiple times
    before to measure its performance, as we did in our harness. Also be aware that
    optimizations built into the compiler could unfairly give an advantage to the
    sequential version (for example, by performing dead code analysis—removing a computation
    that’s never used).
  id: totrans-1278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如你在并行流中发现的那样，你不应该理所当然地认为在多核处理器上使用fork/join框架进行的计算比顺序版本更快。我们之前已经说过，一个任务应该可以分解为几个独立的子任务，以便能够并行化并取得相关的性能提升。所有这些子任务应该比创建新任务的执行时间更长；一个常见的做法是将I/O放入一个子任务，将计算放入另一个子任务，从而重叠计算与I/O。此外，在比较相同算法的顺序和并行版本的性能时，你应该考虑其他因素。像任何其他Java代码一样，fork/join框架需要被“预热”，或者执行几次，然后才能被JIT编译器优化。这就是为什么在测量性能之前，总是重要地多次运行程序，就像我们在我们的工具中做的那样。此外，编译器内建优化可能会不公平地给顺序版本带来优势（例如，通过执行死代码分析——移除从未使用的计算）。
- en: 'The fork/join splitting strategy deserves one last note: you must choose the
    criteria used to decide if a given subtask should be further split or is small
    enough to be evaluated sequentially. We’ll give some hints about this in the next
    section.'
  id: totrans-1279
  prefs: []
  type: TYPE_NORMAL
  zh: fork/join拆分策略值得再提一句：你必须选择用于决定给定子任务是否应该进一步拆分或足够小以至于可以顺序评估的准则。我们将在下一节中给出一些关于这个问题的提示。
- en: 7.2.3\. Work stealing
  id: totrans-1280
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.3. 工作窃取
- en: In our `ForkJoinSumCalculator` example we decided to stop creating more subtasks
    when the array of numbers to be summed contained at most 10,000 items. This is
    an arbitrary choice, but in most cases it’s difficult to find a good heuristic,
    other than trying to optimize it by making several attempts with different inputs.
    In our test case, we started with an array of 10 million items, meaning that the
    `ForkJoinSumCalculator` will fork at least 1,000 subtasks. This might seem like
    a waste of resources because we ran it on a machine that has only four cores.
    In this specific case, that’s probably true because all tasks are CPU bound and
    are expected to take a similar amount of time.
  id: totrans-1281
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`ForkJoinSumCalculator`示例中，我们决定当要加和的数字数组最多包含10,000项时停止创建更多子任务。这是一个任意的选择，但在大多数情况下，除了尝试通过使用不同的输入进行多次尝试来优化它之外，很难找到一个好的启发式方法。在我们的测试案例中，我们从一个包含1000万个项目的数组开始，这意味着`ForkJoinSumCalculator`至少会分叉1000个子任务。这看起来可能像是一种资源浪费，因为我们是在一个只有四个核心的机器上运行的。在这种情况下，这可能确实是正确的，因为所有任务都是CPU密集型的，并且预计会花费相似的时间。
- en: But forking a quite large number of fine-grained tasks is in general a winning
    choice. This is because ideally you want to partition the workload of a parallelized
    task in such a way that each subtask takes exactly the same amount of time, keeping
    all the cores of your CPU equally busy. Unfortunately, especially in cases closer
    to real-world scenarios than the straightforward example we presented here, the
    time taken by each subtask can dramatically vary either due to the use of an inefficient
    partition strategy or because of unpredictable causes like slow access to the
    disk or the need to coordinate the execution with external services.
  id: totrans-1282
  prefs: []
  type: TYPE_NORMAL
  zh: 但将大量细粒度任务进行分叉通常是一个明智的选择。这是因为理想情况下，你希望将并行化任务的工作量分割成这样的方式，即每个子任务花费的时间完全相同，保持CPU的所有核心都处于同等忙碌状态。不幸的是，特别是在比我们这里展示的简单示例更接近现实场景的情况下，每个子任务所需的时间可能会因使用低效的分割策略或由于不可预测的原因（如缓慢的磁盘访问或需要与外部服务协调执行）而大幅变化。
- en: The fork/join framework works around this problem with a technique called *work
    stealing*. In practice, this means that the tasks are more or less evenly divided
    on all the threads in the `ForkJoinPool`. Each of these threads holds a doubly
    linked queue of the tasks assigned to it, and as soon as it completes a task it
    pulls another one from the head of the queue and starts executing it. For the
    reasons we listed previously, one thread might complete all the tasks assigned
    to it much faster than the others, which means its queue will become empty while
    the other threads are still pretty busy. In this case, instead of becoming idle,
    the thread randomly chooses a queue of a different thread and “steals” a task,
    taking it from the tail of the queue. This process continues until all the tasks
    are executed, and then all the queues become empty. That’s why having many smaller
    tasks, instead of only a few bigger ones, can help in better balancing the workload
    among the worker threads.
  id: totrans-1283
  prefs: []
  type: TYPE_NORMAL
  zh: Fork/join框架通过一种称为*窃取工作*的技术来解决这个问题。在实践中，这意味着任务在大约`ForkJoinPool`中的所有线程上大致均匀分配。每个线程都持有分配给它的任务的双链队列，并且一旦它完成一个任务，它就会从队列的头部拉取另一个任务并开始执行。由于我们之前列出的原因，一个线程可能比其他线程更快地完成分配给它的所有任务，这意味着它的队列会变得空，而其他线程仍然相当忙碌。在这种情况下，线程不会空闲，而是随机选择另一个线程的队列，并从队列的尾部“窃取”一个任务。这个过程会一直持续到所有任务都执行完毕，然后所有队列都变为空。这就是为什么拥有许多较小的任务，而不是只有少数较大的任务，有助于更好地在工作线程之间平衡工作负载。
- en: More generally, this work-stealing algorithm is used to redistribute and balance
    the tasks among the worker threads in the pool. [Figure 7.5](#ch07fig05) shows
    how this process occurs. When a task in the queue of a worker is divided into
    two subtasks, one of the two subtasks is stolen by another idle worker. As described
    previously, this process can continue recursively until the condition used to
    define that a given subtask should be executed sequentially becomes true.
  id: totrans-1284
  prefs: []
  type: TYPE_NORMAL
  zh: 更普遍地，这种窃取工作算法用于在池中的工作线程之间重新分配和平衡任务。![图7.5](Images/07fig05_alt.jpg)展示了这个过程是如何发生的。当一个工作线程队列中的任务被分割成两个子任务时，其中一个子任务被另一个空闲的工作线程“窃取”。如前所述，这个过程可以递归地继续进行，直到用于定义给定子任务应该顺序执行的条件变为真。
- en: Figure 7.5\. The work-stealing algorithm used by the fork/join framework
  id: totrans-1285
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.5\. Fork/join框架使用的窃取工作算法
- en: '![](Images/07fig05_alt.jpg)'
  id: totrans-1286
  prefs: []
  type: TYPE_IMG
  zh: '![图7.5](Images/07fig05_alt.jpg)'
- en: It should now be clear how a stream can use the fork/join framework to process
    its items in parallel, but there’s still one missing ingredient. In this section,
    we analyzed an example where you explicitly developed the logic to split an array
    of numbers into multiple tasks. Nevertheless, you didn’t have to do anything similar
    when you used the parallel streams at the beginning of this chapter, and this
    means that there must be an automatic mechanism splitting the stream for you.
    This new automatic mechanism is called the `Spliterator`, and we’ll explore it
    in the next section.
  id: totrans-1287
  prefs: []
  type: TYPE_NORMAL
  zh: 现在应该已经很清楚，一个流如何使用fork/join框架并行处理其项目了，但仍然缺少一个关键因素。在本节中，我们分析了一个例子，其中你明确开发了将数字数组拆分为多个任务的逻辑。然而，当你在本章开头使用并行流时，你并没有做类似的事情，这意味着必须有一个自动机制为你拆分流。这个新的自动机制被称为`Spliterator`，我们将在下一节中探讨它。
- en: 7.3\. Spliterator
  id: totrans-1288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3. `Spliterator`
- en: The `Spliterator` is another new interface added to Java 8; its name stands
    for “splitable iterator.” Like `Iterator`s, `Spliterator`s are used to traverse
    the elements of a source, but they’re also designed to do this in parallel. Although
    you may not have to develop your own `Spliterator` in practice, understanding
    how to do so will give you a wider understanding about how parallel streams work.
    Java 8 already provides a default `Spliterator` implementation for all the data
    structures included in its Collections Framework. The `Collection` interface now
    provides a default method `spliterator()` (you will learn more about default methods
    in [chapter 13](kindle_split_026.xhtml#ch13)) which returns a `Spliterator` object.
    The `Spliterator` interface defines several methods, as shown in the following
    listing.
  id: totrans-1289
  prefs: []
  type: TYPE_NORMAL
  zh: '`Spliterator` 是Java 8中添加的另一个新接口；其名称代表“可拆分迭代器”。与`Iterator`类似，`Spliterator`用于遍历源中的元素，但它们也被设计为并行执行。虽然你可能不需要在实际中开发自己的`Spliterator`，但了解如何做到这一点将使你对并行流的工作原理有更深入的理解。Java
    8已经为它包含在其Collections Framework中的所有数据结构提供了一个默认的`Spliterator`实现。`Collection`接口现在提供了一个默认方法`spliterator()`（你将在第13章中了解更多关于默认方法的内容），该方法返回一个`Spliterator`对象。`Spliterator`接口定义了几个方法，如下面的列表所示。'
- en: Listing 7.3\. The `Spliterator` interface
  id: totrans-1290
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.3. `Spliterator` 接口
- en: '[PRE227]'
  id: totrans-1291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE227]'
- en: As usual, `T` is the type of the elements traversed by the `Spliterator`. The
    `tryAdvance` method behaves in a way similar to a normal `Iterator` in the sense
    that it’s used to sequentially consume the elements of the `Spliterator` one by
    one, returning `true` if there are still other elements to be traversed. But the
    `trySplit` method is more specific to the `Spliterator` interface because it’s
    used to partition off some of its elements to a second `Spliterator` (the one
    returned by the method), allowing the two to be processed in parallel. A `Spliterator`
    may also provide an estimation of the number of the elements remaining to be traversed
    via its `estimateSize` method, because even an inaccurate but quick-to-compute
    value can be useful to split the structure more or less evenly.
  id: totrans-1292
  prefs: []
  type: TYPE_NORMAL
  zh: 如同往常，`T`是`Spliterator`遍历的元素类型。`tryAdvance`方法的行为与正常`Iterator`类似，因为它用于顺序地逐个消费`Spliterator`的元素，如果有其他元素要遍历，则返回`true`。但`trySplit`方法更具体于`Spliterator`接口，因为它用于将一些元素拆分到一个第二个`Spliterator`（由该方法返回的）中，允许这两个并行处理。`Spliterator`还可以通过其`estimateSize`方法提供一个估计值，表示剩余要遍历的元素数量，因为即使是一个不准确但计算快速的值也可以用于更均匀地拆分结构。
- en: It’s important to understand how this splitting process is performed internally
    in order to take control of it when required. Therefore, we’ll analyze it in more
    detail in the next section.
  id: totrans-1293
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在需要时控制这个过程，理解这个拆分过程是如何在内部执行的非常重要。因此，我们将在下一节中更详细地分析它。
- en: 7.3.1\. The splitting process
  id: totrans-1294
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.3.1. 拆分过程
- en: The algorithm that splits a stream into multiple parts is a recursive process
    and proceeds as shown in [figure 7.6](#ch07fig06). In the first step, `trySplit`
    is invoked on the first `Spliterator` and generates a second one. Then in step
    two, it’s called again on these two `Spliterator`s, which results in a total of
    four. The framework keeps invoking the method `trySplit` on a `Spliterator` until
    it returns `null` to signal that the data structure that it’s processing is no
    longer divisible, as shown in step 3\. Finally, this recursive splitting process
    terminates in step 4 when all `Spliterator`s have returned `null` to a `trySplit`
    invocation.
  id: totrans-1295
  prefs: []
  type: TYPE_NORMAL
  zh: 将流分割成多个部分的算法是一个递归过程，其步骤如下所示[图7.6](#ch07fig06)。在第一步中，对第一个`Spliterator`调用`trySplit`生成第二个`Spliterator`。然后在第二步中，它再次被调用在这两个`Spliterator`上，总共生成四个。框架会持续在`Spliterator`上调用`trySplit`方法，直到它返回`null`以表示正在处理的数据结构不再可分割，如图3所示。最后，当所有`Spliterator`都向`trySplit`调用返回`null`时，递归分割过程在步骤4中终止。
- en: Figure 7.6\. The recursive splitting process
  id: totrans-1296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.6\. 递归分割过程
- en: '![](Images/07fig06_alt.jpg)'
  id: totrans-1297
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/07fig06_alt.jpg)'
- en: This splitting process can also be influenced by the characteristics of the
    `Spliterator` itself, which are declared via the `characteristics` method.
  id: totrans-1298
  prefs: []
  type: TYPE_NORMAL
  zh: 这个分割过程也可以受到`Spliterator`本身的特性的影响，这些特性通过`characteristics`方法声明。
- en: The Spliterator characteristics
  id: totrans-1299
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '`Spliterator`的特性'
- en: The last abstract method declared by the `Spliterator` interface is `characteristics`,
    which returns an `int` encoding the set of characteristics of the `Spliterator`
    itself. The `Spliterator` clients can use these characteristics to better control
    and optimize its usage. [Table 7.2](#ch07table02) summarizes them. (Unfortunately,
    although these conceptually overlap with characteristics of a collector, they’re
    coded differently.) The characteristics are int constants defined in the `Spliterator`
    interface.
  id: totrans-1300
  prefs: []
  type: TYPE_NORMAL
  zh: '`Spliterator`接口声明的最后一个抽象方法是`characteristics`，它返回一个`int`编码，表示`Spliterator`本身的特性集。`Spliterator`客户端可以使用这些特性来更好地控制和优化其使用。[表7.2](#ch07table02)总结了它们。（不幸的是，尽管这些在概念上与收集器的特性重叠，但它们的编码方式不同。）特性是在`Spliterator`接口中定义的int常量。'
- en: Table 7.2\. `Spliterator`’s characteristics
  id: totrans-1301
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表7.2\. `Spliterator`的特性
- en: '| Characteristic | Meaning |'
  id: totrans-1302
  prefs: []
  type: TYPE_TB
  zh: '| 特性 | 含义 |'
- en: '| --- | --- |'
  id: totrans-1303
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| ORDERED | Elements have a defined order (for example, a List), so the Spliterator
    enforces this order when traversing and partitioning them. |'
  id: totrans-1304
  prefs: []
  type: TYPE_TB
  zh: '| 有序 | 元素有一个定义的顺序（例如，一个List），因此`Spliterator`在遍历和分割它们时强制执行这个顺序。 |'
- en: '| DISTINCT | For each pair of traversed elements x and y, x.equals(y) returns
    false. |'
  id: totrans-1305
  prefs: []
  type: TYPE_TB
  zh: '| 唯一 | 对于每个遍历的元素对x和y，x.equals(y)返回false。 |'
- en: '| SORTED | The traversed elements follow a predefined sort order. |'
  id: totrans-1306
  prefs: []
  type: TYPE_TB
  zh: '| 排序 | 遍历的元素遵循预定义的排序顺序。 |'
- en: '| SIZED | This Spliterator has been created from a source with a known size
    (for example, a Set), so the value returned by estimatedSize() is precise. |'
  id: totrans-1307
  prefs: []
  type: TYPE_TB
  zh: '| 有大小 | 这个`Spliterator`是从一个已知大小（例如，一个Set）的来源创建的，因此`estimatedSize()`返回的值是精确的。
    |'
- en: '| NON-NULL | It’s guaranteed that the traversed elements won’t be null. |'
  id: totrans-1308
  prefs: []
  type: TYPE_TB
  zh: '| 非空 | 保证遍历的元素不会为空。 |'
- en: '| IMMUTABLE | The source of this Spliterator can’t be modified. This implies
    that no elements can be added, removed, or modified during their traversal. |'
  id: totrans-1309
  prefs: []
  type: TYPE_TB
  zh: '| 不可变 | 这个`Spliterator`的来源不能被修改。这意味着在遍历期间不能添加、删除或修改任何元素。 |'
- en: '| CONCURRENT | The source of this Spliterator may be safely, concurrently modified
    by other threads without any synchronization. |'
  id: totrans-1310
  prefs: []
  type: TYPE_TB
  zh: '| 并发 | 这个`Spliterator`的来源可以安全地由其他线程并发修改，无需任何同步。 |'
- en: '| SUBSIZED | Both this Spliterator and all further Spliterators resulting from
    its split are SIZED. |'
  id: totrans-1311
  prefs: []
  type: TYPE_TB
  zh: '| 子大小 | 这个`Spliterator`及其从其分割产生的所有后续`Spliterator`都是SIZED。 |'
- en: Now that you’ve seen what the `Spliterator` interface is and which methods it
    defines, you can try to develop your own implementation of a `Spliterator`.
  id: totrans-1312
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了`Spliterator`接口是什么以及它定义了哪些方法，你可以尝试开发自己的`Spliterator`实现。
- en: 7.3.2\. Implementing your own Spliterator
  id: totrans-1313
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.3.2\. 实现自己的`Spliterator`
- en: Let’s look at a practical example of where you might need to implement your
    own `Spliterator`. We’ll develop a simple method that counts the number of words
    in a `String`. An iterative version of this method could be written as shown in
    the following listing.
  id: totrans-1314
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看你可能需要实现自己的`Spliterator`的实际情况。我们将开发一个简单的方法来计算`String`中的单词数量。这个方法的迭代版本可以写成如下所示。
- en: Listing 7.4\. An iterative word counter method
  id: totrans-1315
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.4\. 迭代单词计数方法
- en: '[PRE228]'
  id: totrans-1316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE228]'
- en: '***1* Traverses all the characters in the String one by one**'
  id: totrans-1317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 逐个遍历String中的所有字符**'
- en: '***2* Increases the word counter when the last character is a space and the
    currently traversed one isn’t**'
  id: totrans-1318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 当最后一个字符是空格而当前遍历的不是时，增加单词计数器**'
- en: 'Let’s put this method to work on the first sentence of Dante’s *Inferno* (see
    [http://en.wikipedia.org/wiki/Inferno_(Dante)](http://en.wikipedia.org/wiki/Inferno_(Dante)).):'
  id: totrans-1319
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用这种方法处理但丁的《地狱》第一句（见[http://en.wikipedia.org/wiki/Inferno_(Dante)](http://en.wikipedia.org/wiki/Inferno_(Dante))）：
- en: '[PRE229]'
  id: totrans-1320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE229]'
- en: 'Note that we added some additional random spaces in the sentence to demonstrate
    that the iterative implementation is working correctly even in the presence of
    multiple spaces between two words. As expected, this code prints out the following:'
  id: totrans-1321
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们在句子中添加了一些额外的随机空格，以证明迭代实现即使在两个单词之间有多个空格的情况下也能正确工作。正如预期的那样，此代码将打印出以下内容：
- en: '[PRE230]'
  id: totrans-1322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE230]'
- en: Ideally you’d like to achieve the same result in a more functional style because
    this way you’ll be able, as shown previously, to parallelize this process using
    a parallel stream without having to explicitly deal with threads and their synchronization.
  id: totrans-1323
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，你希望以更函数式的风格达到相同的结果，因为这样你将能够，如前所述，使用并行流并行化此过程，而无需显式处理线程及其同步。
- en: Rewriting the WordCounter in functional style
  id: totrans-1324
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 以函数式风格重写WordCounter
- en: 'First, you need to convert the `String` into a stream. Unfortunately, there
    are primitive streams only for `int`, `long`, and `double,` so you’ll have to
    use a `Stream<Character>`:'
  id: totrans-1325
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要将`String`转换为流。不幸的是，只有`int`、`long`和`double`有原始流，所以你必须使用`Stream<Character>`：
- en: '[PRE231]'
  id: totrans-1326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE231]'
- en: 'You can calculate the number of words by performing a reduction on this stream.
    While reducing the stream, you’ll have to carry a state consisting of two variables:
    an `int` counting the number of words found so far and a `boolean` to remember
    if the last-encountered `Character` was a space or not. Because Java doesn’t have
    tuples (a construct to represent an ordered list of heterogeneous elements without
    the need of a wrapper object), you’ll have to create a new class, `WordCounter`,
    which will encapsulate this state as shown in the following listing.'
  id: totrans-1327
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过对这个流执行归约来计算单词数。在归约流时，你必须携带一个由两个变量组成的状态：一个`int`变量用于计算到目前为止找到的单词数，一个`boolean`变量用于记住最后一个遇到的`Character`是否是空格。因为Java没有元组（一个表示无包装对象的异构元素有序列表的构造），你必须创建一个新的类`WordCounter`，它将如以下列表所示封装这个状态。
- en: Listing 7.5\. A class to count words while traversing a stream of `Characters`
  id: totrans-1328
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.5\. 一个在遍历`Characters`流时计算单词的类
- en: '[PRE232]'
  id: totrans-1329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE232]'
- en: '***1* Accumulate method traverses Characters one by one as done by the iterative
    algorithm**'
  id: totrans-1330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 累积方法逐个遍历字符，就像迭代算法所做的那样**'
- en: '***2* Increases the word counter when the last character is a space and the
    currently traversed one isn’t**'
  id: totrans-1331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 当最后一个字符是空格而当前遍历的不是时，增加单词计数器**'
- en: '***3* Combines two WordCounters by summing their counters**'
  id: totrans-1332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 通过求和计数器合并两个WordCounter**'
- en: '***4* Uses only the sum of the counters so you don’t care about lastSpace**'
  id: totrans-1333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 只使用计数器的总和，因此你不必关心lastSpace**'
- en: In this listing, the `accumulate` method defines how to change the state of
    the `WordCounter`, or, more precisely, with which state to create a new `WordCounter`
    because it’s an immutable class. This is important to understand. We are accumulating
    state with an immutable class specifically so that the process can be parallelized
    in the next step. The method `accumulate` is called whenever a new `Character`
    of the stream is traversed. In particular, as you did in the `countWordsIteratively`
    method in [listing 7.4](#ch07ex04), the counter is incremented when a new nonspace
    is met, and the last character encountered is a space. [Figure 7.7](#ch07fig07)
    shows the state transitions of the `WordCounter` when a new `Character` is traversed
    by the `accumulate` method.
  id: totrans-1334
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个列表中，`accumulate`方法定义了如何改变`WordCounter`的状态，或者更确切地说，用哪个状态创建一个新的`WordCounter`，因为这是一个不可变类。这一点很重要。我们使用不可变类累积状态，以便在下一步中可以并行化这个过程。每当流中遍历一个新的`Character`时，都会调用`accumulate`方法。特别是，正如你在[列表7.4](#ch07ex04)中的`countWordsIteratively`方法中所做的那样，当遇到一个新的非空格字符时，计数器会增加，并且遇到的最后一个字符是空格。[图7.7](#ch07fig07)显示了`accumulate`方法遍历新`Character`时`WordCounter`的状态转换。
- en: Figure 7.7\. The state transitions of the `WordCounter` when a new `Character
    c` is traversed
  id: totrans-1335
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.7\. 当遍历新的`Character c`时`WordCounter`的状态转换
- en: '![](Images/07fig07_alt.jpg)'
  id: totrans-1336
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/07fig07_alt.jpg)'
- en: The second method, `combine`, is invoked to aggregate the partial results of
    two `WordCounter`s operating on two different subparts of the stream of `Character`s,
    so it combines two `WordCounter`s by summing their internal counters.
  id: totrans-1337
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法，`combine`，被调用来聚合两个`WordCounter`的局部结果，这两个`WordCounter`分别作用于`Character`流的不同子部分，因此它通过求和它们的内部计数器来合并两个`WordCounter`。
- en: 'Now that you’ve encoded the logic of how to accumulate characters on a `WordCounter`
    and how to combine them in the `WordCounter` itself, writing a method that will
    reduce the stream of `Character`s is straightforward:'
  id: totrans-1338
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经编码了如何在`WordCounter`上累积字符以及如何在`WordCounter`本身中组合它们，编写一个将`Character`流减少的方法就很简单了：
- en: '[PRE233]'
  id: totrans-1339
  prefs: []
  type: TYPE_PRE
  zh: '[PRE233]'
- en: 'Now you can try this method with the stream created from the `String` containing
    the first sentence of Dante’s *Inferno*:'
  id: totrans-1340
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以尝试使用包含但丁的《地狱》第一句的`String`创建的流来尝试这个方法：
- en: '[PRE234]'
  id: totrans-1341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE234]'
- en: 'You can check that its output corresponds with the one generated by the iterative
    version:'
  id: totrans-1342
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以检查其输出是否与迭代版本生成的输出一致：
- en: '[PRE235]'
  id: totrans-1343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE235]'
- en: So far, so good, but we said that one of the main reasons for implementing the
    `WordCounter` in functional terms was to be able to easily parallelize this operation,
    so let’s see how this works.
  id: totrans-1344
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切顺利，但我们说过，在函数式术语中实现`WordCounter`的主要理由之一是能够轻松并行化此操作，那么让我们看看这是如何工作的。
- en: Making the WordCounter work in parallel
  id: totrans-1345
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使`WordCounter`并行工作
- en: 'You could try to speed up the word-counting operation using a parallel stream,
    as follows:'
  id: totrans-1346
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试使用并行流来加速单词计数操作，如下所示：
- en: '[PRE236]'
  id: totrans-1347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE236]'
- en: Unfortunately, this time the output is
  id: totrans-1348
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这次输出是
- en: '[PRE237]'
  id: totrans-1349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE237]'
- en: Evidently something has gone wrong, but what? The problem isn’t hard to discover.
    Because the original `String` is split at arbitrary positions, sometimes a word
    is divided in two and then counted twice. In general, this demonstrates that going
    from a sequential stream to a parallel one can lead to a wrong result if this
    result may be affected by the position where the stream is split.
  id: totrans-1350
  prefs: []
  type: TYPE_NORMAL
  zh: 显然出了些问题，但问题是什么？问题并不难发现。因为原始字符串是在任意位置分割的，有时一个单词被分成两部分，然后被计数两次。总的来说，这表明如果结果可能受到流分割位置的影响，那么从顺序流到并行流可能会导致错误的结果。
- en: How can you fix this issue? The solution consists of ensuring that the `String`
    isn’t split at a random position but only at the end of a word. To do this, you’ll
    have to implement a `Spliterator` of `Character` that splits a `String` only between
    two words (as shown in the following listing) and then creates the parallel stream
    from it.
  id: totrans-1351
  prefs: []
  type: TYPE_NORMAL
  zh: 如何解决这个问题？解决方案包括确保字符串不是在随机位置分割，而是在单词的末尾分割。为此，你必须实现一个`Spliterator`，它只将字符串分割在两个单词之间（如下所示），然后从它创建并行流。
- en: Listing 7.6\. The `WordCounterSpliterator`
  id: totrans-1352
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.6\. `WordCounterSpliterator`
- en: '[PRE238]'
  id: totrans-1353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE238]'
- en: '***1* Consumes the current character**'
  id: totrans-1354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***1* 消费当前字符**'
- en: '***2* Returns true if there are further characters to be consumed**'
  id: totrans-1355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***2* 如果还有更多字符要消费，则返回true**'
- en: '***3* Returns null to signal that the String to be parsed is small enough to
    be processed sequentially**'
  id: totrans-1356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***3* 返回null以表示要解析的字符串足够小，可以顺序处理**'
- en: '***4* Sets the candidate split position to be half of the String to be parsed**'
  id: totrans-1357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***4* 将候选分割位置设置为要解析的字符串的一半**'
- en: '***5* Advances the split position until the next space**'
  id: totrans-1358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***5* 将分割位置推进到下一个空格**'
- en: '***6* Creates a new WordCounter-Spliterator parsing the String from the start
    to the split position**'
  id: totrans-1359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***6* 从起始位置到分割位置创建一个新的`WordCounter-Spliterator`来解析字符串**'
- en: '***7* Sets the start position of the current Word-CounterSpliterator to the
    split position**'
  id: totrans-1360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***7* 将当前`Word-CounterSpliterator`的起始位置设置为分割位置**'
- en: '***8* Found a space and created the new Spliterator, so exit the loop**'
  id: totrans-1361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '***8* 找到一个空格并创建了新的Spliterator，因此退出循环**'
- en: 'This `Spliterator` is created from the `String` to be parsed and iterates over
    its `Character`s by holding the index of the one currently being traversed. Let’s
    quickly revisit the methods of the `WordCounterSpliterator` implementing the `Spliterator`
    interface:'
  id: totrans-1362
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`Spliterator`是从要解析的`String`创建的，并通过保持正在遍历的索引来迭代其`Character`s。让我们快速回顾一下实现`Spliterator`接口的`WordCounterSpliterator`的方法：
- en: The `tryAdvance` method feeds the `Consumer` with the `Character` in the `String`
    at the current index position and increments this position. The `Consumer` passed
    as its argument is an internal Java class forwarding the consumed `Character`
    to the set of functions that have to be applied to it while traversing the stream,
    which in this case is only a reducing function, namely, the `accumulate` method
    of the `WordCounter` class. The `tryAdvance` method returns `true` if the new
    cursor position is less than the total `String` length and there are further `Character`s
    to be iterated.
  id: totrans-1363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tryAdvance` 方法将当前索引位置的 `Character` 从 `String` 中传递给 `Consumer`，并增加这个位置。作为其参数传递的
    `Consumer` 是一个内部 Java 类，它将消耗的 `Character` 转发到在遍历流时必须应用于它的函数集，在这种情况下，只有一个减少函数，即
    `WordCounter` 类的 `accumulate` 方法。如果新的光标位置小于总 `String` 长度并且还有要迭代的 `Character`，则
    `tryAdvance` 方法返回 `true`。'
- en: The `trySplit` method is the most important one in a `Spliterator`, because
    it’s the one defining the logic used to split the data structure to be iterated.
    As you did in the `compute` method of the `RecursiveTask` implemented in [listing
    7.1](#ch07ex01), the first thing you have to do here is set a limit under which
    you don’t want to perform further splits. Here, you use a low limit of 10 `Character`s
    only to make sure that your program will perform some splits with the relatively
    short `String` you’re parsing. But in real-world applications you’ll have to use
    a higher limit, as you did in the fork/join example, to avoid creating too many
    tasks. If the number of remaining `Character`s to be traversed is under this limit,
    you return `null` to signal that no further split is necessary. Conversely, if
    you need to perform a split, you set the candidate split position to the half
    of the `String` chunk remaining to be parsed. But you don’t use this split position
    directly because you want to avoid splitting in the middle of a word, so you move
    forward until you find a blank `Character`. Once you find an opportune split position,
    you create a new `Spliterator` that will traverse the substring chunk going from
    the current position to the split one; you set the current position of `this`
    to the split one, because the part before it will be managed by the new `Spliterator`,
    and then you return it.
  id: totrans-1364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trySplit` 方法是 `Spliterator` 中最重要的一个，因为它定义了用于拆分要迭代的数组的逻辑。正如你在实现 [列表 7.1](#ch07ex01)
    的 `RecursiveTask` 的 `compute` 方法中所做的那样，你在这里首先要做的第一件事是设置一个限制，你不想在这个限制以下执行进一步的拆分。在这里，你只使用
    10 个 `Character` 的低限制，以确保你的程序会在解析相对较短的 `String` 时执行一些拆分。但在实际应用中，你将不得不使用更高的限制，就像你在
    fork/join 示例中所做的那样，以避免创建过多的任务。如果剩余要遍历的 `Character` 数量低于这个限制，你返回 `null` 以表示不需要进一步的拆分。相反，如果你需要执行拆分，你将候选拆分位置设置为剩余要解析的
    `String` 块的一半。但你不会直接使用这个拆分位置，因为你想要避免在单词中间拆分，所以你会向前移动，直到找到一个空白 `Character`。一旦找到一个合适的拆分位置，你将创建一个新的
    `Spliterator`，它将遍历从当前位置到拆分位置的子字符串块；你将 `this` 的当前位置设置为拆分位置，因为它前面的部分将由新的 `Spliterator`
    管理，然后返回它。'
- en: The `estimatedSize` of elements still to be traversed is the difference between
    the total length of the `String` parsed by this `Spliterator` and the position
    currently iterated.
  id: totrans-1365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还要遍历的元素 `estimatedSize` 是由这个 `Spliterator` 解析的 `String` 的总长度与当前迭代的当前位置之间的差值。
- en: Finally, the `characteristics` method signals to the framework that this `Spliterator`
    is `ORDERED` (the order is the sequence of `Character`s in the `String`), `SIZED`
    (the value returned by the `estimatedSize` method is exact), `SUBSIZED` (the other
    `Spliterator`s created by the `trySplit` method also have an exact size), `NON-NULL`
    (there can be no `null Character`s in the `String`), and `IMMUTABLE` (no further
    `Character`s can be added while parsing the `String` because the `String` itself
    is an immutable class).
  id: totrans-1366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，`characteristics` 方法向框架表明这个 `Spliterator` 是 `ORDERED`（顺序是 `String` 中 `Character`
    的序列），`SIZED`（`estimatedSize` 方法返回的值是精确的），`SUBSIZED`（由 `trySplit` 方法创建的其他 `Spliterator`
    也具有精确的大小），`NON-NULL`（`String` 中不能有 `null Character`），以及 `IMMUTABLE`（在解析 `String`
    时不能添加更多的 `Character`，因为 `String` 本身是一个不可变类）。
- en: Putting the WordCounterSpliterator to work
  id: totrans-1367
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 使用 WordCounterSpliterator
- en: 'You can now use a parallel stream with this new `WordCounterSpliterator` as
    follows:'
  id: totrans-1368
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以使用新的 `WordCounterSpliterator` 来并行流，如下所示：
- en: '[PRE239]'
  id: totrans-1369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE239]'
- en: The second boolean argument passed to the `StreamSupport.stream` factory method
    means that you want to create a parallel stream. Passing this parallel stream
    to the `countWords` method
  id: totrans-1370
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给 `StreamSupport.stream` 工厂方法的第二个布尔参数意味着你想要创建一个并行流。将此并行流传递给 `countWords` 方法
- en: '[PRE240]'
  id: totrans-1371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE240]'
- en: 'produces the correct output, as expected:'
  id: totrans-1372
  prefs: []
  type: TYPE_NORMAL
  zh: 产生预期的正确输出：
- en: '[PRE241]'
  id: totrans-1373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE241]'
- en: You’ve seen how a `Spliterator` can let you to gain control over the policy
    used to split a data structure. One last notable feature of `Spliterator`s is
    the possibility of binding the source of the elements to be traversed at the point
    of first traversal, first split, or first query for estimated size, rather than
    at the time of its creation. When this happens, it’s called a *late-binding* `Spliterator`.
    We’ve dedicated [appendix C](kindle_split_039.xhtml#app03) to showing how you
    can develop a utility class capable of performing multiple operations on the same
    stream in parallel using this feature.
  id: totrans-1374
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了如何使用 `Spliterator` 来控制分割数据结构所使用的策略。`Spliterator` 的最后一个显著特性是，在第一次遍历、第一次分割或第一次查询估计大小时，可以将要遍历的元素源绑定到点，而不是在创建时。当这种情况发生时，它被称为
    *延迟绑定* 的 `Spliterator`。我们已在 [附录 C](kindle_split_039.xhtml#app03) 中专门介绍如何开发一个实用类，利用此功能在同一个流上并行执行多个操作。
- en: Summary
  id: totrans-1375
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: Internal iteration allows you to process a stream in parallel without the need
    to explicitly use and coordinate different threads in your code.
  id: totrans-1376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内部迭代允许你在不显式使用和协调代码中的不同线程的情况下并行处理流。
- en: Even if processing a stream in parallel is so easy, there’s no guarantee that
    doing so will make your programs run faster under all circumstances. Behavior
    and performance of parallel software can sometimes be counterintuitive, and for
    this reason it’s always necessary to measure them and be sure that you’re not
    slowing your programs down.
  id: totrans-1377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使并行处理流如此简单，也不能保证在所有情况下这样做会使程序运行得更快。并行软件的行为和性能有时可能是反直觉的，因此始终有必要对其进行测量，并确保你没有使程序变慢。
- en: Parallel execution of an operation on a set of data, as done by a parallel stream,
    can provide a performance boost, especially when the number of elements to be
    processed is huge or the processing of each single element is particularly time
    consuming.
  id: totrans-1378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在一组数据上并行执行操作，如并行流所做的那样，可以提供性能提升，尤其是在要处理的数据元素数量巨大或每个单个元素的处理特别耗时的情况下。
- en: From a performance point of view, using the right data structure, for instance,
    employing primitive streams instead of nonspecialized ones whenever possible,
    is almost always more important than trying to parallelize some operations.
  id: totrans-1379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从性能角度来看，使用合适的数据结构，例如，尽可能使用原始流而不是非专用流，通常比尝试并行化某些操作更重要。
- en: The fork/join framework lets you recursively split a parallelizable task into
    smaller tasks, execute them on different threads, and then combine the results
    of each subtask in order to produce the overall result.
  id: totrans-1380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fork/Join 框架允许你递归地将可并行化的任务分割成更小的任务，在不同的线程上执行它们，然后将每个子任务的输出结果合并，以产生整体结果。
- en: '`Spliterator`s define how a parallel stream can split the data it traverses.'
  id: totrans-1381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Spliterator` 定义了并行流如何分割它遍历的数据。'
