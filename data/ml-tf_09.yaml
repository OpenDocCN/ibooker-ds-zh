- en: 7 Automatically clustering data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 自动聚类数据
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Performing basic clustering with k-means
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用k-means进行基本聚类
- en: Representing audio
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频表示
- en: Segmenting audio
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频分割
- en: Clustering with a self-organizing map
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自组织图进行聚类
- en: Suppose that you have a collection of not-pirated, totally legal MP3s on your
    hard drive. All your songs are crowded into one massive folder. Perhaps automatically
    grouping similar songs into categories such as Country, Rap, and Rock would help
    organize them. This act of assigning an item to a group (such as an MP3 to a playlist)
    in an unsupervised fashion is called *clustering*.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在硬盘上有一个完全合法、非盗版的MP3音乐集合。所有歌曲都挤在一个巨大的文件夹中。也许自动将相似的歌曲分组到如乡村、说唱和摇滚等类别中，可以帮助组织它们。这种以无监督方式将项目分配到组（如MP3到播放列表）的行为被称为*聚类*。
- en: Chapter 6 assumes that you’re given a training dataset of correctly labeled
    data. Unfortunately, you don’t always have that luxury when you collect data in
    the real world. Suppose that you want to divide a large amount of music into interesting
    playlists. How could you possibly group songs if you don’t have direct access
    to their metadata?
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 第6章假设你有一个正确标记的训练数据集。不幸的是，当你收集现实世界中的数据时，你并不总是享有这种便利。假设你想要将大量音乐分割成有趣的播放列表。如果你无法直接访问它们的元数据，你如何可能将歌曲分组？
- en: Spotify, SoundCloud, Google Music, Pandora, and many other music-streaming services
    try to solve this problem to recommend similar songs to customers. Their approach
    includes a mixture of various machine-learning techniques, but clustering is often
    at the heart of the solution.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Spotify、SoundCloud、Google Music、Pandora以及许多其他音乐流媒体服务试图解决这个问题，向客户推荐相似的歌曲。他们的方法包括各种机器学习技术的混合，但聚类通常是解决方案的核心。
- en: '*Clustering* is the process of intelligently categorizing the items in your
    dataset. The overall idea is that two items in the same cluster are “closer” to
    each other than items that belong to separate clusters. That’s the general definition,
    leaving the interpretation of *closeness* open. Perhaps cheetahs and leopards
    belong in the same cluster, whereas elephants belong to another cluster, when
    closeness is measured by the similarity of two species in the hierarchy of biological
    classification (family, genus, and species).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*聚类*是将你的数据集中的项目智能分类的过程。总体思路是，同一聚类中的两个项目比属于不同聚类的项目“更接近”。这是一般定义，将*接近*的解释留给了读者。也许当以生物分类体系（家族、属和物种）中两种物种的相似性来衡量接近度时，猎豹和豹属于同一聚类，而大象属于另一个聚类。'
- en: 'You can imagine that many clustering algorithms exist. This chapter focuses
    on two types: *k-means* and *self-organizing map*. These approaches are *unsupervised*,
    meaning that they fit a model without ground-truth examples.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象存在许多聚类算法。本章重点介绍两种类型：*k-means*和*自组织图*。这些方法是无监督的，意味着它们在没有地面实况示例的情况下拟合模型。
- en: First, you’ll learn how to load audio files into TensorFlow and represent them
    as feature vectors. Then you’ll implement various clustering techniques to solve
    real-world problems.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你将学习如何将音频文件加载到TensorFlow中，并将它们表示为特征向量。然后，你将实现各种聚类技术来解决实际问题。
- en: 7.1 Traversing files in TensorFlow
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 在TensorFlow中遍历文件
- en: Some common input types in machine-learning algorithms are audio and image files.
    This shouldn’t come as a surprise, because sound recordings and photographs are
    raw, redundant, often-noisy representations of semantic concepts. Machine learning
    is a tool to help handle these complications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法中的一些常见输入类型是音频和图像文件。这并不令人惊讶，因为录音和照片是语义概念的原始、冗余、通常嘈杂的表示。机器学习是一种帮助处理这些复杂性的工具。
- en: These data files have various implementations. An image can be encoded as a
    PNG or JPEG file, for example, and an audio file can be an MP3 or a WAV. In this
    chapter, you’ll investigate how to read audio files as input to your clustering
    algorithm so that you automatically group music that sounds similar.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据文件有多种实现方式。例如，一张图片可以编码为PNG或JPEG文件，而音频文件可以是MP3或WAV格式。在本章中，你将研究如何将音频文件作为聚类算法的输入，以便自动将听起来相似的音乐分组。
- en: Exercise 7.1
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 练习7.1
- en: What are the pros and cons of MP3 and WAV? How about PNG versus JPEG?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: MP3和WAV的优点和缺点是什么？PNG与JPEG又如何？
- en: '**Answer**'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案**'
- en: MP3 and JPEG significantly compress the data, so such files are easy to store
    or transmit. But because these files are lossy, WAV and PNG are closer to the
    original content.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: MP3 和 JPEG 显著压缩了数据，因此此类文件易于存储或传输。但因为这些文件是有损的，WAV 和 PNG 更接近原始内容。
- en: Reading files from disk isn’t exactly a machine-learning-specific ability. You
    can use a variety of Python libraries, such as NumPy or SciPy, to load files into
    memory, as *I have shown you in earlier chapters*. Some developers like to treat
    the data-preprocessing step separately from the machine-learning step. There’s
    no absolute right or wrong way to manage the pipeline, but you will try TensorFlow
    for both data preprocessing and learning.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 从磁盘读取文件并不完全是机器学习特有的能力。你可以使用各种 Python 库，如 NumPy 或 SciPy，将文件加载到内存中，正如我在前面的章节中向你展示的那样。一些开发者喜欢将数据预处理步骤与机器学习步骤分开处理。管理管道没有绝对的对错之分，但你会尝试使用
    TensorFlow 进行数据预处理和学习。
- en: TensorFlow provides an operator called `tf.train.match_filenames_once` to list
    files in a directory. You can pass this information along to the queue operator
    `tf.train.string_input_producer`. That way, you can access filenames one at a
    time without loading everything at the same time. Given a filename, you can decode
    the file to retrieve usable data. Figure 7.1 outlines the process of using the
    queue.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 提供了一个名为 `tf.train.match_filenames_once` 的操作符，用于列出目录中的文件。你可以将此信息传递给队列操作符
    `tf.train.string_input_producer`。这样，你可以一次访问一个文件名，而不必同时加载所有内容。给定一个文件名，你可以解码文件以检索可用的数据。图
    7.1 概述了使用队列的过程。
- en: '![CH07_F01_Mattmann2](../Images/CH07_F01_Mattmann2.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F01_Mattmann2](../Images/CH07_F01_Mattmann2.png)'
- en: Figure 7.1 You can use a queue in TensorFlow to read files. The queue is built
    into the TensorFlow framework, and you can use the `reader.read(...)` function
    to access (and dequeue) it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 你可以使用 TensorFlow 中的队列来读取文件。队列是 TensorFlow 框架的一部分，你可以使用 `reader.read(...)`
    函数来访问（并出队）它。
- en: Listing 7.1 shows an implementation of reading files from disk in TensorFlow.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.1 展示了在 TensorFlow 中从磁盘读取文件的实现。
- en: Listing 7.1 Traversing a directory for data
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.1 遍历目录以获取数据
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Stores filenames that match a pattern
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 存储匹配模式的文件名
- en: ❷ Runs the reader to extract file data
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 运行读取器以提取文件数据
- en: ❸ Natively reads a file in TensorFlow
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在 TensorFlow 中原生读取文件
- en: ❹ Sets up a pipeline for retrieving filenames randomly
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 设置用于随机检索文件名的管道
- en: ❺ Counts the number of files
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 计算文件数量
- en: ❻ Initializes threads for the filename queue
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 初始化文件名队列的线程
- en: ❼ Loops through the data one by one
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 逐个遍历数据
- en: 7.2 Extracting features from audio
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 从音频中提取特征
- en: Machine-learning algorithms typically are designed to use feature vectors as
    input, but sound files use a different format. You need a way to extract features
    from sound files to create feature vectors.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法通常设计为使用特征向量作为输入，但声音文件使用不同的格式。你需要一种从声音文件中提取特征以创建特征向量的方法。
- en: It helps to understand how these files are represented. If you’ve ever seen
    a vinyl record, you’ve probably noticed the representation of audio as grooves
    indented in the disk. Our ears interpret audio from a series of vibrations through
    air. By recording the vibration properties, an algorithm can store sound in a
    data format.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于理解这些文件是如何表示的。如果你曾经见过黑胶唱片，你可能已经注意到音频在磁盘上以凹槽的形式表示。我们的耳朵通过空气中的振动来解释音频。通过记录振动特性，算法可以将声音存储在数据格式中。
- en: The real world is continuous, but computers store data in discrete values. The
    sound is digitalized into a discrete representation through an analog-to-digital
    converter (ADC). You can think about sound as being fluctuation of a wave over
    time, but that data is too noisy and difficult to comprehend.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 真实世界是连续的，但计算机以离散值存储数据。声音通过模拟-数字转换器（ADC）数字化为离散表示。你可以将声音视为随时间波动的波动，但那些数据太嘈杂且难以理解。
- en: An equivalent way to represent a wave is to examine its frequencies at each
    time interval. This perspective is called the *frequency domain*. It’s easy to
    convert between time domains and frequency domains by using a mathematical operation
    called a *discrete Fourier transform* (commonly implemented with an algorithm
    known as the *fast Fourier transform*, which you’ll use to extract a feature vector
    from a sound).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表示波的另一种等效方式是检查每个时间间隔的频率。这种观点称为 *频域*。通过使用称为 *离散傅里叶变换* 的数学运算（通常通过称为 *快速傅里叶变换*
    的算法实现），很容易在时域和频域之间进行转换（你将使用它从声音中提取特征向量）。
- en: 'A handy Python library can help you view audio in this frequency domain. Download
    it from [http://mng.bz/X0J6](http://mng.bz/X0J6), extract it, and then run the
    following command to set it up:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一个方便的 Python 库可以帮助你在频域中查看音频。从 [http://mng.bz/X0J6](http://mng.bz/X0J6) 下载它，解压，然后运行以下命令来设置它：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Python 2 required
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 需要 Python 2
- en: The BregmanToolkit is officially supported in Python 2\. If you’re using Jupyter
    Notebooks, you can access both versions of Python by following the directions
    outlined in the official Jupyter docs ([http://mng.bz/ebvw](http://mng.bz/ebvw)).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Bregman Toolkit 在 Python 2 中官方支持。如果你使用 Jupyter Notebooks，你可以按照官方 Jupyter 文档中的说明（[http://mng.bz/ebvw](http://mng.bz/ebvw)）访问两个版本的
    Python。
- en: 'In particular, you can include Python 2 with the following commands:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是你可以使用以下命令包含 Python 2：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: A sound may produce 12 kinds of pitches. In music terminology, the 12 pitches
    are C, C#, D, D#, E, F, F#, G, G#, A, A#, and B. Listing 7.2 shows how to retrieve
    the contribution of each pitch in a 0.1-second interval, resulting in a matrix
    with 12 rows. The number of columns grows as the length of the audio file increases.
    Specifically, there will be 10 × *t* columns for a *t*-second audio. This matrix
    is also called a *chromagram* of the audio.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个声音可以产生 12 种音高。在音乐术语中，这 12 种音高是 C、C#、D、D#、E、F、F#、G、G#、A、A# 和 B。列表 7.2 展示了如何检索
    0.1 秒间隔内每个音高的贡献，从而得到一个有 12 行的矩阵。列数随着音频文件长度的增加而增加。具体来说，对于 t 秒的音频，将有 10 × *t* 列。这个矩阵也称为音频的
    *chromagram*。
- en: Listing 7.2 Representing audio in Python
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.2 在 Python 中表示音频
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: ❶ Passes in the filename
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 传入文件名
- en: ❷ Uses these parameters to describe 12 pitches every 0.1 second
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 每 0.1 秒使用这些参数描述 12 个音阶
- en: ❸ Represents the values of a 12-dimensional vector 10 times per second
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 每秒10次表示一个12维向量的值
- en: The chromagram output is a matrix, shown in figure 7.2\. A sound clip can be
    read as a chromagram, and a chromagram is a recipe for generating a sound clip.
    Now you have a way to convert between audio and matrices. And as you’ve learned,
    most machine-learning algorithms accept feature vectors as a valid form of data.
    That said, the first machine-learning algorithm you’ll look at is k-means clustering.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 谱图输出是一个矩阵，如图 7.2 所示。音频片段可以读作谱图，谱图是生成音频片段的配方。现在你有了在音频和矩阵之间转换的方法。正如你所学的，大多数机器学习算法接受特征向量作为有效的数据形式。因此，你将要查看的第一个机器学习算法是
    k-means 聚类。
- en: '![CH07_F02_Mattmann2](../Images/CH07_F02_Mattmann2.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F02_Mattmann2](../Images/CH07_F02_Mattmann2.png)'
- en: Figure 7.2 The chromagram matrix, where the x-axis represents time and the y-axis
    represents pitch class. The green parallelograms indicate the presence of that
    pitch at that time.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 谱图矩阵，其中 x 轴代表时间，y 轴代表音阶类别。绿色平行四边形表示在该时间存在该音阶。
- en: To run machine-learning algorithms on your chromagram, first you need to decide
    how you’re going to represent a feature vector. One idea is to simplify the audio
    by looking only at the most significant pitch class per time interval, as shown
    in figure 7.3.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要在您的 chromagram 上运行机器学习算法，首先您需要决定您将如何表示特征向量。一个想法是通过只查看每个时间间隔中最显著的音阶类来简化音频，如图
    7.3 所示。
- en: '![CH07_F03_Mattmann2](../Images/CH07_F03_Mattmann2.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F03_Mattmann2](../Images/CH07_F03_Mattmann2.png)'
- en: Figure 7.3 The most influential pitch at every time interval is highlighted.
    You can think of it as being the loudest pitch at each time interval.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 在每个时间间隔中突出的最有影响力的音高。你可以将其视为每个时间间隔中最响亮的音高。
- en: Then you count the number of times each pitch shows up in the audio file. Figure
    7.4 shows this data as a histogram, forming a 12-dimensional vector. If you normalize
    the vector so that all the counts add up to 1, you can easily compare audio of
    different lengths. Note this approach is similar to the Bag of Words approach
    you used in chapter 6 to generate a histogram of word counts from text of arbitrary
    lengths.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你计算每个音高在音频文件中出现的次数。图 7.4 将这些数据作为直方图显示，形成一个 12 维向量。如果你将向量归一化，使得所有计数之和为 1，你可以轻松比较不同长度的音频。注意这种方法与你在第
    6 章中使用的“词袋”方法类似，用于从任意长度的文本中生成词计数的直方图。
- en: '![CH07_F04_Mattmann2](../Images/CH07_F04_Mattmann2.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F04_Mattmann2](../Images/CH07_F04_Mattmann2.png)'
- en: Figure 7.4 You count the frequency of loudest pitches heard at each interval
    to generate this histogram, which acts as your feature vector.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 你计算在每个时间间隔内听到的最响亮音高的频率，以生成这个直方图，它作为你的特征向量。
- en: Exercise 7.2
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 练习 7.2
- en: What are some other ways to represent an audio clip as a feature vector?
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 有哪些其他方法可以将音频片段表示为特征向量？
- en: '**Answer**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案**'
- en: You can visualize the audio clip as an image (such as a spectrogram), and use
    image-analysis techniques to extract image features.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将音频剪辑可视化为图像（例如频谱图），并使用图像分析技术提取图像特征。
- en: Take a look at listing 7.3 to generate the histogram from figure 7.4, which
    is your feature vector.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 查看列表 7.3 以从图 7.4 生成直方图，这是你的特征向量。
- en: Listing 7.3 Obtaining a dataset for k-means
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.3 获取 k-means 的数据集
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ❶ Creates an op to identify the pitch with the biggest contribution
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 创建一个操作来识别贡献最大的音调
- en: ❷ Converts a chromagram into a feature vector
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 将音程图转换为特征向量
- en: ❸ Constructs a matrix where each row is a data item
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 构建一个矩阵，其中每一行是一个数据项
- en: NOTE All code listings are available from this book’s website at [http://mng.bz/
    yrEq](http://mng.bz/yrEq) and on GitHub at [http://mng.bz/MoJn.](http://mng.bz/MoJn)
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：所有代码列表均可在本书的网站上找到，网址为 [http://mng.bz/yrEq](http://mng.bz/yrEq)，以及 GitHub
    上 [http://mng.bz/MoJn](http://mng.bz/MoJn)。
- en: In keeping with what I’ve shown you in other chapters, after preparing your
    dataset, convince yourself that something is relatable among the chromagrams that
    listing 7.1 helps you read from disk and from which listing 7.3 generates a dataset.
    The dataset consists of five sounds corresponding to two different coughing sounds
    and three different screaming sounds. You can use your friendly neighborhood Matplotlib
    library to visualize the data and examine the learnability (unique proprieties
    of the underlying data) in listing 7.4\. If you can spot something that relates
    among the sound files, there is a great chance that the machine-learning algorithm
    can as well.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 按照我在其他章节中向您展示的内容，在准备您的数据集后，说服自己，列表 7.1 帮助您从磁盘读取并从列表 7.3 生成数据集的音程图中存在某种相关性。数据集由五个声音组成，对应两种不同的咳嗽声和三种不同的尖叫声。您可以使用您友好的
    Matplotlib 库来可视化数据并检查列表 7.4 中的可学习性（底层数据的独特属性）。如果您能在声音文件中找到某种相关性，那么机器学习算法也有很大机会能找到。
- en: You will create a set of labels P1-P12 for each of the 12 pitches in listing
    7.4\. Then, because you converted the data into a set of five matrices of size
    1 × 12 in listing 7.3, you will flatten those matrices into 12 data points to
    visualize for each of the five chromagrams. The result of listing 7.4 is shown
    in figure 7.5.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 你将为列表 7.4 中的 12 个音调创建一组标签 P1-P12。然后，因为你已经将数据转换为列表 7.3 中的五个 1 × 12 大小的矩阵，你将把这些矩阵展平成
    12 个数据点，以便为每个五个音程图可视化。列表 7.4 的结果如图 7.5 所示。
- en: '![CH07_F05_Mattmann2](../Images/CH07_F05_Mattmann2.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F05_Mattmann2](../Images/CH07_F05_Mattmann2.png)'
- en: Figure 7.5 Exploring the five sounds—two coughs and three screams—and their
    relationship at the 12 pitches. If your eyes can spot a pattern, there’s a great
    chance that the computer can too.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 探索五个声音——两个咳嗽声和三个尖叫声——及其在 12 个音调上的关系。如果你的眼睛能发现模式，那么计算机也有很大机会能发现。
- en: Listing 7.4 Exploring your sound file chromagrams
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.4 探索你的声音文件音程图
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Generate labels for each of the 12 pitch frequencies.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 为每个 12 个音调频率生成标签。
- en: ❷ Pick a different color for each of the five sounds.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 为五个声音中的每一个选择不同的颜色。
- en: ❸ Flatten the 1 × 12 matrices into 12 points, one for each pitch.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将 1 × 12 矩阵展平成 12 个点，每个音调一个。
- en: '❹ Create a legend for the five sounds: two coughs, and three screams.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 为五个声音创建一个图例：两个咳嗽声和三个尖叫声。
- en: Convince yourself that there are pitch similarities among the sounds by visually
    exploring figure 7.5\. It’s pretty clear that the vertical bars for the cough
    sounds have some correlation to pitches P1 and P5, and that scream sounds strongly
    relate on the vertical bars for pitches P5, P6, and P7\. Other, less-obvious similarities
    are the relationship in P5 and P6 of coughs and screams. You’ll see that it’s
    sometimes easier to see the correlations if you visualize one sound at a time,
    such as in figure 7.6, but this example is a good start. There’s definitely something
    to learn here, so let’s see what the computer can tell us about how to cluster
    these files.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通过视觉探索图 7.5 来说服自己，这些声音之间存在音调相似性。咳嗽声的垂直条与音调 P1 和 P5 有关联，而尖叫声与音调 P5、P6 和 P7 的垂直条有很强的关联。其他不太明显的相似性是咳嗽声和尖叫声在
    P5 和 P6 之间的关系。你会发现，如果你一次可视化一个声音，比如图 7.6，那么看到这些相关性有时会更容易，但这个例子是一个很好的开始。这里肯定有可以学习的东西，所以让我们看看计算机能告诉我们关于如何聚类这些文件的信息。
- en: 7.3 Using k-means clustering
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 使用 k-means 聚类
- en: The *k-means algorithm* is one of the oldest, yet most robust ways to cluster
    data. The *k* in *k-means* is a variable representing a natural number, so you
    can imagine 3-means clustering, 4-means clustering, or any other value for *k*.
    Thus, the first step in k-means clustering is choosing a value for *k*. To be
    concrete, let’s pick *k* = 3\. With that in mind, the goal of 3-means clustering
    is to divide the dataset into three categories (also called *clusters*).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**k-means算法**是数据聚类中最古老且最稳健的方法之一。在**k-means**中的**k**代表一个自然数变量，因此你可以想象3-means聚类、4-means聚类或任何其他**k**的值。因此，k-means聚类的第一步是选择一个**k**的值。具体来说，让我们选择**k**
    = 3。考虑到这一点，3-means聚类的目标是把数据集划分为三个类别（也称为**簇**）。'
- en: Choosing the number of clusters
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 选择簇的数量
- en: Choosing the right number of clusters often depends on the task. Suppose that
    you’re planning an event for hundreds of people, both young and old. If you have
    the budget for only two entertainment options, you can use k-means clustering
    with k = 2 to separate the guests into two age groups. At other times, determining
    the value of k isn’t as obvious. Automatically figuring out the value of k is
    a bit more complicated, so we won’t touch on that much in this section. In simplified
    terms, a straightforward way of determining the best value of k is to iterate
    over a range of k-means simulations and apply a cost function to determine which
    value of k caused the best differentiation between clusters at the lowest value
    of k.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 选择合适的簇数量通常取决于任务。假设你正在为数百人举办活动，既有年轻人也有老年人。如果你只有两个娱乐选项的预算，你可以使用k-means聚类，**k**
    = 2，将客人分成两个年龄组。在其他时候，确定**k**的值可能并不明显。自动确定**k**的值要复杂一些，所以在这个部分我们不会过多涉及。简单来说，确定最佳**k**值的一种直接方法是迭代一系列k-means模拟，并应用一个成本函数来确定哪个**k**值在最低**k**值时产生了最佳的簇间差异。
- en: The k-means algorithm treats data points as points in space. If your dataset
    is a collection of guests at an event, you can represent each guest by their age.
    Thus, your dataset is a collection of feature vectors. In this case, each feature
    vector is 1D because you’re considering only the age of the person.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法将数据点视为空间中的点。如果你的数据集是活动的客人集合，你可以通过他们的年龄来表示每个客人。因此，你的数据集是一组特征向量。在这种情况下，每个特征向量是1维的，因为你只考虑人的年龄。
- en: For clustering music by the audio data, the data points are feature vectors
    from the audio files. If two points are close together, their audio features are
    similar. You want to discover which audio files belong in the same “neighborhood,”
    because those clusters probably will be a good way to organize your music files.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于通过音频数据进行音乐聚类，数据点是音频文件的特征向量。如果两个点彼此靠近，它们的音频特征相似。你希望发现哪些音频文件属于同一个“邻域”，因为这些簇可能是组织你的音乐文件的好方法。
- en: The midpoint of all the points in a cluster is called its *centroid*. Depending
    on the audio features you choose to extract, a centroid could capture concepts
    such as loud sound, high-pitched sound, or saxophone-like sound. It’s important
    to note that the k-means algorithm assigns nondescript labels, such as cluster
    1, cluster 2, and cluster 3\. Figure 7.6 shows examples of the sound data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一个簇中所有点的中点称为其**质心**。根据你选择的音频特征，质心可以捕捉到诸如响亮的声音、高音调的声音或类似萨克斯管的声音等概念。需要注意的是，k-means算法分配了非描述性的标签，如簇1、簇2和簇3。图7.6展示了声音数据的示例。
- en: '![CH07_F06_Mattmann2](../Images/CH07_F06_Mattmann2.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F06_Mattmann2](../Images/CH07_F06_Mattmann2.png)'
- en: Figure 7.6 Four examples of audio files. The two on the right appear to have
    similar histograms, and the two on the left also have similar histograms. Your
    clustering algorithms will be able to group these sounds.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6展示了四个音频文件的示例。右侧的两个似乎具有相似的直方图，左侧的两个也具有相似的直方图。你的聚类算法将能够将这些声音分组。
- en: The k-means algorithm assigns a feature vector to one of the clusters by choosing
    the cluster whose centroid is closest to it. The k-means algorithm starts by guessing
    the cluster location and iteratively improves its guess over time. The algorithm
    either converges when it no longer improves the guesses or stops after a maximum
    number of attempts.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: k-means算法通过选择与它最近的质心的簇来将特征向量分配给一个簇。k-means算法首先猜测簇的位置，并随着时间的推移迭代地改进其猜测。算法要么在不再改进猜测时收敛，要么在尝试达到最大次数后停止。
- en: 'The heart of the algorithm consists of two tasks:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 算法的核心包括两个任务：
- en: '*Assignment* —Assign each data item (feature vector) to a category of the closest
    centroid.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*任务* —将每个数据项（特征向量）分配到最近的质心类别。'
- en: '*Recentering* —Calculate the midpoints of the newly updated clusters.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*重新定位* —计算新更新的簇的中间点。'
- en: These two steps repeat to provide increasingly better clustering results, and
    the algorithm stops when it has repeated a desired number of times or when the
    assignments no longer change. Figure 7.7 illustrates the algorithm.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个步骤重复进行，以提供越来越好的聚类结果，算法在重复了期望的次数或分配不再改变时停止。图7.7说明了该算法。
- en: '![CH07_F07_Mattmann2](../Images/CH07_F07_Mattmann2.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F07_Mattmann2](../Images/CH07_F07_Mattmann2.png)'
- en: Figure 7.7 One iteration of the k-means algorithm. Suppose that you’re clustering
    colors into three buckets (an informal way to say category). You can start with
    a guess of red, green, and blue to begin the assignment step. Then you update
    the bucket colors by averaging the colors that belong to each bucket. Repeat until
    the buckets no longer substantially change color, arriving at the color representing
    the centroid of each cluster.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 k-means算法的一次迭代。假设你正在将颜色聚类到三个桶（一种非正式地说成是类别的说法）。你可以从猜测红色、绿色和蓝色开始，以开始分配步骤。然后通过平均每个桶属于的颜色来更新桶的颜色。重复直到桶的颜色不再显著变化，达到每个簇的质心所代表的颜色。
- en: Listing 7.5 shows how to implement the k-means algorithm by using the dataset
    generated in listing 7.3\. For simplicity, choose *k* = 2, so you can easily verify
    that your algorithm partitions the audio files into two dissimilar categories.
    You’ll use the first *k* vectors as initial guesses for centroids.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.5展示了如何通过使用列表7.3生成的数据集来实现k-means算法。为了简单起见，选择*k* = 2，这样你可以轻松验证你的算法将音频文件分割成两个不同的类别。你将使用前*k*个向量作为质心的初始猜测。
- en: Listing 7.5 Implementing k-means
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.5 实现k-means
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Decides the number of clusters
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 决定簇的数量
- en: ❷ Declares the maximum number of iterations to run k-means
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 声明运行k-means的最大迭代次数
- en: ❸ Chooses the initial guesses of cluster centroids
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 选择簇质心的初始猜测
- en: ❹ Assigns each data item to its nearest cluster
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 将每个数据项分配到最近的簇
- en: ❺ Updates the cluster centroids to their midpoint
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 更新簇质心到它们的中间点
- en: ❻ Iterates to find the best cluster locations
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 迭代以找到最佳的簇位置
- en: That’s it! If you know the number of clusters and the feature vector representation,
    you can use listing 7.5 to cluster anything. In section 7.4, you’ll apply clustering
    to audio snippets within an audio file.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 就这些了！如果你知道簇的数量和特征向量表示，你可以使用7.5列表来聚类任何东西。在7.4节中，你将应用聚类到音频文件内的音频片段。
- en: 7.4 Segmenting audio
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.4 分割音频
- en: In section 7.3, you clustered various audio files to group them automatically.
    This section is about using clustering algorithms within one audio file. Whereas
    the former process is called *clustering*, the latter process is referred to as
    *segmentation*. *Segmentation* is another word for *clustering*, but we often
    say *segment* instead of *cluster* when dividing a single image or audio file
    into separate components. Segmentation is similar to the way dividing a sentence
    into words is different from dividing a word into letters. Though segmentation
    and clustering share the general idea of breaking bigger pieces into smaller components,
    words are different from letters.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在7.3节中，您将各种音频文件进行了聚类以自动分组。本节是关于在一个音频文件内使用聚类算法。前一个过程被称为*聚类*，而后一个过程被称为*分割*。*分割*是*聚类*的另一种说法，但当我们把单个图像或音频文件分割成单独的组件时，我们通常说*分割*而不是*聚类*。分割与将句子分割成单词的方式不同，与将单词分割成字母的方式不同。尽管分割和聚类共享将更大的块分割成更小块的一般思想，但单词与字母是不同的。
- en: Suppose that you have a long audio file, maybe of a podcast or talk show. Imagine
    writing a machine-learning algorithm to identify which of two people is speaking
    in an audio interview. The goal of segmenting an audio file is to associate which
    parts of the audio clip belong to the same category. In this case, you’d have
    a category for each person, and the utterances made by each person should converge
    to their appropriate categories, as shown in figure 7.8.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个长的音频文件，可能是播客或脱口秀。想象一下编写一个机器学习算法来识别音频访谈中哪两个人在说话。分割音频文件的目标是将音频剪辑的哪些部分关联到同一类别。在这种情况下，你将为每个人有一个类别，每个人的话语应该收敛到他们适当的类别，如图7.8所示。
- en: '![CH07_F08_Mattmann2](../Images/CH07_F08_Mattmann2.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F08_Mattmann2](../Images/CH07_F08_Mattmann2.png)'
- en: Figure 7.8 Audio segmentation is the process of labeling segments automatically.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8 音频分割是自动标记段的过程。
- en: Open a new source file, and follow along with listing 7.6, which will get you
    started by organizing the audio data for segmentation. The code splits an audio
    file into multiple segments of size `segment_size`. A long audio file would contain
    hundreds, if not thousands, of segments.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 打开一个新的源文件，并按照列表7.6进行操作，这将通过组织音频数据以进行分割来开始。该代码将音频文件分割成大小为`segment_size`的多个段。一个长的音频文件可能包含数百甚至数千个段。
- en: Listing 7.6 Organizing data for segmentation
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.6 为分割组织数据
- en: '[PRE7]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ❶ Decides the number of clusters
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 决定簇的数量
- en: ❷ The smaller the segment size, the better the results (but slower performance).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 段落大小越小，结果越好（但性能越慢）。
- en: ❸ Decides when to stop the iterations
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 决定何时停止迭代
- en: ❹ Obtains a dataset by extracting segments of the audio as separate data items
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 通过提取音频片段作为单独的数据项来获取数据集
- en: Now run k-means clustering on this dataset to identify when segments are similar.
    The intention is that k-means will categorize similar-sounding segments with the
    same label. If two people have significantly different-sounding voices, their
    sound snippets will belong to different labels. Listing 7.7 illustrates how to
    apply segmentation to an audio clip.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在运行k-means聚类算法于这个数据集，以确定何时段相似。目的是让k-means将听起来相似的段归类为相同的标签。如果两个人的声音听起来显著不同，他们的声音片段将属于不同的标签。列表7.7说明了如何将分割应用于音频剪辑。
- en: Listing 7.7 Segmenting an audio clip
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.7 分割音频剪辑
- en: '[PRE8]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Runs the k-means algorithm
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 运行k-means算法
- en: ❷ Prints the labels for each time interval
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 打印每个时间间隔的标签
- en: 'The output of running listing 7.7 is a list of timestamps and cluster IDs that
    correspond to who is talking during the podcast:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 运行列表7.7的输出是一个时间戳和簇ID的列表，对应于播客中谁在说话：
- en: '[PRE9]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Exercise 7.3
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 练习7.3
- en: How can you detect whether the clustering algorithm has converged (so that you
    can stop the algorithm early)?
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何检测聚类算法是否收敛（以便你可以提前停止算法）？
- en: '**Answer**'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案**'
- en: One way is to monitor how the cluster centroids change and declare convergence
    when no more updates are necessary (such as when the difference in the size of
    the error isn’t changing significantly between iterations). To do so, you’d need
    to calculate the size of the error and decide what constitutes significantly.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是通过监控簇中心的变化，并在不再需要更新时宣布收敛（例如，当迭代之间误差大小的差异没有显著变化时）。为此，你需要计算误差的大小并决定什么构成了显著变化。
- en: 7.5 Clustering with a self-organizing map
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.5 使用自组织映射进行聚类
- en: A *self-organizing map* (SOM) is a model for representing data into a lower-dimensional
    space. In doing so, a SOM automatically shifts similar data items closer together.
    Suppose you’re ordering pizza for a large group of people. You don’t want to order
    the same type of pizza for every single person, because one might happen to prefer
    fancy pineapple with mushrooms and peppers for their toppings, and you may prefer
    anchovies with arugula and onions.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '*自组织映射*（SOM）是一种将数据表示为低维空间中的模型。在这个过程中，SOM会自动将相似的数据项移动得更近。假设你正在为一大群人点披萨。你不想为每个人点同一种类型的披萨，因为可能有人喜欢加有凤梨、蘑菇和辣椒的奢华披萨，而你可能更喜欢加有金枪鱼、芝麻菜和洋葱的披萨。'
- en: Each person’s preference of toppings can be represented as a 3D vector. A SOM
    lets you embed these 3D vectors in two dimensions (as long as you define a distance
    metric between pizzas). Then a visualization of the 2D plot reveals good candidates
    for the number of clusters.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 每个人的配料偏好可以用一个3D向量表示。SOM让你将这些3D向量嵌入到二维空间中（只要你定义披萨之间的距离度量）。然后2D图的可视化揭示了簇数量的良好候选者。
- en: Although it may take longer to converge than the k-means algorithm, the SOM
    approach has no assumptions about the number of clusters. In the real world, it’s
    hard to select a value for the number of clusters. Consider a gathering of people
    in which the clusters change over time, as shown in figure 7.9.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可能比k-means算法收敛得慢，但SOM方法对簇的数量没有假设。在现实世界中，很难选择簇的数量。考虑一个随着时间的推移簇会改变的聚会，如图7.9所示。
- en: '![CH07_F09_Mattmann2](../Images/CH07_F09_Mattmann2.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F09_Mattmann2](../Images/CH07_F09_Mattmann2.png)'
- en: Figure 7.9 In the real world, we see groups of people in clusters all the time.
    Applying k-means requires knowing the number of clusters ahead of time. A more
    flexible tool is a SOM, which has no preconceptions about the number of clusters.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9 在现实世界中，我们经常看到人群在簇中聚集。应用 k-means 需要事先知道簇的数量。一个更灵活的工具是 SOM，它对簇的数量没有先入为主的观念。
- en: 'The SOM merely reinterprets the data as a structure conducive to clustering.
    The algorithm works as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: SOM 仅将数据重新解释为有利于聚类的结构。算法工作原理如下：
- en: Design a grid of nodes. Each node holds a weight vector of the same dimension
    as a data item. The weights of each node are initialized to random numbers, typically
    from a standard normal distribution.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设计一个节点网格。每个节点持有与数据项相同维度的权重向量。每个节点的权重初始化为随机数，通常是标准正态分布。
- en: Show data items to the network one by one. For each data item, the network identifies
    the node whose weight vector most closely matches it. This node is called the
    *best matching unit* (BMU).
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 逐个向网络展示数据项。对于每个数据项，网络都会识别出权重向量与其最接近的节点。这个节点被称为 *最佳匹配单元* (BMU)。
- en: After the network identifies the BMU, all neighbors of the BMU are updated so
    their weight vectors move closer to the BMU’s value. The closer nodes are affected
    more strongly than nodes farther away. Moreover, the number of neighbors around
    a BMU shrinks over time at a rate determined usually by trial and error. Figure
    7.10 illustrates the algorithm.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络识别出 BMU 后，所有 BMU 的邻居都会更新，以便它们的权重向量更接近 BMU 的值。距离 BMU 更近的节点受到的影响比距离更远的节点更强。此外，BMU
    周围邻居的数量会随着时间的推移以通常通过试错确定的速率减少。图 7.10 阐述了该算法。
- en: '![CH07_F10_Mattmann2](../Images/CH07_F10_Mattmann2.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F10_Mattmann2](../Images/CH07_F10_Mattmann2.png)'
- en: Figure 7.10 One iteration of the SOM algorithm. The first step is identifying
    the BMU, and the second is updating the neighboring nodes. You keep iterating
    these two steps with training data until certain convergence criteria are reached.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10 SOM 算法的一次迭代。第一步是识别 BMU，第二步是更新相邻节点。您会继续使用训练数据迭代这两个步骤，直到达到某些收敛标准。
- en: Listing 7.8 shows how to start implementing a SOM in TensorFlow. Follow along
    by opening a new source file.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.8 展示了如何在 TensorFlow 中开始实现 SOM。通过打开一个新的源文件来跟随操作。
- en: Listing 7.8 Setting up the SOM algorithm
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.8 设置 SOM 算法
- en: '[PRE10]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ❶ Each node is a vector of dimension dim. For a 2D grid, there are width × height
    nodes; get_locs is defined in listing 7.11.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 每个节点是一个维度为 dim 的向量。对于 2D 网格，有 width × height 个节点；get_locs 在列表 7.11 中定义。
- en: ❷ These two ops are inputs at each iteration.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 这两个操作在每个迭代中都是输入。
- en: ❸ You’ll need to access them from another method.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 您需要从另一个方法中访问它们。
- en: ❹ Finds the node that most closely matches the input (in listing 7.10)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 找到与输入最接近的节点（在列表 7.10 中）
- en: ❺ Updates the values of the neighbors (in listing 7.9)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 更新邻居的值（在列表 7.9 中）
- en: In listing 7.9, you define how to update neighboring weights, given the current
    time interval and BMU location. As time goes by, the BMU’s neighboring weights
    are less influenced to change. That way, the weights gradually settle over time.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 7.9 中，您定义了如何根据当前时间间隔和 BMU 位置更新相邻权重。随着时间的推移，BMU 的相邻权重受到的影响逐渐减小。这样，权重就会随着时间的推移逐渐稳定。
- en: Listing 7.9 Defining how to update the values of neighbors
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.9 定义如何更新邻居的值
- en: '[PRE11]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ❶ The rate decreases as iter increases. This value influences the alpha and
    sigma parameters.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 随着迭代的增加，该速率降低。此值影响 alpha 和 sigma 参数。
- en: ❷ Expands bmu_loc so you can efficiently compare it pairwise with each element
    of node_locs
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 扩展 bmu_loc 以便您能够高效地将其成对地与 node_locs 中的每个元素进行比较
- en: ❸ Ensures that nodes closer to the BMU change more dramatically
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 确保靠近 BMU 的节点变化更为显著
- en: ❹ Defines the updates
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 定义更新操作
- en: ❺ Returns an op to perform the updates
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 返回一个操作以执行更新
- en: Listing 7.10 shows how to find the BMU location, given an input data item. It
    searches the grid of nodes to find the one with the closest match. This step is
    similar to the assignment step in k-means clustering, in which each node in the
    grid is a potential cluster centroid.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.10 展示了如何根据输入数据项找到 BMU 位置。它搜索节点网格以找到最接近匹配的节点。这一步骤类似于 k-means 聚类中的分配步骤，其中网格中的每个节点都是一个潜在的聚类质心。
- en: Listing 7.10 Getting the node location of the closest match
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.10 获取最接近匹配的节点位置
- en: '[PRE12]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In listing 7.11, you create a helper method to generate a list of (x, y) locations
    on all the nodes in the grid.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表 7.11 中，您创建了一个辅助方法来生成网格中所有节点的 (x, y) 位置列表。
- en: Listing 7.11 Generating a matrix of points
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.11 生成点矩阵
- en: '[PRE13]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Finally, let’s define a method called `train` to run the algorithm, as shown
    in listing 7.12\. First, you must set up the session and run the `global_variables_initializer`
    op. Next, you loop `num_iters` a certain number of times to update weights using
    the input data one by one. When the loop ends, you record the final node weights
    and their locations.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们定义一个名为 `train` 的方法来运行算法，如列表 7.12 所示。首先，你必须设置会话并运行 `global_variables_initializer`
    操作。接下来，你循环 `num_iters` 次数来使用输入数据逐个更新权重。当循环结束时，你记录最终的节点权重及其位置。
- en: Listing 7.12 Running the SOM algorithm
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.12 运行SOM算法
- en: '[PRE14]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: That’s it! Now let’s see the algorithm in action. Test the implementation by
    showing the SOM some input. In listing 7.13, the input is a list of 3D feature
    vectors. By training the SOM, you’ll discover clusters within the data. You’ll
    use a 4 × 4 grid, but it’s best to try various values to cross-validate the best
    grid size. Figure 7.11 shows the output of the code.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！现在让我们看看算法的实际应用。通过向SOM展示一些输入来测试实现。在列表 7.13 中，输入是一个3D特征向量的列表。通过训练SOM，你将在数据中发现簇。你将使用一个
    4 × 4 的网格，但最好尝试不同的值以进行交叉验证以找到最佳网格大小。图 7.11 显示了代码的输出。
- en: '![CH07_F11_Mattmann2](../Images/CH07_F11_Mattmann2.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![CH07_F11_Mattmann2](../Images/CH07_F11_Mattmann2.png)'
- en: Figure 7.11 The SOM places all 3D data points in a 2D grid. From it, you can
    pick the cluster centroids (automatically or manually) and achieve clustering
    in an intuitive lower-dimensional space.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 SOM将所有3D数据点放置在二维网格中。从图中，你可以选择簇中心（自动或手动）并在直观的低维空间中实现聚类。
- en: Listing 7.13 Testing the implementation and visualizing the results
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.13 测试实现并可视化结果
- en: '[PRE15]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ❶ The grid size is 4 × 4, and the input dimension is 3.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 网格大小为 4 × 4，输入维度为 3。
- en: The SOM embeds higher-dimensional data in 2D to make clustering easy. This process
    acts as a handy preprocessing step. You can indicate the cluster centroids manually
    by observing the SOM’s output, but it’s also possible to find good centroid candidates
    automatically by observing the gradient of the weights. If you’re adventurous,
    I suggest reading the famous paper “Clustering of the Self-Organizing Map” by
    Juha Vesanto and Esa Alhoniemi, at [http://mng.bz/XzyS](http://mng.bz/XzyS).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 自组织映射（SOM）将高维数据嵌入到二维空间中，以便于聚类。这个过程充当了一个方便的预处理步骤。你可以通过观察SOM的输出手动指示簇中心，但也可以通过观察权重的梯度自动找到好的中心候选者。如果你喜欢冒险，我建议阅读Juha
    Vesanto和Esa Alhoniemi撰写的著名论文“自组织映射的聚类”，链接为[http://mng.bz/XzyS](http://mng.bz/XzyS)。
- en: 7.6 Applying clustering
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.6 应用聚类
- en: 'You’ve already seen two practical applications of clustering: organizing music
    and segmenting an audio clip to label similar sounds. Clustering is especially
    helpful when the training dataset doesn’t contain corresponding labels. As you
    know, such a situation characterizes unsupervised learning. Sometimes, data is
    too inconvenient to annotate.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了两个聚类的实际应用：组织音乐和分割音频片段以标记相似的声音。当训练数据集不包含相应的标签时，聚类特别有帮助。正如你所知，这种情况代表了无监督学习。有时，数据不便进行标注。
- en: Suppose that you want to understand sensor data from the accelerometer of a
    phone or smartwatch. At each time step, the accelerometer provides a 3D vector,
    but you have no idea whether the human is walking, standing, sitting, dancing,
    jogging, or so on. You can obtain such a dataset at [http://mng.bz/rTMe](http://mng.bz/rTMe).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你想了解来自手机或智能手表加速度计的传感器数据。在每个时间步，加速度计提供一个3D向量，但你不知道人类是在行走、站立、坐着、跳舞、慢跑还是其他活动。你可以在[http://mng.bz/rTMe](http://mng.bz/rTMe)获得这样的数据集。
- en: To cluster the time-series data, you’ll need to summarize the list of accelerometer
    vectors into a concise feature vector. One way is to generate a histogram of differences
    between consecutive magnitudes of the acceleration. The derivative of acceleration
    is called *jerk*, and you can apply the same operation to obtain a histogram outlining
    differences in jerk magnitudes.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 要对时间序列数据进行聚类，你需要将加速度计向量的列表总结成一个简洁的特征向量。一种方法是通过生成加速度连续幅度的差异直方图。加速度的导数称为 *jerk*，你可以应用相同的操作来获得描述jerk幅度差异的直方图。
- en: This process of generating a histogram out of data is exactly like the preprocessing
    steps on audio data explained in this chapter. After you’ve transformed the histograms
    into feature vectors, you can use the code listings in this chapter (such as k-means
    in TensorFlow).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据生成直方图的过程与本章中解释的音频数据预处理步骤非常相似。在你将直方图转换为特征向量之后，你可以使用本章中的代码列表（例如TensorFlow中的k-means）。
- en: Note Whereas previous chapters discussed supervised learning, this chapter focuses
    on unsupervised learning. In chapter 9, you’ll see a machine-learning algorithm
    that is neither of the two. This algorithm is a modeling framework that doesn’t
    get much attention from programmers but is the essential tool of statisticians
    for unveiling hidden factors in data.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：虽然前几章讨论了监督学习，但本章重点介绍无监督学习。在第9章中，您将看到一个既不属于监督学习也不属于无监督学习的机器学习算法。这个算法是一个建模框架，虽然程序员对其关注不多，但它是统计学家揭示数据中隐藏因素的必备工具。
- en: Summary
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Clustering is an unsupervised machine-learning algorithm for discovering structure
    in data.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类是一种用于在数据中寻找结构的无监督机器学习算法。
- en: One of the easiest algorithms to implement and understand is k-means clustering,
    which also performs well in terms of speed and accuracy.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其中最容易实现和理解的算法之一是k-means聚类，它在速度和准确性方面也表现良好。
- en: If the number of clusters isn’t specified, you can use the SOM algorithm to
    view the data in a simplified perspective.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果没有指定聚类数量，您可以使用SOM算法以简化的视角查看数据。
