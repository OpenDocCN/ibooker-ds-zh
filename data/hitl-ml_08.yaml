- en: 6 Applying active learning to different machine learning tasks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 将主动学习应用于不同的机器学习任务
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Calculating uncertainty and diversity for object detection
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算目标检测的不确定性和多样性
- en: Calculating uncertainty and diversity for semantic segmentation
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算语义分割的不确定性和多样性
- en: Calculating uncertainty and diversity for sequence labeling
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算序列标注的不确定性和多样性
- en: Calculating uncertainty and diversity for language generation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算语言生成的不确定性和多样性
- en: Calculating uncertainty and diversity for speech, video, and information retrieval
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算语音、视频和信息检索的不确定性和多样性
- en: Choosing the right number of samples for human review
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择合适数量的样本进行人工审查
- en: In chapters 3, 4, and 5, the examples and algorithms focused on document-level
    or image-level labels. In this chapter, you will learn how the same principles
    of uncertainty sampling and diversity sampling can be applied to more complicated
    computer vision tasks such as object detection and semantic segmentation (pixel
    labeling) and more complicated natural language processing (NLP) tasks such as
    sequence labeling and natural language generation. The general principles are
    the same, and in many cases, there is no change at all. The biggest difference
    is how you sample the items selected by active learning, and that will depend
    on the real-world problem that you are trying to solve.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3、4、5章中，示例和算法主要集中在文档级或图像级标签上。在本章中，你将学习如何将不确定性采样和多样性采样的相同原则应用于更复杂的计算机视觉任务，例如目标检测和语义分割（像素标注）以及更复杂的自然语言处理（NLP）任务，如序列标注和自然语言生成。一般原则是相同的，并且在许多情况下，没有任何变化。最大的不同之处在于你如何采样主动学习选择的项，这将取决于你试图解决的现实世界问题。
- en: Most real-world machine learning systems use tasks that are more complicated
    than document-level or image-level label predictions. Even problems that sound
    simple tend to require advanced active learning techniques when you dive into
    them. Imagine that you are building a computer vision system to help with agriculture.
    You have smart tractors with cameras that need to distinguish seedlings from weeds
    so that the tractors can efficiently and accurately apply fertilizer and herbicides.
    Although weeding fields is one of the most common and repetitive tasks in human
    history, you need object detection within an image, not image-level labels, to
    automate this task.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现实世界的机器学习系统使用比文档级或图像级标签预测更复杂的任务。即使听起来简单的问题，当你深入研究时，往往需要高级的主动学习技术。想象一下，你正在构建一个计算机视觉系统来帮助农业。你拥有带有摄像头的智能拖拉机，需要区分幼苗和杂草，以便拖拉机可以高效准确地施用肥料和除草剂。尽管除草是历史上最常见和重复的任务之一，但你需要图像内的目标检测，而不是图像级标签，来自动化这项任务。
- en: Also, your model has different kinds of confusion. In some cases, your model
    knows that an object is a plant but can’t decide whether that plant is a seedling
    or a weed. In other cases, your model isn’t certain whether some new object is
    a plant because all kinds of small objects can find their way onto a field. You
    need uncertainty sampling for the seedling/weed distinction combined with diversity
    sampling to identify new objects.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你的模型有不同的混淆类型。在某些情况下，你的模型知道一个物体是植物，但无法决定该植物是幼苗还是杂草。在其他情况下，由于各种小物体都可能进入田地，你的模型不确定某些新物体是否是植物。你需要不确定性采样来区分幼苗/杂草，并结合多样性采样来识别新物体。
- en: Finally, your camera is capturing up to 100 plants in every image, so you have
    to decide how to resolve the image-level confusion with the object-level confusion.
    Do you prioritize human review when one object in the image is very confusing
    or when 100 objects are a little confusing? Do you prioritize the correct label
    for the type of object or the accuracy of the object outline? Any of these types
    of error could be the most important for the problem you are addressing, so you
    need to decide how to map your real-world problem to the right sampling and evaluation
    strategy. Therefore, even though you are automating one of the most common and
    repetitive tasks in history, you need advanced active learning techniques to solve
    the problem.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你的相机在每张图像中捕捉多达100种植物，因此你必须决定如何解决图像级混淆与对象级混淆。当图像中的一个对象非常难以识别或当100个对象有点难以识别时，你是否优先考虑人工审查？你是否优先考虑对象的正确标签或对象轮廓的准确性？任何这些类型的错误都可能对你正在解决的问题至关重要，因此你需要决定如何将你的现实世界问题映射到正确的采样和评估策略。因此，尽管你正在自动化历史上最常见和重复的任务之一，但你仍需要高级的主动学习技术来解决问题。
- en: 6.1 Applying active learning to object detection
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 将主动学习应用于目标检测
- en: 'Until now, we have looked at relatively simple machine learning problems: making
    predictions about whole images (image labeling) or whole pieces of text (document
    labeling). For many problems, however, more fine-grained predictions are needed.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们研究的是相对简单的机器学习问题：对整个图像（图像标注）或整个文本片段（文档标注）进行预测。然而，对于许多问题，需要更精细的预测。
- en: 'You may want to identify only certain objects within an image, for example,
    so you care more about uncertainty and diversity in the objects than in the backgrounds.
    Our example at the start of the chapter is like this: you care about identifying
    weeds more than identifying the field that surrounds them. To the extent that
    you care about the background, you care only so that you can distinguish the weeds
    from different backgrounds.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能只想在图像中识别某些对象，例如，因此你更关心对象的不确定性和多样性，而不是背景。本章开头我们的例子就是这样：你更关心识别杂草，而不是识别围绕它们的田野。在关心背景的程度上，你只关心这一点，以便你能区分杂草和不同的背景。
- en: For these examples, you want to employ active learning strategies that also
    focus on the areas that you care about. Sometimes, you get this focus for free;
    your models are concentrating on the areas that you care about, so you won’t often
    need to change anything in the approaches that you learned for image and document
    labeling. In other cases, you need to crop/mask your data to the areas that you
    care about and be careful that you are not introducing bias in that process. For
    the next few sections of this chapter, we will go over some kinds of machine learning
    problems and see how the active learning strategies that you have already learned
    can be adapted to them.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些示例，你希望采用也关注你所关心区域的主动学习策略。有时，这种关注是免费的；你的模型正在关注你所关心的区域，因此你通常不需要改变你在图像和文档标注中学习的方法。在其他情况下，你需要裁剪/遮蔽你的数据到你所关心的区域，并确保在这个过程中没有引入偏差。在接下来的几节中，我们将讨论一些机器学习问题，并看看你已学到的主动学习策略如何适应这些问题。
- en: Figure 6.1 illustrates a problem for identifying uncertainty and diversity in
    object detection tasks. Assume that this task uses the same example image from
    chapter 3, but whereas in chapter 3, we wanted only to predict a label for the
    image, now we want to identify specific objects within an image and place a bounding
    box around those images. As figure 6.1 shows, the object we care about—the bicycle—is
    only a tiny fraction of the pixels in the bounding box that surrounds it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1说明了在目标检测任务中识别不确定性和多样性的问题。假设这个任务使用的是第3章中的相同示例图像，但在第3章中，我们只想预测图像的标签，而现在我们想要识别图像中的特定对象并在这些图像周围放置边界框。如图6.1所示，我们关心的对象——自行车——只是围绕它的边界框中像素的一小部分。
- en: '![](../Images/CH06_F01_Munro.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F01_Munro.png)'
- en: Figure 6.1 An illustration of the problem of identifying uncertainty and diversity
    in object detection tasks. The object we care about—the bicycle—is a small percentage
    of the pixels in the bounding box that surrounds it. Even a modest amount of context
    is twice the number of pixels, and the image as a whole is 10 times the number
    of pixels of the bounding box. Therefore, if we tried to calculate uncertainty
    or diversity across the whole image, we would risk focusing on a lot of irrelevant
    information.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1展示了在目标检测任务中识别不确定性和多样性的问题。我们关心的对象——自行车——是其周围边界框中像素的一小部分。即使是微量的上下文也是像素数量的两倍，整个图像的像素数量是边界框的10倍。因此，如果我们试图在整个图像上计算不确定性和多样性，我们可能会风险关注大量无关信息。
- en: The edge of an object is often where the most information is, but increasing
    the context by 20% will almost double the total amount of pixels at which we are
    looking. The image as a whole is 10 times the number of pixels of the bounding
    box. Therefore, if we tried to calculate uncertainty or diversity across the whole
    image, we would risk focusing on a lot of irrelevant information. Although we
    can use the uncertainty sampling and diversity sampling techniques that we learned
    in chapters 4 and 5, we want to focus that uncertainty and diversity on the areas
    about which we care most.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对象的边缘往往是信息最丰富的地方，但通过增加20%的上下文几乎会翻倍我们关注的像素总数。整个图像的像素数量是边界框的10倍。因此，如果我们试图在整个图像上计算不确定性和多样性，我们可能会风险关注大量无关信息。尽管我们可以使用在第4章和第5章中学到的不确定性采样和多样性采样技术，但我们希望将这种不确定性和多样性集中在我们最关心的区域。
- en: The rest of this section will cover how to calculate uncertainty and diversity.
    You get uncertainty fairly easily from your models; the highest uncertainty will
    tend to be in your objects, not in the background. For diversity, you want to
    focus primarily on diversity in areas that are also uncertain.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的其余部分将介绍如何计算不确定性和多样性。你可以从你的模型中很容易地获得不确定性；最高不确定性往往在于你的对象，而不是背景。对于多样性，你应主要关注那些也是不确定的区域。
- en: '6.1.1 Accuracy for object detection: Label confidence and localization'
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.1 目标检测的准确性：标签置信度和定位
- en: 'You have two tasks here: object detection and object labeling. You should apply
    different types of uncertainty and diversity to both tasks:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你在这里有两个任务：目标检测和目标标注。你应该将不同类型的不确定性和多样性应用于这两个任务：
- en: Labeling each object (bicycle, human, pedestrian, and so on)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标注每个对象（自行车、人类、行人等）
- en: Identifying the boundaries of objects in an image
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别图像中对象的边界
- en: The confidence for each task is
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 每个任务的置信度是
- en: Object label confidence (confidence that the label is correct)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象标签置信度（标签正确的置信度）
- en: Object localization confidence (confidence that the bounding box is correct)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象定位置信度（边界框正确的置信度）
- en: If you get a confidence score from your object detection algorithm, your confidence
    score is most likely *only* the object label confidence. The majority of object
    detection algorithms used today use convolutional neural networks (CNNs) and rely
    on regression to arrive at the right bounding box. All these algorithms return
    the label confidence, but few return a score from the regression that arrived
    at the bounding box itself.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从你的目标检测算法中获得一个置信度分数，你的置信度分数很可能是**仅**目标标签的置信度。今天使用的绝大多数目标检测算法都使用卷积神经网络（CNNs）并依赖于回归来确定正确的边界框。所有这些算法都会返回标签置信度，但很少返回到达边界框本身的回归分数。
- en: 'You can determine label accuracy the same way that you determine image-and
    document-level accuracy: by looking at some variation on F-score or area under
    the curve (AUC), as you learned in earlier chapters and the appendix. Intersection
    over union (IoU) is the most common metric for determining localization accuracy.
    If you’ve worked in computer vision before, you are aware of IoU already. Figure
    6.2 shows an example of IoU, calculating accuracy as the area where the predicted
    and actual bounding box intersect, divided by the total area covered by those
    two boxes.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过查看F分数或曲线下面积（AUC）的某种变化来确定标签准确性，就像你在前面的章节和附录中学到的那样：通过查看预测边界框和实际边界框相交的区域面积，除以这两个框覆盖的总面积。交集与并集（IoU）是确定定位准确性的最常用指标。如果你之前从事过计算机视觉工作，你早已知道IoU。图6.2展示了IoU的一个示例，计算准确性的方法是将预测边界框和实际边界框相交的区域面积除以这两个框覆盖的总面积。
- en: '![](../Images/CH06_F02_Munro.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F02_Munro.png)'
- en: Figure 6.2 An example of IoU for measuring the accuracy of a bounding box. The
    accuracy is calculated as the area that intersects the predicted bounding box
    with the actual bounding box, divided by the area that is the union of the two
    boxes.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 使用IoU测量边界框准确性的示例。准确性是通过预测边界框与实际边界框相交的面积除以两个边界框并集的面积来计算的。
- en: 'IoU is also used in active learning for object detection, so it’s important
    to learn (or refresh your knowledge) before you jump into uncertainty sampling
    and diversity sampling for object detection. In terms of the accuracy metrics
    that we’ve already looked at, IoU is more strict in that it tends to have lower
    values over the same data. Think of IoU in terms of the amount of area (or pixels)
    that is correct or incorrectly predicted:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: IoU也用于主动学习中的目标检测，因此在跳入不确定性采样和多样性采样之前，学习（或更新你的知识）是很重要的。就我们之前讨论的准确度指标而言，IoU更为严格，因为它往往在相同的数据上具有更低的值。将IoU视为正确或错误预测的面积（或像素）的数量：
- en: '![](../Images/CH06_F02_Munro_E01.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F02_Munro_E01.png)'
- en: 'Like F-score, IoU combines both types of errors: false positives and false
    negatives. IoU is always lower than F-score except in the trivial case of 100%
    accuracy. F-score tends to be more popular in NLP, and IoU is used almost exclusively
    in computer vision. You’ll see AUC in the literature for most machine learning
    fields, although AUC is not used as often as it should be in NLP and computer
    vision.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 与F-score类似，IoU结合了两种类型的错误：误报和漏报。除了100%准确性的简单情况外，IoU总是低于F-score。F-score在NLP中更为流行，而IoU几乎仅用于计算机视觉。你会在大多数机器学习领域的文献中看到AUC，尽管AUC在NLP和计算机视觉中并不像应该的那样常用。
- en: You will also see mean average precision (mAP) in the computer vision literature.
    mAP is a different kind of curve from AUC, but with a similar idea. For mAP, you
    rank the items by precision and then plot by recall, creating a precision-recall
    curve, and the average precision is the area under that curve. This application
    of mAP requires a threshold at which an object is “correct”—often, an IoU of 0.5
    or 0.75\. The exact threshold calculation of mAP tends to vary and is often defined
    specifically for different datasets and use cases. For a highly calibrated task
    such as autonomous driving, you obviously want much more than 0.50 IoU to call
    the prediction correct. It is not important to know any of the mAP calculations
    for this book; it is sufficient to be aware of this other, common accuracy metric
    that will be task-specific.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你还会在计算机视觉文献中看到平均平均精度（mAP）。mAP是一种与AUC不同的曲线，但具有类似的想法。对于mAP，你按精度对项目进行排名，然后按召回率绘制，创建一个精度-召回曲线，平均精度是该曲线下的面积。这种mAP的应用需要一个阈值来定义一个物体是否“正确”——通常是一个IoU值为0.5或0.75。mAP的确切阈值计算往往会有所不同，并且通常为不同的数据集和用例专门定义。对于像自动驾驶这样高度校准的任务，显然你需要比0.50的IoU值更高的准确度来认为预测是正确的。对于这本书来说，了解任何mAP的计算都不是必要的；重要的是要意识到这种其他常见的准确度指标，它将根据任务而特定。
- en: For active learning, you generally want to employ a strategy that samples from
    both localization confidence and label confidence. You need to determine how much
    you want to focus on each type. Although your label and IoU accuracy will help
    you determine where you need to focus the most attention, your focus will also
    depend on the application that you are building.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于主动学习，你通常希望采用一种策略，从定位置信度和标签置信度中采样。你需要确定你想要关注每种类型的程度。尽管你的标签和IoU准确性将帮助你确定需要最关注的地方，但你的关注点也将取决于你正在构建的应用程序。
- en: Suppose that you are deploying our example model to detect pedestrians, cars,
    bicycles, and other objects on roads. If your application is designed to predict
    collisions, localization is most important; it doesn’t matter whether you get
    the label wrong as much as it matters whether your object boundaries are off.
    If your application is meant to identify different traffic volumes, however, the
    exact boundaries of the objects aren’t important, but the labels are important
    because you want to be precise about knowing exactly how many cars, pedestrians,
    and other objects are seen.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在部署我们的示例模型以检测道路上的行人、汽车、自行车和其他物体。如果你的应用程序旨在预测碰撞，定位最为重要；错误地标记并不重要，重要的是你的物体边界是否准确。然而，如果你的应用程序旨在识别不同的交通流量，那么物体的精确边界并不重要，但标签很重要，因为你需要精确地知道看到了多少汽车、行人和其他物体。
- en: So you could have the same model deployed in the same place, but depending on
    the use case, you might focus your active learning and data annotation strategies
    on either localization or confidence. Determine what is most important for your
    use case, and focus your active learning strategy accordingly.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以在相同的位置部署相同的模型，但根据用例，你可能需要将你的主动学习和数据标注策略集中在本地化或置信度上。确定对你用例最重要的因素，并相应地集中你的主动学习策略。
- en: 6.1.2 Uncertainty sampling for label confidence and localization in object detection
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.2 对象检测中标签置信度和定位的不确定性采样
- en: You can use label confidence for uncertainty sampling, as you did for image-level
    labels in chapter 3\. Your object detection model will give a probability distribution,
    and you can apply least confidence, margin of confidence, ratio of confidence,
    entropy, or an ensemble model to determine your uncertainty for the label prediction.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用标签置信度进行不确定性采样，就像你在第3章中为图像级标签所做的那样。你的目标检测模型将给出一个概率分布，你可以应用最小置信度、置信度范围、置信度比率、熵或集成模型来确定标签预测的不确定性。
- en: 'For localization confidence, an ensemble model is your best option, combining
    multiple deterministic predictions into a single one that can be interpreted as
    confidence. Figure 6.3 shows an example. You can use either of two approaches:
    a true ensemble or dropouts within one model, both of which you learned in chapter
    3.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于定位置信度，集成模型是你的最佳选择，它将多个确定性预测组合成一个可以解释为置信度的单一预测。图6.3显示了示例。你可以使用两种方法中的任何一种：真正的集成或一个模型内的dropout，这两种方法你都在第3章中学过。
- en: '![](../Images/CH06_F03_Munro.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F03_Munro.png)'
- en: 'Figure 6.3 An example prediction heat map for an object, showing low variation
    (left) and high variation (right). The high variation is evidence of more uncertainty
    in the model; therefore, the right example is a good candidate for human evaluation.
    You can generate multiple predictions by using ensemble models, getting predictions
    from multiple models and changing the parameters, using a subset of features or
    a subset of items, or introducing random variation into your models in some other
    way. Within a single model, you can generate multiple predictions for a single
    item by using a dropout over a random selection of neurons for each prediction
    (known as Monte Carlo dropouts). You can also combine both methods: create an
    ensemble of models, and use dropouts for multiple predictions per model.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 对一个对象的预测热力图示例，显示了低变化（左侧）和高变化（右侧）。高变化是模型中更多不确定性的证据；因此，右侧示例是人工评估的良好候选。你可以通过使用集成模型、从多个模型中获得预测并改变参数、使用特征子集或项目子集，或以其他方式在模型中引入随机变化来生成多个预测。在单个模型中，你可以通过在每个预测中使用随机选择的神经元的dropout来为单个项目生成多个预测（称为蒙特卡洛dropout）。你还可以结合两种方法：创建一个模型集成，并为每个模型进行多次预测使用dropout。
- en: For a true ensemble, you get predictions from multiple models and ensure that
    those predictions will vary by using different hyperparameters for different models,
    training on a subset of features for each model, training on a subset of items
    for each model, or introducing random variation into your training runs in other
    ways, such as shuffling the order of training items.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于真正的集成，你从多个模型中获得预测，并确保这些预测会因不同模型的超参数而有所不同，为每个模型训练特征子集，为每个模型训练项目子集，或者以其他方式（如打乱训练项目的顺序）在训练运行中引入随机变化。
- en: 'For a single model, you can generate multiple predictions by using a dropout
    over a random selection of neurons for each prediction (aka Monte Carlo dropout).
    This approach is faster and easier than building multiple models and surprisingly
    effective for how simple it is. You could also combine both methods: train a handful
    of models with different parameters and then apply dropouts to each model.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单个模型，你可以通过在每个预测中使用随机选择的神经元的dropout来生成多个预测（即蒙特卡洛dropout）。这种方法比构建多个模型更快、更简单，而且出奇地有效。你也可以结合两种方法：训练一些具有不同参数的模型，然后对每个模型应用dropout。
- en: 'The uncertainty is calculated from the average IoU across all predictions.
    This calculation naturally gives a [0, 1] range, so there is no need to normalize
    it. Divide by the number of models, not predictions. Some models may not make
    a prediction, and this information is important: treat all nonpredictions as IoU=0.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性是从所有预测的平均IoU计算得出的。这种计算自然给出一个[0, 1]的范围，因此不需要归一化。除以模型的数量，而不是预测的数量。一些模型可能不会做出预测，这个信息很重要：将所有非预测视为IoU=0。
- en: Now that you have an uncertainty score for each bounding box, you can sample
    the bounding boxes with the greatest uncertainty for human review. If you are
    using ensemble methods or dropouts for localization, you can use them for label
    confidence, in place of or in addition to the other uncertainty sampling methods.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你为每个边界框都有一个不确定性分数，你可以采样具有最大不确定性的边界框以供人工审查。如果你使用集成方法或dropout进行定位，你可以将它们用于标签置信度，代替或补充其他不确定性采样方法。
- en: 6.1.3 Diversity sampling for label confidence and localization in object detection
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.3 对象检测中的标签置信度和定位的多样性采样
- en: 'For diversity sampling, we need to solve the problem that we introduced at
    the start of this chapter: we care about diversity in the objects more than diversity
    in the background. The simplest solution is to crop images to the predicted bounding
    boxes and then apply diversity sampling, but there are more sophisticated variations,
    which we’ll cover in this section. Chapter 4 introduced three types of diversity
    sampling:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多样性采样，我们需要解决本章开头提出的问题：我们更关心对象而非背景的多样性。最简单的解决方案是将图像裁剪到预测的边界框，然后应用多样性采样，但还有更复杂的变体，我们将在本节中介绍。第4章介绍了三种类型的多样性采样：
- en: Model-based outlier sampling
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于模型的异常值采样
- en: Cluster-based sampling
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于聚类的采样
- en: Representative sampling
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代表性采样
- en: Sampling for real-world diversity
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实世界多样性的采样
- en: 'For model-based outliers and real-world diversity, you don’t necessarily need
    to do anything beyond what you’ve already learned for image-level labels:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于模型的异常值和真实世界多样性，你不必做任何超出你已经为图像级标签学习到的事情：
- en: You can apply model-based outlier detection to an object detection problem in
    the same way that you apply it to an image labeling problem.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将基于模型的异常值检测应用于目标检测问题，就像你将其应用于图像标注问题一样。
- en: You can sample for real-world diversity in an object detection problem in the
    same way that you sample for an image labeling problem.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在目标检测问题中为真实世界多样性进行采样，就像你在图像标注问题中进行采样一样。
- en: For model-based outliers, the hidden layers focus on both the labeling and localization
    problems, so your neurons will be capturing information primarily about the objects
    and labels. You can crop the images to the predicted objects and then look for
    model-based outliers, but the small amount of neurons dedicated to the background
    might be interesting for diversity, so you could lose something in this case.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于模型的异常值，隐藏层同时关注标注和定位问题，因此你的神经元主要捕捉关于对象和标签的信息。你可以将图像裁剪到预测的对象，然后寻找基于模型的异常值，但专门用于背景的少量神经元可能对多样性很有趣，因此在这种情况下你可能会失去一些东西。
- en: For diversity sampling, the principles from chapter 4 also apply. You need to
    combine all the active learning methods to ensure fair data across real-world
    demographics. The background can matter in this case too, because you can erroneously
    model the context of objects rather than the objects themselves if you are not
    careful. (See the following sidebar.) For object detection, you may want to ensure
    that your data tries to balance each type of object across factors including the
    type of camera, zoom, time of day, and weather. Even for highly controlled settings,
    such as medical imaging, I’ve seen systems limited by training on data from only
    a small number of patients and only one type of imaging machine, introducing unwanted
    real-world bias.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多样性采样，第4章中的原则也适用。你需要结合所有主动学习方法，以确保跨真实世界人口统计数据的数据公平性。在这种情况下，背景也很重要，因为如果你不小心，你可能会错误地建模对象的上下文而不是对象本身。（参见以下侧边栏。）对于目标检测，你可能希望确保你的数据试图平衡包括相机类型、缩放、一天中的时间和天气在内的各种类型的对象。即使是高度控制的设置，例如医学成像，我也看到系统仅限于从少量患者和仅一种成像设备的数据中进行训练，从而引入了不受欢迎的真实世界偏差。
- en: Is your model really ignoring the background?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你的模型真的忽略了背景吗？
- en: This book assumes that your model focuses on the objects and not the background.
    Sometimes, however, your model might be using background information erroneously.
    If you took photographs of bicycles only in bicycle lanes, for example, your model
    might be predicting bicycle lanes and be essentially blind to bicycles in other
    contexts. Or it might rely on bicycle lanes only when the lanes are present, which
    is still non-ideal, as the model is not generalizing its knowledge of bikes in
    those contexts to other backgrounds.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假设你的模型专注于对象而不是背景。然而，有时你的模型可能会错误地使用背景信息。例如，如果你只拍摄了自行车道上的自行车照片，你的模型可能会预测自行车道，而对其他环境中的自行车视而不见。或者，它可能只在车道存在时依赖自行车道，这仍然不是理想的，因为模型没有将这些环境中对自行车的知识推广到其他背景。
- en: An influential recent paper on model interpretability presents another example.
    The authors created what looked like an accurate model for distinguishing wolves
    from huskies,[¹](#pgfId-1016322) but used only photos of wolves in snow and huskies
    not in snow. They showed that the model was predicting whether snow was in the
    background, not the actual animals! This problem is a bigger one with image-level
    labeling, because with object detection, you are also explicitly forcing the model
    to learn the outline of the object itself, making it hard for your model to focus
    on the background. But the problem can occur to some degree in any machine learning
    problem in which context needs to be controlled for.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一篇关于模型可解释性的有影响力的近期论文提出了另一个例子。作者创建了一个看似准确的模型，用于区分狼和哈士奇[¹](#pgfId-1016322)，但只使用了雪中的狼和不在雪中的哈士奇的照片。他们展示了该模型预测的是背景中是否有雪，而不是实际的动物！这个问题在图像级标签中更为严重，因为在目标检测中，你也在明确地迫使模型学习对象本身的轮廓，这使得模型难以专注于背景。但这个问题在任何需要控制上下文的机器学习问题中都可能以某种程度发生。
- en: 'The solution is better sampling for real-world diversity, ensuring that the
    contexts are as diverse as possible across all the labels and objects that you
    care about. If you are worried about this problem with your model, here is how
    to diagnose it: use a method to find out which pixels are important features for
    your predictions (such as LIME, the method in the huskies/wolves paper, or the
    Captum interpretability library, which is in PyTorch as of October 2019) and then
    measure what percentage of the pixels fall outside the bounding boxes on your
    validation data. The images with the highest scores are the most likely to be
    problematic. Look at these images to identify any patterns in what the model is
    focusing on outside your bounding boxes.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是更好地采样以实现现实世界的多样性，确保所有你关心的标签和对象之间的上下文尽可能多样化。如果你担心你的模型存在这个问题，以下是诊断方法：使用一种方法找出哪些像素对于你的预测是重要特征（例如LIME，哈士奇/狼论文中的方法，或者截至2019年10月的PyTorch中的Captum可解释性库），然后测量有多少像素落在你的验证数据上的边界框之外。得分最高的图像最有可能存在问题。查看这些图像以识别模型在边界框之外关注的任何模式。
- en: '![](../Images/CH06_F04_Munro.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F04_Munro.png)'
- en: Figure 6.4 An example of an object—a bicycle—in an image in which 99% of the
    image is not the bicycle. The bicycle and immediate context captured by the dotted
    line should be enough for identifying that the object is a bicycle. With some
    strategies, such as representative sampling and clustering, we need to crop or
    mask the image to target these areas.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 图像中一个对象——自行车的例子，其中99%的图像不是自行车。用虚线捕获的自行车及其直接上下文应该足以识别该对象是自行车。使用一些策略，如代表性采样和聚类，我们需要裁剪或遮罩图像以针对这些区域。
- en: For cluster-based sampling and representative sampling, the focus should be
    on the objects themselves, not the backgrounds. If your background makes up 90%
    of your images, such as the example in figure 6.1 (repeated in figure 6.4), it
    will make up 90% of the influence on what determines a cluster or is representative.
    Figure 6.1 also contains a relatively large object that takes up half of the height
    of the frame. But in many cases, the example is more like the second image in
    figure 6.4, in which the object takes up fewer than 1% of the pixels.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于聚类的采样和代表性采样，重点应放在对象本身上，而不是背景上。如果你的背景占图像的90%，例如图6.1中的例子（在图6.4中重复），它将占决定聚类或代表性的90%的影响。图6.1还包含一个相对较大的对象，占据了框架高度的一半。但在许多情况下，例子更像是图6.4中的第二幅图像，其中对象只占像素的不到1%。
- en: In figure 6.4, the bicycle itself and immediate context are enough to identify
    the object as a bicycle. Some information outside the box probably can help determine
    the scale and context in which bicycles appear more often, but not much.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在图6.4中，自行车本身及其直接上下文足以识别该对象为自行车。一些框外的信息可能有助于确定自行车出现的规模和上下文，但这并不重要。
- en: 'Therefore, the area around each predicted object should be cropped. Because
    your model isn’t 100% accurate, you need to ensure that you are capturing the
    object. Use your method from uncertainty sampling (ensembles or dropout) to make
    multiple predictions. Then do either of the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每个预测对象的周围区域应该被裁剪。因为你的模型并不完全准确，你需要确保你捕捉到了对象。使用你的不确定性采样方法（集成或dropout）进行多次预测。然后执行以下操作之一：
- en: '*Crop at a given threshold.* You might create the smallest cropping that captures
    90% of the predicted bounding boxes for an object, for example.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在给定的阈值处裁剪。* 例如，你可能创建一个最小的裁剪，以捕捉到对象预测边界框的90%。'
- en: '*Use every predicted box for the same object, and weight the boxes.* You might
    apply rep-resentative sampling to every predicted box and then average across
    all the representative sampling in which the weighted average is determined by
    the average IoU of each box to all others.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用同一对象的每个预测框，并对框进行加权。* 你可能对每个预测框应用代表性采样，然后对所有代表性采样进行平均，其中加权平均由每个框与其他所有框的平均IoU确定。'
- en: As an alternative to cropping the image, you can ignore the pixels outside your
    contextual box—a process called *masking*. You can think of a mask for a model
    trained on pixel inputs as being a dropout on the first layer because you are
    ignoring some input neurons (pixels).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 作为裁剪图像的替代方案，你可以忽略上下文框外的像素——这个过程称为*掩码*。你可以将针对像素输入训练的模型的掩码视为第一层的dropout，因为你正在忽略一些输入神经元（像素）。
- en: How important is context?
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文有多重要？
- en: 'There are a few exceptions in computer vision in which the context *is* important.
    I’ve encountered only one of these exceptions on multiple occasions: identifying
    empty supermarket shelves to help restocking. An empty space (the object) also
    needed context such as adjacent items and a price tag beneath the empty shelf.
    Otherwise, it wasn’t clear to the model whether the shelf was meant to be empty
    or whether there were meant to be products on the shelf.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉中存在一些例外情况，其中上下文*确实*很重要。我在多次场合中只遇到过这些例外情况之一：识别空超市货架以帮助补货。一个空的空间（对象）也需要上下文，例如相邻的物品和空货架下的价格标签。否则，模型无法确定货架是故意留空的，还是应该有产品放在货架上。
- en: Unless you have a use case like this one, essentially labeling a hole according
    to context, keep the boxes as tight as possible for clustering and representative
    sampling. You can capture broader diversity in contexts by using some diversity
    sampling for entire images.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你有这样的用例，即根据上下文基本标记一个孔，否则请尽可能保持框紧，以便进行聚类和代表性采样。通过使用整个图像的一些多样性采样，你可以捕捉到更广泛的环境多样性。
- en: 'Depending on your use case, you also want to resize the images. If you’ve worked
    in computer vision, you already have your tools of choice for resizing programmatically.
    It’s probably not important that our bicycle is at the bottom of the photo, for
    example, so you can normalize your data by cropping each prediction to be the
    entire image and then normalize further by scaling all your sample images to be
    the same dimensions. As a general rule, make the crop/mask decision based on how
    you want to encode data for clustering and representative sampling:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的使用案例，你可能还需要调整图像的大小。如果你在计算机视觉领域工作，你已经有你选择的用于程序化调整大小的工具。例如，我们的自行车在照片底部可能并不重要，因此你可以通过裁剪每个预测以使整个图像为基准来规范化你的数据，然后通过将所有样本图像缩放到相同的尺寸来进一步规范化。作为一个一般规则，根据你想要如何编码数据以进行聚类和代表性采样来做出裁剪/掩码的决定：
- en: If you are using pixels as features or a separate tool to create features, crop
    the images, and consider whether you should also resize them.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在使用像素作为特征或使用单独的工具来创建特征，请裁剪图像，并考虑是否也应该调整它们的大小。
- en: If you are using the hidden layer(s) from the *same* model that you are using
    for object detection, you can mask the images and not move or resize them. Your
    features can capture the similarities in objects at different locations and scales.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你正在使用与用于对象检测的*同一*模型中的隐藏层，你可以对图像进行掩码处理，而不移动或调整它们的大小。你的特征可以捕捉到不同位置和尺度上对象的相似性。
- en: Now you have cropped or masked images that you can use for clustering and representative
    sampling! With each cropped or masked object in an image, you can apply clustering
    or representative sampling. You apply cluster-based sampling and representative
    sampling as you learned in chapter 4.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经裁剪或遮罩了图像，可以用于聚类和代表性采样！在图像中的每个裁剪或遮罩对象上，你可以应用聚类或代表性采样。你应用基于聚类的采样和代表性采样，就像你在第4章中学到的那样。
- en: Make sure that you are sampling images with a different number of objects per
    image. If you find that you are sampling only images with a small or large number
    of objects, you are inadvertently introducing bias into your process. In such
    a case, stratify your sampling. You might sample 100 images that have 1 predicted
    object, 100 images that have 2 predicted objects, and so on.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你采样了具有不同图像中对象数量的图像。如果你发现你只采样了具有少量或大量对象的图像，你无意中在你的过程中引入了偏见。在这种情况下，分层你的采样。你可能采样100个具有1个预测对象的图像，100个具有2个预测对象的图像，依此类推。
- en: 6.1.4 Active transfer learning for object detection
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.4 对目标检测的主动迁移学习
- en: You can apply active transfer learning to object detection in the same way that
    you apply it to image-level labels. You can also apply active transfer learning
    for adaptive sampling (ATLAS), adapting within one active learning cycle because
    you can assume that the first objects you sample will be corrected later by human
    labelers, even if you don’t know what those labels are.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将主动迁移学习应用于目标检测，就像你将其应用于图像级标签一样。你还可以将主动迁移学习应用于自适应采样（ATLAS），在单个主动学习周期内进行调整，因为你假设你首先采样的对象将由人工标注员稍后纠正，即使你不知道那些标签是什么。
- en: Regardless of the type of neural architecture you use for object detection,
    you can use the hidden layer(s) as the features for a binary “Correct”/“Incorrect”
    model that you train on validation data. As an interesting extension, instead
    of a binary “Correct”/ “Incorrect” task, you could calculate the IoU of the validation
    data and create a model that predicts the IoU. That is, you can predict a continuous
    value instead of the binary “Correct”/”Incorrect.” This process could be as simple
    as making the final layer a regression task instead of a classification task and
    having that regression task model the IoU of each validation item. This extension
    could involve changing only one or two lines of code from the ATLAS example in
    chapter 5.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用哪种神经网络架构进行目标检测，你都可以使用隐藏层（s）作为你基于验证数据训练的二进制“正确”/“错误”模型的特征。作为一个有趣的扩展，你可以在二进制“正确”/“错误”任务之外，计算验证数据的IoU并创建一个预测IoU的模型。也就是说，你可以预测一个连续值而不是二进制的“正确”/“错误”。这个过程可能只是将最终层改为回归任务而不是分类任务，并让这个回归任务模拟每个验证项的IoU。这个扩展可能只需要从第5章的ATLAS示例中更改一或两行代码。
- en: 6.1.5 Setting a low object detection threshold to avoid perpetuating bias
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.5 设置低目标检测阈值以避免持续偏见
- en: Set your confidence threshold for object detection low, whatever method you
    use. You don’t want to find only objects that are similar to those that already
    exist in your data, which would perpetuate bias toward those types of objects.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用什么方法进行目标检测，都要设置低置信度阈值。你不想只找到与你数据中已经存在的对象相似的对象，这会持续这些类型对象的偏见。
- en: You may find that a low threshold produces too many candidates. You might get
    100 predicted images at 50% or greater confidence but 10,000 at 10% confidence,
    and most of those 10,000 predictions are the background (false positives that
    are not objects). So you might be tempted to raise the threshold in this case.
    Don’t.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会发现低阈值产生了过多的候选对象。你可能会在50%或更高的置信度下得到100个预测图像，但在10%的置信度下得到10,000个，其中大多数是背景（不是对象的假阳性）。所以你可能会想在这个情况下提高阈值。不要这么做。
- en: 'Unless you are confident that you have set the threshold correctly to get near-perfect
    recall in your predictions, you’re still in danger of perpetuating bias in your
    models. Instead, stratify by confidence and sample from within each:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 除非你确信你已经正确设置了阈值以在预测中获得接近完美的召回率，否则你仍然有可能在你的模型中持续偏见。相反，按置信度分层，并从每个分层中采样：
- en: Sample 100 predicted images at 10–20% confidence.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在10-20%的置信度下采样100个预测图像。
- en: Sample 100 predicted images at 20–30% confidence.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在20-30%的置信度下采样100个预测图像。
- en: Sample 100 predicted images at 30–40% confidence, and so on.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在30-40%的置信度下采样100个预测图像，依此类推。
- en: Figure 6.5 shows an example of the general strategy for stratifying by confidence.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5显示了按置信度分层的通用策略示例。
- en: '![](../Images/CH06_F05_Munro.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F05_Munro.png)'
- en: 'Figure 6.5 Stratifying by confidence: sampling an equal number of items at
    0–10% confidence, 10–20% confidence, and so on up to 90–100% confidence. In this
    example, one item is sampled from each 10% confidence interval for label A. Stratifying
    by confidence helps most when you have a large number imbalance between labels.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5按置信度分层：在0-10%、10-20%置信度等，一直分层到90-100%置信度，抽取等数量的项目。在这个例子中，从标签A的每个10%置信度区间中抽取一个项目。当标签之间存在较大的不平衡时，按置信度分层非常有帮助。
- en: As figure 6.5 shows, you can sample the same number of items at different confidence
    intervals. This strategy is helpful for a task such as object detection because
    most of your images will not contain objects that you care about. Using a sample
    strategy that is stratified by confidence, you’ll be spending most of your time
    sampling high-confidence objects and still have a selection of lower-confidence
    ones. Note that although it feels like a waste of time to identify non-objects,
    that’s not the case for your machine learning algorithm. Learning what is not
    an object but is currently predicted as an object with nontrivial confidence can
    be as important for your model’s accuracy as learning new objects.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如图6.5所示，您可以在不同的置信度区间抽取相同数量的项目。这种策略对于像对象检测这样的任务很有帮助，因为您的许多图像可能不包含您关心的对象。使用按置信度分层的抽样策略，您将花费大部分时间抽样高置信度对象，同时仍有一些低置信度对象的选择。请注意，尽管识别非对象似乎浪费时间，但这对于您的机器学习算法来说并非如此。学习不是对象但当前以非平凡置信度预测为对象的识别，对于您的模型精度的重要性与学习新对象一样重要。
- en: 'This kind of stratification is important for avoiding bias in your data. You
    can also try combinations of methods as alternatives to random sampling within
    each confidence:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分层对于避免数据中的偏差非常重要。您也可以尝试在每种置信度内随机抽样的方法组合作为替代。
- en: Take the 10,000 objects with 10–20% confidence, apply clustering, and sample
    the centroids to get the 100 most diverse objects within that sample.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从具有10-20%置信度的10,000个对象中选取，应用聚类，并从样本中抽取质心来获取其中最多样化的100个对象。
- en: Take the 10,000 objects with 10–20% confidence and apply representative sampling
    to get the 100 objects most like your target domain.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从具有10-20%置信度的10,000个对象中选取，并应用代表性抽样以获取与您的目标领域最相似的100个对象。
- en: Take the 10,000 objects with 10–20% confidence and sample for model-based outliers
    to get the 100 objects most unlike the current training data.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从具有10-20%置信度的10,000个对象中选取，并对基于模型的异常值进行抽样，以获取与当前训练数据最不相似的100个对象。
- en: Note that you can apply this method for stratifying by confidence to any type
    of task, not only object detection.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，您可以将这种方法应用于按置信度分层的任何类型任务，而不仅仅是对象检测。
- en: 6.1.6 Creating training data samples for representative sampling that are similar
    to your predictions
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.6 创建与您的预测相似的代表性抽样训练数据样本
- en: 'Because you are cropping or masking your unlabeled images, you should do the
    same thing with training data if you are implementing representative sampling.
    If you use only the perfect bounding boxes from your training data but then the
    imperfect predictions from your unlabeled data, the “representative” samples could
    end up being the result of different box sizes and cropping strategies instead
    of the actual objects. Here are four options, in order of preference:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您正在裁剪或遮罩您的未标记图像，如果您正在实施代表性抽样，您应该对训练数据执行相同操作。如果您只使用训练数据中的完美边界框，但随后使用未标记数据的不可预测的预测，那么“代表性”样本可能会变成不同框大小和裁剪策略的结果，而不是实际的对象。以下有四种选项，按优先顺序排列：
- en: Cross-validate your training data. You might split your training data into 10
    equal datasets. Iteratively train on each group of nine, and predict bounding
    boxes on each held out dataset. Combine all the predictions, and use the combination
    as the training data portion of your corpus for representative sampling.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对训练数据进行交叉验证。您可能将训练数据分成10个相等的数据集。迭代地对每组九个数据集进行训练，并在每个保留的数据集上进行边界框预测。将所有预测组合起来，并将组合作为代表性抽样语料库的训练数据部分。
- en: Use a validation dataset from the same distribution as your training data, get
    bounding-box predictions over the validation set, and use those validation bounding
    boxes as the training data portion of your corpus for representative sampling.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用与您的训练数据具有相同分布的验证数据集，对验证集进行边界框预测，并将这些验证边界框作为您语料库中代表性抽样的训练数据部分。
- en: Predict on the training data and then randomly expand or contract the boxes
    so that they have the same average variation in your predictions.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练数据上预测，然后随机扩展或收缩框，使它们具有相同的平均预测变化。
- en: Use your actual boxes from the training data and then randomly expand or contract
    the boxes so that they have the same average variation in your predictions.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用你的训练数据中的实际框，然后随机扩展或收缩框，使它们具有相同的平均预测变化。
- en: Options 1 and 2 are statistically equally good. If you’ve got a held-out validation
    set, the process is a little easier than retraining your entire model, but it
    won’t be the exact data in your training set even though it is as close as possible.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 选项1和2在统计上同样好。如果你有一个保留的验证集，这个过程比重新训练整个模型要简单一些，但它不会是训练集中确切的数据，尽管它尽可能接近。
- en: For options 3 and 4, although you can increase the sizes of the bounding boxes
    so that the average is the same, you won’t be able to match the kind of errors
    that you get in predictions. The predicted bounding-box errors will not be randomly
    distributed; they will depend on the image itself in ways that are hard to duplicate
    when you create artificial noise.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 对于选项3和4，虽然你可以增加边界框的大小，使平均值为相同，但你无法匹配预测中出现的错误类型。预测的边界框错误不会随机分布；它们将取决于图像本身，这在创建人工噪声时很难复制。
- en: 6.1.7 Sampling for image-level diversity in object detection
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.7 对象检测中图像级多样性的采样
- en: As with any other method, you should always randomly sample some images for
    review. This sample provides your evaluation data and gives you a baseline for
    how successful your active learning strategy is.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何其他方法一样，你应该始终随机采样一些图像进行审查。这个样本提供了你的评估数据，并为你提供了一个基准，以衡量你的主动学习策略的成功程度。
- en: For a small amount of samples, you can use image-level sampling, which helps
    diversity in a way that prevents bias more easily than the other methods introduced
    in this section. If you apply clustering at the whole-image level and find whole
    clusters with few or no existing training items, you have good evidence that you
    should get human review for some items in those clusters, because you could be
    missing something.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 对于少量样本，你可以使用图像级采样，这有助于多样性，并且比本节中介绍的其他方法更容易防止偏差。如果你在整张图像级别应用聚类，并发现包含少量或没有现有训练样本的整个簇，那么你有很好的证据表明，你应该对这些簇中的某些项目进行人工审查，因为你可能遗漏了一些东西。
- en: If you are introducing new kinds of data to your model (maybe you are using
    a new camera or collecting from a new location), representative sampling at the
    image level should help you adapt faster. This strategy also helps you adapt with
    less bias than trying to implement only object-level active learning when you
    try to incorporate new data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你向模型引入新的数据类型（也许你正在使用新的相机或从新的位置收集数据），图像级别的代表性采样可以帮助你更快地适应。这种策略也有助于你在尝试结合新数据时，比仅尝试实现对象级主动学习时具有更少的偏差。
- en: If you try object-level methods on different types of data, it will be hard
    to avoid biasing toward objects you have already seen, as some of those objects
    might still slip below the threshold you use. Confidence thresholds tend to be
    least reliable for out-of-domain data.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试在不同类型的数据上使用对象级方法，很难避免偏向于你已经看到的对象，因为其中一些对象可能仍然低于你使用的阈值。置信度阈值通常对域外数据最不可靠。
- en: 6.1.8 Considering tighter masks when using polygons
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1.8 使用多边形时考虑更紧密的掩码
- en: 'If you are using polygons rather than bounding boxes, as shown in figure 6.6,
    all the methods still apply. You have one additional option: instead of masking
    outside the bounding box, you can mask at a certain distance from the nearest
    polygon edge. In our bicycle example, this approach more closely captures the
    bicycle itself and not so much of the empty space.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用的是图6.6中所示的多边形而不是边界框，所有的方法仍然适用。你有一个额外的选项：你可以在边界框外部而不是在最近的边缘一定距离处进行掩码。在我们的自行车示例中，这种方法更接近捕捉自行车本身，而不是那么多的空地。
- en: '![](../Images/CH06_F06_Munro.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F06_Munro.png)'
- en: Figure 6.6 An example of object detection using a polygon rather than a bounding
    box. You can use the same active learning methods for both bounding boxes and
    polygons, with the extra option to have a closer mask for a polygon.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 使用多边形而不是边界框进行目标检测的示例。你可以为边界框和多边形使用相同的主动学习方法，并且对于多边形还有一个额外的选项：可以在多边形最近边缘的一定距离处进行掩码。
- en: For the same reason, error detection can be more accurate, especially for irregularly
    shaped objects. You can imagine that a bicycle like the one in figure 6.6 could
    have a handlebar sticking out in many photos. The bounding-box extension to capture
    only that handlebar could easily be almost half the box’s area, creating a lot
    of room for error over pixels that aren’t part of the object. The next level of
    complexity in image recognition, after bounding boxes and polygons, is semantic
    segmentation.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 由于同样的原因，错误检测可以更加精确，尤其是对于形状不规则的物体。你可以想象，像图6.6中的自行车，在许多照片中可能会有把手伸出。仅为了捕捉那个把手而扩展的边界框可能会轻易地占据盒子面积的一半，这为像素错误提供了很大的空间，而这些像素并不属于物体本身。在图像识别中，在边界框和多边形之后，下一个复杂度级别是语义分割。
- en: 6.2 Applying active learning to semantic segmentation
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 将主动学习应用于语义分割
- en: '*Semantic **segmentation* occurs when the entire image receives a label, with
    accurate polygon boundaries around all objects. Because this technique labels
    every pixel in the image, it is also referred to as *pixel labeling*. Figure 6.7
    shows an example.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*语义分割*发生在整个图像都被赋予标签，并且所有物体周围都有准确的多边形边界时。由于这种技术为图像中的每个像素都贴上了标签，因此它也被称为*像素标签*。图6.7展示了这样一个例子。'
- en: '![](../Images/CH06_F07_Munro.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F07_Munro.png)'
- en: 'Figure 6.7 An example of semantic segmentation in which every pixel is labeled.
    This kind of colored photograph is what a lot of semantic segmentation tools look
    like: a coloring-in exercise. We’ll cover those tools later in the book, especially
    in chapter 10\. If you’re looking at this image in black and white, the contrasting
    shades of gray should give you a good idea of what it would look like in color.
    If the objects receive a label (the four trees are labeled separately, for example),
    the task is known as *instance segmentation*.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7展示了语义分割的一个例子，其中每个像素都被标注。这类彩色照片是许多语义分割工具的外观：一种填色练习。我们将在本书的后面部分介绍这些工具，特别是在第10章。如果你以黑白形式查看这张图像，对比的灰色阴影应该能给你一个很好的颜色图像概念。如果物体被赋予标签（例如，四棵树被分别标注），那么这项任务就被称为*实例分割*。
- en: 'If you are trying to estimate objects that extend behind some other object
    (occlusion), it is more common to use the bounding-box-type object detection you
    learned about in section 6.1\. It is also more common to paint all objects as
    a single type with semantic segmentation rather than identify each object separately.
    Every tree in figure 6.7 is the same color, for example, but the image is not
    distinguishing one tree from another. These commonalities are not set in stone,
    however: there are cases in which bounding boxes that ignore occlusion are used,
    semantic segmentation tries to capture occlusion, and semantic segmentation distinguishes
    objects (called *instance segmentation*). If a model combines all these methods,
    it is sometimes known as *panoptic segmentation*, identifying objects and background
    pixels. All the methods in this chapter should be generic enough that they can
    apply to any variation on bounding boxes or semantic segmentation.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你试图估计延伸到其他物体背后（遮挡）的物体，那么更常见的是使用你在6.1节中学到的边界框类型的物体检测。使用语义分割将所有物体涂成单一类型，而不是分别识别每个物体，这种情况也很常见。例如，图6.7中的每棵树都是相同的颜色，但图像并没有区分不同的树。然而，这些共性并不是一成不变的：有些情况下，忽略遮挡的边界框被使用，语义分割试图捕捉遮挡，语义分割区分物体（称为*实例分割*）。如果一个模型结合了所有这些方法，有时它被称为*全景分割*，识别物体和背景像素。本章中的所有方法都应该足够通用，可以应用于边界框或语义分割的任何变化。
- en: 'The methods can apply to other kinds of sensor data, such as the 2D and 3D
    images that from lidar, radar, or sonar, which are all common for autonomous vehicles.
    It is also common to collect data outside the range of human vision in the infrared
    and ultraviolet bands and then shift those results into visible colors for human
    annotation, which is common in agriculture. Search for “infrared forest” or “ultraviolet
    flower” photos, and you’ll see why: a lot of useful information falls outside
    human-viewable range! The principles in this section should still apply if additional
    dimensions and sensor information are involved.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法可以应用于其他类型的传感器数据，例如来自激光雷达、雷达或声纳的2D和3D图像，这些都是自动驾驶汽车中常见的。在农业中，收集红外线和紫外线的图像也很常见，然后将这些结果转换成可见颜色以供人工标注，这也是常见的。搜索“红外森林”或“紫外花卉”照片，你就会明白为什么：很多有用的信息都超出了人类的可视范围！如果涉及到额外的维度和传感器信息，本节中的原则仍然适用。
- en: 6.2.1 Accuracy for semantic segmentation
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 语义分割的准确性
- en: 'Accuracy for semantic segmentation is calculated on a per pixel-level. How
    many of the pixels are classified correctly, relative to a held-out dataset? You
    can use all the accuracy metrics that you have learned so far: precision, recall,
    F-score, AUC, IoU, and micro and macro scores. The right choice for machine learning
    accuracy depends on your use case.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 语义分割的准确性是在每个像素级别上计算的。有多少像素被正确分类，相对于保留的测试集？你可以使用你迄今为止学到的所有准确性指标：精确度、召回率、F分数、AUC、IoU以及微观和宏观分数。机器学习准确性的正确选择取决于你的用例。
- en: 'For determining uncertainty, the macro F-score or macro IoU is often most useful.
    As with our bounding-box examples, we often have a lot of space in semantic segmentation
    that we don’t care about much, such as the sky and background. You can get into
    trouble if you have many discontinuous regions. For instance, figure 6.7 probably
    has more than 100 separate regions of sky between the leaves. By overall size
    and total number, those sky regions would dominate a micro score on a per-pixel
    or per-region basis, and tree-leaf confusion would dominate our uncertainty sampling
    strategies. So assuming that you care about all the labels equally, but not about
    how much of an image that object happens to take up, use a macro score: the average
    IoU of each region per label or the average F-score of each pixel per label.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 对于确定不确定性，宏观F分数或宏观IoU通常最有用。与我们的边界框示例一样，在语义分割中，我们通常有很多我们不关心的空间，例如天空和背景。如果你有很多不连续的区域，你可能会遇到麻烦。例如，图6.7在叶子和天空之间可能有超过100个独立的天空区域。从整体大小和总数来看，这些天空区域将主导基于像素或区域的微观分数，而树叶混淆将主导我们的不确定性采样策略。所以假设你关心所有标签，但不关心该对象在图像中占据多少空间，使用宏观分数：每个标签每个区域的平均IoU或每个标签每个像素的平均F分数。
- en: You might also decide to ignore some labels. Perhaps you care only about people
    and bicycles, so you can choose a macro accuracy value that looks only at those
    labels. You will still get inputs from errors distinguishing people and bicycles
    from the background, the ground, and the sky, but not errors between those irrelevant
    labels. Note that exactly what matters will be specific to your use case. If your
    task is identifying the amount of forest coverage, the regions between leaves
    and the sky will matter most!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可能决定忽略一些标签。也许你只关心人和自行车，因此你可以选择一个宏观准确性值，只查看这些标签。你仍然会从区分人和自行车与背景、地面和天空的错误中获取输入，但不会是那些无关标签之间的错误。请注意，具体是什么重要将取决于你的具体用例。如果你的任务是识别森林覆盖率，那么叶子和天空之间的区域将最为重要！
- en: 'Use your deployed machine learning model accuracy as your guide for calculating
    uncertainty. You should make this calculation in either of two ways, depending
    on whether you weight your labels for your accuracy calculation:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用你部署的机器学习模型准确性作为计算不确定性的指南。你应该根据你为准确性计算加权的标签，以两种方式之一进行此计算：
- en: If you don’t weight your labels (you either 100% care or don’t care if each
    label equals absolute weightings), use the same metric that you use for model
    accuracy to determine where to sample. If you care about confusion for only two
    labels in your model accuracy, sample only predictions with confusion involving
    one or both of those labels for active learning.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你不对你的标签进行加权（你要么100%关心，要么不关心每个标签是否等于绝对权重），使用你用于模型准确性的相同指标来确定采样位置。如果你只关心模型准确性中的两个标签的混淆，则只对涉及一个或两个这些标签的混淆预测进行主动学习采样。
- en: If you have an accuracy metric that is weighted, do *not* use the same metric
    as for model accuracy. Instead, use the stratified sampling methods that you learned
    in chapter 3\. Figure 6.8 shows an example.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你有一个加权的准确性指标，请不要使用与模型准确性相同的指标。相反，使用你在第3章中学到的分层采样方法。图6.8显示了一个示例。
- en: As figure 6.8 shows, stratified sampling by label helps focus your active learning
    strategy on the pixels that matter most. Although you can use stratified sampling
    for any machine learning problem, semantic segmentation is one of the clearest
    examples of where it can help.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如图6.8所示，按标签进行分层采样有助于将你的主动学习策略集中在最重要的像素上。虽然你可以为任何机器学习问题使用分层采样，但语义分割是其中可以提供帮助的最清晰的例子之一。
- en: '![](../Images/CH06_F08_Munro.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F08_Munro.png)'
- en: 'Figure 6.8 An example of stratified sampling by label applied to segmentation.
    For this example task, assume that we care about errors related to human and bicycle
    pixels more than we care about errors related to tree and sky pixels. Our active
    learning sample will consist of a 90:10 split: 90% will be the most confusing
    samples for the labels that we care about most, and 10% will be about the labels
    that we don’t care about. Note that the pixels bordering the sky and trees vastly
    outnumber the pixels bordering humans and bicycles, so stratified sampling helps
    us focus on the errors that we care about most. Therefore, your sampling strategy
    might diverge from your accuracy evaluation strategy, in which you can simply
    apply relative weights of 90% and 10% to high- or low-value errors. The uncertainty
    sampling metrics don’t lend themselves as easily to this kind of weighting, so
    unless you are confident enough in your statistics skills to tune your weighting
    strategy, use this stratification method.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 层次抽样在分割中的应用示例。对于这个示例任务，假设我们更关心与人和自行车像素相关的错误，而不是与树木和天空像素相关的错误。我们的主动学习样本将包括90:10的分割：90%将是我们最关心的标签中最令人困惑的样本，10%将是我们不关心的标签。请注意，天空和树木边缘的像素数量远远超过人和自行车边缘的像素数量，因此层次抽样有助于我们关注我们最关心的错误。因此，你的抽样策略可能与你的准确度评估策略不同，在准确度评估策略中，你可以简单地应用90%和10%的相对权重到高值或低值错误。不确定性抽样指标并不容易进行这种加权，所以除非你对自己的统计技能足够自信以调整你的加权策略，否则使用这种层次抽样方法。
- en: Note that stratified sampling may diverge from your strategy for evaluating
    model accuracy. Suppose that you care about Label A nine times as much as you
    care about Label B. Calculate your model accuracy as 90% × Label A’s F-score +
    10% × Label B’s F-score (a weighted macro F-score). This strategy is fine for
    model accuracy, but unfortunately, you can’t apply weights in a similar way to
    uncertainty scores, because your weighting will almost certainty rank only Label
    A items highest, moving them exclusively to the top of your rankings. Instead,
    use those weights as a ratio of how many to sample. You might sample the 90 most
    uncertain Label A items and the 10 most uncertain Label B items, for example.
    This technique is simpler to implement than trying to create a weighted sampling
    strategy across labels and much more effective. If there are labels that you don’t
    care about, still consider sampling a small number, especially using model-based
    outliers and representative sampling, because they may be false negatives for
    the labels you *do* care about.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，层次抽样可能与你的模型准确度评估策略不同。假设你关心标签A比标签B多九倍。计算你的模型准确度为90% × 标签A的F分数 + 10% × 标签B的F分数（加权宏F分数）。这种策略对于模型准确度来说是可行的，但不幸的是，你不能以类似的方式应用权重到不确定性分数，因为你的加权几乎肯定只会将标签A的项目排在最高位，将它们唯一地置于排名的顶部。相反，使用这些权重作为样本数量的比例。例如，你可能采样90个最不确定的标签A项目和10个最不确定的标签B项目。这种技术比尝试在标签之间创建加权抽样策略简单得多，而且效果更佳。如果你不关心某些标签，仍然可以考虑采样少量样本，特别是使用基于模型的异常值和代表性抽样，因为它们可能是你关心的标签的假阴性。
- en: 6.2.2 Uncertainty sampling for semantic segmentation
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 语义分割的不确定性抽样
- en: Most semantic segmentation algorithms are built on variations of CNNs, using
    softmax to generate a probability distribution across the possible labels for
    every pixel. So you can calculate the uncertainty on a per-pixel basis, using
    the methods you learned in chapter 3\. Your model is unlikely to make a prediction
    for every pixel, which would be inefficient, but instead predict regions and select
    only small (maybe pixel-sized) regions when forced. Know exactly where your predicted
    confidences are coming from.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数语义分割算法都是基于CNN的变体，使用softmax在可能的每个像素的标签上生成概率分布。因此，你可以使用你在第3章学到的方 法，按每个像素计算不确定性。你的模型不太可能对每个像素进行预测，这将是不高效的，而是预测区域，并在被迫时仅选择小的（可能是像素大小的）区域。确切地知道你的预测置信度来自哪里。
- en: 'As with bounding boxes, the confidence you get from your models probably reflects
    your label confidence, not the confidence on the borders of your objects. If so,
    you can derive the localization confidence from the pixel confidences: you know
    which pixels are next to pixels from a different label, so the aggregate confidence
    from all boundary pixels is the localization confidence. You may be OK with errors
    of a few pixels; if so, use this margin of error to determine where you calculate
    confidence. If you are measuring the accuracy of your machine learning model by
    forgiving all errors of less than 3 pixels, for example, do the same for uncertainty,
    measuring the average uncertainty of the pixels that are 3 pixels away from a
    border.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 与边界框一样，从你的模型中得到的置信度可能反映了你的标签置信度，而不是你对象边界的置信度。如果是这样，你可以从像素置信度中推导出定位置信度：你知道哪些像素是相邻不同标签的像素，因此所有边界像素的聚合置信度就是定位置信度。你可能对几个像素的误差可以接受；如果是这样，使用这个误差范围来确定你计算置信度的位置。例如，如果你通过原谅所有小于3像素的错误来衡量你的机器学习模型的准确性，那么对不确定性也做同样的事情，测量距离边界3像素的像素的平均不确定性。
- en: For some reason, you may be using a model that does not give a probability distribution
    for a given label. In that case, you can use ensemble methods and/or dropouts
    to create multiple predictions and calculate uncertainty as the amount of label
    agreement across your predictions.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 由于某种原因，你可能正在使用一个不提供给定标签概率分布的模型。在这种情况下，你可以使用集成方法和/或dropout来创建多个预测，并将不确定性计算为预测中标签一致性的数量。
- en: Now that you are sampling only the pixels that you care about and have an uncertainty
    score for each pixel, you can apply any of the uncertainty sampling algorithms.
    The simplest way to calculate uncertainty for the entire image is to take the
    average uncertainty from each of the pixels you care about. If you care mainly
    about the borders, you can sample the items only within a few pixels of another
    label.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你只采样你关心的像素，并且每个像素都有一个不确定性分数，你可以应用任何不确定性采样算法。计算整个图像的不确定性的最简单方法是从你关心的每个像素中取平均值。如果你主要关心边界，你可以在其他标签的几个像素内采样项目。
- en: Depending on your task, you can try metrics other than average if (for example)
    you want to give the image an uncertainty score that is the maximum uncertainty
    for any one region. Your ability to focus only on regions within the images will
    partially depend on your annotation setup. Will someone need to annotate the entire
    image, or can they annotate only the labels you care about? These considerations
    are addressed from the annotation point of view in chapter 9.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的任务，如果你（例如）想给图像一个不确定性分数，这个分数是任何单个区域的最高不确定性，你可以尝试除了平均值以外的其他指标。你只关注图像内区域的能力部分取决于你的注释设置。是否需要注释整个图像，或者他们是否只能注释你关心的标签？这些问题在第九章从注释的角度进行了讨论。
- en: 6.2.3 Diversity sampling for semantic segmentation
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.3 语义分割的多样性采样
- en: You cannot sample for model-based outliers straight from your model for diversity
    sampling, as you can for object recognition. This approach works with object recognition
    because you are already forcing the model to focus on the areas that you care
    about, but a semantic segmentation algorithm is forced to classify every pixel.
    So you should mask or crop the images to contain only the predicted labels you
    care about, as outlined in section 6.1, and then apply model-based outliers.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型基于异常值采样不能直接从你的模型中采样，就像在对象识别中那样，因此这种方法适用于对象识别，因为你是迫使模型关注你关心的区域，但语义分割算法必须对每个像素进行分类。因此，你应该遮罩或裁剪图像，只包含你关心的预测标签，如第6.1节所述，然后应用基于模型的异常值。
- en: 'The same is true for clustering and representative sampling: crop or mask the
    image to the areas you care about and then apply clustering and/or representative
    sampling. For real-world diversity, the strategy is the same as for bounding boxes:
    use all the techniques that you know in active learning to sample for diversity
    across and within the demographics that you care about. See section 6.1 on object
    detection for more about these methods.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于聚类和代表性采样也是同样的道理：裁剪或遮罩图像到你关心的区域，然后应用聚类和/或代表性采样。对于现实世界的多样性，策略与边界框相同：使用你在主动学习中所知道的所有技术，以采样你关心的跨和内部人口统计数据的多样性。关于这些方法，请参阅第6.1节关于目标检测的更多内容。
- en: 6.2.4 Active transfer learning for semantic segmentation
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.4 语义分割的主动迁移学习
- en: 'You can apply active transfer learning to semantic segmentation in the same
    way that you applied it to image-level labels, but you should use the adaptive
    method: ATLAS. If you don’t use the adaptive version of this algorithm, you could
    sample confusion exclusively in the areas that you don’t care about, such as the
    division between leaves and the sky when you care mainly about objects on the
    ground. Note that ATLAS won’t completely solve this problem; it might initially
    sample types of confusion that you don’t care about. But it will adapt quickly
    to assume that those types of confusion are solved and therefore also cover the
    areas that you care about. If you think about how many pairwise sets of labels
    exist in your data and what percentage of those pairs you actually care about,
    you will have some idea of how successful ATLAS will be out-of-the-box.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将主动迁移学习应用于语义分割，就像你应用于图像级标签一样，但你应该使用自适应方法：ATLAS。如果你不使用此算法的自适应版本，你可能会仅在你不关心的区域采样混淆，例如当你主要关心地面上的物体时，叶子和天空之间的划分。请注意，ATLAS不会完全解决这个问题；它可能会最初采样你不关心的混淆类型。但它会快速适应，假设这些类型的混淆已解决，因此也会覆盖你关心的区域。如果你考虑你的数据中存在多少成对的标签集以及你实际上关心这些对中的百分比，你将会有一些关于ATLAS即插即用成功率的想法。
- en: To get the most out of ATLAS for semantic segmentation, you can be strategic
    about how you set up your validation data for transfer learning. If you don’t
    care about errors between leaves and the sky, for example, you can ignore those
    errors when you run the validation data through the original model to generate
    your “Correct”/ “Incorrect” labels. That way, your model is now predicting errors
    for only the types of labels you care about.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要充分利用ATLAS进行语义分割，你可以策略性地设置你的验证数据以用于迁移学习。例如，如果你不关心叶子和天空之间的错误，你可以在运行验证数据通过原始模型以生成你的“正确”/“错误”标签时忽略这些错误。这样，你的模型现在只预测你关心的标签类型的错误。
- en: 6.2.5 Sampling for image-level diversity in semantic segmentation
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.5 语义分割中图像级多样性的采样
- en: As with object detection, you may want to sample a small number of items from
    the whole image (especially if you are introducing data from new locations, camera
    types, and so on) so that you can adapt quickly and find false negatives for the
    labels that you care about. You could also experiment with loosening the restriction
    to crop or mask if you are combining methods. You could use representative sampling
    on the entire image to find images most representative of a new domain or type
    of image and then sample for the most representative images, apply the mask/crop
    to those samples, and cluster those samples for diversity. This technique gives
    you the most diverse selection of items you care about from whole images that
    are representative of the domain you care about.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 与目标检测一样，你可能想从整个图像中采样少量项目（特别是如果你正在引入来自新位置、相机类型等的数据），这样你可以快速适应并找到你关心的标签的假阴性。如果你在结合方法时，你也可以尝试放宽裁剪或遮罩的限制。你可以对整个图像进行代表性采样，以找到最具代表性的新领域或图像类型的图像，然后对最具代表性的图像进行采样，对这些样本应用遮罩/裁剪，并对这些样本进行聚类以实现多样性。这种技术为你提供了从整个图像中关于你关心的领域最具代表性的项目最多样化的选择。
- en: 6.3 Applying active learning to sequence labeling
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 将主动学习应用于序列标注
- en: '*Sequence* *labeling *is machine learning applied to labeling spans within
    a sequence and is one of the most common tasks in NLP. Suppose that you have this
    sentence (sequence):'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '*序列* *标注*是将机器学习应用于序列内的标注，是NLP中最常见的任务之一。假设你有这个句子（序列）：'
- en: '*“The E-Coli outbreak was first seen in a San Francisco supermarket"*'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '*“首次在旧金山的超市发现大肠杆菌疫情”*'
- en: If you are implementing a model to track outbreaks from text reports, you may
    want to extract information from the sentence, such as the name of the disease,
    any locations in the data, and the important keywords, as shown in table 6.1.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在实现一个从文本报告中追踪疫情爆发的模型，你可能想从句子中提取信息，例如疾病的名称、数据中的任何位置以及重要的关键词，如表6.1所示。
- en: 'Table 6.1 An example sequence labels: keyword detection and two types of named
    entities, diseases, and locations. Label B (beginning) is applied to the beginning
    of the span, and Label I (inside) is applied to the other words within the span,
    allowing us to unambiguously distinguish spans that are next to each other, such
    as “San Francisco” and “supermarket”. This process is called IOB *tagging*, in
    which O (outside) is the nonlabel. (O is omitted from this table for readability.)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.1 一个示例序列标签：关键词检测和两种类型的命名实体，疾病和地点。标签B（开始）应用于跨度的开始，标签I（内部）应用于跨度内的其他单词，使我们能够明确地区分相邻的跨度，例如“旧金山”和“超市”。这个过程被称为IOB
    *标记*，其中O（外部）是非标签。（O从表中省略以增强可读性。）
- en: '![](../Images/06_T1.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/06_T1.png)'
- en: In the literature, you most commonly see IOB tagging for spans, as in table
    6.1\. Notice that you might define spans in different ways for different types
    of labels. The named entity “E-Coli” is one word, but when we extract the keywords,
    it’s the phrase “E-Coli outbreak.” And although “San Francisco” is both an entity
    (location) and a keyword, the common noun “supermarket” is a keyword but not an
    entity. Strictly, this process is called *IOB2 tagging*, and IOB uses the B only
    when there are multiple tokens in a single span. IOB2 is the most common approach
    that you’ll encounter in the literature, sometimes called IOB for short.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在文献中，你最常见的标签是用于跨度的IOB标记，如表6.1所示。请注意，你可能需要根据不同类型的标签以不同的方式定义跨度。名为“大肠杆菌”的命名实体是一个单词，但当我们提取关键词时，它变成了短语“大肠杆菌爆发”。尽管“旧金山”既是实体（地点）也是关键词，但普通名词“超市”是关键词但不是实体。严格来说，这个过程被称为*IOB2标记*，其中IOB只在单个跨度中有多个标记时使用B。IOB2是你在文献中最常见的处理方法，有时简称为IOB。
- en: Other encodings mark the end of the span rather than the start. This type of
    encoding is common for whole-sentence segmentation tasks, such as tagging the
    end of every word and subword span and tagging the end of every sentence. For
    sentences, the end is tagged because it’s a little easier to identify the end
    of a sentence (typically with punctuation) than the start. The methods in this
    chapter work for any type of sequence encoding, so the chapter will stick with
    the IOB2 examples and assume that it is easily adapted if your encoding system
    is different.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 其他编码方式标记跨度的结束而不是开始。这种编码方式在整句分割任务中很常见，例如标记每个单词和子词跨度的结束以及每个句子的结束。对于句子，标记结束是因为识别句子结束（通常用标点符号）比识别开始要容易一些。本章中的方法适用于任何类型的序列编码，因此本章将坚持使用IOB2示例，并假设如果您的编码系统不同，它很容易适应。
- en: 'You might also treat some labels as being naturally part of the same task.
    I have worked a lot in named entity recognition (NER), which considers identifying
    “Location” and “Disease” as part of the same task, but treats keyword identification
    as a different task. Even within one task, there can be a lot of variation in
    how labels are defined. Some popular NER datasets have only four types of entities:
    “People,” “Locations,” “Organizations,” and “Miscellaneous.” By contrast, I once
    helped build an entity recognition system for a car company that had thousands
    of entity types; every kind of engine, door, and even headrest had multiple types
    and names.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可能将一些标签视为同一任务的天然组成部分。我在命名实体识别（NER）方面做了很多工作，它将识别“地点”和“疾病”视为同一任务的一部分，但将关键词识别视为不同的任务。即使在同一任务中，标签的定义也可能有很大的变化。一些流行的NER数据集只有四种实体类型：“人物”、“地点”、“组织”和“杂项”。相比之下，我曾经帮助一家汽车公司构建了一个拥有数千种实体类型的实体识别系统；每种类型的引擎、车门甚至头枕都有多种类型和名称。
- en: Although you might perform a large variety of sequence labeling tasks in NLP,
    all of them come down to identifying spans of text in a sequence. These kinds
    of sequence labeling tasks are called *information extraction* in the literature
    and are often the building blocks for more complicated multifield information
    extraction tasks. If you have a sentence with one disease and multiple locations,
    you would also determine the locations at which the disease was detected, if any.
    In this chapter, we will stick to the example of identifying individual spans
    and assume that you can extend them to more complicated information extraction
    tasks.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可能在NLP中执行各种序列标注任务，但它们都归结为在序列中识别文本跨度。这类序列标注任务在文献中被称为*信息提取*，通常是更复杂的多字段信息提取任务的构建块。如果你有一个包含一个疾病和多个位置的句子，你也会确定疾病被检测到的位置，如果有的话。在本章中，我们将坚持识别单个跨度的示例，并假设你可以将它们扩展到更复杂的信息提取任务。
- en: 6.3.1 Accuracy for sequence labeling
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.1 序列标注的准确性
- en: The accuracy metric for sequence labeling depends on the task. For named entities,
    it is typically F-score on the entire span. So predicting “San Francisco” as a
    location would count 100% toward accuracy, but predicting “Francisco” or “San
    Francisco supermarket” would count 0% toward accuracy.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 序列标注的准确性指标取决于任务。对于命名实体，通常是整个跨度的F分数。因此，将“旧金山”预测为位置将占准确性的100%，但将“Francisco”或“旧金山超市”预测为位置将占准确性的0%。
- en: In some cases, this strict form of accuracy may be relaxed or reported along
    with more forgiving metrics, such as per-word accuracy (called *per-token* because
    not all tokens are exact words). In other cases, the accuracy might be reported
    for entity versus nonentity, with the type of entity (such as Disease or Location)
    reported separately.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，这种严格的准确性可能被放宽，或者与更宽容的指标（如每词准确性，称为*per-token*，因为并非所有标记都是精确的单词）一起报告。在其他情况下，准确性可能针对实体与非实体进行报告，实体的类型（如疾病或位置）将单独报告。
- en: You will most likely not care about the “O” label for your sequence tasks. F-score
    will capture the confusion between other labels and “O,” which might be enough.
    As in object detection and semantic segmentation, you care about some parts of
    each data item more than others. Focusing on these parts of the data for active
    learning will lead to better samples.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不会关心序列任务中的“O”标签。F分数将捕捉其他标签与“O”之间的混淆，这可能已经足够。就像在目标检测和语义分割中，你更关心每个数据项的某些部分而不是其他部分。专注于这些数据部分进行主动学习将导致更好的样本。
- en: As with the computer vision examples, you should use a metric for active learning
    sampling that is consistent with how you are measuring accuracy for your NLP model.
    For many NLP tasks, the context is more important than for object detection. You
    know that “San Francisco” is a location and not an organization with “San Francisco”
    in the name because of the context of the full sentence. So it is safer to have
    a broader context around the predicted sequences and often desirable, as the context
    can be an important predictor.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在计算机视觉示例中一样，你应该使用与测量你的NLP模型准确性一致的指标进行主动学习采样。对于许多NLP任务，上下文比目标检测更重要。你知道“旧金山”是一个地点，而不是一个名称中包含“旧金山”的组织，因为整个句子的上下文。因此，在预测序列周围有一个更广泛的上下文更安全，通常也是可取的，因为上下文可以是一个重要的预测因素。
- en: 6.3.2 Uncertainty sampling for sequence labeling
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.2 序列标注的不确定性采样
- en: Almost all sequence-labeling algorithms give you a probability distribution
    for your labels, most often using softmax, so that you can calculate the per-token
    uncertainty directly. In place of (or in addition to) the softmax confidences,
    you can use ensemble models and/or dropouts to produce multiple predictions and
    calculate the uncertainty as the level of agreement or entropy across those predictions.
    This approach is like the computer vision example for object detection.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有的序列标注算法都会为你提供标签的概率分布，通常使用softmax，这样你就可以直接计算每词的不确定性。除了（或与）softmax置信度之外，你可以使用集成模型和/或dropout来生成多个预测，并将不确定性作为这些预测之间的一致性或熵的水平来计算。这种方法类似于计算机视觉中的目标检测示例。
- en: Also as in the computer vision example, your confidences will be about the label
    confidence for each token, not the span as a whole or the boundary of the spans.
    But if you are using IOB2 tagging, your “B” tag will jointly predict the label
    and start boundary.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，就像在计算机视觉示例中一样，你的置信度将关于每个标记的标签置信度，而不是整个跨度或跨度的边界。但如果你使用IOB2标记，你的“B”标签将联合预测标签和起始边界。
- en: You can decide the best way to calculate the uncertainty for the entire span.
    The product of all the confidences is the (mathematically) most correct joint
    probability. You will also have to normalize for the number of tokens, however,
    which can be complicated. So the average or minimum confidence over all the tokens
    in a span might be easier to work with than the product.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以决定如何计算整个跨度的不确定性。所有信心值的乘积是（从数学上讲）最正确的联合概率。然而，你还需要对标记的数量进行归一化，这可能很复杂。因此，跨度中所有标记的平均或最小信心可能比乘积更容易处理。
- en: Uncertainty can be important for tokens immediately outside the span. If we
    wrongly predicted that “Francisco” was not a location, we would want to take into
    account the fact that it might have been. Table 6.2 shows an example.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 对于跨度外的标记，不确定性可能很重要。如果我们错误地预测“Francisco”不是位置，我们希望考虑到它可能曾是位置的事实。表6.2展示了这样一个例子。
- en: Table 6.2 An example of location identification and confidence associated with
    each label. The table shows an error in that only “San” from “San Francisco” is
    a location, but “Francisco” was reasonably high confidence. So we want to make
    sure that we take into account information outside the predicted spans when calculating
    confidence.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.2展示了与每个标签相关的位置识别和信心示例。表中显示了一个错误，即只有“San”来自“San Francisco”是位置，但“Francisco”的信心相当高。因此，我们想要确保在计算信心时考虑到预测跨度之外的信息。
- en: '![](../Images/06_T2.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/06_T2.png)'
- en: Table 6.2 shows an error, in which only “San” from “San Francisco” is predicted
    to be a location. Even though “Francisco” was a false negative, however, it had
    reasonably high confidence (0.46). For this reason, we want to calculate uncertainty
    from more than the predicted span; we want to make sure the boundary is correct
    too.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.2显示了一个错误，其中只有“San”来自“San Francisco”被预测为位置。然而，“Francisco”是一个假阴性，但它的信心（0.46）相当高。因此，我们想要从预测跨度之外计算不确定性；我们想要确保边界也是正确的。
- en: In Table 6.2, we can treat “Francisco” as 1 - 0.46 = 0.54, which will lower
    our confidence for the span boundary. By contrast, at the start of the prediction,
    the “a” has zero confidence. So 1 - 0 = 1, which will increase our confidence.
    The “B” tag also helps with the confidence of the initial boundary.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在表6.2中，我们可以将“Francisco”视为1 - 0.46 = 0.54，这将降低我们对跨度边界的信心。相比之下，在预测的开始阶段，“a”的信心为零。所以1
    - 0 = 1，这将增加我们的信心。“B”标签也有助于提高初始边界的信心。
- en: 6.3.3 Diversity sampling for sequence labeling
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.3 序列标注的多样性采样
- en: 'For your machine learning models, you are almost certainly using an architecture
    and/or feature representation that captures a wide window of context. In some
    models, you are encoding this representation directly. If you’re using transformer-based
    methods, that context (attention) is discovered as part of the model itself, and
    you are probably providing only a maximum size. To help determine the context
    to use in active learning, choose a window for sampling that is consistent with
    the context your predictive model is using. Chapter 4 covered four types of diversity
    sampling:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你的机器学习模型，你几乎肯定使用了一个架构和/或特征表示，它能够捕捉广泛的上下文窗口。在某些模型中，你直接编码了这个表示。如果你使用基于transformer的方法，那么上下文（注意力）是作为模型本身的一部分被发现的，你可能只提供了一个最大尺寸。为了帮助确定在主动学习中使用上下文，选择一个与你的预测模型使用的上下文一致的采样窗口。第4章介绍了四种类型的多样性采样：
- en: Model-based outlier sampling
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于模型的异常值采样
- en: Cluster-based sampling
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于聚类的采样
- en: Representative sampling
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 典型采样
- en: Sampling for real-world diversity
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现实世界多样性的采样
- en: 'We’ll start with the first and last approaches, which are easiest, as we did
    for object detection:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先从最简单的方法开始，即与对象检测一样：
- en: You can apply model-based outlier detection to a sequence labeling problem in
    the same way that you apply it to a document labeling problem.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将基于模型的异常值检测应用于序列标注问题，就像你将其应用于文档标注问题一样。
- en: You can sample for real-world diversity in a sequence labeling problem in the
    same way that you sample for a document labeling problem.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在序列标注问题中进行现实世界多样性的采样，就像你在文档标注问题中进行采样一样。
- en: For model-based outliers, the hidden layers focus on the spans you care about.
    That is, your neurons will be capturing information primarily to distinguish your
    spans from the nonspans (“B” and “I” from “O”) and from the different labels of
    your spans. So you can apply model-based outliers directly without truncating
    the sentences to the immediate context of every predicted span.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于模型的异常值，隐藏层专注于你关心的跨度。也就是说，你的神经元将主要捕捉信息以区分你的跨度与非跨度（“B”和“I”来自“O”）以及跨度标签的不同。因此，你可以直接应用基于模型的异常值，而无需截断句子到每个预测跨度的直接上下文。
- en: 'You can see different feature representations in figure 6.9: one-hot, noncontextual
    embeddings (such as word2vec) and contextual embeddings (such as BERT). If you
    have worked in NLP, you probably used these common feature representations. In
    all three cases, we want to extract the predicted span of text and create a single
    feature vector to represent that span. The main differences are that we sum the
    one-hot encodings instead of using max (although max would probably work) and
    that there is no need to sample beyond the predicted span when using contextual
    embeddings because the context is already captured in the vectors. Calculate the
    contextual embeddings before you extract the phrase. For the other methods, it
    doesn’t matter whether you extract the phrase before or after you calculate the
    vector. For diversity sampling, the principles from chapter 4 also apply: you
    need to combine all the active learning methods to ensure fairer data across real-world
    demographics.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在图6.9中看到不同的特征表示：one-hot编码、非上下文嵌入（如word2vec）和上下文嵌入（如BERT）。如果你在NLP领域工作过，你可能使用过这些常见的特征表示。在所有三种情况下，我们想要提取预测的文本跨度并创建一个单独的特征向量来表示该跨度。主要区别在于我们使用求和而不是使用最大值（尽管最大值可能也行得通），以及在使用上下文嵌入时不需要在预测跨度之外进行采样，因为上下文已经包含在向量中。在提取短语之前计算上下文嵌入。对于其他方法，你提取短语是在计算向量之前还是之后并不重要。对于多样性采样，第4章中的原则也适用：你需要结合所有主动学习方法以确保跨真实世界人口统计数据的公平数据。
- en: '![](../Images/CH06_F09_Munro.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F09_Munro.png)'
- en: 'Figure 6.9 Three ways to encode predicted spans for active learning: using
    one-hot encoding to encode each token as its own feature (top left); using a noncontextual
    vector (embedding) such as word2vec (top right); and using a contextual embedding
    such as BERT (bottom). You can also experiment with average pooling (avepool)
    in place of or in addition to maximum pooling (maxpool).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9展示了三种用于主动学习的预测跨度编码方式：使用one-hot编码将每个标记编码为其自己的特征（左上角）；使用非上下文向量（嵌入）如word2vec（右上角）；以及使用上下文嵌入如BERT（底部）。你也可以尝试使用平均池化（avepool）代替或与最大池化（maxpool）一起使用。
- en: So far, you can see that diversity sampling for sequence labeling has many similarities
    to diversity sampling for object detection. You care about context of the objects/
    spans, but you don’t necessarily need to worry about them for model-based outliers,
    as your model will already be focusing most of the neurons on the parts of the
    image/ text you care about most.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可以看到序列标注中的多样性采样与目标检测中的多样性采样有很多相似之处。你关心对象/跨度上下文，但对于基于模型的异常值，你不必过于担心，因为你的模型已经将大部分神经元集中在你最关心的图像/文本部分。
- en: For cluster-based sampling and representative sampling, we want to focus our
    models on the spans themselves, not too far into the context on either side. If
    you are using contextual vector-representations of the tokens, you may not need
    extra context; that context is already captured in your vectors.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于聚类采样和代表性采样，我们希望将模型集中在跨度本身上，而不是在任一侧的上下文中太远。如果你使用的是标记的上下文向量表示，你可能不需要额外的上下文；那个上下文已经包含在你的向量中。
- en: 'The preceding and following text should be cropped at meaningful distances
    and at word or sentence boundaries (or at phrasal boundaries, if you have this
    information). Because your model isn’t 100% accurate, you need to ensure that
    you are capturing the full span:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 前后文本应在有意义的距离和单词或句子边界（或如果你有这些信息，在短语边界）处裁剪。因为你的模型不是100%准确的，你需要确保你捕捉到了完整的跨度：
- en: Crop at a given threshold. If the span is a Location, expand the selection to
    words before or after the prediction where Location is predicted with at least
    some low (say, 10%) confidence.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在给定的阈值下裁剪。如果跨度是位置，则将选择扩展到预测位置之前或之后的单词，其中位置至少有一些低（例如，10%）的置信度。
- en: Crop a wide threshold, maybe the whole sentence, and weight each word or subword
    sequence by the probability of each word’s being part of the span.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置一个宽阈值，可能是整个句子，并按每个单词或子单词序列是跨度的组成部分的概率来加权每个单词或子单词。
- en: 'Not all algorithms allow you to weight your features in a meaningful way. If
    you can’t do this, use the same strategy as in object detection: generate multiple
    spans from an ensemble or dropout. Then try representative sampling for each of
    those predictions, weighted by their average overlap with the other predicted
    spans. You can use the words and subwords in each span directly for clustering
    and representative sampling, as you did in chapter 5.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有算法都允许你以有意义的方式对特征进行加权。如果你无法做到这一点，可以使用与目标检测相同的策略：从集成或dropout中生成多个跨度。然后尝试对每个预测进行代表性采样，根据它们与其他预测跨度的平均重叠程度进行加权。你可以直接使用每个跨度中的单词和子单词进行聚类和代表性采样，就像你在第5章中所做的那样。
- en: If you are cropping the text and using the hidden layers of the model for cluster-based
    sampling, model-based outliers, or representative sampling, get those hidden layers
    before you crop the text. The full sentence context will be necessary for getting
    accurate contextual representations for each word in the span. When you have a
    vector of neuron activations for every word or subword in the sentence, you can
    crop the selection to the span.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在裁剪文本并使用模型的隐藏层进行基于聚类的采样、基于模型的异常值或代表性采样，请在裁剪文本之前获取这些隐藏层。完整的句子上下文对于获取跨度中每个单词的准确上下文表示是必要的。当你拥有句子中每个单词或子单词的神经元激活向量时，你可以将选择裁剪到跨度。
- en: The final problem that you’ll need to solve is how to combine the vectors for
    each word or subword. If all your spans are the same length, you can concatenate
    them. If not, you’ll need to combine them--a process known as *pooling* for neural
    vectors. The vectors tend to be sparse, so maxpooling is probably best (taking
    the maximum value in each vector index for each word or subword), but you could
    try averaging or some other pooling method to see the difference.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要解决的最后一个问题是如何组合每个单词或子单词的向量。如果你的所有跨度长度相同，你可以将它们连接起来。如果不相同，你需要将它们组合起来——这是一个称为*池化*的过程，用于神经网络向量。向量往往是稀疏的，所以最大池化可能是最好的（在每个向量索引中取每个单词或子单词的最大值），但你也可以尝试平均或其他池化方法来观察差异。
- en: Whether you are using the words or subwords or a vector representation, you
    can apply cluster-based sampling and representative sampling as you learned in
    chapter 4\. You can sample centroids, outliers, and random cluster members, and
    you can sample the most representative items from your target domain.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是使用单词、子单词还是向量表示，你都可以像在第4章中学到的那样应用基于聚类的采样和代表性采样。你可以采样质心、异常值和随机聚类成员，你也可以从你的目标领域中采样最具代表性的项目。
- en: 6.3.4 Active transfer learning for sequence labeling
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.4 序列标记的主动迁移学习
- en: You can apply active transfer learning to sequence labeling in the same way
    that you applied it to document-level labels. You can also apply ATLAS, adapting
    within one active learning cycle because you can assume that the first sequences
    you sample will be corrected later by human labelers, even if you don’t know what
    those labels are.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将主动迁移学习应用于序列标记，就像你应用于文档级标签一样。你还可以应用ATLAS，在单个主动学习周期内进行调整，因为你可以假设你最初采样的序列将被人类标注员后来纠正，即使你不知道那些标签是什么。
- en: Regardless of the type of neural architecture you use for sequence labeling,
    you can use the hidden layer(s) as the features for a binary “Correct”/“Incorrect”
    model that you train on validation data. You will need to decide what counts as
    “Correct” and “Incorrect” in your validation data. If you care about some sequences
    more than others, you may want to count only errors with those sequences as “Incorrect”
    in your new model, focusing on the types of errors you care most about. You also
    need to decide whether to calculate errors in terms of the per-token error or
    for the sequence as a whole. As a starting point, it makes sense to calculate
    errors by using the same method that you use for calculating accuracy in your
    machine learning model, but you may want to experiment with other methods.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用哪种类型的神经网络架构进行序列标注，您都可以使用隐藏层（s）作为在验证数据上训练的二进制“正确”/“错误”模型的特征。您需要决定在验证数据中什么算作“正确”和“错误”。如果您对某些序列比对其他序列更关心，您可能只想将那些序列的错误视为“错误”，专注于您最关心的错误类型。您还需要决定是否按每标记错误或整个序列来计算错误。作为一个起点，使用与您在机器学习模型中计算准确率相同的方法来计算错误是有意义的，但您可能想尝试其他方法。
- en: 6.3.5 Stratified sampling by confidence and tokens
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.5 按置信度和标记进行分层采样
- en: Set your threshold for predicting spans low, whatever method you use. You don’t
    want to find only spans that are similar to those that already exist in your data,
    which will perpetuate the bias. You can use the same stratified sampling by confidence
    method (section 6.1.5) for object detection, perhaps sampling an equal number
    of spans at 0%-10% confidence, 10%-20% confidence, and so on.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用什么方法预测跨度，都要将阈值设置得低一些。您不希望只找到与您数据中已经存在的跨度相似的跨度，这将导致偏差的持续。您可以使用与目标检测相同的按置信度分层的采样方法（第6.1.5节），例如，在0%-10%置信度、10%-20%置信度等处采样相同数量的跨度。
- en: Also, you can stratify the sample according to the tokens themselves. You might
    cap the sample of spans that are “San Francisco” (or any other sequence) to sample
    a maximum of 5 or 10 instances, thereby sampling a greater diversity of tokens
    overall.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还可以根据标记本身对样本进行分层。您可以将“旧金山”（或任何其他序列）的跨度样本限制在最多5个或10个实例，从而在总体上采样更多样化的标记。
- en: 6.3.6 Create training data samples for representative sampling that are similar
    to your predictions
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.6 为代表性采样创建与您的预测相似的训练数据样本
- en: If you are cropping your unlabeled text for representative sampling, you should
    do the same with the training data. If you use only the perfect span annotations
    from your training data, but then the imperfect predictions from your unlabeled
    data, the “representative” samples could end up bseing the result of different
    cropping strategies instead of the actual span differences.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在为代表性采样裁剪未标记的文本，您应该对训练数据做同样的事情。如果您只使用训练数据中的完美跨度标注，但使用未标记数据中的不完美预测，那么“代表性”样本最终可能是不同裁剪策略的结果，而不是实际的跨度差异。
- en: Section 6.1.6 covered some strategies for cropping the training data and unlabeled
    data to reduce bias. These strategies apply to spans too, so look at those methods
    if you are applying representative sampling to your spans.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 第6.1.6节介绍了一些裁剪训练数据和未标记数据以减少偏差的策略。这些策略也适用于跨度，因此如果您正在对跨度应用代表性采样，请查看这些方法。
- en: As with object detection, you should consider using some sampling methods on
    uncropped text. You might do more of this here, because the context for a span
    typically is contextually relevant pieces of that language optimized to encode
    information; while the backgrounds for object detection are more likely to be
    random junk in the world.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 与目标检测类似，您应该考虑在未裁剪的文本上使用一些采样方法。您可能在这里做更多的事情，因为跨度的上下文通常是上下文中相关的语言片段，这些片段被优化以编码信息；而目标检测的背景更有可能是世界中的随机垃圾。
- en: Some simple approaches to representative sampling can be effective, and you
    may not need to build a model. You might even choose to focus only on predicted
    spans that don’t yet occur in your training data.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 一些简单的代表性采样方法可能很有效，您可能不需要构建模型。您甚至可以选择只关注那些尚未出现在您的训练数据中的预测跨度。
- en: 6.3.7 Full-sequence labeling
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.7 完整序列标注
- en: For a handful of tasks in NLP, you want to label every item in the text. An
    example is part-of-speech (POS) tagging, as shown in table 6.3.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 对于NLP中的一些任务，您希望对文本中的每个项目进行标注。例如，词性标注（POS）标记，如表6.3所示。
- en: Table 6.3 An example of a full-sequence parse, showing POS tags (labels) such
    as nouns, verbs, adverbs (Adv), proper nouns (PRP), and so on
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.3 全序列解析示例，显示名词、动词、副词（Adv）、专有名词（PRP）等POS标签（标签）
- en: '![](../Images/06_T3.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/06_T3.png)'
- en: You can treat this task the same as tagging sequences within the text, but it
    is simplified in that you have to worry less about cropping the text or ignoring
    “O” labels. Stratification by labels is likely to help for cases such as those
    in table 6.3, taking the 100 most uncertain nouns, the 100 most uncertain verbs,
    the 100 most uncertain adverbs, and so on. You can use this sampling method along
    with macro F-score to evaluate the model accuracy.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将这个任务视为与文本内部的序列标记相同，但它在简化方面有所简化，因为你不必太担心裁剪文本或忽略“O”标签。按标签分层可能有助于表6.3中那样的案例，例如选取100个最不确定的名词、100个最不确定的动词、100个最不确定的副词等等。你可以使用这种抽样方法结合宏F分数来评估模型精度。
- en: 6.3.8 Sampling for document-level diversity in sequence labeling
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.8 序列标记中文档级别多样性的抽样
- en: As with any other method, you should always randomly sample text for review.
    This practice provides your evaluation data and gives you a baseline for how successful
    your active learning is. If you apply clustering at the whole-document level and
    find whole clusters with little or no existing training items, you have good evidence
    that you should get human review for some items in those clusters because you
    could be missing something.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何其他方法一样，你应该始终随机抽样文本进行审查。这种做法提供了你的评估数据，并为你提供了一个评估主动学习成功与否的基准。如果你在全文级别应用聚类，并发现存在大量或没有现有训练项的整个集群，那么你有很好的证据表明，你应该对这些集群中的某些项目进行人工审查，因为你可能遗漏了一些东西。
- en: 'There is a good chance that there are real-world diversity considerations at
    the document level, too: the genre of the text, the fluency of the person who
    created it, the language(s), and so on. Stratified sampling for real-world diversity
    may be more effective at document level than at sequence level for these cases.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在文档层面上，也可能存在现实世界的多样性考虑：文本的类型、创建者的流畅性、语言（们）等等。对于这些情况，分层抽样在文档层面上可能比在序列层面上更有效。
- en: 6.4 Applying active learning to language generation
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 将主动学习应用于语言生成
- en: For some NLP tasks, the machine learning algorithm is producing sequences like
    natural language. The most common use case is text generation, which are the example
    use cases in this section. Most language generation for signed and spoken languages
    starts with text generation and then generates the signs or speech as a separate
    task. The machine learning models are typically general sequence generation architectures
    that can be applied to other types of sequences, like genes and music, but these
    are also less common than text.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些自然语言处理任务，机器学习算法正在生成类似于自然语言的序列。最常见的用例是文本生成，这是本节中的示例用例。大多数手语和口语语言生成都是从文本生成开始的，然后作为单独的任务生成符号或语音。机器学习模型通常是通用的序列生成架构，可以应用于其他类型的序列，如基因和音乐，但这些比文本更不常见。
- en: Even then, it is only on the back of recent advances in transfer learning that
    full text generation systems are at a level of accuracy that enables us to start
    using them in real-world applications.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 即使如此，也只有在迁移学习最近取得进展的基础上，全文生成系统才达到了足够准确的水平，使我们能够开始在现实世界应用中开始使用它们。
- en: The most obvious exception is machine translation, which has been popular in
    academic and industry settings for some time. Machine translation is a well-defined
    problem, taking a sentence in one language and producing one in a new language.
    Historically, machine translation has a lot of existing training data to draw
    from in the form of books, articles, and web pages that have been translated between
    languages manually.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 最明显的例外是机器翻译，这在学术界和工业界已经流行了一段时间。机器翻译是一个定义明确的问题，它从一个语言中取一个句子，并产生一个新的语言的句子。从历史上看，机器翻译有很多现有的训练数据可以借鉴，这些数据是以书籍、文章和网页的形式存在的，它们在语言之间被人工翻译。
- en: Question-answering, in which a full sentence is given in response to a question,
    is growing in popularity as an example of text generation. Another example is
    a dialogue system such as a chatbot, producing sentences in response to interactions.
    Summarization is yet another example, producing a smaller number of sentences
    from a larger text. Not all of these use cases necessarily use full text generation,
    however. Many question-answering systems, chatbots, and summarization algorithms
    use templated outputs to create what seem like real communications after extracting
    the important sequences from the inputs. In these cases, they are using document-level
    labels and sequence labels, so the active learning strategies that you have already
    learned for document-labeling and sequence labeling will be sufficient.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 问答，即对一个问题的回答给出一个完整的句子，作为文本生成的例子，越来越受欢迎。另一个例子是对话系统，如聊天机器人，根据交互产生句子。摘要又是另一个例子，从更长的文本中产生更少的句子。然而，并非所有这些用例都必然使用全文生成。许多问答系统、聊天机器人和摘要算法在从输入中提取重要序列后，使用模板输出创建看似真实的通信。在这些情况下，它们使用文档级标签和序列标签，因此，您已经学过的用于文档标签和序列标签的主动学习策略将足够。
- en: 6.4.1 Calculating accuracy for language generation systems
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.1 计算语言生成系统的准确率
- en: One complicating factor for language generation is that there is rarely one
    correct answer. This situation is often addressed by having multiple correct responses
    in the evaluation data and allowing the best match to be the score that is used.
    In translation tasks, the evaluation data often contains several correct translations,
    and accuracy is calculated by the best match of a translation against any of them.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 语言生成的一个复杂因素是很少有一个正确的答案。这种情况通常通过在评估数据中包含多个正确答案，并允许最佳匹配作为使用的分数来解决。在翻译任务中，评估数据通常包含几个正确的翻译，准确率是通过将翻译与其中任何一个的最佳匹配来计算的。
- en: In the past few years, major advances in neural machine translation have been
    full sentence-to-sentence generation; the machine learning takes in examples of
    the same sentences in two languages and then trains a model that can translate
    directly from one sentence to another. This feature is incredibly powerful. Previously,
    machine translation system had multiple steps to parse in and out of different
    languages and align the two sentences. Each step used a machine learning system
    of its own, and the steps were often put together with a meta- machine learning
    system to combine them. The newer neural machine translation systems that need
    only parallel text and can take care of the entire pipeline use only about 1%
    of the code of the earlier cobbled-together systems and are much more accurate.
    The only step back is that neural machine translation systems are less interpretable
    today than their non-neural predecessors, so it is harder to identify confusion
    in the models.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，神经机器翻译的主要进步是全句子到句子的生成；机器学习接受两种语言中相同句子的示例，然后训练一个可以直接从一句话翻译到另一句话的模型。这个功能非常强大。以前，机器翻译系统需要多个步骤来解析不同语言之间的输入和输出，并对齐两个句子。每个步骤都使用自己的机器学习系统，并且这些步骤通常与元机器学习系统一起组合起来。新的神经机器翻译系统只需要平行文本，并且可以处理整个流程，它们仅使用大约1%的早期拼凑系统的代码，并且更加准确。唯一的缺点是，与它们的非神经前辈相比，神经机器翻译系统现在更难以解释，因此更难在模型中识别混淆。
- en: 6.4.2 Uncertainty sampling for language generation
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.2 语言生成的不确定性采样
- en: For uncertainty sampling, you can look at the variation across multiple predictions,
    as you did for sequence labeling and the computer vision tasks, but this area
    is much less studied. If you are building models for text generation, you are
    probably using an algorithm that generates multiple candidates. It may be possible
    to look at the variation in these candidates to measure uncertainty. But the neural
    machine translation models typically generate a small number of candidates by
    using a method called beam search (around 5), which isn’t enough to measure the
    variation accurately. Recent research shows that widening the search can reduce
    overall model accuracy, which you obviously want to avoid.[²](#pgfId-1007202)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不确定性采样，你可以查看多个预测之间的变化，就像你在序列标注和计算机视觉任务中所做的那样，但这个领域的研究相对较少。如果你正在构建用于文本生成的模型，你很可能使用的是生成多个候选算法。可能可以通过查看这些候选之间的变化来测量不确定性。但是，神经机器翻译模型通常通过使用称为beam
    search的方法生成少量候选（大约5个），这不足以准确测量变化。最近的研究表明，扩大搜索范围可能会降低整体模型精度，这显然是你想要避免的。[²](#pgfId-1007202)
- en: You could try to model uncertainty with ensemble models or dropouts from a single
    model. Measuring the level of agreement across ensemble models is a long-standing
    practice in machine translation for determining uncertainty, but the models are
    expensive to train (often taking days or weeks), so training multiple models simply
    to sample for uncertainty could be prohibitively expensive.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试使用集成模型或从单个模型中去除一些神经元来模拟不确定性。在机器翻译中，测量集成模型之间的一致性水平是确定不确定性的长期实践，但这些模型训练起来成本高昂（通常需要几天或几周），因此仅仅为了采样不确定性而训练多个模型可能会非常昂贵。
- en: Using dropouts during sentence generation can help generate uncertainty scores
    by getting multiple sentences from a single model. I experimented with this approach
    for the first time in a paper presented during the writing of this book.[³](#pgfId-1007227)
    Initially, I was going to include this study, which focused on bias detection
    in language models, as an example in the final chapter in this book. Given that
    the content is already in that paper and that the disaster-response examples in
    this book became even more relevant with the COVID-19 pandemic that began while
    I was writing it, however, I replaced that example in chapter 12 with the example
    task tracking potential foodborne outbreaks.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在句子生成过程中使用dropout可以帮助通过从单个模型中获得多个句子来生成不确定性分数。我在撰写本书期间发表的一篇论文中首次尝试了这种方法。[³](#pgfId-1007227)最初，我打算将这项研究包括在内，这项研究专注于语言模型中的偏差检测，并将其作为本书最后一章的例子。然而，鉴于该内容已在论文中，以及本书中的灾害响应示例在撰写期间因COVID-19大流行而变得更加相关，因此我将第12章中的示例任务替换为跟踪潜在食源性疾病爆发的任务。
- en: 6.4.3 Diversity sampling for language generation
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.3 语言生成的多样性采样
- en: Diversity sampling for language generation is more straightforward than uncertainty
    sampling. If your input is text, you can implement diversity sampling exactly
    as you did in chapter 4 for document-level labeling. You can use clustering to
    ensure that you have a diverse set of inputs, representative sampling to adapt
    to new domains, and model-based outliers to sample what is confusing to your current
    model. You can also stratify your samples by any real-world demographics.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 对于语言生成，多样性采样比不确定性采样更直接。如果你的输入是文本，你可以像在第4章中为文档级标注实现的那样实现多样性采样。你可以使用聚类来确保你有一组多样化的输入，代表性采样来适应新领域，以及基于模型的异常值来采样当前模型感到困惑的内容。你还可以根据任何现实世界的人口统计特征对样本进行分层。
- en: Diversity sampling has typically been a major focus of machine translation.
    Most machine translation systems are general-purpose, so the training data needs
    to cover as many words as possible in your language pairs, with each word in as
    many contexts as possible, especially if that word has multiple translations depending
    on context.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 多样性采样通常一直是机器翻译的主要关注点。大多数机器翻译系统都是通用型的，因此训练数据需要覆盖你语言对中的尽可能多的单词，每个单词在尽可能多的上下文中出现，特别是如果该单词根据上下文有多个翻译的话。
- en: For domain-specific machine translation systems, representative sampling is
    often used to ensure that any new words or phrases that are important to a domain
    have translations. When you are adapting a machine translation system to a new
    technical domain, for example, it is good strategy to oversample the technical
    terms for that domain, as they are important to get correct and are unlikely to
    be known by a more general machine translation system.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对于特定领域的机器翻译系统，通常使用代表性抽样来确保任何对领域重要的新单词或短语都有翻译。例如，当您将机器翻译系统适应新的技术领域时，增加该领域的术语样本是一个很好的策略，因为这些术语对于正确性至关重要，并且不太可能被更通用的机器翻译系统所知晓。
- en: One of the most exciting applications for diversity sampling for text generation
    is creating new data for other tasks. One long-standing method is *back translation*.
    If you have a segment of English text labeled as negative sentiment, you could
    use machine translation to translate that sentence into many other languages and
    then back into English. The text itself might change, but the label of negative
    sentiment is probably still correct. This kind of generative approach to training
    data, known as *data augmentation*, includes some exciting recent advances in
    human-in-the-loop machine learning that we will cover in chapter 9.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本生成的多样性抽样，最令人兴奋的应用之一是为其他任务创建新的数据。一种长期存在的方法是*回译*。如果您有一段被标记为负面情绪的英文文本，您可以使用机器翻译将该句子翻译成多种其他语言，然后再将其翻译回英文。文本本身可能会改变，但负面情绪的标签可能仍然正确。这种训练数据生成的方法，称为*数据增强*，包括一些关于人机交互机器学习方面的最新进展，我们将在第9章中介绍。
- en: 6.4.4 Active transfer learning for language generation
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.4 语言生成的主动迁移学习
- en: You can apply active transfer learning to language generation in a similar way
    to the other use cases in this chapter. You can also apply ATLAS, adapting within
    one active learning cycle because you can assume that the first sequences you
    sample will be corrected by human labelers later, even if you don’t know what
    those labels are.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将主动迁移学习应用于语言生成，方式与其他本章中的用例类似。您还可以应用ATLAS，在单个主动学习周期内进行调整，因为您可以假设您最初采样的序列将被人类标注员后来纠正，即使您不知道那些标签是什么。
- en: You need to carefully define what counts as a “Correct” or “Incorrect” prediction
    in your validation data, however. Typically, this task involves setting some threshold
    of accuracy at which a sentence is considered to be correct or incorrect. If you
    can calculate accuracy on a per-token basis, you have the option of aggregating
    the accuracy across all tokens to create a numerical accuracy value. You can predict
    a continuous value instead of the binary “Correct”/“Incorrect,” as in the IoU
    example for object detection in section 6.1.1.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要仔细定义在验证数据中什么算作“正确”或“错误”的预测。通常，这项任务涉及设置一个准确性阈值，超过该阈值，句子就被认为是正确的或错误的。如果您可以按每个标记计算准确性，您可以选择将所有标记的准确性汇总以创建一个数值准确性值。您可以选择预测一个连续值而不是二元的“正确”/“错误”，就像在第6.1.1节中对象检测的IoU示例中那样。
- en: 6.5 Applying active learning to other machine learning tasks
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 将主动学习应用于其他机器学习任务
- en: The active learning principles in chapters 3, 4, and 5 can be applied to almost
    any machine learning task. This section covers a few more at a high level. This
    section doesn’t go into the level of implementation detail that you learned for
    the computer vision and NLP examples, but it will give you an idea about how the
    same principles apply to different data types.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 第3、4、5章中的主动学习原则可以应用于几乎任何机器学习任务。本节从高层次上概述了更多内容。本节不会深入到您在计算机视觉和NLP示例中学到的实现细节水平，但它将让您了解相同的原理如何应用于不同的数据类型。
- en: '*For some use cases, it isn’t possible to collect new unlabeled data at all
    and you will need to find ways to measure your accuracy by other means.* See the
    following sidebar for more about one such method: synthetic controls.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '*对于某些用例，根本无法收集新的未标记数据，您将需要找到其他方法来衡量您的准确性。* 有关此类方法之一的更多信息，请参阅以下侧边栏：合成控制。'
- en: 'Synthetic controls: Evaluating your model without evaluation data'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 合成控制：在没有评估数据的情况下评估您的模型
- en: '*Expert anecdote by Dr. Elena Grewal*'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '*埃莱娜·格罗瓦尔博士的专家轶事*'
- en: 'How can you measure your model’s success if you are deploying an application
    where you can’t run A/B tests? Synthetic control methods are a technique that
    you can use in this case: you find existing data that is closest in features to
    where you are deploying the model and use that data as your control group.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在部署一个无法进行A/B测试的应用程序时，如何衡量你的模型的成功呢？合成控制方法是在这种情况下你可以使用的一种技术：你找到与你在部署模型的地方在特征上最接近的现有数据，并使用这些数据作为你的对照组。
- en: I first learned about synthetic controls when studying education policy analysis.
    When a school tries some new method to improve their students’ learning environment,
    they can’t be expected to improve only half the students’ lives so that the other
    half can be a statistical control group. Instead, education researchers might
    create a synthetic control group of schools that are most similar in terms of
    the student demographics and performance. I took this strategy, and we applied
    it at Airbnb when I was leading data science there. When Airbnb was rolling out
    a product or policy change in a new city/market and could not run an experiment,
    we would create a synthetic control group of the most similar cities/markets.
    We could then measure the impact of our models compared with the synthetic controls
    for metrics such as engagement, revenue, user ratings, and search relevance. Synthetic
    controls allowed us to take a data-driven approach to measuring the impact of
    our models, even where we didn’t have evaluation data.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我第一次了解到合成控制是在研究教育政策分析时。当一所学校尝试一些新方法来改善学生的学习环境时，不能期望只有一半的学生生活得到改善，以便另一半可以作为一个统计对照组。相反，教育研究人员可能会创建一个与学生在人口统计和表现方面最相似的学校的合成控制组。我采取了这种策略，当我领导Airbnb的数据科学团队时，我们应用了这种方法。当Airbnb在新的城市/市场推出产品或政策变化，并且无法进行实验时，我们会创建一个最相似的城市/市场的合成控制组。然后我们可以衡量我们的模型与合成控制组在参与度、收入、用户评分和搜索相关性等指标上的影响。合成控制使我们能够采取数据驱动的方法来衡量我们模型的影响，即使我们没有评估数据。
- en: '*Elena Grewal is founder and CEO of Data 2 the People, a consultancy that uses
    data science to support political candidates. Elena previously led Airbnb’s data
    science team and has a PhD in education from Stanford University*.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '*Elena Grewal是Data 2 the People的创始人兼首席执行官，这是一家利用数据科学支持政治候选人的咨询公司。Elena之前领导了Airbnb的数据科学团队，并在斯坦福大学获得了教育学博士学位*。'
- en: 6.5.1 Active learning for information retrieval
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.1 信息检索的主动学习
- en: '*Information* *retrieval* is the set of algorithms that drives search engines
    and recommendation systems. Multiple metrics can be used for calculating the accuracy
    of retrieval systems that return multiple results from a query. The most common
    of those metrics today is discounted cumulative gain (DCG), in which reli is the
    graded relevance of the result at a ranked position p :'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '*信息检索*是一组算法，驱动着搜索引擎和推荐系统。可以使用多个指标来计算返回多个结果的查询检索系统的准确性。今天最常用的这些指标之一是折现累积增益（DCG），其中reli是排名位置p处结果的分级相关性：'
- en: '![](../Images/CH06_F09_Munro_E01.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH06_F09_Munro_E01.png)'
- en: The `log``()` is used to deweight the lower entries. Perhaps you want the first
    search result to be the most accurate; you care slightly less about the second
    search result; slightly less again about the third search result; and so on. The
    use of a log was a fairly arbitrary weighting when first introduced, but some
    relatively recent theory suggests that it has mathematical validity.[⁴](#pgfId-1007243)
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`log()`函数用于降低低值项的权重。也许你希望第一个搜索结果是最准确的；你对第二个搜索结果关心得稍微少一些；对第三个搜索结果关心得更少一些；以此类推。最初引入对数时，这种使用是一种相当随意的加权，但一些相对较新的理论表明，它具有数学上的有效性。[⁴](#pgfId-1007243)'
- en: Real-world search systems are some of the most sophisticated uses cases for
    human-in-the-loop machine learning today. Think about a simple search in an online
    store. The store is using one form of machine learning to retrieve the search
    results. It uses a second form of machine learning to identify keywords and entities
    in your search string. It uses a third form of machine learning to extract the
    relevant summary text from each product in the results. The products are categorized
    into the type of product (electronics, books, and so on) to help with search relevance
    in a fourth kind of machine learning. The store might also be using a fifth form
    of machine learning to decide what is an ideal display image (plain background
    or in context). Many modern search engines also try to maximize diversity, returning
    different product types rather than 10 versions of the same product. So six or
    more different machine learning systems may be contributing to your search results,
    even before any models try to personalize the results for your experience. Each
    of these machine learning systems needs its own training data. Some of that data
    can be derived from what people click, but much of it is from offline annotators
    who provide that feedback.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界的搜索系统是当今人机交互机器学习中最复杂的用例之一。想想在线商店的一个简单搜索。商店正在使用一种机器学习形式来检索搜索结果。它使用第二种机器学习形式来识别你的搜索字符串中的关键词和实体。它使用第三种机器学习形式从结果中的每个产品中提取相关的摘要文本。产品被分类为产品类型（电子产品、书籍等），以帮助第四种机器学习形式的搜索相关性。商店还可能使用第五种机器学习形式来决定理想的展示图像（纯背景或情境中）。许多现代搜索引擎也试图最大化多样性，返回不同类型的产品，而不是同一产品的10个版本。因此，可能有六个或更多不同的机器学习系统对你的搜索结果做出贡献，甚至在任何模型尝试为你量身定制结果之前。每个机器学习系统都需要自己的训练数据。其中一些数据可以来自人们的点击，但大部分来自离线标注者提供的反馈。
- en: 'You may not realize that you’re using cutting-edge machine learning when you
    shop online, but a lot is going on behind the scenes. In fact, this use case is
    why the best-known crowdsourcing platform, Amazon’s Mechanical Turk, was invented:
    to clean up catalog information for products in the online store.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能没有意识到你在网上购物时正在使用最前沿的机器学习，但幕后有很多事情在进行。事实上，这个用例是为什么最知名的众包平台，亚马逊的Mechanical
    Turk，被发明出来的原因：为了清理在线商店中产品的目录信息。
- en: 'Information retrieval also tends to use more real-world accuracy metrics than
    other machine learning applications. Although DCG is popular for offline evaluation
    of search relevance, the results for people using the system are often optimized
    for business-oriented metrics: the number of purchases a person makes, the number
    of clicks/seconds between a search and a purchase is made, the value of the customer
    over the next six months, and so on. Because these metrics are about use of the
    model, they are sometimes called *online metrics*, as opposed to F-score and IoU,
    which are offline metrics. These metrics are different from F-score and IoU, and
    much more human-centric, so other use cases can learn a lot from the information
    retrieval community.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 信息检索也倾向于使用比其他机器学习应用更多的现实世界准确性指标。尽管DCG在离线评估搜索相关性方面很受欢迎，但系统使用者的结果通常优化为面向商业的指标：一个人购买的商品数量，从搜索到购买之间的点击/秒数，客户未来六个月的客户价值等。因为这些指标是关于模型的使用，所以它们有时被称为*在线指标*，与F-score和IoU不同，后者是离线指标。这些指标与F-score和IoU不同，并且更加以人为中心，因此其他用例可以从信息检索社区中学到很多。
- en: 6.5.2 Active learning for video
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.2 视频的主动学习
- en: Most of the solutions for still images also apply to object detection and/or
    semantic segmentation in videos. Focus on the regions you care about the most
    in the video, and use them for your samples. If your model focuses only on objects
    or labels you care about, you can implement uncertainty sampling and model-based
    outliers without necessarily cropping or masking your videos to the objects you
    care about. If you are applying diversity sampling, you almost certainly want
    to crop or mask to those objects first.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数针对静态图像的解决方案也适用于视频中的目标检测和/或语义分割。关注视频中最关心的区域，并使用它们作为样本。如果你的模型只关注你关心的对象或标签，你可以实现不确定性采样和基于模型的异常值，而不必
    necessarily 裁剪或遮罩你的视频到你所关心的对象。如果你正在应用多样性采样，你几乎肯定想要首先裁剪或遮罩到那些对象。
- en: 'The biggest difference between videos and still images is that you have many
    frames of data from the same video with almost identical images. The obvious solution
    is the best one: if you have multiple frames from what your model thinks is the
    same object, sample the frame with the highest uncertainty. The iterative process
    of retraining on that new object is likely to give you some or all the other frames
    with high confidence afterward.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 视频和静态图像之间最大的区别是，你有很多来自同一视频的几乎相同的图像帧。最明显的解决方案就是最好的解决方案：如果你有多个来自你的模型认为相同的对象的帧，就采样不确定性最高的帧。在新的对象上重新训练的迭代过程可能会在之后给你一些或所有其他高置信度的帧。
- en: Diversity sampling should already reduce the number of times the same object
    is selected in different frames because the object will look the same across frames.
    If the object changes form, you probably want to sample it in different forms,
    so this situation works out. An example is sign language. You are not tracking
    an object so much as trying to interpret a stream of information, so your active
    learning strategy might look more like text and speech than object detection.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 多样性采样应该已经减少了在不同帧中选择相同对象次数，因为对象在帧之间看起来是相同的。如果对象改变了形态，你可能想以不同的形态采样它，所以这种情况是可行的。一个例子是手语。你并不是在追踪一个对象，而是在尝试解释一条信息流，所以你的主动学习策略可能看起来更像文本和语音，而不是对象检测。
- en: 'Note that if you don’t use diversity sampling for object detection in videos,
    you might find that your most uncertain samples are the same object in successive
    frames. Most companies I’ve seen sample every *N*th frame and/or sample an exact
    number of frames per video, typically the first, last, and some number of intermediary
    ones. There is nothing wrong with this approach to stratified sampling, but sampling
    diversity through clustering and adaptive representative sampling in addition
    generally leads to much richer samples. You might also need to oversample some
    videos to get more frames containing certain rarer labels to improve real-world
    diversity. You have a lot of individual images if you take every frame of every
    video, so you can also try large-scale clustering on the whole images first and
    use the total number of videos as a guide:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果你在视频对象检测中不使用多样性采样，你可能会发现你最不确定的样本是连续帧中的相同对象。我所见过的多数公司都会每隔*N*帧采样一次，或者按视频采样精确数量的帧，通常是第一帧、最后一帧和一些中间帧。这种分层采样的方法并没有什么问题，但通过聚类和自适应代表性采样来增加多样性通常会得到更丰富的样本。你可能还需要对某些视频进行过采样，以获取更多包含某些罕见标签的帧，从而提高现实世界的多样性。如果你每部视频都取每一帧，那么你会有很多单独的图像，因此你也可以先对整个图像进行大规模聚类，并使用视频总数作为指导：
- en: If you have fewer clusters than the total number videos, combine similar videos
    into one cluster to have targeted diversity.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你拥有的聚类数量少于视频总数，可以将相似的视频合并成一个聚类，以实现有针对性的多样性。
- en: If you have more clusters than the total number of videos, you should end up
    with some videos split into multiple clusters, ideally the videos that have more
    diverse content.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你拥有的聚类数量多于视频总数，最终你应该有一些视频被分割成多个聚类，理想情况下是内容更丰富的视频。
- en: This approach gives you a lot of scope to combine the active learning methods
    covered in this book to annotate a video as quickly as possible.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法为你提供了很大的空间，可以将本书中涵盖的主动学习方法结合起来，以尽可能快地标注视频。
- en: 6.5.3 Active learning for speech
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.5.3 语音的主动学习
- en: Like text or signed language, speech can be a labeling task, a sequence task,
    or a language generation task. You approach each use case differently, as you
    do for text or images.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 就像文本或手语一样，语音可以是一个标注任务，一个序列任务，或者一个语言生成任务。你对待每个用例的方式与对待文本或图像的方式相同。
- en: If you are labeling speech at the level of entire speech acts (called *intent*
    if you are labeling commands spoken to a smart device or similar object), your
    model is already focused on the phenomena you care about, as with object detection
    and sequence labeling. So the uncertainty sampling and model-based outliers should
    work on your speech data without cropping.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是在整个语音行为（如果你正在标注对智能设备或类似对象发出的命令，称为*意图*）级别进行语音标注，那么你的模型已经专注于你关心的现象，就像对象检测和序列标注一样。因此，不确定性采样和基于模型的异常值检测应该可以在你的语音数据上工作，而无需裁剪。
- en: If you are transcribing speech into text, or performing some other task that
    looks at error across the whole recording, this process is more similar to text
    generation, in which you want to focus on diversity to sample as many speech acts
    as possible. In pretty much every language of the world, the writing system is
    more standardized than the spoken language. So diversity becomes more important
    when you’re trying to capture every possible accent and language variation compared
    with working with text.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在将语音转录成文本，或执行一些查看整个录音错误的任务，这个过程更类似于文本生成，其中你希望关注多样性以采样尽可能多的语音行为。在世界上几乎每一种语言中，书写系统都比口语更标准化。因此，当你试图捕捉每一个可能的口音和语言变化时，与处理文本相比，多样性变得更加重要。
- en: Speech falls between text and images in terms of how much data collection technology
    matters. The quality of the microphone, ambient noise, recording device, file
    format, and compression techniques can all produce artifacts that your model could
    learn erroneously instead of the actual information.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据收集技术的重要性方面，语音介于文本和图像之间。麦克风的质量、环境噪声、录音设备、文件格式和压缩技术都可能产生模型可能错误学习而不是实际信息的伪影。
- en: More than any other data type covered here, speech differs most between its
    perceived structure and actual physical structure. You perceive gaps between words,
    for example, but that perception is an illusion, because real speech almost always
    runs words together. Almost every sound changes in immediate context, too. The
    English plural is *s* or *z* depending on the previous phoneme (*cats* and *dogz*),
    but you might have assumed that the plural suffix was only one sound. When you
    sample speech data, be careful not to rely only on text transcriptions of that
    speech.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里讨论的所有数据类型中，语音在感知结构和实际物理结构之间的差异最大。例如，你可能会感觉到单词之间的间隙，但这种感知是一种错觉，因为真实的语音几乎总是将单词连在一起。几乎每个声音都会在即时语境中发生变化。英语的复数形式是
    *s* 或 *z*，这取决于前面的音素（*cats* 和 *dogz*），但你可能认为复数后缀只有一个声音。当你采样语音数据时，请注意不要仅仅依赖于该语音的文本转录。
- en: 6.6 Choosing the right number of items for human review
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.6 选择合适数量的项目进行人工审查
- en: For advanced active learning techniques, the principles that you have already
    learned apply. You can make some of the active learning strategies, such as representative
    sampling, adaptive within an active learning iteration, but most combinations
    of techniques still produce the most benefit when you retrain the model with the
    newly annotated data.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 对于高级主动学习技术，你已经学到的原则同样适用。你可以在主动学习迭代中使一些主动学习策略，如代表性采样，自适应，但大多数技术组合在用新标注的数据重新训练模型时仍然能产生最大的效益。
- en: You probably need to sample a minimum number of items as a result of drawing
    from a certain number of clusters or stratification to real-world demographics.
    Your maximum number of items per iteration will vary depending on data type. You
    might be able to annotate locations in 1,000 short text messages per hour, but
    only complete semantic segmentation on 1 image over the same time period. So a
    big factor in your decision will be your data types and the annotation strategies
    that you are deploying--something that we’ll cover in chapters 7-12.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要从一定数量的聚类或分层中抽取一定数量的样本，以反映现实世界的受众。你每次迭代的最大样本数量将根据数据类型而变化。你可能每小时可以标注1,000条简短文本消息的位置，但在同一时间段内可能只能完成1张图像的完整语义分割。因此，你的决策中一个重要因素将是你的数据类型以及你正在部署的标注策略——这一点我们将在第7章至第12章中讨论。
- en: 6.6.1 Active labeling for fully or partially annotated data
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.1 对完全或部分标注数据的主动标注
- en: If your machine learning models can learn from partially annotated data, you
    are going to make your systems a lot more efficient. To continue the example we’ve
    used throughout this book, imagine that you are implementing an object detection
    model for city streets. Your model might be accurate enough to identify cars and
    pedestrians, but not accurate enough to identify bicycles and animals.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的机器学习模型可以从部分标注的数据中学习，你将使你的系统变得更加高效。继续我们在这本书中一直使用的例子，想象你正在为城市街道实现一个目标检测模型。你的模型可能足够准确以识别汽车和行人，但可能不足以识别自行车和动物。
- en: You might have thousands of images of bicycles and animals, but each image has
    dozens of cars and pedestrians on average too. Ideally, you’d like to be able
    to annotate only the bicycles and animals in those images and not spend more than
    10 times the resources to make sure that all the cars and pedestrians are also
    labeled in those same images. A lot of machine learning architectures don’t allow
    you to partially annotate data, however; they need to have every object annotated,
    because otherwise, those objects will erroneously count toward the background.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能拥有数千张自行车和动物的图像，但每张图像平均也有几十辆车和行人。理想情况下，你希望只标注那些图像中的自行车和动物，并且不超过10倍的资源来确保所有车和行人也被标注在同一图像中。然而，许多机器学习架构不允许你部分标注数据；它们需要每个对象都被标注，否则，那些对象将错误地计入背景。
- en: 'You might sample the 100 bicycles and animals that maximize confusion and diversity,
    but then spend most of your resources annotating 1,000 cars and pedestrians around
    them for relatively little extra gain. There is no shortcut: if you sample only
    images without many cars or pedestrians, you are biasing your data toward certain
    environments that are not representative of your entire dataset. If you are stuck
    with systems that need full annotation for every image or document, you want to
    be extra-careful to ensure that you are sampling the highest-value items every
    time.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会选择那些最大化混淆和多样性的100辆自行车和动物进行采样，但随后会花费大部分资源标注它们周围的1,000辆车和行人，而得到的额外收益相对较少。没有捷径可走：如果你只采样没有很多车或行人的图像，你就是在使数据偏向某些不具代表性的环境，这些环境不能代表你的整个数据集。如果你遇到需要为每张图像或文档进行完整标注的系统，你想要格外小心，确保每次都采样价值最高的项目。
- en: Increasingly, it is easier to combine different models or have heterogeneous
    training data. You might be able to train separate models for pedestrians and
    cars, and then have a model that combines them via transfer learning.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 越来越容易结合不同的模型或拥有异构的训练数据。你可能能够为行人和车辆训练单独的模型，然后通过迁移学习将它们结合起来。
- en: 6.6.2 Combining machine learning with annotation
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.6.2 将机器学习与标注相结合
- en: You should take these options into account when designing your annotation and
    model strategies, because you might find that a slightly less accurate machine
    learning architecture will end up producing much more accurate models when you
    are not constrained to annotating images entirely or not at all.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计你的标注和模型策略时，你应该考虑这些选项，因为你可能会发现，一个略微不精确的机器学习架构，当你不受限于完全或不标注图像时，最终会产生更精确的模型。
- en: The best solution to the problem of needing to annotate only a few objects/spans
    in a large image/document is to incorporate machine learning into the annotation
    process. It might take an hour to annotate an entire image for semantic segmentation,
    but only 30 seconds to accept/reject every annotation. The danger when combining
    predictions and human annotation is that the people might be primed to trust a
    prediction that was not correct, therefore perpetuating an existing bias. This
    situation is a complicated human-computer interaction problem. Chapters 9, 10,
    and 11 cover the problem of combining model predictions and human annotations
    in the most effective ways possible.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 解决在大图像/文档中仅需要标注少数对象/跨度的最佳方法是将机器学习融入标注过程。进行语义分割时，标注整个图像可能需要一个小时，但接受/拒绝每项标注可能只需30秒。当结合预测和人工标注时，危险在于人们可能会被引导去信任一个不正确的预测，从而延续现有的偏差。这种情况是一个复杂的人机交互问题。第9章、第10章和第11章介绍了以最有效的方式结合模型预测和人工标注的问题。
- en: 6.7 Further reading
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.7 进一步阅读
- en: For more information about calculating confidence for sequence labeling and
    sequence generation, see “Modeling Confidence in Sequence-to-Sequence Models,”
    by Jan Niehues and Ngoc-Quan Pham ([http://mng.bz/9Mqo](http://mng.bz/9Mqo)).
    The authors look at speech recognition and also extend the machine translation
    problem in an interesting way by calculating confidence (uncertainty) on the source
    text tokens, not only the predicted tokens.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 关于计算序列标注和序列生成的置信度，请参阅Jan Niehues和Ngoc-Quan Pham的“在序列到序列模型中建模置信度”（[http://mng.bz/9Mqo](http://mng.bz/9Mqo)）。作者们研究了语音识别，并通过在源文本标记上计算置信度（不确定性）而不是仅预测标记，以有趣的方式扩展了机器翻译问题。
- en: For an overview of active learning techniques for machine translation, see “Empirical
    Evaluation of Active Learning Techniques for Neural MT,” by Xiangkai Zeng, Sarthak
    Garg, Rajen Chatterjee, Udhyakumar Nallasamy, and Matthias Paulik ([http://mng.bz/j4Np](http://mng.bz/j4Np)).
    Many of the techniques in this paper can be applied to other sequence generation
    tasks.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 有关机器翻译活动学习技术的概述，请参阅“神经机器翻译活动学习技术的实证评估”，由Xiangkai Zeng、Sarthak Garg、Rajen Chatterjee、Udhyakumar
    Nallasamy和Matthias Paulik所著 ([http://mng.bz/j4Np](http://mng.bz/j4Np))。本文中的许多技术可以应用于其他序列生成任务。
- en: Summary
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In many use cases, you want to identify or extract information within an image
    or document rather than label the entire image or document. The same active learning
    strategies can be applied to these use cases. Understanding the right strategy
    helps you understand the kinds of problems to which you can apply active learning
    and how to build the right strategy for your use case.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在许多用例中，您希望在图像或文档中识别或提取信息，而不是对整个图像或文档进行标记。相同的活动学习策略可以应用于这些用例。了解正确的策略有助于您了解可以应用活动学习的问题类型以及如何为您的用例构建正确的策略。
- en: You need to crop or mask your images and documents to get the most out of some
    active learning strategies. The right cropping or masking strategy produces better
    samples for human review, and understanding when you need to crop or mask your
    items helps you select the right method for your use cases.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要裁剪或遮罩您的图像和文档，以充分利用某些活动学习策略。正确的裁剪或遮罩策略会产生更好的样本供人工审查，了解何时需要裁剪或遮罩您的项目有助于您选择适合您用例的正确方法。
- en: Active learning can be applied to many tasks beyond computer vision and NLP,
    including information retrieval, speech recognition, and videos. Understanding
    the broader landscape of active learning application areas will help you adapt
    any machine learning problem.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活动学习可以应用于许多超出计算机视觉和自然语言处理的任务，包括信息检索、语音识别和视频。了解活动学习应用领域的更广泛景观将帮助您适应任何机器学习问题。
- en: The number of items to select for human review in each iteration of advanced
    active learning is highly specific to your data. Understanding the right strategy
    for your data is important for deploying the most efficient human-in-the-loop
    machine learning systems for your problems.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在高级活动学习的每一轮中，为人工审查选择的项目数量非常具体，取决于您的数据。了解适合您数据的正确策略对于部署最有效的人机交互机器学习系统对于您的问题至关重要。
- en: '* * *'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '^(1.)“Why Should I Trust You?”: Explaining the Predictions of Any Classifier,”
    by Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin ([https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf
    ).](https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: ^（1）“我应该信任你的预测吗？”：解释任何分类器的预测，由Marco Tulio Ribeiro、Sameer Singh和Carlos Guestrin所著
    ([https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf](https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf)。
- en: ^(2.)“Analyzing Uncertainty in Neural Machine Translation,” by Myle Ott, Michael
    Auli, David Grangier, and Marc’Aurelio Ranzato ([https://arxiv.org/abs/1803.00047](https://arxiv.org/abs/1803.00047)).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: ^（2）“分析神经机器翻译中的不确定性”，由Myle Ott、Michael Auli、David Grangier和Marc’Aurelio Ranzato所著
    ([https://arxiv.org/abs/1803.00047](https://arxiv.org/abs/1803.00047)。
- en: ^(3.)“Detecting Independent Pronoun Bias with Partially-Synthetic Data Generation,”
    by Robert (Munro) Monarch and Alex (Carmen) Morrison ([https://www.aclweb.org/anthology/2020.emnlp-main.157.pdf](https://www.aclweb.org/anthology/2020.emnlp-main.157.pdf)).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: ^（3）“使用部分合成数据生成检测独立代词偏差”，由Robert (Munro) Monarch和Alex (Carmen) Morrison所著 ([https://www.aclweb.org/anthology/2020.emnlp-main.157.pdf](https://www.aclweb.org/anthology/2020.emnlp-main.157.pdf))。
- en: ^(4.)“A Theoretical Analysis of NDCG Type Ranking Measures,” by Yining Wang,
    Liwei Wang, Yuanzhi Li, Di He, Wei Chen, and Tie-Yan Liu ([https://arxiv.org/abs/1304.6480](https://arxiv.org/abs/1304.6480)).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: ^（4）“NDCG类型排名度量理论分析”，由Yining Wang、Liwei Wang、Yuanzhi Li、Di He、Wei Chen和Tie-Yan
    Liu所著 ([https://arxiv.org/abs/1304.6480](https://arxiv.org/abs/1304.6480)。
