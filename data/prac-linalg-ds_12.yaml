- en: Chapter 12\. Least Squares Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬12ç«  æœ€å°äºŒä¹˜æ³•åº”ç”¨
- en: In this chapter, you will see a few applications of least squares model fitting
    in real data. Along the way, you will learn how to implement least squares using
    several differentâ€”and more numerically stableâ€”Python functions, and you will learn
    some new concepts in statistics and machine learning such as multicollinearity,
    polynomial regression, and the grid search algorithm as an alternative to least
    squares.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°æœ€å°äºŒä¹˜æ¨¡å‹æ‹Ÿåˆåœ¨çœŸå®æ•°æ®ä¸­çš„å‡ ä¸ªåº”ç”¨ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨å‡ ç§ä¸åŒâ€”â€”æ›´åŠ æ•°å€¼ç¨³å®šçš„Pythonå‡½æ•°å®ç°æœ€å°äºŒä¹˜æ³•ï¼Œå¹¶å­¦ä¹ ç»Ÿè®¡å­¦å’Œæœºå™¨å­¦ä¹ ä¸­çš„ä¸€äº›æ–°æ¦‚å¿µï¼Œå¦‚å¤šé‡å…±çº¿æ€§ã€å¤šé¡¹å¼å›å½’ä»¥åŠç½‘æ ¼æœç´¢ç®—æ³•ä½œä¸ºæœ€å°äºŒä¹˜æ³•çš„æ›¿ä»£æ–¹æ³•ã€‚
- en: By the end of this chapter, you will have a deeper understanding of how least
    squares is used in applications, including the importance of numerically stable
    algorithms for â€œdifficultâ€ situations involving reduced-rank design matrices.
    And you will see that the analytic solution provided by least squares outperforms
    an empirical parameter search method.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œæ‚¨å°†æ›´æ·±å…¥åœ°äº†è§£æœ€å°äºŒä¹˜æ³•åœ¨åº”ç”¨ä¸­çš„ä½¿ç”¨ï¼ŒåŒ…æ‹¬åœ¨æ¶‰åŠé™ç§©è®¾è®¡çŸ©é˜µçš„â€œå›°éš¾â€æƒ…å†µä¸­ï¼Œæ•°å€¼ç¨³å®šç®—æ³•çš„é‡è¦æ€§ã€‚æ‚¨å°†çœ‹åˆ°ï¼Œæœ€å°äºŒä¹˜æ³•æä¾›çš„è§£æè§£ä¼˜äºç»éªŒå‚æ•°æœç´¢æ–¹æ³•ã€‚
- en: Predicting Bike Rentals Based on Weather
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŸºäºå¤©æ°”é¢„æµ‹è‡ªè¡Œè½¦ç§Ÿèµ
- en: Iâ€™m a big fan of bicycles and a big fan of bibimbap (a Korean dish made with
    rice and veggies or meat). Therefore, I was happy to find a publicly available
    dataset about bike rentals in Seoul.^([1](ch12.xhtml#idm45733294729312)) The dataset
    contains nearly nine thousand observations of data about the number of bikes that
    were rented in the city and variables about the weather including temperature,
    humidity, rainfall, windspeed, and so on.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘æ˜¯è‡ªè¡Œè½¦å’ŒéŸ©å›½æ‹Œé¥­ï¼ˆä¸€é“ç”¨ç±³é¥­ã€è”¬èœæˆ–è‚‰ç±»åˆ¶ä½œçš„éŸ©å›½èœï¼‰çš„é“æ†ç²‰ä¸ã€‚å› æ­¤ï¼Œæˆ‘å¾ˆé«˜å…´åœ¨é¦–å°”æ‰¾åˆ°äº†ä¸€ä¸ªå…¬å¼€å¯ç”¨çš„å…³äºè‡ªè¡Œè½¦ç§Ÿèµçš„æ•°æ®é›†ã€‚^([1](ch12.xhtml#idm45733294729312))
    è¿™ä¸ªæ•°æ®é›†åŒ…å«äº†è¿‘ä¹åƒæ¡æ•°æ®è§‚æµ‹ï¼Œæ¶‰åŠåŸå¸‚ä¸­ç§Ÿèµè‡ªè¡Œè½¦æ•°é‡ä»¥åŠä¸å¤©æ°”ç›¸å…³çš„å˜é‡ï¼Œå¦‚æ¸©åº¦ã€æ¹¿åº¦ã€é™é›¨é‡ã€é£é€Ÿç­‰ç­‰ã€‚
- en: The purpose of the dataset is to predict the demand for bike sharing based on
    weather and season. That is important because it will help bike rental companies
    and local governments optimize the availability of healthier modes of transportation.
    Itâ€™s a great dataset, thereâ€™s a lot that could be done with it, and I encourage
    you to spend time exploring it. In this chapter, I will focus on building relatively
    simple regression models to predict bike rental counts based on a few features.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: æ•°æ®é›†çš„ç›®çš„æ˜¯åŸºäºå¤©æ°”å’Œå­£èŠ‚é¢„æµ‹å…±äº«å•è½¦çš„éœ€æ±‚ã€‚è¿™ä¸€ç‚¹éå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒå°†å¸®åŠ©è‡ªè¡Œè½¦ç§Ÿèµå…¬å¸å’Œåœ°æ–¹æ”¿åºœä¼˜åŒ–æ›´å¥åº·çš„äº¤é€šæ–¹å¼çš„å¯ç”¨æ€§ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„æ•°æ®é›†ï¼Œæœ‰å¾ˆå¤šå¯ä»¥åšçš„äº‹æƒ…ï¼Œæˆ‘é¼“åŠ±æ‚¨èŠ±æ—¶é—´æ¢ç´¢å®ƒã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘å°†é‡ç‚¹ä»‹ç»åŸºäºå°‘æ•°ç‰¹å¾é¢„æµ‹è‡ªè¡Œè½¦ç§Ÿèµæ•°é‡çš„ç›¸å¯¹ç®€å•çš„å›å½’æ¨¡å‹å»ºç«‹ã€‚
- en: Although this is a book on linear algebra and not statistics, it is still important
    to inspect the data carefully before applying and interpreting statistical analyses.
    The online code has more details about importing and inspecting the data using
    the pandas library. [FigureÂ 12-1](#fig_12_1) shows the data from bike count rentals
    (the dependent variable) and rainfall (one of the independent variables).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™æ˜¯ä¸€æœ¬å…³äºçº¿æ€§ä»£æ•°è€Œéç»Ÿè®¡å­¦çš„ä¹¦ç±ï¼Œä½†åœ¨åº”ç”¨å’Œè§£é‡Šç»Ÿè®¡åˆ†æä¹‹å‰ä»ç„¶é‡è¦ä»”ç»†æ£€æŸ¥æ•°æ®ã€‚åœ¨çº¿ä»£ç æœ‰å…³ä½¿ç”¨pandasåº“å¯¼å…¥å’Œæ£€æŸ¥æ•°æ®çš„è¯¦ç»†ä¿¡æ¯ã€‚[å›¾12-1](#fig_12_1)
    å±•ç¤ºäº†è‡ªè¡Œè½¦è®¡æ•°ç§Ÿèµæ•°æ®ï¼ˆå› å˜é‡ï¼‰å’Œé™é›¨é‡ï¼ˆå…¶ä¸­ä¸€ä¸ªè‡ªå˜é‡ï¼‰ã€‚
- en: '![Korean bike rental data](assets/plad_1201.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![éŸ©å›½è‡ªè¡Œè½¦ç§Ÿèµæ•°æ®](assets/plad_1201.png)'
- en: Figure 12-1\. Scatterplots of some data
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾12-1 æ•£ç‚¹å›¾å±•ç¤ºäº†ä¸€äº›æ•°æ®
- en: Notice that rainfall is a sparse variableâ€”itâ€™s mostly zeros with a relatively
    small number of nonzero values. Weâ€™ll come back to this in the exercises.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œé™é›¨é‡æ˜¯ä¸€ä¸ªç¨€ç–å˜é‡â€”â€”å¤§éƒ¨åˆ†æ˜¯é›¶ï¼Œåªæœ‰å°‘é‡éé›¶å€¼ã€‚æˆ‘ä»¬å°†åœ¨ç»ƒä¹ ä¸­å†æ¬¡å›é¡¾è¿™ä¸€ç‚¹ã€‚
- en: '[FigureÂ 12-2](#fig_12_2) shows a correlation matrix from four selected variables.
    Inspecting correlation matrices is always a good idea before starting statistical
    analyses, because it will show which variables (if any) are correlated and can
    reveal errors in the data (e.g., if two supposedly different variables are perfectly
    correlated). In this case, we see that bike rental count is positively correlated
    with *hour* and *temperature* (people rent more bikes later in the day and when
    the weather is warmer) and negatively correlated with *rainfall*. (Note that Iâ€™m
    not showing statistical significance here, so these interpretations are qualitative.)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 12-2](#fig_12_2) å±•ç¤ºäº†å››ä¸ªé€‰å®šå˜é‡çš„ç›¸å…³çŸ©é˜µã€‚åœ¨å¼€å§‹ç»Ÿè®¡åˆ†æä¹‹å‰æ£€æŸ¥ç›¸å…³çŸ©é˜µæ€»æ˜¯ä¸ªå¥½ä¸»æ„ï¼Œå› ä¸ºå®ƒå°†æ˜¾ç¤ºå“ªäº›å˜é‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ç›¸å…³ï¼Œå¹¶ä¸”å¯ä»¥æ˜¾ç¤ºæ•°æ®ä¸­çš„é”™è¯¯ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœä¸¤ä¸ªçœ‹ä¼¼ä¸åŒçš„å˜é‡å®Œå…¨ç›¸å…³ï¼‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çœ‹åˆ°è‡ªè¡Œè½¦ç§Ÿèµæ¬¡æ•°ä¸*å°æ—¶*å’Œ*æ¸©åº¦*å‘ˆæ­£ç›¸å…³ï¼ˆäººä»¬åœ¨ä¸€å¤©åæœŸå’Œå¤©æ°”æ›´æš–æ—¶ç§Ÿæ›´å¤šè‡ªè¡Œè½¦ï¼‰ï¼Œä¸*é™é›¨é‡*å‘ˆè´Ÿç›¸å…³ã€‚ï¼ˆè¯·æ³¨æ„ï¼Œæˆ‘è¿™é‡Œæ²¡æœ‰å±•ç¤ºç»Ÿè®¡æ˜¾è‘—æ€§ï¼Œå› æ­¤è¿™äº›è§£é‡Šæ˜¯å®šæ€§çš„ã€‚ï¼‰'
- en: '![Correlation matrix](assets/plad_1202.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![ç›¸å…³çŸ©é˜µ](assets/plad_1202.png)'
- en: Figure 12-2\. Correlation matrix of four selected variables
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 12-2\. å››ä¸ªé€‰å®šå˜é‡çš„ç›¸å…³çŸ©é˜µ
- en: In the first analysis, I want to predict bike rental counts based on rainfall
    and the seasons. The seasons (winter, spring, summer, fall) are text labels in
    the dataset, and we need to convert them to numbers for the analysis. We could
    translate the four seasons into the numbers 1â€“4, but seasons are circular while
    regressions are linear. There are a few ways to deal with this, including using
    an ANOVA instead of a regression, using one-hot-encoding (used in deep learning
    models), or binarizing the seasons. Iâ€™m going to take the latter approach and
    label autumn and winter â€œ0â€ and spring and summer â€œ1â€. The interpretation is that
    a positive beta coefficient indicates more bike rentals in spring/summer compared
    to autumn/winter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç¬¬ä¸€æ¬¡åˆ†æä¸­ï¼Œæˆ‘æƒ³åŸºäºé™é›¨é‡å’Œå­£èŠ‚æ¥é¢„æµ‹è‡ªè¡Œè½¦ç§Ÿèµæ¬¡æ•°ã€‚å­£èŠ‚ï¼ˆå†¬å­£ã€æ˜¥å­£ã€å¤å­£ã€ç§‹å­£ï¼‰æ˜¯æ•°æ®é›†ä¸­çš„æ–‡æœ¬æ ‡ç­¾ï¼Œæˆ‘ä»¬éœ€è¦å°†å®ƒä»¬è½¬æ¢ä¸ºæ•°å­—è¿›è¡Œåˆ†æã€‚æˆ‘ä»¬å¯ä»¥å°†å››å­£è½¬æ¢ä¸ºæ•°å­—
    1â€“4ï¼Œä½†å­£èŠ‚æ˜¯å¾ªç¯çš„ï¼Œè€Œå›å½’æ˜¯çº¿æ€§çš„ã€‚æœ‰å‡ ç§å¤„ç†æ–¹å¼ï¼ŒåŒ…æ‹¬ä½¿ç”¨æ–¹å·®åˆ†æï¼ˆANOVAï¼‰ä»£æ›¿å›å½’ï¼Œä½¿ç”¨ç‹¬çƒ­ç¼–ç ï¼ˆåœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ä½¿ç”¨ï¼‰ï¼Œæˆ–è€…å¯¹å­£èŠ‚è¿›è¡ŒäºŒå€¼åŒ–å¤„ç†ã€‚æˆ‘å°†é‡‡å–åè€…çš„æ–¹æ³•ï¼Œå¹¶å°†ç§‹å­£å’Œå†¬å­£æ ‡è®°ä¸ºâ€œ0â€ï¼Œæ˜¥å­£å’Œå¤å­£æ ‡è®°ä¸ºâ€œ1â€ã€‚è§£é‡Šæ˜¯ï¼Œæ­£çš„
    beta ç³»æ•°è¡¨æ˜æ˜¥å¤å­£èŠ‚çš„è‡ªè¡Œè½¦ç§Ÿèµæ¬¡æ•°æ¯”ç§‹å†¬å­£èŠ‚è¦å¤šã€‚
- en: '(Tangential note: on the one hand, I could have made things simpler by selecting
    only continuous variables. But I want to stress that there is more to data science
    than just applying a formula to a dataset; there are many nontrivial decisions
    that affect the kinds of analyses you can do, and therefore the kinds of results
    you can obtain.)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ï¼ˆæ—æ³¨ï¼šä¸€æ–¹é¢ï¼Œæˆ‘æœ¬å¯ä»¥é€šè¿‡é€‰æ‹©ä»…è¿ç»­å˜é‡æ¥ç®€åŒ–äº‹æƒ…ã€‚ä½†æ˜¯æˆ‘æƒ³å¼ºè°ƒçš„æ˜¯ï¼Œæ•°æ®ç§‘å­¦ä¸ä»…ä»…æ˜¯å°†å…¬å¼åº”ç”¨äºæ•°æ®é›†ï¼›æœ‰è®¸å¤šéå¹³å‡¡çš„å†³ç­–ä¼šå½±å“æ‚¨å¯ä»¥è¿›è¡Œçš„åˆ†æç±»å‹ï¼Œä»è€Œå½±å“æ‚¨å¯ä»¥è·å¾—çš„ç»“æœã€‚ï¼‰
- en: The left side of [FigureÂ 12-3](#fig_12_3) shows the design matrix visualized
    as an image. This is a common representation of the design matrix, so make sure
    you are comfortable interpreting it. The columns are regressors and the rows are
    observations. Columns are sometimes normalized to facilitate visual interpretation
    if the regressors are in very different numerical scales, although I didnâ€™t do
    that here. You can see that rainfall is sparse and that the dataset spans two
    autumn/winter periods (black areas in the middle column) and one spring/summer
    period (white area in the middle). The intercept is, of course, solid white, because
    it takes the same value for every observation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 12-3](#fig_12_3) çš„å·¦ä¾§å±•ç¤ºäº†è®¾è®¡çŸ©é˜µçš„å›¾åƒåŒ–è¡¨ç¤ºã€‚è¿™æ˜¯è®¾è®¡çŸ©é˜µçš„å¸¸è§è¡¨ç¤ºæ–¹å¼ï¼Œå› æ­¤è¯·ç¡®ä¿æ‚¨èƒ½å¤Ÿèˆ’é€‚åœ°è§£é‡Šå®ƒã€‚åˆ—æ˜¯å›å½’å™¨ï¼Œè¡Œæ˜¯è§‚å¯Ÿç»“æœã€‚å¦‚æœå›å½’å™¨å¤„äºéå¸¸ä¸åŒçš„æ•°å€¼å°ºåº¦ï¼Œæœ‰æ—¶ä¼šå¯¹åˆ—è¿›è¡Œå½’ä¸€åŒ–ä»¥ä¾¿äºè§†è§‰è§£é‡Šï¼Œå°½ç®¡æˆ‘åœ¨è¿™é‡Œæ²¡æœ‰è¿™æ ·åšã€‚æ‚¨å¯ä»¥çœ‹åˆ°é™é›¨å¾ˆç¨€ç–ï¼Œå¹¶ä¸”æ•°æ®é›†è·¨è¶Šäº†ä¸¤ä¸ªç§‹å†¬å­£èŠ‚ï¼ˆä¸­é—´åˆ—çš„é»‘è‰²åŒºåŸŸï¼‰å’Œä¸€ä¸ªæ˜¥å¤å­£èŠ‚ï¼ˆä¸­é—´çš„ç™½è‰²åŒºåŸŸï¼‰ã€‚æˆªè·å½“ç„¶æ˜¯çº¯ç™½è‰²ï¼Œå› ä¸ºå®ƒå¯¹æ¯ä¸ªè§‚å¯Ÿç»“æœéƒ½é‡‡ç”¨ç›¸åŒçš„å€¼ã€‚'
- en: '![Design matrix](assets/plad_1203.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![è®¾è®¡çŸ©é˜µ](assets/plad_1203.png)'
- en: Figure 12-3\. Design matrix and some data
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾ 12-3\. è®¾è®¡çŸ©é˜µå’Œä¸€äº›æ•°æ®
- en: The right side of [FigureÂ 12-3](#fig_12_3) shows the data, plotted as rainfall
    by bikes rented separately for the two seasons. Clearly, the data do not lie on
    a line, because there are many values at or close to zero on both axes. In other
    words, visually inspecting the data suggests that the relationships amongst the
    variables are nonlinear, which means that a linear modeling approach might be
    suboptimal. Again, this highlights the importance of visually inspecting data
    and carefully selecting an appropriate statistical model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 12-3](#fig_12_3)çš„å³ä¾§æ˜¾ç¤ºäº†æ•°æ®ï¼Œå°†é™é›¨é‡å’Œç§Ÿèµè‡ªè¡Œè½¦åˆ†åˆ«ç»˜åˆ¶åœ¨ä¸¤ä¸ªå­£èŠ‚ä¸Šã€‚æ˜¾ç„¶ï¼Œæ•°æ®ä¸åœ¨ä¸€æ¡ç›´çº¿ä¸Šï¼Œå› ä¸ºä¸¤ä¸ªåæ ‡è½´ä¸Šéƒ½æœ‰è®¸å¤šæ¥è¿‘æˆ–ç­‰äºé›¶çš„å€¼ã€‚æ¢å¥è¯è¯´ï¼Œé€šè¿‡è§†è§‰æ£€æŸ¥æ•°æ®è¡¨æ˜å˜é‡ä¹‹é—´çš„å…³ç³»æ˜¯éçº¿æ€§çš„ï¼Œè¿™æ„å‘³ç€çº¿æ€§å»ºæ¨¡æ–¹æ³•å¯èƒ½ä¸å¤Ÿä¼˜åŒ–ã€‚å†æ¬¡å¼ºè°ƒï¼Œè§†è§‰æ£€æŸ¥æ•°æ®å’Œä»”ç»†é€‰æ‹©åˆé€‚çš„ç»Ÿè®¡æ¨¡å‹çš„é‡è¦æ€§ã€‚'
- en: 'Nonetheless, we will forge ahead using a linear model fit to the data using
    least squares. The following code shows how I created the design matrix (variable
    `data` is a pandas dataframe):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å¦‚æ­¤ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æœ€å°äºŒä¹˜æ³•æ‹Ÿåˆçš„çº¿æ€§æ¨¡å‹ç»§ç»­å‰è¿›ã€‚ä»¥ä¸‹ä»£ç å±•ç¤ºäº†æˆ‘å¦‚ä½•åˆ›å»ºè®¾è®¡çŸ©é˜µï¼ˆå˜é‡`data`æ˜¯ä¸€ä¸ª pandas æ•°æ®å¸§ï¼‰ï¼š
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The beta values for *rainfall* and *season* are, respectively, âˆ’80 and 369\.
    These numbers indicate that there are fewer bike rentals when it rains and that
    there are more bike rentals in the spring/summer compared to autumn/winter.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*é™é›¨é‡*å’Œ*å­£èŠ‚*çš„Î²å€¼åˆ†åˆ«ä¸ºâˆ’80å’Œ369ã€‚è¿™äº›æ•°å­—è¡¨æ˜ï¼Œä¸‹é›¨æ—¶è‡ªè¡Œè½¦ç§Ÿèµè¾ƒå°‘ï¼Œæ˜¥å­£/å¤å­£æ¯”ç§‹å­£/å†¬å­£ç§Ÿèµæ›´å¤šã€‚'
- en: '[FigureÂ 12-4](#fig_12_4) shows the predicted versus the observed data, separated
    for the two seasons. If the model were a perfect fit to the data, the dots would
    lie on a diagonal line with a slope of 1\. Clearly, thatâ€™s not the case, meaning
    that the model did not fit the data very well. Indeed, the *R*Â² is a paltry 0.097
    (in other words, the statistical model accounts for around 1% of the variance
    in the data). Futhermore, you can see that the model predicts *negative* bike
    rentals, which is not interpretableâ€”bike rental counts are strictly nonnegative
    numbers.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 12-4](#fig_12_4)æ˜¾ç¤ºäº†é¢„æµ‹ä¸è§‚å¯Ÿæ•°æ®çš„å¯¹æ¯”ï¼Œåˆ†åˆ«é’ˆå¯¹ä¸¤ä¸ªå­£èŠ‚ã€‚å¦‚æœæ¨¡å‹å®Œå…¨æ‹Ÿåˆæ•°æ®ï¼Œç‚¹åº”è¯¥åœ¨å…·æœ‰æ–œç‡1çš„å¯¹è§’çº¿ä¸Šã€‚æ˜¾ç„¶ï¼Œæƒ…å†µå¹¶éå¦‚æ­¤ï¼Œè¿™æ„å‘³ç€æ¨¡å‹å¹¶æœªå¾ˆå¥½åœ°æ‹Ÿåˆæ•°æ®ã€‚äº‹å®ä¸Šï¼Œ*R*Â²ä»…ä¸º0.097ï¼ˆæ¢å¥è¯è¯´ï¼Œç»Ÿè®¡æ¨¡å‹è§£é‡Šæ•°æ®å˜å¼‚çº¦ä¸º1%ï¼‰ã€‚æ­¤å¤–ï¼Œä½ å¯ä»¥çœ‹åˆ°æ¨¡å‹é¢„æµ‹å‡ºäº†*è´Ÿ*è‡ªè¡Œè½¦ç§Ÿèµæ•°é‡ï¼Œè¿™æ˜¯æ— æ³•è§£é‡Šçš„â€”â€”è‡ªè¡Œè½¦ç§Ÿèµæ•°é‡ä¸¥æ ¼æ¥è¯´æ˜¯éè´Ÿæ•°ã€‚'
- en: '![Predicted and observed data](assets/plad_1204.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![é¢„æµ‹ä¸è§‚å¯Ÿæ•°æ®](assets/plad_1204.png)'
- en: Figure 12-4\. Scatterplot of predicted by observed data
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾12-4ã€‚é¢„æµ‹ä¸è§‚å¯Ÿæ•°æ®çš„æ•£ç‚¹å›¾
- en: Thus far in the code, we have received no warnings or errors; we have done nothing
    wrong in terms of math or coding. However, the statistical model we used is not
    the most appropriate for this research question. You will have the opportunity
    to improve it in [Exercise 12-1](#exercise_12_1) and [Exercise 12-2](#exercise_12_2).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°ç›®å‰ä¸ºæ­¢ï¼Œåœ¨ä»£ç ä¸­æˆ‘ä»¬æ²¡æœ‰æ”¶åˆ°ä»»ä½•è­¦å‘Šæˆ–é”™è¯¯ï¼›åœ¨æ•°å­¦æˆ–ç¼–ç æ–¹é¢æˆ‘ä»¬æ²¡æœ‰åšé”™ä»»ä½•äº‹æƒ…ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä½¿ç”¨çš„ç»Ÿè®¡æ¨¡å‹å¹¶ä¸é€‚åˆè¿™ä¸ªç ”ç©¶é—®é¢˜ã€‚ä½ å°†æœ‰æœºä¼šåœ¨[ç»ƒä¹ 
    12-1](#exercise_12_1)å’Œ[ç»ƒä¹  12-2](#exercise_12_2)ä¸­æ”¹è¿›å®ƒã€‚
- en: Regression Table Using statsmodels
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ statsmodels çš„å›å½’è¡¨
- en: 'Without getting too deep into the statistics, I want to show you how to create
    a regression table using the statsmodels library. This library works with pandas
    dataframes instead of NumPy arrays. The following code shows how to set up and
    compute the regression model (OLS stands for *ordinary least squares*):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ·±å…¥ç»Ÿè®¡å­¦ï¼Œæˆ‘æƒ³å‘ä½ å±•ç¤ºå¦‚ä½•ä½¿ç”¨ statsmodels åº“åˆ›å»ºå›å½’è¡¨ã€‚è¯¥åº“ä½¿ç”¨ pandas æ•°æ®å¸§è€Œä¸æ˜¯ NumPy æ•°ç»„ã€‚ä»¥ä¸‹ä»£ç å±•ç¤ºäº†å¦‚ä½•è®¾ç½®å’Œè®¡ç®—å›å½’æ¨¡å‹ï¼ˆOLSä»£è¡¨*æ™®é€šæœ€å°äºŒä¹˜æ³•*ï¼‰ï¼š
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The regression table contains a lot of information. Itâ€™s OK if you donâ€™t understand
    all of it; the key items you can look for are the *R*Â² and the regression coefficients
    (`coef`) for the regressors:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: å›å½’è¡¨åŒ…å«å¤§é‡ä¿¡æ¯ã€‚å¦‚æœä½ ä¸ç†è§£å…¨éƒ¨å†…å®¹ï¼Œæ²¡å…³ç³»ï¼›ä½ å¯ä»¥æŸ¥çœ‹çš„å…³é”®é¡¹ç›®æ˜¯*R*Â²å’Œå›å½’ç³»æ•°(`coef`)ï¼š
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Multicollinearity
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤šé‡å…±çº¿æ€§
- en: If youâ€™ve taken a statistics course, you might have heard of the term *multicollinearity*.
    The Wikipedia definition is â€œone predictor variable in a multiple regression model
    can be linearly predicted from the others with a substantial degree of accuracy.â€^([2](ch12.xhtml#idm45733294283376))
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å­¦è¿‡ç»Ÿè®¡è¯¾ç¨‹ï¼Œå¯èƒ½å¬è¯´è¿‡*å¤šé‡å…±çº¿æ€§*è¿™ä¸ªæœ¯è¯­ã€‚ç»´åŸºç™¾ç§‘çš„å®šä¹‰æ˜¯ï¼šâ€œå¤šå…ƒå›å½’æ¨¡å‹ä¸­çš„ä¸€ä¸ªé¢„æµ‹å˜é‡å¯ä»¥é€šè¿‡å…¶ä»–å˜é‡è¿›è¡Œçº¿æ€§é¢„æµ‹ï¼Œå¹¶ä¸”é¢„æµ‹ç²¾åº¦ç›¸å½“é«˜ã€‚â€^([2](ch12.xhtml#idm45733294283376))
- en: This means that there are linear dependencies in the design matrix. In the parlance
    of linear algebra, multicollinearity is just a fancy term for *linear dependence*,
    which is the same thing as saying that the design matrix is reduced-rank or that
    it is singular.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ„å‘³ç€è®¾è®¡çŸ©é˜µä¸­å­˜åœ¨çº¿æ€§ä¾èµ–å…³ç³»ã€‚åœ¨çº¿æ€§ä»£æ•°ä¸­ï¼Œå¤šé‡å…±çº¿æ€§åªæ˜¯*çº¿æ€§ä¾èµ–*çš„ä¸€ä¸ªèŠ±å“¨æœ¯è¯­ï¼Œæ„æ€æ˜¯è®¾è®¡çŸ©é˜µæ˜¯é™ç§©çš„æˆ–è€…æ˜¯å¥‡å¼‚çš„ã€‚
- en: A reduced-rank design matrix does not have a left-inverse, which means that
    the least squares problem cannot be solved analytically. You will see the implications
    of multicollinearity in [Exercise 12-3](#exercise_12_3).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: é™ç§©çš„è®¾è®¡çŸ©é˜µæ²¡æœ‰å·¦é€†ï¼Œè¿™æ„å‘³ç€æ— æ³•é€šè¿‡è§£ææ–¹æ³•è§£å†³æœ€å°äºŒä¹˜é—®é¢˜ã€‚ä½ å°†åœ¨[Exercise 12-3](#exercise_12_3)ä¸­çœ‹åˆ°å¤šé‡å…±çº¿æ€§çš„å½±å“ã€‚
- en: Regularization
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­£åˆ™åŒ–
- en: '*Regularization* is an umbrella term that refers to various ways of modifying
    a statistical model, with the goal of improving numerical stability, transforming
    singular or ill-conditioned matrices to full-rank (and thus invertible), or improving
    generalizability by reducing overfitting. There are several forms of regularization
    depending on the nature of the problem and the goal of regularizing; some specific
    techniques you might have heard of include Ridge (a.k.a. L2), Lasso (a.k.a. L1),
    Tikhonov, and shrinkage.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*æ­£åˆ™åŒ–*æ˜¯ä¸€ä¸ªç»Ÿç§°ï¼ŒæŒ‡çš„æ˜¯é€šè¿‡å„ç§æ–¹å¼ä¿®æ”¹ç»Ÿè®¡æ¨¡å‹ï¼Œä»¥æé«˜æ•°å€¼ç¨³å®šæ€§ï¼Œå°†å¥‡å¼‚æˆ–ç—…æ€çŸ©é˜µè½¬æ¢ä¸ºæ»¡ç§©ï¼ˆä»è€Œå¯é€†ï¼‰ï¼Œæˆ–é€šè¿‡å‡å°‘è¿‡æ‹Ÿåˆæ¥æé«˜æ³›åŒ–èƒ½åŠ›çš„ç›®çš„ã€‚æ ¹æ®é—®é¢˜çš„æ€§è´¨å’Œæ­£åˆ™åŒ–çš„ç›®æ ‡ï¼Œæœ‰å‡ ç§å½¢å¼çš„æ­£åˆ™åŒ–ï¼›ä½ å¯èƒ½å¬è¯´è¿‡çš„ä¸€äº›å…·ä½“æŠ€æœ¯åŒ…æ‹¬å²­å›å½’ï¼ˆåˆç§°L2ï¼‰ã€Lassoå›å½’ï¼ˆåˆç§°L1ï¼‰ã€Tikhonovå’Œæ”¶ç¼©æ³•ã€‚'
- en: Different regularization techniques work in different ways, but many regularizers
    â€œshiftâ€ the design matrix by some amount. You will recall from [ChapterÂ 5](ch05.xhtml#Chapter_5)
    that shifting a matrix means adding some constant to the diagonal as <math alttext="bold
    upper A plus lamda bold upper I"><mrow><mi>ğ€</mi> <mo>+</mo> <mi>Î»</mi> <mi>ğˆ</mi></mrow></math>
    , and from [ChapterÂ 6](ch06.xhtml#Chapter_6) that shifting a matrix can transform
    a reduced-rank matrix into a full-rank matrix.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸åŒçš„æ­£åˆ™åŒ–æŠ€æœ¯æœ‰ä¸åŒçš„å·¥ä½œæ–¹å¼ï¼Œä½†è®¸å¤šæ­£åˆ™åŒ–å™¨é€šè¿‡æŸç§ç¨‹åº¦çš„â€œç§»åŠ¨â€è®¾è®¡çŸ©é˜µæ¥å®ç°ã€‚ä½ å¯èƒ½è¿˜è®°å¾—ä»[ChapterÂ 5](ch05.xhtml#Chapter_5)ä¸­ï¼Œç§»åŠ¨çŸ©é˜µæ„å‘³ç€åœ¨å¯¹è§’çº¿ä¸Šæ·»åŠ æŸä¸ªå¸¸æ•°ï¼Œå¦‚<math
    alttext="bold upper A plus lamda bold upper I"><mrow><mi>ğ€</mi> <mo>+</mo> <mi>Î»</mi>
    <mi>ğˆ</mi></mrow></math>ï¼Œä»¥åŠä»[ChapterÂ 6](ch06.xhtml#Chapter_6)ä¸­ï¼Œç§»åŠ¨çŸ©é˜µå¯ä»¥å°†é™ç§©çŸ©é˜µè½¬æ¢ä¸ºæ»¡ç§©çŸ©é˜µã€‚
- en: In this chapter, we will regularize the design matrix by shifting it according
    to some proportion of its Frobenius norm. This modifies the least squares solution
    [Equation 12-1](#regularization).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†æ ¹æ®å…¶FrobeniusèŒƒæ•°çš„æŸæ¯”ä¾‹æ¥å¯¹è®¾è®¡çŸ©é˜µè¿›è¡Œæ­£åˆ™åŒ–ã€‚è¿™ä¿®æ”¹äº†æœ€å°äºŒä¹˜è§£[æ–¹ç¨‹å¼ 12-1](#regularization)ã€‚
- en: Equation 12-1\. Regularization
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: æ–¹ç¨‹å¼ 12-1\. æ­£åˆ™åŒ–
- en: <math alttext="beta equals left-parenthesis bold upper X Superscript upper T
    Baseline bold upper X plus gamma parallel-to bold upper X parallel-to Subscript
    upper F Superscript 2 Baseline bold upper I right-parenthesis Superscript negative
    1 Baseline bold upper X Superscript upper T Baseline bold y" display="block"><mrow><mrow><mi>Î²</mi>
    <mo>=</mo> <mo>(</mo></mrow> <msup><mi>ğ—</mi> <mtext>T</mtext></msup> <mi>ğ—</mi>
    <mo>+</mo> <msubsup><mrow><mi>Î³</mi><mo>âˆ¥</mo><mi>ğ—</mi><mo>âˆ¥</mo></mrow> <mi>F</mi>
    <mn>2</mn></msubsup> <msup><mrow><mi>ğˆ</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>ğ—</mi> <mtext>T</mtext></msup> <mi>ğ²</mi></mrow></math>
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="beta equals left-parenthesis bold upper X Superscript upper T
    Baseline bold upper X plus gamma parallel-to bold upper X parallel-to Subscript
    upper F Superscript 2 Baseline bold upper I right-parenthesis Superscript negative
    1 Baseline bold upper X Superscript upper T Baseline bold y" display="block"><mrow><mrow><mi>Î²</mi>
    <mo>=</mo> <mo>(</mo></mrow> <msup><mi>ğ—</mi> <mtext>T</mtext></msup> <mi>ğ—</mi>
    <mo>+</mo> <msubsup><mrow><mi>Î³</mi><mo>âˆ¥</mo><mi>ğ—</mi><mo>âˆ¥</mo></mrow> <mi>F</mi>
    <mn>2</mn></msubsup> <msup><mrow><mi>ğˆ</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>ğ—</mi> <mtext>T</mtext></msup> <mi>ğ²</mi></mrow></math>
- en: The key parameter is <math alttext="gamma"><mi>Î³</mi></math> (Greek letter *gamma*),
    which determines the amount of regularization (observe that <math alttext="gamma
    equals 0"><mrow><mi>Î³</mi> <mo>=</mo> <mn>0</mn></mrow></math> corresponds to
    no regularization). Choosing an appropriate <math alttext="gamma"><mi>Î³</mi></math>
    parameter is nontrivial, and is often done through statistical techniques like
    cross-validation.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: å…³é”®å‚æ•°æ˜¯<math alttext="gamma"><mi>Î³</mi></math>ï¼ˆå¸Œè…Šå­—æ¯*gamma*ï¼‰ï¼Œå®ƒå†³å®šäº†æ­£åˆ™åŒ–çš„ç¨‹åº¦ï¼ˆæ³¨æ„åˆ°<math
    alttext="gamma equals 0"><mrow><mi>Î³</mi> <mo>=</mo> <mn>0</mn></mrow></math>æ„å‘³ç€æ²¡æœ‰æ­£åˆ™åŒ–ï¼‰ã€‚é€‰æ‹©é€‚å½“çš„<math
    alttext="gamma"><mi>Î³</mi></math>å‚æ•°å¹¶éæ˜“äº‹ï¼Œé€šå¸¸é€šè¿‡äº¤å‰éªŒè¯ç­‰ç»Ÿè®¡æŠ€æœ¯æ¥å®Œæˆã€‚
- en: The most obvious effect of regularization is that if the design matrix is reduced-rank,
    then the regularized squared design matrix is full-rank. Regularization also decreases
    the condition number, which measures the â€œspreadâ€ of information in the matrix
    (itâ€™s the ratio of the largest to the smallest singular value; youâ€™ll learn about
    this in [ChapterÂ 14](ch14.xhtml#Chapter_14)). This increases the numerical stability
    of the matrix. The statistical implication of regularization is to â€œsmooth outâ€
    the solution by reducing the sensitivity of the model to individual data points
    that might be outliers or nonrepresentative, and therefore less likely to be observed
    in new datasets.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£åˆ™åŒ–æœ€æ˜æ˜¾çš„æ•ˆæœæ˜¯ï¼Œå¦‚æœè®¾è®¡çŸ©é˜µæ˜¯é™ç§©çš„ï¼Œé‚£ä¹ˆæ­£åˆ™åŒ–åçš„å¹³æ–¹è®¾è®¡çŸ©é˜µå°†æ˜¯æ»¡ç§©çš„ã€‚æ­£åˆ™åŒ–è¿˜ä¼šé™ä½æ¡ä»¶æ•°ï¼Œè¿™æ˜¯çŸ©é˜µä¿¡æ¯â€œåˆ†å¸ƒâ€èŒƒå›´çš„åº¦é‡ï¼ˆå®ƒæ˜¯æœ€å¤§å’Œæœ€å°å¥‡å¼‚å€¼çš„æ¯”å€¼ï¼›ä½ å°†åœ¨[ChapterÂ 14](ch14.xhtml#Chapter_14)å­¦åˆ°æ›´å¤šï¼‰ã€‚è¿™æé«˜äº†çŸ©é˜µçš„æ•°å€¼ç¨³å®šæ€§ã€‚æ­£åˆ™åŒ–çš„ç»Ÿè®¡å«ä¹‰æ˜¯é€šè¿‡å‡å°‘æ¨¡å‹å¯¹å¯èƒ½æ˜¯å¼‚å¸¸å€¼æˆ–éä»£è¡¨æ€§æ•°æ®ç‚¹çš„æ•æ„Ÿæ€§æ¥â€œå¹³æ»‘â€è§£å†³æ–¹æ¡ˆï¼Œå› æ­¤æ›´ä¸å¯èƒ½åœ¨æ–°æ•°æ®é›†ä¸­è§‚å¯Ÿåˆ°ã€‚
- en: Why do I scale by the squared Frobenius norm? Consider that a specified value
    of <math alttext="gamma"><mi>Î³</mi></math> , say, <math alttext="gamma"><mi>Î³</mi></math>
    = .01, can have a huge or a negligible impact on the design matrix depending on
    the range of numerical values in the matrix. Therefore, we scale to the numerical
    range of the matrix, which means we interpret the <math alttext="gamma"><mi>Î³</mi></math>
    parameter as the *proportion* of regularization. The reason for squaring the Frobenius
    norm is that <math alttext="parallel-to bold upper X parallel-to equals parallel-to
    bold upper X Superscript upper T Baseline bold upper X parallel-to"><mrow><msubsup><mrow><mo>âˆ¥</mo><mi>ğ—</mi><mo>âˆ¥</mo></mrow>
    <mi>F</mi> <mn>2</mn></msubsup> <mo>=</mo> <msub><mrow><mo>âˆ¥</mo><msup><mi>ğ—</mi>
    <mtext>T</mtext></msup> <mi>ğ—</mi><mo>âˆ¥</mo></mrow> <mi>F</mi></msub></mrow></math>
    . In other words, the squared norm of the design matrix equals the norm of the
    design matrix times its transpose.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆè¦æŒ‰FrobeniusèŒƒæ•°çš„å¹³æ–¹ç¼©æ”¾ï¼Ÿè€ƒè™‘æŒ‡å®šçš„å€¼<math alttext="gamma"><mi>Î³</mi></math>ï¼Œä¾‹å¦‚ï¼Œ<math
    alttext="gamma"><mi>Î³</mi></math> = .01ï¼Œå¯ä»¥æ ¹æ®çŸ©é˜µä¸­æ•°å€¼èŒƒå›´çš„ä¸åŒå¯¹è®¾è®¡çŸ©é˜µäº§ç”Ÿå·¨å¤§æˆ–å¯å¿½ç•¥çš„å½±å“ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æŒ‰çŸ©é˜µçš„æ•°å€¼èŒƒå›´è¿›è¡Œç¼©æ”¾ï¼Œè¿™æ„å‘³ç€æˆ‘ä»¬å°†<math
    alttext="gamma"><mi>Î³</mi></math>å‚æ•°è§£é‡Šä¸º*æ­£åˆ™åŒ–çš„æ¯”ä¾‹*ã€‚å¹³æ–¹FrobeniusèŒƒæ•°çš„åŸå› åœ¨äº<math alttext="parallel-to
    bold upper X parallel-to equals parallel-to bold upper X Superscript upper T Baseline
    bold upper X parallel-to"><mrow><msubsup><mrow><mo>âˆ¥</mo><mi>ğ—</mi><mo>âˆ¥</mo></mrow>
    <mi>F</mi> <mn>2</mn></msubsup> <mo>=</mo> <msub><mrow><mo>âˆ¥</mo><msup><mi>ğ—</mi>
    <mtext>T</mtext></msup> <mi>ğ—</mi><mo>âˆ¥</mo></mrow> <mi>F</mi></msub></mrow></math>ã€‚æ¢å¥è¯è¯´ï¼Œè®¾è®¡çŸ©é˜µçš„å¹³æ–¹èŒƒæ•°ç­‰äºè®¾è®¡çŸ©é˜µä¸å…¶è½¬ç½®çš„èŒƒæ•°ä¹˜ç§¯ã€‚
- en: Itâ€™s actually more common to use the average of the eigenvalues of the design
    matrix instead of the Frobenius norm. After learning about eigenvalues in [ChapterÂ 13](ch13.xhtml#Chapter_13),
    youâ€™ll be able to compare the two regularization methods.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å®é™…ä¸Šï¼Œé€šå¸¸ä½¿ç”¨è®¾è®¡çŸ©é˜µçš„ç‰¹å¾å€¼å¹³å‡å€¼è€Œä¸æ˜¯FrobeniusèŒƒæ•°ã€‚åœ¨å­¦ä¹ ç¬¬[13ç« ](ch13.xhtml#Chapter_13)ä¸­çš„ç‰¹å¾å€¼åï¼Œæ‚¨å°†èƒ½å¤Ÿæ¯”è¾ƒè¿™ä¸¤ç§æ­£åˆ™åŒ–æ–¹æ³•ã€‚
- en: Implementing regularization in code is the focus of [Exercise 12-4](#exercise_12_4).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä»£ç ä¸­å®ç°æ­£åˆ™åŒ–æ˜¯[ç»ƒä¹  12-4](#exercise_12_4)çš„é‡ç‚¹ã€‚
- en: Polynomial Regression
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼å›å½’
- en: 'A *polynomial regression* is like a normal regression but the independent variables
    are the *x*-axis values raised to higher powers. That is, each column *i* of the
    design matrix is defined as *x*^i, where *x* is typically time or space but can
    be other variables such as medication dosage or population. The mathematical model
    looks like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*å¤šé¡¹å¼å›å½’*ç±»ä¼¼äºæ™®é€šå›å½’ï¼Œä½†ç‹¬ç«‹å˜é‡æ˜¯*x*è½´å€¼çš„é«˜æ¬¡å¹‚ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè®¾è®¡çŸ©é˜µçš„ç¬¬*i*åˆ—å®šä¹‰ä¸º*x*^iï¼Œå…¶ä¸­*x*é€šå¸¸æ˜¯æ—¶é—´æˆ–ç©ºé—´ï¼Œä½†ä¹Ÿå¯ä»¥æ˜¯å…¶ä»–å˜é‡ï¼Œå¦‚è¯ç‰©å‰‚é‡æˆ–äººå£ã€‚æ•°å­¦æ¨¡å‹å¦‚ä¸‹æ‰€ç¤ºï¼š'
- en: <math alttext="y equals beta 0 x Superscript 0 Baseline plus beta 1 x Superscript
    1 Baseline plus period period period plus beta Subscript n Baseline x Superscript
    n" display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>Î²</mi> <mn>0</mn></msub>
    <msup><mi>x</mi> <mn>0</mn></msup> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub>
    <msup><mi>x</mi> <mn>1</mn></msup> <mo>+</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo>
    <mo>+</mo> <msub><mi>Î²</mi> <mi>n</mi></msub> <msup><mi>x</mi> <mi>n</mi></msup></mrow></math>
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals beta 0 x Superscript 0 Baseline plus beta 1 x Superscript
    1 Baseline plus period period period plus beta Subscript n Baseline x Superscript
    n" display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>Î²</mi> <mn>0</mn></msub>
    <msup><mi>x</mi> <mn>0</mn></msup> <mo>+</mo> <msub><mi>Î²</mi> <mn>1</mn></msub>
    <msup><mi>x</mi> <mn>1</mn></msup> <mo>+</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo>
    <mo>+</mo> <msub><mi>Î²</mi> <mi>n</mi></msub> <msup><mi>x</mi> <mi>n</mi></msup></mrow></math>
- en: Note that <math alttext="x Superscript 0 Baseline equals 1"><mrow><msup><mi>x</mi>
    <mn>0</mn></msup> <mo>=</mo> <mn>1</mn></mrow></math> , giving us the intercept
    of the model. Otherwise, itâ€™s still a regular regressionâ€”the goal is to find the
    <math alttext="beta"><mi>Î²</mi></math> values that minimize the squared differences
    between the predicted and observed data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œ<math alttext="x Superscript 0 Baseline equals 1"><mrow><msup><mi>x</mi>
    <mn>0</mn></msup> <mo>=</mo> <mn>1</mn></mrow></math>ï¼Œè¿™ç»™äº†æˆ‘ä»¬æ¨¡å‹çš„æˆªè·ã€‚å¦åˆ™ï¼Œå®ƒä»ç„¶æ˜¯æ™®é€šå›å½’â€”â€”ç›®æ ‡æ˜¯æ‰¾åˆ°ä½¿é¢„æµ‹æ•°æ®ä¸è§‚æµ‹æ•°æ®çš„å¹³æ–¹å·®æœ€å°åŒ–çš„<math
    alttext="beta"><mi>Î²</mi></math>å€¼ã€‚
- en: The *order* of the polynomial is the largest power *i*. For example, a fourth
    order polynomial regression has terms up to <math alttext="x Superscript 4"><msup><mi>x</mi>
    <mn>4</mn></msup></math> (if there is no <math alttext="x cubed"><msup><mi>x</mi>
    <mn>3</mn></msup></math> term, then itâ€™s still a fourth order model with <math
    alttext="beta 3 equals 0"><mrow><msub><mi>Î²</mi> <mn>3</mn></msub> <mo>=</mo>
    <mn>0</mn></mrow></math> ).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼çš„*æ¬¡æ•°*æ˜¯æœ€é«˜æ¬¡å¹‚*i*ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªå››é˜¶å¤šé¡¹å¼å›å½’åŒ…å«é«˜è¾¾<math alttext="x Superscript 4"><msup><mi>x</mi>
    <mn>4</mn></msup></math>çš„é¡¹ï¼ˆå¦‚æœæ²¡æœ‰<math alttext="x cubed"><msup><mi>x</mi> <mn>3</mn></msup></math>é¡¹ï¼Œåˆ™ä»ç„¶æ˜¯ä¸€ä¸ªå››é˜¶æ¨¡å‹ï¼Œå…¶ä¸­<math
    alttext="beta 3 equals 0"><mrow><msub><mi>Î²</mi> <mn>3</mn></msub> <mo>=</mo>
    <mn>0</mn></mrow></math>ï¼‰ã€‚
- en: '[FigureÂ 12-5](#fig_12_5) shows an example of the individual regressors and
    the design matrix of a third order polynomial (keep in mind that an *n*th order
    polynomial has *n* + 1 regressors including the intercept). The polynomial functions
    are the basis vectors for modeling the observed data.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 12-5](#fig_12_5)æ˜¾ç¤ºäº†ä¸‰é˜¶å¤šé¡¹å¼çš„å•ä¸ªå›å½’å™¨å’Œè®¾è®¡çŸ©é˜µçš„ç¤ºä¾‹ï¼ˆè¯·è®°ä½ï¼Œä¸€ä¸ª*n*æ¬¡å¤šé¡¹å¼åŒ…æ‹¬æ‹¦æˆªå™¨åœ¨å†…çš„*n* + 1ä¸ªå›å½’å™¨ï¼‰ã€‚å¤šé¡¹å¼å‡½æ•°æ˜¯å»ºæ¨¡è§‚æµ‹æ•°æ®çš„åŸºç¡€å‘é‡ã€‚'
- en: '![Design matrix of a polynomial regression](assets/plad_1205.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![å¤šé¡¹å¼å›å½’çš„è®¾è®¡çŸ©é˜µ](assets/plad_1205.png)'
- en: Figure 12-5\. Design matrix of a polynomial regression
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 12-5\. å¤šé¡¹å¼å›å½’çš„è®¾è®¡çŸ©é˜µ
- en: 'Other than the special design matrix, a polynomial regression is exactly the
    same as any other regression: use the left-inverse (or more computationally stable
    alternatives) to obtain the set of coefficients such that the weighted combination
    of regressors (i.e., the predicted data) best matches the observed data.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†ç‰¹æ®Šçš„è®¾è®¡çŸ©é˜µå¤–ï¼Œå¤šé¡¹å¼å›å½’ä¸ä»»ä½•å…¶ä»–å›å½’å®Œå…¨ç›¸åŒï¼šä½¿ç”¨å·¦é€†ï¼ˆæˆ–æ›´ç¨³å®šçš„è®¡ç®—æ›¿ä»£æ–¹æ¡ˆï¼‰è·å¾—ä¸€ç»„ç³»æ•°ï¼Œä½¿å¾—å›å½’å™¨çš„åŠ æƒç»„åˆï¼ˆå³é¢„æµ‹æ•°æ®ï¼‰æœ€èƒ½åŒ¹é…è§‚å¯Ÿæ•°æ®ã€‚
- en: Polynomial regressions are used in curve fitting and in approximating nonlinear
    functions. Applications include time series modeling, population dynamics, dose-response
    functions in medical research, and physical stresses on structural support beams.
    Polynomials can also be expressed in 2D, which are used to model spatial structure
    such as earthquake propagation and brain activity.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼å›å½’ç”¨äºæ›²çº¿æ‹Ÿåˆå’Œé€¼è¿‘éçº¿æ€§å‡½æ•°ã€‚åº”ç”¨åŒ…æ‹¬æ—¶é—´åºåˆ—å»ºæ¨¡ã€äººå£åŠ¨æ€ã€åŒ»å­¦ç ”ç©¶ä¸­çš„å‰‚é‡-ååº”å‡½æ•°ä»¥åŠç»“æ„æ”¯æ’‘æ¢çš„ç‰©ç†åº”åŠ›ã€‚å¤šé¡¹å¼ä¹Ÿå¯ä»¥ç”¨äºè¡¨è¾¾äºŒç»´ç»“æ„ï¼Œç”¨äºæ¨¡æ‹Ÿåœ°éœ‡ä¼ æ’­å’Œè„‘æ´»åŠ¨ç­‰ç©ºé—´ç»“æ„ã€‚
- en: Enough background. Letâ€™s work through an example. The dataset I picked is from
    a model of human population doubling. The question is â€œHow long does it take for
    the population of humanity to double (e.g., from five hundred million to one billion)?â€
    If the rate of population increase is itself increasing (because more people have
    more babies, who grow up to have even more babies), then the doubling time will
    decrease with each doubling. On the other hand, if the population growth slows
    (people have fewer babies), then the doubling time will increase over successive
    doublings.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: èƒŒæ™¯è¶³å¤Ÿäº†ã€‚è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç¤ºä¾‹æ¥å·¥ä½œã€‚æˆ‘é€‰æ‹©çš„æ•°æ®é›†æ¥è‡ªäººå£ç¿»å€æ¨¡å‹ã€‚é—®é¢˜æ˜¯â€œäººç±»çš„äººå£ç¿»å€éœ€è¦å¤šé•¿æ—¶é—´ï¼ˆä¾‹å¦‚ï¼Œä»äº”äº¿åˆ°åäº¿ï¼‰ï¼Ÿâ€å¦‚æœäººå£å¢é•¿ç‡æœ¬èº«æ­£åœ¨å¢åŠ ï¼ˆå› ä¸ºæ›´å¤šçš„äººæœ‰æ›´å¤šçš„å­©å­ï¼Œè¿™äº›å­©å­é•¿å¤§ååˆä¼šæœ‰æ›´å¤šçš„å­©å­ï¼‰ï¼Œé‚£ä¹ˆæ¯æ¬¡ç¿»å€çš„æ—¶é—´å°†ä¼šå‡å°‘ã€‚å¦ä¸€æ–¹é¢ï¼Œå¦‚æœäººå£å¢é•¿æ”¾ç¼“ï¼ˆäººä»¬ç”Ÿå­©å­çš„æ•°é‡å‡å°‘ï¼‰ï¼Œé‚£ä¹ˆè¿ç»­ç¿»å€çš„æ—¶é—´å°†ä¼šå¢åŠ ã€‚
- en: I found a relevant dataset online.^([3](ch12.xhtml#idm45733294153856)) Itâ€™s
    a small dataset, so all the numbers are available in the online code and shown
    in [FigureÂ 12-6](#fig_12_6). This dataset includes both actual measured data and
    projections to the year 2100\. These projections into the future are based on
    a number of assumptions, and no one really knows how the future will play out
    (thatâ€™s why you should find a balance between preparing for the future and enjoying
    the moment). Regardless, the data thus far shows that the human population doubled
    with increasing frequency over the past five hundred years (at least), and the
    authors of the dataset predict that the doubling rate will increase slightly over
    the next century.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨ç½‘ä¸Šæ‰¾åˆ°äº†ä¸€ä¸ªç›¸å…³çš„æ•°æ®é›†ã€‚^([3](ch12.xhtml#idm45733294153856)) è¿™æ˜¯ä¸€ä¸ªå°æ•°æ®é›†ï¼Œå› æ­¤æ‰€æœ‰æ•°å­—éƒ½å¯ä»¥åœ¨åœ¨çº¿ä»£ç ä¸­æ‰¾åˆ°ï¼Œå¹¶æ˜¾ç¤ºåœ¨[å›¾Â 12-6](#fig_12_6)ä¸­ã€‚è¯¥æ•°æ®é›†åŒ…æ‹¬å®é™…æµ‹é‡æ•°æ®å’Œå¯¹2100å¹´çš„é¢„æµ‹ã€‚è¿™äº›å¯¹æœªæ¥çš„é¢„æµ‹åŸºäºå¤šç§å‡è®¾ï¼Œæ²¡æœ‰äººç¡®åˆ‡çŸ¥é“æœªæ¥ä¼šå¦‚ä½•å‘å±•ï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½ åº”è¯¥åœ¨æœªæ¥çš„å‡†å¤‡å’Œäº«å—å½“ä¸‹ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ï¼‰ã€‚å°½ç®¡å¦‚æ­¤ï¼Œè¿„ä»Šæ•°æ®æ˜¾ç¤ºï¼Œè¿‡å»500å¹´ä¸­äººå£çš„ç¿»å€é¢‘ç‡é€æ¸å¢åŠ ï¼ˆè‡³å°‘å¦‚æ­¤ï¼‰ï¼Œæ•°æ®é›†çš„ä½œè€…é¢„æµ‹ï¼Œè¿™ç§ç¿»å€é€Ÿç‡åœ¨æœªæ¥ä¸€ä¸ªä¸–çºªå†…å°†ç•¥å¾®å¢åŠ ã€‚
- en: '![Predicted and observed data](assets/plad_1206.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![é¢„æµ‹å’Œè§‚å¯Ÿæ•°æ®](assets/plad_1206.png)'
- en: Figure 12-6\. Plot of the data
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 12-6\. æ•°æ®å›¾
- en: 'I chose a third order polynomial to fit the data, and created and fit the model
    using the following code (variable `year` contains the *x*-axis coordinates and
    variable `doubleTime` contains the dependent variable):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘é€‰æ‹©äº†ä¸‰é˜¶å¤šé¡¹å¼æ¥æ‹Ÿåˆæ•°æ®ï¼Œå¹¶ä½¿ç”¨ä»¥ä¸‹ä»£ç åˆ›å»ºå’Œæ‹Ÿåˆäº†æ¨¡å‹ï¼ˆå˜é‡`year`åŒ…å«*x*è½´åæ ‡ï¼Œå˜é‡`doubleTime`åŒ…å«ä¾èµ–å˜é‡ï¼‰ï¼š
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[FigureÂ 12-7](#fig_12_7) shows the predicted data using the polynomial regression
    created by that code.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[å›¾Â 12-7](#fig_12_7) æ˜¾ç¤ºäº†ä½¿ç”¨è¯¥ä»£ç åˆ›å»ºçš„å¤šé¡¹å¼å›å½’é¢„æµ‹æ•°æ®ã€‚'
- en: '![Predicted and observed data](assets/plad_1207.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![é¢„æµ‹å’Œè§‚å¯Ÿæ•°æ®](assets/plad_1207.png)'
- en: Figure 12-7\. Plot of the data
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 12-7\. æ•°æ®å›¾
- en: The model captures both the downward trend and the projected upswing in the
    data. Without further statistical analysis, we cannot say that this is the *best*
    model or that the model is a statistically significantly good fit to the data.
    But it is clear that polynomial regressions are well suited for fitting curves.
    You will continue exploring this model and the data in [Exercise 12-5](#exercise_12_5),
    but I encourage you to play around with the code that produces [FigureÂ 12-7](#fig_12_7)
    by testing different order parameters.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ¨¡å‹æ•æ‰åˆ°äº†æ•°æ®ä¸­çš„ä¸‹é™è¶‹åŠ¿å’Œé¢„æœŸçš„ä¸Šå‡è¶‹åŠ¿ã€‚ æ²¡æœ‰è¿›ä¸€æ­¥çš„ç»Ÿè®¡åˆ†æï¼Œæˆ‘ä»¬ä¸èƒ½è¯´è¿™æ˜¯*æœ€ä½³*æ¨¡å‹æˆ–è€…è¯´è¯¥æ¨¡å‹åœ¨ç»Ÿè®¡ä¸Šæ˜¾è‘—æ‹Ÿåˆæ•°æ®ã€‚ ä½†æ˜¯å¾ˆæ˜æ˜¾ï¼Œå¤šé¡¹å¼å›å½’éå¸¸é€‚åˆæ‹Ÿåˆæ›²çº¿ã€‚
    ä½ å°†ç»§ç»­æ¢ç´¢è¿™ä¸ªæ¨¡å‹å’Œ[ç»ƒä¹  12-5](#exercise_12_5)ä¸­çš„æ•°æ®ï¼Œä½†æˆ‘é¼“åŠ±ä½ é€šè¿‡æµ‹è¯•ä¸åŒçš„é˜¶å‚æ•°æ¥ç©å¼„ç”Ÿæˆ[å›¾ 12-7](#fig_12_7)çš„ä»£ç ã€‚
- en: 'Polynomial regressions are commonly used, and NumPy has dedicated functions
    to create and fit such models:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼å›å½’é€šå¸¸è¢«ä½¿ç”¨ï¼Œå¹¶ä¸”NumPyæœ‰ä¸“ç”¨å‡½æ•°æ¥åˆ›å»ºå’Œæ‹Ÿåˆè¿™æ ·çš„æ¨¡å‹ï¼š
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Grid Search to Find Model Parameters
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç”¨ç½‘æ ¼æœç´¢æ‰¾åˆ°æ¨¡å‹å‚æ•°
- en: Least squares via the left-inverse is a brilliant way to fit models to data.
    Least squares is accurate, fast, and deterministic (meaning that each time you
    rerun the code, youâ€™ll get the same result). But it works only for linear model
    fitting, and not all models can be fit using linear methods.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å°äºŒä¹˜æ³•é€šè¿‡å·¦é€†æ¥ç²¾ç¡®åœ°å°†æ¨¡å‹æ‹Ÿåˆåˆ°æ•°æ®ã€‚ æœ€å°äºŒä¹˜æ³•å‡†ç¡®ã€å¿«é€Ÿä¸”ç¡®å®šæ€§ï¼ˆè¿™æ„å‘³ç€æ¯æ¬¡é‡æ–°è¿è¡Œä»£ç æ—¶ï¼Œä½ éƒ½ä¼šå¾—åˆ°ç›¸åŒçš„ç»“æœï¼‰ã€‚ ä½†å®ƒä»…é€‚ç”¨äºçº¿æ€§æ¨¡å‹æ‹Ÿåˆï¼Œè€Œä¸æ˜¯æ‰€æœ‰æ¨¡å‹éƒ½å¯ä»¥ä½¿ç”¨çº¿æ€§æ–¹æ³•æ‹Ÿåˆã€‚
- en: In this section, I will introduce you to another optimization method used to
    identify model parameters, known as *grid search*. A grid search works by sampling
    the parameter space, computing the model fit to the data with each parameter value,
    and then selecting the parameter value that gave the best model fit.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€èŠ‚ä¸­ï¼Œæˆ‘å°†å‘ä½ ä»‹ç»å¦ä¸€ç§ç”¨äºè¯†åˆ«æ¨¡å‹å‚æ•°çš„ä¼˜åŒ–æ–¹æ³•ï¼Œç§°ä¸º*ç½‘æ ¼æœç´¢*ã€‚ ç½‘æ ¼æœç´¢é€šè¿‡å¯¹å‚æ•°ç©ºé—´è¿›è¡Œé‡‡æ ·ï¼Œè®¡ç®—æ¯ä¸ªå‚æ•°å€¼å¯¹æ•°æ®çš„æ¨¡å‹æ‹Ÿåˆï¼Œå¹¶é€‰æ‹©ç»™å‡ºæœ€ä½³æ¨¡å‹æ‹Ÿåˆçš„å‚æ•°å€¼ã€‚
- en: As a simple example, letâ€™s take the function <math alttext="y equals x squared"><mrow><mi>y</mi>
    <mo>=</mo> <msup><mi>x</mi> <mn>2</mn></msup></mrow></math> . We want to find
    the minimum of that function. Of course, we already know that the minimum is at
    <math alttext="x equals 0"><mrow><mi>x</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    ; this helps us understand and evaluate the results of the grid search method.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ä½œä¸ºä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œè®©æˆ‘ä»¬è€ƒè™‘å‡½æ•°<math alttext="y equals x squared"><mrow><mi>y</mi> <mo>=</mo>
    <msup><mi>x</mi> <mn>2</mn></msup></mrow></math>ã€‚ æˆ‘ä»¬æƒ³æ‰¾åˆ°è¯¥å‡½æ•°çš„æœ€å°å€¼ã€‚ å½“ç„¶ï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“æœ€å°å€¼åœ¨<math
    alttext="x equals 0"><mrow><mi>x</mi> <mo>=</mo> <mn>0</mn></mrow></math>å¤„ï¼›è¿™æœ‰åŠ©äºæˆ‘ä»¬ç†è§£å’Œè¯„ä¼°ç½‘æ ¼æœç´¢æ–¹æ³•çš„ç»“æœã€‚
- en: In the grid search technique, we start with a predefined set of <math alttext="x"><mi>x</mi></math>
    values to test. Letâ€™s use the set (âˆ’2, âˆ’1, 0, 1, 2). Thatâ€™s our â€œgrid.â€ Then we
    compute the function at each of those grid values to obtain *y* = (4, 1, 0, 1,
    4). And we find that the minimum *y* occurs when <math alttext="x equals 0"><mrow><mi>x</mi>
    <mo>=</mo> <mn>0</mn></mrow></math> . In this case, the grid-based solution is
    the same as the true solution.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ç½‘æ ¼æœç´¢æŠ€æœ¯ä¸­ï¼Œæˆ‘ä»¬ä»ä¸€ä¸ªé¢„å®šä¹‰çš„<math alttext="x"><mi>x</mi></math>å€¼é›†åˆå¼€å§‹æµ‹è¯•ã€‚ è®©æˆ‘ä»¬ä½¿ç”¨é›†åˆ(âˆ’2, âˆ’1,
    0, 1, 2)ã€‚ è¿™å°±æ˜¯æˆ‘ä»¬çš„â€œç½‘æ ¼â€ã€‚ ç„¶åæˆ‘ä»¬è®¡ç®—æ¯ä¸ªç½‘æ ¼å€¼å¤„çš„å‡½æ•°ä»¥è·å–*y* = (4, 1, 0, 1, 4)ã€‚ æˆ‘ä»¬å‘ç°æœ€å°çš„*y*å‡ºç°åœ¨<math
    alttext="x equals 0"><mrow><mi>x</mi> <mo>=</mo> <mn>0</mn></mrow></math> ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒåŸºäºç½‘æ ¼çš„è§£ä¸çœŸå®è§£ç›¸åŒã€‚
- en: But grid search is not guaranteed to give the optimal solution. For example,
    imagine our grid was (âˆ’2, âˆ’.5, 1, 2.5); the function values would be *y* = (4,
    .25, 1, 6.25), and we would conclude that <math display="inline"><mrow><mi>x</mi>
    <mo>=</mo> <mn>-.5</mn></mrow></math> is the parameter value that minimizes the
    function <math alttext="y equals x squared"><mrow><mi>y</mi> <mo>=</mo> <msup><mi>x</mi>
    <mn>2</mn></msup></mrow></math> . That conclusion is â€œkind of correctâ€ because
    it is the best solution within the specified grid. Grid-search failures can also
    arise from a poorly chosen range of values. Imagine, for example, that our grid
    was (âˆ’1000, âˆ’990, âˆ’980, âˆ’970); we would conclude that <math alttext="y equals
    x squared"><mrow><mi>y</mi> <mo>=</mo> <msup><mi>x</mi> <mn>2</mn></msup></mrow></math>
    is minimized when <math display="inline"><mrow><mi>x</mi> <mo>=</mo> <mrow><mo>-</mo>
    <mn>970</mn></mrow></mrow></math> .
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œç½‘æ ¼æœç´¢ä¸èƒ½ä¿è¯ç»™å‡ºæœ€ä¼˜è§£ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬çš„ç½‘æ ¼æ˜¯ï¼ˆâˆ’2, âˆ’0.5, 1, 2.5ï¼‰ï¼›å‡½æ•°å€¼å°†ä¸º*y* = (4, 0.25, 1, 6.25)ï¼Œæˆ‘ä»¬å°†å¾—å‡ºç»“è®º
    <math display="inline"><mrow><mi>x</mi> <mo>=</mo> <mn>-.5</mn></mrow></math>
    æ˜¯ä½¿å‡½æ•° <math alttext="y equals x squared"><mrow><mi>y</mi> <mo>=</mo> <msup><mi>x</mi>
    <mn>2</mn></msup></mrow></math> æœ€å°åŒ–çš„å‚æ•°å€¼ã€‚è¿™ä¸ªç»“è®ºâ€œæœ‰ç‚¹æ­£ç¡®â€ï¼Œå› ä¸ºå®ƒæ˜¯åœ¨æŒ‡å®šç½‘æ ¼å†…çš„æœ€ä½³è§£ã€‚ç½‘æ ¼æœç´¢çš„å¤±è´¥ä¹Ÿå¯èƒ½æ¥è‡ªäºå€¼èŒƒå›´é€‰æ‹©ä¸å½“ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬çš„ç½‘æ ¼æ˜¯ï¼ˆâˆ’1000,
    âˆ’990, âˆ’980, âˆ’970ï¼‰ï¼›æˆ‘ä»¬ä¼šå¾—å‡ºç»“è®º <math alttext="y equals x squared"><mrow><mi>y</mi>
    <mo>=</mo> <msup><mi>x</mi> <mn>2</mn></msup></mrow></math> åœ¨ <math display="inline"><mrow><mi>x</mi>
    <mo>=</mo> <mrow><mo>-</mo> <mn>970</mn></mrow></mrow></math> æ—¶æœ€å°åŒ–ã€‚
- en: The point is that both the range and the resolution (the spacing between grid
    points) are important, because they determine whether you will obtain the *best*
    solution, a *pretty good* solution, or an *awful* solution. In the toy example
    above, the appropriate range and resolution are easy to detemine. In complicated,
    multivariate, nonlinear models, appropriate grid search parameters might take
    some more work and exploration.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: ç‚¹åœ¨äºèŒƒå›´å’Œåˆ†è¾¨ç‡ï¼ˆæ ¼ç‚¹ä¹‹é—´çš„é—´è·ï¼‰éƒ½å¾ˆé‡è¦ï¼Œå› ä¸ºå®ƒä»¬å†³å®šä½ æ˜¯å¦ä¼šå¾—åˆ°*æœ€ä½³*è§£ã€*ç›¸å½“ä¸é”™*çš„è§£æˆ–è€…*ç³Ÿç³•*çš„è§£ã€‚åœ¨ä¸Šè¿°ç©å…·ç¤ºä¾‹ä¸­ï¼Œé€‚å½“çš„èŒƒå›´å’Œåˆ†è¾¨ç‡å¾ˆå®¹æ˜“ç¡®å®šã€‚åœ¨å¤æ‚çš„ã€å¤šå˜é‡çš„ã€éçº¿æ€§æ¨¡å‹ä¸­ï¼Œé€‚å½“çš„ç½‘æ ¼æœç´¢å‚æ•°å¯èƒ½éœ€è¦æ›´å¤šçš„å·¥ä½œå’Œæ¢ç´¢ã€‚
- en: 'I ran a grid search on the â€œhappy studentâ€ data from the previous chapter (as
    a reminder: it was fake data from a fake survey showing that people who enrolled
    in more of my courses had higher life satisfaction). The model of those data has
    two parametersâ€”intercept and slopeâ€”and so we evaluate that function at each point
    on a 2D grid of possible parameter pairings. Results are shown in [FigureÂ 12-8](#fig_12_8).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘åœ¨ä¸Šä¸€ç« çš„â€œå¿«ä¹å­¦ç”Ÿâ€æ•°æ®ä¸Šè¿›è¡Œäº†ç½‘æ ¼æœç´¢ï¼ˆæé†’ä¸€ä¸‹ï¼šè¿™æ˜¯æ¥è‡ªè™šå‡è°ƒæŸ¥çš„è™šå‡æ•°æ®ï¼Œæ˜¾ç¤ºå‡ºå‚åŠ æˆ‘çš„è¯¾ç¨‹æ›´å¤šçš„äººç”Ÿæ´»æ»¡æ„åº¦æ›´é«˜ï¼‰ã€‚è¿™äº›æ•°æ®çš„æ¨¡å‹æœ‰ä¸¤ä¸ªå‚æ•°â€”â€”æˆªè·å’Œæ–œç‡â€”â€”å› æ­¤ï¼Œæˆ‘ä»¬åœ¨å¯èƒ½çš„å‚æ•°å¯¹çš„äºŒç»´ç½‘æ ¼ä¸Šè¯„ä¼°è¯¥å‡½æ•°ã€‚ç»“æœæ˜¾ç¤ºåœ¨
    [å›¾Â 12-8](#fig_12_8) ä¸­ã€‚
- en: What does that graph mean, and how do we interpret it? The two axes correspond
    to values of parameters, and therefore each coordinate in that graph creates a
    model with those corresponding parameter values. Then, the fit of each of those
    models to the data is calculated and stored, and visualized as an image.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¸ªå›¾è¡¨æ„å‘³ç€ä»€ä¹ˆï¼Œæˆ‘ä»¬å¦‚ä½•è§£é‡Šå®ƒï¼Ÿä¸¤ä¸ªè½´å¯¹åº”äºå‚æ•°çš„å€¼ï¼Œå› æ­¤è¯¥å›¾ä¸­çš„æ¯ä¸ªåæ ‡åˆ›å»ºäº†å…·æœ‰å¯¹åº”å‚æ•°å€¼çš„æ¨¡å‹ã€‚ç„¶åï¼Œè®¡ç®—å¹¶å­˜å‚¨æ¯ä¸ªæ¨¡å‹å¯¹æ•°æ®çš„æ‹Ÿåˆï¼Œå¹¶å°†å…¶å¯è§†åŒ–ä¸ºå›¾åƒã€‚
- en: The coordinate with the best fit to the data (the smallest sum of squared errors)
    is the optimal parameter set. [FigureÂ 12-8](#fig_12_8) also shows the analytic
    solution using the least squares approach. They are close but not exactly overlapping.
    In [Exercise 12-6](#exercise_12_6), you will have the opportunity to implement
    this grid search as well as to explore the importance of the grid resolution on
    the accuracy of the results.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€é€‚åˆæ•°æ®çš„åæ ‡ï¼ˆå¹³æ–¹è¯¯å·®ä¹‹å’Œæœ€å°çš„ï¼‰æ˜¯æœ€ä¼˜å‚æ•°é›†ã€‚[å›¾Â 12-8](#fig_12_8) ä¹Ÿå±•ç¤ºäº†ä½¿ç”¨æœ€å°äºŒä¹˜æ³•çš„è§£æè§£ã€‚å®ƒä»¬æ¥è¿‘ä½†ä¸å®Œå…¨é‡å ã€‚åœ¨ [ç»ƒä¹ Â 12-6](#exercise_12_6)
    ä¸­ï¼Œæ‚¨å°†æœ‰æœºä¼šå®ç°è¿™ä¸ªç½‘æ ¼æœç´¢ï¼Œå¹¶æ¢ç´¢ç½‘æ ¼åˆ†è¾¨ç‡å¯¹ç»“æœå‡†ç¡®æ€§çš„å½±å“ã€‚
- en: '![Grid search versus least squares.](assets/plad_1208.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![ç½‘æ ¼æœç´¢ä¸æœ€å°äºŒä¹˜æ³•çš„æ¯”è¾ƒã€‚](assets/plad_1208.png)'
- en: Figure 12-8\. Results from a grid search on the â€œhappy studentâ€ dataset. The
    intensity shows the sum of squared errors fit to the data.
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾12-8\. åœ¨â€œå¿«ä¹å­¦ç”Ÿâ€æ•°æ®é›†ä¸Šè¿›è¡Œç½‘æ ¼æœç´¢çš„ç»“æœã€‚å¼ºåº¦æ˜¾ç¤ºäº†æ‹Ÿåˆåˆ°æ•°æ®çš„å¹³æ–¹è¯¯å·®ä¹‹å’Œã€‚
- en: Why would anyone use grid search when least squares is better and faster? Well,
    you should never use a grid search method when least squares is a viable solution.
    Grid search is a useful technique for finding parameters in nonlinear models and
    is often used, for example, to identify hyperparameters in deep learning models
    (*hyperparameters* are model architecture design features that are selected by
    the researcher, not learned from data). Grid search can be time-consuming for
    large models, but parallelization can make grid search more feasible.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å½“æœ€å°äºŒä¹˜æ³•æ›´å¥½ä¸”æ›´å¿«æ—¶ï¼Œä¸ºä»€ä¹ˆä¼šæœ‰äººä½¿ç”¨ç½‘æ ¼æœç´¢å‘¢ï¼Ÿå—¯ï¼Œå½“æœ€å°äºŒä¹˜æ³•æ˜¯å¯è¡Œè§£å†³æ–¹æ¡ˆæ—¶ï¼Œæ‚¨æ°¸è¿œä¸åº”è¯¥ä½¿ç”¨ç½‘æ ¼æœç´¢æ–¹æ³•ã€‚ç½‘æ ¼æœç´¢æ˜¯ä¸€ç§å¯»æ‰¾éçº¿æ€§æ¨¡å‹å‚æ•°çš„æœ‰ç”¨æŠ€æœ¯ï¼Œä¾‹å¦‚ï¼Œç”¨äºè¯†åˆ«æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„è¶…å‚æ•°ï¼ˆ*è¶…å‚æ•°*æ˜¯ç ”ç©¶äººå‘˜é€‰æ‹©çš„æ¨¡å‹æ¶æ„è®¾è®¡ç‰¹å¾ï¼Œè€Œä¸æ˜¯ä»æ•°æ®ä¸­å­¦ä¹ çš„ï¼‰ã€‚å¯¹äºå¤§å‹æ¨¡å‹æ¥è¯´ï¼Œç½‘æ ¼æœç´¢å¯èƒ½æ˜¯è€—æ—¶çš„ï¼Œä½†å¹¶è¡ŒåŒ–å¯ä»¥ä½¿ç½‘æ ¼æœç´¢å˜å¾—æ›´åŠ å¯è¡Œã€‚
- en: The conclusion is that grid search is a nonlinear method for fitting models
    to data when linear methods cannot be applied. Along your journey into data science
    and machine learning, you will also learn about additional nonlinear methods,
    including simplex and the famous gradient descent algorithm that powers deep learning.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç»“è®ºæ˜¯ï¼Œå½“æ— æ³•åº”ç”¨çº¿æ€§æ–¹æ³•æ—¶ï¼Œç½‘æ ¼æœç´¢æ˜¯å°†æ¨¡å‹æ‹Ÿåˆåˆ°æ•°æ®çš„éçº¿æ€§æ–¹æ³•ã€‚åœ¨æ‚¨å­¦ä¹ æ•°æ®ç§‘å­¦å’Œæœºå™¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­ï¼Œæ‚¨è¿˜å°†äº†è§£åˆ°å…¶ä»–éçº¿æ€§æ–¹æ³•ï¼ŒåŒ…æ‹¬å•çº¯å½¢å’Œæ”¯æŒæ·±åº¦å­¦ä¹ çš„è‘—åæ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚
- en: Summary
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ€»ç»“
- en: 'I hope you enjoyed reading about applications of least squares and the comparison
    to other model-fitting approaches. The following exercises are the most important
    part of this chapter, so I donâ€™t want to take up your time with a long summary.
    Here are the important points:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å¸Œæœ›æ‚¨å–œæ¬¢é˜…è¯»å…³äºæœ€å°äºŒä¹˜æ³•åº”ç”¨åŠä¸å…¶ä»–æ¨¡å‹æ‹Ÿåˆæ–¹æ³•æ¯”è¾ƒçš„å†…å®¹ã€‚ä»¥ä¸‹ç»ƒä¹ æ˜¯æœ¬ç« æœ€é‡è¦çš„éƒ¨åˆ†ï¼Œå› æ­¤æˆ‘ä¸æƒ³ç”¨é•¿ç¯‡å¤§è®ºå ç”¨æ‚¨çš„æ—¶é—´ã€‚ä»¥ä¸‹æ˜¯é‡ç‚¹ï¼š
- en: Visual inspection of data is important for selecting the right statistical models
    and interpreting statistical results correctly.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹æ•°æ®è¿›è¡Œè§†è§‰æ£€æŸ¥å¯¹äºé€‰æ‹©æ­£ç¡®çš„ç»Ÿè®¡æ¨¡å‹å’Œæ­£ç¡®è§£é‡Šç»Ÿè®¡ç»“æœéå¸¸é‡è¦ã€‚
- en: Linear algebra is used for quantitative assessments of datasets, including correlation
    matrices.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: çº¿æ€§ä»£æ•°ç”¨äºå¯¹æ•°æ®é›†è¿›è¡Œå®šé‡è¯„ä¼°ï¼ŒåŒ…æ‹¬ç›¸å…³çŸ©é˜µã€‚
- en: The matrix visualization methods you learned in [ChapterÂ 5](ch05.xhtml#Chapter_5)
    are useful for inspecting design matrices.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‚¨åœ¨[ç¬¬ 5 ç« ](ch05.xhtml#Chapter_5)ä¸­å­¦åˆ°çš„çŸ©é˜µå¯è§†åŒ–æ–¹æ³•å¯¹äºæ£€æŸ¥è®¾è®¡çŸ©é˜µéå¸¸æœ‰ç”¨ã€‚
- en: Mathematical concepts are sometimes given different names in different fields.
    An example in this chapter is *multicollinearity*, which means linear dependences
    in the design matrix.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ•°å­¦æ¦‚å¿µæœ‰æ—¶åœ¨ä¸åŒé¢†åŸŸä¼šæœ‰ä¸åŒçš„åç§°ã€‚æœ¬ç« çš„ä¸€ä¸ªä¾‹å­æ˜¯*å¤šé‡å…±çº¿æ€§*ï¼ŒæŒ‡çš„æ˜¯è®¾è®¡çŸ©é˜µä¸­çš„çº¿æ€§ä¾èµ–å…³ç³»ã€‚
- en: Regularization involves â€œshiftingâ€ the design matrix by some small amount, which
    can increase numerical stability and likelihood of generalizing the new data.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ­£åˆ™åŒ–æ¶‰åŠå°†è®¾è®¡çŸ©é˜µâ€œç§»åŠ¨â€ä¸€å°éƒ¨åˆ†ï¼Œè¿™å¯ä»¥å¢åŠ æ•°å€¼ç¨³å®šæ€§å¹¶å¢åŠ æ³›åŒ–æ–°æ•°æ®çš„å¯èƒ½æ€§ã€‚
- en: Having a deep understanding of linear algebra can help you select the most appropriate
    statistical analyses, interpret the results, and anticipate potential problems.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¯¹çº¿æ€§ä»£æ•°æœ‰æ·±å…¥ç†è§£å¯ä»¥å¸®åŠ©æ‚¨é€‰æ‹©æœ€åˆé€‚çš„ç»Ÿè®¡åˆ†ææ–¹æ³•ï¼Œè§£é‡Šç»“æœï¼Œå¹¶é¢„æµ‹å¯èƒ½å‡ºç°çš„é—®é¢˜ã€‚
- en: A polynomial regression is the same as a â€œregularâ€ regression, but the columns
    in the design matrix are defined as the *x*-axis values raised to increasing powers.
    Polynomial regressions are used for curve fitting.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼å›å½’ä¸â€œå¸¸è§„â€å›å½’ç›¸åŒï¼Œä½†è®¾è®¡çŸ©é˜µä¸­çš„åˆ—å®šä¹‰ä¸ºå‡é«˜åˆ°ä¸åŒå¹‚çš„*x*è½´å€¼ã€‚å¤šé¡¹å¼å›å½’ç”¨äºæ›²çº¿æ‹Ÿåˆã€‚
- en: Grid search is a nonlinear method of model fitting. Linear least squares is
    the optimal approach when the model is linear.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç½‘æ ¼æœç´¢æ˜¯æ¨¡å‹æ‹Ÿåˆçš„éçº¿æ€§æ–¹æ³•ã€‚å½“æ¨¡å‹æ˜¯çº¿æ€§çš„æ—¶ï¼Œæœ€å°äºŒä¹˜æ³•æ˜¯æœ€ä¼˜çš„æ–¹æ³•ã€‚
- en: Code Exercises
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä»£ç ç»ƒä¹ 
- en: Bike Rental Exercises
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªè¡Œè½¦ç§Ÿèµç»ƒä¹ 
- en: Exercise 12-1\.
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  12-1\.
- en: Perhaps part of the problem with negative bike rentals in [FigureÂ 12-4](#fig_12_4)
    can be alleviated by eliminating the no-rainfall days. Repeat the analysis and
    graph for this analysis, but select only the data rows that have zero rainfall.
    Do the results improve, in terms of higher *R*Â² and positive predicted rental
    counts?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ–è®¸åœ¨[å›¾Â 12-4](#fig_12_4)ä¸­è´Ÿè‡ªè¡Œè½¦ç§Ÿèµçš„é—®é¢˜éƒ¨åˆ†å¯ä»¥é€šè¿‡æ¶ˆé™¤æ— é™é›¨æ—¥æ¥ç¼“è§£ã€‚é‡å¤åˆ†æå¹¶ç»˜åˆ¶è¿™ç§åˆ†æçš„å›¾è¡¨ï¼Œä½†åªé€‰æ‹©å…·æœ‰é›¶é™é›¨çš„æ•°æ®è¡Œã€‚ç»“æœæ˜¯å¦æ”¹å–„ï¼Œä»¥æ›´é«˜çš„*R*Â²å’Œæ­£é¢„æµ‹ç§Ÿèµæ•°é‡ä¸ºè¯„åˆ¤æ ‡å‡†ï¼Ÿ
- en: Exercise 12-2\.
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  12-2\.
- en: Because *seasons* is a categorical variable, an ANOVA would actully be a more
    appropriate statistical model than a regression. Maybe the binarized *seasons*
    lacks the sensitivity to predict bike rentals (for example, there can be warm
    sunny days in autumn and cold rainy days in spring), and therefore temperature
    might be a better predictor.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸º *seasons* æ˜¯ä¸€ä¸ªåˆ†ç±»å˜é‡ï¼ŒANOVA å®é™…ä¸Šæ¯”å›å½’æ›´åˆé€‚ä½œä¸ºç»Ÿè®¡æ¨¡å‹ã€‚ä¹Ÿè®¸äºŒå…ƒåŒ–çš„ *seasons* ç¼ºä¹é¢„æµ‹è‡ªè¡Œè½¦ç§Ÿèµçš„æ•æ„Ÿæ€§ï¼ˆä¾‹å¦‚ï¼Œç§‹å¤©å¯èƒ½æœ‰æ¸©æš–çš„æ™´å¤©å’Œæ˜¥å¤©å¯èƒ½æœ‰å¯’å†·çš„é›¨å¤©ï¼‰ï¼Œå› æ­¤
    *temperature* å¯èƒ½æ˜¯ä¸€ä¸ªæ›´å¥½çš„é¢„æµ‹å˜é‡ã€‚
- en: Replace *seasons* with *temperature* in the design matrix and rerun the regression
    (you can use all days, not only the no-rainfall days from the previous exercise),
    and reproduce [FigureÂ 12-9](#fig_12_9). There is still the issue with predicting
    negative rentals (this is because of the linearity of the model), but the *R*Â²
    is higher and the prediction appears qualitatively better.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®¾è®¡çŸ©é˜µä¸­ç”¨ *temperature* æ›¿æ¢ *seasons* å¹¶é‡æ–°è¿è¡Œå›å½’ï¼ˆå¯ä»¥ä½¿ç”¨æ‰€æœ‰å¤©æ•°ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸Šä¸€ä¸ªç»ƒä¹ ä¸­çš„æ— é™é›¨å¤©æ•°ï¼‰ï¼Œå¹¶é‡ç° [å›¾Â 12-9](#fig_12_9)ã€‚ä»ç„¶å­˜åœ¨é¢„æµ‹è´Ÿç§Ÿèµçš„é—®é¢˜ï¼ˆè¿™æ˜¯å› ä¸ºæ¨¡å‹çš„çº¿æ€§æ€§ï¼‰ï¼Œä½†
    *R*Â² æ›´é«˜ï¼Œé¢„æµ‹çœ‹èµ·æ¥è´¨é‡æ›´å¥½ã€‚
- en: '![exercise 12-2](assets/plad_1209.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![ç»ƒä¹  12-2](assets/plad_1209.png)'
- en: Figure 12-9\. Results of Exercise 12-2
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: å›¾Â 12-9\. ç»ƒä¹  12-2 çš„ç»“æœ
- en: Multicollinearity Exercise
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤šé‡å…±çº¿æ€§ç»ƒä¹ 
- en: Exercise 12-3\.
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  12-3\.
- en: This exercise continues with the model from [Exercise 12-2](#exercise_12_2).^([4](ch12.xhtml#idm45733293926768))
    This model contains three regressors, including the intercept. Create a new design
    matrix that contains a fourth regressor defined as some linear weighted combination
    of *temperature* and *rainfall*. Give this design matrix a different variable
    name, because you will need it in the next exercise. Confirm that the design matrix
    has four columns yet a rank of 3, and compute the correlation matrix of the design
    matrix.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç»ƒä¹ å»¶ç»­äº†æ¥è‡ª [ç»ƒä¹  12-2](#exercise_12_2) çš„æ¨¡å‹ã€‚è¿™ä¸ªæ¨¡å‹åŒ…å«ä¸‰ä¸ªå›å½’å˜é‡ï¼ŒåŒ…æ‹¬æˆªè·é¡¹ã€‚åˆ›å»ºä¸€ä¸ªæ–°çš„è®¾è®¡çŸ©é˜µï¼Œå…¶ä¸­åŒ…å«ä½œä¸º
    *temperature* å’Œ *rainfall* çš„æŸç§çº¿æ€§åŠ æƒç»„åˆå®šä¹‰çš„ç¬¬å››ä¸ªå›å½’å˜é‡ã€‚ç»™è¿™ä¸ªè®¾è®¡çŸ©é˜µèµ·ä¸€ä¸ªä¸åŒçš„å˜é‡åï¼Œå› ä¸ºä½ å°†åœ¨ä¸‹ä¸€ä¸ªç»ƒä¹ ä¸­ç”¨åˆ°å®ƒã€‚ç¡®è®¤è®¾è®¡çŸ©é˜µæœ‰å››åˆ—ï¼Œä½†ç§©ä¸º
    3ï¼Œå¹¶è®¡ç®—è®¾è®¡çŸ©é˜µçš„ç›¸å…³çŸ©é˜µã€‚
- en: 'Note that depending on the weightings of the two variables, you wouldnâ€™t expect
    a correlation of 1 even with linear dependencies; you also wouldnâ€™t expect to
    reproduce the exact correlations here:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œæ ¹æ®è¿™ä¸¤ä¸ªå˜é‡çš„æƒé‡ï¼Œå³ä½¿å­˜åœ¨çº¿æ€§ä¾èµ–ï¼Œä½ ä¹Ÿä¸åº”è¯¥æœŸæœ›å¾—åˆ° 1 çš„ç›¸å…³æ€§ï¼›åœ¨è¿™é‡Œï¼Œä¹Ÿä¸åº”è¯¥æœŸæœ›é‡ç°ç¡®åˆ‡çš„ç›¸å…³æ€§ï¼š
- en: '[PRE5]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Fit the model using three different coding approaches: (1) the direct implementation
    with the left-inverse as you learned in the previous chapter, (2) using NumPyâ€™s
    `lstsqr` function, and (3) using `statsmodels`. For all three methods, compute
    *R*Â² and the regression coefficients. Print the results as follows. The numerical
    instability of `np.linalg.inv` on a reduced-rank design matrix is apparent.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ä¸‰ç§ä¸åŒçš„ç¼–ç æ–¹æ³•æ‹Ÿåˆæ¨¡å‹ï¼š(1) ç›´æ¥å®ç°ï¼Œä½¿ç”¨ä½ åœ¨å‰ä¸€ç« å­¦åˆ°çš„å·¦é€†ï¼Œ(2) ä½¿ç”¨ NumPy çš„ `lstsqr` å‡½æ•°ï¼Œä»¥åŠ (3) ä½¿ç”¨ `statsmodels`ã€‚å¯¹äºè¿™ä¸‰ç§æ–¹æ³•ï¼Œè®¡ç®—
    *R*Â² å’Œå›å½’ç³»æ•°ã€‚æŒ‰å¦‚ä¸‹æ ¼å¼æ‰“å°ç»“æœã€‚åœ¨ä¸€ä¸ªé™ç§©è®¾è®¡çŸ©é˜µä¸Šï¼Œ`np.linalg.inv` çš„æ•°å€¼ä¸ç¨³å®šæ€§æ˜¾è€Œæ˜“è§ã€‚
- en: '[PRE6]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Side note: no errors or warning messages were given; Python simply gave outputs
    even though there is clearly something wrong with the design matrix. We can debate
    the merits of this, but this example highlightsâ€”yet againâ€”that understanding the
    linear algebra of data science is important, and that proper data science is about
    more than just knowing the math.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: é™„æ³¨ï¼šPython æ²¡æœ‰ç»™å‡ºä»»ä½•é”™è¯¯æˆ–è­¦å‘Šæ¶ˆæ¯ï¼›å³ä½¿è®¾è®¡çŸ©é˜µæ˜æ˜¾æœ‰é—®é¢˜ï¼ŒPython ä¹Ÿåªæ˜¯ç®€å•åœ°ç»™å‡ºäº†è¾“å‡ºã€‚æˆ‘ä»¬å¯ä»¥è®¨è®ºè¿™æ ·åšçš„ä¼˜ç‚¹ï¼Œä½†è¿™ä¸ªä¾‹å­å†æ¬¡çªæ˜¾äº†ç†è§£æ•°æ®ç§‘å­¦çš„çº¿æ€§ä»£æ•°çš„é‡è¦æ€§ï¼Œè‰¯å¥½çš„æ•°æ®ç§‘å­¦ä¸ä»…ä»…æ˜¯äº†è§£æ•°å­¦ã€‚
- en: Regularization Exercise
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ­£åˆ™åŒ–ç»ƒä¹ 
- en: Exercise 12-4\.
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  12-4\.
- en: 'Here you will explore the effects of regularization on the reduced-rank design
    matrix that you created in the previous exercise. Start by implementing <math
    alttext="left-parenthesis bold upper X Superscript upper T Baseline bold upper
    X plus gamma parallel-to bold upper X parallel-to Subscript upper F Superscript
    2 Baseline bold upper I right-parenthesis Superscript negative 1"><mrow><mrow><mo>(</mo></mrow>
    <msup><mi>ğ—</mi> <mtext>T</mtext></msup> <mi>ğ—</mi> <mo>+</mo> <msubsup><mrow><mi>Î³</mi><mo>âˆ¥</mo><mi>ğ—</mi><mo>âˆ¥</mo></mrow>
    <mi>F</mi> <mn>2</mn></msubsup> <msup><mrow><mi>ğˆ</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math>
    , using <math alttext="gamma equals 0"><mrow><mi>Î³</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    and <math display="inline"><mrow><mi>Î³</mi><mo>=</mo><mn>.01</mn></mrow></math>.
    Print out the size and rank of the two matrices. Here are my results (itâ€™s interesting
    to see that the rank-3 design matrix is so numerically unstable that its â€œinverseâ€
    is actually rank-2):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™é‡Œï¼Œæ‚¨å°†æ¢ç´¢æ­£åˆ™åŒ–å¯¹æ‚¨åœ¨ä¸Šä¸€ä¸ªç»ƒä¹ ä¸­åˆ›å»ºçš„é™ç§©è®¾è®¡çŸ©é˜µçš„å½±å“ã€‚é¦–å…ˆï¼Œå®ç° <math alttext="left-parenthesis bold
    upper X Superscript upper T Baseline bold upper X plus gamma parallel-to bold
    upper X parallel-to Subscript upper F Superscript 2 Baseline bold upper I right-parenthesis
    Superscript negative 1"><mrow><mrow><mo>(</mo></mrow> <msup><mi>ğ—</mi> <mtext>T</mtext></msup>
    <mi>ğ—</mi> <mo>+</mo> <msubsup><mrow><mi>Î³</mi><mo>âˆ¥</mo><mi>ğ—</mi><mo>âˆ¥</mo></mrow>
    <mi>F</mi> <mn>2</mn></msubsup> <msup><mrow><mi>ğˆ</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math>
    ï¼Œä½¿ç”¨ <math alttext="gamma equals 0"><mrow><mi>Î³</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    å’Œ <math display="inline"><mrow><mi>Î³</mi><mo>=</mo><mn>.01</mn></mrow></math>ã€‚æ‰“å°å‡ºä¸¤ä¸ªçŸ©é˜µçš„å¤§å°å’Œç§©ã€‚è¿™é‡Œæ˜¯æˆ‘çš„ç»“æœï¼ˆæœ‰è¶£çš„æ˜¯çœ‹åˆ°ç§©-3è®¾è®¡çŸ©é˜µå¦‚æ­¤æ•°å€¼ä¸ç¨³å®šï¼Œå…¶â€œé€†â€å®é™…ä¸Šæ˜¯ç§©-2ï¼‰ï¼š
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now for the experiment. The goal here is to explore the effects of regularization
    on the fit of the model to the data. Write code that will compute the fit to the
    data as *R*Â² using least squares with regularization on the design matrices with
    and without multicollinearity. Put that code into a `for` loop that implements
    a range of <math alttext="gamma"><mi>Î³</mi></math> values between 0 and .2\. Then
    show the results in a figure like [FigureÂ 12-10](#fig_12_10).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨è¿›è¡Œå®éªŒã€‚è¿™é‡Œçš„ç›®æ ‡æ˜¯æ¢ç´¢æ­£åˆ™åŒ–å¯¹æ¨¡å‹å¯¹æ•°æ®çš„æ‹Ÿåˆæ•ˆæœçš„å½±å“ã€‚ç¼–å†™ä»£ç ï¼Œä½¿ç”¨å¸¦æœ‰å’Œä¸å¸¦æœ‰å¤šé‡å…±çº¿æ€§çš„è®¾è®¡çŸ©é˜µçš„æœ€å°äºŒä¹˜æ³•è®¡ç®—æ•°æ®çš„æ‹Ÿåˆ *R*Â²ã€‚å°†è¯¥ä»£ç æ”¾å…¥ä¸€ä¸ª
    `for` å¾ªç¯ä¸­ï¼Œå®ç°ä» 0 åˆ° .2 çš„ä¸€ç³»åˆ— <math alttext="gamma"><mi>Î³</mi></math> å€¼ã€‚ç„¶ååƒ [FigureÂ 12-10](#fig_12_10)
    é‚£æ ·å±•ç¤ºç»“æœã€‚
- en: By the way, it is trivial that the model fit decreases with increasing regularization
    for full-rank design matricesâ€”indeed, the purpose of regularization is to make
    the model less sensitive to the data. The important question is whether regularization
    improves the fit to a test dataset or validation fold that was excluded when fitting
    the model. If the regularization is beneficial, you would expect the generalizability
    of the regularized model to increase up to some <math alttext="gamma"><mi>Î³</mi></math>
    and then decrease again. Thatâ€™s a level of detail youâ€™d learn about in a dedicated
    statistics or machine learning book, although you will get to code cross-validation
    in [ChapterÂ 15](ch15.xhtml#Chapter_15).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: é¡ºä¾¿è¯´ä¸€å¥ï¼Œå¯¹äºå®Œå…¨ç§©çš„è®¾è®¡çŸ©é˜µæ¥è¯´ï¼Œéšç€æ­£åˆ™åŒ–çš„å¢åŠ ï¼Œæ¨¡å‹çš„æ‹Ÿåˆç¨‹åº¦ä¼šé™ä½â€”äº‹å®ä¸Šï¼Œæ­£åˆ™åŒ–çš„ç›®çš„æ˜¯ä½¿æ¨¡å‹å¯¹æ•°æ®çš„æ•æ„Ÿæ€§é™ä½ã€‚é‡è¦çš„é—®é¢˜æ˜¯æ­£åˆ™åŒ–æ˜¯å¦æ”¹å–„äº†å¯¹æµ‹è¯•æ•°æ®é›†æˆ–åœ¨æ‹Ÿåˆæ¨¡å‹æ—¶æ’é™¤çš„éªŒè¯æŠ˜å çš„æ‹Ÿåˆã€‚å¦‚æœæ­£åˆ™åŒ–æ˜¯æœ‰ç›Šçš„ï¼Œæ‚¨é¢„æœŸæ­£åˆ™åŒ–æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä¼šåœ¨æŸä¸ª
    <math alttext="gamma"><mi>Î³</mi></math> å€¼ä¸Šå¢åŠ ï¼Œç„¶åå†æ¬¡é™ä½ã€‚è¿™æ˜¯æ‚¨åœ¨ä¸“é—¨çš„ç»Ÿè®¡æˆ–æœºå™¨å­¦ä¹ ä¹¦ç±ä¸­ä¼šäº†è§£åˆ°çš„ç»†èŠ‚æ°´å¹³ï¼Œå°½ç®¡æ‚¨å°†åœ¨
    [ChapterÂ 15](ch15.xhtml#Chapter_15) ä¸­å­¦ä¹ äº¤å‰éªŒè¯çš„ç¼–ç ã€‚
- en: '![exercise 12-4](assets/plad_1210.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![exercise 12-4](assets/plad_1210.png)'
- en: Figure 12-10\. Results of Exercise 12-4
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 12-10\. Exercise 12-4 çš„ç»“æœ
- en: Polynomial Regression Exercise
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å¤šé¡¹å¼å›å½’ç»ƒä¹ 
- en: Exercise 12-5\.
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Exercise 12-5\.
- en: The purpose of this exercise is to fit the polynomial regression using a range
    of orders, from zero to nine. In a `for` loop, recompute the regression and the
    predicted data values. Show the results like in [FigureÂ 12-11](#fig_12_11).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç»ƒä¹ çš„ç›®çš„æ˜¯ä½¿ç”¨ä»é›¶åˆ°ä¹çš„ä¸€ç³»åˆ—é˜¶æ•°æ‹Ÿåˆå¤šé¡¹å¼å›å½’ã€‚åœ¨ `for` å¾ªç¯ä¸­ï¼Œé‡æ–°è®¡ç®—å›å½’å’Œé¢„æµ‹æ•°æ®å€¼ã€‚å±•ç¤ºç±»ä¼¼äº [FigureÂ 12-11](#fig_12_11)
    çš„ç»“æœã€‚
- en: '![exercise 12-5](assets/plad_1211.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![exercise 12-5](assets/plad_1211.png)'
- en: Figure 12-11\. Results of Exercise 12-5
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 12-11\. Exercise 12-5 çš„ç»“æœ
- en: This exercise highlights the problems with underfitting and overfitting. The
    model with too few parameters does a poor job at predicting the data. On the other
    hand, the model with many parameters fits the data *too well* and risks being
    overly sensitive to noise and failing to generalize to new data. Strategies for
    finding the balance between under- and overfitting include cross-validation and
    Bayes information criterion; these are topics that you would learn about in a
    machine learning or statistics book.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç»ƒä¹ çªå‡ºäº†æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚å‚æ•°è¿‡å°‘çš„æ¨¡å‹åœ¨é¢„æµ‹æ•°æ®æ—¶è¡¨ç°ä¸ä½³ã€‚å¦ä¸€æ–¹é¢ï¼Œå‚æ•°è¿‡å¤šçš„æ¨¡å‹è¿‡åº¦æ‹Ÿåˆæ•°æ®ï¼Œå¹¶ä¸”é£é™©è¿‡äºæ•æ„Ÿäºå™ªå£°å¹¶ä¸”æ— æ³•æ³›åŒ–åˆ°æ–°æ•°æ®ã€‚å¯»æ‰¾æ¬ æ‹Ÿåˆå’Œè¿‡æ‹Ÿåˆä¹‹é—´å¹³è¡¡çš„ç­–ç•¥åŒ…æ‹¬äº¤å‰éªŒè¯å’Œè´å¶æ–¯ä¿¡æ¯å‡†åˆ™ï¼›è¿™äº›æ˜¯æ‚¨åœ¨æœºå™¨å­¦ä¹ æˆ–ç»Ÿè®¡ä¹¦ç±ä¸­å­¦ä¹ çš„ä¸»é¢˜ã€‚
- en: Grid Search Exercises
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç½‘æ ¼æœç´¢ç»ƒä¹ 
- en: Exercise 12-6\.
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  12-6\.
- en: 'Your goal here is simple: reproduce [FigureÂ 12-8](#fig_12_8) following the
    instructions presented in the text around that figure. Print out the regression
    coefficients to compare. For example, the following results were obtained using
    the grid resolution parameter set to 50:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œçš„ç›®æ ‡å¾ˆç®€å•ï¼šæŒ‰ç…§å›´ç»•å›¾è¡¨å‘¨å›´ç»™å‡ºçš„æŒ‡ç¤ºé‡ç° [FigureÂ 12-8](#fig_12_8)ã€‚æ‰“å°å‡ºå›å½’ç³»æ•°ä»¥è¿›è¡Œæ¯”è¾ƒã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ç½‘æ ¼åˆ†è¾¨ç‡å‚æ•°è®¾ç½®ä¸º
    50 å¾—åˆ°äº†ä»¥ä¸‹ç»“æœï¼š
- en: '[PRE8]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Once you have working code, try a few different resolution parameters. I made
    [FigureÂ 12-8](#fig_12_8) using a resolution of 100; you should also try other
    values, e.g., 20 or 500\. Also note the computation time for higher resolution
    valuesâ€”and this is only a two-parameter model! An exhaustive high-resolution grid
    search for a 10-parameter model is extremely computationally intensive.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æ‚¨æœ‰äº†å¯è¿è¡Œçš„ä»£ç ï¼Œè¯·å°è¯•å‡ ä¸ªä¸åŒçš„åˆ†è¾¨ç‡å‚æ•°ã€‚æˆ‘ä½¿ç”¨åˆ†è¾¨ç‡ä¸º 100 åˆ¶ä½œäº† [FigureÂ 12-8](#fig_12_8)ï¼›æ‚¨è¿˜åº”å°è¯•å…¶ä»–å€¼ï¼Œä¾‹å¦‚
    20 æˆ– 500ã€‚åŒæ—¶æ³¨æ„æ›´é«˜åˆ†è¾¨ç‡å€¼çš„è®¡ç®—æ—¶é—´â€”â€”è¿™åªæ˜¯ä¸€ä¸ªåŒå‚æ•°æ¨¡å‹ï¼å¯¹äºä¸€ä¸ª 10 å‚æ•°æ¨¡å‹çš„è¯¦å°½é«˜åˆ†è¾¨ç‡ç½‘æ ¼æœç´¢æå…¶è®¡ç®—å¯†é›†ã€‚
- en: Exercise 12-7\.
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: ç»ƒä¹  12-7\.
- en: 'You have seen two different methods for evaluating the fit of a model to data:
    sum of squared errors and *R*Â². In the previous exercise, you used the sum of
    squared errors to evaluate the model fit to data; in this exercise, you will determine
    whether *R*Â² is equally viable.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: æ‚¨å·²ç»äº†è§£äº†ä¸¤ç§ä¸åŒçš„æ–¹æ³•æ¥è¯„ä¼°æ¨¡å‹å¯¹æ•°æ®çš„æ‹Ÿåˆåº¦ï¼šå¹³æ–¹è¯¯å·®å’Œ *R*Â²ã€‚åœ¨å‰ä¸€ä¸ªç»ƒä¹ ä¸­ï¼Œæ‚¨ä½¿ç”¨äº†å¹³æ–¹è¯¯å·®æ¥è¯„ä¼°æ¨¡å‹å¯¹æ•°æ®çš„æ‹Ÿåˆåº¦ï¼›åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œæ‚¨å°†ç¡®å®š
    *R*Â² æ˜¯å¦åŒæ ·å¯è¡Œã€‚
- en: 'The coding part of this exercise is simple: modify the code from the previous
    exercise to compute *R*Â² instead of SSE (make sure to modify a copy of the code
    instead of overwriting the previous exercise).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªç»ƒä¹ çš„ç¼–ç éƒ¨åˆ†å¾ˆç®€å•ï¼šä¿®æ”¹ä¸Šä¸€ä¸ªç»ƒä¹ çš„ä»£ç ï¼Œè®¡ç®— *R*Â² è€Œä¸æ˜¯ SSEï¼ˆç¡®ä¿ä¿®æ”¹ä»£ç çš„å‰¯æœ¬è€Œä¸æ˜¯è¦†ç›–ä¸Šä¸€ä¸ªç»ƒä¹ çš„ä»£ç ï¼‰ã€‚
- en: 'Now for the challenging part: you will find that *R*Â² is terrible! It gives
    a completely wrong answer. Your job is to figure out why that is (the online code
    solution contains a discussion on this point). Hint: store the predicted data
    from each parameter pair so you can inspect the predicted values, and then compare
    against the observed data.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„éƒ¨åˆ†ï¼šæ‚¨ä¼šå‘ç° *R*Â² å¾ˆç³Ÿç³•ï¼å®ƒç»™å‡ºäº†å®Œå…¨é”™è¯¯çš„ç­”æ¡ˆã€‚æ‚¨çš„ä»»åŠ¡æ˜¯æ‰¾å‡ºå…¶ä¸­çš„åŸå› ï¼ˆåœ¨çº¿ä»£ç è§£å†³æ–¹æ¡ˆä¸­åŒ…å«äº†å¯¹è¿™ä¸€ç‚¹çš„è®¨è®ºï¼‰ã€‚æç¤ºï¼šå­˜å‚¨æ¯ä¸ªå‚æ•°å¯¹çš„é¢„æµ‹æ•°æ®ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥æ£€æŸ¥é¢„æµ‹å€¼ï¼Œç„¶åä¸è§‚å¯Ÿæ•°æ®è¿›è¡Œæ¯”è¾ƒã€‚
- en: '^([1](ch12.xhtml#idm45733294729312-marker)) V E Sathishkumar, Jangwoo Park,
    and Yongyun Cho, â€œUsing Data Mining Techniques for Bike Sharing Demand Prediction
    in Metropolitan City,â€ *Computer Communications*, 153, (March 2020): 353â€“366,
    data downloaded from [*https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand*](https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '^([1](ch12.xhtml#idm45733294729312-marker)) V E Sathishkumar, Jangwoo Park
    å’Œ Yongyun Choï¼Œâ€œUsing Data Mining Techniques for Bike Sharing Demand Prediction
    in Metropolitan City,â€ *Computer Communications*, 153, (2020 å¹´ 3 æœˆ): 353â€“366ï¼Œæ•°æ®ä¸‹è½½è‡ª
    [*https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand*](https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand).'
- en: ^([2](ch12.xhtml#idm45733294283376-marker)) Wikipedia, s.v. â€œmulticollinearity,â€
    [*https://en.wikipedia.org/wiki/Multicollinearity*](https://en.wikipedia.org/wiki/Multicollinearity).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch12.xhtml#idm45733294283376-marker)) Wikipediaï¼Œs.v. â€œmulticollinearityâ€ï¼Œ[*https://en.wikipedia.org/wiki/Multicollinearity*](https://en.wikipedia.org/wiki/Multicollinearity).
- en: ^([3](ch12.xhtml#idm45733294153856-marker)) Max Roser, Hannah Ritchie, and Esteban
    Ortiz-Ospina, â€œWorld Population Growth,â€ OurWorldInData.org, 2013, [*https://ourworldindata.org/world-population-growth*](https://ourworldindata.org/world-population-growth).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch12.xhtml#idm45733294153856-marker)) Max Roser, Hannah Ritchie å’Œ Esteban
    Ortiz-Ospinaï¼Œâ€œWorld Population Growth,â€ OurWorldInData.org, 2013ï¼Œ[*https://ourworldindata.org/world-population-growth*](https://ourworldindata.org/world-population-growth).
- en: ^([4](ch12.xhtml#idm45733293926768-marker)) If you encounter Python errors,
    you might need to rerun previous code then re-create the design matrix variables.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch12.xhtml#idm45733293926768-marker)) å¦‚æœä½ é‡åˆ° Python é”™è¯¯ï¼Œå¯èƒ½éœ€è¦é‡æ–°è¿è¡Œä¹‹å‰çš„ä»£ç ï¼Œç„¶åé‡æ–°åˆ›å»ºè®¾è®¡çŸ©é˜µå˜é‡ã€‚
