- en: Chapter 12\. Least Squares Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章 最小二乘法应用
- en: In this chapter, you will see a few applications of least squares model fitting
    in real data. Along the way, you will learn how to implement least squares using
    several different—and more numerically stable—Python functions, and you will learn
    some new concepts in statistics and machine learning such as multicollinearity,
    polynomial regression, and the grid search algorithm as an alternative to least
    squares.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将看到最小二乘模型拟合在真实数据中的几个应用。在此过程中，您将学习如何使用几种不同——更加数值稳定的Python函数实现最小二乘法，并学习统计学和机器学习中的一些新概念，如多重共线性、多项式回归以及网格搜索算法作为最小二乘法的替代方法。
- en: By the end of this chapter, you will have a deeper understanding of how least
    squares is used in applications, including the importance of numerically stable
    algorithms for “difficult” situations involving reduced-rank design matrices.
    And you will see that the analytic solution provided by least squares outperforms
    an empirical parameter search method.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章的学习，您将更深入地了解最小二乘法在应用中的使用，包括在涉及降秩设计矩阵的“困难”情况中，数值稳定算法的重要性。您将看到，最小二乘法提供的解析解优于经验参数搜索方法。
- en: Predicting Bike Rentals Based on Weather
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于天气预测自行车租赁
- en: I’m a big fan of bicycles and a big fan of bibimbap (a Korean dish made with
    rice and veggies or meat). Therefore, I was happy to find a publicly available
    dataset about bike rentals in Seoul.^([1](ch12.xhtml#idm45733294729312)) The dataset
    contains nearly nine thousand observations of data about the number of bikes that
    were rented in the city and variables about the weather including temperature,
    humidity, rainfall, windspeed, and so on.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我是自行车和韩国拌饭（一道用米饭、蔬菜或肉类制作的韩国菜）的铁杆粉丝。因此，我很高兴在首尔找到了一个公开可用的关于自行车租赁的数据集。^([1](ch12.xhtml#idm45733294729312))
    这个数据集包含了近九千条数据观测，涉及城市中租赁自行车数量以及与天气相关的变量，如温度、湿度、降雨量、风速等等。
- en: The purpose of the dataset is to predict the demand for bike sharing based on
    weather and season. That is important because it will help bike rental companies
    and local governments optimize the availability of healthier modes of transportation.
    It’s a great dataset, there’s a lot that could be done with it, and I encourage
    you to spend time exploring it. In this chapter, I will focus on building relatively
    simple regression models to predict bike rental counts based on a few features.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的目的是基于天气和季节预测共享单车的需求。这一点非常重要，因为它将帮助自行车租赁公司和地方政府优化更健康的交通方式的可用性。这是一个很棒的数据集，有很多可以做的事情，我鼓励您花时间探索它。在本章中，我将重点介绍基于少数特征预测自行车租赁数量的相对简单的回归模型建立。
- en: Although this is a book on linear algebra and not statistics, it is still important
    to inspect the data carefully before applying and interpreting statistical analyses.
    The online code has more details about importing and inspecting the data using
    the pandas library. [Figure 12-1](#fig_12_1) shows the data from bike count rentals
    (the dependent variable) and rainfall (one of the independent variables).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一本关于线性代数而非统计学的书籍，但在应用和解释统计分析之前仍然重要仔细检查数据。在线代码有关使用pandas库导入和检查数据的详细信息。[图12-1](#fig_12_1)
    展示了自行车计数租赁数据（因变量）和降雨量（其中一个自变量）。
- en: '![Korean bike rental data](assets/plad_1201.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![韩国自行车租赁数据](assets/plad_1201.png)'
- en: Figure 12-1\. Scatterplots of some data
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图12-1 散点图展示了一些数据
- en: Notice that rainfall is a sparse variable—it’s mostly zeros with a relatively
    small number of nonzero values. We’ll come back to this in the exercises.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，降雨量是一个稀疏变量——大部分是零，只有少量非零值。我们将在练习中再次回顾这一点。
- en: '[Figure 12-2](#fig_12_2) shows a correlation matrix from four selected variables.
    Inspecting correlation matrices is always a good idea before starting statistical
    analyses, because it will show which variables (if any) are correlated and can
    reveal errors in the data (e.g., if two supposedly different variables are perfectly
    correlated). In this case, we see that bike rental count is positively correlated
    with *hour* and *temperature* (people rent more bikes later in the day and when
    the weather is warmer) and negatively correlated with *rainfall*. (Note that I’m
    not showing statistical significance here, so these interpretations are qualitative.)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-2](#fig_12_2) 展示了四个选定变量的相关矩阵。在开始统计分析之前检查相关矩阵总是个好主意，因为它将显示哪些变量（如果有的话）相关，并且可以显示数据中的错误（例如，如果两个看似不同的变量完全相关）。在这种情况下，我们看到自行车租赁次数与*小时*和*温度*呈正相关（人们在一天后期和天气更暖时租更多自行车），与*降雨量*呈负相关。（请注意，我这里没有展示统计显著性，因此这些解释是定性的。）'
- en: '![Correlation matrix](assets/plad_1202.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![相关矩阵](assets/plad_1202.png)'
- en: Figure 12-2\. Correlation matrix of four selected variables
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-2\. 四个选定变量的相关矩阵
- en: In the first analysis, I want to predict bike rental counts based on rainfall
    and the seasons. The seasons (winter, spring, summer, fall) are text labels in
    the dataset, and we need to convert them to numbers for the analysis. We could
    translate the four seasons into the numbers 1–4, but seasons are circular while
    regressions are linear. There are a few ways to deal with this, including using
    an ANOVA instead of a regression, using one-hot-encoding (used in deep learning
    models), or binarizing the seasons. I’m going to take the latter approach and
    label autumn and winter “0” and spring and summer “1”. The interpretation is that
    a positive beta coefficient indicates more bike rentals in spring/summer compared
    to autumn/winter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次分析中，我想基于降雨量和季节来预测自行车租赁次数。季节（冬季、春季、夏季、秋季）是数据集中的文本标签，我们需要将它们转换为数字进行分析。我们可以将四季转换为数字
    1–4，但季节是循环的，而回归是线性的。有几种处理方式，包括使用方差分析（ANOVA）代替回归，使用独热编码（在深度学习模型中使用），或者对季节进行二值化处理。我将采取后者的方法，并将秋季和冬季标记为“0”，春季和夏季标记为“1”。解释是，正的
    beta 系数表明春夏季节的自行车租赁次数比秋冬季节要多。
- en: '(Tangential note: on the one hand, I could have made things simpler by selecting
    only continuous variables. But I want to stress that there is more to data science
    than just applying a formula to a dataset; there are many nontrivial decisions
    that affect the kinds of analyses you can do, and therefore the kinds of results
    you can obtain.)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: （旁注：一方面，我本可以通过选择仅连续变量来简化事情。但是我想强调的是，数据科学不仅仅是将公式应用于数据集；有许多非平凡的决策会影响您可以进行的分析类型，从而影响您可以获得的结果。）
- en: The left side of [Figure 12-3](#fig_12_3) shows the design matrix visualized
    as an image. This is a common representation of the design matrix, so make sure
    you are comfortable interpreting it. The columns are regressors and the rows are
    observations. Columns are sometimes normalized to facilitate visual interpretation
    if the regressors are in very different numerical scales, although I didn’t do
    that here. You can see that rainfall is sparse and that the dataset spans two
    autumn/winter periods (black areas in the middle column) and one spring/summer
    period (white area in the middle). The intercept is, of course, solid white, because
    it takes the same value for every observation.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-3](#fig_12_3) 的左侧展示了设计矩阵的图像化表示。这是设计矩阵的常见表示方式，因此请确保您能够舒适地解释它。列是回归器，行是观察结果。如果回归器处于非常不同的数值尺度，有时会对列进行归一化以便于视觉解释，尽管我在这里没有这样做。您可以看到降雨很稀疏，并且数据集跨越了两个秋冬季节（中间列的黑色区域）和一个春夏季节（中间的白色区域）。截距当然是纯白色，因为它对每个观察结果都采用相同的值。'
- en: '![Design matrix](assets/plad_1203.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![设计矩阵](assets/plad_1203.png)'
- en: Figure 12-3\. Design matrix and some data
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-3\. 设计矩阵和一些数据
- en: The right side of [Figure 12-3](#fig_12_3) shows the data, plotted as rainfall
    by bikes rented separately for the two seasons. Clearly, the data do not lie on
    a line, because there are many values at or close to zero on both axes. In other
    words, visually inspecting the data suggests that the relationships amongst the
    variables are nonlinear, which means that a linear modeling approach might be
    suboptimal. Again, this highlights the importance of visually inspecting data
    and carefully selecting an appropriate statistical model.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-3](#fig_12_3)的右侧显示了数据，将降雨量和租赁自行车分别绘制在两个季节上。显然，数据不在一条直线上，因为两个坐标轴上都有许多接近或等于零的值。换句话说，通过视觉检查数据表明变量之间的关系是非线性的，这意味着线性建模方法可能不够优化。再次强调，视觉检查数据和仔细选择合适的统计模型的重要性。'
- en: 'Nonetheless, we will forge ahead using a linear model fit to the data using
    least squares. The following code shows how I created the design matrix (variable
    `data` is a pandas dataframe):'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们将使用最小二乘法拟合的线性模型继续前进。以下代码展示了我如何创建设计矩阵（变量`data`是一个 pandas 数据帧）：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The beta values for *rainfall* and *season* are, respectively, −80 and 369\.
    These numbers indicate that there are fewer bike rentals when it rains and that
    there are more bike rentals in the spring/summer compared to autumn/winter.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*降雨量*和*季节*的β值分别为−80和369。这些数字表明，下雨时自行车租赁较少，春季/夏季比秋季/冬季租赁更多。'
- en: '[Figure 12-4](#fig_12_4) shows the predicted versus the observed data, separated
    for the two seasons. If the model were a perfect fit to the data, the dots would
    lie on a diagonal line with a slope of 1\. Clearly, that’s not the case, meaning
    that the model did not fit the data very well. Indeed, the *R*² is a paltry 0.097
    (in other words, the statistical model accounts for around 1% of the variance
    in the data). Futhermore, you can see that the model predicts *negative* bike
    rentals, which is not interpretable—bike rental counts are strictly nonnegative
    numbers.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-4](#fig_12_4)显示了预测与观察数据的对比，分别针对两个季节。如果模型完全拟合数据，点应该在具有斜率1的对角线上。显然，情况并非如此，这意味着模型并未很好地拟合数据。事实上，*R*²仅为0.097（换句话说，统计模型解释数据变异约为1%）。此外，你可以看到模型预测出了*负*自行车租赁数量，这是无法解释的——自行车租赁数量严格来说是非负数。'
- en: '![Predicted and observed data](assets/plad_1204.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![预测与观察数据](assets/plad_1204.png)'
- en: Figure 12-4\. Scatterplot of predicted by observed data
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图12-4。预测与观察数据的散点图
- en: Thus far in the code, we have received no warnings or errors; we have done nothing
    wrong in terms of math or coding. However, the statistical model we used is not
    the most appropriate for this research question. You will have the opportunity
    to improve it in [Exercise 12-1](#exercise_12_1) and [Exercise 12-2](#exercise_12_2).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在代码中我们没有收到任何警告或错误；在数学或编码方面我们没有做错任何事情。然而，我们使用的统计模型并不适合这个研究问题。你将有机会在[练习
    12-1](#exercise_12_1)和[练习 12-2](#exercise_12_2)中改进它。
- en: Regression Table Using statsmodels
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 statsmodels 的回归表
- en: 'Without getting too deep into the statistics, I want to show you how to create
    a regression table using the statsmodels library. This library works with pandas
    dataframes instead of NumPy arrays. The following code shows how to set up and
    compute the regression model (OLS stands for *ordinary least squares*):'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 不深入统计学，我想向你展示如何使用 statsmodels 库创建回归表。该库使用 pandas 数据帧而不是 NumPy 数组。以下代码展示了如何设置和计算回归模型（OLS代表*普通最小二乘法*）：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The regression table contains a lot of information. It’s OK if you don’t understand
    all of it; the key items you can look for are the *R*² and the regression coefficients
    (`coef`) for the regressors:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 回归表包含大量信息。如果你不理解全部内容，没关系；你可以查看的关键项目是*R*²和回归系数(`coef`)：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Multicollinearity
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多重共线性
- en: If you’ve taken a statistics course, you might have heard of the term *multicollinearity*.
    The Wikipedia definition is “one predictor variable in a multiple regression model
    can be linearly predicted from the others with a substantial degree of accuracy.”^([2](ch12.xhtml#idm45733294283376))
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你学过统计课程，可能听说过*多重共线性*这个术语。维基百科的定义是：“多元回归模型中的一个预测变量可以通过其他变量进行线性预测，并且预测精度相当高。”^([2](ch12.xhtml#idm45733294283376))
- en: This means that there are linear dependencies in the design matrix. In the parlance
    of linear algebra, multicollinearity is just a fancy term for *linear dependence*,
    which is the same thing as saying that the design matrix is reduced-rank or that
    it is singular.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着设计矩阵中存在线性依赖关系。在线性代数中，多重共线性只是*线性依赖*的一个花哨术语，意思是设计矩阵是降秩的或者是奇异的。
- en: A reduced-rank design matrix does not have a left-inverse, which means that
    the least squares problem cannot be solved analytically. You will see the implications
    of multicollinearity in [Exercise 12-3](#exercise_12_3).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 降秩的设计矩阵没有左逆，这意味着无法通过解析方法解决最小二乘问题。你将在[Exercise 12-3](#exercise_12_3)中看到多重共线性的影响。
- en: Regularization
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化
- en: '*Regularization* is an umbrella term that refers to various ways of modifying
    a statistical model, with the goal of improving numerical stability, transforming
    singular or ill-conditioned matrices to full-rank (and thus invertible), or improving
    generalizability by reducing overfitting. There are several forms of regularization
    depending on the nature of the problem and the goal of regularizing; some specific
    techniques you might have heard of include Ridge (a.k.a. L2), Lasso (a.k.a. L1),
    Tikhonov, and shrinkage.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*正则化*是一个统称，指的是通过各种方式修改统计模型，以提高数值稳定性，将奇异或病态矩阵转换为满秩（从而可逆），或通过减少过拟合来提高泛化能力的目的。根据问题的性质和正则化的目标，有几种形式的正则化；你可能听说过的一些具体技术包括岭回归（又称L2）、Lasso回归（又称L1）、Tikhonov和收缩法。'
- en: Different regularization techniques work in different ways, but many regularizers
    “shift” the design matrix by some amount. You will recall from [Chapter 5](ch05.xhtml#Chapter_5)
    that shifting a matrix means adding some constant to the diagonal as <math alttext="bold
    upper A plus lamda bold upper I"><mrow><mi>𝐀</mi> <mo>+</mo> <mi>λ</mi> <mi>𝐈</mi></mrow></math>
    , and from [Chapter 6](ch06.xhtml#Chapter_6) that shifting a matrix can transform
    a reduced-rank matrix into a full-rank matrix.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的正则化技术有不同的工作方式，但许多正则化器通过某种程度的“移动”设计矩阵来实现。你可能还记得从[Chapter 5](ch05.xhtml#Chapter_5)中，移动矩阵意味着在对角线上添加某个常数，如<math
    alttext="bold upper A plus lamda bold upper I"><mrow><mi>𝐀</mi> <mo>+</mo> <mi>λ</mi>
    <mi>𝐈</mi></mrow></math>，以及从[Chapter 6](ch06.xhtml#Chapter_6)中，移动矩阵可以将降秩矩阵转换为满秩矩阵。
- en: In this chapter, we will regularize the design matrix by shifting it according
    to some proportion of its Frobenius norm. This modifies the least squares solution
    [Equation 12-1](#regularization).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将根据其Frobenius范数的某比例来对设计矩阵进行正则化。这修改了最小二乘解[方程式 12-1](#regularization)。
- en: Equation 12-1\. Regularization
  id: totrans-39
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 方程式 12-1\. 正则化
- en: <math alttext="beta equals left-parenthesis bold upper X Superscript upper T
    Baseline bold upper X plus gamma parallel-to bold upper X parallel-to Subscript
    upper F Superscript 2 Baseline bold upper I right-parenthesis Superscript negative
    1 Baseline bold upper X Superscript upper T Baseline bold y" display="block"><mrow><mrow><mi>β</mi>
    <mo>=</mo> <mo>(</mo></mrow> <msup><mi>𝐗</mi> <mtext>T</mtext></msup> <mi>𝐗</mi>
    <mo>+</mo> <msubsup><mrow><mi>γ</mi><mo>∥</mo><mi>𝐗</mi><mo>∥</mo></mrow> <mi>F</mi>
    <mn>2</mn></msubsup> <msup><mrow><mi>𝐈</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>𝐗</mi> <mtext>T</mtext></msup> <mi>𝐲</mi></mrow></math>
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="beta equals left-parenthesis bold upper X Superscript upper T
    Baseline bold upper X plus gamma parallel-to bold upper X parallel-to Subscript
    upper F Superscript 2 Baseline bold upper I right-parenthesis Superscript negative
    1 Baseline bold upper X Superscript upper T Baseline bold y" display="block"><mrow><mrow><mi>β</mi>
    <mo>=</mo> <mo>(</mo></mrow> <msup><mi>𝐗</mi> <mtext>T</mtext></msup> <mi>𝐗</mi>
    <mo>+</mo> <msubsup><mrow><mi>γ</mi><mo>∥</mo><mi>𝐗</mi><mo>∥</mo></mrow> <mi>F</mi>
    <mn>2</mn></msubsup> <msup><mrow><mi>𝐈</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup>
    <msup><mi>𝐗</mi> <mtext>T</mtext></msup> <mi>𝐲</mi></mrow></math>
- en: The key parameter is <math alttext="gamma"><mi>γ</mi></math> (Greek letter *gamma*),
    which determines the amount of regularization (observe that <math alttext="gamma
    equals 0"><mrow><mi>γ</mi> <mo>=</mo> <mn>0</mn></mrow></math> corresponds to
    no regularization). Choosing an appropriate <math alttext="gamma"><mi>γ</mi></math>
    parameter is nontrivial, and is often done through statistical techniques like
    cross-validation.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 关键参数是<math alttext="gamma"><mi>γ</mi></math>（希腊字母*gamma*），它决定了正则化的程度（注意到<math
    alttext="gamma equals 0"><mrow><mi>γ</mi> <mo>=</mo> <mn>0</mn></mrow></math>意味着没有正则化）。选择适当的<math
    alttext="gamma"><mi>γ</mi></math>参数并非易事，通常通过交叉验证等统计技术来完成。
- en: The most obvious effect of regularization is that if the design matrix is reduced-rank,
    then the regularized squared design matrix is full-rank. Regularization also decreases
    the condition number, which measures the “spread” of information in the matrix
    (it’s the ratio of the largest to the smallest singular value; you’ll learn about
    this in [Chapter 14](ch14.xhtml#Chapter_14)). This increases the numerical stability
    of the matrix. The statistical implication of regularization is to “smooth out”
    the solution by reducing the sensitivity of the model to individual data points
    that might be outliers or nonrepresentative, and therefore less likely to be observed
    in new datasets.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化最明显的效果是，如果设计矩阵是降秩的，那么正则化后的平方设计矩阵将是满秩的。正则化还会降低条件数，这是矩阵信息“分布”范围的度量（它是最大和最小奇异值的比值；你将在[Chapter 14](ch14.xhtml#Chapter_14)学到更多）。这提高了矩阵的数值稳定性。正则化的统计含义是通过减少模型对可能是异常值或非代表性数据点的敏感性来“平滑”解决方案，因此更不可能在新数据集中观察到。
- en: Why do I scale by the squared Frobenius norm? Consider that a specified value
    of <math alttext="gamma"><mi>γ</mi></math> , say, <math alttext="gamma"><mi>γ</mi></math>
    = .01, can have a huge or a negligible impact on the design matrix depending on
    the range of numerical values in the matrix. Therefore, we scale to the numerical
    range of the matrix, which means we interpret the <math alttext="gamma"><mi>γ</mi></math>
    parameter as the *proportion* of regularization. The reason for squaring the Frobenius
    norm is that <math alttext="parallel-to bold upper X parallel-to equals parallel-to
    bold upper X Superscript upper T Baseline bold upper X parallel-to"><mrow><msubsup><mrow><mo>∥</mo><mi>𝐗</mi><mo>∥</mo></mrow>
    <mi>F</mi> <mn>2</mn></msubsup> <mo>=</mo> <msub><mrow><mo>∥</mo><msup><mi>𝐗</mi>
    <mtext>T</mtext></msup> <mi>𝐗</mi><mo>∥</mo></mrow> <mi>F</mi></msub></mrow></math>
    . In other words, the squared norm of the design matrix equals the norm of the
    design matrix times its transpose.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要按Frobenius范数的平方缩放？考虑指定的值<math alttext="gamma"><mi>γ</mi></math>，例如，<math
    alttext="gamma"><mi>γ</mi></math> = .01，可以根据矩阵中数值范围的不同对设计矩阵产生巨大或可忽略的影响。因此，我们按矩阵的数值范围进行缩放，这意味着我们将<math
    alttext="gamma"><mi>γ</mi></math>参数解释为*正则化的比例*。平方Frobenius范数的原因在于<math alttext="parallel-to
    bold upper X parallel-to equals parallel-to bold upper X Superscript upper T Baseline
    bold upper X parallel-to"><mrow><msubsup><mrow><mo>∥</mo><mi>𝐗</mi><mo>∥</mo></mrow>
    <mi>F</mi> <mn>2</mn></msubsup> <mo>=</mo> <msub><mrow><mo>∥</mo><msup><mi>𝐗</mi>
    <mtext>T</mtext></msup> <mi>𝐗</mi><mo>∥</mo></mrow> <mi>F</mi></msub></mrow></math>。换句话说，设计矩阵的平方范数等于设计矩阵与其转置的范数乘积。
- en: It’s actually more common to use the average of the eigenvalues of the design
    matrix instead of the Frobenius norm. After learning about eigenvalues in [Chapter 13](ch13.xhtml#Chapter_13),
    you’ll be able to compare the two regularization methods.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，通常使用设计矩阵的特征值平均值而不是Frobenius范数。在学习第[13章](ch13.xhtml#Chapter_13)中的特征值后，您将能够比较这两种正则化方法。
- en: Implementing regularization in code is the focus of [Exercise 12-4](#exercise_12_4).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中实现正则化是[练习 12-4](#exercise_12_4)的重点。
- en: Polynomial Regression
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多项式回归
- en: 'A *polynomial regression* is like a normal regression but the independent variables
    are the *x*-axis values raised to higher powers. That is, each column *i* of the
    design matrix is defined as *x*^i, where *x* is typically time or space but can
    be other variables such as medication dosage or population. The mathematical model
    looks like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*多项式回归*类似于普通回归，但独立变量是*x*轴值的高次幂。也就是说，设计矩阵的第*i*列定义为*x*^i，其中*x*通常是时间或空间，但也可以是其他变量，如药物剂量或人口。数学模型如下所示：'
- en: <math alttext="y equals beta 0 x Superscript 0 Baseline plus beta 1 x Superscript
    1 Baseline plus period period period plus beta Subscript n Baseline x Superscript
    n" display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>β</mi> <mn>0</mn></msub>
    <msup><mi>x</mi> <mn>0</mn></msup> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub>
    <msup><mi>x</mi> <mn>1</mn></msup> <mo>+</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo>
    <mo>+</mo> <msub><mi>β</mi> <mi>n</mi></msub> <msup><mi>x</mi> <mi>n</mi></msup></mrow></math>
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: <math alttext="y equals beta 0 x Superscript 0 Baseline plus beta 1 x Superscript
    1 Baseline plus period period period plus beta Subscript n Baseline x Superscript
    n" display="block"><mrow><mi>y</mi> <mo>=</mo> <msub><mi>β</mi> <mn>0</mn></msub>
    <msup><mi>x</mi> <mn>0</mn></msup> <mo>+</mo> <msub><mi>β</mi> <mn>1</mn></msub>
    <msup><mi>x</mi> <mn>1</mn></msup> <mo>+</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo>
    <mo>+</mo> <msub><mi>β</mi> <mi>n</mi></msub> <msup><mi>x</mi> <mi>n</mi></msup></mrow></math>
- en: Note that <math alttext="x Superscript 0 Baseline equals 1"><mrow><msup><mi>x</mi>
    <mn>0</mn></msup> <mo>=</mo> <mn>1</mn></mrow></math> , giving us the intercept
    of the model. Otherwise, it’s still a regular regression—the goal is to find the
    <math alttext="beta"><mi>β</mi></math> values that minimize the squared differences
    between the predicted and observed data.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，<math alttext="x Superscript 0 Baseline equals 1"><mrow><msup><mi>x</mi>
    <mn>0</mn></msup> <mo>=</mo> <mn>1</mn></mrow></math>，这给了我们模型的截距。否则，它仍然是普通回归——目标是找到使预测数据与观测数据的平方差最小化的<math
    alttext="beta"><mi>β</mi></math>值。
- en: The *order* of the polynomial is the largest power *i*. For example, a fourth
    order polynomial regression has terms up to <math alttext="x Superscript 4"><msup><mi>x</mi>
    <mn>4</mn></msup></math> (if there is no <math alttext="x cubed"><msup><mi>x</mi>
    <mn>3</mn></msup></math> term, then it’s still a fourth order model with <math
    alttext="beta 3 equals 0"><mrow><msub><mi>β</mi> <mn>3</mn></msub> <mo>=</mo>
    <mn>0</mn></mrow></math> ).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式的*次数*是最高次幂*i*。例如，一个四阶多项式回归包含高达<math alttext="x Superscript 4"><msup><mi>x</mi>
    <mn>4</mn></msup></math>的项（如果没有<math alttext="x cubed"><msup><mi>x</mi> <mn>3</mn></msup></math>项，则仍然是一个四阶模型，其中<math
    alttext="beta 3 equals 0"><mrow><msub><mi>β</mi> <mn>3</mn></msub> <mo>=</mo>
    <mn>0</mn></mrow></math>）。
- en: '[Figure 12-5](#fig_12_5) shows an example of the individual regressors and
    the design matrix of a third order polynomial (keep in mind that an *n*th order
    polynomial has *n* + 1 regressors including the intercept). The polynomial functions
    are the basis vectors for modeling the observed data.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-5](#fig_12_5)显示了三阶多项式的单个回归器和设计矩阵的示例（请记住，一个*n*次多项式包括拦截器在内的*n* + 1个回归器）。多项式函数是建模观测数据的基础向量。'
- en: '![Design matrix of a polynomial regression](assets/plad_1205.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![多项式回归的设计矩阵](assets/plad_1205.png)'
- en: Figure 12-5\. Design matrix of a polynomial regression
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-5\. 多项式回归的设计矩阵
- en: 'Other than the special design matrix, a polynomial regression is exactly the
    same as any other regression: use the left-inverse (or more computationally stable
    alternatives) to obtain the set of coefficients such that the weighted combination
    of regressors (i.e., the predicted data) best matches the observed data.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 除了特殊的设计矩阵外，多项式回归与任何其他回归完全相同：使用左逆（或更稳定的计算替代方案）获得一组系数，使得回归器的加权组合（即预测数据）最能匹配观察数据。
- en: Polynomial regressions are used in curve fitting and in approximating nonlinear
    functions. Applications include time series modeling, population dynamics, dose-response
    functions in medical research, and physical stresses on structural support beams.
    Polynomials can also be expressed in 2D, which are used to model spatial structure
    such as earthquake propagation and brain activity.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式回归用于曲线拟合和逼近非线性函数。应用包括时间序列建模、人口动态、医学研究中的剂量-反应函数以及结构支撑梁的物理应力。多项式也可以用于表达二维结构，用于模拟地震传播和脑活动等空间结构。
- en: Enough background. Let’s work through an example. The dataset I picked is from
    a model of human population doubling. The question is “How long does it take for
    the population of humanity to double (e.g., from five hundred million to one billion)?”
    If the rate of population increase is itself increasing (because more people have
    more babies, who grow up to have even more babies), then the doubling time will
    decrease with each doubling. On the other hand, if the population growth slows
    (people have fewer babies), then the doubling time will increase over successive
    doublings.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 背景足够了。让我们通过一个示例来工作。我选择的数据集来自人口翻倍模型。问题是“人类的人口翻倍需要多长时间（例如，从五亿到十亿）？”如果人口增长率本身正在增加（因为更多的人有更多的孩子，这些孩子长大后又会有更多的孩子），那么每次翻倍的时间将会减少。另一方面，如果人口增长放缓（人们生孩子的数量减少），那么连续翻倍的时间将会增加。
- en: I found a relevant dataset online.^([3](ch12.xhtml#idm45733294153856)) It’s
    a small dataset, so all the numbers are available in the online code and shown
    in [Figure 12-6](#fig_12_6). This dataset includes both actual measured data and
    projections to the year 2100\. These projections into the future are based on
    a number of assumptions, and no one really knows how the future will play out
    (that’s why you should find a balance between preparing for the future and enjoying
    the moment). Regardless, the data thus far shows that the human population doubled
    with increasing frequency over the past five hundred years (at least), and the
    authors of the dataset predict that the doubling rate will increase slightly over
    the next century.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我在网上找到了一个相关的数据集。^([3](ch12.xhtml#idm45733294153856)) 这是一个小数据集，因此所有数字都可以在在线代码中找到，并显示在[图 12-6](#fig_12_6)中。该数据集包括实际测量数据和对2100年的预测。这些对未来的预测基于多种假设，没有人确切知道未来会如何发展（这就是为什么你应该在未来的准备和享受当下之间找到平衡）。尽管如此，迄今数据显示，过去500年中人口的翻倍频率逐渐增加（至少如此），数据集的作者预测，这种翻倍速率在未来一个世纪内将略微增加。
- en: '![Predicted and observed data](assets/plad_1206.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![预测和观察数据](assets/plad_1206.png)'
- en: Figure 12-6\. Plot of the data
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-6\. 数据图
- en: 'I chose a third order polynomial to fit the data, and created and fit the model
    using the following code (variable `year` contains the *x*-axis coordinates and
    variable `doubleTime` contains the dependent variable):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了三阶多项式来拟合数据，并使用以下代码创建和拟合了模型（变量`year`包含*x*轴坐标，变量`doubleTime`包含依赖变量）：
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[Figure 12-7](#fig_12_7) shows the predicted data using the polynomial regression
    created by that code.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[图 12-7](#fig_12_7) 显示了使用该代码创建的多项式回归预测数据。'
- en: '![Predicted and observed data](assets/plad_1207.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![预测和观察数据](assets/plad_1207.png)'
- en: Figure 12-7\. Plot of the data
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-7\. 数据图
- en: The model captures both the downward trend and the projected upswing in the
    data. Without further statistical analysis, we cannot say that this is the *best*
    model or that the model is a statistically significantly good fit to the data.
    But it is clear that polynomial regressions are well suited for fitting curves.
    You will continue exploring this model and the data in [Exercise 12-5](#exercise_12_5),
    but I encourage you to play around with the code that produces [Figure 12-7](#fig_12_7)
    by testing different order parameters.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型捕捉到了数据中的下降趋势和预期的上升趋势。 没有进一步的统计分析，我们不能说这是*最佳*模型或者说该模型在统计上显著拟合数据。 但是很明显，多项式回归非常适合拟合曲线。
    你将继续探索这个模型和[练习 12-5](#exercise_12_5)中的数据，但我鼓励你通过测试不同的阶参数来玩弄生成[图 12-7](#fig_12_7)的代码。
- en: 'Polynomial regressions are commonly used, and NumPy has dedicated functions
    to create and fit such models:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式回归通常被使用，并且NumPy有专用函数来创建和拟合这样的模型：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Grid Search to Find Model Parameters
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用网格搜索找到模型参数
- en: Least squares via the left-inverse is a brilliant way to fit models to data.
    Least squares is accurate, fast, and deterministic (meaning that each time you
    rerun the code, you’ll get the same result). But it works only for linear model
    fitting, and not all models can be fit using linear methods.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法通过左逆来精确地将模型拟合到数据。 最小二乘法准确、快速且确定性（这意味着每次重新运行代码时，你都会得到相同的结果）。 但它仅适用于线性模型拟合，而不是所有模型都可以使用线性方法拟合。
- en: In this section, I will introduce you to another optimization method used to
    identify model parameters, known as *grid search*. A grid search works by sampling
    the parameter space, computing the model fit to the data with each parameter value,
    and then selecting the parameter value that gave the best model fit.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我将向你介绍另一种用于识别模型参数的优化方法，称为*网格搜索*。 网格搜索通过对参数空间进行采样，计算每个参数值对数据的模型拟合，并选择给出最佳模型拟合的参数值。
- en: As a simple example, let’s take the function <math alttext="y equals x squared"><mrow><mi>y</mi>
    <mo>=</mo> <msup><mi>x</mi> <mn>2</mn></msup></mrow></math> . We want to find
    the minimum of that function. Of course, we already know that the minimum is at
    <math alttext="x equals 0"><mrow><mi>x</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    ; this helps us understand and evaluate the results of the grid search method.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个简单的例子，让我们考虑函数<math alttext="y equals x squared"><mrow><mi>y</mi> <mo>=</mo>
    <msup><mi>x</mi> <mn>2</mn></msup></mrow></math>。 我们想找到该函数的最小值。 当然，我们已经知道最小值在<math
    alttext="x equals 0"><mrow><mi>x</mi> <mo>=</mo> <mn>0</mn></mrow></math>处；这有助于我们理解和评估网格搜索方法的结果。
- en: In the grid search technique, we start with a predefined set of <math alttext="x"><mi>x</mi></math>
    values to test. Let’s use the set (−2, −1, 0, 1, 2). That’s our “grid.” Then we
    compute the function at each of those grid values to obtain *y* = (4, 1, 0, 1,
    4). And we find that the minimum *y* occurs when <math alttext="x equals 0"><mrow><mi>x</mi>
    <mo>=</mo> <mn>0</mn></mrow></math> . In this case, the grid-based solution is
    the same as the true solution.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在网格搜索技术中，我们从一个预定义的<math alttext="x"><mi>x</mi></math>值集合开始测试。 让我们使用集合(−2, −1,
    0, 1, 2)。 这就是我们的“网格”。 然后我们计算每个网格值处的函数以获取*y* = (4, 1, 0, 1, 4)。 我们发现最小的*y*出现在<math
    alttext="x equals 0"><mrow><mi>x</mi> <mo>=</mo> <mn>0</mn></mrow></math> 。 在这种情况下，基于网格的解与真实解相同。
- en: But grid search is not guaranteed to give the optimal solution. For example,
    imagine our grid was (−2, −.5, 1, 2.5); the function values would be *y* = (4,
    .25, 1, 6.25), and we would conclude that <math display="inline"><mrow><mi>x</mi>
    <mo>=</mo> <mn>-.5</mn></mrow></math> is the parameter value that minimizes the
    function <math alttext="y equals x squared"><mrow><mi>y</mi> <mo>=</mo> <msup><mi>x</mi>
    <mn>2</mn></msup></mrow></math> . That conclusion is “kind of correct” because
    it is the best solution within the specified grid. Grid-search failures can also
    arise from a poorly chosen range of values. Imagine, for example, that our grid
    was (−1000, −990, −980, −970); we would conclude that <math alttext="y equals
    x squared"><mrow><mi>y</mi> <mo>=</mo> <msup><mi>x</mi> <mn>2</mn></msup></mrow></math>
    is minimized when <math display="inline"><mrow><mi>x</mi> <mo>=</mo> <mrow><mo>-</mo>
    <mn>970</mn></mrow></mrow></math> .
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，网格搜索不能保证给出最优解。例如，假设我们的网格是（−2, −0.5, 1, 2.5）；函数值将为*y* = (4, 0.25, 1, 6.25)，我们将得出结论
    <math display="inline"><mrow><mi>x</mi> <mo>=</mo> <mn>-.5</mn></mrow></math>
    是使函数 <math alttext="y equals x squared"><mrow><mi>y</mi> <mo>=</mo> <msup><mi>x</mi>
    <mn>2</mn></msup></mrow></math> 最小化的参数值。这个结论“有点正确”，因为它是在指定网格内的最佳解。网格搜索的失败也可能来自于值范围选择不当。例如，假设我们的网格是（−1000,
    −990, −980, −970）；我们会得出结论 <math alttext="y equals x squared"><mrow><mi>y</mi>
    <mo>=</mo> <msup><mi>x</mi> <mn>2</mn></msup></mrow></math> 在 <math display="inline"><mrow><mi>x</mi>
    <mo>=</mo> <mrow><mo>-</mo> <mn>970</mn></mrow></mrow></math> 时最小化。
- en: The point is that both the range and the resolution (the spacing between grid
    points) are important, because they determine whether you will obtain the *best*
    solution, a *pretty good* solution, or an *awful* solution. In the toy example
    above, the appropriate range and resolution are easy to detemine. In complicated,
    multivariate, nonlinear models, appropriate grid search parameters might take
    some more work and exploration.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 点在于范围和分辨率（格点之间的间距）都很重要，因为它们决定你是否会得到*最佳*解、*相当不错*的解或者*糟糕*的解。在上述玩具示例中，适当的范围和分辨率很容易确定。在复杂的、多变量的、非线性模型中，适当的网格搜索参数可能需要更多的工作和探索。
- en: 'I ran a grid search on the “happy student” data from the previous chapter (as
    a reminder: it was fake data from a fake survey showing that people who enrolled
    in more of my courses had higher life satisfaction). The model of those data has
    two parameters—intercept and slope—and so we evaluate that function at each point
    on a 2D grid of possible parameter pairings. Results are shown in [Figure 12-8](#fig_12_8).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我在上一章的“快乐学生”数据上进行了网格搜索（提醒一下：这是来自虚假调查的虚假数据，显示出参加我的课程更多的人生活满意度更高）。这些数据的模型有两个参数——截距和斜率——因此，我们在可能的参数对的二维网格上评估该函数。结果显示在
    [图 12-8](#fig_12_8) 中。
- en: What does that graph mean, and how do we interpret it? The two axes correspond
    to values of parameters, and therefore each coordinate in that graph creates a
    model with those corresponding parameter values. Then, the fit of each of those
    models to the data is calculated and stored, and visualized as an image.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 那个图表意味着什么，我们如何解释它？两个轴对应于参数的值，因此该图中的每个坐标创建了具有对应参数值的模型。然后，计算并存储每个模型对数据的拟合，并将其可视化为图像。
- en: The coordinate with the best fit to the data (the smallest sum of squared errors)
    is the optimal parameter set. [Figure 12-8](#fig_12_8) also shows the analytic
    solution using the least squares approach. They are close but not exactly overlapping.
    In [Exercise 12-6](#exercise_12_6), you will have the opportunity to implement
    this grid search as well as to explore the importance of the grid resolution on
    the accuracy of the results.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最适合数据的坐标（平方误差之和最小的）是最优参数集。[图 12-8](#fig_12_8) 也展示了使用最小二乘法的解析解。它们接近但不完全重叠。在 [练习 12-6](#exercise_12_6)
    中，您将有机会实现这个网格搜索，并探索网格分辨率对结果准确性的影响。
- en: '![Grid search versus least squares.](assets/plad_1208.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![网格搜索与最小二乘法的比较。](assets/plad_1208.png)'
- en: Figure 12-8\. Results from a grid search on the “happy student” dataset. The
    intensity shows the sum of squared errors fit to the data.
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图12-8\. 在“快乐学生”数据集上进行网格搜索的结果。强度显示了拟合到数据的平方误差之和。
- en: Why would anyone use grid search when least squares is better and faster? Well,
    you should never use a grid search method when least squares is a viable solution.
    Grid search is a useful technique for finding parameters in nonlinear models and
    is often used, for example, to identify hyperparameters in deep learning models
    (*hyperparameters* are model architecture design features that are selected by
    the researcher, not learned from data). Grid search can be time-consuming for
    large models, but parallelization can make grid search more feasible.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当最小二乘法更好且更快时，为什么会有人使用网格搜索呢？嗯，当最小二乘法是可行解决方案时，您永远不应该使用网格搜索方法。网格搜索是一种寻找非线性模型参数的有用技术，例如，用于识别深度学习模型中的超参数（*超参数*是研究人员选择的模型架构设计特征，而不是从数据中学习的）。对于大型模型来说，网格搜索可能是耗时的，但并行化可以使网格搜索变得更加可行。
- en: The conclusion is that grid search is a nonlinear method for fitting models
    to data when linear methods cannot be applied. Along your journey into data science
    and machine learning, you will also learn about additional nonlinear methods,
    including simplex and the famous gradient descent algorithm that powers deep learning.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 结论是，当无法应用线性方法时，网格搜索是将模型拟合到数据的非线性方法。在您学习数据科学和机器学习的过程中，您还将了解到其他非线性方法，包括单纯形和支持深度学习的著名梯度下降算法。
- en: Summary
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'I hope you enjoyed reading about applications of least squares and the comparison
    to other model-fitting approaches. The following exercises are the most important
    part of this chapter, so I don’t want to take up your time with a long summary.
    Here are the important points:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您喜欢阅读关于最小二乘法应用及与其他模型拟合方法比较的内容。以下练习是本章最重要的部分，因此我不想用长篇大论占用您的时间。以下是重点：
- en: Visual inspection of data is important for selecting the right statistical models
    and interpreting statistical results correctly.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对数据进行视觉检查对于选择正确的统计模型和正确解释统计结果非常重要。
- en: Linear algebra is used for quantitative assessments of datasets, including correlation
    matrices.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性代数用于对数据集进行定量评估，包括相关矩阵。
- en: The matrix visualization methods you learned in [Chapter 5](ch05.xhtml#Chapter_5)
    are useful for inspecting design matrices.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您在[第 5 章](ch05.xhtml#Chapter_5)中学到的矩阵可视化方法对于检查设计矩阵非常有用。
- en: Mathematical concepts are sometimes given different names in different fields.
    An example in this chapter is *multicollinearity*, which means linear dependences
    in the design matrix.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数学概念有时在不同领域会有不同的名称。本章的一个例子是*多重共线性*，指的是设计矩阵中的线性依赖关系。
- en: Regularization involves “shifting” the design matrix by some small amount, which
    can increase numerical stability and likelihood of generalizing the new data.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化涉及将设计矩阵“移动”一小部分，这可以增加数值稳定性并增加泛化新数据的可能性。
- en: Having a deep understanding of linear algebra can help you select the most appropriate
    statistical analyses, interpret the results, and anticipate potential problems.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对线性代数有深入理解可以帮助您选择最合适的统计分析方法，解释结果，并预测可能出现的问题。
- en: A polynomial regression is the same as a “regular” regression, but the columns
    in the design matrix are defined as the *x*-axis values raised to increasing powers.
    Polynomial regressions are used for curve fitting.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多项式回归与“常规”回归相同，但设计矩阵中的列定义为升高到不同幂的*x*轴值。多项式回归用于曲线拟合。
- en: Grid search is a nonlinear method of model fitting. Linear least squares is
    the optimal approach when the model is linear.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网格搜索是模型拟合的非线性方法。当模型是线性的时，最小二乘法是最优的方法。
- en: Code Exercises
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码练习
- en: Bike Rental Exercises
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自行车租赁练习
- en: Exercise 12-1\.
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 12-1\.
- en: Perhaps part of the problem with negative bike rentals in [Figure 12-4](#fig_12_4)
    can be alleviated by eliminating the no-rainfall days. Repeat the analysis and
    graph for this analysis, but select only the data rows that have zero rainfall.
    Do the results improve, in terms of higher *R*² and positive predicted rental
    counts?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 或许在[图 12-4](#fig_12_4)中负自行车租赁的问题部分可以通过消除无降雨日来缓解。重复分析并绘制这种分析的图表，但只选择具有零降雨的数据行。结果是否改善，以更高的*R*²和正预测租赁数量为评判标准？
- en: Exercise 12-2\.
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 12-2\.
- en: Because *seasons* is a categorical variable, an ANOVA would actully be a more
    appropriate statistical model than a regression. Maybe the binarized *seasons*
    lacks the sensitivity to predict bike rentals (for example, there can be warm
    sunny days in autumn and cold rainy days in spring), and therefore temperature
    might be a better predictor.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 *seasons* 是一个分类变量，ANOVA 实际上比回归更合适作为统计模型。也许二元化的 *seasons* 缺乏预测自行车租赁的敏感性（例如，秋天可能有温暖的晴天和春天可能有寒冷的雨天），因此
    *temperature* 可能是一个更好的预测变量。
- en: Replace *seasons* with *temperature* in the design matrix and rerun the regression
    (you can use all days, not only the no-rainfall days from the previous exercise),
    and reproduce [Figure 12-9](#fig_12_9). There is still the issue with predicting
    negative rentals (this is because of the linearity of the model), but the *R*²
    is higher and the prediction appears qualitatively better.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计矩阵中用 *temperature* 替换 *seasons* 并重新运行回归（可以使用所有天数，而不仅仅是上一个练习中的无降雨天数），并重现 [图 12-9](#fig_12_9)。仍然存在预测负租赁的问题（这是因为模型的线性性），但
    *R*² 更高，预测看起来质量更好。
- en: '![exercise 12-2](assets/plad_1209.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![练习 12-2](assets/plad_1209.png)'
- en: Figure 12-9\. Results of Exercise 12-2
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 12-9\. 练习 12-2 的结果
- en: Multicollinearity Exercise
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多重共线性练习
- en: Exercise 12-3\.
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 12-3\.
- en: This exercise continues with the model from [Exercise 12-2](#exercise_12_2).^([4](ch12.xhtml#idm45733293926768))
    This model contains three regressors, including the intercept. Create a new design
    matrix that contains a fourth regressor defined as some linear weighted combination
    of *temperature* and *rainfall*. Give this design matrix a different variable
    name, because you will need it in the next exercise. Confirm that the design matrix
    has four columns yet a rank of 3, and compute the correlation matrix of the design
    matrix.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习延续了来自 [练习 12-2](#exercise_12_2) 的模型。这个模型包含三个回归变量，包括截距项。创建一个新的设计矩阵，其中包含作为
    *temperature* 和 *rainfall* 的某种线性加权组合定义的第四个回归变量。给这个设计矩阵起一个不同的变量名，因为你将在下一个练习中用到它。确认设计矩阵有四列，但秩为
    3，并计算设计矩阵的相关矩阵。
- en: 'Note that depending on the weightings of the two variables, you wouldn’t expect
    a correlation of 1 even with linear dependencies; you also wouldn’t expect to
    reproduce the exact correlations here:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，根据这两个变量的权重，即使存在线性依赖，你也不应该期望得到 1 的相关性；在这里，也不应该期望重现确切的相关性：
- en: '[PRE5]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Fit the model using three different coding approaches: (1) the direct implementation
    with the left-inverse as you learned in the previous chapter, (2) using NumPy’s
    `lstsqr` function, and (3) using `statsmodels`. For all three methods, compute
    *R*² and the regression coefficients. Print the results as follows. The numerical
    instability of `np.linalg.inv` on a reduced-rank design matrix is apparent.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用三种不同的编码方法拟合模型：(1) 直接实现，使用你在前一章学到的左逆，(2) 使用 NumPy 的 `lstsqr` 函数，以及 (3) 使用 `statsmodels`。对于这三种方法，计算
    *R*² 和回归系数。按如下格式打印结果。在一个降秩设计矩阵上，`np.linalg.inv` 的数值不稳定性显而易见。
- en: '[PRE6]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Side note: no errors or warning messages were given; Python simply gave outputs
    even though there is clearly something wrong with the design matrix. We can debate
    the merits of this, but this example highlights—yet again—that understanding the
    linear algebra of data science is important, and that proper data science is about
    more than just knowing the math.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 附注：Python 没有给出任何错误或警告消息；即使设计矩阵明显有问题，Python 也只是简单地给出了输出。我们可以讨论这样做的优点，但这个例子再次突显了理解数据科学的线性代数的重要性，良好的数据科学不仅仅是了解数学。
- en: Regularization Exercise
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化练习
- en: Exercise 12-4\.
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 12-4\.
- en: 'Here you will explore the effects of regularization on the reduced-rank design
    matrix that you created in the previous exercise. Start by implementing <math
    alttext="left-parenthesis bold upper X Superscript upper T Baseline bold upper
    X plus gamma parallel-to bold upper X parallel-to Subscript upper F Superscript
    2 Baseline bold upper I right-parenthesis Superscript negative 1"><mrow><mrow><mo>(</mo></mrow>
    <msup><mi>𝐗</mi> <mtext>T</mtext></msup> <mi>𝐗</mi> <mo>+</mo> <msubsup><mrow><mi>γ</mi><mo>∥</mo><mi>𝐗</mi><mo>∥</mo></mrow>
    <mi>F</mi> <mn>2</mn></msubsup> <msup><mrow><mi>𝐈</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math>
    , using <math alttext="gamma equals 0"><mrow><mi>γ</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    and <math display="inline"><mrow><mi>γ</mi><mo>=</mo><mn>.01</mn></mrow></math>.
    Print out the size and rank of the two matrices. Here are my results (it’s interesting
    to see that the rank-3 design matrix is so numerically unstable that its “inverse”
    is actually rank-2):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您将探索正则化对您在上一个练习中创建的降秩设计矩阵的影响。首先，实现 <math alttext="left-parenthesis bold
    upper X Superscript upper T Baseline bold upper X plus gamma parallel-to bold
    upper X parallel-to Subscript upper F Superscript 2 Baseline bold upper I right-parenthesis
    Superscript negative 1"><mrow><mrow><mo>(</mo></mrow> <msup><mi>𝐗</mi> <mtext>T</mtext></msup>
    <mi>𝐗</mi> <mo>+</mo> <msubsup><mrow><mi>γ</mi><mo>∥</mo><mi>𝐗</mi><mo>∥</mo></mrow>
    <mi>F</mi> <mn>2</mn></msubsup> <msup><mrow><mi>𝐈</mi><mo>)</mo></mrow> <mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow></math>
    ，使用 <math alttext="gamma equals 0"><mrow><mi>γ</mi> <mo>=</mo> <mn>0</mn></mrow></math>
    和 <math display="inline"><mrow><mi>γ</mi><mo>=</mo><mn>.01</mn></mrow></math>。打印出两个矩阵的大小和秩。这里是我的结果（有趣的是看到秩-3设计矩阵如此数值不稳定，其“逆”实际上是秩-2）：
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now for the experiment. The goal here is to explore the effects of regularization
    on the fit of the model to the data. Write code that will compute the fit to the
    data as *R*² using least squares with regularization on the design matrices with
    and without multicollinearity. Put that code into a `for` loop that implements
    a range of <math alttext="gamma"><mi>γ</mi></math> values between 0 and .2\. Then
    show the results in a figure like [Figure 12-10](#fig_12_10).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进行实验。这里的目标是探索正则化对模型对数据的拟合效果的影响。编写代码，使用带有和不带有多重共线性的设计矩阵的最小二乘法计算数据的拟合 *R*²。将该代码放入一个
    `for` 循环中，实现从 0 到 .2 的一系列 <math alttext="gamma"><mi>γ</mi></math> 值。然后像 [Figure 12-10](#fig_12_10)
    那样展示结果。
- en: By the way, it is trivial that the model fit decreases with increasing regularization
    for full-rank design matrices—indeed, the purpose of regularization is to make
    the model less sensitive to the data. The important question is whether regularization
    improves the fit to a test dataset or validation fold that was excluded when fitting
    the model. If the regularization is beneficial, you would expect the generalizability
    of the regularized model to increase up to some <math alttext="gamma"><mi>γ</mi></math>
    and then decrease again. That’s a level of detail you’d learn about in a dedicated
    statistics or machine learning book, although you will get to code cross-validation
    in [Chapter 15](ch15.xhtml#Chapter_15).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，对于完全秩的设计矩阵来说，随着正则化的增加，模型的拟合程度会降低—事实上，正则化的目的是使模型对数据的敏感性降低。重要的问题是正则化是否改善了对测试数据集或在拟合模型时排除的验证折叠的拟合。如果正则化是有益的，您预期正则化模型的泛化能力会在某个
    <math alttext="gamma"><mi>γ</mi></math> 值上增加，然后再次降低。这是您在专门的统计或机器学习书籍中会了解到的细节水平，尽管您将在
    [Chapter 15](ch15.xhtml#Chapter_15) 中学习交叉验证的编码。
- en: '![exercise 12-4](assets/plad_1210.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![exercise 12-4](assets/plad_1210.png)'
- en: Figure 12-10\. Results of Exercise 12-4
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 12-10\. Exercise 12-4 的结果
- en: Polynomial Regression Exercise
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多项式回归练习
- en: Exercise 12-5\.
  id: totrans-118
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: Exercise 12-5\.
- en: The purpose of this exercise is to fit the polynomial regression using a range
    of orders, from zero to nine. In a `for` loop, recompute the regression and the
    predicted data values. Show the results like in [Figure 12-11](#fig_12_11).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习的目的是使用从零到九的一系列阶数拟合多项式回归。在 `for` 循环中，重新计算回归和预测数据值。展示类似于 [Figure 12-11](#fig_12_11)
    的结果。
- en: '![exercise 12-5](assets/plad_1211.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![exercise 12-5](assets/plad_1211.png)'
- en: Figure 12-11\. Results of Exercise 12-5
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Figure 12-11\. Exercise 12-5 的结果
- en: This exercise highlights the problems with underfitting and overfitting. The
    model with too few parameters does a poor job at predicting the data. On the other
    hand, the model with many parameters fits the data *too well* and risks being
    overly sensitive to noise and failing to generalize to new data. Strategies for
    finding the balance between under- and overfitting include cross-validation and
    Bayes information criterion; these are topics that you would learn about in a
    machine learning or statistics book.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习突出了欠拟合和过拟合的问题。参数过少的模型在预测数据时表现不佳。另一方面，参数过多的模型过度拟合数据，并且风险过于敏感于噪声并且无法泛化到新数据。寻找欠拟合和过拟合之间平衡的策略包括交叉验证和贝叶斯信息准则；这些是您在机器学习或统计书籍中学习的主题。
- en: Grid Search Exercises
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网格搜索练习
- en: Exercise 12-6\.
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 12-6\.
- en: 'Your goal here is simple: reproduce [Figure 12-8](#fig_12_8) following the
    instructions presented in the text around that figure. Print out the regression
    coefficients to compare. For example, the following results were obtained using
    the grid resolution parameter set to 50:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的目标很简单：按照围绕图表周围给出的指示重现 [Figure 12-8](#fig_12_8)。打印出回归系数以进行比较。例如，使用网格分辨率参数设置为
    50 得到了以下结果：
- en: '[PRE8]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Once you have working code, try a few different resolution parameters. I made
    [Figure 12-8](#fig_12_8) using a resolution of 100; you should also try other
    values, e.g., 20 or 500\. Also note the computation time for higher resolution
    values—and this is only a two-parameter model! An exhaustive high-resolution grid
    search for a 10-parameter model is extremely computationally intensive.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了可运行的代码，请尝试几个不同的分辨率参数。我使用分辨率为 100 制作了 [Figure 12-8](#fig_12_8)；您还应尝试其他值，例如
    20 或 500。同时注意更高分辨率值的计算时间——这只是一个双参数模型！对于一个 10 参数模型的详尽高分辨率网格搜索极其计算密集。
- en: Exercise 12-7\.
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 练习 12-7\.
- en: 'You have seen two different methods for evaluating the fit of a model to data:
    sum of squared errors and *R*². In the previous exercise, you used the sum of
    squared errors to evaluate the model fit to data; in this exercise, you will determine
    whether *R*² is equally viable.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经了解了两种不同的方法来评估模型对数据的拟合度：平方误差和 *R*²。在前一个练习中，您使用了平方误差来评估模型对数据的拟合度；在这个练习中，您将确定
    *R*² 是否同样可行。
- en: 'The coding part of this exercise is simple: modify the code from the previous
    exercise to compute *R*² instead of SSE (make sure to modify a copy of the code
    instead of overwriting the previous exercise).'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习的编码部分很简单：修改上一个练习的代码，计算 *R*² 而不是 SSE（确保修改代码的副本而不是覆盖上一个练习的代码）。
- en: 'Now for the challenging part: you will find that *R*² is terrible! It gives
    a completely wrong answer. Your job is to figure out why that is (the online code
    solution contains a discussion on this point). Hint: store the predicted data
    from each parameter pair so you can inspect the predicted values, and then compare
    against the observed data.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是具有挑战性的部分：您会发现 *R*² 很糟糕！它给出了完全错误的答案。您的任务是找出其中的原因（在线代码解决方案中包含了对这一点的讨论）。提示：存储每个参数对的预测数据，以便您可以检查预测值，然后与观察数据进行比较。
- en: '^([1](ch12.xhtml#idm45733294729312-marker)) V E Sathishkumar, Jangwoo Park,
    and Yongyun Cho, “Using Data Mining Techniques for Bike Sharing Demand Prediction
    in Metropolitan City,” *Computer Communications*, 153, (March 2020): 353–366,
    data downloaded from [*https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand*](https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '^([1](ch12.xhtml#idm45733294729312-marker)) V E Sathishkumar, Jangwoo Park
    和 Yongyun Cho，“Using Data Mining Techniques for Bike Sharing Demand Prediction
    in Metropolitan City,” *Computer Communications*, 153, (2020 年 3 月): 353–366，数据下载自
    [*https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand*](https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand).'
- en: ^([2](ch12.xhtml#idm45733294283376-marker)) Wikipedia, s.v. “multicollinearity,”
    [*https://en.wikipedia.org/wiki/Multicollinearity*](https://en.wikipedia.org/wiki/Multicollinearity).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch12.xhtml#idm45733294283376-marker)) Wikipedia，s.v. “multicollinearity”，[*https://en.wikipedia.org/wiki/Multicollinearity*](https://en.wikipedia.org/wiki/Multicollinearity).
- en: ^([3](ch12.xhtml#idm45733294153856-marker)) Max Roser, Hannah Ritchie, and Esteban
    Ortiz-Ospina, “World Population Growth,” OurWorldInData.org, 2013, [*https://ourworldindata.org/world-population-growth*](https://ourworldindata.org/world-population-growth).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch12.xhtml#idm45733294153856-marker)) Max Roser, Hannah Ritchie 和 Esteban
    Ortiz-Ospina，“World Population Growth,” OurWorldInData.org, 2013，[*https://ourworldindata.org/world-population-growth*](https://ourworldindata.org/world-population-growth).
- en: ^([4](ch12.xhtml#idm45733293926768-marker)) If you encounter Python errors,
    you might need to rerun previous code then re-create the design matrix variables.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch12.xhtml#idm45733293926768-marker)) 如果你遇到 Python 错误，可能需要重新运行之前的代码，然后重新创建设计矩阵变量。
