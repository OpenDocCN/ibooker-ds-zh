- en: 'Chapter 57\. Ethics and Figs: Why Data Scientists Cannot Take Shortcuts'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第57章。伦理与无花果：为什么数据科学家不能走捷径
- en: Jennifer Lewis Priestley
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 詹妮弗·刘易斯·普里斯特利
- en: '![](Images/JENNIFER_PRIESTLEY.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/JENNIFER_PRIESTLEY.png)'
- en: Associate Dean & Dir. of the Analytics and Data Science Institute, Kennesaw
    State University
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 亚特兰大州立大学分析与数据科学研究所副院长兼主任
- en: I would not give a fig for the simplicity this side of complexity, but I would
    give my life for the simplicity on the other side of complexity.
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我不在乎简单性在复杂性这一侧，但我会为复杂性另一侧的简单性奉献我的生命。
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Supreme Court justice Oliver Wendell Holmes Jr.
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最高法院法官奥利弗·温德尔·霍尔姆斯小学
- en: Data scientists should take a minute to reflect on the preceding quote.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家应花时间反思前面的引用。
- en: Simplifying the complex is hard. Calculators, computers, and downloadable packages
    are all mediums of expediency of calculation rather than substitutions for computational
    ability.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 简化复杂是困难的。计算器、计算机和可下载包都是计算速度的工具，而不是计算能力的替代品。
- en: In the rush to become a “data scientist,” many individuals are shortcutting
    the process—stopping at the near side of complexity. While the concept of the
    “citizen data scientist” has its place, too many individuals who represent themselves
    as data scientists have no formal training in data science beyond a weekend boot
    camp. The consequence is greater than just confusion related to the definition
    of “data scientist”—it’s a major source of the myriad ethical issues that are
    emerging relative to algorithmically biased outcomes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在急于成为“数据科学家”的过程中，许多人走捷径——止步于复杂性的近侧。虽然“公民数据科学家”的概念有其存在的理由，但太多自称为数据科学家的人在数据科学领域没有接受过正规的培训，只是参加了周末的集训营。其后果不仅仅是与“数据科学家”定义相关的混乱，还成为了涉及算法偏见结果的众多伦理问题的主要来源。
- en: Note that “algorithms” themselves are not biased; deep learning is no more “biased”
    than addition. However, both are subject to two sources of bias—human biases inherent
    to model specification and the data we select to build an algorithm.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，“算法”本身并不带有偏见；深度学习和加法一样没有“偏见”。然而，两者都受到两种偏见的影响——模型规范中固有的人类偏见以及我们选择用来构建算法的数据。
- en: To that end, ethical data scientists should consider three basic questions in
    the context of algorithm development.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，道德的数据科学家在算法开发的背景下应考虑三个基本问题。
- en: What problem am I trying to solve?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我试图解决什么问题？
- en: Too many individuals shortcut the logic and go straight to the methods without
    understanding the data. Worse, many analytical platforms simply allow the dumping
    of data into a “black box,” with multiple machine learning approaches happening
    simultaneously, followed by an automated sorting by classification rate. These
    platforms—on the near side of complexity—require no model specification consideration
    for the original question. In other words, the approach could be computationally
    optimized—but for a different question.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人在逻辑上走捷径，直接采用方法而不理解数据。更糟糕的是，许多分析平台简单地允许将数据倒入“黑匣子”，同时进行多种机器学习方法，然后按分类率自动排序。这些平台——在复杂性的近侧——不需要对原始问题进行模型规范考虑。换句话说，该方法可能在计算上进行了优化——但是用于不同的问题。
- en: Is the data that I am using to train the algorithm representative of the population
    that will be subject to the outputs?
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用的数据是否代表将受到输出影响的人群？
- en: If the data selected to develop and train the algorithm comes from a homogenous
    subset of the population, but the results are intended to be applied to a diverse
    population, classification accuracy for groups not included in the original training
    set will always be worse. If they are responsible for primary data collection,
    data scientists need to understand the principles of experimental design and sampling
    to ensure representation. If the data were collected previously (more likely),
    data scientists still have a responsibility to ensure the training dataset does
    not exhibit meaningful differences across the population to which the algorithm
    will be applied.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用于开发和训练算法的数据来自人群的同质子集，但其结果将应用于多样化人群，则原始训练集中未包括的群体的分类准确率总是较低的。如果他们负责主要数据收集，数据科学家需要理解实验设计和抽样原则，以确保代表性。如果数据是之前收集的（更可能），数据科学家仍然有责任确保训练数据集在应用算法的人群中没有显著差异。
- en: Can I explain the effects of the inputs/features (or if not, can I prove that
    the outcomes are not biased)?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我能解释输入/特征的影响吗（或者如果不能，我能证明结果没有偏差吗）？
- en: 'The “right to explanation” means that individuals have a right to understand
    how decisions that have a direct impact on their lives were made. The common example
    is the requirement that lenders be able to explain credit decisions. In mathematical
    terms: what is the effect of x on y?'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: “解释权”意味着个人有权了解对其生活有直接影响的决策是如何做出的。一个常见的例子是要求放贷人能够解释信用决策。在数学术语中，这意味着 x 对 y 的影响是什么？
- en: While most supervised statistical modeling techniques are directly interpretable,
    many machine learning techniques are not. Data scientists need to thoughtfully
    consider whether it is acceptable if they cannot explain how inputs used to develop
    an algorithm impact people’s lives (and almost all algorithms do so in some way).
    Alternatively, if the algorithm is correctly specified and the input data has
    been tested for bias, is it acceptable to forgo interpretability in favor of post
    hoc interpretations and explanation by example?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数监督统计建模技术是直接可解释的，但许多机器学习技术却不是。数据科学家需要深思熟虑地考虑，如果他们无法解释开发算法所用输入如何影响人们的生活（而几乎所有算法在某种程度上都会影响到人们的生活），这是否可接受。或者，如果算法被正确规定并且输入数据已经经过偏差测试，那么放弃可解释性以支持事后解释和示例解释是否可接受？
- en: As a community, most data scientists have ethical intentions. However, intentions
    are insufficient, and shortcuts have consequences. As a community, data scientists
    have a responsibility to work through to the simplicity on the far side of the
    complexity to ensure the development and application of socially responsible algorithms,
    which are prone to falter on the near side of complexity.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个社区，大多数数据科学家都有道德意图。然而，意图是不足的，捷径会带来后果。作为社区，数据科学家有责任通过简化复杂性来确保开发和应用社会责任算法的发展，这些算法在复杂性的近侧容易出现失误。
